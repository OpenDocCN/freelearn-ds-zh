

# 第七章：Spark 中的结构化流

随着数据量和数据速度的每日增长，数据处理的世界已经迅速发展。因此，从实时数据中分析和提取洞察的需求变得越来越关键。作为 Apache Spark 的一个组件，结构化流已经出现成为一个强大的框架，用于实时处理和分析数据流。本章深入探讨结构化流的领域，探索其功能、特性和实际应用。

在本章中，我们将涵盖以下主题：

+   实时数据处理

+   流式处理的基本原理

+   流式架构

+   Spark Streaming

+   结构化流

+   流式源和接收器

+   结构化流的进阶主题

+   结构化流中的连接

到本章结束时，你将了解 Spark Streaming 和实时数据洞察的力量。

我们将首先探讨实时数据处理的意义。

# 实时数据处理

在当今快节奏和以数据驱动为主的世界中，实时数据处理变得越来越关键。组织需要分析并从到达的数据中提取洞察，使他们能够及时做出决策并采取即时行动。Apache Spark 的一个强大组件 Spark Streaming 通过提供一个可扩展和容错的框架来处理实时数据流来满足这一需求。

实时数据处理在各个行业中获得了巨大的重要性，从金融和电子商务到物联网（IoT）和社交媒体。虽然传统的批量处理方法在许多场景中适用，但在需要即时洞察和行动时却力不从心。实时数据处理通过允许在数据到达时进行分析和处理来填补这一空白，使组织能够及时做出决策并迅速应对变化的情况。

实时数据处理涉及对流数据的持续摄取、处理和分析。与**批量处理**不同，批量处理在静态数据集上运行，实时数据处理系统处理的是实时生成和更新的数据。这些数据可以来自各种渠道，包括传感器、日志、社交媒体流和金融交易。

实时数据处理的关键特性如下：

+   **低延迟**：实时数据处理旨在最小化数据生成和处理之间的时间延迟。它需要快速高效的处理能力，以提供近乎瞬间的洞察和响应。

+   **可扩展性**：实时数据处理系统必须能够处理高容量和高速度的数据流。能够水平扩展并在多个节点上分配处理能力对于适应不断增长的数据负载是至关重要的。

+   **容错性**：鉴于流数据的连续性，实时处理系统需要能够抵御故障。它们应具备恢复失败的机制，并确保处理不间断。

+   **流数据模型**：实时数据处理系统在**流数据**上运行，这是一个无界的事件或记录序列。流数据模型旨在处理数据的连续流动，并提供基于事件时间和窗口计算的机制。

实时数据处理的特点导致以下几项优势：

+   **快速响应**：实时处理使组织能够快速响应变化的情况、事件或机会。它允许及时采取行动，例如欺诈检测、异常检测、实时监控和警报。

+   **个性化**：实时处理通过实时分析和采取用户行为，实现个性化体验。它推动了实时推荐、动态定价、定向广告和内容个性化。

+   **操作效率**：实时处理提供了对操作流程的洞察，使组织能够优化其操作，识别瓶颈，并在实时内提高效率。它促进了预测性维护、供应链优化和实时资源分配。

+   **情境感知**：实时数据处理通过持续分析和汇总来自各种来源的数据，帮助组织获得情境感知。它使网络安全、金融市场和应急响应系统等领域的实时分析、监控和决策成为可能。

总结来说，实时流涉及数据的持续传输和处理，从而实现即时洞察和快速决策。它在不同行业中具有广泛的应用，并利用各种技术来促进高效和可靠的流处理。

在下一节中，我们将探讨流式的基础知识，并了解流式如何对实时操作有益。

# 什么是流？

流是指数据的连续和实时处理，这些数据是在生成或接收时产生的。与在固定间隔以块或批量处理数据的批处理不同，流允许连续和增量地处理数据。它允许应用程序实时摄取、处理和分析数据，从而实现及时决策和对事件的即时响应。

有多种类型的流式架构可供处理流数据。我们将在下一节中探讨它们。

# 流式架构

流式架构旨在处理流数据的连续和高速度特性。它们通常由三个关键组件组成：

+   **流式处理源**：这些是流数据的来源，例如物联网设备、传感器、日志、社交媒体流或消息系统。流式源持续产生和实时发射数据。

+   **流处理引擎**：流处理引擎负责摄取、处理和分析流数据。它提供了处理流数据的连续性和增量性质所必需的基础设施和计算能力。

+   **流式处理接收器**：流式处理接收器是处理后的数据存储、可视化或采取行动的目的地。它们可以是数据库、数据仓库、仪表板或消费处理数据的系统。

存在着各种流处理架构，包括以下几种：

+   **事件驱动架构**：在事件驱动架构中，事件由源生成，然后由引擎捕获和处理，导致即时反应并触发实时动作或更新。这个框架促进了实时事件处理，支持事件驱动微服务的发展，并有助于创建反应式系统。

    事件驱动架构的优势在于其提供响应性、可扩展性和灵活性。这允许对事件进行快速反应，从而在系统响应中培养敏捷性。

+   **Lambda 架构**：Lambda 架构无缝集成批处理和流处理，有效地管理历史数据和实时数据。这涉及到数据流的并行处理，以实现实时分析，并辅以离线批处理进行深入和全面的分析。

    这种方法特别适合需要平衡实时洞察和深入历史分析的应用。Lambda 架构的优势在于其提供容错性、可扩展性和处理大量数据的能力。这是通过利用批处理和流处理技术的综合力量实现的。

+   **统一流处理架构**：统一流处理架构，如 Apache Spark 的 Structured Streaming，旨在为批处理和流处理提供统一的 API 和处理模型。它们通过抽象管理单独的批处理和流处理系统的复杂性，简化了实时应用程序的开发和部署。

    这种架构通过提供一种简化的方法来开发和部署实时应用程序，抽象了复杂性。这对于简单性和易于开发至关重要的场景来说非常理想，允许开发者更多地关注业务逻辑而不是复杂的技术细节。

    优点在于它简化了开发，减少了运营开销，并确保批处理和流处理的一致性。

这些架构根据特定应用的特定需求满足不同的需求。事件驱动适用于实时反应，lambda 在实时和历史数据之间取得平衡，统一流处理则提供了一种简化和统一的方法来处理批处理和流处理。每种方法都有其优势和权衡，使它们根据系统的特定需求适用于各种场景。

在以下章节中，我们将深入探讨结构化流的具体内容、其关键概念以及它与 Spark Streaming 的比较。我们还将探索无状态和有状态流处理、流源和流目的地，提供代码示例和实际说明以增强理解。

# 介绍 Spark Streaming

如您迄今为止所看到的，Spark Streaming 是基于 Apache Spark 构建的强大实时数据处理框架。它扩展了 Spark 引擎的功能，以支持高吞吐量、容错和可扩展的流处理。Spark Streaming 使开发者能够使用与批处理相同的编程模型来处理实时数据流，从而简化从批处理到流工作负载的过渡。

在核心上，Spark Streaming 将实时数据流划分为小批量或微批量，然后使用 Spark 的分布式计算能力进行处理。每个微批量被视为**弹性分布式数据集**（**RDD**），这是 Spark 用于分布式数据处理的根本抽象。这种方法允许开发者利用 Spark 广泛的生态系统中的库，如 Spark SQL、MLlib 和 GraphX，用于实时分析和机器学习任务。

## 探索 Spark Streaming 的架构

Spark Streaming 遵循**主从架构**，其中驱动程序作为主节点，工作节点处理数据。高级架构包括以下组件：

+   **驱动程序**: 驱动程序运行主应用程序并管理 Spark Streaming 应用程序的整体执行。它将数据流划分为批量，在工作节点上调度任务，并协调处理。

+   **接收器**: 接收器负责连接到流数据源并接收数据。它们在工作节点上运行，并从 Kafka、Flume 或 TCP 套接字等源拉取数据。接收到的数据随后存储在工作节点的内存中。

+   **离散流（DStream）**: DStream 是 Spark Streaming 中的基本抽象。它表示被划分为小而离散的 RDD 的数据连续流。DStream 提供了一个高级 API 来对流数据进行转换和操作。

+   `map`、`filter`和`reduceByKey`应用于 DStream 中的每个 RDD。例如`count`、`saveAsTextFiles`和`foreachRDD`等操作触发流计算的执行并产生结果。

+   **输出操作**：输出操作允许将处理后的数据写入外部系统或存储。Spark Streaming 支持各种输出操作，例如写入文件、数据库或将数据发送到仪表板进行可视化。

## 关键概念

为了有效地使用 Spark Streaming，理解一些关键概念是很重要的：

+   **DStreams**：如前所述，DStreams 表示 Spark Streaming 中的连续数据流。它们是一系列 RDD，其中每个 RDD 包含特定时间间隔的数据。DStreams 支持各种转换和操作，使得在流上执行复杂计算成为可能。

+   **窗口操作**：窗口操作允许你在数据流中的滑动窗口上应用转换。它支持固定窗口大小或基于时间段的计算，使得窗口聚合或基于时间的连接等任务成为可能。

+   **有状态操作**：Spark Streaming 允许你在批次之间维护有状态信息。它使得需要维护和更新状态的操作成为可能，例如累积计数。

+   **Checkpointing**：Checkpointing 是 Spark Streaming 中确保容错和恢复的关键机制。它定期保存有关流应用程序的元数据，包括配置、DStream 操作和已处理的数据。它使得在出现故障时能够恢复应用程序。

## 优势

现在，我们将看到在实时操作中使用 Spark Streaming 的不同优势：

+   **统一的处理模型**：Spark Streaming 的一个显著优势是其与更大的 Spark 生态系统的集成。它利用与批量处理相同的编程模型，使用户能够无缝地在批处理和实时处理之间切换。这种统一的处理模型简化了开发，并降低了熟悉 Spark 的用户的学习曲线。

+   **高级抽象**：Spark Streaming 提供了高级抽象，如 DStreams 来表示流数据。DStreams 旨在处理连续数据流，并允许轻松集成现有的 Spark API、库和数据源。这些抽象提供了一个熟悉且表达性强的编程接口，用于处理实时数据。

+   **容错性和可伸缩性**：Spark Streaming 通过利用 Spark 的 RDD 抽象提供容错处理。它通过重新计算丢失的数据来自动从故障中恢复，确保处理管道保持弹性和健壮。此外，Spark Streaming 可以通过在机器集群中分配工作负载来实现水平扩展，从而有效地处理大规模数据流。

+   **窗口计算**：Spark Streaming 支持窗口计算，这允许在滑动或翻滚窗口的数据上执行基于时间的分析。窗口操作提供了在执行聚合、时间序列分析和窗口级转换方面的灵活性。这种能力在根据时间特征或模式分析流式数据时特别有用。

+   **广泛的数据源**：Spark Streaming 可以无缝集成到各种数据源中，包括 Kafka、Flume、Hadoop 分布式文件系统 (HDFS) 和 Amazon S3。这一广泛的数据源允许用户从多个流中摄取数据并将其与现有数据管道集成。Spark Streaming 还支持自定义数据源，使得可以与专有或专业化的流式平台集成。

虽然 Spark Streaming 提供了强大的实时数据处理能力，但也有一些挑战需要考虑。

## 挑战

为应用程序构建流式架构带来了一系列挑战，如下所述：

+   **端到端延迟**：当 Spark Streaming 以微批处理方式处理数据时，会引入延迟。端到端延迟可能因批处理间隔、数据源和计算复杂度等因素而变化。

+   **容错性**：Spark Streaming 通过 RDD 线性和检查点提供容错性。然而，接收器或驱动程序程序中的故障仍然可能干扰流式处理。处理和恢复故障是确保 Spark Streaming 应用程序可靠性的重要考虑因素。

+   **可扩展性**：将 Spark Streaming 应用程序扩展以处理大量数据并满足高吞吐量要求可能是一个挑战。适当的资源分配、调整和集群管理对于实现可扩展性至关重要。

+   **数据排序**：Spark Streaming 在多个工作节点上并行处理数据，这可能会影响事件的顺序。在某些用例中，确保事件顺序的正确性变得非常重要，开发者在设计应用程序时需要考虑这一点。

总结来说，Spark Streaming 将 Apache Spark 的强大功能带到了实时数据处理中。它与 Spark 生态系统的集成、高级抽象、容错性、可扩展性和对窗口计算的支撑使其成为处理流式数据的诱人选择。通过利用 Spark Streaming 的优势，组织可以解锁宝贵的见解并在实时做出明智的决策。

在下一节中，我们将探讨 Structured Streaming，这是 Apache Spark 中一个更新、更具有表现力的流式 API，它克服了 Spark Streaming 的一些限制和挑战。我们将讨论其核心概念、与 Spark Streaming 的区别以及其在实时数据处理方面的优势。

# 引入 Structured Streaming

Structured Streaming 是 Apache Spark 的一个革命性补充，为实时数据处理带来了新的范式。它引入了一个高级 API，无缝集成批处理和流处理，提供了一个统一的编程模型。Structured Streaming 将流数据视为一个无界的表或 DataFrame，使开发者能够使用熟悉的类似 SQL 的查询和转换来表示复杂的计算。

与 Spark Streaming 的微批处理模型不同，Structured Streaming 遵循连续处理模型。它随着数据的到来增量处理数据，提供低延迟和接近实时的结果。这种向连续处理的转变为交互式分析、动态可视化和实时决策打开了新的可能性。

## 关键特性和优势

Structured Streaming 在几个关键方面优于传统的流处理框架：

+   **表达性 API**：Structured Streaming 提供了一个声明式 API，允许开发者使用 SQL 查询、DataFrame 操作和 Spark SQL 函数来表示复杂的流计算。这使得具有 SQL 或 DataFrame 专长的开发者可以轻松过渡到实时数据处理。

+   **容错性和精确一次语义**：Structured Streaming 通过维护必要的元数据和状态信息来保证端到端容错性和精确一次语义。它优雅地处理故障，并确保即使在出现故障或重试的情况下，数据也只被处理一次。

+   **可伸缩性**：Structured Streaming 利用 Spark 引擎的可伸缩性，通过向集群添加更多工作节点来实现水平扩展。它可以处理高吞吐量的数据流，并在数据量增加时无缝扩展。

+   **统一批处理和流处理**：使用 Structured Streaming，开发者可以为批处理和流处理使用相同的 API 和编程模型。这种统一简化了应用程序的开发和维护，因为不需要管理单独的批处理和流处理代码库。

+   **生态系统集成**：Structured Streaming 无缝集成到更广泛的 Spark 生态系统中，使得可以使用 Spark SQL、MLlib 和 GraphX 等库进行实时分析、机器学习和流数据的图处理。

现在，让我们看看 Structured Streaming 和 Spark Streaming 之间的一些区别。

## Structured Streaming 与 Spark Streaming 的比较

Structured Streaming 在几个基本方面与 Spark Streaming 不同：

+   **处理模型**：Spark Streaming 以微批处理的方式处理数据，其中每个批次都被视为一个独立的 RDD。相比之下，Structured Streaming 以连续的方式增量处理数据，将流视为一个无界的表或 DataFrame。

+   **API 和查询语言**：Spark Streaming 主要提供基于 RDD 转换和操作的底层 API。而 Structured Streaming 则提供了一种更高级的 API，具有类似 SQL 的查询、DataFrame 操作和 Spark SQL 函数。这使得表达复杂的计算并利用 SQL 的力量进行实时分析变得更加容易。

+   **容错性**：Spark Streaming 和 Structured Streaming 都提供容错性。然而，Structured Streaming 的容错性是通过维护必要的元数据和状态信息来实现的，而 Spark Streaming 则依赖于 RDD 线性和检查点来进行故障恢复。

+   **数据处理保证**：Spark Streaming 默认提供至少一次处理保证，即在出现故障时可能会处理一些重复数据。另一方面，Structured Streaming 提供了精确一次处理语义，确保即使在出现故障或重试的情况下，每个事件也只被处理一次。

## 限制和注意事项

虽然 Structured Streaming 提供了显著的优势，但也有一些限制和注意事项需要考虑：

+   **事件时间处理**：在 Structured Streaming 中，正确处理事件时间（如时间戳提取、水印和迟到数据处理）至关重要。应确保正确处理乱序事件。

+   **状态管理**：Structured Streaming 允许你在批次之间维护状态信息，这可能会引入与状态管理和可扩展性相关的挑战。监控内存使用量和配置适当的状态保留策略对于最佳性能至关重要。

+   **生态系统兼容性**：虽然 Structured Streaming 与 Spark 生态系统集成良好，但某些库和功能可能不完全兼容实时流式处理用例。在使用 Structured Streaming 应用程序之前，评估特定库和功能之间的兼容性非常重要。

+   **性能考虑**：Structured Streaming 的连续处理模型与微批处理相比引入了不同的性能考虑因素。事件速率、处理时间和资源分配等因素需要仔细监控和优化，以实现高效的实时数据处理。

在下一节中，我们将深入探讨无状态和有状态流式处理的概念，探讨它们在 Structured Streaming 上下文中的差异和用例。

# 流式处理基础

让我们从查看一些流式处理的基本概念开始，这些概念将帮助我们熟悉流式处理的不同范式。

## 无状态流式处理 – 一次处理一个事件

无状态流指的是独立处理每个事件，不考虑任何来自先前事件的上下文或历史。在这种方法中，每个事件都是独立处理的，处理逻辑不依赖于任何累积的状态或来自过去事件的信息。

无状态流非常适合每个事件可以独立处理的情况，输出完全由事件本身的内容决定。这种方法通常用于简单的过滤、转换或增强操作，不需要你在事件之间维护任何上下文信息。

## 状态流 – 维护状态信息

状态流涉及在处理过程中维护和利用跨多个事件的环境信息或状态。处理逻辑考虑事件的历史，并使用累积的信息做出决策或执行计算。状态流使更复杂的分析和依赖上下文或累积知识的复杂计算成为可能。

状态流要求你在新事件到达时维护和更新状态信息。状态可以很简单，如运行计数，也可以更复杂，涉及聚合、窗口计算或维护会话信息。在状态流应用程序中，适当的状态管理对于确保正确性、可扩展性和容错性至关重要。

让我们了解无状态流和状态流之间的区别。

## 无状态流和状态流之间的区别

无状态流和状态流之间的主要区别可以总结如下：

+   无状态流独立处理事件，而状态流在事件之间维护和使用累积的状态信息。

+   无状态流适用于不依赖过去事件的简单操作，而状态流使复杂的计算成为可能，这些计算需要上下文或累积的知识。

+   无状态流通常更容易实现和推理，而状态流在管理状态、容错性和可扩展性方面引入了额外的挑战。

+   无状态流通常用于实时过滤、转换或基本聚合，而状态流对于窗口计算、会话化和状态化连接是必要的。

在设计实时数据处理系统时，理解无状态流和状态流之间的区别至关重要，因为它有助于确定给定用例的适当处理模型和需求。

现在，让我们来看看结构化流的一些基本概念。

# 结构化流概念

要理解结构化流，了解数据到达时在近实时场景中发生的不同操作对我们来说很重要。我们将在下一节中理解它们。

## 事件时间和处理时间

在 Structured Streaming 中，有两个重要的时间概念——事件时间和处理时间：

+   **事件时间**: 事件时间指的是事件发生或生成的时刻。它通常嵌入在数据本身中，代表时间戳或一个字段，指示事件在现实世界中发生的时刻。事件时间对于基于时间顺序分析数据或执行基于窗口的计算至关重要。

+   **处理时间**: 另一方面，处理时间指的是事件被流应用程序处理的时间。它由系统时钟或事件被处理引擎摄取的时间决定。处理时间对于需要低延迟或即时响应的任务很有用，但可能无法准确反映实际事件顺序。

基于这些不同的时间概念，我们可以确定哪个最适合给定的用例。理解两者之间的区别很重要。基于这一点，可以确定数据处理策略。

## 水印和迟到数据处理

现在，我们将讨论如何处理在实时应用程序中未在定义时间到达的数据。有不同方式来处理这种情况。Structured Streaming 有一个内置机制来处理这类数据。这些机制包括：

+   **水印**: 水印是 Structured Streaming 中用于处理事件时间和处理延迟或迟到数据的机制。水印是一个阈值时间戳，指示系统在某个时刻之前看到的最大事件时间。它允许系统跟踪事件时间的进度并确定何时可以安全地发出特定窗口的结果。

+   **处理延迟数据**: 迟到数据指的是时间戳超过水印阈值的事件。Structured Streaming 提供了处理迟到数据的选择，例如丢弃它、更新现有结果或将它单独存储以供进一步分析。

这些内置机制为用户节省了大量时间，并有效地处理迟到数据。

接下来，我们将看到，一旦数据到达，我们将如何开始对其进行流处理操作。

## 触发器和输出模式

触发器决定了流应用程序何时应发出结果或触发计算的执行。Structured Streaming 支持不同类型的触发器：

+   **事件时间触发器**: 事件时间触发器基于新事件的到达或水印超过某个阈值时进行操作。它们基于事件时间语义，实现更准确和高效的处理。

+   **处理时间触发器**: 这些触发器基于处理时间进行操作，允许您指定计算应执行的时间间隔或持续时间。

Structured Streaming 还提供了不同的输出模式。输出模式决定了数据在接收器中的更新方式。接收器是我们会在流操作后写入输出的地方：

+   **完整模式**：在此模式下，整个更新后的结果，包括输出中的所有行，都被写入到接收器。这种模式提供了最全面的数据视图，但对于大型结果集来说可能非常消耗内存。

+   **追加模式**：在追加模式下，只有自上次触发器以来添加到结果表中的新行被写入到接收器。这种模式适用于结果是一个只追加流的情况。

+   **更新模式**：更新模式只将更改的行写入到接收器，保留自上次触发器以来未更改的现有行。这种模式适用于结果表是增量更新的情况。

现在，让我们看看在流数据上可以执行的不同类型的聚合操作。

## 窗口操作

Structured Streaming 中的窗口操作允许您在特定的时间窗口内对数据进行分组和聚合。这些操作的窗口可以根据事件时间或处理时间定义，并提供了一种在给定时间范围内对事件子集进行计算的方法。

常见的窗口操作类型包括以下几种：

+   **滚动窗口**：滚动窗口将流划分为非重叠的固定大小窗口。每个事件恰好属于一个窗口，并且每个窗口的计算是独立进行的。

+   **滑动窗口**：滑动窗口创建重叠窗口，这些窗口以固定的时间间隔在流上滑动或移动。每个事件可以贡献给多个窗口，并且可以在重叠部分进行计算。

+   **会话窗口**：会话窗口根据指定的会话超时将时间上接近或属于同一会话的事件分组。会话被定义为一系列彼此之间在一定时间阈值内的事件。

在流处理中，我们经常使用的下一个操作是连接操作。现在，我们将看看如何使用连接操作处理流数据。

## 连接和聚合

Structured Streaming 支持在流数据上执行连接和聚合，从而实现复杂的分析和数据转换：

+   **连接**：流连接允许您根据公共键或条件结合两个或多个流或一个流与静态/参考数据。连接操作可以使用事件时间或处理时间执行，并支持不同的连接类型，如内连接、外连接和左/右连接。

+   `count`, `sum`, `average`, `min`, 和 `max`.

Structured Streaming 提供了灵活且表达丰富的 API 来处理事件时间、触发器、输出模式、窗口操作、连接和聚合，这使得开发者能够对流数据进行全面的实时分析和计算。通过理解这些概念，开发者可以轻松且精确地构建复杂的流应用程序。

在下一节中，我们将探讨如何使用流数据源和接收器读取和写入数据。

# 流数据源和接收器

流式源和汇是流式系统中不可或缺的组件，它们使得从外部系统摄取数据并将处理后的数据输出到外部目标成为可能。它们构成了流式应用程序与数据源或汇之间的连接器。

流式源从各种输入系统中检索数据，如消息队列、文件系统、数据库或外部 API，并将数据提供给流式应用程序进行处理。另一方面，流式汇接收应用程序处理后的数据并将其写入外部存储、数据库、文件系统或其他系统以进行进一步分析或消费。

存在着不同类型的流式源和汇。接下来我们将探索其中的一些。

## 内置流式源

结构化流为各种流式源提供了内置支持，使得与流行的数据系统集成变得容易。一些常用的内置流式源包括以下内容：

+   **文件源**：文件源允许您从目录中的文件或基于文件系统的文件流（如 HDFS 或 Amazon S3）中读取数据。

+   **KafkaSource**：KafkaSource 允许从 Apache Kafka（一个分布式流平台）中消费数据。它提供了容错、可伸缩和高吞吐量的数据流摄取。

+   **套接字源**：套接字源允许流式应用程序从**传输控制协议**（**TCP**）套接字读取数据。这对于数据通过网络连接发送的场景很有用，例如日志流或外部系统发送的数据。

+   **结构化流源**：结构化流源允许开发者通过扩展内置源接口来定义自己的流式源。它提供了与自定义或专有数据源集成的灵活性。

## 自定义流式源

除了内置的流式源之外，结构化流允许开发者创建自定义流式源，以从任何可以通过编程访问的系统摄取数据。自定义流式源可以通过扩展结构化流 API 提供的`Source`接口来实现。

在实现自定义流式源时，开发者需要考虑数据摄取、事件时间管理、容错性和可伸缩性等方面。他们必须定义如何获取数据，如何将其分区和分配给工作节点，以及如何处理迟到数据和模式演变。

与不同的流式源类似，我们也有流式汇。接下来让我们来探索它们。

## 内置流式汇

结构化流为各种流式汇提供了内置支持，使得将处理后的数据输出到不同的系统变得容易。一些常用的内置流式汇包括以下内容：

+   **控制台源**: 控制台源将输出数据写入控制台或标准输出。它对于调试和快速原型设计很有用，但不适合生产使用。

+   **文件源**: 文件源将输出数据写入目录或基于文件的系统（如 HDFS 或 Amazon S3）。它允许数据被存储并在以后用于批量处理或归档目的。

+   **Kafka 源**: Kafka 源允许您将数据写入 Apache Kafka 主题。它为 Kafka 提供了容错、可扩展和高吞吐量的输出，以便其他系统进行消费。

+   `ForeachWriter` 接口。它提供了将数据写入外部系统或对输出数据进行自定义操作的灵活性。

## 自定义流式源

与自定义流式源类似，开发者可以通过扩展 `Sink` 接口在结构化流中实现自定义流式源。在某些情况下，您可能需要将数据写回到可能不支持流式写入的系统。这可能是一个数据库或基于文件的存储系统。自定义流式源允许与内置源不支持的外部系统或数据库集成。

当实现自定义流式源时，开发者需要定义外部系统如何写入或处理输出数据。这可能涉及建立连接、处理批处理或缓冲，并确保容错和一次精确语义。

在下一节中，我们将讨论结构化流的高级技术。

# 结构化流的高级技术

结构化流具有某些内置功能，使其成为某些批量操作的默认选择。您不必自己设计架构，结构化流会为您处理这些属性。以下是一些例子。

## 处理容错

在流式系统中，容错至关重要，以确保数据完整性和可靠性。结构化流提供了内置的容错机制来处理流式源和源端的故障：

+   **源容错**: 结构化流通过使用水印跟踪事件时间进度并检查点与流相关的元数据，确保源端端到端的容错。如果出现故障，系统可以恢复并从最后一个一致状态继续处理。

+   **源容错**: 源的容错依赖于特定源实现提供的保证。某些源可能天生提供一次精确语义，而其他源可能依赖于幂等写入或去重技术来实现至少一次语义。源实现应仔细选择，以确保数据一致性和可靠性。

开发者应该考虑他们使用的流源和流的容错特性，并配置适当的检查点间隔、保留策略和恢复机制，以确保其流应用的可靠性。

Structured Streaming 同样内置了对模式演化的支持。让我们在下一节中探讨这一点。

## 处理模式演化

Structured Streaming 为处理流数据源中的模式演化提供了支持。模式演化指的是随时间变化的数据结构或模式的变化。

Structured Streaming 可以通过应用模式推断或模式合并的概念来处理模式演化。在从流源读取时，初始模式从传入的数据中推断出来。随着数据的发展，后续的 DataFrame 将与初始模式合并，以适应任何新或更改的字段。

以下代码片段展示了在 Structured Streaming 中处理模式演化的方法：

```py
stream = spark.readStream \
  .format("csv") \
  .option("header", "true") \
  .schema(initialSchema) \
  .load("data/input")
mergedStream = stream \
  .selectExpr("col1", "col2", "new_col AS col3")
```

在这个示例中，初始模式通过 `schema` 方法显式提供。当新数据到达并带有额外的字段，如 `new_col` 时，可以使用 `selectExpr` 方法选择并将其合并到流中。

处理模式演化对于确保流应用中的兼容性和灵活性至关重要，在这些应用中，数据模式可能会随时间变化或演化。

# Structured Streaming 中的不同连接方式

Structured Streaming 的一个关键特性是它能够在一个汇集中将不同类型的数据流连接在一起。

## 流-流连接

流-流连接，也称为 **流-流组** 或 **流-流关联**，涉及根据公共键或条件将两个或多个流数据源连接起来。在这种类型的连接中，每个来自流的传入事件都与具有相同键或满足指定条件的其他流的事件相匹配。

流-流连接允许实时数据关联和丰富，使得能够将多个数据流合并以获得更深入的见解和执行复杂分析。然而，与批处理或流-静态连接相比，流-流连接由于流数据的无界性和潜在的事件时间偏移，带来了独特的挑战。

流-流连接的一种常见方法是使用窗口操作。通过在流上定义重叠或滚动窗口，可以基于它们的键将同一窗口内的事件连接起来。为了确保准确和有意义的连接，需要对窗口大小、水印和事件时间特性进行仔细考虑。

这是一个使用 Structured Streaming 进行流-流连接的示例：

```py
stream1 = spark.readStream.format("kafka")
.option("kafka.bootstrap.servers", "localhost:9092") .option("subscribe", "topic1") .load()
stream2 = spark.readStream.format("kafka").option("kafka.bootstrap.servers","localhost:9092") .option("subscribe", "topic2") .load()
 joinedStream =stream1.join(stream2, "common_key")
```

在这个示例中，从不同的主题读取了两个 Kafka 流，`stream1` 和 `stream2`。然后应用 `join` 方法，基于两个流共有的 `common_key` 字段执行连接操作。

## 流-静态连接

流式静态连接，也称为**流式批量连接**，涉及将流数据源与静态或参考数据集连接起来。静态数据集通常表示随时间保持恒定的参考数据，例如配置数据或维度表。

流式静态连接用于使用来自静态数据集的附加信息或属性丰富流数据。例如，您可以将用户活动事件流与静态用户配置文件表连接起来，以丰富每个事件的用户相关细节。

在 Structured Streaming 中执行流式静态连接时，您可以加载静态数据集作为静态 DataFrame，然后使用连接方法与流 DataFrame 执行连接操作。由于静态数据集不会改变，连接操作可以使用默认的“右外连接”模式执行。

这里是一个 Structured Streaming 中流式静态连接的示例：

```py
stream =spark.readStream.format("kafka")
.option("kafka.bootstrap.servers", "localhost:9092") .option("subscribe", "topic") .load()
  staticData = spark.read.format("csv") .option("header", "true") .load("data/static_data.csv")
 enrichedStream = stream.join(staticData,"common_key")
```

在此示例中，流数据是从 Kafka 源读取的，静态数据集是从 CSV 文件加载的。然后使用连接方法根据“`common_key`”字段执行流式静态连接。

流式流连接和流式静态连接都为实时数据分析和数据增强提供了强大的功能。当使用这些连接操作时，必须仔细管理事件时间特性、窗口选项和数据一致性，以确保准确可靠的结果。此外，还应考虑性能因素，以处理大量数据并满足实时流应用中的低延迟要求。

# 最后的想法和未来的发展

Structured Streaming 已经成为 Apache Spark 中实时数据处理的一个强大框架。其统一的编程模型、容错性和与 Spark 生态系统的无缝集成使其成为构建可扩展和健壮流式应用的理想选择。

随着 Structured Streaming 的不断发展，有几个领域有望在未来得到发展。以下是一些：

+   **增强对流式源和目的地的支持**：提供更多内置连接器以支持流行的流式系统和数据库，以及改进与自定义源和目的地的集成和兼容性。

+   **高级事件时间处理**：引入更多高级事件时间处理功能，包括支持事件时间偏斜检测和处理、事件去重和水印优化。

+   **性能优化**：持续改进 Structured Streaming 的性能，特别是在数据量高和计算复杂的场景中。这可能包括内存管理、查询计划和查询优化技术的优化。

+   **与 AI 和机器学习的集成**：进一步将结构化流与 Spark 中的 AI 和机器学习库（如 MLlib 和 TensorFlow）集成，以实现流式数据的实时机器学习和预测分析。

+   **与流式数据仓库的无缝集成**：提供与流式数据仓库或数据湖（如 Apache Iceberg 或 Delta Lake）更好的集成，以实现可扩展和高效的存储以及流式数据的查询。

总结来说，结构化流（Structured Streaming）为 Apache Spark 中的实时数据处理提供了一种现代且表达力强的方法。其易用性、可扩展性、容错性和与 Spark 生态系统的集成使其成为构建健壮和可扩展流式应用的有价值工具。通过利用本章涵盖的概念和技术，开发者可以充分发挥结构化流实时数据处理的潜力。

# 摘要

在本章中，我们探讨了结构化流的基本概念和高级技术。

我们首先理解了结构化流的基本原理、其优势以及支撑其运作的核心概念。然后，我们讨论了 Spark Streaming 及其提供的功能。

之后，我们深入探讨了结构化流的核心功能。然后，我们进一步深入到高级主题，例如结构化流中的窗口操作。我们探讨了滑动窗口和滚动窗口，这些窗口使我们能够在指定的时间窗口内执行聚合和计算，从而允许对流式数据进行基于时间的分析。此外，我们还探讨了有状态流式处理，这涉及到在流式应用中维护和更新状态，以及集成外部库和 API 以增强结构化流的功能。

最后，我们探讨了实时数据处理的最新趋势，并在总结关键要点和洞察中结束本章。

在下一章中，我们将探讨机器学习技术以及如何使用 Spark 进行机器学习。
