# 第一部分：数据工程

本节介绍了分布式计算范式，并展示了 Spark 如何成为大数据处理的事实标准。

完成本节后，你将能够从各种数据源摄取数据，进行清洗、集成，并以可扩展和分布式的方式将其写入持久化存储，例如数据湖。你还将能够构建实时分析管道，并在数据湖中执行变更数据捕获（CDC）。你将理解 ETL 和 ELT 数据处理方式的关键区别，以及 ELT 如何为云端数据湖世界的发展演变。本节还介绍了 Delta Lake，以使基于云的数据湖更加可靠和高效。你将理解 Lambda 架构的细微差别，作为同时执行批处理和实时分析的一种手段，以及 Apache Spark 结合 Delta Lake 如何大大简化 Lambda 架构。

本节包括以下章节：

+   *第一章**，分布式计算基础*

+   *第二章**，数据摄取*

+   *第三章**，数据清洗与集成*

+   *第四章**，实时数据分析*
