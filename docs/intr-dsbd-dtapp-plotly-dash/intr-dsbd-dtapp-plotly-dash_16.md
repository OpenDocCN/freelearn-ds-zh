# 第十三章：*第十三章*：下一步

欢迎来到本书的结束，也是你 Dash 旅程的开始！虽然我们已经涵盖了许多主题、用例、图表类型和互动功能，但在使用 Dash 构建内容方面，天高地阔，潜力无限。

到现在为止，你应该已经像制作演示文稿一样熟练地构建仪表板。你应该能够使用各种数据可视化技巧和图表类型，熟练地处理和展示数据。

但本书只是让你踏上了道路，接下来还有很多东西值得探索，所以我们将介绍一些如何更深入地探索我们所涵盖主题的思路和建议。我们还将关注一些书中没有涉及的方面，你可能会有兴趣进一步探索。

本章将涵盖以下内容：

+   扩展数据处理和准备技能

+   探索更多数据可视化技巧

+   探索其他 Dash 组件

+   创建你自己的 Dash 组件

+   操作化和可视化机器学习模型

+   提升性能并使用大数据工具

+   使用 Dash Enterprise 进行大规模部署

# 技术要求

本章不涉及编码或部署，因此没有任何技术要求。

你可以通过两种方向学习新事物并进行探索：自上而下的方法，你想做某件事或被要求做某件事；或者自下而上的方法，从工具开始，探索它们的可能性以及你能用它们做什么：

+   **自上而下**：由于某种要求或限制，通常你需要做某件事——比如让某件事变得更快、更好或更容易。为了解决这些问题，或满足某些要求，你需要学习一些新东西。这种方法的价值主要在于它的实用性。你知道什么是有用的，什么是必需的，这帮助你将心思和精力集中在你想要的解决方案上，这些解决方案专注于解决实际问题。同时，如果你只专注于实际问题，你可能会错过一些新技术和方法，而这些可能会使你的实际生活变得更加轻松。

+   **自下而上**：这是一种从另一方向出发的方法。你从学习一些新事物开始，单纯为了探索或好奇。它可以是一些大问题，比如机器学习，或者像学习一个你每天都在用的函数中的新参数这么小的事。这突然会在你脑海中打开新的可能性，也拓展了你对可能性的认知。这是你可以主动去做的，无论你的工作需求如何。那句著名的格言“我越是练习，我就越幸运”似乎适用于这种情况。这种方法的好处是，你能正确地学习事物，建立扎实的理论基础，从而能更好地掌控手头的技巧。缺点是，你可能变得过于理论化，失去与现实的联系，忘记了什么是真正有用的，什么是没用的。

我发现自己时常在不同的阶段之间切换，有时候我把大部分时间都用来集中精力解决某个具体问题（自上而下），并产生非常实际的解决方案。然后，我会进入一个停滞期，感觉我的想象力不再活跃，创造力也没那么强。我接着进入一种更理论化的模式。在这个阶段，学习新事物变得非常有趣和引人入胜。在掌握了足够的新知识并对某个主题有了较好的理解后，我会突然获得新的想法，再回到实际操作模式，就这样循环往复。

你可以看看什么方法对你有效。现在，让我们探索一些你在 Dash 旅程中可能感兴趣的具体主题。

# 拓展你的数据处理和准备技能

如果你读过任何关于数据科学的入门书籍，你可能已经被告知，数据科学家花费大部分时间在清理数据、重新格式化数据和调整数据形态上。

你在阅读本书时，可能已经看到过这个过程的实际应用！

我们已经多次看到，要将数据转化为某种格式，所需的代码量、精神努力，尤其是领域知识有多少。一旦我们将数据转换为标准化格式，例如长格式（tidy）DataFrame，那么我们的生活就会变得更轻松。

你可能想学习更多关于 pandas 和 NumPy 的知识，以获得更完整的数据重塑技巧，按照你想要的方式进行数据处理。正如本章开始时提到的那样，学习没有实际目的的 pandas 技巧对于拓展你的想象力有很大帮助。学习正则表达式在文本分析中也非常有用，因为文本通常是非结构化的，找到并提取特定模式对你的数据清洗过程帮助很大。统计学和数值技巧无疑会带来巨大的改变。归根结底，我们基本上是在处理数字。

提升数据处理技能自然会引导我们实现更简便、更好的可视化。

# 探索更多数据可视化技巧

我们看到使用 Plotly Express 是多么简单，以及它有多么强大。我们也看到它为我们提供了丰富的选项。同时，我们受限于必须将数据整理成特定格式的要求，而这正是 Plotly Express 无法帮助的地方。作为数据科学家，我们需要在这一点上介入。

我们涵盖了四种主要的图表类型，而这只是可用图表的一个非常小的子集。正如本章开头提到的，数据可视化有几种方式。你可能需要生成某种特定的图表，进而不得不学习它。或者，你可能会学到一种新的图表，它激发你为某些特定的使用场景更好地总结某些数据类型。

你可能会根据图表使用的几何形状/属性了解新的图表类型，如饼图或点图。你也可以根据它们的用途来探索它们；例如，统计图表和财务图表。许多图表类型归结为基本形状，如点、圆、矩形、线条等等。它们的展示方式和组合方式使它们独具特色。

另一种有趣的可视化技术是使用子图。尽管我们在书中广泛使用了分面（faceting），但分面本质上是同一个可视化展示多个数据子集。而子图则允许你创建一组可以彼此独立的图表。这有助于你在一个图表中展示丰富的报告，其中每个子图展示数据的不同方面。

在探索并掌握了新的可视化技术和图表后，你可能会希望将它们放入一个应用程序中，并使它们具有交互性。

# 探索其他 Dash 组件

我们覆盖了基本的 Dash 组件，此外还有许多其他可用组件。请记住，这里有三种可能的方式：

+   `dash_table`，它能够提供相当复杂的功能和电子表格风格的选项。

+   `DatePickerSingle` 和 `DatePickerRange`，它们的功能不言自明。`Interval` 组件允许你在某一时间段过后执行代码。`Store` 组件允许你将数据存储在用户的浏览器中，以便你希望保存一些数据来增强应用的可用性/功能性。还有一个 `Upload` 组件用于上传文件。这些都可以在 Dash 核心组件中找到。还有一些其他有趣的包，适用于其他使用场景。例如，Dash Cytoscape 非常适合进行互动式图表（网络）可视化。我们在使用可视化调试工具时多次看到了它，看到它是如何大大简化我们对应用理解的。这在许多行业中都有广泛的应用。为了让用户能够在你的图表上绘制图形，你可以查看 Dash 提供的图像注释选项以及 Dash Canvas 包。它们一起提供了丰富的选项，让用户可以用鼠标在图表上直接绘制，使用矩形等设定形状，或仅通过拖动鼠标。

+   **探索一些社区组件**：由于 Dash 是一个开源项目，并且有一个创建和集成新组件的机制，许多人独立地创建了自己的 Dash 组件。Dash Bootstrap Components 就是其中之一，我们在工作中依赖了它。还有许多其他的组件，新的组件也一直在不断推出。

这将引出另一个话题，那就是创建你自己的 Dash 组件。

# 创建你自己的 Dash 组件

很有趣的是，Dash 的官方策略是成为“Python、R 和 Julia 的 React”。如你所知，React 是一个非常大的 JavaScript 框架，用于构建用户界面。React 有一个庞大的开源组件库，而 Dash 核心组件基本上是可以在 Python 中使用的 React 组件。这意味着，如果 Dash 没有提供某些功能，而你又希望能够使用，你可以考虑自己开发，雇佣开发者来构建，或者你也可以赞助该功能的开发，让 Plotly 团队来构建。有些我们使用的组件就是由那些希望获得某些尚未提供的功能的客户赞助的。这也是一种支持 Dash 的方式，它也使得所有使用开源 Dash 的人都受益。

有清晰的指引教你如何创建自己的 Dash 组件，作为一个 Dash 开发者，探索这个选项是很有益的。它肯定会让你更深入地理解这个库的运作方式，也许你最终会自己创建一个流行的组件！

通过所有的数据处理、可视化和组件，你拥有了一个丰富的词汇库，可以做的不仅仅是将数据点绘制在图表上。探索机器学习能够做的事情，可以大大提升你的模型，并使其可供他人使用。

# 使机器学习模型可操作化和可视化

机器学习和深度学习当然是完全不同的话题，但是通过前面提到的所有技能，您可以将机器学习提升到一个新的水平。在一天结束时，您将使用图表来表达关于数据的某些想法，并且通过良好的交互式数据可视化词汇，您可以为用户提供许多选项来测试不同的模型和调整超参数。

# 提升性能并使用大数据工具

这是一个非常重要的话题，我们始终需要确保我们的应用程序在可接受的水平上运行。我们在书中没有涉及这个问题，因为重点主要是学习如何创建一个具有使其工作的所有其他细节的 Dash 应用程序。我们还使用了一个非常小的数据集，仅有几兆字节。即使是小数据集，优化它也可能至关重要。大数据可以处理一个庞大的文件，也可以处理一个需要多次处理的小文件。

这些是优化性能可以做的一些事情，但大数据是一个完全不同的主题，因此以下是一些提示和一些可以探索的领域。

一旦我们知道我们的应用程序将如何运行以及我们将使用哪些功能，我们可以清理一些可能会妨碍应用程序性能的不必要的代码和数据。以下是一些可以立即对我们的应用程序进行的想法：

+   **仅加载必要的数据**：我们加载了整个文件，并且对每个回调，我们单独查询了 DataFrame。这可能是浪费的。例如，如果我们仅有人口数据的回调，我们可以创建一个单独的文件（然后是单独的子集）DataFrame，该 DataFrame 仅包含相关列，并仅查询它们，而不是使用整个 DataFrame。

+   **优化数据类型**：有时您需要加载包含许多重复的相同值的数据。例如，贫困数据集包含许多重复的国家名称。我们可以使用 pandas 分类数据类型来优化这些值：

1.  加载`sys`模块并查看字符串（国家名称）和整数的字节大小差异：

    ```py
    import sys
    sys.getsizeof('Central African Republic')
     73
    ```

1.  获取整数值的大小：

    ```py
    sys.getsizeof(150)
     28
    ```

1.  我们可以看到字符串几乎占用整数大小的三倍的内存差异。这基本上是分类数据类型的作用。它创建一个字典，将每个唯一值映射到一个整数。然后使用整数来编码和表示这些值，您可以想象这可以节省多少空间。

1.  加载贫困数据集：

    ```py
    import pandas as pd
    poverty = pd.DataFrame('data/poverty.csv')
    ```

1.  获取包含国家名称列并检查其内存使用情况的子集：

    ```py
    poverty[['Country Name']].info()
    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 8287 entries, 0 to 8286
    Data columns (total 1 columns):
      #   Column        Non-Null Count  Dtype 
    ---  ------        --------------  ----- 
     0   Country Name  8287 non-null   object
    dtypes: object(1)
     memory usage: 64.9+ KB
    ```

1.  将列转换为分类数据类型并检查内存使用情况：

    ```py
    poverty['Country Name'].astype('category').to_frame().info()
    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 8287 entries, 0 to 8286
    Data columns (total 1 columns):
     #   Column        Non-Null Count  Dtype   
    ---  ------        --------------  -----   
     0   Country Name  8287 non-null   category
    dtypes: category(1)
    memory usage: 21.8 KB
    ```

1.  使用一个简单的命令，将我们的国家编码为整数，我们将内存使用量从 64.9 KB 减少到 21.8 KB，大约是原始大小的三分之一。

1.  你可能还想考虑了解更多关于可用的大数据技术和技巧。目前最重要的项目之一是 Apache Arrow 项目。该项目是数据库社区和数据科学社区的领军人物之间的合作。该项目的一个重要目标是统一跨学科的努力，尤其是跨编程语言的努力。

1.  当你想读取一个 CSV 文件时，举个例子，你希望它在内存中表示为一个 DataFrame。无论你使用 R、Python，还是其他任何语言，你都会执行非常相似的操作，如排序、选择、过滤等等。这里有很多重复的工作，每种语言都实现了自己的 DataFrame 规范。从性能角度来看，已经观察到大量的计算资源浪费在将对象从一种语言转换到另一种语言以及读写操作上。这在将对象保存到磁盘并在另一种语言中打开时也会发生。这会造成资源浪费，并且在许多情况下，迫使很多团队必须选择一种语言以便于沟通，减少浪费的时间和精力。

1.  Apache Arrow 项目的目标之一是为数据对象（如 DataFrame）创建一个单一的内存表示方式。这样，数据对象可以在不同的编程语言之间传递，而无需进行任何转换。你可以想象这将使事情变得多么简单。此外，跨编程语言和学科的合作带来了巨大的收益，因为单一的规范正在被使用和维护。

1.  每种编程语言可以实现基于单一规范的库。对于 Python，包是 `pyarrow`，它非常有趣，值得探索。在很多情况下，它可以单独使用，在其他情况下，它可以与 pandas 集成。

1.  一个非常有趣的文件格式，也是该项目的一部分，就是 `parquet` 格式。就像 CSV 和 JSON 一样，`parquet` 是语言无关的。它是一个文件，可以用任何支持 `parquet` 阅读器的语言打开。好消息是 pandas 已经支持这个格式了。

1.  `parquet` 的一个重要特性是强大的压缩功能，可以大幅减少文件的大小。因此，它非常适合长期存储和高效利用空间。不仅如此，由于格式的缘故，打开和读取这些文件也非常高效。文件包含关于文件的元数据，以及模式信息。文件还被安排成独立的结构，以便高效读取。

1.  `parquet` 使用的某些技术如下：

    +   `parquet` 主要按列存储数据。面向行的格式适合事务处理。例如，当用户登录网站时，我们需要检索与该用户相关的数据（一行），并且可能需要根据该用户的交互写入和更新这一行数据。但是在分析处理方面（这是我们感兴趣的领域），例如，如果我们想分析每个国家的平均收入，我们只需要读取数据集中的两列。如果数据是按列排列的，那么我们可以从列的开始跳到结尾，比起行式存储，它能够更快地提取数据。我们可以读取其他列，但只有在需要对它们进行进一步分析时才会这么做。

    +   `parquet` 还执行字典编码。它使用了其他几种编码方案。例如，存在增量编码，当数据包含大数字时，增量编码效果最佳。它保存列中第一个数字的值，并只保存与连续数字之间的差异。例如，如果你有以下列表：[1,000,000, 1,000,001, 1,000,002, 1,000,003]，这些数字可以表示为：[1,000,000, 1, 1, 1]。我们保存了第一个元素的完整值，并且仅保存每个元素与前一个元素之间的差异。这样可以节省大量内存。这在使用时间戳时特别有用，时间戳通常表示为具有小差异的大整数，特别是在时间序列数据中。当你想要读取列表时，程序可以进行计算并给出原始数字。虽然还使用了其他编码策略，但这只是另一个示例。

    +   `parquet` 可以将一个文件拆分成多个文件，并从包含这些文件的文件夹中读取和合并它们。假设有一个包含人员数据的文件，该文件有 1000 万行。其中一列可能是性别，包含“男”和“女”两个值。如果我们将文件拆分成两个文件，每个文件对应一个值，那么我们就不需要再存储整列数据了。我们只需要在文件名中包含“female”，如果请求该列，程序就知道如何填充该列的所有值，因为它们都是相同的。

    +   `parquet` 对列中的数据组使用的一个方法是，它包含每个组的最小值、最大值和一些其他统计信息。假设有一个包含 1000 万行的文件，并且你只想读取介于 10 和 20 之间的值。假设这些行被拆分成每组 100 万行。现在，每个组的头部会包含该组的最小值和最大值。在扫描时，如果你遇到一个最大值为 6 的组，那么你就知道请求的值不在该组中。通过一次比较，你就跳过了 100 万个值。

现在，如果你已经掌握了所有这些技术，并且能够制作有洞察力的可视化效果、良好的交互性，并提供真正有帮助的仪表板，你仍然可能没有足够的经验（或兴趣）去处理 Dash 的大规模部署。此时，你可能会考虑 Dash Enterprise。

# 使用 Dash Enterprise 进行大规模部署

当你在一个拥有众多用户且已有现有基础设施的大型组织中进行部署时，可能会遇到一些你之前没有考虑或预见到的事情。想象一下，你的应用程序将由公司中的数百人使用。你如何处理应用程序的访问权限？你如何管理密码，当有人辞职或加入时会发生什么？你是否在安全方面有足够的经验，足以自信地处理如此大规模的部署？

在这些情况下，数据工程的角色比以往更为重要。有效且安全地存储数据变得更加重要。如果这不是你的专业领域，扩展性和管理起来可能会非常棘手。你的主要工作是设计和创建有助于发现洞察力的东西，而不是维护大规模的应用程序。在某些情况下，你可能具备所需的技能，但不想担心这些问题，主要想专注于界面、模型和可视化。

这正是 Dash Enterprise 可以提供帮助的地方。它基本上是你所熟知的 Dash，但具有许多专门为大规模部署设计的选项。

Dash Enterprise 还提供了一个完整的在线工作台，配有流行的 IDE 和笔记本，因此你还可以与同事在线协作。如果有大量用户需要共同工作，这可能会有所帮助。

专业服务也提供给大型客户，在这种情况下，你将能够接触到那些构建 Dash 的人，他们与许多经历过与你相似的经历的组织合作过，你可以从他们那里获得在许多重要领域的帮助。

这些只是一些想法，但最终决定性的是你的创造力、领域知识和努力工作，因此让我们总结一下本章和整本书所涉及的内容。

# 总结

我们从专注于处理数据的基本技能的重要性开始。我们强调了掌握数据处理和清洗技能的重要性，这将使你能够将数据格式化为你所需要的形状，并使其易于分析和可视化。我们还提到了各种数据可视化技巧和可以探索的图表类型，以提高你在视觉表达想法方面的流利度。

我们还讨论了书中未涉及的其他 Dash 组件，以及社区组件，这些组件正在不断开发中。最终，你可能决定开发自己的一组组件，并为 Dash 生态系统贡献额外的功能，我期待着`pip install dash-your-components`！

接着我们讨论了探索机器学习，以及如何使我们的模型变得可视化和互动。建立数据操作、可视化和交互技能将大大帮助你让模型更具可解释性和可用性，尤其是对于非技术受众。

我们探讨了一些大数据选项，并讨论了其中一个重要的项目，尽管还有许多其他项目需要考虑和探索。

最后，我们讨论了 Dash 提供的付费企业解决方案——Dash Enterprise；当你的项目是大型组织或部署的一部分时，这个解决方案可能会有意义。

非常感谢你的阅读，希望你喜欢这本书。我期待看到你自己的应用上线，拥有你自己的设计、模型、选项和定制功能。
