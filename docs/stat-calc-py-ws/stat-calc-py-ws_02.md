# 第二章：Python 统计的主要工具

概述

本章介绍了大多数统计从业者在 Python 中使用的主要库的实际介绍。它将涵盖一些最重要和有用的概念、函数和每个关键库的**应用程序编程接口**（**API**）。几乎本书其余部分所需的所有计算工具都将在本章介绍。

在本章结束时，您将了解 NumPy 库的数组矢量化背后的思想，并能够使用其抽样功能。您将能够初始化 pandas 数据框架以表示表格数据并操纵其内容。您还将了解数据分析中数据可视化的重要性，并能够利用 Python 的两个最流行的可视化库：Matplotlib 和 Seaborn。

# 介绍

在上一章中对 Python 语言进行了复习之后，我们现在准备着手处理本书的主要主题：数学和统计。

除其他外，计算数学和统计的一般领域可以分为三个主要的工具中心组件：表示和工程；分析和计算；最后是可视化。在 Python 编程语言的生态系统中，专门的库专门用于这些组件中的每一个（即 pandas、NumPy、Matplotlib 和 Seaborn），使整个过程变得模块化。

虽然可能存在其他类似的软件包和工具，但我们将讨论的库已被证明具有广泛的功能和支持强大的计算、数据处理和可视化选项，使它们成为多年来 Python 程序员首选的工具之一。

在本章中，我们将介绍这些库的每一个，并了解它们的主要 API。通过实践方法，我们将看到这些工具如何在 Python 中创建、操纵、分析和可视化数据方面提供了极大的自由和灵活性。了解如何使用这些工具也将使我们能够更好地应对本研讨会后面章节中的更复杂的主题。

# 科学计算和 NumPy 基础知识

到目前为止，在本研讨会中已经多次使用了术语**科学计算**；在该术语的最广泛意义上，它表示使用计算机程序（或任何具有计算能力的东西）来模拟和解决数学、工程或科学中的特定问题的过程。示例可能包括数学模型来查找和分析生物和社会数据中的模式和趋势，或者使用经济数据进行未来预测的机器学习模型。正如您可能已经注意到的那样，这个定义与数据科学的一般领域有重要的重叠，有时甚至可以互换使用这些术语。

在 Python 中许多（如果不是大多数）科学计算项目的主要工具是 NumPy 库。由于 NumPy 是一个外部库，不会预先安装在 Python 中，我们需要下载并安装它。正如您可能已经知道的那样，在 Python 中安装外部库和软件包可以使用包管理器（如 pip 或 Anaconda）轻松完成。

从您的终端运行以下命令，使用 pip 在您的 Python 环境中安装 NumPy：

```py
$ pip install numpy
```

如果您目前在 Anaconda 环境中，您可以运行以下命令：

```py
$ conda install numpy
```

通过这些简单的命令，我们已经完成了安装过程中的所有必要步骤。

NumPy 的一些最强大的功能包括对象的矢量化、多维数组表示；实现广泛的线性代数函数和变换；以及随机抽样。我们将在本节中涵盖所有这些主题，从数组的一般概念开始。

## NumPy 数组

实际上，在上一章中，当我们讨论 Python 列表时，我们已经接触到了数组的概念。一般来说，数组也是一系列不同元素，可以单独访问或作为整体进行操作。因此，NumPy 数组与 Python 列表非常相似；事实上，声明 NumPy 数组的最常见方式是将 Python 列表传递给`numpy.array()`方法，如下所示：

```py
>>> import numpy as np
>>> a = np.array([1, 2, 3])
>>> a
array([1, 2, 3])
>>> a[1]
2
```

我们需要牢记的最大区别是，NumPy 数组中的元素需要是相同类型的。例如，在这里，我们试图创建一个包含两个数字和一个字符串的数组，这导致 NumPy 强制将数组中的所有元素转换为字符串（`<U21`数据类型表示少于 21 个字符的 Unicode 字符串）：

```py
>>> b = np.array([1, 2, 'a'])
>>> b
array(['1', '2', 'a'], dtype='<U21')
```

与我们可以创建多维 Python 列表的方式类似，NumPy 数组也支持相同的选项：

```py
>>> c = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
>>> c
array([[1, 2, 3],
       [4, 5, 6],
       [7, 8, 9]])
```

注意

在使用 NumPy 时，我们经常将多维数组称为矩阵。

除了使用 Python 列表进行初始化外，我们还可以创建特定形式的 NumPy 数组。特别是，可以使用`np.zeros()`和`np.ones()`分别初始化全零或全一的矩阵，指定维度和数据类型。让我们看一个例子：

```py
>>> zero_array = np.zeros((2, 2))  # 2 by 2 zero matrix
>>> zero_array
array([[0., 0.],
       [0., 0.]])
```

这里，元组`(2, 2)`指定正在初始化的数组（或矩阵）应具有二乘二的维度。正如我们在零后面看到的点所示，NumPy 数组的默认数据类型是浮点数，并且可以使用`dtype`参数进一步指定：

```py
>>> one_array = np.ones((2, 2, 3), dtype=int)  # 3D one integer matrix
>>> one_array
array([[[1, 1, 1],
        [1, 1, 1]],
        [[1, 1, 1],
        [1, 1, 1]]])
```

全零或全一矩阵是数学和统计学中常见的对象，因此这些 API 调用在以后将被证明非常有用。现在，让我们看一个常见的矩阵对象，其元素都是随机数。使用`np.random.rand()`，我们可以创建一个给定形状的矩阵，其元素在 0（包括）和 1（不包括）之间均匀抽样：

```py
>>> rand_array = np.random.rand(2, 3)
>>> rand_array
array([[0.90581261, 0.88732623, 0.291661  ],
       [0.44705149, 0.25966191, 0.73547706]])
```

请注意，这里我们不再将所需矩阵的形状作为元组传递，而是作为`np.random.rand()`函数的单独参数传递。

如果您对随机性的概念和从各种分布中进行随机抽样不熟悉，不用担心，因为我们将在本章后面涵盖这个主题。现在，让我们继续讨论 NumPy 数组，特别是关于索引和切片。

您会记得，为了访问 Python 列表中的单个元素，我们将其索引传递到列表变量旁边的方括号中；对于一维 NumPy 数组也是如此：

```py
>>> a = np.array([1, 2, 3])
>>> a[0]
1
>>> a[1]
2
```

然而，当数组是多维的时，我们不再使用多个方括号来访问子数组，而是只需使用逗号来分隔各个索引。例如，我们可以按如下方式访问三乘三矩阵中第二行第二列的元素：

```py
>>> b = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
>>> b
array([[1, 2, 3],
       [4, 5, 6],
       [7, 8, 9]])
>>> b[1, 1]
5
```

切片 NumPy 数组可以以相同的方式进行：使用逗号。这种语法在帮助我们访问矩阵中具有多个维度的子矩阵方面非常有用：

```py
>>> a = np.random.rand(2, 3, 4)  # random 2-by-3-by-4 matrix
>>> a
array([[[0.54376986, 0.00244875, 0.74179644, 0.14304955],
        [0.77229612, 0.32254451, 0.0778769 , 0.2832851 ],
        [0.26492963, 0.5217093 , 0.68267418, 0.29538502]],
       [[0.94479229, 0.28608588, 0.52837161, 0.18493272],
        [0.08970716, 0.00239815, 0.80097454, 0.74721516],
        [0.70845696, 0.09788526, 0.98864408, 0.82521871]]])
>>> a[1, 0: 2, 1:]
array([[0.28608588, 0.52837161, 0.18493272],
       [0.00239815, 0.80097454, 0.74721516]])
```

在上面的例子中，`a[1, 0: 2, 1:]`帮助我们访问原始矩阵`a`中的数字；即在第一个轴（对应索引`1`）中的第二个元素，第二个轴（对应`0: 2`）中的前两个元素，以及第三个轴（对应`1:`）中的最后三个元素。这个选项是 NumPy 数组比 Python 列表更强大和灵活的一个原因，因为 Python 列表不支持多维索引和切片，正如我们所演示的。

最后，另一个重要的用于操作 NumPy 数组的语法是`np.reshape()`函数，正如其名称所示，它可以改变给定 NumPy 数组的形状。需要这种功能的情况可能会多次出现：当我们需要以某种方式显示数组以便更好地阅读时，或者当我们需要将数组传递给只接受特定形状数组的内置函数时。

我们可以在以下代码片段中探索这个函数的效果：

```py
>>> a
array([[[0.54376986, 0.00244875, 0.74179644, 0.14304955],
        [0.77229612, 0.32254451, 0.0778769 , 0.2832851 ],
        [0.26492963, 0.5217093 , 0.68267418, 0.29538502]],
       [[0.94479229, 0.28608588, 0.52837161, 0.18493272],
        [0.08970716, 0.00239815, 0.80097454, 0.74721516],
        [0.70845696, 0.09788526, 0.98864408, 0.82521871]]])
>>> a.shape 
(2, 3, 4)
>>> np.reshape(a, (3, 2, 4))
array([[[0.54376986, 0.00244875, 0.74179644, 0.14304955],
        [0.77229612, 0.32254451, 0.0778769 , 0.2832851 ]],
       [[0.26492963, 0.5217093 , 0.68267418, 0.29538502],
        [0.94479229, 0.28608588, 0.52837161, 0.18493272]],
       [[0.08970716, 0.00239815, 0.80097454, 0.74721516],
        [0.70845696, 0.09788526, 0.98864408, 0.82521871]]])
```

请注意，`np.reshape()`函数不会就地改变传入的数组；相反，它会返回原始数组的副本，新形状的数组而不修改原始数组。我们也可以将这个返回值赋给一个变量。

另外，请注意，虽然数组的原始形状是`(2, 3, 4)`，但我们将其改为`(3, 2, 4)`。只有当两个形状产生的元素总数相同时才能这样做*(2 x 3 x 4 = 3 x 2 x 4 = 24)*。如果新形状与数组的原始形状不对应，将会引发错误，如下所示：

```py
>>> np.reshape(a, (3, 3, 3))
-------------------------------------------------------------------------
ValueError                          Traceback (most recent call last)
...
ValueError: cannot reshape array of size 24 into shape (3,3,3)
```

说到重塑 NumPy 数组，转置矩阵是重塑的一种特殊形式，它*翻转*了矩阵中的元素沿着其对角线。计算矩阵的转置是数学和机器学习中的常见任务。可以使用`[array].T`语法计算 NumPy 数组的转置。例如，当我们在终端中运行`a.T`时，我们得到矩阵`a`的转置，如下所示：

```py
>>> a.T
array([[[0.54376986, 0.94479229],
       [0.77229612, 0.08970716],
        [0.26492963, 0.70845696]],
       [[0.00244875, 0.28608588],
        [0.32254451, 0.00239815],
        [0.5217093 , 0.09788526]],
       [[0.74179644, 0.52837161],
        [0.0778769 , 0.80097454],
        [0.68267418, 0.98864408]],
       [[0.14304955, 0.18493272],
        [0.2832851 , 0.74721516],
        [0.29538502, 0.82521871]]])
```

有了这个，我们可以结束我们对 NumPy 数组的介绍。在下一节中，我们将学习与 NumPy 数组紧密相关的另一个概念：矢量化。

## 矢量化

在计算机科学的最广泛意义上，**矢量化**一词表示将数学运算应用于数组（在一般意义上）的过程，逐个元素。例如，一个加法运算，其中数组中的每个元素都加上相同的项，就是一个矢量化操作；同样，对于矢量化乘法，数组中的所有元素都乘以相同的项。一般来说，当所有数组元素都经过相同的函数处理时，就实现了矢量化。

当在 NumPy 数组（或多个数组）上执行适用的操作时，默认情况下会进行矢量化。这包括二进制函数，如加法、减法、乘法、除法、幂和取模，以及 NumPy 中的几个一元内置函数，如绝对值、平方根、三角函数、对数函数和指数函数。

在我们看到 NumPy 中的矢量化操作之前，值得讨论矢量化的重要性及其在 NumPy 中的作用。正如我们之前提到的，矢量化通常是在数组中的元素上应用常见操作。由于该过程的可重复性，矢量化操作可以被优化为比其在`for`循环中的替代实现更有效。然而，这种能力的权衡是数组中的元素需要是相同的数据类型——这也是任何 NumPy 数组的要求。

有了这个，让我们继续进行下一个练习，我们将在这个练习中看到这种效果。

## 练习 2.01：计时 NumPy 中的矢量化操作

在这个练习中，我们将计算通过使用 NumPy 数组实现各种矢量化操作（如加法，乘法和平方根计算）与不使用矢量化的纯 Python 替代方案相比所实现的加速。为此，请执行以下步骤：

1.  在新的 Jupyter 笔记本的第一个单元格中，导入 NumPy 包和`timeit`库中的`Timer`类。后者将用于实现我们的计时功能：

```py
import numpy as np
from timeit import Timer
```

1.  在一个新的单元格中，使用`range()`函数初始化一个包含从 0（包括）到 1,000,000（不包括）的数字的 Python 列表，以及使用`np.array()`函数的 NumPy 数组对应项：

```py
my_list = list(range(10 ** 6))
my_array = np.array(my_list)
```

1.  现在，我们将在以下步骤中对这个列表和数组应用数学运算。在一个新的单元格中，编写一个名为`for_add()`的函数，它返回一个列表，其中的元素是`my_list`变量中的元素加上`1`（我们将使用列表推导式）。再编写一个名为`vec_add()`的函数，它返回相同数据的 NumPy 数组版本，即`my_array + 1`：

```py
def for_add():
    return [item + 1 for item in my_list]
def vec_add():
    return my_array + 1
```

1.  在下一个代码单元格中，初始化两个`Timer`对象，同时传入前面两个函数。这些对象包含我们将用于跟踪函数速度的接口。

对每个对象调用`repeat()`函数，并使用参数 10 和 10——实质上，我们重复了 100 次的定时实验。最后，由于`repeat()`函数返回表示每个函数的每次实验中经过的时间的数字列表，我们打印出此列表的最小值。简而言之，我们希望每个函数的最快运行时间：

```py
print('For-loop addition:')
print(min(Timer(for_add).repeat(10, 10)))
print('Vectorized addition:')
print(min(Timer(vec_add).repeat(10, 10)))
```

该程序产生的输出如下：

```py
For-loop addition:
0.5640330809999909
Vectorized addition:
0.006047582000007878
```

虽然你的可能不同，但两个数字之间的关系应该是清楚的：`for`循环加法函数的速度应该比向量化加法函数的速度低得多。

1.  在下一个代码单元格中，实现相同的速度比较，我们将数字乘以`2`。对于 NumPy 数组，只需返回`my_array * 2`：

```py
def for_mul():
    return [item * 2 for item in my_list]
def vec_mul():
    return my_array * 2
print('For-loop multiplication:')
print(min(Timer(for_mul).repeat(10, 10)))
print('Vectorized multiplication:')
print(min(Timer(vec_mul).repeat(10, 10)))
```

从输出中验证，向量化的乘法函数也比`for`循环版本更快。运行此代码后的输出如下：

```py
For-loop multiplication: 0.5431750800000259
Vectorized multiplication: 0.005795304000002943
```

1.  在下一个代码单元格中，实现相同的比较，计算数字的平方根。对于 Python 列表，导入并在列表推导式中使用`math.sqrt()`函数。对于 NumPy 数组，返回表达式`np.sqrt(my_array)`：

```py
import math
def for_sqrt():
    return [math.sqrt(item) for item in my_list]
def vec_sqrt():
    return np.sqrt(my_array)
print('For-loop square root:')
print(min(Timer(for_sqrt).repeat(10, 10)))
print('Vectorized square root:')
print(min(Timer(vec_sqrt).repeat(10, 10)))
```

从输出中验证，向量化的平方根函数再次比其`for`循环对应函数更快：

```py
For-loop square root:
1.1018582749999268
Vectorized square root:
0.01677640299999439
```

还要注意，`np.sqrt()`函数被实现为向量化，这就是为什么我们能够将整个数组传递给该函数。

这个练习介绍了一些 NumPy 数组的向量化操作，并演示了它们与纯 Python 循环对应函数相比有多快。

注意

要访问此特定部分的源代码，请参阅[`packt.live/38l3Nk7.`](https://packt.live/38l3Nk7 )

您也可以在[`packt.live/2ZtBSdY.`](https://packt.live/2ZtBSdY )上在线运行此示例。

这就结束了 NumPy 中的向量化主题。在下一个也是最后一个关于 NumPy 的部分中，我们将讨论该软件包提供的另一个强大功能：随机抽样。

## 随机抽样

在上一章中，我们看到了如何使用`random`库在 Python 中实现随机化的示例。然而，在该库中实现的大多数方法中，随机化是均匀的，在科学计算和数据科学项目中，有时我们需要从除均匀分布以外的分布中抽取样本。NumPy 再次提供了广泛的选择。

一般来说，从概率分布中进行随机抽样是从该概率分布中选择一个实例的过程，具有更高概率的元素更有可能被选择（或抽取）。这个概念与统计学中的随机变量的概念密切相关。随机变量通常用于模拟统计分析中的某些未知数量，它通常遵循给定的分布，具体取决于它所模拟的数据类型。例如，人口成员的年龄通常使用正态分布（也称为钟形曲线或高斯分布）来建模，而到达银行的客户通常使用泊松分布来建模。

通过随机抽样给定与随机变量相关的分布，我们可以获得该变量的实际实现，从而可以执行各种计算，以获得有关所讨论的随机变量的见解和推断。

我们将在本书的后面重新访问概率分布的概念和用法。现在，让我们简单地专注于手头的任务：如何从这些分布中抽取样本。这是通过`np.random`包来实现的，该包包括了允许我们从各种分布中抽取的接口。

例如，以下代码片段初始化了一个从正态分布中抽取的样本（请注意，由于随机性，您的输出可能与以下内容不同）：

```py
>>> sample = np.random.normal()
>>> sample
-0.43658969989465696
```

您可能已经意识到正态分布由两个统计数据来指定：均值和标准差。这些可以分别在`np.random.normal()`函数中使用`loc`（默认值为`0.0`）和`scale`（默认值为`1.0`）参数来指定，如下所示：

```py
>>> sample = np.random.normal(loc=100, scale=10)
>>> sample
80.31187658687652
```

还可以一次性以 NumPy 数组的形式抽取多个样本，而不仅仅是单个样本。为此，我们可以在`np.random.normal()`函数的`size`参数中指定所需的输出数组形状。例如，在这里，我们正在创建一个从相同正态分布中抽取的 2 x 3 矩阵样本：

```py
>>> samples = np.random.normal(loc=100, scale=10, size=(2, 3))
>>> samples
array([[ 82.7834678 , 109.16410976, 101.35105681],
       [112.54825751, 107.79073472,  77.70239823]])
```

这个选项允许我们取得输出数组，并可能对其应用其他 NumPy 特定的操作（如矢量化）。另一种方法是顺序地将单个样本抽取到列表中，然后将其转换为 NumPy 数组。

重要的是要注意，每个概率分布都有自己定义它的统计数据。正态分布，正如我们所见，有一个均值和一个标准差，而前面提到的泊松分布则是用λ（lambda）参数来定义的，它被解释为区间的期望。让我们通过一个例子来看一下：

```py
>>> samples = np.random.poisson(lam=10, size=(2, 2))
>>> samples
array([[11, 10],
       [15, 11]])
```

通常，在 NumPy 中从概率分布中抽取样本之前，您应该始终查阅相应的文档，以了解该特定分布可用的参数以及它们的默认值是什么。

除了概率分布，NumPy 还提供了其他与随机性相关的功能，这些功能可以在`random`模块中找到。例如，`np.random.randint()`函数返回两个给定数字之间的随机整数；`np.random.choice()`从给定的一维数组中随机抽取样本；而`np.random.shuffle()`则在原地随机打乱给定的序列。

这些功能在以下代码片段中展示，提供了在 Python 中处理随机性方面的重要灵活性，特别是在科学计算中：

```py
>>> np.random.randint(low=0, high=10, size=(2, 5))
array([[6, 4, 1, 3, 6],
       [0, 8, 8, 8, 8]])
>>> np.random.choice([1, 3, 4, -6], size=(2, 2))
array([[1, 1],
       [1, 4]])
>>> a = [1, 2, 3, 4]
>>> for _ in range(3):
...        np.random.shuffle(a)
...        print(a)
[4, 1, 3, 2]
[4, 1, 2, 3]
[1, 2, 4, 3]
```

每当编程中涉及随机性时，我们需要讨论的最后一个重要主题就是可重现性。这个术语表示在不同运行中从程序中获得相同的结果的能力，特别是当程序中存在与随机性相关的元素时。

当程序中存在错误但只在某些随机情况下才显现时，可重现性是至关重要的。通过强制程序每次执行时生成相同的随机数，我们有另一种方法来缩小并识别这种类型的错误，除了单元测试之外。

在数据科学和统计学中，可重现性是至关重要的。如果一个程序不可重现，那么一个研究人员可能会发现一个统计上显著的结果，而另一个研究人员却无法做到，即使两者使用相同的代码和方法。这就是为什么许多从业者已经开始在数据科学和机器学习领域非常重视可重现性的原因。

实现可重现性的最常见方法（也是最容易编程的方法）是简单地固定程序（特别是其库）的种子，这些程序利用随机性。固定与随机性相关的库的种子可以确保在同一程序的不同运行中生成相同的随机数。换句话说，这允许产生相同的结果，即使程序在不同的机器上运行多次。

为了做到这一点，我们可以简单地将一个整数传递给产生我们程序随机性的库/包的适当种子函数。例如，要为`random`库设置种子，我们可以写如下代码：

```py
>>> import random
>>> random.seed(0)  # can use any other number
```

对于 NumPy 中的随机包，我们可以写如下代码：

```py
>>> np.random.seed(0)
```

设置这些库/包的种子通常是一个很好的做法，当你为一个团队或一个开源项目做贡献时；再次，它确保团队的所有成员能够达到相同的结果，并消除了误解。

这个话题也结束了我们对 NumPy 库的讨论。接下来，我们将转向 Python 中数据科学和科学计算生态系统的另一个重要部分：pandas 库。

# 在 pandas 中处理表格数据

如果 NumPy 用于矩阵数据和线性代数运算，pandas 则设计用于处理表格形式的数据。就像 NumPy 一样，pandas 可以使用 pip 包管理器在 Python 环境中安装：

```py
$ pip install pandas
```

如果你使用 Anaconda，你可以使用以下命令下载它：

```py
$ conda install pandas
```

安装过程完成后，启动 Python 解释器并尝试导入该库：

```py
>>> import pandas as pd
```

如果这个命令没有出现任何错误消息，那么你已经成功安装了 pandas。有了这个，让我们继续我们的讨论，从 pandas 中最常用的数据结构开始，`DataFrame`，它可以表示表格数据：具有行和列标签的二维数据。这与 NumPy 数组形成对比，NumPy 数组可以具有任何维度，但不支持标记。

## 初始化 DataFrame 对象

有多种方法可以初始化`DataFrame`对象。首先，我们可以通过传递一个 Python 字典来手动创建一个，其中每个键应该是列的名称，该键的值应该是该列包含的数据，以列表或 NumPy 数组的形式。

例如，在下面的代码中，我们正在创建一个包含两行三列的表格。第一列按顺序包含数字 1 和 2，第二列包含 3 和 4，第三列包含 5 和 6：

```py
>>> import pandas as pd
>>> my_dict = {'col1': [1, 2], 'col2': np.array([3, 4]),'col3': [5, 6]}
>>> df = pd.DataFrame(my_dict)
>>> df
     col1    col2    col3
0    1       3       5
1    2       4       6
```

关于`DataFrame`对象的第一件事是，正如你从前面的代码片段中看到的那样，当一个被打印出来时，输出会自动由 pandas 的后端格式化。表格格式使得该对象中表示的数据更易读。此外，当在 Jupyter 笔记本中打印出`DataFrame`对象时，也会使用类似的格式化以实现可读性，如下面的截图所示：

![图 2.1：在 Jupyter 笔记本中打印的 DataFrame 对象](img/B15968_02_01.jpg)

图 2.1：在 Jupyter 笔记本中打印的 DataFrame 对象

初始化`DataFrame`对象的另一种常见方法是，当我们已经用 2D NumPy 数组表示其数据时，我们可以直接将该数组传递给`DataFrame`类。例如，我们可以使用以下代码初始化我们之前看过的相同 DataFrame：

```py
>>> my_array = np.array([[1, 3, 5], [2, 4, 6]])
>>> alt_df = pd.DataFrame(my_array, columns=['col1', 'col2', 'col3'])
>>> alt_df
     col1    col2    col3
0    1       3       5
1    2       4       6
```

也就是说，初始化`DataFrame`对象的最常见方式是通过`pd.read_csv()`函数，这个函数读取 CSV 文件（或任何以不同分隔特殊字符格式化的文本文件）并将其呈现为`DataFrame`对象。我们将在下一节中看到这个函数的运行，我们将了解 pandas 库中更多功能的工作方式。

## 访问行和列

一旦我们已经有了用`DataFrame`对象表示的数据表，我们可以使用多种选项与该表进行交互和操作。例如，我们可能关心的第一件事是访问某些行和列的数据。幸运的是，pandas 为这项任务提供了直观的 Python 语法。

要访问一组行或列，我们可以利用`loc`方法，该方法接受我们感兴趣的行/列的标签。从语法上讲，这个方法与方括号一起使用（以模拟 Python 中的索引语法）。例如，使用我们上一节中相同的表，我们可以传入一行的名称（例如`0`）：

```py
>>> df.loc[0]
col1    1
col2    3
col3    5
Name: 0, dtype: int64
```

我们可以看到先前返回的对象包含我们想要的信息（第一行和数字 1、3 和 5），但它的格式是陌生的。这是因为它作为`Series`对象返回。`Series`对象是`DataFrame`对象的特例，只包含 1D 数据。我们不需要太关注这种数据结构，因为它的接口与`DataFrame`的接口非常相似。

仍然考虑`loc`方法，我们可以传入一个行标签列表来访问多个行。以下代码返回我们示例表中的两行：

```py
>>> df.loc[[0, 1]]
     col1    col2    col3
0    1       3       5
1    2       4       6
```

假设您想按列访问我们表中的数据。`loc`方法通过我们在 NumPy 数组中熟悉的索引语法（用逗号分隔的行索引和列索引）提供了这个选项。访问第一行和第二列和第三列中的数据：

```py
>>> df.loc[0, ['col2', 'col3']]
col2    3
col3    5
Name: 0, dtype: int64
```

请注意，如果您想要返回`DataFrame`对象中的整列，可以在行索引中使用特殊字符冒号`:`，表示应返回所有行。例如，要访问我们的`DataFrame`对象中的`'col3'`列，我们可以说`df.loc[:, 'col3']`。然而，在访问整列的特殊情况下，还有另一种简单的语法：只使用方括号而不使用`loc`方法，如下所示：

```py
>>> df['col3']
0    5
1    6
Name: col3, dtype: int64
```

早些时候，我们说在访问`DataFrame`中的单个行或列时，将返回`Series`对象。这些对象可以使用，例如，`for`循环进行迭代：

```py
>>> for item in df.loc[:, 'col3']:
...     print(item)
5
6
```

在更改`DataFrame`对象中的值方面，我们可以使用前面的语法为行和列分配新值：

```py
>>> df.loc[0] = [3, 6, 9]  # change first row
>>> df
     col1    col2    col3
0    3       6       9
1    2       4       6
>>> df['col2'] = [0, 0]  # change second column
>>> df
     col1    col2    col3
0    3       0       9
1    2       0       6
```

此外，我们可以使用相同的语法声明新的行和列：

```py
>>> df['col4'] = [10, 10]
>>> df.loc[3] = [1, 2, 3, 4]
>>> df
     col1    col2    col3    col4
0    3       0       9       10
1    2       0       6       10
3    1       2       3       4
```

最后，即使在`loc`方法中通常通过指定它们的实际索引来访问`DataFrame`对象中的行和列，也可以使用布尔值（`True`和`False`）数组来实现相同的效果。

例如，我们可以通过编写以下内容访问我们当前表中的第二行和第二和第四列中的项目：

```py
>>> df.loc[[False, True, False], [False, True, False, True]]
     col2    col4
1    0       10
```

在这里，行的布尔索引列表`[False, True, False]`表示只返回第二个元素（即第二行），而列的布尔索引列表类似地指定要返回第二和第四列。

虽然这种访问`DataFrame`对象中元素的方法可能看起来很奇怪，但它对于过滤和替换任务非常有价值。具体来说，我们可以在`loc`方法中使用条件，而不是传入布尔值列表作为索引。例如，要显示我们当前的表，只显示第一行中值大于`5`的列（应该是第三和第四列），我们可以编写以下内容：

```py
>>> df.loc[:, df.loc[0] > 5]
     col3    col4
0    9       10
1    6       10
3    3       4
```

同样，这种语法在过滤出满足某些条件的`DataFrame`对象中的行或列并可能为它们分配新值方面特别有用。这种功能的一个特殊情况是查找和替换任务（我们将在下一节中介绍）。

## 操作 DataFrame

在本节中，我们将尝试一些用于操作`DataFrame`对象的方法和函数，以便操作这些对象中的数据。当然，还有许多其他可用的方法（可以在官方文档中找到：[`pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html)）。然而，下表中给出的方法是最常用的，可以在帮助我们创建、维护和改变数据表方面提供强大的功能和灵活性：

![图 2.2：用于操作 pandas 数据的方法](img/B15968_02_02.jpg)

图 2.2：用于操作 pandas 数据的方法

下面的练习将演示前面方法的效果，以便更好地理解。

## 练习 2.02：数据表操作

在这个实践练习中，我们将学习前面部分包含的函数和方法。我们的目标是看到这些方法的效果，并执行常见的数据操作技术，比如重命名列、填充缺失值、排序数值，或者将数据表写入文件。

执行以下步骤完成这个练习：

1.  从这个研讨会的 GitHub 存储库中，将`Exercise2.02/dataset.csv`文件复制到`Chapter02`文件夹中的新目录中。文件的内容如下：

```py
id,x,y,z
0,1,1,3
1,1,0,9
2,1,3,
3,2,0,10
4,1,,4
5,2,2,3
```

1.  在新目录中创建一个新的 Jupyter 笔记本。确保这个笔记本和 CSV 文件在同一个位置。

1.  在这个笔记本的第一个单元格中，导入 pandas 和 NumPy，然后使用`pd.read_csv()`函数读取`dataset.csv`文件。指定这个函数的`index_col`参数为`'id'`，这是我们样本数据集中的第一列的名称：

```py
import pandas as pd
import numpy as np
df = pd.read_csv('dataset.csv', index_col='id')
```

1.  当我们打印这个新创建的`DataFrame`对象时，我们可以看到它的值直接对应于我们原始的输入文件：

```py
      x     y      z
id
0    1      1.0    3.0
1    1      0.0    9.0
2    1      3.0    NaN
3    2      0.0    10.0
4    1      NaN    4.0
5    2      2.0    3.0
```

注意这里的`NaN`（**不是一个数字**）值；`NaN`是`DataFrame`对象在初始化时将填充空单元格的默认值。由于我们的原始数据集被设计为包含两个空单元格，这些单元格被适当地填充为`NaN`，正如我们在这里所看到的。

此外，`NaN`值在 Python 中被注册为浮点数，这就是为什么包含它们的两列的数据类型相应地转换为浮点数（值中的小数点表示）。

1.  在下一个单元格中，使用`rename()`方法将当前列重命名为`'col_x'`、`'col_y'`和`'col_z'`。在这里，`columns`参数应该使用 Python 字典指定每个旧列名到它的新名字的映射：

```py
df = df.rename(columns={'x': 'col_x', 'y': 'col_y', \
                        'z': 'col_z'})
```

当运行代码行后，可以观察到`df`打印出的变化：

```py
     col_x     col_y     col_z
id
0    1         1.0       3.0
1    1         0.0       9.0
2    1         3.0       NaN
3    2         0.0       10.0
4    1         NaN       4.0
5    2         2.0       3.0
```

1.  在下一个单元格中，使用`fillna()`函数将`NaN`值替换为零。之后，使用`astype(int)`将表格中的所有数据转换为整数：

```py
df = df.fillna(0)
df = df.astype(int)
```

结果的`DataFrame`对象现在如下所示：

```py
     col_x    col_y    col_z
id
0    1        1        3
1    1        0        9
2    1        3        0
3    2        0        10
4    1        0        4
5    2        2        3
```

1.  在下一个代码单元格中，通过将`[1, 3, 4]`列表传递给`drop`方法，从数据集中删除第二、第四和第五行：

```py
df = df.drop([1, 3, 4], axis=0)
```

注意，`axis=0`参数指定我们传递给方法的标签指定数据集的行，而不是列。类似地，要删除特定列，可以使用列标签的列表，同时指定`axis=1`。

结果表现如下：

```py
     col_x    col_y    col_z
id
0    1        1        3
2    1        3        0
5    2        2        3
```

1.  在下一个单元格中，创建一个全零的 2 x 3 `DataFrame`对象，并使用相应的列标签作为当前`df`变量：

```py
zero_df = pd.DataFrame(np.zeros((2, 3)),                       columns=['col_x', 'col_y', \
                                'col_z'])
```

输出如下：

```py
     col_x    col_y    col_z
0    0.0      0.0      0.0
1    0.0      0.0      0.0
```

1.  在下一个代码单元格中，使用`pd.concat()`函数将两个`DataFrame`对象连接在一起（指定`axis=0`，以便垂直连接两个表，而不是水平连接）：

```py
df = pd.concat([df, zero_df], axis=0)
```

我们当前的`df`变量现在打印出以下内容（注意表格底部新增的两行）：

```py
     col_x    col_y    col_z
0    1.0      1.0      3.0
2    1.0      3.0      0.0
5    2.0      2.0      3.0
0    0.0      0.0      0.0
1    0.0      0.0      0.0
```

1.  在下一个单元格中，按`col_x`列中的数据按升序对我们当前的表进行排序：

```py
df = df.sort_values('col_x', axis=0)
```

结果数据集现在如下所示：

```py
     col_x    col_y    col_z
0    0.0      0.0      0.0
1    0.0      0.0      0.0
0    1.0      1.0      3.0
2    1.0      3.0      0.0
5    2.0      2.0      3.0
```

1.  最后，在另一个代码单元中，将我们的表转换为整数数据类型（与之前的方式相同），并使用`to_csv()`方法将此表写入文件。将`'output.csv'`作为输出文件的名称传递，并指定`index=False`，以便输出中不包括行标签：

```py
df = df.astype(int)
df.to_csv('output.csv', index=False)
```

书面输出应如下所示：

```py
col_x, col_y, col_z
0,0,0
0,0,0
1,1,3
1,3,0
2,2,3
```

这就是本练习的结束。总的来说，这个练习模拟了使用表格数据集的简化工作流程：读取数据，以某种方式操纵数据，最后将数据写入文件。

注意

要访问此特定部分的源代码，请参阅[`packt.live/38ldQ8O`](https://packt.live/38ldQ8O)。

您还可以在[`packt.live/3dTzkL6`](https://packt.live/3dTzkL6)上在线运行此示例。

在下一个也是最后一个关于 pandas 的部分中，我们将考虑库提供的一些更高级的功能。

## 高级 Pandas 功能

访问和更改`DataFrame`对象的行和列中的值是使用 pandas 库处理表格数据的最简单的方法之一。在本节中，我们将介绍另外三种更复杂但也提供了强大选项来操作我们的`DataFrame`对象的选项。第一个是`apply()`方法。

如果您已经熟悉了其他数据结构的这种方法的概念，那么对于为`DataFrame`对象实现的这种方法也是一样的。从一般意义上讲，此方法用于将函数应用于`DataFrame`对象中的所有元素。与我们之前讨论的矢量化概念类似，`apply()`方法之后的结果`DataFrame`对象的元素将是原始数据的每个元素被馈送到指定函数时的结果。

例如，假设我们有以下`DataFrame`对象：

```py
>>> df = pd.DataFrame({'x': [1, 2, -1], 'y': [-3, 6, 5], \
                       'z': [1, 3, 2]})
>>> df
     x     y     z
0    1     -3    1
1    2     6     3
2    -1    5     2
```

现在，假设我们想创建另一列，其条目是`x_squared`列中的条目。然后，我们可以使用`apply()`方法，如下所示：

```py
>>> df['x_squared'] = df['x'].apply(lambda x: x ** 2)
>>> df
     x     y    z    x_squared
0    1     -3   1    1
1    2     6    3    4
2    -1    5    2    1
```

这里的术语`lambda x: x ** 2`只是一种快速声明无名称函数的方法。从打印输出中，我们看到`'x_squared'`列已正确创建。另外，请注意，对于诸如平方函数之类的简单函数，我们实际上可以利用我们已经熟悉的 NumPy 数组的简单语法。例如，以下代码将产生与我们刚才考虑的代码相同的效果：

```py
>>> df['x_squared'] = df['x'] ** 2
```

然而，对于更复杂且不容易矢量化的函数，最好是完全编写它，然后将其传递给`apply()`方法。例如，假设我们想创建一个列，如果同一行中`x`列中的元素是偶数，则每个单元格应包含字符串`'even'`，否则包含字符串`'odd'`。

在这里，我们可以创建一个名为`parity_str()`的单独函数，该函数接受一个数字并返回相应的字符串。然后，可以将此函数与`df['x']`上的`apply()`方法一起使用，如下所示：

```py
>>> def parity_str(x):
...     if x % 2 == 0:
...         return 'even'

...     return 'odd'
>>> df['x_parity'] = df['x'].apply(parity_str)
>>> df
     x     y     z    x_squared    x_parity
0    1     -3    1    1            odd
1    2     6     3    4            even
2    -1    5     2    1            odd
```

Pandas 中另一个常用的略微高级的功能是`pd.get_dummies()`函数。该函数实现了一种称为独热编码的技术，用于数据集中的分类属性（或列）。

我们将在下一章更详细地讨论分类属性的概念，以及其他类型的数据。现在，我们只需要记住，有时统计和机器学习模型无法解释纯分类数据。相反，我们希望有一种方法将数据的分类特征转换为数字形式，同时确保不丢失任何信息。

独热编码就是这样一种方法；它通过为每个唯一值生成一个新的列/属性，并用布尔数据填充新列中的单元格，指示原始分类属性的值。

这种方法通过示例更容易理解，所以让我们考虑前面例子中创建的新的`'x_parity'`列：

```py
>>> df['x_parity']
0     odd
1    even
2     odd
Name: x_parity, dtype: object
```

这一列被认为是一个分类属性，因为它的值属于一组特定的类别（在这种情况下，类别是`odd`和`even`）。现在，通过在该列上调用`pd.get_dummies()`，我们得到以下的`DataFrame`对象：

```py
>>> pd.get_dummies(df['x_parity'])
     even    odd
0    0       1
1    1       0
2    0       1
```

正如我们从打印输出中所观察到的，`DataFrame`对象包括两列，对应于原始分类数据中的唯一值（`'x_parity'`列）。对于每一行，对应于原始数据中的值的列被设置为`1`，而其他列被设置为`0`。例如，第一行原始包含`odd`在`'x_parity'`列中，所以它的新`odd`列被设置为`1`。

我们可以看到，使用独热编码，我们可以将任何分类属性转换为一组新的二进制属性，使数据对于统计和机器学习模型来说是可读的数字。然而，这种方法的一个很大的缺点是维度的增加，因为它创建了与原始分类属性中的唯一值数量相等的新列。因此，如果分类数据包含许多不同的值，这种方法可能会导致我们的表格大大增加。根据您的计算能力和资源，该方法的推荐唯一分类值的数量限制为 50。

`value_counts()`方法是 pandas 中另一个有价值的工具，你应该掌握。这个方法，要调用在`DataFrame`对象的一列上，返回该列中的唯一值及其相应的计数的列表。因此，这个方法只适用于分类或离散数据，其值属于给定的、预先确定的可能值集合。

例如，仍然考虑我们样本数据集的`'x_parity'`属性，我们将检查`value_counts()`方法的效果：

```py
>>> df['x_parity'].value_counts()
odd     2
even    1
Name: x_parity, dtype: int64
```

我们可以看到，在`'x_parity'`列中，我们确实有两个条目（或行）的值为`odd`，一个条目为`even`。总的来说，这种方法在确定值的分布方面非常有用，再次，特别是对于分类和离散数据类型。

我们将讨论的下一个也是最后一个 pandas 的高级功能是`groupby`操作。这个操作允许我们将`DataFrame`对象分成子组，其中组中的行都共享一个分类属性中的值。从这些单独的组中，我们可以计算描述性统计（这是我们将在下一章中深入探讨的概念），以进一步探索我们的数据集。

我们将在下一个练习中看到这一点，我们将探索一个样本学生数据集。

## 练习 2.03：学生数据集

通过考虑一个真实数据集的样本，我们将运用我们对 pandas 最常见函数的知识，包括我们一直在讨论的内容，以及新的`groupby`操作。

执行以下步骤来完成这个练习：

1.  创建一个新的 Jupyter 笔记本，在它的第一个单元格中运行以下代码以生成我们的样本数据集：

```py
import pandas as pd
student_df = pd.DataFrame({'name': ['Alice', 'Bob', 'Carol', \
                                    'Dan', 'Eli', 'Fran'],\
                           'gender': ['female', 'male', \
                                      'female', 'male', \
                                      'male', 'female'],\
                           'class': ['FY', 'SO', 'SR', \
                                     'SO',' JR', 'SR'],\
                           'gpa': [90, 93, 97, 89, 95, 92],\
                           'num_classes': [4, 3, 4, 4, 3, 2]})
student_df
```

这段代码将产生以下输出，以表格形式显示我们的样本数据集：

```py
     name    gender    class    gpa    num_classes
0    Alice   female    FY       90     4
1    Bob     male      SO       93     3
2    Carol   female    SR       97     4
3    Dan     male      SO       89     4
4    Eli     male      JR       95     3
5    Fran    female    SR       92     2
```

我们数据集中的大多数属性都是不言自明的：在每一行（代表一个学生）中，`name`包含学生的姓名，`gender`表示学生是男性还是女性，`class`是一个可以取四个唯一值的分类属性（`FY`代表大一，`SO`代表大二，`JR`代表大三，`SR`代表大四），`gpa`表示学生的累积分数，最后，`num_classes`保存学生目前正在上多少门课的信息。

1.  在一个新的代码单元格中，创建一个名为`'female_flag'`的新属性，其各个单元格应该包含布尔值`True`，如果对应的学生是女性，则为`True`，否则为`False`。

在这里，我们可以看到我们可以利用`apply()`方法，同时传入一个 lambda 对象，如下所示：

```py
student_df['female_flag'] = student_df['gender']\
                            .apply(lambda x: x == 'female')
```

但是，我们也可以简单地使用`student_df['gender'] == 'female'`表达式声明新属性，该表达式按顺序评估条件：

```py
student_df['female_flag'] = student_df['gender'] == 'female'
```

1.  这个新创建的属性包含了旧的`gender`列中包含的所有信息，因此我们将使用`drop()`方法从数据集中删除后者（请注意，我们需要指定`axis=1`参数，因为我们正在删除一列）：

```py
student_df = student_df.drop('gender', axis=1)
```

我们当前的`DataFrame`对象应该如下所示：

```py
     name    class    gpa    num_classes    female_flag
0    Alice   FY       90     4              True
1    Bob     SO       93     3              False
2    Carol   SR       97     4              True
3    Dan     SO       89     4              False
4    Eli     JR       95     3              False
5    Fran    SR       92     2              True
```

1.  在一个新的代码单元格中，编写一个表达式，对分类属性`class`应用独热编码：

```py
pd.get_dummies(student_df['class'])
```

1.  在同一个代码单元格中，将这个表达式包含在`pd.concat()`函数中，将这个新创建的`DataFrame`对象与我们的旧对象连接起来，同时删除`class`列（因为我们现在有了这个属性信息的替代）：

```py
student_df = pd.concat([student_df.drop('class', axis=1), \
             pd.get_dummies(student_df['class'])], axis=1)
```

当前数据集现在应该如下所示：

```py
     name    gpa    num_classes    female_flag    JR    FY    SO    SR
0    Alice   90     4              True           1     0     0     0
1    Bob     93     3              False          0     0     1     0
2    Carol   97     4              True           0     0     0     1
3    Dan     89     4              False          0     0     1     0
4    Eli     95     3              False          0     1     0     0
5    Fran    92     2              True           0     0     0     1
```

1.  在下一个单元格中，对`student_df`调用`groupby()`方法，并使用`female_flag`参数将返回的值赋给一个名为`gender_group`的变量：

```py
gender_group = student_df.groupby('female_flag')
```

正如你可能已经猜到的，这里我们将相同性别的学生分组，因此男性学生将被分在一起，女性学生也将被分在一起，但与第一组分开。

重要的是要注意，当我们尝试打印存储在`gender_group`变量中的这个`GroupBy`对象时，我们只会得到一个通用的基于内存的字符串表示：

```py
<pandas.core.groupby.generic.DataFrameGroupBy object at  0x11d492550>
```

1.  现在，我们想计算前面分组中每个组的平均 GPA。为此，我们可以使用以下简单的语法：

```py
gender_group['gpa'].mean()
```

输出将如下所示：

```py
female_flag
False    92.333333
True     93.000000
Name: gpa, dtype: float64
```

我们对`gender_group`变量的命令非常直观：我们想要计算特定属性的平均值，因此我们使用方括号`['gpa']`访问该属性，然后对其调用`mean()`方法。

1.  类似地，我们可以使用以下代码计算男性学生和女性学生的总课程数：

```py
gender_group['num_classes'].sum()
```

输出如下：

```py
female_flag
False    10
True     10
Name: num_classes, dtype: int64
```

在整个练习中，我们提醒自己一些 pandas 中重要的方法，并通过一个真实数据集的示例看到了`groupby`操作的效果。这个练习也结束了我们关于 pandas 库的讨论，这是 Python 中处理表格数据的首选工具。

注意

要访问此特定部分的源代码，请参考[`packt.live/2NOe5jt`](https://packt.live/2NOe5jt)。

您也可以在[`packt.live/3io2gP2`](https://packt.live/3io2gP2)上在线运行此示例。

在本章的最后一节中，我们将讨论典型数据科学/科学计算流水线的最后一部分：数据可视化。

# 使用 Matplotlib 和 Seaborn 进行数据可视化

数据可视化无疑是任何数据流水线的重要组成部分。良好的可视化不仅可以帮助科学家和研究人员发现有关其数据的独特见解，还可以以直观、易于理解的方式传达复杂、高级的想法。在 Python 中，大多数数据可视化工具的后端都连接到 Matplotlib 库，该库提供了非常广泛的选项和功能，我们将在接下来的讨论中看到。

首先，要安装 Matplotlib，只需运行以下命令之一，取决于您的 Python 包管理器是哪一个：

```py
$ pip install matplotlib
$ conda install matplotlib
```

Python 中的惯例是从 Matplotlib 库中导入`pyplot`包，如下所示：

```py
>>> import matplotlib.pyplot as plt
```

这个`pyplot`包，现在的别名是`plt`，是 Python 中任何可视化功能的主要工具，因此将被广泛使用。

总的来说，与其学习库的理论背景，本节我们将采取更加实践的方法，并介绍 Matplotlib 提供的许多不同的可视化选项。最终，我们将获得实用的经验，这将有益于您将来的项目。 

## 散点图

散点图是最基本的可视化方法之一-在平面（或其他高维空间）上绘制一系列点的列表。这只需通过`plt.scatter()`函数完成。例如，假设我们有一个包含五个点的列表，其 x 和 y 坐标分别存储在以下两个列表中：

```py
>>> x = [1, 2, 3, 1.5, 2]
>>> y = [-1, 5, 2, 3, 0]
```

现在，我们可以使用`plt.scatter()`函数创建散点图：

```py
>>> import matplotlib.pyplot as plt
>>> plt.scatter(x, y)
>>> plt.show()
```

上述代码将生成以下图表，该图表与我们输入`plt.scatter()`函数的两个列表中的数据完全对应：

![图 2.3：使用 Matplotlib 的散点图](img/B15968_02_03.jpg)

图 2.3：使用 Matplotlib 的散点图

请注意代码片段末尾的`plt.show()`命令。该函数负责显示由上述代码定制的图表，并且应放置在与可视化相关的代码块的末尾。

至于`plt.scatter()`函数，我们可以指定参数进一步定制我们的图表。例如，我们可以定制各个点的大小，以及它们各自的颜色：

```py
>>> sizes = [10, 40, 60, 80, 100]
>>> colors = ['r', 'b', 'y', 'g', 'k']
>>> plt.scatter(x, y, s=sizes, c=colors)
>>> plt.show()
```

上述代码产生以下输出：

![图 2.4：带有大小和颜色自定义的散点图](img/B15968_02_04.jpg)

图 2.4：带有大小和颜色自定义的散点图

当您希望在散点图中可视化的点属于不同的数据组时，此功能非常有用，这种情况下，您可以为每个组分配一个颜色。在许多情况下，使用此方法发现了不同数据组形成的聚类。

注意

要查看 Matplotlib 颜色及其用法的完整文档，请参阅以下网页：[`matplotlib.org/2.0.2/api/colors_api.html.`](https://matplotlib.org/2.0.2/api/colors_api.html )

总的来说，散点图用于可视化我们感兴趣的数据的空间分布。使用散点图的一个潜在目标是揭示数据中存在的任何聚类，这可以为我们提供关于数据集属性之间关系的进一步见解。

接下来，让我们考虑折线图。

## 折线图

折线图是另一种最基本的可视化方法，其中点沿着曲线绘制，而不是分散绘制。这是通过简单的`plt.plot()`函数完成的。例如，我们在以下代码中绘制正弦波（从 0 到 10）：

```py
>>> import numpy as np
>>> x = np.linspace(0, 10, 1000)
>>> y = np.sin(x)
>>> plt.plot(x, y)
>>> plt.show()
```

请注意，这里的`np.linspace()`函数返回两个端点之间均匀间隔的数字数组。在我们的例子中，我们获得了 0 到 10 之间的 1,000 个均匀间隔的数字。这里的目标是对这些数字进行正弦函数并将其绘制出来。由于点非常接近彼此，它将产生真正平滑函数被绘制的效果。

这将导致以下图表：

![图 2.5：使用 Matplotlib 的折线图](img/B15968_02_05.jpg)

图 2.5：使用 Matplotlib 的折线图

与散点图的选项类似，这里我们可以定制线图的各种元素，特别是线条的颜色和样式。以下代码绘制了三条单独的曲线（*y = x*图，自然对数函数和正弦波），提供了一个示例：

```py
x = np.linspace(1, 10, 1000)
linear_line = x
log_curve = np.log(x)
sin_wave = np.sin(x)
curves = [linear_line, log_curve, sin_wave]
colors = ['k', 'r', 'b']
styles = ['-', '--', ':']
for curve, color, style in zip(curves, colors, styles):
    plt.plot(x, curve, c=color, linestyle=style)
plt.show()
```

上述代码产生以下输出：

![图 2.6：带有样式自定义的折线图](img/B15968_02_06.jpg)

图 2.6：带有样式自定义的折线图

注意

可以在 Matplotlib 的官方文档中找到完整的线型列表，具体在以下页面：[`matplotlib.org/3.1.0/gallery/lines_bars_and_markers/linestyles.html.`](https://matplotlib.org/3.1.0/gallery/lines_bars_and_markers/linestyles.html )

通常，线图用于可视化特定函数的趋势，该函数由按顺序排列的点列表表示。因此，这种方法非常适用于具有一些顺序元素的数据，例如时间序列数据集。

接下来，我们将考虑 Matplotlib 中条形图的可用选项。

## 条形图

条形图通常用于通过各个条的高度表示数据集中唯一值的计数。在 Matplotlib 中，这是使用`plt.bar()`函数来实现的，如下所示：

```py
labels = ['Type 1', 'Type 2', 'Type 3']
counts = [2, 3, 5]
plt.bar(labels, counts)
plt.show()
```

`plt.bar()`函数接受的第一个参数（在本例中为`labels`变量）指定了各个条的标签，而第二个参数（在本例中为`counts`）指定了条的高度。使用这段代码，将生成以下图形：

图 2.7：使用 Matplotlib 的条形图

](image/B15968_02_07.jpg)

图 2.7：使用 Matplotlib 的条形图

与往常一样，您可以使用`c`参数指定各个条的颜色。对我们来说更有趣的是能够使用堆叠或分组条来创建更复杂的条形图。与其简单地比较不同数据的计数，堆叠或分组条用于可视化每个条在较小子组中的组成。

例如，假设在`Type 1`、`Type 2`和`Type 3`的每个组中，如前面的例子中，我们有两个子组，`Type A`和`Type B`，如下所示：

```py
type_1 = [1, 1]  # 1 of type A and 1 of type B
type_2 = [1, 2]  # 1 of type A and 2 of type B
type_3 = [2, 3]  # 2 of type A and 3 of type B
counts = [type_1, type_2, type_3]
```

实质上，`Type 1`、`Type 2`和`Type 3`的总计仍然相同，但现在每个都可以进一步分为两个子组，由 2D 列表`counts`表示。一般来说，这里的类型可以是任何东西；我们的目标只是简单地使用堆叠或分组条形图来可视化每个大类型中子组的组成。

首先，我们的目标是创建分组条形图；我们的目标是以下可视化效果：

图 2.8：分组条形图

](image/B15968_02_08.jpg)

图 2.8：分组条形图

这是一种更高级的可视化，因此创建图形的过程更加复杂。首先，我们需要指定分组条的各个位置及其宽度：

```py
locations = np.array([0, 1, 2])
width = 0.3
```

然后，我们在适当的数据上调用`plt.bar()`函数：一次在`Type A`数字上（`[my_type[0] for my_type in counts]`，使用列表推导），一次在`Type B`数字上（`[my_type[1] for my_type in counts]`）：

```py
bars_a = plt.bar(locations - width / 2,   [my_type[0] for my_type in counts], width=width)
bars_b = plt.bar(locations + width / 2,   [my_type[1] for my_type in counts], width=width)
```

术语`locations - width / 2`和`locations + width / 2`指定了`Type A`条和`Type B`条的确切位置。重要的是，我们在`plt.bar()`函数的`width`参数中重用这个`width`变量，以便每组的两个条紧挨在一起。

接下来，我们想要自定义每组条的标签。另外，请注意，我们还将`plt.bar()`的返回值分配给两个变量`bars_a`和`bars_b`，然后将用于生成图例：

```py
plt.xticks(locations, ['Type 1', 'Type 2', 'Type 3'])
plt.legend([bars_a, bars_b], ['Type A', 'Type B'])
```

最后，当我们调用`plt.show()`时，所需的图形将被显示。

因此，这是创建分组条形图的过程，其中属于一组的单个条放在一起。另一方面，堆叠条形图将条形放在彼此之上。这两种类型的图表大多用于传达相同的信息，但使用堆叠条形图，每个组的总计更容易进行视觉检查和比较。

要创建堆叠条形图，我们利用`plt.bar()`函数在声明非第一组时使用`bottom`参数。具体来说，我们这样做：

```py
bars_a = plt.bar(locations, [my_type[0] for my_type in counts])
bars_b = plt.bar(locations, [my_type[1] for my_type in counts], \
                 bottom=[my_type[0] for my_type in counts])
plt.xticks(locations, ['Type 1', 'Type 2', 'Type 3'])
plt.legend([bars_a, bars_b], ['Type A', 'Type B'])
plt.show()
```

上述代码将创建以下可视化效果：

图 2.9：堆叠条形图

](image/B15968_02_09.jpg)

图 2.9：堆叠条形图

这就结束了我们在 Matplotlib 中对条形图的介绍。通常，这些类型的图表用于可视化分类属性中不同值组的计数或百分比。正如我们所观察到的，Matplotlib 提供了可扩展的 API，可以以灵活的方式生成这些图表。

现在，让我们继续我们下一个可视化技术：直方图。

## 直方图

直方图是一种将多个条放在一起的可视化，但它与条形图的联系就到此为止了。直方图通常用于表示属性内的值的分布（更准确地说是数值属性）。接受一个数字数组，直方图应包含多个条，每个条跨越特定范围，表示属于该范围的数字的数量。

假设我们的数据集中有一个包含存储在`x`中的样本数据的属性。我们可以在`x`上调用`plt.hist()`来绘制属性值的分布，如下所示：

```py
x = np.random.randn(100)
plt.hist(x)
plt.show()
```

上述代码产生了类似以下的可视化：

![图 2.10：使用 Matplotlib 的直方图](img/B15968_02_10.jpg)

图 2.10：使用 Matplotlib 的直方图

注意

你的输出可能与我们这里有些不同，但直方图的一般形状应该是一样的——钟形曲线。

可以在`plt.hist()`函数中指定`bins`参数（默认值为 10）来自定义应生成的条形的数量。粗略地说，增加箱子的数量会减少每个箱子跨越的范围的宽度，从而提高直方图的粒度。

然而，直方图中也可能使用太多的箱子而导致糟糕的可视化效果。例如，使用相同的变量`x`，我们可以这样做：

```py
plt.hist(x, bins=100)
plt.show()
```

上述代码将产生以下图表：

![图 2.11：直方图中使用太多的箱子](img/B15968_02_11.jpg)

图 2.11：直方图中使用太多的箱子

这种可视化可能比前面的例子更糟糕，因为它导致我们的直方图变得分散和不连续。解决这个问题的最简单方法是增加输入数据和箱子数量之间的比率，要么增加输入数据，要么使用更少的箱子。

直方图在帮助我们比较多个属性的分布方面也非常有用。例如，通过调整`alpha`参数（指定直方图的不透明度），我们可以在一个图表中叠加多个直方图，以突出它们的差异。以下代码和可视化演示了这一点：

```py
y = np.random.randn(100) * 4 + 5
plt.hist(x, color='b', bins=20, alpha=0.2)
plt.hist(y, color='r', bins=20, alpha=0.2)
plt.show()
```

输出将如下所示：

![图 2.12：叠加直方图](img/B15968_02_12.jpg)

图 2.12：叠加直方图

在这里，我们可以看到，虽然两个分布的形状大致相似，但一个在另一个的右侧，表明它的值通常大于左侧属性的值。

我们需要注意的一个有用的事实是，当我们简单地调用`plt.hist()`函数时，会返回一个包含两个数字数组的元组，表示相应直方图中各个条的位置和高度，如下所示：

```py
>>> plt.hist(x)
(array([ 9.,  7., 19., 18., 23., 12.,  6.,  4.,  1.,  1.]),
    array([-1.86590701, -1.34312205, -0.82033708, -0.29755212,
            0.22523285, 0.74801781,  1.27080278,  1.79358774,
            2.31637271,  2.83915767, 3.36194264]),
  <a list of 10 Patch objects>)
```

两个数组包括了由 Matplotlib 处理的输入数据的所有直方图相关信息。然后可以使用这些数据来绘制直方图，但在某些情况下，甚至可以将数组存储在新变量中，并使用这些统计数据对数据进行进一步分析。

在下一节中，我们将继续讨论本章中将要讨论的最后一种可视化类型：热力图。

## 热力图

热力图是使用二维数组生成的，其中具有高值的数字对应于热色，低值的数字对应于冷色。使用 Matplotlib，可以使用`plt.imshow()`函数创建热力图。假设我们有以下代码：

```py
my_map = np.random.randn(10, 10)
plt.imshow(my_map)
plt.colorbar()
plt.show()
```

上述代码将产生以下可视化：

![图 2.13：使用 Matplotlib 的热图](img/B15968_02_13.jpg)

图 2.13：使用 Matplotlib 的热图

请注意，通过这种表示，输入的 2D 数组中的任何分组结构（例如，如果有一组单元格的值明显大于其余部分）将被有效地可视化。

热图的一个重要用途是当我们考虑数据集的相关矩阵时（这是一个包含数据集内任意属性对之间相关性的 2D 数组）。热图将能够帮助我们找出任何高度相关的属性。

这结束了我们在本节中关于可视化库 Matplotlib 的最后一个讨论主题。下一个练习将通过一个实际示例帮助我们巩固所学到的知识。

## 练习 2.04：概率分布的可视化

当我们讨论抽样时，我们简要提到概率分布是统计学和机器学习中广泛使用的数学对象，用于对现实生活数据进行建模。虽然许多概率分布可能抽象且复杂，但能够有效地可视化它们的特征是理解它们的用途的第一步。

在这个练习中，我们将应用一些可视化技术（直方图和折线图）来比较 NumPy 中的抽样函数与它们真实的概率分布。对于给定的概率分布，**概率密度函数**（也称为**PDF**）定义了根据该分布的任何实数的概率。这里的目标是验证，通过足够大的样本量，NumPy 的抽样函数是否给出了给定概率分布的真实 PDF 的真实形状。

执行以下步骤完成此练习：

1.  从您的终端，也就是您的 Python 环境中（如果您正在使用），安装 SciPy 包。您可以像往常一样使用 pip 进行安装：

```py
$ pip install scipy
```

使用 Anaconda 安装 SciPy，请使用以下命令：

```py
$ conda install scipy
```

SciPy 是 Python 中另一个流行的统计计算工具。它包含了各种概率分布的简单 API，我们将在这里使用。我们将在下一章中重新讨论这个库。

1.  在 Jupyter 笔记本的第一个代码单元中，导入 NumPy、SciPy 的`stats`包和 Matplotlib，如下所示：

```py
import numpy as np
import scipy.stats as stats
import matplotlib.pyplot as plt
```

1.  在下一个单元格中，使用 NumPy 从均值为`0`，标准差为`1`的正态分布中抽取 1,000 个样本：

```py
samples = np.random.normal(0, 1, size=1000)
```

1.  接下来，我们将在我们绘制的样本的最小值和最大值之间创建一个`np.linspace`数组，并最终在数组中的数字上调用真实的 PDF。我们这样做是为了在下一步中将这些点绘制在图表中：

```py
x = np.linspace(samples.min(), samples.max(), 1000)
y = stats.norm.pdf(x)
```

1.  为绘制的样本创建一个直方图，并为通过 PDF 获得的点创建一个折线图。在`plt.hist()`函数中，指定`density=True`参数，以便将条的高度归一化为概率值（0 到 1 之间的数字），`alpha=0.2`参数使直方图颜色较浅，`bins=20`参数使直方图的粒度更大：

```py
plt.hist(samples, alpha=0.2, bins=20, density=True)
plt.plot(x, y)
plt.show()
```

上述代码将创建（大致）以下可视化：

![图 2.14：正态分布的直方图与 PDF](img/B15968_02_14.jpg)

图 2.14：正态分布的直方图与 PDF

我们可以看到，我们绘制的样本的直方图与正态分布的真实 PDF 非常匹配。这证明了 NumPy 的抽样函数和 SciPy 的 PDF 函数之间的一致性。

注意

要获得更平滑的直方图，可以尝试增加直方图中的条数。

1.  接下来，我们将为参数为(2, 5)的 Beta 分布创建相同的可视化。目前，我们不需要太多了解概率分布本身；同样，在这里，我们只想测试一下 NumPy 的抽样函数和 SciPy 的相应概率密度函数。

在下一个代码单元格中，按照之前的步骤进行操作：

```py
samples = np.random.beta(2, 5, size=1000)
x = np.linspace(samples.min(), samples.max(), 1000)
y = stats.beta.pdf(x, 2, 5)
plt.hist(samples, alpha=0.2, bins=20, density=True)
plt.plot(x, y)
plt.show()
```

这将生成以下图表：

![图 2.15：Beta 分布的直方图与概率密度函数](img/B15968_02_15.jpg)

图 2.15：Beta 分布的直方图与概率密度函数

1.  使用参数α = 1 为 Gamma 分布创建相同的可视化：

```py
samples = np.random.gamma(1, size=1000)
x = np.linspace(samples.min(), samples.max(), 1000)
y = stats.gamma.pdf(x, 1)
plt.hist(samples, alpha=0.2, bins=20, density=True)
plt.plot(x, y)
plt.show()
```

然后绘制以下可视化：

![图 2.16：Gamma 分布的直方图与概率密度函数](img/B15968_02_16.jpg)

图 2.16：Gamma 分布的直方图与概率密度函数

在本练习中，我们学习了如何结合直方图和折线图来验证 NumPy 和 SciPy 实现的多个概率分布。我们还简要介绍了概率分布及其概率密度函数的概念。

注

要访问本特定部分的源代码，请参阅[`packt.live/3eZrEbW`](https://packt.live/3eZrEbW)。

您还可以在[`packt.live/3gmjLx8`](https://packt.live/3gmjLx8)上在线运行此示例。

这个练习作为 Matplotlib 主题的结论。在下一节中，我们将通过 Seaborn 和 pandas 提供的一些简写 API 来快速创建复杂的可视化，结束本章的讨论。

## Seaborn 和 Pandas 的可视化简写

首先，让我们讨论 Seaborn 库，它是继 Matplotlib 之后 Python 中第二受欢迎的可视化库。尽管仍由 Matplotlib 支持，Seaborn 提供了简单、表达力强的函数，可以促进复杂的可视化方法。

成功通过 pip 或 Anaconda 安装 Seaborn 后，程序员通常使用`sns`别名导入库的约定。现在，假设我们有一个具有两个数值属性的表格数据集，并且我们想要可视化它们各自的分布：

```py
x = np.random.normal(0, 1, 1000)
y = np.random.normal(5, 2, 1000)
df = pd.DataFrame({'Column 1': x, 'Column 2': y})
df.head()
```

通常，我们可以创建两个直方图，一个用于每个属性。然而，我们也想检查两个属性之间的关系，在这种情况下，我们可以利用 Seaborn 中的`jointplot()`函数。让我们看看它的作用：

```py
import seaborn as sns
sns.jointplot(x='Column 1', y='Column 2', data=df)
plt.show()
```

如您所见，我们可以将整个`DataFrame`对象传递给 Seaborn 函数，并在函数参数中指定要绘制的元素。这个过程可能比使用 Matplotlib 传递实际属性更简单。

上述代码将生成以下可视化：

![图 2.17：使用 Seaborn 的联合图](img/B15968_02_17.jpg)

图 2.17：使用 Seaborn 的联合图

这个可视化包括两个属性的散点图和它们各自的直方图附加到适当的坐标轴上。从这里，我们可以观察到我们放入两个直方图的各个属性的分布，以及从散点图中观察它们的*联合*分布。

再次，因为这是一个相当复杂的可视化，可以为输入数据提供重要见解，手动在 Matplotlib 中创建可能会相当困难。Seaborn 成功的地方在于为这些复杂但有价值的可视化技术构建了一个流水线，并创建了简单的 API 来生成它们。

让我们考虑另一个例子。假设我们有一个与*练习 2.03*中考虑的相同学生数据集的较大版本，*学生数据集*，其外观如下：

```py
student_df = pd.DataFrame({
    'name': ['Alice', 'Bob', 'Carol', 'Dan', 'Eli', 'Fran', \
             'George', 'Howl', 'Ivan', 'Jack', 'Kate'],\
    'gender': ['female', 'male', 'female', 'male', \
               'male', 'female', 'male', 'male', \
               'male', 'male', 'female'],\
    'class': ['JR', 'SO', 'SO', 'SO', 'JR', 'SR', \
              'FY', 'SO', 'SR', 'JR', 'FY'],\
    'gpa': [90, 93, 97, 89, 95, 92, 90, 87, 95, 100, 95],\
    'num_classes': [4, 3, 4, 4, 3, 2, 2, 3, 3, 4, 2]})
```

现在，我们想考虑数据集中学生的平均 GPA，按班级分组。此外，在每个班级内，我们还对女生和男生之间的差异感兴趣。这需要一个分组/堆叠条形图，其中每个组对应一个班级，并分为女生和男生的平均值。

使用 Seaborn，这可以通过一行代码完成：

```py
sns.catplot(x='class', y='gpa', hue='gender', kind='bar', \
            data=student_df)
plt.show()
```

这将生成以下图表（注意图例如何自动包含在图表中）：

![图 2.18：使用 Seaborn 的分组条形图](img/B15968_02_18.jpg)

图 2.18：使用 Seaborn 的分组条形图

除了 Seaborn，pandas 库本身也提供了直接与 Matplotlib 交互的独特 API。这通常是通过`DataFrame.plot`API 完成的。例如，仍然使用我们之前使用的`student_df`变量，我们可以快速生成`gpa`属性数据的直方图，如下所示：

```py
student_df['gpa'].plot.hist()
plt.show()
```

然后创建以下图表：

![图 2.19：使用 pandas 的直方图](img/B15968_02_19.jpg)

图 2.19：使用 pandas 的直方图

假设我们对班级的百分比分布感兴趣（即，每个班级在所有学生中所占的比例）。我们可以从班级计数（通过`value_counts()`方法获得）生成一个饼图：

```py
student_df['class'].value_counts().plot.pie()
plt.show()
```

这将产生以下输出：

![图 2.20：来自 pandas 的饼图](img/B15968_02_20.jpg)

图 2.20：来自 pandas 的饼图

通过这些示例，我们可以了解到 Seaborn 和 Matplotlib 如何简化创建复杂可视化的过程，特别是对于`DataFrame`对象，只需使用简单的函数调用。这清楚地展示了 Python 中各种统计和科学工具之间的功能集成，使其成为最受欢迎的现代科学计算语言之一，如果不是最受欢迎的话。

这结束了本书第二章要涵盖的内容。现在，让我们通过一个真实数据集进行实际操作。

## 活动 2.01：分析 Communities and Crime 数据集

在这个活动中，我们将练习一些基本的数据处理和分析技术，使用一个名为*Communities and Crime*的在线数据集，希望巩固我们的知识和技术。具体来说，我们将处理数据集中的缺失值，遍历属性，并可视化它们的值的分布。

首先，我们需要将这个数据集下载到我们的本地环境中，可以在此页面上访问：[`packt.live/31C5yrZ`](https://packt.live/31C5yrZ)

数据集的名称应该是`CommViolPredUnnormalizedData.txt`。从与此数据集文本文件相同的目录中，创建一个新的 Jupyter 笔记本。现在，执行以下步骤：

1.  首先，导入我们将使用的库：pandas、NumPy 和 Matplotlib。

1.  使用 pandas 从文本文件中读取数据集，并通过在`DataFrame`对象上调用`head()`方法打印出前五行。

1.  循环遍历数据集中的所有列，并逐行打印它们。在循环结束时，还要打印出总列数。

1.  注意，数据集的不完整值在不同单元格中表示为`'?'`。在`DataFrame`对象上调用`replace()`方法，将该字符替换为`np.nan`，以忠实地表示 Python 中的缺失值。

1.  使用`df.isnull().sum()`打印出数据集中列的列表及其各自的缺失值数量，其中`df`是`DataFrame`对象的变量名。

1.  使用`df.isnull().sum()[column_name]`语法（其中`column_name`是我们感兴趣的列的名称），打印出`NumStreet`和`PolicPerPop`列中缺失值的数量。

1.  计算一个包含`state`属性值列表及其各自计数的`DataFrame`对象。然后，使用`DataFrame.plot.bar()`方法将该信息可视化为条形图。

1.  请注意，默认情况下，图表的比例尺上的标签重叠。通过使用`f, ax = plt.subplots(figsize=(15, 10))`命令使图表变大来解决这个问题。这应该放在任何绘图命令的开头。

1.  使用与之前使用的相同值计数`DataFrame`对象，调用`DataFrame.plot.pie()`方法来创建相应的饼图。调整图形大小以确保图表的标签正确显示。

1.  创建一个直方图，代表数据集中地区人口规模的分布（包含在`population`属性中）。调整图形大小以确保图表的标签正确显示。![图 2.21：人口分布的直方图](img/B15968_02_21.jpg)

图 2.21：人口分布的直方图

1.  创建一个等效的直方图来可视化数据集中家庭规模的分布（包含在`householdsize`属性中）。![图 2.22：家庭规模分布的直方图](img/B15968_02_22.jpg)

图 2.22：家庭规模分布的直方图

注意

此活动的解决方案可在第 653 页找到。

# 摘要

本章介绍了 Python 中用于数据科学和统计计算的核心工具，即 NumPy 用于线性代数和计算，pandas 用于表格数据处理，Matplotlib 和 Seaborn 用于可视化。这些工具将在本书的后续章节中广泛使用，并且它们将在您未来的项目中证明有用。在下一章中，我们将深入了解本书中将要使用的一些统计概念的具体内容，并学习如何在 Python 中实现它们。

XBC94

ABB35
