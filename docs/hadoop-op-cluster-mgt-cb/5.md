# 五、增强 Hadoop 集群

在本章中，我们将介绍：

*   配置服务级别身份验证
*   使用 ACL 配置作业授权
*   使用 Kerberos 保护 Hadoop 集群
*   配置 Web 用户界面身份验证
*   从 NameNode 故障中恢复
*   配置 NameNode 高可用性
*   配置 HDFS 联合

# 简介

Hadoop 集群的安全性对其可用性至关重要。 加强 Hadoop 集群包括配置对资源(如作业、队列和各种管理服务)的访问控制。 我们将引入 NameNode**High Availability**(**HA**)来解决单节点故障问题。 最后，我们将介绍 Hadoop 联合，它联合多台机器来扩展集群的容量。

# 配置服务级别身份验证

**服务级身份验证**(**SLA**)的目的是确保 Hadoop 用户拥有访问某些服务的适当权限。 此配置的一个用例是控制可以使用集群的允许用户列表。 这是通过 Hadoop 中的**访问控制列表**(**ACL**)强制执行的。 在本食谱中，我们将列出配置 SLA 的步骤。

## 做好准备

在开始之前，我们假设我们的 Hadoop 集群已经正确配置，并且所有守护进程都在运行，没有任何问题。

使用以下命令从管理员机器登录到主节点：

```sh
ssh hduser@master

```

## 怎么做……

使用以下步骤配置 Hadoop SLA：

1.  Enable SLA by opening the `$HADOOP_HOME/conf/core-site.xml` file and add or change the `hadoop.property.authorization` value to be `true`, as shown in the following snippet:

    ```sh
    <property>
      <name>hadoop.property.authorization</name>
      <value>true</name>
    </property>
    ```

    ### 备注

    默认情况下，Hadoop 集群的 SLA 处于禁用状态。

2.  Allow only specific users to submit jobs to the Hadoop cluster by adding or changing the following property in the `$HADOOP_HOME/conf/hadoop-policy.xml` file:

    ```sh
    <property>
      <name>security.job.submission.protocol.acl</name>
      <value>hduser hadoop</name>
    </property>
    ```

    ### 备注

    此配置仅允许用户`hduser`和组`hadoop`向 Hadoop 集群提交作业。

3.  Allow only specific users and groups to talk to HDFS by opening the `$HADOOP_HOME/conf/hadoop-policy.xml` file and add the following property:

    ```sh
    <property>
      <name>security.client.protocol.acl</name>
      <value>hduser,hdadmin hadoop</name>
    </property>
    ```

    ### 备注

    此配置仅允许用户`hduser`和`hdadmin`以及组`hadoop`访问 HDFS

4.  Allow only specific DataNodes to communicate with the NameNode by changing the `security.datanode.protocol.acl` property in the `$HADOOP_HOME/conf/hadoop-policy.xml` file similar to the following code:

    ```sh
    <property>
      <name>security.datanode.protocol.acl</name>
      <value>datanode</name>
    </property>
    ```

    ### 备注

    此配置仅允许作为属于组`datanode`的用户运行的 DataNode 实例与集群中的 NameNode 通信。

5.  Force the NameNode to reload the ACL configurations with the following command:

    ```sh
    hadoop dfsadmin -refreshServiceAcl

    ```

    ### 备注

    此命令将强制从`policy`文件重新加载与 HDFS 相关的 ACL。

6.  使用以下命令强制 JobTracker 重新加载服务 ACL 配置：

    ```sh
    hadoop mradmin -refreshServiceAcl

    ```

## 它是如何工作的.

属性(如`security.namenode.protocol.acl`)的值是逗号分隔的用户列表和组的逗号分隔列表。 用户列表和组列表由空格分隔。 例如，值的通用格式应类似于以下内容：

```sh
<value>user1,user2,user3 group1,group2</value>

```

## 还有更多...

除了我们在本食谱中提到的三个属性外，Hadoop 中还提供了许多其他 ACL 属性。 下表显示了这些属性的含义：

<colgroup><col style="text-align: left"> <col style="text-align: left"></colgroup> 
| 

性质 / 财产 / 所有权

 | 

服务描述

 |
| --- | --- |
| `security.client.protocol.acl` | 客户端对 HDFS 的访问 |
| `security.client.datanode.protocol.acl` | 用于数据块恢复的客户端到数据节点 |
| `security.inter.datanode.protocol.acl` | 数据节点到数据节点更新时间戳 |
| `security.inter.tracker.protocol.acl` | TaskTracker 到 JobTracker |
| `security.job.submission.protocol.acl` | 用于作业提交、查询等的 JobTracker 客户端 |
| `security.task.umbilical.protocol.acl` | 有关映射和减少任务的信息，请联系 TaskTracker |
| `security.refresh.policy.protocol.acl` | Dfsadmin 和 mradmin 刷新 ACL 策略 |

这些属性的默认值是`*`，这意味着所有实体都可以访问该服务，换句话说，SLA 被禁用。

## 另请参阅

*   [第 5 章](5.html "Chapter 5. Hardening a Hadoop Cluster")，*加强 Hadoop 集群*中的*使用 ACL*配方配置作业授权
*   [http：//hadoop.apache.org/docs/r1.1.2/service_level_auth.html#Enable+Service+Level+Authorization](http://hadoop.apache.org/docs/r1.1.2/service_level_auth.html#Enable+Service+Level+Authorization)

# 使用 ACL 配置作业授权

Hadoop 提供两个级别的**作业授权**：作业级别和队列级别。 启用作业授权后，JobTracker 将对向集群提交作业的用户进行身份验证。 用户对作业和队列的操作也将由 JobTracker 进行身份验证。 在本食谱中，我们将展示使用 ACL 配置作业授权的步骤。

## 做好准备

我们假设我们的 Hadoop 集群已经正确配置，没有任何问题。

使用以下命令从管理员计算机登录到主节点：

```sh
ssh hduser@master

```

## 怎么做……

使用以下步骤配置具有 ACL 的作业授权：

1.  Enable job ACL authorization by adding the following property to the `$HADOOP_HOME/conf/mapred-site.xml` file:

    ```sh
    <property>
      <name>mapred.acls.enabled</name>
      <value>true</name>
    </property>
    ```

    ### 备注

    此属性将启用队列 ACL 和作业 ACL。

2.  Configure job authorization to only allow specific users and groups to submit jobs by adding the following property to the `$HADOOP_HOME/conf/mapred-queue-acls.xml` file:

    ```sh
    <property>
      <name>mapred.queue.hdqueue.acl-submit-job</name>
      <value>hduser hadoop</name>
    </property>
    ```

    ### 备注

    此配置将仅允许用户`hduser`和组`hadoop`向队列`hdqueue`提交作业。

3.  Configure job authorization to allow specific users and groups to manage jobs in a named queue by adding the following property to the `$HADOOP_HOME/conf/mapred-queue-acls.xml` file:

    ```sh
    <property>
      <name>mapred.queue.hdqueue.acl-administer-job</name>
      <value>hduser hadoop</name>
    </property>
    ```

    ### 备注

    此配置将仅允许用户`hduser`和组`hadoop`管理队列`hdqueue`的作业。

4.  Check the status of queue ACLs with the following command:

    ```sh
    hadoop queue -showacls

    ```

    输出将类似于以下内容：

    ```sh
    Queue acls for user :  hduser
    Queue  Operations
    =====================
    default  submit-job,administer-jobs
    hdqueue  submit-job,administer-jobs

    ```

5.  Configure job authorization to allow only specific users and groups to view the status of a job by adding the following property to the `$HADOOP_HOME/conf/mapred-queue-acls.xml` file:

    ```sh
    <property>
      <name>mapreduce.job.acl-view-job</name>
      <value>hduser hadoop</name>
    </property>
    ```

    ### 提示

    与队列级别 ACL 不同，作业级别 ACL 为所有提交的作业指定访问控制，而不考虑作业已提交到的队列。

6.  通过将以下属性添加到`$HADOOP_HOME/conf/mapred-queue-acls.xml`文件，将作业授权配置为仅允许特定用户和组修改作业：

    ```sh
    <property>
      <name>mapreduce.job.acl-modify-job</name>
      <value>hduser hadoop</name>
    </property>
    ```

7.  使用以下命令强制 NameNode 和 JobTracker 重新加载 ACL 配置：

    ```sh
    hadoop dfsadmin -refreshServiceAcl
    hadoop mradmin -refreshServiceAcl

    ```

## 它是如何工作的.

与前面配方中的 SLA 属性类似，`mapred.queue.hdqueue.acl-submit-job`等属性的值是一个逗号分隔的用户列表和一个逗号分隔的组列表。 用户列表和组列表由空格分隔。 例如，值的通用格式应类似于以下内容：

```sh
<value>user1,user2,user3 group1,group2</value>
```

### 提示

作业所有者、超级用户和向其提交作业的集群管理员将始终有权查看和修改作业。

作业视图 ACL 控制作业状态信息的访问，包括计数器、诊断信息、日志、作业配置等。

作业修改 ACL 可以与队列级 ACL 重叠。 发生这种情况时，如果用户已列在这两个 ACL 中的任何一个中，则将授予该用户的操作。

## 另请参阅

*   [第 5 章](5.html "Chapter 5. Hardening a Hadoop Cluster")，*加强 Hadoop 集群*中的*配置服务级别身份验证*配方
*   [http：//hadoop.apache.org/docs/r1.1.2/mapred_tutorial.html#Job+Authorization](http://hadoop.apache.org/docs/r1.1.2/mapred_tutorial.html#Job+Authorization)
*   [http：//hadoop.apache.org/docs/r1.1.2/cluster_setup.html](http://hadoop.apache.org/docs/r1.1.2/cluster_setup.html)

# 使用 Kerberos 保护 Hadoop 集群

最新的 Hadoop 版本通过将**Kerberos**集成到 Hadoop 中添加了安全功能。 Kerberos 是一种网络身份验证协议，它为客户端/服务器应用提供强身份验证。 Hadoop 使用 Kerberos 保护数据免受意外和未经授权的访问。 它通过对底层的**远程过程调用**(**RPC**)进行身份验证来实现这一点。 在本食谱中，我们将概述为 Hadoop 集群配置 Kerberos 身份验证的步骤。

## 做好准备

Kerberos 是由麻省理工学院创建的。 它旨在通过使用密钥加密为客户端/服务器应用提供强身份验证。 Kerberos 协议要求客户端向服务器提供其身份，反之亦然。 当他们的身份被 Kerberos 证实后，他们的所有后续通信都将被加密。

在开始之前，我们假设我们的 Hadoop 已经正确配置，没有任何问题，并且所有 Hadoop 守护进程都在运行，没有任何问题。 在我们的 CentOS 计算机上，使用以下命令安装 Kerberos 软件包：

```sh
sudo yum install krb5-libs, krb5-server, krb5-workstation

```

在此之后，应该可以从命令行访问`kadmin`和`kinit`命令。

如果您还在使用 CentOS 或其他与 Red Hat 兼容的操作系统，我们需要从以下链接下载 Java Cryptoography Extension(JCE)无限强度管辖策略文件：

[http：//www.oracle.com/technetwork/java/javase/downloads/index.html](http://www.oracle.com/technetwork/java/javase/downloads/index.html)

在网页底部，您应该会看到类似以下内容的选项：

![Getting ready](img/5163os_05_01.jpg)

根据您的 Java 版本，单击屏幕右侧的下载链接，我们可以使用`java -version`命令获取该链接。

## 怎么做……

使用以下步骤为 Hadoop 集群配置 Kerberos：

1.  Start the Kerberos admin shell:

    ```sh
    kadmin

    ```

    ### 提示

    如果您的帐户没有 root 访问权限，则需要使用`kadmin.local`命令！

2.  在`kadmin`shell 中使用以下命令创建`hduser`主体：

    ```sh
    addprinc -randkey hduser/master.hdcluster.com@HDREALM

    ```

3.  在`kadmin`外壳中使用以下命令创建 SPNEGO 的 HTTP 主体：

    ```sh
    addprinc -randkey HTTP/master.hdcluster.com@HDREALM

    ```

4.  使用以下命令创建包含`hduser`实例和 HTTP 主体的`keytab`文件：

    ```sh
    xst -norandkey -k hduser.keytab hduser/master.hdcluster.com HTTP/master.hdcluster.com

    ```

5.  Show available `keytab` file entries with the following command:

    ```sh
    klist -e -k -t hduser.keytab

    ```

    输出将类似于以下内容：

    ```sh
    Keytab name: WRFILE:hduser.keytab
    slot KVNO Principal
    ---- ---- ---------------------------------------------------------------
    1    7    HTTP/master.hdcluster.com@HDREALM (DES cbc mode with CRC-32)
    2    7    HTTP/master.hdcluster.com@HDREALM (Triple DES cbc mode with HMAC/sha1)
    3    7    hduser/master.hdcluster.com@HDREALM (DES cbc mode with CRC-32)
    4    7    hduser/master.hdcluster.com@HDREALM (Triple DES cbc mode with HMAC/sha1)

    ```

6.  使用以下命令将`keytab`文件移动到 Hadoop 配置目录：

    ```sh
    cp *.keytab $HADOOP_HOME/conf

    ```

7.  使用以下内容更改`hduser``keytab`文件的所有者：

    ```sh
    sudo chown hduser:hadoop $HADOOP_HOME/conf/hduser.keytab

    ```

8.  Change the permission of the `keytab` files with:

    ```sh
    sudo chmod 400 $HADOOP_HOME/conf/*.keytab

    ```

    ### 备注

    只有所有者才能读取`keytab`文件。

9.  使用

    ```sh
    for node in `cat $HADOOP_HOME/conf/slaves`; do
     echo 'Copying keytab files to ' $host
     scp $HADOOP_HOME/conf/*.keytab $host:$HADOOP_HOME/conf/
    done

    ```

    将所有`kaytab`文件复制到从节点
10.  使用以下命令停止集群：

    ```sh
    stop-all.sh

    ```

11.  使用您喜欢的文本编辑器打开`$HADOOP_HOME/conf/core-site.xml`文件，并向该文件添加以下行：

    ```sh
    <property>
      <name>hadoop.security.authorization</name>
      <value>true</value>
    </property>

    <property>
      <name>hadoop.security.authentication</name>
      <value>kerberos</value> 
    </property>

    <property>
      <name>hadoop.security.use-weak-http-crypto</name>
      <value>false</value>
    </property>
    ```

12.  使用您最喜欢的文本编辑器打开`$HADOOP_HOME/conf/hdfs-site.xml`文件，并在文件中添加以下行：

    ```sh
    <property>
      <name>dfs.block.access.token.enable</name>
      <value>true</value>
    </property>

    <property>
      <name>dfs.http.address</name>
      <value>master:50070</value>
    </property>

    <property>
      <name>dfs.namenode.keytab.file</name>
      <value>$HADOOP_HOME/conf/hduser.keytab</value>
    </property>

    <property>
      <name>dfs.namenode.kerberos.principal</name>
      <value>hduser/master.hdcluster.com@HDREALM</value>
    </property>

    <property>
      <name>dfs.namenode.kerberos.internal.spnego.principal</name>
      <value>HTTP/master.hdcluster.com@HDREALM</value>
    </property>

    <property>
      <name>dfs.secondary.namenode.keytab.file</name>
      <value>$HADOOP_HOME/conf/hduser.keytab</value>
    </property>

    <property>
      <name>dfs.secondary.namenode.kerberos.principal</name>
      <value>hduser/master.hdcluster.com@HDREALM</value>
    </property>
    <property>
      <name>dfs.secondary.namenode.kerberos.internal.spnego.principal</name>
      <value>HTTP/master.hdcluster.com@HDREALM</value>
    </property>

    <property>
      <name>dfs.secondary.http.address</name>
      <value>master.hdcluster.com:50090</value>
    </property>

    <property>
      <name>dfs.datanode.data.dir.perm</name>
      <value>700</value>
    </property>

    <property>
      <name>dfs.datanode.address</name>
      <value>0.0.0.0:1004</value>
    </property>

    <property>
      <name>dfs.datanode.http.address</name>
      <value>0.0.0.0:1006</value>
    </property>

    <property>
      <name>dfs.datanode.keytab.file</name>
      <value>$HADOOP_HOME/conf/hduser.keytab</value>
    </property>

    <property>
      <name>dfs.datanode.kerberos.principal</name>
      <value>hduser/master.hdcluster.com@HDREALM</value>
    </property>
    ```

13.  通过向`$HADOOP_HOME/conf/hdfs-site.xml`文件添加以下属性来启用 webHDFS：

    ```sh
    <property>
      <name>dfs.webhdfs.enabled</name>
      <value>true</value>
    </property>
    ```

14.  通过将以下两个属性添加到`$HADOOP_HOME/conf/hdfs-site.xml`文件来配置 Kerberos Web 身份验证：

    ```sh
    <property>
      <name>dfs.web.authentication.kerberos.principal</name>
      <value>HTTP/master.hdcluster.com@HDREALM</value>
    </property>

    <property>
      <name>dfs.web.authentication.kerberos.keytab</name>
      <value>$HADOOP_HOME/conf/HTTP.keytab</value>
    </property>
    ```

15.  Start the cluster with the following command:

    ```sh
    start-all.sh

    ```

    我们将收到类似以下内容的日志消息：

    ```sh
    13/02/25 10:19:02 INFO security.UserGroupInformation:
    Login successful for user hduser/master.hdcluster.com@HDREALM using keytab file /usr/local/hadoop/hduser.keytab
    13/02/25 10:19:07 INFO http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
    13/02/25 10:19:12 INFO http.HttpServer: Adding Kerberos (SPNEGO) filter to getDelegationToken
    13/02/25 10:19:15 INFO http.HttpServer: Adding Kerberos (SPNEGO) filter to renewDelegationToken
    13/02/25 10:19:22 INFO http.HttpServer: Adding Kerberos (SPNEGO) filter to cancelDelegationToken
    13/02/25 10:19:32 INFO http.HttpServer: Adding Kerberos (SPNEGO) filter to fsck
    13/02/25 10:19:36 INFO http.HttpServer: Adding Kerberos (SPNEGO) filter to getimage

    ```

16.  使用以下命令将一个简单的文本文件复制到 HDFS 中，以测试 Kerberos 配置：

    ```sh
    hadoop fs -put $HADOOP_HOME/conf/slaves .
    ```

17.  在 HDFS 目录上设置*粘滞*位，以防止未经授权的用户使用以下命令删除目录或文件：

    ```sh
    sudo -u hdfs hadoop fs -chmod 1777 /tmp

    ```

18.  Verify the sticky bit setting with the following command:

    ```sh
    hadoop fs -ls /

    ```

    输出应类似于：

    ```sh
    Found 2 items
    drwxrwxrwt - hduser supergroup 0 2013-03-10 15:55 /tmp
    drwxr-xr-x - hduser supergroup 0 2013-03-10 14:01 /user

    ```

19.  通过将以下行添加到`$HADOOP_HOME/conf/mapred-site.xml`文件来配置 MapReduce Kerberos 身份验证：

    ```sh
    <property>
      <name>mapreduce.jobtracker.kerberos.principal</name>
      <value>hduser/master.hdcluster.com@HDREALM</value>
    </property>

    <property>
      <name>mapreduce.jobtracker.keytab.file</name>
      <value>$HADOOP_HOME/conf/hduser.keytab</value>
    </property>

    <property>
      <name>mapreduce.tasktracker.kerberos.principal</name>
      <value>$HADOOP_HOME/conf/hduser.keytab</value>
    </property>

    <property>
      <name>mapreduce.tasktracker.keytab.file</name>
      <value>$HADOOP_HOME/conf/hduser.keytab</value>
    </property>

    <property>
      <name>mapred.task.tracker.task-controller</name>
      <value>org.apache.hadoop.mapred.LinuxTaskController</value>
    </property>

    <property>
      <name>mapreduce.tasktracker.group</name>
      <value>hadoop</value>
    </property>
    ```

20.  创建包含以下内容的`$HADOOP_HOME/conf/taskcontrol.cfg`文件：

    ```sh
    mapred.local.dir=${hadoop.tmp.dir}/mapred/local
    hadoop.log.dir=$HADOOP_HOME/logs
    mapreduce.tasktracker.group=hduser
    banned.users=
    min.user.id=2000
    ```

21.  Change the ownership and permission of the `$HADOOP_HOME/conf/taskcontroller.cfg` file:

    ```sh
    sudo chown root:mapred $HADOOP_HOME/conf/task-controller.cfg
    sudo chmod 4754 $HADOOP_HOME/conf/task-controller.cfg

    ```

    ### 备注

    修改后的权限应如下所示：

    ```sh
    -rwsr-xr-- 1 hduser superuser 91886 2013-03-10 13:44 task-controller.cfg

    ```

22.  Start the MapReduce cluster with the following command:

    ```sh
    start-mapred.sh

    ```

    ### 备注

    我们应该能够获得类似于以下内容的日志记录消息：

    ```sh
    13/02/26 12:25:02 INFO security.UserGroupInformation:
    Login successful for user hduser/master.hdcluster.com@HDREALM using keytab file $HADOOP_HOME/conf/hduser.keytab.

    ```

23.  通过使用以下命令运行示例 MapReduce 作业来测试 Kerberos 配置：

    ```sh
    hadoop jar $HADOOP_HOME/hadoop-example*.jar pi 20 1000000

    ```

## 另请参阅

*   [第 5 章](5.html "Chapter 5. Hardening a Hadoop Cluster")，*加强 Hadoop 集群*中的*配置 Web UI 身份验证*配方
*   [http：//en.wikipedia.org/wiki/SPNEGO](http://en.wikipedia.org/wiki/SPNEGO)
*   [HTTPS：//ccp.cloudera.com/display/CDHDOC/Configuring+Hadoop+Security+in+CDH3+(SPNEGO)](https://ccp.cloudera.com/display/CDHDOC/Configuring+Hadoop+Security+in+CDH3+(SPNEGO))
*   从[http://web.mit.edu/kerberos/](http://web.mit.edu/kerberos/)获取有关 kerberos 的更多信息

# 配置 Web 用户界面身份验证

默认情况下，Hadoop 用户和管理员无需任何身份验证即可访问 Hadoop 守护进程的 Web UI。 可以将 Hadoop 守护程序 Web UI 配置为使用 Kerberos 对用户进行身份验证。 在本菜谱中，我们将概述配置用户身份验证以访问 Web UI 的步骤。

## 做好准备

我们假设我们的 Hadoop 已经正确配置，并且所有守护进程都在正常运行，没有任何问题。 我们还假设已经正确配置了 Kerberos 身份验证。

在本配方中，我们假设所有属性配置都将在`$HADOOP_HOME/conf/core-site.xml`文件上进行更改。

## 怎么做……

使用以下步骤配置 Web 用户界面身份验证：

1.  使用以下命令停止集群：

    ```sh
    stop-all.sh

    ```

2.  添加或更改以下属性：

    ```sh
    <property>
      <name>hadoop.http.filter.initializers</name>
    <value>org.apache.hadoop.security.AuthenticationFilterInitializer</value>
    </property>
    ```

3.  Change the HTTP authentication type by adding the following code:

    ```sh
    <property>
      <name>hadoop.http.authentication.type</name>
      <value>kerberos</value>
    </property>
    ```

    ### 提示

    其他 HTTP 身份验证类型包括简单身份验证和用户自定义身份验证，可通过指定`AUTHENTICATION_HANDLER_CLASSNAME`值选择这两种身份验证类型。 默认身份验证类型为简单。

4.  Configure the authentication token's valid time length by changing the `hadoop.http.authentication.token.validity` property to the following:

    ```sh
    <property>
      <name>hadoop.http.authentication.token.validity</name>
      <value>10000</value>
    </property>
    ```

    ### 提示

    该值的单位是秒。 此属性的默认值为`36000`。

5.  Configure the location of the `signature.secret` file, which will be used to sign the authentication tokens, by changing the `hadoop.http.authentication.signature.secret.file` property similar to the following:

    ```sh
    <property>
      <name>hadoop.http.authentication.signature.secret.file</name>
      <value>$HADOOP_HOME/conf/http-auth.secret</value>
    </property>
    ```

    ### 备注

    如果未设置此属性，将在启动时生成随机的`secret`文件。 用于保密的默认文件将是`${user.name}/hadoop-auth-signature-secret`。

6.  Configure the domain name for HTTP cookies, which stores authentication tokens, by changing the `hadoop.http.authentication.cookie.domain` property similar to the following:

    ```sh
    <property>
      <name>hadoop.http.authentication.cookie.domain</name>
      <value>hdcluster.com</value>
    </property>
    ```

    ### 提示

    **警告！**

    此属性是 HTTP 身份验证正常工作所必需的。

7.  通过更改类似于以下内容的`hadoop.http.authentication.kerberos.principal`属性来配置 HTTP 端点的 Kerberos 主体：

    ```sh
    <property>
      <name>hadoop.http.authentication.kerberos.principal</name>
      <value>HTTP/master.hdcluster.com@HDREALM</value>
    </property>
    ```

8.  通过更改类似于以下内容的`hadoop.http.authentication.kerberos.keytab`属性，为 HTTP 终结点的 Kerberos 主体配置`keytab`文件的位置：

    ```sh
    <property>
      <name>hadoop.http.authentication.kerberos.keytab</name>
      <value>${user.home}/kerberos.hadoop.keytab</value>
    </property>
    ```

9.  使用以下命令将配置同步到从节点：

    ```sh
    for host in `cat $HADOOP_HOME/conf/slaves`; do
     echo "Copying Hadoop configration files to host: ' $host
     scp $HADOOP_HOME/conf/core-site.xml $host:$HADOOP_HOME/conf
    done

    ```

10.  使用以下命令启动 Hadoop 集群：

    ```sh
    start-all.sh

    ```

11.  通过打开 URL`master:50030/jobtracker.jsp`验证配置。
12.  或者，我们可以使用以下`curl`命令测试我们的配置：

    ```sh
    curl -v -u hduser --negotiate http://master:50030/jobtracker.jsp

    ```

## 它是如何工作的.

Web UI 身份验证是使用 HTTP SPNEGO 协议实现的。 **SPNEGO**代表**简单且受保护的协商**机制。 它是一种 GSSAPI 机制，用于协商多种可能的实际机制之一。 当客户端应用想要向远程服务器进行身份验证，但两端都不确定对方支持哪种身份验证协议时，可以使用 SPNEGO。

伪机制使用协议来确定哪些常见的 GSSAPI 机制可用，选择一个，然后将所有进一步的安全操作分派给它。 这可以帮助组织分阶段部署新的安全机制。

有关 SPNEGO 的更多信息，请参考到它的维基页面[http://en.wikipedia.org/wiki/SPNEGO](http://en.wikipedia.org/wiki/SPNEGO)。

## 还有更多...

其他身份验证方法包括简单身份验证。 如果使用此身份验证方法，则必须在第一次浏览器交互中使用 URL 中的`user.name`参数指定用户名。 例如，我们需要打开 JobTracker URL：`http://master:50030/jobtracker.jsp?user.name=hduser`。

如果使用简单身份验证作为身份验证类型，则可以通过更改以下属性来配置匿名用户 Web 用户界面请求：

```sh
<property>
  <name>hadoop.http.authentication.simple.anonymous.allowed</name>
  <value>true</value>
</property>
```

## 另请参阅

*   [第 5 章](5.html "Chapter 5. Hardening a Hadoop Cluster")，*加强 Hadoop 集群*中的*使用 Kerberos*配方保护 Hadoop 集群
*   [http：//hadoop.apache.org/docs/stable/HttpAuthentication.html](http://hadoop.apache.org/docs/stable/HttpAuthentication.html)

# 从 NameNode 故障中恢复

Hadoop 集群中的 NameNode 跟踪整个 HDFS 文件系统的元数据。 不幸的是，在撰写本书时，Hadoop 当前稳定版本中的 NameNode 是单点故障。 如果 NameNode 的元数据损坏(例如，由于硬盘故障)，则整个集群将变得不可用。 因此，保护 NameNode 免受这些灾难性故障的影响非常重要。

我们可以通过多种方式提高 HDFS 集群的弹性。 在本食谱中，我们将向您展示如何将 Second NameNode 配置为备份 NameNode，以及如何从 NameNode 故障中恢复。

## 做好准备

我们假设 Hadoop 集群已经正确配置，我们有一台机器`master1`作为 NameNode，另一台机器`master2`运行 Second daryNameNode。

### 备注

请做好准备，NameNode 故障可能会导致集群暂停。 可能需要一些时间才能从故障中恢复过来。

## 怎么做……

我们要介绍的第一种方法是将 NameNode 配置为将编辑日志和文件系统映像写入两个位置-一个在 NameNode 机器的本地目录上，另一个在 Second daryNameNode 机器上。 这些目录使用 HDFS 属性`dfs.name.dir`指定。 我们可以使用以下步骤进行配置：

1.  使用以下命令登录到`master1`：

    ```sh
    ssh hduser@master1

    ```

2.  Configure the following property in the `$HADOOP_HOME/conf/hdfs-site.xml` file:

    ```sh
    <property>
        <name>dfs.name.dir</name>
        <value>/hadoop/dfs/name,/mnt/snn/name</value>
    </property>
    ```

    ### 提示

    在该属性中，我们为 NameNode 配置了两个要向其中写入元数据的目录。 第一目录`/hadoop/dfs/name`是`master1`上的目录，第二目录`/mnt/ssn/name`是`master2`上的一个 NFS 共享目录`/hadoop/dfs/name`。 换句话说，我们正在配置两台机器`master1`和`master2`，使其具有相同的 NameNode 目录布局。

    为简单起见，我们不会在本食谱中向您展示 NFS 的配置。 有关此主题的更多信息，请访问[http://www.tldp.org/HOWTO/NFS-HOWTO/](http://www.tldp.org/HOWTO/NFS-HOWTO/)

3.  在`$HADOOP_HOME/conf/core-site.xml`文件中配置以下属性：

    ```sh
    <property>
        <name>fs.default.name </name>
        <value>master1:54310</value>
    </property>
    ```

4.  使用以下命令将配置复制到`master2`：

    ```sh
    scp $HADOOP_HOME/conf/hdfs-site.xml master2:$HADOOP_HOME/conf/
    scp $HADOOP_HOME/conf/slaves master2:$HADOOP_HOME/conf/

    ```

5.  使用以下命令将配置文件复制到集群中的所有从节点：

    ```sh
    for host in `cat $HADOOP_HOME/conf/slaves`; do
     echo 'Sync configuration files to ' $host
     scp $HADOOP_HOME/conf/core-site.xml $host:$HADOOP_HOME/conf
    done

    ```

6.  Start the Hadoop cluster in `master1` with the following command:

    ```sh
    start-all.sh

    ```

    ### 提示

    在此配置中，我们实际上没有在 Second daryNameNode 机器`master2`上启动任何守护进程。 我们只使用这台机器存储`master1`上 NameNode 的元数据文件。 一旦 NameNode 出现故障，我们可以很轻松地在`master2`上快速启动 NameNode。

一旦`master1`上的 NameNode 出现故障，我们可以使用以下步骤进行恢复：

1.  使用以下命令登录到`master2`：

    ```sh
    ssh hduser@master2

    ```

2.  使用以下命令停止集群：

    ```sh
    ssh master1 -C "stop-all.sh"

    ```

3.  通过向`$HADOOP_HOME/conf/core-site.xml`文件添加以下属性，将其配置为使用`master2`作为 NameNode：

    ```sh
    <property>
        <name>fs.default.name </name>
        <value>master2:54310</value>
    </property>
    ```

4.  使用以下命令将配置复制到集群中的所有从节点：

    ```sh
    for host in `cat $HADOOP_HOME/conf/slaves`; do
     echo 'Sync configuration files to ' $host
     scp $HADOOP_HOME/conf/core-site.xml $host:$HADOOP_HOME/conf
    done

    ```

5.  使用命令

    ```sh
    start-all.sh

    ```

    启动 Hadoop 集群

## 它是如何工作的.

严格地说，HDFS Second daryNameNode 守护进程不是 NameNode。 它仅充当定期将文件系统元数据图像文件和编辑日志文件提取到属性`fs.checkpoint.dir`指定的目录的角色。 在 NameNode 出现故障的情况下，备份文件可用于恢复 HDFS 文件系统。

## 还有更多...

如前所述，NameNode 失败的主要原因是元数据文件损坏。 因此，NameNode 弹性的关键是元数据文件的恢复。 在这里，我们将介绍另外两种方法-一种是将元数据写入多个硬盘驱动器，另一种是从 Second daryNameNode 的检查点恢复。

### 具有多个硬盘的 NameNode 弹性

我们可以使用以下步骤配置具有多个硬盘的 NameNode：

1.  将硬盘安装、格式化并挂载到机器上；假设挂载点为`/hadoop1/`。
2.  使用以下命令创建 Hadoop 目录：

    ```sh
    mkdir /hadoop1/dfs/name

    ```

3.  Configure the following property in the `$HADOOP_HOME/conf/hdfs-site.xml` file:

    ```sh
    <property>
        <name>dfs.name.dir</name>
        <value>/hadoop/dfs/name,/hadoop1/dfs/name</value>
    </property>
    ```

    ### 备注

    在此配置中，我们添加了两个目录。 第一个是 Hadoop 的主目录。 第二个目录是单独硬盘驱动器上的目录。

我们可以使用以下步骤从 NameNode 故障中恢复：

1.  使用以下命令停止 Hadoop 集群：

    ```sh
    stop-all.sh

    ```

2.  在`$HADOOP_HOME/conf/hdfs-site.xml`文件中配置以下属性：

    ```sh
    <property>
        <name>dfs.name.dir</name>
        <value>/hadoop1/dfs/name</value>
    </property>
    ```

3.  使用以下命令启动集群：

    ```sh
    start-all.sh

    ```

### 从辅助 NameNode 的检查点恢复 NameNode

我们可以使用以下步骤配置 Second daryNameNode，并从 NameNode 故障中恢复：

1.  使用以下命令登录到`master1`：

    ```sh
    ssh hduser@master1

    ```

2.  Add the following line into the `$HADOOP_HOME/conf/masters` file:

    ```sh
    master2

    ```

    ### 备注

    通过这样做，我们将其配置为在`master2`上运行 Second daryNameNode。

3.  在`$HADOOP_HOME/conf/hdfs-site.xml`文件中配置以下属性：

    ```sh
    <property>
        <name>dfs.name.dir</name>
        <value>/hadoop/dfs/name</value>
    </property>
    ```

4.  使用以下命令将配置文件同步到集群中的从节点：

    ```sh
    for host in `cat $HADOOP_HOME/conf/slaves`; do
     echo 'Sync configuration files to ' $host
     scp $HADOOP_HOME/conf/hdfs-site.xml $host:$HADOOP_HOME/conf
    done

    ```

5.  使用以下命令启动集群：

    ```sh
    start-all.sh

    ```

如果 NameNode 出现故障，我们可以使用以下步骤进行恢复：

1.  使用以下命令停止集群：

    ```sh
    stop-all.sh

    ```

2.  Prepare a new machine for running the NameNode.

    ### 备注

    准备工作应包括正确配置 Hadoop。 建议新的 NameNode 计算机与出现故障的 NameNode 具有相同的配置。

3.  使用以下命令格式化 NameNode：

    ```sh
    hadoop fs -format

    ```

4.  使用以下命令配置 NameNode 版本号：

    ```sh
    scp slave1:/hadoop/dfs/data/current/VERSION* /hadoop/dfs/name/current/VERSION

    ```

5.  使用以下命令从 Second daryNameNode 复制检查点映像：

    ```sh
    scp master2:/hadoop/dfs/namesecondary/image/fsimage /hadoop/dfs/name/fsimage

    ```

6.  使用以下命令从 Second daryNameNode 复制当前编辑日志：

    ```sh
    scp master2:/hadoop/dfs/namesecondary/current/* /hadoop/dfs/name/current

    ```

7.  使用以下命令将检查点转换为新版本格式：

    ```sh
    hadoop namenode -upgrade

    ```

8.  使用以下命令启动集群：

    ```sh
    start-all.sh

    ```

## 另请参阅

*   [第 4 章](4.html "Chapter 4. Managing a Hadoop Cluster")，*管理 Hadoop 集群*中的*管理 HDFS 集群*配方
*   [第 4 章](4.html "Chapter 4. Managing a Hadoop Cluster")，*管理 Hadoop 集群*中的*管理 DataNode 守护进程*配方
*   [https：//issues.apache.org/jira/browse/HADOOP-2585](https://issues.apache.org/jira/browse/HADOOP-2585)

# 配置 NameNode 高可用性

在撰写本书时，Hadoop 稳定版本的 NameNode 是一个单点故障。 如果发生意外故障或定期维护，集群将变得不可用。 对于生产 Hadoop 集群来说，这是一个大问题。 在本食谱中，我们列出了配置 NameNode HA 的步骤。

为了使备用 NameNode 能够自动从活动 NameNode 故障中恢复，NameNode HA 实施要求备用 NameNode 的编辑日志始终与活动 NameNode 保持同步。 Hadoop HA 提供了两种方法来实现这一点。 一种基于仲裁，另一种基于使用 NFS 的共享存储。 在本食谱中，我们将只向您展示如何使用 Quorum 配置 HA。

## 做好准备

目前，Hadoop 版本 1.x.y(MRv1)不支持 NameNode HA，因此我们假设所有集群节点都已经安装了 Hadoop 版本 2.0.x(MRv2)。

### 提示

请注意，此 Hadoop 版本仍处于 Alpha 状态，因此不建议将其用于生产部署。 更多关于 mrv2 的开发情况，请参考官网：[http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html](http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html)。

我们假设有两个主节点，主机名为`master1`和`master2`，用于运行 NameNode 守护进程。

## 怎么做……

使用以下步骤配置 Hadoop NameNode HA：

1.  使用以下命令登录其中一台 NameNode 计算机：

    ```sh
    ssh hduser@master1

    ```

2.  Configure a logical name service by adding the following property to the `$HADOOP_CONF_DIR/hdfs-site.xml` file:

    ```sh
    <property>
      <name>dfs.nameservices</name>
      <value>hdcluster</value>
    </property>
    ```

    ### 备注

    我们假设所有后续配置都在`$HADOOP_CONF_DIR/hdfs-site.xml`文件上进行更改。

3.  Specify the NameNode IDs for the configured name service by adding the following property to the file:

    ```sh
    <property>
      <name>dfs.ha.namenodes.hdcluster</name>
      <value>namenode1,namenode2</value>
    </property>
    ```

    ### 备注

    此属性使用属性`dfs.ha.namenodes.<nameservices>`指定 NameNode ID。 例如，在上一步中，我们已经配置了名称服务`hdcluster`，因此这里的属性名称将是`dfs.ha.namenodes.hdcluster`。 在此属性中，我们为`logic`名称服务指定了`namenode1`和`namenode2`。

    当前 HA 实施最多只支持两个 NameNode。

4.  Configure the RPC address for `namenode1` on the `master1` host by adding the following property:

    ```sh
    <property>
      <name>dfs.namenode.rpc-address.hdcluster.namenode1</name>
      <value>master1:54310</value>
    </property>
    ```

    ### 备注

    NameNode 的 MRv1 RPC 地址规范类似于 MRv2 中的规范。 它们都使用`host:port`格式。

5.  通过添加以下属性，在`master2`主机上配置`namenode2`的 RPC 地址：

    ```sh
    <property>
      <name>dfs.namenode.rpc-address.hdcluster.namenode2</name>
      <value>master2:54310</value>
    </property>
    ```

6.  通过向文件中添加以下行来配置两个 NameNode 的 HTTP Web UI 地址：

    ```sh
    <property>
      <name>dfs.namenode.http-address.hdcluster.namenode1</name>
      <value>master1:50070</value>
    </property>

    <property>
      <name>dfs.namenode.http-address.hdcluster.namenode2</name>
      <value>master2:50070</value>
    </property>
    ```

7.  Configure the NameNode `shared edits` directory by adding the following property to the file:

    ```sh
    <property>
      <name>dfs.namenode.shared.edits.dir</name> <value>qjournal://master1:8485;master1:8486;master2:8485/hdcluster</value>
    </property>
    ```

    ### 备注

    此属性为 Quorum 配置三个**日志节点**地址，以提供共享编辑存储。 共享编辑日志将由活动 NameNode 写入，并由备用 NameNode 读取。

8.  Configure the Quorum `Journal Node` directory for storing edit logs in the local filesystem by adding the following property to the file:

    ```sh
    <property>
      <name>dfs.journalnode.edits.dir</name>
      <value>/hadoop/journaledits/</value>
    </property>
    ```

    ### 备注

    应该在每台 NameNode 计算机上配置此属性。

9.  通过将以下行添加到文件来配置 NameNode HA 的代理提供程序：

    ```sh
    <property>
      <name>dfs.client.failover.proxy.provider.hdcluster</name>
    <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
    </property>
    ```

10.  Configure the `fencing` method by adding the following property to the file:

    ```sh
    <property>
      <name>dfs.ha.fencing.methods</name>
      <value>sshfence</value>
    </property>
    ```

    ### 提示

    目前 NameNode HA 支持两种隔离方式，一种是`sshfence`，另一种是`shell`。 `sshfence`使用 SSH 登录到活动 NameNode 并终止进程，`shell`隔离使用常规 shell 命令来隔离活动 NameNode。 在这个配方中，我们假设使用`sshfence`方法。

11.  Configure the `private key` file for the `sshfence` method by adding the following property to the file:

    ```sh
    <property>
      <name>dfs.ha.fencing.ssh.private-key-files</name>
      <value>$HOME/.ssh/id_rsa</value>
    </property>
    ```

    ### 提示

    此属性的值应该是以逗号分隔的私钥文件列表。 为了使`sshfence`正常工作，我们正在配置私钥文件，以便它可以登录到目标节点，而无需提供释义。

12.  通过将以下属性添加到文件来配置 SSH 连接超时(以毫秒为单位)：

    ```sh
    <property>
      <name>dfs.ha.fencing.ssh.connect-timeout</name>
      <value>50000</value>
    </property>
    ```

13.  Enable automatic failover by adding the following property to the file:

    ```sh
    <property>
      <name>dfs.ha.automatic-failover.enabled</name>
      <value>true</value>
    </property>
    ```

    此配置将启用所有名称服务 ID 的自动故障转移。 如果我们要为特定的名称服务 ID(例如`hdcluster`)启用自动故障转移，我们可以配置以下属性：

    ```sh
    <property>
      <name>dfs.ha.automatic-failover.enabled.hdcluster</name>
      <value>true</value>
    </property>
    ```

14.  通过将以下属性添加到`$HADOOP_CONF_DIR/core-site.xml`文件来配置 ZooKeeper 服务：

    ```sh
    <property>
       <name>ha.zookeeper.quorum</name>
       <value>master1:2181,master2:2181</value>
    </property>
    ```

15.  使用以下命令将配置同步到集群中的所有节点：

    ```sh
    for host in cat $HADOOP_CONF_DIR/slaves; do
     echo 'Sync configuration files to ' $host
     scp $HADOOP_CONF_DIR/hdfs-site.xml $host:$HADOOP_CONF_DIR/
     scp $HADOOP_CONF_DIR/core-site.xml $host:$HADOOP_CONF_DIR/
    done

    ```

16.  Initialize the ZooKeeper with the following command:

    ```sh
    hdfs zkfc -formatZK

    ```

    ### 备注

    此命令将在 ZooKeeper 中创建**Znode**，自动故障转移系统将在其中存储数据。

17.  Start the HDFS cluster with the following command:

    ```sh
    start-dfs.sh

    ```

    ### 备注

    此命令将在每台 NameNode 计算机上启动一个 ZKFC 守护进程，并在守护进程启动后选择活动的 NameNode。

    或者，我们可以使用命令`hadoop-daemon.sh start zkfc`在每台 NameNode 机器上手动启动 ZKFC 守护进程。

我们可以使用以下步骤测试 NameNode HA 配置：

1.  通过使用以下 URL 访问 NameNode Web 用户界面来检查 NameNode 的状态：

    ```sh
    master1:50070
    master2:50070

    ```

2.  Assuming `master1` has the active NameNode, we can get the NameNode process ID on `master1` with the following command:

    ```sh
    jps

    ```

    该命令将产生类似于以下内容的输出：

    ```sh
    ...
    22459 NameNode
    ...

    ```

3.  Kill the NameNode process with the following command on `master1`:

    ```sh
    kill -9 22459

    ```

    ### 备注

    如果备用 NameNode 自动成为活动 NameNode，并且 Hadoop 集群仍在工作，没有任何问题，则配置成功。

## 它是如何工作的.

Hadoop NameNode HA 是从版本 0.23.x 或 2.0.x 分支(MRv2)开始引入的。 目标是保证集群的可用性。 它使用集群中的两个 NameNode、一个活动 NameNode 和一个备用 NameNode 来解决该问题。 活动 NameNode 将提供与 MRv1 中的 NameNode 相同的服务。 与仅将 NameNode 映像和编辑日志复制到备份目录的 Second daryNameNode 不同，备用 NameNode 是活动 NameNode 的热备份节点。 如果活动 NameNode 出现故障，备用 NameNode 将在最短时间内成为活动节点。

## 还有更多...

在 NameNode HA 实现中，ZooKeeper 扮演着重要角色。 动物园管理员的安全可能是一个必要的问题。 我们可以使用以下步骤配置受保护的动物园管理员：

1.  使用`ssh`命令登录到`master1`机器。
2.  Add the following property to the `$HADOOP_CONF_DIR/core-site.xml` file:

    ```sh
    <property>
      <name>ha.zookeeper.auth</name>
      <value>@$HADOOP_CONF_DIR/zkauth.txt</value>
    </property>
    ```

    ### 备注

    此属性配置用于 ZooKeeper 身份验证的文件。 特殊符号`@`指定配置指向文件，而不是内联。 该文件的内容应该类似于`digest:zkuser:password`，其中`zkuser`是 ZooKeeper 的用户，`password`是`zkuser`的密码。

3.  Add the following property into the `$HADOOP_CONF_DIR/core-site.xml` file for ZooKeeper access control:

    ```sh
    <property>
      <name>ha.zookeeper.acl</name>
      <value>@$HADOOP_CONF_DIR/zkacl.txt</value>
    </property>
    ```

    ### 备注

    与`ha.zookeeper.auth`属性类似，值中的`@`字符指定`configuration`是磁盘上的文件。

4.  Generate ZooKeeper ACL corresponding to the authentication with the following command:

    ```sh
    java -cp $ZK_HOME/lib/*:$ZK_HOME/zookeeper-*.jar org.apache.zookeeper.server.auth.DigestAuthenticationProvider zkuser:password

    ```

    我们将得到类似于以下内容的输出：

    ```sh
    zkuser:password->zkuser:a4XNgljR6VhODbC7jysuQ4gBt98=

    ```

5.  将加密密码添加到`$HADOOP_CONF_DIR/zkacl.txt`文件：

    ```sh
    digest:zkuser:a4XNgljR6VhODbC7jysuQ4gBt98=
    ```

6.  使用以下命令将配置同步到`master2`：

    ```sh
    scp $HADOOP_CONF_DIR/zkacl.txt master2:$HADOOP_CONF_DIR/
    scp $HADOOP_CONF_DIR/zkauth.txt master2:$HADOOP_CONF_DIR/

    ```

7.  使用以下命令格式化 ZooKeeper：

    ```sh
    hdfs zkfc -formatZK

    ```

8.  Test the configuration with the following command:

    ```sh
    zkCli.sh

    ```

    我们将得到类似于以下内容的输出：

    ```sh
    [zk: master1:2181(CONNECTED) 1] getAcl /hadoop-ha'digest, zkuser: a4XNgljR6VhODbC7jysuQ4gBt98=
    : cdrwa

    ```

9.  使用以下命令重新启动集群：

    ```sh
    start-dfs.sh

    ```

## 另请参阅

*   [第 5 章](5.html "Chapter 5. Hardening a Hadoop Cluster")，*加强 Hadoop 集群*中的*配置 HDFS 联合*配方
*   [http：//hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/HDFSHighAvailabilityWithNF.html](http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/HDFSHighAvailabilityWithNFS.html)

# 配置 HDFS 联合

Hadoop NameNode 将元数据保存在主内存中。 当 HDFS 命名空间变大时，主内存可能成为集群的瓶颈。 在适用于 MRv2 的 Hadoop 中引入了 HDFS 联合。 它通过利用多个独立 NameNode 的容量来增加 NameNode 容量和吞吐量，每个 NameNode 托管或管理 HDFS 命名空间的一部分。

## 做好准备

目前，只有 Hadoop MRv2 支持 NameNode 联合，因此我们假设所有集群计算机上都正确配置了 Hadoop MRv2。

### 备注

我们假设所有配置都在对`$HADOOP_CONF_DIR/hdfs-site.xml`文件进行更改。

## 怎么做……

使用以下步骤配置 HDFS 联合：

1.  使用以下命令登录到`master1`：

    ```sh
    ssh hduser@master1

    ```

2.  Specify a list of NameNode service IDs by adding the following lines into the file:

    ```sh
    <property>
      <name>dfs.nameservices</name>
      <value>namenode1,namenode2</value>
    </property>
    ```

    ### 备注

    此属性的值是以逗号分隔的 NameNode 服务 ID 列表。 例如，在此步骤中，该值指定了两个 NameNode 服务：`namenode1`和`namenode2`。

3.  Configure the NameNode RPC and HTTP URI for `namenode1` by adding the following into the file:

    ```sh
    <property>
        <name>dfs.namenode.rpc-address.namenode1</name>
        <value>master1:54310</value>
      </property>

      <property>
        <name>dfs.namenode.http-address.namenode1</name>
        <value>master1:50070</value>
      </property>

      <property>
        <name>dfs.namenode.secondaryhttp-address.namenode1</name>
        <value>master1:50071</value>
      </property>
    ```

    ### 备注

    前面的配置假设 NameNode 守护进程以及 NameNode HTTP 和辅助 HTTP 守护进程位于主机`master1`上。

4.  通过将以下内容添加到文件中，指定`namenode2`的 NameNode RPC 和 HTTP URI：

    ```sh
    <property>
      <name>dfs.namenode.rpc-address.namenode2</name>
      <value> master2:54310</value>
    </property>
    <property>
      <name>dfs.namenode.http-address.namenode2</name>
      <value> master2:50070</value>
    </property>
    <property>
      <name>dfs.namenode.secondaryhttp-address.namenode2</name>
      <value>master2:50071</value>
    </property>
    ```

5.  使用以下命令将配置同步到集群中的所有节点：

    ```sh
    for host in cat $HADOOP_CONF_DIR/slaves; do
     echo 'Sync configuration files to ' $host
     scp $HADOOP_CONF_DIR/hdfs-site.xml $host:$HADOOP_CONF_DIR/
    done

    ```

6.  Format `namenode1` on `master1` with the following command:

    ```sh
    hdfs namenode -format -clusterId hdcluster

    ```

    ### 备注

    在此命令中，`-clusterId`选项应该是环境中唯一的集群 ID。 如果未指定，将自动生成唯一的集群 ID。

7.  Similarly, format `namenode2` on `master2` with the following command:

    ```sh
    hdfs namenode -format -clusterId hdcluster

    ```

    ### 提示

    **警告！**

    此 NameNode 的集群 ID 应与为`namenode1`指定的集群 ID 相同，以便两个 NameNode 位于同一集群中。

8.  现在，我们可以使用以下命令在任一 NameNode 主机上启动或停止 HDFS 集群：

    ```sh
    start-dfs.sh
    stop-dfs.sh

    ```

## 它是如何工作的.

在非联合 HDFS 集群上，所有 DataNode 都向单个 NameNode 注册并向其发送心跳信号。 在联合 HDFS 集群上，所有 DataNode 都将注册到集群中的所有 NameNode，并且心跳和数据块报告将发送到这些 NameNode。

联合 HDFS 集群由一个或多个命名空间卷组成，命名空间卷由命名空间和属于该命名空间的数据块池组成。 命名空间卷是集群中的管理单位。 例如，集群管理操作(如`delete`和`upgrade`)将在命名空间卷上操作。 此外，联合 NameNode 可以为不同的应用或情况隔离名称空间。

下表显示了配置 NameNode 联合的属性：

<colgroup><col style="text-align: left"> <col style="text-align: left"> <col style="text-align: left"></colgroup> 
| 

精灵 / 恶魔 / 守护进程 / 后台程序

 | 

性质 / 财产 / 所有权

 | 

描述 / 描写 / 形容 / 类别

 |
| --- | --- | --- |
| NameNode | `dfs.namenode.rpc-address` | 用于 NameNode RPC 与客户端的通信 |
| `dfs.namenode.servicerpc-address` | 用于与 HDFS 服务进行 NameNode RPC 通信 |
| `dfs.namenode.http-address` | NameNode HTTP Web 用户界面地址 |
| `dfs.namenode.https-addressw` | NameNode 安全的 HTTP Web 用户界面地址 |
| `dfs.namenode.name.dir` | NameNode 本地目录 |
| `dfs.namenode.edits.dir` | NameNode 编辑日志的本地目录 |
| `dfs.namenode.checkpoint.dir` | Second daryNameNode 本地目录 |
| `dfs.namenode.checkpoint.edits.dir` | Second daryNameNode 编辑日志的目录 |
| Second DaryNameNode | `dfs.secondary.namenode.keytab.file` | Second daryNameNode`keytab`文件 |
| `dfs.namenode.backup.address` | 备份节点的地址 |
| 备份节点 | `dfs.secondary.namenode.keytab.file` | 备份节点\\T0 文件 |

## 还有更多...

NameNode 联合 Hadoop 集群的管理任务与不支持联合的旧版本(MRv1)不同。

### 从集群中取消 NameNode

将 NameNode ID 添加到`$HADOOP_CONF_DIR/namenode_exclude.txt`文件中。 例如，如果我们想要从集群中停用`namenode1`，文件的内容应该是：

```sh
namenode1

```

使用以下命令将`exclude`文件分发给所有 NameNode：

```sh
distributed-exclude.sh $HADOOP_CONF_DIR/namenode_exlude.txt

```

使用以下命令刷新 NameNode 列表：

```sh
refresh-namenodes.sh

```

我们可以使用以下 URL 访问 HDFS 集群的 Web 用户界面：

```sh
http://namenode2:50070/dfsclusterhealth.jsp

```

### 运行平衡机

与旧的 Hadoop 版本类似，平衡器用于平衡集群上的数据块。 在 HDFS 联合 Hadoop 集群上，我们可以使用以下命令运行平衡器：

```sh
hadoop-daemon.sh --config $HADOOP_HOME/conf --script hdfs start balancer -policy node

```

此命令将在节点级别平衡数据块。 另一个平衡策略是`blockpool`，它在数据块池级别和数据节点级别平衡存储。

### 添加新的 NameNode

假设我们已经配置了一个由 NameNode 联合的 Hadoop 集群，其中有两个正在运行的 NameNode。 我们想要在主机`master3`上添加第三个 NameNode`namenode3`。 我们可以使用以下步骤来完成此操作：

1.  登录到新的 NameNode 计算机`master3`。
2.  在`master3`节点上配置 MRv2。
3.  将以下行添加到`$HADOOP_CONF_DIR/hdfs-site.xml`文件中：

    ```sh
    <property>
      <name>dfs.nameservices</name>
      <value>namenode1,namenode2,namenode3</value>
    </property>

    <property>
      <name>dfs.namenode.rpc-address.namenode1</name>
      <value>master1:54310</value>
    </property>

    <property>
      <name>dfs.namenode.http-address.namenode1</name>
      <value> master1:50070</value>
    </property>
    <property>
      <name>dfs.namenode.secondaryhttp-address.namenode1</name>
      <value>master1:50071</value>
    </property>

    <property>
      <name>dfs.namenode.rpc-address.namenode2</name>
      <value>master2:54310</value>
    </property>

    <property>
      <name>dfs.namenode.http-address.namenode2</name>
      <value> master2:50070</value>
    </property>
    <property>
      <name>dfs.namenode.secondaryhttp-address.namenode2</name>
      <value>master2:50071</value>
    </property>

    <property>
      <name>dfs.namenode.rpc-address.namenode3</name>
      <value>master3:54310</value>
    </property>

    <property>
      <name>dfs.namenode.http-address.namenode3</name>
      <value> master3:50070</value>
    </property>
    <property>
      <name>dfs.namenode.secondaryhttp-address.namenode3</name>
      <value>master3:50071</value>
    </property>
    ```

4.  使用以下命令格式化`namenode3`：

    ```sh
    hdfs namenode -format -cluserId hdcluster

    ```

5.  使用以下命令将配置同步到所有其他 NameNode：

    ```sh
    scp $HADOOP_CONF_DIR/hdfs-site.xml master1:$HADOOP_CONF_DIR/
    scp $HADOOP_CONF_DIR/hdfs-site.xml master2:$HADOOP_CONF_DIR/

    ```

6.  使用以下命令将配置同步到集群中的所有从节点：

    ```sh
    for host in `cat $HADOOP_CONF_DIR/slaves`; do
     echo 'Sync configuration files to ' $host
     scp $HADOOP_CONF_DIR/hdfs-site.xml $host:$HADOOP_CONF_DIR/
    done

    ```

7.  使用以下命令启动 HDFS 集群：

    ```sh
    start-dfs.sh

    ```

8.  使用以下命令将 NameNodes 的更改告知 DataNodes：

    ```sh
    for slavehost in `$HADOOP_CONF_DIR/slaves`;  do
     echo "Processing on host " $slavehost
     ssh $slavehost -C "hdfs dfsadmin -refreshNameNode master3:54310"
    done

    ```

## 另请参阅

*   [第 5 章](5.html "Chapter 5. Hardening a Hadoop Cluster")，*加强 Hadoop 集群*中的*配置 NameNode 高可用性*配方
*   [http：//hadoop.apache.org/docs/r2.0.2-alpha/hadoop-yarn/hadoop-yarn-site/Federation.html](http://hadoop.apache.org/docs/r2.0.2-alpha/hadoop-yarn/hadoop-yarn-site/Federation.html)
*   [http：//hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml](http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml)
*   [http：//hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/HDFSHighAvailabilityWithQJM.html](http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/HDFSHighAvailabilityWithQJM.html)