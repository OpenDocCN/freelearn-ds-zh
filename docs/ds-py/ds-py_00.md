# 序言

|   | *"开发者是当今商业中最重要、最有价值的群体，无论在哪个行业。"* |   |
| --- | --- | --- |
|   | --*斯蒂芬·奥格雷迪，《新王 makers》一书的作者* |

首先，我要感谢并祝贺你，亲爱的读者，做出决定，投资宝贵的时间来阅读这本书。在接下来的章节中，我将带领你从开发者的角度来发现或重新发现数据科学，并阐述本书的主题，即数据科学是一项团队运动，如果它要成功，开发者将在不久的将来扮演更重要的角色，并且与数据科学家更好地合作。然而，为了使数据科学更加包容各行各业的人，我们首先需要通过让数据变得简单和可访问来*让它民主化*——这实际上就是本书的核心内容。

# 我为什么要写这本书？

正如我将在第一章中详细解释的那样，*编程与数据科学 – 一套新工具*，我首先是一名开发者，拥有超过 20 年的多样化软件组件构建经验；包括前端、后端、中间件等等。回顾这段时光，我意识到，每当我思考时，正确的算法总是放在首位；数据总是别人的问题。我很少需要分析数据或从中提取洞察。充其量，我只是设计合适的数据结构，以便以一种更高效、更优雅且可复用的方式加载数据，进而使我的算法运行得更加顺畅。

然而，随着人工智能和数据科学革命的展开，我很明显地意识到像我这样的开发者需要参与其中，因此，7 年前的 2011 年，我抓住机会成为 IBM Watson 核心平台 UI 与工具的首席架构师。当然，我并不自称已成为机器学习或自然语言处理领域的专家，远非如此。通过实践学习并不能替代获得正式的学术背景。

然而，我在本书中想要展示的一个重要观点是，凭借正确的工具和方法，拥有合适数学基础的人（我这里只谈高中的微积分概念）可以迅速成为这一领域的优秀从业者。成功的关键之一是尽可能简化构建数据管道的不同步骤；从获取、加载、清洗数据，到可视化和探索，再到构建和部署机器学习模型。

正是出于让数据更简单、让数据科学家之外的社区也能接触到数据的想法，三年前，我在 IBM Watson 数据平台团队中担任领导角色，致力于扩大开发者社区，专注于教育和为开发者争取权益。在那个时期，作为首席开发者倡导者，我开始公开讨论开发者和数据科学家在解决复杂数据问题时需要更好地协作。

### 注意

**注意**：在会议和聚会上讨论时，我有时会与数据科学家产生矛盾，因为他们误解了我的叙述，以为我在说数据科学家不是优秀的软件开发人员。我想澄清一下，包括对你——数据科学家的读者——说，这绝对不是我的意思。

大多数数据科学家都是优秀的软件开发人员，具备全面的计算机科学知识。然而，他们的主要目标是解决复杂的数据问题，这需要快速、反复试验新事物，而不是编写优雅、可重用的组件。

但我不想只是空谈，我还希望有所行动，便启动了 PixieDust 开源项目，作为我为解决这个重要问题所做的微薄贡献。随着 PixieDust 的工作进展顺利，叙述变得更加简洁易懂，开发者和数据科学家们都能为之兴奋。

当我被提供机会写一本关于这个故事的书时，由于两个主要原因，我犹豫了很久才开始这次冒险：

+   我在博客、文章和教程中广泛写过我作为数据科学从业者使用 Jupyter Notebooks 的经验。我还在各种会议中担任过演讲者和工作坊主持人。一个很好的例子是我在 2017 年的 ODSC 伦敦大会上发表的主题演讲，《数据科学的未来：少一些权力的游戏，多一些联盟》（[`odsc.com/training/portfolio/future-data-science-less-game-thrones-alliances`](https://odsc.com/training/portfolio/future-data-science-less-game-thrones-alliances)）。然而，我从未写过书，完全不知道这会是多么大的承诺，尽管许多曾经写过书的朋友多次提醒过我。

+   我希望这本书能够包容不同的读者，平等地面向开发者、数据科学家以及业务线用户，但我在寻找合适的内容和语气时感到困惑。

最终，决定踏上这段冒险之旅变得相当容易。经过两年的 PixieDust 项目工作，我觉得我们在这个项目中取得了非常好的进展，做出了许多有趣的创新，引起了开源社区的广泛关注，写一本书将会很好地补充我们在帮助开发者参与数据科学方面的倡导工作。

作为旁注，对于那些有写书打算并有类似顾虑的读者，我只能大声地建议：“是的，去做吧。”当然，这是一项需要付出巨大承诺的工作，需要大量的牺牲，但只要你有一个好的故事要讲，且内容扎实，这绝对值得付出努力。

# 本书适合谁阅读

本书将帮助有志于提升技能的初学数据科学家和开发者，或任何希望成为专业数据科学家的读者。由于书中引入了 PixieDust 的创造者，这本书还将成为已经成就非凡的数据科学家的优秀桌面伴侣。

无论个人的兴趣程度如何，简洁易读的文本和现实生活中的案例都适合那些对该领域有一般兴趣的人，因为他们可以在 Jupyter Notebooks 中运行 Python 代码进行实践。

要制作一个功能完备的 PixieDust 仪表盘，只需要掌握少量的 HTML 和 CSS。数据解读和可视化的流利性也是必不可少的，因为本书面向的数据专业人士包括商业和一般数据分析师。后面的章节也有很多内容值得学习。

# 本书内容概述

本书分为两个逻辑部分，长度大致相等。在前半部分，我阐述了本书的主题，即需要弥合数据科学与工程之间的鸿沟，详细介绍了我提出的 Jupyter + PixieDust 解决方案。后半部分则专注于将我们在前半部分学到的内容应用于四个行业案例。

第一章, *编程与数据科学——一套新工具*，在这一章中，我试图通过自己的经验来定义数据科学，建立一个对 Twitter 帖子进行情感分析的数据管道。我为这个观点辩护——数据科学是一项团队运动，通常，数据科学团队和工程团队之间存在隔阂，这会导致不必要的摩擦、低效，最终无法充分发挥其潜力。我还提出数据科学将会长期存在，并且最终它将成为今天所称计算机科学的一个组成部分（我喜欢认为，总有一天会出现一些新术语，比如*计算机数据科学*，来更好地体现这一双重性）。

第二章，*用 Python 和 Jupyter Notebooks 推动数据分析*，我开始深入探讨流行的数据科学工具，如 Python 及其专注于数据科学的开源库生态系统，当然还有 Jupyter Notebooks。我解释了为什么我认为 Jupyter Notebooks 将在未来几年成为大赢家。我还介绍了 PixieDust 开源库的功能，从简单的`display()`方法开始，用户可以通过构建引人入胜的图表，在交互式用户界面中直观地探索数据。通过此 API，用户可以选择多个渲染引擎，如 Matplotlib、Bokeh、Seaborn 和 Mapbox。`display()`功能是 PixieDust MVP（最小可行产品）中唯一的特性，但随着时间的推移，随着我与许多数据科学从业者的互动，我添加了新功能，迅速形成了 PixieDust 工具箱：

+   **sampleData()**：一个简单的 API，用于轻松地将数据加载到 pandas 和 Apache Spark 数据框中。

+   **wrangle_data()**：一个简单的 API，用于清理和处理数据集。此功能包括使用正则表达式将列拆解为新列，以提取非结构化文本中的内容。`wrangle_data()` API 还可以根据预定义的模式提供建议。

+   **包管理器**：允许用户在 Python Notebook 中安装第三方 Apache Spark 包。

+   **Scala 桥接**：使用户能够在 Python Notebook 中运行 Scala 代码。在 Python 端定义的变量可以在 Scala 中访问，反之亦然。

+   **Spark 作业进度监控**：让你通过实时进度条跟踪 Spark 作业的状态，进度条直接显示在执行代码的输出单元中。

+   **PixieApp**：提供以 HTML/CSS 为中心的编程模型，允许开发者构建复杂的仪表板，以将 Notebook 中构建的分析操作化。PixieApps 可以直接在 Jupyter Notebook 中运行，也可以使用 PixieGateway 微服务作为分析 Web 应用程序进行部署。PixieGateway 是 PixieDust 的开源配套项目。

以下图表总结了 PixieDust 的发展历程，包括最近添加的 PixieGateway 和 PixieDebugger，后者是 Jupyter Notebooks 中的第一个可视化 Python 调试器：

![本书涵盖的内容](img/B09699_preface_01.jpg)

PixieDust 历程

从本章中要记住的一个关键点是，PixieDust 首先是一个开源项目，它通过开发者社区的贡献而生生不息。与无数开源项目一样，我们可以预期 PixieDust 在未来会加入更多突破性的功能。

第三章，*使用 Python 库加速数据分析*，我将带领读者深入了解 PixieApp 编程模型，沿途通过一个分析 GitHub 数据的示例应用程序来阐明每个概念。我从 PixieApp 的基本结构入手，描述其生命周期和执行流程，并结合路由概念进行讲解。接着，我介绍开发者如何使用常规的 HTML 和 CSS 代码片段构建仪表盘的 UI，实现与分析结果的无缝交互，并利用 PixieDust 的`display()` API 添加复杂的图表。

PixieApp 编程模型是连接数据科学与工程之间的工具策略的基石，因为它简化了将分析成果转化为可操作应用的过程，从而促进了数据科学家与开发者之间的协作，并减少了应用的上市时间。

第四章，*将数据分析发布到 Web - PixieApp 工具*，我讨论了 PixieGateway 微服务，它使开发者能够将 PixieApps 发布为分析型 Web 应用程序。我首先展示了如何在本地和云端快速部署 PixieGateway 微服务实例，作为 Kubernetes 容器。然后，我介绍了 PixieGateway 管理员控制台的功能，包括各种配置文件以及如何实时监控已部署的 PixieApps 实例和相关的 Python 后端内核。我还介绍了 PixieGateway 的图表共享功能，允许用户将使用 PixieDust 的`display()` API 创建的图表转换为网页，供团队中的任何人访问。

PixieGateway 是一项突破性的创新，具有显著加速分析操作化的潜力——这是当今非常需要的——以充分实现数据科学的潜力。它代表了一个开源替代方案，可以与市场上已有的类似产品竞争，如 R-Studio 的 Shiny Server（[`shiny.rstudio.com/deploy`](https://shiny.rstudio.com/deploy)）和 Plotly 的 Dash（[`dash.plot.ly`](https://dash.plot.ly)）。

第五章，*Python 和 PixieDust 最佳实践与高级概念*，我通过深入探讨 PixieApp 编程模型的高级概念，完成了对 PixieDust 工具箱的深度剖析：

+   **@captureOutput 装饰器**：默认情况下，PixieApp 路由要求开发者提供一个将被注入到应用 UI 中的 HTML 片段。当我们想调用一个第三方 Python 库，而该库不了解 PixieApp 架构并直接生成输出到 Notebook 时，就会出现问题。`@captureOutput` 通过自动重定向第三方 Python 库生成的内容并将其封装成一个合适的 HTML 片段来解决这个问题。

+   **利用 Python 类继承提高模块化和代码重用性**：将 PixieApp 代码拆解成逻辑类，并利用 Python 类继承功能将其组合在一起。我还展示了如何通过 `pd_app` 自定义属性调用外部 PixieApp。

+   **PixieDust 对流式数据的支持**：展示了 PixieDust 的 `display()` 和 PixieApp 如何处理流式数据。

+   **通过 PixieApp 事件实现仪表盘深入分析**：提供了一种机制，让 PixieApp 组件能够发布和订阅当用户与 UI 交互时生成的事件（例如，图表和按钮）。

+   **为 PixieDust display() API 构建自定义显示渲染器**：演示了一个简单渲染器的代码，扩展了 PixieDust 菜单。该渲染器展示了一个自定义的 HTML 表格，显示所选数据。

+   **调试技巧**：介绍 PixieDust 提供的各种调试技巧，包括名为 PixieDebugger 的可视化 Python 调试器，以及用于显示 Python 日志消息的`%%PixiedustLog`魔法命令。

+   **运行 Node.js 代码的能力**：我们讨论了 `pixiedust_node` 扩展，它管理一个 Node.js 进程的生命周期，该进程负责直接从 Python Notebook 中执行任意的 Node.js 脚本。

多亏了开放源代码模型，凭借其透明的开发过程和日益增长的用户社区提供的一些宝贵反馈，我们能够随着时间的推移优先实施许多先进的功能。我想表达的关键点是，遵循一个合适的开源模型并采用适当的许可证（PixieDust 使用的是 Apache 2.0 许可证，详情请见 [`www.apache.org/licenses/LICENSE-2.0`](https://www.apache.org/licenses/LICENSE-2.0)）是非常有效的。它帮助我们壮大了用户社区，而社区又为我们提供了必要的反馈，帮助我们优先开发那些我们知道具有高价值的新特性，在某些情况下，甚至贡献了代码，形式为 GitHub 拉取请求。

第六章，*分析研究：AI 与图像识别与 TensorFlow*，我深入讲解了四个行业案例中的第一个。我从机器学习的高级介绍开始，接着介绍了深度学习——机器学习的一个子领域——以及使得构建神经网络模型更简单的 TensorFlow 框架。然后，我继续构建一个图像识别示例应用程序，并在四个部分中包括相关的 PixieApp：

+   *第一部分*：使用预训练的 ImageNet 模型构建一个图像识别的 TensorFlow 模型。通过《TensorFlow for poets》教程，我展示了如何构建分析功能来加载和评分神经网络模型。

+   *第二部分*：创建一个 PixieApp，将*第一部分*中创建的分析功能投入实际应用。这个 PixieApp 从用户提供的网页 URL 中抓取图像，将它们与 TensorFlow 模型进行评分，并以图形方式展示结果。

+   *第三部分*：我展示了如何将 TensorBoard 图形可视化组件直接集成到 Notebook 中，以提供调试神经网络模型的能力。

+   *第四部分*：我展示了如何使用自定义训练数据重新训练模型，并更新 PixieApp 以展示来自两个模型的结果。

我决定以深度学习图像识别为主题开始这一系列示例应用程序，因为这是一个日益流行的重要用例，展示了我们如何构建模型并将其部署到同一个 Notebook 中的应用程序，这一做法为弥合数据科学与工程之间的鸿沟提供了有力的支持。

第七章，*分析研究：NLP 与大数据——Twitter 情感分析*，我谈到了在 Twitter 规模上进行自然语言处理。在这一章中，我展示了如何使用 IBM Watson 自然语言理解的云服务对推文进行情感分析。这一点非常重要，因为它提醒读者，有时候复用托管服务而不是自己构建能力，可能是一个更具吸引力的选择。

我首先介绍了 Apache Spark 并行计算框架，然后分四部分开始构建应用程序：

+   *第一部分*：使用 Spark 结构化流处理获取 Twitter 数据。

+   *第二部分*：通过提取文本中的情感和最相关的实体来丰富数据。

+   *第三部分*：通过创建一个实时仪表盘 PixieApp 来实现分析功能。

+   *第四部分*：这是一个可选部分，重新实现该应用程序，使用 Apache Kafka 和 IBM Streaming Designer 托管服务，展示如何提高可扩展性。

我认为读者，尤其是那些不熟悉 Apache Spark 的读者，会喜欢这一章，因为它比前一章稍微容易跟随。关键的收获是如何构建可扩展的分析，利用连接到 Spark 集群的 Jupyter Notebooks。

第八章，*分析研究：预测 - 财务时间序列分析与预测*，我谈到了时间序列分析，这是数据科学中一个非常重要的领域，在工业界有许多实际应用。我从深入探讨 NumPy 库开始，NumPy 是许多其他库（如 pandas 和 SciPy）的基础。接着，我开始构建示例应用程序，分析一个由历史股票数据组成的时间序列，分为两个部分：

+   *第一部分*：提供了时间序列的统计探索，包括各种图表，如自相关函数（ACF）和偏自相关函数（PACF）。

+   *第二部分*：基于 ARIMA 算法使用 `statsmodels` Python 库构建预测模型。

时间序列分析是数据科学中一个非常重要的领域，我认为它被低估了。在写这章时，我个人学到了很多东西。我真心希望读者也能喜欢它，并且阅读它能够激发对这个伟大主题的兴趣。如果真是这样，我也希望你会被说服，尝试在下次学习时间序列分析时使用 Jupyter 和 PixieDust。

第九章，*分析研究：图算法 - 美国国内航班数据分析*，我通过研究图形算法来完成这一系列的行业应用案例。我选择了一个分析航班延误的示例应用程序，因为数据是现成的，而且非常适合使用图算法（老实说，我也可能是因为我已经写过一个类似的应用程序，基于天气数据预测航班延误，那个应用程序使用了 Apache Spark MLlib：[`developer.ibm.com/clouddataservices/2016/08/04/predict-flight-delays-with-apache-spark-mllib-flightstats-and-weather-data`](https://developer.ibm.com/clouddataservices/2016/08/04/predict-flight-delays-with-apache-spark-mllib-flightstats-and-weather-data)）。

我首先介绍了图形及其相关的图算法，包括一些最流行的图算法，如广度优先搜索（Breadth First Search）和深度优先搜索（Depth First Search）。接着，我介绍了用于构建示例应用程序的 `networkx` Python 库。

该应用程序由四个部分组成：

+   *第一部分*：展示了如何将美国国内航班数据加载到图中。

+   *第二部分*：创建 `USFlightsAnalysis` PixieApp，允许用户选择起点和目的地机场，然后根据选定的中心性展示两机场之间的最短路径的 Mapbox 地图。

+   *第三部分*：为 PixieApp 添加数据探索功能，包括针对每个航司的各种统计数据，统计的是从所选起点机场起飞的航班。

+   *第四部分*：使用在第八章，*分析学习：预测 – 财务时间序列分析与预测* 中学到的技术，构建一个 ARIMA 模型来预测航班延误。

图论也是数据科学中一个重要且不断发展的领域，本章很好地总结了这一系列内容，我希望它提供了一个多样且具有代表性的行业案例集。对于那些特别感兴趣于使用图算法处理大数据的读者，我建议查看 Apache Spark GraphX ([`spark.apache.org/graphx`](https://spark.apache.org/graphx))，它通过一个非常灵活的 API 实现了许多图算法。

第十章，*数据分析的未来及如何发展你的技能*，我通过简要总结并解释 Drew Conway 的 Venn 图来结束本书。接着我会谈到人工智能和数据科学的未来，以及公司如何为人工智能和数据科学的革命做好准备。此外，我还列出了一些有助于进一步学习的优秀参考资料。

附录，*PixieApp 快速参考*，是为开发者提供的快速参考指南，概述了所有 PixieApp 属性。这本指南通过适当的示例解释了各种注释、自定义 HTML 属性和方法。

但介绍部分说得够多了：让我们从第一章开始，标题为 *编程与数据科学 – 新工具集*。

# 为了最大程度地从本书中受益

+   大部分跟随本书示例所需的软件是开源的，因此可以免费下载安装。书中提供了详细的安装说明，首先从安装 Anaconda 开始，Anaconda 包含了 Jupyter Notebook 服务器。

+   在第七章，*分析学习：NLP 和大数据与 Twitter 情感分析*，示例应用程序需要使用 IBM Watson 云服务，包括 NLU 和 Streams Designer。这些服务提供免费的计划层，足以让你跟随本书的示例。

## 下载示例代码文件

你可以从 [`www.packtpub.com`](http://www.packtpub.com) 账户下载本书的示例代码文件。如果你是从其他地方购买的这本书，可以访问 [`www.packtpub.com/support`](http://www.packtpub.com/support)，注册后文件会直接通过电子邮件发送给你。

你可以按照以下步骤下载代码文件：

1.  登录或注册 [`www.packtpub.com`](http://www.packtpub.com)

1.  选择**支持**标签。

1.  点击**代码下载与勘误**。

1.  在**搜索**框中输入书名，并按照屏幕上的指示操作。

一旦文件下载完成，请确保使用以下最新版本解压或提取文件夹：

+   Windows 版 WinRAR / 7-Zip

+   Mac 版 Zipeg / iZip / UnRarX

+   Linux 版 7-Zip / PeaZip

本书的代码包也托管在 GitHub 上，地址是[`github.com/PacktPublishing/Thoughtful-Data-Science`](https://github.com/PacktPublishing/Thoughtful-Data-Science)。我们还有其他来自丰富书籍和视频目录的代码包，地址是[`github.com/PacktPublishing/`](https://github.com/PacktPublishing/)。快来看看吧！

## 下载彩色图片

我们还提供了一个 PDF 文件，里面有本书中使用的截图/图表的彩色图片。你可以在这里下载：[`www.packtpub.com/sites/default/files/downloads/ThoughtfulDataScience_ColorImages.pdf`](http://www.packtpub.com/sites/default/files/downloads/ThoughtfulDataScience_ColorImages.pdf)。

## 使用的约定

本书中使用了多种文本约定。

`CodeInText`：表示文本中的代码字、数据库表名、文件夹名、文件名、文件扩展名、路径名、虚拟 URL、用户输入和 Twitter 用户名。例如：“你可以使用`{%if ...%}...{%elif ...%}...{%else%}…{%endif%}`符号来有条件地输出文本。”

代码块的格式如下：

```py
import pandas
data_url = "https://data.cityofnewyork.us/api/views/e98g-f8hy/rows.csv?accessType=DOWNLOAD"
building_df = pandas.read_csv(data_url)
building_df
```

当我们希望特别提醒你注意代码块中的某一部分时，相关行或项会以粗体显示：

```py
import pandas
data_url = "https://data.cityofnewyork.us/api/views/e98g-f8hy/rows.csv?accessType=DOWNLOAD"
building_df = pandas.read_csv(data_url)
building_df
```

任何命令行输入或输出都如下所示：

```py
jupyter notebook --generate-config

```

**粗体**：表示一个新术语、重要词汇或你在屏幕上看到的词汇，例如在菜单或对话框中，也会在文本中像这样出现。例如：“下一步是创建一个新的路由，该路由接受用户值并返回结果。这个路由将通过**提交查询**按钮触发。”

### 注意

警告或重要提示如下所示。

### 提示

提示和技巧如下所示。

# 联系我们

我们非常欢迎读者的反馈。

**一般反馈**：电子邮件`<feedback@packtpub.com>`，并在邮件主题中提到书籍的标题。如果你有关于本书的任何问题，请通过电子邮件联系我们`<questions@packtpub.com>`。

**勘误**：尽管我们已尽一切努力确保内容的准确性，但错误仍然可能发生。如果你在本书中发现错误，我们将非常感激你能报告给我们。请访问[`www.packtpub.com/submit-errata`](http://www.packtpub.com/submit-errata)，选择你的书籍，点击**勘误提交表单**链接，输入相关细节。

**盗版**：如果您在互联网上发现任何形式的非法复制我们作品的情况，我们将非常感激您能提供该材料的地址或网站名称。请通过`<copyright@packtpub.com>`与我们联系，并附上相关链接。

**如果您有兴趣成为作者**：如果您在某个领域有专长，并且有兴趣写书或为书籍贡献内容，请访问 [`authors.packtpub.com`](http://authors.packtpub.com)。

## 评论

请留下评论。在阅读和使用本书后，为什么不在您购买它的网站上留下评论呢？潜在的读者可以看到并参考您的客观意见来做出购买决策，我们在 Packt 也能了解您对我们产品的看法，作者们也能看到您对他们书籍的反馈。谢谢！

欲了解更多关于 Packt 的信息，请访问 [packtpub.com](http://packtpub.com)。
