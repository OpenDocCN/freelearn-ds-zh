# 第一章：算法概述

本书涵盖了理解、分类、选择和实施重要算法所需的信息。除了解释它们的逻辑之外，本书还讨论了适用于不同类算法的数据结构、开发环境和生产环境。我们专注于越来越重要的现代机器学习算法。除了逻辑之外，还提供了算法实际解决日常问题的实际示例。

本章介绍了算法基础知识。它从需要理解不同算法工作原理的基本概念开始。本节总结了人们如何开始使用算法来数学表达某一类问题，并提到了不同算法的局限性。接下来的部分解释了指定算法逻辑的各种方法。由于本书使用 Python 编写算法，因此解释了如何设置环境来运行示例。然后，讨论了算法性能可以如何量化并与其他算法进行比较的各种方法。最后，本章讨论了验证算法特定实现的各种方法。

总之，本章涵盖了以下主要内容：

+   什么是算法？

+   指定算法的逻辑

+   介绍 Python 包

+   算法设计技术

+   性能分析

+   验证算法

# 什么是算法？

简单来说，算法是一组用于解决问题的计算规则。它旨在根据精确定义的指令为任何有效输入产生结果。如果您在英语词典（如美国传统）中查找算法一词，它定义了以下概念：

“算法是一组明确的指令，给定一些初始条件，可以按照规定的顺序执行，以达到某个目标，并具有可识别的一组结束条件。”

设计算法是创建数学配方的努力，以最有效的方式解决现实世界的问题。这个配方可以作为开发更可重用和通用的数学解决方案的基础，可以应用于更广泛的类似问题集。

# 算法的阶段

以下图表说明了开发、部署和最终使用算法的不同阶段：

![](img/c355481f-a903-437d-b3af-55bc3f84c8c1.png)

正如我们所看到的，这个过程始于理解问题陈述中的需求，详细说明了需要做什么。一旦问题清晰陈述，就会引导我们进入开发阶段。

开发阶段包括两个阶段：

+   **设计阶段**：在设计阶段，算法的架构、逻辑和实现细节被构想和记录下来。在设计算法时，我们同时考虑准确性和性能。在寻找给定问题的解决方案时，在许多情况下，我们会得到多个备选算法。算法的设计阶段是一个迭代过程，涉及比较不同的候选算法。一些算法可能提供简单快速的解决方案，但可能会牺牲准确性。其他算法可能非常准确，但由于复杂性需要花费相当长的时间来运行。其中一些复杂算法可能比其他算法更有效。在做出选择之前，应仔细研究候选算法的所有固有权衡。特别是对于复杂问题，设计高效的算法非常重要。正确设计的算法将导致有效的解决方案，能够同时提供令人满意的性能和合理的准确性。

+   **编码阶段**：在编码阶段，设计的算法被转换为计算机程序。实际程序实现设计阶段建议的所有逻辑和架构是很重要的。

算法的设计和编码阶段是迭代的。设计满足功能和非功能需求的设计可能需要大量的时间和精力。功能需求是指定给定输入数据的正确输出是什么的要求。算法的非功能需求主要是关于给定数据大小的性能。算法的验证和性能分析将在本章后面讨论。验证算法是验证算法是否满足其功能需求。算法的性能分析是验证它是否满足其主要的非功能需求：性能。

一旦设计并在您选择的编程语言中实现，算法的代码就可以部署了。部署算法涉及设计实际的生产环境，代码将在其中运行。生产环境需要根据算法的数据和处理需求进行设计。例如，对于可并行化的算法，需要具有适当数量的计算节点的集群，以便有效地执行算法。对于数据密集型算法，可能需要设计数据进入管道和缓存和存储数据的策略。生产环境的设计将在第十三章“大规模算法”和第十四章“实际考虑”中更详细地讨论。一旦设计并实施了生产环境，算法就可以部署，它将接受输入数据，处理它，并根据要求生成输出。

# 指定算法的逻辑

在设计算法时，重要的是找到不同的方式来指定其细节。需要能够捕捉其逻辑和架构。通常，就像建造房屋一样，在实际实施算法之前，指定算法的结构是很重要的。对于更复杂的分布式算法，预先规划它们的逻辑在运行时如何分布在集群中对于迭代式高效设计过程是重要的。通过伪代码和执行计划，这两个需求都得到满足，并将在下一节中讨论。

# 理解伪代码

指定算法逻辑的最简单方法是以半结构化方式编写算法的高级描述，称为**伪代码**。在用伪代码编写逻辑之前，首先描述其主要流程并用简单的英语写出主要步骤是有帮助的。然后，将这个英语描述转换成伪代码，这是一种以结构化方式编写这个英语描述的方法，它紧密地代表了算法的逻辑和流程。良好编写的算法伪代码应该以合理的细节描述算法的高级步骤，即使详细的代码与主要流程和结构无关。下图显示了步骤的流程：

伪代码的一个实际例子

请注意，一旦编写了伪代码（如我们将在下一节中看到的），我们就可以使用我们选择的编程语言编写算法代码了。

# ![](img/fd17310d-27ab-49b0-8620-05e4021a34e8.png)

图 1.3 显示了一个名为**SRPMP**的资源分配算法的伪代码。在集群计算中，有许多情况需要在一组可用资源上运行并行任务，统称为**资源池**。这个算法将任务分配给一个资源，并创建一个称为`Ω`的映射集。请注意，所呈现的伪代码捕捉了算法的逻辑和流程，这在下一节中进一步解释：

```py
1: BEGIN Mapping_Phase
2: Ω = { }
3: k = 1
4: FOREACH Ti∈T
5:     ωi = RA(Δk,Ti)
6:     add {ωi,Ti} to Ω
7:     state_changeTi [STATE 0: Idle/Unmapped] → [STATE 1: Idle/Mapped]
8:     k=k+1
9:     IF (k>q)
10:       k=1
11:    ENDIF
12: END FOREACH
13: END Mapping_Phase
```

让我们逐行解析这个算法：

1.  我们通过执行算法开始映射。`Ω`映射集是空的。

1.  第一个分区被选为`T[1]`任务的资源池（参见前面代码的第 3 行）。**电视收视率**（**TRPS**）迭代地调用**类风湿性关节炎**（**RA**）算法，对于每个`T[i]`任务，选择一个分区作为资源池。

1.  RA 算法返回为`T[i]`任务选择的资源集，由`ω[i]`表示（参见前面代码的第 5 行）。

1.  `T[i]`和`ω[i]`被添加到映射集中（参见前面代码的第 6 行）。

1.  `T[i]`的状态从`STATE 0:Idle/Mapping`更改为`STATE 1:Idle/Mapped`（参见前面代码的第 7 行）。

1.  请注意，对于第一次迭代，`k=1`，并且选择了第一个分区。对于每个后续迭代，`k`的值增加，直到`k>q`。

1.  如果`k`变得大于`q`，它会再次重置为`1`（参见前面代码的第 9 和第 10 行）。

1.  这个过程重复进行，直到确定并存储了所有任务与它们将使用的资源集之间的映射，并存储在一个称为`Ω`的映射集中。

1.  一旦每个任务在映射阶段映射到一组资源中，它就会被执行。

# 使用片段

随着 Python 等简单但功能强大的编程语言的流行，另一种替代方法变得流行，即直接用编程语言表示算法的逻辑，以一种简化的方式。与伪代码一样，这个选定的代码捕捉了所提出的算法的重要逻辑和结构，避免了详细的代码。这个选定的代码有时被称为**片段**。在本书中，尽可能使用片段代替伪代码，因为它们节省了一个额外的步骤。例如，让我们看一个简单的片段，它是一个关于可以用来交换两个变量的 Python 函数的片段：

```py
define swap(x, y)
    buffer = x
    x = y
    y = buffer
```

请注意，片段并不能总是替代伪代码。在伪代码中，有时我们将许多行代码抽象为一行伪代码，表达算法的逻辑，而不会被不必要的编码细节分散注意力。

# 创建执行计划

伪代码和片段并不总是足以指定与更复杂的分布式算法相关的所有逻辑。例如，分布式算法通常需要在运行时分成不同的编码阶段，这些阶段具有优先顺序。将较大的问题划分为最佳数量的阶段，并具有正确的优先约束条件的正确策略对于有效执行算法至关重要。

我们需要找到一种方法来表示这种策略，以完全表示算法的逻辑和结构。执行计划是详细说明算法将如何被细分为一堆任务的一种方式。一个任务可以是映射器或减速器，可以被分组在称为**阶段**的块中。下图显示了在执行算法之前由 Apache Spark 运行时生成的执行计划。它详细说明了作业为执行我们的算法创建的运行时任务将被分成：

![](img/c2519fcc-2e00-4c7d-948f-a25853e3d835.png)

请注意，前面的图表有五个任务，它们被分成了两个不同的阶段：阶段 11 和阶段 12。

# 引入 Python 包

一旦设计好算法，就需要根据设计在编程语言中实现。对于本书，我选择了编程语言 Python。我选择它是因为 Python 是一种灵活的开源编程语言。Python 也是越来越重要的云计算基础设施的首选语言，如**亚马逊网络服务**（**AWS**）、微软 Azure 和**谷歌云平台**（**GCP**）。

官方 Python 主页可在[`www.python.org/`](https://www.python.org/)找到，其中还有安装说明和有用的初学者指南。

如果您以前没有使用过 Python，浏览这本初学者指南是一个好主意。对 Python 的基本理解将有助于您更好地理解本书中提出的概念。

对于本书，我希望您使用最新版本的 Python 3。在撰写本文时，最新版本是 3.7.3，这是我们将用来运行本书中的练习的版本。

# Python 软件包

Python 是一种通用语言。它设计成具有最基本的功能。根据您打算使用 Python 的用例，需要安装额外的软件包。安装额外软件包的最简单方法是通过 pip 安装程序。这个`pip`命令可以用来安装额外的软件包：

```py
pip install a_package
```

已安装的软件包需要定期更新以获得最新功能。这可以通过使用`upgrade`标志来实现：

```py
pip install a_package --upgrade
```

用于科学计算的另一个 Python 发行版是 Anaconda，可以从[`continuum.io/downloads`](http://continuum.io/downloads)下载。

除了使用`pip`命令安装新软件包外，对于 Anaconda 发行版，我们还可以使用以下命令来安装新软件包：

```py
conda install a_package
```

要更新现有的软件包，Anaconda 发行版提供了以下命令选项：

```py
conda update a_package
```

有各种各样的 Python 软件包可用。一些与算法相关的重要软件包在以下部分中进行了描述。

# SciPy 生态系统

科学 Python（SciPy）——发音为*sigh pie*——是为科学界创建的一组 Python 软件包。它包含许多函数，包括各种随机数生成器、线性代数例程和优化器。SciPy 是一个综合性的软件包，随着时间的推移，人们开发了许多扩展来根据自己的需求定制和扩展软件包。

以下是该生态系统的主要软件包：

+   **NumPy**：对于算法来说，创建多维数据结构（如数组和矩阵）的能力非常重要。NumPy 提供了一组重要的用于统计和数据分析的数组和矩阵数据类型。有关 NumPy 的详细信息可以在[`www.numpy.org/`](http://www.numpy.org/)找到。

+   **scikit-learn**：这个机器学习扩展是 SciPy 最受欢迎的扩展之一。Scikit-learn 提供了一系列重要的机器学习算法，包括分类、回归、聚类和模型验证。您可以在[`scikit-learn.org/`](http://scikit-learn.org/)找到有关 scikit-learn 的更多详细信息。

+   **pandas**：pandas 是一个开源软件库。它包含了广泛用于输入、输出和处理表格数据的表格复杂数据结构。pandas 库包含许多有用的函数，还提供了高度优化的性能。有关 pandas 的更多详细信息可以在[`pandas.pydata.org/`](http://pandas.pydata.org/)找到。

+   **Matplotlib**：Matplotlib 提供了创建强大可视化的工具。数据可以呈现为折线图、散点图、条形图、直方图、饼图等。更多信息可以在[`matplotlib.org/`](https://matplotlib.org/)找到。

+   **Seaborn**：Seaborn 可以被认为类似于 R 中流行的 ggplot2 库。它基于 Matplotlib，并提供了一个高级接口来绘制出色的统计图形。更多细节可以在[`seaborn.pydata.org/`](https://seaborn.pydata.org/)找到。

+   **iPython**：iPython 是一个增强的交互式控制台，旨在促进编写，测试和调试 Python 代码。

+   **运行 Python 程序**：交互式编程模式对于学习和实验代码非常有用。 Python 程序可以保存在带有`.py`扩展名的文本文件中，并且可以从控制台运行该文件。

# 通过 Jupyter Notebook 实现 Python

通过 Jupyter Notebook 运行 Python 程序的另一种方式。 Jupyter Notebook 提供了基于浏览器的用户界面来开发代码。 Jupyter Notebook 用于在本书中展示代码示例。 用文本和图形注释和描述代码的能力使其成为呈现和解释算法的完美工具，也是学习的好工具。

要启动笔记本，您需要启动`Juypter-notebook`进程，然后打开您喜欢的浏览器并导航到`http://localhost:8888`：

![](img/3667b86b-2e9a-4e5c-a3f4-8b4da8372dae.png)

请注意，Jupyter Notebook 由称为**单元格**的不同块组成。

# 算法设计技术

算法是对现实世界问题的数学解决方案。在设计算法时，我们在设计和微调算法时牢记以下三个设计关注点：

+   **关注 1**：这个算法是否产生了我们预期的结果？

+   **关注 2**：这是获得这些结果的最佳方式吗？

+   **关注 3**：算法在更大的数据集上的表现如何？

在设计解决方案之前更好地了解问题本身的复杂性是很重要的。例如，如果我们根据需求和复杂性对问题进行表征，这有助于我们设计适当的解决方案。通常，根据问题的特征，算法可以分为以下类型：

+   **数据密集型算法**：数据密集型算法旨在处理大量数据。预计它们具有相对简单的处理要求。应用于大型文件的压缩算法是数据密集型算法的一个很好的例子。对于这样的算法，数据的大小预计会远大于处理引擎（单个节点或集群）的内存，并且可能需要开发迭代处理设计以根据要求高效处理数据。

+   **计算密集型算法**：计算密集型算法具有相当大的处理需求，但不涉及大量数据。一个简单的例子是查找非常大的质数的算法。找到将算法分成不同阶段的策略，以便至少有一些阶段是并行化的，是最大化算法性能的关键。

+   **数据和计算密集型算法**：有些算法处理大量数据，并且具有相当大的计算需求。用于对实时视频流执行情感分析的算法是处理任务中数据和处理要求都很大的很好的例子。这些算法是最资源密集的算法，需要仔细设计算法并智能分配可用资源。

为了更深入地研究问题的复杂性和需求，有助于我们研究其数据并计算更深入的维度，这将在下一节中进行。

# 数据维度

为了对问题的数据维度进行分类，我们看看其**体积**，**速度**和**多样性**（**3V**），其定义如下：

+   **体积**：体积是算法将处理的数据的预期大小。

+   **速度**：速度是在使用算法时预期的新数据生成速率。它可以为零。

+   **多样性**：多样性量化了设计的算法预计要处理多少不同类型的数据。

下图更详细地显示了数据的 3Vs。这个图的中心显示了最简单的数据，体积小，多样性和速度低。当我们远离中心时，数据的复杂性增加。它可以在三个维度中的一个或多个维度上增加。例如，在速度维度上，我们有批处理作为最简单的，然后是周期性处理，然后是准实时处理。最后，我们有实时处理，在数据速度的背景下处理起来最复杂。例如，由一组监控摄像头收集的实时视频流将具有高体积、高速度和高多样性，并且可能需要适当的设计来有效地存储和处理数据。另一方面，一个在 Excel 中创建的简单`.csv`文件将具有低体积、低速度和低多样性：

![](img/7a6d1af7-5c9b-448c-a5b6-c6ef6b299db5.png)

例如，如果输入数据是一个简单的`csv`文件，那么数据的体积、速度和多样性将很低。另一方面，如果输入数据是安全视频摄像头的实时视频流，那么数据的体积、速度和多样性将会很高，这个问题在设计算法时应该牢记在心。

# 计算维度

计算维度是关于问题处理和计算需求的。算法的处理需求将决定最有效的设计是什么样的。例如，深度学习算法通常需要大量的处理能力。这意味着对于深度学习算法，尽可能拥有多节点并行架构是很重要的。

# 一个实际的例子

假设我们想对一个视频进行情感分析。情感分析是指我们试图标记视频中不同部分的人类情感，如悲伤、快乐、恐惧、喜悦、挫折和狂喜。这是一个计算密集型的工作，需要大量的计算能力。正如你将在下图中看到的，为了设计计算维度，我们将处理分为五个任务，包括两个阶段。所有的数据转换和准备都是在三个 mapper 中实现的。为此，我们将视频分成三个不同的分区，称为**拆分**。在 mapper 执行完毕后，处理后的视频输入到两个聚合器，称为**reducer**。为了进行所需的情感分析，reducer 根据情感对视频进行分组。最后，结果在输出中合并。

![](img/e48c6ab1-cc03-463a-a759-a5ad2f48442f.png)请注意，mapper 的数量直接影响算法的运行并行性。最佳的 mapper 和 reducer 数量取决于数据的特性、需要使用的算法类型以及可用资源的数量。

# 性能分析

分析算法的性能是设计的重要部分。估计算法性能的一种方法是分析其复杂性。

复杂性理论是研究复杂算法的学科。为了有用，任何算法都应该具有三个关键特征：

+   应该是正确的。如果算法不能给出正确的答案，那么它对你来说没有太大的好处。

+   一个好的算法应该是可以理解的。即使是世界上最好的算法，如果对你来说太复杂而无法在计算机上实现，那也没有什么好处。

+   一个好的算法应该是高效的。即使一个算法产生了正确的结果，如果它需要花费一千年或者需要十亿太字节的内存，也不会对你有太大帮助。

算法复杂度的两种可能的分析类型：

+   空间复杂度分析：估计执行算法所需的运行时内存需求。

+   时间复杂度分析：估计算法运行所需的时间。

# 空间复杂度分析

空间复杂度分析估计算法处理输入数据所需的内存量。在处理输入数据时，算法需要将瞬态临时数据结构存储在内存中。算法的设计方式会影响这些数据结构的数量、类型和大小。在分布式计算时代，需要处理越来越多的数据，空间复杂度分析变得越来越重要。这些数据结构的大小、类型和数量将决定底层硬件的内存需求。在分布式计算中使用的现代内存数据结构，如弹性分布式数据集（RDD），需要具有高效的资源分配机制，以便在算法的不同执行阶段了解内存需求。

空间复杂度分析是算法高效设计的必要条件。如果在设计特定算法时没有进行适当的空间复杂度分析，那么对于瞬态临时数据结构的内存可用性不足可能会触发不必要的磁盘溢出，这可能会显著影响算法的性能和效率。

在本章中，我们将更深入地研究时间复杂度。空间复杂度将在第十三章《大规模算法》中更详细地讨论，那里我们将处理具有复杂运行时内存需求的大规模分布式算法。

# 时间复杂度分析

时间复杂度分析估计算法基于其结构完成其分配工作所需的时间。与空间复杂度相比，时间复杂度不依赖于算法将在其上运行的任何硬件。时间复杂度分析仅仅取决于算法本身的结构。时间复杂度分析的总体目标是尝试回答这些重要问题——这个算法是否可扩展？这个算法将如何处理更大的数据集？

为了回答这些问题，我们需要确定算法在数据规模增大时对性能的影响，并确保算法不仅准确而且能够良好扩展。在当今“大数据”世界中，算法的性能对于更大的数据集变得越来越重要。

在许多情况下，我们可能有多种方法来设计算法。在这种情况下进行时间复杂度分析的目标将是：

“对于一个特定的问题和多个算法，哪一个在时间效率上最有效？”

计算算法时间复杂度的基本方法有两种：

+   后实现的分析方法：在这种方法中，实现不同的候选算法并比较它们的性能。

+   预实现的理论方法：在运行算法之前，通过数学近似来估计每个算法的性能。

理论方法的优势在于它仅仅取决于算法本身的结构。它不依赖于实际用于运行算法的硬件、运行时选择的软件栈的选择，或者用于实现算法的编程语言。

# 性能估计

典型算法的性能将取决于输入的数据类型。例如，如果数据已根据我们试图解决的问题的上下文进行了排序，算法可能会执行得非常快。如果排序后的输入用于基准测试这个特定的算法，那么它将给出一个不真实的良好性能数字，这不会真实反映其在大多数情况下的真实性能。为了处理算法对输入数据的依赖性，我们在进行性能分析时需要考虑不同类型的情况。

# 最佳情况

在最佳情况下，输入的数据组织方式使得算法能够发挥最佳性能。最佳情况分析给出了算法性能的上限。

# 最坏情况

估计算法性能的第二种方法是尝试找到在给定一组条件下完成工作所需的最长时间。算法的最坏情况分析非常有用，因为我们保证无论条件如何，算法的性能始终优于我们分析出来的数字。最坏情况分析在处理具有更大数据集的复杂问题时特别有用。最坏情况分析给出了算法性能的下限。

# 平均情况

这从将各种可能的输入分成各种组开始。然后，从每个组的一个代表性输入进行性能分析。最后，计算每个组的性能的平均值。

平均情况分析并不总是准确的，因为它需要考虑算法的所有不同组合和可能性，这并不总是容易做到。

# 选择算法

你怎么知道哪一个是更好的解决方案？你怎么知道哪个算法运行得更快？时间复杂度和大 O 符号（本章后面讨论）是回答这些问题的非常好的工具。

要看它在哪里有用，让我们举一个简单的例子，目标是对一组数字进行排序。有几种可用的算法可以完成这项工作。问题是如何选择正确的算法。

首先，可以观察到的一点是，如果列表中的数字不太多，那么我们选择哪种算法来对数字列表进行排序就无关紧要。因此，如果列表中只有 10 个数字（n=10），那么我们选择哪种算法都无关紧要，因为即使是设计非常糟糕的算法，也可能不会花费超过几微秒的时间。但是一旦列表的大小变成 100 万，现在选择正确的算法将会有所不同。一个非常糟糕的算法甚至可能需要几个小时才能运行，而一个设计良好的算法可能在几秒内完成对列表的排序。因此，对于更大的输入数据集，投入时间和精力进行性能分析，并选择正确设计的算法来高效地完成所需的工作是非常有意义的。

# 大 O 符号

大 O 符号用于量化各种算法的性能，随着输入规模的增长。大 O 符号是进行最坏情况分析的最流行方法之一。本节讨论了不同类型的大 O 符号。

# 常数时间（O(1)）复杂度

如果一个算法在运行时所需的时间与输入数据的大小无关，那么它被称为以常数时间运行。它用 O(1)表示。让我们以访问数组的第 n 个元素为例。无论数组的大小如何，获取结果都需要恒定的时间。例如，以下函数将返回数组的第一个元素，并具有 O(1)的复杂度：

```py
def getFirst(myList):
    return myList[0]
```

输出如下：

![](img/19c85f2d-d972-49ae-b098-b3dfd012daeb.png)

+   通过使用`push`添加新元素到栈或使用`pop`从栈中移除元素。无论栈的大小如何，添加或移除元素都需要相同的时间。

+   访问哈希表的元素（如第二章中讨论的，*算法中使用的数据结构*）。

+   桶排序（如第二章中讨论的，*算法中使用的数据结构*）。

# 线性时间（O(n)）复杂度

如果执行时间与输入大小成正比，则称算法具有线性时间复杂度，表示为 O(n)。一个简单的例子是在单维数据结构中添加元素：

```py
def getSum(myList):
    sum = 0
    for item in myList:
        sum = sum + item
    return sum
```

请注意算法的主循环。主循环中的迭代次数随着*n*的增加而线性增加，产生了下图中的 O(n)复杂度：

![](img/dd689660-a215-40e7-b5ed-3af5bddf280b.png)

数组操作的其他一些例子如下：

+   搜索一个元素

+   在数组的所有元素中找到最小值

# 二次时间（O(n²)）复杂度

如果算法的执行时间与输入大小的平方成正比，则称算法具有二次时间复杂度；例如，一个简单的函数对二维数组求和如下：

```py
def getSum(myList):
    sum = 0
    for row in myList:
        for item in row:
            sum += item
    return sum
```

请注意主循环内嵌在另一个主循环中。这个嵌套循环使得前面的代码具有 O(n²)的复杂度：

![](img/68f8522f-353e-4392-a9d6-fe0d8f1fe69d.png)

另一个例子是**冒泡排序算法**（如第二章中讨论的，*算法中使用的数据结构*）。

# 对数时间（O(logn)）复杂度

如果算法的执行时间与输入大小的对数成正比，则称算法具有对数时间复杂度。每次迭代，输入大小都会以一个常数倍数因子减少。对数的一个例子是二分搜索。二分搜索算法用于在一维数据结构中查找特定元素，例如 Python 列表。数据结构中的元素需要按降序排序。二分搜索算法在名为`searchBinary`的函数中实现，如下所示：

```py
def searchBinary(myList,item):
    first = 0
    last = len(myList)-1
    foundFlag = False
    while( first<=last and not foundFlag):
        mid = (first + last)//2
        if myList[mid] == item :
            foundFlag = True
        else:
            if item < myList[mid]:
                last = mid - 1
            else:
                first = mid + 1
    return foundFlag
```

主循环利用列表有序的事实。它每次迭代将列表分成一半，直到得到结果：

![](img/91156654-6969-48d8-bc16-3a45a8c3599e.png)

在定义函数之后，测试了在第 11 和 12 行搜索特定元素。二分搜索算法在第三章中进一步讨论，*排序和搜索算法*。

请注意，在所提出的四种大 O 符号类型中，O(n²)的性能最差，O(logn)的性能最佳。事实上，O(logn)的性能可以被视为任何算法性能的黄金标准（尽管并非总是实现）。另一方面，O(n²)并不像 O(n³)那么糟糕，但是仍然，属于这一类的算法不能用于大数据，因为时间复杂度对它们能够实际处理的数据量施加了限制。

减少算法复杂度的一种方法是在准确性上做出妥协，产生一种称为**近似算法**的算法类型。

算法性能评估的整个过程是迭代的，如下图所示：

![](img/36636001-28f6-4df4-8df5-2f6b12926599.png)

# 验证算法

验证算法确认它实际上为我们尝试解决的问题提供了数学解决方案。验证过程应该检查尽可能多的可能值和输入值类型的结果。

# 精确、近似和随机算法

验证算法还取决于算法的类型，因为测试技术是不同的。让我们首先区分确定性和随机算法。

对于确定性算法，特定输入总是生成完全相同的输出。但对于某些类别的算法，随机数序列也被视为输入，这使得每次运行算法时输出都不同。详见第六章中详细介绍的 k 均值聚类算法，*无监督机器学习算法*，就是这种算法的一个例子：

![](img/2241208c-9116-4716-bcfd-c46eae124ede.png)

根据用于简化逻辑以使其运行更快的假设或近似，算法也可以分为以下两种类型：

+   一种精确算法：精确算法预计能够在不引入任何假设或近似的情况下产生精确解决方案。

+   一种近似算法：当问题复杂度对于给定资源来说太大而难以处理时，我们通过做一些假设来简化问题。基于这些简化或假设的算法称为近似算法，它并不能给出精确解决方案。

让我们看一个例子来理解精确和近似算法之间的区别——著名的旅行推销员问题，它是在 1930 年提出的。一个旅行推销员向你挑战，要求你找到一名特定推销员访问每个城市（从城市列表中）并返回原点的最短路线。首次尝试提供解决方案将包括生成所有城市的排列并选择最便宜的城市组合。这种方法提供解决方案的复杂度是 O(n!)，其中*n*是城市的数量。显然，随着城市数量的增加，时间复杂度开始变得难以管理。

如果城市数量超过 30 个，减少复杂性的一种方法是引入一些近似和假设。

对于近似算法，在收集要求时设定准确性期望是很重要的。验证近似算法是为了验证结果的误差是否在可接受范围内。

# 可解释性

当算法用于关键情况时，有必要能够在需要时解释每个结果背后的原因。这是为了确保基于算法结果的决策不会引入偏见。

能够准确识别直接或间接用于做出特定决策的特征的能力被称为算法的“可解释性”。当算法用于关键用例时，需要对偏见和成见进行评估。算法的伦理分析已成为对可能影响与人们生活相关的决策的算法进行验证的标准部分。

对于处理深度学习的算法，解释性很难实现。例如，如果算法用于拒绝某人的抵押贷款申请，具有透明度和解释原因的能力就很重要。

算法的可解释性是一个活跃的研究领域。最近开发的一种有效技术是**局部可解释模型无关解释**（**LIME**），该技术是在 2016 年的第 22 届**计算机协会**（**ACM**）**知识发现和数据挖掘专业兴趣小组**（**SIGKDD**）国际会议上提出的。LIME 基于一个概念，即对每个实例的输入进行小的改变，然后努力绘制该实例的局部决策边界。它可以量化每个变量对该实例的影响。

# 摘要

这一章是关于学习算法的基础知识。首先，我们学习了开发算法的不同阶段。我们讨论了指定算法逻辑的不同方式，这对于设计算法是必要的。然后，我们看了如何设计算法。我们学会了分析算法性能的两种不同方式。最后，我们研究了验证算法的不同方面。

经过这一章的学习，我们应该能够理解算法的伪代码。我们应该了解开发和部署算法的不同阶段。我们还学会了如何使用大 O 符号来评估算法的性能。

下一章是关于算法中使用的数据结构。我们将首先看一下 Python 中可用的数据结构。然后我们将看看如何使用这些数据结构来创建更复杂的数据结构，比如栈、队列和树，这些都是开发复杂算法所需的。
