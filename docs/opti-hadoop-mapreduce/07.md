# 七、最佳实践和建议

好了，这是压轴大戏！到目前为止，我们已经学习了如何优化 MapReduce 作业性能，并将本书的主要部分用于奠定一些重要的基础。请记住，设置 Hadoop 集群基本上是一项挑战，需要将高可用性、负载平衡的要求与您希望从集群服务器获得的服务的个别要求结合起来。

在本章中，我们将描述您可以用来优化您的 Hadoop MapReduce 作业的硬件和应用配置清单。

本章将涵盖以下主题:

*   常见的 Hadoop 集群清单
*   基本输入输出系统清单和操作系统建议
*   Hadoop 最佳实践和建议
*   应用中使用的 MapReduce 模板类

# 硬件调整和操作系统建议

系统调优的建议取决于系统的内在能力。以下各节建议了不同的推荐技术和技巧，您可以在参与 MapReduce 优化过程时将其用作提醒基准。

## Hadoop 集群清单

以下清单仅描述了让您的 Hadoop 集群最佳工作所需的最少步骤:

*   检查并确保所有群集节点都可以相互通信，并且您对每个群集节点都具有物理和/或远程管理访问权限
*   检查您的集群是否具有良好的规模，并且能够补偿每个服务(至少)一个节点的故障
*   检查集群环境的限制(硬件可用性资源/机架空间、主机参数等)
*   为故障转移定义集群策略，以确保服务的高可用性
*   定义需要备份的内容、需要保存的内容和位置，以便最大限度地提高您的 Hadoop 存储容量

## Bios 调整清单

本主题列出了在最佳环境中安装 Hadoop 集群节点时应该检查的内容。将进行以下检查:

*   检查硬件上的所有 CPU 核心是否被充分利用；否则，可以降级 CPU 频率。
*   启用 **原生命令排队模式** ( **NCQ** )，通过优化驱动器磁头的移动，帮助提高现代硬盘的 I/O 性能。通常可以通过 BIOS 中的**高级主机控制器接口** ( **AHCI** ) 选项启用 NCQ 模式。

检查是否有任何默认的基本输入输出系统设置可能会对您的 Hadoop MapReduce 作业产生负面影响。

## 操作系统配置建议

在这个最小清单中，我们给出了一些系统调优的建议，它们是中央处理器、输入/输出和内存技术的结合。以下是建议:

*   选择支持 EXT4 文件系统的 Linux 发行版。
*   By default, every file's read operation triggers a disk write operation in order to maintain the time the file was last accessed. This extra disk activity associated with updating the access time is not desired. You can disable this logging of access time for both files and directories using `noatime` on the filesystem.

    ### 注

    `nodiratime` : 这将禁用打开目录时访问时间的更新，以便在枚举目录时不修改访问时间。

*   避免使用用于管理磁盘驱动器和类似大容量存储设备的**逻辑卷管理**(**【LVM】**)，因为这会影响磁盘的输入/输出性能。
*   将 Linux 内核的交换内存设置为低值。这通知 Linux 内核应该尽可能避免交换。
*   Linux 内核的输入/输出调度控制着输入/输出操作将如何提交给存储。试用 I/O 调度器的**完全公平排队** ( **CFQ** ) ，类似于循环算法，I/O 操作实现为循环队列，每个 I/O 操作允许固定的执行时间。
*   增加 Linux 操作系统最大打开文件描述符，这可能会提高 MapReduce 作业的性能。

# Hadoop 最佳实践和建议

为了提高 Hadoop 性能，以下是一些配置提示和建议，代表了运行在 Hadoop 框架上的应用的最佳实践概要。

## 部署 Hadoop

Hadoop 可以通过从官网下载其存档文件并复制到集群中手动安装。这是可行的，但是如果您希望在四个以上的节点集群上安装 Hadoop，则不建议这样做。在大型集群上手动安装 Hadoop 可能会导致维护和故障排除问题。任何配置更改都需要使用**安全复制协议** ( **SCP** ) 或**安全外壳** ( **SSH** )手动应用到所有节点。

要在大型集群上部署 Hadoop，建议使用配置管理系统和/或自动化部署工具，如 Cloudera([http://www.cloudera.com](http://www.cloudera.com))、Hortonworks([http://hortonworks.com](http://hortonworks.com))和 MapR([http://www.mapr.com](http://www.mapr.com))管理系统。对于额外的工作，例如应用部署，使用 Yum 和 Puppet 是很好的。

您可以使用这些工具为以下内容构建和维护 Hadoop 集群:

*   设置
*   配置
*   可量测性
*   监视
*   维护
*   解决纷争

### 注

Puppet 是一个强大的开源工具，它可以帮助您基于集中的规范执行管理任务，如添加用户、安装软件包和更新服务器配置。您可以通过浏览以下链接了解更多关于木偶的信息:[http://puppetlabs.com/puppet/what-is-puppet](http://puppetlabs.com/puppet/what-is-puppet)。

## Hadoop 调优建议

本节中给出的清单和建议将有助于准备和遵循 MapReduce 性能建议。

以下是记忆建议清单:

*   调整内存设置以避免因内存不足而导致作业挂起
*   设置或定义 JVM 重用策略
*   验证 JVM 代码缓存，并在必要时增加它
*   分析**垃圾收集器** ( **GC** ) 周期(使用详细日志)，观察其是否有密集周期(这意味着内存中创建了大量对象实例)，并检查 Hadoop 框架堆使用情况

以下是大量的输入/输出调优建议，以确保输入/输出操作不会出现挫折:

*   在大量输入数据的情况下，压缩源数据以避免/减少大量输入/输出调整
*   Reduce spilled records from map tasks when you experiment with large spilled records

    通过调谐减少溢出的记录:`io.sort.mb`、`io.sort.record.percent`、`io.sort.spill.percent`

*   压缩映射输出以最小化输入/输出磁盘操作
*   Implement a Combiner to minimize massive I/O and network traffic

    用下面一行代码添加一个组合器:

    job . setcombinerclass(reduce . class)；

*   Compress the MapReduce job output to minimize large output data effects

    压缩参数为`mapred.compress.map.output`和`mapred.output.compression.type`

*   更改复制参数值，以最大限度地减少网络流量和大量 I/O 磁盘操作

验证硬件资源的 Hadoop 最小配置清单如下:

*   定义需要安装(和维护)的 Hadoop 生态系统组件
*   定义您将如何手动或使用自动化部署工具(如 Puppet/Yum)安装 Hadoop
*   选择底层核心存储，如 HDFS、HBase 等
*   检查编排、作业调度等是否需要其他组件
*   检查第三方软件依赖项，如 JVM 版本
*   检查 Hadoop 的关键参数配置，如 HDFS 块大小、复制因子和压缩
*   定义监控策略；应该监控什么，使用什么工具(例如 Ganglia)
*   安装一个监控工具，如 Nagios 或 Ganglia，来监控您的 Hadoop 集群资源
*   确定(计算)存储作业数据所需的磁盘空间量
*   确定(计算)执行作业所需的节点数量
*   检查名称节点和数据节点是否具有所需的最小硬件资源，例如内存量、CPU 数量和网络带宽
*   计算最大化 CPU 使用率所需的映射器和缩减器任务的数量
*   检查 MapReduce 任务的数量，以确保有足够的任务正在运行
*   避免在生产环境中使用虚拟服务器，仅将其用于 MapReduce 应用开发
*   消除映射端溢出并减少磁盘输入/输出

## 使用 MapReduce 模板类代码

大多数 MapReduce 应用彼此相似。通常，您可以创建一个基本的应用模板，自定义`map()`和`reduce()`功能，并重用它。

下面截图中的代码片段向您展示了一个 MapReduce 模板类，您可以对其进行增强和定制以满足您的需求:

![Using a MapReduce template class code](img/5655OS_07_01.jpg)

在前面的截图中，第 1-16 行是将在应用中使用的所有 Java 类的声明。

在前面的截图中，第 18 行的`MapReduceTemplate`类是一个声明。这个类扩展了`Configured`类，实现了工具接口。以下屏幕截图显示了映射器功能:

![Using a MapReduce template class code](img/5655OS_07_02.jpg)

在上一个截图中，从第 20-36 行开始，`static class Map`定义代表您的映射函数，如上一个截图中的所示。这个类扩展了`Mapper` 类，`map()`函数应该被你的代码覆盖。建议您捕捉任何异常，以防止映射任务失败而不终止其进程。下面截图中的代码片段代表静态类 Reduce 定义:

![Using a MapReduce template class code](img/5655OS_07_03.jpg)

在上一个截图中，从第 38-54 行开始， `static class Reduce` `definition`代表您在上一个代码截图中显示的`Reducer`功能。这个类扩展了减速器类和 `reduce` `()`功能应该被你的代码覆盖。建议您捕捉任何异常，以防止 reduce 任务在终止其进程之前失败:

![Using a MapReduce template class code](img/5655OS_07_04.jpg)

在前面的截图中，从第 56-85 行开始，不同的类实现是可选的。这些类将帮助您定义一个自定义的关键从业者、组和排序类比较器，就像前面截图中提到的。`run()`方法实现如下截图所示:

![Using a MapReduce template class code](img/5655OS_07_05.jpg)

在前面的截图中，来自的第 87-127 行包括`run()`方法实现。配置 MapReduce 作业，其参数在该方法内设置，如 Map 和 Reduce 类，如上一张截图所示。您现在可以启用压缩，设置`OutputKey`类、`FileOutputFormat`类等。下面截图中的代码代表`main()`方法:

![Using a MapReduce template class code](img/5655OS_07_06.jpg)

在上一个截图中，从第 133-138 行，指定了`main()`方法实现。在这个方法中，会创建一个新的配置实例，并调用`run()`方法来启动 MapReduce 作业。

撰写申请时需要考虑的其他一些因素如下:

*   当您有大的输出文件(多个千兆字节)时，通过设置`dfs.block.size`考虑使用更大的输出块大小。
*   要提高 HDFS 写入性能，请选择合适的压缩程序编解码器(压缩速度与效率)来压缩应用的输出。
*   避免每次减少写多个输出文件。
*   为减速器的输出使用适当的文件格式。
*   仅使用可拆分的压缩编解码器来写出大量压缩的文本数据。像`zlib/gzip/lzo`这样的编解码器会适得其反，因为它不能被拆分和处理，这就迫使 MapReduce 框架在单个映射中处理整个文件。考虑使用`SequenceFile`文件格式，因为它们是压缩和可分割的。

# 总结

在本章中，我们了解了 Hadoop MapReduce 优化的最佳实践。为了提高 Hadoop 的工作性能，以清单的形式给出了几个建议和提示，这将有助于您确保 Hadoop 集群得到良好的配置和规模。

我们优化和增强 MapReduce 作业性能的学习之旅到此结束。我希望你和我一样喜欢它。我鼓励你使用谷歌、Hadoop 官方网站和互联网上的其他来源发布的 MapReduce 论文，继续了解本书涵盖的更多主题。优化 MapReduce 作业是一个迭代且可重复的过程，您需要在找到最佳性能之前完成它。此外，我建议您尝试不同的技术来找出在您的工作环境中哪些调优解决方案最有效，并尝试组合不同的优化技术！