# 四、保护 Hadoop 安装

在本章中，我们将探讨与 Hadoop 安全相关的基本主题。如您所知，Hadoop 由多个组件组成，保护 Hadoop 集群意味着保护这些组件中的每一个。这使得保护 Hadoop 集群成为一项不平凡的任务。在本章中，我们将涵盖以下主题:

*   Hadoop 安全概述
*   HDFS 安全
*   MapReduce 安全性
*   Hadoop 服务级别授权
*   Hadoop 和 Kerberos

# Hadoop 安全概述

最初，Hadoop 被设计成在一个可信的环境中运行。假设所有集群用户都可以被信任来正确地呈现他们的身份，并且不会试图获得比他们拥有的更多的权限。这导致了简单安全模式的实现，这是 Hadoop 中的默认身份验证系统。在简单的安全模式下，Hadoop 信任操作系统来提供用户的身份。与大多数关系数据库不同，Hadoop 没有任何集中的用户和特权存储。没有允许 Hadoop 正确验证用户身份的用户/密码概念。相反，Hadoop 接受由操作系统表示的用户名，并信任它，而无需任何进一步的检查。这种模式的问题是有可能模拟另一个用户。例如，一个流氓用户可以使用一个定制的 HDFS 客户端，而不是使用 Java 调用来识别当前的操作系统用户，将它替换为根用户，并获得对所有数据的完全访问权限。在某些情况下，简单安全模式仍然是首选，尤其是当集群处于受信任的环境中，并且只有少数用户可以访问系统时。

对于许多组织来说，这种宽松的用户授权方式是不可接受的。公司开始在他们的 Hadoop 集群中存储敏感数据，并关注能够在大型多租户环境中隔离数据。为了解决这个问题，Hadoop 引入了对 **Kerberos** 的支持。 Kerberos 是一种成熟的身份验证协议。Kerberos 服务器用作外部用户的存储库，允许用户使用密码进行身份验证。成功通过 Kerberos 身份验证的用户将被授予**访问票证。**在这张票有效期间，他们可以使用 Hadoop 服务。Kerberos 支持不仅针对外部集群用户，也针对所有内部服务。这意味着所有数据节点、任务跟踪器、名称节点等守护程序都需要通过 Kerberos 身份验证才能加入集群。Kerberos 为 Hadoop 提供了更强的安全模式，但它也在集群的配置和维护方面带来了额外的挑战。

# HDFS 安全

HDFS 模仿了 Unix 风格的文件系统权限模式。每个文件和目录都有一个用户、组所有者和一组权限。这些权限可以允许或禁止用户访问给定的目录或文件。例如:

```sh
# hdfs dfs -ls /
drwxr-xr-x   - mapred mapred        0 2013-05-27 04:40 /jobtracker
drwxrwxrwt   - hdfs   supergroup    0 2013-06-08 16:03 /tmp

```

可以看到`/jobtracker`目录归用户`mapred`所有，只有这个用户才允许将文件写入这个目录，而每个用户都可以读取这个目录中的文件。另一方面，虽然`/tmp`目录归`hdfs`用户所有，但每个人都可以在那里读写文件。这模仿了 Unix 类型的`/tmp`目录的行为。

### 注

请注意，在`/tmp`目录上也设置了一个粘性位。这将只允许文件所有者删除和重命名那里的文件。

为了操作文件权限，HDFS 提供了类似于 Unix 环境的命令。例如，让我们为用户`alice`创建一个主目录，并更改目录所有权:

```sh
[root@nn1 ~]# hdfs dfs -mkdir /user/alice/
mkdir: Permission denied: user=root, access=WRITE, inode="/user":hdfs:hdfs:drwxr-xr-x

```

这个创建目录的尝试失败了，我们得到一个错误，因为 Linux 根用户在 HDFS 没有适当的权限。

在 CDH，`hdfs`用户相当于`superuser`——拥有最高级别特权的用户。这是因为所有的 HDFS 守护进程都在`hdfs`用户下运行。

### 注

区分用户“`hdfs`”和 hdfs 命令行工具很重要。

要修复这个错误，我们将切换到`hdfs`用户:

```sh
# sudo su - hdfs
$ hdfs dfs -mkdir /user/alice/
$ hdfs dfs -chown alice:alice /user/alice/

```

您也可以使用语法类似于 Linux 中语法的`–chmod` 命令来更改文件和目录的访问模式。

### 注

操作系统用户和您分配给 HDFS 的权限之间没有直接联系。当您更改目录或文件所有权时，Hadoop 不会检查用户是否真的存在。你需要小心用户名的正确拼写，因为你不会从 HDFS 得到**用户不存在**错误。

# MapReduce 安全

MapReduce 安全性关注于作业提交和管理。默认情况下，它是完全开放的。任何有权访问作业跟踪器服务的用户都可以提交、查看和终止作业。这种行为对于开发或概念验证集群来说是可以接受的，但是对于多租户生产环境来说显然是失败的。

为了解决这些问题，Hadoop 支持 **集群管理员**和 **队列管理员**的概念。集群和队列管理员是拥有查看和操作正在运行的作业的权限的 Linux 用户和组。例如，管理员可以更改作业优先级或终止任何正在运行的作业。

如果你还记得的话，在[第 2 章](2.html "Chapter 2. Installing and Configuring Hadoop")、*安装和配置 Hadoop* 中，我们已经将我们的 JobTracker 配置为使用 **FairScheduler** 。使用此调度程序，您可以定义一组固定的作业队列，并允许特定的用户和组向它们提交作业。每个队列还可以配置一个自定义的管理员列表。

要启用权限模型，您需要对您的`mapred-site.xml`文件进行一些更改:

```sh
<name>mapred.acls.enabled</name>
<value>true</value>
```

接下来，需要设置集群级别`mapred`管理员:

```sh
<name>mapred.cluster.administrators</name>
<value>alice,bob admin</value>
```

在前面的例子中，我们已经为名为`alice,bob`的 Linux 用户和管理 Linux 组中的所有用户分配了管理员访问权限。您可以使用逗号分隔的列表指定多个用户和组。用户列表必须用空格与组列表分开。“`*`”符号表示每个人都可以对 MapReduce 作业执行管理任务。

生产 Hadoop 集群经常执行组织内不同组提交的作业。这些群体可以有不同的优先事项，他们的工作可以有不同的重要性。例如，可以有一个生产组，其作业为业务关键型应用提供数据，还有一个分析组执行后台数据挖掘。您可以定义哪个用户可以访问哪个队列，以及为每个队列分配单独的管理员。

首先，您需要在`mapred-site.xml`中创建一个命名队列列表:

```sh
<name>mapred.queue.names</name>
<value>production,analytics</value>
```

每个作业队列的权限在一个名为`mapred-queue-acls.xml`的单独文件中定义。该文件需要放在 JobTracker 上的/ `etc/hadoop/conf`目录中。CDH 提供了一个模板文件`mapred-queues.xml.template`，您可以将其用作基线。

该文件的格式与其他 Hadoop 配置文件略有不同。以下是一个可能的示例:

```sh
<queues>
 <queue>
   <name>production</name>
    <acl-submit-job> prodgroup</acl-submit-job>
    <acl-administer-jobs>alice </acl-administer-jobs>
 </queue>
 <queue>
   <name>analytics</name>
    <acl-submit-job> datascience</acl-submit-job>
    <acl-administer-jobs>bob </acl-administer-jobs>
 </queue>
</queues>
```

在前面的例子中，我们定义了两个队列:`production`和`analytics`。每个队列都支持可以向该队列提交作业的用户和组列表，以及管理员列表。对于`production`组，我们只有使用`acl-submit-job`选项的`prodgroup` Linux 组的有限提交权。请注意，没有列出单个用户，组名前有一个前导空格字符。我们选择`alice`作为生产队列管理员，并使用`acl-administer-jobs`选项进行指定。该特定配置在管理员列表中没有组，因此用户名后面有一个空格字符。

对`mapred-site.xml`进行所有更改后，需要重新启动 JobTracker 服务。对`mapred-queue-acls.xml`的更改会自动获得，无需重启。

要向给定队列提交作业，可以使用`mapred.job.queue.name`选项。例如，要将`WordCount`作业提交到分析队列中，可以使用以下命令:

```sh
# hadoop jar /usr/lib/hadoop-0.20-mapreduce/hadoop-examples.jar wordcount -Dmapred.job.queue.name=analytics /tmp/word_in /tmp/word_out 

```

通过运行以下`mapred`命令，您可以监控分配给特定队列的活动队列和作业列表:

```sh
# mapred queue –list
# mapred queue -info analytics –showJobs

```

# Hadoop 服务级别授权

除了 HDFS 权限模型和 MapReduce 作业队列管理，您还可以指定哪些用户和组可以访问不同的集群服务。这个可以用来限制对 HDFS 的访问，并只向一小部分用户提交作业。

要启用服务级别授权，您需要在`core-site.xml`配置文件中添加以下选项:

```sh
<name>hadoop.security.authorization</name>
<value>true</value>
```

类似地，对于 MapReduce 队列权限，服务级别 ACL 在一个名为`hadoop-policy.xml`的单独文件中定义。CDH 在`/etc/hadoop/conf`目录中提供了这个文件的示例，默认情况下，它是完全开放的(所有用户都可以访问所有服务)。

服务级别授权和 HDFS 或 MapReduce 权限之间的区别在于执行这些检查的顺序。在用户开始与 HDFS 或 MapReduce 服务通信之前，会对服务级别执行权限检查。这对于完全阻止某些用户或组进入集群非常有用。

假设我们想将 HDFS 和 MapReduce 的访问权限限制在名为`hadoopusers`的 Linux 组。为此，我们需要在`hadoop-policy.xml`中设置以下选项:

```sh
<name>security.client.protocol.acl</name>
<value> hadoopusers</value>
<name>security.client.datanode.protocol.acl</name>
<value> hadoopusers</value>
```

上述选项将阻止`hadoopusers`组以外的用户与 HDFS 守护程序通信。这些值的格式与我们用于 MapReduce 权限的格式相同。请注意“`hadoopuser`”字符串前有一个空格字符。

要仅允许`hadoopuser`组的成员提交 MapReduce 作业，请指定以下选项:

```sh
<name>security.job.submission.protocol.acl</name>
<value> hadoopusers</value>
```

您可以在`hadoop-policy.xml`文件中指定更多可能的选项，基本上限制对任何 Hadoop 服务的访问，包括内部通信协议。例如，您可以只允许`hdfs`用户用于数据节点间通信，以及名称节点通信。所有这些选项都在示例`hadoop-policy.xml`文件中进行了概述，因此您可以在必要时进行调整。

# Hadoop 和 Kerberos

正如您在前面几节中看到的那样， Hadoop 提供了限制对各种资源和服务的访问的所有组件。尽管如此，仍然有一块拼图不见了。由于 Hadoop 不维护任何内部用户数据库，它必须完全信任操作系统提供的用户身份。虽然基于 Linux 的操作系统使用密码或公钥/私钥对对用户进行身份验证，但一旦用户登录，Hadoop 就无法正确验证他/她的身份。在早期版本的 Hadoop 中，HDFS 和 MapReduce 客户端执行相当于`whoami` shell 命令来获取用户的身份。

这是一种非常不安全的方式，因为它允许一个流氓用户用一个自定义脚本替换`whoami`命令，该脚本将返回它喜欢的任何用户名。

在最新版本的 Hadoop 中，检索用户身份的代码被更改为使用 Java SecurityManager API，但这种方法仍然存在各种安全问题。您可以更改客户端源代码以使用任何身份，并使用此更改后的程序连接到群集。还有其他未经授权访问群集的可能性。攻击者可能会拦截并改变客户端和 Hadoop 服务之间的通信流量，因为它没有加密。

为了解决这个问题，Hadoop 支持通过外部 Kerberos 协议进行身份验证。Kerberos 是一种协议，旨在允许参与者通过不安全的网络安全地识别和验证自己。这个协议有不同的实现，但是我们将关注 **MIT Kerberos** 。

## Kerberos 概述

在我们讨论用 Hadoop 实现 Kerberos 身份验证所需的步骤之前，值得简要概述一下该协议。Kerberos 是一种客户端-服务器协议。它由 **重点配送中心** ( **KDC** )以及客户端程序组成。

反过来，KDC 由几个部分组成。**认证服务器** ( **AS** )负责验证用户身份并签发**赠票单** ( **TGT** )。 AS 有一个用户密码的本地副本，每个 TGT 都用这个密码加密。当客户端收到 TGT 时，它会尝试使用密码解密。如果用户提供的密码和 AS 存储的密码匹配，那么 TGT 就可以被成功解密和使用。解密后的 TGT 用于从**出票服务** ( **TGS** )获取认证票。此票证用于针对所有需要的服务对用户进行身份验证。

在 Kerberos 术语中，用户被称为**主体**。主体由以下三部分组成:

*   **主要组件**:它本质上是一个用户名。
*   **实例组件**:可以用于为同一个用户识别不同的角色，或者在 Hadoop 的情况下识别不同服务器上的同一个用户。
*   **领域组件**:可以把想象成 DNS 中的一个领域。

这里有一个 Kerberos 主体的例子:

```sh
alice/dn1.hadoop.test.com@HADOOP.TEST.COM
```

这就是从其中一个数据节点连接的用户如何向 KDC 展示自己。

以下是用户使用 KDC 执行身份验证并接收 TGT 的方式:

```sh
[alice@dn1]$ kinit
Password for alice@HADOOP.TEST.COM:
…

```

通过这种方式获得的票证将缓存在本地文件系统中，并且在 KDC 管理员指定的期限内有效。通常，这个时间范围是 8 到 12 个小时，因此用户不必为每个操作输入密码。为了能够正确识别领域，需要在服务器上安装 Kerberos 客户端程序，并且需要在/ `etc/krb5.conf`文件中提供配置。

## Hadoop 中的 Kerberos

当 Hadoop 配置了 Kerberos 支持时，所有集群交互都需要首先通过 KDC 认证。这不仅适用于集群用户，也适用于所有 Hadoop 服务。启用 Kerberos 支持后，数据节点需要有一个合适的票证才能与名称节点通信。

这使初始部署变得复杂，因为您需要为每个 Hadoop 节点上的每个服务生成主体，并为每个集群用户创建主体。由于 Hadoop 服务不能交互提供密码，它们使用预生成的密钥表文件，这些文件放置在每台服务器上。

创建所有主体并在所有服务器上分发 keytab 文件后，您需要调整 Hadoop 配置文件以指定主体和 keytab 文件的位置。

### 注

此时，您应该决定是否需要在集群上实现 Kerberos。根据环境和集群中存储的数据类型，您可能会发现操作系统提供的基本身份验证在您的情况下已经足够。如果您有严格的安全要求，实现 Kerberos 支持是目前唯一可用的解决方案。请记住，启用后，Kerberos 会影响集群中的所有服务。比如说，只为外部用户实现部分支持是不可能的。

### 配置 Kerberos 客户端

我们将不回顾 KDC 的安装和配置，因为这本身就是一个巨大的话题。我们将假设您安装并配置了专用的麻省理工学院 Kerberos 版本 5，并且您拥有 KDC 管理员帐户权限。

您需要做的第一个任务是在所有服务器上安装和配置 Kerberos 客户端。要安装客户端程序，请运行以下命令:

```sh
# yum install krb5-workstation.x86_64

```

安装客户端后，您需要编辑/ `etc/krb5.conf`文件，并提供在 KDC 上配置的 Hadoop 领域。我们将在以下所有示例中使用`HADOOP.TEST.COM`领域。在这种情况下，领域的名称并不重要，如果您愿意，您可以选择不同的名称。在生产设置中，您可能希望对不同的集群使用不同的领域，例如生产和质量保证。

### 生成 Kerberos 主体

我们将为 HDFS、MapReduce 和 HTTP 服务生成主体和 keytab 文件。需要 HTTP 主体来支持作为 HDFS 和 MapReduce 守护进程一部分的内置 web 服务，并向用户公开一些状态信息。

我们将演示如何为一个数据节点生成这些主体，因为数据节点需要指定 HDFS、MapReduce 和 HTTP 主体。您需要对群集中的所有主机重复此过程。

### 类型

**自动生成委托人**

您可以轻松地编写命令脚本来创建 Kerberos 主体和生成 keytab 文件，并将它们应用于所有服务器。这将帮助你避免错别字和错误。

登录 KDC 服务器，切换到根用户，执行以下命令:

```sh
# kadmin.local
Authenticating as principal root/admin@HADOOP.TEST.COM with password.

```

省略了一些命令行输出。

```sh
# kadmin.local
Authenticating as principal root/admin@HADOOP.TEST.COM with password.
addprinc -randkey HTTP/dn1.hadoop.test.com@HADOOP.TEST.COM
addprinc -randkey hdfs/dn1.hadoop.test.com@HADOOP.TEST.COM
addprinc -randkey mapred/dn1.hadoop.test.com@HADOOP.TEST.COM

```

上述命令将生成三个带有随机密码的主体。我们还需要为`hdfs`和`mapred`主体生成 keytab 文件。为此，在`kadmin.local`控制台中执行以下命令:

```sh
xst -norandkey -k hdfs.keytab hdfs/dn1.hadoop.test.com@HADOOP.TEST.COM HTTP/dn1.hadoop.test.com@HADOOP.TEST.COM
xst -norandkey -k mapred.keytab mapred/dn1.hadoop.test.com@HADOOP.TEST.COM HTTP/dn1.hadoop.test.com@HADOOP.TEST.COM

```

前面的命令将生成两个文件:`hdfs.keytab`和`mapred.keytab`。将这些文件复制到适当的服务器，并将其放入`/etc/hadoop/conf`目录。要保护 keytab 文件，请相应地将文件所有权更改为`hdfs:hdfs`和`mapred:mapred`。确保只允许这些用户读取文件的内容。

在进入下一步之前，您需要确保生成了所有节点的所有主体，并将 keytab 文件复制到所有服务器。

### 为 HDFS 启用 Kerberos

要启用 Kerberos 安全性，请将以下选项添加到`core-site.xml` 配置文件中:

```sh
<name>hadoop.security.authentication</name>
<value>kerberos</value>
```

该变量的默认值为`simple`，禁用 Kerberos 支持。确保将`core-site.xml`中的更改传播到群集中的所有服务器。

要为 HDFS 配置 Kerberos 支持，您需要在`hdfs-site.xml`文件中添加以下选项。将此文件复制到群集中的所有 HDFS 服务器非常重要。Kerberos 身份验证是双向的。这意味着，例如，数据节点需要知道名称节点通信的主体。

```sh
<name>dfs.block.access.token.enable</name>
<value>true</value>

<name>dfs.namenode.kerberos.principal</name>
<value>hdfs/_HOST@HADOOP.TEST.COM</value>

<name>dfs.datanode.kerberos.principal</name>
<value>hdfs/_HOST@HADOOP.TEST.COM</value>

<name>dfs.namenode.kerberos.internal.spnego.principal</name>
<value>HTTP/_HOST@HADOOP.TEST.COM</value>
<name>dfs.datanode.kerberos.http.principal</name>
<value>HTTP/_HOST@HADOOP.TEST.COM</value>

<name>dfs.journalnode.kerberos.principal</name>
<value>hdfs/_HOST@HADOOP.TEST.COM</value>

<name>dfs.journalnode.kerberos.internal.spnego.principal</name>
<value>HTTP/_HOST@HADOOP.TEST.COM</value>
```

上述选项指定了所有与 HDFS 相关的主体。此外，由于我们已经配置了名称节点高可用性，我们还为日志节点指定了主体。这些选项中的`_HOST` 令牌将在运行时被服务器的完全限定主机名替换。

接下来，我们需要为 HDFS 主体提供 keytab 文件的位置:

```sh
<name>dfs.namenode.keytab.file</name>
<value>/etc/hadoop/conf/hdfs.keytab</value>

<name>dfs.datanode.keytab.file</name>
<value>/etc/hadoop/conf/hdfs.keytab</value>

<name>dfs.journalnode.keytab.file</name>
<value>/etc/hadoop/conf/hdfs.keytab</value>
```

其中一个与 Kerberos 没有直接关系的安全要求是在特权端口上运行数据节点服务。特权端口是数字低于 1024 的端口。这样做是为了防止流氓用户编写复杂的 MapReduce 作业，将自己作为有效的数据节点呈现给集群。启用安全性后，您必须在配置文件中进行以下更改:

```sh
<name>dfs.datanode.address</name>
<value>0.0.0.0:1004</value>
<name>dfs.datanode.http.address</name>
<value>0.0.0.0:1006</value>
```

最后，您需要创建一个`/etc/default/hadoop-hdfs-datanode`文件，内容如下:

```sh
export HADOOP_SECURE_DN_USER=hdfs
export HADOOP_SECURE_DN_PID_DIR=/var/lib/hadoop-hdfs
export HADOOP_SECURE_DN_LOG_DIR=/var/log/hadoop-hdfs
export JSVC_HOME=/usr/lib/bigtop-utils/
```

### 为 MapReduce 启用 Kerberos

需要应用于`mapred-site.xml`的变化与我们已经为 HDFS 做的非常相似。我们需要为作业跟踪器、任务跟踪器和嵌入式网络服务器提供主体和键标签文件位置:

```sh
<name>mapreduce.jobtracker.kerberos.principal</name>
<value>mapred/_HOST@HADOOP.TEST.COM</value>

<name>mapreduce.jobtracker.kerberos.http.principal</name>
<value>mapred/_HOST@HADOOP.TEST.COM</value>

<name>mapreduce.tasktracker.kerberos.principal</name>
<value>HTTP/_HOST@HADOOP.TEST.COM</value>

<name>mapreduce.tasktracker.kerberos.http.principal</name>
<value>HTTP/_HOST@HADOOP.TEST.COM</value>

<name>mapreduce.jobtracker.keytab.file</name>
<value>/etc/hadoop/conf/mapred.keytab</value>

<name>mapreduce.tasktracker.keytab.file</name>
<value>/etc/hadoop/conf/mapred.keytab</value>
```

说到安全性，Hadoop 的 MapReduce 部分的一个特点是，用户代码是由 TaskTracker 在一个单独的 JVM 中启动的。默认情况下，这个单独的进程是在启动 TaskTracker 本身的用户下运行的。这可能会为用户提供他或她需要的更多权限。启用安全性后，任务跟踪器会将进程的所有权更改给不同的用户。这将是启动作业的用户。为了支持这一点，需要添加以下选项:

```sh
<name>mapred.task.tracker.task-controller</name>
<value>org.apache.hadoop.mapred.LinuxTaskController</value>

<name>mapreduce.tasktracker.group</name>
<value>mapred</value>
```

此外，需要在`/etc/hadoop/conf`中创建一个单独的`taskcontroller.cfg`文件。此文件将指定允许在此群集上启动任务的用户。以下是我们群集的文件内容:

```sh
mapred.local.dir=/dfs/data1/mapred,/dfs/data2/mapred,/dfs/data3/mapred,/dfs/data4/mapred,/dfs/data5/mapred,/dfs/data6/mapred  
hadoop.log.dir=/var/log/hadoop-0.20-mapreduce
mapreduce.tasktracker.group=mapred
banned.users=mapred,hdfs,bin
min.user.id=500
```

在安全模式下运行时，taskstracker 会在不同的用户下启动不同的作业。我们需要在`taskcontroller.cfg`中指定本地目录的位置，以允许任务跟踪器正确设置权限。我们还指定了不允许使用`banned.users`选项执行 MapReduce 任务的用户。这是为了避免特权用户绕过安全检查并访问本地数据。`min.user.id` 选项将基于同样的原因禁止任何 id 小于 500 的特权用户(特定于 CentOS)提交 MapReduce 作业。

在所有节点上传播完这些配置文件后，您需要重新启动群集中的所有服务。密切关注日志文件中的消息。正如您所看到的，配置一个安全的 Hadoop 集群并不是一项简单的任务，涉及到很多步骤。仔细检查所有服务是否正常工作是很重要的。

# 总结

在本章中，我们回顾了 Hadoop 中使用的身份验证和授权原则。我们已经讨论了 HDFS 权限模型，以及 MapReduce 访问控制列表。默认的 Hadoop 安全策略容易受到各种攻击。我们已经回顾了如何在 Hadoop 中配置 Kerberos 支持以符合企业级安全要求。

在下一章中，我们将重点关注 Hadoop 集群的运行状况和性能。