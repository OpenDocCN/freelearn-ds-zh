# 五、监控 Hadoop 集群

每个生产系统都需要一个计划周密的监控策略；因此，Hadoop 集群也需要它。考虑到所涉及的多个组件和组成集群的多台机器，这不是一项简单的任务。Hadoop 提供了关于其组件内部状态的各种各样的度量标准，但是还没有现成的工具来监控和警告这些度量标准。在本章中，我们将概述监控策略，以及您可以用来实现它的工具。

# 监控策略概述

Hadoop 监控策略不同于您可能用于传统数据库的策略。当您拥有数百台服务器的集群时，各种组件的故障成为常态。如果您将单个数据节点的故障视为紧急情况，您的监控系统很可能会因虚假警报而过载。

相反，重要的是概述哪些组件是关键的，哪些组件的故障是可以容忍的(在一定程度上)。对于关键组件，您需要定义规则，这些规则会立即提醒呼叫人员。对于非关键组件，定期报告整体系统状态就足够了。

您应该已经对 Hadoop 组件有了一个概念，这些组件的故障应该被视为紧急情况。名称节点或作业跟踪器的故障将使群集不可用，应立即进行调查。即使您为这些组件配置了高可用性，找出问题的根本原因仍然很重要。这将有助于您防止将来发生类似的问题。如果您已经按照我们的说明为名称节点设置了自动故障转移的高可用性，那么为所有相关组件提供适当的监控是非常重要的。

您需要确保足够多的日志节点启动并运行，为名称节点日志提供**法定数量**，并监控动物园管理员集群状态。除了给定服务的完全失败之外，您还需要监控一些健康指标，以便能够预防灾难。名称节点和日志节点上的可用磁盘空间，以及总群集容量和当前使用情况等都是您应该监控的最关键指标之一。

从监控的角度来看，工作节点是集群的非关键部分。Hadoop 可以容忍多个工作节点的故障，并且仍然保持集群可用。重要的是要监控数据节点和任务跟踪器的哪个部分可用，并根据此指标配置监控规则。例如，一个或两个工作节点的故障可能不需要运营团队立即关注。另一方面，30%的工作节点出现故障会影响集群可用性，这可能是更大问题的征兆。这可能是由硬件故障或网络中断引起的。

Hadoop 没有自带任何内置的监控系统。最常见的做法是使用开源监控系统(如 Nagios)来发出警报，使用 Ganglia 等工具来获取趋势和历史信息。在接下来的部分中，我们将回顾 Hadoop 服务揭示的指标以及如何访问它们。我们还将研究如何将这些指标与现有的监控系统相结合。

# Hadoop 指标

大多数 Hadoop 组件通过度量子系统显示其内部组件的状态。这个想法是保留特定于给定 Hadoop 进程的计数器，并根据配置将它们重定向到适当的消费者。

Hadoop 度量子系统有几个版本。旧的称为 metrics1 (或者仅仅是 metrics)，新的称为 metrics2。Metrics2 从 CHD4 开始提供，我们将重点关注这个版本。

Metrics2 有一个关于源、汇、和上下文的概念。一个**源**是任何记录内部统计数据的组件，比如 NameNode 或 JobTracker。来源收集各种**上下文**中的指标。例如，NameNode 可以通过 jvm 上下文揭示它正在运行的 JVM 的信息，通过 DFS 上下文揭示 HDFS 状态的信息，以及通过 rpc 上下文揭示 RPC 的信息。 **Sink** 是度量的消费者。接收器可以是文本文件、特定监控系统的文件等等。

默认情况下，Hadoop 组件收集指标，但不提供给任何消费者。要启用特定的接收器，您需要编辑`hadoop-metrics2.properties`文件。你也可以注意到`/etc/hadoop/conf`有一个 `hadoop-metrics.properties`文件。度量子系统的早期版本使用这个。不过，我们将关注 metrics2。

默认情况下，metrics2 配置文件中启用了几个选项:

```sh
*.sink.file.class=org.apache.hadoop.metrics2.sink.FileSink
*.period=10
```

这些配置选项启用了文件接收器，这基本上意味着配置的源将把它们的输出写入文本文件。在这种情况下，指标将每 10 秒采样一次。

例如，要配置要写入文件的名称节点统计信息，您应该在`hadoop-metrics2.properties`文件中添加以下行:

```sh
namenode.sink.file.filename=/var/log/hadoop-hdfs/namenode-metrics.out
```

您需要重新启动 Hadoop 守护程序来应用这些更改。

一般来说，您不需要将指标写入纯文本文件，除非您计划开发一个自定义脚本来处理它们。相反，我们将使用 Hadoop 服务通过 Java 管理扩展(JMX)揭示的指标。

## JMX 指标

大多数 Hadoop 组件都实现了 JMX 接口，以揭示一些关于其内部状态的信息。可以使用诸如 JConsole([http://docs . Oracle . com/javase/6/docs/technotes/guides/management/JConsole . html](http://docs.oracle.com/javase/6/docs/technotes/guides/management/jconsole.html)等工具来探索这些数据，但我们将重点关注获取这些指标的另一种方式——通过 HTTP 接口。

核心 Hadoop 组件有一个嵌入式网络服务器，用于提供一些用户友好的服务状态信息。例如，要查看名称节点状态页面，请访问以下网址— `http://nn1.hadoop.test.com:50070`。不同的服务使用不同的默认端口，下表提供了简要总结:

<colgroup><col style="text-align: left"> <col style="text-align: left"></colgroup> 
| 

服务名称

 | 

HTTP 端口

 |
| --- | --- |
| 名称节点 | Fifty thousand and seventy |
| 数据节点 | Fifty thousand and seventy-five |
| 日志节点 | Eight thousand four hundred and eighty |
| 工作跟踪者 | Fifty thousand and thirty |
| 任务跟踪器 | Fifty thousand and sixty |

除了一般状态信息，Hadoop 服务还在`/jmx`页面公开了 JMX 指标。例如，要获取数据节点指标，请前往[http://dn1.hadoop.test.com:50075/jmx](http://dn1.hadoop.test.com:50075/jmx)。这些指标类似于您将它们流式传输到文本文件时看到的情况，但是是以 JSON 格式提供的。JSON 不仅可读性更强，而且更容易在各种脚本中解析。

在`/jmx`页面上展示的指标被组织在不同的上下文中。其中有相当多的指标，指标的总数令人生畏。但是，我们将只关注几个最重要的指标来进行监控。

以下是从活动名称节点获取的`FSNamesystem` 上下文的示例(此处未显示所有指标):

```sh
{
    "name" : "Hadoop:service=NameNode,name=FSNamesystem",
    "tag.Hostname" : "nn2.hadoop.test.com",
    "MissingBlocks" : 0,
    "CapacityTotalGB" : 62.0,
    "CapacityUsedGB" : 0.0,
    "CapacityRemainingGB" : 48.0,
    "BlocksTotal" : 19,
    "FilesTotal" : 44,
    "PendingReplicationBlocks" : 0,
    "UnderReplicatedBlocks" : 19,
    "CorruptBlocks" : 0,
    "BlockCapacity" : 2097152,
    "TotalFiles" : 44
  }
```

如您所见，JMX 公开了一些关于 HDFS 状态的重要信息，例如剩余磁盘空间、损坏和复制数据块不足。我们将依靠这些信息来构建我们的监控解决方案。

## 用 Nagios 监控 Hadoop

有几种方法可以实现 Hadoop 集群的操作监控。诸如 Cloudera、MapR 和 Hortonworks 等 Hadoop 发行版供应商提供了自己的集群监控和管理软件。在大多数情况下，该软件或其某些功能只能通过付费订阅获得。

如果您计划从其中一家供应商处购买支持，那么研究他们的监控系统所提供的功能是值得的。

另一种选择是使用免费的监控框架，如 Nagios。Nagios 检查是可插入的，您可以基于任何可用的度量来定义警报规则。Nagios 是最流行的开源监控系统之一，很有可能您已经在使用它来监控您的 it 基础架构的组件。如果没有，请参考 Nagios 文档了解在[http://www.nagios.org/documentation](http://www.nagios.org/documentation)的安装和配置细节。

## 监测 HDFS

我们可以将监控检查分为主机特定和 Hadoop 特定，以及关键和非关键。特定于主机的检查将包括您通常会在任何 Linux 服务器上检查的内容:磁盘空间、内存使用等。Hadoop 特定检查将基于 Hadoop 服务提供的指标。关键事件的一个例子是作业跟踪器完全失败。在这种情况下，运营团队的随叫随到成员应立即调查并解决问题。非关键检查可视为群集状态的每日报告。一个这样的报告的例子可以是可用数据节点服务器的百分比。

## 名称节点检查

应在名称节点服务器上配置以下操作系统和主机级检查:

*   检查服务器是否可访问。这可以通过使用 http://nagiosplugins.org/ T2 的 Nagios 插件包中的 T0 插件很容易地实现。如果您正在为名称节点使用高可用性设置，检查主要和辅助名称节点非常重要。类型:关键
*   检查名称节点文件系统和编辑日志目录以及操作系统卷的可用磁盘空间。为此，您可以使用 Nagios 插件中的`check_disk`。Nagios 允许您配置不同级别的警报。您可以将其配置为当检查结果超过一个阈值时进入`WARNING`状态，当达到另一个阈值时进入`CRITICAL`状态。类型:关键
*   确保名称节点服务不会交换很重要。交换可以显著增加 RPC 调用的响应时间，并有效地停止集群。有一个`check_swap`插件可以做到这一点。类型:关键
*   监控任何硬件故障警报，尤其是 RAID 运行状况。在[上有各种特定于供应商的检查，如 Nagios 插件。类型:关键](http://exchange.nagios.org/directory/Plugins/Hardware/%E2%80%A8Storage-Systems/RAID-Controllers)

一般来说，主机级监控的实现方式与您当前监控其他 Linux 服务器的方式相同。实现 Hadoop 特定的检查就不那么简单了。不同的 Hadoop 指标没有现成的实现。互联网上有几个开源脚本可以解析 JMX 网页的内容，并对不同的指标发出警告。这些脚本不够通用，不足以让您监控所有您可能想要的东西。

因为我们关注的是以 JSON 格式提供的 JMX 网络输出，所以使用您选择的语言编写一个脚本来解析它并提取您感兴趣的信息是很容易的。我们不会关注这些脚本的实现细节，因为它们对于不同的语言是不同的。相反，我们将列出应该监控哪些 JMX 指标。

以下列表描述了应在生产集群上监控的特定于 Hadoop 的检查:

服务级别检查是特定于 Hadoop 进程的检查。让我们看看可以对 HDFS 实施哪些检查:

*   您可以通过查看名称节点 JMX 输出中的`CapacityTotalGB/CapacityUsedGB/CapacityRemainingGB`状态变量来监控可用的 HDFS 容量。对 HDFS 能力的监测应在警戒级别和定期报告级别同时进行。您需要知道长期磁盘空间消耗率，以便能够执行适当的容量规划。对这些指标进行警报检查也很重要，以防止失控的用户作业消耗所有群集磁盘空间。类型:关键型和常规型
*   如果您正在存储大量较小的文件，则有可能在真正用完磁盘空间之前用完名称节点上的可用数据块插槽。为了避免这种情况，您需要监控`BlocksTotal`和`BlockCapacity`状态变量。类型:关键型和常规型
*   如果有一个数据块的副本全部损坏，它将被标记为损坏的数据块。群集中此类块的总量在`CorruptedBlocks`变量中报告。没有固定的阈值可以监控，但理想情况下这个数字应该接近 0。类型:关键
*   没有任何副本可用的块数在`MissingBlocks`状态变量中报告。和前面的情况一样，这个数字应该很低。类型:关键
*   监控集群中可用数据节点的百分比非常重要。这可以通过查看`NumLiveDataNodes`和`NumDeadDataNodes`状态变量来完成。根据您的集群大小，您可以针对固定数量的死数据节点或活节点与死节点的比率发出警报。例如，您可以设置一个规则，在出现三个以上故障节点时向您发出警报。另一种方法是在不到 70%的节点处于活动状态时发出警报。为此设置常规检查和警报检查是一个好主意。类型:关键型和常规型
*   当我们配置名称节点时，我们已经指定了这个进程可以消耗的最大内存量。要监控内存使用状态，需要查看`HeapMemoryUsage.max`和`HeapMemoryUsage.used`状态变量。如果使用的内存将超过最大名称节点内存限制，进程将因“内存不足”错误而崩溃。监控这些变量比较棘手，因为随着垃圾收集的发生，`HeapMemoryUsage.used`的值会上下浮动。您可能需要监控一段时间内的平均值，以准确了解当前的内存使用情况。类型:关键

## 日志节点检查

日志节点是特定于名称节点高可用性实现的服务。没有太多特定于服务的指标需要监控。您需要确保日志节点进程正在运行，不会耗尽内存或磁盘空间，等等。由于日志节点通常与其他服务并置，因此不需要重复已经存在的主机级检查。

以下是要在日志节点上监控的主机级资源列表:

*   使用 ping 检查服务器是否可访问。类型:关键
*   检查 editlog 卷上的磁盘空间。类型:关键
*   检查服务器上的交换使用情况。类型:关键

以下检查特定于日志节点流程:

*   **确保服务正在运行**:这可以通过从操作系统角度监控流程，或者确保 JMX 指标页面返回预期结果来实现。类型:关键
*   **监控内存使用情况**:和 NameNode 的情况一样，需要查看的状态变量有`HeapMemoryUsage.used`和`HeapMemoryUsage.max`。类型:关键

## 动物园管理员检查

*   ZooKeeper 是一个独立的项目，在 Hadoop 部署中用于各种目的。我们在设置中使用它的原因之一是为了支持带有名称节点高可用性的故障转移过程。如果不跟踪哪个名称节点是主要的，哪个是次要的，可能会出现两个节点都试图更新文件系统状态而导致损坏的情况。
*   ZooKeeper is a distributed system, which is designed to tolerate failure of several nodes. It is critical to monitor how many nodes in ZooKeeper cluster are alive at any given moment.

    ### 注

    如果你想让你的 ZooKeeper 集群容忍 N 台机器的故障，你需要配置 2 * N + 1 台服务器。

*   不幸的是，ZooKeeper 没有为其内部指标提供类似的 HTTP 接口。相反，您可以使用 telnet 等工具连接到服务端口，并执行特定的命令来打印服务状态指标:

    ```sh
    # telnet localhost 2181
    Trying ::1...
    Connected to localhost.
    Escape character is '^]'.
    mntr
    zk_version  3.4.5-cdh4.3.0--1, built on 05/28/2013 02:01 GMT
    zk_avg_latency  0
    zk_max_latency  196
    zk_min_latency  0
    zk_packets_received  28099
    zk_packets_sent  28097
    zk_num_alive_connections  1
    zk_outstanding_requests  0
    zk_server_state  leader
    zk_znode_count  10
    zk_watch_count  0
    zk_ephemerals_count  1
    zk_approximate_data_size  365
    zk_open_file_descriptor_count  30
    zk_max_file_descriptor_count  1024
    zk_followers  2
    zk_synced_followers  2
    zk_pending_syncs  0

    ```

`mntr`命令是【ZooKeeper 理解的命令之一，它基本上向你展示了服务状态。如果你连接到集群领导者，你会通过查看`zk_synced_followers`线看到活跃追随者的数量。如果该指标低于 ZooKeeper 冗余阈值，则应触发警报。

如果您使用专用的 ZooKeeper 服务器，您还需要实现基本的主机级检查。

# 监控 MapReduce

说到监控当前 Hadoop 实现中的 MapReduce 状态，所有需要的指标都可以在 JobTracker 级别获得。没有理由监视单个任务跟踪器，至少在警报级别上。应定期发送关于存活和死亡任务跟踪器数量的报告，以监控整体框架的运行状况。

## 作业跟踪器检查

以下是要在作业跟踪器上监控的主机级资源列表:

*   使用 ping 检查服务器是否可到达 。类型:关键
*   检查日志和系统卷上的磁盘空间。JobTracker 不会在本地文件系统上保留状态，但是由于磁盘空间不足而无法写入日志文件会导致问题。类型:关键
*   检查服务器上的交换使用情况。 类型:临界

以下检查特定于作业跟踪器流程:

*   监控内存使用情况。您可以通过检查`HeapMemoryUsage.used`和`HeapMemoryUsage.max`变量来监控作业跟踪器的内存使用情况。类型:关键
*   检查`SummaryJson.nodes`和`SummaryJson.alive`状态变量将让您了解在任何给定时刻任务跟踪器的哪个部分可用。该指标没有严格的阈值。即使只有一个任务跟踪器可用，您的作业也会运行，但是性能显然会显著下降。根据您的群集大小选择一个阈值，并根据故障趋势随时间进行调整。类型:关键

如果某些工作节点经常报告性能缓慢或经常失败，JobTracker 可以将它们列入黑名单。您应该通过查看`SummaryJson.blacklisted`指标来监控黑名单任务跟踪器的总数。类型:关键

# 用神经节监控 Hadoop

虽然 Nagios 或任何其他运营监控系统会在出现问题时发出警报，但能够绘制各种集群指标并探索趋势也非常有用。 **Ganglia** 是一个开源软件包，专门设计用于监控大型集群。它通过 web 界面提供对数据的访问，可以跨多台机器聚合度量，等等。

要启用发送到 Ganglia 统计信息收集守护程序的 Hadoop 指标，您需要在`/etc/hadoop/conf/Hadoop-metrics2.properties`中添加以下选项:

```sh
*.sink.ganglia.class=org.apache.hadoop.metrics2.sink.ganglia.GangliaSink31
*.sink.ganglia.period=10
*.sink.ganglia.supportsparse=true
*.sink.ganglia.slope=jvm.metrics.gcCount=zero,jvm.metrics.memHeapUsedM=both
*.sink.ganglia.dmax=jvm.metrics.threadsBlocked=70,jvm
```

此外，您需要将所有接收器指向您的 Ganglia 收集器服务器:

```sh
namenode.sink.ganglia.servers=gangliahost:8649
datanode.sink.ganglia.servers=gangliahost:8649
jobtracker.sink.ganglia.servers=gangliahost:8649
tasktracker.sink.ganglia.servers=gangliahost:8649
maptask.sink.ganglia.servers=gangliahost:8649
reducetask.sink.ganglia.servers=gangliahost:8649
```

# 总结

Hadoop 没有提供任何现成的监控功能，但它确实揭示了许多关于其组件内部状态的信息。您可以使用现有的开源工具来监控这些指标，并在关键事件发生时向您发出警报。与传统的数据库系统不同，不是每个组件故障都应该以相同的优先级来处理，在实现监控解决方案时，您应该记住这一点。将检查分为关键组和常规组将允许您以相当大的灵活性监控 Hadoop 集群。

到目前为止，我们一直在讨论如何构建和托管您自己的 Hadoop 集群。在许多使用案例中，拥有和维护完整的 Hadoop 基础架构并不是最佳选择。这种方法的替代方法是使用云基础设施。在下一章中，我们将回顾一下，如果您想在云中托管集群，您可以选择哪些选项。