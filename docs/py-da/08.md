# 八、使用数据库

本章介绍各种数据库(关系数据库和 NoSQL 数据库)以及相关的应用编程接口。一个**关系数据库**是一个包含由数据项之间的关系组织的数据的表的集合的数据库。可以在表中的每一行和另一个表中的一行之间建立关系。关系也可以是表内的列之间的关系(显然，表内的列必须是相关的，例如，客户表中的名称列和地址列)以及其他表中的列之间的连接。

**不仅是 SQL** ( **NoSQL** )数据库在大数据和 web 应用中被频繁使用。NoSQL 系统可能允许使用类似 SQL 的查询语言。NoSQL 数据库允许以比关系模型更灵活的方式存储数据。这可能意味着没有数据库模式或灵活的数据库模式。当然，灵活性和速度可能是有代价的，例如对一致事务的有限支持。NoSQL 数据库可以使用字典样式或面向列的样式存储数据，或者将其存储为文档、对象、图形、元组或其组合。本章的主题如下:

*   使用 sqlite3 实现轻量级访问
*   从 Pandas 那里访问数据库
*   sqllcemy(SQL 语法)
*   小马蛇
*   面向懒人的数据集数据库
*   PyMongo 和 MongoDB
*   Redis 中的回滚数据
*   将数据存储在 memcached 中
*   阿帕奇·卡桑德拉

# SQLite 3 轻量级访问

**SQLite** 是一个非常流行的关系数据库。它非常轻量级，被许多应用程序使用，例如像 Mozilla Firefox 这样的网络浏览器。安卓系统中的大多数应用程序都使用 SQLite 作为数据存储。

标准 Python 发行版中的`sqlite3`模块可用于处理 SQLite 数据库。借助`sqlite3`，我们可以将数据库存储在文件中，也可以将其保存在内存中。对于这个例子，我们将做后者。导入`sqlite3`如下:

```py
import sqlite3

```

需要连接到数据库才能继续。如果我们想将数据库存储在一个文件中，我们可以提供一个文件名。相反，请执行以下操作:

```py
with sqlite3.connect(":memory:") as con:
```

`with`语句是标准的 Python，依赖于特殊上下文管理器类中`__exit__()`方法的存在。使用此语句，我们不需要显式关闭连接。上下文管理器会自动关闭连接。连接到数据库后，我们需要一个游标，顺便说一下，这通常是它处理数据库的方式。**数据库光标**至少在概念上类似于文本编辑器中的光标。我们还需要关闭光标。按如下方式创建光标:

```py
c = con.cursor() 

```

我们现在可以立即创建一个表。通常，您必须先创建一个数据库，或者让数据库专家为您创建。在本章中，您不仅需要了解 Python，还需要了解 SQL。 **SQL** 是数据库查询和操作的专用语言。本章没有足够的篇幅来完整描述 SQL，但是基本的 SQL 应该足够容易让你学会(更多信息，请访问[http://www.w3schools.com/sql/](http://www.w3schools.com/sql/))。为了创建一个表，我们将一个 SQL 字符串传递给游标，如下所示:

```py
c.execute('''CREATE TABLE sensors(date text, city text,  
code text, sensor_id real, temperature real)''') 

```

这应该会创建一个包含几个名为`sensors`的列的表。在该字符串中，`text`和`real`是对应于字符串和数值的数据类型。我们可以相信表的创建工作正常。如果出了问题，我们会得到一个错误。在数据库中列出表是依赖于数据库的。通常有一个特殊的表或一组表包含关于用户表的元数据。按如下方式列出 SQLite 表:

```py
for table in c.execute("SELECT name FROM sqlite_master  
WHERE type = 'table'"): 
print("Table", table[0]) 

```

不出所料，我们得到了以下输出:

```py
Table sensors

```

让我们插入和查询一些随机数据如下:

```py
c.execute("INSERT INTO sensors VALUES ('2016-11-05', 
'Utrecht','Red',42,15.14)") 
c.execute("SELECT * FROM sensors") 
print(c.fetchone()) 

```

我们插入的记录应打印如下:

```py
(u'2016-11-05', u'Utrecht', u'Red', 42.0, 15.14)

```

当我们不再需要桌子时，我们可以把它放下。这很危险，所以你必须绝对确定你不需要这张桌子。一旦表被删除，除非对其进行备份，否则无法恢复。删除该表，并显示删除后的表数，如下所示:

```py
con.execute("DROP TABLE sensors") 
print("# of tables", c.execute("SELECT COUNT(*)  
FROM sqlite_master WHERE type = 'table'").fetchone()[0]) 

```

我们得到以下输出:

```py
# of tables 0

```

以下代码请参考本书代码包中的`ch-08.ipynb`文件:

```py
import sqlite3 

with sqlite3.connect(":memory:") as con: 
    c = con.cursor() 
    c.execute('''CREATE TABLE sensors(date text, city text,  
code text, sensor_id real, temperature real)''') 

    for table in c.execute("SELECT name FROM sqlite_master  
WHERE type = 'table'"): 
        print("Table", table[0]) 

    c.execute("INSERT INTO sensors VALUES ('2016-11-05', 
'Utrecht','Red',42,15.14)") 
    c.execute("SELECT * FROM sensors") 
    print(c.fetchone()) 
    con.execute("DROP TABLE sensors") 

    print("# of tables", c.execute("SELECT COUNT(*)  
FROM sqlite_master WHERE type = 'table'").fetchone()[0]) 

    c.close() 

```

# 访问 Pandas 的数据库

我们可以给 Pandas 一个数据库连接，比如前面例子中的那个，或者一个 SQLAlchemy 连接。我们将在本章后面的部分讨论后者。我们将加载活动数据的 statsmodels，就像我们在上一章[第 7 章](07.html "Chapter 7. Signal Processing and Time Series")、*信号处理和时间序列*中所做的那样:

1.  Create a list of tuples to form the Pandas DataFrame:

    ```py
            rows = [tuple(x) for x in df.values] 

    ```

    与前面的示例相反，创建表时不指定数据类型:

    ```py
                con.execute("CREATE TABLE sunspots(year, sunactivity)") 

    ```

2.  The `executemany()` method executes multiple statements; in this case, we will be inserting records from a list of tuples. Insert all the rows into the table and show the row count as follows:

    ```py
            con.executemany("INSERT INTO sunspots(year, sunactivity) VALUES 
            (?, ?)", rows) 
            c.execute("SELECT COUNT(*) FROM sunspots") 
            print(c.fetchone()) 

    ```

    表格中的行数打印如下:

    ```py
                (309,)

    ```

3.  The `rowcount` attribute of the result of an `execute()` call gives the number of affected rows. This attribute is somewhat quirky and depends on your SQLite version. On the other hand, an SQL query, as shown in the previous code snippet, is unambiguous. Delete the records where the number of events is more than `20`:

    ```py
            print("Deleted", con.execute("DELETE FROM sunspots where 
            sunactivity > 20").rowcount, "rows") 

    ```

    应打印以下内容:

    ```py
                Deleted 217 rows

    ```

4.  如果我们有 Pandas 的数据库连接，我们可以执行查询并使用`read_sql()`函数返回 Pandas 数据帧。选择记录直到`1732`，如下所示:

```py
       print(read_sql("SELECT * FROM sunspots where year < 1732", con)) 

```

最终结果是以下 Pandas 数据帧:

```py
    year  sunactivity 
0   1700            5 
1   1701           11 
2   1702           16 
3   1707           20 
4   1708           10 
5   1709            8 
6   1710            3 
7   1711            0 
8   1712            0 
9   1713            2 
10  1714           11 
11  1723           11 

[12 rows x 2 columns] 

```

以下代码请参考本书代码包中的`ch-08.ipynb`文件:

```py
import statsmodels.api as sm 
from pandas.io.sql import read_sql 
import sqlite3 

with sqlite3.connect(":memory:") as con: 
    c = con.cursor() 

    data_loader = sm.datasets.sunspots.load_pandas() 
    df = data_loader.data 
    rows = [tuple(x) for x in df.values] 

    con.execute("CREATE TABLE sunspots(year, sunactivity)") 
    con.executemany("INSERT INTO sunspots(year, sunactivity) VALUES (?, 
?)", rows) 
    c.execute("SELECT COUNT(*) FROM sunspots") 
    print(c.fetchone()) 
    print("Deleted", con.execute("DELETE FROM sunspots where sunactivity > 20").rowcount, "rows") 

    print(read_sql("SELECT * FROM sunspots where year < 1732", con)) 
    con.execute("DROP TABLE sunspots") 

    c.close() 

```

# SQL 语法

**SQLAlchemy** 以其基于设计模式的**对象关系映射** ( **ORM** )而闻名，其中 Python 类被映射到数据库表。实际上，这意味着增加了一个额外的抽象层，因此我们使用 SQLAlchemy API 与数据库对话，而不是发出 SQL 命令。SQLAlchemy 负责幕后的细节。缺点是必须学习 API，可能要付出很小的性能代价。在本节中，您将学习如何设置 SQLAlchemy，以及如何用 SQLAlchemy 填充和查询数据库。

## 安装和设置 SQLAlchemy

以下是安装 SQLAlchemy 的命令:

```py
$ pip3 install sqlalchemy

```

在撰写本文时，SQLAlchemy 的最新版本是 1.1.4。SQLAlchemy 的下载页面在[http://www.sqlalchemy.org/download.html](http://www.sqlalchemy.org/download.html)提供，链接到安装程序和代码库。SQLAlchemy 在[http://www.sqlalchemy.org/library.html](http://www.sqlalchemy.org/library.html)也有大量可用的文档。

SQLAlchemy 要求我们定义一个超类，如下所示:

```py
from sqlalchemy.ext.declarative import declarative_base 
Base = declarative_base() 

```

在这一节和下一节中，我们将使用一个包含两个表的小型数据库。第一个表定义了一个观察站。第二个表表示工作站中的传感器。每个工作站都有零个、一个或多个传感器。电台由一个整数标识来标识，该标识由数据库自动生成。电台也是由一个名字来标识的，这个名字是唯一的，也是强制性的。

传感器也有一个整数标识。我们跟踪传感器测量的最后一个值。这个值可以有一个相关的乘数。本节描述的设置在本书的代码包中的`ch-08.ipynb`文件中表达(您不必运行这个脚本，但本章后面的代码会用到它):

```py
from sqlalchemy import Column, ForeignKey, Integer, String, Float 
from sqlalchemy.ext.declarative import declarative_base 
from sqlalchemy.orm import relationship 
from sqlalchemy import create_engine 
from sqlalchemy import UniqueConstraint 

Base = declarative_base() 
class Station(Base): 
    __tablename__ = 'station' 
    id = Column(Integer, primary_key=True) 
    name = Column(String(14), nullable=False, unique=True) 

    def __repr__(self): 
        return "Id=%d name=%s" %(self.id, self.name) 

class Sensor(Base): 
    __tablename__ = 'sensor' 
    id = Column(Integer, primary_key=True) 
    last = Column(Integer) 
    multiplier = Column(Float) 
    station_id = Column(Integer, ForeignKey('station.id')) 
    station = relationship(Station) 

    def __repr__(self): 
       return "Id={:d} last={:d} multiplier={:.1f} station_id=
       {:d}".format( 
       self.id,self.last, self.multiplier, self.station_id)  

if __name__ == "__main__": 
    print("This script is used by code further down in this notebook.") 

```

## 用 SQLAlchemy 填充数据库

创建表将推迟到下一节。在本节中，我们将准备一个脚本来填充数据库(您不必运行这个；它由后面一节中的脚本使用)。有了`DBSession`对象，我们可以将数据插入到表中。也需要一个引擎，但是创建引擎也将推迟到下一节:

1.  按如下方式创建`DBSession`对象:

    ```py
            Base.metadata.bind = engine 

            DBSession = sessionmaker(bind=engine) 
            session = DBSession() 

    ```

2.  Let's create two stations:

    ```py
            de_bilt = Station(name='De Bilt') 
            session.add(de_bilt) 
            session.add(Station(name='Utrecht')) 
            session.commit() 
            print("Station", de_bilt) 

    ```

    在我们提交会话之前，不会插入行。为第一站打印以下内容:

    ```py
                Station Id=1 name=De Bilt

    ```

3.  Similarly, insert a `Sensor` record as follows:

    ```py
            temp_sensor = Sensor(last=20, multiplier=.1, station=de_bilt) 
            session.add(temp_sensor) 
            session.commit() 
            print("Sensor", temp_sensor) 

    ```

    传感器在第一站；因此，我们得到以下打印输出:

    ```py
               Sensor Id=1 last=20 multiplier=0.1 station_id=1

    ```

数据库填充代码可以在本书的代码包中的`ch-08.ipynb`文件中找到(同样，您不需要运行该代码；它被另一个脚本使用):

```py
from sqlalchemy import create_engine 
from sqlalchemy.orm import sessionmaker 

from alchemy_entities import Base, Sensor, Station 

def populate(engine): 
    Base.metadata.bind = engine 

    DBSession = sessionmaker(bind=engine) 
    session = DBSession() 

    de_bilt = Station(name='De Bilt') 
    session.add(de_bilt) 
    session.add(Station(name='Utrecht')) 
    session.commit() 
    print("Station", de_bilt) 

    temp_sensor = Sensor(last=20, multiplier=.1, station=de_bilt) 
    session.add(temp_sensor) 
    session.commit() 
    print("Sensor", temp_sensor) 

if __name__ == "__main__": 
    print("This script is used by code further down in this notebook") 

```

## 用 SQLAlchemy 查询数据库

发动机由 URI 发动机制造，如下所示:

```py
engine = create_engine('sqlite:///demo.db') 

```

在这个 URI 中，我们指定使用 SQLite，数据存储在`demo.db`文件中。使用我们刚刚创建的引擎创建`station`和`sensor`表:

```py
Base.metadata.create_all(engine) 

```

对于 SQLAlchemy 查询，我们再次需要一个`DBSession`对象，如前一节所示。

选择`station`表中的第一行:

```py
station = session.query(Station).first() 

```

按如下方式选择所有电台:

```py
print("Query 1", session.query(Station).all()) 

```

输出如下:

```py
Query 1 [Id=1 name=De Bilt, Id=2 name=Utrecht]

```

如下选择所有传感器:

```py
print("Query 2", session.query(Sensor).all()) 

```

输出如下:

```py
Query 2 [Id=1 last=20 multiplier=0.1 station_id=1]

```

选择属于第一站的第一个传感器:

```py
print("Query 3",session.query(Sensor).filter(Sensor.station == station).one()) 

```

输出如下:

```py
Query 3 Id=1 last=20 multiplier=0.1 station_id=1

```

我们可以用 Pandas`read_sql()`方法再次查询:

```py
print(read_sql("SELECT * FROM station", engine.raw_connection()) 

```

您将获得以下输出:

```py
       id     name
    0   1  De Bilt
    1   2  Utrecht

    [2 rows x 2 columns]

```

检查本书代码包中的`ch-08.ipynb`文件:

```py
from alchemy_entities import Base, Sensor, Station 
from populate_db import populate 
from sqlalchemy import create_engine 
from sqlalchemy.orm import sessionmaker 
import os 
from pandas.io.sql import read_sql 

engine = create_engine('sqlite:///demo.db') 
Base.metadata.create_all(engine) 
populate(engine) 
Base.metadata.bind = engine 
DBSession = sessionmaker() 
DBSession.bind = engine 
session = DBSession() 

station = session.query(Station).first() 

print("Query 1", session.query(Station).all()) 
print("Query 2", session.query(Sensor).all()) 
print("Query 3", session.query(Sensor).filter(Sensor.station == station).one()) 
print(read_sql("SELECT * FROM station", engine.raw_connection())) 

try: 
    os.remove('demo.db') 
    print("Deleted demo.db") 
except OSError: 
    pass 

```

# Pony 蠕虫

**Pony ORM** 是另一个 Python ORM 包。Pony ORM 是用纯 Python 编写的，具有自动查询优化和 GUI 数据库模式编辑器。它还支持自动事务管理、自动缓存和复合键。Pony ORM 使用 Python 生成器表达式，这些表达式被翻译成 SQL。按照以下步骤安装:

```py
$ pip3 install pony

```

导入我们在这个例子中需要的包。参考本书代码包中的`pony_ride.py`文件:

```py
from pony.orm import Database, db_session  
import statsmodels.api as sm 

```

创建内存中的 SQLite 数据库:

```py
db = Database('sqlite', ':memory:') 

```

加载`sunspots`数据并用 Pandas`DataFrame.to_sql`功能写入数据库:

```py
with db_session: 
    data_loader = sm.datasets.sunspots.load_pandas() 
    df = data_loader.data 
    df.to_sql("sunspots", db.get_connection()) 
    print(db.select("count(*) FROM sunspots")) 

```

`sunspots`表中的行数打印如下:

```py
[309]

```

# 数据集——懒人数据库

**数据集**是一个 Python 库，基本上是 SQLAlchemy 的包装器。它号称好用到连懒人都喜欢。

按照以下步骤安装`dataset`:

```py
$ pip3 install dataset

```

创建一个 SQLite 内存数据库并连接到它:

```py
import dataset 
db = dataset.connect('sqlite:///:memory:') 

```

创建一个名为`books`的表格:

```py
table = db["books"] 

```

实际上，数据库中的表还没有创建，因为我们没有指定任何列。我们只创建了一个相关对象。通过调用`insert()`方法自动创建表模式。给`insert()`方法字典加上书名:

```py
table.insert(dict(, author='Ivan Idris')) 
table.insert(dict(,  
author='Ivan Idris')) 
table.insert(dict(,  
author='Ivan Idris')) 

```

按如下方式打印表格中的行:

```py
for row in db['books']: 
   print(row) 

```

将打印以下内容:

```py
<dataset.persistence.util.ResultIter object at 0x10d4bf550>  
OrderedDict([('id', 1), ('title', "NumPy Beginner's Guide"), ('author', 'Ivan Idris')])  
OrderedDict([('id', 2), ('title', 'NumPy Cookbook'), ('author', 'Ivan Idris')])  
OrderedDict([('id', 3), ('title', 'Learning NumPy'), ('author', 'Ivan Idris')]) 

```

我们可以很容易地用下面的行显示数据库中的表:

```py
print("Tables", db.tables) 

```

以下是前面代码的输出:

```py
Tables ['books']

```

以下是本书代码包中`ch-08.ipynb`文件的内容:

```py
import dataset 

db = dataset.connect('sqlite:///:memory:') 
table = db["books"] 
table.insert(dict(, author='Ivan Idris')) 
table.insert(dict(, author='Ivan Idris')) 
table.insert(dict(, author='Ivan Idris')) 
for row in db['books']: 
   print(row) 

print("Tables", db.tables) 

```

# PyMongo 和 MongoDB

是一个面向 NoSQL 文档的数据库。这些文档以类似 JSON 的 BSON 格式存储。您可以从[http://www.mongodb.org/downloads](http://www.mongodb.org/downloads)下载 MongoDB 发行版。安装应该只是打开一个压缩的归档文件。撰写本文时的版本是 3.4.0。在发行版的`bin`目录中，我们会找到`mongod`文件，启动服务器。蒙古数据库希望找到一个`/data/db`目录。这是存储数据的目录。我们可以从命令行指定另一个目录，如下所示:

```py
$ mkdir /tmp/db

```

从包含其二进制可执行文件的目录启动数据库:

```py
./mongod --dbpath /tmp/db

```

我们需要保持这个进程运行，以便能够查询数据库。 **PyMongo** 是 MongoDB 的 Python 驱动。按照以下步骤安装 PyMongo:

```py
$ pip3 install pymongo

```

连接到 MongoDB 测试数据库:

```py
from pymongo import MongoClient 
client = MongoClient() 
db = client.test_database 

```

请记住，我们可以从 Pandas 数据帧创建 JSON。创建 JSON 并将其存储在 MongoDB 中:

```py
data_loader = sm.datasets.sunspots.load_pandas() 
df = data_loader.data 
rows = json.loads(df.T.to_json()).values() 
db.sunspots.insert(rows) 

```

查询我们刚刚创建的文档:

```py
cursor = db['sunspots'].find({}) 
df =  pd.DataFrame(list(cursor)) 
print(df) 

```

这将打印整个 Pandas 数据帧。参考本书代码包中的`ch-08.ipynb`文件:

```py
from pymongo import MongoClient 
import statsmodels.api as sm 
import json 
import pandas as pd 

client = MongoClient() 
db = client.test_database 

data_loader = sm.datasets.sunspots.load_pandas() 
df = data_loader.data 
rows = json.loads(df.T.to_json()).values() 
db.sunspots.insert_many(rows) 

cursor = db['sunspots'].find({}) 
df =  pd.DataFrame(list(cursor)) 
print(df) 

db.drop_collection('sunspots') 

```

# 复读资料中的

**远程词典服务器** ( **Redis** )是一个内存中的键值数据库，用 c 编写，在内存模式下，Redis 速度极快，读写速度几乎一样快。Redis 遵循发布/订阅模型，并使用 Lua 脚本作为存储过程。发布/订阅利用客户端可以订阅的频道来接收消息。在写这本书的时候，我已经安装了 Redis 3 . 2 . 6 版本。Redis 可以从[http://redis.io/](http://redis.io/)的 Redis 主页下载。安装 Redis 分发版后，发出以下命令运行服务器:

```py
$ src/redis-server

```

现在让我们安装一个 Python 驱动程序:

```py
$ pip3 install redis

```

当你意识到 Redis 是一个巨大的字典时，使用它是非常容易的。然而，Redis 确实有其局限性。有时，将复杂的对象存储为 JSON 字符串(或其他格式)会很方便。这就是我们要用 Pandas 数据框做的。按照以下方式连接到 Redis:

```py
r = redis.StrictRedis()

```

使用 JSON 字符串创建键值对:

```py
r.set('sunspots', data) 

```

用以下行检索数据:

```py
blob = r.get('sunspots') 

```

代码很简单，在本书代码包的`ch-08.ipynb`文件中给出:

```py
import redis 
import statsmodels.api as sm 
import pandas as pd 

r = redis.StrictRedis() 
data_loader = sm.datasets.sunspots.load_pandas() 
df = data_loader.data 
data = df.T.to_json() 
r.set('sunspots', data) 
blob = r.get('sunspots') 
print(pd.read_json(blob)) 

```

# 在 memcache 中存储数据

memcache 是一个内存中的键值数据库存储，就像 Redis 一样。安装并运行 memcached 服务器后，使用以下命令安装 memcache Python 客户端:

```py
$ pip3 install python3-memcache

```

`ch-08.ipynb`文件中的代码创建一个 memcache 客户端，然后将数据帧存储到 memcache，自动过期值为`600`秒。该代码类似于 Redis 的代码:

```py
import memcache 
import statsmodels.api as sm 
import pandas as pd 

client = memcache.Client([('127.0.0.1', 11211)]) 
data_loader = sm.datasets.sunspots.load_pandas() 
df = data_loader.data 
data = df.T.to_json() 
client.set('sunspots', data, time=600) 
print("Stored data to memcached, auto-expire after 600 seconds") 
blob = client.get('sunspots') 
print(pd.read_json(blob)) 

```

# 阿帕奇·卡珊德拉

**Apache Cassandra** 混合了键值和传统关系数据库的特性。在传统的关系数据库中，表的列是固定的。然而，在 Cassandra 中，同一表中的行可以有不同的列。因此，Cassandra 是面向列的，因为它允许每行都有一个灵活的模式。列被组织在所谓的列族中，这相当于关系数据库中的表。Cassandra 不支持连接和子查询。卡珊德拉可以从[http://cassandra.apache.org/download/](http://cassandra.apache.org/download/)下载。在撰写本书时，我们使用了 Cassandra 版本。请参考[http://wiki.apache.org/cassandra/GettingStarted](http://wiki.apache.org/cassandra/GettingStarted)开始:

1.  从命令行运行服务器，如下所示:

    ```py
    $ bin/cassandra-f

    ```

2.  创建在`conf/cassandra.yaml`中列出的目录，或者如下调整它们:

    ```py
    data_file_directories:
    /tmp/lib/cassandra/data
    commitlog_directory: /tmp/lib/cassandra/commitlog
    saved_caches_directory: /tmp/lib/cassandra/saved_caches

    ```

3.  如果不想保留数据，以下命令很有意义:

    ```py
    $ mkdir -p /tmp/lib/cassandra/data
    $ mkdir -p /tmp/lib/cassandra/commitlog
    $ mkdir -p /tmp/lib/cassandra/saved_caches

    ```

4.  使用以下命令安装 Python 驱动程序:

    ```py
    $ pip3 install cassandra-driver

    ```

5.  现在是时候编码了。连接到集群并创建会话，如下所示:

    ```py
            cluster = Cluster()
            session = cluster.connect()

    ```

6.  卡珊德拉有钥匙空间的概念。键空间保存表。卡珊德拉有自己的查询语言**卡珊德拉查询语言** ( **CQL** )。CQL 和 SQL 非常相似。创建键空间并设置会话以使用它:

    ```py
            session.execute("CREATE KEYSPACE IF NOT EXISTS mykeyspace WITH   
            REPLICATION = { 'class' : 'SimpleStrategy', 
            'replication_factor' : 1 };")
            session.set_keyspace('mykeyspace')

    ```

7.  现在，为`sunspots`数据创建一个表:

    ```py
            session.execute("CREATE TABLE IF NOT EXISTS sunspots (year   
            decimal PRIMARY KEY, sunactivity decimal);")

    ```

8.  创建一个我们将在循环中使用的语句，将数据行作为元组插入:

    ```py
            query = SimpleStatement( 
                "INSERT INTO sunspots (year, sunactivity) VALUES (%s, %s)", 
                consistency_level=ConsistencyLevel.QUORUM) 

    ```

9.  下一行插入数据:

    ```py
            for row in rows: 
                session.execute(query, row) 

    ```

10.  Get the count of the rows in the table:

    ```py
            rows=session.execute("SELECT COUNT(*) FROM sunspots") 
            for row in rows: 
                print(row) 

    ```

    这将按如下方式打印行数:

    ```py
            [Row(count=309)]

    ```

11.  Drop the keyspace and shut down the cluster:

    ```py
            session.execute('DROP KEYSPACE mykeyspace') 
            cluster.shutdown() 

    ```

    参考本书代码包中的`ch-08.ipynb`文件:

    ```py
    from cassandra import ConsistencyLevel 
    from cassandra.cluster import Cluster 
    from cassandra.query import SimpleStatement 
    import statsmodels.api as sm 

    cluster = Cluster() 
    session = cluster.connect() 
    session.execute("CREATE KEYSPACE IF NOT EXISTS mykeyspace WITH REPLICATION = { 'class' : 'SimpleStrategy', 'replication_factor' : 1 };") 
    session.set_keyspace('mykeyspace') 
    session.execute("CREATE TABLE IF NOT EXISTS sunspots (year decimal PRIMARY KEY, sunactivity decimal);") 

    query = SimpleStatement( 
        "INSERT INTO sunspots (year, sunactivity) VALUES (%s, %s)", 
        consistency_level=ConsistencyLevel.QUORUM) 

    data_loader = sm.datasets.sunspots.load_pandas() 
    df = data_loader.data 
    rows = [tuple(x) for x in df.values] 
    for row in rows: 
        session.execute(query, row) 

    rows=session.execute("SELECT COUNT(*) FROM sunspots") 
    for row in rows: 
        print(row) 

    session.execute('DROP KEYSPACE mykeyspace')  
    cluster.shutdown() 

    ```

# 总结

我们将每年的太阳黑子周期数据存储在不同的关系数据库和 NoSQL 数据库中。

术语*关系*在这里不仅仅指表之间的关系；首先，它与表内各列之间的关系有关；其次，它涉及表之间的连接。

标准 Python 发行版中的`sqlite3`模块可用于处理 SQLite 数据库。我们可以给 Pandas 一个 SQLite 数据库连接或者 SQLAlchemy 连接。

SQLAlchemy 以其基于设计模式的 ORM 而闻名，其中 Python 类被映射到数据库表。ORM 模式是适用于其他面向对象编程语言的通用架构模式。SQLAlchemy 抽象出使用数据库的技术细节，包括编写 SQL。

MongoDB 是一个基于文档的存储，可以保存大量的数据。

在内存模式下，Redis 速度极快，写和读几乎一样快。Redis 是一个键值存储，其功能类似于 Python 字典。

Apache Cassandra 混合了键值和传统关系数据库的特性。它是面向列的，它的列被组织成系列，这相当于关系数据库中的表。Apache Cassandra 中的行不绑定到一组特定的列。

下一章[第 9 章](09.html "Chapter 9. Analyzing Textual Data and Social Media")、*分析文本数据和社交媒体*，介绍了明文数据的分析技术。许多组织和互联网上都有明文数据。一般来说，明文数据是非结构化的，需要一种不同于列表和清理数据的方法。对于分析，我们将使用 NLTK——一个开源的 Python 包。NLTK 非常全面，自带数据集。