# 十一、数据分析的数学和并行技术

程序的并发执行可以显著提高性能。在这一章中，我们将讨论可用于数据科学应用的各种技术。这些范围从低级的数学计算到高级的特定于 API 的选项。

请始终记住，性能增强始于确保实现正确的应用程序功能集。如果应用程序不能满足用户的期望，那么这些改进就是徒劳的。应用程序的架构和使用的算法也比代码增强更重要。总是使用最有效的算法。然后应该考虑代码增强。我们无法在本章中解决更高层次的优化问题；相反，我们将关注代码增强。

许多数据科学应用程序和支持 API 使用矩阵运算来完成任务。通常这些操作隐藏在 API 中，但是有时候我们可能需要直接使用它们。无论如何，理解这些操作是如何被支持的是有益的。为此，我们将解释如何使用几种不同的方法来处理矩阵乘法。

可以使用 Java 线程实现并发处理。开发人员可以使用线程和线程池来改善应用程序的响应时间。当多个 CPU 或 GPU 不可用时，许多 api 会使用线程，就像 **Aparapi** 的情况一样。这里我们不举例说明线程的使用。但是，我们假设读者对线程和线程池有基本的了解。

map-reduce 算法广泛用于数据科学应用。我们将介绍一种使用 Apache 的 Hadoop 实现这种并行处理的技术。Hadoop 是一个支持大型数据集操作的框架，可以大大减少大型数据科学项目所需的处理时间。我们将演示一种计算样本数据集平均值的技术。

有几个著名的 API 支持多处理器，包括 CUDA 和 OpenCL。使用用于 CUDA(**JCuda**)(【http://jcuda.org/】T4)的 **Java 绑定来支持 CUDA。我们不会在这里直接演示这种技术。然而，我们将使用的许多 API 确实支持 CUDA，如果它可用的话，比如 DL4J。我们将简要讨论 OpenCL 以及 Java 是如何支持它的。Aparapi API 提供了更高级别的支持，可能使用多个 CPU 或 GPU，这是没有价值的。我们将演示一个支持矩阵乘法的 Aparapi。**

在本章中，我们将研究如何利用多个 CPU 和 GPU 来加速数据挖掘任务。我们使用的许多 API 已经利用了多处理器的优势，或者至少提供了一种支持 GPU 使用的方法。我们将在本章中介绍其中的一些选项。

云中也广泛支持并发处理。这里讨论的许多技术都在云中使用。因此，我们不会明确说明如何在云中进行并行处理。

# 实现基本矩阵运算

有几种不同类型的矩阵运算，包括简单的加法、减法、标量乘法和各种形式的乘法。为了说明矩阵运算，我们将关注所谓的**矩阵乘积**。这是一种常见的方法，涉及两个矩阵相乘以产生第三个矩阵。

考虑两个矩阵， *A* 和 *B* ，其中矩阵 *A* 有 *n* 行和 *m* 列。矩阵 *B* 将有 *m* 行和 *p* 列。 *A* 和 *B* 的乘积，写成 *AB* ，是一个 *n* 行和 *p* 列的矩阵。将矩阵 *B* 列的 *m* 个条目乘以 *A* 行的 *m* 个条目。这一点在此处有更明确的显示，其中:

![Implementing basic matrix operations](img/image00328.jpeg)

其中产品定义如下:

![Implementing basic matrix operations](img/image00329.jpeg)

我们从矩阵的声明和初始化开始。变量`n`、`m`、`p`代表矩阵的维数。`A`矩阵由`m`表示`n`，`B`矩阵由`p`表示`m`，代表产品的`C`矩阵由`p`表示`n`:

```java
int n = 4; 
int m = 2; 
int p = 3; 

double A[][] = { 
    {0.1950, 0.0311}, 
    {0.3588, 0.2203}, 
    {0.1716, 0.5931}, 
    {0.2105, 0.3242}}; 
double B[][] = { 
    {0.0502, 0.9823, 0.9472}, 
    {0.5732, 0.2694, 0.916}}; 
double C[][] = new double[n][p]; 

```

以下代码序列说明了使用嵌套`for`循环的乘法运算:

```java
for (int i = 0; i < n; i++) { 
    for (int k = 0; k < m; k++) { 
        for (int j = 0; j < p; j++) { 
            C[i][j] += A[i][k] * B[k][j]; 
        } 
    } 
} 

```

以下代码序列格式化输出以显示我们的矩阵:

```java
out.println("\nResult"); 
for (int i = 0; i < n; i++) { 
    for (int j = 0; j < p; j++) { 
        out.printf("%.4f  ", C[i][j]); 
    } 
    out.println(); 
} 

```

结果如下所示:

```java
Result
0.0276  0.1999  0.2132 
0.1443  0.4118  0.5417 
0.3486  0.3283  0.7058 
0.1964  0.2941  0.4964

```

稍后，我们将演示执行相同操作的几种替代技术。接下来，我们将讨论如何使用 DL4J 定制对多处理器的支持。

## 使用 GPU 和 DeepLearning4j

DeepLearning4j 可以与 NVIDIA 提供的 GPU 一起工作。有一些选项可以启用 GPU 的使用，指定应该使用多少 GPU，以及控制 GPU 内存的使用。在本节中，我们将展示如何使用这些选项。这种类型的控件通常可用于其他高级 API。

DL4J 使用 **n 维数组进行 Java**(**ND4J**)(【http://nd4j.org/】T4)进行数值计算。这是一个支持 n 维数组对象和其他数值计算的库，例如线性代数和信号处理。它包括对 GPU 的支持，还集成了 Hadoop 和 Spark。

一个**向量**是一个一维数组，广泛用于神经网络。向量是一种叫做**张量**的数学结构。张量本质上是一个多维数组。我们可以把一个张量想象成一个三维或者多维的数组，每个维度称为一个**秩**。

通常需要将一组多维数字映射到一维数组。这是通过使用定义的顺序展平阵列来实现的。例如，对于二维数组，许多系统将按行列顺序分配数组成员。这意味着第一行被添加到向量中，接着是第二个向量，然后是第三个，依此类推。我们将在*使用 ND4J API* 一节中使用这种方法。

要启用 GPU，需要修改项目的 POM 文件。在 POM 文件的 properties 部分，需要添加或修改`nd4j.backend`标记，如下所示:

```java
<nd4j.backend>nd4j-cuda-7.5-platform</<nd4j.backend> 

```

可以使用`ParallelWrapper`类并行训练模型。训练任务在可用的 CPU/GPU 之间自动分配。该模型被用作`ParallelWrapper`类的`Builder`构造函数的参数，如下所示:

```java
ParallelWrapper parallelWrapper =  
    new ParallelWrapper.Builder(aModel) 
        // Builder methods... 
        .build(); 

```

当执行时，在每个 GPU 上使用模型的副本。在通过`averagingFrequency`方法指定迭代次数之后，模型被平均，然后训练过程继续。

有多种方法可用于配置该类，如下表所示:

| **方法** | **目的** |
| `prefetchBuffer` | 指定用于预取数据的缓冲区的大小 |
| `workers` | 指定要使用的工人数量 |
| `averageUpdaters``averagingFrequency``reportScoreAfterAveraging``useLegacyAveraging` | 控制如何实现平均的各种方法 |

工作线程的数量应该大于可用 GPU 的数量。

与大多数计算一样，使用较低的精度值将加快处理速度。这可以通过`setDTypeForContext`方法来控制，如下图所示。在这种情况下，指定了半精度:

```java
DataTypeUtil.setDTypeForContext(DataBuffer.Type.HALF); 

```

这种支持和更多关于优化技术的细节可以在[http://deeplearning4j.org/gpu](http://deeplearning4j.org/gpu)找到。

# 使用地图缩小

Map-reduce 是一种以并行、分布式方式处理大型数据集的模型。这个模型由一个用于过滤和排序数据的`map`方法和一个用于汇总数据的`reduce`方法组成。map-reduce 框架非常有效，因为它将数据集的处理分布在多个服务器上，同时对较小的数据块执行映射和缩减。当以多线程方式实现时，Map-reduce 提供了显著的性能改进。在这一节中，我们将使用 Apache 的 Hadoop 实现来演示一项技术。在【使用 Java 8 执行 map-reduce 的 一节中，我们将讨论使用 Java 8 流执行 map-reduce 的技术。

Hadoop 是一个为并行计算提供支持的软件生态系统。Map-reduce 作业可以在 Hadoop 服务器上运行，通常设置为集群，以显著提高处理速度。Hadoop 具有在 Hadoop 集群中的节点上运行 map-reduce 操作的跟踪器。每个节点独立运行，跟踪器监控进程并整合每个节点的输出以生成最终输出。下图位于[http://www . developer . com/Java/data/big-data-tool-map-reduce . html](http://www.developer.com/java/data/big-data-tool-map-reduce.html)，展示了带有跟踪器的基本 map-reduce 模型。

## 使用 Apache 的 Hadoop 执行 map-reduce

我们将向您展示一个非常简单的地图缩小应用程序示例。在使用 Hadoop 之前，我们需要下载并提取 Hadoop 应用程序文件。最新版本可以在[http://hadoop.apache.org/releases.html](http://hadoop.apache.org/releases.html)找到。在这个演示中，我们使用的是版本 2.7.3。

您需要设置您的`JAVA_HOME`环境变量。此外，Hadoop 不能容忍长文件路径和路径中的空格，因此请确保将 Hadoop 提取到尽可能简单的目录结构中。

我们将使用一个包含书籍信息的样本文本文件。制表符分隔的文件的每一行都有书名、作者和页数:

```java
Moby Dick  Herman Melville  822 
Charlotte's Web  E.B. White  189
The Grapes of Wrath  John Steinbeck  212
Jane Eyre  Charlotte Bronte  299
A Tale of Two Cities  Charles Dickens  673
War and Peace  Leo Tolstoy  1032
The Great Gatsby  F. Scott Fitzgerald  275

```

我们将使用一个`map`函数来提取标题和页数信息，然后使用一个`reduce`函数来计算数据集中书籍的平均页数。首先，创建一个新的类，`AveragePageCount`。我们将在`AveragePageCount`中创建两个静态类，一个处理 map 过程，一个处理 reduction。

## 绘制地图的方法

首先，我们将创建`TextMapper`类，它将实现`map`方法。这个类继承自`Mapper`类，有两个私有实例变量，`pages`和`bookTitle`。`pages`是一个`IntWritable`对象，`bookTitle`是一个`Text`对象。使用`IntWritable`和`Text`是因为这些对象在被传输到服务器进行处理之前需要被序列化为字节流。这些物体比类似的`int`或`String` 物体占用更少的空间，传输速度更快:

```java
public static class TextMapper 
        extends Mapper<Object, Text, Text, IntWritable> { 

    private final IntWritable pages = new IntWritable(); 
    private final Text bookTitle = new Text(); 

} 

```

在我们的`TextMapper`类中，我们创建了`map`方法。这个方法有三个参数:`key`对象、`Text`对象、`bookInfo`和`Context`。该键允许跟踪器将每个特定的对象映射回正确的作业。对象包含每本书的文本或字符串数据。`Context`保存关于整个系统的信息，并允许该方法报告系统内的进度和更新值。

在`map`方法中，我们使用`split`方法将每条图书信息分解成一个`String`对象数组。我们将变量`bookTitle`设置为数组的位置`0`，并将`pages`设置为存储在位置`2`中的值，然后将其解析为一个整数。然后，我们可以通过上下文写出书名和页数信息，并更新我们的整个系统:

```java
public void map(Object key, Text bookInfo, Context context) 
 throws IOException, InterruptedException { 
        String[] book = bookInfo.toString().split("\t"); 
        bookTitle.set(book[0]); 
        pages.set(Integer.parseInt(book[2])); 
        context.write(bookTitle, pages); 
    } 

```

## 编写 reduce 方法

接下来，我们将编写我们的`AverageReduce`类。这个类扩展了`Reducer`类，并将执行归约过程来计算我们的平均页数。我们为这个类创建了四个变量:一个`FloatWritable`对象存储我们的平均页数，一个浮点`average`保存我们的临时平均值，一个浮点`count`计算我们的数据集中有多少本书，一个整数`sum`计算总页数:

```java
public static class AverageReduce 
        extends Reducer<Text, IntWritable, Text, FloatWritable> { 

    private final FloatWritable finalAvg = new FloatWritable(); 
    Float average = 0f; 
    Float count = 0f; 
    int sum = 0; 

} 

```

在我们的`AverageReduce`类中，我们将创建`reduce`方法。这个方法将一个`Text`键、一个保存代表页面计数的可写整数的`Iterable`对象和`Context`作为输入。我们使用迭代器来处理页面计数，并将每个页面计数添加到我们的总和中。然后我们计算平均值并设置`finalAvg`的值。该信息与一个`Text`对象标签配对，并被写入`Context`:

```java
    public void reduce(Text key, Iterable<IntWritable> pageCnts, 
        Context context)  
            throws IOException, InterruptedException { 

    for (IntWritable cnt : pageCnts) { 
        sum += cnt.get(); 
    } 
    count += 1; 
    average = sum / count; 
    finalAvg.set(average); 
    context.write(new Text("Average Page Count = "), finalAvg); 
} 

```

## 创建并执行新的 Hadoop 作业

我们现在准备在同一个类中创建我们的`main`方法，并执行我们的 map-reduce 过程。为此，我们需要创建一个新的`Configuration`对象和一个新的`Job`。然后，我们设置要在应用程序中使用的重要类。

```java
public static void main(String[] args) throws Exception { 
    Configuration con = new Configuration(); 
    Job bookJob = Job.getInstance(con, "Average Page Count"); 
    ... 
} 

```

我们在`setJarByClass`方法中设置我们的主类`AveragePageCount`。我们分别使用`setMapperClass`和`setReducerClass`方法指定我们的`TextMapper`和`AverageReduce`类。我们还使用`setOutputKeyClass`和`setOutputValueClass`方法指定我们的输出将有一个基于文本的键和一个可写整数:

```java
    bookJob.setJarByClass(AveragePageCount.class); 
    bookJob.setMapperClass(TextMapper.class); 
    bookJob.setReducerClass(AverageReduce.class); 
    bookJob.setOutputKeyClass(Text.class); 
    bookJob.setOutputValueClass(IntWritable.class); 

```

最后，我们使用`addInputPath`和`setOutputPath`方法创建新的输入和输出路径。这些方法都将我们的`Job`对象作为第一个参数，将代表我们的输入和输出文件位置的`Path`对象作为第二个参数。我们于是称之为`waitForCompletion`。一旦这个调用返回 true，我们的应用程序就退出:

```java
    FileInputFormat.addInputPath(bookJob, new Path("C:/Hadoop/books.txt")); 
    FileOutputFormat.setOutputPath(bookJob, new 
        Path("C:/Hadoop/BookOutput")); 
    if (bookJob.waitForCompletion(true)) { 
        System.exit(0); 
    } 

```

要执行应用程序，打开命令提示符并导航到包含我们的`AveragePageCount.class`文件的目录。然后，我们使用以下命令来执行我们的示例应用程序:

```java
hadoop AveragePageCount 

```

当我们的任务运行时，我们会在屏幕上看到关于流程输出的更新信息。我们的输出示例如下所示:

```java
... 
File System Counters
 FILE: Number of bytes read=1132
 FILE: Number of bytes written=569686
 FILE: Number of read operations=0
 FILE: Number of large read operations=0
 FILE: Number of write operations=0
Map-Reduce Framework
 Map input records=7
 Map output records=7
 Map output bytes=136
 Map output materialized bytes=156
 Input split bytes=90
 Combine input records=0
 Combine output records=0
 Reduce input groups=7 
 Reduce shuffle bytes=156 
 Reduce input records=7 
 Reduce output records=7 
 Spilled Records=14 
 Shuffled Maps =1 
 Failed Shuffles=0 
 Merged Map outputs=1 
 GC time elapsed (ms)=11 
 Total committed heap usage (bytes)=536870912 
Shuffle Errors
 BAD_ID=0 
 CONNECTION=0 
 IO_ERROR=0 
 WRONG_LENGTH=0 
 WRONG_MAP=0 
 WRONG_REDUCE=0 
File Input Format Counters
 Bytes Read=249 
File Output Format Counters
 Bytes Written=216 

```

如果我们打开在本地机器上创建的`BookOutput`目录，我们会发现四个新文件。使用文本编辑器打开`part-r-00000`。该文件包含使用并行进程计算的平均页数信息。该输出的示例如下:

```java
Average Page Count =  673.0
Average Page Count =   431.0
Average Page Count =   387.0
Average Page Count =   495.75
Average Page Count =   439.0
Average Page Count =   411.66666
Average Page Count =   500.2857

```

请注意，当每个单独的过程与其他减少过程相结合时，平均值是如何变化的。这与首先计算前两本书的平均值，然后加入第三本书，然后第四本书，以此类推的效果相同。这里的优点当然是平均是以并行方式完成的。如果我们有一个巨大的数据集，我们应该会看到在执行时间上的明显优势。`BookOutput`的最后一行反映了所有七个页面计数的正确和最终平均值。

# 各种数学库

有许多数学库可供 Java 使用。在这一节中，我们将提供几个库的快速和高层次的概述。这些库不一定自动支持多处理器。此外，本节的目的是提供一些关于如何使用这些库的见解。在大多数情况下，它们相对容易使用。

Java 数学库的列表可以在 https://en . Wikipedia . org/wiki/List _ of _ numerical _ libraries # Java 和 https://java-matrix.org/的[找到。我们将演示 jblas、Apache Commons Math 和 ND4J 库的使用。](https://java-matrix.org/)

## 使用 jblas API

jblas API([http://jblas.org/](http://jblas.org/))是一个支持 Java 的数学库。它基于**基础线性代数子程序** ( **布拉斯**)([http://www.netlib.org/blas/](http://www.netlib.org/blas/))和**线性代数包**(**LAPACK**)([http://www.netlib.org/lapack/](http://www.netlib.org/lapack/))，是快速算术计算的标准库。jblas API 提供了这些库的包装器。

下面是如何执行矩阵乘法的演示。我们从矩阵定义开始:

```java
DoubleMatrix A = new DoubleMatrix(new double[][]{ 
    {0.1950, 0.0311}, 
    {0.3588, 0.2203}, 
    {0.1716, 0.5931}, 
    {0.2105, 0.3242}}); 

DoubleMatrix B = new DoubleMatrix(new double[][]{ 
    {0.0502, 0.9823, 0.9472}, 
    {0.5732, 0.2694, 0.916}}); 
DoubleMatrix C; 

```

执行乘法的实际语句非常短，如下所示。对`A`矩阵执行`mmul`方法，其中`B`数组作为参数传递:

```java
C = A.mmul(B); 

```

然后显示生成的`C`矩阵:

```java
for(int i=0; i<C.getRows(); i++) { 
    out.println(C.getRow(i)); 
} 

```

输出应该如下所示:

```java
[0.027616, 0.199927, 0.213192]
[0.144288, 0.411798, 0.541650]
[0.348579, 0.328344, 0.705819]
[0.196399, 0.294114, 0.496353]

```

这个库非常容易使用，并且支持大量的算术运算。

## 使用 Apache Commons 数学应用编程接口

Apache Commons math API([http://commons.apache.org/proper/commons-math/](http://commons.apache.org/proper/commons-math/))支持大量的数学和统计运算。以下示例说明了如何执行矩阵乘法。

我们从声明和初始化`A`和`B`矩阵开始:

```java
double[][] A = { 
    {0.1950, 0.0311}, 
    {0.3588, 0.2203}, 
    {0.1716, 0.5931}, 
    {0.2105, 0.3242}}; 

double[][] B = { 
    {0.0502, 0.9823, 0.9472}, 
    {0.5732, 0.2694, 0.916}}; 

```

Apache Commons 使用`RealMatrix`类来保存一个矩阵。在下面的代码序列中，使用`Array2DRowRealMatrix`构造函数创建了`A`和`B`矩阵的对应矩阵:

```java
RealMatrix aRealMatrix = new Array2DRowRealMatrix(A); 
RealMatrix bRealMatrix = new Array2DRowRealMatrix(B); 

```

使用 multiply 方法进行乘法运算非常简单，如下所示:

```java
RealMatrix cRealMatrix = aRealMatrix.multiply(bRealMatrix); 

```

下一个`for`循环将显示以下结果:

```java
for (int i = 0; i < cRealMatrix.getRowDimension(); i++) { 
    out.println(cRealMatrix.getRowVector(i)); 
} 

```

输出应该如下所示:

```java
{0.02761552; 0.19992684; 0.2131916}
{0.14428772; 0.41179806; 0.54165016}
{0.34857924; 0.32834382; 0.70581912}
{0.19639854; 0.29411363; 0.4963528}

```

## 使用 ND4J API

ND4J(【http://nd4j.org/】)是 DL4J 用来进行算术运算的库。该库也可以直接使用。在本节中，我们将演示如何使用`A`和`B`矩阵执行矩阵乘法。

在执行乘法之前，我们需要将矩阵展平为向量。下面声明并初始化这些向量:

```java
double[] A = { 
    0.1950, 0.0311, 
    0.3588, 0.2203, 
    0.1716, 0.5931, 
    0.2105, 0.3242}; 

double[] B = { 
    0.0502, 0.9823, 0.9472, 
    0.5732, 0.2694, 0.916}; 

```

给定一个向量和维度信息，`Nd4j` class' `create`方法创建一个`INDArray`实例。该方法的第一个参数是向量。第二个参数指定矩阵的维数。最后一个参数指定行和列的布局顺序。这种顺序或者是如`c`所示的行列优先顺序，或者是 FORTRAN 使用的行列优先顺序。行列顺序意味着第一行被分配给向量，接着是第二行，依此类推。

在下面的代码序列中，使用`A`和`B`向量创建了`2INDArray`实例。第一个是由第三个参数`c`指定的使用行优先顺序的`4`行、`2`列矩阵。第二个`INDArray`实例表示`B`矩阵。如果我们想使用行列排序，我们将使用一个`f`来代替。

```java
INDArray aINDArray = Nd4j.create(A,new int[]{4,2},'c'); 
INDArray bINDArray = Nd4j.create(B,new int[]{2,3},'c'); 

```

由`cINDArray`表示的`C`数组随后被声明，并被赋予乘法的结果。`mmul`执行操作:

```java
INDArray cINDArray; 
cINDArray = aINDArray.mmul(bINDArray); 

```

以下序列使用`getRow`方法显示结果:

```java
for(int i=0; i<cINDArray.rows(); i++) { 
   out.println(cINDArray.getRow(i)); 
} 

```

输出应该如下所示:

```java
[0.03, 0.20, 0.21]
[0.14, 0.41, 0.54]
[0.35, 0.33, 0.71]
[0.20, 0.29, 0.50]

```

接下来，我们将提供对 OpenCL API 的概述，该 API 为许多平台上的并发操作提供支持。

# 使用 OpenCL

**开放计算语言**(**OpenCL**)(【https://www.khronos.org/opencl/】T4)支持跨异构平台执行的程序，即可能使用不同厂商和架构的平台。平台可以使用不同的处理单元，包括**中央处理器**(**CPU**)**图形处理器**(**GPU**)**数字信号处理器**(**DSP**)**现场可编程门阵列** ( **FPGA** ，以及其他类型的处理器。

OpenCL 使用基于 C99 的语言对设备进行编程，为编程并发行为提供了标准接口。OpenCL 支持允许用不同语言编写代码的 API。对于 Java，有几个 API 支持开发基于 OpenCL 的语言:

*   OpenCL 的 Java 绑定(**JOCL**)(【http://www.jocl.org/】T4)——这是一个到最初 OpenCL C 实现的绑定，可能会很冗长。
*   JavaCl(【https://code.google.com/archive/p/javacl/】T2)——为 JOCL 提供一个面向对象的接口。
*   Java OpenCL(【http://jogamp.org/jocl/www/】T2)——也提供了一个面向对象的 JOCL 抽象。它不是供客户端使用的。
*   轻量级 Java 游戏库(**LWJGL**)(【https://www.lwjgl.org/】T4)——也为 OpenCL 提供支持，面向 GUI 应用。

此外，Aparapi 提供了对 OpenCL 的高级访问，从而避免了创建 OpenCL 应用程序所涉及的一些复杂性。

运行在处理器上的代码被封装在内核中。多个内核将在不同的计算设备上并行执行。OpenCL 支持不同级别的内存。特定设备可能不支持每个级别。这些级别包括:

*   **全局内存** -由所有计算单元共享
*   **只读存储器** -一般不可写
*   **本地存储器** -由一组计算单元共享
*   **每个元素的私有内存** -通常是一个寄存器

OpenCL 应用程序需要大量的初始代码才能发挥作用。这种复杂性不允许我们提供其使用的详细示例。然而，Aparapi 部分确实提供了一些 OpenCL 应用程序是如何构造的感觉。



# 使用 Aparapi

APAR API([https://github.com/aparapi/aparapi](https://github.com/aparapi/aparapi))是一个支持并发操作的 Java 库。API 支持在 GPU 或 CPU 上运行的代码。GPU 操作使用 OpenCL 执行，CPU 操作使用 Java 线程。用户可以指定使用哪个计算资源。但是，如果 GPU 支持不可用，Aparapi 将恢复到 Java 线程。

API 将在运行时将 Java 字节代码转换成 OpenCL。这使得 API 很大程度上独立于所使用的显卡。该 API 最初是由 AMD 开发的，但已经作为开源软件发布。这反映在基本包名`com.amd.aparari`中。Aparapi 提供了比 OpenCL 更高层次的抽象。

Aparapi 代码位于从`Kernel`类派生的类中。它的`execute`方法将开始操作。这将导致对一个`run`方法的内部调用，该方法需要被覆盖。并发代码放在`run`方法中。`run`方法在不同的处理器上执行多次。

由于 OpenCL 的限制，我们不能使用继承或方法重载。此外，它不喜欢`run`方法中的`println`，因为代码可能运行在 GPI 上。Aparapi 只支持一维数组。使用二维或更多维的数组需要展平为一维数组。对双精度值的支持取决于 OpenCL 版本和 GPU 配置。

当使用 Java 线程池时，它为每个 CPU 内核分配一个线程。包含 Java 代码的内核被克隆，每个线程一个副本。这避免了跨线程访问数据的需要。每个线程都可以访问信息，如全局 ID，以帮助代码执行。内核将等待所有线程完成。

Aparapi 下载可以在 https://github.com/aparapi/aparapi/releases 找到。

## 创建 Aparapi 应用程序

Aparapi 应用程序的基本框架如下所示。它由一个`Kernel`派生类组成，其中`run`方法被重写。在这个例子中，`run`方法将执行标量乘法。这种运算包括将向量的每个元素乘以某个值。

`ScalarMultiplicationKernel`扩展了`Kernel`类。它拥有两个用于保存输入和输出矩阵的实例变量。构造函数将初始化矩阵。`run`方法将执行实际的计算，`displayResult`方法将显示乘法的结果:

```java
public class ScalarMultiplicationKernel extends Kernel { 

    float[] inputMatrix; 

    float outputMatrix []; 

    public ScalarMultiplicationKernel(float inputMatrix[]) { 

        ... 

    } 

    @Override 

    public void run() { 

        ... 

    } 

    public void displayResult() { 

        ... 

    } 

} 

```

此处显示了构造函数:

```java
public ScalarMultiplicationKernel(float inputMatrix[]) { 

    this.inputMatrix = inputMatrix; 

    outputMatrix = new float[this.inputMatrix.length]; 

} 

```

在`run`方法中，我们使用一个全局 ID 来索引矩阵。该代码在每个计算单元上执行，例如 GPU 或线程。为每个计算单元提供唯一的全局 ID，允许代码访问矩阵的特定元素。在这个例子中，输入矩阵的每个元素乘以`2`，然后分配给输出矩阵的相应元素:

```java
public void run() { 

    int globalID = this.getGlobalId(); 

    outputMatrix[globalID] = 2.0f * inputMatrix[globalID]; 

} 

```

`displayResult`方法只是显示`outputMatrix`数组的内容:

```java
public void displayResult() { 

    out.println("Result"); 

    for (float element : outputMatrix) { 

        out.printf("%.4f ", element); 

    } 

    out.println(); 

} 

```

为了使用这个内核，我们需要为`inputMatrix`和它的`size`声明变量。`size`将用于控制执行多少内核:

```java
float inputMatrix[] = {3, 4, 5, 6, 7, 8, 9}; 

int size = inputMatrix.length; 

```

然后使用输入矩阵创建内核，接着调用`execute`方法。该方法启动流程，并最终基于`execute`方法的参数调用`Kernel`类的`run`方法。该参数被称为通行证 ID。虽然在本例中没有使用，但我们将在下一节中使用它。当流程完成时，显示结果输出矩阵，并调用`dispose`方法停止流程:

```java
ScalarMultiplicationKernel kernel =  

        new ScalarMultiplicationKernel(inputMatrix); 

kernel.execute(size); 

kernel.displayResult(); 

kernel.dispose(); 

```

当执行该应用程序时，我们将得到以下输出:

```java
6.0000 8.0000 10.0000 12.0000 14.0000 16.0000 18.000

```

我们可以使用内核类'`setExecutionMode`方法指定执行模式，如下所示:

```java
kernel.setExecutionMode(Kernel.EXECUTION_MODE.GPU); 

```

但是，最好让 Aparapi 来决定执行模式。下表总结了可用的执行模式:

| **执行模式** | **意为** |
| `Kernel.EXECUTION_MODE.NONE` | 不指定模式 |
| `Kernel.EXECUTION_MODE.CPU` | 使用 CPU |
| `Kernel.EXECUTION_MODE.GPU` | 使用 GPU |
| `Kernel.EXECUTION_MODE.JTP` | 使用 Java 线程 |
| `Kernel.EXECUTION_MODE.SEQ` | 使用单循环(用于调试目的) |

接下来，我们将演示如何使用 Aparapi 来执行点积矩阵乘法。

## 使用 Aparapi 进行矩阵乘法

我们将使用在*实现基本矩阵运算*部分中使用的矩阵。我们从`MatrixMultiplicationKernel`类的声明开始，它包含向量声明、一个构造函数、`run`方法和一个`displayResults`方法。通过按行列顺序分配矩阵，矩阵`A`和`B`的向量已被展平为一维数组:

```java
class MatrixMultiplicationKernel extends Kernel { 

    float[] vectorA = { 

        0.1950f, 0.0311f, 0.3588f,  

        0.2203f, 0.1716f, 0.5931f,  

        0.2105f, 0.3242f}; 

    float[] vectorB = { 

        0.0502f, 0.9823f, 0.9472f,  

        0.5732f, 0.2694f, 0.916f}; 

    float[] vectorC; 

    int n; 

    int m; 

    int p; 

    @Override 

    public void run() { 

        ... 

    } 

    public MatrixMultiplicationKernel(int n, int m, int p) { 

        ... 

    } 

    public void displayResults () { 

        ... 

    } 

} 

```

`MatrixMultiplicationKernel`构造函数为矩阵的维数赋值，并为存储在`vectorC,`中的结果分配内存，如下所示:

```java
public MatrixMultiplicationKernel(int n, int m, int p) { 

    this.n = n; 

    this.p = p; 

    this.m = m; 

    vectorC = new float[n * p]; 

} 

```

run 方法使用全局 ID 和通道 ID 来执行矩阵乘法。pass ID 被指定为`Kernel` class' `execute`方法的第二个参数，我们很快就会看到。这个值允许我们提升`vectorC`的列索引。向量索引映射到原始矩阵的相应行和列位置:

```java
public void run() { 

    int i = getGlobalId(); 

    int j = this.getPassId(); 

    float value = 0; 

    for (int k = 0; k < p; k++) { 

        value += vectorA[k + i * m] * vectorB[k * p + j]; 

    } 

    vectorC[i * p + j] = value; 

} 

```

`displayResults`方法如下所示:

```java
public void displayResults() { 

    out.println("Result"); 

    for (int i = 0; i < n; i++) { 

        for (int j = 0; j < p; j++) { 

            out.printf("%.4f  ", vectorC[i * p + j]); 

        } 

        out.println(); 

    } 

} 

```

内核的启动方式与上一节相同。向`execute`方法传递应该创建的内核数和一个整数，该整数表示要传递的次数。通过次数用于控制进入`vectorA`和`vectorB`阵列的索引:

```java
MatrixMultiplicationKernel kernel = new MatrixMultiplicationKernel(n, m,

   p);kernel.execute(6, 3);kernel.displayResults(); 

kernel.dispose(); 

```

当执行此示例时，您将获得以下输出:

```java
Result
0.0276  0.1999  0.2132 
0.1443  0.4118  0.5417 
0.3486  0.3283  0.7058 
0.1964  0.2941  0.4964

```

接下来，我们将看到 Java 8 新增功能如何以并行方式帮助解决数学密集型问题。

# 使用 Java 8 流

Java 8 的发布对该语言进行了大量重要的增强。我们感兴趣的两个增强包括 lambda 表达式和流。lambda 表达式本质上是一个匿名函数，它为 Java 增加了一个函数式编程维度。Java 8 中引入的流的概念不是指 IO 流。相反，您可以将其视为一系列对象，可以使用流畅的编程风格来生成和操作这些对象。这种风格将很快演示。

与大多数 API 一样，程序员必须使用真实的测试用例和环境来仔细考虑他们代码的实际执行性能。如果使用不当，流实际上可能不会提供性能改进。特别是并行流，如果不仔细处理，可能会产生不正确的结果。

我们将从快速介绍 lambda 表达式和流开始。如果你熟悉这些概念，你可以跳过下一节。

## 理解 Java 8 lambda 表达式和流

lambda 表达式可以用几种不同的形式表示。下面是一个简单的 lambda 表达式，其中符号`->`是 lambda 运算符。这将采用某个值`e`，并返回乘以 2 的值。`e`这个名字没什么特别的。可以使用任何有效的 Java 变量名:

```java
e -> 2 * e 

```

它也可以用其他形式表示，例如:

```java
(int e) -> 2 * e 
(double e) -> 2 * e 
(int e) -> {return 2 * e; 

```

使用的形式取决于`e`的预期值。Lambda 表达式经常被用作方法的参数，我们很快就会看到。

可以使用多种技术创建流。在下面的示例中，流是从数组创建的。`IntStream`接口是一种使用整数的流。方法将一个数组转换成一个流:

```java
IntStream stream = Arrays.stream(numbers); 

```

然后，我们可以应用各种`stream`方法来执行操作。在下面的语句中，`forEach`方法将简单地显示流中的每个整数:

```java
stream.forEach(e -> out.printf("%d  ", e)); 

```

有各种各样的`stream`方法可以应用于一个流。在下面的例子中，`mapToDouble`方法将取一个整数，乘以`2`，然后返回一个`double`。`forEach`方法将显示这些值:

```java
stream 
        .mapToDouble(e-> 2 * e) 
        .forEach(e -> out.printf("%.4f  ", e)); 

```

方法调用的级联被称为**流畅编程**。

## 使用 Java 8 执行矩阵乘法

这里，我们将说明如何使用流来执行矩阵乘法。矩阵`A`、`B`和`C`的定义与*实现基本矩阵运算*一节中的定义相同。为了方便起见，这里复制了它们:

```java
double A[][] = { 
    {0.1950, 0.0311}, 
    {0.3588, 0.2203}, 
    {0.1716, 0.5931}, 
    {0.2105, 0.3242}}; 
double B[][] = { 
    {0.0502, 0.9823, 0.9472}, 
    {0.5732, 0.2694, 0.916}}; 
double C[][] = new double[n][p]; 

```

以下序列是矩阵乘法的流实现。代码的详细解释如下:

```java
C = Arrays.stream(A) 
        .parallel() 
        .map(AMatrixRow -> IntStream.range(0, B[0].length) 
                .mapToDouble(i -> IntStream.range(0, B.length) 
                        .mapToDouble(j -> AMatrixRow[j] * B[j][i]) 
                        .sum() 
                ).toArray()).toArray(double[][]::new); 

```

第一个`map`方法，如下所示，创建了一个表示`A`矩阵的`4`行的双向量流。`range`方法将返回从第一个参数到第二个参数的流元素列表。

```java
.map(AMatrixRow -> IntStream.range(0, B[0].length) 

```

变量`i`对应第二个`range`方法生成的数字，对应`B`矩阵(`2`)中的行数。变量`j`对应第三个`range`方法生成的数字，代表`B`矩阵的列数(`3`)。

该语句的核心是矩阵乘法，其中的`sum`方法计算总和:

```java
.mapToDouble(j -> AMatrixRow[j] * B[j][i]) 
.sum() 

```

表达式的最后一部分为 C 矩阵创建二维数组。操作符`::new`称为方法引用，是调用 new 操作符创建新对象的一种更简短的方式:

```java
).toArray()).toArray(double[][]::new); 

```

`displayResult`方法如下:

```java
public void displayResult() { 
    out.println("Result"); 
    for (int i = 0; i < n; i++) { 
        for (int j = 0; j < p; j++) { 
            out.printf("%.4f  ", C[i][j]); 
        } 
        out.println(); 
    } 
} 

```

该序列的输出如下:

```java
Result
0.0276  0.1999  0.2132 
0.1443  0.4118  0.5417 
0.3486  0.3283  0.7058 
0.1964  0.2941  0.4964

```

## 使用 Java 8 执行 map-reduce

在下一节中，我们将使用 Java 8 streams 执行一个 map-reduce 操作，类似于在*使用 map-reduce* 一节中使用 Hadoop 演示的操作。在这个例子中，我们将使用`Book`个对象中的`Stream`。然后，我们将演示如何使用 Java 8 `reduce`和`average`方法来获得总页数和平均页数。

我们没有像在 Hadoop 示例中那样从文本文件开始，而是创建了一个带有标题、作者和页数字段的`Book`类。在`driver`类的`main`方法中，我们创建了`Book`的新实例，并将它们添加到名为`books`的`ArrayList`中。我们还创建了一个`double`值`average`来保存我们的平均值，并将变量`totalPg`初始化为零:

```java
ArrayList<Book> books = new ArrayList<>(); 
double average; 
int totalPg = 0; 

books.add(new Book("Moby Dick", "Herman Melville", 822)); 
books.add(new Book("Charlotte's Web", "E.B. White", 189)); 
books.add(new Book("The Grapes of Wrath", "John Steinbeck", 212)); 
books.add(new Book("Jane Eyre", "Charlotte Bronte", 299)); 
books.add(new Book("A Tale of Two Cities", "Charles Dickens", 673)); 
books.add(new Book("War and Peace", "Leo Tolstoy", 1032)); 
books.add(new Book("The Great Gatsby", "F. Scott Fitzgerald",    275)); 

```

接下来，我们执行映射和归约操作来计算帐套中的总页数。为了以并行的方式实现这一点，我们使用了`stream`和`parallel`方法。然后我们使用带有 lambda 表达式的`map`方法来累计每个`Book`对象的所有页面计数。最后，我们使用`reduce`方法将我们的页面计数合并成一个最终值，该值将被分配给`totalPg`:

```java
totalPg = books 
        .stream() 
        .parallel() 
        .map((b) -> b.pgCnt) 
        .reduce(totalPg, (accumulator, _item) -> { 
            out.println(accumulator + " " +_item); 
            return accumulator + _item; 
                }); 

```

注意，在前面的`reduce`方法中，我们选择了打印出关于归约操作的累积值和单个项目的信息。`accumulator`代表我们页面计数的集合。`_item`表示 map-reduce 流程中在任何给定时刻都在进行缩减的单个任务。

在接下来的输出中，我们将首先看到在处理每个图书项目时,`accumulator`值保持为零。逐渐地，`accumulator`值增加。最后的操作是减少`1223`和`2279`的值。这两个数字的总和就是`3502`，或者说我们所有书籍的总页数:

```java
0 822
0 189
0 299
0 673
0 212
299 673
0 1032 
0 275
1032 275
972 1307
189 212
822 401
1223 2279

```

接下来，我们将添加代码来计算帐套的平均页数。当我们除以由`size`方法返回的整数时，我们将使用 map-reduce 确定的`totalPg`值乘以`1.0`以防止截断。然后我们打印出`average`。

```java
average = 1.0 * totalPg / books.size(); 
out.printf("Average Page Count: %.4f\n", average); 

```

我们的输出如下:

```java
Average Page Count: 500.2857

```

我们可以使用 Java 8 streams 直接使用`map`方法来计算平均值。将以下代码添加到`main`方法中。我们使用`parallelStream`和`map`方法来同时获得我们每本书的页数。然后，我们使用`mapToDouble`来确保我们的数据是正确的类型，以计算我们的平均值。最后，我们使用`average`和`getAsDouble`方法来计算我们的平均页数:

```java
average = books 
        .parallelStream() 
        .map(b -> b.pgCnt) 
        .mapToDouble(s -> s) 
        .average() 
        .getAsDouble(); 
out.printf("Average Page Count: %.4f\n", average);
```

然后我们打印出我们的平均值。我们的输出与前面的示例相同，如下所示:

```java
Average Page Count: 500.2857

```

这些技术利用与 map-reduce 框架相关的 Java 8 功能来解决数值问题。这种类型的过程也可以应用于其他类型的数据，包括基于文本的数据。当这些流程在大大缩短的时间框架内处理极大的数据集时，真正的好处就显现出来了。



# 总结

数据科学广泛使用数学来分析问题。有许多可用的 Java 数学库，其中许多都支持并发操作。在这一章中，我们介绍了一些库和技术，让我们深入了解如何使用它们来支持和提高应用程序的性能。

我们从讨论如何执行简单的矩阵乘法开始。给出了一个基本的 Java 实现。在后面的小节中，我们使用其他 API 和技术复制了实现。

许多高级 API，如 DL4J，支持许多有用的数据分析技术。在这些 API 之下，通常是对多个 CPU 和 GPU 的并发支持。有时这种支持是可配置的，例如 DL4J。我们简要讨论了如何配置 ND4J 来支持多处理器。

map-reduce 算法在数据科学领域得到了广泛的应用。我们利用这个框架的并行处理能力来计算一组给定值的平均值，即一组书的页数。这种技术使用 Apache 的 Hadoop 来执行 map 和 reduce 函数。

大量的库支持数学技术。许多这些库不直接支持并行操作。然而，了解什么是可用的以及如何使用它们是很重要的。为此，我们演示了如何使用三种不同的 Java API:jblas、Apache Commons Math 和 ND4J。

OpenCL 是一种 API，支持在各种硬件平台、处理器类型和语言上的并行操作。这种支持是相当低的水平。OpenCL 有许多 Java 绑定，我们已经讨论过了。

Aparapi 是对 Java 的高级支持，可以使用 CPU、CUDA 或 OpenCL 来实现并行操作。我们用矩阵乘法的例子演示了这种支持。

我们以对 Java 8 流和 lambda 表达式的介绍结束了我们的讨论。这些语言元素可以支持并行操作，从而提高应用程序的性能。此外，一旦程序员熟悉了这些技术，这通常可以提供更优雅、更易维护的实现。我们还演示了使用 Java 8 执行 map-reduce 的技术。

在下一章，我们将通过举例说明有多少介绍的技术可以用来构建一个完整的应用程序来结束这本书。