# 六、与数据库交互

数据分析从数据开始。因此，使用易于设置、操作且数据访问本身不会成为问题的数据存储系统是有益的。简而言之，我们希望拥有易于嵌入到我们的数据分析流程和工作流中的数据库系统。在本书中，我们主要关注数据库交互的 Python 方面，我们将学习如何将数据放入和取出 Pandas 数据结构。

有许多方法可以存储数据。在本章中，我们将学习与三个主要类别交互:文本格式、二进制格式和数据库。我们将重点介绍两种存储解决方案，MongoDB 和 Redis。MongoDB 是一个面向文档的数据库，这很容易开始，因为我们可以存储 JSON 文档，并且不需要预先定义模式。Redis 是一种流行的内存数据结构存储，在此基础上可以构建许多应用程序。使用 Redis 作为快速键值存储是可能的，但是 Redis 也支持列表、集合、散列、位数组，甚至像 HyperLogLog 这样的高级数据结构。

# 与文本格式的数据交互

文本是一种很好的媒介，也是一种简单的信息交流方式。以下陈述摘自*道格·麦克洛伊*的名言:*编写程序来处理文本流，因为那是通用接口。*

在本节中，我们将开始从文本文件读取数据和向文本文件写入数据。

## 从文本格式读取数据

通常，一个系统的原始数据日志存储在多个文本文件中，随着时间的推移，这些文本文件会积累大量信息。谢天谢地，在 Python 中与这类文件交互很简单。

Pandas 支持许多将数据从文本文件读入数据框对象的功能。最简单的一个就是`read_csv()`功能。让我们从一个小示例文件开始:

```py
$ cat example_data/ex_06-01.txt
Name,age,major_id,sex,hometown
Nam,7,1,male,hcm
Mai,11,1,female,hcm
Lan,25,3,female,hn
Hung,42,3,male,tn
Nghia,26,3,male,dn
Vinh,39,3,male,vl
Hong,28,4,female,dn

```

### 型式

`cat`是 Unix shell 命令，可用于将文件内容打印到屏幕上。

在上面的示例文件中，每列由逗号分隔，第一行是标题行，包含列名。要将数据文件读入 DataFrame 对象，我们键入以下命令:

```py
>>> df_ex1 = pd.read_csv('example_data/ex_06-01.txt')
>>> df_ex1
 Name  age  major_id     sex hometown
0    Nam    7         1    male      hcm
1    Mai   11         1  female      hcm
2    Lan   25         3  female       hn
3   Hung   42         3    male       tn
4  Nghia   26         3    male       dn
5   Vinh   39         3    male       vl
6   Hong   28         4  female       dn

```

我们看到`read_csv`函数使用逗号作为文本文件中列之间的默认分隔符，第一行自动用作列的标题。如果我们想更改此设置，我们可以使用`sep`参数更改分隔符号，并在示例文件没有标题行的情况下设置`header=None`。

请参见下面的示例:

```py
$ cat example_data/ex_06-02.txt
Nam     7       1       male    hcm
Mai     11      1       female  hcm
Lan     25      3       female  hn
Hung    42      3       male    tn
Nghia   26      3       male    dn
Vinh    39      3       male    vl
Hong    28      4       female  dn

>>> df_ex2 = pd.read_csv('example_data/ex_06-02.txt',
 sep = '\t', header=None)
>>> df_ex2
 0   1  2       3    4
0    Nam   7  1    male  hcm
1    Mai  11  1  female  hcm
2    Lan  25  3  female   hn
3   Hung  42  3    male   tn
4  Nghia  26  3    male   dn
5   Vinh  39  3    male   vl
6   Hong  28  4  female   dn

```

我们也可以使用等于所选行索引的`header`将特定行设置为标题行。同样，当我们想要使用数据文件中的任何一列作为 DataFrame 的列索引时，我们将`index_col`设置为该列的名称或索引。我们再用第二个数据文件`example_data/ex_06-02.txt`来说明这一点:

```py
>>> df_ex3 = pd.read_csv('example_data/ex_06-02.txt',
 sep = '\t', header=None,
 index_col=0)
>>> df_ex3
 1  2       3    4
0
Nam     7  1    male  hcm
Mai    11  1  female  hcm
Lan    25  3  female   hn
Hung   42  3    male   tn
Nghia  26  3    male   dn
Vinh   39  3    male   vl
Hong   28  4  female   dn

```

除了这些参数，我们还有很多有用的参数可以帮助我们更有效地将数据文件加载到 Pandas 对象中。下表显示了一些常见参数:

<colgroup><col style="text-align: left"> <col style="text-align: left"> <col style="text-align: left"></colgroup> 
| 

参数

 | 

价值

 | 

描述

 |
| --- | --- | --- |
| `dtype` | 列类型的类型名称或字典 | 设置数据或列的数据类型。默认情况下，它会尝试推断最合适的数据类型。 |
| `skiprows` | 列表式或整数式 | 要跳过的行数(从 0 开始)。 |
| `na_values` | 列表式或字典式，默认无 | 要识别为`NA` / `NaN`的值。如果 dict 被通过，这可以在每列的基础上设置。 |
| `true_values` | 目录 | 要转换为布尔真值的值列表。 |
| `false_values` | 目录 | 要转换为布尔假的值列表。 |
| `keep_default_na` | `Bool`、`default True` | 如果存在`na_values`参数并且`keep_default_na`是`False`，则默认的 NaN 值被忽略，否则它们被附加到 |
| `thousands` | `Str`、`default None` | 千位分隔符 |
| `nrows` | `Int`、`default None` | 限制从文件中读取的行数。 |
| `error_bad_lines` | `Boolean`、`default True` | 如果设置为真，将返回一个数据帧，即使在解析过程中出现错误。 |

除了`read_csv()`功能，我们在 Pandas 中还有一些其他的解析功能:

<colgroup><col style="text-align: left"> <col style="text-align: left"></colgroup> 
| 

功能

 | 

描述

 |
| --- | --- |
| `read_table` | 将常规分隔文件读入数据框 |
| `read_fwf` | 将固定宽度格式化行的表格读入数据框 |
| `read_clipboard` | 从剪贴板中读取文本并传递到`read_table`。它对于从网页转换表格很有用 |

在某些情况下，我们无法使用这些函数自动解析磁盘中的数据文件。在这种情况下，我们也可以打开文件，通过阅读器进行迭代，标准库中的 CSV 模块支持:

```py
$ cat example_data/ex_06-03.txt
Nam     7       1       male    hcm
Mai     11      1       female  hcm
Lan     25      3       female  hn
Hung    42      3       male    tn      single
Nghia   26      3       male    dn      single
Vinh    39      3       male    vl
Hong    28      4       female  dn

>>> import csv
>>> f = open('data/ex_06-03.txt')
>>> r = csv.reader(f, delimiter='\t')
>>> for line in r:
>>>    print(line)
['Nam', '7', '1', 'male', 'hcm']
['Mai', '11', '1', 'female', 'hcm']
['Lan', '25', '3', 'female', 'hn']
['Hung', '42', '3', 'male', 'tn', 'single']
['Nghia', '26', '3', 'male', 'dn', 'single']
['Vinh', '39', '3', 'male', 'vl']
['Hong', '28', '4', 'female', 'dn']

```

## 将数据写入文本格式

我们看到了如何将数据从文本文件加载到 Pandas 的数据结构中。现在，我们将学习如何将数据从程序的数据对象导出到文本文件。对应`read_csv()`功能，我们还有`to_csv()`功能，Pandas 支持。让我们看看下面的例子:

```py
>>> df_ex3.to_csv('example_data/ex_06-02.out', sep = ';')

```

结果将如下所示:

```py
$ cat example_data/ex_06-02.out
0;1;2;3;4
Nam;7;1;male;hcm
Mai;11;1;female;hcm
Lan;25;3;female;hn
Hung;42;3;male;tn
Nghia;26;3;male;dn
Vinh;39;3;male;vl
Hong;28;4;female;dn

```

如果我们想在将数据写入磁盘文件时跳过标题行或索引列，我们可以为标题和索引参数设置一个`False`值:

```py
>>> import sys
>>> df_ex3.to_csv(sys.stdout, sep='\t',
 header=False, index=False)
7       1       male    hcm
11      1       female  hcm
25      3       female  hn
42      3       male    tn
26      3       male    dn
39      3       male    vl
28      4       female  dn

```

我们也可以通过在`columns`参数中指定数据帧的列的子集来将它们写入文件:

```py
>>> df_ex3.to_csv(sys.stdout, columns=[3,1,4],
 header=False, sep='\t')
Nam     male    7       hcm
Mai     female  11      hcm
Lan     female  25      hn
Hung    male    42      tn
Nghia   male    26      dn
Vinh    male    39      vl
Hong    female  28      dn

```

有了 series 对象，我们可以使用相同的函数将数据写入文本文件，参数大多与上面相同。

# 与二进制格式的数据交互

我们可以用 pickle 模块读写 Python 对象的二进制序列化，可以在标准库中找到。如果您使用需要很长时间才能创建的对象，比如一些机器学习模型，对象序列化可能会很有用。通过酸洗这些对象，可以更快地访问该模型。它还允许您以标准化的方式分发 Python 对象。

Pandas 包括支持开箱腌制。相关的方法是`read_pickle()`和`to_pickle()`功能，可以轻松地读写文件中的数据。这些方法将以 pickle 格式将数据写入磁盘，这是一种方便的短期存储格式:

```py
>>> df_ex3.to_pickle('example_data/ex_06-03.out')
>>> pd.read_pickle('example_data/ex_06-03.out')
 1  2       3    4
0
Nam     7  1    male  hcm
Mai    11  1  female  hcm
Lan    25  3  female   hn
Hung   42  3    male   tn
Nghia  26  3    male   dn
Vinh   39  3    male   vl
Hong   28  4  female   dn

```

## HDF5

HDF5 不是数据库，而是数据模型和文件格式。它适用于一写多读数据集。HDF5 文件包括两种对象:数据集和组，数据集是类似数组的数据集合，组是类似文件夹的容器，保存数据集和其他组。Python 中有一些与 HDF5 格式交互的接口，比如`h5py`使用大家熟悉的 NumPy 和 Python 构造，比如字典和 NumPy 数组语法。有了`h5py`，我们有了 HDF5 API 的高级接口，这有助于我们开始。但是，在本书中，我们将介绍另一个用于这种格式的库，称为 PyTables，它可以很好地处理 Pandas 对象:

```py
>>> store = pd.HDFStore('hdf5_store.h5')
>>> store
<class 'pandas.io.pytables.HDFStore'>
File path: hdf5_store.h5
Empty

```

我们创建了一个空的 HDF5 文件，名为`hdf5_store.h5`。现在，我们可以向文件中写入数据，就像向`dict`添加键值对一样:

```py
>>> store['ex3'] = df_ex3
>>> store['name'] = df_ex2[0]
>>> store['hometown'] = df_ex3[4]
>>> store
<class 'pandas.io.pytables.HDFStore'>
File path: hdf5_store.h5
/ex3                  frame        (shape->[7,4])
/hometown             series       (shape->[1])
/name                 series       (shape->[1])

```

存储在 HDF5 文件中的对象可以通过指定对象键来检索:

```py
>>> store['name']
0      Nam
1      Mai
2      Lan
3     Hung
4    Nghia
5     Vinh
6     Hong
Name: 0, dtype: object

```

一旦我们完成了与 HDF5 文件的交互，我们就关闭它以释放文件句柄:

```py
>>> store.close()
>>> store
<class 'pandas.io.pytables.HDFStore'>
File path: hdf5_store.h5
File is CLOSED

```

对于使用 HDF5 格式，还有其他受支持的有用功能。如果需要处理大量数据，您应该更详细地探索两个库-`pytables`和`h5py`。

# 与 MongoDB 中的数据交互

许多应用程序需要比文本文件更强大的存储系统，这就是为什么许多应用程序使用数据库来存储数据。数据库有很多种，但有两大类:关系数据库，它支持一种称为 SQL 的标准声明性语言，以及所谓的 NoSQL 数据库，它们通常能够在没有预定义模式的情况下工作，并且数据实例更适合描述为文档，而不是行。

MongoDB 是一种 NoSQL 数据库，它将数据存储为文档，这些文档在集合中组合在一起。文档被表示为 JSON 对象。它存储数据的速度快、可扩展，查询数据也很灵活。要在 Python 中使用 MongoDB，我们需要导入`pymongo`包，并通过传递主机名和端口打开到数据库的连接。假设我们有一个 MongoDB 实例，运行在默认主机(`localhost`)和端口(`27017`)上:

```py
>>> import pymongo
>>> conn = pymongo.MongoClient(host='localhost', port=27017)

```

如果我们不把任何参数放入`pymongo.MongoClient()`功能，它会自动使用默认的主机和端口。

在下一步中，我们将与 MongoDB 实例中的数据库进行交互。我们可以列出实例中可用的所有数据库:

```py
>>> conn.database_names()
['local']
>>> lc = conn.local
>>> lc
Database(MongoClient('localhost', 27017), 'local')

```

上面的片段说我们的 MongoDB 实例只有一个数据库，名为‘local’。如果我们指向的数据库和集合不存在，MongoDB 将根据需要创建它们:

```py
>>> db = conn.db
>>> db
Database(MongoClient('localhost', 27017), 'db')

```

每个数据库都包含文档组，称为集合。我们可以将它们理解为关系数据库中的表。要列出数据库中所有现有的集合，我们使用`collection_names()`函数:

```py
>>> lc.collection_names()
['startup_log', 'system.indexes']
>>> db.collection_names()
[]

```

我们的`db`数据库还没有任何收藏。让我们创建一个名为`person`的集合，并将数据框对象中的数据插入其中:

```py
>>> collection = db.person
>>> collection
Collection(Database(MongoClient('localhost', 27017), 'db'), 'person')
>>> # insert df_ex2 DataFrame into created collection
>>> import json
>>> records = json.load(df_ex2.T.to_json()).values()
>>> records
dict_values([{'2': 3, '3': 'male', '1': 39, '4': 'vl', '0': 'Vinh'}, {'2': 3, '3': 'male', '1': 26, '4': 'dn', '0': 'Nghia'}, {'2': 4, '3': 'female', '1': 28, '4': 'dn', '0': 'Hong'}, {'2': 3, '3': 'female', '1': 25, '4': 'hn', '0': 'Lan'}, {'2': 3, '3': 'male', '1': 42, '4': 'tn', '0': 'Hung'}, {'2': 1, '3':'male', '1': 7, '4': 'hcm', '0': 'Nam'}, {'2': 1, '3': 'female', '1': 11, '4': 'hcm', '0': 'Mai'}])
>>> collection.insert(records)
[ObjectId('557da218f21c761d7c176a40'),
 ObjectId('557da218f21c761d7c176a41'),
 ObjectId('557da218f21c761d7c176a42'),
 ObjectId('557da218f21c761d7c176a43'),
 ObjectId('557da218f21c761d7c176a44'),
 ObjectId('557da218f21c761d7c176a45'),
 ObjectId('557da218f21c761d7c176a46')]

```

`df_ex2`在加载到字典之前被转置并转换为 JSON 字符串。`insert()`函数从`df_ex2`接收我们创建的词典，并将其保存到集合中。

如果我们想要列出集合中的所有数据，我们可以执行以下命令:

```py
>>> for cur in collection.find():
>>>     print(cur)
{'4': 'vl', '2': 3, '3': 'male', '1': 39, '_id': ObjectId('557da218f21c761d7c176
a40'), '0': 'Vinh'}
{'4': 'dn', '2': 3, '3': 'male', '1': 26, '_id': ObjectId('557da218f21c761d7c176
a41'), '0': 'Nghia'}
{'4': 'dn', '2': 4, '3': 'female', '1': 28, '_id': ObjectId('557da218f21c761d7c1
76a42'), '0': 'Hong'}
{'4': 'hn', '2': 3, '3': 'female', '1': 25, '_id': ObjectId('557da218f21c761d7c1
76a43'), '0': 'Lan'}
{'4': 'tn', '2': 3, '3': 'male', '1': 42, '_id': ObjectId('557da218f21c761d7c176
a44'), '0': 'Hung'}
{'4': 'hcm', '2': 1, '3': 'male', '1': 7, '_id': ObjectId('557da218f21c761d7c176
a45'), '0': 'Nam'}
{'4': 'hcm', '2': 1, '3': 'female', '1': 11, '_id': ObjectId('557da218f21c761d7c
176a46'), '0': 'Mai'}

```

如果我们想要在某些条件下从创建的集合中查询数据，我们可以使用`find()`函数，并传入描述我们想要检索的文档的字典。返回的结果是游标类型，它支持迭代器协议:

```py
>>> cur = collection.find({'3' : 'male'})
>>> type(cur)
pymongo.cursor.Cursor
>>> result = pd.DataFrame(list(cur))
>>> result
 0   1  2     3    4                       _id
0   Vinh  39  3  male   vl  557da218f21c761d7c176a40
1  Nghia  26  3  male   dn  557da218f21c761d7c176a41
2   Hung  42  3  male   tn  557da218f21c761d7c176a44
3    Nam   7  1  male  hcm  557da218f21c761d7c176a45

```

有时候，我们希望删除 MongdoDB 中的数据。我们需要做的就是向集合上的`remove()`方法传递一个查询:

```py
>>> # before removing data
>>> pd.DataFrame(list(collection.find()))
 0   1  2       3    4                       _id
0   Vinh  39  3    male   vl  557da218f21c761d7c176a40
1  Nghia  26  3    male   dn  557da218f21c761d7c176a41
2   Hong  28  4  female   dn  557da218f21c761d7c176a42
3    Lan  25  3  female   hn  557da218f21c761d7c176a43
4   Hung  42  3    male   tn  557da218f21c761d7c176a44
5    Nam   7  1    male  hcm  557da218f21c761d7c176a45
6    Mai  11  1  female  hcm  557da218f21c761d7c176a46

>>> # after removing records which have '2' column as 1 and '3' column as 'male'
>>> collection.remove({'2': 1, '3': 'male'})
{'n': 1, 'ok': 1}
>>> cur_all = collection.find();
>>> pd.DataFrame(list(cur_all))
 0   1  2       3    4                       _id
0   Vinh  39  3    male   vl  557da218f21c761d7c176a40
1  Nghia  26  3    male   dn  557da218f21c761d7c176a41
2   Hong  28  4  female   dn  557da218f21c761d7c176a42
3    Lan  25  3  female   hn  557da218f21c761d7c176a43
4   Hung  42  3    male   tn  557da218f21c761d7c176a44
5    Mai  11  1  female  hcm  557da218f21c761d7c176a46

```

我们逐步学习了如何在集合中插入、查询和删除数据。现在，我们将展示如何在 MongoDB 中更新集合中的现有数据:

```py
>>> doc = collection.find_one({'1' : 42})
>>> doc['4'] = 'hcm'
>>> collection.save(doc)
ObjectId('557da218f21c761d7c176a44')
>>> pd.DataFrame(list(collection.find()))
 0   1  2       3    4                       _id
0   Vinh  39  3    male   vl  557da218f21c761d7c176a40
1  Nghia  26  3    male   dn  557da218f21c761d7c176a41
2   Hong  28  4  female   dn  557da218f21c761d7c176a42
3    Lan  25  3  female   hn  557da218f21c761d7c176a43
4   Hung  42  3    male  hcm  557da218f21c761d7c176a44
5    Mai  11  1  female  hcm  557da218f21c761d7c176a46

```

下表显示了为在 MongoDB 中操作文档提供快捷方式的方法:

<colgroup><col style="text-align: left"> <col style="text-align: left"></colgroup> 
| 

更新方法

 | 

描述

 |
| --- | --- |
| `inc()` | 递增数字字段 |
| `set()` | 将某些字段设置为新值 |
| `unset()` | 从文档中删除字段 |
| `push()` | 将值附加到文档中的数组上 |
| `pushAll()` | 将几个值追加到文档的数组中 |
| `addToSet()` | 仅当数组不存在时，才将值添加到数组中 |
| `pop()` | 移除数组的最后一个值 |
| `pull()` | 从数组中移除所有出现的值 |
| `pullAll()` | 从数组中移除任何值集的所有匹配项 |
| `rename()` | 重命名字段 |
| `bit()` | 通过按位运算更新值 |

# 与 Redis 中的数据交互

Redis 是一种高级的键值存储，其中的值可以是不同的类型:字符串、列表、集合、排序集合或散列。Redis 像 memcached 一样将数据存储在内存中，但它可以持久存储在磁盘上，不像 memcached 那样没有这样的选项。Redis 支持快速读写，大约每秒 100，000 次 set 或 get 操作。

要与 Redis 交互，我们需要将`Redis-py`模块安装到 Python 中，Python 在`pypi`上有，可以用`pip`安装:

```py
$ pip install redis

```

现在，我们可以通过数据库服务器的主机和端口连接到 Redis。我们假设已经安装了一个 Redis 服务器，该服务器使用默认主机(`localhost`)和端口(`6379`)参数运行:

```py
>>> import redis
>>> r = redis.StrictRedis(host='127.0.0.1', port=6379)
>>> r
StrictRedis<ConnectionPool<Connection<host=localhost,port=6379,db=0>>>

```

作为在 Redis 中存储数据的第一步，我们需要定义哪种数据结构适合我们的需求。在本节中，我们将介绍 Redis 中常用的四种数据结构:简单值、列表、集合和有序集。尽管数据以许多不同的数据结构存储在 Redis 中，但每个值都必须与一个键相关联。

## 简单值

这是 Redis 中最基本的一种价值。对于 Redis 中的每个键，我们还有一个可以有数据类型的值，比如字符串、整数或双精度。让我们从一个设置和获取 Redis 数据的例子开始:

```py
>>> r.set('gender:An', 'male')
True
>>> r.get('gender:An')
b'male'

```

在这个例子中，我们希望将一个名为`An`的人的性别信息存储到 Redis 中。我们的关键是`gender:An`，我们的价值是`male`。它们都是一种字符串。

`set()`函数接收两个参数:键和值。第一个参数是键，第二个参数是值。如果我们想更新这个键的值，我们只需要再次调用函数并更改第二个参数的值。Redis 会自动更新它。

`get()`函数将检索我们的键的值，该值作为参数传递。在这种情况下，我们要获取关键`gender:An`的性别信息。

在第二个例子中，我们向您展示了另一种值类型，一个整数:

```py
>>> r.set('visited_time:An', 12)
True
>>> r.get('visited_time:An')
b'12'
>>> r.incr('visited_time:An', 1)
13
>>> r.get('visited_time:An')
b'13'

```

我们看到了一个新的函数，`incr()`，用来将 key 的值增加一个给定量。如果我们的键不存在，RedisDB 将以给定的增量作为值创建该键。

## 列表

我们有一些方法来与 Redis 中的列表值进行交互。以下示例使用`rpush()`和`lrange()`函数将列表数据放入数据库和从数据库获取列表数据:

```py
>>> r.rpush('name_list', 'Tom')
1L
>>> r.rpush('name_list', 'John')
2L
>>> r.rpush('name_list', 'Mary')
3L
>>> r.rpush('name_list', 'Jan')
4L
>>> r.lrange('name_list', 0, -1)
[b'Tom', b'John', b'Mary', b'Jan']
>>> r.llen('name_list')
4
>>> r.lindex('name_list', 1)
b'John'

```

除了我们在示例中使用的`rpush()`和`lrange()`函数之外，我们还想介绍另外两个函数。首先，`llen()`函数用于获取给定键在 Redis 中的列表长度。`lindex()`功能是检索列表项目的另一种方式。我们需要向函数传递两个参数:一个键和列表中项目的索引。下表列出了用 Redis 处理列表数据结构的其他一些强大功能:

<colgroup><col style="text-align: left"> <col style="text-align: left"></colgroup> 
| 

功能

 | 

描述

 |
| --- | --- |
| `rpushx(name, value)` | 如果名称存在，将值推到列表名称的尾部 |
| `rpop(name)` | 移除并返回列表名称的最后一项 |
| `lset(name, index, value)` | 将列表名称索引位置的项目设置为输入值 |
| `lpushx(name,value)` | 如果名称存在，将值推送到列表名称的开头 |
| `lpop(name)` | 移除并返回列表名称的第一项 |

## 设置

这个数据结构也类似于列表类型。但是，与列表相反，我们不能在集合中存储重复的值:

```py
>>> r.sadd('country', 'USA')
1
>>> r.sadd('country', 'Italy')
1
>>> r.sadd('country', 'Singapore')
1
>>> r.sadd('country', 'Singapore')
0
>>> r.smembers('country')
{b'Italy', b'Singapore', b'USA'}
>>> r.srem('country', 'Singapore')
1
>>> r.smembers('country')
{b'Italy', b'USA'}

```

对应列表数据结构，我们还有很多功能可以获取、设置、更新或删除集合中的项目。它们列在支持的集合数据结构函数中，如下表所示:

<colgroup><col style="text-align: left"> <col style="text-align: left"></colgroup> 
| 

功能

 | 

描述

 |
| --- | --- |
| `sadd(name, values)` | 用键名向集合中添加值 |
| `scard(name)` | 用键名返回集合中的元素数 |
| `smembers(name)` | 用键名返回集合的所有成员 |
| `srem(name, values)` | 用键名从集合中移除值 |

## 有序集

当我们将数据添加到名为**分数**的集合中时，有序集合数据结构具有额外的属性。有序集合将使用分数来确定集合中元素的顺序:

```py
>>> r.zadd('person:A', 10, 'sub:Math')
1
>>> r.zadd('person:A', 7, 'sub:Bio')
1
>>> r.zadd('person:A', 8, 'sub:Chem')
1
>>> r.zrange('person:A', 0, -1)
[b'sub:Bio', b'sub:Chem', b'sub:Math']
>>> r.zrange('person:A', 0, -1, withscores=True)
[(b'sub:Bio', 7.0), (b'sub:Chem', 8.0), (b'sub:Math', 10.0)]

```

通过使用`zrange(name, start, end)`函数，我们可以从排序的集合中获得一个范围内的值，该范围位于默认情况下按升序排序的开始和结束分数之间。如果要改变`way`的排序方式，可以将`desc`参数设置为`True`。`withscore`参数用于我们想要获得分数和返回值的情况。返回类型是一个(值、分数)对的列表，如您在上面的示例中所见。

有关有序集合的更多可用功能，请参见下表:

<colgroup><col style="text-align: left"> <col style="text-align: left"></colgroup> 
| 

功能

 | 

描述

 |
| --- | --- |
| `zcard(name)` | 用关键字名称返回排序集中的元素数量 |
| `zincrby(name, value, amount=1)` | 将排序后的具有关键字名称的集合中的值的分数按数量递增 |
| `zrangebyscore(name, min, max, withscores=False, start=None, num=None)` | 从排序集中返回一个值范围，关键字名称的得分在最小值和最大值之间。如果`withscores`是`true`，则返回分数和数值。如果给定了开始和`num`，返回范围的一部分 |
| `zrank(name, value)` | 返回一个从 0 开始的值，该值指示带键名的排序集中的值的等级 |
| `zrem(name, values)` | 从具有关键字名称的排序集中移除成员值 |

# 总结

我们已经完成了在不同的常用存储机制中与数据交互的基础知识，从简单的存储机制(如文本文件)到更结构化的存储机制(如 HDF5)，再到更复杂的数据存储系统(如 MongoDB 和 Redis)。最合适的存储类型将取决于您的用例。数据存储层技术的选择在数据处理系统的总体设计中起着重要的作用。有时，我们需要组合各种数据库系统来存储我们的数据，例如数据的复杂性、系统的性能或计算需求。

**练习练习**

*   选择一组您选择的数据，并为其设计存储选项。考虑文本文件、HDF5、文档数据库和数据结构存储作为可能的持久选项。还要评估更新或删除一个特定项目有多困难(例如，通过某种度量，多少行代码)。哪种存储类型最容易设置？哪种存储类型支持最灵活的查询？
*   在[第 3 章](3.html "Chapter 3. Data Analysis with Pandas")、*Pandas 数据分析*中，我们看到可以用 Pandas 创建分级索引。举个例子，假设你有超过 100 万居民的每个城市的数据，我们有一个两级指数，所以我们可以处理单个城市，也可以处理整个国家。您将如何用本章中介绍的各种存储选项来表示这种层次关系:文本文件、HDF5、MongoDB 和 Redis？从长远来看，你认为什么最方便？