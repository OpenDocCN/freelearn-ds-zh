# 零、前言

我们目前正面临着雪崩般的数据，这些数据包含了许多洞察力，这些洞察力掌握着数据驱动的世界中成败的关键。 下一代 Hadoop(V2)提供了一个尖端平台来存储和分析这些海量数据集，并改进了广泛使用且非常成功的 Hadoop MapReduce v1。 将帮助您使用下一代 Hadoop MapReduce 分析大型复杂数据集的食谱将为您提供使用下一代 Hadoop 生态系统处理大型复杂数据集所需的技能和知识。

本书介绍了许多令人兴奋的主题，例如使用 Hadoop 解决分析、分类、数据索引和搜索的 MapReduce 模式。 您还将了解几个 Hadoop 生态系统组件，包括 Have、Pig、HBase、Mahout、Nutch 和 Sqoop。

本书向您介绍简单的示例，然后深入探讨如何解决深入的大数据使用案例。 本书以简单明了的方式介绍了 90 多个即用型 Hadoop MapReduce 食谱，并提供了分步说明和实际示例。

# 这本书涵盖了哪些内容

[第 1 章](01.html "Chapter 1. Getting Started with Hadoop v2")，*Hadoop v2*入门，介绍 Hadoop MapReduce、Yarn 和 HDFS，并逐步完成 Hadoop v2 的安装。

[第 2 章](02.html "Chapter 2. Cloud Deployments – Using Hadoop YARN on Cloud Environments")，*云部署-在云环境中使用 Hadoop Yarn*，说明如何使用 Amazon Elastic MapReduce(EMR)和 Apache Whirr 在云基础架构上部署和执行 Hadoop MapReduce、Pig、Have 和 HBase 计算。

[第 3 章](03.html "Chapter 3. Hadoop Essentials – Configurations, Unit Tests, and Other APIs")，*Hadoop Essentials-配置、单元测试和其他 API*介绍了基本的 Hadoop Yarn 和 HDFS 配置、HDFS Java API 以及 MapReduce 应用的单元测试方法。

[第 4 章](04.html "Chapter 4. Developing Complex Hadoop MapReduce Applications")，*开发复杂的 Hadoop MapReduce 应用*向您介绍了几个高级 Hadoop MapReduce 功能，这些功能将帮助您开发高度自定义且高效的 MapReduce 应用。

[第 5 章](05.html "Chapter 5. Analytics")，*Analytics*解释了如何使用 Hadoop MapReduce 执行基本数据分析操作。

[第 6 章](06.html "Chapter 6. Hadoop Ecosystem – Apache Hive")，*Hadoop 生态系统-Apache Have*介绍了 Apache Have，它使用类似 SQL 的查询语言在 Hadoop 之上提供数据仓库功能。

[第 7 章](07.html "Chapter 7. Hadoop Ecosystem II – Pig, HBase, Mahout, and Sqoop")，*Hadoop 生态系统 II-Pig、HBase、Mahout 和 Sqoop*介绍了 Apache Pig 数据流样式数据处理语言、Apache HBase NoSQL 数据存储、Apache Mahout 机器学习和数据挖掘工具包，以及用于在 Hadoop 和关系数据库之间传输数据的 Apache Sqoop 批量数据传输实用程序。

[第 8 章](08.html "Chapter 8. Searching and Indexing")，*搜索和索引*介绍了几种可用于 Apache Hadoop 执行大规模搜索和索引的工具和技术。

[第 9 章](09.html "Chapter 9. Classifications, Recommendations, and Finding Relationships")，*分类、建议和查找关系*解释了如何使用 Hadoop 实现复杂的算法，如分类、推荐和查找关系。

[第 10 章](10.html "Chapter 10. Mass Text Data Processing")，*海量文本数据处理*解释了如何使用 Hadoop 和 Mahout 处理大型文本数据集，以及如何使用 Hadoop 执行数据预处理和加载操作。

# 这本书你需要什么

您需要具备一定的 Java 知识，能够访问 Internet 和一台运行 Linux 操作系统的计算机。

# 这本书是给谁看的

如果您是一个大数据爱好者，并且希望使用 Hadoop v2 来解决您的问题，那么这本书是为您准备的。 本书面向对 Hadoop MapReduce 知之甚少的 Java 程序员。 这也是希望快速掌握使用 Hadoopv2 的开发人员和系统管理员的一站式参考。 掌握使用 Java 进行软件开发的基本知识和 Linux 的基本工作知识会很有帮助。

# 公约

在这本书中，你会发现许多区分不同信息的文本样式。 以下是这些风格的一些示例，并解释了它们的含义。

文本、数据库表名、文件夹名、文件名、文件扩展名、路径名、虚拟 URL、用户输入和 Twitter 句柄中的代码字如下所示：“以下是我们在`hadoop.properties`文件中使用的属性的说明。”

代码块设置如下：

```scala
Path file = new Path("demo.txt");
FSDataOutputStream outStream = fs.create(file);
outStream.writeUTF("Welcome to HDFS Java API!!!");
outStream.close();
```

当我们希望您注意代码块的特定部分时，相关行或项将以粗体显示：

```scala
Job job = Job.getInstance(getConf(), "MLReceiveReplyProcessor");
job.setJarByClass(CountReceivedRepliesMapReduce.class);
job.setMapperClass(AMapper.class);
job.setReducerClass(AReducer.class);
job.setNumReduceTasks(numReduce);

job.setOutputKeyClass(Text.class);
job.setOutputValueClass(Text.class);
job.setInputFormatClass(MBoxFileInputFormat.class);
FileInputFormat.setInputPaths(job, new Path(inputPath));
FileOutputFormat.setOutputPath(job, new Path(outputPath));

int exitStatus = job.waitForCompletion(true) ? 0 : 1;
```

任何命令行输入或输出都如下所示：

```scala
205.212.115.106 - - [01/Jul/1995:00:00:12 -0400] "GET /shuttle/countdown/countdown.html HTTP/1.0" 200 3985

```

**新术语**和**重要单词**以粗体显示。 例如，您在屏幕、菜单或对话框中看到的文字会出现在文本中，如下所示：“在**Add Bootstrap Actions**下拉框中选择**Custom Action**。单击**Configure and Add**。”

### 备注

警告或重要说明会出现在这样的框中。

### 提示

提示和技巧如下所示。

# 读者反馈

欢迎读者的反馈。 让我们知道你对这本书的看法-你喜欢什么或不喜欢什么。 读者反馈对于我们开发真正能让您获得最大收益的图书非常重要。

要向我们发送一般反馈，只需发送电子邮件至`<[feedback@packtpub.com](mailto:feedback@packtpub.com)>`，并通过消息主题提及书名。

如果有一个您擅长的主题，并且您有兴趣撰写或投稿一本书，请参阅我们位于[www.Packtpub.com/Authors](http://www.packtpub.com/authors)上的作者指南。

# 客户支持

现在您已经成为 Packt 图书的拥有者，我们有很多东西可以帮助您从购买中获得最大价值。

## 下载示例代码

您可以从您的帐户[http://www.packtpub.com](http://www.packtpub.com)下载购买的所有 Packt 图书的示例代码文件。 如果您在其他地方购买了本书，您可以访问[http://www.packtpub.com/support](http://www.packtpub.com/support)并注册，以便将文件通过电子邮件直接发送给您。

## 勘误表

虽然我们已经竭尽全力确保内容的准确性，但错误还是会发生。 如果您在我们的一本书中发现错误--可能是文本或代码中的错误--如果您能向我们报告，我们将不胜感激。 通过这样做，您可以将其他读者从挫折中解救出来，并帮助我们改进本书的后续版本。 如果您发现任何勘误表，请访问[http://www.packtpub.com/submit-errata](http://www.packtpub.com/submit-errata)，选择您的图书，单击**勘误表提交表**链接，然后输入勘误表的详细信息。 一旦您的勘误表被核实，您提交的勘误表将被接受，勘误表将被上传到我们的网站上，或添加到该标题勘误表部分下的任何现有勘误表列表中。 通过从[http://www.packtpub.com/support](http://www.packtpub.com/support)中选择您的书目，可以查看任何现有勘误表。

## 盗版

在互联网上盗版版权材料是所有媒体持续存在的问题。 在 Packt，我们非常重视版权和许可证的保护。 如果您在互联网上发现任何形式的非法复制我们的作品，请立即提供我们的位置、地址或网站名称，以便我们采取补救措施。

请拨打`<[copyright@packtpub.com](mailto:copyright@packtpub.com)>`与我们联系，并提供疑似盗版材料的链接。

我们感谢您在保护我们的作者方面的帮助，以及我们为您提供有价值内容的能力。

## 问题

如果您对本书的任何方面有任何问题，可以拨打`<[questions@packtpub.com](mailto:questions@packtpub.com)>`与我们联系，我们将尽最大努力解决。