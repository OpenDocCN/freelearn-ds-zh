["```py\nCONSUMER_KEY = 'GetYourKey@Twitter'\nCONSUMER_SECRET = ' GetYourKey@Twitter'\nOAUTH_TOKEN = ' GetYourToken@Twitter'\nOAUTH_TOKEN_SECRET = ' GetYourToken@Twitter'\n```", "```py\n    $ pip install twitter\n\n    ```", "```py\n    import twitter\n    import urlparse\n    from pprint import pprint as pp\n\n    class TwitterAPI(object):\n        \"\"\"\n        TwitterAPI class allows the Connection to Twitter via OAuth\n        once you have registered with Twitter and receive the \n        necessary credentiials \n        \"\"\"\n\n    # initialize and get the twitter credentials\n         def __init__(self): \n            consumer_key = 'Provide your credentials'\n            consumer_secret = 'Provide your credentials'\n            access_token = 'Provide your credentials'\n            access_secret = 'Provide your credentials'\n\n            self.consumer_key = consumer_key\n            self.consumer_secret = consumer_secret\n            self.access_token = access_token\n            self.access_secret = access_secret\n\n    #\n    # authenticate credentials with Twitter using OAuth\n            self.auth = twitter.oauth.OAuth(access_token, access_secret, consumer_key, consumer_secret)\n        # creates registered Twitter API\n            self.api = twitter.Twitter(auth=self.auth)\n    #\n    # search Twitter with query q (i.e. \"ApacheSpark\") and max. result\n        def searchTwitter(self, q, max_res=10,**kwargs):\n            search_results = self.api.search.tweets(q=q, count=10, **kwargs)\n            statuses = search_results['statuses']\n            max_results = min(1000, max_res)\n\n            for _ in range(10): \n                try:\n                    next_results = search_results['search_metadata']['next_results']\n                except KeyError as e: \n                    break\n\n                next_results = urlparse.parse_qsl(next_results[1:])\n                kwargs = dict(next_results)\n                search_results = self.api.search.tweets(**kwargs)\n                statuses += search_results['statuses']\n\n                if len(statuses) > max_results: \n                    break\n            return statuses\n    #\n    # parse tweets as it is collected to extract id, creation \n    # date, user id, tweet text\n        def parseTweets(self, statuses):\n            return [ (status['id'], \n                      status['created_at'], \n                      status['user']['id'],\n                      status['user']['name'], \n                      status['text'], url['expanded_url']) \n                            for status in statuses \n                                for url in status['entities']['urls'] ]\n    ```", "```py\n    t= TwitterAPI()\n    ```", "```py\n    q=\"ApacheSpark\"\n    tsearch = t.searchTwitter(q)\n    ```", "```py\n    pp(tsearch[1])\n\n    {u'contributors': None,\n     u'coordinates': None,\n     u'created_at': u'Sat Apr 25 14:50:57 +0000 2015',\n     u'entities': {u'hashtags': [{u'indices': [74, 86], u'text': u'sparksummit'}],\n                   u'media': [{u'display_url': u'pic.twitter.com/WKUMRXxIWZ',\n                               u'expanded_url': u'http://twitter.com/bigdata/status/591976255831969792/photo/1',\n                               u'id': 591976255156715520,\n                               u'id_str': u'591976255156715520',\n                               u'indices': [143, 144],\n                               u'media_url': \n    ...(snip)... \n     u'text': u'RT @bigdata: Enjoyed catching up with @ApacheSpark users &amp; leaders at #sparksummit NYC: video clips are out http://t.co/qrqpP6cG9s http://t\\u2026',\n     u'truncated': False,\n     u'user': {u'contributors_enabled': False,\n               u'created_at': u'Sat Apr 04 14:44:31 +0000 2015',\n               u'default_profile': True,\n               u'default_profile_image': True,\n               u'description': u'',\n               u'entities': {u'description': {u'urls': []}},\n               u'favourites_count': 0,\n               u'follow_request_sent': False,\n               u'followers_count': 586,\n               u'following': False,\n               u'friends_count': 2,\n               u'geo_enabled': False,\n               u'id': 3139047660,\n               u'id_str': u'3139047660',\n               u'is_translation_enabled': False,\n               u'is_translator': False,\n               u'lang': u'zh-cn',\n               u'listed_count': 749,\n               u'location': u'',\n               u'name': u'Mega Data Mama',\n               u'notifications': False,\n               u'profile_background_color': u'C0DEED',\n               u'profile_background_image_url': u'http://abs.twimg.com/images/themes/theme1/bg.png',\n               u'profile_background_image_url_https': u'https://abs.twimg.com/images/themes/theme1/bg.png',\n               ...(snip)... \n               u'screen_name': u'MegaDataMama',\n               u'statuses_count': 26673,\n               u'time_zone': None,\n               u'url': None,\n               u'utc_offset': None,\n               u'verified': False}}\n    ```", "```py\n    tparsed = t.parseTweets(tsearch)\n    pp(tparsed)\n\n    [(591980327784046592,\n      u'Sat Apr 25 15:01:23 +0000 2015',\n      63407360,\n      u'Jos\\xe9 Carlos Baquero',\n      u'Big Data systems are making a difference in the fight against cancer. #BigData #ApacheSpark http://t.co/pnOLmsKdL9',\n      u'http://tmblr.co/ZqTggs1jHytN0'),\n     (591977704464875520,\n      u'Sat Apr 25 14:50:57 +0000 2015',\n      3139047660,\n      u'Mega Data Mama',\n      u'RT @bigdata: Enjoyed catching up with @ApacheSpark users &amp; leaders at #sparksummit NYC: video clips are out http://t.co/qrqpP6cG9s http://t\\u2026',\n      u'http://goo.gl/eF5xwK'),\n     (591977172589539328,\n      u'Sat Apr 25 14:48:51 +0000 2015',\n      2997608763,\n      u'Emma Clark',\n      u'RT @bigdata: Enjoyed catching up with @ApacheSpark users &amp; leaders at #sparksummit NYC: video clips are out http://t.co/qrqpP6cG9s http://t\\u2026',\n      u'http://goo.gl/eF5xwK'),\n     ... (snip)...  \n     (591879098349268992,\n      u'Sat Apr 25 08:19:08 +0000 2015',\n      331263208,\n      u'Mario Molina',\n      u'#ApacheSpark speeds up big data decision-making http://t.co/8hdEXreNfN',\n      u'http://www.computerweekly.com/feature/Apache-Spark-speeds-up-big-data-decision-making')]\n    ```", "```py\n    pip install PyGithub\n    ```", "```py\n    from github import Github\n\n    # Get your own access token\n\n    ACCESS_TOKEN = 'Get_Your_Own_Access_Token'\n\n    # We are focusing our attention to User = apache and Repo = spark\n\n    USER = 'apache'\n    REPO = 'spark'\n\n    g = Github(ACCESS_TOKEN, per_page=100)\n    user = g.get_user(USER)\n    repo = user.get_repo(REPO)\n    ```", "```py\n    repos_apache = [repo.name for repo in g.get_user('apache').get_repos()]\n    len(repos_apache)\n    640\n    ```", "```py\n    pp(repo.get_languages())\n\n    {u'C': 1493,\n     u'CSS': 4472,\n     u'Groff': 5379,\n     u'Java': 1054894,\n     u'JavaScript': 21569,\n     u'Makefile': 7771,\n     u'Python': 1091048,\n     u'R': 339201,\n     u'Scala': 10249122,\n     u'Shell': 172244}\n    ```", "```py\n    stargazers = [ s for s in repo.get_stargazers() ]\n    print \"Number of stargazers\", len(stargazers)\n    Number of stargazers 3738\n\n    [stargazers[i].login for i in range (0,20)]\n    [u'mateiz',\n     u'beyang',\n     u'abo',\n     u'CodingCat',\n     u'andy327',\n     u'CrazyJvm',\n     u'jyotiska',\n     u'BaiGang',\n     u'sundstei',\n     u'dianacarroll',\n     u'ybotco',\n     u'xelax',\n     u'prabeesh',\n     u'invkrh',\n     u'bedla',\n     u'nadesai',\n     u'pcpratts',\n     u'narkisr',\n     u'Honghe',\n     u'Jacke']\n    ```", "```py\n    import json\n    import mimeparse\n    import requests\n    import urllib\n    from pprint import pprint as pp\n\n    MEETUP_API_HOST = 'https://api.meetup.com'\n    EVENTS_URL = MEETUP_API_HOST + '/2/events.json'\n    MEMBERS_URL = MEETUP_API_HOST + '/2/members.json'\n    GROUPS_URL = MEETUP_API_HOST + '/2/groups.json'\n    RSVPS_URL = MEETUP_API_HOST + '/2/rsvps.json'\n    PHOTOS_URL = MEETUP_API_HOST + '/2/photos.json'\n    GROUP_URLNAME = 'London-Machine-Learning-Meetup'\n    # GROUP_URLNAME = 'London-Machine-Learning-Meetup' # 'Data-Science-London'\n\n    class Mee\n    tupAPI(object):\n        \"\"\"\n        Retrieves information about meetup.com\n        \"\"\"\n        def __init__(self, api_key, num_past_events=10, http_timeout=1,\n                     http_retries=2):\n            \"\"\"\n            Create a new instance of MeetupAPI\n            \"\"\"\n            self._api_key = api_key\n            self._http_timeout = http_timeout\n            self._http_retries = http_retries\n            self._num_past_events = num_past_events\n\n        def get_past_events(self):\n            \"\"\"\n            Get past meetup events for a given meetup group\n            \"\"\"\n            params = {'key': self._api_key,\n                      'group_urlname': GROUP_URLNAME,\n                      'status': 'past',\n                      'desc': 'true'}\n            if self._num_past_events:\n                params['page'] = str(self._num_past_events)\n\n            query = urllib.urlencode(params)\n            url = '{0}?{1}'.format(EVENTS_URL, query)\n            response = requests.get(url, timeout=self._http_timeout)\n            data = response.json()['results']\n            return data\n\n        def get_members(self):\n            \"\"\"\n            Get meetup members for a given meetup group\n            \"\"\"\n            params = {'key': self._api_key,\n                      'group_urlname': GROUP_URLNAME,\n                      'offset': '0',\n                      'format': 'json',\n                      'page': '100',\n                      'order': 'name'}\n            query = urllib.urlencode(params)\n            url = '{0}?{1}'.format(MEMBERS_URL, query)\n            response = requests.get(url, timeout=self._http_timeout)\n            data = response.json()['results']\n            return data\n\n        def get_groups_by_member(self, member_id='38680722'):\n            \"\"\"\n            Get meetup groups for a given meetup member\n            \"\"\"\n            params = {'key': self._api_key,\n                      'member_id': member_id,\n                      'offset': '0',\n                      'format': 'json',\n                      'page': '100',\n                      'order': 'id'}\n            query = urllib.urlencode(params)\n            url = '{0}?{1}'.format(GROUPS_URL, query)\n            response = requests.get(url, timeout=self._http_timeout)\n            data = response.json()['results']\n            return data\n    ```", "```py\n    m = MeetupAPI(api_key='Get_Your_Own_Key')\n    last_meetups = m.get_past_events()\n    pp(last_meetups[5])\n\n    {u'created': 1401809093000,\n     u'description': u\"<p>We are hosting a joint meetup between Spark London and Machine Learning London. Given the excitement in the machine learning community around Spark at the moment a joint meetup is in order!</p> <p>Michael Armbrust from the Apache Spark core team will be flying over from the States to give us a talk in person.\\xa0Thanks to our sponsors, Cloudera, MapR and Databricks for helping make this happen.</p> <p>The first part of the talk will be about MLlib, the machine learning library for Spark,\\xa0and the second part, on\\xa0Spark SQL.</p> <p>Don't sign up if you have already signed up on the Spark London page though!</p> <p>\\n\\n\\nAbstract for part one:</p> <p>In this talk, we\\u2019ll introduce Spark and show how to use it to build fast, end-to-end machine learning workflows. Using Spark\\u2019s high-level API, we can process raw data with familiar libraries in Java, Scala or Python (e.g. NumPy) to extract the features for machine learning. Then, using MLlib, its built-in machine learning library, we can run scalable versions of popular algorithms. We\\u2019ll also cover upcoming development work including new built-in algorithms and R bindings.</p> <p>\\n\\n\\n\\nAbstract for part two:\\xa0</p> <p>In this talk, we'll examine Spark SQL, a new Alpha component that is part of the Apache Spark 1.0 release. Spark SQL lets developers natively query data stored in both existing RDDs and external sources such as Apache Hive. A key feature of Spark SQL is the ability to blur the lines between relational tables and RDDs, making it easy for developers to intermix SQL commands that query external data with complex analytics. In addition to Spark SQL, we'll explore the Catalyst optimizer framework, which allows Spark SQL to automatically rewrite query plans to execute more efficiently.</p>\",\n     u'event_url': u'http://www.meetup.com/London-Machine-Learning-Meetup/events/186883262/',\n     u'group': {u'created': 1322826414000,\n                u'group_lat': 51.52000045776367,\n                u'group_lon': -0.18000000715255737,\n                u'id': 2894492,\n                u'join_mode': u'open',\n                u'name': u'London Machine Learning Meetup',\n                u'urlname': u'London-Machine-Learning-Meetup',\n                u'who': u'Machine Learning Enthusiasts'},\n     u'headcount': 0,\n     u'id': u'186883262',\n     u'maybe_rsvp_count': 0,\n     u'name': u'Joint Spark London and Machine Learning Meetup',\n     u'rating': {u'average': 4.800000190734863, u'count': 5},\n     u'rsvp_limit': 70,\n     u'status': u'past',\n     u'time': 1403200800000,\n     u'updated': 1403450844000,\n     u'utc_offset': 3600000,\n     u'venue': {u'address_1': u'12 Errol St, London',\n                u'city': u'EC1Y 8LX',\n                u'country': u'gb',\n                u'id': 19504802,\n                u'lat': 51.522533,\n                u'lon': -0.090934,\n                u'name': u'Royal Statistical Society',\n                u'repinned': False},\n     u'visibility': u'public',\n     u'waitlist_count': 84,\n     u'yes_rsvp_count': 70}\n    ```", "```py\n    members = m.get_members()\n\n    {u'city': u'London',\n      u'country': u'gb',\n      u'hometown': u'London',\n      u'id': 11337881,\n      u'joined': 1421418896000,\n      u'lat': 51.53,\n      u'link': u'http://www.meetup.com/members/11337881',\n      u'lon': -0.09,\n      u'name': u'Abhishek Shivkumar',\n      u'other_services': {u'twitter': {u'identifier': u'@abhisemweb'}},\n      u'photo': {u'highres_link': u'http://photos3.meetupstatic.com/photos/member/9/6/f/3/highres_10898643.jpeg',\n                 u'photo_id': 10898643,\n                 u'photo_link': u'http://photos3.meetupstatic.com/photos/member/9/6/f/3/member_10898643.jpeg',\n                 u'thumb_link': u'http://photos3.meetupstatic.com/photos/member/9/6/f/3/thumb_10898643.jpeg'},\n      u'self': {u'common': {}},\n      u'state': u'17',\n      u'status': u'active',\n      u'topics': [{u'id': 1372, u'name': u'Semantic Web', u'urlkey': u'semweb'},\n                  {u'id': 1512, u'name': u'XML', u'urlkey': u'xml'},\n                  {u'id': 49585,\n                   u'name': u'Semantic Social Networks',\n                   u'urlkey': u'semantic-social-networks'},\n                  {u'id': 24553,\n                   u'name': u'Natural Language Processing',\n    ...(snip)...\n                   u'name': u'Android Development',\n                   u'urlkey': u'android-developers'}],\n      u'visited': 1429281599000}\n    ```"]