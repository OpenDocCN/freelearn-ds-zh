- en: Predicting Votes with Linear Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter shows how to work with statistical models using R. It shows how
    to check data assumptions, specify linear models, make predictions, and measure
    predictive accuracy. It also shows how to find good models programatically to
    avoid doing analysis by hand, which can potentially save a lot of time. By the
    end of this chapter, we will have worked with various quantitative tools that
    are used in many business and research areas nowadays. The packages used in this
    chapter are the same ones from the previous chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'Just like in the previous chapter, the focus here will be on automating the
    analysis programatically rather than on deeply understanding the statistical techniques
    used in the chapter. Furthermore, since we have seen in [Chapter 2](part0059.html#1O8H60-f494c932c729429fb734ce52cafce730),
    *Understanding Votes With Descriptive Statistics*, how to work efficiently with
    functions, we will use that approach directly in this chapter, meaning that when
    possible we''ll work directly with functions that will be used to automate our
    analysis. We will cover the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Splitting data into training and testing sets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating linear regression models used for prediction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Checking model assumptions with various techniques
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Measuring predictive accuracy for numerical and categorical data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Programatically finding the best possible model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Required packages
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: During this chapter we will make use of the following R packages, which were
    already used in the previous chapter, so you should be good to go.
  prefs: []
  type: TYPE_NORMAL
- en: '| **Package** | **Reason** |'
  prefs: []
  type: TYPE_TB
- en: '| `ggplot2` | High-quality graphs |'
  prefs: []
  type: TYPE_TB
- en: '| `corrplot` | Correlation plots |'
  prefs: []
  type: TYPE_TB
- en: '| `progress` | Show progress for Iteration |'
  prefs: []
  type: TYPE_TB
- en: Setting up the data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As it's usual with data analysis, the first step is to understand the data we
    will be working with. In this case, the data is the same as in [Chapter 2](part0059.html#1O8H60-f494c932c729429fb734ce52cafce730),
    *Understanding Votes with Descriptive Statistics*, and we have already understood
    some of its main characteristics. Mainly, we've understood that age, education,
    and race have considerable effects over the propensity to vote in favor of the
    UK leaving or remaining in the EU.
  prefs: []
  type: TYPE_NORMAL
- en: The focus of this chapter will be on using linear models to predict the `Proportion`
    and `Vote` variables, which contain the percentage of votes in favor of leaving
    the EU and whether the ward had more votes for `"Leave"` or `"Remain"`, respectively.
    Both variables have similar information, the difference being that one is a numerical
    continuous variable with values between 0 and 1 (`Proportion`) and the other is
    a categorical variable with two categories (`Vote` with `Leave` and `Remain` categories).
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll keep observations that contain *complete cases* in the `data` object,
    and observations that have missing values for the `Proportion` and `Vote` variables
    in the `data_incomplete` object (we''ll make predictions over these in the latter
    part of this chapter). The functions `prepare_data()`, `adjust_data()`, and `get_numerical_variables()`
    come from [Chapter 2](part0059.html#1O8H60-f494c932c729429fb734ce52cafce730),
    *Understanding Votes with Descriptive Statistics*, so you may want to take a look
    if you''re not clear about what they do. Basically, they load the data with the
    adjusted version that we created by compressing the data spread among various
    variables regarding age, education, and race:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Training and testing datasets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For us to be able to measure the predictive accuracy of our models, we need
    to use some observations to validate our results. This means that our data will
    be split into three different groups:'
  prefs: []
  type: TYPE_NORMAL
- en: Training data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Testing data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Predicting data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The predicting data is the data that we don't have complete cases for, specifically
    these are wards for which the `Vote` and `Proportion` variables have `NA` values.
    Our final objective is to provide predictions for these ward's `Proportion` and
    `Vote` variables using what we can learn from other wards for which we do have
    data for these variables, and it's something we'll do toward the end of the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: The data that has complete cases will be split into two parts, training, and
    testing data. Training data is used to extract knowledge and learn the relationship
    among variables. Testing is treated as if it had `NA` values for `Proportion`
    and `Vote`, and we produce predictions for them. These predictions are then compared
    to the real values in the corresponding observations, and this helps us understand
    how good our predictions are in a way that is objective since those observations
    are never seen by the trained models.
  prefs: []
  type: TYPE_NORMAL
- en: We created the predicting data in the previous section, and we called it `data_incomplete`.
    To create the training and testing data, we use the `sample()` function. It will
    take as input a list of numbers from which it will pick a certain number of values
    (`size`). The list of numbers will go from 1 to the total number of observations
    available in the data with complete cases. We specify the number of observations
    that will be picked for the training data as around 70% of the total number of
    observations available, and use the `replace = FALSE` argument to specify that
    the picked observations may not be duplicated (by avoiding a sample with replacement).
  prefs: []
  type: TYPE_NORMAL
- en: 'The testing data is composed of the remaining 30% of the observations. Since
    `sample` is a Boolean vector that contains a `TRUE` or `FALSE` value for each
    observation to specify whether or not it should be included, respectively, we
    can negate the vector to pick the other part of the data by prepending a minus
    sign (`-`) to the binary vector, effectively making every `TRUE` value a `FALSE`
    value, and vice versa. To understand this, let''s look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: If we did this process various times, we would find that every time we get different
    samples for the training and testing sets, and this may confuse us about our results.
    This is because the `sample()` function is stochastic, meaning that it will use
    *pseudo random number generator* to make the selection for us (computers can not
    generate real randomness, they simulate numbers that appear to be random even
    though they are not, that's why it's called **pseudo random**). If we want our
    process to be reproducible, meaning that, every time we run it the exact same
    samples are selected, then we must specify an initial seed before applying this
    process to precondition the pseudo random number generator. To do so, we need
    to pass an integer to the `set.seed()` function, as we do at the beginning of
    the code snippet. The seed argument must stay fixed to reproduce the same samples,
    and with it in place, every time we generate a random sample, we will get the
    same sample so that our results are reproducible.
  prefs: []
  type: TYPE_NORMAL
- en: Predicting votes with linear models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we can make any predictions, we need to specify a model and train it
    with our training data (`data_train`) so that it learns how to provide us with
    the predictions we're looking for. This means that we will solve an optimization
    problem that outputs certain numbers that will be used as parameters for our model's
    predictions. R makes it very easy for us to accomplish such a task.
  prefs: []
  type: TYPE_NORMAL
- en: 'The standard way of specifying a linear regression model in R is using the
    `lm()` function with the model we want to build expressed as a formula and the
    data that should be used, and save it into an object (in this case `fit`) that
    we can use to explore the results in detail. For example, the simplest model we
    can build is one with a single regressor (independent variable) as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'In this simple model, we would let R know that we want to run a regression
    where we try to explain the `Proportion` variable using only the `Students` variable
    in the data. This model is too simple, what happens if we want to include a second
    variable? Well, we can add it using the plus (`+`) sign after our other regressors.
    For example (keep in mind that this would override the previous `fit` object with
    the new results, so if you want to keep both of them, make sure that you give
    the resulting objects different names):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'This may be a better way of explaining the `Proportion` variable since we are
    working with more information. However, keep in mind the collinearity problem;
    it''s likely that the higher the students percentage is in a ward (`Students`),
    the higher the percentage of relatively young people (`Age_18to44`), meaning that
    we may not be adding independent information into the regression. Of course, in
    most situations, this is not a binary issue, it''s an issue of degree and the
    analyst must be able to handle such situations. We''ll touch more on this when
    checking the model''s assumptions in the next section. For now let''s get back
    to programming, shall we? What if we want to include all the variables in the
    data? Well, we have two options, include all variables manually or use R''s shortcut
    for doing so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: These two models are exactly the same. However, there are a couple of subtle
    points we need to mention. First, when specifying the model manually, we had to
    leave the `Proportion` variable explicitly out of the regressors (variables after
    the `~` symbol) so that we don’t get an error when running the regressions (it
    would not make sense for R to allow us to try to explain the `Proportion` variable
    by using the same `Proportion` variable and other things). Second, if we make
    any typos while writing the variable names, we will get errors since those names
    will not be present in the variable names (if by coincidence your typo actually
    refers to another existing variable in the data it may be a hard mistake to diagnose).
    Third, in both cases the list of regressors includes variables that should not
    be there, like `ID`, `RegionName`, `NVotes`, `Leave`, and `Vote`. In the case
    `of`
  prefs: []
  type: TYPE_NORMAL
- en: '`ID` it doesn’t make sense for that variable to be included in the analysis
    as it doesn’t have any information regarding the `Proportion`, it''s just an identifier.
    In the case of `RegionName` it''s a categorical variable so the regression would
    stop being a *Standard Multiple Linear Regression* and R would automatically make
    it work for us, but if we do not understand what we’re doing, it may produce confusing
    results. In this case we want to work only with numerical variables so we can
    remove it easily from the manual case, but we can’t do that in the shortcut case.
    Finally, in the case of `NVotes`, `Leave`, and `Vote`, those variables are expressing
    the same information in slightly the same way so they shouldn’t be included since
    we would have a multicollinearity problem.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s say the final model we want to work with includes all the valid numerical
    variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: If we want to use the shortcut method, we can make sure that the data does not
    contain the problematic variables (using the selection techniques we looked at
    in [Chapter 1](part0022.html#KVCC0-f494c932c729429fb734ce52cafce730), *Introduction
    to R*) and then using the shortcut.
  prefs: []
  type: TYPE_NORMAL
- en: 'To take a look at the results in detail, we use the `summary()` function on
    the `fit` object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: These results tell us which command was used to create our model, which is useful
    when you're creating various models and want to quickly know the model associated
    to the results you're looking at. It also shows some information about the distribution
    of the residuals. Next, it shows the regression's results for each variable used
    in the mode. We get the name of the variable (`(Intercept)` is the Standard Linear
    Regression intercept used in the model's specification), the coefficient estimate
    for the variable, the standard error, the *t statistic*, the *p-value*, and a
    visual representation of the *p-value* using asterisks for significance codes.
    At the end of the results, we see other results associated with the model, including
    the *R-squared* and the *F-statistic*. As mentioned earlier, we won't go into
    details about what each of these mean, and we will continue to focus on the programming
    techniques. If you're interested, you may look at Casella and Berger's, *Statistical
    Inference, 2002*, or Rice's, *Mathematical Statistics and Data Analysis, 1995*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have a fitted model ready in the `fit` object, we can use it to
    make predictions. To do so, we use the `predict()` function with the `fit` object
    and the data we want to produce predictions for, `data_test` in our case. This
    returns a vector of predictions that we store in the `predictions` object. We
    will get one prediction for each observation in the `data_test` object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: These predictions can be measured for accuracy as we will do in a later section
    in this chapter. For now, we know how to generate predictions easily with R.
  prefs: []
  type: TYPE_NORMAL
- en: Checking model assumptions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Linear models, as with any kind of models, require that we check their assumptions
    to justify their application. The accuracy and interpretability of the results
    comes from adhering to a model's assumptions. Sometimes these will be rigorous
    assumptions in the sense that if they are not strictly met, then the model is
    not considered to be valid at all. Other times, we will be working with more flexible
    assumptions in which a degree of criteria from the analyst will come into play.
  prefs: []
  type: TYPE_NORMAL
- en: For those of you interested, a great article about models' assumptions is David
    Robinson's, *K-means clust**ering is not free lunch, 2015* ([http://varianceexplained.org/r/kmeans-free-lunch/](http://varianceexplained.org/r/kmeans-free-lunch/)).
  prefs: []
  type: TYPE_NORMAL
- en: 'For linear models, the following are some of the core assumptions:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Linearity**: There is a linear relation among the variables'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Normality**: Residuals are normally distributed'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Homoscedasticity**: Residuals have constant variance'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**No collinearity**: Variables are not linear combinations of each other'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Independence**: Residuals are independent or at least not correlated'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We will show how to briefly check four of the them: linearity, normality, homoscedasticity,
    and no collinearity. We should mention that the independence assumption is probably
    the most difficult assumption to test, and you can generally handle it with common
    sense and understanding how the data was collected. We will not get into that
    here as it''s more in the statistics side of things and we want to keep the book
    focused on programming techniques. For the statistically-interested reader, we
    recommend looking at Jeffrey M. Wooldridge''s, *Introductory Econometrics, 2013*
    and Joshua D. Angrist and Jorn-Steffen Pischke''s, *Mostly Harmless Econometrics,
    2008*.'
  prefs: []
  type: TYPE_NORMAL
- en: Checking linearity with scatter plots
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A basic way of checking the linearity assumption is to make a scatter plot
    with the dependent variable in the *y* axis and an independent variable in the
    *x* axis. If the relation appears to be linear, the assumption is validated. In
    any interesting problem it''s extremely hard to find a scatter plot that shows
    a very clear linear relation, and if it does happen we should be a little suspicious
    and careful with the data. To avoid reinventing the wheel, we will use the `plot_scatterlot()`
    function we created in [Chapter 2](part0059.html#1O8H60-f494c932c729429fb734ce52cafce730),
    *Understanding Votes with Descriptive Statistics*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, the scatter plot on the left shows a clear linear relation, as
    the percentage of people between 18 and 44 years of age (`Age_18to44`) increases,
    the proportion of people in favor of leaving the EU (`Proportion`) decreases.
    On the right hand, we see that the relation among the percentage of students in
    a ward (`Students`) and `Proportion` is clearly linear in the initial area (where
    `Students` is between 0 and 20), after that the relation too seems to be linear,
    but it is polluted by observations with very high percentage of students. However,
    we can still assume a linear relation between `Students` and `Proportion`.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00022.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: When we're doing a *Multiple Linear Regression* as we're doing here, the assumption
    should be checked for the rest of the variables, which we omit here to preserve
    space, but we encourage you to do so. Keep in mind that it's very hard to find
    a linear relation in all of them, and this assumption is mostly an indicator of
    the predictive power of the variable in the regression. As long as the relation
    appears to be slightly linear, we should be all set.
  prefs: []
  type: TYPE_NORMAL
- en: Checking normality with histograms and quantile-quantile plots
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will check normality with two different techniques so that we can exemplify
    the usage of a technique known as the **strategy pattern**, which is part of a
    set of patterns from object-oriented programming. We will go deeper into these
    patterns in [Chapter 8](part0178.html#59O440-f494c932c729429fb734ce52cafce730),
    *Object-Oriented System **to Track Cryptocurrencies*.
  prefs: []
  type: TYPE_NORMAL
- en: 'For now, you can think of the strategy pattern as a technique that will re-use
    code that would otherwise be duplicated and simply changes a way of doing things
    called the **strategy**. In the following code you can see that we create a function
    called `save_png()` which contains the code that would be duplicated (saving PNG
    files) and doesn''t need to be. We will have two strategies, in the form of functions,
    to check data normality—histograms and quantile-quantile plots. These will be
    sent through the argument conveniently named `functions_to_create_images`. As
    you can see, this code receives some data, a variable that will be used for the
    graph, the file name for the image, and a function that will be used to create
    the graphs. This last parameter, the function, should not be unfamiliar to the
    reader as we have seen in [Chapter 1](part0022.html#KVCC0-f494c932c729429fb734ce52cafce730),
    *Introduction to R*, that we can send functions as arguments, and use them as
    we do in this code, by calling them through their *new name* inside the function,
    `function_to_create_image()` in this case:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we show the code that will make use of this `save_png()` function and encapsulate
    the knowledge of the function that is used for each case. In the case of the histograms,
    the `histogram()` function shown in the following code simply wraps the `hist()`
    function used to create the graph with a common interface that will also be used
    by the other strategies (the `quantile_quantile()` function shown in the following
    code in this case). This common interface allows us to use these strategies as
    plugins that can be substituted easily as we do in the corresponding `variable_histogram()`
    and `variable_qqplot()` functions (they both do the same call, but use a different
    strategy in each case). As you can see, other details that are not part of the
    common interface (for example, `main` and `xlab`) are handled within each strategy''s
    code. We could add them as optional arguments if we wanted to, but it''s not necessary
    for this example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The following shows the graph for checking proportion normality:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00023.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: If we wanted to share the code used to create the PNG images with a third (or
    more) strategies, then we can simply add a strategy wrapper for each new case
    without worrying about duplicating the code that creates the PNG images. It may
    seem that this is not a big deal, but imagine that the code used to create the
    PNG files was complex and suddenly you found a bug. What would you need to fix
    that bug? Well, you'd have to go to every place where you duplicated the code
    and fix it there. Doesn't seem very efficient. Now, what happens if you no longer
    want to save PNG files and want to instead save JPG files? Well, again, you would
    have to go everywhere you have duplicated your code and change it. Again, not
    very efficient. As you can see, this way of programming requires a little investment
    upfront (creating the common interfaces and providing wrappers), but the benefit
    of doing so will pay for itself through the saved time, you do need to change
    the code, if only once, as well as more understandable and simpler code. This
    is a form of **dependency management** and is something you should learn how to
    do to become a more efficient programmer.
  prefs: []
  type: TYPE_NORMAL
- en: You may have noticed that in the previous code, we could have avoided one function
    call by having the user call directly the `save_png()` function. However, doing
    so would require the user to have knowledge of two things, the `save_png()` function
    to save the image and the `quantile_quantile()` or `histogram()` functions to
    produce the plots, depending on what she was trying to plot. This extra burden
    in the user, although seemingly not problematic, could make things very confusing
    for her since not many users are used to sending functions as arguments, and they
    would have to know two function signatures, instead of one.
  prefs: []
  type: TYPE_NORMAL
- en: Providing a wrapper whose signature is easily usable as we do with `variable_histogram()`
    and `variable_qqplot()` makes it easier on the user, and allows us to expand the
    way we want to show graphs in case we want to change that later without making
    the user learn a new function signature.
  prefs: []
  type: TYPE_NORMAL
- en: 'To actually produce the plots we''re looking for, we use the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, the histogram shows an approximate normal distribution slightly
    skewed towards the right, but we can easily accept it as being normal. The corresponding
    quantile-quantile plot shows the same information in a slightly different way.
    The line it shows corresponds to the quantiles of the normal distribution, and
    the dots show the actual distribution in the data. The closer these dots are to
    the line, the closer the variable's distribution is to being normally distributed.
    As we can see, for the most part, `Proportion` is normally distributed, and it's
    at the extremes that we can see a slight deviation, which probably comes from
    the fact that our `Proportion` variable actually has hard limits at 0 and 1\.
    However, we can also accept it as being normally distributed, and we can proceed
    to the next assumption safely.
  prefs: []
  type: TYPE_NORMAL
- en: Checking homoscedasticity with residual plots
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Homoscedasticity** simply means that we need the data to have constant variance
    in our residuals. To check for it, we can use the `plot(fit)` function call. However,
    this will show one plot at a time asking you to hit *Enter* on your keyboard to
    show the next one. This kind of mechanism is not friendly to the automation processes
    we are creating. So we need a little adjustment. We will use the `par(mfrow =
    c(2, 2))` call to tell the `plot()` function to graph all four plots at the same
    time and show it in a single image. We wrap the command around our already familiar
    mechanism to save PNGs around the `fit_plot()` function, and we''re all set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'With the `fit_plot()` function in place, we can show the regressions graphical
    results with the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/00024.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The information we're looking for is in the plots on the left-hand side, where
    we see fitted values in the x axis and residuals in the y axis. In these plots,
    we are looking for residuals to be randomly distributed in a tubular pattern,
    indicated by the dotted lines. We do not want residuals with a pattern that looks
    similar to a fan or funnel or in any way curvilinear. As we can see, the pattern
    we see does resemble a tubular pattern, so we can say the assumption of homoscedasticity
    holds for the data. As an extra, you can also see, in the top-right quantile-quantile
    plot, that the residuals follow a normal distribution which is also good. The
    plot on the lower-right shows a statistics concept, which we won't go into, called
    Cook's distance, which is used to find *influential* observations in a regression.
    To read more about it, you may look at John Fox's, *Regression Diagnostics, 1991*.
  prefs: []
  type: TYPE_NORMAL
- en: Checking no collinearity with correlations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To check no collinearity, we could use a number of different techniques. For
    example, for those familiar with linear algebra, the condition number is a measure
    of how singular a matrix is, where singularity would imply perfect collinearity
    among the covariates. This number could provide a measure of this collinearity.
    Another technique is to use the *Variance Inflation Factor*, which is a more formal
    technique that provides a measure of how much a regression's variance is increased
    because of collinearity. Another, and a more common, way of checking this is with
    simple correlations. Are any variables strongly correlated among themselves in
    the sense that there could be a direct relation among them? If so, then we may
    have a multicollinearity problem. To get a sense of how correlated our variables
    are, we will use the correlations matrix techniques shown in [Chapter 2](part0059.html#1O8H60-f494c932c729429fb734ce52cafce730),
    *Understanding Votes with Descriptive Statistics*.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code shows how correlations work in R:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, the strong correlations (either positive or negative) are occurring
    intra-groups not inter-groups, meaning that variables that measure the same thing
    in different ways appear to be highly correlated, while variables that measure
    different things don't appear to be highly correlated.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00025.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: For example, `Age_18to44` and `Age_45plus` are variables that measure age, and
    we expect them to have a negative relation since the higher the percentage of
    young people in a ward is, by necessity, the percentage of older people is lower.
    The same relation can be seen in the housing group (`Owned`, `OwnedOutright`,
    `SocialRent`, and `PrivateRent`), the employment group (`Unemp`, `UnempRate_EA`,
    and `HigherOccup`), the deprived group (`Deprived` and `MultiDepriv`), ethnic
    group (`White` and `NonWhite`), the residency group (`Residents` and `Households`),
    and the education group (`LowEducationLevel` and `HighEducationLevel`). If you
    pick variables belonging to different groups, the number of strong correlations
    is significantly lower, but it's there. For example, `HigherOccup` is strongly
    correlated to `HighEducationLevel` and `LowEducationLevel`, positively and negatively,
    respectively. Also, variables in the housing group seem to be correlated with
    variables in the age group. These kinds of relations are expected and natural
    since highly educated people will most probably have better jobs, and young people
    probably can't afford a house yet, so they rent. As analysts, we can assume that
    these variables are in fact measuring different aspects of society and continue
    on with our analysis. However, these are still things you may want to keep in
    mind when interpreting the results, and we may also want to only include one of
    the variables in each group to avoid inter-group collinearity, but we'll avoid
    these complexities and continue with our analysis for now.
  prefs: []
  type: TYPE_NORMAL
- en: Linear regression is one of those types of models that require criteria from
    the analyst to be accepted or rejected. In our specific case, it seems that our
    model's assumptions are valid enough and we may safely use it to provide credible
    predictions as we will do in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: Measuring accuracy with score functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have checked our model's assumptions, we turn toward measuring it's
    predictive power. To measure our predictive accuracy, we will use two methods,
    one for numerical data (`Proportion`) and the other for categorical data (`Vote`).
    We know that the `Vote` variable is a transformation from the `Proportion` variable,
    meaning that we are measuring the same information in two different ways. However,
    both numerical and categorical data are frequently encountered in data analysis,
    and thus we wanted to show both approaches here. Both functions, `score_proportions()`
    (numerical) and `score_votes()` (categorical) receive the data we use for testing
    and the predictions for each of the observations in the testing data, which come
    from the model we built in previous sections.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the numerical case, `score_proportions()` computes a score using the following
    expression:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00026.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, `Y_i` is the *real response* variable value for the *i*th observation
    in the testing data, `Y''_i` is our prediction for that same observation, `SE`
    is our prediction''s standard error, and `n` is the number of observations in
    the testing data. This equation establishes that the score, which we want to minimize,
    is the average of *studentized residuals*. Studentized residuals, as you may know,
    are residuals divided by a measure of the standard errors. This formula gives
    us an average measure of how close we are to predicting an observation''s value
    correctly relative to the variance observed for that data range. If we have a
    high degree of variance (resulting in high standard errors), we don''t want to
    be too strict with the prediction, but if we are in a low-variance area, we want
    to make sure that our predictions are very accurate:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'In the categorical case, `score_votes()` computes a score by simply counting
    the number of times our predictions pointed toward the correct category, which
    we want to maximize. We do that by first using the same classification mechanism
    (if the predicted `Proportion` is larger than 0.5, then we classify it as a `"Leave"`
    vote and vice versa), and compare the categorical values. We know that the sum
    of Boolean vector will be equal to the number of `TRUE` values, and that''s what
    we''re using in the `sum(real == predicted)` expression:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'To test our model''s scores, we do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: In the case of the `score_votes()` function, the measure by itself tells us
    how well we are doing with our predictions since we can take the number of correct
    predictions (the output of the function call, which is 216), and divide it by
    the number of observations (rows) in the `data_test` object (which is 241). This
    gives us a precision of 89%. This means that if we are given the data from the
    regressors but we don't know how the ward actually voted, 89% of the time, we
    would provide a prediction for whether they wanted to leave or remain in the EU,
    which would be correct. This is pretty good if you ask me.
  prefs: []
  type: TYPE_NORMAL
- en: In the case of the `score_proportions()` function, since we're using a more
    abstract measure to be able to know how good we're doing, we would like to compare
    it against other model's scores and get a relative sense of the model's predictive
    power, and that's exactly what we'll do in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: Programatically finding the best model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have seen how to produce scores that represent how good or bad a
    model's predictive power is, you may go ahead and start specifying lots of models
    manually by changing the combinations of variables sent to the `lm()` function,
    compute each model's scores, and then choose the ones with the highest predictive
    power. This can potentially take a large amount of time, and you may want to delegate
    it to someone else since it's tedious work. However, fear not. There's a better
    way! Computers are good at repetitive and tedious tasks, and now we'll see how
    to tell the computer to find the best model for us with a little bit of programming.
  prefs: []
  type: TYPE_NORMAL
- en: The following sections will increase the programming level, but don't worry
    we'll explain the code in detail to make sure that everything is understood. If
    at any point you feel confused, you can always copy-paste small snippets of code
    into your R terminal and see what each of them are doing individually to gradually
    get a sense of the whole thing.
  prefs: []
  type: TYPE_NORMAL
- en: Generating model combinations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The first thing we need to do is develop a way of getting the combinations
    of regressors we want to test. Since this is a combinatorial problem, the number
    of combinations is exponential with the number of available options. In our case,
    with the 19 available variables, the number of possible models is the sum of the
    number of models we can create with one regressor plus the number of models we
    can create with two regressors, and so on, until we sum the number of models we
    can create with all 19 regressors. This is what the sum is:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00027.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Of course, computing so many models, although easy for a computer, may take
    a while, so we want to limit the minimum and maximum number of regressors allowed
    in the combinations. To do so, we specify the minimum and maximum percentage of
    regressors that will be included in the `min_percentage` and `max_percentage`
    parameters, respectively. In our case, if we specify `min_percentage = 0.9` and
    `max_percentage = 1.0`, we're asking for all combinations that contain between
    17 and 19 of the regressors, which adds up to 191 models. Imagine the time it
    would take you to generate 191 model specifications manually! Hopefully thinking
    about that will make you realize the power of this technique.
  prefs: []
  type: TYPE_NORMAL
- en: To start, we create the `generate_combinations_unvectorized()` function that
    will output the a list with all the possible combinations given the `variables`
    and the `min_percentage` and `max_percentage` parameters mentioned earlier. The
    first thing we do is remove the `Proportion` variable by specifying it as `FALSE`
    in the `variables` vector (the `variables` object here corresponds to the `numerical_variables`
    object, but we have adjusted its name within this function to make it more readable).
    The other unwanted variables (`NVotes`, `Leave`, `Vote`, and `RegionName`) were
    removed in the `get_numerical_variable_names()` function at the beginning of the
    chapter. Next, we get the actual names of the variables with `TRUE` values so
    that we can work with string and not Boolean. After that, we compute the total
    number of variables as `n`, and the actual number of variables we will include
    in the combinations by taking the percentage parameters, multiplying them by the
    number of variables, and getting either the *floor* or *ceiling* for that number
    to make sure that we include the extremes. After that, we initialize the `all_combinations`
    object that will contain the list of combinations we want. The next part is the
    progress bar object that we won't explain as we have used it before.
  prefs: []
  type: TYPE_NORMAL
- en: The actual work is done inside the `for` loop. Notice that it goes from the
    minimum to the maximum number of variables we want inside our combinations. In
    each iteration, we compute the number of combinations which is returned to us
    as a matrix where each column represents a different combination and each row
    contains the index of the variables for that particular combination. This means
    that we need to add each of those columns to our total list of combinations (`all_combinations`),
    which is what we do inside the nested `for` loop. Finally, since we have nested
    lists, we want to use the `unlist()` function to bring them to the *same level*,
    but we don't want to do it recursively because we would just end with a single
    long list and we wouldn't be able to differentiate one combination from another.
  prefs: []
  type: TYPE_NORMAL
- en: I encourage you to change the return statement to avoid using the `recursive
    = FALSE` parameter, as well as avoiding the use of the `unlist()` function at
    all. Doing so will quickly show you what effect they have on the function's output,
    and why we need them.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'A sample output of the object that the `generate_combinations_unvectorized()`
    function does is shown next. As you can see, it''s a list where each element is
    a vector or type `character`. The first combination created contains only 17 variables,
    which is the minimum number of variables used when the total number of variables
    is 19 and the minimum percentage requested is 90%. The last combination (combination
    number 191), contains all 19 variables and corresponds to the model we built manually
    earlier in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Getting only those combinations that contain between 90% and 100% of the variables
    may seem a bit restrictive. What if we want to generate all possible combinations?
    In that case, we would change the first parameter to be 0, but it may not finish
    in a practical amount of time. The reason is that our `generate_combinations_unvectorized()`
    function, as the name implies, is not vectorized, and even worse, has nested `for`
    loops. This is a huge bottleneck in this particular case, and it's something you
    want to look out for in your own code. One possible solution is to make a *vectorized*
    version of the function. For those of you interested, we have included a file
    named `vectorized_vs_unvectorized.R` in this book's code repository ([https://github.com/PacktPublishing/R-Programming-By-Example](https://github.com/PacktPublishing/R-Programming-By-Example)),
    that shows the said implementation. We also include some tests that will show
    you just how much faster the vectorized implementation is. Just to give you a
    spoiler, it can be hundreds of times faster! For those cases where vectorizing
    and other approaches that only depend on R itself are not good enough, you can
    try delegating the task to a faster (compiled) language. We will see how to do
    that in [Chapter 9](part0229.html#6QCGQ0-f494c932c729429fb734ce52cafce730), *Implementing
    an Efficient Simple Moving Average.*
  prefs: []
  type: TYPE_NORMAL
- en: 'Going back to our example, the next thing to do is to create the `find_best_fit()`
    function, which will go through each of the combinations generated, use the `data_train`
    data to train a model with the corresponding combination, test it''s accuracy
    with the `measure` selection (either `Proportion` (numerical) or `Vote` (categorical))
    and will save the corresponding score in a `scores` vector. Then, it will find
    the index of the optimal score by either finding the minimum or maximum score,
    depending on the `measure` selection we''re using (`Proportion` requires us to
    minimize while `Vote` requires us to maximize), and finally it will recreate the
    optimal model, print it''s information, and return the model to the user. The
    `compute_model_and_fit()`, `compute_score()`, and `print_best_model_info()` functions
    will be developed next as we''re following a top-down approach:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we create the `compute_model_and_fit()` function, which simply generates
    the formula for the selected combination and uses it within the `lm()` function.
    As you can see in the `combinations` object, we returned previously from the `generate_combinations_unvectorized()`
    function, it''s a list with character vectors, it''s not a formula we can pass
    to the `lm()` function; this is why we need the `generate_model()` function, which
    will take on of these vectors, and concatenate its elements into a single string
    with the plus (`+`) sign between them by using the `paste()` function with the
    `collapse = " + "` argument, and it will prepend the `Proportion ~` string to
    it. This gives us back a formula object specified by a string like `Proportion
    ~ Residents + ... + NonWhite`, which contains, instead of the dots, all the variables
    in the first combination shown in the preceding code. This string is then used
    inside the `lm()` function to execute our regression, and both `model` and `fit`
    are returned within a list to be used in the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'As can be seen by the `score <- compute_score(measure, results[["fit"]], data_test)`
    line, the `compute_score()` function receives a `measure` object, a `fit` object
    (which comes from the `results` list), and the data used for testing. It computes
    the score using the *strategy* pattern mentioned earlier for the plots used to
    check the normality assumption. Basically, depending on the value of the `measure`
    string (the chosen strategy), it will choose one of the two functions that share
    the same signature, and that function will be used to compute the final predictions.
    We send the `se.fit = TRUE` parameter to the `predict()` function we had seen
    before because we want the standard errors to also be sent in case we use the
    numerical score which requires them. The `score_proportions()` and `score_votes()`
    functions were defined previously in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we create a little convenience function called `print_best_model_info()`
    that will print results about the best model found. It simply takes the index
    of the best model, the model formula, its score, and the measure type, and prints
    all of that for the user. As you can see, since the `model` object is not a simple
    string but a *formula* object, we need to work a little with it to get the results
    we want by converting it into a string and splitting it using the plus sign (`+`)
    we know is included; otherwise, it would be a very long string:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'We can find the best model, according to the `Proportion` measure by calling
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, the best model was the third one out of the 191 models, and it
    had a score of 10.23\. We can also see the regressors used in the model. As you
    can see, `NonWhite` and `HighEducationLevel` were left out by the optimization
    method, probably due to their counterparts containing all the information necessary
    for their respective groups. It's no coincidence that those are among the most
    representative variables in the data.
  prefs: []
  type: TYPE_NORMAL
- en: 'To find the best model according to the `Vote` measure, we use the following
    code. Note that given the good techniques we used to create this function, all
    we have to do is change the value of the `measure` parameter to optimize our search
    using a different approach:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: In this case, the best model was the seventh one out of the 191 models, with
    220 out of 241 correct predictions, which gives us an accuracy of 91%, an improvement
    given the accuracy we had computed earlier in the chapter. In this case, `LowEducationLevel`
    and `Age_18to44` were left out. Again, no coincidence that these are part of the
    most important variables in the data.
  prefs: []
  type: TYPE_NORMAL
- en: Predicting votes from wards with unknown data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we know how to train our models and find the best one possible, we
    will provide predictions for those wards for which we don''t have voting data
    using the best models we found using the `Vote` measure. To do so, we simply execute
    the following line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: This will take the best model we found earlier using the `Votes` measure and
    use it to generate predictions for the `Proportion` variable in the `data_incomplete`
    data, which contains those observations for which we don't have any voting data.
    These are the best predictions we can provide with what we have done so far and
    we can expect them to have a 91% accuracy when used to categorize the `Proportion`
    variable into the `Vote` variable.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter showed how to use multiple linear regression models, one of the
    most commonly used family of models, to predict numerical and categorical data.
    Our focus was on showing programming techniques that allow analysts to be more
    efficient in the projects while keeping their code quality high. We did so by
    showing how to create different model combinations programatically, measuring
    the predictive accuracy, and selecting the best one. The techniques used can easily
    be used with other, more advanced, types of models, and we encourage you to try
    to improve on the predictive accuracy by using other families of models. In the
    code that accompanies this book ([https://github.com/PacktPublishing/R-Programming-By-Example](https://github.com/PacktPublishing/R-Programming-By-Example)),
    you can find an implementation that also uses generalized linear models to produce
    predictions.
  prefs: []
  type: TYPE_NORMAL
- en: In the following chapter, we will start working with a different and slightly
    less technical example that uses product data from a hypothetical company to show
    how to work with manipulative data in a variety of ways and use it with many kinds
    of visualizations, including 3D, interactive, and geospatial graphs.
  prefs: []
  type: TYPE_NORMAL
