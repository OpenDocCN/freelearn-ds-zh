<html><head></head><body><div><div><div><div><h1 class="title"><a id="ch11"/>Chapter 11. Working with Databases</h1></div></div></div><p>In the previous chapter, you learned the basic concepts of object-oriented programming. These include class and methods, and how they are connected by generic functions in R through method dispatch. You learned about the basic usage of S3, S4, RC, and R6, including defining classes and generic functions as well as implementing methods for certain classes.</p><p>Now that we have covered most of the important features of R, it is time we go ahead and discuss more practical topics. In this chapter, we will begin the discussion with how R can be used to work with databases, which is perhaps the first step of many data-analysis projects: extracting data from a database. More specifically, we will cover the following topics:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Understanding relational databases</li><li class="listitem" style="list-style-type: disc">Using SQL to query relational databases such as SQLite and MySQL</li><li class="listitem" style="list-style-type: disc">Working with NoSQL databases such as MongoDB and Redis</li></ul></div><div><div><div><div><h1 class="title"><a id="ch11lvl1sec58"/>Working with relational databases</h1></div></div></div><p>In the previous chapters, we used a family of built-in functions such as <code class="literal">read.csv</code> and <code class="literal">read.table</code> to import data from separator-delimited files, such as those in the csv format. Using text formats to store data is handy and portable. When the data file is large, however, such a storage method may not be the best way.</p><p>There are three main reasons why text formats can no longer be easy to use. They are as follows:</p><div><ol class="orderedlist arabic"><li class="listitem">Functions such as <code class="literal">read.csv()</code> are mostly used to load the whole file into memory, that is, a data frame in R. If the data is too large to fit into the computer memory, we simply cannot do it.</li><li class="listitem">Even if the dataset is large, we usually don't have to load the whole dataset into memory when we work on a task. Instead, we often need to extract a subset of the dataset that meets a certain condition. The built-in data-importer functions simply do not support querying a csv file.</li><li class="listitem">The dataset is still updating, that is, we need to insert records into the dataset periodically. If we use the csv format, inserting data can be painful, especially if we want to insert the records in the middle of the file and keep it in order.</li></ol></div><p>Using a database is the best solution for these scenarios. It makes it much easier to store data that may exceed computer memory. Data in a database is queryable subject to user-supplied condition, which also makes it easier to update existing records and insert new records within a database.</p><p>A relational database is a collection of tables and relations between tables. A table in a relational database has the same representation with a data frame in R. Tables can have relations that make it easier to join the information of multiple tables.</p><p>In this section, we will start from the simplest database, SQLite (<a class="ulink" href="http://sqlite.org/">http://sqlite.org/</a>), a portable, lightweight database engine.</p><p>To work with SQLite databases in R, we will use the <code class="literal">RSQLite</code> package. To install it from CRAN, run the following code:</p><pre class="programlisting">install.packages("RSQLite") &#13;
</pre><div><div><div><div><h2 class="title"><a id="ch11lvl2sec130"/>Creating a SQLite database</h2></div></div></div><p>First, let's see how to create a SQLite database. If we want to create an example database at <code class="literal">data/example.sqlite</code>, we need to ensure that the directory is available. If the directory does not exist, we have to create one:</p><pre class="programlisting">if (!dir.exists("data")) dir.create("data") &#13;
</pre><p>Now, the <code class="literal">data/</code> directory is available. Next, we will load the <code class="literal">RSQLite</code> package and create a connection by supplying a database driver (<code class="literal">SQLite()</code>) and database file (<code class="literal">data/example.sqlite</code>). Although the file does not exist, the driver creates an empty file that is an empty SQLite database:</p><pre class="programlisting">library(RSQLite) &#13;
## Loading required package: DBI &#13;
con &lt;- dbConnect(SQLite(), "data/example.sqlite") &#13;
</pre><p>The database connection, <code class="literal">con</code>, is a layer between the user and the system. We can create a connection to a relational database and query, fetch, or update data through it. The connection will be used in all subsequent operations until we close the connection. In a typical relational database, we can create tables with a name and columns of certain names and data types, insert records as rows to a table, and update existing records. A table in a relational database looks very similar to a data frame in R.</p><p>Now, we will create a simple data frame that is to be inserted as a table to the database:</p><pre class="programlisting">example1 &lt;- data.frame( &#13;
id = 1:5,  &#13;
type = c("A", "A", "B", "B", "C"), &#13;
score = c(8, 9, 8, 10, 9),  &#13;
stringsAsFactors = FALSE) &#13;
example1 &#13;
##   id type score &#13;
## 1  1    A     8 &#13;
## 2  2    A     9 &#13;
## 3  3    B     8 &#13;
## 4  4    B    10 &#13;
## 5  5    C     9 &#13;
</pre><p>The data frame is ready and we will call <code class="literal">dbWriteTable()</code> to write this data frame as a table to the database:</p><pre class="programlisting">dbWriteTable(con, "example1", example1) &#13;
## [1] TRUE &#13;
</pre><p>In the preceding code, we may well use other table names but still store the same data. Finally, we will disconnect the database using <code class="literal">dbDisconnect()</code> so that <code class="literal">con</code> is no longer available for data operations:</p><pre class="programlisting">dbDisconnect(con) &#13;
## [1] TRUE &#13;
</pre><div><div><div><div><h3 class="title"><a id="ch11lvl3sec64"/>Writing multiple tables to a database</h3></div></div></div><p>A SQLite database is a collection of tables. Therefore, we can store many tables in one database.</p><p>This time, we put the <code class="literal">diamonds</code> dataset in <code class="literal">ggplot2</code> and the <code class="literal">flights</code> dataset in <code class="literal">nycflights13</code> as two tables into one database. If you haven't installed these two packages, run the following code:</p><pre class="programlisting">install.packages(c("ggplot2", "nycflights13")) &#13;
</pre><p>When the packages are available, we will call <code class="literal">data()</code> to load the two data frames:</p><pre class="programlisting">data("diamonds", package ="ggplot2") &#13;
data("flights", package ="nycflights13") &#13;
</pre><p>We will repeat the same operation as we did earlier, but <code class="literal">dbWriteTable()</code> ends up with errors:</p><pre class="programlisting">con &lt;- dbConnect(SQLite(), "data/datasets.sqlite") &#13;
dbWriteTable(con, "diamonds", diamonds, row.names = FALSE) &#13;
## Error in (function (classes, fdef, mtable) : unable to find an inherited method for function 'dbWriteTable' for signature '"SQLiteConnection", "character", "tbl_df"' &#13;
dbWriteTable(con, "flights", flights, row.names = FALSE) &#13;
## Error in (function (classes, fdef, mtable) : unable to find an inherited method for function 'dbWriteTable' for signature '"SQLiteConnection", "character", "tbl_df"' &#13;
dbDisconnect(con) &#13;
## [1] TRUE &#13;
</pre><p>It can be useful to take a look at the class of these two variables:</p><pre class="programlisting">class(diamonds) &#13;
## [1] "tbl_df"     "tbl"        "data.frame" &#13;
class(flights) &#13;
## [1] "tbl_df"     "tbl"        "data.frame" &#13;
</pre><p>Note that <code class="literal">diamonds</code> and <code class="literal">flights</code> are not simply of class <code class="literal">data.frame</code> but something more complex. To write them into the database, we need to convert them to plain <code class="literal">data.frame</code> objects using <code class="literal">as.data.frame()</code>:</p><pre class="programlisting">con &lt;- dbConnect(SQLite(), "data/datasets.sqlite") &#13;
dbWriteTable(con, "diamonds", as.data.frame(diamonds), row.names = FALSE) &#13;
## [1] TRUE &#13;
dbWriteTable(con, "flights", as.data.frame(flights), row.names = FALSE) &#13;
## [1] TRUE &#13;
dbDisconnect(con) &#13;
## [1] TRUE &#13;
</pre><p>Now, the database contains two tables.</p></div><div><div><div><div><h3 class="title"><a id="ch11lvl3sec65"/>Appending data to a table</h3></div></div></div><p>As mentioned in the beginning of this section, appending records to a table in the database is fairly easy. Here is a simple example where we produce several chunks of data and append them to a database table in turn:</p><pre class="programlisting">con &lt;- dbConnect(SQLite(), "data/example2.sqlite") &#13;
chunk_size &lt;- 10 &#13;
id &lt;- 0 &#13;
for (i in 1:6) { &#13;
  chunk &lt;- data.frame(id = ((i - 1L) * chunk_size):(i * chunk_size -1L),  &#13;
    type = LETTERS[[i]], &#13;
    score =rbinom(chunk_size, 10, (10 - i) /10), &#13;
    stringsAsFactors =FALSE) &#13;
  dbWriteTable(con, "products", chunk,  &#13;
    append = i &gt; 1, row.names = FALSE) &#13;
} &#13;
dbDisconnect(con) &#13;
## [1] TRUE &#13;
</pre><p>Note that each chunk is a data frame with some determined data and some random numbers. Each time, we append these records to a table named <code class="literal">products</code>. The difference between this example and the previous ones is that when we call <code class="literal">dbWriteTable()</code>, we use <code class="literal">append = FALSE</code> for the first chunk to create that table in the database and use <code class="literal">append = TRUE</code> for each subsequent chunk to append to the existing table.</p></div></div><div><div><div><div><h2 class="title"><a id="ch11lvl2sec131"/>Accessing tables and table fields</h2></div></div></div><p>Once we have a SQLite database, we can access not only the data we store in the tables, but also some metadata, such as the names of all tables and the columns of a table.</p><p>To demonstrate, we will connect to the SQLite database we created previously:</p><pre class="programlisting">con &lt;- dbConnect(SQLite(), "data/datasets.sqlite") &#13;
</pre><p>We can use <code class="literal">dbExistsTable()</code> to detect whether a table exists in the database:</p><pre class="programlisting">dbExistsTable(con, "diamonds") &#13;
## [1] TRUE &#13;
dbExistsTable(con, "mtcars") &#13;
## [1] FALSE &#13;
</pre><p>Since we only wrote <code class="literal">diamonds</code> and <code class="literal">flights</code> in <code class="literal">datasets.sqlite</code> previously,
 <code class="literal">dbExistsTable()</code> returns the correct values. On the contrary to detecting table existence, we can use <code class="literal">dbListTables()</code> to list all the existing tables in the database:</p><pre class="programlisting">dbListTables(con) &#13;
## [1] "diamonds" "flights" &#13;
</pre><p>For a certain table, we can also list the names of all columns (or fields) with <code class="literal">dbListFields()</code>:</p><pre class="programlisting">dbListFields(con, "diamonds") &#13;
##  [1] "carat"   "cut"     "color"   "clarity" "depth"   &#13;
##  [6] "table"   "price"   "x"       "y"       "z" &#13;
</pre><p>Contrary to <code class="literal">dbWriteTable()</code>, <code class="literal">dbReadTable()</code> reads the whole table into a data frame:</p><pre class="programlisting">db_diamonds &lt;- dbReadTable(con, "diamonds") &#13;
dbDisconnect(con) &#13;
## [1] TRUE &#13;
</pre><p>We can make a comparison between the data frame (<code class="literal">db_diamonds</code>) we read from the database and the original version (<code class="literal">diamonds</code>):</p><pre class="programlisting">head(db_diamonds, 3) &#13;
##   carat     cut color clarity depth table price    x    y &#13;
## 1  0.23   Ideal     E     SI2  61.5    55   326 3.95 3.98 &#13;
## 2  0.21 Premium     E     SI1  59.8    61   326 3.89 3.84 &#13;
## 3  0.23    Good     E     VS1  56.9    65   327 4.05 4.07 &#13;
##      z &#13;
## 1 2.43 &#13;
## 2 2.31 &#13;
## 3 2.31 &#13;
head(diamonds, 3) &#13;
##   carat     cut color clarity depth table price    x    y &#13;
## 1  0.23   Ideal     E     SI2  61.5    55   326 3.95 3.98 &#13;
## 2  0.21 Premium     E     SI1  59.8    61   326 3.89 3.84 &#13;
## 3  0.23    Good     E     VS1  56.9    65   327 4.05 4.07 &#13;
##      z &#13;
## 1 2.43 &#13;
## 2 2.31 &#13;
## 3 2.31 &#13;
</pre><p>The data in both data frames looks exactly the same. However, if we use <code class="literal">identical()</code> to compare them, they are not really identical:</p><pre class="programlisting">identical(diamonds, db_diamonds) &#13;
## [1] FALSE &#13;
</pre><p>To spot the difference, we can call <code class="literal">str()</code> to reveal the structure of both data frames. First, here is the structure of the data frame in the database:</p><pre class="programlisting">str(db_diamonds) &#13;
## 'data.frame':    53940 obs. of  10 variables: &#13;
##  $ carat  : num  0.23 0.21 0.23 0.29 0.31 0.24 0.24... &#13;
##  $ cut    : chr  "Ideal" "Premium" "Good" "Premium" ... &#13;
##  $ color  : chr  "E" "E" "E" "I" ... &#13;
##  $ clarity: chr  "SI2" "SI1" "VS1" "VS2" ... &#13;
##  $ depth  : num  61.5 59.8 56.9 62.4 63.3 62.8 62.3... &#13;
##  $ table  : num  55 61 65 58 58 57 57 55 61 61 ... &#13;
##  $ price  : int  326 326 327 334 335 336 336 337 337 ... &#13;
##  $ x      : num  3.95 3.89 4.05 4.2 4.34 3.94 3.95... &#13;
##  $ y      : num  3.98 3.84 4.07 4.23 4.35 3.96 3.98... &#13;
##  $ z      : num  2.43 2.31 2.31 2.63 2.75 2.48 2.47... &#13;
</pre><p>Then, here is the structure of the original version:</p><pre class="programlisting">str(diamonds) &#13;
## Classes 'tbl_df', 'tbl' and 'data.frame':    53940 obs. of  10 variables: &#13;
##  $ carat  : num  0.23 0.21 0.23 0.29 0.31 0.24 0.24... &#13;
##  $ cut    : Ord.factor w/ 5 levels "Fair"&lt;"Good"&lt;..: 5 4 2 4 2 3 3 3 1 3 ... &#13;
##  $ color  : Ord.factor w/ 7 levels "D"&lt;"E"&lt;"F"&lt;"G"&lt;..: 2 2 2 6 7 7 6 5 2 5 ... &#13;
##  $ clarity: Ord.factor w/ 8 levels "I1"&lt;"SI2"&lt;"SI1"&lt;..: 2 3 5 4 2 6 7 3 4 5 ... &#13;
##  $ depth  : num  61.5 59.8 56.9 62.4 63.3 62.8 62.3 61.9 65.1 59.4 ... &#13;
##  $ table  : num  55 61 65 58 58 57 57 55 61 61 ... &#13;
##  $ price  : int  326 326 327 334 335 336 336 337 337... &#13;
##  $ x      : num  3.95 3.89 4.05 4.2 4.34 3.94 3.95... &#13;
##  $ y      : num  3.98 3.84 4.07 4.23 4.35 3.96 3.98... &#13;
##  $ z      : num  2.43 2.31 2.31 2.63 2.75 2.48 2.47... &#13;
</pre><p>Now, the difference is obvious. In the original version, <code class="literal">cut</code>, <code class="literal">color</code>, and <code class="literal">clarity</code> are ordered factor variables that are essentially integers with some metadata (ordered levels). By contrast, in the database version, these columns are stored as text instead. This change is simply because SQLite does not have built-in support of ordered factors. Therefore, except for common data types (numbers, texts, logical, and so on), R-specific types will be converted to types supported by SQLite before the data frame is inserted.</p></div><div><div><div><div><h2 class="title"><a id="ch11lvl2sec132"/>Learning SQL to query relational databases</h2></div></div></div><p>In the previous section, you learned how to write data into a SQLite database. In this section, you will learn how to query such a database so that we can get data from it according to our needs. We'll use <code class="literal">data/datasets.sqlite</code> (we created previously) in the following examples.</p><p>First, we need to establish a connection to the database:</p><pre class="programlisting">con &lt;- dbConnect(SQLite(), "data/datasets.sqlite") &#13;
dbListTables(con) &#13;
## [1] "diamonds" "flights" &#13;
</pre><p>There are two tables in the database. Then, we can select all data from <code class="literal">diamonds</code> using the <code class="literal">select</code> statement. Here, we want to select all columns (or fields). So, we will call <code class="literal">dbGetQuery()</code> with the database connection, <code class="literal">con</code>, and a query string:</p><pre class="programlisting">db_diamonds &lt;- dbGetQuery(con,  &#13;
"select * from diamonds") &#13;
head(db_diamonds, 3) &#13;
##   carat     cut color clarity depth table price    x    y &#13;
## 1  0.23   Ideal     E     SI2  61.5    55   326 3.95 3.98 &#13;
## 2  0.21 Premium     E     SI1  59.8    61   326 3.89 3.84 &#13;
## 3  0.23    Good     E     VS1  56.9    65   327 4.05 4.07 &#13;
##      z &#13;
## 1 2.43 &#13;
## 2 2.31 &#13;
## 3 2.31 &#13;
</pre><p>Note that <code class="literal">*</code> means all fields (or, equivalently, columns). If we only need a subset of fields, we can name the fields in turn:</p><pre class="programlisting">db_diamonds &lt;-dbGetQuery(con,  &#13;
"select carat, cut, color, clarity, depth, price  &#13;
  from diamonds") &#13;
head(db_diamonds, 3) &#13;
##   carat     cut color clarity depth price &#13;
## 1  0.23   Ideal     E     SI2  61.5   326 &#13;
## 2  0.21 Premium     E     SI1  59.8   326 &#13;
## 3  0.23    Good     E     VS1  56.9   327 &#13;
</pre><p>If we want to select all distinct cases that appear in the data, we can use <code class="literal">select distinct</code>. For example, the following code returns all distinct values of <code class="literal">cut</code> in <code class="literal">diamonds</code>:</p><pre class="programlisting">dbGetQuery(con, "select distinct cut from diamonds") &#13;
##         cut &#13;
## 1     Ideal &#13;
## 2   Premium &#13;
## 3      Good &#13;
## 4 Very Good &#13;
## 5      Fair &#13;
</pre><p>Note that <code class="literal">dbGetQuery()</code> always returns <code class="literal">data.frame</code>, even though sometimes there is only one column. To retrieve the values as an atomic vector, just extract the first column from the data frame:</p><pre class="programlisting">dbGetQuery(con, "select distinct clarity from diamonds")[[1]] &#13;
## [1] "SI2"  "SI1"  "VS1"  "VS2"  "VVS2" "VVS1" "I1"   "IF" &#13;
</pre><p>When we use <code class="literal">select</code> to select columns to query, sometimes, the column name is not exactly what we want. In this case, we can use <code class="literal">A as B</code> to get column <code class="literal">B</code> with the same data as <code class="literal">A</code>:</p><pre class="programlisting">db_diamonds &lt;- dbGetQuery(con,  &#13;
"select carat, price, clarity as clarity_level from diamonds") &#13;
head(db_diamonds, 3) &#13;
##   carat price clarity_level &#13;
## 1  0.23   326           SI2 &#13;
## 2  0.21   326           SI1 &#13;
## 3  0.23   327           VS1 &#13;
</pre><p>In some other cases, the value we want is not present in the database, but needs some calculation to figure out. Now, we will use <code class="literal">A as B</code> in which <code class="literal">A</code> can be an arithmetic calculation between existing columns:</p><pre class="programlisting">db_diamonds &lt;- dbGetQuery(con, &#13;
"select carat, price, x * y * z as size from diamonds") &#13;
head(db_diamonds, 3) &#13;
##   carat  price     size &#13;
## 1  0.23   326  38.20203 &#13;
## 2  0.21   326  34.50586 &#13;
## 3  0.23   327  38.07688 &#13;
</pre><p>What if we create a new column with existing columns and create another column with the new column, just like the following example?</p><pre class="programlisting">db_diamonds &lt;- dbGetQuery(con, &#13;
"select carat, price, x * y * z as size, &#13;
  price / size as value_density &#13;
  from diamonds") &#13;
## Error in sqliteSendQuery(con, statement, bind.data): error in statement: no such column: size &#13;
</pre><p>We simply can't do this. In <code class="literal">A as B</code>, <code class="literal">A</code> must be composed of existing columns. However, if we insist on doing so, we can use nested query, that is, we <code class="literal">select</code> columns from a temporary table produced by a nested <code class="literal">select</code>:</p><pre class="programlisting">db_diamonds &lt;- dbGetQuery(con, &#13;
"select *, price / size as value_density from &#13;
  (select carat, price, x * y * z as size from diamonds)") &#13;
head(db_diamonds, 3) &#13;
##   carat  price    size   value_density &#13;
## 1  0.23   326  38.20203      8.533578 &#13;
## 2  0.21   326  34.50586      9.447672 &#13;
## 3  0.23   327  38.07688      8.587887 &#13;
</pre><p>In this case, <code class="literal">size</code> is defined in the temporary table when <code class="literal">price</code> /<code class="literal">size</code> is being computed.</p><p>The next important component of a database query is a condition. We can use <code class="literal">where</code> to specify the conditions that the results must satisfy. For example, we can select diamonds with <code class="literal">Good</code> cut:</p><pre class="programlisting">good_diamonds &lt;- dbGetQuery(con,  &#13;
"select carat, cut, price from diamonds where cut = 'Good'") &#13;
head(good_diamonds, 3) &#13;
##   carat  cut price &#13;
## 1  0.23 Good   327 &#13;
## 2  0.31 Good   335 &#13;
## 3  0.30 Good   339 &#13;
</pre><p>Note that records with good cut are only a small proportion of all records:</p><pre class="programlisting">nrow(good_diamonds) /nrow(diamonds) &#13;
## [1] 0.09095291 &#13;
</pre><p>If we have multiple conditions that must be met simultaneously, we can use <code class="literal">and</code> to combine these conditions. For example, we will select all records with <code class="literal">Good</code> cut and color <code class="literal">E</code>:</p><pre class="programlisting">good_e_diamonds &lt;- dbGetQuery(con,  &#13;
"select carat, cut, color, price from diamonds  &#13;
  where cut = 'Good' and color = 'E'") &#13;
head(good_e_diamonds, 3) &#13;
##   carat  cut color price &#13;
## 1  0.23 Good     E   327 &#13;
## 2  0.23 Good     E   402 &#13;
## 3  0.26 Good     E   554 &#13;
nrow(good_e_diamonds) /nrow(diamonds) &#13;
## [1] 0.017297 &#13;
</pre><p>Similar logical operations also include <code class="literal">or</code> and <code class="literal">not</code>.</p><p>In addition to the simple logical operations, we can also use <code class="literal">in</code> to filter records by examining whether the value of a field is contained in a given set. For example, we can select records with colors <code class="literal">E</code> and <code class="literal">F</code>:</p><pre class="programlisting">color_ef_diamonds &lt;- dbGetQuery(con, &#13;
"select carat, cut, color, price from diamonds &#13;
  where color in ('E','F')") &#13;
nrow(color_ef_diamonds) &#13;
## [1] 19339 &#13;
</pre><p>We can verify the result by the following table:</p><pre class="programlisting">table(diamonds$color) &#13;
##  &#13;
##     D     E     F     G     H     I     J  &#13;
##  6775  9797  9542 11292  8304  5422  2808 &#13;
</pre><p>To use <code class="literal">in</code>, we need to specify a set. Similar to <code class="literal">in</code>, we can also use <code class="literal">between and</code> which that allow us to specify a range:</p><pre class="programlisting">some_price_diamonds &lt;- dbGetQuery(con, &#13;
"select carat, cut, color, price from diamonds &#13;
  where price between 5000 and 5500") &#13;
nrow(some_price_diamonds) /nrow(diamonds) &#13;
## [1] 0.03285132 &#13;
</pre><p>In fact, the range does not have to be numeric. As long as the data type of the field is comparable, we can specify a range. For string column, we can write <code class="literal">between 'string1' to 'string2'</code> to filter records by lexical ordering.</p><p>Another useful operator for string column is <code class="literal">like</code>, which enables us to filter records with simple string patterns. For example, we can select all records with a <code class="literal">cut</code> variable that ends with <code class="literal">Good</code>. It can be either <code class="literal">Good</code> or <code class="literal">Very Good</code>. The notation is <code class="literal">like '%Good'</code> where <code class="literal">%</code> matches all strings:</p><pre class="programlisting">good_cut_diamonds &lt;- dbGetQuery(con,  &#13;
"select carat, cut, color, price from diamonds &#13;
  where cut like '%Good'") &#13;
nrow(good_cut_diamonds) /nrow(diamonds) &#13;
## [1] 0.3149425 &#13;
</pre><p>Another major functionality of database query is sorting data with specified columns. We can do this with <code class="literal">order by</code>. For example, we can get the <code class="literal">carat</code> and <code class="literal">price</code> of all records but in an ascending order of <code class="literal">price</code>:</p><pre class="programlisting">cheapest_diamonds &lt;- dbGetQuery(con, &#13;
"select carat, price from diamonds &#13;
  order by price") &#13;
</pre><p>Therefore, we have a data frame of diamonds that is ordered from the cheapest to the most expensive ones:</p><pre class="programlisting">head(cheapest_diamonds) &#13;
##   carat price &#13;
## 1  0.23   326 &#13;
## 2  0.21   326 &#13;
## 3  0.23   327 &#13;
## 4  0.29   334 &#13;
## 5  0.31   335 &#13;
## 6  0.24   336 &#13;
</pre><p>We can do the opposite by adding <code class="literal">desc</code> to the sorting column so that we get a data frame that is ordered in the opposite way:</p><pre class="programlisting">most_expensive_diamonds &lt;- dbGetQuery(con, &#13;
"select carat, price from diamonds &#13;
  order by price desc") &#13;
head(most_expensive_diamonds) &#13;
##   carat price &#13;
## 1  2.29 18823 &#13;
## 2  2.00 18818 &#13;
## 3  1.51 18806 &#13;
## 4  2.07 18804 &#13;
## 5  2.00 18803 &#13;
## 6  2.29 18797 &#13;
</pre><p>We can also sort the records with more than one column. For example, the following results are sorted by price in the ascending order first. If two records have equal price, the one with greater carat will be put ahead:</p><pre class="programlisting">cheapest_diamonds &lt;- dbGetQuery(con,  &#13;
"select carat, price from diamonds &#13;
  order by price, carat desc") &#13;
head(cheapest_diamonds) &#13;
##   carat price &#13;
## 1  0.23   326 &#13;
## 2  0.21   326 &#13;
## 3  0.23   327 &#13;
## 4  0.29   334 &#13;
## 5  0.31   335 &#13;
## 6  0.24   336 &#13;
</pre><p>Like <code class="literal">select</code>, the column to sort can be computed from existing columns:</p><pre class="programlisting">dense_diamonds &lt;- dbGetQuery(con, &#13;
"select carat, price, x * y * z as size from diamonds &#13;
  order by carat / size desc") &#13;
head(dense_diamonds) &#13;
##   carat  price     size &#13;
## 1  1.07  5909  47.24628 &#13;
## 2  1.41  9752  74.41726 &#13;
## 3  1.53  8971  85.25925 &#13;
## 4  1.51  7188 133.10400 &#13;
## 5  1.22  3156 108.24890 &#13;
## 6  1.12  6115 100.97448 &#13;
</pre><p>We can also query the sorted subset of all records using <code class="literal">where</code> and <code class="literal">order by</code> at the same time:</p><pre class="programlisting">head(dbGetQuery(con,  &#13;
"select carat, price from diamonds &#13;
   where cut = 'Ideal' and clarity = 'IF' and color = 'J' &#13;
   order by price")) &#13;
##   carat price &#13;
## 1  0.30   489 &#13;
## 2  0.30   489 &#13;
## 3  0.32   521 &#13;
## 4  0.32   533 &#13;
## 5  0.32   533 &#13;
## 6  0.35   569 &#13;
</pre><p>If we only care about the first several results, we can use <code class="literal">limit</code> to constrain the number of records to retrieve:</p><pre class="programlisting">dbGetQuery(con,  &#13;
"select carat, price from diamonds &#13;
  order by carat desc limit 3") &#13;
##   carat price &#13;
## 1  5.01 18018 &#13;
## 2  4.50 18531 &#13;
## 3  4.13 17329 &#13;
</pre><p>In addition to column selection, conditional filtering, and sorting, we can also aggregate the records in database in groups. For example, we can count the number of records for each color:</p><pre class="programlisting">dbGetQuery(con, &#13;
"select color, count(*) as number from diamonds &#13;
  group by color") &#13;
##   color number &#13;
## 1     D   6775 &#13;
## 2     E   9797 &#13;
## 3     F   9542 &#13;
## 4     G  11292 &#13;
## 5     H   8304 &#13;
## 6     I   5422 &#13;
## 7     J   2808 &#13;
</pre><p>The results can be verified by calling <code class="literal">table()</code> with the original data:</p><pre class="programlisting">table(diamonds$color) &#13;
##  &#13;
##     D     E     F     G     H     I     J  &#13;
##  6775  9797  9542 11292  8304  5422  2808 &#13;
</pre><p>In addition to counting, we also have aggregating functions such as <code class="literal">avg()</code>, <code class="literal">max()</code>, <code class="literal">min()</code>, and <code class="literal">sum()</code>. For example, we can summarize the data by looking at the average price for each level of clarity:</p><pre class="programlisting">dbGetQuery(con, &#13;
"select clarity, avg(price) as avg_price  &#13;
   from diamonds &#13;
   group by clarity  &#13;
   order by avg_price desc") &#13;
##   clarity avg_price &#13;
## 1     SI2  5063.029 &#13;
## 2     SI1  3996.001 &#13;
## 3     VS2  3924.989 &#13;
## 4      I1  3924.169 &#13;
## 5     VS1  3839.455 &#13;
## 6    VVS2  3283.737 &#13;
## 7      IF  2864.839 &#13;
## 8    VVS1  2523.115 &#13;
</pre><p>We can also examine the maximal carat at the five lowest prices:</p><pre class="programlisting">dbGetQuery(con, &#13;
"select price, max(carat) as max_carat  &#13;
   from diamonds &#13;
   group by price &#13;
   order by price &#13;
   limit 5") &#13;
##   price max_carat &#13;
## 1   326      0.23 &#13;
## 2   327      0.23 &#13;
## 3   334      0.29 &#13;
## 4   335      0.31 &#13;
## 5   336      0.24 &#13;
</pre><p>We can also perform multiple calculations in a group. The following code calculates the range of prices and their average value for each clarity level:</p><pre class="programlisting">dbGetQuery(con, &#13;
"select clarity,  &#13;
     min(price) as min_price,  &#13;
     max(price) as max_price, &#13;
     avg(price) as avg_price &#13;
   from diamonds &#13;
   group by clarity  &#13;
   order by avg_price desc") &#13;
##   clarity min_price max_price avg_price &#13;
## 1     SI2       326     18804  5063.029 &#13;
## 2     SI1       326     18818  3996.001 &#13;
## 3     VS2       334     18823  3924.989 &#13;
## 4      I1       345     18531  3924.169 &#13;
## 5     VS1       327     18795  3839.455 &#13;
## 6    VVS2       336     18768  3283.737 &#13;
## 7      IF       369     18806  2864.839 &#13;
## 8    VVS1       336     18777  2523.115 &#13;
</pre><p>The following example calculates an average price for each clarity level weighted by carat, that is, a price with greater carat has more weight:</p><pre class="programlisting">dbGetQuery(con, &#13;
"select clarity, &#13;
     sum(price * carat) / sum(carat) as wprice &#13;
   from diamonds &#13;
   group by clarity  &#13;
   order by wprice desc") &#13;
##   clarity   wprice &#13;
## 1     SI2 7012.257 &#13;
## 2     VS2 6173.858 &#13;
## 3     VS1 6059.505 &#13;
## 4     SI1 5919.187 &#13;
## 5    VVS2 5470.156 &#13;
## 6      I1 5233.937 &#13;
## 7      IF 5124.584 &#13;
## 8    VVS1 4389.112 &#13;
</pre><p>Just like sorting with more than one column, we can also group the data by multiple columns. The following code computes the average price for each clarity and color pair, and shows the top five pairs with the highest average prices:</p><pre class="programlisting">dbGetQuery(con, &#13;
"select clarity, color, &#13;
     avg(price) as avg_price &#13;
   from diamonds &#13;
   group by clarity, color  &#13;
   order by avg_price desc  &#13;
   limit 5") &#13;
##   clarity color avg_price &#13;
## 1      IF     D  8307.370 &#13;
## 2     SI2     I  7002.649 &#13;
## 3     SI2     J  6520.958 &#13;
## 4     SI2     H  6099.895 &#13;
## 5     VS2     I  5690.506 &#13;
</pre><p>The most relational operation in a relational database should be table join, that is, joining a number of tables together by some columns. For example, we will create a data frame of <code class="literal">cut</code>, <code class="literal">color</code>, and <code class="literal">clarity</code> to select records with exactly the same field values of the three cases in <code class="literal">diamond_selector</code>:</p><pre class="programlisting">diamond_selector &lt;- data.frame( &#13;
cut = c("Ideal", "Good", "Fair"), &#13;
color = c("E", "I", "D"), &#13;
clarity = c("VS1", "I1", "IF"), &#13;
stringsAsFactors = FALSE &#13;
) &#13;
diamond_selector &#13;
##     cut color clarity &#13;
## 1 Ideal     E     VS1 &#13;
## 2  Good     I      I1 &#13;
## 3  Fair     D      IF &#13;
</pre><p>After creating the data frame, we write it to the database so that we can join <code class="literal">diamonds</code> and <code class="literal">diamond_selector</code> to filter the desirable records:</p><pre class="programlisting">dbWriteTable(con, "diamond_selector", diamond_selector,  &#13;
row.names = FALSE, overwrite = TRUE) &#13;
## [1] TRUE &#13;
</pre><p>We can specify the columns to match in the join-clause:</p><pre class="programlisting">subset_diamonds &lt;- dbGetQuery(con,  &#13;
"select cut, color, clarity, carat, price &#13;
   from diamonds &#13;
   join diamond_selector using (cut, color, clarity)") &#13;
head(subset_diamonds) &#13;
##     cut color clarity carat price &#13;
## 1 Ideal     E     VS1  0.60  2774 &#13;
## 2 Ideal     E     VS1  0.26   556 &#13;
## 3 Ideal     E     VS1  0.70  2818 &#13;
## 4 Ideal     E     VS1  0.70  2837 &#13;
## 5  Good     I      I1  1.01  2844 &#13;
## 6 Ideal     E     VS1  0.26   556 &#13;
</pre><p>In total, we have only a tiny portion of all records that satisfy one of the three cases:</p><pre class="programlisting">nrow(subset_diamonds) /nrow(diamonds) &#13;
## [1] 0.01121617 &#13;
</pre><p>Finally, don't forget to disconnect the database to ensure that all resources are properly released:</p><pre class="programlisting">dbDisconnect(con) &#13;
## [1] TRUE &#13;
</pre><p>In the previous examples, we only showed the basic use of SQL to query a relational database such as SQLite. In fact, SQL is richer and much more powerful than we have demonstrated. For more details, visit <a class="ulink" href="http://www.w3schools.com/sql">http://www.w3schools.com/sql</a> and learn more.</p></div><div><div><div><div><h2 class="title"><a id="ch11lvl2sec133"/>Fetching query results chunk by chunk</h2></div></div></div><p>In the beginning of the section, we mentioned that one of the advantages of using a relational database is that we can store a large amount of data. Usually, we only take out a subset of the database and do some research. However, sometimes, we need to go through an amount of data that exceeds the capacity of computer memory. Obviously, we cannot load all of the data into memory, but must process the data chunk by chunk.</p><p>Most reasonable relational databases support fetching a query result set chunk by chunk. In the following example, we will use <code class="literal">dbSendQuery()</code> instead of <code class="literal">dbGetQuery()</code> to get a result set. Then, we will repeat fetching chunks (a number of rows) from the result set until all results are fetched. In this way, we can process the data chunk by chunk without using a large amount of working memory:</p><pre class="programlisting">con &lt;- dbConnect(SQLite(), "data/datasets.sqlite") &#13;
res &lt;- dbSendQuery(con,  &#13;
"select carat, cut, color, price from diamonds &#13;
  where cut = 'Ideal' and color = 'E'") &#13;
while (!dbHasCompleted(res)) { &#13;
  chunk &lt;- dbFetch(res, 800) &#13;
cat(nrow(chunk), "records fetched\n") &#13;
# do something with chunk &#13;
} &#13;
## 800 records fetched &#13;
## 800 records fetched &#13;
## 800 records fetched &#13;
## 800 records fetched &#13;
## 703 records fetched &#13;
dbClearResult(res) &#13;
## [1] TRUE &#13;
dbDisconnect(con) &#13;
## [1] TRUE &#13;
</pre><p>In practice, the database may have billions of records. The query may result in tens of millions of records. If you use <code class="literal">dbGetQuery()</code> to fetch the whole result set at once, your memory may not be sufficient. If the task can be finished by processing data chunks, it can be much cheaper to work chunk by chunk.</p></div><div><div><div><div><h2 class="title"><a id="ch11lvl2sec134"/>Using transactions for consistency</h2></div></div></div><p>Popular relational databases have a strong ability to ensure consistency. When we insert or update data, we do it via transactions. If a transaction fails, we can undo the transaction and rollback the database to ensure that everything is consistent.</p><p>The following example is a simple simulation of the data accumulation process that may fail in the middle of the process. Suppose we need to accumulate the data of some products and store it in <code class="literal">data/products.sqlite</code>. Each time a chunk of data is produced, we need to append it to a table in the database. In each iteration, however, the process may fail with a probability of 20 percent:</p><pre class="programlisting">set.seed(123) &#13;
con &lt;- dbConnect(SQLite(), "data/products.sqlite") &#13;
chunk_size &lt;- 10 &#13;
for (i in 1:6) { &#13;
  cat("Processing chunk", i, "\n") &#13;
  if (runif(1) &lt;= 0.2) stop("Data error") &#13;
  chunk &lt;- data.frame(id = ((i - 1L) * chunk_size):(i * chunk_size - 1L),  &#13;
    type = LETTERS[[i]], &#13;
    score = rbinom(chunk_size, 10, (10 - i) /10), &#13;
    stringsAsFactors = FALSE) &#13;
  dbWriteTable(con, "products", chunk,  &#13;
    append = i &gt; 1, row.names = FALSE) &#13;
} &#13;
## Processing chunk 1  &#13;
## Processing chunk 2  &#13;
## Processing chunk 3  &#13;
## Processing chunk 4  &#13;
## Processing chunk 5 &#13;
## Error in eval(expr, envir, enclos): Data error &#13;
</pre><p>The accumulation fails when processing chunk 5. Then, we will count the records in the table:</p><pre class="programlisting">dbGetQuery(con, "select COUNT(*) from products") &#13;
##   COUNT(*) &#13;
## 1      40 &#13;
dbDisconnect(con) &#13;
## [1] TRUE &#13;
</pre><p>We can find that the table has stored a number of records. In some cases, we want either all records to be properly stored or we want nothing to be put into the database. In both cases, the database is consistent. However, if only half of the data is stored, some other problems may occur. To ensure that a series of database changes succeed or fail as a whole, we can call <code class="literal">dbBegin()</code> before we write any data, call <code class="literal">dbCommit()</code> after all changes are made, and call <code class="literal">dbRollback()</code> if anything goes wrong.</p><p>The following code is an enhanced version of the previous example. We use transactions to make sure either all chunks are written to the database or none. More specifically, we put the data-writing process in <code class="literal">tryCatch</code>. Before the writing begins, we begin a transaction by calling <code class="literal">dbBegin()</code>. Then, in <code class="literal">tryCatch</code>, we will write data chunk by chunk to the database. If everything goes well, we will call <code class="literal">dbCommit()</code> to commit the transaction so that all the changes are committed. If anything goes wrong, the error will be captured by the error function in which we produce a warning and rollback by <code class="literal">dbRollback()</code>:</p><pre class="programlisting">set.seed(123) &#13;
file.remove("data/products.sqlite") &#13;
## [1] TRUE &#13;
con &lt;- dbConnect(SQLite(), "data/products.sqlite") &#13;
chunk_size &lt;- 10 &#13;
dbBegin(con) &#13;
## [1] TRUE &#13;
res &lt;- tryCatch({ &#13;
  for (i in 1:6) { &#13;
cat("Processing chunk", i, "\n") &#13;
    if (runif(1) &lt;= 0.2) stop("Data error") &#13;
    chunk &lt;- data.frame(id = ((i - 1L) * chunk_size):(i * chunk_size - 1L),  &#13;
type = LETTERS[[i]], &#13;
score = rbinom(chunk_size, 10, (10 - i) /10), &#13;
stringsAsFactors = FALSE) &#13;
dbWriteTable(con, "products", chunk,  &#13;
append = i &gt; 1, row.names = FALSE) &#13;
  } &#13;
dbCommit(con) &#13;
}, error = function(e) { &#13;
warning("An error occurs: ", e, "\nRolling back", immediate. = TRUE) &#13;
dbRollback(con) &#13;
}) &#13;
## Processing chunk 1  &#13;
## Processing chunk 2  &#13;
## Processing chunk 3  &#13;
## Processing chunk 4  &#13;
## Processing chunk 5 &#13;
## Warning in value[[3L]](cond): An error occurs: Error in doTryCatch(return(expr), name, parentenv, handler): Data error &#13;
##  &#13;
## Rolling back &#13;
</pre><p>We can see that the same error happens again. However, this time, the error is captured, the transaction cancelled, and the database rolled back. To verify, we can again count the number of records in the <code class="literal">products</code> table:</p><pre class="programlisting">dbGetQuery(con, "select COUNT(*) from products") &#13;
## Error in sqliteSendQuery(con, statement, bind.data): error in statement: no such table: products &#13;
dbDisconnect(con) &#13;
## [1] TRUE &#13;
</pre><p>It may be surprising that the counting query results in an error. Why does it not return 0? If we take a closer look at the example, we should understand that the first time we call <code class="literal">dbWriteTable()</code>, it creates a new table first and then inserts the data in the first chunk. In other words, the table creation is included in the transaction. So, when we roll back, the table creation is undone too. As a result, the preceding counting query produces an error because <code class="literal">products</code> does not exist at all. If the table exists before we begin a transaction, the count should be equal to the number of records before the transaction as if nothing happened.</p><p>Another example that requires strong consistency is account transfer. When we transfer an amount of money from one account to another, we need to ensure that the system withdraws the money from one account and deposits the same amount to the other account. The two changes must both happen or both fail to keep consistency. This can be easily done with transactions of relational databases.</p><p>Suppose we define a function that creates a SQLite database of a virtual bank. We will use <code class="literal">dbSendQuery()</code> to send commands to create a table of accounts and a table of transactions:</p><pre class="programlisting">create_bank &lt;- function(dbfile) { &#13;
  if (file.exists(dbfile)) file.remove(dbfile) &#13;
  con &lt;- dbConnect(SQLite(), dbfile) &#13;
  dbSendQuery(con,  &#13;
    "create table accounts  &#13;
    (name text primary key, balance real)") &#13;
  dbSendQuery(con, &#13;
    "create table transactions  &#13;
    (time text, account_from text, account_to text, value real)") &#13;
  con &#13;
} &#13;
</pre><p>The accounts table has two columns: <code class="literal">name</code> and <code class="literal">balance</code>. The transactions table has four columns: <code class="literal">time</code>, <code class="literal">account_from</code>, <code class="literal">account_to</code>, and <code class="literal">value</code>. The first table stores all the information of accounts, and the second one stores all historic transactions.</p><p>We will also define a function to create an account with a name and initial balance. The function uses <code class="literal">insert into</code> to write a new record to the accounts table:</p><pre class="programlisting">create_account &lt;- function(con, name, balance) { &#13;
  dbSendQuery(con,  &#13;
    sprintf("insert into accounts (name, balance) values ('%s', %.2f)", name, balance)) &#13;
  TRUE &#13;
} &#13;
</pre><p>Note that we uses <code class="literal">sprintf</code> to produce the preceding SQL statement. It is acceptable for local and personal use, but it is generally not safe for web applications, because a hacker can easily write a partial expression to run any disastrous statements to manipulate the whole database.</p><p>Next, we will define a transfer function. The function checks whether the withdrawing account and receiving account both exist in the database. It ensures that the balance of the withdrawing account is sufficient for such an amount of transfer. If the transfer is valid, then it updates the balance of both accounts and adds a transaction record to the database:</p><pre class="programlisting">transfer &lt;- function(con, from, to, value) { &#13;
  get_account &lt;- function(name) { &#13;
    account &lt;- dbGetQuery(con,  &#13;
      sprintf("select * from accounts  &#13;
              where name = '%s'", name)) &#13;
    if (nrow(account) == 0)  &#13;
      stop(sprintf("Account '%s' does not exist", name)) &#13;
    account &#13;
  } &#13;
  account_from &lt;- get_account(from) &#13;
  account_to &lt;- get_account(to) &#13;
  if (account_from$balance &lt; value) { &#13;
    stop(sprintf("Insufficient money to transfer from '%s'", &#13;
                 from)) &#13;
  } else { &#13;
    dbSendQuery(con,  &#13;
      sprintf("update accounts set balance = %.2f  &#13;
              where name = '%s'", &#13;
        account_from$balance - value, from)) &#13;
dbSendQuery(con, &#13;
sprintf("update accounts set balance = %.2f  &#13;
where name = '%s'", &#13;
        account_to$balance + value, to)) &#13;
      dbSendQuery(con, &#13;
        sprintf("insert into transactions (time, account_from,  &#13;
                account_to, value) values &#13;
        ('%s', '%s', '%s', %.2f)",  &#13;
        format(Sys.time(), "%Y-%m-%d %H:%M:%S"), &#13;
        from, to, value)) &#13;
  } &#13;
TRUE &#13;
} &#13;
</pre><p>Although we have some basic checking against possible insufficient funds of the withdrawing account, we still cannot ensure that the transfer is safe, because it can be interrupted by other causes. Therefore, we will implement a safe version of <code class="literal">transfer</code> in which we will use transaction to ensure that any changes made by <code class="literal">transfer</code> can be undone if anything goes wrong:</p><pre class="programlisting">safe_transfer &lt;- function(con, ...) { &#13;
  dbBegin(con) &#13;
  tryCatch({ &#13;
    transfer(con, ...) &#13;
    dbCommit(con) &#13;
  }, error = function(e) { &#13;
    message("An error occurs in the transaction. Rollback...") &#13;
    dbRollback(con) &#13;
    stop(e) &#13;
  }) &#13;
} &#13;
</pre><p>In fact, <code class="literal">safe_transfer</code> is a wrapper function of <code class="literal">transfer</code>. It just puts <code class="literal">transfer</code> in a sandbox of <code class="literal">tryCatch</code>. If an error occurs, we call <code class="literal">dbRollback()</code> to ensure that the database is consistent.</p><p>Before putting the functions into tests, we need functions to view the balance of a given account as well as all successful transactions that happened between accounts:</p><pre class="programlisting">get_balance &lt;- function(con, name) { &#13;
  res &lt;- dbGetQuery(con,  &#13;
    sprintf("select balance from accounts  &#13;
            where name = '%s'", name)) &#13;
  res$balance &#13;
} &#13;
get_transactions &lt;- function(con, from, to) { &#13;
  dbGetQuery(con, &#13;
    sprintf("select * from transactions  &#13;
      where account_from = '%s' and account_to = '%s'",  &#13;
      from, to)) &#13;
} &#13;
</pre><p>Now, we can do some tests. First, we will create a virtual bank using <code class="literal">create_bank()</code> that returns a SQLite connection to the database file. Then, we will create two accounts with some initial balance:</p><pre class="programlisting">con &lt;- create_bank("data/bank.sqlite") &#13;
create_account(con, "David", 5000) &#13;
## [1] TRUE &#13;
create_account(con, "Jenny", 6500) &#13;
## [1] TRUE &#13;
get_balance(con, "David") &#13;
## [1] 5000 &#13;
get_balance(con, "Jenny") &#13;
## [1] 6500 &#13;
</pre><p>Then, we will use <code class="literal">safe_transfer()</code> to transfer some money from David's account to Jenny's account:</p><pre class="programlisting">safe_transfer(con, "David", "Jenny", 1500) &#13;
## [1] TRUE &#13;
get_balance(con, "David") &#13;
## [1] 3500 &#13;
get_balance(con, "Jenny") &#13;
## [1] 8000 &#13;
</pre><p>The transfer succeeds, and the balances of both accounts are changed in a consistent manner. Now, we will make another transfer. This time, the balance of David's account is not sufficient, so the transfer will end up with an error:</p><pre class="programlisting">safe_transfer(con, "David", "Jenny", 6500) &#13;
## An error occurs in the transaction. Rollback... &#13;
## Error in transfer(con, ...): Insufficient money to transfer from 'David' &#13;
get_balance(con, "David") &#13;
## [1] 3500 &#13;
get_balance(con, "Jenny") &#13;
## [1] 8000 &#13;
</pre><p>The error is captured, and the function rolls back the database. The balances of both accounts do not change. Now, we will query all successful transactions:</p><pre class="programlisting">get_transactions(con, "David", "Jenny") &#13;
##                  time   account_from  account_to value &#13;
## 1 2016-06-08 23:24:39        David      Jenny  1500 &#13;
</pre><p>We can see the first transaction, but the failed transaction does not appear in the database. Finally, we should always remember to close the database connection:</p><pre class="programlisting">dbDisconnect(con) &#13;
## [1] TRUE &#13;
</pre></div><div><div><div><div><h2 class="title"><a id="ch11lvl2sec135"/>Storing data in files to a database</h2></div></div></div><p>When we deal with large data files, we may usually get stuck with issues of reading and writing data. There are two extremes in practice. One extreme is a really big text-format data source that is almost impossible to load into memory. The other is a large number of small pieces of data files that will require some effort to integrate them into one data frame.</p><p>For the first case, we can read the big source data chunk by chunk and append each chunk to a certain table in a database. The following function is designed for appending rows to a database table from a big source given an input file, an output database, a table name, and a chunk size. Consider that the input data may be too large to load into the memory, so the function will read one chunk each time to write to database and, thus, only require a small working memory:</p><pre class="programlisting">chunk_rw &lt;- function(input, output, table, chunk_size = 10000) { &#13;
  first_row &lt;- read.csv(input, nrows = 1, header = TRUE) &#13;
  header &lt;- colnames(first_row) &#13;
  n &lt;- 0 &#13;
  con &lt;- dbConnect(SQLite(), output) &#13;
on.exit(dbDisconnect(con)) &#13;
  while (TRUE) { &#13;
    df &lt;- read.csv(input,  &#13;
skip = 1 + n * chunk_size, nrows = chunk_size,  &#13;
header = FALSE, col.names = header, &#13;
stringsAsFactors = FALSE) &#13;
    if (nrow(df) == 0) break; &#13;
dbWriteTable(con, table, df, row.names = FALSE, append = n &gt; 0) &#13;
    n &lt;- n + 1 &#13;
cat(sprintf("%d records written\n", nrow(df))) &#13;
  } &#13;
} &#13;
</pre><p>The trick here is to correctly calculate the offset of each chunk in the input file.</p><p>To test the function, we will first write <code class="literal">diamonds</code> into a csv file and use <code class="literal">chunk_rw()</code> to write the csv file into a SQLite database chunk by chunk. With this method, the writing process only requires a much smaller working memory than is required for loading the whole data into memory:</p><pre class="programlisting">write.csv(diamonds, "data/diamonds.csv", quote = FALSE, row.names = FALSE) &#13;
chunk_rw("data/diamonds.csv", "data/diamonds.sqlite", "diamonds") &#13;
## 10000 records written &#13;
## 10000 records written &#13;
## 10000 records written &#13;
## 10000 records written &#13;
## 10000 records written &#13;
## 3940 records written &#13;
</pre><p>Another extreme of loading data is that we need to read from many small data files. In this case, we can put all the data distributed in these files in a database so that we can easily query data from it. The following function is intended for putting the data of all csv files in a folder to one database:</p><pre class="programlisting">batch_rw &lt;- function(dir, output, table, overwrite = TRUE) { &#13;
  files &lt;- list.files(dir, "\\.csv$", full.names = TRUE) &#13;
  con &lt;- dbConnect(SQLite(), output) &#13;
on.exit(dbDisconnect(con)) &#13;
  exist &lt;- dbExistsTable(con, table) &#13;
  if (exist) { &#13;
    if (overwrite) dbRemoveTable(con, table) &#13;
    else stop(sprintf("Table '%s' already exists", table)) &#13;
  } &#13;
  exist &lt;- FALSE &#13;
  for (file in files) { &#13;
cat(file, "... ") &#13;
    df &lt;- read.csv(file, header = TRUE,  &#13;
stringsAsFactors = FALSE) &#13;
dbWriteTable(con, table, df, row.names = FALSE,  &#13;
append = exist) &#13;
    exist &lt;- TRUE &#13;
cat("done\n") &#13;
  } &#13;
} &#13;
</pre><p>To demonstrate, we have a number of small csv files in <code class="literal">data/groups</code>, and we use <code class="literal">batch_rw()</code> to put all the data into a database:</p><pre class="programlisting">batch_rw("data/groups", "data/groups.sqlite", "groups") &#13;
## data/groups/group1.csv ... done &#13;
## data/groups/group2.csv ... done &#13;
## data/groups/group3.csv ... done &#13;
</pre><p>Now, all the data in the files is put into the database. We can query or read the whole table and see what is looks like:</p><pre class="programlisting">con &lt;- dbConnect(SQLite(), "data/groups.sqlite") &#13;
dbReadTable(con, "groups") &#13;
##    group   id   grade &#13;
## 1     1   I-1     A &#13;
## 2     1   I-2     B &#13;
## 3     1   I-3     A &#13;
## 4     2  II-1     C &#13;
## 5     2  II-2     C &#13;
## 6     3 III-1     B &#13;
## 7     3 III-2     B &#13;
## 8     3 III-3     A &#13;
## 9     3 III-4     C &#13;
dbDisconnect(con) &#13;
## [1] TRUE &#13;
</pre><p>In this section, you learned some basic knowledge and usage of SQLite database. However, many popular relational databases share many common features of functionality and the query language. With almost the same knowledge, you can work with MySQL via RMySQL, PostreSQL via RPostges, Microsoft SQL Server via RSQLServer, and ODBC-compatible databases (Microsoft Access and Excel) via RODBC. They share almost the same operating functions, so if you are familiar with one, you shouldn't have a problem working with others.</p></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch11lvl1sec59"/>Working with NoSQL databases</h1></div></div></div><p>In the previous section of this chapter, you learned the basics of relational databases and how to use SQL to query data. Relational data is mostly organized in a tabular form, that is, as a collection of tables with relations.</p><p>However, when the volume of data exceeds the capacity of a server, problems occur because the traditional model of relational databases does not easily support horizontal scalability, that is, storing data in a cluster of servers instead of a single one. This adds a new layer of complexibility of database management as the data is stored in a distributed form while still accessible as one logical database. </p><p>In recent years, NoSQL, or non-relational databases, have become much more popular than before due to the introduction of new database models and the remarkable performance they exhibit in big data analytics and real-time applications. Some non-relational databases are designed for high availability, scalability, and flexibility, and some for high performance.</p><p>The difference in storage model between relational databases and non-relational databases is notable. For example, for a shopping website, the goods and comments can be stored in a relational database with two tables: goods and comments. All the information of goods is stored in one table, and all comments on each good are stored in the other. The following code shows the basic structure of such tables:</p><pre class="programlisting">products: &#13;
code,name,type,price,amount &#13;
A0000001,Product-A,Type-I,29.5,500 &#13;
</pre><p>Each comment has a field that points to the product it is subject to:</p><pre class="programlisting">comments: &#13;
code,user,score,text &#13;
A0000001,david,8,"This is a good product" &#13;
A0000001,jenny,5,"Just so so" &#13;
</pre><p>When a product has many related tables and the number of records is so large that the database must be distributed across a great number of servers, it would be hard to query such a database because executing a simple query can be extremely inefficient. If we use MongoDB to store such data, each good will stored as a document and all comments of this good are stored in an array as a field of the document. As a result, it would be easy to query the data, and the database can be easily distributed to a large number of servers.</p><div><div><div><div><h2 class="title"><a id="ch11lvl2sec136"/>Working with MongoDB</h2></div></div></div><p>MongoDB is a popular non-relational database that provides a document-oriented way of storing data. Each product is a document in a collection. The product has some fields of descriptive information and has a field that is an array of comments. All comments are subdocuments so that each logical item can be stored in their own logical form.</p><p>Here is a JSON (<a class="ulink" href="https://en.wikipedia.org/wiki/JSON">https://en.wikipedia.org/wiki/JSON</a>) representation of a good in the collection:</p><pre class="programlisting">{ &#13;
  "code":"A0000001", &#13;
  "name":"Product-A", &#13;
  "type":"Type-I", &#13;
  "price":29.5, &#13;
  "amount":500, &#13;
  "comments":[ &#13;
    { &#13;
      "user":"david", &#13;
      "score":8, &#13;
      "text":"This is a good product" &#13;
    }, &#13;
    { &#13;
      "user":"jenny", &#13;
      "score":5, &#13;
      "text":"Just so so" &#13;
    } &#13;
  ] &#13;
} &#13;
</pre><p>A relational database may contain many schemas. Each schema (or database) may consist of many tables. Each table may contain many records. Similarly, a MongoDB instance can host many databases. Each database can include many collections. Each collection may contain many documents. The main difference is that the records in a table of a relational database need to have the same structure, but a document in a collection of a MongoDB database is schema-less and is flexible enough to have nested structures.</p><p>In the preceding JSON code, for example, a good is represented by such a document in which <code class="literal">code</code>, <code class="literal">name</code>, <code class="literal">type</code>, <code class="literal">price</code>, and <code class="literal">amount</code> are data fields with simple data types while <code class="literal">comments</code> is an array of objects. Each comment is represented by an object in <code class="literal">comments</code> and has a structure of <code class="literal">user</code>, <code class="literal">score</code>, and <code class="literal">text</code>. All comments of a good are stored as an object in <code class="literal">comments</code>. Therefore, a good is highly self-contained in terms of product information and comments. If we need information of a product, we no longer need to join two tables but pick out several fields.</p><p>To install MongoDB, visit <a class="ulink" href="https://docs.mongodb.com/manual/installation/">https://docs.mongodb.com/manual/installation/</a> and follow the instructions. It supports nearly all major platforms.</p><div><div><div><div><h3 class="title"><a id="ch11lvl3sec66"/>Querying data from MongoDB</h3></div></div></div><p>Suppose we have a working MongoDB instance running on a local machine. We can use the <code class="literal">mongolite</code> package to work with MongoDB. To install the package, run the following code:</p><pre class="programlisting">install.packages("mongolite") &#13;
</pre><p>Once we have the package installed, we can create a Mongo connection by specifying the collection, database, and MongoDB address:</p><pre class="programlisting">library(mongolite) &#13;
m &lt;- mongo("students", "test", "mongodb://localhost") &#13;
</pre><p>First, we will create a connection to the local MongoDB instance. Initially, the <code class="literal">products</code> collection has no documents:</p><pre class="programlisting">m$count() &#13;
## [1] 0 &#13;
</pre><p>To insert the product with comments, we can directly supply the JSON document as a string to <code class="literal">m$insert()</code>:</p><pre class="programlisting">m$insert(' &#13;
{ &#13;
  "code": "A0000001", &#13;
  "name": "Product-A", &#13;
  "type": "Type-I", &#13;
  "price": 29.5, &#13;
  "amount": 500, &#13;
  "comments": [ &#13;
    { &#13;
      "user": "david", &#13;
      "score": 8, &#13;
      "text": "This is a good product" &#13;
    }, &#13;
    { &#13;
      "user": "jenny", &#13;
      "score": 5, &#13;
      "text": "Just so so" &#13;
    } &#13;
  ] &#13;
}') &#13;
</pre><p>Now, the collection has one document:</p><pre class="programlisting">m$count() &#13;
## [1] 1 &#13;
</pre><p>Alternatively, we can use list object in R to represent the same structure. The following code inserts the second product with <code class="literal">list</code>:</p><pre class="programlisting">m$insert(list( &#13;
  code = "A0000002", &#13;
  name = "Product-B", &#13;
  type = "Type-II", &#13;
  price = 59.9, &#13;
  amount = 200L, &#13;
  comments = list( &#13;
    list(user = "tom", score = 6L, &#13;
      text = "Just fine"), &#13;
    list(user = "mike", score = 9L, &#13;
      text = "great product!") &#13;
  ) &#13;
), auto_unbox = TRUE) &#13;
</pre><p>Note that R does not provide a scalar type so that, by default, all vectors are interpreted as JSON arrays in MongoDB, unless <code class="literal">auto_unbox = TRUE</code>, which turns one-element vectors into scalars in JSON. Without <code class="literal">auto_unbox = TRUE</code>, one has to use either <code class="literal">jsonlite::unbox()</code> to ensure scalar output or <code class="literal">I()</code> to ensure array output.</p><p>Now, the collection has two documents:</p><pre class="programlisting">m$count() &#13;
## [1] 2 &#13;
</pre><p>Then, we can use <code class="literal">m$find()</code> to retrieve all documents in the collection, and the results are automatically simplified into a data frame for easier data manipulation:</p><pre class="programlisting">products &lt;- m$find() &#13;
##  &#13;
 Found 2 records... &#13;
 Imported 2 records. Simplifying into dataframe... &#13;
str(products) &#13;
## 'data.frame':    2 obs. of  6 variables: &#13;
##  $ code    : chr  "A0000001" "A0000002" &#13;
##  $ name    : chr  "Product-A" "Product-B" &#13;
##  $ type    : chr  "Type-I" "Type-II" &#13;
##  $ price   : num  29.5 59.9 &#13;
##  $ amount  : int  500 200 &#13;
##  $ comments:List of 2 &#13;
##   ..$ :'data.frame': 2 obs. of  3 variables: &#13;
##   .. ..$ user : chr  "david" "jenny" &#13;
##   .. ..$ score: int  8 5 &#13;
##   .. ..$ text : chr  "This is a good product" "Just so so" &#13;
##   ..$ :'data.frame': 2 obs. of  3 variables: &#13;
##   .. ..$ user : chr  "tom" "mike" &#13;
##   .. ..$ score: int  6 9 &#13;
##   .. ..$ text : chr  "Just fine" "great product!" &#13;
</pre><p>To avoid the automatic conversion, we can use <code class="literal">m$iterate()</code> to iterate over the collection and get list objects that represent the original form of storage:</p><pre class="programlisting">iter &lt;- m$iterate() &#13;
products &lt;- iter$batch(2) &#13;
str(products) &#13;
## List of 2 &#13;
##  $ :List of 6 &#13;
##   ..$ code    : chr "A0000001" &#13;
##   ..$ name    : chr "Product-A" &#13;
##   ..$ type    : chr "Type-I" &#13;
##   ..$ price   : num 29.5 &#13;
##   ..$ amount  : int 500 &#13;
##   ..$ comments:List of 2 &#13;
##   .. ..$ :List of 3 &#13;
##   .. .. ..$ user : chr "david" &#13;
##   .. .. ..$ score: int 8 &#13;
##   .. .. ..$ text : chr "This is a good product" &#13;
##   .. ..$ :List of 3 &#13;
##   .. .. ..$ user : chr "jenny" &#13;
##   .. .. ..$ score: int 5 &#13;
##   .. .. ..$ text : chr "Just so so" &#13;
##  $ :List of 6 &#13;
##   ..$ code    : chr "A0000002" &#13;
##   ..$ name    : chr "Product-B" &#13;
##   ..$ type    : chr "Type-II" &#13;
##   ..$ price   : num 59.9 &#13;
##   ..$ amount  : int 200 &#13;
##   ..$ comments:List of 2 &#13;
##   .. ..$ :List of 3 &#13;
##   .. .. ..$ user : chr "tom" &#13;
##   .. .. ..$ score: int 6 &#13;
##   .. .. ..$ text : chr "Just fine" &#13;
##   .. ..$ :List of 3 &#13;
##   .. .. ..$ user : chr "mike" &#13;
##   .. .. ..$ score: int 9 &#13;
##   .. .. ..$ text : chr "great product!" &#13;
</pre><p>To filter the collection, we can specify the conditional query and fields in <code class="literal">m$find()</code>.</p><p>First, we will query documents with <code class="literal">code</code> of <code class="literal">A0000001</code> and retrieve the <code class="literal">name</code>, <code class="literal">price</code>, and <code class="literal">amount</code> fields:</p><pre class="programlisting">m$find('{ "code": "A0000001" }',  &#13;
'{ "_id": 0, "name": 1, "price": 1, "amount": 1 }') &#13;
##  &#13;
 Found 1 records... &#13;
 Imported 1 records. Simplifying into dataframe... &#13;
##        name price amount &#13;
## 1 Product-A  29.5    500 &#13;
</pre><p>Then, we will query documents with <code class="literal">price</code> greater than or equal to <code class="literal">40</code>, which is done by the <code class="literal">$gte</code> operator in the conditional query:</p><pre class="programlisting">m$find('{ "price": { "$gte": 40 } }', &#13;
'{ "_id": 0, "name": 1, "price": 1, "amount": 1 }') &#13;
##  &#13;
 Found 1 records... &#13;
 Imported 1 records. Simplifying into dataframe... &#13;
##        name price amount &#13;
## 1 Product-B  59.9    200 &#13;
</pre><p>We can not only query the document fields, but also the object fields in an array field. The following code retrieves all documents with any comment that gives a 9-point score:</p><pre class="programlisting">m$find('{ "comments.score": 9 }',  &#13;
'{ "_id": 0, "code": 1, "name": 1}') &#13;
##  &#13;
 Found 1 records... &#13;
 Imported 1 records. Simplifying into dataframe... &#13;
##       code      name &#13;
## 1 A0000002 Product-B &#13;
</pre><p>Similarly, the following code retrieves all documents with any comment that gives a score less than 6:</p><pre class="programlisting">m$find('{ "comments.score": { "$lt": 6 }}', &#13;
'{ "_id": 0, "code": 1, "name": 1}') &#13;
##  &#13;
 Found 1 records... &#13;
 Imported 1 records. Simplifying into dataframe... &#13;
##       code      name &#13;
## 1 A0000001 Product-A &#13;
</pre><p>Note that accessing the field of a subdocument is easily done by the <code class="literal">.</code> notation, which makes it pretty easy to work with nested structures:</p><pre class="programlisting">## [1] TRUE &#13;
</pre><p>The <code class="literal">m$insert()</code> function also works with data frames in R. Now, we will create a new MongoDB connection to another collection:</p><pre class="programlisting">m &lt;- mongo("students", "test", "mongodb://localhost") &#13;
</pre><p>We will create a MongoDB connection, <code class="literal">m</code>, to work with the <code class="literal">students</code> collection in the <code class="literal">test</code> database in a local MongoDB instance:</p><pre class="programlisting">m$count() &#13;
## [1] 0 &#13;
</pre><p>Initially, the collection has no documents. To insert some data, we will create a simple data frame:</p><pre class="programlisting">students &lt;- data.frame( &#13;
  name = c("David", "Jenny", "Sara", "John"), &#13;
  age = c(25, 23, 26, 23), &#13;
  major = c("Statistics", "Physics", "Computer Science", "Statistics"), &#13;
  projects = c(2, 1, 3, 1), &#13;
  stringsAsFactors = FALSE &#13;
) &#13;
students &#13;
##    name age            major projects &#13;
## 1 David  25       Statistics        2 &#13;
## 2 Jenny  23          Physics        1 &#13;
## 3  Sara  26 Computer Science        3 &#13;
## 4  John  23       Statistics        1 &#13;
</pre><p>Then, we will insert the rows as documents into the collection:</p><pre class="programlisting">m$insert(students) &#13;
##  &#13;
Complete! Processed total of 4 rows. &#13;
</pre><p>Now, the collection has some documents:</p><pre class="programlisting">m$count() &#13;
## [1] 4 &#13;
</pre><p>We can retrieve all the documents from the collection using <code class="literal">find()</code>:</p><pre class="programlisting">m$find() &#13;
##  &#13;
 Found 4 records... &#13;
 Imported 4 records. Simplifying into dataframe... &#13;
##    name age            major projects &#13;
## 1 David  25       Statistics        2 &#13;
## 2 Jenny  23          Physics        1 &#13;
## 3  Sara  26 Computer Science        3 &#13;
## 4  John  23       Statistics        1 &#13;
</pre><p>As we mentioned in the previous example, the way in which documents are stored in a MongoDB collection is different from the way columns are stored in a table of a relational database. A document in a MongoDB collection is more like a JSON document, but in fact, it is stored in binary form to achieve super performance and compactness. The <code class="literal">m$find()</code> function first retrieves the data in a JSON-like form and simplifies it into a data form for easy data manipulation.</p><p>To filter the data, we can specify the query condition by supplying documents to <code class="literal">find()</code>. For example, we want to find all documents whose name is <code class="literal">Jenny</code>:</p><pre class="programlisting">m$find('{ "name": "Jenny" }') &#13;
##  &#13;
 Found 1 records... &#13;
 Imported 1 records. Simplifying into dataframe... &#13;
##    name age   major projects &#13;
## 1 Jenny  23 Physics        1 &#13;
</pre><p>The results are automatically coerced to a data frame to make it easier to use. Then, we will query all documents with a number of projects greater or equal to <code class="literal">2</code>:</p><pre class="programlisting">m$find('{ "projects": { "$gte": 2 }}') &#13;
##  &#13;
 Found 2 records... &#13;
 Imported 2 records. Simplifying into dataframe... &#13;
##    name age            major projects &#13;
## 1 David  25       Statistics        2 &#13;
## 2  Sara  26 Computer Science        3 &#13;
</pre><p>To select fields, we will specify the <code class="literal">fields</code> argument of <code class="literal">find()</code>:</p><pre class="programlisting">m$find('{ "projects": { "$gte": 2 }}',  &#13;
'{ "_id": 0, "name": 1, "major": 1 }') &#13;
##  &#13;
 Found 2 records... &#13;
 Imported 2 records. Simplifying into dataframe... &#13;
##    name            major &#13;
## 1 David       Statistics &#13;
## 2  Sara Computer Science &#13;
</pre><p>We can also sort the data by specifying the <code class="literal">sort</code> argument:</p><pre class="programlisting">m$find('{ "projects": { "$gte": 2 }}',  &#13;
fields ='{ "_id": 0, "name": 1, "age": 1 }', &#13;
sort ='{ "age": -1 }') &#13;
##  &#13;
 Found 2 records... &#13;
 Imported 2 records. Simplifying into dataframe... &#13;
##    name age &#13;
## 1  Sara  26 &#13;
## 2 David  25 &#13;
</pre><p>To limit the documents returned, we will specify <code class="literal">limit</code>:</p><pre class="programlisting">m$find('{ "projects": { "$gte": 2 }}',  &#13;
fields ='{ "_id": 0, "name": 1, "age": 1 }', &#13;
sort ='{ "age": -1 }', &#13;
limit =1) &#13;
##  &#13;
 Found 1 records... &#13;
 Imported 1 records. Simplifying into dataframe... &#13;
##   name age &#13;
## 1 Sara  26 &#13;
</pre><p>Also, we can get all distinct values of a certain field of all documents:</p><pre class="programlisting">m$distinct("major") &#13;
## [1] "Statistics"       "Physics"          "Computer Science" &#13;
</pre><p>We can get the distinct values with a condition:</p><pre class="programlisting">m$distinct("major", '{ "projects": { "$gte": 2 } }') &#13;
## [1] "Statistics"       "Computer Science" &#13;
</pre><p>To update a document, we will call <code class="literal">update()</code>, find the documents in selection, and set the values of certain fields:</p><pre class="programlisting">m$update('{ "name": "Jenny" }', '{ "$set": { "age": 24 } }') &#13;
## [1] TRUE &#13;
m$find() &#13;
##  &#13;
 Found 4 records... &#13;
 Imported 4 records. Simplifying into dataframe... &#13;
##    name age            major projects &#13;
## 1 David  25       Statistics        2 &#13;
## 2 Jenny  24          Physics        1 &#13;
## 3  Sara  26 Computer Science        3 &#13;
## 4  John  23       Statistics        1 &#13;
</pre></div><div><div><div><div><h3 class="title"><a id="ch11lvl3sec67"/>Creating and removing indexes</h3></div></div></div><p>Like relational databases, MongoDB also supports indexes. Each collection may have multiple indexes, and the fields of indexes are cached in memory for fast lookup. Properly created indexes can make document lookup extremely efficient.</p><p>Creating indexes in MongoDB with <code class="literal">mongolite</code> is easy. It can be done before or after we import data into the collection. However, if we already imported billions of documents, it can be time consuming to create an index. If we create many indexes before pouring any documents into the collection, the performance of inserting documents may be harmed.</p><p>Here, we will create an index for the <code class="literal">students</code> collection:</p><pre class="programlisting">m$index('{ "name": 1 }') &#13;
##   v key._id key.name   name            ns &#13;
## 1 1       1       NA   _id_ test.students &#13;
## 2 1      NA        1 name_1 test.students &#13;
</pre><p>Now, if we find a document with the indexed field, the performance is super:</p><pre class="programlisting">m$find('{ "name": "Sara" }') &#13;
##  &#13;
 Found 1 records... &#13;
 Imported 1 records. Simplifying into dataframe... &#13;
##   name age            major projects &#13;
## 1 Sara  26 Computer Science        3 &#13;
</pre><p>If no document satisfies the condition, an empty data frame will be returned:</p><pre class="programlisting">m$find('{ "name": "Jane" }') &#13;
##  &#13;
 Imported 0 records. Simplifying into dataframe... &#13;
## data frame with 0 columns and 0 rows &#13;
</pre><p>Finally, the collection can be abandoned with <code class="literal">drop()</code>:</p><pre class="programlisting">m$drop() &#13;
## [1] TRUE &#13;
</pre><p>The performance boost of using an index is definitively not obvious if the amount of data is small. In the next example, we will create a data frame with many rows so that we can compare the performance of finding documents between using an index and not using one.</p><p>Here, we will use <code class="literal">expand.grid()</code> to create a data frame that exhausts all possible combinations of the provided vectors in the arguments:</p><pre class="programlisting">set.seed(123) &#13;
m &lt;- mongo("simulation", "test") &#13;
sim_data &lt;- expand.grid( &#13;
type = c("A", "B", "C", "D", "E"),  &#13;
category = c("P-1", "P-2", "P-3"), &#13;
group = 1:20000,  &#13;
stringsAsFactors = FALSE) &#13;
head(sim_data) &#13;
##   type category group &#13;
## 1    A      P-1     1 &#13;
## 2    B      P-1     1 &#13;
## 3    C      P-1     1 &#13;
## 4    D      P-1     1 &#13;
## 5    E      P-1     1 &#13;
## 6    A      P-2     1 &#13;
</pre><p>The index columns are created. Next, we need to simulate some random numbers:</p><pre class="programlisting">sim_data$score1 &lt;- rnorm(nrow(sim_data), 10, 3) &#13;
sim_data$test1 &lt;- rbinom(nrow(sim_data), 100, 0.8) &#13;
</pre><p>The data frame now looks like this:</p><pre class="programlisting">head(sim_data) &#13;
##   type category group    score1 test1 &#13;
## 1    A      P-1     1  8.318573    80 &#13;
## 2    B      P-1     1  9.309468    75 &#13;
## 3    C      P-1     1 14.676125    77 &#13;
## 4    D      P-1     1 10.211525    79 &#13;
## 5    E      P-1     1 10.387863    80 &#13;
## 6    A      P-2     1 15.145195    76 &#13;
</pre><p>Then, we will insert all the data into the <code class="literal">simulation</code> collection:</p><pre class="programlisting">m$insert(sim_data) &#13;
Complete! Processed total of 300000 rows. &#13;
[1] TRUE &#13;
</pre><p>The first test is trying to answer how long it takes to query a document without any index:</p><pre class="programlisting">system.time(rec &lt;- m$find('{ "type": "C", "category": "P-3", "group": 87 }')) &#13;
##  &#13;
 Found 1 records... &#13;
 Imported 1 records. Simplifying into dataframe... &#13;
##    user  system elapsed  &#13;
##   0.000   0.000   0.104 &#13;
rec &#13;
##   type category  group   score1 test1 &#13;
## 1    C      P-3    87  6.556688    72 &#13;
</pre><p>The second test is about the performance of finding documents with joint conditions:</p><pre class="programlisting">system.time({ &#13;
  recs &lt;- m$find('{ "type": { "$in": ["B", "D"]  },  &#13;
    "category": { "$in": ["P-1", "P-2"] },  &#13;
    "group": { "$gte": 25, "$lte": 75 } }') &#13;
}) &#13;
##  &#13;
Found 204 records... &#13;
 Imported 204 records. Simplifying into dataframe... &#13;
##    user  system elapsed  &#13;
##   0.004   0.000   0.094 &#13;
</pre><p>Then, the resulting data frame looks like this:</p><pre class="programlisting">head(recs) &#13;
##   type category group    score1 test1 &#13;
## 1    B      P-1    25 11.953580    80 &#13;
## 2    D      P-1    25 13.074020    84 &#13;
## 3    B      P-2    25 11.134503    76 &#13;
## 4    D      P-2    25 12.570769    74 &#13;
## 5    B      P-1    26  7.009658    77 &#13;
## 6    D      P-1    26  9.957078    85 &#13;
</pre><p>The third test is about the performance of finding documents using a non-index field:</p><pre class="programlisting">system.time(recs2 &lt;- m$find('{ "score1": { "$gte": 20 } }')) &#13;
##  &#13;
Found 158 records... &#13;
 Imported 158 records. Simplifying into dataframe... &#13;
##    user  system elapsed  &#13;
##   0.000   0.000   0.096 &#13;
</pre><p>The resulting data frame looks like this:</p><pre class="programlisting">head(recs2) &#13;
##   type category group   score1 test1 &#13;
## 1    D      P-1    89 20.17111    76 &#13;
## 2    B      P-3   199 20.26328    80 &#13;
## 3    E      P-2   294 20.33798    75 &#13;
## 4    E      P-2   400 21.14716    83 &#13;
## 5    A      P-3   544 21.54330    73 &#13;
## 6    A      P-1   545 20.19368    80 &#13;
</pre><p>All three tests are done without creating an index for the collection. To make a contrast, we will now create an index:</p><pre class="programlisting">m$index('{ "type": 1, "category": 1, "group": 1 }') &#13;
##   v key._id key.type key.category key.group &#13;
## 1 1       1       NA           NA        NA &#13;
## 2 1      NA        1            1         1 &#13;
##                        name              ns &#13;
## 1                      _id_ test.simulation &#13;
## 2 type_1_category_1_group_1 test.simulation &#13;
</pre><p>Once the index is created, the query of the first test with index fields is quick:</p><pre class="programlisting">system.time({ &#13;
  rec &lt;- m$find('{ "type": "C", "category": "P-3", "group": 87 }') &#13;
}) &#13;
##  &#13;
 Found 1 records... &#13;
 Imported 1 records. Simplifying into dataframe... &#13;
##    user  system elapsed  &#13;
##   0.000   0.000   0.001 &#13;
</pre><p>The second test also yields results quickly:</p><pre class="programlisting">system.time({ &#13;
  recs &lt;- m$find('{ "type": { "$in": ["B", "D"]  },  &#13;
    "category": { "$in": ["P-1", "P-2"] },  &#13;
    "group": { "$gte": 25, "$lte": 75 } }') &#13;
}) &#13;
##  &#13;
 Found 204 records... &#13;
 Imported 204 records. Simplifying into dataframe... &#13;
##    user  system elapsed  &#13;
##   0.000   0.000   0.002 &#13;
</pre><p>However, the non-index fields do not contribute to the index search for documents:</p><pre class="programlisting">system.time({ &#13;
  recs2 &lt;- m$find('{ "score1": { "$gte": 20 } }') &#13;
}) &#13;
##  &#13;
 Found 158 records... &#13;
 Imported 158 records. Simplifying into dataframe... &#13;
##    user  system elapsed  &#13;
##   0.000   0.000   0.095 &#13;
</pre><p>Another important feature of MongoDB is its aggregation pipeline. When we aggregate data, we supply an array of aggregate operations so that they are scheduled by the MongoDB instance. For example, the following code groups the data by <code class="literal">type</code>. Each group has a field count, average score, min test score, and max test score. Since the output can be long, we don't print it here. You may execute the code yourself and see the results:</p><pre class="programlisting">m$aggregate('[ &#13;
  { "$group": {  &#13;
      "_id": "$type",  &#13;
      "count": { "$sum": 1 }, &#13;
      "avg_score": { "$avg": "$score1" }, &#13;
      "min_test": { "$min": "$test1" }, &#13;
      "max_test": { "$max": "$test1" } &#13;
    } &#13;
  } &#13;
]') &#13;
</pre><p>We can also use multiple fields as the key of a group, which is similar to <code class="literal">group by A, B</code> in SQL:</p><pre class="programlisting">m$aggregate('[ &#13;
  { "$group": {  &#13;
      "_id": { "type": "$type", "category": "$category" },  &#13;
      "count": { "$sum": 1 }, &#13;
      "avg_score": { "$avg": "$score1" }, &#13;
      "min_test": { "$min": "$test1" }, &#13;
      "max_test": { "$max": "$test1" } &#13;
    } &#13;
  } &#13;
]') &#13;
</pre><p>The aggregation pipeline supports running aggregate operations in a streamline:</p><pre class="programlisting">m$aggregate('[ &#13;
  { "$group": {  &#13;
      "_id": { "type": "$type", "category": "$category" },  &#13;
      "count": { "$sum": 1 }, &#13;
      "avg_score": { "$avg": "$score1" }, &#13;
      "min_test": { "$min": "$test1" }, &#13;
      "max_test": { "$max": "$test1" } &#13;
    } &#13;
  },  &#13;
  { &#13;
    "$sort": { "_id.type": 1, "avg_score": -1 } &#13;
  } &#13;
]') &#13;
</pre><p>We can lengthen the pipeline by adding more operations. For example, the following code creates groups and aggregate data. Then, it sorts the documents with average score in the descending order, takes out the top three documents, and projects the fields into something useful:</p><pre class="programlisting">m$aggregate('[ &#13;
  { "$group": {  &#13;
      "_id": { "type": "$type", "category": "$category" },  &#13;
      "count": { "$sum": 1 }, &#13;
      "avg_score": { "$avg": "$score1" }, &#13;
      "min_test": { "$min": "$test1" }, &#13;
      "max_test": { "$max": "$test1" } &#13;
    } &#13;
  },  &#13;
  { &#13;
    "$sort": { "avg_score": -1 } &#13;
  },  &#13;
  { &#13;
    "$limit": 3 &#13;
  },  &#13;
  { &#13;
    "$project": {  &#13;
      "_id.type": 1,  &#13;
      "_id.category": 1,  &#13;
      "avg_score": 1,  &#13;
      "test_range": { "$subtract": ["$max_test", "$min_test"] } &#13;
    } &#13;
  } &#13;
]') &#13;
</pre><p>In addition to the aggregate operators we used in the example, there are many other operators that are more powerful. For more details, visit <a class="ulink" href="https://docs.mongodb.com/manual/reference/operator/aggregation-pipeline/">https://docs.mongodb.com/manual/reference/operator/aggregation-pipeline/</a> and <a class="ulink" href="https://docs.mongodb.com/manual/reference/operator/aggregation-arithmetic/">https://docs.mongodb.com/manual/reference/operator/aggregation-arithmetic/</a>.</p><p>Another important feature of MongoDB is that it supports MapReduce (<a class="ulink" href="https://en.wikipedia.org/wiki/MapReduce">https://en.wikipedia.org/wiki/MapReduce</a>) at an internal level. The MapReduce model is widely used in big data analytics in distributed clusters. In our environment, we can write an extremely simple MapReduce code that tries to produce a histogram of certain data:</p><pre class="programlisting">bins &lt;- m$mapreduce( &#13;
map = 'function() { &#13;
    emit(Math.floor(this.score1 / 2.5) * 2.5, 1); &#13;
  }', &#13;
reduce = 'function(id, counts) { &#13;
    return Array.sum(counts); &#13;
  }' &#13;
) &#13;
</pre><p>The first step of MapReduce is map. In this step, all values are mapped to a key-value pair. Then, the reduce step aggregates the key-value pair. In the preceding example, we simply calculated the number of records for each bin:</p><pre class="programlisting">bins &#13;
##     _id  value &#13;
## 1  -5.0     6 &#13;
## 2  -2.5   126 &#13;
## 3   0.0  1747 &#13;
## 4   2.5 12476 &#13;
## 5   5.0 46248 &#13;
## 6   7.5 89086 &#13;
## 7  10.0 89489 &#13;
## 8  12.5 46357 &#13;
## 9  15.0 12603 &#13;
## 10 17.5  1704 &#13;
## 11 20.0   153 &#13;
## 12 22.5     5 &#13;
</pre><p>We can also create a bar plot from <code class="literal">bins</code>:</p><pre class="programlisting">with(bins, barplot(value /sum(value), names.arg = `_id`, &#13;
main = "Histogram of scores",  &#13;
xlab = "score1", ylab = "Percentage")) &#13;
</pre><p>The plot generated is shown as follows:</p><div><img src="img/image_11_001.jpg" alt="Creating and removing indexes"/></div><p>If the collection is no longer used, then we can use the <code class="literal">drop()</code> function to drop it:</p><pre class="programlisting">m$drop() &#13;
## [1] TRUE &#13;
</pre><p>Since this section is at the introductory level, the more advanced use of MongoDB is beyond the scope of this book. If you are interested in MongoDB, go through the official tutorial at <a class="ulink" href="https://docs.mongodb.com/manual/tutorial/">https://docs.mongodb.com/manual/tutorial/</a>.</p></div></div><div><div><div><div><h2 class="title"><a id="ch11lvl2sec137"/>Using Redis</h2></div></div></div><p>Redis (<a class="ulink" href="http://redis.io/">http://redis.io/</a>), unlike SQLite that stores data in tabular form or MongoDB that allows to store and query nested structures, is an in-memory data structure store. It stores key-values in memory and thus has very high performance of key lookup. However, it does not support query languages as used in SQL databases or MongoDB.</p><p>Redis is usually used as a high-performance data cache. We can store and manipulate a range of basic data structures in it. To install Redis, visit <a class="ulink" href="http://redis.io/download">http://redis.io/download</a>. Unfortunately, the Windows operating system is not officially supported, but the Microsoft Open Tech group develops and maintains a Win64 port of Redis at <a class="ulink" href="https://github.com/MSOpenTech/redis">https://github.com/MSOpenTech/redis</a>.</p><p>While SQL database stores tables and MongoDB stores documents, Redis stores key-value pairs as follows:</p><pre class="programlisting">name: Something &#13;
type: 1 &#13;
grade: A &#13;
</pre><p>The value can be more complex data structures (for example, hashmap, set, and sorted set) rather than simple values, and Redis provides a simple interface to work with these data structures in high performance and low latency.</p><div><div><div><div><h3 class="title"><a id="ch11lvl3sec68"/>Accessing Redis from R</h3></div></div></div><p>To access a Redis instance from R, we can use the <code class="literal">rredis</code> package that provides simple functions to work with Redis. To install the package, run the following code:</p><pre class="programlisting">install.packages("rredis") &#13;
</pre><p>Once the package is ready, we can connect to a Redis instance:</p><pre class="programlisting">library(rredis) &#13;
redisConnect() &#13;
</pre><p>If we leave the arguments blank, it connects to the local Redis instance by default. It also lets us connect to a remote instance.</p></div><div><div><div><div><h3 class="title"><a id="ch11lvl3sec69"/>Setting and getting values from the Redis server</h3></div></div></div><p>The most basic use of Redis is to store a value by calling <code class="literal">redisSet(key, value)</code>. In R, the value is, by default, serialized so that we can store any R objects in Redis:</p><pre class="programlisting">redisSet("num1", 100) &#13;
## [1] "OK" &#13;
</pre><p>Now that the command has succeeded, we can retrieve the value with the same key:</p><pre class="programlisting">redisGet("num1") &#13;
## [1] 100 &#13;
</pre><p>We can store an integer vector:</p><pre class="programlisting">redisSet("vec1", 1:5) &#13;
## [1] "OK" &#13;
redisGet("vec1") &#13;
## [1] 1 2 3 4 5 &#13;
</pre><p>We can even store a data frame:</p><pre class="programlisting">redisSet("mtcars_head", head(mtcars, 3)) &#13;
## [1] "OK" &#13;
redisGet("mtcars_head") &#13;
##                mpg cyl disp  hp drat    wt  qsec vs am gear &#13;
## Mazda RX4     21.0   6  160 110 3.90 2.620 16.46  0  1    4 &#13;
## Mazda RX4 Wag 21.0   6  160 110 3.90 2.875 17.02  0  1    4 &#13;
## Datsun 710    22.8   4  108  93 3.85 2.320 18.61  1  1    4 &#13;
##               carb &#13;
## Mazda RX4        4 &#13;
## Mazda RX4 Wag    4 &#13;
## Datsun 710       1 &#13;
</pre><p>In fact, if other computers have access to your Redis instance, they will get the same data in R using <code class="literal">redisGet()</code>:</p><p>However, we can only get <code class="literal">NULL</code> if the key does not exist at all:</p><pre class="programlisting">redisGet("something") &#13;
## NULL &#13;
</pre><p>Instead of getting <code class="literal">NULL</code>, we can use <code class="literal">redisExists()</code> to detect whether a key is defined:</p><pre class="programlisting">redisExists("something") &#13;
## [1] FALSE &#13;
redisExists("num1") &#13;
## [1] TRUE &#13;
</pre><p>If we no longer need a key, we can delete it with <code class="literal">redisDelete()</code>:</p><pre class="programlisting">redisDelete("num1") &#13;
## [1] "1" &#13;
## attr(,"redis string value") &#13;
## [1] TRUE &#13;
redisExists("num1") &#13;
## [1] FALSE &#13;
</pre><p>In addition to plain key-value pairs, Redis also supports more advanced data structures. For example, we can use <code class="literal">redisHSet()</code> to create a hash map of fruits in which different fruits have different numbers:</p><pre class="programlisting">redisHSet("fruits", "apple", 5) &#13;
## [1] "1" &#13;
## attr(,"redis string value") &#13;
## [1] TRUE &#13;
redisHSet("fruits", "pear", 2) &#13;
## [1] "1" &#13;
## attr(,"redis string value") &#13;
## [1] TRUE &#13;
redisHSet("fruits", "banana", 9) &#13;
## [1] "1" &#13;
## attr(,"redis string value") &#13;
## [1] TRUE &#13;
</pre><p>We can call <code class="literal">redisHGet()</code> to get the value of a field of a hash map:</p><pre class="programlisting">redisHGet("fruits", "banana") &#13;
## [1] 9 &#13;
</pre><p>We can also get a list to represent the structure of the hash map:</p><pre class="programlisting">redisHGetAll("fruits") &#13;
## $apple &#13;
## [1] 5 &#13;
##  &#13;
## $pear &#13;
## [1] 2 &#13;
##  &#13;
## $banana &#13;
## [1] 9 &#13;
</pre><p>Alternatively, we can get the keys of the hash map:</p><pre class="programlisting">redisHKeys("fruits") &#13;
## [[1]] &#13;
## [1] "apple" &#13;
## attr(,"redis string value") &#13;
## [1] TRUE &#13;
##  &#13;
## [[2]] &#13;
## [1] "pear" &#13;
## attr(,"redis string value") &#13;
## [1] TRUE &#13;
##  &#13;
## [[3]] &#13;
## [1] "banana" &#13;
## attr(,"redis string value") &#13;
## [1] TRUE &#13;
</pre><p>We can also get only the values of the hash map:</p><pre class="programlisting">redisHVals("fruits") &#13;
## [[1]] &#13;
## [1] 5 &#13;
##  &#13;
## [[2]] &#13;
## [1] 2 &#13;
##  &#13;
## [[3]] &#13;
## [1] 9 &#13;
</pre><p>Aditionally, we can simply get the number of fields in the hash map:</p><pre class="programlisting">redisHLen("fruits") &#13;
## [1] "3" &#13;
## attr(,"redis string value") &#13;
## [1] TRUE &#13;
</pre><p>We can get the values of multiple fields at once:</p><pre class="programlisting">redisHMGet("fruits", c("apple", "banana")) &#13;
## $apple &#13;
## [1] 5 &#13;
##  &#13;
## $banana &#13;
## [1] 9 &#13;
</pre><p>We can also set the values of multiple fields by supplying a list:</p><pre class="programlisting">redisHMSet("fruits", list(apple = 4, pear = 1)) &#13;
## [1] "OK" &#13;
</pre><p>Now, the values of the fields are updated:</p><pre class="programlisting">redisHGetAll("fruits") &#13;
## $apple &#13;
## [1] 4 &#13;
##  &#13;
## $pear &#13;
## [1] 1 &#13;
##  &#13;
## $banana &#13;
## [1] 9 &#13;
</pre><p>In addition to the hash map, Redis also supports queue. We can push values from either left-hand side or the right-hand side of the queue. For example, we push integers from <code class="literal">1</code> to <code class="literal">3</code> from the right-hand side of a queue:</p><pre class="programlisting">for (qi in 1:3) { &#13;
  redisRPush("queue", qi)   &#13;
} &#13;
</pre><p>We can get the current length of the queue with <code class="literal">redisLLen()</code>:</p><pre class="programlisting">redisLLen("queue") &#13;
## [1] "3" &#13;
## attr(,"redis string value") &#13;
## [1] TRUE &#13;
</pre><p>Now, the queue has three elements. Note that the value is a character vector rather than an integer. Therefore, we need to convert it if we need to use it as a number in other places.</p><p>Then, we can keep popping values from the left-hand side of the queue:</p><pre class="programlisting">redisLPop("queue") &#13;
## [1] 1 &#13;
redisLPop("queue") &#13;
## [1] 2 &#13;
redisLPop("queue") &#13;
## [1] 3 &#13;
redisLPop("queue") &#13;
## NULL &#13;
</pre><p>Note that the queue only has three elements to pop out. The fourth attempt returns <code class="literal">NULL</code>, which can be a criterion to check whether the queue is empty.</p><p>Finally, we should close the connection to Redis to release all resources:</p><pre class="programlisting">redisClose() &#13;
</pre><p>Redis has more advanced features that are beyond the scope of this chapter. It supports not only data structure store, but also message broker, that is, we can use it to pass messages between different programs. For more advanced usage, read the official documentation at <a class="ulink" href="http://redis.io/documentation">http://redis.io/documentation</a>.</p></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch11lvl1sec60"/>Summary</h1></div></div></div><p>In this chapter, you learned how to access different types of databases from R. We introduced the basic usage of relational databases such as SQLite and non-relational databases such as MongoDB and Redis. With the understanding of major differences in their functionality and feature sets, we need to choose an appropriate database to work with in our projects according to our purpose and needs.</p><p>In many data-related projects, data storage and data importing are the initial steps, but data cleaning and data manipulation cost most of the time. In the next chapter, we will move on to data-manipulation techniques. You will learn about a number of packages that are specially tailored for handy but powerful data manipulation. To better work with these packages, we'll need a better understanding of how they work, which requires the sound knowledge introduced in the previous chapters.</p></div></body></html>