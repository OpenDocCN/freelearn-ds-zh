<html><head></head><body><div><h1 class="header-title">Vector Data Analysis</h1>
                
            
            
                
<p>This chapter will cover geospatial analysis and processing of vector data. The following three Python libraries will be covered—Shapely, OGR, and GeoPandas. The reader will learn how to use these Python libraries to perform geospatial analysis, including the writing of basic and advanced analysis scripts.</p>
<p>Each library is covered separately, with an overview of its data structures, methods, and classes where appropriate. We'll discuss the best use cases for each library and how to use them together for geospatial workflows. Short example scripts illustrate how to perform the basic geographical analysis. The GeoPandas library enables more complex functionality for doing data science tasks and incorporating geospatial analysis.</p>
<p>In this chapter, we'll cover the following topics:</p>
<ul>
<li>Reading and writing vector data</li>
<li>Creating and manipulating vector data</li>
<li>Visualizing (plotting) vector data on a map</li>
<li>Working with map projections and reproject data</li>
<li>Performing spatial operations such as spatial joins</li>
<li>Working with vector geometries and attribute data in tabular form</li>
<li>Analyzing the results to answer questions, such as how many wildfires are there in area x?</li>
</ul>
<p>After this chapter, you'll have a solid foundation to start working with geospatial vector data. You'll know the characteristics and use cases of all three geospatial libraries, and know how to do basic vector data processing and analysis.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">OGR Simple Features Library</h1>
                
            
            
                
<p><strong>OGR Simple Features Library</strong> (part of the <strong>Geospatial Data Abstraction Library</strong> (<strong>GDAL</strong>)) offers a set of tools for dealing with vector data. Although both GDAL and OGR are now more integrated than they used to be, we can still divide GDAL between a vector part (OGR) and a raster part (GDAL). While OGR was written in C++ and the documentation is also in C++, with Python bindings we can access all of GDAL's functionality using Python.</p>
<p>We can distinguish the following components of OGR:</p>
<ul>
<li>OGR batch commands for describing and processing vector data</li>
<li><kbd>ogrmerge</kbd>, an instant Python script for merging multiple vector data files</li>
<li>The OGR library itself</li>
</ul>
<p>We'll briefly cover these components first, before moving on to some examples of how to use all three.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">OGR batch commands</h1>
                
            
            
                
<p>OGR offers a series of batch commands that can be used to describe and convert existing geospatial vector data. We've already mentioned two of them, <kbd>ogrinfo</kbd> and <kbd>ogr2ogr</kbd>, in <a href="16f36845-4cea-4aa2-8eb4-8b2916c23398.xhtml">Chapter 4</a>, <em>Data Types, Storage, and Conversion</em>:</p>
<ul>
<li><kbd>ogrinfo</kbd> can be used for doing all sorts of reporting on vector data, such as listing supported vector formats, available layers, and summary details, and can be combined with SQL-query syntax to select features from a dataset.</li>
<li><kbd>ogr2ogr</kbd> is for doing vector data translations, such as converting vector files between different formats, converting multiple layers into a new data source, and reproject vector data and filter features based on location. It can also be used with SQL-query syntax just like <kbd>ogrinfo</kbd>.</li>
</ul>
<p>These are very powerful commands that let you do a lot of work. It is recommended you familiarize yourself with these commands when working with vector data. We'll get to some examples shortly.</p>
<p>Additionally, two other batch commands exist for creating vector tiles, <kbd>ogrtindex</kbd> and <kbd>ogr2vrt</kbd>. The difference between the two is that the second one is more broadly usable than the first. The second command needs to be imported from an online script as it is not distributed with recent GDAL versions.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">ogrmerge</h1>
                
            
            
                
<p>Along with the installation of GDAL comes a set of Python scripts that can be used for specialized geospatial tasks. These scripts can be run directly from a Jupyter Notebook or terminal, along with a specified dataset. You can find all of the scripts inside of the <kbd>scripts</kbd> directory of your local <kbd>gdal</kbd> file folder, which on a Windows machine might be similar to the following path:</p>
<p><kbd>C:\Users\Username\Anaconda3\pkgs\gdal-2.2.2-py36_1\scripts</kbd></p>
<p>As you can see from the list of Python scripts in this folder, almost all of them are for GDAL rather than OGR. All of these Python scripts can be run from a Jupyter Notebook or a terminal. Using a Jupyter Notebook, you can use the magic command <kbd>%run</kbd> to execute your Python script, whereas using a terminal you'd use <kbd>python</kbd> followed by the name of the script and the input/output data files.</p>
<p>Magic commands are commands that extend the core Python language and can only be used in the Jupyter Notebook application. They offer useful shortcuts, for example, inserting code from an external script, and executing Python code from <kbd>.py</kbd> files on disc or <kbd>shell</kbd> commands. A full list of magic commands can be printed with the following command in an empty cell, <kbd>%lsmagic</kbd>. </p>
<p>The following example uses <kbd>ogrmerge.py</kbd>, a Python script available with GDAL version 2.2.2 and higher. Running this script from a Jupyter Notebook, it takes all shapefiles in a single folder from the Earth dataset and merges them into a single GeoPackage file called <kbd>merged.gpkg</kbd>:</p>
<pre>In: %run "C:\Users\Eric\Anaconda3\pkgs\gdal-2.2.2-                        <br/>    py36_1\Scripts\ogrmerge.py" -f GPKG -o<br/>    merged.gpkg "C:\data\gdal\NE\10m_cultural\*.shp"</pre>
<p>Please note that in order to run one of the Python scripts in the GDAL directory correctly, you need to reference their file location if it's located in a different folder than the one where you're running the script, which is likely to be the case if you're working with the Jupyter Notebook application.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">The OGR library and Python bindings</h1>
                
            
            
                
<p>The <kbd>OGR</kbd> library, combined with its Python bindings, forms the most important part for working with vector data in Python. With it, you can create points, lines, and polygons, and perform spatial operations on these elements. For example, you can calculate the area of a geometry, overlay different data on top of each other, and use proximity tools such as buffers. Additionally, just as with <kbd>ogrinfo</kbd> and <kbd>ogr2ogr</kbd>, the OGR library offers tools to read vector data files, iterate over individual elements, and select and reproject data.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">OGR's main modules and classes</h1>
                
            
            
                
<p>The OGR library consists of two main modules—<kbd>ogr</kbd> and <kbd>osr</kbd>. Both are sub-modules inside of the <kbd>osgeo</kbd> module. The <kbd>ogr</kbd> sub-module deals with vector geometry, while <kbd>osr</kbd> is all about projections. In the <em>Reading and writing vector data with OGR</em> section in <a href="16f36845-4cea-4aa2-8eb4-8b2916c23398.xhtml">Chapter 4</a>, <em>Data Types, Storage, and Conversion</em>, we already saw some examples of how to make use of both.</p>
<p>OGR offers the following seven classes:</p>
<ul>
<li><kbd>Geometry</kbd></li>
<li><kbd>Spatial Reference</kbd></li>
<li><kbd>Feature</kbd></li>
<li><kbd>Feature Class Definition</kbd></li>
<li><kbd>Layer</kbd></li>
<li><kbd>Dataset</kbd></li>
<li><kbd>Drivers</kbd></li>
</ul>
<p>The class names are mostly self-explanatory, but it's good to have an overview of how OGR is structured. In the following examples, we'll see how to access and make use of these classes. OGR's modules, classes, and functions are documented on the GDAL website (<a href="http://www.gdal.org/python">www.gdal.org/python</a>) but offer no code examples, which makes it hard to get started. What's good to know at this point is that other Python libraries fill in the gap and offer a more user-friendly way to deal with GDAL's capabilities (such as Fiona and GeoPandas). Also, both <kbd>ogrinfo</kbd> and <kbd>ogr2ogr</kbd> might be preferable over using Python in some use cases, for example, when reprojecting vector data.</p>
<p>Let's look at a few OGR examples.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Creating polygon geometry with OGR</h1>
                
            
            
                
<p>OGR lets you write vector geometries such as points, lines, mulitipoints, multilinestrings, multipolygons and geometry collections. You can give these geometry values in coordinates or meters if you plan to project them later. All geometries you create follow the same procedure, separate points are defined and then strung together as lines or polygons. You define separate entities in numbers, encode them in <strong>well-known binary</strong> (<strong>WKB</strong>), and the final polygon is translated to <strong>well-known text</strong> (<strong>WKT</strong>). A Jupyter Notebook will return the coordinates of the polygon but won't plot it automatically, for this, we'll use Shapely later in this chapter:</p>
<pre style="padding-left: 30px">In: from osgeo import ogr<br/>    r = ogr.Geometry(ogr.wkbLinearRing)<br/>    r.AddPoint(1,1)<br/>    r.AddPoint(5,1)<br/>    r.AddPoint(5,5)<br/>    r.AddPoint(1,5)<br/>    r.AddPoint(1,1)<br/>    poly = ogr.Geometry(ogr.wkbPolygon)<br/>    poly.AddGeometry(r)<br/>    print(poly.ExportToWkt())<br/>Out: POLYGON ((1 1 0,5 1 0,5 5 0,1 5 0,1 1 0))</pre>


            

            
        
    </div>



  
<div><h1 class="header-title">Creating polygon geometry from GeoJSON</h1>
                
            
            
                
<p>You can also create a geometry by passing in GeoJSON to OGR, which saves space compared to the first example:</p>
<pre>In: from osgeo import ogr<br/>    geojson = """{"type":"Polygon","coordinates":[[[1,1],[5,1],<br/>    [5,5],[1,5], [1,1]]]}"""<br/>    polygon = ogr.CreateGeometryFromJson(geojson)<br/>    print(polygon)  <br/>Out: POLYGON ((1 1,5 1,5 5,1 5,1 1))</pre>


            

            
        
    </div>



  
<div><h1 class="header-title">Basic geometric operations</h1>
                
            
            
                
<p>Here are some basic geometric operations we can perform on our polygon. We create the area, centroid, boundary, convex hull, buffer, and check if a polygon contains a certain point:</p>
<pre style="padding-left: 60px"># 1 create area<br/>In: print("The area of our polygon is %d" % polygon.Area())<br/>Out: The area of our polygon is 16<br/><br/># 2 calculate centroid of polygon<br/>In: cen = polygon.Centroid()<br/>print(cen)<br/>Out: POINT (3 3)<br/><br/># 3 Get the boundary<br/>In: b = polygon.GetBoundary()<br/>print(b)<br/>Out: LINESTRING (1 1,5 1,5 5,1 5,1 1)<br/><strong><br/></strong># 4 convex hull does the same in this case as boundary, as our polygon is a square:<br/>In: ch = polygon.ConvexHull() <br/>print(ch)<br/>Out: POLYGON ((1 1,1 5,5 5,5 1,1 1))<br/><strong><br/></strong># 5 buffer. A buffer value of 0 (zero) returns the same values as boundary and convex hull in this example:<br/>In: buffer = polygon.Buffer(0) <br/>print(buffer)<br/>Out: POLYGON ((1 1,1 5,5 5,5 1,1 1))<strong><br/><br/></strong># 6 check if a point is inside our polygon<br/>In: point = ogr.Geometry(ogr.wkbPoint)<br/>point.AddPoint(10, 10)<br/>polygon.Contains(point)<br/>Out: False</pre>


            

            
        
    </div>



  
<div><h1 class="header-title">Writing polygon data to a newly created shapefile</h1>
                
            
            
                
<p>Our current polygon only exists in memory. We can create a new shapefile and write the polygon geometry we created earlier to this shapefile. The script consists of the following steps:</p>
<ol>
<li>Import the modules and set the spatial reference (in this case, <strong>World Geodetic System 1984</strong> (<strong>WGS1984</strong>)).</li>
<li>Create the shapefile, then the layer using polygon geometry. Next, the geometry is put inside a feature and the feature in a layer. Notice that the script directly references the polygon from the earlier example.</li>
<li>The catch is to use the right geometry type in the first line of code, which in this case should be <kbd>wkbPolygon</kbd>.</li>
<li>The polygon geometry from our earlier example is referenced in this step and put into the shapefile.</li>
<li>The shapefile is added as a layer in this step.</li>
</ol>
<p>Take a look at the following code:</p>
<pre style="padding-left: 60px">In:  import osgeo.ogr, osgeo.osr<br/>    # 1 set the spatial reference<br/>    spatialReference = osgeo.osr.SpatialReference()<br/>    spatialReference.ImportFromProj4('+proj=longlat +ellps=WGS84                 <br/>    +datum=WGS84 +no_defs')<br/>    <br/>    # 2 create a new shapefile<br/>    driver = osgeo.ogr.GetDriverByName('ESRI Shapefile')<br/>    shapeData = driver.CreateDataSource('my_polygon.shp')<br/><br/>    # 3 create the layer<br/>    layer = shapeData.CreateLayer('polygon_layer', spatialReference,             <br/>    osgeo.ogr.wkbPolygon)<br/>    layerDefinition = layer.GetLayerDefn()<br/><br/>    # 4 geometry is put inside feature<br/>    featureIndex = 0<br/>    feature = osgeo.ogr.Feature(layerDefinition)<br/>    feature.SetGeometry(polygon)<br/>    feature.SetFID(featureIndex)<br/><br/>    # 5 feature is put into layer<br/>    layer.CreateFeature(feature)</pre>
<p>We can use <kbd>ogrInfo</kbd> to see if the file has been created correctly:</p>
<pre style="padding-left: 60px">In: !ogrinfo my_polygon.shp<br/>Out: INFO: Open of `my_polygon.shp'<br/>     using driver `ESRI Shapefile' successful.<br/>     1: my_polygon (Polygon)</pre>


            

            
        
    </div>



  
<div><h1 class="header-title">Using a spatial filter to select features</h1>
                
            
            
                
<p>This example uses the Natural Earth Dataset introduced in <a href="16f36845-4cea-4aa2-8eb4-8b2916c23398.xhtml" target="_blank">Chapter 4</a>, <em>Data Types, Storage</em>, <em>and Conversion</em>, under the <em>Reading and writing vector data with GeoPandas</em> section. We'll use latitude-longitude coordinates to create a spatial filter in the form of a bounding box. This box selects only the data inside of this box. This is a way to work with a subset of our data. We'll use OGR's <kbd>SpatialFilterRec</kbd> method, which takes four values—<kbd>minx</kbd>, <kbd>miny</kbd>, <kbd>maxx</kbd> and <kbd>maxy</kbd>, to create a bounding box. Our (random) example is to select the cities in our bounding box (which shows the state of Texas, as well as parts of Oklahoma and Mexico). To filter our results even further, we only want the cities in the US. This means we have to filter our search results with an extra <kbd>if</kbd>/<kbd>else</kbd> statement in our <kbd>for</kbd> loop.</p>
<p>The website <a href="http://www.mapsofworld.com">www.mapsofworld.com</a> gives the following four values for our example code: <kbd>-102</kbd> (<kbd>minx</kbd>), <kbd>26</kbd> (<kbd>miny</kbd>), <kbd>-94</kbd> (<kbd>maxx</kbd>), and <kbd>36</kbd> (<kbd>maxy</kbd>) for the state of Texas. Here is the script:</p>
<pre>In: # import the modules<br/>    from osgeo import ogr<br/>    import os<br/>    # reference the shapefile and specify driver type<br/>    shapefile =                                              <br/>    r"C:\data\gdal\NE\10m_cultural\ne_10m_populated_places.shp"<br/>    driver = ogr.GetDriverByName("ESRI Shapefile")<br/>    # open the data source with driver, zero means open in read-only <br/>    mode<br/>    dataSource = driver.Open(shapefile, 0)<br/>    # use the GetLayer() function for referencing the layer that holds <br/>    the data<br/>    layer = dataSource.GetLayer()<br/>    # pass in the coordinates for the data frame to the                     <br/>    SetSpatialFilterRect() function. This filter creates a rectangular     <br/>    extent and selects the features<br/>      inside the extent<br/>      layer.SetSpatialFilterRect(-102, 26, -94, 36)<br/>      for feature in layer:<br/>      # select only the cities inside of the USA<br/>      # we can do this through a SQL query:<br/>      # we skip the cities that are not in the USA,<br/>      # and print the names of the cities that are<br/>          if feature.GetField("ADM0NAME") != "United States of                              <br/>      America":<br/>              continue<br/>          else:<br/>              print(feature.GetField("NAME"))<br/><br/>Out:    Ardmore<br/>        McAlester<br/>        Bryan<br/>        San Marcos<br/>        Longview<br/>        …</pre>


            

            
        
    </div>



  
<div><h1 class="header-title">Shapely and Fiona</h1>
                
            
            
                
<p>The Shapely and Fiona libraries have been introduced in <a href="757a81a6-cc47-4f08-88d2-b50480eb32e6.xhtml" target="_blank">Chapter 2</a>, <em>Introduction to Geospatial Code Libraries</em>, in the sections <em>Shapely</em> and <em>Fiona</em>. It makes sense to cover both of them together, as Shapely depends on other libraries for reading and writing files and Fiona fits the bill. As we'll see in the examples, we can use Fiona to open and read files and then pass geometry data to Shapely objects.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Shapely objects and classes</h1>
                
            
            
                
<p>The Shapely library is used for creating and manipulating 2D vector data without the need for a spatial database. Not only does it do away with a database, it also does away with projections and data formats, focusing on geometry only. The strength of Shapely is that it uses easily-readable syntax to create a variety of geometries that can be used for geometric operations.</p>
<p>With the aid of other Python packages, these geometries and the results of geometric operations can be written to a vector file format and projected if necessary—we'll cover examples combing <kbd>pyproj</kbd> and Fiona with Shapely's capabilities. An example of a workflow incorporating Shapely might be where you'd read vector geometries out of a shapefile using Fiona, and then use Shapely to simplify or clean up existing geometries, in case things might line up correctly internally or in combination with other geometries. The cleaned-up geometries can be used as input for other workflows, for example, for creating a thematic map or performing data science.</p>
<p> The Shapely library uses a set of classes that are implementations of three fundamental types of geometric objects—points, curves, and surfaces. If you are familiar with geospatial data and their geometries, they will sound familiar. If you're not, use the examples to get familiar with them:</p>
<div><table>
<tbody>
<tr>
<td>
<p><strong>Geometric object name</strong></p>
</td>
<td>
<p><strong>Class name</strong></p>
</td>
</tr>
<tr>
<td>
<p>Point</p>
</td>
<td>
<p>Point</p>
</td>
</tr>
<tr>
<td>
<p>Curve</p>
</td>
<td>
<p>LineString, LinearRing</p>
</td>
</tr>
<tr>
<td>
<p>Surface</p>
</td>
<td>
<p>Polygon</p>
</td>
</tr>
<tr>
<td>
<p>Collection of points</p>
</td>
<td>
<p>MultiPoint</p>
</td>
</tr>
<tr>
<td>
<p>Collection of curves</p>
</td>
<td>
<p>MultiLineString</p>
</td>
</tr>
<tr>
<td>
<p>Collection of surfaces</p>
</td>
<td>
<p>MultiPolygon</p>
</td>
</tr>
</tbody>
</table>
</div>


            

            
        
    </div>



  
<div><h1 class="header-title">Shapely methods for geospatial analysis</h1>
                
            
            
                
<p>Topological relationships are implemented as methods on geometric objects (for example, contains, touches, and more). Shapely also provides analysis methods that return new geometric objects (intersections, unions, and more). Creative use of the buffering method provides ways to clean shapes. Interoperation with other software is provided through well-known formats (WKT and WKB), NumPy + Python arrays, and the Python Geo Interface.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Fiona's data model</h1>
                
            
            
                
<p>Although Fiona is OGR's Python wrapper, Fiona uses a data model that differs from OGR. While OGR uses data sources, layers and features, Fiona uses the term records for accessing geographic features stored in vector data. These are based on GeoJSON features—reading a shapefile with Fiona, you reference a record through one of its keys, using a Python dictionary object. A record has an ID, geometry, and property key.</p>
<p>Let's look at a few Shapely and Fiona code examples.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Creating geometries with Shapely</h1>
                
            
            
                
<p>Just like OGR, you can use Shapely to create geometries. Jupyter Notebook will plot the geometries after you've created them, as opposed to OGR. You don't have to use extra plot statements to do this, just repeat the variable name used to store the geometries:</p>
<pre>In:   from shapely.geometry import Polygon<br/>      p1 = Polygon(((1, 2), (5, 3), (5, 7), (1, 9), (1, 2)))<br/>      p2 = Polygon(((6,6), (7,6), (10,4), (11,8), (6,6)))<br/>      p1 <br/>      # A new command line is required for printing the second polygon:<br/>In:   p2<br/><br/>      # Point takes tuples as well as positional coordinate values<br/>In:   from shapely.geometry import Point<br/>      point = Point(2.0, 2.0)<br/>      q = Point((2.0, 2.0))<br/>      q<br/><br/>       # line geometry<br/>In:    from shapely.geometry import LineString<br/>       line = LineString([(0, 0), (10,10)])<br/>       line<br/><br/>       # linear rings<br/>In:    from shapely.geometry.polygon import LinearRing<br/>       ring = LinearRing([(0,0), (3,3), (3,0)])<br/>       ring<br/><br/>       # collection of points<br/>In:    from shapely.geometry import MultiPoint<br/>       points = MultiPoint([(0.0, 0.0), (3.0, 3.0)])<br/>       points<br/><br/>       # collection of lines<br/>In:    from shapely.geometry import MultiLineString<br/>       coords = [((0, 0), (1, 1)), ((-1, 0), (1, 0))]<br/>       coords<br/><br/>       # collection of polygons<br/>In:    from shapely.geometry import MultiPolygon<br/>       polygons = MultiPolygon([p1, p2,])<br/>       polygons</pre>


            

            
        
    </div>



  
<div><h1 class="header-title">Applying geometrical methods with Shapely</h1>
                
            
            
                
<p>In a similar way to OGR, you can apply geometrical methods, using the polygon from the earlier example:</p>
<pre>In:    print(p1.area)<br/>       print(p1.bounds)<br/>       print(p1.length)<br/>       print(p1.geom_type)<br/><br/>Out:   22.0<br/>       (1.0, 2.0, 5.0, 9.0)<br/>       19.59524158061724<br/>       Polygon</pre>


            

            
        
    </div>



  
<div><h1 class="header-title">Reading JSON geometries with Shapely</h1>
                
            
            
                
<p>Although Shapely does not read or write data files, you can access geometries from outside of the library, for instance, by feeding it vector data written in <kbd>json</kbd>. The following script creates a polygon in <kbd>json</kbd> that is read into Shapely in line. Next, the mapping command returns a new, independent geometry with coordinates copied from the context:</p>
<pre>In:    import json<br/>       from shapely.geometry import mapping, shape<br/>       p = shape(json.loads('{"type": "Polygon", "coordinates":                                     <br/>       [[[1,1], [1,3 ], [3,3]]]}'))<br/>       print(json.dumps(mapping(p)))<br/>       p.area<br/><br/>Out:   {"type": "Polygon", "coordinates": [[[1.0, 1.0], [1.0, 3.0],                             <br/>       [3.0, 3.0], [1.0, 1.0]]]}<br/>       2.0<strong>  </strong>        # result of p.area</pre>


            

            
        
    </div>



  
<div><h1 class="header-title">Reading data with Fiona</h1>
                
            
            
                
<p>The following code reads a file from our Natural Earth dataset and prints its dictionary keys:</p>
<pre>In:   import fiona<br/>      c = fiona.open(r"C:\data\gdal\NE\<br/>      110m_cultural\ne_110m_admin_1_states_provinces.shp")<br/>      rec = next(iter(c))<br/>      rec.keys()<br/><br/>Out:  dict_keys(['type', 'id', 'geometry', 'properties'])</pre>
<p>Using the data pretty-print (<kbd>pprint</kbd>) library that is part of Python's standard library, we can print the corresponding values to the keys of the first feature from our dataset:</p>
<pre>In:   import pprint<br/>      pprint.pprint(rec['type'])<br/>      pprint.pprint(rec['id'])<br/>      pprint.pprint(rec['properties'])<br/>      pprint.pprint(rec['geometry'])<br/><br/>Out:  'Feature'<br/>      '0'<br/>      OrderedDict([('adm1_code', 'USA-3514'),<br/>                  ('diss_me', 3514),<br/>                  ('iso_3166_2', 'US-MN'),<br/>                  ('wikipedia',                                               <br/>      'http://en.wikipedia.org/wiki/Minnesota'),<br/>                  ('iso_a2', 'US'),<br/>                  ('adm0_sr', 1),<br/>                  ('name', 'Minnesota'), ….</pre>
<p>Use the following methods on the data file object for printing the following information:</p>
<pre>In:   print(len(c))        # prints total amount of features     <br/>      print(c.driver)      # prints driver name<br/>      print(c.crs)         # prints coordinate reference system of data                                                                                  file<br/><br/>Out:  51<br/>      ESRI Shapefile<br/>      {'init': 'epsg:4326'}</pre>


            

            
        
    </div>



  
<div><h1 class="header-title">Accessing vector geometry in shapefiles using Shapely and Fiona</h1>
                
            
            
                
<p>Using Fiona, you can open a shapefile and access attribute data, such as geometries. For example, our Natural Earth dataset contains a shapefile with all of the states in the US with their vector geometries. Use the following code to open the shapefile and get all of the vector geometry of the first feature (starting from index number <kbd>0</kbd>):</p>
<pre>In:   import pprint, fiona<br/>      with fiona.open\              <br/>     (r"C:\data\gdal\NE\110m_cultural\ne_110m_admin_1_states_provinc        <br/>     es.shp") as src:<br/>      pprint.pprint(src[0])</pre>
<p>We can use the <kbd>shape</kbd> method and pass in all of the coordinates from Minnesota:</p>
<pre>In:   from shapely.geometry import shape<br/>      minnesota = {'type': 'Polygon', 'coordinates': <br/>      [[(-89.61369767938538, 47.81925202085796), (-89.72800594761503, <br/>      47.641976019880644), (-89.84283098016755, 47.464725857119504), <br/>      (-89.95765601272012, 47.286907253603175),....]]}</pre>
<p>Next, we plot the geometry with Shapely:</p>
<div><img src="img/39032e40-fc47-412b-8d32-15240025c709.png" width="305" height="156"/></div>
<p>A note on plotting separate shapefile geometries in Python:</p>
<p>As you may have noticed from the prefacing text, referencing separate geometry elements such as a state from shapefiles and plotting them with Python isn't that straightforward. Luckily, there are many code examples available for professionals to solve this problem. Have a look at the following options that are freely available for Python users, to see how you could approach plotting shapefile vector geometries in Python, if you decide to work directly with shapefiles instead of converting to the GeoJSON format:</p>
<ul>
<li>Use NumPy arrays and <kbd>matplotlib</kbd><strong>: </strong>You can use NumPy arrays to squeeze all of the coordinates in a one-dimensional array and plot these next.</li>
<li>Use Shapely and create a new dictionary from an existing shapefile<strong>: </strong>If you know how to reorganize an existing collection of dictionaries, it is possible to create a new dictionary out of an existing shapefile that uses the name of a geographical area as a key, with the geometry data of that area as values. Next, you can use Shapely to pass in elements of these dictionaries and plot them in Python.</li>
<li>Use <kbd>pyshp</kbd> and <kbd>matplotlib</kbd><strong>: </strong>The <kbd>pyshp</kbd> library can be used to read in geometry information that can then be plotted with <kbd>matplotlib</kbd>.</li>
<li>Use GeoPandas and <kbd>matplotlib</kbd><strong>: </strong>The GeoPandas library can be used together to read in shapefiles. Not only can you plot vector data using matplotlib's capabilities, but you can also read in attribute tables as <kbd>pandas</kbd> dataframes.</li>
</ul>


            

            
        
    </div>



  
<div><h1 class="header-title">GeoPandas</h1>
                
            
            
                
<p>GeoPandas has been introduced in the <em>GeoPandas</em> section of  <a href="757a81a6-cc47-4f08-88d2-b50480eb32e6.xhtml" target="_blank">Chapter 2</a>, <em>Introduction to Geospatial Code Libraries</em>, where its data structures and methods have also been covered.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Geospatial analysis with GeoPandas</h1>
                
            
            
                
<p>GeoPandas was created to offer data to scientists who want to work with spatial data similar to <kbd>pandas</kbd>, and this means giving access to geospatial attribute data through data structures not available through <kbd>pandas</kbd>. Combine this with a set of geometric operations, data overlay capabilities, geocoding and plotting capabilities and you have an idea of this library's capabilities. In the examples mentioned as we proceed, we'll cover GeoPandas' plotting methods, explain how to access and subset spatial data, and provide a typical workflow for doing geospatial analysis with GeoPandas, where data processing is an important condition for being able to analyze and interpret the data correctly.</p>
<p>Let's have a look at a few code examples of GeoPandas.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Selecting and plotting geometry data with GeoPandas and Matplotlib</h1>
                
            
            
                
<p>The following script combines <kbd>pandas</kbd> dataframe methods on GeoPandas GeoDataFrame objects. Together, you can easily subset data and plot separate feature geometries. We start with importing the module, the magic command for plotting data inside a Juypter Notebook and input data, which is a shapefile with all US state boundaries:</p>
<pre>In: import geopandas as gpd<br/>    %matplotlib inline<br/>    df = gpd.read_file\<br/> (r"C:\data\gdal\NE\110m_cultural\ne_110m_admin_1_states_provinces.shp" )<br/>    df</pre>
<p>Some simple data inspection methods—<kbd>type(df)</kbd> returns the object type, which is a GeoPandas <kbd>GeoDataFrame</kbd>, which takes in the same methods as <kbd>pandas</kbd> dataframes. The <kbd>shape</kbd> method returns a tuple with rows and column amounts, while <kbd>df.columns</kbd> returns the column names as a list item:</p>
<pre>In:        type(df)<br/>Out:       geopandas.geodataframe.GeoDataFrame<br/><br/>In:        df.shape<br/>Out:       (51, 61)<br/><br/>In:        df.columns<br/>Out:       Index(['adm1_code', 'diss_me', 'iso_3166_2', 'wikipedia', ...</pre>
<p>We can subset separate rows of our <kbd>GeoDataFrame</kbd> using <kbd>pandas</kbd>, <kbd>.loc</kbd> and <kbd>.iloc</kbd> methods. We access the first feature's attributes, as follows:</p>
<pre>In:        df.loc[0]<br/><br/>Out:       adm1_code       USA-3514<br/>           diss_me         3514<br/>           iso_3166_2      US-MN<br/>           Wikipedia       http://en.wikipedia.org/wiki/Minnesota<br/>           iso_a2          US<br/>           adm0_sr         1<br/>           name            Minnesota<br/>           …               …</pre>
<p>Now, we'll plot some state data. First, we'll get a list of all of the state names as we need the state names and their row numbers next:</p>
<pre>In:    df['name']<br/><br/>Out:   0    Minnesota<br/>       1    Montana<br/>       2    North Dakota<br/>       3    Hawaii<br/>       4    Idaho<br/>       5    Washington<br/>       …    …</pre>
<p>Separate rows can be referenced by <kbd>name</kbd> instead of row number using <kbd>.loc</kbd> and a value. Repeating the <kbd>name</kbd> value returns all columns and attribute data:</p>
<pre>In:    california = df.loc[df['name'] == "California"]<br/>       california</pre>
<p>You can plot the geometry of this variable as follows:</p>
<pre>In:    california.plot(figsize=(7,7))</pre>
<p>Here is what the graph looks like:</p>
<div><img src="img/35aa3f80-07fc-48e7-ad32-6bc065dc5b38.png" width="525" height="437"/></div>
<p>You can plot multiple items by using the <kbd>.iloc</kbd> function and pass it a list of row numbers; in this case, the row numbers correspond to Washington, California, Nevada, and Oregon, respectively:</p>
<pre>In:   multipl = df.iloc[[5,7,9,11]]<br/>      multipl.plot(cmap="Set1", figsize=(7,7))</pre>
<p>The output graph will look like this:</p>
<div><img src="img/53ca246a-1f7e-4212-9d3f-63c0d05bad08.png" width="522" height="448"/></div>
<p>The same results can be obtained using the <kbd>.cx</kbd> method on the <kbd>GeoDataFrame</kbd>, passing in values for a bounding box. This method uses the following syntax: <kbd>df.cx[xmin:xmax, ymin:ymax]</kbd>:</p>
<pre>In:  exp = df.cx[-124:-118,30:50]<br/>     exp.plot(cmap="Set1", figsize=(7,7))</pre>


            

            
        
    </div>



  
<div><h1 class="header-title">Mapping wildfire data with GeoPandas</h1>
                
            
            
                
<p>The following script can be used to create a choropleth map that shows the total wildfires in the US from 1984-2015, based on total count per state. We can use the MTBS with fire data that was introduced in <a href="16f36845-4cea-4aa2-8eb4-8b2916c23398.xhtml" target="_blank">Chapter 4</a>, <em>Data Types, Storage, and Conversion</em>, which gives us point data of all of the wildfire occurrences from 1984-2015. We can use the state field of the wildfire data to map the wildfire occurrences by state. But, we choose here to overlay the data on a separate shapefile with state geometries, to illustrate the use of a spatial join. Next, we'll count the total wildfires per state and map the results. GeoPandas can be used to accomplish all of these tasks.</p>
<p>We start with importing the module:</p>
<pre>In:   import geopandas</pre>
<p>Next, we import the shapefile with all of the state boundaries:</p>
<pre>In:  states =              <br/>     geopandas.read_file(r"C:\data\gdal\NE\110m_cultural\ne_110m_admin_          <br/>     1_states_provinces.shp")</pre>
<p>The attribute table of the file can be displayed as a <kbd>pandas</kbd> dataframe by repeating the variable name:</p>
<pre>In:   states</pre>
<p>We can see all of the state names listed in the name column. We will need this column later. The vector data can be plotted inside our Jupyter Notebook, using the magic command and the <kbd>plot</kbd> method from <kbd>matplotlib</kbd>. As the default maps look quite small, we'll pass in some values using the <kbd>figsize</kbd> option to make it look bigger:</p>
<pre>In: %matplotlib inline<br/>    states.plot(figsize=(10,10))</pre>
<p>You'll see the following map:</p>
<div><img src="img/0f4166b8-d750-402b-a4c0-84b903e89bed.png" width="678" height="351"/></div>
<p>The same procedure is repeated for our wildfire data. Using large values for the <kbd>figsize</kbd> option gives a large map showing the location of the wildfires:</p>
<pre>In: fires =                                                                     <br/>    geopandas.read_file(r"C:\data\mtbs_fod_pts_data\mtbs_fod_pts_201705        <br/>    01.shp") <br/>    fires<br/>In: fires.plot(markersize=1, figsize=(17,17))</pre>
<p>The map looks something like this:</p>
<div><img src="img/0ef12ff6-c9ae-46ad-adb1-ffba9bff5878.png" style="width:43.58em;height:23.33em;" width="931" height="497"/></div>
<p>Have a look at the column called MTBS Zone in the <kbd>fires</kbd> <kbd>GeoDataFrame</kbd>, and verify that this dataset does not include all of the state names to reference the data. However, we have a geometry column that we can use to join both of the datasets. Before we can do this, we have to make sure that the data uses the same map projection. We can verify this as follows:</p>
<pre>In:    fires.crs<br/>Out:   {'init': 'epsg:4269'}<br/><br/>In:    states.crs<br/>Out:   {'init': 'epsg:4326'}</pre>
<p>There are two map projections, but both need to have the same CRS in order to line up correctly. We can reproject the <kbd>fires</kbd> shapefile to WGS84 as follows:</p>
<pre>In: fires = fires.to_crs({'init': 'epsg:4326'})</pre>
<p>Now, we're ready to perform a spatial join, using the <kbd>sjoin</kbd> method, indicating we want to know if the <kbd>fires</kbd> geometries are within the state geometries:</p>
<pre>In: state_fires =                                                    <br/>   geopandas.sjoin(fires,states[['name','geometry']].copy(),op='within'    )<br/>    state_fires</pre>
<p>The new <kbd>state_fires</kbd> <kbd>GeoDataFrame</kbd> has a column added to the outer right called name, showing the state where each fire is located:</p>
<div><img src="img/44eddb95-7f43-4511-bb9a-4060333fe9e3.png" style="width:25.75em;height:22.92em;" width="358" height="318"/></div>
<p>We can now count the total amount of wildfires per state. The result is a <kbd>pandas</kbd> series object showing the state name and total count. To start with the highest counts, we'll use the <kbd>sort_values</kbd> method:</p>
<pre>In:   counts_per_state = state_fires.groupby('name').size()<br/>      counts_per_state.sort_values(axis=0, ascending=False)</pre>
<p><kbd>Florida</kbd>, <kbd>California</kbd>, and <kbd>Idaho</kbd> are the three states with the most wildfires during 1984-2015, according to our data:</p>
<div><img src="img/85151228-aa11-41f2-b580-a5acf8b4f2b0.png" style="width:21.17em;height:11.00em;" width="271" height="141"/></div>
<p>These values can be fed into the original shapefile as a new field, showing total wildfire count per state:</p>
<pre>In: states =        <br/>    states.merge(counts_per_state.reset_index(name='number_of_fires'))<br/>    states.head()</pre>
<p>The <kbd>head</kbd> method prints the first five entries in the <kbd>states</kbd> shapefile, with a new field added to the right end of the table. Finally, a choropleth map for wildfire count per state can be created and plotted as follows:</p>
<pre>In: ax = states.plot(column='number_of_fires', figsize=(15, 6),                       <br/>    cmap='OrRd', legend=True)</pre>
<p>The output will look something like this:</p>
<div><img src="img/89b121e1-d8ce-40b8-a6f6-d099b4af28b3.png" width="786" height="369"/></div>
<p>Compare this to another color scheme applied to the same results, doing away with the light colors for the lower values:</p>
<pre>In: ax = states.plot(column='number_of_fires', figsize=(15, 6),<br/>    cmap='Accent', legend=True)</pre>
<p>Here is what the map looks like:</p>
<div><img src="img/cfe4449d-6928-4c49-b997-a88001460399.png" width="798" height="376"/></div>
<p>Use the following code to fine-tune the map a little further, by adding a title and dropping the <em>x</em>-axis and <em>y</em>-axis:</p>
<pre>In: import matplotlib.pyplot as plt<br/>    f, ax = plt.subplots(1, figsize=(18,6))<br/>    ax = states.plot(column='number_of_fires', cmap='Accent',                 <br/>    legend=True, ax=ax)<br/>    lims = plt.axis('equal')<br/>    f.suptitle('US Wildfire count per state in 1984-2015')                     <br/>    ax.set_axis_off()<br/>    plt.show()</pre>
<p>The output is as follows:</p>
<div><img src="img/aaff1d5b-9846-4f61-b356-e29fbbf393bd.png" width="936" height="400"/></div>


            

            
        
    </div>



  
<div><h1 class="header-title">Why data inspection matters</h1>
                
            
            
                
<p>When you're preparing your data, it's good to know the data you're dealing with. For example, listing statistics about your dataset that show you how many elements there are, and if there are any missing values. It's common that data has to be cleaned up before doing the analysis. Because the GeoPandas data objects are subclasses of <kbd>pandas</kbd> data objects, you can use their methods to do data inspection and cleaning. Take, for instance, the wildfire data shapefile we used earlier. By listing our dataframe object, it not only prints all of the attribute data, but also lists the total rows and columns, which is 20340 rows and 30 columns. The total amount of rows can also be printed this way:</p>
<pre>In:        len(fires.index)<br/><br/>Out:       20340</pre>
<p>This means there are <kbd>20340</kbd> individual wildfire cases in our input dataset. Now, compare this row value to the sum of the counts per state, after we've performed the spatial join:</p>
<pre>In:        counts_per_state.sum()<br/><br/>Out:       20266</pre>
<p>We notice that there are 74 less wildfires in our dataset after our spatial join. While at this point it's not clear what went wrong with our spatial join and why there are missing values, it's possible and recommended to check datasets before and after performing geometric operations, for example, checking for empty fields, non-values, or simply null-values:</p>
<pre>In:        fires.empty   #checks if there are empty fields in the                             <br/>                         dataframe<br/><br/>Out:       False</pre>
<p>The same operation can also be done by specifying a column name:</p>
<pre>In:        fires['geometry'].empty<br/><br/>Out:       False</pre>
<p>Be aware of the fact that GeoPandas geometry columns use a combination of text and values, so checking for NaN or zero values doesn't make any sense.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Summary</h1>
                
            
            
                
<p>This chapter covered three Python libraries for working with vector data—OGR, Shapely, and GeoPandas. In particular, we showed how to use all three for doing geospatial analysis and processing. Each library was covered separately, with their classes, methods, data structures and popular use cases. Short example scripts showed how to get started doing data processing and analysis. Taken as a whole, the reader now knows how to use each library separately, as well as how to combine all three for doing the following tasks:</p>
<ul>
<li>Reading and writing vector data</li>
<li>Creating and manipulating vector data</li>
<li>Plotting vector data</li>
<li>Working with map projections</li>
<li>Performing spatial operations</li>
<li>Working with vector geometries and attribute data in tabular form</li>
<li>Presenting and analyzing the data to answer questions with a spatial component</li>
</ul>
<p>The next chapter discusses raster data processing and how to use the GDAL and Rasterio libraries. Using these libraries, the reader will learn how to perform raster-based geospatial search and analysis, and how to use geolocated text and images.</p>


            

            
        
    </div>



  </body></html>