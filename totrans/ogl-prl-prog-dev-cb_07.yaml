- en: Chapter 7. Developing the Matrix Multiplication with OpenCL
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第7章. 使用OpenCL开发矩阵乘法
- en: 'In this chapter, we will cover the following recipes:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下内容：
- en: Understanding matrix multiplication
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解矩阵乘法
- en: OpenCL implementation of the matrix multiplication
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 矩阵乘法的OpenCL实现
- en: Faster OpenCL implementation of the matrix multiplication by thread coarsening
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过线程粗化加速矩阵乘法的OpenCL实现
- en: Faster OpenCL implementation of the matrix multiplication through register tiling
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过寄存器细分加速矩阵乘法的OpenCL实现
- en: Reducing global memory via shared memory data prefetching in matrix multiplication
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过矩阵乘法中的共享内存数据预取减少全局内存
- en: Introduction
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简介
- en: 'In this chapter, we are going to take a look at the problem of multiplying
    two matrices to produce another matrix. This problem is also known as the matrix
    multiplication and its applications range from mathematics, finance, physics,
    and it is a popular system for solving linear equations. For illustration purposes,
    we present a typical use case for solving linear equations:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨两个矩阵相乘以产生另一个矩阵的问题。这个问题也被称为矩阵乘法，其应用范围包括数学、金融、物理，并且是解决线性方程的流行系统。为了说明目的，我们提供了一个解决线性方程的典型用例：
- en: '![Introduction](img/4520OT_07_01.jpg)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![介绍](img/4520OT_07_01.jpg)'
- en: These equations can be modeled as ![Introduction](img/4520OT_07_02.jpg), where
    the L.H.S of the equation consists of a 2 x 2 matrix which is multiplied by a
    2 x 1 matrix (often called a vector, and they can be row vectors or column vectors)
    which is equal to the vector on the R.H.S. Considering the fact that matrices
    can have any order of rows and columns, mathematicians invented the notation,
    ![Introduction](img/4520OT_07_03.jpg) where to solve this, we have to determine
    ![Introduction](img/4520OT_07_04.jpg).Here, as we can see that the inverse of
    the matrix needs to be known. At this point, that's all we like to say about the
    wonderful world of matrices, lest we fall into the rabbit hole!
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这些方程可以建模为![介绍](img/4520OT_07_02.jpg)，其中方程的左侧由一个2x2的矩阵组成，该矩阵乘以一个2x1的矩阵（通常称为向量，它们可以是行向量或列向量），等于右侧的向量。考虑到矩阵可以具有任意行和列的顺序，数学家发明了如下表示法，![介绍](img/4520OT_07_03.jpg)，为了解这个问题，我们必须确定![介绍](img/4520OT_07_04.jpg)。在这里，正如我们所看到的，需要知道矩阵的逆。到此为止，这就是我们关于矩阵美妙世界的所有想说的，以免我们陷入兔子洞！
- en: Note
  id: totrans-11
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: You should be aware that only square matrices have inverses, and even among
    such matrices the inverses are not guaranteed to be present. We won't be covering
    computing inverses in this chapter or book.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该知道，只有方阵才有逆，即使在这样的矩阵中，逆也不一定存在。我们不会在本章或本书中介绍计算逆。
- en: Understanding matrix multiplication
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解矩阵乘法
- en: 'The product C of two matrices A and B is defined as ![Understanding matrix
    multiplication](img/4520OT_07_05.jpg), where j is the sum of all possible values
    of i and k. There is an implied summation over the indices i, j, and k. The dimensions
    of the matrix C is: ![Understanding matrix multiplication](img/4520OT_07_06.jpg),
    where ![Understanding matrix multiplication](img/4520OT_07_07.jpg) denotes a matrix
    with ![Understanding matrix multiplication](img/4520OT_07_08.jpg) rows and ![Understanding
    matrix multiplication](img/4520OT_07_09.jpg) columns and when we write out the
    product explicitly, it looks as follows:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 两个矩阵A和B的乘积C定义为![理解矩阵乘法](img/4520OT_07_05.jpg)，其中j是所有可能的i和k值的和。这里隐含地对索引i、j和k进行了求和。矩阵C的维度为：![理解矩阵乘法](img/4520OT_07_06.jpg)，其中![理解矩阵乘法](img/4520OT_07_07.jpg)表示一个有![理解矩阵乘法](img/4520OT_07_08.jpg)行和![理解矩阵乘法](img/4520OT_07_09.jpg)列的矩阵，当我们明确写出乘积时，它看起来如下：
- en: '![Understanding matrix multiplication](img/4520OT_07_10.jpg)![Understanding
    matrix multiplication](img/4520OT_07_11.jpg)![Understanding matrix multiplication](img/4520OT_07_12.jpg)![Understanding
    matrix multiplication](img/4520OT_07_13.jpg)![Understanding matrix multiplication](img/4520OT_07_14.jpg)![Understanding
    matrix multiplication](img/4520OT_07_15.jpg)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![理解矩阵乘法](img/4520OT_07_10.jpg)![理解矩阵乘法](img/4520OT_07_11.jpg)![理解矩阵乘法](img/4520OT_07_12.jpg)![理解矩阵乘法](img/4520OT_07_13.jpg)![理解矩阵乘法](img/4520OT_07_14.jpg)![理解矩阵乘法](img/4520OT_07_15.jpg)'
- en: Another property of matrix multiplication is that multiplication is associative
    and distributive over addition, but they are however not commutative.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵乘法的另一个特性是乘法在加法上是结合的，并且对加法是分配的，但它们却不是交换的。
- en: Note
  id: totrans-17
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Two matrices A and B are considered commutative if they are diagonal matrices
    and are of the same dimension.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 如果两个矩阵 A 和 B 是对角矩阵并且维度相同，则认为它们是交换的。
- en: 'Knowing these properties will help us in formulating our initial algorithm
    stemming from this formula: *c[ik]* = *a[ij]**b[jk]*. The commutative property
    basically informs us that the order of multiplication between matrices A and B
    matters, while the associative property allows us the flexibility to explore what
    happens when two matrices A and B are too huge to fit into available memory on
    the OpenCL device and we need to partition the matrix data across multiple devices.
    The following diagram illustrates what happens when a row of matrix A and a column
    of matrix B is read and its aggregated result is written into the appropriate
    location in the output matrix, C:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 了解这些属性将帮助我们制定从以下公式开始的初始算法：*c[ik]* = *a[ij]*b[jk]*。交换律基本上告诉我们矩阵 A 和 B 之间乘法的顺序很重要，而结合律允许我们探索当两个矩阵
    A 和 B 太大而无法适合 OpenCL 设备上的可用内存，并且我们需要将矩阵数据分配到多个设备时会发生什么。以下图表说明了当读取矩阵 A 的行和矩阵 B
    的列并将其聚合结果写入输出矩阵 C 的适当位置时会发生什么：
- en: '![Understanding matrix multiplication](img/4520OT_07_17.jpg)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![理解矩阵乘法](img/4520OT_07_17.jpg)'
- en: Getting ready
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: At this point, we are in pretty good shape to take a stab at matrix multiplication.
    As before, we begin with an implementation in C/C++, which is a direct translation
    of the formula and from there we will develop a better intuition on how to import
    it to OpenCL and apply suitable optimizations.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经有很好的基础来尝试矩阵乘法。像以前一样，我们从 C/C++ 的实现开始，这是公式的直接翻译，然后我们将发展更好的直觉，了解如何将其导入
    OpenCL 并应用适当的优化。
- en: For the rest of this chapter, we are going to craft our algorithm so that it
    runs on the GPU on your desktop/laptop. The reason for this is because the GPU
    has more computation units than a CPU, and GPUs are often equipped with other
    hardware components that allows the OpenCL to take advantage of that hardware
    (including local data stores, out of order execution units, shared data store,
    and so on), which often allows an enormous number of threads to execute in. Current
    CPU processors don't implement OpenCL shared memory, so using GPUs is probably
    the best option!
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的剩余部分，我们将构建我们的算法，使其在您的桌面/笔记本电脑上的 GPU 上运行。这样做的原因是因为 GPU 拥有比 CPU 更多的计算单元，并且
    GPU 通常配备有其他硬件组件，这允许 OpenCL 利用这些硬件（包括本地数据存储、乱序执行单元、共享数据存储等），这通常允许执行大量的线程。当前的 CPU
    处理器不实现 OpenCL 共享内存，因此使用 GPU 可能是最佳选择！
- en: Tip
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: Get a GPU that supports OpenCL 1.1 and the preceding information is good enough
    for these experiments.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 获取一个支持 OpenCL 1.1 的 GPU，上述信息足以进行这些实验。
- en: How to do it...
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: By now, you should be familiar with creating the necessary data structures to
    represent our three matrices in question (let's call them A, B, and C). Coincidentally,
    they happen to be square matrices, but this does not affect our understanding
    in any way.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 到现在为止，您应该熟悉创建必要的数据结构来表示我们正在讨论的三个矩阵（让我们称它们为 A、B 和 C）。巧合的是，它们恰好是方阵，但这以任何方式都不会影响我们的理解。
- en: 'When we examine this problem from the previous section, we understand that
    we want to basically iterate through both matrices in the following fashion:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们从上一节检查这个问题时，我们理解我们基本上想要以下方式遍历两个矩阵：
- en: Pick a row from matrix A.
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从矩阵 A 中选择一行。
- en: Pick a column from matrix B.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从矩阵 B 中选择一列。
- en: Multiply each element from the picked row with the corresponding element from
    the picked column.
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将所选行的每个元素与所选列的对应元素相乘。
- en: 'From this description, we can begin to think of various implementation methods
    and one such method could be as follows:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个描述中，我们可以开始考虑各种实现方法，其中一种方法可能是以下：
- en: Create two in-memory data structures for A and B, say `TmpA` and `TmpB`.
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为 A 和 B 创建两个内存中的数据结构，例如 `TmpA` 和 `TmpB`。
- en: 'Loop through A and pick a row for which each element to deposit into its corresponding
    position in `TmpA`, do the same for a picked column and deposit into `TmpB`:'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 遍历 A 并选择一个行，将其每个元素存入 `TmpA` 的对应位置，对所选列做同样的操作，存入 `TmpB`：
- en: '[PRE0]'
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Loop through `TmpA` and `TmpB` and perform the matrix multiplication.
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 遍历 `TmpA` 和 `TmpB` 并执行矩阵乘法。
- en: 'In pseudo code, it looks something like this:'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在伪代码中，它看起来像这样：
- en: '[PRE1]'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Another implementation is very similar to this one with the exception that we
    use standard C/C++ array indexing techniques to reference the respective row(s)
    and column(s) and we present an implementation in the following sections.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种实现方式与这一种非常相似，只是我们使用标准的 C/C++ 数组索引技术来引用相应的行和列，并在以下章节中展示实现方式。
- en: How it works…
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: There are various ways of implementing matrix multiplication algorithm in C/C++
    as we've discussed previously. And it seems that there isn't a best design to
    adopt. Personally, I've always favored a readable design versus a convoluted design.
    However, it's necessary to write high performance code from time to time, so that
    you can squeeze all the power that the programming language or hardware can provide.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前讨论的那样，在 C/C++ 中实现矩阵乘法算法有多种方式。似乎没有一种最佳的设计方案。我个人一直更喜欢可读的设计而不是复杂的设计。然而，有时有必要编写高性能的代码，以便你可以榨取编程语言或硬件所能提供的全部力量。
- en: Tip
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: At this point, you may or may not have developed the necessary intuition to
    design your algorithms, but one way is to continuously practice using different
    techniques and measure each implementation with some benchmarks, and never clump
    all the optimizations in one algorithm unless you're confident.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你可能已经或还没有发展出设计算法所必需的直觉，但一种方法是持续不断地练习使用不同的技术，并使用一些基准测试来衡量每个实现，除非你非常有信心，否则不要将所有优化都集中在一种算法上。
- en: 'Now that we have some inkling as to what is meant by matrix multiplication,
    it is definitely time for us to start exploring what the algorithm looks like
    after being translated into its sequential form. The following is an example of
    the matrix multiplication program in sequential form (the code is executed by
    only one thread):'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经对矩阵乘法的含义有了初步的了解，那么我们现在开始探索算法被转换为顺序形式后的样子是时候了。以下是一个矩阵乘法程序顺序形式的示例（代码仅由一个线程执行）：
- en: '[PRE2]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: When you examine this code, you will notice that there are three loop structures
    and we use regular C/C++ array indexing techniques to reference each subsequent
    element from their respective rows and columns. Take some time now to convince
    that we are actually computing the matrix multiplication.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 当你检查这段代码时，你会注意到有三个循环结构，我们使用常规的 C/C++ 数组索引技术来引用从各自的行和列中引用的后续元素。现在花点时间来确信我们实际上是在计算矩阵乘法。
- en: As before, we put on our parallel developer hat and try to see how we can provide
    a parallel OpenCL form of the equivalent program. Again, I'm naturally drawn to
    the loop structures and we have three of them!
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们戴上并行开发者的帽子，试图看看我们如何提供等效程序的并行 OpenCL 版本。再次，我自然地被循环结构所吸引，我们这里有三个循环结构！
- en: We noticed that as we iterate through the matrices A and B, the innermost loop
    is the code block that is performing all the heavy lifting for `statement 1`,
    `statement 2`, and `statement 3`. These statements will represent the core of
    our OpenCL kernel and let's go and take a look at how we can map it to OpenCL.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们注意到，当我们遍历矩阵 A 和 B 时，最内层的循环是执行所有重负载的代码块，包括“语句 1”、“语句 2”和“语句 3”。这些语句将代表我们 OpenCL
    内核的核心，让我们去看看我们如何将其映射到 OpenCL。
- en: OpenCL implementation of the matrix multiplication
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 矩阵乘法的 OpenCL 实现
- en: We have spent a good amount of time understanding how matrix multiplication
    works and we've looked at how it looks in its sequential form. Now we're going
    to attempt to map this to OpenCL in the most direct way.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经花费了大量时间来理解矩阵乘法的工作原理，并研究了它在顺序形式下的样子。现在，我们将尝试以最直接的方式将其映射到 OpenCL。
- en: The implementation technique here makes use of the fact that we create 2D thread
    blocks where each thread/work item in each dimension will access their respective
    elements in the row/column dimension.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这里使用的实现技术利用了这样一个事实：我们创建了二维线程块，其中每个维度中的每个线程/工作项都将访问它们在行/列维度中的相应元素。
- en: Getting ready
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备中
- en: In this recipe, we are going to use two matrices of dimensions 1024 x 1024 (we
    call A and B), and we'll multiply these two matrices together to produce a third
    matrix of 1024 x 1024, we call C.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将使用两个维度为 1024 x 1024 的矩阵（我们称之为 A 和 B），并将这两个矩阵相乘，以产生一个 1024 x 1024 的第三个矩阵，我们称之为
    C。
- en: Note
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: You may wish to refresh your basic matrix theory at this point to convince yourself
    that this is the case.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，你可能需要刷新一下你的基本矩阵理论，以确信这是正确的。
- en: 'We construct the familiar data structures in our host code and fill them with
    random values. The host code in `Ch7/matrix_multiplication_01/MatrixMultiplication.c`
    looks as follows:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在主机代码中构建熟悉的数据结构，并用随机值填充它们。`Ch7/matrix_multiplication_01/MatrixMultiplication.c`
    中的主机代码如下：
- en: '[PRE3]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Next, we set up the OpenCL command queue to enable profiling because we want
    to keep looking at the effects of the subsequent optimizations that we are going
    to apply. It's definitely very important to establish a reference point to which
    your measurements can be compared against.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们设置 OpenCL 命令队列以启用分析，因为我们想继续观察我们将要应用的后续优化的效果。确实，建立一个参考点是至关重要的，这样你的测量结果就可以与之比较。
- en: Note
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Recall that OpenCL command queues can be created such that commands are executed
    out-of-order. In this book, all command queues are created in-order so that they
    execute in program order also known as program reading order.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，OpenCL 命令队列可以被创建为按顺序执行命令。在这本书中，所有命令队列都是按顺序创建的，以便它们按程序顺序执行，也称为程序读取顺序。
- en: How to do it…
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到这一点…
- en: 'We present our first attempt to provide you an OpenCL version of the sequential
    matrix multiplication algorithm. The kernel can be found in `Ch7/matrix_multiplication_01/simple_mm_mult.cl`:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们展示了我们的第一次尝试，为你提供一个顺序矩阵乘法算法的 OpenCL 版本。内核可以在 `Ch7/matrix_multiplication_01/simple_mm_mult.cl`
    中找到：
- en: '[PRE4]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Given the preceding OpenCL kernel code, we need to build an executable so that
    it can execute on your platform. As before, the compilation will look familiar
    to you. On my setup with an Intel Core i7 CPU & AMD HD6870x2 GPU running Ubuntu
    12.04 LTS, the compilation looks like this and it''ll create an executable called
    `MatrixMultiplication` into the directory:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 给定前面的 OpenCL 内核代码，我们需要构建一个可执行文件，以便它可以在你的平台上执行。和之前一样，编译过程对你来说应该是熟悉的。在我的配置中，使用
    Intel Core i7 CPU 和 AMD HD6870x2 GPU 运行 Ubuntu 12.04 LTS，编译过程如下，并且它会在目录中创建一个名为
    `MatrixMultiplication` 的可执行文件：
- en: '[PRE5]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'At this point, you should have an executable deposited in that directory and
    all you need to do now is to run the program, simply execute the `MatrixMultiplication`
    program in the directory and you should have noticed an output as follows:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你应该在那个目录中有一个可执行文件，你现在需要做的就是运行程序，只需在目录中简单地执行 `MatrixMultiplication` 程序，你应该已经注意到以下输出：
- en: '[PRE6]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: How it works…
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: 'We discussed how the matrices were initialized and the next thing is to realize
    the execution model where each work item in each dimension would work on each
    element. And to accomplish this, we have to ensure that the invocation to execute
    the OpenCL kernel code doesn''t dictate the size of the thread block:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们讨论了矩阵的初始化方式，接下来要实现的是每个维度中每个工作项对每个元素进行工作的执行模型。为了完成这个任务，我们必须确保执行 OpenCL 内核代码的调用不指定线程块的大小：
- en: '[PRE7]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We achieve this by passing in the `NULL` value to the placeholder meant for
    dictating work group size in the `clEnqueueNDRangeKernel` API. Next, we set the
    values of the global work items to be equivalent to that of width of matrix B
    and height of A represented by the `widthB` and `heightA` variables respectively.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过将 `NULL` 值传递给 `clEnqueueNDRangeKernel` API 中用于指定工作组大小的占位符来实现这一点。接下来，我们将全局工作项的值设置为矩阵
    B 的宽度和矩阵 A 的高度，分别由 `widthB` 和 `heightA` 变量表示。
- en: 'The following diagram serves to illustrate what the execution would have looked
    like:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表用于说明执行将看起来是什么样子：
- en: '![How it works…](img/4520OT_07_19.jpg)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![它是如何工作的…](img/4520OT_07_19.jpg)'
- en: An astute reader would probably start guessing that this isn't the best way
    to conduct this business and you're right! We are going to take a deeper look
    at how we can make this work better soon.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 一个敏锐的读者可能会开始猜测这不是进行这项业务的最佳方式，你是对的！我们很快将深入探讨如何使这项工作做得更好。
- en: Faster OpenCL implementation of the matrix multiplication by thread coarsening
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过线程粗化加速矩阵乘法的 OpenCL 实现
- en: 'In this section, let''s try to make this beast run faster by applying a technique
    in parallel programming: thread coarsening. This is important because when you
    have a work item accessing an element, and then you have large matrices you could
    potentially have millions of work items running! In general, that''s not a good
    thing because many devices today cannot support millions of work items in *n*
    dimensions unless it''s a supercomputer. But there are often clever ways to reduce
    the amount of work items needed.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，让我们尝试通过应用并行编程中的技术：线程粗化，来让这个“野兽”运行得更快。这很重要，因为当你有一个工作项访问一个元素，然后你有大矩阵时，你可能会拥有数百万个工作项在运行！一般来说，这不是一个好现象，因为今天许多设备都无法支持在
    *n* 维度上数百万个工作项，除非它是超级计算机。但通常有巧妙的方法来减少所需的工作项数量。
- en: Getting ready
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: The general technique here is to explore ways in which we can merge threads
    so that each thread now calculates multiple elements. When we reexamine the preceding
    code, we might wonder if we could do with fewer threads and have them compute
    more elements, and indeed we can.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的通用技术是探索我们可以合并线程的方法，以便每个线程现在计算多个元素。当我们重新审视前面的代码时，我们可能会想知道我们是否可以用更少的线程并让它们计算更多的元素，实际上我们可以。
- en: The strategy we have adopted will basically have one work item updating an entire
    row in the matrix C while walking through matrices A and B. At this time, we need
    not even explore the use of atomic functions in OpenCL, since that's an aspect
    we should try to delay exploring as long as possible. The main reason for not
    exploring the use of atomics is simply because their execution time is too long
    and it isn't mature of utilizing the capabilities of the OpenCL devices.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们采用的战略基本上将有一个工作项在遍历矩阵 A 和 B 的同时更新矩阵 C 中的整个行。此时，我们甚至不需要探索在 OpenCL 中使用原子函数，因为这是我们应尽可能延迟探索的方面。不探索使用原子的主要原因很简单，就是它们的执行时间太长，而且还没有充分利用
    OpenCL 设备的能力。
- en: How to do it...
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到这一点…
- en: 'This OpenCL kernel is revised based on the concept of thread coarsening and
    can be found in `Ch7/matrix_multiplication_02/mmult.cl`:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 这个 OpenCL 内核是基于线程粗化的概念修订的，可以在 `Ch7/matrix_multiplication_02/mmult.cl` 中找到：
- en: '[PRE8]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Now that we have taken a good look at the OpenCL kernel, we need to build an
    executable form. As before, the compilation will look familiar to you. On my setup
    with an Intel Core i7 CPU & AMD HD6870x2 GPU running Ubuntu 12.04 LTS the compilation
    looks as follows, and it''ll create an executable called `MatrixMultiplication`
    into the directory:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经仔细查看过 OpenCL 内核，我们需要构建一个可执行形式。和之前一样，编译过程对你来说应该很熟悉。在我的配置中，有一个 Intel Core
    i7 CPU 和 AMD HD6870x2 GPU 运行 Ubuntu 12.04 LTS，编译过程如下，它会在目录中创建一个名为 `MatrixMultiplication`
    的可执行文件：
- en: '[PRE9]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'At this point, an executable should have been deposited in the directory and
    to execute it, simply execute the program `MatrixMultiplication` in the directory
    and you should have noticed an output as follows:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，可执行文件应该已经存放在目录中，要执行它，只需在目录中运行程序 `MatrixMultiplication` 即可，你应该已经注意到以下输出：
- en: '[PRE10]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Now if you were to compare the results with the previous one you would notice
    that it is running faster!
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 现在如果你要比较之前的结果，你会注意到它运行得更快！
- en: How it works…
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: The hard part of this is being able to recognize when redundant work is being
    applied. But in our case, it won't take too much effort to recognize that we are
    actually using too many threads. How so you may ask? The clue lies in the fact
    that the original matrix multiplication algorithm ran with one executing thread,
    so the fact that we are using more than one work item does imply that there's
    more we can do to improve it.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的难点在于能够识别出正在应用冗余工作。但在我们的情况下，识别出我们实际上使用了过多的线程并不会花费太多精力。你可能会问，为什么会这样？线索在于原始的矩阵乘法算法是使用一个执行线程运行的，所以我们使用多个工作项的事实确实意味着我们还可以做更多来改进它。
- en: Hence when we look back at the algorithm, we discover a way to make them run
    faster by getting more creative in the way we obtain those values using one work
    item. At this point, you should convince yourself that the OpenCL kernel we just
    looked at is indeed referencing the data values from the matrices A and B as expected.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，当我们回顾算法时，我们发现了一种通过更富有创意地使用一个工作项获取这些值来使它们运行更快的方法。在这个时候，你应该确信我们刚才查看的 OpenCL
    内核确实如预期那样引用了矩阵 A 和 B 中的数据值。
- en: 'To achieve what we did, we made some changes to the code in `Ch7/matrix_multiplication_02/MatrixMultiplication.c`
    as follows:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现我们所做的，我们对 `Ch7/matrix_multiplication_02/MatrixMultiplication.c` 中的代码做了一些修改，如下所示：
- en: '[PRE11]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The problem size is known to us, which is to perform matrix multiplication
    for matrices of dimensions 1024 x 1024 and the reason why I chose the work group
    size to be 256 is because my GPU has four compute units and you can discover this
    by passing `CL_DEVICE_MAX_COMPUTE_UNITS` to `clGetDeviceInfo`. The following diagram
    illustrates what it is like with thread coarsening:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道问题的大小，即对1024 x 1024维度的矩阵进行矩阵乘法。我选择工作组大小为256的原因是因为我的GPU有四个计算单元，你可以通过传递`CL_DEVICE_MAX_COMPUTE_UNITS`到`clGetDeviceInfo`来发现这一点。以下图表说明了线程粗化后的情况：
- en: '![How it works…](img/4520OT_07_20.jpg)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![它如何工作…](img/4520OT_07_20.jpg)'
- en: When you are able to reduce redundant work through thread coarsening, the kernel
    would now execute faster and scale better because now more processors can execute.
    It may seem counter intuitive because it defies common sense, since more threads
    executing the kernel means that it should execute faster. Well, that's the simple
    picture.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 当你能够通过线程粗化减少冗余工作时，内核现在将执行得更快，并且扩展得更好，因为现在更多的处理器可以执行。这看起来可能有些反直觉，因为它违背了常识，因为执行内核的线程越多，它应该执行得越快。好吧，这就是简单的画面。
- en: What happens under the hood is more complicated and it starts from the fact
    that each GPU has a number of processors and each of those processors would execute
    the kernel. For a GPU to be able to execute at full capacity, naturally its processors
    must be filled with data in the data cache and instructions should be ready to
    be fired and execute the OpenCL kernel.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在底层发生的事情更为复杂，它始于这样一个事实：每个GPU都有一定数量的处理器，每个处理器都会执行内核。为了使GPU能够以全容量运行，自然其处理器必须填充数据缓存中的数据，指令应该准备好被触发并执行OpenCL内核。
- en: However due to poor data spatial and temporal locality, the data caches perform
    suboptimal and that causes stalls in the instruction pipeline, which translates
    to delayed execution. Another problem is also related to the fact that memory
    access patterns could be erratic or non-coalesced which translates to cache misses
    and possibly memory ejection. This finally causes more delays.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，由于数据空间和时间局部性较差，数据缓存的表现不佳，这导致指令流水线中的停滞，这转化为延迟执行。另一个问题也与内存访问模式可能是不规则或非归约的事实有关，这转化为缓存未命中和可能的内存驱逐。这最终导致更多的延迟。
- en: Coming back to the problem, there is another solution for optimizing the kernel
    and that's by reusing the hardware registers of the work items.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 回到问题本身，还有另一种优化内核的方法，那就是通过重用工作项的硬件寄存器。
- en: Faster OpenCL implementation of the matrix multiplication through register tiling
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过注册分块加快矩阵乘法的OpenCL实现
- en: Register tiling is another technique we can apply to our matrix multiplication
    algorithm. What it basically means is to explore opportunities to reuse the hardware
    registers. In our case, what it means is that we need to examine the kernel code
    and find opportunities to reuse registers.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 注册分块是我们可以对矩阵乘法算法应用的其他技术之一。它基本上意味着探索重用硬件寄存器的机会。在我们的情况下，这意味着我们需要检查内核代码并找到重用寄存器的机会。
- en: Now we need to put on our hardcore C developer hat (this person needs to think
    on the level of the processor core, how data moves on buses, memory loads and
    stores, and so on). And once your mind is sensitive enough to this level, then
    things become better.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们需要戴上我们硬核C开发者帽（这个人需要从处理器核心的层面思考，比如数据如何在总线上移动，内存的加载和存储等等）。一旦你的思维足够敏感到这个层面，事情就会变得更好。
- en: Recall the kernel code in the previous section and we would notice after careful
    scrutiny that the `A[i * heightA + k]` statement is always executed in the loop
    structure, and this causes a lot of memory traffic to transpire because data needs
    to be loaded from device memory into the registers of the device.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下上一节的内核代码，我们会注意到经过仔细审查后，`A[i * heightA + k]`语句总是在循环结构中执行，这导致大量的内存流量，因为数据需要从设备内存加载到设备寄存器中。
- en: Getting ready
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: To reduce the global memory traffic caused by the `A[i * heightA + k]` statement,
    we can pull that statement out of the loop structure and create a thread local
    memory structure that is visible only to the work item executing thread, and then
    we can reuse that prefetched data in the subsequent computations.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 为了减少由`A[i * heightA + k]`语句引起的全局内存流量，我们可以将这个语句从循环结构中提取出来，创建一个仅对执行线程可见的线程局部内存结构，然后我们可以在后续的计算中重用预取的数据。
- en: How to do it
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到这一点
- en: 'This OpenCL kernel code is found in `Ch7/matrix_multiplication_03/mmult.cl`:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 这个OpenCL内核代码位于`Ch7/matrix_multiplication_03/mmult.cl`：
- en: '[PRE12]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Now that we have taken a good look at the OpenCL kernel, we need to build an
    executable form, where we can execute. As before, the compilation will look familiar
    to you. On my setup with an Intel Core i7 CPU & AMD HD6870x2 GPU running Ubuntu
    12.04 LTS, the compilation looks like this and it''ll create an executable called
    `MatrixMultiplication` into the directory:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经仔细查看过OpenCL内核，我们需要构建一个可执行形式，以便我们可以执行。和之前一样，编译过程对你来说应该很熟悉。在我的配置中，使用Intel
    Core i7 CPU和AMD HD6870x2 GPU运行Ubuntu 12.04 LTS，编译过程如下，并且它会在目录中创建一个名为`MatrixMultiplication`的可执行文件：
- en: '[PRE13]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'At this point, the executable should be available to you in the directory.
    To run the program, simply execute the program in the `MatrixMultiplication` directory
    and you should notice an output as follows:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，可执行文件应该已经在你所在的目录中可用。要运行程序，只需在`MatrixMultiplication`目录中执行程序，你应该会看到以下输出：
- en: '[PRE14]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Now if you were to compare the results with the previous one you would notice
    that it is running faster.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 现在如果你将结果与之前的一个比较，你会注意到它运行得更快。
- en: How it works…
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: The idea originated from a technique found in high performance computing and
    some folks like to call it scalar replacement. This is the form we have applied
    in this section. Let's take some time to understand this with a simple algorithm.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 这个想法源自高性能计算中的一种技术，有些人喜欢称之为标量替换。这是我们在这个部分应用的形式。让我们花点时间通过一个简单的算法来理解这一点。
- en: 'Let''s say we have the following algorithm:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个以下算法：
- en: '[PRE15]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Now we unroll the loop so that it looks like this:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们展开循环，使其看起来像这样：
- en: '[PRE16]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'When we will carefully observe this code, we will notice that the `statement
    1`, `statement 2`, and `statement 3` have something in common and that is this
    code, `A[i1,i2]`. In computer science terms, we noticed that there is one store
    to memory and two loads from memory to registers. In scalar replacement, we replace
    `A[i1,i2]` with a variable, which we call `X` for now. The code now looks as follows
    after scalar replacement:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们仔细观察这段代码时，我们会注意到`statement 1`、`statement 2`和`statement 3`有一些共同点，那就是这段代码，`A[i1,i2]`。用计算机科学术语来说，我们注意到有一个存储到内存的操作和两个从内存到寄存器的加载操作。在标量替换中，我们将`A[i1,i2]`替换为一个变量，暂时称之为`X`。标量替换后，代码现在看起来如下：
- en: '[PRE17]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: When the replacements have been done consistently and the algorithm is still
    working as it should, we are good for now. Have a cup of tea!
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 当替换工作一致完成，并且算法仍然按预期工作，我们现在就可以了。喝杯茶吧！
- en: Let's have a look at what we did. We have replaced array references (which are
    in fact memory references) with scalars, and how it helps is that we have actually
    reduced memory traffic by processing those items in register memory. Considering
    that memory speed is significantly much slower than register read-write speed,
    this revised algorithm is in much better form.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们做了什么。我们将数组引用（实际上就是内存引用）替换为标量，这样做的好处是我们实际上通过在寄存器内存中处理这些项目来减少了内存流量。考虑到内存速度比寄存器读写速度慢得多，这个改进的算法形式要好得多。
- en: Tip
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: Loop unrolling is often used to explode the loop, so that we can identify expressions
    or statements that can possibly be repeating and allowing scalar replacement to
    extract those expressions/statements into thread private register memory.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 循环展开通常用于展开循环，以便我们可以识别可能重复的表达式或语句，并允许标量替换将这些表达式/语句提取到线程私有寄存器内存中。
- en: Scalar replacement is actually more complicated in actual practice, but the
    presentation here serves its purpose in illustrating the general concept.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 实际操作中，标量替换要复杂得多，但这里的演示旨在说明一般概念。
- en: Another thing we like to share with you is to optimize memory usage for the
    work items and we've caught several glimpses of it before in previous chapters.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还想与你分享的另一件事是优化工作项的内存使用，我们之前在章节中也提到了几个关于它的例子。
- en: Reducing global memory via shared memory data prefetching in matrix multiplication
  id: totrans-127
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过矩阵乘法中的共享内存数据预取减少全局内存
- en: Our revised matrix multiplication algorithm appears to be pretty good but it
    isn't quite there yet. The algorithm is still making a lot of references to matrix
    B over global memory and we can actually reduce this traffic by prefetching the
    data. You may not have noticed, but the concept of prefetching, which is to keep
    the cache "hot" (an idea borrowed from the CPU). A CPU typically has a good size
    of data and instruction caches (which are really hardware registers), so that
    the processor can take advantage of the spatial and temporal localities of the
    data. How does this concept map into other OpenCL devices, for example, the GPU?
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 我们改进的矩阵乘法算法看起来相当不错，但还不是完全如此。该算法仍然在全局内存中对矩阵B进行了大量引用，我们实际上可以通过预取数据来减少这种流量。你可能没有注意到，但预取的概念是为了保持缓存“热”（一个从CPU借来的想法）。CPU通常具有相当大的数据和指令缓存（实际上是非常大的硬件寄存器），这样处理器就可以利用数据的时空局部性。这个概念如何映射到其他OpenCL设备，例如GPU？
- en: Every GPU that is an OpenCL compliant has a small amount of memory designed
    for this purpose and their sizes typically are 32 KB to 64 KB. If you wish to
    determine the exact amount of available high speed memory, simply pass the `CL_DEVICE_LOCAL_MEM_SIZE`
    variable to `clGetDeviceInfo` for a device.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 每个符合OpenCL规范的GPU都有一小部分内存用于此目的，它们的尺寸通常是32 KB到64 KB。如果你想要确定可用的高速内存的确切数量，只需将`CL_DEVICE_LOCAL_MEM_SIZE`变量传递给`clGetDeviceInfo`即可获取设备信息。
- en: Getting ready
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'In order for us to be able to reduce references to global memory, we need to
    make changes in our code so that we load the data we need. Sieving through the
    code again, we see that there is indeed one such opportunity and it is the following
    statement:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让我们能够减少对全局内存的引用，我们需要对我们的代码进行修改，以便加载我们所需的数据。再次筛选代码后，我们发现确实有一个这样的机会，如下所示：
- en: '[PRE18]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Concentrating on this loop, we noticed that matrix B always gets loaded and
    its values are always reused by all work items executing this kernel. We could
    of course preload this data into shared memory. That should reduce global memory
    requests significantly.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 专注于这个循环，我们注意到矩阵B总是被加载，并且其值总是被执行此内核的所有工作项重用。我们当然可以将这些数据预加载到共享内存中。这应该会显著减少全局内存请求。
- en: How to do it...
  id: totrans-134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做…
- en: 'The following OpenCL kernel can be found in `Ch7/matrix_multiplicatione_04/mmult.cl`:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 以下OpenCL内核可以在`Ch7/matrix_multiplicatione_04/mmult.cl`中找到：
- en: '[PRE19]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Now that you have taken a look at the OpenCL kernel, you would want to compile
    the code and run it. As before the compilation will look familiar to you. On my
    setup with an Intel Core i7 CPU and AMD HD6870x2 GPU running Ubuntu 12.04 LTS,
    the compilation looks like this and it'll create an executable called `MatrixMultiplication`
    into the directory.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经查看过OpenCL内核，你可能会想编译代码并运行它。和之前一样，编译过程对你来说应该是熟悉的。在我的配置中，有一个Intel Core i7
    CPU和AMD HD6870x2 GPU，运行Ubuntu 12.04 LTS，编译过程如下，它会在目录中创建一个名为`MatrixMultiplication`的可执行文件。
- en: '[PRE20]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'To run the program, simply execute the `MatrixMultiplication` program in the
    directory and you should get an output that resembles this:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行程序，只需在目录中执行`MatrixMultiplication`程序，你应该会得到一个类似于以下输出的结果：
- en: '[PRE21]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Now if you were to compare the results with the previous one, you would notice
    that it is running much faster!
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 现在如果你要比较这个结果与之前的结果，你会注意到它运行得快得多！
- en: How it works…
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何工作…
- en: 'The code that we have introduced might cast some doubts within yourself that
    because it looks sequential, it is actually executed in parallel during runtime.
    The parallelism is introduced by the value indicated in the `localThreads` variable,
    which is passed to `clEnqueueNDRangeKernel`. The memory barrier we placed into
    the code serves to stop all work items from executing beyond that point, until
    all functions before that point have been executed and the following diagram serves
    to illustrate this:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们所介绍的代码可能会让你产生一些疑问，因为它看起来是顺序执行的，但实际上在运行时是并行执行的。并行性是通过`localThreads`变量中指示的值引入的，该值传递给`clEnqueueNDRangeKernel`。我们在代码中放置的内存屏障的作用是停止所有工作项执行超过该点，直到该点之前的所有函数都已执行，以下图表用于说明这一点：
- en: '![How it works…](img/4520OT_07_22.jpg)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![如何工作…](img/4520OT_07_22.jpg)'
- en: 'So far you have seen changes made to the OpenCL kernel code, and now we need
    to make changes to our host code so that we can actually accomplish this. The
    following code snippet is taken from `Ch7/matrix_multiplication_04/MatrixMultiplication.c`:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你已经看到了对OpenCL内核代码所做的更改，现在我们需要修改我们的主机代码，以便我们实际上能够完成这项工作。以下代码片段取自`Ch7/matrix_multiplication_04/MatrixMultiplication.c`：
- en: '[PRE22]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The schematics of the final algorithm have seen us tailoring the algorithm,
    so that it achieves an initial reasonable performance and can be conceptually
    represented by the following diagram:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 最终算法的框图让我们对算法进行了调整，使其达到一个初始的合理性能，并且可以用以下图表进行概念上的表示：
- en: '![How it works…](img/4520OT_07_24.jpg)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![如何工作…](img/4520OT_07_24.jpg)'
- en: Tip
  id: totrans-149
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: If you want to know how much shared memory you can possibly create and pass
    the `CL_DEVICE_LOCAL_MEM_SIZE` parameter to `clGetDeviceInfo` for your device
    and the value returned will be in bytes. Typical values are between 32 KB to 64
    KB.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想知道你可以创建多少共享内存，并将`CL_DEVICE_LOCAL_MEM_SIZE`参数传递给`clGetDeviceInfo`以获取你的设备，返回的值将以字节为单位。典型值在32
    KB到64 KB之间。
