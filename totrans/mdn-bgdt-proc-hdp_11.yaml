- en: Production Hadoop Cluster Deployment
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生产级 Hadoop 集群部署
- en: Hadoop itself started with a strong core and File System designed to handle
    the big data challenges. Later, many applications were developed on top of this,
    creating a big ecosystem of applications that play nicely with each other. As
    the number of applications started increasing, the challenges to create and manage
    the Hadoop environment increased as well.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: Hadoop 本身始于一个强大的核心和文件系统，旨在处理大数据挑战。后来，在之上开发了众多应用程序，形成了一个相互兼容的应用程序大生态系统。随着应用程序数量的增加，创建和管理
    Hadoop 环境的挑战也随之增加。
- en: 'In this chapter, we will look at the following:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨以下内容：
- en: Apache Ambari
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Apache Ambari
- en: A Hadoop cluster with Ambari
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 带有 Ambari 的 Hadoop 集群
- en: Apache Ambari architecture
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Apache Ambari 架构
- en: Apache Ambari follows a master/slave architecture where the master node instructs
    the slave nodes to perform certain actions and report back the state of every
    action. The master node is responsible for keeping track of the state of the infrastructure.
    In order to do this, the master node uses a database server, which can be configured
    during setup time.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Ambari 采用主/从架构，其中主节点指导从节点执行特定操作并报告每个操作的状态。主节点负责跟踪基础设施的状态。为了做到这一点，主节点使用数据库服务器，该服务器可以在设置时进行配置。
- en: 'In order to have a better understanding of how Ambari works, let''s take a
    look at the high level architecture of Ambari, in the following diagram:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解 Ambari 的工作原理，让我们看一下 Ambari 的高级架构，如下所示：
- en: '![](img/c9883b7a-2f6f-47b2-a18e-6e90f41f2f76.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/c9883b7a-2f6f-47b2-a18e-6e90f41f2f76.png)'
- en: 'At the core, we have the following applications:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在核心，我们有以下应用程序：
- en: Ambari server
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ambari 服务器
- en: Ambari agent
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ambari 代理
- en: Ambari web UI
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ambari 网页界面
- en: Database
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据库
- en: The Ambari server
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Ambari 服务器
- en: The Ambari server (`ambari-server`) is a shell script which is the entry point
    for all administrative activities on the master server. This script internally
    uses Python code, `ambari-server.py,` and routes all the requests to it.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: Ambari 服务器（`ambari-server`）是一个 shell 脚本，它是主服务器上所有管理活动的入口点。此脚本内部使用 Python 代码
    `ambari-server.py`，并将所有请求路由到它。
- en: 'The Ambari server has the following entry points which are available when passed
    different parameters to the `ambari-server` program:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: Ambari 服务器有以下入口点，当向 `ambari-server` 程序传递不同参数时可用：
- en: Daemon management
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 守护进程管理
- en: Software upgrade
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 软件升级
- en: Software setup
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 软件设置
- en: LDAP/PAM/Kerberos management
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LDAP/PAM/Kerberos 管理
- en: Ambari backup and restore
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ambari 备份和恢复
- en: Miscellaneous options
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其他选项
- en: Daemon management
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 守护进程管理
- en: The daemon management mode is activated when the script is invoked with `start`,
    `stop`, `reset`, `restart` arguments from the command line.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 当脚本通过命令行使用 `start`、`stop`、`reset`、`restart` 参数调用时，守护进程管理模式被激活。
- en: 'For example, if we want to start the Ambari background server, we can run the
    following command:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果我们想启动 Ambari 背景服务器，我们可以运行以下命令：
- en: '[PRE0]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Software upgrade
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 软件升级
- en: 'Once Ambari is installed, we can use this mode to upgrade the Ambari server
    itself. This is triggered when we call the `ambari-server` program with the `upgrade`
    flag. In case we want to upgrade the entire stack of Ambari, we can pass the `upgradestack`
    flag:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 安装 Ambari 后，我们可以使用此模式升级 Ambari 服务器本身。当我们使用 `upgrade` 标志调用 `ambari-server` 程序时，会触发此操作。如果我们想升级整个
    Ambari 堆栈，我们可以传递 `upgradestack` 标志：
- en: '[PRE1]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Software setup
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 软件设置
- en: 'Once Ambari is downloaded from the internet (or installed via YUM and APT),
    we need to do a preliminary setup of the software. This mode can be triggered
    when we pass the `setup` flag to the program. This mode will ask us several questions
    that we need to answer. Unless we finish this step, Ambari cannot be used for
    any kind of management of our servers:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦从互联网下载 Ambari（或通过 YUM 和 APT 安装），我们需要对软件进行初步设置。当我们向程序传递 `setup` 标志时，可以触发此模式。此模式将询问我们几个需要回答的问题。除非我们完成此步骤，否则
    Ambari 无法用于管理我们的服务器：
- en: '[PRE2]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: LDAP/PAM/Kerberos management
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LDAP/PAM/Kerberos 管理
- en: '**T**he **Lightweight Directory Access Protocol** (**LDAP**) is used for identity
    management in enterprises. In order to use LDAP-based authentication, we need
    to use the following flags: `setup-ldap` (for setting up `ldap` properties with
    `ambari`) and `sync-ldap` (to perform a synchronization of the data from the `ldap`
    server):'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**轻量级目录访问协议**（**LDAP**）在企业中用于身份管理。为了使用基于 LDAP 的身份验证，我们需要使用以下标志：`setup-ldap`（用于使用
    `ambari` 设置 `ldap` 属性）和 `sync-ldap`（用于从 `ldap` 服务器同步数据）：'
- en: '[PRE3]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '**Pluggable Authentication Module **(**PAM**) is at the core of the authentication
    and authorization in any UNIX or Linux operating systems. If we want to leverage
    the PAM-based access for Ambari then we need to run it with the `setup-pam` option.
    If we then want to move from LDAP to PAM-based authentication, we need to run
    it with `migrate-ldap-pam`:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**可插拔身份验证模块**（**PAM**）是任何 UNIX 或 Linux 操作系统身份验证和授权的核心。如果我们想利用基于 PAM 的访问权限为
    Ambari，我们需要使用 `setup-pam` 选项运行它。如果我们想从 LDAP 迁移到基于 PAM 的身份验证，我们需要使用 `migrate-ldap-pam`
    运行它：'
- en: '[PRE4]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '**Kerberos** is another advanced authentication and authorization mechanism
    which is very helpful in networked environments. This simplifies **Authenticity,
    Authorisation and Auditing** (**AAA**) on large-scale servers. If we want to use
    Kerberos for Ambari, we can use the `setup-kerberos` flag:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**Kerberos** 是另一种在网络环境中非常有用的高级身份验证和授权机制。这简化了在大型服务器上的**真实性、授权和审计**（**AAA**）。如果我们想为
    Ambari 使用 Kerberos，我们可以使用 `setup-kerberos` 标志：'
- en: '[PRE5]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Ambari backup and restore
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Ambari 备份和还原
- en: 'If we want to take a snapshot of the current installation of Ambari (excluding
    the database), we can enter this mode. This supports both backup and restore methods
    invoked via the `backup` and `restore` flags:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想要对当前安装的 Ambari（不包括数据库）进行快照，我们可以进入此模式。这支持通过 `backup` 和 `restore` 标志调用的备份和还原方法：
- en: '[PRE6]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Miscellaneous options
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 其他选项
- en: In addition to these options, there are other options that are available with
    the Ambari server program which you can invoke with the `-h` (help) flag.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这些选项之外，还有其他选项可以通过 Ambari 服务器程序调用，您可以使用 `-h`（帮助）标志调用这些选项。
- en: Ambari Agent
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Ambari 代理
- en: Ambari Agent is a program which runs on all the nodes that we want to be managed
    with Ambari. This program periodically heartbeats to the master node. Using this
    agent, `ambari-server` executes many of the tasks on the servers.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: Ambari 代理是一个程序，它运行在我们想要用 Ambari 管理的所有节点上。这个程序定期向主节点发送心跳。使用此代理，`ambari-server`
    在服务器上执行许多任务。
- en: Ambari web interface
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Ambari 网络界面
- en: This is one of the powerful features of the Ambari application. This web application
    is exposed by the Ambari server program that is running on the master host; we
    can access this application on port `8080` and it is protected by authentication.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这是 Ambari 应用程序的一个强大功能。这个网络应用程序由运行在主主机上的 Ambari 服务器程序暴露；我们可以在端口 `8080` 上访问此应用程序，并且它受到身份验证的保护。
- en: Once we log in to this web portal, we can control and view all aspects of our
    Hadoop clusters.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们登录到这个网络门户，我们就可以控制并查看我们 Hadoop 集群的各个方面。
- en: Database
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据库
- en: Ambari supports multiple RDBMS to keep track of the state of the entire Hadoop
    infrastructure. During the setup of the Ambari server for the first time, we can
    choose the database we want to use.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: Ambari 支持多个关系数据库管理系统（RDBMS），以跟踪整个 Hadoop 基础设施的状态。在第一次设置 Ambari 服务器时，我们可以选择我们想要使用的数据库。
- en: 'At the time of writing, Ambari supports the following databases:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，Ambari 支持以下数据库：
- en: PostgreSQL
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PostgreSQL
- en: Oracle
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Oracle
- en: MySQL or MariaDB
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MySQL 或 MariaDB
- en: Embedded PostgreSQL
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 嵌入式 PostgreSQL
- en: Microsoft SQL Server
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Microsoft SQL Server
- en: SQL Anywhere
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SQL Anywhere
- en: Berkeley DB
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Berkeley DB
- en: Setting up a Hadoop cluster with Ambari
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Ambari 设置 Hadoop 集群
- en: In this section, we will learn how to set up a brand new Hadoop cluster from
    scratch using Ambari. In order to do this, we are going to need four servers –
    one server for running the Ambari server and three other nodes for running the
    Hadoop components.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将学习如何使用 Ambari 从头开始设置全新的 Hadoop 集群。为了做到这一点，我们需要四台服务器——一台用于运行 Ambari 服务器，另外三台节点用于运行
    Hadoop 组件。
- en: Server configurations
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 服务器配置
- en: 'The following table displays the configurations of the servers we are using
    as part of this exercise:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 以下表格显示了我们在本次练习中使用的服务器的配置：
- en: '| **Server Type** | **Name** | **CPU** | **RAM** | **DISK** |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| **服务器类型** | **名称** | **CPU** | **RAM** | **磁盘** |'
- en: '| Ambari Server node | master | 1 | 3.7 GB | 100 GB |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| Ambari 服务器节点 | master | 1 | 3.7 GB | 100 GB |'
- en: '| Hadoop node 1 | node-1 | 2 | 13 GB | 250 GB |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| Hadoop 节点 1 | node-1 | 2 | 13 GB | 250 GB |'
- en: '| Hadoop node 2 | node-2 | 2 | 13 GB | 250 GB |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| Hadoop 节点 2 | node-2 | 2 | 13 GB | 250 GB |'
- en: '| Hadoop node 3 | node-3 | 2 | 13 GB | 250 GB |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| Hadoop 节点 3 | node-3 | 2 | 13 GB | 250 GB |'
- en: Since this is a sample setup, we are good with this configuration. For real-world
    scenarios, please choose the configuration according to your requirements.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这是一个示例设置，我们对此配置感到满意。对于现实世界的场景，请根据您的需求选择配置。
- en: Preparing the server
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备服务器
- en: This section and all further sections assume that you have a working internet
    connection on all the servers and are safely firewalled to prevent any intrusions.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 本节以及所有后续章节都假设您在所有服务器上都有正常工作的互联网连接，并且已经安全地设置了防火墙以防止任何入侵。
- en: All the servers are running the CentOS 7 operating system, as it's a system
    that uses RPM/YUM for package management. Don't get confused when you see `yum`
    in the following sections.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 所有服务器都运行 CentOS 7 操作系统，因为它是一个使用 RPM/YUM 进行软件包管理的系统。在以下部分看到 `yum` 时，不要感到困惑。
- en: 'Before we go ahead and start using the servers, we need to run basic utility
    programs which help us troubleshoot various issues with the servers. They are
    installed as part of the next command. Don''t worry if you are not sure what they
    are. Except for `mysql-connector-java` and `wget`, all other utilities are not
    mandatory:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始使用服务器之前，我们需要运行一些基本的实用程序，这些程序可以帮助我们解决服务器上的各种问题。它们是作为下一个命令的一部分安装的。如果你不确定它们是什么，不要担心。除了
    `mysql-connector-java` 和 `wget` 之外，所有其他实用程序都是非强制性的：
- en: '[PRE7]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Installing the Ambari server
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装 Ambari 服务器
- en: 'The first step in creating the Hadoop cluster is to get our Ambari server application
    up and running. So, log in to the master node with SSH and perform the following
    steps in order:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 创建 Hadoop 集群的第一个步骤是启动我们的 Ambari 服务器应用程序。因此，使用 SSH 登录到主节点，并按以下顺序执行以下步骤：
- en: 'Download the Ambari YUM repository for CentOS 7 with this command:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令下载适用于 CentOS 7 的 Ambari YUM 仓库：
- en: '[PRE8]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'After this step, we need to move the `ambari.repo` file to the `/etc/yum.repos.d`
    directory using this command:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在此步骤之后，我们需要使用以下命令将 `ambari.repo` 文件移动到 `/etc/yum.repos.d` 目录：
- en: '[PRE9]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The next step is to install the `ambari-server` package with the help of this
    command:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一个步骤是使用以下命令安装 `ambari-server` 软件包：
- en: '[PRE10]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We are going to use a MySQL server for our Ambari server. So, let''s install
    the required packages as well:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用 MySQL 服务器作为我们的 Ambari 服务器。因此，让我们安装所需的软件包：
- en: '[PRE11]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Let''s configure the MySQL server (or MariaDB) before we touch the Ambari setup
    process. This is done with the following commands:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在我们接触 Ambari 设置过程之前，让我们配置 MySQL 服务器（或 MariaDB）。这是通过以下命令完成的：
- en: '[PRE12]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Then, create a database called `ambari` and a user called `ambari` with the
    password, `ambari,` so that the Ambari server configuration is easy to set up
    in the following steps. This can be done with these SQL queries:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，创建一个名为 `ambari` 的数据库和一个名为 `ambari` 的用户，密码为 `ambari`，这样在以下步骤中设置 Ambari 服务器配置就会变得容易。可以使用以下
    SQL 查询完成此操作：
- en: '[PRE13]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Store these four lines into a text file called `ambari.sql` and execute with
    the following command:'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将这四行存储到一个名为 `ambari.sql` 的文本文件中，并使用以下命令执行：
- en: '[PRE14]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: This will create a database, users and give necessary privileges.
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这将创建一个数据库、用户并赋予必要的权限。
- en: Please use a strong password for production setup, otherwise your system will
    be vulnerable to any attacks.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 请在生产设置中使用强密码，否则您的系统将容易受到任何攻击。
- en: 'Now that we have done the groundwork, let''s run the Ambari server setup. Note
    that we are required to answer a few questions that are highlighted as follows:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经完成了准备工作，让我们运行 Ambari 服务器设置。请注意，我们需要回答一些突出显示的问题，如下所示：
- en: '[PRE15]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Once the setup is complete, we need to create the tables in the Ambari database
    by using the previous file that is generated during the setup process. This can
    be done with this command:'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦设置完成，我们需要使用设置过程中生成的上一个文件在 Ambari 数据库中创建表。可以使用以下命令完成此操作：
- en: '[PRE16]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The next step is for us to start the `ambari-server` daemon. This will start
    the web interface that we will use in the following steps to create the Hadoop
    cluster:'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一个步骤是启动 `ambari-server` 守护进程。这将启动我们将用于以下步骤创建 Hadoop 集群的 Web 界面：
- en: '[PRE17]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Once the server setup is complete, configure the JDBC driver (which is helpful
    for all the other nodes as well):'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 服务器设置完成后，配置 JDBC 驱动程序（这对其他所有节点也有帮助）：
- en: '[PRE18]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Preparing the Hadoop cluster
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备 Hadoop 集群
- en: There are a few more steps that we need to do before we go ahead and create
    the Hadoop cluster.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续创建 Hadoop 集群之前，我们还需要执行几个步骤。
- en: Since we have the Ambari server up and running, let's generate an RSA key pair
    that we can use for communication between the Ambari server and the Ambari agent
    nodes.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们已经启动并运行了 Ambari 服务器，让我们生成一个 RSA 密钥对，我们可以用它来在 Ambari 服务器和 Ambari 代理节点之间进行通信。
- en: This key pair lets the Ambari server node log in to all the Hadoop nodes and
    perform the installation in an automated way.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 这个密钥对允许 Ambari 服务器节点登录到所有 Hadoop 节点，并以自动化的方式执行安装。
- en: 'This step is optional if you have already done this as part of procuring the
    servers and infrastructure:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你已经作为获取服务器和基础设施的一部分完成了这一步，则此步骤是可选的：
- en: '[PRE19]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'This will generate two files inside the `/home/user/.ssh` directory:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 这将在`/home/user/.ssh`目录内生成两个文件：
- en: '`~/.ssh/id_rsa`: This is the private key file which has to be kept in a secret
    place'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`~/.ssh/id_rsa`：这是一个私钥文件，必须将其保存在一个秘密的地方'
- en: '`~/.ssh/id_rsa.pub`: This is the public key file which allows any SSH login
    using the private key file'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`~/.ssh/id_rsa.pub`：这是一个公钥文件，它允许使用私钥文件进行任何SSH登录'
- en: The contents of this `id_rsa.pub` file should be put in `~/.ssh/authorized_keys`
    on all the Hadoop nodes. In this case, they are node servers (1–3).
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 应将此`id_rsa.pub`文件的内容放入所有Hadoop节点上的`~/.ssh/authorized_keys`中。在这种情况下，它们是节点服务器（1–3）。
- en: This step of propagating all the public SSH keys can be done during the server
    provisioning itself, so a manual step is avoided every time we acquire new servers.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在服务器配置过程中就可以完成传播所有公钥的步骤，因此每次获取新服务器时都可以避免手动步骤。
- en: Now, we will do all the work with only the Ambari web interface.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将只使用Ambari Web界面来完成所有工作。
- en: Creating the Hadoop cluster
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建Hadoop集群
- en: 'In this section, we will build a Hadoop cluster using the Ambari web interface.
    This section assumes the following things:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用Ambari Web界面构建一个Hadoop集群。本节假设以下事项：
- en: The nodes (1–3) are reachable over SSH from the master server
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 节点（1–3）可以通过主服务器使用SSH进行访问
- en: Admin can log in to the nodes (1–3) using the `id-rsa` private key from the
    master server
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理员可以使用主服务器上的`id-rsa`私钥登录到节点（1–3）
- en: A UNIX user can run `sudo` and perform all administrative actions on the node
    (1–3) servers
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: UNIX用户可以通过运行`sudo`在节点（1–3）服务器上执行所有管理操作。
- en: The Ambari server setup is complete
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ambari服务器设置已完成
- en: The Ambari web interface is accessible to the browser without any firewall restrictions
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ambari Web界面可以通过浏览器无任何防火墙限制进行访问
- en: Ambari web interface
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Ambari Web界面
- en: 'Let''s open a web browser and connect to the Ambari server web interface using
    `http://<server-ip>:8080`. We are presented with a login screen like this. Please
    enter `admin` as the username and `admin` as the password to continue:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们打开一个网页浏览器，并使用`http://<server-ip>:8080`连接到Ambari服务器Web界面。我们将看到一个登录屏幕，如下所示。请输入`admin`作为用户名，并输入`admin`作为密码以继续：
- en: '![](img/342804dc-4adf-4c32-8c58-c81024b86a4f.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/342804dc-4adf-4c32-8c58-c81024b86a4f.png)'
- en: Once the login is successful, we are taken to the home page.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 登录成功后，我们将被带到首页。
- en: The Ambari home page
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Ambari首页
- en: This is the main page where there are multiple options on the UI. Since this
    is a brand new installation, there is no cluster data available yet.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 这是主页面，其中UI上有多个选项。由于这是一个全新的安装，目前还没有集群数据。
- en: 'Let''s take a look at the home page with this screenshot:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这个截图的首页：
- en: '![](img/e406237d-ad0e-4dba-8fc2-d82db7913b57.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/e406237d-ad0e-4dba-8fc2-d82db7913b57.png)'
- en: 'From this place, we can carry out the following activities:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个地方，我们可以执行以下活动：
- en: Creating a cluster
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建一个集群
- en: As you may have guessed, this section is used to launch a wizard that will help
    us create a Hadoop cluster from the browser.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所猜，这个部分用于启动一个向导，它将帮助我们通过浏览器创建一个Hadoop集群。
- en: Managing users and groups
  id: totrans-131
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 管理用户和组
- en: This section is helpful to manage users and groups that can use and manage the
    Ambari web application.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 本节有助于管理可以使用和管理的Ambari Web应用程序的用户和组。
- en: Deploying views
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署视图
- en: This interface is helpful in creating views for different types of users and
    what actions they can perform via the Ambari web interface.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 此界面有助于为不同类型的用户创建视图，以及他们可以通过Ambari Web界面执行的操作。
- en: Since our objective is to create a new Hadoop cluster, we will click on the
    Launch Install Wizard button and start the process of creating a Hadoop cluster.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们的目标是创建一个新的Hadoop集群，我们将点击“启动安装向导”按钮，开始创建Hadoop集群的过程。
- en: The cluster install wizard
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 集群安装向导
- en: Hadoop cluster creation is broken down into multiple steps. We will go through
    all these steps in the following sections. First, we are presented with a screen
    where we need to name our Hadoop cluster.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: Hadoop集群创建被分解为多个步骤。我们将在接下来的章节中逐一介绍这些步骤。首先，我们面对一个屏幕，我们需要为我们的Hadoop集群命名。
- en: Naming your cluster
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 命名你的集群
- en: 'I have chosen `packt` as the Hadoop cluster name. Click Next when the Hadoop
    name is entered in the screen. The screen looks like this:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 我已经将`packt`选为Hadoop集群的名称。当屏幕上输入Hadoop名称时，请点击“下一步”。屏幕看起来像这样：
- en: '![](img/6cae5fdd-9dbd-49e1-b16e-793bf355b979.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/6cae5fdd-9dbd-49e1-b16e-793bf355b979.png)'
- en: Selecting the Hadoop version
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 选择Hadoop版本
- en: Once we name the Hadoop cluster, we are presented with a screen to select the
    version of Hadoop we want to run.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们为 Hadoop 集群命名，系统就会显示一个界面，让我们选择要运行的 Hadoop 版本。
- en: 'At the time of writing, Ambari supports the following Hadoop versions:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，Ambari 支持以下 Hadoop 版本：
- en: Hadoop 2.3
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hadoop 2.3
- en: Hadoop 2.4
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hadoop 2.4
- en: Hadoop 2.5
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hadoop 2.5
- en: Hadoop 2.6 (upto 2.6.3.0)
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hadoop 2.6（至 2.6.3.0）
- en: 'You can choose any version for the installation. I have selected the default
    option which is version 2.6.3.0, which can be seen in this screenshot:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以选择任何版本进行安装。我选择了默认选项，即版本 2.6.3.0，这在以下截图中可以看到：
- en: '![](img/bf80801e-ac87-404a-b773-b28e24e41787.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bf80801e-ac87-404a-b773-b28e24e41787.png)'
- en: Click Next at the bottom of the screen to continue to the next step.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 点击屏幕底部的“下一步”继续到下一步。
- en: Selecting a server
  id: totrans-151
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 选择服务器
- en: The next logical step is to select the list of servers on which we are going
    to install the Hadoop-2.6.3.0 version. If you remember the original table, we
    named our node servers (1–3). We will enter those in the UI.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个逻辑步骤是选择要安装 Hadoop-2.6.3.0 版本的服务器列表。如果您还记得原始表格，我们命名了我们的节点服务器（1–3）。我们将在 UI
    中输入这些名称。
- en: Since the installation is going to be completely automated, we also need to
    provide the RSA private key that we generated in the previous section in the UI.
    This will make sure that the master node can log in to the servers without any
    password over SSH.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 由于安装将完全自动化，我们还需要在 UI 中提供在前一节中生成的 RSA 私钥。这将确保主节点可以通过 SSH 无密码登录到服务器。
- en: Also, we need to provide a UNIX username that's already been created on all
    the node (1–3) servers that can also accept RSA key for authentication.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们还需要提供一个 UNIX 用户名，该用户名已在所有节点（1–3）服务器上创建，并且也可以接受 RSA 密钥进行身份验证。
- en: Add `id_rsa.pub` to `~/.ssh/authorized_keys` on the node (1–3) servers.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 将 `id_rsa.pub` 添加到节点（1–3）服务器上的 `~/.ssh/authorized_keys`。
- en: Please keep in mind that these hostnames should have proper entries in the **DNS**
    (**Domain Name System**) Servers otherwise the installation won't be able to proceed
    from this step.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，这些主机名应该在 **DNS**（**域名系统**）服务器中有适当的条目，否则安装将无法从这一步继续进行。
- en: 'The names that I have given can be seen in this following screenshot:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 我给出的名称可以在以下截图看到：
- en: '![](img/8f8538ec-bcee-4508-b32b-b6056f188dca.png)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8f8538ec-bcee-4508-b32b-b6056f188dca.png)'
- en: After the data is entered, click on Register and Confirm.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 输入数据后，点击“注册”和“确认”。
- en: Setting up the node
  id: totrans-160
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置节点
- en: 'In this step, the Ambari agent is automatically installed on the given nodes,
    provided the details are accurate. Success confirmation looks like this:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一步，如果详细信息准确，Ambari 代理将自动安装到指定的节点上。成功确认看起来像这样：
- en: '![](img/d657b897-b614-45c0-8735-e66399aac561.png)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d657b897-b614-45c0-8735-e66399aac561.png)'
- en: If we want to remove any nodes, this is the screen in which we can do it. Click
    Next when we are ready to go to the next step.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们要删除任何节点，这就是我们可以做到的屏幕。准备好进入下一步时，点击“下一步”。
- en: Selecting services
  id: totrans-164
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 选择服务
- en: Now, we need to select the list of applications/services that we want to install
    on the three servers we have selected.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们需要选择要在我们选择的三个服务器上安装的应用程序/服务列表。
- en: 'At the time of writing, Ambari supports the following services:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，Ambari 支持以下服务：
- en: '| **Application/Service** | **Application Description** |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| **应用程序/服务** | **应用程序描述** |'
- en: '| HDFS | Hadoop Distributed File System |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| HDFS | Hadoop 分布式文件系统 |'
- en: '| YARN + MapReduce2 | Next generation Map Reduce framework |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| YARN + MapReduce2 | 下一代 MapReduce 框架 |'
- en: '| Tez | Hadoop query processing framework built on top of YARN |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| Tez | 基于 YARN 的 Hadoop 查询处理框架 |'
- en: '| Hive | Data warehouse system for ad hoc queries |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| Hive | 用于 ad hoc 查询的数据仓库系统 |'
- en: '| HBase | Non-relational distributed database |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| HBase | 非关系型分布式数据库 |'
- en: '| Pig | Scripting platform to analyze datasets in HDFS |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| Pig | 用于分析 HDFS 中数据集的脚本平台 |'
- en: '| Sqoop | Tool to transfer data between Hadoop and RDBMS |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| Sqoop | 在 Hadoop 和 RDBMS 之间传输数据的工具 |'
- en: '| Oozie | Workflow co-ordination for Hadoop jobs with a web UI |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| Oozie | 带有 Web UI 的 Hadoop 作业工作流协调 |'
- en: '| ZooKeeper | Distributed system coordination providing service |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| ZooKeeper | 提供服务的分布式系统协调服务 |'
- en: '| Falcon | Data processing and management platform |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| Falcon | 数据处理和管理平台 |'
- en: '| Storm | Stream processing framework |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| Storm | 流处理框架 |'
- en: '| Flume | Distributed system to collect, aggregate, and move streaming data
    to HDFS |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| Flume | 用于收集、聚合并将流数据移动到 HDFS 的分布式系统 |'
- en: '| Accumulo | Distributed key/value store |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| Accumulo | 分布式键/值存储 |'
- en: '| Ambari Infra | Shared service used by Amari components |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| Ambari Infra | Ambari 组件使用的共享服务 |'
- en: '| Ambari Metrics | Grafana-based system for metric collection and storage |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| Ambari Metrics | 基于Grafana的指标收集和存储系统 |'
- en: '| Atlas | Metadata and governance platform |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| Atlas | 元数据和治理平台 |'
- en: '| Kafka | Distributed streaming platform |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| Kafka | 分布式流平台 |'
- en: '| Knox | Single-point authentication provider for all Hadoop components |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| Knox | Hadoop所有组件的单点认证提供者 |'
- en: '| Log Search | Ambari-managed services log aggregator and viewer |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| Log Search | Ambari管理的服务日志聚合器和查看器 |'
- en: '| Ranger | Hadoop data security application |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '| Ranger | Hadoop数据安全应用 |'
- en: '| Ranger KMS | Key management server |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '| Ranger KMS | 密钥管理服务器 |'
- en: '| SmartSense | Hortonworks Smart Sense tool to diagnose applications |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '| SmartSense | Hortonworks Smart Sense工具，用于诊断应用程序 |'
- en: '| Spark | Large-scale data processing framework |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '| Spark | 大规模数据处理框架 |'
- en: '| Zeppelin Notebook | Web-based notebook for data analytics |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '| Zeppelin Notebook | 基于Web的数据分析笔记本 |'
- en: '| Druid | Column-oriented data store |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| Druid | 列式数据存储 |'
- en: '| Mahout | Machine learning algorithms |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| Mahout | 机器学习算法 |'
- en: '| Slider | Framework to monitor applications on YARN |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| Slider | 用于监控YARN上应用程序的框架 |'
- en: '| Superset | Browser-based data exploration platform for RDBMS and Druid |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| Superset | 基于浏览器的RDBMS和Druid数据探索平台 |'
- en: 'As part of the current step, we have selected only HDFS and its dependencies.
    The screen is shown as follows:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 作为当前步骤的一部分，我们只选择了HDFS及其依赖项。屏幕如下所示：
- en: '![](img/3d5ef787-a2a7-47b3-a56a-4f0726dc3793.png)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/3d5ef787-a2a7-47b3-a56a-4f0726dc3793.png)'
- en: Once you have made your choices, click the Next button at the bottom of the
    UI.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你做出了选择，点击UI底部的“下一步”按钮。
- en: Service placement on nodes
  id: totrans-199
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 节点上的服务放置
- en: 'In this step, we are shown the automatic selection of services on the three
    nodes we have selected for installation. If we want to customize the placement
    of the services on the nodes, we can do so. The placement looks like this:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 在此步骤中，我们展示了在安装所选的三个节点上自动选择服务的情况。如果我们想自定义节点上服务的放置，我们可以这样做。放置情况如下所示：
- en: '![](img/fd7ee964-d0a2-40e5-a058-5d31a73a6c9d.png)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/fd7ee964-d0a2-40e5-a058-5d31a73a6c9d.png)'
- en: Click Next when the changes look good.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 当更改看起来不错时，点击“下一步”。
- en: Selecting slave and client nodes
  id: totrans-203
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 选择从属节点和客户端节点
- en: 'Some applications support slaves and client utilities. In this screen, we need
    to select the nodes on which we want these applications to be installed. If you
    are unsure, click Next. The screen looks like this:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 一些应用程序支持从属和客户端实用工具。在此屏幕上，我们需要选择我们希望在哪些节点上安装这些应用程序的节点。如果你不确定，请点击“下一步”。屏幕如下所示：
- en: '![](img/67a9dcf8-1d46-4bc4-9907-db153f82d489.png)'
  id: totrans-205
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/67a9dcf8-1d46-4bc4-9907-db153f82d489.png)'
- en: Customizing services
  id: totrans-206
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自定义服务
- en: 'Even though Ambari automatically selects most of the properties and linkage
    between the applications, it provides us with some flexibility to choose values
    for some of the features, such as:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管Ambari自动选择了大多数属性和应用程序之间的链接，但它为我们提供了一些灵活性，可以选择一些功能的值，例如：
- en: Databases
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据库
- en: Usernames
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户名
- en: Passwords
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 密码
- en: And other properties that help the applications run smoothly. These are highlighted
    in the current screen in red.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 以及其他有助于应用程序平稳运行的属性。这些在当前屏幕中以红色突出显示。
- en: 'In order to customize these, we need to go to the tab with the highlighted
    properties and choose the values according to our need. The screen looks like
    this:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 为了自定义这些，我们需要转到带有突出显示属性的标签页，并根据我们的需求选择值。屏幕如下所示：
- en: '![](img/0736a2bc-163a-4774-b4c1-347e8e2afea7.png)'
  id: totrans-213
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/0736a2bc-163a-4774-b4c1-347e8e2afea7.png)'
- en: After all the service properties are configured correctly, we will not see anything
    in red in the UI and can click the Next button at the bottom of the page.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 在正确配置所有服务属性后，我们将在UI中看不到任何红色内容，并且可以点击页面底部的“下一步”按钮。
- en: Reviewing the services
  id: totrans-215
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 审查服务
- en: In this step, we are shown a summary of the changes we have made so far. We
    are given an option to print the changes so that we will not forget them (don't
    worry, all these are available on the UI later). For now we can click Deploy.
    This is when the actual changes will be made to the nodes.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 在此步骤中，我们展示了我们迄今为止所做的更改摘要。我们有一个选项可以打印更改，这样我们就不会忘记它们（别担心，所有这些都可以在UI稍后找到）。现在我们可以点击“部署”。这是实际更改将应用于节点的时候。
- en: 'No changes will be made to the servers if we cancel this process. The current
    state of the wizard looks like this now:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们取消此过程，服务器将不会进行任何更改。当前向导的状态如下所示：
- en: '![](img/a89754af-2fc1-4e5c-8b69-64cde207f49e.png)'
  id: totrans-218
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/a89754af-2fc1-4e5c-8b69-64cde207f49e.png)'
- en: Installing the services on the nodes
  id: totrans-219
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在节点上安装服务
- en: After we've clicked Deploy in the previous step, a deployment plan is generated
    by the Ambari server and applications will be deployed on all the nodes in parallel,
    using the Ambari agents running on all the nodes.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一步点击“部署”之后，Ambari服务器将生成一个部署计划，并使用所有节点上运行的Ambari代理并行地在所有节点上部署应用程序。
- en: We are shown the progress of what is being deployed in real time in this step.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一步，我们可以实时看到正在部署的进度。
- en: 'Once all the components have been installed, they will be automatically started
    and we can see the successful completion in this screen:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦所有组件都安装完毕，它们将自动启动，我们可以在屏幕上看到成功的完成状态：
- en: '![](img/a3026110-8cdf-4996-a162-cb94ea509f42.png)'
  id: totrans-223
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a3026110-8cdf-4996-a162-cb94ea509f42.png)'
- en: Click Next when everything is done successfully. In the case of any failures,
    we are shown what has failed and will be given an option to retry the installation.
    If there are any failures, we need to dig into the errors and fix the underlying
    problems.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 当一切操作成功完成后，请点击“下一步”。如果出现任何故障，我们会看到哪些失败了，并会提供一个选项来重试安装。如果出现任何故障，我们需要深入错误并修复根本问题。
- en: If you have followed the instructions given at the beginning of the section
    you should have everything running smoothly.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你已经遵循了本节开头给出的说明，你应该一切运行顺利。
- en: Installation summary
  id: totrans-226
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装摘要
- en: 'In this step, we are shown the summary of what has been installed. The screen
    looks like this:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一步，我们会看到已安装内容的摘要。屏幕看起来像这样：
- en: '![](img/324eceec-02e5-4514-b822-a2fb762a9caf.png)'
  id: totrans-228
  prefs: []
  type: TYPE_IMG
  zh: '![](img/324eceec-02e5-4514-b822-a2fb762a9caf.png)'
- en: Click on the Complete button which marks the end of the Hadoop cluster setup.
    Next, we will be taken to the cluster dashboard.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 点击“完成”按钮，这标志着Hadoop集群设置的结束。接下来，我们将被带到集群仪表板。
- en: The cluster dashboard
  id: totrans-230
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 集群仪表板
- en: This is the home page of the Hadoop cluster we have just created where we can
    see the list of all the services that have been installed and the health sensors.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 这是刚刚创建的Hadoop集群的主页，在这里我们可以看到已安装的所有服务的列表和健康传感器。
- en: 'We can manage all aspects of the Hadoop cluster in this interface. Feel free
    to explore the interface and play with it to understand more:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过这个界面管理Hadoop集群的所有方面。请随意探索这个界面，并尝试操作以了解更多信息：
- en: '![](img/653fc1b7-f43b-4cff-8613-447f54d147bb.png)'
  id: totrans-233
  prefs: []
  type: TYPE_IMG
  zh: '![](img/653fc1b7-f43b-4cff-8613-447f54d147bb.png)'
- en: This marks the end of the Hadoop cluster creation with Ambari.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 这标志着使用Ambari创建Hadoop集群的结束。
- en: Hadoop clusters
  id: totrans-235
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Hadoop集群
- en: So far, we have seen how to create a single Hadoop cluster using Ambari. But,
    is there ever a requirement for multiple Hadoop clusters?
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经看到了如何使用Ambari创建单个Hadoop集群。但是，是否真的需要多个Hadoop集群？
- en: The answer depends on the business requirements. There are trade-offs for both
    single versus multiple Hadoop clusters.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 答案取决于业务需求。在单集群与多集群之间，都有一些权衡。
- en: Before we jump into the advantages and disadvantages of both of these, let's
    see in what scenarios we might use either.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入探讨这两种方案的优缺点之前，让我们看看在什么场景下我们可能会使用其中之一。
- en: A single cluster for the entire business
  id: totrans-239
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 整个业务的单一集群
- en: This is the most straightforward approach and every business starts with one
    cluster, at least. As the diversity of the business increases, organizations tend
    to choose one cluster per department, or business unit.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 这是最直接的方法，每个企业至少从一个集群开始。随着业务多样性的增加，组织倾向于为每个部门或业务单元选择一个集群。
- en: 'The following are some of the advantages:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些优点：
- en: '**Ease of operability**: Since there is only one Hadoop cluster, managing it
    is very easy and the team sizes will also be optimal when administering it.'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**易于操作**：由于只有一个Hadoop集群，因此管理它非常容易，在管理它时，团队规模也将是最优的。'
- en: '**One-stop shop**: Since all the company data is in a single place, it''s very
    easy to come up with innovative ways to use and generate analytics on top of the
    data.'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**一站式服务**：由于所有公司数据都在一个地方，因此很容易想出创新的方法来使用数据并生成数据上的分析。'
- en: '**Integration cost**: Teams and departments within the enterprise can integrate
    with this single system very easily. They have less complex configurations to
    deal with when managing their applications.'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**集成成本**：企业内部团队和部门可以非常容易地与这个单一系统集成。在管理他们的应用程序时，他们需要处理的配置更简单。'
- en: '**Cost to serve**: Enterprises can have a better understanding of their entire
    big data usage and can also plan, in a less stringent way, on scaling their system.'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**服务成本**：企业可以更好地了解其整个大数据使用情况，并且可以以不那么严格的方式计划扩展其系统。'
- en: 'Some disadvantages of employing this approach are as follows:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 采用这种方法的一些缺点如下：
- en: '**Scale becomes a challenge**: Even though Hadoop can be run on hundreds and
    thousands of servers, it becomes a challenge to manage such big clusters, particularly
    during upgrades and other changes.'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**规模成为挑战**：尽管Hadoop可以在数百甚至数千台服务器上运行，但管理如此大的集群，尤其是在升级和其他变更期间，成为一个挑战。'
- en: '**Single point of failure**: Hadoop internally has replication built-in to
    it in the HDFS File System. When more nodes fail, the chances are that there is
    loss of data and it''s hard to recover from that.'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**单点故障**：Hadoop在HDFS文件系统中内置了复制功能。当更多节点失败时，数据丢失的可能性增加，且难以从中恢复。'
- en: '**Governance is a challenge**: As the scale of data, applications, and users
    increase, it is a challenge to keep track of the data without proper planning
    and implementation in place.'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**治理是一个挑战**：随着数据、应用程序和用户的规模增加，如果没有适当的规划和实施，跟踪数据是一个挑战。'
- en: '**Security and confidential data management**: Enterprises deal with a variety
    of data that varies from highly sensitive to transient data. When all sorts of
    data is put in a big-data solution, we have to employ very strong authentication
    and authorization rules so that the data is visible only to the right audience.'
  id: totrans-250
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全和机密数据管理**：企业处理各种数据，从高度敏感的数据到临时数据不等。当所有类型的数据都放入大数据解决方案中时，我们必须采用非常强大的身份验证和授权规则，以确保数据只对正确的受众可见。'
- en: With these thoughts, let's take a look at the other possibility of having Hadoop
    clusters in an enterprise.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 带着这些想法，让我们来看看企业中拥有Hadoop集群的另一种可能性。
- en: Multiple Hadoop clusters
  id: totrans-252
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多个Hadoop集群
- en: Even though having a single Hadoop cluster is easier to maintain within an organization,
    sometimes its important to have multiple Hadoop clusters to keep the business
    running smoothly and reduce dependency on a single point of failure system.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然在组织内部维护单个Hadoop集群更容易，但有时为了使业务顺利运行并减少对单点故障系统的依赖，有时需要拥有多个Hadoop集群。
- en: 'These multiple Hadoop clusters can be used for several reasons:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 这些多个Hadoop集群可以用于以下几个原因：
- en: Redundancy
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 冗余
- en: Cold backup
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 冷备份
- en: High availability
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高可用性
- en: Business continuity
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 业务连续性
- en: Application environments
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用环境
- en: Redundancy
  id: totrans-260
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 冗余
- en: When we think of redundant Hadoop clusters, we should think about how much redundancy
    we can keep. As we already know, the **Hadoop Distributed File System** (**HDFS**)
    has internal data redundancy built in to it.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们考虑冗余的Hadoop集群时，我们应该考虑我们可以保持多少冗余。正如我们所知，**Hadoop分布式文件系统**（**HDFS**）内部已经内置了数据冗余。
- en: Given that a Hadoop cluster has lot of ecosystem built around it (services such
    as YARN, Kafka, and so on), we should think and plan carefully about whether to
    have the entire ecosystem made redundant or make only the data redundant by keeping
    it in a different cluster.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到Hadoop集群周围构建了大量的生态系统（如YARN、Kafka等服务），我们应该仔细思考和计划是否要使整个生态系统冗余，或者只通过将数据保存在不同的集群中来使数据冗余。
- en: It's easier to make the HDFS portion of the Hadoop redundant as there are tools
    to copy the data from one HDFS to another HDFS.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 由于有工具可以从一个HDFS复制数据到另一个HDFS，因此使Hadoop的HDFS部分冗余更容易。
- en: 'Let''s take a look at possible ways to achieve this via this diagram:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过这张图来看看实现这一目标的可能方法：
- en: '![](img/9ac21035-486c-41d0-903a-c7b9e1a0b41a.png)'
  id: totrans-265
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9ac21035-486c-41d0-903a-c7b9e1a0b41a.png)'
- en: As we can see here, the main Hadoop cluster runs a full stack of all its applications,
    and data is supplied to it via multiple sources.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所见，主Hadoop集群运行了所有其应用程序的全栈，数据通过多个来源供应给它。
- en: 'We have defined two types of redundant clusters:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经定义了两种类型的冗余集群：
- en: A fully redundant Hadoop cluster
  id: totrans-268
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个完全冗余的Hadoop集群
- en: This cluster runs the exact set of applications as the primary cluster and the
    data is copied periodically from the main Hadoop cluster. Since this is a one-way
    copy from the main cluster to the second cluster, we can be 100% sure that the
    main cluster isn't impacted when we make any changes to this fully redundant cluster.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 这个集群运行与主集群完全相同的应用程序集合，并且数据定期从主Hadoop集群复制。由于这是从主集群到第二个集群的单向复制，因此当我们对这个完全冗余的集群进行任何更改时，我们可以100%确信主集群不会受到影响。
- en: One important thing to understand is that we are running all other instances
    of applications in this cluster. Since every application maintains its state in
    its own predefined location, the application states are not replicated from the
    main Hadoop cluster to this cluster, which means that the jobs that were created
    in the main Hadoop cluster are not visible in this cluster. The same applies to
    the Kafka topics, zookeeper nodes, and many more.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 需要理解的一个重要问题是，我们在这个集群中运行所有其他应用程序实例。由于每个应用程序都维护其预定义位置的状态，应用程序状态不会从主 Hadoop 集群复制到这个集群，这意味着在主
    Hadoop 集群中创建的作业在这个集群中是不可见的。同样适用于 Kafka 主题、zookeeper 节点等。
- en: This type of cluster is helpful for running different environments such as QA,
    Staging, and so on.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 这种类型的集群有助于运行不同的环境，例如 QA、预发布等。
- en: A data redundant Hadoop cluster
  id: totrans-272
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据冗余的 Hadoop 集群
- en: In this type of cluster setup, we create a new Hadoop cluster and copy the data
    from the main cluster, like in the previous case; but here we are not worried
    about the other applications that are run in this cluster.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种类型的集群设置中，我们创建一个新的 Hadoop 集群，并从主集群复制数据，就像之前的例子一样；但在这里，我们并不担心在这个集群中运行的其他应用程序。
- en: 'This type of setup is good for:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 这种设置适用于：
- en: Having data backup for Hadoop in a different geography
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在不同的地理区域为 Hadoop 进行数据备份
- en: Sharing big data with other enterprises/organizations
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与其他企业/组织共享大数据
- en: Cold backup
  id: totrans-277
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 冷备份
- en: Cold backup is important for enterprises as the data gets older. Even though
    Hadoop is designed to store unlimited amounts of data, it's not always necessary
    to keep all the data available for processing.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 对于企业来说，冷备份很重要，因为数据会随着时间的推移而老化。尽管 Hadoop 被设计用来存储无限量的数据，但并非总是需要保留所有数据以供处理。
- en: It is sometimes necessary to preserve the data for auditing purposes and also
    for historical reasons. In such cases, we can create a dedicated Hadoop cluster
    with only the HDFS (File System) component and periodically sync all the data
    into this cluster.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 有时为了审计目的和历史原因，有必要保留数据。在这种情况下，我们可以创建一个仅包含 HDFS（文件系统）组件的专用 Hadoop 集群，并定期将所有数据同步到这个集群中。
- en: The design for this system is similar to the data redundant Hadoop cluster.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 该系统的设计类似于数据冗余的 Hadoop 集群。
- en: High availability
  id: totrans-281
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 高可用性
- en: Even though Hadoop has multiple components within the architecture, not all
    the components are highly available due to the internal design.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 Hadoop 架构中包含多个组件，但由于内部设计，并非所有组件都高度可用。
- en: The core component of Hadoop is its distributed, fault-tolerant, filesystem
    HDFS. HDS has multiple components one of them is the NameNode which is the registry
    of where the files are located in the HDFS. In the earlier versions of HDS NameNode
    was Single point of Failure, In the recent versions Secondary NameNode has been
    added to assist with high availability requirements for Hadoop Cluster.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: Hadoop 的核心组件是其分布式、容错的文件系统 HDFS。HDFS 有多个组件，其中之一是 NameNode，它是 HDFS 中文件位置的注册表。在
    HDFS 的早期版本中，NameNode 是单点故障，而在最近版本中，Secondary NameNode 已被添加以协助满足 Hadoop 集群的高可用性需求。
- en: In order to make every component of the Hadoop ecosystem a highly available
    system, we need to add multiple redundant nodes (they come with their own cost)
    which work together as a cluster.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使 Hadoop 生态系统的每个组件都成为一个高可用系统，我们需要添加多个冗余节点（它们有自己的成本），这些节点协同工作形成一个集群。
- en: One more thing to note is that high availability with Hadoop is possible within
    a single geographical region, as the locality of the data with applications is
    one of the key things with Hadoop. The moment we have multiple data centers in
    play we need to think alternatively to achieve high availability across the data
    centers.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 另一点需要注意的是，在单个地理区域内，使用 Hadoop 实现高可用性是可能的，因为数据的本地性与应用程序是 Hadoop 的关键因素之一。当我们有多个数据中心参与时，我们需要考虑其他方法来实现数据中心间的高可用性。
- en: Business continuity
  id: totrans-286
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 业务连续性
- en: This is part of **Business Continuity Planning **(**BCP**) where natural disasters
    can bring an end to the Hadoop system, if not planned correctly.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 这部分是**业务连续性计划**（**BCP**）的一部分，如果计划不当，自然灾害可能会结束 Hadoop 系统。
- en: Here, the strategy would be to use multiple geographical regions as providers
    to run the big data systems. When we talk about multiple data centers, the obvious
    challenge is the network and the cost associated with managing both systems. One
    of the biggest challenges is how to keep multiple regions in sync.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，策略将是使用多个地理区域作为提供者来运行大数据系统。当我们谈论多个数据中心时，明显的挑战是网络以及管理两个系统的成本。最大的挑战之一是如何保持多个区域同步。
- en: One possible solution is to build a fully redundant Hadoop cluster in other
    geographical regions and keep the data in sync, periodically. In the case of any
    disaster/breakdown of one region, our businesses won't come to halt as we can
    smoothly run our operations.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 一种可能的解决方案是在其他地理区域构建一个完全冗余的Hadoop集群，并定期保持数据同步。在任何一个区域发生灾难/故障的情况下，我们的业务不会停止，因为我们可以平稳地运行我们的操作。
- en: Application environments
  id: totrans-290
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 应用环境
- en: Many businesses internally follow different ways of releasing their software
    to production. As part of this, they follow several continuous integration methodologies,
    in order to have better control over the stability of the Hadoop environments.
    It's good to build multiple smaller Hadoop clusters with X% of the data from the
    main production environment and run all the applications here.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 许多企业内部遵循不同的方式将软件发布到生产环境中。作为其中的一部分，他们遵循几种持续集成方法，以便更好地控制Hadoop环境的稳定性。构建多个较小的Hadoop集群，其中包含主生产环境的X%的数据，并在这些集群中运行所有应用程序是很好的。
- en: Applications can build their integration tests on these dedicated environments
    (QA, Staging, and so on) and can release their software to production once everything
    is good.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序可以在这些专用环境中（如QA、Staging等）构建它们的集成测试，并在一切正常后将其软件发布到生产环境。
- en: One practice that I have come across is that organizations tend to directly
    ship the code to production and end up facing outage of their applications because
    of an untested workflow or bug. It's good practice to have dedicated Hadoop application
    environments to test the software thoroughly and achieve higher uptime and happier
    customers.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 我遇到的一种做法是，组织倾向于直接将代码发送到生产环境，最终因为未经测试的工作流程或错误而面临应用程序的中断。拥有专门的Hadoop应用程序环境来彻底测试软件，实现更高的正常运行时间和更满意的客户是一个好的做法。
- en: Hadoop data copy
  id: totrans-294
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Hadoop数据复制
- en: We have seen in the previous sections that, having highly available data is
    very important for a business to succeed and stay up to date with its competition.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在前面几节中看到，拥有高度可用的数据对于企业成功并跟上其竞争至关重要。
- en: In this section, we will explore the possible ways to achieve highly available
    data setup.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探讨实现高度可用数据设置的可能方法。
- en: HDFS data copy
  id: totrans-297
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: HDFS数据复制
- en: Hadoop uses HDFS as its core to store the files. HDFS is rack aware and is intelligent
    enough to reduce the network data transfer when applications are run on the data
    nodes.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: Hadoop使用HDFS作为其核心来存储文件。HDFS具有机架感知性，并且足够智能，能够在数据节点上运行应用程序时减少网络数据传输。
- en: One of the preferred ways of data copying in an HDFS environment is to use the
    DistCp. The official documentation for this is available at the following URL
    [http://hadoop.apache.org/docs/r1.2.1/distcp.html](http://hadoop.apache.org/docs/r1.2.1/distcp.html).
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 在HDFS环境中进行数据复制的一种首选方式是使用DistCp。官方文档可在以下URL找到：[http://hadoop.apache.org/docs/r1.2.1/distcp.html](http://hadoop.apache.org/docs/r1.2.1/distcp.html)。
- en: 'We will see a few examples of copying data from one Hadoop cluster to another
    Hadoop cluster. But before that, let''s look at how the data is laid out:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将看到一些从一个Hadoop集群复制数据到另一个Hadoop集群的示例。但在那之前，让我们看看数据是如何布局的：
- en: '![](img/5a884670-9141-4abc-890e-e045b5280301.png)'
  id: totrans-301
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5a884670-9141-4abc-890e-e045b5280301.png)'
- en: 'In order to copy the data from the production Hadoop cluster to the backup
    Hadoop cluster, we can use `distcp`. Let''s see how to do it:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将生产Hadoop集群中的数据复制到备份Hadoop集群，我们可以使用`distcp`。让我们看看如何操作：
- en: '[PRE20]'
  id: totrans-303
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: When we run the `distcp` command, a MapReduce job is created to automatically
    find out the list of files and then copy them to the destination.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们运行`distcp`命令时，会创建一个MapReduce作业来自动找出文件列表，然后将它们复制到目标位置。
- en: 'The full command syntax looks like this:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的命令语法如下：
- en: '[PRE21]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '`OPTIONS`: These are the multiple options the command takes which control the
    behavior of the execution.'
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`OPTIONS`：这些是命令接受的多个选项，它们控制执行的行为。'
- en: '`source path`: A source path can be any valid File System URI that''s supported
    by Hadoop. DistCp supports taking multiple source paths in one go.'
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`source path`：源路径可以是Hadoop支持的任何有效的文件系统URI。DistCp支持一次性处理多个源路径。'
- en: '`destination path`: This is a single path where all the source paths need to
    be copied.'
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`目标路径`：这是一个单独的路径，所有源路径都需要复制到这个路径。'
- en: 'Let''s take a closer look at a few of the important options:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地看看一些重要的选项：
- en: '| **Flag/Option** | **Description** |'
  id: totrans-311
  prefs: []
  type: TYPE_TB
  zh: '| **标志/选项** | **描述** |'
- en: '| `append` | Incrementally writes the data to the destination files if they
    already exist (only `append` is performed, no block level check is performed to
    do incremental copy). |'
  id: totrans-312
  prefs: []
  type: TYPE_TB
  zh: '| `append` | 如果目标文件已存在，则增量地将数据写入目标文件（仅执行`append`，不执行块级检查以进行增量复制）。 |'
- en: '| `async` | Performs the copy in a non-blocking way. |'
  id: totrans-313
  prefs: []
  type: TYPE_TB
  zh: '| `async` | 以非阻塞方式执行复制。 |'
- en: '| `atomic` | Perform all the file copy or aborts even if one fails. |'
  id: totrans-314
  prefs: []
  type: TYPE_TB
  zh: '| `atomic` | 即使其中一个失败，也会执行所有文件复制或中止。 |'
- en: '| `Tmp <path>` | Path to be used for atomic commit. |'
  id: totrans-315
  prefs: []
  type: TYPE_TB
  zh: '| `Tmp <路径>` | 用于原子提交的路径。 |'
- en: '| `delete` | Deletes the files from the destination if they are not present
    in the source tree. |'
  id: totrans-316
  prefs: []
  type: TYPE_TB
  zh: '| `delete` | 如果在源树中不存在，则从目标位置删除文件。 |'
- en: '| `Bandwidth <arg>` | Limits how much network bandwidth to be used during the
    copy process. |'
  id: totrans-317
  prefs: []
  type: TYPE_TB
  zh: '| `Bandwidth <参数>` | 限制复制过程中使用的网络带宽。 |'
- en: '| `f <file-path>` | Filename consisting of a list of all paths which need to
    be copied. |'
  id: totrans-318
  prefs: []
  type: TYPE_TB
  zh: '| `f <文件路径>` | 包含需要复制的所有路径的文件名列表。 |'
- en: '| `i` | Ignores any errors during file copy. |'
  id: totrans-319
  prefs: []
  type: TYPE_TB
  zh: '| `i` | 忽略文件复制过程中的任何错误。 |'
- en: '| `Log <file-path>` | Location where the execution log is saved. |'
  id: totrans-320
  prefs: []
  type: TYPE_TB
  zh: '| `Log <文件路径>` | 执行日志保存的位置。 |'
- en: '| `M <number>` | Maximum number of concurrent maps to use for copying. |'
  id: totrans-321
  prefs: []
  type: TYPE_TB
  zh: '| `M <数字>` | 用于复制的最大并发映射数。 |'
- en: '| `overwrite` | Overwrites the files even if they exist on destination. |'
  id: totrans-322
  prefs: []
  type: TYPE_TB
  zh: '| `overwrite` | 即使在目标位置存在，也会覆盖文件。 |'
- en: '| `update` | Copies only the missing files and directories. |'
  id: totrans-323
  prefs: []
  type: TYPE_TB
  zh: '| `update` | 仅复制缺少的文件和目录。 |'
- en: '| `skipcrccheck` | If passed, CRC checks are skipped during transfer. |'
  id: totrans-324
  prefs: []
  type: TYPE_TB
  zh: '| `skipcrccheck` | 如果通过，则在传输过程中将跳过CRC检查。 |'
- en: Summary
  id: totrans-325
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Summary
- en: In this chapter, we learned about Apache Ambari and studied its architecture
    in detail. We then understood how to prepare and create our own Hadoop cluster
    with Ambari. In order to do this, we also looked into configuring the Ambari server
    as per the requirement before preparing our cluster. We also learned about single
    and multiple Hadoop clusters and how they can be used, based on the business requirement.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了Apache Ambari，并详细研究了其架构。然后我们了解了如何使用Ambari准备和创建自己的Hadoop集群。为了做到这一点，我们在准备集群之前还研究了根据需求配置Ambari服务器。我们还了解了单集群和多集群，以及根据业务需求如何使用它们。
