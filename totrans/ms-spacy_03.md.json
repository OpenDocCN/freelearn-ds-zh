["```py\n import spacy\n nlp = spacy.load(\"en_core_web_md\")\n doc = nlp(\"I went there\")\n```", "```py\n import spacy\n nlp = spacy.load(\"en_core_web_md\")\n doc = nlp(\"I own a ginger cat.\")\n print ([token.text for token in doc])\n ['I', 'own', 'a', 'ginger', 'cat', '.']\n```", "```py\n import spacy\n nlp = spacy.load(\"en_core_web_md\")\n doc = nlp(\"It's been a crazy week!!!\")\n print ([token.text for token in doc])\n['It', \"'s\", 'been', 'a', 'crazy', 'week', '!', '!', '!']\n```", "```py\n import spacy\n from spacy.symbols import ORTH\n nlp = spacy.load(\"en_core_web_md\")\n doc = nlp(\"lemme that\")\n print([w.text for w in doc])\n['lemme', 'that']\n special_case = [{ORTH: \"lem\"}, {ORTH: \"me\"}]\n nlp.tokenizer.add_special_case(\"lemme\", special_case)\n print([w.text for w in nlp(\"lemme that\")])\n['lem', 'me', 'that']\n```", "```py\n print([w.text for w in nlp(\"lemme!\")])\n['lem', 'me', '!']\n```", "```py\n nlp.tokenizer.add_special_case(\"...lemme...?\", [{\"ORTH\": \"...lemme...?\"}])\n print([w.text for w in nlp(\"...lemme...?\")])\n'...lemme...?'\n```", "```py\n import spacy\n nlp = spacy.load(\"en_core_web_md\")\n text = \"Let's go!\"\n doc = nlp(text)\n tok_exp = nlp.tokenizer.explain(text)\n for t in tok_exp:\n     print(t[1], \"\\t\", t[0])\nLet    SPECIAL-1\n's     SPECIAL-2\ngo     TOKEN\n!      SUFFIX\n```", "```py\n import spacy\n nlp = spacy.load(\"en_core_web_md\")\n text = \"I flied to N.Y yesterday. It was around 5 pm.\"\n doc = nlp(text)\n for sent in doc.sents:\n     print(sent.text)\nI flied to N.Y yesterday.\nIt was around 5 pm.\n```", "```py\n import spacy\n nlp = spacy.load(\"en_core_web_md\")\n doc = nlp(\"I went there for working and worked for 3 years.\")\n for token in doc:\n     print(token.text, token.lemma_)\nI -PRON-\nwent go\nthere\nfor for\nworking work\nand and\nworked work\nfor for\n3 3\nyears year\n. .\n```", "```py\nfly – flight – airway – airplane - plane\nbus \nrailway – train \n```", "```py\nList me all flights to Atlanta.\nI need a flight to NY.\nI flew to Atlanta yesterday evening and forgot my baggage.\n```", "```py\n import spacy\n from spacy.symbols import ORTH, LEMMA\n nlp = spacy.load('en')\n special_case = [{ORTH: 'Angeltown', LEMMA: 'Los Angeles'}]\n nlp.tokenizer.add_special_case(u'Angeltown', special_case)\n doc = nlp(u'I am flying to Angeltown')\n for token in doc:\n     print(token.text, token.lemma_)\nI -PRON-\nam be\nflying fly\nto to\nAngeltown Los Angeles\n```", "```py\nWord                Lemma\nuniversity        university\nuniverse          universe\nuniversal         universal\nuniversities     university\nuniverses        universe\nimprovement  improvement\nimprovements improvements\nimproves         improve\n```", "```py\nWord                Stem\nuniversity        univers\nuniverse          univer\nuniversal         univers\nuniversities     universi\nuniverses        univers\nimprovement  improv\nimprovements improv\nimproves         improv\n```", "```py\n doc = nlp(\"I like cats.\") \n```", "```py\n doc.text\nI like cats.\n```", "```py\n for token in doc:\n     print(token.text)\nI\nlike\ncats\n.\n```", "```py\n doc[1]\nlike\n```", "```py\n len(doc)\n4\n```", "```py\n doc = nlp(\"This is a sentence. This is the second sentence\")\n doc.sents\n<generator object at 0x7f21dc565948>\n sentences = list(doc.sents)\n sentences\n[\"This is a sentence.\", \"This is the second sentence.\"]\n```", "```py\n doc = nlp(\"I flied to New York with Ashley.\")\n doc.ents\n(New York, Ashley)\n```", "```py\n doc = nlp(\"Sweet brown fox jumped over the fence.\")\n list(doc.noun_chunks)\n[Sweet brown fox, the fence]\n```", "```py\n doc.lang_\n'en'\n```", "```py\n doc = nlp(\"Hi\")\n json_doc = doc.to_json()\n{\n  \"text\": \"Hi\",\n  \"ents\": [],\n  \"sents\": [{\"start\": 0, \"end\": 3}],\n  \"tokens\": [{\"id\": 0, \"start\": 0, \"end\": 3, \"pos\": \"INTJ\", \"tag\": \"UH\", \"dep\": \"ROOT\", \"head\": 0}]\n}\n```", "```py\n doc = nlp(\"Hello Madam!\")\n doc[0]\nHello\n```", "```py\n doc[0].text\nHello\n```", "```py\n doc[0].text_with_ws\n'Hello '\n doc[2].text_with_ws\n'!\"\n```", "```py\n len(doc[0])\n5\n```", "```py\n token = doc[2]\n token.i\n2\n```", "```py\n doc[0].idx\n0\n doc[1].idx\n6\n```", "```py\n token = doc[0]\n token.doc\nHello Madam!\n```", "```py\n token = doc[1]\n token.sent\nHello Madam!\n```", "```py\n doc = nlp(\"He entered the room. Then he nodded.\")\n doc[0].is_sent_start\nTrue\n doc[5].is_sent_start\nTrue\n doc[6].is_sent_start\nFalse\n```", "```py\n doc = nlp(\"I went there.\")\n doc[1].lemma_\n'go'\n```", "```py\n doc = nlp(\"President Trump visited Mexico City.\")\n doc.ents\n(Trump, Mexico City)\n doc[1].ent_type_\n'PERSON'\n doc[3].ent_type_\n'GPE'  # country, city, state\n doc[4].ent_type_\n'GPE'  # country, city, state\n doc[0].ent_type_\n''  # not an entity\n```", "```py\n doc = nlp(\"I know that you have been to USA.\")\n doc[2:4]\n\"that you\"\n```", "```py\n doc = nlp(\"President Trump visited Mexico City.\")\n doc[4:]  # end index empty means rest of the string\nCity.\n doc[3:-1]  # minus indexes are supported\n doc[6:]\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"span.pyx\", line 166, in spacy.tokens.span.Span.__repr__\n  File \"span.pyx\", line 503, in spacy.tokens.span.Span.text.__get__\n  File \"span.pyx\", line 190, in spacy.tokens.span.Span.__getitem__\nIndexError: [E201] Span index out of range.\n doc[1:1]  # empty spans are not allowed\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"span.pyx\", line 166, in spacy.tokens.span.Span.__repr__\n  File \"span.pyx\", line 503, in spacy.tokens.span.Span.text.__get__\n  File \"span.pyx\", line 190, in spacy.tokens.span.Span.__getitem__\nIndexError: [E201] Span index out of range.\n```", "```py\n doc = nlp(\"You love Atlanta since you're 20.\")\n doc.char_span(4, 16)\nlove Atlanta\n```", "```py\n doc = nlp(\"You went there after you saw me\")\n span = doc[2:4]\n for token in span:\n     print(token)\nthere\nafter\n```", "```py\n doc = nlp(\"Hello Madam!\")\n span = doc[1:2]\n len(span)\n1\n```", "```py\n doc = nlp(\"You went there after you saw me\")\n span = doc[2:6]\n span \nthere after you saw\n subspan = span[1:3]\nafter you\n```", "```py\n doc = nlp(\"You went there after you saw me\")\n span = doc[2:6]\n span.char_span(15,24)\nafter you\n```", "```py\n doc = nlp(\"You went there after you saw me\")\n span = doc[2:6]\n span.doc\nYou went there after you saw me\n span.sent\nYou went there after you saw me\n```", "```py\n doc = nlp(\"You went there after you saw me\")\n span = doc[2:6]\n span.start\n2\n span.end\n6\n span.start_char\n9\n span.end_char\n28\n```", "```py\n doc = nlp(\"You went there after you saw me\") \n span = doc[2:6]\n type(span)\n<class 'spacy.tokens.span.Span'>\n small_doc = span.as_doc()\n type(small_doc)\n<class 'spacy.tokens.doc.Doc'>\n```", "```py\n doc = nlp(\"Hello, hi!\")\n doc[0].lower_\n'hello'\n```", "```py\n doc = nlp(\"HELLO, Hello, hello, hEllO\")\n doc[0].is_upper\nTrue\n doc[0].is_lower\nFalse\n doc[1].is_upper\nFalse\n doc[1].is_lower\nFalse\n```", "```py\ndoc = nlp(\"Cat and Cat123\")\n doc[0].is_alpha\nTrue\n doc[2].is_alpha\nFalse\n```", "```py\n doc = nlp(\"Hamburg and Göttingen\")\n doc[0].is_ascii\nTrue\n doc[2].is_ascii\nFalse\n```", "```py\n doc = nlp(\"Cat Cat123 123\")\n doc[0].is_digit\nFalse\n doc[1].is_digit\nFalse\n doc[2].is_digit\nTrue\n```", "```py\n doc = nlp(\"You, him and Sally\")\n doc[1]\n,\n doc[1].is_punct\nTrue\n```", "```py\ndoc = nlp(\"( [ He said yes. ] )\")\ndoc[0]\n(\ndoc[0].is_left_punct\nTrue\ndoc[1]\n[\ndoc[1].is_left_punct\nTrue\ndoc[-1]\n)\ndoc[-1].is_right_punct\nTrue\ndoc[-2]\n]\ndoc[-2].is_right_punct\nTrue\n```", "```py\n doc = nlp(\" \")\n doc[0]\n len(doc[0])\n1\n doc[0].is_space\nTrue\n doc = nlp(\"  \")\n doc[0]\n len(doc[0])\n2\n doc[0].is_space\nTrue\n```", "```py\n doc = nlp(\"( You said [1] and {2} is not applicable.)\")\n doc[0].is_bracket, doc[-1].is_bracket\n(True, True)\n doc[3].is_bracket, doc[5].is_bracket\n(True, True)\n doc[7].is_bracket, doc[9].is_bracket\n(True, True)\n```", "```py\n doc = nlp(\"( You said '1\\\" is not applicable.)\")\n doc[3]\n'\n doc[3].is_quote\nTrue\n doc[5]\n\"\n doc[5].is_quote\nTrue\n```", "```py\n doc = nlp(\"I paid 12$ for the tshirt.\")\n doc[3]\n$\n doc[3].is_currency\nTrue\n```", "```py\n doc = nlp(\"I emailed you at least 100 times\")\n doc[-2]\n100\n doc[-2].like_num\nTrue\n doc = nlp(\"I emailed you at least hundred times\")\n doc[-2]\nhundred\n doc[-2].like_num\nTrue doc = nlp(\"My email is duygu@packt.com and you can visit me under https://duygua.github.io any time you want.\")\n doc[3]\nduygu@packt.com\n doc[3].like_email\nTrue\n doc[10]\nhttps://duygua.github.io/\n doc[10].like_url\nTrue\n```", "```py\n doc = nlp(\"Girl called Kathy has a nickname Cat123.\")\n for token in doc:\n     print(token.text, token.shape_)\nGirl Xxxx\ncalled xxxx\nKathy Xxxxx\nhas xxx\na x\nnickname xxxx\nCat123 Xxxddd\n. .\n```", "```py\n doc = nlp(\"I visited Jenny at Mynks Resort\")\n for token in doc:\n     print(token, token.is_oov)\nI False\nvisited False\nJenny False\nat False\nMynks True\nResort False\n```", "```py\n doc = nlpI just want to inform you that I was with the principle.\")\n for token in doc:\n     print(token, token.is_stop)\nI True\njust True\nwant False\nto True\ninform False\nyou True\nthat True\nI True\nwas True\nwith True\nthe True\nprinciple False\n. False\n```"]