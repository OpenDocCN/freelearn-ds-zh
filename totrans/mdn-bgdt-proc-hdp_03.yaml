- en: Hadoop Design Consideration
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Hadoop 设计考虑因素
- en: Big data does not necessarily mean huge data. If a dataset is small, it's very
    easy to analyze it. We can load it on to an Excel spreadsheet and do the required
    calculations. But, as the volume of data gets bigger, we have to find other alternatives
    to process it. We may have to load it to an RDMBS table and run a SQL query to
    find the trend and patterns on the given structure. Further, if the dataset format
    changes to something like email, then loading to RDBMS becomes a huge challenge.
    To add more complexity to it, if the data speed changes to something like real
    time, it becomes almost impossible to analyze the given dataset with traditional
    RDBMS-based tools. In the modern world, the term *big data* can be expressed using
    the five most famous *V*s. Following is the explanation of each *V* in a nutshell.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 大数据并不一定意味着大量数据。如果数据集很小，分析它非常容易。我们可以将其加载到 Excel 电子表格中，并进行所需的计算。但是，随着数据量的增加，我们必须找到其他替代方案来处理它。我们可能需要将其加载到
    RDMBS 表中，并运行 SQL 查询以在给定的结构上找到趋势和模式。此外，如果数据集格式变为类似电子邮件的格式，那么将其加载到 RDBMS 中将是一个巨大的挑战。更复杂的是，如果数据速度变为类似实时，使用传统的基于
    RDBMS 的工具分析给定的数据集几乎是不可能的。在现代社会，*大数据*这个术语可以用五个最著名的 *V* 来表达。以下是对每个 *V* 的简要说明。
- en: '![](img/21dfce7d-6161-4729-94cb-0e9c871736e3.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/21dfce7d-6161-4729-94cb-0e9c871736e3.png)'
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Data structure principles
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据结构原则
- en: Installing Hadoop cluster
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装 Hadoop 集群
- en: Exploring Hadoop architecture
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索 Hadoop 架构
- en: Introducing YARN
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍 YARN
- en: Hadoop cluster composition
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hadoop 集群组成
- en: Hadoop file formats
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hadoop 文件格式
- en: Understanding data structure principles
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解数据结构原则
- en: 'Let''s go through some important data architecture principles:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一些重要的数据架构原则：
- en: '**Data is an asset to an enterprise**: Data has a measurable value. It provides
    some real value to the enterprise. In modern times, data is treated like real
    gold.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据是企业的一项资产**：数据具有可衡量的价值。它为企业提供了实际的价值。在现代社会，数据被视为真正的黄金。'
- en: '**Data is shared enterprise-wide**: Data is captured only once and then used
    and analyzed many times. Multiple users access the same data for different uses
    cases and requirements.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据是全企业共享的**：数据只被捕获一次，然后被多次使用和分析。多个用户可以访问相同的数据，用于不同的用例和需求。'
- en: '**Data governance**: Data is governed to ensure data quality.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据治理**：数据得到治理以确保数据质量。'
- en: '**Data management**: Data needs to be managed to attain enterprise objectives.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据管理**：需要管理数据以实现企业目标。'
- en: '**Data access**: All users should have access to data.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据访问**：所有用户都应有权访问数据。'
- en: '**Data security**: Data should be properly secured and protected.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据安全**：数据应该得到适当的保护和保护。'
- en: '**Data definition**: Each attribute of the data needs to be consistently defined
    enterprise-wide.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据定义**：数据中的每个属性都需要在企业范围内保持一致的定义。'
- en: Now that we know the basics of big data and its principles, let's get into some
    real action.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经了解了大数据及其原理的基础，让我们开始一些实际操作。
- en: Installing Hadoop cluster
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装 Hadoop 集群
- en: The following steps need to be performed in order to install Hadoop cluster.
    As the time of writing this book, Hadoop Version 2.7.3 is a stable release. We
    will install it.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 需要执行以下步骤来安装 Hadoop 集群。在撰写本书时，Hadoop 版本 2.7.3 是一个稳定的版本。我们将安装它。
- en: 'Check the Java version using the following command:'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令检查 Java 版本：
- en: '[PRE0]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Create a Hadoop user account on all the servers, including all NameNodes and
    DataNodes with the help of the following commands:'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在所有服务器上创建 Hadoop 用户账户，包括所有 NameNodes 和 DataNodes，可以使用以下命令：
- en: '[PRE1]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Assume that we have four servers and we have to create a Hadoop cluster using
    all four servers. The IPs of these four servers are as follows: `192.168.11.1`,
    `192.168.11.2`, `192.168.11.3`, and `192.168.11.4`. Out of these four servers,
    we will first use a server as a master server (NameNode) and all remaining servers
    will be used as slaves (DataNodes).'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们拥有四台服务器，我们必须使用这四台服务器创建一个 Hadoop 集群。这四台服务器的 IP 地址如下：`192.168.11.1`、`192.168.11.2`、`192.168.11.3`
    和 `192.168.11.4`。在这四台服务器中，我们将首先使用一台服务器作为主服务器（NameNode），其余所有服务器将用作从服务器（DataNodes）。
- en: 'On both servers, NameNode and DataNodes, change the `/etc/hosts` file using
    the following command:'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在两个服务器上，NameNode 和 DataNodes，使用以下命令更改 `/etc/hosts` 文件：
- en: '[PRE2]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Then add the following to all files on all servers:'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后将以下内容添加到所有服务器上的所有文件中：
- en: '[PRE3]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now, set up SSH on NamesNodes and DataNodes:'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，在 NameNodes 和 DataNodes 上设置 SSH：
- en: '[PRE4]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Download and install Hadoop on NameNode and all DataNodes:'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 NameNode 和所有 DataNodes 上下载并安装 Hadoop：
- en: '[PRE5]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Configuring Hadoop on NameNode
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在NameNode上配置Hadoop
- en: 'Log in to NameNode:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 登录到NameNode：
- en: '[PRE6]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Find and change the following properties with these values:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 找到并更改以下属性为这些值：
- en: '| **Filename** | **Property name** | **Property value** |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| **Filename** | **属性名称** | **属性值** |'
- en: '| `core-site.xml` |  `fs.default.name` |  `hdfs://namenode:9000/` |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| `core-site.xml` |  `fs.default.name` |  `hdfs://namenode:9000/` |'
- en: '|  | `dfs.permissions` |  `False` |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '|  | `dfs.permissions` |  `False` |'
- en: '| `hdfs-site.xml` | `dfs.data.dir` | `/opt/hadoop/hadoop/dfs/namenode/data`
    |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| `hdfs-site.xml` | `dfs.data.dir` | `/opt/hadoop/hadoop/dfs/namenode/data`
    |'
- en: '|  | `dfs.name.dir` | `/opt/hadoop/hadoop/dfs/namenode` |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '|  | `dfs.name.dir` | `/opt/hadoop/hadoop/dfs/namenode` |'
- en: '|  | `dfs.replication` | `1` |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '|  | `dfs.replication` | `1` |'
- en: '| `mapred-site.xml` | `mapred.job.tracker` | `namenode:9001 ` |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| `mapred-site.xml` | `mapred.job.tracker` | `namenode:9001 ` |'
- en: '[PRE7]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Format NameNode
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 格式化NameNode
- en: 'The following code is used to format the NameNode:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码用于格式化NameNode：
- en: '[PRE8]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Start all services
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 启动所有服务
- en: 'We start all the services with the following line of code:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用以下代码行启动所有服务：
- en: '[PRE9]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: For details about how to set up a Hadoop single-node and multi-node cluster,
    please use the following link: [https://hadoop.apache.org/docs/r2.7.0/hadoop-project-dist/hadoop-common/ClusterSetup.html](https://hadoop.apache.org/docs/r2.7.0/hadoop-project-dist/hadoop-common/ClusterSetup.html).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 关于如何设置Hadoop单节点和多节点集群的详细信息，请使用以下链接： [https://hadoop.apache.org/docs/r2.7.0/hadoop-project-dist/hadoop-common/ClusterSetup.html](https://hadoop.apache.org/docs/r2.7.0/hadoop-project-dist/hadoop-common/ClusterSetup.html).
- en: Exploring HDFS architecture
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索HDFS架构
- en: The HDFS architecture is based on master and slave patterns. NameNode is a master
    node and all DataNodes are SlaveNodes. Following are some important points to
    be noted about these two nodes.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: HDFS架构基于主从模式。NameNode是主节点，所有DataNode都是从节点。以下是一些关于这两个节点的重要注意事项。
- en: Defining NameNode
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义NameNode
- en: The NameNode is a master node of all DataNodes in the Hadoop cluster. It stores
    only the metadata of files and directories stored in the form of a tree. The important
    point is NameNode never stores any other data other than metadata. NameNode keeps
    track of all data written to DataNodes in the form of blocks. The default block
    size is 256 MB (which is configurable). Without the NameNode, the data on the
    DataNodes filesystem cannot be read. The metadata is stored locally on the NameNode
    using two files—filesystem namespace image file, FSImage, and edit logs. FSImage
    is the snapshot of the filesystem from the start of the NameNode edit logs—all
    the changes of the filesystem since the NameNode started, when the NameNode starts,
    it reads FSImage file and edits log files. All the transactions (edits) are merged
    into the FSImage file. The FSImage file is written to disk and a new, empty edits
    log file is created to log all the edits. Since NameNode is not restarted very
    often, the edits log file becomes very large and unmanageable. When NameNode is
    restarted, it takes a very long time to restart it as all the edits need to be
    applied to the FSImage file. In the event of NameNode crashing, all the metadata
    in the edits log file will not be written to the FSImage file and will be lost.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: NameNode是Hadoop集群中所有DataNode的主节点。它仅以树形结构存储文件的元数据。重要的是NameNode永远不会存储除元数据以外的任何其他数据。NameNode以块的形式跟踪写入DataNode的所有数据。默认块大小为256
    MB（可配置）。没有NameNode，DataNode文件系统上的数据无法读取。元数据存储在NameNode上，使用两个文件——文件系统命名空间镜像文件FSImage和编辑日志。FSImage是NameNode编辑日志开始时的文件系统快照——自NameNode启动以来文件系统的所有更改，当NameNode启动时，它读取FSImage文件和编辑日志文件。所有事务（编辑）都合并到FSImage文件中。FSImage文件写入磁盘，并创建一个新的空编辑日志文件以记录所有编辑。由于NameNode不经常重启，编辑日志文件变得非常大且难以管理。当NameNode重启时，由于所有编辑都需要应用到FSImage文件，因此重启需要非常长的时间。在NameNode崩溃的情况下，编辑日志文件中的所有元数据将不会写入FSImage文件，并将丢失。
- en: Secondary NameNode
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 次要NameNode
- en: The name secondary NameNode is confusing. It does not act as a NameNode. Its
    main function is to get the filesystem changes from the NameNode and merge it
    to NameNode FSImage at regular intervals. Writing edits log file changes to FSImage
    are called **commits**. Regular commits help to reduce the NameNode start time.
    The secondary NameNode is also known as the commit node.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 次要NameNode的名称令人困惑。它并不充当NameNode。其主要功能是定期从NameNode获取文件系统更改并将其合并到NameNode的FSImage中。将编辑日志文件更改写入FSImage的操作称为**提交**。定期的提交有助于减少NameNode的启动时间。次要NameNode也被称为提交节点。
- en: NameNode safe mode
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: NameNode安全模式
- en: It is a read-only mode for the HDFS cluster. Clients are not allowed any modifications
    to the filesystem or blocks. During startup, NameNode automatically starts in
    safe mode, applies edits to FSImage, disables safe mode automatically, and restarts
    in normal mode.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这是HDFS集群的只读模式。客户端不允许对文件系统或块进行任何修改。在启动时，NameNode自动以安全模式启动，应用对FSImage的编辑，自动禁用安全模式，并以正常模式重新启动。
- en: DataNode
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: DataNode
- en: DataNodes are the workhorses of the Hadoop cluster. Their main function is to
    store and retrieve data in the form of blocks. They always communicate their status
    to the NameNode in the form of heartbeats. That's how NameNode keeps track of
    any DataNodes, whether they are alive or dead. DataNodes keep three copies of
    the blocks known and the replication factor. DataNodes communicate with other
    DataNodes to copy data blocks to maintain data replication.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: DataNodes是Hadoop集群的功臣。它们的主要功能是以块的形式存储和检索数据。它们总是以心跳的形式向NameNode报告其状态。这就是NameNode如何跟踪任何DataNodes，无论它们是活着还是死了。DataNodes保持三个已知块的副本和复制因子。DataNodes与其他DataNodes通信，以复制数据块来维护数据复制。
- en: Data replication
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据复制
- en: HDFS architecture supports placing very large files across the machines in a
    cluster. Each file is stored as a series of blocks. In order to ensure fault tolerance,
    each block is replicated three times to three different machines. It is known
    as a replication factor, which can be changed at the cluster level or at the individual
    file level. It is a NameNode that makes all the decisions related to block replication.
    NameNode gets heartbeat and block reports from each DataNode. Heartbeat makes
    sure that the DataNode is alive. A block report contains a list of all blocks
    on a DataNode.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: HDFS架构支持在集群的机器上放置非常大的文件。每个文件都存储为一系列块。为了确保容错性，每个块被复制三次到三台不同的机器上。这被称为复制因子，可以在集群级别或单个文件级别进行更改。是NameNode做出所有与块复制相关的决策。NameNode从每个DataNode获取心跳和块报告。心跳确保DataNode是活着的。块报告包含一个DataNode上所有块的列表。
- en: Rack awareness
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机架感知
- en: 'HDFS block placement will use rack awareness for fault tolerance by placing
    one block replica on a different rack, as shown in the following diagram:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: HDFS块放置将使用机架感知来提高容错性，将一个块副本放置在不同的机架上，如下图所示：
- en: '![](img/aba679b2-4019-46ed-aea6-8d2e45428bae.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](img/aba679b2-4019-46ed-aea6-8d2e45428bae.png)'
- en: 'Let''s understand the figure in detail:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们详细理解这个图：
- en: The first replica is placed on the same rack as the initiating request DataNode,
    for example, Rack 1 and DataNode 1
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一个副本被放置在发起请求的DataNode所在的同一机架上，例如，机架1和DataNode 1
- en: The second replica is placed on any DataNode of another rack, for example, Rack
    2, DataNode 2
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二个副本被放置在另一个机架上的任意DataNode上，例如，机架2，DataNode 2
- en: The third replica is placed on any DataNode of the same rack, for example, Rack
    2, DataNode 3
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第三个副本被放置在相同机架上的任意DataNode上，例如，机架2，DataNode 3
- en: A custom rack topology script, which contains an algorithm to select appropriate
    DataNodes, can be developed using a Unix shell, Java, or Python. It can be activated
    on the cluster by changing the `topology.script.file.name` parameter in `Core-site.xml`
    file.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用Unix shell、Java或Python开发一个自定义的机架拓扑脚本，该脚本包含一个选择适当DataNodes的算法。它可以通过更改`Core-site.xml`文件中的`topology.script.file.name`参数在集群中激活。
- en: HDFS WebUI
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: HDFS WebUI
- en: 'The following table shows the services in the HDFS WebUI:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 下表显示了HDFS WebUI中的服务：
- en: '| **Service** | **Protocol** | **Port** | **URL** |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| **服务** | **协议** | **端口** | **URL** |'
- en: '| NameNode WebUI | HTTP | `50070` | `http://namenode:50070/` |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| NameNode WebUI | HTTP | `50070` | `http://namenode:50070/` |'
- en: '| DataNode WebUI | HTTP | `50075` | `http://datanode:50075/` |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| DataNode WebUI | HTTP | `50075` | `http://datanode:50075/` |'
- en: '| Secondary NameNode | HTTP | `50090` | `http://Snamenode:50090/` |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| Secondary NameNode | HTTP | `50090` | `http://Snamenode:50090/` |'
- en: Introducing YARN
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍YARN
- en: The **Yet Another Resource Negotiator** (**YARN**) separates the resource management,
    scheduling, and processing components. It helps to achieve 100% resource utilization
    of the cluster resources. YARN manages the CPU and memory of the cluster based
    on the Hadoop scheduler policy. YARN supports any type of application and is not
    restricted to just MapReduce. It supports applications written in any type of
    language, provided binaries can be installed on the Hadoop cluster.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '**YARN（Yet Another Resource Negotiator**）将资源管理、调度和处理组件分离。它有助于实现集群资源的100%利用率。YARN根据Hadoop调度策略管理集群的CPU和内存。YARN支持任何类型的应用程序，而不仅限于MapReduce。它支持用任何类型的语言编写的应用程序，前提是可以在Hadoop集群上安装二进制文件。'
- en: YARN architecture
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: YARN架构
- en: Let's understand the YARN architecture in detail in the following sections.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的几节中，我们将详细理解 YARN 架构。
- en: Resource manager
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 资源管理器
- en: 'The resource manager is responsible for tracking the resources in a cluster
    and scheduling applications. The resource manager has two main components: the
    scheduler and the applications manager.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 资源管理器负责跟踪集群中的资源并调度应用程序。资源管理器有两个主要组件：调度器和应用程序管理器。
- en: Node manager
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 节点管理器
- en: The node manager is responsible for launching and managing containers on a node.
    Containers execute tasks as specified by the application master. It acts as a
    slave for the resource manager. Each node manager tracks the available data processing
    resources on its SlaveNode and sends regular reports to the resource manager.
    The processing resources in a Hadoop cluster are consumed in byte-size pieces
    called **containers**.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 节点管理器负责在节点上启动和管理容器。容器执行应用程序主指定的任务。它作为资源管理器的从属。每个节点管理器跟踪其 SlaveNode 上可用的数据处理资源，并向资源管理器发送定期报告。Hadoop
    集群中的处理资源以称为**容器**的字节大小块消耗。
- en: Configuration of YARN
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: YARN 配置
- en: 'You can perform the following steps for the configuration of YARN:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以执行以下步骤来配置 YARN：
- en: Start Hadoop NameNode, secondary NameNode, and DataNode
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动 Hadoop NameNode、辅助 NameNode 和 DataNode
- en: Alter `yarn-env.sh`.
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 修改 `yarn-env.sh`。
- en: Find corresponding XML files based on your Hadoop installation.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 根据您的 Hadoop 安装查找相应的 XML 文件。
- en: 'Add the following under the definition of `YARN_CONF_DIR`:'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `YARN_CONF_DIR` 的定义下添加以下内容：
- en: '[PRE10]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Alter `yarn-site.xml`:'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 修改 `yarn-site.xml`：
- en: '[PRE11]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Alter `mapred-site.xml`:'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 修改 `mapred-site.xml`：
- en: '[PRE12]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Start the YARN services:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动 YARN 服务：
- en: '[PRE13]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Configuring HDFS high availability
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置 HDFS 高可用性
- en: Let's take a look at the changes brought about in Hadoop over time.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看 Hadoop 随时间带来的变化。
- en: During Hadoop 1.x
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 Hadoop 1.x 期间
- en: Hadoop 1.x started with the architecture of a single NameNode. All DataNodes
    used to send their block reports to that single NameNode. There was a secondary
    NameNode in the architecture, but its sole responsibility was to merge all edits
    to FSImage. With this architecture, the NameNode became the **single point of
    failure** (**SPOF**). Since it has all the metadata of all the DataNodes of the
    Hadoop cluster, in the event of NameNode crash, the Hadoop cluster becomes unavailable
    till the next restart of NameNode repair. If the NameNode cannot be recovered,
    then all the data in all the DataNodes would be completely lost. In the event
    of shutting down NameNode for planned maintenance, the HDFS becomes unavailable
    for normal use. Hence, it was necessary to protect the existing NameNode by taking
    frequent backups of the NameNode filesystem to minimize data loss.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: Hadoop 1.x 从单个 NameNode 架构开始。所有 DataNode 都会将它们的块报告发送到该单个 NameNode。架构中有一个辅助 NameNode，但它的唯一责任是合并所有对
    FSImage 的编辑。在这种架构中，NameNode 成为了**单点故障**（SPOF）。由于它拥有 Hadoop 集群中所有 DataNode 的元数据，在
    NameNode 崩溃的情况下，Hadoop 集群将无法使用，直到 NameNode 重新启动并修复。如果 NameNode 无法恢复，那么所有 DataNode
    中的所有数据都将完全丢失。在计划维护时关闭 NameNode，HDFS 将无法用于正常使用。因此，有必要通过频繁备份 NameNode 文件系统来保护现有的
    NameNode，以最大限度地减少数据丢失。
- en: During Hadoop 2.x and onwards
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从 Hadoop 2.x 及以后版本开始
- en: 'In order to overcome HDFS **high availability** (**HA**) problems and make
    NameNode a SPOF, the architecture has changed. The new architecture provides a
    running of two redundant NameNodes in the same cluster in an active/passive configuration
    with a hot standby. This allows a fast failover to a new NameNode in the event
    of a machine crashing, or a graceful administrator-initiated failover for the
    purpose of planned maintenance. The following two architectural options are provided
    for HDFS HA:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 为了克服 HDFS **高可用性**（HA）问题并使 NameNode 成为 SPOF，架构已经改变。新的架构提供了在同一集群中运行两个冗余 NameNode
    的能力，采用活动/被动配置和热备用。这允许在机器崩溃的情况下快速切换到新的 NameNode，或者为了计划维护而进行的优雅的由管理员启动的故障转移。以下提供了两种
    HDFS HA 架构选项：
- en: Using shared storage
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用共享存储
- en: Using quorum journal manager
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用法定多数日志管理器
- en: HDFS HA cluster using NFS
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 NFS 的 HDFS HA 集群
- en: 'The following diagram depicts the HDFS HA cluster using NFS for shared storage
    required by the NameNodes architecture:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图展示了使用 NFS 作为共享存储的 HDFS HA 集群，该存储是 NameNodes 架构所需的：
- en: '![](img/6b9bba22-b44f-4c0c-91b9-00fc64bd9794.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/6b9bba22-b44f-4c0c-91b9-00fc64bd9794.png)'
- en: Important architecture points
  id: totrans-112
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 重要架构要点
- en: 'Following are some important points to remember about the HDFS HA using shared
    storage architecture:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用共享存储架构的 HDFS 高可用性（HA）中，以下是一些需要记住的重要要点：
- en: 'In the cluster, there are two separate machines: active state NameNode and
    standby state NameNode.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在集群中，有两台独立的机器：活动状态NameNode和备用状态NameNode。
- en: At any given point in time, one-and-only, one of the NameNodes is in the active
    state, and the other is in the standby state.
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在任何给定时间点，只有一个NameNode处于活动状态，另一个处于备用状态。
- en: The active NameNode manages the requests from all client DataNodes in the cluster,
    while the standby remains a slave.
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 活动NameNode管理集群中所有客户端DataNode的请求，而备用节点保持为从属状态。
- en: All the DataNodes are configured in such a way that they send their block reports
    and heartbeats to both the active and standby NameNodes.
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有DataNode都配置为向活动NameNode和备用NameNode发送其块报告和心跳。
- en: The standby NameNode keeps its state synchronized with the active NameNode.
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 备用NameNode保持其状态与活动NameNode同步。
- en: Active and standby nodes both have access to a filesystem on a shared storage
    device (for example, an NFS mount from a NAS)
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 活动节点和备用节点都可以访问共享存储设备上的文件系统（例如，从NAS的NFS挂载）
- en: When a client makes any filesystem change, the active NameNode makes the corresponding
    change (edits) to the edit log file residing on the network shared directory.
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当客户端进行任何文件系统更改时，活动NameNode会将相应的更改（编辑）应用到位于网络共享目录上的编辑日志文件中。
- en: The standby NameNode makes all the corresponding changes to its own namespace.
    That way, it remains in sync with the active NameNode.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 备用NameNode对其自己的命名空间进行所有相应的更改。这样，它就与活动NameNode保持同步。
- en: In the event of the active NameNode being unavailable, the standby NameNode
    makes sure that it absorbs all the changes (edits) from the shared network directory
    and promotes itself to an active NameNode.
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在活动NameNode不可用的情况下，备用NameNode确保它从共享网络目录吸收所有更改（编辑），并将其提升为活动NameNode。
- en: The Hadoop administrator should apply the fencing method to the shared storage
    to avoid a scenario that makes both the NameNodes active at a given time. In the
    event of failover, the fencing method cuts the access to the previous active NameNode
    to make any changes to the shared storage to ensure smooth failover to standby
    NameNode. After that, the standby NameNode becomes the active NameNode.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hadoop管理员应将隔离方法应用于共享存储，以避免同时使两个NameNode处于活动状态的场景。在故障转移的情况下，隔离方法切断对先前活动NameNode的访问，以确保对共享存储的更改顺利转移到备用NameNode。之后，备用NameNode成为活动NameNode。
- en: Configuration of HA NameNodes with shared storage
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置具有共享存储的HA NameNode
- en: 'Add the following properties to the `hdfs-site.xml`:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 将以下属性添加到`hdfs-site.xml`中：
- en: '| **Property** | **Value** |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| **属性** | **值** |'
- en: '| `dfs.nameservices` | `cluster_name` |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| `dfs.nameservices` | `cluster_name` |'
- en: '| `dfs.ha.namenodes.cluster_name` | `NN1`, `NN2` |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| `dfs.ha.namenodes.cluster_name` | `NN1`, `NN2` |'
- en: '| `dfs.namenode.rpc-address.cluster_name.NN1` | `machine1:8020` |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| `dfs.namenode.rpc-address.cluster_name.NN1` | `machine1:8020` |'
- en: '| `dfs.namenode.rpc-address.cluster_name.NN2` | `machine2:8020` |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| `dfs.namenode.rpc-address.cluster_name.NN2` | `machine2:8020` |'
- en: '| `dfs.namenode.http-address.cluster_name.NN1` | `machine1:50070` |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| `dfs.namenode.http-address.cluster_name.NN1` | `machine1:50070` |'
- en: '| `dfs.namenode.http-address.cluster_name.NN2` | `machine2:50070` |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| `dfs.namenode.http-address.cluster_name.NN2` | `machine2:50070` |'
- en: '| `dfs.namenode.shared.edits.dir` | `file:///mnt/filer1/dfs/ha-name-dir-shared`
    |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| `dfs.namenode.shared.edits.dir` | `file:///mnt/filer1/dfs/ha-name-dir-shared`
    |'
- en: '| `dfs.client.failover.proxy.provider.cluster_name` | `org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider`
    |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| `dfs.client.failover.proxy.provider.cluster_name` | `org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider`
    |'
- en: '| `dfs.ha.fencing.methods` | `sshfence` |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| `dfs.ha.fencing.methods` | `sshfence` |'
- en: '| `dfs.ha.fencing.ssh.private-key-files` | `/home/myuser/.ssh/id_rsa` |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| `dfs.ha.fencing.ssh.private-key-files` | `/home/myuser/.ssh/id_rsa` |'
- en: '| `dfs.ha.fencing.methods` | `sshfence([[username][:port]])` |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| `dfs.ha.fencing.methods` | `sshfence([[username][:port]])` |'
- en: '| `dfs.ha.fencing.ssh.connect-timeout` | `30000` |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| `dfs.ha.fencing.ssh.connect-timeout` | `30000` |'
- en: 'Add the following properties to `core-site.xml`:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 将以下属性添加到`core-site.xml`中：
- en: '| **Property** | **Value** |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| **属性** | **值** |'
- en: '| `fs.defaultFS` | `hdfs://cluster_name` |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| `fs.defaultFS` | `hdfs://cluster_name` |'
- en: HDFS HA cluster using the quorum journal manager
  id: totrans-142
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Quorum Journal Manager的HDFS HA集群
- en: 'The following diagram depicts the **quorum journal manager** (**QJM**) architecture
    to share edit logs between the active and standby NameNodes:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图展示了**Quorum Journal Manager**（**QJM**）架构，用于在活动NameNode和备用NameNode之间共享编辑日志：
- en: '![](img/d19fd8c6-61cf-47dc-b86b-a68d32a19151.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d19fd8c6-61cf-47dc-b86b-a68d32a19151.png)'
- en: Important architecture points
  id: totrans-145
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 重要架构点
- en: 'Following are some important points to remember about the HDFS HA using the
    QJM architecture:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是关于使用QJM架构的HDFS HA的一些重要要点：
- en: In the cluster, there are two separate machines—the active state NameNode and
    standby state NameNode.
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在集群中，有两个独立的机器——活动状态的NameNode和待机状态的NameNode。
- en: At any point in time, exactly one of the NameNodes is in an active state, and
    the other is in a standby state.
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在任何时刻，恰好有一个NameNode处于活动状态，另一个处于待机状态。
- en: The active NameNode manages the requests from all client DataNodes in the cluster,
    while the standby remains a slave.
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 活动NameNode管理集群中所有客户端DataNode的请求，而待机节点保持为从属状态。
- en: All the DataNodes are configured in such a way that they send their block reports
    and heartbeats to both active and standby NameNodes.
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有DataNode都配置为向活动NameNode和待机NameNode发送它们的块报告和心跳。
- en: Both NameNodes, active and standby, remain synchronized with each other by communicating
    with a group of separate daemons called **JournalNodes** (**JNs**).
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 活动和待机NameNode通过与一组称为**JournalNodes**（**JNs**）的独立守护进程通信，保持彼此的同步。
- en: When a client makes any filesystem change, the active NameNode durably logs
    a record of the modification to the majority of these JNs.
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当客户端进行任何文件系统更改时，活动状态的NameNode会持久地将修改记录日志记录到大多数JNs中。
- en: The standby node immediately applies those changes to its own namespace by communicating
    with JNs.
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 待机节点通过与JNs通信，立即将其更改应用到自己的命名空间中。
- en: In the event of the active NameNode being unavailable, the standby NameNode
    makes sure that it absorbs all the changes (edits) from JNs and promotes itself
    as an active NameNode.
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在活动NameNode不可用的情况下，待机NameNode确保从JNs吸收所有更改（编辑），并提升自己为活动NameNode。
- en: To avoid a scenario that makes both the NameNodes active at a given time, the
    JNs will only ever allow a single NameNode to be a writer at a time. This allows
    the new active NameNode to safely proceed with failover.
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了避免同时使两个NameNode处于活动状态的场景，JNs将只允许一个NameNode在某一时刻成为写者。这允许新的活动NameNode安全地进行故障转移。
- en: Configuration of HA NameNodes with QJM
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置使用QJM的HA NameNode
- en: 'Add the following properties to `hdfs-site.xml`:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 将以下属性添加到`hdfs-site.xml`中：
- en: '| **Property** | **Value** |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| **属性** | **值** |'
- en: '| `dfs.nameservices` | `cluster_name` |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| `dfs.nameservices` | `cluster_name` |'
- en: '| `dfs.ha.namenodes.cluster_name` | `NN1`, `NN2` |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| `dfs.ha.namenodes.cluster_name` | `NN1`, `NN2` |'
- en: '| `dfs.namenode.rpc-address.cluster_name.NN1` | `machine1:8020` |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| `dfs.namenode.rpc-address.cluster_name.NN1` | `machine1:8020` |'
- en: '| `dfs.namenode.rpc-address.cluster_name.NN2` | `machine2:8020` |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| `dfs.namenode.rpc-address.cluster_name.NN2` | `machine2:8020` |'
- en: '| `dfs.namenode.http-address.cluster_name.NN1` | `machine1:50070` |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| `dfs.namenode.http-address.cluster_name.NN1` | `machine1:50070` |'
- en: '| `dfs.namenode.http-address.cluster_name.NN2` | `machine2:50070` |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| `dfs.namenode.http-address.cluster_name.NN2` | `machine2:50070` |'
- en: '| `dfs.namenode.shared.edits.dir` | `qjournal://node1:8485;node2:8485;node3:8485/cluster_name`
    |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| `dfs.namenode.shared.edits.dir` | `qjournal://node1:8485;node2:8485;node3:8485/cluster_name`
    |'
- en: '| `dfs.client.failover.proxy.provider.cluster_name` | `org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider`
    |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| `dfs.client.failover.proxy.provider.cluster_name` | `org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider`
    |'
- en: '| `dfs.ha.fencing.methods` | `sshfence` |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| `dfs.ha.fencing.methods` | `sshfence` |'
- en: '| `dfs.ha.fencing.ssh.private-key-files` | `/home/myuser/.ssh/id_rsa` |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| `dfs.ha.fencing.ssh.private-key-files` | `/home/myuser/.ssh/id_rsa` |'
- en: '| `dfs.ha.fencing.methods` | `sshfence([[username][:port]])` |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| `dfs.ha.fencing.methods` | `sshfence([[用户名][:端口]])` |'
- en: '| `dfs.ha.fencing.ssh.connect-timeout` | `30000` |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| `dfs.ha.fencing.ssh.connect-timeout` | `30000` |'
- en: 'Add the following properties to `core-site.xml`:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 将以下属性添加到`core-site.xml`中：
- en: '| **Property** | **Value** |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| **属性** | **值** |'
- en: '| `fs.defaultFS` | `hdfs://cluster_name` |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| `fs.defaultFS` | `hdfs://cluster_name` |'
- en: '| `dfs.journalnode.edits.dir` | `/path/to/journal/node/local/datat` |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| `dfs.journalnode.edits.dir` | `/path/to/journal/node/local/datat` |'
- en: Automatic failover
  id: totrans-175
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自动故障转移
- en: It's very important to know that the above two architectures support only manual
    failover. In order to do automatic failover, we have to introduce two more components
    a ZooKeeper quorum, and the **ZKFailoverController** (**ZKFC**) process, and more
    configuration changes.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 非常重要的是要知道上述两种架构仅支持手动故障转移。为了实现自动故障转移，我们必须引入两个额外的组件：一个ZooKeeper集群和一个**ZKFailoverController**（**ZKFC**）进程，以及更多的配置更改。
- en: Important architecture points
  id: totrans-177
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 重要架构点
- en: Each NameNode, active and standby, runs the ZKFC process.
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个NameNode，无论是活动状态还是待机状态，都会运行ZKFC进程。
- en: The state of the NameNode is monitored and managed by the ZKFC.
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NameNode的状态由ZKFC监控和管理。
- en: The ZKFC pings its local NameNode periodically to make sure that that the NameNode
    is alive. If it doesn't get the ping back, it will mark that NameNode unhealthy.
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ZKFC 定期 ping 本地 NameNode，以确保 NameNode 是活跃的。如果它没有收到 ping 回复，它将标记该 NameNode 为不健康。
- en: The healthy NameNode holds a special lock. If the NameNode becomes unhealthy,
    that lock will be automatically deleted.
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 健康的 NameNode 持有一个特殊的锁。如果 NameNode 变得不健康，该锁将自动删除。
- en: If the local NameNode is healthy, and the ZKFC sees the lock is not currently
    held by any other NameNode, it will try to acquire the lock. If it is successful
    in acquiring the lock, then it has won the election. It is now the responsibility
    of this NameNode to run a failover to make its local NameNode active.
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果本地 NameNode 健康且 ZKFC 看到锁当前未被任何其他 NameNode 持有，它将尝试获取该锁。如果它成功获取锁，那么它赢得了选举。现在，这个
    NameNode 负责运行故障转移，使其本地 NameNode 激活。
- en: Configuring automatic failover
  id: totrans-183
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置自动故障转移
- en: 'Add the following properties to `hdfs-site.xml` to configure automatic failover:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 将以下属性添加到 `hdfs-site.xml` 以配置自动故障转移：
- en: '| **Property** | **Value** |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| **属性** | **值** |'
- en: '| `dfs.ha.automatic-failover.enabled` | `true` |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| `dfs.ha.automatic-failover.enabled` | `true` |'
- en: '| `ha.zookeeper.quorum` | `zk1:2181`, `zk2:2181`, `zk3:2181` |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '| `ha.zookeeper.quorum` | `zk1:2181`, `zk2:2181`, `zk3:2181` |'
- en: Hadoop cluster composition
  id: totrans-188
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Hadoop 集群组成
- en: 'As we know, a Hadoop cluster consists of master and slave servers: MasterNodes—to
    manage the infrastructure, and SlaveNodes—distributed data store and data processing.
    EdgeNodes are not a part of the Hadoop cluster. This machine is used to interact
    with the Hadoop cluster. Users are not given any permission to directly log in
    to any of the MasterNodes and DataNodes, but they can log in to the EdgeNode to
    run any jobs on the Hadoop cluster. No application data is stored on the EdgeNode.
    The data is always stored on the DataNodes on the Hadoop cluster. There can be
    more than one EdgeNode, depending on the number of users running jobs on the Hadoop
    cluster. If enough hardware is available, it''s always better to host each master
    and DataNode on a separate machine. But, in a typical Hadoop cluster, there are
    three MasterNodes.'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所知，一个 Hadoop 集群由主服务器和从服务器组成：主节点——管理基础设施，从节点——分布式数据存储和处理。边缘节点不是 Hadoop 集群的一部分。这台机器用于与
    Hadoop 集群交互。用户没有权限直接登录到任何主节点和数据节点，但他们可以登录到边缘节点以在 Hadoop 集群上运行任何作业。没有应用程序数据存储在边缘节点上。数据始终存储在
    Hadoop 集群的数据节点上。根据在 Hadoop 集群上运行作业的用户数量，可能会有多个边缘节点。如果硬件足够，始终最好将每个主节点和数据节点托管在不同的机器上。但在典型的
    Hadoop 集群中，有三个主节点。
- en: Please note that it is assumed that we are using HBase as a NoSQL datastore
    in our cluster.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们假设在集群中使用 HBase 作为 NoSQL 数据存储。
- en: Typical Hadoop cluster
  id: totrans-191
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 典型的 Hadoop 集群
- en: 'The Hadoop cluster composition will look like the following:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: Hadoop 集群的组成将如下所示：
- en: '![](img/d657d3de-3c51-464f-a724-3d74f6ff3430.png)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d657d3de-3c51-464f-a724-3d74f6ff3430.png)'
- en: 'The following are some hardware specifications to be taken into account:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些需要考虑的硬件规格：
- en: NameNode and standby NameNodes.
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NameNode 和备用 NameNode。
- en: The memory requirement depends on the number of files and block replicas to
    be created. Typically, at least 64 GB - 96 GB memory is recommended for NameNodes.
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内存需求取决于要创建的文件和块副本的数量。通常，建议 NameNodes 至少有 64 GB - 96 GB 的内存。
- en: NameNodes need reliable storage to host FSImage and edit logs. It is recommended
    that these MasterNodes should have at least 4 TB - 6 TB SAS storage. It is a good
    idea to have RAID 5 - 6 storage for NameNodes. If the cluster is a HA cluster,
    then plan your Hadoop cluster in such a way that JNs should be configured on the
    master node.
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NameNodes 需要可靠的存储来托管 FSImage 和编辑日志。建议这些主节点至少拥有 4 TB - 6 TB 的 SAS 存储。为 NameNodes
    配置 RAID 5 - 6 存储是一个好主意。如果集群是高可用集群，那么请这样规划您的 Hadoop 集群，即 JNs 应该配置在主节点上。
- en: As far as processors are concerned, it is recommended to have at least 2 quad
    core CPUs running at 2 GHz, to handle messaging traffic for the MasterNodes.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 就处理器而言，建议至少有 2 个运行在 2 GHz 的四核 CPU，以处理主节点的消息流量。
- en: DataNodes/SlaveNodes should have at least 64 GB RAM per node. It is recommended
    that, typically, 2 GB - 3 GB memory is required for each Hadoop daemon, such as
    DataNode, node manager ZooKeeper, and so on; 5 GB for OS and other services; and
    5 GB - 8 GB for each MapReduce task.
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据节点/从节点每个节点至少应有 64 GB RAM。通常，每个 Hadoop 守护进程（如数据节点、节点管理器 ZooKeeper 等）需要 2 GB
    - 3 GB 内存；操作系统和其他服务需要 5 GB；每个 MapReduce 作业需要 5 GB - 8 GB。
- en: DataNodes may have commodity storage with at least 8 TB - 10 TB disk storage
    with 7,200 RPM SATA drives. Hard disk configuration should be in **Just a Bunch
    Of Disks** (**JBOD**).
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DataNodes可能配备至少8 TB - 10 TB的磁盘存储，使用7200 RPM SATA驱动器。硬盘配置应该是**Just a Bunch Of
    Disks**（**JBOD**）。
- en: It is recommended to have at least 8 processors—2.5 GHz cores and 24 cores CPUs
    for all DataNodes.
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 建议所有DataNodes至少配备8个处理器——2.5 GHz核心和24核心CPU。
- en: It is recommended to have 1 GbE to 10 GbE network connectivity within each RACK.
    For all slaves, 1 GB network bandwidth, and for MasterNodes, 10 GB bandwidth is
    recommended.
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 建议每个机架内部具有1 GbE到10 GbE的网络连接。对于所有从节点，建议1 GB网络带宽，对于主节点，建议10 GB带宽。
- en: If you plan to expand your Hadoop cluster in future, you can also add additional
    machines.
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您计划在未来扩展您的Hadoop集群，您也可以添加额外的机器。
- en: 'Please read the following articles from Hortonworks and Cloudera for additional
    reference:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 请阅读以下来自Hortonworks和Cloudera的文章以获取更多信息：
- en: '[http://docs.hortonworks.com/HDPDocuments/HDP1/HDP-1.3.3/bk_cluster-planning-guide/content/conclusion.html](http://docs.hortonworks.com/HDPDocuments/HDP1/HDP-1.3.3/bk_cluster-planning-guide/content/conclusion.html)'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://docs.hortonworks.com/HDPDocuments/HDP1/HDP-1.3.3/bk_cluster-planning-guide/content/conclusion.html](http://docs.hortonworks.com/HDPDocuments/HDP1/HDP-1.3.3/bk_cluster-planning-guide/content/conclusion.html)'
- en: '[http://blog.cloudera.com/blog/2013/08/how-to-select-the-right-hardware-for-your-new-hadoop-cluster/](http://blog.cloudera.com/blog/2013/08/how-to-select-the-right-hardware-for-your-new-hadoop-cluster/)'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://blog.cloudera.com/blog/2013/08/how-to-select-the-right-hardware-for-your-new-hadoop-cluster/](http://blog.cloudera.com/blog/2013/08/how-to-select-the-right-hardware-for-your-new-hadoop-cluster/)'
- en: Best practices Hadoop deployment
  id: totrans-207
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Hadoop部署最佳实践
- en: 'Following are some best practices to be followed for Hadoop deployment:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些在Hadoop部署中应遵循的最佳实践：
- en: '**Start small**: Like other software projects, an implementation Hadoop also
    involves risks and cost. It''s always better to set up a small Hadoop cluster
    of four nodes. This small cluster can be set up as **proof of concept** (**POC**).
    Before using any Hadoop component, it can be added to the existing Hadoop POC
    cluster as **proof of technology** (**POT**). It allows the infrastructure and
    development team to understand big data project requirements. After successful
    completion of POC and POT, additional nodes can be added to the existing cluster.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**从小开始**：与其他软件项目一样，Hadoop的实施也涉及风险和成本。最好设置一个由四个节点组成的小型Hadoop集群。这个小集群可以作为一个**概念验证**（**POC**）。在使用任何Hadoop组件之前，它可以添加到现有的Hadoop
    POC集群中作为**技术验证**（**POT**）。这允许基础设施和开发团队了解大数据项目需求。在POC和POT成功完成后，可以添加额外的节点到现有集群。'
- en: '**Hadoop cluster monitoring**: Proper monitoring of the NameNode and all DataNodes
    is required to understand the health of the cluster. It helps to take corrective
    actions in the event of node problems. If a service goes down, timely action can
    help avoid big problems in the future. Setting up Gangalia and Nagios are popular
    choices to configure alerts and monitoring. In the case of the Hortonworks cluster,
    Ambari monitoring, and the Cloudera cluster, Cloudera (CDH) manager monitoring
    can be an easy setup.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Hadoop集群监控**：为了了解集群的健康状况，需要对NameNode和所有DataNode进行适当的监控。这有助于在节点出现问题时采取纠正措施。如果某个服务崩溃，及时的行动可以帮助避免未来出现大问题。设置Gangalia和Nagios是配置警报和监控的流行选择。在Hortonworks集群的情况下，Ambari监控，以及Cloudera集群，Cloudera
    (CDH) 管理器监控可以是一个简单的设置。'
- en: '**Automated deployment**: Use of tools like Puppet or Chef is essential for
    Hadoop deployment. It becomes super easy and productive to deploy the Hadoop cluster
    with automated tools instead of manual deployment. Give importance to data analysis
    and data processing using available tools/components. Give preference to using
    Hive or Pig scripts for problem solving rather than writing heavy, custom MapReduce
    code. The goal should be to develop less and analyze more.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自动化部署**：使用Puppet或Chef等工具对于Hadoop部署至关重要。使用自动化工具而不是手动部署来部署Hadoop集群变得超级简单和高效。重视使用可用的工具/组件进行数据分析和处理。在解决问题时，优先考虑使用Hive或Pig脚本而不是编写重量级的自定义MapReduce代码。目标应该是开发更少，分析更多。'
- en: '**Implementation of HA**: While deciding about HA infrastructure and architecture,
    careful consideration should be given to any increase in demand and data growth.
    In the event of any failure or crash, the system should be able to recover itself
    or failover to another data center/site.'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高可用性（HA）的实施**：在决定HA基础设施和架构时，应仔细考虑任何需求增加和数据增长。在任何故障或崩溃发生时，系统应能够自我恢复或故障转移到另一个数据中心/站点。'
- en: '**Security**: Data needs to be protected by creating users and groups, and
    mapping users to the groups. Setting appropriate permissions and enforcing strong
    passwords should lock each user group down.'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全**：需要通过创建用户和组，并将用户映射到组中来保护数据。设置适当的权限并强制执行强密码应该锁定每个用户组。'
- en: '**Data protection**: The identification of sensitive data is critical before
    moving it to the Hadoop cluster. It''s very important to understand privacy policies
    and government regulations for the better identification and mitigation of compliance
    exposure risks.'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据保护**：在将敏感数据移动到 Hadoop 集群之前，识别敏感数据至关重要。了解隐私政策和政府法规对于更好地识别和缓解合规风险暴露至关重要。'
- en: Hadoop file formats
  id: totrans-215
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Hadoop 文件格式
- en: In Hadoop, there are many file formats available. A user can select any format
    based on the use case. Each format has special features in terms of storage and
    performance. Let's discuss each file format in detail.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Hadoop 中，有许多文件格式可供选择。用户可以根据用例选择任何格式。每种格式在存储和性能方面都有特殊功能。让我们详细讨论每种文件格式。
- en: Text/CSV file
  id: totrans-217
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 文本/CSV 文件
- en: Text and CSV files are very common in Hadoop data processing algorithms. Each
    line in the file is treated as a new record. Typically, each line ends with the *n*
    character. These files do not support column headers. Hence, while processing,
    an extra line of the code is always required to remove column headings. CSV files
    are typically compressed using GZIP codec because they do not support block level
    compression; it adds to more processing costs. Needless to mention they do not
    support schema evolution.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 文本和 CSV 文件在 Hadoop 数据处理算法中非常常见。文件中的每一行都被视为一个新的记录。通常，每一行以 *n* 字符结束。这些文件不支持列标题。因此，在处理时，总是需要额外的代码行来删除列标题。CSV
    文件通常使用 GZIP 编解码器进行压缩，因为它们不支持块级压缩；这会增加更多的处理成本。不用说，它们也不支持模式演变。
- en: JSON
  id: totrans-219
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: JSON
- en: The JSON format is becoming very popular in all modern programming languages.
    These files are collection name/value pairs. The JSON format is typically used
    in data exchange applications and it is treated as an object, record, struct,
    or an array. These files are text files and support schema evolutions. It's very
    easy to add or delete attributes from a JSON file. Like text/CSV files, JSON files
    do not support block-level compression.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: JSON 格式在所有现代编程语言中变得越来越受欢迎。这些文件是名称/值对的集合。JSON 格式通常用于数据交换应用程序，并被视为对象、记录、结构或数组。这些文件是文本文件，并支持模式演变。从
    JSON 文件中添加或删除属性非常容易。与文本/CSV 文件一样，JSON 文件不支持块级压缩。
- en: Sequence file
  id: totrans-221
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 序列文件
- en: 'A sequence file is a flat file consisting of binary key/value pairs. They are
    extensively used in MapReduce ([https://wiki.apache.org/hadoop/MapReduce](https://wiki.apache.org/hadoop/MapReduce))
    as input/output formats. They are mostly used for intermediate data storage within
    a sequence of MapReduce jobs. Sequence files work well as containers for small
    files. If there are too many small files in HDFS, they can be packed in a sequence
    file to make file processing efficient. There are three formats of sequence files:
    uncompressed, record compressed, and block compressed key/value records. Sequence
    files support block-level compression but do not support schema evolution.'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 序列文件是一个由二进制键/值对组成的平面文件。它们在 MapReduce ([https://wiki.apache.org/hadoop/MapReduce](https://wiki.apache.org/hadoop/MapReduce))
    作为输入/输出格式中被广泛使用。它们主要用于 MapReduce 作业序列中的中间数据存储。序列文件作为小文件的容器工作得很好。如果 HDFS 中有太多小文件，它们可以被打包成一个序列文件，以提高文件处理效率。序列文件有三种格式：未压缩、记录压缩和块压缩键/值记录。序列文件支持块级压缩，但不支持模式演变。
- en: Avro
  id: totrans-223
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Avro
- en: Avro is a widely used file type within the Hadoop community. It is popular because
    it helps schema evolution. It contains serialized data with a binary format. An
    Avro file is splittable and supports block compression. It contains data and metadata.
    It uses a separate JSON file to define the schema format. When Avro data is stored
    in a file, its schema is stored with it so that files may be processed later by
    any program. If the program reading the data expects a different schema, this
    can be easily resolved, since both schemas are present.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: Avro 是 Hadoop 社区中广泛使用的文件类型。它之所以受欢迎，是因为它有助于模式演变。它包含以二进制格式序列化的数据。Avro 文件是可分割的，并支持块压缩。它包含数据和元数据。它使用一个单独的
    JSON 文件来定义模式格式。当 Avro 数据存储在文件中时，其模式也会与其一起存储，以便文件可以在以后由任何程序处理。如果读取数据的程序期望不同的模式，这可以很容易地解决，因为两种模式都存在。
- en: Parquet
  id: totrans-225
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Parquet
- en: Parquet stores nested data structures in a flat columnar format. Parquet is
    more efficient in terms of storage and performance than any row-level file formats.
    Parquet stores binary data in a column-oriented way. In the Parquet format, new
    columns are added at the end of the structure. Cloudera mainly supports this format
    for Impala implementation but is aggressively becoming popular recently. This
    format is good for SQL queries, which read particular columns from a wide table
    having many columns because only selective columns are read to reduce I/O cost.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: Parquet 以扁平的列式格式存储嵌套数据结构。与任何行级文件格式相比，Parquet 在存储和性能方面更高效。Parquet 以列导向的方式存储二进制数据。在
    Parquet 格式中，新列被添加到结构的末尾。Cloudera 主要支持这种格式用于 Impala 实现，但最近正迅速变得流行。这种格式适合 SQL 查询，因为它从具有许多列的宽表中读取特定列，从而只读取选择性列以减少
    I/O 成本。
- en: ORC
  id: totrans-227
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ORC
- en: ORC files are optimized record columnar file format and are the extended version
    of RC files. These are great for compression and are best suited for Hive SQL
    performance when Hive is reading, writing, and processing data to reduce access
    time and the storage space. These files do not support true schema evolution.
    They are mainly supported by Hortonworks and are not suitable for Impala SQL processing.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: ORC 文件是优化的记录列式文件格式，是 RC 文件的扩展版本。这些文件非常适合压缩，并且最适合 Hive SQL 性能，当 Hive 读取、写入和处理数据以减少访问时间和存储空间时。这些文件不支持真正的模式演变。它们主要得到
    Hortonworks 的支持，并且不适合 Impala SQL 处理。
- en: Which file format is better?
  id: totrans-229
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 哪种文件格式更好？
- en: 'The answer is: it depends on your use cases. Generally, the criteria for selecting
    a file format is based on query-read and query-write performance. Also, it depends
    on which Hadoop distribution you are using. The ORC file format is the best for
    Hive and Tez using the Hortonworks distribution and a parquet file is recommended
    for Cloudera Impala implementations. For a use case involving schema evolution,
    Avro files are best suited. If you want to import data from RDBMS using Sqoop,
    text/CSV file format is the better choice. For storing map intermediate output,
    a sequence file is the ultimate choice.'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 答案是：这取决于您的用例。通常，选择文件格式的标准基于查询读取和查询写入性能。此外，这也取决于您正在使用的 Hadoop 发行版。使用 Hortonworks
    发行版时，ORC 文件格式是 Hive 和 Tez 的最佳选择，而对于 Cloudera Impala 实现，建议使用 parquet 文件格式。对于涉及模式演变的用例，Avro
    文件格式最为合适。如果您想使用 Sqoop 从 RDBMS 导入数据，text/CSV 文件格式是更好的选择。对于存储映射中间输出，序列文件是最终的选择。
- en: Summary
  id: totrans-231
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, the main objective was to learn about various Hadoop design
    alternatives. We've learned a lot when it comes to the Hadoop cluster and its
    best practices for deployment in a typical production environment. We started
    with a basic understanding about Hadoop and we proceeded to Hadoop configuration,
    installation, and HDFS architecture. We also learned about various techniques
    for achieving HDFS high availability. We also looked into YARN architecture. Finally,
    we looked at various file formats and how to choose one based on your use case.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，主要目标是了解各种 Hadoop 设计替代方案。当我们谈到 Hadoop 集群及其在典型生产环境中的最佳部署实践时，我们学到了很多。我们从对
    Hadoop 的基本理解开始，然后继续到 Hadoop 配置、安装和 HDFS 架构。我们还学习了实现 HDFS 高可用性的各种技术。我们还研究了 YARN
    架构。最后，我们探讨了各种文件格式以及如何根据您的用例选择一个。
- en: In the next chapter, we will see how to ingest data into a newly created Hadoop
    cluster.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将了解如何将数据导入到一个新创建的 Hadoop 集群中。
