["```py\n#!/bin/bash\n# Set unix environment variables\ncat << EOF >> $HADOOP_HOME/.bashrc\nexport HADOOP_CMD=$HADOOP_HOME/bin/hadoop\nexport HADOOP_STREAMING=$HADOOP_HOME/contrib/streaming/hadoop-streaming.jar\nEOF\n. $HADOOP_HOME/.bashrc\n# Fix hadoop tmp permission\nsudo chmod 777 -R /mnt/var/lib/hadoop/tmp\n# Install dependencies\nsudo yum install -y libcurl-devel \n# Install R packages\nsudo –E R CMD javareconf\nsudo –E R --no-save << EOF\ninstall.packages(\"R.utils\", repos=\"http://cran.rstudio.com\")\nEOF\n# Install HadoopR dependencies\nsudo –E R --no-save << EOF\ninstall.packages(\n    c(\"bitops\", \"caTools\", \"digest\", \"functional\", \"plyr\", \"Rcpp\",\n      \"reshape2\", \"rJava\", \"RJSONIO\", \"stringr\"),\n    repos=\"http://cran.rstudio.com\")\nEOF\n# Install rhdfs package\nwget https://raw.githubusercontent.com/RevolutionAnalytics/rhdfs/master/build/rhdfs_1.0.8.tar.gz\nsudo -E R CMD INSTALL rhdfs_1.0.8.tar.gz\n# Install rmr2 package\nwget https://raw.githubusercontent.com/RevolutionAnalytics/rmr2/master/build/rmr2_3.2.0.tar.gz\nsudo –E R CMD INSTALL rmr2_3.2.0.tar.gz\n```", "```py\n$ ssh –i hadoop.pem root@master-public-dns\n```", "```py\n$ R\n```", "```py\nlibrary(rhdfs)\nlibrary(R.utils)\nhdfs.init()\nhdfs.mkdir(\"/ngrams/data\")\nfiles <- paste0(\"googlebooks-eng-all-1gram-20120701-\", letters)\nfor (f in files) {\n    gzfile <- paste0(f, \".gz\")\n    url <- paste0(\"http://storage.googleapis.com/\",\n                  \"books/ngrams/books/\",\n                  gzfile)\n    download.file(url, destfile = gzfile)\n    gunzip(gzfile)\n    hdfs.put(f, paste0(\"/ngrams/data/\", f))\n    file.remove(f)\n}\n```", "```py\nhdfs.ls(\"/ngrams/data\")\n## permission  owner      group       size          modtime\n## 1  -rw-r--r-- hadoop supergroup 1801526075 2014-10-05 09:59\n## 2  -rw-r--r-- hadoop supergroup 1268392934 2014-10-05 10:00\n## 3  -rw-r--r-- hadoop supergroup 2090710388 2014-10-05 10:01\n## 4  -rw-r--r-- hadoop supergroup 1252213884 2014-10-05 10:01\n## 5  -rw-r--r-- hadoop supergroup 1085415448 2014-10-05 10:02\n## file\n## 1  /ngrams/data/googlebooks-eng-all-1gram-20120701-a\n## 2  /ngrams/data/googlebooks-eng-all-1gram-20120701-b\n## 3  /ngrams/data/googlebooks-eng-all-1gram-20120701-c\n## 4  /ngrams/data/googlebooks-eng-all-1gram-20120701-d\n## 5  /ngrams/data/googlebooks-eng-all-1gram-20120701-e\n## $ hdfs dfs -du -h /ngrams\n# Output truncated\n```", "```py\nmountain    1978    1435642    1453\n```", "```py\nlibrary(rmr2)\ninput.format <- make.input.format(\n    format = \"csv\", sep = \"\\t\",\n    col.names = c(\"ngram\", \"year\", \"occurrences\", \"books\"),\n    colClasses = c(\"character\", \"integer\", \"integer\", \"integer\"))\n```", "```py\nmapper <- function(keys, values) {\n    values$ngram <- tolower(values$ngram)\n    superheroes <- values$ngram %in% c(\"batman\", \"superman\") &\n        values$year >= 1950L\n    if (any(superheroes)) {\n        keyval(values$ngram[superheroes],\n               values[superheroes, c(\"year\", \"occurrences\")])\n    }\n}\n```", "```py\nreducer <- function(key, values) {\n    val <- tapply(values$occurrences, values$year, sum)\n    val <- data.frame(year = as.integer(names(val)),\n                      occurrences = val)\n    keyval(key, val)\n}\n```", "```py\njob <- mapreduce(input = \"/ngrams/data\",\n                 input.format = input.format,\n                 output = \"/ngrams/batmanVsuperman\",\n                 map = mapper, reduce = reducer)\n```", "```py\nresults <- from.dfs(job)\nbatman <- results$val[results$key == \"batman\", ]\nhead(batman)\n##      year occurrences\n## 1950 1950         153\n## 1951 1951         105\n## 1952 1952         173\n## 1953 1953         133\n## 1954 1954         359\n## 1955 1955         150\nsuperman <- results$val[results$key == \"superman\", ]\nhead(superman)\n##      year occurrences\n## 1950 1950        1270\n## 1951 1951        1130\n## 1952 1952        1122\n## 1953 1953         917\n## 1954 1954        1222\n## 1955 1955        1087\n```"]