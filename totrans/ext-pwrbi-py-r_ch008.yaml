- en: 7 Logging Data from Power BI to External Sources
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As you''ve learned from previous chapters, **Power BI** uses **Power Query**
    as a tool for **extract transform load** (**ETL**) operations. The tool in question
    is really very powerful – it allows you to extract data from a wide variety of
    data sources and then easily transform it with very user-friendly options in order
    to persist it into the Power BI data model. It is a tool that is only able to
    read information from the outside. In fact, the most stringent limitation of Power
    Query is its inability to write information outside of Power BI. However, thanks
    to the integration of analytical languages such as **Python** and **R**, you''ll
    be able to persist information about Power Query loading and transformation processes
    to external files or systems. In this chapter, you will learn the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Logging to **CSV** files
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logging to **Excel** files
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logging to **Azure** **SQL Server**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This chapter requires you to have a working Internet connection and **Power
    BI Desktop** already installed on your machine. You must have properly configured
    the R and Python engines and IDEs as outlined in *Chapter 2*, *Configuring R with
    Power BI*, and *Chapter 3*, *Configuring Python with Power BI*.
  prefs: []
  type: TYPE_NORMAL
- en: Logging to CSV files
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One of the most widely used formats for logging tabular structured information
    to files is **comma-separated value** (**CSV**). Since a CSV file is still a flat
    text file, CSV is the most popular format for exchanging information between heterogeneous
    applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'A CSV file is a representation of a rectangular dataset (**matrix**), containing
    numeric or string columns. Each row of the matrix is represented by a list of
    values (one for each column), separated by a comma, and should have the same number
    of values. Sometimes, other value delimiters could be used, like tab (`\t`), colon
    (`:`), and semi-colon (`;`) characters. The first row could contain the column
    header names. Usually, a **line break**, made by **CRLF** (**Carriage Return Line
    Feed**)characters (usually entered as `\r\n`), or simply by **LF** (`\n`) in Unix
    systems, is used as a **row delimiter**. So, an example of CSV file content could
    be the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.1 – Example of CSV file content](img/file174.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.1 – Example of CSV file content
  prefs: []
  type: TYPE_NORMAL
- en: Note the spaces as they become part of a string value! For example, the second
    value of the `V1, V2` row will be `[space]V2`.
  prefs: []
  type: TYPE_NORMAL
- en: 'It may happen that a string value contains line breaks (`CRLF`), double-quotes,
    or commas (as usually happens with free text fields like “Notes”). In this case,
    the value should be enclosed in double-quotes and any literal double quote has
    to be escaped using another double quote. For example, the values `"` `C,D"`,
    “`E""F`” and `"G[CRLF]H"` for the column `Col1` are formatted in the following
    way in a CSV file:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.2 – Example of CSV values containing commas, double quotes, or CRLF](img/file175.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.2 – Example of CSV values containing commas, double quotes, or CRLF
  prefs: []
  type: TYPE_NORMAL
- en: '**Important Note**'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: It is important to keep in mind that a CSV file doesn’t have any size limits
    per se.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Since it is a flat text file, the maximum size is determined by the limits imposed
    by the filesystem. For example, the default filesystem for Windows is the **New
    Technology File System** (**NTFS**) and it allows a maximum file size of *16 TB*
    as its current implementation. However, its designed theoretical limit is *16
    EB* (16 × 2^(64) bytes) minus *1 KB*.
  prefs: []
  type: TYPE_NORMAL
- en: However, the old **File Allocation Table** filesystem, in its variant of 32
    bits (**FAT32**), can only handle a maximum size of *4 GB*.
  prefs: []
  type: TYPE_NORMAL
- en: '**Important Note**'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Keep in mind that handling large CSV files leads to memory and/or CPU bottlenecks.
    You are very likely to get an `OutOfMemory` error if the CSV file to be loaded
    is larger than the RAM you have available and if your libraries don’t use parallelism/distribution/lazy
    loading mechanisms. You'll learn how to handle such large CSV files in *Chapter
    8*, *Loading Large Datasets Beyond the Available RAM in Power BI*.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Let's see how to read and write CSV files with Python.
  prefs: []
  type: TYPE_NORMAL
- en: Logging to CSV files with Python
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Python has a built-in CSV module that provides some functions to read and write
    CSV files. Very often, however, you will have to import a CSV file whose content
    will then be transformed through Pandas functions, or you must export in a CSV
    format a DataFrame previously processed through Pandas. That's why, in these cases,
    it is much more convenient to directly use the built-in pandas functions with
    DataFrame objects. You will find the `01-read-csv-file-in-python.py` and `02-write-csv-file-in-python.py`
    files in the `Chapter07/Python` folder that will show you how to use the CSV module.
    In the following section, we will focus exclusively on the functionality provided
    by pandas.
  prefs: []
  type: TYPE_NORMAL
- en: Let's look in detail at the pandas functions available to work with CSV files.
  prefs: []
  type: TYPE_NORMAL
- en: Using the pandas module
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The functions that the `pandas` module provides to read and write a CSV file
    are very simple and straightforward. You can use the `read_csv()` function to
    read data from a CSV file. The following is the code that allows you to load the
    content of the `example.csv` file in a DataFrame:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Chapter07\Python\03-read-csv-file-with-pandas.py`'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the output using the **VS Code** **Interactive Window**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.3 – Output of the pandas DataFrame loaded with the example CSV file’s
    content](img/file176.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.3 – Output of the pandas DataFrame loaded with the example CSV file’s
    content
  prefs: []
  type: TYPE_NORMAL
- en: The `read_csv` function also allows you to pass the `sep` parameter to define
    the value separator to be used when reading the file.
  prefs: []
  type: TYPE_NORMAL
- en: 'If, on the other hand, you need to write a CSV file from the contents of a
    DataFrame, you can use the `to_csv()` function. The following is an example of
    the code you could use:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Chapter07\Python\04-write-csv-file-with-pandas.py`'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The `to_csv()` function also allows you to pass the `sep` parameter in order
    to define the value separator you intend to use in the file.
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, working with CSV files in Python is very easy. In the next section,
    you'll put this into practice in Power BI.
  prefs: []
  type: TYPE_NORMAL
- en: Logging emails to CSV files in Power BI with Python
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'As an example of generating a CSV file, we will use the same scenario provided
    in *Chapter 5*, *Using Regular Expressions in Power BI*, in which you needed to
    validate email addresses and ban dates. The goal is to export the rows of the
    dataset containing an incorrect email to a CSV file and to filter them out of
    the dataset so that only valid emails remain in Power BI. We will use the `to_csv()`
    function that pandas provides. The necessary steps are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Follow all the steps in the *Using regex in Power BI to validate emails with
    Python* section of *Chapter 5*, *Using Regular Expressions in Power BI* to the
    end, but do not click on **Close & Apply**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Then, click on **Run Python Script**, enter the following script, and click
    **OK**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You can find this Python script also in the `Python\05-log-wrong-emails-csv-in-power-bi.py`
    file. Note the `~` character that in this case is a negation of the Boolean condition
    defined by the `filter` variable.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Click on the `df` dataset’s **Table** value:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.4 – Selecting the df dataset as a result of the Python script transformation](img/file177.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 7.4 – Selecting the df dataset as a result of the Python script transformation
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Only rows containing valid emails will be kept:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.5 – A table containing only valid emails](img/file178.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 7.5 – A table containing only valid emails
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Moreover, the `wrong-emails.csv` file has been created in your `Chapter07\Python`
    folder.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Go back to the **Home** menu, and then click **Close & Apply**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'If you go and check the contents of the created CSV file, it matches the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, the emails in the CSV file are all the invalid ones. At this
    point, you can share the previous file with your colleagues so that they can correct
    invalid emails.
  prefs: []
  type: TYPE_NORMAL
- en: Well done! You just learned how to log information to a CSV file from Power
    BI using Python. Now, let's see how you can do the same thing using R.
  prefs: []
  type: TYPE_NORMAL
- en: Logging to CSV files with R
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The basic R language provides some out-of-the-box functions for working with
    CSV files. However, there is also the `readr` package, included in the **Tidyverse**
    ecosystem, which provides similar functions, but is faster in loading larger CSV
    files.
  prefs: []
  type: TYPE_NORMAL
- en: Let's see how to use them in detail.
  prefs: []
  type: TYPE_NORMAL
- en: Using the Tidyverse functions
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The `readr` package provides some functions mirroring those seen for reading
    and writing CSV files with R base. The advantage of these functions is that, in
    addition to respecting the common interface provided by the functions of the Tidyverse
    world, they are up to five times faster than standard functions and also progress
    meters. Make sure you have at least version 1.4.0 of the package installed, otherwise,
    update it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Always using the usual `example.csv` file, similarly to what we did in the
    previous section, you can load the data through the `read_csv()` function of the
    `readr` package in this way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'As output, you can see the following specification:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Besides the fact that the `read_csv()` function outputs a **tibble** instead
    of a DataFrame, there is one point that is important to note:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Important Note**'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The interesting thing is that the `read_csv()` function correctly imports the
    carriage return character by default.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'If you check the newly imported tibble, you have the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.6– Characters \r\n correctly imported by read_csv](img/file179.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.6– Characters \r\n correctly imported by read_csv
  prefs: []
  type: TYPE_NORMAL
- en: Just as with R base, the `readr` package also provides the same functions, `read_csv2()`,
    `read_tsv()`, and `read_delim()`, to ensure a similar interface and thus easy
    usability.
  prefs: []
  type: TYPE_NORMAL
- en: 'To persist data toa CSV file, the `readr` package provides the `write_csv()`
    function with its whole family of functions, similarly to R base (`write_csv2`,
    `write_tsv`, and `write_delim`). Unlike `write.csv()`, these functions do not
    include row names as a column in the written file. Moreover, the default end-of-line
    separator is just a new line (`\n`). So, if you want to export your data using
    the `\r\n` characters as a line separator, you have to pass them through the `eol`
    parameter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Observe that, in this case, you have to use both characters (`\r\n`) in your
    data if you want to extract them in exactly the same way.
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, working with CSV files in R is as simple as it was in Python.
    In the next section, you will log emails and dates with R in Power BI.
  prefs: []
  type: TYPE_NORMAL
- en: Logging dates to CSV files in Power BI with R
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We will always use the scenario presented in *Chapter 5*, *Using Regular Expressions
    in Power BI*, where it was necessary to validate both email addresses and ban
    dates. This time, we will use R to export invalid ban dates to a CSV file. The
    necessary steps are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Follow all the steps in the *Using regex in Power BI to validate dates with
    R* section of *Chapter 5*, *Using Regular Expressions in Power BI* to the end,
    but do not click on **Close & Apply**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Then click on **Run R Script**, enter the following script, and click **OK**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You can find this R script also in the `R\01-log-wrong-emails-in-r.R` file.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Click on the `df` dataset’s **Table** value:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.7 – Selecting the df dataset as a result of the R script transformation](img/file180.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 7.7 – Selecting the df dataset as a result of the R script transformation
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Only rows containing valid emails will be kept:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.8 – A table containing only valid emails](img/file181.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 7.8 – A table containing only valid emails
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Moreover, the `wrong-dates.csv` file has been created in your `Chapter07\R`
    folder.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Go back to the **Home** menu, and then click **Close & Apply**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: At this point, you can share the just created `wrong-emails.csv` file with your
    colleagues so that they can correct invalid emails.
  prefs: []
  type: TYPE_NORMAL
- en: Awesome! You just learned how to log information to a CSV file from Power BI
    using R. Let's now see how to use Excel files to log your information.
  prefs: []
  type: TYPE_NORMAL
- en: Logging to Excel files
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As you probably already know, Microsoft Excel is **spreadsheet** software available
    in the **Microsoft** **Office** suite. It’s one of the most widely used tools
    in the world for storing and organizing data in a table format. It is very popular
    in companies because it allows business data to be shared between departments
    and enables individual users to do their own data analysis directly and quickly
    without the help of the IT department.
  prefs: []
  type: TYPE_NORMAL
- en: Early versions of Excel stored information in files of the **Excel Sheet** (**XLS**)
    format. This is a proprietary Microsoft format, based on the **Binary Interchange
    File Format** (**BIFF**). It has been the default format for versions from v7.0
    (Excel 95) to v11.0 (Excel 2003). From version 8.0 to 11.0 the XLS format can
    handle *64K (2^(16) = 65,536) rows* and *256 columns (2⁸)*. Starting with version
    v12.0 (Excel 2007), the default format has changed to **Excel Open XML Spreadsheet**
    (**XLSX**). This is based on the **Office Open XML** format, and it is based on
    text files that use XML to define all its parameters.
  prefs: []
  type: TYPE_NORMAL
- en: '**Note**'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Did you know that an XLSX file contains data in multiple XML files compressed
    in the **ZIP** format? If you want to verify this, simply rename one of your XLSX
    files, for example, `example.xlsx`, adding the `.zip` extension to it (for example,
    `example.xlsx.zip`). Then, extract its content using the **File Explorer** or
    any other Zip client (like **7-Zip**).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The XLSX format can handle *1024K (2^(20) = 1,048,576) rows and 16,384 (2^(14))
    columns*.
  prefs: []
  type: TYPE_NORMAL
- en: Since **Power Pivot** (starting with Excel 2013) and **Power Query** (starting
    with Excel 2016) were introduced, most of the data ingestion and data analysis
    activities for the purpose of generating a prototype data model are often performed
    by power-users thanks to Microsoft Excel. Power Query gives you a set of rich
    tools for transforming data all in one place. Power Pivot gives you the ability
    to work with large volumes of data by overcoming Excel's limitation of 1,048,576
    rows. Once imported, you can use pivot tables and the **DAX** formula language
    on them, since the engine behind the scenes is the same as **Analysis Service
    Tabular** and Power BI. That's why Excel and Power BI are the premier tools for
    self-service BI on the **Microsoft** **Data Platform**.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's see how to interact with Excel files in Python. We will use the latest
    XLSX format from now on.
  prefs: []
  type: TYPE_NORMAL
- en: Logging to Excel files with Python
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The fastest way to interact with Excel files in Python is to use the functions
    that pandas provides. However, you need to install the `openpyxl` package in your
    `pbi_powerquery_env` environment. If you remember correctly, you already installed
    this package in the environment dedicated to **Presidio** (`presidio_env`) in
    *Chapter 6*, *Anonymizing and Pseudonymizing your Data in Power BI*. In order
    to install this package, also in the `pbi_powerquery_env` environment, simply
    follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Open your **Anaconda** **Prompt**
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Set your current environment to `pbi_powerquery_env`, entering the following
    command and pressing **Enter**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Enter the following command and press **Enter**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: As an example, you will find the `example.xlsx` file in the `Chapter07` folder.
    Let’s see how to import its content with Python.
  prefs: []
  type: TYPE_NORMAL
- en: Using the pandas module
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'You can easily import your data into a pandas DataFrame using this code:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Chapter07\Python\06-read-excel-file-with-pandas.py`'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'If you visualize the DataFrame in VS Code, you’ll see something like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.9 – Output of the pandas DataFrame loaded with the example.xlsx
    file’s content](img/file182.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.9 – Output of the pandas DataFrame loaded with the example.xlsx file’s
    content
  prefs: []
  type: TYPE_NORMAL
- en: In this case, if an Excel cell contains a string with the `\r\n` characters,
    the carriage return (`\r`) is lost after import, as you can see in *Figure 7.11*.
  prefs: []
  type: TYPE_NORMAL
- en: 'As you probably already know, an Excel file (**workbook**) can contain one
    or more sheets (**worksheets**) in which there is data. If you need to import
    data from a specific worksheet, you can use this code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Similarly, you can write the contents of a DataFrame to Excel files using this
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Chapter07\Python\07-write-excel-file-with-pandas.py`'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting Excel file will have a default `Sheet1` worksheet, and its content
    will look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.10 – The content of the Excel file created using pandas functions](img/file183.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.10 – The content of the Excel file created using pandas functions
  prefs: []
  type: TYPE_NORMAL
- en: If you copy the contents of cell `A6` into an advanced editor, you can verify
    that the `\r\n` characters are kept.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want to write the content of your dataset to a specific named worksheet
    in *a new Excel file*, then you can use the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The result will be the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.11 – The content is now written into a named worksheet](img/file184.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.11 – The content is now written into a named worksheet
  prefs: []
  type: TYPE_NORMAL
- en: 'If instead you want to write the content of your dataset to a specific named
    worksheet in *an existing Excel file*, then you have to use the pandas `ExcelWriter`
    class in the following way:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Chapter07\Python\08-write-excel-file-named-sheet-with-pandas.py`'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Note, that the `mode='a'` is for *“append”*. Let's now look at an example of
    logging in Power BI using the previous pandas functions.
  prefs: []
  type: TYPE_NORMAL
- en: Logging emails and dates to Excel files in Power BI with Python
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Let's go back to the same scenario used in the previous sections, namely, the
    one we already analyzed in *Chapter 5*, *Using Regular Expressions in Power BI*,
    in which you needed to validate email addresses and ban dates. This time, however,
    the goal is to export invalid emails and invalid dates to two separate worksheets
    in an Excel file and then share it with the team.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, open your Power BI Desktop, make sure the Python environment to use is
    `pbi_powerquery_env`, and let''s get started:'
  prefs: []
  type: TYPE_NORMAL
- en: From the ribbon, click on the **Excel** icon to import data from Excel.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: From the **Open** dialog box, select the `Users.xlsx` file you can find in the
    `Chapter05` folder.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: From the **Navigator** window, select the **Users** sheet and then click on
    **Transform Data**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on the **Transform** menu, and then click on **Run Python Script**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Copy the code you can find in the `09-validate-emails-dates-with-regex-in-power-bi.py`
    file in the `Chapter07/Python` folder, and paste it into the Python script editor.
    This code is just a merging of the scripts you already used to validate emails
    and dates separately. Then, click **OK**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Select just the **Table** value related to the `df` table name and you will
    see something like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.11 – The transformed data contains both the flags for valid emails
    and dates](img/file185.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 7.11 – The transformed data contains both the flags for valid emails
    and dates
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Now, you have both the `isEmailValidFromRegex` and `isValidDateFromRegex` flags
    that allow you to select emails and correct dates.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click again on **Run Python Script**, enter the script you can find in the `10-log-wrong-emails-dates-excel-in-power-bi.py`
    file, and click **OK**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Select just the **Table** value related to the `df` table name and you will
    see a table where only rows containing valid emails and dates will be kept:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.12 – The output data contains rows containing valid emails and dates](img/file186.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 7.12 – The output data contains rows containing valid emails and dates
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Moreover, the `wrong-data.xlsx` file has been created in your `Chapter07/Python`
    folder and it contains two worksheets: `Wrong emails` and `Wrong dates`.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Go back to the **Home** menu, and then click **Close & Apply**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazing! You just learned how to log information to an Excel file in multiple
    sheets from Power BI using Python. Now, let's see how you can do the same thing
    using R.
  prefs: []
  type: TYPE_NORMAL
- en: Logging to Excel files with R
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To be able to read and write Excel files in R, we recommend the use of two
    separate packages:'
  prefs: []
  type: TYPE_NORMAL
- en: '**readxl**: This is a package that is part of the Tidyverse world and allows
    you to read the information contained in an Excel file in the simplest and most
    flexible way.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**openxlsx**: This is a package that provides a high-level interface for creating
    and editing Excel files. Compared to other packages that do the same thing, `openxlsx`
    removes the dependency on **Java** behind the scenes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'First, you need to install the `openxlsx` package:'
  prefs: []
  type: TYPE_NORMAL
- en: Open **RStudio**, and make sure your latest **MRO** engine is selected in the
    **Global Options** (in our case, MRO 4.0.2).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Enter the `install.packages("openxlsx")` command in the console. Remember that
    it installs the package at the version corresponding to the **CRAN** snapshot
    defined by your MRO installation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now you are ready to learn how to read and write data to Excel files.
  prefs: []
  type: TYPE_NORMAL
- en: Using the readxl and openxlsx packages
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The `readxl` package provides two separate functions – `read_xls()`, to read
    Excel files in an XLS format, and `read_xlsx()`, to read those in an XLSX format.
    If you want to read the contents of the `example.xlsx` file located in the `Chapter07`
    folder, you can use the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The result will be a tibble:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.13 – Excel data read using the read_xlsx function](img/file187.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.13 – Excel data read using the read_xlsx function
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see, the carriage returns and the line feed characters (`\r\n`)
    are kept. If you want to read data from a specific worksheet instead, you can
    use this code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'To write your data into Excel files, you can use the `write.xlsx()` function
    of the `openxlsx` package, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Observe how, in this case, you have to use the “Unix convention” regarding the
    new lines, and that is to use only the `\n` character in the strings of your data
    to have the standard Windows characters `\r\n` in Excel.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want to write the content of your dataset to a specific named worksheet
    in *a new Excel file*, then you can use the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'If, on the other hand, you need to add a worksheet to *an existing Excel file*,
    you have to use a named list of DataFrames/tibbles as the input of the `write.xlsx`
    function. This is the code to use if you can manually assign a string name to
    each sheet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Keep in mind that if you need to use a list of DataFrames/tibbles (`df_lst`)
    and a list of worksheet names (`names_lst`) separately, you can use the following
    code to write all your data in one Excel workbook:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Let's now look at an example of logging in Power BI using the previous R functions.
  prefs: []
  type: TYPE_NORMAL
- en: Logging emails and dates to Excel in Power BI with R
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The example we will use is still the one from *Chapter 5*, *Using Regular Expressions
    in Power BI*, in which you needed to validate email addresses and ban dates. The
    ultimate goal will always be to export invalid emails and invalid dates to two
    separate worksheets in an Excel file and then share it with the team.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now open your Power BI Desktop, make sure your latest MRO is referenced in
    the options, and let''s get started:'
  prefs: []
  type: TYPE_NORMAL
- en: From the ribbon, click on the **Excel** icon to import data from Excel.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: From the **Open** dialog box, select the `Users.xlsx` file you can find in the
    `Chapter05` folder.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: From the **Navigator** window, select the **Users** sheet and then click on
    **Transform Data**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on the **Transform** menu, and then click on **Run R Script**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Copy the code you can find in the `02-validate-emails-dates-with-regex-in-power-bi.R`
    file in the `Chapter07/R` folder, and paste it into the R script editor. This
    code is just a merging of the scripts you already used to validate emails and
    dates separately. Then click **OK**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Select just the **Table** value related to the `df` table name and you will
    see something like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.14 – The transformed data contains both the flags for valid emails
    and dates](img/file188.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 7.14 – The transformed data contains both the flags for valid emails
    and dates
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Now you have both the `isEmailValidFromRegex` and `isDateValidFromRegex` flags
    that allow you to select correct emails and dates.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click again on **Run R Script**, enter the script you can find in the `03-log-wrong-emails-dates-excel-in-power-bi.R`
    file, and click **OK**. Remember to change the paths in the code.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Select just the **Table** value related to the `df` table name and you will
    see a table where only rows containing valid emails and dates will be kept:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.15 – The output data contains rows containing valid emails and dates](img/file189.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 7.15 – The output data contains rows containing valid emails and dates
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Moreover, the `wrong-data.xlsx` file has been created in your `Chapter07/R`
    folder and it contains two worksheets: `Wrong emails` and `Wrong dates`.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Go back to the **Home** menu, and then click **Close & Apply**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Awesome! You just learned how to log information to an Excel file in multiple
    sheets from Power BI using R.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, you will learn how to log information from Power BI to
    either an **on-premises** **SQL Server**, or to an **Azure** **SQL Server**.
  prefs: []
  type: TYPE_NORMAL
- en: Logging to an Azure SQL Server
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the vast majority of companies, business information is persisted in a **Relational
    Database Management System** (**RDBMS**). Microsoft's quintessential relational
    database is **SQL Server** in its on-premises version if the company adopts the
    Microsoft Data Platform. Otherwise it is **Azure SQL Server** which is a **Platform
    as a Service** (**PaaS**), cloud-hosted database.
  prefs: []
  type: TYPE_NORMAL
- en: Generally, it is a good idea to centralize all of a company's key information
    in a single repository. That's why it might be useful to know how to log information
    from within a Power BI process into a SQL Server database or an Azure SQL database.
  prefs: []
  type: TYPE_NORMAL
- en: If you have the option to already access an instance of SQL Server on-premises
    or an Azure SQL Server, you just need to make sure that the **ODBC Driver for
    SQL Server** is installed on your machine. In fact, both Python and R will connect
    to (Azure) SQL Server via an ODBC connection. You have the option to install the
    driver on your machine directly (via the link [http://bit.ly/ODBC-SQLServer](http://bit.ly/ODBC-SQLServer)),
    but more often this driver is installed indirectly when installing the ultimate
    client for managing any SQL infrastructure, which is **SQL Server Management Studio**
    (**SSMS**).
  prefs: []
  type: TYPE_NORMAL
- en: 'On the other hand, if you don''t have access to either an on-premises SQL Server
    instance or an Azure SQL database, then you have two options for testing the examples
    in this section:'
  prefs: []
  type: TYPE_NORMAL
- en: Install a free instance of **SQL Server Express Edition** (or **Developer**).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create an Azure SQL database from the Azure portal using your account.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's see in detail how to proceed for each of these options.
  prefs: []
  type: TYPE_NORMAL
- en: Installing SQL Server Express
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this section, we will show how to install the Express Edition of SQL Server.
    This is the free version of Microsoft''s database engine that can also be used
    in production for desktop and small server data-driven applications. Obviously,
    the Express Edition has limitations that distinguish it from the top-of-the-line
    **Enterprise Edition**. Here are a few examples:'
  prefs: []
  type: TYPE_NORMAL
- en: A maximum memory of 1,410 MB is used by an instance of the database engine.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A maximum size of 10 GB for a single database.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Compute capacity used by a single instance limited to the lesser of one socket
    or four cores.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Despite these limitations, SQL Server Express remains an excellent solution
    to use in production for small applications. If, on the other hand, you need to
    be able to test the more advanced features of the engine because you know that
    your application will use a more complete edition in production (Standard or Enterprise),
    you can install the **Developer Edition** on your machine. This edition allows
    you to test all the features of the Enterprise Edition while not paying for an
    Enterprise license. The most stringent limitation is, of course, that the Developer
    Edition cannot be used in production.
  prefs: []
  type: TYPE_NORMAL
- en: 'That said, there are tons of tutorials about how to install the latest version
    of SQL Server Express available to date (2019). One of the many that we suggest
    you follow for installation is this one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.sqlshack.com/how-to-install-sql-server-express-edition](https://www.sqlshack.com/how-to-install-sql-server-express-edition)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Just keep these observations in mind:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The **Feature Selection** screen suggests also installing the **SQL Server
    Replication**. If you would also like to test Machine Learning Services separately
    with R, Python and Full-Text available in SQL Server, we suggest selecting the
    following, leaving out the Replication and Java options:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.16 – Suggested instance features](img/file190.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 7.16 – Suggested instance features
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The important thing is to keep the **Shared Features** selected by default so
    that the ODBC drivers needed to connect to the instance are also installed.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Remember to save the password for the `sa` (system administrator) user in a
    safe place, because it provides access to the instance you are installing as an
    administrator.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The tutorial will ask you to install SSMS in *Step 5*. If you haven't already
    installed it, do it now.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In order to connect to your SQL Server Express instance with SSMS, instead of
    the computer name and then the instance name, you can also use `.\SQLExpress`
    as the **Server name**. That said, the tutorial suggests testing your connection
    using the **SQL Server Authentication** with the **sa** account credentials. Remember
    that you can also connect to your instance directly using the **Windows authentication**,
    as your user is automatically added to the **SQL Server Administrators** group.
    As the tutorial says, if the login window closes without any issues after clicking
    **Connect**, this means the connection works properly.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Just stop at the *For the Windows authentication* section. The following applies:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Important Note**'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: It is important that the connection to the new `SQLExpress` instance works properly
    from SSMS. This confirms the correct installation of the instance.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'After the installation is complete, you can verify that the ODBC drivers have
    been installed by following these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Click the Windows **Start** button, and start entering the string `ODBC`. You
    will see something like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.17 – The Windows ODBC Data Sources configuration tools](img/file191.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 7.17 – The Windows ODBC Data Sources configuration tools
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Click on the 32-bit app or the 64-bit app, and then click on the **Drivers**
    tab. You’ll see the **ODBC Driver 17 for SQL Server** installed:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.18 – The ODBC Driver 17 for SQL Server correctly installed](img/file192.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.18 – The ODBC Driver 17 for SQL Server correctly installed
  prefs: []
  type: TYPE_NORMAL
- en: Fantastic! Now your `SQLExpress` instance is working properly.
  prefs: []
  type: TYPE_NORMAL
- en: Let's also see how to configure an Azure SQL database through the Azure portal.
  prefs: []
  type: TYPE_NORMAL
- en: Creating an Azure SQL database
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In order to create an Azure SQL database, you must be subscribed to Azure services.
    This gives you the ability to access the **Azure portal** ([https://portal.azure.com/](https://portal.azure.com/))
    to manage all of your tenant''s Azure resources. Once you have accessed the portal,
    follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Search for `SQL databases` in the main search box and click on it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.19 – Selecting SQL databases in the Azure portal](img/file193.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 7.19 – Selecting SQL databases in the Azure portal
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Click on **Create SQL database** in the middle of the page:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.20 – Clicking on Create SQL database](img/file194.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 7.20 – Clicking on Create SQL database
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You need to select a **Subscription** associated with your account (usually,
    the selected default one is ok if you have just one subscription associated) and
    then a **Resource group** to collect all the resources you want to create under
    a name (like a virtual folder). Select one if you have already created it, or
    create a new one if needed.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You must also provide the **Database name** and **Server**. As the database
    name, use `SystemsLogging`. If this is your first time creating an Azure SQL database,
    you need to create a new server too. So, click on **Create new** and provide a
    server name, a login, the related password, and the location you prefer. After
    clicking **OK**, you’ll see something like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.21 – Entering the database name and the new server](img/file195.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 7.21 – Entering the database name and the new server
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'As we’re creating an Azure SQL database for testing purposes, we can choose
    a **Standard** **Database Transaction Unit** (**DTU**) workload. So, click on
    **Configure database** under **Compute + storage**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.22 – Configuring the compute](img/file196.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 7.22 – Configuring the compute
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The **General Purpose** option is selected by default. So, click on the **Looking
    for basic, standard, premium?** link on the top-left and then click on the **Standard**
    workload option. Then, click on the **Apply** button.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Select also to install sample data (from the demo **AdventureWorkLT** database)
    in the **Additional settings** tab by clicking on **Sample**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.2 – Choosing to install a sample database](img/file197.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 7.2 – Choosing to install a sample database
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click on **Review + create**, and then on **Create** to deploy your brand-new
    Azure SQL database.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'After the deployment is complete, click on **Go to resource** to access the
    general dashboard of the newly created resource. In the top-right corner, you
    will notice that the server’s name takes the following form:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In order to access your Azure SQL database from any client, you must declare
    the client''s IP address in the server firewall rules. To do this, click on **Set
    server firewall** at the top of the dashboard:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.24 – Setting rules on the Azure SQL server firewall](img/file198.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 7.24 – Setting rules on the Azure SQL server firewall
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'In addition to other options, you''ll see textboxes to enter the **Rule name**,
    the **Start IP**, and the **End IP**. Additionally, the portal also shows you
    the IP address from which you are currently connected:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 7.25 – Copying your current IP address and using it in your rule](img/file199.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 7.25 – Copying your current IP address and using it in your rule
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You can then enter your Client IP address as the Start and End IP if you will
    be connecting to the Azure SQL database from that same machine. Keep in mind that
    if your machine's public IP address is not static, it will assume a new IP address
    on its next reboot that is different from the previous one. Therefore, if you
    need to connect to your Azure SQL database from your machine often, make sure
    to create a **static public IP address**. If you have just created a new Azure
    Virtual Machine, Azure will ask you if you want to make its current public IP
    address static when you stop it for the first time. If you decide yes, Azure will
    do everything automatically. Otherwise, you can easily configure it later by following
    this tutorial:[http://bit.ly/AzureVM-assign-static-ip](http://bit.ly/AzureVM-assign-static-ip)Click
    **Save** to keep your changes in the firewall settings.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'At this point, you can test the connection to your new Azure SQL database using
    SSMS. If you haven''t installed it yet, do so now by downloading the installer
    from the link [http://aka.ms/ssms](http://aka.ms/ssms). Once installed, open the
    **Microsoft SQL Server Management Studio** app from the **Start** menu (you can
    find it under the **Microsoft SQL Server Tools XX** folder). Use the server name
    in the `<your-server-name>.database.windows.net` format, choose **SQL Server Authentication**
    as the authentication method, and then enter the login and password you used during
    the creation of your Azure SQL database. Then click **Connect**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.26 – Connecting to your Azure SQL database with SSMS](img/file200.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 7.26 – Connecting to your Azure SQL database with SSMS
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'If the **Connect to Server** window disappears, then you are connected to your
    server. In fact, if you open the **Databases** node in the **Object Explorer**
    on the left, you can see your `SystemsLogging` database containing the `AdventureWorkLT`
    tables:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.27 – You are connected to your Azure SQL database](img/file201.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.27 – You are connected to your Azure SQL database
  prefs: []
  type: TYPE_NORMAL
- en: Awesome! Your Azure SQL database is running and ready to be used.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s try now to read and write data into a SQL Server or an Azure SQL database
    using Python.
  prefs: []
  type: TYPE_NORMAL
- en: Logging to an Azure SQL server with Python
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The most widely used Python module for connecting to databases to which you
    can connect via ODBC drivers is **pyodbc**. So, first you need to install this
    package in the `pbi_powerquery_env` environment:'
  prefs: []
  type: TYPE_NORMAL
- en: Open your Anaconda Prompt.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Switch to the `pbi_powerquery_env` environment by entering this command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Install the new package by entering this command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: At this point, you can start interacting with your database instances using
    Python.
  prefs: []
  type: TYPE_NORMAL
- en: Using the pyodbc module
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: First, you need to *create a connection* to your database instance. You can
    do this with the `connect()` function, which accepts a *connection string* as
    an argument. Depending on whether you need to connect to an instance of a SQL
    server on-premises or an Azure SQL database, the connection string varies only
    in its server parameter.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can establish a connection to your on-premises instance using the Windows
    authentication with this code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: You can also find the code snippets used here in the `11-read-write-on-azure-sql-server-with-python.py`
    file in the `Chapter07\Python` folder. In contrast to the other Python script
    you found in the repository, in this one you can find comments like `# %%`. They
    are placeholders that VS Code recognizes as **Jupyter-like code cells**. When
    VS Code identifies a cell, it automatically adds commands to execute its contents
    in the Interactive Window, making it easier for the user to interact with the
    code.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want to connect to the same instance using the SQL authentication instead,
    you can use this code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'The format of the previous connection strings remains the same even when you
    want to connect to an Azure SQL database. You must use the format `<your-server-name>.database.windows.net`
    as the server name. The authentication mode must necessarily be the SQL authentication
    mode. Therefore, the code to connect to your Azure SQL database is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Once you have established a connection to an instance of your choice, you can
    read data from tables or views via the pandas `read_sql()` function, which accepts
    a query in SQL (in our case, in **T-SQL** for SQL Server) as a parameter. For
    example, regardless of whether you are connected to your on-premises instance
    or on Azure, you can run the following code to read the database information available
    in the instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'In the case of Azure SQL, you will see this result:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.28 – Result of a query in Azure SQL database](img/file202.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.28 – Result of a query in Azure SQL database
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s try writing something to a database instead. First, in the case of your
    on-premises instance, you need to create a new database to write your data to.
    You can do that in SSMS following these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on **Connect**, and then on **Database Engine…**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.29 – Connecting to a database engine in SSMS](img/file203.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 7.29 – Connecting to a database engine in SSMS
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Connect to your `SQLExpress` instance using the Windows authentication with
    the string `.\SQLExpress` as the server name. Then, click on **Connect**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.30 – Connecting to your SQLExpress instance](img/file204.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 7.30 – Connecting to your SQLExpress instance
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Click on **New Query** on the toolbar at the top:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.31– Opening a new query editor](img/file205.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 7.31– Opening a new query editor
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Enter the `CREATE DATABASE SystemsLogging` script and then click on the **Execute**
    button with the green arrow (or just press **F5**).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Open the **Databases** node in the **Object Explorer** and you can now see
    the brand-new `SystemsLogging` database:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.32 – The new SystemsLogging database in your SQLExpress instance](img/file206.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.32 – The new SystemsLogging database in your SQLExpress instance
  prefs: []
  type: TYPE_NORMAL
- en: 'Now you can create the new `WrongEmails` table in the `SystemsLogging` database.
    It is usually preferable to run **Data Definition Language** (**DDL**) commands
    (like `CREATE`) directly in SSMS. In this case, we''ll do it through Python to
    show you some special commands. You will first create a `cursor` object from the
    `conn` connection and then call its `execute()` method, passing it a `CREATE TABLE`
    query:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Keep in mind that an Azure SQL Server database collects its objects (tables,
    views, and so on) in **SQL schemas**. Usually, when you create a database object,
    you also specify the schema in the `CREATE` statement. For a table, you generally
    use the `CREATE TABLE <your-schema>.<table-name>` script. The `WrongEmails` table
    was created without specifying any schema. Therefore, it assumes the default schema,
    which is `dbo`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Make sure to create the same table in your Azure SQL database:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'At this point, you can *write pandas DataFrame content* in the `WrongEmails`
    table row by row, using the `cursor.execute()` method, passing to it an `INSERT
    INTO` query. We will use the Azure SQL database in the example since there is
    also the `SalesLT.Customer` table there (note the `SalesLT` schema) from which
    to read some customer data to write to the `WrongEmails` table:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: The `iterrows()` function iterates over the DataFrame columns, and it will return
    a tuple with the column name and content in the form of series. Keep in mind that
    if you want to write to a SQL server on-premises, you only need to change the
    connection string, and the syntax you just saw remains valid. You can't run the
    code exactly as it is written in your `SQLExpress` instance simply because there
    is no `AdventureWorksLT` example data there, so it will give you an error.
  prefs: []
  type: TYPE_NORMAL
- en: 'To display the first rows of the `WrongEmails` table, you can use this code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'You will see something like this in VS Code:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.33 – The content of the WrongEmails table](img/file207.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.33 – The content of the WrongEmails table
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, make sure to empty the `WrongEmails` table with the following command
    so that it can be ready to be used later:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'When you have finished all read and write operations on the database instance,
    remember to close the connection as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Hey! You just learned how to read and write data from a SQL Server or Azure
    SQL database via Python. Simple, isn't it? Let's apply what you've learned in
    Power BI.
  prefs: []
  type: TYPE_NORMAL
- en: Logging emails and dates to an Azure SQL database in Power BI with Python
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In this section, we will use the same scenario provided in *Chapter 5*, *Using
    Regular Expressions in Power BI*, in which you validated email addresses and ban
    dates. The goal is to log the rows of the dataset containing incorrect emails
    to an Azure SQL database and to filter them out of the dataset so that only valid
    emails remain in Power BI. In order to properly execute the following Python code,
    you need to make sure you have created both the Azure SQL `SystemsLogging` database
    and the `WrongEmails` table as discussed in the previous section. If you prefer,
    you can also use your on-premises SQL Server instance by appropriately changing
    the server name in the connection string. In this case, make sure that the `SystemsLogging`
    database and the `WrongEmails` table are there.
  prefs: []
  type: TYPE_NORMAL
- en: 'The necessary steps are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Follow all the steps in the *Using regex in Power BI to validate emails with
    Python* section of *Chapter 5*, *Using Regular Expressions in Power BI*, to the
    end, but do not click on **Close & Apply**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then click on **Run Python Script**, enter the script you can find in the `Python\12-log-wrong-emails-azure-sql-in-power-bi.py`
    file, and click **OK**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on the `df` dataset’s **Table** value.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Only rows containing valid emails will be kept:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.34 – A table containing only valid emails](img/file208.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 7.34 – A table containing only valid emails
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Moreover, the invalid emails have been written into the `WrongEmails` table
    of your `SystemsLogging` Azure SQL database.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Go back to the **Home** menu, and then click **Close & Apply**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To verify that invalid emails were indeed written to the previous table, you
    can do this with SSMS:'
  prefs: []
  type: TYPE_NORMAL
- en: Connect with SSMS to your Azure SQL database using the `<your-server-name>.database.windows.net`
    string as **Server name** and the SQL authentication.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Open the **Databases** node, then open the **Tables** node, right-click on
    the **dbo.WrongEmails** table, and click on **Select Top 1000 Rows**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.35 – Querying the WrongEmails table in SSMS](img/file209.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 7.35 – Querying the WrongEmails table in SSMS
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'You’ll see the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 7.36 – The content of the WrongEmails table in SSMS](img/file210.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.36 – The content of the WrongEmails table in SSMS
  prefs: []
  type: TYPE_NORMAL
- en: Now, third-party systems can simply access your Azure SQL database (even simply
    with Excel, see the *References* section) to read invalid emails and mobilize
    the appropriate team to correct them.
  prefs: []
  type: TYPE_NORMAL
- en: Well done! You just learned how to log information to an Azure SQL database
    from Power BI using Python (you can do the same writing into an on-premises SQL
    Server database just by changing the connection string). Now, let's see how you
    can do the same using R.
  prefs: []
  type: TYPE_NORMAL
- en: Logging to an Azure SQL server with R
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To connect to a database via ODBC drivers in R, we will use two packages: `DBI`
    and `odbc`. The `DBI` package has the task of separating the connectivity to the
    database into a *frontend* and a *backend*. The R code you’ll write will use only
    the exposed frontend API. The backend will take care of communicating with the
    specific DBMS through special drivers provided by the installation of other packages.
    In our case, the `odbc` package will allow us to interface with SQL Server instances,
    both on-premises and on Azure. So, first you need to install these packages in
    your most recent MRO engine:'
  prefs: []
  type: TYPE_NORMAL
- en: Open RStudio, and make sure it is referencing your latest MRO in the **Global
    Options**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Enter this command into the console:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: At this point, you can start interacting with your database instances using
    R.
  prefs: []
  type: TYPE_NORMAL
- en: Using the DBI and odbc packages
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Also, in this case, you need to *create a connection* to your database instance.
    You can do this with the `dbConnect()` function of the DBI package, which accepts
    a *driver object* (in our case the `odbc()` one from the `odbc` package) and a
    *connection string* as arguments.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can establish a connection to your `SQLExpress` on-premises instance using
    the Windows authentication with this code:'
  prefs: []
  type: TYPE_NORMAL
- en: '`R\04-read-write-on-azure-sql-server-with-r.R`'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'If you want to connect to the same instance using the SQL authentication instead,
    you can use this code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'The format of the previous connection strings remains the same even when you
    want to connect to an Azure SQL database. You just need to use the `<your-server-name>.database.windows.net`
    format as the server name. In this case, the authentication mode must necessarily
    be the SQL authentication one. Therefore, the code to connect to your Azure SQL
    database is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'An interesting thing is that, as soon as the connection is established, RStudio
    allows you to browse the databases inside your server through the **Connections**
    tab at the top right. For example, *Figure 7.37* displays the contents of the
    `SystemLogging` database of the `SQLExpress` instance, going down to the detail
    of individual columns in a table:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.37 – RStudio’s object explorer of the connection established](img/file211.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.37 – RStudio’s object explorer of the connection established
  prefs: []
  type: TYPE_NORMAL
- en: Remember that the `WrongEmails` table was created in the previous section.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you have established a connection to an instance of your choice, you can
    easily read data from tables or views via the `DBI`’s `dbGetQuery()` function,
    which accepts a SQL query (in our case, T-SQL for SQL Server) as a parameter.
    For example, in the same way as with Python, you can run the following code to
    read the database information available on both on-premises instances and Azure
    SQL servers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'In the case of Azure SQL, you will see this result:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.38 – Result of a query on Azure SQL database](img/file212.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.38 – Result of a query on Azure SQL database
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s try writing something to a database instead. For example, you can *write
    a R DataFrame content* into the `WrongEmails` table using the `dbAppendTable()`
    method. It simply accepts the connection object, the name of the target table,
    and the DataFrame containing the source data. You just need to be careful to properly
    rename the source data columns using aliases in the SQL query (using the `AS`
    keyword) when reading from the database, so that the names match those of the
    target table columns. We will use an Azure SQL database in the example since there
    is also the `SalesLT.Customer` table from which to take the source data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Keep in mind that if you need to create the target table and fill it, you can
    use the one-shot `dbCreateTable()` method that get the same parameters of the
    `dbAppendTable()` method. To display the first rows of the `WrongEmails` table,
    you can use this code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'You will see something like this in VS Code:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.39 – The content of the WrongEmails table](img/file213.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.39 – The content of the WrongEmails table
  prefs: []
  type: TYPE_NORMAL
- en: 'Now make sure to empty the `WrongEmails` table with the `TRUNCATE TABLE` SQL
    command inside the `dbSendQuery()` method (which just executes a query without
    retrieving any data), so that it is ready to be used:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'When you have finished all read and write operations on the database instance,
    remember to close the connection, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: Wow! You just learned how to read and write data from a SQL server or Azure
    SQL database with R! Let's apply what you've learned in Power BI.
  prefs: []
  type: TYPE_NORMAL
- en: Logging emails and dates to an Azure SQL database in Power BI with R
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In this section, we will use the same scenario already used to show how to
    log data to Azure SQL from Power BI. In order to properly execute the following
    R code, you need to make sure you have created the Azure SQL `SystemsLogging`
    database and the `WrongEmails` table as discussed in the *Logging to an Azure
    SQL server with Python* section. If you prefer, you can also use your on-premises
    SQL Server instance by appropriately changing the server name in the connection
    string. In this case, make sure that the `SystemsLogging` database and the `WrongEmails`
    table are there. The necessary steps are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Follow all the steps in the *Using regex in Power BI to validate emails with
    R* section of *Chapter 5*, *Using Regular Expressions in Power BI*, to the end,
    but do not click on **Close & Apply**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then, click on **Run R Script**, enter the script you can find in the `R\05-log-wrong-emails-azure-sql-in-power-bi.R`
    file, and click **OK**. Remember to edit the server’s name and your credentials
    in the code.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on the `df` dataset’s **Table** value.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Only rows containing valid emails will be kept:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.40 – A table containing only valid emails](img/file214.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 7.40 – A table containing only valid emails
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Moreover, the invalid emails have been written into the `WrongEmails` table
    in your Azure SQL database.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Go back to the **Home** menu, and then click **Close & Apply**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'As done before, you can verify that invalid emails were written to the previous
    table with SSMS. You’ll see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.41 – The content of the WrongEmails table in SSMS](img/file215.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.41 – The content of the WrongEmails table in SSMS
  prefs: []
  type: TYPE_NORMAL
- en: Awesome! You’ve just logged your wrong emails to your (Azure) SQL Server database
    using R from Power BI.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this chapter, you learned how to log some information processed in Power
    Query to CSV files, Excel, on-premises SQL Servers, and Azure SQL, in both Python
    and R, using very simple and straightforward commands.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, you will see how to handle very large CSV files that cannot
    be loaded from Power BI Desktop due to the RAM size of your machine not being
    sufficient.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For additional reading, check out the following books and articles:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Common Format and MIME Type for Comma-Separated Values (CSV) Files* ([https://tools.ietf.org/html/rfc4180](https://tools.ietf.org/html/rfc4180))'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Excel (.xlsx) Extensions to the Office Open XML SpreadsheetML File Format*
    ([https://docs.microsoft.com/en-us/openspecs/office_standards/ms-xlsx/](https://docs.microsoft.com/en-us/openspecs/office_standards/ms-xlsx/))'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Connect Excel to a database in Azure SQL Database* ([https://docs.microsoft.com/en-us/azure/azure-sql/database/connect-excel](https://docs.microsoft.com/en-us/azure/azure-sql/database/connect-excel))'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
