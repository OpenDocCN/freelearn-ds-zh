["```py\ndef filter_insignificant(chunk, tag_suffixes=['DT', 'CC']):\n  good = []\n\n  for word, tag in chunk:\n    ok = True\n\n    for suffix in tag_suffixes:\n      if tag.endswith(suffix):\n        ok = False\n        break\n\n    if ok:\n      good.append((word, tag))\n\n  return good\n```", "```py\n>>> from transforms import filter_insignificant\n>>> filter_insignificant([('the', 'DT'), ('terrible', 'JJ'), ('movie', 'NN')])\n[('terrible', 'JJ'), ('movie', 'NN')]\n```", "```py\n>>> filter_insignificant([('your', 'PRP$'), ('book', 'NN'), ('is', 'VBZ'), ('great', 'JJ')], tag_suffixes=['PRP', 'PRP$'])\n[('book', 'NN'), ('is', 'VBZ'), ('great', 'JJ')]\n```", "```py\nplural_verb_forms = {\n  ('is', 'VBZ'): ('are', 'VBP'),\n  ('was', 'VBD'): ('were', 'VBD')\n}\n\nsingular_verb_forms = {\n  ('are', 'VBP'): ('is', 'VBZ'),\n  ('were', 'VBD'): ('was', 'VBD')\n}\n```", "```py\ndef first_chunk_index(chunk, pred, start=0, step=1):\n  l = len(chunk)\n  end = l if step > 0 else -1\n\n  for i in range(start, end, step):\n    if pred(chunk[i]):\n      return i\n\n  return None\n\ndef correct_verbs(chunk):\n  vbidx = first_chunk_index(chunk, lambda (word, tag): tag.startswith('VB'))\n  # if no verb found, do nothing\n  if vbidx is None:\n    return chunk\n\n  verb, vbtag = chunk[vbidx]\n  nnpred = lambda (word, tag): tag.startswith('NN')\n  # find nearest noun to the right of verb\n  nnidx = first_chunk_index(chunk, nnpred, start=vbidx+1)\n  # if no noun found to right, look to the left\n  if nnidx is None:\n    nnidx = first_chunk_index(chunk, nnpred, start=vbidx-1, step=-1)\n  # if no noun found, do nothing\n  if nnidx is None:\n    return chunk\n\n  noun, nntag = chunk[nnidx]\n  # get correct verb form and insert into chunk\n  if nntag.endswith('S'):\n    chunk[vbidx] = plural_verb_forms.get((verb, vbtag), (verb, vbtag))\n  else:\n    chunk[vbidx] = singular_verb_forms.get((verb, vbtag), (verb, vbtag))\n\n  return chunk\n```", "```py\n>>> from transforms import correct_verbs\n>>> correct_verbs([('is', 'VBZ'), ('our', 'PRP$'), ('children', 'NNS'), ('learning', 'VBG')])\n[('are', 'VBP'), ('our', 'PRP$'), ('children', 'NNS'), ('learning', 'VBG')]\n```", "```py\n>>> correct_verbs([('our', 'PRP$'), ('child', 'NN'), ('were', 'VBD'), ('learning', 'VBG')])\n[('our', 'PRP$'), ('child', 'NN'), ('was', 'VBD'), ('learning', 'VBG')]\n```", "```py\ndef swap_verb_phrase(chunk):\n  # find location of verb\n  vbpred = lambda (word, tag): tag != 'VBG' and tag.startswith('VB') and len(tag) > 2\n  vbidx = first_chunk_index(chunk, vbpred)\n\n  if vbidx is None:\n    return chunk\n\n  return chunk[vbidx+1:] + chunk[:vbidx]\n```", "```py\n>>> from transforms import swap_verb_phrase\n>>> swap_verb_phrase([('the', 'DT'), ('book', 'NN'), ('was', 'VBD'), ('great', 'JJ')])\n[('great', 'JJ'), ('the', 'DT'), ('book', 'NN')]\n```", "```py\n>>> swap_verb_phrase([('this', 'DT'), ('gripping', 'VBG'), ('book', 'NN'), ('is', 'VBZ'), ('fantastic', 'JJ')])\n[('fantastic', 'JJ'), ('this', 'DT'), ('gripping', 'VBG'), ('book', 'NN')]\n```", "```py\n>>> from transforms import swap_verb_phrase, filter_insignificant\n>>> swap_verb_phrase(filter_insignificant([('this', 'DT'), ('gripping', 'VBG'), ('book', 'NN'), ('is', 'VBZ'), ('fantastic', 'JJ')]))\n[('fantastic', 'JJ'), ('gripping', 'VBG'), ('book', 'NN')]\n>>> filter_insignificant(swap_verb_phrase([('this', 'DT'), ('gripping', 'VBG'), ('book', 'NN'), ('is', 'VBZ'), ('fantastic', 'JJ')]))\n[('fantastic', 'JJ'), ('gripping', 'VBG'), ('book', 'NN')]\n```", "```py\ndef swap_noun_cardinal(chunk):\n  cdidx = first_chunk_index(chunk, lambda (word, tag): tag == 'CD')\n  # cdidx must be > 0 and there must be a noun immediately before it\n  if not cdidx or not chunk[cdidx-1][1].startswith('NN'):\n    return chunk\n\n  noun, nntag = chunk[cdidx-1]\n  chunk[cdidx-1] = chunk[cdidx]\n  chunk[cdidx] = noun, nntag\n  return chunk\n```", "```py\n>>> from transforms import swap_noun_cardinal\n>>> swap_noun_cardinal([('Dec.', 'NNP'), ('10', 'CD')])\n[('10', 'CD'), ('Dec.', 'NNP')]\n>>> swap_noun_cardinal([('the', 'DT'), ('top', 'NN'), ('10', 'CD')])\n[('the', 'DT'), ('10', 'CD'), ('top', 'NN')]\n```", "```py\ndef swap_infinitive_phrase(chunk):\n  inpred = lambda (word, tag): tag == 'IN' and word != 'like'\n  inidx = first_chunk_index(chunk, inpred)\n\n  if inidx is None:\n    return chunk\n\n  nnpred = lambda (word, tag): tag.startswith('NN')\n  nnidx = first_chunk_index(chunk, nnpred, start=inidx, step=-1) or 0\n\n  return chunk[:nnidx] + chunk[inidx+1:] + chunk[nnidx:inidx]\n```", "```py\n>>> from transforms import swap_infinitive_phrase\n>>> swap_infinitive_phrase([('book', 'NN'), ('of', 'IN'), ('recipes', 'NNS')])\n[('recipes', 'NNS'), ('book', 'NN')]\n```", "```py\n>>> swap_infinitive_phrase([('delicious', 'JJ'), ('book', 'NN'), ('of', 'IN'), ('recipes', 'NNS')])\n[('delicious', 'JJ'), ('recipes', 'NNS'), ('book', 'NN')]\n```", "```py\n>>> swap_infinitive_phrase([('tastes', 'VBZ'), ('like', 'IN'), ('chicken', 'NN')])\n[('tastes', 'VBZ'), ('like', 'IN'), ('chicken', 'NN')]\n```", "```py\ndef singularize_plural_noun(chunk):\n  nnspred = lambda (word, tag): tag == 'NNS'\n  nnsidx = first_chunk_index(chunk, nnspred)\n\n  if nnsidx is not None and nnsidx+1 < len(chunk) and chunk[nnsidx+1][1][:2] == 'NN':\n    noun, nnstag = chunk[nnsidx]\n    chunk[nnsidx] = (noun.rstrip('s'), nnstag.rstrip('S'))\n\n  return chunk\n```", "```py\n>>> from transforms import singularize_plural_noun\n>>> singularize_plural_noun([('recipes', 'NNS'), ('book', 'NN')])\n[('recipe', 'NN'), ('book', 'NN')]\n```", "```py\ndef transform_chunk(chunk, chain=[filter_insignificant, swap_verb_phrase, swap_infinitive_phrase, singularize_plural_noun], trace=0):\n  for f in chain:\n    chunk = f(chunk)\n\n    if trace:\n      print f.__name__, ':', chunk\n\n  return chunk\n```", "```py\n>>> from transforms import transform_chunk\n>>> transform_chunk([('the', 'DT'), ('book', 'NN'), ('of', 'IN'), ('recipes', 'NNS'), ('is', 'VBZ'), ('delicious', 'JJ')])\n[('delicious', 'JJ'), ('recipe', 'NN'), ('book', 'NN')]\n```", "```py\n>>> from transforms import transform_chunk\n>>> transform_chunk([('the', 'DT'), ('book', 'NN'), ('of', 'IN'), ('recipes', 'NNS'), ('is', 'VBZ'), ('delicious', 'JJ')], trace=1)\nfilter_insignificant : [('book', 'NN'), ('of', 'IN'), ('recipes', 'NNS'), ('is', 'VBZ'), ('delicious', 'JJ')]\nswap_verb_phrase : [('delicious', 'JJ'), ('book', 'NN'), ('of', 'IN'), ('recipes', 'NNS')]\nswap_infinitive_phrase : [('delicious', 'JJ'), ('recipes', 'NNS'), ('book', 'NN')]\nsingularize_plural_noun : [('delicious', 'JJ'), ('recipe', 'NN'), ('book', 'NN')]\n[('delicious', 'JJ'), ('recipe', 'NN'), ('book', 'NN')]\n```", "```py\n>>> from nltk.corpus import treebank_chunk\n>>> tree = treebank_chunk.chunked_sents()[0]\n>>> ' '.join([w for w, t in tree.leaves()])\n'Pierre Vinken , 61 years old , will join the board as a nonexecutive director Nov. 29 .'\n```", "```py\nimport re\npunct_re = re.compile(r'\\s([,\\.;\\?])')\n\ndef chunk_tree_to_sent(tree, concat=' '):\n  s = concat.join([w for w, t in tree.leaves()])\n  return re.sub(punct_re, r'\\g<1>', s)\n```", "```py\n>>> from transforms import chunk_tree_to_sent\n>>> chunk_tree_to_sent(tree)\n'Pierre Vinken, 61 years old, will join the board as a nonexecutive director Nov. 29.'\n```", "```py\nimport nltk.tag, re\npunct_re = re.compile(r'\\s([,\\.;\\?])')\n\ndef chunk_tree_to_sent(tree, concat=' '):\n  s = concat.join(nltk.tag.untag(tree.leaves()))\n  return re.sub(punct_re, r'\\g<1>', s)\n```", "```py\nfrom nltk.tree import Tree\n\ndef flatten_childtrees(trees):\n  children = []\n\n  for t in trees:\n    if t.height() < 3:\n      children.extend(t.pos())\n    elif t.height() == 3:\n      children.append(Tree(t.node, t.pos()))\n    else:\n      children.extend(flatten_childtrees([c for c in t]))\n\n  return children\n\ndef flatten_deeptree(tree):\n  return Tree(tree.node, flatten_childtrees([c for c in tree]))\n```", "```py\n>>> from nltk.corpus import treebank\n>>> from transforms import flatten_deeptree\n>>> flatten_deeptree(treebank.parsed_sents()[0])\nTree('S', [Tree('NP', [('Pierre', 'NNP'), ('Vinken', 'NNP')]), (',', ','), Tree('NP', [('61', 'CD'), ('years', 'NNS')]), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), Tree('NP', [('the', 'DT'), ('board', 'NN')]), ('as', 'IN'), Tree('NP', [('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN')]), Tree('NP-TMP', [('Nov.', 'NNP'), ('29', 'CD')]), ('.', '.')])\n```", "```py\n>>> from nltk.tree import Tree\n>>> Tree('NNP', ['Pierre']).height()\n2\n```", "```py\n>>> Tree('NNP', ['Pierre']).pos()\n[('Pierre', 'NNP')]\n```", "```py\n>>> Tree('NP', [Tree('NNP', ['Pierre']), Tree('NNP', ['Vinken'])]).height()\n3\n```", "```py\n>>> Tree('NP', [Tree('NNP', ['Pierre']), Tree('NNP', ['Vinken'])]).pos()\n[('Pierre', 'NNP'), ('Vinken', 'NNP')]\n```", "```py\n>>> from nltk.chunk.util import tree2conlltags\n>>> tree2conlltags(treebank.parsed_sents()[0])\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"/usr/local/lib/python2.6/dist-packages/nltk/chunk/util.py\", line 417, in tree2conlltags\n    raise ValueError, \"Tree is too deeply nested to be printed in CoNLL format\"\nValueError: Tree is too deeply nested to be printed in CoNLL format\n```", "```py\n>>> tree2conlltags(flatten_deeptree(treebank.parsed_sents()[0]))\n[('Pierre', 'NNP', 'B-NP'), ('Vinken', 'NNP', 'I-NP'), (',', ',', 'O'), ('61', 'CD', 'B-NP'), ('years', 'NNS', 'I-NP'), ('old', 'JJ', 'O'), (',', ',', 'O'), ('will', 'MD', 'O'), ('join', 'VB', 'O'), ('the', 'DT', 'B-NP'), ('board', 'NN', 'I-NP'), ('as', 'IN', 'O'), ('a', 'DT', 'B-NP'), ('nonexecutive', 'JJ', 'I-NP'), ('director', 'NN', 'I-NP'), ('Nov.', 'NNP', 'B-NP-TMP'), ('29', 'CD', 'I-NP-TMP'), ('.', '.', 'O')]\n```", "```py\n>>> from nltk.corpus import cess_esp\n>>> cess_esp.parsed_sents()[0].height()\n22\n>>> flatten_deeptree(cess_esp.parsed_sents()[0]).height()\n3\n```", "```py\nfrom nltk.tree import Tree\n\ndef shallow_tree(tree):\n  children = []\n\n  for t in tree:\n    if t.height() < 3:\n      children.extend(t.pos())\n    else:\n      children.append(Tree(t.node, t.pos()))\n\n  return Tree(tree.node, children)\n```", "```py\n>>> from transforms import shallow_tree\n>>> shallow_tree(treebank.parsed_sents()[0])\nTree('S', [Tree('NP-SBJ', [('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ',')]), Tree('VP', [('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD')]), ('.', '.')])\n```", "```py\n>>> treebank.parsed_sents()[0].height()\n7\n>>> shallow_tree(treebank.parsed_sents()[0]).height()\n3\n```", "```py\nfrom nltk.tree import Tree\n\ndef convert_tree_nodes(tree, mapping):\n  children = []\n\n  for t in tree:\n    if isinstance(t, Tree):\n      children.append(convert_tree_nodes(t, mapping))\n    else:\n      children.append(t)\n\n  node = mapping.get(tree.node, tree.node)\n  return Tree(node, children)\n```", "```py\n>>> from transforms import convert_tree_nodes\n>>> mapping = {'NP-SBJ': 'NP', 'NP-TMP': 'NP'}\n>>> convert_tree_nodes(treebank.parsed_sents()[0], mapping)\nTree('S', [Tree('NP', [Tree('NP', [Tree('NNP', ['Pierre']), Tree('NNP', ['Vinken'])]), Tree(',', [',']), Tree('ADJP', [Tree('NP', [Tree('CD', ['61']), Tree('NNS', ['years'])]), Tree('JJ', ['old'])]), Tree(',', [','])]), Tree('VP', [Tree('MD', ['will']), Tree('VP', [Tree('VB', ['join']), Tree('NP', [Tree('DT', ['the']), Tree('NN', ['board'])]), Tree('PP-CLR', [Tree('IN', ['as']), Tree('NP', [Tree('DT', ['a']), Tree('JJ', ['nonexecutive']), Tree('NN', ['director'])])]), Tree('NP', [Tree('NNP', ['Nov.']), Tree('CD', ['29'])])])]), Tree('.', ['.'])])\n```"]