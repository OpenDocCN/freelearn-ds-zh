- en: Chapter 4. Working with PostGIS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Executing a PostGIS ST_Buffer analysis query and exporting it to GeoJSON
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finding out whether a point is inside a polygon
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Splitting LineStrings at intersections using ST_Node
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Checking the validity of LineStrings
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Executing a spatial join and assigning point attributes to a polygon
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conducting a complex spatial analysis query using ST_Distance()
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A spatial database is nothing but a standard database that can store geometry
    and execute spatial queries in their simplest forms. We will explore how to run
    spatial analysis queries, handle connections, and more, all from our Python code.
    Your ability to answer spatial questions such as "I want to locate all the hotels
    that are within 2 km of a golf course and less than 5 km from a park" is where
    PostGIS comes into play. This chaining of requests into a model is where the powers
    of spatial analysis shine.
  prefs: []
  type: TYPE_NORMAL
- en: We will work with the most popular and powerful open source spatial database
    called **PostgreSQL**, along with the **PostGIS** extension, including over 150
    functions. Basically, we'll get a full-blown GIS with complex spatial analysis
    functions for both vectors and rasters, spatial data types, and diverse methods
    to move spatial data around.
  prefs: []
  type: TYPE_NORMAL
- en: If you are looking for more information on PostGIS and a good read, please check
    out *PostGIS Cookbook* by *Paolo Corti* (available at [https://www.packtpub.com/big-data-and-business-intelligence/postgis-cookbook](https://www.packtpub.com/big-data-and-business-intelligence/postgis-cookbook)).
    This book explores the wider use of PostGIS and includes a full chapter on PostGIS
    Programming using Python.
  prefs: []
  type: TYPE_NORMAL
- en: Executing a PostGIS ST_Buffer analysis query and exporting it to GeoJSON
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's start by executing our first spatial analysis query from Python against
    our already running PostgreSQL and PostGIS database. The goal is to generate a
    100 m buffer around all schools and export the new buffer polygon to GeoJSON,
    including the name of a school. The end result will be shown on this map, available
    ([https://github.com/mdiener21/python-geospatial-analysis-cookbook/blob/master/ch04/geodata/out_buff_100m.geojson](https://github.com/mdiener21/python-geospatial-analysis-cookbook/blob/master/ch04/geodata/out_buff_100m.geojson))
    on GitHub.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Quick visualizations of GeoJSON data using GitHub is a fast and simple way to
    create a web map without coding a single line. Note that the data is then free
    for everyone else to download if you are using a public and free GitHub account.
    Private GitHub accounts mean the data, that is, GeoJSON, will also remain private
    if data privacy or sensitivity is an issue.
  prefs: []
  type: TYPE_NORMAL
- en: '![Executing a PostGIS ST_Buffer analysis query and exporting it to GeoJSON](img/50790OS_04_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To get started, we'll use our data in the PostGIS database. We will begin by
    accessing our `schools` table that we uploaded to PostGIS in the Batch importing
    a folder of Shapefiles into PostGIS using ogr2ogr recipe of [Chapter 3](ch03.html
    "Chapter 3. Moving Spatial Data from One Format to Another"), *Moving Spatial
    Data from One Format to Another*.
  prefs: []
  type: TYPE_NORMAL
- en: Connecting to a PostgreSQL and PostGIS database is accomplished with **Psycopg**,
    which is a Python DB API ([http://initd.org/psycopg/](http://initd.org/psycopg/))
    implementation. We've already installed this in [Chapter 1](ch01.html "Chapter 1. Setting
    Up Your Geospatial Python Environment"), *Setting Up Your Geospatial Python Environment*
    along with PostgreSQL, Django, and PostGIS.
  prefs: []
  type: TYPE_NORMAL
- en: 'For all the following recipes, enter your virtual environment, `pygeoan_cb`,
    so that you have access to your libraries using this command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The long road is not so long after all, so follow along:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The database connection is using the `pyscopg2` module, so we import the libraries
    at the start alongside `geojson` and the standard `json` modules to handle our
    GeoJSON export.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our connection is created and then followed immediately with our SQL Buffer
    query string. The query uses three PostGIS functions. Working your way from the
    inside out, you will see the `ST_Buffer` function taking in the geometry of the
    school points followed by the 100 m buffer distance and the number of circle segments
    that we would like to generate. `ST_Transform` then takes the newly created buffer
    geometry and transforms it into the WGS84 coordinate system (EPSG: 4326) so that
    we can display it on GitHub, which only displays WGS84 and the projected GeoJSON.
    Lastly, we''ll use the `ST_asGeoJSON` function to export our geometry as the GeoJSON
    geometry.'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: PostGIS does not export the complete GeoJSON syntax, only the geometry in the
    form of the GeoJSON geometry. This is the reason that we need to complete our
    GeoJSON using the Python `geojson` module.
  prefs: []
  type: TYPE_NORMAL
- en: All of this means that we not only perform analysis on the query, but we also
    specify the output format and coordinate system all in one go.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will execute the query and fetch all the returned objects using `cur.fetchall()`
    so that we can later loop through each returned buffer polygon. Our `new_geom_collection`
    list will store each of the new geometries and the feature names. Next, in the
    `for` loop function, we'll use the `geojson` module function, `loads(geom)`, to
    input our geometry into a GeoJSON geometry object. This is followed by the `Feature()`function
    that actually creates our GeoJSON feature. This is then used as the input for
    the `FeatureCollection` function where the final, completed GeoJSON is created.
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, we'll need to write this new GeoJSON file to disk and save it. Hence,
    we'll use the new file object where we use the standard Python `json.dumps` module
    to export our `FeatureCollection`.
  prefs: []
  type: TYPE_NORMAL
- en: We'll do a little clean up to close the cursor object and connection. Bingo!
    We are now done and can visualize our final results.
  prefs: []
  type: TYPE_NORMAL
- en: Finding out whether a point is inside a polygon
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A point inside a polygon analysis query is a very common spatial operation.
    This query can identify objects located within an area such as a polygon. The
    area of interest in this example is a 100 m buffer polygon around bike paths and
    we would like to locate all schools that are inside this polygon.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the previous section, we used the `schools` table to create a buffer. This
    time around, we will use this table as our input points table. The `bikeways`
    table that we imported in [Chapter 3](ch03.html "Chapter 3. Moving Spatial Data
    from One Format to Another"), *Moving Spatial Data from One Format to Another*,
    will be used as our input lines to generate a new 100 m buffer polygon. Be sure,
    however, that you have the two datasets in your local PostgreSQL database.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now, let''s dive into some more code to find schools located within 100 m of
    the bikeways in order to find points inside a polygon:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You can now view your newly created GeoJSON file on a great little site created
    by Mapbox at [http://www.geojson.io](http://www.geojson.io). Simply drag and drop
    your GeoJSON file from Windows Explorer in Windows or Nautilus in Ubuntu onto
    the [http://www.geojson.io](http://www.geojson.io) web page and, Bob's your uncle,
    you should see 50 or so schools that are located within 100 m of a bikeway in
    Vancouver.
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it...](img/50790OS_04_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will reuse code to make our database connection, so this should be familiar
    to you at this point. The `new_bike_buff_100m` query string contains our query
    to generate a new 100 m buffer polygon around all the bikeways. We need to execute
    this query and commit it to the database so that we can access this new set of
    polygons as input to our actual query that will find schools (points) located
    inside this new buffer polygon.
  prefs: []
  type: TYPE_NORMAL
- en: The `is_inside_query` string actually does the hard work for us by selecting
    selecting the values from the field `name` and the geometry from the `geom` field.
    The geometry is wrapped up in two other PostGIS functions to allow us to export
    our data as GeoJSON in the WGS 84 coordinate system. This will be the input geometry
    needed to generate our final new GeoJSON file.
  prefs: []
  type: TYPE_NORMAL
- en: The `WHERE` clause uses the `ST_Within` function to see whether a point is inside
    the polygon and returns `True` if the point is within the buffer polygon.
  prefs: []
  type: TYPE_NORMAL
- en: Now, we've created a new function that simply wraps up our export to the GeoJSON
    code that was used in the previous, *Executing a PostGIS ST_Buffer analysis query
    and exporting it to GeoJSON*, recipe. This new `export2geojson` function simply
    takes one input of our PostGIS query and outputs a GeoJSON file. To set the name
    and location of the new output file, simply replace the path and name within the
    function.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, all we need to do is call the new function to export the GeoJSON file
    using the `db_rows` variable that contains our list of schools as points located
    within the 100 m buffer polygon.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This example to find all schools located within 100 m of the bike paths could
    be completed using another PostGIS function called `ST_Dwithin`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The SQL to select all the schools located within 100 m of the bikepaths would
    look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Splitting LineStrings at intersections using ST_Node
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Working with road data is usually a tricky business because the validity of
    the data and data structure plays a very important role. If you want to do anything
    useful with your road data, such as building a routing network, you will need
    to prepare the data first. The first task is usually to segmentize your lines,
    which means splitting all lines at intersections where LineStrings cross each
    other, creating a base network road dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Be aware that this recipe will split all lines on all intersections regardless
    of whether, for example, there is a road-bridge overpass where no intersection
    should be created.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before we get into the details of how to do this, we will use a small section
    of the **OpenStreetMap** (**OSM**) road data for our example. The OSM data is
    available in your `/ch04/geodata/`folder called `vancouver-osm-data.osm`. This
    data was simply downloaded from the [www.openstreetmap.org](http://www.openstreetmap.org)
    home page using the **Export** button located at the top of the page:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Getting ready](img/50790OS_04_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The OSM data contains not only roads but all the other points and polygons located
    within the extent that I have chosen. The region of interest is again the Burrard
    Street bridge in Vancouver.
  prefs: []
  type: TYPE_NORMAL
- en: 'We are going to need to extract all the roads and import them into our PostGIS
    table. This time, let''s try using the `ogr2ogr` command line directly from the
    console to upload the OSM streets to our PostGIS database:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: This assumes that your OSM data is in the `/ch04/geodata` folder and the command
    is run while you are located in the `/ch04/code` folder.
  prefs: []
  type: TYPE_NORMAL
- en: Now this really long thing means that we connect to our PostGIS database as
    our output and input the `vancouver-osm-data.osm` file. Create a new table called
    `lines` and transform the input OSM projection to EPSG:3857\. All data exported
    from OSM is in EPSG:4326\. You can, of course, leave it in this system and simply
    remove the `-t_srs EPSG:3857` part of the command line option.
  prefs: []
  type: TYPE_NORMAL
- en: 'We are now ready to rock and roll with the splitting at intersections. If you
    like, go ahead and open the data in **QGIS** (**Quantum GIS**). In QGIS, you will
    see that the road data is not split at all road intersections as shown in this
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Getting ready](img/50790OS_04_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Here, you can see that **McNicoll Avenue** is a single LineString crossing over
    **Cypress Street**. After we've completed the recipe, we will see that **McNicoll
    Avenue** will be split at this intersection.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Running through the Python code is quite straightforward since the hard work
    is done in one SQL query. So follow along:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![How to do it...](img/50790OS_04_05.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Well, this was quite simple and we can now see that **McNicoll Avenue** is split
    at the intersection with **Cypress Street**.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Looking at the code, we can see that the database connection remains the same
    and the only new thing is the query itself that creates the intersection. Here
    three separate PostGIS functions are used to obtain our results:'
  prefs: []
  type: TYPE_NORMAL
- en: The first function, when working our way inside-out in the query, starts with
    `ST_Collect(wkb_geometry)`. This simply takes our original geometry column as
    input. The simple combining of the geometries is all that is going on here.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Next up is the actual splitting of the lines using the `ST_Node(geometry)`,
    inputting the new geometry collection and nodding, which splits our LineStrings
    at intersections.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, we'll use `ST_Dump()` as a set returning function. This means that
    it basically explodes all the LineString geometry collections into individual
    LineStrings. The end of the query with `.geom` specifies that we only want to
    export the geometry and not the returned array numbers of the split geometry.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, we'll execute and commit the query to the database. The commit is an important
    part because, otherwise, the query will be run but it will not actually create
    the new table that we are looking to generate. Last but not least, we can close
    down our cursor and connection. That is that; we now have split LineStrings.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Be aware that the new split LineStrings do NOT contain the street names and
    other attributes. To export the names, we would need to do a join on our data.
    Such a query to include the attributes on the newly created LineStrings could
    look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Checking the validity of LineStrings
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Working with road data has many areas to watch out for and one of these is invalid
    geometry. Our source data is OSM and is, therefore, collected by a community of
    users that are not trained by GIS professionals, resulting in errors. To execute
    spatial queries, the data must be valid or we will have results with errors or
    no results at all.
  prefs: []
  type: TYPE_NORMAL
- en: PostGIS includes the `ST_isValid()` function that returns True/False on the
    basis of whether a geometry is valid or not. There is also the `ST_isValidReason()`
    function that will output a text description of the geometry error. Finally, the
    `ST_isValidDetail()` function will return if the geometry is valid along with
    the reason and location of the geometry error. These three functions all accomplish
    similar tasks and selecting one depends on what you want to accomplish.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now, to determine if `geodata.lines` are valid, we will run another query that
    will list all invalid geometries if there are any:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This query should return an empty Python list, which means that we have no invalid
    geometries. If there are objects in your list, then you'll know that you have
    some manual work to do to correct those geometries. Your best bet is to fire up
    QGIS and get started with digitizing tools to clean things up.
  prefs: []
  type: TYPE_NORMAL
- en: Executing a spatial join and assigning point attributes to a polygon
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We'll now get back to some more golf action where we would like to execute a
    spatial attribute join. We're given a situation where we have a set of polygons,
    in this case, these are in the form of golf greens without any hole number. Our
    hole number is stored in a point dataset that is located spatially within the
    green of each hole. We would like to assign each green its appropriate hole number
    based on its location within the polygon.
  prefs: []
  type: TYPE_NORMAL
- en: The OSM data from the Pebble Beach Golf Course located in Monterey California
    is our source data. This golf course is one the great golf courses on the PGA
    tour and is well mapped in OSM.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If you are interested in getting golf course data yourself from OSM, it is recommended
    that you use the great Overpass API at [http://overpass-turbo.eu/](http://overpass-turbo.eu/).
    This site enables you to export the OSM data as GeoJSON or KML, for example.
  prefs: []
  type: TYPE_NORMAL
- en: 'To download all the golf-specific OSM data, you will need to correct tags.
    To do this, simply copy and paste the following Overpass API query into the query
    window located on the left hand side, then click on `Download`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Importing our data into PostGIS will be the first step to execute our spatial
    query. This time around, we will use the `shp2pgsql` tool to import our data to
    change things a little since there are so many ways to get data into PostGIS.
    The `shp2pgsql` tool is definitely the most well-tested and common way to import
    Shapefiles into PostGIS. Let's get going and perform this import once again, executing
    this tool directly from the command line.
  prefs: []
  type: TYPE_NORMAL
- en: For Windows users, this should work, but check that the paths are correct or
    that `shp2pgsql.exe` is in your system path variable. By doing this, you save
    having to type the full path to execute.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'I assume that you are running the following command when you are in the `/ch04/code`
    folder:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: On a Linux machine your command is basically the same without the long path,
    assuming that your system links were all set up when you installed PostGIS in
    [Chapter 1](ch01.html "Chapter 1. Setting Up Your Geospatial Python Environment"),
    *Setting Up Your Geospatial Python Environment*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next up, we need to import our points with the attributes, so let''s get to
    it as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: That's that! We now have our points and polygons available in the PostGIS Schema
    `geodata` setting, which sets the stage for our spatial join.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The core work is done once again inside our PostGIS query string, assigning
    the attributes to the polygons, so follow along:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The query is straightforward enough; we'll use the `UPDATE` standard SQL command
    to update the values in the name field of our table, `geodata.pebble_beach_greens`,
    with the hole numbers located in the `pebble_beach_hole_num` table.
  prefs: []
  type: TYPE_NORMAL
- en: We follow up by setting the name value from our `geodata.pebble_beach_hole_num`
    table, where the field name also exists and holds our needed attribute values.
  prefs: []
  type: TYPE_NORMAL
- en: Our `WHERE` clause uses the PostGIS query, `ST_Contains`, to return `True` if
    the point lies inside our greens, and if so, it will update our values.
  prefs: []
  type: TYPE_NORMAL
- en: This was easy and demonstrates the great power of spatial relationships.
  prefs: []
  type: TYPE_NORMAL
- en: Conducting a complex spatial analysis query using ST_Distance()
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now let's check for a more complex query in PostGIS to get our spatial juices
    flowing. We want to locate all the golf courses that are either inside or within
    5 km of a national park or protected area. Plus, the golf course must be within
    2 km of a city. The city data is derived from the tags in OSM where the *tag place
    = city*.
  prefs: []
  type: TYPE_NORMAL
- en: The national parks and protected areas for this query belong to the Government
    of Canada. Our golf courses and datasets of cities are derived from an OSM located
    in British Columbia and Alberta.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We need the data of all the national parks and protected areas in Canada, so
    go and make sure they're located in the `/ch04/geodata/` folder.
  prefs: []
  type: TYPE_NORMAL
- en: The original data is located at [http://ftp2.cits.rncan.gc.ca/pub/geott/frameworkdata/protected_areas/1M_PROTECTED_AREAS.shp.zip](http://ftp2.cits.rncan.gc.ca/pub/geott/frameworkdata/protected_areas/1M_PROTECTED_AREAS.shp.zip)
    for download if you do not already have the `/geodata` folder downloaded from
    GitHub.
  prefs: []
  type: TYPE_NORMAL
- en: The other datasets needed are the cities and golf courses that can be obtained
    from OSM. These two files are the GeoJSON files located in the /ch04/geodata/
    folder and are called `osm-golf-courses-bc-alberta.geojson` and `osm-place-city-bc-alberta.geojson`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will now import the downloaded data into our database:'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Ensure that you are currently in the `/ch04/code` folder when you run the following
    commands; otherwise, adjust the paths as necessary.
  prefs: []
  type: TYPE_NORMAL
- en: 'Starting with the OSM golf courses from British Columbia and Alberta, run this
    command-line call to ogr2ogr. Windows users need to note that they can either
    switch the slashes to backslashes or include the full path to GeoJSON:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we''ll run the same command again to import the cities:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Last but not least, we''ll need to import the protected areas and national
    parks of Canada using the `shp2pgsql` command line. Here, note that we need to
    use the `-W latin1` option to specify the required encoding. The data you acquire
    is for all of Canada and not just BC and Alberta:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now we have all three tables in our database and we can execute our analysis
    script.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s see what the code looks like:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s go step by step through the SQL query:'
  prefs: []
  type: TYPE_NORMAL
- en: We'll start with defining what columns we want our query to return and from
    which tables. Here, we'll define that we want the golf club geometry as a point,
    city name, golf club name, park name, distance between a city and golf club, and
    finally, distance between a park and golf club. The geometry that we return is
    of the golf course as a point, hence `ST_Centroid`, which returns the middle point
    of the golf course and then outputs this as the GeoJSON geometry.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `FROM` clause sets our parks and tables of cities and assigns them an alias
    name with `SQL AS`. We then `JOIN` the golf courses based on the distance using
    `ST_DWithin()` so that we can locate distances that are less than 4 km between
    a city and golf course.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `WHERE` clause, `ST_DWithin()`, enforces the last requirement that the distance
    between a park and golf course cannot be more than 5 km.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The SQL does all of our heavy lifting to return the correct spatial analysis
    results. The next step is to use Python to output our results as valid GeoJSON
    in order to view our newly found golf courses. Each attribute property is then
    identified by its array location in the query and assigned a name for the GeoJSON
    output. In the end, we'll output a .geojson file that you can visualize directly
    in GitHub at [https://github.com/mdiener21/python-geospatial-analysis-cookbook/blob/master/ch04/geodata/golfcourses_analysis.geojson](https://github.com/mdiener21/python-geospatial-analysis-cookbook/blob/master/ch04/geodata/golfcourses_analysis.geojson).
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works...](img/50790OS_04_06.jpg)'
  prefs: []
  type: TYPE_IMG
