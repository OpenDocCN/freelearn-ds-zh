<html><head></head><body>
  <div><div><div><div><div><h1 class="title"><a id="pref08"/>Preface</h1></div></div></div><p>It is estimated that in 2013 the whole world produced around 4.4 zettabytes of data; that is, 4.4 <em>billion </em>terabytes! By 2020, we (as the human race) are expected to produce ten times that. With data getting larger literally by the second, and given the growing appetite for making sense out of it, in 2004 Google employees Jeffrey Dean and Sanjay Ghemawat published the seminal paper <em>MapReduce: Simplified Data Processing on Large Clusters</em>. Since then, technologies leveraging the concept started growing very quickly with Apache Hadoop initially being the most popular. It ultimately created a Hadoop ecosystem that included abstraction layers such as Pig, Hive, and Mahout – all leveraging this simple concept of map and reduce.</p><p>However, even though capable of chewing through petabytes of data daily, MapReduce is a fairly restricted programming framework. Also, most of the tasks require reading and writing to disk. Seeing these drawbacks, in 2009 Matei Zaharia started working on Spark as part of his PhD. Spark was first released in 2012. Even though Spark is based on the same MapReduce concept, its advanced ways of dealing with data and organizing tasks make it 100x faster than Hadoop (for in-memory computations).</p><p>In this book, we will guide you through the latest incarnation of Apache Spark using Python. We will show you how to read structured and unstructured data, how to use some fundamental data types available in PySpark, build machine learning models, operate on graphs, read streaming data, and deploy your models in the cloud. Each chapter will tackle different problem, and by the end of the book we hope you will be knowledgeable enough to solve other problems we did not have space to cover here.</p><div><div><div><div><h1 class="title"><a id="ch00lvl1sec01"/>What this book covers</h1></div></div></div><p>
<a class="link" href="ch01.html" title="Chapter 1. Understanding Spark">Chapter 1</a>, <em>Understanding Spark</em>, provides an introduction into the Spark world with an overview of the technology and the jobs organization concepts.</p><p>
<a class="link" href="ch02.html" title="Chapter 2. Resilient Distributed Datasets">Chapter 2</a>, <em>Resilient Distributed Datasets</em>, covers RDDs, the fundamental, schema-less data structure available in PySpark.</p><p>
<a class="link" href="ch03.html" title="Chapter 3. DataFrames">Chapter 3</a>, <em>DataFrames</em>, provides a detailed overview of a data structure that bridges the gap between Scala and Python in terms of efficiency.</p><p>
<a class="link" href="ch04.html" title="Chapter 4. Prepare Data for Modeling">Chapter 4</a>, <em>Prepare Data for Modeling</em>, guides the reader through the process of cleaning up and transforming data in the Spark environment.</p><p>
<a class="link" href="ch05.html" title="Chapter 5. Introducing MLlib">Chapter 5</a>, <em>Introducing MLlib</em>, introduces the machine learning library that works on RDDs and reviews the most useful machine learning models.</p><p>
<a class="link" href="ch06.html" title="Chapter 6. Introducing the ML Package">Chapter 6</a>, <em>Introducing the ML Package</em>, covers the current mainstream machine learning library and provides an overview of all the models currently available.</p><p>
<a class="link" href="ch07.html" title="Chapter 7. GraphFrames">Chapter 7</a>, <em>GraphFrames</em>, will guide you through the new structure that makes solving problems with graphs easy.</p><p>
<a class="link" href="ch08.html" title="Chapter 8. TensorFrames">Chapter 8</a>, <em>TensorFrames</em>, introduces the bridge between Spark and the Deep Learning world of TensorFlow.</p><p>
<a class="link" href="ch09.html" title="Chapter 9. Polyglot Persistence with Blaze">Chapter 9</a>, <em>Polyglot Persistence with Blaze</em>, describes how Blaze can be paired with Spark for even easier abstraction of data from various sources.</p><p>
<a class="link" href="ch10.html" title="Chapter 10. Structured Streaming">Chapter 10</a>, <em>Structured Streaming</em>, provides an overview of streaming tools available in PySpark.</p><p>
<a class="link" href="ch11.html" title="Chapter 11. Packaging Spark Applications">Chapter 11</a>, <em>Packaging Spark Applications</em>, will guide you through the steps of modularizing your code and submitting it for execution to Spark through command-line interface.</p><p>For more information, we have provided two bonus chapters as follows:</p><p>
<em>Installing Spark</em>: <a class="ulink" href="https://www.packtpub.com/sites/default/files/downloads/InstallingSpark.pdf">https://www.packtpub.com/sites/default/files/downloads/InstallingSpark.pdf</a>
</p><p>
<em>Free Spark Cloud Offering</em>: <a class="ulink" href="https://www.packtpub.com/sites/default/files/downloads/FreeSparkCloudOffering.pdf">https://www.packtpub.com/sites/default/files/downloads/FreeSparkCloudOffering.pdf</a>
</p></div></div></div>


  <div><div><div><div><div><h1 class="title"><a id="ch00lvl1sec02"/>What you need for this book</h1></div></div></div><p>For this book you need a personal computer (can be either Windows machine, Mac, or Linux). To run Apache Spark, you will need Java 7+ and an installed and configured Python 2.6+ or 3.4+ environment; we use the Anaconda distribution of Python in version 3.5, which can be downloaded from <a class="ulink" href="https://www.continuum.io/downloads">https://www.continuum.io/downloads</a>.</p><p>The Python modules we randomly use throughout the book come preinstalled with Anaconda. We also use GraphFrames and TensorFrames that can be loaded dynamically while starting a Spark instance: to load these you just need an Internet connection. It is fine if some of those modules are not currently installed on your machine – we will guide you through the installation process.</p></div></div>


  <div><div><div><div><div><h1 class="title"><a id="ch00lvl1sec03"/>Who this book is for</h1></div></div></div><p>This book is for everyone who wants to learn the fastest-growing technology in big data: Apache Spark. We hope that even the more advanced practitioners from the field of data science can find some of the examples refreshing and the more advanced topics interesting.</p></div></div>


  <div><div><div><div><div><h1 class="title"><a id="ch00lvl1sec04"/>Conventions</h1></div></div></div><p>In this book, you will find a number of styles of text that distinguish between different kinds of information. Here are some examples of these styles, and an explanation of their meaning.</p><p>Code words in text, database table names, folder names, filenames, file extensions, pathnames, dummy URLs, user input, and Twitter handles are shown as follows:</p><p>A block of code is set as follows:</p><div><pre class="programlisting">data = sc.parallelize(
    [('Amber', 22), ('Alfred', 23), ('Skye',4), ('Albert', 12), 
     ('Amber', 9)])</pre></div><p>When we wish to draw your attention to a particular part of a code block, the relevant lines or items are set in bold:</p><div><pre class="programlisting">rdd1 = sc.parallelize([('a', 1), ('b', 4), ('c',10)])
rdd2 = sc.parallelize([('a', 4), ('a', 1), ('b', '6'), ('d', 15)])
rdd3 = rdd1.leftOuterJoin(rdd2)</pre></div><p>Any command-line input or output is written as follows:</p><div><pre class="programlisting">
<strong>java -version</strong>
</pre></div><p>
<strong>New terms</strong> and <strong>important words</strong> are shown in bold. Words that you see on the screen, in menus or dialog boxes for example, appear in the text like this: "Clicking the <strong>Next</strong> button moves you to the next screen."</p><div><div><h3 class="title"><a id="note01"/>Note</h3><p>Warnings or important notes appear in a box like this.</p></div></div><div><div><h3 class="title"><a id="tip01"/>Tip</h3><p>Tips and tricks appear like this.</p></div></div></div></div>


  <div><div><div><div><div><h1 class="title"><a id="ch00lvl1sec05"/>Reader feedback</h1></div></div></div><p>Feedback from our readers is always welcome. Let us know what you think about this book—what you liked or may have disliked. Reader feedback is important for us to develop titles that you really get the most out of.</p><p>To send us general feedback, simply send an e-mail to <code class="email">&lt;<a class="email" href="mailto:feedback@packtpub.com">feedback@packtpub.com</a>&gt;</code>, and mention the book title via the subject of your message.</p><p>If there is a topic that you have expertise in and you are interested in either writing or contributing to a book, see our author guide on <a class="ulink" href="http://www.packtpub.com/authors">www.packtpub.com/authors</a>.</p></div></div>


  <div><div><div><div><div><h1 class="title"><a id="ch00lvl1sec06"/>Customer support</h1></div></div></div><p>Now that you are the proud owner of a Packt book, we have a number of things to help you to get the most from your purchase.</p><div><div><div><div><h2 class="title"><a id="ch00lvl2sec01"/>Downloading the example code</h2></div></div></div><p>You can download the example code files for all Packt books you have purchased from your account at <a class="ulink" href="http://www.packtpub.com">http://www.packtpub.com</a>. If you purchased this book elsewhere, you can visit <a class="ulink" href="http://www.packtpub.com/support">http://www.packtpub.com/support</a> and register to have the files e-mailed directly to you.</p><p>All the code is also available on GitHub: <a class="ulink" href="https://github.com/drabastomek/learningPySpark">https://github.com/drabastomek/learningPySpark</a>.</p><p>You can download the code files by following these steps:</p><div><ol class="orderedlist arabic"><li class="listitem">Log in or register to our website using your e-mail address and password.</li><li class="listitem">Hover the mouse pointer on the <strong>SUPPORT</strong> tab at the top.</li><li class="listitem">Click on <strong>Code Downloads &amp; Errata</strong>.</li><li class="listitem">Enter the name of the book in the <strong>Search </strong>box.</li><li class="listitem">Select the book for which you're looking to download the code files.</li><li class="listitem">Choose from the drop-down menu where you purchased this book from.</li><li class="listitem">Click on <strong>Code Download</strong>.</li></ol></div><p>Once the file is downloaded, please make sure that you unzip or extract the folder using the latest version of:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">WinRAR / 7-Zip for Windows</li><li class="listitem" style="list-style-type: disc">Zipeg / iZip / UnRarX for Mac</li><li class="listitem" style="list-style-type: disc">7-Zip / PeaZip for Linux</li></ul></div><p>The code bundle for the book is also hosted on GitHub at <a class="ulink" href="https://github.com/PacktPublishing/Learning-PySpark">https://github.com/PacktPublishing/Learning-PySpark</a>. We also have other code bundles from our rich catalog of books and videos available at <a class="ulink" href="https://github.com/PacktPublishing/">https://github.com/PacktPublishing/</a>. Check them out!</p></div><div><div><div><div><h2 class="title"><a id="ch00lvl2sec02"/>Downloading the color images of this book</h2></div></div></div><p>We also provide you with a PDF file that has color images of the screenshots/diagrams used in this book. The color images will help you better understand the changes in the output. You can download this file from <a class="ulink" href="https://www.packtpub.com/sites/default/files/downloads/LearningPySpark_ColorImages.pdf">https://www.packtpub.com/sites/default/files/downloads/LearningPySpark_ColorImages.pdf</a>.</p></div><div><div><div><div><h2 class="title"><a id="ch00lvl2sec03"/>Errata</h2></div></div></div><p>Although we have taken every care to ensure the accuracy of our content, mistakes do happen. If you find a mistake in one of our books—maybe a mistake in the text or the code—we would be grateful if you would report this to us. By doing so, you can save other readers from frustration and help us improve subsequent versions of this book. If you find any errata, please report them by visiting <a class="ulink" href="http://www.packtpub.com/submit-errata">http://www.packtpub.com/submit-errata</a>, selecting your book, clicking on the <strong>errata</strong> <strong>submission</strong> <strong>form</strong> link, and entering the details of your errata. Once your errata are verified, your submission will be accepted and the errata will be uploaded on our website, or added to any list of existing errata, under the Errata section of that title. Any existing errata can be viewed by selecting your title from <a class="ulink" href="http://www.packtpub.com/support">http://www.packtpub.com/support</a>.</p></div><div><div><div><div><h2 class="title"><a id="ch00lvl2sec04"/>Piracy</h2></div></div></div><p>Piracy of copyright material on the Internet is an ongoing problem across all media. At Packt, we take the protection of our copyright and licenses very seriously. If you come across any illegal copies of our works, in any form, on the Internet, please provide us with the location address or website name immediately so that we can pursue a remedy.</p><p>Please contact us at <code class="email">&lt;<a class="email" href="mailto:copyright@packtpub.com">copyright@packtpub.com</a>&gt;</code> with a link to the suspected pirated material.</p><p>We appreciate your help in protecting our authors, and our ability to bring you valuable content.</p></div><div><div><div><div><h2 class="title"><a id="ch00lvl2sec05"/>Questions</h2></div></div></div><p>You can contact us at <code class="email">&lt;<a class="email" href="mailto:questions@packtpub.com">questions@packtpub.com</a>&gt;</code> if you are having a problem with any aspect of the book, and we will do our best to address it.</p></div></div></div>
</body></html>