<html><head></head><body><div><div><div><div><h1 class="title"><a id="ch03"/>Chapter 3. Topic Modeling – Changing Concerns in the State of the Union Addresses</h1></div></div></div><p>A huge source of data right now is the volumes of unstructured, natural-language data that's everywhere on the Internet. Think of all the news articles, blog posts, Twitter posts, and YouTube comments as well as the thousands of other ways that people can create and share textual content online. What they're saying may be important to you, and being able to track what subjects they are talking about is incredibly useful to become aware of the trends and conversations.</p><p>A tool to explore the information a group of text documents discusses is called<a id="id199" class="indexterm"/> <strong>topic modeling</strong>. This is a technique to <a id="id200" class="indexterm"/>identify the "topics" discussed in a collection of documents, although as we'll see, "topics" is defined a little differently here than it is in informal conversation. The strength of these models is that they don't assume that each document talks only about one thing. Instead, they model documents as collections of topics. This is incredibly powerful in that it allows more complex conceptions of what a document is as well as more complex patterns between documents.</p><p>In this chapter, we will cover the following topics:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Understanding data in State of the Union addresses</li><li class="listitem" style="list-style-type: disc">Understanding topic modeling</li><li class="listitem" style="list-style-type: disc">Preparing for visualizations</li><li class="listitem" style="list-style-type: disc">Setting up the project</li><li class="listitem" style="list-style-type: disc">Getting the data</li><li class="listitem" style="list-style-type: disc">Visualizing data with D3 and ClojureScript</li><li class="listitem" style="list-style-type: disc">Exploring the topics</li></ul></div><div><div><div><div><h1 class="title"><a id="ch03lvl1sec20"/>Understanding data in the State of Union addresses</h1></div></div></div><p>In this chapter, we'll apply topic modeling to the<a id="id201" class="indexterm"/> (<strong>SOTU</strong>) <strong>State of the Union</strong> addresses presented by the presidents of the<a id="id202" class="indexterm"/> United States of America. Each January or <a id="id203" class="indexterm"/>February, the President addresses the US Senate and the House of Representatives either in person or in writing, and talks about how the country is doing as well as outlining his agenda for the coming year. The speeches can be fairly short, but the written reports can be much longer. George Washington's first State of the Union address from 1790 had less than 500 words. Barack Obama's latest SOTU (at the time of this writing in 2013) had over 3,000 words. Jimmy Carter had the longest<a id="id204" class="indexterm"/> SOTU address, which he delivered in writing in 1981. It is almost 14,000 words long.</p><p>The gradual increase in the length of the SOTU address, which climaxed around 1910, was because starting from Thomas Jefferson's 1801 address up until William H. Taft's 1912 address, the SOTU address was a written report delivered before Congress. The following <a id="id205" class="indexterm"/>graph represents the increase in the word counts of SOTU addresses:</p><div><img src="img/4139OS_03_01.jpg" alt="Understanding data in the State of Union addresses"/></div><p>Of course, as the situation has changed both domestically and internationally, so have the topics that the President discusses in the SOTU addresses. You wouldn't expect John Adams' 1800 address to talk about the same things as Bill Clinton's 2000 address. This immediately raises the question: what topics have the Presidents talked about in their SOTU addresses and how have those topics changed over time?</p><p>This isn't a new <a id="id206" class="indexterm"/>question, even for topic modeling. Xuerui Wang<a id="id207" class="indexterm"/> and Andrew McCallum covered it as one of several examples in their 2006 paper, <em>Topics over time: A non-Markov continuous-time model of topical trends (2006)</em> (<a class="ulink" href="http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.152.2460">http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.152.2460</a>). In this paper, they present a way of analyzing a series of time-stamped documents in order to get an improved understanding of how the topics interact over time. In fact, this is an area of considerable further research, and there are a number of other extensions to topic modeling that take time into account.</p><p>In this <a id="id208" class="indexterm"/>chapter, we're only going to cover the most widely used topic modeling algorithm today: <strong>LDA</strong> (<strong>Latent Dirichlet Allocation</strong>). With an understanding of this procedure and the underlying thought behind it, you can understand Wang's and McCallum's Topics over Time algorithm without too much difficulty.</p></div></div>
<div><div><div><div><h1 class="title"><a id="ch03lvl1sec21"/>Understanding topic modeling</h1></div></div></div><p>A topic model<a id="id209" class="indexterm"/> is a statistical model of the topics in a document. The assumption is that if 10 percent of a document talks about the military and 40 percent of it talks about the economy (and 50 percent talks about other things), then there should be roughly four <a id="id210" class="indexterm"/>times as many words about economics as about the military.</p><p>An early form of topic modeling<a id="id211" class="indexterm"/> was described by Christos Papadimitriou and others in their 1998 paper, <em>Latent Semantic Indexing: A probabilistic analysis</em> (<a class="ulink" href="http://www.cs.berkeley.edu/~christos/ir.ps">http://www.cs.berkeley.edu/~christos/ir.ps</a>). This was refined by Thomas Hofmann in 1999 with <em>Probabilistic Latent Semantic Indexing</em> (<a class="ulink" href="http://www.cs.brown.edu/~th/papers/Hofmann-SIGIR99.pdf">http://www.cs.brown.edu/~th/papers/Hofmann-SIGIR99.pdf</a>).</p><p>In 2003, David Blei, Andrew Ng, and Michael I. Jordan published their paper, <em>Latent Dirichlet Allocation</em> (<a class="ulink" href="http://jmlr.csail.mit.edu/papers/v3/blei03a.html">http://jmlr.csail.mit.edu/papers/v3/blei03a.html</a>). Currently, this is the most common type of topic modeling. It's simple, easy to get started, and widely available. Most work in the field since then has been developing extensions to the original LDA topic modeling method. This is the procedure that we'll learn about and use in this chapter.</p><p>In <a id="id212" class="indexterm"/>LDA, each document is modeled as a bag of words, each word drawn from a number of topics. So each word in the document is the result of one of those topics. The model takes the following steps to create each document:</p><div><ol class="orderedlist arabic"><li class="listitem">Select a distribution for the topic in the document.</li><li class="listitem">Select a distribution for the words from the topic.</li><li class="listitem">Select a topic and then a word from that topic from those distributions for each word in the document.</li></ol></div><p>The distributions for the<a id="id213" class="indexterm"/> topics and words use a Dirichlet distribution for their prior probability, which is the assumed uncertainty about the distribution of topics and words before considering any evidence or documents. However, as they are trained on a set of input documents, these distributions more accurately reflect the data they've seen so far, and so they are able to more accurately categorize future documents.</p><p>A short example may be helpful. Initially the distributions are picked randomly. Afterwards, we'll train on one document. Say we have a document with the following words: budget, spending, army, navy, plane, soldier, and dollars. The model knows from previous training that the words <em>budget, spending</em>, and <em>dollars</em> all relate to a topic on finance, while army, navy, plane, and soldier relate to a topic on the military, and plane relates to one on travel. This may suggest that the document is 35 percent about finance, 50 percent about the military, and 10 percent about travel. Military would be the dominant topic, but other topics would be represented as well.</p><p>If the LDA is in its training phase, then the presence of those words would slightly strengthen the association between all of the words listed, between those words and the other words in the document, and between those words and the topics that represent the relationship between them.</p><p>One twist to this is that the topics aren't named. In the previous example, I said that there were topics about finance, the military, and travel. However, LDA would see those as topics 1, 2, and 3. The labels are interpretations I would give based on the terms in those topics and the documents that scored high in them. One of the tasks when using LDA is investigating and interpreting the topics. We'll see several examples of this at the end of the chapter when we explore the results of our analysis.</p></div>
<div><div><div><div><h1 class="title"><a id="ch03lvl1sec22"/>Preparing for visualizations</h1></div></div></div><p>One of the basic tools of<a id="id214" class="indexterm"/> data analysis is visualization. Good, flexible visualizations make it easier to explore and understand the data, and this is useful at all stages of the data analysis process. At the beginning, visualizations make it easier to find errors and inconsistencies and to get to know your data and developing an intuition for it. It continues to drive insights throughout the process. In the end, visualizations make great supporting evidence and explanations in reports and presentations.</p><p>Visualizations will be an important part of this chapter and in understanding the results of topic modeling. To create and interact with the graphs, we're going to use some software that's recently become an important part of many data scientists' toolkits: the Web browser.</p><p>As we did in <a class="link" href="ch01.html" title="Chapter 1. Network Analysis – The Six Degrees of Kevin Bacon">Chapter 1</a>, <em>Network Analysis – The Six Degrees of Kevin Bacon</em>, we'll use D3 (<a class="ulink" href="http://d3js.org/">http://d3js.org/</a>) and ClojureScript (<a class="ulink" href="https://github.com/clojure/clojurescript/">https://github.com/clojure/clojurescript/</a>).</p><p>The graph of the word counts earlier in this chapter as well as the ones that will come later are examples of this system. They're part of a static website. That is, the resources that load in the <a id="id215" class="indexterm"/>browser are read from the filesystem, not generated dynamically by a server-side web application. The data is read from <strong>CSV</strong> (<strong>comma-separated values</strong>) files<a id="id216" class="indexterm"/> that we'll create from the topic model data. Finally, the ClojureScript is compiled into a JavaScript file that's loaded by the browser.</p><p>We'll see later how to set up this site with ClojureScript as well as how to create the graphs. As usual, for the full code, refer to the source code download from the Packt Publishing website.</p></div>
<div><div><div><div><h1 class="title"><a id="ch03lvl1sec23"/>Setting up the project</h1></div></div></div><p>Before we dive in further, however, we'll <a id="id217" class="indexterm"/>need to set up our project for this chapter. So<a id="id218" class="indexterm"/> with all of that in mind, let's tackle the solution. The first thing we'll need is the following Leiningen 2 <code class="literal">project.clj</code> file:</p><div><pre class="programlisting">(defproject tm-sotu "0.1.0-SNAPSHOT"
  :license {:name "Eclipse Public License"
            :url "http://www.eclipse.org/legal/epl-v10.html"}
  :plugins [[lein-cljsbuild "0.3.2"]]
  :dependencies [[org.clojure/clojure "1.5.1"]
                 [enlive "1.1.1"]
                 [org.clojure/data.csv "0.1.2"]
                 [cc.mallet/mallet "2.0.7"]]
  :cljsbuild {:builds [{:source-paths ["src-cljs"],
                        :compiler {:pretty-printer true,
                                   :output-to "www/js/main.js",
                                   :optimizations :whitespace}}]})</pre></div><p>We use a couple of dependencies for this: Enlive to download the text of the SOTU addresses and MALLET for topic modeling. We'll talk more about both of these in the forthcoming sections.</p></div>
<div><div><div><div><h1 class="title"><a id="ch03lvl1sec24"/>Getting the data</h1></div></div></div><p>To get a copy of the SOTU addresses, we'll visit the website for the American Presidency Project at the University of California, Santa Barbara (<a class="ulink" href="http://www.presidency.ucsb.edu/">http://www.presidency.ucsb.edu/</a>). This site has the text for the SOTU addresses as well as an archive of many messages, letters, public papers, and other documents for various presidents. It's a great resource for looking at political rhetoric.</p><p>In this case, we'll write some code to visit the index page for the SOTU addresses. From there, we'll visit each of the pages that contain an address; remove the menus, headers, and footers; and strip out the HTML. We'll save this in a file in the <code class="literal">data</code> directory.</p><p>We won't see all of the code for this. To see the rest, look at the <code class="literal">download.clj</code> file in the <code class="literal">src/tm_sotu/</code> directory in the downloaded code.</p><p>To handle downloading and parsing the files, we'll use the <a id="id219" class="indexterm"/>Enlive library (<a class="ulink" href="https://github.com/cgrand/enlive/wiki">https://github.com/cgrand/enlive/wiki</a>). This library provides a DSL to navigate and pull data from HTML pages. The syntax and concepts are similar to CSS selectors, so if you're familiar with those, using Enlive will seem very natural.</p><p>We'll tackle this problem piece by piece. First, we need to set up the namespace and imports for this module with the following code:</p><div><pre class="programlisting">(ns tm-sotu.download
  (:require [net.cgrand.enlive-html :as enlive]
            [clojure.java.io :as io])
  (:import [java.net URL]
           [java.io File]))</pre></div><p>Now, we can define a function that downloads the index page for the SOTU addresses as shown in the following code (<a class="ulink" href="http://www.presidency.ucsb.edu/sou.php">http://www.presidency.ucsb.edu/sou.php</a>). It will take this URL as a parameter, download the resource, pull out the list of links, and remove any text that isn't a year:</p><div><pre class="programlisting">(defn get-index-links [index-url]
  (-&gt;
    index-url	
    enlive/html-resource
    (enlive/select [:.doclist :a])
    filter-year-content?))</pre></div><p>Let's walk through these lines step by step:</p><div><ol class="orderedlist arabic"><li class="listitem">First, <code class="literal">index-url</code> is just the URL of the index page that needs to be downloaded. This line just kicks off the processing pipeline.</li><li class="listitem">The <code class="literal">enlive/html-resource</code> function<a id="id220" class="indexterm"/> downloads and parses the web page. Most processing that uses Enlive will start with this function.</li><li class="listitem">Now, <code class="literal">(enlive/select [:.doclist :a])</code> only pulls out certain anchor tags. The vector that specifies the tags to return is similar to a CSS selector. In this case, it would be equivalent to the <code class="literal">.doclist :a</code> selector. I found which classes and tags to look for by examining the source code for the HTML file and experimenting with it for a few minutes.</li><li class="listitem">Finally, I called <code class="literal">filter-year-content?</code> on the sequence of tags. This looks at the text within the anchor tag and throws out any text that is not a four-digit year.</li></ol></div><p>The<a id="id221" class="indexterm"/> <code class="literal">get-index-links</code> function<a id="id222" class="indexterm"/> returns a sequence of anchor tags that need to be downloaded. Between the tag's <code class="literal">href</code> attribute and its content, we have the URL for the address and the year it was delivered, and we'll use both of them.</p><p>The next step of the process is the<a id="id223" class="indexterm"/> <code class="literal">process-speech-page</code> function. It takes an output directory and a tag, and it downloads the page the tag points to, gets the text of the address, strips out the HTML tags from it, and saves the plain text to a file, as shown in the following code:</p><div><pre class="programlisting">(defn process-speech-page [outputdir a-tag]
  (-&gt;&gt; a-tag
    :attrs
    :href
    URL.
    enlive/html-resource
    get-text-tags
    extract-text
    (save-text-seq
      (unique-filename
        (str outputdir \/ (first (:content a-tag)))))))</pre></div><p>This strings together a number of functions. We'll walk through these a little more quickly, and then dive into one of the functions this calls in more detail.</p><p>First, the sequence of keywords <code class="literal">:attrs</code> and <code class="literal">:href</code> gets the URL from the anchor tag. We pass this to <code class="literal">enlive/html-resource</code> to download and parse the web page. Finally, we identify the text (<code class="literal">get-text-tags</code>), strip out the HTML (<code class="literal">extract-text</code>), and save it (<code class="literal">save-text-seq</code>). Most of these operations are fairly straightforward, but let's dig into <code class="literal">extract-text</code>.</p><p>This procedure is actually the sole method from a protocol of types that we can pull text from, stripping out HTML tags in the process. The following code gives the definition of this protocol. It's also defined over all the data structures that Enlive uses to return data: Strings for text blocks, hash maps for tags, lazy sequences for lists of content, and <code class="literal">nil</code> to handle all the possible input values, as shown in the following code:</p><div><pre class="programlisting">(defprotocol Textful
  (extract-text [x]
    "This pulls the text from an element.
    Returns a seq of String."))

(extend-protocol Textful
  java.lang.String
  (extract-text [x] (list x))

<strong>  clojure.lang.PersistentStructMap</strong>
<strong>  (extract-text [x]</strong>
<strong>      (concat</strong>
<strong>        (extract-text (:content x))</strong>
<strong>        (when (contains? #{:span :p} (:tag x))</strong>
<strong>          ["\n\n"])))</strong>

  clojure.lang.LazySeq
  (extract-text [x] (mapcat extract-text x))

  nil
  (extract-text [x] nil))</pre></div><p>The preceding code allows<a id="id224" class="indexterm"/> us to find the parent elements for each address, pass those elements to this protocol, and get the HTML tags stripped out. Of all of these methods, the most interesting implementation is hash map's, which is highlighted in the preceding code.</p><p>First, it recursively calls the <code class="literal">extract-text</code> method<a id="id225" class="indexterm"/> to process the tag's content. Then, if the tag is <code class="literal">p</code> or <code class="literal">span</code>, the method adds a couple of new lines to format the tag as a paragraph. Having a <code class="literal">span</code> tag trigger a new paragraph is a bit odd, but the introduction to the address is in a <code class="literal">span</code> tag. Like any screen-scraping task, this is very specialized to the SOTU. Getting data from other sites will require a different set of rules and functions to get the data back out.</p><p>I've tied this process together in a function that first downloads the index page and then processes the address links one by one as shown in the following code:</p><div><pre class="programlisting">(defn download-corpus [datadir index-url]
  (doseq [link (get-index-links (URL. index-url))]
    (println (first (:content link)))
    (process-speech-page datadir link)))</pre></div><p>After this function executes, there will be a <code class="literal">data/</code> directory that contains one text file for each SOTU address. Now we just need to see how to run LDA topic modeling on them.</p><div><div><div><div><h2 class="title"><a id="ch03lvl2sec26"/>Loading the data into MALLET</h2></div></div></div><p>To actually <a id="id226" class="indexterm"/>perform<a id="id227" class="indexterm"/> topic modeling, we'll use the MALLET Java library (<a class="ulink" href="http://mallet.cs.umass.edu/">http://mallet.cs.umass.edu/</a>). <strong>MALLET</strong> (<strong>MAchine Learning for LanguagE Toolkit</strong>) contains a number of algorithms for various statistical and machine learning algorithms for natural-language processing, including document classification, sequence tagging, and numerical optimization. However, it's commonly also used for topic modeling, and its support for that is very robust and flexible. We'll interact with it using Clojure's Java <code class="literal">interop</code> functions.</p><p>Each document is stored in a MALLET <code class="literal">cc.mallet.types.Instance</code> class. So to begin with, we'll need to create a processing pipeline that reads the files from disk and processes them and loads them into MALLET.</p><p>The next group of code will go into the <code class="literal">src/tm_sotu/topic_model.clj</code> file. The following code is the namespace declaration with the list of dependencies for this module. Be patient; the following list isn't short:</p><div><pre class="programlisting">(ns tm-sotu.topic-model
  (:require [clojure.java.io :as io]
            [clojure.data.csv :as csv]
            [clojure.string :as str])
  (:import [cc.mallet.util.*]
           [cc.mallet.types InstanceList]
           [cc.mallet.pipe
            Input2CharSequence TokenSequenceLowercase
            CharSequence2TokenSequence SerialPipes
            TokenSequenceRemoveStopwords
            TokenSequence2FeatureSequence]
           [cc.mallet.pipe.iterator FileListIterator]
           [cc.mallet.topics ParallelTopicModel]
           [java.io FileFilter]
           [java.util Formatter Locale]))</pre></div><p>Now we can write a function that creates the processing pipeline and the list of instances based on it, as shown in the following code:</p><div><pre class="programlisting">(defn make-pipe-list []
  (InstanceList.
    (SerialPipes.
      [(Input2CharSequence. "UTF-8")
       (CharSequence2TokenSequence.
         #"\p{L}[\p{L}\p{P}]+\p{L}")
       (TokenSequenceLowercase.)
       (TokenSequenceRemoveStopwords. false false)
       (TokenSequence2FeatureSequence.)])))</pre></div><p>This function creates a pipeline of classes that process the input. Each stage in the process makes a small, select modification to its input, and then it passes the data down the pipeline.</p><p>The first step takes the input file's name and reads it as a sequence of characters. It tokenizes the character sequence using the regular expression given, which matches the sequence of letters with embedded punctuation.</p><p>Next, it normalizes the case of the tokens and removes stop words. Stop words are very common words. Most of these function grammatically in the sentence, but do not really add to the semantics (that is, to the content) of the sentence. Examples of stop words in English are <em>the</em>, <em>of</em>, <em>and</em>, and <em>are</em>.</p><p>Finally, it<a id="id228" class="indexterm"/> converts the token sequence to a sequence of features. A feature is a <a id="id229" class="indexterm"/>word, a token, or some metadata from a document that you want to include in the training. For example, the presence or absence of the word <em>president</em> might be a feature in this corpus. Features are often assembled into vectors; one vector for each document. The position of each feature in the vectors must be consistent. For example, the feature <em>president</em> must always be found at the seventh position in all documents' feature vectors. </p><p>Feature sequences are sequences of numbers along with mappings from words to indices, so the rest of the algorithm will deal with numbers instead of words.</p><p>For instance, the first SOTU address by George Washington (1790) begins with, "I embrace with great satisfaction the opportunity which now presents itself." The following are some of the steps that the processing pipeline would take for this input:</p><div><ol class="orderedlist arabic"><li class="listitem"><code class="literal">CharSequence2TokenSequence</code>: After tokenization, it <a id="id230" class="indexterm"/>would be a sequence of individual strings such as <em>I</em>, <em>embrace</em>, <em>with</em>, <em>great</em>, and <em>satisfaction</em>.</li><li class="listitem"><code class="literal">TokenSequenceLowercase</code>: Normalizing the<a id="id231" class="indexterm"/> case would convert the first word to <em>i</em>.</li><li class="listitem"><code class="literal">TokenSequenceRemoveStopwords</code>: Removing <a id="id232" class="indexterm"/>stop words would leave just content words: <em>embrace</em>, <em>great</em>, <em>satisfaction</em>, <em>opportunity</em>, <em>now</em>, <em>presents</em>, and <em>itself</em>.</li><li class="listitem"><code class="literal">TokenSequence2FeatureSequence</code>: This<a id="id233" class="indexterm"/> changes input into a sequence of numbers. Internally, it also maintains a mapping between the indexes and the words, so 0 would be associated with <em>embrace</em>. The next time it finds a word that it has encountered before, it will reuse the feature index, so from here on, <em>now</em> will always be replaced by 4.</li></ol></div><p>We can also visually represent this process as shown in the following chart:</p><div><img src="img/4139OS_03_02.jpg" alt="Loading the data into MALLET"/></div><p>We still haven't <a id="id234" class="indexterm"/>specified which files to process or connected them to the processing<a id="id235" class="indexterm"/> pipeline. We do that using the instance list's <code class="literal">addThruPipe</code> method. To make this step easier, we'll define a function that takes a list of files and plugs them into the pipeline as shown in the following code:</p><div><pre class="programlisting">(defn add-directory-files
  "Adds the files from a directory to the instance list."
  [instance-list data-dir]
  (.addThruPipe
    instance-list
    (FileListIterator.
      (.listFiles (io/file data-dir))
      (reify FileFilter
        (accept [this pathname] true))
      #"/([^/]*).txt$"
      true)))</pre></div><p>The <code class="literal">FileListIterator</code> function wraps <a id="id236" class="indexterm"/>the array of files. It can also filter the array, which is more than we need. The regular expression, <code class="literal">#"/([^/]*).txt$"</code>, is used to separate the filename from the directory. This will be used to identify the instance for the rest of the processing.</p><p>That's it. Now we're ready to write a function to train the model. This process has a number of options, including how many threads to use, how many iterations to perform, how many topics to find, and a couple of hyper parameters to the algorithm itself: the <em>α</em> sum and <em>β</em>. The <em>α</em> parameter is the sum over the topics and <em>β</em> is the parameter for one dimension of the Dirichlet prior distributions that are behind topic modeling. In the following code, I've hardcoded them to <code class="literal">1.0</code> and <code class="literal">0.01</code>, and I've provided defaults for the number of topics (<code class="literal">100</code>), threads (<code class="literal">4</code>), and iterations (<code class="literal">50</code>):</p><div><pre class="programlisting">(defn train-model
  ([instances] (train-model 100 4 50 instances))
  ([num-topics num-threads num-iterations instances]
   (doto (ParallelTopicModel. num-topics 1.0 0.01)
     (.addInstances instances)
     (.setNumThreads num-threads)
     (.setNumIterations num-iterations)
     (.estimate))))</pre></div><p>Finding the right number of topics is a bit of an art. The value is an interaction between the size of your collection, the type of documents it contains, and how finely grained you wish the topics to be. The number could range from the tens to the hundreds.</p><p>One way to get a<a id="id237" class="indexterm"/> grasp on this is to see how many instances have a given topic <a id="id238" class="indexterm"/>with the top weighting. In other words, if there are a lot of topics with only one or two documents strongly associated with them, then maybe those topics are too specific, and we can run the training again with fewer documents. If none do, or only a few do, then maybe we need to use fewer topics.</p><p>However, ultimately, the number of topics depends on how fine-grained and precise you want the topic categories to be, and that will depend upon exactly what questions you're attempting to answer. If you need to find topics that are only important for a year or two, then you'll want more topics; however, if you're looking for broader, more general trends and movements, then fewer topics will be more helpful.</p><p>For example, the following graph shows the weightings for each topic in each SOTU address when ten topics are used:</p><div><img src="img/4139OS_03_03.jpg" alt="Loading the data into MALLET"/></div><p>We can see that <a id="id239" class="indexterm"/>the lines describe large arcs. Some lines begin strong and then<a id="id240" class="indexterm"/> taper off. Others have a hump in the middle and fall away to both sides. Others aren't mentioned much at the beginning but finish strong at the end of the graph.</p><p>One line that peaks around 1890 is a good example of one of these trends. Its top ten keywords are <em>year</em>, <em>government</em>, <em>states</em>, <em>congress</em>, <em>united</em>, <em>secretary</em>, <em>report</em>, <em>department</em>, <em>people</em>, and <em>fiscal</em>. Initially, it's difficult to say what this topic would be about. In fact, it is less about the addresses' subject matter per se, and more about the way that the Presidents went into the details of the topics, reporting amounts for taxation, mining, and agriculture. They tended to use a lot of phrases, such as "fiscal year". The following paragraph on sugar production from Grover Cleveland's 1894 address is typical:</p><div><blockquote class="blockquote"><p><em>The total bounty paid upon the production of sugar in the United States for the fiscal year was $12,100,208.89, being an increase of $2,725,078.01 over the payments made during the preceding year. The amount of bounty paid from July 1, 1894, to August 28, 1894, the time when further payments ceased by operation of law, was $966,185.84. The total expenses incurred in the payment of the bounty upon sugar during the fiscal year was $130,140.85.</em></p></blockquote></div><p>Exciting stuff.</p><p>This also illustrates how topics aren't always about the documents' subject matter, but also about rhetoric, ways of talking, and clusters of vocabulary that tend to be used together for a variety of reasons.</p><p>The topics represented in the following graph clearly describe large trends in the concerns that SOTU addresses dealt with. However, if we increase the number of topics to 200, the graph is very different, and not just because it has more lines on it:</p><div><img src="img/4139OS_03_04.jpg" alt="Loading the data into MALLET"/></div><p>Once you start<a id="id241" class="indexterm"/> looking at the topics in more detail, in general, the topics are only<a id="id242" class="indexterm"/> relevant for a smaller period of time, like for a twenty- or forty-year period, and most of the time, the documents' weightings for a given topic aren't as high. There are exceptions to this of course; however, most of the topics are more narrowly relevant and narrowly defined. For example, the third topic is largely focused on events related to the Civil War, especially those that occurred around 1862. The top ten keywords for that topic are <em>emancipation</em>, <em>insurgents</em>, <em>kentucky</em>, <em>laborers</em>, <em>adopted</em>, <em>north</em>, <em>hired</em>, <em>maryland</em>, <em>disloyal</em>, and <em>buy</em>. The following graph represents the topic of the Civil War:</p><div><img src="img/4139OS_03_05.jpg" alt="Loading the data into MALLET"/></div><p>The previous<a id="id243" class="indexterm"/> three graphs illustrate the role that the number of topics plays in our<a id="id244" class="indexterm"/> topic modeling. However, for the rest of this chapter, we're going to look at a run with 75 models. This graph provides a more balanced set of topics than either of the last two examples. In general, the subjects are neither too broad nor too narrow.</p></div><div><div><div><div><h2 class="title"><a id="ch03lvl2sec27"/>Visualizing with D3 and ClojureScript</h2></div></div></div><p>Before we look at <a id="id245" class="indexterm"/>D3 or <a id="id246" class="indexterm"/>ClojureScript, we <a id="id247" class="indexterm"/>should take some time to examine how the <a id="id248" class="indexterm"/>visualizations are put together since they're such an integral part of our work. The graphs will be on a static web page, meaning that there will be no need to for any server-side component to help create them. All changes on the graph will be created through JavaScript.</p><p>The first component of this will be a standard web page that has a couple of pieces (the entire site is in the code download in the <code class="literal">www/</code> directory). It needs a <code class="literal">div</code> tag for the JavaScript to hang the visualization on the static web page, as shown in the following code:</p><div><pre class="programlisting">&lt;div class="container"&gt;&lt;/div&gt;</pre></div><p>Then, it needs a few JavaScript libraries. We'll load <a id="id249" class="indexterm"/>jQuery (<a class="ulink" href="https://jquery.org/">https://jquery.org/</a>) from Google's <a id="id250" class="indexterm"/>
<strong>content distribution network</strong> (<strong>CDN</strong>). We'll load D3<a id="id251" class="indexterm"/> (<a class="ulink" href="http://d3js.org/">http://d3js.org/</a>) from its website, as they suggest and then we'll load our own script. Then, we'll call an entrance function in it as shown in the following code:</p><div><pre class="programlisting">&lt;script src="img/jquery.min.js"&gt;&lt;/script&gt;
&lt;script src="img/d3.v3.min.js"
        charset="utf-8"&gt;&lt;/script&gt;
&lt;script src="img/main.js"&gt;&lt;/script&gt;
&lt;script type="application/javascript"&gt;
    tm_sotu.topic_plot.plot_topics();
&lt;/script&gt;</pre></div><p>The <code class="literal">js/main.js</code> file will be the output of the compiled ClojureScript. We've already set up the configuration for this in the <code class="literal">project.clj</code> file, but let's look at that again in the following code:</p><div><pre class="programlisting">  :cljsbuild {:builds [{:source-paths ["src-cljs"],
                        :compiler {:pretty-printer true,
                                   :output-to "www/js/main.js",
                                   :optimizations :whitespace}}]})</pre></div><p>The preceding <a id="id252" class="indexterm"/>code specifies that ClojureScript will compile <a id="id253" class="indexterm"/>anything<a id="id254" class="indexterm"/> in the <code class="literal">src-cljs/</code> directory into the <code class="literal">www/js/main.js</code> file. We'll need to create the source directory and the <a id="id255" class="indexterm"/>directories for the namespace structure.</p><p>In ClojureScript, the files look almost exactly like regular Clojure scripts. There are slight wrinkles in importing and using macros from other libraries, but we won't need to do that today. There is also a <code class="literal">js</code> namespace always available. This is used to reference a name directly from JavaScript without requiring it to be declared.</p><p>Speaking of which, the following is the namespace declaration we'll use for the graph. You can find the <code class="literal">tm-sotu.utils</code> file along with the code that I haven't listed here in the source code for the chapter:</p><div><pre class="programlisting">(ns tm-sotu.topic-plot
  (:require [tm-sotu.utils :as utils]
            [clojure.browser.dom :as dom]
            [clojure.string :as str]))</pre></div><p>Another difference with regular JavaScript is that some functions must be exported using metadata on the function's name. This allows them to be called from regular JavaScript. The entrance function <code class="literal">plot-topics</code> is an example of this and is described in the following code:</p><div><pre class="programlisting">(defn ^:export plot-topics []
  (let [{:keys [x y]} (utils/get-scales)
        {:keys [x-axis y-axis]} (utils/axes x y)
        <strong>color (.. js/d3 -scale category20)</strong>
        line (utils/get-line #(x (get-year %))
                             #(y (get-distribution %)))
        svg (utils/get-svg)]
    (.csv js/d3 "topic-dists.csv"
          (partial load-topic-weights
                   svg line color x x-axis y y-axis))))</pre></div><p>Most of this function is concerned with calling some functions from the <code class="literal">tm-sotu.utils</code> namespace that set up boilerplate for the graphic. It's all standard D3, if you're familiar with that. The more interesting part—actually dealing with the data—we'll look at in more detail.</p><p>Before we move on, though, I'd like to pay a little more attention to the highlighted line in the previous code. This is an example of calling JavaScript directly and it illustrates a couple of things to be aware of, as follows:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">As we saw in <a class="link" href="ch01.html" title="Chapter 1. Network Analysis – The Six Degrees of Kevin Bacon">Chapter 1</a>, <em>Network Analysis – The Six Degrees of Kevin Bacon</em>, we can access JavaScript's global scope with the <code class="literal">js/</code> prefix, that is, <code class="literal">js/d3</code>.</li><li class="listitem" style="list-style-type: disc">Also, we distinguish JavaScript parameters by prefixing the name with a hyphen: <code class="literal">(.-scale js/d3)</code>.</li><li class="listitem" style="list-style-type: disc">Finally, we also see a call to a JavaScript function that takes no parameters. We've also used Clojure's standard <code class="literal">..</code> macro to make the series of calls easier to type and clearer to read: <code class="literal">(.. js/d3 -scale category20)</code>.</li></ul></div><p>The last line in<a id="id256" class="indexterm"/> the preceding code is a call to another <a id="id257" class="indexterm"/>D3 function—<code class="literal">d3.csv</code> or <code class="literal">(.csv js/d3 …)</code>—as it is expressed in ClojureScript. This <a id="id258" class="indexterm"/>function makes an AJAX call<a id="id259" class="indexterm"/> back to the server for the data file <code class="literal">"topic-dists.csv"</code>. The result, along with several other pieces of data from this function, is passed to <code class="literal">load-topic-weights</code>. You may have caught that I said "back to the server." This system doesn't need any code running on the server, but it does require a web server running in order to handle the AJAX calls that load the data. If you have Python installed on your system, it comes packaged with a zero-configuration web server that is simple to use. From the command line, just change into the directory that contains the website and execute the following command:</p><div><pre class="programlisting">
<strong>$ cd www</strong>
<strong>$ python -m SimpleHTTPServer</strong>
<strong>Serving HTTP on 0.0.0.0 port 8000 …</strong>
</pre></div><p>At this point, we've set the stage for the chart and loaded the data. Now we need to figure out what to do with it. The <code class="literal">load-topic-dists</code> function<a id="id260" class="indexterm"/> takes the pieces of the chart that we've created and the data, and populates the chart, as follows:</p><div><pre class="programlisting">(defn load-topic-weights [svg line color x x-axis y y-axis data]
  (let [data <strong>(into-array (map parse-datum data))</strong>]
    (.domain color (into-array (set (map get-topic data))))
    (let [topics (into-array
                   <strong>(map #(make-topic data %) (.domain color))</strong>)
          wghts <strong>(map get-weighting data)</strong>]
      (.domain x (.extent js/d3 data get-instance))
      (.domain y (array (apply min wghts) (apply max wghts)))
      (utils/setup-x-axis svg x-axis)
      (utils/setup-y-axis svg y-axis "Weightings")
      (let [topic-svg (make-topic-svg svg topics)]
        (add-topic-lines line color topic-svg)
        (add-topic-labels topic-svg x y)
        (utils/caption
          (str "Topic Weightings over Time (topic count = "
               (count topics) \))
          650)))))</pre></div><p>The lines in the preceding function fall into three broad categories:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Transforming and filtering the data</li><li class="listitem" style="list-style-type: disc">Setting the domains for the <em>x</em> axis, the <em>y</em> axis, and the color scheme</li><li class="listitem" style="list-style-type: disc">Adding the transformed data to the chart</li></ul></div><p>The <a id="id261" class="indexterm"/>transformation <a id="id262" class="indexterm"/>and filtering of data is handled <a id="id263" class="indexterm"/>in a number of different <a id="id264" class="indexterm"/>places. Let's see what they all are. I've highlighted them in the previous code; let's break them apart in more detail as follows:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The <code class="literal">(into-array (map parse-datum data))</code> form converts the data into its JavaScript-native types. The call to <code class="literal">d3.csv</code> returns an array of JavaScript objects, and all of the values are strings. This parses the instance string (for example, "1790-0" or "1984-1") into a decimal (1790.0 or 1984.5). This allows the years with more than one SOTU address to be sorted and displayed more naturally.</li><li class="listitem" style="list-style-type: disc">The <code class="literal">(map #(make-topic data %) (.domain color))</code> form creates a record with a topic number and the instances for that color.</li><li class="listitem" style="list-style-type: disc">Finally, the <code class="literal">(map get-weighting data)</code> form pulls all the weightings from the data. This is used to set the domain for the <em>y</em> axis.</li></ul></div><p>This data is used to set the domains for both axes and for the color scale. All of these tasks happen in the three calls to the <code class="literal">domain</code> method.</p><p>Finally, in the following code, we insert the data into the chart and create the SVG elements from it. This takes place in three other functions. The first, <code class="literal">make-topic-svg</code>, selects the elements with the <code class="literal">topic</code> class and inserts data into them. It then creates a <code class="literal">g</code> element for each datum:</p><div><pre class="programlisting">(defn make-topic-svg [svg topics]
  (.. svg
    (selectAll ".topic")
    (data topics)
    (enter)
    (append "g")
    (attr "class" "topic")))</pre></div><p>The next<a id="id265" class="indexterm"/> function <a id="id266" class="indexterm"/>appends path elements for each <a id="id267" class="indexterm"/>line and populates it with attributes<a id="id268" class="indexterm"/> for the points on the line and for the color, as shown in the following code:</p><div><pre class="programlisting">(defn add-topic-lines [line color topic-svg]
  (.. topic-svg
    (append "path")
    (attr "class" "line")
    (attr "id" #(str "line" (.-topic %)))
    (attr "d" #(line (.-values %)))
    (style "stroke" #(color (.-topic %)))))</pre></div><p>Finally, the last function in the following code adds a label for the line to the right-hand side of the graph. The label just displays the topic number for that line. Most of these topics get layered on top of each other and are illegible, but a few of the lines that are labelled at a higher level are distinguishable, and it's useful to be able to see them:</p><div><pre class="programlisting">(defn add-topic-labels [topic-svg x y]
  (.. topic-svg
    (append "text")
    (datum make-text)
    (attr "transform" #(str "translate(" (x (.-year (.-value %)))
                            \, (y (.-weighting (.-value %))) \)))
    (attr "x" 3)
    (attr "dy" ".35em")
    (text get-name)))</pre></div><p>Put together, these functions create the graphs we've seen so far. With a few added bells and whistles (refer to the source code), they'll also create the graphs that we'll see in the rest of this chapter.</p><p>Now, let's use these graphs to explore the topics that the LDA identified.</p></div><div><div><div><div><h2 class="title"><a id="ch03lvl2sec28"/>Exploring the topics</h2></div></div></div><p>The following is a complete set of <a id="id269" class="indexterm"/>topic weightings that we'll dig into in this chapter. This is from a run of 75 topics. This should provide a relatively focused set of topics, but not so narrow that it will not apply to more than one year:</p><div><img src="img/4139OS_03_06.jpg" alt="Exploring the topics"/></div><p>The MALLET library makes it easy to get a lot of information about each topic. This includes the words that are associated with each topic, ranked by how important each word is to that topic. The following table lists some of the topics from this run along with the top five words for each:</p><div><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th style="text-align: left" valign="bottom">
<p>Topic number</p>
</th><th style="text-align: left" valign="bottom">
<p>Top words</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<p>0</p>
</td><td style="text-align: left" valign="top">
<p>states government subject united citizens good</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>1</p>
</td><td style="text-align: left" valign="top">
<p>world free nations united democracy life</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>2</p>
</td><td style="text-align: left" valign="top">
<p>people work tonight Americans year jobs</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>3</p>
</td><td style="text-align: left" valign="top">
<p>years national support education rights water</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>4</p>
</td><td style="text-align: left" valign="top">
<p>congress government made country report united</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>5</p>
</td><td style="text-align: left" valign="top">
<p>present national tax great cent country</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>6</p>
</td><td style="text-align: left" valign="top">
<p>government congress made American foreign conditions</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>7</p>
</td><td style="text-align: left" valign="top">
<p>America great nation freedom free hope</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>8</p>
</td><td style="text-align: left" valign="top">
<p>congress president years today future ago</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>9</p>
</td><td style="text-align: left" valign="top">
<p>congress employment executive people measures relief</p>
</td></tr></tbody></table></div><p>The word lists help us get an understanding of the topics and what they contain. For instance, the seventh topic seems clearly about American freedom rhetoric. However, there are still a lot of questions left unanswered. The eighth and ninth topics both have <em>congress</em> as their most important word, and some of the words listed for many topics don't have a clear relationship among each other. We'll need to dig deeper.</p><p>A better graph would help. It <a id="id270" class="indexterm"/>could make each topic's dynamics and changes through time more clear, and it would make evident the trace of each topic's relation to history, wars, expansions, and economics.</p><p>Unfortunately, as presented here, the graph is pretty confusing and difficult to read. To make it easier to pull out the weightings for a single topic, I added a feature to the graph so I could select one topic and make the others fade into the background. We'll use the graph to look at a few topics. However, we'll still need to go further and look at some of the addresses for which these topics play an important part.</p><div><div><div><div><h3 class="title"><a id="ch03lvl3sec04"/>Exploring topic 43</h3></div></div></div><p>The first topic that we'll look<a id="id271" class="indexterm"/> at in more depth is number 43. The following are the top ten words for this topic and their corresponding weightings:</p><div><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th style="text-align: left" valign="bottom">
<p>Word</p>
</th><th style="text-align: left" valign="bottom">
<p>Weighting</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<p>Great</p>
</td><td style="text-align: left" valign="top">
<p>243</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>War</p>
</td><td style="text-align: left" valign="top">
<p>165</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Commerce</p>
</td><td style="text-align: left" valign="top">
<p>143</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Powers</p>
</td><td style="text-align: left" valign="top">
<p>123</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>National</p>
</td><td style="text-align: left" valign="top">
<p>115</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Made</p>
</td><td style="text-align: left" valign="top">
<p>113</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>British</p>
</td><td style="text-align: left" valign="top">
<p>103</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Militia</p>
</td><td style="text-align: left" valign="top">
<p>80</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Part</p>
</td><td style="text-align: left" valign="top">
<p>74</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Effect</p>
</td><td style="text-align: left" valign="top">
<p>73</p>
</td></tr></tbody></table></div><p>The following graph for topic 43<a id="id272" class="indexterm"/> shows that this topic was primarily a concern between 1800 and 1825:</p><div><img src="img/4139OS_03_07.jpg" alt="Exploring topic 43"/></div><p>The dominant theme of this <a id="id273" class="indexterm"/>topic is foreign policy and setting up the military, with a particular emphasis on the War of 1812 and Great Britain. To get an idea of the arc of this topic, we'll take a look at several SOTU addresses: one from before that War, one from the time of the War, and one from after the War.</p><p>The first address we'll look at in more depth is James Madison's 1810 address. The topic model gave the probability for this topic in the document as 11 percent. One of its concerns is trade relations with other countries and how other countries' warships are disrupting them. The following is a quote where Madison rather verbosely talks about the ongoing talks with Britain and France over blockades that were impeding the new republic's trade (I've highlighted the words in the quote that are most applicable to the topic):</p><div><blockquote class="blockquote"><p><em>From the <strong>British</strong> Government, no communication on the subject of the act has been received. To a communication from our minister at London of a revocation by the French Government of its Berlin and Milan decrees it was answered that the <strong>British</strong> system would be relinquished as soon as the repeal of the French decrees should have actually taken effect and the <strong>commerce</strong> of neutral nations have been restored to the condition in which it stood previously to the promulgation of those decrees.</em></p><p><em>This pledge, although it does not necessarily import, does not exclude the intention of relinquishing, along with the others in council, the practice of those novel blockades which have a like <strong>effect</strong> of interrupting our neutral <strong>commerce</strong>, and this further justice to the United States is the rather to be looked for, in as much as the blockades in question, being not more contrary to the established law of nations than inconsistent with the rules of blockade formally recognized by <strong>Great</strong> Britain herself, could have no alleged basis other than the plea of retaliation alleged as the basis of the orders in council.</em></p></blockquote></div><p>Later, as part of a larger discussion about enabling the state militias, Madison talks about the requirements for establishing schools of military science, even during peacetime, in the following part of the address:</p><div><blockquote class="blockquote"><p><em>Even among nations whose large standing armies and frequent <strong>wars</strong> afford every other opportunity of instruction these establishments are found to be indispensable for the due attainment of the branches of military science which require a regular course of study and experiment. In a government happily without the other opportunities seminaries where the elementary principles of the art of <strong>war</strong> can be taught without actual <strong>war</strong>, and without the expense of extensive and standing armies, have the precious advantage of uniting an essential preparation against external danger with a scrupulous regard to internal safety. In no other way, probably, can a provision of equal efficacy for the public defense be <strong>made</strong> at so little expense or more consistently with the public liberty.</em></p></blockquote></div><p>Next, we'll look at Madison's 1813 address. The probability of topic 43 in this address was almost 21 percent. The War of 1812 had been going on for a year at that point, and his concerns reflect that. In the following address, Madison is concerned with the role of prisoners of war and Native Americans in the war (they sided with the British); however, there's only one mention of <em>commerce</em>, which had almost ceased because of interference by the war.</p><p>The following is a sample paragraph where Madison complains about the British trying some political prisoners in court:</p><div><blockquote class="blockquote"><p><em>The <strong>British</strong> commander in that Province, nevertheless, with the sanction, as appears, of his Government, thought proper to select from American prisoners of <strong>war</strong> and send to <strong>Great</strong> Britain for trial as criminals a # of individuals who had emigrated from the <strong>British</strong> dominions long prior to the state of <strong>war</strong> between the two nations, who had incorporated themselves into our political society in the modes recognized by the law and the practice of <strong>Great</strong> Britain, and who were made prisoners of <strong>war</strong> under the banners of their adopted country, fighting for its rights and its safety.</em></p></blockquote></div><p>Finally, for topic 43, <a id="id274" class="indexterm"/>we'll take a look at James Monroe's 1820 SOTU address. The probability of topic 43 in this address was 20 percent. In this case, Monroe's looking at the United States' trade relations with the European powers. He goes through each of the major trading partners and talks about the latest happenings with them and discusses the country's military preparedness on a number of fronts.</p><p>The following is the paragraph where he talks about the trading relationship with Great Britain; he doesn't appear entirely satisfied:</p><div><blockquote class="blockquote"><p><em>The commercial relations between the United States and the <strong>British</strong> colonies in the West Indies and on this continent have undergone no change, the <strong>British</strong> Government still preferring to leave that <strong>commerce</strong> under the restriction heretofore imposed on it on each side. It is satisfactory to recollect that the restraints resorted to by the United States were defensive only, intended to prevent a monopoly under <strong>British</strong> regulations in favor of <strong>Great</strong> Britain, as it likewise is to know that the experiment is advancing in a spirit of amity between the parties.</em></p></blockquote></div><p>In this topic, there's a clear trend of conversations around a series of events. In this case, topic modeling has pointed out an interesting dynamic in the US government's early years.</p></div><div><div><div><div><h3 class="title"><a id="ch03lvl3sec05"/>Exploring topic 26</h3></div></div></div><p>We'll look at a very different type <a id="id275" class="indexterm"/>of topic next. This one focuses on one event: the Japanese bombing of Pearl Harbor, which brought the United States actively and openly into World War II.</p><p>The following are the top ten words that contributed to this topic along with their weightings; as it is more narrowly focused, the subject of this topic is clear:</p><div><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th style="text-align: left" valign="bottom">
<p>Word</p>
</th><th style="text-align: left" valign="bottom">
<p>Weighting</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<p>Production</p>
</td><td style="text-align: left" valign="top">
<p>66</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Victory</p>
</td><td style="text-align: left" valign="top">
<p>48</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Japanese</p>
</td><td style="text-align: left" valign="top">
<p>44</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Enemy</p>
</td><td style="text-align: left" valign="top">
<p>41</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>United</p>
</td><td style="text-align: left" valign="top">
<p>39</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Fighting</p>
</td><td style="text-align: left" valign="top">
<p>37</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Attack</p>
</td><td style="text-align: left" valign="top">
<p>37</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Japan</p>
</td><td style="text-align: left" valign="top">
<p>31</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Pacific</p>
</td><td style="text-align: left" valign="top">
<p>28</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Day</p>
</td><td style="text-align: left" valign="top">
<p>27</p>
</td></tr></tbody></table></div><p>The narrow focus of the topic is evident in the graph as well. The spike at 1942 and 1943 in the following graph—the two years after the bombing of Pearl Harbor—lends weight to the evidence that this topic is about this particular event:</p><div><img src="img/4139OS_03_08.jpg" alt="Exploring topic 26"/></div><p>For the first SOTU address that we'll examine, we'll look at the one immediately after the Pearl Harbor bombing, presented by Franklin D. Roosevelt on January 6, 1942. This topic's probability of application is 22.7 percent. This was less than one month after the attack, so its memory was still pretty raw in the minds of American citizens, and this emotion is evident in the speech.</p><p>The text of the speech itself is predictable, especially given the words listed earlier. To paraphrase: <em>After the attack</em>; <em>they're our enemy</em>; <em>bent on world conquest</em>; <em>along with the</em> <em>Nazis</em>; <em>we must have victory to maintain the cause of freedom and democracy</em>. Beyond this, he's also making the point that we need to enter the European theater to fight alongside the British and other ally partners, and furthermore, to do that effectively, the U.S. must increase production of military weapons, vehicles, boats, airplanes, and supplies across the board.</p><p>The following is a short paragraph in which Roosevelt outlines the steps that are already underway to work with the allied powers:</p><div><blockquote class="blockquote"><p><em>Plans have been laid here and in the other capitals for coordinated and cooperative action by all the <strong>United</strong> Nations—military action and economic action. Already we have established, as you know, unified command of land, sea, and air forces in the southwestern <strong>Pacific</strong> theater of war. There will be a continuation of conferences and consultations among military staffs, so that the plans and operations of each will fit into the general strategy designed to crush the <strong>enemy</strong>. We shall not fight isolated wars—each Nation going its own way. These 26 Nations are <strong>united</strong>—not in spirit and determination alone, but in the broad conduct of the war in all its phases.</em></p></blockquote></div><p>Although this <a id="id276" class="indexterm"/>particular SOTU address clearly dominates this topic, there are other addresses that have some small probability of applying. It might be interesting to see what else was categorized in this topic, even the words with a low probability percentage. One such address is James Madison's 1814 address, which has a probability of 3.7 percent for this topic.</p><p>In the following part of the address, Madison spends a lot of time talking about "the enemy," who in this case, is Great Britain. This short paragraph is typical:</p><div><blockquote class="blockquote"><p><em>In another recent <strong>attack</strong> by a powerful force on our troops at Plattsburg, of which regulars made a part only, the <strong>enemy</strong>, after a perseverance for many hours, was finally compelled to seek safety in a hasty retreat, with our gallant bands pressing upon them.</em></p></blockquote></div><p>This address has a number of other short descriptions of battles like this one.</p><p>Finally, a more recent SOTU address also had a relatively high probability for this topic (2 percent): George W. Bush's 2003 address. In this address, most of the mentions of words that apply to this topic are spread out and there are few quotable clusters. He spends some time referring to the United Nations, which helps this document rate more highly for this topic. He also talks quite a bit about war as he is trying to build a case for invading Iraq, which he did less than two months later.</p><p>This document is clearly weaker than the other two on this topic. However, it does contain some shared vocabulary and some discourse, so its relationship to the topic, albeit weak, is clear. It's also interesting that in both of these cases, the President is trying to make a case for war.</p></div><div><div><div><div><h3 class="title"><a id="ch03lvl3sec06"/>Exploring topic 42</h3></div></div></div><p>Finally, we'll look at a more <a id="id277" class="indexterm"/>domestically oriented topic. The words in the following table suggest that this topic will be about childcare, schools, and healthcare:</p><div><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th style="text-align: left" valign="bottom">
<p>Word</p>
</th><th style="text-align: left" valign="bottom">
<p>Weighting</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<p>Children</p>
</td><td style="text-align: left" valign="top">
<p>270</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Health</p>
</td><td style="text-align: left" valign="top">
<p>203</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Care</p>
</td><td style="text-align: left" valign="top">
<p>182</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Support</p>
</td><td style="text-align: left" valign="top">
<p>164</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Schools</p>
</td><td style="text-align: left" valign="top">
<p>159</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>School</p>
</td><td style="text-align: left" valign="top">
<p>139</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Community</p>
</td><td style="text-align: left" valign="top">
<p>131</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Century</p>
</td><td style="text-align: left" valign="top">
<p>130</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Parents</p>
</td><td style="text-align: left" valign="top">
<p>124</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Make</p>
</td><td style="text-align: left" valign="top">
<p>121</p>
</td></tr></tbody></table></div><p>Looking at the following<a id="id278" class="indexterm"/> graph on this topic, it's clearly a late twentieth-century subject, and it really doesn't take off until after 1980. Somewhat predictably, this topic sees its zenith in the Clinton administration. We'll look at one of Clinton's speeches on this topic later in this section:</p><div><img src="img/4139OS_03_09.jpg" alt="Exploring topic 42"/></div><p>Let's first look at one of the SOTU addresses from the first, smaller cluster of addresses that prove this topic. For that, we'll pick Lyndon B. Johnson's 1964 SOTU address, which shows a probability of 4.4 percent for this topic.</p><p>In this speech, Johnson lays out a proposal that includes what would become the Civil Rights Act of 1964, which outlawed major forms of racial, ethnic, religious, and gender discrimination as well as the medicare and medicaid programs, which would be created in 1965. He's obviously laying the groundwork for the "Great Society" program he would announce in May of that year at Ohio University in Athens, Ohio.</p><p>His main topic in this is<a id="id279" class="indexterm"/> combating poverty—after all, this is the speech that gave us the phrase "war on poverty"—but he saw education and healthcare as being a big part of that:</p><div><blockquote class="blockquote"><p><em>Our chief weapons in a more pinpointed attack will be better <strong>schools</strong>, and better <strong>health</strong>, and better homes, and better training, and better job opportunities to help more Americans, especially young Americans, escape from squalor and misery and unemployment rolls where other citizens help to carry them.</em></p></blockquote></div><p>He also saw education and healthcare as being integral to the goals of the program and the American dream itself:</p><div><blockquote class="blockquote"><p><em>This budget, and this year's legislative program, are designed to help each and every American citizen fulfill his basic hopes—his hopes for a fair chance to <strong>make</strong> good; his hopes for fair play from the law; his hopes for a full-time job on full-time pay; his hopes for a decent home for his family in a decent <strong>community</strong>; his hopes for a good <strong>school</strong> for his <strong>children</strong> with good teachers; and his hopes for security when faced with sickness or unemployment or old age.</em></p></blockquote></div><p>So although this particular speech has only a low probability for this topic, it clearly raises issues that will be more directly addressed later.</p><p>One of the SOTU addresses with the highest probability for this topic is Bill Clinton's 2000 address, which had a probability of 22.1 percent. This is his last SOTU address before leaving office, and although he still had one year left in his term, realistically, not much was going to happen in it.</p><p>Additionally, because it was his last chance, Clinton spends a lot of time looking back at what he's accomplished. Children, education, and healthcare were major focuses of his administration, whatever actually was passed through Congress, and this was reflected in his retrospective:</p><div><blockquote class="blockquote"><p><em>We ended welfare as we knew it, requiring work while protecting <strong>health care</strong> and nutrition for <strong>children</strong> and investing more in child <strong>care</strong>, transportation, and housing to help their <strong>parents</strong> go to work. We've helped parents to succeed at home and at work with family leave, which 20 million Americans have now used to <strong>care</strong> for a newborn child or a sick loved one. We've engaged 150,000 young Americans in citizen service through AmeriCorps, while helping them earn money for college.</em></p></blockquote></div><p>Clinton also spent time laying out what he saw as the major tasks ahead of the nation, and education and healthcare played a big part of them as well:</p><div><blockquote class="blockquote"><p><em>To 21st <strong>century</strong> America, let us pledge these things: Every child will begin <strong>school</strong> ready to learn and graduate ready to succeed. Every family will be able to succeed at home and at work, and no child will be raised in poverty. We will meet the challenge of the aging of America. We will assure quality, affordable <strong>health care</strong>, at last, for all Americans. We will <strong>make</strong> America the safest big country on Earth. We will pay off our national debt for the first time since 1835. We will bring prosperity to every American <strong>community</strong>. We will reverse the course of climate change and leave a safer, cleaner planet. America will lead the world toward shared peace and prosperity and the far frontiers of science and technology. And we will become at last what our Founders pledged us to be so long ago: One Nation, under God, indivisible, with liberty and justice for all.</em></p></blockquote></div><p>In fact, even <a id="id280" class="indexterm"/>beyond these broad strokes, Clinton spends a lot of time talking specifically about education, what needs to be done to improve schools, and what works to make better schools. All of this contributes to this address's high probability for topic 42.</p><p>He also spent more time talking about healthcare, what he's done on that front, and what is still left to accomplish:</p><div><blockquote class="blockquote"><p><em>We also need a 21st <strong>century</strong> revolution to reward work and strengthen families by giving every parent the tools to succeed at work and at the most important work of all, raising <strong>children</strong>. That means making sure every family has <strong>health care</strong> and the <strong>support</strong> to <strong>care</strong> for aging <strong>parents</strong>, the tools to bring their <strong>children</strong> up right, and that no child grows up in poverty.</em></p></blockquote></div><p>So looking at these addresses, we may wish that there was a separate topic for education and healthcare. However, it is interesting to note the ways in which the two topics are related. Not only are they often discussed together and simultaneously in two parts of a President's agenda for a year, but also have related rhetoric. Children are directly related to education, but they are also often invoked while talking about healthcare, and many laws about health insurance and healthcare try to ensure that children are still insured, even if their parents are not.</p></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch03lvl1sec25"/>Summary</h1></div></div></div><p>This has been an interesting dive into natural-language processing and topic modeling, and hopefully we've learned a little US history at the same time. I know I have.</p><p>However, it seems that the larger takeaway is something that we all know, but likely forget: Freeform, unstructured, text data is messy, messy, messy. In fact, what we have been working with here is exceptionally clean, as these things go. Topics don't often stand out clearly, and the relationships between subjects as opposed to the topics identified by LDA are often complex and difficult to tease apart.</p><p>However, we've also seen some interesting technologies and algorithms to help us deal with the messiness. Topic modeling doesn't—and possibly shouldn't—completely sweep the ambiguities and messiness of texts under the rug, but it does help us get a handle on what's inside large collections of documents.</p><p>In the next chapter, we'll head in a different direction and apply Bayesian classification to reports of UFO sightings.</p></div></body></html>