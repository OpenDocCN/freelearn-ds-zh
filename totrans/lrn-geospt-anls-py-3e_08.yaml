- en: Python and Remote Sensing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will discuss remote sensing. Remote sensing is about gathering
    a collection of information about the Earth without making physical contact with
    it. Typically, this means having to use satellite or aerial imagery, **Light Detection
    and Ranging** (**LIDAR**), which measures laser pulses from an aircraft to the
    Earth, or synthetic aperture radar. Remote sensing can also refer to processing
    data that's been collected, which is how we'll use the term in this chapter. Remote
    sensing grows in a more exciting way every day as more satellites are launched
    and the distribution of data becomes easier. The high availability of satellite
    and aerial images, as well as interesting new types of sensors launching each
    year, is changing the role that remote sensing plays in understanding our world.
  prefs: []
  type: TYPE_NORMAL
- en: In remote sensing, we step through each pixel in an image and perform some form
    of query or mathematical process. An image can be thought of as a large numerical
    array. In remote sensing, these arrays can be quite large, in the order of tens
    of megabytes to several gigabytes in size. While Python is fast, only C-based
    libraries can provide the speed that's needed to loop through arrays at a tolerable
    speed.
  prefs: []
  type: TYPE_NORMAL
- en: We'll use the **Python Imaging Library** (**PIL**) for image processing and
    NumPy, which provides multidimensional array mathematics. While written in C for
    speed, these libraries are designed for Python and provide a Pythonic API.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we''ll cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Swapping image bands
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating image histograms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Performing a histogram stretch
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Clipping and classifying images
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Extracting features from images
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Change detection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: First, we'll start with basic image manipulation and then build on each exercise,
    all the way to automatic change detection. These techniques will compliment the
    previous chapters by adding the ability to process satellite data and other remote
    sensing products to our toolbox.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Python 3.6 or higher
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'RAM: Minimum 6 GB (Windows), 8 GB (macOS), recommended 8 GB'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Storage: Minimum 7200 RPM SATA with 20 GB of available space; recommended SSD
    with 40 GB of available space'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Processor: Minimum Intel Core i3 2.5 GHz; recommended Intel Core i5'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Swapping image bands
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Our eyes can only see colors in the visible spectrum as combinations of **red,
    green, and blue** (**RGB**). Air and space-borne sensors can collect wavelengths
    of the energy outside of the visible spectrum. To view this data, we move images
    representing different wavelengths of light reflectance in and out of the RGB
    channels to make color images.
  prefs: []
  type: TYPE_NORMAL
- en: 'These images often end up as bizarre and alien color combinations that can
    make visual analysis difficult. An example of a typical satellite image is shown
    in the following Landsat 7 satellite scene near the NASA Stennis Space Center
    in Mississippi along the Gulf of Mexico, which is a leading center for remote
    sensing and geospatial analysis in general:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/49b6f836-41c4-4c32-ae3a-ae7c8b75071c.png)'
  prefs: []
  type: TYPE_IMG
- en: Most of the vegetation appears red and water appears almost black. This image
    is a type of false-color image, meaning the color of the image is not based on
    the RGB light. However, we can change the order of the bands or swap out certain
    bands to create another type of false-color image that looks more like the world
    we are used to seeing. To do so, you first need to download this image as a ZIP
    file from here: [https://git.io/vqs41](https://git.io/vqs41).
  prefs: []
  type: TYPE_NORMAL
- en: We installed the GDAL library with Python bindings in [Chapter 4](ff05aa7d-3aac-40b6-b857-e6bf08498141.xhtml),
    *Geospatial Python Toolbox*, in the *Installing GDAL and NumPy* section. The GDAL
    library includes a module called `gdal_array` that loads and saves remotely-sensed
    images to and from NumPy arrays for easy manipulation. GDAL itself is a data access
    library and does not provide much in the name of processing. So, in this chapter,
    we will rely heavily on NumPy to actually change images.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this example, we''ll load the image into a NumPy array using `gdal_array`
    and then we''ll immediately save it back to a new GeoTiff file. However, upon
    saving, we''ll use NumPy''s advanced array-slicing feature to change the order
    of the bands. Images in NumPy are multi-dimensional arrays in the order of band,
    height, and width. This means that an image with three bands will be an array
    of length 3, containing an array for the band, height, and width of the image.
    It''s important to note that NumPy references array locations as *y,x (row, column)*
    instead of the usual *x, y (column, row)* format we work with in spreadsheets
    and other software. Let''s get started:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we''ll import `gdal_array`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we''ll load an image named `FalseColor.tif` into a `numpy` array:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we''ll reorder the image bands by slicing the array, rearranging the
    order, and saving it back out:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: In the `SaveArray` method, the last argument is called a **prototype**. This
    argument lets you specify another image for GDAL from which you copy spatial reference
    information and some other image parameters. Without this argument, we'd end up
    with an image without georeferencing information, which could not be used in a
    GIS. In this case, we specify our input image file name because the images are
    identical, except for the band order. In this method, you can tell that the Python
    GDAL API is a wrapper around a C library and is not as Pythonic as a Python-designed
    library. For example, a pure Python library would have written the `SaveArray()`
    method as `save_array()` to follow Python standards.
  prefs: []
  type: TYPE_NORMAL
- en: 'The result of this example produces the `swap.tif` image, which is a much more
    visually appealing image with green vegetation and blue water:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d57d2ccf-ba6e-4595-a858-620f2869675f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'There''s only one problem with this image: it''s kind of dark and difficult
    to see. Let''s see if we can figure out why in the next section.'
  prefs: []
  type: TYPE_NORMAL
- en: Creating histograms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A histogram shows the statistical frequency of data distribution within a dataset.
    In the case of remote sensing, the dataset is an image. The data distribution
    is the frequency of pixels in the range of **0** to **255**, which is the range
    of 8-byte numbers that are used to store image information on computers.
  prefs: []
  type: TYPE_NORMAL
- en: In an RGB image, color is represented as a 3-digit tuple with *(0,0,0, 0, 0)*
    being black and *(255,255,255)* being white. We can graph the histogram of an
    image with the frequency of each value along the y-axis and the range of 256 possible
    pixel values along the x-axis.
  prefs: []
  type: TYPE_NORMAL
- en: Remember in [Chapter 1](6b5bd08a-170c-4471-a3f3-d79d5b91f017.xhtml), *Learning
    about Geospatial Analysis with Python*, in the *Creating the simplest possible
    Python GIS *section, when we used the Turtle graphics engine included with Python
    to create a simple GIS? Well, we can also use it to easily graph histograms.
  prefs: []
  type: TYPE_NORMAL
- en: Histograms are usually a one-off product that makes a quick script. Also, histograms
    are typically displayed as a bar graph with the width of the bars representing
    the size of grouped data bins. But, in an image, each `bin` is only one value,
    so we'll create a line graph. We'll use the histogram function in this example
    and create a red, green, and blue line for each respective band.
  prefs: []
  type: TYPE_NORMAL
- en: 'The graphing portion of this example also defaults to scaling the *y*-axis
    values to the max RGB frequency found in the image. Technically, the *y*-axis
    represents the maximum frequency, which is the number of pixels in the image,
    which would be the case if the image was all one color. We''ll use the `turtle`
    module again here, but this example could be easily converted into any graphical
    output module. Let''s take a look at the `swap.tif` image we created in the previous
    example:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we import the libraries we need, including the `turtle` graphics library:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we create a `histogram` function that can take an array and sort the numbers
    into bins making up the histogram:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we have our `turtle` graphics function that takes a histogram and
    draws it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Draw the graph axes using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we can label them:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we''ll add tick marks on the x-axis so that we can see the line values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'We''ll do the same for the y-axis:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'We can begin plotting our histogram lines:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we can load our image and plot its histogram using the functions we
    defined previously:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Here''s what the histogram for `swap.tif` looks like after running the preceding
    code example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ccabeb94-8ddb-4c33-be02-0847abd958cf.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, all three bands are grouped closely toward the left-hand side
    of the graph and all have values less than **125** or so. As these values approach
    zero, the image becomes darker, which is not surprising.
  prefs: []
  type: TYPE_NORMAL
- en: 'Just for fun, let''s run the script again and when we call the `draw_histogram()`
    function, we''ll add the `scale=False` option to get a sense of the size of the
    image and provide an absolute scale. We''ll change the following line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'This will be changed to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'This change will produce the following histogram graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/54b4b7e2-a5b7-42b4-92ba-981a15b4bb8c.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, it's harder to see the details of the value distribution. However,
    this absolute-scale approach is useful if you are comparing multiple histograms
    of different products that were produced from the same source image.
  prefs: []
  type: TYPE_NORMAL
- en: So, now that we understand the basics of looking at an image statistically using
    histograms, how do we make our image brighter? Let's check this out in the next
    section.
  prefs: []
  type: TYPE_NORMAL
- en: Performing a histogram stretch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A histogram stretch operation does exactly what its name says. It redistributes
    the pixel values across the whole scale. By doing so, we have more values at the
    higher-intensity level and the image becomes brighter. So, in this example, we''ll
    reuse our histogram function, but we''ll add another function called `stretch()`
    that takes an image array, creates the histogram, and then spreads out the range
    of values for each band. We''ll run these functions on `swap.tif` and save the
    result in an image called `stretched.tif`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The `stretch` algorithm will produce the following image. Look how much brighter
    and visually appealing it is:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/53cfa72c-2bc1-49bb-aba8-7402f1557e7c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We can run our `turtle` graphics histogram script on `stretched.tif` by changing
    the file name in the `im` variable to `stretched.tif`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Running the preceding code will give us the following histogram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ecc2138e-13f1-4111-abec-fe8252abe7e8.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, all three bands are distributed evenly now. Their relative distribution
    to each other is the same, but, within the image, they are now spread across the
    spectrum.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we can change images for better presentation, let's look at clipping
    them to examine a particular area of interest.
  prefs: []
  type: TYPE_NORMAL
- en: Clipping images
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Very rarely is an analyst interested in an entire satellite scene, which can
    easily cover hundreds of square miles. Given the size of satellite data, we are
    highly motivated to reduce the size of an image to only our area of interest.
    The best way to accomplish this reduction is to clip an image to a boundary that
    defines our study area. We can use shapefiles (or other vector data) as our boundary
    definition and basically get rid of all the data outside that boundary.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following image contains our `stretched.tif` image with a county boundary
    file layered on top, visualized in **Quantum GIS** (**QGIS**):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c175ce35-001f-41a4-a87a-c9e164b6f95e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'To clip the image, we need to follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Load the image into an array using `gdal_array`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a shapefile reader using PyShp.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Rasterize the shapefile into a georeferenced image (convert it from a vector
    into a raster).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Turn the shapefile image into a binary mask or filter to only grab the image
    pixels we want within the shapefile boundary.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Filter the satellite image through the mask.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Discard satellite image data outside the mask.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Save the clipped satellite image as `clip.tif`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We installed PyShp in [Chapter 4](ff05aa7d-3aac-40b6-b857-e6bf08498141.xhtml),
    *Geospatial Python Toolbox*, so you should already have it installed from PyPi.
    We will also add a couple of useful new utility functions in this script. The
    first is `world2pixel()`, which uses the GDAL GeoTransform object to do the world-coordinate
    to image-coordinate conversion for us.
  prefs: []
  type: TYPE_NORMAL
- en: It's still the same process we've used throughout this book, but it's integrated
    better with GDAL.
  prefs: []
  type: TYPE_NORMAL
- en: We also add the `imageToArray()` function, which converts a PIL image into a
    NumPy array. The county boundary shapefile is the `hancock.shp` boundary we've
    used in previous chapters, but you can also download it here if you need to: [http://git.io/vqsRH](http://git.io/vqsRH).
  prefs: []
  type: TYPE_NORMAL
- en: 'We use PIL because it is the easiest way to rasterize our shapefile as a mask
    image to filter out the pixels beyond the shapefile boundary. Let''s get started:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we''ll load the libraries we need:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we''ll load PIL. This may need to be installed slightly differently on
    different platforms, so we have to check for that difference:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we will set up the variables for our input image, shapefile, and our output
    image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, create a function that simply converts an image into a `numpy` array
    so that we can convert the mask image we will create and use it in our NumPy-based
    clipping process:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we need a function to convert geospatial coordinates into image pixels,
    which will allow us to use coordinates from our clipping shapefile to limit which
    image pixels are saved:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can load our source image into a `numpy` array:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'We''ll also load the source image as a gdal image because `gdal_array` does
    not give us the geotransform information we need to convert coordinates into pixels:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we''ll use the Python shapefile library to open our shapefile:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we''ll convert the shapefile bounding box coordinates into image coordinates
    based on our source image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we can calculate the size of our output image based on the extents of
    the shapefile and take just that part of the source image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we''ll create new geomatrix data for the output image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can create a simple black-and-white mask image from the shapefile that
    will define the pixels we want to extract from the source image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we convert the mask image into a `numpy` array:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we''re ready to use the mask array to clip the source array in `numpy`
    and save it to a new geotiff image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'This script produces the following clipped image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c79fbf2a-441a-4cf1-856b-2c65d9aa1f65.png)'
  prefs: []
  type: TYPE_IMG
- en: The areas that remain outside the county boundary that appear in black are actually
    called `NoData` values, meaning there is no information at that location, and
    are ignored by most geospatial software. Because images are rectangular, the `NoData`
    values are common for data that does not completely fill an image.
  prefs: []
  type: TYPE_NORMAL
- en: You have now walked through an entire workflow that is used by geospatial analysts
    around the world every day to prepare multispectral satellite and aerial images
    for use in a GIS. We'll look at how we can actually analyze images as information
    in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Classifying images
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Automated remote sensing** (**ARS**) is rarely ever done in the visible spectrum.
    ARS processes images without any human input. The most commonly available wavelengths
    outside of the visible spectrum are infrared and near-infrared.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following illustration is a thermal image (band 10) from a fairly recent
    Landsat 8 flyover of the US Gulf Coast from New Orleans, Louisiana to Mobile,
    Alabama. The major natural features in the image have been labeled so that you
    can orient yourself:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e1a8105d-059b-43a4-ad0c-ba5d31674e10.png)'
  prefs: []
  type: TYPE_IMG
- en: Because every pixel in that image has a reflectance value, it is information
    as opposed to just color. The type of reflectance can tell us definitively what
    a feature is, as opposed to us guessing by looking at it. Python can see those
    values and pick out features the same way we intuitively do by grouping related
    pixel values. We can colorize pixels based on their relation to each other to
    simplify the image and view-related features. This technique is called **classification**.
  prefs: []
  type: TYPE_NORMAL
- en: Classifying can range from fairly simple groupings, based only on some value
    distribution algorithm derived from the histogram, to complex methods involving
    training datasets and even computer learning and artificial intelligence. The
    simplest forms are called **unsupervised classifications**, in which no additional
    input is given other than the image itself. Methods involving some sort of training
    data to guide the computer are called **supervised classifications**. It should
    be noted that classification techniques are used across many fields, from medical
    doctors searching for cancerous cells in a patient's body scan, to casinos using
    facial-recognition software on security videos to automatically spot known **con-artists
    at blackjack tables**.
  prefs: []
  type: TYPE_NORMAL
- en: To introduce remote sensing classification, we'll just use the histogram to
    group pixels with similar colors and intensities and see what we get. First, you'll
    need to download the Landsat 8 scene from here: [http://git.io/vByJu](http://git.io/vByJu).
  prefs: []
  type: TYPE_NORMAL
- en: 'Instead of our `histogram()` function from the previous examples, we''ll use
    the version included with NumPy that allows you to easily specify the number of
    bins and returns two arrays with the frequency, as well as the ranges of the bin
    values. We''ll use the second array with the ranges as our class definitions for
    the image. The `lut` or look-up table is an arbitrary color palette that''s used
    to assign colors to the 20 unsupervised classes. You can use any colors you want.
    Let''s look at the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we import our libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we set up some variables for our input and output images:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Load the image into a `numpy` array for processing:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we''re going to create a histogram of our image with 20 groups or `bins` that
    we''ll use for classifying:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we''ll create a look-up table that will define the color ranges for our
    classes so that we can visualize them:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that our setup is complete, we can perform the classification:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we can save our classified image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'The following image is our classification output, which we just saved as a
    JPEG:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a2271208-f024-4758-893d-4a53fde9e4f5.png)'
  prefs: []
  type: TYPE_IMG
- en: We didn't specify the prototype argument when saving this as an image, so it
    has no georeferencing information, though we could easily have done otherwise
    to save the output as a GeoTIFF.
  prefs: []
  type: TYPE_NORMAL
- en: This result isn't bad for a very simple unsupervised classification. The islands
    and coastal flats show up as different shades of green. The clouds were isolated
    as shades of orange and dark blues. We did have some confusion inland where the
    land features were colored the same as the Gulf of Mexico. We could further refine
    this process by defining the class ranges manually instead of just using the histogram.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have the ability to separate features in the image, we can try to
    extract features as vector data for inclusion in a GIS.
  prefs: []
  type: TYPE_NORMAL
- en: Extracting features from images
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The ability to classify an image leads us to another remote sensing capability.
    Now that you've worked with shapefiles over the last few chapters, have you ever
    wondered where they come from? Vector GIS data such as shapefiles are typically
    extracted from remotely-sensed images such as the examples we've seen so far.
  prefs: []
  type: TYPE_NORMAL
- en: Extraction normally involves an analyst clicking around each object in an image
    and drawing the feature to save it as data. But with good remotely-sensed data
    and proper pre-processing, it is possible to automatically extract features from
    an image.
  prefs: []
  type: TYPE_NORMAL
- en: 'For this example, we''ll take a subset of our Landsat 8 thermal image to isolate
    a group of barrier islands in the Gulf of Mexico. The islands appear white as
    the sand is hot and the cooler water appears black (you can download this image
    here: [http://git.io/vqarj](http://git.io/vqarj)):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bdd03cfc-b79b-424a-b888-f7f571fbb1f2.png)'
  prefs: []
  type: TYPE_IMG
- en: Our goal with this example is to automatically extract the three islands in
    the image as a shapefile. But before we can do that, we need to mask out any data
    we aren't interested in. For example, the water has a wide range of pixel values,
    as do the islands themselves. If we just want to extract the islands themselves,
    we need to push all the pixel values into just two bins to make the image black
    and white. This technique is called **thresholding**. The islands in the image
    have enough contrast with the water in the background that thresholding should
    isolate them nicely.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following script, we will read the image into an array and then histogram
    the image using only two bins. We will then use the colors black and white to
    color the two bins. This script is simply a modified version of our classification
    script with very limited output. Let''s look at the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we import the one library we need:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we define the variables for our input and output image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we can load the image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can set up our simple classification scheme:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we classify the image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we save the image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'The output looks great, as shown in the following image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ae499dec-3998-48cc-ad4d-5ec670e52f70.png)'
  prefs: []
  type: TYPE_IMG
- en: The islands are clearly isolated, so our extraction script will be able to identify
    them as polygons and save them to a shapefile. The GDAL library has a method called
    `Polygonize()` that does exactly that. It groups all sets of isolated pixels in
    an image and saves them out as a feature dataset. One interesting technique we
    will use in this script is to use our input image as a mask.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `Polygonize()` method allows you to specify a mask that will use the color
    black as a filter that will prevent the water from being extracted as a polygon,
    and we''ll end up with just the islands. Another area to note in the script is
    that we copy the georeferencing information from our source image to our shapefile
    to geolocate it properly. Let''s look at the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we import our libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we set up our input and output image and shapefile variables:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s open our input image and get the first and only band:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we''ll tell `gdal` to use that band as a mask:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we''re ready to set up our shapefile:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we need to copy our spatial reference information from the source image
    to the shapefile, to locate it on the Earth:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can set up our shapefile attributes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we can extract our polygons:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: The output shapefile is simply called `extract.shp`. As you may remember from [Chapter
    4](ff05aa7d-3aac-40b6-b857-e6bf08498141.xhtml), *Geospatial Python Toolbox*, we
    created a quick pure Python script using PyShp and PNG Canvas to visualize shapefiles.
    We'll bring that script back here so that we can look at our shapefile, but we'll
    add something extra to it. The largest island has a small lagoon which shows up
    as a hole in the polygon. To properly render it, we have to deal with parts in
    a shapefile record.
  prefs: []
  type: TYPE_NORMAL
- en: 'The previous example using that script did not do that, so we''ll add that
    piece as we loop through the shapefile features in the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we need to import the libraries we''ll need:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we get the spatial information from the shapefile that will allow us
    to map coordinates to pixels:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we''ll create a list to hold our polygons:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we will loop through the shapefile and collect our polygons:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we map each point to an image pixel:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we draw the image using our polygon pixel information in `PNGCanvas`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we save the image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'The following image shows our automatically extracted island features:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f05b6042-5339-402d-b6bb-078186d2a19b.png)'
  prefs: []
  type: TYPE_IMG
- en: Commercial packages that do this kind of work can easily cost tens of thousands
    of dollars. While these packages are very robust, it is still fun and empowering
    to see how far you can get with simple Python scripts and a few open-source packages.
    In many cases, you can do everything you need to do.
  prefs: []
  type: TYPE_NORMAL
- en: 'The western-most island contains the polygon hole, as shown in the following
    image, and is zoomed in on that area:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4411871b-5108-48e5-9b8c-9b455393da0c.png)'
  prefs: []
  type: TYPE_IMG
- en: If you want to see what would happen if we didn't deal with the polygon holes,
    then just run the version of the script from [Chapter 4](ff05aa7d-3aac-40b6-b857-e6bf08498141.xhtml),
    *Geospatial Python Toolbox*, on this same shapefile to compare the difference.
    The lagoon is not easy to see, but you will find it if you use the other script.
  prefs: []
  type: TYPE_NORMAL
- en: Automated feature extraction is a holy grail within geospatial analysis because
    of the cost and tedious effort required to manually extract features. The key
    to feature extraction is proper image classification. Automated feature extraction
    works well with water bodies, islands, roads, farm fields, buildings, and other
    features that tend to have high-contrast pixel values with their background.
  prefs: []
  type: TYPE_NORMAL
- en: 'You now have a good grasp of working with remote sensing data using GDAL, NumPy,
    and PIL. It''s time to move on to our most complex example: change detection.'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding change detection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Change detection is the process of taking two geo-registered images of the exact
    same area from two different dates and automatically identifying differences.
    It is really just another form of image classification. Just like our previous
    classification examples, it can range from trivial techniques like those used
    here, to highly-sophisticated algorithms that provide amazingly precise and accurate
    results.
  prefs: []
  type: TYPE_NORMAL
- en: For this example, we'll use two images from a coastal area. These images show
    a populated area before and after a major hurricane, so there are significant
    differences, many of which are easy to visually spot, making these samples good
    for learning change detection. Our technique is to simply subtract the first image
    from the second to get a simple image difference using NumPy. This is a valid
    and often used technique.
  prefs: []
  type: TYPE_NORMAL
- en: The advantages are it is comprehensive and very reliable. The disadvantage of
    this overly simple algorithm is that it doesn't isolate the type of change. Many
    changes are insignificant for analysis, such as the waves on the ocean. In this
    example, we'll mask the water fairly effectively to avoid that distraction and
    only focus on the higher reflectance values toward the right-hand side of the
    difference image histogram.
  prefs: []
  type: TYPE_NORMAL
- en: You can download the baseline image from [http://git.io/vqa6h](http://git.io/vqa6h).
  prefs: []
  type: TYPE_NORMAL
- en: You can download the changed image from [http://git.io/vqaic](http://git.io/vqaic).
  prefs: []
  type: TYPE_NORMAL
- en: Note these images are quite large – 24 MB and 64 MB, respectively!
  prefs: []
  type: TYPE_NORMAL
- en: The baseline image is panchromatic, while the changed image is in false color.
    Panchromatic images are created by sensors that capture all visible light and
    are typical of higher resolution sensors rather than multispectral sensors that
    capture bands containing restricted wavelengths.
  prefs: []
  type: TYPE_NORMAL
- en: Normally, you would use two identical band combinations, but these samples will
    work for our purposes. The visual markers we can use to evaluate change detection
    include a bridge in the southeast quadrant of the image that spans from the Peninsula
    to the edge of the image. This bridge is clearly visible in the before image and
    is reduced to pilings by the hurricane. Another marker is a boat in the northwest
    quadrant which appears in the after image as a white trail but is not in the before
    image.
  prefs: []
  type: TYPE_NORMAL
- en: 'A neutral marker is the water and the state highway, which runs through the
    town and connects to the bridge. This feature is easily visible concrete, which
    does not change significantly between the two images. The following is a screenshot
    of the baseline image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/432f940f-0245-47e7-979a-35a54b04bfeb.png)'
  prefs: []
  type: TYPE_IMG
- en: 'To view these images up-close yourself, you should use QGIS or OpenEV (FWTools),
    as described in the *Quantum GIS and OpenEv* section in [Chapter 3](a5e439d1-e7fd-46b4-8fd3-8f811bfe73e4.xhtml),
    *The Geospatial Technology Landscape*, to view them easily. The following image
    is the after image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/aaeb9249-4c99-47fc-a5dd-5f1d557e577f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'So, let''s perform change detection:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we load our libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we set up the variables for our input and output images:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we read both images into NumPy arrays with `gdal_array`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we subtract the before image from the after image (difference = after
    – before):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we divide the image into five classes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we set our color table to use black to mask the lower classes. We do
    this to filter water and roads because they are darker in the image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we assign colors to the classes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we save our image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'Here''s what our initial difference image looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/79fec589-c670-41f0-8612-98194620107b.png)'
  prefs: []
  type: TYPE_IMG
- en: For the most part, the green classes represent areas where something was added.
    The red would be a darker value where something was probably removed. We can see
    that the boat trail is green in the northwest quadrant. We can also see a lot
    of changes in vegetation, as would be expected due to seasonal differences. The
    bridge is an anomaly because the exposed pilings are brighter than the darker
    surface of the original bridge, which makes them green instead of red.
  prefs: []
  type: TYPE_NORMAL
- en: Concrete is a major indicator in change detection because it is very bright
    in sunlight and is usually a sign of new development. Conversely, if a building
    is torn down and the concrete is removed, the difference is also easy to identify.
    So, the simple difference algorithm that we used here isn't perfect, but it could
    be greatly improved using thresholding, masking, better class definitions, and
    other techniques.
  prefs: []
  type: TYPE_NORMAL
- en: 'To really appreciate our change detection product, you can overlay it on the
    before or after image in QGIS and set the color black to transparent, as shown
    in the following image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b9a17df0-71c6-4c87-9370-b6b7a4f7f56e.png)'
  prefs: []
  type: TYPE_IMG
- en: Potentially, you can combine this change detection analysis with the feature
    extraction example to extract changes as vector data that can be analyzed in a
    GIS efficiently.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we covered the foundations of remote sensing, including band
    swapping, histograms, image classification, feature extraction, and change detection.
    Like in the other chapters, we stayed as close to pure Python as possible, and
    where we compromised on this goal for processing speed, we limited the software
    libraries as much as possible to keep things simple. However, if you have the
    tools from this chapter installed, you really have a complete remote sensing package
    that is limited only by your desire to learn.
  prefs: []
  type: TYPE_NORMAL
- en: The techniques in this chapter are foundational to all remote sensing processes
    and will allow you to build more complex operations.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we'll investigate elevation data. Elevation data doesn't
    fit squarely in GIS or remote sensing as it has elements of both types of processing.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The authors of GDAL have a set of Python examples that cover a number of advanced
    topics that may be of interest to you. You can find them at [https://github.com/OSGeo/gdal/tree/master/gdal/swig/python/samples](https://github.com/OSGeo/gdal/tree/master/gdal/swig/python/samples).
  prefs: []
  type: TYPE_NORMAL
