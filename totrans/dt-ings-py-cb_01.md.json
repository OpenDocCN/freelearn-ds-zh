["```py\n    $ mkdir my-project\n    ```", "```py\n    $ cd my-project\n    ```", "```py\n    $ python -–version\n    ```", "```py\nCommand 'python' not found, did you mean:\n command 'python3' from deb python3\n command 'python' from deb python-is-python3\n```", "```py\nPython 3.9.0\n```", "```py\n$ python3 --version\n```", "```py\nPython 3.9.0\n```", "```py\n    $ pip --version\n    ```", "```py\npip 20.0.2 from /usr/lib/python3/dist-packages/pip (python 3.9)\n```", "```py\n    $ wget https://www.python.org/ftp/python/3.9.1/Python-3.9.1.tgz\n    $ tar -xf Python-3.9.1.tgz\n    $ ./configure –enable-optimizations\n    $ make -j 9\n    ```", "```py\n    $ java -version\n    ```", "```py\nopenjdk version \"1.8.0_292\"\nOpenJDK Runtime Environment (build 1.8.0_292-8u292-b10-0ubuntu1~20.04-b10)\nOpenJDK 64-Bit Server VM (build 25.292-b10, mixed mode)\n```", "```py\n    $ java -version\n    openjdk version \"1.8.0_292\"\n    OpenJDK Runtime Environment (build 1.8.0_292-8u292-b10-0ubuntu1~20.04-b10)\n    OpenJDK 64-Bit Server VM (build 25.292-b10, mixed mode)\n    ```", "```py\n    $ pip install pyspark\n    ```", "```py\nSuccessfully built pyspark\nInstalling collected packages: py4j, pyspark\nSuccessfully installed py4j-0.10.9.5 pyspark-3.3.2\n```", "```py\n    $ pyspark\n    Python 3.8.10 (default, Jun 22 2022, 20:18:18)\n    [GCC 9.4.0] on linux\n    Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n    22/10/08 15:06:11 WARN Utils: Your hostname, DESKTOP-DVUDB98 resolves to a loopback address: 127.0.1.1; using 172.29.214.162 instead (on interface eth0)\n    22/10/08 15:06:11 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n    22/10/08 15:06:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n    Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n    Setting default log level to \"WARN\".\n    To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n    Welcome to\n          ____              __\n         / __/__  ___ _____/ /__\n        _\\ \\/ _ \\/ _ `/ __/  '_/\n       /__ / .__/\\_,_/_/ /_/\\_\\   version 3.1.2\n          /_/\n    Using Python version 3.8.10 (default, Jun 22 2022 20:18:18)\n    Spark context Web UI available at http://172.29.214.162:4040\n    Spark context available as 'sc' (master = local[*], app id = local-1665237974112).\n    SparkSession available as 'spark'.\n    >>>\n    ```", "```py\n    >>> exit()\n    $\n    ```", "```py\nmy-project$ mkdir mongo-local\nmy-project$ cd mongo-local\n```", "```py\n    my-project/mongo-local$ docker pull mongo\n    ```", "```py\nUsing default tag: latest\nlatest: Pulling from library/mongo\n(...)\nbc8341d9c8d5: Pull complete\n(...)\nStatus: Downloaded newer image for mongo:latest\ndocker.io/library/mongo:latest\n```", "```py\n    my-project/mongo-local$ docker run \\\n    --name mongodb-local \\\n    -p 27017:27017 \\\n    -e MONGO_INITDB_ROOT_USERNAME=\"your_username\" \\\n    -e MONGO_INITDB_ROOT_PASSWORD=\"your_password\"\\\n    -d mongo:latest\n    ```", "```py\nmy-project/mongo-local$ docker ps\n```", "```py\n    my-project/mongo-local$ docker stop 427cc2e5d40e\n    ```", "```py\n# Use your own values for username and password\nversion: '3.1'\nservices:\n  mongo:\n    image: mongo\n    restart: always\n    environment:\n      MONGO_INITDB_ROOT_USERNAME: root\n      MONGO_INITDB_ROOT_PASSWORD: example\n  mongo-express:\n    image: mongo-express\n    restart: always\n    ports:\n      - 8081:8081\n    environment:\n      ME_CONFIG_MONGODB_ADMINUSERNAME: root\n      ME_CONFIG_MONGODB_ADMINPASSWORD: example\n      ME_CONFIG_MONGODB_URL: mongodb://root:example@mongo:27017/\n```", "```py\nmy-project$ mkdir airflow-local\nmy-project$ cd airflow-local\n```", "```py\n    my-project/airflow-local$ curl -LfO 'https://airflow.apache.org/docs/apache-airflow/2.3.0/docker-compose.yaml'\n    ```", "```py\n    my-project/airflow-local$ mkdir ./dags ./logs ./plugins\n    ```", "```py\n    my-project/airflow-local$ echo -e \"AIRFLOW_UID=$(id -u)\\nAIRFLOW_GID=0\" > .env\n    ```", "```py\n    my-project/airflow-local$ docker-compose up airflow-init\n    ```", "```py\nCreating network \"airflow-local_default\" with the default driver\nCreating volume \"airflow-local_postgres-db-volume\" with default driver\nPulling postgres (postgres:13)...\n13: Pulling from library/postgres\n(...)\nStatus: Downloaded newer image for postgres:13\nPulling redis (redis:latest)...\nlatest: Pulling from library/redis\nbd159e379b3b: Already exists\n(...)\nStatus: Downloaded newer image for redis:latest\nPulling airflow-init (apache/airflow:2.3.0)...\n2.3.0: Pulling from apache/airflow\n42c077c10790: Pull complete\n(...)\nStatus: Downloaded newer image for apache/airflow:2.3.0\nCreating airflow-local_postgres_1 ... done\nCreating airflow-local_redis_1    ... done\nCreating airflow-local_airflow-init_1 ... done\nAttaching to airflow-local_airflow-init_1\n(...)\nairflow-init_1       | [2022-10-09 09:49:26,250] {manager.py:213} INFO - Added user airflow\nairflow-init_1       | User \"airflow\" created with role \"Admin\"\n(...)\nairflow-local_airflow-init_1 exited with code 0\n```", "```py\n    my-project/airflow-local$ docker-compose up\n    ```", "```py\n    my-project/airflow-local$ docker ps\n    ```", "```py\n    my-project/airflow-local$ docker-compose stop\n    ```"]