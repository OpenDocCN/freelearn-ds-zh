["```py\nlein new reloaded financial\n\n```", "```py\n(defproject financial \"0.1.0-SNAPSHOT\":dependencies [[org.clojure/clojure \"1.5.1\"][org.clojure/data.xml \"0.0.7\"][org.clojure/data.csv \"0.1.2\"][clj-time \"0.6.0\"][me.raynes/fs \"1.4.4\"][org.encog/encog-core \"3.1.0\"][enclog \"0.6.3\"]]:profiles\n  {:dev {:dependencies [[org.clojure/tools.namespace \"0.2.4\"]]\n            :source-paths [\"dev\"]}})\n```", "```py\n(ns financial.types)\n```", "```py\n(defrecord NewsArticle [title pub-date text])\n```", "```py\n$ ls d/OANC-GrAF/data/written_1/journal/slate/\n. .. 1 10 11 12 13 14 15 16 17 18 19 2 20 21 22 23 24 25 26 27 28 29 3 30 31 32\n33 34 35 36 37 38 39 4 40 41 42 43 44 45 46 47 48 49 5 50 51 52 53 54 55 6 7 8\n9\n\n```", "```py\n$ ls 1/Article247_99*\n1/Article247_99-hepple.xml  1/Article247_99-s.xml \n1/Article247_99.txt\n1/Article247_99-logical.xml 1/Article247_99-vp.xml\n1/Article247_99-np.xml      1/Article247_99.anc\n\n```", "```py\n(ns financial.oanc\n  (:require [clojure.data.xml :as xml]\n            [clojure.java.io :as io]\n            [clojure.string :as str]\n            [me.raynes.fs :as fs]\n            [clj-time.core :as clj-time]\n            [clj-time.format :as time-format])\n  (:use [financial types utils]))\n```", "```py\n(defn list-category-genres [category-dir]\n  (map #(hash-map :genre % :dirname (io/file category-dir %))\n       (fs/list-dir category-dir)))\n(defn list-genres [oanc-dir]\n  (mapcat list-category-genres (ls (io/file oanc-dir \"data\"))))\n(defn find-genre-dir [genre oanc-dir]\n  (->> oanc-dir\n    list-genres\n    (filter #(= (:genre %) genre))\n    first\n    :dirname))\n(defn find-source-data [genre source oanc-dir]\n  (-> (find-genre-dir genre oanc-dir)\n    (io/file source)\n    (fs/find-files #\".*\\.anc\")))\n```", "```py\n(defn find-slate-files [oanc-dir]\n  (map #(hash-map :anc % :txt (chext % \".txt\"))\n       (find-source-data \"journal\" \"slate\" oanc-dir)))\n```", "```py\n(defn find-all [xml tag-name]\n  (lazy-seq\n    (if (= (:tag xml) tag-name)\n      (cons xml (mapcat #(find-all % tag-name) (:content xml)))\n      (mapcat #(find-all % tag-name) (:content xml)))))\n(defn content-str [xml]\n  (apply str (filter string? (:content xml))))\n```", "```py\n(def date-time-format\n     (time-format/formatter \"M/d/yyyy h:mm:ss a\"))\n```", "```py\n(defn parse-pub-date [pub-date-el]\n  (time-format/parse date-time-format (content-str pub-date-el)))\n```", "```py\n(defn norm-date [date]\n  (cond\n    (= (clj-time/year date) 0)\n      (clj-time/plus date (clj-time/years 2000))\n    (< (clj-time/year date) 100)\n      (clj-time/plus date (clj-time/years 1900))\n    :else date))\n```", "```py\n(defn find-pub-date [anc-xml]\n  (-> anc-xml\n    (find-all :pubDate)\n    first\n    parse-pub-date\n    norm-date))\n```", "```py\n(defn find-title [anc-xml]\n  (content-str (first (find-all anc-xml :title))))\n```", "```py\n(defn load-article [data-info]\n  (let [{:keys [anc txt]} data-info\n        anc-xml (xml/parse (io/reader anc))]\n    (->NewsArticle (find-title anc-xml)\n                   (find-pub-date anc-xml)\n                   (slurp txt))))\n(defn load-text-file [data filename]\n  (->NewsArticle filename date (slurp filename)))\n```", "```py\nuser=> (def articles (doall (map oanc/load-article\n (oanc/find-slate-files\n (io/file \"d/OANC-GrAF\")))))\nuser=> (count articles)\n4531\nuser=> (let [a (first articles)]\n [(:title a) (:pub-date a) (count (:text a))])\n[\"Article247_4\" #<DateTime 1999-03-09T07:47:21.000Z> 3662]\n\n```", "```py\n(defrecord StockData [date open high low close volume])\n```", "```py\n(ns financial.csv-data\n  (:require [clojure.data.csv :as csv]\n            [clojure.java.io :as io]\n            [clj-time.core :as clj-time]\n            [clj-time.format :as time-format])\n  (:use [financial types utils]))\n```", "```py\nDate,Open,High,Low,Close,Volume\n29-Dec-00,33.47,33.56,33.09,33.50,857800\n28-Dec-00,33.62,33.62,32.94,33.47,961200\n27-Dec-00,33.50,33.97,33.19,33.56,992400\n26-Dec-00,32.88,33.69,32.88,33.62,660600\n```", "```py\n(def date-format (time-format/formatter \"d-MMM-YY\"))\n```", "```py\n(defn row->StockData [row]\n  (let [[date open high low close vol] row]\n    (->StockData (time-format/parse date-format date)\n                 (->double open)\n                 (->double high)\n                 (->double low)\n                 (->double close)\n                 (->long vol))))\n```", "```py\n(defn read-stock-prices [filename]\n  (with-open [f (io/reader filename)]\n    (doall (map row->StockData (drop 1 (csv/read-csv f))))))\n```", "```py\nuser=> (def sp (csvd/read-stock-prices \"d/d-1995-2001.csv\"))\nuser=> (first sp)\n#financial.types.StockData{:date #<DateTime 2000-12-29T00:00:00.000Z>,\n :open 33.47, :high 33.56, :low 33.09, :close 33.5, :volume 857800}\nuser=> (count sp)\n1263\n\n```", "```py\n(ns financial.nlp\n  (:require [clojure.string :as str]\n            [clojure.set :as set])\n  (:use [financial types utils]))\n```", "```py\n(defn tokenize [string]\n  (map str/lower-case (re-seq #\"[\\p{L}\\p{M}]+\" string)))\n(defn tokenize-text [m] (update-in m [:text] tokenize))\n```", "```py\n(defn token-freqs [m] (update-in m [:text] frequencies))\n```", "```py\n(defn corpus-freqs [coll]\n  (reduce #(merge-with + %1 %2) {} (map :text coll)))\n```", "```py\n    user=> (def tokens (map nlp/tokenize-text articles))\n    user=> (take 10 (:text (first tokens)))\n    (\"harmonic\" \"convergences\" \"you\" \"re\" \"right\" \"maxim\" \"s\" \"strong\" \"point\" \"is\")\n\n    ```", "```py\n    user=> (def freqs (map nlp/token-freqs tokens))\n    user=> (take 10 (:text (first freqs)))\n    ([\"sillier\" 1] [\"partly\" 2] [\"mags\" 4] [\"new\" 1] [\"advisor\" 1] [\"a\" 13] [\"worry\" 1] [\"unsentimental\" 1] [\"method\" 1] [\"pampering\" 1])\n\n    ```", "```py\n    user=> (def c-freqs (nlp/corpus-freqs freqs))\n    user=> (take 10 (reverse (sort-by second c-freqs)))\n    ([\"the\" 266011]\n     [\"of\" 115973]\n     [\"to\" 107951]\n     [\"a\" 101017]\n     [\"and\" 96375]\n     [\"in\" 74558]\n     [\"s\" 66349]\n     [\"that\" 64447]\n     [\"is\" 49311]\n     [\"it\" 38175])\n\n    ```", "```py\n(defn load-stop-words [filename]\n  (set (tokenize (slurp filename))))\n```", "```py\n(defn remove-stop-words [stop-words m]\n  (update-in m [:text] #(remove stop-words %)))\n```", "```py\nuser=> (def stop-words (nlp/load-stop-words \"d/english.stop\"))\nuser=> (def filtered\n (map #(nlp/remove-stop-words stop-words %) tokens))\nuser=> (take 10 (:text (first filtered)))\n(\"harmonic\" \"convergences\" \"maxim\" \"strong\" \"point\" \"totally\" \"unsentimental\" \"ungenteel\" \"sendup\" \"model\")\n\n```", "```py\nuser=> (def freqs (map nlp/token-freqs filtered))\nuser=> (def c-freqs (nlp/corpus-freqs freqs))\nuser=> (pprint (take 10 (reverse (sort-by second c-freqs))))\n([\"clinton\" 8567]\n [\"times\" 6528]\n [\"people\" 6351]\n [\"time\" 6091]\n [\"story\" 5645]\n [\"president\" 5223]\n [\"year\" 4539]\n [\"york\" 4516]\n [\"world\" 4256]\n [\"years\" 4144])\n\n```", "```py\n(defn keep-white-list [white-list-set m]\n  (over :text #(filter white-list-set %) m))\n```", "```py\nuser=> (def ffreqs (frequencies (vals c-freqs)))\nuser=> (pprint (take 10 (reverse (sort-by second ffreqs))))\n([1 23342]\n [2 8814]\n [3 5310]\n [4 3749]\n [5 2809]\n [6 2320]\n [7 1870]\n [8 1593]\n [9 1352]\n [10 1183])\n\n```", "```py\n(defn make-rare-word-list [freqs n]\n  (map first (filter #(< (second %) n) freqs)))\n```", "```py\n(with-open [f (io/writer \"d/english.rare\")]\n  (binding [*out* f]\n    (doseq [t (sort (nlp/make-rare-word-list c-freqs 8))]\n      (println t))))\n```", "```py\nuser=> (def rare (nlp/load-stop-words \"d/english.rare\"))\nuser=> (def filtered2\n (map #(nlp/remove-stop-words rare %) filtered))\nuser=> (take 10 (:text (first filtered2)))\n(\"maxim\" \"strong\" \"point\" \"totally\" \"unsentimental\" \"sendup\" \"model\" \"hustler\" \"difference\" \"surprise\")\n\n```", "```py\n(defn process-articles\n  ([articles]\n   (process-articles\n      articles [\"d/english.stop\" \"d/english.rare\"]))\n  ([articles stop-files]\n   (let [stop-words (reduce set/union #{}\n                            (map load-stop-words stop-files))\n         process (fn [text]\n                   (frequencies\n                     (remove stop-words (tokenize text))))]\n     (map #(over :text process %) articles))))\n```", "```py\nuser=> (def freqs (nlp/process-articles articles))\n\n```", "```py\n(defn load-articles [white-list-set articles]\n  (let [process (fn [text]\n                  (frequencies\n                    (filter white-list-set (tokenize text))))]\n    (map #(over :text process %) articles)))\n```", "```py\n(defn tf [term-freq max-freq]\n  (+ 0.5 (/ (* 0.5 term-freq) max-freq)))\n(defn tf-article [article term]\n  (let [freqs (:text article)]\n    (tf (freqs term 0) (reduce max 0 (vals freqs)))))\n```", "```py\n(defn has-term?\n  ([term] (fn [a] (has-term? term a)))\n  ([term a] (not (nil? (get (:text a) term)))))\n(defn idf [corpus term]\n  (Math/log\n    (/ (count corpus)\n       (inc (count (filter (has-term? term) corpus))))))\n```", "```py\n(defn get-vocabulary [corpus]\n  (reduce set/union #{} (map #(set (keys (:text %))) corpus)))\n(defn get-idf-cache [corpus]\n  (reduce #(assoc %1 %2 (idf corpus %2)) {}\n          (get-vocabulary corpus)))\n```", "```py\n(defn tf-idf [idf-value freq max-freq]\n  (* (tf freq max-freq) idf-value))\n```", "```py\n(defn tf-idf-freqs [idf-cache freqs]\n  (let [max-freq (reduce max 0 (vals freqs))]\n    (into {}\n          (map #(vector (first %)\n                        (tf-idf\n                          (idf-cache (first %))\n                          (second %)\n                          max-freq))\n               freqs))))\n```", "```py\n(defn tf-idf-over [idf-cache article]\n  (over :text (fn [f] (tf-idf-freqs idf-cache f)) article))\n(defn tf-idf-cached [idf-cache corpus]\n  (map #(tf-idf-over idf-cache %) corpus))\n(defn tf-idf-all [corpus]\n  (tf-idf-cached (get-idf-cache corpus) corpus))\n```", "```py\n(def tf-idfs (nlp/tf-idf-all filtered2))\n(doseq [[t f] (sort-by second (:text (first filtered2)))]\n  (println t \\tab f \\tab (get (:text (first tf-idfs)) t)))\n```", "```py\n(defn load-text-files [token-white-list idf-cache articles]\n  (tf-idf-cached idf-cache\n                 (load-articles token-white-list articles)))\n```", "```py\nuser=> (def stock (csvd/read-stock-prices \"d/d-1995-2001.csv\"))\nuser=> (count stock)\n1263\n\n```", "```py\n(ns financial.nn\n  (:require [clj-time.core :as time]\n            [clj-time.coerce :as time-coerce]\n            [clojure.java.io :as io]\n            [enclog.nnets :as nnets]\n            [enclog.training :as training]\n            [financial.utils :as u]\n            [financial.validate :as v])\n  (:import [org.encog.neural.networks PersistBasicNetwork]))\n```", "```py\n(def periods [(time/days 1)\n              (time/days 2)\n              (time/days 3)\n              (time/days 4)\n              (time/days 5)\n              (time/days (* 7 2))\n              (time/days (* 7 3))\n              (time/days 30)\n              (time/days (* 30 2))\n              (time/days (* 30 6))\n              (time/days 365)])\n```", "```py\n(defn index-by [key-fn coll]\n  (into {} (map #(vector (key-fn %) %) coll)))\n(defn get-stock-date [stock-index date]\n  (if-let [price (stock-index date)]\n    price\n    (if (<= (time/year date) 1990)\n      nil\n      (get-stock-date\n        stock-index (time/minus date (time/days 1))))))\n```", "```py\n(defn make-price-vector [stock-index article date-op]\n  (let [pub-date (:pub-date article)\n        base-price (:close (get-stock-date stock-index pub-date))\n        price-feature\n        (fn [period]\n          (let [date-key (date-op pub-date period)]\n            (if-let [stock (get-stock-date stock-index date-key)]\n              (/ (price-diff base-price (:close stock))\n                 base-price)\n              0.0)))]\n    (vec (remove nil? (map price-feature periods)))))\n```", "```py\n(defn make-feature-vector [stock-index vocab article]\n  (let [freqs (:text article)\n        token-features (map #(freqs % 0.0) (sort vocab))\n        price-features (make-price-vector\n                         stock-index article time/minus)]\n    (vec (concat token-features price-features))))\n```", "```py\n(defn make-training-vector [stock-index article]\n  (vec (make-price-vector stock-index article time/plus)))\n```", "```py\n(defn make-training-set [stock-index vocab articles]\n  (let [make-pair\n        (fn [article]\n          {:input (make-feature-vector stock-index vocab article)\n           :outputs (zipmap periods\n                            (make-training-vector\n                              stock-index article))})]\n    (map make-pair articles)))\n```", "```py\n(defn make-network [vocab-size hidden-nodes]\n  (nnets/network (nnets/neural-pattern :feed-forward)\n                 :activation :sigmoid\n                 :input (+ vocab-size (count periods))\n                 :hidden [hidden-nodes]\n                 :output 1))\n```", "```py\n(defn activated [act-fn output]\n  (let [a (double-array 1 [output]))]\n    (.activationFunction act-fn a 0 1)\n    a)\n```", "```py\n(defn build-data [nnet period training-set]\n  (let [act (.getActivation nnet (dec (.getLayerCount nnet)))\n        output (mapv #(activated act (get (:outputs %) period))\n                     training-set)]\n    (training/data :basic-dataset\n                   (mapv :input training-set)\n                   output)))\n```", "```py\n(defn train-for\n  ([nnet period training-set]\n    (train-for nnet period training-set 0.01 500 []))\n  ([nnet period training-set error-tolerance\n    iterations strategies]\n    (let [data (build-data nnet period training-set)\n          trainer (training/trainer :back-prop\n                                    :network nnet:training-set data)]\n      (training/train\n        trainer error-tolerance iterations strategies)\n      nnet)))\n```", "```py\n(defn make-train [vocab-size hidden-count period coll]\n  (let [nn (make-network vocab-size hidden-count)]\n    (train-for nn period coll 0.01 100 [])\n    nn))\n```", "```py\n(defn run-network [nnet input]\n  (let [input (double-array (count input) input)\n        output (double-array (.getOutputCount nnet))]\n    (.compute nnet input output)\n    output))\n```", "```py\n(defn test-on [nnet period test-set]\n  \"Runs the net on the test set and calculates the SSE.\"\n  (let [act (.getActivation nnet (dec (.getLayerCount nnet)))\n        sqr (fn [x] (* x x))\n        error (fn [{:keys [input outputs]}]\n                (- (first (activated act (get outputs period)))\n                   (first (run-network nnet input))))]\n    (reduce + 0.0 (map sqr (map error test-set)))))\n```", "```py\n(defn accum\n  ([] [])\n  ([v x] (conj v x)))\n(defn x-validate [vocab-size hidden-count period coll]\n  (v/k-fold #(make-train vocab-size hidden-count period %)\n            #(test-on %1 period %2)\n            accum\n            10\n            coll))\n```", "```py\n(defn explore-point [vocab-count period hidden-count training]\n  (println period hidden-count)\n  (let [error (x-validate\n                vocab-count hidden-count period training)]\n    (println period hidden-count\n             '=> \\tab (u/mean error) \\tab error)\n    (println)\n    error))\n```", "```py\n(def ^:dynamic *hidden-counts* [5 10 25 50 75])\n(defn final-eval [vocab-size period hidden-count\n                  training-set test-set]\n  (let [nnet (make-train\n               vocab-size hidden-count period training-set)\n        error (test-on nnet period test-set)]\n    {:period period\n     :hidden-count hidden-count\n     :nnet nnet\n     :error error}))\n\n(defn explore-params\n  ([error-ref vocab-count training]\n   (explore-params\n     error-ref vocab-count training *hidden-counts* 0.2))\n  ([error-ref vocab-count training hidden-counts test-ratio]\n   (let [[test-set dev-set] (u/rand-split training test-ratio)\n         search-space (for [p periods, h hidden-counts] [p h])]\n     (doseq [pair search-space]\n       (let [[p h] pair,\n             error (explore-point vocab-count p h dev-set)]\n         (dosync\n           (commute error-ref assoc pair error))))\n     (println \"Final evaluation against the test set.\")\n     (let [[period hidden-count]\n           (first (min-key #(u/mean (second %)) @error-ref))\n           final (final-eval\n                   vocab-count period hidden-count\n                   dev-set test-set)]\n       (dosync\n         (commute error-ref assoc :final final))))\n   @error-ref))\n```", "```py\nuser=> (require\n [me.raynes.fs :as fs]\n [financial]\n [financial.types :as t]\n [financial.nlp :as nlp]\n [financial.nn :as nn]\n [financial.oanc :as oanc]\n [financial.csv-data :as csvd]\n [financial.utils :as u])\n\n```", "```py\nuser=> (def stocks (csvd/read-stock-prices \"d/d-1996-2001.csv\"))\nuser=> (def stock-index (nn/index-by :date stocks))\n\n```", "```py\nuser=> (def slate (doall\n (map oanc/load-article\n (oanc/find-slate-files\n (io/file \"d/OANC-GrAF\")))))\nuser=> (def corpus (nlp/process-articles slate))\nuser=> (def freqs (nlp/tf-idf-all corpus))\nuser=> (def vocab (nlp/get-vocabulary corpus))\n\n```", "```py\nuser=> (def training\n (nn/make-training-set stock-index vocab freqs))\n\n```", "```py\nuser=> (def error-rates (ref {}))\nuser=> (nn/explore-params error-rates (count vocab) training)\n\n```", "```py\nuser=> (def error-means\n (into {}\n (map #(vector (first %) (u/mean (second %)))\n @error-rates)))\nuser=> (pprint (sort-by second error-means))\n([[#<Days P1D> 10] 1.0435393]\n [[#<Days P1D> 5] 1.5253379]\n [[#<Days P1D> 25] 5.0099998]\n [[#<Days P1D> 50] 32.00977]\n [[#<Days P1D> 100] 34.264244]\n [[#<Days P1D> 200] 60.73007]\n [[#<Days P1D> 300] 100.29568])\n\n```", "```py\nuser=> (def nn (nn/make-network (count vocab) 10))\nuser=> (def day1 (first nn/periods))\nuser=> (nn/train-for nn day1 training)\nIteration # 1 Error: 22.025400% Target-Error: 1.000000%\nIteration # 2 Error: 19.332094% Target-Error: 1.000000%\nIteration # 3 Error: 14.241920% Target-Error: 1.000000%\nIteration # 4 Error: 6.283643% Target-Error: 1.000000%\nIteration # 5 Error: 0.766110% Target-Error: 1.000000%\n\n```", "```py\n(def idf-cache (nlp/get-idf-cache corpus))\n(def sample-day (time/date-time 2014 3 20 0 0 0))\n(def used-vocab (set (map first idf-cache)))\n```", "```py\n(def articles (doall\n                (->> \"d/slate/\"\n                  fs/list-dir\n                  (map #(str \"d/slate/\" %))\n                  (map #(oanc/load-text-file sample-day %))\n                  (nlp/load-text-files used-vocab idf-cache))))\n```", "```py\n(def recent-stocks (csvd/read-stock-prices \"d/d-2013-2014.csv\"))\n(def recent-index (nn/index-by :date recent-stocks))\n```", "```py\n(def inputs\n  (map #(nn/make-feature-vector recent-index used-vocab %)\n       articles))\n```", "```py\nuser=> (pprint\n (flatten\n (map vec\n (map #(nn/run-network nn %) inputs))))\n(0.5046613110846201\n 0.5046613110846201\n 0.5046613135395166\n 0.5046613110846201\n 0.5046613110846201\n 0.5046613110846201\n 0.5046613110846201\n 0.5046613110846201\n 0.5046613112651592\n 0.5046613110846201)\n\n```"]