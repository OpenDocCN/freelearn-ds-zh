["```py\n    {\n        \"word1\": 5,\n        \"word2\", 3,\n    }\n    ```", "```py\n          self.conn.zincrby(name, word)\n          self.conn.expireat(name, expires)\n          Total rankings bolt (totalrankings.py)\n    ```", "```py\nself.conn.zunionstore(\n    'twitter_word_count',\n    ['twitter_word_count:%s' % t for t in xrange(\n        first_window, now_floor)])\nfor t in self.conn.zrevrange('twitter_word_count', 0, self.maxSize, withscores=True):\n    log.info('Emitting: %s', repr(t))\n    storm.emit(t)\n```", "```py\nnimbus.host: \"localhost\"\ntopology.workers: 1\noauth.consumer_key: \"your-key-for-oauth-blah\"\noauth.consumer_secret: \"your-secret-for-oauth-blah\"\noauth.access_token: \"your-access-token-blah\"\noauth.access_token_secret: \"your-access-secret-blah\"\ntwitter_word_count.redis_url: \"redis://localhost:6379\"\ntwitter_word_count.num_windows: 5\ntwitter_word_count.window_duration: 60\n```", "```py\nimport math\nimport time\nfrom collections import defaultdict\n\nimport redis\n\nfrom petrel import storm\nfrom petrel.emitter import BasicBolt\n\nclass RollingCountBolt(BasicBolt):\n    def __init__(self):\n        super(RollingCountBolt, self).__init__(script=__file__)\n\n    def initialize(self, conf, context):\n        self.conf = conf\n        self.num_windows = self.conf['twitter_word_count.num_windows']\n        self.window_duration = self.conf['twitter_word_count.window_duration']\n        self.conn = redis.from_url(conf['twitter_word_count.redis_url'])\n\n    @classmethod\n    def declareOutputFields(cls):\n        return ['word', 'count']\n\n    def process(self, tup):\n        word = tup.values[0]\n        now = time.time()\n        now_floor = int(math.floor(now / self.window_duration) * self.window_duration)\n        expires = int(now_floor + self.num_windows * self.window_duration)\n        name = 'twitter_word_count:%s' % now_floor\n        self.conn.zincrby(name, word)\n        self.conn.expireat(name, expires)\n\n    def run():\n        RollingCountBolt().run()\n```", "```py\nimport logging\nimport math\nimport time\nimport redis\n\nfrom petrel import storm\nfrom petrel.emitter import BasicBolt\n\nlog = logging.getLogger('totalrankings')\n\nclass TotalRankingsBolt(BasicBolt):\n    emitFrequencyInSeconds = 15\n    maxSize = 10\n\n    def __init__(self):\n        super(TotalRankingsBolt, self).__init__(script=__file__)\n        self.rankedItems = {}\n\n    def initialize(self, conf, context):\n        self.conf = conf\n          self.num_windows = \\\n            self.conf['twitter_word_count.num_windows']\n        self.window_duration = \\\n            self.conf['twitter_word_count.window_duration']\n        self.conn = redis.from_url(\n            conf['twitter_word_count.redis_url'])\n\n    def declareOutputFields(self):\n        return ['word', 'count']\n\n    def process(self, tup):\n        if tup.is_tick_tuple():\n            now = time.time()\n            now_floor = int(math.floor(now / self.window_duration) *\n                self.window_duration)\n            first_window = int(now_floor - self.num_windows *\n                self.window_duration)\n            self.conn.zunionstore(\n                'twitter_word_count',\n                ['twitter_word_count:%s' % t for t in xrange(first_window, now_floor)])\n            for t in self.conn.zrevrange('\n                'twitter_word_count', 0,\n               self.maxSize, withScores=True):\n                log.info('Emitting: %s', repr(t))\n                storm.emit(t)\n    def getComponentConfiguration(self):\n          return {\"topology.tick.tuple.freq.secs\":\n            self.emitFrequencyInSeconds}\n\n   def run():\n       TotalRankingsBolt().run()\n```", "```py\nfrom twitterstream import TwitterStreamSpout\nfrom splitsentence import SplitSentenceBolt\nfrom rollingcount import RollingCountBolt\nfrom totalrankings import TotalRankingsBolt\n\ndef create(builder):\n    spoutId = \"spout\"\n    splitterId = \"splitter\"\n    counterId = \"counter\"\n    totalRankerId = \"finalRanker\"\n    builder.setSpout(spoutId, TwitterStreamSpout(), 1)\n    builder.setBolt(\n        splitterId, SplitSentenceBolt(), 1).shuffleGrouping(\"spout\")\n    builder.setBolt(\n        counterId, RollingCountBolt(), 4).fieldsGrouping(\n            splitterId, [\"word\"])\n    builder.setBolt(\n        totalRankerId, TotalRankingsBolt()).globalGrouping(\n            counterId)\n```", "```py\n    pip install -U pip\n    pip install nltk==3.0.1 oauthlib==0.7.2\n    tweepy==3.2.0\n    ```", "```py\n    logconfig.ini\n    setup.sh\n    ```", "```py\n     sudo apt-get install redis-server\n    ```", "```py\n     sudo apt-get install python-redis\n    ```", "```py\n    petrel submit --config topology.yaml --logdir `pwd`\n    ```", "```py\nls -ltr petrel*totalrankings.log\n```", "```py\ntail -f petrel24748_totalrankings.log\n```", "```py\n[2015-08-10 21:30:01,691][totalrankings][INFO]Emitting: ('love', 74.0)\n[2015-08-10 21:30:01,691][totalrankings][INFO]Emitting: ('amp', 68.0)\n[2015-08-10 21:30:01,691][totalrankings][INFO]Emitting: ('like', 67.0)\n[2015-08-10 21:30:01,692][totalrankings][INFO]Emitting: ('zaynmalik', 61.0)\n[2015-08-10 21:30:01,692][totalrankings][INFO]Emitting: ('mtvhottest', 61.0)\n[2015-08-10 21:30:01,692][totalrankings][INFO]Emitting: ('get', 58.0)\n[2015-08-10 21:30:01,692][totalrankings][INFO]Emitting: ('one', 49.0)\n[2015-08-10 21:30:01,692][totalrankings][INFO]Emitting: ('follow', 46.0)\n[2015-08-10 21:30:01,692][totalrankings][INFO]Emitting: ('u', 44.0)\n[2015-08-10 21:30:01,692][totalrankings][INFO]Emitting: ('new', 38.0)\n[2015-08-10 21:30:01,692][totalrankings][INFO]Emitting: ('much', 37.0)\n```", "```py\nmongo\n```", "```py\nuse cities\ndb.minute.createIndex( { minute: 1, city: 1 }, { unique: true } )\n```", "```py\nImport datetime\nimport logging\nimport geotext\nimport nltk.corpus\nimport pymongo\n\nfrom petrel import storm\nfrom petrel.emitter import BasicBolt\n\nlog = logging.getLogger('citycount')\n\nclass CityCountBolt(BasicBolt):\n    def __init__(self):\n        super(CityCountBolt, self).__init__(script=__file__)\n        self.stop_words = set(nltk.corpus.stopwords.words('english'))\n        self.stop_words.update(['http', 'https', 'rt'])\n        self.stop_cities = set([\n            'bay', 'best', 'deal', 'man', 'metro', 'of', 'un'])\n\n    def initialize(self, conf, context):\n        self.db = pymongo.MongoClient()\n\n    def declareOutputFields(self):\n        return []\n\n    def process(self, tup):\n        clean_text = ' '.join(w for w in self._get_words(tup.values[0]))\n        places = geotext.GeoText(clean_text)\n        now_minute = self._get_minute()\n        now_hour = now_minute.replace(minute=0)\n        for city in places.cities:\n            city = city.lower()\n            if city in self.stop_cities:\n                continue\n            log.info('Updating count: %s, %s, %s', now_hour, now_minute, city)\n            self.db.cities.minute.update(\n                {\n                    'hour': now_hour,\n                    'minute': now_minute,\n                    'city': city\n                },\n                {'$inc': { 'count' : 1 } },\n                upsert=True)\n\n    @staticmethod\n    def _get_minute():\n        return datetime.datetime.now().replace(second=0, microsecond=0)\n\n    def _get_words(self, sentence):\n        for w in nltk.word_tokenize(sentence):\n            wl = w.lower()\n            if wl.isalpha() and wl not in self.stop_words:\n                yield w\n\ndef run():\n    CityCountBolt().run()\n```", "```py\nfrom twitterstream import TwitterStreamSpout\nfrom citycount import CityCountBolt\n\ndef create(builder):\n    spoutId = \"spout\"\n    cityCountId = \"citycount\"\n    builder.setSpout(spoutId, TwitterStreamSpout(), 1)\n    builder.setBolt(cityCountId, CityCountBolt(), 1).shuffleGrouping(\"spout\")\n```", "```py\n    pip install -U pip\n    pip install nltk==3.0.1 oauthlib==0.7.2 tweepy==3.2.0 geotext==0.1.0 pymongo==3.0.3\n    ```", "```py\n    pip install pymongo==3.0.3\n    ```", "```py\n    import pymongo\n    from pymongo import MongoClient\n    db = MongoClient()\n    for index in db.cities.minute.list_indexes():\n        print index\n    ```", "```py\n    SON([(u'v', 1), (u'key', SON([(u'_id', 1)])), (u'name', u'_id_'), (u'ns', u'cities.minute')])\n    SON([(u'v', 1), (u'unique', True), (u'key', SON([(u'minute', 1.0), (u'city', 1.0)])), (u'name', u'minute_1_city_1'), (u'ns', u'cities.minute')])\n    ```", "```py\n    pip install geotext==0.1.0\n    ```", "```py\n    petrel submit --config topology.yaml --logdir `pwd`\n    ```", "```py\nimport pymongo\n\ndef main():\n    db = pymongo.MongoClient()\n    pipeline = [{\n        '$group': { \n          '_id':   { 'hour': '$hour', 'city': '$city' },\n          'count': { '$sum': '$count' } \n        } \n      }]\n    for r in db.cities.command('aggregate', 'minute', pipeline=pipeline)['result']:\n        print '%s,%s,%s' % (r['_id']['city'], r['_id']['hour'], r['count'])\n\nif __name__ == '__main__':\n    main()\n```"]