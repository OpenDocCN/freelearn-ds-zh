<html><head></head><body><div class="chapter" title="Chapter&#xA0;7.&#xA0;Processing Large Datasets with Limited RAM"><div class="titlepage"><div><div><h1 class="title"><a id="ch07"/>Chapter 7. Processing Large Datasets with Limited RAM</h1></div></div></div><p>In the previous chapter, we learned how to optimize the memory consumption of R programs by reducing the copying of data and by removing temporary data. Sometimes, that is still not enough. We might have data that is too large to even fit into memory, let alone perform any computations on them, or even if the data can fit into memory, there is not much free memory left for the analyses that we need to perform.</p><p>In this chapter, we will learn advanced techniques to overcome memory limitations and process large datasets.</p><p>This chapter covers:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Using memory-efficient data structures</li><li class="listitem" style="list-style-type: disc">Using memory-mapped files and processing data in chunks</li></ul></div><div class="section" title="Using memory-efficient data structures"><div class="titlepage"><div><div><h1 class="title"><a id="ch07lvl1sec39"/>Using memory-efficient data structures</h1></div></div></div><p>One of the first things to consider when you work with a large dataset is whether the same<a id="id203" class="indexterm"/> information can be stored and processed using more memory-efficient data structures. But first we need to know how data is stored in R. Vectors are the basic building blocks of almost all data types in R. R provides atomic vectors of logical, integer, numeric, complex, character and raw types. Many other data structures are also built from vectors. Lists, for example, are essentially vectors in R's internal storage structures. They differ from atomic vectors in the way that they store pointers to other R objects rather than atomic values. That is why lists can contain objects of different types.</p><p>Let's examine how much memory is required for each of the atomic data types. To do that, we will create vectors of each type with 1 million elements and measure their <a id="id204" class="indexterm"/>memory consumption using <code class="literal">object.size()</code> (for character vectors, we will call <code class="literal">rep.int(NA_character_, 1e6)</code>, which will create a truly empty character vector containing the <code class="literal">NA</code> values, which as we shall see shortly, takes up less memory than a character vector containing empty strings):</p><div class="informalexample"><pre class="programlisting">object.size(logical(1e6))
## 4000040 bytes
object.size(integer(1e6))
## 4000040 bytes
object.size(numeric(1e6))
## 8000040 bytes
object.size(complex(1e6))
## 16000040 bytes
object.size(rep.int(NA_character_, 1e6))
## 8000040 bytes
object.size(raw(1e6))
## 1000040 bytes
object.size(vector("list", 1e6))
## 8000040 bytes</pre></div><p>These results were taken from a 64-bit version of R. Notice that all these vectors take up memory in multiples of 1 million plus an extra 40 bytes. These 40 bytes are taken up by the headers of the vectors that R uses to store information about the vectors, such as the lengths and data types. The remaining space is taken up by the data stored in the vectors.</p><p>By dividing these numbers by 1 million, we see that raw values take up 1 byte each, logical and integer values 4 bytes, numeric values 8 bytes, and complex values 16 bytes. The following figure depicts the structure and memory required for these types of vectors:</p><div class="mediaobject"><img src="graphics/9263OS_07_01.jpg" alt="Using memory-efficient data structures"/><div class="caption"><p>Internal structure of logical, integer, numeric, and complex vectors</p></div></div><p>Character vectors and lists are a little different because they do not store the actual data within their vectors. Instead, they store pointers to other vectors that contain the actual data. In the <a id="id205" class="indexterm"/>computer's memory, each element of a character vector or list is a pointer that occupies 4 bytes in a 32-bit R and 8 bytes in a 64-bit R. This is depicted in the following figure:</p><div class="mediaobject"><img src="graphics/9263OS_07_02.jpg" alt="Using memory-efficient data structures"/><div class="caption"><p>Internal structure of lists and character vectors</p></div></div><p>Let's examine character vectors more closely to see how they are stored. To do this, we will generate three different character vectors, all having 1 million strings with 10 characters each. The first vector simply contains 1 million copies of the <code class="literal">"0123456789"</code> string, generated using the <code class="literal">formatC()</code> function to take up ten characters. The second vector contains 1,000 copies of 1,000 unique strings, generated using <code class="literal">formatC()</code> to take up 10 characters. The third vector contains 1 million unique strings with 10 characters each. Because these vectors contain the same number of strings with the same length, we would expect them to take up the same amount of memory. Let's test this hypothesis:</p><div class="informalexample"><pre class="programlisting">object.size(rep.int("0123456789", 1e6))
## 8000096 bytes
object.size(rep.int(formatC(seq_len(1e3), width = 10), 1e3))
## 8056040 bytes
object.size(formatC(seq_len(1e6), width = 10))
## 64000040 bytes</pre></div><p>It turns out that the three character vectors take up vastly different amounts of memory, depending on the actual content of the strings. This is because R stores only one copy of each unique string in its CHARSXP cache in order to save memory. The character vectors that we created actually store pointers to the strings in this cache, rather than the strings themselves.</p><p>Furthermore, each of the strings in this cache is a full-fledged R vector with a 24- or 40-byte header (in a 32-bit and 64-bit R respectively) and exactly one string. The null character is appended to the end of the string, and the total vector length is rounded up to the nearest multiple of eight. So, for example, the string <code class="literal">0123456789</code> would be stored as <code class="literal">0123456789\0</code> (where <code class="literal">\0</code> is the null character) plus five more bytes to make a total of 16 bytes. Adding on the 40-byte header in a 64-bit R, this 10-character string occupies 56 bytes <a id="id206" class="indexterm"/>of memory.</p><p>Turning back to the results, the first vector with 1 million copies of <code class="literal">0123456789</code> requires 8,000,040 bytes for the character vector itself that contains pointers and another 56 bytes for storing the string itself. This makes for a total of 8,000,096 bytes, as reported by <code class="literal">object.size()</code>.</p><p>The second vector contains 1,000 unique strings, so it uses a total of <span class="emphasis"><em>8,000,040 + 1,000 × 56 = 8,056,040</em></span> bytes of memory.</p><p>The third vector contains 1 million unique strings, so it uses a total of <span class="emphasis"><em>8,000,040 + 1,000,000 × 56 = 64,000,040</em></span> bytes of memory.</p><p>Evidently the memory consumption of character vectors depends on the number of unique strings contained in the vector.</p><div class="section" title="Smaller data types"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec19"/>Smaller data types</h2></div></div></div><p>Having understood how atomic vectors are stored in R, we now look at some simple strategies to <a id="id207" class="indexterm"/>reduce the <a id="id208" class="indexterm"/>memory footprint of large datasets so that they might fit in memory for analysis.</p><p>One way is to coerce data to smaller data types, where possible. For example, if a dataset contains only integer values, storing them in an integer instead of numeric vector reduces memory consumption by about half:</p><div class="informalexample"><pre class="programlisting">object.size(as.numeric(seq_len(1e6)))
## 8000040 bytes
object.size(as.integer(seq_len(1e6)))
## 4000040 bytes</pre></div><p>This also applies to character strings. Where there are many duplicated strings in a character vector, converting it to a factor vector can reduce the memory consumption, since factors are actually integer vectors that index a character vector of the unique strings (the levels of the factor) that appear in the data:</p><div class="informalexample"><pre class="programlisting">strings &lt;- rep.int(formatC(seq_len(1e4), width = 1000), 100)
factors &lt;- factor(strings)
object.size(strings)
## 18480040 bytes
object.size(factors)
## 14560400 bytes</pre></div><p>These<a id="id209" class="indexterm"/> same techniques <a id="id210" class="indexterm"/>can be applied to the components of other data structures, such as matrices, data frames, and lists that are built on atomic vectors.</p></div><div class="section" title="Sparse matrices"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec20"/>Sparse matrices</h2></div></div></div><p>Sometimes the data might be very sparse, that is, it contains a lot of zeroes or empty values. Instead of storing a full vector of matrix in memory, using <span class="emphasis"><em>sparse matrices</em></span> can significantly <a id="id211" class="indexterm"/>reduce the amount of memory required to represent the data. Sparse matrices are provided<a id="id212" class="indexterm"/> by the <a id="id213" class="indexterm"/>
<code class="literal">Matrix</code> package that comes with R.</p><p>Say we have a 1,000 by 1,000 matrix of numbers (1 million elements in total) with about 70 percent zeroes. We can use the <code class="literal">Matrix()</code> function to create either dense or sparse matrices from this data, depending on the sparse argument:</p><div class="informalexample"><pre class="programlisting">library(Matrix)
n &lt;- rnorm(1e6)
n[sample.int(1e6, 7e5)] &lt;- 0
m.dense &lt;- Matrix(n, 1e3, 1e3, sparse = FALSE)
m.sparse &lt;- Matrix(n, 1e3, 1e3, sparse = TRUE)
object.size(n)
## 8000040 bytes
object.size(m.dense)
## 8001112 bytes
object.size(m.sparse)
## 3605424 bytes</pre></div><p>The dense matrix requires about the same amount of memory as the numeric vector of raw data. The sparse matrix reduces the size of the data by 55 percent.</p><p>Sparse matrices are also very useful for binary data (<code class="literal">TRUE</code>/<code class="literal">FALSE</code>, <code class="literal">0</code>/<code class="literal">1</code>, <code class="literal">"yes"</code>/<code class="literal">"no"</code>, <code class="literal">"hot"</code>/<code class="literal">"cold"</code>, and so on). Simply convert the binary data into logical values, where the majority class is <code class="literal">FALSE</code> (if the majority class if <code class="literal">TRUE</code>, just invert the data). We can then create sparse matrices that only store information about where the <code class="literal">TRUE</code> values occur in the matrix. Again, let's test this on a 70 percent sparse matrix of 1 million logical values:</p><div class="informalexample"><pre class="programlisting">l &lt;- sample(c(FALSE, TRUE), 1e6, TRUE, c(0.7, 0.3))
m2.dense &lt;- Matrix(l, 1e3, 1e3, sparse = FALSE)
m2.sparse &lt;- Matrix(l, 1e3, 1e3, sparse = TRUE)
object.size(l)
## 4000040 bytes
object.size(m2.dense)
## 4001112 bytes
object.size(m2.sparse)
## 2404384 bytes</pre></div><p>The sparse logical <a id="id214" class="indexterm"/>matrix is even more compact than the sparse numeric matrix, being 33 percent smaller.</p></div><div class="section" title="Symmetric matrices"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec21"/>Symmetric matrices</h2></div></div></div><p>Symmetric matrices, that is, matrices that are equal to their transpose are used in many statistical<a id="id215" class="indexterm"/> methods. Some examples include distance matrices, correlation matrices, and graph <a id="id216" class="indexterm"/>adjacency matrices. It is possible to save memory by keeping only half of the matrix, including the diagonal, since we can generate the other half of the matrix by taking the mirror image of the half matrix. The <code class="literal">Matrix</code> package provides the <code class="literal">dspMatrix</code> class to efficiently store symmetric matrices:</p><div class="informalexample"><pre class="programlisting">library(Matrix)
data &lt;- matrix(rnorm(1E5), 1E2, 1E3) 
A &lt;- cor(data)
isSymmetric(A)
## [1] TRUE
B &lt;- as(A, "dspMatrix")
object.size(A)
## 8000200 bytes
object.size(B)
## 4005320 bytes</pre></div><p>Beyond sparse and symmetric matrices, the <code class="literal">Matrix</code> package <a id="id217" class="indexterm"/>provides several other efficient matrix-type data structures including triangular matrices and diagonal matrices. Depending on the type of data, some of these data structures might be even more memory-efficient than the generic sparse or symmetric matrices used in the preceding examples. Furthermore, the package makes it such that basic matrix operations, such as matrix multiplication (<code class="literal">%*%</code>), are applicable for both dense and sparse matrices. Hence, in most cases, we do not need to manually port matrix operations from their dense to sparse versions. Consult the documentation of the <code class="literal">Matrix</code> package for more details.</p></div><div class="section" title="Bit vectors"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec22"/>Bit vectors</h2></div></div></div><p>Binary data <a id="id218" class="indexterm"/>can be represented in an even more efficient way, using bit vectors. Unlike logical values in R that take up four bytes or 32 bits, bit vectors store each logical value <a id="id219" class="indexterm"/>using only one bit. This reduces the memory consumption of logical values by a factor of 32. Bit vectors, however, cannot store the <code class="literal">NA</code> value, so they are not suitable for data that contains the <code class="literal">NA</code> values.</p><p>In R, bit vectors are provided by the <code class="literal">bit</code> package on CRAN. Let's compare the sizes of a logical vector and the equivalent bit vector:</p><div class="informalexample"><pre class="programlisting">library(bit)
l &lt;- sample(c(TRUE, FALSE), 1e6, TRUE)
b &lt;- as.bit(l)
object.size(l)
## 4000040 bytes
object.size(b)
## 126344 bytes</pre></div><p>As expected, the bit vector is 3.2 percent, or 1/32 as large as the logical vector.</p><p>Bit vectors also allow for much quicker logical operations:</p><div class="informalexample"><pre class="programlisting">library(microbenchmark)
l2 &lt;- sample(c(TRUE, FALSE), 1e6, TRUE)
b2 &lt;- as.bit(l2)
microbenchmark(!l, !b)
## Unit: microseconds
##  expr      min        lq   median        uq       max neval
##    !l 1201.993 1452.2925 1566.966 2951.0405 23045.003   100
##    !b   51.145   64.7185  <code class="literal">107.065</code>  113.2045   461.624   100
microbenchmark(l &amp; l2, b &amp; b2)
## Unit: microseconds
##    expr       min        lq     median        uq      max neval
##  l &amp; l2 22808.696 23104.647 23309.7475 24473.137 38334.65   100
##  b &amp; b2    60.948    64.615    <code class="literal">78.5025</code>   135.126 13732.20   100
microbenchmark(l == l2, b == b2)
## Unit: microseconds
##     expr      min        lq    median       uq      max neval
##  l == l2 1954.402 2208.3235 2227.8980 2320.104 16825.13   100
##  b == b2   60.263   63.2235   <code class="literal">87.7245</code>  121.448 14184.91   100</pre></div><p>When dealing with large amounts of logical or binary data, bit vectors not only save memory but also provide a speed boost when they are operated on.</p></div></div></div>
<div class="section" title="Using memory-mapped files and processing data in chunks"><div class="titlepage"><div><div><h1 class="title"><a id="ch07lvl1sec40"/>Using memory-mapped files and processing data in chunks</h1></div></div></div><p>Some datasets <a id="id220" class="indexterm"/>are so large that even after applying all memory optimization techniques and using the most efficient data types possible, they are still too large to fit in or be processed in the memory. Short of getting additional RAM, one way to work with such large data is to store them on a disk in the form <a id="id221" class="indexterm"/>of <span class="strong"><strong>memory-mapped files</strong></span> and load the data into the memory for processing one small chunk <a id="id222" class="indexterm"/>at a time.</p><p>For example, say we have a dataset that would require 100 GB of RAM if it is fully loaded into the memory and another 100 GB of free memory for the computations that need to be performed on the data. If the computer on which the data is to be processed only has 64 GB of RAM, we might divide the data into four chunks of 25 GB each. The R program will then load the data into the memory one chunk at a time and perform the necessary computations on each chunk. After all the chunks have been processed, the results from each chunk-wise computation will finally be combined in order to compute the final results. Whether this can be done easily depends on the nature of the algorithm that is being run on the data. Some algorithms can easily be converted to compute on chunks of data, while others might require substantial effort to do so.</p><p>There are two CRAN packages that provide memory-mapped files to work with large datasets in this manner: <code class="literal">bigmemory</code> and <code class="literal">ff</code>. We will look at each of these in turn.</p><div class="section" title="The bigmemory package"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec23"/>The bigmemory package</h2></div></div></div><p>The <code class="literal">bigmemory</code> CRAN package <a id="id223" class="indexterm"/>provides a matrix-like data structure called <code class="literal">big.matrix</code>. Data <a id="id224" class="indexterm"/>stored in <code class="literal">big.matrix</code> objects <a id="id225" class="indexterm"/>can be of type <code class="literal">double</code> (8 bytes, the default), <code class="literal">integer</code> (4 bytes), <code class="literal">short</code> (2 bytes), or <code class="literal">char</code> (1 byte).The <code class="literal">big.matrix</code> objects can exist in RAM or in the form of memory-mapped files, and they can be manipulated in very much the same way as standard R matrices.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note11"/>Note</h3><p>At the time of writing, <code class="literal">bigmemory</code> is not supported on Windows, but the package authors are working to fix this.</p></div></div><p>To create a <code class="literal">big.matrix</code> object, we can either call <code class="literal">big.matrix()</code> to create a new object, or <code class="literal">as.big.matrix()</code> to coerce a matrix into <code class="literal">big.matrix</code>. For the next example, we will create a new <code class="literal">big.matrix</code> object with 1 billion rows and 3 columns in R's temporary folder:</p><div class="informalexample"><pre class="programlisting">library(bigmemory)
bm &lt;- big.matrix(1e9, 3, backingfile = "bm",
                  backingpath = tempdir())
bm
## An object of class "big.matrix"
## Slot "address":
## &lt;pointer: 0x7fac1950a4a0&gt;</pre></div><p>Running this <a id="id226" class="indexterm"/>might take a <a id="id227" class="indexterm"/>while, but when it is done, we have a new object <code class="literal">bm</code> that stores a pointer to the new memory-mapped file. We can find the new file called <code class="literal">bm</code> in the temporary directory with a size of 22 GB:</p><div class="informalexample"><pre class="programlisting">aloysius@localhost RtmpG0CQdS $ ls -lh
total 46875024
-rw-r--r--  1 aloysius  staff    22G Sep 18 08:02 bm
-rw-r--r--  1 aloysius  staff   452B Sep 18 08:02 bm.desc</pre></div><p>Such a large dataset would not have fit into the main memory of most computers. Another file, <code class="literal">bm.desc</code>, was created alongside the data file. This is used to retrieve the memory-mapped file at a later time or by another R program by calling something like <code class="literal">my.bm &lt;- attach.big.matrix(file.path(tempdir(), "bm.desc"))</code>.</p><p>The <code class="literal">big.matrix</code> objects support many of the same operations as standard R matrices:</p><div class="informalexample"><pre class="programlisting">typeof(bm)
## [1] "double"
dim(bm)
## [1] 1e+09 3e+00
nrow(bm)
## [1] 1e+09
ncol(bm)
## [1] 3
length(bm)
## [1] 3e+09
bm[1:5, ]
##      [,1] [,2] [,3]
## [1,]    1    0    0
## [2,]    0    1    0
## [3,]    0    0    1
## [4,]    0    0    0
## [5,]    0    0    0
bm[1:3, ] &lt;- diag(3)
bm[1:5, ]
##      [,1] [,2] [,3]
## [1,]    1    0    0
## [2,]    0    1    0
## [3,]    0    0    1
## [4,]    0    0    0
## [5,]    0    0    0</pre></div><p>When the subsetting operator <code class="literal">[</code> is used, <code class="literal">bigmemory</code> materializes the selected portion of the data into the RAM as a matrix. As different parts of a <code class="literal">big.matrix</code> are used, <code class="literal">bigmemory</code> automatically loads the relevant portions of the data into the RAM and removes<a id="id228" class="indexterm"/> portions that are no longer needed. Because everything selected by <code class="literal">[</code> is loaded into the memory, care must be taken to ensure that the selected data can fit into the available memory. Calls such as <code class="literal">bm[, ]</code> will likely lead to out of memory errors.</p><p>Let's now see how <a id="id229" class="indexterm"/>an R program might work with <code class="literal">big.matrix</code> by processing one chunk of it at a time. First we will fill it with random data, one chunk at a time. The first column will contain integers from the Poisson distribution with a mean of 1,000. The second column will contain binary data represented by ones and zeroes. The third will contain real numbers uniformly distributed between 0 and 100,000. The following code fills in <code class="literal">bm</code> with these random numbers in 100 chunks of 10 million rows at a time:</p><div class="informalexample"><pre class="programlisting">chunksize &lt;- 1e7
start &lt;- 1
while (start &lt;= nrow(bm)) {
    end &lt;- min(start + chunksize - 1, nrow(bm))
    chunksize &lt;- end - start + 1
    bm[start:end, 1] &lt;- rpois(chunksize, 1e3)
    bm[start:end, 2] &lt;- sample(0:1, chunksize, TRUE,
                               c(0.7, 0.3))
    bm[start:end, 3] &lt;- runif(chunksize, 0, 1e5)    
    start &lt;- start + chunksize
}</pre></div><p>Another example of a chunked computation is to find the standard deviation of each column. Calling <code class="literal">sd(bm[1, ])</code> might not work, as even a single column of data can exceed available memory. Two passes through the data are needed: one to compute the mean of each column, and another to compute the squared deviations from the mean.</p><p>The data can be split into chunks of 10 million rows, as before. In the first pass, the column means are computed:</p><div class="informalexample"><pre class="programlisting">col.sums &lt;- numeric(3)
chunksize &lt;- 1e7
start &lt;- 1
while (start &lt;= nrow(bm)) {
    end &lt;- min(start + chunksize - 1, nrow(bm))
    col.sums &lt;- col.sums + colSums(bm[start:end, ])
    start &lt;- start + chunksize
}
col.means &lt;- col.sums / nrow(bm)</pre></div><p>The code iterates<a id="id230" class="indexterm"/> through each chunk of data and computes the column sums of each chunk <a id="id231" class="indexterm"/>using the <code class="literal">colSums()</code> function. This is added to the global column sums, stored in <code class="literal">col.sums</code>. Once all the chunks have been processed, the column means are computed by dividing <code class="literal">col.sums</code> by the number of rows in the data.</p><p>In the second pass, the squared deviations of the observations from the column means are computed:</p><div class="informalexample"><pre class="programlisting">col.sq.dev &lt;- numeric(3)
start &lt;- 1
while (start &lt;= nrow(bm)) {
    end &lt;- min(start + chunksize - 1, nrow(bm))
    col.sq.dev &lt;- col.sq.dev +
        rowSums((t(bm[start:end, ]) - col.means) ^ 2)
    start &lt;- start + chunksize
}
col.var &lt;- col.sq.dev / (nrow(bm) - 1)
col.sd &lt;- sqrt(col.var)</pre></div><p>Each chunk of data is first transposed using <code class="literal">t()</code> so that <code class="literal">col.means</code> can be subtracted from each column of the transposed data to calculate the deviations from the means. The deviations are then squared and summed over the rows as the data was transposed.</p><p>Once all the chunks have been processed, the total squared deviations of each column are then divided by <span class="emphasis"><em>n-1</em></span> to compute the variance of each column. Finally, the square roots of the column variances give the column standard deviations.</p><p>The authors of <code class="literal">bigmemory</code> also wrote a companion package <code class="literal">biganalytics</code> that provides common statistical functions for <code class="literal">big.matrix</code> objects. We can compare the results of the preceding exercise with the <code class="literal">colsd()</code> function from <code class="literal">biganalytics</code>:</p><div class="informalexample"><pre class="programlisting">library(biganalytics)
col.sd
## [1] 3.162261e+01 4.582687e-01 2.886805e+04
big.col.sd &lt;- colsd(bm)
all.equal(col.sd, big.col.sd)
## [1] TRUE</pre></div><p>We have seen how to perform computations over chunks of data using <code class="literal">big.matrix </code>objects. The <a id="id232" class="indexterm"/>authors <a id="id233" class="indexterm"/>of <code class="literal">bigmemory</code> have also created other CRAN packages that provide useful functions that operate over <code class="literal">big.matrix</code> objects. These are listed in the following table:</p><div class="informaltable"><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th style="text-align: left" valign="bottom">
<p>Package</p>
</th><th style="text-align: left" valign="bottom">
<p>Samples of functions provided</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<p><code class="literal">biganalytics</code></p>
</td><td style="text-align: left" valign="top">
<p>Statistics: <code class="literal">colmean()</code>, <code class="literal">colmin()</code>, <code class="literal">min()</code>, <code class="literal">colmax()</code>, <code class="literal">max()</code>, <code class="literal">colrange()</code>, <code class="literal">range()</code>, <code class="literal">colvar()</code>, <code class="literal">colsd()</code>, <code class="literal">colsum()</code>, <code class="literal">sum()</code>, <code class="literal">colprod()</code>, <code class="literal">prod()</code>, and <code class="literal">colna()</code></p>
<p>Apply: <code class="literal">apply()</code></p>
<p>Linear models: <code class="literal">biglm.big.matrix()</code>, <code class="literal">bigglim.big.matrix()</code></p>
<p>Clustering: <code class="literal">bigkmeans()</code></p>
</td></tr><tr><td style="text-align: left" valign="top">
<p><code class="literal">bigtabulate</code></p>
</td><td style="text-align: left" valign="top">
<p>Table and <code class="literal">tapply</code>: <code class="literal">bigtabulate()</code>, <code class="literal">bigtable()</code>, <code class="literal">bigtsummary()</code></p>
<p>Split: <code class="literal">bigsplit()</code></p>
</td></tr><tr><td style="text-align: left" valign="top">
<p><code class="literal">bigalgebra</code></p>
</td><td style="text-align: left" valign="top">
<p>Arithmetic operations</p>
</td></tr></tbody></table></div></div><div class="section" title="The ff package"><div class="titlepage"><div><div><h2 class="title"><a id="ch07lvl2sec24"/>The ff package</h2></div></div></div><p>While <code class="literal">big.matrix</code> is useful for data that can be coerced to the same type, sometimes a more <a id="id234" class="indexterm"/>data frame-like memory-mapped format is required while dealing with heterogeneous <a id="id235" class="indexterm"/>data types. The <code class="literal">ff</code> CRAN package provides this capability.</p><p>The <code class="literal">ff</code> CRAN package supports more data types than <code class="literal">bigmemory</code>. The following table shows the different data types, called <code class="literal">vmodes</code>, that can be stored in <code class="literal">ff</code> vectors, arrays and data frames.</p><div class="informaltable"><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th style="text-align: left" valign="bottom">
<p>Data type or vmode</p>
</th><th style="text-align: left" valign="bottom">
<p>Description</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<p><code class="literal">Boolean</code></p>
</td><td style="text-align: left" valign="top">
<p>1-bit <a id="id236" class="indexterm"/>logical without <code class="literal">NA</code></p>
</td></tr><tr><td style="text-align: left" valign="top">
<p><code class="literal">Logical</code></p>
</td><td style="text-align: left" valign="top">
<p>2-bit logical <a id="id237" class="indexterm"/>with <code class="literal">NA</code></p>
</td></tr><tr><td style="text-align: left" valign="top">
<p><code class="literal">Quad</code></p>
</td><td style="text-align: left" valign="top">
<p>2-bit unsigned <a id="id238" class="indexterm"/>integer without <code class="literal">NA</code></p>
</td></tr><tr><td style="text-align: left" valign="top">
<p><code class="literal">Nibble</code></p>
</td><td style="text-align: left" valign="top">
<p>4-bit unsigned integer<a id="id239" class="indexterm"/> without <code class="literal">NA</code></p>
</td></tr><tr><td style="text-align: left" valign="top">
<p><code class="literal">Byte</code></p>
</td><td style="text-align: left" valign="top">
<p>8-bit <a id="id240" class="indexterm"/>signed integer with <code class="literal">NA</code></p>
</td></tr><tr><td style="text-align: left" valign="top">
<p><code class="literal">Ubyte</code></p>
</td><td style="text-align: left" valign="top">
<p>8-bit unsigned <a id="id241" class="indexterm"/>integer without <code class="literal">NA</code></p>
</td></tr><tr><td style="text-align: left" valign="top">
<p><code class="literal">Short</code></p>
</td><td style="text-align: left" valign="top">
<p>16-bit <a id="id242" class="indexterm"/>signed integer with <code class="literal">NA</code></p>
</td></tr><tr><td style="text-align: left" valign="top">
<p><code class="literal">Ushort</code></p>
</td><td style="text-align: left" valign="top">
<p>16-bit unsigned <a id="id243" class="indexterm"/>integer without <code class="literal">NA</code></p>
</td></tr><tr><td style="text-align: left" valign="top">
<p><code class="literal">Integer</code></p>
</td><td style="text-align: left" valign="top">
<p>32-bit <a id="id244" class="indexterm"/>signed integer with <code class="literal">NA</code></p>
</td></tr><tr><td style="text-align: left" valign="top">
<p><code class="literal">Single</code></p>
</td><td style="text-align: left" valign="top">
<p>32-bit <a id="id245" class="indexterm"/>float</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p><code class="literal">Double</code></p>
</td><td style="text-align: left" valign="top">
<p>64-bit <a id="id246" class="indexterm"/>float</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p><code class="literal">Complex</code></p>
</td><td style="text-align: left" valign="top">
<p>2 x 64 <a id="id247" class="indexterm"/>bit float</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p><code class="literal">Raw</code></p>
</td><td style="text-align: left" valign="top">
<p>8-bit <a id="id248" class="indexterm"/>unsigned char</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p><code class="literal">Factor</code></p>
</td><td style="text-align: left" valign="top">
<p>Factor (stored <a id="id249" class="indexterm"/>as <code class="literal">integer</code>)</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p><code class="literal">Ordered</code></p>
</td><td style="text-align: left" valign="top">
<p>Ordered <a id="id250" class="indexterm"/>factor (stored as <code class="literal">integer</code>)</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p><code class="literal">POSIXct</code></p>
</td><td style="text-align: left" valign="top">
<p>POSIXct (stored <a id="id251" class="indexterm"/>as a <code class="literal">double</code>)</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p><code class="literal">Date</code></p>
</td><td style="text-align: left" valign="top">
<p>Date (stored <a id="id252" class="indexterm"/>as <code class="literal">double</code>)</p>
</td></tr></tbody></table></div><p>The <code class="literal">ff</code> objects <a id="id253" class="indexterm"/>can be created <a id="id254" class="indexterm"/>by passing a vector of values to the <code class="literal">ff()</code> function:</p><div class="informalexample"><pre class="programlisting">i &lt;- ff(1:1e6)
i
## ff (open) integer length=1000000 (1000000)
##       [1]       [2]       [3]       [4]       [5]       [6] 
##         1         2         3         4         5         6 
##       [7]       [8]            [999993]  [999994]  [999995] 
##         7         8         :    999993    999994    999995 
##  [999996]  [999997]  [999998]  [999999] [1000000] 
##   999996    999997    999998    999999   1000000 
filename(i)
## [1] "/private/var/folders/xw/xp2p4mjd3nb6n6h30w67jkdc0000gn/T/## RtmptxP4qw/ff449847497df9.ff"</pre></div><p>Because no filename was specified, <code class="literal">ff()</code> automatically creates a new file in R's temporary directory. The filename can also be specified using the <code class="literal">filename</code> argument, as shown in the next example.</p><p>If a scalar is passed to <code class="literal">ff()</code> along with the dimensions for the new <code class="literal">ff</code> object, the scalar value will be used to initialize the object:</p><div class="informalexample"><pre class="programlisting">j &lt;- ff(FALSE, dim = c(50, 100),
        filename = file.path(tempdir(), "j.ff"))
j
## ff (open) logical length=5000 (5000) dim=c(50,100)
## dimorder=c(1,2)
##        [,1]  [,2]  [,3]  [,4]  [,5]  [,6]  [,7]  [,8]  [,100]
## [1,]  FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE : FALSE
## [2,]  FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE : FALSE
## [3,]  FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE : FALSE
## [4,]  FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE : FALSE
## [5,]  FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE : FALSE
## :         :     :     :     :     :     :     :     : :     :
## [46,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE : FALSE
## [47,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE : FALSE
## [48,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE : FALSE
## [49,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE : FALSE
## [50,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE : FALSE</pre></div><p>The <code class="literal">vmode</code> argument sets the storage mode of the <code class="literal">ff</code> object:</p><div class="informalexample"><pre class="programlisting">q &lt;- ff(sample(0:3, 1e6, TRUE), vmode = "quad")
q
## ff (open) quad length=1000000 (1000000)
##       [1]       [2]       [3]       [4]       [5]       [6] 
##         2         2         2         2         0         1 
##       [7]       [8]            [999993]  [999994]  [999995] 
##         1         0         :         1         0         1 
##  [999996]  [999997]  [999998]  [999999] [1000000] 
##         0         1         0         0         0</pre></div><p>Data frames <a id="id255" class="indexterm"/>can be<a id="id256" class="indexterm"/> constructed using <code class="literal">ffdf()</code>. Here, we create a new <code class="literal">ffdf</code> object using the integer and quad <code class="literal">ff</code> vectors created in the preceding code:</p><div class="informalexample"><pre class="programlisting">d &lt;- ffdf(i, q)
d[1:5, ]
##   i q
## 1 1 2
## 2 2 2
## 3 3 2
## 4 4 2
## 5 5 0
vmode(d)
##         i         q 
## "integer"    "quad"</pre></div><p>The <code class="literal">ff</code> objects provide the convenient <code class="literal">chunk()</code> function to split up the data into chunks based on the available memory. With its default arguments, <code class="literal">chunk()</code> recommends to load the entire data frame <code class="literal">d</code> in one chunk:</p><div class="informalexample"><pre class="programlisting">chunk(d)
## [[1]]
## range index (ri) from 1 to 1000000 maxindex 1000000</pre></div><p>The maximum chunk size in bytes can also be set using the <code class="literal">BATCHBYTES</code> argument. When it is set to 2 million bytes, <code class="literal">chunk()</code> recommends splitting the data into four chunks:</p><div class="informalexample"><pre class="programlisting">ch &lt;- chunk(d, BATCHBYTES = 2e6)
ch
## [[1]]
## range index (ri) from 1 to 250000 maxindex 1000000 
##
## [[2]]
## range index (ri) from 250001 to 500000 maxindex 1000000 
##
## [[3]]
## range index (ri) from 500001 to 750000 maxindex 1000000 
##
## [[4]]
## range index (ri) from 750001 to 1000000 maxindex 1000000</pre></div><p>In general, it is <a id="id257" class="indexterm"/>desirable to have smaller number chunks, as every chunk incurs an (typically small) I/O overhead that is required every time an R session needs to read data from <a id="id258" class="indexterm"/>disk.</p><p>The indices returned by <code class="literal">chunk()</code> can be used to index the rows of an <code class="literal">ffdf</code> or <code class="literal">ff</code> object. The following code iterates through each chunk of data, selecting the chunk with <code class="literal">d[idx, ]</code> and <code class="literal">q[idx]</code>, and performs some computations on the chunk.</p><div class="informalexample"><pre class="programlisting">total &lt;- numeric(2)
quad.table &lt;- integer(4)
names(quad.table) &lt;- 0:3
for (idx in ch) {
    total &lt;- total + colSums(d[idx, ])
    quad.table &lt;- quad.table + table(q[idx])
}
total
##            i            q 
## 500000500000      1500191 
quad.table
##      0      1      2      3 
## 249939 249964 250064 250033</pre></div><p>The <code class="literal">ff</code> CRAN package has a <a id="id259" class="indexterm"/>companion package, <code class="literal">ffbase</code>, that provides useful functions for <a id="id260" class="indexterm"/>manipulating <code class="literal">ff</code> and <code class="literal">ffdf</code> objects. Here is a sample of these functions:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Mathematics</strong></span>: <code class="literal">abs()</code>, <code class="literal">sign()</code>, <code class="literal">sqrt()</code>, <code class="literal">ceiling()</code>, <code class="literal">floor()</code>, <code class="literal">log()</code>, <code class="literal">exp()</code>, <code class="literal">cos()</code>, <code class="literal">cosh()</code>, <code class="literal">sin()</code>, <code class="literal">sinh()</code>, <code class="literal">gamma()</code></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Summaries</strong></span>: <code class="literal">all()</code>, <code class="literal">any()</code>, <code class="literal">max()</code>, <code class="literal">min()</code>, <code class="literal">cumsum()</code>, <code class="literal">cummin()</code></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Uniqueness</strong></span>: <code class="literal">duplicated()</code>, <code class="literal">unique()</code></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Apply</strong></span>: <code class="literal">ffdfdply()</code></li></ul></div><p>When we are finished with the <code class="literal">ff</code> or <code class="literal">ffdf</code> objects, we can delete the files using <code class="literal">delete()</code> and remove the R variables using <code class="literal">rm()</code>:</p><div class="informalexample"><pre class="programlisting">delete(d)
## [1] TRUE
delete(lm)
## [1] TRUE
rm(d)
rm(lm)</pre></div><p>Because the <a id="id261" class="indexterm"/>underlying <a id="id262" class="indexterm"/>vectors <code class="literal">i</code> and <code class="literal">q</code> are also deleted while deleting the data frame <code class="literal">d</code>, attempting to delete the vectors will result in an error. We can simply remove the R objects:</p><div class="informalexample"><pre class="programlisting">delete(i)
## [1] FALSE
## Warning message:
## In file.remove(attr(physical, "filename")) :
##   cannot remove file '/private/var/folders/xw/## xp2p4mjd3nb6n6h30w67jkdc0000gn/T/RtmptxP4qw/ff449847497df9.ff', ## reason 'No such file or directory'
rm(i)
rm(q)</pre></div></div></div>
<div class="section" title="Summary"><div class="titlepage"><div><div><h1 class="title"><a id="ch07lvl1sec41"/>Summary</h1></div></div></div><p>In this chapter, we learned how R stores vectors in memory, and how to estimate the amount of memory required for different types of data. We also learned how to use more efficient data structures like sparse matrices and bit vectors in order to store some types of data, so that they can be fully loaded and processed in the memory.</p><p>For datasets that are still too large, we used <code class="literal">big.matrix</code>, <code class="literal">ff</code>, and <code class="literal">ffdf</code> objects to store memory on disk using memory-mapped files and processed the data one chunk at a time. The <code class="literal">bigmemory</code> and <code class="literal">ff</code> packages, along with their companion packages, provide a rich set of functionality for memory-mapped files that cannot be covered fully, in this book. We encourage you to look up the documentation for these packages to learn more about how to take advantage of the power of memory-mapped files when you handle large datasets.</p><p>In the next chapter, we will look beyond running R in a single process or thread, and learn how to run R computations in parallel.</p></div></body></html>