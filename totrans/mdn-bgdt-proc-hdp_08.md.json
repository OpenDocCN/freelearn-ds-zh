["```py\n{\n\"name\": \"Sam Taylor\",\n\"birthdate\": \"1995-08-11\",\n\"address\":\n{\n\"street\": \"155 rabbit Street\",\n\"city\": \"San Francisco\",\n\"state\": \"ca\",\n\"postalCode\": \"94107\"\n},\n\"contactPhone\":\n[\n{\n\"type\": \"home\",\n\"number\": \"510-415-8929\"\n},\n{\n\"type\": \"cell\",\n\"number\": \"408-171-8187\"\n}\n]\n}\n```", "```py\n{\n\"name\": \"Angela Martin\",\n\"birthdate\": \"1997-11-02\",\n\"street\": \"63542 Times Square\",\n\"city\": \"New York\",\n\"state\": \"NY\",\n\"zip\": \"10036\",\n\"homePhone\": \"212-415-8929\",\n\"cellPhone\": \"212-171-8187\"\n} ,\n{\n\"name\": \"Sam Taylor\",\n\"birthdate\": \"1995-08-11\",\n\"street\": \"155 rabbit Street\",\n\"city\": \"San Francisco\",\n\"state\": \"ca\",\n\"zip\": \"94107\",\n\"homePhone\": \"510-415-8929\",\n\"cellPhone\": \"408-171-8187\"\n} ,\n{\n\"name\": \"Dan Lee\",\n\"birthdate\": \"1970-01-25\",\n\"street\": \"76336 1st Street\",\n\"city\": \"Los Angeles\",\n\"state\": \"ca\",\n\"zip\": \"90010\",\n\"homePhone\": \"323-892-5363\",\n\"cellPhone\": \"213-978-1320\"\n}\n```", "```py\n $ cd ~\n```", "```py\n$ wget --no-cookies --no-check-certificate --header \"Cookie: gpw_e24=http%3A%2F%2Fwww.oracle.com%2F; oraclelicense=accept-securebackup-cookie\" http://download.oracle.com/otn-pub/java/jdk/8u73-b02/jdk-8u73-linux-x64.rpm\n```", "```py\n$ sudo yum -y localinstall jdk-8u73-linux-x64.rpm\n```", "```py\n$ wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.1.2.rpm\n$ sudo rpm --install elasticsearch-6.1.2.rpm\n```", "```py\nsudo /bin/systemctl daemon-reload\nsudo /bin/systemctl enable elasticsearch.service\n```", "```py\nsudo systemctl start elasticsearch.service\nsudo systemctl stop elasticsearch.service\n```", "```py\ncluster.name: my-elaticsearch\npath.data: /opt/data\npath.logs: /opt/logs\nnetwork.host: 0.0.0.0\nhttp.port: 9200\n```", "```py\nsudo systemctl start elasticsearch.service\n```", "```py\nhttp://localhost:9200\n```", "```py\n// 20180320161034\n// http://localhost:9200/\n{\n \"name\": \"o7NVnfX\",\n\"cluster_name\": \"my-elasticsearch\",\n\"cluster_uuid\": \"jmB-_FEuTb6N_OFokwxF1A\",\n\"version\": {\n\"number\": \"6.1.2\",\n\"build_hash\": \"5b1fea5\",\n\"build_date\": \"2017-01-10T02:35:59.208Z\",\n\"build_snapshot\": false,\n\"lucene_version\": \"7.1.0\",\n\"minimum_wire_compatibility_version\": \"5.6.0\",\n\"minimum_index_compatibility_version\": \"5.0.0\"\n},\n\"tagline\": \"You Know, for Search\"\n}\n```", "```py\ncurl -XPUT 'localhost:9200/my_index?pretty' -H 'Content-Type: application/json' -d'\n{\n\"settings\" : {\n\"index\" : {\n\"number_of_shards\" : 2,\n\"number_of_replicas\" : 1\n}\n}\n}\n'\n```", "```py\n{\n\"acknowledged\" : true,\n\"shards_acknowledged\" : true,\n\"index\" : \"my_index\"\n}\n```", "```py\ncurl -XGET 'localhost:9200/_cat/indices?v&amp;amp;amp;pretty'\n```", "```py\nhealth status index uuid pri rep docs.count docs.deleted store.size pri.store.size\nyellow open my_index 2MXqDHedSUqoV8Zyo0l-Lw 5 1 1 0 6.9kb 6.9kb\n```", "```py\ncurl -X PUT 'localhost:9200/my_index/customer/1' -H 'Content-Type: application/json' -d '\n{\n\"name\": \"Angela Martin\",\n\"birthdate\": \"1997-11-02\",\n\"street\": \"63542 Times Square\",\n\"city\": \"New York\",\n\"state\": \"NY\",\n\"zip\": \"10036\",\n\"homePhone\": \"212-415-8929\",\n\"cellPhone\": \"212-171-8187\"\n}'\n```", "```py\n{\"index\":{\"_id\":\"1\"}}\n\n{\"name\": \"Sam Taylor\",\"birthdate\": \"1995-08-11\",\"address\":{\"street\": \"155 rabbit Street\",\"city\": \"San Francisco\",\"state\": \"CA\",\"zip\": \"94107\"},\"contactPhone\":[{\"type\": \"home\",\"number\": \"510-415-8929\"},{\"type\": \"cell\",\"number\": \"408-171-8187\"}]}\n\n{\"index\":{\"_id\":\"2\"}}\n{\"name\": \"Dan Lee\",\"birthdate\": \"1970-01-25\",\"address\":{\"street\": \"76336 1st Street\",\"city\": \"Los Angeles\",\"state\": \"CA\",\"zip\": \"90010\"},\"contactPhone\":[{\"type\": \"home\",\"number\": \"323-892-5363\"},{\"type\": \"cell\",\"number\": \"213-978-1320\"}]}\n\n{\"index\":{\"_id\":\"3\"}}\n\n{\"name\": \"Angela Martin\",\"birthdate\": \"1997-11-02\",\"address\":{\"street\": \"63542 Times Square\",\"city\": \"New York\",\"state\": \"NY\",\"zip\": \"10036\"},\"contactPhone\":[{\"type\": \"home\",\"number\": \"212-415-8929\"},{\"type\": \"cell\",\"number\": \"212-171-8187\"}]}\n```", "```py\ncurl -H 'Content-Type: application/json' -XPUT 'localhost:9200/my_index/customer/_bulk?pretty&amp;amp;amp;refresh' --data-binary \"@sample.json\"\n```", "```py\nhttp://localhost:9200/my_index/_search\n```", "```py\ncurl -XGET 'http://localhost:9200/my_index2/_search?pretty' -H 'Content-Type: application/json' -d' {\n\"query\": {\n\"match\": {\n\"city\": \"Los Angeles\" }\n}\n}'\n```", "```py\n{\n\"took\" : 3,\n\"timed_out\" : false,\n\"_shards\" : {\n\"total\" : 3,\"successful\" : 3,\n\"skipped\" : 0,\n\"failed\" : 0\n},\n\"hits\" : {\n\"total\" : 1,\n\"max_score\" : 1.3862944,\n\"hits\" : [\n{\n\"_index\" : \"my_index\",\n\"_type\" : \"customer\",\n\"_id\" : \"3\",\n\"_score\" : 1.3862944,\n\"_source\" : {\n\"name\" : \"Dan Lee\",\n\"birthdate\" : \"1970-01-25\",\n\"street\" : \"76336 1st Street\",\n\"city\" : \"Los Angeles\", \"state\" : \"ca\",\n\"postalCode\" : \"90010\",\n\"homePhone\" : \"323-892-5363\",\n\"cellPhone\" : \"213-978-1320\"\n}\n}\n]\n}\n}\n```", "```py\ncurl -XGET 'localhost:9200/my_index2/_mapping/?pretty'\n```", "```py\n{\n\"my_index\" : {\n\"mappings\" : {\ncustomer\" : {\n\"properties\" : {\n\"birthdate\" : {\n\"type\" : \"date\"\n},\n\"cellPhone\" : {\n\"type\" : \"text\",\n\"fields\" : {\n\"keyword\" : {\n\"type\" : \"keyword\",\n\"ignore_above\" : 256\n}\n}\n},\n\"city\" : {\n\"type\" : \"text\",\n\"fields\" : {\n\"keyword\" : {\n\"type\" : \"keyword\",\n\"ignore_above\" : 256\n}\n}\n},\n\"homePhone\" : {\n\"type\" : \"text\",\n\"fields\" : {\n\"keyword\" : {\n\"type\" : \"keyword\",\n\"ignore_above\" : 256\n}\n}\n},\n\"name\" : {\n\"type\" : \"text\",\n\"fields\" : {\n\"keyword\" : {\ntype\" : \"keyword\",\n\"ignore_above\" : 256\n}\n}\n},\n\"postalCode\" : {\n\"type\" : \"text\",\n\"fields\" : {\n\"keyword\" : {\n\"type\" : \"keyword\",\n\"ignore_above\" : 256\n}\n}\n},\n\"state\" : {\n\"type\" : \"text\",\n\"fields\" : {\n\"keyword\" : {\n\"type\" : \"keyword\",\n\"ignore_above\" : 256\n}\n}\n},\n\"street\" : {\n\"type\" : \"text\",\n\"fields\" : {\n\"keyword\" : {\n\"type\" : \"keyword\",\n\"ignore_above\" : 256\n}\n}\n}\n}\n}\n}\n}\n}\n```", "```py\ncurl -XPUT localhost:9200/second_index -d '{\n\"mappings\": {\n\"customer\": {\n\"_source\": {\n\"enabled\": false\n},\n\"properties\": {\n\"name\": {\"type\": \"string\", \"store\": true},\n\"birthdate\": {\"type\": \"string\"},\n\"street\": {\"type\": \"string\"},\n\"city\": {\"type\": \"date\"},\n\"state\": {\"type\": \"string\", \"index\": \"no\", \"store\": true}\n\"zip\": {\"type\": \"string\", \"index\": \"no\", \"store\": true}}\n}\n}\n}\n```", "```py\ncurl -XPOST 'localhost:9200/_analyze?pretty' -H 'Content-Type: application/json' -d'\n{\n\"analyzer\": \"standard\",\n\"text\": \" 1\\. Today it's a Sunny-day, very Bright.\"\n}'\n```", "```py\n[today, it's , a, sunny, day, very, bright ]\n```", "```py\ncurl -XPOST 'localhost:9200/_analyze?pretty' -H 'Content-Type: application/json' -d'\n{\n\"analyzer\": \"simple\",\n\"text\": \" 1\\. Today it's a Sunny-day, very Bright.\"\n}'\n```", "```py\n[today, it's , a, sunny, day, very, bright ]\n```", "```py\n$wget https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-6.1.2-x86_64.rpm\n$ sudo rpm --install filebeat-6.1.2-x86_64.rpm\nsudo /bin/systemctl daemon-reload\nsudo /bin/systemctl enable filebeat.service\n```", "```py\ninput {\n...\n}\nfilter {\n...\n}\noutput {\n..\n}\n```", "```py\n$ wget https://artifacts.elastic.co/downloads/logstash/logstash-6.1.2.rpm\n$ sudo rpm --install logstash-6.1.2.rpm\n$ sudo /bin/systemctl daemon-reload\n$ sudo systemctl start logstash.service\n```", "```py\n$wget https://artifacts.elastic.co/downloads/kibana/kibana-6.1.2-x86_64.rpm\n$ sudo rpm --install kibana-6.1.2-x86_64.rpm\nsudo /bin/systemctl daemon-reload\nsudo /bin/systemctl enable kibana.service\n```", "```py\n127.0.0.1 - - [21/Mar/2017:13:52:29 -0400] \"GET /web-portal/performance/js/common-functions.js HTTP/1.1\" 200 3558\n127.0.0.1 - - [21/Mar/2017:13:52:30 -0400] \"GET /web-portal/performance/js/sitespeed-functions.js HTTP/1.1\" 200 13068\n127.0.0.1 - - [21/Mar/2017:13:52:34 -0400] \"GET /web-portal/img/app2-icon-dark.png HTTP/1.1\" 200 4939\n127.0.0.1 - - [21/Mar/2017:13:52:43 -0400] \"GET /web-search-service/service/performanceTest/release/list HTTP/1.1\" 200 186\n127.0.0.1 - - [21/Mar/2017:13:52:44 -0400] \"GET /web-portal/performance/fonts/opan-sans/OpenSans-Light-webfont.woff HTTP/1.1\" 200 22248\n127.0.0.1 - - [21/Mar/2017:13:52:44 -0400] \"GET /web-portal/performance/img/icon/tile-actions.png HTTP/1.1\" 200 100\n127.0.0.1 - - [21/Mar/2017:13:52:44 -0400] \"GET /web-portal/performance/fonts/fontawesome/fontawesome-webfont.woff?v=4.0.3 HTTP/1.1\" 200 44432\n```", "```py\n# initial brokers for reading cluster metadata\nhosts: [\"localhost:6667\"]\n```", "```py\n###################### Filebeat Configuration Example #########################\n# This file is an example configuration file highlighting only the most common\n# options. The filebeat.reference.yml file from the same directory contains all the\n# supported options with more comments. You can use it as a reference.\n#\n# You can find the full configuration reference here:\n# https://www.elastic.co/guide/en/beats/filebeat/index.html\n# For more available modules and options, please see the filebeat.reference.yml sample\n# configuration file.\n#======================== Filebeat prospectors========================\nfilebeat.prospectors:\n# Each - is a prospector. Most options can be set at the prospector level, so\n# you can use different prospectors for various configurations.\n# Below are the prospector specific configurations.\n- type: log\n# Change to true to enable this prospector configuration.\nenabled: true\n# Paths that should be crawled and fetched. Glob based paths.\npaths:\n- /var/log/myapp/*.log\n#- c:programdataelasticsearchlogs*\n#json.keys_under_root: true\n#json.add_error_key: true\n# Exclude lines. A list of regular expressions to match. It drops the lines that are\n# matching any regular expression from the list.\n#exclude_lines: ['^DBG']\n# Include lines. A list of regular expressions to match. It exports the lines that are\n# matching any regular expression from the list.\n#include_lines: ['^ERR', '^WARN']\n# Exclude files. A list of regular expressions to match. Filebeat drops the files that\n# are matching any regular expression from the list. By default, no files are dropped.\n#exclude_files: ['.gz$']\n# Optional additional fields. These fields can be freely picked\n# to add additional information to the crawled log files for filtering\n#fields:\n# level: debug\n# review: 1\nfields:\napp: myapp\nenv: dev\ndc: gce\n### Multiline options\n# Mutiline can be used for log messages spanning multiple lines. This is common\n# for Java Stack Traces or C-Line Continuation\n# The regexp Pattern that has to be matched. The example pattern matches all lines starting with [#multiline.pattern: ^[\n# Defines if the pattern set under pattern should be negated or not. Default is false.\n#multiline.negate: false\n# Match can be set to \"after\" or \"before\". It is used to define if lines should be append to a pattern\n# that was (not) matched before or after or as long as a pattern is not matched based on negate.\n# Note: After is the equivalent to previous and before is the equivalent to to next in Logstash\n#multiline.match: after\n#============================= Filebeat modules ===============================\nfilebeat.config.modules:\n# Glob pattern for configuration loading\npath: ${path.config}/modules.d/*.yml\n# Set to true to enable config reloading\nreload.enabled: false\n# Period on which files under path should be checked for changes\n#reload.period: 10s\n#==================== Elasticsearch template setting ==========================\nsetup.template.settings:\nindex.number_of_shards: 3\n#index.codec: best_compression\n#_source.enabled: false\n#================================ General =====================================\n# The name of the shipper that publishes the network data. It can be used to group\n# all the transactions sent by a single shipper in the web interface.\n#name:\n# The tags of the shipper are included in their own field with each\n# transaction published.\n#tags: [\"service-X\", \"web-tier\"]\n# Optional fields that you can specify to add additional information to the\n# output.\n#fields:\n# env: staging\n#============================== Dashboards =====================================\n# These settings control loading the sample dashboards to the Kibana index. Loading\n# the dashboards is disabled by default and can be enabled either by setting the\n# options here, or by using the `-setup` CLI flag or the `setup` command.\n#setup.dashboards.enabled: false\n# The URL from where to download the dashboards archive. By default this URL\n# has a value which is computed based on the Beat name and version. For released\n# versions, this URL points to the dashboard archive on the artifacts.elastic.co\n# website.\n#setup.dashboards.url:\n#============================== Kibana =====================================\n# Starting with Beats version 6.0.0, the dashboards are loaded via the Kibana API.\n# This requires a Kibana endpoint configuration.\nsetup.kibana:\n# Kibana Host\n# Scheme and port can be left out and will be set to the default (http and 5601)\n# In case you specify and additional path, the scheme is required: http://localhost:5601/path\n# IPv6 addresses should always be defined as: https://[2001:db8::1]:5601\n#host: \"localhost:5601\"\n#============================= Elastic Cloud ==================================\n# These settings simplify using filebeat with the Elastic Cloud (https://cloud.elastic.co/).\n# The cloud.id setting overwrites the `output.elasticsearch.hosts` and\n# `setup.kibana.host` options.\n# You can find the `cloud.id` in the Elastic Cloud web UI.\n#cloud.id:\n# The cloud.auth setting overwrites the `output.elasticsearch.username` and\n# `output.elasticsearch.password` settings. The format is `<user>:<pass>`.\n#cloud.auth:\n#================================ Outputs =====================================\n# Configure what output to use when sending the data collected by the beat.\n#-----------------------------------Kafka Output-------------------------------\noutput.kafka: # initial brokers for reading cluster metadata hosts: [\"localhost:6667\"] # message topic selection + partitioning\ntopic: logs-topic\npartition.round_robin:\nreachable_only: false\nrequired_acks: 1\ncompression: gzip\nmax_message_bytes: 1000000\n#-------------------------- Elasticsearch output ------------------------------\n#output.elasticsearch:\n# Array of hosts to connect to.\n#hosts: [\"localhost:9200\"]\n# Optional protocol and basic auth credentials.\n#protocol: \"https\"\n#username: \"elastic\"\n#password: \"changeme\"\n#----------------------------- Logstash output --------------------------------#output.logstash:\n# The Logstash hosts\n#hosts: [\"localhost:5044\"]\n# Optional SSL. By default is off.\n# List of root certificates for HTTPS server verifications\n#ssl.certificate_authorities: [\"/etc/pki/root/ca.pem\"]\n# Certificate for SSL client authentication\n#ssl.certificate: \"/etc/pki/client/cert.pem\"\n# Client Certificate Key\n#ssl.key: \"/etc/pki/client/cert.key\"\n#================================ Logging =====================================\n# Sets log level. The default log level is info.\n# Available log levels are: error, warning, info, debug\nlogging.level: debug\n# At debug level, you can selectively enable logging only for some components.\n# To enable all selectors use [\"*\"]. Examples of other selectors are \"beat\",\n# \"publish\", \"service\".\n#logging.selectors: [\"*\"]\n#============================== Xpack Monitoring ===============================\n# filebeat can export internal metrics to a central Elasticsearch monitoring\n# cluster. This requires xpack monitoring to be enabled in Elasticsearch. The\n# reporting is disabled by default.\n# Set to true to enable the monitoring reporter.\n#xpack.monitoring.enabled: false\n# Uncomment to send the metrics to Elasticsearch. Most settings from the\n# Elasticsearch output are accepted here as well. Any setting that is not set is\n# automatically inherited from the Elasticsearch output configuration, so if you\n# have the Elasticsearch output configured, you can simply uncomment the\n# the following line.\n#xpack.monitoring.elasticsearch:\n```", "```py\nbin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic logs-topic\n```", "```py\ninput\n{\nkafka\n{\nbootstrap_servers => \"127.0.0.1:6667\"\ngroup_id => \"logstash_logs\"\ntopics => [\"logs-topic\"]\nconsumer_threads => 1\ntype => \"kafka_logs\"\n}\n}\nfilter {\nif [type] == \"kafka_logs\"\n{\njson {\nsource => \"message\"\n}\ngrok {\nmatch => { \"message\" => \"%{IP:ip} - - [%{GREEDYDATA:log_timestamp}] %{GREEDYDATA:middle} %{NUMBER:status} %{NUMBER:bytes}\" }\n}\nmutate {\nadd_field => {\n\"App\" => \"%{[fields][app]}\"\n}\n}\n}\n}\noutput {\nif [App] == \"myapp\"\n{\nelasticsearch\n{\naction => \"index\"\ncodec => \"plain\"\nhosts => [\"http://127.0.0.1:9200\"]\nindex => \"log_index-%{+YYYY-MM-dd}\"\n}\n}\n}\n```", "```py\nKafka bootstrap_servers => \"127.0.0.1:6667\"\nKafka topics => [\"logs-topic\"]\n```"]