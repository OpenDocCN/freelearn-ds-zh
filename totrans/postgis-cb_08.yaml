- en: PostGIS Programming
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Writing PostGIS vector data with Psycopg
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Writing PostGIS vector data with OGR Python bindings
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Writing PostGIS functions with PL/Python
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Geocoding and reverse geocoding using the GeoNames datasets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Geocoding using the OSM datasets with trigrams
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Geocoding with geopy and PL/Python
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Importing NetCDF datasets with Python and GDAL
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are several ways to write PostGIS programs, and in this chapter we will
    see a few of them. You will mainly use the Python language throughout this chapter.
    Python is a fantastic language with a plethora of GIS and scientific libraries
    that can be combined with PostGIS to write awesome geospatial applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you are new to Python, you can quickly get productive with these excellent
    web resources:'
  prefs: []
  type: TYPE_NORMAL
- en: The official Python tutorial at [http://docs.python.org/2/tutorial/](http://docs.python.org/2/tutorial/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The popular *Dive into Python* book at [http://www.diveintopython.net/](http://www.diveintopython.net/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can combine Python with some excellent and popular libraries, such as:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Psycopg**: This is the most complete and popular Python DB API implementation
    for PostgreSQL; see [http://initd.org/psycopg/](http://initd.org/psycopg/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**GDAL**: Used to unchain the powerful GDAL library in your Python scripts;
    see [http://www.gdal.org/gdal_tutorial.html](http://www.gdal.org/gdal_tutorial.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**requests**: This is a handy Python standard library to manage HTTP stuff,
    such as opening URLs'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**simplejson**: This is a simple and fast JSON encoder/decoder'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The recipes in this chapter will cover some other useful geospatial Python
    libraries that are worthy of being looked at if you are developing a geospatial
    application. Under these Python libraries, the following libraries are included:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Shapely**: This is a Python interface to the GEOS library for the manipulation
    and analysis of planar geometric objects: [http://toblerity.github.io/shapely/](http://toblerity.github.io/shapely/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fiona**: This is a very light OGR Python API, which can be used as an alternative
    to the OGR bindings used in this chapter to manage vector datasets: [https://github.com/Toblerity/Fiona](https://github.com/Toblerity/Fiona)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Rasterio**: This a Pythonic GDAL Python API, which can be used as an alternative
    to the GDAL bindings used in this chapter in order to manage raster datasets:
    [https://github.com/mapbox/rasterio](https://github.com/mapbox/rasterio)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**pyproj**: This is the Python interface to the PROJ.4 library: [https://pypi.python.org/pypi/pyproj](https://pypi.python.org/pypi/pyproj)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Rtree**: This is a `ctype` Python wrapper to the `libspatialindex` library,
    providing several spatial indexing features that can be extremely useful for some
    kinds of geospatial development: [http://toblerity.github.io/rtree/](http://toblerity.github.io/rtree/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the first recipe, you will write a program that uses Python and its utilities
    such as `psycopg`, `requests`, and `simplejson` to fetch weather data from the
    web and import it in PostGIS.
  prefs: []
  type: TYPE_NORMAL
- en: In the second recipe, we will drive you to use Python and the GDAL OGR Python
    bindings library to create a script for geocoding a list of place names using
    one of the GeoNames web services.
  prefs: []
  type: TYPE_NORMAL
- en: You will then write a Python function for PostGIS using the PL/Python language
    to query the [http://openweathermap.org/](http://openweathermap.org/) web services,
    already used in the first recipe, to calculate the weather for a PostGIS geometry
    from within a PostgreSQL function.
  prefs: []
  type: TYPE_NORMAL
- en: In the fourth recipe, you will create two PL/pgSQL PostGIS functions that will
    let you perform geocoding and reverse geocoding using the GeoNames datasets.
  prefs: []
  type: TYPE_NORMAL
- en: After this, there is a recipe in which you will use the `OpenStreetMap` street
    datasets imported in PostGIS to implement a very basic Python class in order to
    provide a geocode implementation to the class's consumer using PostGIS trigram
    support.
  prefs: []
  type: TYPE_NORMAL
- en: The sixth recipe will show you how to create a PL/Python function using the
    geopy library to geocode addresses using a web geocoding API such as Google Maps,
    Yahoo! Maps, Geocoder, GeoNames, and others.
  prefs: []
  type: TYPE_NORMAL
- en: In the last recipe of this chapter, you will create a Python script to import
    data from the `netCDF` format to PostGIS using the GDAL Python bindings.
  prefs: []
  type: TYPE_NORMAL
- en: Let's see some notes before starting with the recipes in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you are using Linux or macOS, follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a Python `virtualenv` ([http://www.virtualenv.org/en/latest/](http://www.virtualenv.org/en/latest/))
    to keep a Python-isolated environment to be used for all the Python recipes in
    this book and activate it. Create it in a central directory, as you will need
    to use it for most of the Python recipes in this book:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Once activated, you can install the Python libraries you will need for the
    recipes in this chapter:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'If you are new to the virtual environment and you are wondering where the libraries
    have been installed, you should find everything in the `virtualenv` directory
    in our development box. You can find the libraries using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: If you are wondering what is going on with the previous command lines, then
    `virtualenv` is a tool that will be used to create isolated Python environments,
    and you can find more information about this tool at [http://www.virtualenv.org](http://www.virtualenv.org),
    while `pip` ([http://www.pip-installer.org](http://www.pip-installer.org)) is
    a package management system used to install and manage software packages written
    in Python.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you are using Windows, follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: The easiest way to get Python and all the libraries needed for the recipes in
    this chapter is to use **OSGeo4W**, a popular binary distribution of open source
    geospatial software for Windows. You can download it from [http://trac.osgeo.org/osgeo4w/](http://trac.osgeo.org/osgeo4w/).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In our Windows box the OSGeo4W shell, at the time of writing this book comes
    with Python 2.7, GDAL 2.2 Python bindings, simplejson, psycopg2, and numpy. You
    will only need to install geopy.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The easiest way to install geopy and to eventually add more Python libraries
    to the OSGeo4W shell is to install `setuptools` and `pip` by following the instructions
    found at [http://www.pip-installer.org/en/latest/installing.html](http://www.pip-installer.org/en/latest/installing.html).
    Open the OSGeo4W shell and just enter the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Writing PostGIS vector data with Psycopg
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, you will use Python combined with Psycopg, the most popular
    PostgreSQL database library for Python, in order to write some data to PostGIS
    using the SQL language.
  prefs: []
  type: TYPE_NORMAL
- en: You will write a procedure to import weather data for the most populated US
    cities. You will import such weather data from [http://www.openweatherdata.org/](http://www.openweatherdata.org/),
    which is a web service that provides free weather data and a forecast API. The
    procedure you are going to write will iterate each major USA city and get the
    actual temperature for it from the closest weather stations using the [http://www.openweatherdata.org/](http://www.openweatherdata.org/)
    web service API, getting the output in JSON format. (In case you are new to the
    JSON format, you can find details about it at [http://www.json.org/](http://www.json.org/).)
  prefs: []
  type: TYPE_NORMAL
- en: You will also generate a new PostGIS layer with the 10 closest weather stations
    to each city.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Create a database schema for the recipes in this chapter using the following
    command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Download the USA cities'' shapefile from the [https://nationalmap.gov/](https://nationalmap.gov/)
    website at [http://dds.cr.usgs.gov/pub/data/nationalatlas/citiesx020_nt00007.tar.gz](http://dds.cr.usgs.gov/pub/data/nationalatlas/citiesx020_nt00007.tar.gz)
    (this archive is also included in the book''s dataset that is available with the
    code bundle), extract it to `working/chp08`, and import it in PostGIS, filtering
    out cities with less than 100,000 inhabitants:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Add a `real` field to store the temperature for each city using the following
    command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'If you are on Linux, ensure that you follow the initial instructions in this
    chapter and create a Python virtual environment in order to keep a Python-isolated
    environment to be used for all the Python recipes in this book. Then, activate
    it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Carry out the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create the following table to host weather stations'' data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Create an account at [https://openweathermap.org](https://openweathermap.org)
    to get an API key. Then, check the JSON response for the web service you are going
    to use. If you want the 10 closest weather stations from a point (the city centroid),
    the request you need to run is as follows (test it in a browser): [http://api.openweathermap.org/data/2.5/find?lat=55&lon=37&cnt=10&appid=YOURKEY](http://api.openweathermap.org/data/2.5/find?lat=55&lon=37&cnt=10&appid=YOURKEY)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You should get the following JSON response (the closest 10 stations and their
    relative data are ordered by their distance from the point coordinates, which
    in this case are `lon=37` and `lat=55`):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, create the Python program that will provide the desired output and name
    it `get_weather_data.py`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the Python program:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Check the output of the Python program you just wrote. Open the two PostGIS
    layers, `cities` and `wstations`, with your favorite GIS desktop tool and investigate
    the results. The following screenshot shows how it looks in QGIS:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/d7c91e45-c87e-4835-9a31-c493c8b59bce.png)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Psycopg** is the most popular PostgreSQL adapter for Python, and it can be
    used to create Python scripts that send SQL commands to PostGIS. In this recipe,
    you created a Python script that queries weather data from the [https://openweathermap.org/](https://openweathermap.org/)
    web server using the popular **JSON** format to get the output data and then used
    that data to update two PostGIS layers.'
  prefs: []
  type: TYPE_NORMAL
- en: For one of the layers, `cities`, the weather data is used to update the `temperature`
    field using the temperature data of the weather station closest to the city. For
    this purpose, you used an `UPDATE SQL` command. The other layer, `wstations`,
    is updated every time a new weather station is identified from the weather data
    and inserted in the layer. In this case, you used an `INSERT SQL` statement.
  prefs: []
  type: TYPE_NORMAL
- en: This is a quick overview of the script's behavior (you can find more details
    in the comments within the Python code). In the beginning, a PostgreSQL connection
    is created using the Psycopg `connection` object. The `connection` object is created
    using the main connection parameters (`dbname`, `user`, and `password`, while
    default values for `server name` and `port` are not specified; instead, `localhost`
    and `5432` are used). The connection behavior is set to `auto commit` so that
    any SQL performed by Psycopg will be run immediately and will not be embedded
    in a transaction.
  prefs: []
  type: TYPE_NORMAL
- en: Using a cursor, you first iterate all of the records in the `cities` PostGIS
    layer; for each of the cities, you need to get the temperature from the [https://openweathermap.org/](https://openweathermap.org/)
    web server. For this purpose, for each city you make a call to the `GetWeatherData`
    method, passing the coordinates of the city to it. The method queries the server
    using the `requests` library and parses the JSON response using the `simplejson`
    Python library.
  prefs: []
  type: TYPE_NORMAL
- en: You should send the URL request to a `try...catch` block. This way, if there
    is any issue with the web service (internet connection not available, or any HTTP
    status codes different from 200, or whatever else), the process can safely continue
    with the data of the next city (iteration).
  prefs: []
  type: TYPE_NORMAL
- en: The JSON response contains, as per the request, the information about the 10
    weather stations closest to the city. You will use the information of the first
    weather station, the closest one to the city, to set the `temperature` field for
    the city.
  prefs: []
  type: TYPE_NORMAL
- en: You then iterate all of the `station` JSON objects, and by using the `AddWeatherStation`
    method, you create a weather station in the `wstation` PostGIS layer, but only
    if a weather station with the same `id` does not exist.
  prefs: []
  type: TYPE_NORMAL
- en: Writing PostGIS vector data with OGR Python bindings
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, you will use Python and the Python bindings of the GDAL/OGR
    library to create a script for geocoding a list of the names of places using one
    of the GeoNames web services ([http://www.geonames.org/export/ws-overview.html](http://www.geonames.org/export/ws-overview.html)).
    You will use the **Wikipedia Fulltext Search** web service ([http://www.geonames.org/export/wikipedia-webservice.html#wikipediaSearch](http://www.geonames.org/export/wikipedia-webservice.html#wikipediaSearch)),
    which for a given search string returns the coordinates of the places matching
    that search string as the output, and some other useful attributes from Wikipedia,
    including the Wikipedia `page title` and `url`.
  prefs: []
  type: TYPE_NORMAL
- en: The script should first create a PostGIS point layer named `wikiplaces` in which
    all of the locations and their attributes returned by the web service will be
    stored.
  prefs: []
  type: TYPE_NORMAL
- en: This recipe should give you the basis to use other similar web services, such
    as Google Maps, Yahoo! BOSS Geo Services, and so on, to get results in a similar
    way.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before you start, please note the terms of use of GeoNames: [http://www.geonames.org/export/](http://www.geonames.org/export/).
    In a few words, at the time of writing, you have a 30,000 credits'' daily limit
    per application (identified by the `username` parameter); the hourly limit is
    2,000 credits. A credit is a web service request hit for most services.'
  prefs: []
  type: TYPE_NORMAL
- en: You will generate the PostGIS table containing the geocoded place names using
    the GDAL/OGR Python bindings ([http://trac.osgeo.org/gdal/wiki/GdalOgrInPython](http://trac.osgeo.org/gdal/wiki/GdalOgrInPython)).
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To access GeoNames web services, you need to create a user at [http://www.geonames.org/login](http://www.geonames.org/login).
    The user we created for this recipe is `postgis`; you will need to change it with
    your username whenever you query the GeoNames web service URL.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If you are using Windows, be sure to have OSGeo4W installed as suggested in
    the initial instructions of this chapter.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'If you are using Linux, follow the initial instructions for this chapter, create
    a Python `virtualenv` in order to keep a Python-isolated environment to be used
    for all the Python recipes in this book, and activate it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Once activated, if you still haven''t done so, you have to install the `gdal`
    and `simplejson` Python packages needed for this recipe:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Carry out the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: First, test the web services and their JSON output yourself with the following
    request (change the `q` and `username` parameters as you wish): [http://api.geonames.org/wikipediaSearchJSON?formatted=true&q=london&maxRows=10&username=postgis&style=full](http://api.geonames.org/wikipediaSearchJSON?formatted=true&q=london&maxRows=10&username=postgis&style=full).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You should get the following JSON output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: As you can see from the JSON output for the GeoNames web service, for a given
    query string (a location name), you get a list of Wikipedia pages related to that
    location in JSON format. For each JSON object representing a Wikipedia page, you
    can get access to the attributes, such as the `page title`, `summary`, `url`,
    and the `coordinates` of the location.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now, create a text file named `working/chp08/names.txt` with the names of places
    you would like to geocode from the Wikipedia Fulltext Search web services. Add
    some place names, for example (in Windows, use a text editor such as Notepad):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, create a file named `import_places.py` under `working/chp08/` and add
    to it the Python script for this recipe. The following is how the script should
    look (you should be able to follow it by reading the inline comments and the *How
    it works...* section):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, execute the Python script:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/e839b9f9-2cfe-4277-98de-15c07c383925.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Test whether the table was correctly created and populated using SQL and use
    your favorite GIS desktop tool to display the layer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/139bfbcb-f27b-4e99-b0d5-d99f60ee79b7.png)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This Python script uses the `requests` and `simplejson` libraries to fetch data
    from the GeoNames `wikipediaSearchJSON` web service, and the GDAL/OGR library
    to store geographic information inside the PostGIS database.
  prefs: []
  type: TYPE_NORMAL
- en: First, you create a PostGIS point table to store the geographic data. This is
    made using the GDAL/OGR bindings. You need to instantiate an OGR PostGIS driver
    ([http://www.gdal.org/drv_pg.html](http://www.gdal.org/drv_pg.html)) from where
    it is possible to instantiate a dataset to connect to your `postgis_cookbook`
    database using a specified connection string.
  prefs: []
  type: TYPE_NORMAL
- en: The `update` parameter in the connection string specifies to the GDAL driver
    that you will open the dataset for updating.
  prefs: []
  type: TYPE_NORMAL
- en: From the PostGIS dataset, we created a PostGIS layer named `wikiplaces` that
    will store points (`geom_type=ogr.wkbPoint`) using the *WGS 84* spatial reference
    system (`srs.ImportFromEPSG(4326)`). When creating the layer, we specified other
    parameters as well, such as `dimension` (`3`, as you want to store the `z` values),
    `GEOMETRY_NAME` (name of the geometric field), and `schema`. After creating the
    layer, you can use the `CreateField` layer method to create all the fields that
    are needed to store the information. Each field will have a specific `name` and
    `datatype` (all of them are `ogr.OFTString` in this case).
  prefs: []
  type: TYPE_NORMAL
- en: After the layer has been created (note that we need to have the `pg_ds` and
    `pg_layer` objects always in context for the whole script, as noted at [http://trac.osgeo.org/gdal/wiki/PythonGotchas](http://trac.osgeo.org/gdal/wiki/PythonGotchas)),
    you can query the GeoNames web services for each place name in the `names.txt`
    file using the `urllib2` library.
  prefs: []
  type: TYPE_NORMAL
- en: We parsed the JSON response using the `simplejson` library, then iterated the
    JSON objects list and added a feature to the PostGIS layer for each of the objects
    in the JSON output. For each element, we created a feature with a point `wkt`
    geometry (using the `lng`, `lat`, and `elevation` object attributes) using the
    `ogr.CreateGeometryFromWkt` method, and updated the other fields using the other
    object attributes returned by GeoNames, using the feature `setField` method (`title`,
    `countryCode`, and so on).
  prefs: []
  type: TYPE_NORMAL
- en: 'You can get more information on programming with GDAL Python bindings by using
    the following great resource by *Chris Garrard*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.manning.com/books/geoprocessing-with-python](https://www.manning.com/books/geoprocessing-with-python)'
  prefs: []
  type: TYPE_NORMAL
- en: Writing PostGIS functions with PL/Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, you will write a Python function for PostGIS using the PL/Python
    language. The PL/Python procedural language allows you to write PostgreSQL functions
    with the Python language.
  prefs: []
  type: TYPE_NORMAL
- en: You will use Python to query the [http://openweathermap.org/](http://openweathermap.org/) web
    services, already used in a previous recipe, to get the weather for a PostGIS
    geometry from within a PostgreSQL function.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Verify your PostgreSQL server installation has PL/Python support. In Windows,
    this should be already included, but this is not the default if you are using,
    for example, Ubuntu 16.04 LTS, so you will most likely need to install it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Install PL/Python on the database (you could consider installing it in your
    `template1` database; in this way, every newly created database will have PL/Python
    support by default):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You could alternatively add PL/Python support to your database, using the `createlang`
    shell command (this is the only way if you are using PostgreSQL version 9.1 or
    lower):'
  prefs: []
  type: TYPE_NORMAL
- en: '`$ createlang plpythonu postgis_cookbook`'
  prefs: []
  type: TYPE_NORMAL
- en: '`$ psql -U me postgis_cookbook`'
  prefs: []
  type: TYPE_NORMAL
- en: '`postgis_cookbook=# CREATE EXTENSION plpythonu;`'
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Carry out the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, as with the previous one, you will use a [http://openweathermap.org/](http://openweathermap.org/)
    web service to get the temperature for a point from the closest weather station.
    The request you need to run (test it in a browser) is [http://api.openweathermap.org/data/2.5/find?lat=55&lon=37&cnt=10&appid=YOURKEY](http://api.openweathermap.org/data/2.5/find?lat=55&lon=37&cnt=10&appid=YOURKEY).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You should get the following JSON output (the closest weather station''s data
    from which you will read the temperature to the point, with the coordinates of
    the given longitude and latitude):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Create the following PostgreSQL function in Python, using the PL/Python language:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, test your function; for example, get the temperature from the weather
    station closest to Wat Pho Templum in Bangkok:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'If you want to get the temperature for the point features in a PostGIS table,
    you can use the coordinates of each feature''s geometry:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Now it would be nice if our function could accept not only the coordinates
    of a point, but also a true PostGIS geometry as well as an input parameter. For
    the temperature of a feature, you could return the temperature of the weather
    station closest to the centroid of the feature geometry. You can easily get this
    behavior using function overloading. Add a new function, with the same name, supporting
    a PostGIS geometry directly as an input parameter. In the body of the function,
    call the previous function, passing the coordinates of the centroid of the geometry.
    Note that in this case, you can write the function without using Python, with
    the PL/PostgreSQL language:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, test the function, passing a PostGIS geometry to the function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'If you use the function on a PostGIS layer, you can pass the feature''s geometries
    to the function directly, using the overloaded function written in the PL/PostgreSQL
    language:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, you wrote a Python function in PostGIS, using the PL/Python
    language. Using Python inside PostgreSQL and PostGIS functions gives you the great
    advantage of being able to use any Python library you wish. Therefore, you will
    be able to write much more powerful functions compared to those written using
    the standard PL/PostgreSQL language.
  prefs: []
  type: TYPE_NORMAL
- en: In fact, in this case, you used the `urllib2` and `simplejson` Python libraries
    to query a web service from within a PostgreSQL function—this would be an impossible
    operation to do using plain PL/PostgreSQL. You have also seen how to overload
    functions in order to provide the function's user a different way to access the
    function, using input parameters in a different way.
  prefs: []
  type: TYPE_NORMAL
- en: Geocoding and reverse geocoding using the GeoNames datasets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, you will write two PL/PostgreSQL PostGIS functions that will
    let you perform geocoding and reverse geocoding using the GeoNames datasets.
  prefs: []
  type: TYPE_NORMAL
- en: GeoNames is a database of place names in the world, containing over 8 million
    records that are available for download free of charge. For the purpose of this
    recipe, you will download a part of the database, load it in PostGIS, and then
    use it within two functions to perform geocoding and reverse geocoding. **Geocoding**
    is the process of finding coordinates from geographical data, such as an address
    or a place name, while **reverse geocoding** is the process of finding geographical
    data, such as an address or place name, from its coordinates.
  prefs: []
  type: TYPE_NORMAL
- en: You are going to write the two functions using PL/pgSQL, which adds on top of
    the PostgreSQL SQL commands the ability to tie more commands and queries together,
    a bunch of control structures, cursors, error management, and other goodness.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Download a GeoNames dataset. At the time of writing, you can find some of the
    datasets ready to be downloaded from [http://download.geonames.org/export/dump/](http://download.geonames.org/export/dump/).
    You may decide which dataset you want to use; if you want to follow this recipe,
    it will be enough to download the Italian dataset, `IT.zip` (included in the book's
    dataset, in the `chp08` directory).
  prefs: []
  type: TYPE_NORMAL
- en: If you want to download the full GeoNames dataset, you need to download the
    `allCountries.zip` file; it will take longer as it is about 250 MB.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Carry out the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Unzip the `IT.zip` file to the `working/chp08` directory. Two files will be
    extracted: the `readme.txt` file that contains information on the GeoNames database
    structure—you can read it to get some more information—and the `IT.txt` file,
    which is a `.csv` file containing all the GeoNames entities for Italy. As suggested
    in the `readme.txt` file, the content of the CSV file is composed of records with
    the following attributes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Get an overview of this CSV dataset, using `ogrinfo`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/37ab3ab7-3de1-4e6a-8766-fe4fe01b6e85.png)'
  prefs: []
  type: TYPE_IMG
- en: 'You could query the `IT.txt` file as an OGR entity. For example, analyze one
    of the dataset features, as shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/d93ac89a-d5aa-40dd-a285-10dc580af64a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'For your purpose, you just need the `name`, `asciiname`, `latitude`, and `longitude`
    attributes. You will import the file to PostGIS using the CSV OGR driver ([http://www.gdal.org/drv_csv.html](http://www.gdal.org/drv_csv.html)).
    Use the `ogr2ogr` command to import this GeoNames dataset in PostGIS:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Try to query the new `geonames` table in PostGIS to see if the process works
    correctly:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, create a PL/PostgreSQL function that will return the five place names
    closest to the given point and their coordinates (reverse geocoding):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Query the new function. You can specify the number of results you want by passing
    the optional `num_results` input parameter:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the output for this query:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d3aadd6e-c073-40b7-97f5-6af6abf6c0a9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'If you don''t specify the `num``_results` optional parameter, it will default
    to five results:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'And you will get the following rows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/885f1bfc-c639-4bc3-b80e-820ac913d97e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, create a PL/pgSQL function that will return a list of place names and
    geometries containing a text search in their name field (geocoding):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Query this second function to check if it is working properly:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/2c7d1318-9afa-40bf-953b-9ba113f1b229.png)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, you wrote two PostgreSQL functions to perform geocoding and
    reverse geocoding. For both the functions, you defined a set of input and output
    parameters, and after some PL/PostgreSQL processing, you returned a set of records
    to the function client, given by executing a query.
  prefs: []
  type: TYPE_NORMAL
- en: As the input parameters, the `Get_Closest_PlaceNames` function accepts a PostGIS
    geometry and an optional `num_results` parameter that is set to a default of 5
    in case the function caller does not provide it. The output of this function is
    `SETOF RECORD`, which is returned after running a query in the function body (defined
    by the `$$` notation). Here, the query finds the places closest to the centroid
    of the input geometry. This is done using an indexed nearest neighbor search (KNN
    index), a new feature available in PostGIS 2.
  prefs: []
  type: TYPE_NORMAL
- en: The `Find_PlaceNames` function accepts as the input parameters a search string
    to look for and an optional `num_results` parameter, which in this case is also
    set to a default of `5` if not provided by the function caller. The output is
    a `SETOF RECORD`, which is returned after running a query that uses the `to_tsquery`
    PostgreSQL text search function. The results of the query are the places from
    the database that contain the `search_string` value in the name field.
  prefs: []
  type: TYPE_NORMAL
- en: Geocoding using the OSM datasets with trigrams
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this recipe, you will use **OpenStreetMap** streets'' datasets imported
    in PostGIS to implement a very basic Python class in order to provide geocoding
    features to the class'' consumer. The geocode engine will be based on the implementation
    of the PostgreSQL trigrams provided by the `contrib` module of PostgreSQL: `pg_trgm`.'
  prefs: []
  type: TYPE_NORMAL
- en: A trigram is a group of three consecutive characters contained in a string,
    and it is a very effective way to measure the similarity of two strings by counting
    the number of trigrams they have in common.
  prefs: []
  type: TYPE_NORMAL
- en: This recipe aims to be a very basic sample to implement some kinds of geocoding
    functionalities (it will just return one or more points from a street name), but
    it could be extended to support more advanced features.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For this recipe, make sure you have the latest GDAL, at least version 1.10,
    as you will use it with the `ogr2ogr` the OGR OSM driver ([http://www.gdal.org/drv_osm.html](http://www.gdal.org/drv_osm.html)):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'As you will use PostgreSQL trigrams, install the PostgreSQL `contrib` package
    (which includes `pg_trgm`). The Windows EDB installer should already include this.
    In an Ubuntu 12.4 box, the following command will help you to do it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Make sure to add the `pg_trgm` extension to the database:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: You will need to use some OSM datasets included in the source for this chapter.
    (in the `data/chp08` book's dataset directory). If you are using Windows, be sure
    to have installed the OSGeo4W suite, as suggested in the initial instructions
    for this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you are using Linux, follow the initial instructions for this chapter and
    create a Python virtual environment in order to keep a Python-isolated environment
    to be used for all the Python recipes of this book. Then, activate it as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the environment has been activated, if you still haven''t done so, you
    can install the Python packages needed for this recipe:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Carry out the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, check out how the OSM `.pbf` file is built using `ogrinfo`. PBF is a
    binary format intended as an alternative to the OSM XML format, mainly because
    it is much smaller. As you must have noticed, it is composed of several layers—you
    will export the `lines` layer to PostGIS as that layer contains the street names
    that you will use for the overall geocoding process:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Export the lines'' OSM features to a PostGIS table, using `ogr2ogr` (`ogr2ogr`,
    as always, will implicitly create the GiST index that is needed by the `pg_trgm`
    module to run):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Now try a trigram matching to identify the road names similar to a given search
    text, using a query such as the following. Note that the `similarity` function
    returns a value that decreases from `1` to `0` as the similarity of the word decreases
    (with `1`, the strings are identical; with `0`, they are totally different):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/e54ab1a5-61ee-44b3-b120-653b6206aaa8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'As a variant, you will use the following query to complete the recipe (in this
    case, when the weight is 0, the strings are identical):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/6075ff38-c013-4785-9269-c431ec2e6447.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We will use the last query as the SQL core of a Python class, which will provide
    geocoding features to the consumer, using the layer we just imported in PostGIS
    (`chp08.osm_roads`). First, create a file named `osmgeocoder.py` and add the following
    class to it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, add the `__main__` check to provide the class user a method to directly
    use the geocoder from the command line:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Now you can test the class by calling the script, as shown here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'So, now that you wrote a class that can be used to geocode street names, let''s
    suppose that another user wants to use it to geocode a file with a list of street
    names in order to import it in a new PostGIS layer. Here is how the user could
    do this (try this as well). First, create a `streets.txt` file with a list of
    street names; for example:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, create a file named `geocode_streets.py` and add this Python code to it
    (you are going to use the `OSMGeocoder` class to geocode the street name list,
    and GDAL/OGR to create a new PostGIS layer for storing the geocoded points for
    the street names):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the preceding script, and then check with your favorite PostgreSQL client
    or with a GIS desktop tool if the points for the street names were correctly geocoded:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For this recipe, you first imported an OSM dataset to PostGIS with `ogr2ogr`,
    using the GDAL OSM driver.
  prefs: []
  type: TYPE_NORMAL
- en: Then, you created a Python class, `OSMGeocoder`, to provide very basic support
    to the class consumer for geocoding street names, using the OSM data imported
    in PostGIS. For this purpose, you used the trigram support included in PostgreSQL
    with the `pg_trgm contrib` module.
  prefs: []
  type: TYPE_NORMAL
- en: 'The class that you have written is mainly composed of two methods: the `__init__`
    method, where the connection parameters must be passed in order to instantiate
    an `OSMGeocoder` object, and the `geocode` method. The `geocode` method accepts
    an input parameter, `placename`, and creates a connection to the PostGIS database
    using the Psycopg2 library in order to execute a query to find the streets in
    the database with a name similar to the `placename` parameter.'
  prefs: []
  type: TYPE_NORMAL
- en: The class can be consumed both from the command line, using the `__name__ ==
    '__main__'` code block, or from an external Python code. You tried both approaches.
    In the latter, you created another Python script, where you imported the `OSMGeocoder`
    class combined with the GDAL/OGR Python bindings to generate a new PostGIS point
    layer with features resulted from a list of geocoded street names.
  prefs: []
  type: TYPE_NORMAL
- en: Geocoding with geopy and PL/Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, you will geocode addresses using web geocoding APIs, such as
    Google Maps, Yahoo! Maps, Geocoder, GeoNames, and so on. Be sure to read the terms
    of service of these APIs carefully before using them in production.
  prefs: []
  type: TYPE_NORMAL
- en: The `geopy` Python library ([https://github.com/geopy/geopy](https://github.com/geopy/geopy))
    offers convenient uniform access to all of these web services. Therefore, you
    will use it to create a PL/Python PostgreSQL function that can be used in your
    SQL commands to query all of these engines.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Install `geopy` globally. (You cannot use a virtual environment in this case,
    as the user running the PostgreSQL service needs to access it on its Python path.)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In a Debian/Ubuntu box, it is as easy as typing the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'In Windows, you can use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'If you still have not used PL/Python, verify whether your PostgreSQL server
    installation supports it. The Windows EDB installer should already include support,
    but this is not the default if you are using, for example, Ubuntu 16.04 LTS, so
    you most likely need to install it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'Install PL/Python in the database (you could consider installing it in the
    `template1` database; this way, every newly created database will have PL/Python
    support by default):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'Alternatively, you could add PL/Python support to your database, using the `createlang` shell
    command (this is the only way if you are using PostgreSQL Version 9.1 and lower):'
  prefs: []
  type: TYPE_NORMAL
- en: '`$ createlang plpythonu postgis_cookbook`'
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Carry out the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'As the first test, open your favorite SQL client (`psql` or `pgAdmin`), and
    write a very basic PL/Python function, just using the GoogleV3 geocoding API with
    `geopy`. The function will accept the address string as an input parameter and,
    after importing `geopy`, it will instantiate a `geopy` Google Geocoder, run the
    geocode process, and then return the point geometry, using the `ST_GeomFromText`
    function and the `geopy` output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'After creating the function, try to test it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, you will make the function a little bit more sophisticated. First, you
    will add another input parameter to let the user specify the geocode API engine
    (defaulting to GoogleV3). Then, using the Python `try...except` block, you will
    try to add some kind of error management in case the geopy Geocoder cannot manage
    to return valid results for any reason:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'Test the new version of your function without specifying the parameter for
    the API. In such a case, it should default to the Google API:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'If you test it by specifying a different API, it should return the result processed
    for the given API. For example:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: As a bonus step, create a table in PostgreSQL with street addresses, and generate
    a new point PostGIS layer storing the geocoded points returned by the Geocode
    function.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You wrote a PL/Python function to geocode an address. For this purpose, you
    used the `geopy` Python library, which lets you query several geocoding APIs in
    the same manner.
  prefs: []
  type: TYPE_NORMAL
- en: Using geopy, you need to instantiate a `geocoder` object with a given API and
    query it to get the results, such as a place name and a couple of coordinates.
    You can use the `plpy` module utilities to run a query on the database using the
    PostGIS `ST_GeomFromText` function, and log informative messages and warnings
    for the user.
  prefs: []
  type: TYPE_NORMAL
- en: If the geocoding process fails, you return a `NULL` geometry to the user with
    a warning message, using a `try..except` Python block.
  prefs: []
  type: TYPE_NORMAL
- en: Importing NetCDF datasets with Python and GDAL
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, you will write a Python script to import data from the NetCDF
    format to PostGIS.
  prefs: []
  type: TYPE_NORMAL
- en: NetCDF is an open standard format, widely used for scientific applications,
    and can contain multiple raster datasets, each composed of a spectrum of bands.
    For this purpose, you will use the GDAL Python bindings and the popular NumPy
    ([http://www.numpy.org/](http://www.numpy.org/)) scientific library.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you are using Windows, be sure to install OSGeo4W, as suggested in the initial
    instructions for this chapter. This will include Python and GDAL Python bindings
    with NumPy support.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For Linux users, in case you did not do it yet, follow the initial instructions
    for this chapter and create a Python virtual environment in order to keep a Python-isolated
    environment to be used for all the Python recipes in this book. Then, activate
    it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'For this recipe, you need the GDAL Python bindings and NumPy, the latter being
    needed by a GDAL method (`ReadAsArray`) for arrays. In the most likely case, you
    have already installed GDAL in your virtual environment as you have been using
    it for other recipes, so be sure to remove it and reinstall it after installing
    NumPy. In fact, GDAL needs to be compiled with NumPy support if you want to use
    its array''s features:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: For the purpose of this recipe, you will use a sample dataset from NOAA **Earth
    System Research Laboratory** (**ESRL**). The excellent ESRL web portal offers
    a plethora of data in the NetCDF format to be freely downloaded. For example,
    download the following dataset from the ESRL CPC Soil Moisture data repository
    (you can find, as usual, a copy of this dataset in the book's dataset directory
    for this chapter): [https://www.esrl.noaa.gov/psd/data/gridded/data.cpcsoil.html](https://www.esrl.noaa.gov/psd/data/gridded/data.cpcsoil.html).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Carry out the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'As the first step, investigate the NetCDF format of the dataset you downloaded
    using `gdalinfo`. This kind of dataset is composed of several subdatasets, as
    you may have realized by looking at the `gdalinfo` output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/595b0036-e52e-4066-bd6b-84032572cfb1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Use `gdalinfo` to investigate one of the file''s subdatasets. The syntax that
    the NetCDF GDAL driver ([http://www.gdal.org/frmt_netcdf.html](http://www.gdal.org/frmt_netcdf.html))
    uses is to append a colon followed by the variable name at the end of the filename.
    For example, try to figure out how many bands the `soilw` subdataset is composed
    of. This subdataset, representing `lwe_thickness_of_soil_moisture_content`, is
    composed of 12 bands. Each band, according to the information derived by its metadata,
    represents the CPC Monthly Soil Moisture for a given month. The month is identified
    by the `NETCDF_DIM_time` metadata value, which is the number of days from the
    beginning of the year (`0` for January, `31` for February, `59` for March, and
    so on):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/91f75db2-f04e-488e-927f-034fcabc25f8.png)'''
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'What you are going to do is create a Python script using GDAL and NumPy. You
    will read a given NetCDF dataset, iterate its subdatasets, and then iterate each
    subdataset''s bands. For each subdataset, you will create a point PostGIS layer,
    and you will add a field for each band in order to store the band values in the
    layer table. Then, you will iterate the band''s cells, and for each cell, you
    will add a point in the layer with the corresponding band''s values. Therefore,
    create a `netcdf2postgis.py` file and add the following Python code to it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'To run the `netcdf2postgis` method from the command line, add the entry point
    for the script. The code will check whether the script user is correctly using
    the three required parameters, which are the NetCDF file path, the GDAL PostGIS
    connection string, and a prefix/suffix to use for table names in PostGIS:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the script. Be sure to use the correct NetCDF file path, GDAL PostGIS connection
    string (check the format at [http://www.gdal.org/drv_pg.html](http://www.gdal.org/drv_pg.html)),
    and a table prefix that has to be appended to the table names for tables that
    will be created in PostGIS:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'At the end of the process, check the results by opening one of the output PostGIS
    tables using your favorite GIS desktop tool. The following screenshot shows how
    it looks in the QGIS `soilw` layer with the original NetCDF dataset behind it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/c91741bf-91cd-4ad3-8fac-98b45e2400ee.png)'
  prefs: []
  type: TYPE_IMG
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You have used Python with GDAL and NumPy in order to create a command-line utility
    to import a NetCDF dataset into PostGIS.
  prefs: []
  type: TYPE_NORMAL
- en: A NetCDF dataset is composed of multiple subdatasets, and each subdataset is
    composed of multiple raster bands. Each band is composed of cells. This structure
    should be clear to you after investigating a sample NetCDF dataset using the `gdalinfo`
    GDAL command tool.
  prefs: []
  type: TYPE_NORMAL
- en: There are several approaches to exporting cell values to PostGIS. The approach
    you adopted here is to generate a PostGIS point layer for each subdataset, which
    is composed of one field for each subdataset band. You then iterated the raster
    cells and appended a point to the PostGIS layer with the values read from each
    cell band.
  prefs: []
  type: TYPE_NORMAL
- en: The way you do this with Python is by using the GDAL Python bindings. For reading,
    you open the NetCDF dataset, and for updating, you open the PostGIS database,
    using the correct GDAL and OGR drivers. Then, you iterate the NetCDF subdatasets,
    using the `GetSubDatasets` method, and create a PostGIS table named `NetCDF subdataset
    variable` (with the prefix) for each subdataset, using the `CreateLayer` method.
  prefs: []
  type: TYPE_NORMAL
- en: For each subdataset, you iterate its bands, using the `GetRasterBand` method.
    To read each band, you run the `ReadAsArray` method which uses NumPy to get the
    band as an array.
  prefs: []
  type: TYPE_NORMAL
- en: For each band, you create a field in the PostGIS layer with the correct field
    data type that will be able to store the band's values. To choose the correct
    data type, you investigate the band's data type, using the `DataType` property.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, you iterate the raster cells, by reading the correct *x* and *y* coordinates
    using the subdataset transform parameters, available via the `GetGeoTransform`
    method. For each cell, you create a point with the `CreateGeometryFromWkt` method,
    then set the field values, and read from the band array using the `SetField` feature
    method.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, you append the new point to the PostGIS layer using the `CreateFeature`
    method.
  prefs: []
  type: TYPE_NORMAL
