- en: Chapter 8. TensorFrames
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第8章。TensorFrames
- en: This chapter will provide a high-level primer on the burgeoning field of Deep
    Learning and the reasons why it is important. It will provide the fundamentals
    surrounding feature learning and neural networks required for deep learning. As
    well, this chapter will provide a quick start for TensorFrames for Apache Spark.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将提供一个关于新兴领域深度学习及其重要性的高级入门，它将提供围绕特征学习和神经网络的基本原理，这些是深度学习所必需的。此外，本章还将为Apache
    Spark的TensorFrames提供快速入门。
- en: 'In this chapter, you will learn about:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将学习关于：
- en: What is Deep Learning?
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是深度学习？
- en: A primer on feature learning
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征学习入门
- en: What is feature engineering?
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是特征工程？
- en: What is TensorFlow?
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是TensorFlow？
- en: Introducing TensorFrames
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍TensorFrames
- en: TensorFrames – quick start
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFrames – 快速入门
- en: As you can see in the preceding breakdown, we will be initially discussing deep
    learning – more specifically we will start with neural networks.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们将首先讨论深度学习——更具体地说，我们将从神经网络开始。
- en: What is Deep Learning?
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是深度学习？
- en: Deep Learning is part of a family of machine learning techniques based on *learning*
    representations of data. Deep Learning is loosely based on our brain's own neural
    networks, the purpose of this structure is to provide a large number of highly
    interconnected elements (in biological systems, this would be the neurons in our
    brains); there are approximately 100 billion neurons in our brain, each connected
    to approximately 10,000 other neurons, resulting in a mind-boggling 1015 synaptic
    connections. These elements work together to solve problems through learning processes
    – examples include pattern recognition and data classification.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习是机器学习技术家族的一部分，它基于*学习*数据表示。深度学习松散地基于我们大脑自己的神经网络，这个结构的目的在于提供大量高度相互连接的元素（在生物系统中，这将是我们的大脑中的神经元）；我们的大脑中大约有1000亿个神经元，每个神经元连接到大约10000个其他神经元，从而产生了令人难以置信的10^15个突触连接。这些元素通过学习过程共同解决问题——例如模式识别和数据分类。
- en: 'Learning within this architecture involves modifications of the connections
    between the interconnected elements similar to how our own brains make adjustments
    to the synaptic connections between neurons:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个架构中学习涉及对相互连接的元素之间连接的修改，类似于我们自己的大脑如何调整神经元之间的突触连接：
- en: '![What is Deep Learning?](img/B05793_08_01.jpg)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![什么是深度学习？](img/B05793_08_01.jpg)'
- en: 'Source: *Wikimedia Commons: File: Réseau de neurones.jpg*; [https://commons.wikimedia.org/wiki/File:Réseau_de_neurones.jpg](https://commons.wikimedia.org/wiki/File:R%C3%A9seau_de_neurones.jpg).'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：*维基媒体共享资源：文件：神经元网络.jpg*；[https://commons.wikimedia.org/wiki/File:Réseau_de_neurones.jpg](https://commons.wikimedia.org/wiki/File:R%C3%A9seau_de_neurones.jpg)。
- en: The traditional algorithmic approach involves programming known steps or quantities,
    that is, you already know the steps to solve a specific problem, now repeat the
    solution and make it run faster. Neural networks are an interesting paradigm because
    neural networks learn by example and are not actually programmed to perform a
    specific task per se. This makes the training process in neural networks (and
    Deep Learning) very important in that you must provide good examples for the neural
    network to learn from otherwise it will "learn" the wrong thing (that is, provide
    unpredictable results).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的算法方法涉及编程已知的步骤或数量，也就是说，你已经知道解决特定问题的步骤，现在重复解决方案并使其运行更快。神经网络是一个有趣的范例，因为神经网络通过示例学习，实际上并没有被编程去执行特定的任务。这使得神经网络（和深度学习）的训练过程非常重要，你必须提供好的示例供神经网络学习，否则它将“学习”错误的东西（即提供不可预测的结果）。
- en: 'The most common approach to building an artificial neural network involves
    the creation of three layers: input, hidden, and outer; as noted in the following
    diagram:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 建立人工神经网络最常见的方法涉及创建三个层次：输入、隐藏和输出；如下面的图所示：
- en: '![What is Deep Learning?](img/B05793_08_02.jpg)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![什么是深度学习？](img/B05793_08_02.jpg)'
- en: 'Each layer is comprised of one or more nodes with connections (that is, flow
    of data) between each of these nodes, as noted in the preceding diagram. Input
    nodes are passive in that they receive data, but do not modify the information.
    The nodes in the hidden and output layers will actively modify the data. For example,
    the connections from the three nodes in the input layer to one of the nodes in
    the first hidden layer is noted in the following diagram:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 每一层由一个或多个节点组成，这些节点之间有连接（即数据流），正如前面图中所注明的。输入节点是被动接收数据，但不修改信息。隐藏层和输出层中的节点将积极修改数据。例如，从输入层中的三个节点到第一个隐藏层中的一个节点的连接在以下图中表示：
- en: '![What is Deep Learning?](img/B05793_08_03.jpg)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![什么是深度学习？](img/B05793_08_03.jpg)'
- en: 'Referring to a signal processing neural network example, each input (denoted
    as ![What is Deep Learning?](img/B05793_08_22.jpg)) has a weight applied to it
    (![What is Deep Learning?](img/B05793_08_23.jpg)), which produces a new value.
    In this case, one of the hidden nodes (![What is Deep Learning?](img/B05793_08_24.jpg))
    is the result of three modified input nodes:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 参考信号处理神经网络示例，每个输入（表示为![什么是深度学习？](img/B05793_08_22.jpg)）都应用了一个权重（表示为![什么是深度学习？](img/B05793_08_23.jpg)），这产生了新的值。在这种情况下，一个隐藏节点（表示为![什么是深度学习？](img/B05793_08_24.jpg)）是三个修改后的输入节点的结果：
- en: '![What is Deep Learning?](img/B05793_08_04.jpg)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![什么是深度学习？](img/B05793_08_04.jpg)'
- en: 'There is also a bias applied to the sum in a form of a constant that also gets
    adjusted during the training process. The sum (the *h* *1* in our example) passes
    through so-called activation function that determines the output of the neuron.
    Some examples of such activation functions are presented in the following image:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练过程中，还会应用一个偏差，以常数的形式调整总和。总和（在我们的例子中是*h* *1*）通过所谓的激活函数，该函数决定了神经元的输出。以下图像中展示了此类激活函数的一些示例：
- en: '![What is Deep Learning?](img/B05793_08_20.jpg)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![什么是深度学习？](img/B05793_08_20.jpg)'
- en: This process is repeated for each node in the hidden layers as well as the output
    layer. The output node is the accumulation of all the weights applied to the input
    values for every active layer node. The learning process is the result of many
    iterations running in parallel, applying and reapplying these weights (in this
    scenario).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 此过程在隐藏层以及输出层中的每个节点上都会重复进行。输出节点是所有应用于每个激活层节点的输入值的权重的累积。学习过程是许多并行运行的迭代的结果，应用并重新应用这些权重（在本场景中）。
- en: Neural networks appear in all the different sizes and shapes. The most popular
    are single- and multi-layer feedforward networks that resemble the one presented
    earlier; such structures (even with two layers and one neuron!) neuron in the
    output layer are capable of solving simple regression problems (such as linear
    and logistic) to highly complex regression and classification tasks (with many
    hidden layers and a number of neurons). Another type commonly used are self-organizing
    maps, sometimes referred to as Kohonen networks, due to Teuvo Kohonen, a Finnish
    researcher who first proposed such structures. The structures are trained *without-a-teacher*,
    that is, they do not require a target (an unsupervised learning paradigm). Such
    structures are used most commonly to solve clustering problems where the aim is
    to find an underlying pattern in the data.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络以各种大小和形状出现。最流行的是单层和多层前馈网络，类似于前面展示的结构；这种结构（即使只有两层和一个神经元！）在输出层中的神经元能够解决简单的回归问题（如线性回归和逻辑回归）到高度复杂的回归和分类任务（具有许多隐藏层和多个神经元）。另一种常用的类型是自组织图，有时也称为Kohonen网络，以芬兰研究者Teuvo
    Kohonen的名字命名，他首先提出了这种结构。这些结构是在没有教师的情况下进行训练的，也就是说，它们不需要目标（一个无监督学习范式）。这种结构最常用于解决聚类问题，其目的是在数据中找到潜在的规律。
- en: Note
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'For more information about neural network types, we suggest checking this document:
    [http://www.ieee.cz/knihovna/Zhang/Zhang100-ch03.pdf](http://www.ieee.cz/knihovna/Zhang/Zhang100-ch03.pdf)'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 关于神经网络类型的更多信息，我们建议查看以下文档：[http://www.ieee.cz/knihovna/Zhang/Zhang100-ch03.pdf](http://www.ieee.cz/knihovna/Zhang/Zhang100-ch03.pdf)
- en: Note that there are many other interesting deep learning libraries in addition
    to TensorFlow; including, but not limited, to Theano, Torch, Caffe, Microsoft
    Cognitive Toolkit (CNTK), mxnet, and DL4J.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，除了TensorFlow之外，还有许多其他有趣的深度学习库；包括但不限于Theano、Torch、Caffe、Microsoft认知工具包（CNTK）、mxnet和DL4J。
- en: The need for neural networks and Deep Learning
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 神经网络和深度学习的需求
- en: There are many potential applications with neural networks (and Deep Learning).
    Some of the more popular ones include facial recognition, handwritten digit identification,
    game playing, speech recognition, language translation, and object classification.
    The key aspect here is that it involves learning and pattern recognition.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络（以及深度学习）有许多潜在的应用。其中一些更受欢迎的应用包括面部识别、手写数字识别、游戏、语音识别、语言翻译和物体分类。关键之处在于它涉及到学习和模式识别。
- en: 'While neural networks have been around for a long time (at least within the
    context of the history of computer science), they have become more popular now
    because of the overarching themes: advances and availability of distributed computing
    and advances in research:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管神经网络已经存在很长时间（至少在计算机科学的历史背景下），但它们现在变得更加流行，这得益于以下主题：分布式计算和研究的进步与可用性：
- en: '**Advances and availability of distributed computing and hardware**: Distributed
    computing frameworks such as Apache Spark allows you to complete more training
    iterations faster by being able to run more models in parallel to determine the
    optimal parameters for your machine learning models. With the prevalence of GPUs
    – graphic processing units that were originally designed for displaying graphics
    – these processors are adept at performing the resource intensive mathematical
    computations required for machine learning. Together with cloud computing, it
    becomes easier to harness the power of distributed computing and GPUs due to the
    lower up-front costs, minimal time to deployment, and easier to deploy elastic
    scale.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分布式计算和硬件的进步与可用性**：如Apache Spark这样的分布式计算框架允许你通过并行运行更多模型来更快地完成更多训练迭代，从而确定机器学习模型的最佳参数。随着GPU（最初设计用于显示图形的图形处理单元）的普及，这些处理器擅长执行机器学习所需的资源密集型数学计算。与云计算相结合，由于前期成本较低、部署时间短、易于弹性扩展，因此更容易利用分布式计算和GPU的力量。'
- en: '**Advances in deep learning research**: These hardware advances have helped
    return neural networks to the forefront of data sciences with projects such as
    TensorFlow as well as other popular ones such as Theano, Caffe, Torch, Microsoft
    Cognitive Toolkit (CNTK), mxnet, and DL4J.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**深度学习研究的进步**：这些硬件进步帮助神经网络重新回到了数据科学的前沿，例如TensorFlow以及其他流行的项目，如Theano、Caffe、Torch、微软认知工具包（CNTK）、mxnet和DL4J。'
- en: 'To dive deeper into these topics, two good references include:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 要深入了解这些主题，两个很好的参考资料包括：
- en: '*Lessons Learned from Deploying Deep Learning at Scale* ([http://blog.algorithmia.com/deploying-deep-learning-cloud-services/](http://blog.algorithmia.com/deploying-deep-learning-cloud-services/)):
    This blog post by the folks at Algorithmia discuss their learnings on deploying
    deep learning solutions at scale.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*从大规模部署深度学习中学到的经验* ([http://blog.algorithmia.com/deploying-deep-learning-cloud-services/](http://blog.algorithmia.com/deploying-deep-learning-cloud-services/)):
    这篇博客文章由Algorithmia团队撰写，讨论了他们在大规模部署深度学习解决方案中的经验。'
- en: '*Neural Networks by Christos Stergio and Dimitrios Siganos* ([http://bit.ly/2hNSWar](http://bit.ly/2hNSWar)):
    A great primer on neural networks.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*《神经网络》由Christos Stergio和Dimitrios Siganos编写* ([http://bit.ly/2hNSWar](http://bit.ly/2hNSWar))：这是一本关于神经网络的优秀入门书籍。'
- en: 'As noted previously, Deep Learning is part of a family of machine learning
    methods based on learning representations of data. In the case of learning representations,
    this can also be defined as *feature learning*. What makes Deep Learning so exciting
    is that it has the potential to replace or minimize the need for *manual* feature
    engineering. Deep Learning will allow the machine to not just learn a specific
    task, but also learn the *features* needed for that task. More succinctly, automating
    feature engineering or teaching machines *to learn how to learn* (a great reference
    on feature learning is Stanford''s Unsupervised Feature Learning and Deep Learning
    tutorial: [http://deeplearning.stanford.edu/tutorial/](http://deeplearning.stanford.edu/tutorial/)).'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，深度学习是机器学习方法家族的一部分，基于学习数据表示。在学习表示的情况下，这也可以定义为*特征学习*。使深度学习如此令人兴奋的是，它有潜力取代或最小化对*手动*特征工程的需求。深度学习将使机器不仅能够学习特定任务，还能够学习完成该任务所需的*特征*。更简洁地说，自动化特征工程或教会机器*如何学习学习*（关于特征学习的一个很好的参考资料是斯坦福大学的无监督特征学习和深度学习教程：[http://deeplearning.stanford.edu/tutorial/](http://deeplearning.stanford.edu/tutorial/)）。
- en: 'Breaking these concepts down to the fundamentals, let''s start with a *feature*.
    As observed in Christopher Bishop''s *Pattern Recognition and machine learning*
    (Berlin: Springer. ISBN 0-387-31073-8\. 2006) and as noted in the previous chapters
    on MLlib and ML, a feature is a measurable property of the phenomenon being observed.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 将这些概念分解到基础，让我们从*特征*开始。正如在Christopher Bishop的《模式识别与机器学习》（柏林：Springer. ISBN 0-387-31073-8\.
    2006）中观察到的那样，以及在MLlib和ML的前几章中提到的，特征是观察现象的可测量属性。
- en: 'If you are more familiar in the domain of statistics, a *feature* would be
    in reference to the independent variables (*x[1], x[2], …, x[n]*) within a stochastic
    linear regression model:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你更熟悉统计学领域，一个*特征*将指的是在随机线性回归模型中的独立变量（*x[1]，x[2]，…，x[n]*）：
- en: '![The need for neural networks and Deep Learning](img/B05793_08_05.jpg)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![神经网络和深度学习的必要性](img/B05793_08_05.jpg)'
- en: In this specific example, *y* is the dependent variable and *x* *i* are the
    independent variables.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个特定例子中，*y*是因变量，*x* *i*是自变量。
- en: 'Within the context of machine learning scenarios, examples of features include:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习场景的背景下，特征示例包括：
- en: '**Restaurant recommendations**: Features include the reviews, ratings, and
    other content and user profile attributes related to the restaurant. A good example
    of this model is the *Yelp Food Recommendation System*: [http://cs229.stanford.edu/proj2013/SawantPai-YelpFoodRecommendationSystem.pdf](http://cs229.stanford.edu/proj2013/SawantPai-YelpFoodRecommendationSystem.pdf)).'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**餐厅推荐**：特征包括评论、评分以及其他与餐厅相关的内容和用户个人资料属性。这个模型的一个好例子是*Yelp食品推荐系统*：[http://cs229.stanford.edu/proj2013/SawantPai-YelpFoodRecommendationSystem.pdf](http://cs229.stanford.edu/proj2013/SawantPai-YelpFoodRecommendationSystem.pdf)。'
- en: '**Handwritten Digit recognition**: Features include block wise histograms (count
    of pixels along 2D directions), holes, stroke detection, and so on. Examples include:'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**手写数字识别**：特征包括块状直方图（沿2D方向的像素计数）、空洞、笔画检测等。示例包括：'
- en: '*Handwritten Digit Classification*: [http://ttic.uchicago.edu/~smaji/projects/digits/](http://ttic.uchicago.edu/~smaji/projects/digits/)'
  id: totrans-45
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*手写数字分类*: [http://ttic.uchicago.edu/~smaji/projects/digits/](http://ttic.uchicago.edu/~smaji/projects/digits/)'
- en: '*Recognizing Handwritten Digits and Characters*: [http://cs231n.stanford.edu/reports/vishnu_final.pdf](http://cs231n.stanford.edu/reports/vishnu_final.pdf)'
  id: totrans-46
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*识别手写数字和字符*: [http://cs231n.stanford.edu/reports/vishnu_final.pdf](http://cs231n.stanford.edu/reports/vishnu_final.pdf)'
- en: '**Image Processing**: Features include the points, edges, and objects within
    the image; some good examples include:'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图像处理**：特征包括图像中的点、边缘和对象；一些好的例子包括：'
- en: 'Seminar: Feature extraction by André Aichert, [http://home.in.tum.de/~aichert/featurepres.pdf](http://home.in.tum.de/~aichert/featurepres.pdf)'
  id: totrans-48
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 研讨会：André Aichert的“特征提取”，[http://home.in.tum.de/~aichert/featurepres.pdf](http://home.in.tum.de/~aichert/featurepres.pdf)
- en: 'University of Washington Computer Science & Engineering CSE455: Computer Vision
    Lecture 6, [https://courses.cs.washington.edu/courses/cse455/09wi/Lects/lect6.pdf](https://courses.cs.washington.edu/courses/cse455/09wi/Lects/lect6.pdf)'
  id: totrans-49
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 华盛顿大学计算机科学与工程学院CSE455：计算机视觉讲座6，[https://courses.cs.washington.edu/courses/cse455/09wi/Lects/lect6.pdf](https://courses.cs.washington.edu/courses/cse455/09wi/Lects/lect6.pdf)
- en: Feature engineering is about determining which of these features (for example,
    in statistics, the independent variables) are important in defining the model
    that you are creating. Typically, it involves the process of using domain knowledge
    to create the features to allow the ML models to work.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 特征工程是确定这些特征（例如，在统计学中，独立变量）中哪些对于定义你正在创建的模型是重要的过程。通常，它涉及到使用领域知识来创建特征，以便ML模型能够工作。
- en: Coming up with features is difficult, time-consuming, requires expert knowledge.
  id: totrans-51
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 提出特征是困难的，耗时，需要专业知识。
- en: ''
  id: totrans-52
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '"Applied machine learning" is basically feature engineering.'
  id: totrans-53
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “应用机器学习”基本上是特征工程。
- en: ''
  id: totrans-54
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: —Andrew Ng, Machine Learning and AI via Brain simulations ([http://helper.ipam.ucla.edu/publications/gss2012/gss2012_10595.pdf](http://helper.ipam.ucla.edu/publications/gss2012/gss2012_10595.pdf))
  id: totrans-55
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: —Andrew Ng，《通过脑模拟进行机器学习和人工智能》([http://helper.ipam.ucla.edu/publications/gss2012/gss2012_10595.pdf](http://helper.ipam.ucla.edu/publications/gss2012/gss2012_10595.pdf))
- en: What is feature engineering?
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征工程是什么？
- en: 'Typically, performing feature engineering involves concepts such as feature
    selection (selecting a subset of the original feature set) or feature extraction
    (building a new set of features from the original feature set):'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，执行特征工程涉及诸如特征选择（选择原始特征集的子集）或特征提取（从原始特征集中构建新的特征集）等概念：
- en: In *feature selection*, based on domain knowledge, you can filter the variables
    that you think define the model (for example, predicting football scores based
    on number of turnovers). Often data analysis techniques such as regression and
    classification can also be used to help you determine this.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在*特征选择*中，基于领域知识，你可以过滤掉你认为定义模型的变量（例如，根据转换次数预测足球比分）。通常，数据分析技术如回归和分类也可以用来帮助你确定这一点。
- en: 'In *feature extraction*, the idea is to transform the data from a high dimensional
    space (that is, many different independent variables) to a smaller space of fewer
    dimensions. Continuing the football analogy, this would be the quarterback rating,
    which is based on several selected features (e.g. completions, touchdowns, interceptions,
    average gain per pass attempt, etc.). A common approach for feature extraction
    within the linear data transformation space is **principal component analysis**
    (**PCA**): [http://spark.apache.org/docs/latest/mllib-dimensionality-reduction.html#principal-component-analysis-pca](http://spark.apache.org/docs/latest/mllib-dimensionality-reduction.html#principal-component-analysis-pca).
    Other common mechanisms include:'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在*特征提取*中，想法是将数据从高维空间（即许多不同的独立变量）转换到更小的空间，维度更少。继续使用足球的比喻，这将类似于四分卫评分，它基于几个选定的特征（例如，完成率、达阵、拦截、每次传球尝试的平均增益等）。在线性数据转换空间内进行特征提取的常见方法之一是**主成分分析**（PCA）：[http://spark.apache.org/docs/latest/mllib-dimensionality-reduction.html#principal-component-analysis-pca](http://spark.apache.org/docs/latest/mllib-dimensionality-reduction.html#principal-component-analysis-pca)。其他常见机制包括：
- en: '*Nonlinear dimensionality reduction*: [https://en.wikipedia.org/wiki/Nonlinear_dimensionality_reduction](https://en.wikipedia.org/wiki/Nonlinear_dimensionality_reduction)'
  id: totrans-60
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*非线性降维*: [https://en.wikipedia.org/wiki/Nonlinear_dimensionality_reduction](https://en.wikipedia.org/wiki/Nonlinear_dimensionality_reduction)'
- en: '*Multilinear subspace learning*: [https://en.wikipedia.org/wiki/Multilinear_subspace_learning](https://en.wikipedia.org/wiki/Multilinear_subspace_learning)'
  id: totrans-61
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*多线性子空间学习*: [https://en.wikipedia.org/wiki/Multilinear_subspace_learning](https://en.wikipedia.org/wiki/Multilinear_subspace_learning)'
- en: Tip
  id: totrans-62
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: A good reference on the topic of feature selection versus feature extraction
    is *What is dimensionality reduction?* *What is the difference between feature
    selection and extraction?* [http://datascience.stackexchange.com/questions/130/what-is-dimensionality-reduction-what-is-the-difference-between-feature-selecti/132#132](http://datascience.stackexchange.com/questions/130/what-is-dimensionality-reduction-what-is-the-difference-between-feature-selecti/132#132)
  id: totrans-63
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 关于特征选择与特征提取的主题，一本很好的参考书是*什么是降维？* *特征选择与提取的区别是什么？* [http://datascience.stackexchange.com/questions/130/what-is-dimensionality-reduction-what-is-the-difference-between-feature-selecti/132#132](http://datascience.stackexchange.com/questions/130/what-is-dimensionality-reduction-what-is-the-difference-between-feature-selecti/132#132)
- en: Bridging the data and algorithm
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据与算法的桥梁
- en: 'Let''s bridge the feature and feature engineering definitions within the context
    of feature selection using the example of restaurant recommendations:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以餐厅推荐为例，在特征选择的情况下，将特征和特征工程定义联系起来：
- en: '![Bridging the data and algorithm](img/B05793_08_06.jpg)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![数据与算法的桥梁](img/B05793_08_06.jpg)'
- en: While this is a simplified model, the analogy describes the basic premise of
    applied machine learning. It would be up to a data scientist to analyze the data
    to determine the key features of this restaurant recommendation model.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这是一个简化的模型，但这个比喻描述了应用机器学习的基本前提。确定这个餐厅推荐模型的关键特征将取决于数据科学家分析数据。
- en: In our restaurant recommendation case, while it may be easy to presume that
    geolocation and cuisine type are major factors, it will require some digging into
    the data to understand how the user (that is, restaurant-goer) has chosen their
    preference for a restaurant. Different restaurants often have different characteristics
    or weights for the mode.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的餐厅推荐案例中，虽然可能很容易假设地理位置和菜系类型是主要因素，但要了解用户（即餐厅顾客）是如何选择他们的餐厅偏好的，可能需要深入挖掘数据。不同的餐厅往往有不同的特征或权重。
- en: 'For example, the key features for high-end restaurant catering businesses are
    often related to location (that is, proximity to their customer''s location),
    the ability to make reservations for large parties, and the diversity of the wine
    list:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，高端餐厅餐饮业务的关键特征通常与位置（即，靠近客户的位置）有关，能够为大型团体预订，以及酒单的多样性：
- en: '![Bridging the data and algorithm](img/B05793_08_07.jpg)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![数据与算法的桥梁](img/B05793_08_07.jpg)'
- en: 'Meanwhile, for specialty restaurants, often few of those previous factors are
    involved; instead, the focus is on the reviews, ratings, social media buzz, and,
    possibly whether the restaurant is good for kids:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，对于特色餐厅，往往很少涉及之前提到的因素；相反，重点是评论、评分、社交媒体的热度，以及，可能的话，餐厅是否适合孩子：
- en: '![Bridging the data and algorithm](img/B05793_08_08.jpg)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![数据与算法的桥梁](img/B05793_08_08.jpg)'
- en: 'The ability to segment these different restaurants (and their target audience)
    is a key facet of applied machine learning. It can be an arduous process where
    you try different models and algorithms with different variables and weights and
    then retry after iteratively training and testing many different combinations.
    But note how this time consuming iterative approach itself is its own process
    that can potentially be automated? This is the key context of building algorithms
    of helping machines *learn to learn*: Deep Learning has the potential to automating
    the learning process when building our models.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 将这些不同的餐厅（及其目标受众）进行细分的能力是应用机器学习的关键方面。这可能是一个费时的过程，你尝试不同的模型和算法，使用不同的变量和权重，然后在迭代训练和测试许多不同组合后重新尝试。但请注意，这种耗时迭代的本身就是一个可以潜在自动化的过程？这是构建算法、帮助机器“学会学习”的关键背景：深度学习有潜力在构建我们的模型时自动化学习过程。
- en: What is TensorFlow?
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是TensorFlow？
- en: TensorFlow is a Google open source software library for numerical computation
    using data flow graphs; that is, an open source machine learning library focusing
    on Deep Learning. Based loosely on neural networks, TensorFlow is the culmination
    of the work of Google's Brain Team researchers and engineers to apply Deep Learning
    to Google products and build production models for various Google teams including
    (but not limited to) search, photos, and speech.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow是一个使用数据流图进行数值计算的Google开源软件库；也就是说，一个专注于深度学习的开源机器学习库。基于神经网络，TensorFlow是Google
    Brain团队的研究人员和工程师将深度学习应用于Google产品并构建各种Google团队（包括但不限于搜索、照片和语音）的生产模型的成果。
- en: 'Built on C++ with a Python interface, it has quickly become one of the most
    popular Deep Learning projects in a short amount of time. The following screenshot
    denotes a Google Trends comparison between four popular deep learning libraries;
    note the spike around November 8th - 14th, 2015 (when TensorFlow was announced)
    and the rapid rise over the last year (this snapshot was taken late December 2016):'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 基于 C++ 并具有 Python 接口构建，它迅速成为短时间内最受欢迎的深度学习项目之一。以下截图显示了四个流行深度学习库之间的Google趋势比较；请注意，2015年11月8日至14日（TensorFlow发布时）的峰值以及过去一年内的快速上升（此快照是在2016年12月底拍摄的）：
- en: '![What is TensorFlow?](img/B05793_08_09.jpg)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![什么是TensorFlow？](img/B05793_08_09.jpg)'
- en: 'Another way to measure the popularity of TensorFlow is to note that TensorFlow
    is the most popular machine learning framework on GitHub per [http://www.theverge.com/2016/4/13/11420144/google-machine-learning-tensorflow-upgrade](http://www.theverge.com/2016/4/13/11420144/google-machine-learning-tensorflow-upgrade).
    Note that TensorFlow was only released in November 2015 and in two months it had
    already become the most popular forked ML GitHub repository. In the following
    diagram, you can review the GitHub Repositories Created in 2015 (Interactive Visualization)
    per [http://donnemartin.com/viz/pages/2015](http://donnemartin.com/viz/pages/2015):'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种衡量TensorFlow受欢迎程度的方法是注意到，根据[http://www.theverge.com/2016/4/13/11420144/google-machine-learning-tensorflow-upgrade](http://www.theverge.com/2016/4/13/11420144/google-machine-learning-tensorflow-upgrade)，TensorFlow是GitHub上最受欢迎的机器学习框架。请注意，TensorFlow仅在2015年11月发布，两个月后它已经成为最受欢迎的GitHub
    ML分支库。在下图中，您可以查看2015年创建的GitHub仓库（交互式可视化）[http://donnemartin.com/viz/pages/2015](http://donnemartin.com/viz/pages/2015)：
- en: '![What is TensorFlow?](img/B05793_08_10.jpg)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![什么是TensorFlow？](img/B05793_08_10.jpg)'
- en: As noted previously, TensorFlow performs numerical computation using data flow
    graphs. When thinking about graph (as per the previous chapter on GraphFrames),
    the node (or vertices) of this graph represent mathematical operations while the
    graph edges represent the multidimensional arrays (that is, tensors) that communicate
    between the different nodes (that is, mathematical operations).
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，TensorFlow使用数据流图进行数值计算。当思考图（如前一章所述的GraphFrames）时，该图的节点（或顶点）代表数学运算，而图边代表在不同节点（即数学运算）之间通信的多维数组（即张量）。
- en: 'Referring to the following diagram, `t` `1` is a **2x3** matrix while `t` `2`
    is a **3x2** matrix; these are the tensors (or edges of the tensor graph). The
    node is the mathematical operations represented as `op` `1`:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 参考以下图，`t` `1` 是一个 **2x3** 矩阵，而 `t` `2` 是一个 **3x2** 矩阵；这些是张量（或张量图的边）。节点是表示为 `op`
    `1` 的数学操作：
- en: '![What is TensorFlow?](img/B05793_08_11.jpg)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![什么是 TensorFlow？](img/B05793_08_11.jpg)'
- en: 'In this example, `op` `1` is a matrix multiplication operation represented
    by the following diagram, though this could be any of the many mathematics operations
    available in TensorFlow:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，`op` `1` 是由以下图表示的矩阵乘法操作，尽管这可以是 TensorFlow 中可用的许多数学操作之一：
- en: '![What is TensorFlow?](img/B05793_08_12.jpg)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![什么是 TensorFlow？](img/B05793_08_12.jpg)'
- en: Together, to perform your numerical computations within the graph, there is
    a flow of multidimensional arrays (that is, tensors) between the mathematical
    operations (nodes) - that is, the flow of tensors, or *TensorFlow*.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 一起，为了在图中进行数值计算，多维数组（即张量）在数学操作（节点）之间流动，即张量的流动，或称 *TensorFlow*。
- en: 'To better understand how TensorFlow works, let''s start by installing TensorFlow
    within your Python environment (initially sans Spark). For the full instructions,
    please refer to TensorFlow | Download and Setup: [https://www.tensorflow.org/versions/r0.12/get_started/os_setup.html](https://www.tensorflow.org/versions/r0.12/get_started/os_setup.html).'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解 TensorFlow 的工作原理，让我们首先在你的 Python 环境中安装 TensorFlow（最初不带 Spark）。完整的说明请参阅
    TensorFlow | 下载和设置：[https://www.tensorflow.org/versions/r0.12/get_started/os_setup.html](https://www.tensorflow.org/versions/r0.12/get_started/os_setup.html)。
- en: For this chapter, let's focus on the Python `pip` package management system
    installation on Linux or Mac OS.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本章，让我们专注于在 Linux 或 Mac OS 上安装 Python `pip` 软件包管理系统。
- en: Installing Pip
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装 Pip
- en: 'Ensure that you have installed `pip`; if have not, please use the following
    commands to install the Python package installation manager for Ubuntu/Linux:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 确保你已经安装了 `pip`；如果没有，请使用以下命令安装 Ubuntu/Linux 的 Python 软件包安装管理器：
- en: '[PRE0]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'For Mac OS, you would use the following commands:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 Mac OS，你会使用以下命令：
- en: '[PRE1]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Note, for Ubuntu/Linux, you may also want to upgrade `pip` as the pip within
    the Ubuntu repository is old and may not be compatible with newer packages. To
    do this, you can run the command:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，对于 Ubuntu/Linux，你可能还想升级 `pip`，因为 Ubuntu 仓库中的 `pip` 很旧，可能不与新软件包兼容。为此，你可以运行以下命令：
- en: '[PRE2]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Installing TensorFlow
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装 TensorFlow
- en: 'To install TensorFlow (with `pip` already installed), you only need to execute
    the following command:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 要安装 TensorFlow（`pip` 已安装），你只需要执行以下命令：
- en: '[PRE3]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'If you have a computer that has GPU support, you can *instead* use the following
    command:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有一台支持 GPU 的计算机，你可以*改用*以下命令：
- en: '[PRE4]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Note that if the preceding command does not work, there are specific instructions
    to install TensorFlow with GPU support based on your Python version (that is,
    2.7, 3.4, or 3.5) and GPU support.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，如果前面的命令不起作用，根据你的 Python 版本（即 2.7、3.4 或 3.5）和 GPU 支持情况，有特定的说明来安装带有 GPU 支持的
    TensorFlow。
- en: 'For example, if I wanted to install TensorFlow on Python 2.7 with GPU enabled
    on Mac OS, execute the following commands:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果我想在 Mac OS 上为 Python 2.7 安装带有 GPU 启用的 TensorFlow，请执行以下命令：
- en: '[PRE5]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Note
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Please refer to [https://www.tensorflow.org/versions/r0.12/get_started/os_setup.html](https://www.tensorflow.org/versions/r0.12/get_started/os_setup.html)
    for the latest installation instructions.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 请参阅 [https://www.tensorflow.org/versions/r0.12/get_started/os_setup.html](https://www.tensorflow.org/versions/r0.12/get_started/os_setup.html)
    获取最新的安装说明。
- en: Matrix multiplication using constants
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用常数的矩阵乘法
- en: 'To better describe tensors and how TensorFlow works, let''s start with a matrix
    multiplication calculation involving two constants. As noted in the following
    diagram, we have `c` `1` (**3x1** matrix) and `c` `2` (**1x3** matrix), where
    the operation (`op` `1`) is a matrix multiplication:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地描述张量以及 TensorFlow 的工作原理，让我们从一个涉及两个常数的矩阵乘法计算开始。如以下图所示，我们有 `c` `1` （**3x1**
    矩阵）和 `c` `2` （**1x3** 矩阵），其中操作（`op` `1`）是矩阵乘法：
- en: '![Matrix multiplication using constants](img/B05793_08_13.jpg)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![使用常数的矩阵乘法](img/B05793_08_13.jpg)'
- en: 'We will now define `c` `1` (**1x3** matrix) and `c` `2` (**3x1** matrix) using
    the following code:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将使用以下代码定义 `c` `1` （**1x3** 矩阵）和 `c` `2` （**3x1** 矩阵）：
- en: '[PRE6]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Now that we have our constants, let''s run our matrix multiplication using
    the following code. Within the context of a TensorFlow graph, recall that the
    nodes in the graph are called operations (or `ops`). The following matrix multiplication
    is the `ops`, while the two matrices (`c` `1`, `c` `2`) are the tensors (typed
    multi-dimensional array). An `op` takes zero or more tensors as its input, performs
    the operation such as a mathematical calculation, with the output being zero or
    more tensors in the form of `numpy ndarray` objects ([http://www.numpy.org/](http://www.numpy.org/))
    or `tensorflow::Tensor interfaces` in C, C++:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了我们的常量，让我们使用以下代码运行我们的矩阵乘法。在TensorFlow图的上下文中，请记住，图中的节点被称为操作（或`ops`）。以下矩阵乘法是`ops`，而两个矩阵（`c1`，`c2`）是张量（类型化的多维数组）。一个`op`可以接受零个或多个张量作为其输入，执行数学计算等操作，输出为零个或多个以`numpy
    ndarray`对象或C，C++中的`tensorflow::Tensor interfaces`形式存在的张量：
- en: '[PRE7]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Now that this TensorFlow graph has been established, execution of this operation
    (for example, in this case, the matrix multiplication) is done within the context
    of a `session`; the `session` places the graph `ops` into the CPU or GPU (that
    is, devices) to be executed:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 现在这个TensorFlow图已经建立，这个操作的执行（例如，在这种情况下，矩阵乘法）是在`session`的上下文中完成的；`session`将图`ops`放置在CPU或GPU（即设备）上以执行：
- en: '[PRE8]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'With the output being:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 输出为：
- en: '[PRE9]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Once you have completed your operations, you can close the session:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你完成了你的操作，你可以关闭会话：
- en: '[PRE10]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Matrix multiplication using placeholders
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用占位符进行矩阵乘法
- en: 'Now we will perform the same task as before, except this time, we will use
    tensors instead of constants. As noted in the following diagram, we will start
    off with two matrices (`m1: 3x1, m2: 1x3`) using the same values as in the previous
    section:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '现在我们将执行与之前相同的任务，但这次我们将使用张量而不是常量。如以下图所示，我们将从两个矩阵（`m1: 3x1, m2: 1x3`）开始，使用与上一节相同的值：'
- en: '![Matrix multiplication using placeholders](img/B05793_08_14.jpg)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![使用占位符进行矩阵乘法](img/B05793_08_14.jpg)'
- en: 'Within TensorFlow, we will use `placeholder` to define our two tensors as per
    the following code snippet:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在TensorFlow中，我们将使用`placeholder`来定义我们的两个张量，如下代码片段所示：
- en: '[PRE11]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The advantage of this approach is that, with placeholders you can use the same
    operations (that is, in this case, the matrix multiplication) with tensors of
    different sizes and shape (provided they meet the criteria of the operation).
    Like the operations in the previous section, let's define two matrices and execute
    the graph (with a simplified session execution).
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法的优势在于，使用占位符，你可以使用相同的操作（即在这种情况下，矩阵乘法）与不同大小和形状的张量（只要它们满足操作的标准）。就像上一节中的操作一样，让我们定义两个矩阵并执行图（使用简化的会话执行）。
- en: Running the model
  id: totrans-124
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 运行模型
- en: 'The following code snippet is similar to the code snippet in the previous section,
    except that it now uses placeholders instead of constants:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码片段与上一节的代码片段类似，但现在它使用占位符而不是常量：
- en: '[PRE12]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'With the output being both the value, as well as the data type:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 输出既包括值，也包括数据类型：
- en: '[PRE13]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Running another model
  id: totrans-129
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 运行另一个模型
- en: 'Now that we have a graph (albeit a simple one) using `placeholders`, we can
    use different tensors to perform the same operation using different input matrices.
    As noted in the following figure, we have `m1` (4x1) and `m2` (1x4):'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经有一个使用`placeholders`的图（尽管是一个简单的图），我们可以使用不同的张量来执行相同的操作，使用不同的输入矩阵。如以下图所示，我们有`m1`（4x1）和`m2`（1x4）：
- en: '![Running another model](img/B05793_08_15.jpg)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![运行另一个模型](img/B05793_08_15.jpg)'
- en: 'Because we''re using `placeholders`, we can easily reuse the same graph within
    a new session using new input:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们使用`placeholders`，我们可以轻松地在新的会话中重用相同的图，使用新的输入：
- en: '[PRE14]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'With the output being:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 输出为：
- en: '[PRE15]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Discussion
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: As noted previously, TensorFlow provides users with the ability to perform deep
    learning using Python libraries by representing computations as graphs where the
    tensors represent the data (edges of the graph) and operations represent what
    is to be executed (for example, mathematical computations) (vertices of the graph).
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，TensorFlow通过将计算表示为图来为用户提供使用Python库执行深度学习的能力，其中张量代表数据（图的边），操作代表要执行的内容（例如，数学计算）（图的顶点）。
- en: 'For more information, please refer to:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 更多信息请参阅：
- en: TensorFlow | Get Started | Basic Usage [https://www.tensorflow.org/get_started/get_started#basic_usage](https://www.tensorflow.org/get_started/get_started#basic_usage)
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow | 入门 | 基本用法 [https://www.tensorflow.org/get_started/get_started#basic_usage](https://www.tensorflow.org/get_started/get_started#basic_usage)
- en: Shannon McCormick's Neural Network and Google TensorFlow [http://www.slideshare.net/ShannonMcCormick4/neural-networks-and-google-tensor-flow](http://www.slideshare.net/ShannonMcCormick4/neural-networks-and-google-tensor-flow)
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shannon McCormick的神经网络和Google TensorFlow [http://www.slideshare.net/ShannonMcCormick4/neural-networks-and-google-tensor-flow](http://www.slideshare.net/ShannonMcCormick4/neural-networks-and-google-tensor-flow)
- en: Introducing TensorFrames
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍TensorFrames
- en: 'At the time of writing, TensorFrames is an experimental binding for Apache
    Spark; it was introduced in early 2016, shortly after the release of TensorFlow.
    With TensorFrames, one can manipulate Spark DataFrames with TensorFlow programs.
    Referring to the tensor diagrams in the previous section, we have updated the
    figure to show how Spark DataFrames work with TensorFlow, as shown in the following
    diagram:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，TensorFrames是Apache Spark的一个实验性绑定；它于2016年初推出，紧随TensorFlow的发布之后。使用TensorFrames，可以通过TensorFlow程序操作Spark
    DataFrames。参考上一节中的张量图，我们已更新了以下图示，以展示Spark DataFrames如何与TensorFlow协同工作：
- en: '![Introducing TensorFrames](img/B05793_08_16.jpg)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![介绍TensorFrames](img/B05793_08_16.jpg)'
- en: As noted in the preceding diagram, TensorFrames provides a bridge between Spark
    DataFrames and TensorFlow. This allows you to take your DataFrames and apply them
    as input into your TensorFlow computation graph. TensorFrames also allows you
    to take the TensorFlow computation graph output and push it back into DataFrames
    so you can continue your downstream Spark processing.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，TensorFrames在Spark DataFrames和TensorFlow之间提供了一个桥梁。这使得您可以将您的DataFrames作为输入应用到TensorFlow的计算图中。TensorFrames还允许您将TensorFlow计算图的输出推回DataFrames，以便您可以继续您的下游Spark处理。
- en: 'In terms of common usage scenarios for TensorFrames, these typically include
    the following:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在TensorFrames的常见使用场景中，通常包括以下内容：
- en: '**Utilize TensorFlow with your data**'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '**利用TensorFlow处理您的数据**'
- en: The integration of TensorFlow and Apache Spark with TensorFrames allows data
    scientists to expand their analytics, streaming, graph, and machine learning capabilities
    to include Deep Learning via TensorFlow. This allows you to both train and deploy
    models at scale.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow与Apache Spark的集成，通过TensorFrames允许数据科学家扩展他们的分析、流处理、图和机器学习能力，包括通过TensorFlow进行深度学习。这允许您在大规模上训练和部署模型。
- en: '**Parallel training to determine optimal hyperparameters**'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '**并行训练以确定最佳超参数**'
- en: When building deep learning models, there are several configuration parameters
    (that is, hyperparameters) that impact on how the model is trained. Common in
    Deep Learning/artificial neural networks are hyperparameters that define the learning
    rate (if the rate is high it will learn quickly, but it may not take into account
    highly variable input - that is, it will not learn well if the rate and variability
    in the data is too high) and the number of neurons in each layer of your neural
    network (too many neurons results in noisy estimates, while too few neurons will
    result in the network not learning well).
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建深度学习模型时，有几个配置参数（即超参数）会影响模型的训练方式。在深度学习/人工神经网络中常见的超参数包括定义学习率（如果速率高，则学习速度快，但它可能不会考虑到高度可变性的输入——也就是说，如果数据和速率的可变性太高，它可能学不好）以及您神经网络中每层的神经元数量（神经元太多会导致估计噪声，而神经元太少会导致网络学不好）。
- en: As observed in *Deep Learning with Apache Spark and TensorFlow* ([https://databricks.com/blog/2016/01/25/deep-learning-with-apache-spark-and-tensorflow.html](https://databricks.com/blog/2016/01/25/deep-learning-with-apache-spark-and-tensorflow.html)),
    using Spark with TensorFlow to help find the best set of hyperparameters for neural
    network training resulted in an order of magnitude reduction in training time
    and a 34% lower error rate for the handwritten digit recognition dataset.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 如在《Apache Spark和TensorFlow的深度学习》([https://databricks.com/blog/2016/01/25/deep-learning-with-apache-spark-and-tensorflow.html](https://databricks.com/blog/2016/01/25/deep-learning-with-apache-spark-and-tensorflow.html))中观察到的那样，使用Spark与TensorFlow结合以帮助找到神经网络训练的最佳超参数集，这导致训练时间减少了10个数量级，并且手写数字识别数据集的错误率降低了34%。
- en: 'For more information on Deep Learning and hyperparameters, please refer to:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 如需了解更多关于深度学习和超参数的信息，请参阅：
- en: '*Optimizing Deep Learning Hyper-Parameters Through an Evolutionary Algorithm*
    [http://ornlcda.github.io/MLHPC2015/presentations/4-Steven.pdf](http://ornlcda.github.io/MLHPC2015/presentations/4-Steven.pdf)'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*通过进化算法优化深度学习超参数* [http://ornlcda.github.io/MLHPC2015/presentations/4-Steven.pdf](http://ornlcda.github.io/MLHPC2015/presentations/4-Steven.pdf)'
- en: '*CS231n Convolutional Network Networks for Visual Recognition* [http://cs231n.github.io/](http://cs231n.github.io/)'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*CS231n 卷积网络视觉识别网络* [http://cs231n.github.io/](http://cs231n.github.io/)'
- en: '*Deep Learning with Apache Spark and TensorFlow* [https://databricks.com/blog/2016/01/25/deep-learning-with-apache-spark-and-tensorflow.html](https://databricks.com/blog/2016/01/25/deep-learning-with-apache-spark-and-tensorflow.html)'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用 Apache Spark 和 TensorFlow 进行深度学习* [https://databricks.com/blog/2016/01/25/deep-learning-with-apache-spark-and-tensorflow.html](https://databricks.com/blog/2016/01/25/deep-learning-with-apache-spark-and-tensorflow.html)'
- en: At the time of writing, TensorFrames is officially supported as of Apache Spark
    1.6 (Scala 2.10), though most contributions are currently focused on Spark 2.0
    (Scala 2.11). The easiest way to use TensorFrames is to access it via Spark Packages
    ([https://spark-packages.org](https://spark-packages.org)).
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，TensorFrames 作为 Apache Spark 1.6（Scala 2.10）的官方支持，尽管目前大多数贡献都集中在 Spark
    2.0（Scala 2.11）上。使用 TensorFrames 的最简单方法是通过 Spark Packages ([https://spark-packages.org](https://spark-packages.org))
    访问它。
- en: TensorFrames – quick start
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TensorFrames – 快速入门
- en: After all this preamble, let's jump start our use of TensorFrames with this
    quick start tutorial. You can download and use the full notebook within Databricks
    Community Edition at [http://bit.ly/2hwGyuC](http://bit.ly/2hwGyuC).
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有这些前言之后，让我们通过这个快速入门教程快速开始使用 TensorFrames。您可以在 Databricks Community Edition
    中下载并使用完整的笔记本，网址为 [http://bit.ly/2hwGyuC](http://bit.ly/2hwGyuC)。
- en: 'You can also run this from the PySpark shell (or other Spark environments),
    like any other Spark package:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以从 PySpark shell（或其他 Spark 环境）中运行此命令，就像运行任何其他 Spark 包一样：
- en: '[PRE16]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Note, you will only use one of the above commands (that is, not both). For more
    information, please refer to the `databricks/tensorframes` GitHub repository ([https://github.com/databricks/tensorframes](https://github.com/databricks/tensorframes)).
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，您将只使用上述命令中的一个（即，不是两个）。有关更多信息，请参阅 `databricks/tensorframes` GitHub 仓库 ([https://github.com/databricks/tensorframes](https://github.com/databricks/tensorframes))。
- en: Configuration and setup
  id: totrans-161
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 配置和设置
- en: 'Please follow the configuration and setup steps in the following order:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 请按照以下顺序遵循配置和设置步骤：
- en: Launching a Spark cluster
  id: totrans-163
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 启动 Spark 集群
- en: Launch a Spark cluster using Spark 1.6 (Hadoop 1) and Scala 2.10\. This has
    been tested with Spark 1.6, Spark 1.6.2, and Spark 1.6.3 (Hadoop 1) on Databricks
    Community Edition ([http://databricks.com/try-databricks](http://databricks.com/try-databricks)).
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Spark 1.6（Hadoop 1）和 Scala 2.10 启动 Spark 集群。这已经在 Databricks Community Edition
    上的 Spark 1.6、Spark 1.6.2 和 Spark 1.6.3（Hadoop 1）上进行了测试 ([http://databricks.com/try-databricks](http://databricks.com/try-databricks))。
- en: Creating a TensorFrames library
  id: totrans-165
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创建 TensorFrames 库
- en: 'Create a library to attach TensorFrames 0.2.2 to your cluster: `tensorframes-0.2.2-s_2.10`.
    Refer to [Chapter 7](ch07.html "Chapter 7. GraphFrames"), *GraphFrames* to recall
    how to create a library.'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个库以将 TensorFrames 0.2.2 附加到您的集群：`tensorframes-0.2.2-s_2.10`。请参阅[第 7 章](ch07.html
    "第 7 章。GraphFrames")，*GraphFrames*，以回忆如何创建库。
- en: Installing TensorFlow on your cluster
  id: totrans-167
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在您的集群上安装 TensorFlow
- en: 'In a notebook, run one of the following commands to install TensorFlow. This
    has been tested with TensorFlow 0.9 CPU edition:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在笔记本中运行以下命令之一以安装 TensorFlow。这已经与 TensorFlow 0.9 CPU 版本进行了测试：
- en: 'TensorFlow 0.9, Ubuntu/Linux 64-bit, CPU only, Python 2.7:'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow 0.9，Ubuntu/Linux 64 位，仅 CPU，Python 2.7：
- en: '[PRE17]'
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'TensorFlow 0.9, Ubuntu/Linux 64-bit, GPU enabled, Python 2.7:'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow 0.9，Ubuntu/Linux 64 位，启用 GPU，Python 2.7：
- en: '[PRE18]'
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The following is the `pip` install command that will install TensorFlow on
    to the Apache Spark driver:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是将 TensorFlow 安装到 Apache Spark 驱动器的 `pip` 安装命令：
- en: '[PRE19]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'A successful installation should have something similar to the following output:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 成功安装应该有类似以下输出：
- en: '[PRE20]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Upon successful installation of TensorFlow, detach and reattach the notebook
    where you just ran this command. Your cluster is now configured; you can run pure
    TensorFlow programs on the driver, or TensorFrames examples on the whole cluster.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在成功安装 TensorFlow 后，断开并重新连接您刚刚运行此命令的笔记本。您的集群现在已配置；您可以在驱动器上运行纯 TensorFlow 程序，或在整个集群上运行
    TensorFrames 示例。
- en: Using TensorFlow to add a constant to an existing column
  id: totrans-178
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 TensorFlow 向现有列添加常数
- en: This is a simple TensorFrames program where the `op` is to perform a simple
    addition. Note that the original source code can be found in the `databricks/tensorframes`
    GitHub repository. This is in reference to the TensorFrames `Readme.md` | *How
    to Run in Python* section ([https://github.com/databricks/tensorframes#how-to-run-in-python](https://github.com/databricks/tensorframes#how-to-run-in-python)).
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个简单的TensorFrames程序，其中`op`是执行简单的加法。请注意，原始源代码可以在`databricks/tensorframes` GitHub存储库中找到。这是关于TensorFrames
    `Readme.md` | *如何在Python中运行*部分（[https://github.com/databricks/tensorframes#how-to-run-in-python](https://github.com/databricks/tensorframes#how-to-run-in-python)）。
- en: 'The first thing we will do is import `TensorFlow`, `TensorFrames`, and `pyspark.sql.row`
    to create a DataFrame based on an RDD of floats:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先将导入`TensorFlow`、`TensorFrames`和`pyspark.sql.row`，然后基于浮点RDD创建一个DataFrame：
- en: '[PRE21]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'To view the `df` DataFrame generated by the RDD of floats, we can use the `show`
    command:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看由浮点RDD生成的`df` DataFrame，我们可以使用`show`命令：
- en: '[PRE22]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'This produces the following result:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 这会产生以下结果：
- en: '![Using TensorFlow to add a constant to an existing column](img/B05793_08_17.jpg)'
  id: totrans-185
  prefs: []
  type: TYPE_IMG
  zh: '![使用TensorFlow向现有列添加常数](img/B05793_08_17.jpg)'
- en: Executing the Tensor graph
  id: totrans-186
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 执行Tensor图
- en: 'As noted previously, this tensor graph consists of adding 3 to the tensor created
    by the `df` DataFrame generated by the RDD of floats. We will now execute the
    following code snippet:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，这个张量图由将3加到由浮点RDD生成的`df` DataFrame创建的张量组成。我们现在将执行以下代码片段：
- en: '[PRE23]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Here are some specific call outs for the preceding code snippet:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是对前面代码片段的一些具体说明：
- en: '`x` utilizes `tfs.block`, where the `block` builds a block placeholder based
    on the content of a column in a DataFrame'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`x`使用`tfs.block`，其中`block`基于DataFrame中列的内容构建块占位符'
- en: '`z` is the output tensor from the TensorFlow `add` method (`tf.add`)'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`z`是TensorFlow `add`方法（`tf.add`）的输出张量'
- en: '`df2` is the new DataFrame, which adds an extra column to the `df` DataFrame
    with the `z` tensor block by block'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`df2`是新的DataFrame，它通过分块将`z`张量添加到`df` DataFrame的额外列中'
- en: 'While `z` is the tensor (as noted in the preceding output), for us to work
    with the results of the TensorFlow program, we will utilize the `df2` dataframe.
    The output from `df2.show()` is as follows:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然`z`是张量（如前所述），但为了处理TensorFlow程序的结果，我们将使用`df2` dataframe。`df2.show()`的输出如下：
- en: '![Executing the Tensor graph](img/B05793_08_18.jpg)'
  id: totrans-194
  prefs: []
  type: TYPE_IMG
  zh: '![执行Tensor图](img/B05793_08_18.jpg)'
- en: Blockwise reducing operations example
  id: totrans-195
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分块减少操作示例
- en: In this next section, we will show how to work with blockwise reducing operations.
    Specifically, we will compute the sum and min of field vectors, working with blocks
    of rows for more efficient processing.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将展示如何处理分块减少操作。具体来说，我们将计算字段向量的和与最小值，通过处理行块以实现更有效的处理。
- en: Building a DataFrame of vectors
  id: totrans-197
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 构建向量DataFrame
- en: 'First, we will create a one-column DataFrame of vectors:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将创建一个包含向量的单列DataFrame：
- en: '[PRE24]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The output is as follows:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Building a DataFrame of vectors](img/B05793_08_19.jpg)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![构建向量DataFrame](img/B05793_08_19.jpg)'
- en: Analysing the DataFrame
  id: totrans-202
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分析DataFrame
- en: 'We need to analyze the DataFrame to determine what its shape is (that is, dimensions
    of the vectors). For example, in the following snippet, we use the `tfs.print_schema`
    command for the `df` DataFrame:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要分析DataFrame以确定其形状（即向量的维度）。例如，在以下代码片段中，我们使用`tfs.print_schema`命令对`df` DataFrame进行操作：
- en: '[PRE25]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Notice the `double[?,?]`, meaning that TensorFlow does not know the dimensions
    of the vectors:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 注意`double[?,?]`，这意味着TensorFlow不知道向量的维度：
- en: '[PRE26]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Upon analysis of the `df2` DataFrame, TensorFlow has inferred that `y` contains
    vectors of size 2\. For small tensors (scalars and vectors), TensorFrames usually
    infers the shapes of the tensors without requiring a preliminary analysis. If
    it cannot do so, an error message will indicate that you need to run the DataFrame
    through `tfs.analyze()` first.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 在分析`df2` DataFrame后，TensorFlow推断出`y`包含大小为2的向量。对于小张量（标量和向量），TensorFrames通常不需要初步分析就能推断出张量的形状。如果它无法做到这一点，错误信息将指示您首先运行DataFrame通过`tfs.analyze()`。
- en: Computing elementwise sum and min of all vectors
  id: totrans-208
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 计算所有向量的逐元素和与最小值
- en: 'Now, let''s analyze the `df` DataFrame to compute the `sum` and the elementwise
    `min` of all the vectors using `tf.reduce_sum` and `tf.reduce_min`:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们分析`df` DataFrame，使用`tf.reduce_sum`和`tf.reduce_min`计算所有向量的`sum`和逐元素`min`：
- en: '`tf.reduce_sum`: Computes the sum of elements across dimensions of a tensor,
    for example, if `x = [[3, 2, 1], [-1, 2, 1]]` then `tf.reduce_sum(x) ==> 8`. More
    information can be found at: `https://www.tensorflow.org/api_docs/python/tf/reduce_sum`.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tf.reduce_sum`：计算张量跨维度的元素总和，例如，如果`x = [[3, 2, 1], [-1, 2, 1]]`，则`tf.reduce_sum(x)
    ==> 8`。更多信息可以在：`https://www.tensorflow.org/api_docs/python/tf/reduce_sum`找到。'
- en: '`tf.reduce_min`: Computes the minimum of elements across dimensions of a tensor,
    for example, if `x = [[3, 2, 1], [-1, 2, 1]]` then `tf.reduce_min(x) ==> -1`.
    More information can be found at: `https://www.tensorflow.org/api_docs/python/tf/reduce_min`.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tf.reduce_min`：计算张量跨维度的元素最小值，例如，如果`x = [[3, 2, 1], [-1, 2, 1]]`，则`tf.reduce_min(x)
    ==> -1`。更多信息可以在：`https://www.tensorflow.org/api_docs/python/tf/reduce_min`找到。'
- en: 'The following code snippet allows us to perform efficient elementwise reductions
    using TensorFlow, where the source data is within a DataFrame:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码片段允许我们使用TensorFlow执行高效的元素级缩减，其中源数据位于DataFrame中：
- en: '[PRE27]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: With a few lines of TensorFlow code with TensorFrames, we can take the data
    stored within the `df` DataFrame and execute a Tensor Graph to perform element
    wise sum and min, merge the data back into a DataFrame, and (in our case) print
    out the final values.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 使用TensorFrames的几行TensorFlow代码，我们可以从存储在`df` DataFrame中的数据中提取数据，执行Tensor图以执行元素级求和和最小值，将数据合并回DataFrame，并在我们的案例中打印出最终值。
- en: Summary
  id: totrans-215
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we have reviewed the fundamentals of neural networks and Deep
    Learning, including the components of feature engineering. With all this new excitement
    in Deep Learning, we introduced TensorFlow and how it can work closely together
    with Apache Spark through TensorFrames.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们回顾了神经网络和深度学习的基础知识，包括特征工程组件。随着深度学习的所有这些新兴奋点，我们介绍了TensorFlow以及它是如何通过TensorFrames与Apache
    Spark紧密协作的。
- en: 'TensorFrames is a powerful deep learning tool that allows data scientists and
    engineers to work with TensorFlow with data stored in Spark DataFrames. This allows
    you to expand the capabilities of Apache Spark to a powerful deep learning toolset
    that is based on the learning process of neural networks. To help continue your
    Deep Learning journey, the following are some great TensorFlow and TensorFrames
    resources:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFrames是一个强大的深度学习工具，允许数据科学家和工程师使用存储在Spark DataFrame中的数据与TensorFlow一起工作。这使您能够将Apache
    Spark的功能扩展到基于神经网络学习过程的强大深度学习工具集。为了帮助您继续深度学习之旅，以下是一些优秀的TensorFlow和TensorFrames资源：
- en: 'TensorFlow: [https://www.tensorflow.org/](https://www.tensorflow.org/)'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow：[https://www.tensorflow.org/](https://www.tensorflow.org/)
- en: 'TensorFlow | Get Started: [https://www.tensorflow.org/get_started/get_started](https://www.tensorflow.org/get_started/get_started)'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow | 入门：[https://www.tensorflow.org/get_started/get_started](https://www.tensorflow.org/get_started/get_started)
- en: 'TensorFlow | Guides: [https://www.tensorflow.org/tutorials/](https://www.tensorflow.org/tutorials/)'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow | 指南：[https://www.tensorflow.org/tutorials/](https://www.tensorflow.org/tutorials/)
- en: 'Deep Learning on Databricks: [https://databricks.com/blog/2016/12/21/deep-learning-on-databricks.html](https://databricks.com/blog/2016/12/21/deep-learning-on-databricks.html)'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Databricks上的深度学习：[https://databricks.com/blog/2016/12/21/deep-learning-on-databricks.html](https://databricks.com/blog/2016/12/21/deep-learning-on-databricks.html)
- en: 'TensorFrames (GitHub): [https://github.com/databricks/tensorframes](https://github.com/databricks/tensorframes)'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFrames（GitHub）：[https://github.com/databricks/tensorframes](https://github.com/databricks/tensorframes)
- en: 'TensorFrames User Guide: [https://github.com/databricks/tensorframes/wiki/TensorFrames-user-guide](https://github.com/databricks/tensorframes/wiki/TensorFrames-user-guide)'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFrames用户指南：[https://github.com/databricks/tensorframes/wiki/TensorFrames-user-guide](https://github.com/databricks/tensorframes/wiki/TensorFrames-user-guide)
