- en: Chapter 5. Building Models (authored by Renata Nemeth and Gergely Toth)
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第5章。构建模型（由Renata Nemeth和Gergely Toth撰写）
- en: '"All models should be as simple as possible... but no simpler."'
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '"所有模型都应该尽可能简单...但不要过于简单。"'
- en: ''
  id: totrans-2
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: – Attributed to Albert Einstein
  id: totrans-3
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: – 归功于阿尔伯特·爱因斯坦
- en: ''
  id: totrans-4
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '"All models are wrong... but some are useful."'
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '"所有模型都是错误的...但有些是有用的。"'
- en: ''
  id: totrans-6
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: – George Box
  id: totrans-7
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: – 乔治·博克斯
- en: After loading and transforming data, in this chapter, we will focus on how to
    build statistical models. Models are representations of reality, and, as the preceding
    citations emphasize, are always simplified representations. Although you can't
    possibly take everything into account, you should be aware about what to include
    and exclude in a good model that provides meaningful results.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在加载数据并进行转换后，本章将重点介绍如何构建统计模型。模型是现实的表示，正如前面的引用所强调的，总是简化的表示。虽然你不可能考虑所有因素，但你应该了解在提供有意义结果的良好模型中应该包含和排除什么。
- en: 'In this chapter, regression models are discussed on the basis of linear regression
    models and standard modeling. **Generalized Linear Models** (**GLM**) extend these
    to allow the response variables to differ in distribution, which will be covered
    in the [Chapter 6](ch06.html "Chapter 6. Beyond the Linear Trend Line (authored
    by Renata Nemeth and Gergely Toth)"), *Beyond the Linear Trend Line (authored
    by Renata Nemeth and Gergely Toth)*. In all, we will discuss the three most well
    known regression models:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将基于线性回归模型和标准建模讨论回归模型。**广义线性模型**（**GLM**）将这些扩展到允许响应变量具有不同的分布，这将在[第6章](ch06.html
    "第6章。超越线性趋势线（由Renata Nemeth和Gergely Toth撰写)"), *超越线性趋势线（由Renata Nemeth和Gergely
    Toth撰写)*中介绍。总的来说，我们将讨论三种最著名的回归模型：
- en: '**Linear regression** for continuous outcomes (birth weight measured in grams)'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**线性回归**用于连续结果（以克为单位的出生体重）'
- en: '**Logistic regression** for binary outcomes (low birth weight versus normal
    birth weight)'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**逻辑回归**用于二元结果（低出生体重与正常出生体重）'
- en: '**Poisson regression** for count data (number of low birth weight infants per
    year or per country)'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**泊松回归**用于计数数据（每年或每个国家的低出生体重婴儿数量）'
- en: Although there are many other regression models, such as *Cox-regression* which
    we will not discuss here, the logic in the building of the models and the interpretation
    are similar. So, after reading this chapter, you will be able to understand those
    without doubt.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然还有许多其他回归模型，例如我们在此处不讨论的*Cox回归*，但模型构建的逻辑和解释是相似的。因此，阅读本章后，你将毫无疑问地理解那些模型。
- en: 'By the end of this chapter, you will learn the most important things about
    regression models: how to avoid confounding, how to fit, how to interpret, and
    how to choose the best model among the many different options.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将了解关于回归模型最重要的内容：如何避免混杂因素，如何拟合，如何解释，以及如何在众多不同选项中选择最佳模型。
- en: The motivation behind multivariate models
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多变量模型背后的动机
- en: If you would like to measure the strength of association between a response
    and a predictor, you can choose a simple two-way association measure, such as
    correlation or the odds ratio, depending on the nature of your data. But, if your
    aim is to model a complex mechanism by taking into account other predictors as
    well, you will need regression models.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要衡量响应变量和预测变量之间关联的强度，你可以选择一个简单的双向关联度量，例如相关系数或优势比，这取决于你数据的性质。但是，如果你的目标是通过考虑其他预测变量来建模复杂机制，你需要回归模型。
- en: As Ben Goldacre, the evidence-based columnist for *The Guardian*, tells in his
    brilliant TED talk that the strong association between olive oil consumption and
    young looking skin does not imply that olive oil is beneficial to our skin. When
    modeling a complex association structure, we should also control for other predictors,
    such as smoking status or physical activity, because those who consume more olive
    oil are more likely to live a healthy life in general, so it may not be the olive
    oil itself that prevents skin wrinkles. In short, it seems that the kind of lifestyle
    is likely to confound the relationship between the variables of interest, making
    it appear that there might be causality, when in fact there is none.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 如《卫报》的证据基础专栏作家Ben Goldacre在他的精彩TED演讲中所说，橄榄油消费与年轻外观皮肤之间的强烈关联并不意味着橄榄油对我们的皮肤有益。在建模复杂的关联结构时，我们也应该控制其他预测变量，例如吸烟状况或身体活动，因为那些消费更多橄榄油的人更有可能总体上过上健康的生活，因此可能不是橄榄油本身防止皮肤皱纹。简而言之，似乎这种生活方式可能混淆了感兴趣变量之间的关系，使得看起来可能存在因果关系，而实际上并不存在。
- en: Note
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: A confounder is a third variable that biases (increases or decreases) the association
    we are interested in. The confounder is always associated with both the response
    and the predictor.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 混合因素是一个第三变量，它会影响（增加或减少）我们感兴趣的关联。混合因素总是与响应和预测因子相关联。
- en: If we examine the olive oil and skin wrinkles association again by fixing the
    smoking status, hence building separate models for smokers and non-smokers, the
    association may vanish. Holding the confounders fixed is the main idea behind
    controlling confounding via regression models.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们再次通过固定吸烟状态来检查橄榄油和皮肤皱纹的关联，即为吸烟者和非吸烟者建立单独的模型，这种关联可能会消失。固定混合因素是控制混合因素通过回归模型的主要思想。
- en: Regression models in general are intended to measure associations between a
    response and a predictor by controlling for others. Potential confounders are
    entered into the model as predictors, and the regression coefficient of the predictor
    (the *partial coefficient*) measures the effect adjusted to the confounders.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 一般而言，回归模型旨在通过控制其他因素来衡量响应和预测因子之间的关联。潜在的混合因素作为预测因子进入模型，预测因子的回归系数（部分系数）衡量了调整混合因素后的效应。
- en: Linear regression with continuous predictors
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 具有连续预测因子的线性回归
- en: 'Let''s start with an actual and illuminating example of confounding. Consider
    that we would like to predict the amount of air pollution based on the size of
    the city (measured in population size as thousand of habitants). Air pollution
    is measured by the sulfur dioxide (SO2) concentration in the air, in milligrams
    per cubic meter. We will use the US air pollution data set (Hand and others 1994)
    from the `gamlss.data` package:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从实际且富有启发性的混合因素例子开始。假设我们想要根据城市的大小（以人口规模衡量，以千人为单位）来预测空气污染量。空气污染通过空气中二氧化硫（SO2）浓度来衡量，以每立方米的毫克为单位。我们将使用来自`gamlss.data`包的美国空气污染数据集（Hand等人，1994年）：
- en: '[PRE0]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Model interpretation
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型解释
- en: 'Let''s draw our very first linear regression model by building a formula. The
    `lm` function from the `stats` package is used to fit linear models, which is
    an important tool for regression modeling:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过构建一个公式来绘制我们非常第一个线性回归模型。`stats`包中的`lm`函数用于拟合线性模型，这是回归建模的重要工具：
- en: '[PRE1]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Note
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Formula notation is one of the best features of R, which lets you define flexible
    models in a human-friendly way. A typical model has the form of `response ~ terms`,
    where `response` is the continuous response variable, and `terms` provides one
    or a series of numeric variables that specifies a linear predictor for the response.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 公式表示法是R语言最好的特性之一，它允许你以人性化的方式定义灵活的模型。一个典型的模型具有`response ~ terms`的形式，其中`response`是连续的响应变量，而`terms`提供了一或一系列数值变量，这些变量指定了响应的线性预测因子。
- en: In the preceding example, the variable, `y`, denotes air pollution, while `x3`
    stands for the population size. The coefficient of `x3` says that a one unit (one
    thousand) increase in the population size causes a `0.02` unit (0.02 milligram
    per cubic meter) increase in the sulfur dioxide concentration, and the effect
    is statistically significant with a `p` value of `0.001035`.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的例子中，变量`y`表示空气污染，而`x3`代表人口规模。`x3`的系数表明人口规模每增加一个单位（一千人），二氧化硫浓度就会增加`0.02`个单位（每立方米的0.02毫克），并且这种效应在`p`值为`0.001035`的情况下具有统计学意义。
- en: Note
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: See more details on the p-value in the *How well does the line fit to the data?*
    section. To keep it simple for now, we will refer to models as statistically significant
    when the *p* value is below `0.05`.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在*线如何拟合数据？*部分中了解更多关于p值的细节。为了保持简单，现在我们将把p值低于`0.05`的模型称为具有统计学意义的模型。
- en: 'The intercept in general is the value of the response variable when each predictor
    equals to 0, but in this example, there are no cities without inhabitants, so
    the intercept (17.87) doesn''t have a direct interpretation. The two regression
    coefficients define the regression line:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，截距是当每个预测因子等于0时响应变量的值，但在这个例子中，没有没有居民的城市，所以截距（17.87）没有直接的解释。两个回归系数定义了回归线：
- en: '[PRE2]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![Model interpretation](img/2028OS_04_01.jpg)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![模型解释](img/2028OS_04_01.jpg)'
- en: 'As you can see, the intercept (**17.87**) is the value at which the regression
    line crosses the y-axis. The other coefficient (**0.02**) is the slope of the
    regression line: it measures how steep the line is. Here, the function runs uphill
    because the slope is positive (**y** increases as **x3** increases). Similarly,
    if the slope is negative, the function runs downhill.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，截距（**17.87**）是回归线与 y 轴相交的值。另一个系数（**0.02**）是回归线的斜率：它衡量线的陡峭程度。在这里，函数向上运行，因为斜率是正的（**y**
    随着 **x3** 的增加而增加）。同样，如果斜率是负的，函数就会向下运行。
- en: You can easily understand the way the estimates were obtained if you realize
    how the line was drawn. This is the line that best fits the data points. Here,
    we refer to the *best fit* as the linear least-squares approach, which is why
    the model is also known as the **ordinary least squares** (**OLS**) regression.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你意识到线是如何绘制的，你就可以轻松理解估计值是如何得到的。这是最适合数据点的线。在这里，我们将“最佳拟合”称为线性最小二乘法，这也是为什么该模型也被称为**普通最小二乘法**（**OLS**）回归。
- en: 'The least-squares method finds the best fitting line by minimizing the sum
    of the squares of the residuals, where the residuals represent the error, which
    is the difference between the observed value (an original dot in the scatterplot)
    and the fitted or predicted value (a dot on the line with the same *x*-value):'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 最小二乘法通过最小化残差的平方和来找到最佳拟合线，其中残差代表误差，即观测值（散点图中的一个原始点）与拟合值或预测值（与相同 *x* 值的线上的点）之间的差异：
- en: '[PRE3]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![Model interpretation](img/2028OS_04_02.jpg)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![模型解释](img/2028OS_04_02.jpg)'
- en: The *linear* term in linear regression refers to the fact that we are interested
    in a linear relation, which is more natural, easier to understand, and simpler
    to handle mathematically, as compared to the more complex methods.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归中的“线性”术语指的是我们感兴趣的是线性关系，这比更复杂的方法更自然、更容易理解，也更简单从数学上进行处理。
- en: Multiple predictors
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多个预测因子
- en: 'On the other hand, if we aim to model a more complex mechanism by separating
    the effect of the population size from the effect of the presence of industries,
    we have to control for the variable, `x2`, which describes the number of manufacturers
    employing more than 20 workers. Now, we can either create a new model by `lm(y
    ~ x3 + x2, data = usair)`, or use the `update` function to refit the previous
    model:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，如果我们旨在通过分离人口规模的影响和工业存在的影响来模拟更复杂的机制，我们必须控制变量 `x2`，它描述了雇佣超过 20 名工人的制造商数量。现在，我们可以通过
    `lm(y ~ x3 + x2, data = usair)` 创建一个新的模型，或者使用 `update` 函数重新拟合先前的模型：
- en: '[PRE4]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Now, the coefficient of `x3` is `-0.06`! While the crude association between
    air pollution and city size was positive in the previous model, after controlling
    for the number of manufacturers, the association becomes negative. This means
    that a one thousand increase in the population decreases the SO2 concentration
    by 0.06 unit, which is a statistically significant effect.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，`x3` 的系数是 `-0.06`！在先前的模型中，空气污染与城市规模之间的粗略关联是正的，但在控制了制造商数量之后，这种关联变为负的。这意味着人口增加一千会降低二氧化硫浓度
    0.06 单位，这是一个具有统计学意义的效应。
- en: On first sight, this change of sign from positive to negative may be surprising,
    but it is rather plausible after a closer look; it's definitely not the population
    size, but rather the level of industrialization that affects the air pollution
    directly. In the first model, population size showed a positive effect because
    it implicitly measured industrialization as well. When we hold industrialization
    fixed, the effect of the population size becomes negative, and growing a city
    with a fixed industrialization level spreads the air pollution in a wider range.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 初看之下，这种从正到负的符号变化可能令人惊讶，但在仔细观察后，这相当合理；这绝对不是人口规模，而是工业化水平直接影响了空气污染。在第一个模型中，人口规模显示出正效应，因为它隐含地测量了工业化。当我们保持工业化不变时，人口规模的影响变为负，以固定的工业化水平增长的城市会将空气污染扩散到更广泛的范围。
- en: So, we can conclude that `x2` is a confounder here, as it biases the association
    between `y` and `x3`. Although it is beyond the scope of our current research
    question, we can interpret the coefficient of `x2` as well. It says that holding
    the city size at a constant level, a one unit increase in the number of manufacturers
    increases the SO2 concentration by 0.08 mgs.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们可以得出结论，`x2` 在这里是一个混杂因素，因为它会偏倚 `y` 和 `x3` 之间的关联。尽管它超出了我们当前研究问题的范围，我们也可以解释
    `x2` 的系数。它表示，在保持城市规模恒定的情况下，制造商数量的每增加一个单位，SO2 浓度会增加 0.08 毫克。
- en: 'Based on the model, we can predict the expected value of the response for any
    combination of predictors. For example, we can predict the expected level of sulfur
    dioxide concentration for a city with 400,000 habitants and 150 manufacturers,
    each of whom employ more than 20 workers:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 根据模型，我们可以预测任何组合预测变量的响应的期望值。例如，我们可以预测一个有 40 万居民和 150 家制造商（每家制造商雇佣超过 20 名工人）的城市中二氧化硫浓度的预期水平：
- en: '[PRE5]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'You could also calculate the prediction by yourself, multiplying the values
    with the slopes, and then summing them up with the constant—all these numbers
    are simply copied and pasted from the previous model summary:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以自己计算预测值，将值乘以斜率，然后将它们与常数相加——所有这些数字都简单地从先前的模型摘要中复制粘贴过来：
- en: '[PRE6]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Note
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 备注
- en: Prediction outside the range of the data is known as extrapolation. The further
    the values are from the data, the riskier your prediction becomes. The problem
    is that you cannot check model assumptions (for example, linearity) outside of
    your sample data.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据范围之外进行预测被称为外推。值离数据越远，你的预测风险就越高。问题是，你无法检查模型假设（例如，线性）在样本数据之外。
- en: 'If you have two predictors, the regression line is represented by a surface
    in the three dimensional space, which can be easily shown via the `scatterplot3d`
    package:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有两个预测变量，回归线在三维空间中由一个曲面表示，这可以通过 `scatterplot3d` 包轻松展示：
- en: '[PRE7]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![Multiple predictors](img/2028OS_04_03.jpg)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![多个预测变量](img/2028OS_04_03.jpg)'
- en: 'As it''s rather hard to interpret this plot, let''s draw the 2-dimensional
    projections of this 3D graph, which might prove to be more informative after all.
    Here, the value of the third, non-presented variable is held at zero:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这个图很难解释，让我们绘制这个三维图的二维投影，这可能会在所有方面都更有信息量。在这里，第三个未呈现变量的值被保持在零：
- en: '[PRE8]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![Multiple predictors](img/2028OS_04_04.jpg)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![多个预测变量](img/2028OS_04_04.jpg)'
- en: According to the changed sign of the slope, it's well worth mentioning that
    the *y-x3* regression line has also changed; from uphill, it became downhill.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 根据斜率的符号变化，值得一提的是，*y-x3* 回归线也发生了变化；从上升趋势变为下降趋势。
- en: Model assumptions
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型假设
- en: 'Linear regression models with standard estimation techniques make a number
    of assumptions about the outcome variable, the predictor variables, and also about
    their relationship:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 使用标准估计技术的线性回归模型对结果变量、预测变量及其关系做出了一些假设：
- en: '*Y* is a continuous variable (not binary, nominal, or ordinal)'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*Y* 是一个连续变量（不是二进制、名义或有序的）'
- en: The errors (the residuals) are statistically independent
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 错误（残差）在统计上是独立的
- en: There is a stochastic linear relationship between *Y* and each *X*
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*Y* 与每个 *X* 之间存在随机线性关系'
- en: '*Y* has a normal distribution, holding each *X* fixed'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在固定每个 *X* 的情况下，*Y* 服从正态分布
- en: '*Y* has the same variance, regardless of the fixed value of the *X*s'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 无论 *X* 的固定值如何，*Y* 都具有相同的方差
- en: A violation of assumption **2** occurs in trend analysis, if we use time as
    the predictor. Since the consecutive years are not independent, the errors will
    not be independent from each other. For example, if we have a year with high mortality
    from a specific illness, then we can expect the mortality for the next year to
    also be high.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们使用时间作为预测变量，则在趋势分析中，如果违反假设 **2**，则会出现问题。由于连续年份不是独立的，误差将不会相互独立。例如，如果我们有一年因特定疾病死亡率高，那么我们可以预期下一年的死亡率也会很高。
- en: A violation of assumption (**3**) says that the relationship is not exactly
    linear, but there is a deviation from the linear trend line. Assumption **4**
    and **5** require the conditional distribution of *Y* to be normal and having
    the same variance, regardless of the fixed value of *X*s. They are needed for
    inferences of the regression (confidence intervals, *F*- and *t*-tests). Assumption
    **5** is known as the homoscedasticity assumption. If it is violated, heteroscedasticity
    holds.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 假设**3**的违反意味着关系不是完全线性的，而是偏离线性趋势线。假设**4**和**5**要求*Y*的条件分布是正态的，并且具有相同的方差，无论*X*的固定值如何。它们是回归推断（置信区间、*F*检验和*t*检验）所需的。假设**5**被称为同方差性假设。如果它被违反，则存在异方差性。
- en: 'The following plot helps in visualizing these assumptions with a simulated
    dataset:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表有助于使用模拟数据集可视化这些假设：
- en: '[PRE9]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![Model assumptions](img/2028OS_5_05.jpg)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![模型假设](img/2028OS_5_05.jpg)'
- en: Tip
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: The code bundle, available to be downloaded from the Packt Publishing homepage,
    includes a slightly longer code chunk for the preceding plot with some tweaks
    on the plot margins, legends, and titles. The preceding code block focuses on
    the major parts of the visualization, without wasting too much space in the printed
    book on the style details.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 可从Packt Publishing主页下载的代码包包含一个稍长的代码块，用于前面的图表，并对图表边距、图例和标题进行了一些调整。前面的代码块专注于可视化的主要部分，没有在打印的书籍中过多地浪费空间在样式细节上。
- en: We will discuss in more detail, how to assess the model assumptions in [Chapter
    9](ch09.html "Chapter 9. From Big to Small Data"), *From Big to Smaller Data*.
    If some of the assumptions fail, a possible solution is to look for outliers.
    If you have an outlier, do the regression analysis without that observation, and
    determine how the results differ. Ways of outlier detection will be discussed
    in more detail in [Chapter 8](ch08.html "Chapter 8. Polishing Data"), *Polishing
    Data*.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[第9章](ch09.html "第9章。从大数据到小数据")“从大数据到小数据”中更详细地讨论如何评估模型假设。如果某些假设失败，一个可能的解决方案是寻找异常值。如果你有一个异常值，不要该观测值进行回归分析，并确定结果如何不同。异常值检测的方法将在[第8章](ch08.html
    "第8章。数据抛光")“数据抛光”中更详细地讨论。
- en: 'The following example illustrates that dropping an outlier (observation number
    31) may make the assumptions valid. To quickly verify if a model''s assumptions
    are satisfied, use the `gvlma` package:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例说明，删除异常值（第31个观测值）可能会使假设有效。为了快速验证模型假设是否满足，请使用`gvlma`包：
- en: '[PRE10]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'It seems that three out of the five assumptions are not satisfied. However,
    if we build the very same model on the same dataset excluding the 31st observation,
    we get much better results:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来有五个假设中的三个没有得到满足。然而，如果我们从同一数据集中排除第31个观测值构建完全相同的模型，我们会得到更好的结果：
- en: '[PRE11]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This suggests that we must always exclude the 31st observation from the dataset
    when building regression models in the future sections.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这表明，在未来的章节中构建回归模型时，我们必须始终排除第31个观测值。
- en: However, it's important to note that it is not acceptable to drop an observation
    just because it is an outlier. Before you decide, investigate the particular case.
    If it turns out that the outlier is due to incorrect data, you should drop it.
    Otherwise, run the analysis, both with and without it, and state in your research
    report how the results changed and why you decided on excluding the extreme values.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，需要注意的是，仅仅因为观测值是异常值就排除它是不被接受的。在你做出决定之前，调查具体情况。如果发现异常值是由于数据错误导致的，你应该将其删除。否则，进行带有和不带有该观测值的分析，并在你的研究报告中说清楚结果如何变化以及你决定排除极端值的原因。
- en: Note
  id: totrans-82
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: You can fit a line for any set of data points; the least squares method will
    find the optimal solution, and the trend line will be interpretable. The regression
    coefficients and the R-squared coefficient are also meaningful, even if the model
    assumptions fail. The assumptions are only needed if you want to interpret the
    p-values, or if you aim to make good predictions.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以为任何一组数据点拟合一条线；最小二乘法将找到最优解，趋势线将是可解释的。即使模型假设失败，回归系数和R平方系数也是有意义的。假设仅在你想要解释p值或你旨在做出良好预测时才是必需的。
- en: How well does the line fit in the data?
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 这条线在数据中拟合得有多好？
- en: Although we know that the trend line is the best fitting among the possible
    linear trend lines, we don't know how well this fits the actual data. The significance
    of the regression parameters is obtained by testing the null hypothesis, which
    states that the given parameter equals to zero. The *F-test* in the output pertains
    to the hypothesis that each regression parameter is zero. In a nutshell, it tests
    the significance of the regression in general. A *p-value* below 0.05 can be interpreted
    as "the regression line is significant." Otherwise, there is not much point in
    fitting the regression model at all.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们知道趋势线是在可能的线性趋势线中拟合得最好的，但我们不知道它对实际数据的拟合程度如何。回归参数的显著性是通过检验零假设获得的，该假设指出给定的参数等于零。输出中的*F检验*涉及每个回归参数为零的假设。简而言之，它测试了回归的一般显著性。一个低于0.05的*p值*可以解释为“回归线是显著的”。否则，拟合回归模型几乎没有任何意义。
- en: However, even if you have a significant F-value, you cannot say too much about
    the fit of the regression line. We have seen that residuals characterize the error
    of the fit. The R-squared coefficient summarizes them into a single measure. *R-squared*
    is the proportion of the variance in the response variable explained by the regression.
    Mathematically, it is defined as the variance in the predicted *Y* values, divided
    by the variance in the observed *Y* values.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，即使你有显著的F值，你也不能对回归线的拟合说太多。我们已经看到，残差描述了拟合的误差。R平方系数将它们总结成一个单一指标。*R平方*是回归解释响应变量方差的比率。数学上，它定义为预测*Y*值的方差除以观察到的*Y*值的方差。
- en: Note
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: In some cases, despite the significant F-test, the predictors, according to
    the R-squared, explain only a small proportion (<10 percent) of the total variance.
    You can interpret this by saying that although the predictors have a statistically
    significant effect on the response, the response is formed by a mechanism that
    is much more complex than your model suggests. This phenomenon is common in the
    area of medicine or biology where complex biological processes are modeled, while
    it is less common in the area of econometrics, where macro-level, aggregated variables,
    which usually smooth out small variations in the data.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，尽管F检验显著，但根据R平方，预测因子仅解释了总方差的一小部分（<10%）。你可以这样解释：尽管预测因子对响应有统计学上的显著影响，但响应是由一个比你的模型所暗示的机制更为复杂的机制形成的。这种现象在医学或生物学领域很常见，在这些领域中，复杂的生物过程被建模，而在计量经济学领域则较少见，在计量经济学领域，通常是宏观层面的聚合变量，这些变量通常平滑了数据中的小变化。
- en: 'If we use the population size as the only predictor in our air pollution example,
    the R-squared equals 0.37, so we can say that 37 percent of the variation in SO2
    concentration can be explained by the size of the city:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们在空气污染的例子中只使用人口规模作为唯一的预测因子，R平方等于0.37，因此我们可以这样说：37%的SO2浓度变化可以由城市规模来解释：
- en: '[PRE12]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'After adding the number of manufacturers to the model, the R-squared increases
    dramatically and almost doubles its previous value:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型中添加制造商数量后，R平方显著增加，几乎翻了一番：
- en: '[PRE13]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Note
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: It's important to note here that every time you add an extra predictor to your
    model, the R-squared increases simply because you have more information to predict
    the response, even if the lastly added predictor doesn't have an important effect.
    Consequently, a model with more predictors may appear to have a better fit just
    because it is bigger.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 这里需要注意的是，每次你向模型中添加一个额外的预测因子，R平方都会增加，仅仅是因为你有了更多预测响应的信息，即使最后添加的预测因子没有重要的影响。因此，具有更多预测因子的模型可能看起来拟合得更好，仅仅是因为它更大。
- en: The solution is to use the adjusted R-squared, which takes into account the
    number of predictors as well. In the previous example, not only the R-squared
    but also the adjusted R-squared showed a huge advantage in favor of the latter
    model.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 解决方案是使用调整后的R平方，它考虑了预测因子的数量。在先前的例子中，不仅R平方，调整后的R平方也显示出对后者的巨大优势。
- en: The two previous models are nested, which means that the extended model contains
    each predictor of the first one. But unfortunately, the adjusted R-squared cannot
    be used as a base for choosing the best model for non-nested models. If you have
    non-nested models, you can use the **Akaike Information Criterion** (**AIC**)
    measure to select the best model.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 前两个模型是嵌套的，这意味着扩展模型包含第一个模型中的每个预测因子。但不幸的是，调整后的R平方不能用作选择非嵌套模型最佳模型的基础。如果你有非嵌套模型，你可以使用**赤池信息量准则**（**AIC**）来选择最佳模型。
- en: 'AIC is founded on the information theory. It introduces a penalty term for
    the number of parameters in the model, giving a solution for the problem of bigger
    models tending to show as better fitted. When using this criterion, you should
    select the model with the least AIC. As a rule of thumb, two models are essentially
    indistinguishable if the difference between their AICs is less than 2\. In the
    example that follows, we have two plausible alternative models. Taking the AIC
    into account, `model.4` is better than `model.3`, as its advantage over `model.3`
    is about 10:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: AIC基于信息理论。它为模型中参数的数量引入了一个惩罚项，为更大的模型倾向于显示更好的拟合问题提供了一个解决方案。当使用这个标准时，你应该选择AIC最小的模型。作为一个经验法则，如果两个模型的AIC差异小于2，那么这两个模型基本上是不可区分的。在下面的例子中，我们有两个合理的替代模型。考虑到AIC，`model.4`比`model.3`更好，因为它的优势大约是10：
- en: '[PRE14]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Note
  id: totrans-99
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 备注
- en: Note that AIC can tell nothing about the quality of the model in an absolute
    sense; your best model may still fit poorly. It does not provide a test for testing
    model fit either. It is essentially for ranking different models.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，AIC在绝对意义上无法说明模型的品质；你的最佳模型可能仍然拟合得不好。它也不提供测试模型拟合的测试。它本质上是为了对不同模型进行排名。
- en: Discrete predictors
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 离散预测因子
- en: 'So far, we have seen only the simple case of both the response and the predictor
    variables being continuous. Now, let''s generalize the model a bit, and enter
    a discrete predictor into the model. Take the `usair` data and add `x5` (precipitation:
    average number of wet days per year) as a predictor with three categories (low,
    middle, and high levels of precipitation), using 30 and 45 as the cut-points.
    The research question is how these precipitation groups are associated with the
    SO2 concentration. The association is not necessary linear, as the following plot
    shows:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们只看到了响应变量和预测变量都是连续的简单情况。现在，让我们将模型推广一点，并将一个离散预测因子纳入模型。以`usair`数据为例，添加`x5`（降水：每年湿天气的平均天数）作为有三个类别（低、中、高降水水平）的预测因子，使用30和45作为切分点。研究问题是这些降水组如何与SO2浓度相关联。这种关联不一定是线性的，如下面的图所示：
- en: '[PRE15]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '![Discrete predictors](img/2028OS_04_06.jpg)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![离散预测因子](img/2028OS_04_06.jpg)'
- en: 'The cut-points 30 and 45 were more or less ad hoc. An advanced way to define
    optimal cut-points is to use a regression tree. There are various implementations
    of classification trees in R; a commonly used function is `rpart` from the package
    with the very same name. The regression tree follows an iterative process that
    splits the data into partitions, and then continues splitting each partition into
    smaller groups. In each step, the algorithm selects the best split on the continuous
    precipitation scale, where the best point minimizes the sum of the squared deviations
    from the group-level SO2 mean:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 切分点30和45大致是临时的。定义最佳切分点的一个高级方法是使用回归树。R中有多种分类树的实现；常用的函数是来自同名包的`rpart`。回归树遵循一个迭代过程，将数据分割成分区，然后继续将每个分区分割成更小的组。在每一步中，算法选择在连续降水尺度上的最佳分割，最佳点最小化从组水平SO2均值的平方偏差之和：
- en: '[PRE16]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '![Discrete predictors](img/2028OS_04_07.jpg)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![离散预测因子](img/2028OS_04_07.jpg)'
- en: The interpretation of the preceding result is rather straightforward; if we
    are looking for two groups that differ highly regarding SO2, the optimal cut-point
    is a precipitation level of 45.34, and if we are looking for three groups, then
    we will have to split the second group by using the cut-point of 30.91, and so
    on. The four box-plots describe the SO2 distribution in the four partitions. So,
    these results confirm our previous assumption, and we have three precipitation
    groups that strongly differ in their level of SO2 concentration.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 对先前结果的理解相当直接；如果我们正在寻找两个在SO2方面高度不同的组，则最佳切分点是45.34的降水水平，如果我们正在寻找三个组，那么我们将不得不使用30.91的切分点来分割第二个组，依此类推。四个箱线图描述了四个分区中SO2的分布。因此，这些结果证实了我们的先前假设，并且我们有三个在SO2浓度水平上强烈不同的降水组。
- en: Tip
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: Take a look at [Chapter 10](ch10.html "Chapter 10. Classification and Clustering"),
    *Classification and Clustering*, for more details and examples on decisions trees.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 查看第[10章](ch10.html "第10章. 分类与聚类")，*分类与聚类*，以获取更多关于决策树的细节和示例。
- en: 'The following scatterplot also shows that the three groups differ heavily from
    each other. It seems that the SO2 concentration is highest in the middle group,
    and the two other groups are very similar:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的散点图也显示，三个组之间存在很大的差异。似乎中间组的SO2浓度最高，而其他两组非常相似：
- en: '[PRE17]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '![Discrete predictors](img/2028OS_04_08.jpg)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![离散预测因子](img/2028OS_04_08.jpg)'
- en: 'Now, let us refit our linear regression model by adding the three-category
    precipitation to the predictors. Technically, this goes by adding two dummy variables
    (learn more about this type of variable in [Chapter 10](ch10.html "Chapter 10. Classification
    and Clustering"), *Classification and Clustering*) pertaining to the second and
    third group, as shown in the table that follows:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们通过添加三个降水类别到预测因子中来重新拟合我们的线性回归模型。技术上，这通过添加两个与第二和第三组相关的虚拟变量（在[第10章](ch10.html
    "第10章. 分类与聚类")，*分类与聚类*）来实现，如下表所示：
- en: '|   | Dummy variables |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '|   | 虚拟变量 |'
- en: '| --- | --- |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Categories | first | second |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| 类别 | 第一 | 第二 |'
- en: '| --- | --- | --- |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| low (0-30) | 0 | 0 |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| 低（0-30） | 0 | 0 |'
- en: '| middle (30-45) | 1 | 0 |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| 中间（30-45） | 1 | 0 |'
- en: '| high (45+) | 0 | 1 |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| 高（45+） | 0 | 1 |'
- en: 'In R, you can run this model using the `glm` (Generalized Linear Models) function,
    because the classic linear regression doesn''t allow non-continuous predictors:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在R中，你可以使用`glm`（广义线性模型）函数运行此模型，因为经典线性回归不允许非连续预测因子：
- en: '[PRE18]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The second group (wet days between 30 and 45) has a higher average by 15.2 units
    of SO2, as compared to the first group. This is controlled by the population size
    and number of manufacturers. The difference is statistically significant.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 第二组（30到45天的湿润天气）的平均值比第一组高15.2个SO2单位。这是由人口规模和制造商数量控制的。这种差异在统计学上是显著的。
- en: On the contrary, the third group shows only a slight difference when compared
    to the first group (0.04 unit lower), which is not significant. The three group
    mean shows a reversed U-shaped curve. Note that if you used precipitation in its
    original continuous form, implicitly you would assume a linear relation, so you
    wouldn't discover this shape. Another important thing to note is that the U-shaped
    curve here describes the partial association (controlled for `x2` and `x3`), but
    the crude association, presented on the preceding scatterplot, showed a very similar
    picture.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，第三组与第一组相比（低0.04单位），只有轻微的差异，这不具有统计学意义。三个组均值显示一个倒U形曲线。请注意，如果你使用原始的连续形式的降水，你隐含地假设了一个线性关系，因此你不会发现这种形状。另一个需要注意的重要事项是，这里的U形曲线描述了部分关联（控制了`x2`和`x3`），但粗略的关联，在前面的散点图中呈现，显示了非常相似的图像。
- en: The regression coefficients were interpreted as the difference between the group
    means, and both groups were compared to the omitted category (the first one).
    This is why the omitted category is usually referred to as the reference category.
    This way of entering discrete predictors is called reference-category coding.
    In general, if you have a discrete predictor with *n* categories, you have to
    define (*n-1*) dummies. Of course, if other contrasts are of interest, you can
    easily modify the model by entering dummies referring to other (*n-1*) categories.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 回归系数被解释为组均值之间的差异，两组都与省略的类别（第一个）进行比较。这就是为什么省略的类别通常被称为参考类别。这种进入离散预测因子的方式被称为参考类别编码。一般来说，如果你有一个具有*n*个类别的离散预测因子，你必须定义(*n-1*)个虚拟变量。当然，如果你对其他对比感兴趣，你可以通过输入其他(*n-1*)个类别的虚拟变量来轻松修改模型。
- en: Note
  id: totrans-127
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 备注
- en: If you fit linear regression with discrete predictors, the regression slopes
    are the differences in the group means. If you also have other predictors, then
    the group-mean differences will be controlled for these predictors. Remember,
    the key feature of multivariate regression models is that they model partial two-way
    associations, holding the other predictors fixed.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你使用离散预测因子拟合线性回归，回归斜率是组均值之间的差异。如果你还有其他预测因子，那么组均值差异将受这些预测因子的控制。记住，多元回归模型的关键特征是它们在固定其他预测因子的条件下，建模部分双向关联。
- en: You can go further by entering any other types and any number of predictors.
    If you have an ordinal predictor, it is your decision whether to enter it in its
    original form, assuming a linear relation, or to form dummies and enter each of
    them, allowing any type of relation. If you have no background knowledge on how
    to make this decision, you can try both solutions and compare how the models fit.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过输入任何其他类型和任何数量的预测变量来进一步深入。如果你有一个有序预测变量，你可以决定是否以原始形式输入，假设线性关系，或者形成虚拟变量并分别输入每个变量，允许任何类型的关系。如果你没有关于如何做出这个决定的背景知识，你可以尝试两种解决方案并比较模型的拟合情况。
- en: Summary
  id: totrans-130
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This chapter introduced the concept of how to build and interpret basic models,
    such as linear regression models. By now, you should be familiar with the motivation
    behind linear regression models; you should know how to control for confounders,
    how to enter discrete predictors, how to fit models in R, and how to interpret
    the results.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了如何构建和解释基本模型的概念，例如线性回归模型。到目前为止，你应该熟悉线性回归模型背后的动机；你应该知道如何控制混杂因素，如何输入离散预测变量，如何在
    R 中拟合模型，以及如何解释结果。
- en: In the next chapter, we will extend this knowledge with generalized models,
    and analyzing the model fit.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将通过广义模型扩展这一知识，并分析模型拟合情况。
