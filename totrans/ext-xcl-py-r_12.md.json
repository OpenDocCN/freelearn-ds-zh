["```py\n# Library Load\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(healthyR)\nlibrary(readxl)\n# Source Functions\nsource(paste0(getwd(),\"/Chapter1/excel_sheet_reader.R\"))\n# Read data\nfile_path <- paste0(getwd(), \"/Chapter12/\")\ndf <- read_excel_sheets(\n  filename = paste0(file_path, \"diamonds_split.xlsx\"),\"),\n  single_tbl = TRUE\n)\n```", "```py\n# Library Load\nlibrary(tidyverse)\nlibrary(writexl)\nlibrary(janitor)\n# Write File to disk\nfile_path <- paste0(getwd(), \"/Chapter12/\")\n# Split data by cut and clean names of the list\ndf_list <- split(diamonds, diamonds$cut) |>\n  clean_names()\n# Write to xlsx\ndf_list |>\n  write_xlsx(paste0(file_path, \"diamonds_split.xlsx\"))\n```", "```py\nbreaks <- tibble(x = df$price) |>\n  opt_bin(x) |>\n  pull(value)\nhead(breaks)\n[1]  326.000 1130.217 1934.435 2738.652 3542.870 4347.087\n```", "```py\npar(mfrow = c(1, 2))\nhist(df$price, main = \"Price Histogram - Default binning\",\n      xlab = \"Price\", ylab = \"Frequency\")\nhist(df$price, breaks = breaks, main = \"Price Histogram - Optimal binning\",\n      xlab = \"Price\", ylab = \"Frequency\")\npar(mfrow = c(1, 1))\n```", "```py\ndf |>\n  ggplot(aes(x = carat, y = price, fill = cut)) +\n  geom_hex(bins = length(breaks), alpha = 1/5) +\n  facet_wrap(~ clarity, scales = \"free\") +\n  theme_minimal() +\n  labs(\n     x = \"Carat\",\n     y = \"Price\",\n     title = \"Diamonds Data\",\n     fill = \"Cut\"\n  ) +\n  hr_scale_color_colorblind()\n```", "```py\ndf |>\n  ggplot(aes(x = carat, y = price, fill = cut)) +\n  geom_boxplot(alpha = 1/5, outlier.color = \"lightgrey\") +\n  facet_wrap(~ clarity, scales = \"free\") +\n  theme_minimal() +\n  labs(\n     x = \"Carat\",\n     y = \"Price\",\n     title = \"Diamonds Data\",\n     fille = \"Cut\"\n  ) +\n  hr_scale_color_colorblind()\n```", "```py\ndf |>\n  summarize(m = mean(price), .by = c(clarity, cut)) |>\n  ggplot(aes(x = clarity, y = m, group = cut, color = cut)) +\n  geom_point() +\n  geom_line() +\n  geom_smooth() +\n  facet_wrap(~cut, ncol = 2) +\n  labs(x= \"Clarity\",\n         y = \"Mean Price\",\n         title = \"Mean Price by Clarity and Cut\",\n         color = \"Cut\") +\n  theme_minimal() +\n  hr_scale_color_colorblind()\n```", "```py\ndf |>\n  summarize(m = mean(price/carat), .by = c(cut, color, clarity)) |>\n  ggplot(aes(x = color, y = m, group = clarity, color = clarity)) +\n  geom_point() +\n  geom_line() +\n  facet_wrap(~ cut, ncol = 2, scales = \"free\") +\n  labs(x= \"Clarity\",\n         y = \"Mean Price\",\n         title = \"Mean Price per Carat by Clarity, Color and Cut\",\n         color = \"Cut\") +\n  theme_minimal() +\n  hr_scale_color_colorblind()\n```", "```py\ndf |>\n  ggplot(aes(x = price)) +\n  geom_histogram(breaks = breaks, fill = \"lightblue\",\n                        color = \"black\") +\n  theme_minimal() +\n  facet_wrap(~ cut, ncol = 2, scales = 'free') +\n  labs(x = \"Price\", y = \"Frequency\", title = \"Price Histogram by Cut\")\n```", "```py\n# Lib Load\nlibrary(healthyR.ai)\nlibrary(dplyr)\nglimpse(head(df, 2))\nRows: 2\nColumns: 10\n$ carat   <dbl> 0.22, 0.86\n$ cut      <chr> \"Fair\", \"Fair\"\n$ color   <chr> \"E\", \"E\"\n$ clarity <chr> \"VS2\", \"SI2\"\n$ depth   <dbl> 65.1, 55.1\n$ table   <dbl> 61, 69\n$ price   <dbl> 337, 2757\n$ x         <dbl> 3.87, 6.45\n$ y         <dbl> 3.78, 6.33\n$ z         <dbl> 2.49, 3.52\n```", "```py\n# Pass data through pre-processor\nrec_obj <- hai_xgboost_data_prepper(\n  .data = df,\n  .recipe_formula = price ~ .\n)\nrec_obj\n── Recipe ───────────\n── Inputs\nNumber of variables by role\noutcome:   1\npredictor: 9\n── Operations\n• Factor variables from: tidyselect::vars_select_helpers$where(is.character)\n• Novel factor level assignment for: recipes::all_nominal_predictors()\n• Dummy variables from: recipes::all_nominal_predictors()\n• Zero variance filter on: recipes::all_predictors()\n```", "```py\n# Now see the juiced output\nget_juiced_data(rec_obj) |>\n  head(2) |>\n  glimpse()\nRows: 2\nColumns: 24\n$ carat            <dbl> 0.22, 0.86\n$ depth            <dbl> 65.1, 55.1\n$ table            <dbl> 61, 69\n$ x                  <dbl> 3.87, 6.45\n$ y                  <dbl> 3.78, 6.33\n$ z                  <dbl> 2.49, 3.52\n$ price            <dbl> 337, 2757\n$ cut_Good        <dbl> 0, 0\n$ cut_Ideal      <dbl> 0, 0\n$ cut_Premium   <dbl> 0, 0\n$ cut_Very.Good <dbl> 0, 0\n$ color_E         <dbl> 1, 1\n$ color_F         <dbl> 0, 0\n$ color_G         <dbl> 0, 0\n$ color_H         <dbl> 0, 0\n$ color_I         <dbl> 0, 0\n$ color_J         <dbl> 0, 0\n$ clarity_IF     <dbl> 0, 0\n$ clarity_SI1   <dbl> 0, 0\n$ clarity_SI2   <dbl> 0, 1\n$ clarity_VS1   <dbl> 0, 0\n$ clarity_VS2   <dbl> 1, 0\n$ clarity_VVS1  <dbl> 0, 0\n$ clarity_VVS2  <dbl> 0, 0\n```", "```py\nhai_auto_xgboost(\n  .data,\n  .rec_obj,\n  .splits_obj = NULL,\n  .rsamp_obj = NULL,\n  .tune = TRUE,\n  .grid_size = 10,\n  .num_cores = 1,\n  .best_metric = \"f_meas\",\n  .model_type = \"classification\"\n)\n```", "```py\nauto_xgb <- hai_auto_xgboost(\n  .data = df,\n  .rec_obj = rec_obj,\n  .best_metric = \"rsq\",\n  .num_cores = 10,\n  .model_type = \"regression\"\n)\n```", "```py\nxgb_wflw_fit <- auto_xgb$model_info$fitted_wflw\nclass(xgb_wflw_fit)\n[1] \"workflow\"\nmod_spec <- xgb_wflw_fit[[\"fit\"]][[\"actions\"]][[\"model\"]][[\"spec\"]]\nmod_spec\nBoosted Tree Model Specification (regression)\nMain Arguments:\n  trees = 817\n  min_n = 17\n  tree_depth = 9\n  learn_rate = 0.0205081386887847\n  loss_reduction = 2.0421383990836e-05\n  sample_size = 0.762693894910626\nComputational engine: xgboost\n```", "```py\nimport pandas as pd\n# Define the file path (may be different for you)\nfile_path = \"./Chapter 12/diamonds.xlsx\"\n# Load the dataset into a pandas DataFrame\ndf = pd.read_excel(file_path)\n# Display the first few rows of the DataFrame\nprint(df.head())\n```", "```py\nfrom plotnine import ggplot, aes, geom_bin2d, facet_wrap, theme_minimal, labs, scale_fill_manual\n# Define a colorblind-friendly color palette\ncolor_palette = [\"#E69F00\", \"#56B4E9\", \"#009E73\", \"#F0E442\", \"#0072B2\", \"#D55E00\", \"#CC79A7\"]\n# Plot using plotnine\n(\n    ggplot(df, aes(x='carat', y='price', fill='cut')) +\n    geom_bin2d(bins=20) +  # Adjust the bins parameter as needed\n    facet_wrap('~ clarity', scales='free') +\n    theme_minimal() +\n    labs(\n        x='Carat',\n        y='Price',\n        title='Diamonds Data',\n        fill='Cut'\n    ) +\n    scale_fill_manual(values=color_palette)\n)\n```", "```py\nfrom plotnine import geom_boxplot\n# Plot using plotnine\n(\n    ggplot(df, aes(x='carat', y='price', fill='cut')) +\n    geom_boxplot(alpha=1/5, outlier_color=\"lightgrey\") +\n    facet_wrap('~ clarity', scales='free') +\n    theme_minimal() +\n    labs(\n        x='Carat',\n        y='Price',\n        title='Diamonds Data',\n        fill='Cut'\n    ) +\n    scale_fill_manual(values=color_palette)\n)\n```", "```py\nfrom plotnine import geom_point, geom_line, geom_smooth, scale_color_manual\n# Plot the mean price\n(\n    ggplot(df.groupby(['clarity', 'cut']).mean().reset_index(), aes(x='clarity', y='price', group='cut', color='cut')) +\n    geom_point() +\n    geom_line() +\n    geom_smooth() +\n    facet_wrap('~ cut', ncol=2) +\n    labs(\n        x='Clarity',\n        y='Mean Price',\n        title='Mean Price by Clarity and Cut',\n        color='Cut'\n    ) +\n    theme_minimal() +\n    scale_color_manual(values=color_palette)\n)\n```", "```py\n# Calculate mean price per carat by clarity, color, and cut\ndf_mean = df.groupby(['cut', 'color', 'clarity']).apply(lambda x: (x['price'] / x['carat']).mean()).reset_index(name='m')\n# Plot using plotnine\n(\n        ggplot(df_mean, aes(x='color', y='m', group='clarity', color='clarity')) +\n        geom_point() +\n        geom_line() +\n        facet_wrap('~ cut', ncol=2, scales='free') +\n        labs(\n                x='Clarity',\n                y='Mean Price',\n                title='Mean Price per Carat by Clarity, \n                Color and Cut',\n                color='Cut'\n        ) +\n        scale_color_manual(values=color_palette)\n)\n```", "```py\nfrom plotnine import geom_histogram\n# Create a histogram of price by Cut\n(\n        ggplot(df, aes(x='price')) +\n        geom_histogram(fill='lightblue', color='black') +\n        theme_minimal() +\n        facet_wrap('~ cut', ncol=2, scales='free') +\n        labs(x='Price', y='Frequency', title='Price Histogram by Cut')\n)\n```", "```py\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\n# Encode categorical variables\nencoder = OneHotEncoder()\ndf_encoded = encoder.fit_transform(df[['cut', 'color', 'clarity']])\n# Scale numerical features\nscaler = StandardScaler()\ndf_scaled = scaler.fit_transform(df[['carat', 'depth', 'table', \n    'x', 'y', 'z']])\n# Concatenate encoded categorical features with scaled numerical features\ndf_processed = np.concatenate((df_encoded.toarray(), df_scaled),\n    axis=1)\n# Split data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(\n    df_processed, df[\"price\"], test_size=0.2, random_state=42)\n```", "```py\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.metrics import mean_squared_error\n# Instantiate XGBoost regressor\nxgb_reg = GradientBoostingRegressor(random_state=42)\n# Train the model\nxgb_reg.fit(X_train, y_train)\n# Predict on the test set\ny_pred = xgb_reg.predict(X_test)\n# Calculate RMSE\nrmse = np.sqrt(mean_squared_error(y_test, y_pred))\nprint(\"Root Mean Squared Error:\", rmse)\n```"]