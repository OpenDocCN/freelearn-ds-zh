<html><head></head><body><div><div><p><a id="_idTextAnchor054"/></p>
			<h1 id="_idParaDest-55"><a id="_idTextAnchor055"/>Chapter 3: Linguistic Features</h1>
			<p>This chapter is a deep dive into the full power of spaCy. You will discover the linguistic features, including spaCy's most commonly used features such as the <strong class="bold">part-of-speech (POS) tagger</strong>, the <strong class="bold">dependency parser</strong>, the <strong class="bold">named entity recognizer</strong>, and <strong class="bold">merging/splitting</strong> features.</p>
			<p>First, you'll learn the POS tag concept, how the spaCy POS tagger functions, and how to place POS tags into your <strong class="bold">natural-language understanding</strong> (<strong class="bold">NLU</strong>) applications. Next, you'll learn a structured way to represent the sentence syntax through the dependency parser. You'll learn about the dependency labels of spaCy and how to interpret the spaCy dependency labeler results with revealing examples. Then, you'll learn a very important NLU concept that lies at the heart of many <strong class="bold">natural language processing</strong> (<strong class="bold">NLP</strong>) applications—<strong class="bold">named entity recognition</strong> (<strong class="bold">NER</strong>). We'll go over examples of how to extract information from the text using NER. Finally, you'll learn how to merge/split the entities you extracted.</p>
			<p>In this chapter, we're going to cover the following main topics:</p>
			<ul>
				<li>What is POS tagging?</li>
				<li>Introduction to dependency parsing</li>
				<li>Introducing NER</li>
				<li>Merging and splitting tokens</li>
			</ul>
			<h1 id="_idParaDest-56"><a id="_idTextAnchor056"/>Technical requirements </h1>
			<p>The chapter code can be found at the book's GitHub repository: <a href="https://github.com/PacktPublishing/Mastering-spaCy/tree/main/Chapter03">https://github.com/PacktPublishing/Mastering-spaCy/tree/main/Chapter03</a></p>
			<h1 id="_idParaDest-57"><a id="_idTextAnchor057"/>What is POS tagging?</h1>
			<p>We <a id="_idIndexMarker132"/>saw the terms <em class="italic">POS tag</em> and <em class="italic">POS tagging</em> briefly in the previous chapter, while discussing the spaCy <code>Token</code> class features. As is obvious from the name, they refer to the process of tagging tokens with POS tags. One question remains here: <em class="italic">What is a POS tag?</em> In this section, we'll discover in detail the concept of POS and how to make the most of it in our NLP applications.</p>
			<p>The <strong class="bold">POS tagging</strong> acronym expands as <strong class="bold">part-of-speech tagging</strong>. A <strong class="bold">part of speech</strong> is a <a id="_idIndexMarker133"/>syntactic category in which every <a id="_idIndexMarker134"/>word falls into a category according to its function in a sentence. For example, English has nine main categories: verb, noun, pronoun, determiner, adjective, adverb, preposition, conjunction, and interjection. We can describe <a id="_idIndexMarker135"/>the functions of each category as follows:</p>
			<ul>
				<li><strong class="bold">Verb</strong>: Expresses an action or a state of being</li>
				<li><strong class="bold">Noun</strong>: Identifies a person, a place, or a thing, or names a particular of one of these (a proper noun)</li>
				<li><strong class="bold">Pronoun</strong>: Can replace a noun or noun phrase</li>
				<li><strong class="bold">Determiner</strong>: Is placed in front of a noun to express a quantity or clarify what the noun refers to—briefly, a noun introducer</li>
				<li><strong class="bold">Adjective</strong>: Modifies a noun or a pronoun</li>
				<li><strong class="bold">Adverb</strong>: Modifies a verb, an adjective, or another adverb</li>
				<li><strong class="bold">Preposition</strong>: Connects a noun/pronoun to other parts of the sentence</li>
				<li><strong class="bold">Conjunction</strong>: Glues words, clauses, and sentences together </li>
				<li><strong class="bold">Interjection</strong>: Expresses emotion in a sudden and exclamatory way</li>
			</ul>
			<p>This core set <a id="_idIndexMarker136"/>of categories, without any language-specific morphological or syntactic features, are called <code>pos_</code> feature and describes them with examples, as follows:</p>
			<div><div><img src="img/B16570_03_01.jpg" alt="Figure 3.1 – spaCy universal tags explained with examples &#13;&#10;" width="1533" height="696"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.1 – spaCy universal tags explained with examples </p>
			<p>Throughout the book, we are providing examples with the English language and, in this section, we'll therefore focus on English. Different languages offer different tagsets, and spaCy supports <a id="_idIndexMarker137"/>different tagsets via <code>tag_map.py</code> under each language submodule. For example, the current English tagset lies under <code>lang/en/tag_map.py</code> and the German tagset lies under <code>lang/de/tag_map.py</code>. Also, the same language can support different tagsets; for this reason, spaCy and other NLP libraries always <em class="italic">specify</em> which tagset they use. The spaCy English POS tagger uses the <code>Ontonotes 5</code> tagset, and the German POS tagger uses the <code>TIGER Treebank</code> tagset.</p>
			<p>Each supported language of spaCy admits its own fine-grained tagset and tagging scheme, a specific tagging scheme that usually covers morphological features, tenses and aspects of verbs, number of nouns (singular/plural), person and number information of pronouns (first-, second-, third-person singular/plural), pronoun type (personal, demonstrative, interrogative), adjective type (comparative or superlative), and so on.</p>
			<p>spaCy supports fine-grained POS tags to answer language-specific needs, and the <code>tag_</code> feature corresponds to the fine-grained tags. The following screenshot shows us a part of these fine-grained POS tags and their mappings to more universal POS tags for English:</p>
			<div><div><img src="img/B16570_03_02.jpg" alt="Figure 3.2 – Fine-grained English tags and universal tag mappings&#13;&#10;" width="1525" height="810"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.2 – Fine-grained English tags and universal tag mappings</p>
			<p>Don't worry if you haven't worked with POS tags before, as you'll become familiar by practicing with <a id="_idIndexMarker138"/>the help of our examples. We'll always include explanations of the tags that we use. You can also call <code>spacy.explain()</code> on the tags. We usually call <code>spacy.explain()</code> in two ways, either directly on the tag name string or with <code>token.tag_</code>, as illustrated in the following code snippet:</p>
			<pre> spacy.explain("NNS)
'noun, plural'
 doc = nlp("I saw flowers.")
 token = doc[2]
 token.text, token.tag_, spacy.explain(token.tag_)
('flowers', 'NNS', 'noun, plural')</pre>
			<p>If you want to know more about POS, you can read more about it at two excellent resources: <em class="italic">Part of Speech</em> at http://partofspeech.org/, and the <em class="italic">Eight Parts of Speech</em> at <a href="http://www.butte.edu/departments/cas/tipsheets/grammar/parts_of_speech.html">http://www.butte.edu/departments/cas/tipsheets/grammar/parts_of_speech.html</a>.</p>
			<p>As you can see, POS tagging offers a very basic syntactic understanding of the sentence. POS tags are used in NLU extensively; we frequently want to find the verbs and the nouns in a sentence and better disambiguate some words for their meanings (more on this subject soon).</p>
			<p>Each word <a id="_idIndexMarker139"/>is tagged by a POS tag depending on its <em class="italic">context</em>—the other surrounding words and their POS tags. POS taggers are sequential statistical models, which means <em class="italic">that a tag of a word depends on the word-neighbor tokens, their tags, and the word itself</em>. POS tagging has always been done <a id="_idIndexMarker140"/>in different forms. <strong class="bold">Sequence-to-sequence learning</strong> (<strong class="bold">Seq2seq</strong>) started with <strong class="bold">Hidden Markov Models</strong> (<strong class="bold">HMMs</strong>) in the <a id="_idIndexMarker141"/>early days and evolved to neural network models—typically, <strong class="bold">long short-term memory</strong> (<strong class="bold">LSTM</strong>) variations (spaCy also uses an LSTM variation). You <a id="_idIndexMarker142"/>can witness the evolution of state-of-art POS tagging on the ACL website (<a href="https://aclweb.org/aclwiki/POS_Tagging_(State_of_the_art">https://aclweb.org/aclwiki/POS_Tagging_(State_of_the_art</a>)).</p>
			<p>It's time for some code now. Again, spaCy offers universal POS tags via the <code>token.pos (int)</code> and <code>token.pos_ (unicode)</code> features. The fine-grained POS tags are available via the <code>token.tag (int)</code> and <code>token.tag_ (unicode)</code> features. Let's learn more about tags that you'll come across most, through some examples. The following example includes examples of noun, proper noun, pronoun, and verb tags:</p>
			<pre> import spacy
 nlp = spacy.load("en_core_web_md")
 doc = nlp("Alicia and me went to the school by bus.")
 for token in doc:
     token.text, token.pos_, token.tag_, \
     spacy.explain(token.pos_), spacy.explain(token.tag_)
...
('Alicia', 'PROPN', 'NNP', 'proper noun', 'noun, proper singular')
('and', 'CCONJ', 'CC', 'coordinating conjunction', 'conjunction, coordinating')
('me', 'PRON', 'PRP', 'pronoun', 'pronoun, personal')
('went', 'VERB', 'VBD', 'verb', 'verb, past tense')
('to', 'ADP', 'IN', 'adposition', 'conjunction, subordinating or preposition')
('school', 'NOUN', 'NN', 'noun', 'noun, singular or mass')
('with', 'ADP', 'IN', 'adposition', 'conjunction, subordinating or preposition')
('bus', 'NOUN', 'NN', 'noun', 'noun, singular or mass')
('.', 'PUNCT', '.', 'punctuation', 'punctuation mark, sentence closer')</pre>
			<p>We iterated <a id="_idIndexMarker143"/>over the tokens and printed the tokens' text, universal tag, and fine-grained tag, together with the explanations, which are outlined here:</p>
			<ul>
				<li><code>Alicia</code> is a proper noun, as expected, and <code>NNP</code> is a tag for proper nouns.</li>
				<li><code>me</code> is a pronoun and <code>bus</code> is a noun. <code>NN</code> is a tag for singular nouns and <code>PRP</code> is a personal pronoun tag. </li>
				<li>Verb tags start with <code>V</code>. Here, <code>VBD</code> is a tag for <em class="italic">went</em>, which is a past-tense verb.</li>
			</ul>
			<p>Now, consider the following sentence:</p>
			<pre> doc = nlp("My friend will fly to New York fast and she is staying there for 3 days.")
 for token in doc:
     token.text, token.pos_, token.tag_, \
     spacy.explain(token.pos_), spacy.explain(token.tag_)
…
('My', 'DET', 'PRP$', 'determiner', 'pronoun, possessive')
('friend', 'NOUN', 'NN', 'noun', 'noun, singular or mass')
('will', 'VERB', 'MD', 'verb', 'verb, modal auxiliary')
('fly', 'VERB', 'VB', 'verb', 'verb, base form')
('to', 'ADP', 'IN', 'adposition', 'conjunction, subordinating or preposition')
('New', 'PROPN', 'NNP', 'proper noun', 'noun, proper singular')
('York', 'PROPN', 'NNP', 'proper noun', 'noun, proper singular')
('fast', 'ADV', 'RB', 'adverb', 'adverb')
('and', 'CCONJ', 'CC', 'coordinating conjunction', 'conjunction, coordinating')
('she', 'PRON', 'PRP', 'pronoun', 'pronoun, personal')
('is', 'AUX', 'VBZ', 'auxiliary', 'verb, 3rd person singular present')
('staying', 'VERB', 'VBG', 'verb', 'verb, gerund or present participle')
('there', 'ADV', 'RB', 'adverb', 'adverb')
('for', 'ADP', 'IN', 'adposition', 'conjunction, subordinating or preposition')
('3', 'NUM', 'CD', 'numeral', 'cardinal number')
('days', 'NOUN', 'NNS', 'noun', 'noun, plural')
('.', 'PUNCT', '.', 'punctuation', 'punctuation mark, sentence closer')</pre>
			<p>Let's start <a id="_idIndexMarker144"/>with the verbs. As we pointed out in the first example, verb tags start with <code>V</code>. Here, there are three verbs, as follows: </p>
			<ul>
				<li><code>fly</code>: a base form </li>
				<li><code>staying</code>: an <em class="italic">-ing</em> form </li>
				<li><code>is</code>: an auxiliary verb</li>
			</ul>
			<p>The corresponding tags are <code>VB</code>, <code>VBG</code>, and <code>VBZ</code>. </p>
			<p>Another detail is both <code>New</code> and <code>York</code> are tagged as proper nouns. If a proper noun consists of multiple tokens, then all the tokens admit the tag <code>NNP</code>. <code>My</code> is a possessive pronoun and is tagged as <code>PRP$</code>, in contrast to the preceding personal pronoun <code>me</code> and its tag <code>PRP</code>.</p>
			<p>Let's continue with a word that can be a verb or noun, depending on the context: <code>ship</code>. In the following sentence, <code>ship</code> is used as a verb:</p>
			<pre> doc = nlp("I will ship the package tomorrow.")
 for token in doc:
     token.text, token.tag_, spacy.explain(token.tag_)
... 
('I', 'PRP', 'pronoun, personal')
('will', 'MD', 'verb, modal auxiliary')
('ship', 'VB', 'verb, base form')
('the', 'DT', 'determiner')
('package', 'NN', 'noun, singular or mass')
('tomorrow', 'NN', 'noun, singular or mass')
('.', '.', 'punctuation mark, sentence closer') </pre>
			<p>Here, <code>ship</code> is tagged <a id="_idIndexMarker145"/>as a verb, as we expected. Our next sentence also contains the word <code>ship</code>, but as a noun. Now, can the spaCy tagger tag it correctly? Have a look at the following code snippet to find out:</p>
			<pre> doc = nlp("I saw a red ship.")
 for token in doc:
...  token.text, token.tag_, spacy.explain(token.tag_)
... 
('I', 'PRP', 'pronoun, personal')
('saw', 'VBD', 'verb, past tense')
('a', 'DT', 'determiner')
('red', 'JJ', 'adjective')
('ship', 'NN', 'noun, singular or mass')
('.', '.', 'punctuation mark, sentence closer')</pre>
			<p><em class="italic">Et voilà</em>! This time, the word <code>ship</code> is now tagged as a noun, as we wanted to see. The tagger looked <a id="_idIndexMarker146"/>at the surrounding words; here, <code>ship</code> is used with a determiner and an adjective, and spaCy deduced that it should be a noun. </p>
			<p>How about this tricky sentence:</p>
			<pre> doc = nlp("My cat will fish for a fish tomorrow in a fishy way.")
 for token in doc:
     token.text, token.pos_, token.tag_, \
     spacy.explain(token.pos_), spacy.explain(token.tag_)
…
('My', 'DET', 'PRP$', 'determiner', 'pronoun, possessive')
('cat', 'NOUN', 'NN', 'noun', 'noun, singular or mass')
('will', 'VERB', 'MD', 'verb', 'verb, modal auxiliary')
('fish', 'VERB', 'VB', 'verb', 'verb, base form')
('for', 'ADP', 'IN', 'adposition', 'conjunction, subordinating or preposition')
('a', 'DET', 'DT', 'determiner', 'determiner')
('fish', 'NOUN', 'NN', 'noun', 'noun, singular or mass')
('tomorrow', 'NOUN', 'NN', 'noun', 'noun, singular or mass')
('in', 'ADP', 'IN', 'adposition', 'conjunction, subordinating or preposition')
('a', 'DET', 'DT', 'determiner', 'determiner')
('fishy', 'ADJ', 'JJ', 'adjective', 'adjective')
('way', 'NOUN', 'NN', 'noun', 'noun, singular or mass')
('.', 'PUNCT', '.', 'punctuation', 'punctuation mark, sentence closer')</pre>
			<p>We wanted to fool the tagger with the different usages of the word <code>fish</code>, but the tagger is intelligent enough to distinguish the verb <code>fish</code>, the noun <code>fish</code>, and the adjective <code>fishy</code>. Here's how it did it:</p>
			<ul>
				<li>Firstly, <code>fish</code> comes right after the modal verb <code>will</code>, so the tagger recognized it as a verb.</li>
				<li>Secondly, <code>fish</code> serves as the object of the sentence and is qualified by a determiner; the tag is most probably a noun.</li>
				<li>Finally, <code>fishy</code> ends in <code>y</code> and comes before a noun in the sentence, so it's clearly an adjective.</li>
			</ul>
			<p>The spaCy tagger made a very smooth job here of predicting a tricky sentence. After examples of very accurate tagging, only one question is left in our minds: <em class="italic">Why do we need the POS tags?</em></p>
			<p>What is the <a id="_idIndexMarker147"/>importance of POS tags in NLU, and why do we need to distinguish the class of the words anyway? The answer is simple: many applications need to know the word type for better accuracy. Consider machine translation systems for an example of this: the words for <code>fish (V)</code> and <code>fish (N)</code> correspond to different words in Spanish, as illustrated in the following code snippet:</p>
			<pre>I will fish/VB tomorrow.  -&gt;  Pescaré/V mañana.
I eat fish/NN.  -&gt; Como pescado/N.</pre>
			<p>Syntactic information can be used in many NLU tasks, and playing some POS tricks can help your NLU code a lot. Let's continue with a traditional problem: <strong class="bold">word-sense disambiguation</strong> (<strong class="bold">WSD</strong>), and how to tackle it with the help of the spaCy tagger.</p>
			<h2 id="_idParaDest-58"><a id="_idTextAnchor058"/>WSD</h2>
			<p><strong class="bold">WSD</strong> is a <a id="_idIndexMarker148"/>classical NLU problem of deciding in which <em class="italic">sense</em> a particular word is used in a sentence. A word can have many senses—for instance, consider the word <em class="italic">bass</em>. Here are some senses we can think of:</p>
			<ul>
				<li>Bass—seabass, fish (<code>N</code>))</li>
				<li>Bass—lowest male voice (<code>N</code>)</li>
				<li>Bass—male singer with lowest voice range (<code>N</code>)</li>
			</ul>
			<p>Determining the sense of the word can be crucial in search engines, machine translation, and question-answering systems. For the preceding example, <em class="italic">bass</em>, a POS tagger is unfortunately not much of help as the tagger labels all senses with a noun tag. We need more than a POS tagger. How about the word <em class="italic">beat</em>? Let's have a look at this here:</p>
			<ul>
				<li>Beat—to strike violently (<code>V</code>))</li>
				<li>Beat—to defeat someone else in a game or a competition (<code>V</code>)</li>
				<li>Beat—rhythm in music or poetry (<code>N</code>)</li>
				<li>Beat—bird wing movement (<code>N</code>)</li>
				<li>Beat—completely exhausted (<code>ADJ</code>))</li>
			</ul>
			<p>Here, POS tagging <a id="_idIndexMarker149"/>can help a lot indeed. The <code>ADJ</code> tag determines the word sense definitely; if the word <em class="italic">beat</em> is tagged as <code>ADJ</code>, it identifies the sense <em class="italic">completely exhausted</em>. This is not true for the <code>V</code> and <code>N</code> tags here; if the word <em class="italic">beat</em> is labeled with a <code>V</code> tag, its sense can be <em class="italic">to strike violently</em> or <em class="italic">to defeat someone else</em>. WSD is an open problem, and many complicated statistical models are proposed. However, if you need a quick prototype, you can tackle this problem in some cases (such as in the preceding example) with the help of the spaCy tagger. </p>
			<h2 id="_idParaDest-59"><a id="_idTextAnchor059"/>Verb tense and aspect in NLU applications</h2>
			<p>In the <a id="_idIndexMarker150"/>previous chapter, we used the example of the travel <a id="_idIndexMarker151"/>agency application where we got the base <a id="_idIndexMarker152"/>forms (which are freed from verb tense and aspect) of <a id="_idIndexMarker153"/>the verbs by using <strong class="bold">lemmatization</strong>. In this subsection, we'll <a id="_idIndexMarker154"/>focus on how to use the verb tense and aspect information that we lost during the lemmatization process.</p>
			<p><strong class="bold">Verb tense</strong> and <strong class="bold">aspect</strong> are maybe the most interesting information that verbs provide us, telling <a id="_idIndexMarker155"/>us when the action happened in time and if the action of <a id="_idIndexMarker156"/>the verb is finished or ongoing. Tense and aspect together indicate a verb's reference to the current time. English has three basic tenses: past, present, and future. A tense is accompanied by either simple, progressive/continuous, or perfect aspects. For instance, in the sentence <em class="italic">I'm eating</em>, the action <em class="italic">eat</em> happens in the present and is ongoing, hence we describe this verb as <em class="italic">present progressive/continuous</em>. </p>
			<p>So far, so <a id="_idIndexMarker157"/>good. So, how do we use this information <a id="_idIndexMarker158"/>in our travel agency NLU, then? Consider <a id="_idIndexMarker159"/>the following customer sentences that can be directed <a id="_idIndexMarker160"/>to our NLU application:</p>
			<pre>I flew to Rome.
I have flown to Rome.
I'm flying to Rome.
I need to fly to Rome.
I will fly to Rome.</pre>
			<p>In all the sentences, the action is <em class="italic">to fly</em>: however, only some sentences state intent to make a ticket booking. Let's imagine these sentences with a surrounding context, as follows:</p>
			<pre>I flew to Rome 3 days ago. I still didn't get the bill, please send it ASAP.
I have flown to Rome this morning and forgot my laptop on the airplane. Can you please connect me to lost and found?
I'm flying to Rome next week. Can you check flight availability?
I need to fly to Rome. Can you check flights on next Tuesday?
I will fly to Rome next week. Can you check the flights?   </pre>
			<p>At a quick glance, past and perfect forms of the verb <em class="italic">fly</em> don't indicate a booking intent at all. Rather, they direct to either a customer complaint or customer service issues. The infinitive and present progressive forms, on the other hand, point to booking intent. Let's tag and lemmatize the verbs with the following code segment:</p>
			<pre> sent1 = "I flew to Rome".
 sent2 = "I'm flying to Rome."
 sent3 = "I will fly to Rome." 
 doc1 = nlp(sent1)
 doc2 = nlp(sent2)
 doc3 = nlp(sent3)
 for doc in [doc1, doc2, doc3]
     print([(w.text, w.lemma_) for w in doc if w.tag_== 'VBG' or w.tag_== 'VB'])
... 
[]
[('flying', 'fly')]
[('fly', 'fly')]</pre>
			<p>We iterated <a id="_idIndexMarker161"/>three <code>doc</code> objects one by one, and for each <a id="_idIndexMarker162"/>sentence we checked if the fine-grained tag of <a id="_idIndexMarker163"/>the token is <code>VBG</code> (a verb in present progressive form) or <code>VB</code> (a verb in base/infinitive form). Basically, we filtered out the present <a id="_idIndexMarker164"/>progressive and infinitive verbs. You can think of this process as a semantic representation of the verb in the form of <code>(word form, lemma, tag)</code> as illustrated in the following code snippet:</p>
			<pre>flying: (fly, VBG)</pre>
			<p>We have covered one semantic and one morphological task—WSD and tense/aspect of verbs. We'll continue with a tricky subject: how to make the best of some special tags—namely, number, symbol, and punctuation tags.</p>
			<h2 id="_idParaDest-60"><a id="_idTextAnchor060"/>Understanding number, symbol, and punctuation tags</h2>
			<p>If you look at the English POS, you will notice the <code>NUM</code>, <code>SYM</code>, and <code>PUNCT</code> tags. These are the <a id="_idIndexMarker165"/>tags for numbers, symbols, and punctuation, respectively. These <a id="_idIndexMarker166"/>categories are divided into fine-grained categories: <code>$</code>, <code>SYM</code>, <code>''</code>, <code>-LRB-</code>, and <code>-RRB-</code>. These <a id="_idIndexMarker167"/>are shown in the following screenshot:</p>
			<div><div><img src="img/B16570_03_03.jpg" alt="Figure 3.3 – spaCy punctuation tags, general and fine-grained&#13;&#10;" width="1328" height="780"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.3 – spaCy punctuation tags, general and fine-grained</p>
			<p>Let's tag some example sentences that contain numbers and symbols, as follows:</p>
			<pre> doc = nlp("He earned $5.5 million in 2020 and paid %35 tax.")
 for token in doc:
     token.text, token.tag_, spacy.explain(token.tag_)
... 
('He', 'PRP', 'pronoun, personal')
('earned', 'VBD', 'verb, past tense')
('$', '$', 'symbol, currency')
('5.5', 'CD', 'cardinal number')
('million', 'CD', 'cardinal number')
('in', 'IN', 'conjunction, subordinating or preposition')
('2020', 'CD', 'cardinal number')
('and', 'CC', 'conjunction, coordinating')
('paid', 'VBD', 'verb, past tense')
('35', 'CD', 'cardinal number')
('percent', 'NN', 'noun, singular or mass')
('tax', 'NN', 'noun, singular or mass')
('.', '.', 'punctuation mark, sentence closer')</pre>
			<p>We again <a id="_idIndexMarker168"/>iterated over the tokens and printed the fine-grained tags. The tagger <a id="_idIndexMarker169"/>was able to distinguish symbols, punctuation marks, and numbers. Even <a id="_idIndexMarker170"/>the word <code>million</code> is recognized as a number too! </p>
			<p>Now, what to do with symbol tags? Currency symbols and numbers offer a way to systematically extract descriptions of money and are very handy in financial text such as financial reports. We'll see how to extract money entities in <a href="B16570_04_Final_JM_ePub.xhtml#_idTextAnchor069"><em class="italic">Chapter 4</em></a>, <em class="italic">Rule-Based Matching</em>.</p>
			<p>That's it—you made it to the end of this exhaustive section! There's a lot to unpack and digest, but we assure you that you made a great investment for your industrial NLP work. We'll now continue with another syntactic concept—dependency parsing.</p>
			<h1 id="_idParaDest-61"><a id="_idTextAnchor061"/>Introduction to dependency parsing</h1>
			<p>If you are already familiar with spaCy, you must have come across the spaCy dependency parser. Though <a id="_idIndexMarker171"/>many developers see <em class="italic">dependency parser</em> on the spaCy documentation, they're shy about using it or don't know how to use this feature to the fullest. In this part, you'll explore a systematic way of representing a sentence syntactically. Let's start with what dependency parsing actually is.</p>
			<h2 id="_idParaDest-62"><a id="_idTextAnchor062"/>What is dependency parsing?</h2>
			<p>In the previous section, we focused on POS tags—syntactic categories of words. Though POS tags provide <a id="_idIndexMarker172"/>information about neighbor words' tags as well, they do not give away any relations between words that are not neighbors in the given sentence. </p>
			<p>In this section, we'll focus on dependency parsing—a more structured way of exploring the sentence syntax. As the name suggests, <strong class="bold">dependency parsing</strong> is related to analyzing sentence structures via dependencies between the tokens. A <strong class="bold">dependency parser</strong> tags syntactic <a id="_idIndexMarker173"/>relations between tokens of the sentence <a id="_idIndexMarker174"/>and connects <a id="_idIndexMarker175"/>syntactically related pairs of tokens. A <strong class="bold">dependency</strong> or a <strong class="bold">dependency relation</strong> is a <em class="italic">directed link</em> between two tokens. </p>
			<p>The result of the dependency parsing is always a <strong class="bold">tree</strong>, as illustrated in the following screenshot:</p>
			<div><div><img src="img/B16570_03_04.jpg" alt="Figure 3.4 – An example of a dependency tree (taken from Wikipedia)&#13;&#10;" width="300" height="269"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.4 – An example of a dependency tree (taken from Wikipedia)</p>
			<p>If you're not familiar with a tree data structure, you can learn more about it at this excellent Computer Science resource: </p>
			<p>https://www.cs.cmu.edu/~clo/www/CMU/DataStructures/Lessons/lesson4_1.htm</p>
			<h2 id="_idParaDest-63"><a id="_idTextAnchor063"/>Dependency relations</h2>
			<p>What is the use of <strong class="bold">dependency relations</strong>, then? Quite a number of statistical methods in NLP revolve around vector representations of words and treat a sentence as a sequence <a id="_idIndexMarker176"/>of words. As you can see in <em class="italic">Figure 3.4</em>, a sentence is more than a sequence of tokens—it has a structure; every word in a sentence has a well-defined role, such as verb, subject, object, and so on; hence, sentences definitely have a structure. This structure is used extensively in chatbots, question answering, and machine translation. </p>
			<p>The most useful application that first comes to mind is determining the sentence object and subject. Again, let's go back to our travel agency application. Imagine a customer is complaining about the service. Compare the two sentences, <code>I forwarded you the email</code> and <code>You forwarded me the email</code>; if we eliminate the stopwords <code>I</code>, <code>you</code>, <code>me</code>, and <code>the</code>, this is what remains:</p>
			<pre>I forwarded you the email. -&gt; forwarded email
You forwarded me the email. -&gt; forwarded email</pre>
			<p>Though the remaining parts of the sentences are identical, sentences have very different meanings and require different answers. In the first sentence, the sentence subject is <code>I</code> (then, the answer most probably will start with <code>you</code>) and the second sentence's subject is <code>you</code> (which will end up in an <code>I</code> answer).</p>
			<p>Obviously, the dependency parser helps us to go deeper into the sentence syntax and semantics. Let's explore more, starting from the dependency relations.</p>
			<h2 id="_idParaDest-64"><a id="_idTextAnchor064"/>Syntactic relations</h2>
			<p>spaCy assigns each token a dependency label, just as with other linguistic features such as a lemma <a id="_idIndexMarker177"/>or a POS tag. spaCy shows dependency relations with <em class="italic">directed arcs</em>. The following screenshot shows an example of a dependency relation between a noun and the adjective that qualifies the noun:</p>
			<div><div><img src="img/B16570_03_05.jpg" alt="Figure 3.5 – Dependency relation between a noun and its adjective&#13;&#10;" width="709" height="461"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.5 – Dependency relation between a noun and its adjective</p>
			<p>A dependency label describes the type of syntactic relation between two tokens as follows: one <a id="_idIndexMarker178"/>of the tokens is the <code>flower</code> is the head and <code>blue</code> is its dependent/child.</p>
			<p>The dependency <a id="_idIndexMarker180"/>label is assigned to the child. Token objects have <code>dep (int)</code> and <code>dep_ (unicode)</code> properties that hold the dependency label, as illustrated in the following code snippet:</p>
			<pre> doc = nlp("blue flower")
 for token in doc:
     token.text, token.dep_
…
('blue', 'amod')
('flower', 'ROOT')</pre>
			<p>In this example, we iterated over the tokens and printed their text and dependency label. Let's go <a id="_idIndexMarker181"/>over what happened bit by bit, as follows:</p>
			<ul>
				<li><code>blue</code> admitted the <code>amod</code> label. <code>amod</code> is the dependency label for an adjective-noun relation. For more examples of the <code>amod</code> relation, please refer to <em class="italic">Figure 3.7</em>. </li>
				<li><code>flower</code> is the <code>ROOT</code>. <code>ROOT</code> is a special label in the dependency tree; it is assigned to the main verb of a sentence. If we're processing a phrase (not a full sentence), the <code>ROOT</code> label is assigned to the root of the phrase, which is the head noun of the phrase. In the <code>blue flower</code> phrase, the head noun, <code>flower</code>, is the root of the phrase.</li>
				<li>Each sentence/phrase has exactly one root, and it's the root of the parse tree (remember, the dependency parsing result is a tree). </li>
				<li>Tree nodes can have more than one child, but each node can only have one parent (due to tree restrictions, and trees containing no cycles). In other words, every token has exactly one head, but a parent can have several children. This is the reason why the dependency label is assigned to the dependent node.</li>
			</ul>
			<p>Here is a full list of spaCy's English dependency labels:</p>
			<div><div><img src="img/B16570_03_06.jpg" alt="Figure 3.6 – List of some spaCy English dependency labels&#13;&#10;" width="373" height="698"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.6 – List of spaCy English dependency labels</p>
			<p>That's a long list! No worries—you don't need to memorize every list item. Let's first see a list of the <a id="_idIndexMarker182"/>most common and useful labels, then we'll see how exactly they link tokens to each other. Here's the list first:</p>
			<ul>
				<li><code>amod</code>: Adjectival modifier</li>
				<li><code>aux</code>: Auxiliary</li>
				<li><code>compound</code>: Compound</li>
				<li><code>dative</code>: Dative object</li>
				<li><code>det</code>: Determiner</li>
				<li><code>dobj</code>: Direct object</li>
				<li><code>nsubj</code>: Nominal subject</li>
				<li><code>nsubjpass</code>: Nominal subject, passive</li>
				<li><code>nummod</code>: Numeric modifier</li>
				<li><code>poss</code>: Possessive modifier</li>
				<li><code>root</code>: The root</li>
			</ul>
			<p>Let's see examples of how the aforementioned labels are used and what relation they express. <code>amod</code> is adjectival modifier. As understood from the name, this relation modifies the noun (or pronoun). In the following screenshot, we see <strong class="bold">white</strong> modifies <strong class="bold">sheep</strong>:</p>
			<div><div><img src="img/B16570_03_07.jpg" alt="Figure 3.7 – amod relation&#13;&#10;" width="418" height="157"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.7 – amod relation</p>
			<p><code>aux</code> is what you might guess: it's the dependency relation between an auxiliary verb and its main verb; the <a id="_idIndexMarker183"/>dependent is an auxiliary verb, and the head is the main verb. In the following screenshot, we see that <strong class="bold">has</strong> is the auxiliary verb of the main verb <strong class="bold">gone</strong>:</p>
			<div><div><img src="img/B16570_03_08.jpg" alt="Figure 3.8 – aux relation&#13;&#10;" width="363" height="196"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.8 – aux relation</p>
			<p><code>compound</code> is used for the noun compounds; the second noun is modified by the first noun. In the following screenshot, <strong class="bold">phone book</strong> is a noun compound and the <strong class="bold">phone</strong> noun modifies the <strong class="bold">book</strong> noun:</p>
			<div><div><img src="img/B16570_03_09.jpg" alt="Figure 3.9 – Compound relation between phone and book&#13;&#10;" width="610" height="228"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.9 – Compound relation between phone and book</p>
			<p>The <code>det</code> relation <a id="_idIndexMarker184"/>links a determiner (the dependent) to the noun it qualifies (its head). In the following screenshot, <strong class="bold">the</strong> is the determiner of the noun <strong class="bold">girl</strong> in this sentence:</p>
			<div><div><img src="img/B16570_03_10.jpg" alt="Figure 3.10 – det relation on the right&#13;&#10;" width="453" height="121"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.10 – det relation</p>
			<p>Next, we look into two object relations, <code>dative</code> and <code>dobj</code>. The <code>dobj</code> relation is between the verb and its direct object. A sentence can have more than one object (such as in the following example); a direct object is the object that the verb acts upon, and the others are called indirect objects.</p>
			<p>A direct object is generally marked with <code>dative</code> relation points to a <code>dative</code> object, which <a id="_idIndexMarker185"/>receives an indirect action from the verb. In the sentence shown in the following screenshot, the indirect object is <strong class="bold">me</strong> and the direct object is <strong class="bold">book</strong>:</p>
			<div><div><img src="img/B16570_03_11.jpg" alt="Figure 3.11 – The direct and indirect objects of the sentence &#13;&#10;" width="521" height="152"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.11 – The direct and indirect objects of the sentence </p>
			<p><code>nsubj</code> and <code>nsubjposs</code> are two relations that are related to the nominal sentence subject. The subject of the sentence is the one that committed the action. A passive subject is still the subject, but we mark it with <code>nsubjposs</code>. In the following screenshot, <strong class="bold">Mary</strong> is the nominal subject of the first sentence: </p>
			<div><div><img src="img/B16570_03_12.jpg" alt="Figure 3.12 – nsubj relation&#13;&#10;" width="453" height="170"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.12 – nsubj relation</p>
			<p><strong class="bold">you</strong> is the passive <a id="_idIndexMarker186"/>nominal subject of the sentence in the following screenshot:</p>
			<div><div><img src="img/B16570_03_13.jpg" alt="Figure 3.13 – nsubjpass relation &#13;&#10;" width="603" height="176"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.13 – nsubjpass relation </p>
			<p>We have now covered sentence subject and object relations. Now, we'll discover two modifier relations; one is the <code>nummod</code> <code>poss</code> <code>nummod</code> is easy to spot; it's between <strong class="bold">3</strong> and <strong class="bold">books</strong>: </p>
			<div><div><img src="img/B16570_03_14.jpg" alt="Figure 3.14 – nummod relation&#13;&#10;" width="460" height="174"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.14 – nummod relation</p>
			<p>A possessive <a id="_idIndexMarker189"/>modifier happens either between a <em class="italic">possessive pronoun</em> and a noun or a <em class="italic">possessive 's</em> and a noun. In the sentence shown in the following screenshot, <strong class="bold">my</strong> is a possessive marker on the noun <strong class="bold">book</strong>:</p>
			<div><div><img src="img/B16570_03_15.jpg" alt="Figure 3.15 – poss relation between “my” and “book”&#13;&#10;" width="437" height="167"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.15 – poss relation between "my" and "book"</p>
			<p>Last, but not least, is the <strong class="bold">root label</strong>, which is not a real relation but is a marker for the sentence verb. A root <a id="_idIndexMarker190"/>word has no real parent in the syntactic tree; the root is the main verb of the sentence. In the preceding sentences, <strong class="bold">took</strong> and <strong class="bold">given</strong> are the corresponding roots. The main verbs of both sentences are the auxiliary verbs <strong class="bold">is</strong> and <strong class="bold">are</strong>. Notice that the root node has no incoming arc—that is, no parent.</p>
			<p>These are the <a id="_idIndexMarker191"/>most useful labels for our NLU purposes. You definitely don't need to memorize all the labels, as you'll become familiar as you practice in the next pages. Also, you can ask spaCy about a label any time you need, via <code>spacy.explain()</code>. The code to do this is shown in the following snippet:</p>
			<pre> spacy.explain("nsubj")
'nominal subject'
 doc = nlp("I own a ginger cat.")
 token = doc[4]
 token.text, token.dep_, spacy.explain(token.dep_)
('cat', 'dobj', 'direct object')</pre>
			<p>Take a deep breath, since there is a lot to digest! Let's practice how we can make use of dependency labels.</p>
			<p>Again, <code>token.dep_</code> includes the dependency label of the dependent token. The<code> token.head</code> property points to the head/parent token. Only the root token does not have a parent; spaCy points to the token itself in this case. Let's bisect the example sentence from <em class="italic">Figure 3.7</em>, as follows:</p>
			<pre> doc = nlp("I counted white sheep.")
 for token in doc:
     token.text, token.pos_, token.dep_
... 
('I', 'PRP', 'nsubj')
('counted', 'VBD', 'ROOT')
('white', 'JJ', 'amod')
('sheep', 'NNS', 'dobj')
('.', '.', 'punct') </pre>
			<p>We iterated over the tokens and printed the fine-grained POS tag and the dependency label. <code>counted</code> is the main verb of the sentence and is labeled by the label <code>ROOT</code>. Now, <code>I</code> is the subject of the sentence, and <code>sheep</code> is the direct object. <code>white</code> is an adjective and <a id="_idIndexMarker192"/>modifies the noun <code>sheep</code>, hence its label is <code>amod</code>. We go one level deeper and print the token heads this time, as follows: </p>
			<pre> doc = nlp(“I counted white sheep.”) 
for token in doc:
      token.text, token.tag_, token.dep_, token.head
... 
('I', 'PRP', 'nsubj', counted)
('counted', 'VBD', 'ROOT', counted)
('white', 'JJ', 'amod', sheep)
('sheep', 'NNS', 'dobj', counted)
('.', '.', 'punct', counted)</pre>
			<p>The visualization is as follows:</p>
			<div><div><img src="img/B16570_03_16.jpg" alt="Figure 3.16 – An example parse of a simple sentence&#13;&#10;" width="520" height="194"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.16 – An example parse of a simple sentence</p>
			<p>When the <code>token.head</code> property is also involved, it's a good idea to follow the code and the visual <a id="_idIndexMarker193"/>at the same time. Let's go step by step in order to understand how the visual and the code match:</p>
			<ol>
				<li>We start reading the parse tree from the root. It's the main verb: <code>counted</code>. </li>
				<li>Next, we follow its arc on the left toward the pronoun <code>I</code>, which is the nominal subject of the sentence and is labeled by the label <code>nsubj</code>. </li>
				<li>Now, return back to the root, <code>counted</code>. This time, we navigate to the right. Follow the <code>dobj</code> arc to reach the noun <code>sheep</code>. <code>sheep</code> is modified by the adjective <code>white</code> with an <code>amod</code> relation, hence the direct object of this sentence is <code>white sheep</code>.</li>
			</ol>
			<p>Even such a simple, flat sentence has a dependency parse tree that's fancy to read, right? Don't rush—you'll get used to it by practicing. Let's examine the dependency tree of a longer and more complicated sentence, as follows:</p>
			<pre> doc = nlp("We are trying to understand the difference.")
 for token in doc:
     token.text, token.tag_, token.dep_, token.head
... 
('We', 'PRP', 'nsubj', trying)
('are', 'VBP', 'aux', trying)
('trying', 'VBG', 'ROOT', trying)
('to', 'TO', 'aux', understand)
('understand', 'VB', 'xcomp', trying)
('the', 'DT', 'det', difference)
('difference', 'NN', 'dobj', understand)
('.', '.', 'punct', trying)</pre>
			<p>Now, this time things look a bit different, as we'll see in <em class="italic">Figure 3.17</em>. We locate the main verb and the root <code>trying</code> (it has no incoming arcs). The left side of the word <code>trying</code> looks manageable, but the right side has a chain of arcs. Let's start with the left side. The pronoun <code>we</code> is labeled by <code>nsubj</code>, hence this is the nominal subject of the sentence. The <a id="_idIndexMarker194"/>other left arc, labeled <code>aux</code>, points to the <code>trying</code> dependent <code>are</code>, which is the auxiliary verb of the main verb <code>trying</code>.</p>
			<p>So far, so good. Now, what is happening on the right side? <code>trying</code> is attached to the second verb <code>understand</code> via an <code>xcomp</code> relation. The <code>xcomp</code> (or open complement) relation of a verb is a clause without its own subject. Here, the <code>to understand the difference</code> clause has no subject, so it's an open complement. We follow the <code>dobj</code> arc from the second verb, <code>understand</code>, and land on the noun, <code>difference</code>, which is the direct object of the <code>to understand the difference</code> clause, and this is the result:</p>
			<div><div><img src="img/B16570_03_17.jpg" alt="Figure 3.17 – A complicated parsing example&#13;&#10;" width="653" height="131"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.17 – A complicated parsing example</p>
			<p>This was an <a id="_idIndexMarker195"/>in-depth analysis for this example sentence, which indeed does not look that complicated. Next, we process a sentence with a subsentence that owns its own nominal subject, as follows:</p>
			<pre> doc = nlp("Queen Katherine, who was the mother of Mary Tudor, died at 1536.")
 for token in doc:
     token.text, token.tag_, token.dep_, token.head
... 
('Queen', 'NNP', 'compound', Katherine)
('Katherine', 'NNP', 'nsubj', died)
(',', ',', 'punct', Katherine)
('who', 'WP', 'nsubj', was)
('was', 'VBD', 'relcl', Katherine)
('the', 'DT', 'det', mother)
('mother', 'NN', 'attr', was)
('of', 'IN', 'prep', mother)
('Mary', 'NNP', 'compound', Tudor)
('Tudor', 'NNP', 'pobj', of)
(',', ',', 'punct', Katherine)
('died', 'VBD', 'ROOT', died)
('at', 'IN', 'prep', died)
('1536', 'CD', 'pobj', at)</pre>
			<p>In order to make the visuals big enough, I have split the visualization into two parts. First, let's find <a id="_idIndexMarker196"/>the root. The root lies in the right part. <code>died</code> is the main sentence of the verb and the root (again, it has no incoming arcs). The rest of the right side contains nothing tricky. </p>
			<p>On the other hand, the left side has some interesting stuff—actually, a relative clause. Let's bisect the relative clause structure:</p>
			<ul>
				<li>We start with the proper noun <code>Katherine</code>, which is attached to <code>died</code> with a <code>nsubj</code> relation, hence the subject of the sentence. </li>
				<li>We see a compound arc leaving <code>Katherine</code> toward the proper noun, <code>Queen</code>. Here, <code>Queen</code> is a title, so the relationship with <code>Katherine</code> is compound. The same relationship exists between <code>Mary</code> and <code>Tudor</code> on the right side, and the last names and first names are also tied with the compound relation. </li>
			</ul>
			<p>It's time to bisect the relative clause, <code>who was the mother of Mary Tudor</code>, as follows: </p>
			<ul>
				<li>First of all, it is <code>Katherine</code> who is mentioned in the relative clause, so we see a <code>relcl</code> (relative clause) arc from <code>Katherine</code> to <code>was</code> of the relative clause. </li>
				<li><code>who</code> is the nominal subject of the clause and is linked to <code>was</code> via an <code>nsubj</code> relation. As you see in the following screenshot, the dependency tree is different from the previous example sentence, whose clause didn't own a nominal subject:</li>
			</ul>
			<div><div><img src="img/B16570_03_18.jpg" alt="Figure 3.18 – A dependency tree with a relative clause, the left part&#13;&#10;" width="586" height="152"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.18 – A dependency tree with a relative clause, the left part</p>
			<div><div><img src="img/B16570_03_19.jpg" alt="Figure 3.19 – Same sentence, the right part&#13;&#10;" width="581" height="185"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.19 – Same sentence, the right part</p>
			<p>It's perfectly normal if you feel that you won't be able to keep all the relations in your mind. No worries—always find the root/main verb of the sentence, then follow the arcs from the root and go deeper, just as we did previously. You can always have a look at the spaCy documentation (<a href="https://spacy.io/api/annotation#dependency-parsing">https://spacy.io/api/annotation#dependency-parsing</a>) to see what the relation type means. Take your time until you warm up to the concept and the details.</p>
			<p>That was exhaustive! Dear reader—as we said before, please take your time to digest and practice <a id="_idIndexMarker197"/>on example sentences. The <em class="italic">displaCy</em> online demo is a great tool, so don't be shy to try your own example sentences and see the parsing results. It's perfectly normal for you to find this section heavy. However, this section is a solid foundation for general linguistics, and also for the information extraction and pattern-matching exercises in <a href="B16570_04_Final_JM_ePub.xhtml#_idTextAnchor069"><em class="italic">Chapter 4</em></a>, <em class="italic">Rule-Based Matching</em>. You will become even more comfortable after going through a case study in <a href="B16570_06_Final_JM_ePub.xhtml#_idTextAnchor103"><em class="italic">Chapter 6</em></a>, <em class="italic">Putting Everything Together: Semantic Parsing with spaCy</em>. Give yourself time to digest dependency parsing with examples throughout the book. </p>
			<p>What comes after the dependency parser? Without any doubt, you must have heard NER frequently mentioned in the NLU world. Let's look into this very important NLU concept. </p>
			<h1 id="_idParaDest-65"><a id="_idTextAnchor065"/>Introducing NER</h1>
			<p>We opened <a id="_idIndexMarker198"/>this chapter with a tagger, and we'll see another very handy tagger—the NER tagger of spaCy. As NER's name suggests, we are interested in finding named entities.</p>
			<p>What is a <strong class="bold">named entity</strong>? A named entity <a id="_idIndexMarker199"/>is a real-world object that we can refer to by a proper name or a quantity of interest. It can be a person, a place (city, country, landmark, famous building), an organization, a company, a product, dates, times, percentages, monetary amounts, a drug, or a disease name. Some examples are Alicia Keys, Paris, France, Brandenburg Gate, WHO, Google, Porsche Cayenne, and so on.</p>
			<p>A named entity always points to a <em class="italic">specific</em> object, and that object is distinguishable via the corresponding named entity. For instance, if we tag the sentence <em class="italic">Paris is the capital of France</em>, we parse <em class="italic">Paris</em> and <em class="italic">France</em> as named entities, but not the word <em class="italic">capital</em>. The reason is that <em class="italic">capital</em> does not point to a specific object; it's a general name for many objects.</p>
			<p>NER categorization is a bit different from POS categorization. Here, the number of categories is as high as we want. The most common categories are person, location, and organization <a id="_idIndexMarker200"/>and are supported by almost every usable NER tagger. In the following screenshot, we see the corresponding tags:</p>
			<div><div><img src="img/B16570_03_20.jpg" alt="Figure 3.20 – Most common entity types&#13;&#10;" width="1082" height="395"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.20 – Most common entity types</p>
			<p>spaCy supports a wide range of entity types. Which ones you use depends on your corpus. If you process financial text, you most probably use <code>MONEY</code> and <code>PERCENTAGE</code> more often than <code>WORK_OF_ART</code>. </p>
			<p>Here is a list of the entity types supported by spaCy:</p>
			<div><div><img src="img/B16570_03_21.jpg" alt="Figure 3.21 – Full list of entity types supported by spaCy&#13;&#10;" width="1468" height="1798"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.21 – Full list of entity types supported by spaCy</p>
			<p>Just as <a id="_idIndexMarker201"/>with the POS tagger statistical models, NER models <a id="_idIndexMarker202"/>are also sequential models. The very first modern NER tagger model is a <strong class="bold">conditional random field</strong> (<strong class="bold">CRF</strong>). CRFs are sequence classifiers used for structured prediction problems such as labeling and parsing. If you <a id="_idIndexMarker203"/>want to learn more about the CRF implementation details, you can read more at this resource: https://homepages.inf.ed.ac.uk/csutton/publications/crftutv2.pdf. The current state-of-the-art NER tagging is achieved by neural network models, usually LSTM or LSTM+CRF architectures. </p>
			<p>Named entities in a doc are available via the <code>doc.ents</code> property. <code>doc.ents</code> is a list of <code>Span</code> objects, as illustrated in the following code snippet:</p>
			<pre> doc = nlp("The president Donald Trump visited France.")
 doc.ents
(Donald Trump, France)
 type(doc.ents[1])
&lt;class 'spacy.tokens.span.Span'&gt;</pre>
			<p>spaCy also tags each token with the entity type. The type of the named entity is available via <code>token.ent_type (int)</code> and <code>token.ent_type_ (unicode)</code>. If the token is not a named entity, then <code>token.ent_type_</code> is just an empty string.</p>
			<p>Just as for <a id="_idIndexMarker204"/>POS tags and dependency labels, we can call <code>spacy.explain()</code> on the tag string or on the <code>token.ent_type_</code>, as follows:</p>
			<pre> spacy.explain("ORG")
'Companies, agencies, institutions, etc.
 doc = nlp("He worked for NASA.")
 token = doc[3]
 token.ent_type_, spacy.explain(token.ent_type_)
('ORG', 'Companies, agencies, institutions, etc.') </pre>
			<p>Let's go over some examples to see the spaCy NER tagger in action, as follows:</p>
			<pre> doc = nlp("Albert Einstein was born in Ulm on 1879. He studied electronical engineering at ETH Zurich.")
 doc.ents
(Albert Einstein, Ulm, 1879, ETH Zurich)
 for token in doc:
     token.text, token.ent_type_, \
     spacy.explain(token.ent_type_)
... 
('Albert', 'PERSON', 'People, including fictional')
('Einstein', 'PERSON', 'People, including fictional')
('was', '', None)
('born', '', None)
('in', '', None)
('Ulm', 'GPE', 'Countries, cities, states')
('on', '', None)
('1879', 'DATE', 'Absolute or relative dates or periods')
('.', '', None)
('He', '', None)
('studied', '', None)
('electronical', '', None)
('engineering', '', None)
('at', '', None)
('ETH', 'ORG', 'Companies, agencies, institutions, etc.')
('Zurich', 'ORG', 'Companies, agencies, institutions, etc.')
('.', '', None)</pre>
			<p>We iterated <a id="_idIndexMarker205"/>over the tokens one by one and printed the token and its entity type. If the token is not tagged as an entity, then <code>token.ent_type_</code> is just an empty string, hence there is no explanation from <code>spacy.explain()</code>. For the tokens that are part of a NE, an appropriate tag is returned. In the preceding sentences, <code>Albert Einstein</code>, <code>Ulm</code>, <code>1879</code>, and <code>ETH Zurich</code> are correctly tagged as <code>PERSON</code>, <code>GPE</code>, <code>DATE</code>, and <code>ORG</code>, respectively. </p>
			<p>Let's see a longer and more complicated sentence with a non-English entity and look at how spaCy tagged it, as follows:</p>
			<pre> doc = nlp("Jean-Michel Basquiat was an American artist of Haitian and Puerto Rican descent who gained fame with his graffiti and street art work")
 doc.ents
(Jean-Michel Basquiat, American, Haitian, Puerto Rican)
 for ent in doc.ents:
     ent, ent.label_, spacy.explain(ent.label_)
... 
(Jean-Michel Basquiat, 'PERSON', 'People, including fictional')
(American, 'NORP', 'Nationalities or religious or political groups')
(Haitian, 'NORP', 'Nationalities or religious or political groups')
(Puerto Rican, 'NORP', 'Nationalities or religious or political groups')</pre>
			<p>Looks good! The spaCy tagger picked up a person entity with a <code>-</code> smoothly. Overall, the tagger works quite well for different entity types, as we saw throughout the examples. </p>
			<p>After tagging <a id="_idIndexMarker206"/>tokens with different syntactical features, we sometimes want to merge/split entities into fewer/more tokens. In the next section, we will see how merging and splitting is done. Before that, we will see a real-world application of NER tagging.</p>
			<h2 id="_idParaDest-66"><a id="_idTextAnchor066"/>A real-world example</h2>
			<p>NER is a <a id="_idIndexMarker207"/>popular and frequently used pipeline component of spaCy. NER is <a id="_idIndexMarker208"/>one of the key components of understanding the text topic, as named entities usually belong to a <strong class="bold">semantic category</strong>. For instance, <em class="italic">President Trump</em> invokes the <em class="italic">politics</em> subject in our minds, whereas <em class="italic">Leonardo DiCaprio</em> is more about <em class="italic">movies</em>. If you want to go deeper into resolving the text meaning and understanding who made what, you also need named entities. </p>
			<p>This real-world <a id="_idIndexMarker209"/>example includes processing a <em class="italic">New York Times</em> article. Let's go ahead and download the article first by running the following code:</p>
			<pre>from bs4 import BeautifulSoup
import requests
import spacy
def url_text(url_string):
    res = requests.get(url)
    html = res.text
    soup = BeautifulSoup(html, 'html5lib')
    for script in soup(["script", "style", 'aside']):
        script.extract()
    text = soup.get_text()
    return " ".join(text.split())
ny_art = url_text("https://www.nytimes.com/2021/01/12/opinion/trump-america-allies.html")
nlp = spacy.load("en_core_web_md")
doc = nlp(ny_art)</pre>
			<p>We downloaded <a id="_idIndexMarker210"/>the article <code>BeautifulSoup</code> is a <a id="_idIndexMarker212"/>popular Python package for extracting text from HTML and <code>nlp</code> object, passed the article body to the <code>nlp</code> object, and created a <code>Doc</code> object.</p>
			<p>Let's start our analysis of the article by the entity type count, as follows:</p>
			<pre>len(doc.ents)
136</pre>
			<p>That's a totally normal number for a news article that includes many entities. Let's go a bit further and group the entity types, as follows:</p>
			<pre>from collections import Counter
labels = [ent.label_ for ent in doc.ents]
Counter(labels)
Counter({'GPE': 37, 'PERSON': 30, 'NORP': 24, 'ORG': 22, 'DATE': 13, 'CARDINAL': 3, 'FAC': 2, 'LOC': 2, 'EVENT': 1, 'TIME': 1, 'WORK_OF_ART': 1})</pre>
			<p>The most <a id="_idIndexMarker213"/>frequent entity type is <code>GPE</code>, which means a country, city, or state. The second one is <code>PERSON</code>, whereas the third most frequent entity label is <code>NORP</code>, which means a nationality/religious-political group. The next ones are organization, date, and cardinal number-type entities. </p>
			<p>Can we summarize the text by looking at the entities or understanding the text topic? To answer this question, let's start by counting the most frequent tokens that occur in the entities, as follows:</p>
			<pre>items = [ent.text for ent in doc.ents]
Counter(items).most_common(10)
[('America', 12), ('American', 8), ('Biden', 8), ('China', 6), ('Trump', 5), ('Capitol', 4), ('the United States', 3), ('Washington', 3), ('Europeans', 3), ('Americans', 3)]</pre>
			<p>Looks like a semantic group! Obviously, this article is about American politics, and possibly how America interacts with the rest of the world in politics. If we print all the entities of the article, we can see here that this guess is true:</p>
			<pre>print(doc.ents)
(The New York Times SectionsSEARCHSkip, indexLog inToday, storyOpinionSupported byContinue, LaughingstockLast week's, U.S., U.S., Ivan KrastevMr, Krastev, Jan., 2021 <img src="img/CodeBlock_IMG.png" alt="" width="432" height="32"/> A, Rome, Donald Tramp, Thursday, Andrew Medichini, Associated PressDonald Trump, America, America, Russian, Chinese, Iranian, Jan. 6, Capitol, Ukraine, Georgia, American, American, the United States, Trump, American, Congress, Civil War, 19th-century, German, Otto von Bismarck, the United States of America, America, Capitol, Trump, last hours, American, American, Washington, Washington, Capitol, America, America, Russia, at least 10, Four years, Trump, Joe Biden, two, American, China, Biden, America, Trump, Recep Tayyip Erdogan, Turkey, Jair Bolsonaro, Brazil, Washington, Russia, China, Biden, Gianpaolo Baiocchi, H. Jacob Carlson, Social Housing Development Authority, Ezra Klein, Biden, Mark Bittman, Biden, Gail Collins, Joe Biden, Jake Sullivan, Biden, trans-Atlantic, China, Just a week ago, European, Sullivan, Europe, America, China, Biden, Europeans, China, German, Chinese, the European Union's, America, Christophe Ena, the European Council on Foreign Relations, the weeks, American, the day, Biden, Europeans, America, the next 10 years, China, the United States, Germans, Trump, Americans, Congress, America, Bill Clinton, Americans, Biden, the White House, the United States, Americans, Europeans, the past century, America, the days, Capitol, democratic, Europe, American, America, Ivan Krastev, the Center for Liberal Strategies, the Institute for Human Sciences, Vienna, Is It Tomorrow Yet?:, The New York Times Opinion, Facebook, Twitter (@NYTopinion, Instagram, AdvertisementContinue, IndexSite Information Navigation© 2021, The New York Times, GTM, tfAzqo1rYDLgYhmTnSjPqw&amp;gtm_preview)</pre>
			<p>We made <a id="_idIndexMarker214"/>a visualization of the whole article by pasting the text into <strong class="bold">displaCy Named Entity Visualizer</strong> (<a href="https://explosion.ai/demos/displacy-ent/">https://explosion.ai/demos/displacy-ent/</a>). The following screenshot is taken from the demo page that captured a part of the visual:</p>
			<div><div><img src="img/B16570_03_22.jpg" alt="Figure 3.22 – The New York Times article's entities visualized by displaCy&#13;&#10;" width="617" height="365"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.22 – The New York Times article's entities visualized by displaCy</p>
			<p>spaCy's NER <a id="_idIndexMarker215"/>offers great capabilities for understanding text, as well as presenting good-looking visuals to ourselves, colleagues, and stakeholders.</p>
			<h1 id="_idParaDest-67"><a id="_idTextAnchor067"/>Merging and splitting tokens</h1>
			<p>We extracted <a id="_idIndexMarker216"/>the name entities in the previous section, but how about if we <a id="_idIndexMarker217"/>want to unite or split multiword named entities? And what if the tokenizer performed this not so well on some exotic tokens and you want to split them by hand? In this subsection, we'll cover a very practical remedy for our multiword expressions, multiword named entities, and typos. </p>
			<p><code>doc.retokenize</code> is the <a id="_idIndexMarker218"/>correct tool for merging and splitting the spans. Let's see an <a id="_idIndexMarker219"/>example of retokenization by merging a multiword named entity, as follows:</p>
			<pre> doc = nlp("She lived in New Hampshire.")
 doc.ents
(New Hampshire,)
 [(token.text, token.i) for token in doc]
[('She', 0), ('lived', 1), ('in', 2), ('New', 3), ('Hampshire', 4), ('.', 5)]
 len(doc)
6
 with doc.retokenize() as retokenizer:
     retokenizer.merge(doc[3:5], \
     attrs={"LEMMA": "new hampshire"})
... 
 [(token.text, token.i) for token in doc]
[('She', 0), ('lived', 1), ('in', 2), ('New Hampshire', 3), ('.', 4)]
 len(doc)
5
 doc.ents
(New Hampshire,)
 [(token.lemma_) for token in doc]
['-PRON-', 'live', 'in', 'new hampshire', '.']</pre>
			<p>This is what we did in the preceding code: </p>
			<ol>
				<li value="1">First, we created a <code>doc</code> object from the sample sentence. </li>
				<li>Then, we printed its entities with <code>doc.ents</code>, and the result was <code>New Hampshire</code>, as expected. </li>
				<li>In the next line, for each token, we printed <code>token.text</code> with token indices in the sentence (<code>token.i</code>). </li>
				<li>Also, we examined length of the <code>doc</code> object by calling <code>len</code> on it, and the result was <code>6</code> (<code>"."</code> is a token too). </li>
			</ol>
			<p>Now, we wanted <a id="_idIndexMarker220"/>to merge the tokens of position <code>3</code> until <code>5</code> (<code>3</code> is included; <code>5</code> is not), so we <a id="_idIndexMarker221"/>did the following: </p>
			<ol>
				<li value="1">First, we called the <code>retokenizer</code> method <code>merge(indices, attrs)</code>. <code>attrs</code> is a dictionary of token attributes we want to assign to the new token, such as <code>lemma</code>, <code>pos</code>, <code>tag</code>, <code>ent_type</code>, and so on. </li>
				<li>In the preceding example, we set the lemma of the new token; otherwise, the lemma would be <code>New</code> only (the starting token's lemma of the span we want to merge). </li>
				<li>Then, we printed the tokens to see if the operation worked as we wished. When we print the new tokens, we see that the new <code>doc[3]</code> is the <code>New Hampshire</code> token. </li>
				<li>Also, the <code>doc</code> object is of length <code>5</code> now, so we shrank the doc one less token. <code>doc.ents</code> remain the same and the new token's lemma is <code>new hampshire</code> because we set it with <code>attrs</code>.</li>
			</ol>
			<p>Looks good, so how about splitting a multiword token into several tokens? In this setting, either there's a typo in the text you want to fix or the custom tokenization is not satisfactory for your specific sentence. </p>
			<p>Splitting a span is a bit more complicated than merging a span because of the following reasons:</p>
			<ul>
				<li>We are changing the dependency tree.</li>
				<li>We need to assign new POS tags, dependency labels, and necessary token attributes to the new tokens.</li>
				<li>Basically, we need to think about how to assign linguistic features to the new tokens we created. </li>
			</ul>
			<p>Let's see how <a id="_idIndexMarker222"/>to deal with the new tokens with an example of how to <a id="_idIndexMarker223"/>fix a typo, as follows:</p>
			<pre> doc = nlp("She lived in NewHampshire")
 len(doc)
5
 [(token.text, token.lemma_, token.i) for token in doc]
[('She', '-PRON-', 0), ('lived', 'live', 1), ('in', 'in', 2), ('NewHampshire', 'NewHampshire', 3), ('.', '.', 4)]
 for token in doc:
     token.text, token.pos_, token.tag_, token.dep_
... 
('She', 'PRON', 'PRP', 'nsubj')
('lived', 'VERB', 'VBD', 'ROOT')
('in', 'ADP', 'IN', 'prep')
('NewHampshire', 'PROPN', 'NNP', 'pobj')
('.', 'PUNCT', '.', 'punct')</pre>
			<p>Here's what the dependency tree looks like before the splitting operation:</p>
			<div><div><img src="img/B16570_03_23.jpg" alt="Figure 3.23 – Sample sentence’s dependency tree before retokenization&#13;&#10;" width="605" height="155"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.23 – Sample sentence's dependency tree before retokenization</p>
			<p>Now, we will split the <code>doc[3]</code>, <code>NewHampshire</code>, into two tokens: <code>New</code> and <code>Hampshire</code>. We will give <a id="_idIndexMarker224"/>fine-grained POS tags and dependency labels to the new tokens <a id="_idIndexMarker225"/>via the <code>attrs</code> dictionary. We will also rearrange the dependency tree by passing the new tokens' parents via the <code>heads</code> parameter. While arranging the heads, there are two things to consider, as outlined here: </p>
			<ul>
				<li>Firstly, if you give a relative position (such as <code>(doc[3], 1)</code>) in the following code segment, this means that head of <code>doc[3]</code> will be the +1th position token—that is, <code>doc[4]</code> in the new setup (please see the following visualization ). </li>
				<li>Secondly, if you give an absolute position, it means the position in the <em class="italic">original</em> <code>Doc</code> object. In the following code snippet, the second item in the <code>heads</code> list means that the <code>Hampshire</code> token's head is the second token in the original Doc, which is the <code>in</code> token (please refer to <em class="italic">Figure 3.23</em>). </li>
			</ul>
			<p>After the splitting, we printed the list of new tokens and the linguistic attributes. Also, we examined the new length of the <code>doc</code> object, which is <code>6</code> now. You can see the result here:</p>
			<pre> with doc.retokenize() as retokenizer:
     heads = [(doc[3], 1), doc[2]]
     attrs = {"TAG":["NNP", "NNP"], 
              "DEP": ["compound", "pobj"]}
     retokenizer.split(doc[3], ["New", "Hampshire"], 
                       heads=heads, attrs=attrs)
... 
 [(token.text, token.lemma_, token.i) for token in doc]
[('She', '-PRON-', 0), ('lived', 'live', 1), ('in', 'in', 2), ('New', 'New', 3), ('Hampshire', 'Hampshire', 4), ('.', '.', 5)]
 for token in doc:
     token.text, token.pos_, token.tag_, token.dep_
... 
('She', 'PRON', 'PRP', 'nsubj')
('lived', 'VERB', 'VBD', 'ROOT')
('in', 'ADP', 'IN', 'prep')
('New', 'PROPN', 'NNP', 'pobj')
('Hampshire', 'PROPN', 'NNP', 'compound')
('.', 'PUNCT', '.', 'punct')
 len(doc)
6</pre>
			<p>Here's what <a id="_idIndexMarker226"/>the dependency <a id="_idIndexMarker227"/>tree looks like after the splitting operation (please compare this with <em class="italic">Figure 3.22</em>):</p>
			<div><div><img src="img/B16570_03_24.jpg" alt="Figure 3.24 – Dependency tree after the splitting operation&#13;&#10;" width="633" height="185"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.24 – Dependency tree after the splitting operation</p>
			<p>You can <a id="_idIndexMarker228"/>apply merging and splitting onto any span, not only the named <a id="_idIndexMarker229"/>entity spans. The most important part here is to correctly arrange the new dependency tree and the linguistic attributes.</p>
			<h1 id="_idParaDest-68"><a id="_idTextAnchor068"/>Summary</h1>
			<p>That was it—you made it to the end of this chapter! It was an exhaustive and long journey for sure, but we have unveiled the real linguistic power of spaCy to the fullest. This chapter gave you details of spaCy's linguistic features and how to use them. </p>
			<p>You learned about POS tagging and applications, with many examples. You also learned about an important yet not so well-known and well-used feature of spaCy—the dependency labels. Then, we discovered a famous NLU tool and concept, NER. We saw how to do named entity extraction, again via examples. We finalized this chapter with a very handy tool for merging and splitting the spans that we calculated in the previous sections.</p>
			<p>What's next, then? In the next chapter, we will again be discovering a spaCy feature that you'll be using every day in your NLP application code—spaCy's <code>Matcher</code> class. We don't want to give a spoiler on this beautiful subject, so let's go onto our journey together!</p>
		</div>
	</div></body></html>