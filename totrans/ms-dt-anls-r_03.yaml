- en: Chapter 3. Filtering and Summarizing Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After loading data from either flat files or databases (as we have seen in [Chapter
    1](ch01.html "Chapter 1. Hello, Data!"), *Hello, Data!*), or directly from the
    web via some APIs (as covered in [Chapter 2](ch02.html "Chapter 2. Getting Data
    from the Web"), *Getting Data from the Web*), we often have to aggregate, transform,
    or filter the original dataset before the actual data analysis could take place.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will focus on how to:'
  prefs: []
  type: TYPE_NORMAL
- en: Filter rows and columns in data frames
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summarize and aggregate data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Improve the performance of such tasks with the `dplyr` and `data.table` packages
    besides the base R methods
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Drop needless data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Although not loading the needless data is the optimal solution (see the *Loading
    a subset of text files* and *Loading data from databases* sections in [Chapter
    1](ch01.html "Chapter 1. Hello, Data!"), *Hello, Data!*), we often have to filter
    the original dataset inside R. This can be done with the traditional tools and
    functions from base R, such as `subset`, by using `which` and the `[` or `[[`
    operator (see the following code), or for example with the SQL-like approach of
    the `sqldf` package:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'I am sure that all readers who have a decent SQL background and are just getting
    in touch with R appreciate this alternative way of filtering data, but I personally
    prefer the following rather similar, native, and much more concise R version:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Please note the slight difference in the results. This is attributed to the
    fact that the `row.names` argument of `sqldf` is `FALSE` by default, which can
    of course be overridden to get the exact same results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: These examples focused on how to drop rows from `data.frame`, but what if we
    also want to remove some columns?
  prefs: []
  type: TYPE_NORMAL
- en: 'The SQL approach is really straightforward; just specify the required columns
    instead of `*` in the `SELECT` statement. On the other hand, `subset` also supports
    this approach by the `select` argument, which can take vectors or an R expression
    describing, for example, a range of columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Pass the unquoted column names as a vector via the `c` function to select an
    arbitrary list of columns in the given order, or exclude the specified columns
    by using the - operator, for example, `subset(mtcars, select = -c(hp, wt))`.
  prefs: []
  type: TYPE_NORMAL
- en: Let's take this to the next step, and see how we can apply the forementioned
    filters on some larger datasets, when we face some performance issues with the
    `base` functions.
  prefs: []
  type: TYPE_NORMAL
- en: Drop needless data in an efficient way
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: R works best with datasets that can fit in the actual physical memory, and some
    R packages provide extremely fast access to this amount of data.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Some benchmarks (see the *References* section at the end of the book) provide
    real-life examples of more efficient summarizing R functions than what the current
    open source (for example, MySQL, PostgreSQL, and Impala) and commercial databases
    (such as HP Vertica) provide.
  prefs: []
  type: TYPE_NORMAL
- en: Some of the related packages were already mentioned in [Chapter 1](ch01.html
    "Chapter 1. Hello, Data!"), *Hello, Data!*, where we benchmarked reading a relatively
    large amount of data from the `hflights` package into R.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see how the preceding examples perform on this dataset of a quarter
    of a million rows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The `base::subset` function seems to perform pretty well, but can we make it
    any faster? Well, the second generation of the `plyr` package, called `dplyr`
    (the relevant details are discussed *High-performance helper functions* section
    in this chapter and [Chapter 4](ch04.html "Chapter 4. Restructuring Data"), *Restructuring
    Data*), provides extremely fast C++ implementations of the most common database
    manipulation methods in a rather intuitive way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Further, we can extend this solution by dropping some columns from the dataset
    just like we did with `subset` before, although now, we call the `select` function
    instead of passing an argument with the same name:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Therefore, it''s like calling the `filter` function instead of `subset`, and
    we get the results faster than the blink of an eye! The `dplyr` package can work
    with traditional `data.frame` or `data.table` objects, or can interact directly
    with the most widely used database engines. Please note that row names are not
    preserved in `dplyr`, so if you require them, it''s worth copying the names to
    explicit variables before passing them to `dplyr` or directly to `data.table`
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Drop needless data in another efficient way
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let's see a quick example of the `data.table` solution on its own, without `dplyr`.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `data.table` package provides an extremely efficient way to handle larger
    datasets in a column-based, auto-indexed in-memory data structure, with backward
    compatibility for the traditional `data.frame` methods.
  prefs: []
  type: TYPE_NORMAL
- en: 'After loading the package, we have to transform the `hflights` traditional
    `data.frame` to `data.table`. Then, we create a new column, called `rownames`,
    to which we assign the `rownames` of the original dataset with the help of the
    := assignment operator specific to `data.table`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Well, it takes some time to get used to the custom `data.table` syntax and it
    might even seem a bit strange to the traditional R user at first sight, but it's
    definitely worth mastering in the long run. You get great performance, and the
    syntax turns out to be natural and flexible after the relatively steep learning
    curve of the first few examples.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a matter of fact, the `data.table` syntax is pretty similar to SQL:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'This could be described with SQL commands as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Therefore, `[.data.table` (which stands for the `[` operator applied to a `data.table`
    object) has some different arguments as compared to the traditional `[.data.frame`
    syntax, as you have already seen in the preceding example.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now, we are not dealing with the assignment operator in detail, as this example
    might be too complex for such an introductory part of the book, and we are probably
    getting out of our comfort zone. Therefore, please find more details in [Chapter
    4](ch04.html "Chapter 4. Restructuring Data"), *Restructuring Data*, or head to
    `?data.table` for a rather technical overview.
  prefs: []
  type: TYPE_NORMAL
- en: It seems that the first argument (`i`) of the `[.data.table` operator stands
    for filtering, or in other words, for the `WHERE` statement in SQL parlance, while
    `[.data.frame` expects indices specifying which rows to keep from the original
    dataset. The real difference between the two arguments is that the former can
    take any R expression, while the latter traditional method expects mainly integers
    or logical values.
  prefs: []
  type: TYPE_NORMAL
- en: 'Anyway, filtering is as easy as passing an R expression to the `i` argument
    of the `[` operator specific to `data.table`. Further, let''s see how we can select
    the columns in the `data.table` syntax, which should be done in the second argument
    (`j`) of the call on the basis of the abovementioned general `data.table` syntax:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Okay, so we now have the two expected columns with the 3,481 observations.
    Note that `list` was used to define the required columns to keep, although the
    use of `c` (a function from base R to concatenate vector elements) is more traditionally
    used with `[.data.frame`. The latter is also possible with `[.data.table`, but
    then, you have to pass the variable names as a character vector and set `with`
    to `FALSE`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Instead of `list`, you can use a dot as the function name in the style of the
    `plyr` package; for example: `hflights_dt[, .(DepTime, ArrTime)]`.'
  prefs: []
  type: TYPE_NORMAL
- en: Now that we are more or less familiar with our options for filtering data inside
    a live R session, and we know the overall syntax of the `dplyr` and `data.table`
    packages, let's see how these can be used to aggregate and summarize data in action.
  prefs: []
  type: TYPE_NORMAL
- en: Aggregation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The most straightforward way of summarizing data is calling the `aggregate`
    function from the `stats` package, which does exactly what we are looking for:
    splitting the data into subsets by a grouping variable, then computing summary
    statistics for them separately. The most basic way to call the `aggregate` function
    is to pass the numeric vector to be aggregated, and a factor variable to define
    the splits for the function passed in the `FUN` argument to be applied. Now, let''s
    see the average ratio of diverted flights on each weekday:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Well, it took some time to run the preceding script, but please bear in mind
    that we have just aggregated around a quarter of a million rows to see the daily
    averages for the number of diverted flights departing from the Houston airport
    in 2011.
  prefs: []
  type: TYPE_NORMAL
- en: In other words, which also makes sense for all those not into statistics, the
    percentage of diverted flights per weekday. The results are rather interesting,
    as it seems that flights are more often diverted in the middle of the week (around
    0.3 percent) than over the weekends (around 0.05 percent less), at least from
    Houston.
  prefs: []
  type: TYPE_NORMAL
- en: 'An alternative way of calling the preceding function is to supply the arguments
    inside of the `with` function, which seems to be a more human-friendly expression
    after all because it saves us from the repeated mention of the `hflights` database:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The results are not shown here, as they are exactly the same as those shown
    earlier. The manual for the `aggregate` function (see `?aggregate`) states that
    it returns the results in a convenient form. Well, checking the column names of
    the abovementioned returned data does not seem convenient, right? We can overcome
    this issue by using the formula notation instead of defining the numeric and factor
    variables separately:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The gain by using the formula notation is at least two-fold:'
  prefs: []
  type: TYPE_NORMAL
- en: There are relatively few characters to type
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The headers and row names are correct in the results
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This version also runs a bit faster than the previous `aggregate` calls; please
    see the all-out benchmark at the end of this section
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The only downside of using the formula notation is that you have to learn it,
    which might seem a bit awkward at first, but as formulas are highly used in a
    bunch of R functions and packages, particularly for defining models, it's definitely
    worth learning how to use them in the long run.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The formula notation is inherited from the S language with the following general
    syntax: `response_variable ~ predictor_variable_1 + … + predictor_variable_n`.
    The notation also includes some other symbols, such as `-` for excluding variables
    and `:` or `*` to include the interaction between the variables with or without
    themselves. See [Chapter 5](ch05.html "Chapter 5. Building Models (authored by
    Renata Nemeth and Gergely Toth)"), *Building Models (authored by Renata Nemeth
    and Gergely Toth)*, and `?formula` in the R console for more details.'
  prefs: []
  type: TYPE_NORMAL
- en: Quicker aggregation with base R commands
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'An alternative solution to aggregate data might be to call the `tapply` or
    `by` function, which can apply an R function over a *ragged* array. The latter
    means that we can provide one or more `INDEX` variables, which will be coerced
    to factor, and then, run the provided R function separately on all cells in each
    subset. The following is a quick example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Please note that `tapply` returns an `array` object instead of convenient data
    frames; on the other hand, it runs a lot quicker than the abovementioned aggregate
    calls. Thus, it might be reasonable to use `tapply` for the computations and then,
    convert the results to `data.frame` with the appropriate column names.
  prefs: []
  type: TYPE_NORMAL
- en: Convenient helper functions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Such conversions can be done easily and in a very user-friendly way by, for
    example, using the `plyr` package, a general version of the `dplyr` package, which
    stands for *plyr specialized f* *or data frames*.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `plyr` package provides a variety of functions to apply data from `data.frame`,
    `list`, or `array` objects, and can return the results in any of the mentioned
    formats. The naming scheme of these functions is easy to remember: the first character
    of the function name stands for the class of the input data, and the second character
    represents the output format, all followed by *ply* in all cases. Besides the
    three abovementioned R classes, there are some special options coded by the characters:'
  prefs: []
  type: TYPE_NORMAL
- en: '`d` stands for `data.frame`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`s` stands for `array`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`l` stands for `list`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`m` is a special input type, which means that we provide multiple arguments
    in a tabular format for the function'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`r` input type expects an integer, which specifies the number of times the
    function will be replicated'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`_` is a special output type that does not return anything for the function'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Thus, the following most frequently used combinations are available:'
  prefs: []
  type: TYPE_NORMAL
- en: '`ddply` takes `data.frame` as input and returns `data.frame`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ldply` takes `list` as input but returns `data.frame`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`l_ply` does not return anything, but it''s really useful for example, to iterate
    through a number of elements instead of a `for` loop; as with a set `.progress`
    argument, the function can show the current state of iterations, the remaining
    time'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Please find more details, examples, and use cases of `plyr` in [Chapter 4](ch04.html
    "Chapter 4. Restructuring Data"), *Restructuring Data*. Here, we will only concentrate
    on how to summarize data. To this end, we will use `ddply` (not to be confused
    with the `dplyr` package) in all the following examples: taking `data.frame` as
    the input argument and returning data with the same class.'
  prefs: []
  type: TYPE_NORMAL
- en: 'So, let''s load the package and apply the `mean` function on the `Diverted`
    column over each subset by `DayOfWeek`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `.` function of the `plyr` package provides us with a convenient way of
    referring to a variable (name) as is; otherwise, the content of the `DayOfWeek`
    columns would be interpreted by `ddply`, resulting in an error.
  prefs: []
  type: TYPE_NORMAL
- en: 'An important thing to note here is that `ddply` is much quicker than our first
    attempt with the `aggregate` function. On the other hand, I am not yet pleased
    with the results, `V1` and such creative column names have always freaked me out.
    Instead of updating the names of the `data.frame` post processing let''s call
    the `summarise` helper function instead of the previously applied anonymous one;
    here, we can also provide the desired name for our newly computed column:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Okay, much better. But, can we do even better?
  prefs: []
  type: TYPE_NORMAL
- en: High-performance helper functions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Hadley Wickham, the author of `ggplot`, `reshape`, and several other R packages,
    started working on the second generation, or rather a specialized version, of
    `plyr` in 2008\. The basic concept was that `plyr` is most frequently used to
    transform one `data.frame` to another `data.frame`; therefore, its operation requires
    extra attention. The `dplyr` package, `plyr` specialized for data frames, provides
    a faster implementation of the `plyr` functions, written in raw C++, and `dplyr`
    can also deal with remote databases.
  prefs: []
  type: TYPE_NORMAL
- en: However, the performance improvements also go hand-in-hand with some other changes;
    for example, the syntax of `dplyr` has changed a lot as compared to `plyr`. Although
    the previously mentioned `summarise` function does exist in `dplyr`, we do not
    have the `ddplyr` function any more, as all functions in the package are dedicated
    to act as some component of `plyr::ddplyr`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Anyway, to keep the theoretical background short, if we want to summarize the
    subgroups of a dataset, we have to define the groups before aggregation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting object is the very same `data.frame` that we had previously with
    one exception: a bunch of metadata was merged to the object by the means of attributes.
    To keep the following output short, we do not list the whole structure (`str`)
    of the object, but only the attributes are shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'From this metadata, the `indices` attribute is important. It simply lists the
    IDs of each row for one of the weekdays, so later operations can easily select
    the subgroups from the whole dataset. So, let''s see how the proportion of diverted
    flights looks like with some performance boost due to using `summarise` from `dplyr`
    instead of `plyr`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: The results are pretty familiar, which is good. However, while running this
    example, did you measure the execution time? This was close to an instant, which
    makes `dplyr` even better.
  prefs: []
  type: TYPE_NORMAL
- en: Aggregate with data.table
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Do you remember the second argument of `[.data.table`? It''s called `j`, which
    stands for a `SELECT` or an `UPDATE` SQL statement, and the most important feature
    is that it can be any R expression. Thus, we can simply pass a function there
    and set groups with the help of the `by` argument:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'I am pretty sure that you are not in the least surprised by how fast the results
    were returned by `data.table`, as people can get used to great tools very quickly.
    Further, it was very concise as compared to the previous two-line `dplyr` call,
    right? The only downside of this solution is that the weekdays are ordered by
    some hardly intelligible rank. Please see [Chapter 4](ch04.html "Chapter 4. Restructuring
    Data"), *Restructuring Data*, for more details on this; for now, let''s fix the
    issue quickly by setting a key, which means that we order `data.table` first by
    `DayOfWeek`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To specify a name for the second column in the resulting tabular object instead
    of `V1`, you can specify the `summary` object as a named list, for example, as
    `hflights_dt[, list('mean(Diverted)' = mean(Diverted)), by = DayOfWeek]`, where
    you can use `.` (dot) instead of `list`, just like in `ply` `r`.
  prefs: []
  type: TYPE_NORMAL
- en: Besides getting the results in the expected order, summarizing data by an already
    existing key also runs relatively fast. Let's verify this with some empirical
    evidence on your machine!
  prefs: []
  type: TYPE_NORMAL
- en: Running benchmarks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As already discussed in the previous chapters, with the help of the `microbenchmark`
    package, we can run any number of different functions for a specified number of
    times on the same machine to get some reproducible results on the performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'To this end, we have to define the functions that we want to benchmark first.
    These were compiled from the preceding examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'However, as mentioned before, the `summarise` function in `dplyr` needs some
    prior data restructuring, which also takes time. To this end, let''s define another
    function that also includes the creation of the new data structure along with
    the real aggregation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Similarly, benchmarking `data.table` also requires some additional variables
    for the test environment; as `hlfights_dt` is already sorted by `DayOfWeek`, let''s
    create a new `data.table` object for benchmarking:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Further, it probably makes sense to verify that it has no keys:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Okay, now, we can define the `data.table` test cases along with a function
    that also includes the transformation to `data.table`, and adding an index just
    to be fair with `dplyr`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have all the described implementations ready for testing, let''s
    load the `microbenchmark` package to do its job:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'The results are pretty spectacular: from more than 2,000 milliseconds, we could
    improve our tools to provide the very same results in only a bit more than 1 millisecond.
    The spread can be demonstrated easily on a violin plot with a logarithmic scale:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: '![Running benchmarks](img/2028OS_03_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Therefore, `dplyr` seems to be the most efficient solution, although if we also
    take the extra step (to group `data.frame`) into account, it makes the otherwise
    clear advantage rather unconvincing. As a matter of fact, if we already have a
    `data.table` object, and we can save the transformation of a traditional `data.frame`
    object into `data.table`, then `data.table` performs better than `dplyr`. However,
    I am pretty sure that you will not really notice the time difference between the
    two high-performance solutions; both of these do a very good job with even larger
    datasets.
  prefs: []
  type: TYPE_NORMAL
- en: 'It''s worth mentioning that `dplyr` can work with `data.table` objects as well;
    therefore, to ensure that you are not locked to either package, it''s definitely
    worth using both if needed. The following is a POC example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Okay, so now we are pretty sure to use either `data.table` or `dplyr` for computing
    group averages in the future. However, what about more complex operations?
  prefs: []
  type: TYPE_NORMAL
- en: Summary functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we have discussed earlier, all aggregating functions can take any valid R
    functions to apply on the subsets of the data. Some of the R packages make it
    extremely easy for the users, while a few functions do require you to fully understand
    the package concept, custom syntax, and options to get the most out of the high-performance
    opportunities.
  prefs: []
  type: TYPE_NORMAL
- en: For such more advanced topics, please see [Chapter 4](ch04.html "Chapter 4. Restructuring
    Data"), *Restructuring Data*, and the further readings listed in the *References*
    section at the end of the book.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we will concentrate on a very simple `summary` function, which is extremely
    common in any general data analysis project: counting the number of cases per
    group. This quick example will also highlight some of the differences among the
    referenced alternatives mentioned in this chapter.'
  prefs: []
  type: TYPE_NORMAL
- en: Adding up the number of cases in subgroups
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s focus on `plyr`, `dplyr` and `data.table` now, as I am pretty sure that
    you can construct the `aggregate` and `tapply` versions without any serious issues.
    On the basis of the previous examples, the current task seems fairly easy: instead
    of the `mean` function, we can simply call the `length` function to return the
    number of elements in the `Diverted` column:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we also know that a relatively low number of flights leave Houston on
    Saturday. However, do we really have to type so much to answer such a simple question?
    Further, do we really have to name a variable in which we can count the number
    of cases? You already know the answer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: In short, there is no need to choose a variable from `data.frame` to determine
    its length, as it's a lot easier (and faster) to simply check the number of rows
    in the (sub)datasets.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, we can also return the very same results in a much easier and quicker
    way. Probably, you have already thought of using the good old `table` function
    for such a straightforward task:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'The only problem with the resulting object is that we have to transform it
    further, for example, to `data.frame` in most cases. Well, `plyr` already has
    a helper function to do this in one step, with a very intuitive name:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Therefore, we end up with some rather simple examples for counting data, but
    let us also see how to implement summary tables with `dplyr`. If you simply try
    to modify our previous `dplyr` commands, you will soon realize that passing the
    `length` or `nrow` function, as we did in `plyr`, simply does not work. However,
    reading the manuals or some related questions on StackOverflow soon points our
    attention to a handy helper function called `n`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'However, to be honest, do we really need this relatively complex approach?
    If you remember the structure of `hflights_DayOfWeek`, you will soon realize that
    there is a lot easier and quicker way to find out the overall number of flights
    on each weekday:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Further, just to make sure that we do not forget the custom (yet pretty) syntax
    of `data.table`, let us compute the results with another helper function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we introduced some effective and convenient ways of filtering
    and summarizing data. We discussed some use cases on filtering the rows and columns
    of datasets. We also learned how to summarize data for further analysis. After
    getting familiar with the most popular implementations of such tasks, we compared
    them with reproducible examples and a benchmarking package.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will continue this journey of restructuring datasets
    and creating new variables.
  prefs: []
  type: TYPE_NORMAL
