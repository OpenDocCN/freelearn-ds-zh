["```py\n#import packages\nimport igraph as ig\nfrom igraph import Graph\nimport numpy as np\nimport pandas as pd\nimport os\nimport matplotlib as plt\n#import stock data\nFile=\"C:/users/njfar/OneDrive/Desktop/AAPL_GOOGL_Stock_2004_2020.csv\"\npwd=os.getcwd()\nos.chdir(os.path.dirname(File))\nmydata=pd.read_csv(os.path.basename(File),encoding='latin1')\n```", "```py\n#script to create time slices, derive networks,\n#and compute centrality metrics\nstock_networks=[]\nbet_t=[]\ndeg_t=[]\neig_t=[]\nvcurv_t=[]\nbet_ave=[]\ndeg_ave=[]\neig_ave=[]\nvcurv_ave=[]\nfor Date in range(5,3932):\n    #wrangle data into graph\n    data=mydata.iloc[(Date-5):(Date),1:5]\n    cor=np.corrcoef(data.transpose())\n    cor[cor>=0.5]=1\n    cor[cor<0.5]=0\n    stock_data=Graph.Adjacency(cor)\n    stock_networks.append(stock_data)\n    #derive some centrality metrics\n    d=Graph.degree(stock_data)\n    deg_t.append(d)\n    deg_ave.append(np.mean(d))\n    b=Graph.betweenness(stock_data)\n    bet_t.append(b)\n    bet_ave.append(np.mean(b))\n    e=Graph.pagerank(stock_data)\n    eig_t.append(e)\n    eig_ave.append(np.mean(e))\n    #create Forman–Ricci curvature calculations\n    ecurvw=[]\n    for edge in stock_data.es:\n        s=edge.source\n        t=edge.target\n        ecurvw.append(2-d[s]-d[t])\n    vcurvw=[]\n    for vertex in stock_data.vs:\n        inc=Graph.incident(stock_data,vertex)\n        inc_curv=[]\n        for i in inc:\n            inc_curv.append(ecurvw[i])\n        vcurvw.append(sum(inc_curv))\n    vcurv_t.append(vcurvw)\n    vcurv_ave.append(np.mean(vcurvw))\n```", "```py\n#examine correlations among metrics across the time series\nprint(np.corrcoef(deg_ave,eig_ave))\nprint(np.corrcoef(deg_ave,bet_ave))\nprint(np.corrcoef(deg_ave,vcurv_ave))\nprint(np.corrcoef(eig_ave,bet_ave))\nprint(np.corrcoef(eig_ave,vcurv_ave))\nprint(np.corrcoef(bet_ave,vcurv_ave))\n```", "```py\n#plot metric averages across time slices\ntime=range(0,3927)\nplt.plot(time, deg_ave, label = \"Degree Average\")\nplt.plot(time, eig_ave, label = \"Pagerank Average\")\nplt.plot(time, bet_ave, label = \"Betweenness Average\")\nplt.plot(time, vcurv_ave, label = \"Forman–Ricci Curvature Average\")\nplt.legend()\nplt.show()\n```", "```py\n#script to create time slices, derive networks,\n#and compute centrality metrics\nstock_networks=[]\nbet_t=[]\ndeg_t=[]\neig_t=[]\nvcurv_t=[]\nbet_ave=[]\ndeg_ave=[]\neig_ave=[]\nvcurv_ave=[]\nfor Date in range(5,3932):\n    #wrangle data into graph\n    data=mydata.iloc[(Date-5):(Date),1:5]\n    cor=np.corrcoef(data.transpose())\n    cor[cor>=0.9]=1\n    cor[cor<0.9]=0\n    stock_data=Graph.Adjacency(cor)\n    stock_networks.append(stock_data)\n    #derive some centrality metrics\n    d=Graph.degree(stock_data)\n    deg_t.append(d)\n    deg_ave.append(np.mean(d))\n    b=Graph.betweenness(stock_data)\n    bet_t.append(b)\n    bet_ave.append(np.mean(b))\n    e=Graph.pagerank(stock_data)\n    eig_t.append(e)\n    eig_ave.append(np.mean(e))\n    #create Forman–Ricci curvature calculations\n    ecurvw=[]\n    for edge in stock_data.es:\n        s=edge.source\n        t=edge.target\n        ecurvw.append(2-d[s]-d[t])\n    vcurvw=[]\n    for vertex in stock_data.vs:\n        inc=Graph.incident(stock_data,vertex)\n        inc_curv=[]\n        for i in inc:\n            inc_curv.append(ecurvw[i])\n        vcurvw.append(sum(inc_curv))\n    vcurv_t.append(vcurvw)\n    vcurv_ave.append(np.mean(vcurvw))\n```", "```py\n#examine correlations among metrics across the time series\nprint(np.corrcoef(deg_ave,eig_ave))\nprint(np.corrcoef(deg_ave,bet_ave))\nprint(np.corrcoef(deg_ave,vcurv_ave))\nprint(np.corrcoef(eig_ave,bet_ave))\nprint(np.corrcoef(eig_ave,vcurv_ave))\nprint(np.corrcoef(bet_ave,vcurv_ave))\n```", "```py\n#plot metric averages across time slices\ntime=range(0,3927)\nplt.plot(time, deg_ave, label = \"Degree Average\")\nplt.plot(time, eig_ave, label = \"Pagerank Average\")\nplt.plot(time, bet_ave, label = \"Betweenness Average\")\nplt.plot(time, vcurv_ave, label = \"Forman–Ricci Curvature Average\")\nplt.legend()\nplt.show()\n```", "```py\n#define Vietoris–Rips complex\nfrom itertools import combinations\nfrom numpy import linalg as LA\ndef graph_VR(points, eps):\n    points=[np.array(x) for x in points]\n    vr=[(x,y) for (x,y) in combinations(points, 2)\n    if LA.norm(x - y) <= 2*eps]\n    return np.array(vr)\n```", "```py\n#apply Vietoris–Rips with multiple thresholds to a slice of our stock #dataset\ndata=mydata.iloc[0:5,1:5]\nvr1=graph_VR(data.transpose(),1)\nvr2=graph_VR(data.transpose(),10)\n```", "```py\n#print the results\nprint(\"Vietoris–Rips Complex, Threshold=1:\")\nprint(vr1)\nprint(\"Vietoris–Rips Complex, Threshold=10:\")\nprint(vr2)\n```", "```py\nVietoris–Rips Complex, Threshold=1:\n[[0 1]\n [0 2]\n [1 2]\n [1 3]\n [2 3]\n [2 4]\n [3 4]]\nVietoris–Rips Complex, Threshold=10:\n[[0 1]\n [0 2]\n [0 3]\n [0 4]\n [1 2]\n [1 3]\n [1 4]\n [2 3]\n [2 4]\n [3 4]]\n```", "```py\nedges1 = [(0,1),(0,2),(1,2),(1,3),(2,3),(2,4), (3,4)]\nimport networkx as nx\nG1 = nx.Graph()\nG1.add_edges_from(edges1)\nnx.draw(G1,with_labels=True)\n```", "```py\nedges10 = [(0,1),(0,2),(0,3),(0,4),(1,2),(1,3),(1,4),(2,3),(2,4),(3,4)]\nimport networkx as nx\nG10 = nx.Graph()\nG10.add_edges_from(edges10)\nnx.draw(G10,with_labels=True)\n```"]