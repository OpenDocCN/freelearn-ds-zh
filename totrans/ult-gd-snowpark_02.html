<html><head></head><body>
<div><h1 class="chapter-number" id="_idParaDest-16"><a id="_idTextAnchor015" class="calibre6 pcalibre1 pcalibre"/>1</h1>
<h1 id="_idParaDest-17" class="calibre5"><a id="_idTextAnchor016" class="calibre6 pcalibre1 pcalibre"/>Discovering Snowpark</h1>
<p class="calibre3">Snowpark is the recent major innovation released by Snowflake that provides an intuitive set of libraries and runtimes for querying and processing data at scale in Snowflake. This chapter aims to guide you through Snowpark to understand its unique capabilities. In addition, the chapter helps you learn how to utilize Python with Snowpark and implement it in various workloads such as data engineering, data science, and data applications. By the end of this chapter, you will have grasped Snowpark’s capabilities and benefits, including faster data processing, scalability, and reduced costs.</p>
<p class="calibre3">In this chapter, we’re going to cover the following main topics:</p>
<ul class="calibre15">
<li class="calibre14">Introducing Snowpark</li>
<li class="calibre14">Leveraging Python for Snowpark</li>
<li class="calibre14">Understanding Snowpark for different workloads</li>
<li class="calibre14">Realizing the value of using Snowpark</li>
</ul>
<h1 id="_idParaDest-18" class="calibre5"><a id="_idTextAnchor017" class="calibre6 pcalibre1 pcalibre"/>Introducing Snowpark</h1>
<p class="calibre3">Snowflake, founded in 2012, started its journey to the data cloud by completely re-engineering the <a id="_idIndexMarker000" class="calibre6 pcalibre1 pcalibre"/>world of data and rethinking how a reliable, secure, high-performance, and scalable data-processing system should be architected for the cloud. It started with offering cloud-based data warehousing through a managed <strong class="bold">Software as a Service</strong> (<strong class="bold">SaaS</strong>) platform<a id="_idIndexMarker001" class="calibre6 pcalibre1 pcalibre"/> to load, analyze, and process large volumes of data. The success of Snowflake lies in the fact that it is a cloud-native managed solution that is built on top of the major public cloud providers such as Amazon Web Services, Microsoft Azure, and Google Cloud Platform by automatically providing a reliable, secure, high-performance, and scalable data processing system for organizations without the need to deploy hardware or install or configure any software.</p>
<p class="calibre3">As with any cloud data warehousing, Snowflake supports <strong class="bold">American National Standards Institute</strong> (<strong class="bold">ANSI</strong>) SQL as the language of choice. Although SQL is a powerful declarative language<a id="_idIndexMarker002" class="calibre6 pcalibre1 pcalibre"/> that allows users to ask questions about data, it is constrained to data warehouse workloads, limiting the support for advanced workloads such as data science and data engineering, which require developers to write the solution in other programming languages leading them to move data out of Snowflake to perform these workloads.</p>
<p class="calibre3">Snowflake’s solution to this <a id="_idIndexMarker003" class="calibre6 pcalibre1 pcalibre"/>challenge is <strong class="bold">Snowpark</strong>, an innovative developer framework that streamlines the process of building complex data pipelines. With Snowpark, data scientists and developers can directly interact with Snowflake using their preferred programming language, enabling them to quickly and securely deploy <strong class="bold">machine learning</strong> (<strong class="bold">ML</strong>) models, execute<a id="_idIndexMarker004" class="calibre6 pcalibre1 pcalibre"/> data pipelines, and develop data applications on Snowflake’s virtual compute warehouse in a serverless manner without having to transfer data outside of Snowflake.</p>
<p class="calibre3">Snowpark enables data teams to collaborate on the data by natively supporting work with DataFrame style programming in Python, Scala, or Java, exposing deeply integrated interfaces in these languages to augment Snowflake’s original SQL language and minimizing the complexity of having to manage different environments for advanced data pipelines. This has led developers to leverage Snowflake’s robust and scalable computing power to ship code to the data without exporting it outside Snowflake into other environments.</p>
<p class="calibre3">In this section, we covered a brief introduction to Snowpark and learned how it fits into the Snowflake ecosystem and how it helps developers. The following section will cover how to leverage Python for Snowpark.</p>
<h1 id="_idParaDest-19" class="calibre5"><a id="_idTextAnchor018" class="calibre6 pcalibre1 pcalibre"/>Leveraging Python for Snowpark</h1>
<p class="calibre3">In June 2022, Snowflake made a significant announcement, revealing the much-anticipated <strong class="bold">Snowpark for Python</strong>. This new release has rapidly emerged as the preferred <a id="_idIndexMarker005" class="calibre6 pcalibre1 pcalibre"/>programming language for Snowpark, providing users with a more extensive range of options for programming data in Snowflake. Moreover, Snowpark has simplified managing data architectures, enabling users to operate more quickly and efficiently.</p>
<p class="calibre3">Snowpark for Python is a cutting-edge, enterprise-grade, open-source innovation integrated into the Snowflake data cloud. As a result, the platform delivers a seamless, unified experience for data scientists and developers. In addition, the Snowpark for Python package <a id="_idIndexMarker006" class="calibre6 pcalibre1 pcalibre"/>is built upon the Snowflake Python connector. The Python connector enables users to execute SQL commands and other essential functions in Snowflake and Snowpark for Python empowers users to undertake more advanced data applications.</p>
<p class="calibre3">For instance, the platform permits users<a id="_idIndexMarker007" class="calibre6 pcalibre1 pcalibre"/> to run <strong class="bold">user-defined functions</strong> (<strong class="bold">UDFs</strong>), <strong class="bold">external functions</strong>, and <strong class="bold">stored procedures</strong> directly within Snowflake. This powerful new functionality enables data scientists, engineers, and <a id="_idIndexMarker008" class="calibre6 pcalibre1 pcalibre"/>developers <a id="_idIndexMarker009" class="calibre6 pcalibre1 pcalibre"/>to create robust and secure data pipelines and ML models within Snowflake. As a result, they can leverage the platform’s superior performance, elasticity, and security features to deliver advanced insights and drive meaningful business outcomes. Overall, Snowpark for Python represents a significant step forward for Snowflake, offering users enhanced functionality and flexibility while retaining the platform’s exceptional performance and security features.</p>
<p class="calibre3">Snowpark for Python supports pre-vetted open-source packages through integration with the <strong class="bold">Anaconda</strong> environment that <a id="_idIndexMarker010" class="calibre6 pcalibre1 pcalibre"/>executes on an Anaconda-powered sandbox inside Snowflake’s virtual compute warehouses, which provides a familiar interface for the developers. The integrated Anaconda package manager is valuable for developers as it comes with a comprehensive set of curated open-source packages and supports resolving dependencies between different packages and versions. It is a huge time-saver and helps prevent developers from dealing with “dependency hell.”</p>
<h2 id="_idParaDest-20" class="calibre7"><a id="_idTextAnchor019" class="calibre6 pcalibre1 pcalibre"/>Capabilities of Snowpark for Python</h2>
<p class="calibre3">Snowpark for <a id="_idIndexMarker011" class="calibre6 pcalibre1 pcalibre"/>Python is generally available across all cloud instances of Snowflake. It helps accelerate different workloads and comes with a rich set of capabilities, as follows:</p>
<ul class="calibre15">
<li class="calibre14">It allows developers to write Python code within Snowflake, enabling them to directly leverage the power of Python libraries and frameworks in Snowflake</li>
<li class="calibre14">It supports popular open-source Python libraries such as pandas, NumPy, SciPy, and scikit-learn, along with other libraries, allowing developers to perform complex data analysis and ML tasks directly within Snowflake</li>
<li class="calibre14">It also provides access to external data sources such as AWS S3, Azure Blob storage, and Google Cloud Storage, allowing developers to work with data stored outside Snowflake</li>
<li class="calibre14">It provides <a id="_idIndexMarker012" class="calibre6 pcalibre1 pcalibre"/>seamless integration with Snowflake’s SQL engine, allowing developers to write queries using functional programming methods with Python that compile to SQL</li>
<li class="calibre14">It also supports distributed processing, allowing developers to scale their Python code to handle large datasets and complex logic</li>
<li class="calibre14">It enables developers to build custom UDFs that can be used within SQL queries, allowing for greater flexibility and customization of data processing workflows</li>
<li class="calibre14">Snowpark provides a Python development environment within Snowflake, allowing developers to write, test, and debug Python code directly within the Snowflake UI</li>
<li class="calibre14">It enables developers to work with various data formats such as CSV, JSON, Parquet, and Avro, providing data processing and analysis flexibility</li>
<li class="calibre14">It provides a unified data processing experience that works with SQL and Python in a single environment</li>
<li class="calibre14">It enables developers to create custom data pipelines using Python code, making integrating Snowflake with other data sources and data processing tools easier</li>
<li class="calibre14">It can handle real-time and batch data processing, making it easier to build data-intensive workloads</li>
<li class="calibre14">It provides a robust<a id="_idIndexMarker013" class="calibre6 pcalibre1 pcalibre"/> framework built on Snowflake that ensures data privacy and compliance <a id="_idIndexMarker014" class="calibre6 pcalibre1 pcalibre"/>with industry <a id="_idIndexMarker015" class="calibre6 pcalibre1 pcalibre"/>standards such as the <strong class="bold">Health Insurance Portability and Accountability Act</strong> (<strong class="bold">HIPAA</strong>), <strong class="bold">General Data Protection Regulation</strong> (<strong class="bold">GDPR</strong>), and <strong class="bold">Security Operations </strong><strong class="bold">Center</strong> (<strong class="bold">SOC</strong>)</li>
<li class="calibre14">Snowpark supports enhancing data by <a id="_idIndexMarker016" class="calibre6 pcalibre1 pcalibre"/>leveraging <strong class="bold">Snowflake Marketplace</strong></li>
</ul>
<p class="calibre3">Snowpark for Python packs many capabilities that help developers use it efficiently for various workloads and use cases within Snowflake.</p>
<h2 id="_idParaDest-21" class="calibre7"><a id="_idTextAnchor020" class="calibre6 pcalibre1 pcalibre"/>Why Python for Snowpark</h2>
<p class="calibre3">Although<a id="_idIndexMarker017" class="calibre6 pcalibre1 pcalibre"/> Snowpark supports Python, Scala, and Java, this book will focus only on Python, a de facto for Snowpark development. Python’s growing popularity through high-level built-in data structures with dynamic typing and binding makes it ideal for data operations. In addition, the language is very flexible and easy to learn by developers. Its power lies in the rich open-source ecosystem that is well-supported with a growing list of popular packages.</p>
<p class="calibre3">Python is a general-purpose, versatile programming language for different purposes, such as data engineering, data science, and data applications. It enables developers to learn a single programming language for all their needs.</p>
<p class="calibre3">Snowflake is also heavily investing in Python to make it easier for data scientists, engineers, and application developers to build even more in the data cloud without governance trade-offs.</p>
<p class="calibre3">In this section, we covered the capabilities of Snowpark for Python and why Python is a preferred language for developing Snowpark. The following section will cover how Snowpark can be used for different workloads.</p>
<h1 id="_idParaDest-22" class="calibre5"><a id="_idTextAnchor021" class="calibre6 pcalibre1 pcalibre"/>Understanding Snowpark for different workloads</h1>
<p class="calibre3">The release of <a id="_idIndexMarker018" class="calibre6 pcalibre1 pcalibre"/>Snowpark transformed Snowflake into a complete data platform designed to support various workloads. Snowpark supports multiple workloads, such as data science and ML, data engineering, and data applications.</p>
<h2 id="_idParaDest-23" class="calibre7"><a id="_idTextAnchor022" class="calibre6 pcalibre1 pcalibre"/>Data science and ML</h2>
<p class="calibre3">Python is the favorite<a id="_idIndexMarker019" class="calibre6 pcalibre1 pcalibre"/> language for data scientists. Snowpark for Python supports popular libraries and frameworks such as pandas, NumPy, and scikit-learn, making it the ideal framework for data scientists to perform ML development in Snowflake. In addition, data scientists can use the DataFrames API to interact with data inside Snowflake and perform batch training and inference inside Snowflake. Developers can also use Snowpark for feature engineering, ML model inference, and end-to-end ML pipelines. Snowpark also provides a SnowparkML library to support data science and ML in Snowpark.</p>
<h2 id="_idParaDest-24" class="calibre7"><a id="_idTextAnchor023" class="calibre6 pcalibre1 pcalibre"/>Data engineering</h2>
<p class="calibre3">Data cleansing <a id="_idIndexMarker020" class="calibre6 pcalibre1 pcalibre"/>and ELT workloads are complex, and building a data pipeline with just SQL is where Snowpark can be of great benefit. Snowpark lets developers factor code for readability and reuse it while providing a better capability for unit tests. In addition, with the support of Anaconda, developers can use open-source Python libraries for building reliable data pipelines. The other major challenge with data processing is that the infrastructure requires significant manual effort and maintenance. Snowpark solves this problem by being highly performant, enabling data engineers to work with large datasets quickly and efficiently, building complex data pipelines, and processing large volumes of data without performance issues.</p>
<h2 id="_idParaDest-25" class="calibre7"><a id="_idTextAnchor024" class="calibre6 pcalibre1 pcalibre"/>Data governance and security</h2>
<p class="calibre3">Snowpark <a id="_idIndexMarker021" class="calibre6 pcalibre1 pcalibre"/>supports developing solutions that incorporate data governance and security. Data governance is critical and augments the data science and data engineering use cases. Snowpark simplifies the governance posture by helping organizations understand and improve data quality. Developers can quickly create a function to perform data tests and detect anomalies. Snowpark can utilize the data classification capability to detect <strong class="bold">personally identifiable information</strong> (<strong class="bold">PII</strong>) and<a id="_idIndexMarker022" class="calibre6 pcalibre1 pcalibre"/> classify data that is critical to an organization. Custom functions developed in Snowpark can mask sensitive data such as credit card numbers using the robust dynamic data masking feature while retaining the existing security model in Snowflake.</p>
<h2 id="_idParaDest-26" class="calibre7"><a id="_idTextAnchor025" class="calibre6 pcalibre1 pcalibre"/>Data applications</h2>
<p class="calibre3">Snowpark<a id="_idIndexMarker023" class="calibre6 pcalibre1 pcalibre"/> helps the team develop dynamic data applications that run directly on Snowflake without moving the data outside. Using <strong class="bold">Streamlit</strong>, a<a id="_idIndexMarker024" class="calibre6 pcalibre1 pcalibre"/> powerful open-source library that Snowflake acquired, developers can build native applications using the familiar Python environment. Interactive ML-powered applications can be developed and shared with users securely utilizing role-based access controls entirely on Snowflake’s governed platform, taking advantage of its scale, performance, and governance. The Snowflake Native Application Framework provides a streamlined path to monetize apps through Snowflake Marketplace, where you can make your app available to other Snowflake customers and open new revenue opportunities.</p>
<p class="calibre3">Snowpark supports different workloads and makes Snowflake a complete data cloud solution. The following section will highlight Snowpark’s technical and business benefits.</p>
<h1 id="_idParaDest-27" class="calibre5"><a id="_idTextAnchor026" class="calibre6 pcalibre1 pcalibre"/>Realizing the value of using Snowpark</h1>
<p class="calibre3">The <a id="_idIndexMarker025" class="calibre6 pcalibre1 pcalibre"/>traditional big data approach has been in the industry for a long time and is unsuitable for modern cloud-based scalable workloads. Traditional architecture has many challenges, such as the following:</p>
<ul class="calibre15">
<li class="calibre14">De-coupling the compute and data into separate systems</li>
<li class="calibre14">Running separate processing clusters for different languages</li>
<li class="calibre14">Complexity in managing the system</li>
<li class="calibre14">Data silos and data duplication</li>
<li class="calibre14">Lack of unified security and governance</li>
</ul>
<p class="calibre3">Snowflake solves the traditional system’s challenges using Snowpark, providing tremendous value to the data ecosystem and Snowflake users. The following diagram shows the difference between a traditional approach and Snowflake’s streamlined approach:</p>
<div><div><img alt="Figure 1.1 – Traditional versus Snowflake approach" src="img/B19923_01_001.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 1.1 – Traditional versus Snowflake approach</p>
<p class="calibre3">As you can see<a id="_idIndexMarker026" class="calibre6 pcalibre1 pcalibre"/> from the difference between both approaches, Snowpark’s streamlined approach benefits both the business and the developers by providing a flexible, efficient, and cost-effective way to build data that scales with the business needs. Some of the significant values of using Snowpark are as follows:</p>
<ul class="calibre15">
<li class="calibre14">Snowpark can access data programmatically through the DataFrame APIs, making the data ingestion and integration consistent, as you can integrate various structured and unstructured data</li>
<li class="calibre14">Snowpark standardizes the approach to data processing since the data pipelines are in Python code; they can be tested and deployed and are easier to understand and interpret</li>
<li class="calibre14">Anaconda powers Snowpark for Python and provides easy access to third-party Python libraries that are open source, which enhances the data processing capabilities and empowers developers to perform more</li>
<li class="calibre14">Snowpark integrates and runs seamlessly on the existing Snowflake virtual warehouse, allowing developers to build data applications designed to scale without any additional infrastructure</li>
<li class="calibre14">Snowpark’s framework supports various workloads, such as data engineering, data science, and data applications, providing a unified experience for development on the data cloud</li>
<li class="calibre14">Snowpark delivers<a id="_idIndexMarker027" class="calibre6 pcalibre1 pcalibre"/> a secure, governed environment as it is easy to enforce governance policies, and there is no data movement outside Snowflake</li>
</ul>
<p class="calibre3">Let’s wrap up this chapter.</p>
<h1 id="_idParaDest-28" class="calibre5"><a id="_idTextAnchor027" class="calibre6 pcalibre1 pcalibre"/>Summary</h1>
<p class="calibre3">Snowflake’s Snowpark perfectly coalesces SQL and Python, running complex data processing jobs in the Snowflake data cloud and enabling data engineers, data scientists, and developers to take advantage of Snowflake. In this chapter, we have seen the benefits of Snowpark and why Python is the preferred development language. We also covered different workloads that Snowpark supports.</p>
<p class="calibre3">In the next chapter, we will examine configuring and operating with Snowpark in detail and learn how to use Snowpark for various workloads.</p>
</div>
</body></html>