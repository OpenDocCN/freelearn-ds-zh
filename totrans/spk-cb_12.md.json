["```py\n    scala> val words = sc.textFile(\"hdfs://localhost:9000/user/hduser/words\")\n\n    ```", "```py\n    scala> val wordsFlatMap = words.flatMap(_.split(\"\\\\W+\"))\n\n    ```", "```py\n    scala> val wordsMap = wordsFlatMap.map( w => (w,1))\n\n    ```", "```py\n    scala> val wordCount = wordsMap.reduceByKey(_+_)\n\n    ```", "```py\n    $ spark-shell --drive-memory 4g\n\n    ```", "```py\n    $ spark-submit --drive-memory 4g\n\n    ```", "```py\n    $ spark-shell --executor-memory 4g\n\n    ```", "```py\n    $ spark-submit --executor-memory 4g\n\n    ```", "```py\n    $ spark-shell\n\n    ```", "```py\n    scala> import org.apache.spark.storage.StorageLevel._\n\n    ```", "```py\n    scala> val words = sc.textFile(\"words\")\n\n    ```", "```py\n    scala> words.persist(MEMORY_ONLY_SER)\n\n    ```", "```py\n    $ spark-shell --conf spark.serializer=org.apache.spark.serializer.KryoSerializer\n\n    ```", "```py\n    scala> sc.getConf.registerKryoClasses(Array(classOf[com.infoobjects.CustomClass1],classOf[com.infoobjects.CustomClass2])\n\n    ```", "```py\n$ spark-shell --conf spark.storage.memoryFraction=0.4\n\n```", "```py\n    $ spark-shell\n\n    ```", "```py\n    scala> sc.textFile(\"hdfs://localhost:9000/user/hduser/words\",10)\n\n    ```", "```py\n    $ spark-shell --conf spark.default.parallelism=10\n\n    ```", "```py\n    scala> sc.defaultParallelism\n\n    ```"]