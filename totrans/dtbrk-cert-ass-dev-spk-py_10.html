<html><head></head><body>
		<div id="_idContainer038">
			<h1 id="_idParaDest-245" class="chapter-number"><a id="_idTextAnchor246"/>10</h1>
			<h1 id="_idParaDest-246"><a id="_idTextAnchor247"/>Mock Test 2</h1>
			<h1 id="_idParaDest-247"><a id="_idTextAnchor248"/>Questions</h1>
			<p>Try your hand at these practice questions to test your knowledge of <span class="No-Break">Apache Spark:</span></p>
			<p><span class="No-Break"><strong class="bold">Question 1</strong></span><span class="No-Break">:</span></p>
			<p>What is a task <span class="No-Break">in Spark?</span></p>
			<ol class="margin-left">
				<li class="Alphabets">The unit of work performed for each data partition within a task is <span class="No-Break">the slots</span></li>
				<li class="Alphabets">A task is the second-smallest entity that can be executed <span class="No-Break">within Spark</span></li>
				<li class="Alphabets">Tasks featuring wide dependencies can be combined into a <span class="No-Break">single task</span></li>
				<li class="Alphabets">A task is the smallest component that can be executed <span class="No-Break">within Spark</span></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 2</strong></span><span class="No-Break">:</span></p>
			<p>What is the role of an executor <span class="No-Break">in Spark?</span></p>
			<ol class="margin-left">
				<li class="Alphabets">The executor’s role is to request the transformation of operations into a directed acyclic <span class="No-Break">graph (DAG)</span></li>
				<li class="Alphabets">There can only be one executor within a <span class="No-Break">Spark environment</span></li>
				<li class="Alphabets">Executors are tasked with executing the assignments provided to them by <span class="No-Break">the driver</span></li>
				<li class="Alphabets">The executor schedules queries <span class="No-Break">for execution</span></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 3</strong></span><span class="No-Break">:</span></p>
			<p>Which of the following is one of the tasks of Adaptive Query Execution <span class="No-Break">in Spark?</span></p>
			<ol class="margin-left">
				<li class="Alphabets">Adaptive Query Execution collects runtime statistics during query execution to optimize <span class="No-Break">query plans</span></li>
				<li class="Alphabets">Adaptive Query Execution is responsible for distributing tasks <span class="No-Break">to executors</span></li>
				<li class="Alphabets">Adaptive Query Execution is responsible for wide operations <span class="No-Break">in Spark</span></li>
				<li class="Alphabets">Adaptive Query Execution is responsible for fault tolerance <span class="No-Break">in Spark</span></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 4</strong></span><span class="No-Break">:</span></p>
			<p>Which is the lowest level in Spark’s <span class="No-Break">execution hierarchy?</span></p>
			<ol class="margin-left">
				<li class="Alphabets"><span class="No-Break">Task</span></li>
				<li class="Alphabets"><span class="No-Break">Slot</span></li>
				<li class="Alphabets"><span class="No-Break">Job</span></li>
				<li class="Alphabets"><span class="No-Break">Stage</span></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 5</strong></span><span class="No-Break">:</span></p>
			<p>Which one of these operations is <span class="No-Break">an action?</span></p>
			<ol class="margin-left">
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">DataFrame.count()</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">DataFrame.filter()</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">DataFrame.select()</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">DataFrame.groupBy()</strong></span></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 6</strong></span><span class="No-Break">:</span></p>
			<p>Which of the following describes the characteristics of the <span class="No-Break">DataFrame API?</span></p>
			<ol class="margin-left">
				<li class="Alphabets">The DataFrame API is based on resilient distributed dataset (RDD) at <span class="No-Break">the backend</span></li>
				<li class="Alphabets">The DataFrame API is available in Scala, but it is not available <span class="No-Break">in Python</span></li>
				<li class="Alphabets">The DataFrame API does not have data <span class="No-Break">manipulation functions</span></li>
				<li class="Alphabets">The DataFrame API is used for distributing tasks <span class="No-Break">in executors</span></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 7</strong></span><span class="No-Break">:</span></p>
			<p>Which of the following statements is accurate <span class="No-Break">about executors?</span></p>
			<ol class="margin-left">
				<li class="Alphabets">Slots are not a part of <span class="No-Break">an executor</span></li>
				<li class="Alphabets">Executors are able to run tasks in parallel <span class="No-Break">via slots</span></li>
				<li class="Alphabets">Executors are always equal <span class="No-Break">to tasks</span></li>
				<li class="Alphabets">An executor is responsible for distributing tasks for <span class="No-Break">a job</span></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 8</strong></span><span class="No-Break">:</span></p>
			<p>Which of the following statements is accurate about the <span class="No-Break">Spark driver?</span></p>
			<ol class="margin-left">
				<li class="Alphabets">There are multiple drivers in a <span class="No-Break">Spark application</span></li>
				<li class="Alphabets">Slots are a part of <span class="No-Break">a driver</span></li>
				<li class="Alphabets">Drivers execute tasks <span class="No-Break">in parallel</span></li>
				<li class="Alphabets">It is the responsibility of the Spark driver to transform operations into <span class="No-Break">DAG computations</span></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 9</strong></span><span class="No-Break">:</span></p>
			<p>Which one of these operations is a <span class="No-Break">wide transformation?</span></p>
			<ol class="margin-left">
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">DataFrame.show()</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">DataFrame.groupBy()</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">DataFrame.repartition()</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">DataFrame.select()</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">DataFrame.filter()</strong></span></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 10</strong></span><span class="No-Break">:</span></p>
			<p>Which of the following statements is correct about <span class="No-Break">lazy evaluation?</span></p>
			<ol class="margin-left">
				<li class="Alphabets">Execution is triggered <span class="No-Break">by transformations</span></li>
				<li class="Alphabets">Execution is triggered <span class="No-Break">by actions</span></li>
				<li class="Alphabets">Statements are executed as they appear in <span class="No-Break">the code</span></li>
				<li class="Alphabets">Spark distributes tasks to <span class="No-Break">different executors</span></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 11</strong></span><span class="No-Break">:</span></p>
			<p>Which of the following is true about DAGs <span class="No-Break">in Spark?</span></p>
			<ol class="margin-left">
				<li class="Alphabets">DAGs are <span class="No-Break">lazily evaluated</span></li>
				<li class="Alphabets">DAGs can be scaled horizontally <span class="No-Break">in Spark</span></li>
				<li class="Alphabets">DAGs are responsible for processing partitions in an optimized and <span class="No-Break">distributed fashion</span></li>
				<li class="Alphabets">DAG is comprised of tasks that can run <span class="No-Break">in parallel</span></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 12</strong></span><span class="No-Break">:</span></p>
			<p>Which of the following statements is true about Spark’s fault <span class="No-Break">tolerance mechanism?</span></p>
			<ol class="margin-left">
				<li class="Alphabets">Spark achieves fault tolerance <span class="No-Break">via DAGs</span></li>
				<li class="Alphabets">It is the responsibility of the executor to enable fault tolerance <span class="No-Break">in Spark</span></li>
				<li class="Alphabets">Because of fault tolerance, Spark can recompute any <span class="No-Break">failed RDD</span></li>
				<li class="Alphabets">Spark builds a fault-tolerant layer on top of the legacy RDD data system, which by itself is not <span class="No-Break">fault tolerant</span></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 13</strong></span><span class="No-Break">:</span></p>
			<p>What is the core of Spark’s <span class="No-Break">fault-tolerant mechanism?</span></p>
			<ol class="margin-left">
				<li class="Alphabets">RDD is at the core of Spark, which is fault tolerant <span class="No-Break">by design</span></li>
				<li class="Alphabets">Data partitions, since data can <span class="No-Break">be recomputed</span></li>
				<li class="Alphabets">DataFrame is at the core of Spark since it <span class="No-Break">is immutable</span></li>
				<li class="Alphabets">Executors ensure that Spark remains <span class="No-Break">fault tolerant</span></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 14</strong></span><span class="No-Break">:</span></p>
			<p>What is accurate about jobs <span class="No-Break">in Spark?</span></p>
			<ol class="margin-left">
				<li class="Alphabets">Different stages in a job may be executed <span class="No-Break">in parallel</span></li>
				<li class="Alphabets">Different stages in a job cannot be executed <span class="No-Break">in parallel</span></li>
				<li class="Alphabets">A task consists of <span class="No-Break">many jobs</span></li>
				<li class="Alphabets">A stage consists of <span class="No-Break">many jobs</span></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 15</strong></span><span class="No-Break">:</span></p>
			<p>What is accurate about a shuffle <span class="No-Break">in Spark?</span></p>
			<ol class="margin-left">
				<li class="Alphabets">In a shuffle, data is sent to multiple partitions to <span class="No-Break">be processed</span></li>
				<li class="Alphabets">In a shuffle, data is sent to a single partition to <span class="No-Break">be processed</span></li>
				<li class="Alphabets">A shuffle is an action that triggers evaluation <span class="No-Break">in Spark</span></li>
				<li class="Alphabets">In a shuffle, all data remains in memory to <span class="No-Break">be processed</span></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 16</strong></span><span class="No-Break">:</span></p>
			<p>What is accurate about the cluster manager <span class="No-Break">in Spark?</span></p>
			<ol class="margin-left">
				<li class="Alphabets">The cluster manager is responsible for managing resources <span class="No-Break">for Spark</span></li>
				<li class="Alphabets">The cluster manager is responsible for working with <span class="No-Break">executors directly</span></li>
				<li class="Alphabets">The cluster manager is responsible for creating <span class="No-Break">query plans</span></li>
				<li class="Alphabets">The cluster manager is responsible for <span class="No-Break">optimizing DAGs</span></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 17</strong></span><span class="No-Break">:</span></p>
			<p>The following code block needs to take the sum and average of the <strong class="source-inline">salary</strong> column for each department in the <strong class="source-inline">df</strong> DataFrame. Then, it should calculate the sum and maximum value for the <span class="No-Break"><strong class="source-inline">bonus</strong></span><span class="No-Break"> column:</span></p>
			<pre class="source-code">
df.___1___ ("department").___2___ (sum("salary").alias("sum_salary"), ___3___ ("salary").alias("avg_salary"), sum("bonus").alias("sum_bonus"), ___4___("bonus").alias("max_bonus") )</pre>			<p>Choose the answer that correctly fills the blanks in the code block to <span class="No-Break">accomplish this:</span></p>
			<ol class="margin-left">
				<li class="Alphabets"><ol><li class="lower-roman"><span class="No-Break"><strong class="source-inline">groupBy</strong></span></li><li class="lower-roman"><span class="No-Break"><strong class="source-inline">agg</strong></span></li><li class="lower-roman"><span class="No-Break"><strong class="source-inline">avg</strong></span></li><li class="lower-roman"><span class="No-Break"><strong class="source-inline">max</strong></span></li></ol></li>
				<li class="Alphabets"><ol><li class="lower-roman"><span class="No-Break"><strong class="source-inline">filter</strong></span></li><li class="lower-roman"><span class="No-Break"><strong class="source-inline">agg</strong></span></li><li class="lower-roman"><span class="No-Break"><strong class="source-inline">avg</strong></span></li><li class="lower-roman"><span class="No-Break"><strong class="source-inline">max</strong></span></li></ol></li>
				<li class="Alphabets"><ol><li class="lower-roman"><span class="No-Break"><strong class="source-inline">groupBy</strong></span></li><li class="lower-roman"><span class="No-Break"><strong class="source-inline">avg</strong></span></li><li class="lower-roman"><span class="No-Break"><strong class="source-inline">agg</strong></span></li><li class="lower-roman"><span class="No-Break"><strong class="source-inline">max</strong></span></li></ol></li>
				<li class="Alphabets"><ol><li class="lower-roman"><span class="No-Break"><strong class="source-inline">groupBy</strong></span></li><li class="lower-roman"><span class="No-Break"><strong class="source-inline">agg</strong></span></li><li class="lower-roman"><span class="No-Break"><strong class="source-inline">avg</strong></span></li><li class="lower-roman"><span class="No-Break"><strong class="source-inline">avg</strong></span></li></ol></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 18</strong></span><span class="No-Break">:</span></p>
			<p>The following code block contains an error. The code block needs to join the <strong class="source-inline">salaryDf</strong> DataFrame with the bigger <strong class="source-inline">employeeDf</strong> DataFrame on the <span class="No-Break"><strong class="source-inline">employeeID</strong></span><span class="No-Break"> column:</span></p>
			<pre class="source-code">
salaryDf.join(employeeDf, "employeeID", how="broadcast")</pre>			<p>Identify <span class="No-Break">the error:</span></p>
			<ol class="margin-left">
				<li class="Alphabets">Instead of <strong class="source-inline">join</strong>, the code should <span class="No-Break">use </span><span class="No-Break"><strong class="source-inline">innerJoin</strong></span></li>
				<li class="Alphabets"><strong class="source-inline">broadcast</strong> is not a <strong class="source-inline">join</strong> type in Spark for joining <span class="No-Break">two DataFrames</span></li>
				<li class="Alphabets"><strong class="source-inline">salaryDf</strong> and <strong class="source-inline">employeeDf</strong> should <span class="No-Break">be swapped</span></li>
				<li class="Alphabets">In the <strong class="source-inline">how</strong> parameter, <strong class="source-inline">crossJoin</strong> should be used instead <span class="No-Break">of </span><span class="No-Break"><strong class="source-inline">broadcast</strong></span></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 19</strong></span><span class="No-Break">:</span></p>
			<p>Which of the following code blocks shuffles the <strong class="source-inline">df</strong> DataFrame to have 20 partitions instead of <span class="No-Break">5 partitions?</span></p>
			<ol class="margin-left">
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.repartition(5)</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.repartition(20)</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.coalesce(20)</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.coalesce(5)</strong></span></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 20</strong></span><span class="No-Break">:</span></p>
			<p>Which of the following operations will <span class="No-Break">trigger evaluation?</span></p>
			<ol class="margin-left">
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.filter()</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.distinct()</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.intersect()</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.join()</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.count()</strong></span></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 21</strong></span><span class="No-Break">:</span></p>
			<p>Which of the following code blocks returns unique values for the <strong class="source-inline">age</strong> and <strong class="source-inline">name</strong> columns in the <strong class="source-inline">df</strong> DataFrame in its respective columns where all values are unique in <span class="No-Break">these columns?</span></p>
			<ol class="margin-left">
				<li class="Alphabets"><strong class="source-inline">df.select('age').join(df.select('name'), </strong><span class="No-Break"><strong class="source-inline">col(state)==col('name'), 'inner').show()</strong></span></li>
				<li class="Alphabets"><strong class="source-inline">df.select(col('age'), </strong><span class="No-Break"><strong class="source-inline">col('name')).agg({'*': 'count'}).show()</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.select('age', 'name').distinct().show()</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.select('age').unionAll(df.select('name')).distinct().show()</strong></span></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 22</strong></span><span class="No-Break">:</span></p>
			<p>Which of the following code blocks returns the count of the total number of rows in the <span class="No-Break"><strong class="source-inline">df</strong></span><span class="No-Break"> DataFrame?</span></p>
			<ol class="margin-left">
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.count()</strong></span></li>
				<li class="Alphabets"><strong class="source-inline">df.select(col('state'), </strong><span class="No-Break"><strong class="source-inline">col('department')).agg({'*': 'count'}).show()</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.select('state', 'department').distinct().show()</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.select('state').union(df.select('department')).distinct().show()</strong></span></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 23</strong></span><span class="No-Break">:</span></p>
			<p>The following code block contains an error. The code block should save the <strong class="source-inline">df</strong> DataFrame at the <strong class="source-inline">filePath</strong> path as a new <span class="No-Break">parquet file:</span></p>
			<pre class="source-code">
df.write.mode("append").parquet(filePath)</pre>			<p>Identify <span class="No-Break">the error:</span></p>
			<ol class="margin-left">
				<li class="Alphabets">The code block should have <strong class="source-inline">overwrite</strong> instead of <strong class="source-inline">append</strong> as <span class="No-Break">an option</span></li>
				<li class="Alphabets">The code should be <strong class="source-inline">write.parquet</strong> instead <span class="No-Break">of </span><span class="No-Break"><strong class="source-inline">write.mode</strong></span></li>
				<li class="Alphabets">The <strong class="source-inline">df.write</strong> operation cannot be called directly from <span class="No-Break">the DataFrame</span></li>
				<li class="Alphabets">The first part of the code should <span class="No-Break">be </span><span class="No-Break"><strong class="source-inline">df.write.mode(append)</strong></span></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 24</strong></span><span class="No-Break">:</span></p>
			<p>Which of the following code blocks adds a <strong class="source-inline">salary_squared</strong> column to the <strong class="source-inline">df</strong> DataFrame that is the square of the <span class="No-Break"><strong class="source-inline">salary</strong></span><span class="No-Break"> column?</span></p>
			<ol class="margin-left">
				<li class="Alphabets"><strong class="source-inline">df.withColumnRenamed("salary_squared", </strong><span class="No-Break"><strong class="source-inline">pow(col("salary"), 2))</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.withColumn("salary_squared", col("salary"*2))</strong></span></li>
				<li class="Alphabets"><strong class="source-inline">df.withColumn("salary_squared", </strong><span class="No-Break"><strong class="source-inline">pow(col("salary"), 2))</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.withColumn("salary_squared", square(col("salary")))</strong></span></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 25</strong></span><span class="No-Break">:</span></p>
			<p>Which of the following code blocks performs a join in which the small <strong class="source-inline">salaryDf</strong> DataFrame is sent to all executors so that it can be joined with the <strong class="source-inline">employeeDf</strong> DataFrame on the <strong class="source-inline">employeeSalaryID</strong> and <strong class="source-inline">EmployeeID</strong> <span class="No-Break">columns, respectively?</span></p>
			<ol class="margin-left">
				<li class="Alphabets"><strong class="source-inline">employeeDf.join(salaryDf, "employeeDf.employeeID == </strong><span class="No-Break"><strong class="source-inline">salaryDf.employeeSalaryID", "inner")</strong></span></li>
				<li class="Alphabets"><strong class="source-inline">employeeDf.join(salaryDf, "employeeDf.employeeID == </strong><span class="No-Break"><strong class="source-inline">salaryDf.employeeSalaryID", "broadcast")</strong></span></li>
				<li class="Alphabets"><strong class="source-inline">employeeDf.join(broadcast(salaryDf), employeeDf.employeeID == </strong><span class="No-Break"><strong class="source-inline">salaryDf.employeeSalaryID)</strong></span></li>
				<li class="Alphabets"><strong class="source-inline">salaryDf.join(broadcast(employeeDf), employeeDf.employeeID == </strong><span class="No-Break"><strong class="source-inline">salaryDf.employeeSalaryID)</strong></span></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 26</strong></span><span class="No-Break">:</span></p>
			<p>Which of the following code blocks performs an outer join between the <strong class="source-inline">salarydf</strong> DataFrame and the <strong class="source-inline">employeedf</strong> DataFrame, using the <strong class="source-inline">employeeID</strong> and <strong class="source-inline">salaryEmployeeID</strong> columns as join <span class="No-Break">keys respectively?</span></p>
			<ol class="margin-left">
				<li class="Alphabets"><strong class="source-inline">Salarydf.join(employeedf, "outer", salarydf.employeedf == </strong><span class="No-Break"><strong class="source-inline">employeeID.salaryEmployeeID)</strong></span></li>
				<li class="Alphabets"><strong class="source-inline">salarydf.join(employeedf, employeeID == </strong><span class="No-Break"><strong class="source-inline">salaryEmployeeID)</strong></span></li>
				<li class="Alphabets"><strong class="source-inline">salarydf.join(employeedf, salarydf.salaryEmployeeID == </strong><span class="No-Break"><strong class="source-inline">employeedf.employeeID, "outer")</strong></span></li>
				<li class="Alphabets"><strong class="source-inline">salarydf.join(employeedf, salarydf.employeeID == </strong><span class="No-Break"><strong class="source-inline">employeedf.salaryEmployeeID, "outer")</strong></span></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 27</strong></span><span class="No-Break">:</span></p>
			<p>Which of the following pieces of code would print the schema of the <span class="No-Break"><strong class="source-inline">df</strong></span><span class="No-Break"> DataFrame?</span></p>
			<ol class="margin-left">
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.rdd.printSchema</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.rdd.printSchema()</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.printSchema</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.printSchema()</strong></span></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 28</strong></span><span class="No-Break">:</span></p>
			<p>Which of the following code blocks performs a left join between the <strong class="source-inline">salarydf</strong> DataFrame and the <strong class="source-inline">employeedf</strong> DataFrame, using the <span class="No-Break"><strong class="source-inline">employeeID</strong></span><span class="No-Break"> column?</span></p>
			<ol class="margin-left">
				<li class="Alphabets"><strong class="source-inline">salaryDf.join(employeeDf, salaryDf["employeeID"] == </strong><span class="No-Break"><strong class="source-inline">employeeDf["employeeID"], "outer")</strong></span></li>
				<li class="Alphabets"><strong class="source-inline">salaryDf.join(employeeDf, salaryDf["employeeID"] == </strong><span class="No-Break"><strong class="source-inline">employeeDf["employeeID"], "left")</strong></span></li>
				<li class="Alphabets"><strong class="source-inline">salaryDf.join(employeeDf, salaryDf["employeeID"] == </strong><span class="No-Break"><strong class="source-inline">employeeDf["employeeID"], "inner")</strong></span></li>
				<li class="Alphabets"><strong class="source-inline">salaryDf.join(employeeDf, salaryDf["employeeID"] == </strong><span class="No-Break"><strong class="source-inline">employeeDf["employeeID"], "right")</strong></span></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 29</strong></span><span class="No-Break">:</span></p>
			<p>Which of the following code blocks aggregates the <strong class="source-inline">bonus</strong> column of the <strong class="source-inline">df</strong> DataFrame in ascending order with <strong class="source-inline">nulls</strong> <span class="No-Break">being last?</span></p>
			<ol class="margin-left">
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.agg(asc_nulls_last("bonus").alias("bonus_agg"))</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.agg(asc_nulls_first("bonus").alias("bonus_agg"))</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.agg(asc_nulls_last("bonus", asc).alias("bonus_agg"))</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.agg(asc_nulls_first("bonus", asc).alias("bonus_agg"))</strong></span></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 30</strong></span><span class="No-Break">:</span></p>
			<p>The following code block contains an error. The code block should return a DataFrame by joining the <strong class="source-inline">employeeDf</strong> and <strong class="source-inline">salaryDf</strong> DataFrames on the <strong class="source-inline">employeeID</strong> and <strong class="source-inline">employeeSalaryID</strong> columns, respectively, excluding the <strong class="source-inline">bonus</strong> and <strong class="source-inline">department</strong> columns from the <strong class="source-inline">employeeDf</strong> DataFrame and the <strong class="source-inline">salary</strong> column from the <strong class="source-inline">salaryDf</strong> DataFrame in the <span class="No-Break">final DataFrame.</span></p>
			<pre class="source-code">
employeeDf.groupBy(salaryDf, employeeDf.employeeID == salaryDf.employeeSalaryID, "inner").delete("bonus", "department", "salary")</pre>			<p>Identify <span class="No-Break">the error:</span></p>
			<ol class="margin-left">
				<li class="Alphabets"><strong class="source-inline">groupBy</strong> should be replaced with the <span class="No-Break"><strong class="source-inline">innerJoin</strong></span><span class="No-Break"> operator</span></li>
				<li class="Alphabets"><strong class="source-inline">groupBy</strong> should be replaced with a <strong class="source-inline">join</strong> operator and <strong class="source-inline">delete</strong> should be replaced <span class="No-Break">with </span><span class="No-Break"><strong class="source-inline">drop</strong></span></li>
				<li class="Alphabets"><strong class="source-inline">groupBy</strong> should be replaced with the <strong class="source-inline">crossJoin</strong> operator and <strong class="source-inline">delete</strong> should be replaced <span class="No-Break">with </span><span class="No-Break"><strong class="source-inline">withColumn</strong></span></li>
				<li class="Alphabets"><strong class="source-inline">groupBy</strong> should be replaced with a <strong class="source-inline">join</strong> operator and <strong class="source-inline">delete</strong> should be replaced <span class="No-Break">with </span><span class="No-Break"><strong class="source-inline">withColumnRenamed</strong></span></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 31</strong></span><span class="No-Break">:</span></p>
			<p>Which of the following code blocks reads a <strong class="source-inline">/loc/example.csv</strong> CSV file as a <span class="No-Break"><strong class="source-inline">df</strong></span><span class="No-Break"> DataFrame?</span></p>
			<ol class="margin-left">
				<li class="Alphabets"><strong class="source-inline">df = </strong><span class="No-Break"><strong class="source-inline">spark.read.csv("/loc/example.csv")</strong></span></li>
				<li class="Alphabets"><strong class="source-inline">df = </strong><span class="No-Break"><strong class="source-inline">spark.mode("csv").read("/loc/example.csv")</strong></span></li>
				<li class="Alphabets"><strong class="source-inline">df = </strong><span class="No-Break"><strong class="source-inline">spark.read.path("/loc/example.csv")</strong></span></li>
				<li class="Alphabets"><strong class="source-inline">df = </strong><span class="No-Break"><strong class="source-inline">spark.read().csv("/loc/example.csv")</strong></span></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 32</strong></span><span class="No-Break">:</span></p>
			<p>Which of the following code blocks reads a parquet file at the <strong class="source-inline">my_path</strong> location using a schema file <span class="No-Break">named </span><span class="No-Break"><strong class="source-inline">my_schema</strong></span><span class="No-Break">?</span></p>
			<ol class="margin-left">
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">spark.read.schema(my_schema).format("parquet").load(my_path)</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">spark.read.schema("my_schema").format("parquet").load(my_path)</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">spark.read.schema(my_schema).parquet(my_path)</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">spark.read.parquet(my_path).schema(my_schema)</strong></span></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 33</strong></span><span class="No-Break">:</span></p>
			<p>We want to find the number of records in the resulting DataFrame when we join the <strong class="source-inline">employeedf</strong> and <strong class="source-inline">salarydf</strong> DataFrames on the <strong class="source-inline">employeeID</strong> and <strong class="source-inline">employeeSalaryID</strong> columns respectively. Which code blocks should be executed to <span class="No-Break">achieve this?</span></p>
			<ol>
				<li><strong class="source-inline">.</strong><span class="No-Break"><strong class="source-inline">filter(~isnull(col(department)))</strong></span></li>
				<li><strong class="source-inline">.</strong><span class="No-Break"><strong class="source-inline">count()</strong></span></li>
				<li><span class="No-Break"><strong class="source-inline">employeedf.join(salarydf, col("employeedf.employeeID")==col("salarydf.employeeSalaryID"))</strong></span></li>
				<li><strong class="source-inline">employeedf.join(salarydf, employeedf. employeeID ==salarydf. </strong><span class="No-Break"><strong class="source-inline">employeeSalaryID, how='inner')</strong></span></li>
				<li><strong class="source-inline">.</strong><span class="No-Break"><strong class="source-inline">filter(col(department).isnotnull())</strong></span></li>
				<li><strong class="source-inline">.</strong><span class="No-Break"><strong class="source-inline">sum(col(department))</strong></span><ol><li class="Alphabets">3, <span class="No-Break">1, 6</span></li><li class="Alphabets">3, <span class="No-Break">1, 2</span></li><li class="Alphabets"><span class="No-Break">4, 2</span></li><li class="Alphabets">3, <span class="No-Break">5, 2</span></li></ol></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 34</strong></span><span class="No-Break">:</span></p>
			<p>Which of the following code blocks returns a copy of the <strong class="source-inline">df</strong> DataFrame where the name of the <strong class="source-inline">state</strong> column has been changed <span class="No-Break">to </span><span class="No-Break"><strong class="source-inline">stateID</strong></span><span class="No-Break">?</span></p>
			<ol class="margin-left">
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.withColumnRenamed("state", "stateID")</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.withColumnRenamed("stateID", "state")</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.withColumn("state", "stateID")</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.withColumn("stateID", "state")</strong></span></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 35</strong></span><span class="No-Break">:</span></p>
			<p>Which of the following code blocks returns a copy of the <strong class="source-inline">df</strong> DataFrame where the <strong class="source-inline">salary</strong> column has been converted <span class="No-Break">to </span><span class="No-Break"><strong class="source-inline">integer</strong></span><span class="No-Break">?</span></p>
			<ol class="margin-left">
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.col("salary").cast("integer"))</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.withColumn("salary", col("salary").castType("integer"))</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.withColumn("salary", col("salary").convert("integerType()"))</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.withColumn("salary", col("salary").cast("integer"))</strong></span></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 36</strong></span><span class="No-Break">:</span></p>
			<p>Which of the following code blocks splits a <strong class="source-inline">df</strong> DataFrame in half with the exact same values even when the code is run <span class="No-Break">multiple times?</span></p>
			<ol class="margin-left">
				<li class="Alphabets"><strong class="source-inline">df.randomSplit([0.5, </strong><span class="No-Break"><strong class="source-inline">0.5], seed=123)</strong></span></li>
				<li class="Alphabets"><strong class="source-inline">df.split([0.5, </strong><span class="No-Break"><strong class="source-inline">0.5], seed=123)</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.split([0.5, 0.5])</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.randomSplit([0.5, 0.5])</strong></span></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 37</strong></span><span class="No-Break">:</span></p>
			<p>Which of the following code blocks sorts the <strong class="source-inline">df</strong> DataFrame by two columns, <strong class="source-inline">salary</strong> and <strong class="source-inline">department</strong>, where <strong class="source-inline">salary</strong> is in ascending order and <strong class="source-inline">department</strong> is in <span class="No-Break">descending order?</span></p>
			<ol class="margin-left">
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.sort("salary", asc("department"))</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.sort("salary", desc(department))</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.sort(col(salary)).desc(col(department))</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.sort("salary", desc("department"))</strong></span></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 38</strong></span><span class="No-Break">:</span></p>
			<p>Which of the following code blocks calculates the average of the <strong class="source-inline">bonus</strong> column from the <strong class="source-inline">salaryDf</strong> DataFrame and adds that in a new column <span class="No-Break">called </span><span class="No-Break"><strong class="source-inline">average_bonus</strong></span><span class="No-Break">?</span></p>
			<ol class="margin-left">
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">salaryDf.avg("bonus").alias("average_bonus"))</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">salaryDf.agg(avg("bonus").alias("average_bonus"))</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">salaryDf.agg(sum("bonus").alias("average_bonus"))</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">salaryDf.agg(average("bonus").alias("average_bonus"))</strong></span></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 39</strong></span><span class="No-Break">:</span></p>
			<p>Which of the following code blocks saves the <strong class="source-inline">df</strong> DataFrame in the <strong class="source-inline">/FileStore/file.csv</strong> location as a CSV file and throws an error if a file already exists in <span class="No-Break">the location?</span></p>
			<ol class="margin-left">
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.write.mode("error").csv("/FileStore/file.csv")</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.write.mode.error.csv("/FileStore/file.csv")</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.write.mode("exception").csv("/FileStore/file.csv")</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.write.mode("exists").csv("/FileStore/file.csv")</strong></span></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 40</strong></span><span class="No-Break">:</span></p>
			<p>Which of the following code blocks reads the <strong class="source-inline">my_csv.csv</strong> CSV file located at <strong class="source-inline">/my_path/</strong> into <span class="No-Break">a DataFrame?</span></p>
			<ol class="margin-left">
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">spark.read().mode("csv").path("/my_path/my_csv.csv")</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">spark.read.format("csv").path("/my_path/my_csv.csv")</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">spark.read("csv", "/my_path/my_csv.csv")</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">spark.read.csv("/my_path/my_csv.csv")</strong></span></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 41</strong></span><span class="No-Break">:</span></p>
			<p>Which of the following code blocks displays the top 100 rows of the <strong class="source-inline">df</strong> DataFrame, where the <strong class="source-inline">salary</strong> column is present, in <span class="No-Break">descending order?</span></p>
			<ol class="margin-left">
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.sort(asc(value)).show(100)</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.sort(col("value")).show(100)</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.sort(col("value").desc()).show(100)</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.sort(col("value").asc()).print(100)</strong></span></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 42</strong></span><span class="No-Break">:</span></p>
			<p>Which of the following code blocks creates a DataFrame that shows the mean of the <strong class="source-inline">salary</strong> column of the <strong class="source-inline">salaryDf</strong> DataFrame based on the <strong class="source-inline">department</strong> and <strong class="source-inline">state</strong> columns, where <strong class="source-inline">age</strong> is greater than <strong class="source-inline">35</strong> and the returned DataFrame should be sorted in ascending order by the <strong class="source-inline">employeeID</strong> column such that there are no nulls in <span class="No-Break">that column?</span></p>
			<ol>
				<li><strong class="source-inline">salaryDf.filter(col("age") &gt; </strong><span class="No-Break"><strong class="source-inline">35)</strong></span></li>
				<li><strong class="source-inline">.</strong><span class="No-Break"><strong class="source-inline">filter(col("employeeID")</strong></span></li>
				<li><strong class="source-inline">.</strong><span class="No-Break"><strong class="source-inline">filter(col("employeeID").isNotNull())</strong></span></li>
				<li><strong class="source-inline">.</strong><span class="No-Break"><strong class="source-inline">groupBy("department")</strong></span></li>
				<li><strong class="source-inline">.</strong><span class="No-Break"><strong class="source-inline">groupBy("department", "state")</strong></span></li>
				<li><strong class="source-inline">.</strong><span class="No-Break"><strong class="source-inline">agg(avg("salary").alias("mean_salary"))</strong></span></li>
				<li><strong class="source-inline">.</strong><span class="No-Break"><strong class="source-inline">agg(average("salary").alias("mean_salary"))</strong></span></li>
				<li><strong class="source-inline">.</strong><span class="No-Break"><strong class="source-inline">orderBy("employeeID")</strong></span><ol><li class="Alphabets">1, 2, 5, <span class="No-Break">6, 8</span></li><li class="Alphabets">1, 3, 5, <span class="No-Break">6, 8</span></li><li class="Alphabets">1, 3, 6, <span class="No-Break">7, 8</span></li><li class="Alphabets">1, 2, 4, <span class="No-Break">6, 8</span></li></ol></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 43</strong></span><span class="No-Break">:</span></p>
			<p>The following code block contains an error. The code block should return a new DataFrame without the <strong class="source-inline">employee</strong> and <strong class="source-inline">salary</strong> columns and with an additional <strong class="source-inline">fixed_value</strong> column, which has a value <span class="No-Break">of </span><span class="No-Break"><strong class="source-inline">100</strong></span><span class="No-Break">.</span></p>
			<pre class="source-code">
df.withColumnRenamed(fixed_value).drop('employee', 'salary')</pre>			<p>Identify <span class="No-Break">the error:</span></p>
			<ol class="margin-left">
				<li class="Alphabets"><strong class="source-inline">withcolumnRenamed</strong> should be replaced with <strong class="source-inline">withcolumn</strong> and the <strong class="source-inline">lit()</strong> function should be used to fill the <span class="No-Break"><strong class="source-inline">100</strong></span><span class="No-Break"> value</span></li>
				<li class="Alphabets"><strong class="source-inline">withcolumnRenamed</strong> should be replaced <span class="No-Break">with </span><span class="No-Break"><strong class="source-inline">withcolumn</strong></span></li>
				<li class="Alphabets"><strong class="source-inline">employee</strong> and <strong class="source-inline">salary</strong> should be swapped in a <span class="No-Break"><strong class="source-inline">drop</strong></span><span class="No-Break"> function</span></li>
				<li class="Alphabets">The <strong class="source-inline">lit()</strong> function call <span class="No-Break">is missing</span></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 44</strong></span><span class="No-Break">:</span></p>
			<p>Which of the following code blocks returns the basic statistics for numeric and string columns of the <span class="No-Break"><strong class="source-inline">df</strong></span><span class="No-Break"> DataFrame?</span></p>
			<ol class="margin-left">
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.describe()</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.detail()</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.head()</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.explain()</strong></span></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 45</strong></span><span class="No-Break">:</span></p>
			<p>Which of the following code blocks returns the top 5 rows of the <span class="No-Break"><strong class="source-inline">df</strong></span><span class="No-Break"> DataFrame?</span></p>
			<ol class="margin-left">
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.select(5)</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.head(5)</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.top(5)</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.show()</strong></span></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 46</strong></span><span class="No-Break">:</span></p>
			<p>Which of the following code blocks creates a new DataFrame with the <strong class="source-inline">department</strong>, <strong class="source-inline">age</strong>, and <strong class="source-inline">salary</strong> columns from the <span class="No-Break"><strong class="source-inline">df</strong></span><span class="No-Break"> DataFrame?</span></p>
			<ol class="margin-left">
				<li class="Alphabets"><strong class="source-inline">df.select("department", "</strong><span class="No-Break"><strong class="source-inline">age", "salary")</strong></span></li>
				<li class="Alphabets"><strong class="source-inline">df.drop("department", "</strong><span class="No-Break"><strong class="source-inline">age", "salary")</strong></span></li>
				<li class="Alphabets"><strong class="source-inline">df.filter("department", "</strong><span class="No-Break"><strong class="source-inline">age", "salary")</strong></span></li>
				<li class="Alphabets"><strong class="source-inline">df.where("department", "</strong><span class="No-Break"><strong class="source-inline">age", "salary")</strong></span></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 47</strong></span><span class="No-Break">:</span></p>
			<p>Which of the following code blocks creates a new DataFrame with three columns, <strong class="source-inline">department</strong>, <strong class="source-inline">age</strong>, and <strong class="source-inline">max_salary</strong>, which has the maximum salary for each employee from each department and each age group from the <span class="No-Break"><strong class="source-inline">df</strong></span><span class="No-Break"> DataFrame?</span></p>
			<pre class="source-code">
df.___1___ (["department", "age"]).___2___ (___3___ ("salary").alias("max_salary"))</pre>			<p>Identify the <span class="No-Break">correct answer:</span></p>
			<ol class="margin-left">
				<li class="Alphabets"><ol><li class="lower-roman"><span class="No-Break"><strong class="source-inline">filter</strong></span></li><li class="lower-roman"><span class="No-Break"><strong class="source-inline">agg</strong></span></li><li class="lower-roman"><span class="No-Break"><strong class="source-inline">max</strong></span></li></ol></li>
				<li class="Alphabets"><ol><li class="lower-roman"><span class="No-Break">groupBy</span></li><li class="lower-roman"><span class="No-Break">agg</span></li><li class="lower-roman"><span class="No-Break">max</span></li></ol></li>
				<li class="Alphabets"><ol><li class="lower-roman"><span class="No-Break">filter</span></li><li class="lower-roman"><span class="No-Break">agg</span></li><li class="lower-roman"><span class="No-Break">sum</span></li></ol></li>
				<li class="Alphabets"><ol><li class="lower-roman"><span class="No-Break">groupBy</span></li><li class="lower-roman"><span class="No-Break">agg</span></li><li class="lower-roman"><span class="No-Break">sum</span></li></ol></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 48</strong></span><span class="No-Break">:</span></p>
			<p>The following code block contains an error. The code block should return a new DataFrame, filtered by the rows, where the <strong class="source-inline">salary</strong> column is greater than or equal to <strong class="source-inline">1000</strong> in the <span class="No-Break"><strong class="source-inline">df</strong></span><span class="No-Break"> DataFrame.</span></p>
			<pre class="source-code">
df.filter(F(salary) &gt;= 1000)</pre>			<p>Identify <span class="No-Break">the error:</span></p>
			<ol class="margin-left">
				<li class="Alphabets">Instead of <strong class="source-inline">filter()</strong>, <strong class="source-inline">where()</strong> should <span class="No-Break">be used</span></li>
				<li class="Alphabets">The <strong class="source-inline">F(salary)</strong> operation should be replaced <span class="No-Break">with </span><span class="No-Break"><strong class="source-inline">F.col("salary")</strong></span></li>
				<li class="Alphabets">Instead of <strong class="source-inline">&gt;=</strong>, the <strong class="source-inline">&gt;</strong> operator should <span class="No-Break">be used</span></li>
				<li class="Alphabets">The argument to the <strong class="source-inline">where</strong> method should be <strong class="source-inline">"salary &gt; </strong><span class="No-Break"><strong class="source-inline">1000"</strong></span></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 49</strong></span><span class="No-Break">:</span></p>
			<p>Which of the following code blocks returns a copy of the <strong class="source-inline">df</strong> DataFrame where the <strong class="source-inline">department</strong> column has been <span class="No-Break">renamed </span><span class="No-Break"><strong class="source-inline">business_unit</strong></span><span class="No-Break">?</span></p>
			<ol class="margin-left">
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.withColumn(["department", "business_unit"])</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">itemsDf.withColumn("department").alias("business_unit")</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">itemsDf.withColumnRenamed("department", "business_unit")</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">itemsDf.withColumnRenamed("business_unit", "department")</strong></span></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 50</strong></span><span class="No-Break">:</span></p>
			<p>Which of the following code blocks returns a DataFrame with the total count of employees in each department from the <span class="No-Break"><strong class="source-inline">df</strong></span><span class="No-Break"> DataFrame?</span></p>
			<ol class="margin-left">
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.groupBy("department").agg(count("*").alias("total_employees"))</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.filter("department").agg(count("*").alias("total_employees"))</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.groupBy("department").agg(sum("*").alias("total_employees"))</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.filter("department").agg(sum("*").alias("total_employees"))</strong></span></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 51</strong></span><span class="No-Break">:</span></p>
			<p>Which of the following code blocks returns a DataFrame with the <strong class="source-inline">employee</strong> column from the <strong class="source-inline">df</strong> DataFrame case to the <span class="No-Break"><strong class="source-inline">string</strong></span><span class="No-Break"> type?</span></p>
			<ol class="margin-left">
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.withColumn("employee", col("employee").cast_type("string"))</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.withColumn("employee", col("employee").cast("string"))</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.withColumn("employee", col("employee").cast_type("stringType()"))</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.withColumnRenamed("employee", col("employee").cast("string"))</strong></span></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 52</strong></span><span class="No-Break">:</span></p>
			<p>Which of the following code blocks returns a DataFrame with a new <strong class="source-inline">fixed_value</strong> column, which has <strong class="source-inline">Z</strong> in all rows in the <span class="No-Break">df DataFrame?</span></p>
			<ol class="margin-left">
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.withColumn("fixed_value", F.lit("Z"))</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.withColumn("fixed_value", F("Z"))</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.withColumnRenamed("fixed_value", F.lit("Z"))</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.withColumnRenamed("fixed_value", lit("Z"))</strong></span></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 53</strong></span><span class="No-Break">:</span></p>
			<p>Which of the following code blocks returns a new DataFrame with a new <strong class="source-inline">upper_string</strong> column, which is the capitalized version of the <strong class="source-inline">employeeName</strong> column in the <span class="No-Break"><strong class="source-inline">df</strong></span><span class="No-Break"> DataFrame?</span></p>
			<ol class="margin-left">
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.withColumnRenamed('employeeName', upper(df.upper_string))</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.withColumnRenamed('upper_string', upper(df.employeeName))</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.withColumn('upper_string', upper(df.employeeName))</strong></span></li>
				<li class="Alphabets"><strong class="source-inline">df.withColumn(' </strong><span class="No-Break"><strong class="source-inline">employeeName', upper(df.upper_string))</strong></span></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 54</strong></span><span class="No-Break">:</span></p>
			<p>The following code block contains an error. The code block is supposed to capitalize the employee names using <span class="No-Break">a udf:</span></p>
			<pre class="source-code">
capitalize_udf = udf(lambda x: x.upper(), StringType())
df_with_capitalized_names = df.withColumn("capitalized_name", capitalize("employee"))</pre>			<p>Identify <span class="No-Break">the error:</span></p>
			<ol class="margin-left">
				<li class="Alphabets">The <strong class="source-inline">capitalize_udf</strong> function should be called instead <span class="No-Break">of </span><span class="No-Break"><strong class="source-inline">capitalize</strong></span></li>
				<li class="Alphabets">The <strong class="source-inline">udf</strong> function, <strong class="source-inline">capitalize_udf</strong>, is not <span class="No-Break">capitalizing correctly</span></li>
				<li class="Alphabets">Instead of <strong class="source-inline">StringType()</strong>, <strong class="source-inline">IntegerType()</strong> should <span class="No-Break">be used</span></li>
				<li class="Alphabets">Instead of <strong class="source-inline">df.withColumn("capitalized_name", capitalize("employee"))</strong>, it should use <span class="No-Break"><strong class="source-inline">df.withColumn("employee", capitalize("capitalized_name"))</strong></span></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 55</strong></span><span class="No-Break">:</span></p>
			<p>The following code block contains an error. The code block is supposed to sort the <strong class="source-inline">df</strong> DataFrame by salary in ascending order. Then, it should sort based on the <strong class="source-inline">bonus</strong> column, putting <span class="No-Break"><strong class="source-inline">nulls</strong></span><span class="No-Break"> last.</span></p>
			<pre class="source-code">
df.orderBy ('salary', asc_nulls_first(col('bonus')))</pre>			<p>Identify <span class="No-Break">the error:</span></p>
			<ol class="margin-left">
				<li class="Alphabets">The <strong class="source-inline">salary</strong> column should be sorted in descending order and <strong class="source-inline">desc_nulls_last</strong> should be used instead of <strong class="source-inline">asc_nulls_first</strong>. Moreover, it should be wrapped in a <span class="No-Break"><strong class="source-inline">col()</strong></span><span class="No-Break"> operator.</span></li>
				<li class="Alphabets">The <strong class="source-inline">salary</strong> column should be wrapped by the <span class="No-Break"><strong class="source-inline">col()</strong></span><span class="No-Break"> operator.</span></li>
				<li class="Alphabets">The <strong class="source-inline">bonus</strong> column should be sorted in a descending way, putting <span class="No-Break">nulls last.</span></li>
				<li class="Alphabets">The <strong class="source-inline">bonus</strong> column should be sorted by <span class="No-Break"><strong class="source-inline">desc_nulls_first()</strong></span><span class="No-Break"> instead.</span></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 56</strong></span><span class="No-Break">:</span></p>
			<p>The following code block contains an error. The code block needs to group the <strong class="source-inline">df</strong> DataFrame based on the <strong class="source-inline">department</strong> column and calculate the total salary and average salary for <span class="No-Break">each department.</span></p>
			<pre class="source-code">
df.filter("department").agg(sum("salary").alias("sum_salary"), avg("salary").alias("avg_salary"))</pre>			<p>Identify <span class="No-Break">the error:</span></p>
			<ol class="margin-left">
				<li class="Alphabets">The <strong class="source-inline">avg</strong> method should also be called through the <span class="No-Break"><strong class="source-inline">agg</strong></span><span class="No-Break"> function</span></li>
				<li class="Alphabets">Instead of <strong class="source-inline">filter</strong>, <strong class="source-inline">groupBy</strong> should <span class="No-Break">be used</span></li>
				<li class="Alphabets">The <strong class="source-inline">agg</strong> method syntax <span class="No-Break">is incorrect</span></li>
				<li class="Alphabets">Instead of filtering on <strong class="source-inline">department</strong>, the code should filter <span class="No-Break">on </span><span class="No-Break"><strong class="source-inline">salary</strong></span></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 57</strong></span><span class="No-Break">:</span></p>
			<p>Which code block will write the <strong class="source-inline">df</strong> DataFrame as a parquet file on the <strong class="source-inline">filePath</strong> path partitioning it on the <span class="No-Break"><strong class="source-inline">department</strong></span><span class="No-Break"> column?</span></p>
			<ol class="margin-left">
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.write.partitionBy("department").parquet(filePath)</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.write.partition("department").parquet(filePath)</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.write.parquet("department").partition(filePath)</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.write.coalesce("department").parquet(filePath)</strong></span></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 58</strong></span><span class="No-Break">:</span></p>
			<p>The <strong class="source-inline">df</strong> DataFrame contains columns <strong class="source-inline">[employeeID, salary, department]</strong>. Which of the following pieces of code would return the <strong class="source-inline">df</strong> DataFrame with only columns <strong class="source-inline">[</strong><span class="No-Break"><strong class="source-inline">employeeID, salary]</strong></span><span class="No-Break">?</span></p>
			<ol class="margin-left">
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.drop("department")</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.select(col(employeeID))</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.drop("department", "salary")</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.select("employeeID", "department")</strong></span></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 59</strong></span><span class="No-Break">:</span></p>
			<p>Which of the following code blocks returns a new DataFrame with the same columns as the <strong class="source-inline">df</strong> DataFrame, except for the <span class="No-Break"><strong class="source-inline">salary</strong></span><span class="No-Break"> column?</span></p>
			<ol class="margin-left">
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.drop(col("salary"))</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.delete(salary)</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.drop(salary)</strong></span></li>
				<li class="Alphabets"><span class="No-Break"><strong class="source-inline">df.delete("salary")</strong></span></li>
			</ol>
			<p><span class="No-Break"><strong class="bold">Question 60</strong></span><span class="No-Break">:</span></p>
			<p>The following code block contains an error. The code block should return the <strong class="source-inline">df</strong> DataFrame with <strong class="source-inline">employeeID</strong> renamed <span class="No-Break">as </span><span class="No-Break"><strong class="source-inline">employeeIdColumn</strong></span><span class="No-Break">.</span></p>
			<pre class="source-code">
df.withColumnRenamed("employeeIdColumn", "employeeID")</pre>			<p>Identify <span class="No-Break">the error:</span></p>
			<ol class="margin-left">
				<li class="Alphabets">Instead of <strong class="source-inline">withColumnRenamed</strong>, the <strong class="source-inline">withColumn</strong> method should <span class="No-Break">be used</span></li>
				<li class="Alphabets">Instead of <strong class="source-inline">withColumnRenamed</strong>, the <strong class="source-inline">withColumn</strong> method should be used and the <strong class="source-inline">"employeeIdColumn"</strong> argument should be swapped with the <strong class="source-inline">"</strong><span class="No-Break"><strong class="source-inline">employeeID"</strong></span><span class="No-Break"> argument</span></li>
				<li class="Alphabets">The <strong class="source-inline">"employeeIdColumn"</strong> and <strong class="source-inline">"employeeID"</strong> arguments should <span class="No-Break">be swapped</span></li>
				<li class="Alphabets"><strong class="source-inline">withColumnRenamed</strong> is not a method <span class="No-Break">for DataFrames</span></li>
			</ol>
			<h2 id="_idParaDest-248"><a id="_idTextAnchor249"/>Answers</h2>
			<ol>
				<li>D</li>
				<li>C</li>
				<li>A</li>
				<li>A</li>
				<li>A</li>
				<li>A</li>
				<li>B</li>
				<li>D</li>
				<li>C</li>
				<li>B</li>
				<li>C</li>
				<li>C</li>
				<li>A</li>
				<li>B</li>
				<li>A</li>
				<li>A</li>
				<li>A</li>
				<li>B</li>
				<li>B</li>
				<li>E</li>
				<li>C</li>
				<li>A</li>
				<li>A</li>
				<li>C</li>
				<li>C</li>
				<li>D</li>
				<li>D</li>
				<li>B</li>
				<li>A</li>
				<li>B</li>
				<li>A</li>
				<li>A</li>
				<li>C</li>
				<li>A</li>
				<li>D</li>
				<li>A</li>
				<li>D</li>
				<li>B</li>
				<li>A</li>
				<li>D</li>
				<li>C</li>
				<li>B</li>
				<li>A</li>
				<li>A</li>
				<li>B</li>
				<li>A</li>
				<li>B</li>
				<li>B</li>
				<li>C</li>
				<li>A</li>
				<li>B</li>
				<li>A</li>
				<li>C</li>
				<li>A</li>
				<li>A</li>
				<li>B</li>
				<li>A</li>
				<li>A</li>
				<li>A</li>
				<li>C</li>
			</ol>
		</div>
	</body></html>