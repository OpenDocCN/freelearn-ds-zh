- en: '*Chapter 4*'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第四章*'
- en: A Deep Dive into Data Wrangling with Python
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深入学习使用 Python 进行数据整理
- en: Learning Objectives
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 学习目标
- en: 'By the end of this chapter, you will be able to:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将能够：
- en: Perform subsetting, filtering, and grouping on pandas DataFrames
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 pandas DataFrame 上执行子集、过滤和分组操作
- en: Apply Boolean filtering and indexing from a DataFrame to choose specific elements
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从 DataFrame 应用布尔过滤和索引以选择特定元素
- en: Perform JOIN operations in pandas that are analogous to the SQL command
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 pandas 中执行与 SQL 命令类似的 JOIN 操作
- en: Identify missing or corrupted data and choose to drop or apply imputation techniques
    on missing or corrupted data
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别缺失或损坏的数据，并选择删除或应用插补技术处理缺失或损坏的数据
- en: In this chapter, we will learn about pandas DataFrames in detail.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将详细了解 pandas DataFrame。
- en: Introduction
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 简介
- en: In this chapter, we will learn about several advanced operations involving pandas
    DataFrames and NumPy arrays. On completing the detailed activity for this chapter,
    you will have handled real-life datasets and understood the process of data wrangling.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习涉及 pandas DataFrame 和 NumPy 数组的几个高级操作。完成本章的详细活动后，你将处理真实数据集并理解数据整理的过程。
- en: Subsetting, Filtering, and Grouping
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 子集、过滤和分组
- en: One of the most important aspects of data wrangling is to curate the data carefully
    from the deluge of streaming data that pours into an organization or business
    entity from various sources. Lots of data is not always a good thing; rather,
    data needs to be useful and of high-quality to be effectively used in downstream
    activities of a data science pipeline such as machine learning and predictive
    model building. Moreover, one data source can be used for multiple purposes and
    this often requires different subsets of data to be processed by a data wrangling
    module. This is then passed on to separate analytics modules.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 数据整理最重要的方面之一是从各种来源涌入组织或商业实体的数据洪流中精心整理数据。大量的数据并不总是好事；相反，数据需要是有用且高质量的，才能在数据科学管道的下游活动中有效使用，例如机器学习和预测模型构建。此外，一个数据源可以用于多个目的，这通常需要数据整理模块处理不同的数据子集。然后这些数据被传递到单独的分析模块。
- en: For example, let's say you are doing data wrangling on US State level economic
    output. It is a fairly common scenario that one machine learning model may require
    data for large and populous states (such as California, Texas, and so on), while
    another model demands processed data for small and sparsely populated states (such
    as Montana or North Dakota). As the frontline of the data science process, it
    is the responsibility of the data wrangling module to satisfy the requirements
    of both these machine learning models. Therefore, as a data wrangling engineer,
    you have to filter and group data accordingly (based on the population of the
    state) before processing them and producing separate datasets as the final output
    for separate machine learning models.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设你正在对美国州级经济产出进行数据整理。这是一个相当常见的场景，一个机器学习模型可能需要大型和人口众多的州（如加利福尼亚州、德克萨斯州等）的数据，而另一个模型则要求为小型和人口稀少的州（如蒙大拿州或北达科他州）处理的数据。作为数据科学流程的前线，数据整理模块有责任满足这两个机器学习模型的要求。因此，作为一名数据整理工程师，你必须在处理并生成最终输出之前，根据州的（人口）过滤和分组数据。
- en: Also, in some cases, data sources may be biased, or the measurement may corrupt
    the incoming data occasionally. It is a good idea to try to filter only the error-free,
    good data for downstream modeling. From these examples and discussions, it is
    clear that filtering and grouping/bucketing data is an essential skill to have
    for any engineer that's engaged in the task of data wrangling. Let's proceed to
    learn about a few of these skills with pandas.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，在某些情况下，数据源可能存在偏差，或者测量偶尔会损坏传入的数据。尝试仅过滤无错误、高质量的数据用于下游建模是个好主意。从这些例子和讨论中可以看出，过滤和分组/分桶数据是任何从事数据整理任务的工程师必备的技能。让我们继续学习
    pandas 中的一些这些技能。
- en: 'Exercise 48: Loading and Examining a Superstore''s Sales Data from an Excel
    File'
  id: totrans-15
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 48：从 Excel 文件中加载和检查超市的销售数据
- en: In this exercise, we will load and examine an Excel file.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将加载并检查一个 Excel 文件。
- en: 'To read an Excel file into pandas, you will need a small package called `xlrd`
    to be installed on your system. If you are working from inside this book''s Docker
    container, then this package may not be available next time you start your container,
    and you have to follow the same step. Use the following code to install the xlrd
    package:'
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要将 Excel 文件读入 pandas，你需要在你的系统上安装一个名为 `xlrd` 的小型包。如果你在这个书的 Docker 容器内部工作，那么这个包可能在你下次启动容器时不可用，你必须遵循相同的步骤。使用以下代码安装
    xlrd 包：
- en: '[PRE0]'
  id: totrans-18
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Load the Excel file from GitHub by using the simple pandas method `read_excel`:'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用简单的 pandas 方法 `read_excel` 从 GitHub 加载 Excel 文件：
- en: '[PRE1]'
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Examine all the columns and check if they are useful for analysis:'
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 检查所有列，看它们是否对分析有用：
- en: '![Figure 4.1 Output of the Excel file in a DataFrame](img/C11065_04_01.jpg)'
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 4.1 Excel 文件在 DataFrame 中的输出](img/C11065_04_01.jpg)'
- en: Figure 4.1 Output of the Excel file in a DataFrame
  id: totrans-23
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.1 Excel 文件在 DataFrame 中的输出
- en: On examining the file, we can see that the first column, called **Row ID**,
    is not very useful.
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 检查文件时，我们可以看到第一列，称为 **行 ID**，并不是很有用。
- en: 'Drop this column altogether from the DataFrame by using the `drop` method:'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `drop` 方法从 DataFrame 中完全删除此列：
- en: '[PRE2]'
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Check the number of rows and columns in the newly created dataset. We will
    use the `shape` function here:'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查新创建数据集的行数和列数。我们将在这里使用 `shape` 函数：
- en: '[PRE3]'
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The output is as follows:'
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE4]'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: We can see that the dataset has 9,994 rows and 20 columns.
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以看到数据集有 9,994 行和 20 列。
- en: Subsetting the DataFrame
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 子集 DataFrame
- en: '**Subsetting** involves the extraction of partial data based on specific columns
    and rows, as per business needs. Suppose we are interested only in the following
    information from this dataset: Customer ID, Customer Name, City, Postal Code,
    and Sales. For demonstration purposes, let''s assume that we are only interested
    in 5 records – rows 5-9\. We can subset the DataFrame to extract only this much
    information using a single line of Python code.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**子集**涉及根据特定列和行提取部分数据，以满足业务需求。假设我们只对以下信息感兴趣：客户 ID、客户姓名、城市、邮政编码和销售额。为了演示目的，让我们假设我们只对
    5 条记录感兴趣 - 第 5-9 行。我们可以使用一行 Python 代码来子集 DataFrame，只提取这么多信息。'
- en: 'Use the `loc` method to index the dataset by name of the columns and index
    of the rows:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `loc` 方法通过列名和行索引来索引数据集：
- en: '[PRE5]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The output is as follows:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.2: DataFrame indexed by name of the columns](img/C11065_04_02.jpg)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.2：按列名索引的 DataFrame](img/C11065_04_02.jpg)'
- en: 'Figure 4.2: DataFrame indexed by name of the columns'
  id: totrans-38
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.2：按列名索引的 DataFrame
- en: We need to pass on two arguments to the `loc` method – one for indicating the
    rows, and another for indicating the columns. These should be Python lists.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要传递两个参数给 `loc` 方法 - 一个用于指示行，另一个用于指示列。这些应该是 Python 列表。
- en: For the rows, we have to pass a list [5,6,7,8,9], but instead of writing that
    explicitly, we use a list comprehension, that is, `[i for i in range(5,10)]`.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 对于行，我们必须传递一个列表 [5,6,7,8,9]，但不是明确地写出，我们使用列表推导式，即 `[i for i in range(5,10)]`。
- en: Because the columns we are interested in are not contiguous, we cannot just
    put a continuous range and need to pass on a list containing the specific names.
    So, the second argument is just a simple list with specific column names.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我们所感兴趣的列不是连续的，我们不能仅仅放置一个连续的范围，需要传递一个包含特定名称的列表。所以，第二个参数只是一个包含特定列名的简单列表。
- en: The dataset shows the fundamental concepts of the process of subsetting a DataFrame
    based on business requirements.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集展示了根据业务需求对 DataFrame 进行子集的基本概念。
- en: 'An Example Use Case: Determining Statistics on Sales and Profit'
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 一个示例用例：确定销售额和利润的统计数据
- en: 'This quick section shows a typical use case of subsetting. Suppose we want
    to calculate descriptive statistics (mean, median, standard deviation, and so
    on) of records 100-199 for sales and profit. This is how subsetting helps us to
    achieve that:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这一小节展示了子集的典型用例。假设我们想要计算记录 100-199 的销售额和利润的描述性统计（均值、中位数、标准差等）。这就是子集如何帮助我们实现这一点的方式：
- en: '[PRE6]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The output is as follows:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.3 Output of descriptive statistics of data](img/C11065_04_03.jpg)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.3 数据的描述性统计输出](img/C11065_04_03.jpg)'
- en: Figure 4.3 Output of descriptive statistics of data
  id: totrans-48
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.3 数据的描述性统计输出
- en: Furthermore, we can create boxplots of sales and profit figures from this final
    data.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们可以从最终数据中创建销售额和利润数字的箱线图。
- en: 'We simply extract records 100-199 and run the `describe` function on it because
    we don''t want to process all the data! For this particular business question,
    we are only interested in sales and profit numbers and therefore we should not
    take the easy route and run a describe function on all the data. For a real-life
    dataset, the number of rows and columns could often be in the millions, and we
    don''t want to compute anything that is not asked for in the data wrangling task.
    We always aim to subset the exact data that is needed to be processed and run
    statistical or plotting functions on that partial data:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们简单地提取了100-199条记录，并对其运行`describe`函数，因为我们不想处理所有数据！对于这个特定的问题，我们只对销售额和利润数字感兴趣，因此我们不应该走捷径，对全部数据进行描述。对于现实生活中的数据集，行和列的数量可能经常达到数百万，我们不想计算数据整理任务中未要求的数据。我们总是旨在子集化需要处理的确切数据，并在该部分数据上运行统计或绘图函数：
- en: '![Figure 4.4: Boxplot of sales and profit](img/C11065_04_04.jpg)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.4：销售额和利润的箱线图](img/C11065_04_04.jpg)'
- en: 'Figure 4.4: Boxplot of sales and profit'
  id: totrans-52
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.4：销售额和利润的箱线图
- en: 'Exercise 49: The unique Function'
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 49：唯一函数
- en: Before continuing further with filtering methods, let's take a quick detour
    and explore a super useful function called `unique`. As the name suggests, this
    function is used to scan through the data quickly and extract only the unique
    values in a column or row.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续使用过滤方法之前，让我们快速偏离一下，探索一个超级有用的函数，称为`unique`。正如其名所示，此函数用于快速扫描数据并提取列或行中的唯一值。
- en: 'After loading the superstore sales data, you will notice that there are columns
    like "Country", "State", and "City". A natural question will be to ask how many
    countries/states/cities are present in the dataset:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在加载超级商店销售数据后，你会注意到有一些像“国家”、“州”和“城市”这样的列。一个自然的问题将是询问数据集中有多少个国家/州/城市：
- en: 'Extract the countries/states/cities for which the information is in the database,
    with one simple line of code, as follows:'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用一行简单的代码提取数据库中包含信息的国家/州/城市，如下所示：
- en: '[PRE7]'
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The output is as follows:'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.5: Different states present in the dataset](img/C11065_04_05.jpg)'
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 4.5：数据集中存在的不同状态](img/C11065_04_05.jpg)'
- en: 'Figure 4.5: Different states present in the dataset'
  id: totrans-60
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.5：数据集中存在的不同状态
- en: You will see a list of all the states whose data is present in the dataset.
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你将看到所有在数据集中存在的州的列表。
- en: 'Use the `nunique` method to count the number of unique values, like so:'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`nunique`方法来计数唯一值的数量，如下所示：
- en: '[PRE8]'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The output is as follows:'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE9]'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: This returns 49 for this dataset. So, one out of 50 states in the US does not
    appear in this dataset.
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这对于此数据集返回49。所以，在美国的50个州中，有一个州没有出现在这个数据集中。
- en: Similarly, if we run this function on the Country column, we get an array with
    only one element, `United States`. Immediately, we can see that we don't need
    to keep the country column at all, because there is no useful information in that
    column except that all the entries are the same. This is how a simple function
    helped us to decide about dropping a column altogether – that is, removing 9,994
    pieces of unnecessary data!
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，如果我们对国家列运行此函数，我们将得到一个只有一个元素的数组，`United States`。立即，我们可以看到我们根本不需要保留国家列，因为该列中除了所有条目都相同之外，没有有用的信息。这就是一个简单的函数如何帮助我们决定删除整个列——也就是说，删除9,994条不必要的数据！
- en: Conditional Selection and Boolean Filtering
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 条件选择和布尔过滤
- en: Often, we don't want to process the whole dataset and would like to select only
    a partial dataset whose contents satisfy a particular condition. This is probably
    the most common use case of any data wrangling task.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，我们不想处理整个数据集，而只想选择满足特定条件的部分数据集。这可能是任何数据整理任务中最常见的用例。
- en: 'In the context of our superstore sales dataset, think of these common questions
    that may arise from the daily activity of the business analytics team:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的超级商店销售数据集的背景下，考虑以下可能从业务分析团队的日常活动中出现的一些常见问题：
- en: What are the average sales and profit figures in California?
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加利福尼亚的平均销售额和利润数字是多少？
- en: Which states have the highest and lowest total sales?
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 哪些州的销售额最高和最低？
- en: What consumer segment has the most variance in sales/profit?
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 哪个消费者销售/利润的变异性最大？
- en: Among the top 5 states in sales, which shipping mode and product category are
    the most popular choices?
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在销售额最高的前5个州中，哪种运输方式和产品类别最受欢迎？
- en: Countless examples can be given where the business analytics team or the executive
    management want to glean insight from a particular subset of data that meet certain
    criteria.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 可以给出无数个例子，其中业务分析团队或高管团队希望从满足某些特定标准的数据子集中提取洞察。
- en: If you have any prior experience with SQL, you will know that these kinds of
    questions require fairly complex SQL query writing. Remember the WHERE clause?
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有任何SQL的先验经验，你会知道这类问题需要相当复杂的SQL查询编写。还记得WHERE子句吗？
- en: We will show you how to use conditional subsetting and Boolean filtering to
    answer such questions.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将向您展示如何使用条件子集和布尔过滤来回答这类问题。
- en: 'First, we need to understand the critical concept of boolean indexing. This
    process essentially accepts a conditional expression as an argument and returns
    a dataset of booleans in which the `TRUE` value appears in places where the condition
    was satisfied. A simple example is shown in the following code. For demonstration
    purposes, we subset a small dataset of 10 records and 3 columns:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要理解布尔索引的关键概念。这个过程本质上接受一个条件表达式作为参数，并返回一个布尔数据集，其中`TRUE`值出现在条件满足的地方。以下代码展示了简单示例。为了演示目的，我们对一个包含10条记录和3个列的小数据集进行了子集操作：
- en: '[PRE10]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The output is as follows:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.6: Sample dataset](img/C11065_04_06.jpg)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![图4.6：样本数据集](img/C11065_04_06.jpg)'
- en: 'Figure 4.6: Sample dataset'
  id: totrans-82
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4.6：样本数据集
- en: 'Now, if we just want to know the records with sales higher than $100, then
    we can write the following:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果我们只想知道销售额高于$100的记录，我们可以编写以下代码：
- en: '[PRE11]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'This produces the following boolean DataFrame:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 这产生了以下布尔DataFrame：
- en: '![Figure 4.7: Records with sales higher than $100](img/C11065_04_07.jpg)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![图4.7：销售额高于100美元的记录](img/C11065_04_07.jpg)'
- en: 'Figure 4.7: Records with sales higher than $100'
  id: totrans-87
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4.7：销售额高于100美元的记录
- en: Note the True and False entries in the **Sales** column. Values in the **Ship
    Mode** and **State** columns were not impacted by this code because the comparison
    was with a numerical quantity, and the only numeric column in the original DataFrame
    was **Sales**.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 注意**Sales**列中的True和False条目。**Ship Mode**和**State**列的值没有受到影响，因为比较的是数值量，而原始DataFrame中唯一的数值列是**Sales**。
- en: 'Now, let''s see what happens if we pass this boolean DataFrame as an index
    to the original DataFrame:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看如果我们将这个布尔DataFrame作为索引传递给原始DataFrame会发生什么：
- en: '[PRE12]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The output is as follows:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.8: Results after passing the boolean DataFrame as an index to original
    DataFrame](img/C11065_04_08.jpg)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![图4.8：将布尔DataFrame作为索引传递给原始DataFrame后的结果](img/C11065_04_08.jpg)'
- en: 'Figure 4.8: Results after passing the boolean DataFrame as an index to the
    original DataFrame'
  id: totrans-93
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4.8：将布尔DataFrame作为索引传递给原始DataFrame后的结果
- en: The NaN values came from the fact that the preceding code tried to create a
    DataFrame with TRUE indices (in the Boolean DataFrame) only.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: NaN值来自前面的代码尝试仅使用TRUE索引（在布尔DataFrame中）创建DataFrame的事实。
- en: The values which were TRUE in the boolen DataFrame were retained in the final
    output DataFrame.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在布尔DataFrame中为TRUE的值被保留在最终输出DataFrame中。
- en: The program inserted **NaN** values for the rows where data was not available
    (because they were discarded due to the Sales value being < $100).
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 程序在数据不可用（因为它们由于销售额小于$100而被丢弃）的行中插入了**NaN**值。
- en: 'Now, we probably don''t want to work with this resulting DataFrame with `Sales
    > $100`. We can achieve that by simply passing only the `Sales` column:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可能不想与这个结果DataFrame `Sales > $100`一起工作。我们可以通过仅传递`Sales`列来实现这一点：
- en: '[PRE13]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'This produces the expected result:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 这产生了预期的结果：
- en: '![Figure 4.9: Results after removing the NaN values](img/C11065_04_09.jpg)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![图4.9：移除NaN值后的结果](img/C11065_04_09.jpg)'
- en: 'Figure 4.9: Results after removing the NaN values'
  id: totrans-101
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4.9：移除NaN值后的结果
- en: We are not limited to conditional expressions involving numeric quantities only.
    Let's try to extract high sales values (> $100) for entries that do not involve
    Colorado.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不仅限于只涉及数字量的条件表达式。让我们尝试提取不涉及科罗拉多州的销售额较高的值（> $100）。
- en: 'We can write the following code to accomplish that:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以编写以下代码来完成这项任务：
- en: '[PRE14]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Note the use of a conditional involving string. In this expression, we are joining
    two conditionals by an & operator. Both conditions must be wrapped inside parentheses.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 注意字符串条件的使用。在这个表达式中，我们通过&运算符连接了两个条件。两个条件都必须用括号括起来。
- en: 'The first conditional expression simply matches the entries in the `State`
    column to the string `Colorado` and assigns TRUE/FALSE accordingly. The second
    conditional is the same as before. Together, joined by the & operator, they extract
    only those rows for which `State` is not `Colorado` and `Sales` is `> $100`. We
    get the following result:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个条件表达式简单地匹配 `State` 列中的条目与字符串 `Colorado`，并相应地分配 TRUE/FALSE。第二个条件与之前相同。通过 &
    运算符连接在一起，它们仅提取 `State` 不是 `Colorado` 且 `Sales` 大于 $100 的行。我们得到以下结果：
- en: '![](img/C11065_04_10.jpg)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/C11065_04_10.jpg)'
- en: 'Figure 4.10: Results where State is not California and Sales is higher than
    $100'
  id: totrans-108
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.10：`State` 不是加利福尼亚州且 `Sales` 大于 $100 的结果
- en: '**Note**'
  id: totrans-109
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**注意**'
- en: Although, in theory, there is no limit on how complex a conditional you can
    build using individual expressions and & (LOGICAL AND) and | (LOGICAL OR) operators,
    it is advisable to create intermediate boolean DataFrames with limited conditional
    expressions and build your final DataFrame step by step. This keeps the code legible
    and scalable.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然理论上，你可以使用单个表达式和 &（逻辑与）和 |（逻辑或）运算符构建复杂的条件，但建议创建具有有限条件表达式的中间布尔 DataFrame，并逐步构建最终的
    DataFrame。这使代码易于阅读和扩展。
- en: 'Exercise 50: Setting and Resetting the Index'
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 50：设置和重置索引
- en: 'Sometimes, we may need to reset or eliminate the default index of a DataFrame
    and assign a new column as an index:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，我们可能需要重置或消除 DataFrame 的默认索引并分配新列作为索引：
- en: 'Create the `matrix_data`, `row_labels`, and `column_headings` functions using
    the following command:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令创建 `matrix_data`、`row_labels` 和 `column_headings` 函数：
- en: '[PRE15]'
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Create a DataFrame using the `matrix_data`, `row_labels`, and `column_headings`
    functions:'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `matrix_data`、`row_labels` 和 `column_headings` 函数创建一个 DataFrame：
- en: '[PRE16]'
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The output is as follows:'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![](img/C11065_04_11.jpg)'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图片](img/C11065_04_11.jpg)'
- en: 'Figure 4.11: The original DataFrame'
  id: totrans-119
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.11：原始 DataFrame
- en: 'Reset the index, as follows:'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如此重置索引：
- en: '[PRE17]'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '![](img/C11065_04_12.jpg)'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图片](img/C11065_04_12.jpg)'
- en: 'Figure 4.12: DataFrame after resetting the index'
  id: totrans-123
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.12：重置索引后的 DataFrame
- en: 'Reset the index with `drop` set to `True`, as follows:'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 `drop` 设置为 `True` 来重置索引，如下所示：
- en: '[PRE18]'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '![Figure 4.13: DataFrame after resetting the index with the drop option set
    to true](img/C11065_04_13.jpg)'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 4.13：设置 drop 选项为 true 后重置索引的 DataFrame](img/C11065_04_13.jpg)'
- en: 'Figure 4.13: DataFrame after resetting the index with the drop option set to
    true'
  id: totrans-127
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.13：设置 drop 选项为 true 后重置索引的 DataFrame
- en: 'Add a new column using the following command:'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令添加新列：
- en: '[PRE19]'
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The output is as follows:'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![](img/C11065_04_14.jpg)'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图片](img/C11065_04_14.jpg)'
- en: 'Figure 4.14: DataFrame after adding a new column called Profession'
  id: totrans-132
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.14：添加名为 `Profession` 的新列后的 DataFrame
- en: 'Now, set the `Profession` column as an `index` using the following code:'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用以下代码将 `Profession` 列设置为索引：
- en: '[PRE20]'
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The output is as follows:'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![](img/C11065_04_15.jpg)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/C11065_04_15.jpg)'
- en: 'Figure 4.15: DataFrame after setting the Profession as an index'
  id: totrans-137
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.15：将职业设置为索引后的 DataFrame
- en: 'Exercise 51: The GroupBy Method'
  id: totrans-138
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 51：分组方法
- en: 'Group by refers to a process involving one or more of the following steps:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 分组涉及以下步骤之一或多个：
- en: Splitting the data into groups based on some criteria
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据某些标准将数据拆分到组中
- en: Applying a function to each group independently
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对每个组独立应用函数
- en: Combining the results into a data structure
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将结果组合到数据结构中
- en: 'In many situations, we can split the dataset into groups and do something with
    those groups. In the apply step, we might wish to do one of the following:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多情况下，我们可以将数据集分成组并对这些组进行操作。在应用步骤中，我们可能希望执行以下操作之一：
- en: '**Aggregation**: Compute a summary statistic (or statistics) for each group
    – sum, mean, and so on'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**聚合**：对每个组计算汇总统计量（或统计量） - 总和、平均值等'
- en: '**Transformation**: Perform a group-specific computation and return a like-indexed
    object – z-transformation or filling missing data with a value'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**转换**：执行特定组的计算并返回类似索引的对象 - z 转换或用值填充缺失数据'
- en: '**Filtration**: Discard few groups, according to a group-wise computation that
    evaluates TRUE or FALSE'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**过滤**：根据组内计算评估 TRUE 或 FALSE 来丢弃少量组'
- en: There is, of course, a describe method to this `GroupBy` object, which produces
    the summary statistics in the form of a DataFrame.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这个 `GroupBy` 对象有一个描述方法，它以 DataFrame 的形式生成汇总统计信息。
- en: '`GroupBy` is not limited to a single variable. If you pass on multiple variables
    (as a list), then you will get back a structure essentially similar to a Pivot
    Table (from Excel). The following is an example where we group together all the
    states and cities from the whole dataset (the snapshot is a partial view only).'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '`GroupBy`不仅限于单个变量。如果你传递多个变量（作为一个列表），那么你将得到一个本质上类似于Excel中的数据透视表的结构。以下是一个例子，我们将整个数据集（快照仅显示部分视图）中的所有州和城市分组在一起。'
- en: Note
  id: totrans-149
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The name `GroupBy` should be quite familiar to those who have used a SQL-based
    tool before.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 对于那些之前使用过基于SQL的工具的人来说，名称`GroupBy`应该相当熟悉。
- en: 'Create a 10-record subset using the following command:'
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令创建一个10条记录的子集：
- en: '[PRE21]'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Create a pandas DataFrame using the `groupby` object, as follows:'
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令创建一个pandas DataFrame，如下所示：
- en: '[PRE22]'
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Calculate the mean sales figure by state by using the following command:'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令按州计算平均销售额：
- en: '[PRE23]'
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The output is as follows:'
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.16: Output after grouping the state with the listing mean sales](img/C11065_04_16.jpg)'
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图4.16：按列表平均销售额分组州后的输出](img/C11065_04_16.jpg)'
- en: 'Figure 4.16: Output after grouping the state with the listing mean sales'
  id: totrans-159
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4.16：按列表平均销售额分组州后的输出
- en: 'Calculate the total sales figure by state by using the following command:'
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令计算按州的总销售额：
- en: '[PRE24]'
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The output is as follows:'
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.17: The output after grouping the state with the listing sum of
    sales](img/C11065_04_17.jpg)'
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图4.17：按列表销售额总和分组州后的输出](img/C11065_04_17.jpg)'
- en: 'Figure 4.17: The output after grouping the state with the listing sum of sales'
  id: totrans-164
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4.17：按列表销售额总和分组州后的输出
- en: 'Subset that DataFrame for a particular state and show the statistics:'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对DataFrame进行特定州的子集处理并显示统计信息：
- en: '[PRE25]'
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The output is as follows:'
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.18: Checking the statistics of a particular state](img/C11065_04_18.jpg)'
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图4.18：检查特定州的统计信息](img/C11065_04_18.jpg)'
- en: 'Figure 4.18: Checking the statistics of a particular state'
  id: totrans-169
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4.18：检查特定州的统计信息
- en: 'Perform a similar summarization by using the `Ship Mode` attribute:'
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`Ship Mode`属性执行类似的汇总：
- en: '[PRE26]'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The output will be as follows:'
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.19: Checking the sales by summarizing the Ship Mode attribute](img/C11065_04_19.jpg)'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图4.19：通过汇总Ship Mode属性检查销售](img/C11065_04_19.jpg)'
- en: 'Figure 4.19: Checking the sales by summarizing the Ship Mode attribute'
  id: totrans-174
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4.19：通过汇总Ship Mode属性检查销售
- en: Note how pandas has grouped the data by `State` first and then by cities under
    each state.
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意pandas是如何首先按`State`分组，然后按每个州下的城市进行分组的。
- en: 'Display the complete summary statistics of sales by every city in each state
    – all by two lines of code by using the following command:'
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令显示每个州每个城市的销售完整汇总统计信息——全部通过两行代码完成：
- en: '[PRE27]'
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The output is as follows:'
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.20: Checking the summary statistics of sales](img/C11065_04_20.jpg)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
  zh: '![图4.20：检查销售汇总统计信息](img/C11065_04_20.jpg)'
- en: 'Figure 4.20: Checking the summary statistics of sales'
  id: totrans-180
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4.20：检查销售汇总统计信息
- en: Detecting Outliers and Handling Missing Values
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 检测异常值和处理缺失值
- en: Outlier detection and handling missing values fall under the subtle art of data
    quality checking. A modeling or data mining process is fundamentally a complex
    series of computations whose output quality largely depends on the quality and
    consistency of the input data being fed. The responsibility of maintaining and
    gate keeping that quality often falls on the shoulders of a data wrangling team.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 异常值检测和处理缺失值属于数据质量检查的微妙艺术。建模或数据挖掘过程本质上是一系列复杂的计算，其输出质量很大程度上取决于输入数据的质量和一致性。维护和监控这种质量的责任通常落在数据整理团队的肩上。
- en: Apart from the obvious issue of poor quality data, missing data can sometimes
    wreak havoc with the machine learning (ML) model downstream. A few ML models,
    like Bayesian learning, are inherently robust to outliers and missing data, but
    commonly techniques like Decision Trees and Random Forest have an issue with missing
    data because the fundamental splitting strategy employed by these techniques depends
    on an individual piece of data and not a cluster. Therefore, it is almost always
    imperative to impute missing data before handing it over to such a ML model.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 除了明显的数据质量问题外，缺失数据有时会对下游的机器学习（ML）模型造成破坏。一些ML模型，如贝叶斯学习，对异常值和缺失数据具有内在的鲁棒性，但像决策树和随机森林这样的常用技术由于这些技术的基本分割策略依赖于单个数据点而不是数据簇，因此存在处理缺失数据的问题。因此，在将数据传递给这样的ML模型之前，几乎总是必须对缺失数据进行插补。
- en: 'Outlier detection is a subtle art. Often, there is no universally agreed definition
    of an outlier. In a statistical sense, a data point that falls outside a certain
    range may often be classified as an outlier, but to apply that definition, you
    need to have a fairly high degree of certainty about the assumption of the nature
    and parameters of the inherent statistical distribution about the data. It takes
    a lot of data to build that statistical certainty and even after that, an outlier
    may not be just an unimportant noise but a clue to something deeper. Let''s take
    an example with some fictitious sales data from an American fast food chain restaurant.
    If we want to model the daily sales data as a time series, we observe an unusual
    spike in the data somewhere around mid-April:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 异常值检测是一门微妙的艺术。通常，没有关于异常值的普遍认同的定义。从统计学的角度来看，一个落在某个范围之外的数据点可能经常被归类为异常值，但为了应用这个定义，你需要对数据内在统计分布的性质和参数有一个相当高的确定性。这需要大量的数据来建立这种统计确定性，即使如此，异常值可能不仅仅是不重要的噪声，而是更深层次线索的提示。让我们以一家美国快餐连锁餐厅的一些虚构销售数据为例。如果我们想将每日销售数据建模为时间序列，我们会观察到数据在四月中旬某处出现异常峰值：
- en: '![](img/C11065_04_21.jpg)'
  id: totrans-185
  prefs: []
  type: TYPE_IMG
  zh: '![](img/C11065_04_21.jpg)'
- en: 'Figure 4.21: Fictitious sales data of an American fast food chain restaurant'
  id: totrans-186
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4.21：一家美国快餐连锁餐厅的虚构销售数据
- en: A good data scientist or data wrangler should develop curiosity about this data
    point rather than just rejecting it just because it falls outside the statistical
    range. In the actual anecdote, the sales figure really spiked that day because
    of an unusual reason. So, the data was real. But just because it was real does
    not mean it is useful. In the final goal of building a smoothly varying time series
    model, this one point should not matter and should be rejected. But the chapter
    here is that we cannot reject outliers without paying some attention to them.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 一个优秀的数据科学家或数据整理员应该对这一数据点产生好奇心，而不仅仅是由于它超出了统计范围就拒绝它。在实际情况中，当天的销售额之所以大幅上升，是因为一个不寻常的原因。因此，数据是真实的。但仅仅因为数据是真实的，并不意味着它是有用的。在最终目标是构建一个平滑变化的时间序列模型的情况下，这个数据点不应该产生影响，应该被拒绝。但这里的关键是我们不能不关注这些异常值就拒绝它们。
- en: Therefore, the key to outliers is their systematic and timely detection in an
    incoming stream of millions of data or while reading data from a cloud-based storage.
    In this topic, we will quickly go over some basic statistical tests for detecting
    outliers and some basic imputation techniques for filling up missing data.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，关键在于在数百万数据流中系统及时地检测异常值，或者在从基于云的存储中读取数据时。在这个主题中，我们将快速浏览一些用于检测异常值的基本统计测试和一些用于填充缺失数据的基本插补技术。
- en: Missing Values in Pandas
  id: totrans-189
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Pandas中的缺失值
- en: 'One of the most useful functions to detect missing values is `isnull`. Here,
    we have a snapshot of a `DataFrame` called `df_missing` (sampled partially from
    the superstore DataFrame we are working with) with some missing values:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 用于检测缺失值的最有用函数之一是`isnull`。在这里，我们有一个名为`df_missing`的`DataFrame`的快照（部分从我们正在处理的大型超市DataFrame中采样）并包含一些缺失值：
- en: '![Figure 4.22: DataFrame with missing values](img/C11065_04_22.jpg)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![图4.22：包含缺失值的DataFrame](img/C11065_04_22.jpg)'
- en: 'Figure 4.22: DataFrame with missing values'
  id: totrans-192
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4.22：包含缺失值的DataFrame
- en: 'Now, if we simply run the following code, we will get a DataFrame that''s the
    same size as the original with boolean values as TRUE for the places where a **NaN**
    was encountered. Therefore, it is simple to test for the presence of any **NaN**/missing
    value for any row or column of the DataFrame. You just have to add the particular
    row and column of this boolean DataFrame. If the result is greater than zero,
    then you know there are some TRUE values (because FALSE here is denoted by 0 and
    TRUE here is denoted by 1) and correspondingly some missing values. Try the following
    snippet:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果我们简单地运行以下代码，我们将得到一个与原始数据集大小相同的DataFrame，其中布尔值为TRUE表示遇到**NaN**的地方。因此，测试DataFrame的任何行或列中是否存在任何**NaN**/缺失值是简单的。你只需要添加这个布尔DataFrame的特定行和列。如果结果大于零，那么你就知道有一些TRUE值（因为这里的FALSE表示为0，TRUE表示为1），相应地也有一些缺失值。尝试以下代码片段：
- en: '[PRE28]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The output is as follows:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.23: DataFrame with the Excel values](img/C11065_04_23.jpg)'
  id: totrans-196
  prefs: []
  type: TYPE_IMG
  zh: '![图4.23：包含Excel值的DataFrame](img/C11065_04_23.jpg)'
- en: 'Figure 4.23: DataFrame with the Excel values'
  id: totrans-197
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4.23：包含Excel值的DataFrame
- en: 'Use the `isnull` function on the DataFrame and observe the results:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 在DataFrame上使用`isnull`函数并观察结果：
- en: '[PRE29]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '![Figure 4.24 Output highlighting the missing values](img/C11065_04_24.jpg)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.24：突出显示的缺失值输出](img/C11065_04_24.jpg)'
- en: Figure 4.24 Output highlighting the missing values
  id: totrans-201
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.24：突出显示的缺失值输出
- en: 'Here is an example of some very simple code to detect, count, and print out
    missing values in every column of a DataFrame:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个检测、计数和打印 DataFrame 每一列中缺失值的简单代码示例：
- en: '[PRE30]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'This code scans every column of the DataFrame, calls the `isnull` function,
    and sums up the returned object (a pandas Series object, in this case) to count
    the number of missing values. If the missing value is greater than zero, it prints
    out the message accordingly. The output looks as follows:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码扫描 DataFrame 的每一列，调用 `isnull` 函数，并将返回的对象（在这种情况下是一个 pandas Series 对象）求和以计算缺失值的数量。如果缺失值大于零，则相应地打印出消息。输出如下所示：
- en: '![Figure 4.25: Output of counting the missing values](img/C11065_04_25.jpg)'
  id: totrans-205
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.25：计数缺失值的输出](img/C11065_04_25.jpg)'
- en: 'Figure 4.25: Output of counting the missing values'
  id: totrans-206
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.25：计数缺失值的输出
- en: 'Exercise 52: Filling in the Missing Values with fillna'
  id: totrans-207
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 52：使用 fillna 填充缺失值
- en: To handle missing values, you should first look for ways not to drop them altogether
    but to fill them somehow. The `fillna` method is a useful function for performing
    this task on pandas DataFrames. The `fillna` method may work for string data,
    but not for numerical columns like sales or profits. So, we should restrict ourselves
    in regards to this fixed string replacement to non-numeric text-based columns
    only. The `Pad` or `ffill` function is used to fill forward the data, that is,
    copy it from the preceding data of the series.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 要处理缺失值，您应该首先寻找方法不是完全删除它们，而是以某种方式填充它们。`fillna` 方法是执行此任务在 pandas DataFrame 上的一个有用函数。`fillna`
    方法可能适用于字符串数据，但不适用于销售或利润等数值列。因此，我们应该将固定字符串替换限制在仅基于文本的非数值列上。`Pad` 或 `ffill` 函数用于向前填充数据，即从序列的前一个数据复制。
- en: 'The `mean` function can be used to fill using the average of the two values:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用 `mean` 函数使用两个值的平均值进行填充：
- en: 'Fill all missing values with the string `FILL` by using the following command:'
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令使用字符串 `FILL` 填充所有缺失值：
- en: '[PRE31]'
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The output is as follows:'
  id: totrans-212
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.26: Missing values replaced with FILL](img/C11065_04_26.jpg)'
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 4.26：缺失值被替换为 FILL](img/C11065_04_26.jpg)'
- en: 'Figure 4.26: Missing values replaced with FILL'
  id: totrans-214
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.26：缺失值被替换为 FILL
- en: 'Fill in the specified columns with the string `FILL` by using the following
    command:'
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令使用字符串 `FILL` 填充指定的列：
- en: '[PRE32]'
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The output is as follows:'
  id: totrans-217
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![](img/C11065_04_27.jpg)'
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](img/C11065_04_27.jpg)'
- en: 'Figure 4.27: Specified columns replaced with FILL'
  id: totrans-219
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.27：指定的列被替换为 FILL
- en: Note
  id: totrans-220
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: In all of these cases, the function works on a copy of the original DataFrame.
    So, if you want to make the changes permanent, you have to assign the DataFrames
    that are returned by these functions to the original DataFrame object.
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在所有这些情况下，函数都在原始 DataFrame 的副本上工作。因此，如果您想使更改永久，必须将这些函数返回的 DataFrame 赋值给原始 DataFrame
    对象。
- en: 'Fill in the values using pad or backfill by using the following command:'
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令通过 pad 或 backfill 填充值：
- en: '[PRE33]'
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Use `backfill` or `bfill` to fill backward, that is, copy from the next data
    in the series:'
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `backfill` 或 `bfill` 向后填充，即从序列中的下一个数据复制：
- en: '[PRE34]'
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '![Figure 4.28: Using forward fill and backward fill to fill in missing data](img/C11065_04_28.jpg)'
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 4.28：使用前向填充和后向填充填充缺失数据](img/C11065_04_28.jpg)'
- en: 'Figure 4.28: Using forward fill and backward fill to fill in missing data'
  id: totrans-227
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.28：使用前向填充和后向填充填充缺失数据
- en: 'You can also fill by using a function average of DataFrames. For example, we
    may want to fill the missing values in Sales by the average sales amount. Here
    is how we can do that:'
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您也可以使用 DataFrame 的平均值函数进行填充。例如，我们可能希望使用平均销售额填充销售中的缺失值。以下是我们可以这样做的方式：
- en: '[PRE35]'
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '![](img/C11065_04_29.jpg)'
  id: totrans-230
  prefs: []
  type: TYPE_IMG
  zh: '![](img/C11065_04_29.jpg)'
- en: 'Figure 4.29: Using average to fill in missing data'
  id: totrans-231
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.29：使用平均值填充缺失数据
- en: 'Exercise 53: Dropping Missing Values with dropna'
  id: totrans-232
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 53：使用 dropna 删除缺失值
- en: This function is used to simply drop the rows or columns that contain NaN/missing
    values. However, there is some choice involved.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数用于简单地删除包含 NaN/缺失值的行或列。然而，这里涉及一些选择。
- en: If the axis parameter is set to zero, then rows containing missing values are
    dropped; if the axis parameter is set to one, then columns containing missing
    values are dropped. These are useful if we don't want to drop a particular row/column
    if the NaN values do not exceed a certain percentage.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 如果轴参数设置为0，则删除包含缺失值的行；如果轴参数设置为1，则删除包含缺失值的列。如果NaN值不超过一定百分比，这些参数对于我们不希望删除特定行/列是有用的。
- en: 'Two arguments that are useful for the `dropna`() method are as follows:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 `dropna()` 方法有用的两个参数如下：
- en: The `how` argument determines if a row or column is removed from a DataFrame,
    when we have at least one NaN or all NaNs
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`how` 参数确定当我们至少有一个NaN或所有NaN时，是否从DataFrame中删除行或列'
- en: The `thresh` argument requires that many non-NaN values to keep the row/column
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`thresh` 参数要求保留许多非NaN值以保留行/列'
- en: 'To set the axis parameter to zero and drop all missing rows, use the following
    command:'
  id: totrans-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要将轴参数设置为0并删除所有缺失行，请使用以下命令：
- en: '[PRE36]'
  id: totrans-239
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'To set the axis parameter to one and drop all missing rows, use the following
    command:'
  id: totrans-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要将轴参数设置为1并删除所有缺失行，请使用以下命令：
- en: '[PRE37]'
  id: totrans-241
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '![Figure 4.30: Dropping rows or columns to handle missing data](img/C11065_04_30.jpg)'
  id: totrans-242
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图4.30：删除行或列以处理缺失数据](img/C11065_04_30.jpg)'
- en: 'Figure 4.30: Dropping rows or columns to handle missing data'
  id: totrans-243
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4.30：删除行或列以处理缺失数据
- en: 'Drop the values with the axis set to one and thresh set to 10:'
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将axis设置为1和thresh设置为10的值删除：
- en: '[PRE38]'
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'The output is as follows:'
  id: totrans-246
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.31: DataFrame with values dropped with axis=1 and thresh=10](img/C11065_04_31.jpg)'
  id: totrans-247
  prefs: []
  type: TYPE_IMG
  zh: '![图4.31：使用axis=1和thresh=10删除值的DataFrame](img/C11065_04_31.jpg)'
- en: 'Figure 4.31: DataFrame with values dropped with axis=1 and thresh=10'
  id: totrans-248
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4.31：使用axis=1和thresh=10删除值的DataFrame
- en: All of these methods work on a temporary copy. To make a permanent change, you
    have to set `inplace=True` or assign the result to the original DataFrame, that
    is, overwrite it.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些方法都在临时副本上工作。要永久更改，您必须设置 `inplace=True` 或将结果分配给原始DataFrame，即覆盖它。
- en: Outlier Detection Using a Simple Statistical Test
  id: totrans-250
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用简单统计测试进行异常值检测
- en: 'As we''ve already discussed, outliers in a dataset can occur due to many factors
    and in many ways:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们已经讨论过的，数据集中的异常值可能由许多因素以多种方式产生：
- en: Data entry errors
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据输入错误
- en: Experimental errors (data extraction related)
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实验误差（与数据提取相关的）
- en: Measurement errors due to noise or instrumental failure
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于噪声或仪器故障导致的测量误差
- en: Data processing errors (data manipulation or mutations due to coding error)
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据处理错误（由于编码错误导致的数据操作或突变）
- en: Sampling errors (extracting or mixing data from wrong or various sources)
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 抽样误差（从错误或各种来源提取或混合数据）
- en: It is impossible to pin-point one universal method for outlier detection. Here,
    we will show you some simple tricks for numeric data using standard statistical
    tests.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 无法确定一个通用的异常值检测方法。在这里，我们将向您展示一些使用标准统计测试对数值数据进行的一些简单技巧。
- en: 'Boxplots may show unusual values. Corrupt two sales values by assigning negative,
    as follows:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 箱线图可能显示异常值。通过以下方式将两个销售额值设置为负数：
- en: '[PRE39]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'To plot the boxplot, use the following code:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 要绘制箱线图，请使用以下代码：
- en: '[PRE40]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'The output is as follows:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![](img/C11065_04_32.jpg)'
  id: totrans-263
  prefs: []
  type: TYPE_IMG
  zh: '![](img/C11065_04_32.jpg)'
- en: 'Figure 4.32: Boxplot of sales and profit'
  id: totrans-264
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4.32：销售额和利润的箱线图
- en: We can create simple boxplots to check for any unusual/nonsensical values. For
    example, in the preceding example, we intentionally corrupted two sales values
    to be negative and they were readily caught in a boxplot.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以创建简单的箱线图来检查任何异常/不合逻辑的值。例如，在上面的例子中，我们故意将两个销售额值设置为负数，它们在箱线图中很容易被发现。
- en: Note that profit may be negative, so those negative points are generally not
    suspicious. But sales cannot be negative in general, so they are detected as outliers.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，利润可能是负数，所以这些负数点通常并不可疑。但一般来说，销售额不能是负数，所以它们被检测为异常值。
- en: 'We can create a distribution of a numerical quantity and check for values that
    lie at the extreme end to see if they are truly part of the data or outlier. For
    example, if a distribution is almost normal, then any value more than 4 or 5 standard
    deviations away may be a suspect:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以创建一个数值量的分布，并检查位于极端值的位置，以查看它们是否真正是数据的一部分或异常值。例如，如果一个分布几乎是正态的，那么任何超过4或5个标准差的价值可能是有嫌疑的：
- en: '![Figure 4.33: Value away from the main outliers](img/C11065_04_33.jpg)'
  id: totrans-268
  prefs: []
  type: TYPE_IMG
  zh: '![图4.33：远离主要异常值的价值](img/C11065_04_33.jpg)'
- en: 'Figure 4.33: Value away from the main outliers'
  id: totrans-269
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4.33：远离主要异常值的价值
- en: Concatenating, Merging, and Joining
  id: totrans-270
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 连接、合并和连接
- en: Merging and joining tables or datasets are highly common operations in the day-to-day
    job of a data wrangling professional. These operations are akin to the JOIN query
    in SQL for relational database tables. Often, the key data is present in multiple
    tables, and those records need to be brought into one combined table that's matching
    on that common key. This is an extremely common operation in any type of sales
    or transactional data, and therefore must be mastered by a data wrangler. The
    pandas library offers nice and intuitive built-in methods to perform various types
    of JOIN queries involving multiple DataFrame objects.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 将表或数据集合并或连接是数据整理专业人士日常工作中非常常见的操作。这些操作类似于关系数据库表中的 JOIN 查询。通常，关键数据分布在多个表中，这些记录需要被合并到一个匹配该公共键的单一表中。这在任何类型的销售或交易数据中都是一个极其常见的操作，因此数据整理者必须掌握这一技能。pandas
    库提供了方便且直观的内置方法来执行涉及多个 DataFrame 对象的各种类型的 JOIN 查询。
- en: 'Exercise 54: Concatenation'
  id: totrans-272
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 54：连接
- en: 'We will start by learning the concatenation of DataFrames along various axes
    (rows or columns). This is a very useful operation as it allows you to grow a
    DataFrame as the new data comes in or new feature columns need to be inserted
    in the table:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先学习沿各个轴（行或列）连接 DataFrame 的方法。这是一个非常有用的操作，因为它允许你在新数据到来或需要在表中插入新特征列时扩展 DataFrame：
- en: 'Sample 4 records each to create three DataFrames at random from the original
    sales dataset we are working with:'
  id: totrans-274
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从我们正在处理的原销售数据集中随机创建三个 DataFrame，每个 DataFrame 包含 4 条记录：
- en: '[PRE41]'
  id: totrans-275
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Create a combined DataFrame with all the rows concatenated by using the following
    code:'
  id: totrans-276
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下代码创建一个包含所有行连接的合并 DataFrame：
- en: '[PRE42]'
  id: totrans-277
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '![Figure 4.34: Concatenating DataFrames together'
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.34：将 DataFrame 连接在一起](img/C11065_04_34.jpg)'
- en: '](img/C11065_04_34.jpg)'
  id: totrans-279
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.34：将 DataFrame 连接在一起](img/C11065_04_34.jpg)'
- en: 'Figure 4.34: Concatenating DataFrames together'
  id: totrans-280
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.34：将 DataFrame 连接在一起
- en: 'You can also try concatenating along the columns, although that does not make
    any practical sense for this particular example. However, pandas fills in the
    unavailable values with **NaN** for that operation:'
  id: totrans-281
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你也可以尝试沿列进行连接，尽管对于这个特定的例子来说，这没有任何实际意义。然而，pandas 在该操作中用 **NaN** 填充不可用的值：
- en: '[PRE43]'
  id: totrans-282
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: '![Figure 4.35: Output after concatenating the DataFrames](img/C11065_04_35.jpg)'
  id: totrans-283
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.35：连接 DataFrame 后的输出](img/C11065_04_35.jpg)'
- en: 'Figure 4.35: Output after concatenating the DataFrames'
  id: totrans-284
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.35：连接 DataFrame 后的输出
- en: 'Exercise 55: Merging by a Common Key'
  id: totrans-285
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 55：通过公共键合并
- en: Merging by a common key is an extremely common operation for data tables as
    it allows you to rationalize multiple sources of data in one master database –
    that is, if they have some common features/keys.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 通过公共键合并是数据表的一个极其常见的操作，因为它允许你在主数据库中合理化多个数据源——即如果它们有一些公共特征/键。
- en: This is often the first step in building a large database for machine learning
    tasks where daily incoming data may be put into separate tables. However, at the
    end of the day, the most recent table needs to be merged with the master data
    table to be fed into the backend machine learning server, which will then update
    the model and its prediction capacity.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 这通常是构建用于机器学习任务的大型数据库的第一步，其中每日传入的数据可能被放入单独的表中。然而，最终，最新的表需要与主数据表合并，以便输入到后端机器学习服务器中，然后更新模型及其预测能力。
- en: 'Here, we will show a simple example of an inner join with Customer Name as
    the key:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将展示一个以客户名称为键的内部连接的简单示例：
- en: 'One DataFrame, `df_1`, had shipping information associated with the customer
    name, and another table, `df_2`, had the product information tabulated. Our goal
    is to merge these tables into one DataFrame on the common customer name:'
  id: totrans-289
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个 DataFrame，`df_1`，与客户名称相关的运输信息相关联，另一个表，`df_2`，有产品信息表格。我们的目标是根据公共客户名称将这些表合并到一个
    DataFrame 中：
- en: '[PRE44]'
  id: totrans-290
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'The output is as follows:'
  id: totrans-291
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下所示：
- en: '![Figure 4.36: Entries in table df_1](img/C11065_04_36.jpg)'
  id: totrans-292
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 4.36：df_1 表中的条目](img/C11065_04_36.jpg)'
- en: 'Figure 4.36: Entries in table df_1'
  id: totrans-293
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.36：df_1 表中的条目
- en: 'The second DataFrame is as follows:'
  id: totrans-294
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第二个 DataFrame 如下所示：
- en: '[PRE45]'
  id: totrans-295
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'The output is as follows:'
  id: totrans-296
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下所示：
- en: '![Figure 4.37: Entries in table df_2](img/C11065_04_37.jpg)'
  id: totrans-297
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 4.37：df_2 表中的条目](img/C11065_04_37.jpg)'
- en: 'Figure 4.37: Entries in table df_2'
  id: totrans-298
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.37：df_2 表中的条目
- en: 'Join these two tables by inner join by using the following command:'
  id: totrans-299
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令通过内部连接将这两个表连接起来：
- en: '[PRE46]'
  id: totrans-300
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'The output is as follows:'
  id: totrans-301
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下所示：
- en: '![Figure 4.38: Inner join on table df_1 and table df_2](img/C11065_04_38.jpg)'
  id: totrans-302
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 4.38：df_1 和 df_2 表的内部连接](img/C11065_04_38.jpg)'
- en: 'Figure 4.38: Inner join on table df_1 and table df_2'
  id: totrans-303
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.38：df_1 和 df_2 表的内部连接
- en: Drop the duplicates by using the following command.
  id: totrans-304
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令删除重复项。
- en: '[PRE47]'
  id: totrans-305
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'The output is as follows:'
  id: totrans-306
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.39: Inner join on table df_1 and table df_2 after dropping the duplicates](img/C11065_04_39.jpg)'
  id: totrans-307
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 4.39：删除重复项后，在表 df_1 和表 df_2 上进行内连接](img/C11065_04_39.jpg)'
- en: 'Figure 4.39: Inner join on table df_1 and table df_2 after dropping the duplicates'
  id: totrans-308
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.39：删除重复项后，在表 df_1 和表 df_2 上进行内连接
- en: 'Extract another small table called `df_3` to show the concept of an outer join:'
  id: totrans-309
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提取另一个名为 `df_3` 的小表来展示外连接的概念：
- en: '[PRE48]'
  id: totrans-310
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'The output is as follows:'
  id: totrans-311
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![](img/C11065_04_40.jpg)'
  id: totrans-312
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](img/C11065_04_40.jpg)'
- en: 'Figure 4.40: Creating table df_3'
  id: totrans-313
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.40：创建表 df_3
- en: 'Perform an inner join on `df_1` and `df_3` by using the following command:'
  id: totrans-314
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令在 `df_1` 和 `df_3` 上执行内连接：
- en: '[PRE49]'
  id: totrans-315
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'The output is as follows:'
  id: totrans-316
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.41: Merging table df_1 and table df_3 and dropping duplicates](img/C11065_04_41.jpg)'
  id: totrans-317
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 4.41：合并表 df_1 和表 df_3 并删除重复项](img/C11065_04_41.jpg)'
- en: 'Figure 4.41: Merging table df_1 and table df_3 and dropping duplicates'
  id: totrans-318
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.41：合并表 df_1 和表 df_3 并删除重复项
- en: 'Perform an outer join on `df_1` and `df_3` by using the following command:'
  id: totrans-319
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令在 `df_1` 和 `df_3` 上执行外连接：
- en: '[PRE50]'
  id: totrans-320
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'The output is as follows:'
  id: totrans-321
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.42: Outer join on table df_1 and table df_2 and dropping the duplicates](img/C11065_04_42.jpg)'
  id: totrans-322
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.42：在删除重复项后，在表 df_1 和表 df_2 上进行外连接](img/C11065_04_42.jpg)'
- en: 'Figure 4.42: Outer join on table df_1 and table df_2 and dropping the duplicates'
  id: totrans-323
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.42：在删除重复项后，在表 df_1 和表 df_2 上进行外连接
- en: Notice how some `NaN` and `NaT` values are inserted automatically because no
    corresponding entries could be found for those records, as those are the entries
    with unique customer names from their respective tables. `NaT` represents a Not
    a Time object, as the objects in the Ship Date column are of the nature of Timestamp
    objects.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，由于找不到与这些记录对应的条目，因此自动插入了某些 `NaN` 和 `NaT` 值，因为这些条目是各自表中具有唯一客户名称的条目。`NaT` 代表“不是一个时间”对象，因为“发货日期”列中的对象是时间戳对象。
- en: 'Exercise 56: The join Method'
  id: totrans-325
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 56：连接方法
- en: 'Joining is performed based on **index** **keys** and is done by combining the
    columns of two potentially differently indexed DataFrames into a single one. It
    offers a faster way to accomplish merging by row indices. This is useful if the
    records in different tables are indexed differently but represent the same inherent
    data and you want to merge them into a single table:'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 连接操作基于 **索引** **键** 进行，通过将两个可能具有不同索引的 DataFrame 的列合并成一个单一来完成。它提供了一种通过行索引完成合并的更快方式。如果不同表中的记录索引不同但代表相同的基本数据，并且您想将它们合并到一个表中，这很有用：
- en: 'Create the following tables with customer name as the index by using the following
    command:'
  id: totrans-327
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令创建以下表格，以客户名称作为索引：
- en: '[PRE51]'
  id: totrans-328
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'The outputs is as follows:'
  id: totrans-329
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![](img/C11065_04_43.jpg)'
  id: totrans-330
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](img/C11065_04_43.jpg)'
- en: 'Figure 4.43: DataFrames df_1 and df_2'
  id: totrans-331
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.43：DataFrame df_1 和 df_2
- en: 'Perform a left join on `df_1` and `df_2` by using the following command:'
  id: totrans-332
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令在 `df_1` 和 `df_2` 上执行左连接：
- en: '[PRE52]'
  id: totrans-333
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'The output is as follows:'
  id: totrans-334
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![](img/C11065_04_44.jpg)'
  id: totrans-335
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](img/C11065_04_44.jpg)'
- en: 'Figure 4.44: Left join on table df_1 and table df_2 after dropping the duplicates'
  id: totrans-336
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.44：删除重复项后，在表 df_1 和表 df_2 上进行左连接
- en: 'Perform a right join on `df_1` and `df_2` by using the following command:'
  id: totrans-337
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令在 `df_1` 和 `df_2` 上执行右连接：
- en: '[PRE53]'
  id: totrans-338
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'The output is as follows:'
  id: totrans-339
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![](img/C11065_04_45.jpg)'
  id: totrans-340
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](img/C11065_04_45.jpg)'
- en: 'Figure 4.45: Right join on table df_1 and table df_2 after dropping the duplicates'
  id: totrans-341
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.45：删除重复项后，在表 df_1 和表 df_2 上进行右连接
- en: 'Perform an inner join on `df_1` and `df_2` by using the following command:'
  id: totrans-342
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令在 `df_1` 和 `df_2` 上执行内连接：
- en: '[PRE54]'
  id: totrans-343
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'The output is as follows:'
  id: totrans-344
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![](img/C11065_04_46.jpg)'
  id: totrans-345
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](img/C11065_04_46.jpg)'
- en: 'Figure 4.46: Inner join on table df_1 and table df_2 after dropping the duplicates'
  id: totrans-346
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.46：删除重复项后，在表 df_1 和表 df_2 上进行内连接
- en: 'Perform an outer join on `df_1` and `df_2` by using the following command:'
  id: totrans-347
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令在 `df_1` 和 `df_2` 上执行外连接：
- en: '[PRE55]'
  id: totrans-348
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'The output is as follows:'
  id: totrans-349
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![](img/C11065_04_47.jpg)'
  id: totrans-350
  prefs: []
  type: TYPE_IMG
  zh: '![](img/C11065_04_47.jpg)'
- en: 'Figure 4.47: Outer join on table df_1 and table df_2 after dropping the duplicates'
  id: totrans-351
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.47：删除重复项后，在表 df_1 和表 df_2 上进行外连接
- en: Useful Methods of Pandas
  id: totrans-352
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 有用的 Pandas 方法
- en: In this topic, we will discuss some small utility functions that are offered
    by pandas so that we can work efficiently with DataFrames. They don't fall under
    any particular group of function, so they are mentioned here under the Miscellaneous
    category.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个主题中，我们将讨论pandas提供的一些小型实用函数，以便我们能够高效地与DataFrame一起工作。它们不属于任何特定的函数组，因此它们在这里在杂项类别下被提及。
- en: 'Exercise 57: Randomized Sampling'
  id: totrans-354
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习57：随机抽样
- en: Sampling a random fraction of a big DataFrame is often very useful so that we
    can practice other methods on them and test our ideas. If you have a database
    table of 1 million records, then it is not computationally effective to run your
    test scripts on the full table.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 从大型DataFrame中随机采样一个随机分数通常非常有用，这样我们就可以在它们上练习其他方法并测试我们的想法。如果你有一个包含100万条记录的数据库表，那么在完整表上运行你的测试脚本在计算上可能不是有效的。
- en: However, you may also not want to extract only the first 100 elements as the
    data may have been sorted by a particular key and you may get an uninteresting
    table back, which may not represent the full statistical diversity of the parent
    database.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，你可能也不希望只提取前100个元素，因为数据可能已经按特定键排序，你可能会得到一个无趣的表格，这可能不会代表父数据库的完整统计多样性。
- en: 'In these situations, the `sample` method comes in super handy so that we can
    randomly choose a controlled fraction of the DataFrame:'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些情况下，`sample`方法非常有用，这样我们就可以随机选择DataFrame的一个受控分数：
- en: 'Specify the number of samples that you require from the DataFrame by using
    the following command:'
  id: totrans-358
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令指定从DataFrame中所需的样本数量：
- en: '[PRE56]'
  id: totrans-359
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'The output is as follows:'
  id: totrans-360
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![](img/C11065_04_48.jpg)'
  id: totrans-361
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](img/C11065_04_48.jpg)'
- en: 'Figure 4.48: DataFrame with 5 samples'
  id: totrans-362
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4.48：包含5个样本的DataFrame
- en: 'Specify a definite fraction (percentage) of data to be sampled by using the
    following command:'
  id: totrans-363
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令指定要采样的数据的确切分数（百分比）：
- en: '[PRE57]'
  id: totrans-364
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'The output is as follows:'
  id: totrans-365
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![](img/C11065_04_49.jpg)'
  id: totrans-366
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](img/C11065_04_49.jpg)'
- en: 'Figure 4.49: DataFrame with 0.1% data sampled'
  id: totrans-367
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4.49：包含0.1%数据采样的DataFrame
- en: You can also choose if sampling is done with replacement, that is, whether the
    same record can be chosen more than once. The default replace choice is FALSE,
    that is, no repetition, and sampling will try to choose new elements only.
  id: totrans-368
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您也可以选择是否进行有放回的抽样，即是否可以选择相同的记录多次。默认的replace选择是FALSE，即无重复，抽样将尝试只选择新元素。
- en: 'Choose the sampling by using the following command:'
  id: totrans-369
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令选择抽样：
- en: '[PRE58]'
  id: totrans-370
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'The output is as follows:'
  id: totrans-371
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![](img/C11065_04_50.jpg)'
  id: totrans-372
  prefs: []
  type: TYPE_IMG
  zh: '![](img/C11065_04_50.jpg)'
- en: 'Figure 4.50: DataFrame with 0.1% data sampled and repetition enabled'
  id: totrans-373
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4.50：包含0.1%数据且启用重复的DataFrame
- en: The value_counts Method
  id: totrans-374
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '`value_counts`方法'
- en: We discussed the `unique` method before, which finds and counts the unique records
    from a DataFrame. Another useful function in a similar vein is `value_counts`.
    This function returns an object containing counts of unique values. In the object
    that is returned, the first element is the most frequently used object. The elements
    are arranged in descending order.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前讨论了`unique`方法，该方法从DataFrame中查找并计数唯一记录。在类似方面的另一个有用函数是`value_counts`。此函数返回一个包含唯一值计数的对象。在返回的对象中，第一个元素是最频繁使用的对象。元素按降序排列。
- en: 'Let''s consider a practical application of this method to illustrate the utility.
    Suppose your manager asks you to list the top 10 customers from the big sales
    database that you have. So, the business question is: which 10 customers'' names
    occur the most frequently in the sales table? You can achieve the same with an
    SQL query if the data is in a RDBMS, but in pandas, this can be done by using
    one simple function:'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑这个方法的一个实际应用来展示其效用。假设你的经理要求你列出从你拥有的大型销售数据库中排名前10的客户。因此，业务问题是：哪些10个客户的名称在销售表中出现频率最高？如果数据在RDBMS中，你可以使用SQL查询实现相同的功能，但在pandas中，可以通过使用一个简单的函数来完成：
- en: '[PRE59]'
  id: totrans-377
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'The output is as follows:'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![](img/C11065_04_51.jpg)'
  id: totrans-379
  prefs: []
  type: TYPE_IMG
  zh: '![](img/C11065_04_51.jpg)'
- en: 'Figure 4.51: List of top 10 customers'
  id: totrans-380
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4.51：前10名客户列表
- en: The `value_counts` method returns a series of the counts of all unique customer
    names sorted by the frequency of the count. By asking for only the first 10 elements
    of that list, this code returns a series of the most frequently occurring top
    10 customer names.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: '`value_counts` 方法返回一个按计数频率排序的所有唯一客户名称计数的序列。通过只请求该列表的前10个元素，此代码返回出现频率最高的前10个客户名称的序列。'
- en: Pivot Table Functionality
  id: totrans-382
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 交叉表功能
- en: Similar to group by, pandas also offer pivot table functionality, which works
    the same as a pivot table in spreadsheet programs like MS Excel. For example,
    in this sales database, you want to know the average sales, profit, and quantity
    sold, by Region and State (two levels of index).
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 与 group by 类似，pandas 还提供了交叉表功能，这与 MS Excel 等电子表格程序中的交叉表功能相同。例如，在这个销售数据库中，您想了解按地区和州（两个索引级别）的平均销售额、利润和销售数量。
- en: 'We can extract this information by using one simple piece of code (we sample
    100 records first for keeping the computation fast and then apply the code):'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过一段简单的代码提取此信息（我们首先随机抽取 100 条记录以保持计算快速，然后应用此代码）：
- en: '[PRE60]'
  id: totrans-385
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'The output is as follows (note that your specific output may be different due
    to random sampling):'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下（请注意，由于随机抽样，您的具体输出可能不同）：
- en: '![](img/C11065_04_52.jpg)'
  id: totrans-387
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/C11065_04_52.jpg)'
- en: 'Figure 4.52: Sample of 100 records'
  id: totrans-388
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.52：100 条记录的样本
- en: 'Exercise 58: Sorting by Column Values – the sort_values Method'
  id: totrans-389
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 58：按列值排序 – sort_values 方法
- en: 'Sorting a table by a particular column is one of the most frequently used operations
    in the daily work of an analyst. Not surprisingly, pandas provide a simple and
    intuitive method for sorting called the `sort_values` method:'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 按特定列对表格进行排序是分析师日常工作中最常用的操作之一。不出所料，pandas 提供了一个简单直观的排序方法，称为 `sort_values` 方法：
- en: 'Take a random sample of 15 records and then show how we can sort by the Sales
    column and then by both the Sales and State columns together:'
  id: totrans-391
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 随机抽取 15 条记录，然后展示如何按 Sales 列排序，然后按 Sales 和 State 列一起排序：
- en: '[PRE61]'
  id: totrans-392
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'The output is as follows:'
  id: totrans-393
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.53: Sample of 15 records](img/C11065_04_53.jpg)'
  id: totrans-394
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 4.53：15 条记录的样本](img/C11065_04_53.jpg)'
- en: 'Figure 4.53: Sample of 15 records'
  id: totrans-395
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.53：15 条记录的样本
- en: 'Sort the values with respect to `Sales` by using the following command:'
  id: totrans-396
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令按 `Sales` 排序值：
- en: '[PRE62]'
  id: totrans-397
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'The output is as follows:'
  id: totrans-398
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.54: DataFrame with the Sales value sorted](img/C11065_04_54.jpg)'
  id: totrans-399
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 4.54：按 Sales 值排序的 DataFrame](img/C11065_04_54.jpg)'
- en: 'Figure 4.54: DataFrame with the Sales value sorted'
  id: totrans-400
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.54：按 Sales 值排序的 DataFrame
- en: 'Sort the values with respect to Sales and State:'
  id: totrans-401
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照Sales和State排序值：
- en: '[PRE63]'
  id: totrans-402
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'The output is as follows:'
  id: totrans-403
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![](img/C11065_04_55.jpg)'
  id: totrans-404
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/C11065_04_55.jpg)'
- en: 'Figure 4.55: DataFrame sorted with respect to Sales and State'
  id: totrans-405
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.55：按 Sales 和 State 排序的 DataFrame
- en: 'Exercise 59: Flexibility for User-Defined Functions with the apply Method'
  id: totrans-406
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 59：使用 apply 方法对用户定义函数的灵活性
- en: The pandas library provides great flexibility to work with user-defined functions
    of arbitrary complexity through the `apply` method. Much like the native Python
    `apply` function, this method accepts a user-defined function and additional arguments
    and returns a new column after applying the function on a particular column element-wise.
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: pandas 库通过 `apply` 方法提供了极大的灵活性，用于处理任意复杂性的用户定义函数。与原生的 Python `apply` 函数类似，此方法接受用户定义的函数和额外的参数，并在对特定列的每个元素应用函数后返回一个新列。
- en: 'As an example, suppose we want to create a column of categorical features like
    high/medium/low based on the sales price column. Note that it is a conversion
    from a numeric value to a categorical factor (string) based on certain conditions
    (threshold values of sales):'
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设我们想创建一个基于销售价格列的类别特征列，如高/中/低。请注意，这是根据某些条件（销售阈值）将数值值转换为类别因子（字符串）的转换：
- en: 'Create a user-defined function, as follows:'
  id: totrans-409
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个用户定义的函数，如下所示：
- en: '[PRE64]'
  id: totrans-410
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'Sample 100 records randomly from the database:'
  id: totrans-411
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从数据库中随机抽取 100 条记录：
- en: '[PRE65]'
  id: totrans-412
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'The output is as follows:'
  id: totrans-413
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![](img/C11065_04_56.jpg)'
  id: totrans-414
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 4.56：数据库中的 100 条样本记录](img/C11065_04_56.jpg)'
- en: 'Figure 4.56: 100 sample records from the database'
  id: totrans-415
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.56：数据库中的 100 条样本记录
- en: 'Use the `apply` method to apply the categorization function onto the `Sales`
    column:'
  id: totrans-416
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `apply` 方法将分类函数应用于 `Sales` 列：
- en: Note
  id: totrans-417
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: '[PRE66]'
  id: totrans-418
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'The output is as follows:'
  id: totrans-419
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![](img/C11065_04_57.jpg)'
  id: totrans-420
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图片](img/C11065_04_57.jpg)'
- en: 'Figure 4.57: DataFrame with 10 rows after using the apply function on the Sales
    column'
  id: totrans-421
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.57：在 Sales 列上使用 apply 函数后的 10 行 DataFrame
- en: 'The `apply` method also works with the built-in native Python functions. For
    practice, let''s create another column for storing the length of the name of the
    customer. We can do that using the familiar `len` function:'
  id: totrans-422
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`apply` 方法也适用于内置的 Python 原生函数。为了练习，让我们创建另一个用于存储客户名称长度的列。我们可以使用熟悉的 `len` 函数来完成此操作：'
- en: '[PRE67]'
  id: totrans-423
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'The output is as follows:'
  id: totrans-424
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![](img/C11065_04_58.jpg)'
  id: totrans-425
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图片](img/C11065_04_58.jpg)'
- en: 'Figure 4.58: DataFrame with a new column'
  id: totrans-426
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.58：包含新列的 DataFrame
- en: 'Instead of writing out a separate function, we can even insert lambda expressions
    directly into the apply method for short functions. For example, let''s say we
    are promoting our product and want to show the discounted sales price if the original
    price is *> $200*. We can do this using a `lambda` function and the `apply` method:'
  id: totrans-427
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们甚至可以直接将 lambda 表达式插入到 apply 方法中，而不是编写一个单独的函数。例如，假设我们正在推广我们的产品，并且想要显示原始价格大于
    *> $200* 的折扣销售价格。我们可以使用 lambda 函数和 apply 方法来完成此操作：
- en: '[PRE68]'
  id: totrans-428
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'The output is as follows:'
  id: totrans-429
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![](img/C11065_04_59.jpg)'
  id: totrans-430
  prefs: []
  type: TYPE_IMG
  zh: '![img/C11065_04_59.jpg](img/C11065_04_59.jpg)'
- en: 'Figure 4.59: Lambda function'
  id: totrans-431
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.59：Lambda 函数
- en: Note
  id: totrans-432
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The lambda function contains a conditional, and a discount is applied to those
    records where the original sales price is > $200.
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: Lambda 函数包含一个条件，并且对原始销售价格大于 $200 的记录应用折扣。
- en: 'Activity 6: Working with the Adult Income Dataset (UCI)'
  id: totrans-434
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动六：处理 Adult Income 数据集（UCI）
- en: In this activity, you will work with the Adult Income Dataset from the UCI machine
    learning portal. The Adult Income dataset has been used in many machine learning
    papers that address classification problems. You will read the data from a CSV
    file into a pandas DataFrame and do some practice on the advanced data wrangling
    you learned about in this chapter.
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个活动中，您将使用来自 UCI 机器学习门户的 Adult Income 数据集。Adult Income 数据集已被许多解决分类问题的机器学习论文所使用。您将从
    CSV 文件中读取数据到 pandas DataFrame，并在此章节中学习的高级数据处理上进行一些练习。
- en: The aim of this activity is to practice various advanced pandas DataFrame operations,
    for example, for subsetting, applying user-defined functions, summary statistics,
    visualizations, boolean indexing, group by, and outlier detection on a real-life
    dataset. We have the data downloaded as a CSV file on the disk for your ease.
    However, it is recommended to practice data downloading on your own so that you
    are familiar with the process.
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 本活动的目的是练习各种高级 pandas DataFrame 操作，例如，对于子集选择、应用用户定义的函数、汇总统计、可视化、布尔索引、分组和异常值检测在一个真实数据集上。我们已经在磁盘上下载了
    CSV 文件以供您方便使用。然而，建议您自己练习数据下载，以便您熟悉这个过程。
- en: 'Here is the URL for the dataset: [https://archive.ics.uci.edu/ml/machine-learning-databases/adult/](https://archive.ics.uci.edu/ml/machine-learning-databases/adult/).'
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 这是数据集的 URL：[https://archive.ics.uci.edu/ml/machine-learning-databases/adult/](https://archive.ics.uci.edu/ml/machine-learning-databases/adult/)。
- en: 'Here is the URL for the description of the dataset and the variables: [https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names](https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names).'
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: 这是数据集描述和变量的 URL：[https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names](https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names)。
- en: 'These are the steps that will help you solve this activity:'
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 这些步骤将帮助您解决此活动：
- en: Load the necessary libraries.
  id: totrans-440
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载必要的库。
- en: 'Read the adult income dataset from the following URL: [https://github.com/TrainingByPackt/Data-Wrangling-with-Python/blob/master/Chapter04/Activity06/](https://github.com/TrainingByPackt/Data-Wrangling-with-Python/blob/master/Lesson04/Activity06/).'
  id: totrans-441
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从以下 URL 读取 adult income 数据集：[https://github.com/TrainingByPackt/Data-Wrangling-with-Python/blob/master/Chapter04/Activity06/](https://github.com/TrainingByPackt/Data-Wrangling-with-Python/blob/master/Lesson04/Activity06/)。
- en: Create a script that will read a text file line by line.
  id: totrans-442
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个脚本，该脚本将逐行读取文本文件。
- en: Add a name of `Income` for the response variable to the dataset.
  id: totrans-443
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 `Income` 名称添加到响应变量中。
- en: Find the missing values.
  id: totrans-444
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 找出缺失值。
- en: Create a DataFrame with only age, education, and occupation by using subsetting.
  id: totrans-445
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用子集选择创建只包含年龄、教育和职业的 DataFrame。
- en: Plot a histogram of age with a bin size of 20.
  id: totrans-446
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以 20 为 bin 大小绘制年龄直方图。
- en: Create a function to strip the whitespace characters.
  id: totrans-447
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个函数来删除空白字符。
- en: Use the `apply` method to apply this function to all the columns with string
    values, create a new column, copy the values from this new column to the old column,
    and drop the new column.
  id: totrans-448
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `apply` 方法将此函数应用于所有具有字符串值的列，创建一个新列，将新列的值复制到旧列中，然后删除新列。
- en: Find the number of people who are aged between 30 and 50.
  id: totrans-449
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 找出年龄在 30 到 50 岁之间的人数。
- en: Group the records based on age and education to find how the mean age is distributed.
  id: totrans-450
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据年龄和教育分组记录，以找出平均年龄的分布情况。
- en: Group by occupation and show the summary statistics of age. Find which profession
    has the oldest workers on average and which profession has its largest share of
    the workforce above the 75th percentile.
  id: totrans-451
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按职业分组并显示年龄的汇总统计。找出平均年龄最大的职业，以及在其劳动力中占最大份额的 75 分位数以上的职业。
- en: Use subset and groupby to find outliers.
  id: totrans-452
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用子集和分组方法查找异常值。
- en: Plot the values on a bar chart.
  id: totrans-453
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在柱状图上绘制值。
- en: Merge the data using common keys.
  id: totrans-454
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用公共键合并数据。
- en: Note
  id: totrans-455
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The solution for this activity can be found on page 297.
  id: totrans-456
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该活动的解决方案可以在第 297 页找到。
- en: Summary
  id: totrans-457
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we dived deep into the pandas library to learn advanced data
    wrangling techniques. We started with some advanced subsetting and filtering on
    DataFrames and round this up by learning about boolean indexing and conditional
    selection of a subset of data. We also covered how to set and reset the index
    of a DataFrame, especially while initializing.
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们深入研究了 pandas 库，学习高级数据处理技术。我们从 DataFrame 的高级子集和过滤开始，通过学习布尔索引和数据子集的条件选择来总结这一部分。我们还介绍了如何设置和重置
    DataFrame 的索引，尤其是在初始化时。
- en: Next, we learned about a particular topic that has a deep connection with traditional
    relational database systems – the group by method. Then, we dived deep into an
    important skill for data wrangling - checking for and handling missing data. We
    showed you how pandas help in handling missing data using various imputation techniques.
    We also discussed methods for dropping missing values. Furthermore, methods and
    usage examples of concatenation and merging of DataFrame objects were shown. We
    saw the join method and how it compares to a similar operation in SQL.
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们学习了一个与传统的数据库系统有深刻联系的主题——分组方法。然后，我们深入探讨了数据处理的重要技能——检查和处理缺失数据。我们展示了 pandas
    如何使用各种插补技术来处理缺失数据。我们还讨论了删除缺失值的方法。此外，还展示了 DataFrame 对象的连接和合并的方法及其使用示例。我们看到了连接方法，以及它与
    SQL 中类似操作的比较。
- en: Lastly, miscellaneous useful methods on DataFrames, such as randomized sampling,
    `unique`, `value_count`, `sort_values`, and pivot table functionality were covered.
    We also showed an example of running an arbitrary user-defined function on a DataFrame
    using the `apply` method.
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们介绍了 DataFrame 上的各种有用方法，例如随机抽样、`unique`、`value_count`、`sort_values` 和交叉表功能。我们还展示了使用
    `apply` 方法在 DataFrame 上运行任意用户定义函数的示例。
- en: After learning about the basic and advanced data wrangling techniques with NumPy
    and pandas libraries, the natural question of data acquiring rises. In the next
    chapter, we will show you how to work with a wide variety of data sources, that
    is, you will learn how to read data in tabular format in pandas from different
    sources.
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 在学习了 NumPy 和 pandas 库的基本和高级数据处理技术之后，数据获取的自然问题随之而来。在下一章中，我们将向您展示如何处理各种数据源，也就是说，您将学习如何在
    pandas 中从不同来源读取表格格式的数据。
