["```py\nstringJSONRDD = sc.parallelize((\"\"\"\n  { \"id\": \"123\",\n\"name\": \"Katie\",\n\"age\": 19,\n\"eyeColor\": \"brown\"\n  }\"\"\",\n\"\"\"{\n\"id\": \"234\",\n\"name\": \"Michael\",\n\"age\": 22,\n\"eyeColor\": \"green\"\n  }\"\"\", \n\"\"\"{\n\"id\": \"345\",\n\"name\": \"Simone\",\n\"age\": 23,\n\"eyeColor\": \"blue\"\n  }\"\"\")\n)\n```", "```py\nswimmersJSON = spark.read.json(stringJSONRDD)\n```", "```py\nswimmersJSON.createOrReplaceTempView(\"swimmersJSON\")\n```", "```py\n# DataFrame API\nswimmersJSON.show()\n```", "```py\nspark.sql(\"select * from swimmersJSON\").collect()\n```", "```py\n# Print the schema\nswimmersJSON.printSchema()\n```", "```py\n# Import types\nfrom pyspark.sql.types import *\n\n# Generate comma delimited data\nstringCSVRDD = sc.parallelize([\n(123, 'Katie', 19, 'brown'), \n(234, 'Michael', 22, 'green'), \n(345, 'Simone', 23, 'blue')\n])\n```", "```py\n# Specify schema\nschema = StructType([\nStructField(\"id\", LongType(), True),    \nStructField(\"name\", StringType(), True),\nStructField(\"age\", LongType(), True),\nStructField(\"eyeColor\", StringType(), True)\n])\n```", "```py\n# Apply the schema to the RDD and Create DataFrame\nswimmers = spark.createDataFrame(stringCSVRDD, schema)\n\n# Creates a temporary view using the DataFrame\nswimmers.createOrReplaceTempView(\"swimmers\")\n```", "```py\nswimmers.printSchema()\n```", "```py\nswimmers.count()\n```", "```py\nOut[13]: 3\n```", "```py\n# Get the id, age where age = 22\nswimmers.select(\"id\", \"age\").filter(\"age = 22\").show()\n\n# Another way to write the above query is below\nswimmers.select(swimmers.id, swimmers.age).filter(swimmers.age == 22).show()\n```", "```py\n# Get the name, eyeColor where eyeColor like 'b%'\nswimmers.select(\"name\", \"eyeColor\").filter(\"eyeColor like 'b%'\").show()\n```", "```py\nspark.sql(\"select count(1) from swimmers\").show()\n```", "```py\n# Get the id, age where age = 22 in SQL\nspark.sql(\"select id, age from swimmers where age = 22\").show()\n```", "```py\nspark.sql(\n\"select name, eyeColor from swimmers where eyeColor like 'b%'\").show()\n```", "```py\n# Set File Paths\nflightPerfFilePath = \n\"/databricks-datasets/flights/departuredelays.csv\"\nairportsFilePath = \n\"/databricks-datasets/flights/airport-codes-na.txt\"\n\n# Obtain Airports dataset\nairports = spark.read.csv(airportsFilePath, header='true', inferSchema='true', sep='\\t')\nairports.createOrReplaceTempView(\"airports\")\n\n# Obtain Departure Delays dataset\nflightPerf = spark.read.csv(flightPerfFilePath, header='true')\nflightPerf.createOrReplaceTempView(\"FlightPerformance\")\n\n# Cache the Departure Delays dataset \nflightPerf.cache()\n```", "```py\n# Query Sum of Flight Delays by City and Origin Code \n# (for Washington State)\nspark.sql(\"\"\"\nselect a.City, \nf.origin, \nsum(f.delay) as Delays \nfrom FlightPerformance f \njoin airports a \non a.IATA = f.origin\nwhere a.State = 'WA'\ngroup by a.City, f.origin\norder by sum(f.delay) desc\"\"\"\n).show()\n```", "```py\n%sql\n-- Query Sum of Flight Delays by City and Origin Code (for Washington State)\nselect a.City, f.origin, sum(f.delay) as Delays\n  from FlightPerformance f\n    join airports a\n      on a.IATA = f.origin\n where a.State = 'WA'\n group by a.City, f.origin\n order by sum(f.delay) desc\n```", "```py\n%sql\n-- Query Sum of Flight Delays by State (for the US)\nselect a.State, sum(f.delay) as Delays\n  from FlightPerformance f\n    join airports a\n      on a.IATA = f.origin\n where a.Country = 'USA'\n group by a.State\n```"]