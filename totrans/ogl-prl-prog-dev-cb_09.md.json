["```py\ncmpxchg(a[0], a[1]);\ncmpxchg(a[1], a[2]);\ncmpxchg(a[0], a[1]);\n```", "```py\nvoid merge(int a[], int l, int r) {\n  int i, m = (l+r)/2;\n  if (r == (l+1)) compareXchg(a, l, r);\n  if (r < (l+2)) return;\n\n  unshuffle(a, l, r);\n  merge(a, l, m);\n  merge(a,  m+1, r);\n  shuffle(a, l, r);\n  // In the original algorithm the statement was the following:\n  // for(i = l+1; i < r; i+= 2) compareXchg(a, i, i+1);\n  for(i = l; i < r; i+= 2) compareXchg(a, i, i+1);\n}\n```", "```py\nvoid shuffle(int a[], int l, int r) {\n  int* aux = (int*)malloc(sizeof(int) * r);\n  int i, j, m = (l+r)/2;\n  for(i = l, j = 0; i <= r; i += 2, j++ ) {\n    aux[i] = a[l+j];\n    aux[i+1] = a[m+1+j];\n  }\n  for(i = l; i <= r; i++) a[i] = aux[i];\n}\n\nvoid unshuffle(int a[], int l, int r) {\n  int* aux = (int*)malloc(sizeof(int) * r);\n  int i, j, m = (l+r)/2;\n  for(i = l, j = 0; i <= r; i += 2, j++ ) {\n    aux[l+j] = a[i];\n    aux[m+1+j] = a[i+1];\n  }\n  for(i = l; i <= r; i++) a[i] = aux[i];\n}\nvoid compareXchg(int* arr, int offset1, int offset2) {\n  if (arr[offset1] >= arr[offset2]) {\n    int t = arr[offset1];\n    arr[offset1] = arr[offset2];\n    arr[offset2] = t;\n  }\n}\n```", "```py\nvoid merge_iterative(int a[], int l, int r) {\n  int i, j , k, p, N = r -l+1;\n  for(p = 1; p < N; p += p)\n    for(k = p; k > 0; k /= 2)\n     for(j = k%p; j+k < N; j += (k+k))\n      for(i = 0; i < k; i++)\n        if(j+i+k < N)\n          if((j+i)/(p+p) == (j+i+k)/(p+p))\n            compareXchg(a, l+j+i, l+j+i+k);\n}\n```", "```py\n__kernel\nvoid bitonicSort(__global uint * data,\n const uint stage,\n const uint subStage,\n const uint direction) {\n\n uint sortIncreasing = direction;\n uint threadId = get_global_id(0);\n\n // Determine where to conduct the bitonic split\n // by locating the middle-point of this 1D array\n uint distanceBetweenPairs = 1 << (stage - subStage);\n uint blockWidth   = 2 * distanceBetweenPairs;\n\n // Determine the left and right indexes to data referencing\n uint leftId = (threadId % distanceBetweenPairs) + \n (threadId / distanceBetweenPairs) * blockWidth;\n\n uint rightId = leftId + distanceBetweenPairs;\n\n uint leftElement = data[leftId];\n uint rightElement = data[rightId];\n\n // Threads are divided into blocks of size\n // 2^sameDirectionBlockWidth\n // and its used to build bitonic subsequences s.t the sorting is \n // monotically increasing on the left and decreasing on the right\n uint sameDirectionBlockWidth = 1 << stage;\n\n if((threadId/sameDirectionBlockWidth) % 2 == 1)\n sortIncreasing = 1 - sortIncreasing;\n\n uint greater;\n uint lesser;\n // perform pairwise comparison between two elements and depending \n // whether its to build the bitonic that is monotically increasing\n // and decreasing.\n if(leftElement > rightElement) {\n greater = leftElement;\n lesser  = rightElement;\n } else {\n greater = rightElement;\n lesser  = leftElement;\n }\n\n if(sortIncreasing) {\n input[leftId]  = lesser;\n input[rightId] = greater;\n } else {\n input[leftId]  = greater;\n input[rightId] = lesser;\n }\n}\n\n```", "```py\ngcc -std=c99 -Wall -DUNIX -g -DDEBUG -arch i386 -o BitonicSort -framework OpenCL\n\n```", "```py\nPassed!\nExecution of the Bitonic Sort took X.Xs\n\n```", "```py\n uint distanceBetweenPairs = 1 << (stage - subStage);\n uint blockWidth   = 2 * distanceBetweenPairs;\n\n // Determine the left and right indexes to data referencing\n uint leftId = (threadId % distanceBetweenPairs) + \n (threadId / distanceBetweenPairs) * blockWidth;\n\n uint rightId = leftId + distanceBetweenPairs;\n\n```", "```py\n uint sameDirectionBlockWidth = 1 << stage;\n\n if((threadId/sameDirectionBlockWidth) % 2 == 1)\n sortIncreasing = 1 - sortIncreasing;\n\n```", "```py\nfor(cl_uint stage = 0; stage < stages; ++stage) {\n  clSetKernelArg(kernel, 1, sizeof(cl_uint),(void*)&stage);\n\n  for(cl_uint subStage = 0; subStage < stage +1; subStage++) {\n    clSetKernelArg(kernel, 2, sizeof(cl_uint),(void*)&subStage);\n                cl_event exeEvt;\n                cl_ulong executionStart, executionEnd;\n                error = clEnqueueNDRangeKernel(queue,\n                                               kernel,\n                                               1,\n                                               NULL,\n                                               globalThreads,\n                                               threadsPerGroup,\n                                               0,\n                                               NULL,\n                                               &exeEvt);\n                clWaitForEvents(1, &exeEvt);\n```", "```py\ndevice_A_in = clCreateBuffer(context,\n                             CL_MEM_READ_WRITE|CL_MEM_COPY_HOST_PTR,\n                             LENGTH * sizeof(cl_int),\n                             host_A_in,\n                             &error);\n```", "```py\nuint leftElement = data[leftId];\nuint rightElement = data[rightId];\n```", "```py\n__kernel\nvoid bitonicSort_sharedmem(__global uint * data,\n                           const uint stage,\n                           const uint subStage,\n                           const uint direction,\n                           __local uint* sharedMem) {\n    // more code omitted here\n    // Copy data to shared memory on device\n    if (threadId == 0) {\n        sharedMem[threadId] = data[leftId];\n        sharedMem[threadId+1] = data[rightId];\n    } else {\n        sharedMem[threadId+1] = data[leftId];\n        sharedMem[threadId+2] = data[rightId];\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n\n    // more code omitted\n    uint greater;\n    uint lesser;\n\n    if (threadId == 0) {\n        if(sharedMem[threadId] > sharedMem[threadId+1]) {\n            greater = sharedMem[threadId];\n            lesser  = sharedMem[threadId+1];\n        } else {\n            greater = sharedMem[threadId+1];\n            lesser  = sharedMem[threadId];\n        }\n    } else {\n        if(sharedMem[threadId+1] > sharedMem[threadId+2]) {\n            greater = sharedMem[threadId+1];\n            lesser  = sharedMem[threadId+2];\n        } else {\n            greater = sharedMem[threadId+2];\n            lesser  = sharedMem[threadId+1];\n        }\n    }\n```", "```py\n#ifdef USE_SHARED_MEM\nclSetKernelArg(kernel, 4, (GROUP_SIZE << 1) *sizeof(cl_uint),NULL);\n#endif\n```", "```py\ngcc -DUSE_SHARED_MEM -Wall -std=c99 -lOpenCL ./BitonicSort.c -o BitonicSort_GPU\n\n```", "```py\ncmake –DUSE_SHARED_MEM=1 –DDEBUG .\n\n```", "```py\nmake clean;make\n\n```", "```py\n    // Each thread will write the data elements to its own\n    // partition of the shared storage without conflicts.\n    const uint stride = 4;\n    if(sortIncreasing) {\n        aux[threadId*stride] = leftId;\n        aux[threadId*stride+1] = lesser;\n        aux[threadId*stride+2] = rightId;\n        aux[threadId*stride+3] = greater;\n    } else {\n        aux[threadId*stride] = leftId;\n        aux[threadId*stride+1] = greater;\n        aux[threadId*stride+2] = rightId;\n        aux[threadId*stride+3] = lesser;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n\n    if(threadId == 0) {\n        for(int i = 0; i < GROUP_SIZE * stride; ++i) {\n           data[aux[i*stride]] = aux[i*stride+1];\n           data[aux[i*stride+2]] = aux[i*stride+3];\n        }\n    }\n```"]