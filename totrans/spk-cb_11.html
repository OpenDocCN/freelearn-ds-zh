<html><head></head><body><div><div><div><div><h1 class="title"><a id="ch11"/>Chapter 11. Graph Processing Using GraphX</h1></div></div></div><p>This chapter will cover how we can do graph processing using GraphX, Spark's graph processing library.</p><p>The chapter is divided into the following recipes:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Fundamental operations on graphs</li><li class="listitem" style="list-style-type: disc">Using PageRank</li><li class="listitem" style="list-style-type: disc">Finding connected components</li><li class="listitem" style="list-style-type: disc">Performing neighborhood aggregation</li></ul></div><div><div><div><div><h1 class="title"><a id="ch11lvl1sec70"/>Introduction</h1></div></div></div><p>Graph analysis is much more commonplace in our life than we think. To take the most common example, when we ask a GPS to find the shortest route to a destination, it uses a graph-processing algorithm.</p><p>Let's start by understanding graphs. A graph is a representation of a set of vertices where some pairs of vertices are connected by edges. When these edges move from one direction to another, it's called a <strong>directed graph</strong> or <a id="id584" class="indexterm"/>
<strong>digraph</strong>.</p><p>GraphX is the Spark API for graph processing. It provides a wrapper around an RDD called <strong>resilient distributed property graph</strong>. The property graph is a directed multigraph with properties <a id="id585" class="indexterm"/>attached to each vertex and edge.</p><p>There are two types<a id="id586" class="indexterm"/> of graphs—directed graphs (digraphs) and <a id="id587" class="indexterm"/>regular graphs. Directed graphs have edges that run in one direction, for example, from vertex A to vertex B. Twitter follower is a good example of a digraph. If John is David's Twitter follower, it does not mean that David is John's follower. On the other hand, Facebook is a good example of a regular graph. If John is David's Facebook friend, David is also John's Facebook friend.</p><p>A multigraph is<a id="id588" class="indexterm"/> a graph which is allowed to have multiple edges (also called <strong>parallel edges</strong>). Since <a id="id589" class="indexterm"/>every edge in GraphX has properties, each edge has its own identity.</p><p>Traditionally, for <a id="id590" class="indexterm"/>distributed graph processing, there<a id="id591" class="indexterm"/> have been two types of systems:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Data parallel</li><li class="listitem" style="list-style-type: disc">Graph parallel</li></ul></div><p>GraphX aims to combine the two together in one system. GraphX API enables users to view the data both as graphs and as collections (RDDs) without data movement.</p></div></div>
<div><div><div><div><h1 class="title"><a id="ch11lvl1sec71"/>Fundamental operations on graphs</h1></div></div></div><p>In this recipe, we <a id="id592" class="indexterm"/>will learn how to create graphs and do basic operations on them.</p><div><div><div><div><h2 class="title"><a id="ch11lvl2sec105"/>Getting ready</h2></div></div></div><p>As a starting example, we will have three vertices, each representing the city center of three cities in California—Santa Clara, Fremont, and San Francisco. The following is the distance between these cities:</p><div><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th style="text-align: left" valign="bottom">
<p>Source</p>
</th><th style="text-align: left" valign="bottom">
<p>Destination</p>
</th><th style="text-align: left" valign="bottom">
<p>Distance (miles)</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<p>Santa Clara, CA</p>
</td><td style="text-align: left" valign="top">
<p>Fremont, CA</p>
</td><td style="text-align: left" valign="top">
<p>20</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Fremont, CA</p>
</td><td style="text-align: left" valign="top">
<p>San Francisco, CA</p>
</td><td style="text-align: left" valign="top">
<p>44</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>San Francisco, CA</p>
</td><td style="text-align: left" valign="top">
<p>Santa Clara, CA</p>
</td><td style="text-align: left" valign="top">
<p>53</p>
</td></tr></tbody></table></div></div><div><div><div><div><h2 class="title"><a id="ch11lvl2sec106"/>How to do it…</h2></div></div></div><div><ol class="orderedlist arabic"><li class="listitem">Import the GraphX-related classes:<div><pre class="programlisting">
<strong>scala&gt; import org.apache.spark.graphx._</strong>
<strong>scala&gt; import org.apache.spark.rdd.RDD</strong>
</pre></div></li><li class="listitem">Load the vertex data in an array:<div><pre class="programlisting">
<strong>scala&gt; val vertices = Array((1L, ("Santa Clara","CA")),(2L, ("Fremont","CA")),(3L, ("San Francisco","CA")))</strong>
</pre></div></li><li class="listitem">Load the array of vertices into the RDD of vertices:<div><pre class="programlisting">
<strong>scala&gt; val vrdd = sc.parallelize(vertices)</strong>
</pre></div></li><li class="listitem">Load the edge data in an array:<div><pre class="programlisting">
<strong>scala&gt; val edges = Array(Edge(1L,2L,20),Edge(2L,3L,44),Edge(3L,1L,53))</strong>
</pre></div></li><li class="listitem">Load the<a id="id593" class="indexterm"/> data into the RDD of edges:<div><pre class="programlisting">
<strong>scala&gt; val erdd = sc.parallelize(edges)</strong>
</pre></div></li><li class="listitem">Create the graph:<div><pre class="programlisting">
<strong>scala&gt; val graph = Graph(vrdd,erdd)</strong>
</pre></div></li><li class="listitem">Print all the vertices of the graph:<div><pre class="programlisting">
<strong>scala&gt; graph.vertices.collect.foreach(println)</strong>
</pre></div></li><li class="listitem">Print all the edges of the graph:<div><pre class="programlisting">
<strong>scala&gt; graph.edges.collect.foreach(println)</strong>
</pre></div></li><li class="listitem">Print the edge triplets; a triplet is created by adding source and destination attributes to an edge:<div><pre class="programlisting">
<strong>scala&gt; graph.triplets.collect.foreach(println)</strong>
</pre></div></li><li class="listitem">In-degree of a graph is the number of inward-directed edges it has. Print the in-degree of each vertex (as <code class="literal">VertexRDD[Int]</code>):<div><pre class="programlisting">
<strong>scala&gt; graph.inDegrees</strong>
</pre></div></li></ol></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch11lvl1sec72"/>Using PageRank</h1></div></div></div><p>PageRank measures <a id="id594" class="indexterm"/>the importance of each vertex in a graph. PageRank was started <a id="id595" class="indexterm"/>by Google's founders, who used the theory that the most important pages on the Internet are the pages with the most links leading to them. PageRank also looks at the importance of a page leading to the target page. So, if a given web page has incoming links from higher rank pages, it will be ranked higher.</p><div><div><div><div><h2 class="title"><a id="ch11lvl2sec107"/>Getting ready</h2></div></div></div><p>We are going to use Wikipedia page link data to calculate page rank. Wikipedia publishes its data <a id="id596" class="indexterm"/>in the form of a database dump. We are going to use link data from <a class="ulink" href="http://haselgrove.id.au/wikipedia.htm">http://haselgrove.id.au/wikipedia.htm</a>, which has the data in two files:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">links-simple-sorted.txt</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">titles-sorted.txt</code></li></ul></div><p>I have put both of them on <a id="id597" class="indexterm"/>Amazon S3 at <code class="literal">s3n://com.infoobjects.wiki/links</code> and <code class="literal">s3n://com.infoobjects.wiki/nodes</code>. Since the data size is larger, it is recommended that you run it on either Amazon EC2 or your local cluster. Sandbox may be very slow.</p><p>You can<a id="id598" class="indexterm"/> load the files to <code class="literal">hdfs</code> using the following commands:</p><div><pre class="programlisting">
<strong>$ hdfs dfs -mkdir wiki</strong>
<strong>$ hdfs dfs -put links-simple-sorted.txt wiki/links.txt</strong>
<strong>$ hdfs dfs -put titles-sorted.txt wiki/nodes.txt</strong>
</pre></div></div><div><div><div><div><h2 class="title"><a id="ch11lvl2sec108"/>How to do it…</h2></div></div></div><div><ol class="orderedlist arabic"><li class="listitem">Import the GraphX related classes:<div><pre class="programlisting">
<strong>scala&gt; import org.apache.spark.graphx._</strong>
</pre></div></li><li class="listitem">Load the edges from <code class="literal">hdfs</code> with 20 partitions:<div><pre class="programlisting">
<strong>scala&gt; val edgesFile = sc.textFile("wiki/links.txt",20)</strong>
</pre></div><p>Or, load the edges from Amazon S3:</p><div><pre class="programlisting">
<strong>scala&gt; val edgesFile = sc.textFile("s3n:// com.infoobjects.wiki/links",20)</strong>
</pre></div><div><div><h3 class="title"><a id="note22"/>Note</h3><p>The <code class="literal">links</code> file has links in the "sourcelink: link1 link2 …" format.</p></div></div></li><li class="listitem">Flatten and convert it into an RDD of "link1,link2" format and then convert it into an RDD of <code class="literal">Edge</code> objects:<div><pre class="programlisting">
<strong>scala&gt; val edges = edgesFile.flatMap { line =&gt;</strong>
<strong>   val links = line.split("\\W+")</strong>
<strong>   val from = links(0)</strong>
<strong>     val to = links.tail</strong>
<strong>   for ( link &lt;- to) yield (from,link)</strong>
<strong>    }.map( e =&gt; Edge(e._1.toLong,e._2.toLong,1))</strong>
</pre></div></li><li class="listitem">Load the vertices from <code class="literal">hdfs</code> with 20 partitions:<div><pre class="programlisting">
<strong>scala&gt; val verticesFile = sc.textFile("wiki/nodes.txt",20)</strong>
</pre></div></li><li class="listitem">Or, load the edges from Amazon S3:<div><pre class="programlisting">
<strong>scala&gt; val verticesFile = sc.textFile("s3n:// com.infoobjects.wiki/nodes",20)</strong>
</pre></div></li><li class="listitem">Provide an index to the vertices and then swap it to make it in the (index, title) format:<div><pre class="programlisting">
<strong>scala&gt; val vertices = verticesFile.zipWithIndex.map(_.swap)</strong>
</pre></div></li><li class="listitem">Create the <code class="literal">graph</code> object:<div><pre class="programlisting">
<strong>scala&gt; val graph = Graph(vertices,edges)</strong>
</pre></div></li><li class="listitem">Run PageRank and get the vertices:<div><pre class="programlisting">
<strong>scala&gt; val ranks = graph.pageRank(0.001).vertices</strong>
</pre></div></li><li class="listitem">As ranks is in the (vertex ID, pagerank) format, swap it to make it in the (pagerank, vertex ID) format:<div><pre class="programlisting">
<strong>scala&gt; val swappedRanks = ranks.map(_.swap)</strong>
</pre></div></li><li class="listitem">Sort to get the highest ranked pages first:<div><pre class="programlisting">
<strong>scala&gt; val sortedRanks = swappedRanks.sortByKey(false)</strong>
</pre></div></li><li class="listitem">Get the<a id="id599" class="indexterm"/> highest ranked page:<div><pre class="programlisting">
<strong>scala&gt; val highest = sortedRanks.first</strong>
</pre></div></li><li class="listitem">The preceding command gives the vertex id, which you still have to look up to see the actual title with rank. Let's do a join:<div><pre class="programlisting">
<strong>scala&gt; val join = sortedRanks.join(vertices)</strong>
</pre></div></li><li class="listitem">Sort the joined RDD again after converting from the (vertex ID, (page rank, title)) format to the (page rank, (vertex ID, title)) format:<div><pre class="programlisting">
<strong>scala&gt; val final = join.map ( v =&gt; (v._2._1, (v._1,v._2._2))).sortByKey(false)</strong>
</pre></div></li><li class="listitem">Print the top five ranked pages<div><pre class="programlisting">
<strong>scala&gt; final.take(5).collect.foreach(println)</strong>
</pre></div></li></ol></div><p>Here's what the output should be:</p><div><pre class="programlisting">
<strong>(12406.054646736622,(5302153,United_States'_Country_Reports_on_Human_Rights_Practices))</strong>
<strong>(7925.094429748747,(84707,2007,_Canada_budget)) (7635.6564216408515,(88822,2008,_Madrid_plane_crash)) (7041.479913258444,(1921890,Geographic_coordinates)) (5675.169862343964,(5300058,United_Kingdom's))</strong>
</pre></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch11lvl1sec73"/>Finding connected components</h1></div></div></div><p>A connected component is a subgraph (a graph whose vertices are a subset of the vertex set of the <a id="id600" class="indexterm"/>original graph and whose edges are a subset of the edge set of the original graph) in which any two vertices are connected to each other by an<a id="id601" class="indexterm"/> edge or a series of edges.</p><p>An easy way to understand it would be by taking a look at the road network graph of Hawaii. This state has numerous islands, which are not connected by roads. Within each island, most roads will be connected to each other. The goal of finding the connected components is to find these clusters.</p><p>The connected components algorithm labels each connected component of the graph with the ID of its lowest-numbered vertex.</p><div><div><div><div><h2 class="title"><a id="ch11lvl2sec109"/>Getting ready</h2></div></div></div><p>We will build<a id="id602" class="indexterm"/> a small graph here for the clusters we know and use connected components to segregate them. Let's look at the following data:</p><div><img src="img/3056_11_01.jpg" alt="Getting ready"/></div><div><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th style="text-align: left" valign="bottom">
<p>Follower</p>
</th><th style="text-align: left" valign="bottom">
<p>Followee</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<p>John</p>
</td><td style="text-align: left" valign="top">
<p>Pat</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Pat</p>
</td><td style="text-align: left" valign="top">
<p>Dave</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Gary</p>
</td><td style="text-align: left" valign="top">
<p>Chris</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Chris</p>
</td><td style="text-align: left" valign="top">
<p>Bill</p>
</td></tr></tbody></table></div><p>The preceding data is a simple one with six vertices and two clusters. Let's put this data in the form of two files: <code class="literal">nodes.csv</code> and <code class="literal">edges.csv</code>.</p><p>The following is the content of <code class="literal">nodes.csv</code>:</p><div><pre class="programlisting">1,John
2,Pat
3,Dave
4,Gary
5,Chris
6,Bill</pre></div><p>The following is the content of <code class="literal">edges.csv</code>:</p><div><pre class="programlisting">1,2,follows
2,3,follows
4,5,follows
5,6,follows</pre></div><p>We should expect a connected component algorithm to identify two clusters, the first one identified by (1,John) and the second by (4,Gary).</p><p>You can load the files to <code class="literal">hdfs</code> using the following commands:</p><div><pre class="programlisting">
<strong>$ hdfs dfs -mkdir data/cc</strong>
<strong>$ hdfs dfs -put nodes.csv data/cc/nodes.csv</strong>
<strong>$ hdfs dfs -put edges.csv data/cc/edges.csv</strong>
</pre></div></div><div><div><div><div><h2 class="title"><a id="ch11lvl2sec110"/>How to do it…</h2></div></div></div><div><ol class="orderedlist arabic"><li class="listitem">Load the <a id="id603" class="indexterm"/>Spark shell:<div><pre class="programlisting">
<strong>$ spark-shell</strong>
</pre></div></li><li class="listitem">Import the GraphX-related classes:<div><pre class="programlisting">
<strong>scala&gt; import org.apache.spark.graphx._</strong>
</pre></div></li><li class="listitem">Load the edges from <code class="literal">hdfs</code>:<div><pre class="programlisting">
<strong>scala&gt; val edgesFile = sc.textFile("hdfs://localhost:9000/user/hduser/data/cc/edges.csv")</strong>
</pre></div></li><li class="listitem">Convert the <code class="literal">edgesFile</code> RDD into the RDD of edges:<div><pre class="programlisting">
<strong>scala&gt; val edges = edgesFile.map(_.split(",")).map(e =&gt; Edge(e(0).toLong,e(1).toLong,e(2)))</strong>
</pre></div></li><li class="listitem">Load the vertices from <code class="literal">hdfs</code>:<div><pre class="programlisting">
<strong>scala&gt; val verticesFile = sc.textFile("hdfs://localhost:9000/user/hduser/data/cc/nodes.csv")</strong>
</pre></div></li><li class="listitem">Map the vertices:<div><pre class="programlisting">
<strong>scala&gt; val vertices = verticesFile.map(_.split(",")).map( e =&gt; (e(0).toLong,e(1)))</strong>
</pre></div></li><li class="listitem">Create the <code class="literal">graph</code> object:<div><pre class="programlisting">
<strong>scala&gt; val graph = Graph(vertices,edges)</strong>
</pre></div></li><li class="listitem">Calculate the connected components:<div><pre class="programlisting">
<strong>scala&gt; val cc = graph.connectedComponents</strong>
</pre></div></li><li class="listitem">Find the vertices for the connected components (which is a subgraph):<div><pre class="programlisting">
<strong>scala&gt; val ccVertices = cc.vertices</strong>
</pre></div></li><li class="listitem">Print the <code class="literal">ccVertices</code>:<div><pre class="programlisting">
<strong>scala&gt; ccVertices.collect.foreach(println)</strong>
</pre></div></li></ol></div><p>As you can see in the output, vertices 1,2,3 are pointing to 1, while 4,5,6 are pointing to 4. Both of these are the lowest-indexed vertices in their respective clusters.</p></div></div>
<div><div><div><div><h1 class="title"><a id="ch11lvl1sec74"/>Performing neighborhood aggregation</h1></div></div></div><p>GraphX does most of the computation by isolating each vertex and its neighbors. It makes it easier to process the massive graph data on distributed systems. This makes the neighborhood operations very important. GraphX has a mechanism to do it at each neighborhood level<a id="id604" class="indexterm"/> in the form of the <code class="literal">aggregateMessages</code> method. It does it in two steps:</p><div><ol class="orderedlist arabic"><li class="listitem">In the first step (first function of the method), messages are send to the destination vertex or source vertex (similar to the Map function in MapReduce).</li><li class="listitem">In the second step (second function of the method), aggregation is done on these messages (similar to the Reduce function in MapReduce).</li></ol></div><div><div><div><div><h2 class="title"><a id="ch11lvl2sec111"/>Getting ready</h2></div></div></div><p>Let's build a small dataset of the followers:</p><div><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th style="text-align: left" valign="bottom">
<p>Follower</p>
</th><th style="text-align: left" valign="bottom">
<p>Followee</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<p>John</p>
</td><td style="text-align: left" valign="top">
<p>Barack</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Pat</p>
</td><td style="text-align: left" valign="top">
<p>Barack</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Gary</p>
</td><td style="text-align: left" valign="top">
<p>Barack</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Chris</p>
</td><td style="text-align: left" valign="top">
<p>Mitt</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>Rob</p>
</td><td style="text-align: left" valign="top">
<p>Mitt</p>
</td></tr></tbody></table></div><p>Our goal is to find out how many followers each node has. Let's load this data in the form of two files: <code class="literal">nodes.csv</code> and <code class="literal">edges.csv</code>.</p><p>The following is the content of <code class="literal">nodes.csv</code>:</p><div><pre class="programlisting">1,Barack
2,John
3,Pat
4,Gary
5,Mitt
6,Chris
7,Rob</pre></div><p>The following is the content of <code class="literal">edges.csv</code>:</p><div><pre class="programlisting">2,1,follows
3,1,follows
4,1,follows
6,5,follows
7,5,follows</pre></div><p>You can load the files to <code class="literal">hdfs</code> using the following commands:</p><div><pre class="programlisting">
<strong>$ hdfs dfs -mkdir data/na</strong>
<strong>$ hdfs dfs -put nodes.csv data/na/nodes.csv</strong>
<strong>$ hdfs dfs -put edges.csv data/na/edges.csv</strong>
</pre></div></div><div><div><div><div><h2 class="title"><a id="ch11lvl2sec112"/>How to do it…</h2></div></div></div><div><ol class="orderedlist arabic"><li class="listitem">Load the <a id="id605" class="indexterm"/>Spark shell:<div><pre class="programlisting">
<strong>$ spark-shell</strong>
</pre></div></li><li class="listitem">Import the GraphX related classes:<div><pre class="programlisting">
<strong>scala&gt; import org.apache.spark.graphx._</strong>
</pre></div></li><li class="listitem">Load the edges from <code class="literal">hdfs</code>:<div><pre class="programlisting">
<strong>scala&gt; val edgesFile = sc.textFile("hdfs://localhost:9000/user/hduser/data/na/edges.csv")</strong>
</pre></div></li><li class="listitem">Convert the edges into the RDD of edges:<div><pre class="programlisting">
<strong>scala&gt; val edges = edgesFile.map(_.split(",")).map(e =&gt; Edge(e(0).toLong,e(1).toLong,e(2)))</strong>
</pre></div></li><li class="listitem">Load the vertices from <code class="literal">hdfs</code>:<div><pre class="programlisting">
<strong>scala&gt; val verticesFile = sc.textFile("hdfs://localhost:9000/user/hduser/data/cc/nodes.csv")</strong>
</pre></div></li><li class="listitem">Map the vertices:<div><pre class="programlisting">
<strong>scala&gt; val vertices = verticesFile.map(_.split(",")).map( e =&gt; (e(0).toLong,e(1)))</strong>
</pre></div></li><li class="listitem">Create the <code class="literal">graph</code> object:<div><pre class="programlisting">
<strong>scala&gt; val graph = Graph(vertices,edges)</strong>
</pre></div></li><li class="listitem">Do the neighborhood aggregation by sending messages to the followees with the number of followers from each follower, that is, 1 and then adding the number of followers:<div><pre class="programlisting">
<strong>scala&gt; val followerCount = graph.aggregateMessages[(Int)]( t =&gt; t.sendToDst(1), (a, b) =&gt; (a+b))</strong>
</pre></div></li><li class="listitem">Print <code class="literal">followerCount</code> in the form of (followee, number of followers):<div><pre class="programlisting">
<strong>scala&gt; followerCount.collect.foreach(println)</strong>
</pre></div></li></ol></div><p>You should get an output similar to the following:</p><div><pre class="programlisting">
<strong>(1,3)</strong>
<strong>(5,2)</strong>
</pre></div></div></div></body></html>