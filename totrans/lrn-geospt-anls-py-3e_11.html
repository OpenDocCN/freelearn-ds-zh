<html><head></head><body><div><h1 class="header-title">Advanced Geospatial Python Modeling</h1>
                
            
            
                
<p>In this chapter, we'll build on the data processing concepts that we've learned in order to create some full-scale information products. The previously introduced data processing methods rarely provide answers to questions by themselves. You combine these data processing methods to build a geospatial model from multiple processed datasets. A geospatial model is a simplified representation of some aspect of the real world, which helps us answer one or more questions about a project or problem. In this chapter, we will introduce some important geospatial algorithms that are commonly used in agriculture, emergency management, logistics, and other industries.</p>
<p class="mce-root">The products that we will create are as follows:</p>
<ul>
<li>A crop health map</li>
<li>A flood inundation model</li>
<li>A colorized hillshade</li>
<li>A terrain routing map</li>
<li>A street routing map</li>
<li>A shapefile with links to geolocated photos</li>
</ul>
<p>While these products are task-specific, the algorithms that are used to create them are widely applied in geospatial analysis. We will be covering the following topics in this chapter:</p>
<ul>
<li>Creating a normalized difference vegetative index (NVDI)</li>
<li>Creating a flood inundation model</li>
<li>Creating a color hillshade</li>
<li>Performing least cost path analysis</li>
<li>Converting the route to a shapefile</li>
<li>Routing along streets</li>
<li>Geolocating photos</li>
<li>Calculating satellite image cloud cover</li>
</ul>
<p>The examples in this chapter are longer and more involved than in the previous chapters. For that reason, there are far more code comments to make the programs easier to follow. We will also use more functions in these examples. In previous chapters, functions were mostly avoided for clarity, but these examples are sufficiently complex that certain functions make the code easier to read. These examples are actual processes that you would use on the job as a geospatial analyst.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Technical requirements</h1>
                
            
            
                
<p>For this chapter, the following requirements need to be satisfied:</p>
<ul>
<li><strong>Version</strong>: Python 3.6 or higher</li>
<li><strong>RAM</strong>: Minimum 6 GB (Windows), 8 GB (macOS); recommended 8 GB</li>
<li><strong>Storage</strong>: Minimum 7,200 RPM SATA with 20 GB of available space, recommended SSD with 40 GB of available space.</li>
<li class="mce-root"><strong>Processor</strong>: Minimum Intel Core i3 2.5 GHz, recommended Intel Core i5.</li>
</ul>


            

            
        
    </div>



  
<div><h1 class="header-title">Creating a normalized difference vegetative index</h1>
                
            
            
                
<p class="mce-root">Our first example will be an <strong>normalized difference vegetative index</strong> (<strong>NVDI</strong>). NDVIs are used to show the relative health of plants in an area of interest. An NDVI algorithm uses satellite or aerial imagery to show relative health by highlighting the chlorophyll density in plants. NDVIs use only the red and near-infrared bands. The formula of NDVI is as follows:</p>
<pre class="mce-root">NDVI = (Infrared – Red) / (Infrared + Red)</pre>
<p class="mce-root">The goal of this analysis is to produce, to begin with, a multispectral image containing infrared and red bands, and end up with a pseudo color image using seven classes, which color the healthier plants darker green, less-healthy plants lighter green, and bare soil brown.</p>
<p class="mce-root">Because the health index is relative, it is important to localize the area of interest. You could perform a relative index for the entire globe but vast areas, such as the Sahara desert on the low-vegetation extreme and densely forested areas, such as the Amazon jungle, skew the results for vegetation in the middle range. However, that being said, climate scientists routinely create global NDVIs to study worldwide trends. The more common application, though, is for managed areas, such as a forest or a farm field, as in this example.</p>
<p class="mce-root">We will begin with an analysis of a single farm field in the Mississippi Delta. To do so, we'll start with a multispectral image of a fairly large area and use a shapefile in order to isolate a single field. The image in the following screenshot is our broad area, with the field of interest highlighted in yellow:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/7918c9ce-706d-4b4f-a71e-ba3e85c2e0cd.png" style="width:32.08em;height:18.33em;" width="623" height="358"/></p>
<p class="mce-root">You can download this image and the shapefile for the farm field as a ZIP file from <a href="http://git.io/v3fS9">http://git.io/v3fS9</a>.</p>
<p class="mce-root">For this example, we'll use GDAL, OGR, <kbd>gdal_array</kbd>/<kbd>numpy</kbd>, and the <strong>Python Imaging Library</strong> (<strong>PIL</strong>) to clip and process the data. In the other examples in this chapter, we'll just use simple ASCII Grids and NumPy. As we'll be using ASCII elevation grids, GDAL isn't required. In all examples, the scripts use the following convention:</p>
<ul>
<li class="mce-root">Import libraries.</li>
<li class="mce-root">Define functions.</li>
<li class="mce-root">Define global variables, such as filenames.</li>
<li class="mce-root">Execute the analysis.</li>
<li class="mce-root">Save the output.</li>
</ul>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root">Our approach to the crop health example is split into two scripts. The first script creates the index image, which is a grayscale image. The second script classifies the index and outputs a colored image. In this first script, we'll execute the following steps to create the index image:</p>
<ol>
<li>Read the infrared band.</li>
<li>Read the field boundary shapefile.</li>
<li>Rasterize the shapefile to an image.</li>
<li>Convert the shapefile image to a NumPy array.</li>
<li>Use the NumPy array to clip the red band to the field.</li>
<li>Do the same for the infrared band.</li>
<li>Use the band arrays to execute the NDVI algorithm in NumPy.</li>
<li>Save the resulting indexing algorithm to a GeoTIFF file using <kbd>gdal_array</kbd>.</li>
</ol>
<p class="mce-root">We will discuss this script in sections to make it easier to follow. The code comments will also tell you what is going on at each step of the way.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Setting up the framework</h1>
                
            
            
                
<p class="mce-root">Setting up the framework will help us to import the modules that we need and set up the functions that we'll use for steps 1 to 5 of the preceding instructions. The <kbd>imageToArray()</kbd> function converts a PIL image to a NumPy array and is dependent on the <kbd>gdal_array</kbd> and PIL modules. The <kbd>world2Pixel()</kbd> function converts geospatial coordinates to the pixel coordinates of our target image. This function uses the georeferencing information that is presented by the <kbd>gdal</kbd> module. The <kbd>copy_geo()</kbd> function copies the georeferencing information from our source image to our target array but accounts for the offset that is created when we clip the image. These functions are fairly generic and can serve a role in a variety of different remote sensing processes beyond this example:</p>
<ol>
<li>First, we import our libraries:</li>
</ol>
<pre style="padding-left: 60px">import gdal<br/>from osgeo import gdal<br/>from osgeo import gdal_array<br/>from osgeo import ogr<br/>try:<br/> import Image<br/> import ImageDraw<br/>except ImportError:<br/> from PIL import Image, ImageDraw</pre>
<ol start="2">
<li>Then, we need a function to convert an image to a <kbd>numpy</kbd> array:</li>
</ol>
<pre style="padding-left: 60px">def imageToArray(i):<br/>    """<br/>    Converts a Python Imaging Library<br/>    array to a gdal_array image.<br/>    """<br/>    a = gdal_array.numpy.fromstring(i.tobytes(), 'b')<br/>    a.shape = i.im.size[1], i.im.size[0]<br/>    return a</pre>
<ol start="3">
<li>Now, we'll set up a function to convert the coordinates to image pixels:</li>
</ol>
<pre style="padding-left: 60px">def world2Pixel(geoMatrix, x, y):<br/> """<br/> Uses a gdal geomatrix (gdal.GetGeoTransform())<br/> to calculate the pixel location of a<br/> geospatial coordinate<br/> """<br/> ulX = geoMatrix[0]<br/> ulY = geoMatrix[3]<br/> xDist = geoMatrix[1]<br/> yDist = geoMatrix[5]<br/> rtnX = geoMatrix[2]<br/> rtnY = geoMatrix[4]<br/> pixel = int((x - ulX) / xDist)<br/> line = int((ulY - y) / abs(yDist))<br/> return (pixel, line)</pre>
<ol start="4">
<li>Finally, we'll create a function to copy geographic metadata from an image:</li>
</ol>
<pre style="padding-left: 60px">def copy_geo(array, prototype=None, xoffset=0, yoffset=0):<br/> """Copy geotransfrom from prototype dataset to array but account<br/> for x, y offset of clipped array."""<br/> ds = gdal_array.OpenArray(array)<br/> prototype = gdal.Open(prototype)<br/> gdal_array.CopyDatasetInfo(prototype, ds,<br/> xoff=xoffset, yoff=yoffset)<br/> return ds</pre>
<p>The next step is to load the data, which we'll be checking in the next section.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            

            
        
    </div>



  
<div><h1 class="header-title">Loading the data</h1>
                
            
            
                
<p class="mce-root">In this section, we load the source image of a farm field using <kbd>gdal_array</kbd>, which takes it straight into a NumPy array. We also define the name of our output image, which will be <kbd>ndvi.tif</kbd>. One interesting piece of this section is that we load the source image a second time using the <kbd>gdal</kbd> module, as opposed to <kbd>gdal_array</kbd>.</p>
<p class="mce-root">This second call is to capture the georeferencing data for the image that is available through <kbd>gdal</kbd>, and not <kbd>gdal_array</kbd>. Fortunately, <kbd>gdal</kbd> only loads raster data on demand, so this approach avoids loading the complete dataset into the memory twice. Once we have the data as a multidimensional NumPy array, we split out the red and infrared bands, as they will both be used in the NDVI equation:</p>
<pre># Multispectral image used<br/># to create the NDVI. Must<br/># have red and infrared<br/># bands<br/>source = "farm.tif"<br/><br/># Output geotiff file name<br/>target = "ndvi.tif"<br/><br/># Load the source data as a gdal_array array<br/>srcArray = gdal_array.LoadFile(source)<br/><br/># Also load as a gdal image to<br/># get geotransform info<br/>srcImage = gdal.Open(source)<br/>geoTrans = srcImage.GetGeoTransform()<br/><br/># Red and infrared (or near infrared) bands<br/>r = srcArray[1]<br/>ir = srcArray[2]</pre>
<p>Now that we have our data loaded, we can turn our shapefile into a raster.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Rasterizing the shapefile</h1>
                
            
            
                
<p class="mce-root">This section begins the process of clipping. However, the first step is to rasterize the shapefile that outlines the boundary of the specific area that we are going to analyze. That area is within the larger <kbd>field.tif</kbd> satellite image. In other words, we convert it from vector data to raster data. But we also want to fill in the polygon when we convert it so that it can be used as an image mask. The pixels in the mask will be correlated to the pixels in the red and infrared arrays.</p>
<p class="mce-root">Any pixels outside the mask will be turned to <kbd>NODATA</kbd> pixels so they are not processed as part of the NDVI. To make this correlation, we'll need the solid polygon to be a NumPy array, just like the raster bands. This approach will make sure our NDVI calculation will be limited to the farm field.</p>
<p class="mce-root">The easiest way to convert the shapefile polygon into a filled polygon as a NumPy array is to plot it as a polygon in a PIL image, fill that polygon in, and then convert it to a NumPy array using existing methods, in both PIL and NumPy, which allow that conversion.</p>
<p class="mce-root">In this example, we use the <kbd>ogr</kbd> module to read the shapefile, because we already have GDAL available. But, we could have also used PyShp to read the shapefile just as easily. If our farm field image was available as an ASCII Grid, we could have avoided using the <kbd>gdal</kbd>, <kbd>gdal_array</kbd>, and <kbd>ogr</kbd> modules altogether:</p>
<ol>
<li>First, we open our shapefile and select the one and only layer:</li>
</ol>
<pre style="padding-left: 60px"># Clip a field out of the bands using a<br/># field boundary shapefile<br/><br/># Create an OGR layer from a Field boundary shapefile<br/>field = ogr.Open("field.shp")<br/># Must define a "layer" to keep OGR happy<br/>lyr = field.GetLayer("field")</pre>
<ol start="2">
<li>There's only one polygon, so we'll grab that feature:</li>
</ol>
<pre style="padding-left: 60px"># Only one polygon in this shapefile<br/>poly = lyr.GetNextFeature()</pre>
<ol start="3">
<li>Now we'll convert the layer extent to image pixel coordinates:</li>
</ol>
<pre style="padding-left: 60px"># Convert the layer extent to image pixel coordinates<br/>minX, maxX, minY, maxY = lyr.GetExtent()<br/>ulX, ulY = world2Pixel(geoTrans, minX, maxY)<br/>lrX, lrY = world2Pixel(geoTrans, maxX, minY)</pre>
<ol start="4">
<li>Then, we calculate the pixel size of the new image:</li>
</ol>
<pre style="padding-left: 60px"># Calculate the pixel size of the new image<br/>pxWidth = int(lrX - ulX)<br/>pxHeight = int(lrY - ulY)</pre>
<ol start="5">
<li>Next, we create a new blank image at the correct size:</li>
</ol>
<pre style="padding-left: 60px"># Create a blank image of the correct size<br/># that will serve as our mask<br/>clipped = gdal_array.numpy.zeros((3, pxHeight, pxWidth),<br/> gdal_array.numpy.uint8)</pre>
<ol start="6">
<li>Now, we're ready to clip the red and infrared bands using the bounding box:</li>
</ol>
<pre style="padding-left: 60px"># Clip red and infrared to new bounds.<br/>rClip = r[ulY:lrY, ulX:lrX]<br/>irClip = ir[ulY:lrY, ulX:lrX]</pre>
<ol start="7">
<li>Next, we create the georeferencing information for the image:</li>
</ol>
<pre style="padding-left: 60px"># Create a new geomatrix for the image<br/>geoTrans = list(geoTrans)<br/>geoTrans[0] = minX<br/>geoTrans[3] = maxY</pre>
<ol start="8">
<li>Then we can prepare to map points to pixels in order to create our mask image:</li>
</ol>
<pre style="padding-left: 60px"># Map points to pixels for drawing<br/># the field boundary on a blank<br/># 8-bit, black and white, mask image.<br/>points = []<br/>pixels = []<br/># Grab the polygon geometry<br/>geom = poly.GetGeometryRef()<br/>pts = geom.GetGeometryRef(0)</pre>
<ol start="9">
<li>We loop through all of the point features and store their <em>x</em> and <em>y</em> values:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"># Loop through geometry and turn<br/># the points into an easy-to-manage<br/># Python list<br/>for p in range(pts.GetPointCount()):<br/>    points.append((pts.GetX(p), pts.GetY(p)))</pre>
<ol start="10">
<li>Now, we convert the points to pixel locations:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"># Loop through the points and map to pixels.<br/># Append the pixels to a pixel list<br/>for p in points:<br/>    pixels.append(world2Pixel(geoTrans, p[0], p[1]))</pre>
<ol start="11">
<li>Next, we create a new image that will serve as our mask image:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"># Create the raster polygon image as a black and white 'L' mode<br/># and filled as white. White=1<br/>rasterPoly = Image.new("L", (pxWidth, pxHeight), 1)</pre>
<ol start="12">
<li>Now we can rasterize our polygon:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"># Create a PIL drawing object<br/>rasterize = ImageDraw.Draw(rasterPoly)<br/><br/># Dump the pixels to the image<br/># as a polygon. Black=0<br/>rasterize.polygon(pixels, 0)</pre>
<ol start="13">
<li>Finally, we can convert our mask to a <kbd>numpy</kbd> array:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"># Hand the image back to gdal/gdal_array<br/># so we can use it as an array mask<br/>mask = imageToArray(rasterPoly)</pre>
<p>Now that we have converted the shapefile to a mask image, we can clip the bands.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Clipping the bands</h1>
                
            
            
                
<p class="mce-root">Now that we have our image mask, we can clip the red and infrared bands to the boundary of the mask. For this process, we use NumPy's <kbd>choose()</kbd> method that correlates the mask cell to the raster band cell and returns that value, or returns <kbd>0</kbd>. The result is a new array that is clipped to the mask, but with the correlated values from the raster band:</p>
<pre># Clip the red band using the mask<br/>rClip = gdal_array.numpy.choose(mask,<br/> (rClip, 0)).astype(gdal_array.numpy.uint8)<br/><br/># Clip the infrared band using the mask<br/>irClip = gdal_array.numpy.choose(mask,<br/> (irClip, 0)).astype(gdal_array.numpy.uint8)</pre>
<p>We now have just the data that we want, so we can apply our NDVI relative vegetation health formula.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Using the NDVI formula</h1>
                
            
            
                
<p class="mce-root">Our final process for creating the NDVI is to execute the equation that is <em>infrared - red/infrared + red</em>. The first step that we perform silences any <strong>not-a-number</strong>, also known as <strong>NaN</strong>, values in NumPy that might occur during division. And before we save the output, we'll convert any NaN values to <kbd>0</kbd>. We'll save the output as <kbd>ndvi.tif</kbd>, and that will be the input for the next script in order to classify and colorize the NDVI as follows:</p>
<ol>
<li>First, we'll ignore any warnings from <kbd>numpy</kbd>, as we'll get some errors near the edges:</li>
</ol>
<pre style="padding-left: 60px"># We don't care about numpy warnings<br/># due to NaN values from clipping<br/>gdal_array.numpy.seterr(all="ignore")</pre>
<ol start="2">
<li>Now we can perform our NDVI formula:</li>
</ol>
<pre style="padding-left: 60px"># NDVI equation: (infrared - red) / (infrared + red)<br/># *1.0 converts values to floats,<br/># +1.0 prevents ZeroDivisionErrors<br/>ndvi = 1.0 * ((irClip - rClip) / (irClip + rClip + 1.0))</pre>
<ol start="3">
<li>If there are any NaN values, we convert them to zero:</li>
</ol>
<pre style="padding-left: 60px"># Convert any NaN values to 0 from the final product<br/>ndvi = gdal_array.numpy.nan_to_num(ndvi)</pre>
<ol start="4">
<li>Finally, we save our finished NDVI image:</li>
</ol>
<pre style="padding-left: 60px"># Save the ndvi as a GeoTIFF and copy/adjust <br/># the georeferencing info<br/>gtiff = gdal.GetDriverByName( 'GTiff' )<br/>gtiff.CreateCopy(target, copy_geo(ndvi, prototype=source, xoffset=ulX, yoffset=ulY))<br/>gtiff = None</pre>
<p>The following figure is the output of this example. You need to view it in a geospatial viewer such as QGIS or OpenEV. The image won't open in most image editors. The lighter the shade of gray, the healthier the plant is within that field:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/8bc38834-7ad5-40e8-81e9-32c2f8db7151.png" style="width:20.25em;height:23.25em;" width="484" height="557"/></p>
<p>Now that we know how to use the NDVI formula, let's see how to classify it.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Classifying the NDVI</h1>
                
            
            
                
<p class="mce-root">We now have a valid index, but it is not easy to understand, because it is a grayscale image. If we color the image in an intuitive way, then even a child can identify the healthier plants. In the following section, <em>Additional functions</em>, we read in this grayscale index and classify it from brown to dark green using seven classes. The classification and image processing routines, such as the histogram and stretching functions, are almost identical to what we used in the <em>Creating histograms</em> section in <a href="13990656-5786-445c-878b-8b262ad6f3c0.xhtml">Chapter 6</a>, <em>Python and Remote Sensing</em>, but this time we are applying them in a much more specific way.</p>
<p class="mce-root">The output of this example will be another GeoTIFF file, but this time it will be a colorful RGB image.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Additional functions</h1>
                
            
            
                
<p class="mce-root">We won't need any of the functions from our previous NDVI script, but we do need to add a function for creating and stretching a histogram. Both of these functions work with NumPy arrays. We'll also shorten the reference to <kbd>gdal_array</kbd> to <kbd>gd</kbd> in this script because it is a long name, and we need it throughout the script.</p>
<p>Let's have a look at the steps as follows:</p>
<ol>
<li>First, we import the libraries that we need:</li>
</ol>
<pre style="padding-left: 60px">import gdal_array as gd<br/>import operator<br/>from functools import reduce</pre>
<ol start="2">
<li>Next, we need to create a <kbd>histogram</kbd> function, which we'll need in order to do a histogram stretch:</li>
</ol>
<pre style="padding-left: 60px">def histogram(a, bins=list(range(256))):<br/> """<br/> Histogram function for multi-dimensional array.<br/> a = array<br/> bins = range of numbers to match<br/> """<br/> # Flatten, sort, then split our arrays for the histogram.<br/> fa = a.flat<br/> n = gd.numpy.searchsorted(gd.numpy.sort(fa), bins)<br/> n = gd.numpy.concatenate([n, [len(fa)]])<br/> hist = n[1:]-n[:-1]<br/> return hist</pre>
<ol start="3">
<li>Now, we create our histogram <kbd>stretch</kbd> function:</li>
</ol>
<pre style="padding-left: 60px">def stretch(a):<br/> """<br/> Performs a histogram stretch on a gdal_array array image.<br/> """<br/> hist = histogram(a)<br/> lut = []<br/> for b in range(0, len(hist), 256):<br/> # step size – create equal interval bins.<br/> step = reduce(operator.add, hist[b:b+256]) / 255<br/> # create equalization lookup table<br/> n = 0<br/> for i in range(256):<br/> lut.append(n / step)<br/> n = n + hist[i+b]<br/> gd.numpy.take(lut, a, out=a)<br/> return a</pre>
<p>Now that we have our utility functions, we can process the NDVI.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Loading the NDVI</h1>
                
            
            
                
<p class="mce-root">Next, we'll load the output of our NDVI script back into a NumPy array. We'll also define the name of our output image as <kbd>ndvi_color.tif</kbd>, and create a zero-filled multidimensional array as a placeholder for the red, green, and blue bands of the colorized NDVI image. The following code will load the NDVI TIFF image into a <kbd>numpy</kbd> array:</p>
<pre># NDVI output from ndvi script<br/>source = "ndvi.tif"<br/><br/># Target file name for classified<br/># image image<br/>target = "ndvi_color.tif"<br/><br/># Load the image into an array<br/>ndvi = gd.LoadFile(source).astype(gd.numpy.uint8)</pre>
<p>Now that our image is loaded as an array, we can stretch it.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Preparing the NDVI</h1>
                
            
            
                
<p class="mce-root">We need to perform a histogram stretch on the NDVI in order to ensure that the image covers the range of classes that will give the final product meaning:</p>
<pre># Peform a histogram stretch so we are able to<br/># use all of the classes<br/>ndvi = stretch(ndvi)<br/><br/># Create a blank 3-band image the same size as the ndvi<br/>rgb = gd.numpy.zeros((3, len(ndvi), len(ndvi[0])), gd.numpy.uint8)</pre>
<p>Now that we've stretched the image, we can begin the classification process.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Creating classes</h1>
                
            
            
                
<p class="mce-root">In this part, we set up the ranges for our NDVI classes, which are broken up across a range from 0 to 255. We'll use seven classes. You can change the number of classes by adding or removing values from the classes list. Next, we create a <strong>look-up table</strong>, or <strong>LUT</strong>, in order to assign colors for each class. The number of colors must match the number of classes.</p>
<p class="mce-root">The colors are defined as RGB values. The <kbd>start</kbd> variable defines the beginning of the first class. In this case, <kbd>0</kbd> is a nodata value, which we designated in the previous script, so we begin the class at <kbd>1</kbd>. We then loop through the classes, extract the ranges, and use the color assignments to add the RGB value to our placeholder array. Finally, we save the colorized image as a GeoTIFF file:</p>
<pre># Class list with ndvi upper range values.<br/># Note the lower and upper values are listed on the ends<br/>classes = [58, 73, 110, 147, 184, 220, 255]<br/><br/># Color look-up table (lut)<br/># The lut must match the number of classes<br/># Specified as R, G, B tuples from dark brown to dark green<br/>lut = [[120, 69, 25], [255, 178, 74], [255, 237, 166], [173, 232, 94],<br/> [135, 181, 64], [3, 156, 0], [1, 100, 0]]<br/><br/># Starting value of the first class<br/>start = 1</pre>
<p class="mce-root">Now we can classify the image:</p>
<pre># For each class value range, grab values within range,<br/># then filter values through the mask.<br/>for i in range(len(classes)):<br/> mask = gd.numpy.logical_and(start &lt;= ndvi,<br/> ndvi &lt;= classes[i])<br/> for j in range(len(lut[i])):<br/>     rgb[j] = gd.numpy.choose(mask, (rgb[j], lut[i][j]))<br/>     start = classes[i]+1</pre>
<p>Finally, we can save our classified GeoTIFF file:</p>
<pre># Save a geotiff image of the colorized ndvi.<br/>output=gd.SaveArray(rgb, target, format="GTiff", prototype=source)<br/>output = None</pre>
<p>Here is the image that we output:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/26dba7c4-7a58-48e6-9d4c-0a2d61becd64.png" style="width:20.42em;height:23.42em;" width="383" height="440"/></p>
<p>This is our final product for this example. Farmers can use this data to determine how to effectively irrigate and spray chemicals, such as fertilizers and pesticides, in a targeted, more effective, and more environmentally friendly way. In fact, these classes can even be turned into a vector shapefile, which is then loaded into a GPS-driven computer on a field sprayer. This then automatically applies the correct amount of chemicals in the correct place as a sprayer is driven around the field, or in some cases, even flown over the field in an airplane with a sprayer attachment.</p>
<p class="mce-root">Notice as well that even though we clipped the data to the field, the image is still a square. The black areas are the nodata values that have been converted to black. In display software, you can make the nodata color transparent without affecting the rest of the image.</p>
<p>Although we created a very specific type of product, a classified NDVI, the framework of this script can be altered in order to implement many remote sensing analysis algorithms. There are different types of NDVIs, but with relatively minor changes, you can turn this script into a tool that can be used to look for harmful algae blooms in the ocean, or smoke in the middle of a forest indicating a forest fire.</p>
<p>This book attempts to limit the use of GDAL as much as possible in order to focus on what can be accomplished with pure Python and tools that can easily be installed from PyPI. However, it is helpful to remember that there is a wealth of information on using GDAL and its associated utilities to carry out similar tasks. For another tutorial on clipping a raster with GDAL via its command-line utilities, see <a href="https://joeyklee.github.io/broc-cli-geo/guide/XX_raster_cropping_and_clipping.html">https://joeyklee.github.io/broc-cli-geo/guide/XX_raster_cropping_and_clipping.html</a>.</p>
<p>Now that we've worked with the land, let's work with water in order to create a flood inundation model.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Creating a flood inundation model</h1>
                
            
            
                
<p>In this next example, we'll begin to enter the world of hydrology. Flooding is one of the most common and devastating natural disasters, which affects nearly every population on the globe. Geospatial models are a powerful tool in estimating the impact of a flood and mitigating that impact before it happens. We often hear on the news that a river is reaching the flood stage, but that information is meaningless if we can't understand the impact.</p>
<p>Hydrological flood models are expensive to develop and can be very complex. These models are essential for engineers in building flood control systems. However, first responders and potential flood victims are only interested in the impact of an impending flood.</p>
<p>We can begin to understand the flooding impact in an area using a very simple and easy-to-comprehend tool called a <strong>flood inundation model</strong>. This model starts with a single point and floods an area with the maximum volume of water that a flood basin can hold at a particular flood stage. Usually, this analysis is a worst-case scenario. Hundreds of other factors go into calculating how much water will enter into a basin from a river-topping flood stage. But we can still learn a lot from this simple first-order model.</p>
<p>As mentioned in the <em>Elevation data</em> section in <a href="6b5bd08a-170c-4471-a3f3-d79d5b91f017.xhtml">Chapter 1</a>, <em>Learning about Geospatial Analysis with Python</em>, the <strong>Shuttle Radar Topography Mission</strong> (<strong>SRTM</strong>) dataset provides a nearly-global DEM that you can use for these types of models. More on SRTM data can be found here: <a href="http://www2.jpl.nasa.gov/srtm/">http://www2.jpl.nasa.gov/srtm/</a>.</p>
<p class="CDPAlignLeft CDPAlign">You can download the ASCII Grid data in EPSG:4326, and a shapefile containing the point as a <kbd>.zip</kbd> file from <a href="http://git.io/v3fSg">http://git.io/v3fSg</a>. The shapefile is just for reference and has no role in this model. The following image is a <strong>digital elevation model</strong> (<strong>DEM</strong>) with a source point displayed as a yellow star near Houston, Texas. In real-world analysis, this point would likely be a stream gauge where you would have data about the river's water level:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/7e7f70cc-0410-4925-9d89-c2355eb0d961.png" style="width:20.75em;height:20.67em;" width="800" height="799"/></p>
<p>The algorithm that we are introducing in this example is called a <strong>flood fill algorithm</strong>. This algorithm is well known in the field of computer science and is used in the classic computer game <strong>Minesweeper</strong> to clear empty squares on the board when a user clicks a square. It is also the method that is used for the well-known <strong>paint bucket tool</strong> in graphics programs such as <strong>Adobe Photoshop</strong>, and it is used to fill an area of adjacent pixels of the same color with a different color.</p>
<p>There are many ways to implement this algorithm. One of the oldest and most common ways is to recursively crawl through each pixel of the image. The problem with recursion is that you end up processing pixels more than once and creating an unnecessary amount of work. The resource usage for a recursive flood fill can easily crash a program on even a moderately sized image.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>This script uses a four-way queue-based flood fill that may visit a cell more than once but ensures that we only process a cell once. The queue only contains unique, unprocessed cells by using Python's built-in set type, which only holds unique values. We use two sets: <strong>fill</strong>, which contains the cells we need to fill, and <strong>filled</strong>, which contains processed cells.</p>
<p>This example executes the following steps:</p>
<ol>
<li>Extract the header information from the ASCII DEM.</li>
<li>Open the DEM as a <kbd>numpy</kbd> array.</li>
<li>Define our starting point as row and column in the array.</li>
<li>Declare a flood elevation value.</li>
<li>Filter the terrain to only the desired elevation value and below.</li>
<li>Process the filtered array.</li>
<li>Create a 1, 0, 0 array (that is, a binary array) with flooded pixels as 1.</li>
<li>Save the flood inundation array as an ASCII Grid.</li>
</ol>
<p>This example can take a minute or two to run on a slower machine; we'll use the <kbd>print</kbd> statements throughout the script as a simple way to track progress. Once again we'll break this script up with explanations, for clarity.</p>
<p>Now that we have our data, we can begin our flood fill function.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">The flood fill function</h1>
                
            
            
                
<p class="mce-root">We use ASCII Grids in this example, which means that the engine for this model is completely in NumPy. We start off by defining the <kbd>floodFill()</kbd> function, which is the heart and soul of this model. This Wikipedia article on flood fill algorithms provides an excellent overview of the different approaches: <a href="http://en.wikipedia.org/wiki/Flood_fill">http://en.wikipedia.org/wiki/Flood_fill</a>.</p>
<p class="mce-root">Flood fill algorithms start at a given cell and begin checking the neighboring cells for similarity. The similarity factor might be color or, in our case, elevation. If the neighboring cell is of the same or lower elevation as the current cell, then that cell is marked for checks of its neighbor until the entire grid is checked. NumPy isn't designed to crawl over an array in this way, but it is still efficient in handling multidimensional arrays overall. We step through each cell and check its neighbors to the north, south, east, and west. Any of those cells which can be flooded are added to the filled set, and their neighbors are added to the fill set to be checked by the algorithm.</p>
<p class="mce-root">As mentioned earlier, if you try to add the same value to a set twice, it just ignores the duplicate entry and maintains a unique list. By using sets in an array, we efficiently check a cell only once because the fill set contains unique cells. The following code implements our <kbd>floodFill</kbd> function:</p>
<ol>
<li>First we import our libraries:</li>
</ol>
<pre style="padding-left: 60px">import numpy as np<br/>from linecache import getline</pre>
<ol start="2">
<li>Next, we create our <kbd>floodFill</kbd> function:</li>
</ol>
<pre style="padding-left: 60px">def floodFill(c, r, mask):<br/> """<br/> Crawls a mask array containing<br/> only 1 and 0 values from the<br/> starting point (c=column,<br/> r=row - a.k.a. x, y) and returns<br/> an array with all 1 values<br/> connected to the starting cell.<br/> This algorithm performs a 4-way<br/> check non-recursively.<br/> """</pre>
<ol start="3">
<li>Next, we create sets to track the cells that we've already covered:</li>
</ol>
<pre style="padding-left: 60px"> # cells already filled<br/> filled = set()<br/> # cells to fill<br/> fill = set()<br/> fill.add((c, r))<br/> width = mask.shape[1]-1<br/> height = mask.shape[0]-1</pre>
<ol start="4">
<li>Then we create our inundation array:</li>
</ol>
<pre style="padding-left: 60px"> # Our output inundation array<br/> flood = np.zeros_like(mask, dtype=np.int8)</pre>
<ol start="5">
<li>Now we can loop through the cells and flood them, or not:</li>
</ol>
<pre style="padding-left: 60px"> # Loop through and modify the cells which<br/> # need to be checked.<br/> while fill:<br/>   # Grab a cell<br/>   x, y = fill.pop()</pre>
<ol start="6">
<li>If the land is higher than the floodwater, skip it:</li>
</ol>
<pre style="padding-left: 60px">   if y == height or x == width or x &lt; 0 or y &lt; 0:<br/>    # Don't fill<br/>    continue</pre>
<ol start="7">
<li>If the land elevation is equal to or less than the floodwater, fill it in:</li>
</ol>
<pre style="padding-left: 60px">   if mask[y][x] == 1:<br/>    # Do fill<br/>    flood[y][x] = 1<br/>   filled.add((x, y))</pre>
<ol start="8">
<li>Now, we check the surrounding neighbor cells to see if they need to be filled, and when we run out of cells, we return the flooded matrix:</li>
</ol>
<pre style="padding-left: 60px">   # Check neighbors for 1 values<br/>   west = (x-1, y)<br/>   east = (x+1, y)<br/>   north = (x, y-1)<br/>   south = (x, y+1)<br/>   if west not in filled:<br/>     fill.add(west)<br/>   if east not in filled:<br/>     fill.add(east)<br/>   if north not in filled:<br/>     fill.add(north)<br/>   if south not in filled:<br/>     fill.add(south)<br/> return flood</pre>
<p>Now that we've set up our <kbd>floodFill</kbd> function, we can create a flood.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Predicting flood inundation</h1>
                
            
            
                
<p class="mce-root">In the remainder of the script, we load our terrain data from an ASCII Grid, define our output grid filename, and execute the algorithm on the terrain data. The seed of the flood fill algorithm is an arbitrary point, as <kbd>sx</kbd> and <kbd>sy</kbd> within the lower elevation areas. In a real-world application, these points would likely be a known location, such as a stream gauge or a breach in a dam. In the final step, we save the output grid.</p>
<p>The following steps need to be performed:</p>
<ol>
<li>First, we set up our <kbd>source</kbd> and <kbd>target</kbd> data names:</li>
</ol>
<pre style="padding-left: 60px">source = "terrain.asc"<br/>target = "flood.asc"</pre>
<ol start="2">
<li>Next, we open the source:</li>
</ol>
<pre style="padding-left: 60px">print("Opening image...")<br/>img = np.loadtxt(source, skiprows=6)<br/>print("Image opened")</pre>
<ol start="3">
<li>We'll create a mask array of everything below <kbd>70</kbd> meters:</li>
</ol>
<pre style="padding-left: 60px"># Mask elevations lower than 70 meters.<br/>wet = np.where(img &lt; 70, 1, 0)<br/>print("Image masked")</pre>
<ol start="4">
<li>Now, we'll parse the geospatial information from the header:</li>
</ol>
<pre style="padding-left: 60px"># Parse the header using a loop and<br/># the built-in linecache module<br/>hdr = [getline(source, i) for i in range(1, 7)]<br/>values = [float(h.split(" ")[-1].strip()) for h in hdr]<br/>cols, rows, lx, ly, cell, nd = values<br/>xres = cell<br/>yres = cell * -1</pre>
<ol start="5">
<li>Now, we'll establish a starting point that is located in a riverbed:</li>
</ol>
<pre style="padding-left: 60px"># Starting point for the<br/># flood inundation in pixel coordinates<br/>sx = 2582<br/>sy = 2057</pre>
<ol start="6">
<li>Now, we trigger our <kbd>floodFill</kbd> function:</li>
</ol>
<pre style="padding-left: 60px">print("Beginning flood fill")<br/>fld = floodFill(sx, sy, wet)<br/>print("Finished flood fill")<br/><br/>header = ""<br/>for i in range(6):<br/> header += hdr[i]</pre>
<ol start="7">
<li>Finally, we can save our flood inundation model output:</li>
</ol>
<pre style="padding-left: 60px">print("Saving grid")<br/># Open the output file, add the hdr, save the array<br/>with open(target, "wb") as f:<br/> f.write(bytes(header, 'UTF-8'))<br/> np.savetxt(f, fld, fmt="%1i")<br/>print("Done!")</pre>
<p class="mce-root">The image in the following screenshot shows the flood inundation output over a classified version of the DEM, with lower elevation values in brown, mid-range values in green, and higher values in gray and white:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/4696dc35-3027-456b-9b02-a54473c43317.png" style="width:23.75em;height:23.75em;" width="551" height="550"/></p>
<p class="mce-root">The flood raster, which includes all areas less than 70 meters, is colored blue. This image was created with QGIS, but it could be displayed in ArcGIS as EPSG:4326. You could also use GDAL to save the flood raster grid as an 8-bit TIFF file or JPEG file, just like the NDVI example, in order to view it in a standard graphics program.</p>
<p class="mce-root">This image in the following screenshot is nearly identical, except for the filtered mask from which the inundation was derived, which is displayed in yellow. This is done by generating a file for the array called <kbd>wet</kbd>, instead of <kbd>fld</kbd>, to show the non-contiguous regions, which were not included as part of a flood. These areas are not connected to the source point, so they would unlikely be reached during a flood event:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/714014f4-74aa-4ba5-96ee-a99f77b6caca.png" style="width:23.92em;height:19.58em;" width="703" height="577"/></p>
<p class="mce-root">By changing the elevation value, you can create additional flood inundation rasters. We started with an elevation of 70 meters. If we increase that value to 90, we can expand the flood. The following screenshot shows a flood event at both 70 and 90 meters:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/499dbc17-5925-49a3-abc6-a7cf2a17be77.png" style="width:22.00em;height:22.00em;" width="551" height="550"/></p>
<p>The 90 meter inundation is the lighter-blue polygon. You can take bigger or smaller steps and show different impacts as different layers.</p>
<p class="mce-root">This model is an excellent and useful visualization. However, you could take this analysis even further by using GDAL's <kbd>polygonize()</kbd> method on the flood mask, as we did with the island in the <em>Extracting features from images</em> section in <a href="13990656-5786-445c-878b-8b262ad6f3c0.xhtml">Chapter 6</a>, <em>Python and Remote Sensing</em>. This operation would give you a vector flood polygon. Then, you could use the principles that we discussed in the <em>Performing selections</em> section in <a href="306ed8f8-99dd-4751-b273-9d76cfac4ec2.xhtml">Chapter 5</a>, <em>Python and Geographic Information Systems</em>, to select buildings using the polygon to determine population impact. You could also combine that flood polygon with the dot density example in <a href="306ed8f8-99dd-4751-b273-9d76cfac4ec2.xhtml">Chapter 5</a>, <em>Python and Geographic Information Systems</em>, in the <em>Dot density calculations</em> section, to assess the potential population impact of a flood. The possibilities are endless.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Creating a color hillshade</h1>
                
            
            
                
<p class="mce-root">In this example, we'll combine previous techniques to combine our terrain hillshade from <a href="964b7276-1604-4df5-b549-6d8f61d5e9cb.xhtml">Chapter 7</a>, <em>Python and Elevation Data,</em> with the color classification that we used on the LIDAR. For this example, we'll need the ASCII Grid DEMs named <kbd>dem.asc</kbd> and <kbd>relief.asc</kbd> that we used in the previous chapter.</p>
<p class="mce-root">We'll create a colorized DEM and a hillshade, and then use PIL to blend them together for an enhanced elevation visualization. The code comments will guide you through the example, as many of these steps are already familiar to you:</p>
<ol>
<li>First, we import the libraries that we need:</li>
</ol>
<pre style="padding-left: 60px">import gdal_array as gd<br/>try:<br/> import Image<br/>except ImportError:<br/> from PIL import Image</pre>
<p style="padding-left: 60px">For this next part, you'll need the following two files: <a href="https://github.com/GeospatialPython/Learn/raw/master/relief.zip">https://github.com/GeospatialPython/Learn/raw/master/relief.zip</a> and <a href="https://github.com/GeospatialPython/Learn/raw/master/dem.zip">https://github.com/GeospatialPython/Learn/raw/master/dem.zip</a>.</p>
<ol start="2">
<li>Then, we'll set up variables for the inputs and outputs:</li>
</ol>
<pre style="padding-left: 60px">relief = "relief.asc"<br/>dem = "dem.asc"<br/>target = "hillshade.tif"</pre>
<ol start="3">
<li>Next, we'll load our <kbd>relief</kbd> image:</li>
</ol>
<pre style="padding-left: 60px"># Load the relief as the background image<br/>bg = gd.numpy.loadtxt(relief, skiprows=6)</pre>
<ol start="4">
<li>Then, we'll load the DEM image, so that we'll have the elevation data:</li>
</ol>
<pre style="padding-left: 60px"># Load the DEM into a numpy array as the foreground image<br/>fg = gd.numpy.loadtxt(dem, skiprows=6)[:-2, :-2]</pre>
<ol start="5">
<li>Now, we'll create a new image for our colorization with elevation breakpoints forming classes and corresponding colors in a LUT:</li>
</ol>
<pre style="padding-left: 60px"># Create a blank 3-band image to colorize the DEM<br/>rgb = gd.numpy.zeros((3, len(fg), len(fg[0])), gd.numpy.uint8)<br/><br/># Class list with DEM upper elevation range values.<br/>classes = [356, 649, 942, 1235, 1528,<br/> 1821, 2114, 2300, 2700]<br/><br/># Color look-up table (lut)<br/># The lut must match the number of classes.<br/># Specified as R, G, B tuples<br/>lut = [[63, 159, 152], [96, 235, 155], [100, 246, 174],<br/> [248, 251, 155], [246, 190, 39], [242, 155, 39],<br/> [165, 84, 26], [236, 119, 83], [203, 203, 203]]<br/><br/># Starting elevation value of the first class<br/>start = 1</pre>
<ol start="6">
<li>We can now perform our color classification:</li>
</ol>
<pre style="padding-left: 60px"># Process all classes.<br/>for i in range(len(classes)):<br/> mask = gd.numpy.logical_and(start &lt;= fg,<br/> fg &lt;= classes[i])<br/> for j in range(len(lut[i])):<br/> rgb[j] = gd.numpy.choose(mask, (rgb[j], lut[i][j]))<br/> start = classes[i]+1</pre>
<ol start="7">
<li>Then, we can convert our shaded relief array to an image, as well as our colorized DEM:</li>
</ol>
<pre style="padding-left: 60px"># Convert the shaded relief to a PIL image<br/>im1 = Image.fromarray(bg).convert('RGB')<br/><br/># Convert the colorized DEM to a PIL image.<br/># We must transpose it from the Numpy row, col order<br/># to the PIL col, row order (width, height).<br/>im2 = Image.fromarray(rgb.transpose(1, 2, 0)).convert('RGB')</pre>
<ol start="8">
<li>Now, we'll blend the two images for the final effect and save it to an image file:</li>
</ol>
<pre style="padding-left: 60px"># Blend the two images with a 40% alpha<br/>hillshade = Image.blend(im1, im2, .4)<br/><br/># Save the hillshade<br/>hillshade.save(target)</pre>
<p>The following image shows the output, which makes a great backdrop for GIS maps:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/20daa808-1730-438a-9f52-098550887189.png" style="width:31.75em;height:25.08em;" width="900" height="712"/></p>
<p>Now that we can model terrain, let's learn how to navigate over it. </p>
<p class="mce-root"/>
<p class="mce-root"/>


            

            
        
    </div>



  
<div><h1 class="header-title">Performing least cost path analysis</h1>
                
            
            
                
<p class="mce-root">Calculating driving directions is the most commonly used geospatial function in the world. Typically, these algorithms calculate the shortest path between points <em>A</em> and <em>B</em>, or they may take into account the speed limit of the road, or even current traffic conditions, in order to choose a route by drive time.</p>
<p class="mce-root">But what if your job is to build a new road? Or what if you are in charge of deciding where to run power transmission lines or water lines across a remote area? In a terrain-based setting, the shortest path might cross a difficult mountain, or run through a lake. In this case, we need to account for obstacles and avoid them if possible. However, if avoiding a minor obstacle takes us too far out of our way, the cost of implementing that route may be more expensive than just going over a mountain.</p>
<p class="mce-root">This type of advanced analysis is called <strong>least cost path analysis</strong>. We search an area for the route that is the best compromise of distance versus the cost of following that route. The algorithm that we use for this process is called the <strong>A-star or A*</strong> algorithm. The oldest routing method is called the <strong>Dijkstra algorithm</strong>, which calculates the shortest path in a network, such as a road network. The A* method can do that as well, but it is also better suited for traversing a grid-like DEM.</p>
<p>You can find out more about these algorithms on the following web pages:
<ul>
<li class="mce-root">Dijkstra's algorithm: <a href="http://en.wikipedia.org/wiki/Dijkstra's_algorithm">http://en.wikipedia.org/wiki/Dijkstra's_algorithm</a>. </li>
<li class="mce-root">A* algorithm: <a href="http://en.wikipedia.org/wiki/A-star_algorithm">http://en.wikipedia.org/wiki/A-star_algorithm</a>.</li>
</ul>
</p>
<p class="mce-root">This example is the most complex in this chapter. To better understand it, we have a simple version of the program, which is text based, and operates on a 5 x 5 grid with randomly generated values. You can actually see how this program follows the algorithm before trying it on an elevation grid with thousands of values.</p>
<p class="mce-root">This program executes the following steps:</p>
<ol>
<li class="mce-root">Create a simple grid with randomly generated pseudo-elevation values between 1 and 16.</li>
<li class="mce-root">Define a start location in the lower-left corner of the grid.</li>
<li class="mce-root">Define the end point as the upper-right corner of the grid.</li>
</ol>
<ol start="4">
<li class="mce-root">Create a cost grid that has the elevation of each cell, plus the cell's distance to the finish.</li>
<li class="mce-root">Examine each neighboring cell from the start, and choose the one with the lowest cost.</li>
<li class="mce-root">Repeat the evaluation using the chosen cell until we get to the end.</li>
<li class="mce-root">Return the set of chosen cells as the least cost path.</li>
<li class="mce-root">Set up the test grid.</li>
</ol>
<p class="mce-root">You simply run this program from the command line and view its output. The first section of this script sets up our artificial terrain grid as a randomly generated NumPy array, with notional elevation values between 1 and 16. We also create a distance grid that calculates the distance for each cell to the destination cell. This value is the cost of each cell.</p>
<p>Let's have a look at the following steps:</p>
<ol>
<li>First, we'll import <kbd>numpy</kbd> and set the size of our grid:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root">import numpy as np<br/><br/># Width and height<br/># of grids<br/>w = 5<br/>h = 5</pre>
<ol start="2">
<li>Next, we set a starting location cell and an ending location:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"># Start location:<br/># Lower left of grid<br/>start = (h-1, 0)<br/><br/># End location:<br/># Top right of grid<br/>dx = w-1<br/>dy = 0</pre>
<ol start="3">
<li>Now, we can create a grid of zeros based on our width and height:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"># Blank grid<br/>blank = np.zeros((w, h))</pre>
<ol start="4">
<li>Next, we'll set up our distance grid in order to create impedance values:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"># Distance grid<br/>dist = np.zeros(blank.shape, dtype=np.int8)<br/><br/># Calculate distance for all cells<br/>for y, x in np.ndindex(blank.shape):<br/> dist[y][x] = abs((dx-x)+(dy-y))</pre>
<ol start="5">
<li>Now, we'll print out the cost value of each cell in our cost grid:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"># "Terrain" is a random value between 1-16.<br/># Add to the distance grid to calculate<br/># The cost of moving to a cell<br/>cost = np.random.randint(1, 16, (w, h)) + dist<br/><br/>print("COST GRID (Value + Distance)\n{}\n".format(cost))</pre>
<p>Now that we have a simulated terrain grid to work with, we can test a routing algorithm.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">The simple A* algorithm</h1>
                
            
            
                
<p class="mce-root">The A* search algorithm that is implemented here crawls the grid in a similar fashion to our flood fill algorithm in the previous example. Once again, we use sets to avoid using recursion, and to avoid the duplication of cell checks. But this time, instead of checking elevation, we check the distance cost of routing through a cell in question. If the move raises the cost of getting to the end, then we go with a lower-cost option.</p>
<p>The following steps need to be performed, as follows:</p>
<ol>
<li>First, we'll start our A* function by creating sets that will keep track of the path progress:</li>
</ol>
<pre style="padding-left: 60px"># Our A* search algorithm<br/>def astar(start, end, h, g):<br/>    closed_set = set()<br/>    open_set = set()<br/>    path = set()</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<ol start="2">
<li>Next, we add the starting cell to the open list of cells in order to process and begin looping through that set:</li>
</ol>
<pre style="padding-left: 60px">    open_set.add(start)<br/>    while open_set:<br/>        cur = open_set.pop()<br/>        if cur == end:<br/>            return path<br/>        closed_set.add(cur)<br/>        path.add(cur)<br/>        options = []<br/>        y1 = cur[0]<br/>        x1 = cur[1]</pre>
<ol start="3">
<li>We check the surrounding cells as options for forward progress:</li>
</ol>
<pre>        if y1 &gt; 0:<br/>            options.append((y1-1, x1))<br/>        if y1 &lt; h.shape[0]-1:<br/>            options.append((y1+1, x1))<br/>        if x1 &gt; 0:<br/>            options.append((y1, x1-1))<br/>        if x1 &lt; h.shape[1]-1:<br/>            options.append((y1, x1+1))<br/>        if end in options:<br/>            return path<br/>        best = options[0]<br/>        closed_set.add(options[0])</pre>
<ol start="4">
<li>We then check each option for the best option and append it to the path until we reach the end:</li>
</ol>
<pre>        for i in range(1, len(options)):<br/>            option = options[i]<br/>            if option in closed_set:<br/>                continue<br/>            elif h[option] &lt;= h[best]:<br/>                best = option<br/>                closed_set.add(option)<br/>            elif g[option] &lt; g[best]:<br/>                best = option<br/>                closed_set.add(option)<br/>            else:<br/>                closed_set.add(option)<br/>        print(best, ", ", h[best], ", ", g[best])<br/>        open_set.add(best)<br/>    return []</pre>
<p>Now that we have the algorithm set up, we can test it out by creating a path.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Generating the test path</h1>
                
            
            
                
<p>In this section, we'll generate a path on our test grid. We'll call our A* function, using the starting point, end point, cost grid, and distance grid:</p>
<pre class="mce-root"># Find the path<br/>path = astar(start, (dy, dx), cost, dist)<br/>print()</pre>
<p>Now, we'll put our path on its own grid and print it:</p>
<pre class="mce-root"># Create and populate the path grid<br/>path_grid = np.zeros(cost.shape, dtype=np.uint8)<br/>for y, x in path:<br/> path_grid[y][x] = 1<br/>path_grid[dy][dx] = 1<br/><br/>print("PATH GRID: 1=path")<br/>print(path_grid)</pre>
<p>Next, we'll view the output of this test.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Viewing the test output</h1>
                
            
            
                
<p class="mce-root">When you run this program, you'll generate a randomly-numbered grid similar to the following:</p>
<pre><strong>COST GRID (Value + Distance)</strong><br/><strong>[[13 10 5 15 9]</strong><br/><strong> [15 13 16 5 16]</strong><br/><strong> [17 8 9 9 17]</strong><br/><strong> [ 4 1 11 6 12]</strong><br/><strong> [ 2 7 7 11 8]]</strong><br/><br/><strong>(Y,X), HEURISTIC, DISTANCE</strong><br/><strong>(3, 0) , 4 , 1</strong><br/><strong>(3, 1) , 1 , 0</strong><br/><strong>(2, 1) , 8 , 1</strong><br/><strong>(2, 2) , 9 , 0</strong><br/><strong>(2, 3) , 9 , 1</strong><br/><strong>(1, 3) , 5 , 0</strong><br/><strong>(0, 3) , 15 , 1</strong><br/><br/><strong>PATH GRID: 1=path</strong><br/><strong>[[0 0 0 1 1]</strong><br/><strong> [0 0 0 1 0]</strong><br/><strong> [0 1 1 1 0]</strong><br/><strong> [1 1 0 0 0]</strong><br/><strong> [1 0 0 0 0]]</strong></pre>
<p>The grid is small enough such that you can easily trace the algorithm's steps manually. This implementation uses <strong>Manhattan distance</strong>, which means the distance does not use diagonal lines—only left, right, up, and down measurements. The search also does not move diagonally in order to keep things simple.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">The real-world example</h1>
                
            
            
                
<p class="mce-root">Now that we have a basic understanding of the A* algorithm, let's move to a more complex example. For the relief example, we'll use the same DEM that is located near Vancouver, British Columbia, Canada, which we used in <a href="964b7276-1604-4df5-b549-6d8f61d5e9cb.xhtml">Chapter 7</a>, <em>Python and Elevation Data</em>, in the <em>Creating a shaded relief</em> section. The spatial reference for this grid is EPSG:26910 NAD 83/UTM zone 10N. You can download the DEM, relief, and start and end points of the shapefile as a zipped package from <a href="http://git.io/v3fpL">http://git.io/v3fpL</a>.</p>
<p class="mce-root">We'll actually use the shaded relief for visualization. Our goal in this exercise will be to move from the start to the finish point in the lowest-cost way possible:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/100d0634-af6e-4cd1-b470-87d25217cda3.png" style="width:27.75em;height:22.00em;" width="694" height="550"/></p>
<p class="mce-root">Just looking at the terrain, there are two paths that follow low-elevation routes without much change in direction. These two routes are illustrated in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/2c28f9cf-7567-4fd4-94c2-d2ad351c2988.png" style="width:26.92em;height:21.33em;" width="694" height="550"/></p>
<p class="mce-root">So, we would expect that when we used the A* algorithm, it would be close. Remember that the algorithm is only looking in the immediate vicinity, so it can't look at the whole image like we can, and it can't make adjustments early in the route based on a known obstacle ahead.</p>
<p class="mce-root">We will expand this implementation from our simple example and use Euclidean distance, or <em>as the crow flies</em> measurements, and we will also allow the search to look in eight directions instead of four. We will prioritize terrain as the primary decision point. We will also use distance, both to the finish and from the start, as lower priorities in order to make sure that we are moving forward toward the goal and not getting too far off track. Other than those differences, the steps are identical to the simple example. The output will be a raster with the path values set to one and the other values set to zero.</p>
<p>Now that we understand the problem, let's solve it!</p>
<p class="mce-root"/>
<p class="mce-root"/>


            

            
        
    </div>



  
<div><h1 class="header-title">Loading the grid</h1>
                
            
            
                
<p class="mce-root">In this section and the following sections, we'll create the script that can create a route over terrain. The script starts out simple enough. We load the grid into a NumPy array from an ASCII Grid. We name our output path grid, and then we define the starting cell and end cell:</p>
<ol>
<li>First, we import our libraries:</li>
</ol>
<pre style="padding-left: 60px">import numpy as np<br/>import math<br/>from linecache import getline<br/>import pickle</pre>
<ol start="2">
<li>Next, we'll define our input and output data sources:</li>
</ol>
<pre style="padding-left: 60px"># Our terrain data<br/>source = "dem.asc"<br/><br/># Output file name for the path raster<br/>target = "path.asc"</pre>
<ol start="3">
<li>Then, we can load the grid skipping over the header:</li>
</ol>
<pre style="padding-left: 60px">print("Opening %s..." % source)<br/>cost = np.loadtxt(source, skiprows=6)<br/>print("Opened %s." % source)</pre>
<ol start="4">
<li>Next, we'll parse the header for the geospatial and grid size information:</li>
</ol>
<pre style="padding-left: 60px"># Parse the header<br/>hdr = [getline(source, i) for i in range(1, 7)]<br/>values = [float(ln.split(" ")[-1].strip()) for ln in hdr]<br/>cols, rows, lx, ly, cell, nd = values</pre>
<ol start="5">
<li>Finally, we'll define our starting and end locations:</li>
</ol>
<pre style="padding-left: 60px"># Starting column, row<br/>sx = 1006<br/>sy = 954<br/><br/># Ending column, row<br/>dx = 303<br/>dy = 109</pre>
<p>Now that our grid is loaded, we can set up the functions that we'll need.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Defining the helper functions</h1>
                
            
            
                
<p class="mce-root">We need three functions in order to route over terrain. One is the A* algorithm, and the other two assist the algorithm in choosing the next step. We'll briefly discuss these helper functions. First, we have a simple Euclidean distance function named <kbd>e_dist</kbd>, which returns the straight-line distance between two points as map units. Next, we have an important function called <kbd>weighted_score</kbd>, which returns a score for a neighboring cell, based on the elevation change between the neighbor and the current cell, as well as the distance to the destination.</p>
<p class="mce-root">This function is better than distance or elevation alone because it reduces the chance of there being a tie between two cells, making it easier to avoid back-tracking. This scoring formula is loosely based on a concept called the <strong>Nisson Score</strong>, which is commonly used in these types of algorithms and is referenced in the Wikipedia articles mentioned earlier in this chapter. What's great about this function is that it can score the neighboring cell with any values that you wish. You might also use a real-time feed to look at the current weather in the neighboring cell, and avoid cells with rain or snow.</p>
<p>The following code will create our distance function and our weighting function that we'll need to traverse the terrain:</p>
<ol>
<li>First, we'll create a Euclidean distance function that will give us the distance between points:</li>
</ol>
<pre style="padding-left: 60px">def e_dist(p1, p2):<br/> """<br/> Takes two points and returns<br/> the Euclidian distance<br/> """<br/> x1, y1 = p1<br/> x2, y2 = p2<br/> distance = math.sqrt((x1-x2)**2+(y1-y2)**2)<br/> return int(distance)</pre>
<ol start="2">
<li>Now, we'll create our weight function in order to score each node for its suitability to move:</li>
</ol>
<pre style="padding-left: 60px">def weighted_score(cur, node, h, start, end):<br/> """<br/> Provides a weighted score by comparing the<br/> current node with a neighboring node. Loosely<br/> based on the Nisson Score concept: f=g+h<br/> In this case, the "h" value, or "heuristic",<br/> is the elevation value of each node.<br/> """</pre>
<p class="mce-root"/>
<ol start="3">
<li>We start with a <kbd>score</kbd> of <kbd>0</kbd> and check the node's distance from the end and the start:</li>
</ol>
<pre style="padding-left: 60px"> score = 0<br/> # current node elevation<br/> cur_h = h[cur]<br/> # current node distance from end<br/> cur_g = e_dist(cur, end)<br/> # current node distance from<br/> cur_d = e_dist(cur, start)</pre>
<ol start="4">
<li>Next, we examine the neighboring nodes and make a decision on where to move:</li>
</ol>
<pre style="padding-left: 60px"> # neighbor node elevation<br/> node_h = h[node]<br/> # neighbor node distance from end<br/> node_g = e_dist(node, end)<br/> # neighbor node distance from start<br/> node_d = e_dist(node, start)<br/> # Compare values with the highest<br/> # weight given to terrain followed<br/> # by progress towards the goal.<br/> if node_h &lt; cur_h:<br/> score += cur_h-node_h<br/> if node_g &lt; cur_g:<br/> score += 10<br/> if node_d &gt; cur_d:<br/> score += 10<br/> return score</pre>
<p>Now that our helper functions are complete, we can build the A* function.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            

            
        
    </div>



  
<div><h1 class="header-title">The real-world A* algorithm</h1>
                
            
            
                
<p class="mce-root">This algorithm is more involved than the simple version in our previous example. We use sets to avoid redundancy. It also implements our more advanced scoring algorithm and checks to make sure we aren't at the end of the path before doing additional calculations. Unlike our last example, this more advanced version also checks cells in eight directions, so the path can move diagonally. There is a <kbd>print</kbd> statement at the end of this function that is commented out. You can uncomment it in order to watch the search crawl through the grid. The following code will implement the A* algorithm that we will use for the rest of the section:</p>
<ol>
<li>First, we open the function by accepting a starting point, an end point, and a score:</li>
</ol>
<pre style="padding-left: 60px">def astar(start, end, h):<br/> """<br/> A-Star (or A*) search algorithm.<br/> Moves through nodes in a network<br/> (or grid), scores each node's<br/> neighbors, and goes to the node<br/> with the best score until it finds<br/> the end. A* is an evolved Dijkstra<br/> algorithm.<br/> """</pre>
<ol start="2">
<li>Now, we set up the sets that will track progress:</li>
</ol>
<pre style="padding-left: 60px"> # Closed set of nodes to avoid<br/> closed_set = set()<br/> # Open set of nodes to evaluate<br/> open_set = set()<br/> # Output set of path nodes<br/> path = set()</pre>
<ol start="3">
<li>Next, we begin processing using our starting point:</li>
</ol>
<pre style="padding-left: 60px"> # Add the starting point to<br/> # to begin processing<br/> open_set.add(start)<br/> while open_set:<br/> # Grab the next node<br/> cur = open_set.pop()</pre>
<ol start="4">
<li>If we hit the end, we return the completed path:</li>
</ol>
<pre style="padding-left: 60px"> # Return if we're at the end<br/> if cur == end:<br/> return path</pre>
<ol start="5">
<li>Otherwise, we keep working through the grid and eliminating possibilities:</li>
</ol>
<pre style="padding-left: 60px"> # Close off this node to future<br/> # processing<br/> closed_set.add(cur)<br/> # The current node is always<br/> # a path node by definition<br/> path.add(cur)</pre>
<ol start="6">
<li>To keep things moving, we grab all of the neighbors that need to be processed as we go:</li>
</ol>
<pre style="padding-left: 60px"> # List to hold neighboring<br/> # nodes for processing<br/> options = []<br/> # Grab all of the neighbors<br/> y1 = cur[0]<br/> x1 = cur[1]<br/> if y1 &gt; 0:<br/> options.append((y1-1, x1))<br/> if y1 &lt; h.shape[0]-1:<br/> options.append((y1+1, x1))<br/> if x1 &gt; 0:<br/> options.append((y1, x1-1))<br/> if x1 &lt; h.shape[1]-1:<br/> options.append((y1, x1+1))<br/> if x1 &gt; 0 and y1 &gt; 0:<br/> options.append((y1-1, x1-1))<br/> if y1 &lt; h.shape[0]-1 and x1 &lt; h.shape[1]-1:<br/> options.append((y1+1, x1+1))<br/> if y1 &lt; h.shape[0]-1 and x1 &gt; 0:<br/> options.append((y1+1, x1-1))<br/> if y1 &gt; 0 and x1 &lt; h.shape[1]-1:<br/> options.append((y1-1, x1+1))</pre>
<ol start="7">
<li>We check each neighbor for being the destination:</li>
</ol>
<pre style="padding-left: 60px"> # If the end is a neighbor, return<br/> if end in options:<br/> return path</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p class="mceNonEditable"/>
<p class="mceNonEditable"/>
<ol start="8">
<li>We take the first option as the <kbd>best</kbd> option and process the other options, upgrading as we go:</li>
</ol>
<pre style="padding-left: 60px"> # Store the best known node<br/> best = options[0]<br/> # Begin scoring neighbors<br/> best_score = weighted_score(cur, best, h, start, end)<br/> # process the other 7 neighbors<br/> for i in range(1, len(options)):<br/> option = options[i]<br/> # Make sure the node is new<br/> if option in closed_set:<br/> continue<br/> else:<br/> # Score the option and compare <br/> # it to the best known<br/> option_score = weighted_score(cur, option, <br/> h, start, end)<br/> if option_score &gt; best_score:<br/> best = option<br/> best_score = option_score<br/> else:<br/> # If the node isn't better seal it off<br/> closed_set.add(option)<br/> # Uncomment this print statement to watch<br/> # the path develop in real time:<br/> # print(best, e_dist(best, end))<br/> # Add the best node to the open set<br/> open_set.add(best)<br/>return []</pre>
<p>Now that we have our routing algorithm, we can generate a real-world path. </p>


            

            
        
    </div>



  
<div><h1 class="header-title">Generating a real-world path</h1>
                
            
            
                
<p class="mce-root">Finally, we create our real-world path as a chain of ones in a grid of zeros. This raster can then be brought into an application such as QGIS and visualized over the terrain grid. In the following code, we'll use our algorithm and helper functions to generate a path, as follows:</p>
<ol>
<li>First, we send our start and end points, as well as our terrain grid, to the routing function:</li>
</ol>
<pre style="padding-left: 60px">print("Searching for path...")<br/>p = astar((sy, sx), (dy, dx), cost)<br/>print("Path found.")<br/>print("Creating path grid...")<br/>path = np.zeros(cost.shape)<br/>print("Plotting path...")<br/>for y, x in p:<br/> path[y][x] = 1<br/>path[dy][dx] = 1<br/>print("Path plotted.")</pre>
<ol start="2">
<li>Once we have a path, we can save it out as an ASCII Grid:</li>
</ol>
<pre style="padding-left: 60px">print("Saving %s..." % target)<br/>header = ""<br/>for i in range(6):<br/> header += hdr[i]<br/><br/># Open the output file, add the hdr, save the array<br/>with open(target, "wb") as f:<br/> f.write(bytes(header, 'UTF-8'))<br/> np.savetxt(f, path, fmt="%4i")</pre>
<ol start="3">
<li>Now, we want to save our path data because the points are in the correct order, from the starting point to the end point. When we put them into the grid, we lose that order because it is all one raster. We'll use the built-in Python <kbd>pickle</kbd> module to save the list object to disk. We're going to use this data in the next section to create a vector shapefile of the route. So, we'll save our path data as a pickled Python object that we can reuse later, without running the whole program:</li>
</ol>
<pre style="padding-left: 60px">print("Saving path data...")<br/>with open("path.p", "wb") as pathFile:<br/> pickle.dump(p, pathFile)<br/>print("Done!")</pre>
<p>Here is the output route of our search:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/931aa6a2-3312-40cf-86c0-fb529190bf04.png" style="width:23.42em;height:17.42em;" width="780" height="577"/></p>
<p class="mce-root">As you can see, the A* search came very close to one of our manually selected routes. In a couple of cases, the algorithm chose to tackle some terrain, instead of trying to go around it. Sometimes the slight terrain is deemed less of a cost than the distance to go around it. You can see examples of that choice in this zoomed-in portion of the upper-right section of the route. The red line is the route that our program generated through the terrain:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/b4471f0d-911d-4874-9da1-fef9899f8455.png" style="width:21.33em;height:15.92em;" width="772" height="577"/></p>
<p class="mce-root">We only used two values: terrain and distance. But you could also add hundreds of factors, such as soil type, water bodies, and existing roads. All of these items could serve as an impedance or an outright wall. You would just modify the scoring function in the example to account for any additional factors. Keep in mind, the more factors you add, the more difficult it is to trace what the A* implementation was <em>thinking</em> when it chose the route.</p>
<p class="mce-root">An obvious future direction for this analysis would be to create a vector version of this route as a line. The process would include mapping each cell to a point and then using nearest-neighbor analysis to order the points properly, before saving it as a shapefile or GeoJSON file.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Converting the route to a shapefile</h1>
                
            
            
                
<p>The raster version of the least cost path route is useful for visualization, but it isn't much good for analysis because it is embedded in the raster, and it is, therefore, difficult to relate to other datasets as we have done so many other times in this book. Our next goal will be to use the path data that we saved when creating the route to create a shapefile since the saved data is in the proper order. The following code will convert our raster path to a shapefile that is easier to use in a GIS for analysis:</p>
<ol>
<li class="mce-root">First, we'll import the modules that we need, which aren't many. We'll use the <kbd>pickle</kbd> module to restore the path <kbd>data</kbd> object. Then, we'll use the <kbd>linecache</kbd> module to read the geospatial header information from the path raster in order to map the path rows and columns to the earth coordinates. Finally, we'll use the <kbd>shapefile</kbd> module to export the shapefile:</li>
</ol>
<pre style="padding-left: 60px">import pickle<br/>from linecache import getline<br/>import shapefile</pre>
<ol start="2">
<li>Next, we'll create a function to convert rows and columns to <em>x</em> and <em>y</em> coordinates. The function accepts the metadata header information from the path raster file, as well as the column and row number:</li>
</ol>
<pre style="padding-left: 60px">def pix2coord(gt,x,y):<br/> geotransform = gt<br/> ox = gt[2]<br/> oy = gt[3]<br/> pw = gt[4]<br/> ph = gt[4]<br/> cx = ox + pw * x + (pw/2)<br/> cy = oy + pw * y + (ph/2)<br/> return cx, cy</pre>
<ol start="3">
<li>Now, we'll restore the <kbd>path</kbd> object from the pickled object:</li>
</ol>
<pre style="padding-left: 60px">with open("path.p", "rb") as pathFile:<br/> path = pickle.load(pathFile)</pre>
<ol start="4">
<li>Then, we'll parse the metadata information from the path raster file:</li>
</ol>
<pre style="padding-left: 60px">hdr = [getline("path.asc", i) for i in range(1, 7)]<br/>gt = [float(ln.split(" ")[-1].strip()) for ln in hdr]</pre>
<ol start="5">
<li>Next, we need a list object to hold the converted coordinates:</li>
</ol>
<pre style="padding-left: 60px">coords = []</pre>
<ol start="6">
<li>Now, we convert each raster location from the least cost path object into a geospatial coordinate and store it in the list that we created:</li>
</ol>
<pre style="padding-left: 60px">for y,x in path:<br/> coords.append(pix2coord(gt,x,y))</pre>
<ol start="7">
<li>Finally, with just a few lines, we write out a line shapefile:</li>
</ol>
<pre style="padding-left: 60px">with shapefile.Writer("path", shapeType=shapefile.POLYLINE) as w:<br/> w.field("NAME")<br/> w.record("LeastCostPath")<br/> w.line([coords])</pre>
<p>Good work! You have created a program that can automatically navigate through obstacles, based on a set of rules, and exported it to a file that you can display and analyze in a GIS! We only used three rules, but you can add additional restrictions on how the program picks a path by adding other datasets, such as weather or water bodies, or anything else you can imagine.</p>
<p class="mce-root">Now that we understand blazing a path across an arbitrary surface, we'll look at routing through a network.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Calculating satellite image cloud cover</h1>
                
            
            
                
<p>Satellite images give us a powerful bird's-eye view of the Earth. They are useful for a variety of purposes, which we saw in <a href="13990656-5786-445c-878b-8b262ad6f3c0.xhtml">Chapter 6</a>, <em>Python and Remote Sensing</em>. However, they have one flaw—clouds. As a satellite passes around the Earth and collects imagery, it inevitably images clouds. And in addition to obstructing our view of the Earth, the cloud data can adversely affect remote sensing algorithms by wasting CPU cycles on useless cloud data, or skew the results by introducing unwanted data values.</p>
<p class="mce-root">The solution is to create a cloud mask. A cloud mask is a raster that isolates the cloud data in a separate raster. You can then use that raster as a reference when processing the image in order to avoid cloud data, or you can even use it to remove the clouds from the original image.</p>
<p class="mce-root">In this section, we'll create a cloud mask for a Landsat image using the <kbd>rasterio</kbd> module and the <kbd>rio-l8qa</kbd> plugin. The cloud mask will be created as a separate image that just contains clouds:</p>
<ol>
<li class="mce-root">First, we need to download some sample Landsat 8 satellite image data as a ZIP file from <a href="http://bit.ly/landsat8data">http://bit.ly/landsat8data</a>.</li>
<li class="mce-root">Click the download icon in the top right to download the data as a ZIP file, and unzip it to a directory named <kbd>l8</kbd>.</li>
<li class="mce-root">Next, make sure you have the raster libraries that we need by running <kbd>pip</kbd>:</li>
</ol>
<pre style="padding-left: 60px"><strong>pip install rasterio</strong><br/><strong>pip install rio-l8qa</strong></pre>
<ol start="4">
<li>Now, we'll create the cloud mask by first importing the libraries that we need:</li>
</ol>
<pre style="padding-left: 60px">import glob<br/>import os<br/>import rasterio<br/>from l8qa.qa import write_cloud_mask</pre>
<ol start="5">
<li>Next, we need to provide a reference to our satellite image directory:</li>
</ol>
<pre style="padding-left: 60px"># Directory containing landsat data<br/>landsat_dir = "l8"</pre>
<ol start="6">
<li>Now, we need to locate the quality-assurance metadata for the satellite data, which gives us the information that we need to generate the cloud mask:</li>
</ol>
<pre style="padding-left: 60px">src_qa = glob.glob(os.path.join(landsat_dir, '*QA*'))[0]</pre>
<ol start="7">
<li>Finally, we use the quality-assurance file to create a cloud mask TIFF file:</li>
</ol>
<pre style="padding-left: 60px">with rasterio.open(src_qa) as qa_raster:<br/> profile = qa_raster.profile<br/> profile.update(nodata=0)<br/> write_cloud_mask(qa_raster.read(1), profile, 'cloudmask.tif')</pre>
<p>The following image is just the band 7 (short-wave infrared) image from the Landsat 8 dataset:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/8ba31b2b-92f2-4011-8886-cb094f201bef.png" style="width:23.92em;height:24.33em;" width="760" height="771"/></p>
<p>The next image is the cloud mask image containing only the location of clouds and shadows:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/b1379f25-777b-405a-b3e8-f67fb7d071f3.png" style="width:25.33em;height:20.17em;" width="665" height="527"/></p>
<p>And finally, here's the mask over the image, showing the clouds as black:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/e4c9c790-616c-47ed-a00c-14016e0d066d.png" style="width:25.83em;height:26.33em;" width="756" height="771"/></p>
<p>This example brushes the surface of what you can do with image masking. Another <kbd>rasterio</kbd> module, <kbd>rio-cloudmask</kbd>, allows you to calculate the cloud mask from scratch without using the quality-assurance data. But it requires some additional pre-processing steps. You can learn more about that here: <a href="https://github.com/mapbox/rio-cloudmask">https://github.com/mapbox/rio-cloudmask.</a></p>


            

            
        
    </div>



  
<div><h1 class="header-title">Routing along streets</h1>
                
            
            
                
<p class="mce-root">Routing along streets uses a connected network of lines, which is called a graph. The lines in the graph can have impedance values, which discourage a routing algorithm from including them in a route. Examples of impedance values often include traffic volume, speed limit, or even distance. A key requirement for a routing graph is that all of the lines, known as edges, must be connected. Road datasets that are created for mapping will often have lines whose nodes do not intersect.</p>
<p class="mce-root">In this example, we'll calculate the shortest route through a graph by distance. We'll use a start and end point, which are not nodes in the graph, meaning we'll have to first find the graph nodes that are the closest to our start and destination points.</p>
<p class="mce-root">To calculate the shortest route, we'll use a powerful pure Python graph library called NetworkX. NetworkX is a general network graphing library that can create, manipulate, and analyze complex networks, including geospatial networks. If <kbd>pip</kbd> does not install NetworkX on your system, then you can find instructions for downloading and installing NetworkX for different operating systems at <a href="http://networkx.readthedocs.org/en/stable/">http://networkx.readthedocs.org/en/stable/</a>.</p>
<p class="mce-root">You can download the road network and the start and end points, which are located along the U.S. Gulf Coast, as a ZIP file from <a href="http://git.io/vcXFQ">http://git.io/vcXFQ</a>. Then, you can follow these steps:</p>
<ol>
<li class="mce-root">First, we'll need to import the libraries we're going to use. In addition to NetworkX, we’ll use the PyShp library in order to read and write shapefiles:</li>
</ol>
<pre style="padding-left: 60px">import networkx as nx<br/>import math<br/>from itertools import tee<br/>import shapefile<br/>import os</pre>
<ol start="2">
<li>Next, we'll define the current directory as our output directory for the route shapefile that we'll create:</li>
</ol>
<pre style="padding-left: 60px">savedir = "."</pre>
<ol start="3">
<li>Now, we’ll need a function that can calculate the distance between points in order to populate the impedance values of our graph and to find the nodes closest to our start and destination points for the route:</li>
</ol>
<pre style="padding-left: 60px">def haversine(n0, n1):<br/> x1, y1 = n0<br/> x2, y2 = n1<br/> x_dist = math.radians(x1 - x2)<br/> y_dist = math.radians(y1 - y2)<br/> y1_rad = math.radians(y1)<br/> y2_rad = math.radians(y2)<br/> a = math.sin(y_dist/2)**2 + math.sin(x_dist/2)**2 \<br/> * math.cos(y1_rad) * math.cos(y2_rad)<br/> c = 2 * math.asin(math.sqrt(a))<br/> distance = c * 6371<br/> return distance</pre>
<ol start="4">
<li>Then, we'll create another function, which returns pairs of points from a list, to give us the line segments that we'll use to build our graph edges:</li>
</ol>
<pre style="padding-left: 60px">def pairwise(iterable):<br/> """Return an iterable in tuples of two<br/> s -&gt; (s0,s1), (s1,s2), (s2, s3), ..."""<br/> a, b = tee(iterable)<br/> next(b, None)<br/> return zip(a, b)</pre>
<ol start="5">
<li>Now, we'll define our road network shapefile. This road network is a subset of a U.S. interstate highway files shapefile from the <strong>United States Geological Survey</strong> (<strong>USGS</strong>), which has been edited to ensure all the roads are connected:</li>
</ol>
<pre style="padding-left: 60px">shp = "road_network.shp"</pre>
<ol start="6">
<li>Next, we'll create a graph with NetworkX and add the shapefile segments as graph edges:</li>
</ol>
<pre style="padding-left: 60px">G = nx.DiGraph()<br/>r = shapefile.Reader(shp)<br/>for s in r.shapes():<br/> for p1, p2 in pairwise(s.points):<br/> G.add_edge(tuple(p1), tuple(p2))</pre>
<ol start="7">
<li>Then, we can extract the connected components as a subgraph. However, in this case, we've ensured that the entire graph is connected:</li>
</ol>
<pre style="padding-left: 60px">sg = list(nx.connected_component_subgraphs(G.to_undirected()))[0]</pre>
<ol start="8">
<li>Next, we can read in the <kbd>start</kbd> and <kbd>end</kbd> points that we want to navigate:</li>
</ol>
<pre style="padding-left: 60px">r = shapefile.Reader("start_end")<br/>start = r.shape(0).points[0]<br/>end = r.shape(1).points[0]</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<ol start="9">
<li>Now, we loop through the graph, and assign distance values to each edge, using our <kbd>haversine</kbd> formula:</li>
</ol>
<pre style="padding-left: 60px">for n0, n1 in sg.edges_iter():<br/> dist = haversine(n0, n1)<br/> sg.edge[n0][n1]["dist"] = dist</pre>
<ol start="10">
<li>Next, we must find the nodes in the graph that are the closest to our start and end points, in order to begin and end our route by looping through all of the nodes, and measuring the distance to our end points until we find the shortest distance:</li>
</ol>
<pre style="padding-left: 60px">nn_start = None<br/>nn_end = None<br/>start_delta = float("inf")<br/>end_delta = float("inf")<br/>for n in sg.nodes():<br/> s_dist = haversine(start, n)<br/> e_dist = haversine(end, n)<br/> if s_dist &lt; start_delta:<br/> nn_start = n<br/> start_delta = s_dist<br/> if e_dist &lt; end_delta:<br/> nn_end = n <br/> end_delta = e_dist</pre>
<ol start="11">
<li>Now, we are ready to calculate the shortest distance through our road network:</li>
</ol>
<pre style="padding-left: 60px">path = nx.shortest_path(sg, source=nn_start, target=nn_end, weight="dist")</pre>
<ol start="12">
<li>Finally, we'll add the results to the shapefile and save our route:</li>
</ol>
<pre style="padding-left: 60px">w = shapefile.Writer(shapefile.POLYLINE)<br/>w.field("NAME", "C", 40)<br/>w.line(parts=[[list(p) for p in path]])<br/>w.record("route")<br/>w.save(os.path.join(savedir, "route"))</pre>
<p>The following screenshot shows the road network in light gray, the start and end points, and the route in black. You can see that the route cuts across the road network in order to reach the road that is the nearest to the end point in the shortest possible distance:</p>
<p class="mce-root"/>
<p class="CDPAlignCenter CDPAlign"><img src="img/76184867-4eac-4033-a072-0e4d76b85f28.png" style="width:18.75em;height:14.58em;" width="645" height="501"/></p>
<p>Now that we know how to create various types of routes, we can look at locating photos that you might take while traveling along a route.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Geolocating photos</h1>
                
            
            
                
<p class="mce-root">Photos that are taken with GPS-enabled cameras, including smartphones, store location information in the header of the file in a format called <strong>EXIF</strong> tags. These tags are based largely on the same header tags that are used by the TIFF image standard. In this example, we'll use those tags to create a shapefile with point locations for the photos, and file paths to the photos, as attributes.</p>
<p class="mce-root"/>
<p class="mce-root">We’ll use the PIL in this example because it has the ability to extract EXIF data. Most photos that are taken with smartphones are geotagged images; however, you can download the set used in this example from <a href="http://git.io/vczR0">https://git.io/vczR0</a>:</p>
<ol>
<li class="mce-root">First, we'll import the libraries that we need, including PIL for the image metadata and PyShp for the shapefiles:</li>
</ol>
<pre style="padding-left: 60px">import glob<br/>import os<br/>try:<br/> import Image<br/> import ImageDraw<br/>except ImportError:<br/> from PIL import Image<br/> from PIL.ExifTags import TAGS<br/>import shapefile</pre>
<ol start="2">
<li>Now, we'll need three functions. The first function extracts the EXIF data. The second function converts <strong>degree, minutes, seconds</strong> (<strong>DMS</strong>) coordinates to decimal degrees (EXIF data stores GPS data as DMS coordinates). The third function extracts the GPS data and performs the coordinate conversion:</li>
</ol>
<pre style="padding-left: 60px">def exif(img):<br/> # extract exif data.<br/> exif_data = {}<br/> try: <br/> i = Image.open(img)<br/> tags = i._getexif()<br/> for tag, value in tags.items():<br/> decoded = TAGS.get(tag, tag)<br/> exif_data[decoded] = value<br/> except:<br/> pass<br/> return exif_data<br/><br/>def dms2dd(d, m, s, i):<br/> # convert degrees, min, sec to decimal degrees<br/> sec = float((m * 60) + s)<br/> dec = float(sec / 3600)<br/> deg = float(d + dec)<br/> if i.upper() == 'W':<br/> deg = deg * -1<br/> elif i.upper() == 'S':<br/> deg = deg * -1<br/> return float(deg)<br/><br/>def gps(exif):<br/> # get gps data from exif<br/> lat = None<br/> lon = None<br/> if exif['GPSInfo']: <br/> # Lat<br/> coords = exif['GPSInfo']<br/> i = coords[1]<br/> d = coords[2][0][0]<br/> m = coords[2][1][0]<br/> s = coords[2][2][0]<br/> lat = dms2dd(d, m, s, i)<br/> # Lon<br/> i = coords[3]<br/> d = coords[4][0][0]<br/> m = coords[4][1][0]<br/> s = coords[4][2][0]<br/> lon = dms2dd(d, m, s, i)<br/> return lat, lon</pre>
<ol start="3">
<li>Next, we will loop through the photos, extract the coordinates, and store the coordinates and filename in a dictionary:</li>
</ol>
<pre style="padding-left: 60px">photos = {}<br/>photo_dir = "./photos"<br/>files = glob.glob(os.path.join(photo_dir, "*.jpg"))<br/>for f in files:<br/> e = exif(f)<br/> lat, lon = gps(e)<br/> photos[f] = [lon, lat]</pre>
<ol start="4">
<li>Now, we will save the photo information as a shapefile:</li>
</ol>
<pre style="padding-left: 60px">with shapefile.Writer("photos", shapefile.POINT) as w:<br/>    w.field("NAME", "C", 80)<br/>    for f, coords in photos.items():<br/>        w.point(*coords)<br/>        w.record(f)</pre>
<p>The filenames of the photos in the shapefile are now attributes of the point locations where the photos were taken. GIS programs including QGIS and ArcGIS have the tools to turn those attributes into links when you click on the photo path or the point. The following screenshot from QGIS shows that one of the photos opens after clicking on the associated point using the Run Feature Action tool:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/f2c3918e-5f85-4a8f-aa32-2da3fcf5192e.png" width="1008" height="662"/></p>
<p>To view the result, please use the following instructions:</p>
<ol>
<li>Download QGIS from <a href="http://qgis.org">https://qgis.org</a> and follow the installation instructions.</li>
<li>Open QGIS and drag the <kbd>photos.shp</kbd> file onto the blank map.</li>
<li>In the Layer panel on the left, right-click the layer named Photos and select Properties.</li>
<li>On the Actions tab, click the green plus sign to open the new actions dialog.</li>
<li>In the Type drop-down menu, select Open.</li>
<li>In the Description field, enter Open Image.</li>
<li>Click the Insert button in the lower-right corner.</li>
<li>Click the OK button, and then close the properties dialog.</li>
</ol>
<ol start="9">
<li>Click on the small black arrow to the right of the Run Feature Action tool, which is a gear icon with a green center and a white arrow in it.</li>
<li>In the menu that pops up, choose Open Image.</li>
<li>Now, click on one of the points on the map to see the geotagged image popup.</li>
</ol>
<p>Now, let's move from an image taken on the Earth, to images taken of the Earth itself, by working with satellite images.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Summary</h1>
                
            
            
                
<p class="mce-root">In this chapter, we learned how to create three real-world products, which are used every day in government, science, and industry. Apart from where this analysis is typically done with <strong>black box</strong> packages—costing thousands of dollars—we were able to use very minimal and free cross-platform Python tools. And in addition to the examples in this chapter, you now have some more reusable functions, algorithms, and processing frameworks for other advanced analyses, which will allow you to solve new problems that you come across in fields such as transportation, agriculture, and weather.</p>
<p class="mce-root">In the next chapter, we'll move into a relatively new area of geospatial analysis: real-time and near real-time data.</p>


            

            
        
    </div>



  </body></html>