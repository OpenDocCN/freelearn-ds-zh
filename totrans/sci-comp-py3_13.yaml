- en: Chapter 13. Testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will focus on two aspects of testing for scientific programming.
    The first aspect is the often difficult topic of what to test in scientific computing.
    The second aspect covers the question of how to test. We will distinguish between
    manual and automated testing. Manual testing is what is done by every programmer
    to quickly check that an implementation is working or not. Automated testing is
    the refined, automated variant of that idea. We will introduce some tools available
    for automatic testing in general, with a view on the particular case of scientific
    computing.
  prefs: []
  type: TYPE_NORMAL
- en: Manual testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: During the development of code, you do a lot of small tests in order to test
    its functionality. This could be called manual testing. Typically, you would test
    if a given function does what it is supposed to do, by manually testing the function
    in an interactive environment. For instance, suppose that you implement the bisection
    algorithm. It is an algorithm that finds a zero (root) of a scalar non-linear
    function. To start the algorithm, an interval has to be given with the property
    that the function takes different signs on the interval boundaries, see *Exercise
    4*, [Chapter 7](ch07.html "Chapter 7. Functions"), *Functions*, for more information.
  prefs: []
  type: TYPE_NORMAL
- en: 'You will then test an implementation of that algorithm, typically by checking
    that:'
  prefs: []
  type: TYPE_NORMAL
- en: A solution is found when the function has opposite signs at the interval boundaries
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An exception is raised when the function has the same sign at the interval boundaries
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Manual testing, as necessary as it may seem to be, is unsatisfactory. Once you
    have convinced yourself that the code does what it is supposed to do, you formulate
    a relatively small number of demonstration examples to convince others of the
    quality of the code. At that stage, one often looses interest in the tests made
    during development and they are forgotten or even deleted. As soon as you change
    a detail and things no longer work correctly, you might regret that your earlier
    tests are no longer available.
  prefs: []
  type: TYPE_NORMAL
- en: Automatic testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The correct way to develop any piece of code is to use automatic testing. The
    advantages are:'
  prefs: []
  type: TYPE_NORMAL
- en: The automated repetition of a large number of tests after every code refactoring and
    before any new versions are launched.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A silent documentation of the use of the code.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A documentation of the test coverage of your code: Did things work before a
    change or was a certain aspect never tested?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Changes in the program and in particular in its structure which do not affect
    its functionality are called code refactoring.
  prefs: []
  type: TYPE_NORMAL
- en: We suggest developing tests in parallel to the code. Good design of tests is
    an art of its own and there is rarely an investment which guarantees such a good
    pay-off in development time savings as the investment in good tests.
  prefs: []
  type: TYPE_NORMAL
- en: Now we will go through the implementation of a simple algorithm with the automated
    testing methods in mind.
  prefs: []
  type: TYPE_NORMAL
- en: Testing the bisection algorithm
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let us examine automated testing for the bisection algorithm. With this algorithm,
    a zero of a real valued function is found. It is described section *Exercise 4*
    in [Chapter 7](ch07.html "Chapter 7. Functions"), *Functions*. An implementation
    of the algorithm can have the following form:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'We assume this to be stored in the `bisection.py` file. As the first test case,
    we test that the zero of the function *f*(*x*) = *x* is found:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: In this code, you meet the Python keyword `assert` for the first time. It raises `AssertionError`
    exception if its first argument returns the `False` value. Its optional second
    argument is a string with additional information. We use the function `allclose`
    in order to test for equality of floats.
  prefs: []
  type: TYPE_NORMAL
- en: Let us comment on some of the features of the test function. We use an assertion
    to make sure that an exception will be raised if the code does not behave as expected.
    We have to manually run the test in the `test_identity()` line.
  prefs: []
  type: TYPE_NORMAL
- en: There are many tools to automate this kind of call.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us now set up a test that checks if `bisect` raises an exception when the
    function has the same sign on both ends of the interval. For now, we will suppose
    that the exception raised is a `ValueError` exception. In the following example,
    we will check the initial interval [*a*,*b*]. For the bisection algorithm it should
    fulfill a sign condition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: In this case, an `AssertionError` is raised if the exception is not of the `ValueError` type
    . There are tools to simplify the preceding construction to check that an exception
    is raised.
  prefs: []
  type: TYPE_NORMAL
- en: Another useful test is the edge case test. Here we test arguments or user input,
    which is likely to create mathematically undefined situations or states of the
    program not foreseen by the programmer. For instance, what happens if both bounds
    are equal? What happens if *a > b*?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Using unittest package
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The standard `unittest` Python package greatly facilitates automated testing.
    This package requires that we rewrite our tests to be compatible. The first test
    would have to be rewritten in a `class`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s examine the differences to the previous implementation. First, the test
    is now a method and a part of a class. The class must inherit from `unittest.TestCase`.
    The test method''s name must start with `test`. Note that we may now use one of
    the assertion tools of the `unittest` package, namely `assertAlmostEqual`. Finally,
    the tests are run using `unittest.main`. We recommend to write the tests in a
    file separate from the code to be tested. That is why it starts with an `import`.
    The test passes and returns as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'If we run it with a loose tolerance parameter, for example, `1.e-3`, a failure
    of the test would have been reported:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Tests can and should be grouped together as methods of a test class, as given
    in the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Here, in the last test we used the method `unittest.TestCase.assertRaises`.
    It tests whether an exception is correctly raised. Its first parameter is the
    exception type, for example, `ValueError`, `Exception`, and its second argument
    is the name of the function, which is expected to raise the exception. The remaining
    arguments are the arguments for this function. The command `unittest.main()` creates
    an instance of the `TestIdentity` class and executes those methods starting with `test`.
  prefs: []
  type: TYPE_NORMAL
- en: Test setUp and tearDown methods
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The class `unittest.TestCase` provides two special methods, `setUp` and `tearDown`,
    which run before and after every call to a test method. This is needed when testing
    generators, which are exhausted after every test. We demonstrate this by testing
    a program which checks the line in a file in which a given string occurs for the
    first time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'We assume that this code is saved in the `find_in_file.py` file. A test has
    to prepare a file and open it and remove it after the test as given in the following
    example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Before each test `setUp` is run and then `tearDown` is executed.
  prefs: []
  type: TYPE_NORMAL
- en: Parameterizing tests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'One frequently wants to repeat the same test with different data sets. When
    using the functionalities of `unittest` this requires us to automatically generate
    test cases with the corresponding methods injected:'
  prefs: []
  type: TYPE_NORMAL
- en: To this end, we first construct a test case with one or several methods that
    will be used, when we later set up test methods. Let's consider the bisection
    method again and let's check if the values it returns are really zeros of the
    given function.
  prefs: []
  type: TYPE_NORMAL
- en: 'We first build the test case and the method which we will use for the tests
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we dynamically create test functions as attributes of this class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: In this example, the data is provided as a list of dictionaries. The `make_test_function`
    function dynamically generates a test function, which uses a particular data dictionary
    to perform the test with the previously defined method `checkifzero`. Finally,
    the command `setattr` is used to make these test functions methods of the class
    `Tests`.
  prefs: []
  type: TYPE_NORMAL
- en: Assertion tools
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we collect the most important tools for raising an `AssertionError`.
    We saw the `assert` command and two tools from `unittest`, namely `assertAlmostEqual`. The
    following table (*Table 13.1*) summarizes the most important assertion tools and
    the related modules:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Assertion tool and application example** | **Module** |'
  prefs: []
  type: TYPE_TB
- en: '| `assert 5==5` | – |'
  prefs: []
  type: TYPE_TB
- en: '| `assertEqual(5.27, 5.27)` | `unittest.TestCase` |'
  prefs: []
  type: TYPE_TB
- en: '| `assertAlmostEqual(5.24, 5.2,places = 1)` |  `unittest.TestCase` |'
  prefs: []
  type: TYPE_TB
- en: '| `assertTrue(5 > 2)` | `unittest.TestCase` |'
  prefs: []
  type: TYPE_TB
- en: '| `assertFalse(2 < 5)` | `unittest.TestCase` |'
  prefs: []
  type: TYPE_TB
- en: '| `assertRaises(ZeroDivisionError,lambda x: 1/x,0.)` | `unittest.TestCase`
    |'
  prefs: []
  type: TYPE_TB
- en: '| `assertIn(3,{3,4})` | `unittest.TestCase` |'
  prefs: []
  type: TYPE_TB
- en: '| `assert_array_equal(A,B)` | `numpy.testing` |'
  prefs: []
  type: TYPE_TB
- en: '| `assert_array_almost_equal(A, B, decimal=5)` | `numpy.testing` |'
  prefs: []
  type: TYPE_TB
- en: '| `assert_allclose(A, B, rtol=1.e-3,atol=1.e-5)` | `numpy.testing` |'
  prefs: []
  type: TYPE_TB
- en: 'Table 13.1: Assertion tools in Python, unittest and NumPy'
  prefs: []
  type: TYPE_NORMAL
- en: Float comparisons
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Two floating point numbers should not be compared with the `==` comparison,
    because the result of a computation is often slightly off due to rounding errors.
    There are numerous tools to test equality of floats for testing purposes. First,
    `allclose` checks that two arrays are almost equal. It can be used in a test function,
    as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, `self` refers to a `unittest.Testcase` instance. There are also testing
    tools in the `numpy` package `testing`. These are imported by using:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Testing that two scalars or two arrays are equal is done using `numpy.testing.assert_array_allmost_equal`
    or `numpy.testing.assert_allclose`. These methods differ in the way they describe
    the required accuracy, as shown in the preceding table.
  prefs: []
  type: TYPE_NORMAL
- en: '*QR* factorization decomposes a given matrix into a product of an orthogonal
    matrix *Q* and an upper triangular matrix *R* as given in the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Is the method applied correctly? We can check this by verifying that *Q* is
    indeed an orthogonal matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Furthermore, we might perform a sanity test by checking if *A = QR*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'All this can be collected into a `unittest` test case as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Note in `assert_allclose` the parameter `atol` defaults to zero, which often
    causes problems, when working with matrices having small elements.
  prefs: []
  type: TYPE_NORMAL
- en: Unit and functional tests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Up to now, we have only used functional tests. A functional test checks whether
    the functionality is correct. For the bisection algorithm, this algorithm actually
    finds a zero when there is one. In that simple example, it is not really clear
    what a unit test is. Although, it might seem slightly contrived, it is still possible
    to make a unit test for the bisection algorithm. It will demonstrate how unit
    testing often leads to more compartmentalized implementation.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, in the bisection method, we would like to check, for instance, that at
    each step the interval is chosen correctly. How to do that? Note that it is absolutely
    impossible with the current implementation, because the algorithm is hidden inside
    the function. One possible remedy is to run only one step of the bisection algorithm.
    Since all the steps are similar, we might argue that we have tested all the possible
    steps. We also need to be able to inspect the current bounds `a` and `b` at the
    current step of the algorithm. So we have to add the number of steps to be run
    as a parameter and change the return interface of the function. We will do that
    as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that we have to change the existing unit tests in order to accommodate
    for that change. We may now add a unit test as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Debugging
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Debugging is sometimes necessary while testing, in particular if it is not immediately
    clear why a given test does not pass. In that case, it is useful to be able to
    debug a given test in an interactive session. This is however, made difficult
    by the design of the `unittest.TestCase` class, which prevents easy instantiation
    of test case objects. The solution is to create a special instance for debugging
    purpose only.
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose that, in the example of the `TestIdentity` class above, we want to
    test the `test_functionality` method. This would be achieved as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Now this test can be run individually by:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: This will run this individual test and it allows for debugging.
  prefs: []
  type: TYPE_NORMAL
- en: Test discovery
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you write a Python package, various tests might be spread out through the
    package. The `discover` module finds, imports, and runs these test cases. The
    basic call from the command line is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'It starts looking for test cases in the current directory and recurses the
    directory tree downward to find Python objects with the `''test''` string contained
    in its name. The command takes optional arguments. Most important are `-s` to
    modify the start directory and `-p` to define the pattern to recognize the tests:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Measuring execution time
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In order to take decisions on code optimization, one often has to compare several
    code alternatives and decide which code should be preferred based on the execution
    time. Furthermore, discussing execution time is an issue when comparing different
    algorithms. In this section, we present a simple and easy way to measure execution
    time.
  prefs: []
  type: TYPE_NORMAL
- en: Timing with a magic function
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The easiest way to measure the execution time of a single statement is to use
    IPython’s magic function `%timeit`.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The shell IPython adds additional functionality to standard Python. These extra
    functions are called magic functions.
  prefs: []
  type: TYPE_NORMAL
- en: 'As the execution time of a single statement can be extremely short, the statement
    is placed in a loop and executed several times. By taking the minimum measured
    time, one makes sure that other tasks running on the computer do not influence
    the measured result too much. Let''s consider four alternative ways to extract
    nonzero elements from an array as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Measuring time with IPython’s magic function `%timeit` gives the following
    result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: The parameter `-n` controls how often the statement is executed before time
    is measured and the `-r` parameter controls the number of repetitions.
  prefs: []
  type: TYPE_NORMAL
- en: Timing with the Python module timeit
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Python provides a `timeit` module, which can be used to measure execution time.
    It requires that first a time object is constructed. It is constructed from two
    strings, a string with setup commands and a string with the commands to be executed.
    We take the same four alternatives as in the preceding example. The array and
    function definitions are written now in a string called `setup_statements` and
    four-time objects are constructed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'The timer objects have a `repeat` method . It takes `repeat` and `number` parameters.
    It executes the statement of the timer object in a loop, measures the time, and
    repeats this experiment corresponding to the `repeat` parameter:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We continue the preceding example and measure execution times as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: In contrast to the method in the preceding example, we obtain lists of all the
    obtained measurements. As computing time may vary depending on the overall load
    of the computer, the minimal value in such a list can be considered a good approximation
    to the computation time necessary to execute the statement.
  prefs: []
  type: TYPE_NORMAL
- en: Timing with a context manager
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Finally, we present the third method. It serves to show another application
    of a context manager. We first construct a context manager object for measuring
    the elapsed time as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Recall that the `_ _enter_ _` and `_ _exit_ _` methods make this class a context
    manager. The `_ _exit_ _` method’s parameters `ty`, `val`, and `tb` are in the
    normal case `None`. If an exception is raised during execution, they take the
    exception type, its value, and traceback information. The `return False` indicates
    that the exception has not been caught so far.
  prefs: []
  type: TYPE_NORMAL
- en: 'We now show the use of the context manager to measure the execution time of
    the four alternatives in the previous example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: This will then display a message like `Time elapsed 15.0129795074 ms`.
  prefs: []
  type: TYPE_NORMAL
- en: 'If the timing result should be accessible in a variable, the `enter` method
    must return the `Timer` instance (uncomment the `return` statement) and a `with
    ... as ...` construction has to be used:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: No program development without testing! We showed the importance of well organized
    and documented tests. Some professionals even start development by first specifying
    tests. A useful tool for automatic testing is the module `unittest`, which we
    explained in detail. While testing improves the reliability of a code, profiling
    is needed to improve the performance. Alternative ways to code may result in large
    performance differences. We showed how to measure computation time and how to
    localize bottlenecks in your code.
  prefs: []
  type: TYPE_NORMAL
- en: Exercises
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Ex. 1** → Two matrices *A*, *B* are called similar, if there exists a matrix
    *S*, such that *B = S^(-1) A S*. *A* and *B* have the same eigenvalues. Write
    a test checking that two matrices are similar, by comparing their eigenvalues.
    Is it a functional or a unit test?'
  prefs: []
  type: TYPE_NORMAL
- en: '**Ex. 2** → Create two vectors of large dimension. Compare the execution time
    of various ways to compute their `dot` product:'
  prefs: []
  type: TYPE_NORMAL
- en: 'SciPy function: `dot(v,w)`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Generator and sum: `sum((x*y for x,y in zip(v,w)))`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Comprehensive list and sum: `sum([x*y for x,y in zip(v,w)])`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Ex. 3** → Let *u* be a vector. The vector *v* with components'
  prefs: []
  type: TYPE_NORMAL
- en: '![Exercises](img/moveaverage.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'is called a moving average of *u*. Determine which of the two alternatives
    to compute *v* is faster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: or
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
