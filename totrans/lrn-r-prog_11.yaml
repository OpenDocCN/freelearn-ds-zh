- en: Chapter 11. Working with Databases
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, you learned the basic concepts of object-oriented programming.
    These include class and methods, and how they are connected by generic functions
    in R through method dispatch. You learned about the basic usage of S3, S4, RC,
    and R6, including defining classes and generic functions as well as implementing
    methods for certain classes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have covered most of the important features of R, it is time we
    go ahead and discuss more practical topics. In this chapter, we will begin the
    discussion with how R can be used to work with databases, which is perhaps the
    first step of many data-analysis projects: extracting data from a database. More
    specifically, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding relational databases
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using SQL to query relational databases such as SQLite and MySQL
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Working with NoSQL databases such as MongoDB and Redis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Working with relational databases
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapters, we used a family of built-in functions such as `read.csv`
    and `read.table` to import data from separator-delimited files, such as those
    in the csv format. Using text formats to store data is handy and portable. When
    the data file is large, however, such a storage method may not be the best way.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are three main reasons why text formats can no longer be easy to use.
    They are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Functions such as `read.csv()` are mostly used to load the whole file into memory,
    that is, a data frame in R. If the data is too large to fit into the computer
    memory, we simply cannot do it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Even if the dataset is large, we usually don't have to load the whole dataset
    into memory when we work on a task. Instead, we often need to extract a subset
    of the dataset that meets a certain condition. The built-in data-importer functions
    simply do not support querying a csv file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The dataset is still updating, that is, we need to insert records into the dataset
    periodically. If we use the csv format, inserting data can be painful, especially
    if we want to insert the records in the middle of the file and keep it in order.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Using a database is the best solution for these scenarios. It makes it much
    easier to store data that may exceed computer memory. Data in a database is queryable
    subject to user-supplied condition, which also makes it easier to update existing
    records and insert new records within a database.
  prefs: []
  type: TYPE_NORMAL
- en: A relational database is a collection of tables and relations between tables.
    A table in a relational database has the same representation with a data frame
    in R. Tables can have relations that make it easier to join the information of
    multiple tables.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will start from the simplest database, SQLite ([http://sqlite.org/](http://sqlite.org/)),
    a portable, lightweight database engine.
  prefs: []
  type: TYPE_NORMAL
- en: 'To work with SQLite databases in R, we will use the `RSQLite` package. To install
    it from CRAN, run the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Creating a SQLite database
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'First, let''s see how to create a SQLite database. If we want to create an
    example database at `data/example.sqlite`, we need to ensure that the directory
    is available. If the directory does not exist, we have to create one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, the `data/` directory is available. Next, we will load the `RSQLite` package
    and create a connection by supplying a database driver (`SQLite()`) and database
    file (`data/example.sqlite`). Although the file does not exist, the driver creates
    an empty file that is an empty SQLite database:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The database connection, `con`, is a layer between the user and the system.
    We can create a connection to a relational database and query, fetch, or update
    data through it. The connection will be used in all subsequent operations until
    we close the connection. In a typical relational database, we can create tables
    with a name and columns of certain names and data types, insert records as rows
    to a table, and update existing records. A table in a relational database looks
    very similar to a data frame in R.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we will create a simple data frame that is to be inserted as a table to
    the database:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The data frame is ready and we will call `dbWriteTable()` to write this data
    frame as a table to the database:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code, we may well use other table names but still store the
    same data. Finally, we will disconnect the database using `dbDisconnect()` so
    that `con` is no longer available for data operations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Writing multiple tables to a database
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A SQLite database is a collection of tables. Therefore, we can store many tables
    in one database.
  prefs: []
  type: TYPE_NORMAL
- en: 'This time, we put the `diamonds` dataset in `ggplot2` and the `flights` dataset
    in `nycflights13` as two tables into one database. If you haven''t installed these
    two packages, run the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'When the packages are available, we will call `data()` to load the two data
    frames:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'We will repeat the same operation as we did earlier, but `dbWriteTable()` ends
    up with errors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'It can be useful to take a look at the class of these two variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that `diamonds` and `flights` are not simply of class `data.frame` but
    something more complex. To write them into the database, we need to convert them
    to plain `data.frame` objects using `as.data.frame()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Now, the database contains two tables.
  prefs: []
  type: TYPE_NORMAL
- en: Appending data to a table
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'As mentioned in the beginning of this section, appending records to a table
    in the database is fairly easy. Here is a simple example where we produce several
    chunks of data and append them to a database table in turn:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Note that each chunk is a data frame with some determined data and some random
    numbers. Each time, we append these records to a table named `products`. The difference
    between this example and the previous ones is that when we call `dbWriteTable()`,
    we use `append = FALSE` for the first chunk to create that table in the database
    and use `append = TRUE` for each subsequent chunk to append to the existing table.
  prefs: []
  type: TYPE_NORMAL
- en: Accessing tables and table fields
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Once we have a SQLite database, we can access not only the data we store in
    the tables, but also some metadata, such as the names of all tables and the columns
    of a table.
  prefs: []
  type: TYPE_NORMAL
- en: 'To demonstrate, we will connect to the SQLite database we created previously:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'We can use `dbExistsTable()` to detect whether a table exists in the database:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Since we only wrote `diamonds` and `flights` in `datasets.sqlite` previously,
     `dbExistsTable()` returns the correct values. On the contrary to detecting table
    existence, we can use `dbListTables()` to list all the existing tables in the
    database:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'For a certain table, we can also list the names of all columns (or fields)
    with `dbListFields()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Contrary to `dbWriteTable()`, `dbReadTable()` reads the whole table into a
    data frame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'We can make a comparison between the data frame (`db_diamonds`) we read from
    the database and the original version (`diamonds`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The data in both data frames looks exactly the same. However, if we use `identical()`
    to compare them, they are not really identical:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'To spot the difference, we can call `str()` to reveal the structure of both
    data frames. First, here is the structure of the data frame in the database:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, here is the structure of the original version:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Now, the difference is obvious. In the original version, `cut`, `color`, and `clarity`
    are ordered factor variables that are essentially integers with some metadata
    (ordered levels). By contrast, in the database version, these columns are stored
    as text instead. This change is simply because SQLite does not have built-in support
    of ordered factors. Therefore, except for common data types (numbers, texts, logical,
    and so on), R-specific types will be converted to types supported by SQLite before
    the data frame is inserted.
  prefs: []
  type: TYPE_NORMAL
- en: Learning SQL to query relational databases
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the previous section, you learned how to write data into a SQLite database.
    In this section, you will learn how to query such a database so that we can get
    data from it according to our needs. We'll use `data/datasets.sqlite` (we created
    previously) in the following examples.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we need to establish a connection to the database:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'There are two tables in the database. Then, we can select all data from `diamonds`
    using the `select` statement. Here, we want to select all columns (or fields).
    So, we will call `dbGetQuery()` with the database connection, `con`, and a query
    string:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that `*` means all fields (or, equivalently, columns). If we only need
    a subset of fields, we can name the fields in turn:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'If we want to select all distinct cases that appear in the data, we can use
    `select distinct`. For example, the following code returns all distinct values
    of `cut` in `diamonds`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that `dbGetQuery()` always returns `data.frame`, even though sometimes
    there is only one column. To retrieve the values as an atomic vector, just extract
    the first column from the data frame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'When we use `select` to select columns to query, sometimes, the column name
    is not exactly what we want. In this case, we can use `A as B` to get column `B`
    with the same data as `A`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'In some other cases, the value we want is not present in the database, but
    needs some calculation to figure out. Now, we will use `A as B` in which `A` can
    be an arithmetic calculation between existing columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: What if we create a new column with existing columns and create another column
    with the new column, just like the following example?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'We simply can''t do this. In `A as B`, `A` must be composed of existing columns.
    However, if we insist on doing so, we can use nested query, that is, we `select`
    columns from a temporary table produced by a nested `select`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: In this case, `size` is defined in the temporary table when `price` /`size`
    is being computed.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next important component of a database query is a condition. We can use
    `where` to specify the conditions that the results must satisfy. For example,
    we can select diamonds with `Good` cut:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that records with good cut are only a small proportion of all records:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'If we have multiple conditions that must be met simultaneously, we can use
    `and` to combine these conditions. For example, we will select all records with `Good`
    cut and color `E`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Similar logical operations also include `or` and `not`.
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition to the simple logical operations, we can also use `in` to filter
    records by examining whether the value of a field is contained in a given set.
    For example, we can select records with colors `E` and `F`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'We can verify the result by the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'To use `in`, we need to specify a set. Similar to `in`, we can also use `between
    and` which that allow us to specify a range:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: In fact, the range does not have to be numeric. As long as the data type of
    the field is comparable, we can specify a range. For string column, we can write
    `between 'string1' to 'string2'` to filter records by lexical ordering.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another useful operator for string column is `like`, which enables us to filter
    records with simple string patterns. For example, we can select all records with
    a `cut` variable that ends with `Good`. It can be either `Good` or `Very Good`.
    The notation is `like ''%Good''` where `%` matches all strings:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Another major functionality of database query is sorting data with specified
    columns. We can do this with `order by`. For example, we can get the `carat` and `price`
    of all records but in an ascending order of `price`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Therefore, we have a data frame of diamonds that is ordered from the cheapest
    to the most expensive ones:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'We can do the opposite by adding `desc` to the sorting column so that we get
    a data frame that is ordered in the opposite way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also sort the records with more than one column. For example, the following
    results are sorted by price in the ascending order first. If two records have
    equal price, the one with greater carat will be put ahead:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Like `select`, the column to sort can be computed from existing columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also query the sorted subset of all records using `where` and `order
    by` at the same time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'If we only care about the first several results, we can use `limit` to constrain
    the number of records to retrieve:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'In addition to column selection, conditional filtering, and sorting, we can
    also aggregate the records in database in groups. For example, we can count the
    number of records for each color:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'The results can be verified by calling `table()` with the original data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'In addition to counting, we also have aggregating functions such as `avg()`, `max()`, `min()`,
    and `sum()`. For example, we can summarize the data by looking at the average
    price for each level of clarity:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also examine the maximal carat at the five lowest prices:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also perform multiple calculations in a group. The following code calculates
    the range of prices and their average value for each clarity level:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'The following example calculates an average price for each clarity level weighted
    by carat, that is, a price with greater carat has more weight:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'Just like sorting with more than one column, we can also group the data by
    multiple columns. The following code computes the average price for each clarity
    and color pair, and shows the top five pairs with the highest average prices:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'The most relational operation in a relational database should be table join,
    that is, joining a number of tables together by some columns. For example, we
    will create a data frame of `cut`, `color`, and `clarity` to select records with
    exactly the same field values of the three cases in `diamond_selector`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'After creating the data frame, we write it to the database so that we can join
    `diamonds` and `diamond_selector` to filter the desirable records:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'We can specify the columns to match in the join-clause:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'In total, we have only a tiny portion of all records that satisfy one of the
    three cases:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, don''t forget to disconnect the database to ensure that all resources
    are properly released:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: In the previous examples, we only showed the basic use of SQL to query a relational
    database such as SQLite. In fact, SQL is richer and much more powerful than we
    have demonstrated. For more details, visit [http://www.w3schools.com/sql](http://www.w3schools.com/sql)
    and learn more.
  prefs: []
  type: TYPE_NORMAL
- en: Fetching query results chunk by chunk
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the beginning of the section, we mentioned that one of the advantages of
    using a relational database is that we can store a large amount of data. Usually,
    we only take out a subset of the database and do some research. However, sometimes,
    we need to go through an amount of data that exceeds the capacity of computer
    memory. Obviously, we cannot load all of the data into memory, but must process
    the data chunk by chunk.
  prefs: []
  type: TYPE_NORMAL
- en: 'Most reasonable relational databases support fetching a query result set chunk
    by chunk. In the following example, we will use `dbSendQuery()` instead of `dbGetQuery()`
    to get a result set. Then, we will repeat fetching chunks (a number of rows) from
    the result set until all results are fetched. In this way, we can process the
    data chunk by chunk without using a large amount of working memory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: In practice, the database may have billions of records. The query may result
    in tens of millions of records. If you use `dbGetQuery()` to fetch the whole result
    set at once, your memory may not be sufficient. If the task can be finished by
    processing data chunks, it can be much cheaper to work chunk by chunk.
  prefs: []
  type: TYPE_NORMAL
- en: Using transactions for consistency
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Popular relational databases have a strong ability to ensure consistency. When
    we insert or update data, we do it via transactions. If a transaction fails, we
    can undo the transaction and rollback the database to ensure that everything is
    consistent.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following example is a simple simulation of the data accumulation process
    that may fail in the middle of the process. Suppose we need to accumulate the
    data of some products and store it in `data/products.sqlite`. Each time a chunk
    of data is produced, we need to append it to a table in the database. In each
    iteration, however, the process may fail with a probability of 20 percent:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'The accumulation fails when processing chunk 5\. Then, we will count the records
    in the table:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: We can find that the table has stored a number of records. In some cases, we
    want either all records to be properly stored or we want nothing to be put into
    the database. In both cases, the database is consistent. However, if only half
    of the data is stored, some other problems may occur. To ensure that a series
    of database changes succeed or fail as a whole, we can call `dbBegin()` before
    we write any data, call `dbCommit()` after all changes are made, and call `dbRollback()`
    if anything goes wrong.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code is an enhanced version of the previous example. We use transactions
    to make sure either all chunks are written to the database or none. More specifically,
    we put the data-writing process in `tryCatch`. Before the writing begins, we begin
    a transaction by calling `dbBegin()`. Then, in `tryCatch`, we will write data
    chunk by chunk to the database. If everything goes well, we will call `dbCommit()`
    to commit the transaction so that all the changes are committed. If anything goes
    wrong, the error will be captured by the error function in which we produce a
    warning and rollback by `dbRollback()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'We can see that the same error happens again. However, this time, the error
    is captured, the transaction cancelled, and the database rolled back. To verify,
    we can again count the number of records in the `products` table:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: It may be surprising that the counting query results in an error. Why does it
    not return 0? If we take a closer look at the example, we should understand that
    the first time we call `dbWriteTable()`, it creates a new table first and then
    inserts the data in the first chunk. In other words, the table creation is included
    in the transaction. So, when we roll back, the table creation is undone too. As
    a result, the preceding counting query produces an error because `products` does
    not exist at all. If the table exists before we begin a transaction, the count
    should be equal to the number of records before the transaction as if nothing
    happened.
  prefs: []
  type: TYPE_NORMAL
- en: Another example that requires strong consistency is account transfer. When we
    transfer an amount of money from one account to another, we need to ensure that
    the system withdraws the money from one account and deposits the same amount to
    the other account. The two changes must both happen or both fail to keep consistency.
    This can be easily done with transactions of relational databases.
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose we define a function that creates a SQLite database of a virtual bank.
    We will use `dbSendQuery()` to send commands to create a table of accounts and
    a table of transactions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'The accounts table has two columns: `name` and `balance`. The transactions
    table has four columns: `time`, `account_from`, `account_to`, and `value`. The
    first table stores all the information of accounts, and the second one stores
    all historic transactions.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will also define a function to create an account with a name and initial
    balance. The function uses `insert into` to write a new record to the accounts
    table:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: Note that we uses `sprintf` to produce the preceding SQL statement. It is acceptable
    for local and personal use, but it is generally not safe for web applications,
    because a hacker can easily write a partial expression to run any disastrous statements
    to manipulate the whole database.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we will define a transfer function. The function checks whether the withdrawing
    account and receiving account both exist in the database. It ensures that the
    balance of the withdrawing account is sufficient for such an amount of transfer.
    If the transfer is valid, then it updates the balance of both accounts and adds
    a transaction record to the database:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'Although we have some basic checking against possible insufficient funds of
    the withdrawing account, we still cannot ensure that the transfer is safe, because
    it can be interrupted by other causes. Therefore, we will implement a safe version
    of `transfer` in which we will use transaction to ensure that any changes made
    by `transfer` can be undone if anything goes wrong:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: In fact, `safe_transfer` is a wrapper function of `transfer`. It just puts `transfer`
    in a sandbox of `tryCatch`. If an error occurs, we call `dbRollback()` to ensure
    that the database is consistent.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before putting the functions into tests, we need functions to view the balance
    of a given account as well as all successful transactions that happened between
    accounts:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can do some tests. First, we will create a virtual bank using `create_bank()`
    that returns a SQLite connection to the database file. Then, we will create two
    accounts with some initial balance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we will use `safe_transfer()` to transfer some money from David''s account
    to Jenny''s account:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'The transfer succeeds, and the balances of both accounts are changed in a consistent
    manner. Now, we will make another transfer. This time, the balance of David''s
    account is not sufficient, so the transfer will end up with an error:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'The error is captured, and the function rolls back the database. The balances
    of both accounts do not change. Now, we will query all successful transactions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'We can see the first transaction, but the failed transaction does not appear
    in the database. Finally, we should always remember to close the database connection:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: Storing data in files to a database
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When we deal with large data files, we may usually get stuck with issues of
    reading and writing data. There are two extremes in practice. One extreme is a
    really big text-format data source that is almost impossible to load into memory.
    The other is a large number of small pieces of data files that will require some
    effort to integrate them into one data frame.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the first case, we can read the big source data chunk by chunk and append
    each chunk to a certain table in a database. The following function is designed
    for appending rows to a database table from a big source given an input file,
    an output database, a table name, and a chunk size. Consider that the input data
    may be too large to load into the memory, so the function will read one chunk
    each time to write to database and, thus, only require a small working memory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: The trick here is to correctly calculate the offset of each chunk in the input
    file.
  prefs: []
  type: TYPE_NORMAL
- en: 'To test the function, we will first write `diamonds` into a csv file and use `chunk_rw()`
    to write the csv file into a SQLite database chunk by chunk. With this method,
    the writing process only requires a much smaller working memory than is required
    for loading the whole data into memory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: 'Another extreme of loading data is that we need to read from many small data
    files. In this case, we can put all the data distributed in these files in a database
    so that we can easily query data from it. The following function is intended for
    putting the data of all csv files in a folder to one database:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: 'To demonstrate, we have a number of small csv files in `data/groups`, and we
    use `batch_rw()` to put all the data into a database:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, all the data in the files is put into the database. We can query or read
    the whole table and see what is looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: In this section, you learned some basic knowledge and usage of SQLite database.
    However, many popular relational databases share many common features of functionality
    and the query language. With almost the same knowledge, you can work with MySQL
    via RMySQL, PostreSQL via RPostges, Microsoft SQL Server via RSQLServer, and ODBC-compatible
    databases (Microsoft Access and Excel) via RODBC. They share almost the same operating
    functions, so if you are familiar with one, you shouldn't have a problem working
    with others.
  prefs: []
  type: TYPE_NORMAL
- en: Working with NoSQL databases
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous section of this chapter, you learned the basics of relational
    databases and how to use SQL to query data. Relational data is mostly organized
    in a tabular form, that is, as a collection of tables with relations.
  prefs: []
  type: TYPE_NORMAL
- en: However, when the volume of data exceeds the capacity of a server, problems
    occur because the traditional model of relational databases does not easily support
    horizontal scalability, that is, storing data in a cluster of servers instead
    of a single one. This adds a new layer of complexibility of database management
    as the data is stored in a distributed form while still accessible as one logical
    database.
  prefs: []
  type: TYPE_NORMAL
- en: In recent years, NoSQL, or non-relational databases, have become much more popular
    than before due to the introduction of new database models and the remarkable
    performance they exhibit in big data analytics and real-time applications. Some
    non-relational databases are designed for high availability, scalability, and
    flexibility, and some for high performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'The difference in storage model between relational databases and non-relational
    databases is notable. For example, for a shopping website, the goods and comments
    can be stored in a relational database with two tables: goods and comments. All
    the information of goods is stored in one table, and all comments on each good
    are stored in the other. The following code shows the basic structure of such
    tables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: 'Each comment has a field that points to the product it is subject to:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: When a product has many related tables and the number of records is so large
    that the database must be distributed across a great number of servers, it would
    be hard to query such a database because executing a simple query can be extremely
    inefficient. If we use MongoDB to store such data, each good will stored as a
    document and all comments of this good are stored in an array as a field of the
    document. As a result, it would be easy to query the data, and the database can
    be easily distributed to a large number of servers.
  prefs: []
  type: TYPE_NORMAL
- en: Working with MongoDB
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: MongoDB is a popular non-relational database that provides a document-oriented
    way of storing data. Each product is a document in a collection. The product has
    some fields of descriptive information and has a field that is an array of comments.
    All comments are subdocuments so that each logical item can be stored in their
    own logical form.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a JSON ([https://en.wikipedia.org/wiki/JSON](https://en.wikipedia.org/wiki/JSON))
    representation of a good in the collection:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: A relational database may contain many schemas. Each schema (or database) may
    consist of many tables. Each table may contain many records. Similarly, a MongoDB
    instance can host many databases. Each database can include many collections.
    Each collection may contain many documents. The main difference is that the records
    in a table of a relational database need to have the same structure, but a document
    in a collection of a MongoDB database is schema-less and is flexible enough to
    have nested structures.
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding JSON code, for example, a good is represented by such a document
    in which `code`, `name`, `type`, `price`, and `amount` are data fields with simple
    data types while `comments` is an array of objects. Each comment is represented
    by an object in `comments` and has a structure of `user`, `score`, and `text`.
    All comments of a good are stored as an object in `comments`. Therefore, a good
    is highly self-contained in terms of product information and comments. If we need
    information of a product, we no longer need to join two tables but pick out several
    fields.
  prefs: []
  type: TYPE_NORMAL
- en: To install MongoDB, visit [https://docs.mongodb.com/manual/installation/](https://docs.mongodb.com/manual/installation/)
    and follow the instructions. It supports nearly all major platforms.
  prefs: []
  type: TYPE_NORMAL
- en: Querying data from MongoDB
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Suppose we have a working MongoDB instance running on a local machine. We can
    use the `mongolite` package to work with MongoDB. To install the package, run
    the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: 'Once we have the package installed, we can create a Mongo connection by specifying
    the collection, database, and MongoDB address:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: 'First, we will create a connection to the local MongoDB instance. Initially,
    the `products` collection has no documents:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: 'To insert the product with comments, we can directly supply the JSON document
    as a string to `m$insert()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, the collection has one document:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: 'Alternatively, we can use list object in R to represent the same structure.
    The following code inserts the second product with `list`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: Note that R does not provide a scalar type so that, by default, all vectors
    are interpreted as JSON arrays in MongoDB, unless `auto_unbox = TRUE`, which turns
    one-element vectors into scalars in JSON. Without `auto_unbox = TRUE`, one has
    to use either `jsonlite::unbox()` to ensure scalar output or `I()` to ensure array
    output.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, the collection has two documents:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we can use `m$find()` to retrieve all documents in the collection, and
    the results are automatically simplified into a data frame for easier data manipulation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: 'To avoid the automatic conversion, we can use `m$iterate()` to iterate over
    the collection and get list objects that represent the original form of storage:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: To filter the collection, we can specify the conditional query and fields in
    `m$find()`.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we will query documents with `code` of `A0000001` and retrieve the `name`, `price`,
    and `amount` fields:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we will query documents with `price` greater than or equal to `40`, which
    is done by the `$gte` operator in the conditional query:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: 'We can not only query the document fields, but also the object fields in an
    array field. The following code retrieves all documents with any comment that
    gives a 9-point score:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: 'Similarly, the following code retrieves all documents with any comment that
    gives a score less than 6:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that accessing the field of a subdocument is easily done by the `.` notation,
    which makes it pretty easy to work with nested structures:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: 'The `m$insert()` function also works with data frames in R. Now, we will create
    a new MongoDB connection to another collection:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: 'We will create a MongoDB connection, `m`, to work with the `students` collection
    in the `test` database in a local MongoDB instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: 'Initially, the collection has no documents. To insert some data, we will create
    a simple data frame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we will insert the rows as documents into the collection:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, the collection has some documents:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs: []
  type: TYPE_PRE
- en: 'We can retrieve all the documents from the collection using `find()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs: []
  type: TYPE_PRE
- en: As we mentioned in the previous example, the way in which documents are stored
    in a MongoDB collection is different from the way columns are stored in a table
    of a relational database. A document in a MongoDB collection is more like a JSON
    document, but in fact, it is stored in binary form to achieve super performance
    and compactness. The `m$find()` function first retrieves the data in a JSON-like
    form and simplifies it into a data form for easy data manipulation.
  prefs: []
  type: TYPE_NORMAL
- en: 'To filter the data, we can specify the query condition by supplying documents
    to `find()`. For example, we want to find all documents whose name is `Jenny`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE99]'
  prefs: []
  type: TYPE_PRE
- en: 'The results are automatically coerced to a data frame to make it easier to
    use. Then, we will query all documents with a number of projects greater or equal
    to `2`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs: []
  type: TYPE_PRE
- en: 'To select fields, we will specify the `fields` argument of `find()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE101]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also sort the data by specifying the `sort` argument:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE102]'
  prefs: []
  type: TYPE_PRE
- en: 'To limit the documents returned, we will specify `limit`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE103]'
  prefs: []
  type: TYPE_PRE
- en: 'Also, we can get all distinct values of a certain field of all documents:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE104]'
  prefs: []
  type: TYPE_PRE
- en: 'We can get the distinct values with a condition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE105]'
  prefs: []
  type: TYPE_PRE
- en: 'To update a document, we will call `update()`, find the documents in selection,
    and set the values of certain fields:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE106]'
  prefs: []
  type: TYPE_PRE
- en: Creating and removing indexes
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Like relational databases, MongoDB also supports indexes. Each collection may
    have multiple indexes, and the fields of indexes are cached in memory for fast
    lookup. Properly created indexes can make document lookup extremely efficient.
  prefs: []
  type: TYPE_NORMAL
- en: Creating indexes in MongoDB with `mongolite` is easy. It can be done before
    or after we import data into the collection. However, if we already imported billions
    of documents, it can be time consuming to create an index. If we create many indexes
    before pouring any documents into the collection, the performance of inserting
    documents may be harmed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we will create an index for the `students` collection:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE107]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, if we find a document with the indexed field, the performance is super:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE108]'
  prefs: []
  type: TYPE_PRE
- en: 'If no document satisfies the condition, an empty data frame will be returned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE109]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, the collection can be abandoned with `drop()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE110]'
  prefs: []
  type: TYPE_PRE
- en: The performance boost of using an index is definitively not obvious if the amount
    of data is small. In the next example, we will create a data frame with many rows
    so that we can compare the performance of finding documents between using an index
    and not using one.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we will use `expand.grid()` to create a data frame that exhausts all
    possible combinations of the provided vectors in the arguments:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE111]'
  prefs: []
  type: TYPE_PRE
- en: 'The index columns are created. Next, we need to simulate some random numbers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE112]'
  prefs: []
  type: TYPE_PRE
- en: 'The data frame now looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE113]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we will insert all the data into the `simulation` collection:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE114]'
  prefs: []
  type: TYPE_PRE
- en: 'The first test is trying to answer how long it takes to query a document without
    any index:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE115]'
  prefs: []
  type: TYPE_PRE
- en: 'The second test is about the performance of finding documents with joint conditions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE116]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, the resulting data frame looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE117]'
  prefs: []
  type: TYPE_PRE
- en: 'The third test is about the performance of finding documents using a non-index
    field:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE118]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting data frame looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE119]'
  prefs: []
  type: TYPE_PRE
- en: 'All three tests are done without creating an index for the collection. To make
    a contrast, we will now create an index:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE120]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the index is created, the query of the first test with index fields is
    quick:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE121]'
  prefs: []
  type: TYPE_PRE
- en: 'The second test also yields results quickly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE122]'
  prefs: []
  type: TYPE_PRE
- en: 'However, the non-index fields do not contribute to the index search for documents:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE123]'
  prefs: []
  type: TYPE_PRE
- en: 'Another important feature of MongoDB is its aggregation pipeline. When we aggregate
    data, we supply an array of aggregate operations so that they are scheduled by
    the MongoDB instance. For example, the following code groups the data by `type`.
    Each group has a field count, average score, min test score, and max test score.
    Since the output can be long, we don''t print it here. You may execute the code
    yourself and see the results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE124]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also use multiple fields as the key of a group, which is similar to
    `group by A, B` in SQL:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE125]'
  prefs: []
  type: TYPE_PRE
- en: 'The aggregation pipeline supports running aggregate operations in a streamline:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE126]'
  prefs: []
  type: TYPE_PRE
- en: 'We can lengthen the pipeline by adding more operations. For example, the following
    code creates groups and aggregate data. Then, it sorts the documents with average
    score in the descending order, takes out the top three documents, and projects
    the fields into something useful:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE127]'
  prefs: []
  type: TYPE_PRE
- en: In addition to the aggregate operators we used in the example, there are many
    other operators that are more powerful. For more details, visit [https://docs.mongodb.com/manual/reference/operator/aggregation-pipeline/](https://docs.mongodb.com/manual/reference/operator/aggregation-pipeline/)
    and [https://docs.mongodb.com/manual/reference/operator/aggregation-arithmetic/](https://docs.mongodb.com/manual/reference/operator/aggregation-arithmetic/).
  prefs: []
  type: TYPE_NORMAL
- en: 'Another important feature of MongoDB is that it supports MapReduce ([https://en.wikipedia.org/wiki/MapReduce](https://en.wikipedia.org/wiki/MapReduce))
    at an internal level. The MapReduce model is widely used in big data analytics
    in distributed clusters. In our environment, we can write an extremely simple
    MapReduce code that tries to produce a histogram of certain data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE128]'
  prefs: []
  type: TYPE_PRE
- en: 'The first step of MapReduce is map. In this step, all values are mapped to
    a key-value pair. Then, the reduce step aggregates the key-value pair. In the
    preceding example, we simply calculated the number of records for each bin:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE129]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also create a bar plot from `bins`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE130]'
  prefs: []
  type: TYPE_PRE
- en: 'The plot generated is shown as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Creating and removing indexes](img/image_11_001.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'If the collection is no longer used, then we can use the `drop()` function
    to drop it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE131]'
  prefs: []
  type: TYPE_PRE
- en: Since this section is at the introductory level, the more advanced use of MongoDB
    is beyond the scope of this book. If you are interested in MongoDB, go through
    the official tutorial at [https://docs.mongodb.com/manual/tutorial/](https://docs.mongodb.com/manual/tutorial/).
  prefs: []
  type: TYPE_NORMAL
- en: Using Redis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Redis ([http://redis.io/](http://redis.io/)), unlike SQLite that stores data
    in tabular form or MongoDB that allows to store and query nested structures, is
    an in-memory data structure store. It stores key-values in memory and thus has
    very high performance of key lookup. However, it does not support query languages
    as used in SQL databases or MongoDB.
  prefs: []
  type: TYPE_NORMAL
- en: Redis is usually used as a high-performance data cache. We can store and manipulate
    a range of basic data structures in it. To install Redis, visit [http://redis.io/download](http://redis.io/download).
    Unfortunately, the Windows operating system is not officially supported, but the
    Microsoft Open Tech group develops and maintains a Win64 port of Redis at [https://github.com/MSOpenTech/redis](https://github.com/MSOpenTech/redis).
  prefs: []
  type: TYPE_NORMAL
- en: 'While SQL database stores tables and MongoDB stores documents, Redis stores
    key-value pairs as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE132]'
  prefs: []
  type: TYPE_PRE
- en: The value can be more complex data structures (for example, hashmap, set, and
    sorted set) rather than simple values, and Redis provides a simple interface to
    work with these data structures in high performance and low latency.
  prefs: []
  type: TYPE_NORMAL
- en: Accessing Redis from R
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To access a Redis instance from R, we can use the `rredis` package that provides
    simple functions to work with Redis. To install the package, run the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE133]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the package is ready, we can connect to a Redis instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE134]'
  prefs: []
  type: TYPE_PRE
- en: If we leave the arguments blank, it connects to the local Redis instance by
    default. It also lets us connect to a remote instance.
  prefs: []
  type: TYPE_NORMAL
- en: Setting and getting values from the Redis server
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The most basic use of Redis is to store a value by calling `redisSet(key, value)`.
    In R, the value is, by default, serialized so that we can store any R objects
    in Redis:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE135]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that the command has succeeded, we can retrieve the value with the same
    key:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE136]'
  prefs: []
  type: TYPE_PRE
- en: 'We can store an integer vector:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE137]'
  prefs: []
  type: TYPE_PRE
- en: 'We can even store a data frame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE138]'
  prefs: []
  type: TYPE_PRE
- en: 'In fact, if other computers have access to your Redis instance, they will get
    the same data in R using `redisGet()`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'However, we can only get `NULL` if the key does not exist at all:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE139]'
  prefs: []
  type: TYPE_PRE
- en: 'Instead of getting `NULL`, we can use `redisExists()` to detect whether a key
    is defined:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE140]'
  prefs: []
  type: TYPE_PRE
- en: 'If we no longer need a key, we can delete it with `redisDelete()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE141]'
  prefs: []
  type: TYPE_PRE
- en: 'In addition to plain key-value pairs, Redis also supports more advanced data
    structures. For example, we can use `redisHSet()` to create a hash map of fruits
    in which different fruits have different numbers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE142]'
  prefs: []
  type: TYPE_PRE
- en: 'We can call `redisHGet()` to get the value of a field of a hash map:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE143]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also get a list to represent the structure of the hash map:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE144]'
  prefs: []
  type: TYPE_PRE
- en: 'Alternatively, we can get the keys of the hash map:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE145]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also get only the values of the hash map:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE146]'
  prefs: []
  type: TYPE_PRE
- en: 'Aditionally, we can simply get the number of fields in the hash map:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE147]'
  prefs: []
  type: TYPE_PRE
- en: 'We can get the values of multiple fields at once:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE148]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also set the values of multiple fields by supplying a list:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE149]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, the values of the fields are updated:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE150]'
  prefs: []
  type: TYPE_PRE
- en: 'In addition to the hash map, Redis also supports queue. We can push values
    from either left-hand side or the right-hand side of the queue. For example, we
    push integers from `1` to `3` from the right-hand side of a queue:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE151]'
  prefs: []
  type: TYPE_PRE
- en: 'We can get the current length of the queue with `redisLLen()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE152]'
  prefs: []
  type: TYPE_PRE
- en: Now, the queue has three elements. Note that the value is a character vector
    rather than an integer. Therefore, we need to convert it if we need to use it
    as a number in other places.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, we can keep popping values from the left-hand side of the queue:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE153]'
  prefs: []
  type: TYPE_PRE
- en: Note that the queue only has three elements to pop out. The fourth attempt returns
    `NULL`, which can be a criterion to check whether the queue is empty.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we should close the connection to Redis to release all resources:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE154]'
  prefs: []
  type: TYPE_PRE
- en: Redis has more advanced features that are beyond the scope of this chapter.
    It supports not only data structure store, but also message broker, that is, we
    can use it to pass messages between different programs. For more advanced usage,
    read the official documentation at [http://redis.io/documentation](http://redis.io/documentation).
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned how to access different types of databases from
    R. We introduced the basic usage of relational databases such as SQLite and non-relational
    databases such as MongoDB and Redis. With the understanding of major differences
    in their functionality and feature sets, we need to choose an appropriate database
    to work with in our projects according to our purpose and needs.
  prefs: []
  type: TYPE_NORMAL
- en: In many data-related projects, data storage and data importing are the initial
    steps, but data cleaning and data manipulation cost most of the time. In the next
    chapter, we will move on to data-manipulation techniques. You will learn about
    a number of packages that are specially tailored for handy but powerful data manipulation.
    To better work with these packages, we'll need a better understanding of how they
    work, which requires the sound knowledge introduced in the previous chapters.
  prefs: []
  type: TYPE_NORMAL
