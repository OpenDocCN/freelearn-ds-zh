- en: '*Chapter 5*'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Getting Comfortable with Different Kinds of Data Sources
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Learning Objectives
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'By the end of this chapter, you will be able to:'
  prefs: []
  type: TYPE_NORMAL
- en: Read CSV, Excel, and JSON files into pandas DataFrames
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Read PDF documents and HTML tables into pandas DataFrames
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Perform basic web scraping using powerful yet easy to use libraries such as
    Beautiful Soup
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Extract structured and textual information from portals
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this chapter, you will be exposed to real-life data wrangling techniques,
    as applied to web scraping.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: So far in this book, we have focused on learning pandas DataFrame objects as
    the main data structure for the application of wrangling techniques. Now, we will
    learn about various techniques by which we can read data into a DataFrame from
    external sources. Some of those sources could be text-based (CSV, HTML, JSON,
    and so on), whereas some others could be binary (Excel, PDF, and so on), that
    is, not in ASCII format. In this chapter, we will learn how to deal with data
    that is present in web pages or HTML documents. This holds very high importance
    in the work of a data practitioner.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Since we have gone through a detailed example of basic operations with NumPy
    and pandas, in this chapter, we will often skip trivial code snippets such as
    viewing a table, selecting a column, and plotting. Instead, we will focus on showing
    code examples for the new topics we aim to learn about here.
  prefs: []
  type: TYPE_NORMAL
- en: Reading Data from Different Text-Based (and Non-Text-Based) Sources
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One of the most valued and widely used skills of a data wrangling professional
    is the ability to extract and read data from a diverse array of sources into a
    structured format. Modern analytics pipelines depend on their ability to scan
    and absorb a variety of data sources to build and analyze a pattern-rich model.
    Such a feature-rich, multi-dimensional model will have high predictive and generalization
    accuracy. It will be valued by stakeholders and end users alike for any data-driven
    product.
  prefs: []
  type: TYPE_NORMAL
- en: In the first topic of this chapter, we will go through various data sources
    and how they can be imported into pandas DataFrames, thus imbuing wrangling professionals
    with extremely valuable data ingestion knowledge.
  prefs: []
  type: TYPE_NORMAL
- en: Data Files Provided with This Chapter
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Because this topic is about reading from various data sources, we will use small
    files of various types in the following exercises. All of the data files are provided
    along with the Jupyter notebook in the code repository.
  prefs: []
  type: TYPE_NORMAL
- en: Libraries to Install for This Chapter
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Because this chapter deals with reading various file formats, we need to have
    the support of additional libraries and software platforms to accomplish our goals.
  prefs: []
  type: TYPE_NORMAL
- en: 'Execute the following codes in your Jupyter notebook cells (don''t forget the
    ! before each line of code) to install the necessary libraries:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Exercise 60: Reading Data from a CSV File Where Headers Are Missing'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The pandas library provides a simple direct method called `read_csv` to read
    data in a tabular format from a comma-separated text file, or CSV. This is particularly
    useful because a CSV is a lightweight yet extremely handy data exchange format
    for many applications, including such domains as machine-generated data. It is
    not a proprietary format and therefore is universally used by a variety of data-generating
    sources.
  prefs: []
  type: TYPE_NORMAL
- en: 'At times, headers may be missing from a CSV file and you may have to add proper
    headers/column names of your own. Let''s have a look at how this can be done:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Read the example CSV file (with a proper header) using the following code and
    examine the resulting DataFrame, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.1: Output of example CSV file](img/C11065_05_01.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 5.1: Output of example CSV file'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Read a `.csv` file with no header using a pandas DataFrame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.2: Output of the .csv being read using a DataFrame](img/C11065_05_02.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 5.2: Output of the .csv being read using a DataFrame'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: Certainly, the top data row has been mistakenly read as the column header. You
    can specify `header=None` to avoid this.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Read the `.csv` file by mentioning the header `None`, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'However, without any header information, you will get back the following output.
    The default headers will be just some default numeric indices starting from 0:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.3: CSV file with a numeric column header](img/C11065_05_03.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 5.3: CSV file with a numeric column header'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: This may be fine for data analysis purposes, but if you want the DataFrame to
    truly reflect the proper headers, then you will have to add them using the `names`
    argument.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Add the `names` argument to get the correct headers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, you will get a DataFrame that''s as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.4: CSV file with correct column header](img/C11065_05_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.4: CSV file with correct column header'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Exercise 61: Reading from a CSV File where Delimiters are not Commas'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Although CSV stands for comma-separated-values, it is fairly common to encounter
    raw data files where the separator/delimiter is a character other than a comma:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Read a `.csv` file using pandas DataFrames:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:![Figure 5.5: A DataFrame that has a semi-colon
    as a separator](img/C11065_05_05.jpg)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Figure 5.5: A DataFrame that has a semi-colon as a separator'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Clearly, the *;* separator was not expected, and the reading is flawed. A simple
    work around is to specify the separator/delimiter explicitly in the read function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.6: Semicolons removed from the DataFrame](img/C11065_05_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.6: Semicolons removed from the DataFrame'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Exercise 62: Bypassing the Headers of a CSV File'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'If your CSV file already comes with headers but you want to bypass them and
    put in your own, you have to specifically set `header` `=` `0` to make it happen.
    If you try to set the names variable to your header list, unexpected things can
    happen:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Add names to a .csv file that has headers, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.7: CSV file with headers overlapped](img/C11065_05_07.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 5.7: CSV file with headers overlapped'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'To avoid this, set `header` to zero and provide a names list:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.8: CSV file with defined headers](img/C11065_05_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.8: CSV file with defined headers'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Exercise 63: Skipping Initial Rows and Footers when Reading a CSV File'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Skipping initial rows is a widely useful method because, most of the time,
    the first few rows of a CSV data file are metadata about the data source or similar
    information, which is not read into the table:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.9: Contents of the CSV file](img/C11065_05_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.9: Contents of the CSV file'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The first two lines in the CSV file are irrelevant data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Read the CSV file and examine the results:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.10: DataFrame with an unexpected error](img/C11065_05_10.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 5.10: DataFrame with an unexpected error'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Skip the first two rows and read the file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.11: Expected DataFrame after skipping two rows](img/C11065_05_11.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 5.11: Expected DataFrame after skipping two rows'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Similar to skipping the initial rows, it may be necessary to skip the footer
    of a file. For example, we do not want to read the data at the end of the following
    file:![Figure 5.12: Contents of the CSV file](img/C11065_05_12.jpg)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Figure 5.12: Contents of the CSV file'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: We have to use `skipfooter` and the `engine='python'` option to enable this.
    There are two engines for these CSV reader functions â€“ based on C or Python, of
    which only the Python engine supports the `skipfooter` option.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Use the `skipfooter` option in Python:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.13: DataFrame without a footer](img/C11065_05_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.13: DataFrame without a footer'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Reading Only the First N Rows (Especially Useful for Large Files)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In many situations, we may not want to read a whole data file but only the first
    few rows. This is particularly useful for extremely large data files, where we
    may just want to read the first couple of hundred rows to check an initial pattern
    and then decide to read the whole data later on. Reading the entire file can take
    a long time and slow down the entire data wrangling pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: 'A simple option, called `nrows`, in the `read_csv` function enables us to do
    just that:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/C11065_05_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.14: DataFrame with the first few rows of the CSV file'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Exercise 64: Combining Skiprows and Nrows to Read Data in Small Chunks'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Continuing our discussion about reading a very large data file, we can cleverly
    combine `skiprows` and `nrows` to read in such a large file in smaller chunks
    of pre-determined sizes. The following code demonstrates just that:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a list where DataFrames will be stored:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Store the number of rows to be read into a variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a variable to store the number of chunks to be read:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a dummy DataFrame to get the column names:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Loop over the CSV file to read only a fixed number of rows at a time:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note how the `iterator` variable is set up inside the `range` function to break
    it into chunks. Say the number of chunks is 5 and the rows per chunk is 10\. Then,
    the iterator will have a range of (0,5*10,10), where the final 10 is step-size,
    that is, it will iterate with indices of (0,9,19,29,39,49).
  prefs: []
  type: TYPE_NORMAL
- en: Setting the skip_blank_lines Option
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'By default, `read_csv` ignores blank lines. But sometimes, you may want to
    read them in as NaN so that you can count how many such blank entries were present
    in the raw data file. In some situations, this is an indicator of the default
    data streaming quality and consistency. For this, you have to disable the `skip_blank_lines`
    option:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.15: DataFrame that has blank rows of a .csv file](img/C11065_05_15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.15: DataFrame that has blank rows of a .csv file'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Read CSV from a Zip file
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This is an awesome feature of pandas, in that it allows you to read directly
    from a compressed file such as `.zip`, `.gz`, `.bz2`, or `.xz`. The only requirement
    is that the intended data file (CSV) should be the only file inside the compressed
    file.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this example, we compressed the example CSV file with a 7-Zip program and
    read from it directly using the `read_csv` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/C11065_05_16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.16: DataFrame of a compressed CSV'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Reading from an Excel File Using sheet_name and Handling a Distinct sheet_name
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Next, we will turn our attention to a Microsoft Excel file. It turns out that
    most of the options and methods we learned about in the previous exercises with
    the CSV file apply directly to the reading of Excel files too. Therefore, we will
    not repeat them here. Instead, we will focus on their differences. An Excel file
    can consist of multiple worksheets and we can read a specific sheet by passing
    in a particular argument, that is, `sheet_name`.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, in the associated data file, `Housing_data.xlsx`, we have three
    tabs, and the following code reads them one by one in three separate DataFrames:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: If the Excel file has multiple distinct sheets but the `sheet_name` argument
    is set to `None`, then an ordered dictionary will be returned by the `read_excel`
    function. Thereafter, we can simply iterate over that dictionary or its keys to
    retrieve individual DataFrames.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s consider the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Exercise 65: Reading a General Delimited Text File'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'General text files can be read as easily as we read CSV files. However, you
    have to pass on the proper separator if it is anything other than a whitespace
    or a tab:'
  prefs: []
  type: TYPE_NORMAL
- en: 'A comma-separated file, saved with the `.txt` extension, will result in the
    following DataFrame if read without explicitly setting the separator:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](img/C11065_05_17.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 5.17: DataFrame that has a comma-separated CSV file'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'In this case, we have to set the separator explicitly, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.18: DataFrame read using comma seperator](img/C11065_05_18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.18: DataFrame read using a comma separator'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Reading HTML Tables Directly from a URL
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The pandas library allows us to read HTML tables directly from a URL. This means
    that they already have some kind of built-in HTML parser that processes the HTML
    content of a given page and tries to extract various tables in the page.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The `read_html` method returns a list of DataFrames (even if the page has a
    single DataFrame) and you have to extract the relevant tables from the list.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'These results are shown in the following DataFrame:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.19: Results of reading HTML tables](img/C11065_05_19.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.19: Results of reading HTML tables'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Exercise 66: Further Wrangling to Get the Desired Data'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'As discussed in the preceding exercise, this HTML-reading function almost always
    returns more than one table for a given HTML page and we have to further parse
    through the list to extract the particular table we are interested in:'
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, if we want to get the table of the 2016 summer Olympics medal
    tally (by nation), we can easily search to get a page on Wikipedia that we can
    pass on to pandas. We can do this by using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'If we check the length of the list returned, we will see it is 6:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To look for the table, we can run a simple loop:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](img/C11065_05_20.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 5.20: Shape of the tables'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'It looks like the second element in this list is the table we are looking for:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.21: Output of the data in the second table](img/C11065_05_21.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.21: Output of the data in the second table'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Exercise 67: Reading from a JSON File'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Over the last 15 years, JSON has become a ubiquitous choice for data exchange
    on the web. Today, it is the format of choice for almost every publicly available
    web API, and it is frequently used for private web APIs as well. It is a schema-less,
    text-based representation of structured data that is based on key-value pairs
    and ordered lists.
  prefs: []
  type: TYPE_NORMAL
- en: 'The pandas library provides excellent support for reading data from a JSON
    file directly into a DataFrame. To practice with this chapter, we have included
    a file called `movies.json`. This file contains the cast, genre, title, and year
    (of release) information for almost all major movies since 1900:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Extract the cast list for the 2012 Avengers movie (from Marvel comics):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.22: DataFrame displaying Avengers movie cast](img/C11065_05_22.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 5.22: DataFrame displaying the Avengers movie cast'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'To look for the cast where the title is "Avengers", we can use filtering:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Reading a Stata File
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The pandas library provides a direct reading function for Stata files, too.
    Stata is a popular statistical modeling platform that's used in many governmental
    and research organizations, especially by economists and social scientists.
  prefs: []
  type: TYPE_NORMAL
- en: 'The simple code to read in a Stata file (`.dta` format) is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Exercise 68: Reading Tabular Data from a PDF File'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Among the various types of data sources, the PDF format is probably the most
    difficult to parse in general. While there are some popular packages in Python
    for working with PDF files for general page formatting, the best library to use
    for table extraction from PDF files is `tabula-py`.
  prefs: []
  type: TYPE_NORMAL
- en: From the GitHub page of this package, `tabula-py` is a simple Python wrapper
    of `tabula-java`, which can read a table from a PDF. You can read tables from
    PDFs and convert them into pandas DataFrames. The `tabula-py` library also enables
    you to convert a PDF file into a CSV/TSV/JSON file.
  prefs: []
  type: TYPE_NORMAL
- en: 'You will need the following packages installed on your system before you can
    run this, but they are free and easy to install:'
  prefs: []
  type: TYPE_NORMAL
- en: urllib3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: pandas
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: pytest
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: flake8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: distro
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: pathlib
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Find the PDF file in the following link: https://github.com/TrainingByPackt/Data-Wrangling-with-Python/blob/master/Chapter05/Exercise60-68/Housing_data.xlsx.
    The following code retrieves the tables from two pages and joins them to make
    one table:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.23: DataFrame with a table derived by merging a table flowing over
    two pages in a PDF](img/C11065_05_23.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 5.23: DataFrame with a table derived by merging a table flowing over
    two pages in a PDF'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Retrieve the table from another page of the same PDF by using the following
    command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.24: DataFrame displaying a table from another page](img/C11065_05_24.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 5.24: DataFrame displaying a table from another page'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'To concatenate the tables that were derived from the first two steps, execute
    the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.25: DataFrame derived by concatenating two tables](img/C11065_05_25.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 5.25: DataFrame derived by concatenating two tables'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'With PDF extraction, most of the time, headers will be difficult to extract
    automatically. You have to pass on the list of headers with the `names` argument
    in the `read-pdf` function as `pandas_option`, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.26: DataFrame with correct column headers for PDF data](img/C11065_05_26.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.26: DataFrame with correct column headers for PDF data'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: We will have a full activity on reading tables from a PDF report and processing
    them at the end of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to Beautiful Soup 4 and Web Page Parsing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The ability to read and understand web pages is one of paramount interest for
    a person collecting and formatting data. For example, consider the task of gathering
    data about movies and then formatting it for a downstream system. Data for the
    movies is best obtained by the websites such as IMDB and that data does not come
    pre-packaged in nice forms(CSV, JSON< and so on), so you need to know how to download
    and read web page.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, you also need to be equipped with the knowledge of the structure
    of a web page so that you can design a system that can search for (query) a particular
    piece of information from a whole web page and get the value of it. This involves
    understanding the grammar of markup languages and being able to write something
    that can parse them. Doing this, and keeping all the edge cases in mind, for something
    like HTML is already incredibly complex, and if you extend the scope of the bespoke
    markup language to include XML as well, then it becomes full-time work for a team
    of people.
  prefs: []
  type: TYPE_NORMAL
- en: Thankfully, we are using Python, and Python has a very mature and stable library
    to do all of the complicated jobs for us. This library is called `BeautifulSoup`
    (it is, at present, in version 4 and thus we will call it `bs4` in short from
    now on). `bs4` is a library for getting data from HTML or XML documents, and it
    gives you a nice, normalized, idiomatic way of navigating and querying a document.
    It does not include a parser but it supports different ones.
  prefs: []
  type: TYPE_NORMAL
- en: Structure of HTML
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Before we jump into `bs4` and start working with it, we need to examine the
    structure of a HTML document. **H**yper **T**ext **M**arkup **L**anguage is a
    structured way of telling web browsers about the organization of a web page, meaning
    which kind of elements (text, image, video, and so on) come from where, in which
    place inside the page they should appear, what they look like, what they contain,
    and how they will behave with user input. HTML5 is the latest version of HTML.
    An HTML document can be viewed as a tree, as we can see from the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.27: HTML structure](img/C11065_05_27.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.27: HTML structure'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Each node of the tree represents one element in the document. An element is
    anything that starts with `<` and ends with `>`. For example, `<html>`, `<head>`,
    `<p>`, `<br>`, `<img>`, and so on are various HTML elements. Some elements have
    a start and end element, where the end element begins with "</" and has the same
    name as the start element, such as `<p>` and `</p>`, and they can contain an arbitrary
    number of elements of other types in them. Some elements do not have an ending
    part, such as the `<br />` element, and they cannot contain anything within them.
  prefs: []
  type: TYPE_NORMAL
- en: 'The only other thing that we need to know about an element at this point is
    the fact that elements can have attributes, which are there to modify the default
    behavior of an element. An `<a>` element requires a `href` attribute to tell the
    browser which website it should navigate to when that particular `<a>` is clicked,
    like this: `<a href="http://cnn.com">`. The CNN news channel, `</a>`, will take
    you to cnn.com when clicked:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.28: CNN news channel hyperlink](img/C11065_05_28.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.28: CNN news channel hyperlink'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: So, when you are at a particular element of the tree, you can visit all the
    children of that element to get the contents and attributes of them.
  prefs: []
  type: TYPE_NORMAL
- en: Equipped with this knowledge, let's see how we can read and query data from
    a HTML document.
  prefs: []
  type: TYPE_NORMAL
- en: In this topic, we will cover the reading and parsing of web pages, but we do
    not request them from a live website. Instead, we read them from disk. A section
    on reading them from the internet will follow in a future chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 69: Reading an HTML file and Extracting its Contents Using BeautifulSoup'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we will do the simplest thing possible. We will import the
    `BeautifulSoup` library and then use it to read an HTML document. Then, we will
    examine the different kinds of objects it returns. While doing the exercises for
    this topic, you should have the example HTML file open in a text editor all the
    time so that you can check for the different tags and their attributes and contents:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the `bs4` library:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Please download the following test HTML file and save it on your disk and the
    use bs4 to read it from the disk:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You can pass a file handler directly to the constructor of the `BeautifulSoup`
    object and it will read the contents from the file that the handler is attached
    to. We will see that return-type is an instance of `bs4.BeautifulSoup`. This class
    holds all the methods we need to navigate through the DOM tree that the document
    represents.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Print the contents of the file in a nice way by using the `prettify` method
    from the class like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.29: Contents of the HTML file](img/C11065_05_29.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 5.29: Contents of the HTML file'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The same information can also be obtained by using the `soup.contents` member
    variable. The differences are: first, it won''t print anything pretty and, second,
    it is essentially a list.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: If we look carefully at the contents of the HTML file in a separate text editor,
    we will see that there are many paragraph tags, or `<p>` tags. Let's read content
    from one such `<p>` tag. We can do that using the simple `.` access modifier as
    we would have done for a normal member variable of a class.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The magic of `bs4` is the fact that it gives us this excellent way to dereference
    tags as member variables of the `BeautifulSoup` class instance:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.30: Text from the <p> tag ](img/C11065_05_30.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 5.30: Text from the <p> tag'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: As we can see, this is the content of a `<p>` tag.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: We saw how to read a tag in the last exercise, but we can easily see the problem
    with this approach. When we look into our HTML document, we can see that we have
    more than one `<p>` tag there. How can we access all the `<p>` tags? It turns
    out that this is easy.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Use the `findall` method to extract the content from the tag:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This will print 6, which is exactly the number of `<p>`tags in the document.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: We have seen how to access all the tags of the same type. We have also seen
    how to get the content of the entire HTML document.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now, we will see how to get the contents under a particular HTML tag, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.31: Content under the <table> tag ](img/C11065_05_31.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 5.31: Content under the <table> tag'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: Here, we are getting the (first) table from the document and then using the
    same "`.`" notation, to get the contents under that tag.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: We saw in the previous exercise that we can access the entire content under
    a particular tag. However, HTML is represented as a tree and we are able to traverse
    the children of a particular node. There are a few ways to do this.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The first way is by using the `children` generator from any `bs4` instance,
    as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'When we execute the code, we will see something like the following:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 5.32: Traversing children of a table node](img/C11065_05_32.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 5.32: Traversing the children of a table node'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: It seems that the loop has only been executed twice! Well, the problem with
    the "`children`" generator is that it only takes into account the immediate children
    of the tag. We have `<tbody>` under the `<table>` and our whole table structure
    is wrapped in it. That's why it was considered a single child of the `<table>`
    tag.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: We looked into how to browse the immediate children of a tag. We will see how
    we can browse all the possible children of a tag and not only the immediate one.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'To do that, we use the `descendants` generator from the `bs4` instance, as
    follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The comparison print at the end of the code block will show us the difference
    between `children` and `descendants`. The length of the list we got from `children`
    is only 9, whereas the length of the list we got from `descendants` is 61.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 70: DataFrames and BeautifulSoup'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'So far, we have seen some basic ways to navigate the tags inside a HTML document
    using `bs4`. Now, we are going to go one step further and use the power of `bs4`
    combined with the power of pandas to generate a DataFrame out of a plain HTML
    table. This particular knowledge is very useful for us. With the knowledge we
    will acquire now, it will be fairly easy for us to prepare a pandas DataFrame
    to perform EDA (exploratory data analysis) or modeling. We are going to show this
    process on a simple small table from the test HTML file, but the exact same concept
    applies to any arbitrarily large table as well:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import `pandas` and read the document, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Check the original table structure in the HTML source. You will see that the
    first row is the column headings and all of the following rows are the data. We
    assign two different variables for the two sections, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: Keep in mind that the art of scraping a HTML page goes hand in hand with an
    understanding of the source HTML structure. So, whenever you want to scrape a
    page, the first thing you need to do is right-click on it and then use "View Source"
    from the browser to see the source HTML.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Once we have separated the two sections, we need two list comprehensions to
    make them ready to go in a DataFrame. For the header, this is easy:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Data preparation is a bit tricky for a pandas DataFrame. You need to have a
    two-dimensional list, which is a list of lists. We accomplish that in the following
    way:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](img/C11065_05_33.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 5.33: Output as a two-dimensional list'
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Invoke the `pd.DataFrame` method and supply the right arguments by using the
    following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![](img/C11065_05_34.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.34: Output in tabular format with column headers'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Exercise 71: Exporting a DataFrame as an Excel File'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we will see how we can save a DataFrame as an Excel file.
    Pandas can natively do this, but it needs the help of the `openpyxl` library to
    achieve this goal:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Install the `openpyxl` library by using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To save the DataFrame as an Excel file, use the following command from inside
    of the Jupyter notebook:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Exercise 72: Stacking URLs from a Document using bs4'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Previously (while discussing stack), we explained how important it is to have
    a stack that we can push the URLs from a web page to so that we can pop them at
    a later time to follow each of them. Here, in this exercise, we will see how that
    works.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the given test, HTML file links or `<a>` tags are under a `<ul>` tag, and
    each of them is contained inside a `</li>` tag:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Find all the `<a>` tags by using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a stack before you start the loop. Then, inside the loop, use the `append`
    method to push the links in the stack:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Print the stack:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/C11065_05_35.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.35: Output of the stack'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Activity 7: Reading Tabular Data from a Web Page and Creating DataFrames'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this activity, you have been given a Wikipedia page where you have the GDP
    of all countries listed. You have been asked to create three `DataFrames` from
    the three sources mentioned in the page ([https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal)](https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal))):'
  prefs: []
  type: TYPE_NORMAL
- en: 'You will have to do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Open the page in a separate Chrome/Firefox tab and use something like an **Inspect
    Element** tool to view the source HTML and understand its structure
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Read the page using bs4
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Find the table structure you will need to deal with (how many tables there are?)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Find the right table using bs4
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Separate the source names and their corresponding data
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Get the source names from the list of sources you have created
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Separate the header and data from the data that you separated before for the
    first source only, and then create a DataFrame using that
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat the last task for the other two data sources
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: The solution for this activity can be found on page 308.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this topic, we looked at the structure of an HTML document. HTML documents
    are the cornerstone of the World Wide Web and, given the amount of data that's
    contained on it, we can easily infer the importance of HTML as a data source.
  prefs: []
  type: TYPE_NORMAL
- en: We learned about bs4 (BeautifulSoup4), a Python library that gives us Pythonic
    ways to read and query HTML documents. We used bs4 to load an HTML document and
    also explored several different ways to navigate the loaded document. We also
    got necessary information about the difference between all of these methods.
  prefs: []
  type: TYPE_NORMAL
- en: We looked at how we can create a pandas DataFrame from an HTML document (which
    contains a table). Although there are some built-in ways to do this job in pandas,
    they fail as soon as the target table is encoded inside a complex hierarchy of
    elements. So, the knowledge we gathered in this topic by transforming an HTML
    table into a pandas DataFrame in a step-by-step manner is invaluable.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we looked at how we can create a stack in our code, where we push all
    the URLs that we encounter while reading the HTML file and then use them at a
    later time. In the next chapter, we will discuss list comprehensions, zip, format
    and outlier detection and cleaning.
  prefs: []
  type: TYPE_NORMAL
