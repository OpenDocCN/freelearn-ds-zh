<html><head></head><body><div class="chapter" title="Chapter&#xA0;2.&#xA0;GIS Analysis &#x2013; Mapping Climate Change"><div class="titlepage"><div><div><h1 class="title"><a id="ch02"/>Chapter 2. GIS Analysis – Mapping Climate Change</h1></div></div></div><p>One area of data analysis that's gotten a lot of attention is <span class="strong"><strong>Geographic Information Systems</strong></span> (<span class="strong"><strong>GIS</strong></span>). GIS is a system that is designed to store, manage, manipulate, and analyze geographic data. As such, GIS sits at the intersection of cartography, computers, statistics, and information science.</p><p>GIS is applied to fields as diverse as military planning, epidemiology, architecture, urban planning, archaeology, and many other fields. Basically, any domain or problem that involves location or topology can use GIS techniques or methods.</p><p>As you can imagine from this very brief description, we won't even scratch the surface of GIS in this chapter. However, we'll apply it to a small problem to see how it can help us understand the way climate change affects the continental <span class="strong"><strong>United States</strong></span> in a better manner.</p><div class="section" title="Understanding GIS"><div class="titlepage"><div><div><h1 class="title"><a id="ch02lvl1sec15"/>Understanding GIS</h1></div></div></div><p>While the <a id="id113" class="indexterm"/>preceding description is accurate, it doesn't really help us much. As befits a field concerned with the lay of the land, GIS really begins in the field. Data is gathered using aerial and satellite photography, and it is also gathered from people on the ground using<a id="id114" class="indexterm"/> GPS, laser range finders, and surveying tools. GIS can also make use of existing maps, especially for historical research and to compare time periods. For example, this may involve studying how a city has evolved over time or national boundaries have changed. A lot of time and energy in GIS goes into gathering this data and entering it into the computer.</p><p>Once the data is in the computer, GIS can perform a wide range and variety of analyses on the data, depending on the questions being asked and the task at hand. For example, the following are some of the many things you can do with GIS:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>View-shed analysis</strong></span>: This <a id="id115" class="indexterm"/>attempts to answer the question, "What<a id="id116" class="indexterm"/> can someone standing right here at this elevation (and perhaps at a second story window) see?". This takes into account the elevation and slope of the terrain around the viewer.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Topological modeling</strong></span>: This <a id="id117" class="indexterm"/>combines the GIS data with <a id="id118" class="indexterm"/>other data in the data mining and modeling to add a geospatial component to more mainstream data mining and modeling. This allows the models to account for the geographical proximity.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Hydrological modeling</strong></span>: This<a id="id119" class="indexterm"/> models the way in which water <a id="id120" class="indexterm"/>interacts with the environment through rainfall, watershed, runoff, and catchment.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Geocoding</strong></span>: This involves <a id="id121" class="indexterm"/>associating human-readable addresses with their geospatial coordinates. When you click on a <span class="strong"><strong>Google Map</strong></span><a id="id122" class="indexterm"/> or <span class="strong"><strong>Bing Map</strong></span><a id="id123" class="indexterm"/> and get the business <a id="id124" class="indexterm"/>or address of a location, it's because it's been geocoded for the coordinates you tapped on.</li></ul></div><p>The primary tool for most GIS specialists is <span class="strong"><strong>ArcGIS</strong></span><a id="id125" class="indexterm"/> by <span class="strong"><strong>ESRI</strong></span><a id="id126" class="indexterm"/> (<a class="ulink" href="http://www.esri.com/">http://www.esri.com/</a>). This <a id="id127" class="indexterm"/>is a powerful, full-featured GIS workbench. It interoperates with most data sources and performs most of the analyses. It also has an <span class="strong"><strong>API</strong></span> for <span class="strong"><strong>Python</strong></span> and APIs in <span class="strong"><strong>Java</strong></span> and <span class="strong"><strong>.NET</strong></span> to interact with ArcGIS servers. We'll use ArcGIS at the end of this chapter to generate the visualization.</p><p>However, there are other options as well. Most databases have some GIS capabilities, and <a id="id128" class="indexterm"/>
<span class="strong"><strong>Quantum GIS</strong></span><a id="id129" class="indexterm"/> (<a class="ulink" href="http://www.qgis.org/">http://www.qgis.org/</a>) is an open source alternative to ArcGIS. It <a id="id130" class="indexterm"/>isn't as polished or as fully featured, but it's still powerful in its own right and is freely available. <span class="strong"><strong>GeoServer</strong></span><a id="id131" class="indexterm"/> (<a class="ulink" href="http://geoserver.org/">http://geoserver.org/</a>) is an <a id="id132" class="indexterm"/>enterprise-level <a id="id133" class="indexterm"/>server and management system for the GIS data. There are also libraries in a number of programming languages; <span class="strong"><strong>Geospatial Data Abstraction Layer</strong></span>, also known as<a id="id134" class="indexterm"/> <span class="strong"><strong>GDAL</strong></span>, (<a class="ulink" href="http://www.gdal.org/">http://www.gdal.org/</a>) deserves <a id="id135" class="indexterm"/>special mention here, both in its own right and because it serves as the foundation for libraries in a number of other programming languages. One of the libraries for Java is<a id="id136" class="indexterm"/> <span class="strong"><strong>GeoTools</strong></span><a id="id137" class="indexterm"/> (<a class="ulink" href="http://www.geotools.org/">http://www.geotools.org/</a>), and part of it calls GDAL under the table.</p></div></div>
<div class="section" title="Mapping the climate change"><div class="titlepage"><div><div><h1 class="title"><a id="ch02lvl1sec16"/>Mapping the climate change</h1></div></div></div><p>So, let's roll up our sleeves and <a id="id138" class="indexterm"/>perform some geospatially informed data analysis.</p><p>For our problem, we'll look at how the climate change affects the continental United States over the last century or so. Specifically, we'll look at how the average maximum temperature for July has changed. For North America, this should give us a good snapshot of the hottest temperatures.</p><p>One nice thing about working with the weather data is that there's a lot of it, and it's easily available. <a id="id139" class="indexterm"/>
<span class="strong"><strong>US National Oceanic and Atmospheric Administration</strong></span> (<span class="strong"><strong>NOAA</strong></span>) collects it and maintains archives of it.</p><p>For this project, we'll use the <span class="strong"><strong>Global Summary of the Day</strong></span><a id="id140" class="indexterm"/> (<a class="ulink" href="http://www.ncdc.noaa.gov/cgi-bin/res40.pl">http://www.ncdc.noaa.gov/cgi-bin/res40.pl</a>). This includes daily summaries from each active weather station. We'll filter out any weather stations that aren't in the US, and we'll filter out any data that is not in use for the month of July.</p><p>Climate is typically defined on thirty-year periods. For example, the climate for a location would be the average temperature of thirty years, not the temperature for the year. However, there won't be that many thirty-year periods for the time span that we're covering, so instead, we'll look at the maximum temperature for July from each weather station in ten-year rolling averages.</p><p>To find out how much the maximum temperature has changed, we'll find the rolling average for these ten-year periods. Then, for each station, we'll find the difference between the first ten year period's average and the last one's.</p><p>Unfortunately, the stations aren't evenly or closely spaced; as we'll see, they also open and close over the years. So we'll do the best we can with this data, and we'll fill in the geospatial gaps in the data.</p><p>Finally, we'll graph this data over a map of the US. This will make it easy to see how temperatures have changed in different places. What will this process look like? Let's outline the steps for the rest of this chapter:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Download the data from NOAA's FTP servers. Extract it from the files.</li><li class="listitem">Filter out the data that we won't need for this analysis. We'll only hang onto places and the month that we're interested in (the US for July).</li><li class="listitem">Average the maximum temperatures for each month.</li><li class="listitem">Calculate the ten-year rolling averages of the averages from step three.</li><li class="listitem">Get the difference between the first and last ten-year averages for each weather station.</li><li class="listitem">Interpolate the temperature differences for the areas between the stations.</li><li class="listitem">Create a heat map of the differences.</li><li class="listitem">Review the results.</li></ol></div><div class="section" title="Downloading and extracting the data"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec21"/>Downloading and extracting the data</h2></div></div></div><p>As mentioned <a id="id141" class="indexterm"/>above, NOAA maintains an archive<a id="id142" class="indexterm"/> of GSOD. For each weather station around the world, these daily summaries track a wide variety of weather data for all active weather stations around the globe. We'll use the data from here as the basis of our analysis.</p><p>The data is available at <a class="ulink" href="ftp://ftp.ncdc.noaa.gov/pub/data/gsod/">ftp://ftp.ncdc.noaa.gov/pub/data/gsod/</a>. Let's look at how this data is stored and structured:</p><div class="mediaobject"><img src="graphics/4139OS_02_01.jpg" alt="Downloading and extracting the data"/></div><p>So, the main directory on the FTP site (<code class="literal">/pub/data/gsod/</code>) has a directory for each year that has the weather data. There's also a file called <code class="literal">ish-history.csv</code>. This contains information about the weather stations, when they were operational, and where they were located. (Also, the text files and <code class="literal">README</code> files are always important for more specific, detailed information about what's in each file.)</p><p>Now let's check <a id="id143" class="indexterm"/>out one of the data directories; this is for 2013.</p><p>The data directories <a id="id144" class="indexterm"/>contain a large number of data files. Each of the files that ends in <code class="literal">.op.gz</code> has three components for its file name. The first two parts are identifiers for the weather station and the third is the year.</p><p>Each data directory also has a tarball that contains all of the <code class="literal">*.op.gz</code> data files. That file will be the easiest to download, and then we can extract the <code class="literal">*.op.gz</code> files from it. Afterwards, we'll need to decompress these files to get the <code class="literal">*.op</code> data files. Let's do that, and then we can look at the data that we have.</p><div class="section" title="Downloading the files"><div class="titlepage"><div><div><h3 class="title"><a id="ch02lvl3sec01"/>Downloading the files</h3></div></div></div><p>Before we actually get <a id="id145" class="indexterm"/>into any of the code to do this, let's take a look at the dependencies that we'll need.</p><p>Before we get started, let's set up our project. For this chapter, our Leiningen 2<a id="id146" class="indexterm"/> (<a class="ulink" href="http://leiningen.org/">http://leiningen.org/</a>) <code class="literal">project.clj</code> file should look something like the following code:</p><div class="informalexample"><pre class="programlisting">(defproject clj-gis "0.1.0-SNAPSHOT"
  :dependencies [[org.clojure/clojure "1.5.1"]
                 [me.raynes/fs "1.4.4"]
                 [com.velisco/clj-ftp "0.3.0"]
                 [org.clojure/data.csv "0.1.2"]
                 [clj-time "0.5.1"]
                 [incanter/incanter-charts "1.5.1"]]
  :jvm-opts ["-Xmx4096m"])</pre></div><p>Now for this section of code, let's open the <code class="literal">src/clj_gis/download.clj</code> file. We'll use this namespace declaration for this code as follows:</p><div class="informalexample"><pre class="programlisting">(ns clj-gis.download
  (:require [clojure.java.io :as io]
            [me.raynes.fs.compression :as compression]
            [me.raynes.fs :as fs]
            [miner.ftp :as ftp]
            [clj-gis.locations :as loc]
            [clj-gis.util :as u])
  (:import [org.apache.commons.net.ftp FTP]
           [java.util.zip GZIPInputStream]
           [java.io BufferedInputStream]))</pre></div><p>Now, the next two <a id="id147" class="indexterm"/>functions together download the GSOD data files. The main function is <code class="literal">download-data</code>. It walks the directory tree on the FTP server, and whenever it identifies a file to be downloaded, it hands it off to <code class="literal">download-file</code>. This function figures out where to put the file and downloads it to that location. I've left out the source code for some of the utilities and secondary functions listed here, such as <code class="literal">download-src</code>, so that we can focus on the larger issues. You can find these functions in the file in this chapter's code download. The following code snippet is part of the code that is available for download:</p><div class="informalexample"><pre class="programlisting">(defn download-file
  "Download a single file from FTP into a download directory."
  [client download-dir dirname]
  (let [src (download-src dirname)
        dest (download-dest download-dir dirname)]
    (ftp/client-get client src dest)))

(defn download-data
  "Connect to an FTP server and download the GSOD data files."
  [uri download-dir data-dir]
  (let [download-dir (io/file download-dir)
        data-dir (io/file data-dir)]
    (ensure-dir download-dir)
    (ensure-dir data-dir)
    (ftp/with-ftp [client uri]
      (.setFileType client FTP/BINARY_FILE_TYPE)
      (doseq [dirname
              (filter get-year
                      (ftp/client-directory-names client))]
        (download-file client download-dir dirname)))))</pre></div></div><div class="section" title="Extracting the files"><div class="titlepage"><div><div><h3 class="title"><a id="ch02lvl3sec02"/>Extracting the files</h3></div></div></div><p>Now, we've<a id="id148" class="indexterm"/> downloaded the files from the NOAA FTP server onto the local hard drive. However, we still need to use the <code class="literal">tar</code> utility to extract the files we've downloaded and then decompress them.</p><p>We'll use the <span class="strong"><strong>FS</strong></span> library<a id="id149" class="indexterm"/> to extract the downloaded files. Currently, the individual data files are in a common Unix file format called <code class="literal">tar</code>, which collects multiple files into one larger file. These files are also compressed using the utility <a id="id150" class="indexterm"/>
<span class="strong"><strong>gzip</strong></span>. We'll use Java's <code class="literal">GZIPOutputStream</code> to decompress <code class="literal">gz</code>. Let's see how this works:</p><div class="informalexample"><pre class="programlisting">(defn untar
  "Untar the file into the destination directory."
  [input-file dest-dir]
  (compression/untar input-file dest-dir))

(defn gunzip
  "Gunzip the input file and delete the original."
  [input-file]
  (let [input-file (fs/file input-file)
        parts (fs/split input-file)
        dest (fs/file (reduce fs/file (butlast parts))
                      (first (fs/split-ext (last parts))))]
    (with-open [f-in (BufferedInputStream.
                       (GZIPInputStream.
                         (io/input-stream input-file)))]
      (with-open [f-out (io/output-stream dest)]
        (io/copy f-in f-out)))))</pre></div><p>We can put<a id="id151" class="indexterm"/> these functions together with the download functions that we just looked at. This function, <code class="literal">download-all</code>, will download all the data and then decompress all of the data files into a directory specified by <code class="literal">clj-gis.locations/*data-dir*</code>:</p><div class="informalexample"><pre class="programlisting">(defn download-all []
  (let [tar-dir (fs/file loc/*download-dir*)
        data-dir (fs/file loc/*data-dir*)]
    (download-data tar-dir data-dir)
    (doseq [tar-file (fs/list-dir tar-dir)]
      (untar (fs/file tar-dir tar-file) data-dir))
    (doseq [gz-file (fs/list-dir data-dir)]
      (gunzip (fs/file data-dir gz-file)))))</pre></div><p>Now, what do these files look like? The header line of one of them is as follows:</p><div class="informalexample"><pre class="programlisting">STN--- WBAN   YEARMODA    TEMP       DEWP      SLP        STP       VISIB      WDSP     MXSPD   GUST    MAX     MIN   PRCP   SNDP   FRSHTT</pre></div><p>The following is one of the data rows:</p><div class="informalexample"><pre class="programlisting">007032 99999  20130126    80.1 12    65.5 12  9999.9  0  9999.9  0  999.9  0    2.5 12    6.0  999.9    91.4*   71.6*  0.00I 999.9  000000</pre></div><p>So, there are some identification fields, some for temperature, dew point, wind, and other weather data. Next, let's see how to winnow the data down to just the information that we plan to use.</p></div></div><div class="section" title="Transforming the data – filtering"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec22"/>Transforming the data – filtering</h2></div></div></div><p>As we just noticed, there's a lot of<a id="id152" class="indexterm"/> data in the GSOD files that we don't plan to use. This includes the following:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Too many files with data for places that we aren't interested in</li><li class="listitem" style="list-style-type: disc">Too many rows with data for months that we aren't interested in</li><li class="listitem" style="list-style-type: disc">Too many columns with weather data that we aren't interested in (dew points, for instance)</li></ul></div><p>At this point, we'll only worry about the first problem. Just filtering out the places we're not looking at will dramatically reduce the amount of data that we're dealing with from approximately 20 GB of data to just 3 GB.</p><p>The code for this section will be in the <code class="literal">src/clj_gis/filter_data.clj</code> file. Give it the following namespace declaration:</p><div class="informalexample"><pre class="programlisting">(ns clj-gis.filter-data
  (:require
    [clojure.string :as str]
    [clojure.data.csv :as csv]
    [clojure.java.io :as io]
    [me.raynes.fs :as fs]
    [clj-gis.locations :as loc]
    [clj-gis.util :refer (ensure-dir)]))</pre></div><p>Now it's time for the code that is to be put in the rest of the file.</p><p>To filter out the data that we won't use, we'll copy files for stations in the United States into their own directory. We can create a set of these stations from the <code class="literal">ish-history.csv</code> file that we noticed earlier, so our first task will be parsing that file. This code will read the CSV file and put the data from each line into a new data record, <code class="literal">IshHistory</code>. Having its own data type for this information isn't necessary, but it makes the rest of the code much more readable. For example, we can reference the country field using <code class="literal">(:country h)</code> instead of <code class="literal">(nth h 3)</code> later. This type can also reflect the column order from the input file, which makes reading the data easier:</p><div class="informalexample"><pre class="programlisting">(defrecord IshHistory
  [usaf wban station_name country fips state call
   lat lon elevation begin end])
(defn read-history
  "Read the station history file."
  [filename]
  (with-open [f (io/reader filename)]
    (doall
      (-&gt;&gt; (csv/read-csv f)
        (drop 1)
        (map #(apply -&gt;IshHistory %))))))</pre></div><p>The stations are identified by the combination of the USAF and WBAN fields. Some stations use USAF, some use WBAN, and some use both. So we'll need to track both to uniquely identify the stations. This function will create a set of the stations in a given country:</p><div class="informalexample"><pre class="programlisting">(defn get-station-set
  "Create a set of all stations in a country."
  [country histories]
  (set (map #(vector (:usaf %) (:wban %))
            (filter #(= (:country %) country)
                    histories))))</pre></div><p>Finally, we need to<a id="id153" class="indexterm"/> tie these functions together. This function, <code class="literal">filter-data-files</code>, reads the history and creates the set of stations that we want to keep. Then, it walks through the data directory and parses the file names to get the station identifiers for each file. Files from the stations in the set are then copied to a directory with the same name as the country code, as follows:</p><div class="informalexample"><pre class="programlisting">(defn filter-data-files
  "Read the history file and copy data files matching the
  country code into a new directory."
  [ish-history-file data-dir country-code]
  (let [history (read-history ish-history-file)
        stations (get-station-set country-code history)]
    (ensure-dir (fs/file country-code))
    (doseq [filename (fs/glob (str data-dir "*.op"))]
      (let [base (fs/base-name filename)
            station (vec (take 2 (str/split base #"-")))]
        (when (contains? stations station)
          (fs/copy filename (fs/file country-code base)))))))</pre></div><p>This set of functions will filter out most of the data and leave us with only the observations from the stations we're interested in.</p></div><div class="section" title="Rolling averages"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec23"/>Rolling averages</h2></div></div></div><p>We aren't plotting the<a id="id154" class="indexterm"/> raw data. Instead, we want to filter it further and summarize it. This transformation can be described in the following steps:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Process only the observations for the month of July.</li><li class="listitem">Find the mean temperature for the observations for the month of July for each year, so we'll have an average for July 2013, July 2012, July 2011, and so on.</li><li class="listitem">Group these monthly averages into rolling ten-year windows. For example, one window will have the observations for 1950 to 1960, another window will have observations for 1951 to 1961, and so on.</li><li class="listitem">Find the mean temperature for each of these windows for a climatic average temperature for July for that period.</li><li class="listitem">Calculate the change in the maximum temperature by subtracting the climatic average for the last window for a station from the average of its first window.</li></ol></div><p>This breaks down<a id="id155" class="indexterm"/> the rest of the transformation process pretty well. We can use this to help us structure and write the functions that we'll need to implement the process. However, before we can get into that, we need to read the data.</p><div class="section" title="Reading the data"><div class="titlepage"><div><div><h3 class="title"><a id="ch02lvl3sec03"/>Reading the data</h3></div></div></div><p>We'll read the <a id="id156" class="indexterm"/>data from the space-delimited data files and store the rows in a new record type. For this section, let's create the <code class="literal">src/clj_gis/rolling_avg.clj</code> file. It will begin with the following namespace declaration:</p><div class="informalexample"><pre class="programlisting">(ns clj-gis.rolling-avg
  (:require
    [clojure.java.io :as io]
    [clojure.string :as str]
    [clojure.core.reducers :as r]
    [clj-time.core :as clj-time]
    [clj-time.format :refer (formatter parse)]
    [clojure.data.csv :as csv]
    [me.raynes.fs :as fs]
    [clj-gis.filter-data :as fd]
    [clj-gis.locations :as loc]
    [clj-gis.types :refer :all]
    [clj-gis.util :as u]))</pre></div><p>Now, we can define a data type for the weather data. We'll read the data into an instance of <code class="literal">WeatherRow</code>, and then we'll need to normalize the data to make sure that the values are ones that we can use. This will involve converting strings to numbers and dates, for instance:</p><div class="informalexample"><pre class="programlisting">(defrecord WeatherRow
  [station wban date temp temp-count dewp dewp-count slp
   slp-count stp stp-count visibility vis-count wdsp
   wdsp-count max-wind-spd max-gust max-temp min-temp
   precipitation snow-depth rfshtt])
(defn read-weather
  [filename]
  (with-open [f (io/reader filename)]
    (doall
      (-&gt;&gt; (line-seq f)
        (r/drop 1)
        (r/map #(str/split % #"\s+"))
        (r/map #(apply -&gt;WeatherRow %))
        (r/map normalize)
        (r/remove nil?)
        (into [])))))</pre></div><p>Now that we have the<a id="id157" class="indexterm"/> weather data, we can work it through the pipeline as outlined in the preceding code snippet. This series of functions will construct a sequence of reducers.</p><p>
<span class="strong"><strong>Reducers</strong></span>, introduced<a id="id158" class="indexterm"/> in Clojure 1.5, are a relatively new addition to the language. They refine traditional functional-style programming. Instead of <code class="literal">map</code> taking a function and a sequence and constructing a new sequence, the reducers' version of <code class="literal">map</code> takes a function and a sequence or folder (the core reducer data type) and constructs a new folder that will apply the function to the elements of the input when required. So, instead of constructing a series of sequences, it composes the functions into a larger function that performs the same processing, but only produces the final output. This saves on allocating the memory, and if the input data types are structured correctly, the processing can also be automatically parallelized as follows:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">For the first step, we want to return only the rows that fall in the month we're interested in. This looks almost exactly like a regular call to <code class="literal">filter</code>, but instead of returning a new, lazy sequence, it returns a folder that has the same effect; it produces a sequence with only the data rows we want. Or, we can compose this with other folders to further modify the output. This is what we will do in the next few steps:<div class="informalexample"><pre class="programlisting">(defn only-month
  "1. Process only the observations for the month of July."
  [month coll]
  (r/filter #(= (clj-time/month (:date %)) month) coll))</pre></div></li><li class="listitem">This function takes the reducer from the first step and passes it through a few more steps. The <code class="literal">group-by</code> function finally reifies the sequence into a hash map. However, it's immediately fed into another reducer chain that averages the accumulated temperatures for each month:<div class="informalexample"><pre class="programlisting">(defn mean [coll]
  (/ (sum coll) (double (count coll))))
(defn get-monthly-avgs
  "2. Average the observations for each year's July, so
  we'll have an average for July 2013, one for July 2012,
  one for July 2011, and so on."
  [weather-rows]
  (-&gt;&gt; weather-rows
    (group-by #(clj-time/year (:date %)))
    (r/map (fn [[year group]]
             [year (mean (map :max-temp group))]))))</pre></div></li><li class="listitem">For step three, <a id="id159" class="indexterm"/>we create a series of moving windows across the monthly averages. If there aren't enough averages to create a full window, or if there are only enough to create one window, then we throw those extra observations out:<div class="informalexample"><pre class="programlisting">(defn get-windows
  "3. Group these monthly averages into a rolling ten-year
  window. For example, one window will have the
  observations for 1950–1960. Another window will have 
  observations for 1951–1961. And so on."
  [period month-avgs]
  (-&gt;&gt;
    month-avgs
     (into [])
     (sort-by first)
     (partition period 1)
     (r/filter #(&gt; (count %) 1))
     (r/map #(vector (ffirst %) (map second %))))))</pre></div></li><li class="listitem">This step uses a utility function, <code class="literal">mean</code>, to get the average temperature for each window. We saw this defined in step two. This keeps hold of the starting year for that window so they can be properly ordered:<div class="informalexample"><pre class="programlisting">(defn average-window
  "4. Average each of these windows for a climatic average
  temperature for July for that period."
  [windows]
  (r/map (fn [[start-year ws]] [start-year (mean ws)])
         windows))</pre></div></li><li class="listitem">After this, we do a little more filtering to only pass the averages through,and then we replace the list of averages with the difference between the initial and the final averages:<div class="informalexample"><pre class="programlisting">(defn avg-diff
  "5. Calculate the change in maximum temperature by 
  subtracting the climatic average for the last window for 
  a station from the average of its first window."
  [avgs]
  (- (last avgs) (first avgs)))</pre></div></li></ol></div><p>There's more to this, of course. We have to get a list of the files to be processed, and we need to do something with the output; either send it to a vector or to a file. </p><p>Now that we've made it this far, we're done transforming our data, and we're ready to start our analysis.</p></div></div><div class="section" title="Interpolating sample points and generating heat maps using inverse distance weighting (IDW)"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec24"/>Interpolating sample points and generating heat maps using inverse distance weighting (IDW)</h2></div></div></div><p>In the end, we're going to<a id="id160" class="indexterm"/> feed the data we've just <a id="id161" class="indexterm"/>created to ArcGIS in order to create the heat map, but before we do that, let's try to understand what will happen under the covers.</p><p>For this code, let's open up the <code class="literal">src/clj_gis/idw.clj</code> file. The namespace for this should be like the following code:</p><div class="informalexample"><pre class="programlisting">(ns clj-gis.idw
  (:require [clojure.core.reducers :as r]
            [clj-gis.types :refer :all]))</pre></div><p>To generate a <span class="strong"><strong>heat map</strong></span>, we first <a id="id162" class="indexterm"/>start with a sample of<a id="id163" class="indexterm"/> points for the space we're looking at. Often, this space is geographical, but it doesn't have to be. Values for a complex, computationally-expensive, two-dimensional function are another example where a heat map would be useful. It would take too long to completely cover the input domain, and inverse distance weighting could be used to fill in the gaps.</p><p>The sample data points each have a value, often labeled <span class="emphasis"><em>z</em></span> to imply a third dimension. We want a way to interpolate the <span class="emphasis"><em>z</em></span> value from the sample points onto the spaces between them. The heat map visualization is just the result of assigning colors to ranges of <span class="emphasis"><em>z</em></span> and plotting these values.</p><p>One common technique to interpolate the value of <span class="emphasis"><em>z</em></span> to points between the sample points is called <a id="id164" class="indexterm"/>
<span class="strong"><strong>inverse distance weighting (IDW)</strong></span>. To find the interpolated value of <span class="emphasis"><em>z</em></span> for a point <span class="emphasis"><em>x, y</em></span>, IDW sees how much the value of each sample point influences that location, given each sample's distance away and a value <span class="emphasis"><em>p</em></span> that determines how far each sample point's influence carries. Low values of <span class="emphasis"><em>p</em></span> don't project much beyond their immediate vicinity. High values of <span class="emphasis"><em>p</em></span> can be projected too far. We'll see some examples of this in a minute.</p><p>There are a variety of ways to calculate the IDW. One general form is to sum the weighted difference between the data point in question and all others, and divide it by the non-weighted sum.</p><div class="mediaobject"><img src="graphics/4139OS_02_02.jpg" alt="Interpolating sample points and generating heat maps using inverse distance weighting (IDW)"/></div><p>There are several variations of IDW, but here, we'll just describe the base version, as outlined by Donald Shepard in 1968. First, we have to determine the inverse distance function. It's given here as <code class="literal">w</code>. Also, <code class="literal">x_i</code> is the sample point, and <code class="literal">x</code> is the point to estimate the interpolation for, just as <a id="id165" class="indexterm"/>given in the<a id="id166" class="indexterm"/> preceding formula:</p><div class="informalexample"><pre class="programlisting">(defn w
  "Finds the weighted inverse distance between the points x and
  x_i. "
  ([p dist-fn x] (partial w p dist-fn x))
  ([p dist-fn x x_i]
   (/ 1.0 (Math/pow (dist-fn x x_i) p))))</pre></div><p>With this in place, <a id="id167" class="indexterm"/>IDW is the sum of <code class="literal">w</code> for each point in the sample, multiplied by that sample point's value and divided by the sum of <code class="literal">w</code> for <a id="id168" class="indexterm"/>all the samples. It's probably easier to parse the code than it is to describe it verbosely:</p><div class="informalexample"><pre class="programlisting">(defn sum-over [f coll] (reduce + (map f coll)))
(defn idw
  ([sample-points data-key p dist-fn]
   (partial idw sample-points data-key p dist-fn))
  ([sample-points data-key p dist-fn point]
<span class="strong"><strong>   (float</strong></span>
<span class="strong"><strong>     (/ (sum-over #(* (w p dist-fn point %) (data-key %))</strong></span>
<span class="strong"><strong>                  sample-points)</strong></span>
<span class="strong"><strong>        (sum-over (w p dist-fn point) sample-points))))</strong></span>
  ([sample-points data-key p dist-fn lat lon]
   (idw sample-points data-key p dist-fn
        (-&gt;DataPoint lat lon nil))))</pre></div><p>The highlighted part of the function is the part to pay attention to. The rest makes it easier to call <code class="literal">idw</code> in different contexts. I precompute the denominator in the <code class="literal">let</code> form, as it won't change for each sample point that is considered. Then, the distances of each sample point and the target point are multiplied by the value of each sample point and divided by the denominator, and this is summed together.</p><p>This function is easy <a id="id169" class="indexterm"/>to call with the charting <a id="id170" class="indexterm"/>library<a id="id171" class="indexterm"/> that <span class="strong"><strong>Incanter</strong></span><a id="id172" class="indexterm"/> provides, which has a very nice heat map function. Incanter is a library used to perform data analysis and visualization in Clojure by interfacing with high-performance Java libraries. This function first gets the bounding box around the data and pads it a little. It then uses Incanter's <code class="literal">heat-map</code> function to generate the heat map. To make<a id="id173" class="indexterm"/> it more useful, however, we then make the heat map transparent and plot the points from the sample onto the chart. This is found in <code class="literal">src/clj_gis/heatmap.clj</code>:</p><div class="informalexample"><pre class="programlisting">(defn generate-hm
  [sample p border]
  (let [{:keys [min-lat max-lat min-lon max-lon]}
        (min-max-lat-lon sample)]
    (-&gt;
      (c/heat-map (idw sample :value p euclidean-dist)
                  (- min-lon border) (+ max-lon border)
                  (- min-lat border) (+ max-lat border))
      (c/set-alpha 0.5)
      (c/add-points (map :lon sample) (map :lat sample)))))</pre></div><p>Let's take a random data sample and use it to see what different values of <code class="literal">p</code> do.</p><p>For the first experiment, let's look at <span class="emphasis"><em>p=1</em></span>:</p><div class="informalexample"><pre class="programlisting">(i/view (hm/generate-hm sample 1.0 5.0))</pre></div><p>The graph it produces looks like the following figure:</p><div class="mediaobject"><img src="graphics/4139OS_02_03.jpg" alt="Interpolating sample points and generating heat maps using inverse distance weighting (IDW)"/></div><p>We can see <a id="id174" class="indexterm"/>that the <a id="id175" class="indexterm"/>influence for each sample <a id="id176" class="indexterm"/>point is tightly bound to its <a id="id177" class="indexterm"/>immediate neighborhood. More moderate values, around 4 and 5, dominate.</p><p>For <span class="emphasis"><em>p=8</em></span>, the picture is a bit different, as shown in the following screenshot:</p><div class="mediaobject"><img src="graphics/4139OS_02_04.jpg" alt="Interpolating sample points and generating heat maps using inverse distance weighting (IDW)"/></div><p>In the preceding figure, each interpolated <a id="id178" class="indexterm"/>point<a id="id179" class="indexterm"/> is more heavily influenced by <a id="id180" class="indexterm"/>the data points closest to it, and further points are less influential. More extreme regions have great influence over larger distances, except around sample points with moderate values.</p><p>Finally, we'll look at an interpolated point that's more balanced. The following is the chart for when <span class="emphasis"><em>p=3</em></span>:</p><div class="mediaobject"><img src="graphics/4139OS_02_05.jpg" alt="Interpolating sample points and generating heat maps using inverse distance weighting (IDW)"/></div><p>This seems <a id="id181" class="indexterm"/>much more balanced. Each<a id="id182" class="indexterm"/> sample<a id="id183" class="indexterm"/> point clearly exerts its influence across its own neighborhood. However, no point, and no range of values, appears to dominate. A more meaningful graph with real data would probably <a id="id184" class="indexterm"/>look quite good.</p><p>So far, we've been playing with the toy data. Before we can apply this to the climate data that we prepared earlier, there are several things we need to take into consideration.</p></div></div>
<div class="section" title="Working with map projections"><div class="titlepage"><div><div><h1 class="title"><a id="ch02lvl1sec17"/>Working with map projections</h1></div></div></div><p>Have you looked at a <a id="id185" class="indexterm"/>world wall map and noticed how big Greenland is? It's huge. It's larger than China, the United States, and Australia, and is about as big as Africa. Too bad it's so cold, or we could fit a lot of people up there. Or could we?</p><p>Actually, Australia is about three and a half times as big as Greenland, China is almost four and a half times as big, and Africa is almost fourteen times as large!</p><p>What's going on? The <span class="strong"><strong>Mercator projection</strong></span><a id="id186" class="indexterm"/> is what's going on. It was developed by the Flemish cartographer Gerardus Mercator in 1569. Over time, it's become very popular, at least partially so because it fits nicely onto a rectangular page without wasting a lot of space around the edges, the way some projections do.</p><p>A map projection is a transformation of locations on a sphere or ellipsoid onto locations on a plane. You can think of it as a function that transforms latitudes and longitudes of the earth into the x and y coordinates on a sheet of paper. This allows us to take a point on a map and find it on the earth, take a point on the earth and find it on the map, or take a point on one map and find it on another.</p><p>Mercator is a common projection. It's created by wrapping a cylindrical sheet of paper around the globe, only touching along the equator. Then, the shapes on the globe are cast out onto the paper roll like beams of light spreading out. This was developed for navigation, and if you chart a course with a constant bearing, it plots on a Mercator map as a straight line. However, its <a id="id187" class="indexterm"/>major problem is that it distorts shapes around the edges, for example, Greenland or Antarctica.</p><p>There are a number of other common projections, such as the following:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The <span class="strong"><strong>Gall-Peters</strong></span> projection<a id="id188" class="indexterm"/> accurately shows the area but distorts the shape.</li><li class="listitem" style="list-style-type: disc">The <span class="strong"><strong>Eckert IV</strong></span> projection<a id="id189" class="indexterm"/> distorts the outer shape of the map onto an ovoid to minimize the area distortions of the Mercator projection, although it still distorts the shapes of things near the poles.</li><li class="listitem" style="list-style-type: disc">The <span class="strong"><strong>Goode homolosine</strong></span> projection<a id="id190" class="indexterm"/> attempts to accurately portray both the area and shape by cutting the <span class="emphasis"><em>skin</em></span> off the globe into some awkward shapes. It's sometimes called the <span class="emphasis"><em>orange peel map</em></span> because the outlines of the map look like you peeled an orange by hand and flattened it on the table top.</li></ul></div><p>So how does this apply to our project?</p><p>On the one hand, we need some way to accurately measure the distances between points in the real world. For example, as we're working in the northern hemisphere, the points near the top of the map, to the north, will be closer together than the points near the bottom. We need to know the projection in order to measure these distances correctly and correctly calculate the interpolations.</p><p>To put it another way, the distance between two points that are a degree of longitude apart would be different, depending on their latitude. In Grand Forks, North Dakota, the distance between longitude -97 and -96 is approximately 46 miles (74.5 km). On the other hand, the distance between longitudes -97 and -96, just west of Houston, Texas, is almost 60 miles (96.52 km). Think of the way in which two lines that are parallel on the equator have to curve towards each other as they converge at the poles.</p><p>On the other hand, we also <a id="id191" class="indexterm"/>need to then be able to know which pixel a set of latitude and longitude correspond to. In order to actually plot the heat map on the screen, we have to be able to determine which pixel gets which color, depending on the interpolated points on the map.</p><div class="section" title="Finding a base map"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec25"/>Finding a base map</h2></div></div></div><p>Related to the projections, <a id="id192" class="indexterm"/>we also need to have a base layer to display the heat map on top of it. Without being able to see the context of the underlying geography, a heat map is more confusing than it is illuminating.</p><p>There are maps available that have their locations encoded in their metadata. <span class="strong"><strong>GeoTIFF</strong></span><a id="id193" class="indexterm"/> is one such format. GIS packages can layer the data and information on top of these base maps to provide more complex, interesting, and useful visualizations and analyses.</p></div></div>
<div class="section" title="Working with ArcGIS"><div class="titlepage"><div><div><h1 class="title"><a id="ch02lvl1sec18"/>Working with ArcGIS</h1></div></div></div><p>Working with<a id="id194" class="indexterm"/> projections and base maps can be fiddly and prone to errors. While there are Java libraries that can help us with this, let's use the major software package in this domain, <span class="strong"><strong>ArcGIS</strong></span>, for the purposes of this demonstration. While it's awesome to be able to program solutions in a powerful, flexible language like Clojure, sometimes, it's nicer to get pretty pictures quickly.</p><p>We're going to start this by getting the base layer. ESRI maintains a set of topological maps, and this map of the United States is perfect for this:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Navigate to <a class="ulink" href="http://www.arcgis.com/home/item.html?id=99cd5fbd98934028802b4f797c4b1732">http://www.arcgis.com/home/item.html?id=99cd5fbd98934028802b4f797c4b1732</a> to view ESRI's page on the <a id="id195" class="indexterm"/><span class="strong"><strong>US Topo Maps</strong></span>.</li><li class="listitem">Click on the <span class="strong"><strong>Open</strong></span> dropdown.</li><li class="listitem">Select the option that allows you to get <span class="strong"><strong>ArcGIS Desktop</strong></span> to open the layer.</li></ol></div><div class="mediaobject"><img src="graphics/4139OS_02_07.jpg" alt="Working with ArcGIS"/></div><p>Now we'll <a id="id196" class="indexterm"/>add our data. This was created using the functions that we defined earlier as well as a few more that are available in this chapter's code download:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">The data is available at <a class="ulink" href="http://www.ericrochester.com/clj-data-master/temp-diffs.csv">http://www.ericrochester.com/clj-data-master/temp-diffs.csv</a>. Point your web browser there and download the file. Don't forget where you put it!</li><li class="listitem">In ArcGIS, navigate to <span class="strong"><strong>File</strong></span> | <span class="strong"><strong>Add Data</strong></span> | <span class="strong"><strong>Add XY Data</strong></span>.</li><li class="listitem">Select the <code class="literal">temp-diffs.csv</code> file, and specify <code class="literal">z</code> for the <span class="strong"><strong>z</strong></span> field.</li><li class="listitem">We'll also need to change the projection of the input data. To do this, click on <span class="strong"><strong>Edit...</strong></span> to edit the projection.</li><li class="listitem">In the new dialog box, <span class="strong"><strong>Select</strong></span> a predefined coordinate system. Navigate to <span class="strong"><strong>Coordinate Systems</strong></span> | <span class="strong"><strong>Geographic Coordinate Systems</strong></span> | <span class="strong"><strong>North America</strong></span> | <span class="strong"><strong>NAD 1983</strong></span>.</li><li class="listitem">When the file is ready to load, the dialog should look like what is shown in the following screenshot:<div class="mediaobject"><img src="graphics/4139OS_02_08.jpg" alt="Working with ArcGIS"/></div></li><li class="listitem">Once the<a id="id197" class="indexterm"/> data is in place, we need to set the color scheme for the <span class="strong"><strong>z</strong></span> field. Right-click on the new layer and select <span class="strong"><strong>Properties</strong></span>. Select the <span class="strong"><strong>Symbology</strong></span> tab and get the graduated colors the way you like them.</li><li class="listitem">After I was done playing, the dialog box looked like what is shown in the following screenshot:<div class="mediaobject"><img src="graphics/4139OS_02_09.jpg" alt="Working with ArcGIS"/></div></li><li class="listitem">Now we get to the good part. Open up <span class="strong"><strong>Catalog</strong></span> and select <span class="strong"><strong>IDW tool</strong></span>. It is done by navigating to <span class="strong"><strong>System Toolboxes</strong></span> | <span class="strong"><strong>Geostatistical Analyst Tools</strong></span> | <span class="strong"><strong>Interpolation</strong></span>. Generate the heat map into a new layer.</li><li class="listitem">Once ArcGIS is done, the heat map will be too opaque to see the underlying geography. Right-click on the heat map layer and select <span class="strong"><strong>Properties</strong></span>. In the <span class="strong"><strong>Display</strong></span> tab, change the opacity to something reasonable. I used <code class="literal">0.40</code>.</li></ol></div><p>The final results are shown as follows:</p><div class="mediaobject"><img src="graphics/4139OS_02_10.jpg" alt="Working with ArcGIS"/></div><p>We can see<a id="id198" class="indexterm"/> that for a large part of the nation, things have heated up. The west part of the great lakes have cooled a bit, but the Rocky Mountains have especially gotten warmer.</p></div>
<div class="section" title="Summary"><div class="titlepage"><div><div><h1 class="title"><a id="ch02lvl1sec19"/>Summary</h1></div></div></div><p>This has been a fun little experiment. Looking at the data, however, suggests caution. Some of the stations have been in operation long enough to have only a few of the sliding windows defined. Others have been operational for much longer. This makes it difficult to compare the aggregated numbers from the different different stations, which is what we're doing by creating the heat map.</p><p>Nevertheless, this does point to some interesting areas of future enquiry, and it provides a brief glimpse of what geographical information systems can provide and how to use them. They can add a geospatially informed edge to the modeling and analysis, which isn't possible with the data, tools, and techniques they bring to the table.</p><p>In this next chapter, we'll turn our attention to sifting through free-form textual data using topic modeling.</p></div></body></html>