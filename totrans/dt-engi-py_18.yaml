- en: '*Chapter 15*: Real-Time Edge Data with MiNiFi, Kafka, and Spark'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you will learn how **Internet-of-Things** (**IoT**) devices,
    small computers, and sensors can send data into a data pipeline using Apache NiFi.
    For computers or devices with little processing power, MiNiFi allows them to be
    part of a NiFi data pipeline. MiNiFi is a lightweight version of NiFi with a stripped-down
    set of processors and no graphical user interface. It is built to send data using
    a data pipeline built into NiFi and deployed to the device.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we''re going to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Setting up MiNiFi on a device
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building and deploying a MiNiFi task in NiFi
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Setting up MiNiFi
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Apache MiNiFi is a lightweight version of NiFi, to be used in data collection
    at the source. Increasingly, the source has become smaller IoT devices, sensors,
    and low-powered computers such as the Raspberry Pi. To incorporate these devices
    into your data pipelines, you need a way to get the data off the device. MiNiFi
    allows you to stream the data to NiFi as part of a standard data pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: 'To get the MiNiFi binary, browse to [https://nifi.apache.org/minifi/](https://nifi.apache.org/minifi/).
    The following screenshot is of the MiNiFi home page and will provide you with
    information and documentation for the project:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 15.1 – The Apache MiNiFi home page'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_15.1_B15739.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 15.1 – The Apache MiNiFi home page
  prefs: []
  type: TYPE_NORMAL
- en: From the main navigation bar, go to **Downloads** and select the **Download
    MiNiFi Components** option. You will need to decide whether you want to run the
    MiNiFi Java or MiNiFi C++ version. Which version is appropriate will depend on
    the specifications of the device where MiNiFi will live. If you need the smallest
    footprint and memory usage, then the C++ version is for you. If you have more
    resources and need to have a wider selection of available processors, then the
    Java version is your best bet. You can find a list of processors by category,
    with descriptions at [https://nifi.apache.org/docs/nifi-docs/html/getting-started.html#what-processors-are-available](https://nifi.apache.org/docs/nifi-docs/html/getting-started.html#what-processors-are-available).
  prefs: []
  type: TYPE_NORMAL
- en: You can always copy the `NAR` file for any processor in NiFi and put it in the
    MiNiFi `lib` directory. Some processors will require you to also copy and send
    the `NAR` file for the controller service. This chapter will use the MiNiFi Java
    version.
  prefs: []
  type: TYPE_NORMAL
- en: Download the most current version of MiNiFi (Java), which is currently 0.5.0\.
    Select the `minifi-0.5.0-bin.tar.gz` link and download it. You will also need
    to scroll further down the page and select the corresponding version of the MiNiFi
    toolkit binaries. Both the C++ and Java versions use the same toolkit, so you
    will only need to select the right release – 0.5.0\. Download the `minifi-toolkit-0.5.0-bin.tar.gz`
    file.
  prefs: []
  type: TYPE_NORMAL
- en: 'Extract and copy MiNiFi and the MiNiFi toolkit to your home directory using
    the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: I dropped `-0.5.0` when I moved `minifi` and `minifi-toolkit` to my home directory.
    In this chapter, I will run MiNiFi on the same machine as NiFi – as I have done
    with Kafka and Spark – but if you want to run MiNiFi on another device, as you
    would in production, copy the `minifi-0.5.0` directory to that machine. The MiNiFi
    toolkit stays on the NiFi machine.
  prefs: []
  type: TYPE_NORMAL
- en: 'The last step is to set the `$MINIFI_HOME` variable to the location of MiNiFi.
    You can either export the variable and add it to your path, or the better way
    would be to edit your `.bashrc` file, as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Your `.bashrc` file will look as in the following screenshot. Notice that I
    have the edits from the previous chapter on Apache Spark just above the MiNiFi
    edits:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 15.2 – A .bashrc file with exports for Spark and MiNiFi'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_15.2_B15739.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 15.2 – A .bashrc file with exports for Spark and MiNiFi
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have MiNiFi configured and the MiNiFi toolkit ready to go, it is
    time to create your first data pipeline in Apache NiFi. The next section will
    walk you through creating one.
  prefs: []
  type: TYPE_NORMAL
- en: Building a MiNiFi task in NiFi
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, you will build a data pipeline and deploy it to MiNiFi. The
    data pipeline will generate flow files and send them to NiFi. The next section
    will take this further and use a processor that is not included with MiNiFi.
  prefs: []
  type: TYPE_NORMAL
- en: To use MiNiFi, you will need an older version of NiFi. The current tool – 0.5.0
    – breaks because of changes to properties output from the `nifi` template. It
    will be fixed in 0.6.0, but until then, you will need to use at least version
    1.9.0 of NiFi. You can get older NiFi versions at [https://archive.apache.org/dist/nifi/1.9.0/](https://archive.apache.org/dist/nifi/1.9.0/).
    Unzip NiFi using the `tar` command with the `-xvzf` flags. Place the folder in
    your home directory using `mv` or your file explorer tools.
  prefs: []
  type: TYPE_NORMAL
- en: 'You will also need an older version of Java. To install the correct version
    of Java, use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Lastly, you will also need to make sure that NiFi is configured to allow site-to-site
    connections. In a terminal, go to `$NIFI_HOME/conf` and open the `nifi.properties`
    file. Scrolling about halfway down the file, you will see the `Site to Site properties`
    section. In my file, `nifi.remote.input.socket.port` is blank. If there is not
    a port specified, edit the file so that the port is `1026`, as shown in the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 15.3 – Site-to-site properties with input.socket.port set to 1026'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_15.3_B15739.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 15.3 – Site-to-site properties with input.socket.port set to 1026
  prefs: []
  type: TYPE_NORMAL
- en: Next, start NiFi and create an input port to connect MiNiFi with NiFi. Drag
    and drop the input port to the canvas and name it `minifi`. Data from MiNiFi will
    enter NiFi through this port.
  prefs: []
  type: TYPE_NORMAL
- en: 'Connect the input port to a data pipeline. The pipeline is shown in the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 15.4 – Data pipeline to consume MiNiFi data and write to file on the
    NiFi host'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_15.4_B15739.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 15.4 – Data pipeline to consume MiNiFi data and write to file on the
    NiFi host
  prefs: []
  type: TYPE_NORMAL
- en: 'To build the data pipeline, take the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Drag and drop the `EvaluteJsonPath` processor to the canvas. Configure the `flowfile-attribute`.
    Create a new property named `fname` and set the value to `$.fname`. This will
    be in the JSON received from MiNiFi.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Drag and drop the `UpdateAttribute` processor to the canvas. Create a new property
    named `filename` and set the value to `${fname}`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Drag and drop the `PutFile` processor to the canvas. Set the `/home/paulcrickard/output`.
    Leave the other properties as the defaults.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The preceding steps create the connection from MiNiFi to NiFi, but right now,
    we do not have a data pipeline for MiNiFi. To create the MiNiFi data pipeline,
    drag and drop a processor group to the canvas and name it `minifitask`.
  prefs: []
  type: TYPE_NORMAL
- en: Inside the processor group, drag and drop the `GenerateFlowfile` processor to
    the canvas. On the `30 sec`. Set the `{"fname":"minifi.txt","body":"Some text"}`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, you will add a `http://localhost:9300` and the `HTTP`. Leave the rest
    as the defaults, or blank. The settings should look as in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 15.5 – Remote processor group configuration](img/Figure_15.5_B15739.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 15.5 – Remote processor group configuration
  prefs: []
  type: TYPE_NORMAL
- en: 'Connect the `GenerateFlowFile` processor to **Remote Processor Group**. The
    **Create Connection** popup will allow you to select the input port as **To Input**.
    It would have guessed correctly and chosen MiNiFi. If not, use the dropdown to
    select the MiNiFi port you created in the previous steps. Once the processors
    are connected, right-click on **Remote Processor Group** and select **Enable Transmission**.
    The icon should now be a blue circle, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 15.6 – MiNiFi data pipeline to a remote processor group'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_15.6_B15739.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 15.6 – MiNiFi data pipeline to a remote processor group
  prefs: []
  type: TYPE_NORMAL
- en: The MiNiFi data pipeline is complete. To make sure it is runnable on MiNiFi,
    you need to transform it. To transform it, you will need to export it as a template.
    To create the template, exit the processor group. Right-click on the processor
    group, then select `minifitask` template by clicking the download icon to the
    right of the table. This will download an XML version of the data pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: 'To transform the template, you will run `config.sh` in the MiNiFi toolkit.
    I have made a `minifi-templates` folder in my home directory. Changing directories
    to `$MINIFI_HOME`, run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'If everything worked properly, you should get a message like the one shown
    in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 15.7 – minifi-toolkit transforming the XML template into a YML file'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_15.7_B15739.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 15.7 – minifi-toolkit transforming the XML template into a YML file
  prefs: []
  type: TYPE_NORMAL
- en: You will now have a `config.yml` file in your `minifi-templates` directory.
    Copy this file to the `$MINIFI_HOME/conf` directory. You can overwrite the existing
    `config.yml` file that came with MiNiFi.
  prefs: []
  type: TYPE_NORMAL
- en: 'From the `$MINIFI_HOME/bin` directory, you can start `minifi` and it will read
    your `config.yml` file when it does. Use the following command to start MiNiFi:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Your MiNiFi data pipeline is now running. You can view the logs at `$MINIFI_HOME/logs/minifi-app.log`.
    But you can also now open NiFi and look at the data streaming in from MiNiFi through
    the `FromMinifi` input port. Your NiFi data pipeline should look as in the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 15.8 – The data pipeline receiving data on the input port from MiNiFi'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_15.8_B15739.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 15.8 – The data pipeline receiving data on the input port from MiNiFi
  prefs: []
  type: TYPE_NORMAL
- en: You will notice that the processor group you used to create the template is
    stopped. The data is coming from MiNiFi into the NiFi instance and being processed
    and saved to the disk of the NiFi machine. The MiNiFi machine only sends data,
    which allows it to not be overwhelmed with trying to run a version of NiFi locally
    or to have to make remote connections to other machines to write out files at
    intervals. Streaming data can be sent from the MiNiFi machine to NiFi.
  prefs: []
  type: TYPE_NORMAL
- en: Once the MiNiFi data is streaming into NiFi, you have the full range of tools
    available to you to process this data. You could send it to a Kafka topic, as
    shown in [*Chapter 13*](B15739_13_ePub_AM.xhtml#_idTextAnchor140), *Streaming
    Data with Kafka*, and make it available to many other tools listening on the topic.
    MiNiFi opens up the possibility of capturing data from small devices.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned how MiNiFi provides a means by which you can stream
    data to a NiFi instance. With MiNiFi, you can capture data from sensors, smaller
    devices such as a Raspberry Pi, or on regular servers where the data lives, without
    needing a full NiFi install. You learned how to set up and configure a remote
    processor group that allows you to talk to a remote NiFi instance.
  prefs: []
  type: TYPE_NORMAL
- en: In the [*Appendix*](B15739_16_ePub_AM.xhtml#_idTextAnchor163), you will learn
    how you can cluster NiFi to run your data pipelines on different machines so that
    you can further distribute the load. This will allow you to reserve servers for
    specific tasks, or to spread large amounts of data horizontally across the cluster.
    By combining NiFi, Kafka, and Spark into clusters, you will be able to process
    more data than any single machine.
  prefs: []
  type: TYPE_NORMAL
