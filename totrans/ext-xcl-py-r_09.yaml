- en: '9'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Statistical Analysis: Linear and Logistic Regression'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Welcome to our comprehensive guide on linear and logistic regression using
    R and Python, where we will explore these essential statistical techniques using
    two popular frameworks: `tidymodels` and base R and Python. Whether you’re a data
    science enthusiast or a professional looking to sharpen your skills, this tutorial
    will help you gain a deep understanding of **linear** and **logistic regression**
    and how to implement them in R and Python. Now, it is possible to perform linear
    and logistic regression. The issue here is that linear regression can only be
    performed on a single series of ungrouped data, and performing logistic regression
    is cumbersome and may require the use of external solver add-ins. Also, the process
    can only be performed against ungrouped or non-nested data. In R and Python, we
    do not have such limitations.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics in both base R and Python
    and using the `tidymodels` framework:'
  prefs: []
  type: TYPE_NORMAL
- en: Performing linear regression in both base R and Python and the `tidymodels`
    frameworks as well as in Python
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Performing logistic regression in both base R and Python and the `tidymodels`
    frameworks as well as in Python
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'All code for this chapter can be found on GitHub at this URL: [https://github.com/PacktPublishing/Extending-Excel-with-Python-and-R/tree/main/Chapter9](https://github.com/PacktPublishing/Extending-Excel-with-Python-and-R/tree/main/Chapter9).
    You will need the following R packages installed to follow along:'
  prefs: []
  type: TYPE_NORMAL
- en: '`readxl 1.4.3`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`performance 0.10.8`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tidymodels 1.1.1`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`purrr 1.0.2`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will begin by learning about what linear and logistic regression are and
    then move into the details of everything.
  prefs: []
  type: TYPE_NORMAL
- en: Linear regression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Linear regression is a fundamental statistical method used for modeling the
    relationship between a dependent variable (usually denoted as “Y”) and one or
    more independent variables (often denoted as “X”). It aims to find the best-fitting
    linear equation that describes how changes in the independent variables affect
    the dependent variable. Many of you may know this as the **ordinary least squares**
    (**OLS**) method.
  prefs: []
  type: TYPE_NORMAL
- en: In simpler terms, linear regression helps us predict a continuous numeric outcome
    based on one or more input features. For this to work, if you are unaware, many
    assumptions must be held true. If you would like to understand these more, then
    a simple search will bring you a lot of good information on them. In this tutorial,
    we will delve into both simple linear regression (one independent variable) and
    multiple linear regression (multiple independent variables).
  prefs: []
  type: TYPE_NORMAL
- en: Logistic regression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Logistic regression is another crucial statistical technique, which is primarily
    used for binary classification problems. Instead of predicting continuous outcomes,
    logistic regression predicts the probability of an event occurring, typically
    expressed as a “yes” or “no” outcome. This method is particularly useful for scenarios
    where we need to model the likelihood of an event, such as whether a customer
    will churn or not or whether an email is spam or not. Logistic regression models
    the relationship between the independent variables and the log odds of the binary
    outcome.
  prefs: []
  type: TYPE_NORMAL
- en: Frameworks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will explore two approaches to implementing linear and logistic regression
    in R. First, we will use the base R framework, which is an excellent starting
    point to understand the underlying concepts and functions. Then, we will dive
    into `tidymodels`, a modern and tidy approach to modeling and machine learning
    in R. `tidymodels` provides a consistent and efficient way to build, tune, and
    evaluate models, making it a valuable tool for data scientists. In Python, we
    will parallel this exploration with two prominent libraries: `sklearn` and `statsmodels`.
    `sklearn`, or Scikit-learn, offers a wide array of simple and efficient tools
    for predictive data analysis that are accessible to everybody and reusable in
    various contexts. `statsmodels` is more focused on statistical models and hypothesis
    tests. Together, these Python libraries offer a robust framework for implementing
    linear and logistic regression, catering to both machine learning and statistical
    needs.'
  prefs: []
  type: TYPE_NORMAL
- en: Throughout this chapter, we will provide step-by-step instructions, code examples,
    and practical insights to ensure that you can confidently apply linear and logistic
    regression techniques to your own data analysis projects.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s embark on this learning journey and unlock the power of regression analysis
    in R! With this in place, we move to the first example in base R using the `iris`
    dataset we saved in [*Chapter 1*](B19142_01.xhtml#_idTextAnchor014).
  prefs: []
  type: TYPE_NORMAL
- en: Performing linear regression in R
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For this section, we are going to perform linear regression in R, both in base
    R and by way of the `tidymodels` framework. In this section, you will learn how
    to do this on a dataset that has different groups in it. We will do this because
    if you can learn to do it this way, then doing it in a single group becomes simpler
    as there is no need to group data and perform actions by group. The thought process
    here is that by doing it on grouped data, we hope you can learn an extra skill.
  prefs: []
  type: TYPE_NORMAL
- en: Linear regression in base R
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first example we are going to show is using the `lm()` function to perform
    a linear regression in base R. Let’s dive right into it with the `iris` dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will break the code down into chunks and discuss what is happening at each
    step. The first step for us is to use the `library` command to bring in the necessary
    packages into our development environment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'In this section, we’re loading a library called `readxl`. Libraries are collections
    of pre-written R functions and code that we can use in our own R scripts. In this
    case, we’re loading the `readxl` library, which is commonly used for reading data
    from Excel files. The path assumes you have a `chapter1` folder and a data file
    in it called `iris_data.xlsx`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we’re reading data from an Excel file named `iris_data.xlsx`, located
    in the `chapter1` folder. We’re specifically reading the `iris` sheet from that
    Excel file. The `read_xlsx` function is used for this purpose. The resulting data
    is stored in a variable called `df`. The `head(df)` function displays the first
    few rows of this data frame (`df`) so we can see what it looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: This code splits the `df` dataset into multiple subsets based on the unique
    values in the `species` column. The result is a list of data frames where each
    data frame contains only the rows that correspond to a specific species of `iris`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we are going to define what will be the dependent and independent variables
    along with the `formula` object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Here, we’re defining the variables needed for linear regression. `dependent_variable`
    is `petal_length`, which is the variable we want to predict. `independent_variables`
    are `petal_width`, `sepal_length`, and `sepal_width`, which are the variables
    we’ll use to predict the dependent variable.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code then creates an `f_x` formula that represents the linear regression
    model. It essentially says that we want to predict `petal_length` using the other
    variables listed, separated by a plus sign:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'In this part, we’re defining a custom R function called `perform_linear_regression`.
    This function takes one `data` argument, which is a data frame. Inside the function,
    we use the `lm` function to perform linear regression, using the `f_x` formula
    we defined earlier and the provided data frame. The resulting linear model is
    stored in `lm_model`, and we return it as the output of the function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we’re applying the `perform_linear_regression` function to each subset
    of the `iris` dataset using the `lapply` function. This means that we’re running
    linear regression separately for each species of iris, and the results are stored
    in the `results` list:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'This code uses `lapply` again, but this time we’re applying the `summary` function
    to each linear regression model in the `results` list. The `summary` function
    provides statistical information about the linear regression model, such as coefficients
    and R-squared values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'These lines of code are used to create a set of four plots to visualize the
    model performance. We first set the layout of the plots to be a 2x2 grid using
    `par(mfrow = c(2,2))`, so that 4 plots will be displayed in a 2x2 grid. Then,
    we use `lapply` to plot each linear regression model in the `results` list. Finally,
    we reset the plot layout to the default with `par(mfrow =` `c(1, 1))`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: This part accomplishes the same linear regression analysis as before but combines
    the linear model creation and summarization into a more concise form using anonymous
    functions. It first applies the `lm` function to each species subset within `iris_split`,
    creating a list of linear models stored in `lm_models`. Then, it uses `lapply`
    to obtain summaries for each of these linear models.
  prefs: []
  type: TYPE_NORMAL
- en: In summary, this R code reads iris data from an Excel file, performs linear
    regression for each species of `iris`, summarizes the results, and creates visualizations
    to assess the model’s performance. It provides a detailed analysis of how the
    dependent variable (`petal_length`) is influenced by independent variables (`petal_width`,
    `sepal_length`, and `sepal_width`) for each species of `iris`.
  prefs: []
  type: TYPE_NORMAL
- en: Linear regression with tidymodels and purrr
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now that we have gone over how to perform a simple linear regression in R on
    the `iris` dataset, we will do the same with the `tidymodels` framework. Let’s
    dive right into it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'This block defines a formula for the linear regression model. The `formula()`
    function takes two arguments: the response variable and the predictor variables.
    The response variable is the variable that we want to predict, and the predictor
    variables are the variables that we think can help us predict the response variable.
    In this case, the response variable is `petal_width` and the predictor variables
    are `petal_length`, `sepal_width`, and `sepal_length`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: This block creates a nested linear regression model using the `nest()` function
    from the `tidyr` package. The `nest()` function groups the data by a specified
    variable, in this case, the `species` variable.
  prefs: []
  type: TYPE_NORMAL
- en: For each group, the `nest()` function creates a list containing the data for
    that group. The `mutate()` function is then used to add new columns to the nested
    data frame.
  prefs: []
  type: TYPE_NORMAL
- en: The `split()` function is used to randomly split the data in each group into
    a training set and a test set. The `training()` and `testing()` functions are
    then used to select the training and test sets, respectively. With `map()` and
    `map2()`, we can iterate over a vector or list or two vectors or lists and apply
    a function to them.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `lm()` function is used to fit a linear regression model to the training
    data in each group. The `predict()` function is then used to predict the response
    variable for the test data in each group using the fitted linear regression model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: This block selects the `species` and `pred` columns from the nested data frame
    and unnests the `pred` column. The `unnest()` function converts the nested data
    frame to a regular data frame, with one row for each observation.
  prefs: []
  type: TYPE_NORMAL
- en: The resulting data frame is a nested linear regression model, with one fitted
    linear regression model for each species.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s take a look at an example. We are going to use the `f_x` formula that
    was created earlier along with the `df` `tibble` variable we created at the beginning.
    The following code shows an example of how to use the nested linear regression
    model to predict the petal width for a new iris flower:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The predicted petal width is 1.45 cm. We have now finished going over linear
    regression in R with a basic example. We will now continue the chapter in the
    next section on performing logistic regression in R.
  prefs: []
  type: TYPE_NORMAL
- en: Performing logistic regression in R
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we did in the section on linear regression, in this section, we will also
    perform logistic regression in base R and with the `tidymodels` framework. We
    are going to only perform a simple binary classification regression problem using
    the `Titanic` dataset, where we will be deciding if someone is going to survive
    or not. Let’s dive right into it.
  prefs: []
  type: TYPE_NORMAL
- en: Logistic regression with base R
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In order to get going, we are going to start with a base R implementation of
    logistic regression on the `Titanic` dataset where we will be modeling the response
    of `Survived`. So, let’s get straight into it.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the code that will perform the data modeling along with explanations
    of what is happening:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'This block of code starts by loading a library called `tidyverse`, which contains
    various data manipulation and visualization tools. It then creates a data frame
    called `df` by taking the `Titanic` dataset (assuming it’s available in your environment)
    and performing three operations on it using the `|>` operator, where we then use
    `as.data.frame()`, which converts the dataset into a data frame, followed by `uncount(Freq)`,
    which repeats each row in the dataset according to the value in the `Freq` column.
    This is often done to expand summarized data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'This section is about splitting the data into a training set and a test set,
    which is a common practice in machine learning:'
  prefs: []
  type: TYPE_NORMAL
- en: '`set.seed(123)`: This sets a random seed for reproducibility, ensuring that
    random operations produce the same results each time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sample(nrow(df), floor(nrow(df) * 0.8), replace = FALSE)`: This randomly selects
    80% of the rows in the `df` data frame (the training set) without replacement
    and stores their indices in `train_index`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`train <- df[train_index, ]`: This creates the training set by selecting the
    rows from `df` using the `train_index` indices.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`test <- df[-train_index, ]`: This creates the test set by selecting the rows
    from `df` that are not in the training set. We next create the model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now let’s discuss the model code as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: This block trains a logistic regression model using the `glm` function.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model is trained to predict the `Survived` variable based on the `Sex`,
    `Age`, and `Class` variables in the training data. Here, `Age` is actually discrete.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `family = "binomial"` argument specifies that this is a binary classification
    problem, where the outcome is either `Yes` or `No`. The following link helps in
    choosing an appropriate family: [https://stats.stackexchange.com/a/303592/35448](https://stats.stackexchange.com/a/303592/35448).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now, let’s set up the model predictions and response variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let’s go over what we just did:'
  prefs: []
  type: TYPE_NORMAL
- en: Here, we use the trained model to make predictions on the test set.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`predict(model, newdata = test, type = "response")` calculates the predicted
    probabilities of survival for each passenger in the test set.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ifelse(predictions <= 0.5, "No", "Yes")` converts these probabilities into
    binary predictions: `"No"` if the probability is less than or equal to `0.5`,
    and `"Yes"` otherwise. This is common practice, but you must know your project
    first in order to determine if this is correct or not. Now, onto the `accuracy`
    variable:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We created the `accuracy` variable by doing the following:'
  prefs: []
  type: TYPE_NORMAL
- en: This line calculates the accuracy of the model’s predictions by comparing `pred_resp`
    (the model’s predictions) to the actual survival status in the test set (`test$Survived`).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'It computes the mean of the resulting logical values, where `TRUE` represents
    a correct prediction, and `FALSE` represents an incorrect prediction. Let’s now
    go over the rest of the code:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The code prints two things:'
  prefs: []
  type: TYPE_NORMAL
- en: The accuracy of the model on the test set.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A confusion matrix that shows how many predictions were correct and how many
    were incorrect. If you would like to understand confusion matrices more, here
    is a good link: [https://www.v7labs.com/blog/confusion-matrix-guide](https://www.v7labs.com/blog/confusion-matrix-guide).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In summary, this code loads a dataset, splits it into a training and test set,
    trains a logistic regression model to predict survival, evaluates the model’s
    accuracy, and displays the results. It’s a basic example of a binary classification
    machine learning workflow. Now that we have covered performing logistic regression
    for a classification problem in base R, we will try our hand at the same but this
    time using the `tidymodels` framework.
  prefs: []
  type: TYPE_NORMAL
- en: Performing logistic regression using tidymodels
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, we will use the `tidymodels` framework to perform the logistic
    regression on the `Titanic` dataset. Since we have done this in base R already,
    let’s get right into it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'This code loads the two libraries that we will need for our analysis: `tidymodels`
    and `healthyR.ai`. `tidymodels` is a library that provides a common interface
    for many machine learning algorithms, while `healthyR.ai` provides a set of tools
    for evaluating the performance of machine learning models:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'This code converts the `Titanic` dataset to a `tibble`, which is a data structure
    that is compatible with `tidymodels`. It also uncounts the `n` column, which is
    a column that contains the number of times each row appears in the dataset and
    is created by the `uncount()` function. Finally, it converts all the character
    variables in the dataset to factors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'This code splits the `df` dataset into training and test sets. The training
    set is used to train the model, while the test set is used to evaluate the performance
    of the model on unseen data. The `initial_split()` function from `tidymodels`
    is used to perform the split. The `prop` argument specifies the proportion of
    the data that should be used for training. In this case, we are using 80% of the
    data for training and 20% of the data for testing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'This code trains a logistic regression model to predict survival on the Titanic.
    The `recipe()` function from `tidymodels` is used to pre-process the data. The
    `logistic_reg()` function from `tidymodels` is used to specify the logistic regression
    model. The `workflow()` function from `tidymodels` is used to combine the recipe
    and model into a workflow. Finally, the `fit()` function from `tidymodels` is
    used to train the model on the training data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'This code predicts the survival probability for each passenger in the test
    set. The `predict()` function from `tidymodels` is used to make the predictions.
    The `new_data` argument specifies the data that we want to make predictions on.
    In this case, we are making predictions on the test set. The `bind_cols()` function
    is used to bind the predictions to the test set data. The `select()` function
    is used to select the columns that we want to keep. The `pred_fit_tbl` object
    is a `tibble` instance that contains the predictions from the model, as well as
    the ground truth survival labels. This object will be used to evaluate the performance
    of the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: The accuracy check code block evaluates the performance of the model on the
    test set. It does this by using the `hai_default_classification_metric_set()`
    function from the healthyR.ai package to create a set of default classification
    metrics. These metrics include accuracy, precision, recall, and F1 score.
  prefs: []
  type: TYPE_NORMAL
- en: The `perf()` function is then used to calculate the accuracy metrics on the
    test set. The `pred_fit_tbl` object is the data frame that contains the predictions
    from the model, as well as the ground truth survival labels. The `truth` and `estimate`
    arguments specify the columns in the data frame that contain the ground truth
    and predicted labels, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: The `conf_mat()` function is then used to print the confusion matrix for the
    model. The confusion matrix is a table that shows how many observations were correctly
    and incorrectly predicted by the model.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the `tidy()` and `glance()` functions from the `broom` package can
    be used to tidy and summarize the fitted model. The `tidy()` function converts
    the model object to a `tibble` instance, which is a data structure that is easy
    to work with. The `glance()` function prints a summary of the model, including
    the coefficients, standard errors, and p-values for all of the variables in the
    model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a simple explanation of each of the accuracy metrics that are calculated
    in the accuracy check code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Accuracy**: The accuracy of a model is the proportion of observations that
    are correctly predicted by the model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Precision**: The precision of a model is the proportion of positive predictions
    that are correct.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Recall**: The recall of a model is the proportion of actual positive observations
    that are correctly predicted by the model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**F1 score**: The F1 score is a harmonic mean of the precision and recall metrics.
    It is a good overall measure of the performance of a model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The confusion matrix is a helpful tool for understanding how the model is performing.
    The ideal confusion matrix would have all of the observations on the diagonal,
    indicating that all of the observations were correctly predicted. However, in
    practice, no model is perfect and there will be some observations that are incorrectly
    predicted.
  prefs: []
  type: TYPE_NORMAL
- en: 'Lastly, we will visualize the model with a **receiver operating characteristic**
    (**ROC**) curve. To read more about this type of curve, you can see the following
    link: [https://www.tmwr.org/performance](https://www.tmwr.org/performance). Here
    is the code that creates the ROC curve:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.1 – ROC curve for the logistic regression model](img/B19142_09_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.1 – ROC curve for the logistic regression model
  prefs: []
  type: TYPE_NORMAL
- en: Now, we have learned how to perform both linear and logistic regression in both
    base R and via the `tidymodels` modeling framework. We did this with the `Titanic`
    and `iris` datasets. Now, it’s time to do the same in Python!
  prefs: []
  type: TYPE_NORMAL
- en: Performing linear regression in Python using Excel data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Linear regression in Python can be carried out with the help of libraries such
    as `pandas`, `scikit-learn`, `statsmodels`, and `matplotlib`. The following is
    a step-by-step code example:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, import the necessary libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then, we create an Excel file with test data. Of course, in a real-life scenario,
    you would not need the mock data – you would skip this step and load the data
    from Excel (see the next step) after loading the necessary libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, import the data from the Excel file with test data and prepare it for
    analysis using tools you have learned in the previous chapter:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we are ready to carry out the actual analysis. Split the data into training
    and test data so we can evaluate the model on a dedicated data (sub)set, then
    fit the **Ordinary Least Squares** (**OLS**) linear model on the training data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note that doing imputation as part of the data cleaning process before splitting
    the test and training sets may lead to pollution of the test set from the training
    set. Be conscious of this when performing the data cleaning and preparation steps!
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Next, evaluate the trained model on the test data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will create summary statistics as the output that provides valuable insights
    into the relationships within your dataset:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 9.2 – Summary statistics of the model fitted](img/B19142_09_2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.2 – Summary statistics of the model fitted
  prefs: []
  type: TYPE_NORMAL
- en: 'Actual interpretation of model results is a topic that is beyond the scope
    of this book, but here are some hints to get you started:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Coefficients**: The coefficients associated with each independent variable
    (predictor) in the model tell you about the strength and direction of the relationship.
    A positive coefficient indicates a positive correlation, meaning that as the predictor
    increases, the target variable tends to increase as well. Conversely, a negative
    coefficient signifies a negative correlation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Intercept**: The intercept represents the predicted value of the target variable
    when all predictor variables are set to zero. It’s essential to consider the intercept’s
    value in the context of your analysis.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**R-squared (****R**2**)**: The R-squared value measures the goodness of fit
    of the model. It tells you the proportion of variance in the target variable that
    can be explained by the predictors. Higher R-squared values (closer to 1) indicate
    a better fit. Note that adding more variables will always increase this measure.
    A “better” fit might result in “overfitting,” which is something we don’t want.
    You may want to check model-fit selection criteria such as Mallow’s Cp, AIC, BIC,
    and adjusted R-squared, which penalizes the number of parameters used to fit the
    model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**P-values**: P-values associated with coefficients help determine the statistical
    significance of each predictor. Lower p-values suggest greater significance (in
    the sense that it is stronger evidence to reject the null hypothesis). If a p-value
    is less than a chosen significance level (for example, 0.05), you can conclude
    that the predictor has a statistically significant effect on the target variable.
    Please be aware that there are good reasons to not rely on p-values alone; see
    the ongoing debate on p-hacking and related topics in statistical science.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Residuals**: Examining the residuals (the differences between the observed
    and predicted values) is crucial for assessing model performance. Ideally, residuals
    should be random, with no apparent patterns. Patterns in residuals may indicate
    model misspecification.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Confidence intervals**: Confidence intervals around coefficients provide
    a range within which the true population parameter is likely to lie. Wider intervals
    indicate greater uncertainty.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**F-statistic**: The F-statistic tests the overall significance of the model.
    A small F-statistic suggests that the model doesn’t explain much variance in the
    target variable, while a large value indicates a better overall fit.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Adjusted R-squared**: Adjusted R-squared adjusts the R-squared value for
    the number of predictors in the model. It helps you determine whether adding more
    predictors improves the model’s fit.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By carefully examining these elements, you can gain insights into how well the
    linear model fits your data, the significance of predictor variables, and the
    overall quality of the model. This information is invaluable for making informed
    decisions and drawing meaningful conclusions from your analysis.
  prefs: []
  type: TYPE_NORMAL
- en: 'With the model trained and the fit evaluated, we can visualize the results
    to help with interpretation. The following code creates a scatterplot of predicted
    versus observed values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the scatterplot for it:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.3 – Linear regression prediction plot](img/B19142_09_3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.3 – Linear regression prediction plot
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition, we can create diagnostic plots and visualizations such as residual
    plots and Q-Q plots, which can help you identify potential issues with the model,
    such as heteroscedasticity or outliers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'The two preceding plots look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.4 – Residuals plot](img/B19142_09_4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.4 – Residuals plot
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.5 – Residuals Q-Q plot](img/B19142_09_5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.5 – Residuals Q-Q plot
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we can export the results to Excel. This will be covered in detail
    in the next subsection.
  prefs: []
  type: TYPE_NORMAL
- en: As a side note, `scikit-learn` also has an in-built linear model but that does
    not come with the handy summary statistics we have used in the preceding code.
  prefs: []
  type: TYPE_NORMAL
- en: This code demonstrated a basic linear regression workflow using Python and Excel
    data. Let’s move on to logistic regression!
  prefs: []
  type: TYPE_NORMAL
- en: Logistic regression in Python using Excel data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the following code, we generate random sample data with two features (`Feature1`
    and `Feature2`) and a binary target variable (`Target`) based on a simple condition.
    We perform logistic regression, evaluate the model using accuracy, the confusion
    matrix, and a classification report, visualize the results for binary classification,
    and interpret the coefficients.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is a step-by-step code example:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Again, we start with importing the necessary libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'For this example, we will use a different sample dataset:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'With your data available in Excel, we can read it and prepare it for the modeling
    step:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we can create and fit a model. We will use the `scikit-learn` library
    this time:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'With a model fit, we can now visualize the results:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Unlike with linear regression, we need different goodness-of-fit metrics because
    we are using logistic regression for a binary classification:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The result looks like this:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 9.6 – Logistic regression prediction plot](img/B19142_09_6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.6 – Logistic regression prediction plot
  prefs: []
  type: TYPE_NORMAL
- en: 'This is the code result:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.7 – Model summary statistics](img/B19142_09_7.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.7 – Model summary statistics
  prefs: []
  type: TYPE_NORMAL
- en: 'To interpret the preceding results, you can start with the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Accuracy` is a fundamental metric, representing the ratio of correctly predicted
    instances to the total number of instances. While easy to understand, accuracy
    can be misleading if there’s an imbalance between the classes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Confusion Matrix` offers a more detailed view. It breaks down predictions
    into four categories: true positives, true negatives, false positives, and false
    negatives. This matrix provides a clear understanding of how well the model performs
    in terms of correctly classifying positive and negative instances.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Classification Report` provides a comprehensive summary. It includes metrics
    such as `precision`, `recall`, `f1-score`, and `support` for both classes. `Precision`
    measures how many predicted positives were actually positive, while `recall` quantifies
    how many actual positives were correctly predicted. The `F1-score` balances `precision`
    and `recall`. `Support` denotes the number of instances for each class. Together,
    these metrics offer a more nuanced evaluation of the model’s performance in binary
    classification tasks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can use this sample data and code for testing and experimenting with logistic
    regression.
  prefs: []
  type: TYPE_NORMAL
- en: Please note that contrary to the popular (but incorrect) assertion, logistic
    regression can be used as a regression as well – what makes it a classifier is
    an arbitrary cut-off point for the predicted probability. For some use cases,
    you might want to use the raw regression output (if, for example, you are interested
    in the predicted probability of the data point belonging to a class, and not the
    more likely class only) and for others, you might want to play with the cut-off
    point (if, for example, there is pre-existing domain information that implies
    that 50% is not the right cut-off point).
  prefs: []
  type: TYPE_NORMAL
- en: That’s it! Logistic regression is a relatively simple model with lots of benefits.
    It’s performant, easy to fit, easy to interpret, and very versatile. It’s most
    often used for classification with a domain-knowledge-driven cut-off point, but
    under the hood, it remains a regression method that can be used for predicting
    class probabilities.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we explored the powerful world of linear and logistic regression
    using Excel data. Linear regression, a fundamental statistical technique, allows
    us to model relationships between dependent and independent variables. We discussed
    its assumptions and applications, and walked through the entire process of loading
    data from Excel, preparing it for analysis, and fitting linear regression models
    using both R (using base R and `tidymodels`) and Python (with the `scikit-learn`
    and `statsmodels` libraries).
  prefs: []
  type: TYPE_NORMAL
- en: Through comprehensive code examples, you learned how to perform regression analysis,
    assess model accuracy, and generate valuable statistics and metrics to interpret
    model results. We gained insights into creating diagnostic plots, such as residual
    plots and Q-Q plots, which aid in identifying issues such as heteroscedasticity
    and outliers.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, we delved into logistic regression, a powerful tool for class
    probability prediction and binary classification tasks. We established its importance
    and applications and outlined the process of data preparation, model fitting,
    and metrics evaluation. With practical code examples, we observed how logistic
    regression models can be constructed using `tidymodels` in R and the `scikit-learn`
    library in Python.
  prefs: []
  type: TYPE_NORMAL
- en: By the end of this chapter, you should have a strong grasp of linear and logistic
    regression, from theory to practical application, and the ability to harness these
    techniques to analyze your data efficiently.
  prefs: []
  type: TYPE_NORMAL
- en: With these skills, you are well-equipped to conduct regression analyses and
    extract valuable insights from your data in Python.
  prefs: []
  type: TYPE_NORMAL
- en: On to the next chapter, where you will learn about time series analysis and
    its applications to Excel data.
  prefs: []
  type: TYPE_NORMAL
