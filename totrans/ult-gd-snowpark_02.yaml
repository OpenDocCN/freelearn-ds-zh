- en: '1'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Discovering Snowpark
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Snowpark is the recent major innovation released by Snowflake that provides
    an intuitive set of libraries and runtimes for querying and processing data at
    scale in Snowflake. This chapter aims to guide you through Snowpark to understand
    its unique capabilities. In addition, the chapter helps you learn how to utilize
    Python with Snowpark and implement it in various workloads such as data engineering,
    data science, and data applications. By the end of this chapter, you will have
    grasped Snowpark’s capabilities and benefits, including faster data processing,
    scalability, and reduced costs.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’re going to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Introducing Snowpark
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Leveraging Python for Snowpark
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding Snowpark for different workloads
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Realizing the value of using Snowpark
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introducing Snowpark
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Snowflake, founded in 2012, started its journey to the data cloud by completely
    re-engineering the world of data and rethinking how a reliable, secure, high-performance,
    and scalable data-processing system should be architected for the cloud. It started
    with offering cloud-based data warehousing through a managed **Software as a Service**
    (**SaaS**) platform to load, analyze, and process large volumes of data. The success
    of Snowflake lies in the fact that it is a cloud-native managed solution that
    is built on top of the major public cloud providers such as Amazon Web Services,
    Microsoft Azure, and Google Cloud Platform by automatically providing a reliable,
    secure, high-performance, and scalable data processing system for organizations
    without the need to deploy hardware or install or configure any software.
  prefs: []
  type: TYPE_NORMAL
- en: As with any cloud data warehousing, Snowflake supports **American National Standards
    Institute** (**ANSI**) SQL as the language of choice. Although SQL is a powerful
    declarative language that allows users to ask questions about data, it is constrained
    to data warehouse workloads, limiting the support for advanced workloads such
    as data science and data engineering, which require developers to write the solution
    in other programming languages leading them to move data out of Snowflake to perform
    these workloads.
  prefs: []
  type: TYPE_NORMAL
- en: Snowflake’s solution to this challenge is **Snowpark**, an innovative developer
    framework that streamlines the process of building complex data pipelines. With
    Snowpark, data scientists and developers can directly interact with Snowflake
    using their preferred programming language, enabling them to quickly and securely
    deploy **machine learning** (**ML**) models, execute data pipelines, and develop
    data applications on Snowflake’s virtual compute warehouse in a serverless manner
    without having to transfer data outside of Snowflake.
  prefs: []
  type: TYPE_NORMAL
- en: Snowpark enables data teams to collaborate on the data by natively supporting
    work with DataFrame style programming in Python, Scala, or Java, exposing deeply
    integrated interfaces in these languages to augment Snowflake’s original SQL language
    and minimizing the complexity of having to manage different environments for advanced
    data pipelines. This has led developers to leverage Snowflake’s robust and scalable
    computing power to ship code to the data without exporting it outside Snowflake
    into other environments.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we covered a brief introduction to Snowpark and learned how
    it fits into the Snowflake ecosystem and how it helps developers. The following
    section will cover how to leverage Python for Snowpark.
  prefs: []
  type: TYPE_NORMAL
- en: Leveraging Python for Snowpark
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In June 2022, Snowflake made a significant announcement, revealing the much-anticipated
    **Snowpark for Python**. This new release has rapidly emerged as the preferred
    programming language for Snowpark, providing users with a more extensive range
    of options for programming data in Snowflake. Moreover, Snowpark has simplified
    managing data architectures, enabling users to operate more quickly and efficiently.
  prefs: []
  type: TYPE_NORMAL
- en: Snowpark for Python is a cutting-edge, enterprise-grade, open-source innovation
    integrated into the Snowflake data cloud. As a result, the platform delivers a
    seamless, unified experience for data scientists and developers. In addition,
    the Snowpark for Python package is built upon the Snowflake Python connector.
    The Python connector enables users to execute SQL commands and other essential
    functions in Snowflake and Snowpark for Python empowers users to undertake more
    advanced data applications.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, the platform permits users to run **user-defined functions** (**UDFs**),
    **external functions**, and **stored procedures** directly within Snowflake. This
    powerful new functionality enables data scientists, engineers, and developers
    to create robust and secure data pipelines and ML models within Snowflake. As
    a result, they can leverage the platform’s superior performance, elasticity, and
    security features to deliver advanced insights and drive meaningful business outcomes.
    Overall, Snowpark for Python represents a significant step forward for Snowflake,
    offering users enhanced functionality and flexibility while retaining the platform’s
    exceptional performance and security features.
  prefs: []
  type: TYPE_NORMAL
- en: Snowpark for Python supports pre-vetted open-source packages through integration
    with the **Anaconda** environment that executes on an Anaconda-powered sandbox
    inside Snowflake’s virtual compute warehouses, which provides a familiar interface
    for the developers. The integrated Anaconda package manager is valuable for developers
    as it comes with a comprehensive set of curated open-source packages and supports
    resolving dependencies between different packages and versions. It is a huge time-saver
    and helps prevent developers from dealing with “dependency hell.”
  prefs: []
  type: TYPE_NORMAL
- en: Capabilities of Snowpark for Python
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Snowpark for Python is generally available across all cloud instances of Snowflake.
    It helps accelerate different workloads and comes with a rich set of capabilities,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: It allows developers to write Python code within Snowflake, enabling them to
    directly leverage the power of Python libraries and frameworks in Snowflake
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It supports popular open-source Python libraries such as pandas, NumPy, SciPy,
    and scikit-learn, along with other libraries, allowing developers to perform complex
    data analysis and ML tasks directly within Snowflake
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It also provides access to external data sources such as AWS S3, Azure Blob
    storage, and Google Cloud Storage, allowing developers to work with data stored
    outside Snowflake
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It provides seamless integration with Snowflake’s SQL engine, allowing developers
    to write queries using functional programming methods with Python that compile
    to SQL
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It also supports distributed processing, allowing developers to scale their
    Python code to handle large datasets and complex logic
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It enables developers to build custom UDFs that can be used within SQL queries,
    allowing for greater flexibility and customization of data processing workflows
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Snowpark provides a Python development environment within Snowflake, allowing
    developers to write, test, and debug Python code directly within the Snowflake
    UI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It enables developers to work with various data formats such as CSV, JSON, Parquet,
    and Avro, providing data processing and analysis flexibility
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It provides a unified data processing experience that works with SQL and Python
    in a single environment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It enables developers to create custom data pipelines using Python code, making
    integrating Snowflake with other data sources and data processing tools easier
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It can handle real-time and batch data processing, making it easier to build
    data-intensive workloads
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It provides a robust framework built on Snowflake that ensures data privacy
    and compliance with industry standards such as the **Health Insurance Portability
    and Accountability Act** (**HIPAA**), **General Data Protection Regulation** (**GDPR**),
    and **Security Operations** **Center** (**SOC**)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Snowpark supports enhancing data by leveraging **Snowflake Marketplace**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Snowpark for Python packs many capabilities that help developers use it efficiently
    for various workloads and use cases within Snowflake.
  prefs: []
  type: TYPE_NORMAL
- en: Why Python for Snowpark
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Although Snowpark supports Python, Scala, and Java, this book will focus only
    on Python, a de facto for Snowpark development. Python’s growing popularity through
    high-level built-in data structures with dynamic typing and binding makes it ideal
    for data operations. In addition, the language is very flexible and easy to learn
    by developers. Its power lies in the rich open-source ecosystem that is well-supported
    with a growing list of popular packages.
  prefs: []
  type: TYPE_NORMAL
- en: Python is a general-purpose, versatile programming language for different purposes,
    such as data engineering, data science, and data applications. It enables developers
    to learn a single programming language for all their needs.
  prefs: []
  type: TYPE_NORMAL
- en: Snowflake is also heavily investing in Python to make it easier for data scientists,
    engineers, and application developers to build even more in the data cloud without
    governance trade-offs.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we covered the capabilities of Snowpark for Python and why
    Python is a preferred language for developing Snowpark. The following section
    will cover how Snowpark can be used for different workloads.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding Snowpark for different workloads
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The release of Snowpark transformed Snowflake into a complete data platform
    designed to support various workloads. Snowpark supports multiple workloads, such
    as data science and ML, data engineering, and data applications.
  prefs: []
  type: TYPE_NORMAL
- en: Data science and ML
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Python is the favorite language for data scientists. Snowpark for Python supports
    popular libraries and frameworks such as pandas, NumPy, and scikit-learn, making
    it the ideal framework for data scientists to perform ML development in Snowflake.
    In addition, data scientists can use the DataFrames API to interact with data
    inside Snowflake and perform batch training and inference inside Snowflake. Developers
    can also use Snowpark for feature engineering, ML model inference, and end-to-end
    ML pipelines. Snowpark also provides a SnowparkML library to support data science
    and ML in Snowpark.
  prefs: []
  type: TYPE_NORMAL
- en: Data engineering
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Data cleansing and ELT workloads are complex, and building a data pipeline with
    just SQL is where Snowpark can be of great benefit. Snowpark lets developers factor
    code for readability and reuse it while providing a better capability for unit
    tests. In addition, with the support of Anaconda, developers can use open-source
    Python libraries for building reliable data pipelines. The other major challenge
    with data processing is that the infrastructure requires significant manual effort
    and maintenance. Snowpark solves this problem by being highly performant, enabling
    data engineers to work with large datasets quickly and efficiently, building complex
    data pipelines, and processing large volumes of data without performance issues.
  prefs: []
  type: TYPE_NORMAL
- en: Data governance and security
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Snowpark supports developing solutions that incorporate data governance and
    security. Data governance is critical and augments the data science and data engineering
    use cases. Snowpark simplifies the governance posture by helping organizations
    understand and improve data quality. Developers can quickly create a function
    to perform data tests and detect anomalies. Snowpark can utilize the data classification
    capability to detect **personally identifiable information** (**PII**) and classify
    data that is critical to an organization. Custom functions developed in Snowpark
    can mask sensitive data such as credit card numbers using the robust dynamic data
    masking feature while retaining the existing security model in Snowflake.
  prefs: []
  type: TYPE_NORMAL
- en: Data applications
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Snowpark helps the team develop dynamic data applications that run directly
    on Snowflake without moving the data outside. Using **Streamlit**, a powerful
    open-source library that Snowflake acquired, developers can build native applications
    using the familiar Python environment. Interactive ML-powered applications can
    be developed and shared with users securely utilizing role-based access controls
    entirely on Snowflake’s governed platform, taking advantage of its scale, performance,
    and governance. The Snowflake Native Application Framework provides a streamlined
    path to monetize apps through Snowflake Marketplace, where you can make your app
    available to other Snowflake customers and open new revenue opportunities.
  prefs: []
  type: TYPE_NORMAL
- en: Snowpark supports different workloads and makes Snowflake a complete data cloud
    solution. The following section will highlight Snowpark’s technical and business
    benefits.
  prefs: []
  type: TYPE_NORMAL
- en: Realizing the value of using Snowpark
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The traditional big data approach has been in the industry for a long time
    and is unsuitable for modern cloud-based scalable workloads. Traditional architecture
    has many challenges, such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: De-coupling the compute and data into separate systems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running separate processing clusters for different languages
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Complexity in managing the system
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data silos and data duplication
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lack of unified security and governance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Snowflake solves the traditional system’s challenges using Snowpark, providing
    tremendous value to the data ecosystem and Snowflake users. The following diagram
    shows the difference between a traditional approach and Snowflake’s streamlined
    approach:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.1 – Traditional versus Snowflake approach](img/B19923_01_001.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.1 – Traditional versus Snowflake approach
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see from the difference between both approaches, Snowpark’s streamlined
    approach benefits both the business and the developers by providing a flexible,
    efficient, and cost-effective way to build data that scales with the business
    needs. Some of the significant values of using Snowpark are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Snowpark can access data programmatically through the DataFrame APIs, making
    the data ingestion and integration consistent, as you can integrate various structured
    and unstructured data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Snowpark standardizes the approach to data processing since the data pipelines
    are in Python code; they can be tested and deployed and are easier to understand
    and interpret
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Anaconda powers Snowpark for Python and provides easy access to third-party
    Python libraries that are open source, which enhances the data processing capabilities
    and empowers developers to perform more
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Snowpark integrates and runs seamlessly on the existing Snowflake virtual warehouse,
    allowing developers to build data applications designed to scale without any additional
    infrastructure
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Snowpark’s framework supports various workloads, such as data engineering, data
    science, and data applications, providing a unified experience for development
    on the data cloud
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Snowpark delivers a secure, governed environment as it is easy to enforce governance
    policies, and there is no data movement outside Snowflake
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s wrap up this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Snowflake’s Snowpark perfectly coalesces SQL and Python, running complex data
    processing jobs in the Snowflake data cloud and enabling data engineers, data
    scientists, and developers to take advantage of Snowflake. In this chapter, we
    have seen the benefits of Snowpark and why Python is the preferred development
    language. We also covered different workloads that Snowpark supports.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will examine configuring and operating with Snowpark
    in detail and learn how to use Snowpark for various workloads.
  prefs: []
  type: TYPE_NORMAL
