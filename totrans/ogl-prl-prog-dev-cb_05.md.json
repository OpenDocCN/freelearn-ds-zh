["```py\n#define DATA_SIZE 1024\n#define BIN_SIZE 256\n\nint main(int argc, char** argv) {\n    unsigned int* data = (unsigned int*) malloc( DATA_SIZE *\n                         sizeof(unsigned int));\n    unsigned int* bin  = (unsigned int*) malloc( BIN_SIZE *\n                         sizeof(unsigned int));\n    memset(data, 0x0, DATA_SIZE * sizeof(unsigned int));\n    memset(bin, 0x0, BIN_SIZE * sizeof(unsigned int));\n\n    for( int i = 0; i < DATA_SIZE; i++) {\n        int indx = rand() % BIN_SIZE;\n        data[i] = indx;\n    }\n\n    for( int i = 0; i < DATA_SIZE; ++i) {\n       bin[data[i]]++;\n    }\n\n}\n```", "```py\n/usr/bin/gcc –o histogram Ch5/histogram_c/histogram.c\n\n```", "```py\nfor( int i = 0; i < DATA_SIZE; i++) {\n        int indx = rand() % BIN_SIZE;\n        data[i] = indx;\n}\n```", "```py\nfor( int i = 0; i < DATA_SIZE; ++i) {\n       bin[data[i]]++;\n}\n```", "```py\nfor( int i = 0; i < BIN_SIZE; i ++) {\n        if (bin[i] == 0) continue; \n        else printf(\"bin[%d] = %d\\n\", i, bin[i]);\n}\n```", "```py\n#define MEMORY_BANKS 5U // 32-memory banks.\n\n__kernel\n\nvoid histogram256(__global const unsigned int4* data,\n                               __local uchar* sharedArray,\n                               __global uint* binResult) {\n\n// these 4 statements are meant to obtain the ids for the first\n// dimension since our data is a 1-d array\nsize_t localId = get_local_id(0);\nsize_t globalId = get_global_id(0);\nsize_t groupId = get_group_id(0);\nsize_t groupSize = get_local_size(0);\n\nint offSet1 = localId & 31;\nint offSet2 = 4 * offSet1;\nint bankNumber = localId >> MEMORY_BANKS;\n\n__local uchar4* input = (__local uchar4*) sharedArray;\n\n// In a work-group, each work-item would have an id ranging from\n// [0..127]\n// since our localThreads in 'main.c' is defined as 128\n// Each work-item in the work-group would execute the following\n// sequence:\n// work-item id = 0, input[128 * [0..63]] = 0\n// Not forgetting that input is a vector of 4 unsigned char type,\n// that effectively means\n// that each work-group would execute this loop 8192 times and each\n// time it would set\n// 4 bytes to zero => 8192 * 4 bytes = 32-KB and this completes the\n// initialization of the\n// local shared memory array.\n\nfor(int i = 0; i < 64; ++i )\n  input[groupSize * i + locald] = 0;\n\n// OpenCL uses a relaxed consistency memory model which means to say\n// that the state of\n// memory visible to a work-item is not guaranteed to be consistent\n// across the collection\n// of work-items at all times.\n// Within a work-item memory has load/store consistency. Local memory\n// is consistent\n// across work-items in a single work-group at a work-group barrier.\n// The statement below\n// is to perform exactly that function.\n// However, there are no guarantees of memory consistency between\n// different\n// work-groups executing a kernel\n\n// This statement means that all work-items in a single work-group\n// would have to reach\n// this point in execution before ANY of them are allowed to continue\n// beyond this point.\n\nbarrier(CLK_LOCAL_MEM_FENCE);\n\n// The group of statements next fetch the global memory data and\n// creates a binned\n// content in the local memory.\n// Next, the global memory is divided into 4 chunks where the\n// row_size = 64 and'\n// column_size = 128\\. The access pattern for all work-items in the\n// work-group is\n// to sweep across this block by accessing all elements in each\n// column 64-bytes at a time.\n// Once that data is extracted, we need to fill up the 32-KB local\n// shared memory so we\n// next extract the vector values from the local variable \"value\" and\n// fill them up. The\n// pattern we used to store those values is as follows:\n// value.s0 can only range from [0..255] and value.s0 * 128 would\n// indicate which row\n// and column you like to store the value. Now we land in a\n// particular row but we need\n// to decide which 4-byte chunk its going to store this value since\n// value.s0 is a int and\n// sharedArray is a uchar-array so we use offSet2 which produces an\n// array [0,4,8...124]\n// and now we need which chunk its going to land in. At this point,\n// you need to remember\n// that value.s0 is a value [0..255] or [0x00..0xFF] so we need to\n// decide which element in\n// this 4-byte sub-array are we going to store the value.\n// Finally, we use the value of bankNumber to decide since its range\n// is [0..3]\nfor(int i = 0; i < 64; ++i) {\n  uint4 value = data[groupId * groupSize * BIN_SIZE / 4 + i * groupSize + localId];\n  sharedArray[value.s0 * 128 + offSet2 + bankNumber]++;\n  sharedArray[value.s1 * 128 + offSet2 + bankNumber]++;\n  sharedArray[value.s2 * 128 + offSet2 + bankNumber]++;\n  sharedArray[value.s3 * 128 + offSet2 + bankNumber]++;\n}\n\n// At this point, you should have figured it out that the 128 * 256\n// resembles a hashtable\n// where the row indices are the keys of the 256-bin i.e. [0..255]\n// and the \"list\" of values\n// following each key is what it looks like\n// [0]   -> [1,3,5,6 ...]\n// [1]   -> [5,6,2,1... ]\n// ...\n// [255] -> [0,1,5,..]\n// Next, we go through this pseudo-hashtable and aggregate the values\n// for each key\n// and store this result back to the global memory.\n// Apply the barrier again to make sure every work-item has completed\n// the population of\n// values into the local shared memory.\n\nbarrier(CLK_LOCAL_MEM_FENCE);\n\n// Now, we merge the histograms\n// The merging process is such that it makes a pass over the local\n// shared array\n// and aggregates the data into 'binCount' where it will make its way\n// to the\n// global data referenced by 'binResult'\n\nif(localId == 0) { // each work-group only has 1 work-item executing this code block\n  for(int i = 0; i < BIN_SIZE; ++i) {\n    uint result = 0;\n    for(int j = 0; j < groupSize; ++j) {\n      result += sharedArray[i * groupSize + j];\n    }\n    binResult[groupId * BIN_SIZE  + i] = result;\n  }\n}\n```", "```py\ngcc –std=c99 –Wall –DUNIX –g –DDEBUG –DAPPLE –arch i386 –o Histogram main.c –framework OpenCL\n\n```", "```py\nPassed!\n\n```", "```py\nqueue = clCreateCommandQueue(context, device, 0, &error);\n\ncl_kernel kernel = clCreateKernel(program, \"histogram256\", &error);\n\ninputBuffer = clCreateBuffer(context,\n                             CL_MEM_READ_ONLY|CL_MEM_COPY_HOST_PTR,\n                             width * height * sizeof(cl_uint),\n                             data,\n                             &error);\n\nintermediateBinBuffer = clCreateBuffer(context,\n                                       CL_MEM_WRITE_ONLY,\n                                       BIN_SIZE * subHistogramCount * sizeof(cl_uint),\n                                       NULL,\n                                       &error);\n\nclSetKernelArg(kernel, 0, sizeof(cl_mem),(void*)& inputBuffer);\n\n// the importance of uchar being that its unsigned char i.e. value //range[0x00..0xff]\nclSetKernelArg(kernel, 1, BIN_SIZE * GROUP_SIZE * sizeof(cl_uchar), NULL); // bounded by LOCAL MEM SIZE in GPU\nclSetKernelArg(kernel, 2, sizeof(cl_mem), (void*)& intermediateBinBuffer);\n```", "```py\n__local uchar* input = (__local uchar4*) sharedArray;\n\nfor(int i = 0; i < 64; ++i)\n  input[groupSize * i + localId] = 0;\n\nbarrier(CLK_LOCAL_MEM_FENCE);\n```", "```py\nfor(int i = 0; i < 64; i++)\n{\n       uint4 value =  data[groupId * groupSize * BIN_SIZE/4 + i * groupSize + localId];\n       sharedArray[value.s0 * 128 + offSet2 + bankNumber]++;\n       sharedArray[value.s1 * 128 + offSet2 + bankNumber]++;\n       sharedArray[value.s2 * 128 + offSet2 + bankNumber]++;\n       sharedArray[value.s3 * 128 + offSet2 + bankNumber]++;\n}\nbarrier(CLK_LOCAL_MEM_FENCE);\n```", "```py\nif(localId == 0) {\n    for(int i = 0; i < BIN_SIZE; ++i) {\n        uint result = 0;\n        for(int j = 0; j < 128; ++j)  {\n            result += sharedArray[i * 128 + j];\n        }\n        binResult[groupId * BIN_SIZE + i] = result;\n    }\n}\n```", "```py\nfor(int i = 0; i < subHistogramCount; ++i)\n    for( int j = 0; j < BIN_SIZE; ++j) {\n        deviceBin[j] += intermediateBins[i * BIN_SIZE + j];\n}\n```", "```py\ncl_int clEnqueueBarrierWithWaitList(cl_command_queue command_queue,\n           cl_uint num_events_in_wait_list, \n           const cl_event *event_wait_list,\n           cl_event *event)\n\ncl_int clEnqueueMarkerWithWaitList\n          (cl_command_queue command_queue,\n           cl_uint num_events_in_wait_list, \n           const cl_event *event_wait_list, \n           cl_event *event) \n```", "```py\ncl_int clEnqueueBarrier(cl_command_queue queue);\ncl_int clEnqueueMarker(cl_command_queue queue, cl_event* event);\n```", "```py\nvoid barrier(cl_mem_fence flags);\n```"]