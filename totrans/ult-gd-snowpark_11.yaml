- en: '8'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '8'
- en: Introduction to Snowpark Container Services
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 雪花容器服务简介
- en: Containers represent a contemporary method for packaging code in diverse languages,
    ensuring seamless portability and consistency across various environments. This
    is particularly true for advanced AI/ML models and comprehensive data-centric
    applications. These modern data products often handle vast volumes of proprietary
    data, presenting challenges in efficiently creating, developing, and scaling workloads.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 容器是使用多种语言打包代码的当代方法，确保在各种环境中实现无缝的可移植性和一致性。这对于高级AI/ML模型和全面的数据中心应用尤其如此。这些现代数据产品通常处理大量专有数据，在高效创建、开发和扩展工作负载方面提出了挑战。
- en: Developers and data scientists often spend more time managing computing resources
    and clusters than addressing core business challenges. With its unique features,
    Snowpark Container Services offers a seamless solution to this problem. It allows
    applications and **large language models** (**LLMs**) to be executed on containers
    directly within the Snowflake Data Cloud, reducing the time and effort spent on
    resource management. This chapter will help you learn about deploying apps and
    LLMs on containers within Snowpark.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 开发人员和数据科学家通常花费更多的时间来管理计算资源和集群，而不是解决核心业务挑战。凭借其独特功能，Snowpark容器服务为解决这个问题提供了一个无缝的解决方案。它允许应用程序和**大型语言模型**(**LLMs**)直接在Snowflake数据云中执行，从而减少了在资源管理上花费的时间和精力。本章将帮助您了解如何在Snowpark中部署应用程序和LLMs。
- en: 'In this chapter, we are going to cover the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Introduction to Snowpark Container Services
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 雪花容器服务简介
- en: Setting up Snowpark Container Services
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置Snowpark容器服务
- en: Setting up a Snowpark Container Service job
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置Snowpark容器服务作业
- en: Deploying LLMs with Snowpark
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Snowpark部署LLMs
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: To set up the environment, please refer to the technical requirements in the
    previous chapter. Docker Client and Desktop are also required; you can install
    Docker from [https://docs.docker.com/get-docker/](https://huggingface.co/docs/hub/en/security-tokens).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 要设置环境，请参考前一章中的技术要求。还需要Docker客户端和桌面；您可以从[https://docs.docker.com/get-docker/](https://huggingface.co/docs/hub/en/security-tokens)安装Docker。
- en: We’ll also be using the Hugging Face API. To obtain the Hugging Face API token,
    sign up at [https://huggingface.co/](https://github.com/PacktPublishing/The-Ultimate-Guide-To-Snowpark).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将使用Hugging Face API。要获取Hugging Face API令牌，请在[https://huggingface.co/](https://github.com/PacktPublishing/The-Ultimate-Guide-To-Snowpark)注册。
- en: The supporting materials are available at [https://github.com/PacktPublishing/The-Ultimate-Guide-To-Snowpark](https://github.com/PacktPublishing/The-Ultimate-Guide-To-Snowpark).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 支持材料可在[https://github.com/PacktPublishing/The-Ultimate-Guide-To-Snowpark](https://github.com/PacktPublishing/The-Ultimate-Guide-To-Snowpark)获取。
- en: Introduction to Snowpark Container Services
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 雪花容器服务简介
- en: Snowpark Container Services represents a comprehensive managed container solution
    tailored to facilitate the deployment, management, and scaling of containerized
    applications within the Snowflake environment. Users can experience the convenience
    of executing containerized workloads directly within Snowflake, eliminating the
    need to transfer data outside the Snowflake ecosystem for processing. Snowpark
    Container Services introduces an **Open Container Initiative** (**OCI**) runtime
    execution environment meticulously optimized for Snowflake, which empowers users
    to flawlessly execute OCI images while leveraging the robust capabilities of Snowflake’s
    data platform.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 雪花容器服务代表了一种全面的托管容器解决方案，旨在简化在Snowflake环境中部署、管理和扩展容器化应用程序。用户可以直接在Snowflake中执行容器化工作负载，从而无需将数据转移到Snowflake生态系统之外进行处理。Snowpark容器服务引入了一个经过精心优化的**开放容器倡议**(**OCI**)运行时执行环境，适用于Snowflake，使用户能够完美执行OCI镜像，同时利用Snowflake数据平台的强大功能。
- en: Snowpark Container Services extends Snowpark’s capability, empowering developers
    with a trusted and familiar environment to process non-SQL code seamlessly within
    Snowflake’s governed data domain. This enables applications to effortlessly perform
    tasks such as connecting to Snowflake, executing SQL queries within a Snowflake
    virtual warehouse, accessing data files in a Snowflake stage, and processing data
    with Snowpark models. This streamlined integration fosters an environment conducive
    to efficient collaboration and focused development efforts within teams.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: Snowpark容器服务扩展了Snowpark的功能，为开发者提供了一个可信且熟悉的环境，使他们能够在Snowflake受管数据域内无缝处理非SQL代码。这使得应用程序能够轻松执行诸如连接到Snowflake、在Snowflake虚拟仓库中执行SQL查询、访问Snowflake阶段的文件以及使用Snowpark模型处理数据等任务。这种简化的集成促进了团队内部高效协作和专注的开发工作环境。
- en: Developers can create containers tailored to their needs that offer configurable
    hardware options, including GPU support, enabling a wide range of AI/ML and application
    workloads within Snowflake through Snowpark. For instance, data science teams
    can expedite ML tasks by leveraging Python libraries for training and inference
    while executing resource-intensive generative AI models such as LLMs. App developers
    can craft and deploy user interfaces using popular frameworks, and data engineers
    can execute optimized logic within the same processing engine handling SQL or
    Python DataFrame operations.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 开发者可以创建满足他们需求的容器，提供可配置的硬件选项，包括GPU支持，通过Snowpark在Snowflake内实现广泛的AI/ML和应用工作负载。例如，数据科学团队可以通过利用Python库进行训练和推理来加速ML任务，同时执行资源密集型的生成式AI模型，如LLM。应用开发者可以使用流行的框架设计和部署用户界面，而数据工程师可以在处理SQL或Python
    DataFrame操作的同一处理引擎中执行优化的逻辑。
- en: In the next section, we will understand how data security works in Snowpark
    Container Services.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将了解Snowpark容器服务中的数据安全是如何工作的。
- en: Note on Snowpark Container Services
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 关于Snowpark容器服务的注意事项
- en: 'At the time of writing this chapter, Snowpark Container Services are currently
    in a private preview phase. Please note that once they become available to all
    users, there may be slight variations in the API methods compared to what is described
    in this book. We encourage you to monitor the book''s GitHub repository for any
    new changes and updates to the code contents: [https://github.com/PacktPublishing/The-Ultimate-Guide-To-Snowpark](https://github.com/PacktPublishing/The-Ultimate-Guide-To-Snowpark)'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本章时，Snowpark容器服务目前处于私有预览阶段。请注意，一旦它们对所有用户开放，API方法可能与本书中描述的略有不同。我们鼓励您监控本书的GitHub存储库，以获取任何新的代码内容更改和更新：[https://github.com/PacktPublishing/The-Ultimate-Guide-To-Snowpark](https://github.com/PacktPublishing/The-Ultimate-Guide-To-Snowpark)
- en: Data security in Snowpark Container Services
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Snowpark容器服务中的数据安全
- en: Snowpark Container Services facilitates the secure deployment of full-stack
    applications, LLMs, and other advanced data products directly within the data
    environment. This new runtime option under Snowpark streamlines the deployment,
    management, and scaling of containerized workloads, including jobs, services,
    and service functions, leveraging Snowflake-managed infrastructure with customizable
    hardware configurations, such as GPUs. By adopting this innovative runtime, users
    can bypass the complexities of managing compute resources and container clusters,
    allowing seamless integration of sophisticated AI/ML models and applications without
    compromising data security. With containers operating within the Snowflake environment,
    there’s no need to transfer governed data outside of Snowflake, minimizing exposure
    to potential security risks. This ensures a secure and robust ecosystem for leveraging
    internally developed solutions or third-party offerings, such as Snowflake Native
    Apps, accessible through the Snowflake Marketplace.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: Snowpark容器服务简化了全栈应用程序、LLM和其他高级数据产品在数据环境中的安全部署。在Snowpark下，这种新的运行时选项简化了容器化工作负载（包括作业、服务和服务函数）的部署、管理和扩展，利用Snowflake管理的硬件配置基础设施，如GPU。通过采用这种创新运行时，用户可以绕过管理计算资源和容器集群的复杂性，在不影响数据安全的前提下，无缝集成复杂的AI/ML模型和应用。在Snowflake环境中运行的容器无需将受管数据转移到Snowflake之外，从而最小化潜在的安全风险。这确保了利用内部开发解决方案或第三方产品（如通过Snowflake
    Marketplace可访问的Snowflake Native Apps）的可靠和强大生态系统。
- en: In the next section, we will look at the components of Snowpark Containers.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将探讨Snowpark容器的组成部分。
- en: Components of Snowpark Containers
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Snowpark容器的组成部分
- en: Snowpark Container Services offers a streamlined and fully managed approach
    to the life cycle management of containerized applications and AI/ML models. Unlike
    other solutions, it provides a cohesive solution that necessitates piecing together
    disparate components such as container registries, management services, and computing
    platforms. Consolidating these elements eliminates the burden of managing computing
    resources and clusters, thereby accelerating the development and deployment of
    data applications.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: Snowpark 容器服务为容器化应用程序和 AI/ML 模型的生命周期管理提供了一种简化和完全管理的途径。与其他解决方案不同，它提供了一个统一的解决方案，需要将容器注册库、管理服务和计算平台等不同组件组合在一起。整合这些元素消除了管理计算资源和集群的负担，从而加速了数据应用程序的开发和部署。
- en: 'Moreover, Snowpark Container Services simplifies container hosting and deployment
    by offering a combination of simplicity and scalability. Developers only need
    to provide their containers, and Snowflake handles the hosting and scaling without
    requiring extensive knowledge of Kubernetes. Developers can interact with the
    service using SQL, CLI, or Python interfaces, catering to diverse preferences
    and workloads. Snowpark Containers has two distinct execution options to accommodate
    various application requirements: services jobs through using service function,
    and compute pools. The following diagram shows the different components:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，Snowpark 容器服务通过提供简单性和可扩展性的结合简化了容器托管和部署。开发者只需提供他们的容器，Snowflake 就会处理托管和扩展，无需深入了解
    Kubernetes。开发者可以使用 SQL、CLI 或 Python 接口与服务交互，满足不同的偏好和工作负载。Snowpark 容器提供两种不同的执行选项，以适应各种应用程序需求：通过使用服务函数的服务作业和计算池。以下图表显示了不同的组件：
- en: '![Figure 8.1 – Snowpark Container components](img/B19923_08_1.jpg)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.1 – Snowpark 容器组件](img/B19923_08_1.jpg)'
- en: Figure 8.1 – Snowpark Container components
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.1 – Snowpark 容器组件
- en: 'Let’s look at each of the options:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看每个选项：
- en: '**Services**: A service in Snowflake operates continuously, much like a web
    service, until explicitly terminated. These services are hosted on secure ingress
    endpoints and typically host application frontends or APIs. They remain continuously
    available to handle on-demand requests.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**服务**：在 Snowflake 中，服务持续运行，就像一个网络服务一样，直到明确终止。这些服务托管在安全的入口端点，通常托管应用程序前端或 API。它们持续可用，以处理按需请求。'
- en: '**Jobs**: These are processes with specific time limits, often initiated manually
    or scheduled regularly. They encompass various tasks, such as launching container
    images for machine learning training on GPUs or executing steps within a data
    pipeline using diverse languages, frameworks, or libraries encapsulated in containers.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**作业**：这些是具有特定时间限制的进程，通常由人工启动或定期安排。它们包括各种任务，例如在 GPU 上启动用于机器学习训练的容器镜像，或使用封装在容器中的不同语言、框架或库执行数据管道中的步骤。'
- en: '**Service functions**: Functions are time-limited processes designed to receive
    input, execute specific actions, and be triggered repeatedly by events, leveraging
    your containerized environments.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**服务函数**：函数是时间有限的进程，旨在接收输入、执行特定操作，并通过事件反复触发，利用您的容器化环境。'
- en: '**Compute pools**: A compute pool comprising one or more **virtual machine**
    (**VM**) nodes serves as the infrastructure upon which Snowflake executes your
    jobs and services.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**计算池**：由一个或多个 **虚拟机**（VM）节点组成的计算池是 Snowflake 执行您的作业和服务的底层基础设施。'
- en: Snowpark Container Services also enables developers to deploy applications directly
    within their end customers’ Snowflake accounts using the aforementioned components.
    This allows them to securely install and operate state-of-the-art offerings, such
    as hosted notebooks and LLMs, within their Snowflake environment, safeguarding
    the provider’s intellectual property.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: Snowpark 容器服务还允许开发者在他们的最终客户 Snowflake 账户中使用上述组件直接部署应用程序。这使得他们能够在 Snowflake 环境中安全地安装和运行最先进的产品，例如托管笔记本和大型语言模型（LLMs），从而保护提供商的知识产权。
- en: In the next section, we will cover how to set up Snowpark Container Services.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将介绍如何设置 Snowpark 容器服务。
- en: Setting up Snowpark Container Services
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置 Snowpark 容器服务
- en: In this section, we’ll lay down the groundwork necessary for exploring Snowpark
    Container Services. We will use Docker to create an OCI-compliant image to deploy
    to Snowpark. We’ll start by creating Snowflake objects.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将阐述探索 Snowpark 容器服务所需的基础知识。我们将使用 Docker 创建一个符合 OCI 标准的镜像以部署到 Snowpark。我们将从创建
    Snowflake 对象开始。
- en: Creating Snowflake objects
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建 Snowflake 对象
- en: 'To create Snowflake objects, follow these steps in Snowsight with the **ACCOUNTADMIN**
    role:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建 Snowflake 对象，请按照以下步骤在 Snowsight 中使用 **ACCOUNTADMIN** 角色执行：
- en: 'Create a role named **test_role** using the following command. This role will
    be used for our Snowpark application:'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令创建一个名为 **test_role** 的角色。此角色将用于我们的 Snowpark 应用程序：
- en: '[PRE0]'
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This will print the following output:'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将打印以下输出：
- en: '![Figure 8.2 – A Snowflake role](img/B19923_08_2.jpg)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.2 – Snowflake 角色](img/B19923_08_2.jpg)'
- en: Figure 8.2 – A Snowflake role
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.2 – Snowflake 角色
- en: 'Create a database and grant access to the database role by running the following
    command:'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行以下命令创建一个数据库并授予数据库角色的访问权限：
- en: '[PRE1]'
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'This will display the following output:'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将显示以下输出：
- en: '![Figure 8.3 – Granting access](img/B19923_08_3.jpg)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.3 – 授予权限](img/B19923_08_3.jpg)'
- en: Figure 8.3 – Granting access
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.3 – 授予权限
- en: 'We will be granting access to a warehouse for this role by executing the following
    command:'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将通过执行以下命令为该角色授予仓库的访问权限：
- en: '[PRE2]'
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Next, we will create a security integration for Snowflake services to access
    the resources securely by running the following command:'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将通过运行以下命令为 Snowflake 服务创建一个安全集成，以便安全地访问资源：
- en: '[PRE3]'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The output is as follows:'
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 8.4 – Security integration](img/B19923_08_4.jpg)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.4 – 安全集成](img/B19923_08_4.jpg)'
- en: Figure 8.4 – Security integration
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.4 – 安全集成
- en: 'Next, we will bind the service endpoint on the account to this role by running
    the following command. This allows access to the service endpoint from the public
    ingress:'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将通过运行以下命令将账户上的服务端点绑定到该角色。这允许从公共入口访问服务端点：
- en: '[PRE4]'
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'This will display the following output:'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将显示以下输出：
- en: '![Figure 8.5 – Binding the service endpoint](img/B19923_08_5.0.jpg)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.5 – 绑定服务端点](img/B19923_08_5.0.jpg)'
- en: Figure 8.5 – Binding the service endpoint
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.5 – 绑定服务端点
- en: 'Finally, we will create a compute pool and assign it to the role by running
    the following command:'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们将通过运行以下命令创建一个计算池并将其分配给角色：
- en: '[PRE5]'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'This will display the following output:'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将显示以下输出：
- en: '![Figure 8.6 – A compute pool](img/B19923_08_6.0.jpg)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.6 – 计算池](img/B19923_08_6.0.jpg)'
- en: Figure 8.6 – A compute pool
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.6 – 计算池
- en: 'We have now created a role, **test_role**, and the necessary Snowflake objects
    we will use for the container services. Now, grant the role to the user you are
    logged into by running the following command:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们已经创建了一个角色，**test_role**，以及我们将用于容器服务的必要 Snowflake 对象。现在，通过运行以下命令将角色授予你登录的用户：
- en: '[PRE6]'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Now that we have the role configured and ready to use, let’s create the necessary
    database-scoped objects:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们已经配置并准备好了角色，让我们创建必要的数据库范围对象：
- en: 'Select the database by running the following command:'
  id: totrans-69
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过运行以下命令选择数据库：
- en: '[PRE7]'
  id: totrans-70
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Create a schema named **MY_SCHEMA** by running the following code:'
  id: totrans-71
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过运行以下代码创建一个名为 **MY_SCHEMA** 的模式：
- en: '[PRE8]'
  id: totrans-72
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Create an image repository that stores the container image by running the following
    command:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行以下命令创建一个存储容器镜像的图像存储库：
- en: '[PRE9]'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Once the image is created, you’ll see the following output:'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一旦创建图像，你将看到以下输出：
- en: '![Figure 8.7 – An image repository](img/B19923_08_7.0.jpg)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.7 – 图像存储库](img/B19923_08_7.0.jpg)'
- en: Figure 8.7 – An image repository
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.7 – 图像存储库
- en: 'Finally, create a stage that is used to upload the files by running the following
    command:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，通过运行以下命令创建一个用于上传文件的阶段：
- en: '[PRE10]'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'You’ll see the following output:'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你将看到以下输出：
- en: '![Figure 8.8 – Stage creation](img/B19923_08_8.0.jpg)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.8 – 阶段创建](img/B19923_08_8.0.jpg)'
- en: Figure 8.8 – Stage creation
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.8 – 阶段创建
- en: We will be using the HuffPost dataset, which is available on Kaggle. The dataset
    is provided in our code repository. The dataset delineates approximately 200,000
    headlines from 2012 through May 2018, with an additional 10,000 from May 2018
    to 2022, reflecting adjustments in the website’s operational dynamics.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 HuffPost 数据集，该数据集可在 Kaggle 上找到。数据集包含在我们的代码存储库中。该数据集界定了从 2012 年到 2018 年
    5 月的约 200,000 个标题，以及从 2018 年 5 月到 2022 年的额外 10,000 个标题，反映了网站运营动态的调整。
- en: In the next section, we will set up the services.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将设置服务。
- en: Setting up the services
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置服务
- en: '**Flask** is a lightweight web framework that allows developers to easily create
    web applications in Python. It is designed to be flexible, modular, and easy to
    use, making it a popular choice for building web applications of all sizes. Flask
    is particularly well-suited for building small to medium-sized web applications,
    as it provides just enough functionality to get the job done without adding unnecessary
    complexity.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '**Flask** 是一个轻量级的 Web 框架，它允许开发者轻松地在 Python 中创建 Web 应用程序。它被设计成灵活、模块化和易于使用，使其成为构建各种规模
    Web 应用的流行选择。Flask 特别适合构建小型到中型 Web 应用程序，因为它提供了完成任务所需的功能，而不增加不必要的复杂性。'
- en: Flask is used for a wide range of applications, including building web APIs,
    developing microservices, and creating simple web applications. Its flexibility
    and simplicity make it a popular choice for developers who want to quickly prototype
    and deploy web applications. Additionally, Flask can be easily extended with a
    variety of third-party libraries and tools, making it a powerful and versatile
    tool for building web applications in Python.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: Flask 被用于广泛的用途，包括构建 Web API、开发微服务和创建简单的 Web 应用程序。它的灵活性和简单性使其成为希望快速原型设计和部署 Web
    应用的开发者的热门选择。此外，Flask 可以轻松地通过各种第三方库和工具进行扩展，使其成为构建 Python 中 Web 应用程序的有力且多功能的工具。
- en: We will be utilizing Flask to write our service code that runs a persisting
    service to take HTTPS calls.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 Flask 来编写我们的服务代码，该代码运行一个持久化的服务以接收 HTTPS 请求。
- en: Note on filter service
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 关于过滤器服务的说明
- en: Filter service, which we are discussing in the next section, is just one simple
    example since our focus is more on explaining how to set up Snowpark Container
    Services rather than building a complex application. By following similar steps,
    any other use case can be developed.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中我们将讨论的过滤器服务只是一个简单的例子，因为我们的重点更多地在于解释如何设置 Snowpark 容器服务，而不是构建一个复杂的应用程序。通过遵循类似的步骤，可以开发出任何其他用例。
- en: Setting up the filter service
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置过滤器服务
- en: In this section, we will set up a service called `filter_service`, which filters
    the table based on a unique ID. We will perform the following steps to set up
    the service.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将设置一个名为 `filter_service` 的服务，该服务根据唯一 ID 过滤表格。我们将执行以下步骤来设置服务。
- en: Service code
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 服务代码
- en: You’ll find a Python application encompassing the code for crafting the filter
    service on the code repository. To initiate, download the provided zip file to
    a designated directory. Upon download completion, proceed to extract its contents.
    You’ll encounter a `service` directory containing the service code within the
    extracted files. The directory consists of the Docker file, `filter_service.py`,
    and the templates for the UI.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在代码仓库中找到一个包含创建过滤器服务代码的 Python 应用程序。首先，将提供的 zip 文件下载到指定的目录。下载完成后，继续提取其内容。你将遇到一个包含提取文件中的服务代码的
    `service` 目录。该目录包括 Docker 文件、`filter_service.py` 和 UI 模板。
- en: Filter Service in Python
  id: totrans-95
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Python 中的过滤器服务
- en: 'The following Python script includes the core logic of our service, encapsulating
    a minimalistic HTTP server based on Flask, and designed to filter the table based
    on input. It serves a dual purpose: handling filter requests from Snowflake service
    functions and furnishing a web UI for submitting filter requests.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 以下 Python 脚本包含了我们服务的核心逻辑，封装了一个基于 Flask 的最小化 HTTP 服务器，并设计用于根据输入过滤表格。它具有双重用途：处理来自
    Snowflake 服务函数的过滤请求，并为提交过滤请求提供 Web UI。
- en: '[PRE11]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The filter function facilitates communication between a Snowflake service function
    and the service. This function is adorned with the `@app.post()` decoration, signifying
    its capability to handle HTTP `POST` requests directed to the `/filter` path.
    Upon receiving such requests, the function processes and sends back the filter
    results encapsulated within the request body:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 过滤函数促进了 Snowflake 服务函数与服务之间的通信。这个函数被 `@app.post()` 装饰器所装饰，表明它能够处理指向 `/filter`
    路径的 HTTP `POST` 请求。在接收到此类请求后，该函数处理并返回请求体中封装的过滤结果：
- en: '[PRE12]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The UI function segment orchestrates a web form presentation and manages filter
    requests submitted via the web form. Decorated with the `@app.route()` decorator,
    this function is designated to handle requests targeting the `/ui` path. Upon
    receiving an HTTP `GET` request for this path, the server delivers a simple HTML
    form prompting the user to input a string. Subsequently, upon form submission,
    an HTTP `POST` request is dispatched, and the server processes it, returning the
    original string encapsulated within an HTTP response:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: UI 函数段负责协调网页表单的展示和管理通过网页表单提交的筛选请求。使用 `@app.route()` 装饰器装饰的此函数被指定处理针对 `/ui` 路径的请求。当服务器接收到针对此路径的
    HTTP `GET` 请求时，它将提供一个简单的 HTML 表单，提示用户输入一个字符串。随后，在表单提交后，将发送一个 HTTP `POST` 请求，服务器处理它，并在
    HTTP 响应中返回原始字符串：
- en: '[PRE13]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The `readiness_probe` function, adorned with the `@app.get()` decorator, is
    primed to handle requests directed to `/healthcheck`. This function is pivotal
    for Snowflake to verify the service’s readiness. When Snowflake initiates a container,
    it dispatches an HTTP `GET` request to this path as a health probe, ensuring that
    only healthy containers handle incoming traffic. The function’s implementation
    is flexible, accommodating various actions to ascertain the service’s readiness.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 带有 `@app.get()` 装饰器的 `readiness_probe` 函数准备处理指向 `/healthcheck` 的请求。这个函数对于 Snowflake
    验证服务的就绪状态至关重要。当 Snowflake 启动一个容器时，它将向此路径发送一个 HTTP `GET` 请求作为健康检查，确保只有健康的容器处理传入的流量。函数的实现是灵活的，可以适应各种操作以确保服务的就绪状态。
- en: Next, we will look at the Dockerfile in the directory.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将查看目录中的 Dockerfile。
- en: The Dockerfile
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Dockerfile
- en: 'The Dockerfile serves as a blueprint for constructing an image using Docker.
    It includes directives on installing the Flask library within the Docker container.
    The Dockerfile consists of the following:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: Dockerfile 作为使用 Docker 构建镜像的蓝图。它包括在 Docker 容器中安装 Flask 库的指令。Dockerfile 包含以下内容：
- en: '[PRE14]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The code within `filter_service.py` relies on Flask to efficiently handle HTTP
    requests.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '`filter_service.py` 中的代码依赖于 Flask 来高效处理 HTTP 请求。'
- en: Next, we will examine the UI templates.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将检查 UI 模板。
- en: UI templates
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: UI 模板
- en: The UI template files are located at `/template/basic_ui.html`. They render
    a web form for the filter service’s publicly exposed endpoint. This form is displayed
    when the public endpoint URL is loaded in a web browser with `/ui` appended. Users
    can input a string via this form, and upon submission, the service filters the
    table with submitted row given as string within an HTTP response.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: UI 模板文件位于 `/template/basic_ui.html`。它们渲染一个用于筛选服务公开端点的网页表单。当在带有 `/ui` 后缀的网页浏览器中加载公共端点
    URL 时，将显示此表单。用户可以通过此表单输入一个字符串，并在提交后，服务将使用提交的字符串筛选表格，并在 HTTP 响应中返回。
- en: In the next section, we will cover the service function.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将介绍服务函数。
- en: The service function
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 服务函数
- en: 'A service function serves as a conduit for communicating with your service.
    A `CREATE FUNCTION` command with specified parameters, such as the `filter_doc_udf`
    function:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 服务函数作为与您的服务通信的通道。一个带有指定参数的 `CREATE FUNCTION` 命令，例如 `filter_doc_udf` 函数：
- en: '[PRE15]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: This function, for instance, accepts a string as input and returns a string,
    with the `SERVICE` property designating the service (`filter_service`) and the
    `ENDPOINT` property specifying the user-friendly endpoint name (`filterendpoint`).
    The `AS '/filter'` designation denotes the path for the service, tying it to the
    corresponding function within `filter_service.py`. Thus, invoking this function
    triggers Snowflake to dispatch a request to the designated path within the service
    container.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，这个函数接受一个字符串作为输入，并返回一个字符串，其中 `SERVICE` 属性指定服务（`filter_service`）和 `ENDPOINT`
    属性指定用户友好的端点名称（`filterendpoint`）。`AS '/filter'` 指定服务路径，将其与 `filter_service.py`
    内的相应函数关联。因此，调用此函数将触发 Snowflake 向服务容器内的指定路径发送请求。
- en: In the next section, we will build the Docker image.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将构建 Docker 镜像。
- en: Building the Docker image
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建Docker镜像
- en: 'In this section, we will construct the image using the Linux/AMD64 base, which
    is compatible with Snowpark, and dispatch it to your account’s image repository.
    To build the Docker image, perform the following steps:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用与 Snowpark 兼容的 Linux/AMD64 基础构建镜像，并将其发送到您的账户镜像仓库。要构建 Docker 镜像，请执行以下步骤：
- en: 'Obtain the repository URL by executing the following SQL command:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过执行以下 SQL 命令获取仓库 URL：
- en: '[PRE16]'
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'This will display all the image repositories:'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将显示所有图像仓库：
- en: '![Figure 8.9 – The image repositories](img/B19923_08_9.0.jpg)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.9 – 镜像仓库](img/B19923_08_9.0.jpg)'
- en: Figure 8.9 – The image repositories
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.9 – 镜像仓库
- en: The **repository_url** column in the output furnishes the essential URL, and
    the hostname delineated in the repository URL denotes the registry hostname.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 输出中的 **repository_url** 列提供了必要的 URL，而仓库 URL 中指定的主机名表示注册表主机名。
- en: 'The following commands require Docker Desktop to be installed in the system.
    You can install it from [https://www.docker.com/products/docker-desktop/](https://www.docker.com/products/docker-desktop/)
    before proceeding with the commands. Next, in the local terminal window, switch
    to the **service** directory containing the unzipped files and execute the subsequent
    **docker build** command using the Docker CLI:'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下命令需要在系统中安装 Docker Desktop。在执行命令之前，您可以从 [https://www.docker.com/products/docker-desktop/](https://www.docker.com/products/docker-desktop/)
    安装它。接下来，在本地终端窗口中，切换到包含解压文件的 **service** 目录，并使用 Docker CLI 执行后续的 **docker build**
    命令：
- en: '[PRE17]'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '![Figure 8.10 – The Docker build command](img/B19923_08_10.0.jpg)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.10 – Docker 构建命令](img/B19923_08_10.0.jpg)'
- en: Figure 8.10 – The Docker build command
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.10 – Docker 构建命令
- en: 'Next, we’ll authenticate Docker with Snowflake. To authenticate Docker with
    the Snowflake registry, execute the following command:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将使用 Snowflake 注册表对 Docker 进行身份验证。要使用 Snowflake 注册表对 Docker 进行身份验证，请执行以下命令：
- en: '[PRE18]'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Specify your Snowflake username for the username parameter. Docker will prompt
    you for your password. Use the Snowflake password to authenticate:'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为用户名参数指定您的 Snowflake 用户名。Docker 将提示您输入密码。使用 Snowflake 密码进行身份验证：
- en: '![Figure 8.11 – Repository login](img/B19923_08_11.0.jpg)'
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 8.11 – 仓库登录](img/B19923_08_11.0.jpg)'
- en: Figure 8.11 – Repository login
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.11 – 仓库登录
- en: 'Finally, upload the image to the Docker registry by executing the following
    command:'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，通过执行以下命令将镜像上传到 Docker 注册表：
- en: '[PRE19]'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'You should see the following output:'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您应该看到以下输出：
- en: '![Figure 8.12 – Repository push](img/B19923_08_12.0.jpg)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.12 – 仓库推送](img/B19923_08_12.0.jpg)'
- en: Figure 8.12 – Repository push
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.12 – 仓库推送
- en: The image is now available in the registry for deployment into Container Services.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 现在镜像已可在注册表中部署到容器服务。
- en: In the next section, we will examine how to deploy the service, but it is always
    best practice to test your build locally before pushing it to the Snowflake repository.
    This part is not explained in this section as it is beyond the scope of this book.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将检查如何部署服务，但在将构建推送至 Snowflake 仓库之前进行本地测试始终是最佳实践。这部分内容超出了本书的范围，因此在本节中未进行解释。
- en: Deploying the service
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 部署服务
- en: 'In this section, we’ll guide you through deploying the service and establishing
    a service function to facilitate communication with it. We will start by deploying
    the service, which requires the existing compute pool. Let’s start by checking
    the compute pool by running the following command:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将指导您部署服务并建立服务函数以方便与其通信。我们将首先部署服务，这需要现有的计算池。让我们先通过运行以下命令来检查计算池：
- en: '[PRE20]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '![Figure 8.13 – The compute pool](img/B19923_08_13.0.jpg)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.13 – 计算池](img/B19923_08_13.0.jpg)'
- en: Figure 8.13 – The compute pool
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.13 – 计算池
- en: If it’s in the **STARTING** state, you’ll need to wait until it transitions
    to **ACTIVE** or **IDLE**.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 如果它处于 **启动** 状态，您需要等待它过渡到 **活动** 或 **空闲** 状态。
- en: Now that the pool is active, we can create the service in the next section.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 现在池已激活，我们可以在下一节创建服务。
- en: Creating the service
  id: totrans-148
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创建服务
- en: 'We can create the service by running it using `test_role`. To do that, run
    the following command:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过使用 `test_role` 运行服务来创建服务。为此，请运行以下命令：
- en: '[PRE21]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: We are using the image that we have built to deploy the service. The service
    should be created within Snowflake.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用已构建的镜像来部署服务。服务应在 Snowflake 中创建。
- en: 'Once the service is created, you can execute the following SQL command to check
    its status:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦创建服务，你可以执行以下 SQL 命令来检查其状态：
- en: '[PRE22]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The output should show that the service is running. The information about the
    service can be obtained by running the following command:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 输出应显示服务正在运行。可以通过运行以下命令来获取有关服务的详细信息：
- en: '[PRE23]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'This will display the details, as shown in the following screenshot:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 这将显示以下截图中的详细信息：
- en: '![Figure 8.14 – Service information](img/B19923_08_14.0.jpg)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.14 – 服务信息](img/B19923_08_14.0.jpg)'
- en: Figure 8.14 – Service information
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.14 – 服务信息
- en: In the next section, we will create the service function.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将创建服务函数。
- en: Creating a service function
  id: totrans-160
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创建服务函数
- en: 'The service function performs the filter function and associates it with an
    endpoint. To create a service function, execute the following command:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 服务函数执行过滤功能并将其与端点关联。要创建服务函数，执行以下命令：
- en: '[PRE24]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Here, the `SERVICE` property links the UDF with the `filter_service` service,
    while the `ENDPOINT` property associates it with the `filterendpoint` endpoint
    within the service. The `AS '/filter'` specification denotes the HTTP path leading
    to the filter server, which can be located within the service code.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`SERVICE` 属性将 UDF 与 `filter_service` 服务链接起来，而 `ENDPOINT` 属性将其与服务内的 `filterendpoint`
    端点关联起来。`AS '/filter'` 规范表示通向过滤服务器的 HTTP 路径，该路径可以在服务代码中找到。
- en: Once the previous SQL statement is executed correctly, you can see the service
    function you created in Snowsight under **Functions**.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦正确执行了前面的 SQL 语句，您可以在 Snowsight 下的 **函数** 中看到您创建的服务函数。
- en: '![Figure 8.15 – The service function](img/B19923_08_15.0.jpg)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.15 – 服务函数](img/B19923_08_15.0.jpg)'
- en: Figure 8.15 – The service function
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.15 – 服务函数
- en: Now the function is ready to be executed.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 现在函数已准备好执行。
- en: Executing the function
  id: totrans-168
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 执行函数
- en: 'We will switch to the context we created earlier in the chapter by running
    the following command:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过运行以下命令切换到本章中创建的上下文：
- en: '[PRE25]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'You should get the following confirmation:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该获得以下确认：
- en: '![Figure 8.16 – Function execution](img/B19923_08_16.0.jpg)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.16 – 函数执行](img/B19923_08_16.0.jpg)'
- en: Figure 8.16 – Function execution
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.16 – 函数执行
- en: 'With the context set up, you can initiate communication with the filter service
    by invoking the service function within a query. To call the `filter_doc_udf`
    service function, execute the following `SELECT` statement, providing a sample
    input string (`''122880''`):'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '在设置好上下文后，您可以通过在查询中调用服务函数来启动与过滤服务的通信。要调用 `filter_doc_udf` 服务函数，执行以下 `SELECT`
    语句，提供示例输入字符串 (`''122880''`):'
- en: '[PRE26]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Upon executing this query, Snowflake dispatches a `POST` request to the service
    endpoint (`filterendpoint`). Upon receiving the request, the service utilizes
    the input string to filter the table for `UNIQUE_ID` and sends back the appropriate
    row in the response, as shown here:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 执行此查询后，Snowflake 将向服务端点 (`filterendpoint`) 发送一个 `POST` 请求。在收到请求后，服务使用输入字符串来过滤
    `UNIQUE_ID` 表，并在响应中发送适当的行，如下所示：
- en: '![Figure 8.17 – The filter function](img/B19923_08_17.0.jpg)'
  id: totrans-177
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.17 – 过滤功能](img/B19923_08_17.0.jpg)'
- en: Figure 8.17 – The filter function
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.17 – 过滤功能
- en: 'The service exposes its endpoint publicly but still securely behind the Snowflake
    authentication mechanism, as specified in the inline specification provided within
    the `CREATE SERVICE` command. Consequently, you can access a web UI that the service
    exposes to the internet and send requests to the service from a web browser. To
    find the URL of the public endpoint the service exposes, execute the following
    command:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 服务公开其端点，但仍然在 Snowflake 身份验证机制的安全保护下，如 `CREATE SERVICE` 命令中提供的内联说明所述。因此，您可以访问服务公开到互联网的
    Web UI，并通过 Web 浏览器向服务发送请求。要找到服务公开的公共端点 URL，执行以下命令：
- en: '[PRE27]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'To access the web UI, append `/ui` to the endpoint URL and paste it into the
    web browser. This action triggers the execution of the `ui()` function specified
    in the `filter_service.py` script:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问 Web UI，将 `/ui` 添加到端点 URL，并将其粘贴到 Web 浏览器中。此操作将触发 `filter_service.py` 脚本中指定的
    `ui()` 函数的执行：
- en: '![Figure 8.18 – The service UI](img/B19923_08_18.0.jpg)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.18 – 服务 UI](img/B19923_08_18.0.jpg)'
- en: Figure 8.18 – The service UI
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.18 – 服务 UI
- en: Please note that the first time you access the endpoint URL, you’ll be prompted
    to log in to Snowflake. Ensure you log in as the same user who created the service
    to guarantee you possess the necessary privileges.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，您第一次访问端点 URL 时，系统会提示您登录到 Snowflake。请确保以创建服务的同一用户身份登录，以确保您拥有必要的权限。
- en: We have successfully deployed the service and the components. In the next section,
    we will look at the service job.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已成功部署了服务和组件。在下一节中，我们将查看服务作业。
- en: Setting up a Snowpark Container Service job
  id: totrans-186
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置 Snowpark 容器服务作业
- en: In this section, we will create a simple job to connect to a Snowflake table
    and conduct some feature engineering tasks by generating new columns. Subsequently,
    we’ll save the resultant data to the same table within the Snowflake environment.
    Unlike services, jobs are short-lived, providing a one-time execution of tasks.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将创建一个简单的作业，用于连接到Snowflake表，并通过生成新列执行一些特征工程任务。随后，我们将把结果数据保存到Snowflake环境中的同一表中。与服务不同，作业是短暂的，提供一次性的任务执行。
- en: In the next section, we will set up the container job.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将设置容器作业。
- en: Setting up the job
  id: totrans-189
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置作业
- en: For the job, instead of the Flask server implementation for services, we’ll
    utilize a straightforward `main.py` file to execute the job action. We will perform
    the following steps to set up the job.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 对于作业，我们不会使用服务的Flask服务器实现，而是将使用一个简单的`main.py`文件来执行作业操作。我们将执行以下步骤来设置作业。
- en: Job code
  id: totrans-191
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 作业代码
- en: The code for this section is in our GitHub repository under the `chapter_8`
    folder. The folder contains the following files, which are required for the job.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 本节代码位于我们的GitHub仓库的`chapter_8`文件夹中。该文件夹包含以下文件，这些文件对于作业是必需的。
- en: The main.py file
  id: totrans-193
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '`main.py`文件'
- en: The `main.py` file is the core Python script for orchestrating the job’s execution.
    At its heart lies the following `run_job()` function, invoked when the script
    is executed. This function plays a pivotal role in reading environment variables
    and utilizing them to set default values for various parameters that are essential
    for connecting to Snowflake.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '`main.py`文件是作业执行的核心Python脚本。其核心是以下`run_job()`函数，当脚本执行时会被调用。此函数在读取环境变量并利用它们为连接到Snowflake的各种重要参数设置默认值方面发挥着关键作用。'
- en: '[PRE28]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: While Snowflake automatically populates some parameters when the image runs
    within its environment, explicit provision is required when testing the image
    locally. The `run_job()` function gets a table name and column to perform feature
    engineering from the spec.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 当镜像在Snowflake环境中运行时，Snowflake会自动填充一些参数，但在本地测试镜像时需要显式提供。`run_job()`函数从规范中获取一个表名和一个用于特征工程的列。
- en: The Dockerfile
  id: totrans-197
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Dockerfile
- en: The Dockerfile encapsulates all the necessary commands required to build an
    image using Docker. This file resembles what we’ve previously implemented in our
    service section, ensuring consistency and coherence across different Snowpark
    Container Services environment components.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: Dockerfile封装了构建镜像所需的所有必要命令。此文件类似于我们在服务部分中实现的内容，确保了在不同Snowpark容器服务环境组件之间的连贯性和一致性。
- en: The job specification file
  id: totrans-199
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 作业规范文件
- en: The following job specification file provides Snowflake with essential container
    configuration information. Snowflake leverages the information provided in the
    `my_job_spec.yaml` specification file to configure and execute your job seamlessly.
    In addition to mandatory fields such as `container.name` and `container.image`,
    this specification file includes optional fields such as `container.args`, which
    list the arguments required for job execution.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 以下作业规范文件为Snowflake提供了必要的容器配置信息。Snowflake利用`my_job_spec.yaml`规范文件中提供的信息来无缝配置和执行您的作业。除了如`container.name`和`container.image`等必填字段外，此规范文件还包括可选字段，如`container.args`，它列出了作业执行所需的参数。
- en: '[PRE29]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Notably, the `--query` argument specifies the query to be executed when the
    job runs, while the `--result_table` argument identifies the table where the query
    results will be stored.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，`--query`参数指定了作业运行时要执行的查询，而`--result_table`参数标识了查询结果将存储的表。
- en: In the next section, we will deploy the job.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将部署作业。
- en: Deploying the job
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 部署作业
- en: 'To upload your job specification file (`my_job_spec.yaml`) into the Snowflake
    environment, you have a couple of options for uploading it to the designated stage:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 要将您的作业规范文件（`my_job_spec.yaml`）上传到Snowflake环境，您有几个选项将其上传到指定的阶段：
- en: '**Snowsight web interface**: Utilizing the Snowsight web interface offers a
    user-friendly approach to uploading your job specification file. Following the
    instructions we have covered in previous chapters, you can effortlessly navigate
    the process and ensure successful integration.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Snowsight网页界面**：使用Snowsight网页界面提供了一个用户友好的方法来上传您的作业规范文件。按照我们在前几章中介绍的操作说明，您可以轻松地导航此过程并确保成功集成。'
- en: '**SnowSQL command-line interface (CLI)**: Alternatively, you can use the SnowSQL
    CLI to execute the file upload process by executing the following **PUT** command
    syntax:'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**SnowSQL 命令行界面 (CLI)**：或者，您可以使用 SnowSQL CLI 通过执行以下 **PUT** 命令语法来执行文件上传过程：'
- en: '[PRE30]'
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '![Figure 8.19 – Job upload](img/B19923_08_19.0.jpg)'
  id: totrans-209
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.19 – 作业上传](img/B19923_08_19.0.jpg)'
- en: Figure 8.19 – Job upload
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.19 – 作业上传
- en: Now that the job file has been uploaded, we will execute the job in the next
    section.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 现在作业文件已上传，我们将在下一节中执行作业。
- en: Executing the job
  id: totrans-212
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 执行作业
- en: 'To kick off the execution of a job, you’ll utilize the `EXECUTE SERVICE` command,
    which acts as the catalyst for launching the specified task. Run the following
    command to trigger the job (this command may change since we are in private preview
    at the time of writing):'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 要启动作业的执行，您将使用 `EXECUTE SERVICE` 命令，该命令作为启动指定任务的催化剂。运行以下命令以触发作业（由于我们当时处于私有预览阶段，此命令可能会更改）：
- en: '[PRE31]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Alternatively, you can use the following:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，您可以使用以下方法：
- en: '[PRE32]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The specified compute pool, `snowpark_cs_compute_pool`, determines the allocation
    of computational resources necessary for the job’s successful execution. The `@snowpark_cs_stage`
    notation denotes the designated stage within Snowflake where the job specification
    file is stored, facilitating seamless access to the required configuration details.
    The `my_job_spec.yaml` file refers to the specific configuration file containing
    the instructions and parameters for executing the job seamlessly. Successful execution
    of the command should display the following output:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 指定的计算池 `snowpark_cs_compute_pool` 决定了作业成功执行所需的计算资源分配。`@snowpark_cs_stage` 符号表示在
    Snowflake 中存储作业规范文件的指定阶段，便于无缝访问所需的配置细节。`my_job_spec.yaml` 文件指的是包含执行作业所需指令和参数的特定配置文件。成功执行命令应显示以下输出：
- en: '![Figure 8.20 – Job execution](img/B19923_08_20.0.jpg)'
  id: totrans-218
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.20 – 作业执行](img/B19923_08_20.0.jpg)'
- en: Figure 8.20 – Job execution
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.20 – 作业执行
- en: Upon execution, the job performs the specified SQL statement and saves the resultant
    data to a designated table, as outlined within the job specification file (`my_job_spec.yaml`).
    It’s crucial to note that the execution of the SQL statement does not occur within
    the Docker container itself. Instead, the container connects with Snowflake, leveraging
    a Snowflake warehouse to execute the SQL statement efficiently. The `EXECUTE SERVICE`
    command returns the output containing vital information, including the Snowflake-assigned
    **UUID** (short for **Universally Unique Identifier**) of the job. This UUID serves
    as a unique identifier for the executed job, aiding in tracking and monitoring
    its progress and status.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 执行后，作业将执行指定的 SQL 语句，并将结果数据保存到指定的表中，如作业规范文件（`my_job_spec.yaml`）中所述。需要注意的是，SQL
    语句的执行并不在 Docker 容器内部进行。相反，容器连接到 Snowflake，利用 Snowflake 仓库高效地执行 SQL 语句。`EXECUTE
    SERVICE` 命令返回包含关键信息的输出，包括作业分配的 **UUID**（通用唯一标识符的缩写）。这个 UUID 作为执行作业的唯一标识符，有助于跟踪和监控其进度和状态。
- en: In the next section, we will deploy an LLM for Snowpark Container Services.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将为 Snowpark 容器服务部署一个 LLM。
- en: Deploying LLMs with Snowpark
  id: totrans-222
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Snowpark 部署 LLM
- en: Modern enterprises increasingly demand that LLMs be harnessed with proprietary
    data. Open source and proprietary models play pivotal roles in enabling this transition.
    However, the main challenge is finding a robust platform capable of effectively
    leveraging LLMs’ power. Snowflake empowers organizations to apply near-magical
    generative AI transformations to their data. By leveraging advanced LLM models
    within Snowflake, organizations can efficiently operate with large volumes of
    data, enabling generative AI use cases. In this section, we will discuss deploying
    LLM models within Snowpark Container Services.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 现代企业越来越要求将 LLM 与专有数据相结合。开源和专有模型在实现这一转型中发挥着关键作用。然而，主要挑战是找到一个能够有效利用 LLM 力量的强大平台。Snowflake
    使组织能够将近乎神奇的生成式 AI 变换应用于其数据。通过在 Snowflake 内部利用高级 LLM 模型，组织可以高效地处理大量数据，实现生成式 AI
    用例。在本节中，我们将讨论在 Snowpark 容器服务中部署 LLM 模型。
- en: In this walk-through, we’ll explore how to harness publicly accessible data
    to demonstrate the transformative capabilities of Snowflake’s ecosystem by deploying
    the Llama 2 LLM from the Hugging Face repository.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 在本指南中，我们将探讨如何利用公开可访问的数据，通过部署来自 Hugging Face 存储库的 Llama 2 LLM，来展示 Snowflake 生态系统的变革能力。
- en: Note
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Llama 2 by Meta, housed within Hugging Face’s library, epitomizes advanced **natural
    language processing** (**NLP**) technology. As stipulated by Meta’s specific terms
    of service, you’ll need a Hugging Face token to access Llama 2 with Hugging Face.
    Please visit [https://huggingface.co/docs/hub/en/security-tokens](https://huggingface.co/docs/hub/en/security-tokens)
    to learn more.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: Meta的Llama 2，位于Hugging Face的库中，代表了先进的**自然语言处理**（NLP）技术。根据Meta的具体服务条款，你需要一个Hugging
    Face令牌才能通过Hugging Face访问Llama 2。请访问[https://huggingface.co/docs/hub/en/security-tokens](https://huggingface.co/docs/hub/en/security-tokens)了解更多信息。
- en: Preparing the LLM
  id: totrans-227
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备LLM
- en: 'We will start by preparing the LLM by utilizing our convenient wrapper around
    the Hugging Face Transformers API, and harness the capabilities of Llama 2 7B
    from Hugging Face. To achieve this, run the following code:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先通过利用我们对Hugging Face Transformers API的便捷包装来准备LLM，并利用Hugging Face的Llama 2
    7B的能力。为此，请运行以下代码：
- en: '[PRE33]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Make sure to replace `HF_AUTH_TOKEN` with your token from Hugging Face. The
    code creates the model registry and assigns the model from the Hugging Face registry.
    The model is obtained from the Hugging Face registry and directly imported into
    Snowpark.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 确保将`HF_AUTH_TOKEN`替换为你在Hugging Face的令牌。代码创建模型注册库并将从Hugging Face注册库中获取的模型分配给模型。模型是从Hugging
    Face注册库中获取的，并直接导入到Snowpark中。
- en: Next, we will register the model within Snowpark ML.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将在Snowpark ML中注册模型。
- en: Registering the model
  id: totrans-232
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 注册模型
- en: 'Next, we’ll utilize the model registry’s `log_model` API within Snowpark ML
    to register the model. This involves specifying a model name and a version string
    and providing the model obtained in the previous step:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将利用Snowpark ML中的模型注册库的`log_model` API来注册模型。这包括指定一个模型名称和一个版本字符串，并提供上一步获得的模型：
- en: '[PRE34]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'You should see an output similar to the following:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该会看到以下类似的输出：
- en: '![Figure 8.21 – Model registration](img/B19923_08_21.0.jpg)'
  id: totrans-236
  prefs: []
  type: TYPE_IMG
  zh: '![图8.21 – 模型注册](img/B19923_08_21.0.jpg)'
- en: Figure 8.21 – Model registration
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.21 – 模型注册
- en: The model is now registered in the registry. Now that the model is ready, we
    will deploy it to Container Services.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 模型现在已注册在注册库中。现在模型已准备就绪，我们将将其部署到容器服务。
- en: Deploying the model to Snowpark Container Services
  id: totrans-239
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将模型部署到Snowpark容器服务
- en: Now, let us deploy the model to our designated compute pool. Once the deployment
    process is initiated, the model will become accessible as a Snowpark Container
    Services endpoint. Run the following code to deploy the model to Container Services.
    To run this step, you may need to alter your compute pool to include a GPU instance,
    or you can create a new compute pool with a GPU instance.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们将模型部署到我们的指定计算池。一旦部署过程开始，模型将作为Snowpark容器服务端点可用。运行以下代码将模型部署到容器服务。运行此步骤可能需要您将计算池更改为包含GPU实例，或者您可以创建一个新的包含GPU实例的计算池。
- en: '[PRE35]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: This streamlined deployment process highlights how Snowpark ML simplifies the
    deployment of LLMs, handling the creation of the corresponding Snowpark Container
    Services `SERVICE` definition, packaging the model within a Docker image along
    with its runtime dependencies, and launching the service within the specified
    compute pool.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 这个简化的部署过程突出了Snowpark ML如何简化LLM的部署，包括创建相应的Snowpark容器服务`SERVICE`定义，将模型及其运行时依赖项打包到Docker镜像中，并在指定的计算池中启动服务。
- en: 'After executing the code, you should see a similar output:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 执行代码后，你应该会看到类似的输出：
- en: '![Figure 8.22 – Deploying the LLM model to Snowpark Container Services](img/B19923_08_22.0.jpg)'
  id: totrans-244
  prefs: []
  type: TYPE_IMG
  zh: '![图8.22 – 将LLM模型部署到Snowpark容器服务](img/B19923_08_22.0.jpg)'
- en: Figure 8.22 – Deploying the LLM model to Snowpark Container Services
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.22 – 将LLM模型部署到Snowpark容器服务
- en: In the next section, we will execute this model in the container.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将在这个容器中执行此模型。
- en: Note on model deployment
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 关于模型部署的注意事项
- en: Only the snippets required for explanation are shown in this section. The complete
    code is available in the **chapter_8.ipynb** notebook in GitHub. You should be
    mindful of the model deployment step as it takes considerable time and resources.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 本节中仅显示了用于解释的代码片段。完整的代码可在GitHub中的**chapter_8.ipynb**笔记本中找到。您应该注意模型部署步骤，因为它需要相当多的时间和资源。
- en: Running the model
  id: totrans-249
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 运行模型
- en: 'Invoke the model by supplying the subset of the `NEWS_CATEGORY` table with
    the `inputs` column containing the prompt:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 通过提供包含提示的`inputs`列的`NEWS_CATEGORY`表子集来调用模型：
- en: '[PRE36]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'This yields a Snowpark DataFrame with an output column containing the model’s
    response for each row. The raw response intersperses text with the expected JSON
    output, exemplified as follows:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成一个包含模型对每行响应的输出列的 Snowpark DataFrame。原始响应将文本与预期的 JSON 输出交织在一起，如下所示：
- en: '[PRE37]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Deploying and executing an LLM model is very easy with Snowpark Container Services.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Snowpark 容器服务部署和执行 LLM 模型非常简单。
- en: We will conclude the chapter with a summary.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将以本章的总结结束。
- en: Summary
  id: totrans-256
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we explored Snowpark Container Services, a powerful solution
    designed to simplify the deployment and management of containerized applications
    within the Snowflake ecosystem. We discussed the distinction between jobs and
    services within Snowpark Container Services, highlighting their respective functionalities
    and use cases. We demonstrated how to effectively configure, deploy, and manage
    jobs and services through practical implementation examples.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了 Snowpark 容器服务，这是一个旨在简化 Snowflake 生态系统内容器化应用程序部署和管理的强大解决方案。我们讨论了 Snowpark
    容器服务中作业和服务之间的区别，强调了它们各自的功能和用例。我们通过实际实施示例展示了如何有效地配置、部署和管理作业和服务。
- en: Additionally, we delved into containerization through Snowpark ML, showcasing
    how Snowflake users can seamlessly leverage advanced ML models within their environment.
    By integrating a language model from Hugging Face, we illustrated how Snowpark
    ML facilitates the integration of containerized models, enabling sophisticated
    NLP tasks directly within Snowflake. Overall, this chapter equips you with the
    knowledge and tools to harness the transformative potential of SCS and Snowpark
    ML in your data-driven initiatives.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们深入探讨了通过 Snowpark ML 的容器化，展示了 Snowflake 用户如何无缝地在他们的环境中利用高级 ML 模型。通过集成来自
    Hugging Face 的语言模型，我们说明了 Snowpark ML 如何促进容器化模型的集成，使复杂的 NLP 任务能够直接在 Snowflake 中执行。总的来说，本章为您提供了利用
    SCS 和 Snowpark ML 在数据驱动型项目中的变革性潜力的知识和工具。
- en: In conclusion, Snowpark Container Services offers a compelling value proposition
    for businesses seeking efficient and scalable data processing solutions. By enabling
    secure execution of containerized workloads directly within Snowflake, Snowpark
    eliminates the need for data movement, ensuring data integrity and reducing latency.
    Additionally, Snowpark simplifies the development and deployment of data applications,
    allowing teams to focus on innovation rather than infrastructure management. Automated
    container management further streamlines operational tasks, enhancing overall
    productivity and agility.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，Snowpark 容器服务为寻求高效和可扩展数据处理解决方案的企业提供了一个有吸引力的价值主张。通过在 Snowflake 中直接执行容器化工作负载，Snowpark
    消除了数据移动的需要，确保数据完整性并降低延迟。此外，Snowpark 简化了数据应用程序的开发和部署，使团队能够专注于创新而不是基础设施管理。自动化的容器管理进一步简化了运营任务，提高了整体的生产力和敏捷性。
- en: With this, we conclude the book. Thank you for reading.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这个，我们就结束了这本书。感谢您的阅读。
