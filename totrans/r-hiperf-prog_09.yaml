- en: Chapter 9. Offloading Data Processing to Database Systems
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第9章：将数据处理任务卸载到数据库系统
- en: We have learned many different ways to optimize the performance of an R code
    for speed and memory efficiency. But sometimes R alone is not enough. Perhaps,
    a very large dataset is stored in a data warehouse. It would be infeasible to
    extract all the data into R for processing. We might even wish to tap into the
    power of specially-designed analytical databases that can perform computations
    on data much more efficiently than R can. In this chapter, we will learn how to
    tap into the power of external database systems from within R and combine that
    power with the flexibility and ease of use of the R language.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经学习了多种优化R代码性能的方法，以实现速度和内存效率。但有时仅使用R是不够的。也许，一个非常大的数据集存储在数据仓库中。将所有数据提取到R中进行处理是不切实际的。我们甚至可能希望利用专门设计的分析数据库的强大功能，这些数据库可以比R更高效地执行计算。在本章中，我们将学习如何从R内部利用外部数据库系统的功能，并将这种功能与R语言的灵活性和易用性相结合。
- en: 'This chapter covers the following:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖了以下内容：
- en: Extracting data into R versus processing data in a database
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数据提取到R中与在数据库中处理数据
- en: Preprocessing data in a relational database using SQL
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用SQL在关系型数据库中预处理数据
- en: Converting R expressions into SQL
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将R表达式转换为SQL
- en: Running statistical and machine learning algorithms in a database
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在数据库中运行统计和机器学习算法
- en: Using columnar databases for improved performance
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用列式数据库以提高性能
- en: Using array databases for maximum scientific computing performance
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用数组数据库以实现最大的科学计算性能
- en: Extracting data into R versus processing data in a database
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将数据提取到R中与在数据库中处理数据
- en: Most R programmers are familiar with and very comfortable manipulating data
    in R using R data structures and packages. This requires moving all the data into
    R whether in memory or on a disk, on a single computer or on a cluster. In some
    situations, this might not be efficient especially if the data constantly changes
    and needs to be updated often—extracting data out of a database or data warehouse
    every time it needs to be analyzed takes a lot of time and computational resources.
    In some cases, it might not be feasible at all to move terabytes or more of data
    from their sources into R.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数R程序员熟悉且非常舒适地使用R数据结构和包来操作数据。这需要将所有数据移动到R中，无论是在内存中还是在磁盘上，在单台计算机上还是在集群上。在某些情况下，这可能不是高效的，特别是如果数据不断变化且需要经常更新——每次分析时从数据库或数据仓库中提取数据需要大量的时间和计算资源。在某些情况下，可能根本无法将数以兆计的数据从其来源移动到R中。
- en: Instead of moving the data into R, another approach is to move the computational
    tasks to the data. In other words, we can process the data in the database and
    retrieve only the results into R, which are usually much smaller than the raw
    data. This reduces the amount of network bandwidth required to transmit the data
    and the local storage and memory required to process the data in R. It also allows
    R programmers to tap into powerful databases that are purpose-built for analytical
    workloads on large datasets.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 与将数据移动到R中不同，另一种方法是将计算任务移动到数据所在的位置。换句话说，我们可以在数据库中处理数据，并将结果仅检索到R中，这些结果通常比原始数据小得多。这减少了传输数据所需的网络带宽以及处理R中数据所需的本地存储和内存。它还允许R程序员利用专为大型数据集上的分析工作负载而设计的强大数据库。
- en: In order to perform in-database computations and analyses, a new set of tools
    is needed. At the foundation of all in-database tools is the SQL language, which
    most relational databases support. While this book is not about SQL, knowing how
    to run even simple SQL statements in a database can help speed up many tasks in
    R. Other tools such as `dplyr` build on SQL to provide easy and familiar interfaces
    such as data frame-like objects in order to manipulate the data in the database.
    Yet other tools like MonetDB.R and SciDB allow us to tap into databases that are
    designed for high-performance analytical workloads such as columnar and array
    databases. We shall look at these tools in the following sections.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在数据库中执行计算和分析，需要一套新的工具。所有数据库工具的基础是SQL语言，大多数关系型数据库都支持SQL。虽然本书不是关于SQL的，但了解如何在数据库中运行简单的SQL语句可以帮助加快R中许多任务的执行速度。其他工具，如`dplyr`，建立在SQL的基础上，提供易于使用且熟悉的接口，例如类似数据框的对象，以便在数据库中操作数据。还有其他工具，如MonetDB.R和SciDB，使我们能够利用专为高性能分析工作负载（如列式和数组数据库）而设计的数据库。在接下来的几节中，我们将探讨这些工具。
- en: Preprocessing data in a relational database using SQL
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用SQL在关系型数据库中预处理数据
- en: We will start by learning how to run SQL statements in the database from R.
    The first few examples show how processing data in a database instead of moving
    all the data into R can result in faster performance even for simple operations.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先学习如何在R中运行SQL语句，最初的几个示例将展示如何在数据库中处理数据而不是将所有数据移动到R中，即使是简单的操作也能带来更快的性能。
- en: To run the examples in this chapter, you will need a database server supported
    by R. The CRAN package, `RJDBC` provides an interface to JDBC drivers that most
    databases come with. Alternatively, search on CRAN for packages such as `RPostgreSQL`,
    `RMySQL`, and `ROracle` that offer functionalities and optimizations specific
    to each database.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行本章中的示例，你需要一个R支持的数据库服务器。CRAN包`RJDBC`提供了一个接口，用于大多数数据库附带的JDBC驱动程序。或者，在CRAN上搜索提供针对每个数据库特定功能和优化的包，如`RPostgreSQL`、`RMySQL`和`ROracle`。
- en: The following examples are based on a PostgreSQL database and the `RPostgreSQL`
    package as we will need them later in this chapter when we learn about the `PivotalR`
    package and MADlib software. Feel free, however, to adapt the code to the database
    that you use.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例基于PostgreSQL数据库和`RPostgreSQL`包，因为我们将在本章学习`PivotalR`包和MADlib软件时需要它们。不过，你可以自由地将代码适配到你使用的数据库。
- en: 'Configuring PostgreSQL to work with R involves setting up both the server and
    the client. First, we need to set up the PostgreSQL database server. This can
    be on a different computer than the one running R to simulate tapping into an
    existing database from R; or it can be on the same computer for simplicity. In
    our case, we will set up a Linux virtual machine to host the PostgreSQL database
    server and use Mac OS X as the client. Here are the steps to set up the database
    server:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 配置PostgreSQL与R一起工作涉及设置服务器和客户端。首先，我们需要设置PostgreSQL数据库服务器。这可以是在运行R的不同计算机上，以模拟从R中访问现有数据库；或者它也可以在同一台计算机上以简化操作。在我们的案例中，我们将设置一个Linux虚拟机来托管PostgreSQL数据库服务器，并使用Mac
    OS X作为客户端。以下是设置数据库服务器的步骤：
- en: Download PostgreSQL from [http://www.postgresql.org/download/](http://www.postgresql.org/download/)
    and follow the installation instructions for your operating system.
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从[http://www.postgresql.org/download/](http://www.postgresql.org/download/)下载PostgreSQL，并遵循你操作系统的安装说明。
- en: 'Enable username/password authentication on the database server by adding the
    following command line to `pg_hba.conf` (in the PostgreSQL `data` folder):'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过将以下命令行添加到`pg_hba.conf`（在PostgreSQL的`data`文件夹中）来在数据库服务器上启用用户名/密码认证：
- en: '[PRE0]'
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Create a user account and password that can be used to connect to the database
    from R by running the following command line (you might need to be the `root`
    or the `postgres` user to run this):'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行以下命令行创建一个用户账户和密码，该账户和密码可以用于从R连接到数据库（你可能需要作为`root`或`postgres`用户来运行此命令）：
- en: '[PRE1]'
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Create a database for the examples in this chapter by running the following
    command line (you might need to be the `root` or the `postgres` user to run this):'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行以下命令行创建用于本章示例的数据库（你可能需要作为`root`或`postgres`用户来运行此命令）：
- en: '[PRE2]'
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Ensure that the database is accessible via a network connection from the computer
    that runs R by adding the following lines to `postgresql.conf` (in the PostgreSQL
    `data` folder):'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过将以下行添加到`postgresql.conf`（在PostgreSQL的`data`文件夹中）来确保数据库可以通过运行R的计算机的网络连接访问：
- en: '[PRE3]'
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Restart the PostgreSQL server for the changes to take effect (you might need
    to be the `root` user to do this).
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重启PostgreSQL服务器以使更改生效（你可能需要作为`root`用户来完成此操作）。
- en: 'Next, we will set up the client by installing the `RPostgreSQL` package on
    the computer that runs R:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将通过在运行R的计算机上安装`RPostgreSQL`包来设置客户端：
- en: 'Non-Windows only: install `libpq`, the PostgreSQL C libraries, that are needed
    to install `RPostgreSQL`. If you have installed the PostgreSQL server on the same
    computer as R, the libraries are already in the system, so you can skip this step.
    Otherwise, make sure that the version of the libraries matches the version of
    the PostgreSQL server:'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 非Windows系统：安装`libpq`，PostgreSQL的C库，这是安装`RPostgreSQL`所需的。如果你已经在同一台计算机上安装了PostgreSQL服务器，那么库已经存在于系统中，因此你可以跳过此步骤。否则，请确保库的版本与PostgreSQL服务器的版本相匹配：
- en: '[PRE4]'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Run R and install the `RPostgreSQL` CRAN package from its source code:'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行R并从其源代码安装`RPostgreSQL` CRAN包：
- en: '[PRE5]'
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Test the database connection from R by substituting the details with the correct
    information for your database:'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过用你数据库的正确信息替换细节来测试R中的数据库连接：
- en: '[PRE6]'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Once the database is set up, we will generate some sales data for the examples
    to follow. The example database has two tables, `sales` and `trans_items`. The
    `sales` table contains information about sales transactions in a retail chain,
    including the transaction ID, customer ID, and store ID. The `trans_items` table
    records the individual items in each transaction and the total price for each
    item. Once the data is generated in R, we will use `dbWriteTable()` to write the
    data into new tables in the database, as follows:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦数据库设置完成，我们将为后续的示例生成一些销售数据。示例数据库有两个表，`sales`和`trans_items`。`sales`表包含关于零售连锁店销售交易的信息，包括交易ID、客户ID和商店ID。`trans_items`表记录了每个交易中的单个商品以及每个商品的总价格。一旦在R中生成了数据，我们将使用`dbWriteTable()`将数据写入数据库中的新表，如下所示：
- en: '[PRE7]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The first task is to calculate the total sales for each store. Let''s compare
    two different ways of doing this. The first way is to extract all the store IDs
    along with the prices of the items associated with each store by joining the `sales`
    and `trans_items` tables. Once this data is in R, the sales for each store is
    computed by summing the item prices for each store ID using `tapply()`. The second
    way to compute the same data is to perform the aggregation in the database using
    the SQL `GROUP BY` clause and `SUM()` function. We will use `microbenchmark()`
    to compare the execution times for both methods:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个任务是计算每个商店的总销售额。让我们比较两种不同的方法。第一种方法是通过连接`sales`和`trans_items`表，提取所有商店ID以及与每个商店相关的商品价格。一旦这些数据在R中，每个商店的销售额是通过使用`tapply()`对每个商店ID的商品价格进行求和来计算的。计算相同数据的第二种方法是使用SQL的`GROUP
    BY`子句和`SUM()`函数在数据库中执行聚合。我们将使用`microbenchmark()`来比较两种方法的执行时间：
- en: '[PRE8]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'In this simple test, performing the computations in the database takes only
    33 percent of the time to do the same by extracting the data into R. Let''s take
    a look at another example. The second task is to get a list of the top ten customers
    who have spent the most money, in decreasing order. Again, we will compare the
    speed of performing the computations in R versus in the database:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个简单的测试中，在数据库中执行计算只需要用R提取数据执行相同操作所需时间的33%。让我们看看另一个例子。第二个任务是获取花费最多钱的前十位客户的列表，按金额降序排列。同样，我们将比较在R中执行计算与在数据库中执行计算的速率：
- en: '[PRE9]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Again, running the computations in the database instead of in R has resulted
    in a 70 percent reduction in the execution time.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，在数据库中而不是在R中运行计算导致执行时间减少了70%。
- en: 'Once we are done, we need to disconnect from the database:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们完成，我们需要从数据库断开连接：
- en: '[PRE10]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: These tests were conducted on the same computer with the database server running
    in a virtual machine. Even on such a small dataset and over a very small network
    (the virtual network between the host computer and the virtual machine), the differences
    in the performance were dramatic. These tests clearly demonstrate that minimizing
    the amount of data being copied out of the database can provide a big performance
    boost. On larger datasets and powerful analytical databases, the performance difference
    can be even more pronounced.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这些测试是在同一台计算机上进行的，数据库服务器运行在虚拟机中。即使在如此小的数据集和非常小的网络（主机计算机和虚拟机之间的虚拟网络）上，性能差异也非常明显。这些测试清楚地表明，最小化从数据库中复制的数据量可以提供巨大的性能提升。在更大的数据集和强大的分析数据库上，性能差异可能更加明显。
- en: Converting R expressions to SQL
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将R表达式转换为SQL
- en: While SQL is a powerful and flexible language used to manipulate data in a database,
    not everyone is proficient in it. Fortunately, the R community has developed a
    few packages that translate familiar R syntax into SQL statements that are then
    executed on the database. We will look at two of them—`dplyr` and `PivotalR`.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然SQL是一种强大且灵活的语言，用于在数据库中操作数据，但并非每个人都能熟练掌握它。幸运的是，R社区已经开发了一些包，可以将熟悉的R语法转换为在数据库上执行的SQL语句。我们将探讨其中的两个——`dplyr`和`PivotalR`。
- en: Using dplyr
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用dplyr
- en: The `dplyr` package is a handy package designed to allow the manipulation of
    table-like data with a standard set of operations and transformations, no matter
    where the data is stored—in a data frame, data table, or database. It supports
    SQLite, PostgreSQL, MySQL, Amazon RedShift, Google BigQuery, and MonetDB databases.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '`dplyr`包是一个方便的包，旨在允许使用标准操作和转换来操作类似表的数据，无论数据存储在哪里——在数据框、数据表或数据库中。它支持SQLite、PostgreSQL、MySQL、Amazon
    RedShift、Google BigQuery和MonetDB数据库。'
- en: The `dplyr` package provides a way to specify a set of operations to be performed
    on the data without actually performing the computations on the database server
    until we instruct R to do so, by calling the `collect()`function. By pooling a
    few operations together (as opposed to executing them one by one), the database
    server can optimize the execution. This in turn helps to minimize computational
    load of the server. Let's see how this works with an example.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '`dplyr` 包提供了一种方法，可以在不实际在数据库服务器上执行计算的情况下指定要执行的一组操作，通过调用 `collect()` 函数来指示 R
    执行。通过将几个操作组合在一起（而不是逐个执行），数据库服务器可以优化执行。这反过来有助于最小化服务器的计算负载。让我们通过一个例子看看它是如何工作的。'
- en: 'First, we need to establish a connection with the database, as before. Here,
    we will use the `src_postgres()` function provided by `dplyr`. The syntax is slightly
    different from `dbConnect()` of `RPostgreSQL`, but the arguments are similar.
    After establishing the connection, we will create references to the `sales` and
    `trans_items` tables in the database using the `tbl()` function:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要与数据库建立连接，就像之前一样。在这里，我们将使用 `dplyr` 提供的 `src_postgres()` 函数。语法与 `RPostgreSQL`
    的 `dbConnect()` 略有不同，但参数相似。建立连接后，我们将使用 `tbl()` 函数在数据库中创建对 `sales` 和 `trans_items`
    表的引用：
- en: '[PRE11]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Let''s recreate the previous example using `dplyr`:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用 `dplyr` 重新创建之前的例子：
- en: '[PRE12]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The first step is to join the `sales` and `trans_items` tables using `inner_join()`.
    Then, `group_by()` groups the items according to customer ID, and `summarize()`
    sums the total spending for each customer. Finally, we will use `arrange()` to
    sort the customer in decreasing order of spending, and `select()` to select only
    the columns we want.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是使用 `inner_join()` 将 `sales` 和 `trans_items` 表连接起来。然后，`group_by()` 根据客户 ID
    对项目进行分组，`summarize()` 对每个客户的总消费进行求和。最后，我们将使用 `arrange()` 按消费金额降序排序客户，并使用 `select()`
    选择我们想要的列。
- en: 'The output of each of these steps is a `tbl` object:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 每个这些步骤的输出都是一个 `tbl` 对象：
- en: '[PRE13]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'These are virtual tables that are an accumulation of all the operations applied
    so far. Up to this point, no SQL has been sent to the database server and no computation
    has been performed on it. We can examine the SQL query that will be executed when
    the results are retrieved by retrieving the `query` member of the `tbl` object:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是虚拟表，是迄今为止应用的所有操作的累积。到目前为止，尚未向数据库服务器发送 SQL 语句，也没有在其上执行计算。我们可以通过检索 `tbl` 对象的
    `query` 成员来检查在检索结果时将执行的 SQL 查询：
- en: '[PRE14]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Normally, the `collect()` function is used to run the SQL statement and retrieve
    the results:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，`collect()` 函数用于运行 SQL 语句并检索结果：
- en: '[PRE15]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Since we want only the top 10 customers and not all the customers, we can use
    `head()` to minimize the data being transferred from the database into R:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们只想获取前 10 名客户而不是所有客户，我们可以使用 `head()` 来最小化从数据库传输到 R 的数据：
- en: '[PRE16]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'As more complex data manipulation operations are constructed in `dplyr`, the
    individual R statements and temporary variables created can get unwieldy. The
    `dplyr` package provides the `%>%` operator to chain operations together. The
    preceding construct can be rewritten more succinctly as:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 随着在 `dplyr` 中构建更复杂的数据操作，单个 R 语句和临时变量可能会变得难以管理。`dplyr` 包提供了 `%>%` 操作符来链接操作。前面的结构可以更简洁地重写为：
- en: '[PRE17]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The `dplyr` package provides other useful operations like `filter()` for filtering
    rows, and `mutate()` for defining new columns as functions of the existing columns.
    These operations can be combined in many creative and useful ways to process data
    in a database before retrieving the results into R.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '`dplyr` 包提供了其他有用的操作，如 `filter()` 用于过滤行，以及 `mutate()` 用于定义新列作为现有列的函数。这些操作可以以许多创造性和有用的方式组合起来，在将结果检索到
    R 之前在数据库中处理数据。'
- en: Using PivotalR
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 PivotalR
- en: The `PivotalR` package provides similar capabilities as `dplyr`, but with a
    different syntax. Because it was developed by Pivotal Software Inc., it supports
    only PostgreSQL or Pivotal (Greenplum) databases.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '`PivotalR` 包提供了与 `dplyr` 类似的特性，但语法不同。因为它是由 Pivotal Software Inc. 开发的，所以它只支持
    PostgreSQL 或 Pivotal (Greenplum) 数据库。'
- en: 'As usual, the first step in using the package is to establish a connection
    to the database:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 如同往常，使用该包的第一步是建立与数据库的连接：
- en: '[PRE18]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Note
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: If you have not installed MADlib on the PostgreSQL database (see the next section
    of this chapter), you might get a warning that says "MADlib does not exist in
    database." This is not a problem for the examples in this section as they do not
    cover the MADlib functions.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你还没有在 PostgreSQL 数据库上安装 MADlib（请参阅本章下一节），你可能会收到一个警告，提示“数据库中不存在 MADlib。”在本节中的示例不会遇到这个问题，因为它们不涉及
    MADlib 函数。
- en: 'The next step is to create references to the database tables using `db.data.frame()`:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是使用 `db.data.frame()` 创建对数据库表的引用：
- en: '[PRE19]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The `db.data.frame` objects behave similar to standard R data frames in many
    ways, except that they are wrappers for SQL queries that need to be executed on
    the database. Many of the standard R information and statistical functions are
    supported. In order to execute the SQL and retrieve the results, use the `lookat()`
    function (or the shorthand `lk()`). For example:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '`db.data.frame` 对象在许多方面与标准的 R 数据框类似，但它们是需要在数据库上执行的 SQL 查询的包装器。许多标准的 R 信息和统计函数都得到了支持。为了执行
    SQL 并检索结果，请使用 `lookat()` 函数（或简写 `lk()`）。例如：'
- en: '[PRE20]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'To see the SQL query that will be executed on the database server, use the
    `content()` method:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看将在数据库服务器上执行的 SQL 查询，请使用 `content()` 方法：
- en: '[PRE21]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Note
  id: totrans-78
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: If you get the error message "Invalid SciDB object", it could mean that some
    of the `PivotalR` functions are being masked by functions of the same name in
    the `SciDB` package, which we will cover later in this chapter. In particular,
    both packages provide the `count()` function. To run the examples in this section
    successfully, unload the `scidb` package with `detach("package:scidb", unload=TRUE)`.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你收到“无效的 SciDB 对象”错误消息，这可能意味着一些 `PivotalR` 函数被 `SciDB` 包中同名函数遮蔽了，我们将在本章后面讨论这个问题。特别是，这两个包都提供了
    `count()` 函数。为了成功运行本节中的示例，请使用 `detach("package:scidb", unload=TRUE)` 卸载 `scidb`
    包。
- en: 'New columns can be computed from existing columns by using the familiar R syntax
    without affecting the data on the database; instead, the transformations are translated
    into SQL functions that compute the new columns on the fly. In the following example,
    we will compute a new column `foreign_price` that is returned to R in memory and
    not stored in the database:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过使用熟悉的 R 语法从现有列计算新列，而不会影响数据库中的数据；相反，转换被转换为在数据库上实时计算新列的 SQL 函数。在以下示例中，我们将计算一个新的列
    `foreign_price`，该列返回到 R 的内存中，而不是存储在数据库中：
- en: '[PRE22]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Let''s take a look at a full example of how to construct a query in `PivotalR`.
    Say we want to compute some statistics to understand the purchasing patterns of
    consumers at the transaction level. We have to group the data by transactions
    and then group it again by customers to compute the statistics for each customer:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一个如何在 `PivotalR` 中构建查询的完整示例。比如说，我们想要计算一些统计信息，以了解交易层面的消费者购买模式。我们必须按交易分组数据，然后再按客户分组，以计算每个客户的统计信息：
- en: '[PRE23]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The first call to `by()` aggregates the item-level sales data into transactions;
    summing up the total value of each transaction. Next, `merge()` joins the `sales`
    table with the aggregated transaction data to match the customers with how much
    they have spent. Then, we will use `by()` again to aggregate all the transactions
    by customer. For each customer, we will calculate the number of transactions they
    made, the total value of those transactions, and the number of stores they visited.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '`by()` 的第一次调用将项目级别的销售数据聚合到交易中；计算每个交易的总价值。然后，`merge()` 将 `sales` 表与聚合的交易数据合并，以匹配客户及其花费的金额。然后，我们将再次使用
    `by()` 来按客户聚合所有交易。对于每个客户，我们将计算他们进行的交易数量、这些交易的总价值以及他们访问的店铺数量。'
- en: Instead of returning the results, they can also be stored into a new database
    table by using `as.db.data.frame()`. This is useful for lengthy computations with
    many intermediate steps. Storing intermediate results in the database helps to
    reduce the amount of data being transferred between R and the database.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 除了返回结果外，还可以使用 `as.db.data.frame()` 将它们存储到新的数据库表中。这对于涉及许多中间步骤的长时间计算非常有用。将中间结果存储在数据库中有助于减少
    R 和数据库之间传输的数据量。
- en: '[PRE24]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Further statistics can be computed from the intermediate data, such as the
    minimum, maximum, mean and standard deviation of customer spending:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 可以从中间数据中计算更多的统计信息，例如客户消费的最小值、最大值、平均值和标准差：
- en: '[PRE25]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'When the intermediate data is no longer required, it can be deleted from the
    database:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 当中间数据不再需要时，可以从数据库中删除它：
- en: '[PRE26]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Both `dplyr` and `PivotalR` provide flexible easy ways to manipulate data in
    a database using R functions and syntax. They allow us to tap into the processing
    power and speed of high-performance databases to query large datasets and integrate
    the results of the queries into other analyses in R. Because they are quite similar
    in capabilities, choosing between the two is largely a matter of compatibility
    with existing database systems and personal preference for one syntax over the
    other.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '`dplyr` 和 `PivotalR` 都提供了灵活且简单的方法，使用 R 函数和语法在数据库中操作数据。它们使我们能够利用高性能数据库的处理能力和速度来查询大型数据集，并将查询结果集成到
    R 中的其他分析中。由于它们在功能上相当相似，选择两者之间的区别主要取决于与现有数据库系统的兼容性以及个人对某种语法而非另一种语法的偏好。'
- en: Running statistical and machine learning algorithms in a database
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在数据库中运行统计和机器学习算法
- en: So far, the examples in this chapter have performed simple computations on data
    in a database. Sometimes we need to perform more complex computations than that.
    Several database vendors have begun to build advanced statistics or even machine
    learning capabilities into their database products, allowing these advanced algorithms
    to run in the database using highly optimized code for maximum performance. In
    this chapter, we will look at one open source project, MADlib ([http://madlib.net/](http://madlib.net/)),
    whose development is supported by Pivotal Inc., that brings advanced statistics
    and machine learning capabilities to PostgreSQL databases.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，本章中的示例已在数据库中的数据上执行了简单的计算。有时我们需要执行比这更复杂的计算。一些数据库供应商已经开始将高级统计或甚至机器学习功能构建到他们的数据库产品中，允许这些高级算法在数据库中以高度优化的代码运行，以实现最佳性能。在本章中，我们将探讨一个开源项目
    MADlib ([http://madlib.net/](http://madlib.net/))，其开发由 Pivotal Inc. 支持，它将高级统计和机器学习功能带给
    PostgreSQL 数据库。
- en: MADlib adds a host of statistical capabilities to PostgreSQL, including descriptive
    statistics, hypothesis tests, array arithmetic, probability functions, dimensionality
    reduction, linear models, clustering models, association rules, and text analysis.
    New models and statistical methods are constantly being added to the library to
    expand its capabilities.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: MADlib 为 PostgreSQL 添加了大量统计功能，包括描述性统计、假设检验、数组算术、概率函数、降维、线性模型、聚类模型、关联规则和文本分析。新模型和统计方法不断添加到库中，以扩展其功能。
- en: Note
  id: totrans-95
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: At the moment, MADlib binaries are only available for Mac OS X and Red Hat/CentOS
    Linux. For other operating systems, [https://github.com/madlib/madlib/wiki/Building-MADlib-from-Source](https://github.com/madlib/madlib/wiki/Building-MADlib-from-Source)
    provides instructions to build MADlib from source. MADlib does not support Windows
    at the time of writing.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，MADlib 二进制文件仅适用于 Mac OS X 和 Red Hat/CentOS Linux。对于其他操作系统，[https://github.com/madlib/madlib/wiki/Building-MADlib-from-Source](https://github.com/madlib/madlib/wiki/Building-MADlib-from-Source)
    提供了从源代码构建 MADlib 的说明。截至写作时，MADlib 不支持 Windows。
- en: 'Before installing MADlib, ensure that the `plpython` module from PostgreSQL
    is installed. On Redhat/CentOS, run this command by substituting the package name
    with one that matches the version of PostgreSQL:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在安装 MADlib 之前，请确保已安装 PostgreSQL 的 `plpython` 模块。在 Redhat/CentOS 上，通过替换与 PostgreSQL
    版本匹配的包名来运行此命令：
- en: '[PRE27]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'On Mac OS X, check the documentation for your PostgreSQL installation method.
    For example, using Homebrew, the following command installs PostgreSQL with `plpython`
    support:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Mac OS X 上，检查您的 PostgreSQL 安装方法的文档。例如，使用 Homebrew，以下命令安装带有 `plpython` 支持的
    PostgreSQL：
- en: '[PRE28]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Once PostgreSQL has been set up with `plpython`, follow the instructions at
    [https://github.com/madlib/madlib/wiki/Installation-Guide](https://github.com/madlib/madlib/wiki/Installation-Guide)
    to install MADlib. The user account being used to install MADlib needs superuser
    privileges, which can be granted by running `ALTER ROLE ruser WITH SUPERUSER;`
    in PostgreSQL.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦使用 `plpython` 设置了 PostgreSQL，请按照 [https://github.com/madlib/madlib/wiki/Installation-Guide](https://github.com/madlib/madlib/wiki/Installation-Guide)
    中的说明安装 MADlib。用于安装 MADlib 的用户账户需要超级用户权限，这可以通过在 PostgreSQL 中运行 `ALTER ROLE ruser
    WITH SUPERUSER;` 来授予。
- en: 'Now, return to R and connect to PostgreSQL using the `RPostgreSQL` package:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，返回 R 并使用 `RPostgreSQL` 包连接到 PostgreSQL：
- en: '[PRE29]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Say we want to mine our sales database for association rules. As you can remember
    from [Chapter 6](ch06.html "Chapter 6. Simple Tweaks to Use Less RAM"), *Simple
    Tweaks to Use Less RAM*, the `arules` package provides functions to mine for frequent
    itemsets and association rules. In order to use the `arules` package, the entire
    `trans_items` table would need to be extracted into R and converted into a `transactions`
    object. If the dataset is large, this might take a long time, or might not be
    possible at all.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想要挖掘我们的销售数据库中的关联规则。正如你从[第6章](ch06.html "第6章。减少内存使用的小技巧")中记得的，《减少内存使用的小技巧》，`arules`包提供了挖掘频繁项集和关联规则的函数。为了使用`arules`包，整个`trans_items`表需要提取到R中并转换为`transactions`对象。如果数据集很大，这可能会花费很长时间，或者根本不可能完成。
- en: Alternatively, we can mine the association rules in the database using MADlib
    functions. The data does not need to be copied out of the database at all, and
    all the computations can take place in the database as long as the database server
    or cluster has sufficient capacity.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，我们可以使用MADlib函数在数据库中挖掘关联规则。数据根本不需要从数据库中复制出来，只要数据库服务器或集群有足够的容量，所有计算都可以在数据库中完成。
- en: 'Running the association rules mining algorithm is as simple as calling the
    `madlib.assoc_rules()` function in an SQL `SELECT` statement:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 运行关联规则挖掘算法就像在SQL `SELECT`语句中调用`madlib.assoc_rules()`函数一样简单：
- en: '[PRE30]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: The preceding code includes comments that describe the arguments to `madlib.assoc_rules()`.
    Here, the algorithm is asked to search for association rules with a support of
    at least 0.001 and confidence of at least 0.01\. The name of the input table and
    columns are specified, as well as the name of the schema in which you can store
    the results. In this case, the results will be stored in a table called `assoc_rules`
    in the `public` schema.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码中包含了描述`madlib.assoc_rules()`参数的注释。在这里，算法被要求搜索支持至少为0.001和置信度至少为0.01的关联规则。指定了输入表和列的名称，以及可以存储结果的模式的名称。在这种情况下，结果将存储在`public`模式中名为`assoc_rules`的表中。
- en: Every time the function is run, the `assoc_rules` table will be overwritten;
    so if you would like to keep a copy of the results, you will have to make a copy
    of the table.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 每次函数运行时，`assoc_rules`表将被覆盖；所以如果你想要保留结果的一个副本，你必须复制该表。
- en: 'Let''s retrieve the results, that is, the association rules that meet the minimum
    support and confidence:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检索结果，即满足最小支持和置信度的关联规则：
- en: '[PRE31]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: The results indicate the items on the left- and right-hand sides of each association
    rule, along with the statistics for each rule such as the support, confidence,
    lift, and conviction.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 结果表明每个关联规则左右两侧的项目，以及每个规则的统计数据，如支持、置信度、提升和确信度。
- en: Most of the other MADlib functions work in a similar way—data is supplied to
    a function in a database table, the function is called with the appropriate arguments,
    and the results are written to a new database table in the specified schema.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数其他MADlib函数以类似的方式工作——数据以数据库表的形式提供给函数，使用适当的参数调用函数，并将结果写入指定模式的新数据库表。
- en: Note
  id: totrans-114
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Because Pivotal, Inc. developed both the `PivotalR` package and MADlib, it is
    natural that `PivotalR` provides interfaces to some MADlib functions such as linear
    models, ARIMA time series models and decision trees. It also provides useful functions
    to extract information such as regression coefficients from the MADlib output.
    Unfortunately, `PivotalR` does not provide wrappers to all the MADlib functions
    such as the `madlib.assoc_rules()` function used in the preceding code. For maximum
    flexibility in using the MADlib library, use SQL statements to call the MADlib
    functions.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 因为Pivotal, Inc.开发了`PivotalR`包和MADlib，所以`PivotalR`自然提供了对一些MADlib函数的接口，例如线性模型、ARIMA时间序列模型和决策树。它还提供了从MADlib输出中提取信息的有用函数，例如回归系数。不幸的是，`PivotalR`并没有提供所有MADlib函数的包装器，例如前面代码中使用的`madlib.assoc_rules()`函数。为了在MADlib库中使用最大的灵活性，请使用SQL语句调用MADlib函数。
- en: In-database analytics libraries such as MADlib allow us to harness the power
    of advanced analytics in large databases and bring the results of the algorithms
    into R for further analysis and processing.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 像MADlib这样的数据库内分析库允许我们利用大型数据库中高级分析的力量，并将算法的结果带入R进行进一步分析和处理。
- en: Using columnar databases for improved performance
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用列式数据库提高性能
- en: Most relational databases use a row-based data storage architecture—the data
    is stored in the database row by row. Whenever the database performs a query,
    it retrieves the relevant rows for the query before processing the query. This
    architecture is well suited for business transactional uses, where complete records
    (that is, including all columns) are written, read, updated, or deleted, a few
    rows at a time. For most statistical or analytical use cases, however, many rows
    of data, often with only a few columns, need to be read. As a result, row-based
    databases are sometimes inefficient at analytical tasks because they read entire
    records at a time regardless of how many columns are actually needed for analysis.
    The following figure depicts how a row-based database might compute the sum of
    one column.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数关系型数据库使用基于行的数据存储架构——数据按行存储在数据库中。每当数据库执行查询时，它都会在处理查询之前检索查询相关的相关行。这种架构非常适合业务交易用途，其中完整的记录（即包括所有列）一次写入、读取、更新或删除。然而，对于大多数统计或分析用例，通常需要读取多行数据，通常只有少数列。因此，基于行的数据库在分析任务中有时效率不高，因为它们一次读取整个记录，而不管实际分析需要多少列。以下图展示了基于行的数据库如何计算一列的和。
- en: '![Using columnar databases for improved performance](img/9263OS_09_01.jpg)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![使用列式数据库提高性能](img/9263OS_09_01.jpg)'
- en: Computing the sum of one column in a row-based database
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在基于行的数据库中计算一列的和
- en: 'The increase in demand for data analysis platforms in recent years has led
    to the development of databases that use alternative storage architectures that
    are optimized for data analysis instead of business transactions. One such architecture
    is **columnar storage**. Columnar databases store data in columns instead of rows.
    This is very similar to R data frames where each column of a data frame is stored
    in a contiguous block of memory in the form of an R vector. When computing the
    sum of one column, a columnar database needs to read only one column of data,
    as shown in the following figure:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，对数据分析平台的需求增加导致了使用替代存储架构的数据库的发展，这些架构针对数据分析进行了优化，而不是针对业务交易。这种架构之一是**列式存储**。列式数据库按列存储数据，而不是按行存储。这与R数据框非常相似，其中数据框的每一列都存储在内存中的一个连续块中，形式为一个R向量。当计算一列的和时，列式数据库只需要读取一列数据，如下面的图所示：
- en: '![Using columnar databases for improved performance](img/9263OS_09_02.jpg)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![使用列式数据库提高性能](img/9263OS_09_02.jpg)'
- en: Computing the sum of one column in a columnar database
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在列式数据库中计算一列的和
- en: One example of a columnar database is MonetDB, which can be downloaded from
    [https://www.monetdb.org/Downloads](https://www.monetdb.org/Downloads). Follow
    the instructions there to install it. After installation, take the following steps
    to initialize and start the database.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 列式数据库的一个例子是MonetDB，可以从[https://www.monetdb.org/Downloads](https://www.monetdb.org/Downloads)下载。按照那里的说明进行安装。安装后，请按照以下步骤初始化并启动数据库。
- en: 'On Linux or Mac OS X, run the following commands in a terminal window:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在Linux或Mac OS X上，在终端窗口中运行以下命令：
- en: '[PRE32]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: On Windows, initialize and start the server by going to **Start** | **Programs**
    | **MonetDB** | **Start server**.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在Windows上，通过转到**开始** | **程序** | **MonetDB** | **启动服务器**来初始化和启动服务器。
- en: 'Because MonetDB is based on SQL, connecting to and working with MonetDB from
    R is similar to working with PostgreSQL. We can either execute SQL statements
    using the `MonetDB.R` CRAN package or use `dplyr`. For example, we can load the
    same sales and transaction data into MonetDB using `MonetDB.R`:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 由于MonetDB基于SQL，因此从R连接到MonetDB并与MonetDB一起工作与使用PostgreSQL类似。我们可以使用`MonetDB.R`
    CRAN包执行SQL语句或使用`dplyr`。例如，我们可以使用`MonetDB.R`将相同的产品销售和交易数据加载到MonetDB中：
- en: '[PRE33]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Now, let''s benchmark the query performance for the same SQL queries used in
    the `RPostgreSQL` examples:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们基准测试一下在`RPostgreSQL`示例中使用的相同SQL查询的查询性能：
- en: '[PRE34]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Compared to PostgreSQL, MonetDB took 55 percent less time for both queries (as
    you can remember from before that the median times needed by PostgreSQL for the
    first and second queries were 251.1 and 260.1 milliseconds, respectively). Of
    course, this is not a comprehensive or rigorous comparison between row-based and
    columnar databases, but it gives an indication of the performance gains that can
    be achieved by selecting the right database architecture for the task at hand.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 与 PostgreSQL 相比，MonetDB 在查询（如你之前所记得，PostgreSQL 对前两个查询的中位时间分别为 251.1 毫秒和 260.1
    毫秒）上节省了 55% 的时间。当然，这并不是行式数据库和列式数据库之间全面或严格的比较，但它表明，通过选择适合任务的正确数据库架构，可以实现性能的提升。
- en: Using array databases for maximum scientific-computing performance
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用数组数据库实现最大科学计算性能
- en: Columnar databases provide good query performance for datasets that resemble
    R data frames, for example, most data from business IT systems. These datasets
    are usually two dimensional and can contain heterogeneous data types. On the other
    hand, scientific data sometimes contain homogeneous data types but are multidimensional.
    An example of this is weather readings in different points in time and space.
    For such applications, a new type of database called the **array database** provides
    even better query and scientific computing performance. One example of this is
    SciDB, available for download at [http://www.scidb.org/](http://www.scidb.org/).
    `SciDB` provides a **massively parallel processing** (**MPP**) architecture that
    can perform queries in parallel on petabytes of array data. It supports in-database
    linear algebra, graph operations, linear models, correlations, and statistical
    tests. It also offers an R interface through the `SciDB` package that is available
    on CRAN.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 列式数据库为类似于 R 数据框的数据集提供了良好的查询性能，例如，大多数来自商业 IT 系统的数据。这些数据集通常是二维的，可以包含异构的数据类型。另一方面，科学数据有时包含同质的数据类型，但却是多维的。例如，不同时间和空间点的气象读数。对于此类应用，一种称为**数组数据库**的新类型数据库提供了更好的查询和科学计算性能。SciDB
    是一个例子，可在 [http://www.scidb.org/](http://www.scidb.org/) 下载。`SciDB` 提供了一个**大规模并行处理**（**MPP**）架构，可以在PB级的数组数据上并行执行查询。它支持数据库内线性代数、图操作、线性模型、相关性检验和统计检验。它还通过
    CRAN 上的 `SciDB` 软件包提供了一个 R 接口。
- en: To download and install SciDB, follow the instructions at [https://github.com/Paradigm4/deployment](https://github.com/Paradigm4/deployment).
    Then, install `shim` ([https://github.com/paradigm4/shim](https://github.com/paradigm4/shim))
    on the SciDB server, which is needed for R in order to communicate with SciDB.
    Finally, install the `scidb` package from CRAN.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 要下载和安装 SciDB，请遵循 [https://github.com/Paradigm4/deployment](https://github.com/Paradigm4/deployment)
    中的说明。然后，在 SciDB 服务器上安装 `shim` ([https://github.com/paradigm4/shim](https://github.com/paradigm4/shim))，这是
    R 与 SciDB 通信所需的。最后，从 CRAN 安装 `scidb` 软件包。
- en: 'Connect to the SciDB database using the `scidbconnect()` function:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `scidbconnect()` 函数连接到 SciDB 数据库：
- en: '[PRE35]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'We can then load some data into the database using `as.scidb()`:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以使用 `as.scidb()` 将一些数据加载到数据库中：
- en: '[PRE36]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '`scidb` provides familiar R syntax to manipulate SciDB matrices and arrays:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '`scidb` 提供了熟悉的 R 语法来操作 SciDB 矩阵和数组：'
- en: '[PRE37]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'We can even mix SciDB matrices/arrays with R matrices/arrays:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 我们甚至可以将 SciDB 矩阵/数组与 R 矩阵/数组混合使用：
- en: '[PRE38]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'As with the other database packages, operations are not actually performed
    until the results are retrieved. In the case of `SciDB`, the `[]` operator causes
    the database to perform the computations and return the results:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他数据库包一样，操作实际上只有在检索结果时才会执行。在 `SciDB` 的情况下，`[]` 操作符会导致数据库执行计算并返回结果：
- en: '[PRE39]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '`SciDB` supports many other common array/matrix operations such as subsetting,
    comparison, filtering, apply, joining, aggregation, and sorting. It is a powerful
    tool for working with large, multidimensional numerical data.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '`SciDB` 支持许多其他常见的数组/矩阵操作，如子集、比较、过滤、应用、连接、聚合和排序。它是处理大型、多维数值数据的有力工具。'
- en: Summary
  id: totrans-147
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we took a tour of various database systems and the R packages
    that allow us to interface with them, and saw how in-database querying and analysis
    can provide better performance than copying the data into R to do the same analysis.
    This is especially true for large datasets that cannot be easily processed in
    R; using a database that is tuned for querying and analysis can help to avoid
    performance issues in R. As technology improves, more and more advanced analysis
    and algorithms can be run in databases providing more options for R programmers
    who face the challenge of analyzing large datasets efficiently. These powerful
    data processing tools can complement R very nicely—they provide the computing
    muscle to analyze large datasets, while R provides easy interfaces for data manipulation
    and analysis. R can also help to bring together different threads of analyses,
    regardless of the tool used, to present a coherent and compelling picture of the
    data using tools such as data visualization.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们游览了各种数据库系统以及允许我们与之交互的 R 包，并看到了如何在数据库中进行查询和分析可以比将数据复制到 R 中进行相同分析提供更好的性能。这对于无法在
    R 中轻松处理的大型数据集来说尤其如此；使用针对查询和分析进行优化的数据库可以帮助避免 R 中的性能问题。随着技术的进步，越来越多的先进分析和算法可以在数据库中运行，为面对高效分析大型数据集挑战的
    R 程序员提供更多选择。这些强大的数据处理工具可以很好地补充 R——它们提供了分析大型数据集的计算力量，而 R 提供了易于操作和分析的接口。R 还可以帮助将不同的分析线索汇集在一起，无论使用什么工具，都可以使用数据可视化等工具来呈现一个连贯且引人入胜的数据图。
- en: In the next and final chapter, we will go to the frontiers of Big Data and take
    a look at how R can be used alongside Big Data tools to process extremely large
    datasets.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章和最后一章中，我们将进入大数据的前沿，看看 R 如何与大数据工具一起使用来处理极大规模的数据集。
