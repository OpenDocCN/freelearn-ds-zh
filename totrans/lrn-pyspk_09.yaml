- en: Chapter 9. Polyglot Persistence with Blaze
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Our world is complex and no single approach exists that solves all problems.
    Likewise, in the data world one cannot solve all problems with one piece of technology.
  prefs: []
  type: TYPE_NORMAL
- en: Nowadays, any big technology company uses (in one form or another) a MapReduce
    paradigm to sift through terabytes (or even petabytes) of data collected daily.
    On the other hand, it is much easier to store, retrieve, extend, and update information
    about products in a document-type database (such as MongoDB) than it is in a relational
    database. Yet, persisting transaction records in a relational database aids later
    data summarizing and reporting.
  prefs: []
  type: TYPE_NORMAL
- en: Even these simple examples show that solving a vast array of business problems
    requires adapting to different technologies. This means that you, as a database
    manager, data scientist, or data engineer, would have to learn all of these separately
    if you were to solve your problems with the tools that are designed to solve them
    easily. This, however, does not make your company agile and is prone to errors
    and lots of tweaking and hacking needing to be done to your system.
  prefs: []
  type: TYPE_NORMAL
- en: Blaze abstracts most of the technologies and exposes a simple and elegant data
    structure and API.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, you will learn:'
  prefs: []
  type: TYPE_NORMAL
- en: How to install Blaze
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What polyglot persistence is about
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to abstract data stored in files, pandas DataFrames, or NumPy arrays
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to work with archives (GZip)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to connect to SQL (PostgreSQL and SQLite) and No-SQL (MongoDB) databases
    with Blaze
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to query, join, sort, and transform the data, and perform simple summary
    statistics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Installing Blaze
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you run Anaconda it is easy to install Blaze. Just issue the following command
    in your CLI (see the Bonus [Chapter 1](ch01.html "Chapter 1. Understanding Spark"),
    *Installing Spark* if you do not know what a CLI is):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the command is issued, you will see a screen similar to the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Installing Blaze](img/B05793_09_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: We will later use Blaze to connect to the PostgreSQL and MongoDB databases,
    so we need to install some additional packages that Blaze will use in the background.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will install SQL Alchemy and PyMongo, both of which are part of Anaconda:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'All that is now left to do is to import Blaze itself in our notebook:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Polyglot persistence
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Neal Ford introduced the, somewhat similar, term polyglot programming in 2006\.
    He used it to illustrate the fact that there is no such thing as a one-size-fits-all
    solution and advocated using multiple programming languages that were more suitable
    for certain problems.
  prefs: []
  type: TYPE_NORMAL
- en: In the parallel world of data, any business that wants to remain competitive
    needs to adapt a range of technologies that allows it to solve the problems in
    a minimal time, thus minimizing the costs.
  prefs: []
  type: TYPE_NORMAL
- en: Storing transactional data in Hadoop files is possible, but makes little sense.
    On the other hand, processing petabytes of Internet logs using a **Relational
    Database Management System** (**RDBMS**) would also be ill-advised. These tools
    were designed to tackle specific types of tasks; even though they can be co-opted
    to solve other problems, the cost of adapting the tools to do so would be enormous.
    It is a virtual equivalent of trying to fit a square peg in a round hole.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, consider a company that sells musical instruments and accessories
    online (and in a network of shops). At a high-level, there are a number of problems
    that a company needs to solve to be successful:'
  prefs: []
  type: TYPE_NORMAL
- en: Attract customers to its stores (both virtual and physical).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Present them with relevant products (you would not try to sell a drum kit to
    a pianist, would you?!).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once they decide to buy, process the payment and organize shipping.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To solve these problems a company might choose from a number of available technologies
    that were designed to solve these problems:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Store all the products in a document-based database such as MongoDB, Cassandra,
    DynamoDB, or DocumentDB. There are multiple advantages of document databases:
    flexible schema, sharding (breaking bigger databases into a set of smaller, more
    manageable ones), high availability, and replication, among others.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Model the recommendations using a graph-based database (such as Neo4j, Tinkerpop/Gremlin,
    or GraphFrames for Spark): such databases reflect the factual and abstract relationships
    between customers and their preferences. Mining such a graph is invaluable and
    can produce a more tailored offering for a customer.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For searching, a company might use a search-tailored solution such as Apache
    Solr or ElasticSearch. Such a solution provides fast, indexed text searching capabilities.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once a product is sold, the transaction normally has a well-structured schema
    (such as product name, price, and so on.) To store such data (and later process
    and report on it) relational databases are best suited.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: With polyglot persistence, a company always chooses the right tool for the right
    job instead of trying to coerce a single technology into solving all of its problems.
  prefs: []
  type: TYPE_NORMAL
- en: Blaze, as we will see, abstracts these technologies and introduces a simple
    API to work with, so you do not have to learn the APIs of each and every technology
    you want to use. It is, in essence, a great working example of polyglot persistence.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To see how others do it, check out [http://www.slideshare.net/Couchbase/couchbase-at-ebay-2014](http://www.slideshare.net/Couchbase/couchbase-at-ebay-2014)
  prefs: []
  type: TYPE_NORMAL
- en: or
  prefs: []
  type: TYPE_NORMAL
- en: '[http://www.slideshare.net/bijoor1/case-study-polyglotpersistence-in-pharmaceutical-industry](https://www.slideshare.net/bijoor1/case-study-polyglot-persistence-in-pharmaceutical-industry).'
  prefs: []
  type: TYPE_NORMAL
- en: Abstracting data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Blaze can abstract many different data structures and expose a single, easy-to-use
    API. This helps to get a consistent behavior and reduce the need to learn multiple
    interfaces to handle data. If you know pandas, there is not really that much to
    learn, as the differences in the syntax are subtle. We will go through some examples
    to illustrate this.
  prefs: []
  type: TYPE_NORMAL
- en: Working with NumPy arrays
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Getting data from a NumPy array into the DataShape object of Blaze is extremely
    easy. First, let''s create a simple NumPy array: we first load NumPy and then
    create a matrix with two rows and three columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have an array, we can abstract it with Blaze''s DataShape structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: That's it! Simple enough.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to peek inside the structure you can use the .`peek()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see an output similar to what is shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Working with NumPy arrays](img/B05793_09_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: You can also use (familiar to those of you versed in pandas' syntax) the .`head(...)`
    method.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The difference between `.peek()` and `.head(...)` is that `.head(...)` allows
    the specification of the number of rows as its only parameter, whereas `.peek()`
    does not allow that and will always print the top 10 records.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want to retrieve the first column of your DataShape, you can use indexing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see a table, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Working with NumPy arrays](img/B05793_09_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'On the other hand, if you were interested in retrieving a row, all you would
    have to do (like in NumPy) is transpose your DataShape:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'What you will then get is presented in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Working with NumPy arrays](img/B05793_09_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Notice that the name of the column is `None`. DataShapes, just like pandas''
    DataFrames, support named columns. Thus, let''s specify the names of our fields:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Now you can retrieve the data simply by calling the column by its name:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'In return, you will get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Working with NumPy arrays](img/B05793_09_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, defining the fields transposes the NumPy array and, now, each
    element of the array forms a *row*, unlike when we first created the `simpleData_np`.
  prefs: []
  type: TYPE_NORMAL
- en: Working with pandas' DataFrame
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Since pandas' DataFrameinternally uses NumPy data structures, translating a
    DataFrame to DataShape is effortless.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let''s create a simple DataFrame. We start by importing pandas:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we create a DataFrame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'We then transform it into a DataShape:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'You can retrieve data in the same manner as with the DataShape created from
    the NumPy array. Use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, it will produce the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Working with pandas'' DataFrame](img/B05793_09_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Working with files
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A DataShape object can be created directly from a `.csv` file. In this example,
    we will use a dataset that consists of 404,536 traffic violations that happened
    in the Montgomery county of Maryland.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We downloaded the data from [https://catalog.data.gov/dataset/traffic-violations-56dda](https://catalog.data.gov/dataset/traffic-violations-56dda)
    on 8/23/16; the dataset is updated daily, so the number of traffic violations
    might differ if you retrieve the dataset at a later date.
  prefs: []
  type: TYPE_NORMAL
- en: 'We store the dataset in the `../Data` folder locally. However, we modified
    the dataset slightly so we could store it in the MongoDB: in its original form,
    with date columns, reading data back from MongoDB caused errors. We filed a bug
    with Blaze to fix this issue [https://github.com/blaze/blaze/issues/1580](https://github.com/blaze/blaze/issues/1580):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'If you do not know the names of the columns in any dataset, you can get these
    from the DataShape. To get a list of all the fields, you can use the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '![Working with files](img/B05793_09_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Those of you familiar with pandas would easily recognize the similarity between
    the `.fields` and `.columns` attributes, as these work in essentially the same
    way - they both return the list of columns (in the case of pandas DataFrame),
    or the list of fields, as columns are called in the case of Blaze DataShape.
  prefs: []
  type: TYPE_NORMAL
- en: 'Blaze can also read directly from a `GZipped` archive, saving space:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'To validate that we get exactly the same data, let''s retrieve the first two
    records from each structure. You can either call the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Or you can choose to call:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'It produces the same results (columns abbreviated here):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Working with files](img/B05793_09_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: It is easy to notice, however, that it takes significantly more time to retrieve
    the data from the archived file because Blaze needs to decompress the data.
  prefs: []
  type: TYPE_NORMAL
- en: You can also read from multiple files at one time and create one big dataset.
    To illustrate this, we have split the original dataset into four `GZipped` datasets
    by year of violation (these are stored in the `../Data/Years` folder).
  prefs: []
  type: TYPE_NORMAL
- en: 'Blaze uses `odo` to handle saving DataShapesto a variety of formats. To save
    `traffic` data for traffic violations by year you can call `odo` like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: The preceding instruction saves the data into a `GZip` archive, but you can
    save it to any of the formats mentioned earlier. The first argument to the `.odo(...)`
    method specifies the input object (in our case, the DataShapewith traffic violations
    that occurred in 2013), the second argument is the output object - the path to
    the file we want to save the data to. As we are about to learn - storing data
    is not limited to files only.
  prefs: []
  type: TYPE_NORMAL
- en: 'To read from multiple files you can use the asterisk character `*`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding snippet, once again, will produce a familiar table:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Working with files](img/B05793_09_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Blaze reading capabilities are not limited to `.csv` or `GZip` files only:
    you can read data from JSON or Excel files (both, `.xls` and `.xlsx`), HDFS, or
    bcolz formatted files.'
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To learn more about the bcolz format, check its documentation at [https://github.com/Blosc/bcolz](https://github.com/Blosc/bcolz).
  prefs: []
  type: TYPE_NORMAL
- en: Working with databases
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Blaze can also easily read from SQL databases such as PostgreSQL or SQLite.
    While SQLite would normally be a local database, the PostgreSQL can be run either
    locally or on a server.
  prefs: []
  type: TYPE_NORMAL
- en: Blaze, as mentioned earlier, uses `odo` in the background to handle the communication
    to and from the databases.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '`odo` is one of the requirements for Blaze and it gets installed along with
    the package. Check it out here [https://github.com/blaze/odo](https://github.com/blaze/odo).'
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to execute the code in this section, you will need two things: a running
    local instance of a PostgreSQL database, and a locally running MongoDB database.'
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In order to install PostgreSQL, download the package from [http://www.postgresql.org/download/](http://www.postgresql.org/download/)
    and follow the installation instructions for your operating system found there.
  prefs: []
  type: TYPE_NORMAL
- en: To install MongoDB, go to [https://www.mongodb.org/downloads](https://www.mongodb.org/downloads)
    and download the package; the installation instructions can be found here [http://docs.mongodb.org/manual/installation/](http://docs.mongodb.org/manual/installation/).
  prefs: []
  type: TYPE_NORMAL
- en: Before you proceed, we assume that you have a PostgreSQL database up and running
    at `http://localhost:5432/`, and MongoDB database running at `http://localhost:27017`.
  prefs: []
  type: TYPE_NORMAL
- en: We have already loaded the traffic data to both of the databases and stored
    them in the `traffic` table (PostgreSQL) or the `traffic` collection (MongoDB).
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If you do not know how to upload your data, I have explained this in my other
    book [https://www.packtpub.com/big-data-and-business-intelligence/practical-data-analysis-cookbook](https://www.packtpub.com/big-data-and-business-intelligence/practical-data-analysis-cookbook).
  prefs: []
  type: TYPE_NORMAL
- en: Interacting with relational databases
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let's read the data from the PostgreSQL database now. The **Uniform Resource
    Identifier** (**URI**) for accessing a PostgreSQL database has the following syntax
    `postgresql://<user_name>:<password>@<server>:<port>/<database>::<table>`.
  prefs: []
  type: TYPE_NORMAL
- en: 'To read the data from PostgreSQL, you just wrap the URI around `.Data(...)`
    - Blaze will take care of the rest:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: We use Python's `.format(...)` method to fill in the string with the appropriate
    data.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Substitute your credentials to access your PostgreSQL database in the previous
    example. If you want to read more about the `.format(...)` method, you can check
    out the Python 3.5 documentation [https://docs.python.org/3/library/string.html#format-string-syntax](https://docs.python.org/3/library/string.html#format-string-syntax).
  prefs: []
  type: TYPE_NORMAL
- en: 'It is quite easy to output the data to either the PostgreSQL or SQLite databases.
    In the following example, we will output traffic violations that involved cars
    manufactured in 2016 to both PostgreSQL and SQLite databases. As previously noted,
    we will use `odo` to manage the transfers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: In a similar fashion to pandas, to filter the data, we effectively select the
    `Year` column (the `traffic_psql['Year']` part of the first line) and create a
    Boolean flag by checking whether each and every record in that column equals `2016`.
    By indexing the `traffic_psql` object with such a truth vector, we extract only
    the records where the corresponding value equals `True`.
  prefs: []
  type: TYPE_NORMAL
- en: The two commented out lines should be uncommented if you already have the `traffic2016`
    tables in your databases; otherwise `odo` will append the data to the end of the
    table.
  prefs: []
  type: TYPE_NORMAL
- en: The URI for SQLite is slightly different than the one for PostgreSQL; it has
    the following syntax `sqlite://</relative/path/to/db.sqlite>::<table_name>`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Reading data from the SQLite database should be trivial for you by now:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Interacting with the MongoDB database
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'MongoDB has gained lots of popularity over the years. It is a simple, fast,
    and flexible document-based database. The database is a go-to storage solution
    for all full-stack developers, using the `MEAN.js` stack: M here stands for Mongo
    (see [http://meanjs.org](http://meanjs.org)).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Since Blaze is meant to work in a very familiar way no matter what your data
    source, reading from MongoDB is very similar to reading from PostgreSQL or SQLite
    databases:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Data operations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have already presented some of the most common methods you will use with
    DataShapes (for example, `.peek()`), and ways to filter the data based on the
    column value. Blaze has implemented many methods that make working with any data
    extremely easy.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will review a host of other commonly used ways of working
    with data and methods associated with them. For those of you coming from `pandas`
    and/or SQL, we will provide a respective syntax where equivalents exist.
  prefs: []
  type: TYPE_NORMAL
- en: Accessing columns
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are two ways of accessing columns: you can get a single column at a time
    by accessing them as if they were a DataShape attribute:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding script produces the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Accessing columns](img/B05793_09_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'You can also use indexing that allows the selection of more than one column
    at a time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'This generates the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Accessing columns](img/B05793_09_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The preceding syntax would be the same for pandas DataFrames. For those of
    you unfamiliar with Python and pandas API, please note three things here:'
  prefs: []
  type: TYPE_NORMAL
- en: 'To specify multiple columns, you need to enclose them in another list: note
    the double brackets `[[` and `]]`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'If the chain of all methods does not fit on one line (or you want to break
    the chain for better readability) you have two choices: either enclose the whole
    chain of methods in brackets `(...)` where the `...` is the chain of all methods,
    or, before breaking into the new line, put the backslash character `\` at the
    end of every line in the chain. We prefer the latter and will use that in our
    examples from now on.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Note that the equivalent SQL code would be:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Symbolic transformations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The beauty of Blaze comes from the fact that it can operate *symbolically*.
    What this means is that you can specify transformations, filters, or other operations
    on your data and store them as object(s). You can then *feed* such object with
    almost any form of data conforming to the original schema, and Blaze will return
    the transformed data.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, let''s select all the traffic violations that occurred in 2013,
    and return only the `''Arrest_Type''`, `''Color''`, and `` ''Charge` `` columns.
    First, if we could not reflect the schema from an already existing object, we
    would have to specify the schema manually. To do this, we will use the `.symbol(...)`
    method to achieve that; the first argument to the method specifies a symbolic
    name of the transformation (we prefer keeping it the same as the name of the object,
    but it can be anything), and the second argument is a long string that specifies
    the schema in a `<column_name>: <column_type>` fashion, separated by commas:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, you could use the `schema_example` object and specify some transformations.
    However, since we already have an existing `traffic` dataset, we can *reuse* the
    schema by using `traffic.dshape` and specifying our transformations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'To present how this works, let''s read the original dataset into pandas'' `DataFrame`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Once read, we pass the dataset directly to the `traffic_2013` object and perform
    the computation using the `.compute(...)` method of Blaze; the first argument
    to the method specifies the transformation object (ours is `traffic_2013`) and
    the second parameter is the data that the transformations are to be performed
    on:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the output of the preceding snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Symbolic transformations](img/B05793_09_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'You can also pass a list of lists or a list of NumPy arrays. Here, we use the
    `.values` attribute of the DataFrame to access the underlying list of NumPy arrays
    that form the DataFrame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'This code will produce precisely what we would expect:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Symbolic transformations](img/B05793_09_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Operations on columns
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Blaze allows for easy mathematical operations to be done on numeric columns.
    All the traffic violations cited in the dataset occurred between 2013 and 2016\.
    You can check that by getting all the distinct values for the `Stop_year` column
    using the `.distinct()` method. The `.sort()` method sorts the results in an ascending
    order:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code produces the following output table:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Operations on columns](img/B05793_09_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'An equivalent syntax for pandas would be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'For SQL, use the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'You can also make some mathematical transformations/arithmetic to the columns.
    Since all the traffic violations occurred after year `2000`, we can subtract `2000`
    from the `Stop_year` column without losing any accuracy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is what you should get in return:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Operations on columns](img/B05793_09_15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The same could be attained from pandas `DataFrame` with an identical syntax
    (assuming `traffic` was of pandas `DataFrame` type). For SQL, the equivalent would
    be:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: However, if you want to do some more complex mathematical operations (for example,
    `log` or `pow`) then you first need to use the one provided by Blaze (that, in
    the background, will translate your command to a suitable method from NumPy, math,
    or pandas).
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, if you wanted to log-transform the `Stop_year` you need to use
    this code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'This will produce the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Operations on columns](img/B05793_09_16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Reducing data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Some reduction methods are also available, such as `.mean()` (that calculates
    the average), `.std` (that calculates standard deviation), or `.max()` (that returns
    the maximum from the list). Executing the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'It will return the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Reducing data](img/B05793_09_17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'If you had a pandas DataFrame you can use the same syntax, whereas for SQL
    the same could be done with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: It is also quite easy to add more columns to your dataset. Say, you wanted to
    calculate the age of the car (in years) at the time when the violation occurred.
    First, you would take the `Stop_year` and subtract the `Year` of manufacture.
  prefs: []
  type: TYPE_NORMAL
- en: In the following code snippet, the first argument to the `.transform(...)` method
    is the DataShape, the transformation is to be performed on, and the other(s) would
    be a list of transformations.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the source code of the `.transform(...)` method such lists would be expressed
    as `*args` as you could specify more than one column to be created in one go.
    The `*args` argument to any method would take any number of subsequent arguments
    and treat it as if it was a list.
  prefs: []
  type: TYPE_NORMAL
- en: 'The above code produces the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Reducing data](img/B05793_09_18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'An equivalent operation in pandas could be attained through the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'For SQL you can use the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'If you wanted to calculate the average age of the car involved in a fatal traffic
    violation and count the number of occurrences, you can perform a `group by` operation
    using the `.by(...)` operation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: The first argument to `.by(...)` specifies the column of the DataShape to perform
    the aggregation by, followed by a series of aggregations we want to get. In this
    example, we select the `Age_of_car` column and calculate an average and count
    the number of rows per each value of the `'Fatal'` column.
  prefs: []
  type: TYPE_NORMAL
- en: 'The preceding script produces the following aggregation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Reducing data](img/B05793_09_19.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'For pandas, an equivalent would be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'For SQL, it would be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: Joins
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Joining two `DataShapes` is straightforward as well. To present how this is
    done, although the same result could be attained differently, we first select
    all the traffic violations by violation type (the `violation` object) and the
    traffic violations involving belts (the `belts` object):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: Now, we join the two objects on the six date and time columns.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The same effect could have been attained if we just simply selected the two
    columns: `Violation_type` and `Belts` in one go. However, this example is to show
    the mechanics of the `.join(...)` method, so bear with us.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The first argument to the `.join(...)` method is the first DataShape we want
    to join with, the second argument is the second DataShape, while the third argument
    can be either a single column or a list of columns to perform the join on:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Once we have the full dataset in place, let''s check how many traffic violations
    involved belts and what sort of punishment was issued to the driver:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'Here''s the output of the preceding script:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Joins](img/B05793_09_20.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The same could be achieved in pandas with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'With SQL, you would use the following snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The concepts presented in this chapter are just the beginning of the road to
    using Blaze. There are many other ways it can be used and data sources it can
    connect with. Treat this as a starting point to build your understanding of polyglot
    persistence.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note, however, that these days most of the concepts explained in this chapter
    can be attained natively within Spark, as you can use SQLAlchemy directly within
    Spark making it easy to work with a variety of data sources. The advantage of
    doing so, despite the initial investment of learning the API of SQLAlchemy, is
    that the data returned will be stored in a Spark DataFrame and you will have access
    to everything that PySpark has to offer. This, by no means, implies that you never
    should never use Blaze: the choice, as always, is yours.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next chapter, you will learn about streaming and how to do it with Spark.
    Streaming has become an increasingly important topic these days, as, daily (true
    as of 2016), the world produces roughly 2.5 exabytes of data (source: [http://www.northeastern.edu/levelblog/2016/05/13/how-much-data-produced-every-day/](http://www.northeastern.edu/levelblog/2016/05/13/how-much-data-produced-every-day/))
    that need to be ingested, processed and made sense of.'
  prefs: []
  type: TYPE_NORMAL
