<html><head></head><body><div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Python and Elevation Data</h1>
                </header>
            
            <article>
                
<p class="mce-root">Elevation data is one of the most fascinating types of geospatial data. It represents many different types of data sources and formats. It can display properties of both vector and raster data, resulting in unique data products. Elevation data can be used for terrain visualization, land cover classification, hydrology modeling, transportation routing, feature extraction, and many other purposes.</p>
<p class="mce-root">You can't perform all of these options with both raster and vector data, but since elevation data is three-dimensional, due to containing <em>x</em>, <em>y</em>, and <em>z</em> coordinates, you can often get more out of this data than any other type.</p>
<p class="mce-root">In this chapter, we will cover the following topics:</p>
<ul>
<li>Using ASCII Grid elevation data files for simple elevation processing</li>
<li>Creating shaded relief images</li>
<li>Creating elevation contours</li>
<li>Gridding the LIDAR data</li>
<li>Creating a 3D mesh</li>
</ul>
<p>In this chapter, you will learn how to read and write elevation data in both raster and vector formats. We'll also create some derivative products.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Accessing ASCII Grid files</h1>
                </header>
            
            <article>
                
<p>For most of this chapter, we'll use ASCII Grid files, or ASCIIGRID. These files are a type of raster data that's usually associated with elevation data. This grid format stores data as text in equal-sized square rows and columns with a simple header. Each cell in a row/column stores a single numeric value, which can represent some feature of terrain, such as elevation, slope, or flow direction. The simplicity makes it an easy-to-use and platform-independent raster format. This format is described in the <em>ASCII Grids</em> section of <a href="a7a60707-fb99-41d3-959c-7ed43a469c55.xhtml">Chapter 2</a>, <em>Learning Geospatial Data</em>.</p>
<p class="mce-root"/>
<p>Throughout this book, we've relied on GDAL, and to some extent, even PIL, to read and write geospatial raster data, including the <kbd>gdalnumeric</kbd> module, so that we can load raster data into NumPy arrays. ASCII Grid allows us to read and write rasters using only Python or even NumPy because it is simple plain text.</p>
<div class="packt_tip">As a reminder, some elevation datasets use image formats to store elevation data. Most image formats only support 8-bit values ranging from between 0 to 255; however, some formats, including TIFF, can store larger values.<br/>
<br/>
Geospatial software can typically display these datasets; however, traditional image software and libraries usually don't. For simplicity, in this chapter, we'll mostly stick to the ASCII Grid format for data, which is both human and machine-readable, as well as widely supported.</div>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Reading grids</h1>
                </header>
            
            <article>
                
<p>NumPy has the ability to read the ASCII Grid format directly using its <kbd>loadtxt()</kbd> method, which is designed to read arrays from text files. The first six lines consist of the header, which is not a part of the array. The following lines are a sample of a grid header:</p>
<pre>ncols 250<br/>nrows 250<br/>xllcorner 277750.0<br/>yllcorner 6122250.0<br/>cellsize 1.0<br/>NODATA_value -9999</pre>
<p>Let's look at what each line in the preceding code contains:</p>
<ul>
<li>Line 1 contains the number of columns in the grid, which is synonymous with the <em>x </em>axis.</li>
<li>Line 2 represents the <em>y </em>axis as a number of rows.</li>
<li>Line 3 represents the <em>x</em> coordinate of the lower-left corner, which is the minimum <em>x</em> value in meters.</li>
<li>Line 4 is the corresponding minimum <em>y</em> value in the lower-left corner of the grid.</li>
<li>Line 5 is the cell size or resolution of the raster. As the cells are square, only one size value is needed, as opposed to the separate <em>x</em> and <em>y</em> resolution values in most geospatial rasters.</li>
<li>Line 6 is <kbd>NODATA_value</kbd>, which is a number that's assigned to any cell for which a value is not provided.</li>
</ul>
<p class="mce-root"/>
<p>Geospatial software ignores these cells for calculations and often allows special display settings for it, such as making them black or transparent. The <kbd>-9999</kbd> value is a common no data placeholder value that's used in the industry and is easy to detect in software but can be arbitrarily selected. Elevation with negative values (that is, bathymetry) may have valid data at <kbd>-9999</kbd> meters, for instance, and may select <kbd>9999</kbd> or other values. As long as this value is defined in the header, most software will have no issues. In some examples, we'll use the number zero; however, zero can often also be a valid data value.</p>
<p class="mce-root">The <kbd>numpy.loadtxt()</kbd> method includes an argument called <kbd>skiprows</kbd>, which allows you to specify the number of lines in the file to be skipped before reading the array values.</p>
<div class="mce-root packt_infobox">To try out this technique, you can download a sample grid file called <kbd>myGrid.asc</kbd> from <a href="http://git.io/vYapU">http://git.io/vYapU</a>.</div>
<p class="mce-root">So, for <kbd>myGrid.asc</kbd>, we would use the following code:</p>
<pre>myArray  = numpy.loadtxt("myGrid.asc", skiprows=6)</pre>
<p>This line results in the <kbd>myArray</kbd> variable containing a <kbd>numpy</kbd> array derived from the ASCIIGRID <kbd>myGrid.asc</kbd> file. The ASC filename extension is used by the ASCIIGRID format. This code works great, but there's one problem. NumPy allows us to skip the header but not keep it. We need to keep this so that we have a spatial reference for our data. We will also use it to save this grid or create a new one.</p>
<p>To solve this problem, we'll use Python's built-in <kbd>linecache</kbd> module to grab the header. We could open the file, loop through the lines, store each one in a variable, and then close the file. However, <kbd>linecache</kbd> reduces the solution to a single line. The following line reads the first line in the file to a variable called <kbd>line1</kbd>:</p>
<pre>import linecache<br/>line1 = linecache.getline("myGrid.asc", 1)</pre>
<p>In the examples in this chapter, we'll use this technique to create a simple header processor that can parse these headers into Python variables in just a few lines. Now that we know how to read grids, let's learn how to write them.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Writing grids</h1>
                </header>
            
            <article>
                
<p>Writing grids in NumPy is just as easy as reading them. We use the corresponding <kbd>numpy.savetxt()</kbd> function to save a grid to a text file. The only catch is that we must build and add the six lines of header information before we dump the array to the file. This process is slightly different for different versions of NumPy. In either case, you build the header as a string first. If you are using NumPy 1.7 or later, the <kbd>savetext()</kbd> method has an optional argument called header that lets you specify a string as an argument. You can quickly check your NumPy version from the command line using the following command:</p>
<pre><strong>python -c "import numpy;print(numpy.__version__)"</strong><br/><strong>1.8.2</strong></pre>
<p>The backward-compatible method is to open a file, write the header, and then dump the array. Here is a sample of the version 1.7 approach to save an array called <kbd>myArray</kbd> to an ASCIIGRID file called <kbd>myGrid.asc</kbd>:</p>
<pre>header = "ncols {}\n".format(myArray.shape[1])<br/>header += "nrows {}\n".format(myArray.shape[0])<br/>header += "xllcorner 277750.0\n"<br/>header += "yllcorner 6122250.0\n"<br/>header += "cellsize 1.0\n"<br/>header += "NODATA_value -9999"<br/>numpy.savetxt("myGrid.asc", myArray, header=header, fmt="%1.2f")</pre>
<p>We make use of Python format strings, which allow you to put placeholders in a string to format the Python objects to be inserted. The <kbd>{}</kbd> format variable turns the object you refer to into a string. In this case, we are referencing the number of columns and rows in the array.</p>
<p>In NumPy, an array has two properties:</p>
<ul>
<li>Size: It returns an integer for the number of values in the array.</li>
<li>Shape: It returns a tuple with the number of rows and columns, respectively.</li>
</ul>
<p>So, in the preceding example, we use the shape property tuple to add the row and column counts to the header of our ASCII Grid. Notice that we also add a trailing newline character for each line (<kbd>\n</kbd>). There is no reason to change the <kbd>x</kbd> and <kbd>y</kbd> values, cell size, or no data value unless we altered them in the script.</p>
<p class="mce-root"/>
<p>The <kbd>savetxt()</kbd> method also has an <kbd>fmt</kbd> argument, which allows you to use Python format strings to specify how the array values are written. In this case, the <kbd>%1.2f</kbd> value specifies floats with at least one number and no more than two decimal places. The backward-compatible version for NumPy, before 1.6, builds the header string in the same way but creates the file handle first:</p>
<pre>with open("myGrid.asc", "w") as f:<br/> f.write(header)<br/> numpy.savetxt(f, str(myArray), fmt="%1.2f")</pre>
<p>As you'll see in the upcoming examples, this ability to produce valid geospatial data files using only NumPy is quite powerful. In the next couple of examples, we'll be using an ASCIIGRID <strong>Digital Elevation Model</strong> (<strong>DEM</strong>) of a mountainous area near Vancouver, British Columbia, in Canada.</p>
<div class="packt_infobox">You can download this sample as a ZIP file at the following URL: <a href="http://git.io/vYwUX">http://git.io/vYwUX</a>.</div>
<p>The following image is the raw DEM that was colorized using QGIS with a color ramp that makes the lower elevation values dark blue and higher elevation values bright red:</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/b4b05e96-fcba-439e-997b-c3c0fff3bf8b.png" style="width:29.08em;height:23.00em;" width="695" height="550"/></p>
<p>While we can conceptually understand the data in this way, it is not an intuitive way to visualize the data. Let's see if we can do better by creating a shaded relief.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Creating a shaded relief</h1>
                </header>
            
            <article>
                
<p>Shaded relief maps color elevation in such a way that it looks as if the terrain is cast in a low angle light, which creates bright spots and shadows. This aesthetic styling creates an almost photographic illusion, which is easy to grasp so that we can understand the variation in the terrain. It is important to note that this style is truly an illusion as the light is often physically inaccurate in terms of the solar angle, and the elevation is usually exaggerated to increase contrast.</p>
<p class="mce-root">In this example, we'll use the ASCII DEM we referenced previously to create another grid that represents a shaded relief version of the terrain in NumPy. This terrain is quite dynamic, so we won't need to exaggerate the elevation; however, the script has a variable called <kbd>z</kbd>, which can be increased from 1.0 to scale the elevation up.</p>
<p class="mce-root">After we have defined all the variables, including the input and output filenames, we'll see the header parser based on the <kbd>linecache</kbd> module, which also uses a Python list comprehension to loop and parse the lines that are then split from a list into six variables. We also create a <kbd>y</kbd> cell size called <kbd>ycell</kbd>, which is just the inverse of the cell size by convention. If we don't do this, the resulting grid will be transposed.</p>
<div class="mce-root packt_tip">Note that we define filenames for slope and aspect grids, which are two intermediate products that are combined to create the final product. These intermediate grids are output as well. They can also serve as inputs to other types of products.</div>
<p class="mce-root">This script uses a three-by-three windowing method to scan the image and smooth out the center value in these mini-grids to process the image efficiently. It does so within the memory constraints of your computer. However, because we are using NumPy, we can process the entire array at once via matrices, as opposed to using a lengthy series of nested loops. This technique is based on the excellent work of a developer named Michal Migurski, who implemented the clever NumPy version of Matthew Perry's C++ implementation, which served as the basis for the DEM tools in the GDAL suite.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root">After the slope and aspect have been calculated, they are used to output the shaded relief. The slope is the steepness of a hill or mountain, while the aspect is the direction the grid cell faces that is specified as a degree between 0 and 360. Finally, everything is saved to the disk from NumPy. In the <kbd>savetxt()</kbd> method, we specify a four-integer format string as the peak elevations are several thousand meters:</p>
<ol>
<li>First, we'll import the <kbd>linecache</kbd> module to parse the header and the <kbd>numpy</kbd> module to do the processing:</li>
</ol>
<pre style="padding-left: 60px">from linecache import getline<br/>import numpy as np</pre>
<ol start="2">
<li>Next, we'll set up all of the variable names that will define how the shaded relief is processed:</li>
</ol>
<pre style="padding-left: 60px"># File name of ASCII digital elevation model<br/>source = "dem.asc"<br/><br/># File name of the slope grid<br/>slopegrid = "slope.asc"<br/><br/># File name of the aspect grid<br/>aspectgrid = "aspect.asc"<br/><br/># Output file name for shaded relief<br/>shadegrid = "relief.asc"<br/><br/># Shaded elevation parameters<br/># Sun direction<br/>azimuth = 315.0<br/><br/># Sun angle<br/>altitude = 45.0<br/><br/># Elevation exageration<br/>z = 1.0<br/><br/># Resolution<br/>scale = 1.0<br/><br/># No data value for output<br/>NODATA = -9999<br/><br/># Needed for numpy conversions<br/>deg2rad = 3.141592653589793 / 180.0<br/>rad2deg = 180.0 / 3.141592653589793</pre>
<p class="mce-root"/>
<ol start="3">
<li>Now that our variables are set up, we can parse the header:</li>
</ol>
<pre style="padding-left: 60px"># Parse the header using a loop and<br/># the built-in linecache module<br/>hdr = [getline(source, i) for i in range(1, 7)]<br/>values = [float(h.split(" ")[-1].strip()) for h in hdr]<br/>cols, rows, lx, ly, cell, nd = values<br/>xres = cell<br/>yres = cell * -1</pre>
<ol start="4">
<li>Next, we can load the actual data using <kbd>numpy</kbd> by skipping the header portion:</li>
</ol>
<pre style="padding-left: 60px"># Load the dem into a numpy array<br/>arr = np.loadtxt(source, skiprows=6)</pre>
<ol start="5">
<li>We're going to loop through the data, row by row, column by column, to process it. Please note, however, that we're going to skip the outer edges that contain nodata values. We'll break the data into smaller grids of 3 x 3 pixels as we go because for each grid cell, we need to see the cells surrounding it:</li>
</ol>
<pre style="padding-left: 60px"># Exclude 2 pixels around the edges which are usually NODATA.<br/># Also set up structure for 3 x 3 windows to process the slope<br/># throughout the grid<br/>window = []<br/>for row in range(3):<br/> for col in range(3):<br/> window.append(arr[row:(row + arr.shape[0] - 2),<br/> col:(col + arr.shape[1] - 2)])<br/><br/># Process each 3x3 window in both the x and y directions<br/>x = ((z * window[0] + z * window[3] + z * window[3] + z * <br/> window[6]) -<br/> (z * window[2] + z * window[5] + z * window[5] + z * <br/> window[8])) / \<br/> (8.0 * xres * scale)<br/>y = ((z * window[6] + z * window[7] + z * window[7] + z * <br/> window[8]) -<br/> (z * window[0] + z * window[1] + z * window[1] + z * <br/> window[2])) / \<br/> (8.0 * yres * scale)</pre>
<ol start="6">
<li>For each 3 x 3 mini-window, we'll calculate <kbd>slope</kbd>, <kbd>aspect</kbd>, and then the <kbd>shaded</kbd> relief value:</li>
</ol>
<pre style="padding-left: 60px"># Calculate slope<br/>slope = 90.0 - np.arctan(np.sqrt(x * x + y * y)) * rad2deg<br/><br/># Calculate aspect<br/>aspect = np.arctan2(x, y)<br/><br/># Calculate the shaded relief<br/>shaded = np.sin(altitude * deg2rad) * np.sin(slope * deg2rad) + \<br/> np.cos(altitude * deg2rad) * np.cos(slope * deg2rad) * \<br/> np.cos((azimuth - 90.0) * deg2rad - aspect)</pre>
<ol start="7">
<li>Next, we need to scale each value between 0-255 so that it can be viewed as an image:</li>
</ol>
<pre style="padding-left: 60px"># Scale values from 0-1 to 0-255<br/>shaded = shaded * 255</pre>
<ol start="8">
<li>Now, we have to rebuild our header since we have ignored the outer edge of the nodata values and our dataset is smaller:</li>
</ol>
<pre style="padding-left: 60px"># Rebuild the new header<br/>header = "ncols {}\n".format(shaded.shape[1])<br/>header += "nrows {}\n".format(shaded.shape[0])<br/>header += "xllcorner {}\n".format(lx + (cell * (cols - <br/> shaded.shape[1])))<br/>header += "yllcorner {}\n".format(ly + (cell * (rows - <br/> shaded.shape[0])))<br/>header += "cellsize {}\n".format(cell)<br/>header += "NODATA_value {}\n".format(NODATA)</pre>
<ol start="9">
<li>Next, we'll set any nodata values to the chosen nodata values we set in our variables at the beginning:</li>
</ol>
<pre style="padding-left: 60px"><br/># Set no-data values<br/>for pane in window:<br/> slope[pane == nd] = NODATA<br/> aspect[pane == nd] = NODATA<br/> shaded[pane == nd] = NODATA</pre>
<ol start="10">
<li>We're going to save the slope and aspect grids separately so that we can view them later and understand how the shaded relief is created:</li>
</ol>
<pre style="padding-left: 60px"># Open the output file, add the header, save the slope grid<br/>with open(slopegrid, "wb") as f:<br/> f.write(bytes(header, "UTF-8")<br/> np.savetxt(f, slope, fmt="%4i")<br/><br/># Open the output file, add the header, save the aspectgrid<br/>with open(aspectgrid, "wb") as f:<br/> f.write(bytes(header, "UTF-8")<br/> np.savetxt(f, aspect, fmt="%4i")<br/><br/># Open the output file, add the header, save the relief grid<br/>with open(shadegrid, "wb") as f:<br/> f.write(bytes(header, 'UTF-8'))<br/> np.savetxt(f, shaded, fmt="%4i")</pre>
<p>If we load the output shaded relief grid to QGIS and specify the styling to stretch the image to the minimum and maximum values, we will see the following image:</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/434d4a94-9cb0-40c3-8a26-e68b5fe64578.png" style="width:28.83em;height:22.83em;" width="800" height="632"/></p>
<p><span>If QGIS asks you for a projection, the data is EPSG:3157. You can also open the image in the FWTools OpenEV application we discussed in the </span><em>Installing GDAL</em><span> section of <a href="ff05aa7d-3aac-40b6-b857-e6bf08498141.xhtml">Chapter 4</a>, </span><em>Geospatial Python Toolbox</em><span>, which will automatically stretch the image for optimal viewing.</span></p>
<p>As you can see, the preceding image is much easier to comprehend than the pseudo-color representation that we examined originally. Next, let's look at the slope raster that's used to create the shaded relief:</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/002cba26-ba39-4576-81a7-9b1e12c4ee24.png" style="width:28.00em;height:22.08em;" width="800" height="632"/></p>
<p>The slope shows the gradual decline in elevation from the high points to low points in all the directions of the dataset. The slope is an especially useful input for many types of hydrology models:</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/b66eef10-cf96-4450-ac6d-1ae41e627e4f.png" style="width:29.08em;height:22.92em;" width="800" height="632"/></p>
<p>The aspect shows the maximum rate of a downslope change from one cell to its neighbors. If you compare the aspect image to the shaded relief image, you will see that the red and gray values of the aspect image correspond to shadows in the shaded relief. So, the slope is primarily responsible for turning the DEM into a terrain relief while the aspect is responsible for shading.</p>
<p class="mce-root">Now that we can display the data in a useful way, let's see if we can also create other data from it.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Creating elevation contours</h1>
                </header>
            
            <article>
                
<p><span> A contour is an isoline along the same elevation in a dataset. Contours are usually stepped at intervals to create an intuitive way to represent elevation data, both visually and numerically, using a resource-efficient vector dataset. </span>Now, let's look at another way to visualize the elevation better using contours.</p>
<p>The input is used to generate contours in our DEM and the output is a shapefile. The algorithm (Marching Squares: <a href="https://en.wikipedia.org/wiki/Marching_squares">https://en.wikipedia.org/wiki/Marching_squares</a>) that's used to generate contours is fairly complex and very difficult to implement using NumPy's linear algebra. In this case, our solution is to fall back on the GDAL library, which has a contouring method available through the Python API. In fact, the majority of this script is just setting up the OGR library code that is needed to output a shapefile. The actual contouring is a single method call named <kbd>gdal.ContourGenerate()</kbd>. Just before this call, there are comments that define the method's arguments. The most important ones are as follows:</p>
<ul>
<li><kbd>contourInterval</kbd>: This is the distance in the dataset units between contours.</li>
<li><kbd>contourBase</kbd>: This is the starting elevation for the contouring.</li>
<li><kbd>fixedLevelCount</kbd>: This specifies a fixed number of contours as opposed to distance.</li>
<li><kbd>idField</kbd>: This is the name for a required shapefile <kbd>dbf</kbd> field, usually just called ID.</li>
<li><kbd>elevField</kbd>: This is the name for a required shapefile <kbd>dbf</kbd> field for the elevation value and is useful for labeling in maps.</li>
</ul>
<p class="mce-root"/>
<p class="mce-root"/>
<p>You should have GDAL and OGR installed from the <em>Installing GDAL</em> section of <a href="ff05aa7d-3aac-40b6-b857-e6bf08498141.xhtml">Chapter 4</a>, <em>Geospatial Python Toolbox</em>. We will be implementing the following steps:</p>
<ol>
<li>First, we will define the input DEM filename.</li>
<li>Then, we will output the shapefile's name.</li>
<li>Next, we'll create the shapefile data source with OGR.</li>
<li>Then, we'll get the OGR layer.</li>
<li>Next, we'll open the DEM.</li>
<li>Finally, we'll generate contours on the OGR layer.</li>
</ol>
<p>Let's look at a code representation of the preceding steps:</p>
<ol>
<li>First, we load in the <kbd>gdal</kbd> and <kbd>ogr</kbd> libraries to handle the data:</li>
</ol>
<pre style="padding-left: 60px">import gdal<br/>import ogr</pre>
<ol start="2">
<li>Then we'll set up a variable for our filename:</li>
</ol>
<pre style="padding-left: 60px"># Elevation DEM<br/>source = "dem.asc"</pre>
<ol start="3">
<li>Next, we'll create the beginnings of our output shapefile using OGR:</li>
</ol>
<pre style="padding-left: 60px"># Output shapefile<br/>target = "contour"<br/>ogr_driver = ogr.GetDriverByName("ESRI Shapefile")<br/>ogr_ds = ogr_driver.CreateDataSource(target + ".shp")<br/>ogr_lyr = ogr_ds.CreateLayer(target, <br/># wkbLineString25D is the type code for geometry with a z <br/># elevation value.<br/>geom_type=ogr.wkbLineString25D)<br/>field_defn = ogr.FieldDefn("ID" ogr.OFTInteger)<br/>ogr_lyr.CreateField(field_defn)<br/>field_defn = ogr.FieldDefn("ELEV" ogr.OFTReal)<br/>ogr_lyr.CreateField(field_defn)</pre>
<ol start="4">
<li>Then, we'll create some contours:</li>
</ol>
<pre style="padding-left: 60px"># gdal.ContourGenerate() arguments<br/># Band srcBand,<br/># double contourInterval,<br/># double contourBase,<br/># double[] fixedLevelCount,<br/># int useNoData,<br/># double noDataValue,<br/># Layer dstLayer,<br/># int idField,<br/># int elevField<br/>ds = gdal.Open(source)<br/><br/># EPGS:3157<br/>gdal.ContourGenerate(ds.GetRasterBand(1), 400, 10, [], 0, 0, ogr_lyr, 0, 1))<br/>ogr_ds = None</pre>
<ol start="5">
<li>Now, let's draw the contour shapefile that we just created using <kbd>pngcanvas</kbd>, which we introduced in the <em>PNGCanvas</em> section of <a href="ff05aa7d-3aac-40b6-b857-e6bf08498141.xhtml">Chapter 4</a>, <em>Geospatial Python Toolbox</em>:</li>
</ol>
<pre style="padding-left: 60px">import shapefile<br/>import pngcanvas<br/><br/># Open the contours<br/>r = shapefile.Reader("contour.shp")<br/><br/># Setup the world to pixels conversion<br/>xdist = r.bbox[2] - r.bbox[0]<br/>ydist = r.bbox[3] - r.bbox[1]<br/>iwidth = 800<br/>iheight = 600<br/>xratio = iwidth/xdist<br/>yratio = iheight/ydist<br/>contours = []<br/><br/># Loop through all shapes<br/>for shape in r.shapes():<br/> # Loop through all parts<br/> for i in range(len(shape.parts)):<br/>   pixels = []<br/>   pt = None<br/>   if i &lt; len(shape.parts) - 1:<br/>     pt = shape.points[shape.parts[i]:shape.parts[i+1]]<br/>   else:<br/>     pt = shape.points[shape.parts[i]:]<br/>   for x, y in pt:<br/>     px = int(iwidth - ((r.bbox[2] - x) * xratio))<br/>     py = int((r.bbox[3] - y) * yratio)<br/>     pixels.append([px, py])<br/>     contours.append(pixels)<br/><br/># Set up the output canvas<br/>canvas = pngcanvas.PNGCanvas(iwidth, iheight)<br/><br/># PNGCanvas accepts rgba byte arrays for colors<br/>red = [0xff, 0, 0, 0xff]<br/>canvas.color = red<br/><br/># Loop through the polygons and draw them<br/>for c in contours:<br/> canvas.polyline(c)<br/><br/># Save the image<br/>with open("contours.png", "wb") as f:<br/> f.write(canvas.dump())</pre>
<p>We will end up with the following image:</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/14574f31-967d-4cca-9b84-6e736de46bfb.png" style="width:35.00em;height:26.25em;" width="800" height="600"/></p>
<p>If we bring our shaded relief ASCIIGRID and the shapefile into a GIS, such as QGIS, we can create a simple topographic map, as follows. You can use the elevation (that is, <kbd>ELEV</kbd>) <kbd>dbf</kbd> field that you specified in the script to label the contour lines with the elevation:</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/7b38f255-5d58-429a-9418-584fe4c923dc.png" style="width:32.50em;height:26.75em;" width="677" height="557"/></p>
<p>The techniques that were used in these NumPy grid examples provide the building blocks for all kinds of elevation products. Next, we'll work with one of the most complex elevation data types: LIDAR data.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Working with LIDAR data</h1>
                </header>
            
            <article>
                
<p><strong>LIDAR</strong> stands for <strong>Light Detection and Ranging</strong>. It is similar to radar-based images but uses finite laser beams that hit the ground hundreds of thousands of times per second to collect a huge amount of very fine (<em>x</em>,<em>y</em>,<em>z</em>) locations, as well as time and intensity. The intensity value is what really separates LIDAR from other data types. For example, the asphalt rooftop of a building may be of the same elevation as the top of a nearby tree, but the intensities will be different. Just like remote sensing, radiance values in a multispectral satellite image allow us to build classification libraries. The intensity values of LIDAR data allow us to classify and colorize LIDAR data.</p>
<p class="mce-root">The high volume and precision of LIDAR actually make it difficult to use. A LIDAR dataset is referred to as a point cloud because the shape of the dataset is usually irregular as the data is three-dimensional with outlying points. There's not many software packages that effectively visualize point clouds.</p>
<p class="mce-root">Furthermore, an irregular-shaped collection of finite points is just hard to interact with, even when we are using appropriate software.</p>
<p class="mce-root">For these reasons, one of the most common operations on LIDAR data is to project data and resample it to a regular grid. We'll do this using a small LIDAR dataset. This dataset is approximately 7 MB uncompressed and contains over 600,000 points. The data captures some easily identifiable features, such as buildings, trees, and cars in parking lots. You can download the zipped dataset from <a href="http://git.io/vOERW">http://git.io/vOERW</a>.</p>
<p class="mce-root">The file format is a very common binary format specific to LIDAR called <strong>LAS</strong>, which is short for laser. Unzip this file to your working directory. To read this format, we'll use a pure Python library called <kbd>laspy</kbd>. You can install Python version 3.7 using the following command:</p>
<pre class="mce-root"><strong>pip install http://git.io/vOER9</strong></pre>
<p><span>With <kbd>laspy</kbd> installed, we are ready to create a grid from LIDAR.</span></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Creating a grid from the LIDAR data</h1>
                </header>
            
            <article>
                
<p>This script is fairly straightforward. We loop through the (<em>x</em>,<em>y</em>) point locations in the LIDAR data and project them to our grid with a cell size of one meter. Due to the precision of the LIDAR data, we'll end up with multiple points in a single cell. We average these points to create a common elevation value. Another issue that we have to deal with is data loss. Whenever you resample the data, you lose information.</p>
<p>In this case, we'll end up with <kbd>NODATA</kbd> holes in the middle of the raster. To deal with this issue, we fill these holes with average values from the surrounding cells, which is a form of interpolation. We only need two modules, both available on PyPI, as shown in the following code:</p>
<pre>from laspy.file import File<br/>import numpy as np<br/><br/># Source LAS file<br/>source = "lidar.las"<br/><br/># Output ASCII DEM file<br/>target = "lidar.asc"<br/><br/># Grid cell size (data units)<br/>cell = 1.0<br/><br/># No data value for output DEM<br/>NODATA = 0<br/><br/># Open LIDAR LAS file<br/>las = File(source, mode="r")<br/><br/># xyz min and max<br/>min = las.header.min<br/>max = las.header.max<br/><br/># Get the x axis distance in meters<br/>xdist = max[0] - min[0]<br/><br/># Get the y axis distance in meters<br/>ydist = max[1] - min[1]<br/><br/># Number of columns for our grid<br/>cols = int(xdist) / cell<br/><br/># Number of rows for our grid<br/>rows = int(ydist) / cell<br/>cols += 1<br/>rows += 1<br/><br/># Track how many elevation<br/># values we aggregate<br/>count = np.zeros((rows, cols)).astype(np.float32)<br/><br/># Aggregate elevation values<br/>zsum = np.zeros((rows, cols)).astype(np.float32)<br/><br/># Y resolution is negative<br/>ycell = -1 * cell<br/><br/># Project x, y values to grid<br/>projx = (las.x - min[0]) / cell<br/>projy = (las.y - min[1]) / ycell<br/><br/># Cast to integers and clip for use as index<br/>ix = projx.astype(np.int32)<br/>iy = projy.astype(np.int32)<br/><br/># Loop through x, y, z arrays, add to grid shape,<br/># and aggregate values for averaging<br/>for x, y, z in np.nditer([ix, iy, las.z]):<br/> count[y, x] += 1<br/> zsum[y, x] += z<br/><br/># Change 0 values to 1 to avoid numpy warnings,<br/># and NaN values in array<br/>nonzero = np.where(count &gt; 0, count, 1)<br/><br/># Average our z values<br/>zavg = zsum / nonzero<br/><br/># Interpolate 0 values in array to avoid any<br/># holes in the grid<br/>mean = np.ones((rows, cols)) * np.mean(zavg)<br/>left = np.roll(zavg, -1, 1)<br/>lavg = np.where(left &gt; 0, left, mean)<br/>right = np.roll(zavg, 1, 1)<br/>ravg = np.where(right &gt; 0, right, mean)<br/>interpolate = (lavg + ravg) / 2<br/>fill = np.where(zavg &gt; 0, zavg, interpolate)<br/><br/># Create our ASCII DEM header<br/>header = "ncols {}\n".format(fill.shape[1])<br/>header += "nrows {}\n".format(fill.shape[0])<br/>header += "xllcorner {}\n".format(min[0])<br/>header += "yllcorner {}\n".format(min[1])<br/>header += "cellsize {}\n".format(cell)<br/>header += "NODATA_value {}\n".format(NODATA)<br/><br/># Open the output file, add the header, save the array<br/>with open(target, "wb") as f:<br/> f.write(bytes(header, 'UTF-8'))<br/> # The fmt string ensures we output floats<br/> # that have at least one number but only<br/> # two decimal places<br/> np.savetxt(f, fill, fmt="%1.2f")</pre>
<p>The result of our script is an ASCIIGRID, which looks like the following image when viewed in OpenEV. Higher elevations are lighter while lower elevations are darker. Even in this form, you can see buildings, trees, and cars:</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/b16b5692-af2b-4a18-b6bc-8aa384574ee7.png" style="width:22.17em;height:22.17em;" width="551" height="550"/></p>
<p>If we assigned a heat map color ramp, the colors give you a sharper sense of the elevation differences:</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/82927068-0ef4-4863-8b2a-4d7ba91096c8.png" style="width:23.92em;height:23.83em;" width="551" height="550"/></p>
<p>So, what happens if we run this output DEM through our shaded relief script from earlier? There's a big difference between straight-sided buildings and sloping mountains. If you change the input and output names in the shaded relief script to process the LIDAR DEM, we get the following slope result:</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/6e42f201-ffbe-4781-a72f-9772bbfe75e4.png" style="width:21.33em;height:21.25em;" width="551" height="550"/></p>
<p>The gently rolling slope of the mountainous terrain is reduced to outlines of major features in the image. In the aspect image, the changes are so sharp and over such short distances that the output image is very chaotic to view, as shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/b7342f52-23df-4392-9d14-2cafe5748d0a.png" style="width:22.25em;height:22.17em;" width="438" height="437"/></p>
<p>Despite the difference between these images and the coarser but somewhat smoother mountain versions, we still get a very nice shaded relief, which visually resembles a black and white photograph:</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/947c852d-1dd8-4a20-8cfd-142f18ea398c.png" style="width:20.17em;height:20.08em;" width="551" height="550"/></p>
<p>Now that we know how to process LIDAR data, let's learn how to visualize it using Python.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Using PIL to visualize LIDAR data</h1>
                </header>
            
            <article>
                
<p>The previous DEM images in this chapter were visualized using QGIS and OpenEV. We can also create output images in Python by introducing some new functions of the <strong>Python Imaging Library</strong> (<strong>PIL</strong>) that we didn't use in the previous chapters.</p>
<p>In this example, we'll use the <kbd>PIL.ImageOps</kbd> module, which has functions for histogram equalization and automatic contrast enhancement. We'll use PIL's <kbd>fromarray()</kbd> method to import the data from <kbd>numpy</kbd>. Let's see how close we can get to the output of the desktop GIS programs that were pictured in this chapter with the help of the following code:</p>
<pre>import numpy as np<br/><br/>try:<br/> import Image<br/> import ImageOps<br/>except ImportError:<br/> from PIL import Image, ImageOps<br/><br/># Source gridded LIDAR DEM file<br/>source = "lidar.asc"<br/><br/># Output image file<br/>target = "lidar.bmp"<br/><br/># Load the ASCII DEM into a numpy array<br/>arr = np.loadtxt(source, skiprows=6)<br/><br/># Convert array to numpy image<br/>im = Image.fromarray(arr).convert("RGB")<br/><br/># Enhance the image:<br/># equalize and increase contrast<br/>im = ImageOps.equalize(im)<br/>im = ImageOps.autocontrast(im)<br/><br/># Save the image<br/>im.save(target)</pre>
<p>As you can see, in the following image, the enhanced shaded relief has sharper relief than the previous version:</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/5332124a-b2f6-4662-8714-43c222cbdb15.png" style="width:20.17em;height:20.17em;" width="601" height="600"/></p>
<p>Now, let's colorize our shaded relief. We'll use the built-in Python <kbd>colorsys</kbd> module for color space conversion. Normally, we specify colors as RGB values. However, to create a color ramp for a heat map scheme, we'll use <strong>HSV</strong> (short for <strong>Hue, Saturation, and Value</strong>) values to generate our colors.</p>
<p class="mce-root"/>
<p>The advantage of HSV is that you can tweak the <em>H</em> value to be a degree between 0 and 360 on a color wheel. Using a single value for hue allows you to use a linear ramping equation, which is much easier than trying to deal with combinations of three separate RGB values. The following image, which was taken from the online magazine <em>Qt Quarterly</em>, illustrates the HSV color model:</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/aee567c9-1be0-4d32-8204-1217b63a3792.png" style="width:18.42em;height:14.75em;" width="394" height="315"/></p>
<p>The <kbd>colorsys</kbd> module lets you switch back and forth between the HSV and RGB values. The module returns percentages for RGB values, which must then be mapped to the 0-255 scale for each color.</p>
<p>In the following code, we'll convert the ASCII DEM into a PIL image, build our color palette, apply the color palette to the grayscale image, and save the image:</p>
<pre>import numpy as np<br/><br/>try:<br/> import Image<br/> import ImageOps<br/>except:<br/> from PIL import Image, ImageOps<br/>import colorsys<br/><br/># Source LIDAR DEM file<br/>source = "lidar.asc"<br/><br/># Output image file<br/>target = "lidar.bmp"<br/><br/># Load the ASCII DEM into a numpy array<br/>arr = np.loadtxt(source, skiprows=6)<br/><br/># Convert the numpy array to a PIL image.<br/># Use black and white mode so we can stack<br/># three bands for the color image.<br/>im = Image.fromarray(arr).convert('L')<br/><br/># Enhance the image<br/>im = ImageOps.equalize(im)<br/>im = ImageOps.autocontrast(im)<br/><br/># Begin building our color ramp<br/>palette = []<br/><br/># Hue, Saturation, Value<br/># color space starting with yellow.<br/>h = .67<br/>s = 1<br/>v = 1<br/><br/># We'll step through colors from:<br/># blue-green-yellow-orange-red.<br/># Blue=low elevation, Red=high-elevation<br/>step = h / 256.0<br/><br/># Build the palette<br/>for i in range(256):<br/> rp, gp, bp = colorsys.hsv_to_rgb(h, s, v)<br/> r = int(rp * 255)<br/> g = int(gp * 255)<br/> b = int(bp * 255)<br/> palette.extend([r, g, b])<br/> h -= step<br/><br/># Apply the palette to the image<br/>im.putpalette(palette)<br/><br/># Save the image<br/>im.save(target)</pre>
<p>The preceding code produces the following image, with higher elevations in warmer colors and lower elevations in cooler colors:</p>
<p class="CDPAlignCenter CDPAlign"><img src="Images/d1032e79-3dd8-4af2-bde5-a9432721f2cc.png" style="width:24.58em;height:24.58em;" width="601" height="600"/></p>
<p>In this image, we actually get more variation than the default QGIS version. We could potentially improve this image with a smoothing algorithm that would blend the colors where they meet and soften the image visually. As you can see, we have the full range of our color ramp expressed from cool to warm colors, as the elevation change increases.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Creating a triangulated irregular network</h1>
                </header>
            
            <article>
                
<p>The following example is our most sophisticated example yet. A <strong>triangulated irregular network</strong> (<strong>TIN</strong>) is a vector representation of a point dataset in a vector surface of points connected as triangles. An algorithm determines which points are absolutely necessary to accurately represent the terrain as opposed to a raster, which stores a fixed number of cells over a given area and may repeat elevation values in adjacent cells that could be more efficiently stored as a polygon.</p>
<p>A TIN can also be resampled more efficiently on the fly than a raster, which requires less computer memory and processing power when using TIN in a GIS. The most common type of TIN is based on <strong>Delaunay triangulation</strong>, which includes all the points without redundant triangles.</p>
<p class="mce-root">The Delaunay triangulation is very complex. We'll use a pure Python library written by Bill Simons as part of Steve Fortune's Delaunay triangulation algorithm called <kbd>voronoi.py</kbd> to calculate the triangles in our LIDAR data. You can download the script to your working directory or <kbd>site-packages</kbd> directory from <a href="http://git.io/vOEuJ">http://git.io/vOEuJ</a>.</p>
<p class="mce-root">This script reads the LAS file, generates the triangles, loops through them, and writes out a shapefile. For this example, we'll use a clipped version of our LIDAR data to reduce the area to process. If we run our entire dataset of 600,000+ points, the script will run for hours and generate over half a million triangles. You can download the clipped LIDAR dataset as a ZIP file from the following URL: <a href="http://git.io/vOE62">http://git.io/vOE62</a>.</p>
<p class="mce-root">We have several status messages that print while the script runs because of the time-intensive nature of the following example, which can take several minutes to complete. We'll be storing the triangles as <strong>PolygonZ types</strong>, which allow the vertices to have a <kbd>z</kbd> elevation value. Unzip the LAS file and run the following code to generate a shapefile called <kbd>mesh.shp</kbd>:</p>
<ol>
<li>First, we import our libraries:</li>
</ol>
<pre style="padding-left: 60px">import pickle<br/>import os<br/>import time<br/>import math<br/>import numpy as np<br/>import shapefile<br/>from laspy.file import File<br/># voronoi.py for Python 3: pip install http://git.io/vOEuJ<br/>import voronoi</pre>
<ol start="2">
<li>Next, we define the location and name of our LIDAR file, our target output file, and our pickle file:</li>
</ol>
<pre style="padding-left: 60px"># Source LAS file<br/>source = "clippedLAS.las"<br/><br/># Output shapefile<br/>target = "mesh"<br/><br/># Triangles pickle archive<br/>archive = "triangles.p"</pre>
<p class="mce-root"/>
<ol start="3">
<li>Now, we'll create a point class that's needed by the <kbd>voronoi</kbd> module:</li>
</ol>
<pre style="padding-left: 60px">class Point:<br/> """Point class required by the voronoi module"""<br/> def __init__(self, x, y):<br/>   self.px = x<br/>   self.py = y<br/><br/>def x(self):<br/> return self.px<br/><br/>def y(self):<br/> return self.py</pre>
<ol start="4">
<li>Next, we'll create a triangle array to keep track of the triangles that have been created for the mesh:</li>
</ol>
<pre style="padding-left: 60px"># The triangle array holds tuples<br/># 3 point indices used to retrieve the points.<br/># Load it from a pickle<br/># file or use the voronoi module<br/># to create the triangles.<br/>triangles = None</pre>
<ol start="5">
<li>Next, we need to open our LIDAR file and pull the points:</li>
</ol>
<pre style="padding-left: 60px"> # Open LIDAR LAS file<br/> las = File(source, mode="r")<br/>else:<br/> <br/># Open LIDAR LAS file<br/> las = File(source, mode="r")<br/> points = []<br/> print("Assembling points...")<br/> <br/># Pull points from LAS file<br/> for x, y in np.nditer((las.x, las.y)):<br/> points.append(Point(x, y))<br/> print("Composing triangles...")</pre>
<ol start="6">
<li>Now, we can perform a Delaunay calculation on the points to build the triangles:</li>
</ol>
<pre style="padding-left: 60px"># Delaunay Triangulation<br/> triangles = voronoi.computeDelaunayTriangulation(points)</pre>
<ol start="7">
<li>We'll dump the triangles to the pickle archive to save time if we run this exact script again:</li>
</ol>
<pre style="padding-left: 60px"> # Save the triangles to save time if we write more than<br/> # one shapefile.<br/> f = open(archive, "wb")<br/> pickle.dump(triangles, f, protocol=2)<br/> f.close()</pre>
<ol start="8">
<li>Next, we can create a shapefile <kbd>Writer</kbd> object to begin creating our output shapefile by setting up the necessary fields:</li>
</ol>
<pre style="padding-left: 60px">print("Creating shapefile...")<br/> # PolygonZ shapefile (x, y, z, m)<br/> w = shapefile.Writer(target, shapefile.POLYGONZ)<br/> w.field("X1", "C", "40")<br/> w.field("X2", "C", "40")<br/> w.field("X3", "C", "40")<br/> w.field("Y1", "C", "40")<br/> w.field("Y2", "C", "40")<br/> w.field("Y3", "C", "40")<br/> w.field("Z1", "C", "40")<br/> w.field("Z2", "C", "40")<br/> w.field("Z3", "C", "40")<br/> tris = len(triangles)</pre>
<ol start="9">
<li>Then, we loop through the triangles and create the mesh:</li>
</ol>
<pre style="padding-left: 60px"># Loop through shapes and<br/> # track progress every 10 percent<br/> last_percent = 0<br/> for i in range(tris):<br/>     t = triangles[i]<br/>     percent = int((i/(tris*1.0))*100.0)<br/>     if percent % 10.0 == 0 and percent &gt; last_percent:<br/>         last_percent = percent<br/>         print("{} % done - Shape {}/{} at {}".format(percent, <br/>         i, tris, time.asctime()))<br/> part = []<br/> x1 = las.x[t[0]]<br/> y1 = las.y[t[0]]<br/> z1 = las.z[t[0]]<br/> x2 = las.x[t[1]]<br/> y2 = las.y[t[1]]<br/> z2 = las.z[t[1]]<br/> x3 = las.x[t[2]]<br/> y3 = las.y[t[2]]<br/> z3 = las.z[t[2]]</pre>
<ol start="10">
<li>Next, we can eliminate any extremely long line segments, which are miscalculations by the library:</li>
</ol>
<pre style="padding-left: 60px"> # Check segments for large triangles<br/> # along the convex hull which is a common<br/> # artifact in Delaunay triangulation<br/> max = 3<br/> if math.sqrt((x2-x1)**2+(y2-y1)**2) &gt; max:<br/> continue<br/> if math.sqrt((x3-x2)**2+(y3-y2)**2) &gt; max:<br/> continue<br/> if math.sqrt((x3-x1)**2+(y3-y1)**2) &gt; max:<br/> continue<br/> part.append([x1, y1, z1, 0])<br/> part.append([x2, y2, z2, 0])<br/> part.append([x3, y3, z3, 0])<br/> w.poly(parts=[part])<br/> w.record(x1, x2, x3, y1, y2, y3, z1, z2, z3)<br/> print("Saving shapefile...")</pre>
<ol start="11">
<li>Finally, we can save the output shapefile:</li>
</ol>
<pre style="padding-left: 60px">w.close()<br/>print("Done.")</pre>
<p>The following image shows a zoomed-in version of the TIN over the colorized LIDAR data:</p>
<p class="CDPAlignCenter CDPAlign"><img style="font-size: 1em;width:27.67em;height:21.33em;" src="Images/862a2e27-6c8f-4762-8627-291973f0f191.png" width="800" height="617"/></p>
<p>The mesh provides an efficient, continuous surface from point clouds, which can be easier to deal with than the point clouds themselves.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>Elevation data can often provide a complete dataset for analysis and derivative products without any other data. In this chapter, you learned how to read and write ASCII Grids using only NumPy. You also learned how to create shaded reliefs, slope grids, and aspect grids. We created elevation contours using a little-known feature called contour of the GDAL library that's available for Python.</p>
<p>Next, we transformed LIDAR data into an easy-to-manipulate ASCII Grid. We experimented with different ways to visualize the LIDAR data with the PIL. Finally, we created a 3D surface or TIN by turning a LIDAR point cloud into a 3D shapefile of polygons. These are the tools of terrain analysis that are used for transportation planning, construction planning, hydrological drainage modeling, geologic exploration, and more. </p>
<p class="mce-root">In the next chapter, we'll combine the building blocks from the previous three chapters to perform some advanced modeling and actually create some information products.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Further reading</h1>
                </header>
            
            <article>
                
<p><span><span>You can find some additional tutorials on Python and elevation data at the following link: <a href="https://www.earthdatascience.org/tutorials/python/elevation/">https://www.earthdatascience.org/tutorials/python/elevation/</a>.</span></span></p>


            </article>

            
        </section>
    </div>



  </body></html>