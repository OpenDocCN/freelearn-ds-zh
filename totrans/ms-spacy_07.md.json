["```py\n1   a \n2   e-mail  \n3   I\n4   cheese  \n5   order    \n6   phone\n7   pizza   \n8   salami  \n9   topping \n10 want\n```", "```py\na           1 0 0 0 0 0 0 0 0 0\ne-mail   0 1 0 0 0 0 0 0 0 0\nI            0 0 1 0 0 0 0 0 0 0\ncheese  0 0 0 1 0 0 0 0 0 0\norder     0 0 0 0 1 0 0 0 0 0\nphone    0 0 0 0 0 1 0 0 0 0\npizza      0 0 0 0 0 0 1 0 0 0\nsalami    0 0 0 0 0 0 0 1 0 0\ntopping  0 0 0 0 0 0 0 0 1 0\nwant      0 0 0 0 0 0 0 0 0 1   \n```", "```py\nI          0 0 1 0 0 0 0 0 0 0\nwant   0 0 0 0 0 0 0 0 0 1\na         1 0 0 0 0 0 0 0 0 0\npizza   0 0 0 0 0 0 1 0 0 0\n```", "```py\nthe 0.418 0.24968 -0.41242 0.1217 0.34527 -0.044457 -0.49688 -0.17862 -0.00066023 -0.6566 0.27843 -0.14767 -0.55677 0.14658 -0.0095095 0.011658 0.10204 -0.12792 -0.8443 -0.12181 -0.016801 -0.33279 -0.1552 -0.23131 -0.19181 -1.8823 -0.76746 0.099051 -0.42125 -0.19526 4.0071 -0.18594 -0.52287 -0.31681 0.00059213 0.0074449 0.17778 -0.15897 0.012041 -0.054223 -0.29871 -0.15749 -0.34758 -0.045637 -0.44251 0.18785 0.0027849 -0.18411 -0.11514 -0.78581\n```", "```py\n    ch, ha, ai, ir, cha, hai, air\n    ```", "```py\nimport spacy\nnlp = spacy.load(\"en_core_web_md\")\ndoc = nlp(\"I ate a banana.\")\ndoc[3].vector\n```", "```py\ntype(doc[3].vector)\n<class 'numpy.ndarray'>\ndoc[3].vector.shape\n(300,)\n```", "```py\ndoc = nlp(\"I like a banana,\")\ndoc.vector\ndoc[1:3].vector\n```", "```py\ndoc = nlp(\"You went there afskfsd.\")\nfor token in doc:\n          token.is_oov, token.has_vector\n(False, True)\n(False, True)\n(False, True)\n(True, False)\n(False, True)\n```", "```py\ndoc1 = nlp(\"I visited England.\")\ndoc2 = nlp(\"I went to London.\")\ndoc1[1:3].similarity(doc2[1:4])\n0.6539691\n```", "```py\ndoc1[2].similarity(doc2[3])\n0.73891276\n```", "```py\ndoc1.similarity(doc2)\n0.7995623615797786\n```", "```py\ndoc1.similarity(doc1)\n1.0\n```", "```py\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nimport numpy as np\nimport spacy\nnlp = spacy.load(\"en_core_web_md\")\nvocab = nlp(\"cat dog tiger elephant bird monkey lion cheetah burger pizza food cheese wine salad noodles macaroni fruit vegetable\")\nwords = [word.text for word in vocab]\n>>> vecs = np.vstack([word.vector for word in vocab if word.has_vector])\npca = PCA(n_components=2)\nvecs_transformed = pca.fit_transform(vecs)\nplt.figure(figsize=(20,15))\nplt.scatter(vecs_transformed[:,0], vecs_transformed[:,1])\nfor word, coord in zip(words, vecs_transformed):\n           x,y = coord\n          plt.text(x,y,word, size=15)\nplt.show()\n```", "```py\n    $ wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M-subword.vec.zip\n    ```", "```py\n    wiki-news-300d-1M-subword.vec file.\n    ```", "```py\n    wiki-news-300d-1M-subword.vec vectors into spaCy's vector format.b) Creates a language model directory named `en_subwords_wiki_lg` that contains the newly created vectors.\n    ```", "```py\n    Reading vectors from wiki-news-300d-1M-subword.vec\n    Open loc\n    999994it [02:05, 7968.84it/s]\n    Creating model...\n    0it [00:00, ?it/s]      Successfully compiled vocab\n          999731 entries, 999994 vectors\n    ```", "```py\n    import spacy\n    nlp = spacy.load(\"en_subwords_wiki_lg\")\n    ```", "```py\n    doc = nlp(\"I went there.\")\n    ```", "```py\nBlue whales are the biggest mammals in the world. They're observed in California coast during spring.\n```", "```py\nI purchased a science fiction book last week.\nI loved everything related to this fragrance: light, floral and feminine …\nI purchased a bottle of wine. \n```", "```py\nsentences = nlp(\"I purchased a science fiction book last week. I loved everything related to this fragrance: light, floral and feminine... I purchased a bottle of wine.  \")\nkey = nlp(\"perfume\")\nfor sent in sentences.sents:\n           print(sent.similarity(key))\n... \n0.2481654331382154\n0.5075297559861377\n0.42154297167069865\n```", "```py\nA dog\nMy dog\nMy beautiful dog\nA beautiful dog\nA beautiful and happy dog\nMy happy and cute dog\n```", "```py\ndoc = nlp(\"My beautiful and cute dog jumped over the fence\")\ndoc.noun_chunks\n<generator object at 0x7fa3c529be58>\nlist(doc.noun_chunks)\n[My beautiful and cute dog, the fence]\n```", "```py\nfor sent in sentences.sents:\n          nchunks = [nchunk.text for nchunk in sent.noun_chunks]\n             nchunk_doc = nlp(\" \".join(nchunks)) \n             print(nchunk_doc.similarity(key))\n0.21390893517254456\n0.6047741393523175\n0.44506391511570403\n```", "```py\n\"Google Search, often referred as Google, is the most popular search engine nowadays. It answers a huge volume of queries every day.\"\n\"Microsoft Bing is another popular search engine. Microsoft is known by its star product Microsoft Windows, a popular operating system sold over the world.\"\n\"The Dead Sea is the lowest lake in the world, located in the Jordan Valley of Israel. It is also the saltiest lake in the world.\"\n```", "```py\ndoc1 =  nlp(\"Google Search, often referred as Google, is the most popular search engine nowadays. It answers a huge volume of queries every day.\")\ndoc2 = nlp(\"Microsoft Bing is another popular search engine. Microsoft is known by its star product Microsoft Windows, a popular operating system sold over the world.\")\ndoc3 = nlp(\"The Dead Sea is the lowest lake in the world, located in the Jordan Valley of Israel. It is also the saltiest lake in the world.\")\ndoc1.ents\n(Google,)\ndoc2.ents\n(Microsoft Bing, Microsoft, Microsoft, Windows)\ndoc3.ents\n(The Dead Sea, the Jordan Valley, Israel)\n```", "```py\nents1 = [ent.text for ent in doc1.ents]\nents2 = [ent.text for ent in doc2.ents]\nents3 = [ent.text for ent in doc3.ents]\nents1 = nlp(\" \".join(ents1))\nents2 = nlp(\" \".join(ents2))\nents3 = nlp(\" \".join(ents3))\nents1.similarity(ents2)\n0.6078712596225045\nents1.similarity(ents3)\n0.374100398233877\nents2.similarity(ents3)\n0.36244710903224026\n```"]