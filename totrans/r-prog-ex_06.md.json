["```py\nset.seed(12345)\n```", "```py\nsum(!complete.cases(client_messages$MESSAGE))\n#> 0\n\nsum(!complete.cases(client_messages$MULT_PURCHASES))\n#> 0\n```", "```py\nprop.table(table(client_messages$MULT_PURCHASES))\n#>     FALSE      TRUE\n#> 0.3621262 0.6378738\n```", "```py\nindexes <- createDataPartition(\n    client_messages$MULT_PURCHASES,\n    list = FALSE,\n    times = 1,\n    p = 0.7\n)\ntrain <- client_messages[ indexes, ]\ntest <- client_messages[-indexes, ]\n```", "```py\nprop.table(table(train$MULT_PURCHASES))\n#>     FALSE      TRUE\n#> 0.3632075 0.6367925\n\nprop.table(table(test$MULT_PURCHASES))\n#>     FALSE      TRUE\n#> 0.3595506 0.6404494\n```", "```py\ntokens <- tokens(\n    train$MESSAGE,\n    remove_punct = TRUE,\n    remove_numbers = TRUE,\n    remove_symbols = TRUE,\n    remove_hyphens = TRUE\n)\n```", "```py\ntokens <- tokens_tolower(tokens)\n```", "```py\ntokens <- tokens_select(tokens, stopwords(), selection = \"remove\")\n```", "```py\ntokens <- tokens_wordstem(tokens, language = \"english\")\n```", "```py\nbuild_tokens <- function(data, n_grams = 1) {\n    tokens <- tokens(\n        data,\n        remove_punct = TRUE,\n        remove_numbers = TRUE,\n        remove_symbols = TRUE,\n       remove_hyphens = TRUE\n    )\n    tokens <- tokens_tolower(tokens)\n    tokens <- tokens_select(tokens, stopwords(), selection = \"remove\")\n    tokens <- tokens_wordstem(tokens, language = \"english\")\n    tokens <- tokens_ngrams(tokens, n = 1:n_grams)\n    return(tokens)\n}\n```", "```py\nsentence <- \"If it looks like a duck, swims like a duck,\n             and quacks like a duck, then it probably is a duck.\"\n\ntokens <- tokens(sentence)\ntokens\n#> tokens from 1 document.\n#> text1 :\n#>  [1] \"If\"       \"it\"       \"looks\"    \"like\"     \"a\"        \"duck\"\n#>  [7] \",\"        \"swims\"    \"like\"     \"a\"        \"duck\"     \",\"\n#> [13] \"and\"      \"quacks\"   \"like\"     \"a\"        \"duck\"     \",\"\n#> [19] \"then\"     \"it\"       \"probably\" \"is\"       \"a\"        \"duck\"\n#> [25] \".\"\n\ntokens <- tokens(sentence, remove_punct = TRUE)\ntokens\n#> tokens from 1 document.\n#> text1 :\n#>  [1] \"If\"       \"it\"       \"looks\"    \"like\"     \"a\"        \"duck\"\n#>  [7] \"swims\"    \"like\"     \"a\"        \"duck\"     \"and\"      \"quacks\"\n#> [13] \"like\"     \"a\"        \"duck\"     \"then\"     \"it\"       \"probably\"\n#> [19] \"is\"       \"a\"        \"duck\"\n\ntokens <- tokens_tolower(tokens)\ntokens\n#> tokens from 1 document.\n#> text1 :\n#>  [1] \"if\"       \"it\"       \"looks\"    \"like\"     \"a\"        \"duck\"\n#>  [7] \"swims\"    \"like\"     \"a\"        \"duck\"     \"and\"      \"quacks\"\n#> [13] \"like\"     \"a\"        \"duck\"     \"then\"     \"it\"       \"probably\"\n#> [19] \"is\"       \"a\"        \"duck\"\n\ntokens <- tokens_select(tokens, stopwords(), selection = \"remove\")\ntokens\n#> tokens from 1 document.\n#> text1 :\n#>  [1] \"looks\"    \"like\"     \"duck\"     \"swims\"    \"like\"     \"duck\"\n#>  [7] \"quacks\"   \"like\"     \"duck\"     \"probably\" \"duck\"\n\ntokens <- tokens_wordstem(tokens, language = \"english\")\ntokens\n#> tokens from 1 document.\n#> text1 :\n#>  [1] \"look\"    \"like\"    \"duck\"    \"swim\"    \"like\"    \"duck\"    \"quack\"\n#>  [8] \"like\"    \"duck\"    \"probabl\" \"duck\"\n```", "```py\ntrain.dfm <- dfm(tokens)\n```", "```py\ndfm(tokens)\n#> Document-feature matrix of: 1 document, 6 features (0% sparse).\n#> 1 x 6 sparse Matrix of class \"dfmSparse\"\n#>        features\n#>  docs  look like duck swim quack probabl\n#> text1  1    3    4    1    1     1\n```", "```py\nbuild_dfm <- function(data, n_grams = 1) {\n    tokens <- build_tokens(data, n_grams)\n    return(dfm(tokens))\n}\n```", "```py\ntrain.dfm <- build_dfm(train$MESSAGE)\n```", "```py\ntrain.dfm\n#> Document-feature matrix of: 212 documents, 2,007 features (98.4% sparse)\n```", "```py\ndfm.df <- cbind(MULT_PURCHASES = train$MULT_PURCHASES, data.frame(dfm))\nnames(dfm.df) <- make.names(names(dfm.df))\n```", "```py\nbuild_dfm_df <- function(data, dfm) {\n    df <- cbind(MULT_PURCHASES = data$MULT_PURCHASES, data.frame(dfm))\n    names(df) <- make.names(names(df))\n    return(df)\n}\ntrain.dfm.df <- build_dfm_df(train, train.dfm)\n```", "```py\ntopfeatures(train.dfm)\n#>     br    like    tast  flavor     one    just   coffe    good     tri product\n#>    220     107     101      87      82      75      72      71      70      67\n```", "```py\ncv.control <- trainControl(method = \"repeatedcv\", number = 5, repeats = 2)\n```", "```py\nmodel.1 <- train(\n    MULT_PURCHASES ~ .,\n    data = train.dfm.df,\n    method = \"rf\",\n    trControl = cv.control,\n    tuneLength = 5\n)\n```", "```py\ntrain_model <- function(data, cv.control) {\n    cluster <- makeCluster(detectCores())\n    registerDoParallel(cluster)\n    start.time <- Sys.time()\n    model <- train(\n        MULT_PURCHASES ~ .,\n        data = data,\n        method = \"rf\",\n        trControl = cv.control,\n        tuneLength = 5\n    )\n    print(Sys.time() - start.time)\n    stopCluster(cluster)\n    return(model)\n}\n```", "```py\nmodel.1 <- train_model(train.dfm.df, cv.control)\n```", "```py\nmodel.1\n#> Random Forest\n#>\n#>  212 samples\n#> 2007 predictors\n#>    2 classes: 'FALSE', 'TRUE'\n#>\n#> No pre-processing\n#> Resampling: Cross-Validated (5 fold, repeated 2 times)\n#> Summary of sample sizes: 170, 169, 170, 169, 170, 169, ...\n#> Resampling results across tuning parameters:\n#>\n#>   mtry  Accuracy   Kappa\n#>      2  0.6368771  0.00000000\n#>     11  0.6439092  0.03436849\n#>     63  0.6462901  0.07827322\n#>    356  0.6536545  0.16160573\n#>   2006  0.6512735  0.16892126\n#>\n#> Accuracy was used to select the optimal model using  the largest value.\n#> The final value used for the model was mtry = 356.\n```", "```py\nconfusionMatrix(model.1$finalModel$predicted, train$MULT_PURCHASES)\n#> Confusion Matrix and Statistics\n#>\n#>           Reference\n#> Prediction FALSE TRUE\n#>      FALSE    18   19\n#>      TRUE     59  116\n#>\n#>                Accuracy : 0.6321\n#>                  95% CI : (0.5633, 0.6971)\n#>     No Information Rate : 0.6368\n#>     P-Value [Acc > NIR] : 0.5872\n#>\n#>                   Kappa : 0.1047\n#>  Mcnemar's Test P-Value : 1.006e-05\n#>\n#>             Sensitivity : 0.23377\n#>             Specificity : 0.85926\n#>          Pos Pred Value : 0.48649\n#>          Neg Pred Value : 0.66286\n#>              Prevalence : 0.36321\n#>          Detection Rate : 0.08491\n#>    Detection Prevalence : 0.17453\n#>       Balanced Accuracy : 0.54651\n#>\n#>        'Positive' Class : FALSE\n```", "```py\nbuild_tf_idf <- function(dfm, idf = NULL) {\n    tf <- apply(as.matrix(dfm), 1, term_frequency)\n    if (is.null(idf)) {\n        idf <- apply(as.matrix(dfm), 2, inverse_document_frequency)\n    }\n    tfidf <- t(apply(tf, 2, tf_idf, idf = idf))\n    incomplete_cases <- which(!complete.cases(tfidf))\n    tfidf[incomplete_cases, ] <- rep(0.0, ncol(tfidf))\n    return(tfidf)\n}\n```", "```py\ntrain.tfidf <- build_tf_idf(train.dfm)\ntrain.tfidf.df <- build_dfm_df(train, train.tfidf)\n```", "```py\nmodel.2 <- train_model(train.tfidf.df, cv.control)\n```", "```py\nmodel.2\n#> Random Forest\n#>\n#>  212 samples\n#> 2007 predictors\n#>    2 classes: 'FALSE', 'TRUE'\n#>\n#> No pre-processing\n#> Resampling: Cross-Validated (5 fold, repeated 2 times)\n#> Summary of sample sizes: 170, 170, 170, 169, 169, 169, ...\n#> Resampling results across tuning parameters:\n#>\n#>   mtry  Accuracy   Kappa\n#>      2  0.6368771  0.00000000\n#>     11  0.6368771  0.00000000\n#>     63  0.6392580  0.01588785\n#>    356  0.6603544  0.13818300\n#>   2006  0.6648948  0.18269878\n#>\n#> Accuracy was used to select the optimal model using  the largest value.\n#> The final value used for the model was mtry = 2006.\n```", "```py\nbuild_dfm(sentence, n_grams = 2)\n#> Document-feature matrix of: 1 document, 14 features (0% sparse).\n#> 1 x 14 sparse Matrix of class \"dfmSparse\"\n#>          features\n#>  docs    look like duck swim quack probabl look_like like_duck duck_swim\n#> text1    1    3    4    1    1     1       1         3         1\n#>          features\n#>  docs    swim_like duck_quack quack_like duck_probabl probabl_duck\n#> text1    1         1          1          1            1\n```", "```py\ntrain.bigrams.dfm <- build_dfm(train$MESSAGE, n_grams = 2)\ntrain.bigrams.tfidf <- build_tf_idf(train.bigrams.dfm)\ntrain.bigrams.tfidf.df <- build_dfm_df(train, train.bigrams.tfidf)\n```", "```py\nmodel.3 <- train_model(train.bigrams.tfidf.df, cv.control)\nmodel.3\n#> Random Forest\n#>\n#>  212 samples\n#> 9366 predictors\n#>    2 classes: 'FALSE', 'TRUE'\n#>\n#> No pre-processing\n#> Resampling: Cross-Validated (5 fold, repeated 2 times)\n#> Summary of sample sizes: 170, 170, 169, 170, 169, 170, ...\n#> Resampling results across tuning parameters:\n#>\n#>   mtry  Accuracy   Kappa\n#>      2  0.6368771   0.000000000\n#>     16  0.6368771   0.000000000\n#>    136  0.6344961  -0.004672897\n#>   1132  0.6133998  -0.007950251\n#>   9365  0.6109081   0.051144597\n#>\n#> Accuracy was used to select the optimal model using  the largest value.\n#> The final value used for the model was mtry = 2.\n```", "```py\nbuild_svd <- function(dfm) {\n    dfm <- t(dfm)\n    start.time <- Sys.time()\n    svd <- irlba(dfm, nv = min(nrow(dfm), ncol(dfm)) / 4)\n    print(Sys.time() - start.time)\n    return(svd)\n}\n```", "```py\ntrain.bigrams.svd <- build_svd(train.bigrams.tfidf)\ntrain.bigrams.svd.df <- build_dfm_df(train, train.bigrams.svd$v)\nmodel.4 <- train_model(train.bigrams.svd.df, cv.control)\nmodel.4\n#> Random Forest\n#>\n#> 212 samples\n#>  53 predictors\n#>   2 classes: 'FALSE', 'TRUE'\n#>\n#> No pre-processing\n#> Resampling: Cross-Validated (5 fold, repeated 2 times)\n#> Summary of sample sizes: 169, 170, 170, 170, 169, 170, ...\n#> Resampling results across tuning parameters:\n#>\n#>   mtry  Accuracy   Kappa\n#>    2    0.6344408  0.05602509\n#>   14    0.6225360  0.06239153\n#>   27    0.6272979  0.09265294\n#>   40    0.6485604  0.13698858\n#>   53    0.6366002  0.12574827\n#>\n#> Accuracy was used to select the optimal model using  the largest value.\n#> The final value used for the model was mtry = 40.\n```", "```py\ncosine_similarities <- function(df) {\n    return(cosine(t(as.matrix(df[, -c(1)]))))\n}\n```", "```py\nmean_cosine_similarities <- function(df) {\n    similarities <- cosine_similarities(df)\n    indexes <- which(df$MULT_PURCHASES == TRUE)\n    df$MULT_PURCHASES_SIMILARITY <- rep(0.0, nrow(df))\n    for (i in 1:nrow(df)) {\n        df$MULT_PURCHASES_SIMILARITY[i] <- mean(similarities[i, indexes])\n    }\n    return(df)\n}\n```", "```py\ntrain.bigrams.svd.sim.df <- mean_cosine_similarities(train.bigrams.svd.df)\nmodel.5 <- train_model(train.bigrams.svd.sim.df, cv.control)\nmodel.5\n#> Random Forest\n#>\n#> 212 samples\n#>  54 predictors\n#>   2 classes: 'FALSE', 'TRUE'\n#>\n#> No pre-processing\n#> Resampling: Cross-Validated (5 fold, repeated 2 times)\n#> Summary of sample sizes: 169, 170, 170, 170, 169, 170, ...\n#> Resampling results across tuning parameters:\n#>\n#>   mtry  Accuracy   Kappa\n#>    2    0.6460687  0.08590598\n#>   15    0.6227021  0.05793928\n#>   28    0.6437431  0.12111778\n#>   41    0.6296788  0.09535957\n#>   54    0.6227021  0.07662715\n#>\n#> Accuracy was used to select the optimal model using  the largest value.\n#> The final value used for the model was mtry = 2.\n```", "```py\ntrain.sentiment <- sentiment_by(train$MESSAGE)\ntrain.sentiments.df <- cbind(\n    train.tfidf.df,\n    WORD_COUNT = train.sentiment$word_count,\n    SENTIMENT = train.sentiment$ave_sentiment\n)\nmodel.6 <- train_model(train.sentiments.df, cv.control)\nmodel.6\n#> Random Forest\n#>\n#>  212 samples\n#> 2009 predictors\n#>    2 classes: 'FALSE', 'TRUE'\n#>\n#> No pre-processing\n#> Resampling: Cross-Validated (5 fold, repeated 2 times)\n#> Summary of sample sizes: 170, 170, 169, 170, 169, 170, ...\n#> Resampling results across tuning parameters:\n#>\n#>   mtry  Accuracy   Kappa\n#>      2  0.6368771  0.00000000\n#>     11  0.6440753  0.04219596\n#>     63  0.6863787  0.22495962\n#>    356  0.6935770  0.28332726\n#>   2008  0.7173198  0.31705425\n#>\n#> Accuracy was used to select the optimal model using  the largest value.\n#> The final value used for the model was mtry = 2008.\n```", "```py\ntest.dfm <- build_dfm(test)\ntest.dfm <- dfm_select(test.dfm, pattern = train.dfm, selection = \"keep\")\n```", "```py\ntrain.idf <- apply(as.matrix(train.dfm), 2, inverse_document_frequency)\ntest.tfidf <- build_tf_idf(test.dfm, idf = train.idf)\ntest.tfidf.df <- build_dfm_df(test, test.tfidf)\n```", "```py\ntest.sentiment <- sentiment_by(test$MESSAGE)\ntest.sentiments.df <- cbind(\n    test.tfidf.df,\n    WORD_COUNT = test.sentiment$word_count,\n    SENTIMENT = test.sentiment$ave_sentiment\n)\n```", "```py\npredictions <- predict(model.6, test.sentiments.df)\n```", "```py\nconfusionMatrix(predictions, test$MULT_PURCHASES)\n#> Confusion Matrix and Statistics\n#>\n#>           Reference\n#> Prediction FALSE TRUE\n#>      FALSE    11    4\n#>      TRUE     21   53\n#>\n#>                Accuracy : 0.7191\n#>                  95% CI : (0.6138, 0.8093)\n#>     No Information Rate : 0.6404\n#>     P-Value [Acc > NIR] : 0.073666\n#>\n#>                   Kappa : 0.3096\n#>  Mcnemar's Test P-Value : 0.001374\n#>\n#>             Sensitivity : 0.3438\n\n#>             Specificity : 0.9298\n#>          Pos Pred Value : 0.7333\n#>          Neg Pred Value : 0.7162\n#>              Prevalence : 0.3596\n#>          Detection Rate : 0.1236\n#>    Detection Prevalence : 0.1685\n#>       Balanced Accuracy : 0.6368\n#>\n#>        'Positive' Class : FALSE\n```", "```py\nsigma.inverse <- 1 / train.bigrams.svd$d\nu.transpose <- t(train.bigrams.svd$u)\ntest.bigrams.svd <- t(sigma.inverse * u.transpose %*% t(test.bigrams.tfidf))\ntest.bigrams.svd.df <- build_dfm_df(test, test.bigrams.svd)\n```", "```py\nconsumer_key <- \"b9SGfRpz4b1rnHFtN2HtiQ9xl\"\nconsumer_secret <- \"YMifSUmCJ4dlgB8RVxKRNcTLQw7Y4IBwDwBRkdz2Va1vcQjOP0\"\naccess_token <- \"171370802-RTl4RBpMDaSFdVf5q9xrSWQKxtae4Wi3y76Ka4Lz\"\naccess_secret <- \"dHfbMtmpeA2QdOH5cYPXO5b4hF8Nj6LjxELfOMSwHoUB8\"\nsetup_twitter_oauth(consumer_key, consumer_secret, access_token, access_secret)\n```", "```py\nget_twitter_data <- function(keyword, n) {\n    return(twListToDF(searchTwitter(keyword, n, lang = \"en\")))\n}\n```", "```py\ncake_data <- get_twitter_data(\"cake\", 250)\n\nnames(cake_data)\n#>  [1] \"text\"          \"favorited\"     \"favoriteCount\" \"replyToSN\"\n#>  [5] \"created\"       \"truncated\"     \"replyToSID\"    \"id\"\n#>  [9] \"replyToUID\"    \"statusSource\"  \"screenName\"    \"retweetCount\"\n#> [13] \"isRetweet\"     \"retweeted\"     \"longitude\"     \"latitude\"\n```"]