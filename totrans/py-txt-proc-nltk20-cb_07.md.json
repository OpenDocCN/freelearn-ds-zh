["```py\ndef bag_of_words(words):\n  return dict([(word, True) for word in words])\n```", "```py\n>>> from featx import bag_of_words\n>>> bag_of_words(['the', 'quick', 'brown', 'fox'])\n{'quick': True, 'brown': True, 'the': True, 'fox': True}\n```", "```py\ndef bag_of_words_not_in_set(words, badwords):\n  return bag_of_words(set(words) - set(badwords))\n```", "```py\n>>> from featx import bag_of_words_not_in_set\n>>> bag_of_words_not_in_set(['the', 'quick', 'brown', 'fox'], ['the'])\n{'quick': True, 'brown': True, 'fox': True}\n```", "```py\nfrom nltk.corpus import stopwords\n\ndef bag_of_non_stopwords(words, stopfile='english'):\n  badwords = stopwords.words(stopfile)\n  return bag_of_words_not_in_set(words, badwords)\n```", "```py\n>>> from featx import bag_of_non_stopwords\n>>> bag_of_non_stopwords(['the', 'quick', 'brown', 'fox'])\n{'quick': True, 'brown': True, 'fox': True}\n```", "```py\nfrom nltk.collocations import BigramCollocationFinder\nfrom nltk.metrics import BigramAssocMeasures\n\ndef bag_of_bigrams_words(words, score_fn=BigramAssocMeasures.chi_sq, n=200):\n  bigram_finder = BigramCollocationFinder.from_words(words)\n  bigrams = bigram_finder.nbest(score_fn, n)\n  return bag_of_words(words + bigrams)\n```", "```py\n>>> from featx import bag_of_bigrams_words\n>>> bag_of_bigrams_words(['the', 'quick', 'brown', 'fox'])\n{'brown': True, ('brown', 'fox'): True, ('the', 'quick'): True, 'fox': True, ('quick', 'brown'): True, 'quick': True, 'the': True}\n```", "```py\nP(label | features) = P(label) * P(features | label) / P(features)\n```", "```py\nimport collections\ndef label_feats_from_corpus(corp, feature_detector=bag_of_words):\n  label_feats = collections.defaultdict(list)\n  for label in corp.categories():\n    for fileid in corp.fileids(categories=[label]):\n      feats = feature_detector(corp.words(fileids=[fileid]))\n      label_feats[label].append(feats)\n  return label_feats\n```", "```py\ndef split_label_feats(lfeats, split=0.75):\n  train_feats = []\n  test_feats = []\n  for label, feats in lfeats.iteritems():\n    cutoff = int(len(feats) * split)\n    train_feats.extend([(feat, label) for feat in feats[:cutoff]])\n    test_feats.extend([(feat, label) for feat in feats[cutoff:]])\n  return train_feats, test_feats\n```", "```py\n>>> from nltk.corpus import movie_reviews\n>>> from featx import label_feats_from_corpus, split_label_feats\n>>> movie_reviews.categories()\n['neg', 'pos']\n>>> lfeats = label_feats_from_corpus(movie_reviews)\n>>> lfeats.keys()\n['neg', 'pos']\n>>> train_feats, test_feats = split_label_feats(lfeats)\n>>> len(train_feats)\n1500\n>>> len(test_feats)\n500\n```", "```py\n>>> from nltk.classify import NaiveBayesClassifier\n>>> nb_classifier = NaiveBayesClassifier.train(train_feats)\n>>> nb_classifier.labels()\n['neg', 'pos']\n```", "```py\n>>> from featx import bag_of_words\n>>> negfeat = bag_of_words(['the', 'plot', 'was', 'ludicrous'])\n>>> nb_classifier.classify(negfeat)\n'neg'\n>>> posfeat = bag_of_words(['kate', 'winslet', 'is', 'accessible'])\n>>> nb_classifier.classify(posfeat)\n'pos'\n```", "```py\n>>> from nltk.classify.util import accuracy\n>>> accuracy(nb_classifier, test_feats)\n0.72799999999999998\n```", "```py\n>>> probs = nb_classifier.prob_classify(test_feats[0][0])\n>>> probs.samples()\n['neg', 'pos']\n>>> probs.max()\n'pos'\n>>> probs.prob('pos')\n0.99999996464309127\n>>> probs.prob('neg')\n3.5356889692409258e-08\n```", "```py\n>>> nb_classifier.most_informative_features(n=5)\n[('magnificent', True), ('outstanding', True), ('insulting', True), ('vulnerable', True), ('ludicrous', True)]\n```", "```py\n>>> nb_classifier.show_most_informative_features(n=5)\nMost Informative Features\n\n    magnificent = True    pos : neg = 15.0 : 1.0\n\n    outstanding = True    pos : neg = 13.6 : 1.0\n\n    insulting = True      neg : pos = 13.0 : 1.0\n\n    vulnerable = True     pos : neg = 12.3 : 1.0\n\n    ludicrous = True      neg : pos = 11.8 : 1.0\n```", "```py\n>>> from nltk.probability import LaplaceProbDist\n>>> nb_classifier = NaiveBayesClassifier.train(train_feats, estimator=LaplaceProbDist)\n>>> accuracy(nb_classifier, test_feats)\n0.71599999999999997\n```", "```py\n>>> from nltk.probability import DictionaryProbDist\n>>> label_probdist = DictionaryProbDist({'pos': 0.5, 'neg': 0.5})\n>>> true_probdist = DictionaryProbDist({True: 1})\n>>> feature_probdist = {('pos', 'yes'): true_probdist, ('neg', 'no'): true_probdist}\n>>> classifier = NaiveBayesClassifier(label_probdist, feature_probdist)\n>>> classifier.classify({'yes': True})\n'pos'\n>>> classifier.classify({'no': True})\n'neg'\n```", "```py\n>>> from nltk.classify import DecisionTreeClassifier\n>>> dt_classifier = DecisionTreeClassifier.train(train_feats, binary=True, entropy_cutoff=0.8, depth_cutoff=5, support_cutoff=30)\n>>> accuracy(dt_classifier, test_feats)\n0.68799999999999994\n```", "```py\n>>> from nltk.probability import FreqDist, MLEProbDist, entropy\n>>> fd = FreqDist({'pos': 30, 'neg': 10})\n>>> entropy(MLEProbDist(fd))\n0.81127812445913283\n>>> fd['neg'] = 25\n>>> entropy(MLEProbDist(fd))\n0.99403021147695647\n>>> fd['neg'] = 30\n>>> entropy(MLEProbDist(fd))\n1.0\n>>> fd['neg'] = 1\n>>> entropy(MLEProbDist(fd))\n0.20559250818508304\n```", "```py\n>>> from nltk.classify import MaxentClassifier\n>>> me_classifier = MaxentClassifier.train(train_feats, algorithm='iis', trace=0, max_iter=1, min_lldelta=0.5)\n>>> accuracy(me_classifier, test_feats)\n0.5\n```", "```py\n>>> me_classifier.show_most_informative_features(n=4)\n-0.740 worst==True and label is 'pos'\n\n0.740 worst==True and label is 'neg'\n\n0.715 bad==True and label is 'neg'\n\n-0.715 bad==True and label is 'pos'\n```", "```py\n>>> me_classifier = MaxentClassifier.train(train_feats, algorithm='cg', trace=0, max_iter=10)\n>>> accuracy(me_classifier, test_feats)\n0.85599999999999998\n```", "```py\n>>> me_classifier = MaxentClassifier.train(train_feats, algorithm='megam', trace=0, max_iter=10)\n[Found megam: /usr/local/bin/megam]\n>>> accuracy(me_classifier, test_feats)\n0.86799999999999999\n```", "```py\nimport collections\nfrom nltk import metrics\n\ndef precision_recall(classifier, testfeats):\n  refsets = collections.defaultdict(set)\n  testsets = collections.defaultdict(set)\n\n  for i, (feats, label) in enumerate(testfeats):\n    refsets[label].add(i)\n    observed = classifier.classify(feats)\n    testsets[observed].add(i)\n\n  precisions = {}\n  recalls = {}\n\n  for label in classifier.labels():\n    precisions[label] = metrics.precision(refsets[label], testsets[label])\n    recalls[label] = metrics.recall(refsets[label], testsets[label])\n\n  return precisions, recalls\n```", "```py\n>>> from classification import precision_recall\n>>> nb_precisions, nb_recalls = precision_recall(nb_classifier, test_feats)\n>>> nb_precisions['pos']\n0.6413612565445026\n>>> nb_precisions['neg']\n0.9576271186440678\n>>> nb_recalls['pos']\n0.97999999999999998\n>>> nb_recalls['neg']\n0.45200000000000001\n```", "```py\n>>> me_precisions, me_recalls = precision_recall(me_classifier, test_feats)\n>>> me_precisions['pos']\n0.8801652892561983\n>>> me_precisions['neg']\n0.85658914728682167\n>>> me_recalls['pos']\n0.85199999999999998\n>>> me_recalls['neg']\n0.88400000000000001\n```", "```py\n1/(alpha/p + (1-alpha)/r)\n```", "```py\nfrom nltk.metrics import BigramAssocMeasures\nfrom nltk.probability import FreqDist, ConditionalFreqDist\n\ndef high_information_words(labelled_words, score_fn=BigramAssocMeasures.chi_sq, min_score=5):\n  word_fd = FreqDist()\n  label_word_fd = ConditionalFreqDist()\n\n  for label, words in labelled_words:\n    for word in words:\n      word_fd.inc(word)\n      label_word_fd[label].inc(word)\n\n  n_xx = label_word_fd.N()\n  high_info_words = set()\n\n  for label in label_word_fd.conditions():\n    n_xi = label_word_fd[label].N()\n    word_scores = collections.defaultdict(int)\n\n    for word, n_ii in label_word_fd[label].iteritems():\n      n_ix = word_fd[word]\n      score = score_fn(n_ii, (n_ix, n_xi), n_xx)\n      word_scores[word] = score\n\n    bestwords = [word for word, score in word_scores.iteritems() if score >= min_score]\n    high_info_words |= set(bestwords)\n\n  return high_info_words\n```", "```py\ndef bag_of_words_in_set(words, goodwords):\n  return bag_of_words(set(words) & set(goodwords))\n```", "```py\n>>> from featx import high_information_words, bag_of_words_in_set\n>>> labels = movie_reviews.categories()\n>>> labeled_words = [(l, movie_reviews.words(categories=[l])) for l in labels]\n>>> high_info_words = set(high_information_words(labeled_words))\n>>> feat_det = lambda words: bag_of_words_in_set(words, high_info_words)\n>>> lfeats = label_feats_from_corpus(movie_reviews, feature_detector=feat_det)\n>>> train_feats, test_feats = split_label_feats(lfeats)\n```", "```py\n>>> nb_classifier = NaiveBayesClassifier.train(train_feats)\n>>> accuracy(nb_classifier, test_feats)\n0.91000000000000003\n>>> nb_precisions, nb_recalls = precision_recall(nb_classifier, test_feats)\n>>> nb_precisions['pos']\n0.89883268482490275\n>>> nb_precisions['neg']\n0.92181069958847739\n>>> nb_recalls['pos']\n0.92400000000000004\n>>> nb_recalls['neg']\n0.89600000000000002\n```", "```py\n>>> me_classifier = MaxentClassifier.train(train_feats, algorithm='megam', trace=0, max_iter=10)\n>>> accuracy(me_classifier, test_feats)\n0.88200000000000001\n>>> me_precisions, me_recalls = precision_recall(me_classifier, test_feats)\n>>> me_precisions['pos']\n0.88663967611336036\n>>> me_precisions['neg']\n0.87747035573122534\n>>> me_recalls['pos']\n0.876\n>>> me_recalls['neg']\n0.88800000000000001\n```", "```py\n>>> dt_classifier = DecisionTreeClassifier.train(train_feats, binary=True, depth_cutoff=20, support_cutoff=20, entropy_cutoff=0.01)\n>>> accuracy(dt_classifier, test_feats)\n0.68600000000000005\n>>> dt_precisions, dt_recalls = precision_recall(dt_classifier, test_feats)\n>>> dt_precisions['pos']\n0.6741573033707865\n>>> dt_precisions['neg']\n0.69957081545064381\n>>> dt_recalls['pos']\n0.71999999999999997\n>>> dt_recalls['neg']\n0.65200000000000002\n```", "```py\nimport itertools\nfrom nltk.classify import ClassifierI\nfrom nltk.probability import FreqDist\n\nclass MaxVoteClassifier(ClassifierI):\n  def __init__(self, *classifiers):\n    self._classifiers = classifiers\n    self._labels = sorted(set(itertools.chain(*[c.labels() for c in classifiers])))\n\n  def labels(self):\n    return self._labels\n\n  def classify(self, feats):\n    counts = FreqDist()\n\n    for classifier in self._classifiers:\n      counts.inc(classifier.classify(feats))\n\n    return counts.max()\n```", "```py\n>>> from classification import MaxVoteClassifier\n>>> mv_classifier = MaxVoteClassifier(nb_classifier, dt_classifier, me_classifier)\n>>> mv_classifier.labels()\n['neg', 'pos']\n>>> accuracy(mv_classifier, test_feats)\n0.89600000000000002\n>>> mv_precisions, mv_recalls = precision_recall(mv_classifier, test_feats)\n>>> mv_precisions['pos']\n0.8928571428571429\n>>> mv_precisions['neg']\n0.89919354838709675\n>>> mv_recalls['pos']\n0.90000000000000002\n>>> mv_recalls['neg']\n0.89200000000000002\n```", "```py\n>>> from nltk.corpus import reuters\n>>> len(reuters.categories())\n90\n```", "```py\nfrom nltk.corpus import reuters\n\ndef reuters_high_info_words(score_fn=BigramAssocMeasures.chi_sq):\n  labeled_words = []\n\n  for label in reuters.categories():\n    labeled_words.append((label, reuters.words(categories=[label])))\n\n  return high_information_words(labeled_words, score_fn=score_fn)\n```", "```py\ndef reuters_train_test_feats(feature_detector=bag_of_words):\n  train_feats = []\n  test_feats = []\n\n  for fileid in reuters.fileids():\n    if fileid.startswith('training'):\n      featlist = train_feats\n    else: # fileid.startswith('test')\n      featlist = test_feats\n\n    feats = feature_detector(reuters.words(fileid))\n    labels = reuters.categories(fileid)\n    featlist.append((feats, labels))\n\n  return train_feats, test_feats\n```", "```py\n>>> from featx import reuters_high_info_words, reuters_train_test_feats\n>>> rwords = reuters_high_info_words()\n>>> featdet = lambda words: bag_of_words_in_set(words, rwords)\n>>> multi_train_feats, multi_test_feats = reuters_train_test_feats(featdet)\n```", "```py\ndef train_binary_classifiers(trainf, labelled_feats, labelset):\n  pos_feats = collections.defaultdict(list)\n  neg_feats = collections.defaultdict(list)\n  classifiers = {}\n\n  for feat, labels in labelled_feats:\n    for label in labels:\n      pos_feats[label].append(feat)\n\n    for label in labelset - set(labels):\n      neg_feats[label].append(feat)\n\n  for label in labelset:\n    postrain = [(feat, label) for feat in pos_feats[label]]\n    negtrain = [(feat, '!%s' % label) for feat in neg_feats[label]]\n    classifiers[label] = trainf(postrain + negtrain)\n\n  return classifiers\n```", "```py\n>>> from classification import train_binary_classifiers\n>>> trainf = lambda train_feats: MaxentClassifier.train(train_feats, algorithm='megam', trace=0, max_iter=10)\n>>> labelset = set(reuters.categories())\n>>> classifiers = train_binary_classifiers(trainf, multi_train_feats, labelset)\n>>> len(classifiers)\n90\n```", "```py\nfrom nltk.classify import MultiClassifierI\n\nclass MultiBinaryClassifier(MultiClassifierI):\n  def __init__(self, *label_classifiers):\n    self._label_classifiers = dict(label_classifiers)\n    self._labels = sorted(self._label_classifiers.keys())\n\n  def labels(self):\n    return self._labels\n\n  def classify(self, feats):\n    lbls = set()\n\n    for label, classifier in self._label_classifiers.iteritems():\n      if classifier.classify(feats) == label:\n        lbls.add(label)\n\n    return lbls\n```", "```py\n>>> from classification import MultiBinaryClassifier\n>>> multi_classifier = MultiBinaryClassifier(*classifiers.items())\n```", "```py\nimport collections\nfrom nltk import metrics\n\ndef multi_metrics(multi_classifier, test_feats):\n  mds = []\n  refsets = collections.defaultdict(set)\n  testsets = collections.defaultdict(set)\n\n  for i, (feat, labels) in enumerate(test_feats):\n    for label in labels:\n      refsets[label].add(i)\n\n    guessed = multi_classifier.classify(feat)\n\n    for label in guessed:\n      testsets[label].add(i)\n\n    mds.append(metrics.masi_distance(set(labels), guessed))\n\n  avg_md = sum(mds) / float(len(mds))\n  precisions = {}\n  recalls = {}\n\n  for label in multi_classifier.labels():\n    precisions[label] = metrics.precision(refsets[label], testsets[label])\n    recalls[label] = metrics.recall(refsets[label], testsets[label])\n\n  return precisions, recalls, avg_md\n```", "```py\n>>> from classification import multi_metrics\n>>> multi_precisions, multi_recalls, avg_md = multi_metrics(multi_classifier, multi_test_feats)\n>>> avg_md\n0.18191264129488705\n```", "```py\n>>> multi_precisions['zinc']\n1.0\n>>> multi_recalls['zinc']\n0.84615384615384615\n>>> len(reuters.fileids(categories=['zinc']))\n34\n>>> multi_precisions['sunseed']\n0.5\n>>> multi_recalls['sunseed']\n0.20000000000000001\n>>> len(reuters.fileids(categories=['sunseed']))\n16\n>>> multi_precisions['rand']\nNone\n>>> multi_recalls['rand']\n0.0\n>>> len(reuters.fileids(categories=['rand']))\n3\n```"]