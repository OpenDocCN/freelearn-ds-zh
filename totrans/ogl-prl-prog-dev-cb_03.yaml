- en: Chapter 3. Understanding OpenCL Data Types
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we are going to cover the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Initializing the OpenCL scalar data types
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Initializing the OpenCL vector data types
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using OpenCL scalar types
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding OpenCL vector types
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vector and scalar address spaces
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configuring your OpenCL projects to enable the double data type
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: OpenCL supports a wide range of data types derived from the C programming language.
    They are widely classified into two groups called scalars and vectors. Scalars
    are basically elemental values, whereas vectors are a collection of elemental
    values and a good thing about vectors is that many OpenCL SDK vendors have provided
    automated vectorization which allows the values to be loaded into wide, that is,
    128-bit, 256-bit, or 512-bit registers for consumption.
  prefs: []
  type: TYPE_NORMAL
- en: OpenCL scalar integral data types consists of the signed and unsigned types
    of `bool`, `char`, `short`, `int`, `long`, `uchar`, `ushort`, `uint`, and `ulong`
    respectively; for floating-point values there are `float`, `half`, and `double`.
    To represent those types in your host program, you have to just prepend the letters
    `cl_` to each type, which the OpenCL compiler will understand.
  prefs: []
  type: TYPE_NORMAL
- en: OpenCL vector data types consists of a multiple of scalar data integral and
    floating-point data types and they are `char<N>`, `short<N>`, `int<N>`, `long<N>`,
    `uchar<N>`, `ushort<N>`, `uint<N>`, `ulong<N>`, and `float<N>` where `<N>` represents
    a value of 2, 3, 4, 8, or 16\. Similarly, you will represent those types in your
    host program by prepending the letters `cl_` to the data types.
  prefs: []
  type: TYPE_NORMAL
- en: In both the cases, if you prefer the explicit form of an `unsigned` type, then
    you can replace the letter `u` in the data types with the keyword `unsigned`.
  prefs: []
  type: TYPE_NORMAL
- en: Initializing the OpenCL scalar data types
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we are going to demonstrate various ways to initialize scalar
    types, and most of the techniques will make a lot of sense if you already have
    programmed using the C programming language.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In addition to the regular data types defined in C which works in OpenCL, the
    standard have added a few more data types in addition to the ones we have mentioned
    in the previous section, and the following table illustrates them:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `half` | It is a 16-bit floating-point. The `half` data type must conform
    to the IEEE 754-2008 `half precision` storage format. |'
  prefs: []
  type: TYPE_TB
- en: '| `bool` | It is a conditional data type that evaluates to true or false. The
    value true expands to an integer 1 while false expands to 0. |'
  prefs: []
  type: TYPE_TB
- en: '| `size_t` | It is the unsigned integer type of the result of the sizeof operator.
    This can be a 32-bit or 64-bit unsigned integer. |'
  prefs: []
  type: TYPE_TB
- en: '| `ptrdiff_t` | It is a 32-bit or 64-bit signed integer and usually it is used
    to represent the result of subtracting two points |'
  prefs: []
  type: TYPE_TB
- en: '| `intptr_t` | It is a 32-bit or 64-bit signed integer with the property that
    any valid point to avoid can be converted to this type, and then converted back
    to point to void and the result will compare equal to the original pointer. |'
  prefs: []
  type: TYPE_TB
- en: '| `uintptr_t` | It is a 32-bit or 64-bit unsigned integer that has got the
    same property as `intptr_t`. |'
  prefs: []
  type: TYPE_TB
- en: 'OpenCL allows the following data types to be used interchangeably in your source
    codes:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Type in OpenCL | Type in application |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `bool` | `n/a` |'
  prefs: []
  type: TYPE_TB
- en: '| `char` | `cl_char` |'
  prefs: []
  type: TYPE_TB
- en: '| `unsigned char` `, uchar` | `cl_uchar` |'
  prefs: []
  type: TYPE_TB
- en: '| `short` | `cl_short` |'
  prefs: []
  type: TYPE_TB
- en: '| `unsigned short` `, ushort` | `cl_ushort` |'
  prefs: []
  type: TYPE_TB
- en: '| `int` | `cl_int` |'
  prefs: []
  type: TYPE_TB
- en: '| `unsigned int` `, uint` | `cl_uint` |'
  prefs: []
  type: TYPE_TB
- en: '| `long` | `cl_long` |'
  prefs: []
  type: TYPE_TB
- en: '| `unsigned long` `, ulong` | `cl_ulong` |'
  prefs: []
  type: TYPE_TB
- en: '| `float` | `cl_float` |'
  prefs: []
  type: TYPE_TB
- en: '| `double` | `cl_double` |'
  prefs: []
  type: TYPE_TB
- en: '| `half` | `cl_half` |'
  prefs: []
  type: TYPE_TB
- en: '| `size_t` | `n/a` |'
  prefs: []
  type: TYPE_TB
- en: '| `ptrdiff_t` | `n/a` |'
  prefs: []
  type: TYPE_TB
- en: '| `intptr_t` | `n/a` |'
  prefs: []
  type: TYPE_TB
- en: '| `uintptr_t` | `n/a` |'
  prefs: []
  type: TYPE_TB
- en: '| `void` | `void` |'
  prefs: []
  type: TYPE_TB
- en: 'So following are a few examples on how you can possibly declare and define
    scalar data types in your source code in the kernels and host:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: In the previous chapter, *Understanding OpenCL Data Transfer and Partitioning*,
    we spent some time discussing about data types and how alignment works or in other
    words, how data misalignment can affect the performance. Scalar data types are
    always aligned to the size of the data type in bytes. Built-in data types whose
    sizes are not a power of two must be aligned to the next larger power of two.
    That is, a `char` variable will be aligned a 1-byte boundary, a `float` variable
    will be aligned to a 4-byte boundary.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If your application needs user-defined data types, then you need to place `__attribute__((aligned))`
    to those types; refer to the [Chapter 2](ch02.html "Chapter 2. Understanding OpenCL
    Data Transfer and Partitioning"), *Understanding OpenCL Data Transfer and Partitioning*
    for more details.
  prefs: []
  type: TYPE_NORMAL
- en: 'In OpenCL, several operators convert operand values from one type to another,
    and this is commonly referred to as implicit conversions; another way is to apply
    a cast operation on operands or on the result of a binary operation. Implicit
    conversions between scalar built-in types are supported with the exception of
    `void` and `half` data types. What it means is shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Or
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'You can use both forms in your application code. You can coerce a data type
    to another data type in OpenCL too, just as you can do in the C programming language.
    Refer to the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'You can also coerce a scalar data type to a vector data type in OpenCL with
    the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Initializing the OpenCL vector data types
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Vectors are extremely powerful to an OpenCL programmer because it allows the
    hardware to bulk load/store data to/from memory; such computations typically take
    advantage of the algorithms spatial and temporal locality properties. In this
    recipe, we are going to familiarize ourselves with creating various types of vectors.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You can initialize a vector in two primary manners and they are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Vector literal
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vector composition
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Creating a vector literal simply means that you can construct your vector of
    whatever type you wish as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Another way to initialize a vector is to do it via a scalar value as shown
    in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'You can also create vectors in the following fashion:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The data type on the left-hand-side and right-hand-side must be same or the
    OpenCL compiler will issue a complaint.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Vectors have another remarkable property, and that is, you can access the individual
    components through indexes, that is to say if you wish to access each component
    of a `float4` vector, `v`, then you would do so via `v.x`, `v.y`, `v.z`, `v.w`
    respectively, and for larger vectors of 8 or 16 elements we would access those
    individual elements via `v.s0`, `v.s1` through to `v.s7`, and `v.s0`, `v.s1`,
    `v.sa` through to `v.sf` respectively. Hence, vectors of type `char2`, `uchar2`,
    `short2`, `ushort2`, `int2`, `uint2`, `long2`, `ulong2`, and `float2` can access
    their `.xy` elements.
  prefs: []
  type: TYPE_NORMAL
- en: 'Following is another way of creating vectors and that is through composition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'On a similar note, you can use numerical indexes to reference the components
    in your vector and create vectors in turn. The following table shows a list of
    indexes for the various vector data types:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Vector components | Numeric indexes that can be used |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 2-component | `0, 1` |'
  prefs: []
  type: TYPE_TB
- en: '| 3-component | `0, 1, 2` |'
  prefs: []
  type: TYPE_TB
- en: '| 4-component | `0, 1, 2, 3` |'
  prefs: []
  type: TYPE_TB
- en: '| 8-component | `0, 1, 2, 3, 4, 5, 6, 7` |'
  prefs: []
  type: TYPE_TB
- en: '| 16-component | `0, 1, 2, 3, 4, 5, 6, 7, 8, 9, a, A, b, B, c, C, d, D, e,
    E, f, F` |'
  prefs: []
  type: TYPE_TB
- en: 'To use these numerical indexes, you have to precede by the letter *s* or *S*,
    and following are a few quick examples on how to create vectors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: There's more…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Lastly, vector data types can use the `.lo` (or `.even`) and `.hi` (or `.odd`)
    suffixes to compose new vector types, or to combine smaller vector types to a
    larger vector type. Multiple levels of `.lo` (or `.even`) and `.hi` (or `.odd`)
    suffixes can be used until they refer to a scalar term. The `.lo` and `.hi` suffix
    refers to the lower and upper halves of a vector. The `.even` and `.odd` suffixes
    of a vector refer to the even and odd elements of a vector. Following are the
    examples of vector creation via composition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Vectors are disallowed from implicit conversions so you cannot perform the
    following operation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Explicit casts between vector types are also disallowed, and in fact the only
    form of explicit cast to a vector type is when you''re initializing a vector with
    a scalar:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: If you were to extract components of a 3-component vector type via the suffixes
    `.lo` (or `.even`), `.hi` (or `.odd`), then the 3-component vector type would
    behave as if it is a 4-component vector type with the exception that the `w` component
    would be undefined.
  prefs: []
  type: TYPE_NORMAL
- en: Using OpenCL scalar types
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The scalar data types are quite similar to what you would expect if you were
    programming in the C language. However, two topics deserve more attention and
    we'll touch on that in this recipe; we'll look at the `half` data type and examine
    how OpenCL devices might order their data.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Many of the OpenCL compliant devices are actually little-endian architectures,
    and developers need to ensure that their kernels are tested on both big-endian
    and little-endian devices to ensure source compatibility with current and future
    devices. Let's use a simple example to illustrate endian-ness.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Consider a variable `x` that holds the value `0x01234567` and the address of
    `x` starts at `0x100`. In computer architecture terminology, the value `0x01`
    is the **most significant byte** ( **MSB**) and `0x67` is the **least significant
    byte** ( **LSB**). Big-endian storage scheme stores the MSB first till it meets
    the LSB and little-endian storage schemes stores the LSB first till it meets the
    MSB.
  prefs: []
  type: TYPE_NORMAL
- en: Big-endian
  prefs: []
  type: TYPE_NORMAL
- en: '| **Address** | 0x100 | 0x101 | 0x102 | 0x103 |   |'
  prefs: []
  type: TYPE_TB
- en: '| **Values** | 0x01 | 0x23 | 0x45 | 0x67 | … |'
  prefs: []
  type: TYPE_TB
- en: Little-endian
  prefs: []
  type: TYPE_NORMAL
- en: '| **Address** | 0x100 | 0x101 | 0x102 | 0x103 |   |'
  prefs: []
  type: TYPE_TB
- en: '| **Values** | 0x67 | 0x45 | 0x23 | 0x01 | … |'
  prefs: []
  type: TYPE_TB
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Review the full code listed in `Ch3/byte_ordering/show_bytes.c`, compile the
    code by running the commands `cmake` and `make` in that order; that will generate
    a binary named `ShowBytes`, and then run that program to see its output. This
    code will print out a series of output, and depending on the endian-ness of the
    architecture, you will notice different byte orderings.
  prefs: []
  type: TYPE_NORMAL
- en: 'Refer to the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Since you''ve understood how byte ordering affects the way data (scalar) is
    being read and written; let''s take a look at how the ordering affects vector
    data types in OpenCL. With vector data types, both, the order of the bytes within
    each value and the order of the values with respect to one another are reversed.
    Using an example of a `uint4` vector which contains the values `0x000102030405060708090A0B0C0D0E0F`,
    at address `0x100`, following table shows how a little-endian storage scheme would
    look:'
  prefs: []
  type: TYPE_NORMAL
- en: '| 0x100 | 0x104 | 0x108 | 0x1b0 |'
  prefs: []
  type: TYPE_TB
- en: '| 0x0F0E0D0C | 0x0B0A0908 | 0x07060504 | 0x3020100 |'
  prefs: []
  type: TYPE_TB
- en: Awareness of this fact is important if you are working with data compression
    and computer-imaging algorithms since these two classes of algorithms have a significant
    amount of byte-level operations and you don't want to be bitten by these issues.
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `half-precision` data type, conveniently called `half` actually has half
    the storage and precision of a regular `float` type. The `half` type is IEEE754-2008
    compliant and was first introduced by NVIDIA, and Industrial Light and Magic.
    The only thing you can do with this type is to declare a pointer to a buffer that
    contains `half` values; those values must be finite and normal numbers, de-normalized
    numbers, infinities, and NaN.
  prefs: []
  type: TYPE_NORMAL
- en: You can choose to use the vector load and store functions such as `vload_half`,
    `vload_halfn`, `vstore_half`, and so on. However, bear in mind that the load/store
    operation will create an intermediate floating -point value.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `load` function read the `half` values from memory and converts it to a
    regular `float` value. The `store` functions take a `float` as an input, convert
    it to a `half` value and store that value into memory.
  prefs: []
  type: TYPE_NORMAL
- en: 'To determine if your device supports this, you can run the program in `Ch2/device_extension/device_extensions`,
    and the output should contain `cl_khr_fp16`; alternatively you can query the device
    by passing the parameter `CL_DEVICE_EXTENSIONS` to `clGetDeviceInfo`. Following
    is the code snippet from `Ch2/device_extensions/device_extensions.c`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Understanding OpenCL vector types
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When you start working through your OpenCL project you are inevitably going
    to use both the scalar and vector data types to model the algorithm. Scalars work
    like any variable declaration/definition you may have come across in most of the
    programming languages, and you should think of vectors as a wide container that
    can deliver all items in that container in parallel, and the one thing that differentiates
    scalars and vectors is the fact that when an operation is applied to a scalar,
    it affects just a single value while the same operation applied to a vector affects
    all items in it in parallel.
  prefs: []
  type: TYPE_NORMAL
- en: In the modern processors, there exist a specialized hardware unit that processes
    more data per cycle and they are often termed as **Single Instruction Multiple
    Data** (**SIMD**) or known as **Streaming SIMD Extensions** (**SSE**) which is
    intel's implementation of SIMD. The advantage that SIMD instructions provide is
    that they allow multiple values to be operated upon in a large register in a cycle;
    quite often there are many such units, thus increasing performance of the program.
    We should be clear that SIMD describes a mechanism that allows parallelism to
    occur gleaned from Flynn's taxonomy, while SSE describes how two CPU processor
    manufacturers namely, Intel and AMD implemented SIMD.
  prefs: []
  type: TYPE_NORMAL
- en: The first part of the story is to tell you how OpenCL kernels run on the CPUs
    before we reveal how it would work on the GPU, and for now we place our attention
    on the Intel CPU architecture. On these architectures, OpenCL sees a single device
    with multiple compute units and if you are guessing each core is a compute unit
    then you're correct and hence, your kernels run on all compute units unless you
    are using the device fission extension, which is new in OpenCL 1.2.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Device fission (`cl_khr_device_fission`) which is new in OpenCL 1.2 is currently
    supported by multicore CPUs by Intel, AMD, and IBM Cell Broadband. GPUs are currently
    not supported.
  prefs: []
  type: TYPE_NORMAL
- en: The next part of the story is to describe, how OpenCL kernels would run on GPUs
    manufactured by AMD, and we focus on the AMD GPU we used for this book which is
    based on AMD's Southern Island Architecture which includes their Radeon HD 7900,
    7800, and 7700 GPUs; on a side note, you might wish to consult NVIDIA's website
    for more product details pertaining to their GPUs at [www.nvidia.com](http://www.nvidia.com).
  prefs: []
  type: TYPE_NORMAL
- en: Kernels basically execute instructions that are either scalar-based or vector-based,
    and work is assigned to a compute unit in blocks of 64 work items, which is termed
    as wavefront. A wavefront has a single program counter, and is considered as a
    small unit of work and what that means is that they execute in lock-step.
  prefs: []
  type: TYPE_NORMAL
- en: When your application passes workloads to the GPU, it must first compile the
    kernel and load it into memory. It must also bind buffers for the source and result
    data, and finally it would decide how to execute the given workload on the GPU.
    When the workload is to be executed, the GPU divides the input domain into blocks
    of 64 threads aka wavefronts and dispatches them to the **compute unit** (**CU**).
    The kernel is next fetched into the instruction cache and the compute unit begins
    dispatching instructions to the execution units; each compute unit can work on
    multiple wavefronts in parallel, simultaneously processing vector and scalar ALU
    computations, as well as memory accesses. The wavefront continues executing until
    the end of the kernel is reached, when the wavefront is terminated and a new one
    can take its place on the GPU.
  prefs: []
  type: TYPE_NORMAL
- en: Taking into account the fact that memory accesses by wavefronts happens in parallel,
    you will expect some sort of latency to occur and the processor is pretty clever
    in dealing with that situation, and what it does is executing many wavefronts
    in parallel and it works such that if one wavefront is waiting for results from
    the memory, other wavefronts can issue memory requests, and they can execute ALU
    operations in parallel with outstanding memory requests if and only if they are
    independent calculations. Factors that increase the amount of parallelism that
    can be extracted from the program varies, but one of them would be the actual
    number of hardware units available for parallel computation and in OpenCL terminology,
    it is known as the CU and in both CPUs and GPUs they are basically the processor.
  prefs: []
  type: TYPE_NORMAL
- en: 'A compute unit is the basis of parallel computation, and in the Southern Island
    Architecture which hosts other products, the number of compute units varies and
    each compute unit basically contains the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Scalar ALU and scalar **GPRs** (**General-Purpose Registers**) aka **SGPRs**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Four SIMDs, each consisting of a vector ALU and vector GPRs, aka VGPRs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Local memory
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Read/write access to vector memory through a Level-1 cache
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Instruction cache, which is shared by four CUs, that is, compute units
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Constant cache, which is shared by four CUs, that is, compute units
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now we will focus on the vector operations on GPUs, which include ALU and memory
    operations. Each of the four SIMDs contains a vector-ALU that operates on wavefronts
    over four cycles; each SIMD also can host ten wavefronts in flight, that is, one
    CU can have forty wavefronts executing in parallel. In the AMD GPU based on the
    Southern Island Architecture used for this book which is the AMD HD 7870, we have
    20 compute units and we know now that each CU holds four SIMDs and each SIMD would
    execute a wavefront means that we can have 20 x 4 x 10 x 64 = 51,200 work items
    at any one time, and if you were to imagine that each work item is at the stage
    of executing vector operations then the parallelism offered by GPUs is considerably
    larger than that of the CPU; the specific CPU we are referring to is the Intel
    Xeon Phi which has 60 cores and each core hosts 4 work items which provides 60
    x 4 = 240 work items; be aware that we're not stating that GPUs are superior to
    CPUs since each device has its niche but we illustrate these numbers to demonstrate
    a simple fact that GPU has a higher throughput than the CPU.
  prefs: []
  type: TYPE_NORMAL
- en: 'Having said all that, we are going to see an example soon but first recall
    that vector operations are component-wise and that vectors can be accessed via
    numeric indexes, and each index can be combined into larger group of indices to
    perform a store/load to/from memory. Refer to the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: The component-wise manner in which vectors can be aggregated to perform an operation
    without code verbosity actually helps the programmer in their daily work and increases
    productivity. Next, we can a dive into how vector types are translated to utilize
    your hardware.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The demonstration we are going to describe has two parts in it. First, we are
    going to use the Intel OpenCL compiler on Windows to demonstrate the implicit
    vectorization of the kernel code; secondly, we are going to demonstrate how to
    enable native vector type notation in your code to express the desire to generate
    vectorized code using the AMD APP SDK v2.7 or v2.8 on Linux.
  prefs: []
  type: TYPE_NORMAL
- en: We combined these two approaches with the intention to solve the problem of
    transferring a large input array from one part of the device memory to another
    part of the device memory, and finally we extract and compare them for equality.
    As before, we would prepare the data structures for transfers on the host code
    and write a suitable OpenCL kernel to actually transfer the memory contents across.
    The source can be found in `Ch3/vectorization`, and we build the program using
    the AMD APP SDK.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Readers who are interested in the OpenCL code generation for AMD CPU and GPU
    platforms should consult the `AMD CodeXL` product as the AMD APP Kernel Analyzer
    has been retired. You may wish to consult the AMD Intermediate Language Manual
    in conjunction when you study the intermediate language output.
  prefs: []
  type: TYPE_NORMAL
- en: 'Implicit vectorization is a required feature that is supported by all the compliant
    OpenCL compiler implementations, and the reason we chose to demonstrate this feature
    with the Intel OpenCL compiler is the fact that the generated SIMD instructions
    are more likely to be recognized by the reader than would the intermediate code
    generated by other compiler implementations such as AMD or NVIDIA''s. The kernel
    code we have for you can be found in `Ch3/vectorization/vectorization.cl`, and
    we reveal it as in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: This kernel's main action is to transfer the contents from one place to another,
    and it does this by transporting it in parallel using two vectors of eight floats
    each and you will notice that we use the vector component notation to state these
    memory transfers explicitly.
  prefs: []
  type: TYPE_NORMAL
- en: In the next demonstration, we swing from the kernel code back to the host code
    assuming that the developer has a desire to control the code generation in a more
    explicit manner; and this can be done through the native vector type notation.
  prefs: []
  type: TYPE_NORMAL
- en: 'We ask the reader to refer to the section *There''s more…* for details, but
    the demonstration here rests on the assumption that the developer would like to
    hand tune the procedure that handles data validation once the memory transfers
    have been completed in the device, and this function can be found in `Ch3/vectorization/vectorization.c`
    named `valuesOK` and the following code is how it is implemented:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Implicit vectorization through the Intel OpenCL compiler is relatively easy
    and the purpose of this simple example, we have chosen to install it on the Windows
    operating system. You can download the compiler from [http://software.intel.com/en-us/vcsource/tools/opencl](http://software.intel.com/en-us/vcsource/tools/opencl).
  prefs: []
  type: TYPE_NORMAL
- en: 'To witness how the implicit vectorization can be achieved through this compiler,
    you would copy and paste the kernel code (the previous code) into the editor pane
    of the GUI and start the compilation. Once compiled, you would be able to view
    the generated code by clicking on the **ASM** or **LLVM** buttons on the GUI.
    An example of this is shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it…](img/4520OT_03_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The next item is to hand-tune our data validation code, `valuesOK`, to exhibit
    vectorization. This example is only meant to illustrate how one would go about
    accomplishing something similar to this and you don't have to do anything besides
    invoking `make` in the directory `Ch3/vectorization`, and an executable vectorization
    will be dropped into the filesystem to which we'll next dissect it.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If you are running OpenCL 1.1 on Mac OSX 10.7, then passing the flag `–cl-auto-vectorizer-enable`
    to `clBuildProgram` as a build option will vectorize the kernels that will execute
    on the CPU. The SIMD instructions will be similar to the ones you see in this
    recipe.
  prefs: []
  type: TYPE_NORMAL
- en: 'Hand-tuning your code in such a manner basically turns implicit vectorization
    off, and you will need to judge for your scenario whether the effort justifies
    with respects to the complexity of the issue. To view the generated SIMD code,
    it would be best to put the program under a debugger, and on Linux the best debugger
    will be the GNU GDB. You basically load the program into the debugger and issue
    the command `disassemble /m valuesOK` to verify that the SIMD instructions were
    indeed generated. Following is a sample `gdb` session where the disassembly is
    interleaved with the source code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Implicit vectorization is a piece of complicated software written into the compiler
    provided by the implementation, and is definitely hardware dependent and often
    represented by an **intermediate language** (**IL**) that's proprietary to the
    processor manufacturer and to our disappointment, not very well documented so
    we like to focus on how native vector type notation works in more detail.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The interested reader is however invited to explore the ILs developed by AMD
    and NVIDIA, which are known as AMD IL, and NVIDIA's PTX respectively.
  prefs: []
  type: TYPE_NORMAL
- en: This method of hand-tuning allows the developer to reference the built-in vector
    data type of the platform they're working on instead of relying on the OpenCL
    compiler to auto-vectorize the code, and may bring about performance benefits.
    The manner in which it is being done in OpenCL so far is to abstract these differences
    into platform dependent macros in the file `cl_platform.h`. Let's work out how
    this would work in our example.
  prefs: []
  type: TYPE_NORMAL
- en: 'The example, we saw previously, was tested on the Ubuntu Linux 12.04 operating
    system with an Intel Core i7 CPU and an AMD Radeon HD 7870 GPU, but since our
    example focuses on explicit vectorization on the host code, it implies that we
    need to know the width of SIMD vectors based on the Intel instruction set. We
    know this to be 128-bits and what this means is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code gets translated to the following C code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: The function `__mm_add_ps` is the SIMD function for adding two vectors by adding
    their single precision floating-point values component-wise in this manner and
    at first hand, it will look like syntax sugar but this is one of the many ways
    in which OpenCL provides cross platform compatibility and removes the pain of
    delivering customized vectorized code for various processor architectures so in
    this way a façade is actually a good thing.
  prefs: []
  type: TYPE_NORMAL
- en: Coming back to the problem we are trying to solve, which is to vectorize the
    procedure for performing data validation for the input and output arrays. In our
    example, we chose arrays or rather vectors that can contain 8 floats and what
    we will like to do is to examine them and compare them for equality. Using the
    native vector type notation in OpenCL, we know that the vector-of-8 can be decomposed
    into vector-of-4 elements because, OpenCL stipulates that if a platform can support
    a native vector type then the macro is identified in the `cl_platform.h` file
    by the name `__CL_<TYPEN>`, where `<TYPEN>` can be `UCHAR16`, `CHAR16`, `INT4`,
    `FLOAT4`, that is, the vectorized primitive types and in general, you can access
    the native components using the `.v<N>` subvector notation where `<N>` is the
    number of elements in the subvector.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using this newly found information, we can dissect the program we saw previously
    with the fact that the memory content of the original host memory is represented
    by the `cl_float8 *` to while the copied memory contents from host to device are
    held by the `cl_float8*` from:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'We need to iterate through the vectors in both input and output arrays and
    proceed to extract the first and second vector-of-4s from the host pointer as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we extract the first and second vector-of-4s from the device pointer as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we compare each of the halves by using the SSE API `__mm_cmp_neq_ps`,
    and keep the result of each test into the variables test and test2 as shown in
    the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we compare those results as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: There's more…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Another part of the vectorization story that we wanted to tell you is that you,
    the developer, has the option of controlling the auto-vectorization by providing
    an explicit compiler hint to the kernel code. This can be useful if you want to
    hand-tune the vectorization of your code.
  prefs: []
  type: TYPE_NORMAL
- en: 'The compiler hint we are referring to is the `vec_type_hint(<type>)` where
    `<type>` is any of the built-in scalar or vector data types we mentioned previously.
    The attribute `vec_type_hint(<type>)` represents the computation width of the
    kernel and if it''s not specified, the kernel is assumed to have the `vec_type_hint(int)`
    qualifier applied to the kernel, that is, 4-bytes wide. The following code snippets
    illustrate how the computation width of the kernel changes from 16-bytes to 8-bytes
    and finally to 4-bytes which happens to be the default:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'For you, the developer, to be able to use this, you will need to know the width
    of the vector units in your platform which could be running on a CPU or GPU. In
    the next diagram, we have two scenarios where we assume that both the `__kernel`
    functions are declared with `__attribute_((vec_type_hint(float4)))` and `__attribute_((vec_type_hint(char4)))`
    respectively. Furthermore, we assumed that the kernel is running on 256-bit wide
    registers and how the auto-vectorizer might choose to run one or more work items
    so that the register''s usage is maximized; this is of course dependent on the
    compiler''s implementation. The following figure is a conceptual view of how the
    OpenCL compiler might generate work items to consume the data in the wide registers:'
  prefs: []
  type: TYPE_NORMAL
- en: '![There''s more…](img/4520OT_03_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: In the native vector type notation method for explicit vectorization, we mentioned
    that native vector types are identified in `cl_platform.h` by the `__CL_<TYPEN>__`
    preprocessor symbols aka C macros but, we haven't told you how we came to use
    the SSE instructions in the code example. Let's now find out why, and we need
    to reference the `cl_platform.h` defined by the OpenCL 1.2 standard (which you
    can download from [http://www.khronos.org/registry/cl/api/1.2/cl_platform.h](http://www.khronos.org/registry/cl/api/1.2/cl_platform.h))
  prefs: []
  type: TYPE_NORMAL
- en: The code example was tested on the Ubuntu Linux 12.04 64-bit operating system
    with an Intel Core i7 CPU and a AMD Radeon HD 7870 GPU, and we should ignore the
    presence of the GPU as it has no relevance other than to inform you the machine
    setup.
  prefs: []
  type: TYPE_NORMAL
- en: 'What this setup tells us is that we have a SSE-capable instruction set and
    as a convention adopted by the UNIX and GCC community in general, is to look for
    the `__SSE__` preprocessor symbol and we indeed do that as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: From the preceding code snippet, we know we should be focusing on the statement
    1 as it has provided us the indicative width of the SIMD vectors, and we also
    know that by convention `__m128` indicates that its vector's width is 128-bits;
    other values includes 64-bits and 256-bits. We should also be careful to contain
    the explicit vectorization within the preprocessor guard, as a best practice,
    that is, `#ifdef __CL_FLOAT4__`.Using this understanding, we can proceed to search
    for the appropriate SSE APIs that allows us to manipulate data values of the desired
    width. The interested reader is invited to check the Intel Developer Manuals and
    AMD Developer Manuals, and explore how these ISAs compare and most importantly
    where they differ.
  prefs: []
  type: TYPE_NORMAL
- en: Vector and scalar address spaces
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have understood how to use scalars and vectors in OpenCL, it''s
    time to examine the OpenCL''s defined four address spaces: `__global`, `__local`,
    `__constant`, and `__private` in which vectors and scalars can exist in. These
    spaces are mapped to the memory units and hence, limited by the actual resource
    on the device and define how work items can access memory.'
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Following is a conceptual diagram of the various memory domains:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Getting ready](img/4520OT_03_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The **Global Memory** and **Constant Memory** found in the lower-half of the
    preceding diagram corresponds to the `__global` and `__constant` domain. The **Local
    Memory** associated with each compute unit in OpenCL (that executes the kernel
    code) will have a memory space that's shared by all work items in the block which
    corresponds to the `__local` memory space while each processing element will have
    its own namespace to store data and, it is represented by the `__private` memory
    space. Be aware that there is no way in which a work item can access the (`__private`)
    memory space of another work item regardless of whether they're in the same work
    group or not, the same can be said of shared memory, that is, `__local` memory
    where no two work groups can inspect the other's memory.
  prefs: []
  type: TYPE_NORMAL
- en: Each compute unit in the device has a certain number of processing elements
    which executes work items and the compute unit as a whole would access the local,
    constant, or global memory space as determined by the computation. Each processing
    element (work group or work item), stores its own private variables in its private
    memory space.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The `__global` address space name is used to refer to memory objects allocated
    from the global memory pool. To determine the actual amount of resources available
    on the device, you need to pass the parameter `CL_DEVICE_GLOBAL_MEM_SIZE` to `clGetDeviceInfo`.
    The following snippet is drawn from `Ch2/device_details/device_details.c`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: The `__local` address space name is used to describe variables that need to
    be allocated in the local memory and shared by all work items of a work group.
    You can determine the maximum size of this space by passing the parameter `CL_DEVICE_MAX_LOCAL_MEM_SIZE`
    to `clGetDeviceInfo`.
  prefs: []
  type: TYPE_NORMAL
- en: The `__constant` address space name is used to describe non-mutable variables
    that need to be allocated as read-only in global memory, and can be read by all
    work items during the kernel's execution. You can determine the maximum size of
    this space by passing the parameter `CL_DEVICE_MAX_CONSTANT_BUFFER_SIZE` to `clGetDeviceInfo`.
    This address space is useful if there is a specific value that does not change
    and is needed by the kernel functions.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `__private` address space is used to describe objects private-only distinct
    work items; hence work items cannot inspect one another''s variables if they were
    marked by `__private`. By default, variables inside a kernel function not declared
    with any address space qualifiers such as: `__global`, `__local`, or `__constant`
    are marked `__private`; this includes all variables in the non-kernel functions
    and function arguments. The following kernel code from `Ch3/vectorization/vectorization.cl`
    will illustrate the global and private memory spaces whereby the variables `id`,
    `index`, and `t` are in the private memory space and hence not visible across
    other work items, therefore, free from interference, whereas the variables `in`
    and `out` exist in the global memory space and are visible by all work items:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following diagram illustrates the OpenCL programming model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works…](img/4520OT_03_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Let's use the preceding diagram to understand how your kernel will function
    in OpenCL. Imagine you have a kernel named `doCompute` that takes several arguments
    that reference the global, constant, local, or private memory spaces. Work and
    data is divided among the kernels across the compute units represented by the
    W[0…4]; they would represent either work groups (collection of work items) or
    work items.
  prefs: []
  type: TYPE_NORMAL
- en: Typically, computing in OpenCL often either involves individual work items performing
    the computation independently via the global, private, or constant spaces, or
    collecting these work items to form a work group so that they can load and store
    data more efficiently via utilizing the local memory space since that space allows
    sharing of data across all work items in the work group hence, preventing multiple
    memory loads from device memory.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring your OpenCL projects to enable the double data type
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Today's modern processors from Intel, AMD, and ARM have their floating-point
    units (FPUs) IEEE 754 compliant; however, ARM has both hardware and software support
    for half-precision numbers in addition to single-precision and double-precision
    numbers. Hence this implies that your OpenCL programs can actually utilize half-precision
    on ARM-based processors and this raise a question on how can one determine what
    sort of floating-point support does the device have.
  prefs: []
  type: TYPE_NORMAL
- en: 'The answer to that question is to query the device via the `clGetDeviceInfo`
    API and passing in any of the following parameters: `CL_DEVICE_SINGLE_FP_CONFIG`,
    `CL_DEVICE_DOUBLE_FP_CONFIG`, and `CL_DEVICE_HALF_FP_CONFIG` which identifies
    whether the device supports single-precision, double-precision, or half-precision
    number operations.'
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '`CL_DEVICE_HALF_FP_CONFIG` and `CL_DEVICE_DOUBLE_FP_CONFIG` are not supported
    on Mac OSX 10.6 for OpenCL 1.0.'
  prefs: []
  type: TYPE_NORMAL
- en: The result of API invocation returns an object of `cl_device_fp_config` type.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: At the time of this writing, `CL_FP_SOFT_FLOAT` was not available on Mac OSX
    10.6, but available on AMD APP SDK v2.7 and Intel OpenCL SDK.
  prefs: []
  type: TYPE_NORMAL
- en: In the case of the double-precision floating-point values, the OpenCL device
    extension, `cl_khr_fp64`, needs to be present before you can utilize the `double`
    data type in the kernel. As of OpenCL 1.2, the developer no longer has to query
    the device's extensions to verify the existence of the double-precision floating-point
    support, and we'll explain what you'll need to do in this case in the later part
    of this recipe.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As of OpenCL 1.1, the working committee does not mandate the support of the
    `double` data type except through the OpenCL 1.1 device extension `cl_khr_fp64`.
    If you are using AMD devices, you should know that AMD provides an extension that
    implements a subset of `cl_khr_fp64` and is known as `cl_amd_fp64`.
  prefs: []
  type: TYPE_NORMAL
- en: Let's understand this with a simple example.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the upcoming example, the goal of the example is to illustrate the use of
    a `double` data type to hold the intermediate result of adding two `floats`, after
    which we send this `double` to be stored as a `float` in a result array. Take
    note that you cannot use the `double` type in the kernel code if the extension
    `cl_khr_fp64` or `cl_amd_fp64` (for AMD devices) is enabled.
  prefs: []
  type: TYPE_NORMAL
- en: The two test machines involved have `cl_khr_fp64` supported on the Intel Core
    i7 processor and a NVIDIA GPU but the ATI 6870x2 GPU doesn't support `cl_khr_fp64`
    or `cl_amd_fp64`.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Following is the code excerpt from `Ch3/double_support/double_support.cl`,
    which illustrates the kernel code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, is the code snippet from `Ch3/double_support/double_support.c`, where
    it shows how to set the kernel arguments to the function `add3`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: To build the program with `CMake`, navigate to the directory `Ch3/double_support`,
    and enter `make`. It should drop a nice binary named `DoubleSupport` upon which
    you can execute it to observe the results. On both the test machines, the results
    for a small run, that is, 64-floating-point values are good with the runs on CPU
    and GPU.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: The code in this example was constructed in such a manner that even if `double`
    wasn't supported the program will run. Upon inspecting the code, you will realize
    that its use case was to hold the result of adding two `float` values (which by
    intention will not overflow) but in other situations, you might want to use `double`s,
    and the conditional-directives, that is, `#ifdef`, `#else`, and `#endif` used
    to check for the presence of double floating-point support for the device and
    it is a standard technique.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The type, `cl_device_fp_config` is actually composed of several values (shown
    in the following table) and you can determine whether a particular feature is
    supported or not by performing a bitwise-AND operation and for example, if we
    wish to determine which rounding modes are supported in double-precision operations
    then, we will have the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: '| Parameter | float | double | half |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `CL_FP_DENORM` | Optional | Supported | Optional |'
  prefs: []
  type: TYPE_TB
- en: '| `CL_FP_INF_NAN` | Supported | Supported | Supported |'
  prefs: []
  type: TYPE_TB
- en: '| `CL_FP_ROUND_TO_NEAREST` | Supported | Supported | Optional |'
  prefs: []
  type: TYPE_TB
- en: '| `CL_FP_ROUND_TO_ZERO` | Optional | Supported | Supported |'
  prefs: []
  type: TYPE_TB
- en: '| `CL_FP_ROUND_TO_INF` | Optional | Supported | Supported |'
  prefs: []
  type: TYPE_TB
- en: '| `CL_FP_FMA` | Optional | Supported | Optional |'
  prefs: []
  type: TYPE_TB
- en: '| `CL_FP_SOFT_FLOAT` | Optional | Optional | Optional |'
  prefs: []
  type: TYPE_TB
- en: 'For those who are inclined to use OpenCL 1.2, the specification has made double-precision
    an optional feature instead of an extension, and this means that instead of checking
    for the existence of the extensions `cl_khr_fp64` or `cl_amd_fp64` in the device,
    you will simply check that the returned value of the call to `clGetDeviceInfo`
    when passed the parameter `CL_DEVICE_PREFERRED_VECTOR_WIDTH_DOUBLE` and `CL_DEVICE_NATIVE_VECTOR_WIDTH`
    must be equal to `1` if the device were to support double-precision. The following
    code snippet illustrates how to check for the preferred native vector width size
    for built-in scalar types that can be put into vectors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
