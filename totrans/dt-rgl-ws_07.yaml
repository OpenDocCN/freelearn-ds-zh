- en: 7\. Advanced Web Scraping and Data Gathering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Overview
  prefs: []
  type: TYPE_NORMAL
- en: This chapter will introduce you to the concepts of advanced web scraping and
    data gathering. It will enable you to use `requests` and `BeautifulSoup` to read
    various web pages and gather data from them. You can perform read operations on
    XML files and the web using an **Application Program Interface** (**API**). You
    can use regex techniques to scrape useful information from a large and messy text
    corpus. By the end of this chapter, you will have learned how to gather data from
    web pages, XML files, and APIs.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The previous chapter covered how to create a successful data wrangling pipeline.
    In this chapter, we will build a web scraper that can be used by a data wrangling
    professional in their daily tasks using all of the techniques that we have learned
    so far. This chapter builds on the foundation of `BeautifulSoup` and introduces
    various methods for scraping a web page and using an API to gather data.
  prefs: []
  type: TYPE_NORMAL
- en: 'In today''s connected world, one of the most valued and widely used skills
    for a data wrangling professional is the ability to extract and read data from
    web pages and databases hosted on the web. Most organizations host data on the
    cloud (public or private), and the majority of web microservices these days provide
    some kind of API for external users to access data. Let''s take a look at the
    following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.1: Data wrangling HTTP request and an XML/JSON reply'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15780_07_01.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 7.1: Data wrangling HTTP request and an XML/JSON reply'
  prefs: []
  type: TYPE_NORMAL
- en: As we can see in the diagram, to fetch data from a web server or a database,
    we initiate `XML/JSON`. It is necessary that, as a data wrangling engineer, you
    know about the structure of web pages and the Python libraries so that you are
    able to extract data from a web page. The **World Wide Web** (**WWW**) is an ever-growing,
    ever-changing universe, where different data exchange protocols and formats are
    used. A few of these are widely used and have become standard.
  prefs: []
  type: TYPE_NORMAL
- en: Python comes equipped with built-in modules, such as `urllib 3`, which can initiate
    HTTP requests and receive data from the cloud. However, these modules operate
    at a low level and require a deep knowledge of HTTP protocols, encoding, and requests.
  prefs: []
  type: TYPE_NORMAL
- en: The Requests and BeautifulSoup Libraries
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will take advantage of two Python libraries in this chapter: `requests`
    and `BeautifulSoup`. To avoid dealing with HTTP methods at a lower level, we will
    use the `requests` library. It is an API built on top of pure Python web utility
    libraries, which makes placing HTTP requests easy and intuitive.'
  prefs: []
  type: TYPE_NORMAL
- en: '`BeautifulSoup` is one of the most popular HTML parser packages. It parses
    the HTML content you pass on and builds a detailed tree of all the tags and markup
    within the page for easy and intuitive traversal. This tree can be used by a programmer
    to look for certain markup elements (for example, a table, a hyperlink, or a blob
    of text within a particular `div` ID) to scrape useful data.'
  prefs: []
  type: TYPE_NORMAL
- en: We are going to do a couple of exercises in order to demonstrate how to use
    the `requests` library and decode the contents of the response received when data
    is fetched from the server.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 7.01: Using the Requests Library to Get a Response from the Wikipedia
    Home Page'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this exercise, we will use the `requests` library to extract data from a
    Wikipedia web page. The Wikipedia home page consists of many elements and scripts,
    all of which are a mix of HTML, CSS, and JavaScript code blocks. While reading
    from the home page of Wikipedia ([https://en.wikipedia.org/wiki/Main_Page](https://en.wikipedia.org/wiki/Main_Page)),
    the code or markup elements/texts might not be very useful. Therefore, we will
    peel off the layers of HTML/CSS/JavaScript to pry away the information we are
    interested in. Let''s follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Open a new Jupyter Notebook and import the `requests` library:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Assign the home page URL to a variable, `wiki_home`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use the `get` method from the `requests` library to get a response from this
    page:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To find out more about the `response` object, enter the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: As we can see, the output is an object that models the data structure of an
    HTTP response. It is defined in the `requests` library.
  prefs: []
  type: TYPE_NORMAL
- en: The web is an extremely dynamic place. For example, it is quite possible that
    the home page of Wikipedia will have changed by the time somebody uses your code,
    or that a particular web server will be not be running and your request will fail.
    If you proceed to write more complex and elaborate code without checking the status
    of your request, then all that subsequent work will be fruitless.
  prefs: []
  type: TYPE_NORMAL
- en: 'A web page request generally comes back with various numeric codes. They are
    the standard HTTP response codes. The following table shows the common codes you
    may encounter:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.2: HTTP response codes'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15780_07_02.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 7.2: HTTP response codes'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/3d7qmK0.](https://packt.live/3d7qmK0%20)
  prefs: []
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/3hEKbff](https://packt.live/3hEKbff).
  prefs: []
  type: TYPE_NORMAL
- en: In the next exercise, we are going to write a function to check the return code
    and print out messages as needed. These kinds of small helper/utility functions
    are incredibly useful for complex projects.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 7.02: Checking the Status of the Web Request'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this exercise, we will write a small utility function called `status_check`
    to check the status of the response received from the server. Our goal here is
    to check the status code and flag an error/no-error situation by writing a function.
    We will start by getting into the habit of writing small functions to accomplish
    small modular tasks, instead of writing long scripts, which are hard to debug
    and track. Let''s follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Open a new Jupyter notebook and create a `status_check` function as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note that, along with printing the appropriate message, we are returning either
    `1` or `-1` from this function. This is important because in the code that utilizes
    this function, we will be able to examine this return value to find out whether
    the request was a success or a failure.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Import the `requests` library:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Assign the home page URL to a variable, `wiki_home`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use the `get` method from the `requests` library to get a response from this page:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Pass the response object to the `status_check` function to examine the status
    of the response:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/3hHcf1k.](https://packt.live/3hHcf1k%20)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/3hDUhNp](https://packt.live/3hDUhNp).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In this chapter, for more complex programming activity, we will proceed only
    if we get `1` as the return value of the `status_check` function, that is, we
    will write a conditional statement to check the return value and then execute
    the subsequent code based on it.
  prefs: []
  type: TYPE_NORMAL
- en: Checking the Encoding of a Web Page
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can also write a utility function to check the encoding of a web page. Various
    encodings are possible with any HTML document, although the most popular is `UTF-8`.
    Some of the most popular encodings are `ASCII`, `Unicode`, and `UTF-8`. `ASCII`
    is the simplest, but it cannot capture the complex symbols used in various spoken
    and written languages all over the world, so `UTF-8` has become the almost universal
    standard in web development these days.
  prefs: []
  type: TYPE_NORMAL
- en: 'When we run this function on the Wikipedia home page, we get back the particular
    encoding type that''s used for that page. This function, like the previous one,
    takes the `response` object as an argument and returns a value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Check the response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Here, `'UTF-8'` denotes the most popular character encoding scheme that's used
    in the digital medium and on the web today. It employs variable-length encoding
    with `1-4` bytes, thereby representing all Unicode characters in various languages
    around the world.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 7.03: Decoding the Contents of a Response and Checking Its Length'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this exercise, we will create a function to get the Wikipedia page''s contents
    as a blob of text or as a string object that Python can process afterward. We
    will first initiate a request to get the contents of a Wikipedia page and store
    the data in a `response` object. We will then decode this `response` object. To
    do this, follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Open a new Jupyter Notebook and import the `requests` library:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Assign the home page URL to a variable, `wiki_home`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use the `get` method from the `requests` library to get a response from this
    page:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Write a utility function to decode the contents of the response:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Check the type of the decoded object to see what type of data we are finally
    getting:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We finally got a string object by reading the HTML page.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Check the length of the object using the `len` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This output is variable and is susceptible to change depending on the updates
    made to the Wikipedia web page.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Use the following code to print the first `10,000` characters of this string.
    It will look something similar to this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 7.3: Partial output showing a mixed blob of HTML markup tags, text,'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: and element names and properties
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_07_03.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 7.3: Partial output showing a mixed blob of HTML markup tags, text,
    and element names and properties'
  prefs: []
  type: TYPE_NORMAL
- en: Obviously, this is a mixed blob of various HTML markup tags, text, and element
    names/properties. We cannot hope to extract meaningful information from this that
    could be used for efficient analysis without using sophisticated functions or
    methods.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/2BfmUQq.](https://packt.live/2BfmUQq%20)
  prefs: []
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/2UW2L8L](https://packt.live/2UW2L8L).
  prefs: []
  type: TYPE_NORMAL
- en: Fortunately, the `BeautifulSoup` library or `bs4` library provides such methods,
    and we will see how to use them in the following exercise.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 7.04: Extracting Readable Text from a BeautifulSoup Object'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this exercise, we will create a utility function, `decode_content`, to decode
    the response received after initiating a request to the Wikipedia web page. We
    will use the `BeautifulSoup` library on the `response` object to further process
    it so that it becomes easier for us to extract any meaningful information from
    it. `BeautifulSoup` has a `text` method, which can be used to extract text. Let''s
    follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Open a new Jupyter Notebook and import the `requests` library:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Assign the home page URL to a variable, `wiki_home`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use the `get` method from the `requests` library to get a response from this
    page:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Write a utility function to decode the contents of the response:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Import the package and then pass on the whole string (HTML content) to a method
    for parsing:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Execute the following code in your notebook:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Find the type of the `txt_dmp`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Find the length of the `txt_dmp`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This output is variable and is susceptible to change depending on the updates
    made to the Wikipedia web page.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Now, the length of the text dump is much smaller than the raw HTML string's
    length. This is because the `bs4` library has parsed through the HTML and extracted
    only human-readable text for further processing.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Print the initial portion of this text:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You will see something similar to the following:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 7.4: Output showing the initial portion of text'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_07_04.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 7.4: Output showing the initial portion of text'
  prefs: []
  type: TYPE_NORMAL
- en: In this exercise, we were introduced to the main interface of `BeautifulSoup`
    or `bs4` and we also saw how we can parse a raw string containing HTML and other
    types of data using `bs4` and retain only HTML-related data.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/2Cky5rt.](https://packt.live/2Cky5rt%20)
  prefs: []
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/2Bj2Xbr](https://packt.live/2Bj2Xbr).
  prefs: []
  type: TYPE_NORMAL
- en: Web pages are becoming more and more dynamic with more and more diverse types
    of elements and content in them. As a data wrangling engineer, you will have to
    deal with the growing complexity and the heterogeneous nature of data. So, knowing
    what we just saw will often give you a big advantage.
  prefs: []
  type: TYPE_NORMAL
- en: Extracting Text from a Section
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now, let''s move on to more exciting data wrangling tasks. If you open the
    Wikipedia home page, [https://en.wikipedia.org/wiki/Main_Page,](https://en.wikipedia.org/wiki/Main_Page)
    you are likely to see a section called `From today''s featured article`. This
    is an excerpt from the day''s featured article, which is randomly selected and
    promoted on the home page. This article can also change throughout the day:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.5: Sample Wikipedia page highlighting the "From today''s featured
    article" section'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15780_07_05.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 7.5: Sample Wikipedia page highlighting the "From today''s featured
    article" section'
  prefs: []
  type: TYPE_NORMAL
- en: You need to extract the text from this section. There are several ways to accomplish
    this task. We will go through a simple and intuitive method for doing so here.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we try to identify two indices – the *start index* and *end index* of
    the line string – which demarcate the start and end of the text we are interested
    in extracting or reading. In the next screenshot, the indices are shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.6: Wikipedia page highlighting the text to be extracted'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15780_07_06.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 7.6: Wikipedia page highlighting the text to be extracted'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code accomplishes the extraction:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Note that we have to add the length of the `From today's featured article` string
    to `idx1` and then pass that as the starting index. This is because `idx1` finds
    where the `From today's featured article` string starts.
  prefs: []
  type: TYPE_NORMAL
- en: 'It prints out something like this (this is a sample output):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.7: The extracted text'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15780_07_07.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 7.7: The extracted text'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: The output you get will vary based on the current featured article.
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, the `BeautifulSoup` library provides an efficient technique
    to read data from a source. It will also be interesting to know the events that
    occurred on a particular day.
  prefs: []
  type: TYPE_NORMAL
- en: Extracting Important Historical Events that Happened on Today's Date
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Next, we will try to extract the text corresponding to the important historical
    events that happened on today''s date. This can generally be found in the bottom-right
    corner, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.8: Wikipedia page highlighting the On this day section'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15780_07_08.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 7.8: Wikipedia page highlighting the On this day section'
  prefs: []
  type: TYPE_NORMAL
- en: 'So, can we apply the same technique as we did for `From today''s featured article`?
    Apparently not, because there is text just below where we want our extraction
    to end, which is not fixed, unlike in the previous case. Note that, in the previous
    section, the fixed string `Recently featured` occurs at the exact place where
    we want the extraction to stop, so we could use it in our code. However, we cannot
    do that in this case, and the reason for this is illustrated in the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.9: Wikipedia page highlighting the text to be extracted'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15780_07_09.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 7.9: Wikipedia page highlighting the text to be extracted'
  prefs: []
  type: TYPE_NORMAL
- en: 'So, in this section, we just want to find out what the text looks like around
    the main content we are interested in. For that, we must find out the start of
    the `On this day` string and print out the next 1,000 characters using the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'The output looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.10: Output of the On this day section from Wikipedia'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15780_07_10.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 7.10: Output of the On this day section from Wikipedia'
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, there is a bit of unwanted data along with the relevant information
    that we are really interested in reading (as shown by the arrows). To address
    this issue, we need to think differently and use some other methods apart from
    `BeautifulSoup` (and write another utility function).
  prefs: []
  type: TYPE_NORMAL
- en: HTML pages are made of many markup tags, such as `<div>`, which denotes a division
    of text/images, and `<ul>`, which denotes lists. In the following exercise, we'll
    use advanced techniques from the `BeautifulSoup` library to extract relevant information
    from a web page.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 7.05: Using Advanced BS4 Techniques to Extract Relevant Text'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this exercise, we''ll take advantage of `BeautifulSoup` library techniques
    and extract the element that contains the text we are interested in. Let''s perform
    the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Open the Wikipedia page using this link: [https://en.wikipedia.org/wiki/Main_Page](https://en.wikipedia.org/wiki/Main_Page).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the Mozilla Firefox browser, right-click and select the `Inspect Element`
    option (in Chrome, we do the same, except the menu option is called `Inspect`)
    as shown in the following screenshot:![Figure 7.11: Inspecting elements on Wikipedia'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B15780_07_11.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 7.11: Inspecting elements on Wikipedia'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'As you hover over this with the mouse, you will see different portions of the
    page being highlighted. By doing this, it is easy to find out which precise block
    of markup text is responsible for the textual information we are interested in.
    Here, we can see that a certain `<ul>` block contains the text:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 7.12: Identifying the HTML block that contains the text we are interested
    in'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_07_12.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 7.12: Identifying the HTML block that contains the text we are interested
    in'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now, it is prudent to find the `<div>` tag that contains this `<ul>` block
    within it. By looking around the same screen as before, we can find the `<div>`
    and its `ID`:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 7.13: The <ul> tag containing the text'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_07_13.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 7.13: The <ul> tag containing the text'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: We can do similar things using `bs4` functions.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Start off by importing `requests` and `BeautifulSoup`. Also, retrieve the contents
    of the Wikipedia Main Page (highlighted).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use the `find_all` method from `BeautifulSoup`, which scans all the tags of
    the HTML page (and their sub-elements) to find and extract the text associated
    with this particular `<div>` element. Create an empty list and append the text
    from the `NavigableString` class to this list as we traverse the page:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The `find_all` method returns a `NavigableString` class, which has a useful
    `text` method associated with it for extraction. Note how we are utilizing the
    `mp-otd` ID of the `<div>` element to identify it among tens of other `<div>`
    elements. Now, if we examine the `text_list` list, we will see that it has three
    elements.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Print the elements separated by a marker. We will see that the text we are
    interested in appears as the first element:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 7.14: The text highlighted'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15780_07_14.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 7.14: The text highlighted'
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, it is the first element of the list that we are interested in.
    However, the exact position will depend on the web page. In this exercise, we
    were introduced to some advanced uses of `BeautifulSoup` and saw how we can extract
    meaningful information using its APIs.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/2USTDSg.](https://packt.live/2USTDSg%20)
  prefs: []
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/2zGIUTG](https://packt.live/2zGIUTG).
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will create a compact function to encapsulate some of those. Creating
    such functions helps us to increase the reusability of code.
  prefs: []
  type: TYPE_NORMAL
- en: As we discussed before, it is always good to try to functionalize specific tasks,
    particularly in a web-scraping application. In the following exercise, we are
    going to create a compact function.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 7.06: Creating a Compact Function to Extract the On this day Text
    from the Wikipedia Home Page'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this exercise, we are going to create a function that will take the Wikipedia
    URL (as a string), [https://en.wikipedia.org/wiki/Main_Page](https://en.wikipedia.org/wiki/Main_Page),
    and return the text corresponding to the `On this day` section. The benefit of
    a functional approach is that you can call this function from any Python script
    and use it anywhere in another program as a standalone module. To do this, let''s
    follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create the compact `def` function. Extract the text from the `On this day`
    section of the Wikipedia home page, [https://en.wikipedia.org/wiki/Main_Page](https://en.wikipedia.org/wiki/Main_Page).
    Accept the Wikipedia home page URL as a string. A default URL is provided:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a function that will check the status of the response received from
    the web page:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a `BeautifulSoup` object and read the contents of the web page:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Let's see the function in action.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 7.15: Output of wiki_on_this_day'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_07_15.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 7.15: Output of wiki_on_this_day'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Note how this function utilizes the status check and prints out an error message
    if the request failed. When we test this function with an intentionally incorrect
    URL, it behaves as expected:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In this exercise, we saw how to write a function to encapsulate a lot of important
    things that we have learned about `BeautifulSoup`.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/2YcaEJm.](https://packt.live/2YcaEJm%20)
  prefs: []
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/3hBS2dn](https://packt.live/3hBS2dn).
  prefs: []
  type: TYPE_NORMAL
- en: Reading Data from XML
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**XML** or **Extensible Markup Language** is a web markup language that''s
    similar to HTML but with significant flexibility (on the part of the user) built
    in, such as the ability to define your own tags. It was one of the most hyped
    technologies in the 1990s and early 2000s. It is a meta-language, that is, a language
    that allows us to define other languages using its mechanics, such as RSS and
    MathML (a mathematical markup language widely used for web publication and the
    display of math-heavy technical information). XML is also heavily used in regular
    data exchanges over the web, and as a data wrangling professional, you should
    have enough familiarity with its basic features to tap into the data flow pipeline
    whenever you need to extract data for your project.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 7.07: Creating an XML File and Reading XML Element Objects'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this exercise, we''ll create some random data and store it in XML format.
    We''ll then read from the XML file and examine the XML-formatted data string.
    Let''s follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create an XML file using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: As we can see, the `phone` type is a triple-quoted string or multiline string.
    If you print this object, you will get the following output. This is an XML-formatted
    data string in a tree structure, as we will see when we parse the structure and
    break apart the individual parts.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'To process and wrangle with the data, we have to read it as an `Element` object
    using the Python XML parser engine:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In this exercise, we saw how to create an XML file, how to read an XML file,
    and what kind of object we can expect when we read an XML file.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/37EDwgt.](https://packt.live/37EDwgt%20)
  prefs: []
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/3hDwUDv](https://packt.live/3hDwUDv).
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 7.08: Finding Various Elements of Data within a Tree (Element)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this exercise, we will use the `find` method to search for various pieces
    of useful data within an XML element object and print them using the `text` method.
    We will also use the `get` method to extract the specific attribute we want. To
    do so, let''s follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create an XML file using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To process and wrangle with the data, we have to read it as an `Element` object
    using the Python XML parser engine:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use the `find` method to find `Name`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use the `find` method to find `Surname`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use the `find` method to find `Phone`. Note the use of the `strip` method to
    strip away any trailing spaces/blanks:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use the `find` method to find `email status` and `actual email`. Note the use
    of the `get` method to extract the status:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In this exercise, we saw how we can use the `find` method to read the relevant
    information from an XML file. XML is a very diverse format of expressing data.
    Apart from following some ground rules, everything else is customizable in an
    XML document. In this exercise, we saw how to access a custom XML element and
    extract data from it.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/3dgSoTf.](https://packt.live/3dgSoTf%20)
  prefs: []
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/2CjDnU9](https://packt.live/2CjDnU9).
  prefs: []
  type: TYPE_NORMAL
- en: Reading from a Local XML File into an ElementTree Object
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can also read from an XML file saved locally on disk. This is a fairly common
    situation where a frontend web scraping module has already downloaded a lot of
    XML files by reading a table of data on the web and the data wrangler needs to
    parse through this XML file to extract meaningful pieces of numerical and textual
    data.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have a file associated with this chapter called `xml1.xml`. The file can
    be found here: [https://packt.live/3e8jM7n](https://packt.live/3e8jM7n).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Please make sure you have the file in the same directory that you are running
    your Jupyter notebook from:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: Note how we use the `parse` method to read this XML file. This is slightly different
    than using the `fromstring` method used in the previous exercise, where we were
    directly reading from a `string` object. This produces an `ElementTree` object
    instead of a simple `Element`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The idea of building a tree-like object is the same as in the domains of computer
    science and programming. Let''s take a look at the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.16: Tree-like children nodes'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15780_07_16.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 7.16: Tree-like children nodes'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the preceding diagram, we can see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: There is a root.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are child objects attached to the root.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There could be multiple levels, that is, children of children, recursively going
    down.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All of the nodes of the tree (root and children alike) have attributes attached
    to them that contain data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tree traversal algorithms can be used to search for a particular attribute.
    If provided, special methods can be used to probe a node more deeply.
  prefs: []
  type: TYPE_NORMAL
- en: 'Every node in the XML tree has tags and attributes. The idea is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.17: Finding the root and child nodes of an XML tag'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15780_07_17.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 7.17: Finding the root and child nodes of an XML tag'
  prefs: []
  type: TYPE_NORMAL
- en: As the document is organized in a tree fashion, we can use a tree traversal
    algorithm to go through it and visit all the children, starting at the root.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 7.09: Traversing the Tree, Finding the Root, and Exploring All the
    Child Nodes and Their Tags and Attributes'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this exercise, we will use the tree traversal algorithm to traverse a tree,
    find the root, and explore all the child nodes. We will first define a variable
    called `tree2`, which will contain the contents of the `xml1.xml` file. Then,
    we will use a `for` loop to traverse through this XML document tree.
  prefs: []
  type: TYPE_NORMAL
- en: 'The XML file can be found here: [https://packt.live/3e8jM7n](https://packt.live/3e8jM7n).
    Follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Open a new Jupyter Notebook and define the tree:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Explore these tags and attributes using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 7.18: The output showing the extracted XML tags'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15780_07_18.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 7.18: The output showing the extracted XML tags'
  prefs: []
  type: TYPE_NORMAL
- en: In this exercise, we saw how to traverse an XML document tree.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/2AEgqe1.](https://packt.live/2AEgqe1%20)
  prefs: []
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/3ebu5re](https://packt.live/3ebu5re).
  prefs: []
  type: TYPE_NORMAL
- en: Remember that every XML data file could follow a different naming or structural
    format, but using an element tree approach puts the data into a somewhat structured
    flow that can be explored systematically. Still, it is best to examine the raw
    XML file structure once and understand (even if at a high level) the data format
    before attempting automatic extractions.
  prefs: []
  type: TYPE_NORMAL
- en: In the following exercise, we will see how to extract relevant information from
    a tree.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 7.10: Using the text Method to Extract Meaningful Data'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this exercise, we will be using the `text` method from the `BeautifulSoup`
    library to extract different types of data from a particular node of the XML document
    tree. We can almost think of the XML tree as a **list of lists** and index it
    accordingly. Let''s follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Open a new Jupyter Notebook and define the tree:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Explore these tags and attributes using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Access the `root[0][2]` element by using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: So, this points to the `gdppc` piece of data. Here, `gdppc` is the tag and the
    actual GDP/per capita data is attached to this tag.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Use the `text` method to access the data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use the `tag` method to access `gdppc`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Check `root[0]`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Check the tag:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can use the `attrib` method to access it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: So, `root[0]` is again an element, but it has a different set of tags and attributes
    than `root[0][2]`. This is expected because they are all part of the tree as nodes,
    but each is associated with a different level of data.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In this exercise, we saw how to access a particular node in an XML document
    and how to get the data, attributes, and other related things from it. This knowledge
    is very valuable as a lot of data is still presented and exchanged in XML format.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/3ee0mhl.](https://packt.live/3ee0mhl%20)
  prefs: []
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/2YMqbyz](https://packt.live/2YMqbyz).
  prefs: []
  type: TYPE_NORMAL
- en: This last piece of code output is interesting because it returns a dictionary
    object. Therefore, we can just index it by its keys. We will do that in the next
    exercise.
  prefs: []
  type: TYPE_NORMAL
- en: Extracting and Printing the GDP/Per Capita Information Using a Loop
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now that we know how to read the GDP/per capita data and how to get a dictionary
    back from the tree, we can easily construct a simple dataset by running a loop
    over the tree:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: We can put these in a DataFrame or a CSV file to be saved to a local disk for
    further processing, such as a simple plot.
  prefs: []
  type: TYPE_NORMAL
- en: Finding All the Neighboring Countries for Each Country and Printing Them
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are efficient search algorithms for tree structures, and one such method
    for XML trees is `findall`. We can use this, for this example, to find all the
    neighbors a country has and print them out.
  prefs: []
  type: TYPE_NORMAL
- en: 'Why do we need to use `findall` instead of `find`? Well, because not all countries
    have an equal number of neighbors and `findall` searches for all the data with
    that tag that is associated with a particular node, and we want to traverse all
    of them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: 'The output looks something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.19: The output that''s generated by using findall'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15780_07_19.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 7.19: The output that''s generated by using findall'
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we have looked into how to use specific search algorithms in
    the form of pre-defined functions to traverse through an XML document and get
    interesting data from the nodes we visit.
  prefs: []
  type: TYPE_NORMAL
- en: In the previous topic of this chapter, we learned about simple web scraping
    using the `requests` library. So far, we have worked with static XML data, that
    is, data from a local file or a string object we've scripted. Now, it is time
    to combine our learning and read XML data directly over the internet (as you are
    expected to do almost all the time).
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 7.11: A Simple Demo of Using XML Data Obtained by Web Scraping'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this exercise, we will obtain XML data using web scraping. We will read
    a cooking recipe from a website called [http://www.recipepuppy.com/](http://www.recipepuppy.com/),
    which contains aggregates links of various other sites with the recipe. Next,
    we will use the `find` method to extract the appropriate attribute from the XML
    file and display the relevant content. Let''s follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the necessary libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Read from the [http://www.recipepuppy.com/](http://www.recipepuppy.com/) website:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This code will ask the user for input. You have to enter the name of a food
    item: ''`chicken tikka`''.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'You will get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: If we print the last variable, `data`, we may see that it is a mix of a legitimate
    XML document and some junk HTML appended to it. We need to first check if that
    is the case.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Use the `find` method from Python. As `data` is a string, we can simply do
    the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This should return an integer if that string is found in `data`. Otherwise,
    it will return `–1`. If we get a positive integer, then we know – thanks to Python's
    `find` method – it is the start index of the string we are searching.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Get only the XML part using a piece of code like the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: However, if we do not get a positive integer, then we assume that the whole
    return text is valid XML and we simply set the `end_marker` as the total length
    of the string. Although, it is always good practice to print the raw data and
    check whether it is pure XML or some junk added with it.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Write the code to get back data in XML format and read and decode it before
    creating an XML tree out of it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we can use another useful method, called `iter`, which basically iterates
    over the nodes under an element. If we traverse the tree and extract the text,
    we get the following output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output (partially shown) is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 7.20: The output that''s generated by using iter'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_07_20.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 7.20: The output that''s generated by using iter'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: We can use the `find` method to search for the appropriate attribute and extract
    its content. This is the reason it is important to scan through the XML data manually
    and check what attributes are used. Remember, this means scanning the raw string
    data, not the tree structure.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Print the raw string data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output (partially shown) is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 7\. 21: output of raw string data'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_07_21.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 7\. 21: output of raw string data'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Let''s examine the XML data that we received, and let''s locate the `<title>`
    and `<href>` tags:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 7.22: The output showing the extracted href tags'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_07_22.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 7.22: The output showing the extracted href tags'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Now we know what tags to search for.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Print the `<title>` and `<href>` hyperlinks in the XML data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The final output (partially shown) is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 7.23: The output showing the final output'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15780_07_23.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 7.23: The output showing the final output'
  prefs: []
  type: TYPE_NORMAL
- en: Note the use of `h!=None` and `t!=None`. These are difficult to anticipate when
    you first run this kind of code. You may get an error because some of the tags
    may return a `None` object, that is, they were empty for some reason in this XML
    data stream. This kind of situation is fairly common and cannot be anticipated
    beforehand. You have to use your Python knowledge and programming intuition to
    get around it if you receive such an error. Here, we are just checking for the
    type of the object and if it is not `None`, then we need to extract the text associated
    with it.
  prefs: []
  type: TYPE_NORMAL
- en: As we can see in the output of this exercise, we're getting a nice output with
    links to recipes relevant to the food item we searched for. And this concludes
    this exercise. We have used our knowledge of making HTTP requests and getting
    data from the internet and mixed it with our newly acquired knowledge of parsing
    and traversing XML documents to accomplish a small but functional data pipeline.
    This kind of data pipeline building is a fairly common task for a data wrangling
    engineer. Now you know how to approach that.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/2ALU6yZ.](https://packt.live/2ALU6yZ%20)
  prefs: []
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/3hBSMPH](https://packt.live/3hBSMPH).
  prefs: []
  type: TYPE_NORMAL
- en: Reading Data from an API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Fundamentally, an API or Application Programming Interface is an interface to
    a computing resource (for example, an operating system or database table), which
    has a set of exposed methods (function calls) that allow a programmer to access
    particular data or internal features of that resource.
  prefs: []
  type: TYPE_NORMAL
- en: A web API is, as the name suggests, an API over the web. Note that it is not
    a specific technology or programming framework, but an architectural concept.
    Think of an API like a fast-food restaurant's customer service desk. Internally,
    there are many food items, raw materials, cooking resources, and recipe management
    systems, but all you see are fixed menu items on the board and you can only interact
    through those items. It is like a port that can be accessed using an HTTP protocol
    and that's able to deliver data and services if used properly.
  prefs: []
  type: TYPE_NORMAL
- en: Web APIs are extremely popular these days for all kinds of data services. In
    the very first chapter, we talked about how UC San Diego's data science team pulls
    data from Twitter feeds to analyze the occurrence of forest fires. For this, they
    do not go to [twitter.com](http://twitter.com) and scrape the data by looking
    at HTML pages and text. Instead, they use the Twitter API, which sends this data
    continuously in a streaming format.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, it is very important for a data wrangling professional to understand
    the basics of data extraction from a web API as you are extremely likely to find
    yourself in a situation where large quantities of data must be read through an
    API for processing and wrangling. These days, most APIs stream data in JSON format.
    In this chapter, we will use a free API to read some information about various
    countries around the world in JSON format and process it.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use Python''s built-in `urllib` module for this topic, along with pandas
    to make a DataFrame. So, we can import them now. We will also import Python''s
    `json` module:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: Defining the Base URL (or API Endpoint)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'First, we need to set the base URL. When we are dealing with API microservices,
    this is often called the **API endpoint**. Therefore, look for such a phrase in
    the web service portal you are interested in and use the endpoint URL they give
    you:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: API-based microservices are extremely dynamic in nature in terms of what and
    how they offer their services and data. It can change at any time. At the time
    of writing, we found this particular API to be a nice choice for extracting data
    easily and without using authorization keys (login or special API keys).
  prefs: []
  type: TYPE_NORMAL
- en: For most APIs, however, you need to have your own API key. You get that by registering
    with their service. A basic usage (up to a fixed number of requests or a data
    flow limit) is often free, but after that, you will be charged. To register for
    an API key, you often need to enter credit card information.
  prefs: []
  type: TYPE_NORMAL
- en: We wanted to avoid all that hassle to teach you the basics and that's why we
    chose this example, which does not require such authorization. But, depending
    on what kind of data you will encounter in your work, please be prepared to learn
    about using an API key.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 7.12: Defining and Testing a Function to Pull Country Data from an
    API'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this exercise, we''ll use a particular API, `https://restcountries.eu/rest/v2/name/`,
    that serves basic information about countries around the world. We will first
    connect with the API. Next, we will create a user-defined function to get the
    data for a specific country. Let''s follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the necessary libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define the `service_url` variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a function to pull out data when we pass the name of a country as an
    argument. The crux of the operation is contained in the following two lines of code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The first line of code appends the country name as a string to the base URL
    and the second line sends a `get` request to the API endpoint. If all goes well,
    we get back the data, decode it, and read it as a `JSON` file. This whole exercise
    is coded in the following function, along with some error-handling code wrapped
    around the basic actions we talked about previously.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Define the `get_country_data` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Test this function by passing some arguments. Note that we are using the `try..except`
    block here. The `try` block lets you test a block of code and see whether there
    are any errors; the `except` block lets you handle the errors.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Type in the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Feed erroneous data in `country_name1`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We pass a correct name and an erroneous name. The response is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This is an example of rudimentary error handling. You have to think about various
    possibilities and put in the right code to catch and gracefully respond to user
    input when you are building a real-life web or enterprise application.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/30QU3MY.](https://packt.live/30QU3MY%20)
  prefs: []
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/2UUPc9I](https://packt.live/2UUPc9I).
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have written a function to get this data with some kind of error
    handling built into it, we are ready to move on to the next part, where we deal
    with the data that we just got.
  prefs: []
  type: TYPE_NORMAL
- en: Using the Built-In JSON Library to Read and Examine Data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we have already mentioned, JSON looks a lot like a Python dictionary.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use Python''s `requests` module to read raw data in that format and
    see what we can process further:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE99]'
  prefs: []
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs: []
  type: TYPE_PRE
- en: It reads a string datatype into a list of dictionaries. In this case, we get
    only one element in the list, so we extract that and check its type to make sure
    it is a dictionary.
  prefs: []
  type: TYPE_NORMAL
- en: We can quickly check the keys of the dictionary by using the `keys()` method
    on the dictionary, that is, the JSON data (note that a full screenshot is not
    shown here).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s try the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE101]'
  prefs: []
  type: TYPE_PRE
- en: 'The output (partially shown), will be:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.24: The output of dict_keys'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15780_07_24.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 7.24: The output of dict_keys'
  prefs: []
  type: TYPE_NORMAL
- en: We can see the relevant country data, such as calling codes, population, area,
    time zones, borders, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Printing All the Data Elements
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This task is extremely simple given that we have a dictionary at our disposal.
    All we have to do is iterate over the dictionary and print the key/item pairs
    one by one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE102]'
  prefs: []
  type: TYPE_PRE
- en: 'The output (partially shown) is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.25: The output using dict'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15780_07_25.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 7.25: The output using dict'
  prefs: []
  type: TYPE_NORMAL
- en: Note that the items in the dictionary are not of the same type, that is, they
    are not similar objects. Some are floating-point numbers, such as `area`, many
    are simple strings, but some are lists or even lists of dictionaries.
  prefs: []
  type: TYPE_NORMAL
- en: This is fairly common with JSON data. The internal data structure of JSON can
    be arbitrarily complex and multilevel, that is, you can have a dictionary of lists
    of dictionaries of dictionaries of lists of lists… and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: It is clear, therefore, that there is no universal method or processing function
    for the JSON data format, and you have to write custom loops and functions to
    extract data from such a dictionary object based on your particular needs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we will write a small loop to extract the languages spoken in Switzerland.
    First, let''s examine the dictionary closely and see where the language data is:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.26: The tags'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15780_07_26.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 7.26: The tags'
  prefs: []
  type: TYPE_NORMAL
- en: So, the data is embedded inside a list of dictionaries, which is accessed by
    a particular key of the main dictionary.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can write two simple lines of code to extract this data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE103]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.27: The output showing the languages'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15780_07_27.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 7.27: The output showing the languages'
  prefs: []
  type: TYPE_NORMAL
- en: Using a Function that Extracts a DataFrame Containing Key Information
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here, we are interested in writing a function that can take a list of countries
    and return a `pandas` DataFrame with some key information:'
  prefs: []
  type: TYPE_NORMAL
- en: Capital
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Region
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sub-region
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Population
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Latitude/longitude
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Area
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gini index
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Time zones
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Currencies
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Languages
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This is the kind of wrapper function you are generally expected to write in
    real-life data wrangling tasks, that is, a utility function that can take a user
    argument and output a useful data structure (or a mini database-type object) with
    key information extracted over the internet about the item the user is interested
    in.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We will show you the whole function first and then discuss some key points
    about it. It is a slightly complex and long piece of code. However, with your
    Python data-wrangling knowledge, you should be able to examine this function closely
    and understand what it is doing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE104]'
  prefs: []
  type: TYPE_PRE
- en: 'Here are some of the key points about this function:'
  prefs: []
  type: TYPE_NORMAL
- en: It starts by building an empty dictionary of lists. This is the chosen format
    for finally passing to the pandas **DataFrame** method, which accepts this format
    and returns a nice DataFrame with column names set to the dictionary keys' names.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We use the previously defined `get_country_data` function to extract data for
    each country in the user-defined list. For this, we simply iterate over the list
    and call this function.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We check the output of the `get_country_data` function. If for some reason it
    returns a `None` object, we will know that the API reading was not successful,
    and we will print out a suitable message. Again, this is an example of an error-handling
    mechanism and you must have them in your code. Without this small error-checking
    code, your application won't be robust enough for the occasional incorrect input
    or API malfunction.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For many data types, we simply extract the data from the main JSON dictionary
    and append it to the corresponding list in our data dictionary.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: However, for special data types, such as time zones, currencies, and languages,
    we write a special loop to extract the data without error.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We also take care of the fact that these special data types can have a variable
    length, that is, some countries may have multiple spoken languages, but most will
    have only one entry. So, we check whether the length of the list is greater than
    one and handle the data accordingly.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Exercise 7.13: Testing the Function by Building a Small Database of Country
    Information'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this exercise, we will use the example code used in the previous section
    and build a database of country information. We will test this function by passing
    a list of country names.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the necessary libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE105]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define the `service_url` variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE106]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define the `get_country_data` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE107]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define the name of the country:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE108]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Type in the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE109]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE110]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Feed erroneous data in `country_name1`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE111]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'On passing an erroneous name, the response is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE112]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, import the `json` library:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE113]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Load from string `data` as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE114]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Load the only element as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE115]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Check the type of `y` as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE116]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This will return `dict`
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Print the keys of `y` as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE117]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE118]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Iterate over the dictionary and print the key/item pairs one by one:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE119]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'A section of output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE120]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a loop to extract the languages spoken in `Switzerland`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE121]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE122]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Import the necessary libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE123]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define the `build_country_database`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE124]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To test its robustness, we pass in an erroneous name, such as `Turmeric` in
    this case:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE125]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 7.28: output of country database'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_07_28.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 7.28: output of country database'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'As we can see from the output, it detected that it did not get any data back
    for the incorrect entry and printed out a suitable message. The key thing is that
    if you do not have the error-checking and handling code in your function, then
    it will stop the execution on that entry and will not return the expected mini
    database. To avoid this behavior, error-handling code is invaluable. The following
    screenshot points at the incorrect entry:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 7.29: The incorrect entry highlighted'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_07_29.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 7.29: The incorrect entry highlighted'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Print the `pandas` DataFrame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE126]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows (only partial output is shown):'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 7.30: Partial output'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_07_30.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 7.30: Partial output'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s analyze the data that has been extracted:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.31: The data extracted correctly'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15780_07_31.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 7.31: The data extracted correctly'
  prefs: []
  type: TYPE_NORMAL
- en: As we can see from the output, single as well as multiple pieces of data have
    been extracted correctly.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/2YeRDpP.](https://packt.live/2YeRDpP%20)
  prefs: []
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/3fvAY6U](https://packt.live/3fvAY6U).
  prefs: []
  type: TYPE_NORMAL
- en: Fundamentals of Regular Expressions (RegEx)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Reg**ular **ex**pressions or **regex** are used to identify whether a pattern
    exists in a given sequence of characters (a string) or not. They help with manipulating
    textual data, which is often a prerequisite for data science projects that involve
    text mining.'
  prefs: []
  type: TYPE_NORMAL
- en: RegEx in the Context of Web Scraping
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Web pages are often full of text, and while there are some methods in `BeautifulSoup`
    or XML parsers to extract raw text, there is no method for the intelligent analysis
    of that text. If, as a data wrangler, you are looking for a particular piece of
    data (for example, email IDs or phone numbers in a special format), you have to
    do a lot of string manipulation on a large corpus to extract email IDs or phone
    numbers. `RegEx` is very powerful and can save a data wrangling professional a
    lot of time and effort with string manipulation because they can search for complex
    textual patterns with wildcards of an arbitrary length.
  prefs: []
  type: TYPE_NORMAL
- en: '`RegEx` is like a mini-programming language in itself and common ideas are
    used not only in Python, but in all widely used web app languages, such as JavaScript,
    PHP, and Perl. The `regex` module is built into Python, and you can import it
    by using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE127]'
  prefs: []
  type: TYPE_PRE
- en: In the next exercise, we are going to use the `match` method to check whether
    a pattern matches a string or sequence.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 7.14: Using the match Method to Check Whether a Pattern Matches a
    String/Sequence'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this exercise, we will use one of the most common regex methods, `match`,
    to check for an exact or partial match at the beginning of a string. Let''s follow
    these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the `regex` module:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE128]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a string and a pattern:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE129]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Write a conditional expression to check for a match:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE130]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output should be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE131]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Test this with a string that only differs in the first letter by making it
    lowercase:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE132]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE133]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/2N8SKAW.](https://packt.live/2N8SKAW%20)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/3hHJOAr](https://packt.live/3hHJOAr).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In this exercise, we just saw how to do the most basic regex operations. In
    itself, it may not look very impressive, but we will be building further complex
    logic on top of this basic idea in the forthcoming exercises.
  prefs: []
  type: TYPE_NORMAL
- en: Using the compile Method to Create a RegEx Program
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In a program or module, if we are making heavy use of a particular pattern,
    then it is better to use the `compile` method and create a regex program and then
    call methods on this program.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is how you compile a regex program:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE134]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE135]'
  prefs: []
  type: TYPE_PRE
- en: This code produced an `SRE.Match` object that has a `span` of (`0,6`) and the
    matched string of `Python`. The span here simply denotes the start and end indices
    of the pattern that was matched. These indices may come in handy in a text mining
    program where the subsequent code uses the indices for further search or decision-making
    purposes.
  prefs: []
  type: TYPE_NORMAL
- en: Compiled objects act like functions in that they return `None` if the pattern
    does not match. This concept will come in handy later when we write a small utility
    function to check for the type of the returned object from regex-compiled programs
    and act accordingly. We cannot be sure whether a pattern will match a given string
    or whether it will appear in a corpus of text (if we are searching for the pattern
    anywhere within the text). Depending on the situation, we may encounter `Match`
    objects or `None` as the returned value, and we have to handle this gracefully.
    Let's practice this in the following exercise.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 7.15: Compiling Programs to Match Objects'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this exercise, we will define two strings and a pattern. We will use the
    `compile` method to compile a regex program. Next, we will write a small conditional
    to test whether the compiled object matches the defined pattern. Let''s follow
    these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Use the `compile` function from the `regex` module:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE136]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Match it with the first string:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE137]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE138]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Match it with the second string:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE139]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE140]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: So, the `compile` method returns special objects, such as `match` objects. But
    if they don't match, it will return `None`, so we can still run our conditional
    loop.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/30SJ4m9.](https://packt.live/30SJ4m9%20)
  prefs: []
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/3hIBkJE](https://packt.live/3hIBkJE).
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 7.16: Using Additional Parameters in the match Method to Check for
    Positional Matching'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this exercise, we will use the `match` method to check whether there''s
    a match at a specific location in the string. Let''s follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Match `y` in the second position:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE141]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE142]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This is the `match` object that we talked about before.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Check for a pattern called `thon` starting from `pos=2`, that is, the third
    character:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE143]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE144]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Find a match in a different string by using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE145]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE146]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: So, we have seen how can we use regex, and use it in various use cases.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/2CmKc7z.](https://packt.live/2CmKc7z%20)
  prefs: []
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/30OsDY6](https://packt.live/30OsDY6).
  prefs: []
  type: TYPE_NORMAL
- en: Finding the Number of Words in a List That End with "ing"
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Suppose we want to find out whether a given string has the last three letters
    `ing`. This kind of query may come up in a text analytics/text mining program
    where somebody is interested in finding instances of present continuous tense
    words, which are highly likely to end with `ing`. However, nouns may also end
    with `ing` (as we will see in this example):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE147]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a `for` loop to find words ending with `ing`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE148]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE149]'
  prefs: []
  type: TYPE_PRE
- en: The search Method in RegEx
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It looks plain and simple, and you may well wonder what the purpose of using
    a special regex module for this is. A simple string method should have been sufficient.
    Yes, it would have been OK for this particular example, but the whole point of
    using regex is to be able to use very complex string patterns that are not at
    all obvious when it comes to how they are written using simple string methods.
    We will see the real power of regex compared to string methods shortly. But before
    that, let's explore another of the most commonly used methods, called `search`.
  prefs: []
  type: TYPE_NORMAL
- en: '`search` and `match` are related concepts, and they both return the same `match`
    object. The real difference between them is that **match works for only the first
    match** (either at the beginning of the string or at a specified position, as
    we saw in the previous exercises), whereas **search looks for the pattern anywhere
    in the string** and returns the position if it finds a match.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 7.17: The search Method in RegEx'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this exercise, we will use the `search` method to find the `ing` pattern
    in a regex structure. Let''s follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Use the `compile` method to find matching strings:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE150]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE151]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Search the string by using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE152]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE153]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let''s use `Ringtone` as the search parameter:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE154]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE155]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: As you can see, the `match` method returns `None` for the input `Spring`, and
    we had to write code to print that out explicitly (because in a Jupyter notebook,
    nothing will show up for a `None` object). But `search` returns a `match` object
    with `span=(3,6)` as it finds the `ing` pattern spanning those positions.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, for the `Ringtone` string, it finds the correct position of the match
    and returns `span=(1,4)`.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/3fDRmme.](https://packt.live/3fDRmme%20)
  prefs: []
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/30U2WFm](https://packt.live/30U2WFm).
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 7.18: Using the span Method of the Match Object to Locate the Position
    of the Matched Pattern'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this exercise, we will use the `span` contained in the `Match` object to
    locating the exact position of the pattern as it appears in the string. Let''s
    follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Initialize `prog` with the `ing` pattern:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE156]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a function to return a tuple of the start and end positions of the match:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE157]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Print the word ending with `ing` and its start and end position:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE158]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE159]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/2YIZB9y.](https://packt.live/2YIZB9y%20)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/37FXSG5](https://packt.live/37FXSG5).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Now, we will start getting into the real usage of regex with examples of various
    useful pattern matching. In the following exercise, we will explore single-character
    matching.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 7.19: Examples of Single-Character Pattern Matching with search'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this exercise, we will use the `group` method, which will return the matched
    pattern in a string format so that we can print and process it easily. Let''s
    follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Pass a regex expression with a dot (`.`) inside the `compile` method. It matches
    any single character except a newline character:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE160]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE161]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Pass a regex expression with `\w` (lowercase w) inside the `compile` method.
    It matches any single letter, digit, or underscore:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE162]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE163]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Pass a regex expression with `\W` (uppercase W) inside the `compile` method.
    It matches anything not covered by `\w`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE164]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE165]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Pass a regex expression with `\s` (lowercase s) inside the `compile` method.
    It matches a single whitespace character, such as a space, newline, tab, or return:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE166]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE167]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Pass a regex expression with `\d` inside the `compile` method. It matches numerical
    digits 0-9:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE168]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE169]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: As we can see, we can use the `group` function to return a group of matched characters.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/2YOJcAi.](https://packt.live/2YOJcAi%20)
  prefs: []
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/3edPMHj](https://packt.live/3edPMHj).
  prefs: []
  type: TYPE_NORMAL
- en: In the following exercise, we will manipulate the start or end of a string using
    pattern matching.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 7.20: Handling Pattern Matching at the Start or End of a String'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this exercise, we will match patterns with strings using the `^` (caret)
    operator. The focus is to find out whether the pattern is present at the start
    or the end of the string. Let''s follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Write a function to handle cases where a match is not found, that is, to handle
    `None` objects that are returned:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE170]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use `^` (caret) to match a pattern at the start of the string:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE171]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE172]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use `$` (dollar sign) to match a pattern at the end of the string:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE173]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE174]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/3ddku23.](https://packt.live/3ddku23%20)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/3djOXeV](https://packt.live/3djOXeV).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: For these examples and exercises, also try to think about how you would implement
    them without regex, that is, by using simple string methods and any other logic
    that you can think of. Then, compare that solution to the ones implemented with
    regex for brevity and efficiency.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Exercise 7.21: Pattern Matching with Multiple Characters'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this exercise, we will use the `match` method for matching multiple characters.
    Let''s perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Use `*` to match `0` or more repetitions of the preceding regular expression:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE175]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE176]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Using `+` causes the resulting `RE` to match `1` or more repetitions of the
    preceding regular expression:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE177]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE178]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '? causes the resulting `re` string to match precisely 0 or 1 repetitions of
    the preceding regular expression:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE179]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE180]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Here, we saw how we can use regex to search for and match a set of characters
    in the same order as they occur in the search pattern.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/310l7Jw.](https://packt.live/310l7Jw%20)
  prefs: []
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/3hCdnDz](https://packt.live/3hCdnDz).
  prefs: []
  type: TYPE_NORMAL
- en: The standard (default) mode of pattern matching in regex is **greedy**, that
    is, the program tries to match as much as it can. Sometimes, this behavior is
    natural, but in some cases, you may want to match minimally. This is called **non-greedy**
    matching.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 7.22: Greedy versus Non-Greedy Matching'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this exercise, we will perform greedy and non-greedy pattern matching. Let''s
    go through the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Write the code to check the greedy way of matching a string, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE181]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE182]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: So, the preceding regex found both tags with the `<>` pattern, but what if we
    wanted to match the first tag only and stop there.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Use `?` by inserting it after any regex expression to make it non-greedy:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE183]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE184]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In the following exercise, we will be handling repetitions using `match`.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/37Hz944.](https://packt.live/37Hz944%20)
  prefs: []
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/2UVlK3q](https://packt.live/2UVlK3q).
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 7.23: Controlling Repetitions to Match in a Text'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this exercise, we will check the number of repetitions of the pattern we
    want to match in a text. Let''s go through the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '`{m}` specifies exactly `m` copies of `RE` to match. Fewer matches cause a
    non-match and return `None`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE185]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE186]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '`{m,n}` specifies exactly `m` to `n` copies of `RE` to match:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE187]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE188]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Omitting `m` specifies a lower bound of zero:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE189]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE190]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Omitting `n` specifies an infinite upper bound:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE191]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE192]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '`{m,n}?` specifies `m` to `n` copies of `RE` to match in a non-greedy fashion:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE193]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE194]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/2YOzAWf.](https://packt.live/2YOzAWf%20)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/2YKO7T4](https://packt.live/2YKO7T4).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Let's go over to the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Sets of Matching Characters
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To match an arbitrarily complex pattern, we need to be able to include a logical
    combination of characters together as a bunch. Regex gives us that kind of capability.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following examples demonstrate such uses of regex. `[x,y,z]` matches `x`,
    `y`, or `z`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE195]'
  prefs: []
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE196]'
  prefs: []
  type: TYPE_PRE
- en: A range of characters can be matched inside the set using `-`. This is one of
    the most widely used regex techniques.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 7.24: Sets of Matching Characters'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this exercise, we will find the sets of matching characters from a defined
    string. We will look for an email address pattern, `<some name>@<some domain name>.<some
    domain identifier>`, from a string. Let''s go through the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose we want to pick out an email address from some text:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE197]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE198]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Look at the regex pattern inside [ `…` ]. It is `a-zA-Z`. This covers all letters,
    including lowercase and uppercase. With this one simple regex, you are able to
    match any (pure) alphabetical string for that part of the email. Now, the next
    pattern is `@`, which is added to the previous regex by the `+` character. This
    is the way to build up a complex regex: by adding/stacking up individual regex
    patterns. We also use the same `[a-zA-Z]` for the email domain name and add a
    `.com` at the end to complete the pattern as a valid email address. Why `\.`?
    Because, by itself, a dot (`.`) is used as a special modifier in regex but here
    we want to use a dot (`.`) just as a dot (`.`), not as a modifier. So, we need
    to precede it with `\`.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: So, with this regex, we could extract the first email address perfectly but
    got `No match` with the second one. What happened with the second email ID?
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The regex could not capture it because it had the number `12` in the name. That
    pattern is not captured by the expression [`a-zA-Z`].
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Let''s change that and add the digits as well:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE199]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE200]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We caught the first email ID perfectly. But what's going on with the second
    one? Again, we got a mismatch. The reason is that we changed the `.com` to `.org`
    in that email, and in our regex expression, that portion was hardcoded as `.com`,
    so it did not find a match.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Let''s try to address this in the following regex:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE201]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE202]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In this regex, we used the fact that most domain identifiers have two or three
    characters, so we used `[a-zA-Z]{2,3}` to capture that.
  prefs: []
  type: TYPE_NORMAL
- en: What happened with the second email ID? This is an example of the small tweaks
    that you can make to stay ahead of telemarketers who want to scrape online forums
    or any other corpus of text and extract your email ID. If you do not want your
    email to be found, you can change `@` to `[AT]` and `.` to `[DOT]`, and hopefully,
    that should beat some regex techniques (but not all of them).
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/2UXv6eS.](https://packt.live/2UXv6eS%20)
  prefs: []
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/315GaL9](https://packt.live/315GaL9).
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 7.25: The Use of OR in RegEx Using the OR Operator'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this exercise, we will use the `OR` operator in a Regex expression. We will
    try to extract patterns of 10-digit numbers that could be phone numbers. We can
    do that by using the `|` operator. Let''s go through the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s start with the `OR` operator:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE203]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE204]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note the use of `{10}` to denote exactly `10`-digit numbers in the pattern.
    But the second number could not be matched for obvious reasons – it had `-` symbols
    inserted in between groups of numbers.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Use multiple smaller regexes and logically combine them by using the following
    command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE205]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE206]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Phone numbers are written in a myriad of ways and if you search on the web,
    you will see examples of very complex regexes (written not only in Python but
    in other widely used languages for web apps such as JavaScript, C++, PHP, and
    Perl) for capturing phone numbers.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Create four strings and execute `print_match` on them:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE207]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE208]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: So, as you can see, thanks to all the different patterns we have added together
    using the `OR` operator, we are able to detect phone numbers even if they are
    written in very different ways.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/3eeZc59.](https://packt.live/3eeZc59%20)
  prefs: []
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/2APMFH5](https://packt.live/2APMFH5).
  prefs: []
  type: TYPE_NORMAL
- en: The findall Method
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The last regex method that we will cover in this chapter is `findall`. Essentially,
    it is a **search-and-aggregate** method, that is, it puts together all the instances
    that match the regex pattern in a given text and returns them in a list. This
    is extremely useful, as we can just count the length of the returned list to count
    the number of occurrences or pick and use the returned pattern-matched words one
    by one as we see fit.
  prefs: []
  type: TYPE_NORMAL
- en: Note that although we are giving short examples of single sentences in this
    chapter, you will often deal with a large corpus of text when using a regex.
  prefs: []
  type: TYPE_NORMAL
- en: 'In those cases, you are likely to get many matches from a single regex pattern
    search. For all of those cases, the `findall` method is going to be the most useful:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE209]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE210]'
  prefs: []
  type: TYPE_PRE
- en: With all this knowledge gained from the chapter, let's get started with solving
    the following activities.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 7.01: Extracting the Top 100 e-books from Gutenberg'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Project Gutenberg encourages the creation and distribution of eBooks by encouraging
    volunteer efforts to digitize and archive cultural works. This activity aims to
    scrape the URL of Project Gutenberg's Top 100 eBooks to identify the eBooks' links.
    It uses `BeautifulSoup` to parse the HTML and regular expression code to identify
    the Top 100 eBook file numbers. You can use these numbers to download the book
    into your local drive if you want.
  prefs: []
  type: TYPE_NORMAL
- en: 'These are the steps that will help you complete this activity:'
  prefs: []
  type: TYPE_NORMAL
- en: Import the necessary libraries, including `regex` and `BeautifulSoup`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Read the HTML from the URL.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Write a small function to check the status of the web request.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Decode the response and pass this on to `BeautifulSoup` for HTML parsing.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Find all the `href` tags and store them in the list of links. Check what the
    list looks like – print the first 30 elements.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use a regular expression to find the numeric digits in these links. These are
    the file numbers for the top 100 eBooks.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Initialize the empty list to hold the file numbers over an appropriate range
    and use `regex` to find the numeric digits in the link `href` string. `findall`
    method.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What does the `soup` object's text look like? Use the `.text` method and print
    only the first 2,000 characters (do not print the whole thing, as it is too long).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Search in the extracted text (using a regular expression) from the `soup` object
    to find the names of the top 100 eBooks (yesterday's ranking).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a starting index. It should point at the text *Top 100 Ebooks yesterday*.
    Use the `splitlines` method of `soup.text`. It splits the lines of text of the
    `soup` object.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the `for` loop `1-100` to add the strings of the next `100` lines to this
    temporary list. `splitlines` method.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use a regular expression to extract only text from the name strings and append
    it to an empty list. Use `match` and `span` to find the indices and use them.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Print the list of titles.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The output (shown partially) should look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE211]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: The solution for this activity can be found via [this link](B15780_Solution_Final_RK.xhtml#_idTextAnchor323).
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 7.02: Building Your Own Movie Database by Reading an API'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this activity, you will build a complete movie database by communicating
    and interfacing with a free API from the OMDb portal [http://www.omdbapi.com/?](http://www.omdbapi.com/?).You
    will obtain a unique user key from the OMDb website that must be used when your
    program tries to access the API. Then, you will need to store this key value in
    a `.json` file.
  prefs: []
  type: TYPE_NORMAL
- en: 'The aims of this activity are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: To retrieve and print basic data about a movie (the title is entered by the
    user) from the web (the OMDb database).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a poster of the movie can be found, download the file and save it in a user-specified
    location.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'These are the steps that will help you complete this activity:'
  prefs: []
  type: TYPE_NORMAL
- en: Import `urllib.request`, `urllib.parse`, `urllib.error`, and `json`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Load the secret API key (you have to get one from the OMDb website and use that;
    it has a daily limit of 1,000 API keys) from a JSON file, stored in the same folder,
    in a variable.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`json.loads()`.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Students/users will need to obtain a key and store it in a JSON file.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Obtain a key and store it in a JSON file as `APIkeys.json`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open the `APIkeys.json` file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Assign the OMDb portal ([http://www.omdbapi.com/?](http://www.omdbapi.com/?))
    as a string to a variable.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a variable called `apikey` with the last portion of the URL (`&apikey=secretapikey`),
    where `secretapikey` is your own API key.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Write a utility function called `print_json` to print the movie data from a
    JSON file (which we will get from the portal).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Write a utility function to download a poster of the movie based on the information
    from the JSON dataset and save it in your local folder. Use the `os` module. The
    poster data is stored in a JSON key called `Poster`. Use the `open` Python command
    to open a file and write the poster data. Close the file after you're done. This
    function will save the poster data as an image file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Write a utility function called `search_movie` to search for a movie by its
    name, print the downloaded `JSON` data, and save the movie poster in the local
    folder. Use a `try-except` loop for this. Use the previously created `serviceurl`
    and `apikey` variables. You have to pass on a dictionary with a key, `t`, and
    the movie name as the corresponding value to the `urllib.parse.urlencode()` function
    and then add the `serviceurl` and `apikey` variables to the output of the function
    to construct the full URL. This URL will be used to access the data. The `JSON`
    data has a key called `Response`. If it is `True`, that means the read was successful.
    Check this before processing the data. If it's not successful, then print the
    `JSON` key `Error`, which will contain the appropriate error message returned
    by the movie database.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Test the `search_movie` function by entering `Titanic`. The output should look
    like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE212]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Test the `search_movie` function by entering `Random_error` and retrieve the
    data for `Random_error` (obviously, this will not be found, and you should be
    able to check whether your error-catching code is working properly). The expected
    output is as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE213]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The solution for this activity can be found via [this link](B15780_Solution_Final_RK.xhtml#_idTextAnchor324).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Look for a folder called `Posters` in the same directory you are working in.
    It should contain a file called `Titanic.jpg`. Check the file.
  prefs: []
  type: TYPE_NORMAL
- en: In this activity, we have seen a few general tricks for working with an API
    that are fairly common for other popular API services such as Google and Twitter.
    Now, you should be confident about writing more complex programs to scrape data
    from such services.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we went through several important concepts and learning modules
    related to advanced data gathering and web scraping. We started by reading data
    from web pages using two of the most popular Python libraries – `requests` and
    `BeautifulSoup`. In this task, we utilized the knowledge we gained in the previous
    chapter about the general structure of HTML pages and their interaction with Python
    code. We extracted meaningful data from the Wikipedia home page during this process.
  prefs: []
  type: TYPE_NORMAL
- en: Then, we learned how to read data from XML and JSON files – two of the most
    widely used data streaming/exchange formats on the web. For XML, we showed you
    how to traverse the tree-structure data string efficiently to extract key information.
    For JSON, we mixed it with reading data from the web using an API. The API we
    consumed was RESTful, which is one of the major standards in web APIs.
  prefs: []
  type: TYPE_NORMAL
- en: At the end of this chapter, we went through a detailed exercise using regex
    techniques in tricky string-matching problems to scrape useful information from
    a large and messy text corpus, parsed from HTML. This chapter should come in extremely
    handy for string and text processing tasks in your data wrangling career.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will learn about databases with Python.
  prefs: []
  type: TYPE_NORMAL
