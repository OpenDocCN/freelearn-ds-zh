<html><head></head><body>
<div id="_idContainer097" class="calibre2">
<h1 class="chapter-number" id="_idParaDest-42"><a id="_idTextAnchor042" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.1.1">3</span></h1>
<h1 id="_idParaDest-43" class="calibre5"><a id="_idTextAnchor043" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.2.1">Simplifying Data Processing Using Snowpark</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.3.1">In the previous chapter, we learned how to set up a development environment for Snowpark, as well as various Snowpark components, such as DataFrames, UDFs, and stored procedures. </span><span class="kobospan" id="kobo.3.2">We also covered how to operate those objects and run them in Snowflake. </span><span class="kobospan" id="kobo.3.3">In this chapter, we will cover data processing with Snowpark and learn how to load, prepare, analyze, and transform data </span><span><span class="kobospan" id="kobo.4.1">using Snowpark.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.5.1">In this chapter, we’re going to cover the following </span><span><span class="kobospan" id="kobo.6.1">main topics:</span></span></p>
<ul class="calibre15">
<li class="calibre14"><span><span class="kobospan" id="kobo.7.1">Data ingestion</span></span></li>
<li class="calibre14"><span class="kobospan" id="kobo.8.1">Data exploration </span><span><span class="kobospan" id="kobo.9.1">and transformation</span></span></li>
<li class="calibre14"><span class="kobospan" id="kobo.10.1">Data grouping </span><span><span class="kobospan" id="kobo.11.1">and analysis</span></span></li>
</ul>
<h1 id="_idParaDest-44" class="calibre5"><a id="_idTextAnchor044" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.12.1">Technical requirements</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.13.1">For this chapter, you require an active Snowflake account and Python installed with Anaconda configured locally. </span><span class="kobospan" id="kobo.13.2">You can refer to the following documentation for </span><span><span class="kobospan" id="kobo.14.1">installation instructions:</span></span></p>
<ul class="calibre15">
<li class="calibre14"><span class="kobospan" id="kobo.15.1">You can sign up for a Snowflake Trial account </span><span><span class="kobospan" id="kobo.16.1">at </span></span><a href="https://signup.snowflake.com/" class="calibre6 pcalibre1 pcalibre"><span><span class="kobospan" id="kobo.17.1">https://signup.snowflake.com/</span></span></a></li>
<li class="calibre14"><span class="kobospan" id="kobo.18.1">To configure Anaconda, follow the guide at  </span><span><span class="kobospan" id="kobo.19.1">https://conda.io/projects/conda/en/latest/user-guide/getting-started.html</span></span></li>
<li class="calibre14"><span class="kobospan" id="kobo.20.1">To install and set up Python for VS Code, follow the guide </span><span><span class="kobospan" id="kobo.21.1">at </span></span><a href="https://code.visualstudio.com/docs/python/python-tutorial" class="calibre6 pcalibre1 pcalibre"><span><span class="kobospan" id="kobo.22.1">https://code.visualstudio.com/docs/python/python-tutorial</span></span></a></li>
<li class="calibre14"><span class="kobospan" id="kobo.23.1">To learn how to operate Jupyter Notebook in VS Code, go </span><span><span class="kobospan" id="kobo.24.1">to </span></span><a href="https://code.visualstudio.com/docs/datascience/jupyter-notebooks" class="calibre6 pcalibre1 pcalibre"><span><span class="kobospan" id="kobo.25.1">https://code.visualstudio.com/docs/datascience/jupyter-notebooks</span></span></a></li>
</ul>
<p class="calibre3"><span class="kobospan" id="kobo.26.1">The supporting materials for this chapter are available in this book’s GitHub repository </span><span><span class="kobospan" id="kobo.27.1">at </span></span><a href="https://github.com/PacktPublishing/The-Ultimate-Guide-To-Snowpark" class="calibre6 pcalibre1 pcalibre"><span><span class="kobospan" id="kobo.28.1">https://github.com/PacktPublishing/The-Ultimate-Guide-To-Snowpark</span></span></a><span><span class="kobospan" id="kobo.29.1">.</span></span></p>
<h1 id="_idParaDest-45" class="calibre5"><a id="_idTextAnchor045" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.30.1">Data ingestion</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.31.1">The first part </span><a id="_idIndexMarker144" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.32.1">of the data engineering process is data ingestion – it is crucial to get all the different data into a usable format in Snowflake for analytics. </span><span class="kobospan" id="kobo.32.2">In the previous chapter, we learned how Snowpark can access data through a DataFrame. </span><span class="kobospan" id="kobo.32.3">This DataFrame can access data from Snowflake tables, views, and objects, such as streams, if we run a query against it. </span><span class="kobospan" id="kobo.32.4">Snowpark supports structured data in various formats, such as Excel and CSV, as well as semi-structured data, such as JSON, XML, Parquet, Avro, and ORC; specialized formats, such as HL7 and DICOM, and unstructured data, such as images and media, can be ingested and handled in Snowpark. </span><span class="kobospan" id="kobo.32.5">Snowpark enables secure and programmatic access to files in </span><span><span class="kobospan" id="kobo.33.1">Snowflake stages.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.34.1">The flexibility of Snowpark Python allows you to adapt to changing data requirements effortlessly. </span><span class="kobospan" id="kobo.34.2">Suppose you start with a CSV file as your data source; you can switch to a JSON or packet format at a later stage. </span><span class="kobospan" id="kobo.34.3">With Snowpark, you don’t need to rewrite your entire code base. </span><span class="kobospan" id="kobo.34.4">Instead, you can make minor adjustments or configuration changes to accommodate the new structure while keeping the core logic intact. </span><span class="kobospan" id="kobo.34.5">This flexibility saves you valuable time and effort, enabling you to switch between different data formats as your needs </span><span><span class="kobospan" id="kobo.35.1">evolve quickly.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.36.1">By leveraging Snowpark’s capabilities, you can focus more on analyzing and utilizing data rather than worrying about the intricacies of data format handling. </span><span class="kobospan" id="kobo.36.2">This streamlined approach empowers you to experiment with different data sources, adapt to evolving data requirements, and efficiently load data into Snowflake tables, all with minimal code changes and </span><span><span class="kobospan" id="kobo.37.1">maximum flexibility.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.38.1">So, let’s delve into the power of Snowpark Python and its ability to effortlessly handle different data formats, allowing you to work with diverse sources without cumbersome code modifications. </span><span class="kobospan" id="kobo.38.2">You will experience the freedom to explore, analyze, and extract insights from your data while enjoying a seamless and flexible </span><span><span class="kobospan" id="kobo.39.1">integration process.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.40.1">The data ingestion scripts are provided in this book’s GitHub repository: </span><a href="https://github.com/PacktPublishing/The-Ultimate-Guide-To-Snowpark" class="calibre6 pcalibre1 pcalibre"><span class="kobospan" id="kobo.41.1">https://github.com/PacktPublishing/The-Ultimate-Guide-To-Snowpark</span></a><span class="kobospan" id="kobo.42.1">. </span><span class="kobospan" id="kobo.42.2">These scripts will simplify the process of uploading any new dataset that will be used for analysis, ensuring a smooth and efficient workflow. </span><span class="kobospan" id="kobo.42.3">Following a similar approach to what was outlined in the preceding chapters, you can effortlessly upload new datasets and explore Snowflake’s data </span><a id="_idIndexMarker145" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.43.1">engineering and machine learning functionalities. </span><span class="kobospan" id="kobo.43.2">The provided data ingestion scripts will act as your guide, making the process seamless </span><span><span class="kobospan" id="kobo.44.1">and hassle-free.</span></span></p>
<h2 id="_idParaDest-46" class="calibre7"><a id="_idTextAnchor046" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.45.1">Important note on datasets</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.46.1">The dataset we’ll be using</span><a id="_idIndexMarker146" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.47.1"> in this chapter provides unique insights into customer behavior, campaign responses, and complaints, enabling data-driven decision-making and customer satisfaction improvement. </span><span class="kobospan" id="kobo.47.2">The original dataset is from the Kaggle platform (</span><a href="https://www.kaggle.com/datasets/rodsaldanha/arketing-campaign" class="calibre6 pcalibre1 pcalibre"><span class="kobospan" id="kobo.48.1">https://www.kaggle.com/datasets/rodsaldanha/arketing-campaign</span></a><span class="kobospan" id="kobo.49.1">). </span><span class="kobospan" id="kobo.49.2">However, the datasets that will be discussed in this section are not directly accessible via a Kaggle link. </span><span class="kobospan" id="kobo.49.3">Instead, we started with a base dataset and generated new data formats to illustrate loading various dataset formats using Snowpark. </span><span class="kobospan" id="kobo.49.4">These datasets can be found in this book’s GitHub repository under the </span><span><strong class="source-inline"><span class="kobospan" id="kobo.50.1">datasets</span></strong></span><span><span class="kobospan" id="kobo.51.1"> folder.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.52.1">The datasets include purchase history in CSV format, campaign information in JSON format, and complaint information in Parquet format. </span><span class="kobospan" id="kobo.52.2">These datasets provide valuable information about customer behavior, campaign responses, </span><span><span class="kobospan" id="kobo.53.1">and complaints:</span></span></p>
<ul class="calibre15">
<li class="calibre14"><strong class="bold"><span class="kobospan" id="kobo.54.1">Purchase history (CSV)</span></strong><span class="kobospan" id="kobo.55.1">: This </span><a id="_idIndexMarker147" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.56.1">file contains customer information, such as ID, education, marital status, and purchase metrics. </span><span class="kobospan" id="kobo.56.2">The dataset offers insights into customer buying habits and can be further analyzed for </span><span><span class="kobospan" id="kobo.57.1">data-driven decisions.</span></span></li>
<li class="calibre14"><strong class="bold"><span class="kobospan" id="kobo.58.1">Campaign information (JSON)</span></strong><span class="kobospan" id="kobo.59.1">: The JSON dataset includes data on campaign acceptance</span><a id="_idIndexMarker148" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.60.1"> and customer responses. </span><span class="kobospan" id="kobo.60.2">Analyzing this dataset will help you refine marketing strategies and understand </span><span><span class="kobospan" id="kobo.61.1">campaign effectiveness.</span></span></li>
<li class="calibre14"><strong class="bold"><span class="kobospan" id="kobo.62.1">Complaint information (Parquet)</span></strong><span class="kobospan" id="kobo.63.1">: This file contains details about customer complaints, including</span><a id="_idIndexMarker149" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.64.1"> contact and revenue metrics. </span><span class="kobospan" id="kobo.64.2">This dataset aids in tracking and addressing customer complaints for </span><span><span class="kobospan" id="kobo.65.1">improved satisfaction.</span></span></li>
</ul>
<p class="callout-heading"><span class="kobospan" id="kobo.66.1">Note</span></p>
<p class="callout"><span class="kobospan" id="kobo.67.1">Moving forward, we will be utilizing our local development environment to execute all Snowpark code, rather than relying on Snowflake worksheets. </span><span class="kobospan" id="kobo.67.2">This approach offers greater flexibility and control over the development and testing of Snowpark scripts. </span><span class="kobospan" id="kobo.67.3">When worksheets are used for specific tasks, we will explicitly call out their usage for clarity </span><span><span class="kobospan" id="kobo.68.1">and context.</span></span></p>
<h2 id="_idParaDest-47" class="calibre7"><a id="_idTextAnchor047" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.69.1">Ingesting a CSV file into Snowflake</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.70.1">Snowflake </span><a id="_idIndexMarker150" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.71.1">supports ingesting data easily using CSV files. </span><span class="kobospan" id="kobo.71.2">We will load the purchase history data into the </span><strong class="source-inline"><span class="kobospan" id="kobo.72.1">PURCHASE_HISTORY</span></strong><span class="kobospan" id="kobo.73.1"> table as a CSV file. </span><span class="kobospan" id="kobo.73.2">We’ll upload </span><strong class="source-inline"><span class="kobospan" id="kobo.74.1">purchase_history.csv</span></strong><span class="kobospan" id="kobo.75.1"> into an internal stage by using a Snowpark session, as </span><span><span class="kobospan" id="kobo.76.1">shown here:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.77.1">
session.file.put('./datasets/purchase_history.csv', 'MY_STAGE')</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.78.1">With that, the file has been uploaded to the internal stage. </span><span class="kobospan" id="kobo.78.2">We will reference this directly in Snowpark. </span><span class="kobospan" id="kobo.78.3">The data schema for the marketing table can also be directly defined as a Snowpark type. </span><span class="kobospan" id="kobo.78.4">The following code provides the necessary columns and data types to create the table </span><span><span class="kobospan" id="kobo.79.1">in Snowflake:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.80.1">
import snowflake.snowpark.types as T
purchase_history_schema = T.StructType([
    T.StructField("ID", T.IntegerType()),
    T.StructField("Year_Birth", T.IntegerType()),
    T.StructField("Education", T.StringType()),
    T.StructField("Marital_Status", T.StringType()),
    T.StructField("Income", T.IntegerType()),
    T.StructField("Kidhome", T.IntegerType()),
    T.StructField("Teenhome", T.IntegerType()),
    T.StructField("Dt_Customer", T.DateType()),
    T.StructField("Recency", T.IntegerType()),
    T.StructField("MntWines", T.IntegerType()),
    T.StructField("MntFruits", T.IntegerType()),
    T.StructField("MntMeatProducts", T.IntegerType()),
    T.StructField("MntFishProducts", T.IntegerType()),
    T.StructField("MntSweetProducts", T.IntegerType()),
    T.StructField("MntGoldProds", T.IntegerType()),
    T.StructField("NumDealsPurchases", T.IntegerType()),
    T.StructField("NumWebPurchases", T.IntegerType()),
    T.StructField("NumCatalogPurchases", T.IntegerType()),
    T.StructField("NumStorePurchases", T.IntegerType()),
    T.StructField("NumWebVisitsMonth", T.IntegerType())
])</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.81.1">In this code</span><a id="_idIndexMarker151" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.82.1"> snippet, we take our first step toward understanding the structure of our data by defining a schema for our purchase history dataset. </span><span class="kobospan" id="kobo.82.2">Using the Snowflake Snowpark library, we establish the fields and corresponding data types, setting the foundation for our data analysis journey. </span><span class="kobospan" id="kobo.82.3">This code serves as a starting point, guiding us in defining and working with structured data. </span><span class="kobospan" id="kobo.82.4">This is not the only way we can load the dataset using Snowpark. </span><span class="kobospan" id="kobo.82.5">We will continue to explore different methodologies to load other tabular datasets as </span><span><span class="kobospan" id="kobo.83.1">we progress.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.84.1">This code imports the necessary types from the Snowflake Snowpark library. </span><span class="kobospan" id="kobo.84.2">It creates a variable called </span><strong class="source-inline"><span class="kobospan" id="kobo.85.1">purchase_history_schema</span></strong><span class="kobospan" id="kobo.86.1"> and assigns it a </span><strong class="source-inline"><span class="kobospan" id="kobo.87.1">StructType</span></strong><span class="kobospan" id="kobo.88.1"> object, representing a structured schema for the dataset. </span><span class="kobospan" id="kobo.88.2">The </span><strong class="source-inline"><span class="kobospan" id="kobo.89.1">StructType</span></strong><span class="kobospan" id="kobo.90.1"> object contains multiple </span><strong class="source-inline"><span class="kobospan" id="kobo.91.1">StructField</span></strong><span class="kobospan" id="kobo.92.1"> objects, each representing a field in the dataset. </span><span class="kobospan" id="kobo.92.2">Each </span><strong class="source-inline"><span class="kobospan" id="kobo.93.1">StructField</span></strong><span class="kobospan" id="kobo.94.1"> object specifies the name of the area and its corresponding data type using the types provided by Snowflake Snowpark. </span><span class="kobospan" id="kobo.94.2">The following code reads </span><span><span class="kobospan" id="kobo.95.1">the file:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.96.1">
purchase_history = session.read\
        .option("FIELD_DELIMITER", ',')\
        .option("SKIP_HEADER", 1)\
        .option("ON_ERROR", "CONTINUE")\
        .schema(purchase_history_schema).csv(
            "@MY_Stage/purchase_history.csv.gz")\
        .copy_into_table("PURCHASE_HISTORY")</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.97.1">The CSV file </span><a id="_idIndexMarker152" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.98.1">is read with file format options such as </span><strong class="source-inline"><span class="kobospan" id="kobo.99.1">FIELD_DELIMITER</span></strong><span class="kobospan" id="kobo.100.1">, </span><strong class="source-inline"><span class="kobospan" id="kobo.101.1">SKIP_HEADER</span></strong><span class="kobospan" id="kobo.102.1">, and others, all of which are specified alongside the schema defined in the preceding definition. </span><span class="kobospan" id="kobo.102.2">The </span><strong class="source-inline"><span class="kobospan" id="kobo.103.1">PURCHASE_HISTORY</span></strong><span class="kobospan" id="kobo.104.1"> table was created with the data from the CSV file, which is now ready </span><span><span class="kobospan" id="kobo.105.1">for processing:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.106.1">
session.table("PURCHASE_HISTORY").show()</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.107.1">The preceding code shows the output of the </span><span><strong class="source-inline"><span class="kobospan" id="kobo.108.1">PURCHASE_HISTORY</span></strong></span><span><span class="kobospan" id="kobo.109.1"> table:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer054">
<span class="kobospan" id="kobo.110.1"><img alt="Figure 3.1 – The PURCHASE_HISTORY table" src="image/B19923_03_1.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.111.1">Figure 3.1 – The PURCHASE_HISTORY table</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.112.1">The CSV is easy to load as it uses the file format options available in Snowflake. </span><span class="kobospan" id="kobo.112.2">Now, let’s see how we can load JSON files </span><span><span class="kobospan" id="kobo.113.1">into Snowflake.</span></span></p>
<h2 id="_idParaDest-48" class="calibre7"><a id="_idTextAnchor048" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.114.1">Ingesting JSON into Snowflake</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.115.1">Snowflake</span><a id="_idIndexMarker153" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.116.1"> allows JSON structures to be ingested and processed via the </span><strong class="source-inline"><span class="kobospan" id="kobo.117.1">Variant</span></strong><span class="kobospan" id="kobo.118.1"> data type. </span><span class="kobospan" id="kobo.118.2">We can ingest JSON similar to how we would ingest a CSV file – by uploading it into the internal stage. </span><span class="kobospan" id="kobo.118.3">The </span><strong class="source-inline"><span class="kobospan" id="kobo.119.1">campaign_info.json</span></strong><span class="kobospan" id="kobo.120.1"> file contains data about marketing campaigns. </span><span class="kobospan" id="kobo.120.2">We can load this into the </span><strong class="source-inline"><span class="kobospan" id="kobo.121.1">CAMPAIGN_INFO</span></strong><span class="kobospan" id="kobo.122.1"> table by using the </span><span><span class="kobospan" id="kobo.123.1">following code:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.124.1">
session.file.put('./datasets/campaign_info.json', 'MY_STAGE')</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.125.1">With that, the file has been uploaded to the internal stage; we will reference it in Snowpark. </span><span class="kobospan" id="kobo.125.2">Snowpark can access the file to load it into </span><span><span class="kobospan" id="kobo.126.1">a table:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.127.1">
df_from_json = session.read.json("@My_Stage/campaign_info.json.gz")</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.128.1">The </span><a id="_idIndexMarker154" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.129.1">contents of the JSON file are read into the DataFrame as JSON objects. </span><span class="kobospan" id="kobo.129.2">This DataFrame can be written into a table as </span><span><span class="kobospan" id="kobo.130.1">a variant:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.131.1">
df_from_json.write.save_as_table("CAMPAIGN_INFO_TEMP", 
    mode = "overwrite")</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.132.1">The </span><strong class="source-inline"><span class="kobospan" id="kobo.133.1">CAMPAIGN_INFO_TEMP</span></strong><span class="kobospan" id="kobo.134.1"> table contains the JSON data. </span><span class="kobospan" id="kobo.134.2">We can query the table to view </span><span><span class="kobospan" id="kobo.135.1">the data:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.136.1">
df_from_json.show()</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.137.1">The preceding command displays the JSON data from </span><span><span class="kobospan" id="kobo.138.1">the DataFrame:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer055">
<span class="kobospan" id="kobo.139.1"><img alt="Figure 3.2 – The Campaign Info table" src="image/B19923_03_2.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.140.1">Figure 3.2 – The Campaign Info table</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.141.1">The following code snippet utilizes the Snowpark library in Snowflake to manipulate </span><span><span class="kobospan" id="kobo.142.1">a DataFrame:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.143.1">
from snowflake.snowpark.functions import col
df_flatten = df_from_json.select(col("$1")["ID"].as_("ID"),\
    col("$1")["AcceptedCmp1"].as_("AcceptedCmp1"),\
    col("$1")["AcceptedCmp2"].as_("AcceptedCmp2"),\
    col("$1")["AcceptedCmp3"].as_("AcceptedCmp3"),\
    col("$1")["AcceptedCmp4"].as_("AcceptedCmp4"),\
    col("$1")["AcceptedCmp5"].as_("AcceptedCmp5"),\
    col("$1")["Response"].as_("Response"))
df_flatten.write.save_as_table("CAMPAIGN_INFO")</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.144.1">The </span><a id="_idIndexMarker155" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.145.1">preceding code selects specific columns from an existing DataFrame and renames them using the </span><strong class="source-inline"><span class="kobospan" id="kobo.146.1">col</span></strong><span class="kobospan" id="kobo.147.1"> function. </span><span class="kobospan" id="kobo.147.2">The transformed DataFrame is then saved as a new table in Snowflake. </span><span class="kobospan" id="kobo.147.3">The code performs data </span><strong class="bold"><span class="kobospan" id="kobo.148.1">extraction, transformation, and loading </span></strong><span class="kobospan" id="kobo.149.1">(</span><strong class="bold"><span class="kobospan" id="kobo.150.1">ETL</span></strong><span class="kobospan" id="kobo.151.1">) operations by selecting and renaming columns within the DataFrame and saving the result as a new table </span><span><span class="kobospan" id="kobo.152.1">in Snowflake.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.153.1">The </span><strong class="source-inline"><span class="kobospan" id="kobo.154.1">CAMPAIGN_INFO</span></strong><span class="kobospan" id="kobo.155.1"> table now contains the flattened data, with the data in separate columns so that it’s easier to process. </span><span class="kobospan" id="kobo.155.2">Let’s have a look at </span><span><span class="kobospan" id="kobo.156.1">the data:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.157.1">
session.table("CAMPAIGN_INFO").show()</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.158.1">The preceding code shows the output of the </span><span><strong class="source-inline"><span class="kobospan" id="kobo.159.1">CAMPAIGN_INFO</span></strong></span><span><span class="kobospan" id="kobo.160.1"> table:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer056">
<span class="kobospan" id="kobo.161.1"><img alt="Figure 3.3 – The CAMPAIGN_INFO table" src="image/B19923_03_3.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.162.1">Figure 3.3 – The CAMPAIGN_INFO table</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.163.1">Loading and processing JSON </span><a id="_idIndexMarker156" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.164.1">files in Snowpark becomes easier when using the </span><strong class="source-inline"><span class="kobospan" id="kobo.165.1">Variant</span></strong><span class="kobospan" id="kobo.166.1"> column. </span><span class="kobospan" id="kobo.166.2">Next, we will cover how to load a Parquet file into Snowflake </span><span><span class="kobospan" id="kobo.167.1">using Snowpark.</span></span></p>
<h2 id="_idParaDest-49" class="calibre7"><a id="_idTextAnchor049" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.168.1">Ingesting Parquet files into Snowflake</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.169.1">Parquet is a </span><a id="_idIndexMarker157" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.170.1">popular open source format for storing data licensed under Apache. </span><span class="kobospan" id="kobo.170.2">The column-oriented format is lighter to store and faster to process. </span><span class="kobospan" id="kobo.170.3">Parquet also supports complex data types since the data and the column information are stored in Parquet format. </span><span class="kobospan" id="kobo.170.4">The </span><strong class="source-inline"><span class="kobospan" id="kobo.171.1">COMPLAINT_INFO</span></strong><span class="kobospan" id="kobo.172.1"> table consists of customer complaint information. </span><span class="kobospan" id="kobo.172.2">Let’s load this </span><span><span class="kobospan" id="kobo.173.1">into Snowflake:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.174.1">
session.file.put('./datasets/complain_info.parquet', 'MY_STAGE')</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.175.1">The file will be uploaded into the internal stage. </span><span class="kobospan" id="kobo.175.2">Snowpark can access it to process and load it into </span><span><span class="kobospan" id="kobo.176.1">a table:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.177.1">
df_raw = session.read.parquet("@My_Stage/complain_info.parquet")
df_raw.copy_into_table("COMPLAINT_INFO")</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.178.1">The Parquet file is read into the DataFrame and then copied into the </span><strong class="source-inline"><span class="kobospan" id="kobo.179.1">COMPLAINT_INFO</span></strong><span class="kobospan" id="kobo.180.1"> table. </span><span class="kobospan" id="kobo.180.2">Since the Parquet file already contains the table metadata information, it defines the table structure. </span><span class="kobospan" id="kobo.180.3">We can query the table to view </span><span><span class="kobospan" id="kobo.181.1">the data:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.182.1">
session.table("COMPLAINT_INFO").show()</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.183.1">This will output the following </span><span><strong class="source-inline"><span class="kobospan" id="kobo.184.1">COMPLAINT_INFO</span></strong></span><span><span class="kobospan" id="kobo.185.1"> table:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer057">
<span class="kobospan" id="kobo.186.1"><img alt="Figure 3.4 – The COMPLAINT_INFO table" src="image/B19923_03_4.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.187.1">Figure 3.4 – The COMPLAINT_INFO table</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.188.1">Parquet is </span><a id="_idIndexMarker158" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.189.1">one of the preferred formats for Snowflake since it’s the format that’s used by Apache Iceberg. </span><span class="kobospan" id="kobo.189.2">Parquet stands out in data engineering and data science for its columnar storage, which optimizes compression and query performance. </span><span class="kobospan" id="kobo.189.3">Its support for schema evolution and partitioning ensures flexibility and efficiency in handling evolving data structures. </span><span class="kobospan" id="kobo.189.4">With broad compatibility across various data processing frameworks, Parquet enables seamless integration into existing workflows, making it a cornerstone format in modern data pipelines. </span><span class="kobospan" id="kobo.189.5">In the next section, we will cover how easy it is to load unstructured data, such as an image, </span><span><span class="kobospan" id="kobo.190.1">into Snowflake.</span></span></p>
<p class="callout-heading"><span class="kobospan" id="kobo.191.1">Important note</span></p>
<p class="callout"><span class="kobospan" id="kobo.192.1">We’ve chosen to maintain separate stages for handling images and text, although it’s not mandatory to do so. </span><span class="kobospan" id="kobo.192.2">The </span><strong class="source-inline1"><span class="kobospan" id="kobo.193.1">MY_TEXT</span></strong><span class="kobospan" id="kobo.194.1"> and </span><strong class="source-inline1"><span class="kobospan" id="kobo.195.1">MY_IMAGES</span></strong><span class="kobospan" id="kobo.196.1"> stages can be prepared using the same methods we </span><span><span class="kobospan" id="kobo.197.1">outlined earlier.</span></span></p>
<h2 id="_idParaDest-50" class="calibre7"><a id="_idTextAnchor050" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.198.1">Ingesting images into Snowpark</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.199.1">Snowflake</span><a id="_idIndexMarker159" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.200.1"> supports versatile data, such as images, that can be uploaded into a stage and executed directly in Snowpark without the need to manage dependencies </span><span><span class="kobospan" id="kobo.201.1">as well.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.202.1">Platforms such as Amazon S3, Google Cloud Storage, and Azure Blob Storage are commonly preferred for managing and storing image data due to their scalability and reliability. </span><span class="kobospan" id="kobo.202.2">However, it’s worth noting that Snowpark also offers flexibility in loading image files, making it a versatile option for handling image data in data engineering and data science workflows. </span><span class="kobospan" id="kobo.202.3">We will be loading a bunch of sample images that can be used </span><span><span class="kobospan" id="kobo.203.1">for processing:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.204.1">
session.file.put("./datasets/sample_images/*.png", "@My_Images")</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.205.1">The preceding code loads the images from the local folder to the internal stage. </span><span class="kobospan" id="kobo.205.2">The path can support wildcard entries to upload all the images in a particular folder. </span><span class="kobospan" id="kobo.205.3">The folder in the stage can be queried to get the list of images that </span><span><span class="kobospan" id="kobo.206.1">were uploaded:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.207.1">
Session.sql("LS @My_Images").show()</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.208.1">The preceding code shows a list of all the images that are present in </span><span><span class="kobospan" id="kobo.209.1">the stage:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer058">
<span class="kobospan" id="kobo.210.1"><img alt="Figure 3.5 – List of images" src="image/B19923_03_5.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.211.1">Figure 3.5 – List of images</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.212.1">Once the image has been uploaded, it can be directly accessed via Snowpark. </span><span class="kobospan" id="kobo.212.2">Snowpark supports the </span><strong class="source-inline"><span class="kobospan" id="kobo.213.1">get_stream</span></strong><span class="kobospan" id="kobo.214.1"> function to stream the file’s contents as bytes from the stage. </span><span class="kobospan" id="kobo.214.2">We can use a library such as Pillow to read the file from the </span><span><span class="kobospan" id="kobo.215.1">bytes stream:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.216.1">
import PIL.Image
bytes_object = session.file.get_stream(
    "@My_Images/101.png.gz", decompress=True)
image = PIL.Image.open(bytes_object)
image.resize((150,150))</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.217.1">This will </span><a id="_idIndexMarker160" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.218.1">output the </span><span><span class="kobospan" id="kobo.219.1">following image:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer059">
<span class="kobospan" id="kobo.220.1"><img alt="Figure 3.6 – Rendering images" src="image/B19923_03_6.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.221.1">Figure 3.6 – Rendering images</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.222.1">The image is displayed directly in the notebook. </span><span class="kobospan" id="kobo.222.2">Snowpark’s native support for images supports capabilities for use cases such as image classification, image processing, and image recognition. </span><span class="kobospan" id="kobo.222.3">Snowpark also supports rendering images dynamically. </span><span class="kobospan" id="kobo.222.4">We will cover this in the </span><span><span class="kobospan" id="kobo.223.1">next section.</span></span></p>
<h3 class="calibre9"><span class="kobospan" id="kobo.224.1">Reading files dynamically with Snowpark</span></h3>
<p class="calibre3"><span class="kobospan" id="kobo.225.1">Snowpark </span><a id="_idIndexMarker161" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.226.1">contains the </span><strong class="source-inline"><span class="kobospan" id="kobo.227.1">files</span></strong><span class="kobospan" id="kobo.228.1"> module and the </span><strong class="source-inline"><span class="kobospan" id="kobo.229.1">SnowflakeFile</span></strong><span class="kobospan" id="kobo.230.1"> class, both of which provide access to files dynamically and stream them for processing. </span><span class="kobospan" id="kobo.230.2">These dynamic files are also helpful for reading multiple files as we can iterate over them. </span><strong class="source-inline"><span class="kobospan" id="kobo.231.1">open()</span></strong><span class="kobospan" id="kobo.232.1"> extends the </span><strong class="source-inline"><span class="kobospan" id="kobo.233.1">IOBase</span></strong><span class="kobospan" id="kobo.234.1"> file objects and provides the functionality to open a file. </span><span class="kobospan" id="kobo.234.2">The </span><strong class="source-inline"><span class="kobospan" id="kobo.235.1">SnowflakeFile</span></strong><span class="kobospan" id="kobo.236.1"> object also supports other </span><strong class="source-inline"><span class="kobospan" id="kobo.237.1">IOBase</span></strong><span class="kobospan" id="kobo.238.1"> methods for processing the file. </span><span class="kobospan" id="kobo.238.2">The following code shows an example of reading multiple files using a relative path from the </span><span><span class="kobospan" id="kobo.239.1">internal stage:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.240.1">
import snowflake.snowpark as snowpark
from snowflake.snowpark.functions import udf
from snowflake.snowpark.files import SnowflakeFile
from snowflake.snowpark.types import StringType, IntegerType
@udf(
    name="get_bytes_length",
    replace=True,
    input_types=[StringType()],
    return_type=IntegerType(),
    packages=['snowflake-snowpark-python']
)
def get_file_length(file_path):
    with SnowflakeFile.open(file_path) as f:
        s = f.read()
        return len(s)</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.241.1">The </span><a id="_idIndexMarker162" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.242.1">preceding code iterates over the </span><strong class="source-inline"><span class="kobospan" id="kobo.243.1">@MY_TEXTS</span></strong><span class="kobospan" id="kobo.244.1"> stage location and calculates the length of each file using the </span><strong class="source-inline"><span class="kobospan" id="kobo.245.1">SnowflakeFile</span></strong><span class="kobospan" id="kobo.246.1"> method. </span><span class="kobospan" id="kobo.246.2">The path is passed as the input to the UDF. </span><span class="kobospan" id="kobo.246.3">We can execute the function to get </span><span><span class="kobospan" id="kobo.247.1">the output:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.248.1">
session.sql("SELECT RELATIVE_PATH, \
    get_bytes_length(build_scoped_file_url( \
        @MY_TEXTS,RELATIVE_PATH)) \
             as SIZE from DIRECTORY(@MY_TEXTS);").collect()</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.249.1">The preceding code produces the </span><span><span class="kobospan" id="kobo.250.1">following result:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer060">
<span class="kobospan" id="kobo.251.1"><img alt="Figure 3.7 – Dynamic files within Snowpark" src="image/B19923_03_7.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.252.1">Figure 3.7 – Dynamic files within Snowpark</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.253.1">The files in the stage are displayed as output. </span><span class="kobospan" id="kobo.253.2">In this section, we covered ingesting different types </span><a id="_idIndexMarker163" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.254.1">of files into Snowflake using Snowpark. </span><span class="kobospan" id="kobo.254.2">In the next section, we will learn how to perform data preparation and transformations </span><span><span class="kobospan" id="kobo.255.1">using Snowpark.</span></span></p>
<h1 id="_idParaDest-51" class="calibre5"><a id="_idTextAnchor051" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.256.1">Data exploration and transformation</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.257.1">Once the data has been loaded, the next step is to prepare the data so that it can be transformed. </span><span class="kobospan" id="kobo.257.2">In this section, we will cover how to perform data exploration so that we understand how the modify the data </span><span><span class="kobospan" id="kobo.258.1">as necessary.</span></span></p>
<h2 id="_idParaDest-52" class="calibre7"><a id="_idTextAnchor052" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.259.1">Data exploration</span></h2>
<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.260.1">Data exploration</span></strong><span class="kobospan" id="kobo.261.1"> is a</span><a id="_idIndexMarker164" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.262.1"> critical step in data analysis as it sets the stage for successful insights and informed decision-making. </span><span class="kobospan" id="kobo.262.2">By delving into the data, analysts can deeply understand its characteristics, uncover underlying patterns, and identify potential issues or outliers. </span><span class="kobospan" id="kobo.262.3">Exploring the data provides valuable insights into its structure, distribution, and relationships, enabling analysts to choose the appropriate data </span><span><span class="kobospan" id="kobo.263.1">transformation techniques.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.264.1">Understanding the data’s characteristics and patterns helps analysts determine the appropriate transformations and manipulations needed to clean, reshape, or derive new variables from the data. </span><span class="kobospan" id="kobo.264.2">Additionally, data exploration aids in identifying subsets of data that are relevant to the analysis, facilitating the filtering and sub-setting operations required for specific </span><span><span class="kobospan" id="kobo.265.1">analytical objectives.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.266.1">Before embarking on data transformation, we must understand the data we have in place. </span><span class="kobospan" id="kobo.266.2">By comprehensively understanding the data, we can effectively identify its structure, quality, and patterns. </span><span class="kobospan" id="kobo.266.3">This understanding is a solid foundation for informed decision-making during the data transformation process, enabling us to extract meaningful insights and derive maximum value from the data. </span><span class="kobospan" id="kobo.266.4">Take a look at the </span><span><span class="kobospan" id="kobo.267.1">following code:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.268.1">
purchase_history = session.table("PURCHASE_HISTORY")
campaign_info = session.table("CAMPAIGN_INFO")
complain_info = session.table("COMPLAINT_INFO")</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.269.1">Here, we loaded the necessary tables into a session. </span><span class="kobospan" id="kobo.269.2">These tables are now available in the Snowpark session for further data preparation. </span><span class="kobospan" id="kobo.269.3">We will start by preparing the </span><span><strong class="source-inline"><span class="kobospan" id="kobo.270.1">PURCHASE_HISTORY</span></strong></span><span><span class="kobospan" id="kobo.271.1"> table:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.272.1">
purchase_history.show(n=5)</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.273.1">The </span><strong class="source-inline"><span class="kobospan" id="kobo.274.1">show()</span></strong><span class="kobospan" id="kobo.275.1"> method </span><a id="_idIndexMarker165" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.276.1">returns the data from the DataFrame. </span><span class="kobospan" id="kobo.276.2">The preceding code produces the top 5 rows from the </span><span><strong class="source-inline"><span class="kobospan" id="kobo.277.1">PURCHASE_HISTORY</span></strong></span><span><span class="kobospan" id="kobo.278.1"> table:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer061">
<span class="kobospan" id="kobo.279.1"><img alt="Figure 3.8 – PURCHASE_HISTORY – top 5 rows" src="image/B19923_03_8.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.280.1">Figure 3.8 – PURCHASE_HISTORY – top 5 rows</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.281.1">We can use the </span><strong class="source-inline"><span class="kobospan" id="kobo.282.1">collect()</span></strong><span class="kobospan" id="kobo.283.1"> method to display the data in </span><span><span class="kobospan" id="kobo.284.1">the notebook:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.285.1">
purchase_history.collect()</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.286.1">The records from the </span><strong class="source-inline"><span class="kobospan" id="kobo.287.1">PURCHASE_HISTORY</span></strong><span class="kobospan" id="kobo.288.1"> table are shown in the </span><span><span class="kobospan" id="kobo.289.1">JSON array:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer062">
<span class="kobospan" id="kobo.290.1"><img alt="Figure 3.9 – PURCHASE_HISTORY – full table" src="image/B19923_03_9.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.291.1">Figure 3.9 – PURCHASE_HISTORY – full table</span></p>
<p class="callout-heading"><span class="kobospan" id="kobo.292.1">The difference between collect() and show()</span></p>
<p class="callout"><span class="kobospan" id="kobo.293.1">In Snowpark Python, there are two essential functions: </span><strong class="source-inline1"><span class="kobospan" id="kobo.294.1">collect()</span></strong><span class="kobospan" id="kobo.295.1"> and </span><strong class="source-inline1"><span class="kobospan" id="kobo.296.1">show()</span></strong><span class="kobospan" id="kobo.297.1">. </span><span class="kobospan" id="kobo.297.2">These functions serve different purposes in processing and displaying data. </span><span class="kobospan" id="kobo.297.3">The </span><strong class="source-inline1"><span class="kobospan" id="kobo.298.1">collect()</span></strong><span class="kobospan" id="kobo.299.1"> function in Snowpark Python is used to gather or retrieve data from a specified source, such as a table, file, or API. </span><span class="kobospan" id="kobo.299.2">It allows you to perform queries, apply filters, and extract the desired information from the data source. </span><span class="kobospan" id="kobo.299.3">The collected data is stored in a variable or structure, such as a DataFrame, for further analysis </span><span><span class="kobospan" id="kobo.300.1">or manipulation.</span></span></p>
<p class="callout"><span class="kobospan" id="kobo.301.1">On the other hand, the </span><strong class="source-inline1"><span class="kobospan" id="kobo.302.1">show()</span></strong><span class="kobospan" id="kobo.303.1"> function in Snowpark Python is primarily used to display the contents of a DataFrame or any other data structure in a tabular format. </span><span class="kobospan" id="kobo.303.2">It provides a convenient way to visualize and inspect the data at different stages of the data processing pipeline. </span><span class="kobospan" id="kobo.303.3">The </span><strong class="source-inline1"><span class="kobospan" id="kobo.304.1">show()</span></strong><span class="kobospan" id="kobo.305.1"> function presents the data in a human-readable manner, showing the rows and columns in a structured table-like format. </span><span class="kobospan" id="kobo.305.2">It can be helpful for debugging, understanding the data’s structure, or performing exploratory </span><span><span class="kobospan" id="kobo.306.1">data analysis.</span></span></p>
<p class="callout"><span class="kobospan" id="kobo.307.1">In short, the </span><strong class="source-inline1"><span class="kobospan" id="kobo.308.1">collect()</span></strong><span class="kobospan" id="kobo.309.1"> function focuses on gathering and retrieving data from a source, while the </span><strong class="source-inline1"><span class="kobospan" id="kobo.310.1">show()</span></strong><span class="kobospan" id="kobo.311.1"> function displays the data in a readable format. </span><span class="kobospan" id="kobo.311.2">Both functions play essential roles in Snowpark Python when it comes to working with data, but they serve distinct purposes in the data </span><span><span class="kobospan" id="kobo.312.1">processing workflow.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.313.1">Next, we will </span><a id="_idIndexMarker166" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.314.1">use the </span><strong class="source-inline"><span class="kobospan" id="kobo.315.1">count()</span></strong><span class="kobospan" id="kobo.316.1"> method to get the total count of the rows in </span><span><span class="kobospan" id="kobo.317.1">the table:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.318.1">
purchase_history.count()</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.319.1">From the resulting output, we can see that the </span><strong class="source-inline"><span class="kobospan" id="kobo.320.1">PURCHASE_HISTORY</span></strong><span class="kobospan" id="kobo.321.1"> table contains around 2,000 rows </span><span><span class="kobospan" id="kobo.322.1">of data.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.323.1">We can now check the columns of the table to understand more about </span><span><span class="kobospan" id="kobo.324.1">this data:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.325.1">
purchase_history.columns</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.326.1">This returns the column information, which helps us understand the data better. </span><span class="kobospan" id="kobo.326.2">The column information contains the data related to customer </span><span><span class="kobospan" id="kobo.327.1">purchase history:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer063">
<span class="kobospan" id="kobo.328.1"><img alt="Figure 3.10 – PURCHASE_HISTORY columns" src="image/B19923_03_10.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.329.1">Figure 3.10 – PURCHASE_HISTORY columns</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.330.1">We can now filter the data to slice and dice it. </span><span class="kobospan" id="kobo.330.2">We can use the following code to filter specific rows or a </span><span><span class="kobospan" id="kobo.331.1">single row:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.332.1">
from snowflake.snowpark.functions import col
purchase_history.filter(col("id") == 1).show()</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.333.1">This returns</span><a id="_idIndexMarker167" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.334.1"> the column. </span><span class="kobospan" id="kobo.334.2">where </span><strong class="source-inline"><span class="kobospan" id="kobo.335.1">id</span></strong><span class="kobospan" id="kobo.336.1"> is set to </span><strong class="source-inline"><span class="kobospan" id="kobo.337.1">1</span></strong><span class="kobospan" id="kobo.338.1">. </span><span class="kobospan" id="kobo.338.2">We can pass multiple values in the column filter to perform additional </span><span><span class="kobospan" id="kobo.339.1">row-level operations:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer064">
<span class="kobospan" id="kobo.340.1"><img alt="Figure 3.11 – PURCHASE_HISTORY ID filter" src="image/B19923_03_11.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.341.1">Figure 3.11 – PURCHASE_HISTORY ID filter</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.342.1">If we need to add multiple filter values, we can use the </span><strong class="source-inline"><span class="kobospan" id="kobo.343.1">&amp;</span></strong><span class="kobospan" id="kobo.344.1"> operation to pass multiple column filter values to </span><span><span class="kobospan" id="kobo.345.1">the method:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.346.1">
purchase_history.filter((col("MARITAL_STATUS") == "Married") &amp; 
                        (col("KIDHOME") == 1)).show()</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.347.1">The preceding code provides data about those with </span><strong class="source-inline"><span class="kobospan" id="kobo.348.1">MARITAL_STATUS</span></strong><span class="kobospan" id="kobo.349.1"> set to </span><strong class="source-inline"><span class="kobospan" id="kobo.350.1">Married</span></strong><span class="kobospan" id="kobo.351.1"> and who have kids at </span><span><span class="kobospan" id="kobo.352.1">home (</span></span><span><strong class="source-inline"><span class="kobospan" id="kobo.353.1">KIDHOME</span></strong></span><span><span class="kobospan" id="kobo.354.1">):</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer065">
<span class="kobospan" id="kobo.355.1"><img alt="Figure 3.12 – PURCHASE_HISTORY filters" src="image/B19923_03_12.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.356.1">Figure 3.12 – PURCHASE_HISTORY filters</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.357.1">This helps us understand the purchase history pattern of married customers with kids. </span><span class="kobospan" id="kobo.357.2">We can also filter it to the year of birth by passing the year of birth range between 1964 </span><span><span class="kobospan" id="kobo.358.1">and 1980:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.359.1">
purchase_history.filter((col("YEAR_BIRTH") &gt;= 1964) &amp; 
                        (col("YEAR_BIRTH") &lt;= 1980)).show()</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.360.1">This displays the purchase data for customers born between 1964 </span><span><span class="kobospan" id="kobo.361.1">and 1980:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer066">
<span class="kobospan" id="kobo.362.1"><img alt="Figure 3.13 – PURCHASE_HISTORY filters" src="image/B19923_03_13.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.363.1">Figure 3.13 – PURCHASE_HISTORY filters</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.364.1">This data helps </span><a id="_idIndexMarker168" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.365.1">us understand their purchases. </span><span class="kobospan" id="kobo.365.2">We can also use the </span><strong class="source-inline"><span class="kobospan" id="kobo.366.1">select()</span></strong><span class="kobospan" id="kobo.367.1"> method to select only the columns that are required </span><span><span class="kobospan" id="kobo.368.1">for analysis:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.369.1">
purchase_history.select(col("ID"), col("YEAR_BIRTH"), 
                        col("EDUCATION")).show()</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.370.1">The preceding returns only the customer’s ID, year, and </span><span><span class="kobospan" id="kobo.371.1">education status:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer067">
<span class="kobospan" id="kobo.372.1"><img alt="Figure 3.14 – PURCHASE_HISTORY columns" src="image/B19923_03_14.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.373.1">Figure 3.14 – PURCHASE_HISTORY columns</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.374.1">In the upcoming chapters, we will delve deeper into data exploration, uncovering more techniques to gain insights from </span><span><span class="kobospan" id="kobo.375.1">our data.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.376.1">Building upon these basic exploration steps, we will dive into the realm of data transformation operations. </span><span class="kobospan" id="kobo.376.2">By combining our understanding of the data and the power of transformation techniques, we will unlock the full potential of our data and extract valuable insights for </span><a id="_idIndexMarker169" class="calibre6 pcalibre1 pcalibre"/><span><span class="kobospan" id="kobo.377.1">informed decision-making.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.378.1">In the next section, we will discuss how to perform data transformation using </span><span><span class="kobospan" id="kobo.379.1">this data.</span></span></p>
<h2 id="_idParaDest-53" class="calibre7"><a id="_idTextAnchor053" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.380.1">Data transformations</span></h2>
<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.381.1">Data transformation</span></strong><span class="kobospan" id="kobo.382.1"> is a</span><a id="_idIndexMarker170" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.383.1"> fundamental process that involves modifying and reshaping data to make it more suitable for analysis or other downstream tasks, such as the machine learning model building process. </span><span class="kobospan" id="kobo.383.2">It entails applying a series of operations to the data, such as cleaning, filtering, aggregating, and reformatting, to ensure its quality, consistency, and usability. </span><span class="kobospan" id="kobo.383.3">Data transformation allows us to convert raw data into a structured and organized format that can be easily interpreted </span><span><span class="kobospan" id="kobo.384.1">and analyzed.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.385.1">The data requires minimal transformation, and we will cover it extensively in the coming chapters. </span><span class="kobospan" id="kobo.385.2">Our goal for this section is to combine data from different sources, creating a unified table for further processing that we will use in the next chapter. </span><span class="kobospan" id="kobo.385.3">We will leverage Snowpark’s robust join and union capabilities to accomplish this. </span><span class="kobospan" id="kobo.385.4">By utilizing joins, we can merge data based on standard columns or conditions. </span><span class="kobospan" id="kobo.385.5">Unions, on the other hand, allow us to append data from multiple sources vertically. </span><span class="kobospan" id="kobo.385.6">These techniques will enable us to integrate and consolidate our data efficiently, setting the stage for comprehensive analysis and insights. </span><span class="kobospan" id="kobo.385.7">Let’s explore how Snowpark’s join and union capabilities can help us achieve this </span><span><span class="kobospan" id="kobo.386.1">data combination:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.387.1">
purchase_campaign = purchase_history.join(
    campaign_info,
    purchase_history.ID == campaign_info.ID ,
    lsuffix="_left", rsuffix="_right"
)</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.388.1">Here, we are joining the purchase history to campaign information to establish the relationship between purchases and campaigns. </span><span class="kobospan" id="kobo.388.2">The standard ID column is used to select the join and defaults to an </span><span><span class="kobospan" id="kobo.389.1">inner join:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.390.1">
purchase_campaign = purchase_campaign.drop("ID_RIGHT")</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.391.1">We are dropping the extra ID column from the joined result. </span><span class="kobospan" id="kobo.391.2">The DataFrame now contains just a single </span><span><span class="kobospan" id="kobo.392.1">ID column:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.393.1">
purchase_campaign.show()</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.394.1">This displays the </span><a id="_idIndexMarker171" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.395.1">data of the purchase campaign combined with the purchase history and the </span><span><span class="kobospan" id="kobo.396.1">campaign information:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer068">
<span class="kobospan" id="kobo.397.1"><img alt="Figure 3.15 – Purchase campaign data" src="image/B19923_03_15.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.398.1">Figure 3.15 – Purchase campaign data</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.399.1">Let’s combine this with the complaint information to get the </span><span><span class="kobospan" id="kobo.400.1">complete data:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.401.1">
final_combined = purchase_campaign.join(
    complain_info,
    purchase_campaign["ID_LEFT"] == complain_info.ID
)
final_combined = final_combined.drop("ID_LEFT")</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.402.1">Here, we are combining the result of the purchase campaign along with the complaint information by using the standard ID column. </span><span class="kobospan" id="kobo.402.2">The resultant DataFrame contains the complete data required for data analysis. </span><span class="kobospan" id="kobo.402.3">We are dropping the extra ID column from the joined result. </span><span class="kobospan" id="kobo.402.4">The DataFrame now has just a single </span><span><span class="kobospan" id="kobo.403.1">ID column:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.404.1">
final_combined.show()</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.405.1">This displays the final data combined from all three tables. </span><span class="kobospan" id="kobo.405.2">We can now write this data into the table for </span><span><span class="kobospan" id="kobo.406.1">further analysis:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.407.1">
final_combined.write.save_as_table("MARKETING_DATA")</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.408.1">Here, the data is written into the </span><strong class="source-inline"><span class="kobospan" id="kobo.409.1">MARKETING_DATA</span></strong><span class="kobospan" id="kobo.410.1"> table, at which point it will be available inside Snowflake. </span><span class="kobospan" id="kobo.410.2">We need to append this data with the additional marketing data that must</span><a id="_idIndexMarker172" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.411.1"> be loaded into </span><span><span class="kobospan" id="kobo.412.1">this table.</span></span></p>
<p class="callout-heading"><span class="kobospan" id="kobo.413.1">The difference between joins and unions</span></p>
<p class="callout"><span class="kobospan" id="kobo.414.1">Joins combine data from two or more tables based on a shared column or condition. </span><span class="kobospan" id="kobo.414.2">In Snowflake Snowpark, you can perform different types of joins, such as inner join, left join, right join, and full outer join. </span><span class="kobospan" id="kobo.414.3">Joins allow you to merge data horizontally by aligning rows based on matching values in the specified columns. </span><span class="kobospan" id="kobo.414.4">This enables you to combine related data from multiple tables, resulting in a combined dataset that includes information from all the </span><span><span class="kobospan" id="kobo.415.1">joined tables.</span></span></p>
<p class="callout"><span class="kobospan" id="kobo.416.1">On the other hand, unions are used to append data from multiple tables vertically, or result sets into a single dataset. </span><span class="kobospan" id="kobo.416.2">Unlike joins, unions do not require any specific conditions or matching columns. </span><span class="kobospan" id="kobo.416.3">Instead, they stack rows on top of each other, concatenating the data vertically. </span><span class="kobospan" id="kobo.416.4">This is useful when you have similar datasets with the same structure and want to consolidate them into a single dataset. </span><span class="kobospan" id="kobo.416.5">Unions can be performed in Snowflake Snowpark to create a new dataset that contains all the rows from the input tables or </span><span><span class="kobospan" id="kobo.417.1">result sets.</span></span></p>
<p class="callout"><span class="kobospan" id="kobo.418.1">In summary, joins in Snowflake Snowpark are used to combine data horizontally by matching columns, while unions are used to stack data vertically without any specific conditions. </span><span class="kobospan" id="kobo.418.2">Joins merge related data from multiple tables, while unions append similar datasets into a </span><span><span class="kobospan" id="kobo.419.1">single dataset.</span></span></p>
<h3 class="calibre9"><span class="kobospan" id="kobo.420.1">Appending data</span></h3>
<p class="calibre3"><span class="kobospan" id="kobo.421.1">The </span><a id="_idIndexMarker173" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.422.1">Snowflake Snowpark </span><strong class="source-inline"><span class="kobospan" id="kobo.423.1">UNION</span></strong><span class="kobospan" id="kobo.424.1"> function is vital in combining and integrating new data into a Snowflake database. </span><span class="kobospan" id="kobo.424.2">The importance of the </span><strong class="source-inline"><span class="kobospan" id="kobo.425.1">UNION</span></strong><span class="kobospan" id="kobo.426.1"> function lies in its ability to append rows from different data sources vertically, or result sets into a single consolidated dataset. </span><span class="kobospan" id="kobo.426.2">When new data is added to the database, it is often necessary to merge or combine it with existing data for comprehensive analysis. </span><span class="kobospan" id="kobo.426.3">The </span><strong class="source-inline"><span class="kobospan" id="kobo.427.1">UNION</span></strong><span class="kobospan" id="kobo.428.1"> function allows us to seamlessly integrate the newly added data with the existing dataset, creating a unified view encompassing all </span><span><span class="kobospan" id="kobo.429.1">relevant information.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.430.1">This capability of the </span><strong class="source-inline"><span class="kobospan" id="kobo.431.1">UNION</span></strong><span class="kobospan" id="kobo.432.1"> function is precious in scenarios where data is received or updated periodically. </span><span class="kobospan" id="kobo.432.2">For example, suppose we receive daily sales data or log files. </span><span class="kobospan" id="kobo.432.3">In that case, the </span><strong class="source-inline"><span class="kobospan" id="kobo.433.1">UNION</span></strong><span class="kobospan" id="kobo.434.1"> function enables us to effortlessly append the new records to the existing dataset, ensuring that our analysis reflects the most up-to-date information. </span><span class="kobospan" id="kobo.434.2">Additionally, it</span><a id="_idIndexMarker174" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.435.1"> ensures data consistency and allows for seamless continuity in data analysis, enabling us to derive accurate insights and make informed decisions based on the complete and </span><span><span class="kobospan" id="kobo.436.1">unified dataset.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.437.1">The additional marketing data is available in the </span><strong class="source-inline"><span class="kobospan" id="kobo.438.1">MARKETING_ADDITIONAL</span></strong><span class="kobospan" id="kobo.439.1"> table. </span><span class="kobospan" id="kobo.439.2">Let’s see how we can leverage Snowpark’s </span><strong class="source-inline"><span class="kobospan" id="kobo.440.1">UNION</span></strong><span class="kobospan" id="kobo.441.1"> function to include this additional data </span><span><span class="kobospan" id="kobo.442.1">for processing:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.443.1">
marketing_additional = session.table("MARKETING_ADDITIONAL")
marketing_additional.show()</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.444.1">The preceding code displays the data from the </span><span><strong class="source-inline"><span class="kobospan" id="kobo.445.1">MARKETING_ADDITIONAL</span></strong></span><span><span class="kobospan" id="kobo.446.1"> table:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer069">
<span class="kobospan" id="kobo.447.1"><img alt="Figure 3.16 – The MARKETING_ADDITIONAL table" src="image/B19923_03_16.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.448.1">Figure 3.16 – The MARKETING_ADDITIONAL table</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.449.1">With that, the table has been loaded into the DataFrame. </span><span class="kobospan" id="kobo.449.2">Let’s look at the number of rows in our original and </span><span><span class="kobospan" id="kobo.450.1">appended tables:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.451.1">
print("No of rows in MARKETING_ADDITIONAL table: \
    ",marketing_additional.count())
print("No of rows in PURCHASE_HISTORY table: \
    ",final_combined.count())</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.452.1">This code displays the total number of rows in the </span><strong class="source-inline"><span class="kobospan" id="kobo.453.1">MARKETING_ADDITIONAL</span></strong><span class="kobospan" id="kobo.454.1"> and </span><span><strong class="source-inline"><span class="kobospan" id="kobo.455.1">PURCHASE_HISTORY</span></strong></span><span><span class="kobospan" id="kobo.456.1"> tables:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer070">
<span class="kobospan" id="kobo.457.1"><img alt="Figure 3.17 – Data row count" src="image/B19923_03_17.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.458.1">Figure 3.17 – Data row count</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.459.1">The </span><strong class="source-inline"><span class="kobospan" id="kobo.460.1">MARKETING_ ADDITIONAL</span></strong><span class="kobospan" id="kobo.461.1"> table contains 240 rows of new data that must be appended with the </span><strong class="source-inline"><span class="kobospan" id="kobo.462.1">PURCHASE_HISTORY</span></strong><span class="kobospan" id="kobo.463.1"> table, which contains 2,000 rows of data. </span><span class="kobospan" id="kobo.463.2">Since the column names </span><a id="_idIndexMarker175" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.464.1">are identical, the data can be appended by </span><span><span class="kobospan" id="kobo.465.1">using </span></span><span><strong class="source-inline"><span class="kobospan" id="kobo.466.1">union_by_name</span></strong></span><span><span class="kobospan" id="kobo.467.1">:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.468.1">
final_appended = final_combined.union_by_name(marketing_additional)</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.469.1">Now, the DataFrame contains the appended data. </span><span class="kobospan" id="kobo.469.2">Let’s look at the number of rows in </span><span><span class="kobospan" id="kobo.470.1">this DataFrame:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.471.1">
print("No of rows in UPDATED table: ",final_appended.count())
final_appended.show()</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.472.1">The preceding code shows the final data that’s in </span><span><span class="kobospan" id="kobo.473.1">the DataFrame:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer071">
<span class="kobospan" id="kobo.474.1"><img alt="Figure 3.18 – The MARKETING_FINAL table" src="image/B19923_03_18.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.475.1">Figure 3.18 – The MARKETING_FINAL table</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.476.1">The total count of the rows is 2,240. </span><span class="kobospan" id="kobo.476.2">With that, the new data has been appended. </span><span class="kobospan" id="kobo.476.3">Now, we will write this data into the </span><strong class="source-inline"><span class="kobospan" id="kobo.477.1">MARKETING_FINAL</span></strong><span class="kobospan" id="kobo.478.1"> table </span><span><span class="kobospan" id="kobo.479.1">in Snowflake:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.480.1">
final_appended.write.save_as_table("MARKETING_FINAL")</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.481.1">The </span><strong class="source-inline"><span class="kobospan" id="kobo.482.1">MARKETING_DATA</span></strong><span class="kobospan" id="kobo.483.1"> table is now available in Snowflake and can </span><span><span class="kobospan" id="kobo.484.1">be consumed.</span></span></p>
<p class="callout-heading"><span class="kobospan" id="kobo.485.1">The difference between union and union_by_name</span></p>
<p class="callout"><span class="kobospan" id="kobo.486.1">Two methods are available for combining data: </span><strong class="source-inline1"><span class="kobospan" id="kobo.487.1">union_by_name</span></strong><span class="kobospan" id="kobo.488.1"> and </span><strong class="source-inline1"><span class="kobospan" id="kobo.489.1">union</span></strong><span class="kobospan" id="kobo.490.1">. </span><span class="kobospan" id="kobo.490.2">Both methods allow multiple datasets to be merged, but they differ in their approach </span><span><span class="kobospan" id="kobo.491.1">and functionality.</span></span></p>
<p class="callout"><span class="kobospan" id="kobo.492.1">The </span><strong class="source-inline1"><span class="kobospan" id="kobo.493.1">union_by_name</span></strong><span class="kobospan" id="kobo.494.1"> method in Snowpark Python is specifically designed to combine datasets by matching and merging columns based on their names. </span><span class="kobospan" id="kobo.494.2">This method ensures that the columns with the same name from different datasets are merged, creating a unified dataset. </span><span class="kobospan" id="kobo.494.3">It is beneficial when you have datasets with similar column structures and want to consolidate them while preserving the </span><span><span class="kobospan" id="kobo.495.1">column names.</span></span></p>
<p class="callout"><span class="kobospan" id="kobo.496.1">On the other hand, the </span><strong class="source-inline1"><span class="kobospan" id="kobo.497.1">union</span></strong><span class="kobospan" id="kobo.498.1"> method in Snowpark Python combines datasets by simply appending them vertically, regardless of column names or structures. </span><span class="kobospan" id="kobo.498.2">This method concatenates the rows from one dataset with the rows from another, resulting in a single dataset with all the rows from both sources. </span><span class="kobospan" id="kobo.498.3">The </span><strong class="source-inline1"><span class="kobospan" id="kobo.499.1">union</span></strong><span class="kobospan" id="kobo.500.1"> method is suitable for stacking datasets vertically without considering column names or matching structures. </span><span class="kobospan" id="kobo.500.2">However, note that in certain cases, the column type matters, such as when casting a string column to a </span><span><span class="kobospan" id="kobo.501.1">numeric value.</span></span></p>
<h1 id="_idParaDest-54" class="calibre5"><a id="_idTextAnchor054" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.502.1">Data grouping and analysis</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.503.1">Now that the data is ready and has been transformed, the next step is to see how we can group data to understand important patterns and analyze it. </span><span class="kobospan" id="kobo.503.2">In this section, we will aggregate this data and </span><span><span class="kobospan" id="kobo.504.1">analyze it.</span></span></p>
<h2 id="_idParaDest-55" class="calibre7"><a id="_idTextAnchor055" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.505.1">Data grouping</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.506.1">In data analysis, understanding</span><a id="_idIndexMarker176" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.507.1"> patterns within datasets is crucial for gaining insights and making informed decisions. </span><span class="kobospan" id="kobo.507.2">One powerful tool that aids in this process is the </span><strong class="source-inline"><span class="kobospan" id="kobo.508.1">group_by</span></strong><span class="kobospan" id="kobo.509.1"> function in Snowpark Python. </span><span class="kobospan" id="kobo.509.2">This function allows us to group data based on specific criteria, enabling us to dissect and analyze the dataset in a </span><span><span class="kobospan" id="kobo.510.1">structured manner.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.511.1">By utilizing the </span><strong class="source-inline"><span class="kobospan" id="kobo.512.1">group_by</span></strong><span class="kobospan" id="kobo.513.1"> function, we can uncover valuable insights into how data is distributed and correlated across different categories or attributes. </span><span class="kobospan" id="kobo.513.2">For example, we can group sales data by product category to analyze sales trends, or group customer data by demographics to understand </span><span><span class="kobospan" id="kobo.514.1">buying behavior.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.515.1">Furthermore, the </span><strong class="source-inline"><span class="kobospan" id="kobo.516.1">group_by</span></strong><span class="kobospan" id="kobo.517.1"> function can be combined with other data manipulation and visualization techniques to gain deeper insights. </span><span class="kobospan" id="kobo.517.2">For instance, we can create visualizations such as bar charts or heatmaps to visually represent the aggregated data, making it easier to spot patterns </span><span><span class="kobospan" id="kobo.518.1">and trends.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.519.1">To facilitate grouping and conducting deeper analysis, we’ll utilize the </span><strong class="source-inline"><span class="kobospan" id="kobo.520.1">MARKETING_FINAL</span></strong><span class="kobospan" id="kobo.521.1"> table we </span><span><span class="kobospan" id="kobo.522.1">established earlier:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.523.1">
marketing_final = session.table("MARKETING_FINAL")</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.524.1">Here, we </span><a id="_idIndexMarker177" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.525.1">are loading the data from the </span><strong class="source-inline"><span class="kobospan" id="kobo.526.1">MARKETING_FINAL</span></strong><span class="kobospan" id="kobo.527.1"> table into the DataFrame. </span><span class="kobospan" id="kobo.527.2">We will use this DataFrame to </span><span><span class="kobospan" id="kobo.528.1">perform aggregations:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.529.1">
marketing_final.group_by("EDUCATION").mean("INCOME").show()</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.530.1">This returns the average income by </span><strong class="source-inline"><span class="kobospan" id="kobo.531.1">EDUCATION</span></strong><span class="kobospan" id="kobo.532.1">. </span><span class="kobospan" id="kobo.532.2">People with PhDs have the highest average income, and people with primary education have the lowest </span><span><span class="kobospan" id="kobo.533.1">average income:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer072">
<span class="kobospan" id="kobo.534.1"><img alt="Figure 3.19 – Average income by education" src="image/B19923_03_19.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.535.1">Figure 3.19 – Average income by education</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.536.1">Now, we can create an alias for </span><span><span class="kobospan" id="kobo.537.1">the column:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.538.1">
marketing_final.group_by("EDUCATION").agg(avg("INCOME").alias( \
    "Avg_Income")).show()</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.539.1">The average income is displayed as an alias – </span><span><strong class="source-inline"><span class="kobospan" id="kobo.540.1">AVG_INCOME</span></strong></span><span><span class="kobospan" id="kobo.541.1">:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer073">
<span class="kobospan" id="kobo.542.1"><img alt="Figure 3.20 – The AVG_INCOME alias" src="image/B19923_03_20.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.543.1">Figure 3.20 – The AVG_INCOME alias</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.544.1">We can also achieve similar results by using the </span><strong class="source-inline"><span class="kobospan" id="kobo.545.1">function()</span></strong><span class="kobospan" id="kobo.546.1"> method to pass the respective operation from </span><span><span class="kobospan" id="kobo.547.1">Snowpark functions:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.548.1">
marketing_final.group_by("MARITAL_STATUS").function("sum")( \
    "Z_REVENUE").show()</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.549.1">This prints the </span><span><span class="kobospan" id="kobo.550.1">following output:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer074">
<span class="kobospan" id="kobo.551.1"><img alt="Figure 3.21 – Sum of revenue by marital status" src="image/B19923_03_21.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.552.1">Figure 3.21 – Sum of revenue by marital status</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.553.1">Here, we can </span><a id="_idIndexMarker178" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.554.1">see that married customers generate the highest revenue. </span><span class="kobospan" id="kobo.554.2">We can also use </span><strong class="source-inline"><span class="kobospan" id="kobo.555.1">agg()</span></strong><span class="kobospan" id="kobo.556.1"> to perform this particular aggregation. </span><span class="kobospan" id="kobo.556.2">Let’s calculate the maximum income by </span><span><span class="kobospan" id="kobo.557.1">marital status:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.558.1">
marketing_final.group_by("MARITAL_STATUS").agg(max("INCOME")).show()</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.559.1">This generates the </span><span><span class="kobospan" id="kobo.560.1">following output:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer075">
<span class="kobospan" id="kobo.561.1"><img alt="Figure 3.22 – Income by marital status" src="image/B19923_03_22.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.562.1">Figure 3.22 – Income by marital status</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.563.1">Here, we can see that customers who are together and married as a family have the maximum income to spend, and hence they generate the maximum revenue. </span><span class="kobospan" id="kobo.563.2">Next, we will find the </span><a id="_idIndexMarker179" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.564.1">count of different types of graduates and their </span><span><span class="kobospan" id="kobo.565.1">maximum income:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.566.1">
marketing_final.group_by("EDUCATION").agg((col("*"), "count"), 
    max("INCOME")).show()</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.567.1">The preceding code produces the </span><span><span class="kobospan" id="kobo.568.1">following output:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer076">
<span class="kobospan" id="kobo.569.1"><img alt="Figure 3.23 – Count of category" src="image/B19923_03_23.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.570.1">Figure 3.23 – Count of category</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.571.1">Here, we can see that </span><strong class="source-inline"><span class="kobospan" id="kobo.572.1">PhD</span></strong><span class="kobospan" id="kobo.573.1"> has a maximum income of </span><strong class="source-inline"><span class="kobospan" id="kobo.574.1">162397</span></strong><span class="kobospan" id="kobo.575.1">, and that people with </span><strong class="source-inline"><span class="kobospan" id="kobo.576.1">Basic</span></strong><span class="kobospan" id="kobo.577.1"> income have the lowest maximum income – that </span><span><span class="kobospan" id="kobo.578.1">is, </span></span><span><strong class="source-inline"><span class="kobospan" id="kobo.579.1">34445</span></strong></span><span><span class="kobospan" id="kobo.580.1">.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.581.1">We can also perform complex multi-level aggregations in Snowpark. </span><span class="kobospan" id="kobo.581.2">Let’s find out how people with different educations and marital </span><span><span class="kobospan" id="kobo.582.1">statuses spend:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.583.1">
marketing_final.group_by(["EDUCATION","MARITAL_STATUS"]).agg(
    avg("INCOME").alias("Avg_Income"),
    sum("NUMSTOREPURCHASES").alias("Sum_Purchase")
).show()</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.584.1">Here’s </span><span><span class="kobospan" id="kobo.585.1">the output:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer077">
<span class="kobospan" id="kobo.586.1"><img alt="Figure 3.24 – Multi-level aggregation" src="image/B19923_03_24.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.587.1">Figure 3.24 – Multi-level aggregation</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.588.1">Let’s determine</span><a id="_idIndexMarker180" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.589.1"> the relationship between </span><strong class="source-inline"><span class="kobospan" id="kobo.590.1">EDUCATION</span></strong><span class="kobospan" id="kobo.591.1">, </span><strong class="source-inline"><span class="kobospan" id="kobo.592.1">MARITAL_STATUS</span></strong><span class="kobospan" id="kobo.593.1">, and </span><strong class="source-inline"><span class="kobospan" id="kobo.594.1">SUM_PURCHASE</span></strong><span class="kobospan" id="kobo.595.1">. </span><span class="kobospan" id="kobo.595.2">People who are graduates and married spend the most compared to single people. </span><span class="kobospan" id="kobo.595.3">We can also sort the results by using the </span><span><strong class="source-inline"><span class="kobospan" id="kobo.596.1">sort()</span></strong></span><span><span class="kobospan" id="kobo.597.1"> function:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.598.1">
aggregate_result = marketing_final.group_by(["EDUCATION","MARITAL_STATUS"]).agg(
    avg("INCOME").alias("Avg_Income"),
    sum("NUMSTOREPURCHASES").alias("Sum_Purchase")
)
aggregate_result.sort(
    col("EDUCATION").asc(), col("Sum_Purchase").asc()
).show()</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.599.1">Here’s </span><span><span class="kobospan" id="kobo.600.1">the output:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer078">
<span class="kobospan" id="kobo.601.1"><img alt="Figure 3.25 – Sorted result" src="image/B19923_03_25.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.602.1">Figure 3.25 – Sorted result</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.603.1">Here, we are sorting the results in ascending order by purchase amount after the aggregation is </span><a id="_idIndexMarker181" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.604.1">completed. </span><span class="kobospan" id="kobo.604.2">The following section will cover some standard data analysis that can be performed on </span><span><span class="kobospan" id="kobo.605.1">this data.</span></span></p>
<h2 id="_idParaDest-56" class="calibre7"><a id="_idTextAnchor056" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.606.1">Data analysis</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.607.1">In the previous </span><a id="_idIndexMarker182" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.608.1">sections, we delved into data exploration, transformation, and aggregation, where we learned about various techniques we can use to find out what our data is all about and how we can combine different datasets. </span><span class="kobospan" id="kobo.608.2">Armed with a solid foundation of general dataset exploration, we are ready to dive deeper into data analysis using </span><span><span class="kobospan" id="kobo.609.1">Snowpark Python.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.610.1">This section focuses on leveraging the power of statistical functions, sampling techniques, pivoting operations, and converting data into a pandas DataFrame for advanced analysis. </span><span class="kobospan" id="kobo.610.2">We will explore applying statistical functions to extract meaningful information from our data. </span><span class="kobospan" id="kobo.610.3">Then, we will learn about different sampling techniques to work efficiently with large datasets. </span><span class="kobospan" id="kobo.610.4">Additionally, we will discover how to reshape our data using pivoting operations to facilitate </span><span><span class="kobospan" id="kobo.611.1">in-depth analysis.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.612.1">Moreover, we will explore the seamless integration of Snowpark Python with pandas, a widely used data manipulation library. </span><span class="kobospan" id="kobo.612.2">We will understand how to convert our Snowpark data into a pandas DataFrame, enabling us to leverage pandas’ extensive analytical and </span><span><span class="kobospan" id="kobo.613.1">visualization capabilities.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.614.1">The following section provides a glimpse into the capabilities of Snowpark Python for data analysis; we will delve deeper into each topic in the subsequent chapter. </span><span class="kobospan" id="kobo.614.2">Here, we aim to provide a foundational understanding of the key concepts and techniques of analyzing data using Snowpark Python. </span><span class="kobospan" id="kobo.614.3">In the next chapter, we will explore these topics in greater detail, unraveling the full potential of Snowpark Python for </span><span><span class="kobospan" id="kobo.615.1">data analysis.</span></span></p>
<h3 class="calibre9"><span class="kobospan" id="kobo.616.1">Describing the data</span></h3>
<p class="calibre3"><span class="kobospan" id="kobo.617.1">The first step in our</span><a id="_idIndexMarker183" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.618.1"> analysis is understanding how our data is distributed. </span><span class="kobospan" id="kobo.618.2">The </span><strong class="source-inline"><span class="kobospan" id="kobo.619.1">describe()</span></strong><span class="kobospan" id="kobo.620.1"> function in pandas is a valuable tool that helps us gain insights into the statistical properties of our numerical data. </span><span class="kobospan" id="kobo.620.2">When we apply </span><strong class="source-inline"><span class="kobospan" id="kobo.621.1">describe()</span></strong><span class="kobospan" id="kobo.622.1"> to a DataFrame, it computes various descriptive statistics, including the count, mean, standard deviation, minimum, quartiles, and maximum values for each </span><span><span class="kobospan" id="kobo.623.1">numerical column.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.624.1">This summary</span><a id="_idIndexMarker184" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.625.1"> comprehensively overviews our data’s distribution and central tendencies. </span><span class="kobospan" id="kobo.625.2">By examining these statistics, we can quickly identify key characteristics, such as the range of values, the spread of the data, and any potential outliers. </span><span class="kobospan" id="kobo.625.3">This initial exploration sets the stage for more advanced analysis techniques and allows us to make informed decisions based on a solid understanding of our </span><span><span class="kobospan" id="kobo.626.1">dataset’s distribution:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.627.1">
marketing_final.describe().show()</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.628.1">The preceding code shows the data from the </span><span><strong class="source-inline"><span class="kobospan" id="kobo.629.1">MARKETING_FINAL</span></strong></span><span><span class="kobospan" id="kobo.630.1"> table:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer079">
<span class="kobospan" id="kobo.631.1"><img alt="Figure 3.26 – MARKETING_FINAL DataFrame" src="image/B19923_03_26.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.632.1">Figure 3.26 – MARKETING_FINAL DataFrame</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.633.1">The result shows the different columns and the data in the </span><span><strong class="source-inline"><span class="kobospan" id="kobo.634.1">MARKETING_FINAL</span></strong></span><span><span class="kobospan" id="kobo.635.1"> table.</span></span></p>
<h3 class="calibre9"><span class="kobospan" id="kobo.636.1">Finding distinct data</span></h3>
<p class="calibre3"><span class="kobospan" id="kobo.637.1">In Snowpark DataFrames, the </span><strong class="source-inline"><span class="kobospan" id="kobo.638.1">distinct()</span></strong><span class="kobospan" id="kobo.639.1"> function is crucial in identifying unique values within a </span><a id="_idIndexMarker185" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.640.1">column or set of columns. </span><span class="kobospan" id="kobo.640.2">When applied to a Snowpark DataFrame, </span><strong class="source-inline"><span class="kobospan" id="kobo.641.1">distinct()</span></strong><span class="kobospan" id="kobo.642.1"> eliminates duplicate records, resulting in a new DataFrame that contains only distinct values. </span><span class="kobospan" id="kobo.642.2">This function is particularly useful for dealing with large datasets or extracting unique records for analysis or </span><span><span class="kobospan" id="kobo.643.1">data processing:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.644.1">
marketing_final.distinct().count()</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.645.1">The preceding code shows the total count of the </span><span><strong class="source-inline"><span class="kobospan" id="kobo.646.1">MARKETING_FINAL</span></strong></span><span><span class="kobospan" id="kobo.647.1"> table:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer080">
<span class="kobospan" id="kobo.648.1"><img alt="Figure 3.27 – MARKETING_FINAL count" src="image/B19923_03_27.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.649.1">Figure 3.27 – MARKETING_FINAL count</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.650.1">In our case, the entire dataset is returned since we do not have any duplicate rows. </span><strong class="source-inline"><span class="kobospan" id="kobo.651.1">distinct()</span></strong><span class="kobospan" id="kobo.652.1"> preserves the original rows of the DataFrame and only filters out repeated values within the </span><span><span class="kobospan" id="kobo.653.1">specified columns.</span></span></p>
<h3 class="calibre9"><span class="kobospan" id="kobo.654.1">Dropping duplicates</span></h3>
<p class="calibre3"><strong class="source-inline"><span class="kobospan" id="kobo.655.1">drop_duplicates()</span></strong><span class="kobospan" id="kobo.656.1"> removes</span><a id="_idIndexMarker186" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.657.1"> duplicate rows from a Snowpark DataFrame. </span><span class="kobospan" id="kobo.657.2">It analyzes the entire row and compares it with other rows in the DataFrame. </span><span class="kobospan" id="kobo.657.3">If a row is found to be an exact duplicate of another row, </span><strong class="source-inline"><span class="kobospan" id="kobo.658.1">drop_duplicates()</span></strong><span class="kobospan" id="kobo.659.1"> will remove it, keeping only the first occurrence. </span><span class="kobospan" id="kobo.659.2">By default, this function considers all columns in the DataFrame for </span><span><span class="kobospan" id="kobo.660.1">duplicate detection:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.661.1">
marketing_final.select(["Education","Marital_Status"]).drop_duplicates().show()</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.662.1">This will display the </span><span><span class="kobospan" id="kobo.663.1">following output:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer081">
<span class="kobospan" id="kobo.664.1"><img alt="Figure 3.28 – Marketing duplicates removed" src="image/B19923_03_28.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.665.1">Figure 3.28 – Marketing duplicates removed</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.666.1">Note that you can specify specific columns using the </span><strong class="source-inline"><span class="kobospan" id="kobo.667.1">subset</span></strong><span class="kobospan" id="kobo.668.1"> parameter to check for duplicates based on those columns alone. </span><strong class="source-inline"><span class="kobospan" id="kobo.669.1">drop_duplicates()</span></strong><span class="kobospan" id="kobo.670.1"> modifies the original DataFrame by removing </span><span><span class="kobospan" id="kobo.671.1">duplicate rows.</span></span></p>
<h3 class="calibre9"><span class="kobospan" id="kobo.672.1">Crosstab analysis</span></h3>
<p class="calibre3"><span class="kobospan" id="kobo.673.1">Once we have identified </span><a id="_idIndexMarker187" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.674.1">the unique combinations of the </span><strong class="source-inline"><span class="kobospan" id="kobo.675.1">EDUCATION</span></strong><span class="kobospan" id="kobo.676.1"> and </span><strong class="source-inline"><span class="kobospan" id="kobo.677.1">MARITAL_STATUS</span></strong><span class="kobospan" id="kobo.678.1"> columns in our dataset, we might still be curious about how frequently each combination occurs. </span><span class="kobospan" id="kobo.678.2">We can utilize the </span><strong class="source-inline"><span class="kobospan" id="kobo.679.1">crosstab</span></strong><span class="kobospan" id="kobo.680.1"> function to determine the occurrence of these unique combinations. </span><span class="kobospan" id="kobo.680.2">By applying the </span><strong class="source-inline"><span class="kobospan" id="kobo.681.1">crosstab</span></strong><span class="kobospan" id="kobo.682.1"> function to our dataset, we can generate a cross-tabulation or contingency table that displays the frequency distribution of the unique combinations of </span><strong class="source-inline"><span class="kobospan" id="kobo.683.1">EDUCATION</span></strong> <span><span class="kobospan" id="kobo.684.1">and </span></span><span><strong class="source-inline"><span class="kobospan" id="kobo.685.1">MARITAL_STATUS</span></strong></span><span><span class="kobospan" id="kobo.686.1">:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.687.1">
marketing_final.stat.crosstab(col1="Education",col2="Marital_Status").show()</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.688.1">The preceding code shows the crosstab data in </span><span><span class="kobospan" id="kobo.689.1">the DataFrame:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer082">
<span class="kobospan" id="kobo.690.1"><img alt="Figure 3.29 – Crosstab data" src="image/B19923_03_29.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.691.1">Figure 3.29 – Crosstab data</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.692.1">This table provides a comprehensive overview of how often each unique combination occurs in the dataset, allowing us to gain valuable insights into the relationships between these variables. </span><span class="kobospan" id="kobo.692.2">The </span><strong class="source-inline"><span class="kobospan" id="kobo.693.1">crosstab</span></strong><span class="kobospan" id="kobo.694.1"> function aids us in understanding the distribution and occurrence patterns of the unique combinations, further enhancing our data </span><span><span class="kobospan" id="kobo.695.1">analysis capabilities.</span></span></p>
<h4 class="calibre16"><span class="kobospan" id="kobo.696.1">Pivot analysis</span></h4>
<p class="calibre3"><span class="kobospan" id="kobo.697.1">Upon using </span><a id="_idIndexMarker188" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.698.1">the </span><strong class="source-inline"><span class="kobospan" id="kobo.699.1">crosstab</span></strong><span class="kobospan" id="kobo.700.1"> function to examine the unique combinations of the </span><strong class="source-inline"><span class="kobospan" id="kobo.701.1">EDUCATION</span></strong><span class="kobospan" id="kobo.702.1"> and </span><strong class="source-inline"><span class="kobospan" id="kobo.703.1">MARITAL_STATUS</span></strong><span class="kobospan" id="kobo.704.1"> columns in our dataset, we might encounter certain combinations with zero occurrences. </span><span class="kobospan" id="kobo.704.2">We can construct a pivot table to gain a more comprehensive understanding of the data and further investigate the relationships between </span><span><span class="kobospan" id="kobo.705.1">these variables.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.706.1">Constructing a pivot table allows us to summarize and analyze the data more dynamically and flexibly. </span><span class="kobospan" id="kobo.706.2">Unlike the </span><strong class="source-inline"><span class="kobospan" id="kobo.707.1">crosstab</span></strong><span class="kobospan" id="kobo.708.1"> function, which only provides the frequency distribution of unique combinations, a pivot table allows us to explore additional aggregate functions, such as sum, average, or maximum values. </span><span class="kobospan" id="kobo.708.2">This enables us to delve deeper into the dataset and obtain </span><span><span class="kobospan" id="kobo.709.1">meaningful insights:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.710.1">
market_subset = marketing_final.select(
    "EDUCATION","MARITAL_STATUS","INCOME"
)
market_pivot = market_subset.pivot(
    "EDUCATION",
    ["Graduation","PhD","Master","Basic","2n Cycle"]
).sum("INCOME")
market_pivot.show()</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.711.1">The </span><a id="_idIndexMarker189" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.712.1">preceding code shows the data in </span><span><span class="kobospan" id="kobo.713.1">the DataFrame:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer083">
<span class="kobospan" id="kobo.714.1"><img alt="Figure 3.30 – Pivot table" src="image/B19923_03_30.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.715.1">Figure 3.30 – Pivot table</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.716.1">By constructing a pivot table for the </span><strong class="source-inline"><span class="kobospan" id="kobo.717.1">EDUCATION</span></strong><span class="kobospan" id="kobo.718.1"> and </span><strong class="source-inline"><span class="kobospan" id="kobo.719.1">MARITAL_STATUS</span></strong><span class="kobospan" id="kobo.720.1"> columns, we can uncover the occurrence counts and various statistical measures or calculations associated with each combination. </span><span class="kobospan" id="kobo.720.2">This expanded analysis provides a more comprehensive view of the data and allows for a more nuanced and </span><span><span class="kobospan" id="kobo.721.1">detailed exploration.</span></span></p>
<p class="callout-heading"><span class="kobospan" id="kobo.722.1">Note</span></p>
<p class="callout"><span class="kobospan" id="kobo.723.1">When the </span><strong class="source-inline1"><span class="kobospan" id="kobo.724.1">crosstab</span></strong><span class="kobospan" id="kobo.725.1"> function displays zero occurrences for certain combinations of variables, it is essential to note that those combinations will be represented as </span><strong class="source-inline1"><span class="kobospan" id="kobo.726.1">NULL</span></strong><span class="kobospan" id="kobo.727.1"> values instead of zeros when constructing a </span><span><span class="kobospan" id="kobo.728.1">pivot table.</span></span></p>
<p class="callout"><span class="kobospan" id="kobo.729.1">Unlike </span><strong class="source-inline1"><span class="kobospan" id="kobo.730.1">crosstab</span></strong><span class="kobospan" id="kobo.731.1">, which explicitly highlights zero counts for combinations absent in the dataset, a pivot table considers all possible combinations of the variables. </span><span class="kobospan" id="kobo.731.2">Consequently, if a variety does not exist in the dataset, the corresponding cell in the pivot table will be represented as a </span><strong class="source-inline1"><span class="kobospan" id="kobo.732.1">NULL</span></strong><span class="kobospan" id="kobo.733.1"> value rather than </span><span><span class="kobospan" id="kobo.734.1">a zero.</span></span></p>
<p class="callout"><span class="kobospan" id="kobo.735.1">The presence of </span><strong class="source-inline1"><span class="kobospan" id="kobo.736.1">NULL</span></strong><span class="kobospan" id="kobo.737.1"> values in the pivot table highlights the absence of data for those particular combinations. </span><span class="kobospan" id="kobo.737.2">Interpreting and handling these </span><strong class="source-inline1"><span class="kobospan" id="kobo.738.1">NULL</span></strong><span class="kobospan" id="kobo.739.1"> values appropriately during subsequent data analysis processes, such as data cleaning, imputation, or further statistical calculations, </span><span><span class="kobospan" id="kobo.740.1">is essential.</span></span></p>
<h4 class="calibre16"><span class="kobospan" id="kobo.741.1">Dropping missing values</span></h4>
<p class="calibre3"><span class="kobospan" id="kobo.742.1">The </span><strong class="source-inline"><span class="kobospan" id="kobo.743.1">dropna()</span></strong><span class="kobospan" id="kobo.744.1"> function </span><a id="_idIndexMarker190" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.745.1">in pandas is a powerful tool for handling missing values in a DataFrame. </span><span class="kobospan" id="kobo.745.2">In this case, we will be utilizing the </span><strong class="source-inline"><span class="kobospan" id="kobo.746.1">dropna()</span></strong><span class="kobospan" id="kobo.747.1"> functionality of Snowpark, which allows us to remove rows or columns that contain missing or </span><strong class="source-inline"><span class="kobospan" id="kobo.748.1">NULL</span></strong><span class="kobospan" id="kobo.749.1"> values, helping to ensure the integrity and accuracy of our data. </span><span class="kobospan" id="kobo.749.2">The </span><strong class="source-inline"><span class="kobospan" id="kobo.750.1">dropna()</span></strong><span class="kobospan" id="kobo.751.1"> function offers several parameters that provide flexibility in controlling the </span><span><span class="kobospan" id="kobo.752.1">operation’s behavior:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.753.1">
market_pivot.dropna(how="all").show()</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.754.1">The preceding code shows the data with the applied filter from </span><span><span class="kobospan" id="kobo.755.1">the DataFrame:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer084">
<span class="kobospan" id="kobo.756.1"><img alt="Figure 3.31 – Pivot table – dropna()" src="image/B19923_03_31.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.757.1">Figure 3.31 – Pivot table – dropna()</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.758.1">The </span><strong class="source-inline"><span class="kobospan" id="kobo.759.1">how</span></strong><span class="kobospan" id="kobo.760.1"> parameter determines the criteria that are used to drop rows or columns. </span><span class="kobospan" id="kobo.760.2">It accepts the input as </span><strong class="source-inline"><span class="kobospan" id="kobo.761.1">any</span></strong><span class="kobospan" id="kobo.762.1"> and </span><strong class="source-inline"><span class="kobospan" id="kobo.763.1">all</span></strong><span class="kobospan" id="kobo.764.1">: </span><strong class="source-inline"><span class="kobospan" id="kobo.765.1">any</span></strong><span class="kobospan" id="kobo.766.1"> drops the row or column if it contains any missing value, and </span><strong class="source-inline"><span class="kobospan" id="kobo.767.1">all</span></strong><span class="kobospan" id="kobo.768.1"> drops the row or column only if all its values </span><span><span class="kobospan" id="kobo.769.1">are missing.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.770.1">The </span><strong class="source-inline"><span class="kobospan" id="kobo.771.1">thresh</span></strong><span class="kobospan" id="kobo.772.1"> parameter specifies the minimum number of non-null values required to keep a row or column. </span><span class="kobospan" id="kobo.772.2">The row or column is dropped if the </span><em class="italic"><span class="kobospan" id="kobo.773.1">non-null values exceed</span></em> <span><span class="kobospan" id="kobo.774.1">the threshold:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.775.1">
market_pivot.dropna(thresh=5).show()</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.776.1">The </span><a id="_idIndexMarker191" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.777.1">preceding code shows the data with the applied filter from </span><span><span class="kobospan" id="kobo.778.1">the DataFrame:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer085">
<span class="kobospan" id="kobo.779.1"><img alt="Figure 3.32 – Pivot threshold" src="image/B19923_03_32.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.780.1">Figure 3.32 – Pivot threshold</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.781.1">The </span><strong class="source-inline"><span class="kobospan" id="kobo.782.1">subset</span></strong><span class="kobospan" id="kobo.783.1"> parameter allows us to specify a subset of columns or rows for missing value removal. </span><span class="kobospan" id="kobo.783.2">It accepts a list of column or row labels. </span><span class="kobospan" id="kobo.783.3">By default, </span><strong class="source-inline"><span class="kobospan" id="kobo.784.1">dropna()</span></strong><span class="kobospan" id="kobo.785.1"> checks all columns or rows for missing values. </span><span class="kobospan" id="kobo.785.2">However, with a subset, we can focus on specific columns or rows for </span><span><span class="kobospan" id="kobo.786.1">the operation:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.787.1">
market_pivot.dropna(subset="'Graduation'").show()</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.788.1">The preceding code drops any rows from the </span><strong class="source-inline"><span class="kobospan" id="kobo.789.1">market_pivot</span></strong><span class="kobospan" id="kobo.790.1"> DataFrame where the </span><strong class="source-inline"><span class="kobospan" id="kobo.791.1">Graduation</span></strong><span class="kobospan" id="kobo.792.1"> column has missing values and then displays the </span><span><span class="kobospan" id="kobo.793.1">resulting DataFrame:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer086">
<span class="kobospan" id="kobo.794.1"><img alt="Figure 3.33 – Pivot subset" src="image/B19923_03_33.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.795.1">Figure 3.33 – Pivot subset</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.796.1">This shows the data with the applied filter from </span><span><span class="kobospan" id="kobo.797.1">the DataFrame.</span></span></p>
<p class="callout-heading"><span class="kobospan" id="kobo.798.1">Note</span></p>
<p class="callout"><span class="kobospan" id="kobo.799.1">When working with pivot tables, it is crucial to handle </span><strong class="source-inline1"><span class="kobospan" id="kobo.800.1">NULL</span></strong><span class="kobospan" id="kobo.801.1"> values appropriately because they can impact the accuracy and reliability of subsequent analyses. </span><span class="kobospan" id="kobo.801.2">This allows us to ensure that we have complete data for further analysis </span><span><span class="kobospan" id="kobo.802.1">and calculations.</span></span></p>
<p class="callout"><span class="kobospan" id="kobo.803.1">Having </span><strong class="source-inline1"><span class="kobospan" id="kobo.804.1">NULL</span></strong><span class="kobospan" id="kobo.805.1"> values in the pivot result can lead to incorrect interpretations or calculations since </span><strong class="source-inline1"><span class="kobospan" id="kobo.806.1">NULL</span></strong><span class="kobospan" id="kobo.807.1"> values can propagate through the analysis and affect subsequent aggregations, statistics, or visualizations. </span><span class="kobospan" id="kobo.807.2">By replacing </span><strong class="source-inline1"><span class="kobospan" id="kobo.808.1">NULL</span></strong><span class="kobospan" id="kobo.809.1"> values with a specific value, such as 0, we can provide a meaningful representation of the data in the pivot table, allowing us to perform reliable analysis and make informed decisions based on </span><span><span class="kobospan" id="kobo.810.1">complete information.</span></span></p>
<h3 class="calibre9"><span class="kobospan" id="kobo.811.1">Filling missing values</span></h3>
<p class="calibre3"><span class="kobospan" id="kobo.812.1">The </span><strong class="source-inline"><span class="kobospan" id="kobo.813.1">fillna()</span></strong><span class="kobospan" id="kobo.814.1"> function </span><a id="_idIndexMarker192" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.815.1">allows us to replace null values with specific values or apply various techniques for imputation. </span><span class="kobospan" id="kobo.815.2">It also allows us to fill in the missing values in a DataFrame, ensuring that we maintain the integrity of the data structure. </span><span class="kobospan" id="kobo.815.3">We can specify the values for filling nulls, such as a constant value, or values derived from statistical calculations such as mean, median, or mode. </span><span class="kobospan" id="kobo.815.4">The </span><strong class="source-inline"><span class="kobospan" id="kobo.816.1">fillna()</span></strong><span class="kobospan" id="kobo.817.1"> function is useful when we’re treating null values while considering the data’s nature and the </span><span><span class="kobospan" id="kobo.818.1">desired analysis:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.819.1">
market_pivot.fillna(0).show()</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.820.1">The preceding code fills any null values in the </span><strong class="source-inline"><span class="kobospan" id="kobo.821.1">market_pivot</span></strong><span class="kobospan" id="kobo.822.1"> DataFrame with a value of </span><strong class="source-inline"><span class="kobospan" id="kobo.823.1">0</span></strong><span class="kobospan" id="kobo.824.1"> and then displays the </span><span><span class="kobospan" id="kobo.825.1">resulting DataFrame:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer087">
<span class="kobospan" id="kobo.826.1"><img alt="Figure 3.34 – Missing values" src="image/B19923_03_34.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.827.1">Figure 3.34 – Missing values</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.828.1">This is a handy function that fills in missing values that need to be used </span><span><span class="kobospan" id="kobo.829.1">for calculations.</span></span></p>
<h3 class="calibre9"><span class="kobospan" id="kobo.830.1">Variable interaction</span></h3>
<p class="calibre3"><span class="kobospan" id="kobo.831.1">The </span><strong class="source-inline"><span class="kobospan" id="kobo.832.1">corr()</span></strong><span class="kobospan" id="kobo.833.1"> function</span><a id="_idIndexMarker193" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.834.1"> calculates the correlation coefficient, which measures the strength and direction of the linear relationship between two variables. </span><span class="kobospan" id="kobo.834.2">It returns a value between -1 and 1, where -1 represents a perfect negative correlation, 1 illustrates a perfect positive correlation, and 0 indicates no </span><span><span class="kobospan" id="kobo.835.1">linear correlation:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.836.1">
marketing_final.stat.corr("INCOME", "NUMSTOREPURCHASES")</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.837.1">By executing this code, we obtain the correlation coefficient between the </span><strong class="source-inline"><span class="kobospan" id="kobo.838.1">INCOME</span></strong><span class="kobospan" id="kobo.839.1"> and </span><strong class="source-inline"><span class="kobospan" id="kobo.840.1">NUMSTOREPURCHASES</span></strong><span class="kobospan" id="kobo.841.1"> columns, providing insights into the potential relationship between income levels and the number of store purchases in </span><span><span class="kobospan" id="kobo.842.1">the dataset:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer088">
<span class="kobospan" id="kobo.843.1"><img alt="Figure 3.35 – Correlation value" src="image/B19923_03_35.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.844.1">Figure 3.35 – Correlation value</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.845.1">The </span><strong class="source-inline"><span class="kobospan" id="kobo.846.1">cov()</span></strong><span class="kobospan" id="kobo.847.1"> function, on the other hand, calculates the covariance, which measures the degree of association between two variables without normalizing </span><span><span class="kobospan" id="kobo.848.1">for scale:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.849.1">
marketing_final.stat.cov("INCOME", "NUMSTOREPURCHASES")</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.850.1">Here’s </span><span><span class="kobospan" id="kobo.851.1">the output:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer089">
<span class="kobospan" id="kobo.852.1"><img alt="Figure 3.36 – Covariance value" src="image/B19923_03_36.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.853.1">Figure 3.36 – Covariance value</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.854.1">The covariance between the </span><strong class="source-inline"><span class="kobospan" id="kobo.855.1">INCOME</span></strong><span class="kobospan" id="kobo.856.1"> and </span><strong class="source-inline"><span class="kobospan" id="kobo.857.1">NUMSTOREPURCHASES</span></strong><span class="kobospan" id="kobo.858.1"> columns helps us understand how changes in income levels correspond to changes in the number of store purchases in </span><span><span class="kobospan" id="kobo.859.1">the dataset.</span></span></p>
<p class="callout-heading"><span class="kobospan" id="kobo.860.1">Note</span></p>
<p class="callout"><span class="kobospan" id="kobo.861.1">While both </span><strong class="source-inline1"><span class="kobospan" id="kobo.862.1">corr()</span></strong><span class="kobospan" id="kobo.863.1"> and </span><strong class="source-inline1"><span class="kobospan" id="kobo.864.1">cov()</span></strong><span class="kobospan" id="kobo.865.1"> help analyze relationships between variables, it is essential to note that in Snowpark Python, these functions only support the analysis of two variables at a time. </span><span class="kobospan" id="kobo.865.2">This limitation means we can only calculate the correlation or covariance between two columns in a DataFrame, and not simultaneously across multiple variables. </span><span class="kobospan" id="kobo.865.3">Additional techniques or functions may be required to overcome this limitation and perform correlation or covariance analysis for </span><span><span class="kobospan" id="kobo.866.1">various variables.</span></span></p>
<h3 class="calibre9"><span class="kobospan" id="kobo.867.1">Operating with pandas DataFrame</span></h3>
<p class="calibre3"><span class="kobospan" id="kobo.868.1">Converting a </span><a id="_idIndexMarker194" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.869.1">Snowpark DataFrame into a pandas DataFrame is a valuable step that opens up a wide range of analysis capabilities. </span><span class="kobospan" id="kobo.869.2">Snowpark </span><a id="_idIndexMarker195" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.870.1">provides seamless integration with pandas, allowing us to leverage pandas’ extensive data manipulation, analysis, and visualization functionalities. </span><span class="kobospan" id="kobo.870.2">By converting a Snowpark DataFrame into a pandas DataFrame, we gain access to a vast ecosystem of tools and libraries that are designed explicitly for </span><span><span class="kobospan" id="kobo.871.1">data analysis.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.872.1">This transition enables us to leverage pandas’ rich functions and methods, such as statistical calculations, advanced filtering, grouping operations, and time series analysis. </span><span class="kobospan" id="kobo.872.2">pandas also provide many visualization options, such as generating insightful plots, charts, and graphs that are more accessible, to visualize the data. </span><span class="kobospan" id="kobo.872.3">With pandas, we can create meaningful visual representations of our data, facilitating the exploration of patterns, trends, and relationships. </span><span class="kobospan" id="kobo.872.4">Additionally, working with pandas allows us to utilize its extensive community support and resources. </span><span class="kobospan" id="kobo.872.5">The pandas library has a vast user community, making finding documentation, tutorials, and helpful discussions on specific data analysis tasks </span><span><span class="kobospan" id="kobo.873.1">more accessible.</span></span></p>
<h3 class="calibre9"><span class="kobospan" id="kobo.874.1">Limitations of pandas DataFrames</span></h3>
<p class="calibre3"><span class="kobospan" id="kobo.875.1">Converting a </span><a id="_idIndexMarker196" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.876.1">Snowpark DataFrame into a pandas DataFrame can have its limitations, mainly when dealing with large datasets. </span><span class="kobospan" id="kobo.876.2">The primary constraint is memory consumption as converting the entire dataset simultaneously may exceed available memory resources. </span><span class="kobospan" id="kobo.876.3">This can hinder the analysis process and potentially lead to system crashes or </span><span><span class="kobospan" id="kobo.877.1">performance issues.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.878.1">However, these limitations can be mitigated by breaking the DataFrame into batches and sampling the data. </span><span class="kobospan" id="kobo.878.2">We’ll discuss </span><span><span class="kobospan" id="kobo.879.1">this shortly.</span></span></p>
<h3 class="calibre9"><span class="kobospan" id="kobo.880.1">Data analysis using pandas</span></h3>
<p class="calibre3"><span class="kobospan" id="kobo.881.1">Converting a</span><a id="_idIndexMarker197" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.882.1"> Snowpark DataFrame into a pandas DataFrame </span><a id="_idIndexMarker198" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.883.1">empowers us to seamlessly transition from Snowpark’s powerful data processing capabilities to pandas’ feature-rich environment. </span><span class="kobospan" id="kobo.883.2">This interoperability expands our analytical possibilities and enables us to perform advanced analysis and gain deeper insights from </span><span><span class="kobospan" id="kobo.884.1">our data:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.885.1">
pandas_df = marketing_final.to_pandas()
pandas_df.head()</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.886.1">The preceding code converts the </span><strong class="source-inline"><span class="kobospan" id="kobo.887.1">marketing_final</span></strong><span class="kobospan" id="kobo.888.1"> Snowpark DataFrame into a pandas </span><a id="_idIndexMarker199" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.889.1">DataFrame, allowing us to work with the data using pandas’ extensive data analysis and manipulation functionalities. </span><span class="kobospan" id="kobo.889.2">It will print out the </span><span><span class="kobospan" id="kobo.890.1">following output:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer090">
<span class="kobospan" id="kobo.891.1"><img alt="Figure 3.37 – The resulting pandas DataFrame" src="image/B19923_03_37.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.892.1">Figure 3.37 – The resulting pandas DataFrame</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.893.1">This shows </span><a id="_idIndexMarker200" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.894.1">the data that has been converted into the </span><span><span class="kobospan" id="kobo.895.1">pandas DataFrame.</span></span></p>
<h4 class="calibre16"><span class="kobospan" id="kobo.896.1">Correlation in pandas</span></h4>
<p class="calibre3"><span class="kobospan" id="kobo.897.1">In pandas, calculating</span><a id="_idIndexMarker201" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.898.1"> correlations among multiple columns is straightforward: it involves selecting the desired columns and applying the </span><strong class="source-inline"><span class="kobospan" id="kobo.899.1">corr()</span></strong><span class="kobospan" id="kobo.900.1"> function. </span><span class="kobospan" id="kobo.900.2">It generates a correlation matrix, allowing us to examine the relationships between each pair of </span><span><span class="kobospan" id="kobo.901.1">columns simultaneously:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.902.1">
pandas_df[["INCOME","KIDHOME","RECENCY"]].corr()</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.903.1">The preceding code calculates the correlation matrix among the </span><strong class="source-inline"><span class="kobospan" id="kobo.904.1">INCOME</span></strong><span class="kobospan" id="kobo.905.1">, </span><strong class="source-inline"><span class="kobospan" id="kobo.906.1">KIDHOME</span></strong><span class="kobospan" id="kobo.907.1">, and </span><strong class="source-inline"><span class="kobospan" id="kobo.908.1">RECENCY</span></strong><span class="kobospan" id="kobo.909.1"> columns in the </span><strong class="source-inline"><span class="kobospan" id="kobo.910.1">pandas_df</span></strong><span class="kobospan" id="kobo.911.1"> pandas DataFrame. </span><span class="kobospan" id="kobo.911.2">It computes the pairwise correlation coefficients between these columns, providing insights into their relationships. </span><span class="kobospan" id="kobo.911.3">The output is </span><span><span class="kobospan" id="kobo.912.1">as follows:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer091">
<span class="kobospan" id="kobo.913.1"><img alt="Figure 3.38 – Pandas correlation" src="image/B19923_03_38.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.914.1">Figure 3.38 – Pandas correlation</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.915.1">Next, we’ll look at </span><span><span class="kobospan" id="kobo.916.1">frequency distribution.</span></span></p>
<h4 class="calibre16"><span class="kobospan" id="kobo.917.1">Frequency distribution</span></h4>
<p class="calibre3"><span class="kobospan" id="kobo.918.1">Calculating the </span><a id="_idIndexMarker202" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.919.1">frequency of values in a single column is simpler in pandas than in Snowpark Python. </span><span class="kobospan" id="kobo.919.2">We can quickly obtain the frequency distribution in pandas by using the </span><strong class="source-inline"><span class="kobospan" id="kobo.920.1">value_counts()</span></strong><span class="kobospan" id="kobo.921.1"> function on a specific column. </span><span class="kobospan" id="kobo.921.2">It returns a Series with unique values as indices and their corresponding counts as values. </span><span class="kobospan" id="kobo.921.3">This concise method allows us to quickly understand the distribution and prevalence of each unique value in the column. </span><span class="kobospan" id="kobo.921.4">On the other hand, in Snowpark Python, obtaining the frequency of values in a single column requires more steps and additional coding. </span><span class="kobospan" id="kobo.921.5">We typically need to group the DataFrame by the desired column and then perform aggregation operations to count the occurrences of each unique value. </span><span class="kobospan" id="kobo.921.6">Although this can be achieved in Snowpark Python, it involves more complex syntax and multiple transformations, making the process more cumbersome compared </span><span><span class="kobospan" id="kobo.922.1">to pandas:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.923.1">
frequency = pandas_df.EDUCATION.value_counts()
frequency</span></pre> <p class="calibre3"><strong class="source-inline"><span class="kobospan" id="kobo.924.1">frequency = pandas_df.EDUCATION.value_counts()</span></strong><span class="kobospan" id="kobo.925.1"> calculates the frequency distribution of unique values in the </span><strong class="source-inline"><span class="kobospan" id="kobo.926.1">EDUCATION</span></strong><span class="kobospan" id="kobo.927.1"> column of the </span><strong class="source-inline"><span class="kobospan" id="kobo.928.1">pandas_df</span></strong><span class="kobospan" id="kobo.929.1"> pandas DataFrame and assigns the result to the </span><strong class="source-inline"><span class="kobospan" id="kobo.930.1">frequency</span></strong><span class="kobospan" id="kobo.931.1"> variable. </span><span class="kobospan" id="kobo.931.2">The output is </span><span><span class="kobospan" id="kobo.932.1">as follows:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer092">
<span class="kobospan" id="kobo.933.1"><img alt="Figure 3.39 – Pandas data frequency" src="image/B19923_03_39.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.934.1">Figure 3.39 – Pandas data frequency</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.935.1">This shows the data frequency values in the </span><span><span class="kobospan" id="kobo.936.1">pandas DataFrame.</span></span></p>
<h4 class="calibre16"><span class="kobospan" id="kobo.937.1">Visualization in pandas</span></h4>
<p class="calibre3"><span class="kobospan" id="kobo.938.1">Creating visualizations</span><a id="_idIndexMarker203" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.939.1"> is made easy with pandas due to its seamless integration with popular visualization libraries such as Matplotlib and Seaborn. </span><span class="kobospan" id="kobo.939.2">pandas provides a simple and intuitive interface to generate various visualizations, including line plots, bar charts, histograms, scatter plots, </span><span><span class="kobospan" id="kobo.940.1">and more.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.941.1">By </span><a id="_idIndexMarker204" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.942.1">leveraging pandas’ built-in plotting functions, we can effortlessly transform our data into insightful visual representations, enabling us to explore patterns, trends, and relationships within our dataset. </span><span class="kobospan" id="kobo.942.2">With just a few lines of code, pandas </span><em class="italic"><span class="kobospan" id="kobo.943.1">empowers</span></em><span class="kobospan" id="kobo.944.1"> us to produce visually appealing and informative plots, facilitating the communication and interpretation of </span><span><span class="kobospan" id="kobo.945.1">our data:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.946.1">
frequency.plot(kind="barh",figsize=(8,3))</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.947.1">The preceding code creates a horizontal bar plot from the frequency distribution data stored in the </span><strong class="source-inline"><span class="kobospan" id="kobo.948.1">frequency</span></strong><span class="kobospan" id="kobo.949.1"> variable, where each unique value is represented by a bar with a length proportional to its count, and the plot has a customized size of 8 inches in width and 3 inches </span><span><span class="kobospan" id="kobo.950.1">in height:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer093">
<span class="kobospan" id="kobo.951.1"><img alt="Figure 3.40 – Frequency plot" src="image/B19923_03_40.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.952.1">Figure 3.40 – Frequency plot</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.953.1">Similarly, we can generate a Hexbin plot by changing </span><strong class="source-inline"><span class="kobospan" id="kobo.954.1">kind</span></strong> <span><span class="kobospan" id="kobo.955.1">to </span></span><span><strong class="source-inline"><span class="kobospan" id="kobo.956.1">hexbin</span></strong></span><span><span class="kobospan" id="kobo.957.1">:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.958.1">
pandas_df.plot(
    kind="hexbin",
    x="INCOME",y="MNTGOLDPRODS",
    xlim=[0,100000],ylim=[0,100],
    figsize=(8,3)
)</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.959.1">The preceding code creates a Hexbin plot that visualizes the relationship between the </span><strong class="source-inline"><span class="kobospan" id="kobo.960.1">INCOME</span></strong><span class="kobospan" id="kobo.961.1"> and </span><strong class="source-inline"><span class="kobospan" id="kobo.962.1">MNTGOLDPRODS</span></strong><span class="kobospan" id="kobo.963.1"> columns in the </span><strong class="source-inline"><span class="kobospan" id="kobo.964.1">pandas_df</span></strong> <span><span class="kobospan" id="kobo.965.1">pandas DataFrame:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer094">
<span class="kobospan" id="kobo.966.1"><img alt="Figure 3.41 – Hexbin plot" src="image/B19923_03_41.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.967.1">Figure 3.41 – Hexbin plot</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.968.1">Here, the </span><em class="italic"><span class="kobospan" id="kobo.969.1">X</span></em><span class="kobospan" id="kobo.970.1">-axis </span><a id="_idIndexMarker205" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.971.1">represents income values and the </span><em class="italic"><span class="kobospan" id="kobo.972.1">Y</span></em><span class="kobospan" id="kobo.973.1">-axis represents the number of gold products. </span><span class="kobospan" id="kobo.973.2">The plot is limited to X-axis limits of 0 to 100,000 and Y-axis limits of 0 to 100, with a customized size of 8 inches in width and 3 inches </span><span><span class="kobospan" id="kobo.974.1">in height.</span></span></p>
<h4 class="calibre16"><span class="kobospan" id="kobo.975.1">Breaking a DataFrame into batches</span></h4>
<p class="calibre3"><span class="kobospan" id="kobo.976.1">The </span><strong class="source-inline"><span class="kobospan" id="kobo.977.1">to_pandas_batches()</span></strong><span class="kobospan" id="kobo.978.1"> function converts a Snowpark DataFrame into multiple smaller pandas </span><a id="_idIndexMarker206" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.979.1">DataFrames to be processed in batches. </span><span class="kobospan" id="kobo.979.2">This approach reduces memory usage by converting the data into manageable portions, enabling efficient analysis of </span><span><span class="kobospan" id="kobo.980.1">large datasets:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.981.1">
for batch in marketing_final.to_pandas_batches(): print(batch.shape)</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.982.1">Here’s </span><span><span class="kobospan" id="kobo.983.1">the output:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer095">
<span class="kobospan" id="kobo.984.1"><img alt="Figure 3.42 – DataFrame batches" src="image/B19923_03_42.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.985.1">Figure 3.42 – DataFrame batches</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.986.1">The preceding code demonstrates how to analyze a large dataset in batches using the </span><strong class="source-inline"><span class="kobospan" id="kobo.987.1">to_pandas_batches()</span></strong><span class="kobospan" id="kobo.988.1"> function in Snowpark Python. </span><span class="kobospan" id="kobo.988.2">By iterating over the </span><strong class="source-inline"><span class="kobospan" id="kobo.989.1">to_pandas_batches()</span></strong><span class="kobospan" id="kobo.990.1"> function, the code processes the dataset in manageable batches rather than loading the entire dataset into memory at once. </span><span class="kobospan" id="kobo.990.2">In each iteration, a batch of the dataset is converted into a pandas DataFrame and stored in the </span><strong class="source-inline"><span class="kobospan" id="kobo.991.1">batch</span></strong><span class="kobospan" id="kobo.992.1"> variable. </span><span class="kobospan" id="kobo.992.2">The </span><strong class="source-inline"><span class="kobospan" id="kobo.993.1">print(batch.shape)</span></strong><span class="kobospan" id="kobo.994.1"> statement provides the shape of each batch, indicating</span><a id="_idIndexMarker207" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.995.1"> the number of rows and columns in that </span><span><span class="kobospan" id="kobo.996.1">specific batch.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.997.1">Analyzing the dataset in batches allows for more efficient memory utilization, enabling us to process large datasets that might otherwise exceed available memory resources. </span><span class="kobospan" id="kobo.997.2">This approach facilitates the analysis of large datasets by breaking them into smaller, more manageable portions, allowing for faster computations and reducing the risk of </span><span><span class="kobospan" id="kobo.998.1">memory-related issues.</span></span></p>
<h4 class="calibre16"><span class="kobospan" id="kobo.999.1">Sampling a DataFrame</span></h4>
<p class="calibre3"><span class="kobospan" id="kobo.1000.1">The </span><strong class="source-inline"><span class="kobospan" id="kobo.1001.1">sample()</span></strong><span class="kobospan" id="kobo.1002.1"> function </span><a id="_idIndexMarker208" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.1003.1">in Snowpark Python allows us to retrieve a random subset of data from the Snowpark DataFrame. </span><span class="kobospan" id="kobo.1003.2">By specifying the desired fraction or number of rows, we can efficiently extract a representative sample for analysis. </span><span class="kobospan" id="kobo.1003.3">This technique reduces the memory footprint required for conversion and subsequent analysis while providing </span><span><span class="kobospan" id="kobo.1004.1">meaningful insights:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.1005.1">
sample_df = marketing_final.sample(frac=0.50)
sample_df.count()</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.1006.1">Here’s </span><span><span class="kobospan" id="kobo.1007.1">the output:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer096">
<span class="kobospan" id="kobo.1008.1"><img alt="Figure 3.43 – Sampling data" src="image/B19923_03_43.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.1009.1">Figure 3.43 – Sampling data</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.1010.1">The preceding code selects a random sample of 50% of the rows from the </span><strong class="source-inline"><span class="kobospan" id="kobo.1011.1">marketing_final</span></strong><span class="kobospan" id="kobo.1012.1"> DataFrame and assigns it to the </span><strong class="source-inline"><span class="kobospan" id="kobo.1013.1">sample_df</span></strong><span class="kobospan" id="kobo.1014.1"> DataFrame. </span><span class="kobospan" id="kobo.1014.2">The final count step produces slightly different output each time you run the code segment  as it involves sampling the original table. </span><span class="kobospan" id="kobo.1014.3">The subsequent </span><strong class="source-inline"><span class="kobospan" id="kobo.1015.1">sample_df.count()</span></strong><span class="kobospan" id="kobo.1016.1"> function calculates the count of non-null values in each column of the </span><span><strong class="source-inline"><span class="kobospan" id="kobo.1017.1">sample_df</span></strong></span><span><span class="kobospan" id="kobo.1018.1"> DataFrame.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.1019.1">By utilizing the methods we covered here in Snowpark Python, we can overcome the limitations of converting large Snowpark DataFrames into pandas DataFrames, allowing for practical analysis while efficiently managing memory resources. </span><span class="kobospan" id="kobo.1019.2">These functions provide flexibility and control, enabling us to work with sizable datasets in a manageable and </span><span><span class="kobospan" id="kobo.1020.1">optimized </span></span><span><a id="_idIndexMarker209" class="calibre6 pcalibre1 pcalibre"/></span><span><span class="kobospan" id="kobo.1021.1">manner.</span></span></p>
<h1 id="_idParaDest-57" class="calibre5"><a id="_idTextAnchor057" class="calibre6 pcalibre1 pcalibre"/><span class="kobospan" id="kobo.1022.1">Summary</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.1023.1">Snowpark provides different data processing capabilities and supports various techniques. </span><span class="kobospan" id="kobo.1023.2">It provides us with an easy and versatile way to ingest different structured and unstructured file formats, and Snowpark’s DataFrames support various data transformation and analysis operations. </span><span class="kobospan" id="kobo.1023.3">We covered various Snowpark session variables and different data operations that can be performed </span><span><span class="kobospan" id="kobo.1024.1">using Snowpark.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.1025.1">In the next chapter, we will cover how to build data engineering pipelines </span><span><span class="kobospan" id="kobo.1026.1">with Snowpark.</span></span></p>
</div>
</body></html>