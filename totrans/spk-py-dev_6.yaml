- en: Chapter 6. Visualizing Insights and Trends
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第6章：可视化洞察和趋势
- en: So far, we have focused on the collection, analysis, and processing of data
    from Twitter. We have set the stage to use our data for visual rendering and extracting
    insights and trends. We will give a quick lay of the land about visualization
    tools in the Python ecosystem. We will highlight Bokeh as a powerful tool for
    rendering and viewing large datasets. Bokeh is part of the Python Anaconda Distribution
    ecosystem.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们专注于从Twitter收集、分析和处理数据。我们已经为使用我们的数据进行可视化渲染和提取洞察与趋势做好了准备。我们将简要介绍Python生态系统中的可视化工具。我们将强调Bokeh作为渲染和查看大型数据集的强大工具。Bokeh是Python
    Anaconda Distribution生态系统的一部分。
- en: 'In this chapter, we will cover the following points:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下要点：
- en: Gauging the key words and memes within a social network community using charts
    and wordcloud
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用图表和词云衡量社交网络社区中的关键词和流行语
- en: Mapping the most active location where communities are growing around certain
    themes or topics
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将社区围绕特定主题或话题增长最活跃的位置进行映射
- en: Revisiting the data-intensive apps architecture
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 重新审视数据密集型应用架构
- en: 'We have reached the final layer of the data-intensive apps architecture: the
    engagement layer. This layer focuses on how to synthesize, emphasize, and visualize
    the key context relevant information for the data consumers. A bunch of numbers
    in a console will not suffice to engage with end-users. It is critical to present
    the mass of information in a rapid, digestible, and attractive fashion.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经到达了数据密集型应用架构的最后一层：参与层。这一层专注于如何综合、强调和可视化对数据消费者相关的关键背景信息。仅仅在控制台中显示一堆数字是不够与最终用户互动的。以快速、易于消化和吸引人的方式呈现大量信息至关重要。
- en: The following diagram sets the context of the chapter's focus highlighting the
    engagement layer.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表设置了本章重点的上下文，突出了参与层。
- en: '![Revisiting the data-intensive apps architecture](img/B03968_06_01.jpg)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![重新审视数据密集型应用架构](img/B03968_06_01.jpg)'
- en: 'For Python plotting and visualizations, we have quite a few tools and libraries.
    The most interesting and relevant ones for our purpose are the following:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Python的绘图和可视化，我们有很多工具和库。对我们目的来说最有趣和相关的如下：
- en: '**Matplotlib** is the grandfather of the Python plotting libraries. Matplotlib
    was originally the brainchild of *John Hunter* who was an open source software
    proponent and established Matplotlib as one of the most prevalent plotting libraries
    both in the academic and the data scientific communities. Matplotlib allows the
    generation of plots, histograms, power spectra, bar charts, error charts, scatterplots,
    and so on. Examples can be found on the Matplotlib dedicated website at [http://matplotlib.org/examples/index.html](http://matplotlib.org/examples/index.html).'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Matplotlib**是Python绘图库的鼻祖。Matplotlib最初是*John Hunter*的创意，他是一位开源软件倡导者，并将Matplotlib确立为学术和数据科学社区中最普遍的绘图库之一。Matplotlib允许生成图表、直方图、功率谱、条形图、误差图、散点图等。示例可以在Matplotlib的专用网站上找到，网址为[http://matplotlib.org/examples/index.html](http://matplotlib.org/examples/index.html)。'
- en: '**Seaborn**, developed by *Michael Waskom*, is a great library to quickly visualize
    statistical information. It is built on top of Matplotlib and integrates seamlessly
    with Pandas and the Python data stack, including Numpy. A gallery of graphs from
    Seaborn at [http://stanford.edu/~mwaskom/software/seaborn/examples/index.html](http://stanford.edu/~mwaskom/software/seaborn/examples/index.html)
    shows the potential of the library.'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由*Michael Waskom*开发的**Seaborn**是一个快速可视化统计信息的优秀库。它建立在Matplotlib之上，并与Pandas和Python数据堆栈（包括Numpy）无缝集成。Seaborn的图形画廊可以在[http://stanford.edu/~mwaskom/software/seaborn/examples/index.html](http://stanford.edu/~mwaskom/software/seaborn/examples/index.html)上查看，展示了该库的潜力。
- en: '**ggplot** is relatively new and aims to offer the equivalent of the famous
    ggplot2 from the R ecosystem for the Python data wranglers. It has the same look
    and feel of ggplot2 and uses the same grammar of graphics as expounded by Hadley
    Wickham. The ggplot the Python port is developed by the team at `yhat`. More information
    can be found at [http://ggplot.yhathq.com](http://ggplot.yhathq.com).'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ggplot**相对较新，旨在为Python数据整理者提供R生态系统中著名的ggplot2的等效功能。它具有与ggplot2相同的视觉和感觉，并使用Hadley
    Wickham阐述的相同的图形语法。ggplot的Python端口由`yhat`团队开发。更多信息可以在[http://ggplot.yhathq.com](http://ggplot.yhathq.com)找到。'
- en: '**D3.js** is a very popular, JavaScript library developed by *Mike Bostock*.
    **D3** stands for **Data Driven Documents** and brings data to life on any modern
    browser leveraging HTML, SVG, and CSS. It delivers dynamic, powerful, interactive
    visualizations by manipulating the DOM, the Document Object Model. The Python
    community could not wait to integrate D3 with Matplotlib. Under the impulse of
    Jake Vanderplas, mpld3 was created with the aim of bringing `matplotlib` to the
    browser. Examples graphics are hosted at the following address: [http://mpld3.github.io/index.html](http://mpld3.github.io/index.html).'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**D3.js**是一个非常流行的、由*Mike Bostock*开发的JavaScript库。**D3**代表**数据驱动文档**，它利用HTML、SVG和CSS在任何现代浏览器中将数据生动化。它通过操作DOM（文档对象模型）提供动态、强大、交互式的可视化。Python社区迫不及待地想要将D3与Matplotlib集成。在Jake
    Vanderplas的推动下，mpld3被创建出来，旨在将`matplotlib`带到浏览器中。示例图形托管在以下地址：[http://mpld3.github.io/index.html](http://mpld3.github.io/index.html)。'
- en: '**Bokeh** aims to deliver high-performance interactivity over very large or
    streaming datasets whilst leveraging lot of the concepts of `D3.js` without the
    burden of writing some intimidating `javascript` and `css` code. Bokeh delivers
    dynamic visualizations on the browser with or without a server. It integrates
    seamlessly with Matplotlib, Seaborn and ggplot and renders beautifully in IPython
    notebooks or Jupyter notebooks. Bokeh is actively developed by the team at Continuum.io
    and is an integral part of the Anaconda Python data stack.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Bokeh**旨在在非常大的或流式数据集上提供高性能交互性，同时利用`D3.js`的许多概念，而不必承担编写一些令人畏惧的`javascript`和`css`代码的负担。Bokeh在浏览器中提供动态可视化，无论是否有服务器。它与Matplotlib、Seaborn和ggplot无缝集成，并在IPython笔记本或Jupyter笔记本中渲染得非常漂亮。Bokeh由Continuum.io团队积极开发，是Anaconda
    Python数据栈的一个组成部分。'
- en: Bokeh server provides a full-fledged, dynamic plotting engine that materializes
    a reactive scene graph from JSON. It uses web sockets to keep state and update
    the HTML5 canvas using Backbone.js and Coffee-script under the hoods. Bokeh, as
    it is fueled by data in JSON, creates easy bindings for other languages such as
    R, Scala, and Julia.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: Bokeh服务器提供了一个完整的、动态的绘图引擎，它从JSON中生成一个反应性场景图。它使用Web套接字来保持状态并更新HTML5画布，背后使用Backbone.js和Coffee-script。由于Bokeh由JSON中的数据驱动，因此它为其他语言如R、Scala和Julia提供了简单的绑定。
- en: This gives a high-level overview of the main plotting and visualization library.
    It is not exhaustive. Let's move to concrete examples of visualizations.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这提供了主要绘图和可视化库的高级概述。它并不详尽。让我们转到具体可视化示例。
- en: Preprocessing the data for visualization
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预处理数据以进行可视化
- en: 'Before jumping into the visualizations, we will do some preparatory work on
    the data harvested:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在跳入可视化之前，我们将对收集到的数据进行一些准备工作：
- en: '[PRE0]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'For the purpose of our visualization activity, we will use a dataset of 7,540
    tweets. The key information is stored in the `tweet_text` column. We preview the
    data stored in the dataframe calling the `head()` function on the dataframe:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 为了我们的可视化活动，我们将使用包含7,540条推文的数据库。关键信息存储在`tweet_text`列中。我们通过在数据框上调用`head()`函数来预览存储在数据框中的数据：
- en: '[PRE1]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We will now create some utility functions to clean up the tweet text and parse
    the twitter date. First, we import the Python regular expression regex library
    `re` and the time library to parse dates and time:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将创建一些实用函数来清理推文文本并解析Twitter日期。首先，我们导入Python正则表达式库`re`和用于解析日期和时间的`time`库：
- en: '[PRE2]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We create a dictionary of regex that will be compiled and then passed as function:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建一个正则表达式字典，该字典将被编译，然后作为函数传递：
- en: '**RT**: The first regex with key `RT` looks for the keyword `RT` at the beginning
    of the tweet text:'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**RT**：第一个以键`RT`为关键字的正则表达式在推文文本的开头寻找关键字`RT`：'
- en: '[PRE3]'
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '**ALNUM**: The second regex with key `ALNUM` looks for words including alphanumeric
    characters and underscore sign preceded by the `@` symbol in the tweet text:'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ALNUM**：第二个以键`ALNUM`为关键字的正则表达式在推文文本中寻找以`@`符号开头的包含字母数字字符和下划线符号的单词：'
- en: '[PRE4]'
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '**HASHTAG**: The third regex with key `HASHTAG` looks for words including alphanumeric
    characters preceded by the `#` symbol in the tweet text:'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**HASHTAG**：第三个以键`HASHTAG`为关键字的正则表达式在推文文本中寻找以`#`符号开头的包含字母数字字符的单词：'
- en: '[PRE5]'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '**SPACES**: The fourth regex with key `SPACES` looks for blank or line space
    characters in the tweet text:'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**SPACES**：第四个以键`SPACES`为关键字的正则表达式在推文文本中寻找空白或行空间字符：'
- en: '[PRE6]'
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '**URL**: The fifth regex with key `URL` looks for `url` addresses including
    alphanumeric characters preceded with `https://` or `http://` markers in the tweet
    text:'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**URL**：第五个以键`URL`为关键字的正则表达式在推文文本中寻找以`https://`或`http://`标记开头的包含字母数字字符的`url`地址：'
- en: '[PRE7]'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We create a utility function to identify whether a tweet is a retweet or an
    original tweet:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建一个实用函数来识别推文是转发推文还是原始推文：
- en: '[PRE8]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Then, we extract all user handles in a tweet:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们提取推文中的所有用户名：
- en: '[PRE9]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'We also extract all hashtags in a tweet:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还提取推文中的所有标签：
- en: '[PRE10]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Extract all URL links in a tweet as follows:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 按如下方式提取推文中的所有URL链接：
- en: '[PRE11]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We strip all URL links and user handles preceded by `@` sign in a tweet text.
    This function will be the basis of the wordcloud we will build soon:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从推文文本中剥离所有以`@`符号开头的URL链接和用户名。这个函数将成为我们即将构建的词云的基础：
- en: '[PRE12]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'We label the data so we can create groups of datasets for the wordcloud:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们标记数据，以便我们可以为词云创建数据集组：
- en: '[PRE13]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We parse the twitter date in the `yyyy-mm-dd hh:mm:ss` format:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们以`yyyy-mm-dd hh:mm:ss`格式解析推文的日期：
- en: '[PRE14]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We preview the data prior to processing:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理之前预览数据：
- en: '[PRE15]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We create new dataframe columns by applying the utility functions described.
    We create a new column for `htag`, user handles, URLs, the text terms stripped
    from URLs, and unwanted characters and the labels. We finally parse the date:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过应用描述的实用函数创建新的dataframe列，创建一个新列用于`htag`、用户名、URL、从URL中剥离的文本术语、不需要的字符和标签。最后解析日期：
- en: '[PRE16]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The following code gives a quick snapshot of the newly generated dataframe:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码提供了新生成的dataframe的快速快照：
- en: '[PRE17]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'We save the processed information in a CSV format. We have 7,540 records and
    13 columns. In your case, the output will vary according to the dataset you chose:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将处理后的信息保存为CSV格式。我们有7,540条记录和13列。在你的情况下，输出将根据你选择的数据集而变化：
- en: '[PRE18]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Gauging words, moods, and memes at a glance
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一眼就能判断词汇、情绪和梗
- en: 'We are now ready to proceed with building the wordclouds which will give us
    a sense of the important words carried in those tweets. We will create wordclouds
    for the datasets harvested. Wordclouds extract the top words in a list of words
    and create a scatterplot of the words where the size of the word is correlated
    to its frequency. The more frequent the word in the dataset, the bigger will be
    the font size in the wordcloud rendering. They include three very different themes
    and two competing or analogous entities. Our first theme is obviously data processing
    and analytics, with Apache Spark and Python as our entities. Our second theme
    is the 2016 presidential election campaign, with the two contenders: Hilary Clinton
    and Donald Trump. Our last theme is the world of pop music with Justin Bieber
    and Lady Gaga as the two exponents.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已准备好开始构建词云，这将让我们感受到这些推文中携带的重要词汇。我们将为收集到的数据集创建词云。词云提取单词列表中的顶级单词，并创建一个散点图，其中单词的大小与其频率相关。在数据集中单词越频繁，词云渲染中的字体大小就越大。它们包括三个非常不同的主题和两个竞争或类似实体。我们的第一个主题显然是数据处理和分析，Apache
    Spark和Python是我们的实体。我们的第二个主题是2016年总统选举活动，两位竞争者是希拉里·克林顿和唐纳德·特朗普。我们的最后一个主题是流行音乐界，两位代表是贾斯汀·比伯和Lady
    Gaga。
- en: Setting up wordcloud
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置词云
- en: 'We will illustrate the programming steps by analyzing the spark related tweets.
    We load the data and preview the dataframe:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过分析与Spark相关的推文来展示编程步骤。我们加载数据并预览dataframe：
- en: '[PRE19]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Note
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The wordcloud library we will use is the one developed by Andreas Mueller and
    hosted on his GitHub account at [https://github.com/amueller/word_cloud](https://github.com/amueller/word_cloud).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用的词云库是由Andreas Mueller开发的，托管在他的GitHub账户上，网址为[https://github.com/amueller/word_cloud](https://github.com/amueller/word_cloud)。
- en: 'The library requires **PIL** (short for **Python Imaging Library**). PIL is
    easily installable by invoking `conda install pil`. PIL is a complex library to
    install and is not yet ported on Python 3.4, so we need to run a Python 2.7+ environment
    to be able to see our wordcloud:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 该库需要**PIL**（即**Python Imaging Library**）。可以通过调用`conda install pil`轻松安装PIL。PIL是一个复杂的库，安装起来比较麻烦，并且尚未移植到Python
    3.4，因此我们需要运行Python 2.7+环境才能看到我们的词云：
- en: '[PRE20]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The following packages will be downloaded:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 以下包将被下载：
- en: '[PRE21]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The following packages will be UPDATED:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 以下包将被更新：
- en: '[PRE22]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Next, we install the wordcloud library:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们安装词云库：
- en: '[PRE23]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Creating wordclouds
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建词云
- en: At this stage, we are ready to invoke the wordcloud program with the generated
    list of terms from the tweet text.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在此阶段，我们已准备好使用从推文文本生成的术语列表调用词云程序。
- en: 'Let''s get started with the wordcloud program by first calling `%matplotlib`
    inline to display the wordcloud in our notebook:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从调用`%matplotlib` inline开始，以便在我们的笔记本中显示词云：
- en: '[PRE24]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'We convert the dataframe `txt_terms` column into a list of words. We make sure
    it is all converted into the `str` type to avoid any bad surprises and check the
    list''s first four records:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将 dataframe `txt_terms` 列转换为单词列表。我们确保它全部转换为 `str` 类型，以避免任何意外，并检查列表的前四条记录：
- en: '[PRE25]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We first call the Matplotlib and the wordcloud libraries:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先调用 Matplotlib 和 wordcloud 库：
- en: '[PRE26]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'From the input list of terms, we create a unified string of terms separated
    by a whitespace as the input to the wordcloud program. The wordcloud program removes
    stopwords:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 从输入的术语列表中，我们创建一个由空格分隔的统一字符串，作为词云程序的输入。词云程序会移除停用词：
- en: '[PRE27]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Here, we can visualize the wordclouds for Apache Spark and Python. Clearly,
    in the case of Spark, *Hadoop*, *big data*, and *analytics* are the memes, while
    Python recalls the root of its name Monty Python with a strong focus on *developer*,
    *apache spark*, and programming with some hints to java and ruby.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以可视化 Apache Spark 和 Python 的词云。显然，在 Spark 的情况下，*Hadoop*、*big data* 和
    *analytics* 是热门话题，而 Python 则回忆起其名称的根源 Monty Python，重点在于 *developer*、*apache spark*
    和编程，并有一些关于 java 和 ruby 的提示。
- en: '![Creating wordclouds](img/B03968_06_02.jpg)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![创建词云](img/B03968_06_02.jpg)'
- en: 'We can also get a glimpse in the following wordclouds of the words preoccupying
    the North American 2016 presidential election candidates: Hilary Clinton and Donald
    Trump. Seemingly Hilary Clinton is overshadowed by the presence of her opponents
    Donald Trump and Bernie Sanders, while Trump is heavily centered only on himself:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以从以下词云中一瞥占据北美 2016 年总统选举候选人注意力的词汇：希拉里·克林顿和唐纳德·特朗普。显然，希拉里·克林顿被她的对手唐纳德·特朗普和伯尼·桑德斯的存在所掩盖，而特朗普则主要集中在他自己身上：
- en: '![Creating wordclouds](img/B03968_06_03.jpg)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![创建词云](img/B03968_06_03.jpg)'
- en: Interestingly, in the case of Justin Bieber and Lady Gaga, the word *love* appears.
    In the case of Bieber, *follow* and *belieber* are key words, while *diet*, *weight
    loss*, and *fashion* are the preoccupations for the Lady Gaga crowd.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，在贾斯汀·比伯和Lady Gaga 的情况下，出现了单词 *love*。在比伯的情况下，*follow* 和 *belieber* 是关键词，而
    *diet*、*weight loss* 和 *fashion* 是 Lady Gaga 粉丝团的关注点。
- en: '![Creating wordclouds](img/B03968_06_04.jpg)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![创建词云](img/B03968_06_04.jpg)'
- en: Geo-locating tweets and mapping meetups
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定位推文和绘制聚会地图
- en: Now, we will dive into the creation of interactive maps with Bokeh. First, we
    create a world map where we geo-locate sample tweets and, on moving our mouse
    over these locations, we can see the users and their respective tweets in a hover
    box.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将深入探讨使用 Bokeh 创建交互式地图的过程。首先，我们创建一个世界地图，在这个地图上我们定位样本推文，并将鼠标移动到这些位置时，我们可以在悬停框中看到用户及其相应的推文。
- en: The second map is focused on mapping upcoming meetups in London. It could be
    an interactive map that would act as a reminder of date, time, and location for
    upcoming meetups in a specific city.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个地图专注于伦敦即将举行的聚会。这可能是一个交互式地图，它将作为特定城市即将举行的聚会的日期、时间和地点的提醒。
- en: Geo-locating tweets
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定位推文
- en: 'The objective is to create a world map scatter plot of the locations of important
    tweets on the map, and the tweets and authors are revealed on hovering over these
    points. We will go through three steps to build this interactive visualization:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 目标是创建一个世界地图散点图，显示地图上重要推文的位置，并在悬停这些点时显示推文和作者。我们将通过三个步骤来构建这个交互式可视化：
- en: Create the background world map by first loading a dictionary of all the world
    country boundaries defined by their respective longitude and latitudes.
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先加载一个包含所有世界国家边界及其相应经纬度的字典，以创建背景世界地图。
- en: Load the important tweets we wish to geo-locate with their respective coordinates
    and authors.
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载我们希望定位的推文及其相应的坐标和作者。
- en: Finally, scatter plot on the world map the tweets coordinates and activate the
    hover tool to visualize interactively the tweets and author on the highlighted
    dots on the map.
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，在世界地图上散点图推文的坐标，并激活悬停工具，以交互式地可视化地图上突出显示的点上的推文和作者。
- en: 'In step one, we create a Python list called data that will contain all the
    world countries boundaries with their respective latitude and longitude:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一步中，我们创建一个名为 data 的 Python 列表，它将包含所有世界国家边界及其相应的纬度和经度：
- en: '[PRE28]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'In step two, we load a sample set of important tweets that we wish to visualize
    with their respective geo-location information:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二步中，我们加载一组重要的样本推文，我们希望用它们各自的地理定位信息来可视化：
- en: '[PRE29]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: In step three, we first imported all the necessary Bokeh libraries. We will
    instantiate the output in the Jupyter Notebook. We get the world countries boundary
    information loaded. We get the geo-located tweet data. We instantiate the Bokeh
    interactive tools such as wheel and box zoom as well as the hover tool.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在第三步中，我们首先导入了所有必要的Bokeh库。我们将在Jupyter Notebook中实例化输出。我们加载了世界国家边界信息。我们获取了地理定位的推文数据。我们实例化了Bokeh交互式工具，如滚轮和框缩放以及悬停工具。
- en: '[PRE30]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'We are now ready to layer the various elements gathered into an object figure
    called **p**. Define the title, width, and height of **p**. Attach the tools.
    Create the world map background by patches with a light background color and borders.
    Scatter plot the tweets according to their respective geo-coordinates. Then, activate
    the hover tool with the users and their respective tweet. Finally, render the
    picture on the browser. The code is as follows:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在准备好将收集到的各种元素层叠到一个名为**p**的对象中。定义**p**的标题、宽度和高度。附加工具。通过带有浅色背景色和边框的补丁创建世界地图背景。根据各自的地理坐标散点图绘制推文。然后，激活带有用户及其相应推文的悬停工具。最后，在浏览器上渲染图片。代码如下：
- en: '[PRE31]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The following code gives an overview of the world map with the red dots representing
    the locations of the tweets'' origins:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码给出了带有红色点的世界地图概览，代表推文来源的位置：
- en: '![Geo-locating tweets](img/B03968_06_05.jpg)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![地理定位推文](img/B03968_06_05.jpg)'
- en: 'We can hover on a specific dot to reveal the tweets in that location:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以悬停在特定的点上，以揭示该位置上的推文：
- en: '![Geo-locating tweets](img/B03968_06_06.jpg)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![地理定位推文](img/B03968_06_06.jpg)'
- en: 'We can zoom into a specific location:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以放大到特定位置：
- en: '![Geo-locating tweets](img/B03968_06_07.jpg)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![地理定位推文](img/B03968_06_07.jpg)'
- en: 'Finally, we can reveal the tweets in the given zoomed-in location:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以揭示给定放大位置上的推文：
- en: '![Geo-locating tweets](img/B03968_06_08.jpg)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![地理定位推文](img/B03968_06_08.jpg)'
- en: Displaying upcoming meetups on Google Maps
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在谷歌地图上显示即将举行的聚会
- en: Now, our objective is to focus on upcoming meetups in London. We are mapping
    three meetups **Data Science London**, **Apache Spark**, and **Machine Learning**.
    We embed a Google Map within a Bokeh visualization and geo-locate the three meetups
    according to their coordinates and get information such as the name of the upcoming
    event for each meetup with a hover tool.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们的目标是关注伦敦的即将举行的聚会。我们正在绘制三个聚会**数据科学伦敦**、**Apache Spark**和**机器学习**。我们在一个Bokeh可视化中嵌入谷歌地图，并根据它们的坐标地理定位这三个聚会，并使用悬停工具获取每个聚会的即将举行活动的信息。
- en: 'First, import all the necessary Bokeh libraries:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，导入所有必要的Bokeh库：
- en: '[PRE32]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'We will instantiate the Google Map that will act as the substrate upon which
    our Bokeh visualization will be layered:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将实例化作为我们的Bokeh可视化底层的谷歌地图：
- en: '[PRE33]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Instantiate the Bokeh object plot from the class `GMapPlot` with the dimensions
    and map options from the previous step:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 使用前一步骤中的尺寸和地图选项，从`GMapPlot`类实例化Bokeh对象`plot`：
- en: '[PRE34]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Bring in the information from our three meetups we wish to plot and get the
    information by hovering above the respective coordinates:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 引入我们希望绘制的三个聚会的信息，并通过悬停在相应的坐标上方来获取信息：
- en: '[PRE35]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Define the dots to be drawn on the Google Map:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 定义要在谷歌地图上绘制的点：
- en: '[PRE36]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Define the stings for the Bokeh tools to be used in this visualization:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 定义用于此可视化的Bokeh工具的字符串：
- en: '[PRE37]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Activate the `hover` tool with the information that will be carried:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 激活携带信息的`hover`工具：
- en: '[PRE38]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Render the plot that gives a pretty good view of London:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 渲染出伦敦的视图：
- en: '![Displaying upcoming meetups on Google Maps](img/B03968_06_09.jpg)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![在谷歌地图上显示即将举行的聚会](img/B03968_06_09.jpg)'
- en: 'Once we hover on a highlighted dot, we can get the information of the given
    meetup:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们悬停在突出显示的点上，我们就可以获取给定聚会的信息：
- en: '![Displaying upcoming meetups on Google Maps](img/B03968_06_10.jpg)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![在谷歌地图上显示即将举行的聚会](img/B03968_06_10.jpg)'
- en: 'Full smooth zooming capability is preserved, as the following screenshot shows:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 如以下截图所示，保留了完整的平滑缩放功能：
- en: '![Displaying upcoming meetups on Google Maps](img/B03968_06_11.jpg)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![在谷歌地图上显示即将举行的聚会](img/B03968_06_11.jpg)'
- en: Summary
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we focused on few visualization techniques. We saw how to build
    wordclouds and their intuitive power to reveal, at a glance, lots of the key words,
    moods, and memes carried through thousands of tweets.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们关注了几种可视化技术。我们看到了如何构建词云及其直观的强大功能，可以一眼揭示成千上万推文中携带的关键词、情绪和梗。
- en: We then discussed interactive mapping visualizations using Bokeh. We built a
    world map from the ground up and created a scatter plot of critical tweets. Once
    the map was rendered on the browser, we could interactively hover from dot to
    dot and reveal the tweets originating from different parts of the world.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 我们随后讨论了使用 Bokeh 的交互式地图可视化。我们从零开始构建了一个世界地图，并创建了一个关键推文的散点图。一旦地图在浏览器上渲染，我们就可以交互式地从一点移动到另一点，揭示来自世界各地不同部分的推文。
- en: Our final visualization was focused on mapping upcoming meetups in London on
    Spark, data science, and machine learning and their respective topics, making
    a beautiful interactive visualization with an actual Google Map.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的最终可视化集中在伦敦即将举行的 Spark、数据科学和机器学习聚会及其相应主题的映射上，使用实际的谷歌地图制作了一个美丽的交互式可视化。
