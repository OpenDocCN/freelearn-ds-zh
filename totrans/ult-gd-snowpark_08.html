<html><head></head><body>
<div><h1 class="chapter-number" id="_idParaDest-96"><a id="_idTextAnchor097" class="calibre6 pcalibre1 pcalibre"/>6</h1>
<h1 id="_idParaDest-97" class="calibre5"><a id="_idTextAnchor098" class="calibre6 pcalibre1 pcalibre"/>Deploying and Managing ML Models with Snowpark</h1>
<p class="calibre3">The seamless deployment and effective management of models have become pivotal components of developing data science with Snowpark. The previous chapter covered how to prepare the data and train the model. This chapter delves into the intricacies of leveraging Snowpark to deploy and manage <strong class="bold">machine learning</strong> (<strong class="bold">ML</strong>) models efficiently, from deployment to integration with feature stores and model registries, exploring the essentials of streamlining ML models in Snowpark.</p>
<p class="calibre3">In this chapter, we’re going to cover the following main topics:</p>
<ul class="calibre15">
<li class="calibre14">Deploying ML models in Snowpark</li>
<li class="calibre14">Managing Snowpark model data</li>
</ul>
<h1 id="_idParaDest-98" class="calibre5"><a id="_idTextAnchor099" class="calibre6 pcalibre1 pcalibre"/>Technical requirements</h1>
<p class="calibre3">Please refer to the <em class="italic">Technical requirements</em> section in the previous chapter for environment setup.</p>
<p class="calibre3">Supporting materials are available at <a href="https://github.com/PacktPublishing/The-Ultimate-Guide-To-Snowpark" class="calibre6 pcalibre1 pcalibre">https://github.com/PacktPublishing/The-Ultimate-Guide-To-Snowpark</a>.</p>
<h1 id="_idParaDest-99" class="calibre5"><a id="_idTextAnchor100" class="calibre6 pcalibre1 pcalibre"/>Deploying ML models in Snowpark</h1>
<p class="calibre3">In <a id="_idIndexMarker336" class="calibre6 pcalibre1 pcalibre"/>the preceding<a id="_idIndexMarker337" class="calibre6 pcalibre1 pcalibre"/> chapter, we learned about how to develop ML models. Now that the models are ready, we must deploy them into Snowpark. To make it easier for developers to deploy the models, the Snowpark ML library consists of functions that encompass the introduction of a new development interface <a id="_idIndexMarker338" class="calibre6 pcalibre1 pcalibre"/>and additional functionalities aimed at securely facilitating the deployment of both features and models. Snowpark MLOps seamlessly complements<a id="_idIndexMarker339" class="calibre6 pcalibre1 pcalibre"/> the Snowpark ML Development API by offering advanced model management capabilities and integrated deployment functionalities within the Snowflake ecosystem. In the following subsections, we will explore the model registry and deploy the model for inference to obtain predictions.</p>
<h2 id="_idParaDest-100" class="calibre7"><a id="_idTextAnchor101" class="calibre6 pcalibre1 pcalibre"/>Snowpark ML model registry</h2>
<p class="calibre3">A <strong class="bold">model registry</strong> is a<a id="_idIndexMarker340" class="calibre6 pcalibre1 pcalibre"/> centralized repository that enables model developers to organize, share, and publish ML models efficiently. It streamlines collaboration <a id="_idIndexMarker341" class="calibre6 pcalibre1 pcalibre"/>among teams and stakeholders, facilitating the collaborative management of the lifecycle of all models within an organization. Organizing models is crucial for tracking various versions, quickly identifying the latest, and gaining insights into each model’s hyperparameters. A well-structured model registry enhances reproducibility and compelling comparison of results. It also allows tracking and analyzing model accuracy metrics, empowering informed decisions and continuous improvement. The following diagram shows the deployment of a model into a model registry:</p>
<div><div><img alt="Figure 6.1 – Deploying a model into a model registry" src="img/B19923_06_1.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.1 – Deploying a model into a model registry</p>
<p class="calibre3">The <a id="_idIndexMarker342" class="calibre6 pcalibre1 pcalibre"/>model registry is a Python API that manages models within the Snowflake environment, offering scalable, secure deployment and management capabilities for models within Snowflake. The Snowpark model registry is built upon a native Snowflake model entity, incorporating built-in versioning support for more streamlined management of models.</p>
<h3 class="calibre9">Preparing the model</h3>
<p class="calibre3">To <a id="_idIndexMarker343" class="calibre6 pcalibre1 pcalibre"/>illustrate the model registration process, we’ll efficiently craft a streamlined XGBoost model using minimal parameters, leveraging grid search on the <em class="italic">Bike Sharing</em> dataset. The <code>BSD_TRAINING</code> table prepared in the previous chapter is the foundational dataset for constructing our XGBoost model.</p>
<p class="calibre3">Here, we are making a feature list and finding label and output columns:</p>
<pre class="source-code">
FEATURE_LIST = [ "HOLIDAY", "WORKINGDAY", "HUMIDITY", "TEMP", "ATEMP", 
    "WINDSPEED", "SEASON", "WEATHER"]
LABEL_COLUMNS = ['COUNT']
OUTPUT_COLUMNS = ['PREDICTED_COUNT']
df = session.table("BSD_TRAINING")
df = df.drop("DATETIME","DATE")
df.show(2)</pre> <p class="calibre3">This<a id="_idIndexMarker344" class="calibre6 pcalibre1 pcalibre"/> will print out the following DataFrame:</p>
<div><div><img alt="Figure 6.2 – Model DataFrame" src="img/B19923_06_2.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.2 – Model DataFrame</p>
<p class="calibre3">For the sake of simplicity, we will focus on optimizing two parameters within XGBoost:</p>
<pre class="source-code">
from snowflake.ml.modeling.model_selection import GridSearchCV
from snowflake.ml.modeling.xgboost import XGBRegressor
param_grid = {
    "max_depth":[3, 4, 5, 6, 7, 8],
    "min_child_weight":[1, 2, 3, 4],
}
grid_search = GridSearchCV(
    estimator=XGBRegressor(),
    param_grid=param_grid,
    n_jobs = -1,
    scoring="neg_root_mean_squared_error",
    input_cols=FEATURE_LIST,
    label_cols=LABEL_COLUMNS,
    output_cols=OUTPUT_COLUMNS
)</pre> <p class="calibre3">This code<a id="_idIndexMarker345" class="calibre6 pcalibre1 pcalibre"/> employs Snowflake’s ML module to perform a grid search for hyperparameter tuning on a gradient boosting regressor. It explores combinations of <code>max_depth</code> and <code>min_child_weight</code> within specified ranges, aiming to optimize the model based on the input and label columns provided.</p>
<p class="calibre3">The subsequent logical progression involves partitioning the dataset into training and testing sets:</p>
<pre class="source-code">
train_df, test_df = df.random_split(weights=[0.7, 0.3], seed=0)
grid_search.fit(train_df)</pre> <p class="calibre3">This division is essential to facilitate model fitting, allowing us to train the model on the designated training dataset.</p>
<h4 class="calibre16">Extracting the optimum parameter</h4>
<p class="calibre3">Having<a id="_idIndexMarker346" class="calibre6 pcalibre1 pcalibre"/> successfully trained our dataset using the XGBoost model, the next imperative is identifying optimal parameter values defined through grid search. Remarkably similar to the process in the <code>scikit-learn</code> package, Snowpark ML offers a comparable methodology. The ensuing code mirrors the steps in extracting these optimal parameters and subsequently visualizing them, demystifying the process for seamless comprehension:</p>
<pre class="source-code">
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
gs_results = grid_search.to_sklearn().cv_results_
max_depth_val = []
min_child_weight_val = []
for param_dict in gs_results["params"]:
    max_depth_val.append(param_dict["max_depth"])
    min_child_weight_val.append(param_dict["min_child_weight"])
mape_val = gs_results["mean_test_score"]*-1</pre> <p class="calibre3">The <a id="_idIndexMarker347" class="calibre6 pcalibre1 pcalibre"/>preceding code uses <code>pandas</code>, <code>seaborn</code>, and <code>matplotlib</code> to analyze and visualize grid search results from a Snowpark ML model. It extracts the parameters, such as <code>max_depth</code> and <code>min_child_weight</code>, along with the corresponding <strong class="bold">mean absolute percentage error</strong> (<strong class="bold">MAPE</strong>) values for evaluation. The following code showcases the values:</p>
<pre class="source-code">
gs_results_df = pd.DataFrame(data={
    "max_depth":max_depth_val,
    "min_child_weight":min_child_weight_val,
    "mape":mape_val})
sns.relplot(data=gs_results_df, x="min_child_weight",
    y="mape", hue="max_depth", kind="line")</pre> <p class="calibre3">The preceding code creates a <code>pandas</code> DataFrame named <code>gs_results_df</code> from listed <code>max_depth</code>, <code>min_child_weight</code>, and <code>mape</code> values. It then utilizes <code>seaborn</code> to generate a line plot, visualizing the relationship between learning rates, MAPE scores, and different numbers of estimators. Finally, the <code>matplotlib</code> <code>plt.show()</code> command displays the following plot:</p>
<div><div><img alt="Figure 6.3 – Data plot" src="img/B19923_06_3.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.3 – Data plot</p>
<p class="calibre3">Upon<a id="_idIndexMarker348" class="calibre6 pcalibre1 pcalibre"/> careful observation of the previous plot, it becomes evident that a <code>max_depth</code> value of <code>8</code> paired with a <code>min_child_weight</code> learning rate of <code>2</code> yields the optimal results. It’s noteworthy that, akin to <code>scikit-learn</code>, Snowpark ML offers streamlined methods for extracting these optimal parameters, simplifying the process for enhanced user convenience:</p>
<pre class="source-code">
grid_search.to_sklearn().best_estimator_</pre> <p class="calibre3">The code transforms the Snowpark ML grid search results into a format compatible with <code>scikit-learn</code> and then retrieves the best estimator, representing the model with optimal hyperparameters:</p>
<div><div><img alt="Figure 6.4 – Snowpark ML grid search result" src="img/B19923_06_4.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.4 – Snowpark ML grid search result</p>
<p class="calibre3">In the <a id="_idIndexMarker349" class="calibre6 pcalibre1 pcalibre"/>next section, we will use the Snowpark model registry to log the model.</p>
<h3 class="calibre9">Logging the optimal model</h3>
<p class="calibre3">With <a id="_idIndexMarker350" class="calibre6 pcalibre1 pcalibre"/>our optimal model in hand, the pivotal phase of the model registry unfolds. Much akin to the previously created model, we can extend this process to encompass multiple models, registering each through the model registry. In this case, we will be registering only our optimal model. We’ll delve into a step-by-step exploration of how models can be registered and seamlessly deployed.</p>
<p class="callout-heading">Note on the Model Registry and Feature Store</p>
<p class="callout">While we write this chapter, both the Model Registry and Feature Store are in private preview. Once they are open to all, the API methods might be slightly different from what we see in this book.</p>
<p class="calibre3">Next, we need to create a registry to log our model:</p>
<pre class="source-code">
from snowflake.ml.registry import model_registry
registry = model_registry.ModelRegistry(session=session,
    database_name="SNOWPARK_DEFINITIVE_GUIDE",
    schema_name="MY_SCHEMA", create_if_not_exists=True)
ModelRegistry</strong> instance with session information, specified database, and schema names. If not existing, it creates a registry in the <code>SNOWPARK_DEFINITIVE_GUIDE</code> database and <code>MY_SCHEMA</code> schema.</pre>
<p class="calibre3">The <a id="_idIndexMarker351" class="calibre6 pcalibre1 pcalibre"/>following code prepares the essential details to log a model in the model registry:</p>
<pre class="source-code">
optimal_model = grid_search.to_sklearn().best_estimator_
optimal_max_depth = \
    grid_search.to_sklearn().best_estimator_.max_depth
optimal_min_child_weight = \
    grid_search.to_sklearn().best_estimator_.min_child_weight
optimal_mape = gs_results_df.loc[
    (gs_results_df['max_depth']==optimal_max_depth) &amp;
    (gs_results_df['min_child_weight']== \
        optimal_min_child_weight), 'mape'].values[0]</pre> <p class="calibre3">It extracts the optimal model, as determined by the grid search, and retrieves specific hyperparameters such as <code>max_depth</code>, <code>min_child_weight</code>, and optimal parameter values.</p>
<p class="calibre3">Having completed all necessary steps for model registration, the preceding code seamlessly integrates the gathered information to register our optimal XGBoost model officially in the model registry:</p>
<pre class="source-code">
model_name = "bike_model_xg_boost"
model_version = 1
X = train_df.select(FEATURE_LIST).limit(100)
registry.log_model( model_name=model_name,
                    model_version=model_version,
                    model=optimal_model,
                    sample_input_data=X,
                    options={"embed_local_ml_library": True, \
                             "relax": True})
registry.set_metric(model_name=model_name,
                    model_version=model_version,
                    metric_name="mean_abs_pct_err",
                    metric_value=optimal_mape)</pre> <p class="calibre3">The <a id="_idIndexMarker352" class="calibre6 pcalibre1 pcalibre"/>code assigns a name (<code>bike_model_xg_boost</code>) and version (<code>1</code>) to the model and logs it into the registry with associated details, including the sample input data and specific options. Additionally, it sets a custom metric, MAPE (<code>mean_abs_pct_err</code>), for the registered model with its corresponding value (<code>optimal_mape</code>). To verify successful registration, execute the following code:</p>
<pre class="source-code">
registry.list_models().to_pandas()</pre> <p class="calibre3">This will confirm whether our XGBoost model and the gradient boost model (only the XGBoost model are steps shown here to avoid unnecessary repetition) are appropriately listed in the model registry:</p>
<div><div><img alt="Figure 6.5 – Model registered in the model registry" src="img/B19923_06_5.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.5 – Model registered in the model registry</p>
<p class="calibre3">In the iterative journey of experimentation with diverse models and varied parameter configurations, we<a id="_idIndexMarker353" class="calibre6 pcalibre1 pcalibre"/> diligently register each model within the model registry through a structured methodology that ensures that each model, fine-tuned and optimized, is stored efficiently for future use. In the next section, we will deploy the model from the registry using Snowpark MLOps and predict its results.</p>
<h3 class="calibre9">Model deployment</h3>
<p class="calibre3">In the <a id="_idIndexMarker354" class="calibre6 pcalibre1 pcalibre"/>preceding sections, we navigated the intricate landscape of deploying models through complex <strong class="bold">user-defined functions</strong> (<strong class="bold">UDFs</strong>) or stored procedures. However, the new Snowpark model registry simplifies the cumbersome process. It enhances the maintainability of models by providing a streamlined and standardized framework for handling predictive models in a production setting. This shift in methodology optimizes operational efficiency and aligns seamlessly with contemporary practices in the dynamic field of data science. A standard model deployment would follow this naming convention:</p>
<pre class="source-code">
model_deployment_name = model_name + f"{model_version}" + "_UDF"
registry.deploy(model_name=model_name,
                model_version=model_version,
                deployment_name=model_deployment_name,
                target_method="predict",
                permanent=True,
                options={"relax_version": True})
predict</strong> target method, ensuring permanence in the deployment. Additionally, it includes an option to relax version constraints during deployment. Just as we’ve showcased the catalog of registered models, an equivalent insight into deployed models can be obtained using the following line of code:</pre>
<pre class="source-code">
registry.list_deployments(model_name, model_version).to_pandas()</pre> <p class="calibre3">This functionality<a id="_idIndexMarker355" class="calibre6 pcalibre1 pcalibre"/> provides a comprehensive view of models transitioning from registration to deployment within the system:</p>
<div><div><img alt="Figure 6.6 – Bike model deployment" src="img/B19923_06_6.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.6 – Bike model deployment</p>
<p class="calibre3">Now, let’s leverage our deployed model to infer predictions for the test data and assess the accuracy of our predictions against actual outcomes:</p>
<pre class="source-code">
model_ref = model_registry.ModelReference(
    registry=registry,
    model_name=model_name,
    model_version=model_version)
result_sdf = model_ref.predict(
    deployment_name=model_deployment_name,
    data=test_df)
result_sdf.show()</pre> <p class="calibre3">The code initiates a <code>ModelReference</code> object, linking to a specific model within the registry by referencing its name and version. Subsequently, it leverages this reference to predict the provided test data using the specified deployment, resulting in a Snowpark DataFrame (<code>result_sdf</code>). Finally, it displays the expected results through the <code>show()</code> method, as shown in the following screenshot:</p>
<div><div><img alt="Figure 6.7 – Model result DataFrame" src="img/B19923_06_7.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.7 – Model result DataFrame</p>
<p class="calibre3">Having <a id="_idIndexMarker356" class="calibre6 pcalibre1 pcalibre"/>observed a comprehensive cycle encompassing model development, registration, and deployment, it’s noteworthy that this process is replicable for any model-building endeavor through the model registry. In the subsequent section, we will elucidate several beneficial methods inherent in the model registry, elevating its usability and augmenting the overall modeling experience. Now that we have deployed the model, we will look at other model registry methods.</p>
<h3 class="calibre9">Model registry methods</h3>
<p class="calibre3">Beyond the<a id="_idIndexMarker357" class="calibre6 pcalibre1 pcalibre"/> functionality outlined for model deployment, the model registry extends its utility with several beneficial methods designed for effective model maintenance and housekeeping activities. In this section, we will explore a selection of these methods to enhance our understanding of their practical applications. We will start with model metrics.</p>
<h4 class="calibre16">Model metrics</h4>
<p class="calibre3">Linking metrics<a id="_idIndexMarker358" class="calibre6 pcalibre1 pcalibre"/> to your model version is a pivotal feature within the model registry. This functionality serves as a fundamental aspect, providing a systematic means to gauge the performance of each model version distinctly. By associating metrics, users gain valuable insights into the efficacy of different iterations, facilitating informed decision-making based on the quantitative evaluation of model performance across various versions. It also helps in automating the pipeline, thereby retraining if model metrics drop below the threshold value. This deliberate metrics integration enriches the comprehensive model management capabilities and establishes a structured framework for ongoing model evaluation and refinement:</p>
<pre class="source-code">
registry.set_metric(model_name=model_name,
                    model_version=model_version,
                    metric_name="mean_abs_pct_err",
                    metric_value=optimal_mape)</pre> <p class="calibre3">The <a id="_idIndexMarker359" class="calibre6 pcalibre1 pcalibre"/>preceding line sets a custom metric, <code>mean_abs_pct_err</code>, for a specific model version in the model registry, assigning the calculated MAPE value to quantify the model’s performance. It enhances the model registry’s ability to track and evaluate the effectiveness of different model versions:</p>
<pre class="source-code">
registry.get_metric_value(model_name=model_name,
                          model_version=model_version,
                          metric_name="mean_abs_pct_err")</pre> <p class="calibre3">This will print the following output:</p>
<div><div><img alt="Figure 6.8 – MAPE value of mean_abs_pct_err" src="img/B19923_06_8.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.8 – MAPE value of mean_abs_pct_err</p>
<p class="calibre3">In addition to setting, we can retrieve the value of a specific custom metric, <code>mean_abs_pct_err</code>, associated with a particular model version from the model registry. It allows users to access and analyze quantitative performance metrics for practical model evaluation and comparison across different versions:</p>
<pre class="source-code">
registry.get_metrics(model_name=model_name, 
    model_version=model_version)</pre> <p class="calibre3">Much like retrieving a specific metric for a deployed model, an analogous approach allows us to access a comprehensive list of all associated metrics for a given deployed model. This facilitates a holistic understanding of the model’s performance, providing a detailed overview of various metrics related to its evaluation and contributing to a thorough analysis of its effectiveness:</p>
<div><div><img alt="Figure 6.9 – Metrics of mean_abs_pct_err" src="img/B19923_06_9.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.9 – Metrics of mean_abs_pct_err</p>
<p class="calibre3">We can find <a id="_idIndexMarker360" class="calibre6 pcalibre1 pcalibre"/>the value of metrics from the model in the registry. In the next section, we will cover model tags and descriptions.</p>
<h4 class="calibre16">Model tags and descriptions</h4>
<p class="calibre3">Setting a <a id="_idIndexMarker361" class="calibre6 pcalibre1 pcalibre"/>tag name and description for a deployed model is crucial for effective experiment tracking and documentation. Tags and descriptions provide context and insights into the model’s purpose, configuration, and notable characteristics. This aids in maintaining a structured and informative record, enhancing reproducibility, and facilitating a more comprehensive analysis of experiment outcomes:</p>
<pre class="source-code">
registry.set_tag(model_name=model_name,
                 model_version=model_version,
                 tag_name="usage",
                 tag_value="experiment")
registry.list_models().to_pandas()[["NAME", "TAGS"]]</pre> <p class="calibre3">The provided code first sets a tag named <code>stage</code> with the <code>experiment_1</code> value for a specific model version in the model registry. This tagging is a contextual marker for the model’s purpose or usage. The subsequent line retrieves and displays, in a tabular format, the names of all models along with their associated tags, showcasing the tagged information for each model:</p>
<div><div><img alt="Figure 6.10 – Model tags" src="img/B19923_06_10.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.10 – Model tags</p>
<p class="calibre3">Another noteworthy aspect is the flexibility to modify and remove tags as necessary, allowing<a id="_idIndexMarker362" class="calibre6 pcalibre1 pcalibre"/> for a dynamic adjustment of our experiment design. This capability empowers users to iteratively refine contextual information associated with a model, providing meaningful and evolving tags. The ability to alter and remove tags enhances experiment design flexibility. It ensures that the documentation and context surrounding models can adapt to changing insights and requirements throughout the experimentation lifecycle:</p>
<pre class="source-code">
registry.remove_tag(model_name=model_name,
                    model_version=model_version,
                    tag_name="usage")
registry.list_models().to_pandas()[["NAME", "TAGS"]]</pre> <p class="calibre3">The provided code initiates the removal of a specific tag, named <code>usage</code>, from a particular model version within the model registry. Following this operation, the subsequent line retrieves and displays, in a tabular format, the names of all models along with their associated tags. This showcases the updated information after removing the specified tag, providing a comprehensive view of models and their altered tag configurations:</p>
<div><div><img alt="Figure 6.11 – Model tags removed" src="img/B19923_06_11.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.11 – Model tags removed</p>
<p class="calibre3">We can also provide descriptive information for a deployed model, offering valuable context and aiding future references. The ability to furnish a meaningful description enhances the comprehensibility of the model’s purpose, configuration, or other pertinent details. The ensuing code block, which is self-explanatory and mirrors the process of setting tags, enables the assignment of a descriptive narrative to a deployed model, ensuring that vital information is encapsulated for reference in subsequent analyses or experiments:</p>
<pre class="source-code">
registry.set_model_description(model_name=model_name,
    model_version=model_version,
    description="this is a test model")
print(registry.get_model_description(model_name=model_name,
    model_version=model_version))</pre> <p class="calibre3">The<a id="_idIndexMarker363" class="calibre6 pcalibre1 pcalibre"/> model description is set and can be retrieved to display on the screen:</p>
<div><div><img alt="Figure 6.12 – Model description" src="img/B19923_06_12.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.12 – Model description</p>
<p class="calibre3">Now that we have the model tags and description set, we will examine how to access the registry history.</p>
<h4 class="calibre16">Registry history</h4>
<p class="calibre3">Accessing<a id="_idIndexMarker364" class="calibre6 pcalibre1 pcalibre"/> the registry history is an invaluable capability, offering a chronological account of model versions, associated metrics, tags, and descriptions. This historical perspective enhances transparency in model development and empowers data scientists to make informed decisions, track performance trends, and iterate on model improvements with precision. The ML registry, coupled with its history-tracking feature, thus emerges as a pivotal asset in the data science arsenal, fostering a structured and efficient approach to model development, deployment, and ongoing refinement:</p>
<pre class="source-code">
registry.get_history().to_pandas()</pre> <p class="calibre3">The code retrieves and converts the entire history of the model registry into a <code>pandas</code> DataFrame, presenting a comprehensive tabular view of all recorded events and changes:</p>
<div><div><img alt="Figure 6.13 – Registry history" src="img/B19923_06_13.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.13 – Registry history</p>
<p class="calibre3">Narrowing down the search in the registry history is a common practice, and it can be achieved<a id="_idIndexMarker365" class="calibre6 pcalibre1 pcalibre"/> by specifying a model name and version. This targeted filtering allows for more focused exploration, aligning with typical preferences when navigating the model registry history:</p>
<pre class="source-code">
registry.get_model_history(model_name=model_name,
    model_version=model_version).to_pandas()</pre> <p class="calibre3">This code fetches and converts the specific history of a particular model version, identified by its name and version, into a <code>pandas</code> DataFrame:</p>
<div><div><img alt="Figure 6.14 – Registry history filter" src="img/B19923_06_14.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.14 – Registry history filter</p>
<p class="calibre3">The resulting DataFrame offers a detailed chronological record of all events and changes associated with that specific model version within the registry. In the next section, we will learn about operations on the model registry.</p>
<h4 class="calibre16">Model registry operations</h4>
<p class="calibre3">In the<a id="_idIndexMarker366" class="calibre6 pcalibre1 pcalibre"/> contemporary landscape of ML, the lifecycle of models is continually contracting, leading to shorter durations for deployed models. Concurrently, experiments with varying parameters generate many models, and their subsequent deployments are registered. This proliferation necessitates a thoughtful approach to model management, including periodic cleanup processes to maintain a streamlined and efficient model registry:</p>
<pre class="source-code">
registry.delete_deployment(model_name=model_name,
    model_version=model_version,
    deployment_name=model_deployment_name)
    registry.list_deployments(model_name, model_version).to_pandas()</pre> <p class="calibre3">The preceding code deletes a specific deployment instance identified by the model’s name, version, and deployment name from the model registry, ensuring efficient cleanup and management of deployed models:</p>
<div><div><img alt="Figure 6.15 – Deleting a specific deployment" src="img/B19923_06_15.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.15 – Deleting a specific deployment</p>
<p class="calibre3">It serves<a id="_idIndexMarker367" class="calibre6 pcalibre1 pcalibre"/> as a method to remove obsolete or undesired deployments. We can also delete a whole model from the registry by using the following code:</p>
<pre class="source-code">
registry.delete_model(model_name=model_name,
    model_version=model_version)
registry.list_models().to_pandas()</pre> <p class="calibre3">Similar to deleting a deployment, this code will delete a model from the model registry:</p>
<div><div><img alt="Figure 6.16 – Deleting a model" src="img/B19923_06_16.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.16 – Deleting a model</p>
<p class="calibre3">We can see that the entire model has been deleted from the registry. In the next section, we will look at the benefits of a model registry.</p>
<h3 class="calibre9">Benefits of the model registry in the model lifecycle</h3>
<p class="calibre3">The<a id="_idIndexMarker368" class="calibre6 pcalibre1 pcalibre"/> Snowpark model registry streamlines the management of ML models throughout their lifecycle. Let’s delve into how the model registry in Snowpark can assist in various stages of the ML model lifecycle:</p>
<ol class="calibre13">
<li class="calibre14"><strong class="bold">Model development</strong>: During the development phase, data scientists can use Snowpark to build, train, and validate ML models directly within Snowflake. The model registry provides a centralized location to store and version control these models, making it easier to track changes, compare performance, and collaborate with team members.</li>
<li class="calibre14"><strong class="bold">Model deployment</strong>: Once a model is trained and validated, it needs to be deployed into production environments for inference. The model registry facilitates seamless deployment by providing a standardized interface to deploy models<a id="_idIndexMarker369" class="calibre6 pcalibre1 pcalibre"/> across different environments. This ensures consistency and reliability in model deployment processes.</li>
<li class="calibre14"><strong class="bold">Model monitoring</strong>: Monitoring the performance of deployed models is crucial for detecting drift and ensuring continued accuracy over time. The model registry can integrate with monitoring tools to track model performance metrics, such as accuracy, precision, recall, and F1-score, enabling proactive maintenance and optimization.</li>
<li class="calibre14"><strong class="bold">Model governance</strong>: Ensuring compliance with regulatory requirements and organizational policies is essential for responsible AI deployment. The model registry supports governance by providing capabilities for access control, audit logging, and versioning. This helps organizations maintain visibility and control over the entire model lifecycle.</li>
<li class="calibre14"><strong class="bold">Model retraining and updating</strong>: ML models need to be periodically retrained and updated to adapt to changing data distributions and business requirements. The model registry simplifies this process by enabling data scientists to seamlessly retrain models using updated data and algorithms while preserving the lineage and history of model versions.</li>
<li class="calibre14"><strong class="bold">Model retirement</strong>: As models become obsolete or are replaced by newer versions, they need to be retired gracefully. The model registry facilitates the retirement process by archiving outdated models, documenting reasons for retirement, and ensuring that relevant stakeholders are notified of changes.</li>
</ol>
<p class="calibre3">The model registry offers an organized framework for model management and provides functionalities for efficient housekeeping, including setting and tracking metrics, tags, and descriptions. The registry’s history-tracking capabilities have emerged as a valuable feature, allowing users to gain insights into the evolution of models over time. Tags and descriptions offer context and facilitate experiment tracking for accessing and filtering the registry history, enabling a comprehensive view of model-related activities. Overall, the model<a id="_idIndexMarker370" class="calibre6 pcalibre1 pcalibre"/> registry emerges as a powerful addition to Snowpark ML, centralizing model management, facilitating experimentation, and ensuring a streamlined and organized approach to model development and deployment.</p>
<p class="calibre3">Overall, the model registry in Snowpark plays a pivotal role in streamlining the ML model lifecycle, from development and deployment to monitoring, governance, retraining, and retirement. By providing a centralized platform for managing models, it helps organizations maximize the value of their ML investments while minimizing operational overhead and risks.</p>
<h1 id="_idParaDest-101" class="calibre5"><a id="_idTextAnchor102" class="calibre6 pcalibre1 pcalibre"/>Managing Snowpark model data</h1>
<p class="calibre3">In the previous <a id="_idIndexMarker371" class="calibre6 pcalibre1 pcalibre"/>section, we covered the deployment of ML models using the model registry. This section will look at managing Snowpark Models using feature stores. Snowpark ML Feature Store simplifies the feature engineering process and is integral to ML, significantly influencing model performance based on the quality of features employed. This chapter will help us learn about using feature stores and managing Snowpark models.</p>
<h2 id="_idParaDest-102" class="calibre7"><a id="_idTextAnchor103" class="calibre6 pcalibre1 pcalibre"/>Snowpark Feature Store</h2>
<p class="calibre3">The Snowpark Feature Store<a id="_idIndexMarker372" class="calibre6 pcalibre1 pcalibre"/> is an integrated <a id="_idIndexMarker373" class="calibre6 pcalibre1 pcalibre"/>solution for data scientists and ML engineers. It facilitates the creation, storage, management, and serving of ML features for model training and inference and is accessible through the Snowpark ML library. The feature store defines, manages, and retrieves features, supported by a managed infrastructure for feature metadata management and continuous feature processing. Its primary function is to make these features readily available for reuse in the ongoing development of future ML models. Feature stores play a pivotal role in operationalizing data input, tracking, and governance within the realm of feature engineering for ML:</p>
<div><div><img alt="Figure 6.17 – Feature Store" src="img/B19923_06_17.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.17 – Feature Store</p>
<p class="calibre3">By <a id="_idIndexMarker374" class="calibre6 pcalibre1 pcalibre"/>leveraging the Snowpark Feature Store, which<a id="_idIndexMarker375" class="calibre6 pcalibre1 pcalibre"/> is designed to simplify and enhance this process by offering increased efficiency for data scientists and ML practitioners. ML teams can uphold a singular and updated source of truth for model training, versioning, and inference features. We will use the <em class="italic">Bike Sharing</em> dataset and the ML model developed in the previous section to showcase how the Feature Store enhances the model development and deployment cycle.</p>
<h2 id="_idParaDest-103" class="calibre7"><a id="_idTextAnchor104" class="calibre6 pcalibre1 pcalibre"/>Benefits of Feature Store</h2>
<p class="calibre3">Utilizing <a id="_idIndexMarker376" class="calibre6 pcalibre1 pcalibre"/>feature stores provides several benefits for ML initiatives. Firstly, they enable feature reuse by saving developed features, allowing them to be quickly accessed and repurposed for new ML models, thereby saving time and effort. Secondly, they ensure feature consistency by providing a centralized registry for all ML features, maintaining consistent definitions and documentation across teams. Thirdly, feature stores help maintain peak model performance by centralizing feature pipelines, ensuring consistency between training and inference, and continuously monitoring data pipelines for any discrepancies.</p>
<p class="calibre3">Furthermore, feature stores enhance security and data governance by providing detailed information about each ML model’s training data and deployment data, facilitating iteration and debugging. Integrating feature stores with cloud data warehouses enhances data security, ensuring the protection of both models and training data. Lastly, feature stores foster collaboration between teams by offering a centralized platform for the development, storage, modification, and sharing of ML features, promoting<a id="_idIndexMarker377" class="calibre6 pcalibre1 pcalibre"/> cross-team collaboration and idea-sharing for multiple business applications.</p>
<h2 id="_idParaDest-104" class="calibre7"><a id="_idTextAnchor105" class="calibre6 pcalibre1 pcalibre"/>Feature stores versus data warehouses</h2>
<p class="calibre3">Delving into the distinction between feature stores and data warehouses sheds light on their collaborative role in enhancing value within ML projects.</p>
<h3 class="calibre9">Similarities – shared traits and functions</h3>
<p class="calibre3">Both<a id="_idIndexMarker378" class="calibre6 pcalibre1 pcalibre"/> feature stores and data warehouses exhibit parallels in their operational methodologies. They rely on <strong class="bold">Extract, Transform, Load</strong> (<strong class="bold">ETL</strong>) pipelines to facilitate data management and accessibility. Additionally, they serve as repositories endowed with metadata, fostering seamless data sharing and utilization across organizational teams.</p>
<h3 class="calibre9">End users – tailored utility</h3>
<p class="calibre3">A notable <a id="_idIndexMarker379" class="calibre6 pcalibre1 pcalibre"/>deviation lies in their primary user base. Data warehouses traditionally cater to analysts entrenched in the generation of comprehensive business reports, delving into historical data for strategic insights. Conversely, feature stores cater specifically to data scientists immersed in the development of predictive ML models. While the latter may draw from data warehouses for supplementary insights, their core function revolves around leveraging feature stores for streamlined model development and inference.</p>
<h3 class="calibre9">Data types – structural variances</h3>
<p class="calibre3">Structurally, data<a id="_idIndexMarker380" class="calibre6 pcalibre1 pcalibre"/> warehouses house domain-specific data within relational databases characterized by well-defined schemas. This structured format facilitates streamlined querying and retrieval of pertinent information, ideal for analytical endeavors. Conversely, feature stores house a distinct array of feature values crucial for ML model training. These values encompass both quantitative and categorical variables, enriching the model development process with granular insights.</p>
<h3 class="calibre9">ETL pipelines – divergent trajectories</h3>
<p class="calibre3">The<a id="_idIndexMarker381" class="calibre6 pcalibre1 pcalibre"/> operational dynamics of ETL pipelines further accentuate the disparity between feature stores and data warehouses. ETL processes within data warehouses predominantly focus on data cleansing and transformation, ensuring data accuracy and coherence within the defined schema. In contrast, feature store pipelines embark on a more intricate journey, encompassing data extraction, transformation, and feature engineering. The transformations within feature stores often entail sophisticated computations and aggregations to distill intricate insights vital for model training and inference, underscoring their pivotal role in the ML lifecycle.</p>
<p class="calibre3">Now that we’ve grasped the essence of feature stores, comprehending their significance and differentiation from data warehouses, let’s delve deeper into the various components comprising a feature store.</p>
<p class="calibre3">In the subsequent section, we’ll embark on the creation of a rudimentary feature store tailored to the <em class="italic">Bike Sharing</em> dataset, focusing solely on weather-related features. The process entails the following:</p>
<ol class="calibre13">
<li class="calibre14">Feature store creation</li>
<li class="calibre14">Feature entity creation</li>
<li class="calibre14">Selecting and transforming weather features</li>
<li class="calibre14">Creating a feature view</li>
<li class="calibre14">Generating datasets enriched with the feature view</li>
<li class="calibre14">Constructing an ML model empowered by the enriched dataset</li>
<li class="calibre14">Facilitating predictions based on the trained model</li>
</ol>
<p class="calibre3">Let’s discuss each of them in detail.</p>
<h4 class="calibre16">Creating a feature store</h4>
<p class="calibre3">Initiating<a id="_idIndexMarker382" class="calibre6 pcalibre1 pcalibre"/> work with the Snowflake Feature Store involves establishing a new feature store or connecting to an existing one. This is accomplished by furnishing specific details to the <code>FeatureStore</code> constructor, including a Snowpark session, database name, feature store name, and default warehouse name. The <code>creation_mode</code> parameter is crucial in determining whether a new feature store should be created if it does not exist. To implement this functionality, we’ll use the following code:</p>
<pre class="source-code">
from snowflake.ml.feature_store import (
    FeatureStore, FeatureView, Entity, CreationMode)
fs = FeatureStore(
    session=session,
    database="SNOWPARK_DEFINITIVE_GUIDE",
    name="BIKE_SHARING_FEATURES",
    default_warehouse="COMPUTE_WH",
    creation_mode=CreationMode.CREATE_IF_NOT_EXIST,
)</pre> <p class="calibre3">This will open a session to the feature store and allow it to be accessed in the Snowpark session. The next step will be to set up a feature entity on this feature store.</p>
<h4 class="calibre16">Creating feature entities</h4>
<p class="calibre3">Entities <a id="_idIndexMarker383" class="calibre6 pcalibre1 pcalibre"/>are fundamental elements linked with features and feature views, providing the cornerstone for feature lookups by defining join keys. Users can generate novel entities and formally register them within the feature store, thereby fostering connections and relationships between various features. This code creates an entity named <code>WEATHER</code> with an <code>ID</code> join key, registers it in the<a id="_idIndexMarker384" class="calibre6 pcalibre1 pcalibre"/> feature store (<code>fs</code>), and then displays a list of entities in the feature store:</p>
<pre class="source-code">
entity = Entity(name="ENTITY_WEATHER", join_keys=["ID"])
fs.register_entity(entity)
fs.list_entities().show()</pre> <p class="calibre3">This generates the following output:</p>
<div><div><img alt="Figure 6.18 – Feature entity" src="img/B19923_06_18.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.18 – Feature entity</p>
<p class="calibre3">The <code>ENTITY_WEATHER</code> entity has been created with the ID as the join key. The next step is to set up feature views.</p>
<h4 class="calibre16">Creating feature views</h4>
<p class="calibre3">Within <a id="_idIndexMarker385" class="calibre6 pcalibre1 pcalibre"/>a feature store, feature views act as comprehensive pipelines, systematically transforming raw data into interconnected features at regular intervals. These feature views are materialized from designated source tables, ensuring incremental and efficient updates as fresh data is introduced. In our previous chapter, we explored a dataset that comprised various weather-related features. To preprocess this data effectively, we employed a Snowpark pipeline.</p>
<p class="calibre3">Through this pipeline, we performed transformations on the <code>SEASON</code> and <code>WEATHER</code> columns using one-hot encoding techniques. Additionally, we normalized the <code>TEMP</code> column to ensure consistency and facilitate model training. Given that we thoroughly discussed each step of this pipeline in our previous chapter, we’ll be revisiting it briefly, focusing more on a high-level overview rather than delving into detailed explanations:</p>
<pre class="source-code">
import snowflake.ml.modeling.preprocessing as snowml
from snowflake.ml.modeling.pipeline import Pipeline
from snowflake.snowpark.types import IntegerType
# CREATING ID COLUMN
from snowflake.snowpark.functions \
    import monotonically_increasing_id
df = df.withColumn("ID", monotonically_increasing_id())
df = df.drop("DATETIME","DATE")
CATEGORICAL_COLUMNS = ["SEASON","WEATHER"]
CATEGORICAL_COLUMNS_OHE = ["SEASON_OE","WEATHER_OE"]
MIN_MAX_COLUMNS = ["TEMP"]
import numpy as np
categories = {
    "SEASON": np.array([1,2,3,4]),
    "WEATHER": np.array([1,2,3,4]),
}</pre> <p class="calibre3">This code<a id="_idIndexMarker386" class="calibre6 pcalibre1 pcalibre"/> block utilizes Snowflake’s ML capabilities for data preprocessing. It imports necessary modules such as preprocessing functions and the <code>Pipeline</code> class. The code creates a new <code>ID</code> column with unique identifiers for each row and drops unnecessary columns. It defines lists of categorical columns and their transformed versions after one-hot encoding, along with columns to be normalized. Additionally, it specifies categories for each categorical column, likely for encoding purposes, facilitating effective ML model processing:</p>
<pre class="source-code">
preprocessing_pipeline = Pipeline(
    steps=[
        (
            "OE",
            snowml.OrdinalEncoder(
                input_cols=CATEGORICAL_COLUMNS,
                output_cols=CATEGORICAL_COLUMNS_OHE,
                categories=categories
            )
        ),
        (
            "MMS",
            snowml.MinMaxScaler(
                clip=True,
                input_cols=MIN_MAX_COLUMNS,
                output_cols=MIN_MAX_COLUMNS,
            )
        )
    ]
)
transformed_df = preprocessing_pipeline.fit(df).transform(df)
transformed_df.show()</pre> <p class="calibre3">In the first step, an ordinal encoder (<code>OE</code>) is applied to transform categorical columns specified in the <code>CATEGORICAL_COLUMNS</code> list into their one-hot encoded versions, as defined by the <code>CATEGORICAL_COLUMNS_OHE</code> list. The <code>categories</code> parameter specifies the categories for each categorical column, likely used for encoding purposes.</p>
<p class="calibre3">In the second step, a min-max scaler (<code>MMS</code>) is used to normalize columns specified in the <code>MIN_MAX_COLUMNS</code> list. This scaler ensures that values in these columns are scaled to a specific range, typically between <code>0</code> and <code>1</code>, while preserving their relative proportions.</p>
<p class="calibre3">The <a id="_idIndexMarker387" class="calibre6 pcalibre1 pcalibre"/>preprocessing pipeline is then applied to the <code>df</code> DataFrame using the fit-transform paradigm, where the pipeline is first fit to the data to learn parameters (for example, category mappings for ordinal encoding), and then applied to transform the DataFrame. The transformed DataFrame is then displayed using the <code>show()</code> method. Overall, this code prepares the DataFrame for further analysis or model training by preprocessing its columns using the specified pipeline. The resultant DataFrame is as follows:</p>
<div><div><img alt="Figure 6.19 – Transformed DataFrame" src="img/B19923_06_19.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.19 – Transformed DataFrame</p>
<p class="calibre3">Throughout the model-building process, various models are constructed using subsets of features, such as weather features and time-related features. Additionally, models are developed using combined data to ascertain superior performance. To expedite the model-building process and reduce data engineering overheads, we’ll organize weather-related features into a dedicated feature view. Subsequently, we’ll leverage this feature view to generate datasets and construct an XGBoost model in the ensuing section:</p>
<pre class="source-code">
feature_df = transformed_df.select(["SEASON_OE",
    "WEATHER_OE", "TEMP", "ATEMP", "HUMIDITY",
    "WINDSPEED", "ID"])
fv = FeatureView(
    name="WEATHER_FEATURES",
    entities=[entity],
    feature_df=feature_df,
    desc="weather features"
)
fv = fs.register_feature_view(
    feature_view=fv,
    version="V1",
    block=True
)
fs.read_feature_view(fv).show()</pre> <p class="calibre3">The <a id="_idIndexMarker388" class="calibre6 pcalibre1 pcalibre"/>code selects specific columns from the DataFrame to create a feature DataFrame (<code>feature_df</code>). Then, it constructs a feature view named <code>WEATHER_FEATURES</code> associated with the previously defined entity and registers it in the feature store (<code>fs</code>) with version <code>V1</code>. The resulting DataFrame is as follows:</p>
<div><div><img alt="Figure 6.20 – Feature DataFrame" src="img/B19923_06_20.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.20 – Feature DataFrame</p>
<p class="calibre3">Once developed, features can be systematically stored in the feature store, fostering their availability for reuse or seamless sharing among various ML models and teams. This functionality <a id="_idIndexMarker389" class="calibre6 pcalibre1 pcalibre"/>significantly accelerates the creation of new ML models, eliminating the redundancy of building each feature from scratch. In the same way, we can create another feature view as rental features by combining similar features.</p>
<h4 class="calibre16">Preparing the dataset</h4>
<p class="calibre3">Once our <a id="_idIndexMarker390" class="calibre6 pcalibre1 pcalibre"/>feature pipelines are meticulously configured and ready, we can initiate their deployment to generate training data. Subsequently, these feature pipelines become instrumental in facilitating model prediction, marking the seamless transition from feature engineering to the practical application of ML models:</p>
<pre class="source-code">
#GENERATING TRAINING DATA
spine_df = session.table("BSD_TRAINING")
spine_df = spine_df.withColumn("ID",
    monotonically_increasing_id())
spine_df = spine_df.select("ID", "COUNT")
spine_df.show()
train_data = fs.generate_dataset(
    spine_df=spine_df,
    features=[
        fv.slice([
            "HUMIDITY","SEASON_OE","TEMP",
            "WEATHER_OE","WINDSPEED"
        ])
    ],
    materialized_table=None,
    spine_timestamp_col=None,
    spine_label_cols=["COUNT"],
    save_mode="merge",
    exclude_columns=['ID']
)
train_data.df.show()</pre> <p class="calibre3">Creating training<a id="_idIndexMarker391" class="calibre6 pcalibre1 pcalibre"/> data becomes straightforward as materialized feature views inherently encompass crucial metadata such as join keys and timestamps<a id="_idIndexMarker392" class="calibre6 pcalibre1 pcalibre"/> for <strong class="bold">point-in-time</strong> (<strong class="bold">PIT</strong>) lookup:</p>
<div><div><img alt="Figure 6.21 – Training data" src="img/B19923_06_21.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.21 – Training data</p>
<p class="calibre3">The process primarily involves supplying spine data—termed so because it serves as the foundational structure enriched by feature joins. In our case, spine data encompasses the feature to be predicted—<code>COUNT</code>—along with the join key column ID. Moreover, the flexibility to generate datasets with subsets of features within the feature view is available through slicing. Now that we have the training data ready, we will use it to train the model and predict the data output using the feature store.</p>
<p class="calibre3">The <a id="_idIndexMarker393" class="calibre6 pcalibre1 pcalibre"/>preparation of all data—both for training and operational use—requires meticulous handling through feature pipelines. These pipelines, resembling traditional data pipelines, aggregate, validate, and transform data output in a format suitable for input into the ML model. Properly orchestrated feature pipelines ensure that data is refined before being fed into the model, maintaining the integrity and relevance of features derived from the training process.</p>
<h4 class="calibre16">Model training</h4>
<p class="calibre3">We<a id="_idIndexMarker394" class="calibre6 pcalibre1 pcalibre"/> covered the model-building process extensively in the previous chapter, so in this section, we will focus on building it using the training dataset generated from feature views from the feature store. We are using a similar method outlined in the previous chapter in training a gradient boost model but just using feature views:</p>
<pre class="source-code">
from snowflake.ml.modeling.model_selection import GridSearchCV
from snowflake.ml.modeling.ensemble \
    import GradientBoostingRegressor
FEATURE_LIST = ["TEMP", "WINDSPEED", "SEASON_OE", "WEATHER_OE"]
LABEL_COLUMNS = ['COUNT']
OUTPUT_COLUMNS = ['PREDICTED_COUNT']
param_grid = {
    "n_estimators":[100, 200, 300, 400, 500],
    "learning_rate":[0.1, 0.2, 0.3, 0.4, 0.5],
}
grid_search = GridSearchCV(
    estimator=GradientBoostingRegressor(),
    param_grid=param_grid,
    n_jobs = -1,
    scoring="neg_root_mean_squared_error",
    input_cols=FEATURE_LIST,
    label_cols=LABEL_COLUMNS,
    output_cols=OUTPUT_COLUMNS
)
train_df = train_data.df.drop(["ID"])
grid_search.fit(train_df)</pre> <p class="calibre3">The <a id="_idIndexMarker395" class="calibre6 pcalibre1 pcalibre"/>elegance of Snowpark surfaces in this simplicity, as no significant modifications are needed to train a model using feature views seamlessly. We will create testing data to test the model for accuracy using the following code:</p>
<pre class="source-code">
test_df = spine_df.limit(3).select("ID")
enriched_df = fs.retrieve_feature_values(
    test_df, train_data.load_features())
enriched_df = enriched_df.drop('ID')
enriched_df.show()</pre> <p class="calibre3">This creates a test DataFrame (<code>test_df</code>) by selecting the <code>ID</code> column from the first three rows of <code>spine_df</code>. Then, it retrieves and displays feature values for the test data frame using <a id="_idIndexMarker396" class="calibre6 pcalibre1 pcalibre"/>the feature store and training data generated from feature views:</p>
<div><div><img alt="Figure 6.22 – Testing data" src="img/B19923_06_22.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.22 – Testing data</p>
<p class="calibre3">Now that the testing data is ready, we can predict the model using this data to get the results.</p>
<h4 class="calibre16">Model prediction</h4>
<p class="calibre3">In this<a id="_idIndexMarker397" class="calibre6 pcalibre1 pcalibre"/> section, we will use the testing data generated from the feature store to make a prediction:</p>
<pre class="source-code">
pred = grid_search.predict(enriched_df.to_pandas())
pred.head()</pre> <p class="calibre3">The prediction displays the results with the predicted count value, showing the number of customers using shared bikes at the given hour:</p>
<div><div><img alt="Figure 6.23 – Model prediction" src="img/B19923_06_23.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 6.23 – Model prediction</p>
<p class="calibre3">This shows how easy and improved it is to use a feature store to build a Snowpark ML model. In the next section, we will highlight some benefits of using feature stores.</p>
<h2 id="_idParaDest-105" class="calibre7"><a id="_idTextAnchor106" class="calibre6 pcalibre1 pcalibre"/>When to utilize versus when to avoid feature stores</h2>
<p class="calibre3">Feature stores <a id="_idIndexMarker398" class="calibre6 pcalibre1 pcalibre"/>are particularly advantageous in ML processes when there’s a need for efficient feature management and reuse across multiple models or teams. They shine in<a id="_idIndexMarker399" class="calibre6 pcalibre1 pcalibre"/> the following scenarios:</p>
<ul class="calibre15">
<li class="calibre14"><strong class="bold">Feature reuse</strong>: Features need to be reused or shared between different ML models or teams, reducing redundant efforts in feature engineering</li>
<li class="calibre14"><strong class="bold">Consistency and governance</strong>: Ensuring consistent definitions, documentation, and governance of features across diverse ML projects or teams is critical</li>
<li class="calibre14"><strong class="bold">Model performance</strong>: Maintaining peak model performance by ensuring consistency between feature definitions in training and inference pipelines, thus avoiding performance degradation due to discrepancies</li>
<li class="calibre14"><strong class="bold">Data collaboration</strong>: Fostering collaboration between different teams or stakeholders involved in ML projects by offering a centralized platform for feature development, storage, modification, and sharing</li>
<li class="calibre14"><strong class="bold">Scalability</strong>: Handling large volumes of features and data efficiently, especially in environments where data is continuously evolving or being updated</li>
</ul>
<p class="calibre3">However, feature stores may not be necessary in the following scenarios:</p>
<ul class="calibre15">
<li class="calibre14"><strong class="bold">Simple models</strong>: For simple models with few features and minimal complexity, the overhead of setting up and maintaining a feature store may outweigh its benefits</li>
<li class="calibre14"><strong class="bold">Static data</strong>: In cases where the data is relatively static and doesn’t require frequent updates or feature engineering, the need for a feature store may be limited</li>
<li class="calibre14"><strong class="bold">Limited collaboration</strong>: When ML projects involve a small, tightly-knit team working on isolated tasks without the need for extensive collaboration or feature sharing, the use of a feature store may be unnecessary</li>
<li class="calibre14"><strong class="bold">Resource constraints</strong>: Organizations with limited resources or infrastructure may find it challenging to implement and maintain a feature store effectively</li>
</ul>
<p class="calibre3">In summary, while<a id="_idIndexMarker400" class="calibre6 pcalibre1 pcalibre"/> feature stores offer numerous benefits for efficient feature management in ML projects, their adoption should be carefully considered based on the specific needs and constraints of each project or organization.</p>
<h1 id="_idParaDest-106" class="calibre5"><a id="_idTextAnchor107" class="calibre6 pcalibre1 pcalibre"/>Summary</h1>
<p class="calibre3">This chapter discussed the model registry and the importance of meaningful tags and descriptions, offering context and facilitating experiment tracking. We also highlighted different methods of operating with the model registry. We navigated through the capabilities of the Snowflake Feature Store within the Snowpark ML ecosystem and how to utilize it for managing Snowflake models.</p>
<p class="calibre3">In the next chapter, we will learn about developing native applications using the Snowpark framework.</p>
</div>
</body></html>