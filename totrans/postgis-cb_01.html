<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Moving Data In and Out of PostGIS</h1>
                </header>
            
            <article>
                
<p class="mce-root">In this chapter, we will cover:</p>
<ul>
<li>Importing nonspatial tabular data (CSV) using PostGIS functions</li>
<li>Importing nonspatial tabular data (CSV) using GDAL</li>
<li>Importing shapefiles with shp2pgsql</li>
<li>Importing and exporting data with the ogr2ogr GDAL command</li>
<li>Handling batch importing and exporting of datasets</li>
<li>Exporting data to a shapefile with the pgsql2shp PostGIS command</li>
<li>Importing OpenStreetMap data with the osm2pgsql command</li>
<li>Importing raster data with the raster2pgsql PostGIS command</li>
<li>Importing multiple rasters at a time</li>
<li>Exporting rasters with the gdal_translate and gdalwarp GDAL commands</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Introduction</h1>
                </header>
            
            <article>
                
<p>PostGIS is an open source extension for the PostgreSQL database that allows support for geographic objects; throughout this book you will find recipes that will guide you step by step to explore the different functionalities it offers.</p>
<p>The purpose of the book is to become a useful tool for understanding the capabilities of PostGIS and how to apply them in no time. Each recipe presents a preparation stage, in order to organize your workspace with everything you may need, then the set of steps that you need to perform in order to achieve the main goal of the task, that includes all the external commands and SQL sentences you will need (which have been tested in Linux, Mac and Windows environments), and finally a small summary of the recipe. This book will go over a large set of common tasks in geographical information systems and location-based services, which makes it a must-have book in your technical library.</p>
<p>In this first chapter, we will show you a set of recipes covering different tools and methodologies to import and export geographic data from the PostGIS spatial database, given that pretty much every common action to perform in a GIS starts with inserting or exporting geospatial data.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Importing nonspatial tabular data (CSV) using PostGIS functions</h1>
                </header>
            
            <article>
                
<p>There are a couple of alternative approaches to importing a <strong>Comma Separated Values</strong> (<strong>CSV</strong>) file, which stores attributes and geometries in PostGIS. In this recipe, we will use the approach of importing such a file using the PostgreSQL <kbd>COPY</kbd> command and a couple of PostGIS functions.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>We will import the <kbd>firenews.csv</kbd> file that stores a series of web news collected from various RSS feeds related to forest fires in Europe in the context of the <strong>European </strong><strong>Forest </strong><strong>Fire </strong><strong>Information </strong><strong>System</strong> (<strong>EFFIS</strong>), available at <a href="http://effis.jrc.ec.europa.eu/"><span class="URLPACKT">http://effis.jrc.ec.europa.eu/</span></a>.</p>
<p>For each news feed, there are attributes such as <kbd>place name</kbd>, <kbd>size</kbd> of the fire in hectares, <kbd>URL</kbd>, and so on. Most importantly, there are the <kbd>x</kbd> and <kbd>y</kbd> fields that give the position of the geolocalized news in decimal degrees (in the WGS 84 spatial reference system, SRID = 4326).</p>
<p>For Windows machines, it is necessary to install OSGeo4W, a set of open source geographical libraries that will allow the manipulation of the datasets. The link is: <a href="https://trac.osgeo.org/osgeo4w/"><span class="URLPACKT">https://trac.osgeo.org/osgeo4w/</span></a></p>
<p>In addition, include the OSGeo4W and the Postgres binary folders in the Path environment variable to be able to execute the commands from any location in your PC.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>The steps you need to follow to complete this recipe are as shown:</p>
<ol>
<li>Inspect the structure of the CSV file, <kbd>firenews.csv</kbd>, which you can find within the book dataset (if you are on Windows, open the CSV file with an editor such as Notepad).</li>
</ol>
<pre><strong>      $ cd ~/postgis_cookbook/data/chp01/<br/></strong><strong>      $ head -n 5 firenews.csv</strong></pre>
<p style="padding-left: 60px">The output of the preceding command is as shown:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/2b34e608-2d3b-4c8a-8974-cfd3e04e7c7f.png" style="width:43.50em;height:18.42em;"/></div>
<ol start="2">
<li>Connect to PostgreSQL, create the <kbd>chp01 SCHEMA</kbd>, and create the following table:</li>
</ol>
<pre><strong>      $ psql -U me -d postgis_cookbook 
      postgis_cookbook=&gt; CREATE EXTENSION postgis; 
      postgis_cookbook=&gt; CREATE SCHEMA chp01; 
      postgis_cookbook=&gt; CREATE TABLE chp01.firenews 
      ( 
        x float8, 
        y float8, 
        place varchar(100), 
        size float8, 
        update date, 
        startdate date, 
        enddate date, 
        title varchar(255), 
        url varchar(255), 
        the_geom geometry(POINT, 4326) 
      );</strong> </pre>
<div class="packt_infobox">We are using the <kbd>psql</kbd> client for connecting to PostgreSQL, but you can use your favorite one, for example, <kbd>pgAdmin</kbd>.<br/>
Using the <kbd>psql</kbd> client, we will not show the host and port options as we will assume that you are using a local PostgreSQL installation on the standard port.<br/>
If that is not the case, please provide those options!</div>
<ol start="3">
<li>Copy the records from the CSV file to the PostgreSQL table using the <kbd>COPY</kbd> command (if you are on Windows, use an input directory such as <kbd>c:\temp</kbd> instead of <kbd>/tmp</kbd>) as follows:</li>
</ol>
<pre><strong>      postgis_cookbook=&gt; COPY chp01.firenews (</strong><br/><strong>        x, y, place, size, update, startdate, </strong><br/><strong>        enddate, title, url</strong><br/><strong>      ) FROM '/tmp/firenews.csv' WITH CSV HEADER;</strong></pre>
<div class="packt_tip">Make sure that the <kbd>firenews.csv</kbd> file is in a location accessible from the PostgreSQL process user. For example, in Linux, copy the file to the <kbd>/tmp</kbd> directory.<br/>
If you are on Windows, you most likely will need to set the encoding to UTF-8 before copying: <kbd>postgis_cookbook=# set client_encoding to 'UTF-8'</kbd>; and remember to set the full path, <kbd>'c:\\tmp\firenews.csv'</kbd>.</div>
<ol start="4">
<li>Check all of the records have been imported from the CSV file to the PostgreSQL table:</li>
</ol>
<pre><strong>      postgis_cookbook=&gt; SELECT COUNT(*) FROM chp01.firenews;</strong> </pre>
<p style="padding-left: 60px">The output of the preceding command is as follows:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/aef84fb3-8a9b-4fde-a923-59e038340642.png" style="width:35.50em;height:14.50em;"/></div>
<ol start="5">
<li>Check a record related to this new table is in the PostGIS <kbd>geometry_columns</kbd> metadata view:</li>
</ol>
<pre><strong>     postgis_cookbook=# SELECT f_table_name, </strong><br/><strong>     f_geometry_column, coord_dimension, srid, type </strong><br/><strong>     FROM geometry_columns where f_table_name = 'firenews';</strong></pre>
<p style="padding-left: 60px">The output of the preceding command is as follows:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/87588446-a973-4ce2-bd0b-c5ed1940467b.png" style="width:40.25em;height:12.33em;"/></div>
<div class="packt_tip"><span>Before PostGIS 2.0, you had to create a table containing spatial data in two distinct steps; in fact, the </span><kbd>geometry_columns</kbd><span> view was a table that needed to be manually updated. For that purpose, you had to use the </span><kbd>AddGeometryColumn</kbd><span><span> function to create the column. For example, this is for this recipe:<br/></span></span><kbd>postgis_cookbook=&gt; CREATE TABLE chp01.firenews(</kbd><br/>
<kbd>x float8,</kbd><br/>
<kbd>y float8,</kbd><br/>
<kbd>place varchar(100),</kbd><br/>
<kbd>size float8,</kbd><br/>
<kbd>update date,</kbd><br/>
<kbd>startdate date,</kbd><br/>
<kbd>enddate date,</kbd><br/>
<kbd>title varchar(255),</kbd><br/>
<kbd>url varchar(255))</kbd><br/>
<kbd>WITHOUT OIDS;postgis_cookbook=&gt; SELECT AddGeometryColumn('chp01', 'firenews', 'the_geom', 4326, 'POINT', 2);</kbd><br/>
<kbd>chp01.firenews.the_geom SRID:4326 TYPE:POINT DIMS:2</kbd><strong><br/></strong>
<p><span>In PostGIS 2.0, you can still use the </span><kbd>AddGeometryColumn</kbd><span> function if you wish; however, you need to set its </span><kbd>use_typmod</kbd><span> parameter to </span><kbd>false</kbd><span>.</span></p>
</div>
<ol start="6">
<li>Now, import the points in the geometric column using the <kbd>ST_MakePoint</kbd> or <kbd>ST_PointFromText</kbd> functions (use one of the following two update commands):</li>
</ol>
<pre><strong>      postgis_cookbook=&gt; UPDATE chp01.firenews </strong><br/><strong>      SET the_geom = ST_SetSRID(ST_MakePoint(x,y), 4326); 
      postgis_cookbook=&gt; UPDATE chp01.firenews </strong><br/><strong>      SET the_geom = ST_PointFromText('POINT(' || x || ' ' || y || ')',<br/>                                      4326);</strong> </pre>
<ol start="7">
<li>Check how the geometry field has been updated in some records from the table:</li>
</ol>
<pre><strong>      postgis_cookbook=# SELECT place, ST_AsText(the_geom) AS wkt_geom </strong><br/><strong>      FROM chp01.firenews ORDER BY place LIMIT 5;</strong> </pre>
<p style="padding-left: 60px">The output of the preceding comment is as follows:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/1aecf1e2-71eb-4345-bb45-b367758842ce.png" style="width:48.42em;height:14.08em;"/></div>
<ol start="8">
<li>Finally, create a spatial index for the geometric column of the table:</li>
</ol>
<pre><strong>      postgis_cookbook=&gt; CREATE INDEX idx_firenews_geom</strong><br/><strong>      ON chp01.firenews USING GIST (the_geom);</strong> </pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>This recipe showed you how to load nonspatial tabular data (in CSV format) in PostGIS using the <kbd>COPY</kbd> PostgreSQL command.</p>
<p>After creating the table and copying the CSV file rows to the PostgreSQL table, you updated the geometric column using one of the geometry constructor functions that PostGIS provides (<kbd>ST_MakePoint</kbd> and <kbd>ST_PointFromText</kbd> for bi-dimensional points).</p>
<p class="mce-root">These geometry constructors (in this case, <kbd>ST_MakePoint</kbd> and <kbd>ST_PointFromText</kbd>) must always provide the <strong>spatial reference system identifier</strong> (<strong>SRID</strong>) together with the point coordinates to define the point geometry.</p>
<p>Each geometric field added in any table in the database is tracked with a record in the <kbd>geometry_columns</kbd> PostGIS metadata view. In the previous PostGIS version (&lt; 2.0), the <kbd>geometry_fields</kbd> view was a table and needed to be manually updated, possibly with the convenient <kbd>AddGeometryColumn</kbd> function.</p>
<p>For the same reason, to maintain the updated <kbd>geometry_columns</kbd> view when dropping a geometry column or removing a spatial table in the previous PostGIS versions, there were the <kbd>DropGeometryColumn</kbd> and <kbd>DropGeometryTable</kbd> functions. With PostGIS 2.0 and newer, you don't need to use these functions any more, but you can safely remove the column or the table with the standard <kbd>ALTER TABLE</kbd>, <kbd>DROP COLUMN</kbd>, and <kbd>DROP TABLE</kbd> SQL commands.</p>
<p>In the last step of the recipe, you have created a spatial index on the table to improve performance. Please be aware that as in the case of alphanumerical database fields, indexes improve performances only when reading data using the <kbd>SELECT</kbd> command. In this case, you are making a number of updates on the table (<kbd>INSERT</kbd>, <kbd>UPDATE</kbd>, and <kbd>DELETE</kbd>); depending on the scenario, it could be less time consuming to drop and recreate the index after the updates.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Importing nonspatial tabular data (CSV) using GDAL</h1>
                </header>
            
            <article>
                
<p class="mce-root">As an alternative approach to the previous recipe, you will import a CSV file to PostGIS using the <kbd>ogr2ogr</kbd> GDAL command and the <strong>GDAL OGR virtual format</strong>. The <strong>Geospatial Data Abstraction Library</strong> (<strong>GDAL</strong>) is a translator library for raster geospatial data formats. OGR is the related library that provides similar capabilities for vector data formats.</p>
<p>This time, as an extra step, you will import only a part of the features in the file and you will reproject them to a different spatial reference system.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>You will import the <kbd>Global_24h.csv</kbd> file to the PostGIS database from NASA's <strong>Earth Observing System Data and Information System</strong> (<strong>EOSDIS</strong>).</p>
<p>You can copy the file from the dataset directory of the book for this chapter.</p>
<p>This file represents the active hotspots in the world detected by the <strong>Moderate Resolution Imaging Spectroradiometer</strong> (<strong>MODIS</strong>) satellites in the last 24 hours. For each row, there are the coordinates of the hotspot (latitude, longitude) in decimal degrees (in the WGS 84 spatial reference system, SRID = 4326), and a series of useful fields such as the <kbd>acquisition date</kbd>, <kbd>acquisition time</kbd>, and <kbd>satellite type</kbd>, just to name a few.</p>
<p>You will import only the active fire data scanned by the satellite type marked as <em>T</em> (Terra MODIS), and you will project it using the <strong>Spherical Mercator</strong> projection coordinate system (<kbd>EPSG:3857</kbd>; it is sometimes marked as <kbd>EPSG:900913</kbd>, where the number 900913 represents Google in 1337 speak, as it was first widely used by Google Maps).</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>The steps you need to follow to complete this recipe are as follows:</p>
<ol>
<li>Analyze the structure of the <kbd>Global_24h.csv</kbd> file (in Windows, open the CSV file with an editor such as Notepad):</li>
</ol>
<pre><strong>      $ cd ~/postgis_cookbook/data/chp01/<br/></strong><strong>      $ head -n 5 Global_24h.csv</strong></pre>
<p style="padding-left: 60px">The output of the preceding command is as follows:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/5b9c0310-2d2d-4cdd-b7f8-09cb14296bec.png" style="width:53.08em;height:10.33em;"/></div>
<ol start="2">
<li>Create a GDAL virtual data source composed of just one layer derived from the <kbd>Global_24h.csv</kbd> file. To do so, create a text file named <kbd>global_24h.vrt</kbd> in the same directory where the CSV file is and edit it as follows:</li>
</ol>
<pre>       &lt;OGRVRTDataSource&gt; 
         &lt;OGRVRTLayer name="Global_24h"&gt; 
         &lt;SrcDataSource&gt;Global_24h.csv&lt;/SrcDataSource&gt; 
         &lt;GeometryType&gt;wkbPoint&lt;/GeometryType&gt; 
         &lt;LayerSRS&gt;EPSG:4326&lt;/LayerSRS&gt; 
           &lt;GeometryField encoding="PointFromColumns"<br/>            x="longitude" y="latitude"/&gt; 
         &lt;/OGRVRTLayer&gt; 
       &lt;/OGRVRTDataSource&gt;</pre>
<ol start="3">
<li>With the <kbd>ogrinfo</kbd> command, check if the virtual layer is correctly recognized by GDAL. For example, analyze the schema of the layer and the first of its features (<kbd>fid</kbd>=<kbd>1</kbd>):</li>
</ol>
<pre><strong>      $ ogrinfo global_24h.vrt Global_24h -fid 1</strong> </pre>
<p style="padding-left: 60px">The output of the preceding command is as follows:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/00e0d0c1-ae17-4672-9633-0123d5c329a0.png" style="width:38.92em;height:41.00em;"/></div>
<p style="padding-left: 60px">You can also try to open the virtual layer with a desktop GIS supporting a GDAL/OGR virtual driver such as <strong>Quantum GIS</strong> (<strong>QGIS</strong>). In the following screenshot, the <kbd>Global_24h</kbd> layer is displayed together with the shapefile of the countries that you can find in the dataset directory of the book:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-184 image-border" src="assets/98686468-75de-4e25-a5dc-493c63cf78e1.png" style="width:135.67em;height:70.67em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">The global_24h dataset over the countries layers and information of the selected features</div>
<ol start="4">
<li>Now, export the virtual layer as a new table in PostGIS using the <kbd>ogr2ogr</kbd> GDAL/OGR command (in order for this command to become available, you need to add the GDAL installation folder to the <kbd>PATH</kbd> variable of your OS). You need to use the <kbd>-f</kbd> option to specify the output format, the <kbd>-t_srs</kbd> option to project the points to the <kbd>EPSG:3857</kbd> spatial reference, the <kbd>-where</kbd> option to load only the records from the MODIS Terra satellite type, and the <kbd>-lco</kbd> layer creation option to provide the schema where you want to store the table:</li>
</ol>
<pre><strong>      $ ogr2ogr -f PostgreSQL -t_srs EPSG:3857</strong><br/><strong>      PG:"dbname='postgis_cookbook' user='me' password='mypassword'"</strong><br/><strong>      -lco SCHEMA=chp01 global_24h.vrt -where "satellite='T'" </strong><br/><strong>      -lco GEOMETRY_NAME=the_geom</strong></pre>
<ol start="5">
<li>Check how the <kbd>ogr2ogr</kbd> command created the table, as shown in the following command:</li>
</ol>
<pre><strong>      $ pg_dump -t chp01.global_24h --schema-only -U me postgis_cookbook 
 
      CREATE TABLE global_24h ( 
        ogc_fid integer NOT NULL, 
        latitude character varying, 
        longitude character varying, 
        brightness character varying, 
        scan character varying, 
        track character varying, 
        acq_date character varying, 
        acq_time character varying, 
        satellite character varying, 
        confidence character varying, 
        version character varying, 
        bright_t31 character varying, 
        frp character varying, 
        the_geom public.geometry(Point,3857) 
      );</strong></pre>
<ol start="6">
<li>Now, check the record that should appear in the <kbd>geometry_columns</kbd> metadata view:</li>
</ol>
<pre><strong>      postgis_cookbook=# SELECT f_geometry_column, coord_dimension,</strong><br/><strong>      srid, type FROM geometry_columns </strong><br/><strong>      WHERE f_table_name = 'global_24h';</strong></pre>
<p style="padding-left: 60px">The output of the preceding command is as follows:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/f81757a1-c90d-491b-84f6-9ac569c336f8.png" style="width:43.50em;height:12.25em;"/></div>
<ol start="7">
<li>Check how many records have been imported in the table:</li>
</ol>
<pre><strong>      postgis_cookbook=# SELECT count(*) FROM chp01.global_24h;</strong> </pre>
<p style="padding-left: 60px">The output of the preceding command is as follows:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/62e12896-962c-4db3-b94a-3b6518d2ceea.png" style="width:46.17em;height:10.50em;"/></div>
<ol start="8">
<li>Note how the coordinates have been projected from <kbd>EPSG:4326</kbd> to <kbd>EPSG:3857</kbd>:</li>
</ol>
<pre><strong>      postgis_cookbook=# SELECT ST_AsEWKT(the_geom)<br/>      FROM chp01.global_24h LIMIT 1;</strong></pre>
<p style="padding-left: 60px">The output of the preceding command is as follows:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/fede3455-5d4b-4c90-ac95-51fe7839c6aa.png" style="width:45.17em;height:10.58em;"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>As mentioned in the GDAL documentation:</p>
<div class="packt_quote">"OGR Virtual Format is a driver that transforms features read from other drivers based on criteria specified in an XML control file."</div>
<p>GDAL supports the reading and writing of nonspatial tabular data stored as a CSV file, but we need to use a virtual format to derive the geometry of the layers from attribute columns in the CSV file (the longitude and latitude coordinates for each point). For this purpose, you need to at least specify in the driver the path to the CSV file (the <kbd>SrcDataSource</kbd> element), the geometry type (the <kbd>GeometryType</kbd> element), the spatial reference definition for the layer (the <kbd>LayerSRS</kbd> element), and the way the driver can derive the geometric information (the <kbd>GeometryField</kbd> element).</p>
<p>There are many other options and reasons for using OGR virtual formats; if you are interested in developing a better understanding, please refer to the GDAL documentation available at <a href="http://www.gdal.org/drv_vrt.html">http://www.gdal.org/drv_vrt.html</a>.</p>
<p>After a virtual format is correctly created, the original flat nonspatial dataset is spatially supported by GDAL and software-based on GDAL. This is the reason why we can manipulate these files with GDAL commands such as <kbd>ogrinfo</kbd> and <kbd>ogr2ogr</kbd>, and with desktop GIS software such as QGIS.</p>
<p>Once we have verified that GDAL can correctly read the features from the virtual driver, we can easily import them in PostGIS using the popular <kbd>ogr2ogr</kbd> command-line utility. The <kbd>ogr2ogr</kbd> command has a plethora of options, so refer to its documentation at <a href="http://www.gdal.org/ogr2ogr.html"><span class="URLPACKT">http://www.gdal.org/ogr2ogr.html</span></a> for a more in-depth discussion.</p>
<p>In this recipe, you have just seen some of these options, such as:</p>
<ul>
<li><kbd>-where</kbd>: It is used to export just a selection of the original feature class</li>
<li><kbd>-t_srs</kbd>: It is used to reproject the data to a different spatial reference system</li>
<li><kbd>-lco layer creation</kbd>: It is used to provide the schema where we would want to store the table (without it, the new spatial table would be created in the <kbd>public</kbd> schema) and the name of the geometry field in the output layer</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Importing shapefiles with shp2pgsql</h1>
                </header>
            
            <article>
                
<p>If you need to import a shapefile in PostGIS, you have at least a couple of options such as the <kbd>ogr2ogr</kbd> GDAL command, as you have seen previously, or the <kbd>shp2pgsql</kbd> PostGIS command.</p>
<p>In this recipe, you will load a shapefile in the database using the <kbd>shp2pgsql</kbd> command, analyze it with the <kbd>ogrinfo</kbd> command, and display it in QGIS desktop software.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>The steps you need to follow to complete this recipe are as follows:</p>
<ol>
<li>Create a shapefile from the virtual driver created in the previous recipe using the <kbd>ogr2ogr</kbd> command (note that in this case, you do not need to specify the <kbd>-f</kbd> option as the shapefile is the default output format for the <kbd>ogr2ogr</kbd> command):</li>
</ol>
<pre><strong>      $ ogr2ogr global_24h.shp global_24h.vrt</strong></pre>
<ol start="2">
<li>Generate the SQL dump file for the shapefile using the <kbd>shp2pgsql</kbd> command. You are going to use the <kbd>-G</kbd> option to generate a PostGIS spatial table using the geography type, and the <kbd>-I</kbd> option to generate the spatial index on the geometric column:</li>
</ol>
<pre><strong>      $ shp2pgsql -G -I global_24h.shp<br/>        chp01.global_24h_geographic &gt; global_24h.sql</strong></pre>
<ol start="3">
<li>Analyze the <kbd>global_24h.sql</kbd> file (in Windows, use a text editor such as Notepad):</li>
</ol>
<pre><strong>      $ head -n 20 global_24h.sql</strong></pre>
<p style="padding-left: 60px">The output of the preceding command is as follows:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/6b8087cd-9b20-4f99-94af-8a2f94a515db.png" style="width:42.42em;height:30.00em;"/></div>
<ol start="4">
<li>Run the <kbd>global_24h.sql</kbd> file in PostgreSQL:</li>
</ol>
<pre><strong>      $ psql -U me -d postgis_cookbook -f global_24h.sql</strong></pre>
<div class="packt_tip"><span>If you are on Linux, you may concatenate the commands from the last two steps in a single line in the following manner:<br/>
<kbd>$ shp2pgsql -G -I global_24h.shp chp01.global_24h_geographic | psql -U me -d postgis_cookbook</kbd><br/></span></div>
<ol start="5">
<li>Check if the metadata record is visible in the <kbd>geography_columns</kbd> view (and not in the <kbd>geometry_columns</kbd> view, as with the <kbd>-G</kbd> option of the <kbd>shp2pgsql</kbd> command, we have opted for a <kbd>geography</kbd> type):</li>
</ol>
<pre><strong>      postgis_cookbook=# SELECT f_geography_column,   coord_dimension,<br/>      srid, type FROM geography_columns   <br/>      WHERE f_table_name = 'global_24h_geographic';</strong></pre>
<p style="padding-left: 60px">The output of the preceding command is as follows:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/b1408e1d-7782-4d94-8d59-0eb20e7509c9.png" style="width:47.08em;height:10.92em;"/></div>
<ol start="6">
<li>Analyze the new PostGIS table with <kbd>ogrinfo</kbd> (use the <kbd>-fid</kbd> option just to display one record from the table):</li>
</ol>
<pre><strong>      $ ogrinfo PG:"dbname='postgis_cookbook' user='me'<br/>        password='mypassword'" chp01.global_24h_geographic -fid 1</strong></pre>
<p style="padding-left: 60px">The output of the preceding command is as follows:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/0f94ead1-6d7c-466e-a58c-6382b11019d1.png" style="width:29.83em;height:30.50em;"/></div>
<p>Now, open QGIS and try to add the new layer to the map. Navigate to <span class="packt_screen">Layer</span> | <span class="packt_screen">Add Layer</span> | <span class="packt_screen">Add PostGIS layers</span> and provide the connection information, and then add the layer to the map as shown in the following screenshot:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-185 image-border" src="assets/12b21dbe-4c65-4092-abba-7536961a2447.png" style="width:49.33em;height:22.75em;"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>The PostGIS command, <kbd>shp2pgsql</kbd>, allows the user to import a shapefile in the PostGIS database. Basically, it generates a PostgreSQL dump file that can be used to load data by running it from within PostgreSQL.</p>
<p>The SQL file will be generally composed of the following sections:</p>
<ul>
<li>The <kbd>CREATE TABLE</kbd> section (if the <kbd>-a</kbd> option is not selected, in which case, the table should already exist in the database)</li>
<li>The <kbd>INSERT INTO</kbd> section (one <kbd>INSERT</kbd> statement for each feature to be imported from the shapefile)</li>
<li>The <kbd>CREATE INDEX</kbd> section (if the <kbd>-I</kbd> option is selected)</li>
</ul>
<div class="packt_infobox">Unlike <kbd>ogr2ogr</kbd>, there is no way to make spatial or attribute selections (<kbd>-spat</kbd>, <kbd>-where ogr2ogr</kbd> options) for features in the shapefile to import.<br/>
On the other hand, with the <kbd>shp2pgsql</kbd> command, it is possible to import the <em>m</em> coordinate of the features too (<kbd>ogr2ogr</kbd> only supports <em>x</em>, <em>y</em>, and <em>z</em> at the time of writing).</div>
<p>To get a complete list of the <kbd>shp2pgsql</kbd> command options and their meanings, just type the command name in the shell (or in the command prompt, if you are on Windows) and check the output.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">There's more...</h1>
                </header>
            
            <article>
                
<p>There are GUI tools to manage data in and out of PostGIS, generally integrated into GIS desktop software such as QGIS. In the last chapter of this book, we will take a look at the most popular one.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Importing and exporting data with the ogr2ogr GDAL command</h1>
                </header>
            
            <article>
                
<p>In this recipe, you will use the popular <kbd>ogr2ogr</kbd> GDAL command for importing and exporting vector data from PostGIS.</p>
<p>Firstly, you will import a shapefile in PostGIS using the most significant options of the <kbd>ogr2ogr</kbd> command. Then, still using <kbd>ogr2ogr</kbd>, you will export the results of a spatial query performed in PostGIS to a couple of GDAL-supported vector formats.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>The steps you need to follow to complete this recipe are as follows:</p>
<ol>
<li>Unzip the <kbd>wborders.zip</kbd> archive to your working directory. You can find this archive in the book's dataset.</li>
<li>Import the world countries shapefile (<kbd>wborders.shp</kbd>) in PostGIS using the <kbd>ogr2ogr</kbd> command. Using some of the options from <kbd>ogr2ogr</kbd>, you will import only the features from <kbd>SUBREGION=2</kbd> (Africa), and the <kbd>ISO2</kbd> and <kbd>NAME</kbd> attributes, and rename the feature class to <kbd>africa_countries</kbd>:</li>
</ol>
<pre><strong>      $ ogr2ogr -f PostgreSQL -sql "SELECT ISO2, <br/>      NAME AS country_name FROM wborders WHERE REGION=2" -nlt <br/>      MULTIPOLYGON PG:"dbname='postgis_cookbook' user='me'<br/>      password='mypassword'" -nln africa_countries <br/>      -lco SCHEMA=chp01 -lco GEOMETRY_NAME=the_geom wborders.shp</strong></pre>
<ol start="3">
<li>Check if the shapefile was correctly imported in PostGIS, querying the spatial table in the database or displaying it in a desktop GIS.</li>
<li>Query PostGIS to get a list of the 100 active hotspots with the highest brightness temperature (the <kbd>bright_t31</kbd> field) from the <kbd>global_24h</kbd> table created in the previous recipe:</li>
</ol>
<pre><strong>      postgis_cookbook=# SELECT</strong><strong>ST_AsText(the_geom) AS the_geom, bright_t31<br/>      </strong><strong>FROM chp01.global_24h<br/>      </strong><strong>ORDER BY bright_t31 DESC LIMIT 100;</strong></pre>
<p style="padding-left: 60px">The output of the preceding command is as follows:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/16ba1008-1b28-4071-bd00-af4bcd4d3893.png" style="width:31.42em;height:32.83em;"/></div>
<ol start="5">
<li>You want to figure out in which African countries these hotspots are located. For this purpose, you can do a spatial join with the <kbd>africa_countries</kbd> table produced in the previous step:</li>
</ol>
<pre><strong>      postgis_cookbook=# SELECT </strong><strong>ST_AsText(f.the_geom) <br/>      AS the_geom, f.bright_t31, ac.iso2, ac.country_name<br/></strong><strong>      FROM chp01.global_24h as f<br/></strong><strong>      JOIN chp01.africa_countries as ac<br/></strong><strong>      ON ST_Contains(ac.the_geom, ST_Transform(f.the_geom, 4326))<br/></strong><strong>      ORDER BY f.bright_t31 DESC</strong><strong>LIMIT 100;</strong></pre>
<p style="padding-left: 60px">The output of the preceding command is as follows:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/f23bd99b-8a4a-483b-ae57-9766b62728b3.png" style="width:46.92em;height:32.83em;"/></div>
<p style="padding-left: 60px">You will now export the result of this query to a vector format supported by GDAL, such as GeoJSON, in the WGS 84 spatial reference using <kbd>ogr2ogr</kbd>:</p>
<pre><strong>      $ ogr2ogr -f GeoJSON -t_srs EPSG:4326 warmest_hs.geojson<br/>      PG:"dbname='postgis_cookbook' user='me' password='mypassword'" -sql "<br/>      SELECT f.the_geom as the_geom, f.bright_t31, <br/>             ac.iso2, ac.country_name<br/>      FROM chp01.global_24h as f JOIN chp01.africa_countries as ac<br/>      ON ST_Contains(ac.the_geom, ST_Transform(f.the_geom, 4326))<br/>      ORDER BY f.bright_t31 DESC LIMIT 100"</strong></pre>
<ol start="6">
<li>Open the GeoJSON file and inspect it with your favorite desktop GIS. The following screenshot shows you how it looks with QGIS:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-515 image-border" src="assets/9efd9122-f509-4a0d-841e-a4227e8ecc38.png" style="width:79.00em;height:53.75em;"/><br/></div>
<ol start="7">
<li>Export the previous query to a CSV file. In this case, you have to indicate how the geometric information must be stored in the file; this is done using the <kbd>-lco GEOMETRY</kbd> option:</li>
</ol>
<pre><strong>      $ ogr2ogr -t_srs EPSG:4326 -f CSV -lco GEOMETRY=AS_XY <br/>      -lco SEPARATOR=TAB warmest_hs.csv PG:"dbname='postgis_cookbook' <br/>       user='me' password='mypassword'" -sql "<br/>       SELECT f.the_geom, f.bright_t31,<br/>         ac.iso2, ac.country_name <br/>       FROM chp01.global_24h as f JOIN chp01.africa_countries as ac <br/>       ON ST_Contains(ac.the_geom, ST_Transform(f.the_geom, 4326)) <br/>       ORDER BY f.bright_t31 DESC  LIMIT 100"</strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>GDAL is an open source library that comes together with several command-line utilities, which let the user translate and process raster and vector geodatasets into a plethora of formats. In the case of vector datasets, there is a GDAL sublibrary for managing vector datasets named OGR (therefore, when talking about vector datasets in the context of GDAL, we can also use the expression <strong>OGR dataset</strong>).</p>
<p>When you are working with an OGR dataset, two of the most popular OGR commands are <kbd>ogrinfo</kbd>, which lists many kinds of information from an OGR dataset, and <kbd>ogr2ogr</kbd>, which converts the OGR dataset from one format to another.</p>
<p>It is possible to retrieve a list of the supported OGR vector formats using the <kbd>-formats</kbd> option on any OGR commands, for example, with <kbd>ogr2ogr</kbd>:</p>
<pre><strong>$ ogr2ogr --formats</strong></pre>
<p>The output of the preceding command is as follows:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/83ffb756-1e96-4428-ae89-e4abd06c9a13.png" style="width:40.83em;height:34.92em;"/></div>
<p>Note that some formats are read-only, while others are read/write.</p>
<p>PostGIS is one of the supported read/write OGR formats, so it is possible to use the OGR API or any OGR commands (such as <kbd>ogrinfo</kbd> and <kbd>ogr2ogr</kbd>) to manipulate its datasets.</p>
<p>The <kbd>ogr2ogr</kbd> command has many options and parameters; in this recipe, you have seen some of the most notable ones such as <kbd>-f</kbd> to define the output format, <kbd>-t_srs</kbd> to reproject/transform the dataset, and <kbd>-sql</kbd> to define an (eventually spatial) query in the input OGR dataset.</p>
<p>When using <kbd>ogrinfo</kbd> and <kbd>ogr2ogr</kbd> together with the desired option and parameters, you have to define the datasets. When specifying a PostGIS dataset, you need a connection string that is defined as follows:</p>
<pre><strong>PG:"dbname='postgis_cookbook' user='me' password='mypassword'"</strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<p>You can find more information about the <kbd>ogrinfo</kbd> and <kbd>ogr2ogr</kbd> commands on the GDAL website available at <a href="http://www.gdal.org"><span class="URLPACKT">http://www.gdal.org</span></a>.</p>
<p>If you need more information about the PostGIS driver, you should check its related documentation page available at <a href="http://www.gdal.org/drv_pg.html">http://www.gdal.org/drv_pg.html</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Handling batch importing and exporting of datasets</h1>
                </header>
            
            <article>
                
<p>In many GIS workflows, there is a typical scenario where subsets of a PostGIS table must be deployed to external users in a filesystem format (most typically, shapefiles or a spatialite database). Often, there is also the reverse process, where datasets received from different users have to be uploaded to the PostGIS database.</p>
<p>In this recipe, we will simulate both of these data flows. You will first create the data flow for processing the shapefiles out of PostGIS, and then the reverse data flow for uploading the shapefiles.</p>
<p>You will do it using the power of bash scripting and the <kbd>ogr2ogr</kbd> command.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>If you didn't follow all the other recipes, be sure to import the hotspots (<kbd>Global_24h.csv</kbd>) and the countries dataset (<kbd>countries.shp</kbd>) in PostGIS. The following is how to do it with <kbd>ogr2ogr</kbd> (you should import both the datasets in their original SRID, 4326, to make spatial operations faster):</p>
<ol>
<li>Import in PostGIS the <kbd>Global_24h.csv</kbd> file, using the <kbd>global_24.vrt</kbd> virtual driver you created in a previous recipe:</li>
</ol>
<pre><strong>      $ ogr2ogr -f PostgreSQL PG:"dbname='postgis_cookbook' <br/>      user='me' password='mypassword'" -lco SCHEMA=chp01 global_24h.vrt <br/>      -lco OVERWRITE=YES -lco GEOMETRY_NAME=the_geom -nln hotspots</strong></pre>
<ol start="2">
<li>Import the countries shapefile using <kbd>ogr2ogr</kbd>:</li>
</ol>
<pre><strong>      $ ogr2ogr -f PostgreSQL -sql "SELECT ISO2, NAME AS country_name <br/>      FROM wborders" -nlt MULTIPOLYGON PG:"dbname='postgis_cookbook' <br/>      user='me' password='mypassword'" -nln countries <br/>      -lco SCHEMA=chp01 -lco OVERWRITE=YES <br/>      -lco GEOMETRY_NAME=the_geom wborders.shp</strong></pre>
<div class="packt_infobox"><span>If you already imported the hotspots dataset using the 3857 SRID, you can use the PostGIS 2.0 method that allows the user to modify the geometry type column of an existing spatial table. You can update the SRID definition for the hotspots table in this way thanks to the support of </span><kbd>typmod</kbd><span><span> on geometry objects:<br/></span></span><kbd>postgis_cookbook=# ALTER TABLE chp01.hotspots</kbd><br/>
<kbd>ALTER COLUMN the_geom</kbd><br/>
<kbd>SET DATA TYPE geometry(Point, 4326)</kbd><br/>
<kbd>USING ST_Transform(the_geom, 4326);</kbd></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>The steps you need to follow to complete this recipe are as follows:</p>
<ol>
<li>Check how many hotspots there are for each distinct country by using the following query:</li>
</ol>
<pre><strong>      postgis_cookbook=&gt; SELECT c.country_name, MIN(c.iso2) <br/>      as iso2, count(*) as hs_count </strong><strong>FROM chp01.hotspots as hs <br/>      JOIN chp01.countries as c ON ST_Contains(c.the_geom, hs.the_geom) <br/>      GROUP BY c.country_name ORDER BY c.country_name;</strong></pre>
<p style="padding-left: 60px">The output of the preceding command is as follows:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/731ac673-6fc3-445c-a961-5bde1a65326d.png" style="width:42.00em;height:33.67em;"/></div>
<ol start="2">
<li>Using the same query, generate a CSV file using the PostgreSQL <kbd>COPY</kbd> command or the <kbd>ogr2ogr</kbd> command (in the first case, make sure that the Postgre service user has full write permission to the output directory). If you are following the <kbd>COPY</kbd> approach and using Windows, be sure to replace <kbd>/tmp/hs_countries.csv</kbd> with a different path:</li>
</ol>
<pre><strong>      $ ogr2ogr -f CSV hs_countries.csv <br/>      PG:"dbname='postgis_cookbook' user='me' password='mypassword'"<br/>      -lco SCHEMA=chp01 -sql "SELECT c.country_name, MIN(c.iso2) as iso2, <br/>      count(*) as hs_count FROM chp01.hotspots as hs <br/>      JOIN chp01.countries as c ON ST_Contains(c.the_geom, hs.the_geom) <br/>      GROUP BY c.country_name ORDER BY c.country_name"<br/></strong><strong>      postgis_cookbook=&gt; COPY (SELECT c.country_name, MIN(c.iso2) as iso2, <br/>      count(*) as hs_count</strong><strong>  FROM chp01.hotspots as hs</strong><strong>  <br/>      JOIN chp01.countries as c</strong><strong>  ON ST_Contains(c.the_geom, hs.the_geom)</strong><strong>  <br/>      GROUP BY c.country_name</strong><strong>  ORDER BY c.country_name) <br/>      TO '/tmp/hs_countries.csv' WITH CSV HEADER;</strong></pre>
<ol start="3">
<li>If you are using Windows, go to step 5. With Linux, create a bash script named <kbd>export_shapefiles.sh</kbd> that iterates each record (country) in the <kbd>hs_countries.csv</kbd> file and generates a shapefile with the corresponding hotspots exported from PostGIS for that country:</li>
</ol>
<pre>        #!/bin/bash 
        while IFS="," read country iso2 hs_count 
        do 
          echo "Generating shapefile $iso2.shp for country <br/>          $country ($iso2) containing $hs_count features." 
          ogr2ogr out_shapefiles/$iso2.shp<br/>          PG:"dbname='postgis_cookbook' user='me' password='mypassword'"<br/>          -lco SCHEMA=chp01 -sql "SELECT ST_Transform(hs.the_geom, 4326), <br/>          hs.acq_date, hs.acq_time, hs.bright_t31 <br/>          FROM chp01.hotspots as hs JOIN chp01.countries as c <br/>          ON ST_Contains(c.the_geom, ST_Transform(hs.the_geom, 4326))  
          WHERE c.iso2 = '$iso2'" done &lt; hs_countries.csv </pre>
<ol start="4">
<li>Give execution permissions to the <kbd>bash</kbd> file, and then run it after creating an output directory (<kbd>out_shapefiles</kbd>) for the shapefiles that will be generated by the script. Then, go to <em>step 7</em>:</li>
</ol>
<pre><strong>      chmod 775 export_shapefiles.sh<br/></strong><strong>      mkdir out_shapefiles<br/></strong><strong>      $ ./export_shapefiles.sh<br/></strong><strong>      Generating shapefile AL.shp for country <br/>        Albania (AL) containing 66 features.<br/></strong><strong>      Generating shapefile DZ.shp for country <br/>        Algeria (DZ) containing 361 features.<br/>      </strong><strong>...<br/></strong><strong>      Generating shapefile ZM.shp for country <br/>        Zambia (ZM) containing 1575 features.<br/></strong><strong>      Generating shapefile ZW.shp for country <br/>        Zimbabwe (ZW) containing 179 features.</strong></pre>
<div class="packt_tip"><span>If you get the output</span> <kbd>ERROR: function getsrid(geometry) does not exist LINE 1: SELECT getsrid("the_geom") FROM (SELECT,...</kbd><span><span>, you will need to load legacy support in PostGIS, for example, in a Debian Linux box:<br/></span></span><kbd>psql -d postgis_cookbook -f /usr/share/postgresql/9.1/contrib/postgis-2.1/legacy.sql</kbd></div>
<ol start="5">
<li>If you are using Windows, create a batch file named <kbd>export_shapefiles.bat</kbd> that iterates each record (country) in the <kbd>hs_countries.csv</kbd> file and generates a shapefile with the corresponding hotspots exported from PostGIS for that country:</li>
</ol>
<pre>        @echo off 
        for /f "tokens=1-3 delims=, skip=1" %%a in (hs_countries.csv) do ( 
          echo "Generating shapefile %%b.shp for country %%a <br/>                (%%b) containing %%c features" 
          ogr2ogr .\out_shapefiles\%%b.shp <br/>          PG:"dbname='postgis_cookbook' user='me' password='mypassword'" <br/>          -lco SCHEMA=chp01 -sql "SELECT ST_Transform(hs.the_geom, 4326), <br/>          hs.acq_date, hs.acq_time, hs.bright_t31 <br/>          FROM chp01.hotspots as hs JOIN chp01.countries as c <br/>          ON ST_Contains(c.the_geom, ST_Transform(hs.the_geom, 4326)) <br/>          WHERE c.iso2 = '%%b'" 
        ) </pre>
<ol start="6">
<li>Run the batch file after creating an output directory (<kbd>out_shapefiles</kbd>) for the shapefiles that will be generated by the script:</li>
</ol>
<pre><strong>      &gt;mkdir out_shapefiles<br/></strong><strong>      &gt;export_shapefiles.bat<br/></strong><strong>      "Generating shapefile AL.shp for country <br/>       Albania (AL) containing 66 features"<br/></strong><strong>      "Generating shapefile DZ.shp for country <br/>       Algeria (DZ) containing 361 features"<br/></strong><strong>      ...<br/></strong><strong>      "Generating shapefile ZW.shp for country <br/>       Zimbabwe (ZW) containing 179 features"</strong></pre>
<ol start="7">
<li>Try to open a couple of these output shapefiles in your favorite desktop GIS. The following screenshot shows you how they look in QGIS:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="assets/db5464c0-eea0-4c62-aa2e-b73c1e0cb442.png" style="font-size: 1em;"/></div>
<ol start="8">
<li>Now, you will do the return trip, uploading all of the generated shapefiles to PostGIS. You will upload all of the features for each shapefile and include the upload datetime and the original shapefile name. First, create the following PostgreSQL table, where you will upload the shapefiles:</li>
</ol>
<pre><strong>      postgis_cookbook=# CREATE TABLE chp01.hs_uploaded<br/></strong><strong>      (<br/></strong><strong>        ogc_fid serial NOT NULL,<br/></strong><strong>        acq_date character varying(80),<br/></strong><strong>        acq_time character varying(80),<br/></strong><strong>        bright_t31 character varying(80),<br/></strong><strong>        iso2 character varying,<br/></strong><strong>        upload_datetime character varying,<br/></strong><strong>        shapefile character varying,<br/></strong><strong>        the_geom geometry(POINT, 4326),<br/></strong><strong>        CONSTRAINT hs_uploaded_pk PRIMARY KEY (ogc_fid)<br/></strong><strong>      );</strong></pre>
<ol start="9">
<li>If you are using Windows, go to step 12. With OS X, you will need to install <kbd>findutils</kbd> with <kbd>homebrew</kbd> and run the script for Linux:</li>
</ol>
<pre><strong>      $ brew install findutils</strong> </pre>
<ol start="10">
<li>With Linux, create another bash script named <kbd>import_shapefiles.sh</kbd>:</li>
</ol>
<pre>        #!/bin/bash 
        for f in `find out_shapefiles -name \*.shp -printf "%f\n"` 
        do 
          echo "Importing shapefile $f to chp01.hs_uploaded PostGIS<br/>            table..." #, ${f%.*}" 
          ogr2ogr -append -update  -f PostgreSQL<br/>          PG:"dbname='postgis_cookbook' user='me'<br/>          password='mypassword'" out_shapefiles/$f <br/>          -nln chp01.hs_uploaded -sql "SELECT acq_date, acq_time,<br/>          bright_t31, '${f%.*}' AS iso2, '`date`' AS upload_datetime,  <br/>         'out_shapefiles/$f' as shapefile FROM ${f%.*}" 
        done </pre>
<ol start="11">
<li>Assign the execution permission to the bash script and execute it:</li>
</ol>
<pre><strong>      $ chmod 775 import_shapefiles.sh<br/></strong><strong>      $ ./import_shapefiles.sh<br/></strong><strong>      Importing shapefile DO.shp to chp01.hs_uploaded PostGIS table<br/>      ...<br/></strong><strong>      Importing shapefile ID.shp to chp01.hs_uploaded PostGIS table<br/>      ...<br/></strong><strong>      Importing shapefile AR.shp to chp01.hs_uploaded PostGIS table<br/>      ...</strong><strong>...</strong></pre>
<p style="padding-left: 60px">Now, go to <em>step 14</em>.</p>
<ol start="12">
<li>If you are using Windows, create a batch script named <kbd>import_shapefiles.bat</kbd>:</li>
</ol>
<pre>        @echo off 
        for %%I in (out_shapefiles\*.shp*) do ( 
          echo Importing shapefile %%~nxI to chp01.hs_uploaded<br/>          PostGIS table... 
 
          ogr2ogr -append -update  -f PostgreSQL<br/>          PG:"dbname='postgis_cookbook' user='me'<br/>          password='password'" out_shapefiles/%%~nxI </pre>
<pre>          -nln chp01.hs_uploaded -sql "SELECT acq_date, acq_time, <br/>          bright_t31, '%%~nI' AS iso2, '%date%' AS upload_datetime, <br/>          'out_shapefiles/%%~nxI' as shapefile FROM %%~nI" 
        ) </pre>
<ol start="13">
<li>Run the batch script:</li>
</ol>
<pre><strong>      &gt;import_shapefiles.bat<br/></strong><strong>      Importing shapefile AL.shp to chp01.hs_uploaded PostGIS table...<br/></strong><strong>      Importing shapefile AO.shp to chp01.hs_uploaded PostGIS table...<br/></strong><strong>      Importing shapefile AR.shp to chp01.hs_uploaded PostGIS table...</strong><strong>...</strong></pre>
<ol start="14">
<li>Check some of the records that have been uploaded to the PostGIS table by using SQL:</li>
</ol>
<pre><strong>      postgis_cookbook=# SELECT upload_datetime,<br/>      shapefile, ST_AsText(wkb_geometry)<br/>      FROM chp01.hs_uploaded WHERE ISO2='AT';</strong> </pre>
<p style="padding-left: 60px">The output of the preceding command is as follows:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/9e2ff933-31c5-4df2-9504-b0cf1a1bd116.png" style="width:48.67em;height:17.58em;"/></div>
<ol start="15">
<li>Check the same query with <kbd>ogrinfo</kbd> as well:</li>
</ol>
<pre><strong>      $ ogrinfo PG:"dbname='postgis_cookbook' user='me'<br/>      password='mypassword'"<br/>      chp01.hs_uploaded -where "iso2='AT'"</strong></pre>
<p style="padding-left: 60px">The output of the preceding command is as follows:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/b40ad790-bac2-4b8a-b6b7-fa5c1b72fde0.png" style="width:24.58em;height:28.50em;"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>You could implement both the data flows (processing shapefiles out from PostGIS, and then into it again) thanks to the power of the <kbd>ogr2ogr</kbd> GDAL command.</p>
<p>You have been using this command in different forms and with the most important input parameters in other recipes, so you should now have a good understanding of it.</p>
<p>Here, it is worth mentioning the way OGR lets you export the information related to the current datetime and the original shapefile name to the PostGIS table. Inside the <kbd>import_shapefiles.sh</kbd> (Linux, OS X) or the <kbd>import_shapefiles.bat</kbd> (Windows) scripts, the core is the line with the <kbd>ogr2ogr</kbd> command (here is the Linux version):</p>
<pre><strong>ogr2ogr -append -update  -f PostgreSQL PG:"dbname='postgis_cookbook' user='me' password='mypassword'" out_shapefiles/$f -nln chp01.hs_uploaded -sql "SELECT acq_date, acq_time, bright_t31, '${f%.*}' AS iso2, '`date`' AS upload_datetime, 'out_shapefiles/$f' as shapefile FROM ${f%.*}"</strong> </pre>
<p>Thanks to the <kbd>-sql</kbd> option, you can specify the two additional fields, getting their values from the system date command and the filename that is being iterated from the script.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Exporting data to a shapefile with the pgsql2shp PostGIS command</h1>
                </header>
            
            <article>
                
<p>In this recipe, you will export a PostGIS table to a shapefile using the <kbd>pgsql2shp</kbd> command that is shipped with any PostGIS distribution.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>The steps you need to follow to complete this recipe are as follows:</p>
<ol>
<li>In case you still haven't done it, export the countries shapefile to PostGIS using the <kbd>ogr2ogr</kbd> or the <kbd>shp2pgsql</kbd> commands. The <kbd>shp2pgsql</kbd> approach is as shown:</li>
</ol>
<pre><strong>      $ shp2pgsql -I -d -s 4326 -W LATIN1 -g the_geom countries.shp<br/>      chp01.countries &gt; countries.sql<br/></strong><strong>      $ psql -U me -d postgis_cookbook -f countries.sql</strong></pre>
<ol start="2">
<li>The <kbd>ogr2ogr</kbd> approach is as follows:</li>
</ol>
<pre><strong>      $ ogr2ogr -f PostgreSQL PG:"dbname='postgis_cookbook' user='me'<br/>      password='mypassword'"<br/>      -lco SCHEMA=chp01 countries.shp -nlt MULTIPOLYGON -lco OVERWRITE=YES<br/>      -lco GEOMETRY_NAME=the_geom</strong></pre>
<ol start="3">
<li>Now, query PostGIS in order to get a list of countries grouped by the <kbd>subregion</kbd> field. For this purpose, you will merge the geometries for features having the same <kbd>subregion</kbd> code, using the <kbd>ST_Union</kbd> PostGIS geometric processing function:</li>
</ol>
<pre><strong>      postgis_cookbook=&gt; SELECT subregion,<br/>        ST_Union(the_geom) AS the_geom, SUM(pop2005) AS pop2005<br/>        FROM chp01.countries GROUP BY subregion;</strong></pre>
<ol start="4">
<li>Execute the <kbd>pgsql2shp</kbd> PostGIS command to export into a shapefile the result of the given query:</li>
</ol>
<pre><strong>      $ pgsql2shp -f subregions.shp -h localhost -u me -P mypassword<br/>      postgis_cookbook "SELECT MIN(subregion) AS subregion, <br/>      ST_Union(the_geom) AS the_geom, SUM(pop2005) AS pop2005 <br/>      FROM chp01.countries GROUP BY subregion;" 
 
      Initializing... 
      Done (postgis major version: 2). 
      Output shape: Polygon 
      Dumping: X [23 rows].</strong> </pre>
<ol start="5">
<li>Open the shapefile and inspect it with your favorite desktop GIS. This is how it looks in QGIS after applying a graduated classification symbology style based on the aggregated population for each subregion:</li>
</ol>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-187 image-border" src="assets/5411f57b-7013-4d2b-b24a-a46cc7c2ca74.png" style="width:95.92em;height:63.25em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">Visualization in QGIS of the classification of subregions based on population and information of the selected feature</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>You have exported the results of a spatial query to a shapefile using the <kbd>pgsql2shp</kbd> PostGIS command. The spatial query you have used aggregates fields using the <kbd>SUM</kbd> PostgreSQL function for summing country populations in the same subregion, and the <kbd>ST_Union</kbd> PostGIS function to aggregate the corresponding geometries as a geometric union.</p>
<p>The <kbd>pgsql2shp</kbd> command allows you to export PostGIS tables and queries to shapefiles. The options you need to specify are quite similar to the ones you use to connect to PostgreSQL with <kbd>psql</kbd>. To get a full list of these options, just type <kbd>pgsql2shp</kbd> in your command prompt and read the output.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Importing OpenStreetMap data with the osm2pgsql command</h1>
                </header>
            
            <article>
                
<p>In this recipe, you will import <strong>OpenStreetMap</strong> (<strong>OSM</strong>) data to PostGIS using the <kbd>osm2pgsql</kbd> command.</p>
<p>You will first download a sample dataset from the OSM website, and then you will import it using the <kbd>osm2pgsql</kbd> command.</p>
<p>You will add the imported layers in GIS desktop software and generate a view to get subdatasets, using the <kbd>hstore</kbd> PostgreSQL additional module to extract features based on their tags.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>We need the following in place before we can proceed with the steps required for the recipe:</p>
<ol>
<li>Install <kbd>osm2pgsql</kbd>. If you are using Windows, follow the instructions available at <a href="http://wiki.openstreetmap.org/wiki/Osm2pgsql"><span class="URLPACKT">http://wiki.openstreetmap.org/wiki/Osm2pgsql</span></a>. If you are on Linux, you can install it from the preceding website or from packages. For example, for Debian distributions, use the following:</li>
</ol>
<pre><strong>      $ sudo apt-get install osm2pgsql</strong></pre>
<ol start="2">
<li>For more information about the installation of the <kbd>osm2pgsql</kbd> command for other Linux distributions, macOS X, and MS Windows, please refer to the <kbd>osm2pgsql</kbd> web page available at <span class="URLPACKT"><a href="http://wiki.openstreetmap.org/wiki/Osm2pgsql">http://wiki.openstreetmap.org/wiki/Osm2pgsql</a>.</span></li>
<li>It's most likely that you will need to compile <kbd>osm2pgsql</kbd> yourself as the one that is installed with your package manager could already be obsolete. In my Linux Mint 12 box, this was the case (it was <kbd>osm2pgsql</kbd> v0.75), so I have installed Version 0.80 by following the instructions on the <kbd>osm2pgsql</kbd> web page. You can check the installed version just by typing the following command:</li>
</ol>
<pre><strong>      $ osm2pgsql</strong><strong>osm2pgsql SVN version 0.80.0 (32bit id space)</strong></pre>
<ol start="4">
<li>We will create a different database only for this recipe, as we will use this OSM database in other chapters. For this purpose, create a new database named <kbd>rome</kbd> and assign privileges to your user:</li>
</ol>
<pre><strong>      postgres=# CREATE DATABASE rome OWNER me;<br/></strong><strong>      postgres=# \connect rome;<br/></strong><strong>      rome=# create extension postgis;</strong></pre>
<ol start="5">
<li>You will not create a different schema in this new database, though, as the <kbd>osm2pgsql</kbd> command can only import OSM data in the public schema at the time of writing.</li>
<li>Be sure that your PostgreSQL installation supports <kbd>hstore</kbd> (besides <kbd>PostGIS</kbd>). If not, download and install it; for example, in Debian-based Linux distributions, you will need to install the <kbd>postgresql-contrib-9.6</kbd> package. Then, add <kbd>hstore</kbd> support to the <kbd>rome</kbd> database using the <kbd>CREATE EXTENSION</kbd> syntax:</li>
</ol>
<pre><strong>      $ sudo apt-get update<br/></strong><strong>      $ sudo apt-get install postgresql-contrib-9.6<br/></strong><strong>      $ psql -U me -d romerome=# CREATE EXTENSION hstore;</strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>The steps you need to follow to complete this recipe are as follows:</p>
<ol>
<li>Download an <kbd>.osm</kbd> file from the O<span class="URLPACKT">penStreetMap</span> website (<a href="https://www.openstreetmap.org/#map=5/21.843/82.795">https://www.openstreetmap.org/#map=5/21.843/82.795</a>).</li>
</ol>
<ol>
<li style="list-style-type: none">
<ol>
<li>Go to the <span class="URLPACKT">OpenStreetMap</span> website.</li>
<li>Select the area of interest for which you want to export data. You should not select a large area, as the live export from the website is limited to 50,000 nodes.</li>
</ol>
</li>
</ol>
<div class="packt_tip">If you want to export larger areas, you should consider downloading the whole database, built daily at <kbd>planet.osm</kbd> (250 GB uncompressed and 16 GB compressed). At <kbd>planet.osm</kbd>, you may also download extracts that contain OpenstreetMap data for individual continents, countries, and metropolitan areas.</div>
<ol>
<li style="list-style-type: none">
<ol start="3">
<li>If you want to get the same dataset used for this recipe, just copy and paste the following URL in your browser: <a href="http://www.openstreetmap.org/export?lat=41.88745&amp;lon=12.4899&amp;zoom=15&amp;layers=M"><span class="URLPACKT">http://www.openstreetmap.org/export?lat=41.88745&amp;lon=12.4899&amp;zoom=15&amp;layers=M</span></a>; or, get it from the book datasets (<kbd>chp01/map.osm</kbd> file).</li>
<li>Click on the <span class="packt_screen">Export</span> link.</li>
<li>Select <span class="packt_screen">OpenStreetMap XML Data</span> as the output format.</li>
<li>Download the <kbd>map.osm</kbd> file to your working directory.</li>
</ol>
</li>
</ol>
<ol start="2">
<li>Run <kbd>osm2pgsql</kbd> to import the OSM data in the PostGIS database. Use the <kbd>-hstore</kbd> option, as you wish to add tags with an additional <kbd>hstore</kbd> (key/value) column in the PostgreSQL tables:</li>
</ol>
<pre><strong>      $ osm2pgsql -d rome -U me --hstore map.osm<br/></strong><strong>      osm2pgsql SVN version 0.80.0 (32bit id space)Using projection<br/>      SRS 900913 (Spherical Mercator)Setting up table: <br/>      planet_osm_point...All indexes on planet_osm_polygon created <br/>      in 1sCompleted planet_osm_polygonOsm2pgsql took 3s overall</strong></pre>
<ol start="3">
<li>At this point, you should have the following geometry tables in your database:</li>
</ol>
<pre><strong>      rome=# SELECT f_table_name, f_geometry_column,<br/>      coord_dimension, srid, type FROM geometry_columns;</strong></pre>
<p style="padding-left: 60px">The output of the preceding command is shown here:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/88b339fc-20b5-4e8c-91c3-28d0ef61b2d6.png" style="width:37.58em;height:6.33em;"/></div>
<ol start="4">
<li>Note that the <kbd>osm2pgsql</kbd> command imports everything in the public schema. If you did not deal differently with the command's input parameter, your data will be imported in the Mercator Projection (<kbd>3857</kbd>).</li>
<li>Open the PostGIS tables and inspect them with your favorite desktop GIS. The following screenshot shows how it looks in QGIS. All the different thematic features are mixed at this time, so it looks a bit confusing:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-188 image-border" src="assets/8364e6ee-ac8a-42f1-aa14-e2b05ab73faa.png" style="width:51.33em;height:38.50em;"/></div>
<ol start="6">
<li>Generate a PostGIS view that extracts all the polygons tagged with <kbd>trees</kbd> as <kbd>land cover</kbd>. For this purpose, create the following view:</li>
</ol>
<pre class="mce-root CDPAlignLeft CDPAlign"><strong>      rome=# CREATE VIEW rome_trees AS SELECT way, tags </strong><br/><strong>      FROM planet_osm_polygon WHERE (tags -&gt; 'landcover') = 'trees';</strong></pre>
<div class="CDPAlignLeft CDPAlign">
<ol start="7">
<li>Open the view with a desktop GIS that supports PostGIS views, such as QGIS, and add your <kbd>rome_trees</kbd> view. The previous screenshot shows you how it looks.</li>
</ol>
</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p class="mce-root CDPAlignLeft CDPAlign">OpenStreetMap is a popular collaborative project for creating a free map of the world. Every user participating in the project can edit data; at the same time, it is possible for everyone to download those datasets in <kbd>.osm</kbd> datafiles (an XML format) under the terms of the <strong>Open Data Commons Open Database License</strong> (<strong>ODbL</strong>) at the time of writing.</p>
<p class="mce-root CDPAlignLeft CDPAlign">The <kbd>osm2pgsql</kbd> command is a command-line tool that can import <kbd>.osm</kbd> datafiles (eventually zipped) to the PostGIS database. To use the command, it is enough to give the PostgreSQL connection parameters and the <kbd>.osm</kbd> file to import.</p>
<p class="mce-root CDPAlignLeft CDPAlign">It is possible to import only features that have certain tags in the spatial database, as defined in the <kbd>default.style</kbd> configuration file. You can decide to comment in or out the OSM tagged features that you would like to import, or not, from this file. The command by default exports all the nodes and ways to linestring, point, and geometry PostGIS geometries.</p>
<p class="mce-root CDPAlignLeft CDPAlign">It is highly recommended to enable <kbd>hstore</kbd> support in the PostgreSQL database and use the <kbd>-hstore</kbd> option of <kbd>osm2pgsql</kbd> when importing the data. Having enabled this support, the OSM tags for each feature will be stored in a <kbd>hstore</kbd> PostgreSQL data type, which is optimized for storing (and retrieving) sets of key/values pairs in a single field. This way, it will be possible to query the database as follows:</p>
<pre class="mce-root CDPAlignLeft CDPAlign"><strong>SELECT way, tags FROM planet_osm_polygon WHERE (tags -&gt; 'landcover') = 'trees';</strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Importing raster data with the raster2pgsql PostGIS command</h1>
                </header>
            
            <article>
                
<p class="mce-root CDPAlignLeft CDPAlign">PostGIS 2.0 now has full support for raster datasets, and it is possible to import raster datasets using the <kbd>raster2pgsql</kbd> command.</p>
<p class="mce-root CDPAlignLeft CDPAlign">In this recipe, you will import a raster file to PostGIS using the <kbd>raster2pgsql</kbd> command. This command, included in any PostGIS distribution from version 2.0 onward, is able to generate an SQL dump to be loaded in PostGIS for any GDAL raster-supported format (in the same fashion that the <kbd>shp2pgsql</kbd> <span> </span><span>command </span>does for shapefiles).</p>
<p class="mce-root CDPAlignLeft CDPAlign">After loading the raster to PostGIS, you will inspect it both with SQL commands (analyzing the raster metadata information contained in the database), and with the <kbd>gdalinfo</kbd> command-line utility (to understand the way the input <kbd>raster2pgsql</kbd> parameters have been reflected in the PostGIS import process).</p>
<p class="mce-root CDPAlignLeft CDPAlign">You will finally open the raster in a desktop GIS and try a basic spatial query, mixing vector and raster tables.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p class="mce-root CDPAlignLeft CDPAlign">We need the following in place before we can proceed with the steps required for the recipe:</p>
<ol>
<li>From the <span class="URLPACKT">worldclim</span> website, download the current raster data (<a href="http://www.worldclim.org/current"><span class="URLPACKT">http://www.worldclim.org/current</span></a>) for min and max temperatures (only the raster for max temperatures will be used for this recipe). Alternatively, use the ones provided in the book datasets (<kbd>data/chp01</kbd>). Each of the two archives (<kbd>data/tmax_10m_bil.zip</kbd> and <kbd>data/tmin_10m_bil.zip</kbd>) contain 12 rasters in the BIL format, one for each month. You can look for more information at <a href="http://www.worldclim.org/formats"><span class="URLPACKT">http://www.worldclim.org/formats</span></a>.</li>
<li>Extract the two archives to a directory named <kbd>worldclim</kbd> in your working directory.</li>
<li>Rename each raster dataset to a name format with two digits for the month, for example, <kbd>tmax1.bil</kbd> and <kbd>tmax1.hdr</kbd> will become <kbd>tmax01.bil</kbd> and <kbd>tmax01.hdr</kbd>.</li>
<li>If you still haven't loaded the countries shapefile to PostGIS from a previous recipe, do it using the <kbd>ogr2ogr</kbd> or <kbd>shp2pgsql</kbd> commands. The following is the <kbd>shp2pgsql</kbd> syntax:</li>
</ol>
<pre class="mce-root CDPAlignLeft CDPAlign"><strong>      $ shp2pgsql -I -d -s 4326 -W LATIN1 -g the_geom countries.shp<br/>      chp01.countries &gt; countries.sql<br/></strong><strong>      $ psql -U me -d postgis_cookbook -f countries.sql</strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p class="mce-root CDPAlignLeft CDPAlign">The steps you need to follow to complete this recipe are as follows:</p>
<div class="CDPAlignLeft CDPAlign">
<ol>
<li>Get information about one of the rasters using the <kbd>gdalinfo</kbd> command-line tool as follows:</li>
</ol>
</div>
<pre class="mce-root CDPAlignLeft CDPAlign"><strong>      $ gdalinfo worldclim/tmax09.bil<br/></strong><strong><br/>      Driver: EHdr/ESRI .hdr Labelled<br/></strong><strong>      Files: worldclim/tmax9.bil<br/></strong>             <strong>worldclim/tmax9.hdr<br/></strong><strong>      Size is 2160, 900<br/></strong><strong>      Coordinate System is:<br/></strong><strong>      GEOGCS[""WGS 84"",<br/>        DATUM[""WGS_1984"",<br/>          SPHEROID[""WGS 84"",6378137,298.257223563,<br/>            AUTHORITY[""EPSG"",""7030""]],<br/>          TOWGS84[0,0,0,0,0,0,0],<br/>          AUTHORITY[""EPSG"",""6326""]],<br/>        PRIMEM[""Greenwich"",0,<br/>          AUTHORITY[""EPSG"",""8901""]],<br/>        UNIT[""degree"",0.0174532925199433,<br/>        AUTHORITY[""EPSG"",""9108""]],<br/>      AUTHORITY[""EPSG"",""4326""]]<br/>      Origin = (-180.000000000000057,90.000000000000000)<br/></strong><strong>      Pixel Size = (0.166666666666667,-0.166666666666667)<br/></strong><strong>      Corner Coordinates:<br/></strong>        <strong>Upper Left (-180.0000000, 90.0000000) (180d 0'' 0.00""W, 90d<br/>                                               0'' 0.00""N)<br/></strong>        <strong>Lower Left (-180.0000000, -60.0000000) (180d 0'' 0.00""W, 60d<br/>                                                0'' 0.00""S)<br/></strong>        <strong>Upper Right ( 180.0000000, 90.0000000) (180d 0'' 0.00""E, 90d<br/>                                                0'' 0.00""N)<br/></strong>        <strong>Lower Right ( 180.0000000, -60.0000000) (180d 0'' 0.00""E, 60d <br/>                                                 0'' 0.00""S)<br/></strong>        <strong>Center ( 0.0000000, 15.0000000) ( 0d 0'' 0.00""E, 15d<br/>                                          0'' 0.00""N)<br/></strong><strong>        Band 1 Block=2160x1 Type=Int16, ColorInterp=Undefined<br/></strong><strong>        Min=-153.000 Max=441.000<br/></strong><strong>        NoData Value=-9999</strong></pre>
<ol start="2">
<li>The <kbd>gdalinfo</kbd> command provides a lot of useful information about the raster, for example, the GDAL driver being used to read it, the files composing it (in this case, two files with <kbd>.bil</kbd> and <kbd>.hdr</kbd> extensions), the size in pixels (2160 x 900), the spatial reference (WGS 84), the geographic extents, the origin, and the pixel size (needed to correctly georeference the raster), and for each raster band (just one in the case of this file), some statistical information like the min and max values (-153.000 and 441.000, corresponding to a temperature of -15.3 °C and 44.1 °C. Values are expressed as temperature * 10 in °C, according to the documentation available at <a href="http://worldclim.org/">http://worldclim.org/</a>).</li>
<li>Use the <kbd>raster2pgsql</kbd> file to generate the <kbd>.sql</kbd> dump file and then import the raster in PostGIS:</li>
</ol>
<pre class="mce-root CDPAlignLeft CDPAlign"><strong>      $ raster2pgsql -I -C -F -t 100x100 -s 4326<br/>      worldclim/tmax01.bil chp01.tmax01 &gt; tmax01.sql<br/></strong><strong>      $ psql -d postgis_cookbook -U me -f tmax01.sql</strong></pre>
<div class="CDPAlignLeft CDPAlign">
<p style="padding-left: 90px">If you are in Linux, you may pipe the two commands in a unique line:</p>
</div>
<pre class="mce-root CDPAlignLeft CDPAlign"><strong>      $ raster2pgsql -I -C -M -F -t 100x100 worldclim/tmax01.bil <br/>      chp01.tmax01 | psql -d postgis_cookbook -U me -f tmax01.sql</strong></pre>
<div class="CDPAlignLeft CDPAlign">
<ol start="4">
<li>Check how the new table has been created in PostGIS:</li>
</ol>
</div>
<pre class="mce-root CDPAlignLeft CDPAlign"><strong>      $ pg_dump -t chp01.tmax01 --schema-only -U me postgis_cookbook<br/>      ...<br/>      CREATE TABLE tmax01 (<br/>        rid integer NOT NULL,<br/>        rast public.raster,<br/>        filename text,<br/>        CONSTRAINT enforce_height_rast CHECK (<br/>          (public.st_height(rast) = 100)<br/>        ),<br/>        CONSTRAINT enforce_max_extent_rast CHECK (public.st_coveredby<br/>          (public.st_convexhull(rast), ''0103...''::public.geometry)<br/>        ),<br/>        CONSTRAINT enforce_nodata_values_rast CHECK (<br/>          ((public._raster_constraint_nodata_values(rast)<br/>            )::numeric(16,10)[] = ''{0}''::numeric(16,10)[])<br/>          ),<br/>        CONSTRAINT enforce_num_bands_rast CHECK (<br/>          (public.st_numbands(rast) = 1)<br/>        ),<br/>        CONSTRAINT enforce_out_db_rast CHECK (<br/>          (public._raster_constraint_out_db(rast) = ''{f}''::boolean[])<br/>          ),<br/>        CONSTRAINT enforce_pixel_types_rast CHECK (<br/>          (public._raster_constraint_pixel_types(rast) = <br/>           ''{16BUI}''::text[])<br/>          ),<br/>        CONSTRAINT enforce_same_alignment_rast CHECK (<br/>          (public.st_samealignment(rast, ''01000...''::public.raster)<br/>        ),<br/>        CONSTRAINT enforce_scalex_rast CHECK (<br/>          ((public.st_scalex(rast))::numeric(16,10) = <br/>            0.166666666666667::numeric(16,10))<br/>           ),<br/>        CONSTRAINT enforce_scaley_rast CHECK (<br/>          ((public.st_scaley(rast))::numeric(16,10) = <br/>            (-0.166666666666667)::numeric(16,10))<br/>          ),<br/>        CONSTRAINT enforce_srid_rast CHECK ((public.st_srid(rast) = 0)),<br/>        CONSTRAINT enforce_width_rast CHECK ((public.st_width(rast) = 100))<br/>      );</strong></pre>
<ol start="5">
<li>Check if a record for this PostGIS raster appears in the <kbd>raster_columns</kbd> metadata view, and note the main metadata information that has been stored there, such as schema, name, raster column name (default is raster), SRID, scale (for <em>x</em> and <em>y</em>), block size (for <em>x</em> and <em>y</em>), band numbers (1), band types (<kbd>16BUI</kbd>), zero data values (0), and <kbd>db</kbd> storage type (<kbd>out_db</kbd> is <kbd>false</kbd>, as we have stored the raster bytes in the database; you could have used the <kbd>-R</kbd> option to register the raster as an out-of-db filesystem):</li>
</ol>
<pre class="mce-root CDPAlignLeft CDPAlign"><strong>      postgis_cookbook=# SELECT * FROM raster_columns;</strong></pre>
<p class="CDPAlignLeft CDPAlign"/>
<ol start="6">
<li>If you have followed this recipe from the beginning, you should now have 198 rows in the raster table, with each row representing one raster block size (100 x 100 pixels blocks, as indicated with the <kbd>-traster2pgsql</kbd> option):</li>
</ol>
<pre class="mce-root CDPAlignLeft CDPAlign"><strong>      postgis_cookbook=# SELECT count(*) FROM chp01.tmax01;</strong></pre>
<div class="CDPAlignLeft CDPAlign">
<p style="padding-left: 60px">The output of the preceding command is as follows:</p>
</div>
<pre class="mce-root CDPAlignLeft CDPAlign"><strong>      count<br/></strong><strong>      -------<br/></strong><strong>      198<br/></strong><strong>      (1 row)</strong></pre>
<ol start="7">
<li>Try to open the raster table with <kbd>gdalinfo</kbd>. You should see the same information you got from <kbd>gdalinfo</kbd> when you were analyzing the original BIL file. The only difference is the block size, as you moved to a smaller one (100 x 100) from the original (2160 x 900). That's why the original file has been split into several datasets (198):</li>
</ol>
<pre class="mce-root CDPAlignLeft CDPAlign"><strong>      gdalinfo PG":host=localhost port=5432 dbname=postgis_cookbook<br/>      user=me password=mypassword schema='chp01' table='tmax01'"</strong></pre>
<div class="CDPAlignLeft CDPAlign">
<ol start="8">
<li>The <kbd>gdalinfo</kbd> command reads the PostGIS raster as being composed of multiple raster subdatasets (198, one for each row in the table). You still have the possibility of reading the whole table as a single raster, using the <kbd>mode=2</kbd> option in the PostGIS raster connection string (<kbd>mode=1</kbd> is the default). Check the difference:</li>
</ol>
</div>
<pre class="mce-root CDPAlignLeft CDPAlign"><strong>      gdalinfo PG":host=localhost port=5432 dbname=postgis_cookbook<br/>      user=me password=mypassword schema='chp01' table='tmax01' mode=2"</strong></pre>
<div class="CDPAlignLeft CDPAlign">
<ol start="9">
<li>You can easily obtain a visual representation of those blocks by converting the extent of all the 198 rows in the <kbd>tmax01</kbd> table (each representing a raster block) to a shapefile using <kbd>ogr2ogr</kbd>:</li>
</ol>
</div>
<pre class="mce-root CDPAlignLeft CDPAlign"><strong>      $ ogr2ogr temp_grid.shp PG:"host=localhost port=5432 <br/>      dbname='postgis_cookbook' user='me' password='mypassword'" <br/>      -sql "SELECT rid, filename, ST_Envelope(rast) as the_geom <br/>      FROM chp01.tmax01"</strong></pre>
<ol start="10">
<li>Now, try to open the raster table with QGIS (at the time of writing, one of the few desktop GIS tools that has support for it) together with the blocks shapefile generated in the previous steps (<kbd>temp_grid.shp</kbd>). You should see something like the following screenshot:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="assets/d3eda5b4-4270-4915-b0e3-5d8b345eefd3.png" style="font-size: 1em;"/></div>
<div class="packt_tip CDPAlignLeft CDPAlign">If you are using QGIS 2.6 or higher, you can see the layer in the <span class="packt_screen">DB Manager</span> under the <span class="packt_screen">Database</span> menu and drag it to the <span class="packt_screen">Layers</span> panel.</div>
<ol start="11">
<li>As the last bonus step, you will select the 10 countries with the lowest average max temperature in January (using the centroid of the polygon representing the country):</li>
</ol>
<pre class="mce-root CDPAlignLeft CDPAlign"><strong>      SELECT * FROM (<br/>        SELECT c.name, ST_Value(t.rast,<br/>          ST_Centroid(c.the_geom))/10 as tmax_jan FROM chp01.tmax01 AS t <br/>        JOIN chp01.countries AS c <br/>        ON ST_Intersects(t.rast, ST_Centroid(c.the_geom))<br/>      ) AS foo <br/>      ORDER BY tmax_jan LIMIT 10;</strong></pre>
<div class="CDPAlignLeft CDPAlign">
<p style="padding-left: 60px">The output is as follows:</p>
</div>
<div class="mce-root CDPAlignCenter CDPAlign"><strong><img src="assets/aff94286-3fbe-4feb-b22a-d5461f4da345.png" style="width:28.92em;height:10.00em;"/></strong></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p class="mce-root CDPAlignLeft CDPAlign">The <kbd>raster2pgsql</kbd> command is able to load any raster formats supported by GDAL in PostGIS. You can have a format list supported by your GDAL installation by typing the following command:</p>
<pre class="mce-root CDPAlignLeft CDPAlign"><strong>$ gdalinfo --formats</strong></pre>
<p class="mce-root CDPAlignLeft CDPAlign">In this recipe, you have been importing one raster file using some of the most common <kbd>raster2pgsql</kbd> options:</p>
<pre class="mce-root CDPAlignLeft CDPAlign"><strong>$ raster2pgsql -I -C -F -t 100x100 -s 4326 worldclim/tmax01.bil chp01.tmax01 &gt; tmax01.sql</strong></pre>
<p class="mce-root CDPAlignLeft CDPAlign">The <kbd>-I</kbd> option creates a GIST spatial index for the raster column. The <kbd>-C</kbd> option will create the standard set of constraints after the rasters have been loaded. The <kbd>-F</kbd> option will add a column with the filename of the raster that has been loaded. This is useful when you are appending many raster files to the same PostGIS raster table. The <kbd>-s</kbd> option sets the raster's SRID.</p>
<p class="mce-root CDPAlignLeft CDPAlign">If you decide to include the <kbd>-t</kbd> option, then you will cut the original raster into tiles, each inserted as a single row in the raster table. In this case, you decided to cut the raster into 100 x 100 tiles, resulting in 198 table rows in the raster table.</p>
<p class="mce-root CDPAlignLeft CDPAlign">Another important option is <kbd>-R</kbd>, which will register the raster as <kbd>out-of-db</kbd>; in such a case, only the metadata will be inserted in the database, while the raster will be out of the database.</p>
<p class="mce-root CDPAlignLeft CDPAlign">The raster table contains an identifier for each row, the raster itself (eventually one of its tiles, if using the <kbd>-t</kbd> option), and eventually the original filename, if you used the <kbd>-F</kbd> option, as in this case.</p>
<p class="mce-root CDPAlignLeft CDPAlign">You can analyze the PostGIS raster using SQL commands or the <kbd>gdalinfo</kbd> command. Using SQL, you can query the <kbd>raster_columns</kbd> view to get the most significant raster metadata (spatial reference, band number, scale, block size, and so on).</p>
<p class="mce-root CDPAlignLeft CDPAlign">With <kbd>gdalinfo</kbd>, you can access the same information, using a connection string with the following syntax:</p>
<pre class="mce-root CDPAlignLeft CDPAlign"><strong>gdalinfo PG":host=localhost port=5432 dbname=postgis_cookbook user=me password=mypassword schema='chp01' table='tmax01' mode=2"</strong></pre>
<p class="mce-root CDPAlignLeft CDPAlign">The <kbd>mode</kbd> parameter is not influential if you loaded the whole raster as a single block (for example, if you did not specify the <kbd>-t</kbd> option). But, as in the use case of this recipe, if you split it into tiles, <kbd>gdalinfo</kbd> will see each tile as a single subdataset with the default behavior (<kbd>mode=1</kbd>). If you want GDAL to consider the raster table as a unique raster dataset, you have to specify the mode option and explicitly set it to <kbd>2</kbd>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Importing multiple rasters at a time</h1>
                </header>
            
            <article>
                
<p class="mce-root CDPAlignLeft CDPAlign">This recipe will guide you through the importing of multiple rasters at a time.</p>
<p class="mce-root CDPAlignLeft CDPAlign">You will first import some different single band rasters to a unique single band raster table using the <kbd>raster2pgsql</kbd> command.</p>
<p class="mce-root CDPAlignLeft CDPAlign">Then, you will try an alternative approach, merging the original single band rasters in a virtual raster, with one band for each of the original rasters, and then load the multiband raster to a raster table. To accomplish this, you will use the GDAL <kbd>gdalbuildvrt</kbd> command and then load the data to PostGIS with <kbd>raster2pgsql</kbd>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p class="mce-root CDPAlignLeft CDPAlign">Be sure to have all the original raster datasets you have been using for the previous recipe.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p class="mce-root CDPAlignLeft CDPAlign">The steps you need to follow to complete this recipe are as follows:</p>
<ol>
<li>Import all the maximum average temperature rasters in a single PostGIS raster table using <kbd>raster2pgsql</kbd> and then <kbd>psql</kbd> (eventually, pipe the two commands if you are in Linux):</li>
</ol>
<pre class="mce-root CDPAlignLeft CDPAlign"><strong>      $ raster2pgsql -d -I -C -M -F -t 100x100 -s 4326 <br/>      worldclim/tmax*.bil chp01.tmax_2012 &gt; tmax_2012.sql<br/></strong><strong>      $ psql -d postgis_cookbook -U me -f tmax_2012.sql</strong></pre>
<ol start="2">
<li>Check how the table was created in PostGIS, querying the <kbd>raster_columns</kbd> table. Here we are querying only some significant fields:</li>
</ol>
<pre class="mce-root CDPAlignLeft CDPAlign"><strong>      postgis_cookbook=# SELECT r_raster_column, srid,<br/>      ROUND(scale_x::numeric, 2) AS scale_x, <br/>      ROUND(scale_y::numeric, 2) AS scale_y, blocksize_x, <br/>      blocksize_y, num_bands, pixel_types, nodata_values, out_db <br/>      FROM raster_columns where r_table_schema='chp01' <br/>      AND r_table_name ='tmax_2012';</strong> </pre>
<div class="mce-root CDPAlignCenter CDPAlign"><img src="assets/50ae6b7b-52c4-4822-ac30-927ab2cfed6e.png"/></div>
<div class="CDPAlignLeft CDPAlign">
<ol start="3">
<li>Check some raster statistics using the <kbd>ST_MetaData</kbd> function:</li>
</ol>
</div>
<pre class="mce-root CDPAlignLeft CDPAlign"><strong>      SELECT rid, (foo.md).* <br/>      FROM (SELECT rid, ST_MetaData(rast) As md <br/>      FROM chp01.tmax_2012) As foo;</strong></pre>
<div class="packt_infobox"><span>Note that there is different metadata for each raster record loaded in the table.</span></div>
<p style="padding-left: 60px">The output of the preceding command is as shown here:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/48f33502-5b6b-452d-9d58-51f4b36e8b06.png"/></div>
<ol start="4">
<li>
<p>If you now query the table, you would be able to derive the month for each raster row only from the <kbd>original_file</kbd> column. In the table, you have imported 198 distinct records (rasters) for each of the 12 original files (we divided them into 100 x 100 blocks, if you remember). Test this with the following query:</p>
</li>
</ol>
<pre class="mce-root CDPAlignLeft CDPAlign"><strong>      postgis_cookbook=# SELECT COUNT(*) AS num_raster, <br/>      MIN(filename) as original_file FROM chp01.tmax_2012<br/></strong>      <strong>GROUP BY filename ORDER BY filename;</strong></pre>
<div class="mce-root CDPAlignCenter CDPAlign"><img src="assets/5acb956c-6e6b-4a79-a9cc-653fb5169c5e.png" style="width:17.25em;height:17.92em;"/></div>
<ol start="5">
<li>With this approach, using the <kbd>filename</kbd> field, you could use the <kbd>ST_Value</kbd> PostGIS raster function to get the average monthly maximum temperature of a certain geographic zone for the whole year:</li>
</ol>
<pre class="mce-root CDPAlignLeft CDPAlign"><strong>      SELECT REPLACE(REPLACE(filename, 'tmax', ''), '.bil', '') AS month, <br/>      (ST_VALUE(rast, ST_SetSRID(ST_Point(12.49, 41.88), 4326))/10) AS tmax <br/>      FROM chp01.tmax_2012 <br/>      WHERE rid IN (<br/>        SELECT rid FROM chp01.tmax_2012 <br/>        WHERE ST_Intersects(ST_Envelope(rast),<br/>              ST_SetSRID(ST_Point(12.49, 41.88), 4326))<br/>      )<br/>      ORDER BY month;</strong></pre>
<div class="CDPAlignLeft CDPAlign">
<p style="padding-left: 60px">The output of the preceding command is as shown here:</p>
</div>
<div class="mce-root CDPAlignCenter CDPAlign"><img src="assets/94b4e36e-a003-4565-adc4-d4cb2ece5f0c.png" style="width:9.75em;height:19.33em;"/></div>
<ol start="6">
<li>A different approach is to store each month value in a different raster band. The <kbd>raster2pgsql</kbd> command doesn't let you load to different bands in an existing table. But, you can use GDAL by combining the <kbd>gdalbuildvrt</kbd> and the <kbd>gdal_translate</kbd> commands. First, use <kbd>gdalbuildvrt</kbd> to create a new virtual raster composed of 12 bands, one for each month:</li>
</ol>
<pre class="mce-root CDPAlignLeft CDPAlign"><strong>      $ gdalbuildvrt -separate tmax_2012.vrt worldclim/tmax*.bil</strong></pre>
<ol start="7">
<li>Analyze the <kbd>tmax_2012.vrt</kbd> XML file with a text editor. It should have a virtual band (<kbd>VRTRasterBand</kbd>) for each physical raster pointing to it:</li>
</ol>
<pre class="mce-root CDPAlignLeft CDPAlign">      &lt;VRTDataset rasterXSize="2160" rasterYSize="900"&gt;<br/>        &lt;SRS&gt;GEOGCS...&lt;/SRS&gt;<br/>        &lt;GeoTransform&gt; <br/>          -1.8000000000000006e+02, 1.6666666666666699e-01, ...<br/>        &lt;/GeoTransform&gt;<br/>        &lt;VRTRasterBand dataType="Int16" band="1"&gt;<br/>          &lt;NoDataValue&gt;-9.99900000000000E+03&lt;/NoDataValue&gt;<br/>          &lt;ComplexSource&gt;<br/>            &lt;SourceFilename relativeToVRT="1"&gt;<br/>              worldclim/tmax01.bil<br/>            &lt;/SourceFilename&gt;<br/>            &lt;SourceBand&gt;1&lt;/SourceBand&gt;<br/>            &lt;SourceProperties RasterXSize="2160" RasterYSize="900"<br/>             DataType="Int16" BlockXSize="2160" BlockYSize="1" /&gt;<br/>            &lt;SrcRect xOff="0" yOff="0" xSize="2160" ySize="900" /&gt;<br/>            &lt;DstRect xOff="0" yOff="0" xSize="2160" ySize="900" /&gt;<br/>            &lt;NODATA&gt;-9999&lt;/NODATA&gt;<br/>          &lt;/ComplexSource&gt;<br/>        &lt;/VRTRasterBand&gt;<br/>      &lt;VRTRasterBand dataType="Int16" band="2"&gt;<br/>      ...</pre>
<ol start="8">
<li>Now, with <kbd>gdalinfo</kbd>, analyze this output virtual raster to check if it is effectively composed of 12 bands:</li>
</ol>
<pre class="mce-root CDPAlignLeft CDPAlign"><strong>      $ gdalinfo tmax_2012.vrt</strong></pre>
<p class="mce-root CDPAlignLeft CDPAlign" style="padding-left: 60px">The output of the preceding command is as follows:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><strong><img src="assets/7833dc04-0623-4c07-8733-72cc62391b6b.png" style="width:32.00em;height:32.33em;"/> ...</strong></div>
<ol start="9">
<li>Import the virtual raster composed of 12 bands, each referring to one of the 12 original rasters, to a PostGIS raster table composed of 12 bands. For this purpose, you can use the <kbd>raster2pgsql</kbd> command:</li>
</ol>
<pre class="mce-root CDPAlignLeft CDPAlign"><strong>      $ raster2pgsql -d -I -C -M -F -t 100x100 -s 4326 tmax_2012.vrt <br/>      chp01.tmax_2012_multi &gt; tmax_2012_multi.sql<br/></strong><strong>      $ psql -d postgis_cookbook -U me -f tmax_2012_multi.sql</strong></pre>
<div class="CDPAlignLeft CDPAlign">
<ol start="10">
<li>Query the <kbd>raster_columns</kbd> view to get some indicators for the imported raster. Note that the <kbd>num_bands</kbd> is now 12:</li>
</ol>
</div>
<pre class="mce-root CDPAlignLeft CDPAlign"><strong>     postgis_cookbook=# SELECT r_raster_column, srid, blocksize_x,<br/>     blocksize_y, num_bands, pixel_types <br/>     from raster_columns where r_table_schema='chp01' <br/>     AND r_table_name ='tmax_2012_multi';</strong> </pre>
<div class="mce-root CDPAlignCenter CDPAlign"><img src="assets/9a742dc8-375c-49a0-a674-8f8b65b20cfc.png"/></div>
<ol start="11">
<li>Now, let's try to produce the same output as the query using the previous approach. This time, given the table structure, we keep the results in a single row:</li>
</ol>
<pre class="mce-root CDPAlignLeft CDPAlign"><strong>      postgis_cookbook=# SELECT<br/>      (ST_VALUE(rast, 1, ST_SetSRID(ST_Point(12.49, 41.88), 4326))/10) <br/>      AS jan,<br/>      (ST_VALUE(rast, 2, ST_SetSRID(ST_Point(12.49, 41.88), 4326))/10) <br/>      AS feb,<br/>      (ST_VALUE(rast, 3, ST_SetSRID(ST_Point(12.49, 41.88), 4326))/10)<br/>      AS mar,<br/>      (ST_VALUE(rast, 4, ST_SetSRID(ST_Point(12.49, 41.88), 4326))/10) <br/>      AS apr,<br/>      (ST_VALUE(rast, 5, ST_SetSRID(ST_Point(12.49, 41.88), 4326))/10) <br/>      AS may,<br/>      (ST_VALUE(rast, 6, ST_SetSRID(ST_Point(12.49, 41.88), 4326))/10) <br/>      AS jun,<br/>      (ST_VALUE(rast, 7, ST_SetSRID(ST_Point(12.49, 41.88), 4326))/10) <br/>      AS jul,<br/>      (ST_VALUE(rast, 8, ST_SetSRID(ST_Point(12.49, 41.88), 4326))/10) <br/>      AS aug,<br/>      (ST_VALUE(rast, 9, ST_SetSRID(ST_Point(12.49, 41.88), 4326))/10) <br/>      AS sep,<br/>      (ST_VALUE(rast, 10, ST_SetSRID(ST_Point(12.49, 41.88), 4326))/10) <br/>      AS oct,<br/>      (ST_VALUE(rast, 11, ST_SetSRID(ST_Point(12.49, 41.88), 4326))/10) <br/>      AS nov,<br/>      (ST_VALUE(rast, 12, ST_SetSRID(ST_Point(12.49, 41.88), 4326))/10) <br/>      AS dec <br/>      FROM chp01.tmax_2012_multi WHERE rid IN (<br/>        SELECT rid FROM chp01.tmax_2012_multi<br/>        WHERE ST_Intersects(rast, ST_SetSRID(ST_Point(12.49, 41.88), 4326))<br/>      );</strong></pre>
<p class="mce-root CDPAlignLeft CDPAlign" style="padding-left: 60px">The output of the preceding command is as follows:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img src="assets/9f8982fc-aea5-4a99-a525-4f31322ddd8e.png" style="width:45.92em;height:4.42em;"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p class="mce-root CDPAlignLeft CDPAlign">You can import raster datasets in PostGIS using the <kbd>raster2pgsql</kbd> command.</p>
<div class="packt_infobox CDPAlignLeft CDPAlign">The GDAL PostGIS raster so far does not support writing operations; therefore, for now, you cannot use GDAL commands such as <kbd>gdal_translate</kbd> and <kbd>gdalwarp</kbd>.<br/>
This is going to change in the near future, so you may have such an extra option when you are reading this chapter.</div>
<p class="mce-root CDPAlignLeft CDPAlign">In a scenario where you have multiple rasters representing the same variable at different times, as in this recipe, it makes sense to store all of the original rasters as a single table in PostGIS. In this recipe, we have the same variable (average maximum temperature) represented by a single raster for each month. You have seen that you could proceed in two different ways:</p>
<ol>
<li>Append each single raster (representing a different month) to the same PostGIS single band raster table and derive the information related to the month from the value in the filename column (added to the table using the <kbd>-F raster2pgsql</kbd> option).</li>
<li>Generate a multiband raster using <kbd>gdalbuildvrt</kbd> (one raster with 12 bands, one for each month), and import it in a single multiband PostGIS table using the <kbd>raster2pgsql</kbd> command.</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Exporting rasters with the gdal_translate and gdalwarp GDAL commands</h1>
                </header>
            
            <article>
                
<p class="mce-root CDPAlignLeft CDPAlign">In this recipe, you will see a couple of main options for exporting PostGIS rasters to different raster formats. They are both provided as command-line tools, <kbd>gdal_translate</kbd> and <kbd>gdalwarp</kbd>, by GDAL.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p class="mce-root CDPAlignLeft CDPAlign">You need the following in place before you can proceed with the steps required for the recipe:</p>
<ol>
<li>You need to have gone through the previous recipe and imported <kbd>tmax</kbd> 2012 datasets (12 <kbd>.bil</kbd> files) as a single multiband (12 bands) raster in PostGIS.</li>
<li>You must have the PostGIS raster format enabled in GDAL. For this purpose, check the output of the following command:</li>
</ol>
<pre class="mce-root CDPAlignLeft CDPAlign"><strong>      $ gdalinfo --formats | grep -i postgis</strong></pre>
<p class="mce-root CDPAlignLeft CDPAlign" style="padding-left: 60px">The output of the preceding command is as follows:</p>
<pre class="mce-root CDPAlignLeft CDPAlign"><strong>      PostGISRaster (rw): PostGIS Raster driver</strong></pre>
<ol start="3">
<li>You should have already learned how to use the GDAL PostGIS raster driver in the previous two recipes. You need to use a connection string composed of the following parameters:</li>
</ol>
<pre class="mce-root CDPAlignLeft CDPAlign"><strong>      $ gdalinfo PG:"host=localhost port=5432<br/>      dbname='postgis_cookbook' user='me' password='mypassword'<br/>      schema='chp01' table='tmax_2012_multi' mode='2'"</strong></pre>
<ol start="4">
<li>Refer to the previous two recipes for more information about the preceding parameters.</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p class="mce-root CDPAlignLeft CDPAlign">The steps you need to follow to complete this recipe are as follows:</p>
<ol>
<li>As an initial test, you will export the first six months of the <kbd>tmax</kbd> for 2012 (the first six bands in the <kbd>tmax_2012_multi</kbd> PostGIS raster table) using the <kbd>gdal_translate</kbd> command:</li>
</ol>
<pre class="mce-root CDPAlignLeft CDPAlign"><strong>      $ gdal_translate -b 1 -b 2 -b 3 -b 4 -b 5 -b 6<br/>      PG:"host=localhost port=5432 dbname='postgis_cookbook'<br/>      user='me' password='mypassword' schema='chp01'<br/>      table='tmax_2012_multi' mode='2'" tmax_2012_multi_123456.tif</strong></pre>
<ol start="2">
<li>As the second test, you will export all of the bands, but only for the geographic area containing Italy. Use the <kbd>ST_Extent</kbd> command to get the geographic extent of that zone:</li>
</ol>
<pre class="mce-root CDPAlignLeft CDPAlign"><strong>      postgis_cookbook=# SELECT ST_Extent(the_geom) <br/>      FROM chp01.countries WHERE name = 'Italy';</strong></pre>
<p class="mce-root CDPAlignLeft CDPAlign" style="padding-left: 60px">The output of the preceding command is as follows:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><strong><img src="assets/c08790d8-bad4-41ee-affd-131e49a46b5e.png" style="width:37.42em;height:5.00em;"/></strong></div>
<ol start="3">
<li>Now use the <kbd>gdal_translate</kbd> command with the <kbd>-projwin</kbd> option to obtain the desired purpose:</li>
</ol>
<pre class="mce-root CDPAlignLeft CDPAlign"><strong>      $ gdal_translate -projwin 6.619 47.095 18.515 36.649<br/>      PG:"host=localhost port=5432 dbname='postgis_cookbook'<br/>      user='me' password='mypassword' schema='chp01'<br/>      table='tmax_2012_multi' mode='2'" tmax_2012_multi.tif</strong></pre>
<ol start="4">
<li>There is another GDAL command, <kbd>gdalwarp</kbd>, that is still a convert utility with reprojection and advanced warping functionalities. You can use it, for example, to export a PostGIS raster table, reprojecting it to a different spatial reference system. This will convert the PostGIS raster table to GeoTiff and reproject it from <kbd>EPSG:4326</kbd> to <kbd>EPSG:3857</kbd>:</li>
</ol>
<pre class="mce-root CDPAlignLeft CDPAlign"><strong>      gdalwarp -t_srs EPSG:3857 PG:"host=localhost port=5432 <br/>      dbname='postgis_cookbook' user='me' password='mypassword' <br/>      schema='chp01' table='tmax_2012_multi' mode='2'" <br/>      tmax_2012_multi_3857.tif</strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p class="mce-root CDPAlignLeft CDPAlign">Both <kbd>gdal_translate</kbd> and <kbd>gdalwarp</kbd> can transform rasters from a PostGIS raster to all GDAL-supported formats. To get a complete list of the supported formats, you can use the <kbd>--formats</kbd> option of GDAL's command line as follows:</p>
<pre class="mce-root CDPAlignLeft CDPAlign"><strong>$ gdalinfo --formats</strong></pre>
<p class="mce-root CDPAlignLeft CDPAlign">For both these GDAL commands, the default output format is GeoTiff; if you need a different format, you must use the <kbd>-of</kbd> option and assign to it one of the outputs produced by the previous command line.</p>
<p class="mce-root CDPAlignLeft CDPAlign">In this recipe, you have tried some of the most common options for these two commands. As they are complex tools, you may try some more command options as a bonus step.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<p class="mce-root CDPAlignLeft CDPAlign">To get a better understanding, you should check out the excellent documentation on the GDAL website:</p>
<ul>
<li>Information about the <kbd>gdal_translate</kbd> command is available at <a href="http://www.gdal.org/gdal_translate.html"><span class="URLPACKT">http://www.gdal.org/gdal_translate.html</span></a></li>
<li>Information about the <kbd>gdalwarp</kbd> command is available at <a href="http://www.gdal.org/gdalwarp.html"><span class="URLPACKT">http://www.gdal.org/gdalwarp.html</span></a></li>
</ul>


            </article>

            
        </section>
    </body></html>