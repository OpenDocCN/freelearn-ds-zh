["```py\n(defproject sentiment \"0.1.0-SNAPSHOT\"\n:plugins [[lein-cljsbuild \"0.3.2\"]]\n:dependencies [[org.clojure/clojure \"1.5.1\"]\n                 [org.clojure/data.csv \"0.1.2\"]\n                 [org.clojure/data.json \"0.2.3\"]\n                 [org.apache.opennlp/opennlp-tools \"1.5.3\"]\n                 [nz.ac.waikato.cms.weka/weka-dev \"3.7.7\"]]\n:jvm-opts [\"-Xmx4096m\"])\n```", "```py\n(ns sentiment.tokens\n  (:require [clojure.string :as str]\n            [clojure.java.io :as io])\n  (:import [opennlp.tools.tokenizeSimpleTokenizer]\n           [opennlp.tools.postagPOSModelPOSTaggerME]))\n```", "```py\n(defn tokenize [s]\n  (map (memfn toLowerCase)\n       (seq\n         (.tokenize SimpleTokenizer/INSTANCE s))))\n```", "```py\nuser=> (t/tokenize \"How would this be TOKENIZED?\")\n(\"how\" \"would\" \"this\" \"be\" \"tokenized\" \"?\")\n\n```", "```py\n(defn inc-feature [f-index f-vec feature]\n  (if-let [i (f-index feature)]\n    [f-index, (assoc f-veci (inc (nth f-veci)))]\n    (let [i (count f-index)]\n      [(assoc f-index feature i), (assoc f-veci 1)])))\n```", "```py\n(defn ->feature-vec [f-index features]\n  (reduce #(inc-feature (first %1) (second %1) %2)\n          [f-index (vec (repeat (count f-index) 0))]\nfeatures))\n```", "```py\n(defnaccum-features [state features]\n  (let [[index accum] state\n        [new-index feature] (->feature-vec index features)]\n    [new-index (conj accum feature)]))\n\n(defn pad-to [f-index f-vec]\n(vec (take (count f-index) (concat f-vec (repeat 0)))))\n\n(defn ->features [feature-seq]\n  (let [[f-index f-vecs]\n        (reduce accum-features [{} []] feature-seq)]\n    [f-index (map #(pad-to f-index %) f-vecs)]))\n```", "```py\nuser=> (def f-out\n (t/->features\n (map set\n (map t/tokenize [\"I'm nobody.\"\n \"Who are you?\"\n \"Are you nobody too?\"]))))\n#'user/f-out\nuser=> (first f-out)\n{\"nobody\" 0, \"'\" 1, \"i\" 2, \"m\" 3, \".\" 4, \"too\" 9, \"are\" 5,\n \"who\" 6, \"you\" 7, \"?\" 8}\nuser=> (print (second f-out))\n([1 1 111 0 0000] [0 0 000 1 111 0]\n [1 0 000 1 0 1 11])\n\n```", "```py\nuser=> (def index (map first (sort-by second (first f-out))))\n#'user/index\nuser=> index\n(\"nobody\" \"'\" \"i\" \"m\" \".\" \"are\" \"who\" \"you\" \"?\" \"too\")\nuser=> (->> f-out\nsecond\nfirst\n (map-indexed vector)\n (remove #(zero? (second %)))\n (map first)\n (map #(nth index %)))\n(\"nobody\" \"'\" \"i\" \"m\" \".\")\n\n```", "```py\n(def unigrams identity)\n```", "```py\n(defn n-grams [n coll]\n  (map #(str/join \" \" %) (partition n 1 coll)))\n(defn bigrams [coll] (n-grams 2 coll))\n(defn trigrams [coll] (n-grams 3 coll))\n```", "```py\n(defn read-me-tagger [filename]\n  (->>filename\nio/input-stream\nPOSModel.\nPOSTaggerME.))\n```", "```py\n(defn with-pos [model coll]\n  (map #(str/join \"_\" [%1 %2])\ncoll\n       (.tag model (into-array coll))))\n```", "```py\nuser=> (def data\n \"Time flies like an arrow; fruit flies like a banana.\")\nuser=> (def tagger (t/read-me-tagger \"data/en-pos-maxent.bin\"))\nuser=> (def tokens (t/tokenize data))\nuser=> (t/unigrams tokens)\n(\"time\" \"flies\" \"like\" \"an\" \"arrow\" \";\" \"fruit\" \"flies\" \"like\" \"a\"\n \"banana\" \".\")\nuser=> (t/bigrams tokens)\n(\"time flies\" \"flies like\" \"like an\" \"an arrow\" \"arrow ;\"\n \"; fruit\" \"fruit flies\" \"flies like\" \"like a\" \"a banana\"\n \"banana .\")\nuser=> (t/trigrams tokens)\n(\"time flies like\" \"flies like an\" \"like an arrow\" \"an arrow ;\"\n \"arrow ; fruit\" \"; fruit flies\" \"fruit flies like\" \"flies like a\"\n \"like a banana\" \"a banana .\")\nuser=> (t/with-pos tagger tokens)\n(\"time_NN\" \"flies_VBZ\" \"like_IN\" \"an_DT\" \"arrow_NN\" \";_:\"\n \"fruit_NN\" \"flies_NNS\" \"like_IN\" \"a_DT\" \"banana_NN\" \"._.\")\n\n```", "```py\n(defn partition-spread [k coll]\n  (let [get-mod (fn [i x]\n                  [(mod i k) x])\nmap-second #(map second (second %))]\n    (->>coll\n      (map-indexed get-mod)\n      (group-by first)\n      (map map-second))))\n```", "```py\nuser=> (partition 4 (range 10))\n((0 1 2 3) (4 5 6 7))\nuser=> (partition-all 4 (range 10))\n((0 1 2 3) (4 5 6 7) (8 9))\nuser=> (xv/partition-spread 4 (range 10))\n((0 4 8) (1 5 9) (2 6) (3 7))\nuser=> (xv/partition-spread 3 (range 10))\n((0 3 6 9) (1 4 7) (2 5 8))\n\n```", "```py\n(defn step-folds-seq [folds steps]\n  (lazy-seq\n    (when-let [[s &ss] (seq steps)]\n      (let [[prefix [validation & suffix]] (split-at s folds)\ntraining (flatten (concat prefix suffix))\ncurrent [validation training]]\n        (cons current (step-folds-seq folds ss))))))\n(defn step-folds [folds]\n  (step-folds-seq folds (range (count folds))))\n```", "```py\nuser=> (xv/step-folds (xv/partition-spread 10 (range 10)))\n([(0) (1 2 3 4 5 6 7 8 9)] [(1) (0 2 3 4 5 6 7 8 9)]\n [(2) (0 1 3 4 5 6 7 8 9)] [(3) (0 1 2 4 5 6 7 8 9)]\n [(4) (0 1 2 3 5 6 7 8 9)] [(5) (0 1 2 3 4 6 7 8 9)]\n [(6) (0 1 2 3 4 5 7 8 9)] [(7) (0 1 2 3 4 5 6 8 9)]\n [(8) (0 1 2 3 4 5 6 7 9)] [(9) (0 1 2 3 4 5 6 7 8)])\n\n```", "```py\n(defn k-fold\n  ([train error combine data]\n   (k-fold train error combine 10 data))\n  ([train error combine k input-data]\n   (->> input-data\nshuffle\n     (partition-spread k)\nstep-folds\n     (map (fn [[v t]] [v (train t)]))\n     (map (fn [[v t]] [err (error t v)]\n                        (println :error err)\nerr)))\n     (reduce combine (combine)))))\n```", "```py\n(defnaccum-error [error-counts pair]\n  (let [get-key {[\"+\" \"+\"] :true-pos\n                 [\"-\" \"-\"] :true-neg\n                 [\"+\" \"-\"] :false-neg\n                 [\"-\" \"+\"] :false-pos}\nk (get-key pair)]\n    (assoc error-counts k (inc (error-counts k)))))\n```", "```py\n(defn summarize-error [error-counts]\n  (let [{:keys [true-pos false-pos true-neg false-neg]}\nerror-counts]\n    {:precision (float (/ true-pos (+ true-pos false-pos))),\n:recall (float (/ true-pos (+ true-pos false-neg)))}))\n```", "```py\n(defn compute-error [expecteds actuals]\n  (let [start {:true-neg 0, :false-neg 0, :true-pos 0,\n:false-pos 0}]\n    (summarize-error\n      (reduceaccum-error start (map vector expecteds actuals)))))\n```", "```py\n(defn mean-error [coll]\n  (let [start {:precision 0, :recall 0}\naccum (fn [a b]\n                {:precision (+ (:precision a) (:precision b))\n:recall (+ (:recall a) (:recall b))})\nsummarize (fn [n a]\n                    {:precision (/ (:precision a) n)\n:recall (/ (:recall a) n)})]\n    (summarize (count coll) (reduce accum start coll))))\n```", "```py\n(defn instances-attributes [f-index]\n  (let [attrs (->> f-index\n                (sort-by second)\n                (map #(Attribute. (first %)))\nArrayList.)\nreview (Attribute. \"review-rating\"\n                           (ArrayList. [\"+\" \"-\"]))]\n    (.add attrs review)\n    [attrs review]))\n```", "```py\n(defn review->instance [attrs review]\n  (let [i (SparseInstance. (.size attrs))]\n    (doseq [[attr value] (map vector attrs (:feature-vec review))]\n      (when-not (zero? value)\n        (.setValueiattr (double value))))\n    (.setValuei (last attrs) (:rating review))\ni))\n```", "```py\n(defn ->instances\n  ([f-index review-coll]\n   (->instances f-index review-coll \"hotel-reviews\"))\n  ([f-index review-coll name]\n   (let [[attrs review] (instances-attributes f-index)\ninstances (Instances. name attrs (count review-coll))]\n     (doseq [review review-coll]\n       (let [i (review->instance attrs review)]\n         (.add instances i)))\n     (.setClass instances review)\ninstances)))\n```", "```py\n(defn run-instance [classifier instances instance]\n  (let [dist (.distributionForInstance classifier instance)\ni (first (apply max-key second\n                       (map vector (range) dist)))]\n    (.. instances classAttribute (value i))))\n(defn run-classifier [classifier instances]\n  (map #(run-instance classifier instances %) instances))\n```", "```py\n(defn run-k-fold [trainer]\n  (fn [f-index coll]\n    (let [do-train (fn [xs]\n                     (let [is (w/->instances f-index xs)]\n                       (trainer is)))\ndo-test (fn [classifier xs]\n                    (->>xs\n                      (w/->instances f-index)\nw/filter-class-index\n                      (run-classifier classifier)\n                      (xv/compute-error (map :rating xs))\nvector))]\n      (xv/k-fold do-train do-test concat 10 coll))))\n```", "```py\n(w/defanalysis train-logistic Logistic buildClassifier\n  [[\"-D\" debugging false :flag-true]\n   [\"-R\" ridge nil :not-nil]\n   [\"-M\" max-iterations -1]])\n(def k-fold-logistic (run-k-fold train-logistic))\n```", "```py\n(w/defanalysis train-naive-bayesNaiveBayesbuildClassifier\n  [[\"-K\" kernel-density false :flag-true]\n   [\"-D\" discretization false :flag-true]])\n(def k-fold-naive-bayes (run-k-fold train-naive-bayes))\n```", "```py\n(def classifiers\n  {:naive-bayes a/k-fold-naive-bayes\n:maxent a/k-fold-logistic})\n(def feature-factories\n  {:unigram t/unigrams\n:bigram t/bigrams\n:trigram t/trigrams\n:pos (let [pos-model \n              (t/read-me-tagger \"data/en-pos-maxent.bin\")]\n          (fn [ts] (t/with-pos pos-model ts)))})\n```", "```py\n(defn do-class [f-key f-index features c-info]\n  (let [[c-key c] c-info, k [c-key f-key]]\n    (println k)\n    [k (x/mean-error (c f-index features))]))\n```", "```py\n(defn do-features [docs classifiers f-info]\n  (let [[f-key f] f-info\n        [f-index features] (d/add-features f docs)]\n    (map #(do-class f-key f-index features %) classifiers)))\n```", "```py\n(defn test-suite [docs]\n  (into {} (mapcat #(do-features docs classifiers %)\nfeature-factories)))\n```", "```py\nuser=> (def reviews (->> \"data/hotels-sample\" d/read-data\nd/sample vals flatten))\n#'user/reviews\nuser=> (c/test-suite reviews)\n[:naive-bayes :unigram]\n:error [{:precision 0.5185185, :recall 0.5}]\n:error [{:precision 0.6, :recall 0.5769231}]\n:error [{:precision 0.5185185, :recall 0.6666667}]\n```", "```py\n(defn f-score [error]\n  (let [{:keys [precision recall]} error]\n    (* 2 (/ (* precision recall) (+ precision recall)))))\n```"]