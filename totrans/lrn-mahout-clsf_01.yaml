- en: Chapter 1. Classification in Data Analysis
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第一章. 数据分析中的分类
- en: In the last decade, we saw a huge growth in social networking and e-commerce
    sites. I am sure that you must have got information about this book on Facebook,
    Twitter, or some other site. Chances are also high that you are reading an e-copy
    of this book after ordering it on your phone or tablet.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去十年中，我们见证了社交网络和电子商务网站的大幅增长。我确信你一定在Facebook、Twitter或其他网站上看到过这本书的信息。你也很可能在手机或平板电脑上订购后阅读了这本书的电子版。
- en: This must give you an idea of how much data we are generating over the Internet
    every single day. Now, in order to obtain all necessary information from the data,
    we not only create data but also store this data. This data is extremely useful
    to get some important insights into the business. The analysis of this data can
    increase the customer base and create profits for the organization. Take the example
    of an e-commerce site. You visit the site to buy some book. You get information
    about books on related topics or the same topic, publisher, or writer, and this
    helps you to take better decisions, which also helps the site to know more about
    its customers. This will eventually lead to an increase in sales.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 这必须让你意识到我们每天在互联网上生成多少数据。现在，为了从数据中获得所有必要的信息，我们不仅创建数据，还存储这些数据。这些数据对于获得对业务的某些重要见解极为有用。对这些数据的分析可以增加客户群并为企业创造利润。以电子商务网站为例。你访问网站购买书籍。你会得到关于相关主题或同一主题、出版社或作者的书籍信息，这有助于你做出更好的决定，同时也帮助网站更多地了解其客户。这最终将导致销售额的增加。
- en: Finding related items or suggesting a new item to the user is all part of the
    data science in which we analyze the data and try to get useful patterns.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 寻找相关项目或向用户推荐新项目都是数据分析的一部分，我们分析数据并试图获取有用的模式。
- en: Data analysis is the process of inspecting historical data and creating models
    to get useful information that is required to help in decision making. It is helpful
    in many industries, such as e-commerce, banking, finance, healthcare, telecommunications,
    retail, oceanography, and many more.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 数据分析是检查历史数据并创建模型以获取有助于决策的有用信息的流程。它在许多行业中都有帮助，例如电子商务、银行、金融、医疗保健、电信、零售、海洋学等等。
- en: Let's take the example of a weather forecasting system. It is a system that
    can predict the state of the atmosphere at a particular location. In this process,
    scientists collect historical data of the atmosphere of that location and try
    to create a model based on it to predict how the atmosphere will evolve over a
    period of time.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以天气预报系统为例。这是一个可以预测特定地点大气状态的系统。在这个过程中，科学家收集该地点的大气历史数据，并试图基于这些数据创建一个模型，以预测大气在一段时间内的演变。
- en: 'In machine learning, classification is the automation of the decision-making
    process that learns from examples of the past and emulates those decisions automatically.
    Emulating the decisions automatically is a core concept in predictive analytics.
    In this chapter, we will look at the following points:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中，分类是从过去的例子中学习并自动模拟这些决策的决策过程自动化。自动模拟决策是预测分析的核心概念。在本章中，我们将探讨以下要点：
- en: Understanding classification
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解分类
- en: Working of classification systems
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分类系统的工作原理
- en: Classification algorithms
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分类算法
- en: Model evaluation methods
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型评估方法
- en: Introducing the classification
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍分类
- en: The word classification always reminds us of our biology class, where we learned
    about the classification of animals. We learned about different categories of
    animals, such as mammals, reptiles, birds, amphibians, and so on.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 每当我们提到“分类”这个词时，总会让我们想起生物学课程，在那里我们学习了动物分类。我们学习了不同类别的动物，如哺乳动物、爬行动物、鸟类、两栖动物等等。
- en: If you remember how these categories are defined, you will realize that there
    were certain properties that scientists found in existing animals, and based on
    these properties, they categorized a new animal.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你记得这些类别是如何定义的，你就会意识到科学家在现有的动物中发现了某些特性，并且基于这些特性，他们对新的动物进行了分类。
- en: Other real-life examples of classification could be, for instance, when you
    visit the doctor. He/she asks you certain questions, and based on your answers,
    he/she is able to identify whether you have a certain disease or not.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 其他分类的实际例子可以是，例如，当你去看医生时。他会问你一些问题，然后根据你的回答，他能够判断你是否患有某种疾病。
- en: Classification is the categorization of potential answers, and in machine learning,
    we want to automate this process. Biological classification is an example of **multiclass**
    classification and finding the disease is an example of **binary** classification.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 分类是将潜在答案进行分类的过程，在机器学习中，我们希望自动化这个过程。生物分类是**多类**分类的一个例子，而发现疾病是**二元**分类的一个例子。
- en: In data analysis, we want to use machine learning concepts. To analyze the data,
    we want to build a system that can help us to find out which class an individual
    item belongs to. Usually, these classes are mutually exclusive. A related problem
    in this area is finding out the probability that an individual belongs to a certain
    class.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据分析中，我们希望使用机器学习概念。为了分析数据，我们希望构建一个系统，帮助我们找出单个项目属于哪个类别。通常，这些类别是互斥的。这个领域的一个相关问题是要找出单个属于某个特定类别的概率。
- en: 'Classification is a supervised learning technique. In this technique, machines—based
    on historical data—learn and gain the capabilities to predict the unknown. In
    machine learning, another popular technique is unsupervised learning. In supervised
    learning, we already know the output categories, but in unsupervised learning,
    we know nothing about the output. Let''s understand this with a quick example:
    suppose we have a fruit basket, and we want to classify fruits. When we say classify,
    it means that in the training data, we already have output variables, such as
    size and color, and we know whether the color is red and the size is from 2.3"
    to 3.7". We will classify that fruit as an apple. Opposite to this, in unsupervised
    learning, we want to separate different fruits, and we do not have any output
    information in the training dataset, so the learning algorithm will separate different
    fruits based on different features present in the dataset, but it will not be
    able to label them. In other words, it will not be able to tell which one is an
    apple and which one is a banana, although it will be able to separate them.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 分类是一种监督学习技术。在这种技术中，机器——基于历史数据——学习和获得预测未知的能力。在机器学习中，另一种流行的技术是无监督学习。在监督学习中，我们已经知道输出类别，但在无监督学习中，我们一无所知。让我们用一个快速例子来理解这一点：假设我们有一个水果篮，我们想要对水果进行分类。当我们说分类时，意味着在训练数据中，我们已经有输出变量，如大小和颜色，我们知道颜色是红色，大小在2.3"到3.7"之间。我们将该水果分类为苹果。与此相反，在无监督学习中，我们想要将不同的水果分开，在训练数据集中我们没有任何输出信息，因此学习算法将根据数据集中存在的不同特征来分离不同的水果，但它无法对它们进行标记。换句话说，它无法告诉哪个是苹果，哪个是香蕉，尽管它能够将它们分开。
- en: Application of the classification system
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分类系统的应用
- en: Classification is used for prediction. In the case of e-mail categorization,
    it is used to classify e-mail as spam or not spam. Nowadays, Gmail is classifying
    e-mails as primary, social, and promotional as well. Classification is useful
    in predicting credit card frauds, to categorize customers for eligibility of loans,
    and so on. It is also used to predict customer churn in the insurance and telecom
    industries. It is useful in the healthcare industry as well. Based on historical
    data, it is useful in classifying particular symptoms of a disease to predict
    the disease in advance. Classification can be used to classify tropical cyclones.
    So, it is useful across all industries.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 分类用于预测。在电子邮件分类的情况下，它用于将电子邮件分类为垃圾邮件或非垃圾邮件。如今，Gmail还将电子邮件分类为主要邮件、社交邮件和促销邮件。分类在预测信用卡欺诈、为贷款资格分类客户等方面非常有用。它也用于预测保险和电信行业的客户流失。在医疗保健行业也非常有用。基于历史数据，它有助于对疾病的特定症状进行分类，以提前预测疾病。分类可以用于分类热带气旋。因此，它在所有行业中都有用。
- en: Working of the classification system
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分类系统的运作原理
- en: Let's understand the classification process in more detail. In the process of
    classification, with the dataset given to us, we try to find out informative variables
    using which we can reduce the uncertainty and categorize something. These informative
    variables are called **explanatory variables** or features.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地了解分类过程。在分类过程中，我们使用给定的数据集，试图找到信息变量，通过这些变量我们可以减少不确定性并对某事物进行分类。这些信息变量被称为**解释变量**或特征。
- en: 'The final categories that we are interested are called target variables or
    labels. Explanatory variables can be any of the following forms:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们感兴趣的最后类别被称为目标变量或标签。解释变量可以是以下任何一种形式：
- en: Continuous (numeric types)
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 连续的（数值类型）
- en: Categorical
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分类别
- en: Word-like
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 类似于单词的
- en: Text-like
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 类似于文本的
- en: Note
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: If numeric types are not useful for any mathematical functions, those will be
    counted as categorical (zip codes, street numbers, and so on).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 如果数值类型对任何数学函数都没有用，那么这些将被视为分类数据（如邮政编码、街道号码等）。
- en: 'So, for example, we have a dataset of customer''s'' loan applications, and
    we want to build a classifier to find out whether a new customer is eligible for
    a loan or not. In this dataset, we can have the following fields:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们有一个客户贷款申请的数据集，我们想要构建一个分类器来找出新客户是否有资格获得贷款。在这个数据集中，我们可以有以下字段：
- en: '**Customer Age**'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**客户年龄**'
- en: '**Customer Income (PA)**'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**客户收入（PA**）'
- en: '**Customer Account Balance**'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**客户账户余额**'
- en: '**Loan Granted**'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**贷款批准**'
- en: 'From these fields, **Customer Age**, **Customer Income (PA)** and **Customer
    Account Balance** will work as explanatory variables and **Loan Granted** will
    be the target variable, as shown in the following screenshot:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 从这些字段中，**客户年龄**、**客户收入（PA**）和**客户账户余额**将作为解释变量，**贷款批准**将是目标变量，如下截图所示：
- en: '![Working of the classification system](img/4959OS_01_01.jpg)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![分类系统的工作原理](img/4959OS_01_01.jpg)'
- en: 'To understand the creation of the classifier, we need to understand a few terms,
    as shown in the following diagram:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解分类器的创建，我们需要了解一些术语，如下面的图所示：
- en: '![Working of the classification system](img/4959OS_01_02.jpg)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![分类系统的工作原理](img/4959OS_01_02.jpg)'
- en: '**Training dataset**: From the given dataset, a portion of the data is used
    to create the training dataset (it could be 70 percent of the given data). This
    dataset is used to build the classifier. All the feature sets are used in this
    dataset.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**训练数据集**：从给定的数据集中，一部分数据被用来创建训练数据集（可能是给定数据的70%）。这个数据集用于构建分类器。在这个数据集中使用了所有的特征集。'
- en: '**Test dataset**: The dataset that is left after the training dataset is used
    to test the created model. With this data, only the feature set is used and the
    model is used to predict the target variables or labels.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**测试数据集**：在训练数据集被使用后剩下的数据集用于测试创建的模型。使用这些数据，仅使用特征集，并使用模型来预测目标变量或标签。'
- en: '**Model**: This is used to understand the algorithm used to generate the target
    variables.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型**：这是用来理解生成目标变量的算法。'
- en: 'While building a classifier, we follow these steps:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建分类器时，我们遵循以下步骤：
- en: Collecting historical data
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 收集历史数据
- en: Cleaning data (a lot of activities are involved here, such as space removal,
    and so on)
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 清洗数据（这里涉及许多活动，如空格删除等）
- en: Defining target variables
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义目标变量
- en: Defining explanatory variables
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义解释变量
- en: Selecting an algorithm
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择算法
- en: Training the model (using the training dataset)
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练模型（使用训练数据集）
- en: Running test data
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行测试数据
- en: Evaluating the model
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估模型
- en: Adjusting explanatory variables
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调整解释变量
- en: Rerunning the test
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重新运行测试
- en: While preparing the model, one should take care of outlier detection. **Outlier
    detection** is a method to find out items that do not conform to an expected pattern
    in a dataset. Outliers in an input dataset can mislead the training process of
    an algorithm. This can affect the model accuracy. There are algorithms to find
    out these outliers in the datasets. Distance-based techniques and fuzzy-logic-based
    methods are mostly used to find out outliers in the dataset. Let's talk about
    one example to understand the outliers.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在准备模型时，应注意异常值检测。**异常值检测**是一种找出数据集中不符合预期模式的项目的方法。输入数据集中的异常值可能会误导算法的训练过程。这可能会影响模型精度。有一些算法可以找出数据集中的这些异常值。基于距离的技术和基于模糊逻辑的方法通常用于找出数据集中的异常值。让我们通过一个例子来了解异常值。
- en: 'We have a set of numbers, and we want to find out the mean of these numbers:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有一组数字，我们想要找出这些数字的平均值：
- en: 10, 75, 10, 15, 20, 85, 25, 30, 25
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 10, 75, 10, 15, 20, 85, 25, 30, 25
- en: 'Just plot these numbers and the result will be as shown in the following screenshot:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 只需绘制这些数字，结果将如以下截图所示：
- en: '![Working of the classification system](img/4959OS_01_03.jpg)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![分类系统的工作原理](img/4959OS_01_03.jpg)'
- en: Clearly, the numbers 75 and 85 are outliers (far away in the plot from the other
    numbers).
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，数字75和85是异常值（在图中远离其他数字）。
- en: Mean = sum of values/number of values = 32.78
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 平均值 = 值的总和/值的数量 = 32.78
- en: 'Mean without the outliers: = 19.29'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 去除异常值后的平均值：= 19.29
- en: So, now you can understand how outliers can affect the results.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，现在你可以理解异常值如何影响结果。
- en: While creating the model, we can encounter two majorly occurring problems—**Overfitting**
    and **Underfitting**.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建模型时，我们可能会遇到两个主要问题——**过拟合**和**欠拟合**。
- en: Overfitting occurs when the algorithm captures the noise of the data, and the
    algorithm fits the data too well. Generally, it occurs if we use all the given
    data to build the model using pure memorization. Instead of finding out the generalizing
    pattern, the model just memorizes the pattern. Usually, in the case of overfitting,
    the model gets more complex, and it is allowed to pick up spurious correlations.
    These correlations are specific to training datasets and do not represent characteristics
    of the whole dataset in general.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 当算法捕捉到数据的噪声，并且算法拟合数据过于完美时，就会发生过拟合。通常，如果我们使用所有给定数据通过纯记忆来构建模型时，会发生过拟合。模型不是找出泛化模式，而是仅仅记住模式。通常，在过拟合的情况下，模型变得更加复杂，并且允许它选择虚假的相关性。这些相关性仅针对训练数据集，并不代表整个数据集的一般特征。
- en: 'The following diagram is an example of overfitting. An outlier is present,
    and the algorithm considers that and creates a model that perfectly classifies
    the training set, but because of this, the test data is wrongly classified (both
    the rectangles are classified as stars in the test data):'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表是过拟合的一个例子。存在一个异常值，算法考虑了这一点，并创建了一个完美分类训练集的模型，但由于这一点，测试数据被错误分类（测试数据中的两个矩形都被分类为星星）：
- en: '![Working of the classification system](img/4959OS_01_04.jpg)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![分类系统的工作原理](img/4959OS_01_04.jpg)'
- en: There is no single method to avoid overfitting; however, we have some approaches,
    such as a reduction in the number of features and the regularization of a few
    of the features. Another way is to train the model with some dataset and test
    with the remaining dataset. A common method called cross-validation is used to
    generate multiple performance measures. In this way, a single dataset is split
    and used for the creation of performance measures.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 没有一种单一的方法可以避免过拟合；然而，我们有一些方法，例如减少特征数量和将一些特征进行正则化。另一种方法是使用一些数据集来训练模型，并使用剩余的数据集进行测试。一种常用的方法称为交叉验证，用于生成多个性能指标。这样，单个数据集被分割并用于创建性能指标。
- en: Underfitting occurs when the algorithm cannot capture the patterns in the data,
    and the data does not fit well. Underfitting is also known as high bias. It means
    your algorithm has such a strong bias towards its hypothesis that it does not
    fit the data well. For an underfitting error, more data will not help. It can
    increase the training error. More explanatory variables can help to deal with
    the underfitting problem. More explanatory fields will expand the hypothesis space
    and will be useful to overcome this problem.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 当算法无法捕捉数据中的模式，并且数据拟合得不好时，就会发生欠拟合。欠拟合也称为高偏差。这意味着你的算法对其假设有如此强烈的偏差，以至于它无法很好地拟合数据。对于欠拟合错误，更多的数据不会有所帮助。它可能会增加训练错误。更多的解释变量可以帮助处理欠拟合问题。更多的解释字段会扩展假设空间，并有助于克服这个问题。
- en: Both overfitting and underfitting provide poor results with new datasets.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 无论是过拟合还是欠拟合，在使用新数据集时都会产生较差的结果。
- en: Classification algorithms
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分类算法
- en: 'We will now discuss the following algorithms that are supported by Apache Mahout
    in this book:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将讨论本书中由Apache Mahout支持的以下算法：
- en: '**Logistic regression / Stochastic Gradient Descent (SGD)**: We usually read
    regression along with classification, but actually, there is a difference between
    the two. Classification involves a categorical target variable, while regression
    involves a numeric target variable. Classification predicts whether something
    will happen, and regression predicts how much of something will happen. We will
    cover this algorithm in [Chapter 3](ch03.html "Chapter 3. Learning Logistic Regression
    / SGD Using Mahout"), *Learning Logistic Regression / SGD Using Mahout*. Mahout
    supports logistic regression trained via Stochastic Gradient Descent.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**逻辑回归 / 随机梯度下降（SGD）**：我们通常将回归与分类一起阅读，但实际上，两者之间是有区别的。分类涉及分类目标变量，而回归涉及数值目标变量。分类预测某事是否会发生，而回归预测某事会发生多少。我们将介绍这个算法在[第3章](ch03.html
    "第3章。使用Mahout学习逻辑回归/随机梯度下降") *学习逻辑回归/随机梯度下降使用Mahout* 中。Mahout支持通过随机梯度下降训练的逻辑回归。'
- en: '**Naïve Bayes classification**: This is a very popular algorithm for text classification.
    Naïve Bayes uses the concept of probability to classify new items. It is based
    on the Bayes theorem. We will discuss this algorithm in [Chapter 4](ch04.html
    "Chapter 4. Learning the Naïve Bayes Classification Using Mahout"), *Learning
    the Naïve Bayes Classification Using Mahout*. In this chapter, we will see how
    Mahout is useful in classifying text, which is required in the data analysis field.
    We will discuss vectorization, bag of words, n-grams, and other terms used in
    text classification.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**朴素贝叶斯分类**：这是文本分类中非常流行的一个算法。朴素贝叶斯使用概率的概念来分类新项目。它基于贝叶斯定理。我们将在[第4章](ch04.html
    "第4章。使用Mahout学习朴素贝叶斯分类")，*使用Mahout学习朴素贝叶斯分类*中讨论这个算法。在这一章中，我们将看到Mahout在文本分类方面的应用，这在数据分析领域是必需的。我们将讨论向量化、词袋、n-gram以及文本分类中使用的其他术语。'
- en: '**Hidden Markov Model (HMM)**: This is used in various fields, such as speech
    recognition, parts-of-speech tagging, gene prediction, time-series analysis, and
    so on. In HMM, we observe a sequence of emissions but do not have a sequence of
    states which a model uses to generate the emission. In [Chapter 5](ch05.html "Chapter 5. Learning
    the Hidden Markov Model Using Mahout"), *Learning the Hidden Markov Model Using
    Mahout*, we will take one more algorithm supported by Mahout Hidden Markov Model.
    We will discuss HMM in detail and see how Mahout supports this algorithm.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**隐马尔可夫模型（HMM）**：它在各种领域都有应用，如语音识别、词性标注、基因预测、时间序列分析等。在HMM中，我们观察到一系列的发射序列，但没有模型使用的状态序列来生成发射。在[第5章](ch05.html
    "第5章。使用Mahout学习隐马尔可夫模型")，*使用Mahout学习隐马尔可夫模型*中，我们将讨论另一个由Mahout支持的算法。我们将详细讨论HMM，并了解Mahout如何支持这个算法。'
- en: '**Random Forest**: This is the most widely used algorithm in classification.
    Random Forest consists of a collection of simple tree predictors, each capable
    of producing a response when presented with a set of explanatory variables. In
    [Chapter 6](ch06.html "Chapter 6. Learning Random Forest Using Mahout"), *Learning
    Random Forest Using Mahout*, we will discuss this algorithm in detail and also
    talk about how to use Mahout to implement this algorithm.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**随机森林**：这是分类中最广泛使用的算法。随机森林由一组简单的树预测器组成，每个预测器都能在给定一组解释变量时产生响应。在[第6章](ch06.html
    "第6章。使用Mahout学习随机森林")，*使用Mahout学习随机森林*中，我们将详细讨论这个算法，并讨论如何使用Mahout实现这个算法。'
- en: '**Multi-layer Perceptron (MLP)**: In [Chapter 7](ch07.html "Chapter 7. Learning
    Multilayer Perceptron Using Mahout"), *Learning Multilayer Perceptron Using Mahout*,
    we will discuss this newly implemented algorithm in Mahout. An MLP consists of
    multiple layers of nodes in a directed graph, with each layer fully connected
    to the next one. It is a base for the implementation of neural networks. We will
    discuss neural networks a little but only after a detailed discussion on MLP in
    Mahout.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多层感知器（MLP）**：在[第7章](ch07.html "第7章。使用Mahout学习多层感知器")，*使用Mahout学习多层感知器*中，我们将讨论Mahout中新实现的这个算法。MLP由一个有向图中的多个层节点组成，每一层都与下一层完全连接。它是神经网络实现的基础。我们将在详细讨论Mahout中的MLP之后，简要讨论神经网络。'
- en: We will discuss all the classification algorithms supported by Apache Mahout
    in this book, and we will also check the model evaluation techniques provided
    by Apache Mahout.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本书中讨论Apache Mahout支持的所有的分类算法，并检查Apache Mahout提供的模型评估技术。
- en: Model evaluation techniques
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型评估技术
- en: 'We cannot have a single evaluation metric that can fit all the classifier models,
    but we can find out some common issues in evaluation, and we have techniques to
    deal with them. We will discuss the following techniques that are used in Mahout:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不能有一个单一的评估指标来适应所有的分类器模型，但我们可以找出评估中的一些常见问题，并且我们有技术来处理这些问题。我们将在Mahout中使用以下技术进行讨论：
- en: Confusion matrix
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 混淆矩阵
- en: ROC graph
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ROC图
- en: AUC
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AUC
- en: Entropy matrix
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 熵矩阵
- en: The confusion matrix
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 混淆矩阵
- en: 'The confusion matrix provides us with the number of correct and incorrect predictions
    made by the model compared with the actual outcomes (target values) in the data.
    A confusion matrix is a N*N matrix, where N is the number of labels (classes).
    Each column is an instance in the predicted class, and each row is an instance
    in the actual class. Using this matrix, we can find out how one class is confused
    with another. Let''s assume that we have a classifier that classifies three fruits:
    strawberries, cherries, and grapes. Assuming that we have a sample of 24 fruits:
    7 strawberries, 8 cherries, and 9 grapes, the resulting confusion matrix will
    be as shown in the following table:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 混淆矩阵为我们提供了模型与数据中实际结果（目标值）相比所做出的正确和错误预测的数量。混淆矩阵是一个 N*N 矩阵，其中 N 是标签（类别）的数量。每一列是预测类中的一个实例，每一行是实际类中的一个实例。使用这个矩阵，我们可以找出一个类别是如何与其他类别混淆的。假设我们有一个将三种水果分类的分类器：草莓、樱桃和葡萄。假设我们有24个水果的样本：7个草莓，8个樱桃和9个葡萄，得到的混淆矩阵如下表所示：
- en: '| Predicted classes by model |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| 模型预测的类别 |'
- en: '| --- |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| **Actual class** |   | **Strawberries** | **Cherries** | **Grapes** |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| **实际类别** |   | **草莓** | **樱桃** | **葡萄** |'
- en: '| **Strawberries** | 4 | 3 | 0 |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| **草莓** | 4 | 3 | 0 |'
- en: '| **Cherries** | 2 | 5 | 1 |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| **樱桃** | 2 | 5 | 1 |'
- en: '| **Grapes** | 0 | 1 | 8 |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| **葡萄** | 0 | 1 | 8 |'
- en: So, in this model, from the 8 strawberries, 3 were classified as cherries. From
    the 8 cherries, 2 were classified as strawberries, and 1 is classified as a grape.
    From the 9 grapes, 1 is classified as a cherry. From this matrix, we will create
    the table of confusion. The table of confusion has two rows and two columns that
    report about true positive, true negative, false positive, and false negative.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在这个模型中，从8个草莓中，有3个被分类为樱桃。从8个樱桃中，有2个被分类为草莓，1个被分类为葡萄。从9个葡萄中，有1个被分类为樱桃。从这个矩阵中，我们将创建混淆表格。混淆表格有两行两列，报告关于真阳性、真阴性、假阳性和假阴性的信息。
- en: 'So, if we build this table for a particular class, let''s say for strawberries,
    it would be as follows:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果我们为特定类别构建这个表格，比如说草莓，它会是这样的：
- en: '| **True Positive**4 (actual strawberries classified correctly) (a) | **False
    Positive**2 (cherries that were classified as strawberries)(b) |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| **真阳性**4（正确分类的实际草莓）(a) | **假阳性**2（被分类为草莓的樱桃）(b) |'
- en: '| **False Negative**3 (strawberries wrongly classified as cherries) (c) | **True
    Negative**15 (all other fruits correctly not classified as strawberries) (d) |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| **假阴性**3（错误分类为樱桃的草莓）(c) | **真阴性**15（所有其他水果正确地没有被分类为草莓）(d) |'
- en: 'Using this table of confusion, we can find out the following terms:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个混淆表格，我们可以找出以下术语：
- en: '**Accuracy**: This is the proportion of the total number of predictions that
    were correctly classified. It is calculated as (True Positive + True Negative)
    / Positive + Negative. Therefore, *accuracy = (a+d)/(a+b+c+d)*.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**准确率**：这是正确分类的总预测数与预测总数的比例。它计算为（真阳性 + 真阴性）/ 阳性 + 阴性。因此，*准确率 = (a+d)/(a+b+c+d)*。'
- en: '**Precision or positive predictive value**: This is the proportion of positive
    cases that were correctly classified. It is calculated as (True Positive)/(True
    Positive + False Positive). Therefore, *precision = a/(a+b)*.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**精确率或阳性预测值**：这是正确分类的阳性案例的比例。它计算为（真阳性）/（真阳性 + 假阳性）。因此，*精确率 = a/(a+b)*。'
- en: '**Negative predictive value**: This is the proportion of negative cases that
    were classified correctly. It is calculated as True Negative/(True Negative +
    False Negative). Therefore, *negative predictive value = d/(c+d)*.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**阴性预测值**：这是正确分类的阴性案例的比例。它计算为真阴性/(真阴性 + 假阴性)。因此，*阴性预测值 = d/(c+d)*。'
- en: '**Sensitivity / true positive rate / recall**: This is the proportion of the
    actual positive cases that were correctly identified. It is calculated as True
    Positive/(True Positive + False Negative). Therefore, *sensitivity = a/(a+c)*.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**灵敏度/真阳性率/召回率**：这是正确识别的实际阳性案例的比例。它计算为真阳性/(真阳性 + 假阴性)。因此，*灵敏度 = a/(a+c)*。'
- en: '**Specificity**: This is the proportion of the actual negative cases. It is
    calculated as *True Negative/(False Positive + True Negative)*. Therefore, *specificity
    =d /(b+d)*.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特异性**：这是实际阴性案例的比例。它计算为 *真阴性/(假阳性 + 真阴性)*。因此，*特异性 = d/(b+d)*。'
- en: '**F1 score**: This is the measure of a test''s accuracy, and it is calculated
    as follows: *F1 = 2.((Positive predictive value (precision) * sensitivity (recall))/(Positive
    predictive* *value (precision) +sensitivity (recall)))*.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**F1分数**：这是测试准确度的度量，其计算如下：*F1 = 2.((阳性预测值（精确度）* 灵敏度（召回率))/(阳性预测值（精确度）+ 灵敏度（召回率)))*。'
- en: The Receiver Operating Characteristics (ROC) graph
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 接收者操作特征（ROC）图
- en: 'ROC is a two-dimensional plot of a classifier with false positive rate on the
    *x* axis and true positive rate on the *y* axis. The lower point (0,0) in the
    figure represents never issuing a positive classification. Point (0,1) represents
    perfect classification. The diagonal from (0,0) to (1,1) divides the ROC space.
    Points above the diagonal represent good classification results, and points below
    the line represent poor results, as shown in the following diagram:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: ROC是分类器的二维图，其假阳性率在x轴上，真阳性率在y轴上。图中的低点（0,0）表示从不发出阳性分类。点（0,1）表示完美分类。从（0,0）到（1,1）的对角线将ROC空间分割。对角线以上的点表示好的分类结果，而对角线以下的点表示差的结果，如下面的图所示：
- en: '![The Receiver Operating Characteristics (ROC) graph](img/4959OS_01_05.jpg)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![接收者操作特征（ROC）图](img/4959OS_01_05.jpg)'
- en: Area under the ROC curve
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ROC曲线下的面积
- en: This is the area under the ROC curve and is also known as AUC. It is used to
    measure the quality of the classification model. In practice, most of the classification
    models have an AUC between 0.5 and 1\. The closer the value is to 1, the greater
    is your classifier.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 这是ROC曲线下的面积，也称为AUC。它用于衡量分类模型的质量。在实践中，大多数分类模型的AUC值介于0.5和1之间。该值越接近1，你的分类器就越强大。
- en: The entropy matrix
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 熵矩阵
- en: Before going into the details of the entropy matrix, first we need to understand
    **entropy**. The concept of entropy in information theory was developed by Shannon.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入了解熵矩阵之前，我们首先需要理解**熵**。信息论中熵的概念是由香农提出的。
- en: 'Entropy is a measure of disorder that can be applied to a set. It is defined
    as:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 熵是应用于集合的混乱度度量。它被定义为：
- en: '*Entropy = -p1log(p1) – p2log(p2)- …….*'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '*熵 = -p1log(p1) – p2log(p2)- …….*'
- en: 'Each p is the probability of a particular property within the set. Let''s revisit
    our customer loan application dataset. For example, assuming we have a set of
    10 customers from which 6 are eligible for a loan and 4 are not. Here, we have
    two properties (classes): eligible or not eligible.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 每个p是该集合中特定属性的概率。让我们回顾一下我们的客户贷款申请数据集。例如，假设我们有10个客户，其中6个有资格贷款，4个没有。在这里，我们有两个属性（类别）：合格或不合格。
- en: '*P(eligible) = 6/10 = 0.6*'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '*P(合格) = 6/10 = 0.6*'
- en: '*P(not eligible) = 4/10 = 0.4*'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '*P(不合格) = 4/10 = 0.4*'
- en: 'So, entropy of the dataset will be:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，数据集的熵将是：
- en: '*Entropy = -[0.6*log2(0.6)+0.4*log2(0.4)]*'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '*熵 = -[0.6*log2(0.6)+0.4*log2(0.4)]*'
- en: '*= -[0.6*-0.74 +0.4*-1.32]*'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '*= -[0.6*-0.74 +0.4*-1.32]*'
- en: '*= 0.972*'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '*= 0.972*'
- en: 'Entropy is useful in acquiring knowledge of information gain. Information gain
    measures the change in entropy due to any new information being added in model
    creation. So, if entropy decreases from new information, it indicates that the
    model is performing well now. Information gain is calculated as:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 熵在获取信息增益知识方面很有用。信息增益衡量由于在模型创建过程中添加任何新信息而导致的熵的变化。因此，如果熵由于新信息而减少，这表明模型现在表现良好。信息增益的计算如下：
- en: '*IG (classes , subclasses) = entropy(class) –(p(subclass1)*entropy(subclass1)+
    p(subclass2)*entropy(subclass2) + …)*'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '*IG (类别，子类别) = 熵(类别) –(p(子类别1)*熵(子类别1)+ p(子类别2)*熵(子类别2) + …)*'
- en: Entropy matrix is basically the same as the confusion matrix defined earlier;
    the only difference is that the elements in the matrix are the averages of the
    log of the probability score for each true or estimated category combination.
    A good model will have small negative numbers along the diagonal and will have
    large negative numbers in the off-diagonal position.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 熵矩阵基本上与之前定义的混淆矩阵相同；唯一的区别是矩阵中的元素是每个真实或估计类别组合的概率得分的对数平均。一个好的模型将对角线上的数字将是小的负数，而在对角线位置将有大的负数。
- en: Summary
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: We have discussed classification and its applications and also what algorithm
    and classifier evaluation techniques are supported by Mahout. We discussed techniques
    like confusion matrix, ROC graph, AUC, and entropy matrix.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经讨论了分类及其应用，以及Mahout支持哪些算法和分类器评估技术。我们讨论了如混淆矩阵、ROC图、AUC和熵矩阵等技术。
- en: Now, we will move to the next chapter and set up Apache Mahout and the developer
    environment. We will also discuss the architecture of Apache Mahout and find out
    why Mahout is a good choice for classification.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将进入下一章，设置Apache Mahout和开发环境。我们还将讨论Apache Mahout的架构，并找出为什么Mahout是分类的一个好选择。
