["```py\nreg = r\"Barack\\s(Hussein\\s)?Obama\"  \n```", "```py\n import spacy\n from spacy.matcher import Matcher\n nlp = spacy.load(\"en\")\n doc = nlp(\"Good morning, I want to reserve a ticket.\")\n matcher = Matcher(nlp.vocab)\n pattern = [{\"LOWER\": \"good\"}, {\"LOWER\": \"morning\"}, \n            {\"IS_PUNCT\": True}]\n matcher.add(\"morningGreeting\", None, pattern)\n matches = matcher(doc)\n for match_id, start, end in matches:\n     m_span = doc[start:end]  \n     print(start, end, m_span.text)\n...\n0 3 Good morning,\n```", "```py\npattern = [{\"LOWER\": \"good\"}, {\"LOWER\": \"morning\"}, \n           {\"IS_PUNCT\": True}]\n```", "```py\n import spacy\n from spacy.matcher import Matcher\n nlp = spacy.load(\"en\")\n doc = nlp(\"Good morning, I want to reserve a ticket. I will then say good evening!\")\n matcher = Matcher(nlp.vocab)\n pattern1 = [{\"LOWER\": \"good\"}, {\"LOWER\": \"morning\"}, \n             {\"IS_PUNCT\": True}]\n matcher.add(\"morningGreeting\",  [pattern1])\n pattern2 = [{\"LOWER\": \"good\"}, {\"LOWER\": \"evening\"}, \n             {\"IS_PUNCT\": True}]\n matcher.add(\"eveningGreeting\",  [pattern2])\n matches = matcher(doc)\n for match_id, start, end in matches:\n     pattern_name = nlp.vocab_strings[match_id]\n     m_span = doc[start:end]  \n     print(pattern_name, start, end, m_span.text)\n...\nmorningGreeting 0 3 Good morning,\neveningGreeting 15 18 good evening!\n```", "```py\n pattern = [{\"TEXT\": \"Bill\"}]\n```", "```py\n doc = nlp(\"I bought a pineapple.\")\n matcher = Matcher(nlp.vocabulary)\n pattern = [{\"LENGTH\": 1}]\n matcher.add(\"onlyShort\",  [pattern])\n matches = matcher(doc)\n for mid, start, end in matches:\n     print(start, end, doc[start:end])\n...\n0 1 I\n2 3 a\n```", "```py\n doc1 = nlp(\"I met him at 2 o'clock.\")\n doc2 = nlp(\"He brought me 2 apples.\")\n pattern = [{\"IS_DIGIT\": True},{\"IS_ALPHA\": True}] \n matcher.add(\"numberAndPlainWord\",  [pattern])\n matcher(doc1)\n[]\n matches = matcher(doc2)\n len(matches)\n1\n mid, start, end = matches[0]\n print(start, end, doc2[start:end])\n3, 5, 2 apples\n```", "```py\n doc = nlp(\"Take me out of your SPAM list. We never asked you to contact me. If you write again we'll SUE!!!!\")\n pattern = [{\"IS_UPPER\": True}]\n matcher.add(\"capitals\",  [pattern])\n matches = matcher(doc)\n for mid, start, end in matches:\n     print(start, end, doc[start:end])\n...\n5, 6, SPAM\n22, 23, SUE\n```", "```py\n doc1 = nlp(\"Can you swim?\")\n doc2 = nlp(\"Can Sally swim?\")\n pattern = [{\"IS_SENT_START\": True, \"LOWER\": \"can\"},\n            {\"IS_TITLE\": True}]\n matcher.add(\"canThenCapitalized\",  [pattern])\n matcher(doc)\n[]\n matches = matcher(doc2)\n len(matches)\n1\n mid, start, end = matches[0]\n print(start, end, doc2[start:end])\n0, 2, Can Sally\n```", "```py\n doc = nlp(\"Will you go there?')\n pattern = [{\"IS_SENT_START\": True, \"TAG\": \"MD\"}]\n matcher.add([pattern])\n matches = matcher(doc)\n len(matches)\n1\n mid, start, end = matches[0]\n print(start, end, doc[start:end])\n0, 1, Will\n doc2 = nlp(\"I might go there.\")\n matcher(doc2)\n[]\n```", "```py\n doc = nlp(\"Good morning, I'm here. I'll say good evening!!\")\n pattern = [{\"LOWER\": \"good\"},\n            {\"LOWER\": {\"IN\": [\"morning\", \"evening\"]}},\n            {\"IS_PUNCT\": True}]\n matcher.add(\"greetings\",  [pattern])\n matches = matcher(doc)\n for mid, start, end in matches:\n     print(start, end, doc[start:end])\n...\n0, 3, Good morning,\n10, 13, good evening!\n```", "```py\n doc = nlp(\"I suffered from Trichotillomania when I was in college. The doctor prescribed me Psychosomatic medicine.\")\n pattern = [{\"LENGTH\": {\">=\" : 10}}]\n matcher.add(\"longWords\",  [pattern])\n matches = matcher(doc)\n for mid, start, end in matches:\n     print(start, end, doc[start:end])\n...\n3, 4, Trichotillomania\n14, 15, Psychosomatic\n```", "```py\nR\"Barack\\s(Hussein\\s)?Obama\n```", "```py\n doc1 = nlp(\"Barack Obama visited France.\")\n doc2 = nlp(\"Barack Hussein Obama visited France.\")\n pattern = [{\"LOWER\": \"barack\"},\n            {\"LOWER\": \"hussein\", \"OP\": \"?\"},\n            {\"LOWER\": \"obama\"}]\n matcher.add(\"obamaNames\",  [pattern])\n matcher(doc1)\n[(1881848298847208418, 0, 2)]\n matcher(doc2)\n[(1881848298847208418, 0, 3)]\n```", "```py\n doc1 = nlp(\"Hello hello hello, how are you?\")\n doc2 = nlp(\"Hello, how are you?\")\n doc3 = nlp(\"How are you?\")\n pattern = [{\"LOWER\": {\"IN\": [\"hello\", \"hi\", \"hallo\"]},\n             “OP”:”*”, {\"IS_PUNCT\": True}]\n matcher.add(\"greetings\",  [pattern])\n for mid, start, end in matcher(doc1):\n     print(start, end, doc1[start:end])\n... \n2, 4, hello,\n1, 4, hello hello,\n0, 4, Hello hello hello,\n for mid, start, end in matcher(doc2):\n     print(start, end, doc2[start:end])\n... \n0 2 Hello, \nmatcher(doc3)\n...\n[]\n```", "```py\ndoc1 = nlp(\"Hello hello hello, how are you?\")\ndoc2 = nlp(\"Hello, how are you?\")doc3 = nlp(\"How are you?\")\npattern = [{\"LOWER\": {\"IN\": [\"hello\", \"hi\", \"hallo\"]},\n            \"OP\": \"+\"}, {\"IS_PUNCT\": True}]\nmatcher.add(\"greetings\",  [pattern])\nfor mid, start, end in matcher(doc1):\n     print(start, end, doc1[start:end])\n...\n(0, 4, Hello hello hello,)\n(1, 4, hello hello,)\n(2, 4, hello,)\n(3, 4, ,)\n(7, 8, ?)\nfor mid, start, end in matcher(doc2):\n     start, end, doc2[start:end]\n... \n(0, 2, hello,)\n(1, 2, ,)\n(5, 6, ?)\nfor mid, start, end in matcher(doc3):\n     start, end, doc3[start:end]\n... \n(3, 4, ?)\n```", "```py\ndoc = nlp(\"My name is Alice and his name was Elliot.\")\npattern = [{\"LOWER\": \"name\"},{\"LEMMA\": \"be\"},{}]\nmatcher.add(\"pickName\", [pattern])\nfor mid, start, end in matcher(doc):\n     print(start, end, doc[start:end])\n... \n1 4 name is Alice\n6 9 name was Elliot\n```", "```py\ndoc1 = nlp(\"I forwarded his email to you.\")\ndoc2 = nlp(\"I forwarded an email to you.\")\ndoc3 = nlp(\"I forwarded the email to you.\")\npattern = [{\"LEMMA\": \"forward\"}, {}, {\"LOWER\": \"email\"}]\nmatcher.add(\"forwardMail\",  [pattern])\nfor mid, start, end in matcher(doc1):\n     print(start, end, doc1[start:end])\n... \n1 4 forwarded his email\nfor mid, start, end in matcher(doc2):\n     print(start, end, doc2[start:end])\n... \n1 4 forwarded an email\nfor mid, start, end in matcher(doc3):\n.    print(start, end, doc3[start:end])\n... \n1 4 forwarded the email\n```", "```py\ndoc1 = nlp(\"I travelled by bus.\")\ndoc2 = nlp(\"She traveled by bike.\")\npattern = [{\"POS\": \"PRON\"}, \n           {\"TEXT\": {\"REGEX\": \"[Tt]ravell?ed\"}}]\nfor mid, start, end in matcher(doc1):\n     print(start, end, doc1[start:end])\n... \n0 2 I traveled\nfor mid, start, end in matcher(doc2):\n     print(start, end, doc2[start:end])\n... \n0 2 I travelled\n```", "```py\ndoc = nlp(\"I went to Italy; he has been there too. His mother also has told me she wants to visit Rome.\")\npattern = [{\"TAG\": {\"REGEX\": \"^V\"}}] \nmatcher.add(\"verbs\",  [pattern])\nfor mid, start, end in matcher(doc):\n    print(start, end, doc1[start:end])\n... \n1 2 went\n6 7 has\n7 8 been\n14 15 has\n15 16 told\n18 19 wants\n20 21 visit\n```", "```py\nimport spacy\nfrom spacy.matcher import PhraseMatcher\nnlp = spacy.load(\"en_core_web_md\")\nmatcher = PhraseMatcher(nlp.vocab)\nterms = [\"Angela Merkel\", \"Donald Trump\", \"Alexis Tsipras\"]\npatterns = [nlp.make_doc(term) for term in terms]\nmatcher.add(\"politiciansList\", None, *patterns)\ndoc = nlp(\"3 EU leaders met in Berlin. German chancellor Angela Merkel first welcomed the US president Donald Trump. The following day Alexis Tsipras joined them in Brandenburg.\")\nmatches = matcher(doc)\nfor mid, start, end in matches:\n    print(start, end, doc[start:end])\n…\n9 11 Angela Merkel\n16 18 Donald Trump\n22 24 Alexis Tsipras\n```", "```py\nmatcher = PhraseMatcher(nlp.vocab, attr=\"LOWER\")\nterms = [\"Asset\", \"Investment\", \"Derivatives\", \n         \"Demand\",  \"Market\"]\npatterns = [nlp.make_doc(term) for term in terms]\nmatcher.add(\"financeTerms\", None, *patterns)\ndoc = nlp(\"During the last decade, derivatives market became an asset class of their own and influenced the financial landscape strongly.\")\nmatches = matcher(doc)\nfor mid, start, end in matches:\n    print(start, end, doc[start:end])\n…\n5 6 derivatives\n6 7 market\n```", "```py\nmatcher = PhraseMatcher(nlp.vocab, attr=\"SHAPE\")\nip_nums = [\"127.0.0.0\", \"127.256.0.0\"]\npatterns = [nlp.make_doc(ip) for ip in ip_nums]\nmatcher.add(\"IPNums\", None, *pattern)\ndoc = nlp(\"This log contains the following IP addresses: 192.1.1.1 and 192.12.1.1 and 192.160.1.1 .\")\nfor mid, start, end in matcher(doc):\n    print(start, end, doc[start:end])\n8 9 192.1.1.1\n12 13 192.160.1.1\n```", "```py\npattern = [{\"ENT_TYPE\": \"PERSON\"}]\nmatcher.add(\"personEnt\",  [pattern])\ndoc = nlp(\"Bill Gates visited Berlin.\")\nmatches = matcher(doc)\nfor mid, start, end in matches:\n    print(start, end, doc[start:end])\n... \n0 1 Bill\n1 2 Gates\n```", "```py\npattern = [{\"ENT_TYPE\": \"PERSON\", \"OP\": \"+\"}]\nmatcher.add(\"personEnt\",  [pattern])\ndoc = nlp(\"Bill Gates visited Berlin.\")\nmatches = matcher(doc)\nfor mid, start, end in matches:\n    print(start, end, doc[start:end])\n... \n0 1 Bill\n1 2 Gates\n0 2 Bill Gates\n```", "```py\npattern = [{\"ENT_TYPE\": \"PERSON\", \"OP\": \"+\"}, {\n            \"POS\" : \"VERB\"}]\nmatcher.add(\"personEntAction\",  [pattern])\ndoc = nlp(\"Today German chancellor Angela Merkel met with the US president.\")\nmatches = matcher(doc)\nfor mid, start, end in matches:\n    print(start, end, doc[start:end])\n... \n4 6 Merkel met\n3 6 Angela Merkel met\n```", "```py\ndoc = nlp(\"I have an acccount with chime since 2017\")\ndoc.ents\n(2017,)\npatterns = [{\"label\": \"ORG\", \n             \"pattern\": [{\"LOWER\": \"chime\"}]}]\nruler = nlp.add_pipe(\"entity_ruler\")\nruler.add_patterns(patterns)\ndoc.ents\n(chime, 2017)\ndoc[5].ent_type_\n'ORG'\n```", "```py\n{\"SHAPE\": \"XXdd\"}\n```", "```py\n{\"TEXT\": {\"REGEX\": \"\\d{1,4}\"}}\n```", "```py\n{\"TEXT\": {\"REGEX\": \"\\d{1,4}\"}, \"OP\": \"+\"}\n```", "```py\ndoc = nlp(\"My IBAN number is BE71 0961 2345 6769, please send the money there.\")\ndoc1 = nlp(\"My IBAN number is FR76 3000 6000 0112 3456 7890 189, please send the money there.\")\npattern = [{\"SHAPE\": \"XXdd\"}, \n           {\"TEXT\": {\"REGEX\": \"\\d{1,4}\"}, \"OP\":\"+\"}]\nmatcher = Matcher(nlp.vocab)\nmatcher.add(\"ibanNum\",  [pattern])\nfor mid, start, end in matcher(doc):\n    print(start, end, doc[start:end])\n... \n4 6 BE71 0961\n4 7 BE71 0961 2345\n4 8 BE71 0961 2345 6769\nfor mid, start, end in matcher(doc1):\n    print(start, end, doc1[start:end])\n... \n4 6 FR76 3000\n4 7 FR76 3000 6000\n4 8 FR76 3000 6000 0112\n4 9 FR76 3000 6000 0112 3456\n4 10 FR76 3000 6000 0112 3456 7890\n4 11 FR76 3000 6000 0112 3456 7890 189\n```", "```py\n{\"LOWER\": \"account\"}, {\"LOWER\": {\"IN\": [\"num\", \"number\"]}},{}, {\"IS_DIGIT\": True}\n```", "```py\n doc = nlp(\"My account number is 8921273.\")\npattern = [{\"LOWER\": \"account\"}, \n           {\"LOWER\": {\"IN\": [\"num\", \"number\"]}},{}, \n           {\"IS_DIGIT\": True}]\nmatcher = Matcher(nlp.vocab)\nmatcher.add(\"accountNum\",  [pattern])\nfor mid, start, end in matcher(doc):\n    print(start, end, doc[start:end])\n... \n1 5 account number is 8921273\n```", "```py\n{\"TEXT\": \"+1\", \"OP\": \"?\"}, {\"TEXT\": \"(\"}, {\"SHAPE\": \"ddd\"}, {\"TEXT\": \")\"}, {\"SHAPE\": \"ddd\"}, {\"TEXT\": \"-\", \"OP\": \"?\"}, {\"SHAPE\": \"dddd\"}\n```", "```py\ndoc1 = nlp(\"You can call my office on +1 (221) 102-2423 or email me directly.\")\ndoc2 = nlp(\"You can call me on (221) 102 2423 or text me.\")\npattern = [{\"TEXT\": \"+1\", \"OP\": \"?\"}, {\"TEXT\": \"(\"}, \n           {\"SHAPE\": \"ddd\"}, {\"TEXT\": \")\"}, \n           {\"SHAPE\": \"ddd\"}, {\"TEXT\": \"-\", \"OP\": \"?\"}, \n           {\"SHAPE\": \"dddd\"}]\nmatcher = Matcher(nlp.vocab)\nmatcher.add(\"usPhonNum\",  [pattern])\nfor mid, start, end in matcher(doc1):\n    print(start, end, doc1[start:end])\n... \n 6 13 +1 (221) 102-2423\nfor mid, start, end in matcher(doc2):\n    print(start, end, doc2[start:end])\n... \n 5 11 (221) 102-2423\n```", "```py\nCafeA is very generous with the portions.\nCafeB is horrible, we waited for mins for a table.\nRestaurantA is terribly expensive, stay away!\nRestaurantB is pretty amazing, we recommend.\n```", "```py\n[{\"ENT_TYPE\": \"ORG\"}, {\"LEMMA\": \"be\"}, {\"POS\": \"ADV\", \"OP\": \"*\"}, {\"POS\": \"ADJ\"}]\n```", "```py\n[{\"LOWER\": \"acme\"}, {\"LEMMA\": \"be\"}, {\"POS\": \"ADV\", \"OP\": \"*\"}, {\"POS\": \"ADJ\"}]\n```", "```py\ndoc = nlp(\"#MySpace\")\n[token.text for token in doc]\n['#', 'MySpace']\n```", "```py\n{\"TEXT\": \"#\"}, {\"IS_ASCII\": True}\n```", "```py\ndoc = nlp(\"Start working out now #WeekendShred\")\npattern = [{\"TEXT\": \"#\"}, {\"IS_ASCII\": True}]\nmatcher = Matcher(nlp.vocab)\nmatcher.add(\"hashTag\",  [pattern])\nmatches = matcher(doc)\nfor mid, start, end in matches:\n    print(start, end doc[start:end])\n...\n4 6 #WeekendShred\n```", "```py\npos_emoji = [\"\", \"\", \"\", \"\", \"\", \"\"]  \nneg_emoji = [\"\", \"\", \"\", \"\", \"\", \"\"]\npos_patterns = [[{\"ORTH\": emoji}] for emoji in pos_emoji]\nneg_patterns = [[{\"ORTH\": emoji}] for emoji in neg_emoji]\nmatcher = matcher(nlp.vocab)\nmatcher.add(\"posEmoji\", pos_patterns)\nmatcher.add(\"negEmoji\", neg_patterns)\ndoc = nlp(\" I love Zara  \")\nfor mid, start, end in matcher(doc):\n    print(start, end, doc[start:end])\n...\n3 4 \n```", "```py\ndoc = nlp(\"Ms. Smith left her house 2 hours ago.\")\ndoc.ents\n(Smith, 2 hours ago)\n```", "```py\npatterns = [{\"label\": \"TITLE\", \"pattern\": [{\"LOWER\": {\"IN\": [\"ms.\", \"mr.\", \"mrs.\", \"prof.\", \"dr.\"]}}]}]\nruler = nlp.add_pipe(\"entity_ruler\")\nruler.add_patterns(patterns)\nnlp.add_pipe(ruler)\ndoc = nlp(\"Ms. Smith left her house\")\nprint([(ent.text, ent.label_) for ent in doc.ents])\n[('Ms.', 'TITLE'), ('SMITH', 'PERSON')]\n```", "```py\ndoc = nlp(\"Einstein lived in Zurich.\")\n[(ent.text, ent.label_) for ent in doc.ents]\n[('Einstein', 'PERSON'), ('Zurich', 'GPE')]\n```", "```py\nperson_ents = [ent for ent in doc.ents if ent.label_ == \"PERSON\"]\nfor person_ent in person_entities:\n    #We use head of the entity's last token\n    head = person_ent[-1].head  \n    If head.lemma_ == \"live\":\n    #Check if the children of live contains prepositional \n    attachment \n    preps = [token for token in head.children if token.dep_ == \"prep\"]\n    for prep in preps:         \n        places = [token for token in prep.children if token.ent_type_ == \"GPE\"]   \n        # Verb is in past or present tense\n        print({'person': person_ent, 'city': places, \n               'past': head.tag_ == \"VBD\"})\n```"]