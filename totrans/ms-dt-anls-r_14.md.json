["```py\n> library(XML)\n> page <- htmlParse('http://r-project.org/foundation/donors.html')\n\n```", "```py\n> list <- unlist(xpathApply(page,\n+     \"//h3[@id='supporting-members']/following-sibling::ul[1]/li\", \n+     xmlValue))\n> str(list)\n chr [1:279] \"Klaus Abberger (Germany)\" \"Claudio Agostinelli (Italy)\" \n\n```", "```py\n> supporterlist <- sub(' \\\\([a-zA-Z ]*\\\\)$', '', list)\n> countrylist   <- substr(list, nchar(supporterlist) + 3,\n+                               nchar(list) - 1)\n\n```", "```py\n> tail(sort(prop.table(table(countrylist)) * 100), 5)\n Canada Switzerland          UK     Germany         USA \n 4.659498    5.017921    7.168459   15.770609   37.992832 \n\n```", "```py\n> countries <- as.data.frame(table(countrylist))\n\n```", "```py\n> library(rworldmap)\n> joinCountryData2Map(countries, joinCode = 'NAME',\n+    nameJoinColumn = 'countrylist', verbose = TRUE)\n32 codes from your data successfully matched countries in the map\n4 codes from your data failed to match with a country code in the map\n failedCodes failedCountries\n[1,] NA          \"Brasil\" \n[2,] NA          \"CZ\" \n[3,] NA          \"Danmark\" \n[4,] NA          \"NL\" \n213 codes from the map weren't represented in your data\n\n```", "```py\n> library(ggmap)\n> for (fix in c('Brasil', 'CZ', 'Danmark', 'NL')) {\n+   countrylist[which(countrylist == fix)] <-\n+       geocode(fix, output = 'more')$country\n+ }\n\n```", "```py\n> countries <- as.data.frame(table(countrylist))\n> countries <- joinCountryData2Map(countries, joinCode = 'NAME',\n+   nameJoinColumn = 'countrylist')\n36 codes from your data successfully matched countries in the map\n0 codes from your data failed to match with a country code in the map\n211 codes from the map weren't represented in your data\n\n```", "```py\n> mapCountryData(countries, 'Freq', catMethod = 'logFixedWidth',\n+   mapTitle = 'Number of R Foundation supporting members')\n\n```", "```py\n> packages <- readHTMLTable(paste0('http://cran.r-project.org', \n+   '/web/checks/check_summary.html'), which = 2)\n\n```", "```py\n> maintainers <- sub('(.*) <(.*)>', '\\\\1', packages$' Maintainer')\n> maintainers <- gsub(' ', ' ', maintainers)\n> str(maintainers)\n chr [1:6994] \"Scott Fortmann-Roe\" \"Gaurav Sood\" \"Blum Michael\" ...\n\n```", "```py\n> tail(sort(table(maintainers)), 8)\n Paul Gilbert     Simon Urbanek Scott Chamberlain   Martin Maechler \n 22                22                24                25 \n ORPHANED       Kurt Hornik    Hadley Wickham Dirk Eddelbuettel \n 26                29                31                36 \n\n```", "```py\n> N <- as.numeric(table(maintainers))\n> library(fitdistrplus)\n> plotdist(N)\n\n```", "```py\n> descdist(N, boot = 1e3)\nsummary statistics\n------\nmin:  1   max:  36 \nmedian:  1 \nmean:  1.74327 \nestimated sd:  1.963108 \nestimated skewness:  7.191722 \nestimated kurtosis:  82.0168 \n\n```", "```py\n> (gparams <- fitdist(N, 'gamma'))\nFitting of the distribution ' gamma ' by maximum likelihood \nParameters:\n estimate Std. Error\nshape 2.394869 0.05019383\nrate  1.373693 0.03202067\n\n```", "```py\n> gshape <- gparams$estimate[['shape']]\n> grate  <- gparams$estimate[['rate']]\n> sum(rgamma(1e5, shape = gshape, rate = grate))\n[1] 173655.3\n> hist(rgamma(1e5, shape = gshape, rate = grate))\n\n```", "```py\n> pgamma(2, shape = gshape, rate = grate)\n[1] 0.6672011\n\n```", "```py\n> prop.table(table(N <= 2))\n FALSE      TRUE \n0.1458126 0.8541874 \n\n```", "```py\n> ploc <- min(N)\n> pshp <- length(N) / sum(log(N) - log(ploc))\n\n```", "```py\n> library(actuar)\n> ppareto(2, pshp, ploc)\n[1] 0.9631973\n\n```", "```py\n> fg <- fitdist(N, 'gamma')\n> fw <- fitdist(N, 'weibull')\n> fl <- fitdist(N, 'lnorm')\n> fp <- fitdist(N, 'pareto', start = list(shape = 1, scale = 1))\n> par(mfrow = c(1, 2))\n> denscomp(list(fg, fw, fl, fp), addlegend = FALSE)\n> qqcomp(list(fg, fw, fl, fp),\n+   legendtext = c('gamma', 'Weibull', 'Lognormal', 'Pareto')) \n\n```", "```py\n> length(unique(maintainers))\n[1] 4012\n\n```", "```py\n> library(RCurl)\n> url <- getURL('https://stat.ethz.ch/pipermail/r-help/')\n\n```", "```py\n> R.help.toc <- htmlParse(url)\n> R.help.archives <- unlist(xpathApply(R.help.toc,\n+      \"//table//td[3]/a\", xmlAttrs), use.names = FALSE)\n\n```", "```py\n> dir.create('r-help')\n> for (f in R.help.archives)\n+     download.file(url = paste0(url, f),\n+          file.path('help-r', f), method = 'curl'))\n\n```", "```py\n> lines <- system(paste0(\n+     \"zgrep -E '^From: .* at .*' ./help-r/*.txt.gz\"),\n+                 intern = TRUE)\n> length(lines)\n[1] 387218\n> length(unique(lines))\n[1] 110028\n\n```", "```py\n> lines[26]\n[1] \"./1997-April.txt.gz:From: pcm at ptd.net (Paul C. Murray)\"\n\n```", "```py\n> lines    <- sub('.*From: ', '', lines)\n> Rhelpers <- sub('.*\\\\((.*)\\\\)', '\\\\1', lines)\n\n```", "```py\n> tail(sort(table(Rhelpers)), 6)\n jim holtman     Duncan Murdoch         Uwe Ligges \n 4284               6421               6455 \nGabor Grothendieck  Prof Brian Ripley    David Winsemius \n 8461               9287              10135\n\n```", "```py\n> grep('Brian( D)? Ripley', names(table(Rhelpers)), value = TRUE)\n [1] \"Brian D Ripley\"\n [2] \"Brian D Ripley [mailto:ripley at stats.ox.ac.uk]\"\n [3] \"Brian Ripley\"\n [4] \"Brian Ripley <ripley at stats.ox.ac.uk>\"\n [5] \"Prof Brian D Ripley\"\n [6] \"Prof Brian D Ripley [mailto:ripley at stats.ox.ac.uk]\"\n [7] \"         Prof Brian D Ripley <ripley at stats.ox.ac.uk>\"\n [8] \"\\\"Prof Brian D Ripley\\\" <ripley at stats.ox.ac.uk>\"\n [9] \"Prof Brian D Ripley <ripley at stats.ox.ac.uk>\"\n[10] \"Prof Brian Ripley\"\n[11] \"Prof. Brian Ripley\"\n[12] \"Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]\"\n[13] \"Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk] \"\n[14] \"          \\tProf Brian Ripley <ripley at stats.ox.ac.uk>\"\n[15] \"  Prof Brian Ripley <ripley at stats.ox.ac.uk>\"\n[16] \"\\\"Prof Brian Ripley\\\" <ripley at stats.ox.ac.uk>\"\n[17] \"Prof Brian Ripley<ripley at stats.ox.ac.uk>\"\n[18] \"Prof Brian Ripley <ripley at stats.ox.ac.uk>\"\n[19] \"Prof Brian Ripley [ripley at stats.ox.ac.uk]\"\n[20] \"Prof Brian Ripley <ripley at toucan.stats>\"\n[21] \"Professor Brian Ripley\"\n[22] \"r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Prof Brian Ripley\" \n[23] \"r-help-bounces at stat.math.ethz.ch [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Prof Brian Ripley\"\n\n```", "```py\n> sum(grepl('Brian( D)? Ripley', Rhelpers))\n[1] 10816\n\n```", "```py\n> lines <- system(paste0(\n+     \"zgrep -E '^Date: [A-Za-z]{3}, [0-9]{1,2} [A-Za-z]{3} \",\n+     \"[0-9]{4} [0-9]{2}:[0-9]{2}:[0-9]{2} [-+]{1}[0-9]{4}' \",\n+     \"./help-r/*.txt.gz\"),\n+                 intern = TRUE)\n\n```", "```py\n> length(lines)\n[1] 360817\n\n```", "```py\n> head(sub('.*Date: ', '', lines[1]))\n[1] \"Tue, 1 Apr 1997 20:35:48 +1200 (NZST)\"\n\n```", "```py\n> times <- strptime(sub('.*Date: ', '', lines),\n+            format = '%a, %d %b %Y %H:%M:%S %z')\n\n```", "```py\n> plot(table(format(times, '%Y')), type = 'l')\n\n```", "```py\n> library(data.table)\n> Rhelp <- data.table(time = times)\n> Rhelp[, H := hour(time)]\n> Rhelp[, D := wday(time)]\n\n```", "```py\n> library(ggplot2)\n> ggplot(na.omit(Rhelp[, .N, by = .(H, D)]),\n+      aes(x = factor(H), y = factor(D), size = N)) + geom_point() +\n+      ylab('Day of the week') + xlab('Hour of the day') +\n+      ggtitle('Number of mails posted on [R-help]') +\n+      theme_bw() + theme('legend.position' = 'top')\n\n```", "```py\n> tail(sort(table(sub('.*([+-][0-9]{4}).*', '\\\\1', lines))), 22)\n-1000 +0700 +0400 -0200 +0900 -0000 +0300 +1300 +1200 +1100 +0530 \n 164   352   449  1713  1769  2585  2612  2917  2990  3156  3938 \n-0300 +1000 +0800 -0600 +0000 -0800 +0200 -0500 -0400 +0100 -0700 \n 4712  5081  5493 14351 28418 31661 42397 47552 50377 51390 55696\n\n```", "```py\n> Rhelp[, date := as.Date(time)]\n> Rdaily <- na.omit(Rhelp[, .N, by = date])\n\n```", "```py\n> Rdaily <- zoo(Rdaily$N, Rdaily$date)\n\n```", "```py\n> plot(Rdaily)\n\n```", "```py\n> library(forecast)\n> fit <- ets(Rdaily)\n\n```", "```py\n> predict(fit, 1)\n Point Forecast   Lo 80    Hi 80        Lo 95    Hi 95\n5823       28.48337 9.85733 47.10942 -0.002702251 56.96945\n\n```", "```py\n> plot(forecast(fit, 30), include = 365)\n\n```", "```py\n> lists <- rbindlist(list(\n+     data.frame(name = unique(supporterlist), list = 'supporter'),\n+     data.frame(name = unique(maintainers),   list = 'maintainer'),\n+     data.frame(name = unique(Rhelpers),      list = 'R-help')))\n\n```", "```py\n> t <- table(lists$name, lists$list)\n> table(rowSums(t))\n 1     2     3 \n44312   860    40\n\n```", "```py\n> library(Rcapture)\n> descriptive(t)\n\nNumber of captured units: 45212 \n\nFrequency statistics:\n fi     ui     vi     ni \ni = 1  44312    279    157    279\ni = 2    860   3958   3194   4012\ni = 3     40  40975  41861  41861\nfi: number of units captured i times\nui: number of units captured for the first time on occasion i\nvi: number of units captured for the last time on occasion i\nni: number of units captured on occasion i \n\n```", "```py\n> closedp(t)\n\nNumber of captured units: 45212 \n\nAbundance estimations and model fits:\n abundance     stderr  deviance df       AIC       BIC\nM0              750158.4    23800.7 73777.800  5 73835.630 73853.069\nMt              192022.2     5480.0   240.278  3   302.109   336.986\nMh Chao (LB)    806279.2    26954.8 73694.125  4 73753.956 73780.113\nMh Poisson2    2085896.4   214443.8 73694.125  4 73753.956 73780.113\nMh Darroch     5516992.8  1033404.9 73694.125  4 73753.956 73780.113\nMh Gamma3.5   14906552.8  4090049.0 73694.125  4 73753.956 73780.113\nMth Chao (LB)   205343.8     6190.1    30.598  2    94.429   138.025\nMth Poisson2   1086549.0   114592.9    30.598  2    94.429   138.025\nMth Darroch    6817027.3  1342273.7    30.598  2    94.429   138.025\nMth Gamma3.5  45168873.4 13055279.1    30.598  2    94.429   138.025\nMb                 -36.2        6.2   107.728  4   167.559   193.716\nMbh               -144.2       25.9    84.927  3   146.758   181.635\n\n```", "```py\n> library(fbRads)\n> fbad_init(FB account ID, FB API token)\n> fbad_get_search(q = 'rstats', type = 'adinterest')\n id                       name audience_size path description\n6003212345926 R (programming language)       1308280 NULL          NA\n\n```", "```py\n> fbad_get_search(fbacc = fbacc, q = 'SPSS', type = 'adinterest')\n id      name audience_size path description\n1 6004181236095      SPSS        203840 NULL          NA\n2 6003262140109 SPSS Inc.          2300 NULL          NA\n\n```", "```py\n> res <- fbad_get_search(fbacc = fbacc, q = 'programming language',\n+                        type = 'adinterest')\n> res <- res[order(res$audience_size, decreasing = TRUE), ]\n> res[1:10, 1:3]\n id                          name audience_size\n1  6003030200185          Programming language     295308880\n71 6004131486306                           C++      27812820\n72 6003017204650                           PHP      23407040\n73 6003572165103               Lazy evaluation      18251070\n74 6003568029103   Object-oriented programming      14817330\n2  6002979703120   Ruby (programming language)      10346930\n75 6003486129469                      Compiler      10101110\n76 6003127967124                    JavaScript       9629170\n3  6003437022731   Java (programming language)       8774720\n4  6003682002118 Python (programming language)       7932670\n\n```", "```py\n> library(twitteR)\n> setup_twitter_oauth(...)\n\n```", "```py\n> str(searchTwitter(\"#rstats\", n = 1, resultType = 'recent'))\nReference class 'status' [package \"twitteR\"] with 17 fields\n $ text         : chr \"7 #rstats talks in 2014\"| __truncated__\n $ favorited    : logi FALSE\n $ favoriteCount: num 2\n $ replyToSN    : chr(0) \n $ created      : POSIXct[1:1], format: \"2015-07-21 19:31:23\"\n $ truncated    : logi FALSE\n $ replyToSID   : chr(0) \n $ id           : chr \"623576019346280448\"\n $ replyToUID   : chr(0) \n $ statusSource : chr \"Twitter Web Client\"\n $ screenName   : chr \"daroczig\"\n $ retweetCount : num 2\n $ isRetweet    : logi FALSE\n $ retweeted    : logi FALSE\n $ longitude    : chr(0) \n $ latitude     : chr(0) \n $ urls         :'data.frame':\t2 obs. of  5 variables:\n ..$ url         : chr [1:2] \n \"http://t.co/pStTeyBr2r\" \"https://t.co/5L4wyxtooQ\"\n ..$ expanded_url: chr [1:2] \"http://budapestbiforum.hu/2015/en/cfp\" \n \"https://twitter.com/BudapestBI/status/623524708085067776\"\n ..$ display_url : chr [1:2] \"budapestbiforum.hu/2015/en/cfp\" \n \"twitter.com/BudapestBI/sta…\"\n ..$ start_index : num [1:2] 97 120\n ..$ stop_index  : num [1:2] 119 143\n\n```", "```py\n> tweets <- Rtweets(n = 500)\n\n```", "```py\n> length(strip_retweets(tweets))\n[1] 149\n\n```", "```py\n> tweets <- twListToDF(tweets)\n\n```", "```py\n> library(tm)\nLoading required package: NLP\n> corpus <- Corpus(VectorSource(tweets$text))\n\n```", "```py\n> corpus <- tm_map(corpus, removeWords, stopwords(\"english\"))\n> corpus <- tm_map(corpus, content_transformer(tolower))\n> corpus <- tm_map(corpus, removePunctuation)\n> corpus <- tm_map(corpus, stripWhitespace)\n\n```", "```py\n> corpus <- tm_map(corpus, removeWords, 'rstats')\n\n```", "```py\n> library(wordcloud)\nLoading required package: RColorBrewer\n> wordcloud(corpus)\n\n```"]