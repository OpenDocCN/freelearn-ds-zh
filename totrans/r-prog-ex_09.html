<html><head></head><body>
        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Implementing an Efficient Simple Moving Average</h1>
                
            
            <article>
                
<p class="calibre2">During the last few decades, demand for computing power has steadily increased as the data volume has become larger and models have become more complex. It is obvious that minimizing the time needed for these calculations has become an important task and that there are obvious performance problems that need to be tackled. These performance problems arise from a mismatch between data volume and existing analytical methods. Eventually, a fundamental shift in data analysis techniques will be required, but for now, we must settle with improving the efficiency of our implementations.</p>
<p class="calibre2">R was designed as an interpreted language with a high-level expressiveness, and that's one of the reasons why it lacks much of the fine-grained control and basic constructs to support highly-performant code. As Arora nails it in the book, she edited, <em class="calibre19">Conquering Big Data with High Performance Computing, by Springer, 2016:</em> "<em class="calibre19">While R is clearly a high productivity language, it has not necessarily been a high performance language</em>.<em class="calibre19">"</em></p>
<p class="calibre2">It is not uncommon for the execution time of an R program to be measured in hours, or even in days. As the volume of data to be analyzed increases, the execution time can become prohibitively long, and it's often the case that data scientists and statisticians get stuck with these bottlenecks. When this happens, and if they don't know much about performance optimization, they'll probably just settle with reduced amounts of data, which can hinder their analysis. However, fear not; R programs can be slow, but well-written R programs are usually fast enough, and we will look at various techniques you can use to increase the performance of your R code.</p>
<p class="calibre2">This chapter is not meant to make you a performance optimization expert, but rather provide an overview that introduces you to the vast amount of techniques that can be used when attempting to increase your code's performance. We will look at many different techniques, each of which can have chapters and even books dedicated to them, so we will have to look at them from a very high level, but if you find yourself being constantly restricted by computing resources, they are something you will want to look further into.</p>
<p class="calibre2">Some of the important topics covered in this chapter are as follows:</p>
<ul class="calibre11">
<li class="calibre12">Deciding how fast <span>an </span>implementation <span>must </span>be</li>
<li class="calibre12">The importance of using good algorithms</li>
<li class="calibre12">Reasons why R can be slow or inefficient at times</li>
<li class="calibre12">The big performance impact small changes can have</li>
<li class="calibre12">Measuring your code's performance to find bottlenecks</li>
<li class="calibre12">Comparing different implementations among themselves</li>
<li class="calibre12">Getting the most from your computer by parallelizing</li>
<li class="calibre12">Improving performance by interfacing with other languages</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Required packages</h1>
                
            
            <article>
                
<p class="calibre2">We have already worked with some of the packages required for this chapter, such as <kbd class="calibre9">ggplot2</kbd> and <kbd class="calibre9">lubridate</kbd>. The other three packages are introduced to benchmark functions and compare their performance among themselves, and for advanced optimization techniques like <strong class="calibre1">delegation</strong> and <strong class="calibre1">parallelization</strong>, which will be explained in their respective sections.</p>
<p class="calibre2">To be able to replicate all the examples in this chapter, you also need working compilers for Fortran and C++ code. Refer to <a href="part0296.html#8Q96G0-f494c932c729429fb734ce52cafce730" class="calibre4">Appendix</a>, <em class="calibre19">Required Packages</em>, for instructions on how to install them for your operating system.</p>
<p class="calibre2">Let's take a look at the following table depicting the uses of the required packages:</p>
<table class="calibre5">
<tbody class="calibre6">
<tr class="calibre7">
<td class="calibre8">
<p class="calibre2"><strong class="calibre1">Packages</strong></p>
</td>
<td class="calibre8">
<p class="calibre2"><strong class="calibre1">Reason</strong></p>
</td>
</tr>
<tr class="calibre7">
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9">ggplot2</kbd></p>
</td>
<td class="calibre8">
<p class="calibre2">High-quality graphs</p>
</td>
</tr>
<tr class="calibre7">
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9">lubridate</kbd></p>
</td>
<td class="calibre8">
<p class="calibre2">Easily transfer dates</p>
</td>
</tr>
<tr class="calibre7">
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9">microbenchmark</kbd></p>
</td>
<td class="calibre8">
<p class="calibre2">Benchmark functions' performance</p>
</td>
</tr>
</tbody>
</table>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Starting by using good algorithms</h1>
                
            
            <article>
                
<p class="calibre2">To be able to communicate the ideas contained in this chapter clearly, first I need to provide some simple definitions. When I refer to an <em class="calibre19">algorithm</em>, I mean an abstract specification for a process. When I refer to an <em class="calibre19">implementation</em>, I refer to the way an algorithm is actually programmed. Finally, when I refer to a <em class="calibre19">program</em> or an <em class="calibre19">application</em>, I mean a set of such algorithm implementations working together. Having said that, it's easy to see how an algorithm can be implemented in many different ways (for example, one implementation may be using a list, while another may be using an array). Each of these implementations will have different performances, and they are related, but not equivalent, to an algorithm's time-complexity.</p>
<p class="calibre2">For those unfamiliar with the last term, each algorithm has the following two basic properties</p>
<ul class="calibre11">
<li class="calibre12"><strong class="calibre1">Time complexity</strong>: This property refers to the number of calculations an algorithm needs to execute, in relation to the size of input it receives. There are various mathematical tools to measure this complexity, the most common one being Big-O notation, which measures the worst-case scenario for an algorithm.</li>
<li class="calibre12"><strong class="calibre1">Space complexity</strong>: This property refers to the amount of memory required to execute the algorithm, again in relation to the size of the input it receives, and it can be also measured with the same mathematical tools.</li>
</ul>
<p class="calibre2">It's a well-known fact that an inefficient algorithm implemented very efficiently can be orders of magnitude slower than an efficient algorithm implemented inefficiently. This means that most of the time, algorithm selection is much more important than implementation optimization.</p>
<p class="calibre2">There are many other things to consider when evaluating an algorithm other than the complexities mentioned previously, such as efficiency resources usage (for example, internet bandwith), as well as other properties such as security or implementation difficulty. We won't dig into these topics in this book. However, if you want your code to perform well, you must study data structures and algorithms formally. Great resources to get started on these topics are the book by Cormen, Leiserson, Rivest, and Stein, titled <em class="calibre19">Introduction to Algorithms, by MIT Press, 2009</em>, and Skiena's, <em class="calibre19">The Algorithm Design Manual, by Springer, 2008</em>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Just how much impact can algorithm selection have?</h1>
                
            
            <article>
                
<p class="calibre2">Calculating Fibonacci numbers is a traditional example when teaching recursiveness. Here, we will use it to compare the performance of two algorithms, one recursive and one sequential.</p>
<p class="calibre2">In case you are not familiar with them, Fibonacci numbers are defined recursively in a sequence where the next is the sum of the previous two, and the first two numbers are ones (our base cases). The actual sequence is 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, and so on. This is called a Fibonacci sequence, and it exhibits interesting properties, such as being related to the golden ratio, which you should definitely look up if don't know what it is.</p>
<p class="calibre2">Our <kbd class="calibre9">fibonacci_recursive()</kbd> function receives the position of the Fibonacci number we want to calculate as <kbd class="calibre9">n</kbd>, restricted to integers greater than or equal to one. If <kbd class="calibre9">n</kbd> is a base case, that is, if it's below 1, we will simply return it (not that if we're computing the Fibonacci number at the second position, our operation <kbd class="calibre9">n - 2</kbd> would be zero, which is not a valid position, that's why we need to use <kbd class="calibre9">&lt;=</kbd> instead of <kbd class="calibre9">==</kbd>). Otherwise, we will return the sum of the recursive calls to the previous two with <kbd class="calibre9">fibonacci_recursive(n - 1)</kbd> and <kbd class="calibre9">fibonacci_recursive(n - 2)</kbd>, as shown in the following code snippet:</p>
<pre class="mce-root">fibonacci_recursive &lt;- function(n) {<br class="title-page-name"/>    if(n &lt;= 1) { return(n) }<br class="title-page-name"/>    return(<span>fibonacci_recursive</span><span>(n </span><span>- </span><span>1</span><span>) </span><span>+ </span><span>fibonacci_recursive</span><span>(n </span><span>- </span><span>2</span><span>))</span> <br class="title-page-name"/>}</pre>
<p class="calibre2">As you can see in the following code snippet, our function works as expected. However, what happens when we want to retrieve the 35<sup class="calibre61">th</sup> or 40<sup class="calibre61">th</sup> Fibonacci number? As you may experience when running this code, the further the Fibonacci number is from the base cases, the more time it will take, and somewhere around the 30<sup class="calibre61">th</sup> position, it starts being noticeably slower. If you try to compute the 100<sup class="calibre61">th</sup> Fibonacci number, you'll be waiting for a long while before you get the result:</p>
<pre class="mce-root">fibonacci_recursive(1)
<strong class="calibre1">#&gt; [1] 1</strong>
<br class="title-page-name"/>fibonacci_recursive(2)
<strong class="calibre1">#&gt; [1] 1</strong>
<br class="title-page-name"/>fibonacci_recursive(3)
<strong class="calibre1">#&gt; [1] 2</strong>
<br class="title-page-name"/>fibonacci_recursive(4)
<strong class="calibre1">#&gt; [1] 3</strong>
<br class="title-page-name"/>fibonacci_recursive(5)
 <strong class="calibre1">#&gt; [1] 5</strong>
 <br class="title-page-name"/>fibonacci_recursive(35)
<strong class="calibre1">#&gt; [1] 9227465</strong></pre>
<p class="calibre2">Why is this happening? The answer is that this algorithm is doing a lot of unnecessary work, making it a bad algorithm. To understand why, let's mentally go through the execution of the algorithm for the third and fourth Fibonacci numbers and make the corresponding execution trees, as shown in the following diagram:</p>
<div class="cdpaligncenter"><img src="../images/00061.jpeg" class="calibre62"/></div>
<p class="calibre2">In the preceding diagram, <strong class="calibre1">f(n)</strong> is short for <kbd class="calibre9">fibonacci_recursive(n)</kbd>, so that we can fit all the objects inside it, and colors are used to show which function calls are repeated. As you can see, when you execute <kbd class="calibre9">fibonacci_recusive(3)</kbd>, the <kbd class="calibre9">fibonacci_recursive(1)</kbd> call is executed twice. When executing <kbd class="calibre9">fibonacci_recursive(4)</kbd>, that same call is executed three times. How many times will it be executed for <kbd class="calibre9">fibonacci_recursive(5)</kbd> and <kbd class="calibre9">for fibonacci_recursive(6)</kbd>? That's an exercise for you, the reader, and as you'll find, the number increases exponentially.</p>
<p class="calibre2">To be technically precise, the time complexity for the algorithm is O(2<sup class="calibre61">n</sup>), which is as bad as you can get. Furthermore, most of the calculations are completely unnecessary since they are repeated. The algorithm is correct, but its performance is one of the worst. As we mentioned earlier, even if you provide the most efficient implementation possible for this algorithm, it will be much slower than a very inefficient implementation of a more efficient one.</p>
<p class="calibre2">If we design a correct algorithm that avoids doing all the unnecessary calculations, we can have a much faster program, and that's exactly what the following algorithm does. Instead of making a tree of recursive calls, we will simply compute the Fibonacci numbers in order up to the one we are being asked for. We will simply add the previous two numbers and store the result in the array <kbd class="calibre9">f</kbd>, which will have <kbd class="calibre9">n</kbd> integers. We specify the two base cases and proceed with the calculation, as shown in the following code snippet:</p>
<pre class="mce-root"><span>fibonacci_sequential &lt;- </span><span>function</span><span>(n) {<br class="title-page-name"/></span><span>    if </span><span>(n </span><span>&lt;= </span><span>2</span><span>) { </span><span>return</span><span>(</span><span>1</span><span>) }<br class="title-page-name"/>    f &lt;- </span><span>integer</span><span>(n)<br class="title-page-name"/>    f[</span><span>1</span><span>] &lt;- </span><span>1<br class="title-page-name"/></span><span>    f[</span><span>2</span><span>] &lt;- </span><span>1<br class="title-page-name"/></span><span>    for </span><span>(i </span><span>in </span><span>3</span><span>:</span><span>n) {</span> <br class="title-page-name"/>        f[i] &lt;- f[i-2] + f[i-1]<br class="title-page-name"/>    }<br class="title-page-name"/>    return(f[n])<br class="title-page-name"/>}</pre>
<p class="calibre2">As you can see, each number is computed only once, which is the most efficient algorithm we can design for this problem. This avoids all the overhead from the recursive algorithm and leaves us with a linear time complexity of O(n). Even if we code this algorithm without much care for performance optimization, it's execution time will be many orders of magnitude faster.</p>
<p class="calibre2">With this algorithm, we can actually compute the 1476<sup class="calibre61">th</sup> Fibonacci number, which is the largest one that R's internal architecture will allow for. If we try to compute the 1477<sup class="calibre61">th</sup> Fibonacci number, we will get infinity (<kbd class="calibre9">Inf</kbd>) as a response due to the mechanisms R uses to store integers, which is a topic we won't go into. Furthermore, the computation for the 1476<sup class="calibre61">th</sup> Fibonacci number is almost instantaneous, which goes to showcase the importance of choosing a good algorithm before worrying about optimizing it:</p>
<pre class="mce-root">fibonacci_sequential(1476)
<strong class="calibre1">#[1] 1.306989e+308</strong><br class="title-page-name"/><br class="title-page-name"/>fibonacci_sequential(1477)
<strong class="calibre1">#[1] Inf</strong></pre>
<p class="calibre2">Finally, note that we achieved an increase in speed at the expense of using more memory. The recursive algorithm discarded every Fibonacci number once it computed it, while the sequential algorithm keeps every single one in memory. For this particular problem, this seems to be a good trade-off. The trade-off among time and space is a common one in performance optimization.</p>
<p class="calibre2">Now that we have seen just how important algorithm selection can be, for the rest of the chapter <span>we will work with a single algorithm</span>, and we will focus on optimizing its implementation. However, the point remains that choosing an efficient algorithm is more important than implementing it efficiently.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">How fast is fast enough?</h1>
                
            
            <article>
                
<p class="calibre2">Let's assume that you have chosen a good algorithm and implemented it without too much regard for optimization, as is commonly the case with first attempts. Should you invest the time to optimize it? Performance optimization can be a very costly activity. You must not try to optimize your code unless you must. Your time is valuable, and it's probably better spent doing something else.</p>
<p class="calibre2">Let's say that for some reason, you must make your implementation faster. The first thing you must decide on is how fast is fast enough. Is your algorithm required to simply finish within a couple of hours instead of a couple of days, or do you need to come down to microsecond levels? Is this an absolute requirement or should you simply do the best job you can within a specific time frame? These are important questions that you must consider before optimizing your code, and sometimes the solution is not even optimization.</p>
<p class="calibre2">It's not rare for clients to prefer spending more money on using some type of cloud resource to tackle the performance problem rather than spending valuable time optimizing an algorithm's performance, especially if they can be providing more business value doing something else.</p>
<p class="calibre2">Apart from the machine-time versus human-time trade-off mentioned earlier, there are other considerations when deciding whether to optimize an algorithm's implementation <span>or not</span>. Do you want your code to be easily readable? Do you want your code to be shareable? It's often the case that more performant code is also more difficult to understand. Furthermore, if you're developing code that is executed parallelly, it will impose a bunch of restrictions on the type of systems that can execute it, and you need to keep that in mind.</p>
<p class="calibre2">I suggest that you keep to the minimum number of optimizations; this will make you achieve your goal regarding how fast an implementation must run, and don't do more than that. The process will be simple: find the most important bottleneck, remove it (or at least decrease its impact), check whether or not your implementation is fast enough, and if it's not, repeat. We will go through this cycle a couple of times along this chapter, and even though it seems easy in retrospective, it can be quite difficult <span>in reality</span>, especially when dealing with complex algorithms.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Calculating simple moving averages inefficiently</h1>
                
            
            <article>
                
<p class="calibre2">The algorithm we will work with for the rest of the chapter is called <strong class="calibre1">simple moving average</strong> (<strong class="calibre1">SMA</strong>). It's a very well-known tool for doing technical analysis of time-series, specially for financial markets and trading. The idea behind SMA is that you will compute an average at each point in time by looking back at a predefined number periods. For example, let's say you're looking at a minute-by-minute time-series, and you will compute an SMA(30). This means that at each observation in your time-series, you will take the observations that correspond to the previous 30 minutes from starting at a specific observation (30 observations back), and will save the average for those 30 observations as the SMA(30) value for that point in time.</p>
<p class="calibre2">In the later diagram, you can visualize the idea behind SMAs. The diagram shows a monotone time-series that increases by one value-unit for every time-unit, both of which start at one (that is, its value is <strong class="calibre1">1</strong> <span>at time <strong class="calibre1">1</strong></span>, <strong class="calibre1">2</strong> <span>at time <strong class="calibre1">2</strong></span>, and so on), along with some figures surrounding the group of observations the SMA calculation will take. As you can see, for SMA(3), <span>we get the last three elements </span>at every point in the time-series; similarly, for SMA(4), we get the last four elements. When you calculate the average for the subset of elements in the figure, you get the numbers in the top-left corners, which correspond to the specific SMA time-series calculated. Specifically for such a time-series, for the SMA(3) case, the result is NA, NA, <strong class="calibre1">2</strong>, <strong class="calibre1">3</strong>, <strong class="calibre1">4</strong>, <strong class="calibre1">5</strong>, <strong class="calibre1">6</strong>, <strong class="calibre1">7</strong>, and <strong class="calibre1">8</strong>, and for the SMA(4) case, the result is NA, NA, NA, <strong class="calibre1">2.5</strong>, <strong class="calibre1">3.5</strong>, <strong class="calibre1">4.5</strong>, <strong class="calibre1">5.5</strong>, <strong class="calibre1">6.5</strong>, and <strong class="calibre1">7.5</strong>.</p>
<p class="calibre2">There are a couple of following properties we should note about SMAs:</p>
<ul class="calibre11">
<li class="calibre12">First, note that both SMA(3) and SMA(4) are series that contain the same number of observations as the original time-series, <strong class="calibre1">9</strong> in this case.</li>
<li class="calibre12">Second, note that they both begin with a number of NA equal to the number SMA parameter minus one. This is because in the case of SMA(3), at time <strong class="calibre1">2</strong>, we don't have three observations back, we only have two. Therefore, an NA is used to indicate that SMA(3) could not be computed at that point. The same explanation applies to all other NA values.</li>
<li class="calibre12">Third and finally, note that every time we move one time-unit, we add one observation and remove another observation (the tail) from the current subset.</li>
</ul>
<p class="calibre2">Take a look at the following figure depicting the preceding properties:</p>
<div class="cdpaligncenter"><img src="../images/00062.jpeg" class="calibre63"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Simulating the time-series </h1>
                
            
            <article>
                
<p class="calibre2">Of course, you have been collecting data from cryptocurrency markets since you implemented your own version of the object-oriented system we developed in the last chapter, haven't you? I'm just kidding. If you have, it's probably not enough data for what we will do in this chapter, so here's a small piece of code that will simulate two time-series for Bitcoin and Litecoin price in US Dollars. The data structure is similar to the one used in the previous chapter, making the code we develop here useful for that system <span>also</span>.</p>
<p class="calibre2">We won't go too deep into how the function works since it should be clear for you at this point, except to point out that we're using the <kbd class="calibre9">time_to_timestamp.TimeStamp()</kbd> function we developed in the last chapter, and that the <kbd class="calibre9">simulate_prices()</kbd> function uses a quadratic model on top of an ARIMA simulation. If you don't know what an ARIMA model is, don't worry too much about it (it's not needed to understand this chapter). If you're interested in learning more about it, take a look at Shumway and Stoffer's book, <em class="calibre19">Time Series Analysis and Its Applications: With R Examples, Springer, 2011</em>. We are using a quadratic model because Bitcoin's price has been accelerating during the past couple of months (this is being written during November 2017). Let's take a look at the following code:</p>
<pre class="mce-root"><span>source</span><span>(</span><span>"../chapter-08/cryptocurrencies/utilities/time-stamp.R"</span><span>)<br class="title-page-name"/></span><span>library</span><span>(lubridate)<br class="title-page-name"/>N &lt;- </span><span>60 </span><span>* </span><span>24 </span><span>* </span><span>365<br class="title-page-name"/></span><span><br class="title-page-name"/>simulate_market &lt;- </span><span>function</span><span>(name, symbol, now, n, base, sd, x) {<br class="title-page-name"/>    dates &lt;- </span><span>seq</span><span>(now </span><span>- </span><span>minutes</span><span>(n </span><span>- </span><span>1</span><span>), now, </span><span>by = </span><span>"min"</span><span>)<br class="title-page-name"/>    ts &lt;- </span><span>unlist</span><span>(</span><span>lapply</span><span>(</span><span>lapply </span><span>(<br class="title-page-name"/>                            dates, <br class="title-page-name"/>                            time_to_timestamp.TimeStamp), <br class="title-page-name"/>                            unclass))<br class="title-page-name"/>    price_usd &lt;- </span><span>simulate_prices</span><span>(n, base, sd, x)<br class="title-page-name"/>    data &lt;- </span><span>data.frame</span><span>(</span><span>timestamp = </span><span>ts, </span><span>price_usd = </span><span>price_usd)</span> <br class="title-page-name"/>    <span>data</span><span>$</span><span>name &lt;- name<br class="title-page-name"/>    data</span><span>$</span><span>symbol &lt;- symbol<br class="title-page-name"/></span><span>    return</span><span>(data)<br class="title-page-name"/>}<br class="title-page-name"/><br class="title-page-name"/>simulate_prices &lt;- </span><span>function</span><span>(n, base, sd, x) {<br class="title-page-name"/>    ts &lt;- </span><span>arima.sim</span><span>(</span><span>list</span><span>(</span><span>15</span><span>, </span><span>15</span><span>, </span><span>15</span><span>), </span><span>n = </span><span>n, </span><span>sd = </span><span>sd)<br class="title-page-name"/>    quadratic_model &lt;- base </span><span>+ </span><span>(x </span><span>- </span><span>1</span><span>) </span><span>* </span><span>base </span><span>/ </span><span>(n</span><span>^</span><span>2</span><span>) </span><span>* </span><span>(</span><span>1</span><span>:</span><span>n)</span><span>^</span><span>2<br class="title-page-name"/></span><span>    return</span><span>(</span><span>as.numeric</span><span>(ts </span><span>+ </span><span>quadratic_model))<br class="title-page-name"/>}<br class="title-page-name"/><br class="title-page-name"/>now &lt;- </span><span>Sys.time</span><span>()<br class="title-page-name"/>btc &lt;- </span><span>simulate_market</span><span>(</span><span>"Bitcoin"</span><span>, </span><span>"BTC"</span><span>, now, N, </span><span>8000</span><span>, </span><span>8</span><span>, </span><span>2</span><span>)<br class="title-page-name"/>ltc &lt;- </span><span>simulate_market</span><span>(</span><span>"Litecoin"</span><span>, </span><span>"LTC"</span><span>, now, N, </span><span>80</span><span>, </span><span>0.08</span><span>, </span><span>1.5</span><span>)<br class="title-page-name"/>data &lt;- </span><span>rbind</span><span>(btc, ltc)<br class="title-page-name"/>data &lt;- data[</span><span>order</span><span>(data</span><span>$</span><span>timestamp), ]<br class="title-page-name"/></span><span>write.csv</span><span>(data, </span><span>"./data.csv"</span><span>, </span><span>row.names = </span><span>FALSE</span><span>)</span> </pre>
<p class="calibre2">Note that the parameters used to call the <kbd class="calibre9">simulate_market()</kbd> function try to resemble what is seen currently in Bitcoin and Litecoin prices, but keep in mind that this is a very simple model, so don't expect it to behave as the actual price time-series for these assets. Finally, we simulate 525,600 observations for each asset, which is approximately equal to the number of minutes in a year (<kbd class="calibre9">N &lt;- 60 * 24 * 365</kbd>, which contains seconds per hour, hours per day, and days per year). This means we're simulating minute-by-minute data.</p>
<p class="calibre2">To visualize the Bitcoin prices we simulated, you may use the following code. It simply produces one graph that uses a sample of 1,000 elements throughout the year (more than that is unnecessary, since you won't be able to perceive more points, and it will slow down the calculations); also, another graph is produced, which shows a zoom-in effect into the first hour in the data:</p>
<pre class="mce-root"><span>s &lt;- </span><span>sample</span><span>(</span><span>1</span><span>:</span><span>nrow</span><span>(btc), </span><span>1000</span><span>)<br class="title-page-name"/></span><span>plot</span><span>(btc[s[</span><span>order</span><span>(s)], </span><span>"price_usd"</span><span>], </span><span>xlab=</span><span>"Minutes"</span><span>, </span><span>ylab=</span><span>"Price"</span><span>, </span><span>xaxt=</span><span>'n'</span><span>)<br class="title-page-name"/></span><span>title</span><span>(</span><span>main=</span><span>"Bitcoin price simulation for 1 year"</span><span>)<br class="title-page-name"/></span><span>lines</span><span>(btc[s[</span><span>order</span><span>(s)], </span><span>"price_usd"</span><span>])<br class="title-page-name"/></span><span>plot</span><span>(btc[</span><span>1</span><span>:</span><span>60</span><span>, </span><span>"price_usd"</span><span>], </span><span>xlab=</span><span>"Minutes"</span><span>, </span><span>ylab=</span><span>"Price"</span><span>, </span><span>xaxt=</span><span>'n'</span><span>)<br class="title-page-name"/></span><span>title</span><span>(</span><span>main=</span><span>"Bitcoin price simulation for 1 hour"</span><span>)<br class="title-page-name"/></span><span>lines</span><span>(btc[</span><span>1</span><span>:</span><span>60</span><span>, </span><span>"price_usd"</span><span>])</span></pre>
<p class="calibre2">As can be seen, there's a strong upward trend when looking at the full year simulation, but if you zoom-in into a smaller time frame, you'll see quite a bit of price variance, which allows for useful SMA implementations. Let's take a look at the following graph: </p>
<div class="cdpaligncenter"><img src="../images/00063.jpeg" class="calibre64"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Our first (very inefficient) attempt at an SMA</h1>
                
            
            <article>
                
<p class="calibre2">As was mentioned earlier, we will work with SMA implementations for the rest of the chapter. To differentiate among them, we will change the function name for each subsequent implementation, starting with <kbd class="calibre9">sma_slow_1()</kbd>. All SMA implementations will receive the following parameters:</p>
<ul class="calibre11">
<li class="calibre12"><kbd class="calibre9">period</kbd>: To specify how many observations to use for the SMA.</li>
<li class="calibre12"><kbd class="calibre9">symbol</kbd>: To denote the asset we want to make the calculations for
<ul class="calibre56">
<li class="calibre12">For this example, options will be  <kbd class="calibre9">BTC</kbd> for <kbd class="calibre9">Bitcoin</kbd> or <kbd class="calibre9">LTC</kbd> for <kbd class="calibre9">Litecoin</kbd>. However, when you execute the system yourself, you'll be able to expand it with any cryptocurrency symbol you so desire.</li>
</ul>
</li>
<li class="calibre12"><kbd class="calibre9">data</kbd>: The actual data that contains the price time-series for every asset.</li>
</ul>
<p class="calibre2">We will make two assumptions on <kbd class="calibre9">data</kbd>—the <kbd class="calibre9">timestamp</kbd> column is in increasing order and we don't have gaps in the time-series, meaning that we have price data <span>for every minute</span>. This allows us to skip any ordering procedures and check whether the SMA should contain NA internally when no data is available. Note that both these assumptions are fulfilled by our data simulation. </p>
<p class="calibre2">Now, we'll explain how <kbd class="calibre9">sma_slow_1()</kbd> works. Note that this is a very inefficient implementation, and you should definitely avoid programming this way. However, these are common errors people make, and we will be removing them one by one while we measure the impact they actually have on your code's speed. Let's see how it is done by performing the following steps:</p>
<ol class="calibre14">
<li value="1" class="calibre12">First, we create an empty data frame named <kbd class="calibre9">result</kbd> that contains a single column called <kbd class="calibre9">sma</kbd>.</li>
<li value="2" class="calibre12">Then, we loop over all rows in the data; <kbd class="calibre9">end</kbd> denotes the end, or right-extreme, of the SMA interval under consideration.</li>
<li value="3" class="calibre12">We create a <kbd class="calibre9">position</kbd> integer that is the same as the <kbd class="calibre9">end</kbd> every time we start the loop as well as an <kbd class="calibre9">sma</kbd> object that will contain the actual SMA computation for the end position, an <kbd class="calibre9">n_accumulated</kbd> integer that keeps track of the number of observations we have accumulated, and a <kbd class="calibre9">period_prices</kbd> data frame that contains a single column to store the prices for the current SMA calculation.</li>
<li value="4" class="calibre12">Next, we check whether the observation at the current <kbd class="calibre9">end</kbd> corresponds to the <kbd class="calibre9">symbol</kbd> we're interested in. If it's not, we simply ignore that iteration, but if it is, we will accumulate <kbd class="calibre9">period_prices</kbd> starting at the <kbd class="calibre9">end</kbd> position (remember that <kbd class="calibre9">position</kbd> is equal to <kbd class="calibre9">end</kbd> and this point) and going backward until the number of accumulated prices is equal to the <kbd class="calibre9">period</kbd> we're interested in or the current <kbd class="calibre9">position</kbd> is lower than 1 (meaning that we're at the beginning of the time-series). To do so, we use a while-loop that checks for the condition mentioned before, increases <kbd class="calibre9">n_accumulated</kbd> when an observation with the same <kbd class="calibre9">symbol</kbd> is found and its data is appended to the <kbd class="calibre9">period_prices</kbd> data frame, and increases the <kbd class="calibre9">position</kbd> regardless of whether the observation was useful so that we don't get stuck.</li>
</ol>
<ol start="5" class="calibre14">
<li value="5" class="calibre12">After the while-loop is finished, we know that we <span>have </span>either accumulated a number of prices equal to the <kbd class="calibre9">period</kbd> we are interested in or we encountered the beginning of the time-series. In the first case, we compute the mean of such prices by iterating over the <kbd class="calibre9">period_prices</kbd> data frame, and assign that as the <kbd class="calibre9">sma</kbd> value for the current <kbd class="calibre9">end</kbd> position. In the second case, we simply record an <kbd class="calibre9">NA</kbd> value since we were not able to compute the full SMA. Take a look at the following code snippet:</li>
</ol>
<pre class="calibre65"><span>sma_slow_</span><span>1 </span><span>&lt;- </span><span>function</span><span>(period, symbol, data) {<br class="title-page-name"/>    result &lt;- </span><span>data.frame</span><span>(</span><span>sma=</span><span>numeric</span><span>())<br class="title-page-name"/></span><span>    for</span><span>(end </span><span>in </span><span>1</span><span>:</span><span>nrow</span><span>(data)) {<br class="title-page-name"/>        position &lt;- end<br class="title-page-name"/>        sma &lt;- </span><span>NA<br class="title-page-name"/></span><span>        n_accumulated &lt;- </span><span>0<br class="title-page-name"/></span><span>        period_prices &lt;- </span><span>data.frame</span><span>(</span><span>price=</span><span>numeric</span><span>())</span> <br class="title-page-name"/><span>        if </span><span>(data[end, </span><span>"symbol"</span><span>] </span><span>== </span><span>symbol) {<br class="title-page-name"/></span><span>            while</span><span>(n_accumulated </span><span>&lt; </span><span>period </span><span>&amp; </span><span>position </span><span>&gt;= </span><span>1</span><span>) {<br class="title-page-name"/></span><span>                if </span><span>(data[position, </span><span>"symbol"</span><span>] </span><span>== </span><span>symbol) {<br class="title-page-name"/>                    period_prices &lt;- </span><span>rbind</span><span>(<br class="title-page-name"/>                        period_prices,<br class="title-page-name"/></span><span>                        data.frame</span><span>(</span><span>price=</span><span>data[position, </span><span>"price_usd"</span><span>])<br class="title-page-name"/>                    )<br class="title-page-name"/>                    n_accumulated &lt;- n_accumulated </span><span>+ </span><span>1<br class="title-page-name"/></span><span>                }<br class="title-page-name"/>                position &lt;- position </span><span>- </span><span>1<br class="title-page-name"/></span><span>            }<br class="title-page-name"/></span><span>            if </span><span>(n_accumulated </span><span>== </span><span>period) {<br class="title-page-name"/>                sma &lt;- </span><span>0<br class="title-page-name"/></span><span>                for </span><span>(price </span><span>in </span><span>period_prices</span><span>$</span><span>price) {<br class="title-page-name"/>                    sma &lt;- sma </span><span>+ </span><span>price<br class="title-page-name"/>                }<br class="title-page-name"/>                sma &lt;- sma </span><span>/ </span><span>period<br class="title-page-name"/>            } </span><span>else </span><span>{<br class="title-page-name"/>                sma &lt;- </span><span>NA<br class="title-page-name"/></span><span>            }<br class="title-page-name"/>            result &lt;- </span><span>rbind</span><span>(result, </span><span>data.frame</span><span>(</span><span>sma=</span><span>sma))<br class="title-page-name"/>        }<br class="title-page-name"/>    }<br class="title-page-name"/></span><span>    return</span><span>(result)<br class="title-page-name"/>}</span> </pre>
<p class="calibre66">If the implementation seems complicated, it's because it is. As we start improving our code, it will naturally be simplified, which will make it easier to understand.</p>
<ol start="6" class="calibre14">
<li value="6" class="calibre12">Now, we want to actually see that it works. To do so, we bring the <kbd class="calibre9">sma-slow.R</kbd> file into memory (which contains all the slow implementations) as well as the data as shown in the following code snippet:</li>
</ol>
<pre class="calibre65">source("./sma-slow.R")
data_original &lt;- read.csv("./data.csv")</pre>
<p class="calibre66">Note that we take only the first 100 observations, which correspond to 50 minutes of Bitcoin price action (remember that these 100 observations only contain 50 for Bitcoin; the other 50 are for Litecoin). We can see that the SMA(5) for Bitcoin makes sense, including the first four NA (feel free to check the numbers by hand, but remember to use the data and results for your own data simulation):</p>
<pre class="calibre65">data   &lt;- data_original[1:100, ]
symbol &lt;- "BTC"
period &lt;- 5

sma_1 &lt;- sma_slow_1(period, symbol, data)
sma_1
<strong class="calibre1">#&gt;         sma
#&gt; 1        NA
#&gt; 2        NA
#&gt; 3        NA
#&gt; 4        NA
#&gt; 5  7999.639
#&gt; 6  7997.138
#&gt; 7  8000.098
#&gt; 8  8001.677
#&gt; 9  8000.633
#&gt; 10 8000.182
(Truncated output)</strong></pre>
<p class="calibre2">Before we understand how to fix this code, we need to understand why R can be slow as well as how to measure how much of an impact we're having while we are improving it.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Understanding why R can be slow</h1>
                
            
            <article>
                
<p class="calibre2">Understanding why a programming language can be slow is a fundamental skill needed to be able to increase the speed of its implementations. Any implementation in any programming language is similarly affected by an algorithm's time and memory complexities, because they are algorithms, and not implementation properties. However, the way languages handle specific implementations can vary quite a bit, and that's what we'll focus on now.</p>
<p class="calibre2">In the case of R, people often find the following four main bottlenecks:</p>
<ul class="calibre11">
<li class="calibre12">Object immutability</li>
<li class="calibre12">Interpreted dynamic typings</li>
<li class="calibre12">Memory-bound processes</li>
<li class="calibre12">Single-threaded processes</li>
</ul>
<p class="calibre2">By no means is this list complete or encountered in every implementation. It's just the most common bottlenecks I've seen people encounter, and which, after being fixed, produced the largest amount of speed improvements. They are often good starting points, but every implementation is different, so it's very difficult to suggest general rules for performance optimization, and you should keep this in mind.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Object immutability</h1>
                
            
            <article>
                
<p class="calibre2">Improving the speed of R implementations does not necessarily involve advanced optimization techniques, such as parallelization. Indeed, there are a number of simple tweaks that, while not always obvious, can make R run significantly faster. The top bottleneck people encounter with R is a lack of understanding about its object immutability property, and the overhead incurred when making copies of such objects. Simply taking care of this can produce dramatic performance improvements, and it's not too difficult once you understand how to do so. This is a good candidate to start looking for optimizations.</p>
<p class="calibre2">As an example of some of the issues that can arise, suppose you have an array of numbers named <kbd class="calibre9">a</kbd>. Now, suppose you want to update first element of <kbd class="calibre9">a</kbd> to be <kbd class="calibre9">10</kbd>, as shown in the following code snippet:</p>
<pre class="mce-root">a[1] &lt;- 10</pre>
<p class="calibre2">This assignment is much more complex than it seems. It is actually implemented via the <kbd class="calibre9">`"[&lt;-"`</kbd> <span>replacement function </span>through this call and assignment:</p>
<pre class="mce-root">a &lt;- `"[&lt;-"`(a, 1, value = 10)</pre>
<p class="calibre2">At first, you may find this to be a very weird syntax, but remember that, as we saw in <a href="part0022.html#KVCC0-f494c932c729429fb734ce52cafce730" class="calibre4">Chapter 1</a>, <em class="calibre19">Introduction to R</em>, we can have strings that represent objects, including functions, as is the case here. The `<kbd class="calibre9">"[&lt;-"`</kbd> parts of the line is actually a function name being called with the <kbd class="calibre9">a</kbd>, <kbd class="calibre9">1</kbd>, and <kbd class="calibre9">value = 10</kbd> parameters. If you execute the previous two lines, you should get the same result; that is the first element in <kbd class="calibre9">a</kbd> being equal to <kbd class="calibre9">10</kbd>.</p>
<p class="calibre2">What actually happens is that an internal copy of <kbd class="calibre9">a</kbd> is made; the first element of such an object is changed to <kbd class="calibre9">10</kbd> and the resulting object is reassigned to <kbd class="calibre9">a</kbd>. Even though we are simply changing just one element of the array, in reality, the entire vector is recomputed. The larger the vector, the worse the problem is, and this can considerably slow down your implementation. It's even worse when you're using heavy data structures, such as data frames.</p>
<p class="calibre2">Languages that allow for mutabilty, such as Fortran or C++, will simply change a specific value in the array instead of producing a new copy of the full array. That's why it's often the case where code that would be just fine in other languages produces a very large, and often unnecessary, overhead when programmed similarly in R. We will see ways to mitigate this impact as we go through the chapter.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Interpreted dynamic typings</h1>
                
            
            <article>
                
<p class="calibre2">The second most important bottleneck people find is R's nature of being an interpreted and dynamically-typed language. This means that at any given line in your program, an object may be an integer, in the next line it may be a data frame, then a string, and it may be a list of data frames <span>two lines later</span>. This is the nature of not having fixed types for your objects, and since the interpreter can't know how to handle such objects <span>in advance </span>because they may be entirely different each time, it must check the object's type every time it wants to apply some kind of operation on it. This is a little exaggerated, but the point remains that since it's possible that an object's type changed, it must be continuously checked.</p>
<p class="calibre2">We will see how to avoid some of these checks to increase performance, but to deal with the interpreted and dynamically typed nature, we will have to resort to other programming languages, such as Fortran or C++, as we will show you later in the chapter. These languages fix an object's type when it's created and if you attempt to change it at some point, the program will throw an error. This may seen like an unnecessary restriction, but actually it can be very powerful when communicating some code's intent as well as to allow compilers to provide powerful optimizations for handling such objects.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Memory-bound processes</h1>
                
            
            <article>
                
<p class="calibre2">The third most important bottleneck people find is that R must have all objects in memory. This means that the computer being used for the analysis must have enough RAM to hold the entire data at once, as well as intermediate and resulting objects, and keep in mind that this RAM is shared with all the other applications running in the computer.</p>
<p class="calibre2">If R doesn't have enough RAM to hold every object in memory, the operating system will perform a <strong class="calibre1">swapping</strong> operation that, within R, will look as if you had all data in memory but data will be written and read from the hard drive <span>in reality</span>. Reading and writing from hard drives is orders of magnitude slower than doing equivalent operations in-memory, and R won't let you know that this is happening since it really can't (this is done by the operating system). To detect that this is happening, you should keep an eye on the tool provided by your operating system to monitor your system's resources.</p>
<p class="calibre2">Even though this is the third bottleneck in the list, when it happens, it's by far the most damaging one, as we have a disk input/output bottleneck on top of the memory bottleneck. When you encounter this problem, you'll be able to tell because R will seem to have frozen or will be unresponsive. If it's happening to you, you should definitely look for ways to eliminate it. It's the third in the list because it's not encountered as often as the previous two, not because it has less of an impact.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Single-threaded processes</h1>
                
            
            <article>
                
<p class="calibre2">The fourth most important bottleneck people encounter is the fact that R language has no explicit constructs for parallelism. An out-of-the-box R installation cannot take advantage of multiple CPUs, and it does not matter if you install R on a powerful server with 64 CPU cores, R will only use one of them.</p>
<p class="calibre2">The way to fix this is to introduce parallelism in your implementations. However, doing so is not an easy task at all. In fact, serious parallelization efforts require deep hardware and software knowledge, and often depend on the specific hardware used to execute an implementation.</p>
<p class="calibre2">Even though it's a very difficult thing to do, and maybe even because of that, R has a lot of packages whose objectives are to provide parallel solutions for specific R functions. There are some general packages you may use to create your own parallel implementations, as we will see later in the chapter, but it's definitely not the first place to start looking for performance enhancements.</p>
<p class="calibre2">Now that you understand why R can be slow, we will use this knowledge to gradually improve the SMA implementation we showed earlier, but before we do that, we must learn to measure our code's performance, and that's the focus of the next section.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Measuring by profiling and benchmarking</h1>
                
            
            <article>
                
<p class="calibre2">There's a common saying which states that you can't change what you can't measure. Even though you <span>can </span>technically change your code's performance in R, you definitely won't be able to know whether a change is worth it if you don't measure it. In this section, we will introduce three tools you can use to measure your code: <kbd class="calibre9">Rprof()</kbd>, <kbd class="calibre9">system.time()</kbd>, and <kbd class="calibre9">microbenchmark()</kbd>. The first two are included in R, and the third one requires the <kbd class="calibre9">microbenchmark</kbd> package to be installed. The <kbd class="calibre9">Rprof()</kbd> tool is used to profile code, while <kbd class="calibre9">system.time()</kbd> and <kbd class="calibre9">microbenchmark()</kbd> are used to benchmark code.</p>
<ul class="calibre11">
<li class="calibre12"><strong class="calibre1">Profiling</strong> means that you measure how much time a particular implementation is spending on each of its parts.</li>
<li class="calibre12"><strong class="calibre1">Benchmarking</strong> means that you compare the total amount of time to execute different implementations to compare them among themselves, without regard for their internal parts.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Profiling fundamentals with Rprof()</h1>
                
            
            <article>
                
<p class="calibre2">Even experienced programmers have a hard time identifying bottlenecks in their code. Unless you have quite a bit of experience and a good sense of what parts of your code are slowing<span> down</span> its execution, you're probably better-off profiling your code before you start optimizing it. Only once you've identified the most important bottlenecks can you attempt to eliminate them. It's difficult to provide general advice on improving performance since every implementation is quite different.</p>
<p class="calibre2">The <kbd class="calibre9">Rprof()</kbd> function is a built-in tool for profiling the execution of R functions. At regular intervals, the profiler stops the interpreter, records the current function call stack, and saves the information to a file. We can then look at summaries of such information to find out where our implementation <span>is </span>spending the most time.</p>
<p class="calibre2">Keep in mind that the results from <kbd class="calibre9">Rprof()</kbd> are stochastic. Each time we use it, the results will be slightly different, depending on many things specific to your system, which are out of R's control. Therefore, the results we get from <kbd class="calibre9">Rprof()</kbd> are estimates and can vary within the sample implementation.</p>
<p class="calibre2">To use the <kbd class="calibre9">Rprof()</kbd> function, we simply call it without parameters before we call the code we want to measure, and then we call it again, this time sending the <kbd class="calibre9">NULL</kbd> parameter. The results are saved to a file in your hard drive and can be invoked with the <kbd class="calibre9">summaryRprof()</kbd> function call.</p>
<p class="calibre2">In this particular case, note that we sent the first 10,000 elements. If we had sent a small amount of data, the <kbd class="calibre9">sma_slow_1()</kbd> function would have finished so fast that we would not have any meaningful output (remember that <kbd class="calibre9">Rprof()</kbd> measures by time intervals). Also, the results shown here are truncated, since the actual results are much larger because they show many function calls our code used. We left the top five results for each table.</p>
<p class="calibre2">Both tables have the same information. The difference is that the <kbd class="calibre9">$by.self</kbd> table (the first one) is ordered by <kbd class="calibre9">self</kbd>, while the <kbd class="calibre9">$by.total</kbd> table (the second one) is ordered by <kbd class="calibre9">total</kbd>; <kbd class="calibre9">self</kbd> indicates how much time a function call took without regard for its child function calls, while <kbd class="calibre9">total</kbd> information includes the child function calls. This means that <kbd class="calibre9">self</kbd> data must sum to <kbd class="calibre9">100</kbd>, while aggregated total data will commonly sum to much more than <kbd class="calibre9">100</kbd>:</p>
<pre class="calibre65">Rprof()
sma_1 &lt;- sma_slow_1(period, symbol, data_original[1:10000, ])
Rprof(NULL)
summaryRprof()
<strong class="calibre1">#&gt; $by.self
#&gt;                         self.time self.pct total.time total.pct
#&gt; "rbind"                      1.06    10.84       6.16     62.99
#&gt; "structure"                  0.82     8.38       0.94      9.61
#&gt; "data.frame"                 0.68     6.95       4.32     44.17
#&gt; "[.data.frame"               0.54     5.52       1.76     18.00
#&gt; "sma_slow_1"                 0.48     4.91       9.78    100.00
#&gt; (Truncated output)
#&gt;
#&gt; $by.total
#&gt;                         total.time total.pct self.time self.pct
#&gt; "sma_slow_1"                  9.78    100.00      0.48     4.91
#&gt; "rbind"                       6.16     62.99      1.06    10.84
#&gt; "data.frame"                  4.32     44.17      0.68     6.95
#&gt; "["                           1.88     19.22      0.20     2.04
#&gt; "as.data.frame"               1.86     19.02      0.10     1.02
#&gt; (Truncated output)
#&gt;
#&gt; $sample.interval
#&gt; [1] 0.02
#&gt;
#&gt; $sampling.time
#&gt; [1] 9.78</strong></pre>
<p class="calibre2">As you can see in the results, the first column indicates a function call in the stack, and the numbers indicate how much time was spent in a particular function call, either in absolute (<kbd class="calibre9">time</kbd>) or relative terms (<kbd class="calibre9">pct</kbd>). Normally, you'll want to focus on the top values in the <kbd class="calibre9">self.pct</kbd> column of the <kbd class="calibre9">$by.self</kbd> table, since they show the functions that are taking the most amount of time by themselves. In this particular case, <kbd class="calibre9">rbind</kbd>, <kbd class="calibre9">structure</kbd>, and <kbd class="calibre9">data.frame</kbd> are the functions taking the most amount of time.</p>
<p class="calibre2">Finally, you should know that some of the names found in the functions call stack can be very cryptic, and sometimes you'll have a hard time finding references or documentation for them. This is because they are probably internal R implementations that are not meant to be used directly by R users. What I suggest is that you simply try to fix those function calls that you recognize, unless you're dealing with situations where highly-optimized code is an absolute requirement, but in that case, you would be better off reading a specialized book on the subject.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Benchmarking manually with system.time()</h1>
                
            
            <article>
                
<p class="calibre2">Now, we will look into how to benchmark your code. If you're looking for a simple measurement of execution time, <kbd class="calibre9">system.time()</kbd> is a good choice. You simply call a function inside of it, and it will print the following three time measures for you: .</p>
<ul class="calibre11">
<li class="calibre12"><kbd class="calibre9">user</kbd>: It is the <kbd class="calibre9">user</kbd> time that we should pay more attention to, since it measures the CPU time used by R to execute the code</li>
<li class="calibre12"><kbd class="calibre9">system</kbd>: The <kbd class="calibre9">system</kbd> time is a measure of time spent by the system to be able to execute the function</li>
<li class="calibre12"><kbd class="calibre9">elapsed</kbd>:  The <kbd class="calibre9">elapsed</kbd> time is total time it took to execute the code, even if it was slowed down due to other system processes</li>
</ul>
<p class="calibre2">Sometimes, <kbd class="calibre9">elapsed</kbd> time is longer than the sum of <kbd class="calibre9">user</kbd> time and <kbd class="calibre9">system</kbd> time because the CPU is multitasking on other processes, or it has to wait for resources such as files and network connections to be available. Other times, elapsed time is shorter than the sum of <kbd class="calibre9">user</kbd> time and <kbd class="calibre9">system</kbd> time. This can happen when multiple threads or CPUs are used to execute the expression. For example, a task that takes 10 seconds of user time can be completed in 5 seconds if there are two CPUs sharing the load.</p>
<p class="calibre2">Most of the time, however, we are interested in the total elapsed time to execute the given expression. When the expression is executed on a single thread (the default for R), the elapsed time is usually very close to the sum of the <kbd class="calibre9">user</kbd> time and <kbd class="calibre9">system</kbd> time. If that is not the case, either the expression has spent time waiting for resources to be available, or there were many other processes on the system competing for the CPU's time. In any case, if you're suspicious of your measurements, try measuring the same code various times while the computer is not spending resources in other applications.</p>
<p class="calibre2">In this particular case, we see that the execution took approximately 9 seconds to complete, which is roughly equivalent to the same time it took to execute it when measured by <kbd class="calibre9">Rprof()</kbd> in the previous section, as can be seen in the column  <kbd class="calibre9">total.time</kbd> on the <kbd class="calibre9">sma_slow_1</kbd> observation of the <kbd class="calibre9">$by.total</kbd> table.</p>
<pre class="calibre65">system.time(sma_slow_1(period, symbol, data_original[1:10000, ]))
<strong class="calibre1">#&gt;   user  system elapsed
#&gt;  9.251   0.015   9.277</strong></pre>
<p class="calibre2">If you want to measure multiple functions to compare their times, you will have to use the <kbd class="calibre9">system.time()</kbd> function on each of them, so it's somewhat of a manual process. A better alternative for such a thing is the <kbd class="calibre9">microbenchmark()</kbd> function shown in the next section.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Benchmarking automatically with microbenchmark()</h1>
                
            
            <article>
                
<p class="calibre2">If you have identified a function that is called many times in your code and needs to be accelerated, you can write several implementations for it and use the <kbd class="calibre9">microbenchmark()</kbd> function from the <kbd class="calibre9">microbenchmark</kbd> package to compare them. Its results will <span>also </span><span>normally </span>be more reliable because, by default, it runs each function 100 times and thus is able to produce statistics on its performance.</p>
<p class="calibre2">To use the <kbd class="calibre9">microbenchmark()</kbd> function, you simply wrap it around a piece of code you want to measure. Some handy features are that you can make an assignment, within which it's very handy to measure and use the results in one go; also, you can pass various function calls separated by commas, and it will give you results for each of them. This way, you can automatically benchmark various functions at the same time.</p>
<p class="calibre2">Here, we will assign the results of <kbd class="calibre9">sma_slow_1()</kbd> to <kbd class="calibre9">sma_1</kbd>, as we did previously, but since it's wrapped with the <kbd class="calibre9">microbenchmark()</kbd> function, it will also be measured and the performance results will be stored in the <kbd class="calibre9">performance</kbd> data frame. This object contains the following columns: <kbd class="calibre9">expr</kbd> is a string that contains the function call used, <kbd class="calibre9">neval</kbd> is the number of times the function was executed (by default, it's <kbd class="calibre9">100</kbd>), and the <kbd class="calibre9">min</kbd>, <kbd class="calibre9">lq</kbd> (first quartile), <kbd class="calibre9">mean</kbd>, <kbd class="calibre9">median</kbd>, <kbd class="calibre9">uq</kbd> (third quartile), and <kbd class="calibre9">max</kbd> statistics:</p>
<pre class="calibre65">performance &lt;- microbenchmark(
    sma_1 &lt;- sma_slow_1(period, symbol, data),
    unit = "us"
)
<br class="title-page-name"/>summary(performance)$median
<strong class="calibre1">#&gt; [1] 81035.19</strong></pre>
<p class="calibre2">If you want to look at the full performance data frame, simply print it. Here, we only showed that the <kbd class="calibre9">median</kbd> time it took when executing the <kbd class="calibre9">sma_slow_1()</kbd> function call was <kbd class="calibre9">81,035.19</kbd> microseconds (which was the unit specified with the <kbd class="calibre9">unit = "us"</kbd> parameter). By default, this would have used milliseconds instead of microseconds, but we want to provide the same units for all comparisons we perform along the chapter, and microseconds is a better option for that.</p>
<p class="calibre2">We will continue to add records to the following table. Each row will contain an implementation identifier, the median microseconds it took to execute such a function, indication of the fastest implementation so far, and a percentage when being compared to the fastest one we have so far. In this particular case, since it's the only one we have done, it is obviously the fastest one and is <span>also </span>100% from the best one, which is itself:</p>
<table class="calibre5">
<tbody class="calibre6">
<tr class="calibre7">
<td class="calibre8">
<p class="calibre2"><strong class="calibre1">Fastest</strong></p>
</td>
<td class="calibre8">
<p class="calibre2"><strong class="calibre1">Implementation</strong></p>
</td>
<td class="calibre8">
<p class="calibre2"><strong class="calibre1">Microseconds median</strong></p>
</td>
<td class="calibre8">
<p class="calibre2"><strong class="calibre1">% From Fastest</strong></p>
</td>
</tr>
<tr class="calibre7">
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9">    ⇒</kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9">sma_slow_1</kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9">81,035.19</kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9">100%</kbd></p>
</td>
</tr>
</tbody>
</table>
<p class="calibre2"> </p>
<p class="calibre2">The objective of the rest of the chapter is to extend this table to provide precise measurements of just how much performance improvements we're making as we improve our SMA implementation.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Easily achieving high benefit - cost improvements</h1>
                
            
            <article>
                
<p class="calibre2">In this section, we will show how the efficiency of <span>R </span>can be drastically improved without resorting to advanced techniques such as delegating to other programming languages or implementing parallelization. Those techniques will be shown in the later sections.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Using the simple data structure for the job</h1>
                
            
            <article>
                
<p class="calibre2">Many R users would agree that data frame as a data structure is a basic tool for data analysis. It provides an intuitive way to represent a typical structured dataset with rows and columns representing observations and variables, respectively, but it provides more flexibility than a matrix by allowing variables of different types (such as character and numeric variables in a single structure). Furthermore, when data frames contain only numeric variables, basic matrix operations conveniently become applicable to it without any explicit coercing required. This convenience, however, comes with a performance cost that people often don't mention.</p>
<p class="calibre2">Here, we avoid repeating the <kbd class="calibre9">Rprof()</kbd> results we got from profiling the <kbd class="calibre9">sma_slow_1()</kbd> function. However, if you look back at them, you will see that <kbd class="calibre9">rbind()</kbd> and <kbd class="calibre9">data.frame()</kbd> were among the functions that took the most time. This is precisely the performance cost mentioned earlier. If you want your implementations to be faster, avoiding using data frames can be a good start. Data frames can be a great tool for data analysis, but not when writing fast code.</p>
<p class="calibre2">As you can see in <kbd class="calibre9">sma_slow_2()</kbd>, the code is practically the same as <kbd class="calibre9">sma_slow_1()</kbd>, except that the <kbd class="calibre9">period_prices</kbd> object is no longer a data frame. Instead, it has become a vector, which is extended with the <kbd class="calibre9">c()</kbd> function in place of the <kbd class="calibre9">rbind()</kbd> function. Note that we are still dynamically expanding the size of an object when calling the <kbd class="calibre9">c()</kbd> function, which is something you shouldn't be doing for performant code, but we will take it step-by-step:</p>
<pre class="mce-root"><span>sma_slow_</span><span>2 </span><span>&lt;- </span><span>function</span><span>(period, symbol, data) {</span> <br class="title-page-name"/>    result &lt;- data.frame(sma=numeric())<br class="title-page-name"/>    for(end in 1:nrow(data)) {<br class="title-page-name"/>        position &lt;- end<br class="title-page-name"/>        sma &lt;- NA<br class="title-page-name"/>        n_accumulated &lt;- 0<br class="title-page-name"/>        period_prices &lt;- NULL<br class="title-page-name"/>        if(data[end, "symbol"] == symbol) {<br class="title-page-name"/>            while(n_accumulated &lt; period &amp; position &gt;= 1) {<br class="title-page-name"/>                if(data[position, "symbol"] == symbol) {<br class="title-page-name"/>                    period_prices &lt;- c(period_prices, <br class="title-page-name"/>                        data[position, "price_usd"])<br class="title-page-name"/>                    n_accumulated &lt;- n_accumulated + 1<br class="title-page-name"/>                }<br class="title-page-name"/>                position &lt;- position - 1<br class="title-page-name"/>            }<br class="title-page-name"/>            if (n_accumulated == period) {<br class="title-page-name"/>                sma &lt;- 0<br class="title-page-name"/>                for (price in period_prices) {<br class="title-page-name"/>                    sma &lt;- sma + price<br class="title-page-name"/>                }<br class="title-page-name"/>                sma &lt;- sma / period<br class="title-page-name"/>            } else {<br class="title-page-name"/>                sma &lt;- NA    <br class="title-page-name"/>            }<br class="title-page-name"/>            result &lt;- rbind(result, data.frame(sma=sma))<br class="title-page-name"/>        }<br class="title-page-name"/>    }<br class="title-page-name"/>    return(result)<br class="title-page-name"/>}</pre>
<p class="calibre2">In this case, we measure its execution time just as we did earlier, but we also perform a very important verification, which is often overlooked. We verify that the values we get from <kbd class="calibre9">sma_slow_1()</kbd> are the same as those we get from <kbd class="calibre9">sma_slow_2()</kbd>. It wouldn't be a correct comparison if we measured implementations that do different things. Performing the check is also useful to increase our confidence that every change we make does not introduce unexpected behavior. As can be seen, all values are the same, so we can proceed with confidence:</p>
<pre class="mce-root">performance &lt;- microbenchmark(
    sma_2 &lt;- sma_slow_2(period, symbol, data),
    unit = "us"
)
<br class="title-page-name"/>all(sma_1$sma == sma_2$sma, na.rm = TRUE)
<strong class="calibre1">#&gt; TRUE</strong>
<br class="title-page-name"/>summary(performance)$median
<strong class="calibre1">#&gt; [1] 33031.7785</strong></pre>
<p class="calibre2">We record our results in our table, and realize that removing this data frame structure allowed us to remove two-thirds of the execution time. That's pretty good for such an easy change, isn't it? Since our base case (the fastest implementation we have so far) is <kbd class="calibre9">sma_slow_2()</kbd>, we can see that <kbd class="calibre9">sma_slow_1()</kbd> would take approximately 145% more time to execute:</p>
<table class="calibre5">
<tbody class="calibre6">
<tr class="calibre7">
<td class="calibre8">
<p class="calibre2"><strong class="calibre1">Fastest</strong></p>
</td>
<td class="calibre8">
<p class="calibre2"><strong class="calibre1">Implementation</strong></p>
</td>
<td class="calibre8">
<p class="calibre2"><strong class="calibre1">Microseconds median</strong></p>
</td>
<td class="calibre8">
<p class="calibre2"><strong class="calibre1">% from fastest</strong></p>
</td>
</tr>
<tr class="calibre7">
<td class="calibre8"/>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9">sma_slow_1</kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9">81,035.1900</kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9">245.32%</kbd></p>
</td>
</tr>
<tr class="calibre7">
<td class="calibre8">
<p class="calibre2">⇒</p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>sma_slow_2</span></kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9">33,031.7785</kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9">100%</kbd></p>
</td>
</tr>
</tbody>
</table>
<p class="calibre2">Now that we realize what an impact unnecessary data frames <span>can </span>have in the performance of our code, we proceed to also remove the other data frame we were using for the <kbd class="calibre9">result</kbd> object. We also replace it with a vector, and use the <kbd class="calibre9">c()</kbd> function to append to it. The same dynamic expansion problem mentioned earlier appears here, too. As you can see, everything else is kept the same.</p>
<p class="calibre2">We proceed to benchmark as we did earlier, and also check that the results we got are also the same. The cautious reader may have noted that the previous check was performed with an equality operator, while this one is performed with an inequality operator. In reality, when checking real numbers, you're better off checking that they are close enough as opposed to exactly the same. If you checked for identical numbers, you may get a <kbd class="calibre9">FALSE</kbd> result due to one of the numbers having a difference of <kbd class="calibre9">0.000000001</kbd>, which is not significant in our case. Therefore, we establish what is a significant check for our specific use case, and test that each pair of numbers has a difference not larger than that threshold, just as we do here, with our threshold being <kbd class="calibre9">0.001</kbd>:</p>
<pre class="mce-root">performance &lt;- microbenchmark(
    sma_3 &lt;- sma_slow_3(period, symbol, data),
    unit = "us"
)
<br class="title-page-name"/>all(sma_1$sma - sma_3 &lt;= 0.001, na.rm = TRUE)
<strong class="calibre1">#&gt; TRUE
</strong><br class="title-page-name"/>summary(performance)$median
<strong class="calibre1">#&gt; [1] 19628.243</strong></pre>
<p class="calibre2">In this case, the median time it took to execute <kbd class="calibre9">sma_slow_3()</kbd> was of <kbd class="calibre9">19,628.243</kbd> microseconds. We go ahead and record that into our table, and recalculate the percentage from the best, which is <kbd class="calibre9">sma_slow_3()</kbd> at this point. Note that we are able to remove close to half the time from the already improved <kbd class="calibre9">sma_slow_2()</kbd> function, and that using the original <kbd class="calibre9">sma_slow_1()</kbd> function will take 312% more time than the latest one. It can be surprising how much performance gain you can get by simply using a simpler data structure.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Vectorizing as much as possible</h1>
                
            
            <article>
                
<p class="calibre2">Vectorization means removing a manual looping mechanism in favor of an operation optimized to do the same thing without a need for an explicit loop. It is very helpful because it helps avoid the overhead incurred on by explicit loops in R. Vectorizing is a fundamental tool in R, and you should get used to programming using it instead of using explicit loops whenever possible, without waiting until a performance stage comes into play. Once you understand how it works, it will come naturally. A good read for this topic is Ross's blog post, <em class="calibre19">Vectorization in R: Why?</em> (<a href="http://www.noamross.net/blog/2014/4/16/vectorization-in-r--why.html" class="calibre4">http://www.noamross.net/blog/2014/4/16/vectorization-in-r--why.html</a>).</p>
<div class="packt_tip">Explicit loops may be efficient in other languages, such as Fortran and C++. However, in R, you're better off using vectorization most of the time.</div>
<p class="calibre2">There are various ways of vectorizing operations. For example, if you want to perform a matrix-vector multiplication, instead of iterating over the elements of vector and the matrix, multiplying the appropriate coefficients, and adding them together as is normally done in other programming languages, you can simply do something like <kbd class="calibre9">A %*% b</kbd> to perform all of those operations in a vectorized manner <span>in R</span>. Vectorization provides more expressive code that is easier to understand as well as more performant, and that's why you should always attempt to use it.</p>
<p class="calibre2">Another way of vectorizing is using the family of the <kbd class="calibre9">apply()</kbd> function R provides (for example, <kbd class="calibre9">lapply()</kbd>, <kbd class="calibre9">sapply()</kbd>, and so on). This will produce simpler code than explicit loops and will also make your implementation faster. In reality, the <kbd class="calibre9">apply()</kbd> function is a special case since it's not as optimized as the other functions in its family, so the performance gains won't be as much as with the other functions, but the code clarity will indeed increase.</p>
<p class="calibre2">Another way of vectorizing code is to replace loops with R built-in functions, and that's the case we will use in the next modification. In the third <kbd class="calibre9">if</kbd> in the code, the one after the <kbd class="calibre9">while</kbd> loop has finished, there's a <kbd class="calibre9">for</kbd> loop that adds the elements we have in the <kbd class="calibre9">period_prices</kbd> vector, and then it is divided by the <kbd class="calibre9">period</kbd> vector to produce the mean. We can simply use the <kbd class="calibre9">mean()</kbd> function instead of using such a loop, and that's what we do.</p>
<p class="calibre2">Now, when you read that part of the code, it reads easily as if the number accumulated prices is equal to the period, making the SMA equal to the mean of the accumulated prices. It's much easier to understand code than using the loop:</p>
<pre class="calibre65"><span>sma_slow_</span><span>4 </span><span>&lt;- </span><span>function</span><span>(period, symbol, data) {<br class="title-page-name"/>    result &lt;- </span><span>NULL<br class="title-page-name"/></span><span>    for</span><span>(end </span><span>in </span><span>1</span><span>:</span><span>nrow</span><span>(data)) {<br class="title-page-name"/>        position &lt;- end<br class="title-page-name"/>        sma &lt;- </span><span>NA<br class="title-page-name"/></span><span>        n_accumulated &lt;- </span><span>0<br class="title-page-name"/></span><span>        period_prices &lt;- </span><span>NULL<br class="title-page-name"/></span><span>        if </span><span>(data[end, </span><span>"symbol"</span><span>] </span><span>== </span><span>symbol) {<br class="title-page-name"/></span><span>            while</span><span>(n_accumulated </span><span>&lt; </span><span>period </span><span>&amp; </span><span>position </span><span>&gt;= </span><span>1</span><span>) {<br class="title-page-name"/></span><span>                if </span><span>(data[position, </span><span>"symbol"</span><span>] </span><span>== </span><span>symbol) {<br class="title-page-name"/>                    period_prices &lt;- </span><span>c</span><span>(period_prices, <br class="title-page-name"/>                        data[position, </span><span>"price_usd"</span><span>])<br class="title-page-name"/>                    n_accumulated &lt;- n_accumulated </span><span>+ </span><span>1<br class="title-page-name"/></span><span>                }<br class="title-page-name"/>                position &lt;- position </span><span>- </span><span>1<br class="title-page-name"/></span><span>            }<br class="title-page-name"/></span><span>            if </span><span>(n_accumulated </span><span>== </span><span>period) {<br class="title-page-name"/>                sma &lt;- </span><span>mean</span><span>(period_prices)<br class="title-page-name"/>            } </span><span>else </span><span>{<br class="title-page-name"/>                sma &lt;- </span><span>NA<br class="title-page-name"/></span><span>            }<br class="title-page-name"/>            result &lt;- </span><span>c</span><span>(result, sma)<br class="title-page-name"/>        }<br class="title-page-name"/>    }<br class="title-page-name"/></span><span>    return</span><span>(result)<br class="title-page-name"/>}</span> </pre>
<p class="calibre2">Again, we benchmark and check correctness. However, in this case, we find that the median time is <kbd class="calibre9">20,825.879</kbd> microseconds, which is more than the current minimum from <kbd class="calibre9">sma_slow_3()</kbd>. Wasn't vectorized code supposed to be faster? The answer is that most of the time it is, but in situations like this, there's an overhead within the <kbd class="calibre9">mean()</kbd> function, due to the fact that it needs to check what type of object it's dealing with, before using it for any operations, which can cause an implementation to be slower. When we were using the explicit loop, the sums and the division incurred in a much lower overhead because they could be applied to a much smaller set of objects. Therefore, as you see in the table below, <kbd class="calibre9">sma_slow_4()</kbd> takes 6% more time than <kbd class="calibre9">sma_slow_3()</kbd>. This is not much, and since I prefer expressive code, I'll keep the change:</p>
<pre class="calibre65">performance &lt;- microbenchmark(
    sma_4 &lt;- sma_slow_4(period, symbol, data),
    unit = "us"
)<br class="title-page-name"/><br class="title-page-name"/>all(sma_1$sma - sma_4 &lt;= 0.001, na.rm = TRUE)
<strong class="calibre1">#&gt; TRUE</strong>
<br class="title-page-name"/>summary(performance)$median
<strong class="calibre1">#&gt; [1] 20825.8790</strong></pre>
<p class="calibre2">Take a look at the following table:</p>
<table class="calibre5">
<tbody class="calibre6">
<tr class="calibre7">
<td class="calibre8">
<p class="calibre2"><strong class="calibre1">Fastest</strong></p>
</td>
<td class="calibre8">
<p class="calibre2"><strong class="calibre1">Implementation</strong></p>
</td>
<td class="calibre8">
<p class="calibre2"><strong class="calibre1">Microseconds median</strong></p>
</td>
<td class="calibre8">
<p class="calibre2"><strong class="calibre1">% from fastest</strong></p>
</td>
</tr>
<tr class="calibre7">
<td class="calibre8"/>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>sma_slow_1</span></kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>81,035.1900</span></kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>412.84 %</span></kbd></p>
</td>
</tr>
<tr class="calibre7">
<td class="calibre8">
<p class="calibre2"> </p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>sma_slow_2</span></kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>33,031.7785</span></kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>168.28 %</span></kbd></p>
</td>
</tr>
<tr class="calibre7">
<td class="calibre8">
<p class="calibre2">⇒</p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>sma_slow_3</span></kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>19,628.2430</span></kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>100 %</span></kbd></p>
</td>
</tr>
<tr class="calibre7">
<td class="calibre8"/>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>sma_slow_4</span></kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>20,825.8790</span></kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>106.10 %</span></kbd></p>
</td>
</tr>
</tbody>
</table>
<p class="calibre2"> </p>
<p class="calibre2">If you want to compare the overhead of the <kbd class="calibre9">mean()</kbd> function to the overhead of other ways of doing the same calculation, take a look at the following benchmark. The <kbd class="calibre9">.Internal(mean(x))</kbd> function avoids the dispatch mechanism for methods we showed in the previous chapter and skips directly to a C implementation of the <kbd class="calibre9">mean()</kbd> function, as shown in the following code snippet:</p>
<pre class="calibre65">x &lt;- sample(100)
performance &lt;- microbenchmark(
    mean(x),
    sum(x) / length(x),
    .Internal(mean(x)),
    times = 1e+05
)
<br class="title-page-name"/>performance
<strong class="calibre1">#&gt; Unit: nanoseconds
#&gt;                expr  min   lq      mean median   uq      max neval
#&gt;             mean(x) 1518 1797 2238.2607   1987 2230  2335285 1e+05
#&gt;    sum(x)/length(x)  291  345  750.2324    403  488 27016544 1e+05
#&gt;  .Internal(mean(x))  138  153  187.0588    160  176    34513 1e+05</strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Removing unnecessary logic</h1>
                
            
            <article>
                
<p class="calibre2">There are times when simple logic shows us that there are parts of our implementations that are unnecessary. In this particular case, the accumulation of <kbd class="calibre9">period_prices</kbd> can be avoided by setting <kbd class="calibre9">sma</kbd> to <kbd class="calibre9">0</kbd> initially instead of <kbd class="calibre9">NA</kbd>, and adding to it each price. However, when doing so, we lose track of the number of elements in the vector, so the <kbd class="calibre9">mean()</kbd> function doesn't make sense any more, and we proceed to simply divide the sum by <kbd class="calibre9">period</kbd> as we were doing earlier:</p>
<pre class="calibre65"><span>sma_slow_</span><span>5 </span><span>&lt;- </span><span>function</span><span>(period, symbol, data) {<br class="title-page-name"/>    result &lt;- </span><span>NULL<br class="title-page-name"/></span><span>    for</span><span>(end </span><span>in </span><span>1</span><span>:</span><span>nrow</span><span>(data)) {<br class="title-page-name"/>        position &lt;- end<br class="title-page-name"/>        sma &lt;- </span><span>0<br class="title-page-name"/></span><span>        n_accumulated &lt;- </span><span>0<br class="title-page-name"/></span><span>        if </span><span>(data[end, </span><span>"symbol"</span><span>] </span><span>== </span><span>symbol) {<br class="title-page-name"/></span><span>            while</span><span>(n_accumulated </span><span>&lt; </span><span>period </span><span>&amp; </span><span>position </span><span>&gt;= </span><span>1</span><span>) {<br class="title-page-name"/></span><span>                if </span><span>(data[position, </span><span>"symbol"</span><span>] </span><span>== </span><span>symbol) {<br class="title-page-name"/>                    sma &lt;- sma </span><span>+ </span><span>data[position, </span><span>"price_usd"</span><span>]<br class="title-page-name"/>                    n_accumulated &lt;- n_accumulated </span><span>+ </span><span>1<br class="title-page-name"/></span><span>                }<br class="title-page-name"/>                position &lt;- position </span><span>- </span><span>1<br class="title-page-name"/></span><span>            }<br class="title-page-name"/></span><span>            if </span><span>(n_accumulated </span><span>== </span><span>period) {<br class="title-page-name"/>                sma &lt;- sma </span><span>/ </span><span>period<br class="title-page-name"/>            } </span><span>else </span><span>{<br class="title-page-name"/>                sma &lt;- </span><span>NA<br class="title-page-name"/></span><span>            }<br class="title-page-name"/>            result &lt;- </span><span>c</span><span>(result, sma)<br class="title-page-name"/>        }<br class="title-page-name"/>    }<br class="title-page-name"/></span><span>    return</span><span>(result)<br class="title-page-name"/>}</span></pre>
<p class="calibre2">Again, we benchmark and check correctness, as shown in the following code snippet:</p>
<pre class="calibre65">performance &lt;- microbenchmark(
    sma_5 &lt;- sma_slow_5(period, symbol, data),
    unit = "us"
)
<br class="title-page-name"/>all(sma_1$sma - sma_5 &lt;= 0.001, na.rm = TRUE)
<strong class="calibre1">#&gt; TRUE</strong>
<br class="title-page-name"/>summary(performance)$median
<strong class="calibre1">#&gt; [1] 16682.68</strong></pre>
<p class="calibre2">In this case, our median time was <kbd class="calibre9">16682.68</kbd> microseconds, making this our fastest implementation so far. Again, note how a very simple change produced a reduction of around 17% with respect to the previously fastest implementation:</p>
<table class="calibre5">
<tbody class="calibre6">
<tr class="calibre7">
<td class="calibre8"><strong class="calibre1">Fastest</strong></td>
<td class="calibre8">
<p class="calibre2"><strong class="calibre1">Implementation</strong></p>
</td>
<td class="calibre8">
<p class="calibre2"><strong class="calibre1">Microseconds median</strong></p>
</td>
<td class="calibre8">
<p class="calibre2"><strong class="calibre1">% from fastest</strong></p>
</td>
</tr>
<tr class="calibre7">
<td class="calibre8"/>
<td class="calibre8"><kbd class="calibre41"><span>sma_slow_1</span></kbd></td>
<td class="calibre8"><kbd class="calibre41"><span>81,035.1900</span></kbd></td>
<td class="calibre8"><kbd class="calibre41"><span>485.74 %</span></kbd></td>
</tr>
<tr class="calibre7">
<td class="calibre8"/>
<td class="calibre8"><kbd class="calibre41"><span>sma_slow_2</span></kbd></td>
<td class="calibre8"><kbd class="calibre41"><span>33,031.7785</span></kbd></td>
<td class="calibre8"><kbd class="calibre41"><span>198.00 %</span></kbd></td>
</tr>
<tr class="calibre7">
<td class="calibre8"/>
<td class="calibre8"><kbd class="calibre41"><span>sma_slow_3</span></kbd></td>
<td class="calibre8"><kbd class="calibre41"><span>19,628.2430</span></kbd></td>
<td class="calibre8"><kbd class="calibre41"><span>117.65 %</span></kbd></td>
</tr>
<tr class="calibre7">
<td class="calibre8"/>
<td class="calibre8"><kbd class="calibre41"><span>sma_slow_4</span></kbd></td>
<td class="calibre8"><kbd class="calibre41"><span>20,825.8790</span></kbd></td>
<td class="calibre8"><kbd class="calibre41"><span>124.83 %</span></kbd></td>
</tr>
<tr class="calibre7">
<td class="calibre8">⇒</td>
<td class="calibre8"><kbd class="calibre41"><span>sma_slow_5</span></kbd></td>
<td class="calibre8"><kbd class="calibre41"><span>16,682.6800</span></kbd></td>
<td class="calibre8"><kbd class="calibre41"><span>100 %</span></kbd></td>
</tr>
</tbody>
</table>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Moving checks out of iterative processes</h1>
                
            
            <article>
                
<p class="calibre2">Suppose that we're stuck in our optimization process and don't know what we should change next. What should we do? Well, as we mentioned earlier, we should profile our code to find out our current bottlenecks, and that's what we do here. We use the <kbd class="calibre9">Rprof()</kbd> function again to profile our <kbd class="calibre9">sma_slow_5()</kbd> implementation.</p>
<p class="calibre2">The results show that the <kbd class="calibre9">[.data.frame</kbd> and <kbd class="calibre9">[</kbd> functions are our biggest bottlenecks, and although their names are a bit cryptic, we can guess that they are related to subsetting data frames (which they are). This means that our current most important bottleneck is checking whether we are at an observation that corresponds to <kbd class="calibre9">symbol</kbd> we are using, and we are performing such checks at different places in our code:</p>
<pre class="calibre65">Rprof()
sma_5 &lt;- sma_slow_5(period, symbol, data_original[1:10000, ])
Rprof(NULL)
summaryRprof()
<strong class="calibre1">#&gt; $by.self
#&gt;                self.time self.pct total.time total.pct
#&gt; "[.data.frame"      0.54    26.21       1.24     60.19
#&gt; "["                 0.22    10.68       1.34     65.05
#&gt; "NextMethod"        0.20     9.71       0.20      9.71
#&gt; "sma_slow_5"        0.14     6.80       2.06    100.00
#&gt; "Ops.factor"        0.12     5.83       0.52     25.24
#&gt; (Truncated output)
#&gt;
#&gt; $by.total
#&gt;                  total.time total.pct self.time self.pct
#&gt; "sma_slow_5"           2.06    100.00      0.14     6.80
#&gt; "["                    1.34     65.05      0.22    10.68
#&gt; "[.data.frame"         1.24     60.19      0.54    26.21
#&gt; "Ops.factor"           0.52     25.24      0.12     5.83
#&gt; "NextMethod"           0.20      9.71      0.20     9.71
#&gt; (Truncated output)</strong></pre>
<p class="calibre2">Now that we know our current largest bottleneck, we can remove it by avoiding to check whether the current observation corresponds <kbd class="calibre9">symbol</kbd> we receive as a parameter. To accomplish this, we simply introduce a filter at the beginning of the function that keeps only observations that contain the correct symbol.</p>
<p class="calibre2">Note that this simple filter allows us to remove the two checks we were performing earlier, since we are sure that all observations have the correct symbol. This reduces two indentation levels in our code, since these checks were nested. Doing so feels great, doesn't it? Now it seems that we have a very simple implementation which will <span>intuitively </span>perform much better.</p>
<p class="calibre2">To verify this, we proceed to benchmark and check for correctness, as earlier:</p>
<pre class="calibre65">performance &lt;- microbenchmark(
    sma_6 &lt;- sma_slow_6(period, symbol, data),
    unit = "us"
)
<br class="title-page-name"/>all(sma_1$sma - sma_6 &lt;= 0.001, na.rm = TRUE)
<strong class="calibre1">#&gt; TRUE</strong>
<br class="title-page-name"/>summary(performance)$median
<strong class="calibre1">#&gt; [1] 2991.5720</strong></pre>
<p class="calibre2">Also, our intuition is confirmed; our median time for <kbd class="calibre9">sma_slow_6()</kbd> is <kbd class="calibre9">2,991.57</kbd>. That's only 17% from the previously fastest implementation we had, which was <kbd class="calibre9">sma_slow_5()</kbd>, and it takes only 3% of the time that our initial implementation took. Is this awesome or what? Take a look at the following table:</p>
<table class="calibre5">
<tbody class="calibre6">
<tr class="calibre7">
<td class="calibre8">
<p class="calibre2"><strong class="calibre1">Fastest</strong></p>
</td>
<td class="calibre8">
<p class="calibre2"><strong class="calibre1">Implementation</strong></p>
</td>
<td class="calibre8">
<p class="calibre2"><strong class="calibre1">Microseconds median</strong></p>
</td>
<td class="calibre8">
<p class="calibre2"><strong class="calibre1">% from fastest</strong></p>
</td>
</tr>
<tr class="calibre7">
<td class="calibre8"/>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>sma_slow_1</span></kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>81,035.1900</span></kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>2,708.78 %</span></kbd></p>
</td>
</tr>
<tr class="calibre7">
<td class="calibre8"/>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>sma_slow_2</span></kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>33,031.7785</span></kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>1,104.16 %</span></kbd></p>
</td>
</tr>
<tr class="calibre7">
<td class="calibre8"/>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>sma_slow_3</span></kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>19,628.2430</span></kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>656.11 %</span></kbd></p>
</td>
</tr>
<tr class="calibre7">
<td class="calibre8"/>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>sma_slow_4</span></kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>20,825.8790</span></kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>696.15 %</span></kbd></p>
</td>
</tr>
<tr class="calibre7">
<td class="calibre8"/>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>sma_slow_5</span></kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>16,682.6800</span></kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>557.65 %</span></kbd></p>
</td>
</tr>
<tr class="calibre7">
<td class="calibre8">
<p class="calibre2">⇒</p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>sma_slow_6</span></kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>2,991.5720</span></kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>100 %</span></kbd></p>
</td>
</tr>
</tbody>
</table>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">If you can, avoid iterating at all</h1>
                
            
            <article>
                
<p class="calibre2">In the previous section, we realized how large an impact can unnecessary overhead within iterations have on our implementation's performance. However, what if we could avoid iterating at all? Now that would be better, wouldn't it? Well, as we mentioned earlier, doing so is achievable with vectorization.</p>
<p class="calibre2">In this case, we will remove the <kbd class="calibre9">while</kbd> loop and replace it with a vectorized mean over the <kbd class="calibre9">start</kbd> and <kbd class="calibre9">end</kbd> positions, where <kbd class="calibre9">end</kbd> continues to be defined as it has been so far, and <kbd class="calibre9">start</kbd> is defined as the <kbd class="calibre9">end</kbd> position minus <kbd class="calibre9">period</kbd> we receive as a parameter, plus one. This ensures that we get the exact number of prices we need, and we can create an interval with <kbd class="calibre9">start:end</kbd> that will take the specific subset we need from <kbd class="calibre9">data</kbd> so that we can apply the <kbd class="calibre9">mean()</kbd> function to it:</p>
<pre class="calibre65">sma_slow_7 &lt;- function(period, symbol, data) {<br class="title-page-name"/>    data &lt;- data[data$symbol == symbol, ]<br class="title-page-name"/>    result &lt;- NULL<br class="title-page-name"/>    for(end in 1:nrow(data)) {<br class="title-page-name"/>        start &lt;- end - period + 1<br class="title-page-name"/>        if (start &gt;= 1) {<br class="title-page-name"/>            sma &lt;- mean(data[start:end, "price_usd"])<br class="title-page-name"/>        } else {<br class="title-page-name"/>            sma &lt;- NA<br class="title-page-name"/>        }<br class="title-page-name"/>        result &lt;- c(result, sma)<br class="title-page-name"/>    }<br class="title-page-name"/>    return(result)<br class="title-page-name"/>}</pre>
<p class="calibre2">Note that this change would not have been possible if we had not filtered the data at the top of the function, since we would have observations that correspond to different symbols mixed among themselves and our <kbd class="calibre9">start:end</kbd> interval would pick observations that contain other symbols. This goes to show that sometimes optimizations depend on each other, and one can't be applied without applying a previous one, and these relations are often found accidentally.</p>
<p class="calibre2">As always, we benchmark and check for correctness as shown  in the following code snippet:</p>
<pre class="calibre65">performance &lt;- microbenchmark(
    sma_7 &lt;- sma_slow_7(period, symbol, data),
    unit = "us"
)
<br class="title-page-name"/>all(sma_1$sma - sma_7 &lt;= 0.001, na.rm = TRUE)
<strong class="calibre1">#&gt; TRUE</strong>
<br class="title-page-name"/>summary(performance)$median
<strong class="calibre1">#&gt; [1] 910.793</strong></pre>
<p class="calibre2">The median time is now <kbd class="calibre9">910.793</kbd> microseconds. This was expected as we know that removing explicit loops can produce big performance improvements. In this case, we were able to reduce to a little under one-third of the time from our previously fastest implementation. Note that we are now dealing with hundreds of microseconds, instead of thousands of microseconds. This means that we have achieved performance improvements in the orders of magnitude. Take a look at the following table:</p>
<table class="calibre5">
<tbody class="calibre6">
<tr class="calibre7">
<td class="calibre8">
<p class="calibre2"><strong class="calibre1">Fastest</strong></p>
</td>
<td class="calibre8">
<p class="calibre2"><strong class="calibre1">Implementation</strong></p>
</td>
<td class="calibre8">
<p class="calibre2"><strong class="calibre1">Microseconds median</strong></p>
</td>
<td class="calibre8">
<p class="calibre2"><strong class="calibre1">% from fastest</strong></p>
</td>
</tr>
<tr class="calibre7">
<td class="calibre8"/>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9">sma_slow_1</kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9">81,035.1900</kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9">8,897.21 %</kbd></p>
</td>
</tr>
<tr class="calibre7">
<td class="calibre8"/>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>sma_slow_2</span></kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>33,031.7785</span></kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>3,626.70 %</span></kbd></p>
</td>
</tr>
<tr class="calibre7">
<td class="calibre8"/>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>sma_slow_3</span></kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>19,628.2430</span></kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>2,155.07 %</span></kbd></p>
</td>
</tr>
<tr class="calibre7">
<td class="calibre8"/>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>sma_slow_4</span></kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>20,825.8790</span></kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>2,286.56 %</span></kbd></p>
</td>
</tr>
<tr class="calibre7">
<td class="calibre8"/>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>sma_slow_5</span></kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>16,682.68</span></kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>1,831.66 %</span></kbd></p>
</td>
</tr>
<tr class="calibre7">
<td class="calibre8"/>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>sma_slow_6</span></kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>2,991.5720</span></kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>328.45 %</span></kbd></p>
</td>
</tr>
<tr class="calibre7">
<td class="calibre8">
<p class="calibre2">⇒</p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>sma_slow_7</span></kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>910.7930</span></kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>100 %</span></kbd></p>
</td>
</tr>
</tbody>
</table>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Using R's way of iterating efficiently</h1>
                
            
            <article>
                
<p class="calibre2">At this point, we're left with a single <kbd class="calibre9">for</kbd> loop, which we would like to remove. However, there's a bit of logic in there that gets in the way. This is where the <kbd class="calibre9">lapply()</kbd> function comes in handy. As you know from <a href="part0022.html#KVCC0-f494c932c729429fb734ce52cafce730" class="calibre4">Chapter 1</a>, <em class="calibre19">Introduction to R</em>, this function receives a list of objects that will be sent to a function provided as a second argument, and it will return the results from such function calls in a list. An added benefit of the <kbd class="calibre9">lapply()</kbd> function is that it takes care of the memory preallocation for us, which is a very efficient way to reduce execution time in R.</p>
<p class="calibre2">In this case, we encapsulate the logic inside our <kbd class="calibre9">for</kbd> loop in a separate function called <kbd class="calibre9">sma_from_position_1()</kbd> and use it within our <kbd class="calibre9">lapply()</kbd> function call. Our <kbd class="calibre9">sma_from_position_1()</kbd> function receives the <kbd class="calibre9">end</kbd>, <kbd class="calibre9">period</kbd>, and <kbd class="calibre9">data</kbd> objects we have been working with, and they keep the same meaning and perform the same vectorized mean computation we were doing earlier. However, instead of using an explicit <kbd class="calibre9">if…else</kbd> conditional, it uses the <kbd class="calibre9">ifelse()</kbd> function we introduced in <a href="part0022.html#KVCC0-f494c932c729429fb734ce52cafce730" class="calibre4">Chapter 1</a>, <em class="calibre19">Introduction to R</em>, which takes the condition to be checked as its first argument, the desired result in case of the condition being met as its second argument, and the desired result in case the condition is not met as its third argument. In our case, these are <kbd class="calibre9">start &gt;= 1</kbd>, <kbd class="calibre9">mean(data[start:end]</kbd>, <kbd class="calibre9">price_usd</kbd>, and <kbd class="calibre9">NA</kbd>, respectively.</p>
<p class="calibre2">The result we get from the function calls to  <kbd class="calibre9">sma_from_position_1()</kbd> are unlisted into a single vector so that we get a vector result instead of a list, and that is in turn returned by <kbd class="calibre9">sma_efficient_1()</kbd>. Note the change in the name? At this point, this implementation can be considered an efficient one. Hurray! Take a look at the following code snippet:</p>
<pre class="calibre65">sma_efficient_1 &lt;- function(period, symbol, data) {<br class="title-page-name"/>    data &lt;- data[data$symbol == symbol, ]<br class="title-page-name"/>    return(unlist(lapply(1:nrow(data), <br class="title-page-name"/>                         sma_from_position_1, <br class="title-page-name"/>                         period, data)))<br class="title-page-name"/>}<br class="title-page-name"/><br class="title-page-name"/>sma_from_position_1 &lt;- function(end, period, data) {<br class="title-page-name"/>    start &lt;- end - period + 1<br class="title-page-name"/>    return(ifelse(start &gt;= 1, <br class="title-page-name"/>                  mean(data[start:end, "price_usd"]), NA))<br class="title-page-name"/>}</pre>
<p class="calibre2">Just in case you don't remember the mechanics of the <kbd class="calibre9">lapply()</kbd> function and you're a bit confused about the way it's being used here, let me remind you that it will take each of the elements in the list provided as the first argument, and feed them as the first argument to the function provided in the second argument. If the said function requires more parameters, those can also be passed after the function object has been provided to the <kbd class="calibre9">lapply()</kbd> function, which is the case of the <kbd class="calibre9">period</kbd> and <kbd class="calibre9">data</kbd> arguments you see toward the end.</p>
<p class="calibre2">Again, benchmark and check for correctness, as shown in the following code snippet:</p>
<pre class="mce-root">performance &lt;- microbenchmark(
    sma_8 &lt;- sma_efficient_1(period, symbol, data),
    unit = "us"
)
<br class="title-page-name"/>all(sma_1$sma - sma_8 &lt;= 0.001, na.rm = TRUE)
<strong class="calibre1">#&gt; TRUE</strong>
<br class="title-page-name"/>summary(performance)$median
<strong class="calibre1">#&gt; [1] 1137.704</strong></pre>
<p class="calibre2">This time, our median time is <kbd class="calibre9">1,137.704</kbd> microseconds. This is more than our previously fastest implementation. What happened? If you want to know the details, you should profile the function, but in essence, the problem is that we're adding a function call that is executed many times (<kbd class="calibre9">sma_from_position_1()</kbd>) and function calls can be expensive, and also adding a transformation from a list to a vector we were not doing before (<kbd class="calibre9">unlist()</kbd>). However, we prefer to advance with version for reasons that shall become clear in a later section. Take a look at the following table:</p>
<table class="calibre5">
<tbody class="calibre6">
<tr class="calibre7">
<td class="calibre8">
<p class="calibre2"><strong class="calibre1">Fastest</strong></p>
</td>
<td class="calibre8">
<p class="calibre2"><strong class="calibre1">Implementation</strong></p>
</td>
<td class="calibre8">
<p class="calibre2"><strong class="calibre1">Microseconds median</strong></p>
</td>
<td class="calibre8">
<p class="calibre2"><strong class="calibre1">% from fastest</strong></p>
</td>
</tr>
<tr class="calibre7">
<td class="calibre8"/>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9">sma_slow_1</kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9">81,035.1900</kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9">8,897.21 %</kbd></p>
</td>
</tr>
<tr class="calibre7">
<td class="calibre8"/>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>sma_slow_2</span></kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>33,031.7785</span></kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>3,626.70 %</span></kbd></p>
</td>
</tr>
<tr class="calibre7">
<td class="calibre8"/>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>sma_slow_3</span></kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>19,628.2430</span></kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>2,155.07 %</span></kbd></p>
</td>
</tr>
<tr class="calibre7">
<td class="calibre8"/>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>sma_slow_4</span></kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>20,825.8790</span></kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>2,286.56 %</span></kbd></p>
</td>
</tr>
<tr class="calibre7">
<td class="calibre8"/>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>sma_slow_5</span></kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>16,682.68</span></kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>1,466.63 %</span></kbd></p>
</td>
</tr>
<tr class="calibre7">
<td class="calibre8"/>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>sma_slow_6</span></kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>2,991.5720</span></kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>328.45 %</span></kbd></p>
</td>
</tr>
<tr class="calibre7">
<td class="calibre8">
<p class="calibre2">⇒</p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>sma_slow_7</span></kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>910.7930</span></kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>100 %</span></kbd></p>
</td>
</tr>
<tr class="calibre7">
<td class="calibre8"/>
<td class="calibre8">
<p class="calibre2"><span><span><kbd class="calibre9">sma_efficient_1</kbd></span><br class="title-page-name"/></span></p>
</td>
<td class="calibre8">
<p class="calibre2"><span><kbd class="calibre9"><span>1,137.7040</span></kbd><br class="title-page-name"/></span></p>
</td>
<td class="calibre8">
<p class="calibre2"><span><kbd class="calibre9">124.91 %</kbd><br class="title-page-name"/></span></p>
</td>
</tr>
</tbody>
</table>
<p class="calibre2">Thera are many other vectorized functions in R that may help speed your code. Some examples are <kbd class="calibre9">which()</kbd>, <kbd class="calibre9">where()</kbd>, <kbd class="calibre9">any()</kbd>, <kbd class="calibre9">all()</kbd>, <kbd class="calibre9">cumsum()</kbd>, and <kbd class="calibre9">cumprod()</kbd>. When working with matrices, you may use <kbd class="calibre9">rowSums()</kbd>, <kbd class="calibre9">colSums()</kbd>, <kbd class="calibre9">lower.tri()</kbd>, <kbd class="calibre9">upper.tri()</kbd>, and others, and when working with combinations, you may use <kbd class="calibre9">combin()</kbd>. There are many more, and when dealing with something that seems like it could be vectorized, chances are that there's already a function for that.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Avoiding sending data structures with overheads</h1>
                
            
            <article>
                
<p class="calibre2">We know that operating on heavy data structures such as data frames should be avoided when possible, and here it seems that it's still possible to do just that. What if instead of passing our data frame, we extract the <kbd class="calibre9">price_usd</kbd> variable we're interested in and simply use that? That seems promising.</p>
<p class="calibre2">To accomplish this, at the top of the function, we not only filter for observations containing <kbd class="calibre9">symbol</kbd> we want, but we also extract the <kbd class="calibre9">price_usd</kbd> variable at that point. Now, we may send this lower-overhead data structure to our slightly modified the <kbd class="calibre9">sma_from_position_2()</kbd> function. It is simply modified to work with this vector instead of the full data frame:</p>
<pre class="calibre65">sma_efficient_2 &lt;- function(period, symbol, data) {<br class="title-page-name"/>    data &lt;- data[data$symbol == symbol, "price_usd"]<br class="title-page-name"/>    return(unlist(lapply(1:length(data), <br class="title-page-name"/>                         sma_from_position_2, <br class="title-page-name"/>                         period, data)))<br class="title-page-name"/>}<br class="title-page-name"/><br class="title-page-name"/>sma_from_position_2 &lt;- function(end, period, data) {<br class="title-page-name"/>    start &lt;- end - period + 1<br class="title-page-name"/>    return(ifelse(start &gt;= 1, sum(data[start:end]) / period, NA))<br class="title-page-name"/>}</pre>
<p class="calibre2">Again, benchmark and check for correctness, as shown in the following code snippet:</p>
<pre class="mce-root">performance &lt;- microbenchmark(
    sma_9 &lt;- sma_efficient_2(period, symbol, data),
    unit = "us"
)
<br class="title-page-name"/>all(sma_1$sma - sma_9 &lt;= 0.001, na.rm = TRUE)
<strong class="calibre1">#&gt; TRUE</strong>
<br class="title-page-name"/>summary(performance)$median
<strong class="calibre1">#&gt; [1] 238.2425</strong></pre>
<p class="calibre2">This time, our mean time is <kbd class="calibre9">238.2425</kbd> microseconds. That's a big change. In fact, it's the largest performance improvement we have been able to produce pondered by the amount of change required, with respect to the previously fastest implementation.</p>
<p class="calibre2">Do you realize how drastic the performance improvement has been? Our first implementation takes approximately 33,900% more time to execute. Inversely, our <kbd class="calibre9">sma_efficient_2()</kbd> implementation takes only around 0.2% of the time that our <kbd class="calibre9">sma_slow_1()</kbd> implementation took. Were you expecting such a large time reduction by only writing better R code when we started this chapter? Take a look at the following table:</p>
<table class="calibre5">
<tbody class="calibre6">
<tr class="calibre7">
<td class="calibre8">
<p class="calibre2"><strong class="calibre1">Fastest</strong></p>
</td>
<td class="calibre8">
<p class="calibre2"><strong class="calibre1">Implementation</strong></p>
</td>
<td class="calibre8">
<p class="calibre2"><strong class="calibre1">Microseconds median</strong></p>
</td>
<td class="calibre8">
<p class="calibre2"><strong class="calibre1">% from fastest</strong></p>
</td>
</tr>
<tr class="calibre7">
<td class="calibre8"/>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9">sma_slow_1</kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9">81,035.1900</kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>34,013.74 %</span></kbd></p>
</td>
</tr>
<tr class="calibre7">
<td class="calibre8"/>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>sma_slow_2</span></kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>33,031.7785</span></kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>13,865.77 %</span></kbd></p>
</td>
</tr>
<tr class="calibre7">
<td class="calibre8"/>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>sma_slow_3</span></kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>19,628.2430</span></kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>8,238.76 %</span></kbd></p>
</td>
</tr>
<tr class="calibre7">
<td class="calibre8"/>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>sma_slow_4</span></kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>20,825.8790</span></kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>8,741.46 %</span></kbd></p>
</td>
</tr>
<tr class="calibre7">
<td class="calibre8"/>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>sma_slow_5</span></kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>16,682.6800</span></kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>7,002.39 %</span></kbd></p>
</td>
</tr>
<tr class="calibre7">
<td class="calibre8"/>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>sma_slow_6</span></kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>2,991.5720</span></kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>1,255.68 %</span></kbd></p>
</td>
</tr>
<tr class="calibre7">
<td class="calibre8">
<p class="calibre2">⇒</p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>sma_slow_7</span></kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>910.7930</span></kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>382.29 %</span></kbd></p>
</td>
</tr>
<tr class="calibre7">
<td class="calibre8"/>
<td class="calibre8">
<p class="calibre2"><span><span><kbd class="calibre9">sma_efficient_1</kbd></span><br class="title-page-name"/></span></p>
</td>
<td class="calibre8">
<p class="calibre2"><span><kbd class="calibre9"><span>1,137.7040</span></kbd><br class="title-page-name"/></span></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>477.54 %</span></kbd></p>
</td>
</tr>
<tr class="calibre7">
<td class="calibre8"/>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span><span>sma_efficient_2</span></span></kbd></p>
</td>
<td class="calibre8">
<p class="calibre2"><span><span><kbd class="calibre9">238.2425</kbd><br class="title-page-name"/></span></span></p>
</td>
<td class="calibre8">
<p class="calibre2"><kbd class="calibre9"><span>100%</span></kbd></p>
</td>
</tr>
</tbody>
</table>
<p class="calibre2"> </p>
<p class="calibre2">Let's assume that we are very picky, and we want to further improve performance. What should we do? Well, let's profile our code again to find out. As you can see here, the number of function calls is reduced to just one in the <kbd class="calibre9">$by.self</kbd> table and only five in the <kbd class="calibre9">$by.total</kbd> table. Unfortunately, these results don't show us any way we can further improve performance, since all the functions shown are highly optimized already. The only thing you can attempt is to replace the <kbd class="calibre9">mean()</kbd> function with one of the faster alternatives shown earlier, but we won't do it in this case, since the effect of doing so was already shown previously:</p>
<pre class="calibre65">Rprof()
sma_9 &lt;- sma_efficient_2(period, symbol, data_original[1:10000, ])
Rprof(NULL)
summaryRprof()<br class="title-page-name"/><strong class="calibre1">#&gt; $by.self
#&gt;          self.time self.pct total.time total.pct
#&gt; "ifelse"      0.02      100       0.02       100
#&gt;
#&gt; $by.total
#&gt;                   total.time total.pct self.time self.pct
#&gt; "ifelse"                0.02       100      0.02      100
#&gt; "FUN"                   0.02       100      0.00        0
#&gt; "lapply"                0.02       100      0.00        0
#&gt; "sma_efficient_2"       0.02       100      0.00        0
#&gt; "unlist"                0.02       100      0.00        0</strong></pre>
<p class="calibre2">To further reduce the execution time of our implementation, we will have to resort to more advanced techniques such as parallelization and delegation, which are the subjects of the following sections.</p>
<p class="calibre2">Note that that's where <kbd class="calibre9">Rprof()</kbd> will stop being useful most of the time, since we will start using advanced tools, outside of R, to continue to improve performance, and such tools require their own profiling techniques and knowledge that we won't go into in this book.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Using parallelization to divide and conquer</h1>
                
            
            <article>
                
<p class="calibre2">So far, we have learned various ways to optimize the performance of R programs running serially, that is, in a single thread. This does not take advantage of the multiple CPU cores most computers have nowadays. Parallel computing allows us to tap into them by splitting our implementations in multiple parts that are sent to these processors independently, and it has the potential to accelerate programs when a single thread is an important bottleneck.</p>
<p class="calibre2">Parallelizing real-world applications can be a very challenging task, and it requires deep software as well as hardware knowledge. The extent of possible parallelization depends on the particular algorithm we're working with, and there are many types of parallelizations available. Furthermore, parallelization is not a yes/no decision; it involves a continuous scale. On one side of the scale, we have embarrassingly parallel tasks, where there are no dependencies between the parallel subtasks, thus making them great candidates for parallelization. On the other side, we have tasks that cannot be parallelized at all, since each step of the task depends on the results of previous steps. Most algorithms fall in between these two extremes, and most real-world parallelized applications perform some tasks serially and others in parallel.</p>
<p class="calibre2">Some tasks that are relatively easy to implement in parallel (some of them would be classified as embarrassingly parallel tasks) are converting hundreds of images from color to grayscale, adding millions of numbers, brute-force searches, and Monte Carlo simulations. The common property among these is that each subtask can be done independently of the others. For example, each image can be processed independently, or we can add various subgroups of numbers and then add the results together, and so on. The moment we introduce an order-dependency, parallelization breaks out.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">How deep does the parallelization rabbit hole go?</h1>
                
            
            <article>
                
<p class="calibre2">With parallelizing and algorithm, there are a lot of decisions that must be made. First of all, we must decide what parts of the algorithm will be implemented in parallel and which parts will be implemented serially, and how to manage these parts to work correctly among themselves. Next we must decide, whether explicitly or implicitly, whether the parallelized parts will have shared or distributed memory, whether we will do data or task parallelization, whether we need to introduce some type of distributed or concurrent mechanism, and if so, what protocol will be used to coordinate them. Once we have established those high-level decisions, we must take care of the fine-grained decisions regarding the number and architecture of the processors we will use as well as the amount of memory and control permissions.</p>
<p class="calibre2">Don't worry too much about the concepts mentioned earlier; they are for more advanced usage than the intended level for this book. I will provide very general and simple explanations here to ensure that you understand the type of parallelization we will implement ourselves, but feel free to skip this section if you want.</p>
<p class="calibre2"><strong class="calibre1">Shared memory</strong> systems share objects stored in-memory across different processes, which can be very resource efficient, but also dangerous since one process may modify an object that is used by another process without it knowing that it happened. Another disadvantage of such systems is that they don't scale well. A more powerful, but also more complex alternative, is <strong class="calibre1">distributed memory</strong>, which makes copies of the data needed for different processes that may reside in different systems altogether. This approach can scale to thousands of CPUs, but comes at the cost of complex coordination among processes.</p>
<p class="calibre2"><strong class="calibre1">Data parallelism</strong> is when data is partitioned and each task is executed using a different partition. These types of parallelization help algorithm scale as more data is acquired, since we can simply create more partitions. Note that using data parallelism does not necessarily imply distributed memory, and vice versa. <strong class="calibre1">Task parallelism</strong> is when tasks are sent to different processors to be executed in parallel and they may <span>or may not </span>be working on top of the same data.</p>
<p class="calibre2">A disadvantage of parallel computing is that people run code on different machines, and if you are writing software that you expect to share with others, you need to be careful that your implementation is useful even when executed in different hardware configurations.</p>
<p class="calibre2">All the decisions mentioned earlier require deep technical knowledge to be properly taken, and if they seem complex, it's because they really are. Implementing parallelization can be quite complex activity, depending on the level of control you want to have over it.</p>
<p class="calibre2">Most importantly, remember that R is an interpreted language, so speed gains from utilizing compiled languages will almost always exceed speed gains from parallelizing <kbd class="calibre9">for</kbd> loops or other loop-hiding functions.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Practical parallelization with R</h1>
                
            
            <article>
                
<p class="calibre2">In this section, we will show you how to take advantage of multiple cores with R. We will show you how to perform a shared memory single system with multiple cores approach. This is the simplest parallel technique you can implement.</p>
<p class="calibre2">A deep look at various parallelization mechanisms available in R can be found in Theubl's doctoral thesis, <em class="calibre19">Applied High Performance Computing Using R, by Wirtschafts Universitat, 2007</em>.</p>
<p class="calibre2">Implementing parallel programs with R has become increasingly easier with time since it's a topic of much interest, and many people have provided, and continue to provide, better ways of doing so. Currently, there are over 70 packages in CRAN that provide some kind of parallelization functionality. Choosing the right package for the right problem, or simply knowing that a variety of options exist, remains a challenge.</p>
<p class="calibre2">In this case, we will use the <kbd class="calibre9">parallel</kbd> package that comes preinstalled in the recent versions of R. Other very popular packages are <kbd class="calibre9">doSNOW</kbd>, <kbd class="calibre9">doMC</kbd>, and <kbd class="calibre9">foreach</kbd>, but it really depends on what kind of parallelization you want to perform.</p>
<p class="calibre2">The most common parallelization technique in R is to use parallelized replacements of the <kbd class="calibre9">lapply()</kbd>, <kbd class="calibre9">sapply()</kbd>, and <kbd class="calibre9">apply()</kbd> functions. In the case of the <kbd class="calibre9">parallel</kbd> package, we have the <kbd class="calibre9">parLapply()</kbd>, <kbd class="calibre9">parSapply()</kbd>, and <kbd class="calibre9">parApply()</kbd> functions <span>available</span>, respectively. The fact that signatures among this function pairs are very similar makes the barrier to using this form of parallelization very low, and that's why I decided to showcase this technique.</p>
<p class="calibre2">Implementing the parallelization technique we will showcase is simple enough, and it involves the following three main steps once you have loaded the <kbd class="calibre9">parallel</kbd> package:</p>
<ol class="calibre14">
<li value="1" class="calibre12">Create a cluster with the <kbd class="calibre9">makeCluster()</kbd> function</li>
<li value="2" class="calibre12">Replace a <kbd class="calibre9">apply()</kbd> function with one a <kbd class="calibre9">par*pply()</kbd> one</li>
<li value="3" class="calibre12">Stop the cluster you created in the first step</li>
</ol>
<p class="calibre2">For our case, we will replace the <kbd class="calibre9">lapply()</kbd> function with <kbd class="calibre9">parLapply()</kbd> in our <kbd class="calibre9">sma_efficient_2()</kbd> implementation. However, you should avoid a common mistake done by people just starting with parallelization. Normally, they will create and later destroy a cluster within the function called to perform a task, instead of receiving a cluster from the outside and using it within. This creates performance problems, because the cluster will potentially be started many times, and starting a parallelization cluster can have quite a bit of overhead. A function that makes such a mistake is the <kbd class="calibre9">sma_parallel_inefficient()</kbd> function, as follows:</p>
<pre class="calibre65">library(parallel)<br class="title-page-name"/>sma_parallel_inefficient &lt;- function(period, symbol, data) {<br class="title-page-name"/>    data &lt;- as.numeric(data[data$symbol == symbol, "price_usd"])<br class="title-page-name"/>    cluster &lt;- makeCluster(detectCores())<br class="title-page-name"/>    result &lt;- unlist(parLapply(<br class="title-page-name"/>    cluster, 1:length(data), sma_from_position_2, period, data))<br class="title-page-name"/>    stopCluster(cluster)<br class="title-page-name"/>    return(result)<br class="title-page-name"/>}</pre>
<p class="calibre2">As you can see, <kbd class="calibre9">sma_parallel_inefficient()</kbd> is just <kbd class="calibre9">sma_efficient_2()</kbd> with the added logic for the cluster creation and deletion, and the <kbd class="calibre9">lapply()</kbd> replacement with <kbd class="calibre9">parLapply()</kbd>. You shouldn't really use this function, but it's put here to showcase how bad it can be for performance if you do. As always, we benchmark and check for correctness, as shown in the following code snippet:</p>
<pre class="calibre65">performance &lt;- microbenchmark(
    sma_10 &lt;- sma_parallel_inefficient(period, symbol, data),
    unit = "us"
)
<br class="title-page-name"/>all(sma_1$sma - sma_10 &lt;= 0.001, na.rm = TRUE)
<strong class="calibre1">#&gt; TRUE
</strong><br class="title-page-name"/>summary(performance)$median
<strong class="calibre1">#&gt; [1] 1197329.3980</strong></pre>
<p class="calibre2">In this case, our median time is <kbd class="calibre9">1,197,329.398</kbd> microseconds, which should not be too surprising after mentioning that creating and destroying a cluster multiple times can be quite inefficient. Take a look at the following table:</p>
<div class="cdpaligncenter"><img src="../images/00064.jpeg" class="calibre22"/></div>
<p class="calibre2">Now, we proceed to remove the logic that creates and destroys the cluster out of the function, and instead receive the <kbd class="calibre9">cluster</kbd> as a parameter to <kbd class="calibre9">sma_parallel()</kbd>. In that case, our implementation looks just like the one we had before, except for the use of <kbd class="calibre9">parLapply()</kbd>. It's nice to be able to achieve something as complex as parallelization with simply this change, but it's really a product of having simplified our code up to what we have now. If we attempted to parallelize our initial <kbd class="calibre9">sma_slow_1()</kbd> implementation, we would have a hard time doing so. Take a look at the following code snippet:</p>
<pre class="calibre65">sma_parallel &lt;- function(period, symbol, data, cluster) {<br class="title-page-name"/>    data &lt;- as.numeric(data[data$symbol == symbol, "price_usd"])<br class="title-page-name"/>    return(unlist(parLapply(<br class="title-page-name"/>        cluster, 1:length(data), sma_from_position_2, period, data)))<br class="title-page-name"/>}</pre>
<p class="calibre2">Again, we benchmark and check for correctness, as shown in the following code snippet:</p>
<pre class="calibre65">cluster &lt;- makeCluster(detectCores())
performance &lt;- microbenchmark(
    sma_11 &lt;- sma_parallel(period, symbol, data, cluster),
    unit = "us"
)
<br class="title-page-name"/>all(sma_1$sma - sma_11 &lt;= 0.001, na.rm = TRUE)
<strong class="calibre1">#&gt; TRUE</strong>
<br class="title-page-name"/>summary(performance)$median
<strong class="calibre1">#&gt; [1] 44825.9355</strong></pre>
<p class="calibre2">In this case, our median time is <kbd class="calibre9">44,825.9355</kbd> microseconds, which is roughly worse than we were able to achieve with <kbd class="calibre9">sma_slow_2()</kbd>. Wasn't parallelization supposed to be much faster? The answer is yes, when working with larger inputs. When we use data that has millions of observations (not the 100 observations we have been using for these tests), it will be faster, because its execution time won't increase as much as the one for other implementations. Right now, <kbd class="calibre9">sma_paralle()</kbd> is paying a big fixed cost that is not a good investment when working with small datasets, but as we start working with larger datasets, the fixed cost starts being small as compared to the performance gains. Take a look at the following table:</p>
<div class="cdpaligncenter"><img src="../images/00065.jpeg" class="calibre22"/></div>
<p class="calibre2">To finalize the section, remember to call <kbd class="calibre9">stopCluster(cluster)</kbd> when you want to stop using the cluster. In this case, we will leave it running as we will continue to perform more benchmarks through the rest of the chapter.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Using C++ and Fortran to accelerate calculations</h1>
                
            
            <article>
                
<p class="calibre2">Sometimes, R code just isn't fast enough. Sometimes, you've used profiling to figure out where your bottlenecks are, and you've done everything you can think of within R, but your code still isn't fast enough. In those cases, a useful alternative can be to delegate some parts of the implementation to more efficient languages such as Fortran and C++. This is an advanced technique that can often prove to be quite useful if know how to program in such languages.</p>
<p class="calibre2">Delegating code to other languages can address bottlenecks such as the following:</p>
<ul class="calibre11">
<li class="calibre12">Loops that can't be easily vectorized due to iteration dependencies</li>
<li class="calibre12">Processes that involve calling functions millions of times</li>
<li class="calibre12">Inefficient but necessary data structures that are slow in R</li>
</ul>
<p class="calibre2">Delegating code to other languages can provide great performance benefits, but it also incurs the cost of being more explicit and careful with the types of objects that are being moved around. In R, you can get away with simple things such as being imprecise about a number being an integer or a real. In these other languages, you can't; every object must have a precise type, and it remains fixed for the entire execution.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Using an old-school approach with Fortran</h1>
                
            
            <article>
                
<p class="calibre2">We will start with an old-school approach using Fortran first. If you are not familiar with it, Fortran is the oldest programming language still under use today. It was designed to perform lots of calculations very efficiently and with very few resources. There are a lot of numerical libraries developed with it, and many high-performance systems nowadays still use it, either directly or indirectly.</p>
<p class="calibre2">Here's our implementation, named <kbd class="calibre9">sma_fortran()</kbd>. The syntax may throw you off if you're not used to working with Fortran code, but it's simple enough to understand. First, note that to define a function technically known as a <kbd class="calibre9">subroutine</kbd> in Fortran, we use the <kbd class="calibre9">subroutine</kbd> keyword before the name of the function. As our previous implementations do, it receives the <kbd class="calibre9">period</kbd> and <kbd class="calibre9">data</kbd> (we use the <kbd class="calibre9">dataa</kbd> name with an extra <kbd class="calibre9">a</kbd> at the end because Fortran has a reserved keyword <kbd class="calibre9">data</kbd>, which we shouldn't use in this case), and we will assume that the data is already filtered for the correct symbol at this point.</p>
<p class="calibre2">Next, note that we are sending new arguments that we did not send before, namely <kbd class="calibre9">smas</kbd> and <kbd class="calibre9">n</kbd>. Fortran is a peculiar language in the sense that it does not return values, it uses side effects instead. This means that instead of expecting something back from a call to a Fortran subroutine, we should expect that subroutine to change one of the objects that was passed to it, and we should treat that as our <kbd class="calibre9">return</kbd> value. In this case, <kbd class="calibre9">smas</kbd> fulfills that role; initially, it will be sent as an array of undefined real values, and the objective is to modify its contents with the appropriate SMA values. Finally, the <kbd class="calibre9">n</kbd> represents the number of elements in the data we send. Classic Fortran doesn't have a way to determine the size of an array being passed to it, and it needs us to specify the size manually; that's why we need to send <kbd class="calibre9">n</kbd>. In reality, there are ways to work around this, but since this is not a book about Fortran, we will keep the code as simple as possible.</p>
<p class="calibre2">Next, note that we need to declare the type of objects we're dealing with as well as their size in case they are arrays. We proceed to declare <kbd class="calibre9">pos</kbd> (which takes the place of position in our previous implementation, because Fortran imposes a limit on the length of each line, which we don't want to violate), <kbd class="calibre9">n</kbd>, <kbd class="calibre9">endd</kbd> (again, <kbd class="calibre9">end</kbd> is a keyword in Fortran, so we use the name <kbd class="calibre9">endd</kbd> instead), and <kbd class="calibre9">period</kbd> as integers. We also declare <kbd class="calibre9">dataa(n)</kbd>, <kbd class="calibre9">smas(n)</kbd>, and <kbd class="calibre9">sma</kbd> as reals because they will contain decimal parts. Note that we specify the size of the array with the <kbd class="calibre9">(n)</kbd> part in the first two objects.</p>
<p class="calibre2">Once we have declared everything we will use, we proceed with our logic. We first create a <kbd class="calibre9">for</kbd> loop, which is done with the <kbd class="calibre9">do</kbd> keyword in Fortran, followed by a unique identifier (which are normally named with multiples of tens or hundreds), the variable name that will be used to iterate, and the values that it will take, <kbd class="calibre9">endd</kbd> and <kbd class="calibre9">1</kbd> to <kbd class="calibre9">n</kbd> in this case, respectively.</p>
<p class="calibre2">Within the <kbd class="calibre9">for</kbd> loop, we assign <kbd class="calibre9">pos</kbd> to be equal to <kbd class="calibre9">endd</kbd> and <kbd class="calibre9">sma</kbd> to be equal to <kbd class="calibre9">0</kbd>, just as we did in some of our previous implementations. Next, we create a <kbd class="calibre9">while</kbd> loop with the <kbd class="calibre9">do…while</kbd> keyword combination, and we provide the condition that should be checked to decide when to break out of it. Note that Fortran uses a very different syntax for the comparison operators. Specifically, the <kbd class="calibre9">.lt.</kbd> operator stand for less-than, while the <kbd class="calibre9">.ge.</kbd> operator stands for greater-than-or-equal-to. If any of the two conditions specified is not met, then we will exit the <kbd class="calibre9">while</kbd> loop.</p>
<p class="calibre2">Having said that, the rest of the code should be self-explanatory. The only other uncommon syntax property is that the code is indented to the sixth position. This indentation has meaning within Fortran, and it should be kept as it is. Also, the number IDs provided in the first columns in the code should match the corresponding looping mechanisms, and they should be kept toward the left of the logic-code.</p>
<p class="calibre2">For a good introduction to Fortran, you may take a look at <em class="calibre19">Stanford's Fortran 77 Tutorial</em> (<a href="https://web.stanford.edu/class/me200c/tutorial_77/" class="calibre4">https://web.stanford.edu/class/me200c/tutorial_77/</a>). You should know that there are various Fortran versions, and the 77 version is one of the oldest ones. However, it's also one of the better supported ones:</p>
<pre class="mce-root">    subroutine sma_fortran(period, dataa, smas, n)
    integer pos, n, endd, period
    real dataa(n), smas(n), sma
    do 10 endd = 1, n
        pos = endd
        sma = 0.0
        do 20 while ((endd - pos .lt. period) .and. (pos .ge. 1))
            sma = sma + dataa(pos)
            pos = pos - 1
20      end do
        if (endd - pos .eq. period) then
            sma = sma / period
        else
            sma = 0
        end if
        smas(endd) = sma
10  continue
    end</pre>
<p class="calibre2">Once your code is finished, you need to compile it before it can be executed within R. Compilation is the process of translating code into machine-level instructions. You have two options when compiling Fortran code: you can either do it manually outside of R or you can do it within R. The second one is recommended since you can take advantage of R's tools for doing so. However, we show both of them. The first one can be achieved with the following code:</p>
<pre class="mce-root"><strong class="calibre1">$ gfortran -c sma-delegated-fortran.f -o sma-delegated-fortran.so</strong></pre>
<p class="calibre2">This code should be executed in a Bash terminal (which can be found in Linux or Mac operating systems). We must ensure that we have the <kbd class="calibre9">gfortran</kbd> compiler installed, which was probably installed when R was. Then, we call it, telling it to compile (using the <kbd class="calibre9">-c</kbd> option) the <kbd class="calibre9">sma-delegated-fortran.f</kbd> file (which contains the Fortran code we showed before) and provide an output file (with the <kbd class="calibre9">-o</kbd> option) named <kbd class="calibre9">sma-delegated-fortran.so</kbd>. Our objective is to get this <kbd class="calibre9">.so</kbd> file, which is what we need within R to execute the Fortran code.</p>
<p class="calibre2">The way to compile within R, which is the recommended way, is to use the following line:</p>
<pre class="mce-root">system("R CMD SHLIB sma-delegated-fortran.f")</pre>
<p class="calibre2">It basically tells R to execute the command that produces a shared library derived from the <kbd class="calibre9">sma-delegated-fortran.f</kbd> file. Note that the <kbd class="calibre9">system()</kbd> function simply sends the string it receives to a terminal in the operating system, which means that you could have used that same command in the Bash terminal used to compile the code manually.</p>
<p class="calibre2">To load the shared library into R's memory, we use the <kbd class="calibre9">dyn.load()</kbd> function, providing the location of the <kbd class="calibre9">.so</kbd> file we want to use, and to actually call the shared library that contains the Fortran implementation, we use the <kbd class="calibre9">.Fortran()</kbd> function. This function requires type checking and coercion to be explicitly performed by the user before calling it.</p>
<p class="calibre2">To provide a similar signature as the one provided by the previous functions, we will create a function named <kbd class="calibre9">sma_delegated_fortran()</kbd>, which receives the <kbd class="calibre9">period</kbd>, <kbd class="calibre9">symbol</kbd>, and <kbd class="calibre9">data</kbd> parameters as we did before, <span>also </span>filters the data as we did earlier, calculates the length of the data and puts it in <kbd class="calibre9">n</kbd>, and uses the <kbd class="calibre9">.Fortran()</kbd> function to call the <kbd class="calibre9">sma_fortran()</kbd> subroutine, providing the appropriate parameters. Note that we're wrapping the parameters around functions that coerce the types of these objects as required by our Fortran code. The <kbd class="calibre9">results</kbd> list created by the <kbd class="calibre9">.Fortran()</kbd> function contains the <kbd class="calibre9">period</kbd>, <kbd class="calibre9">dataa</kbd>, <kbd class="calibre9">smas</kbd>, and <kbd class="calibre9">n</kbd> objects, corresponding to the parameters sent to the subroutine, with the contents left in them after the subroutine was executed. As we mentioned earlier, we are interested in the contents of the <kbd class="calibre9">sma</kbd> object since they contain the values we're looking for. That's why we send only that part back after converting it to a <kbd class="calibre9">numeric</kbd> type within R.</p>
<p class="calibre2">The transformations you see before sending objects to Fortran and after getting them back is something that you need to be very careful with. For example, if instead of using <kbd class="calibre9">single(n)</kbd> and <kbd class="calibre9">as.single(data)</kbd>, we use <kbd class="calibre9">double(n)</kbd> and <kbd class="calibre9">as.double(data)</kbd>, our Fortran implementation will not work. This is something that can be ignored within R, but it can't be ignored in the case of Fortran:</p>
<pre class="calibre65">system("R CMD SHLIB sma-delegated-fortran.f")<br class="title-page-name"/>dyn.load("sma-delegated-fortran.so")<br class="title-page-name"/><br class="title-page-name"/>sma_delegated_fortran &lt;- function(period, symbol, data) {<br class="title-page-name"/>    data &lt;- data[which(data$symbol == symbol), "price_usd"]<br class="title-page-name"/>    n &lt;- length(data)<br class="title-page-name"/>    results &lt;- .Fortran(<br class="title-page-name"/>        "sma_fortran",<br class="title-page-name"/>        period = as.integer(period),<br class="title-page-name"/>        dataa = as.single(data),<br class="title-page-name"/>        smas = single(n),<br class="title-page-name"/>        n = as.integer(n)<br class="title-page-name"/>    )<br class="title-page-name"/>    return(as.numeric(results$smas))<br class="title-page-name"/>}</pre>
<p class="calibre2">Just as we did earlier, we benchmark and test for correctness:</p>
<pre class="calibre65">performance &lt;- microbenchmark(<br class="title-page-name"/>    sma_12 &lt;- sma_delegated_fortran(period, symboo, data), <br class="title-page-name"/>    unit = "us"<br class="title-page-name"/>) <br class="title-page-name"/><br class="title-page-name"/>all(sma_1$sma - sma_12 &lt;= 0.001, na.rm = TRUE)<br class="title-page-name"/><strong class="calibre1">#&gt; TRUE</strong> <br class="title-page-name"/><br class="title-page-name"/>summary(performance)$median<br class="title-page-name"/><strong class="calibre1">#&gt; [1] 148.0335</strong></pre>
<p class="calibre2">In this case, our median time is of <kbd class="calibre9">148.0335</kbd> microseconds, making this the fastest implementation up to this point. Note that it's barely over half of the time from the most efficient implementation we were able to come up with using only R. Take a look at the following table:</p>
<div class="cdpaligncenter"><img src="../images/00066.jpeg" class="calibre22"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Using a modern approach with C++</h1>
                
            
            <article>
                
<p class="calibre2">Now, we will show you how to use a more modern approach using C++. The aim of this section is to provide just enough information for you to start experimenting using C++ within R on your own. We will only look at a tiny piece of what can be done by interfacing R with C++ through the <kbd class="calibre9">Rcpp</kbd> package (which is installed by default in R), but it should be enough to get you started.</p>
<p class="calibre2">If you have never heard of C++, it's a language used mostly when resource restrictions play an important role and performance optimization is of paramount importance. Some good resources to learn more about C++ are Meyer's books on the topic, a popular one being <em class="calibre19">Effective C++</em> (Addison-Wesley, 2005), and specifically for the <kbd class="calibre9">Rcpp</kbd> package, Eddelbuettel's <em class="calibre19">Seamless R and C++ integration with Rcpp</em> <em class="calibre19">by Springer, 2013</em>, is great.</p>
<p class="calibre2">Before we continue, you need to ensure that you have a C++ compiler in your system. On Linux, you should be able to use <kbd class="calibre9">gcc</kbd>. On Mac, you should install Xcode from the application store. O n Windows, you should install Rtools. Once you test your compiler and know that it's working, you should be able to follow this section. We'll cover more on how to do this in <a href="part0296.html#8Q96G0-f494c932c729429fb734ce52cafce730" class="calibre4">Appendix</a>, <em class="calibre19">Required Packages</em>.</p>
<p class="calibre2">C++ is more readable than Fortran code because it follows more syntax conventions we're used to nowadays. However, just because the example we will use is readable, don't think that C++ in general is an easy language to use; it's not. It's a very low-level language and using it correctly requires a good amount of knowledge. Having said that, let's begin.</p>
<p class="calibre2">The <kbd class="calibre9">#include</kbd> <span>line </span>is used to bring variable and function definitions from R into this file when it's compiled. Literally, the contents of the <kbd class="calibre9">Rcpp.h</kbd> file are pasted right where the <kbd class="calibre9">include</kbd> statement is. Files ending with the <kbd class="calibre9">.h</kbd> extensions are called header files, and they are used to provide some common definitions between a code's user and its developers. They play a similar role to what we called an interface in the previous chapter.</p>
<p class="calibre2">The <kbd class="calibre9">using namespace Rcpp</kbd> <span>line </span>allows you to use shorter names for your function. Instead of having to specify <kbd class="calibre9">Rcpp::NumericVector</kbd>, we can simply use <kbd class="calibre9">NumericVector</kbd> to define the type of the <kbd class="calibre9">data</kbd> object. Doing so in this example may not be too beneficial, but when you start developing for complex C++ code, it will really come in handy.</p>
<p class="calibre2">Next, you will notice the <kbd class="calibre9">// [[Rcpp::export(sma_delegated_cpp)]]</kbd> <span>code</span>. This is a tag that marks the function right below it so that R know that it should import it and make it available within R code. The argument sent to <kbd class="calibre9">export()</kbd> is the name of the function that will be accessible within R, and it does not necessarily have to match the name of the function in C++. In this case, <kbd class="calibre9">sma_delegated_cpp()</kbd> will be the function we call within R, and it will call the  <kbd class="calibre9">smaDelegated()</kbd> function within C++:</p>
<pre class="calibre65">#include 
using namespace Rcpp;

// [[Rcpp::export(sma_delegated_cpp)]]
NumericVector smaDelegated(int period, NumericVector data) {
    int position, n = data.size();
    NumericVector result(n);
    double sma;
    for (int end = 0; end &lt; n; end++) {
        position = end;
        sma = 0;
        while(end - position &lt; period &amp;&amp; position &gt;= 0) {
            sma = sma + data[position];
            position = position - 1;
        }
        if (end - position == period) {
            sma = sma / period;
        } else {
            sma = NA_REAL;
        }
        result[end] = sma;
    }
    return result;
}</pre>
<p class="calibre2">Next, we will explain the actual <kbd class="calibre9">smaDelegated()</kbd> function. Since you have a good idea of what it's doing at this point, we won't explain its logic, only the syntax that is not so obvious. The first thing to note is that the function name has a keyword before it, which is the type of the <kbd class="calibre9">return</kbd> value for the function. In this case, it's <kbd class="calibre9">NumericVector</kbd>, which is provided in the <kbd class="calibre9">Rcpp.h</kbd> file. This is an object designed to interface vectors between R and C++. Other types of vector provided by <kbd class="calibre9">Rcpp</kbd> are <kbd class="calibre9">IntegerVector</kbd>, <kbd class="calibre9">LogicalVector</kbd>, and <kbd class="calibre9">CharacterVector</kbd>. You also have <kbd class="calibre9">IntegerMatrix</kbd>, <kbd class="calibre9">NumericMatrix</kbd>, <kbd class="calibre9">LogicalMatrix</kbd>, and <kbd class="calibre9">CharacterMatrix</kbd> <span>available</span>.</p>
<p class="calibre2">Next, you should note that the parameters received by the function also have types associated with them. Specifically, <kbd class="calibre9">period</kbd> is an integer (<kbd class="calibre9">int</kbd>), and <kbd class="calibre9">data</kbd> is <kbd class="calibre9">NumericVector</kbd>, just like the output of the function. In this case, we did not have to pass the <kbd class="calibre9">output</kbd> or <kbd class="calibre9">length</kbd> objects as we did with Fortran. Since functions in C++ do have output values, it also has an easy enough way of computing the length of objects.</p>
<p class="calibre2">The first line in the function declare a variables <kbd class="calibre9">position</kbd> and <kbd class="calibre9">n</kbd>, and assigns the length of the data to the latter one. You may use commas, as we do, to declare various objects of the same type one after another instead of splitting the declarations and assignments into its own lines. We also declare the vector <kbd class="calibre9">result</kbd> with length <kbd class="calibre9">n</kbd>; note that this notation is similar to Fortran's. Finally, instead of using the <kbd class="calibre9">real</kbd> keyword as we do in Fortran, we use the <kbd class="calibre9">float</kbd> or <kbd class="calibre9">double</kbd> keyword here to denote such numbers. Technically, there's a difference regarding the precision allowed by such keywords, and they are not interchangeable, but we won't worry about that here.</p>
<p class="calibre2">The rest of the function should be clear, except for <span>maybe </span>the <kbd class="calibre9">sma = NA_REAL</kbd> assignment. This <kbd class="calibre9">NA_REAL</kbd> object is also provided by <kbd class="calibre9">Rcpp</kbd> as a way to denote what should be sent to R as an <kbd class="calibre9">NA</kbd>. Everything else should result familiar.</p>
<p class="calibre2">Now that our function is ready, we save it in a file called <kbd class="calibre9">sma-delegated-cpp.cpp</kbd> and use R's <kbd class="calibre9">sourceCpp()</kbd> function to bring compile it for us and bring it into R. The <kbd class="calibre9">.cpp</kbd> extension denotes contents written in the C++ language. Keep in mind that functions brought into R from C++ files cannot be saved in a <kbd class="calibre9">.Rdata</kbd> file for a later session. The nature of C++ is to be very dependent on the hardware under which it's compiled, and doing so will probably produce various errors for you. Every time you want to use a C++ function, you should compile it and load it with the <kbd class="calibre9">sourceCpp()</kbd> function at the moment of usage.</p>
<pre class="calibre65">library(Rcpp)<br class="title-page-name"/><br class="title-page-name"/>sourceCpp("./sma-delegated-cpp.cpp")<br class="title-page-name"/><br class="title-page-name"/>sma_delegated_cpp &lt;- function(period, symbol, data) {<br class="title-page-name"/>    data &lt;- as.numeric(data[which(data$symbol == symbol), "price_usd"])<br class="title-page-name"/>    return(sma_cpp(period, data))<br class="title-page-name"/>}</pre>
<p class="calibre2">If everything worked fine, our function should be usable within R, so we benchmark and test for correctness. I promise this is the last one:</p>
<pre class="calibre65">performance &lt;- microbenchmark(
    sma_13 &lt;- sma_delegated_cpp(period, symboo, data),
    unit = "us"
)
all(sma_1$sma - sma_13 &lt;= 0.001, na.rm = TRUE)
<strong class="calibre1">#&gt; TRUE</strong>
summary(performance)$median
<strong class="calibre1">#&gt; [1] 80.6415</strong></pre>
<p class="calibre2">This time, our median time was <kbd class="calibre9">80.6415</kbd> microseconds, which is three orders of magnitude faster than our first implementation. Think about it this way: if you provide an input for <kbd class="calibre9">sma_delegated_cpp()</kbd> so that it took around one hour for it to execute, <kbd class="calibre9">sma_slow_1()</kbd> would take around 1,000 hours, which is roughly 41 days. Isn't that a surprising difference? When you are in situations that take that much execution time, it's definitely worth it to try and make your implementations as optimized as possible.</p>
<p class="calibre2">You may use the <kbd class="calibre9">cppFunction()</kbd> function to write your C++ code directly inside an <kbd class="calibre9">.R</kbd> file, but you should not do so. Keep that just for testing small pieces of code. Separating your C++ implementation into its own files allows you to use the power of your editor of choice (or IDE) to guide you through the development as well as perform deeper syntax checks for you.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Looking back at what we have achieved</h1>
                
            
            <article>
                
<p class="calibre2">As you know, up to now, we have benchmarked our code using a subset of the data that contains only the first 100 observations. However, as we saw at the beginning of the chapter, performance can vary for different implementations, depending on the size of the input. To bring together all our efforts in the chapter, we will create a couple of functions that will help us measure how the execution times for our implementations change as we use more observations from our data. </p>
<p class="calibre2">First, we bring our requirements into R, mainly, the <kbd class="calibre9">microbenchmark</kbd> and <kbd class="calibre9">ggplot2</kbd> packages and the files that contain our implementations.</p>
<p class="calibre2">Next, we create the <kbd class="calibre9">sma_performance()</kbd> function that takes a <kbd class="calibre9">symbol</kbd>, a <kbd class="calibre9">period</kbd>, the <kbd class="calibre9">original_data</kbd>, a list named <kbd class="calibre9">sizes</kbd> whose elements are the number of observations that will be taken from <kbd class="calibre9">original_data</kbd> to test our implementations, a <kbd class="calibre9">cluster</kbd> to avoid the overhead of initializing it within our <kbd class="calibre9">sma_parallel()</kbd> function as we saw in the corresponding section, and the number of times we want to measure each implementation.</p>
<p class="calibre2">As you can see, for each size in sizes, we take the corresponding number of observations in the <kbd class="calibre9">data</kbd> object, and we send it along with the other necessary arguments for the <kbd class="calibre9">sma_microbenchmark()</kbd> function. Then, we add the <kbd class="calibre9">size</kbd> value into the <kbd class="calibre9">result</kbd> data frame, which is provided by the <kbd class="calibre9">summary()</kbd> function applied on top of the resulting object from the <kbd class="calibre9">microbenchmark()</kbd> function from <kbd class="calibre9">sma_microbenchmark()</kbd>. We need to add this ourselves because the <kbd class="calibre9">microbenchmark()</kbd> function doesn't have any knowledge about the size of the data it's dealing with. Finally, we flatten the list of data frames in the <kbd class="calibre9">results</kbd> list with the <kbd class="calibre9">do.call("rbind", results)</kbd> function call, which sends a single data frame as output.</p>
<p class="calibre2">The <kbd class="calibre9">sma_microbenchmark()</kbd> function is very simple. It only receives some parameters and passes them forward to each of the implementations that will be measured by the <kbd class="calibre9">microbenchmark()</kbd> function. Note that we are leaving inside the <kbd class="calibre9">sma_paralel_inefficient()</kbd> function, but it's commented out to avoid any scale issues in the graph we will end up producing (since it is very slow, it will skew our graph).</p>
<p class="calibre2">The resulting object from the <kbd class="calibre9">sma_performance()</kbd> function returns a data frame with the results for all the tests, which is used as input for the <kbd class="calibre9">graph_sma_performance()</kbd> function in the form of <kbd class="calibre9">results</kbd> objects. It also receives the <kbd class="calibre9">sizes</kbd>, which will be used to define the values in the x axis. As you can see, we call <kbd class="calibre9">remove_arguments()</kbd>, which we mention as we move ahead. It creates a graph using the <kbd class="calibre9">ggplot()</kbd>, <kbd class="calibre9">geom_point()</kbd>, and <kbd class="calibre9">geom_line()</kbd> functions as we saw earlier, and we use logarithmic scales for both axes.</p>
<p class="calibre2">The <kbd class="calibre9">remove_arguments()</kbd> function does exactly what it says—it removes the parenthesis and the arguments from the function calls so that we keep only the function name. This is done to reduce the space in the graph's legend. To accomplish this, we use the <kbd class="calibre9">gsub()</kbd> function we saw in <a href="part0022.html#KVCC0-f494c932c729429fb734ce52cafce730" class="calibre4">Chapter 1</a>, <em class="calibre19">Introduction to R</em>.</p>
<p class="calibre2">To use the code we just presented, we simply create the <kbd class="calibre9">sizes</kbd> list we are missing and use all the other objects we had defined previously in this chapter. In this particular case, we want to measure the first 10, 100, 1,000, and 10,000 observations. If you want, you can increase this list with larger amounts. Remember that the total amount of observations in the simulated data is a little over 1,000,000.</p>
<p class="calibre2">The resulting graph shows the number of observations in the <em class="calibre19">x</em> axis and the microseconds median in the <em class="calibre19">y</em> axis. Both axes use logarithmic scale, so keep in mind when interpreting the relations. As you can see, when the size of the input is smaller (toward the left of the graph) the execution time difference is smaller, and as we increase the input size, differences start being larger and larger, specially considering the logarithmic scales.</p>
<p class="calibre2">Some interesting things to note are as listed as follows:</p>
<ul class="calibre11">
<li class="calibre12"><kbd class="calibre9">sma_efficient_1()</kbd>: The function was shown to be slower than the <kbd class="calibre9">sma_slow_7()</kbd> for 100 observations, is actually faster when using 10,000 observations. This shows that the tradeoff made sense, specially as inputs increase.</li>
<li class="calibre12"><kbd class="calibre9">sma_efficient_2()</kbd>: This implementation is faster, for 10 observations, than the Fortran implementation. That's pretty surprising and shows that the overhead incurred in calling Fortran code is not worth it for that input size. However, <kbd class="calibre9">sma_efficient_2()</kbd> quickly becomes slower as input size increases.</li>
<li class="calibre12"><kbd class="calibre9">sma_parallel()</kbd>: This implementation is slow due to all the overhead it incurs as we saw in the corresponding section, but it's also the implementation where percentage time increase is the least as input size increases. This should makes us wonder what happens when we're dealing with the full data? Will it be faster, at that point, that the Fortran or C++ implementations which seem to be increasing faster? That's left as an exercise for the reader.</li>
</ul>
<p class="calibre2">Finally, for the curious reader, what do you think will happen if you use the <kbd class="calibre9">sma_delegated_cpp()</kbd> implementation along with the parallelization approach we showed? If you want to know the answer, you should definitely try it yourself.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Other topics of interest to enhance performance</h1>
                
            
            <article>
                
<p class="calibre2">We saw an overview of the most important and common techniques used to optimize R implementations. However, there is still a lot we have not covered. In the following sections, we will briefly mention some of them.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Preallocating memory to avoid duplication</h1>
                
            
            <article>
                
<p class="calibre2">Memory preallocation is an important technique we covered implicitly when we used the <kbd class="calibre9">lapply()</kbd> function, since it does preallocation for us. However, a more explicit explanation can be useful. As we have already seen, dynamically growing objects in R is not great for performance. Instead, you should define an object with the full size you will need and then perform updates on its elements instead of recreating them. To accomplish this, you may use something like <kbd class="calibre9">double(10)</kbd> to define an vector of doubles that will contain 10 elements at most. Whenever you define an object's size before you start using it, will help you avoid recreating new objects each time its size is increased and will save you a lot of time.</p>
<p class="calibre2">However, accurate preallocation is not always feasible because it requires that we know the total number prior to the iteration. Sometimes, we can only ask for a result to store repeatedly without knowing the exact total number. In this case, maybe it is still a good idea to preallocate a list or vector with a reasonable length. When the iteration is over, if the number of iterations does not reach the preallocated length, we can take a subset of the list or vector. In this way, we can avoid intensive reallocation of data structures.</p>
<p class="calibre2">When it comes to preallocating memory, R is no different from the other programming languages. However, being an interpreted language, it imposes less restrictions; thus, it is easy for users to overlook this types of issues. R will not throw any compilation error if a vector's memory is not preallocated. You should keep this in mind when writing fast code.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Making R code a bit faster with byte code compilation</h1>
                
            
            <article>
                
<p class="calibre2">Even though R is an interpreted language, it can go through a small phase before code execution called <strong class="calibre1">byte code compilation</strong>, which is a less strict compilation procedure. Under some scenarios, it can save between 5% to 10% of time if already optimized functions are not being used heavily. All base R functions are byte code compiled by default.</p>
<p class="calibre2">To byte code compile your functions, you use the <kbd class="calibre9">cmpfunc()</kbd> function wrapped around the function you want to compile, after loading the <kbd class="calibre9">compiler</kbd> package. You may also send an <kbd class="calibre9">options</kbd> arguments such as <kbd class="calibre9">options = list(optimize = 3))</kbd>, where the optimize element should be an integer between <kbd class="calibre9">0</kbd> and <kbd class="calibre9">3</kbd>. The higher the number, the more effort R will put into optimizing the compilation. The following lines show how to create a function called <kbd class="calibre9">sma_efficient_2_compiled()</kbd>, which is a compiled version of the <kbd class="calibre9">sma_efficient_2()</kbd> function:</p>
<pre class="mce-root">library(compiler)
sma_efficient_2_compiled &lt;- <br class="title-page-name"/>    cmpfun(sma_efficient_2, options = list(optimize = e))</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Just-in-time (JIT) compilation of R code</h1>
                
            
            <article>
                
<p class="calibre2">R also supports <strong class="calibre1">Just-in-time</strong> (<strong class="calibre1">JIT</strong>) compilation. When JIT compilation is enabled, R will automatically byte code compile any code that is executed without explicitly having called one of the compile functions. To activate JIT compilation, use the <kbd class="calibre9">enableJIT()</kbd> function.</p>
<p class="calibre2">The level argument tells R how much code to compile before execution; <kbd class="calibre9">0</kbd> disables <kbd class="calibre9">JIT</kbd>, <kbd class="calibre9">1</kbd> compiles functions before their first use, <kbd class="calibre9">2</kbd> also compiles functions before they are duplicated, and <kbd class="calibre9">3</kbd> also compiles loops before they are executed:</p>
<pre class="mce-root">library(compiler)
enableJIT(level = 3)</pre>
<div class="packt_tip"><strong class="calibre23">JIT</strong> compilation can also be enabled by setting the <kbd class="calibre21">R_ENABLE_JIT</kbd> environment in the operating system before starting R. The value of <kbd class="calibre21">R_ENABLE_JIT</kbd> should be set to the value of the level argument.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Using memoization or cache layers</h1>
                
            
            <article>
                
<p class="calibre2">If you have deterministic algorithms, every time you provide equal inputs, you should receive equal outputs, and if that's the case and the process to go from inputs to outputs is very time-consuming, you may use memoization or cache layers. The basic idea is that you store some copies of the inputs and outputs, and whenever an input is sent to a function, before computing the output, you check whether or not that specific input's output has been computed before. If it has, send that instead of doing all the work again. This means you should only be computing the output for each input once.</p>
<p class="calibre2">You should try to implement such a layer in the <kbd class="calibre9">fibonacci_recursive()</kbd> function we created at the beginning of this chapter to see how big of an impact these kind of techniques can have, even when using slow algorithms.</p>
<p class="calibre2">Sometimes, these types of techniques are also used even when the output for a given input changes through time. All you have to do in such cases is to provide a mechanism that will invalidate or delete the stored input/output relation after a specific amount of time so that it's actually recalculated next time the input is used.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Improving our data and memory management</h1>
                
            
            <article>
                
<p class="calibre2">R, as any programming language, is constrained by CPU, RAM, and I/O, and in this chapter, we focused on increasing the speed for the CPU part. However, considerable performance gains can be achieved by also making our RAM and I/O usage more efficient.</p>
<p class="calibre2">Measuring RAM (memory) usage is best done outside of R using the tools provided by your operating system for exactly this purpose. The information that these tools report varies depending on the operating system, but here are the key metrics you should keep an eye on: CPU usage, free memory, physical memory, swap size, and bytes read/written per second.</p>
<p class="calibre2">If you encounter high CPU utilization, the CPU is likely the main bottleneck for R's performance. Use the profiling techniques in this chapter to identify which parts of the code are taking most of the CPU's time is the way to go.</p>
<p class="calibre2">If you encounter enough free system memory with high disk I/O, your code is likely performing lots of read/write operations to disk. Remove any unnecessary I/O operations and store intermediate data in the memory if there is sufficient memory.</p>
<p class="calibre2">If you encounter low CPU utilization and low free system memory with a large swap size, the system is likely running out of physical memory and is thus swapping memory onto the disk. In this case, see whether you have enough resources to handle the loads you're sending to R, and if you do, try to use the <kbd class="calibre9">rm()</kbd> function to remove unused objects that are waiting memory from R's session.</p>
<p class="calibre2">If you encounter a scenario similar to the last one, but you know that you don't have enough memory to handle the full data you're working with, even if you did so efficiently, you may try to partition your data. Can you work with a subset of the data by parts and then bring the results together? If so, you should try that. For example, if your full data doesn't fit in memory and you're trying to find the maximum value, you may want to split your data into four parts, load each them one by one, calculate the maximum for each of them, and remove them from memory after you do, while keeping the maximum and then getting the maximum of the four maximums you computed separately.</p>
<p class="calibre2">Another possibility for a scenario like the previous one is to simply migrate your data handling to a database. Databases are specialized tools for dealing with data, and can avoid data being a bottleneck in R since only the preprocessed subset of the data you need is brought into R. Most of databases nowadays also perform very efficient simple operations, like finding the maximum. You can leverage the techniques we showed in <a href="part0091.html#2MP360-f494c932c729429fb734ce52cafce730" class="calibre4">Chapter 4</a>, <em class="calibre19">Simulating Sales Data and Working with Databases</em>, to accomplish this.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Using specialized packages for performance</h1>
                
            
            <article>
                
<p class="calibre2">Another good way to increase the performance of your implementations is to look for specialized functions published in CRAN packages or elsewhere. Before you go about changing your own code, take a look and see if you can find a very efficient implementation somewhere else. There's tremendous variation in CRAN packages' quality and speed, but leveraging them can definitely save you a lot of time.</p>
<p class="calibre2">Two very powerful packages to help you develop efficient implementations are the <kbd class="calibre9">data.table</kbd> and <kbd class="calibre9">dplyr</kbd> packages. They can provide efficient ways of dealing with data frames, and in the case of <kbd class="calibre9">dplyr</kbd> other objects as well. The <strong class="calibre1">Basic Linear Algebra Subprogram</strong> (<strong class="calibre1">BLAS</strong>) library can also be very helpful when performing linear algebra operations. It's written using Fortran and is highly optimized.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Flexibility and power with cloud computing</h1>
                
            
            <article>
                
<p class="calibre2">Sometimes, you don't even need more computing power or efficient resources usage. Sometimes, you just need to run R on some other computer without tying up your own for hours or days. In those cases, using cloud computing resources can be very useful.</p>
<p class="calibre2">Cloud computing resources are not only useful when you want to use an extra machine, they are a very efficient way to get hold of supercomputers to do some work for you. It's very easy to build a machine with 64 CPU cores and 512 GB of RAM memory. Using a system like that may be cheaper than you think, and it can be leveraged for very costly computations that would take way too much time in commodity hardware.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Specialized R distributions</h1>
                
            
            <article>
                
<p class="calibre2">Finally, if none of the previous options have worked for you, you may also use specialized R distributions. These distributions are maintained independently of the common R distribution and are focused on optimizing specific aspects within R. Some of them are built to provide fine-grained controlled for parallelization, and some do it for you automatically. Learning to use those distributions can be require a significant time investment, which may or may not be beneficial for your particular case.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    </header><h1 class="header-title" id="calibre_pb_0">Summary</h1>
                
            
            <article>
                
<p class="calibre2">In this chapter, we saw the most important reasons behind slow R code: programming without understanding object immutability, the nature of interpreted dynamic typings, memory-bound processes, and single-threaded processes. We learned that the first one can be reduced by properly using R, the second one can be reduced by delegating to statistically typed languages such as Fortran or C++, the third one can be reduced using more powerful computers (specifically with more RAM), and, finally, the fourth one can be reduced using parallelization.</p>
<p class="calibre2">We also mentioned some variables that we may want to take into account when deciding whether or not to optimize our implementations, how small a difference in implementation may result in big performance enhancements, and how the performance gains from these enhancements can become larger as the size of the inputs increases. Finally, we also learned how to profile and benchmark to improve our implementations.</p>
<p class="calibre2">In the next and final chapter, we will learn to use the <kbd class="calibre9">Shiny</kbd> package to create interactive dashboards that will make use of the SMA implementation we developed throughout this chapter.</p>


            </article>

            
        </section>
    </body></html>