- en: Chapter 1. From Data to Decisions – Getting Started with Analytic Applications
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第一章：从数据到决策 - 开始使用分析应用
- en: From quarterly financial projections to customer surveys, analytics help businesses
    to make decisions and plan for the future. While data visualizations such as pie
    charts and trend lines using spreadsheet programs have been used for decades,
    recent years have seen a growth in both the volume and diversity of data sources
    available to the business analyst and the sophistication of tools used to interpret
    this information.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 从季度财务预测到客户调查，分析帮助企业在做出决策和规划未来方面。虽然使用电子表格程序制作的饼图和趋势线等数据可视化已经使用了数十年，但近年来，业务分析师可用的数据源的数量和多样性以及用于解释这些信息的工具的复杂性都有所增长。
- en: The rapid growth of the Internet, through e-commerce and social media platforms,
    has generated a wealth of data, which is available faster than ever before for
    analysis. Photographs, search queries, and online forum posts are all examples
    of unstructured data that can't be easily examined in a traditional spreadsheet
    program. With the proper tools, these kinds of data offer new insights, in conjunction
    with or beyond traditional data sources.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 互联网的快速增长，通过电子商务和社交媒体平台，产生了大量数据，这些数据比以往任何时候都更快地用于分析。照片、搜索查询和在线论坛帖子都是无法在传统电子表格程序中轻松检查的非结构化数据示例。有了适当的工具，这些类型的数据可以提供新的见解，与或超越传统数据源。
- en: Traditionally, data such as historical customer records appear in a structured,
    tabular form that is stored in an electronic data warehouse and easily imported
    into a spreadsheet program. Even in the case of such tabular data, the volume
    of records and the rate at which they are available are increasing in many industries.
    While the analyst might have historically transformed raw data through interactive
    manipulation, robust analytics increasingly requires automated processing that
    can scale with the volume and velocity of data being received by a business.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 传统上，如历史客户记录之类的数据以结构化、表格形式出现，存储在电子数据仓库中，并易于导入电子表格程序。即使在表格数据的情况下，记录的数量和可用速度也在许多行业中不断增加。虽然分析师可能通过交互式操作将原始数据转换为历史数据，但强大的分析越来越需要能够与业务接收到的数据量和速度相匹配的自动化处理。
- en: Along with the data itself, the methods used to examine it have become more
    powerful and complex. Beyond summarizing historical patterns or projecting future
    events using trend lines derived from a few key input variables, advanced analytics
    emphasizes the use of sophisticated predictive modeling (see the goals of predictive
    analytics, as follows) to understand the present and forecast near and long-term
    outcomes.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 除了数据本身，用于检查数据的方法也变得更加强大和复杂。除了总结历史模式或使用来自少数关键输入变量的趋势线来预测未来事件之外，高级分析强调使用复杂的预测建模（如下所述预测分析的目标）来理解现状并预测短期和长期结果。
- en: 'Diverse methods for generating such predictions typically require the following
    common elements:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 生成此类预测的多种方法通常需要以下共同要素：
- en: An outcome or target that we are trying to predict, such as a purchase or a
    **click-through-rate** (**CTR**) on a search result.
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们试图预测的结果或目标，例如购买或搜索结果上的**点击率**（**CTR**）。
- en: A set of columns that comprise **features**, also known as **predictors** (for
    example, a customer's demographic information, past transactions on a sales account,
    or click behavior on a type of ad) describing individual properties of each record
    in our dataset (for example, an account or ad).
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一组列，这些列组成**特征**，也称为**预测因子**（例如，客户的人口统计信息、销售账户的历史交易或某种广告上的点击行为），描述我们数据集中每个记录的个体属性（例如，一个账户或广告）。
- en: A procedure that finds the model or set of models which best maps these features
    to the outcome of interest on a given sample of data.
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一种找到模型或模型集的程序，这些模型或模型集最好地将这些特征映射到给定数据样本中感兴趣的结果。
- en: A way to evaluate the performance of the model on new data.
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一种评估模型在新数据上性能的方法。
- en: 'While predictive modeling techniques can be used in powerful analytic applications
    to discover complex relationships between seemingly unrelated inputs, they also
    present a new set of challenges to the business analyst:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然预测建模技术可以在强大的分析应用中使用，以发现看似无关输入之间的复杂关系，但它们也给业务分析师带来了新的挑战：
- en: What method is the best suited for a particular problem?
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么方法最适合特定问题？
- en: How does one correctly evaluate the performance of these techniques on historical
    and new data?
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何正确评估这些技术在历史数据和新技术上的表现？
- en: What are the preferred strategies for tuning the performance of a given method?
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调整给定方法性能的首选策略是什么？
- en: How does one robustly scale these techniques for both one-off analysis and ongoing
    insight?
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何稳健地扩展这些技术以适应一次性分析和持续洞察？
- en: 'In this book, we will show you how to address these challenges by developing
    analytic solutions that transform data into powerful insights for you and your
    business. The main tasks involved in building these applications are:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们将向您展示如何通过开发将数据转化为您和您的业务强大见解的分析解决方案来应对这些挑战。构建这些应用程序涉及的主要任务是：
- en: Transforming raw data into a sanitized form that can be used for modeling. This
    may involve both cleaning anomalous data and converting unstructured data into
    a structured format.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将原始数据转换为可用于建模的清洁形式。这可能涉及清理异常数据以及将非结构化数据转换为结构化格式。
- en: Feature engineering, by transforming these sanitized inputs into the format
    that is used to develop a predictive model.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征工程，通过将这些清洁输入转换为用于开发预测模型的格式。
- en: Calibrating a predictive model on a subset of this data and assessing its performance.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在这部分数据的一个子集上校准预测模型并评估其性能。
- en: Scoring new data while evaluating the ongoing performance of the model.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在评估模型持续性能的同时评分新数据。
- en: Automating the transformation and modeling steps for regular updates.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动化转换和建模步骤以进行常规更新。
- en: Exposing the output of the model to other systems and users, usually through
    a web application.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将模型的输出暴露给其他系统和用户，通常通过Web应用程序。
- en: Generating reports for the analyst and business user that distills the data
    and model into regular and robust insights.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为分析师和业务用户生成报告，提炼数据和模型为常规和稳健的见解。
- en: Throughout this volume, we will use open-source tools written in the Python
    programming language to build these sorts of applications. Why Python? The Python
    language strikes an attractive balance between robust compiled languages such
    as Java, C++, and Scala, and pure statistical packages such as R, SAS, or MATLAB.
    We can work interactively with Python using the command line (or, as we will use
    in subsequent chapters, browser-based notebook environments), plotting data, and
    prototyping commands. Python also provides extensive libraries, allowing us to
    transform this exploratory work into web applications (such as Flask, CherryPy,
    and Celery, as we will see in [Chapter 8](ch08.html "Chapter 8. Sharing Models
    with Prediction Services"), *Sharing Models with Prediction Services*), or scale
    them to large datasets (using PySpark, as we will explore in future chapters).
    Thus we can both analyze data and develop software applications within the same
    language.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在整个本卷中，我们将使用用Python编程语言编写的开源工具来构建这些类型的应用程序。为什么是Python？Python语言在健壮的编译语言（如Java、C++和Scala）和纯统计软件包（如R、SAS或MATLAB）之间取得了吸引人的平衡。我们可以通过命令行（或，如我们在后续章节中将使用的，基于浏览器的笔记本环境）与Python进行交互式工作，绘制数据，并原型化命令。Python还提供了广泛的库，使我们能够将这种探索性工作转化为Web应用程序（如Flask、CherryPy和Celery，我们将在第8章中看到，*通过预测服务共享模型*），或将它们扩展到大型数据集（使用PySpark，我们将在未来的章节中探讨）。因此，我们可以在同一语言中同时分析数据和开发软件应用程序。
- en: 'Before diving into the technical details of these tools, let''s take a high-level
    look at the concepts behind these applications and how they are structured. In
    this chapter, we will:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入这些工具的技术细节之前，让我们从高层次上看看这些应用背后的概念以及它们的结构。在本章中，我们将：
- en: 'Define the elements of an analytic pipeline: data transformation, sanity checking,
    preprocessing, model development, scoring, automation, deployment, and reporting.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义分析管道的元素：数据转换、合理性检查、预处理、模型开发、评分、自动化、部署和报告。
- en: Explain the differences between batch-oriented and stream processing and their
    implications at each step of the pipeline.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释批处理和流处理之间的差异以及它们在管道每个步骤中的影响。
- en: Examine how batch and stream processing can be jointly accommodated within the
    Lambda Architecture for data processing.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查批处理和流处理如何在Lambda架构中联合适应数据处理。
- en: Explore an example stream-processing pipeline to perform sentiment analysis
    of social media feeds.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索一个示例流处理管道，以执行社交媒体流量的情感分析。
- en: Explore an example of a batch-processing pipeline to generate targeted e-mail
    marketing campaigns.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索一个批处理管道的示例，以生成定向电子邮件营销活动。
- en: Tip
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: '**The goals of predictive analytics**'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**预测分析的目标**'
- en: The term **predictive analytics**, along with others such as **data** **mining**
    and **machine learning**, are often used to describe the techniques used in this
    book to build analytic solutions. However, it is important to keep in mind that
    there are two distinct goals these methods can address. *Inference* involves building
    models in order to evaluate the significance of a parameter on an outcome and
    emphasizes interpretation and transparency over predictive performance. For example,
    the coefficients of a regression model ([Chapter 4](ch04.html "Chapter 4. Connecting
    the Dots with Models – Regression Methods"), *Connecting the Dots with Models
    – Regression Methods*) can be used to estimate the effect of variation in a particular
    model input (for example, customer age or income) on an output variable (for example,
    sales). The predictions from a model developed for inference may be less accurate
    than other techniques, but provide valuable conceptual insights that may guide
    business decisions. Conversely, *prediction* emphasizes the accuracy of the estimated
    outcome, even if the model itself is a black box where the connection between
    an input and the resulting output is not always clear. For example, Deep Learning
    ([Chapter 7](ch07.html "Chapter 7. Learning from the Bottom Up – Deep Networks
    and Unsupervised Features"), *Learning from the Bottom Up – Deep Networks and
    Unsupervised Features*) can produce state-of-the-art models and extremely accurate
    predictions from complex sets of inputs, but the connection between the input
    parameters and the prediction may be hard to interpret.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 术语**预测分析**，以及其他如**数据挖掘**和**机器学习**，通常用来描述本书中用于构建分析解决方案的技术。然而，重要的是要记住，这些方法可以解决两个不同的目标。*推理*涉及建立模型以评估参数对结果的影响的重要性，并强调解释和透明度而非预测性能。例如，回归模型的系数（[第4章](ch04.html
    "第4章. 通过模型连接点 – 回归方法"), *通过模型连接点 – 回归方法*)可以用来估计特定模型输入（例如，客户年龄或收入）对输出变量（例如，销售额）的影响。为推理开发的模型的预测可能不如其他技术准确，但提供了有价值的概念洞察，可能指导商业决策。相反，*预测*强调估计结果的准确性，即使模型本身是一个黑盒，其中输入和结果输出之间的联系并不总是清晰的。例如，深度学习（[第7章](ch07.html
    "第7章. 从底部学习 – 深度网络和无监督特征"), *从底部学习 – 深度网络和无监督特征*)可以从复杂输入集产生最先进的模型和极其准确的预测，但输入参数和预测之间的联系可能难以解释。
- en: Designing an advanced analytic solution
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设计高级分析解决方案
- en: 'What are the essential components of an analytic solution? While the exact
    design can vary between applications, most consist of the following pieces (Figure
    1):'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 分析解决方案的基本组成部分是什么？虽然具体设计可能因应用而异，但大多数解决方案都包含以下部分（图1）：
- en: '![Designing an advanced analytic solution](img/B04881_chapter01_01.jpg)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![设计高级分析解决方案](img/B04881_chapter01_01.jpg)'
- en: 'Figure 1: Reference architecture for an analytic pipeline'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：分析管道的参考架构
- en: '**Data layer**: This stage deals with storage, processing, and persistence
    of the data, and how it is served to downstream applications such as the analytical
    applications we will build in this volume. As indicated in Figure 1, data serves
    as the **glue** the binds together the other pieces of our application, all of
    which rely on the data layer to store and update information about their state.
    This also reflects the **separation of concerns** that we will discuss in more
    detail in [Chapters 8](ch08.html "Chapter 8. Sharing Models with Prediction Services"),
    *Sharing Models with Prediction Services* and [Chapter 9](ch09.html "Chapter 9. Reporting
    and Testing – Iterating on Analytic Systems"), *Reporting and Testing – Iterating
    on Analytic Systems*, where the other three components of our application can
    be designed independently since they interact only through the data layer.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据层**：这一阶段涉及数据的存储、处理和持久化，以及如何将其提供给下游应用程序，例如我们将在这本书中构建的分析应用程序。如图1所示，数据作为**粘合剂**将我们应用程序的其他部分粘合在一起，所有这些部分都依赖于数据层来存储和更新它们状态的信息。这也反映了我们将更详细讨论的**关注点分离**，在[第8章](ch08.html
    "第8章. 与预测服务共享模型"), *与预测服务共享模型*和[第9章](ch09.html "第9章. 报告和测试 – 在分析系统中迭代"), *报告和测试
    – 在分析系统中迭代*中，我们应用程序的其他三个组件可以独立设计，因为它们仅通过数据层进行交互。'
- en: '**Modeling layer**: At this point, the data has been turned into a form that
    may be ingested by our modeling code in Python. Further feature engineering tasks
    may be involved to convert this sanitized data into model inputs, along with splitting
    data into subsets and performing iterative rounds of optimization and tuning.
    It will also be necessary to prepare the model in a way that can be persisted
    and deployed to downstream users. This stage is also involved with scoring new
    data as it is received or performing audits of model health over time.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**建模层**：在此阶段，数据已经被转换成可以被我们的Python建模代码摄取的形式。可能还需要进一步的特征工程任务，将清洗后的数据转换为模型输入，以及将数据分割成子集并执行迭代优化和调整的轮次。还需要以可以持久化和部署给下游用户的方式准备模型。此阶段还涉及对新接收的数据进行评分，或随着时间的推移对模型健康进行审计。'
- en: '**Deployment layer**: The algorithm development and performance components
    in the modeling layer are usually exposed to either human users or other software
    systems through web services, which these consumers interact with through a server
    layer by means of network calls to both trigger new rounds of model development
    and query the results of previous analyses.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**部署层**：建模层中的算法开发和性能组件通常通过Web服务暴露给人类用户或其他软件系统，这些消费者通过服务器层通过网络调用与它们交互，以触发新的模型开发轮次并查询先前分析的结果。'
- en: '**Reporting layer**: Predictions, model parameters, and insights can all be
    visualized and automated using reporting services.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**报告层**：预测、模型参数和洞察都可以通过报告服务进行可视化和自动化。'
- en: With these broad components in mind, let's delve more deeply into the details
    of each of these pieces.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这些广泛的组件，让我们更深入地探讨这些各个部分的细节。
- en: 'Data layer: warehouses, lakes, and streams'
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据层：仓库、湖泊和流
- en: The beginning of any analytic pipeline is the data itself, which serves as the
    basis for predictive modeling. This input can vary both in the rate at which updates
    are available and the amount of transformation that needs to be applied to form
    the final set of features used in the predictive model. The data layer serves
    as the repository for this information.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 任何分析管道的开始都是数据本身，它是预测建模的基础。这种输入可以在可用的更新速率和需要应用以形成最终用于预测模型的特征集的转换量方面有所不同。数据层是这个信息的存储库。
- en: 'Traditionally, data used for analytics might simply be stored on disk in flat
    files, such as a spreadsheet or document. As the diversity and scale of data have
    increased, so have the scale and complexity of resources needed to house and process
    them. Indeed, a modern view of the data layer encompasses both real-time (stream)
    data and batch data in the context of many potential downstream uses. This combined
    system, known as **Lambda Architecture** (Marz, Nathan, and James Warren. *Big
    Data: Principles and best practices of scalable realtime data systems*. Manning
    Publications Co., 2015.), is diagrammed in the following figure:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 传统上，用于分析的数据可能只是简单地存储在磁盘上的平面文件中，例如电子表格或文档。随着数据的多样性和规模增加，存储和处理这些数据所需的资源和复杂性也增加了。确实，现代数据层的观点涵盖了实时（流）数据和批量数据，这在许多潜在的下层使用中都是如此。这个称为**Lambda架构**（Marz,
    Nathan, 和 James Warren. *大数据：可扩展实时数据系统的原理和最佳实践*. Manning Publications Co., 2015。）的联合系统，在以下图中进行了说明：
- en: '![Data layer: warehouses, lakes, and streams](img/B04881_chapter01_02.jpg)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![数据层：仓库、湖泊和流](img/B04881_chapter01_02.jpg)'
- en: 'Figure 2: Data layer as a Lambda Architecture'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：数据层作为Lambda架构
- en: 'The components of this data layer are:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 此数据层的组成部分包括：
- en: '**Data sources**: These could be either real time data received in streams,
    or batch updates received on a periodic or discontinuous basis.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据来源**：这些可以是实时流接收到的数据，也可以是定期或不定期的批量更新。'
- en: '**Data lake**: Both real-time and batch data is commonly saved in a data lake
    model, in which a distributed file system such as the **Hadoop File System** (**HDFS**)
    or **Amazon Web Services** (**AWS**) **Simple Storage Service** (**S3**) is used
    as a common storage medium for data received both in batch and in streams. This
    data can either be stored with a fixed lifetime (transient) or permanent (persisted)
    retention policy. This data may then be processed in ongoing batch transformations
    such as **Extract, Load, and Transform** (**ETL**) jobs running in frameworks
    such as MapReduce or Spark. ETL processes might involve cleaning the data, aggregating
    it into metrics of interest, or reshaping it into a tabular form from raw inputs.
    This processing forms the batch layer of the Lambda Architecture, where real-time
    availability is not expected and latency of minutes to days is acceptable in surfacing
    views of the data for downstream consumption.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据湖**: 实时数据和批处理数据通常保存在数据湖模型中，其中使用如**Hadoop文件系统**（**HDFS**）或**亚马逊网络服务**（**AWS**）的**简单存储服务**（**S3**）等分布式文件系统作为批量接收和流接收数据的通用存储介质。这些数据可以按照固定寿命（临时）或永久（持久）的保留策略进行存储。然后，这些数据可以在MapReduce或Spark等框架中运行的持续批处理转换，如**提取、加载和转换**（**ETL**）作业中进行处理。ETL过程可能包括清理数据、将其聚合到感兴趣的指标中，或将其从原始输入重塑为表格形式。这种处理形成了Lambda架构的批处理层，其中不期望实时可用性，并且对于呈现数据视图供下游消费的延迟（分钟到几天）是可以接受的。'
- en: '**Data river**: While the data lake accumulates all types of raw data in a
    central location, the data river forms an ongoing message queue where real-time
    data is dispatched to stream processing tasks. This is also termed the **speed
    layer** (Marz, Nathan, and James Warren. *Big Data: Principles and best practices
    of scalable realtime data systems*. Manning Publications Co., 2015.) of the architecture,
    as it operates on data as soon as it is available and real-time availability is
    expected.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据河**: 当数据湖在中央位置累积所有类型的原始数据时，数据河形成了一个持续的消息队列，实时数据被发送到流处理任务。这也被称为架构的**速度层**（Marz,
    Nathan, and James Warren. *Big Data: Principles and best practices of scalable
    realtime data systems*. Manning Publications Co., 2015.），因为它在数据可用时立即操作，并期望实时可用性。'
- en: '**Merged view**: Both real-time and batch views of the raw data may be merged
    into a common persistence layer, such as a data warehouse in structured tables,
    where they can be queried using **Structured Query Language** (**SQL**) and utilized
    in either transactional (for example, updating a bank balance in real time) or
    analytic (for example, running analyses or reports) applications. Examples of
    such warehouse systems include traditional relational systems such as MySQL and
    PostgreSQL (which usually store data with tabular schema in rows and columns),
    and NoSQL systems such as MongoDB or Redis (which arrange data more flexibly in
    key-value systems, where values can take on numerous formats outside the traditional
    rows and columns). This merged system is also referred to as the **serving layer**
    (Marz, Nathan, and James Warren. *Big Data: Principles and best practices of scalable
    realtime data systems*. Manning Publications Co., 2015.), and can either be directly
    queried using the database system, or surfaced to downstream applications.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**合并视图**: 原始数据的实时和批处理视图可以合并到一个共同的持久层，例如结构化表格中的数据仓库，在那里可以使用**结构化查询语言**（**SQL**）进行查询，并在事务性（例如，实时更新银行余额）或分析性（例如，运行分析或报告）应用程序中使用。此类仓库系统的例子包括传统的关系型系统，如MySQL和PostgreSQL（通常在行和列中以表格模式存储数据），以及NoSQL系统，如MongoDB或Redis（在键值系统中更灵活地安排数据，其中值可以采用许多格式，而不仅仅是传统的行和列）。这个合并系统也被称为**服务层**（Marz,
    Nathan, and James Warren. *Big Data: Principles and best practices of scalable
    realtime data systems*. Manning Publications Co., 2015.），可以直接使用数据库系统进行查询，或者呈现给下游应用程序。'
- en: '**Downstream applications**: Systems such as our advanced analytic pipelines
    can either directly consume the outputs of the batch and real-time processing
    layers, or interact with one or both of these sources through the merged view
    in the warehousing system.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**下游应用**: 我们的高级分析管道等系统可以直接消费批处理和实时处理层的输出，或者通过仓库系统中的合并视图与这些来源之一或两者进行交互。'
- en: 'How might streaming and batch data be processed differently in the data layer?
    In batch pipelines, the allowed delay between receiving and processing the data
    allows for potentially complex transformations of the source data: elements may
    be aggregated (such as calculating a user or product''s average properties over
    a period of time), joined to other sources (for example, indexing additional website
    metadata on search logs), and filtered (for example, many web logging systems
    need to remove bot activity that would otherwise skew the results of predictive
    models). The source data could be obtained, for example, from simple text files
    posted to a server, a relational database system, or a mixture of different storage
    formats (see as follows).'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据层中，流式数据和批处理数据如何被不同地处理？在批处理管道中，接收和处理数据之间的允许延迟允许对源数据进行潜在的复杂转换：元素可能被聚合（例如，计算用户或产品在一定时间内的平均属性），与其他来源连接（例如，在搜索日志上索引额外的网站元数据），以及过滤（例如，许多网络日志系统需要删除会扭曲预测模型结果的其他机器人活动）。源数据可能来自服务器上发布的简单文本文件、关系数据库系统，或不同存储格式的混合（见下文）。
- en: Conversely, due to the speed at which incoming data must often be consumed,
    streaming processes typically involve less complex processing of inputs than batch
    jobs, and instead use simple filters or transformations. The sources for such
    applications are typically continuously updated streams from web services (such
    as social media or news feeds), events (such as geo-locations of vehicles and
    mobile phones), or customer activities (such as searches or clicks).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，由于必须快速消费传入数据，流式处理通常涉及比批处理作业更简单的输入处理，并使用简单的过滤器或转换。此类应用的来源通常是来自网络服务（如社交媒体或新闻源）、事件（如车辆和手机的地理位置）或客户活动（如搜索或点击）的持续更新的流。
- en: The choice between batch and stream processing at this stage is largely determined
    by the data source, which is either available as a continuously updated series
    of events (streaming) or larger, periodically available chunks (batch). In some
    cases, the nature of the data will also determine the form of the subsequent pipeline
    and an emphasis on real-time or higher latency processing. In others, the use
    of the application will take precedent in downstream choices. The normalized view
    surfaced in the data layer is used downstream in the next stage of the analytic
    pipeline, the modeling layer.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在此阶段，选择批处理和流处理主要取决于数据源，数据源可以是持续更新的事件系列（流式处理）或较大、定期可用的块（批处理）。在某些情况下，数据的性质也会决定后续管道的形式，以及对实时或更高延迟处理的强调。在其他情况下，应用的使用将优先于下游选择。数据层中呈现的标准化视图将在分析管道的下一阶段，即建模层中使用。
- en: Modeling layer
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 建模层
- en: 'The modeling layer involves a number of interconnected tasks, diagrammed in
    the following figure (**Figure 3**). As the data layer accommodates both real-time
    and batch data, we can imagine two main kinds of modeling systems:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 建模层涉及许多相互关联的任务，如下面的图所示（**图3**）。由于数据层可以容纳实时和批处理数据，我们可以想象两种主要的建模系统：
- en: Streaming pipelines act upon a continuous source of data (such as instant messages
    or a news feed) as soon as it becomes available, potentially allowing real-time
    model updates or scoring. However, the ability to update the model in real time
    may vary by algorithm (for example it will work for models using stochastic updates,
    described in [Chapter 5](ch05.html "Chapter 5. Putting Data in its Place – Classification
    Methods and Analysis"), *Putting Data in its Place – Classification Methods and
    Analysis*), and some can only be developed in an offline process. The potential
    volume of streaming data may also mean that it cannot be stored in its raw form,
    but only transformed into a more manageable format before the original record
    is discarded.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 流式管道对可用的连续数据源（如即时消息或新闻源）立即进行操作，这可能允许实时模型更新或评分。然而，实时更新模型的能力可能因算法而异（例如，对于使用随机更新的模型，请参阅[第5章](ch05.html
    "第5章。将数据放在合适的位置 – 分类方法和分析")，*将数据放在合适的位置 – 分类方法和分析*），并且某些模型只能在离线过程中开发。流式数据的潜在体积也可能意味着它不能以原始形式存储，而只能在丢弃原始记录之前转换为更易于管理的格式。
- en: '**Batch processing**. Data sources that are updated on a periodic basis (often
    daily) are frequently processed using a batch-oriented framework. The input does
    not need to be used at the moment it is available, with a latency of hours or
    days between updates usually acceptable, meaning the data processing and model
    development are typically not occurring in real time.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**批量处理**。定期更新（通常为每日）的数据源通常使用面向批量的框架进行处理。输入数据不需要在可用时立即使用，更新之间的延迟通常为几小时或几天，通常是可以接受的，这意味着数据处理和模型开发通常不是实时进行的。'
- en: Note
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: On the surface, the choice between the two classes of pipelines seems to involve
    the tradeoff between real-time (streaming) or offline (batch) analysis. In practice,
    the two classes can have real-time and non-real-time components intermingled within
    a single application.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在表面上，选择这两类管道似乎涉及实时（流式）或离线（批量）分析之间的权衡。在实践中，这两类管道可以在单个应用程序中混合使用实时和非实时组件。
- en: If both types of pipeline are viable for a given problem (for example, if the
    streams are stock prices, a dataset whose volume and simple format – a set of
    numbers – should allow it to be readily stored offline and processed in its entirety
    at a later date), the choice between the two frameworks may be dictated by technical
    or business concerns. For example, sometimes the method used in a predictive model
    allows only for batch updates, meaning that continuously processing a stream as
    it is received does not add additional value. In other cases, the importance of
    the business decisions informed by the predictive model necessitates real-time
    updates and so would benefit from stream processing.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这两种类型的管道对于给定问题都是可行的（例如，如果流是股票价格，一个体积大且格式简单——一组数字——的数据集应该允许它被轻松离线存储并在稍后日期完整处理），那么选择这两个框架可能由技术或业务问题决定。例如，有时预测模型中使用的方法只允许批量更新，这意味着连续处理接收到的流不会增加额外的价值。在其他情况下，由预测模型提供的信息对业务决策的重要性需要实时更新，因此将受益于流处理。
- en: '![Modeling layer](img/B04881_chapter01_03.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![建模层](img/B04881_chapter01_03.jpg)'
- en: 'Figure 3: Overview of the modeling layer'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：建模层概述
- en: 'The details of the generic components of each type of pipeline as shown in
    Figure 3 are as follows:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图3中所示每种类型管道的通用组件的详细信息如下：
- en: In the **Model Input** step the source data is loaded and potentially transformed
    by the pipeline into the inputs required for a predictive model. This can be as
    simple as exposing a subset of columns in a database table, or transforming an
    unstructured source such as text into a form that may be input to a predictive
    model. If we are fortunate, the kinds of features we wish to use in a model are
    already the form in which they are present in the raw data. In this case, the
    model fitting proceeds directly on the inputs. More often, the input data just
    contains the base information we might want to use as inputs to our model, but
    needs to be processed into a form that can be utilized in prediction.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在**模型输入**步骤中，源数据被加载，并且可能通过管道转换为预测模型所需的输入。这可能只是公开数据库表中的一部分列，或者将非结构化源（如文本）转换为可能输入到预测模型的形式。如果我们很幸运，我们希望在模型中使用的特征已经以它们在原始数据中存在的形式存在。在这种情况下，模型拟合直接在输入上进行。更常见的是，输入数据仅包含我们可能希望用作模型输入的基本信息，但需要将其处理成可用于预测的形式。
- en: In the case of numerical data, this might take the form of discretization or
    transformation. Discretization involves taking a continuous number (such as consumer
    tenure on a subscription service) and dividing it into bins (such as users with
    **<30** or **>=30** days of subscription) that either reduce the variation in
    the dataset (by thresholding an outlier on a continuous scale to a reasonable
    bin number) or turn a numerical range into a set of values that have more direct
    business implications. Another example of discretization is turning a continuous
    value into a rank, in cases where we don't care as much about the actual number
    as its relative value compared to others. Similarly, values that vary over exponential
    scales might be transformed using a natural logarithm to reduce the influence
    of large values on the modeling process.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在数值数据的情况下，这可能采取离散化或转换的形式。离散化涉及将一个连续的数字（例如订阅服务的消费者使用年限）划分为区间（例如，拥有**<30**天或**>=30**天订阅的用户），这要么通过将连续尺度上的异常值阈值化到一个合理的区间数量来减少数据集中的变化，要么将数值范围转换为具有更多直接商业含义的值集。离散化的另一个例子是将连续值转换为排名，在这种情况下，我们更关心的是与其他人的相对价值，而不是实际数字。同样，随着指数尺度的变化，可能使用自然对数进行转换，以减少大值对建模过程的影响。
- en: In addition to these sorts of transformations, numerical features might be combined
    in ratios, sums, products, or other combinations, yielding a potential combinatorial
    explosion of features from even a few basic inputs. In some models, these sorts
    of interactions need to be explicitly represented by generating such combined
    features between inputs (such as the regression models we discuss in [Chapter
    4](ch04.html "Chapter 4. Connecting the Dots with Models – Regression Methods"),
    *Connecting the Dots with Models – Regression Methods*). Other models have some
    ability to decipher these interactions in datasets without our direct creation
    of the feature (such as random forest algorithms in [Chapter 5](ch05.html "Chapter 5. Putting
    Data in its Place – Classification Methods and Analysis"), *Putting Data in its
    Place – Classification Methods and Analysis* or gradient boosted decision trees
    in [Chapter 6](ch06.html "Chapter 6. Words and Pixels – Working with Unstructured
    Data"), *Words and Pixels – Working with Unstructured Data*).
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这些类型的转换之外，数值特征可能以比率、总和、乘积或其他组合的形式结合，从而从几个基本输入中产生潜在的特征组合爆炸。在某些模型中，这些类型的交互需要通过在输入之间生成这样的组合特征来明确表示（例如，我们在[第4章](ch04.html
    "第4章。通过模型连接点 – 回归方法")中讨论的回归模型，*通过模型连接点 – 回归方法*）。其他模型具有在数据集中解码这些交互的能力，而无需我们直接创建特征（例如，[第5章](ch05.html
    "第5章。将数据放在其位置 – 分类方法和分析")中的随机森林算法，*将数据放在其位置 – 分类方法和分析*或[第6章](ch06.html "第6章。文字和像素
    – 处理非结构化数据")中的梯度提升决策树，*文字和像素 – 处理非结构化数据*）。
- en: In the case of categorical data, such as country codes or days of the week,
    we may need to transform the category into a numerical descriptor. This could
    be a number (if the data is ordinal, meaning for example that a value of `2` has
    an interpretation of being larger than another record with value `1` for that
    feature) or a vector with one or more non-zero entries indicating the class to
    which a categorical feature belongs (for example, a document could be represented
    by a vector the same length as the English vocabulary, with a number indicating
    how many times each word represented by a particular vector position appears in
    the document).
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在分类数据的情况下，例如国家代码或星期几，我们可能需要将类别转换为数值描述符。这可能是一个数字（如果数据是序数的，例如，值为`2`的含义是大于值为`1`的记录），或者是一个具有一个或多个非零条目的向量，指示分类特征所属的类别（例如，一个文档可以表示为一个与英语词汇表长度相同的向量，其中的数字表示特定向量位置所代表的单词在文档中出现的次数）。
- en: Finally, we might find cases where we wish to discover the hidden features represented
    by a particular set of inputs. For example, income, occupation, and age might
    all be correlated with the zip code in which a customer lives. If geographic variables
    aren't part of our dataset, we could still discover these common underlying patterns
    using dimensionality reduction, as we will discuss in [Chapter 6](ch06.html "Chapter 6. Words
    and Pixels – Working with Unstructured Data"), *Words and Pixels – Working with
    Unstructured Data*.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可能会发现一些情况，我们希望发现由特定输入集表示的隐藏特征。例如，收入、职业和年龄都可能与其居住的邮政编码相关。如果地理变量不是我们的数据集的一部分，我们仍然可以使用降维技术发现这些共同的潜在模式，正如我们将在[第6章](ch06.html
    "第6章。文字和像素 - 处理非结构化数据")“文字和像素 - 处理非结构化数据”中讨论的那样。
- en: 'Sanity checking may also be performed at this stage, as it is crucial to spot
    data anomalies when they appear, such as outliers that might degrade the performance
    of the model. In the first phase of quality checks, the input data is evaluated
    to prevent outliers or incorrect data from impacting the quality of models in
    the following stages. These sanity checks could take many forms: for categorical
    data (for example, a state or country), there are only a fixed number of allowable
    values, making it easy to rule out incorrect inputs. In other cases, this quality
    check is based on an empirical distribution, such as variation from an average
    value, or a sensible minimum or maximum range. More complex scenarios usually
    arise from business rules (such as a product being unavailable in a given territory,
    or a particular combination of IP addresses in web sessions being illogical).'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段也可能进行合理性检查，因为当数据异常出现时，如可能降低模型性能的异常值，及时发现这些异常至关重要。在质量检查的第一阶段，评估输入数据以防止异常值或错误数据影响后续阶段模型的质量。这些合理性检查可能采取多种形式：对于分类数据（例如，一个州或国家），只有固定数量的允许值，这使得排除错误输入变得容易。在其他情况下，这种质量检查基于经验分布，例如与平均值的变化，或合理的最小或最大范围。更复杂的情况通常源于业务规则（例如，某个地区产品不可用，或网络会话中特定IP地址组合不合理）。
- en: 'Such quality checks serve as more than safeguards for the modeling process:
    they can also serve as warnings of events such as bot traffic on websites that
    may indicate malicious activity. Consequently, these audit rules may also be incorporated
    as part of the visualization and reporting layer at the conclusion of the pipeline.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 这样的质量检查不仅作为建模过程的保障措施，还可以作为对事件（如网站上的机器人流量）的警告，这些事件可能表明恶意活动。因此，这些审计规则也可能作为管道结束时可视化和报告层的一部分被纳入。
- en: In the second round of quality checks following model development, we want to
    evaluate whether the parameters of the model make sense and whether the performance
    on the test data is in an acceptable range for deployment. The former might involve
    plotting the important parameters of a model if the technique permits, visualizations
    that can then also be utilized by the reporting step downstream. Similarly, the
    second class of checks can involve looking at accuracy statistics such as precision,
    recall, or squared error, or the similarity of the test set to data used in model
    generation in order to determine if the reported performance is reasonable.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型开发后的第二轮质量检查中，我们希望评估模型的参数是否合理，以及测试数据上的性能是否在可接受的部署范围内。前者可能涉及在技术允许的情况下绘制模型的重要参数，这些可视化结果也可以在下一步的报告中使用。同样，第二类检查可能包括查看准确度统计信息，如精确度、召回率或平方误差，或者测试集与用于模型生成数据之间的相似性，以确定报告的性能是否合理。
- en: As with the first round of sanity checks, not only can these quality control
    measures serve to monitor the health of the model development process, but also
    potentially highlight changes in the actual modeling code itself (especially if
    this code is expected to be regularly updated).
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 与第一轮合理性检查一样，这些质量控制措施不仅可以帮助监控模型开发过程的状态，还可能突出实际建模代码本身的变化（特别是如果预期该代码将定期更新）。
- en: 'There isn''t inherently much difference between streaming and batch-oriented
    processing in the sanity checking process, just the latency at which the application
    can uncover anomalies in the source data or modelling process and deliver them
    to the reporting layer. The complexity of the sanity checks may guide this decision:
    simple checks that can be done in real-time are well suited for stream processing,
    while evaluation of the properties of a predictive model could potentially take
    longer than the training of the algorithm itself, and is thus more suited for
    a batch process.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在合理性检查过程中，流式处理和批量处理之间本质上没有太大的区别，只是应用程序在发现源数据或建模过程中的异常并将其传递到报告层时的延迟。合理性检查的复杂性可能会指导这一决策：可以在实时进行的简单检查非常适合流处理，而评估预测模型的属性可能需要比算法本身训练更长的时间，因此更适合批量处理。
- en: 'In the model development or update step, once the input data has undergone
    any necessary processing or transformation steps and passed the quality checks
    described above, it is ready to be used in developing a predictive model. This
    phase of the analytic pipeline can have several steps, with the exact form depending
    upon the application:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型开发或更新步骤中，一旦输入数据经过任何必要的处理或转换步骤并通过上述描述的质量检查，它就准备好用于开发预测模型了。这个分析流程的阶段可以包含几个步骤，具体形式取决于应用：
- en: '**Data splitting**: At this stage we typically split data into disjoin sets,
    the training data (from which we will tune the parameters of the algorithm), and
    the test data (which is used for evaluation purposes). The important reason for
    making this split is so that the model generalizes to data beyond its initial
    inputs (the training data), which we can check by evaluating its performance on
    the test set.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据拆分**：在这个阶段，我们通常将数据拆分为不重叠的集合，即训练数据（我们将从中调整算法的参数）和测试数据（用于评估目的）。进行这种拆分的重要原因是为了使模型能够泛化到其初始输入（训练数据）之外的数据，我们可以通过评估其在测试集上的性能来检查这一点。'
- en: '**Parameter tuning**: As we will examine in more detail in subsequent chapters,
    many predictive models have a number of hyperparameters— variables that need to
    be set before the parameters of the model can be optimized for a training set.
    Examples include the number of groups in a clustering application ([Chapter 3](ch03.html
    "Chapter 3. Finding Patterns in the Noise – Clustering and Unsupervised Learning"),
    *Finding Patterns in the Noise – Clustering and Unsupervised Learning*), the number
    of trees used in a random forest [Chapter 4](ch04.html "Chapter 4. Connecting
    the Dots with Models – Regression Methods"), *Connecting the Dots with Models
    – Regression Methods*, or the learning rate and number of layers in a neural network
    ([Chapter 7](ch07.html "Chapter 7. Learning from the Bottom Up – Deep Networks
    and Unsupervised Features"), *Learning from the Bottom Up – Deep Networks and
    Unsupervised Features*). These hyperparameters frequently need to be calibrated
    for optimal performance of a predictive model, through grid search ([Chapter 5](ch05.html
    "Chapter 5. Putting Data in its Place – Classification Methods and Analysis"),
    *Putting Data in its Place – Classification Methods and Analysis*) or other methods.
    This tuning can occur only during the initial phase of model development, or as
    part of a regular retraining cycle. Following or jointly with hyperparameter tuning,
    the parameters, such as regression coefficients or decision splits in a tree model
    [Chapter 4](ch04.html "Chapter 4. Connecting the Dots with Models – Regression
    Methods"), *Connecting the Dots with Models – Regression Methods*, are optimized
    for a given set of training data. Depending upon the method, this step may also
    involve variable selection—the process of pruning uninformative features from
    the input data. Finally, we may perform the above tasks for multiple algorithms
    and choose the best performing technique.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**参数调整**：正如我们将在后续章节中更详细地探讨的那样，许多预测模型都有多个超参数——在模型参数可以针对训练集进行优化之前需要设置的变量。例如，聚类应用中的组数（[第3章](ch03.html
    "第3章。在噪声中寻找模式 – 聚类和无监督学习"), *在噪声中寻找模式 – 聚类和无监督学习*），随机森林中使用的树的数量 [第4章](ch04.html
    "第4章。用模型连接点 – 回归方法"), *用模型连接点 – 回归方法*），或者神经网络中的学习率和层数（[第7章](ch07.html "第7章。自下而上学习
    – 深度网络和无监督特征"), *自下而上学习 – 深度网络和无监督特征*）。这些超参数通常需要通过网格搜索 ([第5章](ch05.html "第5章。将数据放在合适的位置
    – 分类方法和分析"), *将数据放在合适的位置 – 分类方法和分析*）或其他方法进行校准，以实现预测模型的最佳性能。这种调整只能在模型开发的初始阶段进行，或者作为常规重新训练周期的一部分。在超参数调整之后或与其同时，参数，如回归系数或树模型中的决策分割
    [第4章](ch04.html "第4章。用模型连接点 – 回归方法"), *用模型连接点 – 回归方法*，将针对给定的训练数据集进行优化。根据方法的不同，这一步还可能涉及变量选择——从输入数据中剪枝无信息特征的过程。最后，我们可能需要对多个算法执行上述任务，并选择表现最佳的技术。'
- en: Batch-oriented and streaming processes could differ at this stage depending
    upon the algorithm. For example, in models that allow for incremental updates
    through stochastic learning ([Chapter 5](ch05.html "Chapter 5. Putting Data in
    its Place – Classification Methods and Analysis"), *Putting Data in its Place
    – Classification Methods and Analysis*), new data may be processed in a stream
    as each new training example can individually tune the model parameters. Conversely,
    data may arrive in a stream but be aggregated until a sufficient size is reached,
    at which point a batch process is launched to retrain the model. Some models allow
    for both kinds of training, and the choice depends more on the expected volatility
    of the input data. For example, rapidly trending signals in social media posts
    may suggest updating a model as soon as events are available, while models based
    on longer-term events such as household buying patterns may not justify such continuous
    updates.
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 批处理和流式处理过程在此阶段可能会因算法的不同而有所区别。例如，在允许通过随机学习进行增量更新的模型中（[第5章](ch05.html "第5章。将数据放在合适的位置
    – 分类方法和分析"), *将数据放在合适的位置 – 分类方法和分析*），新数据可以以流的形式进行处理，因为每个新的训练示例都可以单独调整模型参数。相反，数据可能以流的形式到达，但会聚合到足够大的规模，此时才会启动批处理过程以重新训练模型。一些模型允许两种类型的训练，选择更多取决于输入数据的预期波动性。例如，社交媒体帖子中的快速趋势信号可能表明在事件可用时立即更新模型，而基于长期事件（如家庭购买模式）的模型可能不要求这种持续的更新。
- en: '**Model performance**: Using either the test data split off during model development
    or an entirely new set of observations, the modeling layer is also responsible
    for scoring new data, surfacing important features in the model, and providing
    information about its ongoing performance. Once the model has been trained on
    a set of input data, it can be applied to new data in either in real-time computations,
    or through offline, batch processing to generate a predicted outcome or behavior.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型性能**：使用在模型开发期间分割出的测试数据或一组全新的观测数据，建模层还负责对新数据进行评分、在模型中突出显示重要特征，并提供关于其持续性能的信息。一旦模型在一系列输入数据上被训练，它就可以应用于新数据，无论是实时计算还是通过离线批量处理来生成预测结果或行为。'
- en: Depending upon the extent of initial data processing, new records may also need
    to be transformed to generate the appropriate features for evaluation by a model.
    The extent of such transformations may dictate whether scoring is best accomplished
    through a streaming or batch framework.
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 根据初始数据处理的程度，新的记录可能还需要转换以生成模型评估所需的适当特征。这种转换的程度可能决定了评分最好是通过流式或批量框架来完成。
- en: Similarly, the use of the resulting prediction may guide the choice between
    streaming or batch-oriented processing. When such scores are used as inputs to
    other, responsive systems (such as in reordering search results or ads presented
    on a webpage), real-time updates from streaming pipelines, allow for immediate
    use of the new scores and so may be valuable. When the scores are primarily used
    for internal decision-making (such as prioritizing sales leads for follow-up),
    real-time updates may not be necessary and a batch-oriented framework can be used
    instead. This difference in latency may be correlated with whether the downstream
    consumer is another application (machine to machine interaction), or a human user
    relying upon the model for insight (machine to human).
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 同样，结果的预测使用可能指导选择流式或批量导向的处理。当这些评分被用作其他响应系统的输入（如重新排序搜索结果或网页上展示的广告）时，来自流式管道的实时更新允许立即使用新的评分，因此可能很有价值。当评分主要用于内部决策（如优先处理销售线索以进行跟进）时，实时更新可能不是必需的，可以使用批量导向的框架。这种延迟差异可能与下游消费者是另一个应用程序（机器到机器交互）还是依赖模型进行洞察的人类用户有关。
- en: '**Model persistence**: Once we have tuned the parameters of the predictive
    model, the result may also need to be packaged, or serialized into a format to
    allow deployment within a production environment. We will examine this in greater
    depth in [Chapter 8](ch08.html "Chapter 8. Sharing Models with Prediction Services"),
    *Sharing Models with Prediction Services*, but in brief this process involves
    transforming the model output into a form for use by downstream systems and saving
    it back to the data layer for both disaster recovery and potential use by the
    reporting layer downstream described as follows.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型持久化**：一旦我们调整了预测模型的参数，结果可能还需要打包或序列化为一种格式，以便在生产环境中部署。我们将在第8章[共享预测服务中的模型](ch08.html
    "第8章。与预测服务共享模型")中更深入地探讨这一点，但简要来说，这个过程涉及将模型输出转换为下游系统可用的形式，并将其保存回数据层，以便进行灾难恢复以及可能由下游的报表层使用，如下所述。'
- en: Deployment layer
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 部署层
- en: 'The output of our predictive modeling can be made broadly available to both
    individual users and other software services through a deployment layer, which
    encapsulates the modeling, scoring, and evaluation functions in the previous layer
    inside of web applications, as shown in the following Figure 4:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我们预测建模的输出可以通过部署层广泛提供给个人用户和其他软件服务，该部署层将上一层的建模、评分和评估功能封装在Web应用程序中，如下面的图4所示：
- en: '![Deployment layer](img/B04881_chapter01_04.jpg)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![部署层](img/B04881_chapter01_04.jpg)'
- en: 'Figure 4: Deployment layer components'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：部署层组件
- en: This **application layer** receives network calls over the web, transmitted
    either through a web browser or from a programmatic request generated by another
    software system. As we will describe in [Chapter 8](ch08.html "Chapter 8. Sharing
    Models with Prediction Services"), *Sharing Models with Prediction Services*,
    these applications usually provide a standard set of commands to initiate an action,
    get a result, save new information, or delete unwanted information. They also
    typically interact with the data layer to both store results and, in the case
    of long-running tasks, to store information about the progress of modeling computations.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这个**应用层**通过网页接收网络调用，这些调用是通过网页浏览器或由其他软件系统生成的程序性请求传输的。正如我们将在[第8章](ch08.html "第8章。与预测服务共享模型")中描述的那样，*与预测服务共享模型*，这些应用程序通常提供一组标准命令来启动操作、获取结果、保存新信息或删除不需要的信息。它们还通常与数据层交互，以存储结果，在长时间运行的任务的情况下，存储建模计算进度的信息。
- en: The network calls received by these applications are brokered by the Server
    Layer, which serves to route traffic between applications (usually based on `url`
    patterns). As we will cover in [Chapter 8](ch08.html "Chapter 8. Sharing Models
    with Prediction Services"), *Sharing Models with Prediction Services*, this separation
    between the server and application allows us to scale our application by adding
    more machines, and independently add more servers to balance incoming requests.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 这些应用程序接收到的网络调用由服务器层代理，该层的作用是在应用程序之间路由流量（通常基于`url`模式）。正如我们将在[第8章](ch08.html "第8章。与预测服务共享模型")中介绍的那样，*与预测服务共享模型*，这种服务器和应用程序之间的分离使我们能够通过添加更多机器来扩展我们的应用程序，并独立添加更多服务器以平衡传入的请求。
- en: The **client layer**, which initiates the requests received by the server, could
    be both interactive systems, such as a dashboard, or an independent system such
    as an e-mail server, that uses the output of a model to schedule outgoing messages.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '**客户端层**，它启动服务器接收到的请求，可以是交互式系统，如仪表板，也可以是独立系统，如电子邮件服务器，该服务器使用模型的输出来安排发出的消息。'
- en: Reporting layer
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 报告层
- en: 'The output of the analytical pipeline may be surfaced by the reporting layer,
    which involves a number of distinct tasks, as shown in the following Figure 5:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 分析管道的输出可能由报告层呈现，这涉及许多不同的任务，如下面的图5所示：
- en: '![Reporting layer](img/B04881_chapter01_05.jpg)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![报告层](img/B04881_chapter01_05.jpg)'
- en: 'Figure 5: Reporting applications for prediction services'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：预测服务的报告应用
- en: '**Visualizations**: This can allow interactive querying of the source data
    along with model data such as parameters and feature importance. It can also be
    used to visualize the output of a model, such as the set of recommendations that
    would be provided to a user on an e-commerce site, or the risk score assigned
    to a particular bank account. Because it is frequently used in interactive mode,
    we may also consider aggregating large model inputs into summarized datasets for
    lower latency during exploratory sessions. Additionally, visualizations can be
    either an ad hoc process (such as the interactive notebooks we will examine in
    future chapters), or a fixed series of graphics (such as the dashboards we will
    construct in [Chapter 9](ch09.html "Chapter 9. Reporting and Testing – Iterating
    on Analytic Systems"), *Reporting and Testing – Iterating on Analytic Systems*).'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可视化**：这可以允许对源数据和模型数据进行交互式查询，例如参数和特征重要性。它还可以用于可视化模型输出，例如在电子商务网站上提供给用户的推荐集，或分配给特定银行账户的风险评分。由于它通常以交互式模式使用，我们还可以考虑将大型模型输入汇总到汇总数据集中，以在探索会话期间降低延迟。此外，可视化可以是临时的过程（例如我们将在未来章节中检查的交互式笔记本），也可以是一系列固定的图形（例如我们在[第9章](ch09.html
    "第9章。报告和测试 – 在分析系统中迭代")中构建的仪表板，*报告和测试 – 在分析系统中迭代*）。'
- en: '**Audit/Healthcheck**: The reporting service involves ongoing monitoring of
    the application. Indeed, an important factor in developing robust analytic pipelines
    is regular assessment to ensure that the model is performing as expected. Combining
    outputs from many previous steps, such as quality control checks and scores for
    new data, a reporting framework visualizes these statistics and compares them
    to previous values or a gold standard. This sort of reporting can be used both
    by the analyst, to monitor the application, and as a way to surface insights uncovered
    by the modeling process to the larger business organization.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**审计/健康检查**：报告服务涉及对应用的持续监控。确实，开发健壮的分析管道的一个重要因素是定期评估，以确保模型按预期运行。通过结合许多先前步骤的输出，例如质量控制检查和新数据的评分，报告框架将这些统计数据可视化，并将它们与先前值或黄金标准进行比较。这种类型的报告既可以由分析师用来监控应用，也可以作为一种方式，将建模过程中发现的见解呈现给更大的业务组织。'
- en: '**Comparison reports**: This might be used as we iterate on model development
    through the process of experimentation, as we will discuss in [Chapter 9](ch09.html
    "Chapter 9. Reporting and Testing – Iterating on Analytic Systems"), *Reporting
    and Testing – Iterating on Analytic Systems*. Because this analysis may involve
    statistical measurements, the visualizations might be combined with a service
    in the deployment layer to calculate significance metrics.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**比较报告**：在通过实验过程迭代模型开发时，这可能被用来，正如我们在[第9章](ch09.html "第9章。报告和测试 – 在分析系统中迭代")中讨论的，*报告和测试
    – 在分析系统中迭代*。因为这种分析可能涉及统计测量，可视化可能需要与部署层中的服务结合来计算显著性指标。'
- en: The choice of batch versus streaming processes will often determine whether
    such reports can be provided in real-time, but just because they are available
    immediately doesn't imply that such frequency is valuable to the user. For example,
    even if user response rates to an ad campaign can be collected in real-time, decisions
    about future advertising programs on these results may be constrained by quarterly
    business planning. In contrast, trending interest in particular search queries
    might also allow us to quickly tune the results of a recommendation algorithm,
    and thus this low-latency signal has value. Again, judgment based on the particular
    use-case is required.
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 批处理与流处理过程的选择通常会决定此类报告是否可以实时提供，但仅仅因为它们可以立即获得，并不意味着这种频率对用户有价值。例如，即使可以实时收集用户对广告活动的响应率，关于未来广告计划的决策可能受到季度商业计划的限制。相比之下，对特定搜索查询趋势的兴趣也可能使我们能够快速调整推荐算法的结果，因此这种低延迟信号是有价值的。再次强调，需要根据特定的用例进行判断。
- en: To conclude this introduction, let's examine a pair of hypothetical applications
    that illustrates many of the components we've described above. Don't worry too
    much about the exact meaning of all the terminology, which will be expanded upon
    in following chapters.
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了结束这个介绍，让我们考察一对假设的应用程序，这些应用程序说明了我们上面描述的许多组件。不必过于担心所有术语的确切含义，这些将在后续章节中进一步阐述。
- en: 'Case study: sentiment analysis of social media feeds'
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 案例研究：社交媒体流量的情感分析
- en: Consider a marketing department that wants to evaluate the effectiveness of
    its campaigns by monitoring brand sentiment on social media sites. Because changes
    in sentiment could have negative effects on the larger company, this analysis
    is performed in real time. An overview of this example is shown in the Figure
    6.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个想要通过监控社交媒体网站上的品牌情绪来评估其活动有效性的市场营销部门。因为情绪的变化可能对整个公司产生负面影响，这种分析是在实时进行的。本例的概述如图6所示。
- en: '![Case study: sentiment analysis of social media feeds](img/B04881_chapter01_06.jpg)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![案例研究：社交媒体流量的情感分析](img/B04881_chapter01_06.jpg)'
- en: 'Figure 6: Diagram of social media sentiment analysis case study'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：社交媒体情感分析案例研究图示
- en: Data input and transformation
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据输入和转换
- en: The input data to this application are social media posts. This data is available
    in real time, but a number of steps need to be applied to make it usable by the
    sentiment-scoring model. Common words (such as **and** and **the**) need to be
    filtered, messages to be selected which actually refer to the company, and misspellings
    and word capitalization need to be normalized. Once this cleaning is done, further
    transformations may turn the message into a vector, with a count of each word
    in the model's allowed vocabulary, or hashed to populate a fixed-length vector.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 此应用程序的输入数据是社交媒体帖子。这些数据是实时可用的，但需要应用多个步骤才能使其可用于情感评分模型。需要过滤掉常见词语（如**和**和**the**），选择实际涉及公司的消息，以及需要对拼写错误和单词大小写进行归一化。一旦完成清理，进一步的转换可能将消息转换为向量，其中包含模型允许词汇表中每个单词的计数，或者将其散列以填充固定长度的向量。
- en: Sanity checking
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理性检查
- en: The outputs of the preceding transformations need to be sanity checked – are
    there any users who account for an unusually large number of messages (which might
    indicate bot spam)? Are there unexpected words in the input (which could be due
    to character encoding issues)? Are any of the input messages longer than the allowed
    message size for the service (which could indicate incorrect separation of messages
    in the input stream)?
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 前面转换的输出需要经过理性检查——是否有用户发送了异常大量的消息（这可能表明是机器人垃圾邮件）？输入中是否有意外的词语（这可能是由于字符编码问题造成的）？是否有任何输入消息的长度超过了服务允许的消息大小（这可能表明输入流中的消息分割不正确）？
- en: Once the model is developed, sanity checking involves some human guidance. Do
    the sentiments predicted by the model correlate with the judgment of human readers?
    Do the words that correspond to high probability for a given sentiment in the
    model make intuitive sense?
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦模型开发完成，理性检查需要一些人工指导。模型预测的情感是否与人类读者的判断相关？模型中对应给定情感的高概率词语是否具有直观意义？
- en: These and other sanity checks can be visualized as a webpage or document summary
    that can be utilized by both the modeler, to evaluate model health, and the rest
    of the marketing staff to understand new topics that may correspond to positive
    or negative brand sentiment.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 这些以及其他理性检查可以可视化为一个网页或文档摘要，可以被模型开发者用来评估模型健康状况，以及营销团队的其余成员用来理解可能对应积极或消极品牌情感的新主题。
- en: Model development
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型开发
- en: 'The model used in this pipeline is a multinomial logistic regression ([Chapter
    5](ch05.html "Chapter 5. Putting Data in its Place – Classification Methods and
    Analysis"), *Putting Data in its Place – Classification Methods and Analysis*)
    that takes as input counts of the words in each social media message and outputs
    a predicted probability that the message belongs to a given sentiment category:
    **VERY POSITIVE**, **POSITIVE**, **NEUTRAL**, **NEGATIVE**, and **VERY NEGATIVE**.
    While in theory (because the multinomial logistic regression can be trained using
    stochastic gradient updates), we could perform model training online, in practice
    this is not possible because the labels (sentiments) need to be assigned by a
    human expert. Therefore, our model is developed in an offline batch-process each
    week as a sufficient set of social media messages labelled by an expert becomes
    available. The hyperparameters of this model (the regularization weight and learning
    weight) have been estimated previously, so the batch retraining calculates the
    regression coefficient weights for a set of training messages and evaluates the
    performance on a separate batch of test messages.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在此流程中使用的模型是多项逻辑回归（[第5章](ch05.html "第5章。将数据放在合适的位置——分类方法和分析"），*将数据放在合适的位置——分类方法和分析*），它以每个社交媒体消息中的词语计数作为输入，并输出一个预测概率，即该消息属于给定的情感类别：**非常积极**、**积极**、**中性**、**消极**和**非常消极**。虽然在理论上（因为多项逻辑回归可以使用随机梯度更新进行训练），我们可以在线执行模型训练，但在实践中这是不可能的，因为标签（情感）需要由人工专家分配。因此，我们的模型每周在离线批量处理中开发，当足够数量的由专家标记的社会媒体消息集可用时。此模型的超参数（正则化权重和学习权重）之前已经估计过，因此批量重新训练计算一组训练消息的回归系数权重，并在单独的测试消息批次上评估性能。
- en: Scoring
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评分
- en: Incoming messages processed by this pipeline can be scored by the existing model
    and assigned to one of the five sentiment classes, and the volume of each category
    is updated in real time to allow monitoring of brand sentiment and immediate action
    if there is an extremely negative response to one of the marketing department's
    campaigns.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 通过此管道处理的传入消息可以由现有模型评分，并分配到五个情感类别之一，并且每个类别的数量会实时更新，以便监控品牌情感，并在营销部门的某项活动收到极端负面反馈时立即采取行动。
- en: Visualization and reporting
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可视化和报告
- en: As the model scores new social media messages, it updates a real-time dashboard
    with the volume of messages in each category compared to yesterday, the preceding
    week, and the preceding month, along with which words are given most weight in
    this week's model for the different classes. It also monitors the presence of
    new words, which may not have been present in the model's vocabulary, and which
    could indicate new features that the model cannot appropriately score, and suggest
    the need for inter-week retraining. In addition to this real-time dashboard, which
    the marketing department uses to monitor response to its campaigns, the analyst
    develops a more detailed report concerning model parameters and performance along
    with input dataset summary statistics, which they use to determine if the model
    training process each week is performing as expected, or if the quality of the
    model is degrading over time.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 当模型对新的社交媒体消息进行评分时，它会更新一个实时仪表板，显示与昨天、上周和上个月相比每个类别的消息数量，以及本周模型对不同类别赋予最高权重的词汇。它还监控新词汇的出现，这些词汇可能不在模型的词汇表中，可能表明模型无法适当评分的新特征，并建议进行跨周重新训练的需求。除了营销部门用于监控其活动响应的实时仪表板外，分析师还开发了一份更详细的报告，涉及模型参数和性能，以及输入数据集的摘要统计信息，他们使用这些信息来确定每周的模型训练过程是否按预期进行，或者模型的质量是否随时间退化。
- en: 'Case study: targeted e-mail campaigns'
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 案例研究：定向电子邮件活动
- en: In our next example, our same marketing department wants to promote new items
    on their website to users who are mostly likely to be interested in purchasing
    them. Using a predictive model that includes features from both users and these
    new items, customers are sent e-mails containing a list of their most probable
    purchase. Unlike the real-time sentiment-monitoring example, e-mails are sent
    in batches and use data accumulated over a customer's whole transaction history
    as inputs to the model, which is a better fit for batch processing.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的下一个例子中，我们的同一个营销部门希望向可能对购买新商品感兴趣的用户推广其网站上的新商品。使用包含用户和这些新商品特征的预测模型，向客户发送包含他们最可能购买的商品列表的电子邮件。与实时情感监控示例不同，电子邮件是批量发送的，并使用客户整个交易历史中积累的数据作为模型的输入，这对于批量处理更合适。
- en: An overview of the processes used in this example is shown in Figure 7.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 本例中使用的流程概述如图7所示。
- en: '![Case study: targeted e-mail campaigns](img/B04881_chapter01_07.jpg)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![案例研究：定向电子邮件活动](img/B04881_chapter01_07.jpg)'
- en: 'Figure 7: Diagram of e-mail targeting case study'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 图7：电子邮件定向案例研究图
- en: Data input and transformation
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据输入和转换
- en: During the initial data ingestion step, customer records stored in a company's
    data warehouse (a relational database system) are aggregated to generate features
    such as the average amount spent per week, frequency with which a customer visits
    the company's website, and the number of items purchased in a number of categories,
    such as furniture, electronics, clothing, and media. This is combined with a set
    of features for the set of items that are potentially promoted in the e-mail campaign,
    such as price, brand, and the average rating of similar items on the site. These
    features are constructed through a batch process that runs once per week, before
    e-mails are sent, on Mondays, to customers.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在初始数据摄取步骤中，存储在公司数据仓库（关系数据库系统）中的客户记录被聚合以生成特征，例如每周平均花费金额、客户访问公司网站频率以及多个类别（如家具、电子产品、服装和媒体）中购买的商品数量。这些特征与电子邮件活动中可能推广的商品集的特征相结合，例如价格、品牌以及网站上类似商品的平均评分。这些特征通过每周一次的批量处理构建，在发送电子邮件之前，在周一对客户进行。
- en: Sanity checking
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 精神检查
- en: 'The inputs to the model are checked for reasonable values: are the average
    purchase behaviors or transactions volume of a customer far outside the expected
    range? These could indicate errors in the data warehouse processing, or bot traffic
    on the website. Because the transformation logic involved in constructing features
    for the model is complex and may change over time as the model evolves, its outputs
    are also checked. For example, the purchase numbers and average prices should
    never be less than zero, and no category of merchandise should have zero records.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的输入将检查其合理性：客户的平均购买行为或交易量是否远超出预期范围？这可能会表明数据仓库处理中的错误，或者网站上的机器人流量。由于构建模型特征涉及到的转换逻辑复杂，并且可能随着模型的发展而变化，因此其输出也将进行检查。例如，购买数量和平均价格不应低于零，且没有任何商品类别应有零条记录。
- en: Following scoring of potential items prior to e-mail messaging, the top-scoring
    items per customer are sanity checked by comparing them to either the customer's
    historical transactions (to determine if they are sensible), or if no history
    is available, to the purchases of customers most similar in demographics.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在电子邮件消息之前对潜在项目进行评分后，每个客户得分最高的项目将通过与客户的过往交易（以确定其是否合理）进行比较进行合理性检查，或者如果没有历史记录，则与在人口统计上最相似的客户的购买行为进行比较。
- en: Model development
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型开发
- en: In this example, the model is a random forest regression [Chapter 4](ch04.html
    "Chapter 4. Connecting the Dots with Models – Regression Methods"), *Connecting
    the Dots with Models – Regression Methods* that divides historical items – customer
    pairs into purchases (**labeled 1**) and non-purchases (**labeled 0**) and produces
    a scored probability that customer A purchases **item X**. One complexity in this
    model is that items which haven't been purchased might simply not have been seen
    by the customer yet, so a restriction is imposed in which the negative examples
    must be drawn from items already available for a month or more on the website.
    The hyperparameters of this model (the number and size of each tree) are calibrated
    during weekly retraining, along with the influence of individual variables on
    the resulting predictions.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在本例中，该模型是一个随机森林回归[第4章](ch04.html "第4章. 使用模型连接点 – 回归方法")*使用模型连接点 – 回归方法*，它将历史项目
    – 客户对划分为购买（**标记为1**）和非购买（**标记为0**），并产生一个评分概率，即客户A购买**项目X**。该模型的一个复杂性在于，尚未购买的项目可能只是尚未被客户看到，因此对负例施加了限制，即必须从网站上已上架一个月或更长时间的项目中抽取。此模型的超参数（每棵树的数量和大小）在每周重新训练期间进行校准，同时校准个别变量对结果预测的影响。
- en: Scoring
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评分
- en: After the model is retrained each week using historical data, the set of new
    items on the website are scored using this model for each customer, and the top
    three are sent in the e-mail campaign.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 每周使用历史数据重新训练模型后，网站上的新项目将使用此模型为每个客户进行评分，并将前三项发送到电子邮件营销活动中。
- en: Visualization and reporting
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可视化和报告
- en: Either class of sanity checking (of either input data or model performance)
    can be part of a regular diagnostics report on the model. Because the random forest
    model is more complex than other approaches, it is particularly important to monitor
    changes in feature importance and model accuracy as problems may require more
    time to debug and resolve.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 任何类型的合理性检查（无论是输入数据还是模型性能）都可以是模型定期诊断报告的一部分。由于随机森林模型比其他方法更复杂，因此特别重要的是要监控特征重要性和模型准确性的变化，因为问题可能需要更多时间来调试和解决。
- en: Because the predictions are used in a production system rather than delivering
    insights themselves, this reporting is primarily used by the analyst who developed
    the pipeline rather than the other members of the marketing department.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 由于预测在生产系统中使用，而不是直接提供洞察，因此此类报告主要供开发管道的分析师使用，而不是营销部门的其他成员。
- en: The success of these promotional e-mails will typically be monitored over the
    next month, and updates on the accuracy (for example, how many e-mails led to
    purchases above expected levels) can form the basis of a longer-term report that
    can help guide both the structure of the campaign itself (for example, varying
    the number of items in the messages) and the model (perhaps training should be
    performed more frequently if the predictions seem to become significantly worse
    between weeks).
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 这些促销电子邮件的成功通常会在接下来的一个月内进行监控，关于准确性的更新（例如，有多少电子邮件导致了超出预期水平的购买）可以成为长期报告的基础，该报告可以帮助指导活动的结构（例如，改变信息中的项目数量）以及模型（如果预测似乎在周之间变得明显更差，可能需要更频繁地进行训练）。
- en: Tip
  id: totrans-134
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: '**Downloading the example code**'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '**下载示例代码**'
- en: You can download the example code files for this book from your account at [http://www.packtpub.com](http://www.packtpub.com).
    If you purchased this book elsewhere, you can visit [http://www.packtpub.com/support](http://www.packtpub.com/support)
    and register to have the files e-mailed directly to you.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从[http://www.packtpub.com](http://www.packtpub.com)的账户下载此书的示例代码文件。如果你在其他地方购买了这本书，你可以访问[http://www.packtpub.com/support](http://www.packtpub.com/support)并注册，以便将文件直接通过电子邮件发送给你。
- en: 'You can download the code files by following these steps:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过以下步骤下载代码文件：
- en: Log in or register to our website using your e-mail address and password.
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用你的电子邮件地址和密码登录或注册我们的网站。
- en: Hover the mouse pointer on the **SUPPORT** tab at the top.
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将鼠标指针悬停在顶部的**支持**标签上。
- en: Click on **Code Downloads & Errata**.
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 点击**代码下载与勘误表**。
- en: Enter the name of the book in the **Search** box.
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在**搜索**框中输入书籍名称。
- en: Select the book for which you're looking to download the code files.
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择你想要下载代码文件的书籍。
- en: Choose from the drop-down menu where you purchased this book from.
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从下拉菜单中选择你购买此书籍的来源。
- en: Click on **Code Download**.
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 点击**代码下载**。
- en: 'Once the file is downloaded, please make sure that you unzip or extract the
    folder using the latest version of:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 文件下载完成后，请确保使用最新版本的以下软件解压或提取文件夹：
- en: WinRAR / 7-Zip for Windows
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: WinRAR / 7-Zip（适用于Windows）
- en: Zipeg / iZip / UnRarX for Mac
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zipeg / iZip / UnRarX（适用于Mac）
- en: 7-Zip / PeaZip for Linux
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 7-Zip / PeaZip（适用于Linux）
- en: Summary
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: After finishing this chapter, you should now be able to describe the core components
    of an analytic pipeline and the ways in which they interact. We've also examined
    the differences between batch and streaming processes, and some of the use cases
    in which each type of application is well suited. We've also walked through examples
    using both paradigms and the design decisions needed at each step.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 完成本章后，你现在应该能够描述分析管道的核心组件以及它们之间的交互方式。我们还探讨了批处理和流处理之间的差异，以及每种类型的应用程序适合的用例。我们还通过使用这两种范例的示例以及每一步所需的设计决策进行了说明。
- en: In the following sections we will develop the concepts previously described,
    and go into greater detail on some of the technical terms brought up in the case
    studies. In [Chapter 2](ch02.html "Chapter 2. Exploratory Data Analysis and Visualization
    in Python"), *Exploratory Data Analysis and Visualization in Python*, we will
    introduce interactive data visualization and exploration using open source Python
    tools. [Chapter 3](ch03.html "Chapter 3. Finding Patterns in the Noise – Clustering
    and Unsupervised Learning"), *Finding Patterns in the Noise – Clustering and Unsupervised
    Learning*, describes how to identify groups of related objects in a dataset using
    clustering methods, also known as unsupervised learning. In contrast, [Chapter
    4](ch04.html "Chapter 4. Connecting the Dots with Models – Regression Methods"),
    *Connecting the Dots with Models – Regression Methods*, and [Chapter 5](ch05.html
    "Chapter 5. Putting Data in its Place – Classification Methods and Analysis"),
    *Putting Data in its Place – Classification Methods and Analysis*, explore supervised
    learning, whether for continuous outcomes such as prices (using regression techniques
    in [Chapters 4](ch04.html "Chapter 4. Connecting the Dots with Models – Regression
    Methods"), *Connecting the Dots with Models – Regression Methods*), or categorical
    responses such as user sentiment (using classification models described in [Chapter
    5](ch05.html "Chapter 5. Putting Data in its Place – Classification Methods and
    Analysis"), *Putting Data in its Place – Classification Methods and Analysis*).
    Given a large number of features, or complex data such as text or image, we may
    benefit by performing dimensionality reduction, as described in [Chapter 6](ch06.html
    "Chapter 6. Words and Pixels – Working with Unstructured Data"), *Words and Pixels
    – Working with Unstructured Data*. Alternatively, we may fit textual or image
    data using more sophisticated models such as the deep neural networks covered
    in [Chapter 7](ch07.html "Chapter 7. Learning from the Bottom Up – Deep Networks
    and Unsupervised Features"), *Learning from the Bottom Up – Deep Networks and
    Unsupervised Features*, which can capture complex interactions between input variables.
    In order to use these models in business applications, we will develop a web framework
    to deploy analytical solutions in [Chapter 8](ch08.html "Chapter 8. Sharing Models
    with Prediction Services"), *Sharing Models with Prediction Services*, and describe
    ongoing monitoring and refinement of the system in [Chapter 9](ch09.html "Chapter 9. Reporting
    and Testing – Iterating on Analytic Systems"), *Reporting and Testing – Iterating
    on Analytic Systems*.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下章节中，我们将发展之前描述的概念，并对案例研究中提出的一些技术术语进行更深入的探讨。在[第2章](ch02.html "第2章. 使用Python进行探索性数据分析和可视化")，*使用Python进行探索性数据分析和可视化*中，我们将介绍使用开源Python工具进行交互式数据可视化和探索。[第3章](ch03.html
    "第3章. 在噪声中寻找模式 - 聚类和无监督学习")，*在噪声中寻找模式 - 聚类和无监督学习*描述了如何使用聚类方法（也称为无监督学习）在数据集中识别相关对象的组。相比之下，[第4章](ch04.html
    "第4章. 用模型连接点 - 回归方法")，*用模型连接点 - 回归方法*和[第5章](ch05.html "第5章. 将数据放在合适的位置 - 分类方法和分析")，*将数据放在合适的位置
    - 分类方法和分析*探讨了监督学习，无论是用于连续结果，如价格（在第4章[第4章. 用模型连接点 - 回归方法]中使用的回归技术），还是用于分类响应，如用户情绪（在第5章[第5章.
    将数据放在合适的位置 - 分类方法和分析]中描述的分类模型）。给定大量特征或复杂数据，如文本或图像，我们可能通过执行降维来受益，如第6章[第6章. 文字和像素
    - 处理非结构化数据]中所述，*文字和像素 - 处理非结构化数据*。或者，我们可以使用更复杂的方法，如第7章[第7章. 从底部学习 - 深度网络和无监督特征]中涵盖的深度神经网络，*从底部学习
    - 深度网络和无监督特征*，这些方法可以捕捉输入变量之间的复杂交互。为了将这些模型用于商业应用，我们将在第8章[第8章. 与预测服务共享模型]中开发一个Web框架来部署分析解决方案，*与预测服务共享模型*，并在第9章[第9章.
    报告和测试 - 在分析系统中迭代]中描述系统的持续监控和改进，*报告和测试 - 在分析系统中迭代*。
- en: 'Throughout, we will emphasize both how these methods work and practical tips
    for choosing between different approaches for various problems. Working through
    the code examples will illustrate the required components for building and maintaining
    an application for your own use case. With these preliminaries, let''s dive next
    into some exploratory data analysis using notebooks: a powerful way to document
    and share analysis.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在整个过程中，我们将强调这些方法是如何工作的，以及在不同问题之间选择不同方法的实用技巧。通过分析代码示例，将展示构建和维护适用于您自己用例的应用程序所需的组件。有了这些预备知识，让我们接下来深入探讨一些使用笔记本进行的数据探索分析：这是一种强大的记录和分享分析的方法。
