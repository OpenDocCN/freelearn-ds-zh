- en: Chapter 5. Introducing MLlib
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we learned how to prepare the data for modeling. In
    this chapter, we will actually use some of that learning to build a classification
    model using the MLlib package of PySpark.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: MLlib stands for Machine Learning Library. Even though MLlib is now in a maintenance
    mode, that is, it is not actively being developed (and will most likely be deprecated
    later), it is warranted that we cover at least some of the features of the library.
    In addition, MLlib is currently the only library that supports training models
    for streaming.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-3
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Starting with Spark 2.0, ML is the main machine learning library that operates
    on DataFrames instead of RDDs as is the case for MLlib.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: 'The documentation for `MLlib` can be found here: [http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html).'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, you will learn how to do the following:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: Prepare the data for modeling with MLlib
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Perform statistical testing
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Predict survival chances of infants using logistic regression
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Select the most predictable features and train a random forest model
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Overview of the package
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'At the high level, MLlib exposes three core machine learning functionalities:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: '**Data preparation**: Feature extraction, transformation, selection, hashing
    of categorical features, and some natural language processing methods'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Machine learning algorithms**: Some popular and advanced regression, classification,
    and clustering algorithms are implemented'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Utilities**: Statistical methods such as descriptive statistics, chi-square
    testing, linear algebra (sparse and dense matrices and vectors), and model evaluation
    methods'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As you can see, the palette of available functionalities allows you to perform
    almost all of the fundamental data science tasks.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will build two classification models: a linear regression
    and a random forest. We will use a portion of the US 2014 and 2015 birth data
    we downloaded from [http://www.cdc.gov/nchs/data_access/vitalstatsonline.htm](http://www.cdc.gov/nchs/data_access/vitalstatsonline.htm);
    from the total of 300 variables we selected 85 features that we will use to build
    our models. Also, out of the total of almost 7.99 million records, we selected
    a balanced sample of 45,429 records: 22,080 records where infants were reported
    dead and 23,349 records with infants alive.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The dataset we will use in this chapter can be downloaded from [http://www.tomdrabas.com/data/LearningPySpark/births_train.csv.gz](http://www.tomdrabas.com/data/LearningPySpark/births_train.csv.gz).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: Loading and transforming the data
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Even though MLlib is designed with RDDs and DStreams in focus, for ease of transforming
    the data we will read the data and convert it to a DataFrame.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The DStreams are the basic data abstraction for Spark Streaming (see [http://bit.ly/2jIDT2A](http://bit.ly/2jIDT2A))
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: Just like in the previous chapter, we first specify the schema of our dataset.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Note that here (for brevity), we only present a handful of features. You should
    always check our GitHub account for this book for the latest version of the code:
    [https://github.com/drabastomek/learningPySpark](https://github.com/drabastomek/learningPySpark).'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s the code:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Next, we load the data. The `.read.csv(...)` method can read either uncompressed
    or (as in our case) GZipped comma-separated values. The `header` parameter set
    to `True` indicates that the first row contains the header, and we use the `schema`
    to specify the correct data types:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: There are plenty of features in our dataset that are strings. These are mostly
    categorical variables that we need to somehow convert to a numeric form.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can glimpse over the original file schema specification here: [ftp://ftp.cdc.gov/pub/Health_Statistics/NCHS/Dataset_Documentation/DVS/natality/UserGuide2015.pdf](ftp://ftp.cdc.gov/pub/Health_Statistics/NCHS/Dataset_Documentation/DVS/natality/UserGuide2015.pdf).'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: 'We will first specify our recode dictionary:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Our goal in this chapter is to predict whether the `''INFANT_ALIVE_AT_REPORT''`
    is either `1` or `0`. Thus, we will drop all of the features that relate to the
    infant and will try to predict the infant''s chances of surviving only based on
    the features related to its mother, father, and the place of birth:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: In our dataset, there are plenty of features with Yes/No/Unknown values; we
    will only code `Yes` to `1`; everything else will be set to `0`.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: 'There is also a small problem with how the number of cigarettes smoked by the
    mother was coded: as 0 means the mother smoked no cigarettes before or during
    the pregnancy, between 1-97 states the actual number of cigarette smoked, 98 indicates
    either 98 or more, whereas 99 identifies the unknown; we will assume the unknown
    is 0 and recode accordingly.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: 'So next we will specify our recoding methods:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The `recode` method looks up the correct key from the `recode_dictionary` (given
    the `key`) and returns the corrected value. The `correct_cig` method checks when
    the value of the feature `feat` is not equal to 99 and (for that situation) returns
    the value of the feature; if the value is equal to 99, we get 0 otherwise.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: 'We cannot use the `recode` function directly on a `DataFrame`; it needs to
    be converted to a UDF that Spark will understand. The `rec_integer` is such a
    function: by passing our specified `recode` function and specifying the return
    value data type, we can use it then to encode our Yes/No/Unknown features.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: 'So, let''s get to it. First, we''ll correct the features related to the number
    of cigarettes smoked:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The `.withColumn(...)` method takes the name of the column as its first parameter
    and the transformation as the second one. In the previous cases, we do not create
    new columns, but reuse the same ones instead.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we will focus on correcting the Yes/No/Unknown features. First, we will
    figure out which these are with the following snippet:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: First, we created a list of tuples (`cols`) that hold column names and corresponding
    data types. Next, we loop through all of these and calculate distinct values of
    all string columns; if a `'Y'` is within the returned list, we append the column
    name to the `YNU_cols` list.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: 'DataFrames can transform the features in bulk while selecting features. To
    present the idea, consider the following example:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Here''s what we get in return:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: '![Loading and transforming the data](img/B05793_05_01.jpg)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
- en: We select the `'INFANT_NICU_ADMISSION'` column and we pass the name of the feature
    to the `rec_integer` method. We also alias the newly transformed column as `'INFANT_NICU_ADMISSION_RECODE'`.
    This way we will also confirm that our UDF works as intended.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: 'So, to transform all the `YNU_cols` in one go, we will create a list of such
    transformations, as shown here:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Let''s check if we got it correctly:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Here''s what we get:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: '![Loading and transforming the data](img/B05793_05_02.jpg)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
- en: Looks like everything worked as we wanted it to work, so let's get to know our
    data better.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: Getting to know your data
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In order to build a statistical model in an informed way, an intimate knowledge
    of the dataset is necessary. Without knowing the data it is possible to build
    a successful model, but it is then a much more arduous task, or it would require
    more technical resources to test all the possible combinations of features. Therefore,
    after spending the required 80% of the time cleaning the data, we spend the next
    15% getting to know it!
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: Descriptive statistics
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I normally start with descriptive statistics. Even though the DataFrames expose
    the `.describe()` method, since we are working with `MLlib`, we will use the `.colStats(...)`
    method.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A word of warning: the `.colStats(...)` calculates the descriptive statistics
    based on a sample. For real world datasets this should not really matter but if
    your dataset has less than 100 observations you might get some strange results.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: 'The method takes an `RDD` of data to calculate the descriptive statistics of
    and return a `MultivariateStatisticalSummary` object that contains the following
    descriptive statistics:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: '`count()`: This holds a row count'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`max()`: This holds maximum value in the column'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mean():` This holds the value of the mean for the values in the column'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`min()`: This holds the minimum value in the column'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`normL1()`: This holds the value of the L1-Norm for the values in the column'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`normL2()`: This holds the value of the L2-Norm for the values in the column'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`numNonzeros()`: This holds the number of nonzero values in the column'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`variance()`: This holds the value of the variance for the values in the column'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  id: totrans-77
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You can read more about the L1- and L2-norms here [http://bit.ly/2jJJPJ0](http://bit.ly/2jJJPJ0)
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: 'We recommend checking the documentation of Spark to learn more about these.
    The following is a snippet that calculates the descriptive statistics of the numeric
    features:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The preceding code produces the following result:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: '![Descriptive statistics](img/B05793_05_03.jpg)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
- en: 'As you can see, mothers, compared to fathers, are younger: the average age
    of mothers was 28 versus over 44 for fathers. A good indication (at least for
    some of the infants) was that many mothers quit smoking while being pregnant;
    it is horrifying, though, that there still were some that continued smoking.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: 'For the categorical variables, we will calculate the frequencies of their values:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Here is what the results look like:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: '![Descriptive statistics](img/B05793_05_04.jpg)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
- en: 'Most of the deliveries happened in hospital (`BIRTH_PLACE` equal to `1`). Around
    550 deliveries happened at home: some intentionally (`''BIRTH_PLACE''` equal to
    `3`), and some not (`''BIRTH_PLACE''` equal to `4`).'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: Correlations
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Correlations help to identify collinear numeric features and handle them appropriately.
    Let''s check the correlations between our features:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The preceding code will calculate the correlation matrix and will print only
    those features that have a correlation coefficient greater than `0.5`: the `corrs
    > 0.5` part takes care of that.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s what we get:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: '![Correlations](img/B05793_05_05.jpg)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
- en: 'As you can see, the `''CIG_...''` features are highly correlated, so we can
    drop most of them. Since we want to predict the survival chances of an infant
    as soon as possible, we will keep only the `''CIG_1_TRI''`. Also, as expected,
    the weight features are also highly correlated and we will only keep the `''MOTHER_PRE_WEIGHT''`:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Statistical testing
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We cannot calculate correlations for the categorical features. However, we can
    run a Chi-square test to determine if there are significant differences.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s how you can do it using the `.chiSqTest(...)` method of `MLlib`:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: We loop through all the categorical variables and pivot them by the `'INFANT_ALIVE_AT_REPORT'`
    feature to get the counts. Next, we transform them into an RDD, so we can then
    convert them into a matrix using the `pyspark.mllib.linalg` module. The first
    parameter to the `.Matrices.dense(...)` method specifies the number of rows in
    the matrix; in our case, it is the length of distinct values of the categorical
    feature.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: 'The second parameter specifies the number of columns: we have two as our `''INFANT_ALIVE_AT_REPORT''`
    target variable has only two values.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: The last parameter is a list of values to be transformed into a matrix.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s an example that shows this more clearly:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The preceding code produces the following matrix:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: '![Statistical testing](img/B05793_05_06.jpg)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
- en: Once we have our counts in a matrix form, we can use the `.chiSqTest(...)` to
    calculate our test.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s what we get in return:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: '![Statistical testing](img/B05793_05_07.jpg)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
- en: Our tests reveal that all the features should be significantly different and
    should help us predict the chance of survival of an infant.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: Creating the final dataset
  id: totrans-112
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Therefore, it is time to create our final dataset that we will use to build
    our models. We will convert our DataFrame into an RDD of `LabeledPoints`.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: 'A `LabeledPoint` is a MLlib structure that is used to train the machine learning
    models. It consists of two attributes: `label` and `features`.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: The `label` is our target variable and `features` can be a NumPy `array`, `list`,
    `pyspark.mllib.linalg.SparseVector`, `pyspark.mllib.linalg.DenseVector`, or `scipy.sparse`
    column matrix.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: Creating an RDD of LabeledPoints
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before we build our final dataset, we first need to deal with one final obstacle:
    our `''BIRTH_PLACE''` feature is still a string. While any of the other categorical
    variables can be used as is (as they are now dummy variables), we will use a hashing
    trick to encode the `''BIRTH_PLACE''` feature:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: First, we create the hashing model. Our feature has seven levels, so we use
    as many features as that for the hashing trick. Next, we actually use the model
    to convert our `'BIRTH_PLACE'` feature into a `SparseVector`; such a data structure
    is preferred if your dataset has many columns but in a row only a few of them
    have non-zero values. We then combine all the features together and finally create
    a `LabeledPoint`.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: Splitting into training and testing
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before we move to the modeling stage, we need to split our dataset into two
    sets: one we''ll use for training and the other for testing. Luckily, RDDs have
    a handy method to do just that: `.randomSplit(...)`. The method takes a list of
    proportions that are to be used to randomly split the dataset.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is how it is done:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: That's it! Nothing more needs to be done.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: Predicting infant survival
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Finally, we can move to predicting the infants'' survival chances. In this
    section, we will build two models: a linear classifier—the logistic regression,
    and a non-linear one—a random forest. For the former one, we will use all the
    features at our disposal, whereas for the latter one, we will employ a `ChiSqSelector(...)`
    method to select the top four features.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: Logistic regression in MLlib
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Logistic regression is somewhat a benchmark to build any classification model.
    MLlib used to provide a logistic regression model estimated using a **stochastic
    gradient descent** (**SGD**) algorithm. This model has been deprecated in Spark
    2.0 in favor of the `LogisticRegressionWithLBFGS` model.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: The `LogisticRegressionWithLBFGS` model uses the **Limited-memory Broyden–Fletcher–Goldfarb–Shanno**
    (**BFGS**) optimization algorithm. It is a quasi-Newton method that approximates
    the BFGS algorithm.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-130
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'For those of you who are mathematically adept and interested in this, we suggest
    perusing this blog post that is a nice walk-through of the optimization algorithms:
    [http://aria42.com/blog/2014/12/understanding-lbfgs](http://aria42.com/blog/2014/12/understanding-lbfgs).'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we train the model on our data:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们在我们的数据上训练模型：
- en: '[PRE18]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Training the model is very simple: we just need to call the `.train(...)` method.
    The required parameters are the RDD with `LabeledPoints`; we also specified the
    number of `iterations` so it does not take too long to run.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 训练模型非常简单：我们只需要调用`.train(...)`方法。所需的参数是带有`LabeledPoints`的RDD；我们还指定了`iterations`的数量，这样它不会运行得太久。
- en: 'Having trained the model using the `births_train` dataset, let''s use the model
    to predict the classes for our testing set:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`births_train`数据集训练模型后，让我们使用该模型来预测测试集的类别：
- en: '[PRE19]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The preceding snippet creates an RDD where each element is a tuple, with the
    first element being the actual label and the second one, the model's prediction.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码片段创建了一个RDD，其中每个元素都是一个元组，第一个元素是实际标签，第二个元素是模型的预测。
- en: 'MLlib provides an evaluation metric for classification and regression. Let''s
    check how well or how bad our model performed:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: MLlib为分类和回归提供了评估指标。让我们检查一下我们的模型表现如何：
- en: '[PRE20]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Here''s what we got:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是我们的结果：
- en: '![Logistic regression in MLlib](img/B05793_05_08.jpg)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![MLlib中的逻辑回归](img/B05793_05_08.jpg)'
- en: The model performed reasonably well! The 85% area under the Precision-Recall
    curve indicates a good fit. In this case, we might be getting slightly more predicted
    deaths (true and false positives). In this case, this is actually a good thing
    as it would allow doctors to put the expectant mother and the infant under special
    care.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的表现相当不错！精确-召回曲线下的85%区域表示拟合良好。在这种情况下，我们可能会得到稍微更多的预测死亡（真实和假阳性）。在这种情况下，这实际上是一件好事，因为它可以让医生对预期母亲和婴儿进行特殊护理。
- en: The area under **Receiver-Operating Characteristic** (**ROC**) can be understood
    as a probability of the model ranking higher than a randomly chosen positive instance
    compared to a randomly chosen negative one. A 63% value can be thought of as acceptable.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '**接收者操作特征**（ROC）曲线下的面积可以理解为模型将随机选择的正实例排名高于随机选择的负实例的概率。63%的值可以被认为是可接受的。'
- en: Note
  id: totrans-144
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: For more on these metrics, we point interested readers to [http://stats.stackexchange.com/questions/7207/roc-vs-precision-and-recall-curves](http://stats.stackexchange.com/questions/7207/roc-vs-precision-and-recall-curves)
    and [http://gim.unmc.edu/dxtests/roc3.htm](http://gim.unmc.edu/dxtests/roc3.htm).
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 更多关于这些指标的信息，我们建议感兴趣的读者参考[http://stats.stackexchange.com/questions/7207/roc-vs-precision-and-recall-curves](http://stats.stackexchange.com/questions/7207/roc-vs-precision-and-recall-curves)和[http://gim.unmc.edu/dxtests/roc3.htm](http://gim.unmc.edu/dxtests/roc3.htm)。
- en: Selecting only the most predictable features
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 仅选择最可预测的特征
- en: Any model that uses less features to predict a class accurately should always
    be preferred to a more complex one. MLlib allows us to select the most predictable
    features using a Chi-Square selector.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 任何使用更少特征准确预测类别的模型都应该优先于更复杂的模型。MLlib允许我们使用卡方选择器选择最可预测的特征。
- en: 'Here''s how you do it:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是如何做到这一点的步骤：
- en: '[PRE21]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: We asked the selector to return the four most predictive features from the dataset
    and train the selector using the `births_train` dataset. We then used the model
    to extract only those features from our training and testing datasets.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要求选择器从数据集中返回四个最可预测的特征，并使用`births_train`数据集来训练选择器。然后我们使用模型从我们的训练和测试数据集中提取仅这些特征。
- en: The `.ChiSqSelector(...)` method can only be used for numerical features; categorical
    variables need to be either hashed or dummy coded before the selector can be used.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '`.ChiSqSelector(...)`方法只能用于数值特征；分类变量在使用选择器之前需要被哈希化或转换为虚拟变量。'
- en: Random forest in MLlib
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MLlib中的随机森林
- en: We are now ready to build the random forest model.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在准备好构建随机森林模型。
- en: 'The following code shows you how to do it:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码展示了如何实现：
- en: '[PRE22]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: The first parameter to the `.trainClassifier(...)` method specifies the training
    dataset. The `numClasses` one indicates how many classes our target variable has.
    As the third parameter, you can pass a dictionary where the key is the index of
    a categorical feature in our RDD and the value for the key indicates the number
    of levels that the categorical feature has. The `numTrees` specifies the number
    of trees to be in the forest. The next parameter tells the model to use all the
    features in our dataset instead of keeping only the most descriptive ones, while
    the last one specifies the seed for the stochastic part of the model.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '`.trainClassifier(...)` 方法的第一个参数指定了训练数据集。`numClasses` 参数表示我们的目标变量有多少个类别。作为第三个参数，您可以传递一个字典，其中键是我们RDD中分类特征的索引，而键的值表示分类特征有多少个级别。`numTrees`
    指定了森林中的树的数量。下一个参数告诉模型使用我们数据集中的所有特征，而不是只保留最具描述性的特征，而最后一个参数指定了模型随机部分的种子。'
- en: 'Let''s see how well our model did:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们的模型表现如何：
- en: '[PRE23]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Here are the results:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是结果：
- en: '![Random forest in MLlib](img/B05793_05_09.jpg)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![MLlib中的随机森林](img/B05793_05_09.jpg)'
- en: 'As you can see, the Random Forest model with fewer features performed even
    better than the logistic regression model. Let''s see how the logistic regression
    would perform with a reduced number of features:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，具有较少特征的随机森林模型甚至比逻辑回归模型表现更好。让我们看看逻辑回归在特征数量减少的情况下会如何表现：
- en: '[PRE24]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The results might surprise you:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 结果可能会让您感到惊讶：
- en: '![Random forest in MLlib](img/B05793_05_10.jpg)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
  zh: '![MLlib中的随机森林](img/B05793_05_10.jpg)'
- en: As you can see, both models can be simplified and still attain the same level
    of accuracy. Having said that, you should always opt for a model with fewer variables.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，这两个模型可以简化，同时仍然达到相同的准确度水平。话虽如此，您应该始终选择具有较少变量的模型。
- en: Summary
  id: totrans-166
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we looked at the capabilities of the `MLlib` package of PySpark.
    Even though the package is currently in a maintenance mode and is not actively
    being worked on, it is still good to know how to use it. Also, for now it is the
    only package available to train models while streaming data. We used `MLlib` to
    clean up, transform, and get familiar with the dataset of infant deaths. Using
    that knowledge we then successfully built two models that aimed at predicting
    the chance of infant survival given the information about its mother, father,
    and place of birth.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了PySpark的`MLlib`包的功能。尽管该包目前处于维护模式，并且没有积极开发，但了解如何使用它仍然是有益的。此外，目前它是唯一可用于在流数据时训练模型的包。我们使用`MLlib`清理、转换并熟悉婴儿死亡数据集。利用这些知识，我们成功构建了两个模型，旨在根据母亲、父亲和出生地信息预测婴儿存活的机会。
- en: In the next chapter, we will revisit the same problem, but using the newer package
    that is currently the Spark recommended package for machine learning.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将重新审视相同的问题，但使用目前Spark推荐的机器学习新包。
