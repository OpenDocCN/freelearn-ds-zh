<html><head></head><body><div><div><h1 id="_idParaDest-292"><a id="_idTextAnchor302"/>Appendix</h1>
		</div>
		<div><h1 id="_idParaDest-293"><a id="_idTextAnchor303"/>1. Introduction to Data Wrangling with Python</h1>
			<h2 id="_idParaDest-294"><a id="_idTextAnchor304"/>Activity 1.01: Handling Lists</h2>
			<p><strong class="bold">Solution:</strong></p>
			<p>These are the steps to complete this activity:</p>
			<ol>
				<li>Import the <code>random</code> library:<pre>import random</pre></li>
				<li>Use the <code>randint</code> method from the <code>random</code> library to create <code>100</code> random numbers:<pre>random_number_list = [random.randint(0, 100) \
                      for x in range(0, 100)]</pre></li>
				<li>Print <code>random_number_list</code>:<pre>random_number_list</pre><p>The sample output is as follows:</p><div><img src="img/B15780_01_20.jpg" alt="Figure 1.20: Section of output for random_number_list&#13;&#10;" width="608" height="468"/></div><p class="figure-caption">Figure 1.20: Section of output for random_number_list</p><p class="callout-heading">Note</p><p class="callout">The output is susceptible to change since we are generating random numbers.</p></li>
				<li>Create a <code>list_with_divisible_by_3</code> list from <code>random_number_list</code>, which will contain only numbers that are divisible by <code>3</code>:<pre>list_with_divisible_by_3 = [a for a in \
                            random_number_list if a % 3 == 0]
list_with_divisible_by_3</pre><p>The sample output is as follows:</p><div><img src="img/B15780_01_21.jpg" alt="Figure 1.21: Section of the output for random_number_list divisible by 3&#13;&#10;" width="541" height="361"/></div><p class="figure-caption">Figure 1.21: Section of the output for random_number_list divisible by 3</p></li>
				<li>Use the <code>len</code> function to measure the length of the first list and the second list, and store them in two different variables, <code>length_of_random_list</code> and <code>length_of_3_divisible_list</code>. Calculate the difference in length in a variable called <code>difference</code>:<pre>length_of_random_list = len(random_number_list)
length_of_3_divisible_list = len(list_with_divisible_by_3)
difference = length_of_random_list - length_of_3_divisible_list
difference</pre><p>The sample output is as follows:</p><pre>71</pre></li>
				<li>Combine the tasks we have performed so far and add a <code>for</code> loop to it. Run the loop 10 times and add the values of the difference variables to a list:<pre>NUMBER_OF_EXPERIMENTS = 10
difference_list = []
for i in range(0, NUMBER_OF_EXPERIMENTS):
    random_number_list = [random.randint(0, 100) \
                          for x in range(0, 100)]
    list_with_divisible_by_3 = [a for a in random_number_list \
                                if a % 3 == 0]
    
    length_of_random_list = len(random_number_list)
    length_of_3_divisible_list = len(list_with_divisible_by_3)
    difference = length_of_random_list \
                 - length_of_3_divisible_list
    difference_list.append(difference)
difference_list</pre><p>The sample output is as follows:</p><pre>[64, 61, 67, 60, 73, 66, 66, 75, 70, 61]</pre></li>
				<li>Then, calculate the arithmetic mean (common average) for the differences in the lengths that you have: <pre>avg_diff = sum(difference_list) / float(len(difference_list))
avg_diff</pre><p>The sample output is as follows:</p><pre>66.3</pre><p class="callout-heading">Note</p><p class="callout">The output is susceptible to change since we have used random numbers.</p><p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/30VMjt3">https://packt.live/30VMjt3</a>.</p><p class="callout">You can also run this example online at <a href="https://packt.live/3eh0JIb">https://packt.live/3eh0JIb</a>.</p></li>
			</ol>
			<p>With this, we have successfully completed our first activity. Let's move on to the next section, where we will discuss another type of data structure – <strong class="bold">sets</strong>. </p>
			<h2 id="_idParaDest-295"><a id="_idTextAnchor305"/>Activity 1.02: Analyzing a Multiline String and Generating the Unique Word Count</h2>
			<p><strong class="bold">Solution:</strong></p>
			<p>These are the steps to complete this activity:</p>
			<ol>
				<li value="1">Open a new Jupyter Notebook, create a string called <code>multiline_text</code>, and copy the text present in the first chapter of <em class="italic">Pride and Prejudice</em>.<p class="callout-heading">Note</p><p class="callout">Part of the first chapter of <em class="italic">Pride and Prejudice</em> by Jane Austen has been made available on this book's GitHub repository at <a href="https://packt.live/2N6ZGP6">https://packt.live/2N6ZGP6</a>.</p><p>Use <em class="italic">Ctrl</em> <em class="italic">+</em> <em class="italic">A</em> to select the entire text and then <em class="italic">Ctrl</em> <em class="italic">+</em> <em class="italic">C</em> to copy it and use <em class="italic">Ctrl + V</em> to paste the text you just copied into it:</p><div><img src="img/B15780_01_22.jpg" alt="Figure 1.22: Initializing the mutliline_text string&#13;&#10;" width="1182" height="544"/></div><p class="figure-caption">Figure 1.22: Initializing the mutliline_text string</p></li>
				<li>Find the type of the string using the <code>type</code> function:<pre>type(multiline_text)</pre><p>The output is as follows:</p><pre>str</pre></li>
				<li>Now, find the length of the string using the <code>len</code> function:<pre>len(multiline_text)</pre><p>The output is as follows:</p><pre>1228</pre></li>
				<li>Use string methods to get rid of all the new lines (<code>\n</code> or <code>\r</code>) and symbols. Remove all new lines by replacing them with the following: <pre>multiline_text = multiline_text.replace('\n', "")</pre></li>
				<li>Then, we will print and check the output:<pre>multiline_text</pre><p>The output is as follows:</p><div><img src="img/B15780_01_23.jpg" alt="Figure 1.23: The multiline_text string after removing the new lines&#13;&#10;" width="1183" height="326"/></div><p class="figure-caption">Figure 1.23: The multiline_text string after removing the new lines</p></li>
				<li>Remove the special characters and punctuation:<pre># remove special chars, punctuation etc.
cleaned_multiline_text = ""
for char in multiline_text:
    if char == " ":
        cleaned_multiline_text += char
    elif char.isalnum():  # using the isalnum() method of strings.
        cleaned_multiline_text += char
    else:
        cleaned_multiline_text += " "</pre></li>
				<li>Check the content of <code>cleaned_multiline_text</code>:<pre>cleaned_multiline_text</pre><p>The output is as follows:</p><div><img src="img/B15780_01_24.jpg" alt="Figure 1.24: The cleaned_multiline_text string&#13;&#10;" width="1181" height="305"/></div><p class="figure-caption">Figure 1.24: The cleaned_multiline_text string</p></li>
				<li>Generate a list of all the words from the cleaned string using the following command:<pre>list_of_words = cleaned_multiline_text.split()
list_of_words</pre><p>The section of the output is shown below:</p><div><img src="img/B15780_01_25.jpg" alt="Figure 1.25: The section of output displaying the list_of_words&#13;&#10;" width="557" height="422"/></div><p class="figure-caption">Figure 1.25: The section of output displaying the list_of_words</p></li>
				<li>Find the number of words:<pre>len(list_of_words)</pre><p>The output is <code>236</code>.</p></li>
				<li>Create a list from the list you just created, which includes only unique words:<pre>unique_words_as_dict = dict.fromkeys(list_of_words)
len(list(unique_words_as_dict.keys()))</pre><p>The output is <code>135</code>.</p></li>
				<li>Count the number of times each of the unique words appeared in the cleaned text:<pre>for word in list_of_words:
    if unique_words_as_dict[word] is None:
        unique_words_as_dict[word] = 1
    else:
        unique_words_as_dict[word] += 1
unique_words_as_dict</pre><p>The section of the output is shown below:</p><div><img src="img/B15780_01_26.jpg" alt="Figure 1.26: Section of output showing unique_words_as_dict&#13;&#10;" width="658" height="448"/></div><p class="figure-caption">Figure 1.26: Section of output showing unique_words_as_dict</p><p>You just created, step by step, a unique word counter using all the neat tricks that you've learned about in this chapter.</p></li>
				<li>Find the top 25 words from <code>unique_words_as_dict</code>:<pre>top_words = sorted(unique_words_as_dict.items(), \
                   key=lambda key_val_tuple: key_val_tuple[1], \
                   reverse=True)
top_words[:25]</pre><p>The output (partially shown) is as follows:</p><div><img src="img/B15780_01_27.jpg" alt="Figure 1.27: Top 25 unique words from multiline_text&#13;&#10;" width="656" height="352"/></div></li>
			</ol>
			<p class="figure-caption">Figure 1.27: Top 25 unique words from multiline_text</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/2ASNIWL">https://packt.live/2ASNIWL</a>.</p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/3dcIKkz">https://packt.live/3dcIKkz</a>.</p>
			<h1 id="_idParaDest-296"><a id="_idTextAnchor306"/>2. Advanced Operations on Built-In Data Structures</h1>
			<h2 id="_idParaDest-297"><a id="_idTextAnchor307"/>Activity<a id="_idTextAnchor308"/> 2.01: Permutation, Iterator, Lambda, and List</h2>
			<p><strong class="bold">Solution:</strong></p>
			<p>These are the detailed steps to solve this activity:</p>
			<ol>
				<li value="1">Look up the definition of <code>permutations</code> and <code>dropwhile</code> from <code>itertools</code>. There is a way to look up the definition of a function inside Jupyter itself. Just type the function name, followed by <em class="italic">?</em>, and press <em class="italic">Shift </em>+ <em class="italic">Enter</em>:<pre>from itertools import permutations, dropwhile
permutations?
dropwhile?</pre><p>You will see a long list of definitions after each <code>?</code>. We will skip it here.</p></li>
				<li>Write an expression to generate all the possible three-digit numbers using <code>1</code>, <code>2</code>, and <code>3</code>:<pre>permutations(range(3)) </pre><p>The output (which will vary in your case) is as follows:</p><pre>&lt;itertools.permutations at 0x7f6c6c077af0&gt;</pre></li>
				<li>Loop over the iterator expression you generated before. Use the <code>print</code> method to print each element returned by the iterator. Use <code>assert</code> and <code>isinstance</code> to make sure that the elements are tuples:<pre>for number_tuple in permutations(range(3)):
    print(number_tuple)
    assert isinstance(number_tuple, tuple) </pre><p>The output is as follows:</p><pre>(0, 1, 2)
(0, 2, 1)
(1, 0, 2)
(1, 2, 0)
(2, 0, 1)
(2, 1, 0)</pre></li>
				<li>Write the loop again. But this time, use <code>dropwhile</code> with a lambda expression to drop any leading zeros from the tuples. As an example, <code>(0, 1, 2)</code> will become <code>[0, 2]</code>. Also, cast the output of <code>dropwhile</code> to a list.<p>An extra task can be to check the actual type that <code>dropwhile</code> returns without casting:</p><pre>for number_tuple in permutations(range(3)):
    print(list(dropwhile(lambda x: x &lt;= 0, number_tuple))) </pre><p>The output is as follows:</p><pre>[1, 2]
[2, 1]
[1, 0, 2]
[1, 2, 0]
[2, 0, 1]
[2, 1, 0]</pre></li>
				<li>Write all the logic you wrote before, but this time write a separate function where you will be passing the list generated from <code>dropwhile</code>; the function will return the whole number contained in the list. As an example, if you pass <code>[1, 2]</code> to the function, it will return <code>12</code>. Make sure that the return type is indeed a number and not a string. Although this task can be achieved using other tricks, we require you to treat the incoming list as a stack in the function and generate the number there:<pre>import math
def convert_to_number(number_stack):
    final_number = 0
    for i in range(0, len(number_stack)):
        final_number += (number_stack.pop() \
                         * (math.pow(10, i)))
    return final_number
for number_tuple in permutations(range(3)):
    number_stack = list(dropwhile(lambda x: x &lt;= 0, number_tuple))
    print(convert_to_number(number_stack)) </pre><p>The output is as follows:</p><pre>12.0
21.0
102.0
120.0
201.0
210.0</pre><p class="callout-heading">Note</p><p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/37Gk9DT">https://packt.live/37Gk9DT</a>. </p><p class="callout">You can also run this example online at <a href="https://packt.live/3hEWt7f">https://packt.live/3hEWt7f</a>.</p></li>
			</ol>
			<h2 id="_idParaDest-298"><a id="_idTextAnchor309"/>Activity<a id="_idTextAnchor310"/> 2.02: Designing Your Own CSV Parser</h2>
			<p><strong class="bold">Solution:</strong></p>
			<p>These are the detailed steps to solve this activity:</p>
			<ol>
				<li value="1">Import <code>zip_longest</code> from <code>itertools</code>:<pre>from itertools import zip_longest </pre></li>
				<li>Define the <code>return_dict_from_csv_line</code> function so that it contains <code>header</code>, <code>line</code>, and <code>fillvalue</code> as <code>None</code>, and add it to a dictionary:<pre>def return_dict_from_csv_line(header, line):
    # Zip them
    zipped_line = zip_longest(header, line, fillvalue=None)
    # Use dict comprehension to generate the final dict
    ret_dict = {kv[0]: kv[1] for kv in zipped_line}
    return ret_dict </pre></li>
				<li>Open the accompanying <code>sales_record.csv</code> file using <code>r</code> mode inside a <code>with</code> block. First, check that it is opened, read the first line, and use string methods to generate a list of all the column names as follows:<pre>with open("<code>csv</code> file.</p></li>
				<li>When you read each line, pass that line to a function along with the list of the headers. The work of the function is to construct a dictionary out of these two and fill up the <code>key:values</code> variables. Keep in mind that a missing value should result in <code>None</code>:<pre>    first_line = fd.readline()
    header = first_line.replace("\n", "").split(",")
    for i, line in enumerate(fd):
        line = line.replace("\n", "").split(",")
        d = return_dict_from_csv_line(header, line)
        print(d)
        if i &gt; 10:
            break </pre><p>The output (partially shown) is as follows:</p><div><img src="img/B15780_02_15.jpg" alt="Figure 2.15: Section of output&#13;&#10;" width="610" height="171"/></div></li>
			</ol>
			<p class="figure-caption">Figure 2.15: Section of output</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/37FlVVK">https://packt.live/37FlVVK</a>. </p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/2YepGyb">https://packt.live/2YepGyb</a>.</p>
			<h1 id="_idParaDest-299"><a id="_idTextAnchor311"/>3. Introduction to NumPy, Pandas, and Matplotlib</h1>
			<h2 id="_idParaDest-300"><a id="_idTextAnchor312"/>Activity 3.01: Generating Statistics from a CSV File</h2>
			<p><strong class="bold">Solution:</strong></p>
			<p>These are the steps to complete this activity:</p>
			<ol>
				<li value="1">Load the necessary libraries:<pre>import numpy as np
import pandas as pd
import matplotlib.pyplot as plt</pre></li>
				<li>Read in the Boston Housing dataset (given as a <code>.csv</code> file) from the local directory:<pre>df=pd.read_csv("<strong class="bold">../datasets/Boston_housing.csv</strong>")</pre><p class="callout-heading">Note</p><p class="callout">Don't forget to change the path of the dataset (highlighted) based on where it is saved on your system.</p></li>
				<li>Check the first 10 records:<pre>df.head(10)</pre><p>The output is as follows:</p><div><img src="img/B15780_03_30.jpg" alt="Figure 3.30: Output displaying the first 10 records&#13;&#10;" width="816" height="363"/></div><p class="figure-caption">Figure 3.30: Output displaying the first 10 records</p></li>
				<li>Find the total number of records:<pre>df.shape</pre><p>The output is as follows:</p><pre>(506, 14)</pre></li>
				<li>Create a smaller DataFrame with columns that do not include <code>CHAS</code>, <code>NOX</code>, <code>B</code>, and <code>LSTAT</code>:<pre>df1=df[['CRIM','ZN','INDUS',\
        'RM','AGE','DIS','RAD',\
        'TAX','PTRATIO','PRICE']]</pre></li>
				<li>Check the last <code>7</code> records of the new DataFrame you just created:<pre>df1.tail(7)</pre><p>The output is as follows:</p><div><img src="img/B15780_03_31.jpg" alt="Figure 3.31: Last seven records of the DataFrame&#13;&#10;" width="916" height="358"/></div><p class="figure-caption">Figure 3.31: Last seven records of the DataFrame</p></li>
				<li>Plot histograms of all the variables (columns) in the new DataFrame by using a for loop:<pre>for c in df1.columns:
    plt.title("Plot of "+c,fontsize=15)
    plt.hist(df1[c],bins=20)
    plt.show()</pre><p>The output is as follows:</p><div><img src="img/B15780_03_32.jpg" alt="Figure 3.32: Partial plot of all variables using a for loop&#13;&#10;" width="513" height="493"/></div><p class="figure-caption">Figure 3.32: Partial plot of all variables using a for loop</p><p class="callout-heading">Note</p><p class="callout">To take a look at all the plots, head over to the following link: <a href="https://packt.live/2AGb95F">https://packt.live/2AGb95F</a>.</p><p>Crime rate could be an indicator of house price (people don't want to live in high-crime areas). In some cases, having multiple charts together can allow for the easy analysis of a variety of variables. In the preceding group of charts, we can see several unique spikes in the data: <code>INDIUS</code>, <code>TAX</code>, and <code>RAD</code>. With further exploratory analysis, we can find out more. We might want to plot one variable against another after looking at the preceding group of charts. </p></li>
				<li>Create a scatter plot of crime rate versus price:<pre>plt.scatter(df1['CRIM'], df1['PRICE'])
plt.show()</pre><p>The output is as follows:</p><div><img src="img/B15780_03_33.jpg" alt="Figure 3.33: Scatter plot of crime rate versus price&#13;&#10;" width="482" height="252"/></div><p class="figure-caption">Figure 3.33: Scatter plot of crime rate versus price</p><p>We can understand this relationship better if we plot <code>log10(crime)</code> versus <code>price</code>.</p></li>
				<li>Create a plot of <code>log10(crime)</code> versus price:<pre>plt.scatter(np.log10(df1['CRIM']),df1['PRICE'], c='red')
plt.title("Crime rate (Log) vs. Price plot", fontsize=18)
plt.xlabel("Log of Crime rate",fontsize=15)
plt.ylabel("Price",fontsize=15)
plt.grid(True)
plt.show()</pre><p>The output is as follows:</p><div><img src="img/B15780_03_34.jpg" alt="Figure 3.34: Scatter plot of crime rate (Log) versus price&#13;&#10;" width="535" height="287"/></div><p class="figure-caption">Figure 3.34: Scatter plot of crime rate (Log) versus price</p></li>
				<li>Calculate the mean rooms per dwelling:<pre>df1['RM'].mean()</pre><p>The output is as follows:</p><pre>6.284634387351788</pre></li>
				<li>Calculate the median age:<pre>df1['AGE'].median()</pre><p>The output is as follows:</p><pre>77.5</pre></li>
				<li>Calculate the average (mean) distances to five Boston employment centers:<pre>df1['DIS'].mean()</pre><p>The output is as follows:</p><pre>3.795042687747034</pre></li>
				<li>Calculate the price of the housing that's less than <code>20</code>:<pre>low_price=df1['PRICE']&lt;20
print(low_price)</pre><p>The output is as follows:</p><div><img src="img/B15780_03_35.jpg" alt="Figure 3.35: Output of low_price&#13;&#10;" width="880" height="436"/></div><p class="figure-caption">Figure 3.35: Output of low_price</p><p>This creates a Boolean array of <code>True, False</code>, <code>True = 1</code>, and <code>False = 0</code>. If you take an average of this NumPy array, you will know how many <code>1(True)</code> values are there.</p></li>
				<li>Calculate the mean of this array:<pre># That many houses are priced below 20,000. 
# So that is the answer. 
low_price.mean()</pre><p>The output is:</p><pre>0.4150197628458498</pre></li>
				<li>Calculate the percentage of houses with a low price (<code>&lt; $20,000</code>):<pre># You can convert that into percentage
# Do this by multiplying with 100
pcnt=low_price.mean()*100
print("\nPercentage of house with &lt;20,000 price is: ", pcnt)</pre><p>The output is as follows:</p><pre>Percentage of house with &lt;20,000 price is: 41.50197628458498</pre><p class="callout-heading">Note</p><p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/2AGb95F">https://packt.live/2AGb95F</a>. </p><p class="callout">You can also run this example online at <a href="https://packt.live/2YT3Hfg">https://packt.live/2YT3Hfg</a>.</p></li>
			</ol>
			<h1 id="_idParaDest-301"><a id="_idTextAnchor313"/>4. A Deep Dive into Data Wrangling with Python</h1>
			<h2 id="_idParaDest-302"><a id="_idTextAnchor314"/>Activity 4.01: <a id="_idTextAnchor315"/>Working with the Adult Income Dataset (UCI)</h2>
			<p><strong class="bold">Solution:</strong></p>
			<p>These are the steps to complete this activity:</p>
			<ol>
				<li value="1">Load the necessary libraries:<pre>import numpy as np
import pandas as pd
import matplotlib.pyplot as plt</pre></li>
				<li>Read in the Adult Income Dataset (given as a <code>.csv</code> file) from the local directory and check the first five records:<pre>df = pd.read_csv("<strong class="bold">../datasets/adult_income_data.csv</strong>")
df.head()</pre><p class="callout-heading">Note</p><p class="callout">The highlighted path must be changed based on the location of the file on your system. </p><p>The output is as follows:</p><div><img src="img/B15780_04_76.jpg" alt="Figure 4.76: DataFrame displaying the first five records from the .csv file&#13;&#10;" width="914" height="328"/></div><p class="figure-caption">Figure 4.76: DataFrame displaying the first five records from the .csv file</p></li>
				<li>Create a script that will read a text file line by line and extract the first line, which is the header of the <code>.csv</code> file:<pre>names = []
with open('<strong class="bold">../datasets/adult_income_names.txt</strong>','r') as f:
    for line in f:
        f.readline()
        var=line.split(":")[0]
        names.append(var)
names</pre><p class="callout-heading">Note</p><p class="callout">The highlighted path must be changed based on the location of the file on your system. </p><p>The output is as follows:</p><div><img src="img/B15780_04_77.jpg" alt="Figure 4.77: Names of the columns in the database" width="521" height="281"/></div><p class="figure-caption">Figure 4.77: Names of the columns in the database</p></li>
				<li>Add a name of <code>Income</code> for the response variable (last column) to the dataset by using the <code>append</code> command:<pre>names.append('Income')</pre></li>
				<li>Read the new file again using the following command:<pre>df = pd.read_csv("<strong class="bold">../datasets/adult_income_data.csv</strong>", names=names)
df.head()</pre><p class="callout-heading">Note</p><p class="callout">The highlighted path must be changed based on the location of the file on your system. </p><p>The output is as follows:</p><div><img src="img/B15780_04_78.jpg" alt="Figure 4.78: DataFrame with the income column added&#13;&#10;" width="761" height="475"/></div><p class="figure-caption">Figure 4.78: DataFrame with the income column added</p></li>
				<li>Use the <code>describe</code> command to get the statistical summary of the dataset:<pre>df.describe()</pre><p>The output is as follows:</p><div><img src="img/B15780_04_79.jpg" alt="Figure 4.79: Statistical summary of the dataset&#13;&#10;" width="931" height="367"/></div><p class="figure-caption">Figure 4.79: Statistical summary of the dataset</p><p>Note that only a small number of columns are included. Many variables in the dataset have multiple factors or classes.</p></li>
				<li>Make a list of all the variables in the classes by using the following command:<pre># Make a list of all variables with classes
vars_class = ['workclass','education','marital-status',\
              'occupation','relationship','sex','native-country']</pre></li>
				<li>Create a loop to count and print them by using the following command:<pre>for v in vars_class:
    classes=df[v].unique()
    num_classes = df[v].nunique()
    print("There are {} classes in the \"{}\" column. "\
          "They are: {}".format(num_classes,v,classes))
    print("-"*100)</pre><p>The output (partially shown) is as follows:</p><div><img src="img/B15780_04_80.jpg" alt="Figure 4.80: Output of different factors or classes" width="787" height="211"/></div><p class="figure-caption">Figure 4.80: Output of different factors or classes</p></li>
				<li>Find the missing values by using the following command:<pre>df.isnull().sum()</pre><p>The output is as follows:</p><div><img src="img/B15780_04_81.jpg" alt="Figure 4.81: Finding the missing values&#13;&#10;" width="551" height="323"/></div><p class="figure-caption">Figure 4.81: Finding the missing values</p></li>
				<li>Create a DataFrame with only <code>age</code>, <code>education</code>, and <code>occupation</code> by using subsetting:<pre>df_subset = df[['age','education', 'occupation']]
df_subset.head()</pre><p>The output is as follows:</p><div><img src="img/B15780_04_82.jpg" alt="Figure 4.82: Subset of the DataFrame&#13;&#10;" width="633" height="225"/></div><p class="figure-caption">Figure 4.82: Subset of the DataFrame</p></li>
				<li>Plot a histogram of age with a bin size of 20:<pre>df_subset['age'].hist(bins=20)</pre><p>The output is as follows:</p><div><img src="img/B15780_04_83.jpg" alt="Figure 4.83: Histogram of age with a bin size of 20&#13;&#10;" width="485" height="252"/></div><p class="figure-caption">Figure 4.83: Histogram of age with a bin size of 20</p></li>
				<li>Plot box plots for <code>age</code> grouped by <code>education</code> (use a long figure size of <code>25x10</code> and make the <code>x</code> ticks font size <code>15</code>):<pre>df_subset.boxplot(column='age',by='education',figsize=(25,10))
plt.xticks(fontsize=15)
plt.xlabel("Education",fontsize=20)
plt.show()</pre><p>The output is as follows:</p><div><img src="img/B15780_04_84.jpg" alt="Figure 4.84: Box plot of age grouped by education&#13;&#10;" width="1482" height="656"/></div><p class="figure-caption">Figure 4.84: Box plot of age grouped by education</p><p>Before doing any further operations, we need to use the <code>apply</code> method we learned about in this chapter. It turns out that when reading the dataset from the CSV file, all the strings came with a whitespace character in front of them. So, we need to remove that whitespace from all the strings.</p></li>
				<li>Create a function to strip the whitespace characters:<pre>def strip_whitespace(s):
    return s.strip()</pre></li>
				<li>Use the <code>apply</code> method to apply this function to all the columns with string values, create a new column, copy the values from this new column to the old column, and drop the new column. This is the preferred method so that you don't accidentally delete valuable data. Most of the time, you will need to create a new column with a desired operation and then copy it back to the old column if necessary. Ignore any warning messages that are printed:<pre># Education column
df_subset['education_stripped'] = df['education']\
                                  .apply(strip_whitespace)
df_subset['education'] = df_subset['education_stripped']
df_subset.drop(labels = ['education_stripped'],\
               axis=1,inplace=True)
# Occupation column
df_subset['occupation_stripped'] = df['occupation']\
                                   .apply(strip_whitespace)
df_subset['occupation'] = df_subset['occupation_stripped']
df_subset.drop(labels = ['occupation_stripped'],\
               axis=1,inplace=True)</pre><p>This is the sample warning message, which you should ignore:</p><div><img src="img/B15780_04_85.jpg" alt="Figure 4.85: Warning message to be ignored&#13;&#10;" width="1061" height="257"/></div><p class="figure-caption">Figure 4.85: Warning message to be ignored</p></li>
				<li>Find the number of people who are aged between <code>30</code> and <code>50</code> (inclusive) by using the following command:<pre># Conditional clauses and join them by &amp; (AND) 
df_filtered=df_subset[(df_subset['age']&gt;=30) \
                      &amp; (df_subset['age']&lt;=50)]</pre></li>
				<li>Check the contents of the new dataset:<pre>df_filtered.head()</pre><p>The output is as follows:</p><div><img src="img/B15780_04_86.jpg" alt="Figure 4.86: Contents of the new DataFrame&#13;&#10;" width="817" height="267"/></div><p class="figure-caption">Figure 4.86: Contents of the new DataFrame</p></li>
				<li>Find the <code>shape</code> of the filtered DataFrame and specify the index of the tuple as 0 to return the first element:<pre>answer_1=df_filtered.shape[0]
answer_1</pre><p>The output is as follows:</p><pre>16390</pre></li>
				<li>Print the number of people aged between <code>30</code> and <code>50</code> using the following command:<pre>print("There are {} people of age between 30 and 50 "\
      "in this dataset.".format(answer_1))</pre><p>The output is as follows:</p><pre>There are 16390 people of age between 30 and 50 in this dataset.</pre></li>
				<li>Group by <code>occupation</code> and show the summary statistics of age. Find which profession has the oldest workers on average and which profession has its largest share of the workforce above the <code>75th</code> percentile:<pre>df_subset.groupby('occupation').describe()['age']</pre><p>The output is as follows:</p><div><img src="img/B15780_04_87.jpg" alt="Figure 4.87: DataFrame with data grouped by age and education&#13;&#10;" width="503" height="386"/></div><p class="figure-caption">Figure 4.87: DataFrame with data grouped by age and education</p><p>The code returns <code>79 rows × 1 columns</code>.</p></li>
				<li>Use subset and <code>groupBy</code> to find the outliers:<pre>occupation_stats=df_subset.groupby('occupation').describe()['age']</pre></li>
				<li>Plot the values on a bar chart:<pre>plt.figure(figsize=(15,8))
plt.barh(y=occupation_stats.index, \
         width=occupation_stats['count'])
plt.yticks(fontsize=13)
plt.show()</pre><p>The output is as follows:</p><div><img src="img/B15780_04_88.jpg" alt="Figure 4.88: Bar chart displaying occupation statistics&#13;&#10;" width="981" height="469"/></div><p class="figure-caption">Figure 4.88: Bar chart displaying occupation statistics</p><p>Is there a particular occupation group that has very low representation? Perhaps we should remove those pieces of data because, with very low data, the group won't be useful in analysis. Just by looking at <em class="italic">Figure 4.89</em>, you should be able to see that the <code>Armed-Forces</code> group has only got a <code>9</code> count, that is, <code>9</code> data points. But how can we detect this? By plotting the count column in a bar chart. Note how the first argument to the <code>barh</code> function is the index of the DataFrame, which is the summary stats of the occupation groups. We can see that the <code>Armed-Forces</code> group has almost no data. This activity teaches you that, sometimes, the outlier is not just a value, but can be a whole group. The data of this group is fine, but it is too small to be useful for any analysis. So, it can be treated as an outlier in this case. But always use your business knowledge and engineering judgment for such outlier detection and how to process them. We will now practice merging two datasets using a common key.</p></li>
				<li>Suppose you are given two datasets where the common key is <code>occupation</code>. First, create two such disjoint datasets by taking random samples from the full dataset and then try merging. Include at least two other columns, along with the common key column for each dataset. Notice how the resulting dataset, after merging, may have more data points than either of the two starting datasets if your common key is not unique:<pre>df_1 = df[['age','workclass','occupation']]\
          .sample(5,random_state=101)
df_1.head()</pre><p>The output is as follows:</p><div><img src="img/B15780_04_89.jpg" alt="Figure 4.89: Output after merging the common keys&#13;&#10;" width="833" height="267"/></div><pre>df_2 = df[['education','occupation']].sample(5,random_state=101)
df_2.head()</pre><p>The output is as follows:</p><div><img src="img/B15780_04_90.jpg" alt="Figure 4.90: Output after merging the common keys&#13;&#10;" width="930" height="267"/></div><p class="figure-caption">Figure 4.90: Output after merging the common keys</p></li>
				<li>Merge the two datasets together:<pre>df_merged = pd.merge(df_1,df_2,on='occupation',\
                     how='inner').drop_duplicates()
df_merged</pre><p>The output is as follows:</p><div><img src="img/B15780_04_91.jpg" alt="Figure 4.91: Output of distinct occupation values&#13;&#10;" width="801" height="267"/></div></li>
			</ol>
			<p class="figure-caption">Figure 4.91: Output of distinct occupation values</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/37IamwR">https://packt.live/37IamwR</a>. </p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/2YhuF1j">https://packt.live/2YhuF1j</a>.</p>
			<h1 id="_idParaDest-303"><a id="_idTextAnchor316"/>5. Getting Comfortable with Different Kinds of Data Sources</h1>
			<h2 id="_idParaDest-304"><a id="_idTextAnchor317"/>Activity 5.01: Reading Tabular <a id="_idTextAnchor318"/>Data from a Web Page and Creating DataFrames</h2>
			<p><strong class="bold">Solution:</strong></p>
			<p>These are the steps to complete this activity:</p>
			<ol>
				<li value="1">Import <code>BeautifulSoup</code> and load the data by using the following command:<pre>from bs4 import BeautifulSoup
import pandas as pd</pre></li>
				<li>Open the Wikipedia file by using the following command:<pre>fd = open("<strong class="bold">../datasets/List of countries by GDP (nominal) "</strong>\
<strong class="bold">          "- Wikipedia.htm</strong>", "r", encoding = "utf-8")
soup = BeautifulSoup(fd)
fd.close()</pre><p class="callout-heading">Note</p><p class="callout">Don't forget to change the path of the dataset (highlighted) based on its location on your system</p></li>
				<li>Calculate the tables by using the following command:<pre>all_tables = soup.find_all("table")
print("Total number of tables are {} ".format(len(all_tables)))</pre><p>There are nine tables in total.</p></li>
				<li>Find the right table using the <code>class</code> attribute by using the following command:<pre>data_table = soup.find("table", {"class": '"wikitable"|}'})
print(type(data_table))</pre><p>The output is as follows:</p><pre>&lt;class 'bs4.element.Tag'&gt;</pre></li>
				<li>Separate the source and the actual data by using the following command:<pre>sources = data_table.tbody.findAll('tr', recursive=False)[0]
sources_list = [td for td in sources.findAll('td')]
print(len(sources_list))</pre><p>The output is as follows:</p><pre>3</pre></li>
				<li>Use the <code>findAll</code> function to find the data from the <code>body</code> tag of <code>data_table</code> using the following command:<pre>data = data_table.tbody.findAll('tr', recursive=False)[1]\
                                .findAll('td', recursive=False)</pre></li>
				<li>Use the <code>findAll</code> function to find the data from the <code>data_table</code> <code>td</code> tag by using the following command:<pre>data_tables = []
for td in data:
    data_tables.append(td.findAll('table'))</pre></li>
				<li>Find the length of <code>data_tables</code> by using the following command:<pre>len(data_tables)</pre><p>The output is as follows:</p><pre>3</pre></li>
				<li>Check how to get the source names by using the following command:<pre>source_names = [source.findAll('a')[0].getText() \
                for source in sources_list]
print(source_names)</pre><p>The output is as follows:</p><pre>['International Monetary Fund', 'World Bank', 'United Nations']</pre></li>
				<li>Separate the header and data for the first source:<pre>header1 = [th.getText().strip() for th in \
           data_tables[0][0].findAll('thead')[0].findAll('th')]
header1</pre><p>The output is as follows:</p><pre>['Rank', 'Country', 'GDP(US$MM)']</pre></li>
				<li>Find the rows from <code>data_tables</code> using <code>findAll</code>:<pre>rows1 = data_tables[0][0].findAll('tbody')[0].findAll('tr')[1:]</pre></li>
				<li>Find the data from <code>rows1</code> using the <code>strip</code> function for each <code>td</code> tag:<pre>data_rows1 = [[td.get_text().strip() for td in \
               tr.findAll('td')] for tr in rows1]</pre></li>
				<li>Find the DataFrame:<pre>df1 = pd.DataFrame(data_rows1, columns=header1)
df1.head()</pre><p>The output is as follows:</p><div><img src="img/B15780_05_35.jpg" alt="Figure 5.35: DataFrame created from the web page&#13;&#10;" width="1508" height="537"/></div><p class="figure-caption">Figure 5.35: DataFrame created from the web page</p></li>
				<li>Do the same for the other two sources by using the following command:<pre>header2 = [th.getText().strip() for th in data_tables[1][0]\
           .findAll('thead')[0].findAll('th')]
header2</pre><p>The output is as follows:</p><pre>['Rank', 'Country', 'GDP(US$MM)']</pre></li>
				<li>Find the rows from <code>data_tables</code> using <code>findAll</code> by using the following command:<pre>rows2 = data_tables[1][0].findAll('tbody')[0].findAll('tr')</pre></li>
				<li>Define <code>find_right_text</code> using the <code>strip</code> function by using the following command:<pre>def find_right_text(i, td):
    if i == 0:
        return td.getText().strip()
    elif i == 1:
        return td.getText().strip()
    else:
        index = td.text.find("♠")
        return td.text[index+1:].strip()</pre></li>
				<li>Find the rows from <code>data_rows</code> using <code>find_right_text</code> by using the following command:<pre>data_rows2 = [[find_right_text(i, td) for i, td in \
               enumerate(tr.findAll('td'))] for tr in rows2]</pre></li>
				<li>Calculate the <code>df2</code> DataFrame by using the following command:<pre>df2 = pd.DataFrame(data_rows2, columns=header2)
df2.head()</pre><p>The output is as follows:</p><div><img src="img/B15780_05_36.jpg" alt="Figure 5.36: Output of the DataFrame&#13;&#10;" width="1470" height="541"/></div><p class="figure-caption">Figure 5.36: Output of the DataFrame</p></li>
				<li>Now, perform the same operations for the third DataFrame by using the following command:<pre>header3 = [th.getText().strip() for th in data_tables[2][0]\
           .findAll('thead')[0].findAll('th')]
header3</pre><p>The output is as follows:</p><pre>['Rank', 'Country', 'GDP(US$MM)']</pre></li>
				<li>Find the rows from <code>data_tables</code> using <code>findAll</code> by using the following command:<pre>rows3 = data_tables[2][0].findAll('tbody')[0].findAll('tr')</pre></li>
				<li>Find the rows from <code>data_rows3</code> by using <code>find_right_text</code>:<pre>data_rows3 = [[find_right_text(i, td) for i, td in \
               enumerate(tr.findAll('td'))] for tr in rows2]</pre></li>
				<li>Calculate the <code>df3</code> DataFrame by using the following command:<pre>df3 = pd.DataFrame(data_rows3, columns=header3)
df3.head()</pre><p>The output is as follows:</p><div><img src="img/B15780_05_37.jpg" alt="Figure 5.37: The third DataFrame&#13;&#10;" width="1478" height="535"/></div></li>
			</ol>
			<p class="figure-caption">Figure 5.37: The third DataFrame</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/2NaCrDB">https://packt.live/2NaCrDB</a>.</p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/2YRAukP">https://packt.live/2YRAukP</a>.</p>
			<h1 id="_idParaDest-305"><a id="_idTextAnchor319"/>6. Learning the Hidden Secrets of Data Wrangling</h1>
			<h2 id="_idParaDest-306"><a id="_idTextAnchor320"/>Activity 6.01: Handling Outliers a<a id="_idTextAnchor321"/>nd Missing Data</h2>
			<p><strong class="bold">Solution:</strong></p>
			<p>The steps to completing this activity are as follows:</p>
			<p class="callout-heading">Note</p>
			<p class="callout">The dataset to be used for this activity can be found at <a href="https://packt.live/2YajrLJ">https://packt.live/2YajrLJ</a>.</p>
			<ol>
				<li value="1">Load the data:<pre>import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline</pre></li>
				<li>Read the <code>.csv</code> file:<pre>df = pd.read_csv("<strong class="bold">../datasets/visit_data.csv</strong>")</pre><p class="callout-heading">Note</p><p class="callout">Don't forget to change the path (highlighted) based on where the CSV file is saved on your system.</p></li>
				<li>Print the data from the DataFrame:<pre>df.head()</pre><p>The output is as follows:</p><div><img src="img/B15780_06_11.jpg" alt="Figure 6.11: The contents of the CSV file&#13;&#10;" width="1008" height="268"/></div><p class="figure-caption">Figure 6.11: The contents of the CSV file</p><p>As we can see, there is data where some values are missing, and if we examine this, we will see some outliers.</p></li>
				<li>Check for duplicates by using the following command:<pre>print("First name is duplicated - {}"\
      .format(any(df.first_name.duplicated())))
print("Last name is duplicated - {}"\
      .format(any(df.last_name.duplicated())))
print("Email is duplicated - {}"\
      .format(any(df.email.duplicated())))</pre><p>The output is as follows:</p><pre>First name is duplicated - True
Last name is duplicated - True
Email is duplicated - False</pre><p>There are duplicates in both the first and last names, which is normal. However, as we can see, there are no duplicates in email. That's good.</p></li>
				<li>Check whether any essential column contains <code>NaN</code>:<pre>"""
Notice that we have different ways to 
format boolean values for the % operator
"""
print("The column Email contains NaN - %r " % \
      df.email.isnull().values.any())
print("The column IP Address contains NaN - %s " % \
      df.ip_address.isnull().values.any())
print("The column Visit contains NaN - %s " % \
      df.visit.isnull().values.any())</pre><p>The output is as follows:</p><pre>The column Email contains NaN - False 
The column IP Address contains NaN - False 
The column Visit contains NaN - True </pre><p>The <code>Visit</code> column contains some <code>NaN</code> values. Given that the final task at hand will probably be predicting the number of visits, we cannot do anything with rows that do not have that information. They are a type of outlier. Let's get rid of them.</p></li>
				<li>Get rid of the outliers:<pre>"""
There are various ways to do this. This is just one way. We encourage you   to explore other ways. But before that we need to store the previous size of the data set and we  will compare it with the new size
"""
size_prev = df.shape
df = df[np.isfinite(df['visit'])] 
#This is an inplace operation.
# After this operation the original DataFrame is lost.
size_after = df.shape</pre></li>
				<li>Report the size difference:<pre># Notice how parameterized format is used.
# Then, the indexing is working inside the quote marks
print("The size of previous data was - {prev[0]} rows and "\
      "the size of the new one is - {after[0]} rows"\
      .format(prev=size_prev, after=size_after))</pre><p>The output is as follows:</p><pre>The size of previous data was - 1000 rows and the size of the new one is - 974 rows</pre></li>
				<li>Plot a box plot to find whether the data has outliers:<pre>plt.boxplot(df.visit, notch=True)</pre><p>The box plot is as follows:</p><p> </p><div><img src="img/B15780_06_12.jpg" alt="Figure 6.12: Box plot using the data&#13;&#10;" width="1030" height="630"/></div><p class="figure-caption">Figure 6.12: Box plot using the data</p><p>As we can see, we have data in this column in the interval (<code>0, 3000</code>). However, the main concentration of the data is between <code>~700</code> and <code>~2300</code>. </p></li>
				<li>Get rid of values beyond <code>2900</code> and below <code>100</code> – these are outliers for us. We need to get rid of them:<pre>df1 = df[(df['visit'] &lt;= 2900) &amp; (df['visit'] &gt;= 100)]
# Notice the  powerful &amp; operator
"""
Here we abuse the fact the 
number of variable can be greater 
than the number of replacement targets
"""
print("After getting rid of outliers the new size of the data "\
      "is - {}".format(*df1.shape))</pre><p>The output is as follows:</p><pre>After getting rid of outliers the new size of the data is - 923</pre><p class="callout-heading">Note</p><p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/2AFcSbn">https://packt.live/2AFcSbn</a>.</p><p class="callout">You can also run this example online at <a href="https://packt.live/3fAL9qY">https://packt.live/3fAL9qY</a></p></li>
			</ol>
			<h1 id="_idParaDest-307"><a id="_idTextAnchor322"/>7. Advanced Web Scraping and Data Gathering</h1>
			<h2 id="_idParaDest-308"><a id="_idTextAnchor323"/>Activity 7.01: Extracting the Top 100 e-books from Gutenberg</h2>
			<p><strong class="bold">Solution:</strong></p>
			<p>These are the steps to complete this activity:</p>
			<ol>
				<li value="1">Import the necessary libraries, including regex and <code>BeautifulSoup</code>:<pre>import urllib.request, urllib.parse, urllib.error
import requests
from bs4 import BeautifulSoup
import ssl
import re</pre></li>
				<li>Read the HTML from the URL:<pre>top100url = 'https://www.gutenberg.org/browse/scores/top'
response = requests.get(top100url)</pre></li>
				<li>Write a small function to check the status of the web request:<pre>def status_check(r):
    if r.status_code==200:
        print("Success!")
        return 1
    else:
        print("Failed!")
        return -1</pre></li>
				<li>Check the status of response:<pre>status_check(response)</pre><p>The output is as follows:</p><pre>Success!
1</pre></li>
				<li>Decode the response and pass it on to <code>BeautifulSoup</code> for HTML parsing:<pre>contents = response.content.decode(response.encoding)
soup = BeautifulSoup(contents, 'html.parser')</pre></li>
				<li>Find all the href tags and store them in the list of links. <pre># Empty list to hold all the http links in the HTML page
lst_links=[]
# Find all href tags and store them in the list of links
for link in soup.find_all('a'):
    #print(link.get('href'))
    lst_links.append(link.get('href'))</pre></li>
				<li>Check what the list looks like – print the first 30 elements:<pre>lst_links[:30]</pre><p>The output (partially shown) is as follows:</p><pre>['/wiki/Main_Page',
 '/catalog/',
 '/ebooks/',
 '/browse/recent/last1',
 '/browse/scores/top',
 '/wiki/Gutenberg:Offline_Catalogs',
 '/catalog/world/mybookmarks',
 '/wiki/Main_Page',
'https://www.paypal.com/xclick/business=donate%40gutenberg.org&amp;item_name=Donation+to+Project+Gutenberg',
 '/wiki/Gutenberg:Project_Gutenberg_Needs_Your_Donation',
 'http://www.ibiblio.org',
 'http://www.pgdp.net/',
 'pretty-pictures',
 '#books-last1',
 '#authors-last1',
 '#books-last7',
 '#authors-last7',
 '#books-last30',
 '#authors-last30',
 '/ebooks/1342',
 '/ebooks/84',
 '/ebooks/1080',
 '/ebooks/46',
 '/ebooks/219',
 '/ebooks/2542',
 '/ebooks/98',
 '/ebooks/345',
 '/ebooks/2701',
 '/ebooks/844',
 '/ebooks/11']</pre></li>
				<li>Use a regular expression to find the numeric digits in these links. These are the file numbers for the top 100 books. Initialize the empty list to hold the file numbers:<pre>booknum=[]</pre><p>Numbers 19 to 118 in the original list of links have the top 100 eBooks' numbers. </p></li>
				<li>Loop over the appropriate range and use a regex to find the numeric digits in the link (<code>href</code>) string. Use the <code>findall()</code> method:<pre>for i in range(19,119):
    link=lst_links[i]
    link=link.strip()
    """
    Regular expression to find the numeric digits in the link (href) string
    """
    n=re.findall('[0-9]+',link)
    if len(n)==1:
        # Append the filenumber casted as integer
        booknum.append(int(n[0]))</pre></li>
				<li>Print the file numbers:<pre>print("\nThe file numbers for the top 100 ebooks",\
      "on Gutenberg are shown below\n"+"-"*70)
print(booknum)</pre><p>The output is as follows:</p><pre>The file numbers for the top 100 ebooks on Gutenberg are shown below
----------------------------------------------------------------------
[1342, 84, 1080, 46, 219, 2542, 98, 345, 2701, 844, 11, 5200, 
43, 16328, 76, 74, 1952, 6130, 2591, 1661, 41, 174, 23, 1260, 
1497, 408, 3207, 1400, 30254, 58271, 1232, 25344, 58269, 158, 
44881, 1322, 205, 2554, 1184, 2600, 120, 16, 58276, 5740, 34901, 
28054, 829, 33, 2814, 4300, 100, 55, 160, 1404, 786, 58267, 3600, 
19942, 8800, 514, 244, 2500, 2852, 135, 768, 58263, 1251, 3825, 
779, 58262, 203, 730, 20203, 35, 1250, 45, 161, 30360, 7370, 
58274, 209, 27827, 58256, 33283, 4363, 375, 996, 58270, 521, 
58268, 36, 815, 1934, 3296, 58279, 105, 2148, 932, 1064, 13415]</pre><p class="callout-heading">Note</p><p class="callout">Since the list of top 100 books is frequently updated, the output you get will vary.</p><p>What does the <code>soup</code> object's text look like?</p></li>
				<li> Use the <code>.text</code> method and print only the first 2,000 characters (do not print the whole thing as it is too long).<p>You will notice a lot of empty spaces/blanks here and there. Ignore them. They are part of the HTML page's markup and its whimsical nature:</p><pre>print(soup.text[:2000])</pre><p>The output is as follows:</p><pre>if (top != self) {
         top.location.replace (http://www.gutenberg.org);
         alert ('Project Gutenberg is a FREE service with NO membership required. If you paid somebody else to get here, make them give you your money back!');
         }
    Top 100 - Project Gutenberg
Online Book Catalog
 Book  Search
-- Recent  Books
-- Top  100
-- Offline Catalogs
-- My Bookmarks
Main Page
…
Pretty Pictures
Top 100 EBooks yesterday —
  Top 100 Authors yesterday —
  Top 100 EBooks last 7 days —
  Top 100 Authors last 7 days —
  Top 100 EBooks last 30 days —
  Top 100 Authors last 30 days
Top 100 EBooks yesterday
Pride and Prejudice by Jane Austen (1826)
Frankenstein; Or, The Modern Prometheus by Mary Wollstonecraft Shelley (1367)
A Modest Proposal by Jonathan Swift (1020)
A Christmas Carol in Prose; Being a Ghost Story of Christmas by Charles Dickens (953)
Heart of Darkness by Joseph Conrad (887)
Et dukkehjem. English by Henrik Ibsen (761)
A Tale of Two Cities by Charles Dickens (741)
Dracula by Bram Stoker (732)
Moby Dick; Or, The Whale by Herman Melville (651)
The Importance of Being Earnest: A Trivial Comedy for Serious People by Oscar Wilde (646)
Alice's Adventures in Wonderland by Lewis Carrol</pre></li>
				<li>Search the extracted text (using regex) from the <code>soup</code> object to find the names of the top 100 eBooks (yesterday's ranking):<pre>lst_titles_temp=[]</pre></li>
				<li>Create a starting index. It should point at the text Top 100 Ebooks yesterday. Use the <code>splitlines</code> method of <code>soup.text</code>. It splits the lines of the text of the <code>soup</code> object:<pre>start_idx=soup.text.splitlines().index('Top 100 EBooks yesterday')</pre><p class="callout-heading">Note</p><p class="callout">Since the list of top 100 books is frequently updated, the output you get will vary.</p></li>
				<li>Run the <code>for</code> loop from <code>1-100</code> to add the strings of the next <code>100</code> lines to this temporary list. <code>splitlines</code> method:<pre>for i in range(100):
    lst_titles_temp.append(soup.text.splitlines()[start_idx+2+i])</pre></li>
				<li>Use regex to extract only text from the name strings and append them to an empty list. Use <code>match</code> and <code>span</code> to find the indices and use them:<pre>lst_titles=[]
for i in range(100):
    id1,id2=re.match('^[a-zA-Z ]*',lst_titles_temp[i]).span()
    lst_titles.append(lst_titles_temp[i][id1:id2])</pre></li>
				<li>Print the list of titles:<pre>for l in lst_titles:
    print(l)</pre><p>The partial output is as follows:</p><pre>Pride and Prejudice by Jane Austen 
Frankenstein
A Modest Proposal by Jonathan Swift 
A Christmas Carol in Prose
Heart of Darkness by Joseph Conrad 
Et dukkehjem
A Tale of Two Cities by Charles Dickens 
Dracula by Bram Stoker 
Moby Dick
The Importance of Being Earnest
Alice
Metamorphosis by Franz Kafka 
The Strange Case of Dr
Beowulf
…
The Russian Army and the Japanese War
Calculus Made Easy by Silvanus P
Beyond Good and Evil by Friedrich Wilhelm Nietzsche 
An Occurrence at Owl Creek Bridge by Ambrose Bierce 
Don Quixote by Miguel de Cervantes Saavedra 
Blue Jackets by Edward Greey 
The Life and Adventures of Robinson Crusoe by Daniel Defoe 
The Waterloo Campaign 
The War of the Worlds by H
Democracy in America 
Songs of Innocence
The Confessions of St
Modern French Masters by Marie Van Vorst 
Persuasion by Jane Austen 
The Works of Edgar Allan Poe 
The Fall of the House of Usher by Edgar Allan Poe 
The Masque of the Red Death by Edgar Allan Poe 
The Lady with the Dog and Other Stories by Anton Pavlovich Chekhov</pre><p class="callout-heading">Note</p><p class="callout">Since the list of top 100 books is frequently updated, the output you get will vary.</p></li>
			</ol>
			<p>Here, we have seen how we can use web scraping and parsing using a mix of <code>BeautifulSoup</code> and regex to find information from very untidy and vast source data. These are some essential steps that you will have to perform on a daily basis when you are dealing with data wrangling.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/2BltmFo">https://packt.live/2BltmFo</a>.</p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/37FdLwD">https://packt.live/37FdLwD</a>.</p>
			<h2 id="_idParaDest-309"><a id="_idTextAnchor324"/>Activity 7.02: Building Your Own Mov<a id="_idTextAnchor325"/>ie Database by Reading an API</h2>
			<p><strong class="bold">SOLUTION</strong></p>
			<p class="callout-heading">Note</p>
			<p class="callout">Before you begin, ensure that you modify the <code>APIkeys.json</code> file and add your secret API key there. Link to the file: <a href="https://packt.live/2CmIpze">https://packt.live/2CmIpze</a>.</p>
			<p>These are the steps to complete this activity:</p>
			<ol>
				<li value="1">Import <code>urllib.request</code>, <code>urllib.parse</code>, <code>urllib.error</code>, and <code>json</code>:<pre>import urllib.request, urllib.parse, urllib.error
import json</pre></li>
				<li>Load the secret API key (you have to get one from the OMDb website and use that; it has a daily API key limit of 1,000) from a JSON file, stored in the same folder, into a variable, by using <code>json.loads()</code>: <p class="callout-heading">Note</p><p class="callout">The following cell will not be executed in the solution notebook because the author cannot give out their private API key.</p><p>The students/users will need to obtain a key and store it in a JSON file. We are calling this file <code>APIkeys.json</code>. </p></li>
				<li>Open the <code>APIkeys.json</code> file by using the following command:<pre>with open('APIkeys.json') as f:
    keys = json.load(f)
    omdbapi = keys['OMDBapi']</pre><p>The final URL to be passed should look like this: <a href="http://www.omdbapi.com/?t=movie_name&amp;apikey=secretapikey">http://www.omdbapi.com/?t=movie_name&amp;apikey=secretapikey</a>.</p></li>
				<li>Assign the OMDb portal (<a href="http://www.omdbapi.com/?">http://www.omdbapi.com/?</a>) as a string to a variable called <code>serviceurl</code> by using the following command:<pre>serviceurl = 'http://www.omdbapi.com/?'</pre></li>
				<li>Create a variable called <code>apikey</code> with the last portion of the URL (<code>&amp;apikey=secretapikey</code>), where <code>secretapikey</code> is your own API key. The movie name portion is <code>t=movie_name</code>, and it will be addressed later:<pre>apikey = '&amp;apikey='+omdbapi</pre></li>
				<li>Write a utility function called <code>print_json</code> to print the movie data from a JSON file (which we will get from the portal). Here are the keys of a JSON file: <code>'Title', 'Year', 'Rated', 'Released', 'Runtime', 'Genre', 'Director', 'Writer', 'Actors', 'Plot', 'Language','Country', 'Awards', 'Ratings', 'Metascore', 'imdbRating', 'imdbVotes', and 'imdbID'</code>:<pre>def print_json(json_data):
    list_keys = ['Title', 'Year', 'Rated', 'Released',\
                 'Runtime', 'Genre', 'Director', 'Writer', \
                 'Actors', 'Plot', 'Language', 'Country', \
                 'Awards', 'Ratings','Metascore', 'imdbRating', \
                 'imdbVotes', 'imdbID']
    print("-"*50)
    for k in list_keys:
        if k in list(json_data.keys()):
            print(f"{k}: {json_data[k]}")
    print("-"*50)</pre></li>
				<li>Write a utility function to download a poster of the movie based on the information from the JSON dataset and save it in your local folder. Use the <code>os</code> module. The poster data is stored in the JSON key Poster. You may want to split the name of the Poster file and extract the file extension only. Let's say that the extension is <code>.jpg</code>. We could later join this extension to the movie name and create a filename such as <code>movie.jpg</code>. Use the <code>open</code> Python command open to open a file and write the poster data. Close the file after you're done. This function may not return anything. It just saves the poster data as an image file:<pre>def save_poster(json_data):
    import os
    title = json_data['Title']
    poster_url = json_data['Poster']
    """
    Splits the poster url by '.' and 
    picks up the last string as file extension
    """
    poster_file_extension=poster_url.split('.')[-1]
    # Reads the image file from web
    poster_data = urllib.request.urlopen(poster_url).read()
    savelocation=os.getcwd()+'\\'+'Posters'+'\\'
    """ 
    Creates new directory if the directory does not exist.
    Otherwise, just use the existing path.
    """
    if not os.path.isdir(savelocation):
        os.mkdir(savelocation)
    filename=savelocation+str(title)\
             +'.'+poster_file_extension
    f=open(filename,'wb')
    f.write(poster_data)
    f.close()</pre></li>
				<li>Write a utility function called <code>search_movie</code> to search a movie by its name, print the downloaded JSON data (use the <code>print_json</code> function for this), and save the movie poster in the local folder (use the <code>save_poster</code> function for this). Use a try-except loop for this, that is, try to connect to the web portal. If successful, proceed, but if not (that is, if an exception is raised), then just print an error message. Use the previously created variables, <code>serviceurl</code> and <code>apikey</code>. You have to pass on a dictionary with a key, t, and the movie name as the corresponding value to the <code>urllib.parse.urlencode</code> function and then add the <code>serviceurl</code> and <code>apikey</code> variables to the output of the function to construct the full URL. This URL will be used to access the data. The JSON data has a key called Response. If it is True, that means that the read was successful. Check this before processing the data. If it was not successful, then print the JSON key Error, which will contain the appropriate error message that's returned by the movie database:<pre>def search_movie(title):
    try:
        url = serviceurl \
              + urllib.parse.urlencode({'t':str(title)})+apikey
        print(f'Retrieving the data of "{title}" now... ')
        print(url)
        uh = urllib.request.urlopen(url)
        data = uh.read()
        json_data=json.loads(data)
        if json_data['Response']=='True':
            print_json(json_data)
            """
            Asks user whether to download the poster of the movie
            """
            if json_data['Poster']!='N/A':
                save_poster(json_data)
            else:
                print("Error encountered: ", json_data['Error'])
    except urllib.error.URLError as e:
        print(f"ERROR: {e.reason}")</pre></li>
				<li>Test the <code>search_movie</code> function by entering <code>Titanic</code>:<pre>search_movie("Titanic")</pre><p>The following is the retrieved data for Titanic:</p><pre>http://www.omdbapi.com/?t=Titanic&amp;apikey=<strong class="bold">&lt;your api key&gt;</strong> 
--------------------------------------------------
Title: Titanic
Year: 1997
Rated: PG-13
Released: 19 Dec 1997
Runtime: 194 min
Genre: Drama, Romance
Director: James Cameron
Writer: James Cameron
Actors: Leonardo DiCaprio, Kate Winslet, Billy Zane, Kathy Bates
Plot: A seventeen-year-old aristocrat falls in love with a kind but poor artist aboard the luxurious, ill-fated R.M.S. Titanic.
Language: English, Swedish
Country: USA
Awards: Won 11 Oscars. Another 111 wins &amp; 77 nominations.
Ratings: [{'Source': 'Internet Movie Database', 'Value': '7.8/10'}, {'Source': 'Rotten Tomatoes', 'Value': '89%'}, {'Source': 'Metacritic', 'Value': '75/100'}]
Metascore: 75
imdbRating: 7.8
imdbVotes: 913,780
imdbID: tt0120338
--------------------------------------------------</pre></li>
				<li>Test the <code>search_movie</code> function by entering <code>Random_error</code> (obviously, this will not be found, and you should be able to check whether your error-catching code is working properly):<pre>search_movie("Random_error")</pre><p>Retrieve the data of <code>Random_error</code>:</p><pre>Retrieving the data of "Random_error" now...
http://www.omdbapi.com/?t=Random_error&amp;apikey=<strong class="bold">&lt;your api key&gt; </strong>
Error encountered: Movie not found!</pre><p class="callout-heading">Note</p><p class="callout">In the last two steps, we've not shown the private API key (highlighted) for security reasons.</p><p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/3hLJvoy">https://packt.live/3hLJvoy</a>.</p><p class="callout">You can also run this example online at <a href="https://packt.live/3efkDTZ">https://packt.live/3efkDTZ</a>.</p></li>
			</ol>
			<h1 id="_idParaDest-310"><a id="_idTextAnchor326"/>8. RDBMS and SQL</h1>
			<h2 id="_idParaDest-311"><a id="_idTextAnchor327"/>Activity 8.01: Retrieving Data Accurately from Databases</h2>
			<p><strong class="bold">Solution:</strong></p>
			<p>These are the steps to complete this activity:</p>
			<ol>
				<li value="1">Connect to the supplied <code>petsdb</code> database:<pre>import sqlite3
conn = sqlite3.connect("petsdb")</pre></li>
				<li>Write a function to check whether the connection has been successful:<pre># a tiny function to make sure the connection is successful
def is_opened(conn):
    try:
        conn.execute("SELECT * FROM persons LIMIT 1")
        return True
    except sqlite3.ProgrammingError as e:
        print("Connection closed {}".format(e))
        return False
print(is_opened(conn))</pre><p>The output is as follows:</p><pre>True</pre></li>
				<li>Close the connection:<pre>conn.close()</pre></li>
				<li>Check whether the connection is open or closed:<pre>print(is_opened(conn))</pre><p>The output is as follows:</p><pre>Connection closed Cannot operate on a closed database.
False</pre></li>
				<li>Connect to the <code>petsdb</code> database:<pre>conn = sqlite3.connect("petsdb")
c = conn.cursor()</pre></li>
				<li>Find out the different age groups in the persons table. Execute the following command:<pre>for ppl, age in c.execute("SELECT count(*), \
                          age FROM persons GROUP BY age"):
    print("We have {} people aged {}".format(ppl, age))</pre><p>The output is as follows:</p><div><img src="img/B15780_08_13.jpg" alt="Figure 8.13: Section of output grouped by age&#13;&#10;" width="554" height="432"/></div><p class="figure-caption">Figure 8.13: Section of output grouped by age</p></li>
				<li>To find out which age group has the maximum number of people, execute the following command:<pre>for ppl, age in c.execute("SELECT count(*), age FROM persons \
<a id="_idTextAnchor328"/>                          GROUP BY age ORDER BY count(*)DESC"):
    print("The highest number of people is {} and "\
          "came from {} age group".format(ppl, age))
    break</pre><p>The output is as follows:</p><pre>The highest number of people is 5 and came from 73 age group</pre></li>
				<li>To find out how many people do not have a full name (the last name is blank/null), execute the following command:<pre>res = c.execute("SELECT count(*) FROM persons \
                WHERE last_name IS null")
for row in res:
    print(row)</pre><p>The output is as follows:</p><pre>(60,)</pre></li>
				<li>To find out how many people have more than one pet, execute the following command:<pre>res = c.execute("SELECT count(*) FROM \
                (SELECT count(owner_id) FROM pets \
                 GROUP BY owner_id HAVING count(owner_id) &gt;1)")
for row in res:
    print("{} people have more than one pets".format(row[0]))</pre><p>The output is as follows:</p><pre>43 People have more than one pets</pre></li>
				<li>To find out how many pets have received treatment, execute the following command:<pre>res = c.execute("SELECT count(*) FROM pets \
                WHERE treatment_done=1")
for row in res:
    print(row)</pre><p>The output is as follows:</p><pre>(36,)</pre></li>
				<li>To find out how many pets have received treatment and the type of pet is known, execute the following command:<pre>res = c.execute("SELECT count(*) FROM pets \
                WHERE treatment_done=1 AND pet_type IS NOT null")
for row in res:
    print(row)</pre><p>The output is as follows:</p><pre>(16,)</pre></li>
				<li>To find out how many pets are from the city called <code>east port</code>, execute the following command:<pre>res = c.execute("SELECT count(*) FROM pets \
                JOIN persons ON pets.owner_id = persons.id \
                WHERE persons.city='east port'")
for row in res:
    print(row)</pre><p>The output is as follows:</p><pre>(49,)</pre></li>
				<li>To find out how many pets are from the city called <code>east port</code> and who received treatment, execute the following command:<pre>res = c.execute("SELECT count(*) FROM pets \
                JOIN persons ON pets.owner_id = \
                persons.id WHERE persons.city='east port' \
                AND pets.treatment_done=1")
for row in res:
    print(row)</pre><p>The output is as follows:</p><pre>(11,)</pre><p class="callout-heading">Note</p><p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/3derN9D">https://packt.live/3derN9D</a>.</p><p class="callout">You can also run this example online at <a href="https://packt.live/2ASWYKi">https://packt.live/2ASWYKi</a>.</p></li>
			</ol>
			<h1 id="_idParaDest-312"><a id="_idTextAnchor329"/>9. Applications in Business Use Cases and Conclusion of the Course</h1>
			<h2 id="_idParaDest-313"><a id="_idTextAnchor330"/>Activity 9.01: Data Wrangling Task – <a id="_idTextAnchor331"/>Fixing UN Data</h2>
			<p><strong class="bold">Solution:</strong></p>
			<p>These are the steps to complete this activity:</p>
			<ol>
				<li value="1">Import the required libraries:<pre>import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')</pre></li>
				<li>Save the URL of the dataset (highlighted) and use the pandas <code>read_csv</code> method to directly pass this link and create a DataFrame:<pre>education_data_link="<strong class="bold">http://data.un.org/_Docs/SYB/CSV/"</strong>\
<strong class="bold">                    "SYB61_T07_Education.csv</strong>"
df1 = pd.read_csv(education_data_link)</pre></li>
				<li>Print the data in the DataFrame:<pre>df1.head()</pre><p>The output (partially shown) is as follows:</p><div><img src="img/B15780_09_7.jpg" alt="Figure 9.7: Partial DataFrame from the UN data&#13;&#10;" width="808" height="478"/></div><p class="figure-caption">Figure 9.7: Partial DataFrame from the UN data</p></li>
				<li>As the first row does not contain useful information, use the <code>skiprows</code> parameter to remove the first row:<pre>df1 = pd.read_csv(education_data_link,skiprows=1)</pre></li>
				<li>Print the data in the DataFrame:<pre>df1.head()</pre><p>The output is as follows:</p><div><img src="img/B15780_09_8.jpg" alt="Figure 9.8: Partial  DataFrame after removing the first row&#13;&#10;" width="767" height="466"/></div><p class="figure-caption">Figure 9.8: Partial  DataFrame after removing the first row</p></li>
				<li>Drop the <code>Region/Country/Area</code> and <code>Source</code> columns as they will not be very helpful:<pre>df2 = df1.drop(['Region/Country/Area','Source'],axis=1)</pre></li>
				<li>Assign the following names as the columns of the DataFrame: <code>['Region/Country/Area','Year','Data','Value','Footnotes']</code><pre>df2.columns=['Region/Country/Area','Year','Data',\
             'Enrollments (Thousands)','Footnotes']</pre></li>
				<li>Print the data in the DataFrame:<pre>df2.head()</pre><p>The output is as follows:</p><div><img src="img/B15780_09_9.jpg" alt="Figure 9.9: DataFrame after dropping the Region/Country/Area and Source columns&#13;&#10;" width="817" height="184"/></div><p class="figure-caption">Figure 9.9: DataFrame after dropping the Region/Country/Area and Source columns</p></li>
				<li>Check how many unique values the <code>Footnotes</code> column contains:<pre>df2['Footnotes'].unique()</pre><p>The output is as follows:</p><div><img src="img/B15780_09_10.jpg" alt="Figure 9.10: Unique values of the Footnotes column&#13;&#10;" width="1098" height="72"/></div><p class="figure-caption">Figure 9.10: Unique values of the Footnotes column</p></li>
				<li>Convert the <code>Value</code> column data into a numeric one for further processing:<pre>type(df2['Enrollments (Thousands)'][0])</pre><p>The output is as follows:</p><pre>str</pre></li>
				<li>Create a utility function to convert the strings in the <code>Value</code> column into floating-point numbers:<pre>def to_numeric(val):
    """
    Converts a given string (with one or more commas) to a numeric value
    """
    if ',' not in str(val):
        result = float(val)
    else:
        val=str(val)
        val=''.join(str(val).split(','))
        result=float(val)
    return result</pre></li>
				<li>Use the <code>apply</code> method to apply this function to the <code>Value</code> column data:<pre>df2['Enrollments (Thousands)']=df2['Enrollments (Thousands)']\
                               .apply(to_numeric)</pre></li>
				<li>Print the unique types of data in the <code>Data</code> column:<pre>df2['Data'].unique()</pre><p>The output is as follows:</p><div><img src="img/B15780_09_11.jpg" alt="Figure 9.11: Unique values in a column&#13;&#10;" width="663" height="188"/></div><p class="figure-caption">Figure 9.11: Unique values in a column</p></li>
				<li>Create three DataFrames by filtering and selecting them from the original DataFrame:<p><code>df_primary</code>: Only students enrolled in primary education (thousands)</p><p><code>df_secondary</code>: Only students enrolled in secondary education (thousands)</p><p><code>df_tertiary</code>: Only students enrolled in tertiary education (thousands):</p><pre>df_primary = df2[df2['Data']=='Students enrolled in primary '\
                              'education (thousands)']
df_secondary = df2[df2['Data']=='Students enrolled in secondary '\
                                'education (thousands)']
df_tertiary = df2[df2['Data']=='Students enrolled in tertiary '\
                               'education (thousands)']</pre></li>
				<li>Compare them using bar charts of the primary students' enrollment of a low-income country and a high-income country:<pre>primary_enrollment_india = df_primary[df_primary\
                           ['Region/Country/Area']=='India']
primary_enrollment_USA = df_primary[df_primary\
                         ['Region/Country/Area']\
                         =='United States of America']</pre></li>
				<li>Print the <code>primary_enrollment_india</code> data:<pre>primary_enrollment_india</pre><p>The output is as follows:</p><div><img src="img/B15780_09_12.jpg" alt="Figure 9.12: Data for enrollment in primary education in India&#13;&#10;" width="824" height="175"/></div><p class="figure-caption">Figure 9.12: Data for enrollment in primary education in India</p></li>
				<li>Print the <code>primary_enrollment_USA</code> data:<pre>primary_enrollment_USA</pre><p>The output is as follows:</p><div><img src="img/B15780_09_13.jpg" alt="Figure 9.13: Data for enrollment in primary education in USA&#13;&#10;" width="831" height="157"/></div><p class="figure-caption">Figure 9.13: Data for enrollment in primary education in USA</p></li>
				<li>Plot the data for India:<pre>plt.figure(figsize=(8,4))
plt.bar(primary_enrollment_india['Year'],\
primary_enrollment_india['Enrollments (Thousands)'])
plt.title("Enrollment in primary education\nin India "\
          "(in thousands)",fontsize=16)
plt.grid(True)
plt.xticks(fontsize=14)
plt.yticks(fontsize=14)
plt.xlabel("Year", fontsize=15)
plt.show()</pre><p>The output is as follows:</p><div><img src="img/B15780_09_14.jpg" alt="Figure 9.14: Bar plot for enrollment in primary education in India&#13;&#10;" width="675" height="333"/></div><p class="figure-caption">Figure 9.14: Bar plot for enrollment in primary education in India</p></li>
				<li>Plot the data for the USA:<pre>plt.figure(figsize=(8,4))
plt.bar(primary_enrollment_USA['Year'],\
primary_enrollment_USA['Enrollments (Thousands)'])
plt.title("Enrollment in primary education\nin the "\
          "United States of America (in thousands)",fontsize=16)
plt.grid(True)
plt.xticks(fontsize=14)
plt.yticks(fontsize=14)
plt.xlabel("Year", fontsize=15)
plt.show()</pre><p>The output is as follows:</p><div><img src="img/B15780_09_15.jpg" alt="Figure 9.15: Bar plot for enrollment in primary education in the USA&#13;&#10;" width="709" height="335"/></div><p class="figure-caption">Figure 9.15: Bar plot for enrollment in primary education in the USA</p><p>As we can see, we have missing data. Now is the time to use <code>pandas</code> methods to do the data imputation. But to do that, we need to create a DataFrame with missing values inserted into it – that is, we need to append another DataFrame with missing values to the current DataFrame.</p></li>
				<li>Find the missing years:<pre>missing_years = [y for y in range(2004,2010)]\
                +[y for y in range(2011,2014)]</pre></li>
				<li>Print the value in the <code>missing_years</code> variable:<pre>missing_years</pre><p>The output is as follows:</p><pre>[2004, 2005, 2006, 2007, 2008, 2009, 2011, 2012, 2013]</pre></li>
				<li>Create a dictionary of values with <code>np.nan</code>. Note that there are nine missing data points, so we need to create a list with identical values repeated nine times:<pre>dict_missing = \
{'Region/Country/Area':['India']*9,\
 'Year':missing_years,\
 'Data':'Students enrolled in primary education(thousands)'*9,\
 'Enrollments (Thousands)':[np.nan]*9,'Footnotes':[np.nan]*9}</pre></li>
				<li>Create a DataFrame of missing values (from the preceding dictionary) that we can <code>append</code>:<pre>df_missing = pd.DataFrame(data=dict_missing)</pre></li>
				<li>Append the new DataFrames to the previously existing ones:<pre>primary_enrollment_india=primary_enrollment_india\
                         .append(df_missing,ignore_index=True,\
                                 sort=True)</pre></li>
				<li>Print the data in <code>primary_enrollment_india</code>:<pre>primary_enrollment_india</pre><p>The output is as follows:</p><div><img src="img/B15780_09_16.jpg" alt="Figure 9.16: Partial Data for enrollment in primary education in India after appending &#13;&#10;the data&#13;&#10;" width="869" height="225"/></div><p class="figure-caption">Figure 9.16: Partial Data for enrollment in primary education in India after appending the data</p></li>
				<li>Sort by <code>year</code> and reset the indices using <code>reset_index</code>. Use <code>inplace=True</code> to execute the changes on the DataFrame itself:<pre>primary_enrollment_india.sort_values(by='Year',inplace=True)
primary_enrollment_india.reset_index(inplace=True,drop=True)</pre></li>
				<li>Print the data in <code>primary_enrollment_india</code>:<pre>primary_enrollment_india</pre><p>The output is as follows:</p><div><img src="img/B15780_09_17.jpg" alt="Figure 9.17: Partial Data for enrollment in primary education in India after sorting the data&#13;&#10;" width="1108" height="521"/></div><p class="figure-caption">Figure 9.17: Partial Data for enrollment in primary education in India after sorting the data</p></li>
				<li>Use the <code>interpolate</code> method for linear interpolation. It fills all the <code>NaN</code> values with linearly interpolated values. Check out this link for more details about this method: <a href="http://pandas.pydata.org/pandas-docs/version/0.17/generated/pandas.DataFrame.interpolate.html">http://pandas.pydata.org/pandas-docs/version/0.17/generated/pandas.DataFrame.interpolate.html</a>:<pre>primary_enrollment_india.interpolate(inplace=True)</pre></li>
				<li>Print the data in <code>primary_enrollment_india</code>:<pre>primary_enrollment_india</pre><p>The output is as follows:</p><div><img src="img/B15780_09_18.jpg" alt="Figure 9.18: Data for enrollment in primary education in India after interpolating the data&#13;&#10;" width="867" height="288"/></div><p class="figure-caption">Figure 9.18: Data for enrollment in primary education in India after interpolating the data</p></li>
				<li>Plot the data:<pre>plt.figure(figsize=(8,4))
plt.bar(primary_enrollment_india['Year'],\
        primary_enrollment_india['Enrollments (Thousands)'])
plt.title("Enrollment in primary education\nin India "\
          "(in thousands)", fontsize=16)
plt.grid(True)
plt.xticks(fontsize=14)
plt.yticks(fontsize=14)
plt.xlabel("Year", fontsize=15)
plt.show()</pre><p>The output is as follows:</p><div><img src="img/B15780_09_19.jpg" alt="Figure 9.19: Bar plot for enrollment in primary education in India&#13;&#10;" width="612" height="307"/></div><p class="figure-caption">Figure 9.19: Bar plot for enrollment in primary education in India</p></li>
				<li>Repeat the same steps for the USA:<pre>missing_years = [2004]+[y for y in range(2006,2010)]\
                +[y for y in range(2011,2014)]+[2016]</pre></li>
				<li>Print the value in <code>missing_years</code>.<pre>missing_years</pre><p>The output is as follows:</p><pre>[2004, 2006, 2007, 2008, 2009, 2011, 2012, 2013, 2016]</pre></li>
				<li>Create <code>dict_missing</code>, as follows:<pre>dict_missing = \
{'Region/Country/Area':['United States of America']*9,\
 'Year':missing_years, \
 'Data':'Students enrolled in primary education (thousands)'*9, \
 'Value':[np.nan]*9,'Footnotes':[np.nan]*9}</pre></li>
				<li>Create the DataFrame for <code>df_missing</code>, as follows:<pre>df_missing = pd.DataFrame(data=dict_missing)</pre></li>
				<li>Append this to the <code>primary_enrollment_USA</code> variable, as follows:<pre>primary_enrollment_USA=primary_enrollment_USA\
                       .append(df_missing,\
                               ignore_index =True,sort=True)</pre></li>
				<li>Sort the values in the <code>primary_enrollment_USA</code> variable, as follows:<pre>primary_enrollment_USA.sort_values(by='Year',inplace=True)</pre></li>
				<li>Reset the index of the <code>primary_enrollment_USA</code> variable, as follows:<pre>primary_enrollment_USA.reset_index(inplace=True,drop=True)</pre></li>
				<li>Interpolate the <code>primary_enrollment_USA</code> variable, as follows:<pre>primary_enrollment_USA.interpolate(inplace=True)</pre></li>
				<li>Print the <code>primary_enrollment_USA</code> variable:<pre>primary_enrollment_USA</pre><p>The output is as follows:</p><div><img src="img/B15780_09_20.jpg" alt="Figure 9.20: Data for enrollment in primary education in the USA after all operations have been completed&#13;&#10;" width="1037" height="435"/></div><p class="figure-caption">Figure 9.20: Data for enrollment in primary education in the USA after all operations have been completed</p></li>
				<li>Still, the first value is unfilled. We can use the <code>limit</code> and <code>limit_direction</code> parameters with the interpolate method to fill it in. How did we know this? By searching on Google and looking at the StackOverflow page. Always search for the solution to your problem and look for what has already been done and try to implement it:<pre>primary_enrollment_USA.interpolate(method='linear',\
                                   limit_direction='backward',\
                                   limit=1)</pre><p>The output is as follows:</p><div><img src="img/B15780_09_21.jpg" alt="Figure 9.21: Data for enrollment in primary education in the USA after limiting the data&#13;&#10;" width="1033" height="434"/></div><p class="figure-caption">Figure 9.21: Data for enrollment in primary education in the USA after limiting the data</p></li>
				<li>Print the data in <code>primary_enrollment_USA</code>:<pre>primary_enrollment_USA</pre><p>The output is as follows:</p><div><img src="img/B15780_09_22.jpg" alt="Figure 9.22: Data for enrollment in primary education in the USA&#13;&#10;" width="1036" height="435"/></div><p class="figure-caption">Figure 9.22: Data for enrollment in primary education in the USA</p></li>
				<li>Plot the data:<pre>plt.figure(figsize=(8,4))
plt.bar(primary_enrollment_USA['Year'],\
        primary_enrollment_USA['Enrollments (Thousands)'])
plt.title("Enrollment in primary education\nin the "\
          "United States of America (in thousands)",fontsize=16)
plt.grid(True)
plt.xticks(fontsize=14)
plt.yticks(fontsize=14)
plt.xlabel("Year", fontsize=15)
plt.show()</pre><p>The output is as follows:</p><div><img src="img/B15780_09_23.jpg" alt="Figure 9.23: Bar plot for enrollment in primary education in the USA&#13;&#10;" width="632" height="307"/></div></li>
			</ol>
			<p class="figure-caption">Figure 9.23: Bar plot for enrollment in primary education in the USA</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/3fyIqy8">https://packt.live/3fyIqy8</a>.</p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/3fQ0PXJ">https://packt.live/3fQ0PXJ</a>.</p>
			<h2 id="_idParaDest-314"><a id="_idTextAnchor332"/>Activity 9.02: Data Wrangling Task – Cleaning GDP Data<a id="_idTextAnchor333"/></h2>
			<p><strong class="bold">Solution:</strong></p>
			<p>These are the steps to complete this activity:</p>
			<ol>
				<li value="1">Import the required libraries:<pre>import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')</pre></li>
				<li><code>pandas</code> <code>read_csv</code> method will throw an error if we try to read it normally. Let's look at a step-by-step guide of how we can read useful information from it:<pre>df3=pd.read_csv("<code>error_bad_lines=False</code> option in this kind of situation.</p></li>
				<li>Read the India World Bank Information <code>.csv</code> file.<pre>df3=pd.read_csv("<strong class="bold">../datasets/India_World_Bank_Info.csv</strong>",\
                error_bad_lines=False)</pre><p>The output (partially shown) will be:</p><div><img src="img/B15780_09_24.jpg" alt="Figure 9.24: Partial output of the warnings.&#13;&#10;" width="1053" height="319"/></div><p class="figure-caption">Figure 9.24: Partial output of the warnings.</p></li>
				<li>Then, let's take a look at the contents of the DataFrame.<pre>df3.head(10)</pre><p>The output is as follows:</p><div><img src="img/B15780_09_25.jpg" alt="Figure 9.25: DataFrame from the India World Bank Information&#13;&#10;" width="541" height="311"/></div><p class="figure-caption">Figure 9.25: DataFrame from the India World Bank Information</p><p class="callout-heading">Note</p><p class="callout">At times, the output may not be found because there are three rows instead of the expected one row.</p></li>
				<li>Clearly, the delimiter in this file is tab (<code>\t</code>):<pre>df3=pd.read_csv("<strong class="bold">../datasets/India_World_Bank_Info.csv</strong>", \
                error_bad_lines=False,delimiter='\t')
df3.head(10)</pre><p>The output is as follows:</p><div><img src="img/B15780_09_26.jpg" alt="Figure 9.26: Partial output of the DataFrame from the India World Bank Information after using a delimiter&#13;&#10;" width="519" height="301"/></div><p class="figure-caption">Figure 9.26: Partial output of the DataFrame from the India World Bank Information after using a delimiter</p></li>
				<li>Use the <code>skiprows</code> parameter to skip the first four rows:<pre>df3=pd.read_csv("<strong class="bold">../datasets/India_World_Bank_Info.csv</strong>",\
                error_bad_lines=False,delimiter='\t',\
                skiprows=4)
df3.head(10)</pre><p>The output is as follows:</p><div><img src="img/B15780_09_27.jpg" alt="Figure 9.27: Partial output of DataFrame from the India World Bank Information after &#13;&#10;using skiprows&#13;&#10;" width="553" height="286"/></div><pre>df4=df3[df3['Indicator Name']=='GDP per capita (current US$)'].T
df4.head(10)</pre><p>The output is as follows:</p><div><img src="img/B15780_09_28.jpg" alt="Figure 9.28: DataFrame focusing on GDP per capita&#13;&#10;" width="587" height="348"/></div><p class="figure-caption">Figure 9.28: DataFrame focusing on GDP per capita</p></li>
				<li>There is no index, so let's use <code>reset_index</code> again:<pre>df4.reset_index(inplace=True)
df4.head(10)</pre><p>The output is as follows:</p><div><img src="img/B15780_09_29.jpg" alt="Figure 9.29: DataFrame from the India World Bank Information using reset_index&#13;&#10;" width="549" height="349"/></div><p class="figure-caption">Figure 9.29: DataFrame from the India World Bank Information using reset_index</p></li>
				<li>The first three rows aren't useful. We can redefine the DataFrame without them. Then, we re-index again:<pre>df4.drop([0,1,2],inplace=True)
df4.reset_index(inplace=True,drop=True)
df4.head(10)</pre><p>The output is as follows:</p><div><img src="img/B15780_09_30.jpg" alt="Figure 9.30: DataFrame from the India World Bank Information after dropping and resetting the index&#13;&#10;" width="562" height="349"/></div><p class="figure-caption">Figure 9.30: DataFrame from the India World Bank Information after dropping and resetting the index</p></li>
				<li>Let's rename the columns properly (this is necessary for merging, which we will look at shortly):<pre>df4.columns=['Year','GDP']
df4.head(10)</pre><p>The output is as follows:</p><div><img src="img/B15780_09_31.jpg" alt="Figure 9.31: DataFrame focusing on Year and GDP&#13;&#10;" width="547" height="348"/></div><p class="figure-caption">Figure 9.31: DataFrame focusing on Year and GDP</p></li>
				<li>It looks like we have GDP data from 1960 onward. However, we are only interested in <code>2003 – 2016</code>. Let's examine the last 20 rows:<pre>df4.tail(20)</pre><p>The output is as follows:</p><div><img src="img/B15780_09_32.jpg" alt="Figure 9.32: DataFrame from the India World Bank Information&#13;&#10;" width="579" height="412"/></div><p class="figure-caption">Figure 9.32: DataFrame from the India World Bank Information</p></li>
				<li>So, we should be good with rows <code>43-56</code>. Let's create a DataFrame called <code>df_gdp:</code><pre>df_gdp=df4.iloc[[i for i in range(43,57)]]
df_gdp</pre><p>The output is as follows:</p><div><img src="img/B15780_09_33.jpg" alt="Figure 9.33: DataFrame from the India World Bank Information&#13;&#10;" width="562" height="316"/></div><p class="figure-caption">Figure 9.33: DataFrame from the India World Bank Information</p></li>
				<li>We need to reset the index again (for merging):<pre>df_gdp.reset_index(inplace=True,drop=True)
df_gdp</pre><p>The output is as follows:</p><div><img src="img/B15780_09_34.jpg" alt="Figure 9.34: DataFrame from the India World Bank Information&#13;&#10;" width="564" height="317"/></div><p class="figure-caption">Figure 9.34: DataFrame from the India World Bank Information</p></li>
				<li>The year in this DataFrame is not of the <code>int</code> type. So, it will have problems merging with the education DataFrame:<pre>df_gdp['Year']</pre><p>The output is as follows:</p><div><img src="img/B15780_09_35.jpg" alt="Figure 9.35: DataFrame focusing on year&#13;&#10;" width="587" height="324"/></div><p class="figure-caption">Figure 9.35: DataFrame focusing on year</p></li>
				<li>Use the <code>apply</code> method with Python's built-in <code>int</code> function. Ignore any warnings that are thrown:<pre>df_gdp['Year']=df_gdp['Year'].apply(int)</pre><p class="callout-heading">Note</p><p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/3fyIqy8">https://packt.live/3fyIqy8</a>.</p><p class="callout">You can also run this example online at <a href="https://packt.live/3fQ0PXJ">https://packt.live/3fQ0PXJ</a>.</p></li>
			</ol>
			<h2 id="_idParaDest-315"><a id="_idTextAnchor334"/>Activity 9.03: Data Wrangling Task – Merging UN Data and GDP Data</h2>
			<p><strong class="bold"><a id="_idTextAnchor335"/>Solution:</strong></p>
			<p>These are the steps to complete this activity:</p>
			<ol>
				<li value="1">Now, merge the two DataFrames, that is, <code>primary_enrollment_india</code> and <code>df_gdp</code>, on the <code>Year</code> column:<pre>primary_enrollment_with_gdp=\
primary_enrollment_india.merge(df_gdp,on='Year')
primary_enrollment_with_gdp</pre><p>The output is as follows:</p><div><img src="img/B15780_09_36.jpg" alt="Figure 9.36: Merged data&#13;&#10;" width="1037" height="376"/></div><p class="figure-caption">Figure 9.36: Merged data</p></li>
				<li>Now, we can drop the <code>Data</code>, <code>Footnotes</code>, and <code>Region/Country/Area</code> columns:<pre>primary_enrollment_with_gdp.drop(['Data','Footnotes',\
                                  'Region/Country/Area'],\
                                  axis=1,inplace=True)
primary_enrollment_with_gdp</pre><p>The output is as follows:</p><div><img src="img/B15780_09_37.jpg" alt="Figure 9.37: Merged data after dropping the Data, Footnotes, &#13;&#10;and Region/Country/Area columns&#13;&#10;" width="743" height="550"/></div><p class="figure-caption">Figure 9.37: Merged data after dropping the Data, Footnotes, and Region/Country/Area columns</p></li>
				<li>Rearrange the columns for proper viewing and presentation to a data scientist:<pre>primary_enrollment_with_gdp = \
primary_enrollment_with_gdp[['Year',\
                             'Enrollments (Thousands)','GDP']]
primary_enrollment_with_gdp</pre><p>The output is as follows:</p><div><img src="img/B15780_09_38.jpg" alt="Figure 9.38: Merged data after rearranging the columns&#13;&#10;" width="738" height="549"/></div><p class="figure-caption">Figure 9.38: Merged data after rearranging the columns</p></li>
				<li>Plot the data:<pre>plt.figure(figsize=(8,5))
plt.title("India's GDP per capita vs primary education "\
          "enrollment",fontsize=16)
plt.scatter(primary_enrollment_with_gdp['GDP'],\
            primary_enrollment_with_gdp['Enrollments (Thousands)'],\
            edgecolor='k',color='orange',s=200)
plt.xlabel("GDP per capita (US $)",fontsize=15)
plt.ylabel("Primary enrollment (thousands)", fontsize=15)
plt.xticks(fontsize=14)
plt.yticks(fontsize=14)
plt.grid(True)
plt.show()</pre><p>The output is as follows:</p><div><img src="img/B15780_09_39.jpg" alt="Figure 9.39: Scatter plot of merged data&#13;&#10;" width="558" height="344"/></div></li>
			</ol>
			<p class="figure-caption">Figure 9.39: Scatter plot of merged data</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/3fyIqy8">https://packt.live/3fyIqy8</a>.</p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/3fQ0PXJ">https://packt.live/3fQ0PXJ</a>.</p>
			<h2 id="_idParaDest-316"><a id="_idTextAnchor336"/>Activity 9.04: Data Wrangling Task – Connecting the New Data to the Database</h2>
			<p><strong class="bold">Solution:</strong></p>
			<p>These are the steps to complete this activity:</p>
			<ol>
				<li value="1">Connect to a database and start writing values in it. We start by importing the <code>sqlite3</code> module of Python and then use the <code>connect</code> function to connect to a database. Designate <code>Year</code> as the <code>PRIMARY KEY</code> of this table:<pre>import sqlite3
with sqlite3.connect("Education_GDP.db") as conn:
    cursor = conn.cursor()
    cursor.execute("CREATE TABLE IF NOT EXISTS \
                   education_gdp(Year INT, Enrollment \
                   FLOAT, GDP FLOAT, PRIMARY KEY (Year))")</pre></li>
				<li>Run a loop with the dataset rows one by one to insert them into the table:<pre>with sqlite3.connect("Education_GDP.db") as conn:
    cursor = conn.cursor()
    for i in range(14):
        year = int(primary_enrollment_with_gdp.iloc[i]['Year'])
        enrollment = \
        primary_enrollment_with_gdp.iloc[i]\
        ['Enrollments (Thousands)']
        gdp = primary_enrollment_with_gdp.iloc[i]['GDP']
        #print(year,enrollment,gdp)
        cursor.execute("INSERT INTO \
                       education_gdp (Year,Enrollment,GDP) \
                       VALUES(?,?,?)",(year,enrollment,gdp))</pre></li>
			</ol>
			<p>If we look at the current folder, we should see a file called <code>Education_GDP.db</code>, and if we can examine that using a database viewer program, we will see that the data has been transferred there.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/3fyIqy8">https://packt.live/3fyIqy8</a>.</p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/3fQ0PXJ">https://packt.live/3fQ0PXJ</a>.</p>
		</div>
	</div>
<div><nav id="toc" epub:type="toc">
		<h2>Contents</h2>
			<ol>
				<li><a href="B15780_FM_Final_SMP.xhtml#_idParaDest-1">The Data Wrangling Workshop</a></li>
				<li><a href="B15780_FM_Final_SMP.xhtml#_idParaDest-2">Second Edition</a></li>
				<li><a href="B15780_Preface_Final_NT.xhtml#_idParaDest-3">Preface</a>
					<ol>
						<li><a href="B15780_Preface_Final_NT.xhtml#_idParaDest-4">About the Book</a>
							<ol>
								<li><a href="B15780_Preface_Final_NT.xhtml#_idParaDest-5">Audience</a></li>
								<li><a href="B15780_Preface_Final_NT.xhtml#_idParaDest-6">About the Chapters</a></li>
								<li><a href="B15780_Preface_Final_NT.xhtml#_idParaDest-7">Conventions</a></li>
								<li><a href="B15780_Preface_Final_NT.xhtml#_idParaDest-8">Code Presentation</a></li>
								<li><a href="B15780_Preface_Final_NT.xhtml#_idParaDest-9">Setting up Your Environment</a></li>
								<li><a href="B15780_Preface_Final_NT.xhtml#_idParaDest-10">Installing Python</a>
									<ol>
										<li><a href="B15780_Preface_Final_NT.xhtml#_idParaDest-11">Installing Python on Windows</a></li>
										<li><a href="B15780_Preface_Final_NT.xhtml#_idParaDest-12">Installing Python on Linux</a></li>
										<li><a href="B15780_Preface_Final_NT.xhtml#_idParaDest-13">Installing Python on MacOS</a></li>
									</ol>
								</li>
								<li><a href="B15780_Preface_Final_NT.xhtml#_idParaDest-14">Installing Libraries</a></li>
								<li><a href="B15780_Preface_Final_NT.xhtml#_idParaDest-15">Project Jupyter</a></li>
								<li><a href="B15780_Preface_Final_NT.xhtml#_idParaDest-16">Accessing the Code Files</a></li>
							</ol>
						</li>
					</ol>
				</li>
				<li><a href="B15780_01_Final_SMP.xhtml#_idParaDest-17">1. Introduction to Data Wrangling with Python</a>
					<ol>
						<li><a href="B15780_01_Final_SMP.xhtml#_idParaDest-18">Introduction</a></li>
						<li><a href="B15780_01_Final_SMP.xhtml#_idParaDest-19">Importance of Data Wrangling</a></li>
						<li><a href="B15780_01_Final_SMP.xhtml#_idParaDest-20">Python for Data Wrangling</a></li>
						<li><a href="B15780_01_Final_SMP.xhtml#_idParaDest-21">Lists, Sets, Strings, Tuples, and Dictionaries</a>
							<ol>
								<li><a href="B15780_01_Final_SMP.xhtml#_idParaDest-22">Lists</a></li>
							</ol>
						</li>
						<li><a href="B15780_01_Final_SMP.xhtml#_idParaDest-23">List Functions</a>
							<ol>
								<li><a href="B15780_01_Final_SMP.xhtml#_idParaDest-24">Exercise 1.01: Accessing the List Members</a></li>
								<li><a href="B15780_01_Final_SMP.xhtml#_idParaDest-25">Exercise 1.02: Generating and Iterating through a List</a></li>
								<li><a href="B15780_01_Final_SMP.xhtml#_idParaDest-26">Exercise 1.03: Iterating over a List and Checking Membership</a></li>
								<li><a href="B15780_01_Final_SMP.xhtml#_idParaDest-27">Exercise 1.04: Sorting a List</a></li>
								<li><a href="B15780_01_Final_SMP.xhtml#_idParaDest-28">Exercise 1.05: Generating a Random List</a></li>
								<li><a href="B15780_01_Final_SMP.xhtml#_idParaDest-29">Activity 1.01: Handling Lists</a></li>
								<li><a href="B15780_01_Final_SMP.xhtml#_idParaDest-30">Sets</a></li>
								<li><a href="B15780_01_Final_SMP.xhtml#_idParaDest-31">Introduction to Sets</a></li>
								<li><a href="B15780_01_Final_SMP.xhtml#_idParaDest-32">Union and Intersection of Sets</a></li>
								<li><a href="B15780_01_Final_SMP.xhtml#_idParaDest-33">Creating Null Sets</a></li>
								<li><a href="B15780_01_Final_SMP.xhtml#_idParaDest-34">Dictionary</a></li>
								<li><a href="B15780_01_Final_SMP.xhtml#_idParaDest-35">Exercise 1.06: Accessing and Setting Values in a Dictionary</a></li>
								<li><a href="B15780_01_Final_SMP.xhtml#_idParaDest-36">Exercise 1.07: Iterating over a Dictionary</a></li>
								<li><a href="B15780_01_Final_SMP.xhtml#_idParaDest-37">Exercise 1.08: Revisiting the Unique Valued List Problem</a></li>
								<li><a href="B15780_01_Final_SMP.xhtml#_idParaDest-38">Exercise 1.09: Deleting a Value from Dict</a></li>
								<li><a href="B15780_01_Final_SMP.xhtml#_idParaDest-39">Exercise 1.10: Dictionary Comprehension</a></li>
								<li><a href="B15780_01_Final_SMP.xhtml#_idParaDest-40">Tuples</a></li>
								<li><a href="B15780_01_Final_SMP.xhtml#_idParaDest-41">Creating a Tuple with Different Cardinalities</a></li>
								<li><a href="B15780_01_Final_SMP.xhtml#_idParaDest-42">Unpacking a Tuple</a></li>
								<li><a href="B15780_01_Final_SMP.xhtml#_idParaDest-43">Exercise 1.11: Handling Tuples</a></li>
								<li><a href="B15780_01_Final_SMP.xhtml#_idParaDest-44">Strings</a></li>
								<li><a href="B15780_01_Final_SMP.xhtml#_idParaDest-45">Exercise 1.12: Accessing Strings</a></li>
								<li><a href="B15780_01_Final_SMP.xhtml#_idParaDest-46">Exercise 1.13: String Slices</a></li>
								<li><a href="B15780_01_Final_SMP.xhtml#_idParaDest-47">String Functions</a></li>
								<li><a href="B15780_01_Final_SMP.xhtml#_idParaDest-48">Exercise 1.14: Splitting and Joining a String</a></li>
								<li><a href="B15780_01_Final_SMP.xhtml#_idParaDest-49">Activity 1.02: Analyzing a Multiline String and Generating the Unique Word Count</a></li>
							</ol>
						</li>
						<li><a href="B15780_01_Final_SMP.xhtml#_idParaDest-50">Summary</a></li>
					</ol>
				</li>
				<li><a href="B15780_02_Final_SMP.xhtml#_idParaDest-51">2. Advanced Operations on Built-In Data Structures</a>
					<ol>
						<li><a href="B15780_02_Final_SMP.xhtml#_idParaDest-52">Introduction</a></li>
						<li><a href="B15780_02_Final_SMP.xhtml#_idParaDest-53">Advanced Data Structures</a>
							<ol>
								<li><a href="B15780_02_Final_SMP.xhtml#_idParaDest-54">Iterator </a></li>
								<li><a href="B15780_02_Final_SMP.xhtml#_idParaDest-55">Exercise 2.01: Introducing to the Iterator</a></li>
								<li><a href="B15780_02_Final_SMP.xhtml#_idParaDest-56">Stacks</a></li>
								<li><a href="B15780_02_Final_SMP.xhtml#_idParaDest-57">Exercise 2.02: Implementing a Stack in Python</a></li>
								<li><a href="B15780_02_Final_SMP.xhtml#_idParaDest-58">Exercise 2.03: Implementing a Stack Using User-Defined Methods</a></li>
								<li><a href="B15780_02_Final_SMP.xhtml#_idParaDest-59">Lambda Expressions</a></li>
								<li><a href="B15780_02_Final_SMP.xhtml#_idParaDest-60">Exercise 2.04: Implementing a Lambda Expression </a></li>
								<li><a href="B15780_02_Final_SMP.xhtml#_idParaDest-61">Exercise 2.05: Lambda Expression for Sorting</a></li>
								<li><a href="B15780_02_Final_SMP.xhtml#_idParaDest-62">Exercise 2.06: Multi-Element Membership Checking</a></li>
								<li><a href="B15780_02_Final_SMP.xhtml#_idParaDest-63">Queue</a></li>
								<li><a href="B15780_02_Final_SMP.xhtml#_idParaDest-64">Exercise 2.07: Implementing a Queue in Python</a></li>
								<li><a href="B15780_02_Final_SMP.xhtml#_idParaDest-65">Activity 2.01: Permutation, Iterator, Lambda, and List</a></li>
							</ol>
						</li>
						<li><a href="B15780_02_Final_SMP.xhtml#_idParaDest-66">Basic File Operations in Python</a>
							<ol>
								<li><a href="B15780_02_Final_SMP.xhtml#_idParaDest-67">Exercise 2.08: File Operations</a></li>
								<li><a href="B15780_02_Final_SMP.xhtml#_idParaDest-68">File Handling</a></li>
								<li><a href="B15780_02_Final_SMP.xhtml#_idParaDest-69">Exercise 2.09: Opening and Closing a File</a></li>
								<li><a href="B15780_02_Final_SMP.xhtml#_idParaDest-70">The with Statement</a></li>
								<li><a href="B15780_02_Final_SMP.xhtml#_idParaDest-71">Opening a File Using the with Statement</a></li>
								<li><a href="B15780_02_Final_SMP.xhtml#_idParaDest-72">Exercise 2.10: Reading a File Line by Line</a></li>
								<li><a href="B15780_02_Final_SMP.xhtml#_idParaDest-73">Exercise 2.11: Writing to a File</a></li>
								<li><a href="B15780_02_Final_SMP.xhtml#_idParaDest-74">Activity 2.02: Designing Your Own CSV Parser</a></li>
							</ol>
						</li>
						<li><a href="B15780_02_Final_SMP.xhtml#_idParaDest-75">Summary</a></li>
					</ol>
				</li>
				<li><a href="B15780_03_Final_SMP.xhtml#_idParaDest-76">3. Introduction to NumPy, Pandas, and Matplotlib</a>
					<ol>
						<li><a href="B15780_03_Final_SMP.xhtml#_idParaDest-77">Introduction</a></li>
						<li><a href="B15780_03_Final_SMP.xhtml#_idParaDest-78">NumPy Arrays</a>
							<ol>
								<li><a href="B15780_03_Final_SMP.xhtml#_idParaDest-79">NumPy Arrays and Features</a></li>
								<li><a href="B15780_03_Final_SMP.xhtml#_idParaDest-80">Exercise 3.01: Creating a NumPy Array (from a List)</a></li>
								<li><a href="B15780_03_Final_SMP.xhtml#_idParaDest-81">Exercise 3.02: Adding Two NumPy Arrays</a></li>
								<li><a href="B15780_03_Final_SMP.xhtml#_idParaDest-82">Exercise 3.03: Mathematical Operations on NumPy Arrays</a></li>
							</ol>
						</li>
						<li><a href="B15780_03_Final_SMP.xhtml#_idParaDest-83">Advanced Mathematical Operations </a>
							<ol>
								<li><a href="B15780_03_Final_SMP.xhtml#_idParaDest-84">Exercise 3.04: Advanced Mathematical Operations on NumPy Arrays</a></li>
								<li><a href="B15780_03_Final_SMP.xhtml#_idParaDest-85">Exercise 3.05: Generating Arrays Using arange and linspace Methods</a></li>
								<li><a href="B15780_03_Final_SMP.xhtml#_idParaDest-86">Exercise 3.06: Creating Multi-Dimensional Arrays</a></li>
								<li><a href="B15780_03_Final_SMP.xhtml#_idParaDest-87">Exercise 3.07: The Dimension, Shape, Size, and Data Type of Two-dimensional Arrays</a></li>
								<li><a href="B15780_03_Final_SMP.xhtml#_idParaDest-88">Exercise 3.08: Zeros, Ones, Random, Identity Matrices, and Vectors</a></li>
								<li><a href="B15780_03_Final_SMP.xhtml#_idParaDest-89">Exercise 3.09: Reshaping, Ravel, Min, Max, and Sorting</a></li>
								<li><a href="B15780_03_Final_SMP.xhtml#_idParaDest-90">Exercise 3.10: Indexing and Slicing</a></li>
								<li><a href="B15780_03_Final_SMP.xhtml#_idParaDest-91">Conditional SubSetting</a></li>
								<li><a href="B15780_03_Final_SMP.xhtml#_idParaDest-92">Exercise 3.11: Array Operations </a></li>
								<li><a href="B15780_03_Final_SMP.xhtml#_idParaDest-93">Stacking Arrays</a></li>
								<li><a href="B15780_03_Final_SMP.xhtml#_idParaDest-94">Pandas DataFrames</a></li>
								<li><a href="B15780_03_Final_SMP.xhtml#_idParaDest-95">Exercise 3.12: Creating a Pandas Series</a></li>
								<li><a href="B15780_03_Final_SMP.xhtml#_idParaDest-96">Exercise 3.13: Pandas Series and Data Handling</a></li>
								<li><a href="B15780_03_Final_SMP.xhtml#_idParaDest-97">Exercise 3.14: Creating Pandas DataFrames</a></li>
								<li><a href="B15780_03_Final_SMP.xhtml#_idParaDest-98">Exercise 3.15: Viewing a DataFrame Partially</a></li>
								<li><a href="B15780_03_Final_SMP.xhtml#_idParaDest-99">Indexing and Slicing Columns</a></li>
								<li><a href="B15780_03_Final_SMP.xhtml#_idParaDest-100">Indexing and Slicing Rows</a></li>
								<li><a href="B15780_03_Final_SMP.xhtml#_idParaDest-101">Exercise 3.16: Creating and Deleting a New Column or Row</a></li>
							</ol>
						</li>
						<li><a href="B15780_03_Final_SMP.xhtml#_idParaDest-102">Statistics and Visualization with NumPy and Pandas</a>
							<ol>
								<li><a href="B15780_03_Final_SMP.xhtml#_idParaDest-103">Refresher on Basic Descriptive Statistics</a></li>
								<li><a href="B15780_03_Final_SMP.xhtml#_idParaDest-104">Exercise 3.17: Introduction to Matplotlib through a Scatter Plot</a></li>
							</ol>
						</li>
						<li><a href="B15780_03_Final_SMP.xhtml#_idParaDest-105">The Definition of Statistical Measures – Central Tendency and Spread</a>
							<ol>
								<li><a href="B15780_03_Final_SMP.xhtml#_idParaDest-106">Random Variables and Probability Distribution</a></li>
								<li><a href="B15780_03_Final_SMP.xhtml#_idParaDest-107">What is a Probability Distribution?</a></li>
								<li><a href="B15780_03_Final_SMP.xhtml#_idParaDest-108">Discrete Distributions</a></li>
								<li><a href="B15780_03_Final_SMP.xhtml#_idParaDest-109">Continuous Distributions</a></li>
							</ol>
						</li>
						<li><a href="B15780_03_Final_SMP.xhtml#_idParaDest-110">Data Wrangling in Statistics and Visualization</a>
							<ol>
								<li><a href="B15780_03_Final_SMP.xhtml#_idParaDest-111">Using NumPy and Pandas to Calculate Basic Descriptive Statistics</a></li>
								<li><a href="B15780_03_Final_SMP.xhtml#_idParaDest-112">Random Number Generation Using NumPy</a></li>
								<li><a href="B15780_03_Final_SMP.xhtml#_idParaDest-113">Exercise 3.18: Generating Random Numbers from a Uniform Distribution</a></li>
								<li><a href="B15780_03_Final_SMP.xhtml#_idParaDest-114">Exercise 3.19: Generating Random Numbers from a Binomial Distribution and Bar Plot</a></li>
								<li><a href="B15780_03_Final_SMP.xhtml#_idParaDest-115">Exercise 3.20: Generating Random Numbers from a Normal Distribution and Histograms</a></li>
								<li><a href="B15780_03_Final_SMP.xhtml#_idParaDest-116">Exercise 3.21: Calculating Descriptive Statistics from a DataFrame</a></li>
								<li><a href="B15780_03_Final_SMP.xhtml#_idParaDest-117">Exercise 3.22: Built-in Plotting Utilities</a></li>
								<li><a href="B15780_03_Final_SMP.xhtml#_idParaDest-118">Activity 3.01: Generating Statistics from a CSV File</a></li>
							</ol>
						</li>
						<li><a href="B15780_03_Final_SMP.xhtml#_idParaDest-119">Summary</a></li>
					</ol>
				</li>
				<li><a href="B15780_04_Final_SMP.xhtml#_idParaDest-120">4. A Deep Dive into Data Wrangling with Python</a>
					<ol>
						<li><a href="B15780_04_Final_SMP.xhtml#_idParaDest-121">Introduction</a></li>
						<li><a href="B15780_04_Final_SMP.xhtml#_idParaDest-122">Subsetting, Filtering, and Grouping</a>
							<ol>
								<li><a href="B15780_04_Final_SMP.xhtml#_idParaDest-123">Exercise 4.01: Examining the Superstore Sales Data in an Excel File</a></li>
								<li><a href="B15780_04_Final_SMP.xhtml#_idParaDest-124">Subsetting the DataFrame</a></li>
								<li><a href="B15780_04_Final_SMP.xhtml#_idParaDest-125">An Example Use Case – Determining Statistics on Sales and Profit</a></li>
								<li><a href="B15780_04_Final_SMP.xhtml#_idParaDest-126">Exercise 4.02: The unique Function</a></li>
								<li><a href="B15780_04_Final_SMP.xhtml#_idParaDest-127">Conditional Selection and Boolean Filtering</a></li>
								<li><a href="B15780_04_Final_SMP.xhtml#_idParaDest-128">Exercise 4.03: Setting and Resetting the Index</a></li>
								<li><a href="B15780_04_Final_SMP.xhtml#_idParaDest-129">The GroupBy Method</a></li>
								<li><a href="B15780_04_Final_SMP.xhtml#_idParaDest-130">Exercise 4.04: The GroupBy Method</a></li>
							</ol>
						</li>
						<li><a href="B15780_04_Final_SMP.xhtml#_idParaDest-131">Detecting Outliers and Handling Missing Values</a>
							<ol>
								<li><a href="B15780_04_Final_SMP.xhtml#_idParaDest-132">Missing Values in Pandas</a></li>
								<li><a href="B15780_04_Final_SMP.xhtml#_idParaDest-133">Exercise 4.05: Filling in the Missing Values Using the fillna Method</a></li>
								<li><a href="B15780_04_Final_SMP.xhtml#_idParaDest-134">The dropna Method</a></li>
								<li><a href="B15780_04_Final_SMP.xhtml#_idParaDest-135">Exercise 4.06: Dropping Missing Values with dropna</a></li>
								<li><a href="B15780_04_Final_SMP.xhtml#_idParaDest-136">Outlier Detection Using a Simple Statistical Test</a></li>
							</ol>
						</li>
						<li><a href="B15780_04_Final_SMP.xhtml#_idParaDest-137">Concatenating, Merging, and Joining</a>
							<ol>
								<li><a href="B15780_04_Final_SMP.xhtml#_idParaDest-138">Exercise 4.07: Concatenation in Datasets</a></li>
								<li><a href="B15780_04_Final_SMP.xhtml#_idParaDest-139">Merging by a Common Key</a></li>
								<li><a href="B15780_04_Final_SMP.xhtml#_idParaDest-140">Exercise 4.08: Merging by a Common Key</a></li>
								<li><a href="B15780_04_Final_SMP.xhtml#_idParaDest-141">The join Method</a></li>
								<li><a href="B15780_04_Final_SMP.xhtml#_idParaDest-142">Exercise 4.09: The join Method</a></li>
							</ol>
						</li>
						<li><a href="B15780_04_Final_SMP.xhtml#_idParaDest-143">Useful Methods of Pandas</a>
							<ol>
								<li><a href="B15780_04_Final_SMP.xhtml#_idParaDest-144">Randomized Sampling</a></li>
								<li><a href="B15780_04_Final_SMP.xhtml#_idParaDest-145">Exercise 4.10: Randomized Sampling</a></li>
								<li><a href="B15780_04_Final_SMP.xhtml#_idParaDest-146">The value_counts Method</a></li>
								<li><a href="B15780_04_Final_SMP.xhtml#_idParaDest-147">Pivot Table Functionality</a></li>
								<li><a href="B15780_04_Final_SMP.xhtml#_idParaDest-148">Exercise 4.11: Sorting by Column Values – the sort_values Method</a></li>
								<li><a href="B15780_04_Final_SMP.xhtml#_idParaDest-149">Exercise 4.12: Flexibility of User-Defined Functions with the apply Method</a></li>
								<li><a href="B15780_04_Final_SMP.xhtml#_idParaDest-150">Activity 4.01: Working with the Adult Income Dataset (UCI)</a></li>
							</ol>
						</li>
						<li><a href="B15780_04_Final_SMP.xhtml#_idParaDest-151">Summary</a></li>
					</ol>
				</li>
				<li><a href="B15780_05_Final_RK.xhtml#_idParaDest-152">5. Getting Comfortable with Different Kinds of Data Sources</a>
					<ol>
						<li><a href="B15780_05_Final_RK.xhtml#_idParaDest-153">Introduction</a></li>
						<li><a href="B15780_05_Final_RK.xhtml#_idParaDest-154">Reading Data from Different Sources</a>
							<ol>
								<li><a href="B15780_05_Final_RK.xhtml#_idParaDest-155">Data Files Provided with This Chapter</a></li>
								<li><a href="B15780_05_Final_RK.xhtml#_idParaDest-156">Libraries to Install for This Chapter</a></li>
								<li><a href="B15780_05_Final_RK.xhtml#_idParaDest-157">Reading Data Using Pandas</a></li>
								<li><a href="B15780_05_Final_RK.xhtml#_idParaDest-158">Exercise 5.01: Working with Headers When Reading Data from a CSV File</a></li>
								<li><a href="B15780_05_Final_RK.xhtml#_idParaDest-159">Exercise 5.02: Reading from a CSV File Where Delimiters Are Not Commas</a></li>
								<li><a href="B15780_05_Final_RK.xhtml#_idParaDest-160">Exercise 5.03: Bypassing and Renaming the Headers of a CSV File</a></li>
								<li><a href="B15780_05_Final_RK.xhtml#_idParaDest-161">Exercise 5.04: Skipping Initial Rows and Footers When Reading a CSV File</a></li>
								<li><a href="B15780_05_Final_RK.xhtml#_idParaDest-162">Reading Only the First N Rows </a></li>
								<li><a href="B15780_05_Final_RK.xhtml#_idParaDest-163">Exercise 5.05: Combining skiprows and nrows to Read Data in Small Chunks</a></li>
								<li><a href="B15780_05_Final_RK.xhtml#_idParaDest-164">Setting the skip_blank_lines Option</a></li>
								<li><a href="B15780_05_Final_RK.xhtml#_idParaDest-165">Reading CSV Data from a Zip File</a></li>
								<li><a href="B15780_05_Final_RK.xhtml#_idParaDest-166">Reading from an Excel File Using sheet_name and Handling a Distinct sheet_name</a></li>
								<li><a href="B15780_05_Final_RK.xhtml#_idParaDest-167">Exercise 5.06: Reading a General Delimited Text File</a></li>
								<li><a href="B15780_05_Final_RK.xhtml#_idParaDest-168">Reading HTML Tables Directly from a URL</a></li>
								<li><a href="B15780_05_Final_RK.xhtml#_idParaDest-169">Exercise 5.07: Further Wrangling to Get the Desired Data</a></li>
								<li><a href="B15780_05_Final_RK.xhtml#_idParaDest-170">Reading from a JSON file</a></li>
								<li><a href="B15780_05_Final_RK.xhtml#_idParaDest-171">Exercise 5.08: Reading from a JSON File</a></li>
								<li><a href="B15780_05_Final_RK.xhtml#_idParaDest-172">Reading a PDF File</a></li>
								<li><a href="B15780_05_Final_RK.xhtml#_idParaDest-173">Exercise 5.09: Reading Tabular Data from a PDF File</a></li>
							</ol>
						</li>
						<li><a href="B15780_05_Final_RK.xhtml#_idParaDest-174">Introduction to Beautiful Soup 4 and Web Page Parsing</a>
							<ol>
								<li><a href="B15780_05_Final_RK.xhtml#_idParaDest-175">Structure of HTML</a></li>
								<li><a href="B15780_05_Final_RK.xhtml#_idParaDest-176">Exercise 5.10: Reading an HTML File and Extracting Its Contents Using Beautiful Soup</a></li>
								<li><a href="B15780_05_Final_RK.xhtml#_idParaDest-177">Exercise 5.11: DataFrames and BeautifulSoup</a></li>
								<li><a href="B15780_05_Final_RK.xhtml#_idParaDest-178">Exercise 5.12: Exporting a DataFrame as an Excel File</a></li>
								<li><a href="B15780_05_Final_RK.xhtml#_idParaDest-179">Exercise 5.13: Stacking URLs from a Document Using bs4</a></li>
								<li><a href="B15780_05_Final_RK.xhtml#_idParaDest-180">Activity 5.01: Reading Tabular Data from a Web Page and Creating DataFrames</a></li>
							</ol>
						</li>
						<li><a href="B15780_05_Final_RK.xhtml#_idParaDest-181">Summary</a></li>
					</ol>
				</li>
				<li><a href="B15780_06_Final_RK.xhtml#_idParaDest-182">6. Learning the Hidden Secrets of Data Wrangling</a>
					<ol>
						<li><a href="B15780_06_Final_RK.xhtml#_idParaDest-183">Introduction</a></li>
						<li><a href="B15780_06_Final_RK.xhtml#_idParaDest-184">Advanced List Comprehension and the zip Function</a>
							<ol>
								<li><a href="B15780_06_Final_RK.xhtml#_idParaDest-185">Introduction to Generator Expressions</a></li>
								<li><a href="B15780_06_Final_RK.xhtml#_idParaDest-186">Exercise 6.01: Generator Expressions</a></li>
								<li><a href="B15780_06_Final_RK.xhtml#_idParaDest-187">Exercise 6.02: Single-Line Generator Expression</a></li>
								<li><a href="B15780_06_Final_RK.xhtml#_idParaDest-188">Exercise 6.03: Extracting a List with Single Words</a></li>
								<li><a href="B15780_06_Final_RK.xhtml#_idParaDest-189">Exercise 6.04: The zip Function</a></li>
								<li><a href="B15780_06_Final_RK.xhtml#_idParaDest-190">Exercise 6.05: Handling Messy Data</a></li>
							</ol>
						</li>
						<li><a href="B15780_06_Final_RK.xhtml#_idParaDest-191">Data Formatting</a>
							<ol>
								<li><a href="B15780_06_Final_RK.xhtml#_idParaDest-192">The % operator</a></li>
								<li><a href="B15780_06_Final_RK.xhtml#_idParaDest-193">Using the format Function</a></li>
								<li><a href="B15780_06_Final_RK.xhtml#_idParaDest-194">Exercise 6.06: Data Representation Using {}</a></li>
							</ol>
						</li>
						<li><a href="B15780_06_Final_RK.xhtml#_idParaDest-195">Identifying and Cleaning Outliers</a>
							<ol>
								<li><a href="B15780_06_Final_RK.xhtml#_idParaDest-196">Exercise 6.07: Outliers in Numerical Data</a></li>
								<li><a href="B15780_06_Final_RK.xhtml#_idParaDest-197">Z-score</a></li>
								<li><a href="B15780_06_Final_RK.xhtml#_idParaDest-198">Exercise 6.08: The Z-Score Value to Remove Outliers</a></li>
							</ol>
						</li>
						<li><a href="B15780_06_Final_RK.xhtml#_idParaDest-199">Levenshtein Distance</a>
							<ol>
								<li><a href="B15780_06_Final_RK.xhtml#_idParaDest-200">Additional Software Required for This Section</a></li>
								<li><a href="B15780_06_Final_RK.xhtml#_idParaDest-201">Exercise 6.09: Fuzzy String Matching</a></li>
								<li><a href="B15780_06_Final_RK.xhtml#_idParaDest-202">Activity 6.01: Handling Outliers and Missing Data</a></li>
							</ol>
						</li>
						<li><a href="B15780_06_Final_RK.xhtml#_idParaDest-203">Summary</a></li>
					</ol>
				</li>
				<li><a href="B15780_07_Final_SZ.xhtml#_idParaDest-204">7. Advanced Web Scraping and Data Gathering</a>
					<ol>
						<li><a href="B15780_07_Final_SZ.xhtml#_idParaDest-205">Introduction</a></li>
						<li><a href="B15780_07_Final_SZ.xhtml#_idParaDest-206">The Requests and BeautifulSoup Libraries</a>
							<ol>
								<li><a href="B15780_07_Final_SZ.xhtml#_idParaDest-207">Exercise 7.01: Using the Requests Library to Get a Response from the Wikipedia Home Page</a></li>
								<li><a href="B15780_07_Final_SZ.xhtml#_idParaDest-208">Exercise 7.02: Checking the Status of the Web Request</a></li>
								<li><a href="B15780_07_Final_SZ.xhtml#_idParaDest-209">Checking the Encoding of a Web Page</a></li>
								<li><a href="B15780_07_Final_SZ.xhtml#_idParaDest-210">Exercise 7.03: Decoding the Contents of a Response and Checking Its Length</a></li>
								<li><a href="B15780_07_Final_SZ.xhtml#_idParaDest-211">Exercise 7.04: Extracting Readable Text from a BeautifulSoup Object</a></li>
								<li><a href="B15780_07_Final_SZ.xhtml#_idParaDest-212">Extracting Text from a Section</a></li>
								<li><a href="B15780_07_Final_SZ.xhtml#_idParaDest-213">Extracting Important Historical Events that Happened on Today's Date</a></li>
								<li><a href="B15780_07_Final_SZ.xhtml#_idParaDest-214">Exercise 7.05: Using Advanced BS4 Techniques to Extract Relevant Text</a></li>
								<li><a href="B15780_07_Final_SZ.xhtml#_idParaDest-215">Exercise 7.06: Creating a Compact Function to Extract the On this day Text from the Wikipedia Home Page</a></li>
							</ol>
						</li>
						<li><a href="B15780_07_Final_SZ.xhtml#_idParaDest-216">Reading Data from XML</a>
							<ol>
								<li><a href="B15780_07_Final_SZ.xhtml#_idParaDest-217">Exercise 7.07: Creating an XML File and Reading XML Element Objects</a></li>
								<li><a href="B15780_07_Final_SZ.xhtml#_idParaDest-218">Exercise 7.08: Finding Various Elements of Data within a Tree (Element)</a></li>
								<li><a href="B15780_07_Final_SZ.xhtml#_idParaDest-219">Reading from a Local XML File into an ElementTree Object</a></li>
								<li><a href="B15780_07_Final_SZ.xhtml#_idParaDest-220">Exercise 7.09: Traversing the Tree, Finding the Root, and Exploring All the Child Nodes and Their Tags and Attributes</a></li>
								<li><a href="B15780_07_Final_SZ.xhtml#_idParaDest-221">Exercise 7.10: Using the text Method to Extract Meaningful Data</a></li>
								<li><a href="B15780_07_Final_SZ.xhtml#_idParaDest-222">Extracting and Printing the GDP/Per Capita Information Using a Loop</a></li>
								<li><a href="B15780_07_Final_SZ.xhtml#_idParaDest-223">Finding All the Neighboring Countries for Each Country and Printing Them</a></li>
								<li><a href="B15780_07_Final_SZ.xhtml#_idParaDest-224">Exercise 7.11: A Simple Demo of Using XML Data Obtained by Web Scraping</a></li>
							</ol>
						</li>
						<li><a href="B15780_07_Final_SZ.xhtml#_idParaDest-225">Reading Data from an API</a>
							<ol>
								<li><a href="B15780_07_Final_SZ.xhtml#_idParaDest-226">Defining the Base URL (or API Endpoint)</a></li>
								<li><a href="B15780_07_Final_SZ.xhtml#_idParaDest-227">Exercise 7.12: Defining and Testing a Function to Pull Country Data from an API</a></li>
								<li><a href="B15780_07_Final_SZ.xhtml#_idParaDest-228">Using the Built-In JSON Library to Read and Examine Data</a></li>
								<li><a href="B15780_07_Final_SZ.xhtml#_idParaDest-229">Printing All the Data Elements</a></li>
								<li><a href="B15780_07_Final_SZ.xhtml#_idParaDest-230">Using a Function that Extracts a DataFrame Containing Key Information</a></li>
								<li><a href="B15780_07_Final_SZ.xhtml#_idParaDest-231">Exercise 7.13: Testing the Function by Building a Small Database of Country Information</a></li>
							</ol>
						</li>
						<li><a href="B15780_07_Final_SZ.xhtml#_idParaDest-232">Fundamentals of Regular Expressions (RegEx)</a>
							<ol>
								<li><a href="B15780_07_Final_SZ.xhtml#_idParaDest-233">RegEx in the Context of Web Scraping</a></li>
								<li><a href="B15780_07_Final_SZ.xhtml#_idParaDest-234">Exercise 7.14: Using the match Method to Check Whether a Pattern Matches a String/Sequence</a></li>
								<li><a href="B15780_07_Final_SZ.xhtml#_idParaDest-235">Using the compile Method to Create a RegEx Program</a></li>
								<li><a href="B15780_07_Final_SZ.xhtml#_idParaDest-236">Exercise 7.15: Compiling Programs to Match Objects</a></li>
								<li><a href="B15780_07_Final_SZ.xhtml#_idParaDest-237">Exercise 7.16: Using Additional Parameters in the match Method to Check for Positional Matching</a></li>
								<li><a href="B15780_07_Final_SZ.xhtml#_idParaDest-238">Finding the Number of Words in a List That End with "ing"</a></li>
								<li><a href="B15780_07_Final_SZ.xhtml#_idParaDest-239">The search Method in RegEx</a></li>
								<li><a href="B15780_07_Final_SZ.xhtml#_idParaDest-240">Exercise 7.17: The search Method in RegEx</a></li>
								<li><a href="B15780_07_Final_SZ.xhtml#_idParaDest-241">Exercise 7.18: Using the span Method of the Match Object to Locate the Position of the Matched Pattern</a></li>
								<li><a href="B15780_07_Final_SZ.xhtml#_idParaDest-242">Exercise 7.19: Examples of Single-Character Pattern Matching with search</a></li>
								<li><a href="B15780_07_Final_SZ.xhtml#_idParaDest-243">Exercise 7.20: Handling Pattern Matching at the Start or End of a String</a></li>
								<li><a href="B15780_07_Final_SZ.xhtml#_idParaDest-244">Exercise 7.21: Pattern Matching with Multiple Characters</a></li>
								<li><a href="B15780_07_Final_SZ.xhtml#_idParaDest-245">Exercise 7.22: Greedy versus Non-Greedy Matching</a></li>
								<li><a href="B15780_07_Final_SZ.xhtml#_idParaDest-246">Exercise 7.23: Controlling Repetitions to Match in a Text</a></li>
								<li><a href="B15780_07_Final_SZ.xhtml#_idParaDest-247">Sets of Matching Characters</a></li>
								<li><a href="B15780_07_Final_SZ.xhtml#_idParaDest-248">Exercise 7.24: Sets of Matching Characters</a></li>
								<li><a href="B15780_07_Final_SZ.xhtml#_idParaDest-249">Exercise 7.25: The Use of OR in RegEx Using the OR Operator</a></li>
								<li><a href="B15780_07_Final_SZ.xhtml#_idParaDest-250">The findall Method</a></li>
								<li><a href="B15780_07_Final_SZ.xhtml#_idParaDest-251">Activity 7.01: Extracting the Top 100 e-books from Gutenberg</a></li>
								<li><a href="B15780_07_Final_SZ.xhtml#_idParaDest-252">Activity 7.02: Building Your Own Movie Database by Reading an API</a></li>
							</ol>
						</li>
						<li><a href="B15780_07_Final_SZ.xhtml#_idParaDest-253">Summary</a></li>
					</ol>
				</li>
				<li><a href="B15780_08_Final_SZ.xhtml#_idParaDest-254">8. RDBMS and SQL</a>
					<ol>
						<li><a href="B15780_08_Final_SZ.xhtml#_idParaDest-255">Introduction</a></li>
						<li><a href="B15780_08_Final_SZ.xhtml#_idParaDest-256">Refresher of RDBMS and SQL</a>
							<ol>
								<li><a href="B15780_08_Final_SZ.xhtml#_idParaDest-257">How Is an RDBMS Structured?</a></li>
								<li><a href="B15780_08_Final_SZ.xhtml#_idParaDest-258">SQL</a></li>
								<li><a href="B15780_08_Final_SZ.xhtml#_idParaDest-259">Using an RDBMS (MySQL/PostgreSQL/SQLite)</a></li>
								<li><a href="B15780_08_Final_SZ.xhtml#_idParaDest-260">Exercise 8.01: Connecting to a Database in SQLite</a></li>
								<li><a href="B15780_08_Final_SZ.xhtml#_idParaDest-261">DDL and DML Commands in SQLite</a></li>
								<li><a href="B15780_08_Final_SZ.xhtml#_idParaDest-262">Exercise 8.02: Using DDL and DML Commands in SQLite</a></li>
								<li><a href="B15780_08_Final_SZ.xhtml#_idParaDest-263">Reading Data from a Database in SQLite</a></li>
								<li><a href="B15780_08_Final_SZ.xhtml#_idParaDest-264">Exercise 8.03: Sorting Values That Are Present in the Database</a></li>
								<li><a href="B15780_08_Final_SZ.xhtml#_idParaDest-265">The ALTER Command</a></li>
								<li><a href="B15780_08_Final_SZ.xhtml#_idParaDest-266">Exercise 8.04: Altering the Structure of a Table and Updating the New Fields</a></li>
								<li><a href="B15780_08_Final_SZ.xhtml#_idParaDest-267">The GROUP BY clause</a></li>
								<li><a href="B15780_08_Final_SZ.xhtml#_idParaDest-268">Exercise 8.05: Grouping Values in Tables</a></li>
							</ol>
						</li>
						<li><a href="B15780_08_Final_SZ.xhtml#_idParaDest-269">Relation Mapping in Databases</a>
							<ol>
								<li><a href="B15780_08_Final_SZ.xhtml#_idParaDest-270">Adding Rows in the comments Table</a></li>
							</ol>
						</li>
						<li><a href="B15780_08_Final_SZ.xhtml#_idParaDest-271">Joins</a></li>
						<li><a href="B15780_08_Final_SZ.xhtml#_idParaDest-272">Retrieving Specific Columns from a JOIN Query</a>
							<ol>
								<li><a href="B15780_08_Final_SZ.xhtml#_idParaDest-273">Deleting Rows from Tables</a></li>
								<li><a href="B15780_08_Final_SZ.xhtml#_idParaDest-274">Exercise 8.06: Deleting Rows from Tables</a></li>
								<li><a href="B15780_08_Final_SZ.xhtml#_idParaDest-275">Updating Specific Values in a Table</a></li>
								<li><a href="B15780_08_Final_SZ.xhtml#_idParaDest-276">Exercise 8.07: RDBMS and DataFrames</a></li>
								<li><a href="B15780_08_Final_SZ.xhtml#_idParaDest-277">Activity 8.01: Retrieving Data Accurately from Databases</a></li>
							</ol>
						</li>
						<li><a href="B15780_08_Final_SZ.xhtml#_idParaDest-278">Summary</a></li>
					</ol>
				</li>
				<li><a href="B15780_09_Final_SZ.xhtml#_idParaDest-279">9. Applications in Business Use Cases and Conclusion of the Course</a>
					<ol>
						<li><a href="B15780_09_Final_SZ.xhtml#_idParaDest-280">Introduction</a></li>
						<li><a href="B15780_09_Final_SZ.xhtml#_idParaDest-281">Applying Your Knowledge to a Data Wrangling Task</a>
							<ol>
								<li><a href="B15780_09_Final_SZ.xhtml#_idParaDest-282">Activity 9.01: Data Wrangling Task – Fixing UN Data</a></li>
								<li><a href="B15780_09_Final_SZ.xhtml#_idParaDest-283">Activity 9.02: Data Wrangling Task – Cleaning GDP Data</a></li>
								<li><a href="B15780_09_Final_SZ.xhtml#_idParaDest-284">Activity 9.03: Data Wrangling Task – Merging UN Data and GDP Data</a></li>
								<li><a href="B15780_09_Final_SZ.xhtml#_idParaDest-285">Activity 9.04: Data Wrangling Task – Connecting the New Data to the Database</a></li>
							</ol>
						</li>
						<li><a href="B15780_09_Final_SZ.xhtml#_idParaDest-286">An Extension to Data Wrangling</a>
							<ol>
								<li><a href="B15780_09_Final_SZ.xhtml#_idParaDest-287">Additional Skills Required to Become a Data Scientist</a></li>
								<li><a href="B15780_09_Final_SZ.xhtml#_idParaDest-288">Basic Familiarity with Big Data and Cloud Technologies</a></li>
								<li><a href="B15780_09_Final_SZ.xhtml#_idParaDest-289">What Goes with Data Wrangling?</a></li>
								<li><a href="B15780_09_Final_SZ.xhtml#_idParaDest-290">Tips and Tricks for Mastering Machine Learning</a></li>
							</ol>
						</li>
						<li><a href="B15780_09_Final_SZ.xhtml#_idParaDest-291">Summary</a></li>
					</ol>
				</li>
				<li><a href="B15780_Solution_Final_RK.xhtml#_idParaDest-292">Appendix</a>
					<ol>
						<li><a href="B15780_Solution_Final_RK.xhtml#_idParaDest-293">1. Introduction to Data Wrangling with Python</a>
							<ol>
								<li><a href="B15780_Solution_Final_RK.xhtml#_idParaDest-294">Activity 1.01: Handling Lists</a></li>
								<li><a href="B15780_Solution_Final_RK.xhtml#_idParaDest-295">Activity 1.02: Analyzing a Multiline String and Generating the Unique Word Count</a></li>
							</ol>
						</li>
						<li><a href="B15780_Solution_Final_RK.xhtml#_idParaDest-296">2. Advanced Operations on Built-In Data Structures</a>
							<ol>
								<li><a href="B15780_Solution_Final_RK.xhtml#_idParaDest-297">Activity 2.01: Permutation, Iterator, Lambda, and List</a></li>
								<li><a href="B15780_Solution_Final_RK.xhtml#_idParaDest-298">Activity 2.02: Designing Your Own CSV Parser</a></li>
							</ol>
						</li>
						<li><a href="B15780_Solution_Final_RK.xhtml#_idParaDest-299">3. Introduction to NumPy, Pandas, and Matplotlib</a>
							<ol>
								<li><a href="B15780_Solution_Final_RK.xhtml#_idParaDest-300">Activity 3.01: Generating Statistics from a CSV File</a></li>
							</ol>
						</li>
						<li><a href="B15780_Solution_Final_RK.xhtml#_idParaDest-301">4. A Deep Dive into Data Wrangling with Python</a>
							<ol>
								<li><a href="B15780_Solution_Final_RK.xhtml#_idParaDest-302">Activity 4.01: Working with the Adult Income Dataset (UCI)</a></li>
							</ol>
						</li>
						<li><a href="B15780_Solution_Final_RK.xhtml#_idParaDest-303">5. Getting Comfortable with Different Kinds of Data Sources</a>
							<ol>
								<li><a href="B15780_Solution_Final_RK.xhtml#_idParaDest-304">Activity 5.01: Reading Tabular Data from a Web Page and Creating DataFrames</a></li>
							</ol>
						</li>
						<li><a href="B15780_Solution_Final_RK.xhtml#_idParaDest-305">6. Learning the Hidden Secrets of Data Wrangling</a>
							<ol>
								<li><a href="B15780_Solution_Final_RK.xhtml#_idParaDest-306">Activity 6.01: Handling Outliers and Missing Data</a></li>
							</ol>
						</li>
						<li><a href="B15780_Solution_Final_RK.xhtml#_idParaDest-307">7. Advanced Web Scraping and Data Gathering</a>
							<ol>
								<li><a href="B15780_Solution_Final_RK.xhtml#_idParaDest-308">Activity 7.01: Extracting the Top 100 e-books from Gutenberg</a></li>
								<li><a href="B15780_Solution_Final_RK.xhtml#_idParaDest-309">Activity 7.02: Building Your Own Movie Database by Reading an API</a></li>
							</ol>
						</li>
						<li><a href="B15780_Solution_Final_RK.xhtml#_idParaDest-310">8. RDBMS and SQL</a>
							<ol>
								<li><a href="B15780_Solution_Final_RK.xhtml#_idParaDest-311">Activity 8.01: Retrieving Data Accurately from Databases</a></li>
							</ol>
						</li>
						<li><a href="B15780_Solution_Final_RK.xhtml#_idParaDest-312">9. Applications in Business Use Cases and Conclusion of the Course</a>
							<ol>
								<li><a href="B15780_Solution_Final_RK.xhtml#_idParaDest-313">Activity 9.01: Data Wrangling Task – Fixing UN Data</a></li>
								<li><a href="B15780_Solution_Final_RK.xhtml#_idParaDest-314">Activity 9.02: Data Wrangling Task – Cleaning GDP Data</a></li>
								<li><a href="B15780_Solution_Final_RK.xhtml#_idParaDest-315">Activity 9.03: Data Wrangling Task – Merging UN Data and GDP Data</a></li>
								<li><a href="B15780_Solution_Final_RK.xhtml#_idParaDest-316">Activity 9.04: Data Wrangling Task – Connecting the New Data to the Database</a></li>
							</ol>
						</li>
					</ol>
				</li>
			</ol>
		</nav>
		<nav epub:type="landmarks">
		<h2>Landmarks</h2>
			<ol>
				<li><a epub:type="cover" href="Images/cover.xhtml">Cover</a></li>
				<li><a epub:type="toc" href="B15780_FM_Final_SMP.xhtml#_idContainer004">Table of Contents</a></li>
			</ol>
		</nav>
	</div></body></html>