<html><head></head><body><div><div><div><div><h1 class="title"><a id="ch04"/>Chapter 4. Linear Algebra – Arrays</h1></div></div></div><p>Linear algebra is one of the essential building blocks of computational mathematics. The objects of linear algebra are vectors and matrices. The package NumPy includes all the necessary tools to manipulate those objects.</p><p>The first task is to build matrices and vectors, or to alter existing ones by slicing. The other main task is the <code class="literal">dot</code> operation, which embodies most of the linear algebra operations (scalar product, matrix-vector product, and matrix-matrix product). Finally, various methods are available to solve linear problems.</p><div><div><div><div><h1 class="title"><a id="ch04lvl1sec31"/>Overview of the array type</h1></div></div></div><p>For the impatient, here is how to use arrays in a nutshell. Be aware though that the behavior of arrays may be surprising at first, so we encourage you to read on after this introductory section.</p><div><div><div><div><h2 class="title"><a id="ch04lvl2sec45"/>Vectors and matrices</h2></div></div></div><p>Creating vectors is as simple as using the function <code class="literal">array</code>  to convert a list to an array:</p><pre class="programlisting">v = array([1.,2.,3.])</pre><p>The object <code class="literal">v</code>  is now a vector that behaves much like a vector in linear algebra. We have already emphasized the differences with the list object in Python (refer to section <em>Arrays</em> in <a class="link" href="ch03.html" title="Chapter 3. Container Types">Chapter 3</a>, <em>Containers Type)</em>. Here are some illustrations of the basic linear algebra operations on vectors:</p><pre class="programlisting"># two vectors with three components&#13;
v1 = array([1., 2., 3.])&#13;
v2 = array([2, 0, 1.])&#13;
&#13;
# scalar multiplications/divisions&#13;
2*v1 # array([2., 4., 6.])&#13;
v1/2 # array([0.5, 1., 1.5])&#13;
&#13;
# linear combinations&#13;
3*v1 # array([ 3., 6., 9.])&#13;
3*v1 + 2*v2 # array([ 7., 6., 11.])&#13;
&#13;
# norm&#13;
from scipy.linalg import norm&#13;
norm(v1) # 3.7416573867739413&#13;
# scalar product&#13;
dot(v1, v2) # 5.&#13;
v1 @ v2 # 5 ; alternative formulation</pre><p>Note that all basic arithmetic operations are performed elementwise:</p><pre class="programlisting"># elementwise operations:&#13;
v1 * v2 # array([2., 0., 3.])&#13;
v2 / v1 # array([2.,0.,.333333])&#13;
v1 - v2 # array([-1., 2., 2.])&#13;
v1 + v2 # array([ 3., 2., 4.])</pre><p>Some functions act elementwise on arrays as well:</p><pre class="programlisting">cos(v1) # cosine, elementwise: array([ 0.5403,&#13;
                                 -0.4161, -0.9899])</pre><p>This subject will be covered in the section <em>Functions Acting on Arrays.</em>
</p><p>A matrix is created in a similar way to a vector, but from a list of lists instead:</p><pre class="programlisting">M = array([[1.,2],[0.,1]])</pre><div><div><h3 class="title"><a id="note14"/>Note</h3><p><strong>Vectors are no column - and no row matrices</strong></p><p>The <em>n</em> vector, an <em>n</em> × 1, and a 1 × n matrix are three different objects even if they contain the same data.</p></div></div><p>To create a row matrix containing the same data as the vector <code class="literal">v = array([1., 2., 1.])</code>, we do this:</p><pre class="programlisting">R = array([[1.,2.,1.]]) # notice the double brackets: &#13;
                        # this is a matrix&#13;
shape(R)                # (1,3): this is a row matrix</pre><p>The corresponding column matrix is obtained by the method <code class="literal">reshape</code>:</p><pre class="programlisting">C = array([1., 2., 1.]).reshape(3, 1)&#13;
shape(C) # (3,1): this is a column matrix</pre></div><div><div><div><div><h2 class="title"><a id="ch04lvl2sec46"/>Indexing and slices</h2></div></div></div><p>Indexing and slicing are similar to that of a list. The main difference is that there may be several indexes or slices when the array is a matrix. The subject will be covered in depth in section <em>Array indexing;</em> here, we just give some illustrating examples of indexing and slicing:</p><pre class="programlisting">v = array([1., 2., 3])&#13;
M = array([[1., 2],[3., 4]])&#13;
&#13;
v[0] # works as for lists&#13;
v[1:] # array([2., 3.])&#13;
&#13;
M[0, 0] # 1.&#13;
M[1:] # returns the matrix array([[3., 4]])&#13;
M[1] # returns the vector array([3., 4.])&#13;
&#13;
# access&#13;
v[0] # 1.&#13;
v[0] = 10&#13;
&#13;
# slices&#13;
v[:2] # array([10., 2.])&#13;
v[:2] = [0, 1] # now v == array([0., 1., 3.])&#13;
v[:2] = [1, 2, 3] # error!</pre></div><div><div><div><div><h2 class="title"><a id="ch04lvl2sec47"/>Linear algebra operations</h2></div></div></div><p>The essential operator that performs most of the usual operations of linear algebra is the Python function <code class="literal">dot</code>. It is used for matrix-vector multiplications:</p><pre class="programlisting">dot(M, v) # matrix vector multiplication; returns a vector&#13;
M @ v # alternative formulation</pre><p>It may be used to compute a scalar product between two vectors:</p><pre class="programlisting">dot(v, w) # scalar product; the result is a scalar&#13;
v @ w # alternative formulation</pre><p>Lastly, it is used to compute matrix-matrix products:</p><pre class="programlisting">dot(M, N) # results in a matrix&#13;
M @ N # alternative formulation</pre><div><div><div><div><h3 class="title"><a id="ch04lvl3sec10"/>Solving a linear system</h3></div></div></div><p>If <em>A</em> is a matrix and <em>b</em> is a vector, you can solve the linear equation:</p><p>
</p><div><img src="img/linsystem.jpg" alt="Solving a linear system"/></div><p>
</p><p>Using the <code class="literal">solve</code> method, which has this syntax:</p><pre class="programlisting">from scipy.linalg import solve&#13;
x = solve(A, b)</pre><p>For example, we want to solve:</p><p>
</p><div><img src="img/b05511_06_1200.jpg" alt="Solving a linear system"/></div><p>
</p><p>Here is the solution for the preceding equation:</p><pre class="programlisting">from scipy.linalg import solve&#13;
A = array([[1., 2.], [3., 4.]])&#13;
b = array([1., 4.])&#13;
x = solve(A, b)&#13;
allclose(dot(A, x), b) # True&#13;
allclose(A @ x, b) # alternative formulation</pre><p>The command <code class="literal">allclose</code> is used here to compare two vectors. If they are close enough to each other, this command returns <code class="literal">True</code>. Optionally a tolerance value can be set. For more methods related to linear equations systems, refer to section <em>Linear algebra methods in SciPy</em>.</p></div></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch04lvl1sec32"/>Mathematical preliminaries</h1></div></div></div><p>In order to understand how arrays work in NumPy, it is useful to understand the mathematical parallel between accessing tensor (matrix and vector) elements by indexes and evaluating mathematical functions by providing arguments. We also cover in this section the generalization of the dot product as a reduction operator.</p><div><div><div><div><h2 class="title"><a id="ch04lvl4sec0"/>Arrays as functions</h2></div></div></div><p>Arrays may be considered from several different points of view. We believe that the most fruitful one in order to understand arrays is that of functions of several variables.</p><p>For instance, selecting a component of a given vector in <em>ℝ</em><sup><em>n</em>
</sup> may just be considered a function from the set of ℕ<sub><em>n</em></sub> to ℝ, where we define the set:</p><p>
</p><div><img src="img/somenumbers.jpg" alt="Arrays as functions"/></div><p>
</p><p>Here the set ℕ<sub>n</sub> has <em>n</em> elements. The Python function <code class="literal">range</code> generates ℕ<sub><em>n</em></sub>.</p><p>Selecting an element of a given matrix, on the other hand, is a function of two parameters, taking its value in ℝ. Picking a particular element of an <em>m</em> × <em>n</em> matrix may thus be considered a function from ℕ<sub><em>m</em></sub> × ℕ<sub><em>n</em></sub> to ℝ.</p></div><div><div><div><div><h2 class="title"><a id="ch04lvl4sec1"/>Operations are elementwise</h2></div></div></div><p>NumPy arrays are essentially treated as mathematical functions. This is in particular true for operations. Consider two functions, <em>f</em> and <em>g</em>, defined on the same domain and taking real values. The product <em>f g</em> of those two functions is defined as the pointwise product, that is:</p><p>
</p><div><img src="img/pointwiseproduct.jpg" alt="Operations are elementwise"/></div><p>
</p><p>Note that this construction is possible for any operation between two functions. For an arbitrary operation defined on two scalars, which we denote here by <img src="img/star.jpg" alt="Operations are elementwise"/>, we could define <img src="img/fstarg.jpg" alt="Operations are elementwise"/> as follows:</p><p>
</p><div><img src="img/starop.jpg" alt="Operations are elementwise"/></div><p>
</p><p>This innocuous remark allows us to understand NumPy's stance on operations; all operations are elementwise in arrays. For instance, the product between two matrices <em>m</em> and <em>n</em> is defined, as with functions, as follows:</p><p>
</p><div><img src="img/indexfunction.jpg" alt="Operations are elementwise"/></div><p>
</p></div><div><div><div><div><h2 class="title"><a id="ch04lvl4sec2"/>Shape and number of dimensions</h2></div></div></div><p>There is a clear distinction between a:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><strong>Scalar</strong>: Function with no arguments</li><li class="listitem" style="list-style-type: disc"><strong>Vector</strong>: Function with one argument</li><li class="listitem" style="list-style-type: disc"><strong>Matrix</strong>: Function with two arguments</li><li class="listitem" style="list-style-type: disc"><strong>Higher order tensor</strong>: Function with more than two arguments</li></ul></div><p>In what follows, the number of dimensions is the number of arguments of a function. The shape corresponds essentially to the domain of definition of a function.</p><p>For instance, a vector of size <em>n</em> is a function from the set ℕ<sub><em>n</em></sub> to ℝ. As a result, its domain of definition is ℕ<sub><em>n</em></sub>. Its shape is defined as the singleton (<em>n,</em>). Similarly, a matrix of size <em>m</em> × <em>n</em> is a function defined on ℕ<sub><em>m</em></sub> × ℕ<sub><em>m</em></sub>. The corresponding shape is simply the pair (<em>m</em>, <em>n</em>). The shape of an array is obtained by the <code class="literal">numpy.shape</code> function, and the number of dimensions by the <code class="literal">numpy.ndim</code> function.</p></div><div><div><div><div><h2 class="title"><a id="ch04lvl4sec3"/>The dot operations</h2></div></div></div><p>Treating arrays as functions, although very powerful, completely neglects the linear algebra structures we are familiar with, that is, matrix-vector and matrix-matrix operations. Fortunately, these linear algebra operations may all be written in a similar unified form:</p><p>The vector-vector operation:</p><p>    </p><div><img src="img/B05511_04_02.jpg" alt="The dot operations"/></div><p>
</p><p>The matrix-vector operation:</p><p>    </p><div><img src="img/B05511_04_03.jpg" alt="The dot operations"/></div><p>
</p><p>The matrix-matrix operation:</p><p>    </p><div><img src="img/B05511_04_04.jpg" alt="The dot operations"/></div><p>
</p><p>The vector-matrix operation:</p><p>     </p><div><img src="img/B05511_04_05.jpg" alt="The dot operations"/></div><p>
</p><p>The essential mathematical concept is that of reduction. For a matrix-vector operation, the reduction is given by:</p><p>    </p><div><img src="img/B05511_04_06.jpg" alt="The dot operations"/></div><p>
</p><p>In general, a reduction operation defined between two tensors <em>T</em> and <em>U</em> of respective number of dimensions <em>m</em> and <em>n</em> may be defined as:</p><p>
</p><div><img src="img/B05511_04_07-1.jpg" alt="The dot operations"/></div><p>
</p><p>Clearly, the shapes of the tensors must be compatible for that operation to make any sense. This requirement is familiar for matrix-matrix multiplication. The multiplication <em>M N</em> of matrices <em>M</em> and <em>N</em> only makes sense if the number of columns of <em>M</em> equals the number of rows of <em>N</em>.</p><p>Another consequence of the reduction operation is that it produces a new tensor with <em>m + n - 2</em> dimensions. In the following table, we gather the output of the reduction operation for the familiar cases involving matrices and vectors:</p><p>
</p><div><img src="img/Table-4.1.jpg" alt="The dot operations"/></div><p>
</p><p>Table 4.1: Output of the reduction operation for the familiar cases involving matrices and vectors</p><p>In Python, all reduction operations are performed using the <code class="literal">dot</code> function:</p><pre class="programlisting">angle = pi/3&#13;
M = array([[cos(angle), -sin(angle)], &#13;
           [sin(angle), cos(angle)]])&#13;
v = array([1., 0.])&#13;
y = dot(M, v)</pre><p>As in mathematical textbooks, also in modern Python (Version 3.5 and higher), the dot product is sometimes preferred to be written in its operator form, <code class="literal">dot(M, v)</code>, or by using the more handy infix notation, <code class="literal">M @ v</code>. From now on we stick to the operator form; you can modify the examples if the other form is preferred.</p><div><div><h3 class="title"><a id="note15"/>Note</h3><p><strong>Elementwise versus matrix multiplication</strong></p><p>The multiplication operator <code class="literal">*</code> is always elementwise. It has nothing to do with the dot operation. Even if <em>A</em> is a matrix and <em>v</em> is a vector, <em>A*v</em> is still a legal operation.</p><p>The matrix-vector multiplication is performed using the <code class="literal">dot</code> function. Refer to section <em>Broadcasting</em> of <a class="link" href="ch05.html" title="Chapter 5. Advanced Array Concepts">Chapter 5</a>, <em>Advanced Array Concepts</em>, for more information.</p></div></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch04lvl1sec33"/>The array type</h1></div></div></div><p>The objects used to manipulate vectors, matrices, and more general tensors in NumPy are called arrays. In this section, we examine their essential properties, how to create them, and how to access their information.</p><div><div><div><div><h2 class="title"><a id="ch04lvl2sec48"/>Array properties</h2></div></div></div><p>Arrays are essentially characterized by three properties, which is given in the following table (<em>Table 4.2</em>):</p><div><table border="1"><colgroup><col/><col/></colgroup><tbody><tr><td>
<p>
<strong>Name</strong>
</p>
</td><td>
<p>
<strong>Description</strong>
</p>
</td></tr><tr><td>
<p>
<code class="literal">shape</code>
</p>
</td><td>
<p>It describes how the data should be interpreted, as a vector, a matrix or as a higher order tensor, and it gives the corresponding dimension. It is accessed with the <code class="literal">shape</code> attribute.</p>
</td></tr><tr><td>
<p>
<code class="literal">dtype</code>
</p>
</td><td>
<p>It gives the type of the underlying data (float, complex, integer, and so on).</p>
</td></tr><tr><td>
<p>
<code class="literal">strides</code>
</p>
</td><td>
<p>This attribute specifies in which order the data should be read. For instance, a matrix could be stored in memory contiguously column by column (the FORTRAN convention), or row by row (the C convention). The attribute is a tuple with the numbers of bytes that have to be skipped in memory to reach the next row and the number of bytes to be skipped to reach the next column. The <code class="literal">strides</code> attribute even allows for a more flexible interpretation of the data in memory, which is what makes array views possible.</p>
</td></tr></tbody></table></div><p>Table 4.2 : Properties of Arrays</p><p>Consider the following array:</p><pre class="programlisting">A = array([[1, 2, 3], [3, 4, 6]])&#13;
A.shape   # (2, 3)&#13;
A.dtype   # dtype('int64')&#13;
A.strides # (24, 8)</pre><p>Its elements have type <code class="literal">'int64'</code>; that is, they use 64 bits or 8 bytes in memory. The complete array is stored in memory row-wise. The distance from <code class="literal">A[0, 0]</code> to the first element in the next row <code class="literal">A[1,0]</code> is thus 24 bytes (three matrix elements) in memory. Correspondingly, the distance in memory between <code class="literal">A[0,0]</code> and <code class="literal">A[0,1]</code> is 8 bytes (one matrix element). These values are stored in the attribute <code class="literal">strides</code> .</p></div><div><div><div><div><h2 class="title"><a id="ch04lvl2sec49"/>Creating arrays from lists</h2></div></div></div><p>The general syntax to create an array is the function <code class="literal">array</code> . The syntax to create a real vector would be:</p><pre class="programlisting">V = array([1., 2., 1.], dtype=float)</pre><p>To create a complex vector with the same data:</p><pre class="programlisting">V = array([1., 2., 1.], dtype=complex)</pre><p>When no type is specified, the type is guessed. The <code class="literal">array</code> function chooses the type that allows storing of all the specified values:</p><pre class="programlisting">V = array([1, 2]) # [1, 2] is a list of integers&#13;
V.dtype # int&#13;
V = array([1., 2]) # [1., 2] mix float/integer&#13;
V.dtype # float&#13;
V = array([1. + 0j, 2.]) # mix float/complex&#13;
V.dtype # complex</pre><p>
<strong>Silent type conversion</strong>
NumPy silently casts floats into integers, which might give unexpected results:</p><pre class="programlisting">a = array([1, 2, 3])&#13;
a[0] = 0.5&#13;
a # now: array([0, 2, 3])</pre><p>The same often unexpected array type casting happens from complex to float.</p><p>
<strong>Array and Python parentheses</strong>
</p><p>As we have noticed in section <em>Program and program flow </em>in <a class="link" href="ch01.html" title="Chapter 1. Getting Started">Chapter 1</a>,<em> Getting Started</em>, Python allows a line break when some opening brace or parenthesis is not closed. This allows a convenient syntax for array creation, which makes it more pleasing to the human eye:</p><pre class="programlisting"> # the identity matrix in 2D&#13;
 Id = array([[1., 0.], [0., 1.]])&#13;
 # Python allows this:&#13;
 Id = array([[1., 0.],&#13;
             [0., 1.]])&#13;
 # which is more readable</pre></div></div>
<div><div><div><div><h1 class="title"><a id="ch04lvl1sec34"/>Accessing array entries</h1></div></div></div><p>Array entries are accessed by indexes. In contrast to vector coefficients two indexes are needed to access matrix coefficients. These are given in one pair of brackets. This distinguishes the array syntax from a list of lists. There, two pairs of brackets are needed to access elements.</p><pre class="programlisting">M = array([[1., 2.],[3., 4.]])&#13;
M[0, 0] # first row, first column: 1.&#13;
M[-1, 0] # last row, first column: 3.</pre><div><div><div><div><h2 class="title"><a id="ch04lvl2sec50"/>Basic array slicing</h2></div></div></div><p>Slices are similar to those of lists except that there might now be in more than one dimension:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">M[i,:]</code> is a vector filled by the row <em>i</em> of <em>M.</em></li><li class="listitem" style="list-style-type: disc"><code class="literal">M[:,j]</code> is a vector filled by the column<em> i</em> of <em>M.</em></li><li class="listitem" style="list-style-type: disc"><code class="literal">M[2:4,:]</code> is a slice of <code class="literal">2:4</code> on the rows only.</li><li class="listitem" style="list-style-type: disc"><code class="literal">M[2:4,1:4]</code> is a slice on rows and columns.</li></ul></div><p>The result of matrix slicing is given in the following figure (<em>Figure 4.1</em>):</p><p>
</p><div><img src="img/array_slice.jpg" alt="Basic array slicing"/></div><p>
</p><p>Figure 4.1: The result of matrix slicing</p><div><div><h3 class="title"><a id="note16"/>Note</h3><p>
<strong>Omitting a dimension</strong></p><p>If you omit an index or a slice, NumPy assumes you are taking rows only. <code class="literal">M[3]</code> is a vector that is a view on the third row of <em>M </em>and <code class="literal">M[1:3]</code> is a matrix that is a view on the second and third rows of <em>M.</em></p></div></div><p>Changing the elements of a slice affects the entire array:</p><pre class="programlisting">v = array([1., 2., 3.])&#13;
v1 = v[:2] # v1 is array([1., 2.])&#13;
v1[0] = 0. # if v1 is changed ...&#13;
v # ... v is changed too: array([0., 2., 3.])</pre><p>General slicing rules are given in the following table (<em>Table 4.3)</em>:</p><p>
</p><div><img src="img/Table-4.3.jpg" alt="Basic array slicing"/></div><p>
</p><p>Table 4.3: General Slicing Rules</p><p>The results of slicing operations for an array <code class="literal">M</code> of shape <em>(4, 4)</em> are given in the following table (<em>Table 4.4</em>):</p><p>
</p><div><img src="img/Table-4.4.jpg" alt="Basic array slicing"/></div><p>
</p><p>Table 4.4: Result of slicing operation for an array M of shape (4,4)</p></div><div><div><div><div><h2 class="title"><a id="ch04lvl2sec51"/>Altering an array using slices</h2></div></div></div><p>You may alter an array using slices or by direct access. The following changes only one element in a 5 × 3 matrix <code class="literal">M</code>:</p><pre class="programlisting">M[1, 3] = 2.0 # scalar</pre><p>But we may change one full row of the matrix:</p><pre class="programlisting">M[2, :] = [1., 2., 3.] # vector</pre><p>We may also replace a full submatrix:</p><pre class="programlisting">M[1:3, :] = array([[1., 2., 3.],[-1.,-2., -3.]])</pre><div><div><h3 class="title"><a id="note17"/>Note</h3><p>There is a distinction between a column matrix and a vector. The following assignment with a column matrix returns no error
<code class="literal">M[1:4, 2:3] = array([[1.],[0.],[-1.0]])</code>
while the assignment with a vector returns a <code class="literal">Value Error</code>
<code class="literal">M[1:4, 2:3] = array([1., 0., -1.0]) #  error</code>
</p></div></div><p>The general slicing rules are shown in <em>Table 4.2</em>. The matrices and vectors in the preceding examples must have the right size to fit into matrix <em>M</em>. You may also make use of the broadcasting rules (for more information, refer to section <em>Broadcasting</em> of <a class="link" href="ch05.html" title="Chapter 5. Advanced Array Concepts">Chapter 5</a>, <em>Advanced Array Concepts</em>) to determine the allowed size of the replacement arrays. If the replacement array does not have the right shape, a <code class="literal">ValueError</code> exception will be raised.</p></div></div>
<div><div><div><div><h1 class="title"><a id="ch04lvl1sec35"/>Functions to construct arrays</h1></div></div></div><p>The usual way to set up an array is via a list. But there are also a couple of convenient methods for generating special arrays, which are given in the following table (<em>Table 4.5</em>):</p><div><table border="1"><colgroup><col/><col/><col/></colgroup><tbody><tr><td>
<p>
<strong>Methods</strong>
</p>
</td><td>
<p>
<strong>Shape</strong>
</p>
</td><td>
<p>
<strong>Generates</strong>
</p>
</td></tr><tr><td>
<p> <code class="literal">zeros((n,m))</code>
</p>
</td><td>
<p>
<em>(n,m)</em>
</p>
</td><td>
<p>Matrix filled with zeros</p>
</td></tr><tr><td>
<p>
<code class="literal">ones((n,m)) </code>
</p>
</td><td>
<p>
<em>(n,m)</em>
</p>
</td><td>
<p>Matrix filled with ones</p>
</td></tr><tr><td>
<p>
<code class="literal">diag(v,k) </code>
</p>
</td><td>
<p>
<em>(n,n)</em>
</p>
</td><td>
<p>(Sub-, super-) diagonal matrix from a vector <em>v</em>
</p>
</td></tr><tr><td>
<p>
<code class="literal">random.rand(n,m) </code>
</p>
</td><td>
<p>
<em>(n,m)</em>
</p>
</td><td>
<p>Matrix filled with uniformly distributed random numbers in (0,1)</p>
</td></tr><tr><td>
<p> <code class="literal">arange(n)</code>
</p>
</td><td>
<p>
<em>(n,)</em>
</p>
</td><td>
<p>First <em>n</em> integers</p>
</td></tr><tr><td>
<p>
<code class="literal">linspace(a,b,n) </code>
</p>
</td><td>
<p>
<em>(n,)</em>
</p>
</td><td>
<p>Vector with <em>n</em> equispaced points between <em>a</em> and <em>b</em>
</p>
</td></tr></tbody></table></div><p>Table 4.5: Commands to create arrays</p><p>These commands may take additional arguments. In particular, the commands <code class="literal">zeros</code>, <code class="literal">ones</code>, and <code class="literal">arange</code> take <code class="literal">dtype</code> as an optional argument. The default type is <code class="literal">float</code>, except for <code class="literal">arange</code>. There are also methods such as <code class="literal">zeros_like</code> and <code class="literal">ones_like</code>, which are slight variants of the preceding ones. For instance, the <code class="literal">zeros_like(A)</code> method is equivalent to <code class="literal">zeros(shape(A))</code>.</p><p>Here is the <code class="literal">identity</code> function, which constructs an identity matrix of a given size:</p><pre class="programlisting">I = identity(3)</pre><p>The command is identical to:</p><pre class="programlisting">I = array([[ 1., 0., 0.],&#13;
           [ 0., 1., 0.],&#13;
           [ 0., 0., 1.]])</pre></div>
<div><div><div><div><h1 class="title"><a id="ch04lvl1sec36"/>Accessing and changing the shape</h1></div></div></div><p>The number of dimensions is what distinguishes a vector from a matrix. The <strong>shape</strong> is what distinguishes vectors of different sizes, or matrices of different sizes. In this section, we examine how to obtain and change the shape of an array.</p><div><div><div><div><h2 class="title"><a id="ch04lvl2sec52"/>The shape function</h2></div></div></div><p>The shape of a matrix is the tuple of its dimensions. The shape of an n × m matrix is the tuple <code class="literal">(n, m)</code>. It can be obtained by the <code class="literal">shape</code> function:</p><pre class="programlisting">M = identity(3)&#13;
shape(M) # (3, 3)</pre><p>For a vector, the shape is a singleton containing the length of that vector:</p><pre class="programlisting">v = array([1., 2., 1., 4.])&#13;
shape(v) # (4,) &lt;- singleton (1-tuple)</pre><p>An alternative is to use the array attribute <code class="literal">shape</code>, which gives  the same result:</p><pre class="programlisting">M = array([[1.,2.]])&#13;
shape(M) # (1,2)&#13;
M.shape # (1,2)</pre><p>However, the advantage of using  <code class="literal">shape</code> as a function is that this function may be used on scalars and lists as well. This may come in handy when code is supposed to work with both scalars and arrays:</p><pre class="programlisting">shape(1.) # ()&#13;
shape([1,2]) # (2,)&#13;
shape([[1,2]]) # (1,2)</pre></div><div><div><div><div><h2 class="title"><a id="ch04lvl2sec53"/>Number of dimensions</h2></div></div></div><p>The number of dimensions of an array is obtained with the function <code class="literal">numpy.ndim</code>  or using the array attribute <code class="literal">ndarray.ndim</code> :</p><pre class="programlisting">ndim(A) # 2&#13;
A.ndim # 2</pre><p>Note that the number of dimensions, given by the function <code class="literal">ndim</code>, of a tensor <code class="literal">T</code> (a vector, matrix, or higher order tensor) is always equal to the length of its shape:</p><pre class="programlisting">T = zeros((2,2,3)) # tensor of shape (2,2,3); three dimensions&#13;
ndim(T) # 3&#13;
len(shape(T)) # 3</pre></div><div><div><div><div><h2 class="title"><a id="ch04lvl2sec54"/>Reshape</h2></div></div></div><p>The method <code class="literal">reshape</code> gives a new view of the array, with a new shape, without copying the data:</p><pre class="programlisting">v = array([0,1,2,3,4,5])&#13;
M = v.reshape(2,3)&#13;
shape(M) # returns (2,3)&#13;
M[0,0] = 10 # now v[0] is 10</pre><div><div><h3 class="title"><a id="tip18"/>Tip</h3><p><strong>Reshape does not copy</strong></p><p>Reshape does not create a new array. It rather gives a new view on the existing array. In the preceding example, changing one element of <code class="literal">M</code> would automatically result in a change in the corresponding element in <code class="literal">v</code>. When this behavior is not acceptable, you need to copy the data.</p></div></div><p>The various effects of the <code class="literal">reshape</code> method on an array defined by <code class="literal">arange(6)</code> are given in the following figure :</p><p>
</p><div><img src="img/array_reshape.jpg" alt="Reshape"/></div><p>
</p><p>Figure 4.2: The various effects of the reshape method on an array defined by arange(6)</p><p>If one tries to reshape an array with a shape that does not multiply to the original shape, an error is raised:</p><pre class="programlisting"> ValueError: total size of new array must be unchanged.</pre><p>Sometimes, it is convenient to specify only one shape parameter and let Python determine the other in such a way that it multiplies to the original shape. This is done by setting the free shape parameter <code class="literal">-1</code>:</p><pre class="programlisting">v = array([1, 2, 3, 4, 5, 6, 7, 8])&#13;
M = v.reshape(2, -1)&#13;
shape(M) # returns (2, 4)&#13;
M = v.reshape(-1, 2)&#13;
shape(M) # returns (4,2 )&#13;
M = v.reshape(3,- 1) # returns error</pre><div><div><div><div><h3 class="title"><a id="ch04lvl3sec11"/>Transpose</h3></div></div></div><p>A special form of reshaping is transposing. It just switches the two shape elements of the matrix. The transpose of a matrix <em>A</em> is a matrix <em>B</em> such that:</p><p>
</p><div><img src="img/transpose.jpg" alt="Transpose"/></div><p>
</p><p>Which is resolved in the following way:</p><pre class="programlisting">A = ...&#13;
shape(A) # 3,4&#13;
&#13;
B = A.T # A transpose&#13;
shape(B) # 4,3</pre><div><div><h3 class="title"><a id="tip19"/>Tip</h3><p><strong>Transpose does not copy</strong></p><p>Transposition is very similar to reshaping. In particular, it does not copy the data either and just returns a view on the same array:</p><pre class="programlisting">A= array([[ 1., 2.],[ 3., 4.]])
B=A.T
A[1,1]=5.
B[1,1] # 5</pre></div></div><p>Transposing a vector makes no sense since vectors are tensors of one dimension, that is, functions of one variable. NumPy will, however, comply and return exactly the same object:</p><pre class="programlisting">v = array([1., 2., 3.])&#13;
v.T # exactly the same vector!</pre><p>What you have in mind when you want to transpose a vector is probably to create a row or column matrix. This is done using <code class="literal">reshape</code>:</p><pre class="programlisting">v.reshape(-1, 1) # column matrix containing v&#13;
v.reshape(1, -1) # row matrix containing v</pre></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch04lvl1sec37"/>Stacking</h1></div></div></div><p>The universal method to build matrices from a couple of (matching) submatrices is <code class="literal">concatenate</code>. Its syntax is:</p><pre class="programlisting">concatenate((a1, a2, ...), axis = 0)</pre><p>This command stacks the submatrices vertically (on top of each other) when <code class="literal">axis=0</code> is specified. With the <code class="literal">axis=1</code> argument, they are stacked horizontally, and this generalizes according to arrays with more dimensions. This function is called by several convenient functions, as follows:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">hstack</code>: Used to stack matrices horizontally</li><li class="listitem" style="list-style-type: disc"><code class="literal">vstack</code>: Used to stack matrices vertically</li><li class="listitem" style="list-style-type: disc"><code class="literal">columnstack</code>: Used to stack vectors in columns</li></ul></div><div><div><div><div><h2 class="title"><a id="ch04lvl2sec55"/>Stacking vectors</h2></div></div></div><p>One may stack vectors row-wise or column-wise using <code class="literal">vstack</code> and <code class="literal">column_stack</code>, as illustrated in the following figure:</p><p>
</p><div><img src="img/array_stack.jpg" alt="Stacking vectors"/></div><p>
</p><div><div><h3 class="title"><a id="tip20"/>Tip</h3><p>
<code class="literal">hstack</code> would produce the concatenation of v1 and v2. </p></div></div><p>Let us consider the symplectic permutation as an example for vector stacking:
We have a vector of size 2<em>n</em>. We want to perform a symplectic transformation of a vector with an even number of components, that is, exchange the first half with the second half of the vector with sign change:</p><p>
</p><div><img src="img/symplectic.jpg" alt="Stacking vectors"/></div><p>
</p><p>This operation is resolved in Python as follows:</p><pre class="programlisting"># v is supposed to have an even length.&#13;
def symp(v):&#13;
    n = len(v) // 2 # use the integer division //&#13;
    return hstack([v[-n:], -v[:n]])</pre></div></div>
<div><div><div><div><h1 class="title"><a id="ch04lvl1sec38"/>Functions acting on arrays</h1></div></div></div><p>There are different types of functions acting on arrays. Some act elementwise, and they return an array of the same shape. Those are called universal functions. Other array functions return an array of a different shape.</p><div><div><div><div><h2 class="title"><a id="ch04lvl2sec56"/>Universal functions</h2></div></div></div><p>Universal functions are functions that act elementwise on arrays. They thus have an output array that has the same shape as the input array. These functions allow us to compute the result of a scalar function on a whole array at once.</p><div><div><div><div><h3 class="title"><a id="ch04lvl3sec12"/>Built-in universal functions</h3></div></div></div><p>A typical example is the <code class="literal">cos</code> function (the one provided by NumPy):</p><pre class="programlisting">cos(pi) # -1&#13;
cos(array([[0, pi/2, pi]])) # array([[1, 0, -1]])</pre><p>Note that universal functions work on arrays in a componentwise manner. This is also true for operators, such as multiplication or exponent:</p><pre class="programlisting">2 * array([2, 4]) # array([4, 8])&#13;
array([1, 2]) * array([1, 8]) # array([1, 16])&#13;
array([1, 2])**2 # array([1, 4])&#13;
2**array([1, 2]) # array([1, 4])&#13;
array([1, 2])**array([1, 2]) # array([1, 4])</pre></div><div><div><div><div><h3 class="title"><a id="ch04lvl3sec13"/>Create universal functions</h3></div></div></div><p>Your function will automatically be universal if you use only universal functions in it. If, however, your function uses functions that are not universal, you might get scalar results, or even an error, when trying to apply them on an array:</p><pre class="programlisting">def const(x):&#13;
    return 1&#13;
const(array([0, 2])) # returns 1 instead of array([1, 1])</pre><p>Another example is the following:</p><pre class="programlisting">def heaviside(x):&#13;
    if x &gt;= 0:&#13;
        return 1.&#13;
    else: &#13;
        return 0.&#13;
 &#13;
heaviside(array([-1, 2])) # error</pre><p>The expected behaviour would be that the <code class="literal">heaviside</code> function applied to a vector <code class="literal">[<em>a</em>, <em>b</em>]</code> would return <code class="literal">[heaviside(<em>a</em>), heaviside(<em>b</em>)]</code>. Alas, this does not work because the function always returns a scalar, no matter the size of the input argument. Besides, using the function with an array input would raise an exception. The NumPy function <code class="literal">vectorize</code> allows us to quickly solve this problem:</p><pre class="programlisting">vheaviside = vectorize(heaviside)&#13;
vheaviside(array([-1, 2])) # array([0, 1]) as expected</pre><p>A typical application of this method is its use when plotting a function:</p><pre class="programlisting">xvals = linspace(-1, 1, 100)&#13;
plot(xvals, vectorize(heaviside)(xvals))&#13;
axis([-1.5, 1.5, -0.5, 1.5])</pre><p>The following graph shows the heaviside function:</p><p>
</p><div><img src="img/heaviside.jpg" alt="Create universal functions"/></div><p>
</p><div><div><h3 class="title"><a id="tip21"/>Tip</h3><p>The <code class="literal">vectorize</code> function does not improve performance<em>. </em>It provides only a convenient way to quickly transform a function, so that it operates elementwise on list and arrays.</p></div></div></div></div><div><div><div><div><h2 class="title"><a id="ch04lvl2sec57"/>Array functions</h2></div></div></div><p>There are a number of functions acting on arrays that do not act componentwise. Examples of such functions are <code class="literal">max</code>, <code class="literal">min</code>, and <code class="literal">sum</code>. These functions may operate on the whole matrix, row-wise, or column-wise. When no argument is provided, they act on the whole matrix. Suppose <code class="literal">A</code> is the following matrix:</p><p>
</p><div><img src="img/array_methods_1.jpg" alt="Array functions"/></div><p>
</p><p>The <code class="literal">sum</code> function acting on that matrix returns a scalar:</p><pre class="programlisting">sum(A) # 36</pre><p>The command has an optional parameter, <code class="literal">axis</code> . It allows us to choose along which axis to perform the operation. For instance, if the axis is <em>0</em>, it means that the sum should be computed along the first axis. The sum along axis <em>0</em> of an array of shape (<em>m</em>, <em>n</em>) will be a vector of length <em>n</em>.</p><p>Suppose we compute the sum of <code class="literal">A</code> along the axis 0:</p><pre class="programlisting">sum(A, axis=0) # array([ 6, 8, 10, 12])</pre><p>This amounts to computing the sum on the columns:</p><p>
</p><div><img src="img/array_methods_2.jpg" alt="Array functions"/></div><p>
</p><p>The result is a vector:</p><p>
</p><div><img src="img/array_methods_5.jpg" alt="Array functions"/></div><p>
</p><p>Now suppose we compute the sum along the axis <em>1</em>:</p><pre class="programlisting">A.sum(axis=1) # array([10, 26])</pre><p>This amounts to computing the sum on the rows:</p><p>
</p><div><img src="img/array_methods_4.jpg" alt="Array functions"/></div><p>
</p><p>The result is a vector:</p><p>
</p><div><img src="img/array_methods_3.jpg" alt="Array functions"/></div><p>
</p></div></div>
<div><div><div><div><h1 class="title"><a id="ch04lvl1sec39"/>Linear algebra methods in SciPy</h1></div></div></div><p>SciPy offers a large range of methods from numerical linear algebra in its <code class="literal">scipy.linalg</code> module. Many of these methods are Python wrapping programs from <code class="literal">LAPACK</code>, a collection of well-approved FORTRAN subroutines used to solve linear equation systems and eigenvalue problems. Linear algebra methods are the core of any method in scientific computing, and the fact that SciPy uses wrappers instead of pure Python code makes these central methods extremely fast. We present in detail here how two linear algebra problems are solved with SciPy to give you a flavour of this module.</p><div><div><div><div><h2 class="title"><a id="ch04lvl2sec58"/>Solving several linear equation systems with LU</h2></div></div></div><p>Let <em>A</em> be an <em>n × n</em> matrix and <em>b<sub>1</sub></em>, <em>b<sub>2</sub></em>, ..., <em>b<sub>k</sub></em> be a sequence of <em>n</em>-vectors. We consider the problem to find <em>n</em> vectors <em>x<sub>i</sub></em> such that:</p><p>
</p><div><img src="img/severallinsystems.jpg" alt="Solving several linear equation systems with LU"/></div><p>
</p><p>We assume that the vectors <em>b<sub>i</sub></em> are not known simultaneously. In particular, it is quite a common situation that the <em>i</em><sup>th</sup> problem has to be solved before <em>b<sub>i+1</sub></em> becomes available.</p><p>LU factorization is a way to organize the classical Gauss elimination method in such a way that the computation is done in two steps:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">A factorization step of the matrix <em>A</em> to get matrices in triangular form</li><li class="listitem" style="list-style-type: disc">A relatively cheap backward and forward elimination step that works on the <em>b<sub>i</sub></em>'s and benefits from the more time-consuming factorization step</li></ul></div><p>The method also uses the fact that if <em>P</em> is a permutation matrix such that <em>PA</em> is the original matrix with its rows permuted.</p><p>The two systems</p><p>
</p><div><img src="img/permutation.jpg" alt="Solving several linear equation systems with LU"/></div><p>
</p><p>have the same solution.</p><p>
<em>LU</em> factorization finds a permutation matrix <em>P</em>, a lower triangular matrix <em>L,</em> and an upper triangular matrix <em>U</em> such that:</p><p>
<img src="img/permutation2.jpg" alt="Solving several linear equation systems with LU"/> .</p><p>Such a factorization always exists. Furthermore, <em>L</em> can be determined in such a way that <em>L<sub>ii</sub> = 1</em>. Thus, the essential data from <em>L</em> that has to be stored is<em> L<sub>ij</sub></em> with <em>i &gt; j</em>. Consequently, <em>L</em> and <em>U</em> can be stored together in an <em>n</em> × <em>n</em> array, while the information about the permutation matrix <em>P</em> just requires an <em>n</em> integer vector – the pivot vector.</p><p>In SciPy, there are two methods to compute the <em>LU</em> factorization. The standard one is <code class="literal">scipy.linalg.lu</code>, which returns the three matrices <code class="literal">L</code>, <code class="literal">U</code>, and <code class="literal">P</code>. The other method is<code class="literal">lu_factor.</code> That is the method we describe here, because it will be conveniently used later in combination with <code class="literal">lu_solve</code>:</p><pre class="programlisting">import scipy.linalg as sl&#13;
[LU,piv] = sl.lu_factor(A)</pre><p>Here, the <code class="literal">A</code> matrix is factorized and an array with the information about <code class="literal">L</code> and <code class="literal">U</code> is returned, together with the pivot vector. With this information, the system can be solved by performing row interchanges of the vectors <em>b<sub>i</sub></em> according to the information stored in the pivot vector, backward substitution using <em>U,</em> and finally forward substitution using <em>L</em>. This is bundled in Python, in the <code class="literal">lu_solve</code> method. The following code snippet shows how the system <em>Ax<sub>i</sub> = b<sub>i</sub></em> is solved once the <em>LU</em> factorization is performed and its results stored in the tuple <code class="literal">(LU, piv)</code>:</p><pre class="programlisting">import scipy.linalg as sl&#13;
xi = sl.lu_solve((LU, piv), bi)</pre></div><div><div><div><div><h2 class="title"><a id="ch04lvl2sec59"/>Solving a least square problem with SVD</h2></div></div></div><p>A linear equation system <em>Ax = b</em>, with <em>A</em> being an <em>m</em> × <em>n</em> matrix and <em>m </em>&gt;<em> n</em>, is called an overdetermined linear system. In general it has no classical solution and one seeks a vector <em>x*</em> <img src="img/in.jpg" alt="Solving a least square problem with SVD"/>  ℝ<sup><em>n</em></sup> with the property:</p><p>
</p><div><img src="img/B05511_04_08.900.jpg" alt="Solving a least square problem with SVD"/></div><p>
</p><p>Here, <img src="img/norm.jpg" alt="Solving a least square problem with SVD"/> denotes the Euclidean vector norm <img src="img/B05511_04_09.jpg" alt="Solving a least square problem with SVD"/>.</p><p>This problem is called a least square problem. A stable method to solve it is based on factorizing <em>A = U</em>Σ<em>V<sup>T</sup></em>, with <em>U</em> being a <em>m</em> × <em>m</em> orthogonal matrix, <em>V</em> a <em>n</em> × <em>n</em> orthogonal matrix, and Σ = (σ<sub><em>ij</em></sub>) an <em>m</em> × <em>n</em> matrix with the property σ<sub><em>ij</em></sub> = 0 for all <em>i</em> ≠<em>j</em>. This factorization is called a <strong>singular value decomposition</strong> (<strong>SVD</strong>).</p><p>We write,</p><p>
</p><div><img src="img/B05511_04_10.jpg" alt="Solving a least square problem with SVD"/></div><p>
</p><p>with a diagonal <em>n</em> × <em>n</em> matrix Σ<sub><em>1</em></sub>. If we assume that <em>A</em> has full rank, then Σ<sub><em>1</em></sub>  is invertible and it can be shown that, <img src="img/B05511_04_11.jpg" alt="Solving a least square problem with SVD"/>. If we split <em>U</em> = [<em>U<sub>1</sub> U<sub>2</sub></em>] with <em>U<sub>1</sub></em> being an <em>m</em> × <em>n</em> submatrix, then the preceding equation can be simplified to <img src="img/B05511_04_12.jpg" alt="Solving a least square problem with SVD"/>.</p><p>SciPy provides a function called <code class="literal">svd</code>, which we use to solve this task:</p><pre class="programlisting">import scipy.linalg as sl &#13;
[U1, Sigma_1, VT] = sl.svd(A, full_matrices = False,&#13;
                              compute_uv = True) &#13;
xast = dot(VT.T, dot(U1.T, b) / Sigma_1)&#13;
r = dot(A, xast) - b # computes the residual&#13;
nr = sl.norm(r, 2) # computes the Euclidean norm of r</pre><p>The keyword <code class="literal">full_matrices</code> says that only the portion <em>U<sub>1</sub></em> of <em>U</em> needs to be computed. As one often uses <code class="literal">svd</code> to compute only singular values, σ<sub><em>ii</em></sub>, we have to explicitly demand the computation of <em>U</em> and <em>V</em> by using the keyword <code class="literal">compute_uv</code>. The SciPy function <code class="literal">scipy.linalg.lstsq</code> solves the least square problem similarly by using a singular value decomposition.</p></div><div><div><div><div><h2 class="title"><a id="ch04lvl2sec60"/>More methods</h2></div></div></div><p>In the examples so far, you met a couple of methods for computational tasks in linear algebra, for example, <code class="literal">solve</code>. Most common methods are available after the command <code class="literal">import scipy.linalg as sl</code> is executed. We refer to their documentation for further reference. Some linear algebra functions of the <code class="literal">scipy.linalg</code> module are given in the following table (<em>Table 4.6</em>):</p><div><table border="1"><colgroup><col/><col/></colgroup><tbody><tr><td>
<p>
<strong>Methods</strong>
</p>
</td><td>
<p>
<strong>Description (matrix methods)</strong>
</p>
</td></tr><tr><td>
<p>
<code class="literal">sl.det</code>
</p>
</td><td>
<p>Determinant of a matrix</p>
</td></tr><tr><td>
<p>
<code class="literal">sl.eig</code>
</p>
</td><td>
<p>Eigenvalues and eigenvectors of a matrix</p>
</td></tr><tr><td>
<p>
<code class="literal">sl.inv</code>
</p>
</td><td>
<p>Matrix inverse</p>
</td></tr><tr><td>
<p>
<code class="literal">sl.pinv</code>
</p>
</td><td>
<p>Matrix pseudoinverse</p>
</td></tr><tr><td>
<p>
<code class="literal">sl.norm</code>
</p>
</td><td>
<p>Matrix or vector norm</p>
</td></tr><tr><td>
<p>
<code class="literal">sl.svd</code>
</p>
</td><td>
<p>Singular value decomposition</p>
</td></tr><tr><td>
<p>
<code class="literal">sl.lu</code>
</p>
</td><td>
<p>LU decomposition</p>
</td></tr><tr><td>
<p>
<code class="literal">sl.qr</code>
</p>
</td><td>
<p>QR decomposition</p>
</td></tr><tr><td>
<p>
<code class="literal">sl.cholesky</code>
</p>
</td><td>
<p>Cholesky decomposition</p>
</td></tr><tr><td>
<p>
<code class="literal">sl.solve</code>
</p>
</td><td>
<p>Solution of a general or symmetric linear system: <em>Ax = b</em>
</p>
</td></tr><tr><td>
<p>
<code class="literal">sl.solve.banded</code>
</p>
</td><td>
<p>The same for banded matrices</p>
</td></tr><tr><td>
<p>
<code class="literal">sl.lstsq</code>
</p>
</td><td>
<p>Least squares solution</p>
</td></tr></tbody></table></div><p>Table 4.6: Linear algebra functions of the <strong>scipy.linalg</strong> module</p><p>Execute <code class="literal">import scipy.linalg as sl</code> first.</p></div></div>
<div><div><div><div><h1 class="title"><a id="ch04lvl1sec40"/>Summary</h1></div></div></div><p>In this chapter, we worked with the most important objects in linear algebra – vectors and matrices. For this, we learned how to define arrays and we met important array methods. A smaller section demonstrated how to use modules from <code class="literal">scipy.linalg</code> to solve central tasks in linear algebra.</p></div>
<div><div><div><div><h1 class="title"><a id="ch04lvl1sec41"/>Exercises</h1></div></div></div><p>
<strong>Ex. 1</strong> → Consider a 4 × 3 matrix <em>M</em>:</p><p>
</p><div><img src="img/B05511_04_13..jpg" alt="Exercises"/></div><p>
</p><div><ol class="orderedlist arabic"><li class="listitem">Construct this matrix in Python using the function <code class="literal">array</code> .</li><li class="listitem">Construct the same matrix using the function <code class="literal">arange</code>  followed by a suitable reshape.</li><li class="listitem">What is the result of the expression <code class="literal">M[2,:]</code> ? What is the result of the similar expression <code class="literal">M[2:]</code>?</li></ol></div><p>
<strong>Ex. 2</strong> → Given a vector <em>x</em>, construct in Python the following matrix:</p><p>                  </p><div><img src="img/B05511_04_14.jpg" alt="Exercises"/></div><p>
</p><p>Here, <em>x<sub>i</sub></em> are the components of the vector <em>x</em> (numbered from zero). Given a vector <em>y</em>, solve in Python the linear equation system <em>Va = y</em>. Let the components of <em>a</em> be denoted by <em>a<sub>i</sub>, i = 0, ..., 5</em>. Write a function <code class="literal">poly</code>, which has <em>a</em> and <em>z</em> as input and which computes the polynomial:</p><p>
</p><div><img src="img/B05511_04_15-1.jpg" alt="Exercises"/></div><p>
</p><p>Plot this polynomial and depict in the same plot the points (<em>x<sub>i</sub></em>, <em>y<sub>i</sub></em>) as small stars. Try your code with the vectors:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><em>x = (0.0, 0.5, 1.o, 1.5, 2.0, 2.5)</em></li><li class="listitem" style="list-style-type: disc"><em>y = (-2.0, 0.5, -2.0, 1.0, -0.5, 1.0)</em></li></ul></div><p>
<strong>Ex. 3</strong> → The matrix <em>V</em> in <em>Ex. 2</em> is called a Vandermonde matrix. It can be set up in Python directly by the command <code class="literal">vander</code>. Evaluating a polynomial defined by a coefficient vector can be done with the Python command <code class="literal">polyval</code>. Repeat <em>Ex. 2</em> by using these commands.</p><p>
<strong>Ex. 4 </strong>→ Let <em>u</em> be a one dimensional array. Construct another array ξ with values ξ<em><sub>i</sub> = (u<sub>1</sub> + u<sub>i+1</sub> + u<sub>i+2</sub>)/3</em>. In statistics, this array is called the moving average of <em>u</em>. In approximation theory, it plays the role as the Greville abscissae of cubic splines. Try to avoid the use of for loops in your script.</p><p>
<strong>Ex. 5</strong> →</p><div><ol class="orderedlist arabic"><li class="listitem">Construct from the matrix <em>V</em> given in <em>Ex. 2</em> a matrix <em>A</em> by deleting <em>V</em>'s first column.</li><li class="listitem">Form the matrix <em>B = (A<sup>T</sup> A)<sup>-1</sup> A<sup>T</sup></em>.</li><li class="listitem">Compute <em>c = B y</em> with <em>y</em> from <em>Ex. 2</em>.</li><li class="listitem">Use <em>c</em> and <code class="literal">polyval</code> to plot the polynomial defined by <em>c</em>. Plot in the same picture again the points (<em>x<sub>i</sub></em>, <em>y<sub>i</sub></em>).</li></ol></div><p>
<strong>Ex. 6</strong> → <em>Ex. 5</em> describes the least square method. Repeat that exercise but use SciPy's <code class="literal">scipy.linalg.lstsq</code> method instead.</p><p>
<strong>Ex. 7</strong> → Let <em>v</em> be a vector written in its coordinate form as a 3 × 1 matrix
[1 -1 1]<em><sup>T</sup></em>. Construct the projection matrices:</p><p>
<img src="img/projection.jpg" alt="Exercises"/>.</p><p>Show experimentally that <em>v</em> is an eigenvector for both matrices <em>P</em> and <em>Q</em>. What are the corresponding eigenvalues?</p><p>
<strong>Ex. 8</strong> → In numerical linear algebra the <em>m</em> × <em>m</em> matrix <em>A</em> with the property</p><p>
</p><div><img src="img/B05511_04_17.jpg" alt="Exercises"/></div><p>
</p><p> is used as an example for an extreme growth-factor, when performing <em>LU</em> factorization.</p><p>Set up this matrix in Python for various <em>m</em>, compute its <em>LU</em> factorization using the command <code class="literal">scipy.linalg.lu</code> and derive experimentally a statement about the growth factor
</p><p>
</p><div><img src="img/B05511_04_18.jpg" alt="Exercises"/></div><p>
</p><p>in relation to m.</p></div></body></html>