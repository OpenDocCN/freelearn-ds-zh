- en: Chapter 5. Putting Data in its Place – Classification Methods and Analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we explored methods for analyzing data whose outcome
    is a continuous variable, such as the purchase volume for a customer account or
    the expected number of days until cancellation of a subscription service. However,
    many of the outcomes for data in business analyses are discrete—they may only
    take a limited number of values. For example, a movie review can be 1–5 stars
    (but only integers), a customer can cancel or renew a subscription, or an online
    advertisement can be clicked or ignored.
  prefs: []
  type: TYPE_NORMAL
- en: 'The methods used to model and predict outcomes for such data are similar to
    the regression models we covered in the previous chapter. Moreover, sometimes
    we might want to convert a regression problem into a classification problem: for
    instance, rather than predicting customer spending patterns in a month, we might
    be more interested in whether it is above a certain threshold that is meaningful
    from a business perspective, and assign values in our training data as 0 (below
    the threshold) and 1 (above) depending upon this cutoff. In some scenarios, this
    might increase the noise in our classification: imagine if many customers'' personal
    expenditures were right near the threshold we set for this model, making it very
    hard to learn an accurate model. In other cases, making the outcome discrete will
    help us hone in on the question we are interested in answering. Imagine the customer
    expenditure data is well separated above and below our threshold, but that there
    is wide variation in values above the cutoff. In this scenario, a regression model
    would try to minimize overall error in the model by fitting the trends in larger
    data points that disproportionately influence the total value of the error, rather
    than achieving our actual goal of identifying high- and low- spending customers.'
  prefs: []
  type: TYPE_NORMAL
- en: In addition to these considerations, some data is inherently not modeled effectively
    by regression analyses. For instance, consider the scenario in which we are trying
    to predict which ad out of a set of five a customer is most likely to click. We
    could encode these ads with the numerical values ranging from 1 to 5, but they
    do not have a natural ordering that would make sense in a regression problem—2
    is not greater than 1, it is simply a label denoting which of the five categories
    an ad belongs to. In this scenario, it will make more sense to encode the labels
    of the dataset as a vector of length `5` and place a `1` in the column corresponding
    to the ad, which will make all labels equivalent from the perspective of the algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: 'With these points in mind, in the following exercises, we will cover:'
  prefs: []
  type: TYPE_NORMAL
- en: Encoding data responses as categorical outcomes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building classification models with both balanced and skewed data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluating the accuracy of classification models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Assessing the benefits and shortcomings of different classification methods
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logistic regression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will start our exploration of classifier algorithms with one of the most
    commonly used classification models: logistic regression. Logistic regression
    is similar to the linear regression method discussed in [Chapter 4](ch04.html
    "Chapter 4. Connecting the Dots with Models – Regression Methods"), *Connecting
    the Dots with Models – Regression Methods*, with the major difference being that
    instead of directly computing a linear combination of the inputs, it compresses
    the output of a linear model through a function that constrains outputs to be
    in the range `[0,1]`. As we will see, this is in fact a kind of "generalized linear
    model that we discussed in the last [Chapter 4](ch04.html "Chapter 4. Connecting
    the Dots with Models – Regression Methods"), *Connecting the Dots with Models
    – Regression Methods*, recall that in linear regression, the predicted output
    is given by:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Logistic regression](img/B04881_05_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'where `Y` is the response variable for all `n` members of a dataset, `X` is
    an `n` by `m` matrix of `m` features for each of the n rows of data, and `βT`
    is a column vector of `m` coefficients (Recall that the `T` operator represents
    the transpose of a vector or matrix. Here we transpose the coefficients so they
    are of dimension `mx1`, so that we can form a product with the matrix `X` with
    is `nxm`), which gives the change in the response expected for a 1-unit change
    in a particular feature. Thus, taking the dot product of `X` and `β` (multiplying
    each coefficient by its corresponding feature and summing over the features) gives
    the predicted response. In logistic regression, we begin instead with the formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Logistic regression](img/B04881_05_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'where the `logistic` function is:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Logistic regression](img/B04881_05_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'You can see the behavior of the logistic function by plotting using the following
    code in a notebook session:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '![Logistic regression](img/B04881_05_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: The Output of the Logistic Function for a Continuous Input'
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see in Figure 1, the logistic function takes the output of the linear
    regression and transforms it using a sigmoid (an S-shaped function): as the linear
    regression value becomes larger, the exponential term tends toward 0, making the
    output `1`. Conversely, as the linear regression value becomes negative, the exponential
    term becomes very large, and the output becomes `0`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'How can we interpret the coefficients in this model, given that it is no longer
    modeling a simple linear trend? Because of the logistic transform, the coefficients
    no longer represent an expected increase in response per 1-unit increase in the
    predictor. To develop a similar interpretation, we start with the observation
    that the logistic regression equation represents the probability of a given observation,
    *x*, being a member of class `1` (assuming the response variable for the data
    falls into two classes—see the following for a discussion of cases where the number
    of classes is *> 2*). We could also write a similar equation to represent the
    probability of a given observation being class `0`, which is given by:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Logistic regression](img/B04881_05_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, we can take the natural logarithm of these two probabilities get finally:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Logistic regression](img/B04881_05_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: In other words, the outcome of the linear response now represents the natural
    logarithm of the ratio between the probability of class *1* and class *0*. This
    quantity is also referred to as the log-odds or the logit function, and is equivalent
    to the inverse of the logistic function. In this formula, a 1-unit change in the
    coefficient *β* will lead to a 1-unit increase in the log-odds, allowing us a
    way to interpret the coefficients in this model.
  prefs: []
  type: TYPE_NORMAL
- en: 'You may recall from [Chapter 4](ch04.html "Chapter 4. Connecting the Dots with
    Models – Regression Methods"), *Connecting the Dots with Models – Regression Methods*,
    that in **Generalized Linear Models** (**GLMs**), link function transforms the
    linear response to a nonlinear range. In logistic regression, the logit function
    is the link function. While a full discussion of the various types of GLMs is
    outside the scope of this book, we refer the interested reader to more comprehensive
    treatments of this topic (Madsen, Henrik, and Poul Thyregod. *Introduction to
    general and generalized linear models*. CRC Press, 2010; Madsen, Henrik, and Poul
    Thyregod. Introduction to general and generalized linear models. CRC Press, 2010:
    Hardin, James William, Joseph M. Hilbe, and Joseph Hilbe. Generalized linear models
    and extensions. Stata press, 2007.).'
  prefs: []
  type: TYPE_NORMAL
- en: 'If you have been reading carefully, you may realize that we have contradicted
    ourselves in the discussion above. On the one hand, we want to fit data in which
    the only allowable outcome is either a `0` or a `1`. One the other hand, our logistic
    function (and the log-odds) can take a value between `0` and `1`, continuously.
    Thus, to correctly apply this model, we will need to choose a threshold between
    `0` and `1` to classify the outputs of the regression: if a value is above this
    threshold, we consider the observation as class `1`, otherwise `0`. The simplest
    threshold to choose would be half, and indeed for balanced dataset with an equal
    number of positive and negative examples, this is a reasonable choice. However,
    in many cases that we encounter in the real world (such as ad clicks or subscriptions),
    the number of positive outcomes is much fewer than the negatives. If we optimize
    a logistic regression model using such an imbalanced dataset, the optimal parameters
    will identify few observations as positive. Thus, using half as a cutoff will
    inaccurately classify many negatives as class 1 (positive) and result in a high
    false positive rate.'
  prefs: []
  type: TYPE_NORMAL
- en: We have a few options to address this problem of imbalanced classes in our data.
    The first is to simply tune the threshold for the logistic function to consider
    the outcome as 1, which we can do visually using the **receiver operator characteristic**
    (**ROC**) curve, described in more detail in the following exercises. We could
    also rebalance our training data such that half represents a reasonable value,
    by selecting an equal number of positive and negative examples. In case we were
    worried about making a biased choice among the many negative examples, we could
    repeat this process many times and average the results—this process is known as
    Bagging and was described in more detail in [Chapter 4](ch04.html "Chapter 4. Connecting
    the Dots with Models – Regression Methods"), *Connecting the Dots with Models
    – Regression Methods*, in the context of Random Forest regression models. Finally,
    we could simply penalize errors on the few positive examples by assigning a weight
    to them in the error function that is greater than the more numerous negative
    examples. More details on reweighting appear as follows.
  prefs: []
  type: TYPE_NORMAL
- en: 'Multiclass logistic classifiers: multinomial regression'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'While we have dealt thus far with the simple of example of a two-class problem
    , we could imagine scenarios in which there are multiple classes: for example,
    predicting which of a set of items a customer will select in an online store.
    For these sorts of problems, we can imagine extending the logistic regression
    to `K` classes, where *K > 2*. Recall that taking e to the power of the logit
    function gives:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Multiclass logistic classifiers: multinomial regression](img/B04881_05_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'In a two-class problem, this value compares the ratio of the probability that
    *Y=1* to all other values, with the only other value being `0`. We could imagine
    running instead a series of logistic regression models for *K* classes, where
    `e(Logit(x))` gives the ratio of the probability of *Y = class k* to any of other
    class. We would then up with a series of *K* expressions for `e(Xβ)` with different
    regression coefficients. Because we want to constrain the outcome to be in the
    range `0` to `–1`, we can divide the output of any of the *K* models by the sum
    of all *K* models using the formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Multiclass logistic classifiers: multinomial regression](img/B04881_05_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: This equation also known as the `softmax` function. It is used extensively in
    neural network models (which we will cover in [Chapter 7](ch07.html "Chapter 7. Learning
    from the Bottom Up – Deep Networks and Unsupervised Features"), *Learning from
    the Bottom Up – Deep Networks and Unsupervised Features*). It has the nice property
    that even for extreme values of `e(xβ)` for a given class k, the overall value
    of the function cannot go beyond 1\. Thus, we can keep outliers in the dataset
    while limiting their influence on the overall accuracy of the model (since otherwise
    they would tend to dominate the overall value of an error function, such as the
    squared error we used in linear regression in [Chapter 4](ch04.html "Chapter 4. Connecting
    the Dots with Models – Regression Methods"), *Connecting the Dots with Models
    – Regression Methods*).
  prefs: []
  type: TYPE_NORMAL
- en: To keep the current presentation less complex, we will examine only a 2-class
    problem in the following exercises. However, keep in mind that as with logistic
    regression, the other methods discussed in the following can be extended to work
    with multiple classes as well. Additionally, we will demonstrate a full multiclass
    problem in [Chapter 7](ch07.html "Chapter 7. Learning from the Bottom Up – Deep
    Networks and Unsupervised Features"), *Learning from the Bottom Up – Deep Networks
    and Unsupervised Features* using neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have covered what logistic regression is and the problem it is designed
    to solve, let us prepare a dataset for use with this and other classification
    methods. In addition to working through a practical example of fitting and interpreting
    a logistic regression model, we will use this a starting point to examine other
    classification algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Formatting a dataset for classification problems
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this example, we will use a census dataset with rows representing the characteristic
    of an adult US citizen (Kohavi, Ron. *Scaling Up the Accuracy of Naive-Bayes Classifiers:
    A Decision-Tree Hybrid*. KDD. Vol. 96\. 1996). The objective is to predict whether
    an individual''s income is above or below the average income of $55,000 a year.
    Let us start by loading the dataset into a pandas data frame and examining the
    first few rows using the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '![Formatting a dataset for classification problems](img/B04881_05_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Why did we use the argument (`header = None`) to load the data? Unlike some
    of the other datasets we have examined in previous chapters, the column names
    for the census data are contained in a separate file. These feature names will
    be helpful in interpreting the results, so let us parse them from the dataset
    description file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have the column names appended to the dataset, we can see that
    the response variable, income, needs to be re-encoded. In the input data, it is
    coded as a string, but since scikit-learn is unable to take a string as an input,
    we need to convert it into a `0` or `1` label using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Here, we have used a lambda expression to apply an anonymous function (a function
    without a name defined in the rest of the program) to the data. The conditional
    expression within the map (…) call takes `x` as an input and returns either `0`
    or `1`. We could just as easily have formally defined such as function, but especially
    for expressions we do not intend to reuse, lambda expressions provide an easy
    way to specify such transformations without crowding our code with a lot of functions
    that do not have general utility.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us take a moment and look at the distribution of the different income classes
    by plotting a histogram with income as the value on the vertical axis:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '![Formatting a dataset for classification problems](img/B04881_05_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Notice that observations with the label `1` are about 50 percent less prevalent
    than those with a label of `0`. As we discussed previously, this is a situation
    in which a simple threshold of half in evaluating the class probabilities will
    lead to an inaccurate model, and we should keep this data skew in mind as we evaluate
    the performance later.
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition to our outcome variable, many of the features in this dataset are
    also categorical: we will need to re-encode them as well before fitting our model.
    We can do so in two steps: first, let us find the number of unique elements in
    each of these columns and map them to integer values using a dictionary. To begin,
    we check whether each column in the data frame is categorical (`dtype` equal to
    **object**), and, if so, we add its index into the list of columns we want to
    convert:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have the column numbers we want to convert, we need to make a mapping
    of each column from a string to a label from *1* to *k*, where *k* is the number
    of categories:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Notice that we first extract the unique elements of each column and then use
    the enumerate function on this list of unique elements to generate the labels
    we need. By converting this indexed list into a dictionary where the keys are
    the unique elements of a column and the values are the labels, we have exactly
    the mapping we need to re-encode the categorical string variables in this data
    as integers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we can create a second copy of the data using the mapping dictionary we
    generated above:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can use scikit-learn''s one-hot encoder to transform these integer
    values into a series of columns, of which only one is set to `1`, representing
    which of the k classes this row belongs to. To use the one-hot encoder, we also
    need to know how many categories each of the columns has, which we can do with
    the following command by storing the size of each mapping dictionary:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'We then apply the one-hot encoder:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'From here we have the data in the right format to fit our logistic regression.
    As with our examples in [Chapter 4](ch04.html "Chapter 4. Connecting the Dots
    with Models – Regression Methods"), *Connecting the Dots with Models – Regression
    Methods*, we need to split our data into training and test sets, specifying the
    fraction of data in the test set (*0.4*). We also set the random number generator
    seed to 0 so that we can replicate the analysis later by generating the same random
    set of numbers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Now that we have prepared training and test data, we can fit a logistic regression
    model to the dataset. How can we find the optimal parameters (coefficients) of
    this model? We will examine two options.
  prefs: []
  type: TYPE_NORMAL
- en: The first approach, known as **stochastic gradient descent** (**SGD**), calculates
    the change in the error function at a given data point and adjusts the parameters
    to account for this error. For an individual data point, this will result in a
    poor fit, but if we repeat this process over the whole training set several times,
    the coefficients will converge to the desired values. The term **stochastic**
    in this method's name refers to the fact that this optimization is achieved by
    following the gradient (first derivative) of the loss function with respect to
    a given data point in a random order over the dataset. Stochastic methods such
    as this one often scale well to large datasets because they allow us to only examine
    the data individually or in small batches rather than utilizing the whole dataset
    at once, allowing us to parallelize the learning procedure or at least not use
    all the memory on our machine to process large volumes of data.
  prefs: []
  type: TYPE_NORMAL
- en: In contrast, the optimization methods implemented by default for the logistic
    regression function in scikit-learn are known as **second-order methods**. SGD,
    because it adjusts the model parameter values using the first derivative of the
    error function, is known as a first-order method. Second-order methods can be
    beneficial in cases where the first derivative is changing very slowly, as we
    will see in the following, and to find the optimal value in cases where the error
    function follows complex patterns.
  prefs: []
  type: TYPE_NORMAL
- en: Let us look at each of these methods in more detail.
  prefs: []
  type: TYPE_NORMAL
- en: Learning pointwise updates with stochastic gradient descent
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'How do we find the optimal parameters for our logistic regression model using
    stochastic updates? Recall that we are trying to optimize the probabilities:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Learning pointwise updates with stochastic gradient descent](img/B04881_05_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: f we want to optimize the probability of each individual point in our dataset,
    we want to maximize the value of the equation, known as the Likelihood as it scores
    the probability of given point being class `1` (or `0`) based on the model;
  prefs: []
  type: TYPE_NORMAL
- en: '![Learning pointwise updates with stochastic gradient descent](img/B04881_05_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: You can see that if the real label `yi` is `1`, and the model gives high probability
    of `1`, then we maximize the value of `F(zi)` (since the exponent of the second
    term is `0`, making it `1`, while the first term in the product is simply the
    value of `F(zi))`. Conversely, if the real label of `yi` is `0`, then we want
    the model to maximize the value of `(1-F(zi))`, which is the probability of class
    `0` under the model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Thus, each point will contribute to the likelihood by the probability of its
    real class. It is usually easier to work with sums than products, so we can take
    the logarithm of the likelihood equation and sum over all elements in the data
    set using:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Learning pointwise updates with stochastic gradient descent](img/B04881_05_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'To find the optimal value of the parameters, we just take the first partial
    derivative with respect to the parameters of this equation (the regression coefficients)
    and solve for the value of *β* that maximizes the likelihood equation by setting
    the derivative equal to `0` and finding the value of *β* as illustrated below:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Learning pointwise updates with stochastic gradient descent](img/B04881_05_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'This is the direction we want to update the coefficients β in order to move
    it closer to the optimum. Thus, for each data point, we can make an update of
    the following form:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Learning pointwise updates with stochastic gradient descent](img/B04881_05_15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'where `α` is the learning rate (which we use to control the magnitude by which
    the coefficients can change in each step – usually a smaller learning rate will
    prevent large changes in value and converge to a better model, but will take longer),
    t is the current optimization step, and *t-1* is the previous step. Recall that
    in [Chapter 4](ch04.html "Chapter 4. Connecting the Dots with Models – Regression
    Methods"), *Connecting the Dots with Models – Regression Methods* we discussed
    the concept of regularization, in which we can use a penalty term *λ* to control
    the magnitude of our coefficients. We can do the same here: if the regularization
    term in our likelihood is given by (to penalize the squared sum of the coefficients,
    which is the *L2* norm from Ridge Regression in [Chapter 4](ch04.html "Chapter 4. Connecting
    the Dots with Models – Regression Methods"), *Connecting the Dots with Models
    – Regression Methods*):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Learning pointwise updates with stochastic gradient descent](img/B04881_05_16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Then once we take the first derivate, we have:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Learning pointwise updates with stochastic gradient descent](img/B04881_05_17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'And the final update equation becomes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Learning pointwise updates with stochastic gradient descent](img/B04881_05_18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: We can see, this regularization penalty has the effect of shrinking the amount
    by which we modify the coefficients β at any given step.
  prefs: []
  type: TYPE_NORMAL
- en: As we mentioned previously, stochastic updates are especially efficient for
    large datasets as we only have to examine each data point one at a time. One downside
    of this approach is that we need to run the optimization long enough to make sure
    the parameters converge. For example, we could monitor the change in the coefficient
    values as we take the derivative with respect to each data point, and stop when
    the values cease changing. Depending upon the dataset, this could occur quickly
    or take a long time. A second downside is that following the gradient of the error
    function along the first derivative will not always lead to the fastest solution.
    Second-order methods allow us to overcome some of these deficits.
  prefs: []
  type: TYPE_NORMAL
- en: Jointly optimizing all parameters with second-order methods
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the case of logistic regression, our objective function is convex (see aside),
    meaning that whichever optimization method we choose should be able to converge
    to the global optimum. However, we could imagine other scenarios: for example,
    the surface of the likelihood equation plotted as a function of the inputs could
    vary slowly in a long ravine toward its global optimum. In such a case, we would
    like to find the direction to move the coefficients that is the optimal tradeoff
    between the rate of change and the **rate of the rate of change**, represented
    by the second derivative of the likelihood. Finding this tradeoff allows the optimization
    routine to traverse slowly varying regions quickly. This kind of strategy is represented
    by the class of so-called **Newton methods**, which minimizes equations of the
    following form:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Jointly optimizing all parameters with second-order methods](img/B04881_05_19.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Where `f(x*)` is the objective function we are trying to minimize, such as
    the logistic regression error, and x are the values (such as the model coefficients)
    that do minimize regression likelihood, `x*` are the inputs which optimize the
    value of the function (such as the optimal coefficients β), and `xt` are the value
    of these parameters at the current step of the optimization (there is admittedly
    some abuse of notation here: in the rest of the chapter, *x* are the input rows,
    where here we use *x* to represent a parameter value in a model). The name **Newton
    method** is due to the father of physics, Isaac Newton, who described an early
    version of this procedure (Ypma, Tjalling J. *Historical development of the Newton-Raphson
    method*. SIAM review 37.4 (1995): 531-551). The minimization involves finding
    the direction we should move the parameters at the current stage, `xt`, in order
    to find the minimal value of `f`. We can use a Taylor Expansion from Calculus
    to approximate the value of the preceding function:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Jointly optimizing all parameters with second-order methods](img/B04881_05_20.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'We want to find the value of `Δx` which maximizes the function, since this
    is the direction we wish to move the parameters, just as in gradient descent.
    We can obtain this optimal direction by solving for the point where the gradient
    of the function becomes `0` with respect to `Δx`, to give:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Jointly optimizing all parameters with second-order methods](img/B04881_05_21.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Thus, when `f′(x)` is changing slowly (small `f″(x)`), we take larger steps
    to change the value of the parameters, and vice versa.
  prefs: []
  type: TYPE_NORMAL
- en: 'One of the most commonly used second order methods for logistic regression
    is **iteratively reweighted least squares** (**IRLS**). To show how it works let
    us translate the equations above to our logistic regression model. We already
    known `f''(x)`, since this is just our formula from above used for stochastic
    gradient descent:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Jointly optimizing all parameters with second-order methods](img/B04881_05_22.jpg)'
  prefs: []
  type: TYPE_IMG
- en: What about the second derivative of the likelihood? We can solve for it as well
  prefs: []
  type: TYPE_NORMAL
- en: '![Jointly optimizing all parameters with second-order methods](img/B04881_05_23.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Here we are still writing this equation as a solution for a single data point.
    In second order methods we are not usually going to use stochastic updates, so
    we need to apply the formula to all data points. For the gradient (first derivative),
    this gives the sum:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Jointly optimizing all parameters with second-order methods](img/B04881_05_24.jpg)'
  prefs: []
  type: TYPE_IMG
- en: For second derivative, we can express the result as a matrix. The matrix of
    pairwise second derivatives is known also known as the Hessian matrix.
  prefs: []
  type: TYPE_NORMAL
- en: '![Jointly optimizing all parameters with second-order methods](img/B04881_05_25.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Where I is the identity matrix (a matrix with 1 on the diagonal and 0 elsewhere),
    and A contains the second derivative evaluated for each pair of points *i* and
    *j*. Thus, if we use these expressions to make a Newton update, we have:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Jointly optimizing all parameters with second-order methods](img/B04881_05_26.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Because the second derivative appears in the denominator, we use a matrix inverse
    (given by the *-1* exponent) to perform this operation. If you look closely at
    the denominator, we have the product *XT X* weighted by the elements of *A*, and
    in the numerator we have *X(Y-F(X))*. This resembles the equation for ordinary
    linear regression that we saw in [Chapter 4](ch04.html "Chapter 4. Connecting
    the Dots with Models – Regression Methods"), *Connecting the Dots with Models
    – Regression Methods*! In essence, this update is performing a stepwise linear
    regression weighted at each pass by *A* (whose values change as we update the
    coefficients), thus giving the method its name. One of the shortcomings of IRLS
    is that we need to repeatedly invert a Hessian matrix that will become quite large
    as the number of parameters and data points grows. Thus, we might try to find
    ways to approximate this matrix instead of explicitly calculating it. One method
    commonly used for this purpose is the Limited Memory Broyden–Fletcher–Goldfarb–Shanno
    (L-BFGS) algorithm (Liu, Dong C., and Jorge Nocedal. *On the limited memory BFGS
    method for large scale optimization*. Mathematical programming 45.1-3 (1989):
    503-528), which uses the last k updates of the algorithm to calculate an approximation
    of the Hessian matrix instead of explicitly solving for it in each stage.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In both SGD and Newton methods, we have theoretical confidence that both methods
    will eventually converge to the correct (globally optimal) parameter values due
    to a property of the likelihood function known as convexity. Mathematically, a
    convex function F fulfills the condition:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Jointly optimizing all parameters with second-order methods](img/B04881_05_27.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Conceptually, this means that for two points `x1` and `x2`, the value of F for
    points between them (the left-hand side of the equation) is less than or equal
    to the straight line between the points (the right-hand side of the equation,
    which gives a linear combination of the function value at the two points). Thus,
    a convex function will have a global minimum between the points `x1` or `x2`.
    Graphically, you can see this by plotting the following in a python notebook
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '![Jointly optimizing all parameters with second-order methods](img/B04881_05_28.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The parabola is a convex function because the values between `x1` and `x2` (the
    two points where the blue line intersects with the parabola) are always below
    the blue line representing `α(F(x1))+(1-α) (F(x2))`. As you can see, the parabola
    also has a global minimum between these two points.
  prefs: []
  type: TYPE_NORMAL
- en: When we are dealing with matrices such as the Hessian referenced previously,
    this condition is fulfilled by each element of the matrix being *≥ 0*, a property
    known as positive semidefinite, meaning any vector multiplied by this matrix on
    either side (xTHx) yields a value `≥ 0`. This means the function has a global
    minimum, and if our solution converges to a set of coefficients, we can be guaranteed
    that they represent the best parameters for the model, not a local minimum.
  prefs: []
  type: TYPE_NORMAL
- en: We noted previously that we could potentially offset imbalanced distribution
    of classes in our data by reweighting individual points during training. In the
    formulas for either SGD or IRLS, we could apply a weight wi for each data point,
    increasing or decreasing its relative contribution to the value of the likelihood
    and the updates made during each iteration of the optimization algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have described how to obtain the optimal parameters of the logistic
    regression model, let us return to our example and apply these methods to our
    data.
  prefs: []
  type: TYPE_NORMAL
- en: Fitting the model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We can use either the SGD or second-order methods to fit the logistic regression
    model to our data. Let us compare the results using SGD; we fit the model using
    the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Where the parameter `log` for loss specifies that this is a logistic regression
    that we are training, and `n_iter` specifies the number of times we iterate over
    the training data to perform SGD, alpha represents the weight on the regularization
    term, and we specify that we do not want to fit the intercept to make comparison
    to other methods more straightforward (since the method of fitting the intercept
    could differ between optimizers). The penalty argument specifies the regularization
    penalty, which we saw in [Chapter 4](ch04.html "Chapter 4. Connecting the Dots
    with Models – Regression Methods"), *Connecting the Dots with Models – Regression
    Methods*, already for ridge regression. As `l2` is the only penalty we can use
    with second-order methods, we choose `l2` here as well to allow comparison between
    the methods. We can examine the resulting model coefficients by referencing the
    coeff_ property of the model object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Compare these coefficients to the second-order fit we obtain using the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Like the SGD model, we remove the intercept fit to allow the most direct comparison
    of the coefficients produced by the two methods., We find that the coefficients
    are not identical, with the output of the SGD model containing several larger
    coefficients. Thus, we see in practice that even with similar models and a convex
    objective function, different optimization methods can give different parameter
    results. However, we can see that the results are highly correlated based on a
    pairwise scatterplot of the coefficients:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '![Fitting the model](img/B04881_05_29.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The fact that the SGD model has larger coefficients gives us a hint as to what
    might be causing the difference: perhaps SGD is more sensitive to differences
    in scale between features? Let us evaluate this hypothesis by using the **StandardScaler**
    introduced in [Chapter 3](ch03.html "Chapter 3. Finding Patterns in the Noise
    – Clustering and Unsupervised Learning"), *Finding Patterns in the Noise – Clustering
    and Unsupervised Learning* in the context of K-means clustering to normalize the
    features before running the SGD model using the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Recall that we need to turn the features matrix to a dense format since StandardScaler
    does not accept a sparse matrix as input. Now, if we retrain the SGD using the
    same arguments and plot the result versus the Newton method, we find the coefficients
    are much closer:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Fitting the model](img/B04881_05_30.jpg)'
  prefs: []
  type: TYPE_IMG
- en: This example should underscore the fact that the optimizer is sometimes as important
    as the actual algorithm, and may determine what steps we should take in data normalization.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating classification models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have fit a classification model, we can examine the accuracy on
    the test set. One common tool for performing this kind of analysis is the **Receiver
    Operator Characteristic** (**ROC**) curve. To draw an ROC curve, we select a particular
    cutoff for the classifier (here, a value between `0` and `1` above which we consider
    a data point to be classified as a positive, or 1) and ask what fraction of 1s
    are correctly classified by this cutoff (true positive rate) and, concurrently,
    what fraction of negatives are incorrectly predicted to be positive (false positive
    rate) based on this threshold. Mathematically, this is represented by choosing
    a threshold and computing four values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: The **true positive rate** (**TPR**) plotted by the ROC is then *TP/(TP+FN)*,
    while the **false positive rate** (**FPR**) is *FP/(FP+TN)*.
  prefs: []
  type: TYPE_NORMAL
- en: If both rates are equal, then this is no better than random. In other words,
    at whatever cutoff we choose, a prediction of class 1 by the model is equally
    likely regardless if the point is actually positive or negative. Thus, a diagonal
    line from the lower left to the upper right hand represent the performance of
    a classifier made through randomly choosing labels for data points, since the
    true positive and false positive rates are always equal. Conversely, if the classifier
    exhibits better than random performance, the true positive rate rises much faster
    as correctly classified points are enriched above the threshold. Integrating the
    **area under the curve** (**AUC**) of the ROC curve, which has a maximum of 1,
    is a common way to report the accuracy of classifier methods. To find the best
    threshold to use for classification, we find the point on this curve where the
    ratio between true positive and false positive rates is maximal.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our example, this is important because `1` is less frequent than `0`. As
    we mentioned in the beginning of this chapter when we were examining the data
    set, this can cause problems in training a classification model. While the naïve
    choice would be to consider events with predicted probability above 0.5 as 1,
    in practice we find that due to this dataset imbalance, a lower threshold is optimal
    as the solution is biased toward the zeros. This effect can become even more extreme
    in highly skewed data: consider an example where only 1 in 1,000 points have label
    1\. We could have an excellent classifier that predicts that every data point
    is 0: it is 99.9% percent accurate! However, it would not be very useful in identifying
    rare events. There are a few ways we could counteract this bias besides adjusting
    the threshold in the AUC.'
  prefs: []
  type: TYPE_NORMAL
- en: 'One way would be to rebalance the model by constructing a training set that
    is 50 percent 1s and 50 percent 0s. We can then evaluate the performance on the
    unbalanced test dataset. If the imbalance is very large, our rebalanced training
    set might contain only a small number of the possible variation in the 0s: thus,
    to generate a model representative of the entire dataset, we may want to construct
    many such datasets and average the results of the models generated from them.
    This approach is not dissimilar to the Bagging method used in constructing Random
    Forest models, as we saw in [Chapter 4](ch04.html "Chapter 4. Connecting the Dots
    with Models – Regression Methods"), *Connecting the Dots with Models – Regression
    Methods*.'
  prefs: []
  type: TYPE_NORMAL
- en: Secondly, we can use our knowledge of the imbalance to change the contribution
    of each data point as we optimize the parameters. For example, in the SGD equations,
    we can penalize errors on 1s 1,000 times as much as errors on 0s. This weight
    will then correct the bias in the model.
  prefs: []
  type: TYPE_NORMAL
- en: Our interpretation of the AUC is also changed in very imbalanced datasets. While
    an overall AUC of 0.9 might be considered good, if the ratio between the TPR and
    FPR at a false positive rate of 0.001 (the fraction of data containing the rare
    class) is not > 1, it indicates we may have to search through a large amount of
    the head of the ranking to enrich the rare events. Thus, while the overall accuracy
    appears good, the accuracy in the range of data we most These scenarios are not
    uncommon in practice. For example, ad clicks are usually much less frequent than
    non-clicks, as are responses to sales inquiries. Visually, a classifier that is
    not well-fit to imbalanced data would be indicated by an ROC curve where the difference
    between TPR and FPR is greatest near the middle of the curve (*~0.5*). Conversely,
    in an ROC curve of a classifier that is appropriately adapted to rare events,
    most of the area is contained to the left hand side (rising sharply from a cutoff
    of 0 and leveling off to the right), representing enrichment of positives at high
    thresholds.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that false positive rate and false negative rate are just two examples
    of accuracy metrics we could compute. We may also be interested in knowing, above
    a given cutoff for model score, 1) how many of our positive examples are classified
    (recall) and what percentage of points above this threshold are actually positive
    2) precision. These are calculated as:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Precision = TP/(TP+FP)*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Recall = TP/(TP+FN)*'
  prefs: []
  type: TYPE_NORMAL
- en: 'In fact, recall is identical to the true positive rate. While the ROC curve
    allows us to evaluate whether the model generates true positive predictions at
    a greater rate than false positives, comparing precision versus recall gives a
    sense of how reliable and complete the predictions above a given score threshold
    are. We could have very high precision, but only be able to detect a minority
    of the overall positive examples. Conversely, we could have high recall at the
    cost of low precision as we incur false positives by lowering the score threshold
    to call positives in our model. The tradeoff between these can be application
    specific. For example, if the model is largely exploratory, such as a classifier
    used to generate potential sales leads for marketing, then we accept a fairly
    low precision since the value of each positive is quite high even if the true
    predictions are interspersed with noise. On the other hand, in a model for spam
    identification, we may want to err on the side of high precision, since the cost
    of incorrectly moving a valid business email to the user''s trash folder may be
    higher than the occasional piece of unwanted mail that gets through the filter.
    Finally, we could also consider performance metrics that are appropriate even
    for imbalanced data, because they represent a tradeoff between the precision and
    recall for majority and minority classes. These include the F-measure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Evaluating classification models](img/B04881_05_31.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'And Matthew''s correlation coefficient (Matthews, Brian W. *Comparison of the
    predicted and observed secondary structure of T4 phage lysozyme*. Biochimica et
    Biophysica Acta (BBA)-Protein Structure 405.2 (1975): 442-451.):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Evaluating classification models](img/B04881_05_32.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Returning to our example, we have two choices in how we could compute the predictions
    from our model: either a class label (`0` or `1`) or a probability of a particular
    individual being class `1`. For computing the ROC curve, we want the second choice,
    since this will allow us to evaluate the accuracy of the classifier over a range
    of probabilities used as a threshold for classification:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'With this probability, we can we see visually that our model gives a subpar
    accuracy using the following code to plot the ROC curve for the training and test
    sets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '![Evaluating classification models](img/B04881_05_33.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Numerically, we find that the AUC of the test and training set is little better
    than random (`0.5`), as both the commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: and
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: give results of ~ 0.6.
  prefs: []
  type: TYPE_NORMAL
- en: If possible, we would like to improve the performance of our classified—how
    can we diagnose the problems with our existing logistic regression model and work
    toward a better prediction?
  prefs: []
  type: TYPE_NORMAL
- en: Strategies for improving classification models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Confronted with this less than desirable performance, we typically have a few
    options:'
  prefs: []
  type: TYPE_NORMAL
- en: Train with more data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Regularize the model to reduce over-fitting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Choose another algorithm
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In our example with an under-performing logistic regression model, which option
    makes most sense?
  prefs: []
  type: TYPE_NORMAL
- en: Let us consider take the first option, that we simply need more data to improve
    performance. In some cases, we may not have enough data in our training set to
    represent the patterns we observe in the test set. If this were the case, we would
    expect to see our performance on the test set improve as we increase the size
    of the training set used to build the model. However, we do not always have the
    convenience of getting more data. In this example, we don't actually have more
    data to train with; even if is possible to collect more data in theory, in practice
    it may be too expensive to justify the cost, or we may need to make a decision
    before more data will be available.
  prefs: []
  type: TYPE_NORMAL
- en: What about over-fitting? In other words, perhaps our model is precisely tuned
    to the patterns in the training set, but does not generalize to the test set.
    Like the first option, we will observe better performance on the training set
    than the test set. However, the solution is not necessarily to add more data,
    but rather to prune features to make the model more general. In the preceding
    scenario, we see that the performance on both training and test is similar, so
    this does not seem like the most likely explanation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we might try another algorithm. To do so, let us consider what the
    limitations of our current model are. For one, the logistic regression only incorporates
    single features: it has no way to represent interactions between them. For instance,
    it can only model the effect of marital status, not marital status conditional
    on education and age. It is perhaps not surprising that these factors probably
    in combination predict income, but not necessarily individually. It may help to
    look at the values of the coefficients, and to do so, we will need to map the
    original column headers to column names in our one-hot encoding, where each of
    the categorical features is now represented by several columns. In this format,
    the numerical columns are appended to the end of the data frame, so we need to
    add them last to the list of columns. The following code remaps the column headers
    using the mapping of category to one-hot position we calculated earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'We can check that the individual coefficient make sense: keep in mind that
    the sort function arranges items in ascending order, so to find the largest coefficients
    we sort by the negative value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Logically, the order appears to make sense, since we would expect age and education
    to be important predictors of income. However, we see that only *~1/3rd* of the
    features have a large influence on the model through the following plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '![Strategies for improving classification models](img/B04881_05_34.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Thus, it looks like the model is only able to learn information from a subet
    of features. We could potentially try to generate interaction features by making
    combinatorial labels (for example, a binary flag representing married and maximum
    education level as Master's Degree) by taking the product of all features with
    each other. Generating potential nonlinear features in this way is known as polynomial
    expansion, since we are taking single coefficient terms and converting them into
    products that have squared, cubic, or higher power relationships. However, for
    the purposes of this example, will try some alternative algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Separating Nonlinear boundaries with Support vector machines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In our previous example of logistic regression, we assumed implicitly that every
    point in the training set might be useful in defining the boundary between the
    two classes we are trying to separate. In practice we may only need a small number
    of data points to define this boundary, with additional information simply adding
    noise to the classification. This concept, that classification might be improved
    by using only a small number of critical data points, is the key features of the
    **support vector machine** (**SVM**) model.
  prefs: []
  type: TYPE_NORMAL
- en: 'In its basic form, the SVM is similar to the linear models we have seen before,
    using the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Separating Nonlinear boundaries with Support vector machines](img/B04881_05_35.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'where `b` is an intercept, and β is the vector of coefficients such as we have
    seen in regression models. We can see a simple rule that a point `X` is classified
    as class `1` if `F(x) ≥ 1`, and class `-1` if `F(x) ≤ –1`. Geometrically, we can
    understand this as the distance from the plane to the point `x`, where β is a
    vector sitting orthogonal (at a right angle) to the plane. If the two classes
    are ideally separated, then the width between the two classes represented by 1/![Separating
    Nonlinear boundaries with Support vector machines](img/B04881_05_36.jpg) is as
    large as possible; thus, in finding the optimal value of β, we would to minimize
    the norm ![Separating Nonlinear boundaries with Support vector machines](img/B04881_05_36.jpg).
    At the same time, we want to minimize the error in assigning labels to the data.
    Thus, we can have a loss function that minimizes the tradeoff between these two
    objectives:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Separating Nonlinear boundaries with Support vector machines](img/B04881_05_37.jpg)'
  prefs: []
  type: TYPE_IMG
- en: where `y` is the correct label of `x`. When `x` is correctly classified, `y(xβ+b)
    ≥ 1`, and we overall subtract from the values of `L`. Conversely, when we incorrectly
    predict `x`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that the || here represent the Euclidean norm, or:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Separating Nonlinear boundaries with Support vector machines](img/B04881_05_38.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '`y(xβ+b) < 1`, and we thus add to the value of `L`. If we want to minimize
    the value of `L`, we could find the optimal value of `β` and *b* by taking the
    derivative of this function and setting it to 0\. Starting with `β`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Separating Nonlinear boundaries with Support vector machines](img/B04881_05_39.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Similarly, for `b`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Separating Nonlinear boundaries with Support vector machines](img/B04881_05_40.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Plugging these back into the loss function equation we get:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Separating Nonlinear boundaries with Support vector machines](img/B04881_05_41.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Two things are important here. First, only some of the `α` need to be nonzero.
    The rest can be set to `0`, meaning only a small number of points influence the
    choice of optimal model parameters. These points are the support vectors that
    give the algorithm its name, which lie along the boundary between the two classes.
    Note that in practice we would not use the above version of the error function,
    but rather a **soft-margin** formulation in which we use the **hinge loss**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Separating Nonlinear boundaries with Support vector machines](img/B04881_05_42.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'This means that we only penalize points if they are on the wrong side of the
    separating hyperplane, and then by the magnitude of their misclassification error.
    This allows the SVM to be applied even in cases where the data is not linearly
    separable by allowing the algorithm to make mistakes according to the hinge loss
    penalty. For full details please consult references (Cortes, Corinna, and Vladimir
    Vapnik. **Support-vector networks**. Machine learning 20.3 (1995): 273-297; Burges,
    Christopher JC. *A tutorial on support vector machines for pattern recognition*.
    Data mining and knowledge discovery 2.2 (1998): 121-167.).'
  prefs: []
  type: TYPE_NORMAL
- en: Second, we now see that the solution depends on the inputs *x* only through
    the product of individual points. In fact, we could replace this product with
    any function `K(xi,xj)`, where `K` is a so-called **kernel function** representing
    the similarity between `xi` and `xj`. This can be particularly useful when trying
    to capture nonlinear relationships between data points. For example, consider
    data points along a parabola in two-dimensional space, where `x2` (the vertical
    axis) is the square of `x1` (the horizontal). Normally, we could not draw a straight
    line to separate points above and below the parabola. However, if we first mapped
    the points using the function `x1`, `sqrt(x2)`, we can now linearly separate them.
    We saw the effectiveness of this nonlinear mapping in [Chapter 3](ch03.html "Chapter 3. Finding
    Patterns in the Noise – Clustering and Unsupervised Learning"), *Finding Patterns
    in the Noise – Clustering and Unsupervised Learning*, when we use the Gaussian
    Kernel to separate the nonlinear boundary between concentric circles using Spectral
    K-Means clustering.
  prefs: []
  type: TYPE_NORMAL
- en: 'Besides creating a linear decision boundary between data points that are not
    linearly separable in the input space, Kernel functions also allow us to calculate
    similarities between objects that have no vector representation, such as graphs
    (nodes and edges) or collections of words. The objects do not need to be the same
    length, either, as long as we can compute a similarity. These facts are due to
    a result known as Mercer''s Theorem, which guarantees that Kernel functions which
    are *>=0* for all pairs of inputs represent a valid inner product ![Separating
    Nonlinear boundaries with Support vector machines](img/B04881_05_43.jpg) between
    inputs x mapped into a linearly separable space using the mapping represented
    by φ (Hofmann, Thomas, Bernhard Schölkopf, and Alexander J. Smola. *Kernel methods
    in machine learning*. The annals of statistics (2008): 1171-1220). This mapping
    could be explicit, such as the square root function applied to the parabolic input
    in the example above. However, we do not actually need the mapping at all, since
    the kernel is guaranteed to represent the similarity between the mapped inputs.
    Indeed, the mapping could even be performed in an infinite-dimensional space that
    we can not explicitly represent, as is the case with the Gaussian kernel we will
    describe as follows.'
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have covered some of the intuition behind SVMs, let us see if it
    can improve the performance of our classification model by fitting an SVM to the
    data.
  prefs: []
  type: TYPE_NORMAL
- en: Fitting and SVM to the census data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For this example, we will try the default kernel function for the SVM model
    in scikit-learn, which is a Gaussian kernel, which you may recognize as the same
    equation used in a normal distribution function. We previously used the Gaussian
    Kernel in the context of Spectral Clustering in [Chapter 3](ch03.html "Chapter 3. Finding
    Patterns in the Noise – Clustering and Unsupervised Learning"), *Finding Patterns
    in the Noise – Clustering and Unsupervised Learning*, as a reminder, the formula
    is:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Fitting and SVM to the census data](img/B04881_05_44.jpg)'
  prefs: []
  type: TYPE_IMG
- en: In essence, this function translates the difference between two data points
    into the range `1` (when they are equal and the exponent becomes 0) and `0` (when
    the difference is very large and the exponent tends toward a very large negative
    number). The parameter *γ* represents the standard deviation, or bandwith, which
    controls how quickly the value of the function tends towards zero as the difference
    between the points increases. Small values of the bandwith will make the numerator
    a larger negative number, thus shrinking the kernel value to *0*.
  prefs: []
  type: TYPE_NORMAL
- en: 'As we mentioned preceding, the Gaussian kernel represented mapping the inputs
    *x* into an infinite dimensional space. We can see this if we expand the value
    of the kernel function using an infinite series:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Fitting and SVM to the census data](img/B04881_05_45.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Thus, the Gaussian kernel captures a similarity in an infinite dimensional features
    space.
  prefs: []
  type: TYPE_NORMAL
- en: 'We fit the SVM model to the training data using the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'However, upon plotting the ROC curve for the results, we find that we have
    not improved very much over the logistic regression:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Fitting and SVM to the census data](img/B04881_05_46.jpg)'
  prefs: []
  type: TYPE_IMG
- en: It may be difficult to see, but the red line in the upper left-hand corner of
    the image is the performance on the training set, while the blue line is the performance
    on the test set. Thus, we are in a situation such as we described previously,
    where the model almost perfectly predicts the training data but poorly generalizes
    to the test set.
  prefs: []
  type: TYPE_NORMAL
- en: 'In some sense, we were able to make progress because we used a nonlinear function
    to represent similarity within our data. However, the model now fits our data
    too well. If we wanted to experiment more with SVM models, we could tune a number
    of parameters: we could change kernel function, adjust the bandwidth of the Gaussian
    kernel (or the particular hyper parameters of whichever kernel function we chose),
    or tune the amount by which we penalize errors in classification. However, for
    our next step of algorithm optimization, we will instead switch gears and try
    to incorporate nonlinearity with many weak models instead of one overfit model,
    a concept known as boosting.'
  prefs: []
  type: TYPE_NORMAL
- en: Boosting – combining small models to improve accuracy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the previous examples, we have implicitly assumed that there is a single
    model that can describe all the patterns present in our data set. What if, instead,
    a different model were best suited for a pattern represented by a subset of data,
    and only by combining models representing many of these smaller patterns can we
    can get an accurate picture? This is the intuition behind boosting—we start with
    a weak individual model, determine which points it correctly classifies, and fit
    additional models to compensate for points missed by this first model. While each
    additional model is also relatively poor on its own, by successively adding these
    weak models that capture a certain subset of the data, we gradually arrive at
    an accurate prediction overall. Furthermore, because each of the models in this
    group is fit to only a subset of the data, we have to worry less about over-fitting.
    While the general idea of boosting can be applied to many models, let us look
    at an example using the decision trees we covered in [Chapter 4](ch04.html "Chapter 4. Connecting
    the Dots with Models – Regression Methods"), *Connecting the Dots with Models
    – Regression Methods*.
  prefs: []
  type: TYPE_NORMAL
- en: Gradient boosted decision trees
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Recall that in [Chapter 4](ch04.html "Chapter 4. Connecting the Dots with Models
    – Regression Methods"), *Connecting the Dots with Models – Regression Methods*,
    we achieved greater predictive power in our regression task by averaging over
    a set of trees with random features. Gradient boosted decision trees (Breiman,
    Leo. Arcing the edge. Technical Report 486, Statistics Department, University
    of California at Berkeley, 1997; Friedman, Jerome H. *Greedy function approximation:
    a gradient boosting machine*. Annals of statistics (2001): 1189-1232; Friedman,
    Jerome H. *Stochastic gradient boosting*. Computational Statistics and Data Analysis
    38.4 (2002): 367-378.) follow a similar strategy, but instead of choosing random
    features with each step, we greedily optimize at each point. The general algorithm
    is:'
  prefs: []
  type: TYPE_NORMAL
- en: Start with a constant value, such as the average response across the input data.
    This is the baseline model, *F0*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Fit a decision tree *h* to the training data, usually limiting it to have very
    shallow depth, with the target as the **pseudo-residuals** for each point `i`
    given by:![Gradient boosted decision trees](img/B04881_05_50.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Conceptually, the pseudo-residual for a given loss function L (such as the squared
    error that we studied in [Chapter 4](ch04.html "Chapter 4. Connecting the Dots
    with Models – Regression Methods"), *Connecting the Dots with Models – Regression
    Methods* or the hinge loss for the SVM described above) is the derivative of the
    loss function with respect to the value of the current model *F* at a point `yi`.
    While a standard residual would just give the difference between the predicted
    and observed value, the pseudo-residual represents how rapidly the loss is changing
    at a given point, and thus in what direction we need to move the model parameters
    to better classify this point.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To step 1, add the value of the tree in step 2 multiplied by an optimal step
    `γ` and a learning rate `α`:![Gradient boosted decision trees](img/B04881_05_47.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We could either choose a `γ` that is optimal for the whole tree, or for each
    individual leaf node, and we can determine the optimal value using a method such
    as the Newton optimization we discussed above.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat steps 1–3 until convergence.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The goal is that by fitting several weaker trees, in aggregate they make better
    predictions as they sequentially are fit to compensate for the remaining residuals
    in the model at each step. In practice, we also choose only a subset of the training
    data to fit the trees at each stage, which should further reduce the possibility
    of over-fitting. Let us examine this theory on our dataset by fitting a model
    with 200 trees with a maximum depth of 5:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, when we plot the results, we see a remarkable increase in accuracy on
    the test set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: '![Gradient boosted decision trees](img/B04881_05_48.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Similar to the random forest model, we can examine the importance of features
    as determined by the loss in accuracy upon shuffling their values among data points:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Note that this is not directly comparable to the same evaluation we performed
    for the logistic regression model as the importance here is not determined by
    whether the feature predicts positively or negatively, which is implicit in the
    sign of the coefficients in the logistic regression.
  prefs: []
  type: TYPE_NORMAL
- en: 'Also note that there is a subtler problem here with interpreting the output
    coefficients: many of our features are actually individual categories of a common
    feature, such as country of origin or education level. What we are really interested
    in is the importance of the overall feature, not the individual levels. Thus,
    to quantify feature importance more accurately, we could average the importance
    over all columns containing categories belonging to a common feature.'
  prefs: []
  type: TYPE_NORMAL
- en: If we wanted to further tune the performance of the gbm model, we could perform
    a search of different values for the number of trees, the depth of those trees,
    the learning rate (`α` in the formulas above), and `min_samples_leaf` (which determines
    the minimum number of data points that need to be present to split the data form
    a bottom-most split, or leaf, in the tree), among others. As a rule of thumb,
    making deeper trees will increase the risk of over-fitting, but shallower trees
    will requires a larger number of models to achieve good accuracy. Similarly, a
    lower learning rate will also control over-fitting by reducing the contribution
    of any single tree to the model score, but again may require a tradeoff in more
    models to achieve the desired level of predictive accuracy. The balance between
    these parameters may be guided both by the application (how accurate the model
    should be to contribute meaningfully to a business problem) as well as performance
    considerations (if the model needs to run online in a website, for example, a
    smaller number of trees that occupy less memory may be beneficial and worth a
    somewhat reduced accuracy).
  prefs: []
  type: TYPE_NORMAL
- en: Comparing classification methods
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter we have examined classification using logistic regression, support
    vector machines, and gradient boosted decision trees. In what scenarios should
    we prefer one algorithm over another?
  prefs: []
  type: TYPE_NORMAL
- en: For logistic regression, the data ideally will be linearly separable (the exponent
    in the formula for the logistic regression, after all, is essentially the same
    as the SVM equation for a separating hyperplane). If our goal is inference (producing
    a unit increase in response per 1-unit increase of input measurement, as we described
    in [Chapter 1](ch01.html "Chapter 1. From Data to Decisions – Getting Started
    with Analytic Applications"), *From Data to Decisions – Getting Started with Analytic
    Applications*) then the coefficients and log-odds values will be helpful. The
    stochastic gradient method can also be helpful in cases where we are unable to
    process all the data concurrently, while the second order methods we discussed
    may be easier to employ on un-normalized data. Finally, in the context of serializing
    model parameters and using these results to score new data, the logistic regression
    is attractive in that it is represented by a vector of numbers and is thus easily
    stored.
  prefs: []
  type: TYPE_NORMAL
- en: Support vector machines, as we discussed, can accommodate complex nonlinear
    boundaries between inputs. They can also be used on data without a vector representation,
    or data of different lengths, making them quite flexible. However, they require
    more computational resources for fitting as well as scoring.
  prefs: []
  type: TYPE_NORMAL
- en: Gradient boosted decision trees can fit nonlinear boundaries between inputs,
    but only certain kinds. Consider that a decision tree splits a dataset into two
    groups at each decision node. Thus, the resulting boundaries represent a series
    of hyperplanes in the m-dimensional space of the dataset, but only split along
    a particular dimension at each pass and only in a straight line. Thus, these planes
    will not necessarily capture the nonlinearity possible with the SVM, but if the
    data can be separated in this piecewise fashion a GBM may perform well.
  prefs: []
  type: TYPE_NORMAL
- en: The flowchart below gives a general overview from choosing among the classification
    methods we have discussed. Also, keep in mind that the Random Forest algorithm
    we discussed in [Chapter 4](ch04.html "Chapter 4. Connecting the Dots with Models
    – Regression Methods"), *Connecting the Dots with Models – Regression Methods*
    may also be applied for classification, while the SVM and GBM models describe
    in this chapter have forms that may be applied for regression.
  prefs: []
  type: TYPE_NORMAL
- en: '![Comparing classification methods](img/B04881_05_49.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Case study: fitting classifier models in pyspark'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have examined several algorithms for fitting classifier models
    in the scikit-learn library, let us look at how we might implement a similar model
    in PySpark. We can use the same census dataset from earlier in this chapter, and
    start by loading the data using a textRdd after starting the spark context:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Next we need to split the data into individual fields, and strip whitespace
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, as before, we need to determine which of our features are categorical
    and need to be re-encoded using one-hot encoding. We do this by taking a single
    row and asking whether the string in each position represent a digit (is not a
    categorical variable):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, as before, we need to collect a dictionary representing the string-to-position
    mapping of each categorical label to a place in the one-hot-encoding vector:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we calculate what the total length of the one-hot encoding vector should
    be to represent all the features. We subtract two from this value because the
    last categorical features is income, which has two values and which we use as
    the label for the data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we use a map function to turn all of our data into labeled point objects
    for use in logistic regression. To do so, we extract the label for each row from
    the last element in the vector, then instantiate an empty vector using the length
    of the one-hot-encoded feature set we calculated preceding. We use two indices:
    one for which categorical variable we are accessing (to index the right dictionary
    to perform our mapping), and a second to record where in the feature vector we
    are (since for categorical variables we will skip over k spaces for a given variable,
    where k is the number of categories in that variable).'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: We apply this function to all data points
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that our data is in the right format, we can run logistic regression:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'To access the weights from the resulting model, we can inspect the weights
    parameter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: If we wanted to apply the generated model to a new dataset, we can use the `predict()`
    method of `censusLogistic` on a new feature vector. The steps described above
    are similar to the data processing we used for the scikit-learn example, but can
    ultimately scale to larger datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you've examined how to use classification models and some of
    the strategies for improving model performance. In addition to transforming categorical
    features, you've looked at the interpretation of logistic regression accuracy
    using the ROC curve. In attempting to improve model performance, we demonstrated
    the use of SVMs and were able to increase performance on the training set the
    cost of overfitting. Finally, we were able to achieve good performance on the
    test set through gradient boosted decision trees. Taken together with the material
    in [Chapter 4](ch04.html "Chapter 4. Connecting the Dots with Models – Regression
    Methods"), *Connecting the Dots with Models – Regression Methods*, you should
    now have a full toolkit of methods for continuous and categorical outcomes, which
    you can apply to problems in main domains.
  prefs: []
  type: TYPE_NORMAL
