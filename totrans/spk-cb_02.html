<html><head></head><body><div class="chapter" title="Chapter&#xA0;2.&#xA0;Developing Applications with Spark"><div class="titlepage"><div><div><h1 class="title"><a id="ch02"/>Chapter 2. Developing Applications with Spark</h1></div></div></div><p>In this chapter, we will cover:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Exploring the Spark shell</li><li class="listitem" style="list-style-type: disc">Developing a Spark application in Eclipse with Maven</li><li class="listitem" style="list-style-type: disc">Developing Spark applications in Eclipse with SBT</li><li class="listitem" style="list-style-type: disc">Developing a Spark application in Intellij IDEA with Maven</li><li class="listitem" style="list-style-type: disc">Developing a Spark application in Intellij IDEA with SBT</li></ul></div><div class="section" title="Introduction"><div class="titlepage"><div><div><h1 class="title"><a id="ch02lvl1sec17"/>Introduction</h1></div></div></div><p>To create production quality Spark jobs/application, it is useful to use various <span class="strong"><strong>integrated development environments</strong></span> (<span class="strong"><strong>IDEs</strong></span>) and build tools. This chapter will cover various IDEs and build tools.</p></div></div>
<div class="section" title="Exploring the Spark shell"><div class="titlepage"><div><div><h1 class="title"><a id="ch02lvl1sec18"/>Exploring the Spark shell</h1></div></div></div><p>Spark comes bundled with a REPL shell, which is a wrapper around the Scala shell. Though the Spark<a id="id93" class="indexterm"/> shell looks like a command line for simple things, in reality a lot of complex queries can also be executed using it. This chapter explores different development environments in which Spark applications can be developed.</p><div class="section" title="How to do it..."><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec29"/>How to do it...</h2></div></div></div><p>Hadoop MapReduce's word count becomes very simple with the Spark shell. In this recipe, we <a id="id94" class="indexterm"/>are going to create a simple 1-line text file, upload it to the <span class="strong"><strong>Hadoop distributed file system</strong></span> (<span class="strong"><strong>HDFS</strong></span>), and use Spark to count occurrences of words. Let's see how:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Create the <code class="literal">words</code> directory by using the following command:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ mkdir words</strong></span>
</pre></div></li><li class="listitem">Get into the <code class="literal">words</code> directory:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ cd words</strong></span>
</pre></div></li><li class="listitem">Create a <code class="literal">sh.txt</code> text file and enter <code class="literal">"to be or not to be"</code> in it:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ echo "to be or not to be" &gt; sh.txt</strong></span>
</pre></div></li><li class="listitem">Start the Spark shell:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ spark-shell</strong></span>
</pre></div></li><li class="listitem">Load the <code class="literal">words</code> directory as RDD:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>Scala&gt; val words = sc.textFile("hdfs://localhost:9000/user/hduser/words")</strong></span>
</pre></div></li><li class="listitem">Count the number of lines ( result: 1):<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>Scala&gt; words.count</strong></span>
</pre></div></li><li class="listitem">Divide the line (or lines) into multiple words:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>Scala&gt; val wordsFlatMap = words.flatMap(_.split("\\W+"))</strong></span>
</pre></div></li><li class="listitem">Convert <code class="literal">word</code> to (word,1)—that is, output <code class="literal">1</code> as the value for each occurrence of <code class="literal">word</code> as <a id="id95" class="indexterm"/>a key:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>Scala&gt; val wordsMap = wordsFlatMap.map( w =&gt; (w,1))</strong></span>
</pre></div></li><li class="listitem">Use the <code class="literal">reduceByKey</code> method to add the number of occurrences for each word as a key (the function works on two consecutive values at a time represented by <code class="literal">a</code> and <code class="literal">b</code>):<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>Scala&gt; val wordCount = wordsMap.reduceByKey( (a,b) =&gt; (a+b))</strong></span>
</pre></div></li><li class="listitem">Sort the results:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>Scala&gt; val wordCountSorted = wordCount.sortByKey(true)</strong></span>
</pre></div></li><li class="listitem">Print the RDD:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>Scala&gt; wordCountSorted.collect.foreach(println)</strong></span>
</pre></div></li><li class="listitem">Doing all of the preceding operations in one step is as follows:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>Scala&gt; sc.textFile("hdfs://localhost:9000/user/hduser/words"). flatMap(_.split("\\W+")).map( w =&gt; (w,1)). reduceByKey( (a,b) =&gt; (a+b)).sortByKey(true).collect.foreach(println)</strong></span>
</pre></div></li></ol></div><p>This gives us the following output:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>(or,1)</strong></span>
<span class="strong"><strong>(to,2)</strong></span>
<span class="strong"><strong>(not,1)</strong></span>
<span class="strong"><strong>(be,2)</strong></span>
</pre></div><p>Now you understand the basics, load HDFS with a large amount of text—for example, stories—and see the magic.</p><p>If you have the files in a compressed format, you can load them as is in HDFS. Both Hadoop and Spark have codecs for unzipping, which they use based on file extensions.</p><p>When <code class="literal">wordsFlatMap</code> was converted to <code class="literal">wordsMap</code> RDD, there was an implicit conversion. This converts RDD into <code class="literal">PairRDD</code>. This is an implicit conversion, which does not require<a id="id96" class="indexterm"/> anything to be done. If you are doing it in Scala code, please add the following <code class="literal">import</code> statement:</p><div class="informalexample"><pre class="programlisting">import org.apache.spark.SparkContext._</pre></div></div></div>
<div class="section" title="Developing Spark applications in Eclipse with Maven"><div class="titlepage"><div><div><h1 class="title"><a id="ch02lvl1sec19"/>Developing Spark applications in Eclipse with Maven</h1></div></div></div><p>Maven as <a id="id97" class="indexterm"/>a build tool has become<a id="id98" class="indexterm"/> the de-facto standard over the years. It's not surprising if we look little deeper into the promise Maven brings. Maven <a id="id99" class="indexterm"/>has two primary features and they<a id="id100" class="indexterm"/> are:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Convention over configuration</strong></span>: Build tools prior to Maven gave developers freedom about where<a id="id101" class="indexterm"/> to put source files, where to put test files, where to put compiled files, and so on. Maven takes away that freedom. With this freedom, all the confusion about locations also goes. In Maven, there is a specific directory structure for everything. The following table shows a few of the most common locations:<div class="informaltable"><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/></colgroup><tbody><tr><td style="text-align: left" valign="top">
<p><code class="literal">/src/main/scala</code></p>
</td><td style="text-align: left" valign="top">
<p>Source code in Scala</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p><code class="literal">/src/main/java</code></p>
</td><td style="text-align: left" valign="top">
<p>Source code in Java</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p><code class="literal">/src/main/resources</code></p>
</td><td style="text-align: left" valign="top">
<p>Resources to be used by source code such as configuration files</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p><code class="literal">/src/test/scala</code></p>
</td><td style="text-align: left" valign="top">
<p>Test code in Scala</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p><code class="literal">/src/test/java</code></p>
</td><td style="text-align: left" valign="top">
<p>Test code in Java</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p><code class="literal">/src/test/resources</code></p>
</td><td style="text-align: left" valign="top">
<p>Resources to be used by test code such as configuration files</p>
</td></tr></tbody></table></div></li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Declarative dependency management</strong></span>: In Maven, every library is defined by following three coordinates:<div class="informaltable"><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/></colgroup><tbody><tr><td style="text-align: left" valign="top">
<p><code class="literal">groupId</code></p>
</td><td style="text-align: left" valign="top">
<p>A logical way of grouping libraries similar to a package in Java/Scala, which has to be at least the domain name you own—for example, <code class="literal">org.apache.spark</code></p>
</td></tr><tr><td style="text-align: left" valign="top">
<p><code class="literal">artifactId</code></p>
</td><td style="text-align: left" valign="top">
<p>The name of the project and JAR</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p><code class="literal">version</code></p>
</td><td style="text-align: left" valign="top">
<p>Standard version numbers</p>
</td></tr></tbody></table></div></li></ul></div><p>In <code class="literal">pom.xml</code> (the configuration file that tells Maven all the information about a project), dependencies are declared in the form of these three coordinates. There is no need to search over the Internet and download, unpack, and copy libraries. All you need to do is to provide three coordinates of the dependency JAR you need and Maven will do the rest for you. The following is an example of using a JUnit dependency:</p><div class="informalexample"><pre class="programlisting">&lt;dependency&gt;
  &lt;groupId&gt;junit&lt;/groupId&gt;
  &lt;artifactId&gt;junit&lt;/artifactId&gt;
  &lt;version&gt;4.12&lt;/version&gt;
&lt;/dependency&gt;</pre></div><p>This<a id="id102" class="indexterm"/> makes dependency management<a id="id103" class="indexterm"/> including transitive<a id="id104" class="indexterm"/> dependencies very easy. Build tools that came after Maven such as SBT and Gradle also follow these two rules as-is and provide enhancements in other aspects.</p><div class="section" title="Getting ready"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec30"/>Getting ready</h2></div></div></div><p>From this recipe<a id="id105" class="indexterm"/> onwards, this chapter assumes you have installed Eclipse. Please visit <a class="ulink" href="http://www.eclipse.org">http://www.eclipse.org</a> for details.</p></div><div class="section" title="How to do it..."><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec31"/>How to do it...</h2></div></div></div><p>Let's see how to install the Maven plugin for Eclipse:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Open Eclipse and navigate to <span class="strong"><strong>Help</strong></span> | <span class="strong"><strong>Install New Software</strong></span>.</li><li class="listitem">Click on the <span class="strong"><strong>Work with</strong></span> drop-down menu.</li><li class="listitem">Select the &lt;eclipse version&gt; update site.</li><li class="listitem">Click on <span class="strong"><strong>Collaboration tools</strong></span>.</li><li class="listitem">Check Maven's integration with Eclipse, as in the following screenshot:<div class="mediaobject"><img src="graphics/B03056_02_01.jpg" alt="How to do it..."/></div></li><li class="listitem">Click<a id="id106" class="indexterm"/> on <span class="strong"><strong>Next</strong></span> and then <a id="id107" class="indexterm"/>click on <span class="strong"><strong>Finish</strong></span>.<p>There will be a prompt to restart Eclipse and Maven will be installed after the restart.</p></li></ol></div><p>Now let's <a id="id108" class="indexterm"/>see how we can install the Scala plugin for Eclipse:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Open Eclipse and navigate to <span class="strong"><strong>Help</strong></span> | <span class="strong"><strong>Install New Software</strong></span>.</li><li class="listitem">Click on the <span class="strong"><strong>Work with</strong></span> drop-down menu.</li><li class="listitem">Select the &lt;eclipse version&gt; update site.</li><li class="listitem">Type <code class="literal">http://download.scala-ide.org/sdk/helium/e38/scala210/stable/site</code>.</li><li class="listitem">Press<a id="id109" class="indexterm"/> <span class="emphasis"><em>Enter</em></span>.</li><li class="listitem">Select <a id="id110" class="indexterm"/><span class="strong"><strong>Scala IDE for Eclipse</strong></span>:<div class="mediaobject"><img src="graphics/B03056_02_02.jpg" alt="How to do it..."/></div></li><li class="listitem">Click<a id="id111" class="indexterm"/> on <span class="strong"><strong>Next</strong></span> and then click on <span class="strong"><strong>Finish</strong></span>. You will be prompted to restart Eclipse and Scala will be installed after the restart.</li><li class="listitem">Navigate<a id="id112" class="indexterm"/> to <span class="strong"><strong>Window</strong></span> | <span class="strong"><strong>Open Perspective</strong></span> | <span class="strong"><strong>Scala</strong></span>.</li></ol></div><p>Eclipse<a id="id113" class="indexterm"/> is <a id="id114" class="indexterm"/>now ready for Scala development!</p></div></div>
<div class="section" title="Developing Spark applications in Eclipse with SBT"><div class="titlepage"><div><div><h1 class="title"><a id="ch02lvl1sec20"/>Developing Spark applications in Eclipse with SBT</h1></div></div></div><p><span class="strong"><strong>Simple Build Tool</strong></span> (<span class="strong"><strong>SBT</strong></span>) is <a id="id115" class="indexterm"/>a build tool made especially for Scala-based development. SBT follows Maven-based naming <a id="id116" class="indexterm"/>conventions and declarative <a id="id117" class="indexterm"/>dependency management.</p><p>SBT <a id="id118" class="indexterm"/>provides the following enhancements over Maven:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Dependencies are in the form of key-value pairs in the <code class="literal">build.sbt</code> file as opposed to <code class="literal">pom.xml</code> in Maven</li><li class="listitem" style="list-style-type: disc">It provides a shell that makes it very handy to perform build operations</li><li class="listitem" style="list-style-type: disc">For simple projects without dependencies, you do not even need the <code class="literal">build.sbt</code> file</li></ul></div><p>In <code class="literal">build.sbt</code>, the first line is the project definition:</p><div class="informalexample"><pre class="programlisting">lazy val root = (project in file("."))</pre></div><p>Each project has an immutable map of key-value pairs. This map is changed by settings in SBT like so:</p><div class="informalexample"><pre class="programlisting">lazy val root = (project in file("."))
  settings(
    name := "wordcount"
  )</pre></div><p>Every change in the settings leads to a new map, as it's an immutable map.</p><div class="section" title="How to do it..."><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec32"/>How to do it...</h2></div></div></div><p>Here's how we go about adding the <code class="literal">sbteclipse</code> plugin:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Add this to the global plugin file:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ mkdir /home/hduser/.sbt/0.13/plugins</strong></span>
<span class="strong"><strong>$ echo addSbtPlugin("com.typesafe.sbteclipse" % "sbteclipse-plugin" % "2.5.0" )  &gt; /home/hduser/.sbt/0.12/plugins/plugin.sbt</strong></span>
</pre></div><p>Alternatively, you can add the following to your project:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ cd &lt;project-home&gt;</strong></span>
<span class="strong"><strong>$ echo addSbtPlugin("com.typesafe.sbteclipse" % "sbteclipse-plugin" % "2.5.0" )  &gt; plugin.sbt</strong></span>
</pre></div></li><li class="listitem">Start <a id="id119" class="indexterm"/>the <code class="literal">sbt</code> shell <a id="id120" class="indexterm"/>without any arguments:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$sbt</strong></span>
</pre></div></li><li class="listitem">Type <code class="literal">eclipse</code> and <a id="id121" class="indexterm"/>it will make an Eclipse-ready project:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ eclipse</strong></span>
</pre></div></li><li class="listitem">Now you can navigate to <span class="strong"><strong>File</strong></span> | <span class="strong"><strong>Import</strong></span> | <span class="strong"><strong>Import existing project into workspace</strong></span> to load the project into Eclipse.</li></ol></div><p>Now you can develop the Spark application in Scala using Eclipse and SBT.</p></div></div>
<div class="section" title="Developing a Spark application in IntelliJ IDEA with Maven"><div class="titlepage"><div><div><h1 class="title"><a id="ch02lvl1sec21"/>Developing a Spark application in IntelliJ IDEA with Maven</h1></div></div></div><p>IntelliJ IDEA <a id="id122" class="indexterm"/>comes bundled<a id="id123" class="indexterm"/> with support for Maven. We <a id="id124" class="indexterm"/>will see how to create a new Maven project in this recipe.</p><div class="section" title="How to do it..."><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec33"/>How to do it...</h2></div></div></div><p>Perform the following steps to develop a Spark application on IntelliJ IDEA with Maven:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Select <span class="strong"><strong>Maven</strong></span> in new project window and click on <span class="strong"><strong>Next</strong></span>:<div class="mediaobject"><img src="graphics/B03056_02_03.jpg" alt="How to do it..."/></div></li><li class="listitem">Enter <a id="id125" class="indexterm"/>three dimensions<a id="id126" class="indexterm"/> of<a id="id127" class="indexterm"/> the project:<div class="mediaobject"><img src="graphics/B03056_02_04.jpg" alt="How to do it..."/></div></li><li class="listitem">Enter<a id="id128" class="indexterm"/> the project's <a id="id129" class="indexterm"/>name <a id="id130" class="indexterm"/>and location:<div class="mediaobject"><img src="graphics/B03056_02_05.jpg" alt="How to do it..."/></div></li><li class="listitem">Click<a id="id131" class="indexterm"/> on <span class="strong"><strong>Finish</strong></span> and<a id="id132" class="indexterm"/> the Maven <a id="id133" class="indexterm"/>project is ready.</li></ol></div></div></div>
<div class="section" title="Developing a Spark application in IntelliJ IDEA with SBT"><div class="titlepage"><div><div><h1 class="title"><a id="ch02lvl1sec22"/>Developing a Spark application in IntelliJ IDEA with SBT</h1></div></div></div><p>Before Eclipse<a id="id134" class="indexterm"/> became famous, IntelliJ IDEA <a id="id135" class="indexterm"/>was considered<a id="id136" class="indexterm"/> best of the breed in IDEs. IDEA has not shed its former glory yet and a lot of developers love IDEA. IDEA also has a community edition, which is free. IDEA provides native support for SBT, which makes it ideal for SBT and Scala development.</p><div class="section" title="How to do it..."><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec34"/>How to do it...</h2></div></div></div><p>Perform<a id="id137" class="indexterm"/> the following steps to develop a <a id="id138" class="indexterm"/>Spark application on IntelliJ IDEA <a id="id139" class="indexterm"/>with SBT:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Add the <code class="literal">sbt-idea</code> plugin.</li><li class="listitem">Add to the global plugin file:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$mkdir /home/hduser/.sbt/0.13/plugins</strong></span>
<span class="strong"><strong>$echo addSbtPlugin("com.github.mpeltone" % "sbt-idea" % "1.6.0" )  &gt; /home/hduser/.sbt/0.12/plugins/plugin.sbt</strong></span>
</pre></div><p>Alternatively, you can add to your project as well:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$cd &lt;project-home&gt;</strong></span>
<span class="strong"><strong>$ echo addSbtPlugin("com.github.mpeltone" % "sbt-idea" % "1.6.0" ) &gt; plugin.sbt</strong></span>
</pre></div></li></ol></div><p>IDEA is ready to use with SBT.</p><p>Now you can develop Spark code using Scala and build using SBT.</p></div></div></body></html>