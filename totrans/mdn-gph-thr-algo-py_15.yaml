- en: '10'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Pathway Mining
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we’ll explore pathway mining, where we use network science
    and reasoning algorithms to uncover paths that exist within sequential data. Pathways
    to outcomes are common in both the medical field, where disease progression often
    follows a pathway from one disease state to another, and the educational field,
    where course material often builds on prior course material within a degree program
    such as law or medicine. We’ll consider a simulated example of medical courses
    leading to student success or failure in a hypothetical medical school to understand
    which courses may require extra support for struggling students to ensure ultimate
    program success.
  prefs: []
  type: TYPE_NORMAL
- en: By the end of this chapter, you’ll understand how to spot problems involving
    pathways to an outcome of interest, apply advanced reasoning algorithms to find
    likely pathways within a dataset and interpret the results to intervene at key
    points in the pathway to a given outcome of interest. We’ll consider pathway mining
    within the context of education, but many problems in the real world involve pathways.
    Let’s explore some of these scenarios in more depth.
  prefs: []
  type: TYPE_NORMAL
- en: 'Specifically, we will cover the following topics in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to Bayesian networks and causal pathways
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Educational pathway example
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Analyzing course sequencing to find optimal student pathways to graduation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You will require Jupyter Notebook to run the practical examples in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code for this chapter is available here: [https://github.com/PacktPublishing/Modern-Graph-Theory-Algorithms-with-Python](https://github.com/PacktPublishing/Modern-Graph-Theory-Algorithms-with-Python)'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to Bayesian networks and causal pathways
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Many outcomes of interest across industries involve a sequence of events or
    choices to reach the outcome of interest. The arrival of packages depends on the
    safe arrival of packages at each relay point between shipping and arrival. Machinery
    failure can involve **single points of failure** (**SPOFs**) or cascades of failure,
    in which multiple parts of the machine fail before the machinery itself fails.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the pathway to drug addiction. First, a person must be in a situation
    where drug use occurs—through friends, through family, or through a new social
    group. Then, a person must try an addictive substance. Then, they must like the
    substance enough to continue using the substance frequently enough to reach a
    point of physical or psychological dependence on the drug. *Figure 10**.1* shows
    this sequence of steps in a diagram format:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.1 – A sequential progression of events leading to drug addiction](img/B21087_10_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.1 – A sequential progression of events leading to drug addiction
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 10**.1* looks a lot like a directed network, where each situation is
    a vertex and each step in the pathway is a directed edge. Each edge representing
    a progression step might be weighted by a probability of progression from one
    vertex to the next. Let’s consider a population of adolescents at high risk of
    trying a new type of drug and some cross-sectional data on populations at each
    stage of use that a researcher has collected on the population to determine risks
    at each step. Let’s say that all adolescents have been in a situation where they
    could try the drug, but only 30% of those who could try it actually do try it.
    Of those who try the drug, only 20% like it enough to continue using the drug.
    However, of those who do continue using it, 40% will become dependent on the drug.
    *Figure 10**.2* summarizes this information:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.2 – A pathway to drug addiction with probability of transition
    at each step in the pathway](img/B21087_10_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.2 – A pathway to drug addiction with probability of transition at
    each step in the pathway
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 10**.2* shows a chain of probabilities as drug use progresses through
    different stages of use. We can find the probability of reaching each stage by
    multiplying the transition probability of each step before a given stage. For
    instance, regular use in this population involves trying the drug (30% chance
    of doing so) and starting regular use (20% chance of doing so); this gives a 6%
    chance (0.3 multiplied by 0.2) of an adolescent in this population using this
    new drug regularly. Given that 40% of these adolescents using the new drug regularly
    end up dependent on it, we’d expect any given adolescent in this population to
    have a 2.4% chance of progressing to dependency on the new drug given their environment
    that is conducive to trying the drug.'
  prefs: []
  type: TYPE_NORMAL
- en: Mathematics provides us with a formal way to study these pathways or construct
    them from a set of data. Let’s turn to the mathematical tools we need to formalize
    this intuition of probabilities across a sequence of events.
  prefs: []
  type: TYPE_NORMAL
- en: Bayes’ Theorem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The probability of an event that depends on other events is called **conditional
    probability**. In probability theory, conditional probability is a measure of
    the probability of an event occurring, given that another event has already occurred.
    In *Figure 10**.2*, the progression to drug dependence relies on regularly using
    the new drug, which relies upon trying the drug for the first time, which relies
    upon being in a situation where people use the drug. While conditional probability
    doesn’t need to involve this many conditional steps, it does involve a prior event
    that influences the probability of an event of interest occurring.
  prefs: []
  type: TYPE_NORMAL
- en: 'Going back to our example in *Figure 10**.2*, we have a universe where an adolescent
    is exposed to drug use, represented in *Figure 10**.3* as a rectangle:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.3 – A universe in which drug use is possible](img/B21087_10_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.3 – A universe in which drug use is possible
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 10**.3* shows an event that is 100% for our group of adolescents; all
    of them are exposed to this new drug at home, at school, or while they are with
    friends. However, the event of trying the new drug only occurs 30% of the time,
    given a new universe that is much smaller (shown in *Figure 10**.4*):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.4 – A new universe of trying the drug within our initial universe
    of being exposed to drug use](img/B21087_10_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.4 – A new universe of trying the drug within our initial universe
    of being exposed to drug use
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 10**.4* shows a new universe, where a subset of adolescents try the
    new drug. Of these adolescents, 20% will regularly use the drug. This creates
    a new universe, as shown in *Figure 10**.5*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.5 – A smaller universe containing adolescents who regularly use
    the new drug](img/B21087_10_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.5 – A smaller universe containing adolescents who regularly use the
    new drug
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 10**.5* shows a very small universe of adolescents compared to the
    initial universe of all adolescents at risk of trying this new drug (as we would
    expect, given that only 6% of adolescents in this population end up using the
    new drug regularly). Among those who regularly use the new drug, we can split
    the universe shown in *Figure 10**.5* again to obtain the set of adolescents who
    become dependent on the drug. We won’t visualize this universe, as it is too small
    to visualize well within the small rectangle of regular drug use.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Bayes’ Theorem** provides a formula for calculating conditional probability
    by relating prior events’ probabilities to the event of interest. We can compute
    the probability of an event, *A*, given event *B* through the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '`P(A|B)=(P(A)*P(B|A))/P(B)`'
  prefs: []
  type: TYPE_NORMAL
- en: Here, *P(A|B)* is the probability of event *A* occurring given event *B* occurring,
    *P(A)* is the probability of event *A* happening, *P(B|A)* is the probability
    of event *B* occurring given event *A* occurring, and *P(B)* is the probability
    of event *B* occurring.
  prefs: []
  type: TYPE_NORMAL
- en: 'To make this more concrete, let’s go back to our drug use example. We’ll call
    event *A* trying the new drug and event *B* being present where the drug is used.
    The probability of event *B* is 100%, as is the probability of event *B* given
    event *A*. The probability of event *A* is 30%. Let’s plug the values into our
    formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '`P(A|B)=(0.3*1)/1`'
  prefs: []
  type: TYPE_NORMAL
- en: This gives us our expected 30%. However, within probability theory, not all
    events have a probability of 100%, and many calculations will be more complicated
    as conditional events are added. Within real-world data, we may need to estimate
    these probabilities with an algorithm given the data we’ve collected. Let’s move
    on to event chains such as our drug use example.
  prefs: []
  type: TYPE_NORMAL
- en: Causal pathways
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Conditional probability can involve more than two events of interest with conditional
    relationships. **Causal pathways** involve chains of conditional probability that
    can be relatively short, such as our drug dependence example, or very, very long
    and complex, such as protein activation pathways contributing to disease risk.
  prefs: []
  type: TYPE_NORMAL
- en: Thanks to Bayes’ Theorem, we can chain conditional probabilities together in
    a piecewise fashion until all conditional probabilities are linked into a final
    pathway. This works quite well for estimating effect sizes and progression rates
    for well-known causal pathways. However, many times, we don’t know the exact sequence
    of events leading to an outcome of interest and simply collect a lot of data we
    think is related to the outcome. To analyze this data, we’ll need an algorithm.
    Fortunately, one exists. Let’s dive into Bayesian networks and their application
    to causal pathway mining.
  prefs: []
  type: TYPE_NORMAL
- en: Bayesian networks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A **Bayesian network** depicts a set of variables and their conditional probabilities
    as a **directed acyclic graph** (**DAG**). Vertices that are not connected by
    an edge are conditionally independent (not dependent on each other). Vertices
    connected by an edge are conditionally dependent.
  prefs: []
  type: TYPE_NORMAL
- en: 'The **chain rule of probability** allows us to construct a Bayesian network
    as a product of conditional probabilities. Consider events *A*, *B*, and *C*.
    Returning to our drug use example, event *A* might be regular use, event *B* trying
    the drug, and event *C* might be around the drug. Our causal chain is thus the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`P(A,B,C)=P(A|B,C)*P(B|C)*P(C)`'
  prefs: []
  type: TYPE_NORMAL
- en: '*P(A, B, C)* refers to the probability of all events occurring. *P(A|B, C)*
    refers to the probability of A occurring given that *B* and *C* have occurred.
    *P(B|C)* is the probability of *B* occurring given that *C* has occurred. Because
    these events are usually inferred from data, we need to use an algorithm to estimate
    the joint probability distribution *P(A,B,C).* Typically, this is done with an
    expectation-maximization algorithm through the computation of expected values
    conditional on the data. Then, the algorithm maximizes the complete likelihood,
    assuming that the expected values computed are the correct ones. Values are then
    adjusted again given the likelihood computed in the last step. Once the expected
    values and likelihood converge, the algorithm stops.'
  prefs: []
  type: TYPE_NORMAL
- en: Now that we know the basics of Bayesian networks, let’s turn to an educational
    data example of causal pathways and datasets upon which Bayesian networks can
    learn.
  prefs: []
  type: TYPE_NORMAL
- en: Educational pathway example
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the common uses of Bayesian probability and networks is in educational
    research. Course sequencing involves building upon prior knowledge, and students
    taking courses conditional on prior knowledge must first obtain that prior knowledge
    before they can succeed in the course at hand. Prerequisite courses allow professors
    to require students to take certain courses before taking their courses. Entry
    to university and then to graduate programs is conditional on successful completion
    of exams at the previous level of education. Thus, education is a field in which
    Bayesian networks arise naturally. Let’s dive into an example.
  prefs: []
  type: TYPE_NORMAL
- en: Outcomes in education
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Many outcomes in education are the culmination of the long sequence of courses
    students take. For instance, in South Africa and the United States, a student
    hoping to practice law must take many courses and take a final examination before
    being able to practice law independently. Passing the examination relies on prior
    success in coursework and experience gained in internships and other hands-on
    legal activities. Most medical degrees follow a similar educational approach,
    with a combination of coursework, practical experience, and final examination
    culminating in professional status in the field.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding key milestones and turning points within these pathways ensures
    as many students as possible pass the final examinations to obtain their licenses.
    However, many courses exist, and not all students take the same courses throughout
    their education. Medical students may focus on courses most related to their medical
    subspecialty of interest. Law students may intern within different branches of
    legal practice to see what type of law they might like to practice. Thus, the
    data is often incomplete; coupled with small program sizes, this creates a difficult
    data mining scenario.
  prefs: []
  type: TYPE_NORMAL
- en: Course sequences
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One of the major caveats in professional education is course dependencies. For
    instance, prior to taking a pathology course, medical students typically finish
    human anatomy. You would expect that success in pathology is at least partially
    dependent on success in human anatomy. However, it may not be the case that success
    in pathology depends on success in a human genetics course. It may also be the
    case that success in these three courses does not influence final examination
    results (unlikely, but possible).
  prefs: []
  type: TYPE_NORMAL
- en: To make matters even more complicated, certain modules within a course may be
    more related to student outcomes than other modules. Thus, even a course-level
    analysis might not be sufficient to pinpoint exactly where students’ success or
    failure usually stems. When looking at these types of real-world problems, it
    is important to consider the level of analysis under which the pathway is scrutinized.
  prefs: []
  type: TYPE_NORMAL
- en: Antecedents to success
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Two approaches are common when collecting data related to student success. One
    approach, the agnostic one, does not make assumptions about which courses or modules
    relate most to the outcome. Advantages of this approach include ensuring that
    all possible data is collected so that any existing relationships may be found.
    However, the amount of course/module data collected may be large relative to sample
    size, leading to worse performance of algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Another approach is to have knowledge about pathways of interest prior to collecting
    the data. This approach limits the amount of data collected, allowing algorithms
    to run on a sufficient sample size for good performance; however, if the guess
    is wrong, the results do not reflect the true pathway that exists in the system.
  prefs: []
  type: TYPE_NORMAL
- en: As we simulate data, we’ll take the prior knowledge approach to generate a small
    dataset to demonstrate how Bayesian networks find pathways in datasets. Let’s
    dive into the dataset simulation and see Bayesian networks in action.
  prefs: []
  type: TYPE_NORMAL
- en: Analyzing course sequencing to find optimal student pathways to graduation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this example, we’ll work with a dataset representing a medical program to
    understand pathways to the successful completion of a medical degree. In a real
    medical program, we’d likely include all courses and potentially other factors,
    such as clinical experiences and research projects required for graduation. However,
    to run a simple example, we’ll assume this data mining has already been done to
    identify courses related to graduation outcomes.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to a dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s imagine a medical program with many courses leading to a final licensing
    exam. Some courses aren’t emphasized by the final licensing exam very much (but
    are still important to study before entering the field). A handful of courses,
    though, do show up regularly on the licensing exam, and some build on prior important
    licensing courses. Let’s suppose human anatomy, cellular biology, pathology, microbiology,
    and neuroscience are five courses that are typically associated with success on
    the licensing exam. Some material may overlap across the courses—particularly
    human anatomy, pathology, and microbiology.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use Python to simulate student performance in five courses, with three
    having an overlap of material over the course sequence and two being relatively
    unrelated to the other three courses, and on a final exam to explore how we would
    mine for course pathways related to success on a final outcome—our final exam.
    The `numpy` package has several useful functions to first generate binomial distributions
    with different success probabilities (`random.binomial()`) and then to select
    outcomes from different distributions conditional on other generated probability
    distributions (using the `where()` clause):'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s see this in action with **Script 10.1**, where we first import our packages
    and then generate our conditional course distributions for **500** students:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We’ll then add to **Script 10.1** our final two courses and the dependent performance
    on the final exam:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now that we have our course data on pass/fail performance, we can create a
    data frame containing this data to pass into our pathway mining with a Bayesian
    network. Let’s add this piece to **Script 10.1** to prepare for our pathway mining:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now that we have our dataset, we can turn our attention to the Bayesian network
    we’ll create.
  prefs: []
  type: TYPE_NORMAL
- en: bnlearn analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Python has an easy-to-use package to fit Bayesian networks to datasets such
    as the one we generated in `Script 10.1`: the `bnlearn` package. If you do not
    have the current version of `numpy` installed, you’ll need to update your `numpy`
    version before installing the `bnlearn` package to avoid installation errors.
    We assume that you have completed this step. Follow the next steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: There is a `pandas` dependency as well, so we will provide an example of installing
    a specific version of a package in the following code to deal with the `pandas`
    versioning dependency. You’ll need to restart your Jupyter kernel after this installation.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we’ll install the **bnlearn** package and load it with **Script 10.2**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now that we have our package installed, we can fit a Bayesian network to our
    **Course_Data** dataset using the function’s default parameters by adding to **Script
    10.2**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The default parameters include a hill-climbing algorithm, which searches the
    local model space in a greedy fashion (where each step adjusts a single edge),
    and the **Bayesian inference criterion** (**BIC**) used as a performance measurement
    (which is a model deviance-based measurement penalized by the number of model
    parameters).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The **bnlearn** package has a nice table summary of dependencies found in the
    Bayesian network to show which variables are related. Let’s add this piece to
    **Script 10.2** and examine the printed table’s results in *Figure 10**.6*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '![Figure 10.6 – A summary of our Bayesian network’s results](img/B21087_10_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.6 – A summary of our Bayesian network’s results
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 10**.6* shows which relationships exist between different variables.
    The target is the dependent event, while the source is the prior event upon which
    the target depends. If the dependency was found to exist, the cell relating the
    target and source will read as `True`, while if the dependency was not found to
    exist, the cell will read `False`. Because this is a naïve analysis with respect
    to the timing of courses, we’ll ignore the directionality of the results (such
    as the final exam not being dependent on any of the courses prior to it according
    to the directionality of source and target, but courses being found dependent
    on final exam performance). Typically, Bayesian network analysis is used to find
    relationships rather than explicit directionality, which can be tested with other
    statistical methods (discussed later in this chapter).'
  prefs: []
  type: TYPE_NORMAL
- en: We do find several of the dependencies we simulated. `Course_2` was found to
    be dependent on `Course_1`, and the final exam performance is dependent on `Course_1`,
    `Course_2`, and `Course_3`. While this is not 100% accurate, we did find all four
    of our dependencies as being within a causal pathway.
  prefs: []
  type: TYPE_NORMAL
- en: 'By adding to **Script 10.2**, we can visualize the DAG we found in our analysis:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This plot should show something like *Figure 10**.7*, showing the four related
    variables we simulated as existing within a course success pathway:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 10.7 – A plot of the Bayesian network’s results ](img/B21087_10_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.7 – A plot of the Bayesian network’s results
  prefs: []
  type: TYPE_NORMAL
- en: Our results are pretty good for a small dataset that we simulated with conditional
    and random distribution draws. However, Bayesian networks can be very sensitive
    to algorithms used in fitting. Let’s rerun our analysis using an exhaustive search,
    which scores all possible Bayesian network structures to choose the best model,
    rather than a hill-climbing algorithm. Note that due to the increased compute
    time and power needed to fit the model, it is not advised as a fitting algorithm
    for large datasets or datasets with many variables to explore.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Depending on your system, you may or may not have the following script run to
    completion on your system. On our machine, the following script took over an hour
    to run.
  prefs: []
  type: TYPE_NORMAL
- en: '`Script 10.3` runs this new fit of a Bayesian network to our three courses
    designed to depend on prior course performance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now examine the table of relationships found by our Bayesian network,
    shown in *Figure 10**.8*, by adding to `Script 10.3`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '![Figure 10.8 – Bayesian network table of dependencies among three courses
    we simulated](img/B21087_10_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.8 – Bayesian network table of dependencies among three courses we
    simulated
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 10**.8* shows that this exhaustive search algorithm does find all three
    courses to be dependent, as well as the correct directionality of those dependencies—with
    passing `Course_2` being dependent on passing `Course_1` and with passing `Course_3`
    dependent on passing `Course_1` and `Course_2`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s now visualize these results with a graph representation of our Bayesian
    network, adding the following to `Script 10.3`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'This yields the output shown in *Figure 10**.9*, which shows the dependencies
    found among the three courses. Note the directionality in *Figure 10**.6* matches
    the dependencies we simulated in our dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B21087_10_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.9 – A plot of course pass dependencies among the three courses simulated
    to have interdependencies
  prefs: []
  type: TYPE_NORMAL
- en: Note that while the exhaustive search finds the correct causal pathway, it is
    impractical for most real-world problems, as its run time limits are used on datasets
    with more variables. Even for our full dataset, the runtime to compute a Bayesian
    network with exhaustive search is impractical. However, the greedy hill-climbing
    algorithm was good enough to parse through our data and find likely relationships
    that exist in the dataset. In the real world, mining for pathways is usually just
    a first step in understanding a system. Identifying the main components usually
    suffices for the next steps, which we’ll discuss next.
  prefs: []
  type: TYPE_NORMAL
- en: Structural equation models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Once we have an idea of which parts of a pathway may lead to an outcome of
    interest, we can form a hypothesis regarding the logical steps between these parts.
    For instance, in our course example, we may know that most students take `Course_1`
    before `Course_2` and `Course_2` before `Course_3`. This leads to a hypothesis
    that `Course_1` impacts performance in `Course_2` and `Course_3` and that `Course_2`
    impacts performance in `Course_3`. All three courses are assumed to influence
    performance in the licensing exam. This gives us the hypothesized pathway shown
    in *Figure 10**.10*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.10 – Hypothesized pathway leading to performance in the final licensing
    exam](img/B21087_10_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.10 – Hypothesized pathway leading to performance in the final licensing
    exam
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 10**.10* shows the sequence of events leading to the licensing exam.
    Performance in prior courses influences performance in future courses and, ultimately,
    the licensing step. Failure along the way increases the likelihood of future failure,
    and success along the way increases the likelihood of future success.'
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have a hypothesized pathway, we can collect data from another year
    of students going through this pathway to test our hypothesis. Because we are
    testing several relationships, we’d want a relatively large sample size. Perhaps
    500 students per year take the licensing exam. We may want 2 years’ worth of new
    or historical data on students’ pathways to that licensing exam to test our hypothesis
    with enough statistical power to find effects that exist.
  prefs: []
  type: TYPE_NORMAL
- en: 'Given that random error influences regression model fitting and statistical
    results, running six logistic regression models is not ideal; we’d likely find
    false positives within our set of regression models. However, a handy framework
    exists to model multiple regression models’ fit to causal pathways of interest:
    **structural equation models** (**SEMs**). SEMs provide a framework for fitting
    causal pathway data within the regression framework, including those with fully
    measured variables and **latent variables**—those inferred from relationships
    that exist among measured variables but are not measured directly in the data.'
  prefs: []
  type: TYPE_NORMAL
- en: While SEMs are beyond the scope of this book, many frameworks for fitting models
    exist, and some of the same estimation algorithms and goodness-of-fit statistics
    that we saw in Bayesian network model fitting are used to fit SEMs. R and Mplus
    are more commonly used to fit SEMs than Python, but Python includes the `semopy`
    package to fit SEMs. Note that the types of SEMs are limited compared to the other
    two software systems and that not all estimation algorithms or goodness-of-fit
    statistics exist in Python as of 2023\. However, if you are interested, I encourage
    you to explore SEMs as the next step in pathway mining, and references are provided
    at the end of this chapter if you would like to go further in the field of pathway
    mining.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we introduced causal pathways and conditional probability
    theory through a social science example, building a network-based data mining
    tool called Bayesian networks. We then simulated data from an educational pathway
    to implement Bayesian networks in Python. These tools provided a starting point
    for collecting additional data that could be analyzed to confirm hypotheses constructed
    from Bayesian networks through a class of models called SEMs. In the next chapter,
    we’ll pivot from causal pathways to look at another niche subfield in analytics:
    computational linguistics, where we will study languages and their relationships
    over long periods of time.'
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Gladwin, T. E., Figner, B., Crone, E. A., & Wiers, R. W. (2011). Addiction,
    adolescence, and the integration of control and motivation. *Developmental cognitive
    neuroscience,* *1(4), 364-376.*
  prefs: []
  type: TYPE_NORMAL
- en: 'Heckerman, D. (2008). A tutorial on learning with Bayesian networks. *Innovations
    in Bayesian networks: Theory and* *applications, 33-82.*'
  prefs: []
  type: TYPE_NORMAL
- en: Hoffman, K. I. (1993). The USMLE, the NBME subject examinations, and assessment
    of individual academic achievement. *Academic Medicine,* *68(10), 740-7.*
  prefs: []
  type: TYPE_NORMAL
- en: 'Hoyle, R. H. (Ed.). (1995). *Structural equation modeling: Concepts, issues,
    and* *applications. Sage.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Igolkina, A. A., & Meshcheryakov, G. (2020). semopy: A Python package for structural
    equation modeling. *Structural Equation Modeling: A Multidisciplinary Journal,*
    *27(6), 952-963.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Kaufman, K. A., LaSalle-Ricci, V. H., Glass, C. R., & Arnkoff, D. B. (2007).
    *Passing the bar exam: Psychological, educational, and demographic predictors
    of success. J. Legal Educ.,* *57, 205.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Mak, K. K., Jeong, J., Lee, H. K., & Lee, K. (2018). Mediating effect of internet
    addiction on the association between resilience and depression among Korean University
    students: a structural equation modeling approach. *Psychiatry Investigation,*
    *15(10), 962.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Meca, A., Sabet, R. F., Farrelly, C. M., Benitez, C. G., Schwartz, S. J., Gonzales-Backen,
    M., ... & Lizzi, K. M. (2017). Personal and cultural identity development in recently
    immigrated Hispanic adolescents: Links with psychosocial functioning. *Cultural
    diversity and ethnic minority psychology,* *23(3), 348.*'
  prefs: []
  type: TYPE_NORMAL
- en: Ross, S. M. (2014). *Introduction to probability models.* *Academic Press.*
  prefs: []
  type: TYPE_NORMAL
- en: Scutari, M. (2009). *Learning Bayesian networks with the bnlearn R package.
    arXiv* *preprint* arXiv:0908.3817.
  prefs: []
  type: TYPE_NORMAL
- en: Turner, M. E., & Stevens, C. D. (1959). *The regression analysis of causal paths.
    Biometrics,* *15(2), 236-258.*
  prefs: []
  type: TYPE_NORMAL
- en: 'Violato, C., & Hecker, K. G. (2007). *How to use structural equation modeling
    in medical education research: A brief guide. Teaching and learning in medicine,*
    *19(4), 362-371.*'
  prefs: []
  type: TYPE_NORMAL
- en: Wise, R. A., & Koob, G. F. (2014). The development and maintenance of drug addiction.
    *Neuropsychopharmacology,* *39(2), 254-262.*
  prefs: []
  type: TYPE_NORMAL
- en: Wu, W., Garcia, K., Chandrahas, S., Siddiqui, A., Baronia, R., & Ibrahim, Y.
    (2021). Predictors of performance on USMLE step 1\. *The Southwest Respiratory
    and Critical Care Chronicles,* *9(39), 63-72.*
  prefs: []
  type: TYPE_NORMAL
