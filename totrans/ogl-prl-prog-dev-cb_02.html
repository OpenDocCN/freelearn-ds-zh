<html><head></head><body><div><div><div><div><h1 class="title"><a id="ch02"/>Chapter 2. Understanding OpenCL Data Transfer and Partitioning</h1></div></div></div><p>In this chapter, we'll cover the following recipes:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Creating OpenCL buffer objects</li><li class="listitem" style="list-style-type: disc">Retrieving information about OpenCL buffer objects</li><li class="listitem" style="list-style-type: disc">Creating OpenCL sub-buffer objects</li><li class="listitem" style="list-style-type: disc">Retrieving information about OpenCL sub-buffer objects</li><li class="listitem" style="list-style-type: disc">Understanding events and event-synchronization</li><li class="listitem" style="list-style-type: disc">Copying data between memory objects</li><li class="listitem" style="list-style-type: disc">Using work items to partition data</li></ul></div><div><div><div><div><h1 class="title"><a id="ch02lvl1sec16"/>Introduction</h1></div></div></div><p>In this chapter, we're going to explore how to invoke the OpenCL's data transfer APIs, query memory objects, and data/work partitioning between the GPUs and CPUs.</p><div><div><h3 class="title"><a id="tip03"/>Tip</h3><p>Be aware that not all OpenCL SDKs support the compilation and execution on both GPUs and CPUs. AMD's OpenCL implementation supports its own AMD and Intel CPUs and GPUs; NVIDIA supports its GPUs and Intel supports its own Intel Core CPUs and Intel HD Graphics. Check with the vendor for supported devices.</p></div></div><p>In the <strong>Open Computing Language</strong> (<strong>OpenCL</strong>) development, you <a id="id94" class="indexterm"/>would inevitably need data to be processed, and the standard does not permit you to manipulate memory objects directly as you would do when you program in C or C++, because the data memory in the host is ultimately transferred to the devices in a heterogeneous environment for processing, and previously you would use the programming constructs in various libraries or languages to access them which is one of the reasons why OpenCL came about; hence to unify these approaches, the standard added abstractions to shield the developer from these concerns.</p><p>With respect to data types, there are a few you need to be aware of other than the one-dimensional data buffer. OpenCL buffer objects<a id="id95" class="indexterm"/> can be used to load and store two/three-dimensional data. The next data type in OpenCL is the <code class="literal">image</code> object; these objects are used to store two or three dimensional images (we won't cover much of using the <code class="literal">image</code> objects in this book).</p><p>The OpenCL 1.1 new data transfer capabilities<a id="id96" class="indexterm"/> includes the<a id="id97" class="indexterm"/> following:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Using sub-buffer objects to distribute regions of a buffer across multiple OpenCL devices</li><li class="listitem" style="list-style-type: disc">3-component vector data types</li><li class="listitem" style="list-style-type: disc">Using the global work offset which enables kernels to operate on different portions of the NDRange—global work offset refers to the data points in the input data where work items can start processing</li><li class="listitem" style="list-style-type: disc">Reading, writing, or copying a 1D, 2D or 3D rectangular region of a buffer object</li></ul></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch02lvl1sec17"/>Creating OpenCL buffer objects</h1></div></div></div><p>In the previous chapter, we<a id="id98" class="indexterm"/> understood the need to create or wrap our host's <a id="id99" class="indexterm"/>memory objects into an abstraction that OpenCL can operate on, and in this recipe we'll explore how to create a particular type of memory object defined in the specification that is commonly used for general purpose computation—buffer object. The developer can choose to create a one, two or three dimensional memory object that best fits the computational model.</p><p>Creating buffer objects is simple in OpenCL and is akin to the way in which you would use C's memory allocation routines such as <code class="literal">malloc</code> <a id="id100" class="indexterm"/>and<a id="id101" class="indexterm"/> <code class="literal">alloca</code>. But, that's where the similarity ends for the reason that OpenCL cannot operate directly on memory structures created by those routines. What you can do is to create a memory structure that lives on the devices that can be mapped to the memory on the host and the data is transferred to the device by issuing memory transfer commands to the command queue (which you recall is the conduit to the device). What you need to decide is the sort of objects, and how much of these objects you would like the device to compute.</p><p>In this example, we're going to learn how to create buffer objects based on user-defined structures also known as <code class="literal">structs</code> <a id="id102" class="indexterm"/>in the C/C++ language. Before that, let's understand the API:</p><div><pre class="programlisting">cl_mem clCreateBuffer(cl_context context,
                      cl_mem_flags flags,
                      size_t size,
                      void* host_ptr,
                      cl_int* errcode_ret)</pre></div><p>You can create a buffer by specifying which <code class="literal">context</code> it should attach to (recall that contexts can be created with several devices), specify the size of the data, and where to reference it with <code class="literal">size</code> and <code class="literal">host_ptr</code> respectively, specify how memory is to be allocated and whether that memory is to be of type read, read-only, read-write, or write only via <code class="literal">flags</code>; lastly capture the resultant error code in <code class="literal">errcode_ret</code>. Note that <code class="literal">clCreateBuffer</code> doesn't queue the command to conduct the memory transfer from host to device memory.</p><div><div><div><div><h2 class="title"><a id="ch02lvl2sec28"/>Getting ready</h2></div></div></div><p>Here's a portion <a id="id103" class="indexterm"/>of the code from <code class="literal">Ch2/user_buffer/user_buffer.c</code> where you will see how to use the <code class="literal">clCreateBuffer</code> API to allocate <a id="id104" class="indexterm"/>memory for a user-defined structure. The problem we are trying to solve in this example is to send a million user-defined structures to the device for computation. The computation encapsulated by the kernel is a simple one—sum of all elements of each user-structure. The astute reader would have noticed we could have demonstrated this data structure with a vector data type in OpenCL, <code class="literal">int4</code>; the reason why we didn't do it that way is a two fold: (a) it's an example of application domain modeling, (b) because in a few paragraphs from current we wanted to illustrate how you could use the data type alignment construct, and don't fret over the data types now because we'll dive into the various data types in the next chapter. Continuing further, the user-defined structure is as follows:</p><div><pre class="programlisting">typedef struct UserData {
 int x;
 int y;
 int z;
 int w;
} UserData;</pre></div><p>What you will need to do is to create a buffer on the host application using standard C/C++ dynamic/static memory allocation techniques such as <code class="literal">new</code>, <code class="literal">malloc</code>, and <code class="literal">alloca</code>. Next, you will need to initialize that data buffer, and finally you will have to invoke <code class="literal">clCreateBuffer</code> and you should make sure it's done prior to the call to <code class="literal">clSetKernelArg</code>; recall that we mentioned that kernels get scheduled for execution on the device, well before it executes the kernel code on the device it would need data and values to work against, and you can achieve this by an invocation to <code class="literal">clSetKernelArg</code> and you typically do this when the buffer object is created.</p><p>The API <code class="literal">clSetKernelArg</code> looks like the following code and it'll be important for you to understand how it works:</p><div><pre class="programlisting">cl_int clSetKernelArg(cl_kernel kernel,
                      cl_uint arg_index,
                      size_T arg_size,
                      const void *arg_value);</pre></div><p>The kernel can take no arguments or at least one and probably more arguments, and how you configure them is simple. The following code snippet should complete the story:</p><div><pre class="programlisting">// in the kernel code
_kernel void somefunction(__global int* arg1, __global int* arg2) {…} 
// in the host code
int main(int argc, char**argv) {
// code omitted
cl_kernel kernel; 
// kernel is initialized to point to "somefunction" in the kernel file
clSetKernelArg(kernel, 0, sizeof(cl_mem), (void*) &amp;memoryobjectA);
clSetKernelArg(kernel, 1, sizeof(cl_mem), (void*) &amp;memoryobjectB);</pre></div><p>Therefore, the kernel arguments are configured programmatically with the understanding that if the kernel function has <code class="literal">n</code> arguments then the <code class="literal">arg_index</code> would range from <code class="literal">0</code> to (<code class="literal">n – 1</code>).</p></div><div><div><div><div><h2 class="title"><a id="ch02lvl2sec29"/>How to do it…</h2></div></div></div><p>We've included the<a id="id105" class="indexterm"/> main part of <a id="id106" class="indexterm"/>this recipe from <code class="literal">Ch2/user_buffer/user_buffer.c</code>, with the highlighted commentary:</p><div><pre class="programlisting">/* Defined earlier */
#define DATA_SIZE 1048576
UserData* ud_in = (UserData*) malloc(sizeof(UserData) *
                                     DATA_SIZE); // input to device
/* initialization of 'ud_in' is omitted. See code for details.*/
/* Create a OpenCL buffer object */
cl_mem UDObj = clCreateBuffer(context, 
                              CL_MEM_READ_ONLY |
                              CL_MEM_COPY_HOST_PTR, 
                              sizeof(UserData) * DATA_SIZE,
                              ud_in, &amp;error);
if (error != CL_SUCCESS) {
  perror("Unable to create buffer object");
  exit(1)
}</pre></div><p>On OSX, you would compile the program by running the following command on your terminal:</p><div><pre class="programlisting">
<strong>gcc -std=c99 -Wall -DUNIX -g -DDEBUG -DAPPLE -arch i386 -o user_buffer user_buffer.c   -framework OpenCL</strong>
</pre></div><p>On the Ubuntu Linux 12.04 with Intel OpenCL SDK, the command will be as follows:</p><div><pre class="programlisting">
<strong>gcc -std=c99 -Wall -DUNIX -g -DDEBUG -m64 -o user_buffer user_buffer.c -I . -I /usr/include -L/usr/lib64/OpenCL/vendors/intel -lintelocl -ltbb -ltbbmalloc -lcl_logger -ltask_executor</strong>
</pre></div><p>On the Ubuntu Linux 12.04 with AMD APP SDK v2.8, the command will be as follows:</p><div><pre class="programlisting">
<strong>gcc -std=c99 -Wall -DUNIX -g -DDEBUG –m64 -o user_buffer user_buffer.c   -I. –I/opt/AMDAPP/include –L/opt/AMDAPP/lib/x86_64 –lOpenCL</strong>
</pre></div><p>Regardless of the platform, a binary executable <code class="literal">user_buffer</code> would be deposited locally.</p><div><div><h3 class="title"><a id="note02"/>Note</h3><p>Running the<a id="id107" class="indexterm"/> application <a id="id108" class="indexterm"/>on both platforms, we would get the following result:</p><div><pre class="programlisting">
<strong>Number of OpenCL platforms found: 1</strong>
<strong>Kernel name: hello with arity: 1</strong>
<strong>About to create command queue and enqueue this kernel...</strong>
<strong>Task has been enqueued successfully!</strong>
<strong>Check passed!</strong>
</pre></div></div></div></div><div><div><div><div><h2 class="title"><a id="ch02lvl2sec30"/>How it works…</h2></div></div></div><p>The application created a million of the <code class="literal">UserData</code> objects on the host. Refer to the following code snippet:</p><div><pre class="programlisting">/*
  Prepare an array of UserData via dynamic memory allocation
*/
UserData* ud_in = (UserData*) malloc( sizeof(UserData) * DATA_SIZE); // input to device
UserData* ud_out = (UserData*) malloc( sizeof(UserData) * DATA_SIZE); // output from device
  for( int i = 0; i &lt; DATA_SIZE; ++i) {
    (ud_in + i)-&gt;x = i;
    (ud_in + i)-&gt;y = i;
    (ud_in + i)-&gt;z = i;
    (ud_in + i)-&gt;w = 3 * i;
  }</pre></div><p>The application then sends it to the device for computation after the program and kernel objects have been initialized, and we assign the recently created <code class="literal">UDObj</code> memory object to the kernel as its argument. Refer to the following code snippet:</p><div><pre class="programlisting">error = clSetKernelArg(kernels[i], 0, sizeof(cl_mem), &amp;UDObj);
  if (error != CL_SUCCESS) {
    perror("Unable to create buffer object");
      exit(1);
  }</pre></div><p>Next, we issue a<a id="id109" class="indexterm"/> kernel <a id="id110" class="indexterm"/>execution command to the command-queue, <code class="literal">cQ</code>, and the code will run against the device, the following code snippet demonstrates the enqueuing of the kernel:</p><div><pre class="programlisting">  /* Enqueue the kernel to the command queue */
  error = clEnqueueTask(cQ, kernels[i], 0, NULL, NULL);
    if (error != CL_SUCCESS) {
      perror("Unable to enqueue task to command-queue");
      exit(1);
    }</pre></div><p>After that's done, the data in the device's memory is read back and we indicated that we wish to read the data back until the device has completed its execution by passing <code class="literal">CL_TRUE</code> to indicate blocking read which otherwise could result in partial data read back; finally the data is verified, demonstrated by the following code snippet:</p><div><pre class="programlisting">/* Enqueue the read-back from device to host */
            error = clEnqueueReadBuffer(cQ, UDObj,
                                         CL_TRUE, // blocking read
                                         0, // write from the start
                                         sizeof(UserData) * DATA_SIZE, // how much to copy
                                         ud_out, 0, NULL, NULL);
    if ( valuesOK(ud_in, ud_out) ) {
      printf("Check passed!\n");
    } else printf("Check failed!\n");</pre></div><p>Let's explore how we used <code class="literal">clCreateBuffer</code> further.</p><p>In this scenario, you would want to allocate memory on the device as read-only when it comes to providing input to the device and because you want to be sure nothing else is writing to the data store. Therefore, the flag <code class="literal">CL_MEM_READ_ONLY</code> is passed, but if your input data was meant to be readable and writable then you would need to indicate it using <code class="literal">CL_MEM_READ_WRITE</code>. Notice that we actually created a data store on the host via <code class="literal">ud_in</code> and, we wanted our OpenCL memory object to be the same size as <code class="literal">ud_in</code> and the <code class="literal">C</code> statement reflects this; finally we wanted OpenCL to know that the new memory object is to copy its values from <code class="literal">ud_in</code> and we provided the flag <code class="literal">CL_MEM_COPY_HOST_PTR</code> too, and we use the bitwise <code class="literal">OR</code> operator that is represented on the standard US keyboard as a pipe symbol, <em>|</em>, to merge these two flags.</p><p>Conceptually, you<a id="id111" class="indexterm"/> can <a id="id112" class="indexterm"/>visualize it to be an 1D-array-of-structs for short or an array-of-structures in general.</p><div><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/></colgroup><tbody><tr><td style="text-align: left" valign="top">
<p><code class="literal">UserData</code></p>
</td><td style="text-align: left" valign="top">
<p><code class="literal">UserData</code></p>
</td><td style="text-align: left" valign="top">
<p><code class="literal">UserData</code></p>
</td><td style="text-align: left" valign="top">
<p>……………………………………………</p>
</td><td style="text-align: left" valign="top">
<p><code class="literal">UserData</code></p>
</td></tr></tbody></table></div><div><div><h3 class="title"><a id="tip04"/>Tip</h3><p>Provide the same declaration of the application data type to the OpenCL kernel file (<code class="literal">*.cl</code>) as well as the host application files (<code class="literal">*.c</code>, <code class="literal">*.h</code>, <code class="literal">*.cpp</code>, <code class="literal">*.hpp</code>); else the OpenCL runtime will emit errors to reflect that the struct it is looking for does not exist, and the replication is necessary as OpenCL prohibits the <code class="literal">C</code> header file inclusion mechanism.</p></div></div><p>Let's spend some time to understand the C <code class="literal">struct</code> we just used in this example. The C structure we just used, <code class="literal">UserData</code>, is an example of an application data type. OpenCL makes no requirement about the alignment of OpenCL data types outside of buffers and images; hence developers of OpenCL need to make sure the data is properly aligned. Fortunately, OpenCL has provided attribute qualifiers so that we can annotate our types, functions and variables to suit the algorithm and CPU/GPU architecture with the primary motivation being to improve memory bandwidth. The alignment needs to be a power of two and at least a perfect multiple of the lowest common multiple of all the alignments of all the members of the <code class="literal">struct</code> or <code class="literal">union</code>.</p><div><div><h3 class="title"><a id="note03"/>Note</h3><p>Refer to Section 6.11.1 Specifiying Attributes of Types in the OpenCL 1.2 specification</p></div></div><p>Let's take a look at what is available to developers when it comes to aligning data types such as <code class="literal">enum</code>, <code class="literal">struct</code>, or <code class="literal">union</code>.</p><p>Data alignment is a direct result of how various computer systems restrict the allowable addresses for the primitive data types, requiring that the address for some type of object must be a multiple of some value <em>K</em> (typically 2, 4, or 8), and this actually simplifies the design of the hardware between the processor and the memory system. For example, if the processor were to always fetch 8 bytes from memory with an address that must be a multiple of 8, then the value can be read or written in a single memory operation otherwise, the processor needs to perform two or more memory accesses.</p><p>Alignment is enforced by making sure that every data type is organized and allocated in such a way that every object within the type satisfies its alignment restrictions.</p><p>Let's use an example for this illustration. Following is the generic manner in which alignment can be defined for application data type such as <code class="literal">UserData</code>. While examining the code, you will notice that without the <code class="literal">aligned</code> attribute, this data structure will be allocated on a 17-byte boundary assuming <code class="literal">int</code> is 4-bytes and <code class="literal">char</code> is 1-byte on a 32-bit / 64-bit system architecture. Once this attribute is included, following is the alignment:</p><div><pre class="programlisting">| __attribute__((aligned))</pre></div><p>The alignment is <a id="id113" class="indexterm"/>now <a id="id114" class="indexterm"/>determined by the OpenCL compiler to be aligned to 32-bytes instead of 17-bytes, that is, summing all the struct member's sizes, and the specification designates the alignment size to be the largest power of 2 and therefore it is 25 because, the 24 is 1-byte too many; however if you were to change the previous alignment to the following alignment:</p><div><pre class="programlisting">| __attribute__((aligned (8)))</pre></div><p>Then the alignment will be at least 8-bytes as shown in the following code:</p><div><pre class="programlisting">typedef struct __attribute__((aligned)) UserData {
    int x;
    int y;
    int z;
    int w;
    char c;
} UserData;</pre></div><p>Equivalently, you can also write in more explicit form as follows:</p><div><pre class="programlisting">typedef struct __attribute__((aligned(32)) UserData {…}</pre></div><p>In general, the golden rule of designing the data to be memory aligned is still a necessary practice; a rule of thumb I keep in mind is 16-byte aligned for 128-bit access and 32-byte aligned for 256-bit access.</p><p>On the other side of the story, you may find yourself wishing that the alignment wasn't that large, and with OpenCL you can indicate that by using the <code class="literal">packed</code> attribute as in the following code assuming that <code class="literal">LargeUserData</code> is an imaginary large data structure:</p><div><pre class="programlisting">typedef struct __attribute__((packed)) LargeUserData {…}</pre></div><p>When you apply this attribute to a <code class="literal">struct</code> or <code class="literal">union</code>, you're effectively applying the attribute to every member of the data; applying to an <code class="literal">enum</code> means that the OpenCL compiler will select the smallest integral type found on that architecture. You can refer to the <code class="literal">Ch2/user_buffer_alignment/user_buffer_align.c</code> to review what's done and how to profile the performance of the application via AMD APP SDK in the <code class="literal">readme.txt</code> file.</p></div></div>
<div><div><div><div><h1 class="title"><a id="ch02lvl1sec18"/>Retrieving information about OpenCL buffer objects</h1></div></div></div><p>To retrieve <a id="id115" class="indexterm"/>information about a buffer or<a id="id116" class="indexterm"/> sub-buffer object, you'll need to use the API <code class="literal">clGetMemObjectInfo</code> and its signature as in the following code:</p><div><pre class="programlisting">cl_int clGetMemObjectInfo(cl_mem memobj,
                          cl_mem_info param_name,
                          size_t param_value_size,
                          void* param_value,
                          size_t* param_value_size_ret)</pre></div><p>To query the memory object, simply pass the object to <code class="literal">memobj</code> specifying the type of information you want in <code class="literal">param_name</code>, inform OpenCL the size of the returned information in <code class="literal">param_value_size</code> and where to deposit it in <code class="literal">param_value</code>; the last parameter, <code class="literal">param_value_size_ret</code>, is largely optional but it returns the size of the value in <code class="literal">param_value_size</code>.</p><div><div><div><div><h2 class="title"><a id="ch02lvl2sec31"/>Getting ready</h2></div></div></div><p>Here's an excerpt from the code in <code class="literal">Ch2/buffer_query/buffer_query.c</code> where it shows how to extract the information about the memory object, <code class="literal">UDObj</code> is encapsulated into a user-defined function <code class="literal">displayBufferDetails</code> because, the code can be long depending on how many attributes you wish to extract about a memory object and you would place the invocation to this function after you've created the buffer object or if you have been given a handle to the memory object. The following code illustrates how it would display the information about a memory object by abstracting the OpenCL memory retrieval APIs into the function <code class="literal">displayBufferDetails</code>:</p><div><pre class="programlisting">cl_mem UDObj = clCreateBuffer(context, … sizeof(UserData) *                
                              DATA_SIZE, ud_in, &amp;error);
/* Extract some info about the buffer object we created */
displayBufferDetails(UDObj);</pre></div></div><div><div><div><div><h2 class="title"><a id="ch02lvl2sec32"/>How to do it…</h2></div></div></div><p>We've included the main part of this recipe, as shown in the following code:</p><div><pre class="programlisting">void displayBufferDetails(cl_mem memobj) {
  cl_mem_object_type objT;
  cl_mem_flags flags;
  size_t memSize;
  clGetMemObjectInfo(memobj, CL_MEM_TYPE,
                     sizeof(cl_mem_object_type), &amp;objT, 0);
  clGetMemObjectInfo(memobj, CL_MEM_FLAGS, sizeof(cl_mem_flags),
                     &amp;flags, 0);
  clGetMemObjectInfo(memobj, CL_MEM_SIZE, sizeof(size_t),
                     &amp;memSize, 0);
  char* str = '\0';
  switch (objT) {
    case CL_MEM_OBJECT_BUFFER: str = "Buffer or Sub
                                      buffer";break;
    case CL_MEM_OBJECT_IMAGE2D: str = "2D Image Object";break;
    case CL_MEM_OBJECT_IMAGE3D: str = "3D Image Object";break;
  }
  char flagStr[128] = {'\0'};
  if(flags &amp; CL_MEM_READ_WRITE) strcat(flagStr, "Read-Write|");
  if(flags &amp; CL_MEM_WRITE_ONLY) strcat(flagStr, "Write Only|");
  if(flags &amp; CL_MEM_READ_ONLY)  strcat(flagStr, "Read Only|");
  if(flags &amp; CL_MEM_COPY_HOST_PTR) strcat(flagStr, "Copy from
                                                    Host|");
  if(flags &amp; CL_MEM_USE_HOST_PTR)  strcat(flagStr, "Use from
                                                    Host|");
  if(flags &amp; CL_MEM_ALLOC_HOST_PTR) strcat(flagStr, "Alloc from
                                                     Host|");
  printf("\tOpenCL Buffer's details =&gt;\n\t size: %lu MB,\n\t object type is: %s,\n\t flags:0x%lx (%s) \n", memSize &gt;&gt; 20, str, flags, flagStr);
}</pre></div><p>On OSX, you <a id="id117" class="indexterm"/>will compile the program by running the<a id="id118" class="indexterm"/> following command on your terminal:</p><div><pre class="programlisting">
<strong>gcc -std=c99 -Wall -DUNIX -g -DDEBUG -DAPPLE -arch i386 -o buffer_query buffer_query.c   -framework OpenCL</strong>
</pre></div><p>On Ubuntu Linux 12.04 with Intel OpenCL SDK, the command will be as follows:</p><div><pre class="programlisting">
<strong>gcc -std=c99 -Wall -DUNIX -g -DDEBUG -m64 -o buffer_query buffer_query.c -I . -I /usr/include -L/usr/lib64/OpenCL/vendors/intel -lintelocl -ltbb -ltbbmalloc -lcl_logger -ltask_executor</strong>
</pre></div><p>On Ubuntu Linux 12.04 with AMD APP SDK v2.8, the command will be as follows:</p><div><pre class="programlisting">
<strong>gcc -std=c99 -Wall -DUNIX -g -DDEBUG –m64 -o buffer_query buffer_query.c   -I. –I/opt/AMDAPP/include –L/opt/AMDAPP/lib/x86_64 –lOpenCL</strong>
</pre></div><p>Regardless of the platform, a binary executable <code class="literal">buffer_query</code> would be deposited locally.</p><p>Executing the program on an OSX 10.6 and Ubuntu 12.04 with AMD APP SDK v2.7 would present the following result:</p><div><pre class="programlisting">Number of OpenCL platforms found: 1
Kernel name: hello with arity: 1
About to create command queue and enqueue this kernel...
  OpenCL Buffer's details =&gt;
    size: 128 MB,
    object type is: Buffer or Sub-buffer,
    flags:0x21 (Read-Write|Copy from Host)
Task has been enqueued successfully!
Check passed!</pre></div></div><div><div><div><div><h2 class="title"><a id="ch02lvl2sec33"/>How it works…</h2></div></div></div><p>The host<a id="id119" class="indexterm"/> application proceeds to first create the <a id="id120" class="indexterm"/>buffer that it will send to the device, then the application queries for information about the buffer. The full list of attributes that can be queried is as shown in the following table:</p><div><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th style="text-align: left" valign="bottom">
<p>cl_mem_info</p>
</th><th style="text-align: left" valign="bottom">
<p>Return type</p>
</th><th style="text-align: left" valign="bottom">
<p>Info. Returned in param_value</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<p><code class="literal">CL_MEM_TYPE</code></p>
</td><td style="text-align: left" valign="top">
<p><code class="literal">cl_mem_object_type</code></p>
</td><td style="text-align: left" valign="top">
<p>It returns <code class="literal">CL_MEM_OBJECT_BUFFER</code> if <code class="literal">memobj</code> is created with <code class="literal">clCreateBuffer</code> or <code class="literal">clCreateSubBuffer</code>.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p><code class="literal">Cl_MEM_FLAGS</code></p>
</td><td style="text-align: left" valign="top">
<p><code class="literal">cl_mem_flags</code></p>
</td><td style="text-align: left" valign="top">
<p>It returns the flags argument specified when <code class="literal">memobj</code> is created with <code class="literal">clCreateBuffer</code>, <code class="literal">clCreateSubBuffer</code>, <code class="literal">clCreateImage2D</code>, or <code class="literal">clCreateImage3D</code>.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p><code class="literal">CL_MEM_SIZE</code></p>
</td><td style="text-align: left" valign="top">
<p><code class="literal">size_t</code></p>
</td><td style="text-align: left" valign="top">
<p>It returns the actual size of the data associated with <code class="literal">memobj</code> in bytes.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p><code class="literal">CL_MEM_HOST_PTR</code></p>
</td><td style="text-align: left" valign="top">
<p><code class="literal">void*</code></p>
</td><td style="text-align: left" valign="top">
<p>If <code class="literal">memobj</code> is created with <code class="literal">clCreateBuffer</code> or <code class="literal">clCreateImage2d</code>, <code class="literal">clCreateImage3D</code>, then it returns the <code class="literal">host_ptr</code> argument specified when <code class="literal">memobj</code> is created.</p>
<p>If <code class="literal">memobj</code> is created with <code class="literal">clCreateSubBuffer</code>, then it returns the <code class="literal">host_ptr</code> plus <code class="literal">origin</code> specified when <code class="literal">memobj</code> was created.</p>
<p>See <code class="literal">clCreateBuffer</code> for what <code class="literal">host_ptr</code> is.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p><code class="literal">CL_MEM_MAP_COUNT</code></p>
</td><td style="text-align: left" valign="top">
<p><code class="literal">cl_uint</code></p>
</td><td style="text-align: left" valign="top">
<p>Map count.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p><code class="literal">CL_MEM_REFERENCE_COUNT</code></p>
</td><td style="text-align: left" valign="top">
<p><code class="literal">cl_uint</code></p>
</td><td style="text-align: left" valign="top">
<p>It returns <code class="literal">memobj</code>'s reference count.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p><code class="literal">CL_MEM_CONTEXT</code></p>
</td><td style="text-align: left" valign="top">
<p><code class="literal">cl_context</code></p>
</td><td style="text-align: left" valign="top">
<p>It returns the context specified when the memory is created. If <code class="literal">memobj</code> is created using <code class="literal">clCreateSubBuffer</code>, the context associated with the memory object specified as the <code class="literal">buffer</code> argument to <code class="literal">clCreateSubBuffer</code> is returned.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p><code class="literal">CL_MEM_ASSOCIATED_MEMOBJECT</code></p>
</td><td style="text-align: left" valign="top">
<p><code class="literal">cl_mem</code></p>
</td><td style="text-align: left" valign="top">
<p>It return memory object from which <code class="literal">memobj</code> is created.</p>
<p>In <code class="literal">clCreateSubBuffer</code>, it returns the <code class="literal">buffer</code> argument; else NULL is returned.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p><code class="literal">CL_MEM_OFFSET</code></p>
</td><td style="text-align: left" valign="top">
<p><code class="literal">size_t</code></p>
</td><td style="text-align: left" valign="top">
<p>Applicable to <code class="literal">memobj</code> created via <code class="literal">clCreateSubBuffer</code>. It returns offset or 0.</p>
</td></tr></tbody></table></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch02lvl1sec19"/>Creating OpenCL sub-buffer objects</h1></div></div></div><p>Sub-buffers are <a id="id121" class="indexterm"/>incredibly<a id="id122" class="indexterm"/> useful data types and as you continue to explore OpenCL in this chapter, you'll notice that this data type can be used to partition the data and distribute them across your OpenCL devices on your platform.</p><div><div><h3 class="title"><a id="note04"/>Note</h3><p>At the time of this writing, sub-buffer support is not enabled on OpenCL delivered in the OSX 10.6, because the official version is OpenCL 1.0. However, if you have OSX 10.7 then you'll be able to run this code without any problem.</p></div></div><p>Let's take a look at the method signature and examine it:</p><div><pre class="programlisting">cl_mem clCreateSubBuffer(cl_mem buffer,
                         cl_mem_flags flags,
                         cl_buffer_create_type bufferType,
                         const void* buffer_create_info,
                         cl_int* errcode_ret)</pre></div><p>The argument <code class="literal">buffer</code> refers to the buffer you created via <code class="literal">clCreateBuffer</code>, the <code class="literal">flags</code> argument refers to the options you wish this offer to have and if it's zero then the default option is <code class="literal">CL_MEM_READ_WRITE</code>; this flag can adopt any values from the previous table. The argument <code class="literal">bufferType</code> is of a data structure:</p><div><pre class="programlisting">typedef struct _cl_buffer_region {
  size_t origin;
  size_t size;
} cl_buffer_region;</pre></div><p>Therefore, you<a id="id123" class="indexterm"/> indicate<a id="id124" class="indexterm"/> where to start creating the region via the <code class="literal">origin</code> argument and how large it is going to be via the <code class="literal">size</code> argument.</p><div><div><div><div><h2 class="title"><a id="ch02lvl2sec34"/>Getting ready</h2></div></div></div><p>In the <em>How to do it...</em> section of this recipe there is an excerpt from <code class="literal">Ch2/sub_buffers/sub_buffer.c</code> where we create two sub-buffer objects and each of them holds one-half of the data; these two sub-buffers will be sent to each OpenCL device on my setup, and they're computed and results are checked. Conceptually, here's what the code is doing:</p><div><img src="img/sub_buffers.jpg" alt="Getting ready"/></div></div><div><div><div><div><h2 class="title"><a id="ch02lvl2sec35"/>How to do it…</h2></div></div></div><p>We've included the main part of this recipe as shown in the following code:</p><p><strong>/* Chop up the data evenly between all devices &amp; create sub-buffers */</strong></p><div><pre class="programlisting">  cl_buffer_region region;
  region.size   = (sizeof(UserData)*DATA_SIZE) / numOfDevices; 
  region.origin = offset * region.size;
  cl_mem subUDObj = clCreateSubBuffer(UDObj,
                                CL_MEM_READ_WRITE, // read-write
                                CL_BUFFER_CREATE_TYPE_REGION,
                                &amp;region, &amp;error);
  if (error != CL_SUCCESS) { 
    perror("Unable to create sub-buffer object");
    exit(1);
  }</pre></div><p><strong>/* Let OpenCL know that the kernel is suppose to receive an argument */</strong></p><div><pre class="programlisting">error = clSetKernelArg(kernels[j], 0, sizeof(cl_mem), &amp;subUDObj);
// Error handling code omitted</pre></div><p>As noted earlier, this <a id="id125" class="indexterm"/>application doesn't work on OSX 10.6 and hence <a id="id126" class="indexterm"/>to compile it using the AMD APP SDK, you will enter the following command:</p><div><pre class="programlisting">
<strong>gcc –std=c99 –Wall –DUNIX –g –DDEBUG –m64 –o sub_buffer sub_buffer.c –I. –I/opt/AMDAPP/include –L/opt/AMDAPP/lib/x86_64 –lOpenCL</strong>
</pre></div><p>For the Intel OpenCL SDK, you will enter the following command:</p><div><pre class="programlisting">
<strong>gcc –std=c99 –Wall –DUNIX –g –DDEBUG –m64 –o sub_buffer sub_buffer.c –I. –I/usr/include </strong>
<strong>–L/usr/lib64/OpenCL/vendors/intel</strong>
<strong>-lintelocl</strong>
<strong>-ltbb</strong>
<strong>-ltbbmalloc</strong>
<strong>-lcl_logger</strong>
<strong>-ltask_executor</strong>
</pre></div><p>For NVIDIA on Ubuntu Linux 12.04, you will enter the following command:</p><div><pre class="programlisting">
<strong>gcc –std=c99 –Wall –DUNIX –g –DDEBUG –m64 –o sub_buffer sub_buffer.c –I. –I/usr/local/cuda/include –lOpenCL</strong>
</pre></div><p>Regardless of the platform, a binary executable <code class="literal">sub_buffer</code> would be deposited locally.</p><p>In the setup I have with Ubuntu Linux 12.04 with a NVIDIA GTX460 graphics chip with both NVIDIA's and Intel's OpenCL toolkit installed, I have the following output:</p><div><pre class="programlisting">Number of OpenCL platforms found: 2
Number of detected OpenCL devices: 1
Kernel name: hello with arity: 1
About to create command queue and enqueue this kernel...
Task has been enqueued successfully!
Check passed!
</pre></div><p>In the other setup with<a id="id127" class="indexterm"/> Ubuntu Linux 12.04 with an ATI 6870x2 graphics <a id="id128" class="indexterm"/>chip and AMD APP SDK installed, the difference in the output is only that the number of platforms is one and data is split between the CPU and GPU:</p><div><pre class="programlisting">Number of OpenCL platforms found: 1
Number of detected OpenCL devices: 2
Kernel name: hello with arity: 1
About to create command queue and enqueue this kernel...
Task has been enqueued successfully!
Check passed!
Kernel name: hello with arity: 1
About to create command queue and enqueue this kernel...
Task has been enqueued successfully!
Check passed!
</pre></div></div><div><div><div><div><h2 class="title"><a id="ch02lvl2sec36"/>How it works…</h2></div></div></div><p>The application basically discovers all the OpenCL compliant devices and keeps tracks of how it discovered. Next, the application uses the prior information to divide the data among the devices before enqueuing the data for execution and the code snippet demonstrates the following:</p><div><pre class="programlisting">cl_buffer_region region;
region.size   = (sizeof(UserData)*DATA_SIZE) / numOfDevices;
region.origin = offset * region.size;
cl_mem subUDObj = clCreateSubBuffer(UDObj,
                                    CL_MEM_READ_WRITE, // read-write
                                    CL_BUFFER_CREATE_TYPE_REGION,
                                    &amp;region, &amp;error);</pre></div><p>Finally, the data is checked for sanity after reading the data back from the device memory to the host memory as the following code snippet shows:</p><div><pre class="programlisting">error = clEnqueueReadBuffer(cQ, 
                            subUDObj,
                            CL_TRUE, // blocking read
                            region.origin, // write from the last offset
                            region.size, // how much to copy
                            ud_out, 0, NULL, NULL);
                /* Check the returned data */
                if ( valuesOK(ud_in, ud_out, DATA_SIZE/numOfDevices){
                  printf("Check passed!\n");
               } else printf("Check failed!\n");</pre></div><p>What you've just seen is a data partitioning technique also known as the distributed array pattern on a one-dimensional block of data.</p><div><div><h3 class="title"><a id="note05"/>Note</h3><p>Based on the distributed array pattern, there had been three general techniques that were developed, and they are over one-dimensional and two-dimensional blocks of data and finally the block-cyclic pattern.</p></div></div><p>Depending on whether <a id="id129" class="indexterm"/>you've installed one or more OpenCL toolkits <a id="id130" class="indexterm"/>from the vendors, the OpenCL will report the appropriate platforms and the OpenCL <strong>Installable Client Driver</strong> (<strong>ICD</strong>)<a id="id131" class="indexterm"/> allows multiple OpenCL implementations to co-exist on the same physical machine. Refer to the URL <a class="ulink" href="http://www.khronos.org/registry/cl/extensions/khr/cl_khr_icd.txt">http://www.khronos.org/registry/cl/extensions/khr/cl_khr_icd.txt</a> for more information about ICDs. This explains why your program may display distinct numbers for each installed platforms. The ICD actually identifies the vendors who provided the OpenCL implementation on the machine you have setup and its main function is to expose the platforms to the host code so that the developer may choose to run the algorithm in question against. The ICD has two pieces of information—(a) entry points to the vendor's OpenCL implementation in the library on the filesystem on which it's been installed, (b) the suffix string used to identify the suffix for OpenCL extensions provided by that vendor.</p></div></div>
<div><div><div><div><h1 class="title"><a id="ch02lvl1sec20"/>Retrieving information about OpenCL sub-buffer objects</h1></div></div></div><p>The retrieval of <a id="id132" class="indexterm"/>information about<a id="id133" class="indexterm"/> OpenCL sub-buffers is very similar to that described in the previous recipe and involves the invocation of <code class="literal">clGetMemObjInfo</code>. Let's take a look at it.</p><div><div><h3 class="title"><a id="tip05"/>Tip</h3><p>OSX Caveat—you will<a id="id134" class="indexterm"/> need a OpenCL 1.1, at least the implementation to see this build and run; since OSX 10.6 doesn't support that version, you'll have to get a OSX 10.7 to get this code to run.</p></div></div><div><div><div><div><h2 class="title"><a id="ch02lvl2sec37"/>Getting ready</h2></div></div></div><p>In the <code class="literal">Ch2/sub_buffer_query/subbuffer_query.c</code>, you'll find an excerpt of the following <a id="id135" class="indexterm"/>code demonstrating how we would <a id="id136" class="indexterm"/>pass the sub-buffer memory object to our defined function <code class="literal">displayBufferDetails</code>:</p><div><pre class="programlisting">cl_buffer_region region;
region.size = sizeof(UserData)*DATA_SIZE;
region.origin = 0;
cl_mem subUDObj = clCreateSubBuffer(UDObj,
                                    CL_MEM_READ_WRITE, // read-write
                                    CL_BUFFER_CREATE_TYPE_REGION,
                                    &amp;region, &amp;error);
displayBufferDetails(subUDObj);</pre></div><div><div><h3 class="title"><a id="tip06"/>Tip</h3><p>During my experimentation, I found that the NVIDIA CUDA 5 OpenCL toolkit was stricter in evaluating the attributes in the argument flags that's passed to <code class="literal">clCreateSubBuffer</code> as compared to AMD's APP SDK v2.7. Take note that the bug may be fixed by the time you read this book. As a concrete example, the following code throws an error using NVIDIA as opposed to AMD when you write:</p><p><code class="literal">clCreateSubBuffer(buffer,CL_MEM_READ_WRITE|CL_MEM_COPY_HOST_PTR,…)</code> to reflect the fact that <code class="literal">CL_MEM_COPY_HOST_PTR</code> doesn't make sense.</p></div></div></div><div><div><div><div><h2 class="title"><a id="ch02lvl2sec38"/>How to do it…</h2></div></div></div><p>We've included the main part of this recipe, as shown in the following code:</p><div><pre class="programlisting">void displayBufferDetails(cl_mem memobj) {
  cl_mem_object_type objT;
  cl_mem_flags flags;
  size_t memSize;
  size_t memOffset;
  cl_mem mainBuffCtx;
  clGetMemObjectInfo(memobj, CL_MEM_TYPE,
                     sizeof(cl_mem_object_type), &amp;objT, 0);
  clGetMemObjectInfo(memobj, CL_MEM_FLAGS, sizeof(cl_mem_flags),
                     &amp;flags, 0);
  clGetMemObjectInfo(memobj, CL_MEM_SIZE, sizeof(size_t),
                     &amp;memSize, 0);
  clGetMemObjectInfo(memobj, CL_MEM_OFFSET, sizeof(size_t),
                     &amp;memOffset, 0); // 'CL_MEM_OFF_SET' new in OpenCL 1.2
  clGetMemObjectInfo(memobj, CL_MEM_ASSOCIATED_MEMOBJECT,
                     sizeof(size_t),
                     &amp;memOffset, 0);
  char* str = '\0';
  if (mainBuffCtx) { // implies that 'memobj' is a sub-buffer
    switch (objT) {
      case CL_MEM_OBJECT_BUFFER: str = "Sub-buffer";break;
      case CL_MEM_OBJECT_IMAGE2D: str = "2D Image Object";break;
      case CL_MEM_OBJECT_IMAGE3D: str = "3D Image Object";break;
    }
  } else {
switch (objT) {
  case CL_MEM_OBJECT_BUFFER: str = "Buffer";break;
  case CL_MEM_OBJECT_IMAGE2D: str = "2D Image Object";break;
  case CL_MEM_OBJECT_IMAGE3D: str = "3D Image Object";break;
  } 
}
  char flagStr[128] = {'\0'};
  if(flags &amp; CL_MEM_READ_WRITE) strcat(flagStr, "Read-Write|");
  if(flags &amp; CL_MEM_WRITE_ONLY) strcat(flagStr, "Write Only|");
  if(flags &amp; CL_MEM_READ_ONLY)  strcat(flagStr, "Read Only|");
  if(flags &amp; CL_MEM_COPY_HOST_PTR) strcat(flagStr, "Copy from
                                                    Host|");
  if(flags &amp; CL_MEM_USE_HOST_PTR)  strcat(flagStr, "Use from
                                                    Host|");
  if(flags &amp; CL_MEM_ALLOC_HOST_PTR) strcat(flagStr, "Alloc from
                                                     Host|");
  printf("\tOpenCL Buffer's details =&gt;\n\t size: %lu MB,\n\t object type is: %s,\n\t flags:0x%lx (%s) \n", memSize &gt;&gt; 20, str, flags, flagStr);
}</pre></div><p>On the <a id="id137" class="indexterm"/>Ubuntu Linux 12.04 with <a id="id138" class="indexterm"/>AMD's APP SDK v2.8, the following command would suffice:</p><div><pre class="programlisting">
<strong>gcc –std=c99 –Wall –DUNIX –g –DDEBUG –m64 –o subbuffer _query subbuffer_query.c –I. –I/opt/AMDAPP/include –L/opt/AMDAPP/lib/x86_64 –lOpenCL</strong>
</pre></div><p>For the Intel OpenCL SDK, you would enter the following command:</p><div><pre class="programlisting">
<strong>gcc –std=c99 –Wall –DUNIX –g –DDEBUG –m64 –o subbuffer_query subbuffer_query.c –I. –I/usr/include </strong>
<strong>–L/usr/lib64/OpenCL/vendors/intel</strong>
<strong>-lintelocl</strong>
<strong>-ltbb</strong>
<strong>-ltbbmalloc</strong>
<strong>-lcl_logger</strong>
<strong>-ltask_executor</strong>
</pre></div><p>For NVIDIA on Ubuntu Linux 12.04, you would enter the following command :</p><div><pre class="programlisting">
<strong>gcc –std=c99 –Wall –DUNIX –g –DDEBUG –m64 –o subbuffer_query subbuffer_query.c –I. –I/usr/local/cuda/include –lOpenCL</strong>
</pre></div><p>Regardless of the<a id="id139" class="indexterm"/> platform, a binary <a id="id140" class="indexterm"/>executable <code class="literal">subbuffer_query</code> would be deposited locally.</p><p>When you run the program, you should get something similar to the following output:</p><div><pre class="programlisting">Number of OpenCL platforms found: 2
Kernel name: hello with arity: 1
About to create command queue and enqueue this kernel...
    OpenCL Buffer's details =&gt;
    size: 128 MB,
   object type is: Buffer,
    flags:0x21 (Read-Write|Copy from Host|) 
    OpenCL Buffer's details =&gt;
    size: 128 MB,
    object type is: Sub-buffer,
    flags:0x1 (Read-Write|) 
Task has been enqueued successfully!
Check passed!</pre></div></div><div><div><div><div><h2 class="title"><a id="ch02lvl2sec39"/>How it works…</h2></div></div></div><p>The application could decipher whether it's an OpenCL sub-buffer object because of the two flags introduced in OpenCL 1.2. They are <code class="literal">CL_MEM_OFFSET</code> and <code class="literal">CL_MEM_ASSOCIATED_MEMOBJECT</code>; using either one of the flags would reveal whether it's a sub-buffer, but the catch is that <code class="literal">CL_MEM_OFFSET</code> can be zero for a sub-buffer because that indicates to OpenCL where to start to extract the data from; a better, recommended option is to use <code class="literal">CL_MEM_ASSOCIATED_MEMOBJECT</code> since the presence implies the argument <code class="literal">memobj</code> is a sub-buffer. See the earlier recipe, <em>Retrieving information about OpenCL buffer objects</em>.</p></div></div>
<div><div><div><div><h1 class="title"><a id="ch02lvl1sec21"/>Understanding events and event-synchronization</h1></div></div></div><p>The previous recipes demonstrated how you can create memory objects that encapsulates the data that is to be transferred from the host memory to the device memory, and discusses how you can partition the input data among the devices via sub-buffers.</p><p>In this recipe, we are going to develop an understanding of how the developer can make use of the event system in OpenCL to control execution of kernel commands as well as memory commands. This is beneficial to the developer because it offers myriad ways in which you can control execution flow in a heterogeneous environment.</p><p>Events are, generally, passive mechanisms when the developers wish to be notified of an occurrence, and having the choice of conducting processing past that occurrence; contrasting to the say, polling where it's a more active mechanism as the application makes an active enquiry into the current state and decides what to do when a particular condition is met.</p><p>Events in <a id="id141" class="indexterm"/>OpenCL<a id="id142" class="indexterm"/> fall into two <a id="id143" class="indexterm"/>categories as follows:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Host monitoring events</li><li class="listitem" style="list-style-type: disc">Command events</li></ul></div><p>In both the event types, the developer needs to create the events explicitly and associate them with the objects through waitlists; waitlists are nothing more than a container of events that the command must wait upon completion, that is, the event's status is <code class="literal">CL_COMPLETE</code> or <code class="literal">CL_SUCCESS</code> before progressing. The difference between these two event types (as we shall soon see) is in the manner in which the next subsequent command in the queue gets executed, host events are updated by the developer and when this is done it is indicative by the program source, command events in the waitlists on the other hand are updated by the OpenCL runtime. Considering that the events held up in the waitlists must be of a certain state before the next command executes means that waitlists are actually synchronization points since no progress can be made without emptying that list.</p><p>Let's start by examining the <a id="id144" class="indexterm"/>host events. So far, we understood that commands needs to be placed onto the command queue so that they can be scheduled for execution, and what host monitoring events allow the developer is to monitor the state of enqueued command and we can, optionally, attach a callback function to the event so that when it returns with a state we desire, the callback function will execute. This is made possible via the APIs <code class="literal">clCreateUserEvent</code>, <code class="literal">clSetUserEventStatus</code>, <code class="literal">clReleaseEvent</code>, and <code class="literal">clSetEventCallback</code>. An example in the <em>How to do it</em> section would illustrate how this can be achieved.</p><div><div><div><div><h2 class="title"><a id="ch02lvl2sec40"/>Getting ready</h2></div></div></div><p>Assume that a kernel <a id="id145" class="indexterm"/>wishes to process two 1D memory objects named <code class="literal">objA</code> and <code class="literal">objB</code> and write the result to <code class="literal">objC</code> (for this example, we can ignore the output of <code class="literal">objC</code>). We wish that the copying of input data from <code class="literal">objB</code> should only take place when we have indicated to the host program.</p></div><div><div><div><div><h2 class="title"><a id="ch02lvl2sec41"/>How to do it…</h2></div></div></div><p>The full source is demonstrated in <code class="literal">Ch2/events/{events.c,sample_kernel.cl}</code> and we have to first create the necessary data structures as before; next we will create the event object as follows:</p><div><pre class="programlisting">event1 = clCreateUserEvent(context, &amp;ret);</pre></div><p>In this event object, we can next assign a call back function to the event and indicate that upon the event's status changes to <code class="literal">CL_COMPLETE</code>, the callback would execute like the following code:</p><div><pre class="programlisting">void CL_CALLBACK postProcess(cl_event event, cl_int status, void *data) {
  printf("%s\n", (char*)data);
}
clSetEventCallback(event1, CL_COMPLETE, &amp;postProcess, "Looks like its done.");</pre></div><p>Then the host program would continue to conduct memory transfers for <code class="literal">objA</code> and <code class="literal">objB</code>, but it doesn't proceed to process any more OpenCL commands enqueued on the command queue till the status of the <code class="literal">event1</code> is set to <code class="literal">CL_COMPLETE</code>.</p><div><pre class="programlisting">ret = clEnqueueWriteBuffer(command_queue, objA, CL_TRUE, 0, 4*4*sizeof(float), A, 0, NULL, NULL );
  printf("A has been written\n");
  /* The next command will wait for event1 according to its status*/
  ret = clEnqueueWriteBuffer(command_queue, objB, CL_TRUE, 0, 4*4*sizeof(float), B, 1, &amp;event1, NULL);
  printf("B has been written\n");
clSetUserEventStatus(event1, CL_COMPLETE);
//….code omitted
clReleaseEvent(event1);</pre></div><p>Another API we will introduce is the <code class="literal">clWaitForEvents</code> with it's signature:</p><div><pre class="programlisting">Cl_int clWaitForEvents(cl_uint num_events, const cl_event* event_list);</pre></div><p>This is typically used to stall the host thread until all the commands in the event list have completed (the next code snippet demonstrates how).</p><p>The next topic we look at are the command events, which are typically used when you wish to be notified of certain happenings associated with commands. A typical use case would be the following where you have a command-queue and you want to be notified of the status of an memory transfer command like <code class="literal">clEnqueueWriteBuffer</code> and take a particular action depending on that status:</p><div><pre class="programlisting">cl_event event1;
// create memory objects and other stuff
ret = clEnqueueWriteBuffer(queue, object, CL_TRUE, 0, 1048576, hostPtrA, 1, &amp;event1, NULL);
clWaitForEvents(&amp;event1); // stalls the host thread until 'event1' has a status of CL_COMPLETE.</pre></div><p>You can easily<a id="id146" class="indexterm"/> extrapolate the scenario where you have a large heterogeneous computing environment with large numbers of CPUs and GPUs and obviously you wish to maximize your computational power, and the events mechanism in OpenCL allows the developer to design how to sequence those computations and coordinate those computations. However, as a best practice you probably want to clean up the event object associated with the commands, but you need to discover the state of the event you're watching otherwise you might release the event prematurely, and here's how you can do that by polling the API <code class="literal">clGetEventInfo</code> passing in the event you are watching; the following code demonstrates this idea:</p><div><pre class="programlisting">int
waitAndReleaseEvent(cl_event* event) {
  cl_int eventStatus = CL_QUEUED;
  while(eventStatus != CL_COMPLETE) {
    clGetEventInfo(*event, 
                   CL_EVENT_COMMAND_EXECUTION_STATUS,
                   sizeof(cl_int), 
                   &amp;eventStatus, NULL);
  }
  clReleaseEvent(*event);
  return 0;
}</pre></div></div><div><div><div><div><h2 class="title"><a id="ch02lvl2sec42"/>There's more…</h2></div></div></div><p>There are two scenarios that deserve mentioning and they address the situation where (a) you like to receive notification for a group of events (assuming that they are associated to memory objects) and (b) you like to stall the execution of any commands further down the pipeline, that is, command-queue, until this group of events you are watching for have completed. The API <code class="literal">clEnqueueMarkerWithWaitList</code> is for the former situation whereas <code class="literal">clEnqueueBarrierWithWaitList</code> suits the latter. You are encouraged to explore them in the OpenCL 1.2 specification.</p><div><div><h3 class="title"><a id="note06"/>Note</h3><p>If you are still using OpenCL 1.1, you can use <code class="literal">clEnqueueMarker</code> and <code class="literal">clEnqueueBarrier</code> (which are the older versions of <code class="literal">clEnqueueMarkerWithWaitList</code> and <code class="literal">clEnqueueBarrierWithWaitList</code>) but be aware that they are both deprecated in OpenCL 1.2.</p></div></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch02lvl1sec22"/>Copying data between memory objects</h1></div></div></div><p>You will quickly <a id="id147" class="indexterm"/>realize how useful the event mechanism in<a id="id148" class="indexterm"/> OpenCL is in controlling the various parts of your algorithm, and it can be found in the common kernel and memory commands. This recipe will continue from creating memory objects and focus on how those memory objects can be transferred from the host memory to the device memory and vice versa and we'll be fixated on the data transfer APIs <code class="literal">clEnqueueReadBuffer</code> and <code class="literal">clEnqueueWriteBuffer</code>, which is for one-dimensional data blocks, and <code class="literal">clEnqueueReadBufferRect</code> and <code class="literal">clEnqueueWriteBufferRect</code> for two-dimensional data blocks; we'll also look at <code class="literal">clEnqueueCopyBuffer</code> for data transfers between memory objects in the device. First, we look at copying data between memory objects.</p><p>There will come times when you have to copy data between distinct memory objects, and OpenCL provides us a convenient way to do this via <code class="literal">clEnqueueCopyBuffer</code>. It can only take place between two different memory objects (for example, one is a plain buffer and the other is a sub-buffer) or between two similar objects (for example, both are sub-buffers or plain buffers) and the area of copy cannot overlap. Here's the method signature:</p><div><pre class="programlisting">cl_int clEnqueueCopyBuffer(cl_command_queue command_queue,
                           cl_mem src_buffer,
                           cl_mem dst_buffer,
                           size_t src_offset,
                           size_t dst_offset,
                           size_t cb,
                           cl_uint num_events_in_wait_list,
                           const cl_event* event_wait_list,
                           cl_event* event)</pre></div><p>The list of functions for copying data between memory objects are as follows:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">clEnqueueCopyBuffer</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">clEnqueueCopyImage</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">clEnqueueCopyBufferToImage</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">clEnqueueCopyImageToBuffer</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">clEnqueueCopyBufferRect</code></li></ul></div><p>To copy a buffer, you need to indicate the source and destination <code class="literal">cl_mem</code> objects via <code class="literal">src_buffer</code> and <code class="literal">dst_buffer</code>, indicate where to start the copying by indicating the offsets of the <code class="literal">src_buffer</code> and <code class="literal">dst_buffer</code> via <code class="literal">src_offset</code> and <code class="literal">dst_offset</code> respectively together with the size of data to copy via <code class="literal">cb</code>. If you wish for the copying of the data to take place after some operations, you need to indicate the number of those operations and a valid array of <code class="literal">cl_event</code> objects that represent each operation via<code class="literal"> num_events_in_wait_list</code> and <code class="literal">event_wait_list</code> respectively.</p><div><div><h3 class="title"><a id="tip07"/>Tip</h3><p>Take note that you can query the device on the status of the copying, when your data array is large, by passing an event object to the <code class="literal">event</code> argument. Another approach is to enqueue a <code class="literal">clEnqueueBarrier</code> command.</p></div></div><div><div><div><div><h2 class="title"><a id="ch02lvl2sec43"/>Getting ready</h2></div></div></div><p>The<a id="id149" class="indexterm"/> following code is an extract from <code class="literal">Ch2/copy_buffer/copy_buffer.c</code>, and it <a id="id150" class="indexterm"/>illustrates how to enqueue a <code class="literal">clEnqueueCopyBuffer</code> command to the command queue, and the kernel uses this copy of the data for computation. This process is iterated among the detected OpenCL devices on the machine. The following diagram illustrates how the original data block (previous diagram) is copied to another <code class="literal">cl_mem</code> object (next diagram) and passed off to the OpenCL devices for computation.</p><div><img src="img/copy_buffers.jpg" alt="Getting ready"/></div></div><div><div><div><div><h2 class="title"><a id="ch02lvl2sec44"/>How to do it…</h2></div></div></div><p>We've included the<a id="id151" class="indexterm"/> main<a id="id152" class="indexterm"/> part of this recipe, with the highlighted commentary:</p><div><pre class="programlisting">cl_mem UDObj = clCreateBuffer(context,
                              CL_MEM_READ_WRITE |
                              CL_MEM_COPY_HOST_PTR,
                              sizeof(UserData) * DATA_SIZE, 
                              ud_in, &amp;error);
… // code omitted. See the source.
<strong>/* Create a buffer from the main buffer 'UDObj' */</strong>
cl_mem copyOfUDObj = clCreateBuffer(context, CL_MEM_READ_WRITE,	                                               
                                    sizeof(UserData) * DATA_SIZE,
                                    0, &amp;error)
if (error != CL_SUCCESS) { 
  perror("Unable to create sub-buffer object");
  exit(1);
}
<strong>/* Let OpenCL know that the kernel is suppose to receive an argument */</strong>
error = clSetKernelArg(kernels[j], 
                       0,
                       sizeof(cl_mem),
                       &amp;copyOfUDObj);
if (error != CL_SUCCESS) { 
  perror("Unable to set buffer object in kernel");
  exit(1);
}
// code omitted. See the source.
<strong>/* Enqueue the copy-write from device to device */</strong>
error = clEnqueueCopyBuffer(cQ,
                            UDObj,
                            copyOfUDObj,              
                            0,            // copy from which offset
                            0,            // copy to which offset
                            sizeof(UserData)*DATA_SIZE,
                            0, NULL, NULL);
printf("Data will be copied!\n");
// Code for enqueueing kernels is omitted.
<strong>/* Enqueue the read-back from device to host */</strong>
error = clEnqueueReadBuffer(cQ, 
                            copyOfUDObj, 
                            CL_TRUE,  // blocking read
                            0,        // read from the start
                            sizeof(UserData)*DATA_SIZE,
                            ud_out, 0, NULL, NULL);</pre></div><p>On OSX, you can run the following command:</p><div><pre class="programlisting">
<strong>gcc -std=c99 -Wall -DUNIX -g  -DAPPLE -arch i386 -o copy_buffer copy_buffer.c   -framework OpenCL</strong>
</pre></div><p>On Ubuntu Linux 12.04 with Intel OpenCL SDK installed, you can run the following command:</p><div><pre class="programlisting">
<strong>gcc -std=c99 -Wall -DUNIX -g -DDEBUG -m64 -o copy_buffer copy_buffer.c -I . -I /usr/include -L/usr/lib64/OpenCL/vendors/intel -lintelocl -ltbb -ltbbmalloc -lcl_logger -ltask_executor</strong>
</pre></div><p>On Ubuntu Linux 12.04 with NVIDIA CUDA 5 installed, you can run the following command:</p><div><pre class="programlisting">
<strong>gcc -std=c99 -Wall -DUNIX -g -DDEBUG -m64 -o copy_buffer copy_buffer.c -I. -I/usr/local/cuda/include  -lOpenCL</strong>
</pre></div><p>A binary <a id="id153" class="indexterm"/>executable named <code class="literal">copy_buffer</code> will be deposited on the directory.</p><p>Depending on how<a id="id154" class="indexterm"/> many OpenCL SDKs are installed on your machine, your output may vary but on my OSX, the following is the output:</p><div><pre class="programlisting">Number of OpenCL platforms found: 1
Number of detected OpenCL devices: 2
Kernel name: hello with arity: 1
About to create command queue and enqueue this kernel...
Task has been enqueued successfully!
Data will be copied!
Check passed!
Kernel name: hello with arity: 1
About to create command queue and enqueue this kernel...
Task has been enqueued successfully!
Data will be copied!
Check passed!</pre></div></div><div><div><div><div><h2 class="title"><a id="ch02lvl2sec45"/>How it works…</h2></div></div></div><p>The application needed to compute the copied buffer, and you can tell this because <code class="literal">clSetKernelArg</code> was defined that way by this statement:</p><div><pre class="programlisting">error = clSetKernelArg(kernels[j], 0, sizeof(cl_mem), &amp;copyOfUDObj);</pre></div><p>Next, we can perform a copy operation, which takes place in the device's memory, via <code class="literal">clEnqueueCopyBuffer</code> and finally retrieve the computed values via <code class="literal">clEnqueueReadBuffer</code>.</p><div><div><h3 class="title"><a id="tip08"/>Tip</h3><p>The created command queue will default to in-order execution, instead of out-of-order execution so the device will execute the commands in the order of the queueing.</p></div></div><p>Now, we<a id="id155" class="indexterm"/> are going to talk about the one-dimensional and two-dimensional data transfer APIs such as <code class="literal">clEnqueueReadBuffer</code>, <code class="literal">clEnqueueWriteBuffer</code>, <code class="literal">clEnqueueWriteBufferRect</code>, and <code class="literal">clEnqueueReadBufferRect</code> and we are doing this now because you have seen that most of our examples, so far, we demonstrated the creation of memory objects via<code class="literal"> clCreateBuffer</code> by associating with a memory structure in the host and though that might suffice for some situations, you probably want APIs that gives you more control when memory objects in the <a id="id156" class="indexterm"/>device memory are to be written or read from. The control these APIs give you, the developer, is from the fact that they are enqueued onto the command-queue with any events the developer might craft; and that provides a good permutation of strategies and flexibilities for structuring I/O in heterogeneous environments.</p><div><div><h3 class="title"><a id="note07"/>Note</h3><p>Be aware that there are similar APIs for reading and writing two or three dimensional images to/from host to the device memory. Their names are <code class="literal">clEnqueueReadImage</code>, <code class="literal">clEnqueueWriteImage</code>, <code class="literal">clEnqueueReadImageRect</code>, and <code class="literal">clEnqueueWriteImageRect</code>. Refer to the OpenCL 1.2 Specifications for more details.</p></div></div><p>These APIs allows us to indicate to the device when we wish the data transfer to occur, very much like <code class="literal">clEnqueueCopyBuffer</code>. Let's take a look at their method signatures:</p><div><pre class="programlisting">cl_int clEnqueueReadBuffer(cl_command_queue command_queue,
                        cl_mem buffer,
                           cl_bool blocking_read, 
                           size_t offset,
                           size_t cb, 
                           void *ptr,
                           cl_uint num_events_in_wait_list,
                           const cl_event *event_wait_list,
                           cl_event *event)
cl_int clEnqueueWriteBuffer(cl_command_queue command_queue,
                        cl_mem buffer,
                           cl_bool blocking_write, 
                           size_t offset,
                           size_t cb, 
                           const void *ptr,
                           cl_uint num_events_in_wait_list,
                           const cl_event *event_wait_list,
                           cl_event *event)</pre></div><p>These <a id="id157" class="indexterm"/>two functions are very similar to one another, and they <a id="id158" class="indexterm"/>basically say if you wish to read/write to/from a memory buffer , that is, a <code class="literal">cl_mem</code> object, you need to indicate which command queue is it via <code class="literal">command_queue</code>, what buffer it is via <code class="literal">buffer</code>, whether to be a blocking-read/write via <code class="literal">blocking_read/blocking_write</code>, where to read/write from for what size via <code class="literal">offset</code> and <code class="literal">cb</code>, where to read the data or write the data to via <code class="literal">ptr</code>, should this read/write command occur after some events via <code class="literal">num_events_in_wait_list</code> and <code class="literal">event_wait-list</code>. The last argument in the function is <code class="literal">event</code>, which allows the reading or writing operation to be queried which is described in <code class="literal">clEnqueueCopyBuffer</code>.</p><p>Blocking reads in <code class="literal">clEnqueuReadBuffer</code> means that the command does not exit until the host pointer has been filled by the device memory buffer; similarly blocking-writes in <code class="literal">clEnqueueWriteBuffer</code> means that the command doesn't exit until the entire device memory buffer has been written to by the host pointer.</p><p>To see how these calls are used, you can refer to the earlier illustrated code in the recipe <em>Understanding events and event-synchronization</em> and for your convenience the following is the relevant code in <code class="literal">Ch2/events/events.c</code>:</p><div><pre class="programlisting">ret = clEnqueueWriteBuffer(command_queue, objA, CL_TRUE, 0, 4*4*sizeof(float), A, 0, NULL, NULL );
ret = clEnqueueWriteBuffer(command_queue, objB, CL_TRUE, 0, 4*4*sizeof(float), B, 1, &amp;event1, NULL);</pre></div><p>Having the capability to model one-dimensional memory objects is fantastic, but OpenCL goes a notch further by facilitating two-dimensional memory object memory transfers.</p><p>Here is an example of reading a two-dimensional data blocks from the device's memory to the output buffer in the host memory; extracted from <code class="literal">Ch2/simple_2d_readwrite/simple_2d_readwrite.c</code>. The code illustrates the usage of the <code class="literal">buffer_origin</code>, <code class="literal">host_origin</code>, and <code class="literal">region</code> as in the API. The application will read from the <code class="literal">UDObj cl_mem</code> object, which represents the one-dimensional input data, <code class="literal">hostBuffer</code>, as a 2 x 2 matrix and writes them into the host memory data block represented by <code class="literal">outputPtr</code>. The application reads back the data from the device to host memory and checks for sanity.</p><div><pre class="programlisting">cl_int hostBuffer[NUM_BUFFER_ELEMENTS] = {0, 1, 2, 3, 4, 5, 6, 7,
                                          8,9,10,11,12,13,14,15};
cl_int outputPtr[16] = {-1, -1, -1, -1,-1, -1, -1, -1,-1, -1, -1, 
                        -1,-1, -1, -1, -1};
for(int idx = 0; idx &lt; 4; ++ idx) {	
    size_t buffer_origin[3] = {idx*2*sizeof(int), idx, 0}; 
    size_t host_origin[3] = {idx*2*sizeof(int), idx, 0}; 
    size_t region[3] = {2*sizeof(int), 2, 1};
error = clEnqueueReadBufferRect (cQ,
                                 UDObj,
                                 CL_TRUE,
                                 buffer_origin,
                                 host_origin,
                                 region,
                                 0, //buffer_row_pitch,
                                 0, //buffer_slice_pitch,
                                 0, //host_row_pitch,
                                 0, //host_slice_pitch,
                                 outputPtr,
                                 0, NULL, NULL);
}//end of for-loop</pre></div><p>In this example, we used the <code class="literal">for</code> loop and<a id="id159" class="indexterm"/> standard array indexing<a id="id160" class="indexterm"/> techniques in <code class="literal">C</code> to model how you might iterate through a two-dimensional array and referencing the elements so that we progressively copy the input. We won't dwell too much into this because, building and running it is very similar to the previous, and you should explore the directory to see how the build and program works via the <a id="id161" class="indexterm"/>Makefile.</p></div></div>
<div><div><div><div><h1 class="title"><a id="ch02lvl1sec23"/>Using work items to partition data</h1></div></div></div><p>In the previous chapter, we <a id="id162" class="indexterm"/>introduced how<a id="id163" class="indexterm"/> work can be partitioned in a one-dimensional array across several work items (you should flip back now if you cannot remember), and also how each work item would obtain an index in which the kernel can use to conduct the computation in the kernel code <code class="literal">vector_multiplication</code>. In this recipe, we are going to build on that by exploring two-dimensional data partitioning in more detail.</p><p>By now, you should realize that one of the cornerstones of OpenCL is getting the data into the device/s for processing via kernels, and you've seen how data can be partitioned among different devices via kernels. In the former, you've seen how we used the distributed array pattern to partition the data among the devices; this refers to coarse grain data-parallelism. The latter refers to the coarse grained task-parallelism that OpenCL provides and it is coarse grained because OpenCL is capable of both data-parallelism and task-parallelism.</p><p>Most of the code you've seen so far have been using <code class="literal">clEnqueueTask</code> to execute the kernel based on the one-dimensional data blocks and to get your kernel to process two or three dimensional data we need to understand <code class="literal">clEnqueueNDRangeKernel</code>; and how data can be laid out conceptually in two or three dimensional space.</p><div><div><h3 class="title"><a id="tip09"/>Tip</h3><p>It is helpful to visualize the two or three dimensional data layout in the device memory to be row-based instead of column-based.</p></div></div><p>The <code class="literal">NDRange</code> in <code class="literal">clEnqueueNDRangeKernel</code> refers to a data indexing scheme that is supposed to span an N-dimensional range of values and hence, the given name. Currently, <em>N</em> in <a id="id164" class="indexterm"/>this N-dimensional index space can be one, two, or three. Next, <a id="id165" class="indexterm"/>we can split each dimensional into chunks of sizes two, three, four, or more till we reached the maximum allowable by the parameter <code class="literal">CL_DEVICE_MAX_WORK_ITEM_DIMENSIONS</code>. Refer to the<code class="literal"> Ch1/device_details/device_details.c</code> on how to obtain the values. This would decide how many processing groups we can run in parallel, and in OpenCL they are called<a id="id166" class="indexterm"/> <strong>work groups</strong>. The work groups would have a number of available processing elements that are called <strong>work items</strong><a id="id167" class="indexterm"/> though I like to think of them as executable threads.</p><p>Let's work through an example using a two-dimensional data size of 12 rows by 12 columns, that is, a 12 x 12 matrix. Let's look at the following diagram to understand how the work groups and work items are related to one another:</p><div><img src="img/work_partition.jpg" alt="Using work items to partition data"/></div><p>In this example, I've <a id="id168" class="indexterm"/>decided to partition the two-dimensional space to<a id="id169" class="indexterm"/> create nine work groups where each work group is a 4 x 4 matrix. Next, to decide how many work items there should be in each work group, and you have two choices: a) assign one work-item to process each cell in your 4 x 4 matrix, b) assign one work item to process n-cells in your 4 x 4 matrix; in the second option it would be similar to vector processing where n-values are loaded together for the work item to process. Let's assume that we've decided to choose the option a</p><div><div><h3 class="title"><a id="tip10"/>Tip</h3><p>We'll look at the various data types in the <a class="link" href="ch03.html" title="Chapter 3. Understanding OpenCL Data Types">Chapter 3</a>, <em>Understanding OpenCL Data Types</em>.</p></div></div><p>At this time, let's take a detailed look at the API <code class="literal">clEnqueueNDRangeKernel</code> with the following method signature, and understand how to input those values with our example:</p><div><pre class="programlisting">cl_int
clEnqueueNDRangeKernel(cl_command_queue command_queue,
                       cl_kernel kernel,
                       cl_uint work_dim,
                       const size_t *global_work_offset,
                       const size_t *global_work_size,
                       const size_t *local_work_size,
                       cl_uint num_events_in_wait_list,
                       const cl_event *event_wait_list,
                       cl_event *event)</pre></div><p>Let's look at what those variables in <code class="literal">clEnqueueNDRangeKernel</code> are for; the <code class="literal">command_queue</code> refers to the particular queue like the <code class="literal">kernel</code>, to execute on. Next, you need to indicate how many dimensions your input data has via <code class="literal">work_dim</code>; the next two variables <code class="literal">global_work_size</code> and <code class="literal">local_work_size</code> would indicate how many work groups there are and how <a id="id170" class="indexterm"/>many work items / work threads can <a id="id171" class="indexterm"/>execute in each work group. Recall that the kernel gets scheduled on the device, but it is the work group that gets assign compute units of the device and the work items execute on the processing element in the compute unit. Next, if you need the launch of the kernel to wait on a couple of events in your algorithm, you can indicate them through <code class="literal">num_events_in_wait_list</code> and <code class="literal">event_wait_list</code>, and finally if you wish to associate an event to this kernel's state you can pass in an event type to <code class="literal">event</code> in this API.</p><p>The method signature should not look that intimidating to you by now. Given a 12 x 12 matrix partitioned into nine work groups where each work group is a 4 x 4 matrix and each work item will process one data cell, we will code it like the following code snippet:</p><div><pre class="programlisting"> cl_uint work_dim = 2; // 2-D data
 size_t global_work_offset[2] = {0,0}; // kernel evals from (0,0)
 size_t global_work_size[2] = {12,12};
 size_t local_work_size[2]  = {4,4};
 clEnqueueNDRangeKernel(command_q, kernel, work_dim,
 global_work_offset,global_work_size, local_work_size, 0,
 NULL,NULL);</pre></div><p>To ensure you have got your calculations correct, you can use the following simple formula:</p><div><div><h3 class="title"><a id="tip11"/>Tip</h3><p>Number of work-groups = (global_work_size[0]*…*global_work_size[n-1]) / (local_work_size[0]*…*local_work_size[n-1])</p></div></div><p>Next, we are going to take a look at how we can enable this task-parallelism and data-parallelism to be processed by the CPU and GPU where each device will copy a one-dimensional data array from the input buffer and treat it like a two-dimensional matrix for parallel computing, and finally output the results to a one-dimensional matrix.</p><div><div><div><div><h2 class="title"><a id="ch02lvl2sec46"/>Getting ready</h2></div></div></div><p>In <code class="literal">Ch2/work_partition/work_partition.c</code>, we saw an excerpt where we need to copy a million elements from an input buffer to an output buffer using a two-dimensional data format. We proceed to partition the data into a 1024 x 1024 matrix where each work item processes a single cell and we create work groups of the size 64 x 2 matrix.</p><div><div><h3 class="title"><a id="tip12"/>Tip</h3><p>Caveat—during my experimentation, this program crashed when executing on the OSX 10.6 Intel Core i5 with OpenCL 1.0 as the work group can only be of size one in each dimension. We'll look in the <a class="link" href="ch03.html" title="Chapter 3. Understanding OpenCL Data Types">Chapter 3</a>, <em>Understanding OpenCL Data Types</em> on how to make our programs more portable.</p></div></div><p>The kernel <a id="id172" class="indexterm"/>function, <code class="literal">copy2Dfloat4</code> is a typical function<a id="id173" class="indexterm"/> which is executed on the device and we like to express the idea of transferring a vector of elements from one point to another and once that's done, the application will conduct a data sanity check which will pass or fail the program; Refer to the <code class="literal">Ch2/work_partition/work_partition.cl</code>.</p></div><div><div><div><div><h2 class="title"><a id="ch02lvl2sec47"/>How to do it…</h2></div></div></div><p>We've included the main part of this recipe, with the highlighted commentary in the following code:</p><div><pre class="programlisting">// --------- file: work_partition.cl --------------
#define WIDTH 1024
#define DATA_TYPE float4
/*
  The following macros are convenience 'functions'
  for striding across a 2-D array of coordinates (x,y)
  by a factor which happens to be the width of the block
  i.e. WIDTH
*/
#define A(x,y) A[(x)* WIDTH + (y)] #define C(x,y) C[(x)* WIDTH + (y)]
__kernel void copy2Dfloat4(__global DATA_TYPE *A, __global DATA_TYPE *C)
{
    int x = get_global_id(0);
    int y = get_global_id(1);
    // its like a vector load/store of 4 elements
    C(x,y) = A(x,y);
}
// --------- file: work_partition.c ---------
cl_float* h_in = (float*) malloc( sizeof(cl_float4) * DATA_SIZE); // input to device
cl_float* h_out = (float*) malloc( sizeof(cl_float4) * DATA_SIZE); // output from device
  for( int i = 0; i &lt; DATA_SIZE; ++i) {
    h_in[i] = (float)i;
  }
// code omitted
cl_mem memInObj = clCreateBuffer(context, CL_MEM_READ_WRITE | CL_MEM_COPY_HOST_PTR, sizeof(cl_float4) * (DATA_SIZE), h_in, &amp;error);
cl_mem memOutObj = clCreateBuffer(context, 
                                  CL_MEM_WRITE_ONLY ,
                                  sizeof(cl_float4) * (DATA_SIZE),
                                  NULL, &amp;error);
if(error != CL_SUCCESS) {
  perror("Can't create an output buffer object");
  exit(1);
}
<strong>/* Let OpenCL know that the kernel is suppose to receive two arguments */</strong>
error = clSetKernelArg(kernels[j], 0, sizeof(cl_mem), &amp;memInObj);
if (error != CL_SUCCESS) {
  perror("Unable to set buffer object in kernel");
  exit(1);
}
error = clSetKernelArg(kernels[j], 1, sizeof(cl_mem), &amp;memOutObj);
if (error != CL_SUCCESS) {
  perror("Unable to set buffer object in kernel");
  exit(1);
}
<strong>/* Enqueue the kernel to the command queue */</strong>
size_t globalThreads[2];
globalThreads[0]=1024;
globalThreads[1]=1024;
size_t localThreads[2];
localThreads[0] = 64;
localThreads[1] = 2;
cl_event evt;
error = clEnqueueNDRangeKernel(cQ, 
                               kernels[j],
                               2,
                               0,
                               globalThreads,
                               localThreads,
                               0, 
                               NULL, &amp;evt);
clWaitForEvents(1, &amp;evt);
if (error != CL_SUCCESS) {
  perror("Unable to enqueue task to command-queue");
  exit(1);
}
clReleaseEvent(evt);</pre></div><p>On OSX, you can run the following command:</p><div><pre class="programlisting">
<strong>gcc -std=c99 -Wall -DUNIX -g  -DAPPLE -arch i386 -o work_partition work_partition.c   -framework OpenCL</strong>
</pre></div><p>On Ubuntu Linux 12.04 with Intel OpenCL SDK installed, you can run the following command:</p><div><pre class="programlisting">
<strong>gcc -std=c99 -Wall -DUNIX -g -DDEBUG -m64 -o work_partition work_partition.c -I . -I /usr/include -L/usr/lib64/OpenCL/vendors/intel -lintelocl -ltbb -ltbbmalloc -lcl_logger -ltask_executor</strong>
</pre></div><p>On Ubuntu Linux 12.04 with NVIDIA CUDA 5 installed, you can run the following command:</p><div><pre class="programlisting">
<strong>gcc -std=c99 -Wall -DUNIX -g -DDEBUG -m64 -o work_partition work_partition.c -I. -I/usr/local/cuda/include  -lOpenCL</strong>
</pre></div><p>A binary executable named <code class="literal">work_partition</code> will be deposited on the directory.</p><p>On Ubuntu <a id="id174" class="indexterm"/>Linux 12.04 with AMD APP SDK v2.8 and <a id="id175" class="indexterm"/>NVIDIA CUDA 5 installed, I have the following output. If you ran the program using the Intel® OpenCL SDK, then you will not see the output related to the discrete graphics chip. In this example, we have demonstrated both coarse-grained and fine-grained data and task parallelism:</p><div><pre class="programlisting">Number of OpenCL platforms found: 2
Number of detected OpenCL devices: 1
Running GPU 
    =&gt; Kernel name: copy2Dfloat4 with arity: 2
    =&gt; About to create command queue and enqueue this kernel...
    =&gt; Task has been enqueued successfully!
Check passed!
Number of detected OpenCL devices: 1
Running on CPU ........
    =&gt; Kernel name: copy2Dfloat4 with arity: 2
    =&gt; About to create command queue and enqueue this kernel...
    =&gt; Task has been enqueued successfully!
Check passed!</pre></div></div><div><div><div><div><h2 class="title"><a id="ch02lvl2sec48"/>How it works…</h2></div></div></div><p>The host application allocates two buffers that are capable of storing a million elements of the data type <code class="literal">cl_float4</code>, which is a OpenCL <code class="literal">vector</code> data type. Next we proceed to build the program via <code class="literal">clBuildProgramWithSource</code> (refer to <code class="literal">Ch2/work_partition/work_partition.c</code>), and pick up all the kernels in the kernel file (<code class="literal">*.cl</code>). Each detected device will pick up a one-dimensional input buffer, transform it to a two-dimensional matrix, and partition the data among its parallel computing units where each work group will compute the following:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Obtain the index for the row via <code class="literal">get_global_id(0)</code>; which can be thought of as the thread's ID in the x-axis</li><li class="listitem" style="list-style-type: disc">Obtain the index for the column via <code class="literal">get_global_id(1)</code>; which can be thought of as the thread's ID in the y-axis</li><li class="listitem" style="list-style-type: disc">Together with the row and column indexes, perform a memory load of 4 elements and store the same via <code class="literal">C(x,y) = A(x,y)</code></li></ul></div><p>The <a id="id176" class="indexterm"/>OpenCL runtime would have partition the data <a id="id177" class="indexterm"/>among the work groups, together with the IDs for the work items as well as work groups; hence there would not be a situation where the thread IDs being duplicated and hence waging mayhem on the computation (the OpenCL vendor has that responsibility of ensuring it doesn't occur). OpenCL knows how to do this because the dimensions of the input data, together with the number of work groups and number of executing work items are passed via the parameters <code class="literal">work_dim</code>, <code class="literal">global_work_size</code>, and <code class="literal">local_work_size</code> in the <code class="literal">clEnqueueNDRangeKernel</code> API.</p><p>An example should clarify this: Assume that the imaginary input data has two-dimensions and the <code class="literal">global_work_size</code> is 8192 and <code class="literal">local_work_size</code> is 16*16, then we will have 8192/(16*16) = 32 work groups; to be able to reference any element in a two-dimensional data block, you will write some code similar to this to generate the global thread ID in (this is not the only way to do this, but it is the generally preferred method):</p><div><pre class="programlisting">int x = get_local_id(0);//x would range from 0 to 15
int y = get_local_id(1);//y would range from 0 to 15
int blockIdX = get_group_id(0);
int blockIdY = get_group_id(1);
int blockSizeX = get_local_size(0); // would return 16
int blockSizeY = get_local_size(1); // would return 16
uint globalThreadId = (blockIdx * blockSizeX + x) + 
                      (blockIdY * blockSizeY + y);</pre></div><p>The OpenCL kernel will complete its computation eventually because of an invocation to <code class="literal">clWaitForEvents</code> (we'll talk about this in the next chapter), and then the output buffer is stored with data from the device memory via <code class="literal">clEnqueueReadBuffer</code> and the data is sanity checked.</p></div></div></body></html>