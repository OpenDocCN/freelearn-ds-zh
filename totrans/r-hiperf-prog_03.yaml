- en: Chapter 3. Simple Tweaks to Make R Run Faster
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Improving the speed of an R code does not necessarily involve advanced optimization
    techniques like parallelizing the code or making it run in the database. Indeed,
    there are a number of simple tweaks that, while not always obvious, can make R
    run significantly faster. In this chapter, some of these tweaks are described.
    By no means do they capture all possible simple means to optimize the R code.
    However, they constitute some of the most fundamental, and hence often-encountered,
    opportunities to gain some speedups.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter presents these tweaks in the order of decreasing generality—the
    more general ones are those found in almost all R codes, regardless of their application.
    Each tweak is accompanied by an example code that is intentionally kept simple
    so as not to obscure the explanation of the intended concept with unnecessary
    application-specific knowledge. In all these examples, artificial datasets are
    generated using random functions in R.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter covers the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Vectorization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use of built-in functions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Preallocating memory
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use of simpler data structures
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use of hash tables for frequent lookups on large data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Seeking fast alternative packages in CRAN
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vectorization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Most R users should have encountered this first tweak. In essence, vectorization
    allows R operators to take vectors as arguments for quick processing of multiple
    values. This is unlike some other programming languages such as C, C++, and Java,
    in which the processing of multiple values is usually done by iterating through
    and applying operators on each element of a vector (or array). R, being a flexible
    language, allows users to program using either iteration or vectorization. However,
    most of the time, iteration incurs significant and unnecessary computational cost
    because R is an interpreted, not compiled, language.
  prefs: []
  type: TYPE_NORMAL
- en: 'Take for example, the following simple code. Its goal is simply to calculate
    the square of every element in the random vector `data`. The first approach is
    to set up a `for` loop through every element of `data` and square it individually.
    Many would be tempted to take this approach because this is how it is done typically
    in other programming languages. Yet, a far more optimized approach in R is to
    apply the square operator on the `data` vector directly. This gives exactly the
    same output as the `for` loop, but much faster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The following table shows the performance gains as the vector size increases
    (in logarithmic scale) from 100,000 to 100,000,000\. Notice that the compute time
    of the non-vectorized approach is about 200 times that of the vectorized approach,
    regardless of the vector size.
  prefs: []
  type: TYPE_NORMAL
- en: '| **Vector size** | 100,000 | 1,000,000 | 10,000,000 | 100,000,000 |'
  prefs: []
  type: TYPE_TB
- en: '| **Non-vectorized** | 120 ms | 1.19 s | 11.9 s | 117 s |'
  prefs: []
  type: TYPE_TB
- en: '| **Vectorized** | 508 μs | 5.67 ms | 52.5 ms | 583 ms |'
  prefs: []
  type: TYPE_TB
- en: When R executes a code, it has to take many steps behind the scenes. One example
    is type checking. R objects such as vectors do not need to be strictly defined
    to be of a particular type, such as an integer or a character. One can append
    a character to an integer vector without triggering any error—R converts the vector
    into a character vector automatically. Every time an operator is applied on a
    vector, R needs to check the type of the vector only once, but with the use of
    the iteration approach, this type checking happens as many times as the number
    of iterations, which incurs some computational costs.
  prefs: []
  type: TYPE_NORMAL
- en: Use of built-in functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As a programming language, R comes with low-level operators, such as basic arithmetic
    operators that can be used to construct more complex operators or functions. While
    R provides the flexibility to define functions, a performance comparison between
    an R function versus an equivalent function in a compiled language would almost
    always favor the latter. However, R and some CRAN packages provide a rich set
    of functions that are implemented in compiled languages such as C/C++. It is usually
    preferable to use these functions rather than to write custom R functions to perform
    the same task.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider a simple example of how to calculate the sums of the rows of the following
    random matrix `data`. A code to perform these functions can be constructed by
    calling the `apply()` function, and setting the margin to 1 (representing a row
    operation) and by setting the `FUN` (or function) argument to `sum`. Alternatively,
    R provides a built-in function for this purpose called `rowSums`. The computational
    time of the former approach, as measured by `system.time`, is 11 times longer
    than that of the latter approach, which is an optimized and precompiled C function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Speaking of optimized functions, our effort to improve the speed of an R code
    should not stop at precompiled functions that come with R. Over the years, the
    open source community has developed optimized libraries of specific functions
    that R can leverage. Take Basic Linear Algebra Subprograms (BLAS) for example
    (for more information refer to [http://www.netlib.org/blas/](http://www.netlib.org/blas/)).
    It was developed in the 1970s for Fortran and has since gained wider use by other
    languages (including R) because matrix operations make up the building blocks
    of many algorithms in various fields. There are now many implementations of BLAS,
    some of which include the capability to execute matrix operations in a multithreaded
    manner.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, the Mac OS X version of R comes enabled with BLAS. The implementation
    of BLAS that is used is the reference BLAS from R called `libRblas.0.dylib`. Mac
    OS X however comes with its own version of BLAS, `libBLAS.dylib`, which is optimized
    for its hardware. R can be configured to use the optimized BLAS by executing the
    following commands in Terminal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'To test the effect of using different BLAS libraries, the following R code
    performs a simple matrix multiplication on a large random matrix. Using R''s default
    BLAS library, it took about 7 seconds for us to complete the task. After pointing
    R to the optimized BLAS, the same task was completed in about a tenth of the time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'There are BLAS versions of Windows and Linux available for you to download.
    If R is compiled with an enabled BLAS, that is, by setting the configuration option
    to `--enable-BLAS-shlib` while compiling R from its source, swapping between BLAS
    versions is done in a similar manner as in Mac OS X: by replacing the default
    BLAS library file with the new one. In Windows, the default library is located
    in `R_HOME\bin\x64\Rblas.dll`; while in Linux, it is in `R_HOME/lib/libRblas.so`.'
  prefs: []
  type: TYPE_NORMAL
- en: Preallocating memory
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Most strongly typed programming languages like C, C++, and Java generally require
    a vector (or array) to be declared prior to any operation applied on it. This
    declaration in effect preallocates the memory space that the vector requires.
    There are special occasions where dynamic memory allocation is used, but this
    is seldom the first choice mainly because dynamic memory allocation slows down
    a program. Every time a vector is resized, the program needs to perform extra
    steps that include copying the vector to a larger or smaller memory block and
    deleting the old vector. These steps are not needed if the memory is preallocated.
  prefs: []
  type: TYPE_NORMAL
- en: When it comes to preallocating memory, R is no different from the other programming
    languages. However, being an interpreted language, it imposes less control, thus
    it is easy for users to overlook this—R will not throw any compilation error if
    a vector's memory is not preallocated. Nevertheless, not preallocating memory
    in R can result in significantly longer execution times, especially when the vector
    is large.
  prefs: []
  type: TYPE_NORMAL
- en: 'To demonstrate this, let''s have a look at the following R code. It shows you
    two approaches to generate a series of random numbers, where each vector element
    is defined as the value of the previous element +/- a random integer between -5
    to 5\. The first approach (stores the results in `data_series1`) bypasses the
    preallocation of the vector''s memory, that is, it starts with a vector of a single
    element and appends a new element at each iteration. The second approach (with
    results in `data_series2`) preallocates the memory by declaring a numeric vector
    of size `N`. The preallocated space, as represented by the vector''s index, is
    filled in at every iteration. By preallocating the memory, the computation time
    on a vector of 10,000 elements is 10 times faster than the dynamic allocation.
    A benchmark exercise by varying the vector size, captured in the upcoming table,
    shows that while the computation time increases linearly when memory is preallocated,
    it increases super linearly when memory is dynamically allocated. It is critical
    for performance therefore to avoid unnecessary dynamic memory allocation in R:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '| **Vector size** | 10 | 100 | 1000 | 10,000 |'
  prefs: []
  type: TYPE_TB
- en: '| **Dynamic allocation** | 0 | 0.006 | 0.288 | 25.373 |'
  prefs: []
  type: TYPE_TB
- en: '| **Preallocated** | 0.001 | 0.006 | 0.062 | 0.577 |'
  prefs: []
  type: TYPE_TB
- en: At this point, it is interesting to compare the `apply` family of functions
    versus loops in R. Most R users would be familiar with the `apply()` function
    and its variants, including `lapply()`, `sapply()`, and `tapply()`. They provide
    the means to perform the same operation repeatedly on individual elements of a
    collection (for example, `data.frame`, `list`, or `vector`/`matrix`). Effectively,
    the `apply` family serves as a possible substitute of looping in R, provided there
    are no dependencies between one iteration and another. Besides simplifying the
    expression (it is often possible to express a multiline `for` loop as a single
    line `apply()` call), the `apply` family offers the benefit of automatically taking
    care of the memory preallocation and other housekeeping activities like deleting
    loop indices.
  prefs: []
  type: TYPE_NORMAL
- en: 'But does `apply` offer performance advantages over looping? The following code
    offers an answer to this. Two different approaches are used to generate a list
    of normally distributed random vectors whose sizes are also randomly set to values
    between 1 and 30\. The first approach uses a `for` loop while the second uses
    `lapply()`. Applying `system.time()` on both approaches shows that `lapply()`
    is significantly faster than the `for` loop:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'But note that the `for` loop is implemented naively without preallocating the
    memory. The following code modifies it now with the preallocated memory. Its computation
    time has significantly been reduced to be just a tenth of a second slower than
    `lapply()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'To establish this more convincingly, the comparison was repeated using `microbenchmark()`
    to run each expression 100 times. The results indicate that `lapply()` offers
    a slight performance advantage over a `for` loop:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Based on this, the general view of replacing `for` loops with `apply` in R whenever
    possible is valid, but perhaps the performance gain would not be dramatic. In
    [Chapter 6](ch06.html "Chapter 6. Simple Tweaks to Use Less RAM"), *Simple Tweaks
    to Use Less RAM*, another benefit of `apply` will be discussed—that it reveals
    parts of R code that can be parallelized.
  prefs: []
  type: TYPE_NORMAL
- en: Use of simpler data structures
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Many R users would agree that `data.frame` as a data structure is the workhorse
    of data analysis in R. It provides an intuitive way to represent a typical structured
    dataset with rows and columns representing observations and variables respectively.
    A `data.frame` object also allows more flexibility than a matrix by allowing variables
    of different types (such as character and numeric variables in a single `data.frame`).
    Furthermore, in cases where a `data.frame` stores only variables of the same type,
    basic matrix operations conveniently become applicable to it without any explicit
    coercing required. This convenience, however, can come with performance degradation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Applying a matrix operation on a `data.frame` is slower than on a `matrix`.
    One of the reasons is that most matrix operations first coerce the `data.frame`
    into a `matrix` before performing the computation. For this reason, where possible,
    one should use a `matrix` in place of a `data.frame`. The next code demonstrates
    this point. The goal is simply to perform row summation on a matrix and its equivalent
    `data.frame` representation. Using a `matrix` representation results in about
    3x speedup compared to using a `data.frame` representation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'In many cases of R however, the use of `data.frame` is unavoidable, for example,
    when a dataset has mixed variable types. In this case, there is also a simple
    tweak that can improve the speed of one of the most frequently used operations
    on a `data.frame`, subsetting. Subsetting a `data.frame` is commonly done by conditioning
    its rows (or columns) through a logical test as in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'An alternative to this is to wrap the condition by the `which` function. The
    speed is improved significantly as shown follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Use of hash tables for frequent lookups on large data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'One common task in data analysis is data lookup, which is often implemented
    via a list in R. For example, to look up customers'' ages, we can define a list,
    say, `cust_age`, with values set to customer ages and names set to the corresponding
    customer names (or IDs), that is `names(cust_age) <- cust_name`. In this case,
    to look up John Doe''s age, the following can be called: `cust_age[["John_Doe"]]`.
    However, the implementation of lists in R is not optimized for lookup; it incurs
    *O(N)* time complexity to perform a lookup on a list of *N* elements. This means
    that the values indexed later in the list require more time to look up. As *N*
    grows, this effect gets stronger. When a program requires frequent lookups, the
    cumulative effect can be significant. An alternative to lists that offers a more
    optimized data lookup is a hash table. In R, this is available from the CRAN package
    *hash*. A hash table''s lookup incurs *O(1)* time complexity.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The next code demonstrates the benefit of lookups in hash tables over lists.
    It simulates 1,000 lookups from a random list and its equivalent hash table representation.
    The total computation time required for the list is 6.14 seconds, while for the
    hash table is 0.31 seconds. One trade-off is that it takes more time to generate
    a hash table than a list. But for a program that requires frequent lookups on
    large data, this overhead can be insignificant:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Seeking fast alternative packages in CRAN
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One key advantage of R is its rich and active open source community, CRAN. As
    of the time of writing, there are over 6,000 R packages in CRAN. Given this, it
    is common that multiple packages offer the same functionalities. Some of these
    alternatives are designed specifically to improve the performance of a base or
    an existing CRAN package's performance. Others do not target performance improvement
    explicitly, but nevertheless achieve it as a by-product.
  prefs: []
  type: TYPE_NORMAL
- en: 'An example of an alternative fast package developed to achieve performance
    gains is the `fastcluster` package. It was developed to improve the speed of hierarchical
    clustering provided by the base package through the `hclust` function. Depending
    on how the distance matrix gets updated after every branch merging in the hierarchical
    clustering procedure, its time complexity can vary significantly. The `fastcluster`
    package is developed using an optimized C++ code that improves the speed significantly
    compared to the routines implemented in `hclust`. The following R code compares
    the performance of the two functions on a random matrix with 10,000 rows and 100
    columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'An example of a function that has more than one implementation, where one happens
    to be faster than the others as a by-product is **Principal Component Analysis**
    (**PCA**). PCA is a dimensionality reduction technique that achieves its goal
    by projecting a dataset onto orthogonal axes (called principal components) that
    maximize the dataset''s variance. The most common approach to PCA is via the Eigenvalue
    decomposition of the dataset''s covariance matrix. But there are alternative methods.
    In R, two of these alternatives materialize in two PCA functions called `prcomp`
    and `princomp` (both are parts of the `stats` package). A quick comparison on
    a random matrix with 100,000 rows and 100 columns as in the following code demonstrates
    that `princomp` is close to 2x faster than `prcomp`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'There are other examples of fast packages both explicitly and implicitly. They
    include:'
  prefs: []
  type: TYPE_NORMAL
- en: '`fastmatch`: This provides a faster version of base R''s `match` function'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`RcppEigen`: This includes a faster version of linear modeling `lm`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`data.table`: This offers faster data manipulation operations compared to the
    standard `data.frame` operations'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dplyr` : This offers a set of tools to manipulate data frame-like objects
    efficiently'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter described a few simple tweaks to improve the speed of an R code.
    Some of the tweaks are well known, but often overlooked in practice; others are
    less obvious. Regardless of their nature, and despite their simplicity, these
    low hanging fruits can offer significant performance gains and sometimes even
    more than the advanced optimization discussed in subsequent chapters. As such,
    these tweaks should be taken as the first steps in order to optimize an R code.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will see how to take R's performance even further by
    using compiled code.
  prefs: []
  type: TYPE_NORMAL
