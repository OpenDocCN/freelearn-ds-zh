["```py\nexpect_column_values_to_not_be_null('age')\n```", "```py\npip3 install great_expectations \n```", "```py\npip3 install jupyter\n```", "```py\nmkdir $HOME/peoplepipeline\ncd $HOME/peoplepipeline\n```", "```py\nfrom faker import Faker\nimport csv\noutput=open('people.csv','w')\nfake=Faker()\nheader=['name','age','street','city','state','zip','lng','lat']\nmywriter=csv.writer(output)\nmywriter.writerow(header)\nfor r in range(1000):\n    mywriter.writerow([fake.name(),fake.random_int(min=18,\n    max=80, step=1), fake.street_address(), fake.city(),fake.\n    state(),fake.zipcode(),fake.longitude(),fake.latitude()])\noutput.close()\n```", "```py\ngreat_expectations init\n```", "```py\nWhat data would you like Great Expectations to connect to?\nWhat are you processing your files with?\nEnter the path (relative or absolute) of a data file.\nName the new expectation suite [people.warning].\n```", "```py\ngreat_expectations suite edit people.validate\n```", "```py\ngreat_expectations tap new people.validate peoplevalidatescript.py\n```", "```py\nimport sys\nfrom great_expectations import DataContext\ncontext = DataContext(\"/home/paulcrickard/peoplepipeline/great_expectations\")\nsuite = context.get_expectation_suite(\"people.validate\")\nbatch_kwargs = {\n    \"path\": \"/home/paulcrickard/peoplepipeline/people.csv\",\n    \"datasource\": \"files_datasource\",\n    \"reader_method\": \"read_csv\",\n}\nbatch = context.get_batch(batch_kwargs, suite)\nresults = context.run_validation_operator(\n                               \"action_list_operator\", [batch])\nif not results[\"success\"]:\n    print('{\"result\":\"fail\"}')\n    sys.exit(0)\nprint('{\"result\":\"pass\"}')\nsys.exit(0)\n```", "```py\n    ${result:startsWith('pass')}\n    ${result:startsWith('fail')}\n    ```", "```py\nfake.random_int(min=1, max=100, step=1)\n```", "```py\nimport sys\nfrom great_expectations import DataContext\nfrom airflow.exceptions import AirflowException\nfrom airflow import DAG\nfrom airflow.operators.bash_operator import BashOperator\nfrom airflow.operators.python_operator import PythonOperator\n```", "```py\ndef validateData():\n\tcontext = DataContext(\"/home/paulcrickard/peoplepipeline/great_expectations\")\n\tsuite = context.get_expectation_suite(\"people.validate\")\n\tbatch_kwargs = {\n    \t\"path\": \"/home/paulcrickard/peoplepipeline/people.csv\",\n    \t\"datasource\": \"files_datasource\",\n    \t\"reader_method\": \"read_csv\",\n}\n\tbatch = context.get_batch(batch_kwargs, suite)\n\tresults = context.run_validation_operator(\n                               \"action_list_operator\", [batch])\n\tif not results[\"success\"]:\n    \t\traise AirflowException(\"Validation Failed\")\n```"]