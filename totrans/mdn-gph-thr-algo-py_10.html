<html><head></head><body>
<div id="_idContainer086" class="calibre2">
<h1 class="chapter-number" id="_idParaDest-78"><a id="_idTextAnchor078" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.1.1">6</span></h1>
<h1 id="_idParaDest-79" class="calibre5"><a id="_idTextAnchor079" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.2.1">Stock Market Data</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.3.1">In this chapter, we’ll </span><a id="_idIndexMarker260" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.4.1">introduce </span><strong class="bold"><span class="kobospan" id="kobo.5.1">temporal data</span></strong><span class="kobospan" id="kobo.6.1"> and dive into stock market trend analysis. </span><span class="kobospan" id="kobo.6.2">To understand trends over time, we’ll return to </span><strong class="bold"><span class="kobospan" id="kobo.7.1">centrality measurements</span></strong><span class="kobospan" id="kobo.8.1"> on </span><a id="_idIndexMarker261" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.9.1">networks and introduce some more advanced algorithms. </span><span class="kobospan" id="kobo.9.2">Finally, we’ll analyze stock pricing data over time using our centrality measurements and pinpoint changes in behavior over time within and across different stocks to predict spikes and crashes </span><span><span class="kobospan" id="kobo.10.1">in price.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.11.1">By the end of this chapter, you’ll be able to wrangle datasets with time components into a series of networks and analyze structural changes over time with centrality metrics. </span><span class="kobospan" id="kobo.11.2">Many of the centrality metrics scale well to large networks, particularly when they are run </span><span><span class="kobospan" id="kobo.12.1">in parallel.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.13.1">Specifically, we will cover the </span><span><span class="kobospan" id="kobo.14.1">following topics:</span></span></p>
<ul class="calibre10">
<li class="calibre11"><span class="kobospan" id="kobo.15.1">Introduction to </span><span><span class="kobospan" id="kobo.16.1">temporal data</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.17.1">Introduction to </span><span><span class="kobospan" id="kobo.18.1">centrality metrics</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.19.1">Application of centrality metrics across </span><span><span class="kobospan" id="kobo.20.1">time slices</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.21.1">Extending network metrics for time </span><span><span class="kobospan" id="kobo.22.1">series analytics</span></span></li>
</ul>
<p class="calibre3"><span class="kobospan" id="kobo.23.1">Let’s get started by returning to temporal datasets and the limitations of non-network-based models to </span><span><span class="kobospan" id="kobo.24.1">analyze them.</span></span></p>
<h1 id="_idParaDest-80" class="calibre5"><a id="_idTextAnchor080" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.25.1">Technical requirements</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.26.1">You will require Jupyter Notebook to run the practical examples in this chapter. </span></p>
<p class="calibre3"><span class="kobospan" id="kobo.27.1">The code for this chapter is available </span><span><span class="kobospan" id="kobo.28.1">here: </span></span><a href="https://github.com/PacktPublishing/Modern-Graph-Theory-Algorithms-with-Python" class="pcalibre calibre6 pcalibre1"><span><span class="kobospan" id="kobo.29.1">https://github.com/PacktPublishing/Modern-Graph-Theory-Algorithms-with-Python</span></span></a></p>
<h1 id="_idParaDest-81" class="calibre5"><a id="_idTextAnchor081" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.30.1">Introduction to temporal data</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.31.1">In </span><a href="B21087_02.xhtml#_idTextAnchor028" class="pcalibre calibre6 pcalibre1"><span><em class="italic"><span class="kobospan" id="kobo.32.1">Chapter 2</span></em></span></a><span class="kobospan" id="kobo.33.1">, we briefly introduced temporal </span><a id="_idIndexMarker262" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.34.1">data or data in the form of a time series or a group of time series. </span><strong class="bold"><span class="kobospan" id="kobo.35.1">Time series data</span></strong><span class="kobospan" id="kobo.36.1"> tracks important metrics in many </span><a id="_idIndexMarker263" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.37.1">different industries: daily store sales volumes, weekly software product marketing lead volumes, daily incidence of an emerging disease, yearly behavior rates (such as smoking or vegetable consumption) in a population, or hourly stock prices tracking market trends. </span><span class="kobospan" id="kobo.37.2">Many related factors can influence trends over time, and some models consider these factors directly if they are known </span><span><span class="kobospan" id="kobo.38.1">in advance.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.39.1">However, consider</span><a id="_idIndexMarker264" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.40.1"> the case of sales trends for a new gem store in a city where gem stores are a new phenomenon, perhaps somewhere rural between Haifa and Tel Aviv (</span><span><em class="italic"><span class="kobospan" id="kobo.41.1">Figure 6</span></em></span><em class="italic"><span class="kobospan" id="kobo.42.1">.1</span></em><span class="kobospan" id="kobo.43.1">). </span><span class="kobospan" id="kobo.43.2">Thus, there is very little known about what might influence sales. </span><span class="kobospan" id="kobo.43.3">Understanding what trends exist in the time series data is critical when mining for factors that might influence sales. </span><span class="kobospan" id="kobo.43.4">However, time series datasets pose significant challenges to many supervised learning methods, such </span><a id="_idIndexMarker265" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.44.1">as </span><strong class="bold"><span class="kobospan" id="kobo.45.1">random forest models</span></strong><span class="kobospan" id="kobo.46.1"> or </span><strong class="bold"><span class="kobospan" id="kobo.47.1">linear regression</span></strong><span class="kobospan" id="kobo.48.1">. </span><span class="kobospan" id="kobo.48.2">At</span><a id="_idIndexMarker266" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.49.1"> one point in time, sales are not independent; they rely on factors that influence sales in the previous days, limiting the use of supervised learning and many types</span><a id="_idIndexMarker267" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.50.1"> of </span><strong class="bold"><span class="kobospan" id="kobo.51.1">unsupervised learning</span></strong><span class="kobospan" id="kobo.52.1">. </span><span class="kobospan" id="kobo.52.2">The lack of predictors also poses </span><span><span class="kobospan" id="kobo.53.1">a challenge.</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer076">
<span class="kobospan" id="kobo.54.1"><img alt="Figure 6.1 – ﻿An illustration of a gem store located partway between Tel Aviv and Haifa, Israel" src="image/B21087_06_01.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.55.1">Figure 6.1 – An illustration of a gem store located partway between Tel Aviv and Haifa, Israel</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.56.1">Fortunately, for our gem store, many algorithms are designed to </span><a id="_idIndexMarker268" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.57.1">handle time series data, such </span><a id="_idIndexMarker269" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.58.1">as </span><strong class="bold"><span class="kobospan" id="kobo.59.1">autoregressive integrated moving average models</span></strong><span class="kobospan" id="kobo.60.1"> (</span><strong class="bold"><span class="kobospan" id="kobo.61.1">ARIMA models</span></strong><span class="kobospan" id="kobo.62.1">), </span><strong class="bold"><span class="kobospan" id="kobo.63.1">singular spectrum analysis</span></strong><span class="kobospan" id="kobo.64.1"> (</span><strong class="bold"><span class="kobospan" id="kobo.65.1">SSA</span></strong><span class="kobospan" id="kobo.66.1">), and </span><strong class="bold"><span class="kobospan" id="kobo.67.1">Holt–Winters models</span></strong><span class="kobospan" id="kobo.68.1">. </span><span class="kobospan" id="kobo.68.2">However, changes in time series </span><a id="_idIndexMarker270" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.69.1">behavior (spikes, crashes, and changes in variance) pose a</span><a id="_idIndexMarker271" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.70.1"> challenge to these models. </span><span class="kobospan" id="kobo.70.2">Capturing and predicting these changes is critical if you want to create a predictive model or mine for factors influencing the time series values. </span><span class="kobospan" id="kobo.70.3">In our gem store example, seasonality in tourism, conflicts in the region, and holiday travel promotions may influence traffic along the route in which our store </span><span><span class="kobospan" id="kobo.71.1">is positioned.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.72.1">One industry with abundant and very complex time series data is finance. </span><span class="kobospan" id="kobo.72.2">Many social and economic factors influence stock prices, and untangling the relationships and randomness in stock price fluctuations underlies much of the finance industry. </span><span class="kobospan" id="kobo.72.3">Let’s have a look at the stock market pricing data and common tasks in analyzing stock market </span><span><span class="kobospan" id="kobo.73.1">pricing data.</span></span></p>
<h2 id="_idParaDest-82" class="calibre7"><a id="_idTextAnchor082" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.74.1">Stock market applications</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.75.1">In recent years, the </span><a id="_idIndexMarker272" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.76.1">financial sector has shifted from an expert-driven model of stock market insight to a more machine learning-based approach. </span><span class="kobospan" id="kobo.76.2">Machine learning models sift out emerging trends and catch subtle trends that may escape a human pouring over the data. </span><span class="kobospan" id="kobo.76.3">This tactic also allows analysts to process a much larger data collection than a human could process, including many different sectors, international stock exchanges, and even individual frontier markets. </span><span class="kobospan" id="kobo.76.4">By collecting more insight, it is possible for investors and investment management firms to invest in a wider variety of markets without as much expertise in </span><span><span class="kobospan" id="kobo.77.1">those markets.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.78.1">Stock market analytics covers a vast field of applications. </span><span class="kobospan" id="kobo.78.2">Investments can be made within certain market sectors (such as technology or agriculture) or across markets. </span><span class="kobospan" id="kobo.78.3">They can focus on short-term gains (including those made in minutes or hours) and long-term gains (which may span decades). </span><span class="kobospan" id="kobo.78.4">They can also focus on foreign markets, where stock prices may be influenced by factors very different from those influencing a local market’s prices. </span><span class="kobospan" id="kobo.78.5">All these scenarios guide analytics efforts and the time scale of data collected </span><span><span class="kobospan" id="kobo.79.1">for analysis.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.80.1">In general, analyzing stock market data involves assessing many types of trends over time. </span><span class="kobospan" id="kobo.80.2">Stocks can have constant prices over time, experience gradual price growth and reduction, crash suddenly, or grow exponentially. </span><span class="kobospan" id="kobo.80.3">Each of these suggests a different purchase/sale strategy for investors in the short term and the long term. </span><span><em class="italic"><span class="kobospan" id="kobo.81.1">Figure 6</span></em></span><em class="italic"><span class="kobospan" id="kobo.82.1">.2</span></em><span class="kobospan" id="kobo.83.1"> shows a hypothetical stock that exhibits many of </span><span><span class="kobospan" id="kobo.84.1">these patterns:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer077">
<span class="kobospan" id="kobo.85.1"><img alt="Figure 6.2 – An example of stock data trends, including stagnant periods, growth, shrinkage, and a crash" src="image/B21087_06_02.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.86.1">Figure 6.2 – An example of stock data trends, including stagnant periods, growth, shrinkage, and a crash</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.87.1">We can see in </span><span><em class="italic"><span class="kobospan" id="kobo.88.1">Figure 6</span></em></span><em class="italic"><span class="kobospan" id="kobo.89.1">.2</span></em><span class="kobospan" id="kobo.90.1"> that</span><a id="_idIndexMarker273" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.91.1"> Stock A begins 2022 with a consistent price before entering a growth phase around July 2022. </span><span class="kobospan" id="kobo.91.2">This growth phase lasts until early 2023, at which point it enters a constant pricing phase again. </span><span class="kobospan" id="kobo.91.3">As an event happens in March of 2024, the price of Stock A crashes and then enters a period of price decline until the end of our tracked </span><span><span class="kobospan" id="kobo.92.1">time period.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.93.1">Often, these trends do not occur in isolation. </span><span class="kobospan" id="kobo.93.2">The stocks of companies that share supply chains may exhibit similar trends. </span><span class="kobospan" id="kobo.93.3">Stocks in the same industry may exhibit similar or opposite trends, depending on how companies relate to each other or news in the industry. </span><span class="kobospan" id="kobo.93.4">Stocks in shared trade or defense regions may exhibit similar trends, as well, given the sociopolitical ties across countries and their markets (such as the COVID crash across </span><span><span class="kobospan" id="kobo.94.1">most economies).</span></span></p>
<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.95.1">Tipping points</span></strong><span class="kobospan" id="kobo.96.1">, where</span><a id="_idIndexMarker274" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.97.1"> trends change dramatically, attract a lot of attention in financial analytics. </span><span class="kobospan" id="kobo.97.2">These represent opportunities to invest before a period of accelerating growth or warnings to pull out of a market or particular investment before a crash. </span><span class="kobospan" id="kobo.97.3">However, detecting these trends challenges many of the commonly used tools in </span><span><span class="kobospan" id="kobo.98.1">market analytics.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.99.1">Thankfully, newer tools, including a few rooted in network science, identify tipping points more readily than traditional methods. </span><span class="kobospan" id="kobo.99.2">Many tools hinge on large-scale coupling across markets, sectors, or stocks. </span><span class="kobospan" id="kobo.99.3">As more and more stocks (or markets) exhibit similar behavior, the system becomes vulnerable to outside influences that can tip it into a crash (such as supply chain issues, new legislation, or a pandemic). </span><span class="kobospan" id="kobo.99.4">Simply calculating the correlations among individual stocks or sectors of a market can provide some insight, but transforming</span><a id="_idIndexMarker275" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.100.1"> correlations (within slices of time) to networks allows us to leverage many network science tools that dive deeper into the nature of their correlations and their changes over time. </span><span class="kobospan" id="kobo.100.2">Specifically, centrality metrics allow us to quantify and classify relationships that exist within a network. </span><span class="kobospan" id="kobo.100.3">Let’s explore a few of these </span><span><span class="kobospan" id="kobo.101.1">centrality metrics.</span></span></p>
<h1 id="_idParaDest-83" class="calibre5"><a id="_idTextAnchor083" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.102.1">Introduction to centrality metrics</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.103.1">We’ve encountered some centrality metrics in </span><a href="B21087_03.xhtml#_idTextAnchor042" class="pcalibre calibre6 pcalibre1"><span><em class="italic"><span class="kobospan" id="kobo.104.1">Chapter 3</span></em></span></a><span class="kobospan" id="kobo.105.1">, where we learned about bridges and hubs. </span><span class="kobospan" id="kobo.105.2">Many vertex-based centrality metrics calculate properties related to hubs—the connection of a vertex to its nearest neighbors and their nearest neighbors. </span><span class="kobospan" id="kobo.105.3">Many edge-based centrality metrics calculate bridging properties, where the edges near a vertex act as connectors between </span><span><span class="kobospan" id="kobo.106.1">different hubs.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.107.1">Degree is the</span><a id="_idIndexMarker276" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.108.1"> simplest </span><strong class="bold"><span class="kobospan" id="kobo.109.1">vertex-based centrality metric</span></strong><span class="kobospan" id="kobo.110.1">, which we </span><a id="_idIndexMarker277" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.111.1">encountered in </span><a href="B21087_05.xhtml#_idTextAnchor066" class="pcalibre calibre6 pcalibre1"><span><em class="italic"><span class="kobospan" id="kobo.112.1">Chapter 5</span></em></span></a><span class="kobospan" id="kobo.113.1">. </span><strong class="bold"><span class="kobospan" id="kobo.114.1">Degree centrality</span></strong><span class="kobospan" id="kobo.115.1"> is simply the number of vertices directly connected to the</span><a id="_idIndexMarker278" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.116.1"> vertex of interest. </span><span class="kobospan" id="kobo.116.2">Many Laplacian-based metrics or algorithms depend on the degree matrix within algorithm calculations. </span><span class="kobospan" id="kobo.116.3">On the surface, this metric seems to capture important hub properties; a vertex with a high degree centrality will carry a lot of influence within the network (and, thus, might make a good intervention target). </span><span class="kobospan" id="kobo.116.4">It also scales well to very large networks. </span><span class="kobospan" id="kobo.116.5">However, one limitation of degree centrality is its lack of awareness of a vertex’s position beyond any immediate connections to neighbors; a vertex with a low degree centrality may be connected to many vertices with a high degree centrality, giving it more influence over network behavior and structure than its degree </span><span><span class="kobospan" id="kobo.117.1">centrality suggests.</span></span></p>
<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.118.1">Eigenvector centrality</span></strong><span class="kobospan" id="kobo.119.1"> and its </span><a id="_idIndexMarker279" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.120.1">variants (including </span><strong class="bold"><span class="kobospan" id="kobo.121.1">PageRank</span></strong><span class="kobospan" id="kobo.122.1"> and </span><strong class="bold"><span class="kobospan" id="kobo.123.1">Katz centrality</span></strong><span class="kobospan" id="kobo.124.1">) incorporate </span><a id="_idIndexMarker280" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.125.1">awareness about connectivity beyond immediate</span><a id="_idIndexMarker281" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.126.1"> neighbors to give a more comprehensive vertex-based centrality metric. </span><span class="kobospan" id="kobo.126.2">Thus, </span><strong class="bold"><span class="kobospan" id="kobo.127.1">eigenvector centrality</span></strong><span class="kobospan" id="kobo.128.1"> would score our hypothetical low-degree centrality vertex connected to high-degree centrality vertices highly, as that vertex is near very connected vertices. </span><span class="kobospan" id="kobo.128.2">Technically, to find the eigenvector centrality of each vertex in a network, we can perform an eigen decomposition on the adjacency matrix. </span><span class="kobospan" id="kobo.128.3">Because the adjacency matrix does not include negative values, we can assume that the first eigenvalue is the largest, and its eigenvector yields the eigenvector centrality scores for </span><span><span class="kobospan" id="kobo.129.1">our vertices.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.130.1">PageRank centrality</span><a id="_idIndexMarker282" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.131.1"> extends eigenvector centrality</span><a id="_idIndexMarker283" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.132.1"> and increases its flexibility by replacing the adjacency matrix with an adjusted adjacency matrix that is constructed by performing a random walk across vertices to determine the adjacency properties. </span><span class="kobospan" id="kobo.132.2">In addition, random surfer properties, where a random walk can cross the unconnected areas of a graph with a low probability, create an adjusted adjacency matrix that is connected. </span><span class="kobospan" id="kobo.132.3">This adjusted adjacency matrix is then scaled</span><a id="_idIndexMarker284" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.133.1"> before performing the eigen decomposition on the adjusted adjacency matrix, which is carried out to compute eigenvector centrality scores. </span><span class="kobospan" id="kobo.133.2">PageRank centrality scores, thus, provide flexibility. </span><span class="kobospan" id="kobo.133.3">In addition, this computation is typically easier and faster with the adjusted adjacency matrix, allowing the algorithm to scale well to networks of even hundreds of millions </span><span><span class="kobospan" id="kobo.134.1">of vertices.</span></span></p>
<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.135.1">Edge-based centrality measures</span></strong><span class="kobospan" id="kobo.136.1"> capture </span><a id="_idIndexMarker285" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.137.1">network infrastructure that is important for spreading processes and connectivity across different hubs. </span><strong class="bold"><span class="kobospan" id="kobo.138.1">Betweenness centrality</span></strong><span class="kobospan" id="kobo.139.1"> is</span><a id="_idIndexMarker286" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.140.1"> one of the most common edge-based centrality metrics, capturing the relative number of shortest paths that include a given vertex among all shortest paths that exist in the network. </span><span class="kobospan" id="kobo.140.2">Consider a network with 10 shortest paths, 8 of which include a particular vertex. </span><span class="kobospan" id="kobo.140.3">Without this vertex, many of the shortest paths would not exist, inconveniencing the network greatly in terms of spreading processes on a social network or route efficiency on a transportation network. </span><span class="kobospan" id="kobo.140.4">However, betweenness centrality does not scale well, and it should not be used on large networks without some sort of parallelization of </span><span><span class="kobospan" id="kobo.141.1">the operation.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.142.1">One recent edge-based centrality network has proven to be an efficient tool for finding stock market tipping points. </span><strong class="bold"><span class="kobospan" id="kobo.143.1">Forman–Ricci curvature</span></strong><span class="kobospan" id="kobo.144.1"> is </span><a id="_idIndexMarker287" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.145.1">a geometry-based tool that considers adjacent edges in relation to an edge of interest. </span><span class="kobospan" id="kobo.145.2">On an unweighted network, Forman–Ricci curvature is calculated by subtracting the degree centrality of the two vertices attached to an edge of interest from 2. </span><span class="kobospan" id="kobo.145.3">The constant, 2, represents the connection between the two vertices connected by the edge of interest. </span><span class="kobospan" id="kobo.145.4">The degree centrality of both vertices connected by the edge counts the number of adjacent edges to our edge of interest (minus the vertices connected by that edge, whereby we obtain our constant of 2). </span><span class="kobospan" id="kobo.145.5">In </span><em class="italic"><span class="kobospan" id="kobo.146.1">Figures 6–3</span></em><span class="kobospan" id="kobo.147.1">, we see three vertices: two vertices with a single edge in relation to the middle vertex (both with a degree centrality of 1) and a middle vertex connecting to both of the outer vertices (with a degree centrality of 2). </span><span class="kobospan" id="kobo.147.2">Both edges, thus, have a Forman–Ricci curvature of -1, as the sum of the vertex degree</span><a id="_idIndexMarker288" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.148.1"> centralities for both is 3 (2 - 3 = -</span><span><span class="kobospan" id="kobo.149.1">1).</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer078">
<span class="kobospan" id="kobo.150.1"><img alt="Figure 6.3 – An example network demonstrating Forman–Ricci curvature, where the middle vertex is pulled from both the first and third outer vertices" src="image/B21087_06_03.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.151.1">Figure 6.3 – An example network demonstrating Forman–Ricci curvature, where the middle vertex is pulled from both the first and third outer vertices</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.152.1">To obtain vertex centrality metrics from this edge metric, we can sum the edge metrics for each vertex to score the vertices. </span><span class="kobospan" id="kobo.152.2">In our example in </span><span><em class="italic"><span class="kobospan" id="kobo.153.1">Figure 6</span></em></span><em class="italic"><span class="kobospan" id="kobo.154.1">.3</span></em><span class="kobospan" id="kobo.155.1">, we have outer vertices with a Forman–Ricci vertex</span><a id="_idIndexMarker289" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.156.1"> centrality of -1, as both only connect to a single edge. </span><span class="kobospan" id="kobo.156.2">However, the middle vertex connects to two edges, with a Forman–Ricci curvature of -1, giving it a Forman–Ricci vertex centrality of -2. </span><span class="kobospan" id="kobo.156.3">Because this centrality metric relies on low-cost computations, it scales well to large networks and can be used as an alternative edge-based centrality score when betweenness centrality is </span><span><span class="kobospan" id="kobo.157.1">not feasible.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.158.1">Now, let’s explore some stock market data and see how network science can help us identify key trends </span><span><span class="kobospan" id="kobo.159.1">over time.</span></span></p>
<h1 id="_idParaDest-84" class="calibre5"><a id="_idTextAnchor084" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.160.1">Application of centrality metrics across time slices</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.161.1">The NASDAQ stock</span><a id="_idIndexMarker290" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.162.1"> market is an American stock exchange in New York City that includes publicly traded companies such as Apple, Alphabet, Nvidia, and Microsoft. </span><span class="kobospan" id="kobo.162.2">Kaggle provides a full history of NASDAQ stock prices under a public license (</span><a href="https://www.kaggle.com/datasets/jacksoncrow/stock-market-dataset?resource=download" class="pcalibre calibre6 pcalibre1"><span class="kobospan" id="kobo.163.1">https://www.kaggle.com/datasets/jacksoncrow/stock-market-dataset?resource=download</span></a><span class="kobospan" id="kobo.164.1">) that can give us stock data for these four tech companies during the period in which they were all publicly traded up to April 1, 2020. </span><span class="kobospan" id="kobo.164.2">We’ve munged the data for you to include only these four stocks in the period from August 19, 2004, to April 1, 2020. </span><span class="kobospan" id="kobo.164.3">Let’s take a peek at these data to see what trends might exist (</span><span><em class="italic"><span class="kobospan" id="kobo.165.1">Figure 6</span></em></span><span><em class="italic"><span class="kobospan" id="kobo.166.1">.4</span></em></span><span><span class="kobospan" id="kobo.167.1">):</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer079">
<span class="kobospan" id="kobo.168.1"><img alt="Figure 6.4 – NASDAQ selected stock closing values from August 19, 2004, to April 1, 2020" src="image/B21087_06_04.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.169.1">Figure 6.4 – NASDAQ selected stock closing values from August 19, 2004, to April 1, 2020</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.170.1">In </span><span><em class="italic"><span class="kobospan" id="kobo.171.1">Figure 6</span></em></span><em class="italic"><span class="kobospan" id="kobo.172.1">.4</span></em><span class="kobospan" id="kobo.173.1">, we can see that Alphabet has a consistently higher price, but all stocks exhibit the typical trends of constant pricing, dips, spikes, and upward or downward trends over this long period of trading. </span><span class="kobospan" id="kobo.173.2">Of note is the 2020 trend, where stocks experienced the COVID-19 crash. </span><span class="kobospan" id="kobo.173.3">Periods of volatility include 2008–2009 </span><span><span class="kobospan" id="kobo.174.1">and 2016–2020.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.175.1">One of the important </span><a id="_idIndexMarker291" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.176.1">aspects of time series analysis is </span><strong class="bold"><span class="kobospan" id="kobo.177.1">windowing</span></strong><span class="kobospan" id="kobo.178.1"> the </span><a id="_idIndexMarker292" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.179.1">time series data into overlapping pieces. </span><span class="kobospan" id="kobo.179.2">While windowing can be optimized by using a grid search, windowing tends to be more of an art than a science. </span><span class="kobospan" id="kobo.179.3">Choosing a window impacts the length of time in which trends can be captured. </span><span class="kobospan" id="kobo.179.4">In our stock market data, window length limits the period in which we can search for trends and, thus, limits the time period after the last window in which we can forecast market behavior. </span><span class="kobospan" id="kobo.179.5">A window that is too large can miss important trends that impact short-term market behavior. </span><span class="kobospan" id="kobo.179.6">A window that is too small can limit forecasting to the </span><span><span class="kobospan" id="kobo.180.1">immediate future.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.181.1">We’ll choose a window of 5 trading days or roughly a week’s worth of stock data. </span><span class="kobospan" id="kobo.181.2">This allows us to capture trends relevant to day trading, where stocks are traded frequently based on volatility. </span><span class="kobospan" id="kobo.181.3">Our network metrics should work well for volatility-based trading for quick gains, as they capture increasing correlations across the </span><span><span class="kobospan" id="kobo.182.1">two stocks.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.183.1">Another aspect that is important to windowing time series data is the choice of overlap. </span><span class="kobospan" id="kobo.183.2">For our example, we’ll choose maximal overlap (4 days’ overlap) to maximize our sensitivity to day-to-day trends. </span><span class="kobospan" id="kobo.183.3">In other applications, less overlap may be desirable to investigate longer time trends. </span><span class="kobospan" id="kobo.183.4">Note that our example uses a path on one of our machines. </span><span class="kobospan" id="kobo.183.5">Your file path will be different </span><span><span class="kobospan" id="kobo.184.1">from ours.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.185.1">Let’s import our packages and load our data into Python with </span><strong class="source-inline"><span class="kobospan" id="kobo.186.1">Script 6.1</span></strong><span class="kobospan" id="kobo.187.1"> to </span><span><span class="kobospan" id="kobo.188.1">get started:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.189.1">
#import packages
import igraph as ig
from igraph import Graph
import numpy as np
import pandas as pd
import os
import matplotlib as plt
#import stock data
File="C:/users/njfar/OneDrive/Desktop/AAPL_GOOGL_Stock_2004_2020.csv"
pwd=os.getcwd()
os.chdir(os.path.dirname(File))
mydata=pd.read_csv(os.path.basename(File),encoding='latin1')</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.190.1">Now that we have our data</span><a id="_idIndexMarker293" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.191.1"> imported, we can add a loop that windows our time series to 5-day periods that overlap by 4 days across slices. </span><span class="kobospan" id="kobo.191.2">This window strategy yields the best chance to find daily changes in trends. </span><span class="kobospan" id="kobo.191.3">We’ll then create correlations among the four stocks within that time slice, threshold those correlations to limit our analysis to high correlations, create an unweighted network from those thresholds, and analyze Pagerank centrality, degree centrality, betweenness centrality, and Forman–Ricci curvature centrality across the time slices. </span><span class="kobospan" id="kobo.191.4">We’ll also save each unweighted network for future retrieval, as well as the network metrics and their averages over each time slice. </span><span class="kobospan" id="kobo.191.5">Let’s add these pieces to </span><span><strong class="source-inline"><span class="kobospan" id="kobo.192.1">Script 6.1</span></strong></span><span><span class="kobospan" id="kobo.193.1">:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.194.1">
#script to create time slices, derive networks,
#and compute centrality metrics
stock_networks=[]
bet_t=[]
deg_t=[]
eig_t=[]
vcurv_t=[]
bet_ave=[]
deg_ave=[]
eig_ave=[]
vcurv_ave=[]
for Date in range(5,3932):
    #wrangle data into graph
    data=mydata.iloc[(Date-5):(Date),1:5]
    cor=np.corrcoef(data.transpose())
    cor[cor&gt;=0.5]=1
    cor[cor&lt;0.5]=0
    stock_data=Graph.Adjacency(cor)
    stock_networks.append(stock_data)
    #derive some centrality metrics
    d=Graph.degree(stock_data)
    deg_t.append(d)
    deg_ave.append(np.mean(d))
    b=Graph.betweenness(stock_data)
    bet_t.append(b)
    bet_ave.append(np.mean(b))
    e=Graph.pagerank(stock_data)
    eig_t.append(e)
    eig_ave.append(np.mean(e))
    #create Forman–Ricci curvature calculations
    ecurvw=[]
    for edge in stock_data.es:
        s=edge.source
        t=edge.target
        ecurvw.append(2-d[s]-d[t])
    vcurvw=[]
    for vertex in stock_data.vs:
        inc=Graph.incident(stock_data,vertex)
        inc_curv=[]
        for i in inc:
            inc_curv.append(ecurvw[i])
        vcurvw.append(sum(inc_curv))
    vcurv_t.append(vcurvw)
    vcurv_ave.append(np.mean(vcurvw))</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.195.1">This script should run quickly on your machine. </span><span class="kobospan" id="kobo.195.2">If you include a very large number of stocks in your analyses, you may wish to run the script in parallel to save time or exclude betweenness centrality, as betweenness centrality does not scale well as the number of </span><span><span class="kobospan" id="kobo.196.1">vertices increases.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.197.1">Now that we</span><a id="_idIndexMarker294" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.198.1"> have computed our metrics, let’s examine the correlations between the metrics across our set of time series windows to see how the different metrics relate to each other. </span><span class="kobospan" id="kobo.198.2">Given that Forman–Ricci curvature depends on degree centrality metrics, we’d expect to see a strong correlation. </span><span class="kobospan" id="kobo.198.3">We can add to </span><strong class="source-inline"><span class="kobospan" id="kobo.199.1">Script 6.1</span></strong><span class="kobospan" id="kobo.200.1"> to obtain </span><span><span class="kobospan" id="kobo.201.1">these correlations:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.202.1">
#examine correlations among metrics across the time series
print(np.corrcoef(deg_ave,eig_ave))
print(np.corrcoef(deg_ave,bet_ave))
print(np.corrcoef(deg_ave,vcurv_ave))
print(np.corrcoef(eig_ave,bet_ave))
print(np.corrcoef(eig_ave,vcurv_ave))
print(np.corrcoef(bet_ave,vcurv_ave))</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.203.1">You should see a strong correlation between degree centrality and Forman–Ricci curvature centrality (-0.99 in our analysis) but fairly weak correlations among the other centrality metrics (-0.05 for degree and Pagerank centralities, 0.01 for degree and betweenness centralities, 0.04 for Pagerank and betweenness centralities, 0.04 for Pagerank and Forman–Ricci curvature centrality, and 0.05 for betweenness and Forman–Ricci curvature centrality). </span><span class="kobospan" id="kobo.203.2">This suggests that degree centrality and Forman–Ricci curvature may be interchangeable in these analyses, though a more complex Forman–Ricci curvature metric may capture a bit more information that may be relevant to certain trends. </span><span class="kobospan" id="kobo.203.3">It’s unclear if these correlations would hold for other datasets, though degree centrality and Forman–Ricci curvature on unweighted networks will correlate to some extent, given that the</span><a id="_idIndexMarker295" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.204.1"> Forman–Ricci curvature formula depends on </span><span><span class="kobospan" id="kobo.205.1">degree centrality.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.206.1">Let’s visualize the network metric trends over time to see if any patterns emerge or extreme values stand out that might indicate behavior changes in our stock pricing. </span><span class="kobospan" id="kobo.206.2">We’ll add visualization code to </span><strong class="source-inline"><span class="kobospan" id="kobo.207.1">Script 6.1</span></strong><span class="kobospan" id="kobo.208.1"> to </span><span><span class="kobospan" id="kobo.209.1">do this:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.210.1">
#plot metric averages across time slices
time=range(0,3927)
plt.plot(time, deg_ave, label = "Degree Average")
plt.plot(time, eig_ave, label = "Pagerank Average")
plt.plot(time, bet_ave, label = "Betweenness Average")
plt.plot(time, vcurv_ave, label = "Forman–Ricci Curvature Average")
plt.legend()
plt.show()</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.211.1">This should give you a plot similar to </span><span><em class="italic"><span class="kobospan" id="kobo.212.1">Figure 6</span></em></span><span><em class="italic"><span class="kobospan" id="kobo.213.1">.5</span></em></span><span><span class="kobospan" id="kobo.214.1">:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer080">
<span class="kobospan" id="kobo.215.1"><img alt="Figure 6.5 – A plot of centrality averages across time slices for our stock market data" src="image/B21087_06_05.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.216.1">Figure 6.5 – A plot of centrality averages across time slices for our stock market data</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.217.1">Note that Pagerank centrality</span><a id="_idIndexMarker296" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.218.1"> does not show up in our plot. </span><span class="kobospan" id="kobo.218.2">Pagerank and betweenness centrality fill a similar range of values, masking Pagerank centrality in our plot. </span><span class="kobospan" id="kobo.218.3">However, we do see that differences in the average centrality values emerge regularly in our plot, suggesting that our centrality values may be capturing different states of the market </span><span><span class="kobospan" id="kobo.219.1">over time.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.220.1">Our Forman–Ricci curvature centrality averages suggest periods of relative stability in the market, where the values are near zero. </span><span class="kobospan" id="kobo.220.2">Two prominent periods of relative stability occur at the start of our time series (roughly 2004–2006) and again in the mid-to-late 2010s. </span><span class="kobospan" id="kobo.220.3">However, as we approach 2008 and 2020, the correlations among our stocks increase considerably before two major </span><span><span class="kobospan" id="kobo.221.1">market crashes.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.222.1">It’s probable that our choice of threshold value influences our results. </span><span class="kobospan" id="kobo.222.2">To hone in on periods of tight coupling in terms of stock behavior, let’s raise our threshold value to </span><strong class="source-inline"><span class="kobospan" id="kobo.223.1">0.9</span></strong><span class="kobospan" id="kobo.224.1"> and rerun </span><span><strong class="source-inline"><span class="kobospan" id="kobo.225.1">Script 6.1</span></strong></span><span><span class="kobospan" id="kobo.226.1">:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.227.1">
#script to create time slices, derive networks,
#and compute centrality metrics
stock_networks=[]
bet_t=[]
deg_t=[]
eig_t=[]
vcurv_t=[]
bet_ave=[]
deg_ave=[]
eig_ave=[]
vcurv_ave=[]
for Date in range(5,3932):
    #wrangle data into graph
    data=mydata.iloc[(Date-5):(Date),1:5]
    cor=np.corrcoef(data.transpose())
    cor[cor&gt;=0.9]=1
    cor[cor&lt;0.9]=0
    stock_data=Graph.Adjacency(cor)
    stock_networks.append(stock_data)
    #derive some centrality metrics
    d=Graph.degree(stock_data)
    deg_t.append(d)
    deg_ave.append(np.mean(d))
    b=Graph.betweenness(stock_data)
    bet_t.append(b)
    bet_ave.append(np.mean(b))
    e=Graph.pagerank(stock_data)
    eig_t.append(e)
    eig_ave.append(np.mean(e))
    #create Forman–Ricci curvature calculations
    ecurvw=[]
    for edge in stock_data.es:
        s=edge.source
        t=edge.target
        ecurvw.append(2-d[s]-d[t])
    vcurvw=[]
    for vertex in stock_data.vs:
        inc=Graph.incident(stock_data,vertex)
        inc_curv=[]
        for i in inc:
            inc_curv.append(ecurvw[i])
        vcurvw.append(sum(inc_curv))
    vcurv_t.append(vcurvw)
    vcurv_ave.append(np.mean(vcurvw))</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.228.1">Now, we can rerun our correlation analysis to understand how threshold value might influence any </span><a id="_idIndexMarker297" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.229.1">correlations among the metrics. </span><span class="kobospan" id="kobo.229.2">Let’s rerun our correlation analysis in </span><span><strong class="source-inline"><span class="kobospan" id="kobo.230.1">Script 6.1</span></strong></span><span><span class="kobospan" id="kobo.231.1">:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.232.1">
#examine correlations among metrics across the time series
print(np.corrcoef(deg_ave,eig_ave))
print(np.corrcoef(deg_ave,bet_ave))
print(np.corrcoef(deg_ave,vcurv_ave))
print(np.corrcoef(eig_ave,bet_ave))
print(np.corrcoef(eig_ave,vcurv_ave))
print(np.corrcoef(bet_ave,vcurv_ave))</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.233.1">You should see some notable differences compared to our prior results with this new threshold. </span><span class="kobospan" id="kobo.233.2">The degree and Pagerank centralities are still not correlated very much (-0.04), which is mirrored by the correlations between Pagerank centrality and betweenness centrality (0.003) and Pagerank and Forman–Ricci curvature centrality (0.04). </span><span class="kobospan" id="kobo.233.3">However, degree and betweenness centrality are moderately correlated now (0.44), as are betweenness and Forman–Ricci curvature centrality (-0.39). </span><span class="kobospan" id="kobo.233.4">The degree and Forman–Ricci curvature centralities are still highly correlated, though slightly less than in our prior </span><span><span class="kobospan" id="kobo.234.1">threshold (-0.98).</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.235.1">Let’s plot our new</span><a id="_idIndexMarker298" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.236.1"> results to investigate any trends that may have been masked with a low threshold value in our initial analysis. </span><span class="kobospan" id="kobo.236.2">We can replot this using </span><span><strong class="source-inline"><span class="kobospan" id="kobo.237.1">Script 6.1</span></strong></span><span><span class="kobospan" id="kobo.238.1">:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.239.1">
#plot metric averages across time slices
time=range(0,3927)
plt.plot(time, deg_ave, label = "Degree Average")
plt.plot(time, eig_ave, label = "Pagerank Average")
plt.plot(time, bet_ave, label = "Betweenness Average")
plt.plot(time, vcurv_ave, label = "Forman–Ricci Curvature Average")
plt.legend()
plt.show()</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.240.1">This should yield a plot that looks very different from </span><span><em class="italic"><span class="kobospan" id="kobo.241.1">Figure 6</span></em></span><em class="italic"><span class="kobospan" id="kobo.242.1">.5</span></em><span class="kobospan" id="kobo.243.1">. </span><span class="kobospan" id="kobo.243.2">In </span><span><em class="italic"><span class="kobospan" id="kobo.244.1">Figure 6</span></em></span><em class="italic"><span class="kobospan" id="kobo.245.1">.6</span></em><span class="kobospan" id="kobo.246.1">, we can see the periods of volatility much more clearly than we could in </span><span><em class="italic"><span class="kobospan" id="kobo.247.1">Figure 6</span></em></span><span><em class="italic"><span class="kobospan" id="kobo.248.1">.5</span></em></span><span><span class="kobospan" id="kobo.249.1">:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer081">
<span class="kobospan" id="kobo.250.1"><img alt="Figure 6.6 – A plot of network centrality metrics across time slices with a 0.9 threshold" src="image/B21087_06_06.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.251.1">Figure 6.6 – A plot of network centrality metrics across time slices with a 0.9 threshold</span></p>
<p class="calibre3"><span><em class="italic"><span class="kobospan" id="kobo.252.1">Figure 6</span></em></span><em class="italic"><span class="kobospan" id="kobo.253.1">.6</span></em><span class="kobospan" id="kobo.254.1"> shows many more </span><a id="_idIndexMarker299" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.255.1">Forman–Ricci curvature values that are near 0, suggesting less volatility in the market during those time periods. </span><span class="kobospan" id="kobo.255.2">We see a few periods of increasing volatility (more extreme Forman–Ricci curvature values) in the form of dips in our plot. </span><span class="kobospan" id="kobo.255.3">Those periods of intense volatility and coupling precede the crashes in 2008 and 2020, as well as periods of quick rebuilding after crashes. </span><span class="kobospan" id="kobo.255.4">These are periods of interest for investors, as large sums of money are either lost or gained during </span><span><span class="kobospan" id="kobo.256.1">those periods.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.257.1">In general, network metrics seem to pick up on market volatility very well, particularly when high thresholds are applied to the data. </span><span class="kobospan" id="kobo.257.2">This suggests what has been stated in the recent literature: network metrics are useful tools to identify market volatility before crashes and exponential growth. </span><span class="kobospan" id="kobo.257.3">In fact, these tools picked up growing market volatility long before the COVID crash of 2020, which could have saved gains in the months leading up to 2020 had investors heeded the volatility warnings and pulled out before trouble hit the market. </span><span class="kobospan" id="kobo.257.4">Given the volatility and long period of steep growth, it’s likely that any number of factors would have caused a major crash. </span><span class="kobospan" id="kobo.257.5">A large-scale or badly placed regional conflict, a breakdown in the supply chain, or a change in policy within the technology sector probably would have produced a </span><span><span class="kobospan" id="kobo.258.1">major crash.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.259.1">Returning to </span><span><em class="italic"><span class="kobospan" id="kobo.260.1">Figure 6</span></em></span><em class="italic"><span class="kobospan" id="kobo.261.1">.7</span></em><span class="kobospan" id="kobo.262.1">, we</span><a id="_idIndexMarker300" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.263.1"> observe very different trends before the 2008 crash than the 2020 crash. </span><span class="kobospan" id="kobo.263.2">While 2020 was preceded by a long period of growth with recent small crashes, 2008 was preceded by relative stability and slow growth. </span><span class="kobospan" id="kobo.263.3">Given the increasing volatility and accelerated growth of stock prices for these four NASDAQ stocks, these trends make the market more vulnerable to large crashes in the future, and should the trends hold across other NASDAQ sectors, then we’d expect less certainty and more opportunities for large gains and losses in the </span><span><span class="kobospan" id="kobo.264.1">near future.</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer082">
<span class="kobospan" id="kobo.265.1"><img alt="Figure 6.7 – Returning to the plot of the stock data" src="image/B21087_06_07.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.266.1">Figure 6.7 – Returning to the plot of the stock data</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.267.1">Given these trends in the market, network science tools are poised to play a critical role in stock market analytics. </span><span class="kobospan" id="kobo.267.2">Relatively little work exists in terms of the application of these tools to stock market data or time series data more generally, and few centrality metrics have been studied systematically. </span><span class="kobospan" id="kobo.267.3">Much of the existing research on the application of centrality metrics to understand stock market trends over time involves extensions of networks to include multi-way relationships. </span><span class="kobospan" id="kobo.267.4">Let’s now turn our attention to an extension of </span><a id="_idIndexMarker301" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.268.1">applying networks to the relationships that exist among more than </span><span><span class="kobospan" id="kobo.269.1">two entities.</span></span></p>
<h1 id="_idParaDest-85" class="calibre5"><a id="_idTextAnchor085" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.270.1">Extending network metrics for time series analytics</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.271.1">Because networks</span><a id="_idIndexMarker302" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.272.1"> are topological objects and </span><a id="_idIndexMarker303" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.273.1">because our correlation matrix can use a threshold of any value, it is possible to extend network metrics to the realm of topological data analysis. </span><span class="kobospan" id="kobo.273.2">Networks capture the two-way relationships between entities. </span><span class="kobospan" id="kobo.273.3">However, three-way, four-way, and even larger-way interactions can exist, as well. </span><strong class="bold"><span class="kobospan" id="kobo.274.1">Simplicial complexes</span></strong><span class="kobospan" id="kobo.275.1"> extend </span><a id="_idIndexMarker304" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.276.1">the idea of networks to capture these higher-numbered interactions. </span><span class="kobospan" id="kobo.276.2">Three-way interactions are represented as faces (or triangles) outlined by two-way lines. </span><span class="kobospan" id="kobo.276.3">Four-way interactions are represented as tetrahedra, comprised of three-way faces that have four-way interactions. </span><span class="kobospan" id="kobo.276.4">This process can continue to any value of mutual interactions, where the lower-dimensional interactions form the boundaries of the higher-dimensional interactions. </span><span class="kobospan" id="kobo.276.5">A simplicial complex collects the highest-level interactions that exist among vertices into a single object. </span><span><em class="italic"><span class="kobospan" id="kobo.277.1">Figure 6</span></em></span><em class="italic"><span class="kobospan" id="kobo.278.1">.8</span></em><span class="kobospan" id="kobo.279.1"> shows an example of a three-way interaction bounded by mutual, </span><span><span class="kobospan" id="kobo.280.1">two-way interactions:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer083">
<span class="kobospan" id="kobo.281.1"><img alt="Figure 6.8 – A diagram showing how a three-way interaction is defined by mutual, two-way interactions" src="image/B21087_06_08.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.282.1">Figure 6.8 – A diagram showing how a three-way interaction is defined by mutual, two-way interactions</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.283.1">Just as networks can be weighted or unweighted, simplicial complexes can be weighted or unweighted across </span><em class="italic"><span class="kobospan" id="kobo.284.1">n</span></em><span class="kobospan" id="kobo.285.1">-way interactions within the simplicial complex. </span><span class="kobospan" id="kobo.285.2">In addition, just as networks are constructed from an adjacency matrix, so simplicial complexes are created from adjacency matrices at each level of </span><em class="italic"><span class="kobospan" id="kobo.286.1">n</span></em><span class="kobospan" id="kobo.287.1">-way interactions (technically the boundary matrices). </span><span class="kobospan" id="kobo.287.2">Just as we typically need to construct an adjacency matrix to create a network from raw data, we can use raw data to define the </span><em class="italic"><span class="kobospan" id="kobo.288.1">n</span></em><span class="kobospan" id="kobo.289.1">-way interactions existing in </span><span><span class="kobospan" id="kobo.290.1">that data.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.291.1">First, a </span><a id="_idIndexMarker305" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.292.1">relationship metric must be</span><a id="_idIndexMarker306" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.293.1"> defined for the raw data. </span><span class="kobospan" id="kobo.293.2">In our stock dataset, we chose correlation metrics. </span><span class="kobospan" id="kobo.293.3">Distance metrics are also commonly used when constructing both networks and simplicial complexes, and many, many distance metrics can be defined for continuous or discrete measurements on a dataset. </span><span class="kobospan" id="kobo.293.4">Once a metric is defined, a threshold or series of thresholds are applied to the metric matrix to define the relationships within a given radius of each other (defined by the threshold). </span><span class="kobospan" id="kobo.293.5">Two main options exist for constructing the simplicial complex and </span><span><span class="kobospan" id="kobo.294.1">its relationships:</span></span></p>
<ul class="calibre10">
<li class="calibre11"><span class="kobospan" id="kobo.295.1">Defining the </span><em class="italic"><span class="kobospan" id="kobo.296.1">n</span></em><span class="kobospan" id="kobo.297.1">-way relationships through the union of points, the radii of which touch (called </span><a id="_idIndexMarker307" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.298.1">a </span><span><strong class="bold"><span class="kobospan" id="kobo.299.1">Vietoris–Rips complex</span></strong></span><span><span class="kobospan" id="kobo.300.1">)</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.301.1">Counting the connection points, which involves the mutual overlap of points within a given radius, where all connected points must lie within each other’s radius (called </span><a id="_idIndexMarker308" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.302.1">a </span><span><strong class="bold"><span class="kobospan" id="kobo.303.1">Čech complex</span></strong></span><span><span class="kobospan" id="kobo.304.1">)</span></span></li>
</ul>
<p class="calibre3"><span class="kobospan" id="kobo.305.1">The </span><strong class="bold"><span class="kobospan" id="kobo.306.1">filtration</span></strong><span class="kobospan" id="kobo.307.1"> of </span><a id="_idIndexMarker309" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.308.1">simplicial complexes involves varying the radius by different metric thresholds. </span><span class="kobospan" id="kobo.308.2">Remember how applying different correlation thresholds produced different results and insights for our stock market dataset? </span><span class="kobospan" id="kobo.308.3">Different filtration levels of simplicial complexes can produce different simplicial complexes at each filtration level with different properties that may contain important information for </span><span><span class="kobospan" id="kobo.309.1">an analyst.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.310.1">Let’s create a function that defines the Vietoris–Rips simplicial complex for two-way interactions (corresponding to a network) using </span><span><strong class="source-inline"><span class="kobospan" id="kobo.311.1">Script 6.2</span></strong></span><span><span class="kobospan" id="kobo.312.1">:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.313.1">
#define Vietoris–Rips complex
from itertools import combinations
from numpy import linalg as LA
def graph_VR(points, eps):
    points=[np.array(x) for x in points]
    vr=[(x,y) for (x,y) in combinations(points, 2)
    if LA.norm(x - y) &lt;= 2*eps]
    return np.array(vr)</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.314.1">Now, we can apply this to the first slice of our stock market time series data. </span><span class="kobospan" id="kobo.314.2">We’ll choose thresholds of 1 and 10 as a starting point to understand which vertex pairs will be included in our simplicial complex (here, only at the two-way interaction level). </span><span class="kobospan" id="kobo.314.3">Let’s add this to </span><strong class="source-inline"><span class="kobospan" id="kobo.315.1">Script 6.2</span></strong><span class="kobospan" id="kobo.316.1"> to calculate the Vietoris–Rips simplicial complex for the first slice of our stock market time </span><span><span class="kobospan" id="kobo.317.1">series data:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.318.1">
#apply Vietoris–Rips with multiple thresholds to a slice of our stock #dataset
data=mydata.iloc[0:5,1:5]
vr1=graph_VR(data.transpose(),1)
vr2=graph_VR(data.transpose(),10)</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.319.1">We can examine</span><a id="_idIndexMarker310" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.320.1"> the vertex pairs included in </span><a id="_idIndexMarker311" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.321.1">each filtration by adding the following to </span><span><strong class="source-inline"><span class="kobospan" id="kobo.322.1">Script 6.2</span></strong></span><span><span class="kobospan" id="kobo.323.1">:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.324.1">
#print the results
print("Vietoris–Rips Complex, Threshold=1:")
print(vr1)
print("Vietoris–Rips Complex, Threshold=10:")
print(vr2)</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.325.1">This gives us pairs of vertices for each filtration, which should show </span><span><span class="kobospan" id="kobo.326.1">the following:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.327.1">
Vietoris–Rips Complex, Threshold=1:
[[0 1]
 [0 2]
 [1 2]
 [1 3]
 [2 3]
 [2 4]
 [3 4]]
Vietoris–Rips Complex, Threshold=10:
[[0 1]
 [0 2]
 [0 3]
 [0 4]
 [1 2]
 [1 3]
 [1 4]
 [2 3]
 [2 4]
 [3 4]]</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.328.1">We can visualize </span><a id="_idIndexMarker312" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.329.1">the threshold = 1 complex </span><a id="_idIndexMarker313" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.330.1">with two-way interactions by adding the following to </span><span><strong class="source-inline"><span class="kobospan" id="kobo.331.1">Script 6.2</span></strong></span><span><span class="kobospan" id="kobo.332.1">:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.333.1">
edges1 = [(0,1),(0,2),(1,2),(1,3),(2,3),(2,4), (3,4)]
import networkx as nx
G1 = nx.Graph()
G1.add_edges_from(edges1)
nx.draw(G1,with_labels=True)</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.334.1">This gives a figure similar to the one in </span><span><em class="italic"><span class="kobospan" id="kobo.335.1">Figure 6</span></em></span><em class="italic"><span class="kobospan" id="kobo.336.1">.9</span></em><span class="kobospan" id="kobo.337.1">, showing a set of three triangles connected by </span><span><span class="kobospan" id="kobo.338.1">two-way interactions:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer084">
<span class="kobospan" id="kobo.339.1"><img alt="Figure 6.9 – A visualization of the threshold = 1 results for two-way interactions" src="image/B21087_06_09.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.340.1">Figure 6.9 – A visualization of the threshold = 1 results for two-way interactions</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.341.1">Similarly, we can </span><a id="_idIndexMarker314" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.342.1">visualize our threshold = 10 </span><a id="_idIndexMarker315" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.343.1">results by adding the following to </span><span><strong class="source-inline"><span class="kobospan" id="kobo.344.1">Script 6.2</span></strong></span><span><span class="kobospan" id="kobo.345.1">:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.346.1">
edges10 = [(0,1),(0,2),(0,3),(0,4),(1,2),(1,3),(1,4),(2,3),(2,4),(3,4)]
import networkx as nx
G10 = nx.Graph()
G10.add_edges_from(edges10)
nx.draw(G10,with_labels=True)</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.347.1">This should give a plot similar to </span><span><em class="italic"><span class="kobospan" id="kobo.348.1">Figure 6</span></em></span><em class="italic"><span class="kobospan" id="kobo.349.1">.10</span></em><span class="kobospan" id="kobo.350.1">, which shows a more complex connectivity than the threshold = </span><span><span class="kobospan" id="kobo.351.1">1 results:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer085">
<span class="kobospan" id="kobo.352.1"><img alt="Figure 6.10 – A visualization of the threshold = 10 results for two-way interactions" src="image/B21087_06_10.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.353.1">Figure 6.10 – A visualization of the threshold = 10 results for two-way interactions</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.354.1">These results</span><a id="_idIndexMarker316" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.355.1"> show that different radius </span><a id="_idIndexMarker317" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.356.1">thresholds yield different networks, just as our correlation thresholds produced different networks. </span><span class="kobospan" id="kobo.356.2">We could build a full filtration from the first appearance of an edge until all possible edges exist in our network to track changes in network structure based on distances between points. </span><span class="kobospan" id="kobo.356.3">We could also include three-way and four-way interactions in our construction of the Vietoris–Rips complex to extend our analysis to the fully simplicial complexes that exist in each slice of </span><span><span class="kobospan" id="kobo.357.1">our dataset.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.358.1">While simplicial complex metrics are beyond the scope of this book, many extensions of network metrics to simplicial complexes exist (such as Forman–Ricci curvature centrality) and may merit investigation in the analysis of time series data. </span><span class="kobospan" id="kobo.358.2">Currently, very little work has elucidated the use of simplicial complex metrics or methods on stock market change </span><span><span class="kobospan" id="kobo.359.1">point detection.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.360.1">If you are interested, we encourage you to extend </span><strong class="source-inline"><span class="kobospan" id="kobo.361.1">Scripts 6.1</span></strong><span class="kobospan" id="kobo.362.1"> and </span><strong class="source-inline"><span class="kobospan" id="kobo.363.1">6.2</span></strong><span class="kobospan" id="kobo.364.1"> to include an analysis of the full time series through the lens of simplicial complexes and calculate the extensions of the network metrics in terms of simplicial complexes. </span><span class="kobospan" id="kobo.364.2">Our chapter reference section includes papers that experiment with </span><span><span class="kobospan" id="kobo.365.1">these extensions.</span></span></p>
<h1 id="_idParaDest-86" class="calibre5"><a id="_idTextAnchor086" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.366.1">Summary</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.367.1">In this chapter, we’ve introduced some common uses of time series data and time series analytics, including stock market data. </span><span class="kobospan" id="kobo.367.2">We explored several vertex- and edge-based centrality metrics that are common in network analytics. </span><span class="kobospan" id="kobo.367.3">Then, we applied network metrics to a time series problem on NASDAQ stock data from 2004 to 2020 to investigate how network metrics and time series thresholding impact the ability to extract useful information from time series data, such as our stock data. </span><span class="kobospan" id="kobo.367.4">Finally, we investigated extending networks to simplicial complexes and constructed a network by building two simplicial complexes using the Vietoris–Rips method and various threshold values. </span><span class="kobospan" id="kobo.367.5">In </span><a href="B21087_07.xhtml#_idTextAnchor088" class="pcalibre calibre6 pcalibre1"><span><em class="italic"><span class="kobospan" id="kobo.368.1">Chapter 7</span></em></span></a><span class="kobospan" id="kobo.369.1">, we'll look at sales and goods pricing across both time and geography to see how network science can solve problems in </span><span><span class="kobospan" id="kobo.370.1">spatiotemporal data.</span></span></p>
<h1 id="_idParaDest-87" class="calibre5"><a id="_idTextAnchor087" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.371.1">References</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.372.1">De Floriani, L., &amp; Hui, A. </span><span class="kobospan" id="kobo.372.2">(2005, July). </span><em class="italic"><span class="kobospan" id="kobo.373.1">Data Structures for Simplicial Complexes: An Analysis And A Comparison</span></em><span class="kobospan" id="kobo.374.1">. </span><span class="kobospan" id="kobo.374.2">In Symposium on Geometry Processing (</span><span><span class="kobospan" id="kobo.375.1">pp. </span><span class="kobospan" id="kobo.375.2">119-128).</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.376.1">Durbach, I., Katshunga, D., &amp; Parker, H. </span><span class="kobospan" id="kobo.376.2">(2013). </span><em class="italic"><span class="kobospan" id="kobo.377.1">Community structure and centrality effects in the South African company network</span></em><span class="kobospan" id="kobo.378.1">. </span><em class="italic"><span class="kobospan" id="kobo.379.1">South African Journal of Business Management</span></em><span class="kobospan" id="kobo.380.1">, </span><span><span class="kobospan" id="kobo.381.1">44(2), 35-43.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.382.1">Estrada, E., &amp; Ross, G. </span><span class="kobospan" id="kobo.382.2">J. </span><span class="kobospan" id="kobo.382.3">(2018). </span><em class="italic"><span class="kobospan" id="kobo.383.1">Centralities in simplicial complexes. </span><span class="kobospan" id="kobo.383.2">Applications to protein interaction networks.</span></em> <em class="italic"><span class="kobospan" id="kobo.384.1">Journal of theoretical biology</span></em><span class="kobospan" id="kobo.385.1">, </span><span><span class="kobospan" id="kobo.386.1">438, 46-60.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.387.1">Johansen, A., &amp; Sornette, D. </span><span class="kobospan" id="kobo.387.2">(1998). </span><em class="italic"><span class="kobospan" id="kobo.388.1">Stock market crashes are outliers</span></em><span class="kobospan" id="kobo.389.1">. </span><em class="italic"><span class="kobospan" id="kobo.390.1">The European Physical Journal B-Condensed Matter and Complex Systems</span></em><span class="kobospan" id="kobo.391.1">, </span><span><span class="kobospan" id="kobo.392.1">1, 141-143.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.393.1">Rodrigues, F. </span><span class="kobospan" id="kobo.393.2">A. </span><span class="kobospan" id="kobo.393.3">(2019). </span><em class="italic"><span class="kobospan" id="kobo.394.1">Network centrality: an introduction</span></em><span class="kobospan" id="kobo.395.1">. </span><em class="italic"><span class="kobospan" id="kobo.396.1">A mathematical modeling approach from nonlinear dynamics to complex </span></em><span><em class="italic"><span class="kobospan" id="kobo.397.1">systems</span></em></span><span><span class="kobospan" id="kobo.398.1">, 177-196.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.399.1">Salnikov, V., Cassese, D., &amp; Lambiotte, R. </span><span class="kobospan" id="kobo.399.2">(2018). </span><em class="italic"><span class="kobospan" id="kobo.400.1">Simplicial complexes and complex systems</span></em><span class="kobospan" id="kobo.401.1">. </span><em class="italic"><span class="kobospan" id="kobo.402.1">European Journal of Physics</span></em><span class="kobospan" id="kobo.403.1">, </span><span><span class="kobospan" id="kobo.404.1">40(1), 014001.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.405.1">Samal, A., Pharasi, H. </span><span class="kobospan" id="kobo.405.2">K., Ramaia, S. </span><span class="kobospan" id="kobo.405.3">J., Kannan, H., Saucan, E., Jost, J., &amp; Chakraborti, A. </span><span class="kobospan" id="kobo.405.4">(2021). </span><em class="italic"><span class="kobospan" id="kobo.406.1">Network geometry and market instability</span></em><span class="kobospan" id="kobo.407.1">. </span><em class="italic"><span class="kobospan" id="kobo.408.1">Royal Society open science</span></em><span class="kobospan" id="kobo.409.1">, </span><span><span class="kobospan" id="kobo.410.1">8(2), 201734.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.411.1">Valente, T. </span><span class="kobospan" id="kobo.411.2">W., Coronges, K., Lakon, C., &amp; Costenbader, E. </span><span class="kobospan" id="kobo.411.3">(2008). </span><em class="italic"><span class="kobospan" id="kobo.412.1">How correlated are network centrality measures?</span></em> <em class="italic"><span class="kobospan" id="kobo.413.1">Connections</span></em><span class="kobospan" id="kobo.414.1"> (Toronto, Ont.), </span><span><span class="kobospan" id="kobo.415.1">28(1), 16.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.416.1">Xiong, J., &amp; Xiao, W. </span><span class="kobospan" id="kobo.416.2">(2021). </span><em class="italic"><span class="kobospan" id="kobo.417.1">Identification of key nodes in abnormal fund trading network based on improved pagerank algorithm</span></em><span class="kobospan" id="kobo.418.1">. </span><span class="kobospan" id="kobo.418.2">In </span><em class="italic"><span class="kobospan" id="kobo.419.1">Journal of Physics</span></em><span class="kobospan" id="kobo.420.1">: Conference Series (Vol. </span><span class="kobospan" id="kobo.420.2">1774, No. </span><span class="kobospan" id="kobo.420.3">1, p. </span><span class="kobospan" id="kobo.420.4">012001). </span><span><span class="kobospan" id="kobo.421.1">IOP Publishing.</span></span></p>
</div>
</body></html>