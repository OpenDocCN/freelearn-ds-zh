- en: 'Chapter 3: Linguistic Features'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter is a deep dive into the full power of spaCy. You will discover
    the linguistic features, including spaCy's most commonly used features such as
    the **part-of-speech (POS) tagger**, the **dependency parser**, the **named entity
    recognizer**, and **merging/splitting** features.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: First, you'll learn the POS tag concept, how the spaCy POS tagger functions,
    and how to place POS tags into your **natural-language understanding** (**NLU**)
    applications. Next, you'll learn a structured way to represent the sentence syntax
    through the dependency parser. You'll learn about the dependency labels of spaCy
    and how to interpret the spaCy dependency labeler results with revealing examples.
    Then, you'll learn a very important NLU concept that lies at the heart of many
    **natural language processing** (**NLP**) applications—**named entity recognition**
    (**NER**). We'll go over examples of how to extract information from the text
    using NER. Finally, you'll learn how to merge/split the entities you extracted.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we''re going to cover the following main topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: What is POS tagging?
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction to dependency parsing
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introducing NER
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Merging and splitting tokens
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The chapter code can be found at the book''s GitHub repository: [https://github.com/PacktPublishing/Mastering-spaCy/tree/main/Chapter03](https://github.com/PacktPublishing/Mastering-spaCy/tree/main/Chapter03)'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: What is POS tagging?
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We saw the terms *POS tag* and *POS tagging* briefly in the previous chapter,
    while discussing the spaCy `Token` class features. As is obvious from the name,
    they refer to the process of tagging tokens with POS tags. One question remains
    here: *What is a POS tag?* In this section, we''ll discover in detail the concept
    of POS and how to make the most of it in our NLP applications.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: 'The **POS tagging** acronym expands as **part-of-speech tagging**. A **part
    of speech** is a syntactic category in which every word falls into a category
    according to its function in a sentence. For example, English has nine main categories:
    verb, noun, pronoun, determiner, adjective, adverb, preposition, conjunction,
    and interjection. We can describe the functions of each category as follows:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: '**Verb**: Expresses an action or a state of being'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Noun**: Identifies a person, a place, or a thing, or names a particular of
    one of these (a proper noun)'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Pronoun**: Can replace a noun or noun phrase'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Determiner**: Is placed in front of a noun to express a quantity or clarify
    what the noun refers to—briefly, a noun introducer'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Adjective**: Modifies a noun or a pronoun'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Adverb**: Modifies a verb, an adjective, or another adverb'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Preposition**: Connects a noun/pronoun to other parts of the sentence'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Conjunction**: Glues words, clauses, and sentences together'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Interjection**: Expresses emotion in a sudden and exclamatory way'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This core set of categories, without any language-specific morphological or
    syntactic features, are called `pos_` feature and describes them with examples,
    as follows:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.1 – spaCy universal tags explained with examples'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16570_03_01.jpg)'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.1 – spaCy universal tags explained with examples
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: Throughout the book, we are providing examples with the English language and,
    in this section, we'll therefore focus on English. Different languages offer different
    tagsets, and spaCy supports different tagsets via `tag_map.py` under each language
    submodule. For example, the current English tagset lies under `lang/en/tag_map.py`
    and the German tagset lies under `lang/de/tag_map.py`. Also, the same language
    can support different tagsets; for this reason, spaCy and other NLP libraries
    always *specify* which tagset they use. The spaCy English POS tagger uses the
    `Ontonotes 5` tagset, and the German POS tagger uses the `TIGER Treebank` tagset.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: Each supported language of spaCy admits its own fine-grained tagset and tagging
    scheme, a specific tagging scheme that usually covers morphological features,
    tenses and aspects of verbs, number of nouns (singular/plural), person and number
    information of pronouns (first-, second-, third-person singular/plural), pronoun
    type (personal, demonstrative, interrogative), adjective type (comparative or
    superlative), and so on.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: 'spaCy supports fine-grained POS tags to answer language-specific needs, and
    the `tag_` feature corresponds to the fine-grained tags. The following screenshot
    shows us a part of these fine-grained POS tags and their mappings to more universal
    POS tags for English:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.2 – Fine-grained English tags and universal tag mappings'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16570_03_02.jpg)'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.2 – Fine-grained English tags and universal tag mappings
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: 'Don''t worry if you haven''t worked with POS tags before, as you''ll become
    familiar by practicing with the help of our examples. We''ll always include explanations
    of the tags that we use. You can also call `spacy.explain()` on the tags. We usually
    call `spacy.explain()` in two ways, either directly on the tag name string or
    with `token.tag_`, as illustrated in the following code snippet:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'If you want to know more about POS, you can read more about it at two excellent
    resources: *Part of Speech* at http://partofspeech.org/, and the *Eight Parts
    of Speech* at [http://www.butte.edu/departments/cas/tipsheets/grammar/parts_of_speech.html](http://www.butte.edu/departments/cas/tipsheets/grammar/parts_of_speech.html).'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, POS tagging offers a very basic syntactic understanding of the
    sentence. POS tags are used in NLU extensively; we frequently want to find the
    verbs and the nouns in a sentence and better disambiguate some words for their
    meanings (more on this subject soon).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: Each word is tagged by a POS tag depending on its *context*—the other surrounding
    words and their POS tags. POS taggers are sequential statistical models, which
    means *that a tag of a word depends on the word-neighbor tokens, their tags, and
    the word itself*. POS tagging has always been done in different forms. **Sequence-to-sequence
    learning** (**Seq2seq**) started with **Hidden Markov Models** (**HMMs**) in the
    early days and evolved to neural network models—typically, **long short-term memory**
    (**LSTM**) variations (spaCy also uses an LSTM variation). You can witness the
    evolution of state-of-art POS tagging on the ACL website ([https://aclweb.org/aclwiki/POS_Tagging_(State_of_the_art](https://aclweb.org/aclwiki/POS_Tagging_(State_of_the_art))).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: 'It''s time for some code now. Again, spaCy offers universal POS tags via the
    `token.pos (int)` and `token.pos_ (unicode)` features. The fine-grained POS tags
    are available via the `token.tag (int)` and `token.tag_ (unicode)` features. Let''s
    learn more about tags that you''ll come across most, through some examples. The
    following example includes examples of noun, proper noun, pronoun, and verb tags:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We iterated over the tokens and printed the tokens'' text, universal tag, and
    fine-grained tag, together with the explanations, which are outlined here:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: '`Alicia` is a proper noun, as expected, and `NNP` is a tag for proper nouns.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`me` is a pronoun and `bus` is a noun. `NN` is a tag for singular nouns and
    `PRP` is a personal pronoun tag.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Verb tags start with `V`. Here, `VBD` is a tag for *went*, which is a past-tense
    verb.
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now, consider the following sentence:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Let''s start with the verbs. As we pointed out in the first example, verb tags
    start with `V`. Here, there are three verbs, as follows:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: '`fly`: a base form'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`staying`: an *-ing* form'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`is`: an auxiliary verb'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The corresponding tags are `VB`, `VBG`, and `VBZ`.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: Another detail is both `New` and `York` are tagged as proper nouns. If a proper
    noun consists of multiple tokens, then all the tokens admit the tag `NNP`. `My`
    is a possessive pronoun and is tagged as `PRP$`, in contrast to the preceding
    personal pronoun `me` and its tag `PRP`.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s continue with a word that can be a verb or noun, depending on the context:
    `ship`. In the following sentence, `ship` is used as a verb:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Here, `ship` is tagged as a verb, as we expected. Our next sentence also contains
    the word `ship`, but as a noun. Now, can the spaCy tagger tag it correctly? Have
    a look at the following code snippet to find out:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '*Et voilà*! This time, the word `ship` is now tagged as a noun, as we wanted
    to see. The tagger looked at the surrounding words; here, `ship` is used with
    a determiner and an adjective, and spaCy deduced that it should be a noun.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: 'How about this tricky sentence:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We wanted to fool the tagger with the different usages of the word `fish`,
    but the tagger is intelligent enough to distinguish the verb `fish`, the noun
    `fish`, and the adjective `fishy`. Here''s how it did it:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: Firstly, `fish` comes right after the modal verb `will`, so the tagger recognized
    it as a verb.
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Secondly, `fish` serves as the object of the sentence and is qualified by a
    determiner; the tag is most probably a noun.
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, `fishy` ends in `y` and comes before a noun in the sentence, so it's
    clearly an adjective.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The spaCy tagger made a very smooth job here of predicting a tricky sentence.
    After examples of very accurate tagging, only one question is left in our minds:
    *Why do we need the POS tags?*'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: 'What is the importance of POS tags in NLU, and why do we need to distinguish
    the class of the words anyway? The answer is simple: many applications need to
    know the word type for better accuracy. Consider machine translation systems for
    an example of this: the words for `fish (V)` and `fish (N)` correspond to different
    words in Spanish, as illustrated in the following code snippet:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Syntactic information can be used in many NLU tasks, and playing some POS tricks
    can help your NLU code a lot. Let''s continue with a traditional problem: **word-sense
    disambiguation** (**WSD**), and how to tackle it with the help of the spaCy tagger.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: WSD
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**WSD** is a classical NLU problem of deciding in which *sense* a particular
    word is used in a sentence. A word can have many senses—for instance, consider
    the word *bass*. Here are some senses we can think of:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: Bass—seabass, fish (`N`))
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bass—lowest male voice (`N`)
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bass—male singer with lowest voice range (`N`)
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Determining the sense of the word can be crucial in search engines, machine
    translation, and question-answering systems. For the preceding example, *bass*,
    a POS tagger is unfortunately not much of help as the tagger labels all senses
    with a noun tag. We need more than a POS tagger. How about the word *beat*? Let''s
    have a look at this here:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: Beat—to strike violently (`V`))
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Beat—to defeat someone else in a game or a competition (`V`)
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Beat—rhythm in music or poetry (`N`)
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Beat—bird wing movement (`N`)
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Beat—completely exhausted (`ADJ`))
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Here, POS tagging can help a lot indeed. The `ADJ` tag determines the word sense
    definitely; if the word *beat* is tagged as `ADJ`, it identifies the sense *completely
    exhausted*. This is not true for the `V` and `N` tags here; if the word *beat*
    is labeled with a `V` tag, its sense can be *to strike violently* or *to defeat
    someone else*. WSD is an open problem, and many complicated statistical models
    are proposed. However, if you need a quick prototype, you can tackle this problem
    in some cases (such as in the preceding example) with the help of the spaCy tagger.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: Verb tense and aspect in NLU applications
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the previous chapter, we used the example of the travel agency application
    where we got the base forms (which are freed from verb tense and aspect) of the
    verbs by using **lemmatization**. In this subsection, we'll focus on how to use
    the verb tense and aspect information that we lost during the lemmatization process.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: '**Verb tense** and **aspect** are maybe the most interesting information that
    verbs provide us, telling us when the action happened in time and if the action
    of the verb is finished or ongoing. Tense and aspect together indicate a verb''s
    reference to the current time. English has three basic tenses: past, present,
    and future. A tense is accompanied by either simple, progressive/continuous, or
    perfect aspects. For instance, in the sentence *I''m eating*, the action *eat*
    happens in the present and is ongoing, hence we describe this verb as *present
    progressive/continuous*.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: 'So far, so good. So, how do we use this information in our travel agency NLU,
    then? Consider the following customer sentences that can be directed to our NLU
    application:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'In all the sentences, the action is *to fly*: however, only some sentences
    state intent to make a ticket booking. Let''s imagine these sentences with a surrounding
    context, as follows:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'At a quick glance, past and perfect forms of the verb *fly* don''t indicate
    a booking intent at all. Rather, they direct to either a customer complaint or
    customer service issues. The infinitive and present progressive forms, on the
    other hand, point to booking intent. Let''s tag and lemmatize the verbs with the
    following code segment:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'We iterated three `doc` objects one by one, and for each sentence we checked
    if the fine-grained tag of the token is `VBG` (a verb in present progressive form)
    or `VB` (a verb in base/infinitive form). Basically, we filtered out the present
    progressive and infinitive verbs. You can think of this process as a semantic
    representation of the verb in the form of `(word form, lemma, tag)` as illustrated
    in the following code snippet:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We have covered one semantic and one morphological task—WSD and tense/aspect
    of verbs. We''ll continue with a tricky subject: how to make the best of some
    special tags—namely, number, symbol, and punctuation tags.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: Understanding number, symbol, and punctuation tags
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If you look at the English POS, you will notice the `NUM`, `SYM`, and `PUNCT`
    tags. These are the tags for numbers, symbols, and punctuation, respectively.
    These categories are divided into fine-grained categories: `$`, `SYM`, `''''`,
    `-LRB-`, and `-RRB-`. These are shown in the following screenshot:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.3 – spaCy punctuation tags, general and fine-grained'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16570_03_03.jpg)'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.3 – spaCy punctuation tags, general and fine-grained
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s tag some example sentences that contain numbers and symbols, as follows:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: We again iterated over the tokens and printed the fine-grained tags. The tagger
    was able to distinguish symbols, punctuation marks, and numbers. Even the word
    `million` is recognized as a number too!
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: Now, what to do with symbol tags? Currency symbols and numbers offer a way to
    systematically extract descriptions of money and are very handy in financial text
    such as financial reports. We'll see how to extract money entities in [*Chapter
    4*](B16570_04_Final_JM_ePub.xhtml#_idTextAnchor069), *Rule-Based Matching*.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: That's it—you made it to the end of this exhaustive section! There's a lot to
    unpack and digest, but we assure you that you made a great investment for your
    industrial NLP work. We'll now continue with another syntactic concept—dependency
    parsing.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to dependency parsing
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you are already familiar with spaCy, you must have come across the spaCy
    dependency parser. Though many developers see *dependency parser* on the spaCy
    documentation, they're shy about using it or don't know how to use this feature
    to the fullest. In this part, you'll explore a systematic way of representing
    a sentence syntactically. Let's start with what dependency parsing actually is.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: What is dependency parsing?
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the previous section, we focused on POS tags—syntactic categories of words.
    Though POS tags provide information about neighbor words' tags as well, they do
    not give away any relations between words that are not neighbors in the given
    sentence.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we'll focus on dependency parsing—a more structured way of
    exploring the sentence syntax. As the name suggests, **dependency parsing** is
    related to analyzing sentence structures via dependencies between the tokens.
    A **dependency parser** tags syntactic relations between tokens of the sentence
    and connects syntactically related pairs of tokens. A **dependency** or a **dependency
    relation** is a *directed link* between two tokens.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: 'The result of the dependency parsing is always a **tree**, as illustrated in
    the following screenshot:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.4 – An example of a dependency tree (taken from Wikipedia)'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16570_03_04.jpg)'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.4 – An example of a dependency tree (taken from Wikipedia)
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: 'If you''re not familiar with a tree data structure, you can learn more about
    it at this excellent Computer Science resource:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: https://www.cs.cmu.edu/~clo/www/CMU/DataStructures/Lessons/lesson4_1.htm
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: Dependency relations
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: What is the use of **dependency relations**, then? Quite a number of statistical
    methods in NLP revolve around vector representations of words and treat a sentence
    as a sequence of words. As you can see in *Figure 3.4*, a sentence is more than
    a sequence of tokens—it has a structure; every word in a sentence has a well-defined
    role, such as verb, subject, object, and so on; hence, sentences definitely have
    a structure. This structure is used extensively in chatbots, question answering,
    and machine translation.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: 'The most useful application that first comes to mind is determining the sentence
    object and subject. Again, let''s go back to our travel agency application. Imagine
    a customer is complaining about the service. Compare the two sentences, `I forwarded
    you the email` and `You forwarded me the email`; if we eliminate the stopwords
    `I`, `you`, `me`, and `the`, this is what remains:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Though the remaining parts of the sentences are identical, sentences have very
    different meanings and require different answers. In the first sentence, the sentence
    subject is `I` (then, the answer most probably will start with `you`) and the
    second sentence's subject is `you` (which will end up in an `I` answer).
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: Obviously, the dependency parser helps us to go deeper into the sentence syntax
    and semantics. Let's explore more, starting from the dependency relations.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: Syntactic relations
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'spaCy assigns each token a dependency label, just as with other linguistic
    features such as a lemma or a POS tag. spaCy shows dependency relations with *directed
    arcs*. The following screenshot shows an example of a dependency relation between
    a noun and the adjective that qualifies the noun:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.5 – Dependency relation between a noun and its adjective'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16570_03_05.jpg)'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.5 – Dependency relation between a noun and its adjective
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: 'A dependency label describes the type of syntactic relation between two tokens
    as follows: one of the tokens is the `flower` is the head and `blue` is its dependent/child.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: 'The dependency label is assigned to the child. Token objects have `dep (int)`
    and `dep_ (unicode)` properties that hold the dependency label, as illustrated
    in the following code snippet:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'In this example, we iterated over the tokens and printed their text and dependency
    label. Let''s go over what happened bit by bit, as follows:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: '`blue` admitted the `amod` label. `amod` is the dependency label for an adjective-noun
    relation. For more examples of the `amod` relation, please refer to *Figure 3.7*.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`flower` is the `ROOT`. `ROOT` is a special label in the dependency tree; it
    is assigned to the main verb of a sentence. If we''re processing a phrase (not
    a full sentence), the `ROOT` label is assigned to the root of the phrase, which
    is the head noun of the phrase. In the `blue flower` phrase, the head noun, `flower`,
    is the root of the phrase.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each sentence/phrase has exactly one root, and it's the root of the parse tree
    (remember, the dependency parsing result is a tree).
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tree nodes can have more than one child, but each node can only have one parent
    (due to tree restrictions, and trees containing no cycles). In other words, every
    token has exactly one head, but a parent can have several children. This is the
    reason why the dependency label is assigned to the dependent node.
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here is a full list of spaCy''s English dependency labels:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.6 – List of some spaCy English dependency labels'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16570_03_06.jpg)'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.6 – List of spaCy English dependency labels
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: 'That''s a long list! No worries—you don''t need to memorize every list item.
    Let''s first see a list of the most common and useful labels, then we''ll see
    how exactly they link tokens to each other. Here''s the list first:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: '`amod`: Adjectival modifier'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`aux`: Auxiliary'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`compound`: Compound'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dative`: Dative object'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`det`: Determiner'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dobj`: Direct object'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`nsubj`: Nominal subject'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`nsubjpass`: Nominal subject, passive'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`nummod`: Numeric modifier'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`poss`: Possessive modifier'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`root`: The root'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s see examples of how the aforementioned labels are used and what relation
    they express. `amod` is adjectival modifier. As understood from the name, this
    relation modifies the noun (or pronoun). In the following screenshot, we see **white**
    modifies **sheep**:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.7 – amod relation'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16570_03_07.jpg)'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.7 – amod relation
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: '`aux` is what you might guess: it''s the dependency relation between an auxiliary
    verb and its main verb; the dependent is an auxiliary verb, and the head is the
    main verb. In the following screenshot, we see that **has** is the auxiliary verb
    of the main verb **gone**:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.8 – aux relation'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16570_03_08.jpg)'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.8 – aux relation
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: '`compound` is used for the noun compounds; the second noun is modified by the
    first noun. In the following screenshot, **phone book** is a noun compound and
    the **phone** noun modifies the **book** noun:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.9 – Compound relation between phone and book'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16570_03_09.jpg)'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.9 – Compound relation between phone and book
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: 'The `det` relation links a determiner (the dependent) to the noun it qualifies
    (its head). In the following screenshot, **the** is the determiner of the noun
    **girl** in this sentence:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.10 – det relation on the right'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16570_03_10.jpg)'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.10 – det relation
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: Next, we look into two object relations, `dative` and `dobj`. The `dobj` relation
    is between the verb and its direct object. A sentence can have more than one object
    (such as in the following example); a direct object is the object that the verb
    acts upon, and the others are called indirect objects.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: 'A direct object is generally marked with `dative` relation points to a `dative`
    object, which receives an indirect action from the verb. In the sentence shown
    in the following screenshot, the indirect object is **me** and the direct object
    is **book**:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.11 – The direct and indirect objects of the sentence'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16570_03_11.jpg)'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.11 – The direct and indirect objects of the sentence
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: '`nsubj` and `nsubjposs` are two relations that are related to the nominal sentence
    subject. The subject of the sentence is the one that committed the action. A passive
    subject is still the subject, but we mark it with `nsubjposs`. In the following
    screenshot, **Mary** is the nominal subject of the first sentence:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.12 – nsubj relation'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16570_03_12.jpg)'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.12 – nsubj relation
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: '**you** is the passive nominal subject of the sentence in the following screenshot:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.13 – nsubjpass relation'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16570_03_13.jpg)'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.13 – nsubjpass relation
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: 'We have now covered sentence subject and object relations. Now, we''ll discover
    two modifier relations; one is the `nummod` `poss` `nummod` is easy to spot; it''s
    between **3** and **books**:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.14 – nummod relation'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16570_03_14.jpg)'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.14 – nummod relation
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: 'A possessive modifier happens either between a *possessive pronoun* and a noun
    or a *possessive ''s* and a noun. In the sentence shown in the following screenshot,
    **my** is a possessive marker on the noun **book**:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.15 – poss relation between “my” and “book”'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16570_03_15.jpg)'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.15 – poss relation between "my" and "book"
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: Last, but not least, is the **root label**, which is not a real relation but
    is a marker for the sentence verb. A root word has no real parent in the syntactic
    tree; the root is the main verb of the sentence. In the preceding sentences, **took**
    and **given** are the corresponding roots. The main verbs of both sentences are
    the auxiliary verbs **is** and **are**. Notice that the root node has no incoming
    arc—that is, no parent.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: 'These are the most useful labels for our NLU purposes. You definitely don''t
    need to memorize all the labels, as you''ll become familiar as you practice in
    the next pages. Also, you can ask spaCy about a label any time you need, via `spacy.explain()`.
    The code to do this is shown in the following snippet:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Take a deep breath, since there is a lot to digest! Let's practice how we can
    make use of dependency labels.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: 'Again, `token.dep_` includes the dependency label of the dependent token. The
    `token.head` property points to the head/parent token. Only the root token does
    not have a parent; spaCy points to the token itself in this case. Let''s bisect
    the example sentence from *Figure 3.7*, as follows:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We iterated over the tokens and printed the fine-grained POS tag and the dependency
    label. `counted` is the main verb of the sentence and is labeled by the label
    `ROOT`. Now, `I` is the subject of the sentence, and `sheep` is the direct object.
    `white` is an adjective and modifies the noun `sheep`, hence its label is `amod`.
    We go one level deeper and print the token heads this time, as follows:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The visualization is as follows:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.16 – An example parse of a simple sentence'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16570_03_16.jpg)'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.16 – An example parse of a simple sentence
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: 'When the `token.head` property is also involved, it''s a good idea to follow
    the code and the visual at the same time. Let''s go step by step in order to understand
    how the visual and the code match:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: 'We start reading the parse tree from the root. It''s the main verb: `counted`.'
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, we follow its arc on the left toward the pronoun `I`, which is the nominal
    subject of the sentence and is labeled by the label `nsubj`.
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now, return back to the root, `counted`. This time, we navigate to the right.
    Follow the `dobj` arc to reach the noun `sheep`. `sheep` is modified by the adjective
    `white` with an `amod` relation, hence the direct object of this sentence is `white
    sheep`.
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Even such a simple, flat sentence has a dependency parse tree that''s fancy
    to read, right? Don''t rush—you''ll get used to it by practicing. Let''s examine
    the dependency tree of a longer and more complicated sentence, as follows:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Now, this time things look a bit different, as we'll see in *Figure 3.17*. We
    locate the main verb and the root `trying` (it has no incoming arcs). The left
    side of the word `trying` looks manageable, but the right side has a chain of
    arcs. Let's start with the left side. The pronoun `we` is labeled by `nsubj`,
    hence this is the nominal subject of the sentence. The other left arc, labeled
    `aux`, points to the `trying` dependent `are`, which is the auxiliary verb of
    the main verb `trying`.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: 'So far, so good. Now, what is happening on the right side? `trying` is attached
    to the second verb `understand` via an `xcomp` relation. The `xcomp` (or open
    complement) relation of a verb is a clause without its own subject. Here, the
    `to understand the difference` clause has no subject, so it''s an open complement.
    We follow the `dobj` arc from the second verb, `understand`, and land on the noun,
    `difference`, which is the direct object of the `to understand the difference`
    clause, and this is the result:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.17 – A complicated parsing example'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16570_03_17.jpg)'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.17 – A complicated parsing example
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: 'This was an in-depth analysis for this example sentence, which indeed does
    not look that complicated. Next, we process a sentence with a subsentence that
    owns its own nominal subject, as follows:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: In order to make the visuals big enough, I have split the visualization into
    two parts. First, let's find the root. The root lies in the right part. `died`
    is the main sentence of the verb and the root (again, it has no incoming arcs).
    The rest of the right side contains nothing tricky.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: 'On the other hand, the left side has some interesting stuff—actually, a relative
    clause. Let''s bisect the relative clause structure:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: We start with the proper noun `Katherine`, which is attached to `died` with
    a `nsubj` relation, hence the subject of the sentence.
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We see a compound arc leaving `Katherine` toward the proper noun, `Queen`. Here,
    `Queen` is a title, so the relationship with `Katherine` is compound. The same
    relationship exists between `Mary` and `Tudor` on the right side, and the last
    names and first names are also tied with the compound relation.
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'It''s time to bisect the relative clause, `who was the mother of Mary Tudor`,
    as follows:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: First of all, it is `Katherine` who is mentioned in the relative clause, so
    we see a `relcl` (relative clause) arc from `Katherine` to `was` of the relative
    clause.
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`who` is the nominal subject of the clause and is linked to `was` via an `nsubj`
    relation. As you see in the following screenshot, the dependency tree is different
    from the previous example sentence, whose clause didn''t own a nominal subject:'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 3.18 – A dependency tree with a relative clause, the left part'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16570_03_18.jpg)'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.18 – A dependency tree with a relative clause, the left part
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.19 – Same sentence, the right part'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16570_03_19.jpg)'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.19 – Same sentence, the right part
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: It's perfectly normal if you feel that you won't be able to keep all the relations
    in your mind. No worries—always find the root/main verb of the sentence, then
    follow the arcs from the root and go deeper, just as we did previously. You can
    always have a look at the spaCy documentation ([https://spacy.io/api/annotation#dependency-parsing](https://spacy.io/api/annotation#dependency-parsing))
    to see what the relation type means. Take your time until you warm up to the concept
    and the details.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: 'That was exhaustive! Dear reader—as we said before, please take your time to
    digest and practice on example sentences. The *displaCy* online demo is a great
    tool, so don''t be shy to try your own example sentences and see the parsing results.
    It''s perfectly normal for you to find this section heavy. However, this section
    is a solid foundation for general linguistics, and also for the information extraction
    and pattern-matching exercises in [*Chapter 4*](B16570_04_Final_JM_ePub.xhtml#_idTextAnchor069),
    *Rule-Based Matching*. You will become even more comfortable after going through
    a case study in [*Chapter 6*](B16570_06_Final_JM_ePub.xhtml#_idTextAnchor103),
    *Putting Everything Together: Semantic Parsing with spaCy*. Give yourself time
    to digest dependency parsing with examples throughout the book.'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: What comes after the dependency parser? Without any doubt, you must have heard
    NER frequently mentioned in the NLU world. Let's look into this very important
    NLU concept.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: Introducing NER
  id: totrans-224
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We opened this chapter with a tagger, and we'll see another very handy tagger—the
    NER tagger of spaCy. As NER's name suggests, we are interested in finding named
    entities.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: What is a **named entity**? A named entity is a real-world object that we can
    refer to by a proper name or a quantity of interest. It can be a person, a place
    (city, country, landmark, famous building), an organization, a company, a product,
    dates, times, percentages, monetary amounts, a drug, or a disease name. Some examples
    are Alicia Keys, Paris, France, Brandenburg Gate, WHO, Google, Porsche Cayenne,
    and so on.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: A named entity always points to a *specific* object, and that object is distinguishable
    via the corresponding named entity. For instance, if we tag the sentence *Paris
    is the capital of France*, we parse *Paris* and *France* as named entities, but
    not the word *capital*. The reason is that *capital* does not point to a specific
    object; it's a general name for many objects.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: 'NER categorization is a bit different from POS categorization. Here, the number
    of categories is as high as we want. The most common categories are person, location,
    and organization and are supported by almost every usable NER tagger. In the following
    screenshot, we see the corresponding tags:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.20 – Most common entity types'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16570_03_20.jpg)'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.20 – Most common entity types
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: spaCy supports a wide range of entity types. Which ones you use depends on your
    corpus. If you process financial text, you most probably use `MONEY` and `PERCENTAGE`
    more often than `WORK_OF_ART`.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a list of the entity types supported by spaCy:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.21 – Full list of entity types supported by spaCy'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16570_03_21.jpg)'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.21 – Full list of entity types supported by spaCy
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: 'Just as with the POS tagger statistical models, NER models are also sequential
    models. The very first modern NER tagger model is a **conditional random field**
    (**CRF**). CRFs are sequence classifiers used for structured prediction problems
    such as labeling and parsing. If you want to learn more about the CRF implementation
    details, you can read more at this resource: https://homepages.inf.ed.ac.uk/csutton/publications/crftutv2.pdf.
    The current state-of-the-art NER tagging is achieved by neural network models,
    usually LSTM or LSTM+CRF architectures.'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: 'Named entities in a doc are available via the `doc.ents` property. `doc.ents`
    is a list of `Span` objects, as illustrated in the following code snippet:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: spaCy also tags each token with the entity type. The type of the named entity
    is available via `token.ent_type (int)` and `token.ent_type_ (unicode)`. If the
    token is not a named entity, then `token.ent_type_` is just an empty string.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: 'Just as for POS tags and dependency labels, we can call `spacy.explain()` on
    the tag string or on the `token.ent_type_`, as follows:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Let''s go over some examples to see the spaCy NER tagger in action, as follows:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: We iterated over the tokens one by one and printed the token and its entity
    type. If the token is not tagged as an entity, then `token.ent_type_` is just
    an empty string, hence there is no explanation from `spacy.explain()`. For the
    tokens that are part of a NE, an appropriate tag is returned. In the preceding
    sentences, `Albert Einstein`, `Ulm`, `1879`, and `ETH Zurich` are correctly tagged
    as `PERSON`, `GPE`, `DATE`, and `ORG`, respectively.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see a longer and more complicated sentence with a non-English entity
    and look at how spaCy tagged it, as follows:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Looks good! The spaCy tagger picked up a person entity with a `-` smoothly.
    Overall, the tagger works quite well for different entity types, as we saw throughout
    the examples.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: After tagging tokens with different syntactical features, we sometimes want
    to merge/split entities into fewer/more tokens. In the next section, we will see
    how merging and splitting is done. Before that, we will see a real-world application
    of NER tagging.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: A real-world example
  id: totrans-250
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: NER is a popular and frequently used pipeline component of spaCy. NER is one
    of the key components of understanding the text topic, as named entities usually
    belong to a **semantic category**. For instance, *President Trump* invokes the
    *politics* subject in our minds, whereas *Leonardo DiCaprio* is more about *movies*.
    If you want to go deeper into resolving the text meaning and understanding who
    made what, you also need named entities.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
- en: 'This real-world example includes processing a *New York Times* article. Let''s
    go ahead and download the article first by running the following code:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: We downloaded the article `BeautifulSoup` is a popular Python package for extracting
    text from HTML and `nlp` object, passed the article body to the `nlp` object,
    and created a `Doc` object.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s start our analysis of the article by the entity type count, as follows:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'That''s a totally normal number for a news article that includes many entities.
    Let''s go a bit further and group the entity types, as follows:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The most frequent entity type is `GPE`, which means a country, city, or state.
    The second one is `PERSON`, whereas the third most frequent entity label is `NORP`,
    which means a nationality/religious-political group. The next ones are organization,
    date, and cardinal number-type entities.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: 'Can we summarize the text by looking at the entities or understanding the text
    topic? To answer this question, let''s start by counting the most frequent tokens
    that occur in the entities, as follows:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Looks like a semantic group! Obviously, this article is about American politics,
    and possibly how America interacts with the rest of the world in politics. If
    we print all the entities of the article, we can see here that this guess is true:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'We made a visualization of the whole article by pasting the text into **displaCy
    Named Entity Visualizer** ([https://explosion.ai/demos/displacy-ent/](https://explosion.ai/demos/displacy-ent/)).
    The following screenshot is taken from the demo page that captured a part of the
    visual:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.22 – The New York Times article''s entities visualized by displaCy'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16570_03_22.jpg)'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.22 – The New York Times article's entities visualized by displaCy
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
- en: spaCy's NER offers great capabilities for understanding text, as well as presenting
    good-looking visuals to ourselves, colleagues, and stakeholders.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
- en: Merging and splitting tokens
  id: totrans-269
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We extracted the name entities in the previous section, but how about if we
    want to unite or split multiword named entities? And what if the tokenizer performed
    this not so well on some exotic tokens and you want to split them by hand? In
    this subsection, we'll cover a very practical remedy for our multiword expressions,
    multiword named entities, and typos.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
- en: '`doc.retokenize` is the correct tool for merging and splitting the spans. Let''s
    see an example of retokenization by merging a multiword named entity, as follows:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'This is what we did in the preceding code:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
- en: First, we created a `doc` object from the sample sentence.
  id: totrans-274
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then, we printed its entities with `doc.ents`, and the result was `New Hampshire`,
    as expected.
  id: totrans-275
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the next line, for each token, we printed `token.text` with token indices
    in the sentence (`token.i`).
  id: totrans-276
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Also, we examined length of the `doc` object by calling `len` on it, and the
    result was `6` (`"."` is a token too).
  id: totrans-277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now, we wanted to merge the tokens of position `3` until `5` (`3` is included;
    `5` is not), so we did the following:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
- en: First, we called the `retokenizer` method `merge(indices, attrs)`. `attrs` is
    a dictionary of token attributes we want to assign to the new token, such as `lemma`,
    `pos`, `tag`, `ent_type`, and so on.
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the preceding example, we set the lemma of the new token; otherwise, the
    lemma would be `New` only (the starting token's lemma of the span we want to merge).
  id: totrans-280
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then, we printed the tokens to see if the operation worked as we wished. When
    we print the new tokens, we see that the new `doc[3]` is the `New Hampshire` token.
  id: totrans-281
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Also, the `doc` object is of length `5` now, so we shrank the doc one less token.
    `doc.ents` remain the same and the new token's lemma is `new hampshire` because
    we set it with `attrs`.
  id: totrans-282
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Looks good, so how about splitting a multiword token into several tokens? In
    this setting, either there's a typo in the text you want to fix or the custom
    tokenization is not satisfactory for your specific sentence.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
- en: 'Splitting a span is a bit more complicated than merging a span because of the
    following reasons:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
- en: We are changing the dependency tree.
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We need to assign new POS tags, dependency labels, and necessary token attributes
    to the new tokens.
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Basically, we need to think about how to assign linguistic features to the new
    tokens we created.
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s see how to deal with the new tokens with an example of how to fix a
    typo, as follows:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Here''s what the dependency tree looks like before the splitting operation:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.23 – Sample sentence’s dependency tree before retokenization'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16570_03_23.jpg)'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.23 – Sample sentence's dependency tree before retokenization
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we will split the `doc[3]`, `NewHampshire`, into two tokens: `New` and
    `Hampshire`. We will give fine-grained POS tags and dependency labels to the new
    tokens via the `attrs` dictionary. We will also rearrange the dependency tree
    by passing the new tokens'' parents via the `heads` parameter. While arranging
    the heads, there are two things to consider, as outlined here:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
- en: Firstly, if you give a relative position (such as `(doc[3], 1)`) in the following
    code segment, this means that head of `doc[3]` will be the +1th position token—that
    is, `doc[4]` in the new setup (please see the following visualization ).
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Secondly, if you give an absolute position, it means the position in the *original*
    `Doc` object. In the following code snippet, the second item in the `heads` list
    means that the `Hampshire` token's head is the second token in the original Doc,
    which is the `in` token (please refer to *Figure 3.23*).
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'After the splitting, we printed the list of new tokens and the linguistic attributes.
    Also, we examined the new length of the `doc` object, which is `6` now. You can
    see the result here:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 分割后，我们打印了新标记的列表和语言属性。我们还检查了`doc`对象的新长度，现在为`6`。你可以在这里看到结果：
- en: '[PRE30]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Here''s what the dependency tree looks like after the splitting operation (please
    compare this with *Figure 3.22*):'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 这是分割操作后依赖树的模样（请与*图3.22*进行比较）：
- en: '![Figure 3.24 – Dependency tree after the splitting operation'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.24 – 分割操作后的依赖树'
- en: '](img/B16570_03_24.jpg)'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B16570_03_24.jpg](img/B16570_03_24.jpg)'
- en: Figure 3.24 – Dependency tree after the splitting operation
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.24 – 分割操作后的依赖树
- en: You can apply merging and splitting onto any span, not only the named entity
    spans. The most important part here is to correctly arrange the new dependency
    tree and the linguistic attributes.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以应用合并和分割到任何跨度，而不仅仅是命名实体跨度。这里最重要的部分是正确排列新的依赖树和语言属性。
- en: Summary
  id: totrans-304
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: That was it—you made it to the end of this chapter! It was an exhaustive and
    long journey for sure, but we have unveiled the real linguistic power of spaCy
    to the fullest. This chapter gave you details of spaCy's linguistic features and
    how to use them.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样——你到达了本章的结尾！这确实是一次详尽且漫长的旅程，但我们已经完全揭示了spaCy的真实语言能力。本章为您提供了spaCy的语言特征及其使用方法的详细信息。
- en: You learned about POS tagging and applications, with many examples. You also
    learned about an important yet not so well-known and well-used feature of spaCy—the
    dependency labels. Then, we discovered a famous NLU tool and concept, NER. We
    saw how to do named entity extraction, again via examples. We finalized this chapter
    with a very handy tool for merging and splitting the spans that we calculated
    in the previous sections.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 你学习了关于词性标注和应用的知识，还有许多示例。你还了解了一个重要但不太为人所知且使用得很好的spaCy特性——依赖标签。然后，我们发现了一个著名的NLU工具和概念，NER。我们看到了如何通过示例进行命名实体提取。我们用一个非常实用的工具结束了本章，这个工具可以合并和分割我们在前几节计算出的跨度。
- en: What's next, then? In the next chapter, we will again be discovering a spaCy
    feature that you'll be using every day in your NLP application code—spaCy's `Matcher`
    class. We don't want to give a spoiler on this beautiful subject, so let's go
    onto our journey together!
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，接下来是什么？在下一章中，我们又将发现一个你将在日常NLP应用程序代码中每天都会使用的spaCy特性——spaCy的`Matcher`类。我们不想在这个美好的主题上给出剧透，所以让我们一起继续我们的旅程吧！
