<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" xml:lang="en-US">
<head>
<meta charset="utf-8"/>
<meta name="generator" content="packt"/>
<title>6 Anonymizing and Pseudonymizing your Data in Power BI</title>
<link rel="stylesheet" type="text/css" href="../styles/stylesheet1.css"/>
<link rel="stylesheet" type="text/css" href="../styles/stylesheet2.css"/>

</head>
<body>

<section id="anonymizing-and-pseudonymizing-your-data-in-power-bi" class="level1 pkt" data-number="7">
<h1 data-number="7">6 Anonymizing and Pseudonymizing your Data in Power BI</h1>
<p>It happens very often to those who develop a specific software product for a client to want to <em>repackage</em> it and sell it to another client who is interested in similar features. However, if you want to show a few screenshots of the software in a demo to the new client, you should avoid showing any data that might be sensitive. Getting in there and trying to mask the data from a copy of the original software database by hand was definitely one of the tasks the poor hapless developer found themselves having to do in the past, maybe even a few days before the demo.</p>
<p>The scenario described does not require data to be shared with a third-party recipient but aims to successfully demo a product to the customer by displaying like-real data. Therefore, there is no concern about a possible brute force attack by professional analysts with the goal of deriving the original data prior to the de-identification operation.</p>
<p>Things definitely change when you need to share an entire dataset with a third-party recipient. The issue has become more sensitive since 2018, especially in Europe, where the need to give more attention to data privacy and <strong>personally identifiable</strong> <em></em> <strong>information</strong> (<strong>PII</strong>) has become imperative for companies to comply with the requirements of the <strong>General Data Protection Regulation</strong> (<strong>GDPR</strong>).</p>
<p>The goal of this chapter is to introduce de-identification techniques using <strong>Python</strong> or <strong>R</strong> scripts that can help the <strong>Power BI</strong> developer prevent a person's identity from being linked to the information shown on the report.</p>
<p>In this chapter, you will learn the following:</p>
<ul>
<li>De-identifying data</li>
<li>Anonymizing data in Power BI</li>
<li>Pseudonymizing data in Power BI</li>
</ul>
<section id="technical-requirements-5" class="level2" data-number="7.1">
<h2 data-number="7.1">Technical requirements</h2>
<p>This chapter requires you to have a working Internet connection and <strong>Power BI Desktop</strong> already installed on your machine. You must have properly configured the R and Python engines and IDEs as outlined in <em>Chapter 2</em>, <em>Configuring R with Power BI</em>, and <em>Chapter 3</em>, <em>Configuring Python with Power BI</em>.</p>
</section>
<section id="de-identifying-data" class="level2" data-number="7.2">
<h2 data-number="7.2">De-identifying data</h2>
<p><strong>PII</strong>, also called <strong>personal information</strong> or <strong>personal data</strong>, is any information relating to an identifiable person. There are two types of PII – <em>direct</em> and <em>indirect</em>. Examples of <strong>direct identifiers</strong> are your name, your address, a picture of you, or an RFID (Radio Frequency Identification) associated with you. <strong>Indirect identifiers</strong>, on the other hand, are all those pieces of information that don't explicitly refer to you as a person, but somehow make it easier to identify you. Examples of indirect identifiers are your license plate number, your bank account number, the link to your profile on a social network, or your place of work.</p>
<p>The practice of <strong>de-identifying</strong> data is to manipulate PPIs so that it is no longer possible to identify the person who generated them.</p>
<p>There are two options for handling direct and indirect personal identifiers – either you decide to destroy them completely, or you decide to keep them separated from the rest of the data, implementing security measures to prevent anyone from re-identifying the data subject. But let's first explore what some of the most common de-identification techniques are.</p>
<section id="de-identification-techniques" class="level3" data-number="7.2.1">
<h3 data-number="7.2.1">De-identification techniques</h3>
<p><strong>De-identification</strong> is a process that is invisible to end users. After doing a careful study with a team of analysts, generally it is the data manager (or the person acting on their behalf) who decides what information should be de-identified. In the next sections, we will discuss the most commonly used de-identification techniques.</p>
<section id="information-removal" class="level4" data-number="7.2.1.1">
<h4 data-number="7.2.1.1">Information removal</h4>
<p>The simplest form of de-identification is to remove sensitive information from the dataset:</p>
<figure>
<img src="../media/file157.png" alt="Figure 6.1 – Anonymization, information removal" /><figcaption aria-hidden="true">Figure 6.1 – Anonymization, information removal</figcaption>
</figure>
<p>It is clear that one of the disadvantages of this simplistic approach could be that the final dataset no longer conforms to the schema expected by the application that must consume it.</p>
</section>
<section id="data-masking" class="level4" data-number="7.2.1.2">
<h4 data-number="7.2.1.2">Data masking</h4>
<p><strong>Data masking</strong> hides information that users with specific roles shouldn't see. It could consist of modifying data using word or character substitution. For example, you can replace a value character with a symbol, such as <code>*</code> or <code>x</code>. The following is a typical example of data masking:</p>
<figure>
<img src="../media/file158.png" alt="Figure 6.2 – Anonymization, data masking" /><figcaption aria-hidden="true">Figure 6.2 – Anonymization, data masking</figcaption>
</figure>
<p>Keep in mind that if the readable domain name in the email address is not public, but belongs to a recognizable legal entity, the data masking applied does not comply with the GDPR rules, as the workplace becomes recognizable.</p>
<p>Some products include <strong>dynamic data masking</strong> solutions out of the box. These mask or block sensitive information to users based on their role, location, and privileges.</p>
<blockquote>
<p><strong>Note</strong></p>
<p>For example, <strong>Microsoft SQL Server</strong> and <strong>Azure SQL Database</strong> provide dynamic data masking as a solution to avoid exposing sensitive data to unauthorized users. The data in the database is not changed, as masking rules are applied in the query results.</p>
</blockquote>
</section>
<section id="data-swapping" class="level4" data-number="7.2.1.3">
<h4 data-number="7.2.1.3">Data swapping</h4>
<p><strong>Data swapping</strong> consists of shuffling the values of a column containing sensitive data for the entire dataset. For example, if you have a column containing an individual's date of birth, this can very well be anonymized using the swapping technique with very good results.</p>
</section>
<section id="generalization" class="level4" data-number="7.2.1.4">
<h4 data-number="7.2.1.4">Generalization</h4>
<p><strong>Generalization</strong> consists of replacing point values with other values that indicate a broader category, to which the initial value belongs. For example:</p>
<ul>
<li>An <em>age</em> of <code>25</code> can be transformed in the values <code>&gt;=18</code>, or <em>between 18 and 30</em>.</li>
<li>A <em>birth date</em>, like <code>04/11/1989</code>, can be replaced by the <em>year of birth</em> <code>1989</code>.</li>
<li>A <em>postal zip code</em> can be replaced by a broader <em>regional zip code</em>.</li>
</ul>
</section>
<section id="data-perturbation" class="level4" data-number="7.2.1.5">
<h4 data-number="7.2.1.5">Data perturbation</h4>
<p><strong>Data perturbation</strong> is a technique that replaces original values by adding some random noise or creating synthetic data. This transformation results in a loss of information that can make the data itself useless.</p>
</section>
<section id="tokenization" class="level4" data-number="7.2.1.6">
<h4 data-number="7.2.1.6">Tokenization</h4>
<p><strong>Tokenization</strong> is a technique that replaces original sensitive values with a randomly generated alphanumeric value, called a <strong>token</strong>. Completely random tokens offer the highest security, as the content cannot be re-engineered. There is no mathematical algorithm behind the scenes to get the original value back with an inverse transformation. Therefore, the association between the token and original value is generally maintained in a secured database, and tokens are usually generated by specific token servers. Only the token server talks to the token database.</p>
</section>
<section id="hashing" class="level4" data-number="7.2.1.7">
<h4 data-number="7.2.1.7">Hashing</h4>
<p><strong>Hashing</strong> is a technique similar to tokenization, with the difference that the resulting <em>token</em>, called a <strong>hash value</strong>, is generated by a mathematical algorithm, has a fixed length, and is almost impossible to transform back to the original value. If you use the same hashing function with the same input value, you’ll always have the same hash value as output. Often, additional text called <em>salt</em> is added to the input value to make it more complicated for a brute force attack to reverse engineer the hash value.</p>
</section>
<section id="encryption" class="level4" data-number="7.2.1.8">
<h4 data-number="7.2.1.8">Encryption</h4>
<p>Like hashing, <strong>encryption</strong> uses a mathematical algorithm to transform sensitive data. As opposed to hashing, it is a two-way transformation that needs a decryption key to reverse engineer an encrypted value. Using an encrypted mapping table can boost performance when decrypting data.</p>
<p>Most productivity tools and database systems are now available with end-to-end encryption built-in.</p>
<blockquote>
<p><strong>Note</strong></p>
<p>Two examples are the Microsoft SQL Server or Azure SQL databases, which have the <em>Always Encrypted</em> feature out of the box. It works by encrypting the data on the client side and hiding the encryption keys from the server. Even database administrators cannot read information stored in an encrypted column without having explicit permission.</p>
</blockquote>
<p>Now that you have an idea of the most common transformations used to de-identify sensitive information, you will see how they are used in anonymization and pseudonymization.</p>
</section>
</section>
<section id="understanding-pseudonymization" class="level3" data-number="7.2.2">
<h3 data-number="7.2.2">Understanding pseudonymization</h3>
<p><strong>Pseudonymization</strong> is a de-identification process that separates direct or indirect identifiers from the rest of the data, taking care to ensure the following:</p>
<ul>
<li>Replacing one or more PIIs with <strong>pseudonyms</strong> (a random actual name, but more often a random numeric or alphanumeric identifier), ensuring the non-identification of the subject. Analytical correlations are guaranteed thanks to the fact that the pseudonym is always the same for the same input. So, analysis of pseudonymized data doesn’t lose value.</li>
<li>Not destroying the original PIIs, making sure that the entire dataset can be reconstructed (re-identification of the data) using, for example, lookup tables between PIIs and pseudonyms, or digital secret keys to pseudonymize inputs into the same output.</li>
<li>Taking appropriate technical and organizational measures to make it difficult to trace the identity of an individual from the remaining data.</li>
</ul>
<p>During this process, some de-identification transformations can be made to some PIIs that you want to keep in the accessible data. For example, you could replace PII values with similar-looking pseudonyms, making sure to keep track of the replacement in order to guarantee the re-identification.</p>
<p>An example of a pseudonymization process is shown in <em>Figure 6.2</em>, where a lookup table is used to guarantee the mapping for the inverse transformation:</p>
<figure>
<img src="../media/file159.png" alt="Figure 6.3 – The process of pseudonymization" /><figcaption aria-hidden="true">Figure 6.3 – The process of pseudonymization</figcaption>
</figure>
<p>An architecture of this type also guarantees the possibility of satisfying any requests for deletion of personal data by individuals (as required by GDPR) by meeting the following conditions:</p>
<ul>
<li>It will be impossible to identify the subject from that moment on, just by removing the association related to it from the lookup table.</li>
<li>The complete loss of statistical information useful for data analysis will be avoided, as it’s possible to use de-identification transformations that don’t erase analytical correlations.</li>
</ul>
<blockquote>
<p><strong>Important Note</strong></p>
<p>Keep in mind that the moment you <em>permanently lose the link</em> between a row of accessible data and its respective PPIs, that row becomes <em>completely anonymized</em>, thus falling out of GDPR's control.</p>
</blockquote>
<p>So, we have introduced the concept of anonymization. Let's take a look at what this means.</p>
</section>
<section id="what-is-anonymization" class="level3" data-number="7.2.3">
<h3 data-number="7.2.3">What is anonymization?</h3>
<p><strong>Anonymization</strong> completely destroys direct and indirect identifiers, or destroys the link to their de-identified counterpart, so that there is no danger (or at least it is really very unlikely) that any attacker will be able to reconstruct the identity of the subjects to which the data refers. It has the <em>non-reversibility of the process</em> as its main goal. For this reason, the following applies:</p>
<blockquote>
<p><strong>Important Note</strong></p>
<p>Anonymized data is outside the scope and control of the GDPR because anonymized data is no longer <em>personal data</em>.</p>
</blockquote>
<p>The most obvious disadvantage of anonymization is that it removes significant value from the data involved. This is because, after the process is complete, it is impossible to trace the identities that generated that data. It is therefore advisable to assess all relevant risks before anonymizing any dataset.</p>
<p>The second disadvantage of anonymization is that it usually uses randomly generated de-identified strings, so <em>some statistical information of the dataset is permanently lost</em>, making any work a data scientist would have to do futile.</p>
<p>It may be that anonymized data can be vulnerable to <strong>de-anonymization attacks</strong>. They consist of enriching the anonymized dataset with available external information, thus imputing the anonymized items. These attacks are more likely to succeed, as the anonymized data is abundant, granular, and fairly stable over time and context.</p>
<p>Usually, the most adopted de-identification techniques for secure anonymization are as follows:</p>
<ul>
<li>Tokenization</li>
<li>Encryption</li>
</ul>
<p>Let's now see how to apply these concepts to a real case using Power BI.</p>
</section>
</section>
<section id="anonymizing-data-in-power-bi" class="level2" data-number="7.3">
<h2 data-number="7.3">Anonymizing data in Power BI</h2>
<p>One of the possible scenarios that could happen to you during your career as a report developer in Power BI is the following. Imagine you are given an <strong>Excel</strong> dataset to import into Power BI in order to create a report to show to another department of your company. The Excel dataset contains sensitive personal data, such as names and email addresses of people who have made multiple attempts to pay for an order with a credit card. The following is an example of the contents of the Excel file:</p>
<figure>
<img src="../media/file160.png" alt="Figure 6.4 – Excel data to be anonymized" /><figcaption aria-hidden="true">Figure 6.4 – Excel data to be anonymized</figcaption>
</figure>
<p>You are asked to create the report while anonymizing the sensitive data.</p>
<p>The first thing that jumps out at you is that, not only do you have to anonymize the <strong>Name</strong> and <strong>Email</strong> columns, but some names or email addresses can be included in the text of some <strong>Notes</strong>. While locating email addresses is fairly easy using regular expressions, it is not as easy to locate person names in free text. For this purpose, it is necessary to adopt a technique of <strong>natural language processing</strong> (<strong>NLP</strong>) that goes under the name of <strong>named entity recognition</strong> (<strong>NER</strong>). Thanks to NER, it’s possible to identify and classify named entities (like people, places, and so on) in free text.</p>
<p>The basic idea is to replace both full names and email addresses with random <em>tokens</em>. Depending on the analytical language used, there are different solutions driven by the different packages available that lead to the same result.</p>
<section id="anonymizing-data-using-python" class="level3" data-number="7.3.1">
<h3 data-number="7.3.1">Anonymizing data using Python</h3>
<p>Python is one of the most widely used languages for performing de-identification transformations in anonymization processes. There are a plethora of packages that implement such solutions. In particular, Microsoft released the open source package <strong>Presidio</strong> (<a href="https://microsoft.github.io/presidio/">https://microsoft.github.io/presidio/</a>), which is to date one of the best solutions for data protection and anonymization. It provides quick identification and anonymization forms for entities found in free text and images, such as credit card numbers, names, locations, social security numbers, email addresses, financial data, and more. <strong>PII recognizers</strong> leverage NER, regular expressions, rule-based logic, and checksums by identifying the relevant context in multiple languages. Behind the scenes, Presidio adopts NLP engines to recognize the entities – it supports both <strong>SpaCy</strong> (the default one) and <strong>Stanza</strong>. One of the most interesting features of Presidio is its <em>extensibility</em>. In fact, it is possible to extend the Presidio Analyzer by adding <em>custom PII entities</em> very easily.</p>
<p>Once the sensitive entities are identified, you need to replace them with tokens. They are generated in Python using the <code>secrets</code> module.</p>
<p>That said, you can find an implementation of this in the Python file, <code>01-anonymize-data-in-power-bi-python.py</code>, in the <code>Chapter06</code> folder of the GitHub repository that comes with this book. It performs the following operations:</p>
<ol>
<li>Load the libraries needed to execute the code. You will use the <code>pandas</code> module, some functions from the <code>presidio_analyzer</code> and <code>presidio_anonymizer</code> modules, and the <code>secrets</code> module.</li>
<li>Define two custom functions, one to anonymize emails, the other to anonymize person names. Both use the <code>analyzer.analyze()</code> Presidio function to identify the entities to be anonymized and the <code>secrets</code> module to generate the tokens into the <code>anonymizer.anonymize()</code> function.</li>
<li>Initialize the main objects of the <strong>Presidio Analyzer</strong> and <strong>Presidio Anonymizer</strong>.</li>
<li><p>For each row of the dataset previously loaded in Power BI Desktop (or via the <code>pandas</code>’ <code>read_excel()</code> function if you want to test the code in <strong>VSCode</strong>), apply the <code>anonymizeEmail</code> function to the <code>Email</code> and <code>Notes</code> columns and apply the <code>anonymizeName</code> function to the <code>Name</code> and <code>Notes</code> columns. In order to apply a function to each individual value of a column, we adopted the <code>apply()</code> function followed by a construct that goes by the name of <strong>lambda function</strong> (introduced by the keyword <code>lambda</code>). It is a small function defined without a name (anonymous) to be used inline. Here is an example:</p>
<pre><code>df.Name = df.Name.apply(lambda x: anonymizeName(x))</code></pre></li>
</ol>
<p>In order to proceed, however, it is necessary to configure <em>a new Python Environment</em>. This is because, to date, Presidio is supported only for Python versions from 3.6 to 3.8. Your <code>pbi_powerquery_env</code> environment has a newer Python version installed, so you need to create a new environment with Python 3.8. Once created, you have to install the necessary modules to run the code.</p>
<p>These are the steps needed to configure the new environment:</p>
<ol>
<li>Open your <strong>Anaconda</strong> <strong>Prompt</strong>.</li>
<li><p>Enter and run the following code to create the new <code>presidio_env</code> environment with Python 3.8:</p>
<pre><code>conda create --name presidio_env python=3.8</code></pre></li>
<li><p>Enter and run the following code to switch to the newly created environment:</p>
<pre><code>conda activate presidio_env</code></pre></li>
<li><p>Enter and run the following code to install the Presidio Analyzer:</p>
<pre><code>pip install presidio_analyzer</code></pre></li>
<li><p>Enter and run the following code to install the Presidio Anonymizer:</p>
<pre><code>pip install presidio_anonymizer</code></pre></li>
<li><p>The Analyzer also installs SpaCy behind the scenes. So, you must also install the SpaCy’s <em>trained pipeline for written English text</em> (we choose the one for blogs, news, and comments) using this code:</p>
<pre><code>python -m spacy download en_core_web_lg </code></pre>
<p>This is the largest pipeline used by SpaCy and takes up about 788 MB.</p></li>
<li><p>Enter and run the following code to install <strong>pandas</strong>:</p>
<pre><code>pip install pandas</code></pre></li>
<li><p>If you want to use pandas to directly load the Excel with Python and then test the code before entering it in Power BI, you’ll also need the <code>openpyxl</code> module:</p>
<pre><code>pip install openpyxl</code></pre></li>
<li><p>Enter and run the following code to install <code>matplotlib</code>, needed by the Power BI wrapper used with Python scripts:</p>
<pre><code>pip install matplotlib</code></pre></li>
</ol>
<p>You are now ready to apply anonymization in Power BI to the content of the <code>CustomersCreditCardAttempts.xlsx</code> Excel file you can find in the <code>Chapter06</code> folder.</p>
<p>So, let's get started:</p>
<ol>
<li>Open your Power BI Desktop. Make sure the referenced Python environment is <code>presidio_env</code> in the options (its home directory should be <code>C:\Users\&lt;your-username&gt;\miniconda3\envs\presidio_env</code>). Keep in mind that in case you can't find the path to a specific environment, activate it in the Anaconda Prompt (<code>conda activate &lt;your-env&gt;</code>) and then enter <code>where python</code>.</li>
<li><p>From the ribbon, click on the <strong>Excel</strong> icon to import data from Excel:</p>
<figure>
<img src="../media/file161.png" alt="Figure 6.5 – Importing data from Excel" /><figcaption aria-hidden="true">Figure 6.5 – Importing data from Excel</figcaption>
</figure></li>
<li>From the <strong>Open</strong> dialog box, select the aforementioned <code>CustomersCreditCardAttempts.xlsx</code> file.</li>
<li><p>From the <strong>Navigator</strong> window, select the <code>Customers</code> sheet and then click on <strong>Transform Data</strong>:</p>
<figure>
<img src="../media/file162.png" alt="Figure 6.6 – Selecting the Customers sheet and clicking on Transform Data" /><figcaption aria-hidden="true">Figure 6.6 – Selecting the Customers sheet and clicking on Transform Data</figcaption>
</figure></li>
<li>Click on the <strong>Transform</strong> menu and then click on <strong>Run Python Script</strong>.</li>
<li>Copy the script from the <code>01-anonymize-data-in-power-bi-python.py</code> file into the Python script editor and click <strong>OK</strong>.</li>
<li>If Power BI needs you to provide it with data privacy information, you already know how to proceed based on what you've seen in <em>Chapter 5</em>, <em>Using Regular Expressions in Power BI</em>.</li>
<li><p>We are only interested in the <code>df</code> dataset. So, click on its <strong>Table</strong> value:</p>
<figure>
<img src="../media/file163.png" alt="Figure 6.7 – Selecting the dataset df as the result of the Python script transformation" /><figcaption aria-hidden="true">Figure 6.7 – Selecting the dataset df as the result of the Python script transformation</figcaption>
</figure></li>
<li>As you can see, person names in the <code>Name</code> and <code>Notes</code> columns and emails in the <code>Email</code> and <code>Notes</code> columns have been correctly anonymized:</li>
</ol>
<figure>
<img src="../media/file164.png" alt="Figure 6.8 – The transformed dataset as the result of the Python script" /><figcaption aria-hidden="true">Figure 6.8 – The transformed dataset as the result of the Python script</figcaption>
</figure>
<p>You can now click <strong>Close &amp; Apply</strong> in the <strong>Home</strong> tab.</p>
<p>Notice how the person name contained in the <code>Notes</code> column has also been anonymized. This is the result of applying NER algorithms used by the <strong>SpaCy</strong> engine, which works under the hood of Presidio.</p>
<p>Moreover, the de-identification technique used (tokenization) doesn’t preserve the statistical characteristics of the dataset, since applying the procedure to the same personal data does not return the same de-identified string.</p>
<blockquote>
<p><strong>Note</strong></p>
<p>When you publish the report for which you have anonymized the data, the corresponding dataset will also be published. Users who can only access the dataset (and not the source Excel file) <em>will only see the anonymized data</em>, without having the ability to learn about the associations with the original data that has been replaced.</p>
</blockquote>
<p>Thanks to anonymization, you can now develop your reports without having to worry about the danger of exposing sensitive data.</p>
<p>Let's see how it is possible to do the same thing in R.</p>
</section>
<section id="anonymizing-data-using-r" class="level3" data-number="7.3.2">
<h3 data-number="7.3.2">Anonymizing data using R</h3>
<p>You can implement a data anonymization process in R as well. As long as you are identifying strings using regular expressions in R, the processing is quite fast. However, when natural language processing techniques like NER need to be implemented, the most widely adopted R packages available often consist of wrappers of open source modules developed in other languages. For example, the <strong>openNLP</strong> R package is an interface to the <strong>Apache OpenNLP</strong> toolkit, based on machine learning algorithms written in <strong>Java</strong>. In order for the <code>openNLP</code> package to interface with <strong>OpenNLP</strong> software, its installation also requires as a dependency the <code>rJava</code> package, which enables the dialogue between the R and Java worlds.</p>
<p>In order to implement the same anonymization features developed in Python in the previous section in R, you will make use of another widely used R package for NLP operations called <code>spacyr</code>. This library provides a convenient R wrapper around the Python <code>spacy</code> module. In the previous section, you saw that the Python module called <code>presidio</code> installs behind the scenes the same <code>spacy</code> module used by <code>spacyr</code>. If you're wondering how to run Python code from an R module, remember that, in <em>Chapter 3</em>, <em>Configuring Python with Power BI</em>, you ran Python code through <strong>RStudio</strong> using the R package called <code>reticulate</code>. Just as <code>rJava</code> takes care of interfacing R with the Java VM, so <code>reticulate</code> allows R to interface with a Python environment and execute Python code. In a nutshell, the R code you are going to develop does nothing more than execute the functionality of the <code>spacy</code> Python module you used in the previous section.</p>
<blockquote>
<p><strong>Note</strong></p>
<p>Remember that you could have used regular expressions to replace email addresses with dummy data. Instead, replacing person names within free text is only possible with an NLP function that recognizes named entities. Hence the need to use a package like <code>spacyr</code>.</p>
</blockquote>
<p>Just as you did in the previous section, here you will also anonymize the content of the Excel file, <code>CustomersCreditCardAttempts.xlsx</code>, through tokenization. Tokens in R will be generated using the <code>stringi</code> package.</p>
<p>That said, the R code in the <code>02-anonymize-data-in-power-bi-r.R</code> file you can find in the <code>Chapter06</code> folder performs the following operations:</p>
<ol>
<li>Load the libraries needed to execute the code. In particular, you will use <code>stringr</code>, <code>dplyr</code>, and <code>purrr</code> from the <code>Tidyverse</code> to operate data wrangling; <code>spacyr</code> and <code>stringi</code> are used for data anonymization.</li>
<li>Define the <code>anonymizeEmails</code> function, used to anonymize emails, to a free text. It uses the <code>spacyr</code> function’s <code>spacy_parse()</code> with the additional <code>like_email</code> attribute. As it can identify multiple email addresses into a single text, the <code>str_replace_all()</code> function is used to replace all the found occurrences with a token generated by the <code>stri_rand_strings</code> function of the <code>stringi</code> package.</li>
<li>Define the <code>anonymizeNames</code> function, used to anonymize person names, to a free text. It contains more complex logic than the previous function because a person's name can consist of multiple tokens that are not always separated by a space (for example, the name <code>Roma Rodriguez-Bailey</code>). Therefore, in order to identify the set of all tokens referring to a single person, we must construct a regex that references the first and last tokens (from the previous example, <code>Roma.*?Bailey</code>), which is able to match the entire name. As you can see, there was no need to have to implement all of this logic in the previous section, because the Python Presidio module takes care of all of these cases.</li>
<li><p>You must initialize <code>spacyr</code> so that it references a Python environment containing the <code>spacy</code> module installed. Generally, if you haven't already installed <code>spacy</code> in an environment, you can use <code>spacyr</code>'s <code>spacy_install()</code> function, which sets up a new Python environment with everything you need to make it work properly. In our case, we've already created the Python environment, <code>presidio_env</code>, in the previous section, which contains both the <code>spacy</code> module and the trained <code>en_core_web_lg</code> model to extract language attributes using written English samples taken from the web. It is then enough to reference the environment <code>presidio_env</code> path in the <code>spacy_initialize()</code> function to correctly configure <code>spacyr</code>. Here is the code:</p>
<pre><code>spacy_initialize(
  model = &quot;en_core_web_lg&quot;,
  condaenv = r&quot;{C:\Users\&lt;your-username&gt;\miniconda3\envs\presidio_env}&quot;,
  entity = TRUE
)</code></pre>
<p>If you run it in RStudio, you’ll get something similar to the following message if all is working correctly:</p>
<pre><code>successfully initialized (spaCy Version: 2.3.0, language model: en_core_web_lg)
(python options: type = &quot;condaenv&quot;, value = &quot;C:\Users\&lt;your-username&gt;\miniconda3\envs\presidio_env&quot;)</code></pre></li>
<li>For each row of the dataset previously loaded in Power BI (or using the <code>readxl</code> package to test the code in RStudio), apply the <code>anonymizeEmail</code> function to the <code>Email</code> and <code>Notes</code> columns, and apply the <code>anonymizeName</code> function to the <code>Name</code> and <code>Notes</code> columns. In order to apply the two functions defined previously to each element of a column, we used the <code>map()</code> function of the <code>purrr</code> package. More specifically, <code>map_chr()</code> returns the outputs in a vector of strings so that it can replace the column content.</li>
</ol>
<p>Having briefly explained what the R script does, let's get down to business. In order to use the <code>spacyr</code> R package, it must be installed in the latest R engine (in our case, MRO 4.0.2). These are the necessary steps:</p>
<ol>
<li>Open <strong>Rstudio</strong>, and be sure to select in the <strong>Global Options</strong> the most recent MRO engine you already installed, following the steps in <em>Chapter 2</em>, <em>Configuring R with Power BI</em>.</li>
<li><p>Since MRO by definition downloads new packages from a default <strong>CRAN</strong> (<strong>Comprehensive R Archive Network</strong>) snapshot back in time, in order to download the latest version of packages in <code>CRAN</code> you need to overwrite the referenced repository by running the following code:</p>
<pre><code>local({
  r &lt;- getOption(&quot;repos&quot;)
  r[&quot;CRAN&quot;] &lt;- &quot;https://cloud.r-project.org/&quot;
  options(repos = r)
})</code></pre></li>
<li><p>Then, install the <code>spacyr</code> package by running the following code in the console:</p>
<pre><code>install.packages(&quot;spacyr&quot;)</code></pre></li>
</ol>
<p>You are now ready to apply anonymization in Power BI to the content of the <code>CustomersCreditCardAttempts.xlsx</code> Excel file using R.</p>
<p>So, let’s get started:</p>
<ol>
<li>Open your Power BI Desktop, and make sure the referenced R engine is your latest MRO version in the <strong>Global Options</strong>.</li>
<li>From the ribbon, click on the <strong>Excel</strong> icon to import data from Excel.</li>
<li>From the <strong>Open</strong> dialog box, select the aforementioned <code>CustomersCreditCardAttempts.xlsx</code> file.</li>
<li><p>From the <strong>Navigator</strong> window, select the <strong>Customers</strong> sheet and then click on <strong>Transform Data</strong>:</p>
<figure>
<img src="../media/file165.png" alt="Figure 6.9 – Selecting the Customers sheet and clicking on Transform Data" /><figcaption aria-hidden="true">Figure 6.9 – Selecting the Customers sheet and clicking on Transform Data</figcaption>
</figure></li>
<li>Click on the <strong>Transform</strong> menu and then click on <strong>Run R Script</strong>.</li>
<li>Copy the script from the <code>02-anonymize-data-in-power-bi-r.R</code> file into the R script editor and click <strong>OK</strong>. Remember to change the environment path of your machine.</li>
<li>If Power BI needs you to provide it with data privacy information, you already know how to proceed based on what you've seen in <em>Chapter 5</em>, <em>Using Regular Expressions in Power BI</em>.</li>
<li><p>We are only interested in the <code>df</code> dataset. So, click on its <strong>Table</strong> value:</p>
<figure>
<img src="../media/file166.png" alt="Figure 6.10 – Selecting the dataset df as a result of the R script transformation" /><figcaption aria-hidden="true">Figure 6.10 – Selecting the dataset df as a result of the R script transformation</figcaption>
</figure></li>
<li>As you can see, person names in the <code>Name</code> and <code>Notes</code> column and emails in the <code>Email</code> and <code>Notes</code> columns have been correctly anonymized:</li>
</ol>
<figure>
<img src="../media/file167.png" alt="Figure 6.11 – The transformed dataset as the result of the R script" /><figcaption aria-hidden="true">Figure 6.11 – The transformed dataset as the result of the R script</figcaption>
</figure>
<p>You can then click <strong>Close &amp; Apply</strong> in the <strong>Home</strong> tab.</p>
<p>As you could see, the execution of the R script took longer than that of the Python script. Clearly, the overhead of passing information through <code>reticulate</code> makes a difference.</p>
<blockquote>
<p><strong>Important Note</strong></p>
<p>If you need to anonymize a not-so-small dataset, it is advisable to do it directly using a Python script for much better performance.</p>
</blockquote>
<p>Again, the dataset resulting from the publication of this report will contain only the anonymized data, without giving Power BI users the ability to retrieve the original data.</p>
<p>Let's see now how to pseudonymize the data in Power BI.</p>
</section>
</section>
<section id="pseudonymizing-data-in-power-bi" class="level2" data-number="7.4">
<h2 data-number="7.4">Pseudonymizing data in Power BI</h2>
<p>Unlike anonymization, pseudonymization maintains the statistical characteristics of the dataset by transforming the same input string into the same output string, and keeps track of replacements that have occurred, allowing those with access to this mapping information to obtain the original dataset again.</p>
<p>Moreover, pseudonymization replaces sensitive data with <strong>fake strings</strong> (<strong>pseudonyms</strong>), having the same <em>form</em> as the original one, making the de-identified data more realistic.</p>
<p>Depending on the analytical language used, there are different solutions driven by the different packages available that lead to the same result. Let's see how to apply pseudonymization in Power BI to the contents of the same Excel file used in the previous sections with Python.</p>
<section id="pseudonymizing-data-using-python" class="level3" data-number="7.4.1">
<h3 data-number="7.4.1">Pseudonymizing data using Python</h3>
<p>The modules and the code structure you will use are quite similar to those already used for anonymization. One difference is that, once the sensitive entities are identified, they are replaced by fake entities of the same type. The fake data generators par excellence in Python are two: <strong>Faker</strong> (<a href="https://faker.readthedocs.io/">https://faker.readthedocs.io/</a>) and <strong>Mimesis</strong> (<a href="https://mimesis.readthedocs.io/">https://mimesis.readthedocs.io/</a>). In our example, we'll use Faker, which is inspired by the library of the same name previously developed for <strong>PHP</strong>, <strong>Perl</strong>, and <strong>Ruby</strong>.</p>
<p>Moreover, what changes is the logic of the two custom functions used to de-identify entities and the addition of the management of two dictionaries (<code>emails_dict</code> and <code>names_dict</code>) to maintain the mapping between personal data and fake data.</p>
<p>We've also added a little more <em>salt</em> to the handling of the fake data – person names and email addresses are generated considering the country of each individual in the dataset, passing it as a parameter in custom functions. For example, if the individual is German, the generated person name will be a typical German name.</p>
<p>Let's see in detail what this is all about. The referenced Python file is <code>03-pseudonymize-data-in-power-bi-python.py</code>, which you can find in the <code>Chapter06</code> folder:</p>
<ol>
<li>While, in the case of anonymization, the <code>anonymizer.anonymize()</code> function was used to replace all entities identified using the <code>analyzer.analyze()</code> function in one go, now, after the same entity identification, we must <em>first check if each identified single entity has already been mapped to a fake string</em>. If the entity is in its own specific dictionary, you retrieve the associated fake string and use that to pseudonymize the text. Otherwise, you generate a new fake string and add it to the dictionary, associating it with the entity in question.</li>
<li>When the pseudonymization of all expected columns is complete, the mapping dictionaries (both for names and emails) are persisted to <code>pkl</code> files. These are unpickled and used as mapping dictionaries whenever new Excel data needs to be pseudonymized, and then at each refresh of the dataset. This ensures that the same pseudonyms are always used for the same personal data and also for new Excel rows.</li>
</ol>
<p>In order to use the <code>faker</code> module as mentioned before, you need to install it in the <code>presidio_env</code> environment in the following way:</p>
<ol>
<li>Open your Anaconda Prompt.</li>
<li><p>Enter and run the following code to switch to the newly created environment:</p>
<pre><code>conda activate presidio_env</code></pre></li>
<li><p>Enter and run the following code to install <code>Faker</code>:</p>
<pre><code>pip install Faker</code></pre></li>
</ol>
<p>Once this is done, you can start to implement pseudonymization in Power BI:</p>
<ol>
<li>Open your Power BI Desktop and make sure the referenced Python environment is <code>presidio_env</code> in <strong>Options</strong> (its home directory should be <code>C:\Users\&lt;your-username&gt;\miniconda3\envs\presidio_env</code>).</li>
<li>From the Power BI ribbon, click on the <strong>Excel</strong> icon to import data from Excel.</li>
<li>From the <strong>Open</strong> dialog box, select the aforementioned <code>CustomersCreditCardAttempts.xlsx</code> file.</li>
<li><p>From the <strong>Navigator</strong> window, select the <strong>Customers</strong> sheet and then click on <strong>Transform Data</strong>:</p>
<figure>
<img src="../media/file168.png" alt="Figure 6.12 – Selecting the Customers sheet and clicking on Transform Data" /><figcaption aria-hidden="true">Figure 6.12 – Selecting the Customers sheet and clicking on Transform Data</figcaption>
</figure></li>
<li>Click on the <strong>Transform</strong> menu and then click on <strong>Run Python Script</strong>.</li>
<li>Copy the script from the <code>03-pseudonymize-data-in-power-bi-python.py</code> file into the Python script editor and click <strong>OK</strong>. Remember to change the environment path of your machine.</li>
<li>If Power BI needs you to provide it with data privacy information, you already know how to proceed based on what you've seen in <em>Chapter 5</em>, <em>Using Regular Expressions in Power BI</em>.</li>
<li><p>We are only interested in the <code>df</code> dataset. So, click on its <strong>Table</strong> value:</p>
<figure>
<img src="../media/file169.png" alt="Figure 6.13 – Selecting the dataset df as a result of the Python script transformation" /><figcaption aria-hidden="true">Figure 6.13 – Selecting the dataset df as a result of the Python script transformation</figcaption>
</figure></li>
<li>As you can see, person names in the <code>Name</code> and <code>Notes</code> column and emails in the <code>Email</code> and <code>Notes</code> columns have been correctly pseudonymized:</li>
</ol>
<figure>
<img src="../media/file170.png" alt="Figure 6.14 – The transformed dataset as the result of the Python script" /><figcaption aria-hidden="true">Figure 6.14 – The transformed dataset as the result of the Python script</figcaption>
</figure>
<p>You can then click <strong>Close &amp; Apply</strong> in the <strong>Home</strong> tab.</p>
<p>Just as in the case of anonymization, the <code>Name</code>, <code>Email</code>, and <code>Notes</code> columns have been correctly de-identified. What we have in addition is the following:</p>
<ul>
<li>The consistency of the person names and emails with the individual's country, although <code>Faker</code> does not currently allow you to maintain consistency between generated names and their respective emails. For example, in <em>Figure 6.14</em>, you can see an Italian name and an email using a different Italian name at <em>row 11</em> (the name <em>Alfio Migliaccio</em> is not used in the email).</li>
<li>The use of the <code>emails_dict</code> and <code>names_dict</code> mapping dictionaries to ensure that statistical analysis can be done on the pseudonymized dataset.</li>
<li>The fact that we can trace the original data back thanks to these mapping dictionaries that are persisted to disk.</li>
</ul>
<p>In this case, when you publish the report to share it with Power BI users, you have the following:</p>
<blockquote>
<p><strong>Note</strong></p>
<p>Power BI users who can only access the dataset will only see the de-identified data. By also providing mapping dictionaries to those with the right permissions, you ensure that they can trace the original data back for any legal needs.</p>
</blockquote>
<p>Did you notice that, thanks to the Python script, you were able to write to file information resulting from the data processing carried out in Power BI?</p>
<blockquote>
<p><strong>Note</strong></p>
<p>Instead of using serialized dictionaries in PKL files, you could have, for example, written the information to <strong>CSV</strong> or Excel files.</p>
</blockquote>
<p>Simply put, you have the ability to log information outside of Power BI. You'll learn more about this possibility in <em>Chapter 7</em>, <em>Logging Data from Power BI to External Repositories</em>.</p>
<p>Let's now see how to implement pseudonymization, also in R.</p>
</section>
<section id="pseudonymizing-data-using-r" class="level3" data-number="7.4.2">
<h3 data-number="7.4.2">Pseudonymizing data using R</h3>
<p>The libraries we will use for data pseudonymization in R are much the same as those used for anonymization in R. To fully simulate the functionality of the Python script developed in the previous section, we also need an R package that generates <em>fake data</em> to replace <em>sensitive data</em>, such as person names and email addresses. In Python, we used the Faker module, one of the most widely used for that purpose. A package with the same functionality has been developed in R, also inspired by the same code used for Faker, and is called <strong>charlatan</strong> (<a href="https://github.com/ropensci/charlatan">https://github.com/ropensci/charlatan</a>). Additionally, the R code for pseudonymization will follow the same logic already implemented in the Python script in the previous section, with minor differences being as follows:</p>
<ul>
<li>Instead of dictionaries, named lists are used for mapping pseudonyms to original entities.</li>
<li>Named lists are serialized and persisted in <strong>RDS</strong> files, instead of PKL files.</li>
</ul>
<p>In order to use the <code>charlatan</code> R package, it must be installed in the latest R engine (in our case, MRO 4.0.2). These are the necessary steps to follow:</p>
<ol>
<li>Open Rstudio, and be sure to select in the <strong>Global Options</strong> the most recent MRO engine you already installed following the steps in <em>Chapter 2</em>, <em>Configuring R with Power BI</em>.</li>
<li><p>Since MRO by definition downloads new packages from a default CRAN snapshot back in time, in order to download the latest version of packages in CRAN you need to overwrite the referenced repository by running the following code:</p>
<pre><code>local({
  r &lt;- getOption(&quot;repos&quot;)
  r[&quot;CRAN&quot;] &lt;- &quot;https://cloud.r-project.org/&quot;
  options(repos = r)
})</code></pre></li>
<li><p>Then, install the <code>charlatan</code> package by running the following code in the console:</p>
<pre><code>install.packages(&quot;charlatan&quot;)</code></pre></li>
</ol>
<p>You are now ready to apply pseudonymization in Power BI to the content of the <code>CustomersCreditCardAttempts.xlsx</code> Excel file using R. So, let’s get started:</p>
<ol>
<li>Open your Power BI Desktop, and make sure the referenced R engine is your latest MRO version in the <strong>Global Options</strong>.</li>
<li>From the ribbon, click on the <strong>Excel</strong> icon to import data from Excel.</li>
<li>From the <strong>Open</strong> dialog box, select the aforementioned <code>CustomersCreditCardAttempts.xlsx</code> file.</li>
<li><p>From the <strong>Navigator</strong> window, select the <strong>Customers</strong> sheet and then click on <strong>Transform Data</strong>:</p>
<figure>
<img src="../media/file171.png" alt="Figure 6.15 – Selecting the Customers sheet and clicking on Transform Data" /><figcaption aria-hidden="true">Figure 6.15 – Selecting the Customers sheet and clicking on Transform Data</figcaption>
</figure></li>
<li>Click on the <strong>Transform</strong> menu and then click on <strong>Run R Script</strong>.</li>
<li>Copy the script from the <code>04-pseudonymize-data-in-power-bi-r.R</code> file into the R script editor and click <strong>OK</strong>. Remember to change the needed paths in the code.</li>
<li>If Power BI needs you to provide it with data privacy information, you already know how to proceed based on what you've seen in <em>Chapter 5</em>, <em>Using Regular Expressions in Power BI</em>.</li>
<li><p>We are only interested in the <code>df</code> dataset. So, click on its <strong>Table</strong> value:</p>
<figure>
<img src="../media/file172.png" alt="Figure 6.16 – Selecting the dataset df as a result of the R script transformation" /><figcaption aria-hidden="true">Figure 6.16 – Selecting the dataset df as a result of the R script transformation</figcaption>
</figure></li>
<li>As you can see, person names in the <code>Name</code> and <code>Notes</code> column and emails in the <code>Email</code> and <code>Notes</code> columns have been correctly anonymized:</li>
</ol>
<figure>
<img src="../media/file173.png" alt="Figure 6.17 – The transformed dataset as the result of the R script" /><figcaption aria-hidden="true">Figure 6.17 – The transformed dataset as the result of the R script</figcaption>
</figure>
<p>You can then click <strong>Close &amp; Apply</strong> in the <strong>Home</strong> tab.</p>
<p>Unfortunately, charlatan does not yet support the <code>it_IT</code> locale. But since it is an open source project, it is possible that it will be implemented by the community soon. This, however, does not prevent us from obtaining a very good pseudonymization of the dataset and of the report that will be published on the Power BI service, since, in the absence of a specific locale, the default one (<code>en_US</code>) is always used.</p>
<p>It has been said that the implementation of de-identification procedures in R is certainly less performant than in Python. However, the gap can be partially bridged by the introduction of parallelization of operations with multitasking. We'll look at this technique in detail in <em>Chapter 8</em>, <em>Calling External APIs To Enrich Your Data</em>.</p>
</section>
</section>
<section id="summary-5" class="level2" data-number="7.5">
<h2 data-number="7.5">Summary</h2>
<p>In this chapter, you learned the main differences between anonymization and pseudonymization. You also learned which techniques are most frequently used to adopt both of the de-identification processes.</p>
<p>You have also applied the process of anonymization by tokenization and the process of pseudonymization by generating similar pseudonyms in Power BI with both Python and R.</p>
<p>In the next chapter, you will learn how to log data derived from operations done with <strong>Power Query</strong> in Power BI to external repositories.</p>
</section>
<section id="references-2" class="level2" data-number="7.6">
<h2 data-number="7.6">References</h2>
<p>For additional reading, check out the following books and articles:</p>
<ol>
<li><em>Pseudonymization, Anonymization and the GDPR</em> (<a href="https://www.termsfeed.com/blog/gdpr-pseudonymization-anonymization/">https://www.termsfeed.com/blog/gdpr-pseudonymization-anonymization/</a>)</li>
<li><em>Symmetric and Asymmetric Encryption</em> (<a href="https://medium.com/hackernoon/symmetric-and-asymmetric-encryption-5122f9ec65b1">https://medium.com/hackernoon/symmetric-and-asymmetric-encryption-5122f9ec65b1</a>)</li>
<li><em>Cryptography with Python Tutorial</em> (<a href="https://www.tutorialspoint.com/cryptography_with_python/">https://www.tutorialspoint.com/cryptography_with_python/</a>)</li>
<li><em>Encryption in R with cyphr</em> (<a href="https://docs.ropensci.org/cyphr/articles/cyphr.html">https://docs.ropensci.org/cyphr/articles/cyphr.html</a>)</li>
</ol>
</section>
</section>
</body>
</html>
