- en: Preface
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 前言
- en: 'It is estimated that in 2013 the whole world produced around 4.4 zettabytes
    of data; that is, 4.4 *billion* terabytes! By 2020, we (as the human race) are
    expected to produce ten times that. With data getting larger literally by the
    second, and given the growing appetite for making sense out of it, in 2004 Google
    employees Jeffrey Dean and Sanjay Ghemawat published the seminal paper *MapReduce:
    Simplified Data Processing on Large Clusters*. Since then, technologies leveraging
    the concept started growing very quickly with Apache Hadoop initially being the
    most popular. It ultimately created a Hadoop ecosystem that included abstraction
    layers such as Pig, Hive, and Mahout – all leveraging this simple concept of map
    and reduce.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 据估计，到2013年，全世界产生了大约4.4泽字节的数据；也就是说，4.4 *十亿* 太字节！到2020年，我们（人类）预计将产生十倍于此的数据。随着数据以每秒
    literally 的速度增长，以及人们对从中获取意义的日益增长的需求，2004年，谷歌员工杰弗里·迪恩和桑杰·格马瓦特发表了开创性的论文 *MapReduce：在大型集群上简化数据处理*。从那时起，利用这一概念的技术开始迅速增长，Apache
    Hadoop最初是最受欢迎的。它最终创建了一个包括Pig、Hive和Mahout等抽象层的Hadoop生态系统——所有这些都利用了简单的map和reduce概念。
- en: However, even though capable of chewing through petabytes of data daily, MapReduce
    is a fairly restricted programming framework. Also, most of the tasks require
    reading and writing to disk. Seeing these drawbacks, in 2009 Matei Zaharia started
    working on Spark as part of his PhD. Spark was first released in 2012\. Even though
    Spark is based on the same MapReduce concept, its advanced ways of dealing with
    data and organizing tasks make it 100x faster than Hadoop (for in-memory computations).
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，尽管MapReduce每天能够处理PB级的数据，但它仍然是一个相当受限的编程框架。此外，大多数任务都需要读写磁盘。看到这些缺点，2009年，Matei
    Zaharia开始在他的博士期间研究Spark。Spark最初于2012年发布。尽管Spark基于相同的MapReduce概念，但它处理数据和组织任务的高级方式使其比Hadoop（对于内存计算）快100倍。
- en: In this book, we will guide you through the latest incarnation of Apache Spark
    using Python. We will show you how to read structured and unstructured data, how
    to use some fundamental data types available in PySpark, build machine learning
    models, operate on graphs, read streaming data, and deploy your models in the
    cloud. Each chapter will tackle different problem, and by the end of the book
    we hope you will be knowledgeable enough to solve other problems we did not have
    space to cover here.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书中，我们将使用Python引导您了解Apache Spark的最新版本。我们将向您展示如何读取结构化和非结构化数据，如何使用PySpark中的一些基本数据类型，构建机器学习模型，操作图，读取流数据，并在云中部署您的模型。每一章都将解决不同的问题，到本书结束时，我们希望您能够足够了解以解决我们没有空间在此处涵盖的其他问题。
- en: What this book covers
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书涵盖的内容
- en: '[Chapter 1](ch01.html "Chapter 1. Understanding Spark"), *Understanding Spark*,
    provides an introduction into the Spark world with an overview of the technology
    and the jobs organization concepts.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[第1章](ch01.html "第1章。理解Spark")，*理解Spark*，介绍了Spark世界，概述了技术和作业组织概念。'
- en: '[Chapter 2](ch02.html "Chapter 2. Resilient Distributed Datasets"), *Resilient
    Distributed Datasets*, covers RDDs, the fundamental, schema-less data structure
    available in PySpark.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[第2章](ch02.html "第2章。弹性分布式数据集")，*弹性分布式数据集*，涵盖了RDD，这是PySpark中可用的基本、无模式的数据库结构。'
- en: '[Chapter 3](ch03.html "Chapter 3. DataFrames"), *DataFrames*, provides a detailed
    overview of a data structure that bridges the gap between Scala and Python in
    terms of efficiency.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[第3章](ch03.html "第3章。DataFrame")，*DataFrame*，提供了关于一种数据结构的详细概述，这种数据结构在效率方面连接了Scala和Python之间的差距。'
- en: '[Chapter 4](ch04.html "Chapter 4. Prepare Data for Modeling"), *Prepare Data
    for Modeling*, guides the reader through the process of cleaning up and transforming
    data in the Spark environment.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[第4章](ch04.html "第4章。为建模准备数据")，*为建模准备数据*，指导读者在Spark环境中清理和转换数据的过程。'
- en: '[Chapter 5](ch05.html "Chapter 5. Introducing MLlib"), *Introducing MLlib*,
    introduces the machine learning library that works on RDDs and reviews the most
    useful machine learning models.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '[第5章](ch05.html "第5章。介绍MLlib")，*介绍MLlib*，介绍了在RDD上工作的机器学习库，并回顾了最有用的机器学习模型。'
- en: '[Chapter 6](ch06.html "Chapter 6. Introducing the ML Package"), *Introducing
    the ML Package*, covers the current mainstream machine learning library and provides
    an overview of all the models currently available.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[第6章](ch06.html "第6章。介绍ML包")，*介绍ML包*，涵盖了当前主流的机器学习库，并概述了目前所有可用的模型。'
- en: '[Chapter 7](ch07.html "Chapter 7. GraphFrames"), *GraphFrames*, will guide
    you through the new structure that makes solving problems with graphs easy.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[第7章](ch07.html "第7章。GraphFrames"), *GraphFrames*，将引导您了解一种新的结构，使使用图解决问题变得简单。'
- en: '[Chapter 8](ch08.html "Chapter 8. TensorFrames"), *TensorFrames*, introduces
    the bridge between Spark and the Deep Learning world of TensorFlow.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[第8章](ch08.html "第8章。TensorFrames"), *TensorFrames*，介绍了Spark与TensorFlow深度学习世界之间的桥梁。'
- en: '[Chapter 9](ch09.html "Chapter 9. Polyglot Persistence with Blaze"), *Polyglot
    Persistence with Blaze*, describes how Blaze can be paired with Spark for even
    easier abstraction of data from various sources.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[第9章](ch09.html "第9章。使用Blaze的多语言持久性"), *使用Blaze的多语言持久性*，描述了Blaze如何与Spark配合使用，以便更容易地从各种来源抽象数据。'
- en: '[Chapter 10](ch10.html "Chapter 10. Structured Streaming"), *Structured Streaming*,
    provides an overview of streaming tools available in PySpark.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[第10章](ch10.html "第10章。结构化流"), *结构化流*，提供了PySpark中可用的流工具概述。'
- en: '[Chapter 11](ch11.html "Chapter 11. Packaging Spark Applications"), *Packaging
    Spark Applications*, will guide you through the steps of modularizing your code
    and submitting it for execution to Spark through command-line interface.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[第11章](ch11.html "第11章。打包Spark应用程序"), *打包Spark应用程序*，将引导您了解将代码模块化并通过命令行界面提交到Spark以执行步骤。'
- en: 'For more information, we have provided two bonus chapters as follows:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 更多信息，我们提供了以下两个附加章节：
- en: '*Installing Spark*: [https://www.packtpub.com/sites/default/files/downloads/InstallingSpark.pdf](https://www.packtpub.com/sites/default/files/downloads/InstallingSpark.pdf)'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '*安装Spark*: [https://www.packtpub.com/sites/default/files/downloads/InstallingSpark.pdf](https://www.packtpub.com/sites/default/files/downloads/InstallingSpark.pdf)'
- en: '*Free Spark Cloud Offering*: [https://www.packtpub.com/sites/default/files/downloads/FreeSparkCloudOffering.pdf](https://www.packtpub.com/sites/default/files/downloads/FreeSparkCloudOffering.pdf)'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '*免费Spark云服务*: [https://www.packtpub.com/sites/default/files/downloads/FreeSparkCloudOffering.pdf](https://www.packtpub.com/sites/default/files/downloads/FreeSparkCloudOffering.pdf)'
- en: What you need for this book
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 您需要为本书准备什么
- en: For this book you need a personal computer (can be either Windows machine, Mac,
    or Linux). To run Apache Spark, you will need Java 7+ and an installed and configured
    Python 2.6+ or 3.4+ environment; we use the Anaconda distribution of Python in
    version 3.5, which can be downloaded from [https://www.continuum.io/downloads](https://www.continuum.io/downloads).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 为了阅读本书，您需要一个个人电脑（可以是Windows机器、Mac或Linux）。要运行Apache Spark，您将需要Java 7+以及安装并配置好的Python
    2.6+或3.4+环境；我们使用的是Python 3.5版本的Anaconda发行版，可以从[https://www.continuum.io/downloads](https://www.continuum.io/downloads)下载。
- en: 'The Python modules we randomly use throughout the book come preinstalled with
    Anaconda. We also use GraphFrames and TensorFrames that can be loaded dynamically
    while starting a Spark instance: to load these you just need an Internet connection.
    It is fine if some of those modules are not currently installed on your machine
    – we will guide you through the installation process.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本书中随机使用的Python模块都是Anaconda预安装的。我们还使用了GraphFrames和TensorFrames，这些模块可以在启动Spark实例时动态加载：要加载这些模块，您只需要一个互联网连接。如果这些模块中的一些目前没有安装到您的机器上，也没有关系——我们将引导您完成安装过程。
- en: Who this book is for
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书面向对象
- en: 'This book is for everyone who wants to learn the fastest-growing technology
    in big data: Apache Spark. We hope that even the more advanced practitioners from
    the field of data science can find some of the examples refreshing and the more
    advanced topics interesting.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 本书面向所有希望学习大数据中增长最快的技术的读者：Apache Spark。我们希望即使是数据科学领域的资深从业者也能发现一些示例令人耳目一新，一些高级主题引人入胜。
- en: Conventions
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 规范
- en: In this book, you will find a number of styles of text that distinguish between
    different kinds of information. Here are some examples of these styles, and an
    explanation of their meaning.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，您将找到多种文本样式，用于区分不同类型的信息。以下是一些这些样式的示例及其含义的解释。
- en: 'Code words in text, database table names, folder names, filenames, file extensions,
    pathnames, dummy URLs, user input, and Twitter handles are shown as follows:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 文本中的代码单词、数据库表名、文件夹名、文件名、文件扩展名、路径名、虚拟URL、用户输入和Twitter用户名显示如下：
- en: 'A block of code is set as follows:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 代码块设置如下：
- en: '[PRE0]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'When we wish to draw your attention to a particular part of a code block, the
    relevant lines or items are set in bold:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们希望您注意代码块中的特定部分时，相关的行或项目将以粗体显示：
- en: '[PRE1]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Any command-line input or output is written as follows:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 任何命令行输入或输出都按以下方式编写：
- en: '[PRE2]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**New terms** and **important words** are shown in bold. Words that you see
    on the screen, in menus or dialog boxes for example, appear in the text like this:
    "Clicking the **Next** button moves you to the next screen."'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**新术语**和**重要词汇**将以粗体显示。你会在屏幕上看到这些词汇，例如在菜单或对话框中，文本将显示为：“点击**下一步**按钮将你带到下一屏幕。”'
- en: Note
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Warnings or important notes appear in a box like this.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 警告或重要注意事项将以如下框显示。
- en: Tip
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: Tips and tricks appear like this.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 小贴士和技巧看起来像这样。
- en: Reader feedback
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 读者反馈
- en: Feedback from our readers is always welcome. Let us know what you think about
    this book—what you liked or may have disliked. Reader feedback is important for
    us to develop titles that you really get the most out of.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们始终欢迎读者的反馈。告诉我们你对这本书的看法——你喜欢什么或可能不喜欢什么。读者反馈对我们开发你真正能从中获得最大收益的标题非常重要。
- en: To send us general feedback, simply send an e-mail to `<[feedback@packtpub.com](mailto:feedback@packtpub.com)>`,
    and mention the book title via the subject of your message.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 要发送一般反馈，请简单地将电子邮件发送到`<[feedback@packtpub.com](mailto:feedback@packtpub.com)>`，并在邮件主题中提及书籍标题。
- en: If there is a topic that you have expertise in and you are interested in either
    writing or contributing to a book, see our author guide on [www.packtpub.com/authors](http://www.packtpub.com/authors).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在某个领域有专业知识，并且对撰写或参与书籍感兴趣，请参阅我们的作者指南：[www.packtpub.com/authors](http://www.packtpub.com/authors)。
- en: Customer support
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 客户支持
- en: Now that you are the proud owner of a Packt book, we have a number of things
    to help you to get the most from your purchase.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经是Packt书籍的骄傲拥有者，我们有一些东西可以帮助你从购买中获得最大收益。
- en: Downloading the example code
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 下载示例代码
- en: You can download the example code files for all Packt books you have purchased
    from your account at [http://www.packtpub.com](http://www.packtpub.com). If you
    purchased this book elsewhere, you can visit [http://www.packtpub.com/support](http://www.packtpub.com/support)
    and register to have the files e-mailed directly to you.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从[http://www.packtpub.com](http://www.packtpub.com)的账户下载你购买的所有Packt书籍的示例代码文件。如果你在其他地方购买了这本书，你可以访问[http://www.packtpub.com/support](http://www.packtpub.com/support)并注册，以便将文件直接通过电子邮件发送给你。
- en: 'All the code is also available on GitHub: [https://github.com/drabastomek/learningPySpark](https://github.com/drabastomek/learningPySpark).'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 所有代码也都在GitHub上提供：[https://github.com/drabastomek/learningPySpark](https://github.com/drabastomek/learningPySpark)。
- en: 'You can download the code files by following these steps:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过以下步骤下载代码文件：
- en: Log in or register to our website using your e-mail address and password.
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 登录或使用电子邮件地址和密码注册我们的网站。
- en: Hover the mouse pointer on the **SUPPORT** tab at the top.
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将鼠标指针悬停在顶部的**支持**标签上。
- en: Click on **Code Downloads & Errata**.
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**代码下载与勘误**。
- en: Enter the name of the book in the **Search** box.
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**搜索**框中输入书籍名称。
- en: Select the book for which you're looking to download the code files.
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择你想要下载代码文件的书籍。
- en: Choose from the drop-down menu where you purchased this book from.
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从下拉菜单中选择你购买此书籍的地方。
- en: Click on **Code Download**.
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**代码下载**。
- en: 'Once the file is downloaded, please make sure that you unzip or extract the
    folder using the latest version of:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 文件下载完成后，请确保使用最新版本解压缩或提取文件夹：
- en: WinRAR / 7-Zip for Windows
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: WinRAR / 7-Zip for Windows
- en: Zipeg / iZip / UnRarX for Mac
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zipeg / iZip / UnRarX for Mac
- en: 7-Zip / PeaZip for Linux
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 7-Zip / PeaZip for Linux
- en: The code bundle for the book is also hosted on GitHub at [https://github.com/PacktPublishing/Learning-PySpark](https://github.com/PacktPublishing/Learning-PySpark).
    We also have other code bundles from our rich catalog of books and videos available
    at [https://github.com/PacktPublishing/](https://github.com/PacktPublishing/).
    Check them out!
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 本书代码包也托管在GitHub上：[https://github.com/PacktPublishing/Learning-PySpark](https://github.com/PacktPublishing/Learning-PySpark)。我们还有其他来自我们丰富图书和视频目录的代码包可供选择，可在[https://github.com/PacktPublishing/](https://github.com/PacktPublishing/)找到。查看它们吧！
- en: Downloading the color images of this book
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 下载本书的彩色图像
- en: We also provide you with a PDF file that has color images of the screenshots/diagrams
    used in this book. The color images will help you better understand the changes
    in the output. You can download this file from [https://www.packtpub.com/sites/default/files/downloads/LearningPySpark_ColorImages.pdf](https://www.packtpub.com/sites/default/files/downloads/LearningPySpark_ColorImages.pdf).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还提供了一份包含本书中使用的截图/图表彩色图像的PDF文件。彩色图像将帮助你更好地理解输出的变化。你可以从[https://www.packtpub.com/sites/default/files/downloads/LearningPySpark_ColorImages.pdf](https://www.packtpub.com/sites/default/files/downloads/LearningPySpark_ColorImages.pdf)下载此文件。
- en: Errata
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 勘误
- en: Although we have taken every care to ensure the accuracy of our content, mistakes
    do happen. If you find a mistake in one of our books—maybe a mistake in the text
    or the code—we would be grateful if you would report this to us. By doing so,
    you can save other readers from frustration and help us improve subsequent versions
    of this book. If you find any errata, please report them by visiting [http://www.packtpub.com/submit-errata](http://www.packtpub.com/submit-errata),
    selecting your book, clicking on the **errata** **submission** **form** link,
    and entering the details of your errata. Once your errata are verified, your submission
    will be accepted and the errata will be uploaded on our website, or added to any
    list of existing errata, under the Errata section of that title. Any existing
    errata can be viewed by selecting your title from [http://www.packtpub.com/support](http://www.packtpub.com/support).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们已经尽最大努力确保内容的准确性，错误仍然可能发生。如果您在我们的某本书中发现错误——可能是文本或代码中的错误——如果您能向我们报告这一点，我们将不胜感激。通过这样做，您可以避免其他读者感到沮丧，并帮助我们改进本书的后续版本。如果您发现任何勘误，请通过访问[http://www.packtpub.com/submit-errata](http://www.packtpub.com/submit-errata)，选择您的书籍，点击**勘误提交表单**链接，并输入您的勘误详情来报告它们。一旦您的勘误得到验证，您的提交将被接受，勘误将被上传到我们的网站，或添加到该标题的勘误部分下的现有勘误列表中。您可以通过从[http://www.packtpub.com/support](http://www.packtpub.com/support)选择您的标题来查看任何现有的勘误。
- en: Piracy
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 侵权
- en: Piracy of copyright material on the Internet is an ongoing problem across all
    media. At Packt, we take the protection of our copyright and licenses very seriously.
    If you come across any illegal copies of our works, in any form, on the Internet,
    please provide us with the location address or website name immediately so that
    we can pursue a remedy.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 互联网上版权材料的侵权是一个跨所有媒体持续存在的问题。在Packt，我们非常重视我们版权和许可证的保护。如果您在互联网上发现我们作品的任何非法副本，无论形式如何，请立即提供位置地址或网站名称，以便我们可以寻求补救措施。
- en: Please contact us at `<[copyright@packtpub.com](mailto:copyright@packtpub.com)>`
    with a link to the suspected pirated material.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在本书的任何方面遇到问题，请通过 `<[copyright@packtpub.com](mailto:copyright@packtpub.com)>`
    联系我们，并提供疑似侵权材料的链接。
- en: We appreciate your help in protecting our authors, and our ability to bring
    you valuable content.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们感谢您在保护我们的作者和我们为您提供有价值内容的能力方面提供的帮助。
- en: Questions
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 询问
- en: You can contact us at `<[questions@packtpub.com](mailto:questions@packtpub.com)>`
    if you are having a problem with any aspect of the book, and we will do our best
    to address it.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在本书的任何方面遇到问题，请通过 `<[questions@packtpub.com](mailto:questions@packtpub.com)>`
    联系我们，我们将尽力解决。
