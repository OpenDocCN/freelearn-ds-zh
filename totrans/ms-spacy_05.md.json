["```py\n spacy.explain(\"NNS)\n'noun, plural'\n doc = nlp(\"I saw flowers.\")\n token = doc[2]\n token.text, token.tag_, spacy.explain(token.tag_)\n('flowers', 'NNS', 'noun, plural')\n```", "```py\n import spacy\n nlp = spacy.load(\"en_core_web_md\")\n doc = nlp(\"Alicia and me went to the school by bus.\")\n for token in doc:\n     token.text, token.pos_, token.tag_, \\\n     spacy.explain(token.pos_), spacy.explain(token.tag_)\n...\n('Alicia', 'PROPN', 'NNP', 'proper noun', 'noun, proper singular')\n('and', 'CCONJ', 'CC', 'coordinating conjunction', 'conjunction, coordinating')\n('me', 'PRON', 'PRP', 'pronoun', 'pronoun, personal')\n('went', 'VERB', 'VBD', 'verb', 'verb, past tense')\n('to', 'ADP', 'IN', 'adposition', 'conjunction, subordinating or preposition')\n('school', 'NOUN', 'NN', 'noun', 'noun, singular or mass')\n('with', 'ADP', 'IN', 'adposition', 'conjunction, subordinating or preposition')\n('bus', 'NOUN', 'NN', 'noun', 'noun, singular or mass')\n('.', 'PUNCT', '.', 'punctuation', 'punctuation mark, sentence closer')\n```", "```py\n doc = nlp(\"My friend will fly to New York fast and she is staying there for 3 days.\")\n for token in doc:\n     token.text, token.pos_, token.tag_, \\\n     spacy.explain(token.pos_), spacy.explain(token.tag_)\n…\n('My', 'DET', 'PRP$', 'determiner', 'pronoun, possessive')\n('friend', 'NOUN', 'NN', 'noun', 'noun, singular or mass')\n('will', 'VERB', 'MD', 'verb', 'verb, modal auxiliary')\n('fly', 'VERB', 'VB', 'verb', 'verb, base form')\n('to', 'ADP', 'IN', 'adposition', 'conjunction, subordinating or preposition')\n('New', 'PROPN', 'NNP', 'proper noun', 'noun, proper singular')\n('York', 'PROPN', 'NNP', 'proper noun', 'noun, proper singular')\n('fast', 'ADV', 'RB', 'adverb', 'adverb')\n('and', 'CCONJ', 'CC', 'coordinating conjunction', 'conjunction, coordinating')\n('she', 'PRON', 'PRP', 'pronoun', 'pronoun, personal')\n('is', 'AUX', 'VBZ', 'auxiliary', 'verb, 3rd person singular present')\n('staying', 'VERB', 'VBG', 'verb', 'verb, gerund or present participle')\n('there', 'ADV', 'RB', 'adverb', 'adverb')\n('for', 'ADP', 'IN', 'adposition', 'conjunction, subordinating or preposition')\n('3', 'NUM', 'CD', 'numeral', 'cardinal number')\n('days', 'NOUN', 'NNS', 'noun', 'noun, plural')\n('.', 'PUNCT', '.', 'punctuation', 'punctuation mark, sentence closer')\n```", "```py\n doc = nlp(\"I will ship the package tomorrow.\")\n for token in doc:\n     token.text, token.tag_, spacy.explain(token.tag_)\n... \n('I', 'PRP', 'pronoun, personal')\n('will', 'MD', 'verb, modal auxiliary')\n('ship', 'VB', 'verb, base form')\n('the', 'DT', 'determiner')\n('package', 'NN', 'noun, singular or mass')\n('tomorrow', 'NN', 'noun, singular or mass')\n('.', '.', 'punctuation mark, sentence closer') \n```", "```py\n doc = nlp(\"I saw a red ship.\")\n for token in doc:\n...  token.text, token.tag_, spacy.explain(token.tag_)\n... \n('I', 'PRP', 'pronoun, personal')\n('saw', 'VBD', 'verb, past tense')\n('a', 'DT', 'determiner')\n('red', 'JJ', 'adjective')\n('ship', 'NN', 'noun, singular or mass')\n('.', '.', 'punctuation mark, sentence closer')\n```", "```py\n doc = nlp(\"My cat will fish for a fish tomorrow in a fishy way.\")\n for token in doc:\n     token.text, token.pos_, token.tag_, \\\n     spacy.explain(token.pos_), spacy.explain(token.tag_)\n…\n('My', 'DET', 'PRP$', 'determiner', 'pronoun, possessive')\n('cat', 'NOUN', 'NN', 'noun', 'noun, singular or mass')\n('will', 'VERB', 'MD', 'verb', 'verb, modal auxiliary')\n('fish', 'VERB', 'VB', 'verb', 'verb, base form')\n('for', 'ADP', 'IN', 'adposition', 'conjunction, subordinating or preposition')\n('a', 'DET', 'DT', 'determiner', 'determiner')\n('fish', 'NOUN', 'NN', 'noun', 'noun, singular or mass')\n('tomorrow', 'NOUN', 'NN', 'noun', 'noun, singular or mass')\n('in', 'ADP', 'IN', 'adposition', 'conjunction, subordinating or preposition')\n('a', 'DET', 'DT', 'determiner', 'determiner')\n('fishy', 'ADJ', 'JJ', 'adjective', 'adjective')\n('way', 'NOUN', 'NN', 'noun', 'noun, singular or mass')\n('.', 'PUNCT', '.', 'punctuation', 'punctuation mark, sentence closer')\n```", "```py\nI will fish/VB tomorrow.  ->  Pescaré/V mañana.\nI eat fish/NN.  -> Como pescado/N.\n```", "```py\nI flew to Rome.\nI have flown to Rome.\nI'm flying to Rome.\nI need to fly to Rome.\nI will fly to Rome.\n```", "```py\nI flew to Rome 3 days ago. I still didn't get the bill, please send it ASAP.\nI have flown to Rome this morning and forgot my laptop on the airplane. Can you please connect me to lost and found?\nI'm flying to Rome next week. Can you check flight availability?\nI need to fly to Rome. Can you check flights on next Tuesday?\nI will fly to Rome next week. Can you check the flights?   \n```", "```py\n sent1 = \"I flew to Rome\".\n sent2 = \"I'm flying to Rome.\"\n sent3 = \"I will fly to Rome.\" \n doc1 = nlp(sent1)\n doc2 = nlp(sent2)\n doc3 = nlp(sent3)\n for doc in [doc1, doc2, doc3]\n     print([(w.text, w.lemma_) for w in doc if w.tag_== 'VBG' or w.tag_== 'VB'])\n... \n[]\n[('flying', 'fly')]\n[('fly', 'fly')]\n```", "```py\nflying: (fly, VBG)\n```", "```py\n doc = nlp(\"He earned $5.5 million in 2020 and paid %35 tax.\")\n for token in doc:\n     token.text, token.tag_, spacy.explain(token.tag_)\n... \n('He', 'PRP', 'pronoun, personal')\n('earned', 'VBD', 'verb, past tense')\n('$', '$', 'symbol, currency')\n('5.5', 'CD', 'cardinal number')\n('million', 'CD', 'cardinal number')\n('in', 'IN', 'conjunction, subordinating or preposition')\n('2020', 'CD', 'cardinal number')\n('and', 'CC', 'conjunction, coordinating')\n('paid', 'VBD', 'verb, past tense')\n('35', 'CD', 'cardinal number')\n('percent', 'NN', 'noun, singular or mass')\n('tax', 'NN', 'noun, singular or mass')\n('.', '.', 'punctuation mark, sentence closer')\n```", "```py\nI forwarded you the email. -> forwarded email\nYou forwarded me the email. -> forwarded email\n```", "```py\n doc = nlp(\"blue flower\")\n for token in doc:\n     token.text, token.dep_\n…\n('blue', 'amod')\n('flower', 'ROOT')\n```", "```py\n spacy.explain(\"nsubj\")\n'nominal subject'\n doc = nlp(\"I own a ginger cat.\")\n token = doc[4]\n token.text, token.dep_, spacy.explain(token.dep_)\n('cat', 'dobj', 'direct object')\n```", "```py\n doc = nlp(\"I counted white sheep.\")\n for token in doc:\n     token.text, token.pos_, token.dep_\n... \n('I', 'PRP', 'nsubj')\n('counted', 'VBD', 'ROOT')\n('white', 'JJ', 'amod')\n('sheep', 'NNS', 'dobj')\n('.', '.', 'punct') \n```", "```py\n doc = nlp(“I counted white sheep.”) \nfor token in doc:\n      token.text, token.tag_, token.dep_, token.head\n... \n('I', 'PRP', 'nsubj', counted)\n('counted', 'VBD', 'ROOT', counted)\n('white', 'JJ', 'amod', sheep)\n('sheep', 'NNS', 'dobj', counted)\n('.', '.', 'punct', counted)\n```", "```py\n doc = nlp(\"We are trying to understand the difference.\")\n for token in doc:\n     token.text, token.tag_, token.dep_, token.head\n... \n('We', 'PRP', 'nsubj', trying)\n('are', 'VBP', 'aux', trying)\n('trying', 'VBG', 'ROOT', trying)\n('to', 'TO', 'aux', understand)\n('understand', 'VB', 'xcomp', trying)\n('the', 'DT', 'det', difference)\n('difference', 'NN', 'dobj', understand)\n('.', '.', 'punct', trying)\n```", "```py\n doc = nlp(\"Queen Katherine, who was the mother of Mary Tudor, died at 1536.\")\n for token in doc:\n     token.text, token.tag_, token.dep_, token.head\n... \n('Queen', 'NNP', 'compound', Katherine)\n('Katherine', 'NNP', 'nsubj', died)\n(',', ',', 'punct', Katherine)\n('who', 'WP', 'nsubj', was)\n('was', 'VBD', 'relcl', Katherine)\n('the', 'DT', 'det', mother)\n('mother', 'NN', 'attr', was)\n('of', 'IN', 'prep', mother)\n('Mary', 'NNP', 'compound', Tudor)\n('Tudor', 'NNP', 'pobj', of)\n(',', ',', 'punct', Katherine)\n('died', 'VBD', 'ROOT', died)\n('at', 'IN', 'prep', died)\n('1536', 'CD', 'pobj', at)\n```", "```py\n doc = nlp(\"The president Donald Trump visited France.\")\n doc.ents\n(Donald Trump, France)\n type(doc.ents[1])\n<class 'spacy.tokens.span.Span'>\n```", "```py\n spacy.explain(\"ORG\")\n'Companies, agencies, institutions, etc.\n doc = nlp(\"He worked for NASA.\")\n token = doc[3]\n token.ent_type_, spacy.explain(token.ent_type_)\n('ORG', 'Companies, agencies, institutions, etc.') \n```", "```py\n doc = nlp(\"Albert Einstein was born in Ulm on 1879\\. He studied electronical engineering at ETH Zurich.\")\n doc.ents\n(Albert Einstein, Ulm, 1879, ETH Zurich)\n for token in doc:\n     token.text, token.ent_type_, \\\n     spacy.explain(token.ent_type_)\n... \n('Albert', 'PERSON', 'People, including fictional')\n('Einstein', 'PERSON', 'People, including fictional')\n('was', '', None)\n('born', '', None)\n('in', '', None)\n('Ulm', 'GPE', 'Countries, cities, states')\n('on', '', None)\n('1879', 'DATE', 'Absolute or relative dates or periods')\n('.', '', None)\n('He', '', None)\n('studied', '', None)\n('electronical', '', None)\n('engineering', '', None)\n('at', '', None)\n('ETH', 'ORG', 'Companies, agencies, institutions, etc.')\n('Zurich', 'ORG', 'Companies, agencies, institutions, etc.')\n('.', '', None)\n```", "```py\n doc = nlp(\"Jean-Michel Basquiat was an American artist of Haitian and Puerto Rican descent who gained fame with his graffiti and street art work\")\n doc.ents\n(Jean-Michel Basquiat, American, Haitian, Puerto Rican)\n for ent in doc.ents:\n     ent, ent.label_, spacy.explain(ent.label_)\n... \n(Jean-Michel Basquiat, 'PERSON', 'People, including fictional')\n(American, 'NORP', 'Nationalities or religious or political groups')\n(Haitian, 'NORP', 'Nationalities or religious or political groups')\n(Puerto Rican, 'NORP', 'Nationalities or religious or political groups')\n```", "```py\nfrom bs4 import BeautifulSoup\nimport requests\nimport spacy\ndef url_text(url_string):\n    res = requests.get(url)\n    html = res.text\n    soup = BeautifulSoup(html, 'html5lib')\n    for script in soup([\"script\", \"style\", 'aside']):\n        script.extract()\n    text = soup.get_text()\n    return \" \".join(text.split())\nny_art = url_text(\"https://www.nytimes.com/2021/01/12/opinion/trump-america-allies.html\")\nnlp = spacy.load(\"en_core_web_md\")\ndoc = nlp(ny_art)\n```", "```py\nlen(doc.ents)\n136\n```", "```py\nfrom collections import Counter\nlabels = [ent.label_ for ent in doc.ents]\nCounter(labels)\nCounter({'GPE': 37, 'PERSON': 30, 'NORP': 24, 'ORG': 22, 'DATE': 13, 'CARDINAL': 3, 'FAC': 2, 'LOC': 2, 'EVENT': 1, 'TIME': 1, 'WORK_OF_ART': 1})\n```", "```py\nitems = [ent.text for ent in doc.ents]\nCounter(items).most_common(10)\n[('America', 12), ('American', 8), ('Biden', 8), ('China', 6), ('Trump', 5), ('Capitol', 4), ('the United States', 3), ('Washington', 3), ('Europeans', 3), ('Americans', 3)]\n```", "```py\nprint(doc.ents)\n(The New York Times SectionsSEARCHSkip, indexLog inToday, storyOpinionSupported byContinue, LaughingstockLast week's, U.S., U.S., Ivan KrastevMr, Krastev, Jan., 2021  A, Rome, Donald Tramp, Thursday, Andrew Medichini, Associated PressDonald Trump, America, America, Russian, Chinese, Iranian, Jan. 6, Capitol, Ukraine, Georgia, American, American, the United States, Trump, American, Congress, Civil War, 19th-century, German, Otto von Bismarck, the United States of America, America, Capitol, Trump, last hours, American, American, Washington, Washington, Capitol, America, America, Russia, at least 10, Four years, Trump, Joe Biden, two, American, China, Biden, America, Trump, Recep Tayyip Erdogan, Turkey, Jair Bolsonaro, Brazil, Washington, Russia, China, Biden, Gianpaolo Baiocchi, H. Jacob Carlson, Social Housing Development Authority, Ezra Klein, Biden, Mark Bittman, Biden, Gail Collins, Joe Biden, Jake Sullivan, Biden, trans-Atlantic, China, Just a week ago, European, Sullivan, Europe, America, China, Biden, Europeans, China, German, Chinese, the European Union's, America, Christophe Ena, the European Council on Foreign Relations, the weeks, American, the day, Biden, Europeans, America, the next 10 years, China, the United States, Germans, Trump, Americans, Congress, America, Bill Clinton, Americans, Biden, the White House, the United States, Americans, Europeans, the past century, America, the days, Capitol, democratic, Europe, American, America, Ivan Krastev, the Center for Liberal Strategies, the Institute for Human Sciences, Vienna, Is It Tomorrow Yet?:, The New York Times Opinion, Facebook, Twitter (@NYTopinion, Instagram, AdvertisementContinue, IndexSite Information Navigation© 2021, The New York Times, GTM, tfAzqo1rYDLgYhmTnSjPqw&gtm_preview)\n```", "```py\n doc = nlp(\"She lived in New Hampshire.\")\n doc.ents\n(New Hampshire,)\n [(token.text, token.i) for token in doc]\n[('She', 0), ('lived', 1), ('in', 2), ('New', 3), ('Hampshire', 4), ('.', 5)]\n len(doc)\n6\n with doc.retokenize() as retokenizer:\n     retokenizer.merge(doc[3:5], \\\n     attrs={\"LEMMA\": \"new hampshire\"})\n... \n [(token.text, token.i) for token in doc]\n[('She', 0), ('lived', 1), ('in', 2), ('New Hampshire', 3), ('.', 4)]\n len(doc)\n5\n doc.ents\n(New Hampshire,)\n [(token.lemma_) for token in doc]\n['-PRON-', 'live', 'in', 'new hampshire', '.']\n```", "```py\n doc = nlp(\"She lived in NewHampshire\")\n len(doc)\n5\n [(token.text, token.lemma_, token.i) for token in doc]\n[('She', '-PRON-', 0), ('lived', 'live', 1), ('in', 'in', 2), ('NewHampshire', 'NewHampshire', 3), ('.', '.', 4)]\n for token in doc:\n     token.text, token.pos_, token.tag_, token.dep_\n... \n('She', 'PRON', 'PRP', 'nsubj')\n('lived', 'VERB', 'VBD', 'ROOT')\n('in', 'ADP', 'IN', 'prep')\n('NewHampshire', 'PROPN', 'NNP', 'pobj')\n('.', 'PUNCT', '.', 'punct')\n```", "```py\n with doc.retokenize() as retokenizer:\n     heads = [(doc[3], 1), doc[2]]\n     attrs = {\"TAG\":[\"NNP\", \"NNP\"], \n              \"DEP\": [\"compound\", \"pobj\"]}\n     retokenizer.split(doc[3], [\"New\", \"Hampshire\"], \n                       heads=heads, attrs=attrs)\n... \n [(token.text, token.lemma_, token.i) for token in doc]\n[('She', '-PRON-', 0), ('lived', 'live', 1), ('in', 'in', 2), ('New', 'New', 3), ('Hampshire', 'Hampshire', 4), ('.', '.', 5)]\n for token in doc:\n     token.text, token.pos_, token.tag_, token.dep_\n... \n('She', 'PRON', 'PRP', 'nsubj')\n('lived', 'VERB', 'VBD', 'ROOT')\n('in', 'ADP', 'IN', 'prep')\n('New', 'PROPN', 'NNP', 'pobj')\n('Hampshire', 'PROPN', 'NNP', 'compound')\n('.', 'PUNCT', '.', 'punct')\n len(doc)\n6\n```"]