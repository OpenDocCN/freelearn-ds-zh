<html><head></head><body><div><div><div><div><h1 class="title"><a id="ch08"/>Chapter 8. A/B Testing – Statistical Experiments for the Web</h1></div></div></div><p>One of the most common uses of statistics on the Internet right now is <a id="id577" class="indexterm"/>
<strong>A/B testing</strong>. This acts as an aid to design and increase interactions with users in a data-driven way. It's used all over the Web, and there have been some high-profile instances of these techniques being written about in blogs and articles online. For instance, there were several descriptions of how Baraka Obama's 2012 US Presidential campaign used A/B testing to increase both donations and how many people signed up for the e-mail updates.</p><p>Over the course of this chapter, we'll look at the following topics:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Defining A/B testing</li><li class="listitem" style="list-style-type: disc">Conducting an A/B test</li><li class="listitem" style="list-style-type: disc">Analyzing the results</li></ul></div><p>By the end, we'll have simulated a small A/B test to measure a click-through on two different versions of text for a button.</p><div><div><div><div><h1 class="title"><a id="ch08lvl1sec56"/>Defining A/B testing</h1></div></div></div><p>At its most fundamental level, A/B testing<a id="id578" class="indexterm"/> just involves creating two different versions of a web page. Sometimes, the changes are major redesigns of the site or the user experience, but usually, the changes are as simple as changing the text on a button. Then, for a short period of time, new visitors are randomly shown one of the two versions of the page. The site tracks their behavior, and the experiment determines whether one version or the other increases the users' interaction with the site. This may mean more click-through, more purchases, or any other measurable behavior.</p><p>This is similar to other methods in other domains that use different names. The basic framework randomly tests two or more groups simultaneously and is sometimes called random-controlled experiments<a id="id579" class="indexterm"/> or online-controlled experiments. It's also <a id="id580" class="indexterm"/>sometimes referred to as split testing, as the participants are split into two groups.</p><p>These are all examples of <a id="id581" class="indexterm"/>
<strong>between-subjects experiment design</strong>. Experiments that use these designs all split the participants into two groups. One group, the control group, gets the original environment. The other group, the test group, gets the modified environment that those conducting the experiment are interested in testing.</p><p>Experiments of this sort can be <strong>single-blind</strong> or <strong>double-blind</strong>. In single-blind experiments, the <a id="id582" class="indexterm"/>subjects don't know which group they belong to. In double-blind <a id="id583" class="indexterm"/>experiments, those conducting the experiments also don't know which group the subjects they're interacting with belong to. This safeguards the experiments against biases that can be introduced by participants being aware of which group they belong to. For example, participants could get more engaged if they believe they're in the test group because this is <em>newer</em> in some way. Or, an experimenter could treat a subject differently in a subtle way because of the group that they belong to.</p><p>As the computer is the one that directly conducts the experiment, and because those visiting your website aren't aware of which group they belong to, website A/B testing is generally an example of double-blind experiments.</p><p>Of course, this is an<a id="id584" class="indexterm"/> argument for only conducting the test on new visitors. Otherwise, the user might recognize that the design has changed and throw the experiment away. For example, the users may be more likely to click on a new button when they recognize that the button is, in fact, new. However, if they are new to the site as a whole, then the button itself may not stand out enough to warrant extra attention.</p><p>In some cases, these subjects can test more variant sites. This divides the test subjects into more groups. There needs to be more subjects available in order to compensate for this. Otherwise, the experiment's statistical validity might be in jeopardy. If each group doesn't have enough subjects, and therefore observations, then there is a larger error rate for the test, and results will need to be more extreme to be significant.</p><p>In general, though, you'll want to have as many subjects as you reasonably can. Of course, this is always a trade-off. Getting 500 or 1000 subjects may take a while, given the typical traffic of many websites, but you still need to take action within a reasonable amount of time and put the results of the experiment into effect. So we'll talk later about how to determine the number of subjects that you actually need to get a certain level of significance.</p><p>Another wrinkle that is you'll want to know as soon as possible is whether one option is clearly better or not so that you can begin to profit from it early. In the multi-armed bandit problem, this is a problem<a id="id585" class="indexterm"/> of <em>exploration</em> versus <em>exploitation</em>. This refers to the tension in the experiment design (and other domain) between exploring the problem space and exploiting the resources you've found in the experiment so far. We won't get into this further, but it is a factor to stay aware of as you perform A/B tests in the future.</p><p>Because of the power and simplicity of A/B testing, it's being widely used in a variety of domains. For example, marketing and advertising make extensive use of it. Also, it has become a powerful way to test and improve measurable interactions between your website and those who visit it online.</p><p>The primary requirement is that the interaction be somewhat limited and very measurable. Interesting would not make a good metric; the <em>click-through rate</em> or <em>pages visited</em>, however, would. Because of this, A/B tests validate changes in the placement or in the text of buttons that call for action from the users. For example, a test might compare the performance of <strong>Click for more!</strong> against <strong>Learn more now!</strong>. Another test may check whether a button placed in the upper-right section increases sales versus one in the center of the page.</p><p>These changes are <a id="id586" class="indexterm"/>all incremental, and you probably don't want to break a large site redesign into pieces and test all of them individually. In a larger redesign, several changes may work together and reinforce each other. Testing them incrementally and only applying the ones that increase some metric can result in a design that's not aesthetically pleasing, is difficult to maintain, and costs you users in the long run. In these cases, A/B testing is not recommended.</p><p>Some other things that are <a id="id587" class="indexterm"/>regularly tested in A/B tests include the following parts of a web page:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The wording, size, and placement of a call-to-action button</li><li class="listitem" style="list-style-type: disc">The headline and product description</li><li class="listitem" style="list-style-type: disc">The length, layout, and fields in a form</li><li class="listitem" style="list-style-type: disc">The overall layout and style of the website as a larger test, which is not broken down</li><li class="listitem" style="list-style-type: disc">The pricing and promotional offers of products</li><li class="listitem" style="list-style-type: disc">The images on the landing page</li><li class="listitem" style="list-style-type: disc">The amount of text on a page</li></ul></div><p>Now that we have an understanding of what A/B testing is and what it can do for us, let's see what it will take to set up and perform an A/B test.</p></div></div>
<div><div><div><div><h1 class="title"><a id="ch08lvl1sec57"/>Conducting an A/B test</h1></div></div></div><p>In creating an <a id="id588" class="indexterm"/>A/B test, we need to decide several things, and then we need to put our plan into action. We'll walk through those decisions here and create a simple set of web pages that will test the aspects of design that we are interested in changing, based upon the behavior of the user.</p><p>Before we start building stuff, though, we need to think through our experiment and what we'll need to build.</p><div><div><div><div><h2 class="title"><a id="ch08lvl2sec55"/>Planning the experiment</h2></div></div></div><p>For this chapter, we're going<a id="id589" class="indexterm"/> to pretend<a id="id590" class="indexterm"/> that we have a website to sell widgets (or rather, looking at the <strong>Widgets!</strong> website).</p><div><img src="img/4139OS_08_01.jpg" alt="Planning the experiment"/></div><p>The web page in this screenshot is the<a id="id591" class="indexterm"/> <strong>control page</strong>. Currently, we're getting 24 percent click-through on it from the <strong>Learn more!</strong> button.</p><p>We're interested in the text of the button. If it read <strong>Order now!</strong> instead of <strong>Learn more!</strong>, it might generate more <a id="id592" class="indexterm"/>click-through. (Of course, actually explaining what the product is and <a id="id593" class="indexterm"/>what problems it solves might be more effective, but one can't have everything.) This will be the<a id="id594" class="indexterm"/> <strong>test page</strong>, and we're hoping that we can increase the click-through rate to 29 percent (a five percent absolute increase).</p><p>Now that we have two versions of the page to experiment with, we can frame the experiment statistically and figure out how many subjects we'll need for each version of the page in order to achieve a statistically meaningful increase in the click-through rate on that button.</p></div><div><div><div><div><h2 class="title"><a id="ch08lvl2sec56"/>Framing the statistics</h2></div></div></div><p>First, we need to<a id="id595" class="indexterm"/> frame our <a id="id596" class="indexterm"/>experiment in terms of the<a id="id597" class="indexterm"/> <strong>null-hypothesis test</strong>. In this case, the null hypothesis would look something like this:</p><div><blockquote class="blockquote"><p><em>Changing the button copy from <strong>Learn more!</strong> to <strong>Order now!</strong> Would not improve the click-through rate.</em></p></blockquote></div><p>Remember, this is the statement that we're hoping to disprove (or fail to disprove) in the course of this experiment.</p><p>Now we need to think about the sample size. This needs to be fixed in advance. To find the sample size, we'll use the standard error formula, which will be solved to get the number of observations to make for about a 95 percent confidence interval in order to get us in the ballpark of how large our sample should be:</p><div><img src="img/4139OS_08_02.jpg" alt="Framing the statistics"/></div><p>In this, <em>δ</em> is the minimum effect to detect and <em>σ²</em> is the sample variance. If we are testing for something like a percent increase in the click-through, the variance is <em>σ² = p(1 – p)</em>, where <em>p</em> is the initial click-through rate with the control page.</p><p>So for this experiment, the variance will be <em>0.24(1-0.24)</em> or <em>0.1824</em>. This would make the sample size for each variable <em>16(0.1824 / 0.05²)</em> or almost <em>1170</em>.</p><p>The code to compute this in Clojure is fairly simple:</p><div><pre class="programlisting">(defn get-target-sample [rate min-effect]
  (let [v (* rate (- 1.0 rate))]
    (* 16.0 (/ v (* min-effect min-effect)))))</pre></div><p>Running the code from the prompt gives us the response that we expect:</p><div><pre class="programlisting">
<strong>user=&gt; (get-target-sample 0.24 0.05)</strong>
<strong>1167.36</strong>
</pre></div><p>Part of the reason <a id="id598" class="indexterm"/>to calculate the number of participants needed is that monitoring the progress of the experiment and stopping it prematurely can invalidate the results of the test because it increases the risk of false positives where the experiment <a id="id599" class="indexterm"/>says it has disproved the null hypothesis when it really hasn't.</p><p>This seems counterintuitive, doesn't it? Once we have significant results, we should be able to stop the test. Let's work through it.</p><p>Let's say that in actuality, there's no difference between the control page and the test page. That is, both sets of copy for the button get approximately the same click-through rate. If we're attempting to get <em>p ≤ 0.05</em>, then it means that the test will return a false positive five percent of the time. It will incorrectly say that there is a significant difference between the click-through rates of the two buttons five percent of the time.</p><p>Let's say that we're running the test and planning to get 3,000 subjects. We end up checking the results of every 1,000 participants. Let's break down what might happen:</p><div><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th style="text-align: left" valign="bottom">
<p>Run</p>
</th><th style="text-align: left" valign="bottom">
<p>A</p>
</th><th style="text-align: left" valign="bottom">
<p>B</p>
</th><th style="text-align: left" valign="bottom">
<p>C</p>
</th><th style="text-align: left" valign="bottom">
<p>D</p>
</th><th style="text-align: left" valign="bottom">
<p>E</p>
</th><th style="text-align: left" valign="bottom">
<p>F</p>
</th><th style="text-align: left" valign="bottom">
<p>G</p>
</th><th style="text-align: left" valign="bottom">
<p>H</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<p>
<strong>1000</strong>
</p>
</td><td style="text-align: left" valign="top">
<p>No</p>
</td><td style="text-align: left" valign="top">
<p>No</p>
</td><td style="text-align: left" valign="top">
<p>No</p>
</td><td style="text-align: left" valign="top">
<p>No</p>
</td><td style="text-align: left" valign="top">
<p>Yes</p>
</td><td style="text-align: left" valign="top">
<p>Yes</p>
</td><td style="text-align: left" valign="top">
<p>Yes</p>
</td><td style="text-align: left" valign="top">
<p>Yes</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<strong>2000</strong>
</p>
</td><td style="text-align: left" valign="top">
<p>No</p>
</td><td style="text-align: left" valign="top">
<p>No</p>
</td><td style="text-align: left" valign="top">
<p>Yes</p>
</td><td style="text-align: left" valign="top">
<p>Yes</p>
</td><td style="text-align: left" valign="top">
<p>No</p>
</td><td style="text-align: left" valign="top">
<p>Yes</p>
</td><td style="text-align: left" valign="top">
<p>No</p>
</td><td style="text-align: left" valign="top">
<p>Yes</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<strong>3000</strong>
</p>
</td><td style="text-align: left" valign="top">
<p>No</p>
</td><td style="text-align: left" valign="top">
<p>Yes</p>
</td><td style="text-align: left" valign="top">
<p>No</p>
</td><td style="text-align: left" valign="top">
<p>Yes</p>
</td><td style="text-align: left" valign="top">
<p>No</p>
</td><td style="text-align: left" valign="top">
<p>No</p>
</td><td style="text-align: left" valign="top">
<p>Yes</p>
</td><td style="text-align: left" valign="top">
<p>Yes</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<strong>Final</strong>
</p>
</td><td style="text-align: left" valign="top">
<p>No</p>
</td><td style="text-align: left" valign="top">
<p>Yes</p>
</td><td style="text-align: left" valign="top">
<p>No</p>
</td><td style="text-align: left" valign="top">
<p>Yes</p>
</td><td style="text-align: left" valign="top">
<p>No</p>
</td><td style="text-align: left" valign="top">
<p>No</p>
</td><td style="text-align: left" valign="top">
<p>Yes</p>
</td><td style="text-align: left" valign="top">
<p>Yes</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<strong>Stopped</strong>
</p>
</td><td style="text-align: left" valign="top">
<p>No</p>
</td><td style="text-align: left" valign="top">
<p>Yes</p>
</td><td style="text-align: left" valign="top">
<p>Yes</p>
</td><td style="text-align: left" valign="top">
<p>Yes</p>
</td><td style="text-align: left" valign="top">
<p>Yes</p>
</td><td style="text-align: left" valign="top">
<p>Yes</p>
</td><td style="text-align: left" valign="top">
<p>Yes</p>
</td><td style="text-align: left" valign="top">
<p>Yes</p>
</td></tr></tbody></table></div><p>Let's read this table. Each lettered column represents a scenario for how the significance of the results may change over the run of the test. The rows represent the number of observations that have been made. The row labeled <em>Final</em> represents the experiment's true finishing result, and the row labeled <em>Stopped</em> represents the result if the experiment is stopped as soon as a significant result is seen.</p><p>The final results show us that out of eight different scenarios, the final result would be significant in four cases (B, D, G, and H). However, if the experiment is stopped prematurely, then it will be significant in seven cases (all but A). The test could drastically over-generate false positives.</p><p>In fact, most statistical tests assume that the sample size is fixed before the test is run.</p><p>It's exciting to get good results, so we'll design our system so that we can't easily stop it prematurely. We'll just take that temptation away.</p><p>With this in mind, let's <a id="id600" class="indexterm"/>consider <a id="id601" class="indexterm"/>how we can implement this test.</p></div><div><div><div><div><h2 class="title"><a id="ch08lvl2sec57"/>Building the experiment</h2></div></div></div><p>There are several <a id="id602" class="indexterm"/>options to <a id="id603" class="indexterm"/>actually implement the A/B test. We'll consider several of them and weigh their pros and cons. Ultimately, the option that works best for you really depends on your circumstances. However, we'll pick one for this chapter and use it to implement the test for it.</p><div><div><div><div><h3 class="title"><a id="ch08lvl3sec36"/>Looking at options to build the site</h3></div></div></div><p>The first way to <a id="id604" class="indexterm"/>implement A/B testing is to use a server-side implementation. In this case, all of the processing and tracking is handled on the server, and visitors' actions would be tracked using GET or POST parameters on the URL for the resource that the experiment is attempting to drive traffic towards.</p><p>The steps for this process would go something like the following ones:</p><div><ol class="orderedlist arabic"><li class="listitem">A new user visits the site and requests for the page that contains the button or copy that is being tested.</li><li class="listitem">The server recognizes that this is a new user and assigns the user a tracking number.</li><li class="listitem">It assigns the user to one of the test groups.</li><li class="listitem">It adds a row in a database that contains the tracking number and the test group that the user is part of.</li><li class="listitem">It returns the page to the user with the copy, image, or design that is reflective of the control or test group.</li><li class="listitem">The user views the returned page and decides whether to click on the button or link or not.</li><li class="listitem">If the server receives a request for the button's or link's target, it updates the user's row in the tracking table to show us that the interaction was a success, that is, that the user did a click-through or made a purchase.</li></ol></div><p>This way of handling it keeps everything on the server, so it allows more control and configuration over exactly how you want to conduct your experiment.</p><p>A second way of implementing this would be to do everything using JavaScript (or ClojureScript, <a class="ulink" href="https://github.com/clojure/clojurescript">https://github.com/clojure/clojurescript</a>). In this scenario, the code on the page itself would randomly decide whether the user belonged to the control or the test group, and it would notify the server that a new observation in the experiment was beginning. It would then update the page with the appropriate copy or image. Most of the rest of this interaction is the same as the one in previous scenario. However, the complete steps are as follows:</p><div><ol class="orderedlist arabic"><li class="listitem">A new user visits the site and requests for the page that contains the button or copy being tested.</li><li class="listitem">The server inserts some JavaScript to handle the A/B test into the page.</li><li class="listitem">As the page is being rendered, the JavaScript library generates a new tracking number for the user.</li><li class="listitem">It assigns the user to one of the test groups.</li><li class="listitem">It renders that page for the group that the user belongs to, which is either the control group or the test group.</li><li class="listitem">It notifies the server of the user's tracking number and the group.</li><li class="listitem">The server takes this notification and adds a row for the observation in the database.</li><li class="listitem">The JavaScript in the browser tracks the user's next move either by directly notifying the server using an AJAX call or indirectly using a GET parameter in the URL for the next page.</li><li class="listitem">The server receives the notification whichever way it's sent and updates the row in the database.</li></ol></div><p>The downside <a id="id605" class="indexterm"/>of this is that having JavaScript take care of rendering the experiment might take slightly longer and may throw off the experiment. It's also slightly more complicated, because there are more parts that have to communicate. However, the benefit is that you can create a JavaScript library, easily throw a small script tag into the page, and immediately have a new A/B experiment running.</p><p>In reality, though, you'll probably just use a service that handles this and more for you. However, it still makes sense to understand what they're providing for you, and that's what this chapter tries to do by helping you understand how to perform an A/B test so that you can be make better use of these A/B testing vendors and services.</p></div></div><div><div><div><div><h2 class="title"><a id="ch08lvl2sec58"/>Implementing A/B testing on the server</h2></div></div></div><p>For the purposes of <a id="id606" class="indexterm"/>this<a id="id607" class="indexterm"/> chapter, we'll implement the A/B test on the server.</p><p>First, we'll create a new project using <a id="id608" class="indexterm"/>
<strong>Leiningen 2</strong> (<a class="ulink" href="http://leiningen.org/">http://leiningen.org/</a>) and the <a id="id609" class="indexterm"/>
<strong>Luminus web framework</strong> (<a class="ulink" href="http://www.luminusweb.net/">http://www.luminusweb.net/</a>). We'll include some options to include the <a id="id610" class="indexterm"/>
<strong>H2 embedded database</strong> (<a class="ulink" href="http://www.h2database.com/">http://www.h2database.com/</a>) and <strong>ClojureScript support</strong><a id="id611" class="indexterm"/> (<a class="ulink" href="https://github.com/clojure/clojurescript">https://github.com/clojure/clojurescript</a>). We do this with the following command line:</p><div><pre class="programlisting">
<strong>lein new luminus web-ab +h2 +cljs</strong>
</pre></div><p>This command<a id="id612" class="indexterm"/> creates the scaffolding for a website. We'll first get familiar with what <a id="id613" class="indexterm"/>the scaffolding provides, and then we'll fill in the parts of the site with the core site. Next, we'll add the A/B testing, and finally, we'll add a couple of pages to view the results.</p><div><div><div><div><h3 class="title"><a id="ch08lvl3sec37"/>Understanding the scaffolded site</h3></div></div></div><p>Luminus <a id="id614" class="indexterm"/>is a web framework that <a id="id615" class="indexterm"/>is built by combining other libraries and tying them together. For database access and models, it uses<a id="id616" class="indexterm"/> <strong>Korma</strong><a id="id617" class="indexterm"/> (<a class="ulink" href="http://sqlkorma.com/">http://sqlkorma.com/</a>). For HTML templates, it uses <a id="id618" class="indexterm"/>
<strong>Selmer</strong><a id="id619" class="indexterm"/> (<a class="ulink" href="https://github.com/yogthos/Selmer">https://github.com/yogthos/Selmer</a>), which is a port of Django-style templates. For routing, controllers, sessions, and everything else, it uses <strong>lib-noir</strong><a id="id620" class="indexterm"/> (<a class="ulink" href="http://yogthos.github.io/lib-noir/">http://yogthos.github.io/lib-noir/</a>) <a id="id621" class="indexterm"/>and <a id="id622" class="indexterm"/>
<strong>Compojure</strong><a id="id623" class="indexterm"/> (<a class="ulink" href="https://github.com/weavejester/compojure/">https://github.com/weavejester/compojure/</a>).</p><p>Everything in the directory that contains a Luminus project will be a consistent set of subdirectories named after the project. For instance, in the project that we just created for this (<code class="literal">web-ab</code>), the primary directories would be as follows:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">resources</code> is the<a id="id624" class="indexterm"/> directory of static resources. It contains the CSS, JavaScript, and image files for the site.</li><li class="listitem" style="list-style-type: disc"><code class="literal">src</code> is the directory <a id="id625" class="indexterm"/>of Clojure files. Several of the subdirectories in this directory tree are important too, so I'll list them separately.</li><li class="listitem" style="list-style-type: disc"><code class="literal">src/web_ab/models/</code> is the<a id="id626" class="indexterm"/> directory that contain the Clojure files that define the model and interact with the database.</li><li class="listitem" style="list-style-type: disc"><code class="literal">src/web_ab/routes/</code> is the <a id="id627" class="indexterm"/>directory that lists the routes in a web application. Each module under this defines the routes and handlers for a particular subsection of the site.</li><li class="listitem" style="list-style-type: disc"><code class="literal">src/web_ab/views/templates/</code> is the <a id="id628" class="indexterm"/>directory that contains the Selmer templates.</li><li class="listitem" style="list-style-type: disc"><code class="literal">test/web_ab/test/</code> is the <a id="id629" class="indexterm"/>directory that contains the <code class="literal">clojure.test</code> tests for the site's handlers.</li></ul></div><p>We'll primarily deal with the directories under <code class="literal">src/web-ab/</code>. We'll define the models, define the routes and handlers, and fill in the templates.</p><p>As we work, we can view the site as we're developing it by using the development server. You can start this using the following Leiningen command:</p><div><pre class="programlisting">
<strong>lein ring server</strong>
</pre></div><p>Once this server is executed, we can view the site by pointing our browser to <code class="literal">http://localhost:3000/</code>.</p></div></div><div><div><div><div><h2 class="title"><a id="ch08lvl2sec59"/>Building the test site</h2></div></div></div><p>First, we need to<a id="id630" class="indexterm"/> add in the <a id="id631" class="indexterm"/>content for the main page. The file that we'll want to change will be in <code class="literal">src/web_ab/views/templates/home.html</code>. We'll add the following HTML content to that page. (There are a lot more CSS and images involved in creating the site that we saw in the screenshot earlier. All this is listed in the code download for this chapter.) Take a look at the following code:</p><div><pre class="programlisting">{% extends "web_ab/views/templates/base.html" %}
{% block content %}
&lt;header id="banner" class="row"&gt;
  &lt;div class="col-md-12"&gt;
    &lt;h1 style="width: 4.5em;" class="center-block"&gt;Widgets!&lt;/h1&gt;
  &lt;/div&gt;
&lt;/header&gt;
&lt;div id="content" class="row"&gt;
  &lt;div id="left-panel" class="col-md-6 jumbotron"&gt;
    &lt;h1&gt;Fix everything!&lt;/h1&gt;
    &lt;p&gt;These amazing &lt;strong&gt;widgets!&lt;/strong&gt; will fix
      &lt;em&gt;everything&lt;/em&gt;.&lt;/p&gt;
    &lt;p&gt;Let &lt;strong&gt;widgets!&lt;/strong&gt; work for you.&lt;/p&gt;
  &lt;/div&gt;
  &lt;div id="right-panel" class="col-md-6 jumbotron"&gt;
    &lt;a href="/purchase/" id="btn-more"
       class="btn btn-primary btn-lg center-block"&gt;
      Learn more!
    &lt;/a&gt;
  &lt;/div&gt;
&lt;/div&gt;
{% endblock %}</pre></div><p>When the time comes to add in the A/B testing features, we'll change this a little, but most of this is good as it is.</p><p>We'll also need a page to direct the users to if they want to buy a widget. We'll first define a route for this page in the <code class="literal">src/web_ab/routes/home.clj</code> file. The following is the route and the controller:</p><div><pre class="programlisting">(defn purchase-page []
  (layout/render "purchase.html" {}))
(defroutes home-routes
  (GET "/" [] (home-page))
  (GET "/purchase/" [] (purchase-page)))</pre></div><p>The view is <a id="id632" class="indexterm"/>defined in the <code class="literal">src/web_ab/views/templates/purchase.html</code> file. This file is very similar to the preceding template file, except that it's <a id="id633" class="indexterm"/>considerably simpler. It just contains a thank you message for the left panel, and there's no button or link on the right-hand side. For more details about this page, see the code download.</p><div><img src="img/4139OS_08_03.jpg" alt="Building the test site"/></div><p>In fact, this is enough to define the base, control site in this project. Now let's look at what we need to do to define the A/B testing features.</p></div><div><div><div><div><h2 class="title"><a id="ch08lvl2sec60"/>Implementing A/B testing</h2></div></div></div><p>Adding A/B testing into the site <a id="id634" class="indexterm"/>that we have so far will be pretty straightforward web development. We'll need to define a model and functions that implement the test framework's basic functionality. We can then incorporate them into the site's existing controllers and views:</p><div><ol class="orderedlist arabic"><li class="listitem">The code that defines the data and the database settings will go into the <code class="literal">src/web_ab/models/schema.clj</code> file. It will start with the following namespace declaration:<div><pre class="programlisting">(ns web-ab.models.schema
  (:require [clojure.java.jdbc :as sql]
            [noir.io :as io]))</pre></div></li><li class="listitem">The first facet of this section of the site that we'll define is the model. We'll add a table to the database schema that defines a table to track the A/B participants:<div><pre class="programlisting">(defn create-abtracking-table []
  (sql/with-connection db-spec
    (sql/create-table :abtracking
      [:id "INTEGER IDENTITY"]
      [:testgroup "INT NOT NULL"]
      [:startat "TIMESTAMP NOT NULL DEFAULT NOW()"]
      [:succeed "TIMESTAMP DEFAULT NULL"])))</pre></div></li><li class="listitem">Now, in the <code class="literal">src/web_ab/models/db.clj</code> file, we'll define some low-level functions to work with the rows in this table. For this file, we'll use the following namespace declaration:<div><pre class="programlisting">(ns web-ab.models.db
  (:use korma.core
        [korma.db :only (defdb)])
  (:require [web-ab.models.schema :as schema]
            [taoensso.timbre :as timbre]))</pre></div></li><li class="listitem">The first function in this namespace will take a group keyword (<code class="literal">:control</code> or <code class="literal">:test</code>) and insert a row into the database with a code that represents that group and the default values for the starting time (the current time) and the time in which the interaction succeeds (<code class="literal">NULL</code>):<div><pre class="programlisting">(defn create-abtracking [group]
  (get (insert abtracking
               (values [{:testgroup (group-code group)}]))
       (keyword "scope_identity()")))</pre></div></li><li class="listitem">Next, we'll create a function that sets an <code class="literal">abtracking</code> object's succeed field to the current time. This will mark the interaction as a success:<div><pre class="programlisting">(defn mark-succeed [id]
  (update abtracking
          (set-fields {:succeed (sqlfn :now)})
          (where {:id id})))</pre></div></li></ol></div><p>These, along with a few other functions that you can find in the code download for this chapter, will form a low-level interface with this data table. Most of the time, however, we'll deal with A/B testing using a slightly higher-level interface.</p><p>This interface will live in the <code class="literal">src/web_ab/ab_testing.clj</code> file. It will contain the following namespace declaration:</p><div><pre class="programlisting">(ns web-ab.ab-testing
  (:require [noir.cookies :as c]
            [taoensso.timbre :as timbre]
            [web-ab.models.db :as db]
            [incanter.stats :as s]
            [clojure.set :as set]
            [web-ab.util :as util])
  (:import [java.lang Math]))</pre></div><p>To understand the code in this module, we need to first talk about how the A/B testing system will work. We have the following number of requirements that we need to make sure are implemented:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">If the users have<a id="id635" class="indexterm"/> visited the site before the A/B test, they should see the control version of the site. We assume that there's a tracking cookie already being used for this. In this case, the cookie will be named <em>visits</em>, and it will simply track the number of times a user has visited the home page of the site.</li><li class="listitem" style="list-style-type: disc">If this is the users' first visit to the site, they will be randomly assigned to the control group or the test group, and they'll be shown the appropriate page for that group. Also, they'll receive a tracking cookie for the observation that they are, and we'll insert the tracking information for them into the database.</li><li class="listitem" style="list-style-type: disc">If the users have visited the site earlier and are participants in the A/B test, they should see the same version of the site that they saw previously.</li><li class="listitem" style="list-style-type: disc">Finally, when a user who is a participant in the experiment visits the purchase page, that observation in the experiment will be marked as a success.</li></ul></div><p>We'll write functions for most of these cases as well as a function to route the user to the right branch whenever one visits the front page. We'll write another function to handle item number four.</p><p>For the first function, we'll implement what's necessary to start a new observation in the experiment. We'll enter the functions into the database and insert the tracking cookie into the session:</p><div><pre class="programlisting">(defn new-test [test-cases]
  (let [[group text] (rand-nth (seq test-cases))
        ab-tracking (db/get-abtracking
                      (db/create-abtracking group))]
    (c/put! :abcode (:id ab-tracking))
    text))</pre></div><p>The functions in<a id="id636" class="indexterm"/> the <code class="literal">db</code> namespace (aliased from <code class="literal">web-ab.models.db</code>) are from the low-level model interface that we just defined. In fact, the implementation for <code class="literal">create-abtracking</code> is listed on the preceding page.</p><p>The <code class="literal">c/put!</code> function is from the <code class="literal">noir.cookies</code> namespace. It inserts the cookie value into the session. In this case, it inserts the tracking instance's database ID under the <code class="literal">abcode</code> key.</p><p>Finally, <code class="literal">new-test</code> returns the text that should be used on the page.</p><p>The next function for this level of abstraction is <code class="literal">get-previous-copy</code>. This is used whenever a user who is already a participant in the experiment visits the page again. It takes a database ID and the different versions of the site that are being used in the current test, and it retrieves the row from the database and looks up the right copy text to be used on the page, given whether the observation is in the control group or the test group:</p><div><pre class="programlisting">(defn get-previous-copy [ab-code test-cases]
  (-&gt; ab-code
    db/get-abtracking
    :testgroup
    db/code-&gt;group
    test-cases))</pre></div><p>This function simply runs the input through a number of conversions. First, this function converts it to a full data row tuple based on the database ID. Next, it selects the <code class="literal">testgroup</code> field, and it translates it into a group keyword. This is finally translated into the appropriate text for the page, based on the group keyword.</p><p>The next function that we're going to look at ties the two previous functions together with item number one from the preceding list (where the returning visitors are shown the control page without being entered into the experiment):</p><div><pre class="programlisting">(defn start-test [counter default test-cases]
  (let [c (Long/parseLong (c/get counter "0"))
        ab-code (get-abcode-cookie)]
    (c/put! counter (inc c))
    (cond
      (and (&gt;= ab-code 0) (&gt; c 0))
      (get-previous-copy ab-code test-cases)

      (and (&lt; ab-code 0) (&gt; c 0)) default

      :else (new-test test-cases))))</pre></div><p>First, this function expects three parameters: the cookie name for the counter, the default text for the control page, and a map from the group keywords to page text. This function looks at the value of the counter cookie and the <em>abtest</em> cookie, both of which will be <code class="literal">-1</code> or <code class="literal">0</code> if they're not set, and it decides what should be displayed for the user as well as inserts whatever needs to be inserted into the database.</p><p>In the preceding code snippet, we can see that the calls to the two functions that we've just looked at are highlighted in the code listing.</p><p>Also, here we define a<a id="id637" class="indexterm"/> function that looks for the <em>abtest</em> cookie and, if it's found, we mark it as having succeeded, shown as follows:</p><div><pre class="programlisting">(defn mark-succeed []
  (let [ab-code (get-abcode-cookie)]
    (when (&gt; ab-code -1)
      (db/mark-succeed ab-code))))</pre></div><p>Finally, once the experiment is over, we need to perform the analysis that determines whether the control page performed better or the test page:</p><div><pre class="programlisting">(defn perform-test
  ([ab-testing] (perform-test ab-testing 0.05))
  ([ab-testing p]
   (let [groups (group-by-group ab-testing)
         t (-&gt; (s/t-test (to-flags (:test groups))
                         :y (to-flags (:control groups))
                         :alternative :less)
             (select-keys [:p-value :t-stat
                           :x-mean :y-mean :n1 :n2])
             (set/rename-keys {:x-mean :test-p,
                               :y-mean :control-p,
                               :n1 :test-n,
                               :n2 :control-n}))]
     (assoc t
            :p-target p
            :significant (&lt;= (:p-value t) p)))))</pre></div><p>To perform the actual analysis, we use the t-test function from <code class="literal">incanter.stats</code> in the <strong>Incanter</strong> library<a id="id638" class="indexterm"/> (<a class="ulink" href="http://incanter.org/">http://incanter.org/</a>). We'll get into this analysis in more detail later in the chapter. For now, let's just pay attention to how the data flows through this function. The <code class="literal">t-test</code> function<a id="id639" class="indexterm"/> returns a map that contains a lot of numbers. For the output, we need to select some of this information and rename the keys for some of the data that we will use. We use the core <code class="literal">select-keys</code> function<a id="id640" class="indexterm"/> to select only the information that we need, and we use <code class="literal">clojure.set</code>/<code class="literal">rename-keys</code> to give the rest of the names that will fit our current domain in a better manner.</p><p>To the results of<a id="id641" class="indexterm"/> the analysis, we'll also add a couple of other pieces of data. One will be the alpha value, that is, the target value for p that we're trying to improve upon. The other depends on whether the results are significant or not. This is found by testing the value of p against the significance level that we're trying for.</p><p>With the low-level and high-level interfaces to the A/B testing process in place, we can turn our attention to actually using it. First, we need to update the view template for the home page from what we listed in the preceding snippet.</p><p>Remember, the file is in <code class="literal">src/web_ab/views/templates/home.html</code>. We want to simply change the name of the link to go to the purchase page. It needs to be a parameter that we can use to insert a value into the template. For instance, the following snippet contains the updated version of the right-hand panel, including the highlighted line that we can use to insert the text into the page:</p><div><pre class="programlisting">  &lt;div id="right-panel" class="col-md-6 jumbotron"&gt;
    &lt;a href="/purchase/" id="btn-more"
       class="btn btn-primary btn-lg center-block"&gt;
      {{button}}
    &lt;/a&gt;
  &lt;/div&gt;</pre></div><p>The controllers will also need to change. They need to trigger the appropriate stages in the test participant's lifecycle, and they need to pass the button text into the template.</p><p>The controller for the home page does this as part of one form. It calls <code class="literal">start-test</code>, and builds the template parameters using its output directly. This addition to the controller is highlighted as follows:</p><div><pre class="programlisting">(defn home-page []
  (layout/render
    "home.html"
    {:button (ab/start-test :visits default-button test-cases)}))</pre></div><p>The controller for the purchase page just incorporates a call to <code class="literal">mark-succeed</code> in its normal flow:</p><div><pre class="programlisting">(defn purchase-page []
  (ab/mark-succeed)
  (layout/render "purchase.html" {}))</pre></div><p>At this point, everything is in place to actually conduct the test; however, we cannot tell when it's over or look at the results. We can add this section of the website in the next stage.</p></div><div><div><div><div><h2 class="title"><a id="ch08lvl2sec61"/>Viewing the results</h2></div></div></div><p>We'll add the <a id="id642" class="indexterm"/>A/B test <a id="id643" class="indexterm"/>result's views as separate pages in a separate section of the site. It will use the same <code class="literal">abtracking</code> model as the rest of the A/B testing, but we'll define more controllers and views.</p><p>One of the primary features of this part of the site is that we don't want to display some information before the test is complete. In order to decide this, we'll first define a map that specifies how many observations from each group we need:</p><div><pre class="programlisting">(def target-counts {:control 1200, :test 1200})</pre></div><p>We can use these values to define a predicate that tests whether enough participants have been registered in order to call the experiment complete. It reads the participants from the database and categorizes them by the experiment group. It compares the counts of these groups to the target counts:</p><div><pre class="programlisting">(defn is-over?
  ([] (is-over? (ab/get-ab-tracking)))
  ([ab-tracking]
   (let [{:keys [control test]} (ab/group-by-group ab-tracking)]
     (and (&gt;= (count control) (:control target-counts))
          (&gt;= (count test) (:test target-counts))))))</pre></div><p>We can use this to go a step further. We'll define a function that takes the list of rows from the <code class="literal">abtracking</code> table and a function that renders a page. It tests whether the experiment has been performed. If it is complete, it passes the on processing to that function. If it's not, it displays a standard page that informs the user that the experiment has not been completed yet:</p><div><pre class="programlisting">(defn when-is-over [ab-tracking f]
  (if (is-over? ab-tracking)
    (f ab-tracking)
    (let [{:keys [control test]} (ab/group-by-group ab-tracking)]
      (layout/render
        "ab-testing-not-done.html"
        {:counts {:control (count control)
                  :test (count test)}
         :targets target-counts
         :complete {:control (ab/pct (count control)
                                     (:control target-counts))
                    :test (ab/pct (count test)
                                  (:test target-counts))}}))))</pre></div><p>Now, with these utilities in place, we can define a couple of pages. The first one will list the participants from the <code class="literal">abtracking</code> table. You can find the controller function and the view template in the code download. Both are relatively straightforward.</p><p>The other is slightly more interesting for a couple of reasons. First, it uses the <code class="literal">when-is-over</code> function that we just saw, and second, it performs the statistical test to determine whether the control page performed better or the test page:</p><div><pre class="programlisting">(defn grid []
  (when-is-over
    (ab/get-ab-tracking)
    (fn [ab-tracking]
      (let [by-group-outcome (ab/assoc-grid-totals
                               (ab/get-results-grid ab-tracking))
            stats (<strong>ab/perform-test ab-tracking 0.05</strong>)]
        (layout/render "ab-testing-grid.html"
                       {:grid by-group-outcome,
                        :stats (sort (seq stats))
                        :significant (:significant stats)})))))</pre></div><p>As <a id="id644" class="indexterm"/>mentioned, this<a id="id645" class="indexterm"/> function uses the <code class="literal">when-is-over</code> function<a id="id646" class="indexterm"/> that we just defined in order to bypass this page and display a standard page that just says that the experiment has not been finished yet.</p><p>The statistical test, which is highlighted, calls the <code class="literal">perform-test</code> function<a id="id647" class="indexterm"/> that we talked about earlier.</p><p>The template for these primarily displays the results in a grid. It also has a colored alert at the top of the page, which indicates whether the control performed better or the test groups.</p><div><div><div><div><h3 class="title"><a id="ch08lvl3sec38"/>Looking at A/B testing as a user</h3></div></div></div><p>Now that all the parts <a id="id648" class="indexterm"/>are together, let's walk through the user's interaction<a id="id649" class="indexterm"/> with the site. Most people who visit your site won't know that there are two different versions of the site, so they should interact with your site as they normally would.</p><p>When they first visit your site, users should see the following screen. The text on the button in the lower-right section might be different, but the rest should be the same for everyone.</p><div><img src="img/4139OS_08_04.jpg" alt="Looking at A/B testing as a user"/></div><p>Once the user clicks on <a id="id650" class="indexterm"/>
<strong>Learn more!</strong> (in this case), they complete the <a id="id651" class="indexterm"/>purchase, and all the users should see the following page:</p><div><img src="img/4139OS_08_05.jpg" alt="Looking at A/B testing as a user"/></div><p>However, the more <a id="id652" class="indexterm"/>interesting part of this isn't what happens with the user but <a id="id653" class="indexterm"/>what happens afterwards when we can look at and analyze the results. We'll see some details about this in the next section.</p></div></div><div><div><div><div><h2 class="title"><a id="ch08lvl2sec62"/>Analyzing the results</h2></div></div></div><p>Obviously, we're not<a id="id654" class="indexterm"/> going to<a id="id655" class="indexterm"/> be able to get a few thousand people to visit our website and purchase the widgets. In place of actual participants, I've populated the database with random data. This should allow us to see how the analysis section of the website works and what it means.</p><p>Throughout the experiment, we can get a list of the participants by visiting <code class="literal">http://localhost:3000/ab-testing/</code> on the local development server. This allows us to track the experiment's progress without really getting into the results and without having direct access to the counts.</p><div><img src="img/4139OS_08_06.jpg" alt="Analyzing the results"/></div><p>While the <a id="id656" class="indexterm"/>experiment is running, we don't really want to get more information than this page displays. This is where the <code class="literal">when-is-over</code> function, which we previously saw, comes into<a id="id657" class="indexterm"/> play. When we visited the page earlier, we had sufficient participants in the experiment, and then we got a page that explained that the experiment was not done and gave some indication as to how much longer it has to go on for.</p><p>For example, the following screenshot has about all the information we want to provide at this point in the experiment:</p><div><img src="img/4139OS_08_07.jpg" alt="Analyzing the results"/></div><p>Of course, once<a id="id658" class="indexterm"/> the <a id="id659" class="indexterm"/>experiment is complete, we'd like to be able to see the final results, including whether the results allow us to reject the null hypothesis, that is, whether the test group performed better than the control group in a statistically significant way or not.</p><p>So when the experiment is complete, we get the following page:</p><div><img src="img/4139OS_08_08.jpg" alt="Analyzing the results"/></div><p>There's more<a id="id660" class="indexterm"/> information <a id="id661" class="indexterm"/>included on this page. The following is a table that contains the rest of the data and a short explanation of what they are. We'll go into more detail on them in the next section, where we talk about the t-test.</p><div><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th style="text-align: left" valign="bottom">
<p>Name</p>
</th><th style="text-align: left" valign="bottom">
<p>Value</p>
</th><th style="text-align: left" valign="bottom">
<p>Explanation</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<p>:control-mean</p>
</td><td style="text-align: left" valign="top">
<p>252</p>
</td><td style="text-align: left" valign="top">
<p>The average of the control group.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>:control-n</p>
</td><td style="text-align: left" valign="top">
<p>1226</p>
</td><td style="text-align: left" valign="top">
<p>The number of observations in the control group.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>:control-p</p>
</td><td style="text-align: left" valign="top">
<p>0.20555</p>
</td><td style="text-align: left" valign="top">
<p>The conversion rate of the control group.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>:control-variance</p>
</td><td style="text-align: left" valign="top">
<p>200.20228</p>
</td><td style="text-align: left" valign="top">
<p>The variance for the control group.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>:df</p>
</td><td style="text-align: left" valign="top">
<p>2401.10865</p>
</td><td style="text-align: left" valign="top">
<p>The degrees of freedom.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>:p-target</p>
</td><td style="text-align: left" valign="top">
<p>0.05</p>
</td><td style="text-align: left" valign="top">
<p>The alpha value for the test: the maximum p-value for the test.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>:p-value</p>
</td><td style="text-align: left" valign="top">
<p>0.00000</p>
</td><td style="text-align: left" valign="top">
<p>The actual p value for the t-test.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>:se</p>
</td><td style="text-align: left" valign="top">
<p>0.59806</p>
</td><td style="text-align: left" valign="top">
<p>The standard error.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>:significant</p>
</td><td style="text-align: left" valign="top">
<p>TRUE</p>
</td><td style="text-align: left" valign="top">
<p>Checking whether the results statistically significant</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>:t-value</p>
</td><td style="text-align: left" valign="top">
<p>108.68414</p>
</td><td style="text-align: left" valign="top">
<p>The results of the t-test.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>:test-mean</p>
</td><td style="text-align: left" valign="top">
<p>317.00000</p>
</td><td style="text-align: left" valign="top">
<p>The mean of the test group.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>:test-n</p>
</td><td style="text-align: left" valign="top">
<p>1200</p>
</td><td style="text-align: left" valign="top">
<p>The number of observations in the test group.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>:test-p</p>
</td><td style="text-align: left" valign="top">
<p>0.26417</p>
</td><td style="text-align: left" valign="top">
<p>The conversion rate of the test group.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>:test-variance</p>
</td><td style="text-align: left" valign="top">
<p>233.25917</p>
</td><td style="text-align: left" valign="top">
<p>The variance for the test group.</p>
</td></tr></tbody></table></div><p>These values <a id="id662" class="indexterm"/>are given in another table further down the page in the preceding screenshot. To<a id="id663" class="indexterm"/> understand the statistical values in a better manner, let's dig more into exactly what test we used.</p><div><div><div><div><h3 class="title"><a id="ch08lvl3sec39"/>Understanding the t-test</h3></div></div></div><p>First, we need to<a id="id664" class="indexterm"/> understand the statistical nature of the test that we're performing.</p><p>Fundamentally, the experiment is pretty simple; each observation has one of two outcomes. In many ways, this is a series of coin flips. Each flip can be heads or tails. Each site interaction can succeed or fail.</p><p>This kind of value is known as a binomial random variable. It can take one of two values, which vary according to a set probability. Binomial random variables have a number of assumptions that must be met:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">There are a fixed number of observations (<em>n</em>).</li><li class="listitem" style="list-style-type: disc">Each observation will have one of the two possible outcomes.</li><li class="listitem" style="list-style-type: disc">The n observations are independent, that is, the outcome of one observation does not in any way influence the probability of any other observation.</li><li class="listitem" style="list-style-type: disc">The probability of the outcomes stays constant over time, that is, the probability of the outcome X (<em>P(X)</em>) will always be, say, 0.5. You can easily violate that in the design of the experiment by running the control page and the test page consecutively instead of running them simultaneously. If they're not run together, one page could be used during a busier time to get better results.</li></ul></div><p>A common example <a id="id665" class="indexterm"/>of a binomial random variable is testing coin tosses. Let's use this as a first example, and then we'll apply what we've learned to our A/B test.</p><div><div><div><div><h4 class="title"><a id="ch08lvl4sec10"/>Testing coin tosses</h4></div></div></div><p>Specifically, we'll<a id="id666" class="indexterm"/> have a <a id="id667" class="indexterm"/>coin that we know is fair and we'll test another coin that we suspect is biased against it. The null hypothesis is that there is no difference between the two coins and that both are true.</p><p>The following steps show us how this experiment will fulfill the assumptions of a binomial test:</p><div><ol class="orderedlist arabic"><li class="listitem">We'll flip each coin 100 times.</li><li class="listitem">Each coin toss (each observation) can be heads or tails.</li><li class="listitem">Each coin toss is independent. Its probability isn't influenced by the probability of any other coin toss.</li><li class="listitem">The probability of heads or tails won't change over time. The probability of heads (P(heads)) and the probability of tails (P(tails)) will be 0.5 during the entire test, or for the true coin, at least.</li></ol></div><p>First, let's think about what will happen when we flip the true coin. We know that P(heads) = 0.5. Theoretically, every time we flip the coin for 100 times, we expect to get 50 heads and 50 tails. Of course, that isn't what happens in real life. Sometimes, we'll get 57 heads and 43 tails. Sometimes, we may get 44 heads and 56 tails. In extremely rare cases, we may get 100 heads and no tails. The distribution of coin tosses will form a binomial distribution, which is the number of successes in a series of yes/no experiments; however, as the number of coin tosses approaches infinity, the probability of all of these cases can be approximated by a normal distribution around the theoretical, expected probability of 50 heads and 50 tails.</p><p>For this experiment, let's say that we flipped a true coin 100 times, and we get heads 53 times.</p><p>Now, let's think about what will happen when we flip the other coin. It may be true, or it may be biased. If it is biased, we don't know it's biased by how much. So, when we flip it 100 times, and we get heads 58 times, we don't know if it's because P(heads) = 0.58 or because P(heads) = 0.5, P(heads) = 0.6, or something else, and we're slightly off this result on a normal distribution.</p><p>So we're interested in two things here. Primarily, we're interested in the difference between the two probabilities. Or, to express it in terms of the experiment, we're interested in the difference of means. We want to know whether the difference between 0.53 and 0.58 (0.05) is significant. The following graph illustrates the relationship that we're looking at in a continuous form. The actual data here is discrete, of course, but the continuous graph makes the relationship a little more clear.</p><div><img src="img/4139OS_08_09.jpg" alt="Testing coin tosses"/></div><p>The expected number <a id="id668" class="indexterm"/>of<a id="id669" class="indexterm"/> successes of a binomial random variable is given by the following formula:</p><div><img src="img/4139OS_08_10.jpg" alt="Testing coin tosses"/></div><p>The Clojure code for the sample mean of a binomial variable is similarly straightforward:</p><div><pre class="programlisting">(defn binomial-mean [coll] (reduce + 0.0 coll))</pre></div><p>So, for the control group (the known true coins), the mean is 53, and for the test group (the possibly biased coins), it's 58.</p><p>In order to answer whether the difference is significant, we also have to be interested in something else: the possibility that we're wrong. We can assume that the actual means are somewhat different than the actual numbers we're dealing with, but how far off are they?</p><p>To answer this, we need to be able to calculate the standard error for our figures. Given a normal distribution, what's the probability that the figures are so far off that they'd give us the wrong result? To be able to answer this, we need to know something about how much variance the distribution has, that is, how wide the curve of the distribution's graph is.</p><p>Like the mean, the variance for a binomial random variable is pretty simple.</p><div><img src="img/4139OS_08_11.jpg" alt="Testing coin tosses"/></div><p>The Clojure<a id="id670" class="indexterm"/> function<a id="id671" class="indexterm"/> for this is a little more complicated, but it's still clear:</p><div><pre class="programlisting">(defn binomial-variance [coll]
  (let [n (count coll),
        p (/ (count (remove zero? coll)) n)]
    (* n p (- 1.0 p))))</pre></div><p>This gives us variances of 24.91 and 24.36.</p><p>With the variance, we can calculate the standard error of the difference. This is an estimate of the standard deviation of all sample means, and it gives us some idea of how far off our means might be, given how variable the data is and how much data we're looking at. The following is the formula for that:</p><div><img src="img/4139OS_08_12.jpg" alt="Testing coin tosses"/></div><p>The standard error function in Clojure is as follows:</p><div><pre class="programlisting">(defn binomial-se [coll-t coll-c]
  (Math/sqrt (+ (/ (binomial-variance coll-t) (count coll-t))
                (/ (binomial-variance coll-c) (count coll-c)))))</pre></div><p>For the coin flipping experiment, our standard error is 0.702.</p><p>We finally get to the <strong>t-value</strong>. This measures the difference between the means, scaled by how variable the groups are.</p><div><img src="img/4139OS_08_13.jpg" alt="Testing coin tosses"/></div><p>Like the formula, the Clojure function for this builds upon all of the functions that we've just defined:</p><div><pre class="programlisting">(defn binomial-t-test [coll-t coll-c]
  (/ (- (binomial-mean coll-t) (binomial-mean coll-c))
     (binomial-se coll-t coll-c)))</pre></div><p>So the t-value of our coin flipping experiment is 7.123.</p><p>The output values <a id="id672" class="indexterm"/>of this formula follow a t distribution. This is very similar to a<a id="id673" class="indexterm"/> normal distribution, but the peak is smaller and the tails are heavier. However, as the degrees of freedom grow, it comes closer to a normal distribution. You can use the cumulative density function for the t-distribution or look in a table for the p value of this number.</p><p>We'll use Incanter's cumulative distribution functions to look up the probabilities of the particular t-values. In order to calculate this, we need to calculate the degrees of freedom for the test. When the variances of both the groups are equal, the formula is simple. However, for this, that will rarely be the case. For unequal variances, we'll use the Welch-Satterthwaite equation. It's a bit complicated, but it's what we have to work with.</p><div><img src="img/4139OS_08_14.jpg" alt="Testing coin tosses"/></div><p>In this equation, <em>s²</em> is the variation, <em>N</em> is the sample size, and <em>v</em> is <em>N-1</em>.</p><p>The Clojure code for this is only slightly less complicated:</p><div><pre class="programlisting">(defn degrees-of-freedom [coll-t coll-c]
  (let [var-t (binomial-variance coll-t), n-t (count coll-t),
        var-c (binomial-variance coll-c), n-c (count coll-c)]
    (/ (Math/pow (+ (/ var-t n-t) (/ var-c n-c)) 2)
       (+ (/ (* var-t var-t) (* n-t n-t (dec n-t)))
          (/ (* var-c var-c) (* n-c n-c (dec n-c)))))))</pre></div><p>Now, from REPL, we can test to see whether the coin toss test can reject the null hypothesis, that is, whether the second coin is biased:</p><div><pre class="programlisting">
<strong>user=&gt; (require '[web-ab.ab-testing :as ab])</strong>
<strong>nil</strong>
<strong>user=&gt; (require '[incanter.stats :as s])</strong>
<strong>nil</strong>
<strong>user=&gt; (def group-c (take 100 (concat (repeat 53 1) (repeat 0))))</strong>
<strong>#'user/group-c</strong>
<strong>user=&gt; (def group-t (take 100 (concat (repeat 58 1) (repeat 0))))</strong>
<strong>#'user/group-t</strong>
<strong>user=&gt; (s/cdf-t (ab/binomial-t-test group-t group-c)</strong>
<strong>                :df (ab/degrees-of-freedom t c))</strong>
<strong>9.553337936305223E-12</strong>
</pre></div><p>So we can see that in<a id="id674" class="indexterm"/> the case of the coin flips, the coin is in fact biased and<a id="id675" class="indexterm"/> significantly so.</p></div></div></div><div><div><div><div><h2 class="title"><a id="ch08lvl2sec63"/>Testing the results</h2></div></div></div><p>Let's take this same<a id="id676" class="indexterm"/> process <a id="id677" class="indexterm"/>and apply it again to the A/B test that we just conducted. This will help us see where the statistics in the preceding table came from:</p><div><ol class="orderedlist arabic"><li class="listitem">First, we'll create the data sets by taking the number of observations and successes from each group:<div><pre class="programlisting">
<strong>user=&gt; (def c (take 1226 (concat (repeat 252 1.0)</strong>
<strong>                                 (repeat 0.0))))</strong>
<strong>#'user/c</strong>
<strong>user=&gt; (def t (take 1200 (concat (repeat 317 1.0)</strong>
<strong>                                 (repeat 0.0))))</strong>
<strong>#'user/t</strong>
</pre></div></li><li class="listitem">Now, we can compute the mean and variance for each group:<div><pre class="programlisting">
<strong>user=&gt; (ab/binomial-mean t)</strong>
<strong>317.0</strong>
<strong>user=&gt; (ab/binomial-variance t)</strong>
<strong>233.25916666666666</strong>
<strong>user=&gt; (ab/binomial-mean c)</strong>
<strong>252.0</strong>
<strong>user=&gt; (ab/binomial-variance c)</strong>
<strong>200.20228384991844</strong>
</pre></div></li><li class="listitem">This allows us to find the standard error:<div><pre class="programlisting">
<strong>user=&gt; (ab/binomial-se t c)</strong>
<strong>0.5980633502426848</strong>
</pre></div></li><li class="listitem">Finally, we can get the t-value, degrees of freedom, and the p-value.<div><pre class="programlisting">
<strong>user=&gt; (ab/binomial-t-test t c)</strong>
<strong>108.68413851747313</strong>
<strong>user=&gt; (ab/degrees-of-freedom t c)</strong>
<strong>2401.108650831878</strong>
<strong>user=&gt; (s/cdf-t *2 :df *1)</strong>
<strong>1.0</strong>
</pre></div></li></ol></div><p>This gives us the probability that the test results did not occur randomly. We're looking for them to be over 0.95, and they clearly are.</p><p>If this data occurred <a id="id678" class="indexterm"/>naturally, the very high p value makes us suspect that we may have a <strong>type one error</strong><a id="id679" class="indexterm"/> or a false positive. However, in this case, <a id="id680" class="indexterm"/>the data wasn't generated completely randomly. In the code download, I've combined all of these into one function that gets called to perform the statistical test. This is what is used to generate the data for the table on the results page.</p></div></div>
<div><div><div><div><h1 class="title"><a id="ch08lvl1sec58"/>Summary</h1></div></div></div><p>Over the course of this chapter, we've seen how to conceive of, create, and analyze the results of an A/B test.</p><p>The statistics themselves are really a continuation of the null-hypothesis testing that we saw in <a class="link" href="ch07.html" title="Chapter 7. Null Hypothesis Tests – Analyzing Crime Data">Chapter 7</a>, <em>Null Hypothesis Tests – Analyzing Crime Data</em>. A/B testing provides a nice, complete, useful example of the workflow involved in using null-hypothesis testing and of the power and the help in the decision-making that it provides.</p><p>This allows us to use a standard and widely used way of testing exactly what variations on a website drive more interactions and allow us to identify and serve the site's users in a better manner. It allows us to decide on changes to the site in structured, testable ways.</p><p>Of course, in actuality, we'll probably want to use an existing service. There are several services out there, from bare bones but free services such as Google Analytics Content Experiments to full-featured for-pay services that cover all aspects of A/B testing, such as <strong>Optimizely</strong>, <strong>Visual Website Optimizer</strong>, or <strong>Maxymiser</strong>. However, knowing what's involved in A/B testing and what the best practices are means that we can evaluate and use these services and get the most from them in a better manner.</p><p>In the next chapter, we'll look at applying the data analysis to another part of the Web; we'll analyze how people participate in social sites by looking at patterns of participation in the <strong>Stackoverflow</strong> (<a class="ulink" href="http://stackoverflow.com/">http://stackoverflow.com/</a>) data dumps.</p></div></body></html>