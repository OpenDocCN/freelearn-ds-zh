- en: Why GPU Programming?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么选择GPU编程？
- en: It turns out that besides being able to render graphics for video games, **graphics
    processing units** (**GPUs**) also provide a readily accessible means for the
    general consumer to do *massively parallel* *computing*—an average person can
    now buy a $2,000 modern GPU card from a local electronics store, plug it into
    their PC at home, and then use it almost immediately for computational power that
    would only have been available in the supercomputing labs of top corporations
    and universities only 5 or 10 years ago. This open accessibility of GPUs has become
    apparent in many ways in recent years, which can be revealed by a brief observation
    of the news—cryptocurrency miners use GPUs to generate digital money such as Bitcoins,
    geneticists and biologists use GPUs for DNA analysis and research, physicists
    and mathematicians use GPUs for large-scale simulations, AI researchers can now
    program GPUs to write plays and compose music, while major internet companies,
    such as Google and Facebook, use *farms* of servers with GPUs for large-scale
    machine learning tasks… the list goes on and on.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 结果表明，除了能够为视频游戏渲染图形之外，**图形处理单元**（**GPU**）还为普通消费者提供了一个易于访问的**大规模并行****计算**手段——一个普通人现在可以从当地的电子产品店购买一张价值2000美元的现代GPU显卡，将其插入家里的PC，然后几乎立即使用它进行计算能力，这在5到10年前只有顶级公司和大学的超级计算机实验室才能提供。近年来，GPU的这种开放可访问性在许多方面都变得明显，这可以通过对新闻的简要观察来揭示——加密货币矿工使用GPU生成比特币等数字货币，遗传学家和生物学家使用GPU进行DNA分析和研究，物理学家和数学家使用GPU进行大规模模拟，AI研究人员现在可以编程GPU编写剧本和创作音乐，而像谷歌和Facebook这样的主要互联网公司则使用配备GPU的服务器**农场**进行大规模机器学习任务……这个列表可以一直继续下去。
- en: This book is primarily aimed at bringing you up to speed with GPU programming,
    so that you too may begin using their power as soon as possible, no matter what
    your end goal is. We aim to cover the core essentials of how to program a GPU,
    rather than provide intricate technical details and schematics of how a GPU works.
    Toward the end of the book, we will provide further resources so that you may
    specialize further, and apply your new knowledge of GPUs. (Further details as
    to particular required technical knowledge and hardware follow this section.)
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的主要目的是让您尽快掌握GPU编程，这样您也可以尽快开始使用它们的强大功能，无论您的最终目标是什么。我们的目标是涵盖如何编程GPU的核心基本知识，而不是提供GPU如何工作的复杂技术细节和图示。在本书的结尾，我们将提供进一步的资源，以便您可以进一步专业化，并应用您对GPU的新知识。（关于特定所需的技术知识和硬件的进一步细节将在本节之后提供。）
- en: In this book, we will be working with **CUDA**, a framework for **general-purpose
    GPU** (**GPGPU**) programming from NVIDIA, which was first released back in 2007\.
    While CUDA is proprietary for NVIDIA GPUs, it is a mature and stable platform
    that is relatively easy to use, provides an unmatched set of first-party accelerated
    mathematical and AI-related libraries, and comes with the minimal hassle when
    it comes to installation and integration. Moreover, there are readily available
    and standardized Python libraries, such as PyCUDA and Scikit-CUDA, which make
    GPGPU programming all the more readily accessible to aspiring GPU programmers.
    For these reasons, we are opting to go with CUDA for this book.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书中，我们将使用**CUDA**，这是NVIDIA提供的用于**通用GPU**（**GPGPU**）编程的框架，它最初于2007年发布。虽然CUDA是NVIDIA
    GPU的专有技术，但它是一个成熟且稳定的平台，相对容易使用，提供了一套无与伦比的第三方加速数学和AI相关库，并且在安装和集成方面几乎无烦恼。此外，还有现成的和标准化的Python库，如PyCUDA和Scikit-CUDA，这使得GPGPU编程对有志于GPU编程的人来说更加容易接触。出于这些原因，我们选择在本书中使用CUDA。
- en: CUDA is *always* pronounced *coo-duh*, and never as the acronym *C-U-D-A*! CUDA
    originally stood for *Compute Unified Device Architecture*, but Nvidia has dropped
    the acronym and now uses CUDA as a proper name written in all-caps.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: CUDA的发音是**coo-duh**，而不是作为缩写**C-U-D-A**！CUDA最初代表**Compute Unified Device Architecture**，但NVIDIA已经放弃了这个缩写，现在将CUDA作为一个全大写的正确名称。
- en: We will now start our journey into GPU programming with an overview of **Amdahl's
    Law**. Amdahl's Law is a simple but effective method to estimate potential speed
    gains we can get by offloading a program or algorithm onto a GPU; this will help
    us determine whether it's worth our effort to rewrite our code to make use of
    the GPU. We will then go over a brief review of how to profile our Python code
    with the *cProfile* module, to help us find the bottlenecks in our code.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将开始我们的GPU编程之旅，首先概述**Amdahl定律**。Amdahl定律是一种简单但有效的方法，可以估计通过将程序或算法卸载到GPU上所能获得的潜在速度提升；这将帮助我们确定是否值得我们努力重写代码以利用GPU。然后我们将简要回顾如何使用*cProfile*模块分析我们的Python代码，以帮助我们找到代码中的瓶颈。
- en: 'The learning outcomes for this chapter are as follows:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的学习成果如下：
- en: Understand Amdahl's Law
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解Amdahl定律
- en: Apply Amdahl's Law in the context of your code
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在你的代码中应用Amdahl定律
- en: Using the *cProfile* module for basic profiling of Python code
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用*cProfile*模块进行Python代码的基本分析
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'An installation of Anaconda Python 2.7 is suggested for this chapter:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 建议为本章安装Anaconda Python 2.7：
- en: '[https://www.anaconda.com/download/](https://www.anaconda.com/download/)'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[Anaconda下载](https://www.anaconda.com/download/)'
- en: 'This chapter''s code is also available on GitHub:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码也可在GitHub上找到：
- en: '[https://github.com/PacktPublishing/Hands-On-GPU-Programming-with-Python-and-CUDA](https://github.com/PacktPublishing/Hands-On-GPU-Programming-with-Python-and-CUDA)'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[使用Python和CUDA进行GPU编程实战](https://github.com/PacktPublishing/Hands-On-GPU-Programming-with-Python-and-CUDA)'
- en: For more information about the pre-requisites, check the preface of this book;
    for the software and hardware requirements, check the README section in [https://github.com/PacktPublishing/Hands-On-GPU-Programming-with-Python-and-CUDA](https://github.com/PacktPublishing/Hands-On-GPU-Programming-with-Python-and-CUDA).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 关于先决条件的更多信息，请查看本书的序言；关于软件和硬件要求，请查看[使用Python和CUDA进行GPU编程实战](https://github.com/PacktPublishing/Hands-On-GPU-Programming-with-Python-and-CUDA)的README部分。
- en: Parallelization and Amdahl's Law
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 并行化和Amdahl定律
- en: Before we can dive in and unlock the potential of GPUs, we first have to realize
    where their computational power lies in comparison to a modern Intel/AMD central
    processing unit (CPU)—the power does not lie in the fact that it has a higher
    clock speed than a CPU, nor in the complexity or particular design of the individual
    cores. An individual GPU core is actually quite simplistic, and at a disadvantage
    when compared to a modern individual CPU core, which use many fancy engineering
    tricks, such as branch prediction to reduce the **latency** of computations. **Latency**
    refers to the beginning-to-end duration of performing a single computation.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入挖掘并解锁GPU的潜力之前，我们首先必须意识到与现代英特尔/AMD中央处理单元（CPU）相比，它们的计算能力在哪里——这种能力并不在于它比CPU有更高的时钟速度，也不在于单个核心的复杂性或特定设计。单个GPU核心实际上相当简单，并且在与现代单个CPU核心相比时处于劣势，后者使用许多复杂的工程技巧，例如分支预测来减少计算的**延迟**。**延迟**指的是执行单个计算从开始到结束的总持续时间。
- en: The power of the GPU derives from the fact that there are many, many more cores
    than in a CPU, which means a huge step forward in **throughput**. **Throughput**
    here refers to the number of computations that can be performed simultaneously.
    Let's use an analogy to get a better understanding of what this means. A GPU is
    like a very wide city road that is designed to handle many slower-moving cars
    at once (high throughput, high latency), whereas a CPU is like a narrow highway
    that can only admit a few cars at once, but can get each individual car to its
    destination much quicker (low throughput, low latency).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: GPU的强大之处在于其核心数量远多于CPU，这意味着在**吞吐量**上有了巨大的进步。这里的**吞吐量**指的是可以同时进行的计算数量。让我们用一个类比来更好地理解这意味着什么。GPU就像一条非常宽阔的城市道路，设计用来同时处理许多低速行驶的汽车（高吞吐量，高延迟），而CPU则像一条狭窄的高速公路，一次只能允许几辆车通过，但可以将每辆单独的汽车更快地送到目的地（低吞吐量，低延迟）。
- en: We can get an idea of the increase in throughput by seeing how many cores these
    new GPUs have. To give you an idea, the average Intel or AMD CPU has only two
    to eight cores—while an entry-level, consumer-grade NVIDIA GTX 1050 GPU has *640
    cores*, and a new top-of-the-line NVIDIA RTX 2080 Ti has *4,352 cores*! We can
    exploit this massive throughput, provided we know how properly to **parallelize**
    any program or algorithm we wish to speed up. By **parallelize**, we mean to rewrite
    a program or algorithm so that we can split up our workload to run in parallel
    on multiple processors simultaneously. Let's think about an analogy from real-life.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 通过查看这些新GPU有多少核心，我们可以了解吞吐量的增加。为了给你一个概念，平均的英特尔或AMD CPU只有两个到八个核心——而入门级消费级NVIDIA
    GTX 1050 GPU有*640个核心*，而最新的顶级NVIDIA RTX 2080 Ti有*4,352个核心*！只要我们知道如何正确地**并行化**我们希望加速的任何程序或算法，我们就可以利用这种巨大的吞吐量。通过**并行化**，我们的意思是通过重写程序或算法，以便我们可以将我们的工作负载分割成在多个处理器上同时并行运行。让我们从现实生活中的一个类比来思考。
- en: Suppose that you are building a house and that you already have all of the designs
    and materials in place. You hire a single laborer, and you estimate it will take
    100 hours to construct the house. Let's suppose that this particular house can
    be built in such a way that the work can be perfectly divided between every additional
    laborer you hire—that is to say, it will take 50 hours for two laborers, 25 hours
    for four laborers, and 10 hours for ten laborers to construct the house—the number
    of hours to construct your house will be 100 divided by the number of laborers
    you hire. This is an example of a **parallelizable task**.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你正在建造一栋房子，并且你已经准备好了所有的设计和材料。你雇佣了一个工人，并估计建造这栋房子需要100小时。让我们假设这栋特定的房子可以以这种方式建造，即额外雇佣的每个工人都可以完美地分担工作——也就是说，两个工人需要50小时，四个工人需要25小时，十个工人需要10小时来建造这栋房子——建造你房子的所需小时数将是100除以你雇佣的工人数量。这是一个**可并行化任务**的例子。
- en: We notice that this task is twice as fast to complete for two laborers, and
    ten times as fast for ten laborers to complete together (that is, in *parallel)*
    as opposed to one laborer building the house alone (that is, in *serial)*—that
    is, if *N* is the number of laborers, then it will be *N* times as fast. In this
    case, *N* is known as the **speedup** of parallelizing our task over the serial
    version of our task.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们注意到，对于两个工人来说，完成这项任务的速度是单独一个工人独自建造房屋（即串行）的两倍，对于十个工人一起完成（即并行）则是十倍——也就是说，如果 *N*
    是工人的数量，那么它将是 *N* 倍快。在这种情况下，*N* 被称为将我们的任务并行化到串行版本中的**加速比**。
- en: Before we begin to program a parallel version of a given algorithm, we often
    start by coming up with an estimate of the *potential* *speedup* that parallelization
    would bring to our task. This can help us determine whether it is worth expending
    resources and time writing a parallelization of our program or not. Because real
    life is more complicated than the example we gave here, it's pretty obvious that
    we won't be able to parallelize every program perfectly, all of the time—most
    of the time, only a part of our program will be nicely parallelizable, while the
    rest will have to run in serial.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始编写给定算法的并行版本之前，我们通常首先估算一下并行化将给我们的任务带来的**潜在**加速比。这有助于我们确定是否值得投入资源和时间来编写程序的并行化版本。因为现实生活比我们给出的例子要复杂得多，所以很明显，我们不可能总是完美地并行化每个程序——大多数时候，只有我们程序的一部分可以很好地并行化，而其余部分则必须串行运行。
- en: Using Amdahl's Law
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Amdahl定律
- en: We will now derive **Amdahl's Law**, which is a simple arithmetic formula that
    is used to estimate potential speed gain that may arise from parallelizing some
    portion of code from a serial program onto multiple processors. We will do this
    by continuing with our prior analogy of building a house.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将推导出**Amdahl定律**，这是一个简单的算术公式，用于估算将串行程序的一部分代码并行化到多个处理器上可能产生的潜在速度提升。我们将通过继续我们之前的建造房子的类比来完成这个推导。
- en: Last time, we only considered the actual physical construction of the house
    as the entire time duration, but now, we will also consider the time it takes
    to design the house into the time duration for building the house. Suppose that
    only one person in the world has the ability to design your house—you—and it takes
    you 100 hours to design the plans for your house. There is no possibility that
    any other person on the planet can compare to your architectural brilliance, so
    there is no possibility that this part of the task can be split up at all between
    other architects—that is, so it will take 100 hours to design your house, regardless
    of what resources you have or how many people you can hire. So, if you have only
    one laborer to build your house, the entire time it will take to build your home
    will be 200 hours—100 hours for you to design it, and 100 hours for a single laborer
    to build it. If we hire two laborers, this will take 150 hours—the time to design
    the house will remain at 100 hours, while the construction will take 50 hours.
    It's clear that the total number of hours to construct the house will be 100 +
    100 / *N*, where *N* is the number of laborers we hire.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 上次，我们只考虑了房屋的实际物理建造作为整个时间跨度，但现在，我们也将设计房屋的时间纳入建造房屋的时间跨度。假设世界上只有一个人有设计你房屋的能力——那就是你——而你设计你房屋的计划需要100小时。没有其他任何人能与你相比的建筑天赋，所以这部分任务根本不可能被其他建筑师分担——也就是说，设计你的房屋将需要100小时，无论你拥有多少资源或能雇佣多少人。所以，如果你只有一个劳动力来建造你的房屋，建造整个房屋所需的时间将是200小时——100小时用于设计，100小时用于单个劳动力建造。如果我们雇佣两个劳动力，这将需要150小时——设计房屋的时间将保持为100小时，而建造将需要50小时。很明显，建造房屋所需的总小时数将是100
    + 100 / *N*，其中*N*是我们雇佣的劳动力数量。
- en: Now, let's step back and think about how much time building the house takes
    if we hire one laborer—we ultimately use this to determine speedup as we hire
    additional laborers; that is, how many times faster the process becomes. If we
    hire a single laborer, we see that it takes the same amount of time to both design
    and construct the house—100 hours. So, we can say that that the portion of time
    spent on the design is .5 (50%), and the portion of the time it takes to construct
    the house is .5 (50%)—of course, both of these portions add up to 1, that is 100%.
    We want to make comparisons to this as we add laborers—if we have two laborers,
    the portion of time for the construction is halved, so in comparison to the original
    serial version of our task, this will take .5 + .5/2 = .75 (75%) of the time of
    the original task, and .75 x 200 hours is 150 hours, so we can see that this works.
    Moreover, we can see that if we have *N* laborers, we can calculate the percentage
    of time our *parallelized* construction with *N* laborers will take which the
    formula .5 + .5 / N.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们退一步思考，如果我们雇佣一个劳动力，建造房屋需要多少时间——我们最终使用这个来确定随着我们雇佣更多劳动力时的加速比；也就是说，这个过程变得有多快。如果我们雇佣一个劳动力，我们会看到设计和建造房屋所需的时间相同——100小时。所以，我们可以这样说，在设计上花费的时间部分是0.5（50%），建造房屋所需的时间部分也是0.5（50%），当然，这两个部分加起来是1，即100%。当我们增加劳动力时，我们想要与这个进行比较——如果我们有两个劳动力，建造的时间部分减半，所以与我们的任务原始串行版本相比，这将需要0.5
    + 0.5/2 = 0.75（75%）的时间，0.75乘以200小时是150小时，所以我们可以看到这是有效的。此外，我们可以看到，如果我们有*N*个劳动力，我们可以计算出*N*个劳动力的并行化建造将需要多少时间，公式是0.5
    + 0.5 / *N*。
- en: Now, let's determine the *speedup* we are gaining by adding additional laborers.
    Since it takes 75% of the time to build a house if we have two laborers, we can
    take the reciprocal of .75 to determine the speedup of our parallelization—that
    is, the speedup will be 1 / .75, which is around 1.33 times faster than if we
    only have one laborer. In this case, we see that the speedup will be 1 / (.5 +
    .5 / *N*) if we have *N* laborers.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们确定通过增加额外劳动力所获得的 *加速比*。如果我们有两个劳动力，建造房屋需要75%的时间，我们可以取0.75的倒数来确定我们并行化的加速比——也就是说，加速比将是1
    / 0.75，大约是1.33倍于只有一个劳动力的情况。在这种情况下，如果我们有*N*个劳动力，加速比将是1 / (0.5 + 0.5 / *N*)。
- en: We know that .5 / N will shrink very close to 0 as we add more and more laborers,
    so we can see there is always an upper bound on the speedup you can get when you
    parallelize this task—that is, 1 / (.5 + 0) = 2\. We can divide the original serial
    time with the estimated maximum speedup to determine an absolute minimum amount
    of time this task will take—200 / 2 = 100 hours.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道，随着我们添加越来越多的劳动者，.5 / N 将非常接近0，因此我们可以看到，当你并行化这个任务时，你总能得到一个速度提升的上限——即1 / (.5
    + 0) = 2。我们可以用估计的最大速度提升来除以原始串行时间，以确定这个任务将花费的绝对最小时间——200 / 2 = 100小时。
- en: The principle we have just applied to determine speedups in parallel programming
    is known as **Amdahl's Law**. It only requires knowledge of the parallelizable
    proportion of execution time for code in our original serial program, which is
    referred to as *p*, and the number of processor cores *N* that we have available.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚应用于确定并行编程中加速原理的规则被称为**阿姆达尔定律**。它只需要了解我们原始串行程序中代码的可并行化执行时间比例，这被称为*p*，以及我们可用的处理器核心数*N*。
- en: The proportion of execution time for code that is not parallelizable in this
    case is always *1 – p*, so we only need to know *p.*
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，不可并行化代码的执行时间比例总是*1 – p*，所以我们只需要知道*p*。
- en: 'We can now calculate speedup with **Amdahl''s Law** as follows:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以使用**阿姆达尔定律**如下计算速度提升：
- en: '![](img/6cadaf5b-8271-4a68-97f5-c0ef0c7ce418.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6cadaf5b-8271-4a68-97f5-c0ef0c7ce418.png)'
- en: To sum it up, Amdahl's Law is a simple formula that allows us to roughly (*very
    roughly)* estimate potential speedup for a program that can be at least partially
    parallelized. This can provide a general idea as to whether it will be worthwhile
    to write a parallel version of a particular serial program, provided we know what
    proportion of the code we can parallelize (*p*), and how many cores we can run
    our parallelized code on (*N*).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，阿姆达尔定律是一个简单的公式，它允许我们大致（非常粗略地）估计一个至少可以部分并行化的程序的可能速度提升。这可以提供一个一般性的想法，即是否值得编写特定串行程序的并行版本，前提是我们知道我们可以并行化多少代码（*p*），以及我们可以在多少核心上运行我们的并行化代码（*N*）。
- en: The Mandelbrot set
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**曼德尔布罗特集**'
- en: We are now prepared to see a very standard example for parallel computing that
    we will revisit later in this text—an algorithm to generate an image of the *Mandelbrot
    set*. Let's first define exactly what we mean.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在准备看到一个非常标准的并行计算示例，我们将在本文的后面部分再次讨论——一个生成*曼德尔布罗特集*图像的算法。让我们首先准确地定义我们的意思。
- en: For a given complex number, *c*, we define a recursive sequence for ![](img/dd84683c-b705-45c0-9e1c-38a047267cc3.png),
    with ![](img/c18dfdf9-11a0-4f03-bc42-fe6b3eb9bd04.png) and![](img/28ea6645-7e3f-4dfe-abd3-218ad0efc60d.png)
    for ![](img/432f297f-deb2-4c14-a670-d20f5651a213.png). If |*z[n]*| remains bounded
    by 2 as *n* increases to infinity, then we will say that *c* is a member of the
    Mandelbrot set.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 对于给定的复数*c*，我们定义一个递归序列用于![](img/dd84683c-b705-45c0-9e1c-38a047267cc3.png)，其中![](img/c18dfdf9-11a0-4f03-bc42-fe6b3eb9bd04.png)和![](img/28ea6645-7e3f-4dfe-abd3-218ad0efc60d.png)对于![](img/432f297f-deb2-4c14-a670-d20f5651a213.png)。如果|*z[n]*|在*n*增加到无穷大时仍然被2所限制，那么我们将说*c*是曼德尔布罗特集的成员。
- en: 'Recall that we can visualize the complex numbers as residing on a two-dimensional
    Cartesian plane, with the *x*-axis representing the real components and the y-axis
    representing the imaginary components. We can therefore easily visualize the Mandelbrot
    set with a very appealing (and well-known) graph. Here, we will represent members
    of the Mandelbrot set with a lighter shade, and nonmembers with a darker shade
    on the complex Cartesian plane as follows:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，我们可以将复数可视化为位于二维笛卡尔平面上，其中*x*轴代表实部，y轴代表虚部。因此，我们可以很容易地用一个非常吸引人（并且众所周知）的图表来可视化曼德尔布罗特集。在这里，我们将用较浅的色调表示曼德尔布罗特集的成员，用较深的色调表示非成员，如下所示：
- en: '![](img/9808a92f-5a3b-42e2-bf31-ee4297cd94ea.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9808a92f-5a3b-42e2-bf31-ee4297cd94ea.png)'
- en: Now, let's think about how we would go about generating this set in Python.
    We have to consider a few things first—since we obviously can't check whether
    every single complex number is in the Mandelbrot set, we have to choose a certain
    range to check over; we have to determine how many points in each range we will
    consider (*width, height*); and the maximum value of *n* that we will check |*z[n]*|
    for (`max_iters`). We can now prepare to implement a function to generate a graph
    of the Mandelbrot set—here, we do this by iterating over every single point in
    the graph in *serial*.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们考虑如何在Python中生成这个集合。我们首先必须考虑一些事情——因为我们显然不能检查每个复数是否在Mandelbrot集中，我们必须选择一个特定的范围来检查；我们必须确定每个范围内我们将考虑的点数（*宽度，高度*）；以及我们将检查的*最大值*n的值（`max_iters`）。我们现在可以准备实现一个生成Mandelbrot集图的函数——在这里，我们通过在图中迭代每个点来按顺序执行。
- en: 'We will start by importing the NumPy library, which is a numerical library
    that we will be making ample use of throughout this text. Our implementation here
    is in the `simple_mandelbrot` function. We start by using NumPy''s `linspace`
    function to generate a lattice that will act as a discrete complex plane (the
    rest of the code that follows should be fairly straightforward):'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先导入NumPy库，这是一个数值库，我们将在整篇文章中大量使用。我们的实现在这里是`simple_mandelbrot`函数。我们首先使用NumPy的`linspace`函数生成一个网格，这个网格将作为离散的复平面（接下来的代码应该相当直接）：
- en: '[PRE0]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Now, we want to add some code to dump the image of the Mandelbrot set to a
    PNG format file, so let''s add the appropriate headers at the beginning:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们想要添加一些代码来将Mandelbrot集的图像输出为PNG格式文件，所以让我们在开头添加适当的头文件：
- en: '[PRE1]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Now, let''s add some code to generate the Mandelbrot set and dump it to a file,
    and use the time function to time both operations:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们添加一些代码来生成Mandelbrot集并将其输出到文件，并使用time函数来计时这两个操作：
- en: '[PRE2]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now let''s run this program (this is also available as the `mandelbrot0.py`
    file, in folder `1`, within the GitHub repository):'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们运行这个程序（这个程序也可以作为`mandelbrot0.py`文件，位于GitHub仓库的`1`文件夹中）：
- en: '![](img/c06de047-84d9-45c7-b526-fa42221273bf.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/c06de047-84d9-45c7-b526-fa42221273bf.png)'
- en: It took about 14.62 seconds to generate the Mandelbrot set, and about 0.11 seconds
    to dump the image. As we have seen, we generate the Mandelbrot set point by point;
    there is no interdependence between the values of different points, and it is,
    therefore, an intrinsically parallelizable function. In contrast, the code to
    dump the image cannot be parallelized.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 生成Mandelbrot集大约需要14.62秒，而将图像输出大约需要0.11秒。正如我们所看到的，我们是逐点生成Mandelbrot集的；不同点的值之间没有相互依赖性，因此它是一个本质上可并行化的函数。相比之下，输出图像的代码不能并行化。
- en: Now, let's analyze this in terms of Amdahl's Law. What sort of speedups can
    we get if we parallelize our code here? In total, both pieces of the program took
    about 14.73 seconds to run; since we can parallelize the Mandelbrot set generation,
    we can say that the portion of execution time for parallelizable code is *p* =
    14.62 / 14.73 = .99\. This program is 99% parallelizable!
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们从Amdahl定律的角度来分析这个问题。如果我们在这里并行化代码，我们能获得什么样的加速效果？整个程序运行大约需要14.73秒；由于我们可以并行化Mandelbrot集的生成，我们可以认为并行化代码的执行时间部分*p*
    = 14.62 / 14.73 = .99。这个程序有99%的并行性！
- en: 'What sort of speedup can we potentially get? Well, I''m currently working on
    a laptop with an entry-level GTX 1050 GPU with 640 cores; our *N* will thus be
    640 when we use the formula. We calculate the speedup as follows:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们能获得什么样的加速效果？嗯，我现在正在使用一台配备入门级GTX 1050 GPU（640个核心）的笔记本电脑；因此，当我们使用公式时，我们的*N*将是640。我们如下计算加速比：
- en: '![](img/28a9b78a-7113-4023-bfeb-6538e158f111.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/28a9b78a-7113-4023-bfeb-6538e158f111.png)'
- en: That is definitely very good and would indicate to us that it is worth our effort
    to program our algorithm to use the GPU. Keep in mind that Amdahl's Law only gives
    a very rough estimate! There will be additional considerations that will come
    into play when we offload computations onto the GPU, such as the additional time
    it takes for the CPU to send and receive data to and from the GPU; or the fact
    that algorithms that are offloaded to the GPU are only partially parallelizable.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这确实非常好，这会告诉我们，将我们的算法编程以使用GPU是值得的。记住，Amdahl定律只提供了一个非常粗略的估计！当我们将计算卸载到GPU时，会有额外的考虑因素，例如CPU向GPU发送和接收数据所需的时间；或者，卸载到GPU的算法只有部分可并行化。
- en: Profiling your code
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 代码性能分析
- en: 'We saw in the previous example that we can individually time different functions
    and components with the standard `time` function in Python. While this approach
    works fine for our small example program, this won''t always be feasible for larger
    programs that call on many different functions, some of which may or may not be
    worth our effort to parallelize, or even optimize on the CPU. Our goal here is
    to find the bottlenecks and hotspots of a program—even if we were feeling energetic
    and used `time` around every function call we make, we might miss something, or
    there might be some system or library calls that we don''t even consider that
    happen to be slowing things down. We should find candidate portions of the code
    to offload onto the GPU before we even think about rewriting the code to run on
    the GPU; we must always follow the wise words of the famous American computer
    scientist Donald Knuth: Premature optimization is the root of all evil.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的例子中，我们看到了我们可以使用 Python 中的标准 `time` 函数单独计时不同的函数和组件。虽然这种方法对于我们的小型示例程序来说效果不错，但这并不总是适用于调用许多不同函数的大型程序，其中一些可能或可能不值得我们并行化，甚至优化在
    CPU 上。我们的目标是找到程序的瓶颈和热点——即使我们感到精力充沛，在每次函数调用周围使用 `time`，我们可能也会错过某些东西，或者可能有一些系统或库调用我们没有考虑，但恰好是它们减慢了速度。在我们甚至考虑将代码重写为在
    GPU 上运行之前，我们应该找到候选的代码部分来卸载到 GPU 上；我们必须始终遵循著名美国计算机科学家唐纳德·克努特（Donald Knuth）的明智话语：过早优化是万恶之源。
- en: We use what is known as a **profiler** to find these hot spots and bottlenecks
    in our code. A **profiler** will conveniently allow us to see where our program
    is taking the most time, and allow us to optimize accordingly.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用所谓的**分析器**来找到代码中的这些热点和瓶颈。一个**分析器**将方便地让我们看到程序花费最多时间的地方，并允许我们相应地进行优化。
- en: Using the cProfile module
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 cProfile 模块
- en: We will primarily be using the *cProfile* module to check our code. This module
    is a standard library function that is contained in every modern Python installation.
    We can run the profiler from the command line with `-m cProfile`, and specify
    that we want to organize the results by the cumulative time spent on each function
    with `-s cumtime`, and then redirect the output into a text file with the `>`
    operator.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将主要使用 *cProfile* 模块来检查我们的代码。这个模块是标准库中的一个函数，包含在每一个现代 Python 安装中。我们可以通过命令行使用
    `-m cProfile` 来运行分析器，并指定我们想要按每个函数累计花费的时间来组织结果，使用 `-s cumtime`，然后使用 `>` 运算符将输出重定向到文本文件中。
- en: This will work on both the Linux Bash or Windows PowerShell command line.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这在 Linux Bash 或 Windows PowerShell 命令行上都会有效。
- en: 'Let''s try this now:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们试试看：
- en: '![](img/9c107054-44a8-4242-804f-a40a43808776.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/9c107054-44a8-4242-804f-a40a43808776.png)'
- en: 'We can now look at the contents of the text file with our favorite text editor.
    Let''s keep in mind that the output of the program will be included at the beginning
    of the file:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以使用我们喜欢的文本编辑器查看文本文件的内容。让我们记住，程序的输出将包含在文件的开始部分：
- en: '![](img/374abc78-403e-4068-b78f-3e019bd0638c.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/374abc78-403e-4068-b78f-3e019bd0638c.png)'
- en: Now, since we didn't remove the references to `time` in the original example,
    we see their output in the first two lines at the beginning. We can then see the
    total number of function calls made in this program, and the cumulative amount
    of time to run it.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，由于我们没有在原始示例中删除对 `time` 的引用，我们在文件开始的前两行看到了它们的输出。然后我们可以看到在这个程序中进行的总函数调用次数以及运行它的累计时间。
- en: Subsequently, we have a list of functions that are called in the program, ordered
    from the cumulatively most time-consuming functions to the least; the first line
    is the program itself, while the second line is, as expected, the `simple_mandelbrot`
    function from our program. (Notice that the time here aligns with what we measured
    with the `time` command). After this, we can see many libraries and system calls
    that relate to dumping the Mandelbrot graph to a file, all of which take comparatively
    less time. We use such output from *cProfile* to infer where our bottlenecks are
    within a given program.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 随后，我们有一个函数列表，按程序中调用的累积耗时从多到少排序；第一行是程序本身，而第二行是，正如预期的那样，来自我们程序的 `simple_mandelbrot`
    函数。（注意这里的时间与我们使用 `time` 命令测量的时间一致）。之后，我们可以看到许多与将 Mandelbrot 图形输出到文件相关的库和系统调用，所有这些调用相对于较少的时间。我们使用
    *cProfile* 的此类输出来推断给定程序中的瓶颈。
- en: Summary
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: The main advantage of using a GPU over a CPU is its increased throughput, which
    means that we can execute more *parallel* code simultaneously on GPU than on a
    CPU; a GPU cannot make recursive algorithms or nonparallelizable algorithms somewhat
    faster. We see that some tasks, such as the example of building a house, are only
    partially parallelizable—in this example, we couldn't speed up the process of
    *designing* the house (which is intrinsically *serial* in this case), but we could
    speed up the process of the *construction,* by hiring more laborers (which is
    parallelizable in this case).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 使用GPU而不是CPU的主要优势是其更高的吞吐量，这意味着我们可以在GPU上同时执行比CPU更多的*并行*代码；GPU不能使递归算法或不可并行化算法变得稍微快一些。我们注意到一些任务，例如建造房子的例子，只有部分可并行化——在这个例子中，我们无法加快设计房子的过程（在这种情况下，设计本质上是*串行*的），但我们可以通过雇佣更多的工人来加快建设过程（在这种情况下，建设是可并行化的）。
- en: We used this analogy to derive Amdahl's Law, which is a formula that can give
    us a rough estimate of potential speedup for a program if we know the percentage
    of execution time for code that is parallelizable, and how many processors we
    will have to run this code. We then applied Amdahl's Law to analyze a small program
    that generates the Mandelbrot set and dumps it to an image file, and we determined
    that this would be a good candidate for parallelization onto a GPU. Finally, we
    ended with a brief overview of profiling code with the *cPython* module; this
    allows us to see where the bottlenecks in a program are, without explicitly timing
    function calls.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用这个类比来推导阿姆达尔定律，这是一个公式，如果我们知道可并行化代码的执行时间百分比以及我们需要运行此代码的处理器数量，它就可以给我们一个程序潜在加速的粗略估计。然后，我们将阿姆达尔定律应用于分析生成曼德布罗特集并将其输出到图像文件的小程序，并确定这是一个很好的候选者，可以并行化到GPU上。最后，我们简要概述了使用*cPython*模块分析代码；这允许我们看到程序中的瓶颈，而无需显式地计时函数调用。
- en: Now that we have a few of the fundamental concepts in place, and have a motivator
    to learn GPU programming, we will spend the next chapter setting up a Linux- or
    Windows 10-based GPU programming environment. We will then immediately dive into
    the world of GPU programming in the following chapter, where we will actually
    write a GPU-based version of the Mandelbrot program that we saw in this chapter.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经建立了一些基本概念，并且有了学习GPU编程的动机，我们将在下一章设置基于Linux或Windows 10的GPU编程环境。然后，我们将在下一章立即深入GPU编程的世界，在那里我们将实际编写本章中看到的曼德布罗特程序的GPU版本。
- en: Questions
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: There are three `for` statements in this chapter's Mandelbrot example; however,
    we can only parallelize over the first two. Why can't we parallelize over all
    of the `for` loops here?
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 本章的曼德布罗特示例中有三个`for`语句；然而，我们只能并行化前两个。为什么我们不能并行化所有的`for`循环？
- en: What is something that Amdahl's Law doesn't account for when we apply it to
    offloading a serial CPU algorithm to a GPU?
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当我们将阿姆达尔定律应用于将串行CPU算法卸载到GPU时，它没有考虑到什么？
- en: Suppose that you gain exclusive access to three new top-secret GPUs that are
    the same in all respects, except for core counts—the first has 131,072 cores,
    the second has 262,144 cores, and the third has 524,288 cores. If you parallelize
    and offload the Mandelbrot example onto these GPUs (which generates a 512 x 512
    pixel image), will there be a difference in computation time between the first
    and second GPU? How about between the second and third GPU?
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 假设你获得了对三个全新的顶级机密GPU的独家访问权，它们在所有方面都相同，除了核心数量——第一个有131,072个核心，第二个有262,144个核心，第三个有524,288个核心。如果你将这些GPU（生成512
    x 512像素图像的曼德布罗特示例）并行化并卸载，第一个和第二个GPU之间的计算时间会有差异吗？第二个和第三个GPU之间呢？
- en: Can you think of any problems with designating certain algorithms or blocks
    of code as *parallelizable* in the context of Amdahl's Law?
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你能想到在阿姆达尔定律的背景下，将某些算法或代码块指定为*可并行化*的任何问题吗？
- en: Why should we use profilers instead of just using Python's `time` function?
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么我们应该使用分析器而不是仅仅使用Python的`time`函数？
