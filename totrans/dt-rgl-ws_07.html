<html><head></head><body><div id="sbo-rt-content"><div>
			<div id="_idContainer215" class="Content">
			</div>
		</div>
		<div id="_idContainer216" class="Content">
			<h1 id="_idParaDest-204"><a id="_idTextAnchor212"/>7. Advanced Web Scraping and Data Gathering</h1>
		</div>
		<div id="_idContainer248" class="Content">
			<p class="callout-heading">Overview</p>
			<p class="callout">This chapter will introduce you to the concepts of advanced web scraping and data gathering. It will enable you to use <strong class="source-inline">requests</strong> and <strong class="source-inline">BeautifulSoup</strong> to read various web pages and gather data from them. You can perform read operations on XML files and the web using an <strong class="bold">Application Program Interface</strong> (<strong class="bold">API</strong>). You can use regex techniques to scrape useful information from a large and messy text corpus. By the end of this chapter, you will have learned how to gather data from web pages, XML files, and APIs.</p>
			<h1 id="_idParaDest-205"><a id="_idTextAnchor213"/>Introduction</h1>
			<p>The previous chapter covered how to create a successful data wrangling pipeline. In this chapter, we will build a web scraper that can be used by a data wrangling professional in their daily tasks using all of the techniques that we have learned so far. This chapter builds on the foundation of <strong class="source-inline">BeautifulSoup</strong> and introduces various methods for scraping a web page and using an API to gather data.</p>
			<p>In today's connected world, one of the most valued and widely used skills for a data wrangling professional is the ability to extract and read data from web pages and databases hosted on the web. Most organizations host data on the cloud (public or private), and the majority of web microservices these days provide some kind of API for external users to access data. Let's take a look at the following diagram:</p>
			<div>
				<div id="_idContainer217" class="IMG---Figure">
					<img src="Images/B15780_07_01.jpg" alt="Figure 7.1: Data wrangling HTTP request and an XML/JSON reply&#13;&#10;" width="660" height="364"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.1: Data wrangling HTTP request and an XML/JSON reply</p>
			<p>As we can see in the diagram, to fetch data from a web server or a database, we initiate <strong class="bold">H</strong>yper <strong class="bold">T</strong>ext <strong class="bold">T</strong>ransfer <strong class="bold">P</strong>rotocol (<strong class="bold">HTTP</strong>) requests in the form of <strong class="source-inline">XML/JSON</strong>. It is necessary that, as a data wrangling engineer, you know about the structure of web pages and the Python libraries so that you are able to extract data from a web page. The <strong class="bold">World Wide Web</strong> (<strong class="bold">WWW</strong>) is an ever-growing, ever-changing universe, where different data exchange protocols and formats are used. A few of these are widely used and have become standard.</p>
			<p>Python comes equipped with built-in modules, such as <strong class="source-inline">urllib 3</strong>, which can initiate HTTP requests and receive data from the cloud. However, these modules operate at a low level and require a deep knowledge of HTTP protocols, encoding, and requests.</p>
			<h1 id="_idParaDest-206"><a id="_idTextAnchor214"/>The Requests and BeautifulSoup Libraries</h1>
			<p>We will take advantage of two Python libraries in this chapter: <strong class="source-inline">requests</strong> and <strong class="source-inline">BeautifulSoup</strong>. To avoid dealing with HTTP methods at a lower level, we will use the <strong class="source-inline">requests</strong> library. It is an API built on top of pure Python web utility libraries, which makes placing HTTP requests easy and intuitive.</p>
			<p><strong class="source-inline">BeautifulSoup </strong>is one of the most popular HTML parser packages. It parses the HTML content you pass on and builds a detailed tree of all the tags and markup within the page for easy and intuitive traversal. This tree can be used by a programmer to look for certain markup elements (for example, a table, a hyperlink, or a blob of text within a particular <strong class="source-inline">div</strong> ID) to scrape useful data.</p>
			<p>We are going to do a couple of exercises in order to demonstrate how to use the <strong class="source-inline">requests</strong> library and decode the contents of the response received when data is fetched from the server.</p>
			<h2 id="_idParaDest-207"><a id="_idTextAnchor215"/>Exercise 7.01: Using the Requests Library to Get a Response from the Wikipedia Home Page</h2>
			<p>In this exercise, we will use the <strong class="source-inline">requests</strong> library to extract data from a Wikipedia web page. The Wikipedia home page consists of many elements and scripts, all of which are a mix of HTML, CSS, and JavaScript code blocks. While reading from the home page of Wikipedia (<a href="https://en.wikipedia.org/wiki/Main_Page">https://en.wikipedia.org/wiki/Main_Page</a>), the code or markup elements/texts might not be very useful. Therefore, we will peel off the layers of HTML/CSS/JavaScript to pry away the information we are interested in. Let's follow these steps:</p>
			<ol>
				<li>Open a new Jupyter Notebook and import the <strong class="source-inline">requests</strong> library:<p class="source-code">import requests</p></li>
				<li>Assign the home page URL to a variable, <strong class="source-inline">wiki_home</strong>:<p class="source-code">wiki_home = "https://en.wikipedia.org/wiki/Main_Page"</p></li>
				<li>Use the <strong class="source-inline">get</strong> method from the <strong class="source-inline">requests</strong> library to get a response from this page:<p class="source-code">response = requests.get(wiki_home)</p><p class="source-code">response</p><p>The output is as follows:</p><p class="source-code">&lt;Response [200]&gt;</p></li>
				<li>To find out more about the <strong class="source-inline">response</strong> object, enter the following code:<p class="source-code">type(response)</p><p>The output is as follows:</p><p class="source-code">requests.models.Response</p></li>
			</ol>
			<p>As we can see, the output is an object that models the data structure of an HTTP response. It is defined in the <strong class="source-inline">requests</strong> library.</p>
			<p>The web is an extremely dynamic place. For example, it is quite possible that the home page of Wikipedia will have changed by the time somebody uses your code, or that a particular web server will be not be running and your request will fail. If you proceed to write more complex and elaborate code without checking the status of your request, then all that subsequent work will be fruitless.</p>
			<p>A web page request generally comes back with various numeric codes. They are the standard HTTP response codes. The following table shows the common codes you may encounter:</p>
			<div>
				<div id="_idContainer218" class="IMG---Figure">
					<img src="Images/B15780_07_02.jpg" alt="Figure 7.2: HTTP response codes&#13;&#10;" width="1553" height="706"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.2: HTTP response codes</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/3d7qmK0%20">https://packt.live/3d7qmK0.</a></p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/3hEKbff">https://packt.live/3hEKbff</a>.</p>
			<p>In the next exercise, we are going to write a function to check the return code and print out messages as needed. These kinds of small helper/utility functions are incredibly useful for complex projects.</p>
			<h2 id="_idParaDest-208"><a id="_idTextAnchor216"/>Exercise 7.02: Checking the Status of the Web Request</h2>
			<p>In this exercise, we will write a small utility function called <strong class="source-inline">status_check</strong> to check the status of the response received from the server. Our goal here is to check the status code and flag an error/no-error situation by writing a function. We will start by getting into the habit of writing small functions to accomplish small modular tasks, instead of writing long scripts, which are hard to debug and track. Let's follow these steps:</p>
			<ol>
				<li value="1">Open a new Jupyter notebook and create a <strong class="source-inline">status_check</strong> function as follows:<p class="source-code">def status_check(r):</p><p class="source-code">    if r.status_code==200:</p><p class="source-code">        print("Success!")</p><p class="source-code">        return 1</p><p class="source-code">    else:</p><p class="source-code">        print("Failed!")</p><p class="source-code">        return -1</p><p>Note that, along with printing the appropriate message, we are returning either <strong class="source-inline">1</strong> or <strong class="source-inline">-1</strong> from this function. This is important because in the code that utilizes this function, we will be able to examine this return value to find out whether the request was a success or a failure.</p></li>
				<li>Import the <strong class="source-inline">requests</strong> library:<p class="source-code">import requests</p></li>
				<li>Assign the home page URL to a variable, <strong class="source-inline">wiki_home</strong>:<p class="source-code">wiki_home = "https://en.wikipedia.org/wiki/Main_Page"</p></li>
				<li>Use the <strong class="source-inline">get</strong> method from the <strong class="source-inline">requests</strong> library to get a response from this page:<p class="source-code">response = requests.get(wiki_home)</p></li>
				<li>Pass the response object to the <strong class="source-inline">status_check</strong> function to examine the status of the response: <p class="source-code">status_check(response)</p><p>The output is as follows:</p><p class="source-code">Success!</p><p class="source-code">1</p><p class="callout-heading">Note</p><p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/3hHcf1k%20">https://packt.live/3hHcf1k.</a></p><p class="callout">You can also run this example online at <a href="https://packt.live/3hDUhNp">https://packt.live/3hDUhNp</a>.</p></li>
			</ol>
			<p>In this chapter, for more complex programming activity, we will proceed only if we get <strong class="source-inline">1</strong> as the return value of the <strong class="source-inline">status_check</strong> function, that is, we will write a conditional statement to check the return value and then execute the subsequent code based on it.</p>
			<h2 id="_idParaDest-209"><a id="_idTextAnchor217"/>Checking the Encoding of a Web Page</h2>
			<p>We can also write a utility function to check the encoding of a web page. Various encodings are possible with any HTML document, although the most popular is <strong class="source-inline">UTF-8</strong>. Some of the most popular encodings are <strong class="source-inline">ASCII</strong>, <strong class="source-inline">Unicode</strong>, and <strong class="source-inline">UTF-8</strong>. <strong class="source-inline">ASCII</strong> is the simplest, but it cannot capture the complex symbols used in various spoken and written languages all over the world, so <strong class="source-inline">UTF-8</strong> has become the almost universal standard in web development these days.</p>
			<p>When we run this function on the Wikipedia home page, we get back the particular encoding type that's used for that page. This function, like the previous one, takes the <strong class="source-inline">response</strong> object as an argument and returns a value:</p>
			<p class="source-code">def encoding_check(r):</p>
			<p class="source-code">    return (r.encoding)</p>
			<p>Check the response:</p>
			<p class="source-code">response = requests.get("https://en.wikipedia.org/wiki/Main_Page")</p>
			<p class="source-code">encoding_check(response)</p>
			<p>The output is as follows:</p>
			<p class="source-code">'UTF-8'</p>
			<p>Here, <strong class="source-inline">'UTF-8'</strong> denotes the most popular character encoding scheme that's used in the digital medium and on the web today. It employs variable-length encoding with <strong class="source-inline">1-4</strong> bytes, thereby representing all Unicode characters in various languages around the world.</p>
			<h2 id="_idParaDest-210"><a id="_idTextAnchor218"/>Exercise 7.03: Decoding the Contents of a Response and Checking Its Length</h2>
			<p>In this exercise, we will create a function to get the Wikipedia page's contents as a blob of text or as a string object that Python can process afterward. We will first initiate a request to get the contents of a Wikipedia page and store the data in a <strong class="source-inline">response</strong> object. We will then decode this <strong class="source-inline">response</strong> object. To do this, follow these steps:</p>
			<ol>
				<li value="1">Open a new Jupyter Notebook and import the <strong class="source-inline">requests</strong> library:<p class="source-code">import requests</p></li>
				<li>Assign the home page URL to a variable, <strong class="source-inline">wiki_home</strong>:<p class="source-code">wiki_home = "https://en.wikipedia.org/wiki/Main_Page"</p></li>
				<li>Use the <strong class="source-inline">get</strong> method from the <strong class="source-inline">requests</strong> library to get a response from this page:<p class="source-code">response = requests.get(wiki_home)</p></li>
				<li>Write a utility function to decode the contents of the response:<p class="source-code">def encoding_check(r):</p><p class="source-code">    return (r.encoding)</p><p class="source-code">def decode_content(r,encoding):</p><p class="source-code">    return (r.content.decode(encoding))</p><p class="source-code">contents = decode_content(response,encoding_check(response))</p></li>
				<li>Check the type of the decoded object to see what type of data we are finally getting:<p class="source-code">type(contents)</p><p>The output is as follows:</p><p class="source-code">str</p><p>We finally got a string object by reading the HTML page.</p></li>
				<li>Check the length of the object using the <strong class="source-inline">len</strong> function:<p class="source-code">len(contents)</p><p>The output is as follows:</p><p class="source-code">74182</p><p class="callout-heading">Note</p><p class="callout">This output is variable and is susceptible to change depending on the updates made to the Wikipedia web page.</p></li>
				<li>Use the following code to print the first <strong class="source-inline">10,000</strong> characters of this string. It will look something similar to this:<p class="source-code">contents[:10000]</p><p>The output is as follows:</p><div id="_idContainer219" class="IMG---Figure"><img src="Images/B15780_07_03.jpg" alt="Figure 7.3: Partial output showing a mixed blob of HTML markup tags, text, &#13;&#10;and element names and properties&#13;&#10;" width="818" height="199"/></div></li>
			</ol>
			<p class="figure-caption">Figure 7.3: Partial output showing a mixed blob of HTML markup tags, text, and element names and properties</p>
			<p>Obviously, this is a mixed blob of various HTML markup tags, text, and element names/properties. We cannot hope to extract meaningful information from this that could be used for efficient analysis without using sophisticated functions or methods. </p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/2BfmUQq%20">https://packt.live/2BfmUQq.</a></p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/2UW2L8L">https://packt.live/2UW2L8L</a>.</p>
			<p>Fortunately, the <strong class="source-inline">BeautifulSoup</strong> library or <strong class="source-inline">bs4</strong> library provides such methods, and we will see how to use them in the following exercise.</p>
			<h2 id="_idParaDest-211"><a id="_idTextAnchor219"/>Exercise 7.04: Extracting Readable Text from a BeautifulSoup Object</h2>
			<p>In this exercise, we will create a utility function, <strong class="source-inline">decode_content</strong>, to decode the response received after initiating a request to the Wikipedia web page. We will use the <strong class="source-inline">BeautifulSoup</strong> library on the <strong class="source-inline">response</strong> object to further process it so that it becomes easier for us to extract any meaningful information from it. <strong class="source-inline">BeautifulSoup</strong> has a <strong class="source-inline">text</strong> method, which can be used to extract text. Let's follow these steps:</p>
			<ol>
				<li value="1">Open a new Jupyter Notebook and import the <strong class="source-inline">requests</strong> library:<p class="source-code">import requests</p></li>
				<li>Assign the home page URL to a variable, <strong class="source-inline">wiki_home</strong>:<p class="source-code">wiki_home = "https://en.wikipedia.org/wiki/Main_Page"</p></li>
				<li>Use the <strong class="source-inline">get</strong> method from the <strong class="source-inline">requests</strong> library to get a response from this page:<p class="source-code">response = requests.get(wiki_home)</p></li>
				<li>Write a utility function to decode the contents of the response:<p class="source-code">def encoding_check(r):</p><p class="source-code">    return (r.encoding)</p><p class="source-code">def decode_content(r,encoding):</p><p class="source-code">    return (r.content.decode(encoding))</p><p class="source-code">contents = decode_content(response,encoding_check(response))</p></li>
				<li>Import the package and then pass on the whole string (HTML content) to a method for parsing:<p class="source-code">from bs4 import BeautifulSoup</p><p class="source-code">soup = BeautifulSoup(contents, 'html.parser')</p></li>
				<li>Execute the following code in your notebook:<p class="source-code">txt_dump=soup.text</p></li>
				<li>Find the type of the <strong class="source-inline">txt_dmp</strong>:<p class="source-code">type(txt_dump)</p><p>The output is as follows:</p><p class="source-code">str</p></li>
				<li>Find the length of the <strong class="source-inline">txt_dmp</strong>:<p class="source-code">len(txt_dump)</p><p>The output is as follows:</p><p class="source-code">15326</p><p class="callout-heading">Note</p><p class="callout">This output is variable and is susceptible to change depending on the updates made to the Wikipedia web page.</p><p>Now, the length of the text dump is much smaller than the raw HTML string's length. This is because the <strong class="source-inline">bs4</strong> library has parsed through the HTML and extracted only human-readable text for further processing.</p></li>
				<li>Print the initial portion of this text:<p class="source-code">print(txt_dump[10000:11000])</p><p>You will see something similar to the following:</p><div id="_idContainer220" class="IMG---Figure"><img src="Images/B15780_07_04.jpg" alt="Figure 7.4: Output showing the initial portion of text&#13;&#10;" width="798" height="258"/></div></li>
			</ol>
			<p class="figure-caption">Figure 7.4: Output showing the initial portion of text</p>
			<p>In this exercise, we were introduced to the main interface of <strong class="source-inline">BeautifulSoup</strong> or <strong class="source-inline">bs4</strong> and we also saw how we can parse a raw string containing HTML and other types of data using <strong class="source-inline">bs4</strong> and retain only HTML-related data.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/2Cky5rt%20">https://packt.live/2Cky5rt.</a></p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/2Bj2Xbr">https://packt.live/2Bj2Xbr</a>.</p>
			<p>Web pages are becoming more and more dynamic with more and more diverse types of elements and content in them. As a data wrangling engineer, you will have to deal with the growing complexity and the heterogeneous nature of data. So, knowing what we just saw will often give you a big advantage.</p>
			<h2 id="_idParaDest-212"><a id="_idTextAnchor220"/>Extracting Text from a Section</h2>
			<p>Now, let's move on to more exciting data wrangling tasks. If you open the Wikipedia home page, <a href="https://en.wikipedia.org/wiki/Main_Page">https://en.wikipedia.org/wiki/Main_Page,</a> you are likely to see a section called <strong class="source-inline">From today's featured article</strong>. This is an excerpt from the day's featured article, which is randomly selected and promoted on the home page. This article can also change throughout the day:</p>
			<div>
				<div id="_idContainer221" class="IMG---Figure">
					<img src="Images/B15780_07_05.jpg" alt="Figure 7.5: Sample Wikipedia page highlighting the &quot;From today's featured article&quot; section&#13;&#10;" width="1223" height="777"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.5: Sample Wikipedia page highlighting the "From today's featured article" section</p>
			<p>You need to extract the text from this section. There are several ways to accomplish this task. We will go through a simple and intuitive method for doing so here.</p>
			<p>First, we try to identify two indices – the <em class="italic">start index</em> and <em class="italic">end index</em> of the line string – which demarcate the start and end of the text we are interested in extracting or reading. In the next screenshot, the indices are shown:</p>
			<div>
				<div id="_idContainer222" class="IMG---Figure">
					<img src="Images/B15780_07_06.jpg" alt="Figure 7.6: Wikipedia page highlighting the text to be extracted&#13;&#10;" width="1277" height="816"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.6: Wikipedia page highlighting the text to be extracted</p>
			<p>The following code accomplishes the extraction:</p>
			<p class="source-code">idx1=txt_dump.find("From today's featured article")</p>
			<p class="source-code">idx2=txt_dump.find("Recently featured")</p>
			<p class="source-code">print(txt_dump[idx1+len("From today's featured article"):idx2])</p>
			<p>Note that we have to add the length of the <strong class="source-inline">From today's featured article</strong> string to <strong class="source-inline">idx1</strong> and then pass that as the starting index. This is because <strong class="source-inline">idx1</strong> finds where the <strong class="source-inline">From today's featured article</strong> string starts.</p>
			<p>It prints out something like this (this is a sample output):</p>
			<div>
				<div id="_idContainer223" class="IMG---Figure">
					<img src="Images/B15780_07_07.jpg" alt="Figure 7.7: The extracted text&#13;&#10;" width="716" height="174"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.7: The extracted text</p>
			<p class="callout-heading">Note</p>
			<p class="callout">The output you get will vary based on the current featured article.</p>
			<p>As you can see, the <strong class="source-inline">BeautifulSoup</strong> library provides an efficient technique to read data from a source. It will also be interesting to know the events that occurred on a particular day.</p>
			<h2 id="_idParaDest-213"><a id="_idTextAnchor221"/>Extracting Important Historical Events that Happened on Today's Date</h2>
			<p>Next, we will try to extract the text corresponding to the important historical events that happened on today's date. This can generally be found in the bottom-right corner, as shown in the following screenshot:</p>
			<div>
				<div id="_idContainer224" class="IMG---Figure">
					<img src="Images/B15780_07_08.jpg" alt="Figure 7.8: Wikipedia page highlighting the On this day section&#13;&#10;" width="1139" height="641"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.8: Wikipedia page highlighting the On this day section</p>
			<p>So, can we apply the same technique as we did for <strong class="source-inline">From today's featured article</strong>? Apparently not, because there is text just below where we want our extraction to end, which is not fixed, unlike in the previous case. Note that, in the previous section, the fixed string <strong class="source-inline">Recently featured</strong> occurs at the exact place where we want the extraction to stop, so we could use it in our code. However, we cannot do that in this case, and the reason for this is illustrated in the following screenshot:</p>
			<div>
				<div id="_idContainer225" class="IMG---Figure">
					<img src="Images/B15780_07_09.jpg" alt="Figure 7.9: Wikipedia page highlighting the text to be extracted&#13;&#10;" width="1212" height="594"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.9: Wikipedia page highlighting the text to be extracted</p>
			<p>So, in this section, we just want to find out what the text looks like around the main content we are interested in. For that, we must find out the start of the <strong class="source-inline">On this day</strong> string and print out the next 1,000 characters using the following code:</p>
			<p class="source-code">idx3=txt_dump.find("On this day")</p>
			<p class="source-code">print(txt_dump[idx3+len("On this day"):idx3+len("On this day")\</p>
			<p class="source-code">               +1000])</p>
			<p>The output looks as follows:</p>
			<div>
				<div id="_idContainer226" class="IMG---Figure">
					<img src="Images/B15780_07_10.jpg" alt="Figure 7.10: Output of the On this day section from Wikipedia&#13;&#10;" width="1223" height="586"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.10: Output of the On this day section from Wikipedia</p>
			<p>As we can see, there is a bit of unwanted data along with the relevant information that we are really interested in reading (as shown by the arrows). To address this issue, we need to think differently and use some other methods apart from <strong class="source-inline">BeautifulSoup</strong> (and write another utility function).</p>
			<p>HTML pages are made of many markup tags, such as <strong class="source-inline">&lt;div&gt;</strong>, which denotes a division of text/images, and <strong class="source-inline">&lt;ul&gt;</strong>, which denotes lists. In the following exercise, we'll use advanced techniques from the <strong class="source-inline">BeautifulSoup</strong> library to extract relevant information from a web page.</p>
			<h2 id="_idParaDest-214"><a id="_idTextAnchor222"/>Exercise 7.05: Using Advanced BS4 Techniques to Extract Relevant Text</h2>
			<p>In this exercise, we'll take advantage of <strong class="source-inline">BeautifulSoup</strong> library techniques and extract the element that contains the text we are interested in. Let's perform the following steps:</p>
			<ol>
				<li value="1">Open the Wikipedia page using this link: <a href="https://en.wikipedia.org/wiki/Main_Page">https://en.wikipedia.org/wiki/Main_Page</a>.</li>
				<li>In the Mozilla Firefox browser, right-click and select the <strong class="source-inline">Inspect Element</strong> option (in Chrome, we do the same, except the menu option is called <strong class="source-inline">Inspect</strong>) as shown in the following screenshot:<div id="_idContainer227" class="IMG---Figure"><img src="Images/B15780_07_11.jpg" alt="Figure 7.11: Inspecting elements on Wikipedia&#13;&#10;" width="1116" height="687"/></div><p class="figure-caption">Figure 7.11: Inspecting elements on Wikipedia</p><p>As you hover over this with the mouse, you will see different portions of the page being highlighted. By doing this, it is easy to find out which precise block of markup text is responsible for the textual information we are interested in. Here, we can see that a certain <strong class="source-inline">&lt;ul&gt;</strong> block contains the text:</p><div id="_idContainer228" class="IMG---Figure"><img src="Images/B15780_07_12.jpg" alt="Figure 7.12: Identifying the HTML block that contains the text we are interested in&#13;&#10;" width="1270" height="715"/></div><p class="figure-caption">Figure 7.12: Identifying the HTML block that contains the text we are interested in</p><p>Now, it is prudent to find the <strong class="source-inline">&lt;div&gt;</strong> tag that contains this <strong class="source-inline">&lt;ul&gt;</strong> block within it. By looking around the same screen as before, we can find the <strong class="source-inline">&lt;div&gt;</strong> and its <strong class="source-inline">ID</strong>:</p><div id="_idContainer229" class="IMG---Figure"><img src="Images/B15780_07_13.jpg" alt="Figure 7.13: The &lt;ul&gt; tag containing the text&#13;&#10;" width="1387" height="548"/></div><p class="figure-caption">Figure 7.13: The &lt;ul&gt; tag containing the text</p><p>We can do similar things using <strong class="source-inline">bs4</strong> functions. </p></li>
				<li>Start off by importing <strong class="source-inline">requests</strong> and <strong class="source-inline">BeautifulSoup</strong>. Also, retrieve the contents of the Wikipedia Main Page (highlighted).<p class="source-code">import requests </p><p class="source-code">wiki_home = "<strong class="bold">https://en.wikipedia.org/wiki/Main_Page</strong>"</p><p class="source-code">response = requests.get(wiki_home) </p><p class="source-code">def encoding_check(r): </p><p class="source-code">    return (r.encoding) </p><p class="source-code">def decode_content(r,encoding):</p><p class="source-code">    return (r.content.decode(encoding)) </p><p class="source-code">contents = decode_content(response,encoding_check(response))</p><p class="source-code">from bs4 import BeautifulSoup </p><p class="source-code">soup = BeautifulSoup(contents, 'html.parser')</p></li>
				<li>Use the <strong class="source-inline">find_all</strong> method from <strong class="source-inline">BeautifulSoup</strong>, which scans all the tags of the HTML page (and their sub-elements) to find and extract the text associated with this particular <strong class="source-inline">&lt;div&gt;</strong> element. Create an empty list and append the text from the <strong class="source-inline">NavigableString</strong> class to this list as we traverse the page:<p class="source-code">text_list=[] #Empty list</p><p class="source-code">for d in soup.find_all('div'):</p><p class="source-code">    if (d.get('id')=='mp-otd'):</p><p class="source-code">        for i in d.find_all('ul'):</p><p class="source-code">            text_list.append(i.text)</p><p>The <strong class="source-inline">find_all</strong> method returns a <strong class="source-inline">NavigableString</strong> class, which has a useful <strong class="source-inline">text</strong> method associated with it for extraction. Note how we are utilizing the <strong class="source-inline">mp-otd</strong> ID of the <strong class="source-inline">&lt;div&gt;</strong> element to identify it among tens of other <strong class="source-inline">&lt;div&gt;</strong> elements. Now, if we examine the <strong class="source-inline">text_list</strong> list, we will see that it has three elements.</p></li>
				<li>Print the elements separated by a marker. We will see that the text we are interested in appears as the first element:<p class="source-code">for i in text_list:</p><p class="source-code">    print(i)</p><p class="source-code">    print('-'*100)</p><p>The output is as follows:</p></li>
			</ol>
			<div>
				<div id="_idContainer230" class="IMG---Figure">
					<img src="Images/B15780_07_14.jpg" alt="Figure 7.14: The text highlighted&#13;&#10;" width="1432" height="510"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.14: The text highlighted</p>
			<p>As we can see, it is the first element of the list that we are interested in. However, the exact position will depend on the web page. In this exercise, we were introduced to some advanced uses of <strong class="source-inline">BeautifulSoup</strong> and saw how we can extract meaningful information using its APIs.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/2USTDSg%20">https://packt.live/2USTDSg.</a></p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/2zGIUTG">https://packt.live/2zGIUTG</a>.</p>
			<p>Next, we will create a compact function to encapsulate some of those. Creating such functions helps us to increase the reusability of code. </p>
			<p>As we discussed before, it is always good to try to functionalize specific tasks, particularly in a web-scraping application. In the following exercise, we are going to create a compact function. </p>
			<h2 id="_idParaDest-215"><a id="_idTextAnchor223"/>Exercise 7.06: Creating a Compact Function to Extract the On this day Text from the Wikipedia Home Page</h2>
			<p>In this exercise, we are going to create a function that will take the Wikipedia URL (as a string), <a href="https://en.wikipedia.org/wiki/Main_Page">https://en.wikipedia.org/wiki/Main_Page</a>, and return the text corresponding to the <strong class="source-inline">On this day</strong> section. The benefit of a functional approach is that you can call this function from any Python script and use it anywhere in another program as a standalone module. To do this, let's follow these steps:</p>
			<ol>
				<li value="1">Create the compact <strong class="source-inline">def</strong> function. Extract the text from the <strong class="source-inline">On this day</strong> section of the Wikipedia home page, <a href="https://en.wikipedia.org/wiki/Main_Page">https://en.wikipedia.org/wiki/Main_Page</a>. Accept the Wikipedia home page URL as a string. A default URL is provided:<p class="callout-heading">Note</p><p class="callout">It is recommended that you run <em class="italic">Steps 1,2, and 3</em> of this exercise in a single Jupyter Notebook cell.</p><p class="source-code">def wiki_on_this_day(url="https://en.wikipedia.org/"\</p><p class="source-code">                         "wiki/Main_Page"):</p><p class="source-code">    import requests</p><p class="source-code">    from bs4 import BeautifulSoup</p><p class="source-code">    wiki_home = str(url)</p><p class="source-code">    response = requests.get(wiki_home)</p></li>
				<li>Create a function that will check the status of the response received from the web page: <p class="source-code">    def status_check(r):</p><p class="source-code">        if r.status_code==200:</p><p class="source-code">            return 1</p><p class="source-code">        else:</p><p class="source-code">            return -1</p><p class="source-code">    def encoding_check(r): </p><p class="source-code">        return (r.encoding)</p><p class="source-code">    def decode_content(r,encoding): </p><p class="source-code">        return (r.content.decode(encoding))</p><p class="source-code">    status = status_check(response)</p><p class="source-code">    if status==1:</p><p class="source-code">        contents = decode_content(response,\</p><p class="source-code">                                  encoding_check(response))</p><p class="source-code">    else:</p><p class="source-code">        print("Sorry could not reach the web page!")</p><p class="source-code">        return -1</p></li>
				<li> Create a <strong class="source-inline">BeautifulSoup</strong> object and read the contents of the web page:<p class="source-code">soup = BeautifulSoup(contents, 'html.parser')</p><p class="source-code">text_list=[]</p><p class="source-code">for d in soup.find_all('div'):</p><p class="source-code">    if (d.get('id')=='mp-otd'):</p><p class="source-code">        for i in d.find_all('ul'):</p><p class="source-code">            text_list.append(i.text)</p><p class="source-code">return (text_list[0])</p></li>
				<li>Let's see the function in action.<p class="source-code">print(wiki_on_this_day())</p><p>The output will be:</p><div id="_idContainer231" class="IMG---Figure"><img src="Images/B15780_07_15.jpg" alt="Figure 7.15: Output of wiki_on_this_day&#13;&#10;" width="1451" height="346"/></div><p class="figure-caption">Figure 7.15: Output of wiki_on_this_day</p></li>
				<li>Note how this function utilizes the status check and prints out an error message if the request failed. When we test this function with an intentionally incorrect URL, it behaves as expected:<p class="source-code">print(wiki_on_this_day\</p><p class="source-code">      ("https://en.wikipedia.org/wiki/Main_Page1"))</p><p>The output is as follows:</p><p class="source-code">Sorry could not reach the web page!</p></li>
			</ol>
			<p>In this exercise, we saw how to write a function to encapsulate a lot of important things that we have learned about <strong class="source-inline">BeautifulSoup</strong>. </p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/2YcaEJm%20">https://packt.live/2YcaEJm.</a></p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/3hBS2dn">https://packt.live/3hBS2dn</a>.</p>
			<h1 id="_idParaDest-216"><a id="_idTextAnchor224"/>Reading Data from XML</h1>
			<p><strong class="bold">XML</strong> or <strong class="bold">Extensible Markup Language</strong> is a web markup language that's similar to HTML but with significant flexibility (on the part of the user) built in, such as the ability to define your own tags. It was one of the most hyped technologies in the 1990s and early 2000s. It is a meta-language, that is, a language that allows us to define other languages using its mechanics, such as RSS and MathML (a mathematical markup language widely used for web publication and the display of math-heavy technical information). XML is also heavily used in regular data exchanges over the web, and as a data wrangling professional, you should have enough familiarity with its basic features to tap into the data flow pipeline whenever you need to extract data for your project.</p>
			<h2 id="_idParaDest-217"><a id="_idTextAnchor225"/>Exercise 7.07: Creating an XML File and Reading XML Element Objects</h2>
			<p>In this exercise, we'll create some random data and store it in XML format. We'll then read from the XML file and examine the XML-formatted data string. Let's follow these steps:</p>
			<ol>
				<li value="1">Create an XML file using the following command:<p class="source-code">data = '''</p><p class="source-code">&lt;person&gt;</p><p class="source-code">  &lt;name&gt;Dave&lt;/name&gt;</p><p class="source-code">  &lt;surname&gt;Piccardo&lt;/surname&gt;</p><p class="source-code">  &lt;phone type="intl"&gt;</p><p class="source-code">    +1 742 101 4456</p><p class="source-code">  &lt;/phone&gt;</p><p class="source-code">  &lt;email hide="yes"&gt;</p><p class="source-code">    dave.p@gmail.com&lt;/email&gt;</p><p class="source-code">&lt;/person&gt;'''</p><p>As we can see, the <strong class="source-inline">phone</strong> type is a triple-quoted string or multiline string. If you print this object, you will get the following output. This is an XML-formatted data string in a tree structure, as we will see when we parse the structure and break apart the individual parts.</p></li>
				<li>To process and wrangle with the data, we have to read it as an <strong class="source-inline">Element</strong> object using the Python XML parser engine:<p class="source-code">import xml.etree.ElementTree as ET</p><p class="source-code">tree = ET.fromstring(data)</p><p class="source-code">type (tree)</p><p>The output is as follows:</p><p class="source-code">xml.etree.ElementTree.Element</p></li>
			</ol>
			<p>In this exercise, we saw how to create an XML file, how to read an XML file, and what kind of object we can expect when we read an XML file.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/37EDwgt%20">https://packt.live/37EDwgt.</a></p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/3hDwUDv">https://packt.live/3hDwUDv</a>.</p>
			<h2 id="_idParaDest-218"><a id="_idTextAnchor226"/>Exercise 7.08: Finding Various Elements of Data within a Tree (Element)</h2>
			<p>In this exercise, we will use the <strong class="source-inline">find</strong> method to search for various pieces of useful data within an XML element object and print them using the <strong class="source-inline">text</strong> method. We will also use the <strong class="source-inline">get</strong> method to extract the specific attribute we want. To do so, let's follow these steps:</p>
			<ol>
				<li value="1">Create an XML file using the following code:<p class="source-code">data = '''</p><p class="source-code">&lt;person&gt;</p><p class="source-code">  &lt;name&gt;Dave&lt;/name&gt;</p><p class="source-code">  &lt;surname&gt;Piccardo&lt;/surname&gt;</p><p class="source-code">  &lt;phone type="intl"&gt;</p><p class="source-code">    +1 742 101 4456</p><p class="source-code">  &lt;/phone&gt;</p><p class="source-code">  &lt;email hide="yes"&gt;</p><p class="source-code">    dave.p@gmail.com</p><p class="source-code">  &lt;/email&gt;</p><p class="source-code">  &lt;/person&gt;'''</p></li>
				<li>To process and wrangle with the data, we have to read it as an <strong class="source-inline">Element</strong> object using the Python XML parser engine:<p class="source-code">import xml.etree.ElementTree as ET</p><p class="source-code">tree = ET.fromstring(data)</p></li>
				<li>Use the <strong class="source-inline">find</strong> method to find <strong class="source-inline">Name</strong>:<p class="source-code">print('Name:', tree.find('name').text)</p><p>The output is as follows:</p><p class="source-code">Name: Dave</p></li>
				<li>Use the <strong class="source-inline">find</strong> method to find <strong class="source-inline">Surname</strong>:<p class="source-code">print('Surname:', tree.find('surname').text)</p><p>The output is as follows:</p><p class="source-code">Surname: Piccardo</p></li>
				<li>Use the <strong class="source-inline">find</strong> method to find <strong class="source-inline">Phone</strong>. Note the use of the <strong class="source-inline">strip</strong> method to strip away any trailing spaces/blanks:<p class="source-code">print('Phone:', tree.find('phone').text.strip())</p><p>The output will be as follows:</p><p class="source-code">Phone: +1 742 101 4456</p></li>
				<li>Use the <strong class="source-inline">find</strong> method to find <strong class="source-inline">email status</strong> and <strong class="source-inline">actual email</strong>. Note the use of the <strong class="source-inline">get</strong> method to extract the status:<p class="source-code">print('Email hidden:', tree.find('email').get('hide'))</p><p class="source-code">print('Email:', tree.find('email').text.strip())</p><p>The output will be as follows:</p><p class="source-code">Email hidden: yes</p><p class="source-code">Email: dave.p@gmail.com</p></li>
			</ol>
			<p>In this exercise, we saw how we can use the <strong class="source-inline">find</strong> method to read the relevant information from an XML file. XML is a very diverse format of expressing data. Apart from following some ground rules, everything else is customizable in an XML document. In this exercise, we saw how to access a custom XML element and extract data from it.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/3dgSoTf%20">https://packt.live/3dgSoTf.</a></p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/2CjDnU9">https://packt.live/2CjDnU9</a>.</p>
			<h2 id="_idParaDest-219"><a id="_idTextAnchor227"/>Reading from a Local XML File into an ElementTree Object</h2>
			<p>We can also read from an XML file saved locally on disk. This is a fairly common situation where a frontend web scraping module has already downloaded a lot of XML files by reading a table of data on the web and the data wrangler needs to parse through this XML file to extract meaningful pieces of numerical and textual data.</p>
			<p>We have a file associated with this chapter called <strong class="source-inline">xml1.xml</strong>. The file can be found here: <a href="https://packt.live/3e8jM7n">https://packt.live/3e8jM7n</a>.</p>
			<p>Please make sure you have the file in the same directory that you are running your Jupyter notebook from:</p>
			<p class="source-code">tree2=ET.parse('../datasets/xml1.xml')</p>
			<p class="source-code">type(tree2)</p>
			<p>The output will be as follows: </p>
			<p class="source-code">xml.etree.ElementTree.ElementTree</p>
			<p>Note how we use the <strong class="source-inline">parse</strong> method to read this XML file. This is slightly different than using the <strong class="source-inline">fromstring</strong> method used in the previous exercise, where we were directly reading from a <strong class="source-inline">string</strong> object. This produces an <strong class="source-inline">ElementTree</strong> object instead of a simple <strong class="source-inline">Element</strong>.</p>
			<p>The idea of building a tree-like object is the same as in the domains of computer science and programming. Let's take a look at the following diagram:</p>
			<div>
				<div id="_idContainer232" class="IMG---Figure">
					<img src="Images/B15780_07_16.jpg" alt="Figure 7.16: Tree-like children nodes&#13;&#10;" width="1140" height="502"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.16: Tree-like children nodes</p>
			<p>In the preceding diagram, we can see the following:</p>
			<ul>
				<li>There is a root.</li>
				<li>There are child objects attached to the root.</li>
				<li>There could be multiple levels, that is, children of children, recursively going down.</li>
				<li>All of the nodes of the tree (root and children alike) have attributes attached to them that contain data.</li>
			</ul>
			<p>Tree traversal algorithms can be used to search for a particular attribute. If provided, special methods can be used to probe a node more deeply.</p>
			<p>Every node in the XML tree has tags and attributes. The idea is as follows:</p>
			<div>
				<div id="_idContainer233" class="IMG---Figure">
					<img src="Images/B15780_07_17.jpg" alt="Figure 7.17: Finding the root and child nodes of an XML tag&#13;&#10;" width="562" height="477"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.17: Finding the root and child nodes of an XML tag</p>
			<p>As the document is organized in a tree fashion, we can use a tree traversal algorithm to go through it and visit all the children, starting at the root.</p>
			<h2 id="_idParaDest-220"><a id="_idTextAnchor228"/>Exercise 7.09: Traversing the Tree, Finding the Root, and Exploring All the Child Nodes and Their Tags and Attributes</h2>
			<p>In this exercise, we will use the tree traversal algorithm to traverse a tree, find the root, and explore all the child nodes. We will first define a variable called <strong class="source-inline">tree2</strong>, which will contain the contents of the <strong class="source-inline">xml1.xml</strong> file. Then, we will use a <strong class="source-inline">for</strong> loop to traverse through this XML document tree.</p>
			<p>The XML file can be found here: <a href="https://packt.live/3e8jM7n">https://packt.live/3e8jM7n</a>. Follow these steps:</p>
			<ol>
				<li value="1">Open a new Jupyter Notebook and define the tree:<p class="source-code">import xml.etree.ElementTree as ET</p><p class="source-code">tree2=ET.parse('<strong class="bold">../datasets/xml1.xml</strong>')</p><p class="source-code">type(tree2)</p><p class="callout-heading">Note</p><p class="callout">Depending on where it is saved on your system, don't forget to change the path of the XML file (highlighted). </p><p>The output will be as follows: </p><p class="source-code">xml.etree.ElementTree.ElementTree</p></li>
				<li>Explore these tags and attributes using the following code:<p class="source-code">root=tree2.getroot()</p><p class="source-code">for child in root:</p><p class="source-code">    print("Child:",child.tag, "| Child attribute:",\</p><p class="source-code">          child.attrib)</p><p>The output will be as follows:</p></li>
			</ol>
			<div>
				<div id="_idContainer234" class="IMG---Figure">
					<img src="Images/B15780_07_18.jpg" alt="Figure 7.18: The output showing the extracted XML tags&#13;&#10;" width="1235" height="143"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.18: The output showing the extracted XML tags</p>
			<p>In this exercise, we saw how to traverse an XML document tree.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/2AEgqe1%20">https://packt.live/2AEgqe1.</a></p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/3ebu5re">https://packt.live/3ebu5re</a>.</p>
			<p class="callout">Remember that every XML data file could follow a different naming or structural format, but using an element tree approach puts the data into a somewhat structured flow that can be explored systematically. Still, it is best to examine the raw XML file structure once and understand (even if at a high level) the data format before attempting automatic extractions.</p>
			<p>In the following exercise, we will see how to extract relevant information from a tree.</p>
			<h2 id="_idParaDest-221"><a id="_idTextAnchor229"/>Exercise 7.10: Using the text Method to Extract Meaningful Data</h2>
			<p>In this exercise, we will be using the <strong class="source-inline">text</strong> method from the <strong class="source-inline">BeautifulSoup</strong> library to extract different types of data from a particular node of the XML document tree. We can almost think of the XML tree as a <strong class="bold">list of lists</strong> and index it accordingly. Let's follow these steps:</p>
			<ol>
				<li value="1">Open a new Jupyter Notebook and define the tree:<p class="source-code">import xml.etree.ElementTree as ET</p><p class="source-code">tree2=ET.parse('<strong class="bold">../datasets/xml1.xml</strong>')</p><p class="source-code">type(tree2)</p><p class="callout-heading">Note</p><p class="callout">Depending on where it is saved on your system, don't forget to change the path of the XML file (highlighted).</p><p>The output will be as follows:</p><p class="source-code">xml.etree.ElementTree.ElementTree</p></li>
				<li>Explore these tags and attributes using the following code:<p class="source-code">root=tree2.getroot()</p></li>
				<li>Access the <strong class="source-inline">root[0][2]</strong> element by using the following code:<p class="source-code">root[0][2]</p><p>The output will be as follows:</p><p class="source-code">&lt;Element 'gdppc' at 0x00000000051FF278&gt;</p><p>So, this points to the <strong class="source-inline">gdppc</strong> piece of data. Here, <strong class="source-inline">gdppc</strong> is the tag and the actual GDP/per capita data is attached to this tag.</p></li>
				<li>Use the <strong class="source-inline">text</strong> method to access the data:<p class="source-code">root[0][2].text</p><p>The output will be as follows:</p><p class="source-code">'141100'</p></li>
				<li>Use the <strong class="source-inline">tag</strong> method to access <strong class="source-inline">gdppc</strong>:<p class="source-code">root[0][2].tag</p><p>The output will be as follows:</p><p class="source-code">'gdppc'</p></li>
				<li>Check <strong class="source-inline">root[0]</strong>:<p class="source-code">root[0]</p><p>The output will be as follows:</p><p class="source-code">&lt;Element 'country1' at 0x00000000050298B8&gt;</p></li>
				<li>Check the tag:<p class="source-code">root[0].tag</p><p>The output will be as follows:</p><p class="source-code">'country'</p></li>
				<li>We can use the <strong class="source-inline">attrib</strong> method to access it:<p class="source-code">root[0].attrib</p><p>The output will be as follows:</p><p class="source-code">{'name': ' Liechtenstein '}</p><p>So, <strong class="source-inline">root[0]</strong> is again an element, but it has a different set of tags and attributes than <strong class="source-inline">root[0][2]</strong>. This is expected because they are all part of the tree as nodes, but each is associated with a different level of data.</p></li>
			</ol>
			<p>In this exercise, we saw how to access a particular node in an XML document and how to get the data, attributes, and other related things from it. This knowledge is very valuable as a lot of data is still presented and exchanged in XML format.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/3ee0mhl%20">https://packt.live/3ee0mhl.</a></p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/2YMqbyz">https://packt.live/2YMqbyz</a>.</p>
			<p>This last piece of code output is interesting because it returns a dictionary object. Therefore, we can just index it by its keys. We will do that in the next exercise.</p>
			<h2 id="_idParaDest-222"><a id="_idTextAnchor230"/>Extracting and Printing the GDP/Per Capita Information Using a Loop</h2>
			<p>Now that we know how to read the GDP/per capita data and how to get a dictionary back from the tree, we can easily construct a simple dataset by running a loop over the tree:</p>
			<p class="source-code">for c in root:</p>
			<p class="source-code">    country_name=c.attrib['name']</p>
			<p class="source-code">    gdppc = int(c[2].text)</p>
			<p class="source-code">    print("{}: {}".format(country_name,gdppc))</p>
			<p>The output is as follows:</p>
			<p class="source-code">Liechtenstein: 141100</p>
			<p class="source-code">Singapore: 59900</p>
			<p class="source-code">Panama: 13600</p>
			<p>We can put these in a DataFrame or a CSV file to be saved to a local disk for further processing, such as a simple plot.</p>
			<h2 id="_idParaDest-223"><a id="_idTextAnchor231"/>Finding All the Neighboring Countries for Each Country and Printing Them</h2>
			<p>There are efficient search algorithms for tree structures, and one such method for XML trees is <strong class="source-inline">findall</strong>. We can use this, for this example, to find all the neighbors a country has and print them out.</p>
			<p>Why do we need to use <strong class="source-inline">findall</strong> instead of <strong class="source-inline">find</strong>? Well, because not all countries have an equal number of neighbors and <strong class="source-inline">findall</strong> searches for all the data with that tag that is associated with a particular node, and we want to traverse all of them:</p>
			<p class="source-code">for c in root:</p>
			<p class="source-code"># Find all the neighbors</p>
			<p class="source-code">    ne=c.findall('neighbor') </p>
			<p class="source-code">    print("Neighbors\n"+"-"*25)</p>
			<p class="source-code"># Iterate over the neighbors and print their 'name' attribute</p>
			<p class="source-code">    for i in ne: </p>
			<p class="source-code">        print(i.attrib['name'])</p>
			<p class="source-code">    print('\n')</p>
			<p>The output looks something like this:</p>
			<div>
				<div id="_idContainer235" class="IMG---Figure">
					<img src="Images/B15780_07_19.jpg" alt="Figure 7.19: The output that's generated by using findall&#13;&#10;" width="819" height="328"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.19: The output that's generated by using findall</p>
			<p>In this section, we have looked into how to use specific search algorithms in the form of pre-defined functions to traverse through an XML document and get interesting data from the nodes we visit.</p>
			<p>In the previous topic of this chapter, we learned about simple web scraping using the <strong class="source-inline">requests</strong> library. So far, we have worked with static XML data, that is, data from a local file or a string object we've scripted. Now, it is time to combine our learning and read XML data directly over the internet (as you are expected to do almost all the time).</p>
			<h2 id="_idParaDest-224"><a id="_idTextAnchor232"/>Exercise 7.11: A Simple Demo of Using XML Data Obtained by Web Scraping</h2>
			<p>In this exercise, we will obtain XML data using web scraping. We will read a cooking recipe from a website called <a href="http://www.recipepuppy.com/">http://www.recipepuppy.com/</a>, which contains aggregates links of various other sites with the recipe. Next, we will use the <strong class="source-inline">find</strong> method to extract the appropriate attribute from the XML file and display the relevant content. Let's follow these steps:</p>
			<ol>
				<li value="1">Import the necessary libraries:<p class="source-code">import requests, urllib.parse</p><p>Read from the <a href="http://www.recipepuppy.com/">http://www.recipepuppy.com/</a> website:</p><p class="source-code">serviceurl = 'http://www.recipepuppy.com/api/?'</p><p class="source-code">item = str(input('Enter the name of a food item '\</p><p class="source-code">                 '(enter\'quit\' to quit): '))</p><p class="source-code">url = serviceurl + urllib.parse.urlencode({'q':item})\</p><p class="source-code">      +'&amp;p=1&amp;format=xml'</p><p class="source-code">uh = requests.get(url)</p><p class="source-code">data = uh.text</p><p class="source-code">print('Retrieved', len(data), 'characters')</p><p>This code will ask the user for input. You have to enter the name of a food item: '<strong class="source-inline">chicken tikka</strong>'.</p><p>You will get the following output:</p><p class="source-code">Enter the name of a food item (enter 'quit' to quit): chicken tikka</p><p class="source-code">Retrieved 2611 characters</p><p>If we print the last variable, <strong class="source-inline">data</strong>, we may see that it is a mix of a legitimate XML document and some junk HTML appended to it. We need to first check if that is the case. </p></li>
				<li>Use the <strong class="source-inline">find</strong> method from Python. As <strong class="source-inline">data</strong> is a string, we can simply do the following:<p class="source-code">data.find("&lt;!DOCTYPE html PUBLIC") </p><p>This should return an integer if that string is found in <strong class="source-inline">data</strong>. Otherwise, it will return <strong class="source-inline">–1</strong>. If we get a positive integer, then we know – thanks to Python's <strong class="source-inline">find</strong> method – it is the start index of the string we are searching.</p></li>
				<li>Get only the XML part using a piece of code like the following:<p class="source-code">end_marker = data.find("&lt;!DOCTYPE html PUBLIC")</p><p class="source-code">xml_text = data[:end_marker]</p><p>However, if we do not get a positive integer, then we assume that the whole return text is valid XML and we simply set the <strong class="source-inline">end_marker</strong> as the total length of the string. Although, it is always good practice to print the raw data and check whether it is pure XML or some junk added with it.</p></li>
				<li>Write the code to get back data in XML format and read and decode it before creating an XML tree out of it:<p class="source-code">import xml.etree.ElementTree as ET</p><p class="source-code">end_marker = data.find("&lt;!DOCTYPE html PUBLIC") \</p><p class="source-code">             if data.find("&lt;!DOCTYPE html PUBLIC") != \</p><p class="source-code">             -1 else len(data)</p><p class="source-code">xml_text = data[:end_marker]</p><p class="source-code">tree3 = ET.fromstring(xml_text)</p></li>
				<li>Now, we can use another useful method, called <strong class="source-inline">iter</strong>, which basically iterates over the nodes under an element. If we traverse the tree and extract the text, we get the following output:<p class="source-code">for elem in tree3.iter():</p><p class="source-code">    print(elem.text)</p><p>The output (partially shown) is as follows:</p><div id="_idContainer236" class="IMG---Figure"><img src="Images/B15780_07_20.jpg" alt="Figure 7.20: The output that's generated by using iter&#13;&#10;" width="1045" height="689"/></div><p class="figure-caption">Figure 7.20: The output that's generated by using iter</p><p>We can use the <strong class="source-inline">find</strong> method to search for the appropriate attribute and extract its content. This is the reason it is important to scan through the XML data manually and check what attributes are used. Remember, this means scanning the raw string data, not the tree structure.</p></li>
				<li>Print the raw string data:<p class="source-code">print(data)</p><p>The output (partially shown) is as follows:</p><p> </p><div id="_idContainer237" class="IMG---Figure"><img src="Images/B15780_07_21.jpg" alt="Figure 7. 21: output of raw string data&#13;&#10;" width="1121" height="643"/></div><p class="figure-caption">Figure 7. 21: output of raw string data</p><p>Let's examine the XML data that we received, and let's locate the <strong class="source-inline">&lt;title&gt;</strong> and <strong class="source-inline">&lt;href&gt;</strong> tags:</p><div id="_idContainer238" class="IMG---Figure"><img src="Images/B15780_07_22.jpg" alt="Figure 7.22: The output showing the extracted href tags&#13;&#10;" width="1665" height="772"/></div><p class="figure-caption">Figure 7.22: The output showing the extracted href tags</p><p>Now we know what tags to search for.</p></li>
				<li>Print the <strong class="source-inline">&lt;title&gt;</strong> and <strong class="source-inline">&lt;href&gt;</strong> hyperlinks in the XML data:<p class="source-code">for e in tree3.iter():</p><p class="source-code">    h=e.find('href')</p><p class="source-code">    t=e.find('title')</p><p class="source-code">    if h!=None and t!=None:</p><p class="source-code">        print("Receipe Link for:",t.text)</p><p class="source-code">        print(h.text)</p><p class="source-code">        print("-"*100)</p><p>The final output (partially shown) is as follows:</p></li>
			</ol>
			<p> </p>
			<div>
				<div id="_idContainer239" class="IMG---Figure">
					<img src="Images/B15780_07_23.jpg" alt="Figure 7.23: The output showing the final output&#13;&#10;" width="1183" height="597"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.23: The output showing the final output</p>
			<p>Note the use of <strong class="source-inline">h!=None</strong> and <strong class="source-inline">t!=None</strong>. These are difficult to anticipate when you first run this kind of code. You may get an error because some of the tags may return a <strong class="source-inline">None</strong> object, that is, they were empty for some reason in this XML data stream. This kind of situation is fairly common and cannot be anticipated beforehand. You have to use your Python knowledge and programming intuition to get around it if you receive such an error. Here, we are just checking for the type of the object and if it is not <strong class="source-inline">None</strong>, then we need to extract the text associated with it.</p>
			<p>As we can see in the output of this exercise, we're getting a nice output with links to recipes relevant to the food item we searched for. And this concludes this exercise. We have used our knowledge of making HTTP requests and getting data from the internet and mixed it with our newly acquired knowledge of parsing and traversing XML documents to accomplish a small but functional data pipeline. This kind of data pipeline building is a fairly common task for a data wrangling engineer. Now you know how to approach that.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/2ALU6yZ%20">https://packt.live/2ALU6yZ.</a></p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/3hBSMPH">https://packt.live/3hBSMPH</a>.</p>
			<h1 id="_idParaDest-225"><a id="_idTextAnchor233"/>Reading Data from an API</h1>
			<p>Fundamentally, an API or Application Programming Interface is an interface to a computing resource (for example, an operating system or database table), which has a set of exposed methods (function calls) that allow a programmer to access particular data or internal features of that resource.</p>
			<p>A web API is, as the name suggests, an API over the web. Note that it is not a specific technology or programming framework, but an architectural concept. Think of an API like a fast-food restaurant's customer service desk. Internally, there are many food items, raw materials, cooking resources, and recipe management systems, but all you see are fixed menu items on the board and you can only interact through those items. It is like a port that can be accessed using an HTTP protocol and that's able to deliver data and services if used properly.</p>
			<p>Web APIs are extremely popular these days for all kinds of data services. In the very first chapter, we talked about how UC San Diego's data science team pulls data from Twitter feeds to analyze the occurrence of forest fires. For this, they do not go to <a href="http://twitter.com">twitter.com</a> and scrape the data by looking at HTML pages and text. Instead, they use the Twitter API, which sends this data continuously in a streaming format.</p>
			<p>Therefore, it is very important for a data wrangling professional to understand the basics of data extraction from a web API as you are extremely likely to find yourself in a situation where large quantities of data must be read through an API for processing and wrangling. These days, most APIs stream data in JSON format. In this chapter, we will use a free API to read some information about various countries around the world in JSON format and process it.</p>
			<p>We will use Python's built-in <strong class="source-inline">urllib</strong> module for this topic, along with pandas to make a DataFrame. So, we can import them now. We will also import Python's <strong class="source-inline">json</strong> module:</p>
			<p class="source-code">import urllib.request, urllib.parse</p>
			<p class="source-code">from urllib.error import HTTPError,URLError</p>
			<p class="source-code">import json</p>
			<p class="source-code">import pandas as pd</p>
			<h2 id="_idParaDest-226"><a id="_idTextAnchor234"/>Defining the Base URL (or API Endpoint)</h2>
			<p>First, we need to set the base URL. When we are dealing with API microservices, this is often called the <strong class="bold">API endpoint</strong>. Therefore, look for such a phrase in the web service portal you are interested in and use the endpoint URL they give you:</p>
			<p class="source-code">serviceurl = 'https://restcountries.eu/rest/v2/name/'</p>
			<p>API-based microservices are extremely dynamic in nature in terms of what and how they offer their services and data. It can change at any time. At the time of writing, we found this particular API to be a nice choice for extracting data easily and without using authorization keys (login or special API keys).</p>
			<p>For most APIs, however, you need to have your own API key. You get that by registering with their service. A basic usage (up to a fixed number of requests or a data flow limit) is often free, but after that, you will be charged. To register for an API key, you often need to enter credit card information.</p>
			<p>We wanted to avoid all that hassle to teach you the basics and that's why we chose this example, which does not require such authorization. But, depending on what kind of data you will encounter in your work, please be prepared to learn about using an API key.</p>
			<h2 id="_idParaDest-227"><a id="_idTextAnchor235"/>Exercise 7.12: Defining and Testing a Function to Pull Country Data from an API</h2>
			<p>In this exercise, we'll use a particular API, <strong class="source-inline">https://restcountries.eu/rest/v2/name/</strong>, that serves basic information about countries around the world. We will first connect with the API. Next, we will create a user-defined function to get the data for a specific country. Let's follow these steps:</p>
			<ol>
				<li value="1">Import the necessary libraries:<p class="source-code">import urllib.request, urllib.parse</p><p class="source-code">from urllib.error import HTTPError,URLError</p><p class="source-code">import json</p><p class="source-code">import pandas as pd</p></li>
				<li>Define the <strong class="source-inline">service_url</strong> variable:<p class="source-code">serviceurl = 'https://restcountries.eu/rest/v2/name/'</p></li>
				<li>Define a function to pull out data when we pass the name of a country as an argument. The crux of the operation is contained in the following two lines of code:<p class="source-code">country_name = 'Switzerland' </p><p class="source-code">url = serviceurl + country_name</p><p class="source-code">uh = urllib.request.urlopen(url)</p><p>The first line of code appends the country name as a string to the base URL and the second line sends a <strong class="source-inline">get</strong> request to the API endpoint. If all goes well, we get back the data, decode it, and read it as a <strong class="source-inline">JSON</strong> file. This whole exercise is coded in the following function, along with some error-handling code wrapped around the basic actions we talked about previously.</p></li>
				<li>Define the <strong class="source-inline">get_country_data</strong> function:<p class="source-code">def get_country_data(country):</p><p class="source-code">    """</p><p class="source-code">    Function to get data about country</p><p class="source-code">    from "https://restcountries.eu" API</p><p class="source-code">    """</p><p class="source-code">    country_name=str(country)</p><p class="source-code">    url = serviceurl + country_name</p><p class="source-code">    try: </p><p class="source-code">        uh = urllib.request.urlopen(url)</p><p class="source-code">    except HTTPError as e:</p><p class="source-code">        print("Sorry! Could not retrieve anything on {}"\</p><p class="source-code">              .format(country_name))</p><p class="source-code">        return None</p><p class="source-code">    except URLError as e:</p><p class="source-code">        print('Failed to reach a server.')</p><p class="source-code">        print('Reason: ', e.reason)</p><p class="source-code">        return None</p><p class="source-code">    else:</p><p class="source-code">        data = uh.read().decode()</p><p class="source-code">        print("Retrieved data on {}. Total {} characters  read."\</p><p class="source-code">              .format(country_name,len(data)))</p><p class="source-code">        return data</p><p>Test this function by passing some arguments. Note that we are using the <strong class="source-inline">try..except</strong> block here. The <strong class="source-inline">try</strong> block lets you test a block of code and see whether there are any errors; the <strong class="source-inline">except</strong> block lets you handle the errors.</p></li>
				<li>Type in the following command:<p class="source-code">data = get_country_data(country_name)</p><p>The output is as follows:</p><p class="source-code">Retrieved data on Switzerland. Total 1090 characters read.</p></li>
				<li>Feed erroneous data in <strong class="source-inline">country_name1</strong>:<p class="source-code">country_name1 = 'Switzerland1'</p><p class="source-code">data1 = get_country_data(country_name1)</p><p>We pass a correct name and an erroneous name. The response is as follows:</p><p class="source-code">Sorry! Could not retrieve anything on Switzerland1</p></li>
			</ol>
			<p>This is an example of rudimentary error handling. You have to think about various possibilities and put in the right code to catch and gracefully respond to user input when you are building a real-life web or enterprise application.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/30QU3MY%20">https://packt.live/30QU3MY.</a></p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/2UUPc9I">https://packt.live/2UUPc9I</a>.</p>
			<p>Now that we have written a function to get this data with some kind of error handling built into it, we are ready to move on to the next part, where we deal with the data that we just got.</p>
			<h2 id="_idParaDest-228"><a id="_idTextAnchor236"/>Using the Built-In JSON Library to Read and Examine Data</h2>
			<p>As we have already mentioned, JSON looks a lot like a Python dictionary.</p>
			<p>We will use Python's <strong class="source-inline">requests</strong> module to read raw data in that format and see what we can process further:</p>
			<p class="source-code">import json</p>
			<p class="source-code">x=json.loads(data)</p>
			<p class="source-code"># Load the only element</p>
			<p class="source-code">y=x[0]</p>
			<p class="source-code">type(y)</p>
			<p>The output will be as follows:</p>
			<p class="source-code">dict</p>
			<p>It reads a string datatype into a list of dictionaries. In this case, we get only one element in the list, so we extract that and check its type to make sure it is a dictionary.</p>
			<p>We can quickly check the keys of the dictionary by using the <strong class="source-inline">keys()</strong> method on the dictionary, that is, the JSON data (note that a full screenshot is not shown here).</p>
			<p>Let's try the following command: </p>
			<p class="source-code">y.keys()</p>
			<p>The output (partially shown), will be:</p>
			<div>
				<div id="_idContainer240" class="IMG---Figure">
					<img src="Images/B15780_07_24.jpg" alt="Figure 7.24: The output of dict_keys&#13;&#10;" width="851" height="82"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.24: The output of dict_keys</p>
			<p>We can see the relevant country data, such as calling codes, population, area, time zones, borders, and so on.</p>
			<h2 id="_idParaDest-229"><a id="_idTextAnchor237"/>Printing All the Data Elements</h2>
			<p>This task is extremely simple given that we have a dictionary at our disposal. All we have to do is iterate over the dictionary and print the key/item pairs one by one:</p>
			<p class="source-code">for k,v in y.items():</p>
			<p class="source-code">    print("{}: {}".format(k,v))</p>
			<p>The output (partially shown) is as follows:</p>
			<div>
				<div id="_idContainer241" class="IMG---Figure">
					<img src="Images/B15780_07_25.jpg" alt="Figure 7.25: The output using dict&#13;&#10;" width="758" height="252"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.25: The output using dict</p>
			<p>Note that the items in the dictionary are not of the same type, that is, they are not similar objects. Some are floating-point numbers, such as <strong class="source-inline">area</strong>, many are simple strings, but some are lists or even lists of dictionaries.</p>
			<p>This is fairly common with JSON data. The internal data structure of JSON can be arbitrarily complex and multilevel, that is, you can have a dictionary of lists of dictionaries of dictionaries of lists of lists… and so on.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">It is clear, therefore, that there is no universal method or processing function for the JSON data format, and you have to write custom loops and functions to extract data from such a dictionary object based on your particular needs.</p>
			<p>Now, we will write a small loop to extract the languages spoken in Switzerland. First, let's examine the dictionary closely and see where the language data is:</p>
			<div>
				<div id="_idContainer242" class="IMG---Figure">
					<img src="Images/B15780_07_26.jpg" alt="Figure 7.26: The tags&#13;&#10;" width="1428" height="365"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.26: The tags</p>
			<p>So, the data is embedded inside a list of dictionaries, which is accessed by a particular key of the main dictionary.</p>
			<p>We can write two simple lines of code to extract this data:</p>
			<p class="source-code">for lang in y['languages']:</p>
			<p class="source-code">    print(lang['name'])</p>
			<p>The output is as follows:</p>
			<div>
				<div id="_idContainer243" class="IMG---Figure">
					<img src="Images/B15780_07_27.jpg" alt="Figure 7.27: The output showing the languages&#13;&#10;" width="586" height="147"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.27: The output showing the languages</p>
			<h2 id="_idParaDest-230"><a id="_idTextAnchor238"/>Using a Function that Extracts a DataFrame Containing Key Information</h2>
			<p>Here, we are interested in writing a function that can take a list of countries and return a <strong class="source-inline">pandas</strong> DataFrame with some key information:</p>
			<ul>
				<li>Capital</li>
				<li>Region</li>
				<li>Sub-region</li>
				<li>Population</li>
				<li>Latitude/longitude</li>
				<li>Area</li>
				<li>Gini index</li>
				<li>Time zones</li>
				<li>Currencies</li>
				<li>Languages<p class="callout-heading">Note</p><p class="callout">This is the kind of wrapper function you are generally expected to write in real-life data wrangling tasks, that is, a utility function that can take a user argument and output a useful data structure (or a mini database-type object) with key information extracted over the internet about the item the user is interested in.</p></li>
			</ul>
			<p>We will show you the whole function first and then discuss some key points about it. It is a slightly complex and long piece of code. However, with your Python data-wrangling knowledge, you should be able to examine this function closely and understand what it is doing:</p>
			<p class="source-code-heading">Exercise 7.13.ipynb</p>
			<p class="source-code">import pandas as pd</p>
			<p class="source-code">import json</p>
			<p class="source-code">def build_country_database(list_country):</p>
			<p class="source-code">    """</p>
			<p class="source-code">    Takes a list of country names.</p>
			<p class="source-code">    Output a DataFrame with key information about those countries.</p>
			<p class="source-code">    """</p>
			<p class="source-code">    # Define an empty dictionary with keys</p>
			<p class="source-code">    country_dict={'Country':[],'Capital':[],'Region':[],\</p>
			<p class="source-code">                  'Sub-region':[],'Population':[], \</p>
			<p class="source-code">                  'Latitude':[],'Longitude':[], 'Area':[],\</p>
			<p class="source-code">                  'Gini':[],'Timezones':[], 'Currencies':[],\</p>
			<p class="source-code">                  'Languages':[]}</p>
			<p class="source-code-link">The code has been truncated here. You can find the entire code for this function at the following GitHub link: <a href="https://packt.live/2YeRDpP">https://packt.live/2YeRDpP</a>.</p>
			<p>Here are some of the key points about this function:</p>
			<ul>
				<li>It starts by building an empty dictionary of lists. This is the chosen format for finally passing to the pandas <strong class="bold">DataFrame</strong> method, which accepts this format and returns a nice DataFrame with column names set to the dictionary keys' names.</li>
				<li>We use the previously defined <strong class="source-inline">get_country_data</strong> function to extract data for each country in the user-defined list. For this, we simply iterate over the list and call this function.</li>
				<li>We check the output of the <strong class="source-inline">get_country_data</strong> function. If for some reason it returns a <strong class="source-inline">None</strong> object, we will know that the API reading was not successful, and we will print out a suitable message. Again, this is an example of an error-handling mechanism and you must have them in your code. Without this small error-checking code, your application won't be robust enough for the occasional incorrect input or API malfunction.</li>
				<li>For many data types, we simply extract the data from the main JSON dictionary and append it to the corresponding list in our data dictionary.</li>
				<li>However, for special data types, such as time zones, currencies, and languages, we write a special loop to extract the data without error.</li>
				<li>We also take care of the fact that these special data types can have a variable length, that is, some countries may have multiple spoken languages, but most will have only one entry. So, we check whether the length of the list is greater than one and handle the data accordingly.</li>
			</ul>
			<h2 id="_idParaDest-231"><a id="_idTextAnchor239"/>Exercise 7.13: Testing the Function by Building a Small Database of Country Information</h2>
			<p>In this exercise, we will use the example code used in the previous section and build a database of country information. We will test this function by passing a list of country names. </p>
			<p>Let's follow these steps:</p>
			<ol>
				<li value="1">Import the necessary libraries:<p class="source-code">import urllib.request, urllib.parse</p><p class="source-code">from urllib.error import HTTPError,URLError</p><p class="source-code">import pandas as pd</p></li>
				<li>Define the <strong class="source-inline">service_url</strong> variable:<p class="source-code">serviceurl = 'https://restcountries.eu/rest/v2/name/'</p></li>
				<li>Define the <strong class="source-inline">get_country_data</strong> function:<p class="source-code-heading">Exercise 7.13.ipynb</p><p class="source-code">def get_country_data(country):</p><p class="source-code">    """</p><p class="source-code">    Function to get data about a country</p><p class="source-code">    from "https://restcountries.eu" API</p><p class="source-code">    """</p><p class="source-code">    country_name=str(country)</p><p class="source-code-link">The complete code for this step can be found at <a href="https://packt.live/2YeRDpP">https://packt.live/2YeRDpP</a>.</p></li>
				<li>Define the name of the country:<p class="source-code">country_name = 'Switzerland'</p></li>
				<li>Type in the following command:<p class="source-code">data=get_country_data(country_name)</p><p>The output is as follows:</p><p class="source-code">Retrieved data on Switzerland. Total 1090 characters read.</p></li>
				<li>Feed erroneous data in <strong class="source-inline">country_name1</strong>:<p class="source-code">country_name1 = 'Switzerland1'</p><p class="source-code">data1 = get_country_data(country_name1)</p><p>On passing an erroneous name, the response is as follows:</p><p class="source-code">Sorry! Could not retrieve anything on Switzerland1</p></li>
				<li>Now, import the <strong class="source-inline">json</strong> library:<p class="source-code">import json</p></li>
				<li>Load from string <strong class="source-inline">data</strong> as follows:<p class="source-code">x=json.loads(data)</p></li>
				<li>Load the only element as follows:<p class="source-code"># Load the only element</p><p class="source-code">y=x[0]</p></li>
				<li>Check the type of <strong class="source-inline">y</strong> as follows:<p class="source-code">type(y)</p><p>This will return <strong class="source-inline">dict</strong></p></li>
				<li>Print the keys of <strong class="source-inline">y</strong> as follows:<p class="source-code">y.keys()</p><p>The output is as follows:</p><p class="source-code">dict_keys(['name', 'topLevelDomain', 'alpha2Code', 'alpha3Code', 'callingCodes', 'capital', 'altSpellings', 'region', 'subregion', 'population', 'latlng', 'demonym', 'area', 'gini', 'timezones', 'borders', 'nativeName', 'numericCode', 'currencies', 'languages', 'translations', 'flag', 'regionalBlocs', 'cioc'])</p></li>
				<li>Iterate over the dictionary and print the key/item pairs one by one:<p class="source-code">for k,v in y.items():</p><p class="source-code">    print("{}: {}".format(k,v))</p><p>A section of output is as follows:</p><p class="source-code">name: Switzerland</p><p class="source-code">topLevelDomain: ['.ch']</p><p class="source-code">alpha2Code: CH</p><p class="source-code">alpha3Code: CHE</p><p class="source-code">callingCodes: ['41']</p><p class="source-code">capital: Bern</p><p class="source-code">altSpellings: ['CH', 'Swiss Confederation', 'Schweiz', 'Suisse', 'Svizzera', 'Svizra']</p><p class="source-code">region: Europe</p><p class="source-code">subregion: Western Europe</p><p class="source-code">population: 8341600</p><p class="source-code">latlng: [47.0, 8.0]</p><p class="source-code">demonym: Swiss</p></li>
				<li>Create a loop to extract the languages spoken in <strong class="source-inline">Switzerland</strong>:<p class="source-code">for lang in y['languages']:</p><p class="source-code">    print(lang['name'])</p><p>The output is as follows:</p><p class="source-code">German</p><p class="source-code">French</p><p class="source-code">Italian</p></li>
				<li>Import the necessary libraries:<p class="source-code">import pandas as pd</p><p class="source-code">import json</p></li>
				<li>Define the <strong class="source-inline">build_country_database</strong>:<p class="source-code-heading">Exercise 7.13.ipynb</p><p class="source-code">def build_country_database(list_country):</p><p class="source-code">    """</p><p class="source-code">    Takes a list of country names.</p><p class="source-code">    Output a DataFrame with key information about those countries.</p><p class="source-code">    """</p><p class="source-code">    # Define an empty dictionary with keys</p><p class="source-code">    country_dict={'Country':[],'Capital':[],'Region':[],'Sub-      region':[],'Population':[],</p><p class="source-code-link">The complete code for this step is available at: <a href="https://packt.live/2YFVYkM">https://packt.live/2YFVYkM</a>.</p></li>
				<li>To test its robustness, we pass in an erroneous name, such as <strong class="source-inline">Turmeric</strong> in this case:<p class="source-code">df1=build_country_database(['Nigeria','Switzerland','France',\</p><p class="source-code">                            'Turmeric','Russia',\</p><p class="source-code">                            'Kenya','Singapore'])</p><p>The output is as follows:</p><div id="_idContainer244" class="IMG---Figure"><img src="Images/B15780_07_28.jpg" alt="Figure 7.28: output of country database&#13;&#10;" width="1047" height="259"/></div><p class="figure-caption">Figure 7.28: output of country database</p><p>As we can see from the output, it detected that it did not get any data back for the incorrect entry and printed out a suitable message. The key thing is that if you do not have the error-checking and handling code in your function, then it will stop the execution on that entry and will not return the expected mini database. To avoid this behavior, error-handling code is invaluable. The following screenshot points at the incorrect entry:</p><div id="_idContainer245" class="IMG---Figure"><img src="Images/B15780_07_29.jpg" alt="Figure 7.29: The incorrect entry highlighted&#13;&#10;" width="1406" height="495"/></div><p class="figure-caption">Figure 7.29: The incorrect entry highlighted</p></li>
				<li>Print the <strong class="source-inline">pandas</strong> DataFrame:<p class="source-code">df1</p><p>The output is as follows (only partial output is shown):</p><div id="_idContainer246" class="IMG---Figure"><img src="Images/B15780_07_30.jpg" alt="Figure 7.30: Partial output&#13;&#10;" width="1451" height="737"/></div></li>
			</ol>
			<p class="figure-caption">Figure 7.30: Partial output</p>
			<p>Let's analyze the data that has been extracted:</p>
			<div>
				<div id="_idContainer247" class="IMG---Figure">
					<img src="Images/B15780_07_31.jpg" alt="Figure 7.31: The data extracted correctly&#13;&#10;" width="1432" height="628"/>
				</div>
			</div>
			<p class="figure-caption">Figure 7.31: The data extracted correctly</p>
			<p>As we can see from the output, single as well as multiple pieces of data have been extracted correctly.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/2YeRDpP%20">https://packt.live/2YeRDpP.</a></p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/3fvAY6U">https://packt.live/3fvAY6U</a>.</p>
			<h1 id="_idParaDest-232"><a id="_idTextAnchor240"/>Fundamentals of Regular Expressions (RegEx)</h1>
			<p><strong class="bold">Reg</strong>ular <strong class="bold">ex</strong>pressions or <strong class="bold">regex</strong> are used to identify whether a pattern exists in a given sequence of characters (a string) or not. They help with manipulating textual data, which is often a prerequisite for data science projects that involve text mining.</p>
			<h2 id="_idParaDest-233"><a id="_idTextAnchor241"/>RegEx in the Context of Web Scraping</h2>
			<p>Web pages are often full of text, and while there are some methods in <strong class="source-inline">BeautifulSoup</strong> or XML parsers to extract raw text, there is no method for the intelligent analysis of that text. If, as a data wrangler, you are looking for a particular piece of data (for example, email IDs or phone numbers in a special format), you have to do a lot of string manipulation on a large corpus to extract email IDs or phone numbers. <strong class="source-inline">RegEx</strong> is very powerful and can save a data wrangling professional a lot of time and effort with string manipulation because they can search for complex textual patterns with wildcards of an arbitrary length.</p>
			<p><strong class="source-inline">RegEx</strong> is like a mini-programming language in itself and common ideas are used not only in Python, but in all widely used web app languages, such as JavaScript, PHP, and Perl. The <strong class="source-inline">regex</strong> module is built into Python, and you can import it by using the following code:</p>
			<p class="source-code">import re</p>
			<p>In the next exercise, we are going to use the <strong class="source-inline">match</strong> method to check whether a pattern matches a string or sequence.</p>
			<h2 id="_idParaDest-234"><a id="_idTextAnchor242"/>Exercise 7.14: Using the match Method to Check Whether a Pattern Matches a String/Sequence</h2>
			<p>In this exercise, we will use one of the most common regex methods, <strong class="source-inline">match</strong>, to check for an exact or partial match at the beginning of a string. Let's follow these steps:</p>
			<ol>
				<li value="1">Import the <strong class="source-inline">regex</strong> module:<p class="source-code">import re</p></li>
				<li>Define a string and a pattern:<p class="source-code">string1 = 'Python'</p><p class="source-code">pattern = r"Python"</p></li>
				<li>Write a conditional expression to check for a match:<p class="source-code">if re.match(pattern,string1):</p><p class="source-code">    print("Matches!")</p><p class="source-code">else:</p><p class="source-code">    print("Doesn't match.")</p><p>The output should be as follows:</p><p class="source-code">Matches!</p></li>
				<li>Test this with a string that only differs in the first letter by making it lowercase:<p class="source-code">string2 = 'python'</p><p class="source-code">if re.match(pattern,string2):</p><p class="source-code">       print("Matches!")</p><p class="source-code">else:</p><p class="source-code">      print("Doesn't match.")</p><p>The output is as follows:</p><p class="source-code">Doesn't match.</p><p class="callout-heading">Note</p><p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/2N8SKAW%20">https://packt.live/2N8SKAW.</a></p><p class="callout">You can also run this example online at <a href="https://packt.live/3hHJOAr">https://packt.live/3hHJOAr</a>.</p></li>
			</ol>
			<p>In this exercise, we just saw how to do the most basic regex operations. In itself, it may not look very impressive, but we will be building further complex logic on top of this basic idea in the forthcoming exercises.</p>
			<h2 id="_idParaDest-235"><a id="_idTextAnchor243"/>Using the compile Method to Create a RegEx Program</h2>
			<p>In a program or module, if we are making heavy use of a particular pattern, then it is better to use the <strong class="source-inline">compile</strong> method and create a regex program and then call methods on this program.</p>
			<p>Here is how you compile a regex program:</p>
			<p class="source-code">prog = re.compile(pattern)</p>
			<p class="source-code">prog.match(string1)</p>
			<p>The output is as follows:</p>
			<p class="source-code">&lt;re.SRE_Match object; span=(0, 6), match='Python'&gt;</p>
			<p>This code produced an <strong class="source-inline">SRE.Match</strong> object that has a <strong class="source-inline">span</strong> of (<strong class="source-inline">0,6</strong>) and the matched string of <strong class="source-inline">Python</strong>. The span here simply denotes the start and end indices of the pattern that was matched. These indices may come in handy in a text mining program where the subsequent code uses the indices for further search or decision-making purposes. </p>
			<p>Compiled objects act like functions in that they return <strong class="source-inline">None</strong> if the pattern does not match. This concept will come in handy later when we write a small utility function to check for the type of the returned object from regex-compiled programs and act accordingly. We cannot be sure whether a pattern will match a given string or whether it will appear in a corpus of text (if we are searching for the pattern anywhere within the text). Depending on the situation, we may encounter <strong class="source-inline">Match</strong> objects or <strong class="source-inline">None</strong> as the returned value, and we have to handle this gracefully. Let's practice this in the following exercise. </p>
			<h2 id="_idParaDest-236">Exercise 7.15: Compiling Progra<a id="_idTextAnchor244"/>ms to Match Objects</h2>
			<p>In this exercise, we will define two strings and a pattern. We will use the <strong class="source-inline">compile</strong> method to compile a regex program. Next, we will write a small conditional to test whether the compiled object matches the defined pattern. Let's follow these steps:</p>
			<ol>
				<li value="1">Use the <strong class="source-inline">compile</strong> function from the <strong class="source-inline">regex</strong> module:<p class="source-code">import re</p><p class="source-code">def print_match(s):</p><p class="source-code">    if prog.search(s)==None:</p><p class="source-code">        print("No match")</p><p class="source-code">    else:</p><p class="source-code">        print(prog.search(s).group()) </p><p class="source-code">string1 = 'Python'</p><p class="source-code">string2 = 'python'</p><p class="source-code">pattern = r"Python"</p><p class="source-code">prog = re.compile(pattern)</p></li>
				<li>Match it with the first string:<p class="source-code">if prog.match(string1)!=None:</p><p class="source-code">    print("Matches!")</p><p class="source-code">else:</p><p class="source-code">    print("Doesn't match.")</p><p>The output is as follows:</p><p class="source-code">Matches!</p></li>
				<li>Match it with the second string:<p class="source-code">if prog.match(string2)!=None:</p><p class="source-code">    print("Matches!")</p><p class="source-code">else:</p><p class="source-code">    print("Doesn't match.")</p><p>The output is as follows:</p><p class="source-code">Doesn't match.</p></li>
			</ol>
			<p>So, the <strong class="source-inline">compile</strong> method returns special objects, such as <strong class="source-inline">match</strong> objects. But if they don't match, it will return <strong class="source-inline">None</strong>, so we can still run our conditional loop.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/30SJ4m9%20">https://packt.live/30SJ4m9.</a></p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/3hIBkJE">https://packt.live/3hIBkJE</a>.</p>
			<h2 id="_idParaDest-237"><a id="_idTextAnchor245"/>Exercise 7.16: Using Additional Parameters in the match Method to Check for Positional Matching</h2>
			<p>In this exercise, we will use the <strong class="source-inline">match</strong> method to check whether there's a match at a specific location in the string. Let's follow these steps:</p>
			<ol>
				<li value="1">Match <strong class="source-inline">y</strong> in the second position:<p class="source-code">import re</p><p class="source-code">def print_match(s):</p><p class="source-code">    if prog.search(s)==None:</p><p class="source-code">        print("No match")</p><p class="source-code">    else:</p><p class="source-code">        print(prog.search(s).group()) </p><p class="source-code">prog = re.compile(r'y')</p><p class="source-code">prog.match('Python',pos=1)</p><p>The output is as follows:</p><p class="source-code">&lt;re.Match object; span=(1, 2), match='y'&gt;</p><p>This is the <strong class="source-inline">match</strong> object that we talked about before.</p></li>
				<li>Check for a pattern called <strong class="source-inline">thon</strong> starting from <strong class="source-inline">pos=2</strong>, that is, the third character:<p class="source-code">prog = re.compile(r'thon')</p><p class="source-code">prog.match('Python',pos=2)</p><p>The output is as follows:</p><p class="source-code">&lt;_re.SRE_Match object; span=(2, 6), match='thon'&gt;</p></li>
				<li>Find a match in a different string by using the following command:<p class="source-code">prog.match('Marathon',pos=4)</p><p>The output is as follows:</p><p class="source-code">&lt;_re.SRE_Match object; span=(4, 8), match='thon'&gt;</p></li>
			</ol>
			<p>So, we have seen how can we use regex, and use it in various use cases.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/2CmKc7z%20">https://packt.live/2CmKc7z.</a></p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/30OsDY6">https://packt.live/30OsDY6</a>.</p>
			<h2 id="_idParaDest-238"><a id="_idTextAnchor246"/>Finding the Number of Words in a List That End with "ing"</h2>
			<p>Suppose we want to find out whether a given string has the last three letters <strong class="source-inline">ing</strong>. This kind of query may come up in a text analytics/text mining program where somebody is interested in finding instances of present continuous tense words, which are highly likely to end with <strong class="source-inline">ing</strong>. However, nouns may also end with <strong class="source-inline">ing</strong> (as we will see in this example):</p>
			<p class="source-code">prog = re.compile(r'ing')</p>
			<p class="source-code">words = ['Spring','Cycling','Ringtone']</p>
			<p>Create a <strong class="source-inline">for</strong> loop to find words ending with <strong class="source-inline">ing</strong>:</p>
			<p class="source-code">for w in words:</p>
			<p class="source-code">    if prog.match(w,pos=len(w)-3)!=None:</p>
			<p class="source-code">        print("{} has last three letters 'ing'".format(w))</p>
			<p class="source-code">    else:</p>
			<p class="source-code">        print("{} does not have last three letter as 'ing'"\</p>
			<p class="source-code">              .format(w))</p>
			<p>The output is as follows:</p>
			<p class="source-code">Spring has last three letters 'ing'</p>
			<p class="source-code">Cycling has last three letters 'ing'</p>
			<p class="source-code">Ringtone does not have last three letter as 'ing'</p>
			<h2 id="_idParaDest-239"><a id="_idTextAnchor247"/>The search Method in RegEx</h2>
			<p>It looks plain and simple, and you may well wonder what the purpose of using a special regex module for this is. A simple string method should have been sufficient. Yes, it would have been OK for this particular example, but the whole point of using regex is to be able to use very complex string patterns that are not at all obvious when it comes to how they are written using simple string methods. We will see the real power of regex compared to string methods shortly. But before that, let's explore another of the most commonly used methods, called <strong class="source-inline">search</strong>.</p>
			<p><strong class="source-inline">search</strong> and <strong class="source-inline">match</strong> are related concepts, and they both return the same <strong class="source-inline">match</strong> object. The real difference between them is that <strong class="bold">match works for only the first match</strong> (either at the beginning of the string or at a specified position, as we saw in the previous exercises), whereas <strong class="bold">search looks for the pattern anywhere in the string</strong> and returns the position if it finds a match.</p>
			<h2 id="_idParaDest-240"><a id="_idTextAnchor248"/>Exercise 7.17: The search Method in RegEx</h2>
			<p>In this exercise, we will use the <strong class="source-inline">search</strong> method to find the <strong class="source-inline">ing</strong> pattern in a regex structure. Let's follow these steps:</p>
			<ol>
				<li value="1">Use the <strong class="source-inline">compile</strong> method to find matching strings:<p class="source-code">import re</p><p class="source-code">def print_match(s):</p><p class="source-code">    if prog.search(s)==None:</p><p class="source-code">        print("No match")</p><p class="source-code">    else:</p><p class="source-code">        print(prog.search(s).group())</p><p class="source-code">prog = re.compile('ing')</p><p class="source-code">if prog.match('Spring')==None:</p><p class="source-code">    print("None")</p><p>The output is as follows:</p><p class="source-code">None</p></li>
				<li>Search the string by using the following command:<p class="source-code">prog.search('Spring')</p><p>The output is as follows:</p><p class="source-code">&lt;_sre.SRE_Match object; span=(3, 6), match='ing'&gt;</p></li>
				<li>Let's use <strong class="source-inline">Ringtone</strong> as the search parameter:<p class="source-code">prog.search('Ringtone')</p><p>The output is as follows:</p><p class="source-code">&lt;re.Match object; span=(1, 4), match='ing'&gt;</p></li>
			</ol>
			<p>As you can see, the <strong class="source-inline">match</strong> method returns <strong class="source-inline">None</strong> for the input <strong class="source-inline">Spring</strong>, and we had to write code to print that out explicitly (because in a Jupyter notebook, nothing will show up for a <strong class="source-inline">None</strong> object). But <strong class="source-inline">search</strong> returns a <strong class="source-inline">match</strong> object with <strong class="source-inline">span=(3,6)</strong> as it finds the <strong class="source-inline">ing</strong> pattern spanning those positions.</p>
			<p>Similarly, for the <strong class="source-inline">Ringtone</strong> string, it finds the correct position of the match and returns <strong class="source-inline">span=(1,4)</strong>.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/3fDRmme%20">https://packt.live/3fDRmme.</a></p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/30U2WFm">https://packt.live/30U2WFm</a>.</p>
			<h2 id="_idParaDest-241"><a id="_idTextAnchor249"/>Exercise 7.18: Using the span Method of the Match Object to Locate the Position of the Matched Pattern</h2>
			<p>In this exercise, we will use the <strong class="source-inline">span</strong> contained in the <strong class="source-inline">Match</strong> object to locating the exact position of the pattern as it appears in the string. Let's follow these steps:</p>
			<ol>
				<li value="1">Initialize <strong class="source-inline">prog</strong> with the <strong class="source-inline">ing</strong> pattern:<p class="source-code">import re</p><p class="source-code">def print_match(s):</p><p class="source-code">    if prog.search(s)==None:</p><p class="source-code">        print("No match")</p><p class="source-code">    else:</p><p class="source-code">        print(prog.search(s).group()) </p><p class="source-code">prog = re.compile(r'ing')</p><p class="source-code">words = ['Spring','Cycling','Ringtone']</p></li>
				<li>Create a function to return a tuple of the start and end positions of the match:<p class="source-code">for w in words:</p><p class="source-code">    mt = prog.search(w)</p><p class="source-code"># Span returns a tuple of start and end positions of the match</p><p class="source-code"># Starting position of the match</p><p class="source-code">start_pos = mt.span()[0]</p><p class="source-code"># Ending position of the match </p><p class="source-code">end_pos = mt.span()[1] </p></li>
				<li>Print the word ending with <strong class="source-inline">ing</strong> and its start and end position:<p class="source-code">print("The word '{}' contains 'ing' in the position {}-{}"\</p><p class="source-code">      .format(w,start_pos,end_pos))</p><p>The output is as follows:</p><p class="source-code">The word 'Ringtone' contains 'ing' in the position 1-4</p><p class="callout-heading">Note</p><p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/2YIZB9y%20">https://packt.live/2YIZB9y.</a></p><p class="callout">You can also run this example online at <a href="https://packt.live/37FXSG5">https://packt.live/37FXSG5</a>.</p></li>
			</ol>
			<p>Now, we will start getting into the real usage of regex with examples of various useful pattern matching. In the following exercise, we will explore single-character matching.</p>
			<h2 id="_idParaDest-242"><a id="_idTextAnchor250"/>Exercise 7.19: Examples of Single-Character Pattern Matching with search</h2>
			<p>In this exercise, we will use the <strong class="source-inline">group</strong> method, which will return the matched pattern in a string format so that we can print and process it easily. Let's follow these steps:</p>
			<ol>
				<li value="1">Pass a regex expression with a dot (<strong class="source-inline">.</strong>) inside the <strong class="source-inline">compile</strong> method. It matches any single character except a newline character:<p class="source-code">import re</p><p class="source-code">prog = re.compile(r'py.')</p><p class="source-code">print(prog.search('pygmy').group())</p><p class="source-code">print(prog.search('Jupyter').group())</p><p>The output is as follows:</p><p class="source-code">pyg</p><p class="source-code">pyt</p></li>
				<li>Pass a regex expression with <strong class="source-inline">\w</strong> (lowercase w) inside the <strong class="source-inline">compile</strong> method. It matches any single letter, digit, or underscore:<p class="source-code">prog = re.compile(r'c\wm')</p><p class="source-code">print(prog.search('comedy').group())</p><p class="source-code">print(prog.search('camera').group())</p><p class="source-code">print(prog.search('pac_man').group())</p><p class="source-code">print(prog.search('pac2man').group())</p><p>The output is as follows:</p><p class="source-code">com</p><p class="source-code">cam</p><p class="source-code">c_m</p><p class="source-code">c2m</p></li>
				<li>Pass a regex expression with <strong class="source-inline">\W</strong> (uppercase W) inside the <strong class="source-inline">compile</strong> method. It matches anything not covered by <strong class="source-inline">\w</strong>:<p class="source-code">prog = re.compile(r'4\W1')</p><p class="source-code">print(prog.search('4/1 was a wonderful day!').group())</p><p class="source-code">print(prog.search('4-1 was a wonderful day!').group())</p><p class="source-code">print(prog.search('4.1 was a wonderful day!').group())</p><p class="source-code">print(prog.search('Remember the wonderful day 04/1?').group())</p><p>The output is as follows:</p><p class="source-code">4/1</p><p class="source-code">4-1</p><p class="source-code">4.1</p><p class="source-code">4/1</p></li>
				<li>Pass a regex expression with <strong class="source-inline">\s</strong> (lowercase s) inside the <strong class="source-inline">compile</strong> method. It matches a single whitespace character, such as a space, newline, tab, or return:<p class="source-code">prog = re.compile(r'Data\swrangling')</p><p class="source-code">print(prog.search("Data wrangling is cool").group())</p><p class="source-code">print("-"*80)</p><p class="source-code">print("Data\twrangling is the full string")</p><p class="source-code">print(prog.search("Data\twrangling is the full string").group())</p><p class="source-code">print("-"*80)</p><p class="source-code">print("Data\nwrangling is the full string")</p><p class="source-code">print(prog.search("Data\nwrangling").group())</p><p>The output is as follows:</p><p class="source-code">Data wrangling</p><p class="source-code">--------------------------------------------------------------</p><p class="source-code">Data    wrangling is the full string</p><p class="source-code">Data    wrangling</p><p class="source-code">--------------------------------------------------------------</p><p class="source-code">Data</p><p class="source-code">wrangling is the full string</p><p class="source-code">Data</p><p class="source-code">wrangling</p></li>
				<li>Pass a regex expression with <strong class="source-inline">\d</strong> inside the <strong class="source-inline">compile</strong> method. It matches numerical digits 0-9:<p class="source-code">prog = re.compile(r"score was \d\d")</p><p class="source-code">print(prog.search("My score was 67").group())</p><p class="source-code">print(prog.search("Your score was 73").group())</p><p>The output is as follows:</p><p class="source-code">score was 67</p><p class="source-code">score was 73</p></li>
			</ol>
			<p>As we can see, we can use the <strong class="source-inline">group</strong> function to return a group of matched characters.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/2YOJcAi%20">https://packt.live/2YOJcAi.</a></p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/3edPMHj">https://packt.live/3edPMHj</a>.</p>
			<p>In the following exercise, we will manipulate the start or end of a string using pattern matching. </p>
			<h2 id="_idParaDest-243"><a id="_idTextAnchor251"/>Exercise 7.20: Handling Pattern Matching at the Start or End of a String</h2>
			<p>In this exercise, we will match patterns with strings using the <strong class="source-inline">^</strong> (caret) operator. The focus is to find out whether the pattern is present at the start or the end of the string. Let's follow these steps:</p>
			<ol>
				<li value="1">Write a function to handle cases where a match is not found, that is, to handle <strong class="source-inline">None</strong> objects that are returned:<p class="source-code">import re</p><p class="source-code">def print_match(s):</p><p class="source-code">    if prog.search(s)==None:</p><p class="source-code">        print("No match")</p><p class="source-code">    else:</p><p class="source-code">        print(prog.search(s).group())</p></li>
				<li>Use <strong class="source-inline">^</strong> (caret) to match a pattern at the start of the string:<p class="source-code">prog = re.compile(r'^India')</p><p class="source-code">print_match("Russia implemented this law")</p><p class="source-code">print_match("India implemented that law")</p><p class="source-code">print_match("This law was implemented by India")</p><p>The output is as follows: </p><p class="source-code">No match</p><p class="source-code">India</p><p class="source-code">No match</p></li>
				<li>Use <strong class="source-inline">$</strong> (dollar sign) to match a pattern at the end of the string:<p class="source-code">prog = re.compile(r'Apple$')</p><p class="source-code">print_match("Patent no 123456 belongs to Apple")</p><p class="source-code">print_match("Patent no 345672 belongs to Samsung")</p><p class="source-code">print_match("Patent no 987654 belongs to Apple")</p><p>The output is as follows:</p><p class="source-code">Apple</p><p class="source-code">No match</p><p class="source-code">Apple</p><p class="callout-heading">Note</p><p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/3ddku23%20">https://packt.live/3ddku23.</a></p><p class="callout">You can also run this example online at <a href="https://packt.live/3djOXeV">https://packt.live/3djOXeV</a>.</p><p class="callout">For these examples and exercises, also try to think about how you would implement them without regex, that is, by using simple string methods and any other logic that you can think of. Then, compare that solution to the ones implemented with regex for brevity and efficiency.</p></li>
			</ol>
			<h2 id="_idParaDest-244"><a id="_idTextAnchor252"/>Exercise 7.21: Pattern Matching with Multiple Characters</h2>
			<p>In this exercise, we will use the <strong class="source-inline">match</strong> method for matching multiple characters. Let's perform the following steps:</p>
			<ol>
				<li value="1">Use <strong class="source-inline">*</strong> to match <strong class="source-inline">0</strong> or more repetitions of the preceding regular expression:<p class="source-code">import re</p><p class="source-code">def print_match(s):</p><p class="source-code">    if prog.search(s)==None:</p><p class="source-code">        print("No match")</p><p class="source-code">    else:</p><p class="source-code">        print(prog.search(s).group())</p><p class="source-code">prog = re.compile(r'ab*')</p><p class="source-code">print_match("a")</p><p class="source-code">print_match("ab")</p><p class="source-code">print_match("abbb")</p><p class="source-code">print_match("b")</p><p class="source-code">print_match("bbab")</p><p class="source-code">print_match("something_abb_something")</p><p>The output is as follows:</p><p class="source-code">a</p><p class="source-code">ab</p><p class="source-code">abbb</p><p class="source-code">No match</p><p class="source-code">ab</p><p class="source-code">abb</p></li>
				<li>Using <strong class="source-inline">+</strong> causes the resulting <strong class="source-inline">RE</strong> to match <strong class="source-inline">1</strong> or more repetitions of the preceding regular expression:<p class="source-code">prog = re.compile(r'ab+')</p><p class="source-code">print_match("a")</p><p class="source-code">print_match("ab")</p><p class="source-code">print_match("abbb")</p><p class="source-code">print_match("b")</p><p class="source-code">print_match("bbab")</p><p class="source-code">print_match("something_abb_something")</p><p>The output is as follows:</p><p class="source-code">No match</p><p class="source-code">ab</p><p class="source-code">abbb</p><p class="source-code">No match</p><p class="source-code">ab</p><p class="source-code">abb</p></li>
				<li>? causes the resulting <strong class="source-inline">re</strong> string to match precisely 0 or 1 repetitions of the preceding regular expression:<p class="source-code">prog = re.compile(r'ab?')</p><p class="source-code">print_match("a")</p><p class="source-code">print_match("ab")</p><p class="source-code">print_match("abbb")</p><p class="source-code">print_match("b")</p><p class="source-code">print_match("bbab")</p><p class="source-code">print_match("something_abb_something")</p><p>The output is as follows:</p><p class="source-code">a</p><p class="source-code">ab</p><p class="source-code">ab</p><p class="source-code">No match</p><p class="source-code">ab</p><p class="source-code">ab</p></li>
			</ol>
			<p>Here, we saw how we can use regex to search for and match a set of characters in the same order as they occur in the search pattern.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/310l7Jw%20">https://packt.live/310l7Jw.</a></p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/3hCdnDz">https://packt.live/3hCdnDz</a>.</p>
			<p>The standard (default) mode of pattern matching in regex is <strong class="bold">greedy</strong>, that is, the program tries to match as much as it can. Sometimes, this behavior is natural, but in some cases, you may want to match minimally. This is called <strong class="bold">non-greedy</strong> matching.</p>
			<h2 id="_idParaDest-245"><a id="_idTextAnchor253"/>Exercise 7.22: Greedy versus Non-Greedy Matching</h2>
			<p>In this exercise, we will perform greedy and non-greedy pattern matching. Let's go through the following steps:</p>
			<ol>
				<li value="1">Write the code to check the greedy way of matching a string, as follows:<p class="source-code">import re</p><p class="source-code">def print_match(s):</p><p class="source-code">    if prog.search(s)==None:</p><p class="source-code">        print("No match")</p><p class="source-code">    else:</p><p class="source-code">        print(prog.search(s).group())</p><p class="source-code">prog = re.compile(r'&lt;.*&gt;')</p><p class="source-code">print_match('&lt;a&gt; b &lt;c&gt;')</p><p>The output is as follows:</p><p class="source-code"> &lt;a&gt; b &lt;c&gt;</p><p>So, the preceding regex found both tags with the <strong class="source-inline">&lt;&gt;</strong> pattern, but what if we wanted to match the first tag only and stop there. </p></li>
				<li>Use <strong class="source-inline">?</strong> by inserting it after any regex expression to make it non-greedy:<p class="source-code">prog = re.compile(r'&lt;.*?&gt;')</p><p class="source-code">print_match('&lt;a&gt; b &lt;c&gt;')</p><p>The output is as follows:</p><p class="source-code">&lt;a&gt;</p></li>
			</ol>
			<p>In the following exercise, we will be handling repetitions using <strong class="source-inline">match</strong>.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/37Hz944%20">https://packt.live/37Hz944.</a></p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/2UVlK3q">https://packt.live/2UVlK3q</a>.</p>
			<h2 id="_idParaDest-246"><a id="_idTextAnchor254"/>Exercise 7.23: Controlling Repetitions to Match in a Text</h2>
			<p>In this exercise, we will check the number of repetitions of the pattern we want to match in a text. Let's go through the following steps:</p>
			<ol>
				<li value="1"><strong class="source-inline">{m}</strong> specifies exactly <strong class="source-inline">m</strong> copies of <strong class="source-inline">RE</strong> to match. Fewer matches cause a non-match and return <strong class="source-inline">None</strong>:<p class="source-code">import re</p><p class="source-code">def print_match(s):</p><p class="source-code">    if prog.search(s)==None:</p><p class="source-code">        print("No match")</p><p class="source-code">    else:</p><p class="source-code">        print(prog.search(s).group())</p><p class="source-code">prog = re.compile(r'A{3}')</p><p class="source-code">print_match("ccAAAdd")</p><p class="source-code">print_match("ccAAAAdd")</p><p class="source-code">print_match("ccAAdd")</p><p>The output is as follows:</p><p class="source-code">AAA</p><p class="source-code">AAA</p><p class="source-code">No match</p></li>
				<li><strong class="source-inline">{m,n}</strong> specifies exactly <strong class="source-inline">m</strong> to <strong class="source-inline">n</strong> copies of <strong class="source-inline">RE</strong> to match:<p class="source-code">prog = re.compile(r'A{2,4}B')</p><p class="source-code">print_match("ccAAABdd")</p><p class="source-code">print_match("ccABdd")</p><p class="source-code">print_match("ccAABBBdd")</p><p class="source-code">print_match("ccAAAAAAABdd")</p><p>The output is as follows:</p><p class="source-code">AAAB</p><p class="source-code">No match</p><p class="source-code">AAB</p><p class="source-code">AAAAB</p></li>
				<li>Omitting <strong class="source-inline">m</strong> specifies a lower bound of zero:<p class="source-code">prog = re.compile(r'A{,3}B')</p><p class="source-code">print_match("ccAAABdd")</p><p class="source-code">print_match("ccABdd")</p><p class="source-code">print_match("ccAABBBdd")</p><p class="source-code">print_match("ccAAAAAAABdd")</p><p>The output is as follows:</p><p class="source-code">AAAB</p><p class="source-code">AB</p><p class="source-code">AAB</p><p class="source-code">AAAB</p></li>
				<li>Omitting <strong class="source-inline">n</strong> specifies an infinite upper bound:<p class="source-code">prog = re.compile(r'A{3,}B')</p><p class="source-code">print_match("ccAAABdd")</p><p class="source-code">print_match("ccABdd")</p><p class="source-code">print_match("ccAABBBdd")</p><p class="source-code">print_match("ccAAAAAAABdd")</p><p>The output is as follows:</p><p class="source-code">AAAB</p><p class="source-code">No match</p><p class="source-code">No match</p><p class="source-code">AAAAAAAB</p></li>
				<li><strong class="source-inline">{m,n}?</strong> specifies <strong class="source-inline">m</strong> to <strong class="source-inline">n</strong> copies of <strong class="source-inline">RE</strong> to match in a non-greedy fashion:<p class="source-code">prog = re.compile(r'A{2,4}')</p><p class="source-code">print_match("AAAAAAA")</p><p class="source-code">prog = re.compile(r'A{2,4}?')</p><p class="source-code">print_match("AAAAAAA")</p><p>The output is as follows:</p><p class="source-code">AAAA</p><p class="source-code">AA</p><p class="callout-heading">Note</p><p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/2YOzAWf%20">https://packt.live/2YOzAWf.</a></p><p class="callout">You can also run this example online at <a href="https://packt.live/2YKO7T4">https://packt.live/2YKO7T4</a>.</p></li>
			</ol>
			<p>Let's go over to the next section.</p>
			<h2 id="_idParaDest-247"><a id="_idTextAnchor255"/>Sets of Matching Characters</h2>
			<p>To match an arbitrarily complex pattern, we need to be able to include a logical combination of characters together as a bunch. Regex gives us that kind of capability.</p>
			<p>The following examples demonstrate such uses of regex. <strong class="source-inline">[x,y,z]</strong> matches <strong class="source-inline">x</strong>, <strong class="source-inline">y</strong>, or <strong class="source-inline">z</strong>:</p>
			<p class="source-code">prog = re.compile(r'[A,B]')</p>
			<p class="source-code">print_match("ccAd")</p>
			<p class="source-code">print_match("ccABd")</p>
			<p class="source-code">print_match("ccXdB")</p>
			<p class="source-code">print_match("ccXdZ")</p>
			<p>The output will be as follows:</p>
			<p class="source-code">A</p>
			<p class="source-code">A</p>
			<p class="source-code">B</p>
			<p class="source-code">No match</p>
			<p>A range of characters can be matched inside the set using <strong class="source-inline">-</strong>. This is one of the most widely used regex techniques.</p>
			<h2 id="_idParaDest-248"><a id="_idTextAnchor256"/>Exercise 7.24: Sets of Matching Characters</h2>
			<p>In this exercise, we will find the sets of matching characters from a defined string. We will look for an email address pattern, <strong class="source-inline">&lt;some name&gt;@&lt;some domain name&gt;.&lt;some domain identifier&gt;</strong>, from a string. Let's go through the following steps:</p>
			<ol>
				<li value="1">Suppose we want to pick out an email address from some text:<p class="source-code">import re</p><p class="source-code">def print_match(s):</p><p class="source-code">    if prog.search(s)==None:</p><p class="source-code">        print("No match")</p><p class="source-code">    else:</p><p class="source-code">        print(prog.search(s).group())</p><p class="source-code">prog = re.compile(r'[a-zA-Z]+@+[a-zA-Z]+\.com')</p><p class="source-code">print_match("My email is coolguy@xyz.com")</p><p class="source-code">print_match("My email is coolguy12@xyz.com")</p><p>The output is as follows:</p><p class="source-code">coolguy@xyz.com</p><p class="source-code">No match</p><p>Look at the regex pattern inside [<strong class="source-inline"> … </strong>]. It is <strong class="source-inline">a-zA-Z</strong>. This covers all letters, including lowercase and uppercase. With this one simple regex, you are able to match any (pure) alphabetical string for that part of the email. Now, the next pattern is <strong class="source-inline">@</strong>, which is added to the previous regex by the <strong class="source-inline">+</strong> character. This is the way to build up a complex regex: by adding/stacking up individual regex patterns. We also use the same <strong class="source-inline">[a-zA-Z]</strong> for the email domain name and add a <strong class="source-inline">.com</strong> at the end to complete the pattern as a valid email address. Why <strong class="source-inline">\.</strong>? Because, by itself, a dot (<strong class="source-inline">.</strong>) is used as a special modifier in regex but here we want to use a dot (<strong class="source-inline">.</strong>) just as a dot (<strong class="source-inline">.</strong>), not as a modifier. So, we need to precede it with <strong class="source-inline">\</strong>.</p><p>So, with this regex, we could extract the first email address perfectly but got <strong class="source-inline">No match</strong> with the second one. What happened with the second email ID?</p><p>The regex could not capture it because it had the number <strong class="source-inline">12</strong> in the name. That pattern is not captured by the expression [<strong class="source-inline">a-zA-Z</strong>].</p></li>
				<li>Let's change that and add the digits as well:<p class="source-code">prog = re.compile(r'[a-zA-Z0-9]+@+[a-zA-Z]+\.com')</p><p class="source-code">print_match("My email is coolguy12@xyz.com")</p><p class="source-code">print_match("My email is coolguy12@xyz.org")</p><p>The output is as follows:</p><p class="source-code">coolguy12@xyz.com</p><p class="source-code">No match</p><p>We caught the first email ID perfectly. But what's going on with the second one? Again, we got a mismatch. The reason is that we changed the <strong class="source-inline">.com</strong> to <strong class="source-inline">.org</strong> in that email, and in our regex expression, that portion was hardcoded as <strong class="source-inline">.com</strong>, so it did not find a match.</p></li>
				<li>Let's try to address this in the following regex:<p class="source-code">prog = re.compile(r'[a-zA-Z0-9]+@+[a-zA-Z]+\.+[a-zA-Z]{2,3}')</p><p class="source-code">print_match("My email is coolguy12@xyz.org")</p><p class="source-code">print_match("My email is coolguy12[AT]xyz[DOT]org")</p><p>The output is as follows:</p><p class="source-code">coolguy12@xyz.org</p><p class="source-code">No match</p></li>
			</ol>
			<p>In this regex, we used the fact that most domain identifiers have two or three characters, so we used <strong class="source-inline">[a-zA-Z]{2,3}</strong> to capture that.</p>
			<p>What happened with the second email ID? This is an example of the small tweaks that you can make to stay ahead of telemarketers who want to scrape online forums or any other corpus of text and extract your email ID. If you do not want your email to be found, you can change <strong class="source-inline">@</strong> to <strong class="source-inline">[AT]</strong> and <strong class="source-inline">.</strong> to <strong class="source-inline">[DOT]</strong>, and hopefully, that should beat some regex techniques (but not all of them).</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/2UXv6eS%20">https://packt.live/2UXv6eS.</a></p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/315GaL9">https://packt.live/315GaL9</a>.</p>
			<h2 id="_idParaDest-249"><a id="_idTextAnchor257"/>Exercise 7.25: The Use of OR in RegEx Using the OR Operator</h2>
			<p>In this exercise, we will use the <strong class="source-inline">OR</strong> operator in a Regex expression. We will try to extract patterns of 10-digit numbers that could be phone numbers. We can do that by using the <strong class="source-inline">|</strong> operator. Let's go through the following steps:</p>
			<ol>
				<li value="1">Let's start with the <strong class="source-inline">OR</strong> operator:<p class="source-code">import re</p><p class="source-code">def print_match(s):</p><p class="source-code">    if prog.search(s)==None:</p><p class="source-code">         print("No match")</p><p class="source-code">    else:</p><p class="source-code">         print(prog.search(s).group())</p><p class="source-code">prog = re.compile(r'[0-9]{10}')</p><p class="source-code">print_match("3124567897")</p><p class="source-code">print_match("312-456-7897")</p><p>The output is as follows:</p><p class="source-code">3124567897</p><p class="source-code">No match</p><p>Note the use of <strong class="source-inline">{10}</strong> to denote exactly <strong class="source-inline">10</strong>-digit numbers in the pattern. But the second number could not be matched for obvious reasons – it had <strong class="source-inline">-</strong> symbols inserted in between groups of numbers.</p></li>
				<li>Use multiple smaller regexes and logically combine them by using the following command:<p class="source-code">prog = re.compile(r'[0-9]{10}|[0-9]{3}-[0-9]{3}-[0-9]{4}')</p><p class="source-code">print_match("3124567897")</p><p class="source-code">print_match("312-456-7897")</p><p>The output is as follows:</p><p class="source-code">3124567897</p><p class="source-code">312-456-7897</p><p>Phone numbers are written in a myriad of ways and if you search on the web, you will see examples of very complex regexes (written not only in Python but in other widely used languages for web apps such as JavaScript, C++, PHP, and Perl) for capturing phone numbers.</p></li>
				<li>Create four strings and execute <strong class="source-inline">print_match</strong> on them:<p class="source-code">p1= r'[0-9]{10}'</p><p class="source-code">p2=r'[0-9]{3}-[0-9]{3}-[0-9]{4}'</p><p class="source-code">p3 = r'\([0-9]{3}\)[0-9]{3}-[0-9]{4}'</p><p class="source-code">p4 = r'[0-9]{3}\.[0-9]{3}\.[0-9]{4}'</p><p class="source-code">pattern= p1+'|'+p2+'|'+p3+'|'+p4</p><p class="source-code">prog = re.compile(pattern)</p><p class="source-code">print_match("3124567897")</p><p class="source-code">print_match("312-456-7897")</p><p class="source-code">print_match("(312)456-7897")</p><p class="source-code">print_match("312.456.7897")</p><p>The output is as follows:</p><p class="source-code">3124567897</p><p class="source-code">312-456-7897</p><p class="source-code">(312)456-7897</p><p class="source-code">312.456.7897</p></li>
			</ol>
			<p>So, as you can see, thanks to all the different patterns we have added together using the <strong class="source-inline">OR</strong> operator, we are able to detect phone numbers even if they are written in very different ways.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/3eeZc59%20">https://packt.live/3eeZc59.</a></p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/2APMFH5">https://packt.live/2APMFH5</a>.</p>
			<h2 id="_idParaDest-250"><a id="_idTextAnchor258"/>The findall Method</h2>
			<p>The last regex method that we will cover in this chapter is <strong class="source-inline">findall</strong>. Essentially, it is a <strong class="bold">search-and-aggregate</strong> method, that is, it puts together all the instances that match the regex pattern in a given text and returns them in a list. This is extremely useful, as we can just count the length of the returned list to count the number of occurrences or pick and use the returned pattern-matched words one by one as we see fit.</p>
			<p>Note that although we are giving short examples of single sentences in this chapter, you will often deal with a large corpus of text when using a regex.</p>
			<p>In those cases, you are likely to get many matches from a single regex pattern search. For all of those cases, the <strong class="source-inline">findall</strong> method is going to be the most useful:</p>
			<p class="source-code">ph_numbers = """Here are some phone numbers.</p>
			<p class="source-code">Pick out the numbers with 312 area code: </p>
			<p class="source-code">312-423-3456, 456-334-6721, 312-5478-9999, </p>
			<p class="source-code">312-Not-a-Number,777.345.2317, 312.331.6789"""</p>
			<p class="source-code">print(ph_numbers)</p>
			<p class="source-code">re.findall('312+[-\.][0-9-\.]+',ph_numbers)</p>
			<p>The output is as follows:</p>
			<p class="source-code"> Here are some phone numbers.</p>
			<p class="source-code">Pick out the numbers with 312 area code: </p>
			<p class="source-code">312-423-3456, 456-334-6721, 312-5478-9999, </p>
			<p class="source-code">312-Not-a-Number,777.345.2317, 312.331.6789</p>
			<p class="source-code"> ['312-423-3456', '312-5478-9999', '312.331.6789']</p>
			<p>With all this knowledge gained from the chapter, let's get started with solving the following activities. </p>
			<h2 id="_idParaDest-251">Activity 7.01: Extracting the T<a id="_idTextAnchor259"/>op 100 e-books from Gutenberg</h2>
			<p>Project Gutenberg encourages the creation and distribution of eBooks by encouraging volunteer efforts to digitize and archive cultural works. This activity aims to scrape the URL of Project Gutenberg's Top 100 eBooks to identify the eBooks' links. It uses <strong class="source-inline">BeautifulSoup</strong> to parse the HTML and regular expression code to identify the Top 100 eBook file numbers. You can use these numbers to download the book into your local drive if you want.</p>
			<p>These are the steps that will help you complete this activity:</p>
			<ol>
				<li value="1">Import the necessary libraries, including <strong class="source-inline">regex</strong> and <strong class="source-inline">BeautifulSoup</strong>.</li>
				<li>Read the HTML from the URL.</li>
				<li>Write a small function to check the status of the web request.</li>
				<li>Decode the response and pass this on to <strong class="source-inline">BeautifulSoup</strong> for HTML parsing.</li>
				<li>Find all the <strong class="source-inline">href</strong> tags and store them in the list of links. Check what the list looks like – print the first 30 elements.</li>
				<li>Use a regular expression to find the numeric digits in these links. These are the file numbers for the top 100 eBooks.</li>
				<li>Initialize the empty list to hold the file numbers over an appropriate range and use <strong class="source-inline">regex</strong> to find the numeric digits in the link <strong class="source-inline">href</strong> string. <strong class="bold">Hint:</strong> Use the <strong class="source-inline">findall</strong> method.</li>
				<li>What does the <strong class="source-inline">soup</strong> object's text look like? Use the <strong class="source-inline">.text</strong> method and print only the first 2,000 characters (do not print the whole thing, as it is too long).</li>
				<li>Search in the extracted text (using a regular expression) from the <strong class="source-inline">soup</strong> object to find the names of the top 100 eBooks (yesterday's ranking).</li>
				<li>Create a starting index. It should point at the text <em class="italic">Top 100 Ebooks yesterday</em>. Use the <strong class="source-inline">splitlines</strong> method of <strong class="source-inline">soup.text</strong>. It splits the lines of text of the <strong class="source-inline">soup</strong> object.</li>
				<li>Run the <strong class="source-inline">for</strong> loop <strong class="source-inline">1-100</strong> to add the strings of the next <strong class="source-inline">100</strong> lines to this temporary list. <strong class="bold">Hint:</strong> use the <strong class="source-inline">splitlines</strong> method.</li>
				<li>Use a regular expression to extract only text from the name strings and append it to an empty list. Use <strong class="source-inline">match</strong> and <strong class="source-inline">span</strong> to find the indices and use them.</li>
				<li>Print the list of titles.</li>
			</ol>
			<p>The output (shown partially) should look like this:</p>
			<p class="source-code">Pride and Prejudice by Jane Austen </p>
			<p class="source-code">Frankenstein</p>
			<p class="source-code">A Modest Proposal by Jonathan Swift </p>
			<p class="source-code">A Christmas Carol in Prose</p>
			<p class="source-code">Heart of Darkness by Joseph Conrad </p>
			<p class="source-code">Et dukkehjem</p>
			<p class="source-code">A Tale of Two Cities by Charles Dickens </p>
			<p class="source-code">Dracula by Bram Stoker </p>
			<p class="source-code">Moby Dick</p>
			<p class="source-code">The Importance of Being Earnest</p>
			<p class="source-code">Alice</p>
			<p class="source-code">Metamorphosis by Franz Kafka </p>
			<p class="source-code">The Strange Case of Dr</p>
			<p class="source-code">Beowulf</p>
			<p class="source-code">…</p>
			<p class="source-code">The Russian Army and the Japanese War</p>
			<p class="source-code">Calculus Made Easy by Silvanus P</p>
			<p class="source-code">Beyond Good and Evil by Friedrich Wilhelm Nietzsche </p>
			<p class="source-code">An Occurrence at Owl Creek Bridge by Ambrose Bierce </p>
			<p class="source-code">Don Quixote by Miguel de Cervantes Saavedra </p>
			<p class="source-code">Blue Jackets by Edward Greey </p>
			<p class="source-code">The Life and Adventures of Robinson Crusoe by Daniel Defoe </p>
			<p class="source-code">The Waterloo Campaign </p>
			<p class="source-code">The War of the Worlds by H</p>
			<p class="source-code">Democracy in America </p>
			<p class="source-code">Songs of Innocence</p>
			<p class="source-code">The Confessions of St</p>
			<p class="source-code">Modern French Masters by Marie Van Vorst </p>
			<p class="source-code">Persuasion by Jane Austen </p>
			<p class="source-code">The Works of Edgar Allan Poe </p>
			<p class="source-code">The Fall of the House of Usher by Edgar Allan Poe </p>
			<p class="source-code">The Masque of the Red Death by Edgar Allan Poe </p>
			<p class="source-code">The Lady with the Dog and Other Stories by Anton Pavlovich Chekhov</p>
			<p class="callout-heading">Note</p>
			<p class="callout">The solution for this activity can be found via <a href="B15780_Solution_Final_RK.xhtml#_idTextAnchor323">this link</a>.</p>
			<h2 id="_idParaDest-252">Activity 7.02: Building Your Ow<a id="_idTextAnchor260"/>n Movie Database by Reading an API</h2>
			<p>In this activity, you will build a complete movie database by communicating and interfacing with a free API from the OMDb portal <a href="http://www.omdbapi.com/?">http://www.omdbapi.com/?</a>.You will obtain a unique user key from the OMDb website that must be used when your program tries to access the API. Then, you will need to store this key value in a <strong class="source-inline">.json</strong> file.</p>
			<p>The aims of this activity are as follows:</p>
			<ul>
				<li>To retrieve and print basic data about a movie (the title is entered by the user) from the web (the OMDb database).</li>
				<li>If a poster of the movie can be found, download the file and save it in a user-specified location.</li>
			</ul>
			<p>These are the steps that will help you complete this activity:</p>
			<ol>
				<li value="1">Import <strong class="source-inline">urllib.request</strong>, <strong class="source-inline">urllib.parse</strong>, <strong class="source-inline">urllib.error</strong>, and <strong class="source-inline">json</strong>.</li>
				<li>Load the secret API key (you have to get one from the OMDb website and use that; it has a daily limit of 1,000 API keys) from a JSON file, stored in the same folder, in a variable.<p><strong class="bold">Hint:</strong> Use <strong class="source-inline">json.loads()</strong>.</p><p>Students/users will need to obtain a key and store it in a JSON file.</p></li>
				<li>Obtain a key and store it in a JSON file as <strong class="source-inline">APIkeys.json</strong>.</li>
				<li>Open the <strong class="source-inline">APIkeys.json</strong> file.</li>
				<li>Assign the OMDb portal (<a href="http://www.omdbapi.com/?">http://www.omdbapi.com/?</a>) as a string to a variable.</li>
				<li>Create a variable called <strong class="source-inline">apikey</strong> with the last portion of the URL (<strong class="source-inline">&amp;apikey=secretapikey</strong>), where <strong class="source-inline">secretapikey</strong> is your own API key.</li>
				<li>Write a utility function called <strong class="source-inline">print_json</strong> to print the movie data from a JSON file (which we will get from the portal).</li>
				<li>Write a utility function to download a poster of the movie based on the information from the JSON dataset and save it in your local folder. Use the <strong class="source-inline">os</strong> module. The poster data is stored in a JSON key called <strong class="source-inline">Poster</strong>. Use the <strong class="source-inline">open</strong> Python command to open a file and write the poster data. Close the file after you're done. This function will save the poster data as an image file.</li>
				<li>Write a utility function called <strong class="source-inline">search_movie</strong> to search for a movie by its name, print the downloaded <strong class="source-inline">JSON</strong> data, and save the movie poster in the local folder. Use a <strong class="source-inline">try-except</strong> loop for this. Use the previously created <strong class="source-inline">serviceurl</strong> and <strong class="source-inline">apikey</strong> variables. You have to pass on a dictionary with a key, <strong class="source-inline">t</strong>, and the movie name as the corresponding value to the <strong class="source-inline">urllib.parse.urlencode()</strong> function and then add the <strong class="source-inline">serviceurl</strong> and <strong class="source-inline">apikey</strong> variables to the output of the function to construct the full URL. This URL will be used to access the data. The <strong class="source-inline">JSON</strong> data has a key called <strong class="source-inline">Response</strong>. If it is <strong class="source-inline">True</strong>, that means the read was successful. Check this before processing the data. If it's not successful, then print the <strong class="source-inline">JSON</strong> key <strong class="source-inline">Error</strong>, which will contain the appropriate error message returned by the movie database.</li>
				<li>Test the <strong class="source-inline">search_movie</strong> function by entering <strong class="source-inline">Titanic</strong>. The output should look like this:<p class="source-code">http://www.omdbapi.com/?t=Titanic&amp;apikey=&lt;your API key&gt;</p><p class="source-code">--------------------------------------------------</p><p class="source-code">Title: Titanic</p><p class="source-code">Year: 1997</p><p class="source-code">Rated: PG-13</p><p class="source-code">Released: 19 Dec 1997</p><p class="source-code">Runtime: 194 min</p><p class="source-code">Genre: Drama, Romance</p><p class="source-code">Director: James Cameron</p><p class="source-code">Writer: James Cameron</p><p class="source-code">Actors: Leonardo DiCaprio, Kate Winslet, Billy Zane, Kathy Bates</p><p class="source-code">Plot: A seventeen-year-old aristocrat falls in love with a kind but poor artist aboard the luxurious, ill-fated R.M.S. Titanic.</p><p class="source-code">Language: English, Swedish</p><p class="source-code">Country: USA</p><p class="source-code">Awards: Won 11 Oscars. Another 111 wins &amp; 77 nominations.</p><p class="source-code">Ratings: [{'Source': 'Internet Movie Database', 'Value': '7.8/10'}, {'Source': 'Rotten Tomatoes', 'Value': '89%'}, {'Source': 'Metacritic', 'Value': '75/100'}]</p><p class="source-code">Metascore: 75</p><p class="source-code">imdbRating: 7.8</p><p class="source-code">imdbVotes: 913,780</p><p class="source-code">imdbID: tt0120338</p><p class="source-code">--------------------------------------------------</p></li>
				<li>Test the <strong class="source-inline">search_movie</strong> function by entering <strong class="source-inline">Random_error</strong> and retrieve the data for <strong class="source-inline">Random_error</strong> (obviously, this will not be found, and you should be able to check whether your error-catching code is working properly). The expected output is as follows:<p class="source-code">http://www.omdbapi.com/?t=Random_error&amp;apikey=&lt;your api key&gt;</p><p class="source-code">Error encountered:  Movie not found!</p><p class="callout-heading">Note</p><p class="callout">The solution for this activity can be found via <a href="B15780_Solution_Final_RK.xhtml#_idTextAnchor324">this link</a>.</p></li>
			</ol>
			<p>Look for a folder called <strong class="source-inline">Posters</strong> in the same directory you are working in. It should contain a file called <strong class="source-inline">Titanic.jpg</strong>. Check the file. </p>
			<p>In this activity, we have seen a few general tricks for working with an API that are fairly common for other popular API services such as Google and Twitter. Now, you should be confident about writing more complex programs to scrape data from such services.</p>
			<h1 id="_idParaDest-253"><a id="_idTextAnchor261"/>Summary</h1>
			<p>In this chapter, we went through several important concepts and learning modules related to advanced data gathering and web scraping. We started by reading data from web pages using two of the most popular Python libraries – <strong class="source-inline">requests</strong> and <strong class="source-inline">BeautifulSoup</strong>. In this task, we utilized the knowledge we gained in the previous chapter about the general structure of HTML pages and their interaction with Python code. We extracted meaningful data from the Wikipedia home page during this process.</p>
			<p>Then, we learned how to read data from XML and JSON files – two of the most widely used data streaming/exchange formats on the web. For XML, we showed you how to traverse the tree-structure data string efficiently to extract key information. For JSON, we mixed it with reading data from the web using an API. The API we consumed was RESTful, which is one of the major standards in web APIs. </p>
			<p>At the end of this chapter, we went through a detailed exercise using regex techniques in tricky string-matching problems to scrape useful information from a large and messy text corpus, parsed from HTML. This chapter should come in extremely handy for string and text processing tasks in your data wrangling career.</p>
			<p>In the next chapter, we will learn about databases with Python.</p>
		</div>
		<div>
			<div id="_idContainer249" class="Content">
			</div>
		</div>
	</div></body></html>