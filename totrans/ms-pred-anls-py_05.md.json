["```py\n>>> %matplotlib inline\n… import pandas as pd\n… import matplotlib.pyplot as plt\n… import numpy as np\n… plt.style.use('ggplot')\n>>> input = np.arange(-10,10,1)\n>>> output = 1/(1+np.exp(-input))\n>>> pd.DataFrame({\"input\":input,\"output\":output}).plot(x='input',y='output')\n\n```", "```py\n>>> census = pd.read_csv('census.data',header=None)\n>>> census.head()\n\n```", "```py\n>>> headers_file = open('census.headers')\n>>> headers = []\n>>> for line in headers_file:\n>>>    if len(line.split(':'))>1: # colon indicates line is a column description\n>>>        headers.append(line.split(':')[0]) # the column name precedes the colon\n>>> headers = headers[15:] # the filter in the if (…) statement above is not 100 percent accurate, need to remove first 15 elements\n>>> headers.append('income') # add label for the response variable in the last column\n>>> census.columns = headers # set the column names in the dataframe to be extracted names\n\n```", "```py\n>>> census.income = census.income.map( lambda x: 0 if x==' <=50K' else 1)\n\n```", "```py\n>>> census.plot(kind='hist', y='income')\n\n```", "```py\n>>> categorical_features = [e for e,t in enumerate(census.dtypes) if t=='object' ]\n\n```", "```py\n>>> categorical_dicts = []\n>>> for c in categorical_features:\n>>>    categorical_dicts.append(dict( (i,e) for (e,i) in enumerate(census[headers[c]].unique()) ))\n\n```", "```py\n>>> census_categorical = census\n>>> for e,c in enumerate(categorical_features):\n>>>   census_categorical[headers[c]] = \\ census_categorical[headers[c]].\\\nmap(categorical_dicts[e].get)\n\n```", "```py\n>>> n_values = [len(d) for d in categorical_dicts] \n\n```", "```py\n>>> from sklearn.preprocessing import OneHotEncoder\n>>> census_categorical_one_hot = OneHotEncoder(categorical_features=categorical_features, n_values=n_values).fit_transform(census_categorical[headers[:-1]])\n\n```", "```py\n>>> from scipy import sparse\n>>> from sklearn import cross_validation\n>>> census_features_train, census_features_test, census_income_train, census_income_test = \\\n>>> cross_validation.train_test_split(census_categorical_one_hot, \\\n>>> census_categorical['income'], test_size=0.4, random_state=0)\n\n```", "```py\n>>> input = np.arange(10)-5\n>>> parabola = [a*a for a in input]\n>>> line = [-1*a for a in input-10]\n>>> plt.plot(input,parabola)\n>>> plt.plot(input,line,color='blue')\n\n```", "```py\n>>> log_model_sgd = linear_model.SGDClassifier(alpha=10,loss='log',penalty='l2',n_iter=1000, fit_intercept=False).fit(census_features_train,census_income_train)\n\n```", "```py\n>>> log_model_sgd.coef_\n\n```", "```py\n>>> log_model_newton = linear_model.LogisticRegression(penalty='l2',solver='lbfgs', fit_intercept=False).fit(census_features_train,census_income_train\n\n```", "```py\n>>> plt.scatter(log_model_newton.coef_,log_model_sgd.coef_)\n>>> plt.xlim(-0.08,0.08)\n>>> plt.ylim(-0.08,0.08)\n>>> plt.xlabel('Newton Coefficent')\n>>> plt.ylabel('SGD Coefficient')\n\n```", "```py\n>>> from sklearn.preprocessing import StandardScaler\n>>> census_features_train_sc= StandardScaler().fit_transform(X=census_features_train.todense())\n\n```", "```py\nTP = true positives = # of class 1 points above the threshold\nFP = false positives = # of class 0 points above the threshold\nTN = true negatives = # of class 0 points below the threshold\nFN = false negatives = # of class 1 points below the threshold\n\n```", "```py\n>>> train_prediction = log_model_newton.predict_proba(census_features_train)\n>>> test_prediction = log_model_newton.predict_proba(census_features_test)\n\n```", "```py\n>>>  from sklearn import metrics\n>>> fpr_train, tpr_train, thresholds_train = metrics.roc_curve(np.array(census_income_train),\\\n np.array(train_prediction[:,1]), pos_label=1)\n>>> fpr_test, tpr_test, thresholds_test = metrics.roc_curve(np.array(census_income_test),\\\n np.array(test_prediction[:,1]), pos_label=1)\n>>> plt.plot(fpr_train, tpr_train)\n>>> plt.plot(fpr_test, tpr_test)\n>>> plt.xlabel('False Positive Rate')\n>>> plt.ylabel('True Positive Rate')\n\n```", "```py\n>>> metrics.auc(fpr_train,tpr_train)\n\n```", "```py\n>>> metrics.auc(fpr_test,tpr_test)\n\n```", "```py\n>>> expanded_headers = []\n>>> non_categorical_headers = []\n>>> categorical_index = 0\n>>> for e,h in enumerate(np.array(census.columns[:-1])):\n …   if e in set(categorical_features):\n …       unsorted_category = np.array([h+key for key in categorical_dicts[categorical_index].keys()]) # appends the category label h to each feature 'key' \n …       category_indices = np.array(list(categorical_dicts[categorical_index].values())) # gets the mapping from category label h to the position in the one-hot array \n …       expanded_headers+=list(unsorted_category[np.argsort(category_indices)]) # resort the category values in the same order as they appear in the one-hot encoding\n…        categorical_index+=1 # increment to the next categorical feature\n…    else:\n…        non_categorical_headers+=[h]\n… expanded_headers+=non_categorical_headers\n\n```", "```py\n>>> expanded_headers[np.argsort(-1*log_model.coef_[0])]\narray(['capital-gain', 'capital-loss', 'hours-per-week', 'age',        'education-num', 'marital-status Married-civ-spouse',        'relationship Husband', 'sex Male', 'occupation Exec-managerial',        'education Bachelors', 'occupation Prof-specialty',        'education Masters', 'relationship Wife', 'education Prof-school',        'workclass Self-emp-inc', 'education Doctorate',        'workclass Local-gov', 'workclass Federal-gov',        'workclass Self-emp-not-inc', 'race White',        'occupation Tech-support', 'occupation Protective-serv',        'workclass State-gov', 'occupation Sales', … \n\n```", "```py\n>>> plt.bar(np.arange(108),np.sort(log_model_newton.coef_[0]))\n\n```", "```py\n>>> from sklearn import svm\n>>> svm_model = svm.SVC(probability=True,kernel='rbf').fit(census_features_train.toarray(),census_income_train)\n>>> train_prediction = svm_model.predict_proba(census_features_train.toarray())\n>>> test_prediction = svm_model.predict_proba(census_features_test.toarray())\n>>> fpr_train, tpr_train, thresholds_train = metrics.roc_curve(np.array(census_income_train),\\\n np.array(train_prediction[:,1]), pos_label=1)\n>>> fpr_test, tpr_test, thresholds_test = metrics.roc_curve(np.array(census_income_test),\\\n np.array(test_prediction[:,1]), pos_label=1)\n>>> plt.plot(fpr_train, tpr_train)\n>>> plt.plot(fpr_test, tpr_test)\n>>> plt.xlabel('False Positive Rate')\n>>> plt.ylabel('True Positive Rate')\n\n```", "```py\n>>> from sklearn.ensemble import GradientBoostingClassifier\n>>> gbm = GradientBoostingClassifier(n_estimators=200, learning_rate=1.0,\\\n… max_depth=5, random_state=0).fit(census_features_train.toarray(),census_income_train) \n>>> train_prediction = gbm.predict_proba(census_features_train.toarray()) \n>>> test_prediction = gbm.predict_proba(census_features_test.toarray()) \n>>> fpr_train, tpr_train, thresholds_train = metrics.roc_curve(np.array(census_income_train),\\\n…   np.array(train_prediction[:,1]), pos_label=1)\n>>>fpr_test, tpr_test, thresholds_test = metrics.roc_curve(np.array(census_income_test),\\\n…   np.array(test_prediction[:,1]), pos_label=1) \n\n```", "```py\n>>> plt.plot(fpr_train, tpr_train)\n>>> plt.plot(fpr_test, tpr_test)\n>>> plt.xlabel('False Positive Rate')\n>>> plt.ylabel('True Positive Rate')\n\n```", "```py\n>>> np.array(expanded_headers)[np.argsort(gbm.feature_importances_)]\narray(['native-country Outlying-US(Guam-USVI-etc)',        'native-country Holand-Netherlands', 'native-country Laos',        'native-country Hungary', 'native-country Honduras',        'workclass Never-worked', 'native-country Nicaragua',        'education Preschool', 'marital-status Married-AF-spouse',        'native-country Portugal', 'occupation Armed-Forces',        'native-country Trinadad&Tobago', 'occupation Priv-house-serv',        'native-country Dominican-Republic', 'native-country Hong',        'native-country Greece', 'native-country El-Salvador',        'workclass Without-pay', 'native-country Columbia',        'native-country Yugoslavia', 'native-country Thailand',        'native-country Scotland', 'native-country Puerto-Rico',        'education 1st-4th', 'education 5th-6th'\n\n```", "```py\n>>> censusRdd = sc.textFile('census.data')\n\n```", "```py\n>>> censusRddSplit = censusRdd.map(lambda x: [e.strip() for e in x.split(',')])\n\n```", "```py\n>>> categoricalFeatures = [e for e,i in enumerate(censusRddSplit.take(1)[0]) if i.isdigit()==False]\n>>> allFeatures = [e for e,i in enumerate(censusRddSplit.take(1)[0])]\n\n```", "```py\n>>> categoricalMaps = []\n>>> for c in categoricalFeatures:\n…    catDict = censusRddSplit.map(lambda x: x[c] if len(x) > c else None).\\\n…    filter(lambda x: x is not None).\\\n…    distinct().\\\n…    zipWithIndex().\\\n…    collectAsMap()\n…    censusRddSplit.map(lambda x: x[c]).take(1)\n…    categoricalMaps.append(catDict)\n\n```", "```py\n>>> expandedFeatures = 0\n>>> for c in categoricalMaps:\n…    expandedFeatures += len(c)\nexpandedFeatures += len(allFeatures)-len(categoricalFeatures)-2\n\n```", "```py\n>>> def formatPoint(p):\n…      if p[-1] == '<=50K':\n…          label = 0\n…      else:\n …         label = 1\n…      vector = [0.0]*expandedFeatures\n…      categoricalIndex = 0\n…      categoricalVariable = 0\n…      for e,c in enumerate(p[:-1]):\n…          if e in categoricalFeatures:\n …             vector[categoricalIndex + categoricalMaps[categoricalVariable][c]]=1\n…              categoricalIndex += len(categoricalMaps[categoricalVariable])\n…              categoricalVariable +=1\n …         else:\n …             vector[e] = c\n…              categoricalIndex += 1\n…      return LabeledPoint(label,vector)\n\n```", "```py\n>>> censusRddLabeled = censusRddSplit.map(lambda x: formatPoint(x))\n\n```", "```py\n>>> from pyspark.mllib.classification import LogisticRegressionWithLBFGS\n>>> censusLogistic = LogisticRegressionWithLBFGS.train(censusRddLabeled )\n\n```", "```py\n>>> censusLogistic.weights\n\n```"]