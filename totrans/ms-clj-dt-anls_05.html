<html><head></head><body><div class="chapter" title="Chapter&#xA0;5.&#xA0;Benford's Law &#x2013; Detecting Natural Progressions of Numbers"><div class="titlepage"><div><div><h1 class="title"><a id="ch05"/>Chapter 5. Benford's Law – Detecting Natural Progressions of Numbers</h1></div></div></div><p>In this chapter, we'll look at <span class="strong"><strong>Benford's Law</strong></span>; an interesting set of properties that are inherent in many naturally occurring sequences of numbers. For these sets of numbers, this observation predicts the distribution of initial digits.</p><p>The odd rule captures an interesting observation about the way numbers are distributed, and it's useful too. Benford's Law has been used as an evidence of fraud. If a sequence of numbers should be naturally occurring but Benford's Law indicates that they are not, then the sequence is likely to be fraudulent. For example, the daily balances in your bank account should follow Benford's Law, but if they don't, that may be evidence that someone is cooking the books.</p><div class="section" title="Learning about Benford's Law"><div class="titlepage"><div><div><h1 class="title"><a id="ch05lvl1sec34"/>Learning about Benford's Law</h1></div></div></div><p>Originally, Benford's Law was observed by the astronomer Simon Newcomb in 1881. He was<a id="id349" class="indexterm"/> referencing the logarithm tables, which were tomes listing the values for logarithms of different numbers. He noticed that the pages of the books were more worn out and discolored at the beginning than they were at the end. In fact, the pages that deal with numbers that begin with <span class="emphasis"><em>1</em></span> were significantly more worn out than pages that begin with <span class="emphasis"><em>9</em></span>. As the initial digits climbed, the pages were less and less worn.</p><p>This phenomenon was noticed again in 1938 by the physicist Frank Benford. He tested this against data in a number of domains, and the principle now bears his name.</p><p>In practical terms, this means that about one-third of the numbers in the sequence begin with the digit <span class="emphasis"><em>1</em></span>, a little more than 15 percent begin with <span class="emphasis"><em>2</em></span>, about 12 percent begin with <span class="emphasis"><em>3</em></span>, and the rest until the digit <span class="emphasis"><em>9</em></span> are all below 10 percent. Five percent of the numbers begin with <span class="emphasis"><em>9</em></span>. The following is a graphical representation of Benford's law:</p><div class="mediaobject"><img src="graphics/4139OS_05_01.jpg" alt="Learning about Benford's Law"/></div><p>So what's the logic behind this? Although the observation itself is surprising, understanding it is really not that difficult. Let's walk through an example to see what we can learn.</p><p>First, we'll<a id="id350" class="indexterm"/> take the example of putting a 100 dollars in the bank and earning an unheard-of 10 percent interest per year, compounded monthly, where the annual interest rate is divided evenly by the number of times it is compounded (in this case, 12), and that is the effective interest rate used each for compounding period. This behavior is evident in more typical interest rates too, but it takes a longer span of time. Let's look at a table of the end-of-year reports for this account:</p><div class="informaltable"><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th style="text-align: left" valign="bottom">
<p>Year</p>
</th><th style="text-align: left" valign="bottom">
<p>Amount in dollars</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<p>0</p>
</td><td style="text-align: left" valign="top">
<p>100.00</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>1</p>
</td><td style="text-align: left" valign="top">
<p>110.47</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>2</p>
</td><td style="text-align: left" valign="top">
<p>122.04</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>3</p>
</td><td style="text-align: left" valign="top">
<p>134.82</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>4</p>
</td><td style="text-align: left" valign="top">
<p>148.94</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>5</p>
</td><td style="text-align: left" valign="top">
<p>164.53</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>6</p>
</td><td style="text-align: left" valign="top">
<p>181.76</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>7</p>
</td><td style="text-align: left" valign="top">
<p>200.79</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>8</p>
</td><td style="text-align: left" valign="top">
<p>221.82</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>9</p>
</td><td style="text-align: left" valign="top">
<p>245.04</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>10</p>
</td><td style="text-align: left" valign="top">
<p>270.70</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>11</p>
</td><td style="text-align: left" valign="top">
<p>299.05</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>12</p>
</td><td style="text-align: left" valign="top">
<p>330.36</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>13</p>
</td><td style="text-align: left" valign="top">
<p>364.96</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>14</p>
</td><td style="text-align: left" valign="top">
<p>403.17</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>15</p>
</td><td style="text-align: left" valign="top">
<p>445.39</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>16</p>
</td><td style="text-align: left" valign="top">
<p>492.03</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>17</p>
</td><td style="text-align: left" valign="top">
<p>543.55</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>18</p>
</td><td style="text-align: left" valign="top">
<p>600.47</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>19</p>
</td><td style="text-align: left" valign="top">
<p>663.35</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>20</p>
</td><td style="text-align: left" valign="top">
<p>732.81</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>21</p>
</td><td style="text-align: left" valign="top">
<p>809.54</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>22</p>
</td><td style="text-align: left" valign="top">
<p>894.31</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>23</p>
</td><td style="text-align: left" valign="top">
<p>987.96</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>24</p>
</td><td style="text-align: left" valign="top">
<p>1,091.41</p>
</td></tr></tbody></table></div><p>When the <a id="id351" class="indexterm"/>money in a bank account is compounded, the amount of money increases nonlinearly. That is, as the 0.30 dollars of interest that I accrued last month is now earning interest, this month, I'll earn 0.32 dollars. As each month's interest is rolled back into the balance, the amount increases faster and faster.</p><div class="mediaobject"><img src="graphics/4139OS_05_02.jpg" alt="Learning about Benford's Law"/></div><p>Looking at the <a id="id352" class="indexterm"/>balances, we can see that the amount stays in the 100s longer than it does in any other number (seven years). It only stays five years in the 200s. Finally, it stays in the 900s for only one year, at which point it rolls over, and the process starts all over again. Because there is less to work with and grow on, the lower the number (that is, in the 100s), the longer the graph will take to grow out of that range.</p><p>This pattern is common in any geometrically increasing amounts. Populations increase in this way, as do many other sequences.</p><p>However, concrete examples are always good. In this chapter, we'll work through several concrete examples. Then, we'll see what a failure of Benford's Law looks like, and finally, we'll look at an example of its use in life.</p><div class="section" title="Applying Benford's law to compound interest"><div class="titlepage"><div><div><h2 class="title"><a id="ch05lvl2sec31"/>Applying Benford's law to compound interest</h2></div></div></div><p>For the <a id="id353" class="indexterm"/>first illustration, let's keep working <a id="id354" class="indexterm"/>with the example we just started with.</p><p>There are good implementations of analyses using Benford's Law already in a number of libraries—we'll use<a id="id355" class="indexterm"/> <span class="strong"><strong>Incanter</strong></span> (<a class="ulink" href="http://incanter.org/">http://incanter.org/</a>) for the examples later in the chapter—but to better understand what's going on, we'll write our own implementation first. To get started, the project.clj file for this chapter is as follows:</p><div class="informalexample"><pre class="programlisting">(defproject benford "0.1.0-SNAPSHOT"
  :dependencies [[org.clojure/clojure "1.5.1"]
                 [org.clojure/data.csv "0.1.2"]
                 [incanter "1.5.2"]])</pre></div><p>The namespace declaration is as follows:</p><div class="informalexample"><pre class="programlisting">(ns benford.core
  (:require [clojure.string :as str]
            [clojure.java.io :as io]
            [clojure.pprint :as pp]
            [clojure.data.csv :as csv]
            [incanter.stats :as s]))</pre></div><p>First, we need a way to take a sequence of numbers and pull the first digit out of each. There are a <a id="id356" class="indexterm"/>couple of ways to do this. We <a id="id357" class="indexterm"/>could do this mathematically by repeatedly dividing by ten until the value is less than ten. At that point, we take the integer portion of the result.</p><p>However, we'll do something simpler for this. We'll convert the number to a string and use a simple regular expression to skip over any signs or prefixes and just take the first digit. We'll convert that single digit back into an integer as follows:</p><div class="informalexample"><pre class="programlisting">(defn first-digit [n]
  (Integer/parseInt (re-find #"\d" (str n))))</pre></div><p>Now, extracting the first digits for each item in a sequence of numbers becomes simple:</p><div class="informalexample"><pre class="programlisting">(defn first-digit-freq [coll]
  (frequencies (map first-digit coll)))</pre></div><p>Let's use these to pull the first digit from the yearly balances of the compound interest data, and we can graph them against the expected probabilities for Benford's Law.</p><p>The graph that is the result of this analysis is shown as follows. It looks at 25 years of accumulated interest, which is enough to go from 100 dollars to more than 1,000 dollars.</p><div class="mediaobject"><img src="graphics/4139OS_05_03.jpg" alt="Applying Benford's law to compound interest"/></div><p>This gives us an idea of just how close the number sequence is. However, while the bars appear to match the line, they don't quite match. Are they close enough? We need to apply a simple statistical test to find out the answer.</p><p>First, we'll <a id="id358" class="indexterm"/>need a function that computes<a id="id359" class="indexterm"/> the expected value for sequences that conform to Benford's Law. This will take a digit and return the expected proportion for the number of times that digit starts the sequence:</p><div class="informalexample"><pre class="programlisting">(defn benford [d]
  (Math/log10 (+ 1.0 (/ 1.0 (float d)))))</pre></div><p>We can use this to produce the full sequence of ratios for Benford's Law. We can see that the blue line in the preceding graph tracks the following  values:</p><div class="informalexample"><pre class="programlisting">user=&gt; (map benford (range 1 10))
(0.3010299956639812 0.17609125905568124 0.12493873660829993 0.09691001300805642 0.07918124604762482 0.06694678963061322 0.05799194697768673 0.05115252244738129 0.04575749056067514)</pre></div><p>Next, we'll need a statistical function to test whether the frequencies of digits in a sequence match these values or not. As this is categorical data, Pearson's <span class="strong"><strong>Χ<sup>2</sup></strong></span> (<span class="strong"><strong>chi-squared</strong></span>) test is commonly used to test for conformance with Benford's Law.</p><p>The formula for the Χ<sup>2</sup> test is simple. This uses <code class="literal">O</code> for the observed data and <code class="literal">E</code> for the expected data. <code class="literal">N</code> is the number of the categories of data. For example, numbers that begin with 1 are one category. In the case of testing against Benford's law, <code class="literal">N</code> will always be <code class="literal">9</code>.</p><p>The formula for an Χ<sup>2</sup> test looks like what is shown in the following figure:</p><p> </p><div class="mediaobject"><img src="graphics/4139OS_05_04.jpg" alt="Applying Benford's law to compound interest"/></div><p>
</p><p>This translates <a id="id360" class="indexterm"/>directly into Clojure. The <a id="id361" class="indexterm"/>only wrinkle here is that we need to compare the same quantities. This uses ratios for the expected values but raw frequencies for the observed data. So we take the total number of observations and scale the expected ratios to match it:</p><div class="informalexample"><pre class="programlisting">(defn x-sqr [expected-ratios observed]
  (let [total (sum observed)
        f (fn [e o]
            (let [n (- o e)]
              (/ (* n n) e)))]
    (sum (map f (map #(* % total) expected-ratios) observed))))</pre></div><p>We can tie together the Χ<sup>2</sup> function to the expected values from Benford's Law:</p><div class="informalexample"><pre class="programlisting">(defn benford-test [coll]
  (let [freqs (first-digit-freq coll)
        digits (range 1 10)]
    (x-sqr (map benford digits) (map freqs digits))))</pre></div><p>Let's see what kind of results it gives out:</p><div class="informalexample"><pre class="programlisting">user=&gt; (benford-test data)
1.7653767101950812</pre></div><p>What does this number mean? The way this test is set up, values close to zero indicate that the sequence conforms to Benford's Law.</p><p>The value we obtained here, <code class="literal">1.8</code>, is fairly close to zero, given the range of this function, so this looks good. However, we still need to know whether it's statistically significant or not. To find that, we need to find the <code class="literal">p-value</code> for this Χ<sup>2</sup>. There is the probability that this would happen by chance.</p><p>However, before we can find that information for an Χ<sup>2</sup> test, we have to know the degrees of freedom in our experiment. This is the number of variables that are free to vary. Generally, for Χ<sup>2</sup>, the degree of freedom is one less than the number of cells in the test, so for Benford's Law, the degrees of freedom will be eight.</p><p>We use<a id="id362" class="indexterm"/> this information to find the value's<a id="id363" class="indexterm"/> probability of occurring in a Χ<sup>2</sup> cumulative distribution. A cumulative distribution is the probability that a value<a id="id364" class="indexterm"/> or lesser value would occur. While a probability distribution gives the probability of x having a given value, a cumulative distribution gives the probability that x is less than or equal to that value. Incanter has a CDF for Χ<sup>2</sup> in <code class="literal">incanter.stats/cdf-chisq</code>. We can use this to find <code class="literal">p</code> for any output of the Χ<sup>2</sup> test:</p><div class="informalexample"><pre class="programlisting">user=&gt; (s/cdf-chisq 1.7653 :df 8 :lower-tail? false)
0.9873810658453659</pre></div><p>This is a very high p-value. We'd like it to be above 0.05; any value below that would indicate that this data did not follow Benford's law. (We'll get into the reasons for this in <a class="link" href="ch07.html" title="Chapter 7. Null Hypothesis Tests – Analyzing Crime Data">Chapter 7</a>, <span class="emphasis"><em>Null Hypothesis Tests – Analyzing Crime Data</em></span> when we discuss the null-hypothesis testing.) As it's higher, it's clear that this sequence of numbers tracks the predications of Benford's Law. There is no evidence of tampering here.</p></div><div class="section" title="Looking at the world population data"><div class="titlepage"><div><div><h2 class="title"><a id="ch05lvl2sec32"/>Looking at the world population data</h2></div></div></div><p>For the<a id="id365" class="indexterm"/> next example, let's look at the world population data. I downloaded<a id="id366" class="indexterm"/> this from <span class="strong"><strong>World DataBank</strong></span> (<a class="ulink" href="http://databank.worldbank.org/">http://databank.worldbank.org/</a>). To download it to your computer, use the following <a id="id367" class="indexterm"/>steps:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Navigate to the <span class="strong"><strong>World Development Indicators</strong></span> database.</li><li class="listitem">Select all countries.</li><li class="listitem">Select <span class="strong"><strong>Population (Total)</strong></span>.</li><li class="listitem">Select all years.</li><li class="listitem">Click on <span class="strong"><strong>Download</strong></span> and download the data as a CSV file.</li><li class="listitem">To make it easier to reference later, I moved and renamed this file <code class="literal">data/population.csv</code>.</li></ol></div><div class="mediaobject"><img src="graphics/4139OS_05_05.jpg" alt="Looking at the world population data"/></div><p>Now, let's<a id="id368" class="indexterm"/> read in this data. To make this easier, we'll write a <a id="id369" class="indexterm"/>function that reads in a CSV file, and from each row, create a map that uses the values from the header row as keys. The data for this looks like the following code snippet, which lists the header row and one data row:</p><div class="informalexample"><pre class="programlisting">Country Name,Country Code,Indicator Name,Indicator Code,1960 [YR1960],1961 [YR1961],1962 [YR1962],1963 [YR1963],1964 [YR1964],1965 [YR1965],1966 [YR1966],1967 [YR1967],1968 [YR1968],1969 [YR1969],1970 [YR1970],1971 [YR1971],1972 [YR1972],1973 [YR1973],1974 [YR1974],1975 [YR1975],1976 [YR1976],1977 [YR1977],1978 [YR1978],1979 [YR1979],1980 [YR1980],1981 [YR1981],1982 [YR1982],1983 [YR1983],1984 [YR1984],1985 [YR1985],1986 [YR1986],1987 [YR1987],1988 [YR1988],1989 [YR1989],1990 [YR1990],1991 [YR1991],1992 [YR1992],1993 [YR1993],1994 [YR1994],1995 [YR1995],1996 [YR1996],1997 [YR1997],1998 [YR1998],1999 [YR1999],2000 [YR2000],2001 [YR2001],2002 [YR2002],2003 [YR2003],2004 [YR2004],2005 [YR2005],2006 [YR2006],2007 [YR2007],2008 [YR2008],2009 [YR2009],2010 [YR2010],2011 [YR2011],2012 [YR2012],2013 [YR2013]

Afghanistan,AFG,Population (Total),SP.POP.TOTL,8774440,8953544,9141783,9339507,9547131,9765015,9990125,10221902,10465770,10729191,11015621,11323446,11644377,11966352,12273589,12551790,12806810,13034460,13199597,13257128,13180431,12963788,12634494,12241928,11854205,11528977,11262439,11063107,11013345,11215323,11731193,12612043,13811876,15175325,16485018,17586073,18415307,19021226,19496836,19987071,20595360,21347782,22202806,23116142,24018682,24860855,25631282,26349243,27032197,27708187,28397812,29105480,29824536,..</pre></div><p>The first function for this is <code class="literal">read-csv</code>:</p><div class="informalexample"><pre class="programlisting">(defn read-csv [filename]
  (with-open [f (io/reader filename)]
    (let [[row &amp; reader] (csv/read-csv f)
          header (map keyword
                      (map #(str/replace % \space \-) row))]
      (doall
        (map #(zipmap header %) reader)))))</pre></div><p>From this, we <a id="id370" class="indexterm"/>can create another function that reads in the population file and pulls out all the year columns and returns all the populations for all countries for all years in one long sequence:</p><div class="informalexample"><pre class="programlisting">(defn read-databank [filename]
  (let [year-keys (map keyword (map str (range 1960 2013)))]
    (-&gt;&gt; filename
      read-csv
      (mapcat #(map (fn [f] (f %)) year-keys))
      (remove empty?)
      (map #(Double/parseDouble %))
      (remove zero?))))</pre></div><p>One of the problems with the Χ<sup>2</sup> test is that it is very sensitive to the sample size. Small samples (less than 50) will almost always have a high <code class="literal">p-value</code>. Likewise, large samples incline toward low <code class="literal">p-values</code>. In general, samples between 100 and 2,500 observations are a good range, but even in this range, we can see some variance. It's easy to create a function that returns a random subset of a collection. The only problem with using it is that the value of the statistical tests is dependent on the nature of the sample returned. However, that is always the problem with samples:</p><div class="informalexample"><pre class="programlisting">(defn sample [coll k]
  (if (&lt;= (count coll) k)
    coll
    (let [coll-size (count coll)]
      (loop [seen #{}]
        (if (&gt;= (count seen) k)
          (map #(nth coll %) (sort seen))
          (recur (conj seen (rand-int coll-size))))))))</pre></div><p>Now we can put all of this together. For the last example, we used our own functions to perform the Benford's test and the Χ<sup>2</sup> on the output. This time, we'll use Incanter's function for this purpose from <code class="literal">incanter.stats</code>. This also looks up the p-value from the Χ<sup>2</sup> distribution, so it's a bit handier than doing it in two steps:</p><div class="informalexample"><pre class="programlisting">user=&gt; (def population (b/read-databank "data/population.csv"))
#'user/population
user=&gt; (def pop-test (s/benford-test (b/sample population 100)))
#'user/pop-test
user=&gt; (:X-sq pop-test)
7.926272852944953
user=&gt; (:p-value pop-test)
0.4407050181730324</pre></div><p>As the value of <span class="emphasis"><em>p</em></span> is greater than 0.05, this appears to conform to Benford's Law. Graphing this makes the p-Benford's Law relationship clearer. If anything, this seems a better fit than the preceding compounding interest data:</p><div class="mediaobject"><img src="graphics/4139OS_05_06.jpg" alt="Looking at the world population data"/></div><p>Again, it <a id="id371" class="indexterm"/>appears that this data also conforms to Benford's Law.</p></div></div></div>
<div class="section" title="Failing Benford's Law"><div class="titlepage"><div><div><h1 class="title"><a id="ch05lvl1sec35"/>Failing Benford's Law</h1></div></div></div><p>So far, we've<a id="id372" class="indexterm"/> seen several datasets, all of which conform to Benford's Law, most of them quite strongly. We haven't yet seen a dataset that does not conform to this distribution of initial digits. What would a failing dataset look like?</p><p>There are many ways in which we could get data that doesn't conform. Any linear data, for example, would have a more uniform distribution of the initial digits. However, we can also simulate fraudulent data easily, and in the process, we can learn just how much noise a dataset can handle before Benford's Law begins to have trouble with it.</p><p>We'll start this experiment with the population data that we looked at earlier. We'll progressively introduce more and more junk into the dataset. We'll randomly replace items in the dataset with a random value and re-run <code class="literal">incanter.stats/benford-test</code> on it. When it finally fails, we can note how many items we've replaced and how far off the new distribution is.</p><p>The primary function is shown as follows. There are a few utilities, and you can look into the code download for their definitions:</p><div class="informalexample"><pre class="programlisting">(defn make-fraudulent
  ([data] (make-fraudulent data 1 0.05 1000))
  ([data block sig-level k]
   (let [get-rand (make-rand-range-fn data)]
     (loop [v (vec (sample data k)), benford (s/benford-test v),
            n 0, ps [], swapped #{}]
       (println n \. (:p-value benford))
       (if (&lt; (:p-value benford) sig-level)
         {:n n, :benford benford, :data v, :p-history ps,
          :swapped swapped}
         (let [[new-v new-swapped]
               (swap-random
                 v swapped #(rand-int k) get-rand block)
               benford (s/benford-test new-v)]
           (recur new-v benford (inc n)
                  (conj ps (:p-value benford))
                  new-swapped)))))))</pre></div><p>This function is primarily a loop. At each step, it checks whether the <code class="literal">p-value</code> is low enough to declare the job as finished. If so, it returns the information it has collected so far.</p><p>If this isn't done, it swaps out <code class="literal">block</code> indexes, recomputes a new <code class="literal">p-value</code>, and stores the information it tracks.</p><p>This isn't a <a id="id373" class="indexterm"/>particularly efficient process. It is essentially a random walk over the data space. Sometimes, it actually improves the sequence's fit. However, because there's more space that isn't close to the probabilities that Benford's Law predicates for the digits, the values eventually wander off into areas with worse fit and lower <code class="literal">p-values</code>. The following is a graph from one run that began with a <code class="literal">p-value</code> around 0.05. Instead of immediately dropping below 0.05, it goes up to about 0.17 before finally and gradually, dropping below 0.05 around the iteration number 160.</p><div class="mediaobject"><img src="graphics/4139OS_05_08.jpg" alt="Failing Benford's Law"/></div><p>Looking at <a id="id374" class="indexterm"/>the final data from this process is also interesting. It's really not as different from the regular Benford's curve as you might expect it to be. It appears that the problem has too few twos and too many eights and nines.</p><div class="mediaobject"><img src="graphics/4139OS_05_09.jpg" alt="Failing Benford's Law"/></div></div>
<div class="section" title="Case studies"><div class="titlepage"><div><div><h1 class="title"><a id="ch05lvl1sec36"/>Case studies</h1></div></div></div><p>This has <a id="id375" class="indexterm"/>all been very interesting but not exactly useful. So, can<a id="id376" class="indexterm"/> Benford's Law be useful? The answer is <span class="emphasis"><em>yes</em></span>. In fact, analyses using Benford's Law is admissible in the United States courts. To get an idea for some uses of this analysis, let's take a look at a moderately well-publicized case where Benford's law was used.</p><p>The 2009 Iranian presidential election committee gathered analyses into whether the elections were fraudulent or not. Some of these used Benford's Law. One major article on this was <span class="emphasis"><em>A first-digit anomaly in the 2009 Iranian presidential election</em></span> by Boudewijn F. Roukema (<a class="ulink" href="http://arxiv.org/abs/0906.2789">http://arxiv.org/abs/0906.2789</a>). In this study, the author analyzes the first digit of <a id="id377" class="indexterm"/>vote counts in the election results publicized by the Iranian Ministry of the Interior on June 14, 2009. First, he analyzed first-round results for elections in immediately preceding years in other countries. This established a baseline or control to compare with. He also took into account the pre-election polls. This allowed him to establish the immediate political landscape in which the election was conducted.</p><p>Roukema then used a bootstrap to obtain a sample of the votes. In applying an analysis of the votes using Benford's Law, he found that there was a significant number of more vote counts beginning with the digit <span class="emphasis"><em>7</em></span> than could be predicated by Benford's Law. In fact, the frequency of <span class="emphasis"><em>7</em></span> was more in line with the frequency of the digit <span class="emphasis"><em>3</em></span>.</p><p>In another study of the 2009 Iranian elections, Walter R. Mebane, a forensics expert, used Benford's Law to analyze the first and second digits of the vote counts. Based particularly on the second digits, he also found evidence of fraud, especially in the counts of two of the candidates.</p><p>This seems like it should be clear-cut. However, several other people looked at this situation with varying degrees of thoroughness and failed to find anything. Several people wrote blog posts about doing cursory inspections of the data using Benford's Law, without finding evidence of any problems.</p><p>The Carter Center also questioned whether Benford's Law applied to election data at all, and in <span class="emphasis"><em>The Irrelevance of Benford's Law for Detecting Fraud in Elections</em></span>, Joseph Deckert, Mikhail Myagkov, and Peter C. Ordenshook looked at election data from Ohio, Massachusetts, and Ukraine as well as at simulations of elections and concluded that Benford's Law does not, in fact, indicate election fraud well. Deviations in the frequencies of first and second digits do not reliably indicate fraud, and actual fraud may push the distributions into more compliance with Benford's Law. Thus, for a number of reasons, Benford's Law may not work well with the election data.</p></div>
<div class="section" title="Summary"><div class="titlepage"><div><div><h1 class="title"><a id="ch05lvl1sec37"/>Summary</h1></div></div></div><p>In many ways, Benford's Law seems like the perfect test for fraud and other misdeeds. It's intriguing, simple, and computationally cheap. However, as we've seen, it's not always reliable; Χ<sup>2</sup> tests can be finicky, and as evidence, it doesn't stand on its own. It really needs to be buttressed by other data and helps to support cases of fraud.</p><p>However, it is a piece of evidence. It provides a distribution that is difficult to mimic, and it describes a wide class of number sequences accurately. In combination with other information and evidences, it can provide support in the cases of misdeed.</p><p>We've also learned about Χ<sup>2</sup> tests, a very useful statistical procedure. Although they are sensitive to the sample size, these tests still have a lot to offer and are highly recommended. They're cheap to perform., and they work well with the categorical data or data that counts a limited, fixed number possibilities, such as sex or color. When used with appropriate sample sizes, they're straightforward to interpret.</p><p>In the end, we're again reminded that working with data is messy. Having a wide range of tools and techniques that we can apply to our researches and questions is critical to being able to successfully track down the information and analyses that we need.</p><p>In the next chapter, we'll look at using sentiment analysis to find positive and negative hotel reviews automatically. This turns out to be a more problematic and a more interesting problem than you might suspect at first.</p></div></body></html>