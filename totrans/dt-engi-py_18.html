<html><head></head><body>
		<div><h1 id="_idParaDest-157"><em class="italic"><a id="_idTextAnchor159"/>Chapter 15</em>: Real-Time Edge Data with MiNiFi, Kafka, and Spark</h1>
			<p>In this chapter, you will learn how <strong class="bold">Internet-of-Things</strong> (<strong class="bold">IoT</strong>) devices, small computers, and sensors can send data into a data pipeline using Apache NiFi. For computers or devices with little processing power, MiNiFi allows them to be part of a NiFi data pipeline. MiNiFi is a lightweight version of NiFi with a stripped-down set of processors and no graphical user interface. It is built to send data using a data pipeline built into NiFi and deployed to the device.</p>
			<p>In this chapter, we're going to cover the following main topics:</p>
			<ul>
				<li>Setting up MiNiFi on a device</li>
				<li>Building and deploying a MiNiFi task in NiFi</li>
			</ul>
			<h1 id="_idParaDest-158"><a id="_idTextAnchor160"/>Setting up MiNiFi</h1>
			<p>Apache <a id="_idIndexMarker741"/>MiNiFi is a lightweight version of NiFi, to be used in data collection at the source. Increasingly, the source has become smaller IoT devices, sensors, and low-powered computers such as the Raspberry Pi. To incorporate these devices into your data pipelines, you need a way to get the data off the device. MiNiFi allows you to stream the data to NiFi as part of a standard data pipeline.</p>
			<p>To get the MiNiFi binary, browse to <a href="https://nifi.apache.org/minifi/">https://nifi.apache.org/minifi/</a>. The following screenshot is of the MiNiFi home page and will provide you with information and documentation for the project:</p>
			<div><div><img src="img/Figure_15.1_B15739.jpg" alt="Figure 15.1 – The Apache MiNiFi home page&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 15.1 – The Apache MiNiFi home page</p>
			<p>From the main navigation bar, go to <strong class="bold">Downloads</strong> and select the <strong class="bold">Download MiNiFi Components</strong> option. You <a id="_idIndexMarker742"/>will need to decide whether you want to run the MiNiFi Java or MiNiFi C++ version. Which version is appropriate will depend on the specifications of the device where MiNiFi will live. If you need the smallest footprint and memory usage, then the C++ version is for you. If you have more resources and need to have a wider selection of available processors, then the Java version is your best bet. You can find a list of processors by category, with descriptions at <a href="https://nifi.apache.org/docs/nifi-docs/html/getting-started.html#what-processors-are-available">https://nifi.apache.org/docs/nifi-docs/html/getting-started.html#what-processors-are-available</a>.</p>
			<p>You can always copy the <code>NAR</code> file for any processor in NiFi and put it in the MiNiFi <code>lib</code> directory. Some processors will require you to also copy and send the <code>NAR</code> file for the controller service. This chapter will use the MiNiFi Java version. </p>
			<p>Download the most current version of MiNiFi (Java), which is currently 0.5.0. Select the <code>minifi-0.5.0-bin.tar.gz</code> link and download it. You will also need to scroll further down the page and select the corresponding version of the MiNiFi toolkit binaries. Both the C++ and Java versions use the same toolkit, so you will only need to select the right release – 0.5.0. Download the <code>minifi-toolkit-0.5.0-bin.tar.gz</code> file.</p>
			<p>Extract and copy MiNiFi and the MiNiFi toolkit to your home directory using the following commands:</p>
			<pre>tar -xvzf minifi-0.5.0-bin.tar.gz
tar -xvzf minifi-toolkit-0.5.0-bin.tar.gz
mv minifi-0.5.0 ~/minifi
mv minifi-toolkit-0.5.0 ~/minifi-toolkit</pre>
			<p>I dropped <code>-0.5.0</code> when I moved <code>minifi</code> and <code>minifi-toolkit</code> to my home directory. In this chapter, I will run MiNiFi on the same machine as NiFi – as I have done with Kafka and Spark – but if you want to run MiNiFi on another device, as you would in production, copy <a id="_idIndexMarker743"/>the <code>minifi-0.5.0</code> directory to that machine. The MiNiFi toolkit stays on the NiFi machine.</p>
			<p>The last step is to set the <code>$MINIFI_HOME</code> variable to the location of MiNiFi. You can either export the variable and add it to your path, or the better way would be to edit your <code>.bashrc</code> file, as shown:</p>
			<pre>export MINIFI_HOME=/home/paulcrickard/minifi
export PATH=$MINIFI_HOME/bin:$PATH</pre>
			<p>Your <code>.bashrc</code> file will look as in the following screenshot. Notice that I have the edits from the previous chapter on Apache Spark just above the MiNiFi edits:</p>
			<div><div><img src="img/Figure_15.2_B15739.jpg" alt="Figure 15.2 – A .bashrc file with exports for Spark and MiNiFi&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 15.2 – A .bashrc file with exports for Spark and MiNiFi</p>
			<p>Now that you have <a id="_idIndexMarker744"/>MiNiFi configured and the MiNiFi toolkit ready to go, it is time to create your first data pipeline in Apache NiFi. The next section will walk you through creating one.</p>
			<h1 id="_idParaDest-159"><a id="_idTextAnchor161"/>Building a MiNiFi task in NiFi</h1>
			<p>In this section, you <a id="_idIndexMarker745"/>will build a data pipeline and deploy it to MiNiFi. The <a id="_idIndexMarker746"/>data pipeline will generate flow files and send them to NiFi. The next section will take this further and use a processor that is not included with MiNiFi.</p>
			<p>To use MiNiFi, you will need an older version of NiFi. The current tool – 0.5.0 – breaks because of changes to properties output from the <code>nifi</code> template. It will be fixed in 0.6.0, but until then, you will need to use at least version 1.9.0 of NiFi. You can get older NiFi versions at <a href="https://archive.apache.org/dist/nifi/1.9.0/">https://archive.apache.org/dist/nifi/1.9.0/</a>. Unzip NiFi using the <code>tar</code> command with the <code>-xvzf</code> flags. Place the folder in your home directory using <code>mv</code> or your file explorer tools.</p>
			<p>You will also need an older version of Java. To install the correct version of Java, use the following command:</p>
			<pre>sudo apt-get install openjdk-8-jre</pre>
			<p>Lastly, you will also need to make sure that NiFi is configured to allow site-to-site connections. In a terminal, go to <code>$NIFI_HOME/conf</code> and open the <code>nifi.properties</code> file. Scrolling about halfway down the file, you will see the <code>Site to Site properties</code> section. In my file, <code>nifi.remote.input.socket.port</code> is blank. If there is not a port specified, edit the file so that the port is <code>1026</code>, as shown in the following screenshot:</p>
			<div><div><img src="img/Figure_15.3_B15739.jpg" alt="Figure 15.3 – Site-to-site properties with input.socket.port set to 1026&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 15.3 – Site-to-site properties with input.socket.port set to 1026</p>
			<p>Next, start NiFi and<a id="_idIndexMarker747"/> create an input port to connect MiNiFi with NiFi. Drag <a id="_idIndexMarker748"/>and drop the input port to the canvas and name it <code>minifi</code>. Data from MiNiFi will enter NiFi through this port.</p>
			<p>Connect the input port to a data pipeline. The pipeline is shown in the following screenshot:</p>
			<div><div><img src="img/Figure_15.4_B15739.jpg" alt="Figure 15.4 – Data pipeline to consume MiNiFi data and write to file on the NiFi host&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 15.4 – Data pipeline to consume MiNiFi data and write to file on the NiFi host</p>
			<p>To build the<a id="_idIndexMarker749"/> data pipeline, take the following steps:</p>
			<ol>
				<li value="1">Drag and drop <a id="_idIndexMarker750"/>the <code>EvaluteJsonPath</code> processor to the canvas. Configure the <code>flowfile-attribute</code>. Create a new property named <code>fname</code> and set the value to <code>$.fname</code>. This will be in the JSON received from MiNiFi.</li>
				<li>Drag and drop the <code>UpdateAttribute</code> processor to the canvas. Create a new property named <code>filename</code> and set the value to <code>${fname}</code>.</li>
				<li>Drag and drop the <code>PutFile</code> processor to the canvas. Set the <code>/home/paulcrickard/output</code>. Leave the other properties as the defaults.</li>
			</ol>
			<p>The preceding steps create the connection from MiNiFi to NiFi, but right now, we do not have a data pipeline for MiNiFi. To create the MiNiFi data pipeline, drag and drop a processor group to the canvas and name it <code>minifitask</code>.</p>
			<p>Inside the processor group, drag and drop the <code>GenerateFlowfile</code> processor to the canvas. On the <code>30 sec</code>. Set the <code>{"fname":"minifi.txt","body":"Some text"}</code>.</p>
			<p>Next, you will <a id="_idIndexMarker751"/>add a <code>http://localhost:9300</code> and the <code>HTTP</code>. Leave the rest as the defaults, or blank. The settings should look as in the following screenshot:</p>
			<div><div><img src="img/Figure_15.5_B15739.jpg" alt="Figure 15.5 – Remote processor group configuration"/>
				</div>
			</div>
			<p class="figure-caption">Figure 15.5 – Remote processor group configuration</p>
			<p>Connect the <code>GenerateFlowFile</code> processor to <strong class="bold">Remote Processor Group</strong>. The <strong class="bold">Create Connection</strong> popup will allow you to select the input port as <strong class="bold">To Input</strong>. It would have guessed correctly and chosen MiNiFi. If not, use the dropdown to select the MiNiFi port you created in the previous steps. Once the processors are connected, right-click on <strong class="bold">Remote Processor Group</strong> and select <strong class="bold">Enable Transmission</strong>. The icon should now be a blue circle, as shown in the following screenshot:</p>
			<div><div><img src="img/Figure_15.6_B15739.jpg" alt="Figure 15.6 – MiNiFi data pipeline to a remote processor group&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 15.6 – MiNiFi data pipeline to a remote processor group</p>
			<p>The MiNiFi data<a id="_idIndexMarker753"/> pipeline is complete. To make sure it<a id="_idIndexMarker754"/> is runnable on MiNiFi, you need to transform it. To transform it, you will need to export it as a template. To create the template, exit the processor group. Right-click on the processor group, then select <code>minifitask</code> template by clicking the download icon to the right of the table. This will download an XML version of the data pipeline.</p>
			<p>To transform the template, you will run <code>config.sh</code> in the MiNiFi toolkit. I have made a <code>minifi-templates</code> folder in my home directory. Changing directories to <code>$MINIFI_HOME</code>, run the following command:</p>
			<pre>./bin/config.sh transform /home/paulcrickard/Downloads/minifitask.xml /home/paulcrickard/minifi-templates/config.yml</pre>
			<p>If<a id="_idIndexMarker755"/> everything worked properly, you should get a message like the one<a id="_idIndexMarker756"/> shown in the following screenshot:</p>
			<div><div><img src="img/Figure_15.7_B15739.jpg" alt="Figure 15.7 – minifi-toolkit transforming the XML template into a YML file&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 15.7 – minifi-toolkit transforming the XML template into a YML file</p>
			<p>You will now have a <code>config.yml</code> file in your <code>minifi-templates</code> directory. Copy this file to the <code>$MINIFI_HOME/conf</code> directory. You can overwrite the existing <code>config.yml</code> file that came with MiNiFi.</p>
			<p>From the <code>$MINIFI_HOME/bin</code> directory, you can start <code>minifi</code> and it will read your <code>config.yml</code> file when it does. Use the following command to start MiNiFi:</p>
			<pre>./minifi.sh start</pre>
			<p>Your MiNiFi data<a id="_idIndexMarker757"/> pipeline is now running. You can view the logs at <code>$MINIFI_HOME/logs/minifi-app.log</code>. But you can also now open NiFi and look <a id="_idIndexMarker758"/>at the data streaming in from MiNiFi through the <code>FromMinifi</code> input port. Your NiFi data pipeline should look as in the following screenshot:</p>
			<div><div><img src="img/Figure_15.8_B15739.jpg" alt="Figure 15.8 – The data pipeline receiving data on the input port from MiNiFi&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 15.8 – The data pipeline receiving data on the input port from MiNiFi</p>
			<p>You will notice that the processor group you used to create the template is stopped. The data is coming from MiNiFi into the NiFi instance and being processed and saved to the disk of the NiFi machine. The MiNiFi machine only sends data, which allows it to not be overwhelmed with trying to run a version of NiFi locally or to have to make remote connections to other machines to write out files at intervals. Streaming data can be sent from the MiNiFi machine to NiFi.</p>
			<p>Once the<a id="_idIndexMarker759"/> MiNiFi data is streaming into NiFi, you have the full range of<a id="_idIndexMarker760"/> tools available to you to process this data. You could send it to a Kafka topic, as shown in <a href="B15739_13_ePub_AM.xhtml#_idTextAnchor140"><em class="italic">Chapter 13</em></a>, <em class="italic">Streaming Data with Kafka</em>, and make it available to many other tools listening on the topic. MiNiFi opens up the possibility of capturing data from small devices.</p>
			<h1 id="_idParaDest-160"><a id="_idTextAnchor162"/>Summary</h1>
			<p>In this chapter, you learned how MiNiFi provides a means by which you can stream data to a NiFi instance. With MiNiFi, you can capture data from sensors, smaller devices such as a Raspberry Pi, or on regular servers where the data lives, without needing a full NiFi install. You learned how to set up and configure a remote processor group that allows you to talk to a remote NiFi instance.</p>
			<p>In the <a href="B15739_16_ePub_AM.xhtml#_idTextAnchor163"><em class="italic">Appendix</em></a>, you will learn how you can cluster NiFi to run your data pipelines on different machines so that you can further distribute the load. This will allow you to reserve servers for specific tasks, or to spread large amounts of data horizontally across the cluster. By combining NiFi, Kafka, and Spark into clusters, you will be able to process more data than any single machine.</p>
		</div>
	</body></html>