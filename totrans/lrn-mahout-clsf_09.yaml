- en: Chapter 9. Building an E-mail Classification System Using Apache Mahout
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 9 章：使用 Apache Mahout 构建电子邮件分类系统
- en: 'In this chapter, we will create a classifier system using Mahout. In order
    to build this system, we will cover the following topics:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用 Mahout 创建一个分类器系统。为了构建这个系统，我们将涵盖以下主题：
- en: Getting the dataset
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取数据集
- en: Preparation of the dataset
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据集准备
- en: Preparing the model
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准备模型
- en: Training the model
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练模型
- en: In this chapter, we will target the creation of two different classifiers. The
    first one will be an easy one because you can both create and test it on a pseudo-distributed
    Hadoop installation. For the second classifier, I will provide you with all the
    details, so you can run it using your fully distributed Hadoop installation. I
    will count the second one as a hands-on exercise for the readers of this book.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将针对创建两个不同的分类器。第一个将是一个简单的分类器，因为你可以在一个伪分布式 Hadoop 安装上创建和测试它。对于第二个分类器，我将提供所有细节，以便你可以使用你的完全分布式
    Hadoop 安装来运行它。我将把第二个分类器视为本书读者的实践练习。
- en: First of all, let's understand the problem statement for the first use case.
    Nowadays, in most of the e-mail systems, we see that e-mails are classified as
    spam or not spam. E-mails that are not spam are delivered directly into our inbox
    but spam e-mails are stored in a folder called `Spam`. Usually, based on a certain
    pattern such as message subject, sender's e-mail address, or certain keywords
    in the message body, we categorize an incoming e-mail as spam. We will create
    a classifier using Mahout, which will classify an e-mail into spam or not spam.
    We will use SpamAssassin, an Apache open source project dataset for this task.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们了解第一个用例的问题陈述。如今，在大多数电子邮件系统中，我们看到电子邮件被分类为垃圾邮件或非垃圾邮件。非垃圾邮件直接进入我们的收件箱，而垃圾邮件则存储在名为
    `Spam` 的文件夹中。通常，基于某些模式，如消息主题、发件人的电子邮件地址或消息体中的某些关键词，我们将 incoming 电子邮件分类为垃圾邮件。我们将使用
    Mahout 创建一个分类器，将电子邮件分类为垃圾邮件或非垃圾邮件。我们将使用 SpamAssassin，一个 Apache 开源项目数据集来完成这项任务。
- en: For the second use case, we will create a classifier, which can predict a group
    of incoming e-mails. As an open source project, there are lots of projects under
    the Apache software foundation, such as Apache Mahout, Apache Hadoop, Apache Solr,
    and so on. We will take the **Apache** **Software Foundation** (**ASF**) e-mail
    dataset and using this, we will create and train our model so that our model can
    predict a new incoming e-mail. So, based on certain features, we will be able
    to predict which group a new incoming e-mail belongs to.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第二个用例，我们将创建一个分类器，它可以预测一组 incoming 电子邮件。作为一个开源项目，Apache 软件基金会下有许多项目，例如 Apache
    Mahout、Apache Hadoop、Apache Solr 等。我们将使用 **Apache** **软件基金会** (**ASF**) 的电子邮件数据集，并使用这个数据集来创建和训练我们的模型，以便我们的模型可以预测新的
    incoming 电子邮件。因此，基于某些特征，我们将能够预测新 incoming 电子邮件属于哪个组。
- en: In Mahout's classification problem, we will have to identify a pattern in the
    dataset to help us predict the group of a new e-mail. We already have a dataset,
    which is separated by project names. We will use the ASF public e-mail archives
    dataset for this use case.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Mahout 的分类问题中，我们将在数据集中识别一个模式，以帮助我们预测新电子邮件的组别。我们已经有了一个数据集，它被项目名称分开。我们将使用 ASF
    公共电子邮件存档数据集来处理这个用例。
- en: 'Now, let''s consider our first use case: spam e-mail detection classifier.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们考虑我们的第一个用例：垃圾邮件检测分类器。
- en: Spam e-mail dataset
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 垃圾邮件数据集
- en: 'As I mentioned, we will be using the Apache SpamAssassin projects dataset.
    Apache SpamAssassin is an open source spam filter. Download `20021010_easy_ham.tar`
    and `20021010_spam.tar` from [http://spamassassin.apache.org/publiccorpus/](http://spamassassin.apache.org/publiccorpus/),
    as shown in the following screenshot:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我提到的，我们将使用 Apache SpamAssassin 项目数据集。Apache SpamAssassin 是一个开源的垃圾邮件过滤器。从 [http://spamassassin.apache.org/publiccorpus/](http://spamassassin.apache.org/publiccorpus/)
    下载 `20021010_easy_ham.tar` 和 `20021010_spam.tar`，如下截图所示：
- en: '![Spam e-mail dataset](img/4959OS_09_01.jpg)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![垃圾邮件数据集](img/4959OS_09_01.jpg)'
- en: Creating the model using the Assassin dataset
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Assassin 数据集创建模型
- en: 'We can create the model with the help of the following steps:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过以下步骤创建模型：
- en: 'Create a folder under `tmp` with the name `dataset`, and then click on the
    folder and unzip the datasets using the following command:'
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `tmp` 目录下创建一个名为 `dataset` 的文件夹，然后点击该文件夹，使用以下命令解压数据集：
- en: '[PRE0]'
  id: totrans-17
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This will create two folders under the `dataset` folder, `easy _ham` and `spam`,
    as shown in the following screenshot:'
  id: totrans-18
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将在 `dataset` 文件夹下创建两个文件夹，`easy _ham` 和 `spam`，如下截图所示：
- en: '![Creating the model using the Assassin dataset](img/4959OS_09_02.jpg)'
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![使用刺客数据集创建模型](img/4959OS_09_02.jpg)'
- en: 'Create a folder in `Hdfs` and move this dataset into Hadoop:'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`Hdfs`中创建一个文件夹并将此数据集移动到Hadoop中：
- en: '[PRE1]'
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Now our data preparation is done. We have downloaded the data and moved this
    data into `hdfs`. Let's move on to the next step.
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在我们已完成数据准备。我们已经下载了数据并将这些数据移动到`hdfs`中。让我们继续下一步。
- en: 'Convert this data into sequence files so that we can process it using Hadoop:'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将此数据转换为序列文件，以便我们可以使用Hadoop进行处理：
- en: '[PRE2]'
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![Creating the model using the Assassin dataset](img/4959OS_09_03.jpg)'
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![使用刺客数据集创建模型](img/4959OS_09_03.jpg)'
- en: 'Convert the `sequence` file into sparse vector (Mahout algorithms accept input
    in vector format, which is why we are converting the `sequence` file into sparse
    vector) by using the following command:'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令将`sequence`文件转换为稀疏向量（Mahout算法接受向量格式的输入，因此我们需要将`sequence`文件转换为稀疏向量）：
- en: '[PRE3]'
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![Creating the model using the Assassin dataset](img/4959OS_09_04.jpg)'
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![使用刺客数据集创建模型](img/4959OS_09_04.jpg)'
- en: 'The command in the preceding screenshot is explained as follows:'
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上一张截图中的命令解释如下：
- en: '`lnorm`: This command is used for output vector to be log normalized.'
  id: totrans-30
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lnorm`: 这个命令用于输出向量的对数归一化。'
- en: '`nv`: This command is used for named vector.'
  id: totrans-31
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nv`: 这个命令用于命名向量。'
- en: '`wt`: This command is used to identify the kind of weight to use. Here we use
    `tf-idf`.'
  id: totrans-32
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wt`: 这个命令用于确定要使用的权重类型。在这里我们使用`tf-idf`。'
- en: 'Split the set of vectors for training and testing the model, as follows:'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按以下方式拆分向量集以训练和测试模型：
- en: '[PRE4]'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The preceding command can be explained as follows:'
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上一条命令可以这样解释：
- en: The `randomSelectionPct` parameter divides the percentage of data into test
    and training datasets. In this case, it's 80 percent for test and 20 percent for
    training.
  id: totrans-36
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`randomSelectionPct` 参数将数据百分比分为测试集和训练集。在这种情况下，测试集为80%，训练集为20%。'
- en: The `xm` parameter specifies what portion of the `tf (tf-idf)` vectors is to
    be used expressed in times the standard deviation.
  id: totrans-37
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xm` 参数指定了要使用的`tf (tf-idf)`向量的部分，以标准差倍数表示。'
- en: The sigma symbol specifies the document frequencies of these vectors. It can
    be used to remove really high frequency terms. It is expressed as a double value.
    A good value to be specified is 3.0\. If the value is less than `0`, no vectors
    will be filtered out.
  id: totrans-38
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 符号σ指定了这些向量的文档频率。它可以用来移除真正高频的术语。它以双精度值表示。一个合适的值是3.0。如果值小于`0`，则不会过滤掉任何向量。
- en: '![Creating the model using the Assassin dataset](img/4959OS_09_05.jpg)'
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![使用刺客数据集创建模型](img/4959OS_09_05.jpg)'
- en: 'Now, train the model using the following command:'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用以下命令训练模型：
- en: '[PRE5]'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![Creating the model using the Assassin dataset](img/4959OS_09_06.jpg)'
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![使用刺客数据集创建模型](img/4959OS_09_06.jpg)'
- en: 'Now, test the model using the following command:'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用以下命令测试模型：
- en: '[PRE6]'
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![Creating the model using the Assassin dataset](img/4959OS_09_07.jpg)'
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![使用刺客数据集创建模型](img/4959OS_09_07.jpg)'
- en: You can see from the results that the output is displayed on the console. As
    per the matrix, the system has correctly classified 99.53 percent of the instances
    given.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从结果中看到，输出显示在控制台上。根据矩阵，系统正确分类了99.53%的实例。
- en: We can use this created model to classify new documents. To do this, we can
    either use a Java program or create a servlet that can be deployed on our server.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用这个创建的模型来对新文档进行分类。为此，我们可以使用Java程序或创建一个可以部署到我们服务器上的servlet。
- en: Let's take an example of a Java program in continuation of this exercise.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以这个练习的例子来分析一个Java程序。
- en: Program to use a classifier model
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用分类模型模型的程序
- en: We will create a Java program that will use our model to classify new e-mails.
    This program will take model, labelindex, dictionary-file, document frequency,
    and text file as input and will generate a score for the categories. The category
    will be decided based on the higher scores.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将创建一个Java程序，该程序将使用我们的模型来对新电子邮件进行分类。该程序将接受模型、标签索引、字典文件、文档频率和文本文件作为输入，并为类别生成分数。类别将根据较高的分数来决定。
- en: 'Let''s have a look at this program step by step:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们一步一步地看看这个程序：
- en: 'The `.jar` files required to make a compilation of this program are as follows:'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 制作此程序所需的`.jar`文件如下：
- en: '`Hadoop-core-x.y.x.jar`'
  id: totrans-53
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Hadoop-core-x.y.x.jar`'
- en: '`Mahout-core-xyz.jar`'
  id: totrans-54
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Mahout-core-xyz.jar`'
- en: '`Mahout-integration-xyz.jar`'
  id: totrans-55
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Mahout-integration-xyz.jar`'
- en: '`Mahout-math-xyz.jar`'
  id: totrans-56
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Mahout-math-xyz.jar`'
- en: The `import` statements are listed as follows. We are discussing this because
    there are lots of changes in the Mahout releases and people usually find it difficult
    to get the correct classes.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`import` 语句列表如下。我们讨论这个问题是因为 Mahout 的版本中有很多变化，人们通常发现很难找到正确的类。'
- en: '`import java.io.BufferedReader;`'
  id: totrans-58
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`import java.io.BufferedReader;`'
- en: '`import java.io.FileReader;`'
  id: totrans-59
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`import java.io.FileReader;`'
- en: '`import java.io.StringReader;`'
  id: totrans-60
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`import java.io.StringReader;`'
- en: '`import java.util.HashMap;`'
  id: totrans-61
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`import java.util.HashMap;`'
- en: '`import java.util.Map;`'
  id: totrans-62
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`import java.util.Map;`'
- en: '`import org.apache.hadoop.conf.Configuration;`'
  id: totrans-63
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`import org.apache.hadoop.conf.Configuration;`'
- en: '`import org.apache.hadoop.fs.Path;`'
  id: totrans-64
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`import org.apache.hadoop.fs.Path;`'
- en: '`import org.apache.lucene.analysis.Analyzer;`'
  id: totrans-65
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`import org.apache.lucene.analysis.Analyzer;`'
- en: '`import org.apache.lucene.analysis.TokenStream;`'
  id: totrans-66
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`import org.apache.lucene.analysis.TokenStream;`'
- en: '`import org.apache.lucene.analysis.standard.StandardAnalyzer;`'
  id: totrans-67
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`import org.apache.lucene.analysis.standard.StandardAnalyzer;`'
- en: '`import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;`'
  id: totrans-68
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;`'
- en: '`import org.apache.lucene.util.Version;`'
  id: totrans-69
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`import org.apache.lucene.util.Version;`'
- en: '`import org.apache.mahout.classifier.naivebayes.BayesUtils;`'
  id: totrans-70
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`import org.apache.mahout.classifier.naivebayes.BayesUtils;`'
- en: '`import org.apache.mahout.classifier.naivebayes.NaiveBayesModel;`'
  id: totrans-71
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`import org.apache.mahout.classifier.naivebayes.NaiveBayesModel;`'
- en: '`import org.apache.mahout.classifier.naivebayes.StandardNaiveBayesClassifier;`'
  id: totrans-72
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`import org.apache.mahout.classifier.naivebayes.StandardNaiveBayesClassifier;`'
- en: '`import org.apache.mahout.common.Pair;`'
  id: totrans-73
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`import org.apache.mahout.common.Pair;`'
- en: '`import org.apache.mahout.common.iterator.sequencefile.SequenceFileIterable;`'
  id: totrans-74
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`import org.apache.mahout.common.iterator.sequencefile.SequenceFileIterable;`'
- en: '`import org.apache.mahout.math.RandomAccessSparseVector;`'
  id: totrans-75
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`import org.apache.mahout.math.RandomAccessSparseVector;`'
- en: '`import org.apache.mahout.math.Vector;`'
  id: totrans-76
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`import org.apache.mahout.math.Vector;`'
- en: '`import org.apache.mahout.math.Vector.Element;`'
  id: totrans-77
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`import org.apache.mahout.math.Vector.Element;`'
- en: '`import org.apache.mahout.vectorizer.TFIDF;`'
  id: totrans-78
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`import org.apache.mahout.vectorizer.TFIDF;`'
- en: '`import org.apache.hadoop.io.*;`'
  id: totrans-79
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`import org.apache.hadoop.io.*;`'
- en: '`import com.google.common.collect.ConcurrentHashMultiset;`'
  id: totrans-80
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`import com.google.common.collect.ConcurrentHashMultiset;`'
- en: '`import com.google.common.collect.Multiset;`'
  id: totrans-81
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`import com.google.common.collect.Multiset;`'
- en: 'The supporting methods to read the dictionary are as follows:'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 读取字典的支持方法如下：
- en: '[PRE7]'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The supporting methods to read the document frequency are as follows:'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 读取文档频率的支持方法如下：
- en: '[PRE8]'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The first part of the `main` method is used to perform the following actions:'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`main` 方法的第一部分用于执行以下操作：'
- en: Getting the input
  id: totrans-87
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取输入
- en: Loading the model
  id: totrans-88
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加载模型
- en: Initializing `StandardNaiveBayesClassifier` using our created model
  id: totrans-89
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用我们创建的模型初始化 `StandardNaiveBayesClassifier`
- en: Reading `labelindex`, document frequency, and dictionary created while creating
    the vector from the dataset
  id: totrans-90
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 读取在创建向量时从数据集创建的 `labelindex`、文档频率和字典
- en: 'The following code can be used for the preceding actions:'
  id: totrans-91
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下代码可用于执行前面的操作：
- en: '[PRE9]'
  id: totrans-92
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The second part of the `main` method is used to extract words from the e-mail:'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`main` 方法的第二部分用于从电子邮件中提取单词：'
- en: '[PRE10]'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The third part of the `main` method is used to create vector of the `id` word
    and the `tf-idf` weights:'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`main` 方法的第三部分用于创建 `id` 单词的向量和 `tf-idf` 权重：'
- en: '[PRE11]'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'In the fourth part of the `main` method, with `classifier`, we get the score
    for each label and assign the e-mail to the higher scored label:'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 `main` 方法的第四部分，使用 `classifier` 获取每个标签的分数，并将电子邮件分配给得分较高的标签：
- en: '[PRE12]'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Now, put all these codes under one class and create the `.jar` file of this
    class. We will use this `.jar` file to test our new e-mails.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，将这些代码放在一个类中，并创建这个类的 `.jar` 文件。我们将使用这个 `.jar` 文件来测试我们新的电子邮件。
- en: Testing the program
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测试程序
- en: 'To test the program, perform the following steps:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 要测试程序，请执行以下步骤：
- en: 'Create a folder named `assassinmodeltest` in the local directory, as follows:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在本地目录中创建一个名为 `assassinmodeltest` 的文件夹，如下所示：
- en: '[PRE13]'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'To use this model, get the following files from `hdfs` to `/tmp/assassinmodeltest`:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要使用此模型，从 `hdfs` 获取以下文件到 `/tmp/assassinmodeltest`：
- en: 'For the earlier created model, use the following command:'
  id: totrans-105
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于之前创建的模型，使用以下命令：
- en: '[PRE14]'
  id: totrans-106
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'For `labelindex`, use the following command:'
  id: totrans-107
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于 `labelindex`，使用以下命令：
- en: '[PRE15]'
  id: totrans-108
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'For `df-counts` from the `assassinvec` folder (change the name of the `part-00000`
    file to `df-count`), use the following commands:'
  id: totrans-109
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于 `assassinvec` 文件夹中的 `df-counts`（将 `part-00000` 文件名更改为 `df-count`），使用以下命令：
- en: '[PRE16]'
  id: totrans-110
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Under `/tmp/assassinmodeltest`, create a file with the message shown in the
    following screenshot:![Testing the program](img/4959OS_09_08.jpg)
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `/tmp/assassinmodeltest` 目录下创建一个文件，其内容如以下截图所示：![测试程序](img/4959OS_09_08.jpg)
- en: 'Now, run the program using the following command:'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用以下命令运行程序：
- en: '[PRE17]'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '![Testing the program](img/4959OS_09_09.jpg)'
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![测试程序](img/4959OS_09_09.jpg)'
- en: Now, update the `test` e-mail file with the message shown in the following screenshot:![Testing
    the program](img/4959OS_09_10.jpg)
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，更新`test`电子邮件文件，使用以下截图中的消息：![测试程序](img/4959OS_09_10.jpg)
- en: Run the program again using the same command as given in step 4 and view the
    result as follows:![Testing the program](img/4959OS_09_11.jpg)
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再次使用步骤4中给出的相同命令运行程序，并查看以下结果：![测试程序](img/4959OS_09_11.jpg)
- en: Now, we have a program ready that can use our classifier model and predict the
    unknown items. Let's move on to our second use case.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们有一个程序可以用来使用我们的分类器模型并预测未知项。让我们继续我们的第二个用例。
- en: Second use case as an exercise
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 作为练习的第二个用例
- en: As discussed at the start of this chapter, we will now work on a second use
    case, where we will predict the category of a new e-mail.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 如本章开头所述，我们现在将处理第二个用例，在这个用例中，我们将预测一封新电子邮件的类别。
- en: The ASF e-mail dataset
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ASF电子邮件数据集
- en: The Apache Software Foundation e-mail dataset is partitioned by project. This
    e-mail dataset can be found at [http://aws.amazon.com/datasets/7791434387204566](http://aws.amazon.com/datasets/7791434387204566).
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: Apache软件基金会电子邮件数据集按项目分区。此电子邮件数据集可在[http://aws.amazon.com/datasets/7791434387204566](http://aws.amazon.com/datasets/7791434387204566)找到。
- en: '![The ASF e-mail dataset](img/4959OS_09_12.jpg)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![ASF电子邮件数据集](img/4959OS_09_12.jpg)'
- en: 'A smaller dataset can be found at [http://files.grantingersoll.com/ibm.tar.gz](http://files.grantingersoll.com/ibm.tar.gz).
    (Refer to [http://lucidworks.com/blog/scaling-mahout/](http://lucidworks.com/blog/scaling-mahout/)).
    Use this data to perform the following steps:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 可以在[http://files.grantingersoll.com/ibm.tar.gz](http://files.grantingersoll.com/ibm.tar.gz)找到较小的数据集。（参考[http://lucidworks.com/blog/scaling-mahout/](http://lucidworks.com/blog/scaling-mahout/)）。使用这些数据执行以下步骤：
- en: 'Move this data to the folder of your choice (`/tmp/asfmail`) and unzip the
    folder:'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将这些数据移动到您选择的文件夹（`/tmp/asfmail`）并解压文件夹：
- en: '[PRE18]'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Move the dataset to `hdfs`:'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据集移动到`hdfs`：
- en: '[PRE19]'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Convert the `mbox` files into Hadoop''s `SequenceFile` format using Mahout''s
    `SequenceFilesFromMailArchives` as follows:'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用Mahout的`SequenceFilesFromMailArchives`将`mbox`文件转换为Hadoop的`SequenceFile`格式，如下所示：
- en: '[PRE20]'
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '![The ASF e-mail dataset](img/4959OS_09_13.jpg)'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![ASF电子邮件数据集](img/4959OS_09_13.jpg)'
- en: 'Convert the `sequence` file into sparse vector:'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`sequence`文件转换为稀疏向量：
- en: '[PRE21]'
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '![The ASF e-mail dataset](img/4959OS_09_14.jpg)'
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![ASF电子邮件数据集](img/4959OS_09_14.jpg)'
- en: 'Modify the labels:'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 修改标签：
- en: '[PRE22]'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Now, the next three steps are similar to the ones we performed earlier:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，接下来的三个步骤与我们之前执行的操作类似：
- en: 'Split the dataset into `training` and `test` datasets using the following command:'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令将数据集拆分为`training`和`test`数据集：
- en: '[PRE23]'
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Train the model using the `training` dataset as follows:'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下方式使用`training`数据集训练模型：
- en: '[PRE24]'
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Test the model using the `test` dataset:'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`test`数据集测试模型：
- en: '[PRE25]'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: As you may have noticed, all the steps are exactly identical to the ones we
    performed earlier. Hereby, I leave this topic as an exercise for you to create
    your own classifier system using this model. You can use hints as provided for
    the spam filter classifier. We now move our discussion to tuning our classifier.
    Let's take a brief overview of the best practices in this area.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 如您可能已经注意到的，所有步骤都与我们之前执行的操作完全相同。因此，我将这个主题留作练习，让您使用此模型创建自己的分类器系统。您可以使用提供的提示来创建垃圾邮件过滤器分类器。我们现在将讨论调整我们的分类器。让我们简要概述一下该领域的最佳实践。
- en: Classifiers tuning
  id: totrans-144
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分类器调整
- en: We already discussed classifiers' evaluation techniques in [Chapter 1](ch01.html
    "Chapter 1. Classification in Data Analysis"), *Classification in Data Analysis*.
    Just as a reminder, we evaluate our model using techniques such as confusion matrix,
    entropy matrix, area under curve, and so on.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经在[第1章](ch01.html "第1章。数据分析中的分类") *数据分析中的分类* 中讨论了分类器的评估技术。仅作为提醒，我们使用混淆矩阵、熵矩阵、曲线下面积等技术来评估我们的模型。
- en: 'From the explanatory variables, we create the feature vector. To check how
    a particular model is working, these feature vectors need to be investigated.
    In Mahout, there is a class available for this, `ModelDissector`. It takes the
    following three inputs:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 从解释变量中，我们创建特征向量。为了检查特定模型的工作情况，这些特征向量需要被调查。在Mahout中，有一个用于此目的的类，`ModelDissector`。它需要以下三个输入：
- en: '**Features**: This class takes a feature vector to use (destructively)'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特征**：这个类接受一个要使用的特征向量（破坏性）'
- en: '**TraceDictionary**: This class takes a trace dictionary containing variables
    and the locations in the feature vector that are affected by them'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**TraceDictionary**：这个类接受一个包含变量及其在特征向量中受影响的位置的跟踪字典'
- en: '**Learner**: This class takes the model that we are probing to find weights
    on features'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**学习者**：这个课程采用我们正在探查的模型来寻找特征权重'
- en: '`ModelDissector` tweaks the feature vector and observes how the model output
    changes. By taking an average of the number of examples, we can determine the
    effect of different explanatory variables.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '`ModelDissector` 调整特征向量并观察模型输出的变化。通过取示例数量的平均值，我们可以确定不同解释变量的影响。'
- en: '`ModelDissector` has a summary method, which returns the most important features
    with their weights, most important category, and the top few categories that they
    affect.'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '`ModelDissector` 有一个摘要方法，它返回最重要的特征及其权重、最重要的类别以及它们影响的几个顶级类别。'
- en: The output of `ModelDissector` is helpful in troubleshooting problems in a wrongly
    created model.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '`ModelDissector` 的输出有助于解决错误创建的模型中的问题。'
- en: More details for the code can be found at [https://github.com/apache/mahout/blob/master/mrlegacy/src/main/java/org/apache/mahout/classifier/sgd/ModelDissector.java](https://github.com/apache/mahout/blob/master/mrlegacy/src/main/java/org/apache/mahout/classifier/sgd/ModelDissector.java).
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 有关代码的更多细节可以在[https://github.com/apache/mahout/blob/master/mrlegacy/src/main/java/org/apache/mahout/classifier/sgd/ModelDissector.java](https://github.com/apache/mahout/blob/master/mrlegacy/src/main/java/org/apache/mahout/classifier/sgd/ModelDissector.java)找到。
- en: 'While improving the output of the classifier, one should take care with two
    commonly occurring problems: target leak, and broken feature extraction.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在提高分类器输出时，应该注意两个常见问题：目标泄露和损坏的特征提取。
- en: If the model is showing results that are too good to be true or an output beyond
    expectations, we could have a problem with target leak. This error comes once
    information from the target variable is included in the explanatory variables,
    which are used to train the classifier. In this instance, the classifier will
    work too well for the `test` dataset.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 如果模型显示的结果太好以至于不真实或超出预期，我们可能存在目标泄露问题。这种错误发生在目标变量的信息被包含在用于训练分类器的解释变量中时。在这种情况下，分类器对
    `test` 数据集的表现会太好。
- en: On the other hand, broken feature extraction occurs when feature extraction
    is broken. This type of classifier shows the opposite result from the target leak
    classifiers. Here, the model provides results poorer than expected.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，当特征提取失败时，会发生损坏的特征提取。这种类型的分类器会显示与目标泄露分类器相反的结果。在这里，模型提供的结果比预期更差。
- en: To tune the classifier, we can use new explanatory variables, transformations
    of explanatory variables, and can also eliminate some of the variables. We should
    also try different learning algorithms to create the model and choose an algorithm,
    which is good in performance, training time, and speed.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 要调整分类器，我们可以使用新的解释变量、解释变量的变换，也可以消除一些变量。我们还应该尝试不同的学习算法来创建模型，并选择一个在性能、训练时间和速度方面都好的算法。
- en: More details on tuning can be found in Chapter 16, *Deploying a classifier*
    in the book *Mahout in Action*.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 更多关于调整的细节可以在《Mahout in Action》一书的第16章“部署分类器”中找到。
- en: Summary
  id: totrans-159
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we discussed creating our own production ready classifier model.
    We took up two use cases here, one for an e-mail spam filter and the other for
    classifying the e-mail as per the projects. We used datasets for Apache SpamAssassin
    for the e-mail filter and ASF for the e-mail classifier.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了创建我们自己的生产就绪分类器模型。我们在这里提出了两个用例，一个是电子邮件垃圾邮件过滤器，另一个是根据项目对电子邮件进行分类。我们使用了Apache
    SpamAssassin的数据集用于电子邮件过滤器，以及ASF用于电子邮件分类器。
- en: We also saw how to increase the performance of your model.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还看到了如何提高模型性能的方法。
- en: So you are now ready to implement classifiers using Apache Mahout for your own
    real world use cases. Happy learning!
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，你现在可以准备好使用Apache Mahout实现分类器，用于你自己的实际用例。祝学习愉快！
