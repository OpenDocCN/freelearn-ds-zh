["```py\n!apt-get update !apt-get install -y default-jdk\n!pip install tabula-py xlrd lxml\n```", "```py\n    import numpy as np\n    import pandas as pd\n    df1 = pd.read_csv(\"CSV_EX_1.csv\")\n    df1\n    ```", "```py\n    df2 = pd.read_csv(\"CSV_EX_2.csv\")\n    df2\n    ```", "```py\n    df2 = pd.read_csv(\"CSV_EX_2.csv\",header=None)\n    df2\n    ```", "```py\n    df2 = pd.read_csv(\"CSV_EX_2.csv\",header=None, names=['Bedroom','Sq.ft','Locality','Price($)'])\n    df2\n    ```", "```py\n    df3 = pd.read_csv(\"CSV_EX_3.csv\")\n    df3\n    ```", "```py\n    df3 = pd.read_csv(\"CSV_EX_3.csv\",sep=';')\n    df3\n    ```", "```py\n    df4 = pd.read_csv(\"CSV_EX_1.csv\",names=['A','B','C','D'])\n    df4\n    ```", "```py\n    df4 = pd.read_csv(\"CSV_EX_1.csv\",header=0,names=['A','B','C','D'])\n    df4\n    ```", "```py\n    df5 = pd.read_csv(\"CSV_EX_skiprows.csv\")\n    df5\n    ```", "```py\n    df5 = pd.read_csv(\"CSV_EX_skiprows.csv\",skiprows=2)\n    df5\n    ```", "```py\n    df6 = pd.read_csv(\"CSV_EX_skipfooter.csv\",skiprows=2,\n    skipfooter=1,engine='python')\n    df6\n    ```", "```py\ndf7 = pd.read_csv(\"CSV_EX_1.csv\",nrows=2)\ndf7\n```", "```py\n    list_of_dataframe = []\n    ```", "```py\n    rows_in_a_chunk = 10\n    ```", "```py\n    num_chunks = 5\n    ```", "```py\n    df_dummy = pd.read_csv(\"Boston_housing.csv\",nrows=2)\n    colnames = df_dummy.columns\n    ```", "```py\n    for i in range(0,num_chunks*rows_in_a_chunk,rows_in_a_chunk):\n        df = pd.read_csv(\"Boston_housing.csv\",header=0,skiprows=i,nrows=rows_in_a_chunk,names=colnames)\n        list_of_dataframe.append(df)\n    ```", "```py\ndf9 = pd.read_csv(\"CSV_EX_blankline.csv\",skip_blank_lines=False)\ndf9\n```", "```py\ndf10 = pd.read_csv('CSV_EX_1.zip')\ndf10\n```", "```py\ndf11_1 = pd.read_excel(\"Housing_data.xlsx\",sheet_name='Data_Tab_1')\ndf11_2 = pd.read_excel(\"Housing_data.xlsx\",sheet_name='Data_Tab_2')\ndf11_3 = pd.read_excel(\"Housing_data.xlsx\",sheet_name='Data_Tab_3')\n```", "```py\ndict_df = pd.read_excel(\"Housing_data.xlsx\",sheet_name=None)\ndict_df.keys()\n```", "```py\nodict_keys(['Data_Tab_1', 'Data_Tab_2', 'Data_Tab_3'])\n```", "```py\n    df13 = pd.read_table(\"Table_EX_1.txt\")\n    df13\n    ```", "```py\n    df13 = pd.read_table(\"Table_EX_1.txt\",sep=',')\n    df13\n    ```", "```py\nurl = 'http://www.fdic.gov/bank/individual/failed/banklist.html'\nlist_of_df = pd.read_html(url)\ndf14 = list_of_df[0]\ndf14.head()\n```", "```py\n    list_of_df = pd.read_html(\"https://en.wikipedia.org/wiki/2016_Summer_Olympics_medal_table\",header=0)\n    ```", "```py\n    len(list_of_df)\n    ```", "```py\n     6\n    ```", "```py\n    for t in list_of_df:\n        print(t.shape)\n    ```", "```py\n    df15=list_of_df[1]\n    df15.head()\n    ```", "```py\n    df16 = pd.read_json(\"movies.json\")\n    df16.head()\n    ```", "```py\n    cast_of_avengers=df16[(df16['title']==\"The Avengers\") & (df16['year']==2012)]['cast']\n    print(list(cast_of_avengers))\n    ```", "```py\n     [['Robert Downey, Jr.', 'Chris Evans', 'Mark Ruffalo', 'Chris Hemsworth', 'Scarlett Johansson', 'Jeremy Renner', 'Tom Hiddleston', 'Clark Gregg', 'Cobie Smulders', 'Stellan Skarsg√Éyrd', 'Samuel L. Jackson']]\n    ```", "```py\ndf17 = pd.read_stata(\"wu-data.dta\")\n```", "```py\n    from tabula import read_pdf\n    df18_1 = read_pdf('Housing_data.pdf',pages=[1],pandas_options={'header':None})\n    df18_1\n    ```", "```py\n    df18_2 = read_pdf('Housing_data.pdf',pages=[2],pandas_options={'header':None})\n    df18_2\n    ```", "```py\n    df18=pd.concat([df18_1,df18_2],axis=1)\n    df18\n    ```", "```py\n    names=['CRIM','ZN','INDUS','CHAS','NOX','RM','AGE','DIS','RAD','TAX','PTRATIO','B','LSTAT','PRICE']\n    df18_1 = read_pdf('Housing_data.pdf',pages=[1],pandas_options={'header':None,'names':names[:10]})\n    df18_2 = read_pdf('Housing_data.pdf',pages=[2],pandas_options={'header':None,'names':names[10:]})\n    df18=pd.concat([df18_1,df18_2],axis=1)\n    df18\n    ```", "```py\n    from bs4 import BeautifulSoup\n    ```", "```py\n    with open(\"test.html\", \"r\") as fd:    soup = BeautifulSoup(fd)    print(type(soup))\n    ```", "```py\n    <class 'bs4.BeautifulSoup'>\n    ```", "```py\n    print(soup.prettify())\n    ```", "```py\n    with open(\"test.html\", \"r\") as fd:\n        soup = BeautifulSoup(fd)\n        print(soup.p)\n    ```", "```py\n    with open(\"test.html\", \"r\") as fd:\n        soup = BeautifulSoup(fd)\n        all_ps = soup.find_all('p')\n        print(\"Total number of <p>  --- {}\".format(len(all_ps)))\n    ```", "```py\n    Total number of <p>  --- 6\n    ```", "```py\n    with open(\"test.html\", \"r\") as fd:\n        soup = BeautifulSoup(fd)\n        table = soup.table\n        print(table.contents)\n    ```", "```py\n    with open(\"test.html\", \"r\") as fd:\n        soup = BeautifulSoup(fd)\n        table = soup.table\n        for child in table.children:\n            print(child)\n            print(\"*****\")\n    ```", "```py\n    with open(\"test.html\", \"r\") as fd:\n        soup = BeautifulSoup(fd)\n        table = soup.table\n        children = table.children\n        des = table.descendants\n        print(len(list(children)), len(list(des)))\n    ```", "```py\n    9 61\n    ```", "```py\n    import pandas as pd\n    fd = open(\"test.html\", \"r\")\n    soup = BeautifulSoup(fd)\n    data = soup.findAll('tr')\n    print(\"Data is a {} and {} items long\".format(type(data), len(data)))\n    ```", "```py\n    Data is a <class 'bs4.element.ResultSet'> and 4 items long\n    ```", "```py\n    data_without_header = data[1:]\n    headers = data[0]\n    header\n    ```", "```py\n    <tr>\n    <th>Entry Header 1</th>\n    <th>Entry Header 2</th>\n    <th>Entry Header 3</th>\n    <th>Entry Header 4</th>\n    </tr>\n    ```", "```py\n    col_headers = [th.getText() for th in headers.findAll('th')]\n    col_headers\n    ```", "```py\n    ['Entry Header 1', 'Entry Header 2', 'Entry Header 3', 'Entry Header 4']\n    ```", "```py\n    df_data = [[td.getText() for td in tr.findAll('td')] for tr in data_without_header]\n    df_data\n    ```", "```py\n    df = pd.DataFrame(df_data, columns=col_headers)\n    df.head()\n    ```", "```py\n    !pip install openpyxl\n    ```", "```py\n    writer = pd.ExcelWriter('test_output.xlsx')df.to_excel(writer, \"Sheet1\")writer.save()\n    writer\n    ```", "```py\n    <pandas.io.excel._XlsxWriter at 0x24feb2939b0>\n    ```", "```py\n    d = open(\"test.html\", \"r\")\n    soup = BeautifulSoup(fd)\n    lis = soup.find('ul').findAll('li')\n    stack = []\n    for li in lis:    a = li.find('a', href=True)\n    ```", "```py\n    stack.append(a['href'])\n    ```"]