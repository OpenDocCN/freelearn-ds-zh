<html><head></head><body>
<div id="sbo-rt-content"><div id="_idContainer086">
<h1 class="chapter-number" id="_idParaDest-108"><a id="_idTextAnchor108"/>3</h1>
<h1 id="_idParaDest-109"><a id="_idTextAnchor109"/>Data Discovery – Understanding Our Data before Ingesting It</h1>
<p>As you may already have noticed, <strong class="bold">data ingestion</strong> is not just retrieving data from a source and inserting it in another place. It involves understanding some business concepts, secure access to the data, and how to store it, and now it is essential to discover <span class="No-Break">our data.</span></p>
<p><strong class="bold">Data discovery</strong> is the process of understanding our data’s patterns and behaviors, ensuring the whole <a id="_idIndexMarker239"/>data pipeline will be successful. In this process, we will understand how our data is modeled and used, so we can set up and plan our ingestion using the <span class="No-Break">best fit.</span></p>
<p>In this chapter, you will learn about <span class="No-Break">the following:</span></p>
<ul>
<li>Documenting the data <span class="No-Break">discovery process</span></li>
<li><span class="No-Break">Configuring OpenMetadata</span></li>
<li>Connecting OpenMetadata to <span class="No-Break">our database</span></li>
</ul>
<h1 id="_idParaDest-110"><a id="_idTextAnchor110"/>Technical requirements</h1>
<p>You can also find the code from this chapter in its GitHub repository <span class="No-Break">here: </span><a href="https://github.com/PacktPublishing/Data-Ingestion-with-Python-Cookbook"><span class="No-Break">https://github.com/PacktPublishing/Data-Ingestion-with-Python-Cookbook</span></a><span class="No-Break">.</span></p>
<h1 id="_idParaDest-111"><a id="_idTextAnchor111"/>Documenting the data discovery process</h1>
<p>In recent years, manual <a id="_idIndexMarker240"/>data discovery has been rapidly deprecated, giving rise to <strong class="bold">machine learning</strong> and other automated solutions, bringing fast insights into data in storage or online <a id="_idIndexMarker241"/>spreadsheets, such as <span class="No-Break">Google Sheets.</span></p>
<p>Nevertheless, many small companies are just starting out their businesses or data areas, so implementing a paid or cost-related solution might not be a good idea right away. As data professionals, we also need to be malleable when applying the first solution to a problem – there will always be space to improve <span class="No-Break">it later.</span></p>
<h2 id="_idParaDest-112"><a id="_idTextAnchor112"/>Getting ready</h2>
<p>This recipe will cover the steps to start the data discovery process effectively. Even though, here, the process is more related to the manual discovery steps, you will see it also applies to the <span class="No-Break">automated ones.</span></p>
<p>Let’s start by downloading <span class="No-Break">the datasets.</span></p>
<p>For this recipe, we are going to use the <em class="italic">The evolution of genes in viruses and bacteria</em> dataset (<a href="https://www.kaggle.com/datasets/thedevastator/the-evolution-of-genes-in-viruses-and-bacteria">https://www.kaggle.com/datasets/thedevastator/the-evolution-of-genes-in-viruses-and-bacteria</a>), and another one containing <em class="italic">hospital administration</em> <span class="No-Break">information (</span><a href="https://www.kaggle.com/datasets/girishvutukuri/hospital-administration"><span class="No-Break">https://www.kaggle.com/datasets/girishvutukuri/hospital-administration</span></a><span class="No-Break">).</span></p>
<p class="callout-heading">Note</p>
<p class="callout">This recipe does not require the use of the exact datasets mentioned – it covers generically how to apply the methodology to datasets or any data sources. Feel free to use any data <span class="No-Break">you want.</span></p>
<p>The next stage is <a id="_idIndexMarker242"/>creating the documentation. You can use any software or online application that suits you – the important thing is to have a place to detail and catalog <span class="No-Break">the information.</span></p>
<p>I will use <strong class="bold">Notion</strong> (<a href="https://www.notion.so/">https://www.notion.so/</a>). Its home page is shown in <span class="No-Break"><em class="italic">Figure 3</em></span><em class="italic">.1</em>. It offers a free plan <a id="_idIndexMarker243"/>and allows you to create separate places for different types of documentation. However, some companies use <strong class="bold">Confluence by Atlassian</strong> to document their data. It will always depend on the scenario you <span class="No-Break">are in.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer061">
<img alt="Figure 3.1 – Notion home page" height="669" src="image/Figure_3.01_B19453.jpg" width="1460"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.1 – Notion home page</p>
<p>This is an optional stage where we are creating a Notion account. On the main page, click on <strong class="bold">Get </strong><span class="No-Break"><strong class="bold">Notion free</strong></span><span class="No-Break">.</span></p>
<p>Another page <a id="_idIndexMarker244"/>will appear and you can use your Google or Apple email to create an account, <span class="No-Break">as follows:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer062">
<img alt="Figure 3.2 – Notion Sign up page" height="869" src="image/Figure_3.02_B19453.jpg" width="860"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.2 – Notion Sign up page</p>
<p>After that, you should see a blank page with a welcome message from Notion. If any other action is required, just follow the <span class="No-Break">page instructions.</span></p>
<h2 id="_idParaDest-113"><a id="_idTextAnchor113"/>How to do it…</h2>
<p>Let’s imagine a scenario where we work at a hospital and need to apply the data discovery process. Here is how we go <span class="No-Break">about it:</span></p>
<ol>
<li><strong class="bold">Identifying our data sources</strong>: Two main departments need their data to be ingested—the administration and research departments. We know they usually keep their CSV files in a local data center so we can access them via the intranet. Don’t mind the <a id="_idIndexMarker245"/>filenames; generally, in a real application, they are <span class="No-Break">not supported.</span></li>
</ol>
<p>The following are the research <span class="No-Break">department’s files:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer063">
<img alt="Figure 3.3 – Research files on the evolution of genes in E. coli" height="276" src="image/Figure_3.03_B19453.jpg" width="669"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.3 – Research files on the evolution of genes in E. coli</p>
<p>The following are the administration <span class="No-Break">department’s files:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer064">
<img alt="Figure 3.4 – Hospital administration files" height="117" src="image/Figure_3.04_B19453.jpg" width="772"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.4 – Hospital administration files</p>
<ol>
<li value="2"><strong class="bold">Categorizing data per department or project</strong>: Here, we create folders and subfolders related to the department and the type of data (on patients or <span class="No-Break">specific diseases).</span></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer065">
<img alt="Figure 3.5 – Research Department page" height="526" src="image/Figure_3.05_B19453.jpg" width="1020"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.5 – Research Department page</p>
<ol>
<li value="3"><strong class="bold">Identifying the datasets or databases</strong>: When looking at the files, we can find four patterns. There <a id="_idIndexMarker246"/>are the exclusive datasets: <strong class="bold">E.Coli Genomes</strong>, <strong class="bold">Protein Annotations</strong>, <strong class="bold">Escherichia Virus</strong> in general, <span class="No-Break">and </span><span class="No-Break"><strong class="bold">Patients</strong></span><span class="No-Break">.</span></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer066">
<img alt="Figure 3.6 – Subsections created by research type and hospital administration topic" height="649" src="image/Figure_3.06_B19453.jpg" width="1053"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.6 – Subsections created by research type and hospital administration topic</p>
<ol>
<li value="4"><strong class="bold">Describing our data</strong>: Now, at the dataset level, we need to have helpful information about it, such as the overall description of that dataset table, when it is updated, where other teams can find it, a description of each column of the table, and, last but not least, <span class="No-Break">all metadata.</span></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer067">
<img alt="Figure 3.7 – Patient data documentation using Notion" height="1891" src="image/Figure_3.07_B19453.jpg" width="1459"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.7 – Patient data documentation using Notion</p>
<p class="callout-heading">Note</p>
<p class="callout">The description of where the file is stored may not be applied in all cases. You can find the reference of the database name instead, such <span class="No-Break">as </span><span class="No-Break"><strong class="source-inline">'admin_database.patients'</strong></span><span class="No-Break">.</span></p>
<h2 id="_idParaDest-114"><a id="_idTextAnchor114"/>How it works…</h2>
<p>When starting data discovery, the <a id="_idIndexMarker247"/>first objective is identifying patterns and categorizing them to create a logical flow. Usually, the first categorizations are by department or project, followed by database and dataset identification, and finally, describing the <span class="No-Break">data inside.</span></p>
<p>There are some ways to document data discovery manually. People more used to the old-fashioned style of <strong class="bold">BI</strong> (short for <strong class="bold">Business Intelligence</strong>) tend to create more beautiful visualization <a id="_idIndexMarker248"/>models to apply discovery. However, this recipe’s objective is to create a catalog using a simple tool such <span class="No-Break">as Notion:</span></p>
<ol>
<li><strong class="bold">Categorizing data as per department or project</strong>: The first thing we did was to identify the department responsible for each piece of data. Who is the contact in the case of an ingestion problem or if the dataset is broken? In formal terms, they are also known as data stewards. In some companies, categorization by project can also be applied since some companies can have their particular necessities <span class="No-Break">and data.</span></li>
<li><strong class="bold">Identifying the datasets or databases</strong>: Here, we have only used datasets. Under the projects and/or departments, we insert the name of each table and other helpful information. If the tables are periodically updated, it is a good practice to also <span class="No-Break">document that.</span></li>
<li><strong class="bold">Describing our data</strong>: Finally, we document the expected columns with their data types in detail. It helps data engineers plan their scripts when ingesting raw data; if something goes wrong after the automation, they can easily detect <span class="No-Break">the issue.</span></li>
</ol>
<p>You might notice that <a id="_idIndexMarker249"/>some data behaves strangely. For instance, the <strong class="bold">medical_speciality</strong> column in <span class="No-Break"><em class="italic">Figure 3</em></span><em class="italic">.7</em> has values described and a number to reference something else. In a real-world project, it would be necessary to create auxiliary data inside our ingestion to make a pattern and later facilitate the report <span class="No-Break">or dashboards.</span></p>
<h1 id="_idParaDest-115"><a id="_idTextAnchor115"/>Configuring OpenMetadata</h1>
<p><strong class="bold">OpenMetadata</strong> is an open <a id="_idIndexMarker250"/>source tool used for metadata management, allowing the process of <strong class="bold">data discovery</strong> and <strong class="bold">governance</strong>. You can find <a id="_idIndexMarker251"/>more about it <span class="No-Break">here: </span><a href="https://open-metadata.org/"><span class="No-Break">https://open-metadata.org/</span></a><span class="No-Break">.</span></p>
<p>By performing a few steps, it is possible to create a local or production instance using <strong class="bold">Docker</strong> or <strong class="bold">Kubernetes</strong>. OpenMetadata can connect to multiple resources, such as <strong class="bold">MySQL</strong>, <strong class="bold">Redis</strong>, <strong class="bold">Redshift</strong>, <strong class="bold">BigQuery</strong>, and others, to bring the information needed to build a <span class="No-Break">data catalog.</span></p>
<h2 id="_idParaDest-116"><a id="_idTextAnchor116"/>Getting ready</h2>
<p>Before starting our configuration, we must install <strong class="bold">OpenMetadata</strong> and ensure the Docker <a id="_idIndexMarker252"/>containers are running correctly. Let us see how it <span class="No-Break">is done:</span></p>
<p class="callout-heading">Note</p>
<p class="callout">At the time this book was written, the application was in the 0.12 version and with some documentation and installation improvements. This means the best approach to installing it may change over time. Please refer to the official documentation for it <span class="No-Break">here: </span><a href="https://docs.open-metadata.org/quick-start/local-deployment"><span class="No-Break">https://docs.open-metadata.org/quick-start/local-deployment</span></a><span class="No-Break">.</span></p>
<ol>
<li>Let’s create a folder and <span class="No-Break"><strong class="source-inline">virtualenv</strong></span><span class="No-Break"> (optional):</span><pre class="source-code">
<strong class="bold">$ mkdir openmetadata-docker</strong>
<strong class="bold">$ cd openmetadata-docker</strong></pre></li>
</ol>
<p>Since we are using a Docker environment to deploy the application locally, you can create it with <strong class="source-inline">virtualenv</strong> <span class="No-Break">or not:</span></p>
<pre class="source-code">
<strong class="bold">$ python3 -m venv openmetadata</strong>
<strong class="bold">$ source openmetadata /bin/activate</strong></pre>
<ol>
<li value="2">Next, we install OpenMetadata <span class="No-Break">as follows:</span><pre class="source-code">
<strong class="bold">$ pip3 install --upgrade "openmetadata-ingestion[docker]"</strong></pre></li>
<li>Then we check the installation, <span class="No-Break">as follows:</span><pre class="source-code">
<strong class="bold">$ metadata</strong>
<strong class="bold">Usage: metadata [OPTIONS] COMMAND [ARGS]...</strong>
<strong class="bold">  Method to set logger information</strong>
<strong class="bold">Options:</strong>
<strong class="bold">  --version                       Show the version and exit.</strong>
<strong class="bold">  --debug / --no-debug</strong>
<strong class="bold">  -l, --log-level [INFO|DEBUG|WARNING|ERROR|CRITICAL]</strong>
<strong class="bold">                                  Log level</strong>
<strong class="bold">  --help                          </strong><strong class="bold">Show this message and exit.</strong>
<strong class="bold">Commands:</strong>
<strong class="bold">  backup                          Run a backup for the metadata DB.</strong>
<strong class="bold">  check</strong>
<strong class="bold">  docker                          Checks Docker Memory Allocation Run...</strong>
<strong class="bold">  ingest                          Main command for ingesting metadata...</strong>
<strong class="bold">  openmetadata-imports-migration  </strong><strong class="bold">Update DAG files generated after...</strong>
<strong class="bold">  profile                         Main command for profiling Table...</strong>
<strong class="bold">  restore                         Run a restore for the metadata DB.</strong>
<strong class="bold">  test                            Main command for running test suites</strong>
<strong class="bold">  webhook                         Simple Webserver to test webhook...</strong></pre></li>
</ol>
<h2 id="_idParaDest-117"><a id="_idTextAnchor117"/>How to do it…</h2>
<p>After downloading the <strong class="bold">Python</strong> package and <strong class="bold">Docker</strong>, we will proceed with the configurations <span class="No-Break">as follows:</span></p>
<ol>
<li><strong class="bold">Running containers</strong>: It may <a id="_idIndexMarker253"/>take some time to finish when you execute it for the <span class="No-Break">first time:</span><pre class="source-code">
<strong class="bold">$ metadata docker –start</strong></pre></li>
</ol>
<p class="callout-heading">Note</p>
<p class="callout">It is common for this type of error <span class="No-Break">to appear:</span></p>
<p class="callout"><strong class="bold">Error response from daemon: driver failed programming external connectivity on endpoint openmetadata_ingestion (3670b9566add98a3e79cd9a252d2d0d377dac627b4be94b669482f6ccce350e0): Bind for 0.0.0.0:8080 failed: port is </strong><span class="No-Break"><strong class="bold">already allocated</strong></span></p>
<p class="callout">It means other containers or applications are already using port <strong class="source-inline">8080</strong>. To solve this, specify another port (such as <strong class="source-inline">8081</strong>) or stop the <span class="No-Break">other applications.</span></p>
<p>The first time you run this command, the results might take a while due to other containers associated <span class="No-Break">with it.</span></p>
<p>In the end, you should see the <span class="No-Break">following output:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer068">
<img alt="Figure 3.8 – Command line showing success running OpenMetadata containers" height="256" src="image/Figure_3.08_B19453.jpg" width="1214"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.8 – Command line showing success running OpenMetadata containers</p>
<ol>
<li value="2"><strong class="bold">Accessing OpenMetadata UI</strong>: When the container installation is finished, you should be <a id="_idIndexMarker254"/>able to access the UI via a browser using the <span class="No-Break"><strong class="source-inline">http://localhost:8585</strong></span><span class="No-Break"> address:</span></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer069">
<img alt="Figure 3.9 – OpenMetadata sign-in page in the browser" height="934" src="image/Figure_3.09_B19453.jpg" width="1540"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.9 – OpenMetadata sign-in page in the browser</p>
<ol>
<li value="3"><strong class="bold">Creating a user account and logging in</strong>: To access the UI panel, we need to create a user account <span class="No-Break">as follows:</span></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer070">
<img alt="Figure 3.10 – Creating a user account in the OpenMetadata Create Account section" height="911" src="image/Figure_3.10_B19453.jpg" width="1650"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.10 – Creating a user account in the OpenMetadata Create Account section</p>
<p>After that, we will <a id="_idIndexMarker255"/>be redirected to the main page and be able to access the panel, shown <span class="No-Break">as follows:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer071">
<img alt="Figure 3.11 – Main page of OpenMetadata" height="729" src="image/Figure_3.11_B19453.jpg" width="1406"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.11 – Main page of OpenMetadata</p>
<p class="callout-heading">Note</p>
<p class="callout">Is also possible to log in using the default admin user by inserting the <a href="mailto:admin@openmetadata.org">admin@openmetadata.org</a> username and <strong class="source-inline">admin</strong> as <span class="No-Break">the password.</span></p>
<p class="callout">For production <a id="_idIndexMarker256"/>matters, please refer to the Enable Security Guide <span class="No-Break">here: </span><a href="https://docs.open-metadata.org/deployment/docker/security"><span class="No-Break">https://docs.open-metadata.org/deployment/docker/security</span></a><span class="No-Break">.</span></p>
<ol>
<li value="4"><strong class="bold">Creating teams</strong>: In the <strong class="bold">Settings</strong> section, you should see several possible configurations, from <a id="_idIndexMarker257"/>creating users to access the console to integrations with messengers such as <strong class="bold">Slack</strong> or <span class="No-Break"><strong class="bold">MS Teams</strong></span><span class="No-Break">.</span></li>
</ol>
<p>Some ingestion and integration requires the user to be allocated to a team. To create a team, we first need to log in as <strong class="source-inline">admin</strong>. Then, go to <strong class="bold">Settings</strong> | <strong class="bold">Teams</strong> | <strong class="bold">Create </strong><span class="No-Break"><strong class="bold">new team</strong></span><span class="No-Break">:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer072">
<img alt="Figure 3.12 – Creating a team in the OpenMetadata settings" height="1206" src="image/Figure_3.12_B19453.jpg" width="1409"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.12 – Creating a team in the OpenMetadata settings</p>
<ol>
<li value="5"><strong class="bold">Adding users to our teams</strong>: Select <a id="_idIndexMarker258"/>the team you just created and go to the <strong class="bold">Users</strong> tab. Then select the user you want <span class="No-Break">to add.</span></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer073">
<img alt="Figure 3.13 – Adding users to a team" height="1254" src="image/Figure_3.13_B19453.jpg" width="1650"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.13 – Adding users to a team</p>
<p>Creating teams is very <a id="_idIndexMarker259"/>convenient to keep track of users’ activity and define a group of roles and policies. In the following case, all users added to this team will be able to navigate through and create their data <span class="No-Break">discovery pipelines.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer074">
<img alt="Figure 3.14 – Team page and the default associated Data Consumer role" height="1040" src="image/Figure_3.14_B19453.jpg" width="1290"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.14 – Team page and the default associated Data Consumer role</p>
<p>We must have <a id="_idIndexMarker260"/>a Data Steward or Administrator role for the activities in <a id="_idIndexMarker261"/>this chapter and the following recipe. The Data Steward role has almost the same permissions as the Administrator role since it is a position that is <a id="_idIndexMarker262"/>responsible for defining and implementing data policies, standards, and procedures to govern data usage and <span class="No-Break">ensure consistency.</span></p>
<p>You can read more about the <strong class="bold">Roles and Policies</strong> of OpenMetadata <span class="No-Break">here: </span><a href="https://github.com/open-metadata/OpenMetadata/issues/4199"><span class="No-Break">https://github.com/open-metadata/OpenMetadata/issues/4199</span></a><span class="No-Break">.</span></p>
<h2 id="_idParaDest-118"><a id="_idTextAnchor118"/>How it works…</h2>
<p>Now, let’s understand a bit more about how <span class="No-Break">OpenMetadata works.</span></p>
<p>OpenMetadata is an open source metadata management tool designed to help organizations to manage their <a id="_idIndexMarker263"/>data and metadata across different systems or platforms. Since it centralizes data information in one place, it makes it easier to discover and <span class="No-Break">understand data.</span></p>
<p>It is also a flexible and extensible tool, allowing integration with tools such as Apache Kafka, Apache Hive, and others since it uses programming languages such as <strong class="bold">Python</strong> (main core code) and Java <a id="_idIndexMarker264"/>behind <span class="No-Break">the scenes.</span></p>
<p>To orchestrate <a id="_idIndexMarker265"/>and ingest the metadata from sources, OpenMetadata counts the sources using Airflow code. If you look at its core, all Airflow code can be found in <strong class="source-inline">openmetadata-ingestion</strong>. For more heavy users who want to debug any problems related to the ingestion process in this framework, Airflow can be easily accessed at <strong class="source-inline">http://localhost:8080/</strong>, when the metadata Docker container is up <span class="No-Break">and running.</span></p>
<p>It also uses <strong class="bold">MySQL DB</strong> to store user information and relationships and an <strong class="bold">Elasticsearch</strong> container to create efficient indexes. Refer to the following <span class="No-Break">figure (</span><a href="https://docs.open-metadata.org/developers/architecture"><span class="No-Break">https://docs.open-metadata.org/developers/architecture</span></a><span class="No-Break">):</span></p>
<div>
<div class="IMG---Figure" id="_idContainer075">
<img alt="Figure 3.15 – OpenMetadata architecture diagram Font source: OpenMetadata documentation" height="771" src="image/Figure_3.15_B19453.jpg" width="651"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.15 – OpenMetadata architecture diagram Font source: OpenMetadata documentation</p>
<p>For more detailed information <a id="_idIndexMarker266"/>about the design decisions, you can access the <strong class="bold">Main Concepts</strong> page and explore in detail the ideas behind <span class="No-Break">them: </span><a href="https://docs.open-metadata.org/main-concepts/high-level-design"><span class="No-Break">https://docs.open-metadata.org/main-concepts/high-level-design</span></a><span class="No-Break">.</span></p>
<h2 id="_idParaDest-119"><a id="_idTextAnchor119"/>There’s more…</h2>
<p>We saw how <strong class="bold">OpenMetadata</strong> can be easily configured and installed locally on our machines and a brief overview of its architecture. However, other good options on the market can be used to document data, or even a <strong class="bold">SaaS</strong> solution of <strong class="bold">OpenMetadata</strong> using <span class="No-Break"><strong class="bold">Google Cloud</strong></span><span class="No-Break">.</span></p>
<h3>OpenMetadata SaaS sandbox</h3>
<p>Recently, OpenMetadata implemented a <strong class="bold">Software as a Service</strong> (<strong class="bold">SaaS</strong>) sandbox (<a href="https://sandbox.open-metadata.org/signin">https://sandbox.open-metadata.org/signin</a>) using Google, making it easier to deploy and start the discovery <a id="_idIndexMarker267"/>and catalog process. However, it may have costs applied, so keep that <span class="No-Break">in mind.</span></p>
<h2 id="_idParaDest-120"><a id="_idTextAnchor120"/>See also</h2>
<ul>
<li>You can read more about OpenMetadata in their <span class="No-Break">blog: </span><a href="https://blog.open-metadata.org/why-openmetadata-is-the-right-choice-for-you-59e329163cac"><span class="No-Break">https://blog.open-metadata.org/why-openmetadata-is-the-right-choice-for-you-59e329163cac</span></a></li>
<li>Explore OpenMetadata on <span class="No-Break">GitHub: </span><a href="https://github.com/open-metadata/OpenMetadata"><span class="No-Break">https://github.com/open-metadata/OpenMetadata</span></a></li>
</ul>
<h1 id="_idParaDest-121"><a id="_idTextAnchor121"/>Connecting OpenMetadata to our database</h1>
<p>Now that we have <a id="_idIndexMarker268"/>configured our <strong class="bold">Data Discovery</strong> tool, let’s <a id="_idIndexMarker269"/>create a sample connection to our local database instance. Let’s try to use PostgreSQL to do an easy integration and practice another <span class="No-Break">database usage.</span></p>
<h2 id="_idParaDest-122"><a id="_idTextAnchor122"/>Getting ready</h2>
<p>First, ensure our application runs appropriately by accessing the <span class="No-Break"><strong class="source-inline">http://localhost:8585/my-data address</strong></span><span class="No-Break">.</span></p>
<p class="callout-heading">Note</p>
<p class="callout">Inside OpenMetadata, the user must have the <strong class="bold">Data Steward</strong> or <strong class="bold">Administration</strong> role to create connections. You can switch to the <strong class="source-inline">admin</strong> user using the previous credentials <span class="No-Break">we saw.</span></p>
<p>You can check the Docker <span class="No-Break">status here:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer076">
<img alt="Figure 3.16 – Active containers are shown in the Docker desktop application" height="450" src="image/Figure_3.16_B19453.jpg" width="610"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.16 – Active containers are shown in the Docker desktop application</p>
<p>Use PostgreSQL for testing. Since <a id="_idIndexMarker270"/>we already have a Google <a id="_idIndexMarker271"/>project ready, let us create a SQL instance using the <span class="No-Break">PostgreSQL engine.</span></p>
<p>As we kept the queries to create the database and tables in <a href="B19453_02.xhtml#_idTextAnchor064"><span class="No-Break"><em class="italic">Chapter 2</em></span></a>, we can build it again in Postgres. The queries can also be found in the GitHub repository of this chapter. However, feel free to create your <span class="No-Break">own data.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer077">
<img alt="Figure 3.17 – Google Cloud console header for SQL instances" height="391" src="image/Figure_3.17_B19453.jpg" width="563"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.17 – Google Cloud console header for SQL instances</p>
<p>Remember to let this instance allow public access; otherwise, our local OpenMetadata instance won’t be able to <span class="No-Break">access it.</span></p>
<h2 id="_idParaDest-123"><a id="_idTextAnchor123"/>How to do it…</h2>
<p>Go to the OpenMetadata <a id="_idIndexMarker272"/>home page by typing <strong class="source-inline">http://localhost:8585/my-data</strong> in <a id="_idIndexMarker273"/>the <span class="No-Break">browser header:</span></p>
<ol>
<li><strong class="bold">Adding a new database to OpenMetadata</strong>: Go to <strong class="bold">Settings</strong> | <strong class="bold">Services</strong> | <strong class="bold">Databases</strong> and click on <strong class="bold">Add new Database Service</strong>. Some options will appear. Click <span class="No-Break">on </span><span class="No-Break"><strong class="bold">Postgres</strong></span><span class="No-Break">:</span></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer078">
<img alt="Figure 3.18 – OpenMetadata page to add a database as a source" height="1168" src="image/Figure_3.18_B19453.jpg" width="1412"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.18 – OpenMetadata page to add a database as a source</p>
<p>Click on <strong class="bold">Next</strong> and <a id="_idIndexMarker274"/>add a service name. It can be <a id="_idIndexMarker275"/>anything you like since it’s an identifier. I <span class="No-Break">used </span><span class="No-Break"><strong class="source-inline">CookBookData</strong></span><span class="No-Break">.</span></p>
<ol>
<li value="2"><strong class="bold">Adding our connection settings</strong>: After clicking on <strong class="bold">Next</strong> again, a page with some fields to input the MySQL connection settings <span class="No-Break">will appear:</span></li>
</ol>
<p class="IMG---Figure"> </p>
<div>
<div class="IMG---Figure" id="_idContainer079">
<img alt="Figure 3.19 – Adding new database connection information" height="1111" src="image/Figure_3.19_B19453.jpg" width="1405"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.19 – Adding new database connection information</p>
<ol>
<li value="3"><strong class="bold">Testing our connection</strong>: With <a id="_idIndexMarker276"/>all the credentials <a id="_idIndexMarker277"/>in place, we need to test the connection to <span class="No-Break">the database.</span></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer080">
<img alt="Figure 3.20 – Connection test successful message for database connection" height="411" src="image/Figure_3.20_B19453.jpg" width="639"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.20 – Connection test successful message for database connection</p>
<ol>
<li value="4"><strong class="bold">Creating an ingestion pipeline</strong>: You can leave all the fields as they are without <a id="_idIndexMarker278"/>worrying about the <strong class="bold">database tool</strong> (<strong class="bold">DBT</strong>). For <strong class="bold">Schedule Interval</strong>, you <a id="_idIndexMarker279"/>can set what suits you best. I will leave it <span class="No-Break">as </span><span class="No-Break"><strong class="bold">Daily</strong></span><span class="No-Break">.</span></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer081">
<img alt="Figure 3.21 – Adding database metadata ingestion" height="599" src="image/Figure_3.21_B19453.jpg" width="1266"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.21 – Adding database metadata ingestion</p>
<ol>
<li value="5"><strong class="bold">Ingesting the metadata</strong>: Heading <a id="_idIndexMarker280"/>to <strong class="bold">Ingestions</strong>, our <a id="_idIndexMarker281"/>database metadata is <span class="No-Break">successfully ingested.</span></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer082">
<img alt="Figure 3.22 – Postgres metadata successfully ingested" height="410" src="image/Figure_3.22_B19453.jpg" width="1322"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.22 – Postgres metadata successfully ingested</p>
<ol>
<li value="6"><strong class="bold">Exploring our metadata</strong>: To explore the metadata, go to <strong class="bold">Explore</strong> | <span class="No-Break"><strong class="bold">Tables</strong></span><span class="No-Break">:</span></li>
</ol>
<div>
<div class="IMG---Figure" id="_idContainer083">
<img alt="Figure 3.23 – Explore page showing the tables metadata ingested" height="581" src="image/Figure_3.23_B19453.jpg" width="1234"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.23 – Explore page showing the tables metadata ingested</p>
<p>You can see that the <strong class="source-inline">people</strong> table is there with other <span class="No-Break">internal tables:</span></p>
<div>
<div class="IMG---Figure" id="_idContainer084">
<img alt="Figure 3.24 – The people table metadata" height="848" src="image/Figure_3.24_B19453.jpg" width="1322"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.24 – The people table metadata</p>
<p>Here, you can explore some functionalities of the application, such as defining the level of importance to the organization and the owners, querying the table, <span class="No-Break">and others.</span></p>
<h2 id="_idParaDest-124"><a id="_idTextAnchor124"/>How it works…</h2>
<p>As we saw previously, OpenMetadata uses Python to build and connect to <span class="No-Break">different sources.</span></p>
<p>In <strong class="bold">Connection Details</strong>, we saw <strong class="source-inline">Connection Scheme</strong> uses <strong class="source-inline">psycopg2</strong>, a widely used <a id="_idIndexMarker282"/>library in Python. All other arguments are passed <a id="_idIndexMarker283"/>to the behind-the-scenes Python code to create a <span class="No-Break">connection string.</span></p>
<p>For each metadata <a id="_idIndexMarker284"/>ingestion, OpenMetadata will create a new Airflow <strong class="bold">Directed Acyclic Graph</strong> (<strong class="bold">DAG</strong>) to process it based on a generic one. Having a separate DAG for each metadata ingestion makes debugging more manageable in case <span class="No-Break">of errors.</span></p>
<div>
<div class="IMG---Figure" id="_idContainer085">
<img alt="Figure 3.25 – Airflow DAGs created by OpenMetadata" height="935" src="image/Figure_3.25_B19453.jpg" width="1349"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.25 – Airflow DAGs created by OpenMetadata</p>
<p>If you open the Airflow <a id="_idIndexMarker285"/>instance used by OpenMetadata, you can <a id="_idIndexMarker286"/>see it clearly and have other information about the metadata ingestion. It’s a nice place to debug in case an error occurs. Understanding how our solution works and where to look in case of a problem helps identify and solve issues <span class="No-Break">more efficiently.</span></p>
<h1 id="_idParaDest-125"><a id="_idTextAnchor125"/>Further reading</h1>
<ul>
<li><a href="https://nira.com/data-discovery/"><span class="No-Break">https://nira.com/data-discovery/</span></a></li>
<li><a href="https://coresignal.com/blog/data-discovery/"><span class="No-Break">https://coresignal.com/blog/data-discovery/</span></a></li>
<li><a href="https://www.polymerhq.io/blog/diligence/what-is-data-discovery-guide/"><span class="No-Break">https://www.polymerhq.io/blog/diligence/what-is-data-discovery-guide/</span></a></li>
<li><a href="https://bi-survey.com/data-discovery"><span class="No-Break">https://bi-survey.com/data-discovery</span></a></li>
<li><a href="https://www.heavy.ai/technical-glossary/data-discovery"><span class="No-Break">https://www.heavy.ai/technical-glossary/data-discovery</span></a></li>
<li><a href="https://www.datapine.com/blog/what-are-data-discovery-tools/"><span class="No-Break">https://www.datapine.com/blog/what-are-data-discovery-tools/</span></a></li>
<li><a href="https://www.knowsolution.com.br/data-discovery-como-relaciona-bi-descubra/">https://www.knowsolution.com.br/data-discovery-como-relaciona-bi-descubra/</a> (<span class="No-Break">in Portuguese)</span></li>
</ul>
<h2 id="_idParaDest-126"><a id="_idTextAnchor126"/>Other tools</h2>
<p>If you are interested in learning more about other data discovery tools available on the market, here <span class="No-Break">are some:</span></p>
<ul>
<li><strong class="bold">Tableau</strong>: Tableau (<a href="https://www.tableau.com/">https://www.tableau.com/</a>) is more extensively used for data visualizations <a id="_idIndexMarker287"/>and dashboards but comes with some features to discover and catalog data. You can read more about how to use Tableau for data discovery on their resources page <span class="No-Break">here: </span><a href="https://www.tableau.com/learn/whitepapers/data-driven-organization-7-keys-data-discovery"><span class="No-Break">https://www.tableau.com/learn/whitepapers/data-driven-organization-7-keys-data-discovery</span></a><span class="No-Break">.</span></li>
<li><strong class="bold">OpenDataDiscovery</strong> (free and open source): OpenDataDiscovery has recently arrived on the <a id="_idIndexMarker288"/>market and can provide a very nice starting point. Check it out <span class="No-Break">here: </span><a href="https://opendatadiscovery.org/"><span class="No-Break">https://opendatadiscovery.org/</span></a><span class="No-Break">.</span></li>
<li><strong class="bold">Atlan</strong>: Atlan (<a href="https://atlan.com/">https://atlan.com/</a>) is a complete solution and also brings a data governance <a id="_idIndexMarker289"/>structure; however, the costs can be high and it requires a call <a id="_idIndexMarker290"/>with their sales team to start an <strong class="bold">MVP</strong> (short for <strong class="bold">Minimum </strong><span class="No-Break"><strong class="bold">Viable Product</strong></span><span class="No-Break">).</span></li>
<li><strong class="bold">Alation</strong>: Alation is an enterprise <a id="_idIndexMarker291"/>tool that provides several data solutions that include all pillars of data governance. Find out more <span class="No-Break">here: </span><a href="https://www.alation.com/"><span class="No-Break">https://www.alation.com/</span></a><span class="No-Break">.</span></li>
</ul>
</div>
</div></body></html>