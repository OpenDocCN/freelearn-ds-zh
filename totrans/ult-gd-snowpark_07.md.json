["```py\ndf_table=session.table(\"BSD_TRAINING\")\n```", "```py\nnumber_of_rows = df_table.count()\nnumber_of_columns = len(df_table.columns)\n```", "```py\ndf_table.sample(n=2).show()\n```", "```py\nimport pprint\ndata_types = df_table.schema\ndata_types = df_table.schema.fields\npprint.pprint(data_types)\n```", "```py\nfrom snowflake.snowpark.functions import count, col\ndata_types = df_table.schema\nprint(data_types)\nfor column in df_table.columns:\n    print(f\"Null values in {column} is {number_of_rows - df_table.agg(count(col(column))).collect()[0][0]}\")\n```", "```py\nprint(f\"Zero Values in windspeed column is {df_table.filter(df_table['WINDSPEED']==0).count()}\")\n```", "```py\nfrom snowflake.snowpark.functions import iff, avg\nwind_speed_mean = df_train.select(mean(\"windspeed\")).collect()[0][0]\ndf_train = df_train.replace({0:wind_speed_mean}, subset=[\"windspeed\"])\ndf_train.show()\ndf_train.write.mode(\"overwrite\").save_as_table(\"model_data\")\n```", "```py\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nf, axes = plt.subplots(1, 2)\nsns.boxplot(x=df_table.to_pandas()['COUNT'], ax=axes[0])\nsns.boxplot(x=df_without_outlier.to_pandas()['COUNT'], ax=axes[1])\nplt.show()\n```", "```py\nfrom snowflake.snowpark.functions \\\n    import mean, stddev, abs, date_part\nmean_value = df_table.select(mean(\"count\")).collect()[0][0]\nprint(mean_value)\nstd_value = df_table.select(stddev(\"count\")).collect()[0][0]\nprint(std_value)\ndf_without_outlier = df_table.filter(\n    (abs(df_table[\"count\"] - mean_value)) >= (3 * std_value))\ndf_without_outlier.show()\n```", "```py\nChapter_5.ipynb:\n```", "```py\ncorr_matrix = df_without_outlier.to_pandas().corr()\nplt.figure(figsize=(12, 6))\nsns.heatmap(corr_matrix, cmap='coolwarm', annot=True)\n```", "```py\nfrom snowflake.snowpark.functions import hour, month,to_date,dayofweek\ndf_table = df_table.with_column(\"hour\", hour(\"DATETIME\"))\ndf_table = df_table.with_column(\"month\", month(\"DATETIME\"))\ndf_table = df_table.with_column(\"date\", to_date(\"DATETIME\"))\ndf_table = df_table.with_column(\"weekday\", dayofweek(\"DATETIME\"))\ndf_table.show()\n```", "```py\nimport snowflake.ml.modeling.preprocessing as snowml\nfrom snowflake.ml.modeling.pipeline import Pipeline\nimport joblib\ndf = session.table(\"BSD_TRAINING\")\ndf = df.drop(\"DATETIME\",\"DATE\")\nCATEGORICAL_COLUMNS = [\"SEASON\",\"WEATHER\"]\nCATEGORICAL_COLUMNS_OHE = [\"SEASON_OE\",\"WEATHER_OE\"]\nMIN_MAX_COLUMNS = [\"TEMP\"]\nimport numpy as np\ncategories = {\n    \"SEASON\": np.array([1,2,3,4]),\n    \"WEATHER\": np.array([1,2,3,4]),\n}\npreprocessing_pipeline = Pipeline(\n    steps=[\n        (\n            \"OE\",\n            snowml.OrdinalEncoder(\n                input_cols=CATEGORICAL_COLUMNS,\n                output_cols=CATEGORICAL_COLUMNS_OHE,\n                categories=categories\n            )\n        ),\n        (\n            \"MMS\",\n            snowml.MinMaxScaler(\n                clip=True,\n                input_cols=MIN_MAX_COLUMNS,\n                output_cols=MIN_MAX_COLUMNS,\n            )\n        )\n    ]\n)\nPIPELINE_FILE = 'preprocessing_pipeline.joblib'\njoblib.dump(preprocessing_pipeline, PIPELINE_FILE)\ntransformed_df = preprocessing_pipeline.fit(df).transform(df)\ntransformed_df.show()\nsession.file.put(PIPELINE_FILE,\"@snowpark_test_stage\",overwrite=True)\n```", "```py\nCATEGORICAL_COLUMNS = [\"SEASON\",\"WEATHER\"]\nCATEGORICAL_COLUMNS_OHE = [\"SEASON_OE\",\"WEATHER_OE\"]\nMIN_MAX_COLUMNS = [\"TEMP\",\"ATEMP\"]\nFEATURE_LIST = \\\n    [\"HOLIDAY\",\"WORKINGDAY\",\"HUMIDITY\",\"TEMP\",\"ATEMP\",\"WINDSPEED\"]\nLABEL_COLUMNS = ['COUNT']\nOUTPUT_COLUMNS = ['PREDICTED_COUNT']\nPIPELINE_FILE = 'preprocessing_pipeline.joblib'\npreprocessing_pipeline = joblib.load(PIPELINE_FILE)\n```", "```py\nbsd_train_df, bsd_test_df = df.random_split(\n    weights=[0.7,0.3], seed=0)\ntrain_df = preprocessing_pipeline.fit(\n    bsd_train_df).transform(bsd_train_df)\ntest_df = preprocessing_pipeline.transform(bsd_test_df)\ntrain_df.show()\ntest_df.show()\n```", "```py\nfrom snowflake.ml.modeling.linear_model import LinearRegression\nregressor = LinearRegression(\n    input_cols=CATEGORICAL_COLUMNS_OHE+FEATURE_LIST,\n    label_cols=LABEL_COLUMNS,\n    output_cols=OUTPUT_COLUMNS\n)\n# Train\nregressor.fit(train_df)\n# Predict\nresult = regressor.predict(test_df)\nresult.show()\n```", "```py\nfrom snowflake.ml.modeling.metrics import mean_squared_error, explained_variance_score, mean_absolute_error, mean_absolute_percentage_error, d2_absolute_error_score, d2_pinball_score\nmse = mean_squared_error(df=result,\n    y_true_col_names=\"COUNT\",\n    y_pred_col_names=\"PREDICTED_COUNT\")\nevs = explained_variance_score(df=result,\n    y_true_col_names=\"COUNT\",\n    y_pred_col_names=\"PREDICTED_COUNT\")\nmae = mean_absolute_error(df=result,\n    y_true_col_names=\"COUNT\",\n    y_pred_col_names=\"PREDICTED_COUNT\")\nmape = mean_absolute_percentage_error(df=result,\n    y_true_col_names=\"COUNT\",\n    y_pred_col_names=\"PREDICTED_COUNT\")\nd2aes = d2_absolute_error_score(df=result,\n    y_true_col_names=\"COUNT\",\n    y_pred_col_names=\"PREDICTED_COUNT\")\nd2ps = d2_pinball_score(df=result,\n    y_true_col_names=\"COUNT\",\n    y_pred_col_names=\"PREDICTED_COUNT\")\nprint(f\"Mean squared error: {mse}\")\nprint(f\"explained_variance_score: {evs}\")\nprint(f\"mean_absolute_error: {mae}\")\nprint(f\"mean_absolute_percentage_error: {mape}\")\nprint(f\"d2_absolute_error_score: {d2aes}\")\nprint(f\"d2_pinball_score: {d2ps}\")\n```"]