<html><head></head><body><div id="sbo-rt-content"><div id="_idContainer271" class="Content">
			<h1 id="_idParaDest-281"><em class="italics"><a id="_idTextAnchor336"/>Appendix</em></h1>
		</div>
		<div>
			<div id="_idContainer272" class="Content">
			</div>
		</div>
		<div id="_idContainer273" class="Content">
			<h2>About</h2>
			<p>This section is included to assist the students to perform the activities in the book. It includes detailed steps that are to be performed by the students to achieve the objectives of the activities.</p>
		</div>
		<div id="_idContainer343" class="Content">
			<h3 id="_idParaDest-282"><a id="_idTextAnchor337"/>Solution of Activity 1: Handling Lists</h3>
			<p>These are the steps to complete this activity:</p>
			<ol>
				<li>Import the <strong class="inline">random</strong> library:<p class="snippet">import random</p></li>
				<li>Set the maximum number of random numbers:<p class="snippet">LIMIT = 100</p></li>
				<li>Use the <strong class="inline">randint</strong> function from the <strong class="inline">random</strong> library to create 100 random numbers. Tip: try getting a list with the least number of duplicates:<p class="snippet">random_number_list = [random.randint(0, LIMIT) for x in range(0, LIMIT)]</p></li>
				<li>Print <strong class="inline">random_number_list</strong>:<p class="snippet">random_number_list</p><p>The sample output is as follows:</p><div id="_idContainer274" class="IMG---Figure"><img src="Images/C11065_01_16.jpg" alt="Figure 1.16: Section of output for random_number_list" width="828" height="597"/></div><h6>Figure 1.16: Section of output for random_number_list</h6></li>
				<li>Create a <strong class="inline">list_with_divisible_by_3</strong> list from <strong class="inline">random_number_list</strong>, which will contain only numbers that are divisible by <strong class="inline">3</strong>:<p class="snippet">list_with_divisible_by_3 = [a for a in random_number_list if a % 3 == 0]</p><p class="snippet">list_with_divisible_by_3</p><p>The sample output is as follows:</p><div id="_idContainer275" class="IMG---Figure"><img src="Images/C11065_01_17.jpg" alt="Figure 1.17: Section of output for random_number_list divisible by 3" width="644" height="582"/></div><h6>Figure 1.17: Section of output for random_number_list divisible by 3</h6></li>
				<li>Use the <strong class="inline">len</strong> function to measure the length of the first list and the second list, and store them in two different variables, <strong class="inline">length_of_random_list</strong> and <strong class="inline">length_of_3_divisible_list</strong>. Calculate the difference in length in a variable called <strong class="inline">difference</strong>:<p class="snippet">length_of_random_list = len(random_number_list)</p><p class="snippet">length_of_3_divisible_list = len(list_with_divisible_by_3)</p><p class="snippet">difference = length_of_random_list - length_of_3_divisible_list</p><p class="snippet">difference</p><p>The sample output is as follows:</p><p class="snippet">62</p></li>
				<li>Combine the tasks we have performed so far and add a while loop to it. Run the loop 10 times and add the values of the difference variables to a list:<p class="snippet">NUMBER_OF_EXPERIMENTS = 10</p><p class="snippet">difference_list = []</p><p class="snippet">for i in range(0, NUMBER_OF_EXPERIEMENTS):</p><p class="snippet">    random_number_list = [random.randint(0, LIMIT) for x in range(0, LIMIT)]</p><p class="snippet">    list_with_divisible_by_3 = [a for a in random_number_list if a % 3 == 0]</p><p class="snippet">    </p><p class="snippet">    length_of_random_list = len(random_number_list)</p><p class="snippet">    length_of_3_divisible_list = len(list_with_divisible_by_3)</p><p class="snippet">    difference = length_of_random_list - length_of_3_divisible_list</p><p class="snippet">    </p><p class="snippet">    difference_list.append(difference)</p><p class="snippet">difference_list</p><p>The sample output is as follows:</p><p class="snippet">[64, 61, 67, 60, 73, 66, 66, 75, 70, 61]</p></li>
				<li>Then, calculate the arithmetic mean (common average) for the differences in the lengths that you have: <p class="snippet">avg_diff = sum(difference_list) / float(len(difference_list))</p><p class="snippet">avg_diff</p><p>The sample output is as follows:</p><p class="snippet">66.3</p></li>
			</ol>
			<h3 id="_idParaDest-283"><a id="_idTextAnchor338"/>Solution of Activity 2: Analyze a Multiline String and Generate the Unique Word Count</h3>
			<p>These are the steps to complete this activity:</p>
			<ol>
				<li value="1">Create a string called <strong class="inline">multiline_text</strong> and copy the text present in the first chapter of <em class="italics">Pride and Prejudice</em>. Use <em class="italics">Ctrl</em> <em class="italics">+</em> <em class="italics">A</em> to select the entire text and then <em class="italics">Ctrl</em> <em class="italics">+</em> <em class="italics">C</em> to copy it and paste the text you just copied into it:<div id="_idContainer276" class="IMG---Figure"><img src="Images/C11065_01_18.jpg" alt="Figure 1.18: Initializing the mutliline_text string" width="1003" height="473"/></div><h6>Figure 1.18: Initializing the mutliline_text string</h6></li>
				<li>Find the type of the string using the <strong class="inline">type</strong> function:<p class="snippet">type(multiline_text)</p><p>The output is as follows:</p><p class="snippet">str</p></li>
				<li>Now, find the length of the string, using the <strong class="inline">len</strong> function:<p class="snippet">len(multiline_text)</p><p>The output is as follows:</p><p class="snippet">4475</p></li>
				<li>Use string methods to get rid of all the new lines (<strong class="inline">\n</strong> or <strong class="inline">\r</strong>),and symbols. Remove all new lines by replacing them with this: <p class="snippet">multiline_text = multiline_text.replace('\n', "")</p><p>Then, we will print and check the output:</p><p class="snippet">multiline_text</p><p>The output is as follows:</p><div id="_idContainer277" class="IMG---Figure"><img src="Images/C11065_01_19.jpg" alt="Figure 1.19: The multiline_text string after removing the new lines" width="981" height="397"/></div><h6>Figure 1.19: The multiline_text string after removing the new lines</h6></li>
				<li>Removing the special characters and punctuation:<p class="snippet"># remove special chars, punctuation etc.</p><p class="snippet">cleaned_multiline_text = ""</p><p class="snippet">for char in multiline_text:</p><p class="snippet">    if char == " ":</p><p class="snippet">        cleaned_multiline_text += char</p><p class="snippet">    elif char.isalnum():  # using the isalnum() method of strings.</p><p class="snippet">        cleaned_multiline_text += char</p><p class="snippet">    else:</p><p class="snippet">        cleaned_multiline_text += " "</p></li>
				<li>Check the content of <strong class="inline">cleaned_multiline_text</strong>:<p class="snippet">cleaned_multiline_text</p><p>The output is as follows:</p><div id="_idContainer278" class="IMG---Figure"><img src="Images/C11065_01_20.jpg" alt="Figure 1.20: The cleaned_multiline_text string" width="990" height="392"/></div><h6>Figure 1.20: The cleaned_multiline_text string</h6></li>
				<li>Generate a list of all the words from the cleaned string using the following command:<p class="snippet">list_of_words = cleaned_multiline_text.split()</p><p class="snippet">list_of_words</p><p>The output is as follows:</p><div id="_idContainer279" class="IMG---Figure"><img src="Images/C11065_01_21.jpg" alt="Figure 1.21: The section of output displaying the list_of_words" width="682" height="326"/></div><h6>Figure 1.21: The section of output displaying the list_of_words</h6></li>
				<li>Find the number of words:<p class="snippet">len(list_of_words)</p><p>The output is <strong class="inline">852</strong>.</p></li>
				<li>Create a list from the list you just created, which includes only unique words:  <p class="snippet">unique_words_as_dict = dict.fromkeys(list_of_words)</p><p class="snippet">len(list(unique_words_as_dict.keys()))</p><p>The output is <strong class="inline">340</strong>.</p></li>
				<li>Count the number of times each of the unique words appeared in the cleaned text: <p class="snippet">for word in list_of_words:</p><p class="snippet">    if unique_words_as_dict[word] is None:</p><p class="snippet">        unique_words_as_dict[word] = 1</p><p class="snippet">    else:</p><p class="snippet">        unique_words_as_dict[word] += 1</p><p class="snippet">unique_words_as_dict</p><p>The output is as follows:</p><div id="_idContainer280" class="IMG---Figure"><img src="Images/C11065_01_22.jpg" alt="Figure 1.22: Section of output showing unique_words_as_dict" width="667" height="326"/></div><h6>Figure 1.22: Section of output showing unique_words_as_dict</h6><p>You just created, step by step, a unique word counter using all the neat tricks that you just learned.</p></li>
				<li>Find the top 25 words from the <strong class="inline">unique_words_as_dict</strong>.<p class="snippet">top_words = sorted(unique_words_as_dict.items(), key=lambda key_val_tuple: key_val_tuple[1], reverse=True)</p><p class="snippet">top_words[:25]</p><p>These are the steps to complete this activity:</p></li>
			</ol>
			<div>
				<div id="_idContainer281" class="IMG---Figure">
					<img src="Images/C11065_01_23.jpg" alt="Figure 1.23: Top 25 unique words from multiline_text" width="629" height="432"/>
				</div>
			</div>
			<h6>Figure 1.23: Top 25 unique words from multiline_text</h6>
			<h3 id="_idParaDest-284"><a id="_idTextAnchor339"/>Solution of Activity 3: Permutation, Iterator, Lambda, List</h3>
			<p>These are the steps to solve this activity:</p>
			<ol>
				<li value="1">Look up the definition of <strong class="inline">permutations</strong> and <strong class="inline">dropwhile</strong> from <strong class="inline">itertools</strong>. There is a way to look up the definition of a function inside Jupyter itself. Just type the function name, followed by <em class="italics">?</em>, and press <em class="italics">Shift +</em><span class="HTML-Code"> </span><em class="italics">Enter</em>:<p class="snippet">from itertools import permutations, dropwhile</p><p class="snippet">permutations?</p><p class="snippet">dropwhile?</p><p>You will see a long list of definitions after each <strong class="inline">?</strong>. We will skip it here.</p></li>
				<li>Write an expression to generate all the possible three-digit numbers using 1, 2, and 3:<p class="snippet">permutations(range(3))</p><p>The output is as follows:</p><p class="snippet">&lt;itertools.permutations at 0x7f6c6c077af0&gt;</p></li>
				<li>Loop over the iterator expression you generated before. Use print to print each element returned by the iterator. Use <strong class="inline">assert</strong> and <strong class="inline">isinstance</strong> to make sure that the elements are tuples:<p class="snippet">for number_tuple in permutations(range(3)):</p><p class="snippet">    print(number_tuple)</p><p class="snippet">    assert isinstance(number_tuple, tuple)</p><p>The output is as follows:</p><p class="snippet">(0, 1, 2)</p><p class="snippet">(0, 2, 1)</p><p class="snippet">(1, 0, 2)</p><p class="snippet">(1, 2, 0)</p><p class="snippet">(2, 0, 1)</p><p class="snippet">(2, 1, 0)</p></li>
				<li>Write the loop again. But this time, use <strong class="inline">dropwhile</strong> with a lambda expression to drop any leading zeros from the tuples. As an example, <strong class="inline">(0, 1, 2)</strong> will become <strong class="inline">[0, 2]</strong>. Also, cast the output of the <strong class="inline">dropwhile</strong> to a list.<p>An extra task can be to check the actual type that <strong class="inline">dropwhile</strong> returns without casting:</p><p class="snippet">for number_tuple in permutations(range(3)):</p><p class="snippet">    print(list(dropwhile(lambda x: x &lt;= 0, number_tuple)))</p><p>The output is as follows:</p><p class="snippet"><span class="mi">[1, 2]</span></p><p class="snippet"><span class="mi">[2, 1]</span></p><p class="snippet"><span class="mi">[1, 0, 2]</span></p><p class="snippet"><span class="mi">[1, 2, 0]</span></p><p class="snippet"><span class="mi">[2, 0, 1]</span></p><p class="snippet"><span class="mi">[2, 1, 0]</span></p></li>
				<li>Write all the logic you wrote before, but this time write a separate function where you will be passing the list generated from <strong class="inline">dropwhile</strong>, and the function will return the whole number contained in the list. As an example, if you pass <strong class="inline">[1, 2]</strong> to the function, it will return <strong class="inline">12</strong>. Make sure that the return type is indeed a number and not a string. Although this task can be achieved using other tricks, we require that you treat the incoming list as a stack in the function and generate the number there:<p class="snippet">import math</p><p class="snippet">def convert_to_number(number_stack):</p><p class="snippet">    final_number = 0</p><p class="snippet">    for i in range(0, len(number_stack)):</p><p class="snippet">        final_number += (number_stack.pop() * (math.pow(10, i)))</p><p class="snippet">    return final_number</p><p class="snippet">for number_tuple in permutations(range(3)):</p><p class="snippet">    number_stack = list(dropwhile(lambda x: x &lt;= 0, number_tuple))</p><p class="snippet">    print(convert_to_number(number_stack))</p><p>The output is as follows:</p><p class="snippet">12.0</p><p class="snippet">21.0</p><p class="snippet">102.0</p><p class="snippet">120.0</p><p class="snippet">201.0</p><p class="snippet">210.0</p></li>
			</ol>
			<h3 id="_idParaDest-285"><a id="_idTextAnchor340"/>Solution of Activity 4: Design Your Own CSV Parser</h3>
			<p>These are the steps to complete this activity:</p>
			<ol>
				<li value="1">Import <strong class="inline">zip_longest</strong> from <strong class="inline">itertools</strong>:<p class="snippet">from itertools import zip_longest</p></li>
				<li>Define the <strong class="inline">return_dict_from_csv_line</strong> function so that it contains <strong class="inline">header</strong>, <strong class="inline">line</strong>, and <strong class="inline">fillvalue</strong> as <strong class="inline">None</strong>, and add it to a <strong class="inline">dict</strong>:<p class="snippet">def return_dict_from_csv_line(header, line):</p><p class="snippet">    # Zip them</p><p class="snippet">    zipped_line = zip_longest(header, line, fillvalue=None)</p><p class="snippet">    # Use dict comprehension to generate the final dict</p><p class="snippet">    ret_dict = {kv[0]: kv[1] for kv in zipped_line}</p><p class="snippet">    return ret_dict</p></li>
				<li>Open the accompanying <strong class="inline">sales_record.csv</strong> file using <strong class="inline">r</strong> mode inside a with block. First, check that it is opened, read the first line, and use string methods to generate a list of all the column names with <strong class="inline">open("sales_record.csv", "r") as fd</strong>. When you read each line, pass that line to a function along with the list of the headers. The work of the function is to construct a dict out of these two and fill up the <strong class="inline">key:values</strong>. Keep in mind that a missing value should result in a <strong class="inline">None</strong>:<p class="snippet">    first_line = fd.readline()</p><p class="snippet">    header = first_line.replace("\n", "").split(",")</p><p class="snippet">    for i, line in enumerate(fd):</p><p class="snippet">        line = line.replace("\n", "").split(",")</p><p class="snippet">        d = return_dict_from_csv_line(header, line)</p><p class="snippet">        print(d)</p><p class="snippet">        if i &gt; 10:</p><p class="snippet">            break</p><p>The output is as follows:</p></li>
			</ol>
			<div>
				<div id="_idContainer282" class="IMG---Figure">
					<img src="Images/C11065_02_10.jpg" alt="Figure 2.10: Section of code" width="1096" height="136"/>
				</div>
			</div>
			<h6>Figure 2.10: Section of output</h6>
			<h3 id="_idParaDest-286"><a id="_idTextAnchor341"/>Solution of Activity 5: Generating Statistics from a CSV File</h3>
			<p>These are the steps to complete this activity:</p>
			<ol>
				<li value="1">Load the necessary libraries:<p class="snippet">import numpy as np</p><p class="snippet">import pandas as pd</p><p class="snippet">import matplotlib.pyplot as plt</p></li>
				<li>Read in the Boston housing dataset (given as a <strong class="inline">.csv</strong> file) from the local direction:<p class="snippet"># Hint: The Pandas function for reading a CSV file is 'read_csv'.</p><p class="snippet"># Don't forget that all functions in Pandas can be accessed by syntax like pd.{function_name} </p><p class="snippet">df=pd.read_csv("Boston_housing.csv")</p></li>
				<li>Check the first 10 records:<p class="snippet">df.head(10)</p><p>The output is as follows:</p><div id="_idContainer283" class="IMG---Figure"><img src="Images/C11065_03_23.jpg" alt="Figure 3.23: Output displaying the first 10 records" width="1449" height="645"/></div><h6>Figure 3.23: Output displaying the first 10 records</h6></li>
				<li>Find the total number of records:<p class="snippet">df.shape</p><p>The output is as follows:</p><p class="snippet">(506, 14)</p></li>
				<li>Create a smaller DataFrame with columns that do not include <strong class="inline">CHAS</strong>, <strong class="inline">NOX</strong>, <strong class="inline">B</strong>, and <strong class="inline">LSTAT</strong>:<p class="snippet">df1=df[['CRIM','ZN','INDUS','RM','AGE','DIS','RAD','TAX','PTRATIO','PRICE']]</p></li>
				<li>Check the last 7 records of the new DataFrame you just created:<p class="snippet">df1.tail(7)</p><p>The output is as follows:</p><div id="_idContainer284" class="IMG---Figure"><img src="Images/C11065_03_24.jpg" alt="Figure 3.24: Last seven records of the DataFrame" width="1088" height="477"/></div><h6>Figure 3.24: Last seven records of the DataFrame</h6></li>
				<li>Plot histograms of all the variables (columns) in the new DataFrame by using a <strong class="inline">for</strong> loop:<p class="snippet">for c in df1.columns:</p><p class="snippet">    plt.title("Plot of "+c,fontsize=15)</p><p class="snippet">    plt.hist(df1[c],bins=20)</p><p class="snippet">    plt.show()</p><p>The output is as follows:</p><div id="_idContainer285" class="IMG---Figure"><img src="Images/C11065_03_25.jpg" alt="Figure 3.25: Plot of all variables using a for loop" width="916" height="1111"/></div><h6>Figure 3.25: Plot of all variables using a for loop</h6></li>
				<li>Crime rate could be an indicator of house price (people don't want to live in high-crime areas). Create a scatter plot of crime rate versus price:<p class="snippet">plt.scatter(df1['CRIM'],df1['PRICE'])</p><p class="snippet">plt.show()</p><p>The output is as follows:</p><div id="_idContainer286" class="IMG---Figure"><img src="Images/C11065_03_26.jpg" alt="Figure 3.26: Scatter plot of crime rate versus price" width="614" height="252"/></div><h6>Figure 3.26: Scatter plot of crime rate versus price</h6><p>We can understand the relationship better if we plot log10(crime) versus price.</p></li>
				<li>Create that plot of log10(crime) versus price:<p class="snippet">plt.scatter(np.log10(df1['CRIM']),df1['PRICE'],c='red')</p><p class="snippet">plt.title("Crime rate (Log) vs. Price plot", fontsize=18)</p><p class="snippet">plt.xlabel("Log of Crime rate",fontsize=15)</p><p class="snippet">plt.ylabel("Price",fontsize=15)</p><p class="snippet">plt.grid(True)</p><p class="snippet">plt.show()</p><p>The output is as follows:</p><div id="_idContainer287" class="IMG---Figure"><img src="Images/C11065_03_27.jpg" alt="Figure 3.27: Scatter plot of crime rate (Log) versus price" width="669" height="287"/></div><h6>Figure 3.27: Scatter plot of crime rate (Log) versus price</h6></li>
				<li>Calculate the mean rooms per dwelling:<p class="snippet">df1['RM'].mean()</p><p>The output is <strong class="inline">6.284634387351788</strong>.</p></li>
				<li>Calculate the median age:<p class="snippet">df1['AGE'].median()</p><p>The output is <strong class="inline">77.5</strong>.</p></li>
				<li>Calculate the average (mean) distances to five Boston employment centers:<p class="snippet">df1['DIS'].mean()</p><p>The output is <strong class="inline">3.795042687747034</strong>.</p></li>
				<li>Calculate the percentage of houses with low price <em class="italics">(&lt; $20,000):</em><p class="snippet"># Create a Pandas series and directly compare it with 20</p><p class="snippet"># You can do this because Pandas series is basically NumPy array and you have seen how to filter NumPy array</p><p class="snippet">low_price=df1['PRICE']&lt;20</p><p class="snippet"># This creates a Boolean array of True, False</p><p class="snippet">print(low_price)</p><p class="snippet"># True = 1, False = 0, so now if you take an average of this NumPy array, you will know how many 1's are there.</p><p class="snippet"># That many houses are priced below 20,000. So that is the answer. </p><p class="snippet"># You can convert that into percentage by multiplying with 100</p><p class="snippet">pcnt=low_price.mean()*100</p><p class="snippet">print("\nPercentage of house with &lt;20,000 price is: ",pcnt)</p><p>The output is as follows:</p><p class="snippet">0      False</p><p class="snippet">1      False</p><p class="snippet">2      False</p><p class="snippet">3      False</p><p class="snippet">4      False</p><p class="snippet">5      False</p><p class="snippet">6      False</p><p class="snippet">7      False</p><p class="snippet">8       True</p><p class="snippet">9       True</p><p class="snippet">10      True</p><p class="snippet">…</p><p class="snippet">500     True</p><p class="snippet">501    False</p><p class="snippet">502    False</p><p class="snippet">503    False</p><p class="snippet">504    False</p><p class="snippet">505     True</p><p class="snippet">Name: PRICE, Length: 506, dtype: bool</p><p class="snippet">Percentage of house with &lt;20,000 price is:  41.50197628458498</p></li>
			</ol>
			<h3 id="_idParaDest-287"><a id="_idTextAnchor342"/>Solution of Activity 6: Working with the Adult Income Dataset (UCI)</h3>
			<p>These are the steps to complete this activity:</p>
			<ol>
				<li value="1">Load the necessary libraries:<p class="snippet">import numpy as np</p><p class="snippet">import pandas as pd</p><p class="snippet">import matplotlib.pyplot as plt</p></li>
				<li>Read in the adult income dataset (given as a <strong class="inline">.csv</strong> file) from the local directory and check the first 5 records:<p class="snippet">df = pd.read_csv("adult_income_data.csv")</p><p class="snippet">df.head()</p><p>The output is as follows:</p><div id="_idContainer288" class="IMG---Figure"><img src="Images/C11065_04_61.jpg" alt="Figure 4.61: DataFrame displaying the first five records from the .csv file" width="719" height="210"/></div><h6>Figure 4.61: DataFrame displaying the first five records from the .csv file</h6></li>
				<li>Create a script that will read a text file line by line and extracts the first line, which is the header of the .csv file:<p class="snippet">names = []</p><p class="snippet">with open('adult_income_names.txt','r') as f:</p><p class="snippet">    for line in f:</p><p class="snippet">        f.readline()</p><p class="snippet">        var=line.split(":")[0]</p><p class="snippet">        names.append(var)</p><p class="snippet">names</p><p>The output is as follows:</p><div id="_idContainer289" class="IMG---Figure"><img src="Images/C11065_04_62.jpg" alt="Figure 4.62: Names of the columns in the database" width="495" height="214"/></div><h6>Figure 4.62: Names of the columns in the database</h6></li>
				<li>Add a name of <strong class="inline">Income</strong> for the response variable (last column) to the dataset by using the <strong class="inline">append</strong> command:<p class="snippet">names.append('Income')</p></li>
				<li>Read the new file again using the following command:<p class="snippet">df = pd.read_csv("adult_income_data.csv",names=names)</p><p class="snippet">df.head()</p><p>The output is as follows:</p><div id="_idContainer290" class="IMG---Figure"><img src="Images/C11065_04_63.jpg" alt="" width="735" height="279"/></div><h6>Figure 4.63: DataFrame with the income column added</h6></li>
				<li>Use the <strong class="inline">describe</strong> command to get the statistical summary of the dataset:<p class="snippet">df.describe()</p><p>The output is as follows:</p><div id="_idContainer291" class="IMG---Figure"><img src="Images/C11065_04_64.jpg" alt="" width="931" height="367"/></div><h6>Figure 4.64: Statistical summary of the dataset</h6><p>Note that only a small number of columns are included. Many variables in the dataset have multiple factors or classes.</p></li>
				<li>Make a list of all the variables in the classes by using the following command:<p class="snippet"># Make a list of all variables with classes</p><p class="snippet">vars_class = ['workclass','education','marital-status',</p><p class="snippet">              'occupation','relationship','sex','native-country']</p></li>
				<li>Create a loop to count and print them by using the following command:<p class="snippet">for v in vars_class:</p><p class="snippet">    classes=df[v].unique()</p><p class="snippet">    num_classes = df[v].nunique()</p><p class="snippet">    print("There are {} classes in the \"{}\" column. They are: {}".format(num_classes,v,classes))</p><p class="snippet">    print("-"*100)</p><p>The output is as follows:</p><div id="_idContainer292" class="IMG---Figure"><img src="Images/C11065_04_65.jpg" alt="Figure 4.65: Output of different factors or classes" width="935" height="526"/></div><h6>Figure 4.65: Output of different factors or classes</h6></li>
				<li>Find the missing values by using the following command:<p class="snippet">df.isnull().sum()</p><p>The output is as follows:</p><div id="_idContainer293" class="IMG---Figure"><img src="Images/C11065_04_66.jpg" alt="Figure 4.66: Finding the missing values" width="536" height="241"/></div><h6>Figure 4.66: Finding the missing values</h6></li>
				<li>Create a DataFrame with only age, education, and occupation by using subsetting:<p class="snippet">df_subset = df[['age','education','occupation']]</p><p class="snippet">df_subset.head()</p><p>The output is as follows:</p><div id="_idContainer294" class="IMG---Figure"><img src="Images/C11065_04_67.jpg" alt="Fig 4.67: Subset DataFrame" width="531" height="142"/></div><h6>Figure 4.67: Subset DataFrame</h6></li>
				<li>Plot a histogram of age with a bin size of 20:<p class="snippet">df_subset['age'].hist(bins=20)</p><p>The output is as follows:</p><p class="snippet">&lt;matplotlib.axes._subplots.AxesSubplot at 0x19dea8d0&gt;</p><div id="_idContainer295" class="IMG---Figure"><img src="Images/C11065_04_68.jpg" alt="Figure 4.68: Histogram of age with a bin size of 20" width="525" height="252"/></div><h6>Figure 4.68: Histogram of age with a bin size of 20</h6></li>
				<li>Plot boxplots for <strong class="inline">age</strong> grouped by <strong class="inline">education</strong> (use a long figure size 25x10 and make x ticks font size 15):<p class="snippet">df_subset.boxplot(column='age',by='education',figsize=(25,10))</p><p class="snippet">plt.xticks(fontsize=15)</p><p class="snippet">plt.xlabel("Education",fontsize=20)</p><p class="snippet">plt.show()</p><p>The output is as follows:</p><div id="_idContainer296" class="IMG---Figure"><img src="Images/C11065_04_69.jpg" alt="Figure 4.69: Boxplot of age grouped by education" width="1482" height="656"/></div><h6>Figure 4.69: Boxplot of age grouped by education</h6><p>Before doing any further operations, we need to use the <strong class="inline">apply</strong> method we learned in this chapter. It turns out that when reading the dataset from the CSV file, all the strings came with a whitespace character in front. So, we need to remove that whitespace from all the strings.</p></li>
				<li>Create a function to strip the whitespace characters:<p class="snippet">def strip_whitespace(s):</p><p class="snippet">    return s.strip()</p></li>
				<li>Use the <strong class="inline">apply</strong> method to apply this function to all the columns with string values, create a new column, copy the values from this new column to the old column, and drop the new column. This is the preferred method so that you don't accidentally delete valuable data. Most of the time, you will need to create a new column with a desired operation and then copy it back to the old column if necessary. Ignore any warning messages that are printed:<p class="snippet"># Education column</p><p class="snippet">df_subset['education_stripped']=df['education'].apply(strip_whitespace)</p><p class="snippet">df_subset['education']=df_subset['education_stripped']</p><p class="snippet">df_subset.drop(labels=['education_stripped'],axis=1,inplace=True)</p><p class="snippet"># Occupation column</p><p class="snippet">df_subset['occupation_stripped']=df['occupation'].apply(strip_whitespace)</p><p class="snippet">df_subset['occupation']=df_subset['occupation_stripped']</p><p class="snippet">df_subset.drop(labels=['occupation_stripped'],axis=1,inplace=True)</p><p>This is the sample warning message, which you should ignore:</p><div id="_idContainer297" class="IMG---Figure"><img src="Images/C11065_04_70.jpg" alt="Figure 4.70: Warning message to be ignored" width="786" height="347"/></div><h6>Figure 4.70: Warning message to be ignored</h6></li>
				<li>Find the number of people who are aged between 30 and 50 (inclusive) by using the following command:<p class="snippet"># Conditional clauses and join them by &amp; (AND) </p><p class="snippet">df_filtered=df_subset[(df_subset['age']&gt;=30) &amp; (df_subset['age']&lt;=50)]</p><p>Check the contents of the new dataset:</p><p class="snippet">df_filtered.head()</p><p>The output is as follows:</p><div id="_idContainer298" class="IMG---Figure"><img src="Images/C11065_04_71.jpg" alt="Figure 4.71: Contents of new DataFrame" width="844" height="254"/></div><h6>Figure 4.71: Contents of new DataFrame</h6></li>
				<li>Find the <strong class="inline">shape</strong> of the filtered DataFrame and specify the index of the tuple as 0 to return the first element:<p class="snippet">answer_1=df_filtered.shape[0]</p><p class="snippet">answer_1</p><p>The output is as follows:</p><p class="snippet">1630</p></li>
				<li>Print the number of black people aged between 30 and 50 using the following command:<p class="snippet">print("There are {} people of age between 30 and 50 in this dataset.".format(answer_1))</p><p>The output is as follows:</p><p class="snippet">There are 1630 black of age between 30 and 50 in this dataset.</p></li>
				<li>Group the records based on occupation to find how the mean age is distributed:<p class="snippet">df_subset.groupby('occupation').describe()['age']</p><p>The output is as follows:</p><div id="_idContainer299" class="IMG---Figure"><img src="Images/C11065_04_72.jpg" alt="Figure 4.72: DataFrame with data grouped by age and education" width="615" height="386"/></div><h6>Figure 4.72: DataFrame with data grouped by age and education</h6><p>The code returns <strong class="inline">79 rows × 1 columns.</strong></p></li>
				<li>Group by occupation and show the summary statistics of age. Find which profession has the oldest workers on average and which profession has its largest share of workforce above the 75th percentile:<p class="snippet">df_subset.groupby('occupation').describe()['age']</p><p>The output is as follows:</p><div id="_idContainer300" class="IMG---Figure"><img src="Images/C11065_04_73.jpg" alt="Figure 4.73: DataFrame showing summary statistics of age" width="668" height="376"/></div><h6>Figure 4.73: DataFrame showing summary statistics of age</h6><p>Is there a particular occupation group that has very low representation? Perhaps we should remove those pieces of data because with very low data, the group won't be useful in analysis. Actually, just by looking at the preceding table, you should be able to see that the <strong class="bold">Armed-Forces</strong> group has only got a 9 count, that is, 9 data points. But how can we detect this? By plotting the count column in a bar chart. Note how the first argument to the <strong class="inline">barh</strong> function is the index of the DataFrame, which is the summary stats of the occupation groups. We can see that the <strong class="bold">Armed-Forces</strong> group has almost no data. This exercise teaches you that, sometimes, the outlier is not just a value, but can be a whole group. The data of this group is fine, but it is too small to be useful for any analysis. So, it can be treated as an outlier in this case. But always use your business knowledge and engineering judgement for such outlier detection and how to process them.</p></li>
				<li>Use subset and groupby to find the outliers:<p class="snippet">occupation_stats= df_subset.groupby(</p><p class="snippet">    'occupation').describe()['age']</p></li>
				<li>Plot the values on a bar chart:<p class="snippet">plt.figure(figsize=(15,8))</p><p class="snippet">plt.barh(y=occupation_stats.index,</p><p class="snippet">         width=occupation_stats['count'])</p><p class="snippet">plt.yticks(fontsize=13)</p><p class="snippet">plt.show()</p><p>The output is as follows:</p><div id="_idContainer301" class="IMG---Figure"><img src="Images/C11065_04_74.jpg" alt="Figure 4.74: Bar chart displaying occupation statistics" width="981" height="469"/></div><h6>Figure 4.74: Bar chart displaying occupation statistics</h6></li>
				<li>Practice merging by common keys. Suppose you are given two datasets where the common key is <strong class="inline">occupation</strong>. First, create two such disjoint datasets by taking random samples from the full dataset and then try merging. Include at least two other columns, along with the common key column for each dataset. Notice how the resulting dataset, after merging, may have more data points than either of the two starting datasets if your common key is not unique:<p class="snippet">df_1 = df[['age',</p><p class="snippet">           'workclass',</p><p class="snippet">           'occupation']].sample(5,random_state=101)</p><p class="snippet">df_1.head()</p><p>The output is as follows:</p></li>
			</ol>
			<div>
				<div id="_idContainer302" class="IMG---Figure">
					<img src="Images/C11065_04_75.jpg" alt="" width="453" height="144"/>
				</div>
			</div>
			<h6>Figure 4.75: Output after merging the common keys</h6>
			<p>The second dataset is as follows:</p>
			<p class="snippet">df_2 = df[['education',</p>
			<p class="snippet">           'occupation']].sample(5,random_state=101)</p>
			<p class="snippet">df_2.head()</p>
			<p>The output is as follows:</p>
			<div>
				<div id="_idContainer303" class="IMG---Figure">
					<img src="Images/C11065_04_76.jpg" alt="" width="515" height="148"/>
				</div>
			</div>
			<h6>Figure 4.76: Output after merging the common keys</h6>
			<p>Merging the two datasets together:</p>
			<p class="snippet">df_merged = pd.merge(df_1,df_2,</p>
			<p class="snippet">                     on='occupation',</p>
			<p class="snippet">                     how='inner').drop_duplicates()</p>
			<p class="snippet">df_merged</p>
			<p>The output is as follows:</p>
			<div>
				<div id="_idContainer304" class="IMG---Figure">
					<img src="Images/C11065_04_77.jpg" alt="" width="501" height="150"/>
				</div>
			</div>
			<h6>Figure 4.77: Output of distinct occupation values</h6>
			<h3 id="_idParaDest-288"><a id="_idTextAnchor343"/>Solution of Activity 7: Reading Tabular Data from a Web Page and Creating DataFrames</h3>
			<p>These are the steps to complete this activity:</p>
			<ol>
				<li value="1">Import BeautifulSoup and load the data by using the following command:<p class="snippet">from bs4 import BeautifulSoup</p><p class="snippet">import pandas as pd</p></li>
				<li>Open the Wikipedia file by using the following command:<p class="snippet">fd = open("List of countries by GDP (nominal) - Wikipedia.htm", "r")</p><p class="snippet">soup = BeautifulSoup(fd)</p><p class="snippet">fd.close()</p></li>
				<li>Calculate the tables by using the following command:<p class="snippet">all_tables = soup.find_all("table")</p><p class="snippet">print("Total number of tables are {} ".format(len(all_tables)))</p><p>There are 9 tables in total.</p></li>
				<li>Find the right table using the class attribute by using the following command:<p class="snippet">data_table = soup.find("table", {"class": '"wikitable"|}'})</p><p class="snippet">print(type(data_table))</p><p>The output is as follows:</p><p class="snippet">&lt;class 'bs4.element.Tag'&gt;</p></li>
				<li>Separate the source and the actual data by using the following command:<p class="snippet">sources = data_table.tbody.findAll('tr', recursive=False)[0]</p><p class="snippet">sources_list = [td for td in sources.findAll('td')]</p><p class="snippet">print(len(sources_list))</p><p>The output is as follows:</p><p class="snippet">Total number of tables are <strong class="inline">3.</strong></p></li>
				<li>Use <strong class="inline">findAll</strong> function to find the data from the <strong class="inline">data_table</strong>'s <strong class="inline">body</strong> tag, using the following command:<p class="snippet">data = data_table.tbody.findAll('tr', recursive=False)[1].findAll('td', recursive=False)</p></li>
				<li>Use the <strong class="inline">findAll</strong> function to find the data from the <strong class="inline">data_table</strong> <strong class="inline">td</strong> tag by using the following command:<p class="snippet">data_tables = []</p><p class="snippet">for td in data:</p><p class="snippet">    data_tables.append(td.findAll('table'))</p></li>
				<li>Find the length of <strong class="inline">data_tables</strong> by using the following command:<p class="snippet">len(data_tables)</p><p>The output is as follows:</p><p class="snippet">3</p></li>
				<li>Check how to get the source names by using the following command:<p class="snippet">source_names = [source.findAll('a')[0].getText() for source in sources_list]</p><p class="snippet">print(source_names)</p><p>The output is as follows:</p><p class="snippet"> ['International Monetary Fund', 'World Bank', 'United Nations']</p></li>
				<li>Separate the header and data for the first source:<p class="snippet">header1 = [th.getText().strip() for th in data_tables[0][0].findAll('thead')[0].findAll('th')]</p><p class="snippet">header1</p><p>The output is as follows:</p><p class="snippet"> ['Rank', 'Country', 'GDP(US$MM)']</p></li>
				<li>Find the rows from <strong class="inline">data_tables</strong> using <strong class="inline">findAll</strong>:<p class="snippet">rows1 = data_tables[0][0].findAll('tbody')[0].findAll('tr')[1:]</p></li>
				<li>Find the data from <strong class="inline">rows1</strong> using the <strong class="inline">strip</strong> function for each <strong class="inline">td</strong> tag:<p class="snippet">data_rows1 = [[td.get_text().strip() for td in tr.findAll('td')] for tr in rows1]</p></li>
				<li>Find the DataFrame:<p class="snippet">df1 = pd.DataFrame(data_rows1, columns=header1)</p><p class="snippet">df1.head()</p><p>The output is as follows:</p><div id="_idContainer305" class="IMG---Figure"><img src="Images/C11065_05_351.jpg" alt="Figure 5.35: DataFrame" width="568" height="184"/></div><h6>Figure 5.35: DataFrame created from Web page</h6></li>
				<li>Do the same for the other two sources by using the following command:<p class="snippet">header2 = [th.getText().strip() for th in data_tables[1][0].findAll('thead')[0].findAll('th')]</p><p class="snippet">header2</p><p>The output is as follows:</p><p class="snippet"> <strong class="inline">['Rank', 'Country', 'GDP(US$MM)']</strong></p></li>
				<li>Find the rows from <strong class="inline">data_tables</strong> using <strong class="inline">findAll</strong> by using the following command:<p class="snippet">rows2 = data_tables[1][0].findAll('tbody')[0].findAll('tr')[1:]</p></li>
				<li>Define <strong class="inline">find_right_text</strong> using the <strong class="inline">strip</strong> function by using the following command:<p class="snippet">def find_right_text(i, td):</p><p class="snippet">    if i == 0:</p><p class="snippet">        return td.getText().strip()</p><p class="snippet">    elif i == 1:</p><p class="snippet">        return td.getText().strip()</p><p class="snippet">    else:</p><p class="snippet">        index = td.text.find("♠")</p><p class="snippet">        return td.text[index+1:].strip()</p></li>
				<li>Find the rows from <strong class="inline">data_rows</strong> using <strong class="inline">find_right_text</strong> by using the following command:<p class="snippet">data_rows2 = [[find_right_text(i, td) for i, td in enumerate(tr.findAll('td'))] for tr in rows2]</p></li>
				<li>Calculate the <strong class="inline">df2</strong> DataFrame by using the following command:<p class="snippet">df2 = pd.DataFrame(data_rows2, columns=header2)</p><p class="snippet">df2.head()</p><p>The output is as follows:</p><div id="_idContainer306" class="IMG---Figure"><img src="Images/C11065_05_44.jpg" alt="Figure 5.36: Output of the DataFrame&#13;&#10;" width="623" height="182"/></div><h6>Figure 5.36: Output of the DataFrame</h6></li>
				<li>Now, perform the same operations for the third DataFrame by using the following command:<p class="snippet">header3 = [th.getText().strip() for th in data_tables[2][0].findAll('thead')[0].findAll('th')]</p><p class="snippet">header3</p><p>The output is as follows:</p><p class="snippet"><strong class="inline">['Rank', 'Country', 'GDP(US$MM)']</strong></p></li>
				<li>Find the rows from <strong class="inline">data_tables</strong> using <strong class="inline">findAll</strong> by using the following command:<p class="snippet">rows3 = data_tables[2][0].findAll('tbody')[0].findAll('tr')[1:]</p></li>
				<li>Find the rows from <strong class="inline">data_rows3</strong> by using <strong class="inline">find_right_text</strong>:<p class="snippet">data_rows3 = [[find_right_text(i, td) for i, td in enumerate(tr.findAll('td'))] for tr in rows2]</p></li>
				<li>Calculate the <strong class="inline">df3</strong> DataFrame by using the following command:<p class="snippet">df3 = pd.DataFrame(data_rows3, columns=header3)</p><p class="snippet">df3.head()</p><p>The output is as follows:</p></li>
			</ol>
			<div>
				<div id="_idContainer307" class="IMG---Figure">
					<img src="Images/C11065_05_55.jpg" alt="Figure 5.37: The third DataFrame&#13;&#10;" width="535" height="181"/>
				</div>
			</div>
			<h6>Figure 5.37: The third DataFrame</h6>
			<h3 id="_idParaDest-289"><a id="_idTextAnchor344"/>Solution of Activity 8: Handling Outliers and Missing Data </h3>
			<p>These are the steps to complete this activity:</p>
			<ol>
				<li value="1">Load the data:<p class="snippet">import pandas as pd</p><p class="snippet">import numpy as np</p><p class="snippet">import matplotlib.pyplot as plt</p><p class="snippet">%matplotlib inline</p></li>
				<li>Read the .csv file:<p class="snippet">df = pd.read_csv("visit_data.csv")</p></li>
				<li>Print the data from the DataFrame:<p class="snippet">df.head()</p><p>The output is as follows:</p><div id="_idContainer308" class="IMG---Figure"><img src="Images/C11065_06_10.jpg" alt="Figure 6.10: The contents of the CSV file" width="538" height="152"/></div><h6>Figure 6.10: The contents of the CSV file</h6><p>As we can see, there is data where some values are missing, and if we examine this, we will see some outliers.</p></li>
				<li>Check for duplicates by using the following command:<p class="snippet">print("First name is duplicated - {}".format(any(df.first_name.duplicated())))</p><p class="snippet">print("Last name is duplicated - {}".format(any(df.last_name.duplicated())))</p><p class="snippet">print("Email is duplicated - {}".format(any(df.email.duplicated())))</p><p>The output is as follows:</p><p class="snippet">First name is duplicated - True</p><p class="snippet">Last name is duplicated - True</p><p class="snippet">Email is duplicated - False</p><p>There are duplicates in both the first and last names, which is normal. However, as we can see, there is no duplicate in email. That's good.</p></li>
				<li>Check if any essential column contains <strong class="inline">NaN</strong>:<p class="snippet"># Notice that we have different ways to format boolean values for the % operator</p><p class="snippet">print("The column Email contains NaN - %r " % df.email.isnull().values.any())</p><p class="snippet">print("The column IP Address contains NaN - %s " % df.ip_address.isnull().values.any())</p><p class="snippet">print("The column Visit contains NaN - %s " % df.visit.isnull().values.any())</p><p>The output is as follows:</p><p class="snippet">The column Email contains NaN - False </p><p class="snippet">The column IP Address contains NaN - False </p><p class="snippet">The column Visit contains NaN - True </p><p>The column visit contains some None values. Given that the final task at hand will probably be predicting the number of visits, we cannot do anything with rows that do not have that information. They are a type of outlier. Let's get rid of them.</p></li>
				<li>Get rid of the outliers:<p class="snippet"># There are various ways to do this. This is just one way. We encourage you to explore other ways.</p><p class="snippet"># But before that we need to store the previous size of the data set and we will compare it with the new size</p><p class="snippet">size_prev = df.shape</p><p class="snippet">df = df[np.isfinite(df['visit'])] #This is an inplace operation. After this operation the original DataFrame is lost.</p><p class="snippet">size_after = df.shape</p></li>
				<li>Report the size difference:<p class="snippet"># Notice how parameterized format is used and then the indexing is working inside the quote marks</p><p class="snippet">print("The size of previous data was - {prev[0]} rows and the size of the new one is - {after[0]} rows".</p><p class="snippet">format(prev=size_prev, after=size_after))</p><p>The output is as follows:</p><p class="snippet">The size of previous data was - 1000 rows and the size of the new one is - 974 rows</p></li>
				<li>Plot a boxplot to find if the data has outliers.<p class="snippet">plt.boxplot(df.visit, notch=True)</p><p>The output is as follows:</p><p class="snippet">{'whiskers': [&lt;matplotlib.lines.Line2D at 0x7fa04cc08668&gt;,</p><p class="snippet">  &lt;matplotlib.lines.Line2D at 0x7fa04cc08b00&gt;],</p><p class="snippet"> 'caps': [&lt;matplotlib.lines.Line2D at 0x7fa04cc08f28&gt;,</p><p class="snippet">  &lt;matplotlib.lines.Line2D at 0x7fa04cc11390&gt;],</p><p class="snippet"> 'boxes': [&lt;matplotlib.lines.Line2D at 0x7fa04cc08518&gt;],</p><p class="snippet"> 'medians': [&lt;matplotlib.lines.Line2D at 0x7fa04cc117b8&gt;],</p><p class="snippet"> 'fliers': [&lt;matplotlib.lines.Line2D at 0x7fa04cc11be0&gt;],</p><p class="snippet"> 'means': []}</p><p>The boxplot is as follows:</p><div id="_idContainer309" class="IMG---Figure"><img src="Images/C11065_06_43.jpg" alt="Figure 6.43: Boxplot using the data" width="528" height="240"/></div><h6>Figure 6.43: Boxplot using the data</h6><p>As we can see, we have data in this column in the interval (0, 3000). However, the main concentration of the data is between ~700 and ~2300. </p></li>
				<li>Get rid of values beyond 2900 and below 100 – these are outliers for us. We need to get rid of them:<p class="snippet">df1 = df[(df['visit'] &lt;= 2900) &amp; (df['visit'] &gt;= 100)]  # Notice the powerful &amp; operator</p><p class="snippet"># Here we abuse the fact the number of variable can be greater than the number of replacement targets</p><p class="snippet">print("After getting rid of outliers the new size of the data is - {}".format(*df1.shape))</p><p>After getting rid of the outliers, the new size of the data is <strong class="inline">923.</strong></p><p>This is the end of the activity for this chapter.</p></li>
			</ol>
			<h3 id="_idParaDest-290"><a id="_idTextAnchor345"/>Solution of Activity 9: Extracting the Top 100 eBooks from Gutenberg</h3>
			<p>These are the steps to complete this activity:</p>
			<ol>
				<li value="1">Import the necessary libraries, including <strong class="inline">regex</strong> and <strong class="inline">beautifulsoup:</strong><p class="snippet">import urllib.request, urllib.parse, urllib.error</p><p class="snippet">import requests</p><p class="snippet">from bs4 import BeautifulSoup</p><p class="snippet">import ssl</p><p class="snippet">import re</p></li>
				<li>Check the SSL certificate:<p class="snippet"># Ignore SSL certificate errors</p><p class="snippet">ctx = ssl.create_default_context()</p><p class="snippet">ctx.check_hostname = False</p><p class="snippet">ctx.verify_mode = ssl.CERT_NONE</p></li>
				<li>Read the HTML from the URL:<p class="snippet"># Read the HTML from the URL and pass on to BeautifulSoup</p><p class="snippet">top100url = 'https://www.gutenberg.org/browse/scores/top'</p><p class="snippet">response = requests.get(top100url)</p></li>
				<li>Write a small function to check the status of the web request:<p class="snippet">def status_check(r):</p><p class="snippet">    if r.status_code==200:</p><p class="snippet">        print("Success!")</p><p class="snippet">        return 1</p><p class="snippet">    else:</p><p class="snippet">        print("Failed!")</p><p class="snippet">        return -1</p></li>
				<li>Check the status of <strong class="inline">response</strong>:<p class="snippet">status_check(response)</p><p>The output is as follows:</p><p class="snippet">Success!</p><p class="snippet">1</p></li>
				<li>Decode the response and pass it on to <strong class="inline">BeautifulSoup</strong> for HTML parsing:<p class="snippet">contents = response.content.decode(response.encoding)</p><p class="snippet">soup = BeautifulSoup(contents, 'html.parser')</p></li>
				<li>Find all the <strong class="inline">href</strong> tags and store them in the list of links. Check what the list looks like – print the first 30 elements:<p class="snippet"># Empty list to hold all the http links in the HTML page</p><p class="snippet">lst_links=[]</p><p class="snippet"># Find all the href tags and store them in the list of links</p><p class="snippet">for link in soup.find_all('a'):</p><p class="snippet">    #print(link.get('href'))</p><p class="snippet">    lst_links.append(link.get('href'))</p></li>
				<li>Print the links by using the following command:<p class="snippet">lst_links[:30]</p><p>The output is as follows:</p><p class="snippet">['/wiki/Main_Page',</p><p class="snippet"> '/catalog/',</p><p class="snippet"> '/ebooks/',</p><p class="snippet"> '/browse/recent/last1',</p><p class="snippet"> '/browse/scores/top',</p><p class="snippet"> '/wiki/Gutenberg:Offline_Catalogs',</p><p class="snippet"> '/catalog/world/mybookmarks',</p><p class="snippet"> '/wiki/Main_Page',</p><p class="snippet">'https://www.paypal.com/xclick/business=donate%40gutenberg.org&amp;item_name=Donation+to+Project+Gutenberg',</p><p class="snippet"> '/wiki/Gutenberg:Project_Gutenberg_Needs_Your_Donation',</p><p class="snippet"> 'http://www.ibiblio.org',</p><p class="snippet"> 'http://www.pgdp.net/',</p><p class="snippet"> 'pretty-pictures',</p><p class="snippet"> '#books-last1',</p><p class="snippet"> '#authors-last1',</p><p class="snippet"> '#books-last7',</p><p class="snippet"> '#authors-last7',</p><p class="snippet"> '#books-last30',</p><p class="snippet"> '#authors-last30',</p><p class="snippet"> '/ebooks/1342',</p><p class="snippet"> '/ebooks/84',</p><p class="snippet"> '/ebooks/1080',</p><p class="snippet"> '/ebooks/46',</p><p class="snippet"> '/ebooks/219',</p><p class="snippet"> '/ebooks/2542',</p><p class="snippet"> '/ebooks/98',</p><p class="snippet"> '/ebooks/345',</p><p class="snippet"> '/ebooks/2701',</p><p class="snippet"> '/ebooks/844',</p><p class="snippet"> '/ebooks/11']</p></li>
				<li>Use a regular expression to find the numeric digits in these links. These are the file numbers for the top 100 books. Initialize the empty list to hold the file numbers:<p class="snippet">booknum=[]</p></li>
				<li>Numbers 19 to 118 in the original list of links have the top 100 eBooks' numbers. Loop over the appropriate range and use a regex to find the numeric digits in the link (href) string. Use the <strong class="inline">findall()</strong> method:<p class="snippet">for i in range(19,119):</p><p class="snippet">    link=lst_links[i]</p><p class="snippet">    link=link.strip()</p><p class="snippet">    # Regular expression to find the numeric digits in the link (href) string</p><p class="snippet">    n=re.findall('[0-9]+',link)</p><p class="snippet">    if len(n)==1:</p><p class="snippet">        # Append the filenumber casted as integer</p><p class="snippet">        booknum.append(int(n[0]))</p></li>
				<li>Print the file numbers:<p class="snippet">print ("\nThe file numbers for the top 100 ebooks on Gutenberg are shown below\n"+"-"*70)</p><p class="snippet">print(booknum)</p><p>The output is as follows:</p><p class="snippet">The file numbers for the top 100 ebooks on Gutenberg are shown below</p><p class="snippet">----------------------------------------------------------------------</p><p class="snippet">[1342, 84, 1080, 46, 219, 2542, 98, 345, 2701, 844, 11, 5200, 43, 16328, 76, 74, 1952, 6130, 2591, 1661, 41, 174, 23, 1260, 1497, 408, 3207, 1400, 30254, 58271, 1232, 25344, 58269, 158, 44881, 1322, 205, 2554, 1184, 2600, 120, 16, 58276, 5740, 34901, 28054, 829, 33, 2814, 4300, 100, 55, 160, 1404, 786, 58267, 3600, 19942, 8800, 514, 244, 2500, 2852, 135, 768, 58263, 1251, 3825, 779, 58262, 203, 730, 20203, 35, 1250, 45, 161, 30360, 7370, 58274, 209, 27827, 58256, 33283, 4363, 375, 996, 58270, 521, 58268, 36, 815, 1934, 3296, 58279, 105, 2148, 932, 1064, 13415]</p></li>
				<li>What does the soup object's text look like? Use the .<strong class="inline">text</strong> method and print only the first 2,000 characters (do not print the whole thing as it is too long).<p>You will notice a lot of empty spaces/blanks here and there. Ignore them. They are part of the HTML page's markup and its whimsical nature:</p><p class="snippet">print(soup.text[:2000])</p><p class="snippet">if (top != self) {</p><p class="snippet">        top.location.replace (<a href="http://www.gutenberg.org">http://www.gutenberg.org</a>);</p><p class="snippet">        alert ('Project Gutenberg is a FREE service with NO membership required. If you paid somebody else to get here, make them give you your money back!');</p><p class="snippet">      }</p><p class="snippet">    </p><p>The output is as follows:</p><p class="snippet">Top 100 - Project Gutenberg</p><p class="snippet">Online Book Catalog</p><p class="snippet"> Book  Search</p><p class="snippet">-- Recent  Books</p><p class="snippet">-- Top  100</p><p class="snippet">-- Offline Catalogs</p><p class="snippet">-- My Bookmarks</p><p class="snippet">Main Page</p><p class="snippet">…</p><p class="snippet">Pretty Pictures</p><p class="snippet">Top 100 EBooks yesterday —</p><p class="snippet">  Top 100 Authors yesterday —</p><p class="snippet">  Top 100 EBooks last 7 days —</p><p class="snippet">  Top 100 Authors last 7 days —</p><p class="snippet">  Top 100 EBooks last 30 days —</p><p class="snippet">  Top 100 Authors last 30 days</p><p class="snippet">Top 100 EBooks yesterday</p><p class="snippet">Pride and Prejudice by Jane Austen (1826)</p><p class="snippet">Frankenstein; Or, The Modern Prometheus by Mary Wollstonecraft Shelley (1367)</p><p class="snippet">A Modest Proposal by Jonathan Swift (1020)</p><p class="snippet">A Christmas Carol in Prose; Being a Ghost Story of Christmas by Charles Dickens (953)</p><p class="snippet">Heart of Darkness by Joseph Conrad (887)</p><p class="snippet">Et dukkehjem. English by Henrik Ibsen (761)</p><p class="snippet">A Tale of Two Cities by Charles Dickens (741)</p><p class="snippet">Dracula by Bram Stoker (732)</p><p class="snippet">Moby Dick; Or, The Whale by Herman Melville (651)</p><p class="snippet">The Importance of Being Earnest: A Trivial Comedy for Serious People by Oscar Wilde (646)</p><p class="snippet">Alice's Adventures in Wonderland by Lewis Carrol</p></li>
				<li>Search the extracted text (using regular expression) from the soup object to find the names of top 100 eBooks (yesterday's rank):<p class="snippet"># Temp empty list of Ebook names</p><p class="snippet">lst_titles_temp=[]</p></li>
				<li>Create a starting index. It should point at the text <strong class="bold">Top 100 Ebooks yesterday</strong>. Use the <strong class="inline">splitlines</strong> method of <strong class="inline">soup.text</strong>. It splits the lines of the text of the soup object:<p class="snippet">start_idx=soup.text.splitlines().index('Top 100 EBooks yesterday')</p></li>
				<li>Loop 1-100 to add the strings of the next 100 lines to this temporary list. Hint: use the <strong class="inline">splitlines</strong> method:<p class="snippet">for i in range(100):</p><p class="snippet">    lst_titles_temp.append(soup.text.splitlines()[start_idx+2+i])</p></li>
				<li>Use a regular expression to extract only text from the name strings and append them to an empty list. Use match and span to find the indices and use them:<p class="snippet">lst_titles=[]</p><p class="snippet">for i in range(100):</p><p class="snippet">    id1,id2=re.match('^[a-zA-Z ]*',lst_titles_temp[i]).span()</p><p class="snippet">    lst_titles.append(lst_titles_temp[i][id1:id2])</p></li>
				<li>Print the list of titles:<p class="snippet">for l in lst_titles:</p><p class="snippet">    print(l)</p><p>The output is as follows:</p><p class="snippet">Pride and Prejudice by Jane Austen </p><p class="snippet">Frankenstein</p><p class="snippet">A Modest Proposal by Jonathan Swift </p><p class="snippet">A Christmas Carol in Prose</p><p class="snippet">Heart of Darkness by Joseph Conrad </p><p class="snippet">Et dukkehjem</p><p class="snippet">A Tale of Two Cities by Charles Dickens </p><p class="snippet">Dracula by Bram Stoker </p><p class="snippet">Moby Dick</p><p class="snippet">The Importance of Being Earnest</p><p class="snippet">Alice</p><p class="snippet">Metamorphosis by Franz Kafka </p><p class="snippet">The Strange Case of Dr</p><p class="snippet">Beowulf</p><p class="snippet">…</p><p class="snippet">The Russian Army and the Japanese War</p><p class="snippet">Calculus Made Easy by Silvanus P</p><p class="snippet">Beyond Good and Evil by Friedrich Wilhelm Nietzsche </p><p class="snippet">An Occurrence at Owl Creek Bridge by Ambrose Bierce </p><p class="snippet">Don Quixote by Miguel de Cervantes Saavedra </p><p class="snippet">Blue Jackets by Edward Greey </p><p class="snippet">The Life and Adventures of Robinson Crusoe by Daniel Defoe </p><p class="snippet">The Waterloo Campaign </p><p class="snippet">The War of the Worlds by H</p><p class="snippet">Democracy in America </p><p class="snippet">Songs of Innocence</p><p class="snippet">The Confessions of St</p><p class="snippet">Modern French Masters by Marie Van Vorst </p><p class="snippet">Persuasion by Jane Austen </p><p class="snippet">The Works of Edgar Allan Poe </p><p class="snippet">The Fall of the House of Usher by Edgar Allan Poe </p><p class="snippet">The Masque of the Red Death by Edgar Allan Poe </p><p class="snippet">The Lady with the Dog and Other Stories by Anton Pavlovich Chekhov</p></li>
			</ol>
			<h3 id="_idParaDest-291"><a id="_idTextAnchor346"/>Solution of Activity 10: Extracting the top 100 eBooks from Gutenberg.org</h3>
			<p>These are the steps to complete this activity:</p>
			<ol>
				<li value="1">Import <strong class="inline">urllib.request</strong>, <strong class="inline">urllib.parse</strong>, <strong class="inline">urllib.error</strong>, and <strong class="inline">json</strong>:<p class="snippet">import urllib.request, urllib.parse, urllib.error</p><p class="snippet">import json</p></li>
				<li>Load the secret API key (you have to get one from the OMDB website and use that; it has a 1,000 daily limit) from a JSON file, stored in the same folder into a variable, by using <strong class="inline">json.loads()</strong>: <h4>Note</h4><p class="callout">The following cell will not be executed in the solution notebook because the author cannot give out their private API key.</p></li>
				<li>The students/users/instructor will need to obtain a key and store it in a JSON file. We are calling this file <strong class="inline">APIkeys.json</strong>. </li>
				<li>Open the <strong class="inline">APIkeys.json</strong> file by using the following command:<p class="snippet">with open('APIkeys.json') as f:</p><p class="snippet">    keys = json.load(f)</p><p class="snippet">    omdbapi = keys['OMDBapi']</p><p>The final URL to be passed should look like this: <a href="http://www.omdbapi.com/?t=movie_name&amp;apikey=secretapikey">http://www.omdbapi.com/?t=movie_name&amp;apikey=secretapikey</a>.</p></li>
				<li>Assign the OMDB portal (<a href="http://www.omdbapi.com/?">http://www.omdbapi.com/?</a>) as a string to a variable called <strong class="inline">serviceurl</strong> by using the following command:<p class="snippet">serviceurl = 'http://www.omdbapi.com/?'</p></li>
				<li>Create a variable called <strong class="inline">apikey</strong> with the last portion of the URL (<strong class="inline">&amp;apikey=secretapikey</strong>), where <strong class="inline">secretapikey</strong> is your own API key. The movie name portion is <strong class="inline">t=movie_name</strong>, and will be addressed later:<p class="snippet">apikey = '&amp;apikey='+omdbapi</p></li>
				<li>Write a utility function called <strong class="inline">print_json</strong> to print the movie data from a JSON file (which we will get from the portal). Here are the keys of a JSON file: 'Title', 'Year', 'Rated', 'Released', 'Runtime', 'Genre', 'Director', 'Writer', 'Actors', 'Plot', 'Language','Country', 'Awards', 'Ratings', 'Metascore', 'imdbRating', 'imdbVotes', and 'imdbID':<p class="snippet">def print_json(json_data):</p><p class="snippet">    list_keys=['Title', 'Year', 'Rated', 'Released', 'Runtime', 'Genre', 'Director', 'Writer', </p><p class="snippet">               'Actors', 'Plot', 'Language', 'Country', 'Awards', 'Ratings', </p><p class="snippet">               'Metascore', 'imdbRating', 'imdbVotes', 'imdbID']</p><p class="snippet">    print("-"*50)</p><p class="snippet">    for k in list_keys:</p><p class="snippet">        if k in list(json_data.keys()):</p><p class="snippet">            print(f"{k}: {json_data[k]}")</p><p class="snippet">    print("-"*50)</p></li>
				<li>Write a utility function to download a poster of the movie based on the information from the JSON dataset and save it in your local folder. Use the <strong class="inline">os</strong> module. The poster data is stored in the JSON key <strong class="inline">Poster</strong>. You may want to split the name of the <strong class="inline">Poster</strong> file and extract the file extension only. Let's say that the extension is <strong class="inline">jpg</strong>. We would later join this extension to the movie name and create a filename such as <strong class="inline">movie.jpg</strong>. Use the open Python command open to open a file and write the poster data. Close the file after you're done. This function may not return anything. It just saves the poster data as an image file:<p class="snippet">def save_poster(json_data):</p><p class="snippet">    import os</p><p class="snippet">    title = json_data['Title']</p><p class="snippet">    poster_url = json_data['Poster']</p><p class="snippet">    # Splits the poster url by '.' and picks up the last string as file extension</p><p class="snippet">    poster_file_extension=poster_url.split('.')[-1]</p><p class="snippet">    # Reads the image file from web</p><p class="snippet">    poster_data = urllib.request.urlopen(poster_url).read()</p><p class="snippet">        </p><p class="snippet">    savelocation=os.getcwd()+'\\'+'Posters'+'\\'</p><p class="snippet">    # Creates new directory if the directory does not exist. Otherwise, just use the existing path.</p><p class="snippet">    if not os.path.isdir(savelocation):</p><p class="snippet">        os.mkdir(savelocation)</p><p class="snippet">    </p><p class="snippet">    filename=savelocation+str(title)+'.'+poster_file_extension</p><p class="snippet">    f=open(filename,'wb')</p><p class="snippet">    f.write(poster_data)</p><p class="snippet">    f.close()</p></li>
				<li>Write a utility function called <strong class="inline">search_movie</strong> to search a movie by its name, print the downloaded JSON data (use the <strong class="inline">print_json</strong> function for this), and save the movie poster in the local folder (use the <strong class="inline">save_poster</strong> function for this). Use a <strong class="inline">try-except</strong> loop for this, that is, try to connect to the web portal. If successful, proceed, but if not (that is, if an exception is raised), then just print an error message. Use the previously created variables <strong class="inline">serviceurl</strong> and <strong class="inline">apikey</strong>. You have to pass on a dictionary with a key, <strong class="inline">t</strong>, and the movie name as the corresponding value to the <strong class="inline">urllib.parse.urlencode</strong> function and then add the <strong class="inline">serviceurl</strong> and <strong class="inline">apikey</strong> to the output of the function to construct the full URL. This URL will be used for accessing the data. The JSON data has a key called <strong class="inline">Response</strong>. If it is <strong class="inline">True</strong>, that means that the read was successful. Check this before processing the data. If it was not successful, then print the JSON key <strong class="inline">Error</strong>, which will contain the appropriate error message that's returned by the movie database:<p class="snippet">def search_movie(title):</p><p class="snippet">    try:</p><p class="snippet">        url = serviceurl + urllib.parse.urlencode({'t': str(title)})+apikey</p><p class="snippet">        print(f'Retrieving the data of "{title}" now... ')</p><p class="snippet">        print(url)</p><p class="snippet">        uh = urllib.request.urlopen(url)</p><p class="snippet">        data = uh.read()</p><p class="snippet">        json_data=json.loads(data)</p><p class="snippet">        </p><p class="snippet">        if json_data['Response']=='True':</p><p class="snippet">            print_json(json_data)</p><p class="snippet">            # Asks user whether to download the poster of the movie</p><p class="snippet">            if json_data['Poster']!='N/A':</p><p class="snippet">                save_poster(json_data)</p><p class="snippet">        else:</p><p class="snippet">            print("Error encountered: ",json_data['Error'])</p><p class="snippet">    </p><p class="snippet">    except urllib.error.URLError as e:</p><p class="snippet">        print(f"ERROR: {e.reason}"</p></li>
				<li>Test the <strong class="inline">search_movie</strong> function by entering <strong class="inline">Titanic</strong>:<p class="snippet">search_movie("Titanic")</p><p>The following is  the retrieved data for <strong class="inline">Titanic</strong>:</p><p class="snippet">http://www.omdbapi.com/?t=Titanic&amp;apikey=17cdc959</p><p class="snippet">--------------------------------------------------</p><p class="snippet">Title: Titanic</p><p class="snippet">Year: 1997</p><p class="snippet">Rated: PG-13</p><p class="snippet">Released: 19 Dec 1997</p><p class="snippet">Runtime: 194 min</p><p class="snippet">Genre: Drama, Romance</p><p class="snippet">Director: James Cameron</p><p class="snippet">Writer: James Cameron</p><p class="snippet">Actors: Leonardo DiCaprio, Kate Winslet, Billy Zane, Kathy Bates</p><p class="snippet">Plot: A seventeen-year-old aristocrat falls in love with a kind but poor artist aboard the luxurious, ill-fated R.M.S. Titanic.</p><p class="snippet">Language: English, Swedish</p><p class="snippet">Country: USA</p><p class="snippet">Awards: Won 11 Oscars. Another 111 wins &amp; 77 nominations.</p><p class="snippet">Ratings: [{'Source': 'Internet Movie Database', 'Value': '7.8/10'}, {'Source': 'Rotten Tomatoes', 'Value': '89%'}, {'Source': 'Metacritic', 'Value': '75/100'}]</p><p class="snippet">Metascore: 75</p><p class="snippet">imdbRating: 7.8</p><p class="snippet">imdbVotes: 913,780</p><p class="snippet">imdbID: tt0120338</p><p class="snippet">--------------------------------------------------</p></li>
				<li>Test the <strong class="inline">search_movie</strong> function by entering <strong class="inline">"Random_error"</strong> (obviously, this will not be found, and you should be able to check whether your error catching code is working properly):<p class="snippet">search_movie("Random_error")</p><p>Retrieve the data of <strong class="inline">"Random_error"</strong>:</p><p class="snippet">http://www.omdbapi.com/?t=Random_error&amp;apikey=17cdc959</p><p class="snippet">Error encountered:  Movie not found!</p></li>
			</ol>
			<p>Look for a folder called <strong class="inline">Posters</strong> in the same directory you are working in. It should contain a file called <strong class="inline">Titanic.jpg</strong>. Check the file.</p>
			<h3 id="_idParaDest-292">Solution of Activity 11: Retrieving D<a id="_idTextAnchor347"/>ata Correctly from Databases</h3>
			<p>These are the steps to complete this activity:</p>
			<ol>
				<li value="1">Connect to the supplied <strong class="inline">petsDB</strong> database:<p class="snippet">import sqlite3</p><p class="snippet">conn = sqlite3.connect("petsdb")</p></li>
				<li>Write a function to check whether the connection has been successful:<p class="snippet"># a tiny function to make sure the connection is successful</p><p class="snippet">def is_opened(conn):</p><p class="snippet">    try:</p><p class="snippet">        conn.execute("SELECT * FROM persons LIMIT 1")</p><p class="snippet">        return True</p><p class="snippet">    except sqlite3.ProgrammingError as e:</p><p class="snippet">        print("Connection closed {}".format(e))</p><p class="snippet">        return False</p><p class="snippet">print(is_opened(conn))</p><p>The output is as follows:</p><p class="snippet">True</p></li>
				<li>Close the connection:<p class="snippet">conn.close()</p></li>
				<li>Check whether the connection is open or closed:<p class="snippet">print(is_opened(conn))</p><p>The output is as follows:</p><p class="snippet">False</p></li>
				<li>Find out the different age groups are in the <strong class="inline">persons</strong> database. Connect to the supplied <strong class="inline">petsDB</strong> database:<p class="snippet">conn = sqlite3.connect("petsdb")</p><p class="snippet">c = conn.cursor()</p></li>
				<li>Execute the following command:<p class="snippet">for ppl, age in c.execute("SELECT count(*), age FROM persons GROUP BY age"):</p><p class="snippet">    print("We have {} people aged {}".format(ppl, age))</p><p>The output is as follows:</p><div id="_idContainer310" class="IMG---Figure"><img src="Images/C11065_08_17.jpg" alt="Figure 8.17: Section of output grouped by age" width="738" height="415"/></div><h6>Figure 8.17: Section of output grouped by age</h6></li>
				<li>To find out which age group has the highest number of people, execute the following command:<p class="snippet">sfor ppl, age in c.execute(</p><p class="snippet">    "SELECT count(*), age FROM persons GROUP BY age ORDER BY count(*) DESC"):</p><p class="snippet">    print("Highest number of people is {} and came from {} age group".format(ppl, age))</p><p class="snippet">    break</p><p>The output is as follows:</p><p class="snippet">Highest number of people is 5 and came from 73 age group</p></li>
				<li>To find out how many people do not have a full name (the last name is blank/null), execute the following command:<p class="snippet">res = c.execute("SELECT count(*) FROM persons WHERE last_name IS null")</p><p class="snippet">for row in res:</p><p class="snippet">    print(row)</p><p>The output is as follows:</p><p class="snippet">(60,)</p></li>
				<li>To find out how many people have more than one pet, execute the following command:<p class="snippet">res = c.execute("SELECT count(*) FROM (SELECT count(owner_id) FROM pets GROUP BY owner_id HAVING count(owner_id) &gt;1)")</p><p class="snippet">for row in res:</p><p class="snippet">    print("{} People has more than one pets".format(row[0]))</p><p>The output is as follows:</p><p class="snippet">43 People has more than one pets</p></li>
				<li>To find out how many pets have received treatment, execute the following command:<p class="snippet">res = c.execute("SELECT count(*) FROM pets WHERE treatment_done=1")</p><p class="snippet">for row in res:</p><p class="snippet">    print(row)</p><p>The output is as follows:</p><p class="snippet">(36,)</p></li>
				<li>To find out how many pets have received treatment and the type of pet is known, execute the following command:<p class="snippet">res = c.execute("SELECT count(*) FROM pets WHERE treatment_done=1 AND pet_type IS NOT null")</p><p class="snippet">for row in res:</p><p class="snippet">    print(row)</p><p>The output is as follows:</p><p class="snippet">(16,)</p></li>
				<li>To find out how many pets are from the city called "east port", execute the following command:<p class="snippet">res = c.execute("SELECT count(*) FROM pets JOIN persons ON pets.owner_id = persons.id WHERE persons.city='east port'")</p><p class="snippet">for row in res:</p><p class="snippet">    print(row)</p><p>The output is as follows:</p><p class="snippet">(49,)</p></li>
				<li>To find out how many pets are from the city called "east port" and who received treatment, execute the following command:<p class="snippet">res = c.execute("SELECT count(*) FROM pets JOIN persons ON pets.owner_id = persons.id WHERE persons.city='east port' AND pets.treatment_done=1")</p><p class="snippet">for row in res:</p><p class="snippet">    print(row)</p><p>The output is as follows:</p><p class="snippet">(11,)</p></li>
			</ol>
			<h3 id="_idParaDest-293"><a id="_idTextAnchor348"/>Solution of Activity 12: Data Wrangling Task – Fixing UN Data</h3>
			<p>These are the steps to complete this activity:</p>
			<ol>
				<li value="1">Import the required libraries:<p class="snippet">import numpy as np</p><p class="snippet">import pandas as pd</p><p class="snippet">import matplotlib.pyplot as plt</p><p class="snippet">import warnings</p><p class="snippet">warnings.filterwarnings('ignore')s</p></li>
				<li>Save the URL of the dataset and use the pandas <strong class="inline">read_csv</strong> method to directly pass this link and create a DataFrame:<p class="snippet">education_data_link="http://data.un.org/_Docs/SYB/CSV/SYB61_T07_Education.csv"</p><p class="snippet">df1 = pd.read_csv(education_data_link)</p></li>
				<li>Print the data in the DataFrame:<p class="snippet">df1.head()</p><p>The output is as follows:</p><div id="_idContainer311" class="IMG---Figure"><img src="Images/C11065_9_3.jpg" alt="Figure 9.4: DataFrame after removing the first row" width="1096" height="264"/></div><h6>Figure 9.3: DataFrame from the UN data</h6></li>
				<li>As the first row does not contain useful information, use the <strong class="inline">skiprows</strong> parameter to remove the first row:<p class="snippet">df1 = pd.read_csv(education_data_link,skiprows=1)</p></li>
				<li>Print the data in the DataFrame:<p class="snippet">df1.head()</p><p>The output is as follows:</p><div id="_idContainer312" class="IMG---Figure"><img src="Images/C11065_9_4.jpg" alt="Figure 9.4: DataFrame after removing the first row" width="1112" height="251"/></div><h6>Figure 9.4: DataFrame after removing the first row</h6></li>
				<li>Drop the column Region/Country/Area and Source as they will not be very helpful:<p class="snippet">df2 = df1.drop(['Region/Country/Area','Source'],axis=1)</p></li>
				<li>Assign the following names as the columns of the DataFrame: <strong class="inline">['Region/Country/Area','Year','Data','Value','Footnotes']</strong><p class="snippet">df2.columns=['Region/Country/Area','Year','Data','Enrollments (Thousands)','Footnotes']</p></li>
				<li>Print the data in the DataFrame:<p class="snippet">df1.head()</p><p>The output is as follows:</p><div id="_idContainer313" class="IMG---Figure"><img src="Images/C11065_9_5.jpg" alt="Figure 9.5: DataFrame after dropping Region/Country/Area and Source columns" width="817" height="184"/></div><h6>Figure 9.5: DataFrame after dropping Region/Country/Area and Source columns</h6></li>
				<li>Check how many unique values the <strong class="inline">Footnotes</strong> column contains:<p class="snippet">df2['Footnotes'].unique()</p><p>The output is as follows:</p><div id="_idContainer314" class="IMG---Figure"><img src="Images/C11065_9_6.jpg" alt="Figure 9.6: Unique values of the Footnotes column" width="1098" height="72"/></div><h6>Figure 9.6: Unique values of the Footnotes column</h6></li>
				<li>Convert the <strong class="inline">Value</strong> column data into a numeric one for further processing:<p class="snippet">type(df2['Enrollments (Thousands)'][0])</p><p>The output is as follows:</p><p class="snippet">str</p></li>
				<li>Create a utility function to convert the strings in the Value column into floating-point numbers:<p class="snippet">def to_numeric(val):</p><p class="snippet">    """</p><p class="snippet">    Converts a given string (with one or more commas) to a numeric value</p><p class="snippet">    """</p><p class="snippet">    if ',' not in str(val):</p><p class="snippet">        result = float(val)</p><p class="snippet">    else:</p><p class="snippet">        val=str(val)</p><p class="snippet">        val=''.join(str(val).split(','))</p><p class="snippet">        result=float(val)</p><p class="snippet">    return result</p></li>
				<li>Use the <strong class="inline">apply</strong> method to apply this function to the <strong class="inline">Value</strong> column data:<p class="snippet">df2['Enrollments (Thousands)']=df2['Enrollments (Thousands)'].apply(to_numeric)</p></li>
				<li>Print the unique types of data in the <strong class="inline">Data</strong> column:<p class="snippet">df2['Data'].unique()</p><p>The output is as follows:</p><div id="_idContainer315" class="IMG---Figure"><img src="Images/C11065_9_7.jpg" alt="" width="801" height="188"/></div><h6>Figure 9.7:Unique values in a column</h6></li>
				<li>Create three DataFrames by filtering and selecting them from the original DataFrame:<ul><li><strong class="bold">df_primary</strong>: Only students enrolled in primary education (thousands)</li><li><strong class="bold">df_secondary</strong>: Only students enrolled in secondary education (thousands)</li><li><strong class="bold">df_tertiary</strong>: Only students enrolled in tertiary education (thousands):<p class="snippet">df_primary = df2[df2['Data']=='Students enrolled in primary education (thousands)']</p><p class="snippet">df_secondary = df2[df2['Data']=='Students enrolled in secondary education (thousands)']</p><p class="snippet">df_tertiary = df2[df2['Data']=='Students enrolled in tertiary education (thousands)']</p></li></ul></li>
				<li>Compare them using bar charts of the primary students' enrollment of a low-income country and a high-income country:<p class="snippet">primary_enrollment_india = df_primary[df_primary['Region/Country/Area']=='India']</p><p class="snippet">primary_enrollment_USA = df_primary[df_primary['Region/Country/Area']=='United States of America']</p></li>
				<li>Print the <strong class="inline">primary_enrollment_india</strong> data:<p class="snippet">primary_enrollment_india</p><p>The output is as follows:</p><div id="_idContainer316" class="IMG---Figure"><img src="Images/C11065_9_8.jpg" alt="Figure 9.8: Data for the enrollment in primary education in India" width="824" height="175"/></div><h6>Figure 9.8: Data for the enrollment in primary education in India</h6></li>
				<li>Print the <strong class="inline">primary_enrollment_USA</strong> data:<p class="snippet">primary_enrollment_USA</p><p>The output is as follows:</p><div id="_idContainer317" class="IMG---Figure"><img src="Images/C11065_9_9.jpg" alt="Figure 9.9: Data for the enrollment in primary education in USA" width="831" height="143"/></div><h6>Figure 9.9: Data for the enrollment in primary education in USA</h6></li>
				<li>Plot the data for India:<p class="snippet">plt.figure(figsize=(8,4))</p><p class="snippet">plt.bar(primary_enrollment_india['Year'],primary_enrollment_india['Enrollments (Thousands)'])</p><p class="snippet">plt.title("Enrollment in primary education\nin India (in thousands)",fontsize=16)</p><p class="snippet">plt.grid(True)</p><p class="snippet">plt.xticks(fontsize=14)</p><p class="snippet">plt.yticks(fontsize=14)</p><p class="snippet">plt.xlabel("Year", fontsize=15)</p><p class="snippet">plt.show()</p><p>The output is as follows:</p><div id="_idContainer318" class="IMG---Figure"><img src="Images/C11065_9_10.jpg" alt="Figure 9.10: Bar plot for the enrollment in primary education in India" width="652" height="307"/></div><h6>Figure 9.10: Bar plot for the enrollment in primary education in India</h6></li>
				<li>Plot the data for the USA:<p class="snippet">plt.figure(figsize=(8,4))</p><p class="snippet">plt.bar(primary_enrollment_USA['Year'],primary_enrollment_USA['Enrollments (Thousands)'])</p><p class="snippet">plt.title("Enrollment in primary education\nin the United States of America (in thousands)",fontsize=16)</p><p class="snippet">plt.grid(True)</p><p class="snippet">plt.xticks(fontsize=14)</p><p class="snippet">plt.yticks(fontsize=14)</p><p class="snippet">plt.xlabel("Year", fontsize=15)</p><p class="snippet">plt.show()</p><p>The output is as follows:</p><div id="_idContainer319" class="IMG---Figure"><img src="Images/C11065_9_11.jpg" alt="Figure 9.11: Bar plot for the enrollment in primary education in the USA" width="660" height="307"/></div><h6>Figure 9.11: Bar plot for the enrollment in primary education in the USA</h6><p>Data imputation: Clearly, we are missing some data. Let's say we decide to impute these data points by simple linear interpolation between the available data points. We can take out a pen and paper or a calculator and compute those values and manually create a dataset somehow. But being a data wrangler, we will of course take advantage of Python programming, and use pandas imputation methods for this task. But to do that, we first need to create a DataFrame with missing values inserted – that is, we need to append another DataFrame with missing values to the current DataFrame.</p><p><strong class="bold">(For India) Append the rows corresponding to missing the years </strong>–<strong class="bold"> 2004 - 2009, 2011 – 2013.</strong></p></li>
				<li>Find the missing years:<p class="snippet">missing_years = [y for y in range(2004,2010)]+[y for y in range(2011,2014)]</p></li>
				<li>Print the value in the  <strong class="inline">missing_years variable:</strong><p class="snippet">missing_years</p><p>The output is as follows:</p><p class="snippet">[2004, 2005, 2006, 2007, 2008, 2009, 2011, 2012, 2013]</p></li>
				<li>Create a dictionary of values with <strong class="inline">np.nan</strong>. Note that there are 9 missing data points, so we need to create a list with identical values repeated 9 times:<p class="snippet">dict_missing = {'Region/Country/Area':['India']*9,'Year':missing_years,</p><p class="snippet">                'Data':'Students enrolled in primary education (thousands)'*9,</p><p class="snippet">                'Enrollments (Thousands)':[np.nan]*9,'Footnotes':[np.nan]*9}</p></li>
				<li>Create a DataFrame of missing values (from the preceding dictionary) that we can <strong class="inline">append</strong>:<p class="snippet">df_missing = pd.DataFrame(data=dict_missing)</p></li>
				<li>Append the new DataFrames to previously existing ones:<p class="snippet">primary_enrollment_india=primary_enrollment_india.append(df_missing,ignore_index=True,sort=True)</p></li>
				<li>Print the data in <strong class="inline">primary_enrollment_india</strong>:<p class="snippet">primary_enrollment_india</p><p>The output is as follows:</p><div id="_idContainer320" class="IMG---Figure"><img src="Images/C11065_9_12.jpg" alt="Figure 9.12: Data for the enrollment in primary education in India after appending the data" width="811" height="422"/></div><h6>Figure 9.12: Data for the enrollment in primary education in India after appending the data</h6></li>
				<li>Sort by <strong class="inline">year</strong> and reset the indices using <strong class="inline">reset_index</strong>. Use <strong class="inline">inplace=True</strong> to execute the changes on the DataFrame itself:<p class="snippet">primary_enrollment_india.sort_values(by='Year',inplace=True)</p><p class="snippet">primary_enrollment_india.reset_index(inplace=True,drop=True)</p></li>
				<li>Print the data in <strong class="inline">primary_enrollment_india</strong>:<p class="snippet">primary_enrollment_india</p><p>The output is as follows:</p><div id="_idContainer321" class="IMG---Figure"><img src="Images/C11065_9_13.jpg" alt="Figure 9.13: Data for the enrollment in primary education in India after sorting the data" width="863" height="415"/></div><h6>Figure 9.13: Data for the enrollment in primary education in India after sorting the data</h6></li>
				<li>Use the <strong class="inline">interpolate</strong> method for linear interpolation. It fills all the <strong class="inline">NaN</strong> by linearly interpolated values. Check out this link for more details about this method: <a href="http://pandas.pydata.org/pandas-docs/version/0.17/generated/pandas.DataFrame.interpolate.html">http://pandas.pydata.org/pandas-docs/version/0.17/generated/pandas.DataFrame.interpolate.html</a>:<p class="snippet">primary_enrollment_india.interpolate(inplace=True)</p></li>
				<li>Print the data in <strong class="inline">primary_enrollment_india</strong>:<p class="snippet">primary_enrollment_india</p><p>The output is as follows:</p><div id="_idContainer322" class="IMG---Figure"><img src="Images/C11065_9_14.jpg" alt="" width="796" height="419"/></div><h6>Figure 9.14: Data for the enrollment in primary education in India after interpolating the data</h6></li>
				<li>Plot the data:<p class="snippet">plt.figure(figsize=(8,4))</p><p class="snippet">plt.bar(primary_enrollment_india['Year'],primary_enrollment_india['Enrollments (Thousands)'])</p><p class="snippet">plt.title("Enrollment in primary education\nin India (in thousands)",fontsize=16)</p><p class="snippet">plt.grid(True)</p><p class="snippet">plt.xticks(fontsize=14)</p><p class="snippet">plt.yticks(fontsize=14)</p><p class="snippet">plt.xlabel("Year", fontsize=15)</p><p class="snippet">plt.show()</p><p>The output is as follows:</p><div id="_idContainer323" class="IMG---Figure"><img src="Images/C11065_9_15.jpg" alt="Figure 9.15: Bar plot for the enrollment in primary education in India" width="662" height="307"/></div><h6>Figure 9.15: Bar plot for the enrollment in primary education in India</h6></li>
				<li>Repeat the same steps for the USA:<p class="snippet">missing_years = [2004]+[y for y in range(2006,2010)]+[y for y in range(2011,2014)]+[2016]</p></li>
				<li>Print the value in <strong class="inline">missing_years</strong>.<p class="snippet">missing_years</p><p>The output is as follows:</p><p class="snippet">[2004, 2006, 2007, 2008, 2009, 2011, 2012, 2013, 2016]</p></li>
				<li>Create <strong class="inline">dict_missing</strong>, as follows:<p class="snippet">dict_missing = {'Region/Country/Area':['United States of America']*9,'Year':missing_years, 'Data':'Students enrolled in primary education (thousands)'*9, 'Value':[np.nan]*9,'Footnotes':[np.nan]*9}</p></li>
				<li>Create the DataFrame fpr <strong class="inline">df_missing</strong>, as follows:<p class="snippet">df_missing = pd.DataFrame(data=dict_missing)</p></li>
				<li>Append this to the <strong class="inline">primary_enrollment_USA</strong> variable, as follows:<p class="snippet">primary_enrollment_USA=primary_enrollment_USA.append(df_missing,ignore_index=True,sort=True)</p></li>
				<li>Sort the values in the <strong class="inline">primary_enrollment_USA</strong> variable, as follows:<p class="snippet">primary_enrollment_USA.sort_values(by='Year',inplace=True)</p></li>
				<li>Reset the index of the <strong class="inline">primary_enrollment_USA</strong> variable, as follows:<p class="snippet">primary_enrollment_USA.reset_index(inplace=True,drop=True)</p></li>
				<li>Interpolate the <strong class="inline">primary_enrollment_USA</strong> variable, as follows:<p class="snippet">primary_enrollment_USA.interpolate(inplace=True)</p></li>
				<li>Print the <strong class="inline">primary_enrollment_USA</strong> variable:<p class="snippet">primary_enrollment_USA</p><p>The output is as follows:</p><div id="_idContainer324" class="IMG---Figure"><img src="Images/C11065_9_16.jpg" alt="Figure 9.16: Data for the enrollment in primary education in USA after all operations have been completed" width="873" height="392"/></div><h6>Figure 9.16: Data for the enrollment in primary education in USA after all operations have been completed</h6></li>
				<li>Still, the first value is unfilled. We can use the <strong class="inline">limit</strong> and <strong class="inline">limit_direction</strong> parameters with the interpolate method to fill that. How did we know this? By searching on Google and looking at this StackOverflow page. Always search for the solution to your problem and look for what has already been done and try to implement it:<p class="snippet">primary_enrollment_USA.interpolate(method='linear',limit_direction='backward',limit=1)</p><p>The output is as follows:</p><div id="_idContainer325" class="IMG---Figure"><img src="Images/C11065_9_17.jpg" alt="Figure 9.17: Data for the enrollment in primary education in the USA after limiting the data" width="869" height="379"/></div><h6>Figure 9.17: Data for the enrollment in primary education in the USA after limiting the data</h6></li>
				<li>Print the data in primary_enrollment_USA:<p class="snippet">primary_enrollment_USA</p><p>The output is as follows:</p><div id="_idContainer326" class="IMG---Figure"><img src="Images/C11065_9_18.jpg" alt="Figure 9.18: Data for the enrollment in primary education in USA" width="872" height="391"/></div><h6>Figure 9.18: Data for the enrollment in primary education in USA</h6></li>
				<li>Plot the data:<p class="snippet">plt.figure(figsize=(8,4))</p><p class="snippet">plt.bar(primary_enrollment_USA['Year'],primary_enrollment_USA['Enrollments (Thousands)'])</p><p class="snippet">plt.title("Enrollment in primary education\nin the United States of America (in thousands)",fontsize=16)</p><p class="snippet">plt.grid(True)</p><p class="snippet">plt.xticks(fontsize=14)</p><p class="snippet">plt.yticks(fontsize=14)</p><p class="snippet">plt.xlabel("Year", fontsize=15)</p><p class="snippet">plt.show()</p><p>The output is as follows:</p></li>
			</ol>
			<div>
				<div id="_idContainer327" class="IMG---Figure">
					<img src="Images/C11065_9_19.jpg" alt="Figure 9.19: Bar plot for the enrollment in primary education in the USA" width="767" height="307"/>
				</div>
			</div>
			<h6>Figure 9.19: Bar plot for the enrollment in primary education in the USA</h6>
			<h3 id="_idParaDest-294"><a id="_idTextAnchor349"/>Activity 13: Data Wrangling Task – Cleaning GDP Data</h3>
			<p>These are the steps to complete this activity:</p>
			<ol>
				<li value="1">GDP data for India: We will try to read the GDP data for India from a CSV file that was found in a World Bank portal. It is given to you and also hosted on the Packt GitHub repository. But the Pandas <strong class="inline">read_csv</strong> method will throw an error in we try to read it normally. Let's look at a step-by-step guide on how we can read useful information from it:<p class="snippet">df3=pd.read_csv("India_World_Bank_Info.csv")</p><p>The output is as follows:</p><p class="snippet">---------------------------------------------------------------------------</p><p class="snippet">ParserError                               Traceback (most recent call last)</p><p class="snippet">&lt;ipython-input-45-9239cae67df7&gt; in &lt;module&gt;()</p><p class="snippet">…..</p><p class="snippet">ParserError: Error tokenizing data. C error: Expected 1 fields in line 6, saw 3</p><p>We can try and use the <strong class="inline">error_bad_lines=False</strong> option in this kind of situation.</p></li>
				<li>Read the India World Bank Information <strong class="inline">.csv</strong> file:<p class="snippet">df3=pd.read_csv("India_World_Bank_Info.csv",error_bad_lines=False)</p><p class="snippet">df3.head(10)</p><p>The output is as follows:</p><div id="_idContainer328" class="IMG---Figure"><img src="Images/C11065_9_20.jpg" alt="Figure 9.20: DataFrame from the India World Bank Information" width="693" height="311"/></div><h6>Figure 9.20: DataFrame from the India World Bank Information</h6><h4>Note:</h4><p class="callout">At times, the output may not found because there are three rows instead of the expected one row.</p></li>
				<li>Clearly, the delimiter in this file is tab (<strong class="inline">\t</strong>):<p class="snippet">df3=pd.read_csv("India_World_Bank_Info.csv",error_bad_lines=False,delimiter='\t')</p><p class="snippet">df3.head(10)</p><p>The output is as follows:</p><div id="_idContainer329" class="IMG---Figure"><img src="Images/C11065_9_21.jpg" alt="Figure 9.21: DataFrame from the India World Bank Information after using a delimiter" width="1134" height="706"/></div><h6>Figure 9.21: DataFrame from the India World Bank Information after using a delimiter</h6></li>
				<li>Use the <strong class="inline">skiprows</strong> parameter to skip the first 4 rows:<p class="snippet">df3=pd.read_csv("India_World_Bank_Info.csv",error_bad_lines=False,delimiter='\t',skiprows=4)</p><p class="snippet">df3.head(10)</p><p>The output is as follows:</p><div id="_idContainer330" class="IMG---Figure"><img src="Images/C11065_9_22.jpg" alt="Figure 9.22: DataFrame from the India World Bank Information after using skiprows" width="930" height="702"/></div><h6>Figure 9.22: DataFrame from the India World Bank Information after using skiprows</h6></li>
				<li>Closely examine the dataset: In this file, the columns are the yearly data and rows are the various types of information. Upon examining the file with Excel, we find that the column <strong class="inline">Indicator Name</strong> is the one with the name of the particular data type. We filter the dataset with the information we are interested in and also transpose (the rows and columns are interchanged) it to make it a similar format as our previous education dataset:<p class="snippet">df4=df3[df3['Indicator Name']=='GDP per capita (current US$)'].T</p><p class="snippet">df4.head(10)</p><p>The output is as follows:</p><div id="_idContainer331" class="IMG---Figure"><img src="Images/C11065_9_23.jpg" alt="Figure 9.23: DataFrame focusing on GDP per capita" width="526" height="265"/></div><h6>Figure 9.23: DataFrame focusing on GDP per capita</h6></li>
				<li>There is no index, so let's use <strong class="inline">reset_index</strong> again:<p class="snippet">df4.reset_index(inplace=True)</p><p class="snippet">df4.head(10)</p><p>The output is as follows:</p><div id="_idContainer332" class="IMG---Figure"><img src="Images/C11065_9_24.jpg" alt="Figure 9.24: DataFrame from the India World Bank Information using reset_index" width="455" height="256"/></div><h6>Figure 9.24: DataFrame from the India World Bank Information using reset_index</h6></li>
				<li>The first 3 rows aren't useful. We can redefine the DataFrame without them. Then, we re-index again:<p class="snippet">df4.drop([0,1,2],inplace=True)</p><p class="snippet">df4.reset_index(inplace=True,drop=True)</p><p class="snippet">df4.head(10)</p><p>The output is as follows:</p><div id="_idContainer333" class="IMG---Figure"><img src="Images/C11065_9_25.jpg" alt="Figure 9.25: DataFrame from the India World Bank Information after dropping and resetting the index" width="533" height="250"/></div><h6>Figure 9.25: DataFrame from the India World Bank Information after dropping and resetting the index</h6></li>
				<li>Let's rename the columns properly (this is necessary for merging, which we will look at shortly):<p class="snippet">df4.columns=['Year','GDP']</p><p class="snippet">df4.head(10)</p><p>The output is as follows:</p><div id="_idContainer334" class="IMG---Figure"><img src="Images/C11065_9_26.jpg" alt="Figure 9.26: DataFrame focusing on Year and GDP" width="524" height="255"/></div><h6>Figure 9.26: DataFrame focusing on Year and GDP</h6></li>
				<li>It looks like that we have GDP data from 1960 onward. But we are interested in 2003 - 2016. Let's examine the last 20 rows:<p class="snippet">df4.tail(20)</p><p>The output is as follows:</p><div id="_idContainer335" class="IMG---Figure"><img src="Images/C11065_9_27.jpg" alt="Figure 9.27: DataFrame from the India World Bank Information" width="836" height="470"/></div><h6>Figure 9.27: DataFrame from the India World Bank Information</h6></li>
				<li>So, we should be good with rows 43-56. Let's create a DataFrame called <strong class="inline">df_gdp:</strong><p class="snippet">df_gdp=df4.iloc[[i for i in range(43,57)]]</p><p class="snippet">df_gdp</p><p>The output is as follows:</p><div id="_idContainer336" class="IMG---Figure"><img src="Images/C11065_9_28.jpg" alt="Figure 9.28: DataFrame from the India World Bank Information" width="649" height="333"/></div><h6>Figure 9.28: DataFrame from the India World Bank Information</h6></li>
				<li>We need to reset the index again (for merging):<p class="snippet">df_gdp.reset_index(inplace=True,drop=True)</p><p class="snippet">df_gdp</p><p>The output is as follows:</p><div id="_idContainer337" class="IMG---Figure"><img src="Images/C11065_9_29.jpg" alt="Figure 9.29: DataFrame from the India World Bank Information" width="612" height="344"/></div><h6>Figure 9.29: DataFrame from the India World Bank Information</h6></li>
				<li>The year in this DataFrame is not of the <strong class="inline">int</strong> type. So, it will have problems merging with the education DataFrame:<p class="snippet">df_gdp['Year']</p><p>The output is as follows:</p><div id="_idContainer338" class="IMG---Figure"><img src="Images/C11065_9_30.jpg" alt="" width="526" height="248"/></div><h6>Figure 9.30: DataFrame focusing on year</h6></li>
				<li>Use the <strong class="inline">apply</strong> method with Python's built-in <strong class="inline">int</strong> function. Ignore any warnings that are thrown:<p class="snippet">df_gdp['Year']=df_gdp['Year'].apply(int)</p></li>
			</ol>
			<h3 id="_idParaDest-295"><a id="_idTextAnchor350"/>Solution of Activity 14: Data Wrangling Task – Merging UN Data and GDP Data</h3>
			<p>These are the steps to complete this activity:</p>
			<ol>
				<li value="1">Now, merge the two DataFrames, that is, <strong class="inline">primary_enrollment_india</strong> and <strong class="inline">df_gdp</strong>, on the <strong class="inline">Year</strong> column:<p class="snippet">primary_enrollment_with_gdp=primary_enrollment_india.merge(df_gdp,on='Year')</p><p class="snippet">primary_enrollment_with_gdp</p><p>The output is as follows:</p><div id="_idContainer339" class="IMG---Figure"><img src="Images/C11065_9_31.jpg" alt="" width="701" height="359"/></div><h6>Figure 9.31: Merged data</h6></li>
				<li>Now, we can drop the <strong class="inline">Data</strong>, <strong class="inline">Footnotes</strong>, and <strong class="inline">Region/Country/Area</strong> columns:<p class="snippet">primary_enrollment_with_gdp.drop(['Data','Footnotes','Region/Country/Area'],axis=1,inplace=True)</p><p class="snippet">primary_enrollment_with_gdp</p><p>The output is as follows:</p><div id="_idContainer340" class="IMG---Figure"><img src="Images/C11065_9_32.jpg" alt="Figure 9.32: Merged data after dropping the Data, Footnotes, and Region/Country/Area columns" width="628" height="353"/></div><h6>Figure 9.32: Merged data after dropping the Data, Footnotes, and Region/Country/Area columns</h6></li>
				<li>Rearrange the columns for proper viewing and presentation to a data scientist:<p class="snippet">primary_enrollment_with_gdp = primary_enrollment_with_gdp[['Year','Enrollments (Thousands)','GDP']]</p><p class="snippet">primary_enrollment_with_gdp</p><p>The output is as follows:</p><div id="_idContainer341" class="IMG---Figure"><img src="Images/C11065_9_33.jpg" alt="Figure 9.33: Merged data after rearranging the columns" width="592" height="333"/></div><h6>Figure 9.33: Merged data after rearranging the columns</h6></li>
				<li>Plot the data:<p class="snippet">plt.figure(figsize=(8,5))</p><p class="snippet">plt.title("India's GDP per capita vs primary education enrollment",fontsize=16)</p><p class="snippet">plt.scatter(primary_enrollment_with_gdp['GDP'],</p><p class="snippet">            primary_enrollment_with_gdp['Enrollments (Thousands)'],</p><p class="snippet">           edgecolor='k',color='orange',s=200)</p><p class="snippet">plt.xlabel("GDP per capita (US $)",fontsize=15)</p><p class="snippet">plt.ylabel("Primary enrollment (thousands)",fontsize=15)</p><p class="snippet">plt.xticks(fontsize=14)</p><p class="snippet">plt.yticks(fontsize=14)</p><p class="snippet">plt.grid(True)</p><p class="snippet">plt.show()</p><p>The output is as follows:</p></li>
			</ol>
			<div>
				<div id="_idContainer342" class="IMG---Figure">
					<img src="Images/C11065_9_34.jpg" alt="Figure 9.34: Scatter plot of merged data" width="717" height="344"/>
				</div>
			</div>
			<h6>Figure 9.34: Scatter plot of merged data</h6>
			<h3 id="_idParaDest-296"><a id="_idTextAnchor351"/>Activity 15: Data Wrangling Task – Connecting the New Data to a Database</h3>
			<p>These are the steps to complete this activity:</p>
			<ol>
				<li value="1">Connect to a database and writing values it. We start by importing the <strong class="inline">sqlite3</strong> module of Python and then use the connect function to connect to a database. Designate <strong class="inline">Year</strong> as the <strong class="inline">PRIMARY</strong> <strong class="inline">KEY</strong> of this table:<p class="snippet">import sqlite3</p><p class="snippet">with sqlite3.connect("Education_GDP.db") as conn:</p><p class="snippet">    cursor = conn.cursor()</p><p class="snippet">    cursor.execute("CREATE TABLE IF NOT EXISTS \</p><p class="snippet">                   education_gdp(Year INT, Enrollment FLOAT, GDP FLOAT, PRIMARY KEY (Year))")</p></li>
				<li>Run a loop with the dataset rows one by one to insert them in the table:<p class="snippet">with sqlite3.connect("Education_GDP.db") as conn:</p><p class="snippet">    cursor = conn.cursor()</p><p class="snippet">    for i in range(14):</p><p class="snippet">        year = int(primary_enrollment_with_gdp.iloc[i]['Year'])</p><p class="snippet">        enrollment = primary_enrollment_with_gdp.iloc[i]['Enrollments (Thousands)']</p><p class="snippet">        gdp = primary_enrollment_with_gdp.iloc[i]['GDP']</p><p class="snippet">        #print(year,enrollment,gdp)</p><p class="snippet">        cursor.execute("INSERT INTO education_gdp (Year,Enrollment,GDP) VALUES(?,?,?)",(year,enrollment,gdp))</p><p>If we look at the current folder, we should see a file called <strong class="inline">Education_GDP.db</strong>, and if we can examine that using a database viewer program, we can see the data transferred there.</p></li>
			</ol>
			<p>In these activities, we have examined a complete data wrangling flow, including reading data from the web and a local drive, filtering, cleaning, quick visualization, imputation, indexing, merging, and writing back to a database table. We also wrote custom functions to transform some of the data and saw how to handle situations where we may get errors upon reading the file.</p>
		</div>
	</div>



  </body></html>