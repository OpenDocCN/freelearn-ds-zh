<html><head></head><body>
<div><h1 class="chapter-number" id="_idParaDest-183"><a id="_idTextAnchor183" class="pcalibre calibre6 pcalibre1"/>14</h1>
<h1 id="_idParaDest-184" class="calibre5"><a id="_idTextAnchor184" class="pcalibre calibre6 pcalibre1"/>New Frontiers</h1>
<p class="calibre3">In the previous chapters, we overviewed many of the tools and applications of network science within analytics projects. In this chapter, we’ll look ahead toward the newer tools being developed that have many promising applications within network science, including quantum graph algorithms, deep learning/large language model architecture optimization, and multilevel graphs that are useful for organizing metadata and understanding genetics data.</p>
<p class="calibre3">While the prior chapters included coded examples, this chapter will focus on ideas and the possibilities for development in the future. Network science is an evolving field, and it’s likely that tools we can’t even imagine right now will be commonplace in the next decade. Let’s dive into some of the newer applications and see how network science continues to contribute to knowledge in many different fields.</p>
<p class="calibre3">Specifically, we will cover the following topics:</p>
<ul class="calibre10">
<li class="calibre11">Quantum network science algorithms</li>
<li class="calibre11">Neural network architectures as graphs</li>
<li class="calibre11">Hierarchical networks</li>
<li class="calibre11">Hypergraphs</li>
</ul>
<h1 id="_idParaDest-185" class="calibre5"><a id="_idTextAnchor185" class="pcalibre calibre6 pcalibre1"/>Quantum network science algorithms</h1>
<p class="calibre3">One new <a id="_idIndexMarker600" class="pcalibre calibre6 pcalibre1"/>and promising avenue for network science algorithm development is quantum computing. <strong class="bold">Quantum computing</strong> leverages <a id="_idIndexMarker601" class="pcalibre calibre6 pcalibre1"/>many of the advantageous properties of physics at the quantum level to improve computing power and tackle difficult problems. While<a id="_idIndexMarker602" class="pcalibre calibre6 pcalibre1"/> there are many flavors of quantum computing, we’ll focus on <strong class="bold">qubit</strong> systems, where bits are replaced with their quantum version.</p>
<p class="calibre3">Qubits offer many advantages over bits within computing frameworks. <code>0</code> or <code>1</code> configuration, qubits can exist as a <code>1</code> and a <code>0</code> simultaneously until the qubit is measured, collapsing to the usual state of a bit. This allows for massively parallel searches for solutions.</p>
<p class="calibre3">In addition <a id="_idIndexMarker604" class="pcalibre calibre6 pcalibre1"/>to being able to exist as a <code>1</code> and a <code>0</code> at the same time, superposition allows for fractional values where the qubit exists as partially a <code>1</code> and partially a <code>0</code> in a probabilistic sense. Because of this fractional state, it’s possible to design gates that work on the probability function rather than acting on single states of a bit. This flexibility allows for circuit designs to enhance algorithms, and such an approach to computing has shown gains in image classification. <em class="italic">Figure 14</em><em class="italic">.1</em> shows the differences between a qubit and a bit:</p>
<div><div><img alt="Figure 14.1 – A visualization of qubits versus bits" src="img/B21087_14_01.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 14.1 – A visualization of qubits versus bits</p>
<p class="calibre3">Many types of machine learning algorithms have been translated for use on quantum computers to speed up solution convergence or scale algorithms to larger problems. Quantum machine learning is an active area of research, and network science algorithms are one of the larger areas of research within quantum machine learning. Let’s explore two quantum network science algorithms in more detail.</p>
<h2 id="_idParaDest-186" class="calibre7"><a id="_idTextAnchor186" class="pcalibre calibre6 pcalibre1"/>Graph coloring algorithms</h2>
<p class="calibre3"><strong class="bold">Graph coloring algorithms</strong> are <a id="_idIndexMarker605" class="pcalibre calibre6 pcalibre1"/>a branch of network science algorithms aimed at finding the chromatic number of a graph. A <strong class="bold">chromatic number</strong> is the<a id="_idIndexMarker606" class="pcalibre calibre6 pcalibre1"/> minimum number of colors required to color the vertices of a network such that no colors are adjacent to the same color. In<a id="_idIndexMarker607" class="pcalibre calibre6 pcalibre1"/> real-world applications, chromatic numbers are important in determining the number of channels to allocate in communication systems or scheduling jobs within parallel processing. The minimum number of colors required to color the vertices of a network represents the minimum number of channels needed or the minimum number of jobs needed to complete the aforementioned tasks. <em class="italic">Figure 14</em><em class="italic">.2</em> shows a small network with the colors shown:</p>
<div><div><img alt="Figure 14.2 – A small network with four vertices, four edges, and a chromatic number of two" src="img/B21087_14_02.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 14.2 – A small network with four vertices, four edges, and a chromatic number of two</p>
<p class="calibre3">While <em class="italic">Figure 14</em><em class="italic">.2</em> has an easy-to-determine chromatic number, computing the chromatic number of a network, in general, is<a id="_idIndexMarker608" class="pcalibre calibre6 pcalibre1"/> thought to be <strong class="bold">NP-hard</strong>, meaning that it is not solvable in polynomial time. Algorithms that have high complexity translates to computation that is very difficult or currently impossible for large enough or dense enough networks. This poses problems in terms of solving problems in communication and job scheduling where the volume of calls or jobs is very large.</p>
<p class="calibre3">Fortunately, quantum graph coloring algorithms allow algorithms to run much faster than they do on classical machines, leading to quicker solutions for large graphs and potentially computable solutions for very large graphs. However, current quantum hardware systems limit the size of a graph on which a quantum graph coloring algorithm can be run, as the problem must be mapped to the physical system. As quantum hardware supports larger and larger networks, chromatic number computation will be feasible for more real-world problems.</p>
<h2 id="_idParaDest-187" class="calibre7"><a id="_idTextAnchor187" class="pcalibre calibre6 pcalibre1"/>Max flow/min cut</h2>
<p class="calibre3">In <a href="B21087_04.xhtml#_idTextAnchor053" class="pcalibre calibre6 pcalibre1"><em class="italic">Chapter 4</em></a>, we explored <strong class="bold">transportation logistics</strong> and the <strong class="bold">max flow/min cut algorithm</strong>. Recall <a id="_idIndexMarker609" class="pcalibre calibre6 pcalibre1"/>that <a id="_idIndexMarker610" class="pcalibre calibre6 pcalibre1"/>this algorithm is useful in partitioning flows on networks and that it can be used to plan out road closures on a traffic grid, such as the grid shown in <em class="italic">Figure 14</em><em class="italic">.3</em>:</p>
<div><div><img alt="Figure 14.3 – A traffic grid in relation to five stores (considered in Chapter 4)" src="img/B21087_14_03.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 14.3 – A traffic grid in relation to five stores (considered in Chapter 4)</p>
<p class="calibre3">Finding the optimal cut to avoid service delays to each of these five stores (shown in <em class="italic">Figure 14</em><em class="italic">.3</em>) is a difficult problem to compute, and computationally efficient solutions provide a good way to scale these types of analyses.</p>
<p class="calibre3">Another common use of the max flow/min cut algorithm is image partitioning, whereby the foreground and background of an image are determined. Image enhancement typically relies on distinguishing different parts of focus within the image. Photoshopping images also requires a foreground/background discernment step.</p>
<p class="calibre3">As with <a id="_idIndexMarker611" class="pcalibre calibre6 pcalibre1"/>chromatic number calculations, computing max flow/min cut optima on large or dense graphs can be challenging when dealing with classical systems. Quantum versions of this algorithm exist and can optimize solutions more easily than classical versions. However, hardware size currently limits the application of quantum max flow/min cut algorithms on large problems.</p>
<p class="calibre3">Many other<a id="_idIndexMarker612" class="pcalibre calibre6 pcalibre1"/> quantum versions of network algorithms exist and have given strong results on small problems, representing a solid future direction for scaling network algorithms in terms of newer approaches to hardware. As hardware development progresses, it’s likely that network science will benefit, and the algorithms in network science that currently don’t scale as well as other network science algorithms will find a path forward for difficult problems. So far, network science algorithms represent a major part of quantum machine learning research, and given their success, it’s likely that network science and quantum computing will continue to influence each other.</p>
<p class="calibre3">Let’s turn our attention to deep learning architectures, which can be formulated in both classical computing and quantum computing.</p>
<h1 id="_idParaDest-188" class="calibre5"><a id="_idTextAnchor188" class="pcalibre calibre6 pcalibre1"/>Neural network architectures as graphs</h1>
<p class="calibre3">In <a href="B21087_01.xhtml#_idTextAnchor016" class="pcalibre calibre6 pcalibre1"><em class="italic">Chapter 1</em></a>, we touched <a id="_idIndexMarker613" class="pcalibre calibre6 pcalibre1"/>on deep learning models, particularly in the context of generative artificial intelligence. Deep learning models surface in many areas<a id="_idIndexMarker614" class="pcalibre calibre6 pcalibre1"/> of analytics, including <strong class="bold">natural language processing</strong>, <strong class="bold">image classification</strong>, and <strong class="bold">time series forecasting</strong>. Let’s explore these applications<a id="_idIndexMarker615" class="pcalibre calibre6 pcalibre1"/> in more detail.</p>
<p class="calibre3">Natural language<a id="_idIndexMarker616" class="pcalibre calibre6 pcalibre1"/> processing is ubiquitous in the era of big data. Surveys often employ free text collection methods. Customers provide text reviews of products. Social scientists jot down notes when they are observing populations qualitatively (dubbed <strong class="bold">ethnographic research</strong>). Bloggers<a id="_idIndexMarker617" class="pcalibre calibre6 pcalibre1"/> post regular content to disseminate ideas. Legal, medical, and educational notes can include biased content that needs to be addressed to protect people from institutional bias that limits future opportunities and wellness.</p>
<p class="calibre3">All this data needs to be parsed before it is fed into a classification model or exploratory data tools. Most of the tools that do this rely on deep learning models that can connect pieces of information separated across a sentence or a paragraph, which are termed <strong class="bold">recurrent neural networks</strong>. Many <a id="_idIndexMarker618" class="pcalibre calibre6 pcalibre1"/>of the common packages in Python rely on pretrained recurrent neural networks, where the training steps have already been performed on a large dataset and saved as a model. Updating the pretrained models <a id="_idIndexMarker619" class="pcalibre calibre6 pcalibre1"/>often involves adjusting the neural network weights and/or connections based on new data, perhaps from a specific domain of interest such as chemistry or law. <em class="italic">Figure 14</em><em class="italic">.4</em> shows a simple recurrent neural network architecture. In practice, recurrent neural networks can have many more hidden layers and nodes with connections between them:</p>
<div><div><img alt="Figure 14.4 – A simple recurrent neural network diagram, where the hidden layers provide feedback to each other in a forward and backward manner" src="img/B21087_14_04.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 14.4 – A simple recurrent neural network diagram, where the hidden layers provide feedback to each other in a forward and backward manner</p>
<p class="calibre3">Another key task in analytics these days is image classification. Social media allows users to upload high volumes of images across a dizzying array of topics that need to be tagged with topic information and flagged if it is not safe content. Trap cameras and drones allow for the surveillance of wildlife and potential poachers in protected areas, and these images need to be analyzed to protect wildlife and divvy up limited resources. Farmers can now monitor crops using robotic imaging technologies, which then match the images to disease classification models for the early identification of disease or distress in crops that endanger local food sources or hurt local economies. <em class="italic">Figure 14</em><em class="italic">.5</em> shows three images that may be used in a training set of an image classifier to identify different types of animals at Kruger National Park in South Africa:</p>
<div><div><img alt="Figure 14.5 – Three images taken at Kruger National Park that could be used within a training sample for an image classifier" src="img/B21087_14_05.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 14.5 – Three images taken at Kruger National Park that could be used within a training sample for an image classifier</p>
<p class="calibre3">From <em class="italic">Figure 14</em><em class="italic">.5</em>, note <a id="_idIndexMarker620" class="pcalibre calibre6 pcalibre1"/>that the images obtained from trap cameras or surveys may not include images of the entire animal, capture multiple animals within an image, have branches or other clutter obscuring the image, or truncate the full animal in the shot. These all pose issues to image classification and can increase sample size needs or classifier architecture complexity. Let’s examine some potential solutions to these issues within deep learning.</p>
<p class="calibre3">Many image classification models utilize a deep learning architecture called <strong class="bold">convolutional neural networks</strong> (<strong class="bold">CNNs</strong>). CNNs <a id="_idIndexMarker621" class="pcalibre calibre6 pcalibre1"/>include many processing layers and a few pooling layers, where the features derived in prior layers are summarized and fed into subsequent layers. This hones in on the most relevant features found in the training process. Just as in natural language processing, many pretrained models exist that can be updated with new data to modify the neural network weights and connections according to the new data.</p>
<p class="calibre3">Now that we know a bit about deep learning models, let’s dive into some of the architectures that are common in deep learning models and how these can be represented as networks.</p>
<h2 id="_idParaDest-189" class="calibre7"><a id="_idTextAnchor189" class="pcalibre calibre6 pcalibre1"/>Deep learning layers and connections</h2>
<p class="calibre3">Despite the <a id="_idIndexMarker622" class="pcalibre calibre6 pcalibre1"/>existence of many deep learning algorithms, they all include multiple processing layers consisting of vertices that are connected by edges. As the algorithm fits layers and connections to optimize its performance on training and test data, the network structure of the deep learning architecture evolves. This means that network science and its related tools, such as those found in the study of simplicial complexes, can be used to guide the fitting process or evaluate the algorithm at certain benchmarks. While this is a relatively new approach to deep learning algorithms, the approach has improved model fit, reduced the sample size needed to get a good fit, and sped up training.</p>
<p class="calibre3">Within image generation, the classification of filtered simplicial complex features—using an algorithm <a id="_idIndexMarker623" class="pcalibre calibre6 pcalibre1"/>called <strong class="bold">persistent homology</strong>—has played an important role in the realistic generation of landscape terrain features and medical features (such as blood vessel branching) through deep learning algorithms called <strong class="bold">generative adversarial networks</strong>, which <a id="_idIndexMarker624" class="pcalibre calibre6 pcalibre1"/>we briefly overviewed in <em class="italic">Chapter 1</em> as the basis for image generators. The combination of network-based metrics in the loss function upon which the network fitting is measured coaxes the algorithm into more realistic image generation.</p>
<p class="calibre3">Artificial image sets are very important within the medical context. Building image classifiers relies on large sample sizes, which might not exist for rare diseases or within small medical systems. Data augmentation through image generation allows us to create larger sample sizes with (hopefully!) realistic images upon which to build other applications, such as image classifiers. This, in turn, allows researchers to glean insight into the etiology of diseases by, say, studying morphological changes in cellular structure in different stages of a disease or identifying aggressive diseases as quickly as possible by matching patient samples to those curated by an algorithm trained on augmented prior patient data.</p>
<h2 id="_idParaDest-190" class="calibre7"><a id="_idTextAnchor190" class="pcalibre calibre6 pcalibre1"/>Analyzing architectures</h2>
<p class="calibre3">Another perspective<a id="_idIndexMarker625" class="pcalibre calibre6 pcalibre1"/> on deep learning architectures as network structures involves exploring good architectures by<a id="_idIndexMarker626" class="pcalibre calibre6 pcalibre1"/> analyzing them using network science tools. <strong class="bold">Large language models</strong> (<strong class="bold">LLMs</strong>) are massive deep learning algorithms that currently involve billions to trillions of parameters to estimate across layers and their connections. They are trained on massive volumes of text data and require high volumes of computing resources to fit the model. Larger models tend to perform better than smaller models, necessitating more data and more computational power. This is not ideal, as computing resources have limitations based on hardware and substantial environmental impacts.</p>
<p class="calibre3">Network<a id="_idIndexMarker627" class="pcalibre calibre6 pcalibre1"/> science provides a potential avenue for finding good, small LLM architectures that require less training data and fewer computational resources to fit. These architectures are more accessible to developers in resource-scarce countries when building models for underrepresented languages, and they offer a path toward sustainable LLM growth.</p>
<p class="calibre3">Coupling this network science approach with training data can reduce the training sample size needed to build an effective LLM, as well. Related documents with similar linguistic structure or content can be sampled from each structure or domain needed within the LLM. This provides comprehensive data that can be quality-checked using fewer resources. Better training data enhances model fitting, reduces training time, and reduces the computational resources needed to fit a good model. Now that we understand a bit about neural network architecture, let’s turn to a type of network that integrates information about hierarchy and layering within its structure.</p>
<h1 id="_idParaDest-191" class="calibre5"><a id="_idTextAnchor191" class="pcalibre calibre6 pcalibre1"/>Hierarchical networks</h1>
<p class="calibre3">In <a href="B21087_11.xhtml#_idTextAnchor145" class="pcalibre calibre6 pcalibre1"><em class="italic">Chapter 11</em></a>, we encountered<a id="_idIndexMarker628" class="pcalibre calibre6 pcalibre1"/> ontologies and phylogenies within the linguistic and genetic context. A <strong class="bold">hierarchical network</strong> builds on the intuition within ontologies and phylogenies; hierarchical networks are tree-like networks that can include multiple sources and sinks flowing from the top of the tree to the bottom of the tree. Gene regulatory networks often follow this hierarchical network structure rather than strictly a tree structure, where multiple sources and sinks do not exist in the network, or an ontology structure, where parent vertices don’t typically exist. <em class="italic">Figure 14</em><em class="italic">.6</em> shows an example of a hierarchical network:</p>
<div><div><img alt="Figure 14.6 – A hierarchical network example where the second layer of the network contains the parents of a vertex in the third layer" src="img/B21087_14_06.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 14.6 – A hierarchical network example where the second layer of the network contains the parents of a vertex in the third layer</p>
<p class="calibre3">Studying gene <a id="_idIndexMarker629" class="pcalibre calibre6 pcalibre1"/>regulation provides insight into myriad areas of research, including the evolutionary pathways within organ systems or species, the pathologies associated with gene dysregulation, and the discernment of cellular functions. Gene regulation isn’t as simple as understanding the gene pathways themselves. Environmental conditions can change the structure of proteins associated with DNA or RNA to make DNA/RNA less or more accessible to the proteins involved in gene transcription. This, in turn, usually modifies the structures of those proteins further, either upregulating or downregulating the rate of transcription through accessibility to DNA/RNA.</p>
<p class="calibre3">Recent advances<a id="_idIndexMarker630" class="pcalibre calibre6 pcalibre1"/> in the<a id="_idIndexMarker631" class="pcalibre calibre6 pcalibre1"/> fields of <strong class="bold">genomics</strong> and <strong class="bold">epigenomics</strong> (which combines genetic analysis with environmental conditions) include measurement tools for gene expression and the structure of proteins around genes (which reflect local environmental conditions). By measuring these levels of expression under different conditions and different genetic mutation lines, it’s possible to discern regulatory pathways within organisms.</p>
<p class="calibre3">Let’s explore higher-order structures in network data from a more theoretical perspective before considering an example of hierarchical networks in snake venom epigenomics.</p>
<h2 id="_idParaDest-192" class="calibre7"><a id="_idTextAnchor192" class="pcalibre calibre6 pcalibre1"/>Higher-order structures and network data</h2>
<p class="calibre3">If we<a id="_idIndexMarker632" class="pcalibre calibre6 pcalibre1"/> think back to <a href="B21087_11.xhtml#_idTextAnchor145" class="pcalibre calibre6 pcalibre1"><em class="italic">Chapter 11</em></a>, language families start with a source—an initial language that evolves over time to other languages. This gives language families a hierarchical structure defined by time (and, typically, geography). Different levels emerge within different time periods, from the time of the original language to the modern-day derivatives of that language.</p>
<p class="calibre3">Within gene <a id="_idIndexMarker633" class="pcalibre calibre6 pcalibre1"/>regulatory pathways, it’s possible for multiple genes to influence those involved in later steps within the regulatory pathway, thus creating a more complicated network structure than a tree. However, order is still important, giving rise to a hierarchical network. Within biological studies, this structure can be hard to discern by using lab experiments, as the structure is not one-to-one, and, occasionally, the effects are not linear. However, recent technological advances allow researchers to discern these pathways more readily by varying the environment and/or knocking out the genes within a pathway.</p>
<p class="calibre3">Now that we know a bit about hierarchical networks, let’s examine a real-world use case where these have shed light on evolutionary pathways and the variance in biological properties across different snake venoms. Venomous species are important for the health of many environments. In recent years, the study of their venom has led to pharmaceutical breakthroughs for human diseases, including non-addictive pain medications, treatments for cardiac diseases, and new antibiotics that can treat drug-resistant strains. Understanding differences across venomous species allows researchers and clinicians to develop better treatments for snake bite victims, allows medical researchers to study venom properties that may be useful in the pharmaceutical treatment of human disorders, and allows conservations to preserve biodiversity.</p>
<h2 id="_idParaDest-193" class="calibre7"><a id="_idTextAnchor193" class="pcalibre calibre6 pcalibre1"/>An example using gene families</h2>
<p class="calibre3">Venomous <a id="_idIndexMarker634" class="pcalibre calibre6 pcalibre1"/>species of snakes deplete venom either in a controlled way (striking prey) or an uncontrolled way (defensive bites when the snake is threatened). Eventually, the venom stores are depleted, and more venom must be produced for the snake to survive. Venom is mostly composed of proteins and polypeptides; given<a id="_idIndexMarker635" class="pcalibre calibre6 pcalibre1"/> this, rapid venom production induces stress on the <strong class="bold">endoplasmic reticulum</strong> (<strong class="bold">ER</strong>), an organelle mainly involved in protein production within a cell. This suggests that the gene families involved in ER regulation may play a role in venom regulation and production.</p>
<p class="calibre3">A recent functional genomics study of the prairie rattlesnake revealed two distinct pathways heavily involved in venom regulation:</p>
<ul class="calibre10">
<li class="calibre11">An extracellular pathway related to the kinase pathway</li>
<li class="calibre11">An ER-related protein pathway</li>
</ul>
<p class="calibre3">This is<a id="_idIndexMarker636" class="pcalibre calibre6 pcalibre1"/> logical, given that the signals would need to respond to exterior conditions (lower concentrations of venom) and interior conditions (overworked ERs); a balance between venom concentration and cellular health makes sense in terms of start and stop signals to regulate how much venom is being produced. Interestingly, these pathways are ubiquitous across species, and it is thought that similar pathways may be involved in general venom regulation.</p>
<p class="calibre3">Let’s examine the phylogenic tree for genetic conservation within one pathway. You can find the image in the Perry 2022 paper cited in the reference section (<em class="italic">Figure 6</em><em class="italic">C</em>). We’ll discuss this image and its implications for evolutionary pathways in the following sections.</p>
<p class="calibre3">This tree suggests that the enhancer region studied in this pathway is conserved for venomous snake species, with a few further mutations occurring along the evolutionary pathway, giving rise to different types of venom with different modes of action within the body of an envenomated prey or predator.</p>
<p class="calibre3">Hierarchical networks allow us to organize information across levels, and visualizations such as <em class="italic">Figure 6</em><em class="italic">C</em> from the Perry 2022 paper allow us to examine other relevant information (such as time) related to the organizational principles in a hierarchical network. However, hierarchical networks may not be flexible enough for some visualizations, and in the next section, we’ll look at an even more flexible visualization tool.</p>
<h1 id="_idParaDest-194" class="calibre5"><a id="_idTextAnchor194" class="pcalibre calibre6 pcalibre1"/>Hypergraphs</h1>
<p class="calibre3">Another exciting<a id="_idIndexMarker637" class="pcalibre calibre6 pcalibre1"/> avenue of research in network science involves <strong class="bold">hypergraphs</strong>, which are an extension of networks in which multi-way relationships can include multiple vertices. In this way, the concept of edges is extended in a similar way to how the concept of edges was extended in <a href="B21087_06.xhtml#_idTextAnchor078" class="pcalibre calibre6 pcalibre1"><em class="italic">Chapter 6</em></a>, within the <em class="italic">Extending network metrics for time series analytics</em> section on simplicial complexes. In fact, the abstraction of simplicial complexes is one type of hypergraph.</p>
<p class="calibre3">Hypergraphs are often useful for visualizing database diagrams and planning information retrieval systems, where many-to-many relationships often exist. Some distributed computing systems even provide hypergraph algorithms to aid in these retrieval tasks at scale.</p>
<p class="calibre3">Visualization<a id="_idIndexMarker638" class="pcalibre calibre6 pcalibre1"/> via hypergraphs is also used extensively in bioinformatics, where multi-way relationships exist between proteins, biological pathways, gene expression datasets, and metabolic processes. In complex systems, it is often easier to show relationships visually than to show a matrix or a list of the relationships. It’s also much more compact to use this representation as opposed to diagrams with many overlapping lines or complicated tables.</p>
<p class="calibre3">Let’s dive into the particulars of hypergraph visualization and then move on to a real-world example of hypergraphs simplifying data visualization within bioinformatics.</p>
<h2 id="_idParaDest-195" class="calibre7"><a id="_idTextAnchor195" class="pcalibre calibre6 pcalibre1"/>Displaying information</h2>
<p class="calibre3">In science, it’s <a id="_idIndexMarker639" class="pcalibre calibre6 pcalibre1"/>important to communicate clearly and concisely, particularly when discussing complicated or nuanced concepts that may be very unfamiliar to readers. Accurate and concise infographics provide readers with alternative representations of material compared to long, jargon-laden paragraphs. This makes the material more accessible to a wider audience. For a new algorithm in machine learning or a new measurement tool in bioinformatics, the difference between a cool tool that is rarely adopted and a tool that people leverage to solve real problems is often a matter of marketing. Solid communication that invites readers into the material results in a larger and more diverse audience.</p>
<p class="calibre3">Let’s consider four different ways of communicating a biological network’s complex relationships to an audience. The first way is simply through text. Perhaps there are five pathways that overlap at certain stages within the pathway. <strong class="bold">Pathway 1</strong> follows its own pathway until merging with <strong class="bold">Pathways 2</strong> and <strong class="bold">3,</strong> which initially overlapped but then diverged after merging with <strong class="bold">Pathway 1</strong>. <strong class="bold">Pathway 4</strong> emerges on its own and then connects with <strong class="bold">Pathway 2</strong>. <strong class="bold">Pathway 5</strong> emerges on its own and then connects to <strong class="bold">Pathway 3</strong>. Can you picture this in your head as you read the text? It’s difficult to visualize all of these pathways through text.</p>
<p class="calibre3">We could also show this via a table of relationships. For five pathways, this isn’t terrible to visualize when using a pathway table, such as <em class="italic">Table 14.1</em>. However, consider what a table like this would look like for a complicated metabolic process or gene network that includes dozens or hundreds of pathways. Visualizing those through a table is not ideal:</p>
<table class="no-table-style" id="table001-4">
<colgroup class="calibre12">
<col class="calibre13"/>
<col class="calibre13"/>
<col class="calibre13"/>
<col class="calibre13"/>
<col class="calibre13"/>
<col class="calibre13"/>
</colgroup>
<thead class="calibre19">
<tr class="no-table-style1">
<td class="no-table-style2"/>
<td class="no-table-style2">
<p class="calibre3"><strong class="bold">Pathway 1</strong></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><strong class="bold">Pathway 2</strong></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><strong class="bold">Pathway 3</strong></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><strong class="bold">Pathway 4</strong></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><strong class="bold">Pathway 5</strong></p>
</td>
</tr>
</thead>
<tbody class="calibre14">
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3">Pathway 1</p>
</td>
<td class="no-table-style2"/>
<td class="no-table-style2">
<p class="calibre3">X</p>
</td>
<td class="no-table-style2">
<p class="calibre3">X</p>
</td>
<td class="no-table-style2">
<p class="calibre3">X</p>
</td>
<td class="no-table-style2">
<p class="calibre3">X</p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3">Pathway 2</p>
</td>
<td class="no-table-style2">
<p class="calibre3">X</p>
</td>
<td class="no-table-style2"/>
<td class="no-table-style2"/>
<td class="no-table-style2">
<p class="calibre3">X</p>
</td>
<td class="no-table-style2"/>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3">Pathway 3</p>
</td>
<td class="no-table-style2">
<p class="calibre3">X</p>
</td>
<td class="no-table-style2"/>
<td class="no-table-style2"/>
<td class="no-table-style2"/>
<td class="no-table-style2">
<p class="calibre3">X</p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3">Pathway 4</p>
</td>
<td class="no-table-style2">
<p class="calibre3">X</p>
</td>
<td class="no-table-style2">
<p class="calibre3">X</p>
</td>
<td class="no-table-style2"/>
<td class="no-table-style2"/>
<td class="no-table-style2"/>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3">Pathway 5</p>
</td>
<td class="no-table-style2">
<p class="calibre3">X</p>
</td>
<td class="no-table-style2"/>
<td class="no-table-style2">
<p class="calibre3">X</p>
</td>
<td class="no-table-style2"/>
<td class="no-table-style2"/>
</tr>
</tbody>
</table>
<p class="img---caption" lang="en-US" xml:lang="en-US">Table 14.1 – A table showing pathway overlap across five metabolic pathways within an organism</p>
<p class="calibre3">Let’s now <a id="_idIndexMarker640" class="pcalibre calibre6 pcalibre1"/>consider a network with each pathway represented as a vertex and each connection through the metabolic pathways as an edge. While the limited number of pathways doesn’t create a terribly messy graph, this representation will not scale, particularly as the pathway edges scale with the addition of more vertices. When reaching a dozen pathways, it would be very difficult to discern which edges connect which vertices by using this approach. <em class="italic">Figure 14</em><em class="italic">.7</em> shows the metabolic pathway example visualized as a network:</p>
<div><div><img alt="Figure 14.7 – A network representation of the relationships in metabolic pathways" src="img/B21087_14_07.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 14.7 – A network representation of the relationships in metabolic pathways</p>
<p class="calibre3">Finally, let’s <a id="_idIndexMarker641" class="pcalibre calibre6 pcalibre1"/>consider a hypergraph representation of these pathways and their overlap. This approach looks a bit like a Venn diagram showing set overlaps, with different colors or textures parsing out the relationships into sets of related items. If given a temporal component to the data, we could even create evolving hypergraph representations for each branch point of the metabolic pathways. This is much easier to convey to a reader as the number of pathways increases, and considering this evolving network as a set of items allows for easier computation in terms of the changes and properties across evolving sets. <em class="italic">Figure 14</em><em class="italic">.8</em> shows a hypergraph representation with temporal components included:</p>
<div><div><img alt="Figure 14.8 – A hypergraph representation of the metabolic pathways across time" src="img/B21087_14_08.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 14.8 – A hypergraph representation of the metabolic pathways across time</p>
<p class="calibre3"><em class="italic">Figure 14</em><em class="italic">.8</em> captures<a id="_idIndexMarker642" class="pcalibre calibre6 pcalibre1"/> both pathway-merging information and a temporal aspect as the pathways run to completion. This is much easier to understand than the text or the table representations and will scale more easily than a simple network diagram. Hypergraphs are useful visualization tools that scale well for complex problems.</p>
<h2 id="_idParaDest-196" class="calibre7"><a id="_idTextAnchor196" class="pcalibre calibre6 pcalibre1"/>Metadata</h2>
<p class="calibre3">Oftentimes, networks<a id="_idIndexMarker643" class="pcalibre calibre6 pcalibre1"/> include metadata about edges or vertices in the network, which are typically stored in tables. As we mentioned earlier in this section, hypergraphs are useful tools when wrangling complex databases. In fact, hypergraph databases exist and can be quite helpful in the data management of OWL databases, language topic models, document storage, and much more. The flexibility of hypergraph databases compared to graph databases includes the ability to easily capture and represent multi-way connections and interactions between data tables, documents, or sets of tables or documents.</p>
<p class="calibre3">In returning <a id="_idIndexMarker644" class="pcalibre calibre6 pcalibre1"/>to our bioinformatics example, hypergraph databases are ideal for managing bioinformatics data related to genes, proteins, metabolic pathways, or other interconnected sets of processes. The layers can represent the different aspects of pathway overlap, different periods of time, or different organisms with overlapping metabolic or regulatory pathways.</p>
<p class="calibre3">Consider the venom example in the previous section. A hypergraph database could contain all the known gene pathways associated with venom production across venomous organisms. Phylogenic relationships, distribution geographies, antivenin classes, and other types of metadata can be used to connect groups of gene pathways to facilitate the study of particular genes or regulatory functions across habitats, species, and interactions with human populations. Updating this type of knowledge periodically as new papers are published would accelerate research in the field and tie in different branches of knowledge in a manner that is easy for researchers to access.</p>
<p class="calibre3">Given the utility of hypergraph databases, we are likely to see more development in this field of network science in the coming years.</p>
<h1 id="_idParaDest-197" class="calibre5"><a id="_idTextAnchor197" class="pcalibre calibre6 pcalibre1"/>Summary</h1>
<p class="calibre3">In this chapter, we’ve pushed the limits of network science by merging network algorithms with quantum computing frameworks, enhanced our understanding of scaling the deep learning algorithms that are ubiquitous in modern data science, and explored special types of networks that are critical in molecular biology and genetics. Network science plays an important role in data science, offering scalability and novel solutions to common problems. As the field of network science evolves, data science and its practitioners will continue to benefit. We hope this book will equip and inspire anyone who works with data to push the boundaries of knowledge and solve difficult problems in the world by using data. Come join us!</p>
<h1 id="_idParaDest-198" class="calibre5"><a id="_idTextAnchor198" class="pcalibre calibre6 pcalibre1"/>References</h1>
<p class="calibre3">Berkolaiko, G., &amp; Kuchment, P. (2013). <em class="italic">Introduction to quantum graphs</em> (No. 186). American Mathematical Soc.</p>
<p class="calibre3">Biamonte, J., Wittek, P., Pancotti, N., Rebentrost, P., Wiebe, N., &amp; Lloyd, S. (2017). <em class="italic">Quantum machine learning</em>. <em class="italic">Nature</em>, <em class="italic">549</em>(7671), 195-202.</p>
<p class="calibre3">Cerezo, M., Verdon, G., Huang, H. Y., Cincio, L., &amp; Coles, P. J. (2022). <em class="italic">Challenges and opportunities in quantum machine learning</em>. <em class="italic">Nature Computational Science</em>, <em class="italic">2</em>(9), 567-576.</p>
<p class="calibre3">Cui, S. X., Freedman, M. H., Sattath, O., Stong, R., &amp; Minton, G. (2016). <em class="italic">Quantum max-flow/min-cut</em>. <em class="italic">Journal of Mathematical </em><em class="italic">Physics</em>, <em class="italic">57</em>(6).</p>
<p class="calibre3">Ekanayake, E. M. U. S. B., Daundasekara, W. B., &amp; Perera, S. P. C. (2022). <em class="italic">New Approach to Obtain the Maximum Flow in a Network and Optimal Solution for the Transportation Problems</em>. <em class="italic">Modern Applied Science</em>, <em class="italic">16</em>(1), 30.</p>
<p class="calibre3">Feng, S., Heath, E., Jefferson, B., Joslyn, C., Kvinge, H., Mitchell, H. D., ... &amp; Purvine, E. (2021). <em class="italic">Hypergraph models of biological networks to identify genes critical to pathogenic viral response</em>. <em class="italic">BMC bioinformatics</em>, <em class="italic">22</em>(1), 1-21.</p>
<p class="calibre3">Iordanov, B. (2010). <em class="italic">Hypergraphdb: a generalized graph database</em>. In <em class="italic">Web-Age Information Management: WAIM 2010 International Workshops: IWGD 2010, XMLDM 2010, WCMT 2010, Jiuzhaigou Valley, China, July 15-17, 2010 Revised Selected Papers 11</em> (pp. 25-36). Springer Berlin Heidelberg.</p>
<p class="calibre3">James, D. F., Kwiat, P. G., Munro, W. J., &amp; White, A. G. (2001). <em class="italic">Measurement of qubits</em>. <em class="italic">Physical Review A</em>, <em class="italic">64</em>(5), 052312.</p>
<p class="calibre3">Karlebach, G., &amp; Shamir, R. (2008). <em class="italic">Modelling and analysis of gene regulatory networks</em>. <em class="italic">Nature reviews Molecular cell biology</em>, <em class="italic">9</em>(10), 770-780.</p>
<p class="calibre3">Leighton, F. T. (1979). <em class="italic">A graph coloring algorithm for large scheduling problems</em>. <em class="italic">Journal of research of the national bureau of standards</em>, <em class="italic">84</em>(6), 489.</p>
<p class="calibre3">Perry, B. W., Gopalan, S. S., Pasquesi, G. I., Schield, D. R., Westfall, A. K., Smith, C. F., ... &amp; Castoe, T. A. (2022). <em class="italic">Snake venom gene expression is coordinated by novel regulatory architecture and the integration of multiple co-opted vertebrate pathways</em>. <em class="italic">Genome Research</em>, <em class="italic">32</em>(6), 1058-1073.</p>
<p class="calibre3">Titiloye, O., &amp; Crispin, A. (2011). <em class="italic">Quantum annealing of the graph coloring problem</em>. <em class="italic">Discrete Optimization</em>, <em class="italic">8</em>(2), 376-384.</p>
<p class="calibre3">Vidya, V., Achar, R. R., Himathi, M. U., Akshita, N., Kameshwar, V. H., Byrappa, K., &amp; Ramadas, D. (2021). <em class="italic">Venom peptides–A comprehensive translational perspective in pain management</em>. <em class="italic">Current Research in Toxicology</em>, <em class="italic">2</em>, 329-340.</p>
<p class="calibre3">Wittek, P. (2014). <em class="italic">Quantum machine learning: what quantum computing means to data mining</em>. Academic Press.</p>
</div>
</body></html>