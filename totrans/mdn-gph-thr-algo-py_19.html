<html><head></head><body>
<div id="_idContainer175" class="calibre2">
<h1 class="chapter-number" id="_idParaDest-183"><a id="_idTextAnchor183" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.1.1">14</span></h1>
<h1 id="_idParaDest-184" class="calibre5"><a id="_idTextAnchor184" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.2.1">New Frontiers</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.3.1">In the previous chapters, we overviewed many of the tools and applications of network science within analytics projects. </span><span class="kobospan" id="kobo.3.2">In this chapter, we’ll look ahead toward the newer tools being developed that have many promising applications within network science, including quantum graph algorithms, deep learning/large language model architecture optimization, and multilevel graphs that are useful for organizing metadata and understanding </span><span><span class="kobospan" id="kobo.4.1">genetics data.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.5.1">While the prior chapters included coded examples, this chapter will focus on ideas and the possibilities for development in the future. </span><span class="kobospan" id="kobo.5.2">Network science is an evolving field, and it’s likely that tools we can’t even imagine right now will be commonplace in the next decade. </span><span class="kobospan" id="kobo.5.3">Let’s dive into some of the newer applications and see how network science continues to contribute to knowledge in many </span><span><span class="kobospan" id="kobo.6.1">different fields.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.7.1">Specifically, we will cover the </span><span><span class="kobospan" id="kobo.8.1">following topics:</span></span></p>
<ul class="calibre10">
<li class="calibre11"><span class="kobospan" id="kobo.9.1">Quantum network </span><span><span class="kobospan" id="kobo.10.1">science algorithms</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.11.1">Neural network architectures </span><span><span class="kobospan" id="kobo.12.1">as graphs</span></span></li>
<li class="calibre11"><span><span class="kobospan" id="kobo.13.1">Hierarchical networks</span></span></li>
<li class="calibre11"><span><span class="kobospan" id="kobo.14.1">Hypergraphs</span></span></li>
</ul>
<h1 id="_idParaDest-185" class="calibre5"><a id="_idTextAnchor185" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.15.1">Quantum network science algorithms</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.16.1">One new </span><a id="_idIndexMarker600" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.17.1">and promising avenue for network science algorithm development is quantum computing. </span><strong class="bold"><span class="kobospan" id="kobo.18.1">Quantum computing</span></strong><span class="kobospan" id="kobo.19.1"> leverages </span><a id="_idIndexMarker601" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.20.1">many of the advantageous properties of physics at the quantum level to improve computing power and tackle difficult problems. </span><span class="kobospan" id="kobo.20.2">While</span><a id="_idIndexMarker602" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.21.1"> there are many flavors of quantum computing, we’ll focus on </span><strong class="bold"><span class="kobospan" id="kobo.22.1">qubit</span></strong><span class="kobospan" id="kobo.23.1"> systems, where bits are replaced with their </span><span><span class="kobospan" id="kobo.24.1">quantum version.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.25.1">Qubits offer many advantages over bits within computing frameworks. </span><strong class="bold"><span class="kobospan" id="kobo.26.1">Superposition</span></strong><span class="kobospan" id="kobo.27.1"> is a </span><a id="_idIndexMarker603" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.28.1">property in quantum physics that allows particles, such as qubits, to exist in multiple states at the same time. </span><span class="kobospan" id="kobo.28.2">Thus, whereas bits must exist in a </span><strong class="source-inline"><span class="kobospan" id="kobo.29.1">0</span></strong><span class="kobospan" id="kobo.30.1"> or </span><strong class="source-inline"><span class="kobospan" id="kobo.31.1">1</span></strong><span class="kobospan" id="kobo.32.1"> configuration, qubits can exist as a </span><strong class="source-inline"><span class="kobospan" id="kobo.33.1">1</span></strong><span class="kobospan" id="kobo.34.1"> and a </span><strong class="source-inline"><span class="kobospan" id="kobo.35.1">0</span></strong><span class="kobospan" id="kobo.36.1"> simultaneously until the qubit is measured, collapsing to the usual state of a bit. </span><span class="kobospan" id="kobo.36.2">This allows for massively parallel searches </span><span><span class="kobospan" id="kobo.37.1">for solutions.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.38.1">In addition </span><a id="_idIndexMarker604" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.39.1">to being able to exist as a </span><strong class="source-inline"><span class="kobospan" id="kobo.40.1">1</span></strong><span class="kobospan" id="kobo.41.1"> and a </span><strong class="source-inline"><span class="kobospan" id="kobo.42.1">0</span></strong><span class="kobospan" id="kobo.43.1"> at the same time, superposition allows for fractional values where the qubit exists as partially a </span><strong class="source-inline"><span class="kobospan" id="kobo.44.1">1</span></strong><span class="kobospan" id="kobo.45.1"> and partially a </span><strong class="source-inline"><span class="kobospan" id="kobo.46.1">0</span></strong><span class="kobospan" id="kobo.47.1"> in a probabilistic sense. </span><span class="kobospan" id="kobo.47.2">Because of this fractional state, it’s possible to design gates that work on the probability function rather than acting on single states of a bit. </span><span class="kobospan" id="kobo.47.3">This flexibility allows for circuit designs to enhance algorithms, and such an approach to computing has shown gains in image classification. </span><span><em class="italic"><span class="kobospan" id="kobo.48.1">Figure 14</span></em></span><em class="italic"><span class="kobospan" id="kobo.49.1">.1</span></em><span class="kobospan" id="kobo.50.1"> shows the differences between a qubit and </span><span><span class="kobospan" id="kobo.51.1">a bit:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer167">
<span class="kobospan" id="kobo.52.1"><img alt="Figure 14.1 – A visualization of qubits versus bits" src="image/B21087_14_01.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.53.1">Figure 14.1 – A visualization of qubits versus bits</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.54.1">Many types of machine learning algorithms have been translated for use on quantum computers to speed up solution convergence or scale algorithms to larger problems. </span><span class="kobospan" id="kobo.54.2">Quantum machine learning is an active area of research, and network science algorithms are one of the larger areas of research within quantum machine learning. </span><span class="kobospan" id="kobo.54.3">Let’s explore two quantum network science algorithms in </span><span><span class="kobospan" id="kobo.55.1">more detail.</span></span></p>
<h2 id="_idParaDest-186" class="calibre7"><a id="_idTextAnchor186" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.56.1">Graph coloring algorithms</span></h2>
<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.57.1">Graph coloring algorithms</span></strong><span class="kobospan" id="kobo.58.1"> are </span><a id="_idIndexMarker605" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.59.1">a branch of network science algorithms aimed at finding the chromatic number of a graph. </span><span class="kobospan" id="kobo.59.2">A </span><strong class="bold"><span class="kobospan" id="kobo.60.1">chromatic number</span></strong><span class="kobospan" id="kobo.61.1"> is the</span><a id="_idIndexMarker606" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.62.1"> minimum number of colors required to color the vertices of a network such that no colors are adjacent to the same color. </span><span class="kobospan" id="kobo.62.2">In</span><a id="_idIndexMarker607" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.63.1"> real-world applications, chromatic numbers are important in determining the number of channels to allocate in communication systems or scheduling jobs within parallel processing. </span><span class="kobospan" id="kobo.63.2">The minimum number of colors required to color the vertices of a network represents the minimum number of channels needed or the minimum number of jobs needed to complete the aforementioned tasks. </span><span><em class="italic"><span class="kobospan" id="kobo.64.1">Figure 14</span></em></span><em class="italic"><span class="kobospan" id="kobo.65.1">.2</span></em><span class="kobospan" id="kobo.66.1"> shows a small network with the </span><span><span class="kobospan" id="kobo.67.1">colors shown:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer168">
<span class="kobospan" id="kobo.68.1"><img alt="Figure 14.2 – A small network with four vertices, four edges, and a chromatic number of two" src="image/B21087_14_02.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.69.1">Figure 14.2 – A small network with four vertices, four edges, and a chromatic number of two</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.70.1">While </span><span><em class="italic"><span class="kobospan" id="kobo.71.1">Figure 14</span></em></span><em class="italic"><span class="kobospan" id="kobo.72.1">.2</span></em><span class="kobospan" id="kobo.73.1"> has an easy-to-determine chromatic number, computing the chromatic number of a network, in general, is</span><a id="_idIndexMarker608" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.74.1"> thought to be </span><strong class="bold"><span class="kobospan" id="kobo.75.1">NP-hard</span></strong><span class="kobospan" id="kobo.76.1">, meaning that it is not solvable in polynomial time. </span><span class="kobospan" id="kobo.76.2">Algorithms that have high complexity translates to computation that is very difficult or currently impossible for large enough or dense enough networks. </span><span class="kobospan" id="kobo.76.3">This poses problems in terms of solving problems in communication and job scheduling where the volume of calls or jobs is </span><span><span class="kobospan" id="kobo.77.1">very large.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.78.1">Fortunately, quantum graph coloring algorithms allow algorithms to run much faster than they do on classical machines, leading to quicker solutions for large graphs and potentially computable solutions for very large graphs. </span><span class="kobospan" id="kobo.78.2">However, current quantum hardware systems limit the size of a graph on which a quantum graph coloring algorithm can be run, as the problem must be mapped to the physical system. </span><span class="kobospan" id="kobo.78.3">As quantum hardware supports larger and larger networks, chromatic number computation will be feasible for more </span><span><span class="kobospan" id="kobo.79.1">real-world problems.</span></span></p>
<h2 id="_idParaDest-187" class="calibre7"><a id="_idTextAnchor187" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.80.1">Max flow/min cut</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.81.1">In </span><a href="B21087_04.xhtml#_idTextAnchor053" class="pcalibre calibre6 pcalibre1"><span><em class="italic"><span class="kobospan" id="kobo.82.1">Chapter 4</span></em></span></a><span class="kobospan" id="kobo.83.1">, we explored </span><strong class="bold"><span class="kobospan" id="kobo.84.1">transportation logistics</span></strong><span class="kobospan" id="kobo.85.1"> and the </span><strong class="bold"><span class="kobospan" id="kobo.86.1">max flow/min cut algorithm</span></strong><span class="kobospan" id="kobo.87.1">. </span><span class="kobospan" id="kobo.87.2">Recall </span><a id="_idIndexMarker609" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.88.1">that </span><a id="_idIndexMarker610" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.89.1">this algorithm is useful in partitioning flows on networks and that it can be used to plan out road closures on a traffic grid, such as the grid shown in </span><span><em class="italic"><span class="kobospan" id="kobo.90.1">Figure 14</span></em></span><span><em class="italic"><span class="kobospan" id="kobo.91.1">.3</span></em></span><span><span class="kobospan" id="kobo.92.1">:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer169">
<span class="kobospan" id="kobo.93.1"><img alt="Figure 14.3 – A traffic grid in relation to five stores (considered in Chapter 4)" src="image/B21087_14_03.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.94.1">Figure 14.3 – A traffic grid in relation to five stores (considered in Chapter 4)</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.95.1">Finding the optimal cut to avoid service delays to each of these five stores (shown in </span><span><em class="italic"><span class="kobospan" id="kobo.96.1">Figure 14</span></em></span><em class="italic"><span class="kobospan" id="kobo.97.1">.3</span></em><span class="kobospan" id="kobo.98.1">) is a difficult problem to compute, and computationally efficient solutions provide a good way to scale these types </span><span><span class="kobospan" id="kobo.99.1">of analyses.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.100.1">Another common use of the max flow/min cut algorithm is image partitioning, whereby the foreground and background of an image are determined. </span><span class="kobospan" id="kobo.100.2">Image enhancement typically relies on distinguishing different parts of focus within the image. </span><span class="kobospan" id="kobo.100.3">Photoshopping images also requires a foreground/background </span><span><span class="kobospan" id="kobo.101.1">discernment step.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.102.1">As with </span><a id="_idIndexMarker611" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.103.1">chromatic number calculations, computing max flow/min cut optima on large or dense graphs can be challenging when dealing with classical systems. </span><span class="kobospan" id="kobo.103.2">Quantum versions of this algorithm exist and can optimize solutions more easily than classical versions. </span><span class="kobospan" id="kobo.103.3">However, hardware size currently limits the application of quantum max flow/min cut algorithms on </span><span><span class="kobospan" id="kobo.104.1">large problems.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.105.1">Many other</span><a id="_idIndexMarker612" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.106.1"> quantum versions of network algorithms exist and have given strong results on small problems, representing a solid future direction for scaling network algorithms in terms of newer approaches to hardware. </span><span class="kobospan" id="kobo.106.2">As hardware development progresses, it’s likely that network science will benefit, and the algorithms in network science that currently don’t scale as well as other network science algorithms will find a path forward for difficult problems. </span><span class="kobospan" id="kobo.106.3">So far, network science algorithms represent a major part of quantum machine learning research, and given their success, it’s likely that network science and quantum computing will continue to influence </span><span><span class="kobospan" id="kobo.107.1">each other.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.108.1">Let’s turn our attention to deep learning architectures, which can be formulated in both classical computing and </span><span><span class="kobospan" id="kobo.109.1">quantum computing.</span></span></p>
<h1 id="_idParaDest-188" class="calibre5"><a id="_idTextAnchor188" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.110.1">Neural network architectures as graphs</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.111.1">In </span><a href="B21087_01.xhtml#_idTextAnchor016" class="pcalibre calibre6 pcalibre1"><span><em class="italic"><span class="kobospan" id="kobo.112.1">Chapter 1</span></em></span></a><span class="kobospan" id="kobo.113.1">, we touched </span><a id="_idIndexMarker613" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.114.1">on deep learning models, particularly in the context of generative artificial intelligence. </span><span class="kobospan" id="kobo.114.2">Deep learning models surface in many areas</span><a id="_idIndexMarker614" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.115.1"> of analytics, including </span><strong class="bold"><span class="kobospan" id="kobo.116.1">natural language processing</span></strong><span class="kobospan" id="kobo.117.1">, </span><strong class="bold"><span class="kobospan" id="kobo.118.1">image classification</span></strong><span class="kobospan" id="kobo.119.1">, and </span><strong class="bold"><span class="kobospan" id="kobo.120.1">time series forecasting</span></strong><span class="kobospan" id="kobo.121.1">. </span><span class="kobospan" id="kobo.121.2">Let’s explore these applications</span><a id="_idIndexMarker615" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.122.1"> in </span><span><span class="kobospan" id="kobo.123.1">more detail.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.124.1">Natural language</span><a id="_idIndexMarker616" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.125.1"> processing is ubiquitous in the era of big data. </span><span class="kobospan" id="kobo.125.2">Surveys often employ free text collection methods. </span><span class="kobospan" id="kobo.125.3">Customers provide text reviews of products. </span><span class="kobospan" id="kobo.125.4">Social scientists jot down notes when they are observing populations qualitatively (dubbed </span><strong class="bold"><span class="kobospan" id="kobo.126.1">ethnographic research</span></strong><span class="kobospan" id="kobo.127.1">). </span><span class="kobospan" id="kobo.127.2">Bloggers</span><a id="_idIndexMarker617" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.128.1"> post regular content to disseminate ideas. </span><span class="kobospan" id="kobo.128.2">Legal, medical, and educational notes can include biased content that needs to be addressed to protect people from institutional bias that limits future opportunities </span><span><span class="kobospan" id="kobo.129.1">and wellness.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.130.1">All this data needs to be parsed before it is fed into a classification model or exploratory data tools. </span><span class="kobospan" id="kobo.130.2">Most of the tools that do this rely on deep learning models that can connect pieces of information separated across a sentence or a paragraph, which are termed </span><strong class="bold"><span class="kobospan" id="kobo.131.1">recurrent neural networks</span></strong><span class="kobospan" id="kobo.132.1">. </span><span class="kobospan" id="kobo.132.2">Many </span><a id="_idIndexMarker618" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.133.1">of the common packages in Python rely on pretrained recurrent neural networks, where the training steps have already been performed on a large dataset and saved as a model. </span><span class="kobospan" id="kobo.133.2">Updating the pretrained models </span><a id="_idIndexMarker619" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.134.1">often involves adjusting the neural network weights and/or connections based on new data, perhaps from a specific domain of interest such as chemistry or law. </span><span><em class="italic"><span class="kobospan" id="kobo.135.1">Figure 14</span></em></span><em class="italic"><span class="kobospan" id="kobo.136.1">.4</span></em><span class="kobospan" id="kobo.137.1"> shows a simple recurrent neural network architecture. </span><span class="kobospan" id="kobo.137.2">In practice, recurrent neural networks can have many more hidden layers and nodes with connections </span><span><span class="kobospan" id="kobo.138.1">between them:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer170">
<span class="kobospan" id="kobo.139.1"><img alt="Figure 14.4 – A simple recurrent neural network diagram, where the hidden layers provide feedback to each other in a forward and backward manner" src="image/B21087_14_04.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.140.1">Figure 14.4 – A simple recurrent neural network diagram, where the hidden layers provide feedback to each other in a forward and backward manner</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.141.1">Another key task in analytics these days is image classification. </span><span class="kobospan" id="kobo.141.2">Social media allows users to upload high volumes of images across a dizzying array of topics that need to be tagged with topic information and flagged if it is not safe content. </span><span class="kobospan" id="kobo.141.3">Trap cameras and drones allow for the surveillance of wildlife and potential poachers in protected areas, and these images need to be analyzed to protect wildlife and divvy up limited resources. </span><span class="kobospan" id="kobo.141.4">Farmers can now monitor crops using robotic imaging technologies, which then match the images to disease classification models for the early identification of disease or distress in crops that endanger local food sources or hurt local economies. </span><span><em class="italic"><span class="kobospan" id="kobo.142.1">Figure 14</span></em></span><em class="italic"><span class="kobospan" id="kobo.143.1">.5</span></em><span class="kobospan" id="kobo.144.1"> shows three images that may be used in a training set of an image classifier to identify different types of animals at Kruger National Park in </span><span><span class="kobospan" id="kobo.145.1">South Africa:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer171">
<span class="kobospan" id="kobo.146.1"><img alt="Figure 14.5 – Three images taken at Kruger National Park that could be used within a training sample for an image classifier" src="image/B21087_14_05.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.147.1">Figure 14.5 – Three images taken at Kruger National Park that could be used within a training sample for an image classifier</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.148.1">From </span><span><em class="italic"><span class="kobospan" id="kobo.149.1">Figure 14</span></em></span><em class="italic"><span class="kobospan" id="kobo.150.1">.5</span></em><span class="kobospan" id="kobo.151.1">, note </span><a id="_idIndexMarker620" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.152.1">that the images obtained from trap cameras or surveys may not include images of the entire animal, capture multiple animals within an image, have branches or other clutter obscuring the image, or truncate the full animal in the shot. </span><span class="kobospan" id="kobo.152.2">These all pose issues to image classification and can increase sample size needs or classifier architecture complexity. </span><span class="kobospan" id="kobo.152.3">Let’s examine some potential solutions to these issues within </span><span><span class="kobospan" id="kobo.153.1">deep learning.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.154.1">Many image classification models utilize a deep learning architecture called </span><strong class="bold"><span class="kobospan" id="kobo.155.1">convolutional neural networks</span></strong><span class="kobospan" id="kobo.156.1"> (</span><strong class="bold"><span class="kobospan" id="kobo.157.1">CNNs</span></strong><span class="kobospan" id="kobo.158.1">). </span><span class="kobospan" id="kobo.158.2">CNNs </span><a id="_idIndexMarker621" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.159.1">include many processing layers and a few pooling layers, where the features derived in prior layers are summarized and fed into subsequent layers. </span><span class="kobospan" id="kobo.159.2">This hones in on the most relevant features found in the training process. </span><span class="kobospan" id="kobo.159.3">Just as in natural language processing, many pretrained models exist that can be updated with new data to modify the neural network weights and connections according to the </span><span><span class="kobospan" id="kobo.160.1">new data.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.161.1">Now that we know a bit about deep learning models, let’s dive into some of the architectures that are common in deep learning models and how these can be represented </span><span><span class="kobospan" id="kobo.162.1">as networks.</span></span></p>
<h2 id="_idParaDest-189" class="calibre7"><a id="_idTextAnchor189" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.163.1">Deep learning layers and connections</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.164.1">Despite the </span><a id="_idIndexMarker622" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.165.1">existence of many deep learning algorithms, they all include multiple processing layers consisting of vertices that are connected by edges. </span><span class="kobospan" id="kobo.165.2">As the algorithm fits layers and connections to optimize its performance on training and test data, the network structure of the deep learning architecture evolves. </span><span class="kobospan" id="kobo.165.3">This means that network science and its related tools, such as those found in the study of simplicial complexes, can be used to guide the fitting process or evaluate the algorithm at certain benchmarks. </span><span class="kobospan" id="kobo.165.4">While this is a relatively new approach to deep learning algorithms, the approach has improved model fit, reduced the sample size needed to get a good fit, and sped </span><span><span class="kobospan" id="kobo.166.1">up training.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.167.1">Within image generation, the classification of filtered simplicial complex features—using an algorithm </span><a id="_idIndexMarker623" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.168.1">called </span><strong class="bold"><span class="kobospan" id="kobo.169.1">persistent homology</span></strong><span class="kobospan" id="kobo.170.1">—has played an important role in the realistic generation of landscape terrain features and medical features (such as blood vessel branching) through deep learning algorithms called </span><strong class="bold"><span class="kobospan" id="kobo.171.1">generative adversarial networks</span></strong><span class="kobospan" id="kobo.172.1">, which </span><a id="_idIndexMarker624" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.173.1">we briefly overviewed in </span><span><em class="italic"><span class="kobospan" id="kobo.174.1">Chapter 1</span></em></span><span class="kobospan" id="kobo.175.1"> as the basis for image generators. </span><span class="kobospan" id="kobo.175.2">The combination of network-based metrics in the loss function upon which the network fitting is measured coaxes the algorithm into more realistic </span><span><span class="kobospan" id="kobo.176.1">image generation.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.177.1">Artificial image sets are very important within the medical context. </span><span class="kobospan" id="kobo.177.2">Building image classifiers relies on large sample sizes, which might not exist for rare diseases or within small medical systems. </span><span class="kobospan" id="kobo.177.3">Data augmentation through image generation allows us to create larger sample sizes with (hopefully!) realistic images upon which to build other applications, such as image classifiers. </span><span class="kobospan" id="kobo.177.4">This, in turn, allows researchers to glean insight into the etiology of diseases by, say, studying morphological changes in cellular structure in different stages of a disease or identifying aggressive diseases as quickly as possible by matching patient samples to those curated by an algorithm trained on augmented prior </span><span><span class="kobospan" id="kobo.178.1">patient data.</span></span></p>
<h2 id="_idParaDest-190" class="calibre7"><a id="_idTextAnchor190" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.179.1">Analyzing architectures</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.180.1">Another perspective</span><a id="_idIndexMarker625" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.181.1"> on deep learning architectures as network structures involves exploring good architectures by</span><a id="_idIndexMarker626" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.182.1"> analyzing them using network science tools. </span><strong class="bold"><span class="kobospan" id="kobo.183.1">Large language models</span></strong><span class="kobospan" id="kobo.184.1"> (</span><strong class="bold"><span class="kobospan" id="kobo.185.1">LLMs</span></strong><span class="kobospan" id="kobo.186.1">) are massive deep learning algorithms that currently involve billions to trillions of parameters to estimate across layers and their connections. </span><span class="kobospan" id="kobo.186.2">They are trained on massive volumes of text data and require high volumes of computing resources to fit the model. </span><span class="kobospan" id="kobo.186.3">Larger models tend to perform better than smaller models, necessitating more data and more computational power. </span><span class="kobospan" id="kobo.186.4">This is not ideal, as computing resources have limitations based on hardware and substantial </span><span><span class="kobospan" id="kobo.187.1">environmental impacts.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.188.1">Network</span><a id="_idIndexMarker627" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.189.1"> science provides a potential avenue for finding good, small LLM architectures that require less training data and fewer computational resources to fit. </span><span class="kobospan" id="kobo.189.2">These architectures are more accessible to developers in resource-scarce countries when building models for underrepresented languages, and they offer a path toward sustainable </span><span><span class="kobospan" id="kobo.190.1">LLM growth.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.191.1">Coupling this network science approach with training data can reduce the training sample size needed to build an effective LLM, as well. </span><span class="kobospan" id="kobo.191.2">Related documents with similar linguistic structure or content can be sampled from each structure or domain needed within the LLM. </span><span class="kobospan" id="kobo.191.3">This provides comprehensive data that can be quality-checked using fewer resources. </span><span class="kobospan" id="kobo.191.4">Better training data enhances model fitting, reduces training time, and reduces the computational resources needed to fit a good model. </span><span class="kobospan" id="kobo.191.5">Now that we understand a bit about neural network architecture, let’s turn to a type of network that integrates information about hierarchy and layering within </span><span><span class="kobospan" id="kobo.192.1">its structure.</span></span></p>
<h1 id="_idParaDest-191" class="calibre5"><a id="_idTextAnchor191" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.193.1">Hierarchical networks</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.194.1">In </span><a href="B21087_11.xhtml#_idTextAnchor145" class="pcalibre calibre6 pcalibre1"><span><em class="italic"><span class="kobospan" id="kobo.195.1">Chapter 11</span></em></span></a><span class="kobospan" id="kobo.196.1">, we encountered</span><a id="_idIndexMarker628" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.197.1"> ontologies and phylogenies within the linguistic and genetic context. </span><span class="kobospan" id="kobo.197.2">A </span><strong class="bold"><span class="kobospan" id="kobo.198.1">hierarchical network</span></strong><span class="kobospan" id="kobo.199.1"> builds on the intuition within ontologies and phylogenies; hierarchical networks are tree-like networks that can include multiple sources and sinks flowing from the top of the tree to the bottom of the tree. </span><span class="kobospan" id="kobo.199.2">Gene regulatory networks often follow this hierarchical network structure rather than strictly a tree structure, where multiple sources and sinks do not exist in the network, or an ontology structure, where parent vertices don’t typically exist. </span><span><em class="italic"><span class="kobospan" id="kobo.200.1">Figure 14</span></em></span><em class="italic"><span class="kobospan" id="kobo.201.1">.6</span></em><span class="kobospan" id="kobo.202.1"> shows an example of a </span><span><span class="kobospan" id="kobo.203.1">hierarchical network:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer172">
<span class="kobospan" id="kobo.204.1"><img alt="Figure 14.6 – A hierarchical network example where the second layer of the network contains the parents of a vertex in the third layer" src="image/B21087_14_06.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.205.1">Figure 14.6 – A hierarchical network example where the second layer of the network contains the parents of a vertex in the third layer</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.206.1">Studying gene </span><a id="_idIndexMarker629" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.207.1">regulation provides insight into myriad areas of research, including the evolutionary pathways within organ systems or species, the pathologies associated with gene dysregulation, and the discernment of cellular functions. </span><span class="kobospan" id="kobo.207.2">Gene regulation isn’t as simple as understanding the gene pathways themselves. </span><span class="kobospan" id="kobo.207.3">Environmental conditions can change the structure of proteins associated with DNA or RNA to make DNA/RNA less or more accessible to the proteins involved in gene transcription. </span><span class="kobospan" id="kobo.207.4">This, in turn, usually modifies the structures of those proteins further, either upregulating or downregulating the rate of transcription through accessibility </span><span><span class="kobospan" id="kobo.208.1">to DNA/RNA.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.209.1">Recent advances</span><a id="_idIndexMarker630" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.210.1"> in the</span><a id="_idIndexMarker631" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.211.1"> fields of </span><strong class="bold"><span class="kobospan" id="kobo.212.1">genomics</span></strong><span class="kobospan" id="kobo.213.1"> and </span><strong class="bold"><span class="kobospan" id="kobo.214.1">epigenomics</span></strong><span class="kobospan" id="kobo.215.1"> (which combines genetic analysis with environmental conditions) include measurement tools for gene expression and the structure of proteins around genes (which reflect local environmental conditions). </span><span class="kobospan" id="kobo.215.2">By measuring these levels of expression under different conditions and different genetic mutation lines, it’s possible to discern regulatory pathways </span><span><span class="kobospan" id="kobo.216.1">within organisms.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.217.1">Let’s explore higher-order structures in network data from a more theoretical perspective before considering an example of hierarchical networks in snake </span><span><span class="kobospan" id="kobo.218.1">venom epigenomics.</span></span></p>
<h2 id="_idParaDest-192" class="calibre7"><a id="_idTextAnchor192" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.219.1">Higher-order structures and network data</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.220.1">If we</span><a id="_idIndexMarker632" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.221.1"> think back to </span><a href="B21087_11.xhtml#_idTextAnchor145" class="pcalibre calibre6 pcalibre1"><span><em class="italic"><span class="kobospan" id="kobo.222.1">Chapter 11</span></em></span></a><span class="kobospan" id="kobo.223.1">, language families start with a source—an initial language that evolves over time to other languages. </span><span class="kobospan" id="kobo.223.2">This gives language families a hierarchical structure defined by time (and, typically, geography). </span><span class="kobospan" id="kobo.223.3">Different levels emerge within different time periods, from the time of the original language to the modern-day derivatives of </span><span><span class="kobospan" id="kobo.224.1">that language.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.225.1">Within gene </span><a id="_idIndexMarker633" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.226.1">regulatory pathways, it’s possible for multiple genes to influence those involved in later steps within the regulatory pathway, thus creating a more complicated network structure than a tree. </span><span class="kobospan" id="kobo.226.2">However, order is still important, giving rise to a hierarchical network. </span><span class="kobospan" id="kobo.226.3">Within biological studies, this structure can be hard to discern by using lab experiments, as the structure is not one-to-one, and, occasionally, the effects are not linear. </span><span class="kobospan" id="kobo.226.4">However, recent technological advances allow researchers to discern these pathways more readily by varying the environment and/or knocking out the genes within </span><span><span class="kobospan" id="kobo.227.1">a pathway.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.228.1">Now that we know a bit about hierarchical networks, let’s examine a real-world use case where these have shed light on evolutionary pathways and the variance in biological properties across different snake venoms. </span><span class="kobospan" id="kobo.228.2">Venomous species are important for the health of many environments. </span><span class="kobospan" id="kobo.228.3">In recent years, the study of their venom has led to pharmaceutical breakthroughs for human diseases, including non-addictive pain medications, treatments for cardiac diseases, and new antibiotics that can treat drug-resistant strains. </span><span class="kobospan" id="kobo.228.4">Understanding differences across venomous species allows researchers and clinicians to develop better treatments for snake bite victims, allows medical researchers to study venom properties that may be useful in the pharmaceutical treatment of human disorders, and allows conservations to </span><span><span class="kobospan" id="kobo.229.1">preserve biodiversity.</span></span></p>
<h2 id="_idParaDest-193" class="calibre7"><a id="_idTextAnchor193" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.230.1">An example using gene families</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.231.1">Venomous </span><a id="_idIndexMarker634" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.232.1">species of snakes deplete venom either in a controlled way (striking prey) or an uncontrolled way (defensive bites when the snake is threatened). </span><span class="kobospan" id="kobo.232.2">Eventually, the venom stores are depleted, and more venom must be produced for the snake to survive. </span><span class="kobospan" id="kobo.232.3">Venom is mostly composed of proteins and polypeptides; given</span><a id="_idIndexMarker635" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.233.1"> this, rapid venom production induces stress on the </span><strong class="bold"><span class="kobospan" id="kobo.234.1">endoplasmic reticulum</span></strong><span class="kobospan" id="kobo.235.1"> (</span><strong class="bold"><span class="kobospan" id="kobo.236.1">ER</span></strong><span class="kobospan" id="kobo.237.1">), an organelle mainly involved in protein production within a cell. </span><span class="kobospan" id="kobo.237.2">This suggests that the gene families involved in ER regulation may play a role in venom regulation </span><span><span class="kobospan" id="kobo.238.1">and production.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.239.1">A recent functional genomics study of the prairie rattlesnake revealed two distinct pathways heavily involved in </span><span><span class="kobospan" id="kobo.240.1">venom regulation:</span></span></p>
<ul class="calibre10">
<li class="calibre11"><span class="kobospan" id="kobo.241.1">An extracellular pathway related to the </span><span><span class="kobospan" id="kobo.242.1">kinase pathway</span></span></li>
<li class="calibre11"><span class="kobospan" id="kobo.243.1">An ER-related </span><span><span class="kobospan" id="kobo.244.1">protein pathway</span></span></li>
</ul>
<p class="calibre3"><span class="kobospan" id="kobo.245.1">This is</span><a id="_idIndexMarker636" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.246.1"> logical, given that the signals would need to respond to exterior conditions (lower concentrations of venom) and interior conditions (overworked ERs); a balance between venom concentration and cellular health makes sense in terms of start and stop signals to regulate how much venom is being produced. </span><span class="kobospan" id="kobo.246.2">Interestingly, these pathways are ubiquitous across species, and it is thought that similar pathways may be involved in general </span><span><span class="kobospan" id="kobo.247.1">venom regulation.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.248.1">Let’s examine the phylogenic tree for genetic conservation within one pathway. </span><span class="kobospan" id="kobo.248.2">You can find the image in the Perry 2022 paper cited in the reference section (</span><span><em class="italic"><span class="kobospan" id="kobo.249.1">Figure 6</span></em></span><em class="italic"><span class="kobospan" id="kobo.250.1">C</span></em><span class="kobospan" id="kobo.251.1">). </span><span class="kobospan" id="kobo.251.2">We’ll discuss this image and its implications for evolutionary pathways in the </span><span><span class="kobospan" id="kobo.252.1">following sections.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.253.1">This tree suggests that the enhancer region studied in this pathway is conserved for venomous snake species, with a few further mutations occurring along the evolutionary pathway, giving rise to different types of venom with different modes of action within the body of an envenomated prey </span><span><span class="kobospan" id="kobo.254.1">or predator.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.255.1">Hierarchical networks allow us to organize information across levels, and visualizations such as </span><span><em class="italic"><span class="kobospan" id="kobo.256.1">Figure 6</span></em></span><em class="italic"><span class="kobospan" id="kobo.257.1">C</span></em><span class="kobospan" id="kobo.258.1"> from the Perry 2022 paper allow us to examine other relevant information (such as time) related to the organizational principles in a hierarchical network. </span><span class="kobospan" id="kobo.258.2">However, hierarchical networks may not be flexible enough for some visualizations, and in the next section, we’ll look at an even more flexible </span><span><span class="kobospan" id="kobo.259.1">visualization tool.</span></span></p>
<h1 id="_idParaDest-194" class="calibre5"><a id="_idTextAnchor194" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.260.1">Hypergraphs</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.261.1">Another exciting</span><a id="_idIndexMarker637" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.262.1"> avenue of research in network science involves </span><strong class="bold"><span class="kobospan" id="kobo.263.1">hypergraphs</span></strong><span class="kobospan" id="kobo.264.1">, which are an extension of networks in which multi-way relationships can include multiple vertices. </span><span class="kobospan" id="kobo.264.2">In this way, the concept of edges is extended in a similar way to how the concept of edges was extended in </span><a href="B21087_06.xhtml#_idTextAnchor078" class="pcalibre calibre6 pcalibre1"><span><em class="italic"><span class="kobospan" id="kobo.265.1">Chapter 6</span></em></span></a><span class="kobospan" id="kobo.266.1">, within the </span><em class="italic"><span class="kobospan" id="kobo.267.1">Extending network metrics for time series analytics</span></em><span class="kobospan" id="kobo.268.1"> section on simplicial complexes. </span><span class="kobospan" id="kobo.268.2">In fact, the abstraction of simplicial complexes is one type </span><span><span class="kobospan" id="kobo.269.1">of hypergraph.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.270.1">Hypergraphs are often useful for visualizing database diagrams and planning information retrieval systems, where many-to-many relationships often exist. </span><span class="kobospan" id="kobo.270.2">Some distributed computing systems even provide hypergraph algorithms to aid in these retrieval tasks </span><span><span class="kobospan" id="kobo.271.1">at scale.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.272.1">Visualization</span><a id="_idIndexMarker638" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.273.1"> via hypergraphs is also used extensively in bioinformatics, where multi-way relationships exist between proteins, biological pathways, gene expression datasets, and metabolic processes. </span><span class="kobospan" id="kobo.273.2">In complex systems, it is often easier to show relationships visually than to show a matrix or a list of the relationships. </span><span class="kobospan" id="kobo.273.3">It’s also much more compact to use this representation as opposed to diagrams with many overlapping lines or </span><span><span class="kobospan" id="kobo.274.1">complicated tables.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.275.1">Let’s dive into the particulars of hypergraph visualization and then move on to a real-world example of hypergraphs simplifying data visualization </span><span><span class="kobospan" id="kobo.276.1">within bioinformatics.</span></span></p>
<h2 id="_idParaDest-195" class="calibre7"><a id="_idTextAnchor195" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.277.1">Displaying information</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.278.1">In science, it’s </span><a id="_idIndexMarker639" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.279.1">important to communicate clearly and concisely, particularly when discussing complicated or nuanced concepts that may be very unfamiliar to readers. </span><span class="kobospan" id="kobo.279.2">Accurate and concise infographics provide readers with alternative representations of material compared to long, jargon-laden paragraphs. </span><span class="kobospan" id="kobo.279.3">This makes the material more accessible to a wider audience. </span><span class="kobospan" id="kobo.279.4">For a new algorithm in machine learning or a new measurement tool in bioinformatics, the difference between a cool tool that is rarely adopted and a tool that people leverage to solve real problems is often a matter of marketing. </span><span class="kobospan" id="kobo.279.5">Solid communication that invites readers into the material results in a larger and more </span><span><span class="kobospan" id="kobo.280.1">diverse audience.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.281.1">Let’s consider four different ways of communicating a biological network’s complex relationships to an audience. </span><span class="kobospan" id="kobo.281.2">The first way is simply through text. </span><span class="kobospan" id="kobo.281.3">Perhaps there are five pathways that overlap at certain stages within the pathway. </span><strong class="bold"><span class="kobospan" id="kobo.282.1">Pathway 1</span></strong><span class="kobospan" id="kobo.283.1"> follows its own pathway until merging with </span><strong class="bold"><span class="kobospan" id="kobo.284.1">Pathways 2</span></strong><span class="kobospan" id="kobo.285.1"> and </span><strong class="bold"><span class="kobospan" id="kobo.286.1">3,</span></strong><span class="kobospan" id="kobo.287.1"> which initially overlapped but then diverged after merging with </span><strong class="bold"><span class="kobospan" id="kobo.288.1">Pathway 1</span></strong><span class="kobospan" id="kobo.289.1">. </span><strong class="bold"><span class="kobospan" id="kobo.290.1">Pathway 4</span></strong><span class="kobospan" id="kobo.291.1"> emerges on its own and then connects with </span><strong class="bold"><span class="kobospan" id="kobo.292.1">Pathway 2</span></strong><span class="kobospan" id="kobo.293.1">. </span><strong class="bold"><span class="kobospan" id="kobo.294.1">Pathway 5</span></strong><span class="kobospan" id="kobo.295.1"> emerges on its own and then connects to </span><strong class="bold"><span class="kobospan" id="kobo.296.1">Pathway 3</span></strong><span class="kobospan" id="kobo.297.1">. </span><span class="kobospan" id="kobo.297.2">Can you picture this in your head as you read the text? </span><span class="kobospan" id="kobo.297.3">It’s difficult to visualize all of these pathways </span><span><span class="kobospan" id="kobo.298.1">through text.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.299.1">We could also show this via a table of relationships. </span><span class="kobospan" id="kobo.299.2">For five pathways, this isn’t terrible to visualize when using a pathway table, such as </span><em class="italic"><span class="kobospan" id="kobo.300.1">Table 14.1</span></em><span class="kobospan" id="kobo.301.1">. </span><span class="kobospan" id="kobo.301.2">However, consider what a table like this would look like for a complicated metabolic process or gene network that includes dozens or hundreds of pathways. </span><span class="kobospan" id="kobo.301.3">Visualizing those through a table is </span><span><span class="kobospan" id="kobo.302.1">not ideal:</span></span></p>
<table class="no-table-style" id="table001-4">
<colgroup class="calibre12">
<col class="calibre13"/>
<col class="calibre13"/>
<col class="calibre13"/>
<col class="calibre13"/>
<col class="calibre13"/>
<col class="calibre13"/>
</colgroup>
<thead class="calibre19">
<tr class="no-table-style1">
<td class="no-table-style2"/>
<td class="no-table-style2">
<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.303.1">Pathway 1</span></strong></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.304.1">Pathway 2</span></strong></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.305.1">Pathway 3</span></strong></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.306.1">Pathway 4</span></strong></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.307.1">Pathway 5</span></strong></span></p>
</td>
</tr>
</thead>
<tbody class="calibre14">
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.308.1">Pathway 1</span></span></p>
</td>
<td class="no-table-style2"/>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.309.1">X</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.310.1">X</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.311.1">X</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.312.1">X</span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.313.1">Pathway 2</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.314.1">X</span></p>
</td>
<td class="no-table-style2"/>
<td class="no-table-style2"/>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.315.1">X</span></p>
</td>
<td class="no-table-style2"/>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.316.1">Pathway 3</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.317.1">X</span></p>
</td>
<td class="no-table-style2"/>
<td class="no-table-style2"/>
<td class="no-table-style2"/>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.318.1">X</span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.319.1">Pathway 4</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.320.1">X</span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.321.1">X</span></p>
</td>
<td class="no-table-style2"/>
<td class="no-table-style2"/>
<td class="no-table-style2"/>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.322.1">Pathway 5</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.323.1">X</span></p>
</td>
<td class="no-table-style2"/>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.324.1">X</span></p>
</td>
<td class="no-table-style2"/>
<td class="no-table-style2"/>
</tr>
</tbody>
</table>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.325.1">Table 14.1 – A table showing pathway overlap across five metabolic pathways within an organism</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.326.1">Let’s now </span><a id="_idIndexMarker640" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.327.1">consider a network with each pathway represented as a vertex and each connection through the metabolic pathways as an edge. </span><span class="kobospan" id="kobo.327.2">While the limited number of pathways doesn’t create a terribly messy graph, this representation will not scale, particularly as the pathway edges scale with the addition of more vertices. </span><span class="kobospan" id="kobo.327.3">When reaching a dozen pathways, it would be very difficult to discern which edges connect which vertices by using this approach. </span><span><em class="italic"><span class="kobospan" id="kobo.328.1">Figure 14</span></em></span><em class="italic"><span class="kobospan" id="kobo.329.1">.7</span></em><span class="kobospan" id="kobo.330.1"> shows the metabolic pathway example visualized as </span><span><span class="kobospan" id="kobo.331.1">a network:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer173">
<span class="kobospan" id="kobo.332.1"><img alt="Figure 14.7 – A network representation of the relationships in metabolic pathways" src="image/B21087_14_07.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.333.1">Figure 14.7 – A network representation of the relationships in metabolic pathways</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.334.1">Finally, let’s </span><a id="_idIndexMarker641" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.335.1">consider a hypergraph representation of these pathways and their overlap. </span><span class="kobospan" id="kobo.335.2">This approach looks a bit like a Venn diagram showing set overlaps, with different colors or textures parsing out the relationships into sets of related items. </span><span class="kobospan" id="kobo.335.3">If given a temporal component to the data, we could even create evolving hypergraph representations for each branch point of the metabolic pathways. </span><span class="kobospan" id="kobo.335.4">This is much easier to convey to a reader as the number of pathways increases, and considering this evolving network as a set of items allows for easier computation in terms of the changes and properties across evolving sets. </span><span><em class="italic"><span class="kobospan" id="kobo.336.1">Figure 14</span></em></span><em class="italic"><span class="kobospan" id="kobo.337.1">.8</span></em><span class="kobospan" id="kobo.338.1"> shows a hypergraph representation with temporal </span><span><span class="kobospan" id="kobo.339.1">components included:</span></span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer174">
<span class="kobospan" id="kobo.340.1"><img alt="Figure 14.8 – A hypergraph representation of the metabolic pathways across time" src="image/B21087_14_08.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.341.1">Figure 14.8 – A hypergraph representation of the metabolic pathways across time</span></p>
<p class="calibre3"><span><em class="italic"><span class="kobospan" id="kobo.342.1">Figure 14</span></em></span><em class="italic"><span class="kobospan" id="kobo.343.1">.8</span></em><span class="kobospan" id="kobo.344.1"> captures</span><a id="_idIndexMarker642" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.345.1"> both pathway-merging information and a temporal aspect as the pathways run to completion. </span><span class="kobospan" id="kobo.345.2">This is much easier to understand than the text or the table representations and will scale more easily than a simple network diagram. </span><span class="kobospan" id="kobo.345.3">Hypergraphs are useful visualization tools that scale well for </span><span><span class="kobospan" id="kobo.346.1">complex problems.</span></span></p>
<h2 id="_idParaDest-196" class="calibre7"><a id="_idTextAnchor196" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.347.1">Metadata</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.348.1">Oftentimes, networks</span><a id="_idIndexMarker643" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.349.1"> include metadata about edges or vertices in the network, which are typically stored in tables. </span><span class="kobospan" id="kobo.349.2">As we mentioned earlier in this section, hypergraphs are useful tools when wrangling complex databases. </span><span class="kobospan" id="kobo.349.3">In fact, hypergraph databases exist and can be quite helpful in the data management of OWL databases, language topic models, document storage, and much more. </span><span class="kobospan" id="kobo.349.4">The flexibility of hypergraph databases compared to graph databases includes the ability to easily capture and represent multi-way connections and interactions between data tables, documents, or sets of tables </span><span><span class="kobospan" id="kobo.350.1">or documents.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.351.1">In returning </span><a id="_idIndexMarker644" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.352.1">to our bioinformatics example, hypergraph databases are ideal for managing bioinformatics data related to genes, proteins, metabolic pathways, or other interconnected sets of processes. </span><span class="kobospan" id="kobo.352.2">The layers can represent the different aspects of pathway overlap, different periods of time, or different organisms with overlapping metabolic or </span><span><span class="kobospan" id="kobo.353.1">regulatory pathways.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.354.1">Consider the venom example in the previous section. </span><span class="kobospan" id="kobo.354.2">A hypergraph database could contain all the known gene pathways associated with venom production across venomous organisms. </span><span class="kobospan" id="kobo.354.3">Phylogenic relationships, distribution geographies, antivenin classes, and other types of metadata can be used to connect groups of gene pathways to facilitate the study of particular genes or regulatory functions across habitats, species, and interactions with human populations. </span><span class="kobospan" id="kobo.354.4">Updating this type of knowledge periodically as new papers are published would accelerate research in the field and tie in different branches of knowledge in a manner that is easy for researchers </span><span><span class="kobospan" id="kobo.355.1">to access.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.356.1">Given the utility of hypergraph databases, we are likely to see more development in this field of network science in the </span><span><span class="kobospan" id="kobo.357.1">coming years.</span></span></p>
<h1 id="_idParaDest-197" class="calibre5"><a id="_idTextAnchor197" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.358.1">Summary</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.359.1">In this chapter, we’ve pushed the limits of network science by merging network algorithms with quantum computing frameworks, enhanced our understanding of scaling the deep learning algorithms that are ubiquitous in modern data science, and explored special types of networks that are critical in molecular biology and genetics. </span><span class="kobospan" id="kobo.359.2">Network science plays an important role in data science, offering scalability and novel solutions to common problems. </span><span class="kobospan" id="kobo.359.3">As the field of network science evolves, data science and its practitioners will continue to benefit. </span><span class="kobospan" id="kobo.359.4">We hope this book will equip and inspire anyone who works with data to push the boundaries of knowledge and solve difficult problems in the world by using data. </span><span class="kobospan" id="kobo.359.5">Come </span><span><span class="kobospan" id="kobo.360.1">join us!</span></span></p>
<h1 id="_idParaDest-198" class="calibre5"><a id="_idTextAnchor198" class="pcalibre calibre6 pcalibre1"/><span class="kobospan" id="kobo.361.1">References</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.362.1">Berkolaiko, G., &amp; Kuchment, P. </span><span class="kobospan" id="kobo.362.2">(2013). </span><em class="italic"><span class="kobospan" id="kobo.363.1">Introduction to quantum graphs</span></em><span class="kobospan" id="kobo.364.1"> (No. </span><span class="kobospan" id="kobo.364.2">186). </span><span class="kobospan" id="kobo.364.3">American </span><span><span class="kobospan" id="kobo.365.1">Mathematical Soc.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.366.1">Biamonte, J., Wittek, P., Pancotti, N., Rebentrost, P., Wiebe, N., &amp; Lloyd, S. </span><span class="kobospan" id="kobo.366.2">(2017). </span><em class="italic"><span class="kobospan" id="kobo.367.1">Quantum machine learning</span></em><span class="kobospan" id="kobo.368.1">. </span><em class="italic"><span class="kobospan" id="kobo.369.1">Nature</span></em><span class="kobospan" id="kobo.370.1">, </span><span><em class="italic"><span class="kobospan" id="kobo.371.1">549</span></em></span><span><span class="kobospan" id="kobo.372.1">(7671), 195-202.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.373.1">Cerezo, M., Verdon, G., Huang, H. </span><span class="kobospan" id="kobo.373.2">Y., Cincio, L., &amp; Coles, P. </span><span class="kobospan" id="kobo.373.3">J. </span><span class="kobospan" id="kobo.373.4">(2022). </span><em class="italic"><span class="kobospan" id="kobo.374.1">Challenges and opportunities in quantum machine learning</span></em><span class="kobospan" id="kobo.375.1">. </span><em class="italic"><span class="kobospan" id="kobo.376.1">Nature Computational Science</span></em><span class="kobospan" id="kobo.377.1">, </span><span><em class="italic"><span class="kobospan" id="kobo.378.1">2</span></em></span><span><span class="kobospan" id="kobo.379.1">(9), 567-576.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.380.1">Cui, S. </span><span class="kobospan" id="kobo.380.2">X., Freedman, M. </span><span class="kobospan" id="kobo.380.3">H., Sattath, O., Stong, R., &amp; Minton, G. </span><span class="kobospan" id="kobo.380.4">(2016). </span><em class="italic"><span class="kobospan" id="kobo.381.1">Quantum max-flow/min-cut</span></em><span class="kobospan" id="kobo.382.1">. </span><em class="italic"><span class="kobospan" id="kobo.383.1">Journal of Mathematical </span></em><span><em class="italic"><span class="kobospan" id="kobo.384.1">Physics</span></em></span><span><span class="kobospan" id="kobo.385.1">, </span></span><span><em class="italic"><span class="kobospan" id="kobo.386.1">57</span></em></span><span><span class="kobospan" id="kobo.387.1">(6).</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.388.1">Ekanayake, E. </span><span class="kobospan" id="kobo.388.2">M. </span><span class="kobospan" id="kobo.388.3">U. </span><span class="kobospan" id="kobo.388.4">S. </span><span class="kobospan" id="kobo.388.5">B., Daundasekara, W. </span><span class="kobospan" id="kobo.388.6">B., &amp; Perera, S. </span><span class="kobospan" id="kobo.388.7">P. </span><span class="kobospan" id="kobo.388.8">C. </span><span class="kobospan" id="kobo.388.9">(2022). </span><em class="italic"><span class="kobospan" id="kobo.389.1">New Approach to Obtain the Maximum Flow in a Network and Optimal Solution for the Transportation Problems</span></em><span class="kobospan" id="kobo.390.1">. </span><em class="italic"><span class="kobospan" id="kobo.391.1">Modern Applied Science</span></em><span class="kobospan" id="kobo.392.1">, </span><span><em class="italic"><span class="kobospan" id="kobo.393.1">16</span></em></span><span><span class="kobospan" id="kobo.394.1">(1), 30.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.395.1">Feng, S., Heath, E., Jefferson, B., Joslyn, C., Kvinge, H., Mitchell, H. </span><span class="kobospan" id="kobo.395.2">D., ... </span><span class="kobospan" id="kobo.395.3">&amp; Purvine, E. </span><span class="kobospan" id="kobo.395.4">(2021). </span><em class="italic"><span class="kobospan" id="kobo.396.1">Hypergraph models of biological networks to identify genes critical to pathogenic viral response</span></em><span class="kobospan" id="kobo.397.1">. </span><em class="italic"><span class="kobospan" id="kobo.398.1">BMC bioinformatics</span></em><span class="kobospan" id="kobo.399.1">, </span><span><em class="italic"><span class="kobospan" id="kobo.400.1">22</span></em></span><span><span class="kobospan" id="kobo.401.1">(1), 1-21.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.402.1">Iordanov, B. </span><span class="kobospan" id="kobo.402.2">(2010). </span><em class="italic"><span class="kobospan" id="kobo.403.1">Hypergraphdb: a generalized graph database</span></em><span class="kobospan" id="kobo.404.1">. </span><span class="kobospan" id="kobo.404.2">In </span><em class="italic"><span class="kobospan" id="kobo.405.1">Web-Age Information Management: WAIM 2010 International Workshops: IWGD 2010, XMLDM 2010, WCMT 2010, Jiuzhaigou Valley, China, July 15-17, 2010 Revised Selected Papers 11</span></em><span class="kobospan" id="kobo.406.1"> (pp. </span><span class="kobospan" id="kobo.406.2">25-36). </span><span class="kobospan" id="kobo.406.3">Springer </span><span><span class="kobospan" id="kobo.407.1">Berlin Heidelberg.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.408.1">James, D. </span><span class="kobospan" id="kobo.408.2">F., Kwiat, P. </span><span class="kobospan" id="kobo.408.3">G., Munro, W. </span><span class="kobospan" id="kobo.408.4">J., &amp; White, A. </span><span class="kobospan" id="kobo.408.5">G. </span><span class="kobospan" id="kobo.408.6">(2001). </span><em class="italic"><span class="kobospan" id="kobo.409.1">Measurement of qubits</span></em><span class="kobospan" id="kobo.410.1">. </span><em class="italic"><span class="kobospan" id="kobo.411.1">Physical Review A</span></em><span class="kobospan" id="kobo.412.1">, </span><span><em class="italic"><span class="kobospan" id="kobo.413.1">64</span></em></span><span><span class="kobospan" id="kobo.414.1">(5), 052312.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.415.1">Karlebach, G., &amp; Shamir, R. </span><span class="kobospan" id="kobo.415.2">(2008). </span><em class="italic"><span class="kobospan" id="kobo.416.1">Modelling and analysis of gene regulatory networks</span></em><span class="kobospan" id="kobo.417.1">. </span><em class="italic"><span class="kobospan" id="kobo.418.1">Nature reviews Molecular cell biology</span></em><span class="kobospan" id="kobo.419.1">, </span><span><em class="italic"><span class="kobospan" id="kobo.420.1">9</span></em></span><span><span class="kobospan" id="kobo.421.1">(10), 770-780.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.422.1">Leighton, F. </span><span class="kobospan" id="kobo.422.2">T. </span><span class="kobospan" id="kobo.422.3">(1979). </span><em class="italic"><span class="kobospan" id="kobo.423.1">A graph coloring algorithm for large scheduling problems</span></em><span class="kobospan" id="kobo.424.1">. </span><em class="italic"><span class="kobospan" id="kobo.425.1">Journal of research of the national bureau of standards</span></em><span class="kobospan" id="kobo.426.1">, </span><span><em class="italic"><span class="kobospan" id="kobo.427.1">84</span></em></span><span><span class="kobospan" id="kobo.428.1">(6), 489.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.429.1">Perry, B. </span><span class="kobospan" id="kobo.429.2">W., Gopalan, S. </span><span class="kobospan" id="kobo.429.3">S., Pasquesi, G. </span><span class="kobospan" id="kobo.429.4">I., Schield, D. </span><span class="kobospan" id="kobo.429.5">R., Westfall, A. </span><span class="kobospan" id="kobo.429.6">K., Smith, C. </span><span class="kobospan" id="kobo.429.7">F., ... </span><span class="kobospan" id="kobo.429.8">&amp; Castoe, T. </span><span class="kobospan" id="kobo.429.9">A. </span><span class="kobospan" id="kobo.429.10">(2022). </span><em class="italic"><span class="kobospan" id="kobo.430.1">Snake venom gene expression is coordinated by novel regulatory architecture and the integration of multiple co-opted vertebrate pathways</span></em><span class="kobospan" id="kobo.431.1">. </span><em class="italic"><span class="kobospan" id="kobo.432.1">Genome Research</span></em><span class="kobospan" id="kobo.433.1">, </span><span><em class="italic"><span class="kobospan" id="kobo.434.1">32</span></em></span><span><span class="kobospan" id="kobo.435.1">(6), 1058-1073.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.436.1">Titiloye, O., &amp; Crispin, A. </span><span class="kobospan" id="kobo.436.2">(2011). </span><em class="italic"><span class="kobospan" id="kobo.437.1">Quantum annealing of the graph coloring problem</span></em><span class="kobospan" id="kobo.438.1">. </span><em class="italic"><span class="kobospan" id="kobo.439.1">Discrete Optimization</span></em><span class="kobospan" id="kobo.440.1">, </span><span><em class="italic"><span class="kobospan" id="kobo.441.1">8</span></em></span><span><span class="kobospan" id="kobo.442.1">(2), 376-384.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.443.1">Vidya, V., Achar, R. </span><span class="kobospan" id="kobo.443.2">R., Himathi, M. </span><span class="kobospan" id="kobo.443.3">U., Akshita, N., Kameshwar, V. </span><span class="kobospan" id="kobo.443.4">H., Byrappa, K., &amp; Ramadas, D. </span><span class="kobospan" id="kobo.443.5">(2021). </span><em class="italic"><span class="kobospan" id="kobo.444.1">Venom peptides–A comprehensive translational perspective in pain management</span></em><span class="kobospan" id="kobo.445.1">. </span><em class="italic"><span class="kobospan" id="kobo.446.1">Current Research in Toxicology</span></em><span class="kobospan" id="kobo.447.1">, </span><span><em class="italic"><span class="kobospan" id="kobo.448.1">2</span></em></span><span><span class="kobospan" id="kobo.449.1">, 329-340.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.450.1">Wittek, P. </span><span class="kobospan" id="kobo.450.2">(2014). </span><em class="italic"><span class="kobospan" id="kobo.451.1">Quantum machine learning: what quantum computing means to data mining</span></em><span class="kobospan" id="kobo.452.1">. </span><span><span class="kobospan" id="kobo.453.1">Academic Press.</span></span></p>
</div>
</body></html>