["```py\npip install tensorflow\npip install numpy\npip install pandas\npip install matplotlib\n```", "```py\nThis shampoo is great for hair.\n                        POSITIVE\nI loved this shampoo, best product ever!\n         POSITIVE\nMy hair has never been better, great product. POSITIVE\nThis product make my scalp itchy.\n                    NEGATIVE\nNot the best quality for this price.\n                     NEGATIVE\n```", "```py\nfrom spacy.pipeline.textcat import DEFAULT_SINGLE_TEXTCAT_MODEL\n```", "```py\nfrom spacy.pipeline.textcat_multilabel import DEFAULT_MULTI_TEXTCAT_MODEL\n```", "```py\nfrom spacy.pipeline.textcat import DEFAULT_SINGLE_TEXTCAT_MODEL\nconfig = {\n   \"threshold\": 0.5,  \n   \"model\": DEFAULT_SINGLE_TEXTCAT_MODEL\n}\ntextcat = nlp.add_pipe(\"textcat\", config=config)\ntextcat\n<spacy.pipeline.textcat.TextCategorizer object at 0x7f0adf004e08>\n```", "```py\nfrom spacy.pipeline.textcat_multilabel import\nDEFAULT_MULTI_TEXTCAT_MODEL\nconfig = {\n   \"threshold\": 0.5,\n   \"model\": DEFAULT_MULTI_TEXTCAT_MODEL\n}\ntextcat = nlp.add_pipe(\"textcat_multilabel\", config=config)\ntextcat\n<spacy.pipeline.textcat.TextCategorizer object at 0x7f0adf004e08>\n```", "```py\ntrain_data = [\n    (\"I loved this product, very easy to use.\", {\"cats\": {\"sentiment\": 1}}),\n    (\"I'll definitely purchase again. I recommend this product.\", {\"cats\": {\"sentiment\": 1}}),\n    (\"This is the best product ever. I loved the scent and the feel. Will buy again.\", {\"cats\": {\"sentiment\": 1}}),\n   (\"Disappointed. This product didn't work for me at all\", {\"cats\": {\"sentiment\": 0}}),\n   (\"I hated the scent. Won't buy again\", {\"cats\": {\"sentiment\": 0}}),\n   (\"Truly horrible product. Very few amount of product for a high price. Don't recommend.\", {\"cats\": {\"sentiment\": 0}})\n]\n```", "```py\nimport random\nimport spacy   \nfrom spacy.training import Example\nfrom spacy.pipeline.textcat import DEFAULT_SINGLE_TEXTCAT_MODEL\n```", "```py\nnlp = spacy.load(\"en_core_web_md\")\nconfig = {\n   \"threshold\": 0.5,\n   \"model\": DEFAULT_SINGLE_TEXTCAT_MODEL\n}\ntextcat = nlp.add_pipe(\"textcat\", config=config)\n```", "```py\ntextcat.add_label(\"sentiment\")\ntrain_examples = [Example.from_dict(nlp.make_doc(text), label) for text,label in train_data]\ntextcat.initialize(lambda: train_examples, nlp=nlp)\n```", "```py\nepochs=20\nwith nlp.select_pipes(enable=\"textcat\"):\n  optimizer = nlp.resume_training()\n  for i in range(epochs):\n    random.shuffle(train_data)\n    for text, label in train_data:\n      doc = nlp.make_doc(text)\n      example = Example.from_dict(doc, label)\n      nlp.update([example], sgd=optimizer)\n```", "```py\ndoc2 = nlp(\"This product sucks\")\ndoc2.cats\n{'sentiment': 0.09907063841819763}\ndoc3 = nlp(\"This product is great\")\ndoc3.cats\n{'sentiment': 0.9740120000120339}\n```", "```py\ntrain_data = [\n    (\"It's the perfect movie for a Sunday evening.\", {\"cats\": {\"SUNDAY_EVENING\": True}}),\n    (\"Very good thriller\", {\"cats\": {\"THRILLER\": True}}),\n    (\"A great movie for the kids and all the family\"  , {\"cats\": {\"FAMILY\": True}}),\n    (\"An ideal movie for Sunday night with all the family. My kids loved the movie.\", {\"cats\": {\"FAMILY\": True, \"SUNDAY_EVENING\":True}}),\n    (\"A perfect thriller for all the family. No violence, no drugs, pure action.\", {\"cats\": {\"FAMILY\": True, \"THRILLER\": True}})\n]\n```", "```py\nimport random\nimport spacy   \nfrom spacy.training import Example\nfrom spacy.pipeline.textcat_multilabel import\nDEFAULT_MULTI_TEXTCAT_MODEL\n```", "```py\nconfig = {\n   \"threshold\": 0.5,\n   \"model\": DEFAULT_MULTI_TEXTCAT_MODEL\n}\ntextcat = nlp.add_pipe(\"textcat_multilabel\", config=config)\n```", "```py\nlabels = [\"FAMILY\", \"THRILLER\", \"SUNDAY_EVENING\"]\nfor label in labels:\n  textcat.add_label(label)\ntrain_examples = [Example.from_dict(nlp.make_doc(text), label) for text,label in train_data]\ntextcat.initialize(lambda: train_examples, nlp=nlp)\n```", "```py\nepochs=20\nwith nlp.select_pipes(enable=\"textcat_multilabel\"): \n  optimizer = nlp.resume_training() \n  for i in range(epochs): \n     random.shuffle(train_data) \n     for text, label in train_data: \n        doc = nlp.make_doc(text) \n        example = Example.from_dict(doc, label) \n        nlp.update([example], sgd=optimizer)\n```", "```py\ndoc2 = nlp(\"Definitely in my Sunday movie night list\")\ndoc2.cats\n{'FAMILY': 0.9044250249862671, 'THRILLER': 0.34271398186683655, 'SUNDAY_EVENING': 0.9801468253135681}\n```", "```py\nwget  https://github.com/PacktPublishing/Mastering-spaCy/blob/main/Chapter08/data/Reviews.zip\n```", "```py\nunzip Reviews.zip\n```", "```py\n    import pandas as pd\n    import matplotlib.pyplot as plt\n    %matplotlib inline\n    ```", "```py\n    reviews_df=pd.read_csv('data/Reviews.csv')\n    reviews_df.shape\n    (3999, 10)\n    ```", "```py\n    reviews_df.head()\n    ```", "```py\n    reviews_df = reviews_df[['Text','Score']].dropna()\n    ```", "```py\n    ax=reviews_df.Score.value_counts().plot(kind='bar', colormap='Paired')\n    plt.show()\n    ```", "```py\n    reviews_df.Score[reviews_df.Score<=3]=0\n    reviews_df.Score[reviews_df.Score>=4]=1\n    ```", "```py\n    ax=reviews_df.Score.value_counts().plot(kind='bar', colormap='Paired')\n    plt.show()\n    ```", "```py\n    import spacy\n    import random\n    from spacy.training import Example \n    from spacy.pipeline.textcat_multilabel import DEFAULT_MULTI_TEXTCAT_MODEL\n    ```", "```py\n    nlp = spacy.load(\"en_core_web_md\") \n     config = { \n       \"threshold\": 0.5, \n       \"model\": DEFAULT_MULTI_TEXTCAT_MODEL \n    } \n    textcat = nlp.add_pipe(\"textcat_multilabel\", config=config)\n    ```", "```py\n    train_examples = []\n    for index, row in reviews_df.iterrows():\n        text = row[\"Text\"]\n        rating = row[\"Score\"]\n        label = {\"POS\": True, \"NEG\": False} if rating == 1 else {\"NEG\": True, \"POS\": False}\n        train_examples.append(Example.from_dict(nlp.make_doc(text), {\"cats\": label}))    \n    ```", "```py\n    textcat.add_label(\"POS\")\n    textcat.add_label(\"NEG\")\n    textcat.initialize(lambda: train_examples, nlp=nlp)\n    ```", "```py\n    epochs = 2\n    with nlp.select_pipes(enable=\"textcat_multilabel\"): \n      optimizer = nlp.resume_training()\n      for i in range(epochs): \n        random.shuffle(train_examples) \n        for example in train_examples: \n          nlp.update([example], sgd=optimizer)\n    ```", "```py\n    doc2 = nlp(\"This is the best food I ever ate\")\n    doc2.cats\n    {'POS': 0.9553419947624207, 'NEG': 0.061326123774051666}\n    doc3 = nlp(\"This food is so bad\")\n    doc3.cats\n    {'POS': 0.21204468607902527, 'NEG': 0.8010350465774536}\n    ```", "```py\ndata = [\n\"Tomorrow I will visit the hospital.\",\n\"Yesterday I took a flight to Athens.\",\n\"Sally visited Harry and his dog.\"\n]\n```", "```py\nimport spacy\nnlp = spacy.load(\"en_core_web_md\")\nsentences = [[token.text for token in nlp(sentence)] for sentence in data]\nfor sentence in sentences:\n    sentence\n... \n['Tomorrow', 'I', 'will', 'visit', 'the', 'hospital', '.']\n['Yesterday', 'I', 'took', 'a', 'flight', 'to', 'Athens', '.']\n['Sally', 'visited', 'Harry', 'and', 'his', 'dog', '.']\n```", "```py\nfrom tensorflow.keras.preprocessing.text import Tokenizer\ntokenizer = Tokenizer(lower=True)  \ntokenizer.fit_on_texts(data)\ntokenizer\n<keras_preprocessing.text.Tokenizer object at 0x7f89e9d2d9e8>\ntokenizer.word_index\n{'i': 1, 'tomorrow': 2, 'will': 3, 'visit': 4, 'the': 5, 'hospital': 6, 'yesterday': 7, 'took': 8, 'a': 9, 'flight': 10, 'to': 11, 'athens': 12, 'sally': 13, 'visited': 14, 'harry': 15, 'and': 16, 'his': 17, 'dog': 18}\n```", "```py\ntokenizer.texts_to_sequences([\"hospital\"])\n[[6]]\ntokenizer.texts_to_sequences([\"hospital\", \"took\"])\n[[6], [8]]\n```", "```py\ntokenizer.sequences_to_texts([[3,2,1]])\n['will tomorrow i']\ntokenizer.sequences_to_texts([[3,2,1], [5,6,10]])\n['will tomorrow i', 'the hospital flight']\n```", "```py\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nsequences = [[7], [8,1], [9,11,12,14]]\nMAX_LEN=4\npad_sequences(sequences, MAX_LEN, padding=\"post\")\narray([[ 7,  0,  0,  0],\n          [ 8,  1,  0,  0],\n          [ 9, 11, 12, 14]], dtype=int32)\npad_sequences(sequences, MAX_LEN, padding=\"pre\")\narray([[ 0,  0,  0,  7],\n          [ 0,  0,  8,  1],\n          [ 9, 11, 12, 14]], dtype=int32)\n```", "```py\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\ntokenizer = Tokenizer(lower=True)\ntokenizer.fit_on_texts(data)\nseqs = tokenizer.texts_to_sequences(data)\nMAX_LEN=7\npadded_seqs = pad_sequences(seqs, MAX_LEN, padding=\"post\")\npadded_seqs\narray([[ 2,  1,  3,  4,  5,  6,  0],\n          [ 7,  1,  8,  9, 10, 11, 12],\n          [13, 14, 15, 16, 17, 18,  0]], dtype=int32)\n```", "```py\ntrain_examples = []\nlabels = []\nfor index, row in reviews_df.iterrows():\n    text = row[\"Text\"]\n    rating = row[\"Score\"]\n    labels.append(rating)\n    tokens = [token.text for token in nlp(text)]\n    train_examples.append(tokens)    \n```", "```py\n    from tensorflow.keras.preprocessing.text import Tokenizer\n    from tensorflow.keras.preprocessing.sequence import pad_sequences\n    import numpy as np\n    ```", "```py\n    tokenizer = Tokenizer(lower=True)\n    tokenizer.fit_on_texts(train_examples)\n    sequences = tokenizer.texts_to_sequences(train_examples)\n    ```", "```py\n    MAX_LEN = 50\n    X = pad_sequences(sequences, MAX_LEN, padding=\"post\")\n    ```", "```py\n    X = np.array(X)\n    y = np.array(labels)\n    ```", "```py\nsentence_input = Input(shape=(None,))\n```", "```py\nembedding =  Embedding(\\\ninput_dim = len(tokenizer.word_index)+1,\\\noutput_dim = 100)(sentence_input)\n```", "```py\nLSTM_layer = LSTM(units=256)(embedding)\n```", "```py\noutput_dense = Dense(1, activation='sigmoid')(LSTM_layer)\n```", "```py\nmodel = \\\nModel(inputs=[sentence_input],outputs=[output_dense])\nmodel.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",\\\nmetrics=[\"accuracy\"])\n```", "```py\nmodel.fit(x=X,\n          y=y,\n          batch_size=64,\n          epochs=5,\n          validation_split=0.2)\n```"]