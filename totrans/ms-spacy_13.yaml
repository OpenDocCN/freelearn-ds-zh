- en: 'Chapter 10: Putting Everything Together: Designing Your Chatbot with spaCy'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you will use everything you have learned so far to design a
    chatbot. You will perform entity extraction, intent recognition, and context handling.
    You will use different ways of syntactic and semantic parsing, entity extraction,
    and text classification.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, you''ll explore the dataset we''ll use to collect linguistic information
    about the utterances within it. Then, you''ll perform entity extraction by combining
    the spaCy `Matcher` class. After that, you''ll perform intent recognition with
    two different techniques: a pattern-based method and statistical text classification
    with TensorFlow and Keras. You''ll train a character-level LSTM to classify the
    utterance intents.'
  prefs: []
  type: TYPE_NORMAL
- en: The final section is a section dedicated to sentence- and dialog-level semantics.
    You'll take a deep dive into semantic subjects such as **anaphora resolution**,
    **grammatical question types**, and **differentiating subjects from objects**.
  prefs: []
  type: TYPE_NORMAL
- en: By the end of this chapter, you'll be ready to design a real chatbot **natural
    language understanding** (**NLU**) pipeline. You will bring together what you
    learned in all previous chapters – linguistically and statistically – by combining
    several spaCy pipeline components such as **NER**, a **dependency parser**, and
    a **POS tagger**.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we''re going to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to conversational AI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Entity extraction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Intent recognition
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we''ll be using NumPy, TensorFlow, and scikit-learn along
    with spaCy. You can install these libraries via `pip` using the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'You can find the chapter code and data at the book''s GitHub repository: [https://github.com/PacktPublishing/Mastering-spaCy/tree/main/Chapter10](https://github.com/PacktPublishing/Mastering-spaCy/tree/main/Chapter10).'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to conversational AI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We welcome you to our last and very exciting chapter, where you'll be designing
    a chatbot NLU pipeline with spaCy and TensorFlow. In this chapter, you'll learn
    the NLU techniques for extracting meaning from multiturn chatbot-user interactions.
    By learning and applying these techniques, you'll take a step into **conversational
    AI development**.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before diving into the technical details, there''s one fundamental question:
    what is a chatbot? Where can we find one? What exactly does conversational AI
    mean?'
  prefs: []
  type: TYPE_NORMAL
- en: '**Conversational artificial intelligence** (**conversational AI**) is a field
    of machine learning that aims to create technology that enables users to have
    text- or speech-based interactions with machines. Chatbots, virtual assistants,
    and voice assistants are typical conversational AI products.'
  prefs: []
  type: TYPE_NORMAL
- en: A **chatbot** is a software application that is designed to make conversations
    with humans in chat applications. Chatbots are popular in a wide variety of commercial
    areas including HR, marketing and sales, banking, and healthcare, as well as in
    personal, non-commercial areas such as small talk. Many commercial companies,
    such as Sephora (Sephora owns two chatbots – a virtual make-up artist chatbot
    on Facebook messenger platform and a customer service chatbot again on Facebook
    messenger), IKEA (IKEA have a customer service chatbot called Anna), AccuWeather,
    and many more, own customer service and FAQ chatbots.
  prefs: []
  type: TYPE_NORMAL
- en: 'Instant messaging services such as Facebook Messenger and Telegram provide
    interfaces to developers for connecting their bots. These platforms provide detailed
    guidelines for developers as well, such as the Facebook Messenger API documentation:
    ([https://developers.facebook.com/docs/messenger-platform/getting-started/quick-start/](https://developers.facebook.com/docs/messenger-platform/getting-started/quick-start/))
    or the Telegram bot API documentation: ([https://core.telegram.org/bots](https://core.telegram.org/bots)).'
  prefs: []
  type: TYPE_NORMAL
- en: A **virtual assistant** is also a software agent that performs some tasks upon
    user request or question. A well-known example is **Amazon Alexa**. Alexa is a
    voice-based virtual assistant and can perform many tasks, including playing music,
    setting alarms, reading audiobooks, playing podcasts, and giving real-time information
    for weather, traffic, sports, and so on. Alexa Home can control connected smart
    home devices and perform a variety of tasks, including switching the lights on
    and off, controlling the garage door, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Other well-known examples are Google Assistant and Siri. Siri is integrated
    into a number of Apple products, including iPhone, iPad, iPod, and macOS. On iPhone,
    Siri can make calls, answer calls, and send and receive text messages as well
    as WhatsApp messages. Google Assistant also can perform a wide variety of tasks,
    such as providing real-time flight, weather, and traffic information; sending
    and receiving text messages; setting alarms; providing device battery information;
    checking your email inbox; integrating with smart home devices; and so on. Google
    Assistant is available on Google Maps, Google Search, and standalone Android and
    iOS applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a list of the most popular and well-known virtual assistants to give
    you some more ideas of what''s out there:'
  prefs: []
  type: TYPE_NORMAL
- en: Amazon Alexa
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AllGenie from Alibaba Group
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bixby from Samsung
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Celia from Huawei
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Duer from Baidu
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Google Assistant
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Microsoft Cortana
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Siri from Apple
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Xiaowei from Tencent
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All of these virtual assistants are voice-based and are usually invoked with
    a **wake word**. A wake word is a special word or phrase that is used to activate
    a voice assistant. Some examples are *Hey Alexa*, *Hey Google*, and *Hey Siri*,
    which are the wake words of Amazon Alexa, Google Assistant, and Siri, respectively.
    If you want to know more about the development details of these products, please
    refer to the *References* section of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Now, we come to the technical details. What are the NLP components of these
    products? Let's look at these NLP components in detail.
  prefs: []
  type: TYPE_NORMAL
- en: NLP components of conversational AI products
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A typical voice-based conversational AI product consists of the following components:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Speech-to-text component**: Converts user speech into text. Input to this
    component is a WAV/mp3 file and the output is a text file containing the user
    utterance as a text.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Conversational NLU component**: This component performs intent recognition
    and entity extraction on the user utterance text. The output is the user intent
    and a list of entities. Resolving references in the current utterance to the previous
    utterances is done in this component (please refer to the *Anaphora resolution*
    section).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Dialog manager**: Keeps the conversation memory to make a meaningful and
    coherent chat. You can think of this component as the dialog memory as this component
    usually holds a **dialog state**. The dialog state is the state of the conversation:
    the entities that have appeared so far, the intents that have appeared so far,
    and so on. Input to this component is the previous dialog state and the current
    user parsed with intent and entities. The output of this component is the new
    dialog state.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Answer generator**: Given all the inputs from the previous stages, generates
    the system''s answer to the user utterance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Text-to-speech**: This component generates a speech file (WAV or mp3) from
    the system''s answer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each of the components is trained and evaluated separately. For example, the
    speech-to-text component is trained on an annotated speech corpus (training is
    done on speech files and the corresponding transcriptions). The NLU component
    is trained on intent and an entity labeled corpus (similar to the datasets we
    used in *Chapters 6, 7, 8,* and *9*). In this chapter, we'll focus on the NLU
    component tasks. For text-based products, the first and last components are not
    necessary and are replaced with email or chat client integration.
  prefs: []
  type: TYPE_NORMAL
- en: There's another paradigm that is called **end-to-end spoken language understanding**
    (**SLU**). In SLU architectures, the system is trained end to end, which means
    that the input to the system is a speech file and the output is the system response.
    Each approach has pros and cons; you can refer to the *References* section for
    more material.
  prefs: []
  type: TYPE_NORMAL
- en: 'As the author of this book, I''m happy to present this chapter to you with
    my domain experience. I''ve been working in the conversational AI area for quite
    some time and tackle challenges of language and speech processing every day for
    our product. Me and my colleagues are building the world''s first driver digital
    assistant, Chris (*Tips & Tricks: How to talk to Chris – basic voice commands*,
    [https://www.youtube.com/watch?v=Qwnjszu3exY](https://www.youtube.com/watch?v=Qwnjszu3exY)).
    Chris can make calls, answer incoming calls, read and write WhatsApp and text
    messages, play music, navigate, and make small talk. Here is Chris:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.1 – In-car voice assistant Chris (this is the product that the
    author is working on](img/Figure_10_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.1 – In-car voice assistant Chris (this is the product that the author
    is working on)
  prefs: []
  type: TYPE_NORMAL
- en: As we see from the preceding examples, conversational AI has become a hot topic
    recently. As an NLP professional, it's quite likely that you'll work for a conversational
    product or work in a related area such as speech recognition, text-to-speech,
    or question answering. Techniques presented in this chapter such as intent recognition,
    entity extraction, and anaphora resolution are applicable to a wide set of NLU
    problems as well. Let's dive into the technical sections. We'll start by exploring
    the dataset that we'll use throughout this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Getting to know the dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In *Chapters 6*, *7*, *8*, and *9*, we worked on well-known real-world datasets
    for text classification and entity extraction purposes. In these chapters, we
    always explored our dataset as the very first task. The main point of data exploration
    is to understand the nature of the dataset text in order to develop strategies
    in our algorithms that can tackle this dataset. If we recall from [*Chapter 6*](B16570_06_Final_JM_ePub.xhtml#_idTextAnchor103)*,
    Putting Everything Together: Semantic Parsing with spaCy*, the following are the
    main points we should keep an eye on during our exploration:'
  prefs: []
  type: TYPE_NORMAL
- en: What kind of utterances there are? Are utterances short text or full sentences
    or long paragraphs or documents? What is the average utterance length?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What sort of entities does the corpus include? Person names, organization names,
    geographical locations, street names? Which ones do we want to extract?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How is punctuation used? Is the text correctly punctuated or is no punctuation
    used at all?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How are the grammatical rules followed? Is capitalization correct, and did the
    users follow the grammatical rules? Are there misspelled words?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The previous datasets we used consisted of `(text, class_label)` pairs to be
    used in text classification tasks or `(text, list_of_entities)` pairs to be used
    in entity extraction tasks. In this chapter, we'll tackle a much more complicated
    task, chatbot design. Hence, the dataset will be more structured and more complicated.
  prefs: []
  type: TYPE_NORMAL
- en: 'Chatbot design datasets are usually in JSON format to maintain the dataset
    structure. Here, structure means the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Keeping the order of user and system utterances
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Marking slots of the user utterances
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Labeling the intent of the user utterances
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Throughout this chapter, we'll use Google Research's **The Schema-Guided Dialogue**
    dataset (**SGD**) ([https://github.com/google-research-datasets/dstc8-schema-guided-dialogue](https://github.com/google-research-datasets/dstc8-schema-guided-dialogue)).
    This dataset consists of annotated user-virtual assistant interactions. The original
    dataset contains over 20,000 dialog segments in several areas, including restaurant
    reservations, movie reservations, weather queries, and travel ticket booking.
    Dialogs include utterances of user and virtual assistant turn by turn. In this
    chapter, we won't use all of this massive dataset; instead, we'll use a subset
    about restaurant reservations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s get started with downloading the dataset. You can download the dataset
    from the book''s GitHub repository at [https://github.com/PacktPublishing/Mastering-spaCy/blob/main/Chapter10/data/restaurants.json](https://github.com/PacktPublishing/Mastering-spaCy/blob/main/Chapter10/data/restaurants.json).
    Alternatively, you can write the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'If you open the file with a text editor and look at the first few lines, you''ll
    see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: First of all, the dataset consists of dialog segments and each dialog segment
    has a `dialogue_id` instance. Each dialog segment is an ordered list of turns
    and each turn belongs to the user or to the system. A `turns` field is a list
    of the user/system turns. Each element of the `turns` list is a turn. One turn
    consists of a speaker (user or system), the speaker's utterance, a list of slots,
    and an intent for the user utterances.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some example user utterances from the dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: As we see from these example utterances, capital letters and punctuation are
    used in the user utterances. Users can make typos, such as the word `afforadable`
    in the second sentence. There are some grammatical errors as well, such as the
    wrong usage of a capital letter in the word `Thanks` of the fifth sentence. Another
    capitalization mistake occurs in the sixth sentence, where the pronoun *I* is
    written as `i` twice.
  prefs: []
  type: TYPE_NORMAL
- en: Also, one utterance can contain multiple sentences. The first utterance starts
    with a greeting sentence and the last two sentences start with an affirmative
    or negative answer sentence each. The fourth sentence also starts with a `Yes`,
    but not as a standalone sentence; instead it's separated from the second sentence
    with a comma.
  prefs: []
  type: TYPE_NORMAL
- en: Intent recognition for multiple sentence utterances is a point we need to pay
    attention to in general – these types of utterances can contain multiple intents.
    Also, answer generation for multi-sentence utterances is a bit tricky; sometimes
    we need to generate only one answer (such as for the second sentence in the preceding
    code) or sometimes we need to generate an answer per each user sentence (such
    as for the last sentence in the preceding code).
  prefs: []
  type: TYPE_NORMAL
- en: 'This is a dataset for restaurant reservations, so naturally it includes some
    slots in user utterances such as the location, cuisine, time, date, number of
    people, and so on. Our dataset includes the following slots:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Here are some example sentences with the preceding slot types and their values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we come to the class labels for the intent recognition and the distribution
    of these class labels. Here''s the class labels distribution:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '`NONE` is a special class label for utterances that indicate the end of a conversation
    or just saying thank you. This class of utterances is not related to restaurant
    reservation in general. Utterances that intend to list restaurants and get some
    information are labeled with the class label `FindRestaurants`, and utterances
    that include the intent to make a booking are labeled with `ReserveRestaurants`.
    Let''s see some example utterances of each class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: We notice that the follow-up sentences, such as utterances 6, 8, and 9, are
    marked with the intents `FindRestaurants` and `ReserveRestaurant`. These utterances
    don't contain the intents of finding/reserving directly, but they continue the
    dialog about finding/reserving a restaurant and still make queries about the restaurant/reservation.
    Hence, although there are no explicit actions of finding/reserving stated in these
    utterances, still the intents are to find/reserve a restaurant.
  prefs: []
  type: TYPE_NORMAL
- en: That's it – we collected enough insights about our dataset using the preliminary
    work of this section. With these insights, we're ready to build our NLU pipeline.
    We'll start with extracting the user utterance entities.
  prefs: []
  type: TYPE_NORMAL
- en: Entity extraction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we''ll implement the first step of our chatbot NLU pipeline
    and extract entities from the dataset utterances. The following are the entities
    marked in our dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: To extract the entities, we'll use the spaCy NER model and the spaCy `Matcher`
    class. Let's get started by extracting the `city` entities.
  prefs: []
  type: TYPE_NORMAL
- en: Extracting city entities
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We''ll first extract the `city` entities. We''ll get started by recalling some
    information about the spaCy NER model and entity labels from [*Chapter 3*](B16570_03_Final_JM_ePub.xhtml#_idTextAnchor055)*,
    Linguistic Features*, and [*Chapter 6*](B16570_06_Final_JM_ePub.xhtml#_idTextAnchor103)*,
    Putting Everything Together: Semantic Parsing with spaCy*:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we recall that the spaCy named entity label for cities and countries
    is `GPE`. Let''s ask spaCy to explain what `GPE` label corresponds to once again:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Secondly, we also recall that we can access entities of a `Doc` object via
    the `ents` property. We can find all entities in an utterance that are labeled
    by the spaCy NER model as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In this code segment, we listed all named entities of this utterance by calling
    `doc.ents`. Then, we examined the entity labels by calling `ent.label_`. Examining
    the output, we see that this utterance contains five entities – one cardinal number
    entity (`2`), one `TIME` entity (`11:30 am`), one `PRODUCT` entity (`Bird`, which
    is not an ideal label for a restaurant), one `CITY` entity (`Palo Alto`), and
    one `DATE` entity (`today`). The `GPE` type entity is what we're looking for;
    `Palo Alto` is a city in the US and hence is labeled by the spaCy NER model as
    `GPE`.
  prefs: []
  type: TYPE_NORMAL
- en: The script at [https://github.com/PacktPublishing/Mastering-spaCy/blob/main/Chapter10/extract_city_ents.py](https://github.com/PacktPublishing/Mastering-spaCy/blob/main/Chapter10/extract_city_ents.py)
    in the book's GitHub outputs all the utterances that include a city entity together
    with the city entities. From the output of this script, we can see that the spaCy
    NER model performs very well on this corpus for `GPE` entities. We don't need
    to train the spaCy NER model with our custom data.
  prefs: []
  type: TYPE_NORMAL
- en: We extracted city entities, and our chatbot knows in which city to look for
    a restaurant. Now, we'll extract dates and times to allow our chatbot to make
    a real reservation.
  prefs: []
  type: TYPE_NORMAL
- en: Extracting date and time entities
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Extracting `DATE` and `TIME` entities is similar to extracting `CITY` entities,
    which we saw in the previous section. We'll again go over the corpus utterances
    and see how successful the spaCy NER model is at extracting `DATE` and `TIME`
    entities from our corpus.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see some example utterances from the corpus:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'In the following code, we''ll extract the entities of these example utterances:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Looks good! The output looks quite successful:'
  prefs: []
  type: TYPE_NORMAL
- en: The time entities `11:30 am` and `1:30 pm` of the first and second sentences
    are extracted successfully.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `DATE` entities `next friday` and `next Friday` of the third and fourth
    sentences are extracted as well. Notice the first entity includes a typo: `friday`
    should be written as *Friday* – still, the spaCy NER model successfully extracted
    this entity.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The fifth sentence included both a `DATE` entity and a `TIME` entity. We can
    break the `DATE` entity `Monday next week` into two parts: `Monday` – a weekday
    and `next week` – a relative date (the exact date depends on the date of the utterance).
    This entity consists of two noun phrases: `Monday` (noun) and `next week` (adjective
    noun). spaCy can handle such multiword entities. The time entity, `half past 12`,
    of this utterance is also a multiword entity. This entity consists of a noun (`half`),
    a preposition (`past`), and a number (`12`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The same goes for the sixth utterance''s multiword `TIME` entity, `A quarter
    past 5`. Here is the dependency tree of this entity:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 10.2 – Dependency tree of the time entity "A quarter past 5"'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10_2.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.2 – Dependency tree of the time entity "A quarter past 5"
  prefs: []
  type: TYPE_NORMAL
- en: 'The preceding examples look quite good indeed, but how about the following
    utterances:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Oops-a-daisy – looks like we have some `day`, as date entities incorrectly.
    What can we do here?
  prefs: []
  type: TYPE_NORMAL
- en: 'Fortunately, these false matches don''t form a pattern such as `a good day`
    and `a wonderful day` of the third and fourth sentence are not labeled as entities.
    Only the word sequences `a great day` and `a nice day` are labeled as entities.
    Then, we can just filter the spaCy NER results with the following two patterns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code block performs the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: First, we defined a list of phrases that we don't want to come up as `DATE`
    entities.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We extracted the `DATE` entities of the Doc object on the third line by iterating
    over all entities of `doc` and picking the entities whose labels were `DATE`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the next line, we filtered the entities that didn't appear in the `wrong_matches`
    list.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We printed the result. As expected, the final result of the `date` entity is
    an empty list.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Great, we have extracted `DATE` and `TIME` entities along with `CITY` entities.
    For all the three entity types, we used the spaCy NER model directly, because
    spaCy NER recognizes date, time, and location entities. How about `phone_number`
    entities? SpaCy NER doesn't include such a label at all. So, we'll use some `Matcher`
    class tricks to handle this entity type. Let's extract the phone numbers.
  prefs: []
  type: TYPE_NORMAL
- en: Extracting phone numbers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We had some `Matcher` class practice on entities that include numbers in [*Chapter
    4*](B16570_04_Final_JM_ePub.xhtml#_idTextAnchor069)*, Rule-Based Matching*. We
    can also recall from [*Chapter 4*](B16570_04_Final_JM_ePub.xhtml#_idTextAnchor069)*,
    Rule-Based Matching*, that matching number type entities can be indeed quite tricky;
    extracting telephone numbers especially requires attention. Phone numbers can
    come in different formats, with dashes (212-44-44), area codes ((312) 790 12 31),
    country and area codes (+49 30 456 222), and the number of digits differing from
    country to country. As a result, we usually examine the following points:'
  prefs: []
  type: TYPE_NORMAL
- en: How many country formats are the corpus phone number entities written in?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How are the digit blocks separated – with a dash, or whitespace, or both?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is there an area code block in some phone numbers?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is there a country code block in some phone numbers?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Are the country code blocks preceded with a + or 00, or are both formats used?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s examine some of our phone number entities, then:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: All the phone-type entities occur in system utterances. The chatbot fetches
    phone numbers of restaurants and provides them to the users. The chatbot formed
    phone number entities by placing a dash between the digit blocks. Also, all the
    phone numbers are in USA phone number format. Hence the phone number format is
    uniform and is of the form `ddd-ddd-dddd`. This is very good for defining a Matcher
    pattern. We can define only one pattern and it matches all the phone number entities.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s first see how an example phone number tokenizes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Each digit block is tokenized as one token and each dash character is tokenized
    as one token as well. Hence, in our Matcher pattern, we''ll look for a sequence
    of five tokens: a three-digit number, a dash, a three-digit number again, a dash
    again, and finally a four-digit number. Then, our Matcher pattern should look
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'If you recall from [*Chapter 4*](B16570_04_Final_JM_ePub.xhtml#_idTextAnchor069)*,
    Rule-Based Matching*, the `SHAPE` attribute refers to the token shape. The token
    shape represents the shape of the characters: `d` means a digit, `X` means a capital
    character, and `x` means a lowercase character. Hence `{"SHAPE": "ddd"}` means
    a token that consists of three digits. This pattern will match five tokens of
    the form `ddd-ddd-dddd`. Let''s try our brand-new pattern on a corpus utterance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Voila! Our new pattern matched a phone number type entity as expected! Now,
    we'll deal with the cuisine type so that our chatbot can make a reservation. Let's
    see how to extract the cuisine type.
  prefs: []
  type: TYPE_NORMAL
- en: Extracting cuisine types
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Extracting cuisine types is much easier than extracting a number of people
    or phone types; indeed, it''s similar to extracting city entities. We can use
    a spaCy NER label directly for cuisine types – `NORP`. The `NORP` entity label
    refers to ethnic or political groups:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Fortunately, cuisine names in our corpus coincide with nationalities. So, cuisine
    names are labeled as NORP by spaCy's NER.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let''s have a look at some example utterances:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s extract the entities of these utterances and examine how spaCy''s NER
    labels cuisine types as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we are able to extract the city, date and time, number of people, and
    cuisine entities from user utterances. The result of the named entity extraction
    module we built here carries all the information the chatbot needs to provide
    to the reservation system. Here''s an example utterance annotated with extracted
    entities:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Here, we completed the first part of our semantic parsing, extracting entities.
    A full semantic parse needs an intent too. Now, we'll move on to the next section
    and do intent recognition with TensorFlow and Keras.
  prefs: []
  type: TYPE_NORMAL
- en: Intent recognition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Intent recognition** (also called **intent classification**) is the task
    of classifying user utterances with predefined labels (intents). Intent classification
    is basically text classification. Intent classification is a well-known and common
    NLP task. GitHub and Kaggle host many intent classification datasets (please refer
    to the *References* section for the names of some example datasets).'
  prefs: []
  type: TYPE_NORMAL
- en: 'In real-world chatbot applications, we first determine the domain our chatbot
    has to function in, such as finance and banking, healthcare, marketing, and so
    on. Then we perform the following loop of actions:'
  prefs: []
  type: TYPE_NORMAL
- en: We determine a set of intents we want to support and prepare a labeled dataset
    of `(utterance, label)` pairs. We train our intent classifier on this dataset.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, we deploy our chatbot to the users and gather real user data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then we examine how our chatbot performed on real user data. At this stage,
    usually, we spot some new intents and some utterances our chatbot failed to recognize.
    We extend our set of intents with the new intents, add the unrecognized utterances
    to our training set, and retrain our intent classifier.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We go to *step 2* and perform *steps 2-3* until chatbot NLU quality reaches
    a good level of accuracy (> 0.95)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Our dataset is a real-world dataset; it contains typos and grammatical mistakes.
    While designing our intent classifiers – especially while doing pattern-based
    classification – we need to be robust to such mistakes.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll do the intent recognition in two steps: pattern-based text classification
    and statistical text classification. We saw how to do statistical text classification
    with TensorFlow and Keras in [*Chapter 8*](B16570_08_Final_JM_ePub.xhtml#_idTextAnchor137)*,
    Text Classification with spaCy*. In this section, we''ll work with Tensorflow
    and Keras again. Before that, we''ll see how to design a pattern-based text classifier.'
  prefs: []
  type: TYPE_NORMAL
- en: Pattern-based text classification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Pattern-based classification** means classifying text by matching a predefined
    list of patterns to the text. We compare a precompiled list of patterns against
    the utterances and check whether there''s a match.'
  prefs: []
  type: TYPE_NORMAL
- en: An immediate example is **spam classification**. If an email contains one of
    the patterns, such as *you won a lottery* and *I'm a Nigerian prince*, then this
    email should be classified as spam. Pattern-based classifiers are combined with
    **statistical classifiers** to boost the overall system accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: Contrary to statistical classifiers, pattern-based classifiers are easy to build.
    We don't need to put any effort into training a TensorFlow model at all. We will
    compile a list of patterns from our corpus and feed them to Matcher. Then, Matcher
    can look for pattern matches in utterances.
  prefs: []
  type: TYPE_NORMAL
- en: 'To build a pattern-based classifier, we first need to collect some patterns.
    In this section, we''ll classify utterances with the `NONE` label. Let''s see
    some utterance examples first:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'By looking at these utterances, we see that the utterances with the `NONE`
    label follow some patterns:'
  prefs: []
  type: TYPE_NORMAL
- en: Most of the utterances start with `No,` or `No.`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Patterns of saying *thank you* are also quite common. The patterns `Thanks`,
    `thank you`, and `thanks a lot` occur in most of the utterances in the preceding
    code.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Some helper phrases such as `that is all`, `that'll be all`, `that's OK`, and
    `this should be enough` are also commonly used.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Based on this information, we can create three Matcher patterns as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s go over the patterns one by one:'
  prefs: []
  type: TYPE_NORMAL
- en: The first pattern matches token sequences `no,`, `no.`, `nope,`, `nope.`, `No,`,
    `No.`, `Nope,`, and `Nope.`. The first item matches two tokens `no` and `nope`
    either in capitals or small letters. The second item matches the punctuation marks
    `,` and `.`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The second pattern matches `thank`, `thank you`, `thanks`, and `thanks a lot`,
    either in capitals or small letters. The first item matches `thank` and `thanks`
    `s?`. In regex syntax, the `s` character is optional. The second item corresponds
    to the words `you` and `a lot`, which can possibly follow `thanks?`. The second
    item is optional; hence, the pattern matches `thanks` and `thank` as well. We
    used the operator `OP: *` to make the second item optional; recall from [*Chapter
    4*](B16570_04_Final_JM_ePub.xhtml#_idTextAnchor069)*, Rule-Based Matching*, that
    Matcher supports operator syntax with different operators, such as `*` , `+`,
    and `?`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The third pattern matches the token sequences `that is all`, `that's all`, `thats
    all`, and so on. Notice that the first item includes some misspelled words, such
    as `thats` and `thatll`. We included the misspelled words on purpose, so the matching
    will be more robust to user typos.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Different combinations of the preceding three patterns will match the utterances
    of the `NONE` class. You can try the patterns by adding them to a Matcher object
    and see how they match.
  prefs: []
  type: TYPE_NORMAL
- en: Pro tip
  prefs: []
  type: TYPE_NORMAL
- en: While designing a rule-based system, always keep in mind that user data is not
    perfect. User data contains typos, grammatical mistakes, and wrong capitalization.
    Always keep robustness as a high priority and test your patterns on user data.
  prefs: []
  type: TYPE_NORMAL
- en: We made a statistical model-free classifier by making use of some common patterns
    and classified one intent successfully. How about the other two intents – `FindRestaurants`
    and `ReserveRestaurant`? Utterances of these two intents are semantically much
    more complicated, so we cannot cope with pattern lists. We need statistical models
    to recognize these two intents. Let's go ahead and train our statistical text
    classifiers with TensorFlow and Keras.
  prefs: []
  type: TYPE_NORMAL
- en: Classifying text with a character-level LSTM
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, we''ll train a **character-level LSTM architecture** for recognizing
    the intents. We already practiced text classification with TensorFlow and Keras
    in [*Chapter 8*](B16570_08_Final_JM_ePub.xhtml#_idTextAnchor137)*, Text Classification
    with spaCy*. Recall from this chapter that LSTMs are sequential models that process
    one input at one time step. We fed one word at each time step as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.3 – Feeding one word to an LSTM at each time step'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10_3.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.3 – Feeding one word to an LSTM at each time step
  prefs: []
  type: TYPE_NORMAL
- en: As we remarked in [*Chapter 8*](B16570_08_Final_JM_ePub.xhtml#_idTextAnchor137)*,
    Text Classification with spaCy*, LSTMs have an internal state (you can think of
    it as a memory), so LSTMs can model the sequential dependencies in the input sequence
    by holding past information in their internal state.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, we''ll train a character-level LSTM. As the name suggests,
    we''ll feed utterances character by character, not word by word. Each utterance
    will be represented as a sequence of characters. At each time step, we''ll feed
    one character. This is what feeding the utterance from *Figure 10.3* looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.4 – Feeding the first two words of the utterance "I want Italian
    food"'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10_4.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.4 – Feeding the first two words of the utterance "I want Italian food"
  prefs: []
  type: TYPE_NORMAL
- en: We notice that the space character is fed as an input as well, because the space
    character is also a part of the utterance; for character-level tasks, there is
    no distinction between digits, spaces, and letters.
  prefs: []
  type: TYPE_NORMAL
- en: Let's start building the Keras model. We'll skip the data preparation stage
    here. You can find the complete code in the intent classification notebook [https://github.com/PacktPublishing/Mastering-spaCy/blob/main/Chapter10/Intent-classifier-char-LSTM.ipynb](https://github.com/PacktPublishing/Mastering-spaCy/blob/main/Chapter10/Intent-classifier-char-LSTM.ipynb).
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll directly start with Keras'' Tokenizer to create a vocabulary. Recall
    from [*Chapter 8*](B16570_08_Final_JM_ePub.xhtml#_idTextAnchor137)*, Text Classification
    with spaCy*, that we use Tokenizer to do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a vocabulary from the dataset sentences.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Assign a token ID to each token of the dataset.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Transform input sentences to token IDs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s see how to perform each step:'
  prefs: []
  type: TYPE_NORMAL
- en: 'In [*Chapter 8*](B16570_08_Final_JM_ePub.xhtml#_idTextAnchor137)*, Text Classification
    with spaCy*, we tokenized the sentences into words and assigned token IDs to words.
    This time, we''ll break the input sentence into its characters, then assign token
    IDs to characters. Tokenizer provides a parameter named `char_level`. Here''s
    the Tokenizer code for character-level tokenization:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The preceding code segment will create a vocabulary from the input characters.
    We used the `lower=True` parameter, so all characters of the input sentence are
    made lowercase by Tokenizer. After initializing the `Tokenizer` object on our
    vocabulary, we can now examine its vocabulary. Here are the first 10 items of
    the Tokenizer vocabulary:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Just as with the word-level vocabulary, index `0` is reserved for a special
    token, which is the padding character. Recall from [*Chapter 8*](B16570_08_Final_JM_ePub.xhtml#_idTextAnchor137)*,
    Text Classification with spaCy*, that Keras cannot process variable-length sequences;
    each sentence in the dataset should be of the same length. Hence, we pad all sentences
    to a maximum length by appending a padding character to the sentence end or sentence
    start.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Next, we''ll convert each dataset sentence into token IDs. This is achieved
    by calling the `texts_to_sequences` method of Tokenizer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we''ll pad all the input sentences to a length of `150`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We''re ready to feed our transformed dataset into our LSTM model. Our model
    is a simple yet very efficient one: we placed a dense layer on top of a bidirectional
    LSTM layer. Here''s the model architecture:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'A bidirectional LSTM layer means two LSTMs stacked on top of each other. The
    first LSTM goes through the input sequence from left to right (in a forward direction)
    and the second LSTM goes through the input sequence right to left (in a backward
    direction). For each time step, the outputs of the forward LSTM and backward LSTM
    are concatenated to generate a single output vector. The following figure exhibits
    our architecture with a bidirectional LSTM:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 10.5 – Bidirectional LSTM architecture'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/Figure_10_5.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 10.5 – Bidirectional LSTM architecture
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Next, we compile our model and train it on our dataset by calling `model.fit`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here, we compiled our model with the following:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: a) Binary cross-entropy loss, because this is a binary classification task (we
    have two class labels).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b) The `Adam` optimizer, which will help the training procedure to run faster
    by arranging the size of the training steps. Please refer to the *References*
    section and [*Chapter 8*](B16570_08_Final_JM_ePub.xhtml#_idTextAnchor137)*, Text
    Classification with spaCy*, for more information about the `Adam` optimizer.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c) Accuracy as our success metric. Accuracy is calculated by comparing how often
    the predicted label is equal to the actual label.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: After fitting our model, our model gives a `0.8226` accuracy on the validation
    set, which is quite good.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, only one question remains: why did we prefer to train a character-level
    model this time? Character-level models definitely have some advantages:'
  prefs: []
  type: TYPE_NORMAL
- en: Character-level models are highly misspelling-tolerant. Consider the misspelled
    word *charactr* – whether or not the *e* is missing does not affect the overall
    sentence semantics that much. For our dataset, we will benefit from this robustness,
    as we have already seen spelling mistakes by users in our dataset exploration.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The vocabulary size is smaller than a word-level model. The number of characters
    in the alphabet (for any given language) is fixed and low (a maximum of 50 characters,
    including uppercase and lowercase letters, digits, and some punctuation); but
    the number of words in a language is much greater. As a result, model sizes can
    differ. The main difference lies at the embedding layer; an embedding table is
    of size `(vocabulary_size, output_dim)` (refer to the model code). Given that
    the output dimensions are the same, 50 rows is really small compared to thousands
    of rows.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this section, we were able to extract the user intent from the utterances.
    Intent recognition is the main step in understanding sentence semantics, but is
    there something more? In the next section, we'll dive into sentence-level and
    dialog-level semantics. More semantic parsing
  prefs: []
  type: TYPE_NORMAL
- en: This is a section solely on chatbot NLU. In this section, we'll explore sentence-level
    semantic and syntactic information to generate a deeper understanding of the input
    utterances, as well as providing clues to answer generation.
  prefs: []
  type: TYPE_NORMAL
- en: In the rest of this section, please think of the answer generation component
    as a black box. We provide the semantic parse of the sentence and it generates
    an answer based on this semantic parse. Let's start by dissecting sentence syntax
    and examining the subjects and objects of the utterances.
  prefs: []
  type: TYPE_NORMAL
- en: Differentiating subjects from objects
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Recall from [*Chapter 3*](B16570_03_Final_JM_ePub.xhtml#_idTextAnchor055)*,
    Linguistic Features*, that a sentence has two important grammatical components:
    a **subject** and an **object**. The subject is the person or thing that performs
    the action given by the verb of the sentence:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: A subject can be a noun, a pronoun, or a noun phrase.
  prefs: []
  type: TYPE_NORMAL
- en: 'An object is the thing or person on which the subject performs the action given
    by the verb. An object can be a noun, a pronoun, or a noun phrase too. Here are
    some examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: So far, so good, but how does this information help us in our chatbot NLU?
  prefs: []
  type: TYPE_NORMAL
- en: 'Extracting the subject and the object helps us understand the sentence structure,
    hence adding one more layer to the semantic parse of the sentence. Sentence subject
    and object information directly relates to answer generation. Let''s see some
    examples of utterances from our dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'The following figure shows the dependency parse of this utterance. The subject
    is the noun phrase `this restaurant`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.6 – Dependency parse of the example utterance'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10_6.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.6 – Dependency parse of the example utterance
  prefs: []
  type: TYPE_NORMAL
- en: 'How can we generate an answer to this sentence? Obviously, the answer should
    have `this restaurant` (or the restaurant it refers to) as the subject. Some answers
    could be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'What if the user puts `this restaurant` into the object role? Would the answer
    change? Let''s take some example utterances from the dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Obviously, the user is asking about the address of the restaurant again. The
    system needs to give the restaurant address information. However, this time, the
    subject of these sentences is `you`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.7 – Dependency parse of the first sentence'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10_7.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.7 – Dependency parse of the first sentence
  prefs: []
  type: TYPE_NORMAL
- en: 'This question''s subject is `you`, so the answer can start with an *I*. This
    a question sentence, hence the answer can start with a *yes*/*no* or the answer
    can just provide the restaurant''s address directly. The following sentences are
    all possible answers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'The same phrase, `the restaurant`, being the subject or the object doesn''t
    affect the user''s intent, but it affects the sentence structure of the answer.
    Let''s look at the information more systematically. The semantic parses of the
    preceding example sentences look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: When we feed these semantic parses to the answer generator module, this module
    can generate answers by taking the current utterance, the dialog history, the
    utterance intent, and the utterance's sentence structure (for the time being,
    only the sentence subject information) into account.
  prefs: []
  type: TYPE_NORMAL
- en: Here, we extracted the utterance's sentence structure information by looking
    at the utterance's dependency tree. Can a dependency parse provide us with more
    information about the utterance? The answer is yes. We'll see how to extract the
    sentence type in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Parsing the sentence type
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, we''ll extract the sentence type of the user utterances. The
    grammar has four main sentence types, classified by their purpose:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Sentence types in chatbot NLU are a bit different; we classify sentences according
    to the POS tag of the subject and objects as well as the purpose. Here are some
    sentence types that are used in chatbot NLU:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: Let's examine each sentence type and its structural properties. We start with
    question sentences.
  prefs: []
  type: TYPE_NORMAL
- en: Question sentences
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A question sentence is used when the user wants to ask something. A question
    sentence can be formed in two ways, either by using an interrogative pronoun or
    by placing a modal/auxiliary verb at the beginning of the sentence:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: Hence, we also divide the question sentences into two classes, **wh-questions**
    and **yes/no questions**. As the name suggests, wh-questions start with a **wh-word**
    (a wh-word means an interrogative pronoun, such as where, what, who, and how)
    and yes/no questions are formed by using a modal/auxiliary verb.
  prefs: []
  type: TYPE_NORMAL
- en: 'How will this classification help us? Syntactically, yes/no questions should
    be answered with a yes or no. Hence, if our chatbot NLU passes a yes/no question
    to the answer generation module, the answer generator should evaluate this information
    and generate an answer that starts with a yes/no. Wh-questions aim to get information
    about the subject or objects, hence the answer generator module should provide
    information about the sentence subject or objects. Consider the following utterance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'This utterance generates the following dependency parse:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.8 – Dependency parse of the example wh-question'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10_8.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.8 – Dependency parse of the example wh-question
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, the subject of the utterance is `this restaurant`; hence the answer generator
    should generate an answer by relating `Where` and `this restaurant`. How about
    the following utterance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'The dependency parse of this utterance looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.9 -- Dependency parse of the example wh-question'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10_9.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.9 -- Dependency parse of the example wh-question
  prefs: []
  type: TYPE_NORMAL
- en: Here, the sentence structure is a bit different. `Which city` is the subject
    of the sentence and `this restaurant` is the subject of the clause. Here, the
    answer generation module should generate an answer by relating `which city` and
    `this restaurant`.
  prefs: []
  type: TYPE_NORMAL
- en: We will now move on to imperative sentence type.
  prefs: []
  type: TYPE_NORMAL
- en: Imperative sentence
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Imperative sentences** occur quite frequently in chatbot user utterances.
    An imperative sentence is formed by placing the main verb at the beginning of
    the sentence. Here are some utterance examples from our dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'As we see, imperative utterances occur quite a lot in user utterances, because
    they''re succinct and to-the-point. We can spot these types of sentences by looking
    at the POS tags of the words: either the first word is a verb or the sentence
    starts with *please* and the second word is a verb. The following Matcher patterns
    match imperative utterances:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'How would the answer generator process these types of sentences? Imperative
    sentences usually include the syntactic and semantic elements to generate an answer;
    the main verb provides the action and is usually followed by a list of objects.
    Here''s an example parse for the utterance `Find me Ethiopian cuisine in Berkeley`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.10 – Dependency parse of the example utterance'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10_10.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.10 – Dependency parse of the example utterance
  prefs: []
  type: TYPE_NORMAL
- en: 'From the figure, we can see the syntactic components of this sentence as `Find`
    (the action), `Ethiopian cuisine` (an object), and `Berkeley` (an object). These
    components provide a clear template to the answer generator for generating an
    answer to this utterance: the answer generator should ask the restaurants database
    for matches of `Ethiopian cuisine` and `Berkeley` and list the matching restaurants.'
  prefs: []
  type: TYPE_NORMAL
- en: Now we move on to the next sentence type, wish sentences. Let's see look at
    sentences in detail.
  prefs: []
  type: TYPE_NORMAL
- en: Wish sentences
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Wish sentences** are semantically similar to imperative sentences. The difference
    is syntactic: wish sentences start with phrases such as *I''d like to*, *Can I*,
    *Can you*, and *May I*, pointing to a wish. Here are some examples from our dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: Extracting the verb and the objects is similar to what we do for imperative
    sentences, hence the semantic parse is quite similar.
  prefs: []
  type: TYPE_NORMAL
- en: 'After extracting the sentence type, we can include it into our semantic parse
    result as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: Now, we have a rich semantic and syntactic representation of the input utterance.
    In the next section, we'll go one step beyond the sentence-level semantics and
    go through the dialog-level semantics. Let's move on to the next section and see
    how we tackle dialog-level semantics.
  prefs: []
  type: TYPE_NORMAL
- en: Anaphora resolution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, we''ll explore the linguistic concepts of **anaphora** and
    **cohesion**. In linguistics, cohesion means the grammatical links that glue a
    text together semantically. This text can be a single sentence, a paragraph, or
    a dialog segment. Consider the following two sentences:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: Here, the word `one` refers to the dress from the first sentence. A human can
    resolve this link easily. It's not so straightforward for software programs, though.
  prefs: []
  type: TYPE_NORMAL
- en: 'Also, consider the following dialog segment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'The second sentence is completely understandable, though some parts of the
    sentence are missing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'In written and spoken language, we use such **shortcuts** every day. However,
    resolving such shortcuts needs attention while programming, especially in chatbot
    NLU. Consider these utterances and dialog segments from our dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Example 1:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'Example 2:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Example 3:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'Example 4:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'Example 5:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'Example 6:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: All the highlighted parts of the preceding sentences and dialogs are examples
    of a linguistic event named `one`, `more`, `same`, `it`, and so on. Anaphora resolution
    means to resolve exactly the phrases anaphoric words point to.
  prefs: []
  type: TYPE_NORMAL
- en: How do we apply this information to our chatbot NLU then?
  prefs: []
  type: TYPE_NORMAL
- en: 'First of all, we need to determine whether an utterance involves an anaphora
    and whether we need an anaphora resolution. Consider the following dialog segment
    again:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'The dependency parse of the second utterance looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.11 – Dependency parse of the example utterance'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10_11.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.11 – Dependency parse of the example utterance
  prefs: []
  type: TYPE_NORMAL
- en: 'First of all, `one` appears as the direct object of the sentence and there
    are no other direct objects. This means that `one` should be an anaphora. In order
    to resolve what `one` refers to, we''ll look back to the first utterance of the
    dialog. The following dependency parse belongs to the first utterance, `Do you
    want to make a reservation?`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.12 – Dependency parse of the example utterance'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_10_12.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.12 – Dependency parse of the example utterance
  prefs: []
  type: TYPE_NORMAL
- en: 'If we look at *Figure 10.11*, we see that the sentence has a direct object,
    `a reservation`, so `one` should refer to `a reservation`. Then, we can arrange
    the resulting semantic parse as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: Replacing `one` with `a reservation` makes the sentence intent clearer. In our
    chatbot NLU, we only have two intents, but what if there are more intents, such
    as reservation cancellation, refunds, and so on? Then `I want to make one` can
    mean making a cancellation or getting a refund as well.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, we make anaphora resolution come before the intent recognition and
    feed the full sentence, where anaphora words are replaced with the phrases they
    refer to. This way, the intent classifier is fed with a sentence where the direct
    object is a noun phrase, not one of the words `one`, `same`, `it`, or `more`,
    which do not carry any meaning on their own.
  prefs: []
  type: TYPE_NORMAL
- en: Now after extracting meaning (by extracting intent) statistically with Keras,
    in this section you learned ways of processing sentence syntax and semantics with
    special NLU techniques. You're ready to combine all the techniques you know and
    design your own chatbot NLU for your future career. This book started with linguistic
    concepts, continued with statistical applications, and in this chapter, we combined
    it all. You're ready to keep going. In all the NLU pipelines you'll design, always
    try to look at the problem from a different view and remember what you learned
    in this book.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: That's it! You made it to the end of this exhaustive chapter and also to the
    end of this book!
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we designed an end-to-end chatbot NLU pipeline. As a first
    task, we explored our dataset. By doing this, we collected linguistic information
    about the utterances and understood the slot types and their corresponding values.
    Then, we performed a significant task of chatbot NLU, entity extraction. We extracted
    several types of entities such as city, date/time, and cuisine with the spaCy
    NER model as well as Matcher. Then, we performed another traditional chatbot NLU
    pipeline task – intent recognition. We trained a character-level LSTM model with
    TensorFlow and Keras.
  prefs: []
  type: TYPE_NORMAL
- en: In the last section, we dived into sentence-level and dialog-level semantics.
    We worked on sentence syntax by differentiating subjects from objects, then learned
    about sentence types and finally learned about the linguistic concept of anaphora
    resolution. We applied what we learned in the previous chapters, both linguistically
    and statistically, by combining several spaCy pipeline components such as NER,
    dependency parsers, and POS taggers.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here are some references for this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: 'On voice assistant products:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Alexa developer blog: [https://developer.amazon.com/blogs/home/tag/Alexa](https://developer.amazon.com/blogs/home/tag/Alexa%20)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Alexa science blog: [https://www.amazon.science/tag/alexa](https://www.amazon.science/tag/alexa%20)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Microsoft''s publication on chatbots: [https://academic.microsoft.com/search?q=chatbot](https://academic.microsoft.com/search?q=chatbot)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Google Assistant: [https://assistant.google.com/](https://assistant.google.com/%20)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Keras layers and optimizers:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Keras layers: [https://keras.io/api/layers/](https://keras.io/api/layers/%20)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Keras optimizers: [https://keras.io/api/optimizers/](https://keras.io/api/optimizers/%20)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'An overview of optimizers: [https://ruder.io/optimizing-gradient-descent/](https://ruder.io/optimizing-gradient-descent/%20)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Adam optimizer: [https://arxiv.org/abs/1412.6980](https://arxiv.org/abs/1412.6980%20)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Datasets for conversational AI:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Taskmaster from Google Research: [https://github.com/google-research-datasets/Taskmaster/tree/master/TM-1-2019](https://github.com/google-research-datasets/Taskmaster/tree/master/TM-1-2019%20)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Simulated Dialogue dataset from Google Research: [https://github.com/google-research-datasets/simulated-dialogue](https://github.com/google-research-datasets/simulated-dialogue%20)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dialog Challenge dataset from Microsoft: [https://github.com/xiul-msr/e2e_dialog_challenge](https://github.com/xiul-msr/e2e_dialog_challenge%20)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dialog State Tracking Challenge dataset: [https://github.com/matthen/dstc](https://github.com/matthen/dstc)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
