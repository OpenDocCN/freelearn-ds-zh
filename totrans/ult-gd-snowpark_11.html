<html><head></head><body>
<div><h1 class="chapter-number" id="_idParaDest-129"><a id="_idTextAnchor133" class="calibre6 pcalibre1 pcalibre"/>8</h1>
<h1 id="_idParaDest-130" class="calibre5"><a id="_idTextAnchor134" class="calibre6 pcalibre1 pcalibre"/>Introduction to Snowpark Container Services</h1>
<p class="calibre3">Containers represent a contemporary method for packaging code in diverse languages, ensuring seamless portability and consistency across various environments. This is particularly true for advanced AI/ML models and comprehensive data-centric applications. These modern data products often handle vast volumes of proprietary data, presenting challenges in efficiently creating, developing, and scaling workloads.</p>
<p class="calibre3">Developers and data scientists often spend more time managing computing resources and clusters than addressing core business challenges. With its unique features, Snowpark Container Services offers a seamless solution to this problem. It allows applications and <strong class="bold">large language models</strong> (<strong class="bold">LLMs</strong>) to be executed on containers directly within the Snowflake Data Cloud, reducing the time and effort spent on resource management. This chapter will help you learn about deploying apps and LLMs on containers within Snowpark.</p>
<p class="calibre3">In this chapter, we are going to cover the following topics:</p>
<ul class="calibre15">
<li class="calibre14">Introduction to Snowpark Container Services</li>
<li class="calibre14">Setting up Snowpark Container Services</li>
<li class="calibre14">Setting up a Snowpark Container Service job</li>
<li class="calibre14">Deploying LLMs with Snowpark</li>
</ul>
<h1 id="_idParaDest-131" class="calibre5"><a id="_idTextAnchor135" class="calibre6 pcalibre1 pcalibre"/>Technical requirements</h1>
<p class="calibre3">To set up the environment, please refer to the technical requirements in the previous chapter. Docker Client and Desktop are also required; you can install Docker from <a href="https://huggingface.co/docs/hub/en/security-tokens" class="calibre6 pcalibre1 pcalibre">https://docs.docker.com/get-docker/</a>.</p>
<p class="calibre3">We’ll also be using the Hugging Face API. To obtain the Hugging Face API token, sign up at <a href="https://github.com/PacktPublishing/The-Ultimate-Guide-To-Snowpark" class="calibre6 pcalibre1 pcalibre">https://huggingface.co/</a>.</p>
<p class="calibre3">The supporting materials are available at <a href="https://github.com/PacktPublishing/The-Ultimate-Guide-To-Snowpark" class="calibre6 pcalibre1 pcalibre">https://github.com/PacktPublishing/The-Ultimate-Guide-To-Snowpark</a>.</p>
<h1 id="_idParaDest-132" class="calibre5"><a id="_idTextAnchor136" class="calibre6 pcalibre1 pcalibre"/>Introduction to Snowpark Container Services</h1>
<p class="calibre3">Snowpark Container Services<a id="_idIndexMarker477" class="calibre6 pcalibre1 pcalibre"/> represents a comprehensive managed container solution tailored to facilitate the deployment, management, and scaling of containerized applications within the Snowflake environment. Users can experience the convenience of executing containerized workloads directly within Snowflake, eliminating the need to transfer data outside the <a id="_idIndexMarker478" class="calibre6 pcalibre1 pcalibre"/>Snowflake ecosystem for processing. Snowpark Container Services introduces an <strong class="bold">Open Container Initiative</strong> (<strong class="bold">OCI</strong>) runtime execution environment meticulously optimized for Snowflake, which empowers users to flawlessly execute OCI images while leveraging the robust capabilities of Snowflake’s data platform.</p>
<p class="calibre3">Snowpark Container Services extends Snowpark’s capability, empowering developers with a trusted and familiar environment to process non-SQL code seamlessly within Snowflake’s governed data domain. This enables applications to effortlessly perform tasks such as connecting to Snowflake, executing SQL queries within a Snowflake virtual warehouse, accessing data files in a Snowflake stage, and processing data with Snowpark models. This streamlined integration fosters an environment conducive to efficient collaboration and focused development efforts within teams.</p>
<p class="calibre3">Developers can create containers tailored to their needs that offer configurable hardware options, including GPU support, enabling a wide range of AI/ML and application workloads within Snowflake through Snowpark. For instance, data science teams can expedite ML tasks by leveraging Python libraries for training and inference while executing resource-intensive generative AI models such as LLMs. App developers can craft and deploy user interfaces using popular frameworks, and data engineers can execute optimized logic within the same processing engine handling SQL or Python DataFrame operations.</p>
<p class="calibre3">In the next section, we will understand how data security works in Snowpark Container Services.</p>
<p class="callout-heading">Note on Snowpark Container Services</p>
<p class="callout">At the time of writing this chapter, Snowpark Container Services are currently in a private preview phase. Please note that once they become available to all users, there may be slight variations in the API methods compared to what is described in this book. We encourage you to monitor the book's GitHub repository for any new changes and updates to the code contents: <a href="https://github.com/PacktPublishing/The-Ultimate-Guide-To-Snowpark" class="calibre6 pcalibre1 pcalibre">https://github.com/PacktPublishing/The-Ultimate-Guide-To-Snowpark</a></p>
<h2 id="_idParaDest-133" class="calibre7"><a id="_idTextAnchor137" class="calibre6 pcalibre1 pcalibre"/>Data security in Snowpark Container Services</h2>
<p class="calibre3">Snowpark <a id="_idIndexMarker479" class="calibre6 pcalibre1 pcalibre"/>Container Services facilitates the secure deployment of full-stack applications, LLMs, and other advanced data products directly within the data environment. This new runtime option under Snowpark streamlines the deployment, management, and scaling of containerized workloads, including jobs, services, and service functions, leveraging Snowflake-managed infrastructure with customizable hardware configurations, such as GPUs. By adopting this innovative runtime, users can bypass the complexities of managing compute resources and container clusters, allowing seamless integration of sophisticated AI/ML models and applications without compromising data security. With containers operating within the Snowflake environment, there’s no need to transfer governed data outside of Snowflake, minimizing exposure to potential security risks. This ensures a secure and robust ecosystem for leveraging internally developed solutions or third-party offerings, such as Snowflake Native Apps, accessible through the Snowflake Marketplace.</p>
<p class="calibre3">In the next section, we will look at the components of Snowpark Containers.</p>
<h2 id="_idParaDest-134" class="calibre7"><a id="_idTextAnchor138" class="calibre6 pcalibre1 pcalibre"/>Components of Snowpark Containers</h2>
<p class="calibre3">Snowpark Container Services<a id="_idIndexMarker480" class="calibre6 pcalibre1 pcalibre"/> offers a streamlined and fully managed approach to the life cycle management of containerized applications and AI/ML models. Unlike other solutions, it provides a cohesive solution that necessitates piecing together disparate components such as container registries, management services, and computing platforms. Consolidating these elements eliminates the burden of managing computing resources and clusters, thereby accelerating the development and deployment of data applications.</p>
<p class="calibre3">Moreover, Snowpark Container Services simplifies container hosting and deployment by offering a combination of simplicity and scalability. Developers only need to provide their containers, and Snowflake handles the hosting and scaling without requiring extensive knowledge of Kubernetes. Developers can interact with the service using SQL, CLI, or Python interfaces, catering to diverse preferences and workloads. Snowpark Containers has two distinct execution options to accommodate various application requirements: services<a id="_idIndexMarker481" class="calibre6 pcalibre1 pcalibre"/> jobs through using service function, and compute pools. The following diagram shows the different components:</p>
<div><div><img alt="Figure 8.1 – Snowpark Container components" src="img/B19923_08_1.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 8.1 – Snowpark Container components</p>
<p class="calibre3">Let’s look at each of the options:</p>
<ul class="calibre15">
<li class="calibre14"><strong class="bold">Services</strong>: A service in<a id="_idIndexMarker482" class="calibre6 pcalibre1 pcalibre"/> Snowflake operates continuously, much like a web service, until explicitly terminated. These services are hosted on secure ingress endpoints and typically host application frontends or APIs. They remain continuously available to handle on-demand requests.</li>
<li class="calibre14"><strong class="bold">Jobs</strong>: These <a id="_idIndexMarker483" class="calibre6 pcalibre1 pcalibre"/>are processes with specific time limits, often initiated manually or scheduled regularly. They encompass various tasks, such as launching container images for machine learning <a id="_idIndexMarker484" class="calibre6 pcalibre1 pcalibre"/>training on GPUs or executing steps within a data pipeline using diverse languages, frameworks, or libraries encapsulated in containers.</li>
<li class="calibre14"><strong class="bold">Service functions</strong>: Functions <a id="_idIndexMarker485" class="calibre6 pcalibre1 pcalibre"/>are time-limited processes designed to receive input, execute specific actions, and be triggered repeatedly by events, leveraging your containerized environments.</li>
<li class="calibre14"><strong class="bold">Compute pools</strong>: A compute pool<a id="_idIndexMarker486" class="calibre6 pcalibre1 pcalibre"/> comprising one or more <strong class="bold">virtual machine</strong> (<strong class="bold">VM</strong>) nodes serves as<a id="_idIndexMarker487" class="calibre6 pcalibre1 pcalibre"/> the infrastructure upon which Snowflake executes your jobs and services.</li>
</ul>
<p class="calibre3">Snowpark Container Services <a id="_idIndexMarker488" class="calibre6 pcalibre1 pcalibre"/>also enables developers to deploy applications directly within their end customers’ Snowflake accounts using the aforementioned components. This allows them to securely install and operate state-of-the-art offerings, such as hosted notebooks and LLMs, within their Snowflake environment, safeguarding the provider’s intellectual property.</p>
<p class="calibre3">In the next section, we will cover how to set up Snowpark Container Services.</p>
<h1 id="_idParaDest-135" class="calibre5"><a id="_idTextAnchor139" class="calibre6 pcalibre1 pcalibre"/>Setting up Snowpark Container Services</h1>
<p class="calibre3">In this section, we’ll lay down <a id="_idIndexMarker489" class="calibre6 pcalibre1 pcalibre"/>the groundwork necessary for exploring Snowpark Container Services. We will use Docker to create an OCI-compliant image to deploy to Snowpark. We’ll start by creating Snowflake objects.</p>
<h2 id="_idParaDest-136" class="calibre7"><a id="_idTextAnchor140" class="calibre6 pcalibre1 pcalibre"/>Creating Snowflake objects</h2>
<p class="calibre3">To create<a id="_idIndexMarker490" class="calibre6 pcalibre1 pcalibre"/> Snowflake objects, follow these steps in Snowsight with the <strong class="bold">ACCOUNTADMIN</strong> role:</p>
<ol class="calibre13">
<li class="calibre14">Create a role named <strong class="source-inline1">test_role</strong> using the following command. This role will be used for our Snowpark application:<pre class="source-code">
<strong class="bold1">USE ROLE ACCOUNTADMIN;</strong>
<strong class="bold1">CREATE ROLE test_role;</strong></pre><p class="calibre3">This will print the following output:</p></li> </ol>
<div><div><img alt="Figure 8.2 – A Snowflake role" src="img/B19923_08_2.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 8.2 – A Snowflake role</p>
<ol class="calibre13">
<li value="2" class="calibre14">Create a<a id="_idIndexMarker491" class="calibre6 pcalibre1 pcalibre"/> database and grant access to the database role by running the following command:<pre class="source-code">
<strong class="bold1">CREATE DATABASE IF NOT EXISTS SNOWPARK_DEFINITIVE_GUIDE;</strong>
<strong class="bold1">GRANT OWNERSHIP ON DATABASE SNOWPARK_DEFINITIVE_GUIDE</strong>
<strong class="bold1">  TO ROLE test_role COPY CURRENT GRANTS;</strong></pre><p class="calibre3">This will display the following output:</p></li> </ol>
<div><div><img alt="Figure 8.3 – Granting access" src="img/B19923_08_3.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 8.3 – Granting access</p>
<ol class="calibre13">
<li value="3" class="calibre14">We will be granting access to a warehouse for this role by executing the following command:<pre class="source-code">
<strong class="bold1">GRANT USAGE ON WAREHOUSE COMPUTE_WH TO ROLE test_role;</strong></pre></li> <li class="calibre14">Next, we will create a security integration for Snowflake services to access the resources securely by running the following command:<pre class="source-code">
<strong class="bold1">CREATE SECURITY INTEGRATION IF NOT EXISTS snowservices_ingress_oauth</strong>
<strong class="bold1">  TYPE=oauth</strong>
<strong class="bold1">  OAUTH_CLIENT=snowservices_ingress</strong>
<strong class="bold1">  ENABLED=true;</strong></pre><p class="calibre3">The output is as follows:</p></li> </ol>
<div><div><img alt="Figure 8.4 – Security integration" src="img/B19923_08_4.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 8.4 – Security integration</p>
<ol class="calibre13">
<li value="5" class="calibre14">Next, we<a id="_idIndexMarker492" class="calibre6 pcalibre1 pcalibre"/> will bind the service endpoint on the account to this role by running the following command. This allows access to the service endpoint from the public ingress:<pre class="source-code">
<strong class="bold1">GRANT BIND SERVICE ENDPOINT ON ACCOUNT TO ROLE test_role;</strong></pre><p class="calibre3">This will display the following output:</p></li> </ol>
<div><div><img alt="Figure 8.5 – Binding the service endpoint" src="img/B19923_08_5.0.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 8.5 – Binding the service endpoint</p>
<ol class="calibre13">
<li value="6" class="calibre14">Finally, we will create a compute pool and assign it to the role by running the following command:<pre class="source-code">
<strong class="bold1">CREATE COMPUTE POOL snowpark_cs_compute_pool</strong>
<strong class="bold1">MIN_NODES = 1</strong>
<strong class="bold1">MAX_NODES = 1</strong>
<strong class="bold1">INSTANCE_FAMILY = CPU_X64_XS;</strong>
<strong class="bold1">GRANT USAGE, MONITOR ON</strong>
<strong class="bold1">  COMPUTE POOL snowpark_cs_compute_pool TO ROLE test_role;</strong></pre><p class="calibre3">This will display the following output:</p></li> </ol>
<div><div><img alt="Figure 8.6 – A compute pool" src="img/B19923_08_6.0.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 8.6 – A compute pool</p>
<ol class="calibre13">
<li value="7" class="calibre14">We have <a id="_idIndexMarker493" class="calibre6 pcalibre1 pcalibre"/>now created a role, <strong class="source-inline1">test_role</strong>, and the necessary Snowflake objects we will use for the container services. Now, grant the role to the user you are logged into by running the following command:<pre class="source-code">
<strong class="bold1">GRANT ROLE test_role TO USER &lt;user_name&gt;;</strong></pre></li> <li class="calibre14">Now that we have the role configured and ready to use, let’s create the necessary database-scoped objects:<ul class="calibre18"><li class="calibre14">Select the database by running the following command:<pre class="source-code">
<strong class="bold1">USE DATABASE SNOWPARK_DEFINITIVE_GUIDE;</strong></pre></li><li class="calibre14">Create a schema named <strong class="source-inline1">MY_SCHEMA</strong> by running the following code:<pre class="source-code"><strong class="bold1">CREATE SCHEMA IF NOT EXISTS MY_SCHEMA;</strong></pre></li></ul></li> <li class="calibre14">Create an image repository that stores the container image by running the following command:<pre class="source-code">
<strong class="bold1">CREATE IMAGE REPOSITORY IF NOT EXISTS snowpark_cs_repository;</strong></pre><p class="calibre3">Once the image is created, you’ll see the following output:</p></li> </ol>
<div><div><img alt="Figure 8.7 – An image repository" src="img/B19923_08_7.0.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 8.7 – An image repository</p>
<ol class="calibre13">
<li value="10" class="calibre14">Finally, create <a id="_idIndexMarker494" class="calibre6 pcalibre1 pcalibre"/>a stage that is used to upload the files by running the following command:<pre class="source-code">
<strong class="bold1">CREATE STAGE IF NOT EXISTS snowpark_cs_stage</strong>
<strong class="bold1">  DIRECTORY = ( ENABLE = true );</strong></pre><p class="calibre3">You’ll see the following output:</p></li> </ol>
<div><div><img alt="Figure 8.8 – Stage creation" src="img/B19923_08_8.0.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 8.8 – Stage creation</p>
<p class="calibre3">We will be using the HuffPost dataset, which is available on Kaggle. The dataset is provided in our code repository. The dataset delineates approximately 200,000 headlines from 2012 through May 2018, with an additional 10,000 from May 2018 to 2022, reflecting adjustments in the website’s operational dynamics.</p>
<p class="calibre3">In the next section, we will set up the services.</p>
<h2 id="_idParaDest-137" class="calibre7"><a id="_idTextAnchor141" class="calibre6 pcalibre1 pcalibre"/>Setting up the services</h2>
<p class="calibre3"><strong class="bold">Flask</strong> is a<a id="_idIndexMarker495" class="calibre6 pcalibre1 pcalibre"/> lightweight <a id="_idIndexMarker496" class="calibre6 pcalibre1 pcalibre"/>web framework that allows developers to easily create web applications in Python. It is designed to be flexible, modular, and easy to use, making it a popular choice for building web applications of all sizes. Flask is particularly well-suited for building small to medium-sized web applications, as it provides just enough functionality to get the job done without adding unnecessary complexity.</p>
<p class="calibre3">Flask is used for a wide range of applications, including building web APIs, developing microservices, and creating simple web applications. Its flexibility and simplicity make it a popular choice for developers who want to quickly prototype and deploy web applications. Additionally, Flask <a id="_idIndexMarker497" class="calibre6 pcalibre1 pcalibre"/>can be easily extended with a variety of third-party libraries and tools, making it a powerful and versatile tool for building web applications in Python.</p>
<p class="calibre3">We will be utilizing Flask to write our service code that runs a persisting service to take HTTPS calls.</p>
<p class="callout-heading">Note on filter service</p>
<p class="callout">Filter service, which we are discussing in the next section, is just one simple example since our focus is more on explaining how to set up Snowpark Container Services rather than building a complex application. By following similar steps, any other use case can be developed.</p>
<h2 id="_idParaDest-138" class="calibre7"><a id="_idTextAnchor142" class="calibre6 pcalibre1 pcalibre"/>Setting up the filter service</h2>
<p class="calibre3">In this<a id="_idIndexMarker498" class="calibre6 pcalibre1 pcalibre"/> section, we<a id="_idIndexMarker499" class="calibre6 pcalibre1 pcalibre"/> will set up a service called <code>filter_service</code>, which filters the table based on a unique ID. We will perform the following steps to set up the service.</p>
<h3 class="calibre9">Service code</h3>
<p class="calibre3">You’ll find a<a id="_idIndexMarker500" class="calibre6 pcalibre1 pcalibre"/> Python application encompassing the code for crafting the filter service on the code repository. To initiate, download the provided zip file to a designated directory. Upon download completion, proceed to extract its contents. You’ll encounter a <code>service</code> directory containing the service code within the extracted files. The directory consists of the Docker file, <code>filter_service.py</code>, and the templates for the UI.</p>
<h3 class="calibre9">Filter Service in Python</h3>
<p class="calibre3">The <a id="_idIndexMarker501" class="calibre6 pcalibre1 pcalibre"/>following Python script includes the core logic of our service, encapsulating a minimalistic HTTP server based on Flask, and designed to filter the table based on input. It serves a dual purpose: handling filter requests from Snowflake service functions and furnishing a web UI for submitting filter requests.</p>
<pre class="source-code">
@app.post("/filter")
def udf_calling_function():
    message = request.json
    logger.debug(f'Received request: {message}')
    if message is None or not message['data']:
        logger.info('Received empty message')
        return {}
    unique_id = message['data']</pre> <p class="calibre3">The <a id="_idIndexMarker502" class="calibre6 pcalibre1 pcalibre"/>filter function facilitates communication between a Snowflake service function and the service. This function is adorned with the <code>@app.post()</code> decoration, signifying its capability to handle HTTP <code>POST</code> requests directed to the <code>/filter</code> path. Upon receiving such requests, the function processes and sends back the filter results encapsulated within the request body:</p>
<pre class="source-code">
def ui():
    '''
    Main handler for providing a web UI.
    '''
    if request.method == "POST":
        # Getting input in HTML form
        input_text = request.form.get("input")</pre> <p class="calibre3">The UI function segment orchestrates a web form presentation and manages filter requests submitted via the web form. Decorated with the <code>@app.route()</code> decorator, this function is designated to handle requests targeting the <code>/ui</code> path. Upon receiving an HTTP <code>GET</code> request for this path, the server delivers a simple HTML form prompting the user to input a string. Subsequently, upon form submission, an HTTP <code>POST</code> request is dispatched, and the server processes it, returning the original string encapsulated within an HTTP response:</p>
<pre class="source-code">
@app.get("/healthcheck")
def readiness_probe():
    return "I'm ready!"</pre> <p class="calibre3">The <code>readiness_probe</code> function, adorned with the <code>@app.get()</code> decorator, is primed to<a id="_idIndexMarker503" class="calibre6 pcalibre1 pcalibre"/> handle requests directed to <code>/healthcheck</code>. This function is pivotal for Snowflake to verify the service’s readiness. When Snowflake initiates a container, it dispatches an HTTP <code>GET</code> request to this path as a health probe, ensuring that only healthy containers handle incoming traffic. The function’s implementation is flexible, accommodating various actions to ascertain the service’s readiness.</p>
<p class="calibre3">Next, we will look at the Dockerfile in the directory.</p>
<h3 class="calibre9">The Dockerfile</h3>
<p class="calibre3">The Dockerfile <a id="_idIndexMarker504" class="calibre6 pcalibre1 pcalibre"/>serves as a blueprint for constructing an image using Docker. It includes directives on installing the Flask library within the Docker container. The Dockerfile consists of the following:</p>
<pre class="source-code">
ARG BASE_IMAGE=python:3.10-slim-buster
FROM $BASE_IMAGE
COPY filter_service.py ./
COPY templates/ ./templates/
RUN pip install --upgrade pip &amp;&amp; \
    pip install flask &amp;&amp; \
    pip install snowflake-snowpark-python[pandas]
CMD ["python3", "filter_service.py"]</pre> <p class="calibre3">The code within <code>filter_service.py</code> relies on Flask to efficiently handle HTTP requests.</p>
<p class="calibre3">Next, we will examine the UI templates.</p>
<h3 class="calibre9">UI templates</h3>
<p class="calibre3">The UI template<a id="_idIndexMarker505" class="calibre6 pcalibre1 pcalibre"/> files are located at <code>/template/basic_ui.html</code>. They render a web form for the filter service’s publicly exposed endpoint. This form is displayed when the public endpoint URL is loaded in a web browser with <code>/ui</code> appended. Users can input a string via this form, and upon submission, the service filters the table with submitted row given as string within an HTTP response.</p>
<p class="calibre3">In the next section, we will cover the service function.</p>
<h3 class="calibre9">The service function</h3>
<p class="calibre3">A service function serves<a id="_idIndexMarker506" class="calibre6 pcalibre1 pcalibre"/> as a conduit for communicating with your service. A <code>CREATE FUNCTION</code> command with specified parameters, such as the <code>filter_doc_udf</code> function:</p>
<pre class="console">
CREATE FUNCTION filter_doc_udf (InputText varchar)
  RETURNS varchar
  SERVICE=filter_service
  ENDPOINT=filterendpoint
  AS '/filter';</pre> <p class="calibre3">This function, for instance, accepts a string as input and returns a string, with the <code>SERVICE</code> property designating the service (<code>filter_service</code>) and the <code>ENDPOINT</code> property specifying the user-friendly endpoint name (<code>filterendpoint</code>). The <code>AS '/filter'</code> designation denotes the path for the service, tying it to the corresponding function within <code>filter_service.py</code>. Thus, invoking this function triggers Snowflake to dispatch a request to the designated path within the service container.</p>
<p class="calibre3">In the next section, we will build the Docker image.</p>
<h2 id="_idParaDest-139" class="calibre7"><a id="_idTextAnchor143" class="calibre6 pcalibre1 pcalibre"/>Building the Docker image</h2>
<p class="calibre3">In this section, we<a id="_idIndexMarker508" class="calibre6 pcalibre1 pcalibre"/> will construct the image using the Linux/AMD64 base, which is compatible with Snowpark, and dispatch it to your account’s image repository. To build the Docker image, perform the following steps:</p>
<ol class="calibre13">
<li class="calibre14">Obtain the repository URL by executing the following SQL command:<pre class="source-code">
<strong class="bold1">SHOW IMAGE REPOSITORIES;</strong></pre><p class="calibre3">This will display all the image repositories:</p></li> </ol>
<div><div><img alt="Figure 8.9 – The image repositories" src="img/B19923_08_9.0.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 8.9 – The image repositories</p>
<p class="calibre3">The <strong class="bold">repository_url</strong> column in the output furnishes the essential URL, and the hostname delineated in the repository URL denotes the registry hostname.</p>
<ol class="calibre13">
<li value="2" class="calibre14">The following commands require Docker Desktop to be installed in the system. You can install it from <a href="https://www.docker.com/products/docker-desktop/" class="calibre6 pcalibre1 pcalibre">https://www.docker.com/products/docker-desktop/</a> before proceeding with the commands. Next, in the local terminal window, switch to the <strong class="source-inline1">service</strong> directory containing the unzipped files and execute the subsequent <strong class="source-inline1">docker build</strong> command using the Docker CLI:<pre class="source-code">
<code>.</code>) as the path for building the latest image from the Docker file. The output will be as follows:</p></li> </ol>
<div><div><img alt="Figure 8.10 – The Docker build command" src="img/B19923_08_10.0.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 8.10 – The Docker build command</p>
<ol class="calibre13">
<li value="3" class="calibre14">Next, we’ll authenticate Docker with Snowflake. To authenticate Docker with the Snowflake registry, execute the following command:<pre class="source-code">
<strong class="bold1">docker login &lt;registry_hostname&gt; -u &lt;username&gt;</strong></pre><p class="calibre3">Specify your Snowflake username for the username parameter. Docker will prompt you for your password. Use the Snowflake password to authenticate:</p><div><img alt="Figure 8.11 – Repository login" src="img/B19923_08_11.0.jpg" class="calibre4"/></div></li> </ol>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 8.11 – Repository login</p>
<ol class="calibre13">
<li value="4" class="calibre14">Finally, upload the image to the Docker registry by executing the following command:<pre class="source-code">
<strong class="bold1">docker push &lt;orgname&gt;-&lt;acctname&gt;.registry.snowflakecomputing.com/snowpark_definitive_guide/my_schema/snowpark_cs_repository/my_filter_service_image:latest</strong></pre><p class="calibre3">You should see the following output:</p></li> </ol>
<div><div><img alt="Figure 8.12 – Repository push" src="img/B19923_08_12.0.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 8.12 – Repository push</p>
<p class="calibre3">The <a id="_idIndexMarker509" class="calibre6 pcalibre1 pcalibre"/>image is now available in the registry for deployment into Container Services.</p>
<p class="calibre3">In the next section, we will examine how to deploy the service, but it is always best practice to test your build locally before pushing it to the Snowflake repository. This part is not explained in this section as it is beyond the scope of this book.</p>
<h2 id="_idParaDest-140" class="calibre7"><a id="_idTextAnchor144" class="calibre6 pcalibre1 pcalibre"/>Deploying the service</h2>
<p class="calibre3">In this <a id="_idIndexMarker510" class="calibre6 pcalibre1 pcalibre"/>section, we’ll guide you through deploying the service and establishing a service function to facilitate communication with it. We will start by deploying the service, which requires the existing compute pool. Let’s start by checking the compute pool by running the following command:</p>
<pre class="console">
DESCRIBE COMPUTE POOL snowpark_cs_compute_pool;</pre> <div><div><img alt="Figure 8.13 – The compute pool" src="img/B19923_08_13.0.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 8.13 – The compute pool</p>
<p class="calibre3">If it’s in the <strong class="bold">STARTING</strong> state, you’ll need to wait until it transitions to <strong class="bold">ACTIVE</strong> or <strong class="bold">IDLE</strong>.</p>
<p class="calibre3">Now that the <a id="_idIndexMarker511" class="calibre6 pcalibre1 pcalibre"/>pool is active, we can create the service in the next section.</p>
<h3 class="calibre9">Creating the service</h3>
<p class="calibre3">We can <a id="_idIndexMarker512" class="calibre6 pcalibre1 pcalibre"/>create the service by running it using <code>test_role</code>. To do that, run the following command:</p>
<pre class="console">
USE ROLE test_role;
CREATE SERVICE filter_service
  IN COMPUTE POOL snowpark_cs_compute_pool
  FROM SPECIFICATION $$
    spec:
      containers:
      - name: filter
        image: /snowpark_definitive_guide/my_schema/snowpark_cs_repository/my_filter_service_image:latest
        env:
          SERVER_PORT: 8000
        readinessProbe:
          port: 8000
          path: /healthcheck
      endpoints:
      - name: filterendpoint
        port: 8000
        public: true
      $$
  MIN_INSTANCES=1
  MAX_INSTANCES=1;</pre> <p class="calibre3">We are using<a id="_idIndexMarker513" class="calibre6 pcalibre1 pcalibre"/> the image that we have built to deploy the service. The service should be created within Snowflake.</p>
<p class="calibre3">Once the service is created, you can execute the following SQL command to check its status:</p>
<pre class="console">
SELECT SYSTEM$GET_SERVICE_STATUS('filter_service');</pre> <p class="calibre3">The output should show that the service is running. The information about the service can be obtained by running the following command:</p>
<pre class="console">
DESCRIBE SERVICE filter_service;</pre> <p class="calibre3">This will display the details, as shown in the following screenshot:</p>
<div><div><img alt="Figure 8.14 – Service information" src="img/B19923_08_14.0.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 8.14 – Service information</p>
<p class="calibre3">In the next section, we will create the service function.</p>
<h3 class="calibre9">Creating a service function</h3>
<p class="calibre3">The service function<a id="_idIndexMarker514" class="calibre6 pcalibre1 pcalibre"/> performs the filter function and associates it with an endpoint. To create a service function, execute the following command:</p>
<pre class="console">
CREATE FUNCTION filter_doc_udf (InputText varchar)
RETURNS varchar
SERVICE=filter_service
ENDPOINT=filterendpoint
AS '/filter';</pre> <p class="calibre3">Here, the <code>SERVICE</code> property links the UDF with the <code>filter_service</code> service, while the <code>ENDPOINT</code> property associates it with the <code>filterendpoint</code> endpoint within the service. The <code>AS '/filter'</code> specification denotes the HTTP path leading to the filter server, which can be located within the service code.</p>
<p class="calibre3">Once the previous SQL statement is executed correctly, you can see the service function you created in Snowsight under <strong class="bold">Functions</strong>.</p>
<div><div><img alt="Figure 8.15 – The service function" src="img/B19923_08_15.0.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 8.15 – The service function</p>
<p class="calibre3">Now the function is ready to be executed.</p>
<h3 class="calibre9">Executing the function</h3>
<p class="calibre3">We will <a id="_idIndexMarker515" class="calibre6 pcalibre1 pcalibre"/>switch to the context we created earlier in the chapter by running the following command:</p>
<pre class="console">
USE ROLE test_role;
USE DATABASE SNOWPARK_DEFINITIVE_GUIDE;
USE SCHEMA MY_SCHEMA;
USE WAREHOUSE compute_wh;</pre> <p class="calibre3">You should get the following confirmation:</p>
<div><div><img alt="Figure 8.16 – Function execution" src="img/B19923_08_16.0.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 8.16 – Function execution</p>
<p class="calibre3">With the<a id="_idIndexMarker516" class="calibre6 pcalibre1 pcalibre"/> context set up, you can initiate communication with the filter service by invoking the service function within a query. To call the <code>filter_doc_udf</code> service function, execute the following <code>SELECT</code> statement, providing a sample input string (<code>'122880'</code>):</p>
<pre class="console">
SELECT filter_doc_udf('122880');</pre> <p class="calibre3">Upon executing this query, Snowflake dispatches a <code>POST</code> request to the service endpoint (<code>filterendpoint</code>). Upon receiving the request, the service utilizes the input string to filter the table for <code>UNIQUE_ID</code> and sends back the appropriate row in the response, as shown here:</p>
<div><div><img alt="Figure 8.17 – The filter function" src="img/B19923_08_17.0.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 8.17 – The filter function</p>
<p class="calibre3">The service exposes its endpoint publicly but still securely behind the Snowflake authentication mechanism, as specified in the inline specification provided within the <code>CREATE SERVICE</code> command. Consequently, you can access a web UI that the service exposes to the internet and send requests to the service from a web browser. To find the URL of the public endpoint the service exposes, execute the following command:</p>
<pre class="console">
SHOW ENDPOINTS IN SERVICE filter_service;</pre> <p class="calibre3">To access the web UI, append <code>/ui</code> to the endpoint URL and paste it into the web browser. This action triggers the execution of the <code>ui()</code> function specified in the <code>filter_service.py</code> script:</p>
<div><div><img alt="Figure 8.18 – The service UI" src="img/B19923_08_18.0.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 8.18 – The service UI</p>
<p class="calibre3">Please <a id="_idIndexMarker517" class="calibre6 pcalibre1 pcalibre"/>note that the first time you access the endpoint URL, you’ll be prompted to log in to Snowflake. Ensure you log in as the same user who created the service to guarantee you possess the necessary privileges.</p>
<p class="calibre3">We have successfully deployed the service and the components. In the next section, we will look at the service job.</p>
<h1 id="_idParaDest-141" class="calibre5"><a id="_idTextAnchor145" class="calibre6 pcalibre1 pcalibre"/>Setting up a Snowpark Container Service job</h1>
<p class="calibre3">In this section, we<a id="_idIndexMarker518" class="calibre6 pcalibre1 pcalibre"/> will create a simple job to connect to a Snowflake table and conduct some feature engineering tasks by generating new columns. Subsequently, we’ll save the resultant data to the same table within the Snowflake environment. Unlike services, jobs are short-lived, providing a one-time execution of tasks.</p>
<p class="calibre3">In the next section, we will set up the container job.</p>
<h2 id="_idParaDest-142" class="calibre7"><a id="_idTextAnchor146" class="calibre6 pcalibre1 pcalibre"/>Setting up the job</h2>
<p class="calibre3">For the job, instead of the Flask server implementation for services, we’ll utilize a straightforward <code>main.py</code> file to execute the job action. We will perform the following steps to set up the job.</p>
<h3 class="calibre9">Job code</h3>
<p class="calibre3">The code for <a id="_idIndexMarker519" class="calibre6 pcalibre1 pcalibre"/>this section is in our GitHub repository under the <code>chapter_8</code> folder. The folder contains the following files, which are required for the job.</p>
<h4 class="calibre16">The main.py file</h4>
<p class="calibre3">The <code>main.py</code> file is <a id="_idIndexMarker520" class="calibre6 pcalibre1 pcalibre"/>the core Python script for orchestrating the job’s execution. At its heart lies the following <code>run_job()</code> function, invoked when the script is executed. This function plays a pivotal role in reading environment variables and utilizing them to set default values for various parameters that are essential for connecting to Snowflake.</p>
<pre class="source-code">
def run_job():
    """
    Main body of this job.
    """
    logger = get_logger()
    logger.info("Job started")
    # Parse input arguments
    args = get_arg_parser().parse_args()
    table = args.table
    column = args.date_column</pre> <p class="calibre3">While Snowflake automatically populates some parameters when the image runs within its environment, explicit provision is required when testing the image locally. The <code>run_job()</code> function gets a table name and column to perform feature engineering from the spec.</p>
<h4 class="calibre16">The Dockerfile</h4>
<p class="calibre3">The Dockerfile <a id="_idIndexMarker521" class="calibre6 pcalibre1 pcalibre"/>encapsulates all the necessary commands required to build an image using Docker. This file resembles what we’ve previously implemented in our service section, ensuring consistency and coherence across different Snowpark Container Services environment components.</p>
<h4 class="calibre16">The job specification file</h4>
<p class="calibre3">The<a id="_idIndexMarker522" class="calibre6 pcalibre1 pcalibre"/> following job specification file provides Snowflake with essential container configuration information. Snowflake leverages the information provided in the <code>my_job_spec.yaml</code> specification file to configure and execute your job seamlessly. In addition to mandatory fields such as <code>container.name</code> and <code>container.image</code>, this specification file includes optional fields such as <code>container.args</code>, which list the arguments required for job execution.</p>
<pre class="source-code">
spec:
  container:
  - name: main
    image: /snowpark_definitive_guide/my_schema/snowpark_cs_repository/my_job_image:latest
    env:
      SNOWFLAKE_WAREHOUSE: compute_wh
    args:
    - "--table=NEWS_CATEGORY"
    - "--date_column=DATE"</pre> <p class="calibre3">Notably, the <code>--query</code> argument specifies the query to be executed when the job runs, while the <code>--result_table</code> argument identifies the table where the query results will be stored.</p>
<p class="calibre3">In the next section, we will deploy the job.</p>
<h2 id="_idParaDest-143" class="calibre7"><a id="_idTextAnchor147" class="calibre6 pcalibre1 pcalibre"/>Deploying the job</h2>
<p class="calibre3">To<a id="_idIndexMarker523" class="calibre6 pcalibre1 pcalibre"/> upload your job specification file (<code>my_job_spec.yaml</code>) into the Snowflake environment, you have a couple of options for uploading it to the designated stage:</p>
<ul class="calibre15">
<li class="calibre14"><strong class="bold">Snowsight web interface</strong>: Utilizing<a id="_idIndexMarker524" class="calibre6 pcalibre1 pcalibre"/> the Snowsight web interface offers a user-friendly approach to uploading your job specification file. Following the instructions we have covered in previous chapters, you can effortlessly navigate the process and ensure successful integration.</li>
<li class="calibre14"><strong class="bold">SnowSQL command-line interface (CLI)</strong>: Alternatively, you can use the SnowSQL CLI to <a id="_idIndexMarker525" class="calibre6 pcalibre1 pcalibre"/>execute the file upload process by executing the following <strong class="source-inline1">PUT</strong> command syntax:<pre class="source-code">
<code>PUT</code> command, detailed information regarding the uploaded file will be displayed in Snowsight:</p></li> </ul>
<div><div><img alt="Figure 8.19 – Job upload" src="img/B19923_08_19.0.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 8.19 – Job upload</p>
<p class="calibre3">Now that the job file has been uploaded, we will execute the job in the next section.</p>
<h2 id="_idParaDest-144" class="calibre7"><a id="_idTextAnchor148" class="calibre6 pcalibre1 pcalibre"/>Executing the job</h2>
<p class="calibre3">To kick off <a id="_idIndexMarker526" class="calibre6 pcalibre1 pcalibre"/>the execution of a job, you’ll utilize the <code>EXECUTE SERVICE</code> command, which acts as the catalyst for launching the specified task. Run the following command to trigger the job (this command may change since we are in private preview at the time of writing):</p>
<pre class="console">
EXECUTE SERVICE IN COMPUTE POOL snowpark_cs_compute_pool
  FROM @snowpark_cs_stage SPEC='my_job_spec.yaml';</pre> <p class="calibre3">Alternatively, you can use the following:</p>
<pre class="console">
EXECUTE JOB SERVICE
  IN COMPUTE POOL snowpark_cs_compute_pool
  NAME = test_job
  FROM @SNOWPARK_CS_STAGE
  SPECIFICATION_FILE='my_job_spec.yaml';</pre> <p class="calibre3">The specified compute pool, <code>snowpark_cs_compute_pool</code>, determines the allocation of computational resources necessary for the job’s successful execution. The <code>@snowpark_cs_stage</code> notation denotes the designated stage within Snowflake where the job specification file is stored, facilitating seamless access to the required configuration details. The <code>my_job_spec.yaml</code> file refers to the specific configuration file containing the instructions and parameters for executing the job seamlessly. Successful execution of the command should display the following output:</p>
<div><div><img alt="Figure 8.20 – Job execution" src="img/B19923_08_20.0.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 8.20 – Job execution</p>
<p class="calibre3">Upon execution, the job performs the specified SQL statement and saves the resultant data to a designated table, as outlined within the job specification file (<code>my_job_spec.yaml</code>). It’s crucial to note that the execution of the SQL statement does not <a id="_idIndexMarker527" class="calibre6 pcalibre1 pcalibre"/>occur within the Docker container itself. Instead, the container connects with Snowflake, leveraging a Snowflake warehouse to execute the SQL statement efficiently. The <code>EXECUTE SERVICE</code> command returns the<a id="_idIndexMarker528" class="calibre6 pcalibre1 pcalibre"/> output containing vital information, including the Snowflake-assigned <strong class="bold">UUID</strong> (short for <strong class="bold">Universally Unique Identifier</strong>) of the job. This UUID serves as a unique identifier for the executed job, aiding in tracking and monitoring its progress and status.</p>
<p class="calibre3">In the next section, we will deploy an LLM for Snowpark Container Services.</p>
<h1 id="_idParaDest-145" class="calibre5"><a id="_idTextAnchor149" class="calibre6 pcalibre1 pcalibre"/>Deploying LLMs with Snowpark</h1>
<p class="calibre3">Modern enterprises<a id="_idIndexMarker529" class="calibre6 pcalibre1 pcalibre"/> increasingly demand that LLMs be harnessed with proprietary data. Open source and proprietary models play pivotal roles in enabling this transition. However, the main challenge is finding a robust platform capable of effectively leveraging LLMs’ power. Snowflake empowers organizations to apply near-magical generative AI transformations to their data. By leveraging advanced LLM models within Snowflake, organizations can efficiently operate with large volumes of data, enabling generative AI use cases. In this section, we will discuss deploying LLM models within Snowpark Container Services.</p>
<p class="calibre3">In this walk-through, we’ll explore how to harness publicly accessible data to demonstrate the transformative capabilities of Snowflake’s ecosystem by deploying the Llama 2 LLM from the Hugging Face repository.</p>
<p class="callout-heading">Note</p>
<p class="callout">Llama 2 by Meta, housed within Hugging Face’s library, epitomizes advanced <strong class="bold">natural language processing</strong> (<strong class="bold">NLP</strong>) technology. As <a id="_idIndexMarker530" class="calibre6 pcalibre1 pcalibre"/>stipulated by Meta’s specific terms of service, you’ll need a Hugging Face token to access Llama 2 with Hugging Face. Please visit <a href="https://huggingface.co/docs/hub/en/security-tokens" class="calibre6 pcalibre1 pcalibre">https://huggingface.co/docs/hub/en/security-tokens</a> to learn more.</p>
<h2 id="_idParaDest-146" class="calibre7"><a id="_idTextAnchor150" class="calibre6 pcalibre1 pcalibre"/>Preparing the LLM</h2>
<p class="calibre3">We <a id="_idIndexMarker531" class="calibre6 pcalibre1 pcalibre"/>will start by preparing the LLM by utilizing our convenient wrapper around the Hugging Face Transformers API, and harness the capabilities of Llama 2 7B from Hugging Face. To achieve this, run the following code:</p>
<pre class="source-code">
HF_AUTH_TOKEN = " ************************* "
registry = model_registry.ModelRegistry(session=session, database_name="SNOWPARK_DEFINITIVE_GUIDE", schema_name="MY_SCHEMA", create_if_not_exists=True)
llama_model = huggingface_pipeline.HuggingFacePipelineModel(task="text-generation", model="meta-llama/Llama-2-7b-chat-hf", token=HF_AUTH_TOKEN, return_full_text=False, max_new_tokens=100)</pre> <p class="calibre3">Make sure to replace <code>HF_AUTH_TOKEN</code> with your token from Hugging Face. The code creates the model registry and assigns the model from the Hugging Face registry. The model is obtained from the Hugging Face registry and directly imported into Snowpark.</p>
<p class="calibre3">Next, we will register the model within Snowpark ML.</p>
<h2 id="_idParaDest-147" class="calibre7"><a id="_idTextAnchor151" class="calibre6 pcalibre1 pcalibre"/>Registering the model</h2>
<p class="calibre3">Next, we’ll utilize<a id="_idIndexMarker532" class="calibre6 pcalibre1 pcalibre"/> the model registry’s <code>log_model</code> API within Snowpark ML to register the model. This involves specifying a model name and a version string and providing the model obtained in the previous step:</p>
<pre class="source-code">
MODEL_NAME = "LLAMA2_MODEL_7b_CHAT"
MODEL_VERSION = "1"
llama_model=registry.log_model(
    model_name=MODEL_NAME,
    model_version=MODEL_VERSION,
    model=llama_model
)</pre> <p class="calibre3">You should see an output similar to the following:</p>
<div><div><img alt="Figure 8.21 – Model registration" src="img/B19923_08_21.0.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 8.21 – Model registration</p>
<p class="calibre3">The model<a id="_idIndexMarker533" class="calibre6 pcalibre1 pcalibre"/> is now registered in the registry. Now that the model is ready, we will deploy it to Container Services.</p>
<h2 id="_idParaDest-148" class="calibre7"><a id="_idTextAnchor152" class="calibre6 pcalibre1 pcalibre"/>Deploying the model to Snowpark Container Services</h2>
<p class="calibre3">Now, let <a id="_idIndexMarker534" class="calibre6 pcalibre1 pcalibre"/>us deploy the model to our designated compute pool. Once the deployment process is initiated, the model will become accessible as a Snowpark Container Services endpoint. Run the following code to deploy the model to Container Services. To run this step, you may need to alter your compute pool to include a GPU instance, or you can create a new compute pool with a GPU instance.</p>
<pre class="source-code">
llama_model.deploy(
  deployment_name="llama_predict",
  platform=deploy_platforms.TargetPlatform.SNOWPARK_CONTAINER_SERVICES,
  options={
            "compute_pool": "snowpark_cs_compute_pool",
            "num_gpus": 1
  },
)
"external_access_integrations": ["ALLOW_ALL_ACCESS_INTEGRATION"]</pre> <p class="calibre3">This streamlined deployment process highlights how Snowpark ML simplifies the deployment of LLMs, handling the creation of the corresponding Snowpark Container Services <code>SERVICE</code> definition, packaging the model within a Docker image along with its runtime dependencies, and launching the service within the specified compute pool.</p>
<p class="calibre3">After executing the code, you should see a similar output:</p>
<div><div><img alt="Figure 8.22 – Deploying the LLM model to Snowpark Container Services" src="img/B19923_08_22.0.jpg" class="calibre4"/>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US">Figure 8.22 – Deploying the LLM model to Snowpark Container Services</p>
<p class="calibre3">In the next section, we<a id="_idIndexMarker535" class="calibre6 pcalibre1 pcalibre"/> will execute this model in the container.</p>
<p class="callout-heading">Note on model deployment</p>
<p class="callout">Only the snippets required for explanation are shown in this section. The complete code is available in the <strong class="source-inline1">chapter_8.ipynb</strong> notebook in GitHub. You should be mindful of the model deployment step as it takes considerable time and resources.</p>
<h2 id="_idParaDest-149" class="calibre7"><a id="_idTextAnchor153" class="calibre6 pcalibre1 pcalibre"/>Running the model</h2>
<p class="calibre3">Invoke the model by<a id="_idIndexMarker536" class="calibre6 pcalibre1 pcalibre"/> supplying the subset of the <code>NEWS_CATEGORY</code> table with the <code>inputs</code> column containing the prompt:</p>
<pre class="source-code">
res = llama_model_ref.predict( deployment_name=DEPLOYMENT_NAME, data=input_df )</pre> <p class="calibre3">This yields a Snowpark DataFrame with an output column containing the model’s response for each row. The raw response intersperses text with the expected JSON output, exemplified as follows:</p>
<pre class="source-code">
{
  "category": "Art",
  "keywords": [
    "Gertrude",
    "contemporary art",
    "democratization",
    "demystification"
  ],
  "importance": 9
}</pre> <p class="calibre3">Deploying and <a id="_idIndexMarker537" class="calibre6 pcalibre1 pcalibre"/>executing an LLM model is very easy with Snowpark Container Services.</p>
<p class="calibre3">We will conclude the chapter with a summary.</p>
<h1 id="_idParaDest-150" class="calibre5"><a id="_idTextAnchor154" class="calibre6 pcalibre1 pcalibre"/>Summary</h1>
<p class="calibre3">In this chapter, we explored Snowpark Container Services, a powerful solution designed to simplify the deployment and management of containerized applications within the Snowflake ecosystem. We discussed the distinction between jobs and services within Snowpark Container Services, highlighting their respective functionalities and use cases. We demonstrated how to effectively configure, deploy, and manage jobs and services through practical implementation examples.</p>
<p class="calibre3">Additionally, we delved into containerization through Snowpark ML, showcasing how Snowflake users can seamlessly leverage advanced ML models within their environment. By integrating a language model from Hugging Face, we illustrated how Snowpark ML facilitates the integration of containerized models, enabling sophisticated NLP tasks directly within Snowflake. Overall, this chapter equips you with the knowledge and tools to harness the transformative potential of SCS and Snowpark ML in your data-driven initiatives.</p>
<p class="calibre3">In conclusion, Snowpark Container Services offers a compelling value proposition for businesses seeking efficient and scalable data processing solutions. By enabling secure execution of containerized workloads directly within Snowflake, Snowpark eliminates the need for data movement, ensuring data integrity and reducing latency. Additionally, Snowpark simplifies the development and deployment of data applications, allowing teams to focus on innovation rather than infrastructure management. Automated container management further streamlines operational tasks, enhancing overall productivity and agility.</p>
<p class="calibre3">With this, we conclude the book. Thank you for reading.</p>
</div>
</body></html>