- en: Chapter 3. Learning Logistic Regression / SGD Using Mahout
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Instead of jumping directly into logistic regression, let''s try to understand
    a few of its concepts. In this chapter, we will explore the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Introducing regression
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding linear regression
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cost function
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gradient descent
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logistic regression
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding SGD
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Mahout for logistic regression
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introducing regression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Regression analysis is used for prediction and forecasting. It is used to find
    out the relationship between explanatory variables and target variables. Essentially,
    it is a statistical model that is used to find out the relationship among variables
    present in the datasets. An example that you can refer to for a better understanding
    of this term is this: determine the earnings of workers in a particular industry.
    Here, we will try to find out the factors that affect a worker''s salary. These
    factors can be age, education, years of experience, particular skill set, location,
    and so on. We will try to make a model that will take all these variables into
    consideration and try to predict the salary. In regression analysis, we characterize
    the variation of the target variable around the regression function, which can
    be described by a probability distribution that is also of interest. There are
    a number of regression analysis techniques that are available. For example, linear
    regression, ordinary least squares regression, logistic regression, and so on.'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding linear regression
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In linear regression, we create a model to predict the value of a target variable
    with the help of an explanatory variable. To understand this better, let's look
    at an example.
  prefs: []
  type: TYPE_NORMAL
- en: 'A company X that deals in selling coffee has noticed that in the month of monsoon,
    their sales increased to quite an extent. So they have come up with a formula
    to find the relation between rain and their per cup coffee sale, which is shown
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '*C = 1.5R+800*'
  prefs: []
  type: TYPE_NORMAL
- en: So, for 2 mm of rain, there is a demand of 803 cups of coffee. Now if you go
    into minute details, you will realize that we have the data for rainfall and per
    cup coffee sale, and we are trying to build a model that can predict the demand
    for coffee based on the rainfall. We have data in the form of *(R1, C1), (R2,
    C2)…. (Ri, Ci)*. Here, we will build the model in a manner that keeps the error
    in the actual and predicted values at a minimum.
  prefs: []
  type: TYPE_NORMAL
- en: Cost function
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the equation *C = 1.5R+800*, the two values 1.5 and 800 are parameters and
    these values affect the end result. We can write this equation as *C= p0+p1R*.
    As we discussed earlier, our goal is to reduce the difference between the actual
    value and the predicted value, and this is dependent on the values of *p0* and
    *p1*. Let's assume that the predicted value is *Cp* and the actual value is *C*
    so that the difference will be *(Cp-C)*. This can be written as *(p0+p1R-C)*.To
    minimize this error, we define the error function, which is also called the **cost
    function**.
  prefs: []
  type: TYPE_NORMAL
- en: 'The cost function can be defined with the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Cost function](img/4959OS_03_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Here, **i** is the ith sample and **N** is the number of training examples.
    We calculate costs for different sets of **p0** and **p1** and finally select
    the **p0** and **p1** that gives the least cost (*C*). This is the model that
    will be used to make predictions for new input.
  prefs: []
  type: TYPE_NORMAL
- en: Gradient descent
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Gradient descent starts with an initial set of parameter values, *p0* and *p1*,
    and iteratively moves towards a set of parameter values that minimizes the cost
    function. We can visualize this error function graphically, where width and length
    can be considered as the parameters *p0* and *p1* and height as the cost function.
    Our goal is to find the values for *p0* and *p1* in a way that our cost function
    will be minimal. We start the algorithm with some values of *p0* and *p1* and
    iteratively work towards the minimum value. A good way to ensure that the gradient
    descent is working correctly is to make sure that the cost function decreases
    for each iteration. In this case, the cost function surface is convex and we will
    try to find out the minimum value. This can be seen in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Gradient descent](img/4959OS_03_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Logistic regression
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Logistic regression is used to ascertain the probability of an event. Generally,
    logistic regression refers to problems where the outcome is binary, for example,
    in building a model that is based on a customer's income, travel uses, gender,
    and other features to predict whether he or she will buy a particular car or not.
    So, the answer will be a simple yes or no. When the outcome is composed of more
    than one category, this is called **multinomial logistic regression**.
  prefs: []
  type: TYPE_NORMAL
- en: 'Logistic regression is based on the **sigmoid function**. Predictor variables
    are combined with linear weight and then passed to this function, which generates
    the output in the range of 0–1\. An output close to 1 indicates that an item belongs
    to a certain class. Let''s first understand the sigmoid or logistic function.
    It can be defined by the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '*F (z) = 1/1+e (-z)*'
  prefs: []
  type: TYPE_NORMAL
- en: 'With a single explanatory variable, *z* will be defined as *z = β0 + β1*x*.
    This equation is explained as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**z**: This is called the dependent variable. This is the variable that we
    would like to predict. During the creation of the model, we have this variable
    with us in the training set, and we build the model to predict this variable.
    The known values of z are called observed values.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**x**: This is the explanatory or independent variable. These variables are
    used to predict the dependent variable z. For example, to predict the sales of
    a newly launched product at a particular location, we might include explanatory
    variables such as the price of the product, the average income of the people of
    that location, and so on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**β0**: This is called the regression intercept. If all explanatory variables
    are zero, then this parameter is equal to the dependent variable z.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**β1**: These are values for each explanatory variable.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The graph of the logistic function is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Logistic regression](img/4959OS_03_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'With a little bit of mathematics, we can change this equation as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '*ln(F(x)/(1-F(x)) = β0 + β1*x*'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the case of linear regression, the cost function graph was convex, but here,
    it is not going to be convex. Finding the minimum values for parameters in a way
    that our predicted output is close to the actual one will be difficult. In a cost
    function, while calculating for logistic regression, we will replace our *Cp*
    value of linear regression with the function *F(z)*. To make convex logistic regression
    cost functions, we will replace *(p0+p1Ri-Ci)2* with one of the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '*log (1/1+e (-(β0 + β1*x)))* if the actual occurrence of an event is 1, this
    function will represent the cost.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*log (1-(1/1+e (-(β0 + β1*x))))* if the actual occurrence of an event is 0,
    this function will represent the cost.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will have to remember that in logistic regression, we calculate the class
    probability. So, if the probability of an event occurring (customer buying a car,
    being defrauded, and so on ) is *p*, the probability of non-occurrence is *1-p*.
  prefs: []
  type: TYPE_NORMAL
- en: Stochastic Gradient Descent
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Gradient descent minimizes the cost function. For very large datasets, gradient
    descent is a very expensive procedure. Stochastic Gradient Descent (SGD) is a
    modification of the gradient descent algorithm to handle large datasets. Gradient
    descent computes the gradient using the whole dataset, while SGD computes the
    gradient using a single sample. So, gradient descent loads the full dataset and
    tries to find out the local minimum on the graph and then repeat the full process
    again, while SGD adjusts the cost function for every sample, one by one. A major
    advantage that SGD has over gradient descent is that its speed of computation
    is a whole lot faster. Large datasets in RAM generally cannot be held as the storage
    is limited. In SGD, the burden on the RAM is reduced, wherein each sample or batch
    of samples are loaded and worked with, the results for which are stored, and so
    on.
  prefs: []
  type: TYPE_NORMAL
- en: Using Mahout for logistic regression
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Mahout has implementations for logistic regression using SGD. It is very easy
    to understand and use. So let's get started.
  prefs: []
  type: TYPE_NORMAL
- en: '**Dataset**'
  prefs: []
  type: TYPE_NORMAL
- en: We will use the **Wisconsin Diagnostic Breast Cancer** (**WDBC**) dataset. This
    is a dataset for breast cancer tumors and data is available from 1995 onwards.
    It has 569 instances of breast tumor cases and has 30 features to predict the
    diagnosis, which is categorized as either benign or malignant.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: More details on the preceding dataset is available at [http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.names](http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.names).
  prefs: []
  type: TYPE_NORMAL
- en: '**Preparing the training and test data**'
  prefs: []
  type: TYPE_NORMAL
- en: You can download the `wdbc.data` dataset from [http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data](http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data).
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, save it as a CSV file and include the following header line:'
  prefs: []
  type: TYPE_NORMAL
- en: '`ID_Number,Diagnosis,Radius,Texture,Perimeter,Area,Smoothness,Compactness,Concavity,ConcavePoints,Symmetry,Fractal_Dimension,RadiusStdError,TextureStdError,PerimeterStdError,AreaStdError,SmoothnessStdError,CompactnessStdError,ConcavityStdError,ConcavePointStdError,Symmetrystderror,FractalDimensionStderror,WorstRadius,worsttexture,worstperimeter,worstarea,worstsmoothness,worstcompactness,worstconcavity,worstconcavepoints,worstsymmentry,worstfractaldimensions`'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we will have to perform the following steps to prepare this data to be
    used by the Mahout logistic regression algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will make the target class numeric. In this case, the second field diagnosis
    is the target variable. We will change malignant to 0 and benign to 1\. Use the
    following code snippet to introduce the changes. We can use this strategy for
    small datasets, but for huge datasets, we have different strategies, which we
    will cover in [Chapter 4](ch04.html "Chapter 4. Learning the Naïve Bayes Classification
    Using Mahout"), *Learning the Naïve Bayes Classification Using Mahout*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Tip
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Downloading the example code**'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You can download the example code files from your account at [http://www.packtpub.com](http://www.packtpub.com)
    for all the Packt Publishing books you have purchased. If you purchased this book
    elsewhere, you can visit [http://www.packtpub.com/support](http://www.packtpub.com/support)
    and register to have the files e-mailed directly to you.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We will have to split the dataset into training and test datasets and then
    shuffle the datasets so that we can mix them up, which can be done using the following
    code snippet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '**Training the model**'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use the training dataset and trainlogistic algorithm to prepare the
    model. Use the following command to create the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'This command will give you the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Using Mahout for logistic regression](img/4959OS_03_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s understand the parameters used in this command:'
  prefs: []
  type: TYPE_NORMAL
- en: '`trainlogistic`: This is the algorithm that Mahout provides to build the model
    using your input parameters.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`input`: This is the location of the input file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output`: This is the location of the model file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`target`: This is the name of the target variable that we want to predict from
    the dataset.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`categories`: This refers to the number of predicted classes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`predictors`: This features in the dataset used to predict the target variable.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`types`: This is a list of the types of predictor variables. (Here all are
    numeric but it could be word or text as well.)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`features`: This is the size of the feature vector used to build the model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`passes`: This specifies the number of times the input data should be re-examined
    during training. Small input files may need to be examined dozens of times. Very
    large input files probably don''t even need to be completely examined.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`rate`: This sets the initial learning rate. This can be large if you have
    lots of data or use lots of passes because it decreases progressively as data
    is examined.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now our model is ready to move on to the next step of evaluation. To evaluate
    the model further, we can use the same dataset and check the confusion and AUC
    matrix. The command for this will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '`runlogistic`: This is the algorithm to run the logistic regression model over
    an input dataset'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`model`: This is the location of the model file'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`auc`: This prints the AUC score for the model versus the input data after
    the data is read'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`confusion`: This prints the confusion matrix for a particular threshold'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The output of the previous command is shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Using Mahout for logistic regression](img/4959OS_03_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Now, these matrices show that the model is not bad. Having 0.88 as the value
    for AUC is good, but we will check this on test data as well. The confusion matrix
    informs us that out of 172 malignant tumors, it has correctly classified 151 instances
    and that 34 benign tumors are also classified as malignant. In the case of benign
    tumors, out of 298, it has correctly classified 264.
  prefs: []
  type: TYPE_NORMAL
- en: If the model does not provide good results, we have a number of options.
  prefs: []
  type: TYPE_NORMAL
- en: Change the parameters in the feature vector, increasing them if we are selecting
    few features. This should be done one at a time, and we should test the result
    again with each generated model. We should get a model where AUC is close to 1.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s run the same algorithm on test data as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '![Using Mahout for logistic regression](img/4959OS_03_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: So this model works almost the same on test data as well. It has classified
    34 out of the 40 malignant tumors correctly.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we discussed logistic regression and how we can use this algorithm
    available in Apache Mahout. We used the Wisconsin Diagnostic Breast Cancer dataset
    and randomly broke it into two datasets: one for training and the other for testing.
    We created the logistic regression model using Mahout and also ran test data over
    this model. Now, we will move on to the next chapter where you will learn about
    the Naïve Bayes classification and also the most frequently used classification
    technique: text classification.'
  prefs: []
  type: TYPE_NORMAL
