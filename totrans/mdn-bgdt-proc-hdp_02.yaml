- en: Hadoop Life Cycle Management
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will understand the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Data wrangling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data masking
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data security
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data wrangling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you have some experience working on data of some sort, you will recollect
    that most of the time data needs to be preprocessed so that we can further use
    it as part of a bigger analysis. This process is called **data wrangling**.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see what the typical flow in this process looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: Data acquisition
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data structure analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Information extraction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unwanted data removal
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data transformation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data standardization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's try to understand these in detail.
  prefs: []
  type: TYPE_NORMAL
- en: Data acquisition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Even though not a part of data wrangling, this phase deals with the process
    of acquiring data from somewhere. Typically, all data is generated and stored
    in a central location or is available in files located on some shared storage.
  prefs: []
  type: TYPE_NORMAL
- en: Having an understanding of this step helps us to build an interface or use existing
    libraries to pull data from the acquired data source location.
  prefs: []
  type: TYPE_NORMAL
- en: Data structure analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Once data is acquired, we have to understand the structure of the data. Remember
    that the data we are getting can be in any of the following forms:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Text data:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Structured data
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Unstructured data
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Binary data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is where we need certain tools to help us understand the structure of the
    data.
  prefs: []
  type: TYPE_NORMAL
- en: Once we have a thorough understanding of the data we are dealing with, the next
    task is to understand the bits and pieces we need to extract from this structure.
    Sometimes, depending on the complexity and size of the data we are dealing with,
    it might take time for us to really find and extract the information we are looking
    for.
  prefs: []
  type: TYPE_NORMAL
- en: Once we know what we are looking for and also have a solid understanding of
    the structure of the data, it becomes easier for us to come up with simple algorithms
    to extract the required information from the input data.
  prefs: []
  type: TYPE_NORMAL
- en: Information extraction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this phase, we are interested in extracting the necessary details from the
    input data. In the previous phase, we already identified the necessary pieces
    that are of interest to us. Here is where we can adopt the following techniques
    for information extraction:'
  prefs: []
  type: TYPE_NORMAL
- en: Identify and locate where the text is present
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Analyze and come up with the best method of information extraction:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Tokenize and extract information
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Go to offset and extract information
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Regular expression-based information extraction
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Complex algorithm-based information extraction
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Depending on the complexity of the data, we might have to adopt one or more
    of the aforementioned techniques to extract the information from the target data.
  prefs: []
  type: TYPE_NORMAL
- en: Unwanted data removal
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This phase can occur before the information extraction step or after the information
    extraction step. It depends on which one is easier (shortening the text or the
    extraction of information). This is a design choice the analyst can make.
  prefs: []
  type: TYPE_NORMAL
- en: In this phase, we are removing unwanted data from the information or input data
    so that the data is further distilled and can easily be consumed for our business
    needs.
  prefs: []
  type: TYPE_NORMAL
- en: Data transformation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This is also a very important phase, where we enforce the standards defined
    by the enterprise to define the final data output. For example, an organization
    can suggest that all the country codes should be in ISO 3166-1 alpha-2 format.
    In order to adhere to this standard, we might have to transform the input data,
    which can contain countries with their full names. So a mapping and transformation
    has to be done.
  prefs: []
  type: TYPE_NORMAL
- en: Many other transformations can be performed on the input data to make the final
    data consumable by anyone in the organization in a well-defined form and as per
    the organizations standards.
  prefs: []
  type: TYPE_NORMAL
- en: This step also gives some importance to having an enterprise level standard
    to improve collaboration.
  prefs: []
  type: TYPE_NORMAL
- en: Data standardization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once the information extraction is complete and any necessary cleanup is done,
    we need to decide how we are going to save the outcome of this process. Typically,
    we can use a simple **CSV** (**comma separated value**) format for this data.
    If we are dealing with a complicated output format, we can choose **XML** (**Extensible
    Markup Language**) or **JSON** (**javascript object notation**) formats.
  prefs: []
  type: TYPE_NORMAL
- en: These formats are very much standard and almost all the technologies that we
    have today understand these very easily. But to keep things simple at first, it's
    good to start with CSV format.
  prefs: []
  type: TYPE_NORMAL
- en: Data masking
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Businesses that deal with customer data have to make sure that the **PII** (**personally
    identifiable information**) of these customers is not moving freely around the
    entire data pipeline. This criterion is applicable not only to customer data but
    also to any other type of data that is considered classified, as per standards
    such as GDPR, SOX, and so on. In order to make sure that we protect the privacy
    of customers, employees, contractors, and vendors, we need to take the necessary
    precautions to ensure that when the data goes through several pipelines, users
    of the data see only anonymized data. The level of anonymization we do depends
    upon the standards the company adheres to and also the prevailing country standards.
  prefs: []
  type: TYPE_NORMAL
- en: So, data masking can be called the process of hiding/transforming portions of
    original data with other data without losing the meaning or context.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, we will understand various techniques that are available to
    accomplish this:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Substitution:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Static
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dynamic:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Encryption
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Hashing
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Hiding
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Erasing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Truncation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Variance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shuffling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Substitution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Substitution is the process of replacing portions of data with computed data.
    It can be mathematically be defined as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c470b3b9-8183-41c9-b435-60a02375f6f7.png)'
  prefs: []
  type: TYPE_IMG
- en: Where *x* is the source and *y* is the output from this function.
  prefs: []
  type: TYPE_NORMAL
- en: In order to choose the correct substitution mechanism, we need to understand
    how this data is going to be used, the target audience, and the data flow environment
    as well. Let's look at the various available substitution mechanisms.
  prefs: []
  type: TYPE_NORMAL
- en: Static
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this method, we have a Lookup table; it consists of all possible substitutions
    for a given set of inputs. This Lookup table can be visualized like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Source Text (y)** | **Substituted Text (y)** |'
  prefs: []
  type: TYPE_TB
- en: '| Steve Jobs | AAPL-1 |'
  prefs: []
  type: TYPE_TB
- en: '| Cat | 123456789 |'
  prefs: []
  type: TYPE_TB
- en: '| Tennis | Cricket |'
  prefs: []
  type: TYPE_TB
- en: This table illustrates how a Lookup table can be constructed for substituting
    source text with a different text. This method scales well when there is a predefined
    quantity of substitutions available.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another example of this Lookup table-based substitution is when we follow a
    naming standard for country codes, for example, ISO-8661:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Source Text (x)** | **Substituted Text (y)** |'
  prefs: []
  type: TYPE_TB
- en: '| Egypt | EG |'
  prefs: []
  type: TYPE_TB
- en: '| India | IN |'
  prefs: []
  type: TYPE_TB
- en: '| Saint Vincent and Grenadines | VN |'
  prefs: []
  type: TYPE_TB
- en: '| United Kingdom | GB |'
  prefs: []
  type: TYPE_TB
- en: '| United States of America | US |'
  prefs: []
  type: TYPE_TB
- en: Dynamic
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: These substitution techniques are useful when there are a large number of possibilities
    and we want to change the data using some algorithms. These methods can be classified
    into two types.
  prefs: []
  type: TYPE_NORMAL
- en: Encryption
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This is the process of changing a given text to some other form by using some
    form of secret. These are mathematically defined functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9891878e-37f3-416b-b943-034b45a84acb.png)'
  prefs: []
  type: TYPE_IMG
- en: 'As you can see, these functions take an input and a secret and generate data
    that can be decrypted using the same secret and the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/38b93fdb-fc83-4469-9583-b27b217d37b4.png)'
  prefs: []
  type: TYPE_IMG
- en: If we observe carefully, it is the secret that is playing an important role
    here. In cryptography, there are two types of algorithms that are available based
    on this secret. The usage of these depends on the situation and the secret transportation
    challenges.
  prefs: []
  type: TYPE_NORMAL
- en: 'Without going too deep into cryptography, let''s try to understand what these
    methods are:'
  prefs: []
  type: TYPE_NORMAL
- en: Symmetric key encryption
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Asymmetric key encryption
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The basic difference between the two is that in the first one, we use the same
    secret for both encryption and decryption. But in the latter, we use two different
    keys for encryption and decryption.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at a few examples of symmetric key encryption in action:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Algorithm** | **Input Data** | **Output Data** | **Method** |'
  prefs: []
  type: TYPE_TB
- en: '| ROT13 | `hello` | `uryyb` | Encryption |'
  prefs: []
  type: TYPE_TB
- en: '|  | `uryyb` | `hello` | Decryption |'
  prefs: []
  type: TYPE_TB
- en: '| DES | `hello` | `yOYffF4rl8lxCQ4HS2fpMg==` | Encryption (secret is `hello`)
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | `yOYffF4rl8lxCQ4HS2fpMg==` | `hello` | Decryption (secret is `hello`)
    |'
  prefs: []
  type: TYPE_TB
- en: '| RIJNDAEL-256 | `hello` | `v8QbYPszQX/TFeYKbSfPL/` `rNJDywBIQKtxzOzWhBm16/`'
  prefs: []
  type: TYPE_NORMAL
- en: '`VSNN4EtlgZi3/`'
  prefs: []
  type: TYPE_NORMAL
- en: '`iPqJZpCiXXzDu0sKmKSl6IxbBKhYw==` | Encryption (secret is `hello`) |'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | `v8QbYPszQX/TFeYKbSfPL/` `rNJDywBIQKtxzOzWhBm16/`'
  prefs: []
  type: TYPE_NORMAL
- en: '`VSNN4EtlgZi3/`'
  prefs: []
  type: TYPE_NORMAL
- en: '`iPqJZpCiXXzDu0sKmKSl6IxbBKhYw==` | `hello` | Encryption (secret is `hello`)
    |'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, the data that is generated varies in both complexity and length
    depending on the encryption algorithm we use. It also depends on the secret key
    that is used for encryption.
  prefs: []
  type: TYPE_NORMAL
- en: Encryption poses a challenge of more computational requirements and storage
    space. We need to plan our system accordingly if we want to use encryption as
    one of the methods in the masking process.
  prefs: []
  type: TYPE_NORMAL
- en: Hashing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This is also a cryptography-based technique where the original data is converted
    to an irreversible form. Let''s see the mathematical form for this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/70ba8a6e-dc2c-42bd-b83f-28678beefdfb.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, unlike in the case of encryption, we cannot use the output to discover
    what the input is.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see a few examples to understand this better:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Input** | **Output** | **Method** |'
  prefs: []
  type: TYPE_TB
- en: '| `10-point` | `7d862a9dc7b743737e39dd0ea3522e9f` | MD5 |'
  prefs: []
  type: TYPE_TB
- en: '| `10th` | `8d9407b7f819b7f25b9cfab0fe20d5b3` | MD5 |'
  prefs: []
  type: TYPE_TB
- en: '| `10-point` | `c10154e1bdb6ea88e5c424ee63185d2c1541efe1bc3d4656a4c3c99122ba9256`
    | SHA256 |'
  prefs: []
  type: TYPE_TB
- en: '| `10th` | `5b6e8e1fcd052d6a73f3f0f99ced4bd54b5b22fd4f13892eaa3013ca65f4e2b5`
    | SHA256 |'
  prefs: []
  type: TYPE_TB
- en: We can see that depending upon the encryption algorithm we have used, the output
    size varies. Another thing to note is that a given hash function produces the
    same output size irrespective of the input size.
  prefs: []
  type: TYPE_NORMAL
- en: Hiding
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this approach, the data is considered too sensitive even to reveal it to
    the original owners. So, to protect the confidentiality of the data, certain portions
    of the text are masked with a predefined character, say X (or anything), so that
    only the person with complete knowledge about those pieces can extract the necessary
    information.
  prefs: []
  type: TYPE_NORMAL
- en: '**Examples**: Credit card information is considered highly confidential and
    should never be revealed to anyone. If you have some experience of purchasing
    online on websites such as Amazon and so on, you would have seen that your full
    credit card information is not shown; only the last four digits are shown. Since
    I am the genuine owner of such a credit card, I can easily identify it and continue
    with the transaction.'
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, when there is a need for portions of data to be seen by analysts,
    it's important to mask significant pieces of it so that the end users will not
    get the complete picture but will use this data at the same time for any analysis
    that they are doing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see a few examples to understand this better:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Data type** | **Input** | **Output** | **Network** |'
  prefs: []
  type: TYPE_TB
- en: '| Creditcard | 4485 **4769 3682** 9843 | 4485 **XXXX XXXX** 9843 | Visa |'
  prefs: []
  type: TYPE_TB
- en: '| Creditcard | 5402 **1324 5087** 3314 | 5402 **XXXX XXXX** 3314 | Mastercard
    |'
  prefs: []
  type: TYPE_TB
- en: '| Creditcard | 3772 **951960** 72673 | 3772 **XXXXXX** 72673 | American Express
    |'
  prefs: []
  type: TYPE_TB
- en: In the preceding examples, these numbers follow a predefined algorithm and size.
    So a simple technique of masking digits at fixed locations can work better.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take up another example of hiding out portions of email addresses which
    vary in both size and complexity. In this case we have to follow different techniques
    to hide the characters to not reveal complete information:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Data type** | **Input** | **Output** | **Method** |'
  prefs: []
  type: TYPE_TB
- en: '| Email | `hello@world.com` | `h.l.o@w.r.d.com` | Even Hide |'
  prefs: []
  type: TYPE_TB
- en: '|  | `simple@book.com` | `.i.p.e@.o.k.c.m` | Odd Hide |'
  prefs: []
  type: TYPE_TB
- en: '|  | `something@something.com` | `s...th.ng@..me...com` | Complex Hide |'
  prefs: []
  type: TYPE_TB
- en: 'The techniques can be as simple as:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Even Hide**: In this technique, we hide the every character that is in the
    even position'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Odd Hide**: We hide every odd character in the input data'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Complex Hide**: In this technique, we understand the data we are dealing
    with using NLP and then try to apply an algorithm that doesn''t reveal too much
    information that would allow any intelligent person to decode'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Erasing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As the name suggests, this causes data loss when applied to the input data.
    Depending on the significance of the data we are dealing with, we need to apply
    this technique. Typical examples of this technique is to set a `NULL` value for
    all the records in a column. Since this null data cannot be used to infer anything
    that is meaningful, this technique helps in making sure that confidential data
    is not sent to the other phases of data processing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take few examples of erasing:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Input Data** | **Output Data** | **What''s erased** |'
  prefs: []
  type: TYPE_TB
- en: '| NULL earns 1000 INR per month | Ravi earns NULL per month | Salary and name
    |'
  prefs: []
  type: TYPE_TB
- en: '| NULL mobile number is 0123456789 | Ravi''s mobile number is NULL | Mobile
    number and name |'
  prefs: []
  type: TYPE_TB
- en: 'From the examples, you might be wondering: why do we nullify these values?
    This technique is useful when we are not really interested in the PII but interested
    in a summary of how many salary records or mobile number records are there in
    our database/input.'
  prefs: []
  type: TYPE_NORMAL
- en: This concept can be extended to other use cases as well.
  prefs: []
  type: TYPE_NORMAL
- en: Truncation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Another variant of erasing is truncation, where we make all the input data a
    uniform size. This is useful when we are pretty sure that information loss is
    accepted in the further processing of the pipelines.
  prefs: []
  type: TYPE_NORMAL
- en: 'This can also be an intelligent truncation where we are aware of the data we
    are dealing with. Let''s see this example of email addresses:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Input** | **Output** | **What''s truncated** |'
  prefs: []
  type: TYPE_TB
- en: '| `alice@localhost.com` | `alice` | `@localhost.com` |'
  prefs: []
  type: TYPE_TB
- en: '| `bob@localhost.com` | `bob` | `@localhost.com` |'
  prefs: []
  type: TYPE_TB
- en: '| `rob@localhost.com` | `rob` | `@localhost.com` |'
  prefs: []
  type: TYPE_TB
- en: From the preceding examples, we can see that all the domain portions from the
    email are truncated as all of them belong to the same domain. This technique saves
    storage space.
  prefs: []
  type: TYPE_NORMAL
- en: Variance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This technique is useful for data types that are numeric in nature. It can also
    be applied to Date/Time values.
  prefs: []
  type: TYPE_NORMAL
- en: This follows a statistical approach where we try to algorithmically vary the
    input data by a factor of +/- X percent. The value of X purely depends on the
    analysis we are doing and shouldn’t have an overall impact on understanding the
    business figures.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see a few examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Input Data** | **Output Data** | **Method** | **Explanation** |'
  prefs: []
  type: TYPE_TB
- en: '| 100 | 110 | Fixed variance | Increase by 10% |'
  prefs: []
  type: TYPE_TB
- en: '| -100 | 90 | Fixed variance | Decrease by 10% |'
  prefs: []
  type: TYPE_TB
- en: '| 1-Jan-2000 | 1-Feb-2000 | Fixed variance | Add 1 month |'
  prefs: []
  type: TYPE_TB
- en: '| 1-Aug-2000 | 1-Jul-2000 | Fixed variance | Reduce by 1 month |'
  prefs: []
  type: TYPE_TB
- en: '| 100 | 101 | Dynamic variance | 1% to 5% increase or decrease |'
  prefs: []
  type: TYPE_TB
- en: '| 100 | 105 | Dynamic | 1% to 5% increase or decrease |'
  prefs: []
  type: TYPE_TB
- en: Shuffling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This is also considered one of the standard techniques of achieving anonymity
    of data. This process is more applicable where we have records of data with several
    attributes (columns in database terminology). In this technique, the data in the
    records is shuffled around a column so as to make sure that the record-level information
    is changed. But statistically, the data value remains the same in that column.
  prefs: []
  type: TYPE_NORMAL
- en: '**Example**: When doing an analysis on the salary ranges of an organization,
    we can actually do a shuffle of the entire salary column, where the salaries of
    all the employees never match reality. But we can use this data to do an analysis
    on the ranges.'
  prefs: []
  type: TYPE_NORMAL
- en: Complex methods can also be employed in this case, where we can do a shuffle
    based on other fields such as seniority, geography, and so on. The ultimate objective
    of this technique is to preserve the meaning of the data and, at the same time,
    make it impossible to discover the original owners of these attributes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see this with some example data:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/652dfb7b-645d-4f3e-9723-81b5c6a68dc7.png)'
  prefs: []
  type: TYPE_IMG
- en: There are five sample employee records with their salary information. The top
    table has original salary details and the table below has shuffled salary records.
    Look at the data carefully and you will understand. Remember that while shuffling,
    a random algorithm can be applied to increase the complexity of discovering the
    truth.
  prefs: []
  type: TYPE_NORMAL
- en: Data security
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Data has become a very important asset for businesses when making very critical
    decisions. As the complexity of the infrastructure that generates and uses this
    data, its very important to have some control over the access patterns of this
    data. In the Hadoop ecosystem, we have Apache Ranger, which is another open source
    project that helps in managing the security of big data.
  prefs: []
  type: TYPE_NORMAL
- en: What is Apache Ranger?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Apache Ranger is an application that enables data architects to implement security
    policies on a big data ecosystem. The goal of this project is to provide a unified
    way for all Hadoop applications to adhere to the security guidelines that are
    defined.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some of the features of Apache Ranger:'
  prefs: []
  type: TYPE_NORMAL
- en: Centralized administration
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fine grained authorization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Standardized authorization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multiple authorization methods
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Centralized auditing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Apache Ranger installation using Ambari
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will install Ranger using Apache Ambari. This section assumes
    that there is already a running Ambari instance.
  prefs: []
  type: TYPE_NORMAL
- en: Ambari admin UI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Open the Ambari web interface running on master node; then click on Add Service,
    as shown in the screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/688e0308-9b80-4fd8-87a0-9c9240265967.png)'
  prefs: []
  type: TYPE_IMG
- en: This will open a modal window, Add Service Wizard, which will take us through
    several steps for a complete installation of Apache Ambari.
  prefs: []
  type: TYPE_NORMAL
- en: Add service
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once the modal window is in view, select the Apache Ranger service from the
    list and click on Next on the screen.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2be2832c-2753-4d1d-814c-5d4c8a883777.png)'
  prefs: []
  type: TYPE_IMG
- en: Service placement
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once the service is selected, we are presented the next step in the UI where
    we need to chose the servers on which this service is going to be installed and
    run.
  prefs: []
  type: TYPE_NORMAL
- en: 'I have selected node-3 for Ranger (see the green labels):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/87b67475-da9f-4b66-a0f9-6182ebf9b456.png)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot showing how to choose servers on which this services is going to
    be installed and run
  prefs: []
  type: TYPE_NORMAL
- en: After this, select Next, which is at the bottom of the page.
  prefs: []
  type: TYPE_NORMAL
- en: Service client placement
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this step, we can choose where the clients for this service can be installed.
    Use the checkboxes to mark your preferences.
  prefs: []
  type: TYPE_NORMAL
- en: 'They look something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/65982a2c-18c6-4bd3-9665-fe8f2374398d.png)'
  prefs: []
  type: TYPE_IMG
- en: Click on Next when your choices are made.
  prefs: []
  type: TYPE_NORMAL
- en: Database creation on master
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We have installed the MySQL database server on the master node. Before we continue
    to the next step in the Ambari wizard, we have to create a new database and assign
    a few privileges:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bfe9ba4f-aeca-4c63-b308-b9ce5518efe0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We also have to register the JDBC driver using the `ambari-server setup` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: After this step, we can go back to the Ambari wizard.
  prefs: []
  type: TYPE_NORMAL
- en: Ranger database configuration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the wizard, we are prompted with the database name, username, and password.
    Please fill them according to the choices we made in the previous step:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/fbc737cb-de1e-4504-b1c5-54eb414da55b.png)'
  prefs: []
  type: TYPE_IMG
- en: Once the settings are added, please click on Test Connection. This will save
    lot of time later.
  prefs: []
  type: TYPE_NORMAL
- en: If there are any errors, please go back to the previous step; see whether there
    are any spelling mistakes and rerun those.
  prefs: []
  type: TYPE_NORMAL
- en: Click on Next when done with the changes.
  prefs: []
  type: TYPE_NORMAL
- en: Configuration changes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Since we are adding Ranger a service, Ambari shows a list of configuration changes
    that are required for Ranger to work correctly. Mostly leave these on default.
  prefs: []
  type: TYPE_NORMAL
- en: 'These changes look like the following screenshot. Once the changes look good,
    click on OK to continue:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2c1fa6d2-5325-419e-8540-7c7215002dec.png)'
  prefs: []
  type: TYPE_IMG
- en: Configuration review
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this step, we are shown the list of changes that we have made so far in the
    wizard, and are shown choices to print a changes summary and deploy Ranger.
  prefs: []
  type: TYPE_NORMAL
- en: Only when we click on Deploy will the Ranger software get installed. Until then,
    it is all kept in the browser cache.
  prefs: []
  type: TYPE_NORMAL
- en: 'The screen looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5ffb2278-f6c4-4dd6-b8a8-35c2e512af9c.png)'
  prefs: []
  type: TYPE_IMG
- en: Deployment progress
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Once the installation of Ranger starts, it should look something like the one
    in the screenshot. There should not be any failures as we have set up all the
    configurations correctly. If there is any failure, check the logs and review the
    configuration by clicking on the Back button:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/dd1a49f5-1b3c-47b2-aeb4-fc93c599e8c7.png)'
  prefs: []
  type: TYPE_IMG
- en: Application restart
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Once the deployment is complete, we need to restart all the affected Hadoop
    components, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/faa744da-eb8f-4af1-98e2-e1698c0d0d7a.png)'
  prefs: []
  type: TYPE_IMG
- en: Once all the components are restarted, the Ambari dashboard looks pretty healthy
    and we are done with the Apache Ranger installation.
  prefs: []
  type: TYPE_NORMAL
- en: In the next step, we will see how to use Apache Ranger for handling our data
    security.
  prefs: []
  type: TYPE_NORMAL
- en: Apache Ranger user guide
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once the deployment of Apache Ranger is complete, we can manage our entire Hadoop
    infrastructure security using the web interface provided by Apache Ranger.
  prefs: []
  type: TYPE_NORMAL
- en: Login to UI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you have not changed the default settings, Ranger runs on port `6080` by
    default in non-SSL Mode. Open up a web browser on the server where its installed
    on port `6080` (`http://<server-ip>:6080`) and you will be prompted with a screen
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3475861b-dcd2-49b7-a19f-3b8f96b964eb.png)'
  prefs: []
  type: TYPE_IMG
- en: Log in with the default username `admin` and password `admin` (please change
    the password after you log in for the first time, for security reasons).
  prefs: []
  type: TYPE_NORMAL
- en: Once the login is successful, we are taken to the *Access manager* section.
  prefs: []
  type: TYPE_NORMAL
- en: Access manager
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Access manager lets us define policies based on services and tags. This screenshot
    shows the default list of services and the configured policies:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c8e951c5-5dc0-493b-a140-bc425ed0a609.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, there is already a policy defined for HDFS service and KAFKA
    service as they are already installed in the Ambari setup.
  prefs: []
  type: TYPE_NORMAL
- en: When we want to define a new service, we can click on the + icon and define
    the service details.
  prefs: []
  type: TYPE_NORMAL
- en: Service details
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before we start defining the authorization rules for the service, we need to
    define a service and then add authorization policies to the service. These are
    the mandatory properties which are needed to define a service from the UI:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **UI Element name** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| Service Name | Name of the service as defined in agent configuration |'
  prefs: []
  type: TYPE_TB
- en: '| Username | Name of the service user |'
  prefs: []
  type: TYPE_TB
- en: '| Password | Password for the service user |'
  prefs: []
  type: TYPE_TB
- en: '| Namenode URL | URL to the namenode |'
  prefs: []
  type: TYPE_TB
- en: A new service can be defined by clicking on the + icon below the application
    (for example, `HDFS`, `Kafka`, and so on)
  prefs: []
  type: TYPE_NORMAL
- en: 'After that, the service definition screen looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/58f05368-f783-4656-83a1-21cf9fdcea1e.png)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot of the service definition screen after defining new services
  prefs: []
  type: TYPE_NORMAL
- en: We need to fill in all the necessary values for our service definition and hit
    save. Later, we need to add policies to this service to access enforcement and
    auditing.
  prefs: []
  type: TYPE_NORMAL
- en: Policy definition and auditing for HDFS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For every service in Ranger, we can associate different policies to the resources
    in the service. In case of HDFS, the resources will be the file/directory paths.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will define a new policy for an HDFS path called projects
    for three users: `hdfs-alice`, `hdfs-bob`, and `hdfs-tom`. Where only `hdfs-alice`
    is allowed all permissions and rest of the users have only read access.
  prefs: []
  type: TYPE_NORMAL
- en: We will see how Ranger enforces access restrictions once the policy is in place.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see the screen for the policy creation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e5aa0907-08ff-4ed9-87c2-d1ab9cca6a94.png)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot showing how Ranger enforces access restrictions
  prefs: []
  type: TYPE_NORMAL
- en: Once we hit the Add button, this policy is registered and added under the current
    service.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's get back to the Unix terminal and see how Ranger enforces the policies.
  prefs: []
  type: TYPE_NORMAL
- en: 'This screen shows how `hdfs` and `hdfs-alice` users are allowed to create directories
    `/projects` and `/projects/1`, but how this is denied for `hdfs-tom`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/45c42baf-d515-49e0-8d9c-b93f6498473a.png)'
  prefs: []
  type: TYPE_IMG
- en: Apache Ranger also has an audit section in the web interface, where we can see
    these access patterns.
  prefs: []
  type: TYPE_NORMAL
- en: 'This screen shows that `hdfs-tom` is denied and `hdfs-alice` is granted access
    by the policy:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/eeb6ddc0-5791-44e6-ad9a-3ea16271fbb3.png)'
  prefs: []
  type: TYPE_IMG
- en: Screenshot showing access denied to hdfs-tom and access granted to hdfs-alice
    by the policy
  prefs: []
  type: TYPE_NORMAL
- en: Like this, we can define our own policies and customize how `hdfs` should allow/deny
    access to several resources.
  prefs: []
  type: TYPE_NORMAL
- en: The power and flexibility of Ranger comes from the its configurability. There
    is no need for any configuration files and restarts of applications for the access
    control to play a significant role.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned about the different data life cycle stages, including
    when data is created, shared, maintained, archived, retained, and deleted.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter gave you a detailed understanding of how big data is managed, considering
    the fact that it is either unstructured or semi-structured and it has a fast arrival
    rate and large volume.
  prefs: []
  type: TYPE_NORMAL
- en: As the complexity of the infrastructure that generates and uses data in business
    organizations has increased drastically, it has become imperative to secure your
    data properly. This chapter further covered data security tools, such as Apache
    Ranger, and patterns to help us learn how to have control over the access patterns
    of data.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will take a look at Hadoop installation, its architecture
    and key components.
  prefs: []
  type: TYPE_NORMAL
