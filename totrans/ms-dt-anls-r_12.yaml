- en: Chapter 12. Analyzing Time-series
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A time-series is a sequence of data points ordered in time, often used in economics
    or, for example, in social sciences. The great advantage of collecting data over
    a long period of time compared to cross-sectional observations is that we can
    analyze the collected values of the exact same object over time instead of comparing
    different observations.
  prefs: []
  type: TYPE_NORMAL
- en: 'This special characteristic of the data requires new methods and data structures
    for time-series analysis. We will cover these in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: First, we learn how to load or transform observations into time-series objects
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then we visualize them and try to improve the plots by smoothing and filtering
    the observations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Besides seasonal decomposition, we introduce forecasting methods based on time-series
    models, and we also cover methods to identify outliers, extreme values, and anomalies
    in time-series
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating time-series objects
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Most tutorials on time-series analysis start with the `ts` function of the `stats`
    package, which can create time-series objects in a very straightforward way. Simply
    pass a vector or matrix of numeric values (time-series analysis mostly deals with
    continuous variables), specify the frequency of your data, and it's all set!
  prefs: []
  type: TYPE_NORMAL
- en: The frequency refers to the natural time-span of the data. Thus, for monthly
    data, you should set it to 12, 4 for quarterly and 365 or 7 for daily data, depending
    on the most characteristic seasonality of the events. For example, if your data
    has a significant weekly seasonality, which is pretty usual in social sciences,
    it should be 7, but if the calendar date is the main differentiator, such as with
    weather data, it should be 365.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the forthcoming pages, let''s use daily summary statistics from the `hflights`
    dataset. First let''s load the related dataset and transform it to `data.table`
    for easy aggregation. We also have to create a date variable from the provided
    `Year`, `Month`, and `DayofMonth` columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let''s compute the number of flights and the overall sum of arrival delays,
    number of cancelled flights and the average distance of the related flights for
    each day in 2011:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Visualizing time-series
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This is in a very familiar data structure: 365 rows for each day in 2011 and
    five columns to store the four metrics for the dates stored in the first variable.
    Let''s transform that to a time-series object and plot it right away:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '![Visualizing time-series](img/2028OS_12_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: It was easy, right? We have just plotted several independent time-series on
    a line chart. But what's shown on the first plot? The *x* axis is indexed from
    1 to 365 because `ts` did not automatically identify that the first column stores
    our dates. On the other hand, we find the date transformed to timestamps on the
    *y* axis. Shouldn't the points form a linear line?
  prefs: []
  type: TYPE_NORMAL
- en: 'This is one of the beauties of data visualization: a simple plot revealed a
    major issue with our data. It seems we have to sort the data by date:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '![Visualizing time-series](img/2028OS_12_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Much better! Now that the values are in the right order, we can focus on the
    actual time-series data one by one at a time. First let''s see how the number
    of flights looked from the first day of 2011 with a daily frequency:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '![Visualizing time-series](img/2028OS_12_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Seasonal decomposition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Well, it looks like the number of flights fluctuates a lot on weekdays, which
    is indeed a dominant characteristic of human-related activities. Let's verify
    that by identifying and removing the weekly seasonality by decomposing this time-series
    into the seasonal, trend, and random components with moving averages.
  prefs: []
  type: TYPE_NORMAL
- en: 'Although this can be done manually by utilizing the `diff` and `lag` functions,
    there''s a much more straightforward way to do so with the `decompose` function
    from the `stats` package:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '![Seasonal decomposition](img/2028OS_12_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Removing the spikes in the means of weekly seasonality reveals the overall trend
    of the number of flights in 2011\. As the *x* axis shows the number of weeks since
    January 1 (based on the frequency being 7), the peak interval between 25 and 35
    refers to the summertime, and the lowest number of flights happened on the 46th
    week – probably due to Thanksgiving Day.
  prefs: []
  type: TYPE_NORMAL
- en: 'But the weekly seasonality is probably more interesting. Well, it''s pretty
    hard to spot anything on the preceding plot as the very same 7-day repetition
    can be seen 52 times on the seasonal plot. So, instead, let''s extract that data
    and show it in a table with the appropriate headers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: So the seasonal effects (the preceding numbers representing the relative distance
    from the average) suggest that the greatest number of flights happened on Monday
    and the last two weekdays, while there is only a relatively small number of flights
    on Saturdays.
  prefs: []
  type: TYPE_NORMAL
- en: 'Unfortunately, we cannot decompose the yearly seasonal component of this time-series,
    as we have data only for one year, and we need data for at least two time periods
    for the given frequency:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: For more advanced seasonal decomposition, see the `stl` function of the `stats`
    package, which uses polynomial regression models on the time-series data. The
    next section will cover some of this background.
  prefs: []
  type: TYPE_NORMAL
- en: Holt-Winters filtering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We can similarly remove the seasonal effects of a time-series by Holt-Winters
    filtering. Setting the `beta` parameter of the `HoltWinters` function to `FALSE`
    will result in a model with exponential smoothing practically suppressing all
    the outliers; setting the `gamma` argument to `FALSE` will result in a non-seasonal
    model. A quick example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '![Holt-Winters filtering](img/2028OS_12_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The red line represents the filtered time-series. We can also fit a double
    or triple exponential model on the time-series by enabling the `beta` and `gamma`
    parameters, resulting in a far better fit:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '![Holt-Winters filtering](img/2028OS_12_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'As this model provides extremely similar values compared to our original data,
    it can be used to predict future values as well. For this end, we will use the
    `forecast` package. By default, the `forecast` function returns a prediction for
    the forthcoming 2*frequency values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'These are estimates for the first two weeks of 2012, where (besides the exact
    point predictions) we get the confidence intervals as well. Probably it''s more
    meaningful at this time to visualize these predictions and confidence intervals:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '![Holt-Winters filtering](img/2028OS_12_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The blue points shows the estimates for the 31 future time periods and the gray
    area around that covers the confidence intervals returned by the `forecast` function.
  prefs: []
  type: TYPE_NORMAL
- en: Autoregressive Integrated Moving Average models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We can achieve similar results with **Autoregressive Integrated Moving Average**
    (**ARIMA**) models. To predict future values of a time-series, we usually have
    to *stationarize* it first, which means that the data has a constant mean, variance,
    and autocorrelation over time. In the past two sections, we used seasonal decomposition
    and the Holt-Winters filter to achieve this. Now let's see how the generalized
    version of the **Autoregressive Moving Average** (**ARMA**) model can help with
    this data transformation.
  prefs: []
  type: TYPE_NORMAL
- en: '*ARIMA(p, d, q)* actually includes three models with three non-negative integer
    parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '*p* refers to the autoregressive part of the model'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*d* refers to the integrated part'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*q* refers to the moving average parts'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As ARIMA also includes an integrated (differencing) part over ARMA, it can deal
    with non-stationary time-series as well, as they naturally become stationary after
    differencing—in other words, when the *d* parameter is larger than zero.
  prefs: []
  type: TYPE_NORMAL
- en: 'Traditionally, choosing the best ARIMA model for a time-series is required
    to build multiple models with a variety of parameters and compare model fits.
    On the other hand, the `forecast` package comes with a very useful function that
    can select the best fitting ARIMA model for a time-series by running unit root
    tests and minimizing the **maximum-likelihood** (**ML**) and the **Akaike Information
    Criterion** (**AIC**) of the models:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'It seems that the *AR(3)* model has the highest AIC with *AR(2)* seasonal effects.
    But checking the manual of `auto.arima` reveals that the information criteria
    used for the model selection were approximated due to the large number (more than
    100) of observations. Re-running the algorithm and disabling approximation returns
    a different model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Although it seems that the preceding seasonal ARIMA model fits the data with
    a high AIC, we might want to build a real ARIMA model by specifying the *D* argument
    resulting in an integrated model via the following estimates:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '![Autoregressive Integrated Moving Average models](img/2028OS_12_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Although time-series analysis can sometimes be tricky (and finding the optimal
    model with the appropriate parameters requires a reasonable experience with these
    statistical methods), the preceding short examples proved that even a basic understanding
    of the time-series objects and related methods will usually provide some impressive
    results on the patterns of data and adequate predictions.
  prefs: []
  type: TYPE_NORMAL
- en: Outlier detection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Besides forecasting, another time-series related major task is identifying
    suspicious or abnormal data in a series of observations that might distort the
    results of our analysis. One way to do so is to build an ARIMA model and analyze
    the distance between the predicted and actual values. The `tsoutliers` package
    provides a very convenient way to do so. Let''s build a model on the number of
    cancelled flights in 2011:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'So now we can use an *ARIMA(1,1,2)* model and the `tso` function to highlight
    (and optionally remove) the outliers from our dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Please note that the following `tso` call can run for several minutes with a
    full load on a CPU core as it may be performing heavy computations in the background.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '![Outlier detection](img/2028OS_12_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Alternatively, we can run all the preceding steps in one go by automatically
    calling `auto.arima` inside `tso` without specifying any extra arguments besides
    the time-series object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Anyway, the results show that all observations with a high number of cancelled
    flights are outliers and so should be removed from the dataset. Well, considering
    any day with many cancelled flights as outlier sounds really optimistic! But this
    is very useful information; it suggests that, for example, forecasting an outlier
    event is not manageable with the previously discussed methods.
  prefs: []
  type: TYPE_NORMAL
- en: Traditionally, time-series analysis deals with trends and seasonality of data,
    and how to *stationarize* the time-series. If we are interested in deviations
    from normal events, some other methods need to be used.
  prefs: []
  type: TYPE_NORMAL
- en: Twitter recently published one of its R packages to detect anomalies in time-series.
    Now we will use its `AnomalyDetection` package to identify the preceding outliers
    in a much faster way. As you may have noticed, the `tso` function was really slow
    to run, and it cannot really handle large amount of data – while the `AnomalyDetection`
    package performs pretty well.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can provide the input data as a vector of a `data.frame` with the first
    column storing the timestamps. Unfortunately, the `AnomalyDetectionTs` function
    does not really work well with `data.table` objects, so let''s revert to the traditional
    `data.frame` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let''s load the package and plot the anomalies identified among the observations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '![Outlier detection](img/2028OS_12_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The results are very similar to the previous plots, but there are two things
    to note that you might have already noticed. The computation was extremely quick
    and, on the other hand, this plot includes human-friendly dates instead of some
    lame indexes on the *x* axis.
  prefs: []
  type: TYPE_NORMAL
- en: More complex time-series objects
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The main limitation of the `ts` time-series R object class (besides the aforementioned
    *x* axis issue) is that it cannot deal with irregular time-series. To overcome
    this problem, we have several alternatives in R.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `zoo` package and its reverse dependent `xts` packages are `ts`-compatible
    classes with tons of extremely useful methods. For a quick example, let''s build
    a `zoo` object from our data, and see how it''s represented by the default plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '![More complex time-series objects](img/2028OS_12_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: As we have defined the `date` column to act as the timestamp of the observations,
    it's not shown here. The *x* axis has a nice human-friendly date annotation, which
    is really pleasant after having checked a bunch of integer-annotated plots in
    the previous pages.
  prefs: []
  type: TYPE_NORMAL
- en: 'Of course, `zoo` supports most of the `ts` methods, such as `diff`, `lag` or
    cumulative sums; these can be very useful for visualizing data velocity:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '![More complex time-series objects](img/2028OS_12_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Here, the linear line for the **N** variable suggests that we do not have any
    missing values and our dataset includes exactly one data point per day. On the
    other hand, the steep elevation of the **Cancelled** line in February highlights
    that a single day contributed a lot to the overall number of cancelled flights
    in 2011.
  prefs: []
  type: TYPE_NORMAL
- en: Advanced time-series analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Unfortunately, this short chapter cannot provide a more detailed introduction
    to time-series analysis. To be honest, even two or three times the length of this
    chapter would not be enough for a decent tutorial, as time-series analysis, forecasting,
    and anomaly detection are one of the most complex topics of statistical analysis.
  prefs: []
  type: TYPE_NORMAL
- en: But the good news is that there are plenty of great books on the topics! One
    of the best resources—and the ultimate free online tutorial on this subject—can
    be found at [https://www.otexts.org/fpp](https://www.otexts.org/fpp). This is
    a really practical and detailed online tutorial on forecasting and general time-series
    analysis, and I heartily recommend it to anyone who would like to build more complex
    and realizable time-series models in the future.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter focused on how to load, visualize, and model time-related data.
    Although we could not cover all aspects of this challenging topic, we discussed
    the most widely used smoothing and filtering algorithms, seasonal decompositions,
    and ARIMA models; we also computed some forecasts and estimates based on these.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next chapter is somewhat similar to this one, as we will cover another
    domain-independent area on another important dimension of datasets: instead of
    when, we will focus on *where* the observations were captured.'
  prefs: []
  type: TYPE_NORMAL
