- en: Chapter 9. From Big to Small Data
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第9章. 从大数据到小数据
- en: 'Now that we have some cleansed data ready for analysis, let''s first see how
    we can find our way around the high number of variables in our dataset. This chapter
    will introduce some statistical techniques to reduce the number of variables by
    dimension reduction and feature extraction, such as:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有一些准备好的清洁数据用于分析，让我们首先看看我们如何在我们数据集中的大量变量中找到我们的方向。本章将介绍一些统计技术，通过降维和特征提取来减少变量的数量，例如：
- en: '**Principal** **Component Analysis** (**PCA**)'
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**主成分分析**（**PCA**）'
- en: '**Factor** **Analysis** (**FA**)'
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**因子分析**（**FA**）'
- en: '**Multidimensional Scaling** (**MDS**) and a few other techniques'
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多维尺度分析**（**MDS**）和其他一些技术'
- en: Note
  id: totrans-5
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'Most dimension reduction methods require that two or more numeric variables
    in the dataset are highly associated or correlated, so the columns in our matrix
    are not totally independent of each other. In such a situation, the goal of dimension
    reduction is to decrease the number of columns in the dataset to the actual matrix
    rank; or, in other words, the number of variables can be decreased whilst most
    of the information content can be retained. In linear algebra, the matrix rank
    refers to the dimensions of the vector space generated by the matrix—or, in simpler
    terms, the number of independent columns and rows in a quadratic matrix. Probably
    it''s easier to understand rank by a quick example: imagine a dataset on students
    where we know the gender, the age, and the date of birth of respondents. This
    data is redundant as the age can be computed (via a linear transformation) from
    the date of birth. Similarly, the year variable is static (without any variability)
    in the `hflights` dataset, and the elapsed time can be also computed by the departure
    and arrival times.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数降维方法都需要数据集中的两个或多个数值变量高度相关或相关，因此我们矩阵中的列并不是完全相互独立的。在这种情况下，降维的目标是将数据集中的列数减少到实际的矩阵秩；或者换句话说，变量的数量可以减少，同时保留大部分信息内容。在线性代数中，矩阵秩指的是由矩阵生成的向量空间的维度——或者说，在二次矩阵中独立列和行的数量。可能通过一个简单的例子更容易理解秩：想象一个关于学生的数据集，其中我们知道受访者的性别、年龄和出生日期。这些数据是冗余的，因为年龄可以通过线性变换从出生日期计算出来。同样，`hflights`数据集中的年份变量是静态的（没有任何变化），并且可以通过出发和到达时间计算经过的时间。
- en: These transformations basically concentrate on the common variance identified
    among the variables and exclude the remaining total (unique) variance. This results
    in a dataset with fewer columns, which is probably easier to maintain and process,
    but at the cost of some information loss and the creation of artificial variables,
    which are usually harder to comprehend compared to the original columns.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 这些变换基本上集中在变量之间识别出的共同方差上，并排除了剩余的总（独特）方差。这导致数据集的列数减少，这可能更容易维护和处理，但代价是损失一些信息，并创建一些人工变量，这些变量通常比原始列更难以理解。
- en: In the case of perfect dependence, all but one of the perfectly correlated variables
    can be omitted, as the rest provide no additional information about the dataset.
    Although it does not happen often, in most cases it's still totally acceptable
    to keep only one or a few components extracted from a set of questions, for example
    in a survey for further analysis.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在完全依赖的情况下，除了一个完全相关的变量外，其他所有完全相关的变量都可以省略，因为其余的变量没有提供关于数据集的额外信息。尽管这种情况并不常见，但在大多数情况下，只保留从一组问题中提取的一个或几个成分，例如在调查中用于进一步分析，是完全可接受的。
- en: Adequacy tests
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 充分性检验
- en: The first thing you want to do, when thinking about reducing the number of dimensions
    or looking for latent variables in the dataset with multivariate statistical analysis,
    is to check whether the variables are correlated and the data is normally distributed.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 当你考虑通过多元统计分析减少数据集中的维度或寻找潜在变量时，首先想做的事情是检查变量是否相关，数据是否呈正态分布。
- en: Normality
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 正态性
- en: The latter is often not a strict requirement. For example, the results of a
    PCA can be still valid and interpreted if we do not have multivariate normality;
    on the other hand, maximum likelihood factor analysis does have this strong assumption.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 后者通常不是一个严格的要求。例如，如果我们没有多元正态性，PCA的结果仍然可能是有效的，并且可以解释；另一方面，最大似然因子分析确实有这个强烈的假设。
- en: Tip
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: You should always use the appropriate methods to achieve your data analysis
    goals, based on the characteristics of your data.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该始终根据你数据的特征，使用适当的方法来实现你的数据分析目标。
- en: 'Anyway, you can use (for example) `qqplot` to do a pair-wise comparison of
    variables, and `qqnorm` to do univariate normality tests of your variables. First,
    let''s demonstrate this with a subset of `hflights`:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 无论如何，你可以使用（例如）`qqplot`来进行变量的成对比较，以及使用`qqnorm`来进行变量的单变量正态性检验。首先，让我们用一个`hflights`的子集来演示这一点：
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'So we filter our dataset to only those flights heading to the John F. Kennedy
    International Airport and we are interested in only two variables describing how
    long the taxiing in and out times were in minutes. The preceding command with
    the traditional `[` indexing can be refactored with `subset` for much more readable
    source code:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们过滤我们的数据集，只保留那些飞往约翰·肯尼迪国际机场的航班，并且我们只对描述进出滑行时间（以分钟为单位）的两个变量感兴趣。使用传统的`[`索引的先前命令可以用`subset`重构，以获得更易读的源代码：
- en: '[PRE1]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Please note that now there''s no need to quote variable names or refer to the
    `data.frame` name inside the `subset` call. For more details on this, please see
    [Chapter 3](ch03.html "Chapter 3. Filtering and Summarizing Data"), *Filtering
    and Summarizing Data*. And now let''s see how the values of these two columns
    are distributed:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，现在在`subset`调用中不需要引用变量名或提及`data.frame`的名称。关于这方面的更多细节，请参阅[第3章](ch03.html "第3章.
    过滤和汇总数据")，*过滤和汇总数据*。现在让我们看看这两个列值的分布情况：
- en: '[PRE2]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![Normality](img/2028OS_09_01.jpg)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![正态性](img/2028OS_09_01.jpg)'
- en: To render the preceding plot, we created a new graphical device (with `par`
    to hold two plots in a row), then called `qqnorm`, to show the quantiles of the
    empirical variables against the normal distribution, and also added a line for
    the latter with `qqline` for easier comparison. If the data was scaled previously,
    `qqline` would render a 45-degree line.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 为了生成前面的图，我们创建了一个新的图形设备（使用`par`在一行中保持两个图），然后调用`qqnorm`来显示经验变量的分位数与正态分布的对比，并且还添加了`qqline`来便于比较。如果数据之前已经缩放，`qqline`将渲染一条45度的线。
- en: 'Checking the QQ-plots suggest that the data does not fit the normal distribution
    very well, which can be also verified by an analytical test such as the Shapiro-Wilk
    normality test:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 检查QQ图表明数据与正态分布不太吻合，这也可以通过如Shapiro-Wilk正态性检验之类的分析测试来验证：
- en: '[PRE3]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The `p-value` is really small, so the null hypothesis (stating that the data
    is normally distributed) is rejected. But how can we test normality for a bunch
    of variables without and beyond separate statistical tests?
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '`p值`非常小，因此零假设（即数据是正态分布的）被拒绝。但如果没有以及超出单独的统计检验，我们如何测试一串变量的正态性呢？'
- en: Multivariate normality
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多元正态性
- en: Similar statistical tests exist for multiple variables as well; these methods
    provide different ways to check if the data fits the multivariate normal distribution.
    To this end, we will use the `MVN` package, but similar methods can be also found
    in the `mvnormtest` package. The latter includes the multivariate version of the
    previously discussed Shapiro-Wilk test as well.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 对于多个变量也存在类似的统计检验；这些方法提供了不同的方式来检查数据是否符合多元正态分布。为此，我们将使用`MVN`包，但类似的方法也可以在`mvnormtest`包中找到。后者包括之前讨论过的Shapiro-Wilk检验的多变量版本。
- en: 'But Mardia''s test is more often used to check multivariate normality and,
    even better, it does not limit the sample size to below 5,000\. After loading
    the `MVN` package, calling the appropriate R function is pretty straightforward
    with a very intuitive interpretation—after getting rid of the missing values in
    our dataset:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 但Mardia的检验更常用于检查多元正态性，而且更好，它不限制样本量低于5,000。在加载了`MVN`包之后，调用适当的R函数相当直接，并且具有非常直观的解释——在清除我们数据集中的缺失值之后：
- en: '[PRE4]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Tip
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: For more details on handling and filtering missing values, please see [Chapter
    8](ch08.html "Chapter 8. Polishing Data"), *Polishing Data*.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 关于处理和过滤缺失值的更多细节，请参阅[第8章](ch08.html "第8章. 精炼数据")，*精炼数据*。
- en: Out of the three p values, the third one refers to cases when the sample size
    is extremely small (<20), so now we only concentrate on the first two values,
    both below 0.05\. This means that the data does not seem to be multivariate normal.
    Unfortunately, Mardia's test fails to perform well in some cases, so more robust
    methods might be more appropriate to use.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在三个p值中，第三个指的是样本量极小（<20）的情况，所以现在我们只关注前两个值，两者都低于0.05。这意味着数据似乎不是多元正态的。不幸的是，Mardia的检验在某些情况下表现不佳，因此可能更适合使用更稳健的方法。
- en: 'The `MVN` package can run the Henze-Zirkler''s and Royston''s Multivariate
    Normality Test as well. Both return user-friendly and easy to interpret results:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '`MVN` 包还可以运行 Henze-Zirkler 和 Royston 的多元正态性检验。两者都返回用户友好且易于解释的结果：'
- en: '[PRE5]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'A more visual method to test multivariate normality is to render similar QQ
    plots to those we used before. But, instead of comparing only one variable with
    the theoretical normal distribution, let''s first compute the squared Mahalanobis
    distance between our variables, which should follow a chi-square distribution
    with the degrees of freedom being the number of our variables. The `MVN` package
    can automatically compute all the required values and render those with any of
    the preceding normality test R functions; just set the `qqplot` argument to be
    `TRUE`:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 更直观地测试多元正态性的方法是绘制与之前使用的类似的 Q-Q 图。但是，我们不仅仅比较一个变量与理论正态分布，而是首先计算我们变量之间的平方马氏距离，它应该遵循具有自由度为变量数量的卡方分布。`MVN`
    包可以自动计算所有必需的值，并使用任何前面的正态性检验 R 函数渲染这些值；只需将 `qqplot` 参数设置为 `TRUE`：
- en: '[PRE6]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![Multivariate normality](img/2028OS_09_02.jpg)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![多元正态性](img/2028OS_09_02.jpg)'
- en: 'If the dataset was normally distributed, the points shown in the preceding
    graphs should fit the straight line. Other alternative graphical methods can produce
    more visual and user-friendly plots with the previously created `mvt` R object.
    The `MVN` package ships the `mvnPlot` function, which can render perspective and
    contour plots for two variables and thus provides a nice way to test bivariate
    normality:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 如果数据集是正态分布的，前面图形中显示的点应该适合直线。其他替代的图形方法可以使用之前创建的 `mvt` R 对象生成更直观和用户友好的图形。`MVN`
    包提供了 `mvnPlot` 函数，它可以渲染两个变量的透视和等高线图，从而为测试双变量正态性提供了一种很好的方法：
- en: '[PRE7]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![Multivariate normality](img/2028OS_09_03.jpg)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![多元正态性](img/2028OS_09_03.jpg)'
- en: 'On the right plot, you can see the empirical distribution of the two variables
    on a perspective plot, where most cases can be found in the bottom-left corner.
    This means that most flights had only relatively short **TaxiIn** and **TaxiOut**
    times, which suggests a rather heavy-tailed distribution. The left plot shows
    a similar image, but from a bird''s eye view: the contour lines represent a cross-section
    of the right-hand side 3D graph. Multivariate normal distribution looks more central,
    something like a 2-dimensional bell curve:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在右侧的图中，你可以看到两个变量在透视图上的经验分布，其中大多数情况都位于左下角。这意味着大多数航班只有相对较短的 **TaxiIn** 和 **TaxiOut**
    时间，这表明分布有较重的尾部。左侧的图显示了类似的情况，但以鸟瞰图的形式：等高线代表右手边 3D 图的横截面。多元正态分布看起来更集中，类似于二维的钟形曲线：
- en: '[PRE8]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![Multivariate normality](img/2028OS_09_04.jpg)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![多元正态性](img/2028OS_09_04.jpg)'
- en: See [Chapter 13](ch13.html "Chapter 13. Data Around Us"), *Data Around Us* on
    how to create similar contour maps on spatial data.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 查看[第 13 章](ch13.html "第 13 章。我们周围的数据")，*我们周围的数据*，了解如何在空间数据上创建类似的等高线图。
- en: Dependence of variables
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 变量的依赖性
- en: Besides normality, relatively high correlation coefficients are desired when
    applying dimension reduction methods. The reason is that, if there is no statistical
    relationship between the variables, for example, PCA will return the exact same
    values without much transformation.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 除了正态性之外，在应用降维方法时，还希望相对较高的相关系数。原因是，如果没有变量之间的统计关系，例如，PCA 将返回没有太多变换的精确相同值。
- en: 'To this end, let''s see how the numerical variables of the `hflights` dataset
    are correlated (the output, being a large matrix, is suppressed this time):'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 为了达到这个目的，让我们看看 `hflights` 数据集中的数值变量是如何相关的（由于输出是一个大型矩阵，这次将其省略）：
- en: '[PRE9]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'In the preceding example, we have created a new R object to hold only the numeric
    columns of the original `hflights` data frame, leaving out five character vectors.
    Then, we run `cor` with pair-wise deletion of missing values, which returns a
    matrix with 16 columns and 16 rows:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的例子中，我们创建了一个新的 R 对象，仅包含原始 `hflights` 数据框的数值列，省略了五个字符向量。然后，我们使用成对删除缺失值的方式运行
    `cor`，返回一个 16 列 16 行的矩阵：
- en: '[PRE10]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The number of missing values in the resulting correlation matrix seems to be
    very high. This is because `Year` was 2011 in all cases, thus resulting in a standard
    variation of zero. It''s wise to exclude `Year` along with the non-numeric variables
    from the dataset—by not only filtering for numeric values, but also checking the
    variance:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 结果相关矩阵中的缺失值数量似乎非常高。这是因为所有情况下的`Year`都是2011年，因此导致标准差为零。明智的做法是将`Year`以及非数值变量从数据集中排除——不仅通过过滤数值值，还要检查方差：
- en: '[PRE11]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Now the number of missing values is a lot lower:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 现在缺失值的数量要低得多：
- en: '[PRE12]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Can you guess why we still have some missing values here despite the pair-wise
    deletion of missing values? Well, running the preceding command results in a rather
    informative warning, but we will get back to this question later:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管进行了成对删除缺失值的操作，但您能猜到为什么这里仍然有一些缺失值吗？嗯，运行前面的命令会产生一个相当有用的警告，但我们将稍后回到这个问题：
- en: '[PRE13]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Let''s now proceed with analyzing the actual numbers in the 15x15 correlation
    matrix, which would be way too large to print in this book. To this end, we did
    not show the result of the original `cor` command shown previously, but instead,
    let''s rather visualize those 225 numbers with the graphical capabilities of the
    `ellipse` package:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来分析15x15相关矩阵中的实际数字，这个矩阵太大，无法在这本书中打印出来。为此，我们没有展示之前提到的原始`cor`命令的结果，而是用`ellipse`包的图形功能来可视化这225个数字：
- en: '[PRE14]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '![Dependence of variables](img/2028OS_09_05.jpg)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![变量依赖性](img/2028OS_09_05.jpg)'
- en: 'Now we see the values of the correlation matrix represented by ellipses, where:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们看到相关矩阵的值通过椭圆表示，其中：
- en: A perfect circle stands for the correlation coefficient of zero
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 完美的圆圈代表零相关系数
- en: Ellipses with a smaller area reflect the relatively large distance of the correlation
    coefficient from zero
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 面积较小的椭圆反映了相关系数与零之间的相对较大距离
- en: The tangent represents the negative/positive sign of the coefficient
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正切代表系数的负/正符号
- en: 'To help you with analyzing the preceding results, let''s render a similar plot
    with a few artificially generated numbers that are easier to interpret:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助您分析前面的结果，让我们绘制一个具有一些人工生成的、更容易解释的数字的类似图表：
- en: '[PRE15]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '![Dependence of variables](img/2028OS_09_06.jpg)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![变量依赖性](img/2028OS_09_06.jpg)'
- en: Similar plots on the correlation matrix can be created with the `corrgram` package.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用`corrgram`包在相关矩阵上创建类似的图表。
- en: 'But let''s get back to the `hflights` dataset! On the previous diagram, some
    narrow ellipses are rendered for the time-related variables, which show a relatively
    high correlation coefficient, and even the `Month` variable seems to be slightly
    associated with the `FlightNum` function:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 但让我们回到`hflights`数据集！在前面的图表中，为时间相关的变量绘制了一些狭窄的椭圆，这表明相关系数相对较高，甚至`Month`变量似乎与`FlightNum`函数有轻微的关联：
- en: '[PRE16]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: On the other hand, the plot shows perfect circles in most cases, which stand
    for a correlation coefficient around zero. This suggests that most variables are
    not correlated at all, so computing the principal components of the original dataset
    would not be very helpful due to the low proportion of common variance.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，大多数情况下，图表显示的是完美的圆圈，这代表相关系数约为零。这表明大多数变量之间根本不相关，因此由于共同方差的比例较低，计算原始数据集的主成分可能不会很有帮助。
- en: KMO and Barlett's test
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: KMO和巴特利特检验
- en: 'We can verify this assumption on low communalities by a number of statistical
    tests; for example, the SAS and SPSS folks tend to use KMO or Bartlett''s test
    to see if the data is suitable for PCA. Both algorithms are available in R as
    well via, for example, via the `psych` package:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过多种统计测试来验证低共同度假设；例如，SAS和SPSS用户倾向于使用KMO或巴特利特检验来查看数据是否适合主成分分析。这两种算法在R中也可以使用，例如通过`psych`包：
- en: '[PRE17]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Unfortunately, the `Overall MSA` (*Measure of Sampling Adequacy*, representing
    the average correlations between the variables) is not available in the preceding
    output due to the previously identified missing values of the correlation matrix.
    Let''s pick a pair of variables where the correlation coefficient was `NA` for
    further analysis! Such a pair can be easily identified from the previous plot;
    no circle or ellipse was drawn for missing values, for example, for `Cancelled`
    and `AirTime`:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，由于之前识别的相关矩阵缺失值，前述输出中不可用“总体MSA”（抽样充分性度量，表示变量之间的平均相关系数）。让我们选择一对变量，其中相关系数为“NA”，以进行进一步分析！这样的对可以从之前的图中轻松识别；例如，对于“取消”和“AirTime”，没有绘制圆圈或椭圆：
- en: '[PRE18]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'This can be explained by the fact, that if a flight is cancelled, then the
    time spent in the air does not vary much; furthermore, this data is not available:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以通过以下事实来解释，即如果航班被取消，那么在空中度过的时间变化不大；此外，这些数据不可用：
- en: '[PRE19]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'So we get missing values when calling `cor` due to these `NA`; similarly, we
    also get `NA` when calling `cor` with pair-wise deletion, as only the non-cancelled
    flights remain in the dataset, resulting in zero variance for the `Cancelled`
    variable:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，当我们调用`cor`时由于这些“NA”而得到缺失值；同样，当我们使用成对删除调用`cor`时也会得到“NA”，因为数据集中只剩下未取消的航班，导致“取消”变量的方差为零：
- en: '[PRE20]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'This suggests removing the `Cancelled` variable from the dataset before we
    run the previously discussed assumption tests, as the information stored in that
    variable is redundantly available in other columns of the dataset as well. Or,
    in other words, the `Cancelled` column can be computed by a linear transformation
    of the other columns, which can be left out from further analysis:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这表明在运行之前讨论的假设测试之前，我们应该从数据集中删除“取消”变量，因为该变量中存储的信息在其他数据集的列中也是冗余可用的。或者换句话说，“取消”列可以通过其他列的线性变换来计算，这些列可以省略在进一步分析中：
- en: '[PRE21]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'And let''s see if we still have any missing values in the correlation matrix:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看在相关矩阵中是否还有任何缺失值：
- en: '[PRE22]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'It seems that the `Diverted` column is responsible for a similar situation,
    and the other three variables were not available when the flight was diverted.
    After another subset, we are now ready to call KMO on a full correlation matrix:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来“改道”列是造成类似情况的原因，其他三个变量在航班改道时不可用。经过另一个子集后，我们现在可以调用KMO来对完整的相关矩阵进行分析：
- en: '[PRE23]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The `Overall MSA`, or the so called **Kaiser-Meyer-Olkin** (**KMO**) index,
    is a number between 0 and 1; this value suggests whether the partial correlations
    of the variables are small enough to continue with data reduction methods. A general
    rating system or rule of a thumb for KMO can be found in the following table,
    as suggested by Kaiser:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: “总体MSA”，或所谓的**卡特尔-梅耶-奥金**（**KMO**）指数，是一个介于0和1之间的数字；这个值表明变量的部分相关系数是否足够小，可以继续使用数据降维方法。KMO的一般评价体系或经验法则可以在以下表格中找到，如凯撒建议：
- en: '| Value | Description |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| 值 | 描述 |'
- en: '| --- | --- |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| KMO < 0.5 | Unacceptable |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| KMO < 0.5 | 不可接受 |'
- en: '| 0.5 < KMO < 0.6 | Miserable |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| 0.5 < KMO < 0.6 | 糟糕 |'
- en: '| 0.6 < KMO < 0.7 | Mediocre |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| 0.6 < KMO < 0.7 | 一般 |'
- en: '| 0.7 < KMO < 0.8 | Middling |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| 0.7 < KMO < 0.8 | 中等 |'
- en: '| 0.8 < KMO < 0.9 | Meritorious |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| 0.8 < KMO < 0.9 | 优秀 |'
- en: '| KMO > 0.9 | Marvelous |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| KMO > 0.9 | 极佳 |'
- en: The KMO index being below 0.5 is considered unacceptable, which basically means
    that the partial correlation computed from the correlation matrix suggests that
    the variables are not correlated enough for a meaningful dimension reduction or
    latent variable model.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: KMO指数低于0.5被认为是不可接受的，这基本上意味着从相关矩阵计算出的部分相关系数表明变量之间的相关性不足以进行有意义的降维或潜在变量模型。
- en: 'Although leaving out some variables with the lowest MSA would improve the `Overall
    MSA`, and we could build some appropriate models in the following pages, for instructional
    purposes we won''t spend any more time on data transformation for the time being,
    and we will use the `mtcars` dataset, which was introduced in [Chapter 3](ch03.html
    "Chapter 3. Filtering and Summarizing Data"), *Filtering and Summarizing Data*:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然省略一些具有最低MSA的变量可以提高“总体MSA”，我们可以在接下来的几页中构建一些适当的模型，但出于教学目的，我们目前不会在数据转换上花费更多时间，我们将使用在[第3章](ch03.html
    "第3章。过滤和汇总数据")中介绍的`mtcars`数据集，*过滤和汇总数据*：
- en: '[PRE24]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'It seems that the `mtcars` database is a great choice for multivariate statistical
    analysis. This can be also verified by the so-called Bartlett test, which suggests
    whether the correlation matrix is similar to an identity matrix. Or, in other
    words, if there is a statistical relationship between the variables. On the other
    hand, if the correlation matrix has only zeros except for the diagonal, then the
    variables are independent from each other; thus it would not make much sense to
    think of multivariate methods. The `psych` package provides an easy-to-use function
    to compute Bartlett''s test as well:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来，`mtcars`数据库是多元统计分析的一个很好的选择。这也可以通过所谓的Bartlett测试来验证，该测试建议是否协方差矩阵与单位矩阵相似。或者换句话说，如果变量之间存在统计关系。另一方面，如果协方差矩阵除了对角线外只有零，那么变量之间是独立的；因此，考虑多元方法就没有太多意义了。《psych》包提供了一个易于使用的函数来计算Bartlett测试：
- en: '[PRE25]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The very low `p-value` suggests that we reject the null-hypothesis of the Bartlett
    test. This means that the correlation matrix differs from the identity matrix,
    so the correlation coeffiecients between the variables seem to be closer to 1
    than 0\. This is in sync with the high KMO value.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 非常低的`p-value`表明我们拒绝了Bartlett测试的零假设。这意味着协方差矩阵与单位矩阵不同，因此变量之间的相关系数似乎比0更接近于1。这与高KMO值是一致的。
- en: Note
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Before focusing on the actual statistical methods, please be advised that, although
    the preceding assumptions make sense in most cases and should be followed as a
    rule of a thumb, KMO and Bartlett's tests are not always required. High communality
    is important for factor analysis and other latent models, while for example PCA
    is a mathematical transformation that will work with even low KMO values.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在专注于实际的统计方法之前，请务必注意，尽管前面的假设在大多数情况下是有意义的，并且应该作为经验法则遵循，但KMO和Bartlett测试并不总是必需的。高共同性对于因子分析和其他潜在模型很重要，而例如PCA是一种数学变换，即使KMO值较低也能工作。
- en: Principal Component Analysis
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 主成分分析
- en: 'Finding the really important fields in databases with a huge number of variables
    may prove to be a challenging task for the data scientist. This is where **Principal
    Component Analysis** (**PCA**) comes into the picture: to find the core components
    of data. It was invented more than 100 years ago by Karl Pearson, and it has been
    widely used in diverse fields since then.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在具有大量变量的数据库中找到真正重要的字段可能对数据科学家来说是一项具有挑战性的任务。这就是**主成分分析**（**PCA**）发挥作用的地方：找到数据的核心成分。它是由Karl
    Pearson在100多年前发明的，自那时以来，它已经在各个领域得到了广泛的应用。
- en: The objective of PCA is to interpret the data in a more meaningful structure
    with the help of orthogonal transformations. This linear transformation is intended
    to reveal the internal structure of the dataset with an arbitrarily designed new
    basis in the vector space, which best explains the variance of the data. In plain
    English, this simply means that we compute new variables from the original data,
    where these new variables include the variance of the original variables in decreasing
    order.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: PCA的目标是借助正交变换，以更有意义的结构解释数据。这种线性变换旨在通过在向量空间中任意设计的新基中揭示数据集的内部结构，以最佳地解释数据的方差。用简单的话说，这仅仅意味着我们从原始数据中计算新的变量，这些新变量按降序包含原始变量的方差。
- en: This can be either done by eigendecomposition of the covariance, correlation
    matrix (the so-called R-mode PCA), or singular value decomposition (the so-called
    Q-mode PCA) of the dataset. Each method has great advantages, such as computation
    performance, memory requirements, or simply avoiding the prior standardization
    of the data before passing it to PCA when using a correlation matrix in eigendecomposition.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以通过协方差矩阵的特征分解（所谓的R模式PCA）或数据集的奇异值分解（所谓的Q模式PCA）来完成。每种方法都有很大的优势，例如计算性能、内存需求，或者简单地避免在使用协方差矩阵进行特征分解时，在将数据传递给PCA之前对数据进行预先标准化。
- en: Either way, PCA can successfully ship a lower-dimensional image of the data,
    where the uncorrelated principal components are the linear combinations of the
    original variables. And this informative overview can be a great help to the analyst
    when identifying the underlying structure of the variables; thus the technique
    is very often used for exploratory data analysis.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 无论哪种方式，PCA都可以成功地将数据的低维图像传递出去，其中不相关的主成分是原始变量的线性组合。这个信息概览对于分析员在识别变量的潜在结构时非常有帮助；因此，这种技术经常被用于探索性数据分析。
- en: PCA results in the exact same number of extracted components as the original
    variables. The first component includes most of the common variance, so it has
    the highest importance in describing the original dataset, while the last component
    often only includes some unique information from only one original variable. Based
    on this, we would usually only keep the first few components of PCA for further
    analysis, but we will also see some use cases where we will concentrate on the
    extracted unique variance.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: PCA产生的提取组件数量与原始变量完全相同。第一个组件包括大部分共同方差，因此在描述原始数据集时具有最高的重要性，而最后一个组件通常只包括来自一个原始变量的某些独特信息。基于这一点，我们通常会只保留PCA的前几个组件进行进一步分析，但我们也会看到一些专注于提取独特方差的用例。
- en: PCA algorithms
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PCA算法
- en: R provides a variety of functions to run PCA. Although it's possible to compute
    the components manually by `eigen` or `svd` as R-mode or Q-mode PCA, we will focus
    on the higher level functions for the sake of simplicity. Relying on my stats-teacher
    background, I think that sometimes it's more efficient to concentrate on how to
    run an analysis and interpreting the results rather than spending way too much
    time with the linear algebra background—especially with given time/page limits.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: R提供了多种函数来运行PCA。尽管可以通过`eigen`或`svd`手动计算R模式或Q模式的组件，但为了简化，我们将关注高级函数。凭借我的统计学教师背景，我认为有时集中精力分析如何运行和解释结果比花大量时间在线性代数背景上更有效率——尤其是在给定的时间/页面限制下。
- en: 'R-mode PCA can be conducted by `princomp` or `principal` from the `psych` package,
    while the more preferred Q-mode PCA can be called by `prcomp`. Now let''s focus
    on the latter and see what the components of `mtcars` look like:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: R模式PCA可以通过`psych`包中的`princomp`或`principal`进行，而更受欢迎的Q模式PCA可以通过`prcomp`调用。现在让我们专注于后者，看看`mtcars`的组件是什么样的：
- en: '[PRE26]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Note
  id: totrans-113
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'Please note that we have called `prcomp` with `scale` set to `TRUE`, which
    is `FALSE` by default due to being backward-compatible with the S language. But
    in general, scaling is highly recommended. Using the scaling option is equivalent
    to running PCA on a dataset after scaling it previously, such as: `prcomp(scale(mtcars))`,
    which results in data with unit variance.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们已经将`prcomp`的`scale`设置为`TRUE`，这是由于与S语言的向后兼容性而默认为`FALSE`。但一般来说，缩放是非常推荐的。使用缩放选项相当于在先前缩放数据集后运行PCA，例如：`prcomp(scale(mtcars))`，这将产生具有单位方差的数值。
- en: 'First, `prcomp` returned the standard deviations of the principal components,
    which shows how much information was preserved by the 11 components. The standard
    deviation of the first component is a lot larger than any other subsequent value,
    which explains more than 60 percent of the variance:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，`prcomp`返回了主成分的标准差，这显示了11个组件保留了多少信息。第一个组件的标准差远大于任何后续值，解释了超过60%的方差：
- en: '[PRE27]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Besides the first component, only the second one has a higher standard deviation
    than 1, which means that only the first two components include at least as much
    information as the original variables did. Or, in other words: only the first
    two variables have a higher eigenvalue than one. The eigenvalue can be computed
    by the square of the standard deviation of the principal components, summing up
    to the number of original variables as expected:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 除了第一个组件外，只有第二个组件的标准差高于1，这意味着只有前两个组件至少包含与原始变量一样多的信息。或者换句话说：只有前两个变量的特征值高于1。特征值可以通过主成分标准差的平方来计算，总数应与原始变量的数量一致：
- en: '[PRE28]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Determining the number of components
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 确定组件数量
- en: PCA algorithms always compute the same number of principal components as the
    number of variables in the original dataset. The importance of the component decreases
    from the first one to the last one.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: PCA算法总是计算与原始数据集中变量数量相同数量的主成分。组件的重要性从第一个到最后一个逐渐降低。
- en: 'As a rule of a thumb, we can simply keep all those components with higher standard
    deviation than 1\. This means that we keep those components, which explains at
    least as much variance as the original variables do:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 作为经验法则，我们可以简单地保留所有标准差高于1的组件。这意味着我们保留了那些至少解释了与原始变量一样多的方差的组件：
- en: '[PRE29]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'So the preceding summary suggests keeping only two components out of the 11,
    which explains almost 85 percent of the variance:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，前面的总结建议只保留11个组件中的两个，这几乎解释了85%的方差：
- en: '[PRE30]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'An alternative and great visualization tool to help us determine the optimal
    number of component is scree plot. Fortunately, there are at least two great functions
    in the `psych` package we can use here: the `scree` and the `VSS.scree` functions:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 一个帮助我们确定最佳成分数量的替代且优秀的可视化工具是scree图。幸运的是，在`psych`包中至少有两个优秀的函数可以在这里使用：`scree`和`VSS.scree`函数：
- en: '[PRE31]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '![Determining the number of components](img/2028OS_09_08.jpg)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![确定成分数量](img/2028OS_09_08.jpg)'
- en: '[PRE32]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '![Determining the number of components](img/2028OS_09_09.jpg)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![确定成分数量](img/2028OS_09_09.jpg)'
- en: The only difference between the preceding two plots is that `scree` also shows
    the eigenvalues of a factor analysis besides PCA. Read more about this in the
    next section of this chapter.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 前两个图之间的唯一区别是`scree`除了PCA之外还显示了因子分析的特征值。关于这一点，请参阅本章下一节的相关内容。
- en: As can be seen, `VSS.scree` provides a visual overview on the eigenvalues of
    the principal components, and it also highlights the critical value at 1 by a
    horizontal line. This is usually referred to as the Kaiser criterion.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 如所示，`VSS.scree`提供了主成分特征值的视觉概述，并且通过一条水平线突出了1的临界值。这通常被称为Kaiser标准。
- en: Besides this rule of a thumb, as discussed previously one can also rely on the
    so-called Elbow-rule, which simply suggests that the line-plot represents an arm
    and the optimal number of components is the point where this arm's elbow can be
    found. So we have to look for the point from where the curve becomes less steep.
    This sharp break is probably at 3 in this case instead of 2, as we have found
    with the Kaiser criterion.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这个经验法则之外，正如之前讨论的那样，人们还可以依赖所谓的“肘部法则”，它简单地说，线图代表一条臂，最佳成分数量是这条臂的肘部所在的位置。因此，我们必须寻找曲线变得不那么陡峭的点。在这种情况下，这个尖锐的转折可能是在3而不是2，正如我们使用Kaiser标准所发现的那样。
- en: 'And besides Cattell''s original scree test, we can also compare the previously
    described `scree` of the components with a bit of a randomized data to identify
    the optimal number of components to keep:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 除了Cattell的原始scree测试之外，我们还可以将之前描述的`scree`与一些随机数据比较，以确定要保留的最佳成分数量：
- en: '[PRE33]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '![Determining the number of components](img/2028OS_09_09.jpg)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![确定成分数量](img/2028OS_09_09.jpg)'
- en: '[PRE34]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Now we have verified the optimal number of principal components to keep for
    further analysis with a variety of statistical tools, and we can work with only
    two variables instead of 11 after all, which is great! But what do these artificially
    created variables actually mean?
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经验证了用于进一步分析的保留主成分的最佳数量，我们可以只使用两个变量而不是11个，这真是太好了！但人工创建的这些变量实际上意味着什么呢？
- en: Interpreting components
  id: totrans-138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解释成分
- en: 'The only problem with reducing the dimension of our data is that it can be
    very frustrating to find out what our newly created, highly compressed, and transformed
    data actually is. Now we have `PC1` and `PC2` for our 32 cars:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 减少我们数据维度的问题在于，发现我们新创建的、高度压缩和转换的数据实际上是什么可能会非常令人沮丧。现在我们有`PC1`和`PC2`用于我们的32辆汽车：
- en: '[PRE35]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'These values were computed by multiplying the original dataset with the identified
    weights, so-called loadings (`rotation`) or the component matrix. This is a standard
    linear transformation:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 这些值是通过将原始数据集与识别的权重（所谓的负载或旋转）或成分矩阵相乘得到的。这是一个标准的线性变换：
- en: '[PRE36]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Both variables are scaled with the mean being zero and the standard deviation
    as described previously:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 两个变量都经过缩放，均值为零，标准差如前所述：
- en: '[PRE37]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'All scores computed by PCA are scaled, because it always returns the values
    transformed to a new coordinate system with an orthogonal basis, which means that
    the components are not correlated and scaled:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: PCA计算的所有得分都是经过缩放的，因为它总是返回转换到新坐标系（具有正交基）的值，这意味着成分之间不相关且已缩放：
- en: '[PRE38]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'To see what the principal components actually mean, it''s really helpful to
    check the loadings matrix, as we have seen before:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解主成分实际上意味着什么，检查负载矩阵非常有帮助，正如我们之前所看到的：
- en: '[PRE39]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Probably this analytical table might be more meaningful in some visual way,
    for example as a `biplot`, which shows not only the original variables but also
    the observations (black labels) on the same plot with the new coordinate system
    based on the principal components (red labels):'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 可能这个分析表在某些视觉方式上可能更有意义，例如作为一个`biplot`，它不仅显示了原始变量，还显示了基于主成分（红色标签）的新坐标系上的观测值（黑色标签）：
- en: '[PRE40]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '![Interpreting components](img/2028OS_09_10.jpg)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![解释成分](img/2028OS_09_10.jpg)'
- en: We can conclude that `PC1` includes information mostly from the number of cylinders
    (`cyl`), displacement (`disp`), weight (`wt`), and gas consumption (`mpg`), although
    the latter looks likely to decrease the value of `PC1`. This was found by checking
    the highest and lowest values on the `PC1` axis. Similarly, we find that `PC2`
    is constructed by speed-up (`qsec`), number of gears (`gear`), carburetors (`carb`),
    and the transmission type (`am`).
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以得出结论，`PC1`主要包含来自气缸数（`cyl`）、排量（`disp`）、重量（`wt`）和油耗（`mpg`）的信息，尽管后者可能降低`PC1`的值。这是通过检查`PC1`轴上的最高和最低值发现的。同样，我们发现`PC2`是由加速（`qsec`）、档位数（`gear`）、化油器（`carb`）和传动类型（`am`）构成的。
- en: 'To verify this, we can easily compute the correlation coefficient between the
    original variables and the principal components:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 为了验证这一点，我们可以轻松地计算原始变量和主成分之间的相关系数：
- en: '[PRE41]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Does this make sense? How would you name `PC1` and `PC2`? The number of cylinders
    and displacement seem like engine parameters, while the weight is probably rather
    influenced by the body of the car. Gas consumption should be affected by both
    specs. The other component's variables deal with suspension, but we also have
    speed there, not to mention the bunch of mediocre correlation coefficients in
    the preceding matrix. Now what?
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 这有意义吗？你会如何命名`PC1`和`PC2`？气缸数和排量看起来像是发动机参数，而重量可能更多地受到车身的影响。油耗应该受这两个规格的影响。其他组件的变量处理悬挂，但我们也有速度，更不用说前面矩阵中一串平庸的相关系数了。现在怎么办？
- en: Rotation methods
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 旋转方法
- en: Based on the fact that rotation methods are done in a subspace, rotation is
    always suboptimal compared to the previously discussed PCA. This means that the
    new axes after rotation will explain less variance than the original components.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 基于旋转方法是在子空间中进行的这一事实，旋转总是比之前讨论的PCA次优。这意味着旋转后的新轴将解释的方差少于原始组件。
- en: On the other hand, rotation simplifies the structure of the components and thus
    makes it a lot easier to understand and interpret the results; thus, these methods
    are often used in practice.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，旋转简化了组件的结构，因此使得理解和解释结果变得更加容易；因此，这些方法在实践中经常被使用。
- en: Note
  id: totrans-159
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Rotation methods can be (and are) usually applied to both PCA and FA (more on
    this later). Orthogonal methods are preferred.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 旋转方法可以（并且通常是）应用于PCA和FA（关于这一点稍后还会讨论）。正交方法更受欢迎。
- en: 'There are two main types of rotation:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 旋转主要有两种类型：
- en: Orthogonal, where the new axes are orthogonal to each other. There is no correlation
    between the components/factors.
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正交，其中新轴相互垂直。组件/因子之间没有相关性。
- en: Oblique, where the new axes are not necessarily orthogonal to each other; thus
    there might be some correlation between the variables.
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 斜交，其中新轴不一定相互垂直；因此，变量之间可能存在一些相关性。
- en: 'Varimax rotation is one of the most popular rotation methods. It was developed
    by Kaiser in 1958 and has been popular ever since. It is often used because the
    method maximizes the variance of the loadings matrix, resulting in more interpretable
    scores:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: Varimax旋转是最受欢迎的旋转方法之一。它由凯撒于1958年开发，并且自那时起一直很受欢迎。它经常被使用，因为该方法最大化了载荷矩阵的方差，从而得到更可解释的得分：
- en: '[PRE42]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Now the first component seems to be mostly affected (negatively dominated)
    by the transmission type, number of gears, and rear axle ratio, while the second
    one is affected by speed-up, horsepower, and the number of carburetors. This suggests
    naming `PC2` as `power`, while `PC1` instead refers to `transmission`. Let''s
    see those 32 automobiles in this new coordinate system:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 现在第一个成分似乎主要受到传动类型、档位数和后轴比（negatively dominated）的影响，而第二个成分则受到加速、马力和化油器数量的影响。这表明将`PC2`命名为`power`，而`PC1`则指代`transmission`。让我们看看在这个新坐标系中的这32辆汽车：
- en: '[PRE43]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: '![Rotation methods](img/2028OS_09_11.jpg)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![旋转方法](img/2028OS_09_11.jpg)'
- en: Based on the preceding plot, every data scientist should pick a car from the
    upper left quarter to go with the top rated models, right? Those cars have great
    power based on the *y* axis and good transmission systems, as shown on the *x*
    axis—do not forget about the transmission being negatively correlated with the
    original variables. But let's see some other rotation methods and the advantages
    of those as well!
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 基于前面的图，每个数据科学家都应该从左上象限选择一辆车来搭配顶级车型，对吧？这些车在*y*轴上拥有强大的动力，在*x*轴上显示了良好的传动系统——不要忘记传动与原始变量呈负相关。但让我们看看其他旋转方法及其优势吧！
- en: Quartimax rotation is an orthogonal method, as well, and minimizes the number
    of components needed to explain each variable. This often results in a general
    component and additional smaller components. When a compromise between Varimax
    and Quartimax rotation methods is needed, you might opt for Equimax rotation.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: Quartimax旋转也是一种正交方法，它最小化了解释每个变量所需组件的数量。这通常会导致一个一般成分和额外的较小成分。当需要Varimax和Quartimax旋转方法之间的折衷方案时，你可能选择Equimax旋转。
- en: 'Oblique rotation methods include Oblimin and Promax, which are not available
    in the base stats or even the highly used `psych` package. Instead, we can load
    the `GPArotation` package, which provides a wide range of rotation methods for
    PCA and FA as well. For demonstration purposes, let''s see how Promax rotation
    works, which is a lot faster compared to, for example, Oblimin:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 斜旋转方法包括Oblimin和Promax，这些方法在基本统计或高度使用的`psych`包中不可用。相反，我们可以加载`GPArotation`包，它为PCA和FA提供了广泛的旋转方法。为了演示目的，让我们看看Promax旋转是如何工作的，它比例如Oblimin快得多：
- en: '[PRE44]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: The result of the last command supports the view that oblique rotation methods
    generate scores that might be correlated, unlike when running an orthogonal rotation.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一条命令的结果支持这样的观点：斜旋转方法生成的分数可能相关，这与运行正交旋转时不同。
- en: Outlier-detection with PCA
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PCA中的异常值检测
- en: 'PCA can be used for a variety of goals besides exploratory data analysis. For
    example, we can use PCA to generate eigenfaces, compress images, classify observations,
    or to detect outliers in a multidimensional space via image filtering. Now, we
    will construct a simplified model discussed in a related research post published
    on R-bloggers in 2012: [http://www.r-bloggers.com/finding-a-pin-in-a-haystack-pca-image-filtering](http://www.r-bloggers.com/finding-a-pin-in-a-haystack-pca-image-filtering).'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: PCA除了用于探索性数据分析之外，还可以用于各种目标。例如，我们可以使用PCA生成特征脸、压缩图像、分类观察结果，或通过图像过滤在多维空间中检测异常值。现在，我们将构建一个在2012年R-bloggers上发布的相关研究帖子中讨论的简化模型：[http://www.r-bloggers.com/finding-a-pin-in-a-haystack-pca-image-filtering](http://www.r-bloggers.com/finding-a-pin-in-a-haystack-pca-image-filtering)。
- en: 'The challenge described in the post was to detect a foreign metal object in
    the sand photographed by the Curiosity Rover on the Mars. The image can be found
    at the official NASA website at [http://www.nasa.gov/images/content/694811main_pia16225-43_full.jpg](http://www.nasa.gov/images/content/694811main_pia16225-43_full.jpg),
    for which I''ve created a shortened URL for future use: [http://bit.ly/nasa-img](http://bit.ly/nasa-img).'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 帖子中描述的挑战是在火星上由好奇号漫游车拍摄的沙子照片中检测到异物。该图像可以在官方NASA网站上找到，网址为[http://www.nasa.gov/images/content/694811main_pia16225-43_full.jpg](http://www.nasa.gov/images/content/694811main_pia16225-43_full.jpg)，我为未来使用创建了缩短的URL：[http://bit.ly/nasa-img](http://bit.ly/nasa-img)。
- en: 'In the following image, you can see a strange metal object highlighted in the
    sand in a black circle, just to make sure you know what we are looking for. The
    image found at the preceding URL does not have this highlight:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下图像中，你可以看到一个在沙子中用黑色圆圈突出显示的奇怪金属物体，以确保你知道我们在寻找什么。在前面URL中找到的图像没有这个突出显示：
- en: '![Outlier-detection with PCA](img/2028OS_09_12.jpg)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![PCA中的异常值检测](img/2028OS_09_12.jpg)'
- en: 'And now let''s use some statistical methods to identify that object without
    (much) human intervention! First, we need to download the image from the Internet
    and load it into R. The `jpeg` package will be really helpful here:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们使用一些统计方法来识别该物体，而不需要（太多）人为干预！首先，我们需要从互联网上下载图像并将其加载到R中。`jpeg`包在这里将非常有帮助：
- en: '[PRE45]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: The `readJPEG` function returns the RGB values of every pixel in the picture,
    resulting in a three dimensional array where the first dimension is the row, the
    second is the column, and the third dimension includes the three color values.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '`readJPEG`函数返回图片中每个像素的RGB值，结果是一个三维数组，其中第一个维度是行，第二个维度是列，第三个维度包括三个颜色值。'
- en: Note
  id: totrans-182
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: RGB is an additive color model that can reproduce a wide variety of colors by
    mixing red, green, and blue by given intensities and optional transparency. This
    color model is highly used in computer science.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: RGB是一种加色模型，可以通过给定强度和可选透明度混合红色、绿色和蓝色来重现各种颜色。这种颜色模型在计算机科学中高度使用。
- en: 'As PCA requires a matrix as an input, we have to convert this 3-dimensional
    array to a 2-dimensional dataset. To this end, let''s not bother with the order
    of pixels for the time being, as we can reconstruct that later, but let''s simply
    list the RGB values of all pixels, one after the other:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 由于PCA需要一个矩阵作为输入，我们必须将这个三维数组转换为二维数据集。为此，让我们暂时不要担心像素的顺序，因为我们稍后可以重建它，但让我们简单地列出所有像素的RGB值，一个接一个：
- en: '[PRE46]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'In a nutshell, we saved the original height of the image (in pixels) in variable
    `h`, saved the width in `w`, and then converted the 3D array to a matrix with
    1,357,105 rows. And, after four lines of data loading and three lines of data
    transformation, we can call the actual, rather simplified statistical method at
    last:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，我们将图像的原始高度（以像素为单位）保存在变量`h`中，将宽度保存在`w`中，然后将3D数组转换为具有1,357,105行的矩阵。然后，经过四行数据加载和三行数据转换，我们最后可以调用实际的、相对简化的统计方法：
- en: '[PRE47]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: As we've seen before, data scientists do indeed deal with data preparation most
    of the time, while the actual data analysis can be done easily, right?
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前看到的，数据科学家确实大多数时间都在处理数据准备，而实际的数据分析可以轻松完成，对吧？
- en: 'The extracted components seems to perform pretty well; the first component
    explains more than 96 percent of the variance:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 提取的成分似乎表现相当好；第一个成分解释了超过96%的方差：
- en: '[PRE48]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: Previously, interpreting RGB values was pretty straightforward, but what do
    these components mean?
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 以前，解释RGB值相当直接，但这些成分又意味着什么呢？
- en: '[PRE49]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'It seems that the first component is rather mixed with all three colors, the
    second component misses the green color, while the third component includes almost
    only green. Why not visualize that instead of trying to imagine how these artificial
    values look? To this end, let''s extract the color intensities from the preceding
    component/loading matrix by the following quick helper function:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来第一个成分与所有三种颜色混合得相当多，第二个成分缺少绿色，而第三个成分几乎只包含绿色。为什么不可视化这些人工值，而不是试图想象它们看起来如何呢？为此，让我们通过以下快速辅助函数从先前的成分/加载矩阵中提取颜色强度：
- en: '[PRE50]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Calling this on the absolute values of the component matrix results in the
    hex-color codes that describe the principal components:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在成分矩阵的绝对值上调用此方法会产生描述主成分的十六进制颜色代码：
- en: '[PRE51]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'These color codes can be easily rendered—for example, on a pie chart, where
    the area of the pies represents the explained variance of the principal components:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 这些颜色代码可以轻松渲染——例如，在饼图中，饼的面积代表主成分的解释方差：
- en: '[PRE52]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: '![Outlier-detection with PCA](img/2028OS_09_13.jpg)'
  id: totrans-199
  prefs: []
  type: TYPE_IMG
  zh: '![PCA中的异常值检测](img/2028OS_09_13.jpg)'
- en: Now we no longer have red, green, or blue intensities or actual colors in the
    computed scores stored in `pca$x`; rather, the principal components describe each
    pixel with the visualized colors shown previously. And, as previously discussed,
    the third component stands for a greenish color, the second one misses green (resulting
    in a purple color), while the first component includes a rather high value from
    all RGB colors resulting in a tawny color, which is not surprising at all knowing
    that the photo was taken in the desert of Mars.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们不再有存储在`pca$x`中的红色、绿色或蓝色强度或实际颜色，而是主成分用之前显示的可视化颜色描述每个像素。正如之前讨论的，第三个成分代表绿色色调，第二个成分缺少绿色（导致紫色），而第一个成分包含来自所有RGB颜色的相当高的值，结果产生棕黄色调，这在知道照片是在火星沙漠中拍摄的时并不令人惊讶。
- en: 'Now we can render the original image with monochrome colors to show the intensity
    of the principal components. The following few lines of code produce two modified
    photos of the Curiosity Rover and its environment based on `PC1` and `PC2`:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以用单色颜色渲染原始图像，以显示主成分的强度。以下几行代码基于`PC1`和`PC2`生成了好奇号及其环境的两张修改后的照片：
- en: '[PRE53]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: '![Outlier-detection with PCA](img/2028OS_09_14.jpg)'
  id: totrans-203
  prefs: []
  type: TYPE_IMG
  zh: '![PCA中的异常值检测](img/2028OS_09_14.jpg)'
- en: Although the image was rotated by 90 degrees in some of the linear transformations,
    it's pretty clear that the first image was not really helpful in finding the foreign
    metal object in the sand. As a matter of fact, this image represents the noise
    in the desert area, as `PC1` included sand-like color intensities, so this component
    is useful for describing the variety of tawny colors.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然图像在一些线性变换中被旋转了90度，但很明显，第一张图像在寻找沙子中的异物方面并没有真正有帮助。事实上，这张图像代表了沙漠地区的噪声，因为`PC1`包含了类似沙子的颜色强度，所以这个成分对于描述棕黄色调的多样性是有用的。
- en: On the other hand, the second component highlights the metal object in the sand
    very well! All surrounding pixels are dim, due to the low ratio of purple color
    in normal sand, while the anomalous object is rather dark.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，第二个成分很好地突出了沙子中的金属物体！由于正常沙子中紫色比例低，所有周围的像素都很暗，而异常物体则相当暗。
- en: 'I really like this piece of R code and the simplified example: although they''re
    still basic enough to follow, they also demonstrate the power of R and how standard
    data analytic methods can be used to harvest information from raw data.'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 我真的很喜欢这段R代码和简化的例子：虽然它们仍然足够基本以便于理解，但它们也展示了R的力量以及如何使用标准数据分析方法从原始数据中提取信息。
- en: Factor analysis
  id: totrans-207
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 因子分析
- en: Although the literature on confirmatory **factor analysis** (**FA**) is really
    impressive and is being highly used in, for example, social sciences, we will
    only focus on exploratory FA, where our goal is to identify some unknown, not
    observed variables based on other empirical data.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管关于验证性**因子分析**（**FA**）的文献非常令人印象深刻，并且在社会科学等领域被广泛使用，但我们将只关注探索性FA，我们的目标是根据其他经验数据识别一些未知、未观察到的变量。
- en: The latent variable model of FA was first introduced in 1904 by Spearman for
    one factor, and then Thurstone generalized the model for more than one factor
    in 1947\. This statistical model assumes that the manifest variables available
    in the dataset are the results of latent variables that were not observed but
    can be tracked based on the observed data.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 因子分析的潜在变量模型最早由Spearman于1904年提出，用于一个因子，然后在1947年Thurstone将该模型推广到多个因子。这个统计模型假设数据集中可用的显变量是未观察到的潜在变量的结果，这些潜在变量可以通过观察数据追踪。
- en: FA can deal with continuous (numeric) variables, and the model states that each
    observed variable is the sum of some unknown, latent factors.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: FA可以处理连续（数值）变量，并且模型表明每个观察到的变量是某些未知、潜在因子的总和。
- en: Note
  id: totrans-211
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Please note the that normality, KMO, and Bartlett's tests are a lot more important
    to check before doing FA compared to PCA; the latter is a rather descriptive method
    while, in FA, we are actually building a model.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在执行FA之前，检查正态性、KMO和Bartlett的测试比PCA更重要；后者是一种描述性方法，而在FA中，我们实际上是在构建一个模型。
- en: The most used exploratory FA method is maximum-likelihood FA, which is also
    available in the `factanal` function in the already installed `stats` package.
    Other factoring methods are made available by the `fa` functions in the `psych`
    package—for example, **ordinary least squares** (**OLS**), **weighted least squares**
    (**WLS**), **generalized weighted least squares** (**GLS**), or principal factor
    solution. These functions take raw data or the covariance matrix as input.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 最常用的探索性因子分析（FA）方法是最大似然FA，这在已安装的`stats`包中的`factanal`函数中也是可用的。其他分解方法由`psych`包中的`fa`函数提供，例如**普通最小二乘法**（**OLS**）、**加权最小二乘法**（**WLS**）、**广义加权最小二乘法**（**GLS**）或主因子解。这些函数以原始数据或协方差矩阵作为输入。
- en: 'For demonstration purposes, let''s see how the default factoring method performs
    on a subset of `mtcars`. Let''s extract all performance-related variables except
    for displacement, which is probably accountable for all the other relevant metrics:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 为了演示目的，让我们看看默认的分解方法在`mtcars`的一个子集上的表现。让我们提取所有与性能相关的变量，除了排量，因为排量可能负责所有其他相关指标：
- en: '[PRE54]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Now simply call and save the results of `fa` on the preceding `data.frame`:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 现在只需调用并保存前面`data.frame`上的`fa`结果：
- en: '[PRE55]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: Well, this is a rather impressive amount of information with a bunch of details!
    `MR1` stands for the first extracted factor named after the default factoring
    method (Minimal Residuals or OLS). Since there is only one factor included in
    the model, rotation of factors is not an option. There is a test or hypothesis
    to check whether the numbers of factors are sufficient, and some coefficients
    represent a really great model fit.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 嗯，这是一份相当令人印象深刻的信息量，包含了很多细节！`MR1`代表第一个提取的因子，该因子以默认的分解方法（最小残差或OLS）命名。由于模型中只包含一个因子，因此因子旋转不是一个选项。有一个测试或假设来检查因子的数量是否足够，并且一些系数代表了一个非常好的模型拟合。
- en: 'The results can be summarized on the following plot:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 结果可以在以下图表中总结：
- en: '[PRE56]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: '![Factor analysis](img/2028OS_09_15.jpg)'
  id: totrans-221
  prefs: []
  type: TYPE_IMG
  zh: '![因子分析](img/2028OS_09_15.jpg)'
- en: Here we see the high correlation coefficients between the latent and the observed
    variables, and the direction of the arrows suggests that the factor has an effect
    on the values found in our empirical dataset. Guess the relationship between this
    factor and the displacement of the car engines!
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到潜在变量和观察变量之间的高相关系数，箭头的方向表明因子对我们的经验数据集中找到的值有影响。猜测这个因子与汽车发动机位移之间的关系！
- en: '[PRE57]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: Well, this seems like a good match.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 嗯，这似乎是一个很好的匹配。
- en: Principal Component Analysis versus Factor Analysis
  id: totrans-225
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 主成分分析 versus 因子分析
- en: Unfortunately, principal components are often confused with factors, and the
    two terms and related methods are sometimes used as synonyms, although the mathematical
    background and goals of the two methods are really different.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，主成分经常与因子混淆，这两个术语及其相关方法有时被用作同义词，尽管这两种方法的数学背景和目标实际上是非常不同的。
- en: 'PCA is used to reduce the number of variables by creating principal components
    that then can be used in further projects instead of the original variables. This
    means that we try to extract the essence of the dataset in the means of artificially
    created variables, which best describe the variance of the data:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 主成分分析（PCA）通过创建主成分来减少变量的数量，这些主成分可以用于后续项目，而不是原始变量。这意味着我们试图通过人工创建的变量来提取数据集的本质，这些变量最好地描述了数据的方差：
- en: '![Principal Component Analysis versus Factor Analysis](img/2028OS_09_19.jpg)'
  id: totrans-228
  prefs: []
  type: TYPE_IMG
  zh: '![主成分分析 versus 因子分析](img/2028OS_09_19.jpg)'
- en: 'FA is the other way around, as it tries to identify unknown, latent variables
    to explain the original data. In plain English, we use the manifest variables
    from our empirical dataset to guess the internal structure of the data:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: FA是另一种方法，因为它试图识别未知、潜在变量来解释原始数据。用简单的话说，我们使用来自我们的经验数据集的显性变量来猜测数据的内部结构：
- en: '![Principal Component Analysis versus Factor Analysis](img/2028OS_09_20.jpg)'
  id: totrans-230
  prefs: []
  type: TYPE_IMG
  zh: '![主成分分析 versus 因子分析](img/2028OS_09_20.jpg)'
- en: Multidimensional Scaling
  id: totrans-231
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多维尺度
- en: '**Multidimensional Scaling** (**MDS**) is a multivariate technique that was
    first used in geography. The main goal of MDS is to plot multivariate data points
    in two dimensions, thus revealing the structure of the dataset by visualizing
    the relative distance of the observations. MDA is used in diverse fields such
    as attitude study in psychology, sociology, and market research.'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: '**多维尺度**（**MDS**）是一种多变量技术，最初用于地理学。多维尺度（MDS）的主要目标是绘制二维的多变量数据点，通过可视化观察值的相对距离来揭示数据集的结构。MDS在心理学、社会学和市场研究等众多领域得到应用。'
- en: While the `MASS` package provides non-metric MDS via the `isoMDS` function,
    we will concentrate on the classical metric MDS, which is available in the `cmdscale`
    function offered by the `stats` package. Both types of MDS take a distance matrix
    as the main argument and can be created from any numeric tabular data by the `dist`
    function.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然`MASS`包通过`isoMDS`函数提供非度量多维尺度（MDS），但我们将专注于由`stats`包提供的`cmdscale`函数提供的经典度量多维尺度（MDS）。这两种类型的多维尺度都以距离矩阵作为主要参数，并且可以通过`dist`函数从任何数值表格数据创建。
- en: 'But before we explore more complex examples, let''s see what MDS can offer
    us while working with an already existing distance matrix, such as the built-in
    `eurodist` dataset:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 在探索更复杂的例子之前，让我们看看在使用已经存在的距离矩阵时，多维尺度（MDS）能为我们提供什么，例如内置的`eurodist`数据集：
- en: '[PRE58]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'The preceding values represents the travel distance between 21 European cities
    in kilometers, although only the first 5-5 values were shown. Running classical
    MDS is fairly easy:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的值代表21个欧洲城市之间的旅行距离（千米），尽管只显示了前5-5个值。运行经典的多维尺度（MDS）相当简单：
- en: '[PRE59]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: These scores are very similar to two principal components, such as running `prcomp(eurodist)$x[,
    1:2]`. As a matter of fact, PCA can be considered as the most basic MDS solution.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 这些得分与两个主成分非常相似，例如运行`prcomp(eurodist)$x[, 1:2]`。事实上，主成分分析（PCA）可以被认为是多维尺度（MDS）最基本的方法。
- en: 'Anyway, we have just transformed the 21-dimensional space into 2 dimensions,
    which can be plotted very easily (unlike the previous matrix with 21 rows and
    21 columns):'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，我们已经将21维空间转换成了2维，这可以很容易地绘制出来（与之前的21行21列的矩阵不同）：
- en: '[PRE60]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: '![Multidimensional Scaling](img/2028OS_09_16.jpg)'
  id: totrans-241
  prefs: []
  type: TYPE_IMG
  zh: '![多维尺度](img/2028OS_09_16.jpg)'
- en: 'Does this ring a bell? If not, please feel free to see the following image,
    where the following two lines of code also show the city names instead of the
    anonymous points:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 这让你想起什么了吗？如果没有，请随意查看以下图像，其中以下两行代码也显示了城市名称而不是匿名点：
- en: '[PRE61]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: '![Multidimensional Scaling](img/2028OS_09_17.jpg)'
  id: totrans-244
  prefs: []
  type: TYPE_IMG
  zh: '![多维尺度](img/2028OS_09_17.jpg)'
- en: Although the *y* axis is flipped, which you can fix by multiplying the second
    argument of text by -1, we have just rendered a European map of cities from the
    distance matrix—without any further geographical data. I find this rather impressive.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管y轴被翻转了，你可以通过将文本的第二个参数乘以-1来修复这个问题，但我们已经根据距离矩阵渲染了一张欧洲城市地图——没有使用任何其他地理数据。我觉得这相当令人印象深刻。
- en: Please find more data visualization tricks and methods in [Chapter 13](ch13.html
    "Chapter 13. Data Around Us"), *Data Around Us*.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 请在[第13章](ch13.html "第13章。我们周围的数据")，*我们周围的数据*中查找更多数据可视化技巧和方法。
- en: 'Now let''s see how to apply MDS on non-geographic data that was not prepared
    with a view to its being a distance matrix. Let''s get back to the `mtcars` dataset:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看看如何将MDS应用于非地理数据，这些数据并非为成为距离矩阵而准备。让我们回到`mtcars`数据集：
- en: '[PRE62]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: '![Multidimensional Scaling](img/2028OS_09_18.jpg)'
  id: totrans-249
  prefs: []
  type: TYPE_IMG
  zh: '![多维尺度](img/2028OS_09_18.jpg)'
- en: The plot shows the 32 cars of the original dataset scattered in a two-dimensional
    space. The distance between the elements was computed by MDS, which took into
    account all the 11 original variables, and it's very easy to identify the similar
    and very different car types. We will cover these topics in more details in the
    next chapter, [Chapter 10](ch10.html "Chapter 10. Classification and Clustering"),
    *Classification and Clustering*.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 图表显示了原始数据集中的32辆汽车在二维空间中的分布。元素之间的距离是通过MDS计算的，它考虑了所有11个原始变量，因此很容易识别出相似和非常不同的汽车类型。我们将在下一章中更详细地介绍这些主题，[第10章](ch10.html
    "第10章。分类和聚类")，*分类和聚类*。
- en: Summary
  id: totrans-251
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we covered a number of ways to deal with multivariate data
    to reduce the number of available dimensions in the means of artificially computed
    continuous variables and to identify underlying, latent, and similarly numeric
    variables. On the other hand, sometimes it's rather difficult to describe reality
    with numbers and we should rather think in categories.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了几种处理多元数据的方法，以减少人工计算连续变量中的可用维度，并识别潜在的、隐含的和类似的数值变量。另一方面，有时用数字描述现实相当困难，我们更应该按类别思考。
- en: The next chapter will introduce new methods to define data types (clusters)
    and will also demonstrate how to classify elements with the help of available
    training data.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章将介绍新的方法来定义数据类型（聚类），并还将演示如何利用可用训练数据对元素进行分类。
