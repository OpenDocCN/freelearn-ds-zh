- en: Chapter 4. Example Topology – Twitter
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This chapter builds on the material from [Chapter 3](ch03.html "Chapter 3. Introducing
    Petrel"), *Introducing Petrel*. In this chapter, we''ll build a topology that
    demonstrates a number of new features and techniques. In particular, we''ll see
    how to:'
  prefs: []
  type: TYPE_NORMAL
- en: Implement a spout that reads from Twitter
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Build topology components based on third-party Python libraries
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Compute statistics and rankings over rolling time periods
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Read custom configuration settings from `topology.yaml`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use "tick tuples" to execute logic on a schedule
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Twitter analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Most of you have heard of Twitter, but if you have not, check out how Wikipedia
    describes Twitter:'
  prefs: []
  type: TYPE_NORMAL
- en: '*"an online social networking service that enables users to send and read short
    140-character messages called "tweets"."*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In 2013, users posted 400 million messages per day on Twitter. Twitter offers
    an API that gives developers real-time access to streams of tweets. On it, messages
    are public by default. The volume of messages, the availability of an API, and
    the public nature of tweets combine to make Twitter a valuable source of insights
    on current events, topics of interest, public sentiment, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Storm was originally developed at BackType to process tweets, and Twitter analysis
    is still a popular use case of Storm. You can see several examples on the Storm
    website at [https://storm.apache.org/documentation/Powered-By.html](https://storm.apache.org/documentation/Powered-By.html).
  prefs: []
  type: TYPE_NORMAL
- en: 'The topology in this chapter demonstrates how to read from Twitter''s real-time
    streaming API, computing a ranking of the most popular words. It''s a Python version
    of the "rolling top words" sample on the Storm website ([https://github.com/apache/storm/blob/master/examples/storm-starter/src/jvm/storm/starter/RollingTopWords.java](https://github.com/apache/storm/blob/master/examples/storm-starter/src/jvm/storm/starter/RollingTopWords.java)),
    and consists of the following components:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Twitter stream spout (`twitterstream.py`): This reads tweets from the Twitter
    sample stream.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Splitter bolt (`splitsentence.py`): This receives tweets and splits them into
    words. It is an improved version of the splitter bolt from [Chapter 3](ch03.html
    "Chapter 3. Introducing Petrel"), *Introducing Petrel*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rolling word count bolt (`rollingcount.py`): This receives words and counts
    the occurrences. It is similar to the word count bolt from [Chapter 3](ch03.html
    "Chapter 3. Introducing Petrel"), *Introducing Petrel*, but implements a rolling
    count (this means that the bolt periodically discards old data, so the word counts
    only consider recent messages).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Intermediate rankings bolt (`intermediaterankings.py`): This consumes word
    counts and periodically emits the *n* most frequently seen words.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Total rankings bolt (`totalrankings.py`): This is similar to the intermediate
    rankings bolt. It combines the intermediate rankings to produce an overall set
    of rankings.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Twitter's Streaming API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Twitter's public API is both powerful and flexible. It has many features for
    both posting and consuming tweets. Our application needs to receive and process
    tweets in real time. Twitter's streaming API was designed to solve this problem.
    In computer science, a *stream* is a sequence of data elements (in this case,
    tweets) made available over time.
  prefs: []
  type: TYPE_NORMAL
- en: The streaming API is explained in detail at [https://dev.twitter.com/streaming/overview](https://dev.twitter.com/streaming/overview).
    To use it, an application first creates a connection to Twitter. The connection
    remains open indefinitely to receive tweets.
  prefs: []
  type: TYPE_NORMAL
- en: The Streaming API offers several ways to choose which tweets your application
    receives. Our topology uses the so-called sample stream, which provides a small
    subset of all tweets arbitrarily chosen by Twitter. The sample stream is intended
    for demos and testing. Production applications generally use one of the other
    stream types. For more information about the available streams, refer to [https://dev.twitter.com/streaming/public](https://dev.twitter.com/streaming/public).
  prefs: []
  type: TYPE_NORMAL
- en: Creating a Twitter app to use the Streaming API
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before we can use Twitter''s Streaming API, Twitter requires us to create an
    app. This sounds complicated, but it''s quite easy to set up; basically, we just
    fill in a form on the website:'
  prefs: []
  type: TYPE_NORMAL
- en: If you don't have a Twitter account, create one at [https://twitter.com/](https://twitter.com/).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once you have an account, log in and go to [https://apps.twitter.com/](https://apps.twitter.com/).
    Click on **Create New App**. Fill in the form for creating an application. Leave
    the **Callback URL** field blank. The default access level is read-only, which
    means that this application can only read tweets; it can't post or make other
    changes. Read-only access is fine for this example. Finally, click on **Create
    your Twitter application**. You will be redirected to your app's page.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Click on the **Keys and Access Tokens** tab, then click on **Create my access
    token**. Twitter will generate an access token consisting of two parts: **Access
    Token** and **Access Token Secret**. While connecting to Twitter, your application
    will use this token along with **Consumer Key** and **Consumer Secret**.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The following screenshot shows the **Keys and Access Tokens** tab after generating
    the access token:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Creating a Twitter app to use the Streaming API](img/B03471_04_01.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: The topology configuration file
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now that we''ve set up a Twitter account with API access, we''re ready to create
    the topology. First, create `topology.yaml`. We first saw a basic `topology.yaml`
    file in [Chapter 3](ch03.html "Chapter 3. Introducing Petrel"), *Introducing Petrel*.
    Here, `topology.yaml` will also hold the connection parameters for Twitter. Enter
    the following text, replacing the four `oauth` values with your own Twitter credentials
    from [https://apps.twitter.com/](https://apps.twitter.com/):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The Twitter stream spout
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now, let''s look at the Twitter spout. Enter this code in `twitterstream.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'How does the spout communicate with Twitter? The Twitter API imposes a number
    of requirements on API clients:'
  prefs: []
  type: TYPE_NORMAL
- en: Connections must be encrypted using the Secure Sockets Layer (SSL)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: API clients must be authenticated using OAuth, a popular authentication protocol
    used to interact with secure web services
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Because it involves a long-lived connection, the streaming API involves more
    than a simple HTTP request
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fortunately, there is a library called **Tweepy** ([http://www.tweepy.org/](http://www.tweepy.org/))
    that implements these requirements in a simple and easy-to-use Python API. Tweepy
    provides a `Stream` class to connect to the Streaming API. It is used in `_get_tweets()`.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a Tweepy stream requires the four Twitter connection parameters listed
    earlier. We could hardcode these directly in our spout, but then we'd have to
    change the code if the connection parameters change. Instead, we put this information
    in the `topology.yaml` configuration file. Our spout reads these settings in the
    `initialize()` function. Storm calls this function when a task for this component
    starts up, passing it information about the environment and configuration. Here,
    the `initialize()` function captures the topology configuration in `self.conf`.
    This dictionary includes the `oauth` values.
  prefs: []
  type: TYPE_NORMAL
- en: The following sequence diagram shows how the spout communicates with Twitter,
    receives tweets, and emits them. You may have noticed that the spout creates a
    background thread. This thread receives the tweets from Tweepy and passes them
    to the main spout thread using a Python queue.
  prefs: []
  type: TYPE_NORMAL
- en: '![The Twitter stream spout](img/B03471_04_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Why does the spout use a thread? Often, threads are used to support concurrent
    processing. That's not the case here. Rather, there is simply a mismatch between
    the behavior of Tweepy and the Petrel spout API.
  prefs: []
  type: TYPE_NORMAL
- en: When reading from a Twitter stream, Tweepy blocks execution, calling an application-supplied
    event handler function for each tweet received.
  prefs: []
  type: TYPE_NORMAL
- en: In Petrel, the `nextTuple()` function on a spout must return from the function
    after each tuple.
  prefs: []
  type: TYPE_NORMAL
- en: Running Tweepy in a background thread that writes to a queue provides a simple
    and elegant solution to these conflicting requirements.
  prefs: []
  type: TYPE_NORMAL
- en: Splitter bolt
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The splitter bolt here is similar in structure to the one in [Chapter 3](ch03.html
    "Chapter 3. Introducing Petrel"), *Introducing Petrel*. This version has two improvements
    that make it more useful and realistic.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Ignore words that are so common that they are not interesting or useful in a
    "top words" list. This includes English words such as "the," as well as word-like
    terms that appear frequently in Tweets, such as "http," "https," and "rt."
  prefs: []
  type: TYPE_NORMAL
- en: Omit punctuation when splitting a Tweet into words.
  prefs: []
  type: TYPE_NORMAL
- en: A Python library called **Natural Language Toolkit** (**NLTK**) makes it easy
    to implement both. NLTK has many other fascinating, powerful language processing
    features, but those are beyond the scope of this book.
  prefs: []
  type: TYPE_NORMAL
- en: 'Enter this code in `splitsentence.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Rolling word count bolt
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The rolling word count bolt is similar to the word count bolt in [Chapter 3](ch03.html
    "Chapter 3. Introducing Petrel"), *Introducing Petrel*. The bolt in the earlier
    chapter simply accumulated the word counts indefinitely. This is not good for
    analyzing top words on Twitter, where popular topics can change from one moment
    to the next. Rather, we want counts that reflect the latest information. To do
    this, the rolling word count bolt stores data in time-based buckets. Then, it
    periodically discards buckets that exceed 5 minutes in age. Thus, the word counts
    from this bolt only consider the last 5 minutes of data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Enter the following code in `rollingcount.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The `SlotBasedCounter` stores a list of `numSlots` (five) count values for each
    word. Each slot stores `emitFrequencyInSeconds` (60) seconds of data. Count values
    more than 5 minutes old are discarded.
  prefs: []
  type: TYPE_NORMAL
- en: 'How does the bolt know when 60 seconds have elapsed? Storm makes this easy
    by providing a feature called **tick tuples**. This feature is useful when you
    need to execute some logic within your bolts as per a schedule. To use this feature,
    perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: In `getComponentConfiguration()`, return a dictionary containing a `topology.tick.tuple.freq.secs`
    key. The value is the desired number of seconds between ticks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In `process()`, check whether the tuple is a normal tuple or a tick tuple. When
    a tick tuple is received, the bolt should run its scheduled processing.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The intermediate rankings bolt
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The intermediate rankings bolt maintains a dictionary of the top `maxSize` (10)
    items ranked by occurrence count, and emits those items every `emitFrequencyInSeconds`
    (15) seconds. In production, the topology will run many instances of this bolt,
    with each of them maintaining the top words for a *subset* of the overall words
    seen. Having many instances of the same component allows the topology to process
    large numbers of tweets and easily keep all the counts in the memory, even if
    the number of distinct words is quite large.
  prefs: []
  type: TYPE_NORMAL
- en: 'Enter this code in `intermediaterankings.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The total rankings bolt
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The total rankings bolt is very similar to the intermediate rankings bolt. There
    is only one instance of this bolt in the topology. It receives the top words from
    each instance of that bolt, choosing the top `maxSize` (10) items overall.
  prefs: []
  type: TYPE_NORMAL
- en: 'Enter the following code in `totalrankings.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Defining the topology
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here is the `create.py` script that defines the structure of the topology:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The structure of this topology is similar to the word count topology from [Chapter
    3](ch03.html "Chapter 3. Introducing Petrel"), *Introducing Petrel*. `TotalRankingsBolt`
    has a new wrinkle. As described earlier, there is just one instance of this bolt,
    and it uses `globalGrouping()`, so all tuples from `IntermediateRankingsBolt`
    are sent to it.
  prefs: []
  type: TYPE_NORMAL
- en: You may be wondering why the topology needs both an intermediate ranking and
    a total ranking bolt. In order for us to know the top words overall, there needs
    to be a single bolt instance (total rankings) that sees across the entire tweet
    stream. But at high data rates, a single bolt can't possibly keep up with the
    traffic. The intermediate rankings bolt instances "shield" the total rankings
    bolt from this traffic, computing the top words for their slice of the tweet stream.
    This allows the final rankings bolt to compute the most common words overall,
    while consuming only a handful of the overall word counts. Elegant!
  prefs: []
  type: TYPE_NORMAL
- en: Running the topology
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We have a few more small items to address before we run the topology:'
  prefs: []
  type: TYPE_NORMAL
- en: Copy the `logconfig.ini` file from the second example in [Chapter 3](ch03.html
    "Chapter 3. Introducing Petrel"), *Introducing Petrel*, to this topology's directory.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Create a file called `setup.sh`. Petrel will package this script with the topology
    and run it at startup. This script installs the third-party Python libraries used
    by the topology. The file looks like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a file called `manifest.txt` with these two lines:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Before running the topology, let''s review the list of files that we''ve created.
    Make sure you have created these files correctly:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`topology.yaml`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`twitterstream.py`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`splitsentence.py`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`rollingcount.py`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`intermediaterankings.py`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`totalrankings.py`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`manifest.txt`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`setup.sh`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Run the topology with this command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Once the topology starts running, open another terminal in the `topology` directory.
    Enter the following command to see the `log` file for the total rankings bolt,
    sorted from oldest to newest:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'If this is the first time you''ve run the topology, there will be only one
    log file listed. A new file is created for each run. If there are several files
    listed, choose the most recent one. Enter this command to monitor the contents
    of the log file (the exact filename will be different on your system):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'About every 15 seconds, you will see log messages with the top 10 words in
    descending order of popularity, like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Running the topology](img/B03471_04_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we developed a complex topology using a number of new techniques
    and libraries. After reading this example, you should be ready to begin applying
    Petrel and Storm to solve real problems.
  prefs: []
  type: TYPE_NORMAL
- en: In the upcoming chapter, we'll take a closer look at some of Storm's built-in
    features that are useful while operating a cluster, such as logging and monitoring.
  prefs: []
  type: TYPE_NORMAL
