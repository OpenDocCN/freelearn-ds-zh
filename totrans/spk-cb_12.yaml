- en: Chapter 12. Optimizations and Performance Tuning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covers various optimizations and performance-tuning best practices
    when working with Spark.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: 'The chapter is divided into the following recipes:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Optimizing memory
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using compression to improve performance
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using serialization to improve performance
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Optimizing garbage collection
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Optimizing the level of parallelism
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding the future of optimization – project Tungsten
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before looking into various ways to optimize Spark, it is a good idea to look
    at the Spark internals. So far, we have looked at Spark at higher level, where
    focus was the functionality provided by the various libraries.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s start with redefining an RDD. Externally, an RDD is a distributed immutable
    collection of objects. Internally, it consists of the following five parts:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: Set of partitions (`rdd.getPartitions`)
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: List of dependencies on parent RDDs (`rdd.dependencies`)
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Function to compute a partition, given its parents
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Partitioner (optional) (`rdd.partitioner`)
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Preferred location of each partition (optional) (`rdd.preferredLocations`)
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The first three are needed for an RDD to be recomputed, in case the data is
    lost. When combined, it is called **lineage**. The last two parts are optimizations.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: A set of partitions is how data is divided into nodes. In case of HDFS, it means
    `InputSplits`, which are mostly the same as block (except when a record crosses
    block boundaries; in that case, it will be slightly bigger than a block).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s revisit our `wordCount` example to understand these five parts. This
    is how the RDD graph looks for `wordCount` at dataset level view:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: '![Introduction](img/3056_12_01.jpg)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
- en: 'Basically, this is how the flow goes:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: 'Load the `words` folder as an RDD:'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The following are the five parts of `words` RDD:'
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '| **Partitions** | One partition per hdfs inputsplit/block (`org.apache.spark.rdd.HadoopPartition`)
    |'
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| **Dependencies** | None |'
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| **Compute function** | Read the block |'
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| **Preferred location** | The hdfs block location |'
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| **Partitioner** | None |'
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: 'Tokenize the words from `words` RDD with each word on a separate line:'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The following are the five parts of `wordsFlatMap` RDD:'
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '| **Partitions** | Same as parent RDD, that is, `words` (`org.apache.spark.rdd.HadoopPartition`)
    |'
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| **Dependencies** | Same as parent RDD, that is, `words` (`org.apache.spark.OneToOneDependency`)
    |'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| **Compute function** | Compute parent and split each element and flattens
    the results |'
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| **Preferred location** | Ask parent |'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| **Partitioner** | None |'
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: 'Transform each word in `wordsFlatMap` RDD to (word,1) tuple:'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The following are the five parts of `wordsMap` RDD:'
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '| **Partitions** | Same as parent RDD, that is, wordsFlatMap (org.apache.spark.rdd.HadoopPartition)
    |'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| **Dependencies** | Same as parent RDD, that is, wordsFlatMap (org.apache.spark.OneToOneDependency)
    |'
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| **Compute function** | Compute parent and map it to PairRDD |'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| **Preferred Location** | Ask parent |'
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| **Partitioner** | None |'
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: 'Reduce all the values for a given key and sum them up:'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The following are the five parts of `wordCount` RDD:'
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '| **Partitions** | One per reduce task (`org.apache.spark.rdd.ShuffledRDDPartition`)
    |'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| **Dependencies** | Shuffle dependency on each parent (`org.apache.spark.ShuffleDependency`)
    |'
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| **Compute function** | Do addition on shuffled data |'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| **Preferred location** | None |'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| **Partitioner** | HashPartitioner (`org.apache.spark.HashPartitioner`) |'
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: 'This is how an RDD graph for `wordCount` looks at the partition level view:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: '![Introduction](img/3056_12_02.jpg)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
- en: Optimizing memory
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Spark is a complex distributed computing framework, and has many moving parts.
    Various cluster resources, such as memory, CPU, and network bandwidth, can become
    bottlenecks at various points. As Spark is an in-memory compute framework, the
    impact of the memory is the biggest.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: Another issue is that it is common for Spark applications to use a huge amount
    of memory, sometimes more than 100 GB. This amount of memory usage is not common
    in traditional Java applications.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: In Spark, there are two places where memory optimization is needed, and that
    is at the driver and at the executor level.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: 'You can use the following commands to set the driver memory:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: 'Spark shell:'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Spark submit:'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'You can use the following commands to set the executor memory:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: 'Spark shell:'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Spark submit:'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: To understand memory optimization, it is a good idea to understand how memory
    management works in Java. Objects reside in Heap in Java. Heap is created when
    JVM starts, and it can resize itself when needed (based on minimum and maximum
    size, that is, `-Xms` and `-Xmx`, respectively assigned in configuration).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: 'Heap is divided into two spaces or generations: young space and old space.
    The young space is reserved for the allocation of new objects. Young space consists
    of an area called **Eden** and two smaller survivor spaces. When the nursery becomes
    full, garbage is collected by running a special process called **young collection**,
    where all the objects, which have lived long enough, are promoted to old space.
    When the old space becomes full, the garbage is collected there by running a process
    called **old collection**.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: '![Optimizing memory](img/3056_12_03.jpg)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
- en: The logic behind nursery is that most objects have a very short life span. A
    young collection is designed to be fast at finding newly allocated objects and
    moving them to the old space.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: The JVM uses mark and sweep algorithm for garbage collection. Mark and sweep
    collection consists of two phases.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: During the mark phase, all the objects, which have live references, are marked
    alive, the rest are presumed candidates for garbage collection. During the sweep
    phase, the space occupied by garbage collectable candidates is added to the free
    list, that is, they are available to be allocated to new objects.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: There are two improvements to mark and sweep. One is **concurrent mark and sweep**
    (**CMS**) and the other is parallel mark and sweep. CMS focuses on lower latency,
    while the latter focuses on higher throughput. Both strategies have performance
    trade-offs. CMS does not do compaction, while parallel **garbage collector** (**GC**)
    performs whole-heap only compaction, which results in pause times. As a thumb
    rule, for real-time streaming, CMS should be used, and parallel GC otherwise.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: If you would like to have both low latency and high throughput, Java 1.7 update
    4 onwards has another option called **garbage-first GC** (**G1**). G1 is a server-style
    garbage collector, primarily meant for multicore machines with large memories.
    It is planned as a long-term replacement for CMS. So, to modify our thumb rule,
    if you are using Java 7 onwards, simply use G1.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: G1 partitions the heap into a set of equal-sized regions, where each set is
    a contiguous range of virtual memory. Each region is assigned a role like Eden,
    Survivor, and Old. G1 performs a concurrent global marking phase to determine
    the live references of objects throughout the heap. After the mark phase is over,
    G1 knows which regions are mostly empty. It collects in these regions first and
    this frees the larger amount of memory.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: '![Optimizing memory](img/3056_12_04.jpg)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
- en: The regions selected by G1 as candidates for garbage collection are garbage
    collected using evacuation. G1 copies objects from one or more regions of the
    heap to a single region on the heap, and it both compacts and frees up memory.
    This evacuation is performed in parallel on multiple cores to reduce pause times
    and increase throughput. So, each garbage collection round reduces fragmentation
    while working within user-defined pause times.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: 'There are three aspects in memory optimization in Java:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: Memory footprint
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cost of accessing objects in memory
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cost of garbage collection
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Java objects, in general, are fast to access but consume much more space than
    the actual data inside them.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: Using compression to improve performance
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Data compression involves encoding information using fewer bits than the original
    representation. Compression has an important role to play in big data technologies.
    It makes both storage and transport of data more efficient.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: When data is compressed, it becomes smaller, so both disk I/O and network I/O
    become faster. It also saves storage space. Every optimization has a cost, and
    the cost of compression comes in the form of added CPU cycles to compress and
    decompress data.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: Hadoop needs to split data to put them into blocks, irrespective of whether
    the data is compressed or not. Only few compression formats are splittable.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: Two most popular compression formats for big data loads are LZO and Snappy.
    Snappy is not splittable, while LZO is. Snappy, on the other hand, is a much faster
    format.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: If compression format is splittable like LZO, input file is first split into
    blocks and then compressed. Since compression happened at block level, decompression
    can happen at block level as well as node level.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: If compression format is not splittable, compression happens at file level and
    then it is split into blocks. In this case, blocks have to be merged back to file
    before they can be decompressed, so decompression cannot happen at node level.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: For supported compression formats, Spark will deploy codecs automatically to
    decompress, and no action is required from the user's side.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: Using serialization to improve performance
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Serialization plays an important part in distributed computing. There are two
    persistence (storage) levels, which support serializing RDDs:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: '`MEMORY_ONLY_SER`: This stores RDDs as serialized objects. It will create one
    byte array per partition'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`MEMORY_AND_DISK_SER`: This is similar to the `MEMORY_ONLY_SER`, but it spills
    partitions that do not fit in the memory to disk'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following are the steps to add appropriate persistence levels:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: 'Start the Spark shell:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Import the `StorageLevel` and implicits associated with it:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Create an RDD:'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Persist the RDD:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Though serialization reduces the memory footprint substantially, it adds extra
    CPU cycles due to deserialization.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: By default, Spark uses Java's serialization. Since the Java serialization is
    slow, the better approach is to use `Kryo` library. `Kryo` is much faster and
    sometimes even 10 times more compact than the default.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You can use `Kryo` by doing the following settings in your `SparkConf`:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: 'Start the Spark shell by setting `Kryo` as serializer:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '`Kryo` automatically registers most of the core Scala classes, but if you would
    like to register your own classes, you can use the following command:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Optimizing garbage collection
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: JVM garbage collection can be a challenge if you have a lot of short lived RDDs.
    JVM needs to go over all the objects to find the ones it needs to garbage collect.
    The cost of the garbage collection is proportional to the number of objects the
    GC needs to go through. Therefore, using fewer objects and the data structures
    that use fewer objects (simpler data structures, such as arrays) helps.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: Serialization also shines here as a byte array needs only one object to be garbage
    collected.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: By default, Spark uses 60 percent of the executor memory to cache RDDs and the
    rest 40 percent for regular objects. Sometimes, you may not need 60 percent for
    RDDs and can reduce this limit so that more space is available for object creation
    (less need for GC).
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You can set the memory allocated for RDD cache to 40 percent by starting the
    Spark shell and setting the memory fraction:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Optimizing the level of parallelism
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Optimizing the level of parallelism is very important to fully utilize the cluster
    capacity. In the case of HDFS, it means that the number of partitions is the same
    as the number of `InputSplits`, which is mostly the same as the number of blocks.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we will cover different ways to optimize the number of partitions.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Specify the number of partitions when loading a file into RDD with the following
    steps:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: 'Start the Spark shell:'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Load the RDD with a custom number of partitions as a second parameter:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Another approach is to change the default parallelism by performing the following
    steps:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: 'Start the Spark shell with the new value of default parallelism:'
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Check the default value of parallelism:'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Note
  id: totrans-136
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You can also reduce the number of partitions using an RDD method called `coalesce(numPartitions)`
    where `numPartitions` is the final number of partitions you would like. If you
    would like the data to be reshuffled over the network, you can call the RDD method
    called `repartition(numPartitions)` where `numPartitions` is the final number
    of partitions you would like.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the future of optimization – project Tungsten
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Project Tungsten, starting with Spark Version 1.4, is the initiative to bring
    Spark closer to bare metal. The goal of this project is to substantially improve
    the memory and CPU efficiency of the Spark applications and push the limits of
    underlying hardware.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: In distributed systems, conventional wisdom has been to always optimize network
    I/O as that has been the most scarce and bottlenecked resource. This trend has
    changed in the last few years. Network bandwidth, in the last 5 years, has changed
    from 1 gigabit per second to 10 gigabit per second.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: On similar lines, the disk bandwidth has increased from 50 MB/s to 500 MB/s
    and SSDs are being deployed more and more. CPU clock speed, on the other hand,
    was ~3 GHz 5 years back and is still the same. This has unseated the network and
    made CPU the new bottleneck in distributed processing.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-142
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Another trend that has put more load on CPU performance is the new compressed
    data formats such as Parquet. Both compression and serialization, as we have seen
    in the previous recipes in this chapter, lead to more CPU cycles. This trend has
    also pushed the need for CPU optimization to reduce the CPU cycle cost.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: On the similar lines, let's look at the memory footprint. In Java, GC does memory
    management. GC has done an amazing job at taking away the memory management from
    the programmer and making it transparent. To do this, Java has to put a lot of
    overhead, and that substantially increases the memory footprint. As an example,
    a simple String "abcd", which should ideally take 4 bytes, takes 48 bytes in Java.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: What if we do away with GC and manage memory manually like in lower-level programming
    languages such as C? Java does provide a way to do that since 1.7 version and
    it is called `sun.misc.Unsafe`. Unsafe essentially means that you can build long
    regions of memory without any safety checks. This is the first feature of project
    Tungsten.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: Manual memory management by leverage application semantics
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Manual memory management by leverage application semantics, which can be very
    risky if you do not know what you are doing, is a blessing with Spark. We used
    knowledge of data schema (DataFrames) to directly layout the memory ourselves.
    It not only gets rid of GC overheads, but lets you minimize the memory footprint.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 通过利用应用语义进行手动内存管理，如果你不知道自己在做什么，这可能会非常危险，但在Spark中却是一种祝福。我们利用对数据模式（DataFrames）的了解来直接布局内存。这不仅消除了GC开销，还让你最小化内存占用。
- en: The second point is storing data in CPU cache versus memory. Everyone knows
    CPU cache is great as it takes three cycles to get data from the main memory versus
    one cycle in cache. This is the second feature of project Tungsten.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 第二点是存储数据在CPU缓存与内存之间。众所周知，CPU缓存非常出色，因为它从主内存获取数据需要三个周期，而缓存中只需要一个周期。这是Tungsten项目的第二个特性。
- en: Using algorithms and data structures
  id: totrans-149
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用算法和数据结构
- en: Algorithms and data structures are used to exploit memory hierarchy and enable
    more cache-aware computation.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 算法和数据结构被用来利用内存层次结构并实现更缓存感知的计算。
- en: 'CPU caches are small pools of memory that store the data the CPU is going to
    need next. CPUs have two types of caches: instruction cache and data cache. Data
    caches are arranged in hierarchy of L1, L2, and L3:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: CPU缓存是存储CPU即将需要的数据的小型内存池。CPU有两种类型的缓存：指令缓存和数据缓存。数据缓存按L1、L2和L3的层次结构排列：
- en: L1 cache is the fastest and most expensive cache in a computer. It stores the
    most critical data and is the first place the CPU looks for information.
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: L1缓存是计算机中最快且最昂贵的缓存。它存储最关键的数据，是CPU寻找信息的第一个地方。
- en: L2 cache is slightly slower than L1, but still located on the same processor
    chip. It is the second place the CPU looks for information.
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: L2缓存比L1缓存略慢，但仍然位于同一处理器芯片上。这是CPU寻找信息的第二个地方。
- en: L3 cache is still slower, but is shared by all cores, such as DRAM (memory).
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: L3缓存仍然较慢，但由所有核心共享，例如DRAM（内存）。
- en: 'These can be seen in the following diagram:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 这些可以在以下图中看到：
- en: '![Using algorithms and data structures](img/3056_12_05.jpg)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![使用算法和数据结构](img/3056_12_05.jpg)'
- en: The third point is that Java is not very good at bytecode generation for things
    like expression evaluation. If this code generation is done manually, it is much
    more efficient. Code generation is the third feature of project Tungsten.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 第三点是Java在生成诸如表达式评估之类的字节码方面并不十分出色。如果这种代码生成是手动完成的，它将更加高效。代码生成是Tungsten项目的第三个特性。
- en: Code generation
  id: totrans-158
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 代码生成
- en: This involves exploiting modern compliers and CPUs to allow efficient operations
    directly on binary data. Project Tungsten is in its infancy at present and will
    have much wider support in version 1.5.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 这涉及到利用现代编译器和CPU来允许直接在二进制数据上高效操作。Tungsten项目目前还处于起步阶段，将在1.5版本中提供更广泛的支持。
