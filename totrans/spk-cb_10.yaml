- en: Chapter 10. Recommender Systems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Collaborative filtering using explicit feedback
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Collaborative filtering using implicit feedback
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following is Wikipedia''s definition of recommender systems:'
  prefs: []
  type: TYPE_NORMAL
- en: '*"Recommender systems are a subclass of information filtering system that seek
    to predict the ''rating'' or ''preference'' that user would give to an item."*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Recommender systems have gained immense popularity in recent years. Amazon
    uses them to recommend books, Netflix for movies, and Google News to recommend
    news stories. As the proof is in the pudding, here are some examples of the impact
    recommendations can have (source: Celma, Lamere, 2008):'
  prefs: []
  type: TYPE_NORMAL
- en: Two-thirds of the movies watched on Netflix are recommended
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 38 percent of the news clicks on Google News are recommended
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 35 percent of the sales at Amazon sales are the result of recommendations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As we have seen in the previous chapters, features and feature selection play
    a major role in the efficacy of machine learning algorithms. Recommender engine
    algorithms discover these features, called **latent features**, automatically.
    In short, there are latent features responsible for a user to like one movie and
    dislike another. If another user has corresponding latent features, there is a
    good chance that this person will also have a similar taste for movies.
  prefs: []
  type: TYPE_NORMAL
- en: 'To understand this better, let''s look at some sample movie ratings:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Movie | Rich | Bob | Peter | Chris |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| *Titanic* | 5 | 3 | 5 | ? |'
  prefs: []
  type: TYPE_TB
- en: '| *GoldenEye* | 3 | 2 | 1 | 5 |'
  prefs: []
  type: TYPE_TB
- en: '| *Toy Story* | 1 | ? | 2 | 2 |'
  prefs: []
  type: TYPE_TB
- en: '| *Disclosure* | 4 | 4 | ? | 4 |'
  prefs: []
  type: TYPE_TB
- en: '| *Ace Ventura* | 4 | ? | 4 | ? |'
  prefs: []
  type: TYPE_TB
- en: 'Our goal is to predict the missing entries shown with the ? symbol. Let''s
    see if we can find some features associated with movies. At first, you will look
    at the genres, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Movie | Genre |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| *Titanic* | Action, Romance |'
  prefs: []
  type: TYPE_TB
- en: '| *GoldenEye* | Action, Adventure, Thriller |'
  prefs: []
  type: TYPE_TB
- en: '| *Toy Story* | Animation, Children''s, Comedy |'
  prefs: []
  type: TYPE_TB
- en: '| *Disclosure* | Drama, Thriller |'
  prefs: []
  type: TYPE_TB
- en: '| *Ace Ventura* | Comedy |'
  prefs: []
  type: TYPE_TB
- en: Now each movie can be rated for each genre from 0 to 1\. For example, *GoldenEye*
    is not primarily a romance, so it may have 0.1 rating for romance, but 0.98 rating
    for action. Therefore, each movie can be represented as a feature vector.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this chapter, we are going to use the MovieLens dataset from [grouplens.org/datasets/movielens/](http://grouplens.org/datasets/movielens/).
  prefs: []
  type: TYPE_NORMAL
- en: The InfoObjects big data sandbox comes loaded with 100k movie ratings. From
    GroupLens you can also download 1 million-or even up to 10 million-ratings if
    you would like to analyze bigger dataset for better predictions.
  prefs: []
  type: TYPE_NORMAL
- en: 'We are going to use two files from this dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '`u.data`: This has a tab-separated list of movie ratings in the following format:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Since we are not going to need the time stamp, we are going to filter it out
    from the data in our recipe
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`u.item`: This has a tab-separated list of movies in the following format:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This chapter will cover how we can make recommendations using MLlib, the Spark's
    machine learning library.
  prefs: []
  type: TYPE_NORMAL
- en: Collaborative filtering using explicit feedback
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Collaborative filtering is the most commonly used technique for recommender
    systems. It has an interesting property—it learns the features on its own. So,
    in the case of movie ratings, we do not need to provide actual human feedback
    on whether the movie is romantic or action.
  prefs: []
  type: TYPE_NORMAL
- en: As we saw in the *Introduction* section that movies have some latent features,
    such as genre, in the same way users have some latent features, such as age, gender,
    and more. Collaborative filtering does not need them, and figures out latent features
    on its own.
  prefs: []
  type: TYPE_NORMAL
- en: 'We are going to use an algorithm called **Alternating Least Squares** (**ALS**)
    in this example. This algorithm explains the association between a movie and a
    user based on a small number of latent features. It uses three training parameters:
    rank, number of iterations, and lambda (explained later in the chapter). The best
    way to figure out the optimum values of these three parameters is to try different
    values and see which value has the smallest amount of **Root Mean Square Error**
    (**RMSE**). This error is like a standard deviation, but it is based on model
    results rather than actual data.'
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Upload the `moviedata` downloaded from GroupLens to the `moviedata` folder
    in `hdfs`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: We are going to add some personalized ratings to this database so that we can
    test the accuracy of the recommendations.
  prefs: []
  type: TYPE_NORMAL
- en: You can look at `u.item` to pick some movies and rate them. The following are
    some movies I chose, alongside my ratings. Feel free to choose the movies you
    would like to rate and provide your own ratings.
  prefs: []
  type: TYPE_NORMAL
- en: '| Movie ID | Movie name | Rating (1-5) |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 313 | *Titanic* | 5 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | *GoldenEye* | 3 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | *Toy Story* | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 43 | *Disclosure* | 4 |'
  prefs: []
  type: TYPE_TB
- en: '| 67 | *Ace Ventura* | 4 |'
  prefs: []
  type: TYPE_TB
- en: '| 82 | *Jurassic Park* | 5 |'
  prefs: []
  type: TYPE_TB
- en: '| 96 | *Terminator 2* | 5 |'
  prefs: []
  type: TYPE_TB
- en: '| 121 | *Independence Day* | 4 |'
  prefs: []
  type: TYPE_TB
- en: '| 148 | *The Ghost and the Darkness* | 4 |'
  prefs: []
  type: TYPE_TB
- en: 'The highest user ID is 943, so we are going to add the new user as 944\. Let''s
    create a new comma-separated file `p.data` with the following data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Upload the personalized movie data to `hdfs`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Import the ALS and rating classes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Load the rating data into an RDD:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Transform the `val data` into the RDD of rating:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Load the personalized rating data into the RDD:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Transform the data into the RDD of personalized rating:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Combine ratings with personalized ratings:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Build the model using ALS with rank 5 and 10 iterations and 0.01 as lambda:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Let's predict what my rating would be for a given movie based on this model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Let''s start with original *Terminator* with movie ID 195:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Since I rated *Terminator* *2* 5, this is a reasonable prediction.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Let''s try *Ghost* with movie ID 402:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: It's a reasonable guess.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Let''s try *The Ghost and the Darkness*, the movie I already rated, with the
    ID 148:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Very close prediction, knowing that I rated the movie 4.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You can use more movies to the `train` dataset. There are also 1 million and
    10 million rating datasets available that will refine the algorithm even more.
  prefs: []
  type: TYPE_NORMAL
- en: Collaborative filtering using implicit feedback
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Sometimes the feedback available is not in the form of ratings but in the form
    of audio tracks played, movies watched, and so on. This data, at first glance,
    may not look as good as explicit ratings by users, but this is much more exhaustive.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We are going to use million song data from [http://www.kaggle.com/c/msdchallenge/data](http://www.kaggle.com/c/msdchallenge/data).
    You need to download three files:'
  prefs: []
  type: TYPE_NORMAL
- en: '`kaggle_visible_evaluation_triplets`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`kaggle_users.txt`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`kaggle_songs.txt`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a `songdata` folder in `hdfs` and put all the three files here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Upload the song data to `hdfs`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We still need to do some more preprocessing. ALS in MLlib takes both user and
    product IDs as integer. The `Kaggle_songs.txt` file has song IDs and sequence
    number next to it, The `Kaggle_users.txt` file does not have it. Our goal is to
    replace the `userid` and `songid` in `triplets` data with the corresponding integer
    sequence numbers. To do this, follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Load the `kaggle_songs` data as an RDD:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Load the user data as an RDD:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Load the triplets (user, song, plays) data as an RDD:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Convert the song data into the `PairRDD`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Collect the `songIndex` as Map:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Convert the user data into the `PairRDD`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Collect the `userIndex` as Map:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We will need both `songMap` and `userMap` to replace `userId` and `songId` in
    triplets. Spark will automatically make both these maps available on the cluster
    as needed. This works fine but is expensive to send across the cluster every time
    it is needed.
  prefs: []
  type: TYPE_NORMAL
- en: A better approach is to use a Spark feature called `broadcast` variables. The
    `broadcast` variables allow the Spark job to keep a read-only copy of a variable
    cached on each machine, rather than shipping a copy with each task. Spark distributes
    broadcast variables using efficient broadcast algorithms, so communication cost
    over the network is negligible.
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can guess, both `songMap` and `userMap` are good candidates to be wrapped
    around the `broadcast` variables. Perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Broadcast the `userMap`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Broadcast the `songMap`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Convert the `triplet` into an array:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Import the rating:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Convert the `triplet` array into an RDD of rating objects:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now, our data is ready to do the modeling and prediction.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Import ALS:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Build a model using the ALS with rank 10 and 10 iterations:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Extract the user and song tuples from the triplet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Make predictions for the user and song tuples:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Our model takes four parameters to work, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Parameter name | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Rank | Number of latent features in the model |'
  prefs: []
  type: TYPE_TB
- en: '| Iterations | Number of iterations for this factorization to run |'
  prefs: []
  type: TYPE_TB
- en: '| Lambda | Over fitting parameter |'
  prefs: []
  type: TYPE_TB
- en: '| Alpha | Relative weight of observed interactions |'
  prefs: []
  type: TYPE_TB
- en: As you saw in the case of gradient descent, these parameters need to be set
    by hand. We can try different values, but the value that works best is rank=50,
    iterations=30, lambda=0.00001, and alpha= 40.
  prefs: []
  type: TYPE_NORMAL
- en: There's more…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One way to test different parameters quickly is to spawn a spark cluster on
    Amazon EC2\. This gives you flexibility to go with a powerful instance to test
    these parameters fast. I have created a public s3 bucket `com.infoobjects.songdata`
    to pull data to Spark.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the steps you need to follow to load the data from S3 and run the
    ALS:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: These are the predictions made on the `usersSongs` matrix.
  prefs: []
  type: TYPE_NORMAL
