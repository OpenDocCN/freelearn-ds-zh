- en: Chapter 5. Using GPUs to Run R Even Faster
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 5 章：使用 GPU 使 R 运行更快
- en: In this chapter, we will look at another means to speed up the execution of
    an R code using a technology that is often untapped, although it is part of most
    computers—the **Graphics Processing Unit** (**GPU**), otherwise known as a graphics
    card. When we think of a GPU, we often think of the amazing graphics it can produce.
    In fact, GPUs are powered by technologies with highly parallel processing capabilities
    that are like the top supercomputers in the world. In the past, programming with
    GPUs was very difficult. However, in the last few years, this barrier has been
    removed with GPU programming platforms like CUDA and OpenCL that make programming
    with GPUs accessible for many programmers. Better still, the R community has developed
    a few packages for R users to leverage the computing power of GPUs.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨另一种方法来加速 R 代码的执行，这种方法通常未被充分利用，尽管它是大多数计算机的一部分——**图形处理单元**（**GPU**），也称为显卡。当我们想到
    GPU 时，我们常常想到它能够产生的惊人图形。实际上，GPU 由具有高度并行处理能力的科技驱动，这些科技类似于世界上顶级的超级计算机。在过去，使用 GPU
    进行编程非常困难。然而，在过去的几年里，随着 CUDA 和 OpenCL 等GPU 编程平台的推出，编程 GPU 对许多程序员来说变得容易多了。更好的是，R
    社区为 R 用户开发了一些包，以便利用 GPU 的计算能力。
- en: To run the examples in this chapter, you will need an NVIDIA GPU with CUDA capabilities.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行本章中的示例，您需要一个具有 CUDA 功能的 NVIDIA GPU。
- en: 'This chapter covers:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖：
- en: General purpose computing on GPUs
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPU 上的通用计算
- en: R and GPUs
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: R 和 GPU
- en: Fast statistical modeling in R with `gputools`
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `gputools` 在 R 中进行快速统计建模
- en: General purpose computing on GPUs
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GPU 上的通用计算
- en: Historically, GPUs were designed and used to render high-resolution graphics
    such as for video games. To be able to render millions of pixels every second,
    GPUs utilize a highly parallel architecture that specializes in the types of computations
    required to render graphics. At a high level, the architecture of a GPU is similar
    to that of a CPU—it has its own multi-core processor and memory. However, because
    GPUs are not designed for general computation, individual cores are much simpler
    with slower clock speeds and limited support for complex instructions, compared
    to CPUs. In addition, they typically have less RAM than CPUs. To achieve real-time
    rendering, most GPU computations are done in a highly parallel manner, with many
    more cores than CPUs—a modern GPU might have more than 2,000 cores. Given that
    one core can run multiple threads, it is possible to run tens of thousands of
    parallel threads on a GPU.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 从历史上看，GPU 是设计和用于渲染高分辨率图形的，例如用于视频游戏。为了能够每秒渲染数百万个像素，GPU 利用高度并行的架构，专门用于渲染图形所需的计算类型。从高层次来看，GPU
    的架构类似于 CPU 的架构——它有自己的多核处理器和内存。然而，由于 GPU 不是为通用计算设计的，与 CPU 相比，单个核心要简单得多，时钟速度较慢，对复杂指令的支持有限。此外，它们通常比
    CPU 少有 RAM。为了实现实时渲染，大多数 GPU 计算都是以高度并行的方式进行的，拥有比 CPU 多得多的核心——现代 GPU 可能拥有超过 2,000
    个核心。鉴于一个核心可以运行多个线程，在 GPU 上可以运行数万个并行线程。
- en: In 1990s, programmers began to realize that certain computations outside of
    graphics rendering can benefit from the highly parallel architecture of GPUs.
    Remember the embarrassingly parallel nature of vectorized operations in R from
    [Chapter 3](ch03.html "Chapter 3. Simple Tweaks to Make R Run Faster"), *Simple
    Tweaks to Make R Run Faster*; imagine the potential speedup if they were done
    simultaneously by thousands of GPU cores. This awareness gave rise to general
    purpose computing on GPUs (GPGPU).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在 20 世纪 90 年代，程序员开始意识到，某些图形渲染之外的计算可以从 GPU 的高度并行架构中受益。还记得 R 中 [第 3 章](ch03.html
    "第 3 章。通过简单调整使 R 运行更快") 中向量操作的尴尬并行性吗，*通过简单调整使 R 运行更快*；想象一下，如果它们由数千个 GPU 核心同时完成，会有多大的加速潜力。这种认识催生了
    GPU 上的通用计算（GPGPU）。
- en: But it was challenging to program GPUs. Using low-level interfaces provided
    by standards like DirectX and OpenGL, programmers had to trick the GPUs to compute
    on numbers as if they were rendering graphics. Realizing this challenge, efforts
    sprung up to develop proper programming languages and the supporting architectures
    for GPGPU. The chief outcomes from these efforts are two technologies called CUDA,
    developed by NVIDIA, and OpenCL, developed by Apple and now maintained by Khronos.
    While CUDA is proprietary and works only on NVIDIA GPUs, OpenCL is brand agnostic
    and is even able to support other accelerators like **Field Programmable Gate
    Arrays** (**FPGAs**).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 但编程GPU具有挑战性。使用由DirectX和OpenGL等标准提供的低级接口，程序员必须欺骗GPU以计算数字，就像它们在渲染图形一样。意识到这一挑战，人们开始努力开发适合GPGPU的适当编程语言和支持架构。这些努力的成果是两种称为CUDA和OpenCL的技术，分别由NVIDIA和Apple开发，现在由Khronos维护。虽然CUDA是专有的，并且仅在NVIDIA
    GPU上工作，但OpenCL是品牌无关的，甚至能够支持其他加速器，如**现场可编程门阵列**（**FPGAs**）。
- en: R and GPUs
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: R和GPU
- en: 'The R community has developed a few packages for R programmers to leverage
    GPUs. The vectorized nature of R makes the use of GPUs a natural fit. The packages
    vary in the level of encapsulation and hence the required familiarity with the
    native CUDA or OpenCL languages. A selection of R packages for GPU programming
    are listed here:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: R社区已经开发了一些包，供R程序员利用GPU。R的矢量化特性使得使用GPU成为一种自然的选择。这里列出了用于GPU编程的一些R包：
- en: '`gputools`: This provides R functions that wrap around GPU-based algorithms
    for common operations, such as linear models and matrix algebra. It requires CUDA,
    and hence an NVIDIA GPU.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gputools`: 这提供了围绕基于GPU的算法的R函数，用于常见操作，如线性模型和矩阵代数。它需要CUDA，因此需要一个NVIDIA GPU。'
- en: '`gmatrix`: This provides the `gmatrix` and `gvector` classes to represent matrices
    and vectors respectively in NVIDIA GPUs. It also provides functions for common
    matrix operations such as matrix algebra, and random number generation and sorting.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gmatrix`: 这提供了`gmatrix`和`gvector`类，分别用于在NVIDIA GPU上表示矩阵和向量。它还提供了用于常见矩阵操作（如矩阵代数、随机数生成和排序）的函数。'
- en: '`RCUDA`: This provides a low-level interface to load and call a CUDA kernel
    from an R session. Using RCUDA requires a good understanding of the CUDA language,
    but allows more flexibility and code optimization. More information about t can
    be found at [http://www.omegahat.org/RCUDA/](http://www.omegahat.org/RCUDA/).'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RCUDA`: 这为从R会话中加载和调用CUDA内核提供了一个低级接口。使用RCUDA需要很好地理解CUDA语言，但允许更多的灵活性和代码优化。更多关于它的信息可以在[http://www.omegahat.org/RCUDA/](http://www.omegahat.org/RCUDA/)找到。'
- en: '`OpenCL`: This is similar to RCUDA, but interfaces with OpenCL. It caters to
    users that have non-NVIDIA GPUs like ATI, Intel, or AMD GPUs.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`OpenCL`: 这与RCUDA类似，但与OpenCL接口。它适用于拥有非NVIDIA GPU（如ATI、Intel或AMD GPU）的用户。'
- en: 'Other CRAN packages are available for more specialized functions on GPUs, such
    as linear regression. For a list of these packages, see the GPUs section of *CRAN
    Task View: High-Performance and Parallel Computing with R*, maintained by Dirk
    Eddelbuettel on the CRAN website at [http://cran.r-project.org/web/views/HighPerformanceComputing.html](http://cran.r-project.org/web/views/HighPerformanceComputing.html).'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 其他CRAN包可用于GPU上的更多专用功能，例如线性回归。有关这些包的列表，请参阅由Dirk Eddelbuettel在CRAN网站上维护的*CRAN任务视图：使用R进行高性能和并行计算*的GPU部分，网址为[http://cran.r-project.org/web/views/HighPerformanceComputing.html](http://cran.r-project.org/web/views/HighPerformanceComputing.html)。
- en: In this chapter, we will focus only on `gputools` and use a few examples from
    this package to illustrate how GPUs can speed up computations in R.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将仅关注`gputools`，并使用该包的一些示例来说明GPU如何加快R中的计算速度。
- en: Installing gputools
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装gputools
- en: 'These are the steps to install `gputools`:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 安装`gputools`的步骤如下：
- en: Make sure that your computer has a CUDA-enabled GPU card. For the list of CUDA-enabled
    GPUs, refer to [https://developer.nvidia.com/cuda-gpus](https://developer.nvidia.com/cuda-gpus).
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保您的计算机具有CUDA功能的GPU卡。有关CUDA功能GPU卡的列表，请参阅[https://developer.nvidia.com/cuda-gpus](https://developer.nvidia.com/cuda-gpus)。
- en: Download and install CUDA toolkit from [https://developer.nvidia.com/cuda-downloads](https://developer.nvidia.com/cuda-downloads).
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从[https://developer.nvidia.com/cuda-downloads](https://developer.nvidia.com/cuda-downloads)下载并安装CUDA工具包。
- en: Set a few environment variables as specified in the `gputools` installation
    note [http://cran.r-project.org/web/packages/gputools/INSTALL](http://cran.r-project.org/web/packages/gputools/INSTALL).
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据指定的 `gputools` 安装说明设置一些环境变量 [http://cran.r-project.org/web/packages/gputools/INSTALL](http://cran.r-project.org/web/packages/gputools/INSTALL)。
- en: Open an R session and run `install.packages("gputools")`.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个 R 会话并运行 `install.packages("gputools")`。
- en: If you do not have an NVIDIA GPU with CUDA capabilities, **Amazon Web Services**
    (**AWS**) offers GPU instances, called `g2.2xlarge` instances, that come with
    (at the time of writing) NVIDIA GRID K520 GPUs with 1,536 CUDA cores and 4 GB
    of video memory. You can use these instances together with **Amazon Machine Images**
    (**AMIs**) provided by NVIDIA that are preloaded with the CUDA toolkit and drivers.
    Both Windows and Linux AMIs are available at [https://aws.amazon.com/marketplace/seller-profile/ref=sp_mpg_product_vendor?ie=UTF8&id=c568fe05-e33b-411c-b0ab-047218431da9](https://aws.amazon.com/marketplace/seller-profile/ref=sp_mpg_product_vendor?ie=UTF8&id=c568fe05-e33b-411c-b0ab-047218431da9).
    For this chapter, we used the Linux AMI version 2014.03.2.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你没有具有 CUDA 功能的 NVIDIA GPU，**亚马逊网络服务**（**AWS**）提供名为 `g2.2xlarge` 的 GPU 实例，在撰写本文时，这些实例配备了
    NVIDIA GRID K520 GPU，具有 1,536 个 CUDA 核心和 4 GB 的视频内存。你可以使用这些实例以及 NVIDIA 提供的预装了
    CUDA 工具包和驱动程序的 **亚马逊机器镜像**（**AMIs**）。Windows 和 Linux AMIs 都可在 [https://aws.amazon.com/marketplace/seller-profile/ref=sp_mpg_product_vendor?ie=UTF8&id=c568fe05-e33b-411c-b0ab-047218431da9](https://aws.amazon.com/marketplace/seller-profile/ref=sp_mpg_product_vendor?ie=UTF8&id=c568fe05-e33b-411c-b0ab-047218431da9)
    找到。对于本章，我们使用了 Linux AMI 版本 2014.03.2。
- en: Fast statistical modeling in R with gputools
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 gputools 在 R 中进行快速统计建模
- en: '`gputools` provides a convenient way to execute statistical functions on a
    GPU, without CUDA programming. All the heavy lifting, including copying data from
    RAM to GPU memory and setting the number of cores to use have been encapsulated
    within the functions (in fact, `gputools` relies on the well-encapsulated `CUBLAS`
    library, which provides linear algebra functions for GPUs). For example, to perform
    linear modeling on the `mtcars` dataset on a CPU, we use the `lm()`: `lm(mpg~cyl+disp+hp,
    data=mtcars)` function. To run it on a GPU, we call the `gpuLm()` function from
    `gputools`: `gpuLm(mpg~cyl+disp+hp, data=mtcars)`. The output of `gpuLm()` follows
    the same format as `lm()`.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '`gputools` 提供了一种在 GPU 上执行统计函数的便捷方式，无需 CUDA 编程。所有繁重的工作，包括将数据从 RAM 复制到 GPU 内存以及设置要使用的核心数，都已封装在函数中（实际上，`gputools`
    依赖于封装良好的 `CUBLAS` 库，该库为 GPU 提供线性代数函数）。例如，要在 CPU 上对 `mtcars` 数据集执行线性建模，我们使用 `lm()`
    函数：`lm(mpg~cyl+disp+hp, data=mtcars)`。要在 GPU 上运行它，我们调用 `gputools` 中的 `gpuLm()`
    函数：`gpuLm(mpg~cyl+disp+hp, data=mtcars)`。`gpuLm()` 的输出格式与 `lm()` 相同。'
- en: 'To demonstrate the speedup that we can expect from a GPU, we will calculate
    Kendall correlations on random datasets having 100 variables. We will use a varying
    number of observations from 100, 200, … to 500 records in order to observe the
    speedup in comparison to the CPU version. The code is as follows:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示我们可以从 GPU 获得的加速效果，我们将对具有 100 个变量的随机数据集计算肯德尔相关系数。我们将使用从 100、200、… 到 500 个记录的不同观察数，以便观察与
    CPU 版本相比的加速效果。代码如下：
- en: '[PRE0]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We tested this code on an NVIDIA GRID K520 GPU from AWS; the performance you
    get depends on your GPU. The computational times are plotted on the following
    figure. We see that the CPU version of the `cor()` correlation function scales
    super linearly with the number of records. On the other hand, the GPU version
    shows a very small increase in computation time as the number of records increases,
    as evident from the almost flat red line.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在 AWS 上的 NVIDIA GRID K520 GPU 上测试了此代码；你获得的效果取决于你的 GPU。计算时间在下面的图中进行了展示。我们看到，`cor()`
    相关函数的 CPU 版本随着记录数的增加呈超线性增长。另一方面，GPU 版本随着记录数的增加，计算时间几乎没有增加，这从几乎平坦的红色线条中可以看出。
- en: '![Fast statistical modeling in R with gputools](img/9263OS_05_01.jpg)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![使用 gputools 在 R 中进行快速统计建模](img/9263OS_05_01.jpg)'
- en: Computational times of calculating Kendall correlations in GPU versus CPU
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: GPU 与 CPU 计算肯德尔相关系数的计算时间
- en: 'Next, we will run timing comparisons for a few other functions available in
    `gputools`: linear model (`gpuLm()`), generalized linear model (`gpuGlm()`), distance
    matrix calculation (`gpuDist()`), and matrix multiplication (`gpuMatMult()`).
    The datasets used for these tests have 1,000 observations and 1,000 variables,
    except for `gpuLm`, where a dataset with 10,000 observations and 1,000 variables
    is used. The `microbenchmark()` function is used to compare the execution times
    of the CPU and GPU versions of these algorithms:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将对`gputools`中提供的其他几个函数进行计时比较：线性模型（`gpuLm()`）、广义线性模型（`gpuGlm()`）、距离矩阵计算（`gpuDist()`）和矩阵乘法（`gpuMatMult()`）。这些测试所使用的数据集有1,000个观测值和1,000个变量，除了`gpuLm`，它使用的是包含10,000个观测值和1,000个变量的数据集。使用`microbenchmark()`函数来比较这些算法的CPU和GPU版本的执行时间：
- en: '[PRE1]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The test results show the power of using GPU computations in R. However, just
    like any other parallel program, not all functions will enjoy faster performance
    when executed in a GPU. For example, running the correlation comparison for Pearson''s
    correlations (by changing the `method` argument from `kendall` to `pearson`),
    the GPU performs slower than the CPU as shown in the upcoming figure. Due to the
    extra sorting operations required by the Kendall correlation, it is known to be
    much more computationally intensive than the Pearson correlation (our benchmark
    here shows that computing the Kendall correlation is hundreds of times slower
    than computing the Pearson correlation). However, it seems that this implementation
    of the Kendall correlation algorithm is well suited for the highly parallel architecture
    of the GPU, resulting in the performance gains we saw in the first example of
    this chapter. The algorithm for computing the Pearson correlation, on the other
    hand, suffers when we switch from CPU to GPU suggesting that it is not suited
    for the GPU''s architecture. It is difficult to pinpoint exactly the reason for
    the differences in performance between the two algorithms without studying the
    details of the underlying CUDA code and the GPU''s architecture. Before deciding
    to use GPUs for a specific task, it is best to benchmark the relative performance
    of GPUs versus CPUs, as we have done here:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 测试结果展示了在R中使用GPU计算的力量。然而，就像任何其他并行程序一样，并不是所有函数在GPU上执行时都会获得更快的性能。例如，当运行皮尔逊相关性的比较（通过将`method`参数从`kendall`改为`pearson`）时，如图所示，GPU的性能比CPU慢。由于肯德尔相关性的额外排序操作，它已知比皮尔逊相关性计算量更大（我们的基准测试显示计算肯德尔相关性比计算皮尔逊相关性慢数百倍）。然而，似乎这种肯德尔相关性算法的实现非常适合GPU的高度并行架构，从而导致了我们在本章第一个例子中看到的性能提升。另一方面，计算皮尔逊相关性的算法在从CPU切换到GPU时表现不佳，这表明它不适合GPU的架构。没有研究底层CUDA代码和GPU架构的细节，很难确切指出两种算法性能差异的确切原因。在决定为特定任务使用GPU之前，最好是像我们在这里所做的那样，对GPU与CPU的相对性能进行基准测试：
- en: '![Fast statistical modeling in R with gputools](img/9263OS_05_02.jpg)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![使用gputools在R中快速进行统计建模](img/9263OS_05_02.jpg)'
- en: Computation times of calculating Pearson correlations in GPU versus CPU
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在GPU与CPU中计算皮尔逊相关性的计算时间
- en: 'In general, these factors can affect the GPU''s performance:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，以下因素会影响GPU的性能：
- en: GPUs work best for data parallel problems (see [Chapter 8](ch08.html "Chapter 8. Multiplying
    Performance with Parallel Computing"), *Multiplying Performance with Parallel
    Computing* for a definition of data parallelism). They are not suited for tasks
    that require large amounts of synchronization between threads.
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPU最适合处理数据并行问题（参见第8章[Chapter 8](ch08.html "Chapter 8. Multiplying Performance
    with Parallel Computing")，“通过并行计算提高性能”，以了解数据并行的定义）。它们不适合需要大量线程间同步的任务。
- en: GPU's performance depends on the amount of data transferred between the main
    memory (RAM) and the GPU's memory, because the connection between the RAM and
    GPU's memory has a low bandwidth. Good GPU programming should minimize this data
    transfer.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPU的性能取决于主内存（RAM）和GPU内存之间传输的数据量，因为RAM和GPU内存之间的连接带宽较低。良好的GPU编程应该尽量减少这种数据传输。
- en: Addressing these factors requires programming in the low-level GPU interfaces
    provided by RCUDA or OpenCL. Other efforts are being made to minimize the efforts
    required by programmers to optimize a CUDA or OpenCL code. For example, to address
    the RAM-GPU memory bottleneck, AMD has released a GPU that combines the RAM and
    GPU memories in a single card.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这些因素需要使用RCUDA或OpenCL提供的低级GPU接口进行编程。其他努力正在被做出以最小化程序员优化CUDA或OpenCL代码所需的工作量。例如，为了解决RAM-GPU内存瓶颈，AMD发布了一款将RAM和GPU内存结合在一张卡上的GPU。
- en: Summary
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we learned how to speed certain computations in R by leveraging
    GPUs. Given that most computers today come with a GPU, this gives a quick opportunity
    to improve the performance of R programs. This is especially true with the growing
    number of packages that interface R with GPUs. Some, such as `gputools`, require
    no knowledge of CUDA or OpenCL at all. GPUs do not guarantee improved performance
    for all tasks.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了如何通过利用GPU来加速R中的某些计算。鉴于今天的大多数计算机都配备了GPU，这为提高R程序的性能提供了一个快速的机会。这对于与GPU接口的R包数量不断增长的情况尤其如此。其中一些，如`gputools`，甚至不需要了解CUDA或OpenCL。GPU并不保证所有任务都能提高性能。
- en: In the next chapter, we will turn our attention to address RAM-related issues
    in R programs.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将关注解决R程序中的RAM相关问题。
