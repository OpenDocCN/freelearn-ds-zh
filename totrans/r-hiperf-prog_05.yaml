- en: Chapter 5. Using GPUs to Run R Even Faster
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will look at another means to speed up the execution of
    an R code using a technology that is often untapped, although it is part of most
    computers—the **Graphics Processing Unit** (**GPU**), otherwise known as a graphics
    card. When we think of a GPU, we often think of the amazing graphics it can produce.
    In fact, GPUs are powered by technologies with highly parallel processing capabilities
    that are like the top supercomputers in the world. In the past, programming with
    GPUs was very difficult. However, in the last few years, this barrier has been
    removed with GPU programming platforms like CUDA and OpenCL that make programming
    with GPUs accessible for many programmers. Better still, the R community has developed
    a few packages for R users to leverage the computing power of GPUs.
  prefs: []
  type: TYPE_NORMAL
- en: To run the examples in this chapter, you will need an NVIDIA GPU with CUDA capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter covers:'
  prefs: []
  type: TYPE_NORMAL
- en: General purpose computing on GPUs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: R and GPUs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fast statistical modeling in R with `gputools`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: General purpose computing on GPUs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Historically, GPUs were designed and used to render high-resolution graphics
    such as for video games. To be able to render millions of pixels every second,
    GPUs utilize a highly parallel architecture that specializes in the types of computations
    required to render graphics. At a high level, the architecture of a GPU is similar
    to that of a CPU—it has its own multi-core processor and memory. However, because
    GPUs are not designed for general computation, individual cores are much simpler
    with slower clock speeds and limited support for complex instructions, compared
    to CPUs. In addition, they typically have less RAM than CPUs. To achieve real-time
    rendering, most GPU computations are done in a highly parallel manner, with many
    more cores than CPUs—a modern GPU might have more than 2,000 cores. Given that
    one core can run multiple threads, it is possible to run tens of thousands of
    parallel threads on a GPU.
  prefs: []
  type: TYPE_NORMAL
- en: In 1990s, programmers began to realize that certain computations outside of
    graphics rendering can benefit from the highly parallel architecture of GPUs.
    Remember the embarrassingly parallel nature of vectorized operations in R from
    [Chapter 3](ch03.html "Chapter 3. Simple Tweaks to Make R Run Faster"), *Simple
    Tweaks to Make R Run Faster*; imagine the potential speedup if they were done
    simultaneously by thousands of GPU cores. This awareness gave rise to general
    purpose computing on GPUs (GPGPU).
  prefs: []
  type: TYPE_NORMAL
- en: But it was challenging to program GPUs. Using low-level interfaces provided
    by standards like DirectX and OpenGL, programmers had to trick the GPUs to compute
    on numbers as if they were rendering graphics. Realizing this challenge, efforts
    sprung up to develop proper programming languages and the supporting architectures
    for GPGPU. The chief outcomes from these efforts are two technologies called CUDA,
    developed by NVIDIA, and OpenCL, developed by Apple and now maintained by Khronos.
    While CUDA is proprietary and works only on NVIDIA GPUs, OpenCL is brand agnostic
    and is even able to support other accelerators like **Field Programmable Gate
    Arrays** (**FPGAs**).
  prefs: []
  type: TYPE_NORMAL
- en: R and GPUs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The R community has developed a few packages for R programmers to leverage
    GPUs. The vectorized nature of R makes the use of GPUs a natural fit. The packages
    vary in the level of encapsulation and hence the required familiarity with the
    native CUDA or OpenCL languages. A selection of R packages for GPU programming
    are listed here:'
  prefs: []
  type: TYPE_NORMAL
- en: '`gputools`: This provides R functions that wrap around GPU-based algorithms
    for common operations, such as linear models and matrix algebra. It requires CUDA,
    and hence an NVIDIA GPU.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`gmatrix`: This provides the `gmatrix` and `gvector` classes to represent matrices
    and vectors respectively in NVIDIA GPUs. It also provides functions for common
    matrix operations such as matrix algebra, and random number generation and sorting.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`RCUDA`: This provides a low-level interface to load and call a CUDA kernel
    from an R session. Using RCUDA requires a good understanding of the CUDA language,
    but allows more flexibility and code optimization. More information about t can
    be found at [http://www.omegahat.org/RCUDA/](http://www.omegahat.org/RCUDA/).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`OpenCL`: This is similar to RCUDA, but interfaces with OpenCL. It caters to
    users that have non-NVIDIA GPUs like ATI, Intel, or AMD GPUs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Other CRAN packages are available for more specialized functions on GPUs, such
    as linear regression. For a list of these packages, see the GPUs section of *CRAN
    Task View: High-Performance and Parallel Computing with R*, maintained by Dirk
    Eddelbuettel on the CRAN website at [http://cran.r-project.org/web/views/HighPerformanceComputing.html](http://cran.r-project.org/web/views/HighPerformanceComputing.html).'
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will focus only on `gputools` and use a few examples from
    this package to illustrate how GPUs can speed up computations in R.
  prefs: []
  type: TYPE_NORMAL
- en: Installing gputools
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'These are the steps to install `gputools`:'
  prefs: []
  type: TYPE_NORMAL
- en: Make sure that your computer has a CUDA-enabled GPU card. For the list of CUDA-enabled
    GPUs, refer to [https://developer.nvidia.com/cuda-gpus](https://developer.nvidia.com/cuda-gpus).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Download and install CUDA toolkit from [https://developer.nvidia.com/cuda-downloads](https://developer.nvidia.com/cuda-downloads).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set a few environment variables as specified in the `gputools` installation
    note [http://cran.r-project.org/web/packages/gputools/INSTALL](http://cran.r-project.org/web/packages/gputools/INSTALL).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open an R session and run `install.packages("gputools")`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If you do not have an NVIDIA GPU with CUDA capabilities, **Amazon Web Services**
    (**AWS**) offers GPU instances, called `g2.2xlarge` instances, that come with
    (at the time of writing) NVIDIA GRID K520 GPUs with 1,536 CUDA cores and 4 GB
    of video memory. You can use these instances together with **Amazon Machine Images**
    (**AMIs**) provided by NVIDIA that are preloaded with the CUDA toolkit and drivers.
    Both Windows and Linux AMIs are available at [https://aws.amazon.com/marketplace/seller-profile/ref=sp_mpg_product_vendor?ie=UTF8&id=c568fe05-e33b-411c-b0ab-047218431da9](https://aws.amazon.com/marketplace/seller-profile/ref=sp_mpg_product_vendor?ie=UTF8&id=c568fe05-e33b-411c-b0ab-047218431da9).
    For this chapter, we used the Linux AMI version 2014.03.2.
  prefs: []
  type: TYPE_NORMAL
- en: Fast statistical modeling in R with gputools
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`gputools` provides a convenient way to execute statistical functions on a
    GPU, without CUDA programming. All the heavy lifting, including copying data from
    RAM to GPU memory and setting the number of cores to use have been encapsulated
    within the functions (in fact, `gputools` relies on the well-encapsulated `CUBLAS`
    library, which provides linear algebra functions for GPUs). For example, to perform
    linear modeling on the `mtcars` dataset on a CPU, we use the `lm()`: `lm(mpg~cyl+disp+hp,
    data=mtcars)` function. To run it on a GPU, we call the `gpuLm()` function from
    `gputools`: `gpuLm(mpg~cyl+disp+hp, data=mtcars)`. The output of `gpuLm()` follows
    the same format as `lm()`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To demonstrate the speedup that we can expect from a GPU, we will calculate
    Kendall correlations on random datasets having 100 variables. We will use a varying
    number of observations from 100, 200, … to 500 records in order to observe the
    speedup in comparison to the CPU version. The code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: We tested this code on an NVIDIA GRID K520 GPU from AWS; the performance you
    get depends on your GPU. The computational times are plotted on the following
    figure. We see that the CPU version of the `cor()` correlation function scales
    super linearly with the number of records. On the other hand, the GPU version
    shows a very small increase in computation time as the number of records increases,
    as evident from the almost flat red line.
  prefs: []
  type: TYPE_NORMAL
- en: '![Fast statistical modeling in R with gputools](img/9263OS_05_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Computational times of calculating Kendall correlations in GPU versus CPU
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we will run timing comparisons for a few other functions available in
    `gputools`: linear model (`gpuLm()`), generalized linear model (`gpuGlm()`), distance
    matrix calculation (`gpuDist()`), and matrix multiplication (`gpuMatMult()`).
    The datasets used for these tests have 1,000 observations and 1,000 variables,
    except for `gpuLm`, where a dataset with 10,000 observations and 1,000 variables
    is used. The `microbenchmark()` function is used to compare the execution times
    of the CPU and GPU versions of these algorithms:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The test results show the power of using GPU computations in R. However, just
    like any other parallel program, not all functions will enjoy faster performance
    when executed in a GPU. For example, running the correlation comparison for Pearson''s
    correlations (by changing the `method` argument from `kendall` to `pearson`),
    the GPU performs slower than the CPU as shown in the upcoming figure. Due to the
    extra sorting operations required by the Kendall correlation, it is known to be
    much more computationally intensive than the Pearson correlation (our benchmark
    here shows that computing the Kendall correlation is hundreds of times slower
    than computing the Pearson correlation). However, it seems that this implementation
    of the Kendall correlation algorithm is well suited for the highly parallel architecture
    of the GPU, resulting in the performance gains we saw in the first example of
    this chapter. The algorithm for computing the Pearson correlation, on the other
    hand, suffers when we switch from CPU to GPU suggesting that it is not suited
    for the GPU''s architecture. It is difficult to pinpoint exactly the reason for
    the differences in performance between the two algorithms without studying the
    details of the underlying CUDA code and the GPU''s architecture. Before deciding
    to use GPUs for a specific task, it is best to benchmark the relative performance
    of GPUs versus CPUs, as we have done here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Fast statistical modeling in R with gputools](img/9263OS_05_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Computation times of calculating Pearson correlations in GPU versus CPU
  prefs: []
  type: TYPE_NORMAL
- en: 'In general, these factors can affect the GPU''s performance:'
  prefs: []
  type: TYPE_NORMAL
- en: GPUs work best for data parallel problems (see [Chapter 8](ch08.html "Chapter 8. Multiplying
    Performance with Parallel Computing"), *Multiplying Performance with Parallel
    Computing* for a definition of data parallelism). They are not suited for tasks
    that require large amounts of synchronization between threads.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GPU's performance depends on the amount of data transferred between the main
    memory (RAM) and the GPU's memory, because the connection between the RAM and
    GPU's memory has a low bandwidth. Good GPU programming should minimize this data
    transfer.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Addressing these factors requires programming in the low-level GPU interfaces
    provided by RCUDA or OpenCL. Other efforts are being made to minimize the efforts
    required by programmers to optimize a CUDA or OpenCL code. For example, to address
    the RAM-GPU memory bottleneck, AMD has released a GPU that combines the RAM and
    GPU memories in a single card.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned how to speed certain computations in R by leveraging
    GPUs. Given that most computers today come with a GPU, this gives a quick opportunity
    to improve the performance of R programs. This is especially true with the growing
    number of packages that interface R with GPUs. Some, such as `gputools`, require
    no knowledge of CUDA or OpenCL at all. GPUs do not guarantee improved performance
    for all tasks.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will turn our attention to address RAM-related issues
    in R programs.
  prefs: []
  type: TYPE_NORMAL
