- en: Chapter 12. Data Manipulation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, you learned the methods used to access different types
    of databases such as relational databases (SQLite and MySQL) and non-relational
    databases (MongoDB and Redis). Relational databases usually return data in a tabular
    form, while non-relational databases may support nested data structures and other
    features.
  prefs: []
  type: TYPE_NORMAL
- en: Even though the data is loaded into memory, it is usually far from ready for
    data analysis. Most data at this stage still needs cleaning and transforming,
    which, in fact, may take a large proportion of time before any statistical model
    and visualization can be applied. In this chapter, you'll learn about a set of
    built-in functions and several packages for data manipulation. The packages are
    extremely powerful. However, to better work with these packages, we need a concrete
    understanding of the knowledge introduced in the previous chapters.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we''ll cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Using basic functions to manipulate data frames
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using SQL to query data frames via the `sqldf` package
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using `data.table` to manipulate data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using `dplyr` pipelines to manipulate data frames
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using `rlist` to work with nested data structures
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using built-in functions to manipulate data frames
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Previously, you learned the basics of data frames. Here, we will review the
    built-in functions used to filter a data frame. Although a data frame is essentially
    a list of vectors, we can access it like a matrix since all column vectors are
    of the same length. To select rows that meet certain conditions, we will supply
    a logical vector as the first argument of `[]`, while the second is left empty.
  prefs: []
  type: TYPE_NORMAL
- en: In R, these operations can be done with built-in functions. In this section,
    we will introduce some built-in functions that are most helpful to manipulate
    data into the form we need as model input or for presentation. Some of the functions
    or techniques are already presented in the previous chapters.
  prefs: []
  type: TYPE_NORMAL
- en: 'Most of the code in this section and subsequent sections are based on a group
    of fictitious data about some products. We will use the `readr` package to load
    the data for better handling of column types. If you don''t have this package
    installed, run `install.packages("readr")`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the data is loaded into memory as a data frame, we can take a look at
    its column types:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The `readr::read_csv` argument has different behavior from the built-in function `read.csv`.
    For example, it does not automatically convert string columns to factors (which
    can be problematic, but adds little value). Therefore, I recommend that you use
    functions provided by `readr` to read tabular data from file into R. If we were
    using the `read.csv` file, then all these columns would be factors with limited
    possible values.
  prefs: []
  type: TYPE_NORMAL
- en: Using built-in functions to manipulate data frames
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Previously, you learned the basics of data frames. In this section, we will
    review the built-in functions to filter a data frame. Although a data frame is
    essentially a list of vectors, we can access it like a matrix since all column
    vectors are of the same length. To select rows that meet certain conditions, we
    will supply a logical vector as the first argument of `[]`, while the second is
    left empty. In the following examples, we will use a series of product information
    points and statistics we introduced earlier to demonstrate basic data-filtering
    methods and summary techniques.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, we will take out all rows of `toy` type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Alternatively, we could take out all rows that are not released:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'To filter columns, we will supply a character vector as the second argument
    while the first is left empty, which is exactly what we did when we subset a matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Alternatively, we can filter the data frame by regarding it as a list. We will
    supply only one character vector of column names in `[]` and omit the comma:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'To filter a data frame by both row and column, we will supply a vector as the
    first argument to select rows and a vector as the second to select columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'If the row-filtering condition is based on values of certain columns, the preceding
    code can be very redundant, especially when the condition gets more complicated.
    Another built-in function that simplifies code is `subset`, as we introduced previously:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The `subset` function uses non-standard evaluation so that we can directly use
    the columns of the data frame without typing `product_info` many times, because
    the expressions are meant to be evaluated in the context of the data frame.
  prefs: []
  type: TYPE_NORMAL
- en: 'Similarly, we can use `with` to evaluate an expression in the context of the
    data frame, that is, the columns of the data frame can be used as symbols in the
    expression without repeatedly specifying the data frame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The expression can be more than a simple subsetting. We can summarize the data
    by counting the occurrences of each possible value of a vector. For example, we
    can create a table of the occurrences of types of records that are released:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'In addition to the table of product information, we also have a table of product
    statistics that describe some properties of each product:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, think how we can get the names of products with the top three largest
    sizes. One way is to sort the records in `product_stats` by size in descending
    order, select `id` values of the top three records, and use these values to filter
    rows of `product_info` by `id`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Although it works as supposed, this approach looks quite redundant. Note that
    `product_info` and `product_stats` actually describe the same set of products
    from different perspectives. The connection between these two tables is the `id`
    column. Each `id` is unique and refers to the same product. To access both sets
    of information, we can put the two tables together into one data frame. The simplest
    way to do this is use `merge`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Now, we create a new data frame that is a combined version of `product_table`
    and `product_info`, with a shared `id` column. In fact, if you reorder the records
    in the second table, the two tables still can be correctly merged.
  prefs: []
  type: TYPE_NORMAL
- en: 'With the combined version, we can do things more easily. For example, with
    the merged version, we can sort the data frame with any column in one table that
    we loaded without having to manually work with the other:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'To solve the problem, we can directly use the merged table and get the same
    answer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The merged data frame allows us to sort the records by a column in one data
    frame and filter the records by a column in the other. For example, we will first
    sort the product records by weight in descending order and select all records
    of the `model` type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Sometimes, the column values are literal but can be converted to standard R
    data structures to better represent the data. For example, the `released` column
    in `product_info` only takes `yes` and `no`, which can be better represented with
    a logical vector. We can use `<-` to modify the column values, as you learned
    previously. However, it is usually better to create a new data frame with the
    existing columns properly adjusted and new columns added without polluting the
    original data. To do this, we can use `transform`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: The result is a new data frame with `released` converted to a logical vector
    and a new column, `density`, added. You can easily verify that `product_table`
    is not modified at all.
  prefs: []
  type: TYPE_NORMAL
- en: Also, note that `transform` works in a way similar to `subset` because both
    functions use non-standard evaluation to allow direct use of data frame columns
    as symbols in the arguments so that we don't have to type `product_table$` before
    columns all the time.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the preceding data, a number of columns contain missing values represented
    by `NA`. Under many circumstances, we don''t want any missing values to be present
    in our data. Therefore, we need to somehow deal with them. To demonstrate the
    various techniques, we will load another table that contains missing values. The
    table is the test results of the quality, durability, and waterproofing of each
    product in the previous dataset we used. It is the test results of the quality,
    durability, and waterproofing of each product. We will store the data in `product_tests`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that the values in both `quality` and `durability` contain missing values
    (`NA`). To exclude all rows with missing values, we can use `na.omit()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Another way is to use `complete.cases()` to get a logical vector, indicating
    all complete rows (without any missing value):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we can use this logical vector to filter the data frame. For example,
    we can get the `id` of all complete rows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Alternatively, we can get the id of all incomplete rows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that `product_info`, `product_stats`, and `product_tests` all share an `id`
    column; we can merge them all together. Unfortunately, there''s no built-in function
    to merge an arbitrary number of data frames. We can only merge two existing data
    frames at a time, or we''ll have to merge them recursively:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'With the fully merged table, we can use `tapply`, another apply-family function
    specialized to work with tabular data, to summarize the data using certain methods
    over given columns. For example, we can calculate the mean value of `quality`
    of each `type`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that we not only supply `mean` but also specify `na.rm = TRUE` to ignore
    the missing values in `quality`. The result looks like a numeric vector. We will
    use `str()`, so let''s take a look at its structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'In fact, it is a one-dimensional array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'The `tapply` function produces an array instead of a simple numeric vector,
    because it can be easily generalized to work with multiple grouping. For example,
    we can compute the mean value of `quality` for each `type` and `class` pair:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we have a two-dimensional array, whose values can be extracted by two
    arguments:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Moreover, we can supply more columns for grouping. In the following code, we
    will use the `with()` function to reduce redundant typing of `product_full`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, a three-dimensional array is produced. Even though `na.rm = TRUE` is specified,
    many cells are still missing values. This is because no value is present for the
    grouping:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'We can access the cell value by supplying three arguments:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: In summary,`tapply` groups the input data frame with `n` specified variables
    and produces an array with `n` dimensions. This approach to summarizing data can
    be hard to work with, especially when there are more columns for grouping. This
    is mostly because array is usually high-dimensional, hard to represent, and not
    flexible for further manipulation. Later in this chapter, you will learn several
    different methods that make group summary much easier.
  prefs: []
  type: TYPE_NORMAL
- en: Reshaping data frames using reshape2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Previously, you learned how to filter, sort, merge, and summarize data frames.
    These operations only work on rows and columns separately. Sometimes, however,
    we need to do something more complex.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, the following code loads a dataset of tests on quality and durability
    on different dates of two products:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Each row of the preceding data frame represents a record of tests of a particular
    product (`id`) on a certain `date`. If we need to compare the quality or durability
    of the two products at the same time, it can be hard to work with such format
    of data. Instead, we need the data to be transformed like the following code so
    that we can compare the values of the two products more easily:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'The `reshape2` package is designed for such a transform. If you don''t have
    it installed, run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the package is installed, we can use `reshape2::dcast` to transform the
    data so that we can easily compare the `quality` of different products on the
    same `date`. More specifically, it reshapes `toy_tests` so that the `date` column
    is shared, the values in `id` are spread as columns, and the values for each `date`
    and `id` are `quality` data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, `toy_tests` is immediately transformed. The `quality` values
    of both products are aligned with `date`. Although each month the two products
    conduct a test, the date may not exactly match with each other. This results in
    missing values if one product has a value on a day, but the other has no corresponding
    value on exactly the same day.
  prefs: []
  type: TYPE_NORMAL
- en: 'One way to fill the missing value is to use the approach called **Last Observation
    Carried Forward** (**LOCF**), which means that if a non-missing value is followed
    by a missing value, then the non-missing value is carried forward to replace the
    missing value, until all subsequent missing values are replaced. One implementation
    of LOCF is provided by the `zoo` package. Run the following command to install
    the package if you don''t have it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'To demonstrate how it works, we will use `zoo::na.locf()` to perform this technique
    over a very simple numeric vector with missing values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'It is straightforward that all missing values are replaced with previous non-missing
    values. To do the same thing with `T01` and `T02` columns of `toy_quality`, we
    can sub-assign the processed vector to the columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'However, if `toy_tests` contains thousands of products, it is ridiculous to
    write thousands of lines of code to do similar things like this. A better practice
    would be using exclusive sub-assignment as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: We will use `lapply()` to perform LOCF over all columns of `toy_quality`, except `date`,
    and assign the resulting list to the subset of `toy_quality` without the `date`
    column. This works because sub-assignment of a data frame accepts a list and still
    preserves the class of data frame.
  prefs: []
  type: TYPE_NORMAL
- en: However, although the data does not contain any missing values, the meaning
    of each row is changed. Originally, product `T01` does not take a test on `20160303`.
    The value should be interpreted as the last test value of quality on or before
    the day. Another drawback is that in the original data, both products take tests
    every month, but the preceding reshaped data frame is not aligned to `date` of
    regular frequency.
  prefs: []
  type: TYPE_NORMAL
- en: 'One way to fix the drawbacks is to use year-month data instead of an exact
    date. In the following code, we will create a new column `ym`, that is, the first
    6 characters of `toy_tests`. For example, `substr(20160101, 1, 6)` will result
    in `201601`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'This time, we will use the `ym` column for alignment instead of `date`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: Now, the missing values are gone, and the quality scores of both products in
    each month are naturally presented.
  prefs: []
  type: TYPE_NORMAL
- en: 'Sometimes, we need to combine a number of columns into one that indicates the
    measure and another that stores the value. For example, the following code uses
    `reshape2::melt` to combine the two measures (`quality` and `durability`) of the
    original data into a column named `measure` and a column of the measured value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'The variable names are now contained in the data, which can be directly used
    by some packages. For example, we can use `ggplot2` to plot data in such a format.
    The following code is an example of a scatter plot with facet grid of different
    combination of factors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we can see a scatter plot grouped by product `id` and `measure` with `ym`
    as *x* values and `value` as *y* values:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Reshaping data frames using reshape2](img/image_12_001.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The plot can be easily manipulated because the grouping factor (`measure`)
    is contained as data rather than columns, which is easier to represent from the
    perspective of the `ggplot2` package:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'This time, we will present the points of the two products in different colors:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Reshaping data frames using reshape2](img/image_12_002.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Using SQL to query data frames via the sqldf package
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, you learned how to compose SQL statements to query
    data from relational databases such as SQLite and MySQL. Is there a way to directly
    use SQL to query data frames in R as if these data frames are tables in relational
    databases? The `sqldf` package says yes.
  prefs: []
  type: TYPE_NORMAL
- en: 'This package takes advantage of SQLite, thanks to its lightweight structure
    and easiness to embed into an R session. Run the following command to install
    this package if you don''t have it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'First, let''s attach the package, as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: Note that when we attach `sqldf`, a number of other packages are automatically
    loaded. The `sqldf` package depends on these packages, because what it does is
    basically transferring data and converting data types between R and SQLite.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, we will reload the product tables we used in the previous sections:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'The magic of this package is that we can directly query the data frames in
    our working environment with SQL. For example, we can select all records of `product_info`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'The `sqldf` package supports simple select queries that are supported by SQLite.
    For example, we can select a certain set of columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'We can filter records by a certain condition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'We can compute a new column and give it a name:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'We can sort records by certain columns in given orders:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'The package also supports querying multiple data frames such as `join`. In
    the following code, we will merge `product_info` and `product_stats` by `id`,
    just like what we did with `merge()` previously:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'Moreover, it also supports nested query. In the following code, we will select
    all records in `product_info` that are made of wood:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'Alternatively, we can use `join` with the same `where` condition to achieve
    the same goal. For many relational databases, `join` usually works faster than `in`
    when the data is large:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'In addition to `join`, we can easily summarize data by group. For example,
    we group `product_tests` by `waterproof` into two groups: `yes` and `no`. For
    each group, we compute the average values of `quality` and `durability`, respectively:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'For the `toy_tests` data, it is easy to aggregate data for each product. Here
    is an example of averaging `quality` and `durability` values across time for each
    product:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'To make the results more informative, we can join `product_info` with the grouped
    summary table so that the product information and average measures are presented
    together:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: Using `sqldf` and SQL to query data frames looks very handy, but the limitations
    are obvious too.
  prefs: []
  type: TYPE_NORMAL
- en: First, since `sqldf` is, by default, based on SQLite, the limitation of the
    package is also the limitation of SQLite database, that is, the built-in group
    aggregate functions are limited. The official webpage ([https://sqlite.org/lang_aggfunc.html](https://sqlite.org/lang_aggfunc.html))
    provides a list of functions: `avg()`, `count()`, `group_concat()`, `max()`, `min()`, `sum()`,
    and `total()`. If we need more than that, for example, `quantile()`, it won't
    be easy. In R, we can use much more advanced algorithms to aggregate columns.
  prefs: []
  type: TYPE_NORMAL
- en: Second, since we need to supply a string of select statements to query data,
    it is not very convenient to generate SQL dynamically when part of it is determined
    by R variables. Therefore, we need to use `sprintf()` to allow the values of R
    variables to appear in the SQL statement.
  prefs: []
  type: TYPE_NORMAL
- en: Third, the limitation of `sqldf` is also the limitation of SQL. It is hard to
    compute new columns with more complex algorithms. For example, if we need to compute
    a ranking column based on an existing numeric column, it would not be very easy
    to implement. However, in R, we just need `order()`. Another thing is that it
    is hard or verbose to implement more complex filter operations such as ranking-based
    data filtering. For example, how do you select the first one or two products ordered
    by `size` in descending order grouped by `material`? Such a query requires a lot
    more thinking and tricks.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, if we use the `plyr` package, such a task is a piece of cake. If you
    have the package installed, run the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'To demonstrate how simple it is, we will use `plyr::ddply` to do this. We will
    supply `material` as the data splitter, that is, `product_stats` is divided into
    several parts for each value taken by `material`. We also supply a function to
    transform the input data frame (each part) to a new data frame. Then, the `ddply`
    function combines these data frames together:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: The anonymous function we supplied is called with three parts of `product_stats`
    with distinct `material`, each part having identical `material`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another example is to select top two test results with the most samples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'The anonymous function we supplied is called with two parts of `toy_tests`:
    one part is a data frame with `id` being `T01` and the other `T02`. For each part,
    we order the sub-dataframe by `sample` in the descending order and take the top
    two records. The task is easily finished.'
  prefs: []
  type: TYPE_NORMAL
- en: In addition, `ddply`, `plyr` provides a variety of functions of many possible
    pairs of input-output data types. To learn more, visit [http://had.co.nz/plyr/](http://had.co.nz/plyr/)
    and [https://github.com/hadley/plyr](https://github.com/hadley/plyr).
  prefs: []
  type: TYPE_NORMAL
- en: Using data.table to manipulate data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the first section, we reviewed some built-in functions used to manipulate
    data frames. Then, we introduced `sqldf`, which makes simple data query and summary
    easier. However, both approaches have their limitations. Using built-in functions
    can be verbose and slow, and it is not easy to summarize data because SQL is not
    as powerful as the full spectrum of R functions.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `data.table` package provides a powerful enhanced version of `data.frame`.
    It is blazing fast and has the ability to handle large data that fits into memory.
    It invents a natural syntax of data manipulation using `[]`. Run the following
    command to install the package from CRAN if you don''t have it yet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the package is successfully installed, we will load the package and see
    what it offers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: Note that we previously loaded the `reshape2` package in which `dcast` and `melt`
    are defined. The `data.table` package also provides enhanced version of `dcast`
    and `melt` with more powerful functionality, better performance, and higher memory
    efficiency. We'll take a look at them later in this section.
  prefs: []
  type: TYPE_NORMAL
- en: 'Creating `data.table` is very much like creating `data.frame`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'We can see its structure with `str()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: It is clear that `dt` is of class `data.table` and `data.frame`, which means
    that `data.table` inherits from `data.frame`. In other words, it inherits some
    behaviors of `data.frame`, but override others as enhancements.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we still load the product data. However, this time, we will use `fread()`
    provided by `data.table` package. The `fread()` function is super-fast, has great
    memory efficiency, and directly returns `data.table`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'If we take a look at `product_info`, its appearance is only slightly different
    from that of a data frame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'Again, we will look at its structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'As compared to `data.frame`, if we supply only one argument to subset `data.table`,
    it means selecting rows rather than columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'If the number we supply in `[]` is negative, it means excluding the record,
    which is fully consistent with subsetting a vector:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'In addition, `data.table` also provides a number of symbols that represent
    important components of `data.table`. One of the most useful symbols is `.N`,
    which means the number of rows. If we want to select the last row, we no longer
    need `nrow(product_info)`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: 'We can easily select the first and last rows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'The syntax of `data.table` subsetting automatically evaluates the expressions
    in the context of the data, that is, we can directly use column names as symbols,
    just like how we use `subset`, `transform`, and `with`. For example, we can directly
    use `released` in the first argument to select rows of products that are released:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: 'The first argument in the square brackets is a row filter, while the second
    is evaluated within the context of the filtered data. For example, we can directly
    use `id` to represent `product_info$id` because `id` is evaluated within the context
    of `product_info`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: 'The way to select columns of a data frame does not work here. If we put a character
    vector in the second argument, then we''ll get the character vector itself because
    a string is indeed a string:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: 'To disable this behavior, we can specify `with = FALSE` so that the second
    argument accepts a character vector to select columns, and it always returns a `data.table`,
    no matter how many columns are specified:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also write some other expressions as the second argument. For example,
    we can generate a table of the number of released products for each combination
    of `type` and `class`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: 'However, if a list is produced, it will be transformed to `data.table` instead:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: 'In this way, we can easily create a new `data.table` package with existing
    columns replaced:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also easily create a new `data.table` package with new columns based
    on existing columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: 'For simplicity, `data.table` provides `.()` to be short for `list()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: 'By supplying the ordered indices, we can easily sort the records by the given
    criterion:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: 'Previously, we always created a new `data.table` package after subsetting.
    The `data.table` package also provides `:=` for in-place assignment of columns.
    For example, the original data of `product_stats` is shown as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: 'We will use `:=` to create a new column directly in `product_stats`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: 'Nothing shows here, but the original `data.table` package is modified:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: 'We can use `:=` to replace an existing column:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: The `data.table` package provides `:=` mainly because in-place modification
    has a much higher performance since it avoids unnecessary copies of data.
  prefs: []
  type: TYPE_NORMAL
- en: Using key to access rows
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Another distinct feature of `data.table` is the support of indexing, that is,
    we can create a key on `data.table`, so accessing records by key can be extremely
    efficient. For example, we will use `setkey()` to make `id` the key of `product_info`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that the function behaves in a very different way from most R functions.
    It does not return a new copy of the data table but directly installs a key to
    the original input. The data frame, however, looks unchanged:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: 'Also, its key is created:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can use a key to access the records in `product_info`. For example,
    we can directly write a value of `id` to get the records with that `id`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: 'If we use this with a `data.table` package without a key, an error occurs and
    reminds you to set a key:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also use `setkeyv()` to set key, but it only accepts a character vector:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: 'This function is much easier to use if we have a dynamically determined vector
    to be the key. Now, we can use key to access `product_stats` too:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: 'If two tables have the same key, we can easily join them together:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: 'The key of a `data.table` package can be more than one element. For example,
    to locate a record of `toy_tests`, we need to specify both `id` and `date`. In
    the following code, we will set a key of the two columns on `toy_tests`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can get a row by supplying both elements in the key:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs: []
  type: TYPE_PRE
- en: 'If we only supply the first element, we would get a subset of the data with
    all records that match the first element:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: 'However, if we only supply the second element, we can''t get anything but an
    error. It is because the algorithm it behind requires the key to be ordered:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs: []
  type: TYPE_PRE
- en: 'Also, we cannot get any data if we supply a key in a wrong order:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs: []
  type: TYPE_PRE
- en: Summarizing data by groups
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Another important argument of subsetting a `data.table` is `by`, which is used
    to split the data into multiple parts, and for each part, evaluate the second
    argument. In this section, we''ll demonstrate how the `by` syntax makes it much
    easier to summarize data by groups. For example, the simplest usage of `by` is
    counting the records in each group. In the following code, we will count the number
    of both released and unreleased products:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE99]'
  prefs: []
  type: TYPE_PRE
- en: 'The group can be defined by more than one variable. For example, a tuple of
    `type` and `class` can be a group, and for each group, we will count the number
    of records:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also perform statistical calculations for each group. Here, we will
    compute the mean value of quality for both waterproof products and non-waterproof
    ones:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE101]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that the mean values are stored in `V1` because we didn''t supply a name
    for the column, so the package uses its default column names. To avoid that, we
    will use expression in form of `.(y = f(x))` instead:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE102]'
  prefs: []
  type: TYPE_PRE
- en: 'We can chain multiple `[]` in turn. In the following example, we will first
    join `product_info` and `product_tests` by shared key `id` and then calculate
    the mean values of `quality` and `durability` for each group of `type` and `class`
    of released products:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE103]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that the values of `by` columns will be unique in the resulting `data.table`.
    We can use `keyby` instead of `by` to ensure it is automatically used as key by
    the resulted `data.table`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE104]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we can directly use a tuple of key values to access the records:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE105]'
  prefs: []
  type: TYPE_PRE
- en: You can clearly see that using keys can be much more convenient than using logical
    comparisons when we try to find certain records in a table. However, its true
    advantage is not demonstrated yet because the data is not large enough. Using
    key to search records can be much faster than iterative logical comparison for
    large data, because searching by key takes advantage of binary search while iteration
    wastes a lot of time doing unnecessary computation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example to make a contrast. First, we will create a data of 10 million
    rows with an index column `id` and two numeric columns filled with random numbers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE106]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we want to see find a row of `id` being `8765432`. Let''s see how long
    it takes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE107]'
  prefs: []
  type: TYPE_PRE
- en: It seems no big deal, but suppose you need to frequently do this, say, hundreds
    of times per second, then your machine simply can't return a result in time.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, we will use `data.table` to do this. First, we will call `setDT()` to
    transform  `data.frame` to `data.table`. This function performs some magic to
    transform the object in place, no copy made. When we use the `setDT()` function,
    we also provide a key `id` so that the resulted `data.table` has `id` as its keyed
    column:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE108]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, `test1` is transformed to `data.table`. Then, we will search the same
    element:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE109]'
  prefs: []
  type: TYPE_PRE
- en: The results are the same, but the time `data.table` takes is much shorter than `data.frame`.
  prefs: []
  type: TYPE_NORMAL
- en: Reshaping data.table
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Previously, you learned how to reshape a data frame with the `reshape2` package.
    The `data.table` package provides faster and more powerful implementations of `dcast`
    and `melt` for the `data.table` object.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, we will reshape `toy_tests` by aligning the quality scores of
    each product to year-month tuples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE110]'
  prefs: []
  type: TYPE_PRE
- en: First, we used `:=` to create a new column `ym` directly in `toy_tests` and
    use `dcast` to transform it in the same way with the previous example of `reshape2`. The
    result looks the same with the output of `reshape2::dcast` for `data.frame`.
  prefs: []
  type: TYPE_NORMAL
- en: 'While `reshape2::dcast` does not support multi-value `value.var`, `data.table::dcast`
    works with multiple value variables, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE111]'
  prefs: []
  type: TYPE_PRE
- en: 'The column names, except the first, are no longer values of `id` but are value
    variables with values of `id` concatenated by the underscore symbol. In addition,
    the key of the output `data.table` is automatically set to the variables that
    appear on the left-hand side of the reshaping formula  `ym ~ id`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE112]'
  prefs: []
  type: TYPE_PRE
- en: 'The key implies that we can access the records directly by supplying a value
    of `ym`. However, the following code ends up with an error:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE113]'
  prefs: []
  type: TYPE_PRE
- en: 'There''s something wrong with the data types. We can run the following code
    to see the class of each column:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE114]'
  prefs: []
  type: TYPE_PRE
- en: 'The problem lies in the class of `ym:`. It is a character vector, but we supplied
    a key of numeric values. Therefore, the search fails with unmatched data types.
    If we supply a string, we can get the corresponding record:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE115]'
  prefs: []
  type: TYPE_PRE
- en: 'But how did `ym` become a character vector in the first place? Recall `ym :=
    substr(date, 1, 6)` where `date` is an integer vector, but `substr()` will coerce `date`
    to a character vector and then take out the first six characters. Therefore, it
    is natural that the result is a character vector. This is simply demonstrated
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE116]'
  prefs: []
  type: TYPE_PRE
- en: The point here is that we need to be careful about the data types of the key
    columns.
  prefs: []
  type: TYPE_NORMAL
- en: Using in-place set functions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If we use `data.frame`, to change the names or the column order will cause copies
    of the data structure. In recent R versions, the copy is made fewer when we rename
    columns, but it is still hard to reorder the columns of a data frame without making
    a new copy. This should not be a problem when the data is small, but if the data
    is very large, the performance and memory pressure it imposes can really be an
    issue.
  prefs: []
  type: TYPE_NORMAL
- en: An enhanced version of `data.frame`, `data.table` provides a family of `set`
    functions with reference semantics, that is, they modify `data.table` in place
    and avoid unnecessary copying, thus exhibiting astonishing performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Take `product_stats` as an example. We can call `setDF()` to change `data.table`
    to `data.frame` in place without making copies:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE117]'
  prefs: []
  type: TYPE_PRE
- en: 'We can call `setDT()` to make any `data.frame` to `data.table` and set up a
    key if specified:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE118]'
  prefs: []
  type: TYPE_PRE
- en: 'We can call `setnames` to change the name of the given columns to their new
    names:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE119]'
  prefs: []
  type: TYPE_PRE
- en: 'If we add a new column, the column should appear as the last one. For example,
    we will add an index column for all rows using `.I` representing `1:.N`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE120]'
  prefs: []
  type: TYPE_PRE
- en: 'By convention, the index column should, in most cases, appear as the first
    column. We can supply a new order of column names to `setcolorder()` so that the
    columns are directly reordered without making copies:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE121]'
  prefs: []
  type: TYPE_PRE
- en: Understanding dynamic scoping of data.table
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The most commonly used syntax of `data.table` is `data[i, j, by]`, where `i`, `j`,
    and `by` are all evaluated with dynamic scoping. In other words, we can use not
    only the columns directly, but also the predefined symbols such as `.N`, `.I`,
    and `.SD` to refer to important components of the data, as well as symbols and
    functions that can be accessed in the calling environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before demonstrating this, we will create a new `data.table` named `market_data`
    with a consecutive column of `date`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE122]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we will add two new columns to `market_data` by calling `:=` as a function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE123]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that `price` is a simple random walk, and `volume` is randomly drawn from
    a binomial distribution:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE124]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we will plot the data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE125]'
  prefs: []
  type: TYPE_PRE
- en: 'The plot generated is shown as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Understanding dynamic scoping of data.table](img/image_12_003.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Once the data is ready, we can aggregate the data and see how dynamic scoping
    can be used to make things easier.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we will look at the range of the `date` column:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE126]'
  prefs: []
  type: TYPE_PRE
- en: 'The data can be reduced to monthly **open-high-low-close** (**OHLC**) data
    easily by group aggregate:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE127]'
  prefs: []
  type: TYPE_PRE
- en: In the `j` expression, we can generate an OHLC record with each `data.table`
    grouped by `year` and `month`. If the output of `j` is a `list`, or `data.frame`,
    or `data.table`, then the output will be stacked together to result in one `data.table`.
  prefs: []
  type: TYPE_NORMAL
- en: 'In fact, the `j` expression can be anything, even with `by` specified. More
    specifically, `j` is evaluated within the context of each `data.table` as a subset
    of the original data split by the value of the `by` expression. For example, the
    following code does not aggregate data by group, but plot a price chart for each
    year:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE128]'
  prefs: []
  type: TYPE_PRE
- en: 'The plot generated is shown as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Understanding dynamic scoping of data.table](img/image_12_004.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Note that we don't specify the `data` argument of `plot` because it is evaluated
    in the context of `market_data` grouped by `year` where `price` and `date` are
    already defined.
  prefs: []
  type: TYPE_NORMAL
- en: 'Moreover, the `j` expression can be model-fitting code. Here is an example
    of batch fitting of linear models. First, we will load `diamonds` data from the `ggplot2`
    package:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE129]'
  prefs: []
  type: TYPE_PRE
- en: The data contains 53940 records of diamonds with 10 properties. Here, we will
    fit linear regression models on each group of `cut` to see how `carat` and `depth`
    may provide some information of `log(price)` in each group.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following code, the `j` expression involves fitting a linear model and
    coercing its coefficients into a list. Note that the `j` expression is evaluated
    for each value of the `keyby` expression. Since a list is returned, the estimated
    linear coefficients for each group will be stacked as one `data.table` is shown
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE130]'
  prefs: []
  type: TYPE_PRE
- en: 'Dynamic scoping also allows us to combine the use of symbols that are predefined,
    inside or outside `data.table`. For example, we can define a function to calculate
    the annual average values of a user-defined column of `market_data`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE131]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding `j` expression, `.SD` means the grouped `data.table` for each
    value of `year`. We can use `.SD[[x]]` to extract the values of column `x`, just
    like extracting an element by name from a list.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, we can run the following code to calculate the average prices for each
    year:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE132]'
  prefs: []
  type: TYPE_PRE
- en: 'We will just change the argument to `volume` to calculate the average volumes
    for each year:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE133]'
  prefs: []
  type: TYPE_PRE
- en: Also, we can use a specially invented syntax to create a dynamic number of columns
    with dynamically determined names.
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose we add three new alternative price columns, each adds some random noise
    to the original `price` values. Instead of repeat calling `market_data[, price1
    := ...]` and `market_data[, price2 := ...]`, we can use `market_data[, (columns)
    := list(...)]` to set columns dynamically, where `columns` is a character vector
    of column names and `list(...)` is the values for each corresponding column in `columns`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE134]'
  prefs: []
  type: TYPE_PRE
- en: 'On the other hand, if we get a table with many columns and we need to perform
    some computation on a subset of them, we can also use similar syntax to solve
    the problem. Imagine that the price-related columns may have missing values. We
    need to perform `zoo::na.locf()` on each price column. First, we will use regular
    expression to get all the price columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE135]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we will use similar syntax but add an additional argument, `.SDcols =
    price_cols`, in order to limit the columns of `.SD` to be only the price columns
    we get. The following code calls `zoo::na.locf()` on each price column, and the
    old values of each column are replaced:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE136]'
  prefs: []
  type: TYPE_PRE
- en: In this section, we have demonstrated the usage of `data.table` and how it makes
    data manipulation much easier. To see the full feature list of `data.table`, visit
     [https://github.com/Rdatatable/data.table/wiki](https://github.com/Rdatatable/data.table/wiki).
    To quickly review the usage, go through the data table cheat sheet ([https://www.datacamp.com/community/tutorials/data-table-cheat-sheet](https://www.datacamp.com/community/tutorials/data-table-cheat-sheet)).
  prefs: []
  type: TYPE_NORMAL
- en: Using dplyr pipelines to manipulate data frames
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Another popular package is `dplyr`, which invents a grammar of data manipulation.
    Instead of using the subset function (`[]`), `dplyr` defines a set of basic `erb`
    functions as the building blocks of data operations and imports a pipeline operator
    to chain these functions to perform complex multistep tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the following code to install `dplyr` from CRAN if you don''t have it yet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE137]'
  prefs: []
  type: TYPE_PRE
- en: 'First, we will reload the product tables again to reset all data to their original
    forms:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE138]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we will load the `dplyr` package:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE139]'
  prefs: []
  type: TYPE_PRE
- en: The following output indicates that `dplyr` generalizes a number of built-in
    functions, so they are masked after the package is attached.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we can start to play with the verb functions it provides. First, we will
    use `select` to select columns from the provided data frame by creating a new
    table with the given columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE140]'
  prefs: []
  type: TYPE_PRE
- en: The printing of the preceding table is a bit different from the way both `data.frame`
    and `data.table` are printed. It not only shows the table itself, but also includes
    a header indicating the size of the data frame and the data types of each column.
  prefs: []
  type: TYPE_NORMAL
- en: It is clear that `select()` uses non-standard evaluation that allows us to directly
    use column names of the given data frame as arguments. It works in a way similar
    to how `subset()`, `transform()`, and `with()` work.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use `filter` to filter the data frame by logical condition, which is
    also evaluated in the context of the data frame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE141]'
  prefs: []
  type: TYPE_PRE
- en: 'If we want to filter records with multiple conditions, we only need to write
    each condition as an argument of `filter()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE142]'
  prefs: []
  type: TYPE_PRE
- en: 'The `mutate` function is used to create a new data frame with new columns added
    or existing columns replaced, like `transform`, but also supports in-place assignment, `:=`,
    if the provided data is a `data.table`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE143]'
  prefs: []
  type: TYPE_PRE
- en: 'The `arrange` function is used to create a new data frame sorted by one or
    more columns. The `desc()` function indicates the descending order:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE144]'
  prefs: []
  type: TYPE_PRE
- en: 'The `dplyr` function provides a rich set of join operations, including  `inner_join`, `left_join`, `right_join`, `full_join`, `semi_join`,
    and `anti_join`. If two tables to join have records that do not match, these join
    operations may behave very differently. For `product_info` and `product_tests`,
    the records match exactly, so `left_join` should return the same results as `merge`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE145]'
  prefs: []
  type: TYPE_PRE
- en: To know more about the difference between those join operations, run `?dplyr::join`.
  prefs: []
  type: TYPE_NORMAL
- en: 'To summarize the data by groups, we need to first create a grouped table by
    `group_by()`. Then, we will use `summarize()` to aggregate the data. For example,
    we will divide `product_info_tests` with `type` and `class`, and then for each
    type class group, we will calculate the average values of `quality` and `durability`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE146]'
  prefs: []
  type: TYPE_PRE
- en: From the preceding code examples, you learned the verb functions `select()`, `filter()`, `mutate()`, `arrange()`, `group_by()`,
    and `summarize()`. Each of them is designed to do a small thing, but together
    they can perform comprehensive data operations when properly composed. Apart from
    these functions, `dplyr` imports the pipeline operator `%>%` from the `magrittr`
    package to compose functions into pipelines.
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose we have `product_info` and `product_tests`. We need to analyze the
    released product by computing the average values of quality and durability for
    each type class group, and present the summary data in descending order of the
    average quality. This can be done nicely with the `dplyr` verb functions composed
    by the pipeline operator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE147]'
  prefs: []
  type: TYPE_PRE
- en: 'But how does `%>%` work? The pipeline operator basically does only one thing:
    put the result on the left-hand side of the first argument of the function call
    on the right-hand side, that is, `x %>% f(...)` will be basically evaluated as `f(x,
    ...)`. Since `%>%` is a package-defined binary operator, it allows us to chain
    function calls to either avoid redundant intermediate values or decompose nested
    calls.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose we need to transform `d0` to `d3` through three steps. In each step,
    we need to call a function with the previous result and an argument. If we manipulate
    data like this, there will be many intermediate results, and sometimes, it consumes
    a lot of memory when the data is large:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE148]'
  prefs: []
  type: TYPE_PRE
- en: 'If we want to avoid intermediate results, we''ll have to write nested calls.
    This task does not look straightforward at all, especially when there are numerous
    arguments in each function call:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE149]'
  prefs: []
  type: TYPE_PRE
- en: 'Using the pipeline operator, the workflow can be rearranged as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE150]'
  prefs: []
  type: TYPE_PRE
- en: The code looks much cleaner and straightforward. The whole expression not only
    looks like a pipeline but also works like a pipeline. The `d0 %>% f1(arg1)` equation
    is evaluated as `f1(d0, arg1)`, which is sent to `f2(., arg2)`, which is sent
    to `f3(., arg3)`. The output of each step becomes the input of the next step.
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, the pipeline operator not only works with `dplyr` functions, but
    also works with all other functions. Suppose we want to make a density plot of
    the diamond prices:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE151]'
  prefs: []
  type: TYPE_PRE
- en: 'The plot generated is shown as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Using dplyr pipelines to manipulate data frames](img/image_12_005.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Using the pipeline operator, we can rewrite code as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE152]'
  prefs: []
  type: TYPE_PRE
- en: 'Like `data.table`, `dplyr` also supplies `do()` to perform arbitrary operation
    on each group of data. For example, we can group `diamonds` by `cut`, and for
    each group, we can fit a linear model of `log(price) ~ carat`. Different from `data.table`,
    we need to specify the names of such operations so that the results can be stored
    as columns. Also, the expression in `do()` is not directly evaluated in the context
    of the grouped data. Instead, we need to use `.` to represent the data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE153]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that a new column `lmod` is created. It is not a typical data column of
    atomic vectors. Rather, it is a list of linear model objects, that is, the model
    for each value of `cut` is stored in the list-typed column `lmod`. We can access
    each model using an index:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE154]'
  prefs: []
  type: TYPE_PRE
- en: The `do()` function can be very helpful to perform highly customized operations.
    For example, suppose we need to analyze `toy_tests` data by summarizing the quality
    and durability for each product. Consider what we should do if, we only need the
    top three test records with most samples, and the quality and durability of each
    product should be a weighted average of the measure and the sample.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using `dplyr` functions and pipeline, the preceding task can be easily done
    with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE155]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that when the data is grouped, all subsequent operations are performed
    by group. To see the intermediate result, we will run the code before `do(head(.,
    3))`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE156]'
  prefs: []
  type: TYPE_PRE
- en: 'We get all records sorted by `sample` in descending order. Then, `do(head(.,
    3))` will evaluate `head(., 3)` for each group where `.` represents the data in
    the group:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE157]'
  prefs: []
  type: TYPE_PRE
- en: Now, we will get the top three records with most samples. It is handy to summarize
    the data as supposed.
  prefs: []
  type: TYPE_NORMAL
- en: The `dplyr` function defines a very intuitive grammar of data manipulation and
    provides high-performance verb functions that are designed for use in pipeline.
    To learn more, I recommend that you read the package vignettes ([https://cran.rstudio.com/web/packages/dplyr/vignettes/introduction.html](https://cran.rstudio.com/web/packages/dplyr/vignettes/introduction.html))
    and visit the interactive tutorial ([https://www.datacamp.com/courses/dplyr-data-manipulation-r-tutorial](https://www.datacamp.com/courses/dplyr-data-manipulation-r-tutorial))
    at DataCamp.
  prefs: []
  type: TYPE_NORMAL
- en: Using rlist to work with nested data structures
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, you learned about both relational databases that store
    data in tables and non-relational databases that support nested data structures.
    In R, the most commonly used nested data structure is a list object. All previous
    sections focus on manipulating tabular data. In this section, let's play with
    the `rlist` package I developed, which is designed for manipulating non-tabular
    data.
  prefs: []
  type: TYPE_NORMAL
- en: 'The design of `rlist` is very similar to `dplyr`. It provides mapping, filtering,
    selecting, sorting, grouping, and aggregating functionality for list objects.
    Run the following code to install the `rlist` package from CRAN:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE158]'
  prefs: []
  type: TYPE_PRE
- en: 'We have the non-tabular version of the product data stored in `data/products.json`.
    In this file, each product has a JSON representation as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE159]'
  prefs: []
  type: TYPE_PRE
- en: 'All products are stored in an JSON array like `[ {...}, {...} ]`. Instead of
    storing data in different tables, we put everything relating to a product in one
    object. To work with data in this format, we can use `rlist` functions. First,
    let''s load the `rlist` package:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE160]'
  prefs: []
  type: TYPE_PRE
- en: 'To load the data into R as a list, we can use `jsonlite::fromJSON()` or simply `list.load()`
    provided by `rlist`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE161]'
  prefs: []
  type: TYPE_PRE
- en: Now, `products` contains the information of all products. Each element of `products`
    represents a product with all related information.
  prefs: []
  type: TYPE_NORMAL
- en: 'To evaluate an expression within the context of each element, we can call `list.map()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE162]'
  prefs: []
  type: TYPE_PRE
- en: 'It iteratively evaluates `id` on each element of `products` and returns a new
    list containing all the corresponding results. The `list.mapv()` function simplifies
    the list and only returns a vector:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE163]'
  prefs: []
  type: TYPE_PRE
- en: 'To filter `products`, we can call `list.filter()` with logical conditions.
    All elements of `products` for which the conditions yield `TRUE` will be picked
    out:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE164]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that `rlist` functions have design similar to `dplyr` functions, that
    is, the input data is always the first argument. We can, thus, use a pipeline
    operator to pipe the results forward:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE165]'
  prefs: []
  type: TYPE_PRE
- en: 'We can use `list.select()` to select the given fields of each element of the
    input list:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE166]'
  prefs: []
  type: TYPE_PRE
- en: 'Alternatively, we can make new fields in `list.select()` based on the existing
    fields:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE167]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also sort the list elements by certain fields or values using `list.sort()`
    and stack all elements into a data frame using `list.stack()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE168]'
  prefs: []
  type: TYPE_PRE
- en: 'To group a list, we will call `list.group()` to make a nested list in which
    all elements are divided by the values of the field:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE169]'
  prefs: []
  type: TYPE_PRE
- en: 'The `rlist` function also provides many other functions that try to make non-tabular
    data manipulation easier. For example, `list.table()` enhances `table()` to directly
    work with a list of elements:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE170]'
  prefs: []
  type: TYPE_PRE
- en: 'It also supports multi-dimensional tables by evaluating each argument in the
    context of the input list:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE171]'
  prefs: []
  type: TYPE_PRE
- en: Although the storage of data is non-tabular, we can easily perform comprehensive
    data manipulation and get the results presented in the tabular form. For example,
    suppose we need to compute the mean score and number of scores of the top two
    products with the highest mean scores but also with at least five scores.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can decompose such a task into smaller data manipulation subtasks, which
    can be easily done by `rlist` functions. Due to the number of steps involved in
    the data operations, we will use pipeline to organize the workflow:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE172]'
  prefs: []
  type: TYPE_PRE
- en: The code looks straightforward, and it is easy to predict or analyze what happens
    in each step. If the final result can be represented in the tabular form, we can
    call `list.stack()` to bind all list elements together into a data frame.
  prefs: []
  type: TYPE_NORMAL
- en: To learn more about `rlist` functions, read the `rlist` tutorial ([https://renkun.me/rlist-tutorial/](https://renkun.me/rlist-tutorial/)).
    There are other packages that deal with nested data structures but may have different
    philosophy, such as purrr ([https://github.com/hadley/purrr](https://github.com/hadley/purrr)).
    If you are interested, visit and learn more on their websites.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned a number of basic functions and various packages
    for data manipulation. Using built-in functions to manipulate data can be redundant.
    Several packages are tailored for filtering and aggregating data based on different
    techniques and philosophies. The `sqldf` packages use embedded SQLite databases
    so that we can directly write SQL statements to query data frame in our working
    environment. On the other hand, `data.table` provides an enhanced version of `data.frame`
    and a powerful syntax, and `dplyr` defines a grammar of data manipulation by providing
    a set of pipeline friendly verb functions. The `rlist` class provides a set of
    pipeline friendly functions for non-tabular data manipulation. No single package
    is best for all situations. Each of them represents a way of thinking, and which
    best fits a certain problem depends on how you understand the problem and your
    experience of working with data.
  prefs: []
  type: TYPE_NORMAL
- en: Processing data and doing simulation require considerable computing power. However,
    from the beginning to today, performance is not the top priority for R. Although
    R is very powerful in interactive analysis, visualization, and reporting, its
    implementation is considered slow compared to some other popular scripting languages
    when it is used to process a large amount of data. In the next chapter, we'll
    introduce several techniques from performance measure and profiling to vectorization,
    MKL-powered R kernel, parallel computing, and Rcpp. These techniques will help
    you achieve high performance when you really need it.
  prefs: []
  type: TYPE_NORMAL
