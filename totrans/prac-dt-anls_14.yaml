- en: Practical Sentiment Analysis
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: 实用情感分析
- en: This is going to be a fun chapter. In this chapter, we will explore and demonstrate
    some practical examples of using **Natural Language Processing** (**NLP**) concepts
    to understand how unstructured text can be turned into insights. In [Chapter 10](84b19b06-81f4-460f-8c4c-a776f4e66c24.xhtml),
    *Exploring Text Data and Unstructured Data*, we explored the **Natural Language
    Toolkit** (**NLTK**) library and some fundamental features of working with identifying
    words, phrases, and sentences. In that process of tokenizing, we learned how to
    work with data and classify text, but did not go beyond that. In this chapter,
    we will learn about sentiment analysis, which predicts the underlying tone of
    text that's input into an algorithm. We will break down the elements that make
    up an NLP model and the packages used for sentiment analysis before walking through
    an example together.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 这将是一个有趣的章节。在本章中，我们将探索并演示一些使用**自然语言处理**（**NLP**）概念的实际例子，以了解非结构化文本如何转化为洞察。在[第10章](84b19b06-81f4-460f-8c4c-a776f4e66c24.xhtml)“探索文本数据和非结构化数据”中，我们探讨了**自然语言工具包**（**NLTK**）库以及与识别单词、短语和句子相关的一些基本功能。在这个过程中，我们学习了如何处理数据和分类文本，但并未超出这个范围。在本章中，我们将学习情感分析，它预测算法输入文本的潜在语气。在共同分析一个例子之前，我们将分解构成NLP模型的要素以及用于情感分析的包。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们将涵盖以下主题：
- en: Why sentiment analysis is important
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么情感分析很重要
- en: Elements of an NLP model
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NLP模型的要素
- en: Sentiment analysis packages
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 情感分析包
- en: Sentiment analysis in action
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 情感分析实践
- en: Let's get started.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧。
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: You can find the GitHub repository for this book at [https://github.com/PacktPublishing/Practical-Data-Analysis-using-Jupyter-Notebook/tree/master/Chapter11](https://github.com/PacktPublishing/Practical-Data-Analysis-using-Jupyter-Notebook/tree/master/Chapter11).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在此处找到本书的GitHub仓库：[https://github.com/PacktPublishing/Practical-Data-Analysis-using-Jupyter-Notebook/tree/master/Chapter11](https://github.com/PacktPublishing/Practical-Data-Analysis-using-Jupyter-Notebook/tree/master/Chapter11)。
- en: You can download and install the required software for this chapter from the
    following link: [https://www.anaconda.com/products/individual](https://www.anaconda.com/products/individual).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从以下链接下载并安装本章所需的软件：[https://www.anaconda.com/products/individual](https://www.anaconda.com/products/individual)。
- en: Why sentiment analysis is important
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么情感分析很重要
- en: Today, we are all living in a digital age where data is entangled in our daily
    lives. However, since most of this data is unstructured and the volume of it is
    large, it requires statistical libraries and **machine learning** (**ML**) to
    apply it to technology solutions. The NLTK libraries serve as a framework for
    us to work with unstructured data, and sentiment analysis serves as a practical
    use case in NLP. **Sentiment analysis**, or opinion mining, is a type of supervised
    ML that requires a training dataset to accurately predict an input sentence, phrase,
    headline, or even tweet is positive, negative, or neutral. Once the model has
    been trained, you can pass unstructured data into it, like a function, and it
    will return a value between negative one and positive one. The number will output
    decimals, and the closer it is to an integer, the more confident the model's accuracy
    will be. Sentiment analysis is an evolving science, so our focus will be on using
    the NLTK corpus libraries. As with any NLP model, you will find inaccuracies in
    the predicted output if you don't have a good sample for the input training data.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们生活在一个数字时代，数据与我们的日常生活紧密相连。然而，由于大部分数据都是非结构化的，且数据量巨大，它需要统计库和**机器学习**（**ML**）技术来解决技术问题。NLTK库为我们提供了一个处理非结构化数据的框架，而情感分析则是NLP中的一个实际应用案例。**情感分析**，或称为意见挖掘，是一种监督式机器学习，需要训练数据集来准确预测输入的句子、短语、标题甚至推文是正面、负面还是中性。一旦模型被训练，你就可以像传递函数一样将非结构化数据输入其中，它将返回一个介于负一和正一之间的值。这个数值将输出小数，且越接近整数，模型的准确性就越高。情感分析是一个不断发展的科学，因此我们的重点将放在使用NLTK语料库库上。与任何NLP模型一样，如果你没有好的输入训练数据样本，你会在预测输出中找到不准确之处。
- en: Also, note that NLP and sentiment analysis is a deep subject and should be validated
    by a data scientist or ML engineering team if you plan on implementing your own
    models using internal company data sources. That being said, you will notice sentiment
    analysis in many different applications today, and the exercises in this chapter
    provide you with another tool for data analysis. Another benefit of learning about
    how to use sentiment analysis is that it allows you to argue about the data that's
    output from a model. The ability to defend the accuracy and predictive nature
    of working with unstructured data will increase your data literacy skills. For
    example, let's say you are analyzing a population of tweets about a restaurant
    for a marketing campaign that had a mix of positive and negative reviews in the
    past. If the results of your analysis come back as 100% positive, you should start
    questioning the training data, the source of the data, and the model itself. Of
    course, it's possible for all the tweets to be positive, especially against a
    small population of data, but is it likely that every single one has a positive
    sentiment?
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，请注意，NLP和情感分析是一个深奥的主题，如果您计划使用内部公司数据源实现自己的模型，则应由数据科学家或机器学习工程团队进行验证。话虽如此，您今天会在许多不同的应用中注意到情感分析，本章中的练习为您提供了数据分析的另一个工具。了解如何使用情感分析的另一个好处是，它允许您就模型输出的数据进行辩论。能够捍卫处理非结构化数据的准确性和预测性将提高您的数据素养技能。例如，假设您正在分析一个关于餐厅的推文群体，该餐厅过去在营销活动中混合了正面和负面的评论。如果您的分析结果为100%正面，您应该开始质疑训练数据、数据来源以及模型本身。当然，所有推文都是正面的可能性是存在的，尤其是在数据量较小的情况下，但每个推文都有正面情感的可能性大吗？
- en: This is why **Knowing Your Data** (**KYD**) remains important, as covered in
    [Chapter 1](0fa7e28f-7a30-4099-9bae-30dd3c86ee4f.xhtml), *Fundamentals of Data
    Analysis*, regardless of the technology and tools being used to analyze it. However,
    why sentiment analysis is important today needs to be stated. First, the accuracy
    of the models has significantly improved because the more training data there
    is, the better the prediction's output. The second point is that NLP models can
    scale beyond what a human can process in the same amount of time. Finally, the
    alternatives to sentiment analysis available today, such as expert systems, are
    more costly because of the time and resources required to implement them. Expert
    system development using text-based logic and wildcard keyword searches is rigid
    and difficult to maintain.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 正如[第1章](0fa7e28f-7a30-4099-9bae-30dd3c86ee4f.xhtml)“数据分析基础”中所述，无论使用什么技术和工具进行分析，**了解您的数据**（KYD）仍然很重要。然而，今天为什么情感分析很重要需要说明。首先，模型的准确性显著提高，因为训练数据越多，预测输出的效果越好。第二点是，NLP模型可以扩展到人类在相同时间内无法处理的内容。最后，今天可用的情感分析替代方案，如专家系统，由于实施它们所需的时间和资源，成本更高。基于文本逻辑和通配符关键字搜索的专家系统开发是僵化的，且难以维护。
- en: Now, let's explore what makes up the elements of NLP and the process of how
    it is used in sentiment analysis.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来探讨构成自然语言处理（NLP）元素的内容以及它在情感分析中应用的过程。
- en: Elements of an NLP model
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: NLP模型的元素
- en: 'To summarize the process required to use an NLP supervised ML model for sentiment
    analysis, I have created the following diagram, which shows the elements in a
    logical progression indicated by the letters **A** through **E**:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 为了总结使用NLP监督机器学习模型进行情感分析所需的过程，我创建了一个以下图表，它显示了从字母**A**到**E**的逻辑进展：
- en: '![](img/2ed89905-db73-4ed0-af73-182b11d8d644.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/2ed89905-db73-4ed0-af73-182b11d8d644.png)'
- en: The process begins with our source **Unstructured Input Data**, which is represented
    in the preceding diagram with the letter A. Since unstructured data has different
    formats, structures, and forms such as a tweet, sentence, or paragraph, we need
    to perform extra steps to work with the data to gain any insights.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程从我们的源**非结构化输入数据**开始，这在前面图中用字母A表示。由于非结构化数据有不同的格式、结构和形式，如推文、句子或段落，我们需要执行额外的步骤来处理数据以获得任何见解。
- en: The next element is titled Text Normalization and is represented by the letter
    B in the preceding diagram, and involves concepts such as tokenization, n-grams,
    and **bag-of-words** (**BoW**), which were introduced in [Chapter 10](84b19b06-81f4-460f-8c4c-a776f4e66c24.xhtml),
    *Exploring Text Data and Unstructured Data*. Let's explore them in more detail
    so that we can learn how they are applied in sentiment analysis. BoW is when a
    string of text such as a sentence or paragraph is broken down to determine how
    many times a word occurs. In the process of **tokenizing** to create the bag-of-words
    representation, the location of where the word appears in a sentence, tweet, or
    paragraph becomes less relevant. How each word is classified, categorized, and
    defined using a classifier will serve as input to the next process.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个元素被命名为文本归一化，并在前面的图中用字母 B 表示，涉及诸如分词、n-gram 和**词袋模型**（**BoW**）等概念，这些概念在[第 10
    章](84b19b06-81f4-460f-8c4c-a776f4e66c24.xhtml)“探索文本数据和非结构化数据”中介绍过。让我们更详细地探讨它们，以便我们可以了解它们在情感分析中的应用。BoW
    是指将文本字符串（如句子或段落）分解以确定单词出现的次数。在创建词袋表示的过程中进行**分词**，单词在句子、推文或段落中的位置变得不那么相关。每个单词如何被分类、分类和定义，将作为下一个过程的输入。
- en: Think of tokens and bag-of-words as raw ingredients to the sentiment analysis
    recipe; as in cooking, the ingredients take additional steps of refinement. Hence,
    the concept of classification becomes important. This is considered a **Features** and
    is represented by the letter C in the preceding diagram. Because tokens are nothing
    more than ASCII characters to a computer, word embedding and tagging is the process
    of converting the words into an input for an ML model. An example would be to
    classify each word with a pair value such as a one or zero to represent true or
    false. This process also includes finding similar words or groupings in order
    to interpret the context.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 将标记和词袋视为情感分析食谱的原始原料；就像烹饪一样，原料需要额外的步骤进行精炼。因此，分类的概念变得很重要。这被认为是**特征**，并在前面的图中用字母
    C 表示。因为对计算机来说，标记不过是一串 ASCII 字符，所以词嵌入和标记是将其转换为机器学习模型输入的过程。一个例子是将每个单词分类为一个值对，如一或零，以表示真或假。此过程还包括寻找相似单词或分组，以便解释上下文。
- en: Creating **Features** is known as feature engineering, which is the foundation
    of supervised ML. Feature engineering is the process of transforming unstructured
    data elements into specific inputs for the prediction model. Models are abstractions
    where the output is only as accurate as the input data behind it. This means models
    need training data with extracted features to improve their accuracy. Without
    feature engineering, the results of a model would be random guesses.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 创建**特征**被称为特征工程，这是监督式机器学习的基础。特征工程是将非结构化数据元素转换为预测模型特定输入的过程。模型是抽象的，其输出的准确性仅取决于其背后的输入数据。这意味着模型需要带有提取特征的训练数据来提高其准确性。没有特征工程，模型的输出结果将是随机猜测。
- en: Creating a prediction output
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建预测输出
- en: To see how **features** can be extracted from unstructured data, let's walk
    through the NLTK gender feature, which includes some minor modifications from
    the original example. You can find the original source in the *Further reading* section.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 为了了解如何从非结构化数据中提取**特征**，让我们通过 NLTK 性别特征来举例，该特征对原始示例进行了一些小的修改。您可以在“进一步阅读”部分找到原始来源。
- en: 'Launch a new Jupyter Notebook and name it `ch_11_exercises`. Now, follow these
    steps:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 启动一个新的 Jupyter Notebook，并将其命名为 `ch_11_exercises`。现在，按照以下步骤操作：
- en: 'Import the following libraries by adding the following command to your Jupyter
    Notebook and run the cell. Feel free to follow along by creating your own Notebook.
    I have placed a copy in this book''s GitHub repository for reference:'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过在 Jupyter Notebook 中添加以下命令并运行单元格来导入以下库。您可以自由地跟随操作，创建自己的 Notebook。我已经在这个书的
    GitHub 仓库中放置了一个副本供参考：
- en: '[PRE0]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The library should already be available using Anaconda. Refer to [Chapter 2](e0fe6eb2-8f38-41f7-9dea-2b177578fd3c.xhtml),
    *Overview of Python and Installing Jupyter Notebook*, for help with setting up
    your environment.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 该库应该已经通过 Anaconda 可用。有关设置环境的帮助，请参阅[第 2 章](e0fe6eb2-8f38-41f7-9dea-2b177578fd3c.xhtml)“Python
    概述和安装 Jupyter Notebook”。
- en: 'Next, we need to download the specific corpus we want to use. Alternatively,
    you can download all the packages using the `all` parameter. If you are behind
    a firewall, there is an `nltk.set_proxy` option available. Check the documentation
    at [nltk.org](http://www.nltk.org/) for more details:'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们需要下载我们想要使用的特定语料库。或者，您可以使用`all`参数下载所有包。如果您在防火墙后面，有一个`nltk.set_proxy`选项可用。有关更多详细信息，请查看[nltk.org](http://www.nltk.org/)上的文档：
- en: '[PRE1]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The output will look as follows, where the package download is confirmed and
    the output is verified as `True`:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示，其中确认了包的下载，并且输出被验证为`True`：
- en: '![](img/9da572a5-f9b3-4b94-b621-5581c7bf8427.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9da572a5-f9b3-4b94-b621-5581c7bf8427.png)'
- en: 'We can use the following command to reference the corpus:'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以使用以下命令来引用语料库：
- en: '[PRE2]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'To explore the data available in this corpus, let''s run the `print` command
    against the two input sources, `male.txt` and `female.txt`:'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了探索这个语料库中可用的数据，让我们对两个输入源`male.txt`和`female.txt`运行`print`命令：
- en: '[PRE3]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The output will look as follows, where a count of the number of words found
    in each source file is printed in the Notebook:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示，其中在笔记本中打印出每个源文件中找到的单词数量：
- en: '![](img/82feb653-4599-4e2e-b0ff-08fddf8a04f8.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](img/82feb653-4599-4e2e-b0ff-08fddf8a04f8.png)'
- en: We now have a better understanding of the size of the data due to counting the
    number of words found in each source file. Let's continue by looking at the contents
    within each source, taking a look at a few samples from each gender file.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们计算了每个源文件中找到的单词数量，我们现在对数据的大小有了更好的理解。让我们继续查看每个源的内容，查看每个性别文件的一些样本。
- en: 'To see a list of the first few words found in each source, let''s run the `print`
    command against the two input sources, `male.txt` and `female.txt`:'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了查看每个源中找到的前几个单词的列表，让我们对两个输入源`male.txt`和`female.txt`运行`print`命令：
- en: '[PRE4]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The output will look as follows, where a list of words found in each source
    file is printed in the Notebook:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示，其中在笔记本中打印出每个源文件中找到的单词列表：
- en: '![](img/52eeafdf-75a9-4646-8ed6-1205b9853fdf.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](img/52eeafdf-75a9-4646-8ed6-1205b9853fdf.png)'
- en: Remember that the computer has no idea if a name actually returns a value of
    `male` or `female`. The corpus has defined them as two different source files
    as a list of values that the NLTK library has identified as words because they
    have been defined as such. With thousands of names defined as either male or female,
    you can use this data as input for sentiment analysis. However, identifying gender
    alone will not determine whether the sentiment is positive or negative, so additional
    elements are required.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，计算机并不知道一个名字实际上返回的是`male`或`female`的值。语料库将它们定义为两个不同的源文件，作为NLTK库识别为单词的值列表，因为它们被定义为这样的。有成千上万的名称被定义为男性或女性，你可以使用这些数据作为情感分析输入。然而，仅识别性别并不能确定情感是积极的还是消极的，因此还需要额外的元素。
- en: 'The next element, labeled D in the first diagram, is the actual **NLP supervised
    ML** algorithm. Remember, building an accurate model involves using feature engineering, along
    with NLTK libraries and classifier models. When used correctly, the output will
    be based on the input **training** and **test** data. Models should always be
    validated and the accuracy should be measured. For our example, which is building
    a basic gender determination model, we are going to use `NaiveBayesClassifier`,
    which is available in the NLKT libraries. The Naïve Bayes Classifier is an ML
    model created from Bayes theorem that is used to determine the probability of
    an event happening based on how often another similar event has occurred. A classifier
    is a process that chooses the correct tag value or label based on an inputted
    feature dataset. The mathematical concepts behind these models and libraries are
    vast, so I have added some links in the *Further reading* section for additional
    reference. To complete the elements of sentiment analysis summarized in the first
    diagram, we will create a prediction output, so let''s continue in our Jupyter
    Notebook session:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一个图中的下一个元素，标记为 D，是实际的 **NLP 监督机器学习** 算法。记住，构建一个准确模型需要使用特征工程，以及 NLTK 库和分类器模型。当正确使用时，输出将基于输入的
    **训练** 和 **测试** 数据。模型应该始终进行验证，并且应该测量准确性。在我们的例子中，即构建一个基本的性别判断模型，我们将使用 NLTK 库中可用的
    `NaiveBayesClassifier`。朴素贝叶斯分类器是一个基于贝叶斯定理创建的机器学习模型，用于根据另一个类似事件发生的频率来确定事件发生的概率。分类器是一个过程，它根据输入的特征数据集选择正确的标签值或标签。这些模型和库背后的数学概念非常广泛，因此我在
    *进一步阅读* 部分添加了一些链接以供参考。为了完成第一个图中总结的情感分析元素，我们将创建一个预测输出，所以让我们继续在我们的 Jupyter Notebook
    会话中继续：
- en: 'Create a `gender_features` function that returns the last letter of any input
    word. The model will use this classifier feature as input to predict the output,
    which, based on the concept that first names that end in the letters **A**, **E**,
    and **I** are more likely to be female, while first names ending in **K**, **O**,
    **R**, **S**, or **T** are more likely to be male. There will be no output after
    you run the cell:'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为 `gender_features` 的函数，该函数返回任何输入单词的最后一个字母。模型将使用这个分类器特征作为输入来预测输出，基于这样的概念：以字母
    **A**、**E** 和 **I** 结尾的名字更有可能是女性，而以 **K**、**O**、**R**、**S** 或 **T** 结尾的名字更有可能是男性。运行单元格后不会有输出：
- en: '[PRE5]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Remember to indent the second line in your cell so that Python can process the
    function.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，在您的单元格中缩进第二行，以便 Python 可以处理该函数。
- en: 'To confirm the function will return a value, enter the following command, which
    prints the last character of any inputted name or word:'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了确认函数将返回一个值，输入以下命令，该命令打印任何输入名称或单词的最后一个字符：
- en: '[PRE6]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The output will look as follows, where the last character from the inputted
    word `Debra` is printed in the Notebook with `Out[]`:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示，其中在 Notebook 中打印了输入单词 `Debra` 的最后一个字符，并带有 `Out[]`：
- en: '![](img/f4e4784f-f863-4a4c-907f-d8cbedd7dd21.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/f4e4784f-f863-4a4c-907f-d8cbedd7dd21.png)'
- en: 'Create a new variable named `labeled_names` that loops through both source
    gender files and assigns a **name-value pair** so that it can be identified as
    either male or female to be input into the model. To see the results after the
    loop has completed, we print the first few values to verify that the `labeled_names`
    variable contains data:'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为 `labeled_names` 的新变量，该变量遍历两个源性别文件，并为每个 **名称-值对** 分配标签，以便它可以被识别为男性或女性，然后输入到模型中。为了在循环完成后查看结果，我们打印前几个值以验证
    `labeled_names` 变量是否包含数据：
- en: '[PRE7]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The output will look as follows, where each name value from the source file
    will be combined with a tag of `male` or `female`, depending on which text file
    source it came from:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示，其中每个来自源文件的名称值将与 `male` 或 `female` 标签相结合，具体取决于它来自哪个文本文件源：
- en: '![](img/2b2b946b-a7a4-483d-b66a-bc5ee82a7279.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/2b2b946b-a7a4-483d-b66a-bc5ee82a7279.png)'
- en: 'Since the model should be trained using a random list of values to avoid any
    bias, we will input the random function and shuffle all the name and gender combinations,
    which will change the sequence of how they are stored in the `labeled_names` variable.
    I added a `print()` statement so that you can see the difference from the output
    created in the prior step:'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于模型应该使用随机值列表进行训练以避免任何偏差，我们将输入随机函数并打乱所有名称和性别组合，这将改变它们在 `labeled_names` 变量中的存储顺序。我添加了一个
    `print()` 语句，以便您可以看到与先前步骤中创建的输出之间的差异：
- en: '[PRE8]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The output will look as follows, where each name value from the source file
    will be combined with a tag of `male` or `female`, depending on which text file
    source it came from:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示，其中源文件中的每个名字值将与来自哪个文本文件源的`male`或`female`标签相结合：
- en: '![](img/9600fe81-df59-43a7-a7dc-4a984d8f9352.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9600fe81-df59-43a7-a7dc-4a984d8f9352.png)'
- en: Note because the `random()` function is used, the results of the `print()` function
    will always change each time you run the cell.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，因为使用了`random()`函数，所以`print()`函数的结果每次运行单元格时都会改变。
- en: 'Next, we are going to train the model by creating features for each gender
    using the last letter from each name in the `labeled_names` variable. We will
    print the new variable called `featuresets` so that you can see how the feature
    will be used in the next step:'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将通过使用`labeled_names`变量中每个名字的最后一个字母为每个性别创建特征来训练模型。我们将打印出新的变量`featuresets`，以便您可以看到在下一步中如何使用这个特征：
- en: '[PRE9]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The output will look as follows, where each combination of the last letter
    from the names is assigned to a gender value, thereby creating a list of name-value
    pairs:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示，其中每个名字最后一个字母的组合被分配给一个性别值，从而创建了一个名字-值对的列表：
- en: '![](img/f1fe1f7d-2d16-4ba0-8b35-aa25762dcfa6.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f1fe1f7d-2d16-4ba0-8b35-aa25762dcfa6.png)'
- en: 'Next, we are going to slice the data from the `featuresets` variable list into
    two input datasets called `train_set` and `test_set`. Once we have those datasets
    separated, we can use `train_set` as an input for the classifier. We use the `len()`
    function to give us a sense of the size of each dataset:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将从`featuresets`变量列表中切割数据，形成两个输入数据集，分别称为`train_set`和`test_set`。一旦我们将这些数据集分开，我们就可以使用`train_set`作为分类器的输入。我们使用`len()`函数来给我们一个每个数据集大小的感觉：
- en: '[PRE10]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The output will look as follows, where the results of the `len()` function
    provide context as to how large each dataset is compared to the others:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示，其中`len()`函数的结果提供了每个数据集相对于其他数据集大小的上下文：
- en: '![](img/da01ffe1-b381-45c6-954a-e078559ef4dc.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](img/da01ffe1-b381-45c6-954a-e078559ef4dc.png)'
- en: 'We will now pass the `train_set` variable as input to the NLTK Naïve Bayes
    classifier. The model is assigned the name `classifier`, so you can call it like
    a function in the next step. There will be no output once you run the cell:'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将`train_set`变量作为输入传递给NLTK朴素贝叶斯分类器。模型被命名为`classifier`，因此您可以在下一步中像调用函数一样调用它。运行单元格后不会有输出：
- en: '[PRE11]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Now, we will validate the results of the model by sending random names into
    the model using the following commands:'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将通过以下命令将随机名字发送到模型中，以验证模型的结果：
- en: '[PRE12]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The output will look as follows, where the gender values of either `male` or
    `female` will be displayed after each name is passed as a parameter in the `classifier` model:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示，其中每个名字在通过`classifier`模型作为参数传递后，都会显示`male`或`female`的性别值：
- en: '![](img/6af5b410-9cd6-4b42-be43-a175cebe5b51.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6af5b410-9cd6-4b42-be43-a175cebe5b51.png)'
- en: Congratulations – you have successfully created your first supervised ML model!
    As you can see, the classifier model has some accuracy issues and returns incorrect
    values in some cases. For example, when you pass in the values of `Aaron`, `Marc`,
    or `Debra`, the gender results are predicted correctly. The name `Aaron` was found
    in the training data, so that was no surprise. However, the model shows signs
    of being incomplete or requiring additional features because it returns the incorrect
    gender when using the nickname of `Deb` for `Debra` and for the name `Seth`, who
    is male.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜您——您已成功创建了您的第一个监督式机器学习模型！如您所见，分类器模型存在一些准确度问题，在某些情况下返回了错误值。例如，当您传入`Aaron`、`Marc`或`Debra`的值时，性别预测结果是正确的。`Aaron`这个名字在训练数据中出现过，所以这并不令人惊讶。然而，模型显示出不完整或需要额外特征的迹象，因为它在用昵称`Deb`代表`Debra`以及代表男性名字`Seth`时返回了错误的性别。
- en: How do we solve this problem? There are a few approaches that can be used, all
    of which we will explore next.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何解决这个问题？我们可以使用几种方法，我们将在下面一一探讨。
- en: Sentiment analysis packages
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 情感分析包
- en: The NLTK libraries include a few packages to help solve the issues we experienced
    in the gender classifier model. The first is the `SentimentAnalyzer` module, which
    allows you to include additional features using built-in functions. What's special
    about these packages is that they go beyond traditional functions where defined
    parameters are passed in. In Python, arguments (`args`) and keyword arguments (`kwargs`)
    allow us to pass name-value pairs and multiple argument values into a function.
    These are represented with asterisks; for example, `*args` or `**kwargs`. The
    NLTK `SentimentAnalyzer` module is a useful utility for teaching purposes, so
    let's continue by walking through the features that are available within it.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: NLTK 库包含一些包来帮助我们解决我们在性别分类器模型中遇到的问题。第一个是 `SentimentAnalyzer` 模块，它允许您使用内置函数添加额外的功能。这些包的特殊之处在于，它们超越了传统的函数，其中定义的参数被传递进来。在
    Python 中，参数（`args`）和关键字参数（`kwargs`）允许我们将名称-值对和多个参数值传递给一个函数。这些用星号表示；例如，`*args`
    或 `**kwargs`。NLTK 的 `SentimentAnalyzer` 模块是一个用于教学目的的有用工具，因此让我们继续通过浏览其中可用的功能来继续。
- en: The second is called **VADER**, which stands for **Valence Aware Dictionary
    and Sentiment Reasoner**. It was built to handle social media data. The VADER
    sentiment library has a dictionary known as a **lexicon** and includes a rule-based
    algorithm specifically built to process acronyms, emoticons, and slang. A nice
    feature available from VADER is that it already includes training data and we
    can use a built-in function called `polarity_scores()` that returns key insights
    in the output that's displayed. The first is a compound score that is between
    negative one and positive one. This provides you with a normalized sum of VADER's
    lexicon ratings in a single score. For example, if the output returns `0.703`,
    this would be an extremely positive sentence, while a compound score of `-0.5719`
    would be interpreted as negative. The next output from the VADER tool is a distribution
    score in terms of how positive, negative, or neutral the input is from zero to
    one.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个是称为 **VADER** 的，代表 **Valence Aware Dictionary and Sentiment Reasoner**。它是为了处理社交媒体数据而构建的。VADER
    情感库有一个称为 **lexicon** 的字典，并包括一个基于规则的算法，专门用于处理缩写、表情符号和俚语。VADER 的一个不错的特点是它已经包含了训练数据，我们可以使用一个名为
    `polarity_scores()` 的内置函数，该函数返回输出中显示的关键见解。第一个是介于负一和正一之间的复合得分。这为您提供了一个单一得分中 VADER
    字典评级的标准化总和。例如，如果输出返回 `0.703`，这将是一个非常积极的句子，而复合得分为 `-0.5719` 将被解释为消极。VADER 工具的下一个输出是关于输入是积极、消极还是中性的分布得分，范围从零到一。
- en: 'For example, the sentence `I HATE my school!` would return the results shown
    in the following screenshot:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，句子 `我恨我的学校！` 会返回以下截图所示的结果：
- en: '![](img/f61dda82-d3c8-4142-b5f2-e6d096eda89c.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/f61dda82-d3c8-4142-b5f2-e6d096eda89c.png)'
- en: As you can see, a compound value of `-0.6932` is returned, which validates the
    VADER model is accurately predicting the sentiment as very negative. On the same
    output line, you can see `'neg'`, `'neu'`, and `'pos'`, which are short for negative,
    neutral, and positive, respectively. Each metric next to the values provides a
    little more detail about how the compound score was derived. In the preceding
    screenshot, we can see a value of `0.703`, which means that the model prediction
    is 70.3% negative, with the remaining 29.7% being neutral. The model returned
    a value of `0.0` next to `pos`, so there is a `0%` positive sentiment based on
    the built-in VADER training dataset.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，返回了一个 `-0.6932` 的复合值，这验证了 VADER 模型准确预测了非常消极的情感。在同一输出行上，您可以看到 `'neg'`、`'neu'`
    和 `'pos'`，分别代表消极、中性和积极。每个值旁边的指标提供了一些关于复合得分是如何得出的更多细节。在前面的截图中，我们可以看到一个 `0.703`
    的值，这意味着模型预测的消极程度为 70.3%，剩余的 29.7% 为中性。模型在 `pos` 旁边返回了一个 `0.0` 的值，因此基于内置的 VADER
    训练数据集，没有积极的情感。
- en: Note that the VADER sentiment analysis scoring methodology has been trained
    to handle social media data and informal proper grammar. For example, if a tweet
    includes multiple exclamation points for emphasis, the compound score will increase.
    Capitalization, the use of conjunctions, and the use of swear words will all be
    accounted for in the output from the model. So, the main benefit of using VADER
    is that it already includes those extra steps required to feature and train the
    model, but you lose the ability to customize it with additional features.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，VADER情感分析评分方法已经训练过，可以处理社交媒体数据和非正式的正式语法。例如，如果一条推文包含多个感叹号以强调，复合评分将增加。大写字母、连词的使用以及脏话的使用都将计入模型输出的结果中。因此，使用VADER的主要好处是它已经包含了那些用于特征和训练模型的额外步骤，但你失去了使用额外功能来自定义它的能力。
- en: Now that we have a better understanding of the VADER tool, let's walk through
    an example of using it.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们对VADER工具有了更好的理解，让我们通过一个使用它的例子来演示。
- en: Sentiment analysis in action
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 情感分析实战
- en: Let's continue with our Jupyter Notebook session and walk through how to install
    and use the VADER sentiment analysis library. First, we will walk through an example
    of using manual input and then learn how to load data from a file.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续我们的Jupyter Notebook会话，并介绍如何安装和使用VADER情感分析库。首先，我们将通过一个手动输入的例子来演示，然后学习如何从文件中加载数据。
- en: Manual input
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 手动输入
- en: 'Follow these steps to learn how to use manual input in VADER:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤学习如何在VADER中使用手动输入：
- en: 'Import the NLTK library and download the `vader_lexicon` library so that all
    the necessary functions and features will be available:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入NLTK库并下载`vader_lexicon`库，以便所有必要的函数和功能都将可用：
- en: '[PRE13]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The output will look as follows, where the package download will be confirmed
    and the output is verified as `True`:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示，其中包下载将被确认，输出被验证为`True`：
- en: '![](img/ce376473-cec8-4d0b-b699-311c081e7aa0.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/ce376473-cec8-4d0b-b699-311c081e7aa0.png)'
- en: 'Import `SentimentIntensityAnalyzer` from the NLTK Vader library. There will
    be no output when you run the cell:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从NLTK Vader库导入`SentimentIntensityAnalyzer`。运行单元格时不会有输出：
- en: '[PRE14]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'To make it easier, we will assign a variable object called `my_ analyzer` and
    assign it to the `SentimentIntensityAnalyzer()` model. There will be no output
    after you run the cell:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了简化，我们将分配一个名为`my_analyzer`的变量对象，并将其分配给`SentimentIntensityAnalyzer()`模型。运行单元格后不会有输出：
- en: '[PRE15]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Next, we will create a variable named `my_input_sentence` and assign it a string
    value of `I HATE my school!`. On the second line, we will call the model and pass
    the variable as an argument to the `polarity_scores()` function:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将创建一个名为`my_input_sentence`的变量，并将其分配一个字符串值`I HATE my school!`。在第二行，我们将调用模型并将变量作为参数传递给`polarity_scores()`函数：
- en: '[PRE16]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The output will look as follows, where we can see the result of the VADER sentiment
    analysis model:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示，其中我们可以看到VADER情感分析模型的结果：
- en: '![](img/15c382c5-8032-48d1-b0f5-90170521b9a3.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/15c382c5-8032-48d1-b0f5-90170521b9a3.png)'
- en: Excellent—you have now utilized the VADER sentiment analysis model and returned
    results to determine whether a sentence is positive or negative. Now that we understand
    how the model works with individual input sentences, let's demonstrate how to
    work with a sample social media file and combine it with what we have learned
    using the `pandas` and `matplotlib` libraries.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 极好——你现在已经使用了VADER情感分析模型，并返回结果以确定句子是正面还是负面。现在我们了解了模型如何处理单个输入句子，让我们演示如何处理一个示例社交媒体文件，并将其与我们使用`pandas`和`matplotlib`库所学的内容结合起来。
- en: In the next exercise, we are going to work with a text file source that you
    will need to import into your Jupyter Notebook. This is a small sample CSV file
    containing example social media type free text, including a hashtag, informal
    grammar, and extra punctuation.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个练习中，我们将处理一个文本文件源，你需要将其导入到你的Jupyter Notebook中。这是一个包含示例社交媒体类型自由文本的小型样本CSV文件，包括一个标签、非正式语法和额外的标点符号。
- en: 'It has 2 columns and 10 rows of content, with a header row for easy reference,
    as shown in the following screenshot:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 它有2列和10行内容，有一行标题行以便于参考，如下面的截图所示：
- en: '![](img/f74ab551-8bad-452a-b028-648fee1e3293.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/f74ab551-8bad-452a-b028-648fee1e3293.png)'
- en: Social media file input
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 社交媒体文件输入
- en: 'Let''s continue working with our Jupyter Notebook session and walk through
    how to work with this source file so that it includes a VADER sentiment and then
    analyze the results:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续使用我们的Jupyter Notebook会话，并介绍如何处理这个源文件，以便它包含VADER情感分析，然后分析结果：
- en: 'We are going to import some additional libraries so that we can work with and
    analyze the results, as follows:'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'We also have to install a new library named `twython`. Use the following command
    to install it in your Notebook session. The `twython` library includes features
    to make it easier to read social media data:'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The output will look as follows, where the resulting installation will be displayed.
    If you need to upgrade `pip`, you may need to run additional commands:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f344ef7a-acd1-458c-b462-413a7dc5e532.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
- en: 'If required, re-import the NLTK library and import the `SentimentIntensityAnalyzer`
    module. No output will be displayed after you run the cell:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Define a variable as `analyzer` to make it easier to reference later in the
    code. No output will be displayed after you run the cell:'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'If required, redownload the NLTK `vader_lexicon`:'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The output will look as follows, where the download result will be displayed:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7fdb4ce1-5635-46ce-b0d1-6ce5e7f0ba6f.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
- en: 'Now, we will read in the `.csv` file using the `pandas` library and assign
    the result to a variable named `sentences`. To validate the results, you can run
    the `len()` function:'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Be sure to upload the source CSV file in the correct file location so that you
    can reference it in your Jupyter Notebook.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: 'The output will look as follows, where the value of `10` will be displayed.
    This matches the number of records in the source CSV file:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c2354dda-409f-4918-931f-98122dd0d13a.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
- en: 'To preview the data and verify that your DataFrame is loaded correctly, you
    can run the `head()` command:'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The output will look as follows, where the results of the `head()` function
    are displayed to verify that the source file is now a DataFrame:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/69ed741e-9d6d-4e4d-af6c-619ec7d5beea.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
- en: 'The following block of code includes a few steps that look through the DataFrame,
    analyze the text source, apply the VADER sentiment metrics, and assign the results
    to a `numpy` array for easier usage. No output will be displayed after you run
    the cell:'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Be sure to double-check your indentations when entering multiple commands in
    the Jupyter Notebook input cell.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we can extend the source DataFrame so that it includes the results from
    the VADER sentiment model. This will create four new columns. No output will be
    displayed after you run the cell:'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'To see the changes, run the `head()` function again:'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The output will look as follows, where the results of the `head()` function
    are displayed to verify that the DataFrame now includes the new columns that were
    created from the loop in the previous step:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c60b59c6-3d09-4bde-bed8-5772519b0f1c.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
- en: 'While this information is useful, it still requires the user to scan through
    the results row by row. Let''s make it easier to analyze and summarize the results
    by creating a new column that categorizes the compound score results. No output
    will be displayed after you run the cell:'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Similar to before, we will take the results and add a new column to our DataFrame
    called `my prediction sentiment`. No output will be displayed after you run the
    cell:'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 与之前类似，我们将取结果并添加一个名为`my prediction sentiment`的新列到我们的DataFrame中。在运行单元格后不会显示任何输出：
- en: '[PRE28]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'To see the changes, run the `head()` function again:'
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要查看更改，请再次运行`head()`函数：
- en: '[PRE29]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The output will look as follows, where the results of the `head()` function
    are displayed to verify that the DataFrame now includes the new column that was
    created from the loop in the previous step:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示，其中将显示`head()`函数的结果，以验证DataFrame现在包括从上一步骤中循环创建的新列：
- en: '![](img/5b8e0078-f6f3-4dd9-89d7-d7bd8ffdfd7b.png)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/5b8e0078-f6f3-4dd9-89d7-d7bd8ffdfd7b.png)'
- en: 'To make it easier to interpret the results, let''s create a data visualization
    against the DataFrame by summarizing the results using an aggregate `groupby`.
    We''ll use the `plot()` function from the `matplotlib` library to display a horizontal
    bar chart:'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了更容易地解释结果，让我们通过使用聚合`groupby`来总结结果，在DataFrame上创建数据可视化。我们将使用`matplotlib`库中的`plot()`函数来显示水平条形图：
- en: '[PRE30]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The output will look as follows, where a horizontal bar chart will be displayed
    showing a summary of the count of the text by sentiment in terms of positive,
    negative, and neutral:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示，其中将显示一个水平条形图，展示文本按情感（正面、负面和中性）的计数总结：
- en: '![](img/dd8ba209-d076-46b9-902f-58fc141d195c.png)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/dd8ba209-d076-46b9-902f-58fc141d195c.png)'
- en: As you can see, we have more positive opinions in our data source. It was much
    faster to interpret the results like this because we visualized the results to
    make it easier to consume them visually. We now have a reusable workflow to analyze
    much larger volumes of unstructured data by looking at a source data file and
    applying the VADER sentiment analysis model to each record. If you replace the
    sample CSV file with any social media source, you can rerun the same steps and
    see how the analysis changes.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，我们数据源中正面意见较多。这样解释结果要快得多，因为我们通过可视化结果使其更容易视觉上消费。我们现在有一个可重用的工作流程，通过查看源数据文件并应用VADER情感分析模型到每条记录来分析大量非结构化数据。如果您用任何社交媒体源替换样本CSV文件，您可以重新运行相同的步骤，看看分析如何变化。
- en: The accuracy score for VADER models is around 96%, which has been proven to
    be more accurate than a human interpretation according to research on the subject.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: VADER模型的准确率分数约为96%，根据相关研究，这已被证明比人类解释更准确。
- en: There is some bias in the analysis since the bins of **positive**, **negative**,
    and **neutral** can be adjusted in the code. As a good data analyst, understanding
    the bias can help you either adjust it for your specific needs or be able to communicate
    the challenges of working with free text data.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 由于代码中可以调整**正面**、**负面**和**中性**的区间，因此在分析中存在一些偏差。作为一名优秀的数据分析师，理解偏差可以帮助您根据特定需求调整它，或者能够传达处理自由文本数据时的挑战。
- en: Summary
  id: totrans-155
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Congratulations—you have successfully walked through the foundations of NLP and
    should have a high-level understanding of supervised ML using the NLTK libraries!
    Sentiment analysis is a fascinating and evolving science that has many different
    moving parts. I hope this introduction is a good start to your continued research
    so that you can utilize it in your data analysis. In this chapter, we learned
    about the various elements of sentiment analysis, such as feature engineering,
    along with the process of how an NLP ML algorithm works. We also learned how to
    install NLP libraries in Jupyter to work with unstructured data, along with how
    to analyze the results created by a classifier model. With this knowledge, we
    walked through an example of how to use the VADER sentiment analysis model and
    visualized the results for analysis.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜您——您已经成功走过了NLP的基础，应该对使用NLTK库进行监督机器学习有一个高级理解！情感分析是一个令人着迷且不断发展的科学，有许多不同的组成部分。我希望这个介绍是您继续研究的好开始，以便您可以在数据分析中使用它。在本章中，我们学习了情感分析的各个方面，例如特征工程，以及NLP机器学习算法的工作过程。我们还学习了如何在Jupyter中安装NLP库以处理非结构化数据，以及如何分析分类模型创建的结果。有了这些知识，我们通过一个示例了解了如何使用VADER情感分析模型，并可视化结果以进行分析。
- en: In our last chapter, [Chapter 12](4a24a1e7-aff4-4812-ad21-20e5b8737bd9.xhtml),
    *Bringing it all Together*, we will bring together all the concepts we've covered
    in this book and walk through some real-world examples.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们上一章[第12章](4a24a1e7-aff4-4812-ad21-20e5b8737bd9.xhtml)“整合一切”中，我们将结合本书中涵盖的所有概念，并探讨一些真实世界的示例。
- en: Further reading
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: NLTK sentiment analysis example: [https://www.nltk.org/howto/sentiment.html](https://www.nltk.org/howto/sentiment.html)
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NLTK情感分析示例：[https://www.nltk.org/howto/sentiment.html](https://www.nltk.org/howto/sentiment.html)
- en: The source code for VADER and its documentation: [https://github.com/cjhutto/vaderSentiment](https://github.com/cjhutto/vaderSentiment)
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: VADER和其文档的源代码：[https://github.com/cjhutto/vaderSentiment](https://github.com/cjhutto/vaderSentiment)
- en: Bayes theorem explained: [https://plato.stanford.edu/entries/bayes-theorem/](https://plato.stanford.edu/entries/bayes-theorem/)
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 贝叶斯定理解释：[https://plato.stanford.edu/entries/bayes-theorem/](https://plato.stanford.edu/entries/bayes-theorem/)
- en: VADER sentiment analysis research: [http://comp.social.gatech.edu/papers/icwsm14.vader.hutto.pdf](http://comp.social.gatech.edu/papers/icwsm14.vader.hutto.pdf)
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: VADER情感分析研究：[http://comp.social.gatech.edu/papers/icwsm14.vader.hutto.pdf](http://comp.social.gatech.edu/papers/icwsm14.vader.hutto.pdf)
