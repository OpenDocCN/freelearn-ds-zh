["```py\n>>> from dateutil import parser\n>>> parser.parse('Thu Sep 25 10:36:28 2010')\ndatetime.datetime(2010, 9, 25, 10, 36, 28)\n>>> parser.parse('Thursday, 25\\. September 2010 10:36AM')\ndatetime.datetime(2010, 9, 25, 10, 36)\n>>> parser.parse('9/25/2010 10:36:28')\ndatetime.datetime(2010, 9, 25, 10, 36, 28)\n>>> parser.parse('9/25/2010')\ndatetime.datetime(2010, 9, 25, 0, 0)\n>>> parser.parse('2010-09-25T10:36:28Z')\ndatetime.datetime(2010, 9, 25, 10, 36, 28, tzinfo=tzutc())\n```", "```py\n>>> parser.parse('25/9/2010', dayfirst=True)\ndatetime.datetime(2010, 9, 25, 0, 0)\n```", "```py\n>>> parser.parse('10-9-25')\ndatetime.datetime(2025, 10, 9, 0, 0)\n>>> parser.parse('10-9-25', yearfirst=True)\ndatetime.datetime(2010, 9, 25, 0, 0)\n```", "```py\n>>> try:\n...    parser.parse('9/25/2010 at about 10:36AM')\n... except ValueError:\n...    'cannot parse'\n'cannot parse'\n>>> parser.parse('9/25/2010 at about 10:36AM', fuzzy=True)\ndatetime.datetime(2010, 9, 25, 10, 36)\n```", "```py\n>>> from dateutil import tz\n>>> tz.tzutc()\ntzutc()\n>>> import datetime\n>>> tz.tzutc().utcoffset(datetime.datetime.utcnow())\ndatetime.timedelta(0)\n```", "```py\n>>> tz.gettz('US/Pacific')\ntzfile('/usr/share/zoneinfo/US/Pacific')\n>>> tz.gettz('US/Pacific').utcoffset(datetime.datetime.utcnow())\ndatetime.timedelta(-1, 61200)\n>>> tz.gettz('Europe/Paris')\ntzfile('/usr/share/zoneinfo/Europe/Paris')\n>>> tz.gettz('Europe/Paris').utcoffset(datetime.datetime.utcnow())\ndatetime.timedelta(0, 7200)\n```", "```py\n>>> pst = tz.gettz('US/Pacific')\n>>> dt = datetime.datetime(2010, 9, 25, 10, 36)\n>>> dt.tzinfo\n>>> dt.astimezone(tz.tzutc())\nTraceback (most recent call last):\n  File \"/usr/lib/python2.6/doctest.py\", line 1248, in __run\n  compileflags, 1) in test.globs\n  File \"<doctest __main__[22]>\", line 1, in <module>\n  dt.astimezone(tz.tzutc())\nValueError: astimezone() cannot be applied to a naive datetime\n>>> dt.replace(tzinfo=pst)\ndatetime.datetime(2010, 9, 25, 10, 36, tzinfo=tzfile('/usr/share/zoneinfo/US/Pacific'))\n>>> dt.replace(tzinfo=pst).astimezone(tz.tzutc())\ndatetime.datetime(2010, 9, 25, 17, 36, tzinfo=tzutc())\n```", "```py\n>>> parser.parse('Wednesday, Aug 4, 2010 at 6:30 p.m. (CDT)', fuzzy=True)\ndatetime.datetime(2010, 8, 4, 18, 30)\n>>> tzinfos = {'CDT': tz.gettz('US/Central')}\n>>> parser.parse('Wednesday, Aug 4, 2010 at 6:30 p.m. (CDT)', fuzzy=True, tzinfos=tzinfos)\ndatetime.datetime(2010, 8, 4, 18, 30, tzinfo=tzfile('/usr/share/zoneinfo/US/Central'))\n```", "```py\n>>> tz.tzoffset('custom', 3600)\ntzoffset('custom', 3600)\n```", "```py\n>>> import timex\n>>> timex.tag(\"Let's go sometime this week\")\n\"Let's go sometime <TIMEX2>this week</TIMEX2>\"\n>>> timex.tag(\"Tomorrow I'm going to the park.\")\n\"<TIMEX2>Tomorrow</TIMEX2> I'm going to the park.\"\n```", "```py\n>>> timex.tag(\"Let's go sometime <TIMEX2>this week</TIMEX2>\")\n\"Let's go sometime <TIMEX2>this week</TIMEX2>\"\n```", "```py\n>>> from lxml import html\n>>> doc = html.fromstring('Hello <a href=\"/world\">world</a>')\n>>> links = list(doc.iterlinks())\n>>> len(links)\n1\n>>> (el, attr, link, pos) = links[0]\n>>> attr\n'href'\n>>> link\n'/world'\n>>> pos\n0\n```", "```py\n>>> doc.make_links_absolute('http://hello')\n>>> abslinks = list(doc.iterlinks())\n>>> (el, attr, link, pos) = abslinks[0]\n>>> link\n'http://hello/world'\n```", "```py\n>>> links = list(html.iterlinks('Hello <a href=\"/world\">world</a>'))\n>>> links[0][2]\n'/world'\n```", "```py\n>>> doc.xpath('//a/@href')[0]\n'http://hello/world'\n```", "```py\n>>> import lxml.html.clean\n>>> lxml.html.clean.clean_html('<html><head></head><body onload=loadfunc()>my text</body></html>')\n'<div><body>my text</body></div>'\n```", "```py\n>>> import nltk.util\n>>> nltk.util.clean_html('<div><body>my text</body></div>')\n'my text'\n```", "```py\n>>> from BeautifulSoup import BeautifulStoneSoup\n>>> unicode(BeautifulStoneSoup('&lt;', convertEntities='html'))\nu'<'\n>>> unicode(BeautifulStoneSoup('&amp;', convertEntities='html'))\nu'&'\n```", "```py\n>>> unicode(BeautifulStoneSoup('<', convertEntities='html'))\nu''\n>>> unicode(BeautifulStoneSoup('< ', convertEntities='html'))\nu'< '\n```", "```py\n>>> from BeautifulSoup import BeautifulSoup\n>>> soup = BeautifulSoup('Hello <a href=\"/world\">world</a>')\n>>> [a['href'] for a in soup.findAll('a')]\n[u'/world']\n```", "```py\n# -*- coding: utf-8 -*-\nimport chardet\n\ndef detect(s):\n  try:\n    return chardet.detect(s)\n  except UnicodeDecodeError:\n    return chardet.detect(s.encode('utf-8'))\n\n  def convert(s):\n    encoding = detect(s)['encoding']\n\n    if encoding == 'utf-8':\n      return unicode(s)\n    else:\n      return unicode(s, encoding)\n```", "```py\n>>> import encoding\n>>> encoding.detect('ascii')\n{'confidence': 1.0, 'encoding': 'ascii'}\n>>> encoding.detect(u'abcdé')\n{'confidence': 0.75249999999999995, 'encoding': 'utf-8'}\n>>> encoding.detect('\\222\\222\\223\\225')\n{'confidence': 0.5, 'encoding': 'windows-1252'}\n```", "```py\n>>> encoding.convert('ascii')\nu'ascii'\t\n>>> encoding.convert(u'abcdé')\nu'abcd\\\\xc3\\\\xa9'\n>>> encoding.convert('\\222\\222\\223\\225')\nu'\\u2019\\u2019\\u201c\\u2022'\n```", "```py\n>>> import unicodedata\n>>> unicodedata.normalize('NFKD', u'abcd\\xe9').encode('ascii', 'ignore')\n'abcde'\n```"]