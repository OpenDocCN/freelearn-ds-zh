- en: 13 Using Machine Learning without Premium or Embedded Capacity
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 13 使用高级或嵌入式容量之外的机器学习
- en: Thanks to the computing power now available via powerful laptops or through
    the cloud, you can enrich your analysis with insights from machine learning models
    easily and instantly. **Power BI** provides integrated tools (closely related
    to data flows) that allow you to use machine learning models developed by data
    scientists on Azure Machine Learning, models trained and deployed through **Azure
    AutoML**, or services exposed by cognitive services directly through a convenient
    graphical interface. The only drawback is that these tools (known as **Advanced
    AI**) are only enabled if you use an **Embedded** capacity, Premium capacity,
    or **Premium Per User** (**PPU**) license. Does this mean that a user using Power
    BI Desktop or simply the Power BI service with a Pro license cannot benefit from
    machine learning? Absolutely not, and we'll show you how to do it thanks to **Python**
    and **R**.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 多亏了现在通过强大的笔记本电脑或通过云提供的计算能力，您可以通过机器学习模型轻松快速地丰富您的分析。**Power BI** 提供了集成工具（与数据流密切相关），允许您使用在
    Azure Machine Learning 上开发的数据科学家机器学习模型、通过 **Azure AutoML** 训练和部署的模型，或者通过便捷的图形界面直接通过认知服务公开的服务。唯一的缺点是，这些工具（称为
    **高级 AI**）只有在您使用 **嵌入式** 容量、**高级** 容量或 **高级按用户**（**PPU**）许可证时才启用。这意味着使用 Power
    BI Desktop 或仅使用带有 Pro 许可证的 Power BI 服务的用户不能从机器学习中受益吗？绝对不是，我们将通过 **Python** 和 **R**
    展示您如何做到这一点。
- en: 'In this chapter, you will cover the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将涵盖以下主题：
- en: Interacting with ML in Power BI with data flows
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用数据流与 Power BI 中的机器学习交互
- en: Using AutoML solutions
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 AutoML 解决方案
- en: Embedding training code in Power Query
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Power Query 中嵌入训练代码
- en: Using trained models in Power Query
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Power Query 中使用训练好的模型
- en: Using trained models in Script Visuals
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Script Visuals 中使用训练好的模型
- en: Calling web services in Power Query
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Power Query 中调用 Web 服务
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 技术要求
- en: This chapter requires you to have a working internet connection and **Power
    BI Desktop** already installed on your machine. You must have properly configured
    the R and Python engines and IDEs as outlined in *Chapter 2*, *Configuring R with
    Power BI*, and *Chapter 3*, *Configuring Python with Power BI*.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章要求您拥有一个正常工作的互联网连接，并且您的机器上已经安装了 **Power BI Desktop**。您必须已按照 *第 2 章*、*配置 Power
    BI 中的 R* 和 *第 3 章*、*配置 Power BI 中的 Python* 中概述的方式正确配置了 R 和 Python 引擎和 IDE。
- en: Interacting with ML in Power BI with data flows
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用数据流与 Power BI 中的机器学习交互
- en: You can access **Advanced AI features** directly through Power BI Desktop or
    you can access **Advanced AI features for dataflow** through data flows, which
    are easy-to-use tools for transforming big data into insights to be shown in dashboards.
    But, as you can imagine, both modes require the aforementioned licenses in the
    introduction.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以直接通过 Power BI Desktop 访问 **高级 AI 功能**，或者您可以通过数据流访问 **数据流的高级 AI 功能**，这些是易于使用的大数据处理工具，可以将大数据转换为仪表板中显示的洞察。但是，正如您所想象的，这两种模式都需要介绍中提到的上述许可证。
- en: 'These features are accessible from Power BI Desktop, in the **Power Query Home**
    ribbon:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这些功能可通过 Power BI Desktop 访问，在 **Power Query 主页**标签上：
- en: '![Figure 13.1 – AI insights in Power BI Desktop](img/file334.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.1 – Power BI Desktop 中的 AI 洞察](img/file334.png)'
- en: Figure 13.1 – AI insights in Power BI Desktop
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.1 – Power BI Desktop 中的 AI 洞察
- en: The first two options (**Text Analytics** and **Vision**) you can see in *Figure
    13.1* use **Azure Cognitive Services** behind the scenes, specifically Text Analytics
    services and Computer Vision services. Basically, thanks to these features in
    Power BI, you can now use *four functions* to enrich your data through the power
    of machine learning.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *图 13.1* 中您可以看到的前两个选项（**文本分析**和**视觉**）在幕后使用 **Azure 认知服务**，具体是文本分析服务和计算机视觉服务。基本上，多亏了
    Power BI 中的这些功能，您现在可以使用 *四个功能* 通过机器学习的力量丰富您的数据。
- en: '![Figure 13.2 – Cognitive Services functions in Power BI](img/file335.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.2 – Power BI 中的认知服务功能](img/file335.png)'
- en: Figure 13.2 – Cognitive Services functions in Power BI
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.2 – Power BI 中的认知服务功能
- en: 'These are as follows:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这些功能如下：
- en: '**TagImages**. Analyzes images to generate tags based on what they contain'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**TagImages**. 分析图像，根据其内容生成标签'
- en: '**ExtractKeyPhrases**. Evaluates unstructured text, and for each text column,
    returns a list of key phrases'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ExtractKeyPhrases**. 评估非结构化文本，并为每个文本列返回一组关键短语'
- en: '**DetectLanguage**. Evaluates text input, and for each column, returns the
    language name and ISO identifier'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**DetectLanguage**. 评估文本输入，并为每一列返回语言名称和 ISO 标识符'
- en: '**ScoreSentiment**. Evaluates text input and returns a sentiment score for
    each document, ranging from 0 (negative) to 1 (positive)'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ScoreSentiment**. 评估文本输入并为每个文档返回一个情感分数，范围从0（负面）到1（正面）'
- en: The other option of AI Insights is to be able to use models hosted in **Azure
    Machine Learning** as scoring functions in Power Query.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: AI Insights的另一种选择是能够在Power Query中将托管在**Azure机器学习**中的模型用作评分函数。
- en: '![Figure 13.3 – Azure Machine Learning functions in Power BI](img/file336.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![图13.3 – Power BI中的Azure机器学习功能](img/file336.png)'
- en: Figure 13.3 – Azure Machine Learning functions in Power BI
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.3 – Power BI中的Azure机器学习功能
- en: To top it off, the Advanced AI features also include the ability to create machine
    learning models on the fly via a GUI thanks to **AutoML for dataflows**.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 更重要的是，高级AI功能还包括通过**数据流自动机器学习**在GUI上即时创建机器学习模型的能力。
- en: 'AutoML solutions are very convenient, especially for the analyst who doesn’t
    have much experience with machine learning. You will see this in detail in the
    next section. Now you just need to know that in Power BI, you can generate three
    types of models: **classifications** (binary or multi-label), **regressions**,
    and **time series forecasting** (will be available soon).'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 自动机器学习解决方案非常方便，特别是对于没有太多机器学习经验的分析师来说。您将在下一节中详细了解这一点。现在您只需要知道，在Power BI中，您可以生成三种类型的模型：**分类**（二元或多标签）、**回归**和**时间序列预测**（即将推出）。
- en: '![Figure 13.4 – AutoML for data flows in Power BI](img/file337.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![图13.4 – Power BI中的数据流自动机器学习](img/file337.png)'
- en: Figure 13.4 – AutoML for data flows in Power BI
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.4 – Power BI中的数据流自动机器学习
- en: Behind the scenes, there is the Azure AutoML service that allows you to do model
    training, but by leveraging data flows, you don't need to instantiate a machine
    learning workspace to run AutoML experiments.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在幕后，有Azure AutoML服务允许您进行模型训练，但通过利用数据流，您不需要实例化机器学习工作区来运行自动机器学习实验。
- en: A user who only has a Power BI Pro license cannot access these fantastic features
    directly from the Power BI GUI. However, thanks to the introduction of Python
    and R in Power BI, it is possible to use machine learning algorithms or external
    services that facilitate their implementation with just a few lines of code.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 只有Power BI Pro许可证的用户无法直接从Power BI GUI访问这些出色的功能。然而，多亏了Python和R在Power BI中的引入，现在可以使用机器学习算法或外部服务，只需几行代码就可以实现它们的实现。
- en: Is it really possible that just a few lines of code are enough to train a machine
    learning model? Where is the trick!? Let's explain the mystery.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 真的可能只有几行代码就足够训练一个机器学习模型吗？其中的技巧在哪里？！让我们来解释这个谜团。
- en: Using AutoML solutions
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用自动机器学习解决方案
- en: 'Writing code from scratch to do machine learning requires specific knowledge
    that a generic analyst using Power BI often doesn’t know. Therefore, we recommend
    the use of **Automated Machine Learning** (**AutoML**) processes from here on
    out for analysts who do not have a data science background. Does this mean that
    anyone can create an accurate machine learning model without knowing the theory
    behind this science simply by using AutoML algorithms? Absolutely not! The following
    applies:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 从头编写代码进行机器学习需要特定的知识，而通常使用Power BI的通用分析师并不具备这些知识。因此，我们建议从现在开始，对于没有数据科学背景的分析师，推荐使用**自动机器学习**（**AutoML**）过程。这难道意味着任何人都可以仅通过使用AutoML算法，而不了解这一科学背后的理论，就能创建一个准确的机器学习模型吗？绝对不是！以下适用：
- en: '**Important Note**'
  id: totrans-36
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**重要提示**'
- en: ''
  id: totrans-37
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: An AutoML tool relieves the analyst of all those repetitive tasks typical of
    a machine learning process (hyperparameter tuning, model selection, and so on).
    Often, those that require specific theoretical knowledge on the part of the analyst
    (for example, missing value imputation, dataset balancing strategies, feature
    selection, and feature engineering) are left out of the automated steps. Therefore,
    not applying the appropriate transformations that only an expert knows to the
    dataset before starting an AutoML process leads to the generation of a baseline
    model that might be sufficiently accurate, but could not ensure product performance.
  id: totrans-38
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 自动机器学习工具减轻了分析师在机器学习过程中典型的重复性任务（超参数调整、模型选择等）。通常，那些需要分析师具备特定理论知识（例如，缺失值填充、数据集平衡策略、特征选择和特征工程）的步骤被排除在自动化步骤之外。因此，在开始自动机器学习过程之前，没有应用只有专家才知道的适当转换到数据集，会导致生成一个可能足够准确但无法确保产品性能的基线模型。
- en: You might think that AutoML tools are hated by data scientists. This is also
    a myth. Many of them use it as a quick and dirty prototyping tool and as an executor
    of repetitive steps while they focus on more critical tasks.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会认为AutoML工具受到数据科学家的厌恶。这也是一个神话。他们中的许多人将其用作快速原型设计和重复步骤的执行工具，同时他们专注于更关键的任务。
- en: In this chapter, we will be satisfied with obtaining discrete performance models
    (sometimes very good if we are lucky enough to have a properly transformed training
    dataset), and so the outputs provided by AutoML solutions are more than fine.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将满足于获得离散的性能模型（如果我们足够幸运，拥有一个正确转换的训练数据集，有时会非常好），因此AutoML解决方案提供的输出已经足够好了。
- en: Moreover, we will exclusively use AutoML solutions in Python as it is the most
    widely used language in most third-party machine learning platforms. The R language
    is a little less widely used than Python, but that doesn't mean the results you
    get in R are any less valid. On the contrary, as you may have noticed in previous
    chapters, some specialized packages of statistical functions that allow high flexibility
    of data manipulation exist only for R and not for Python.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们将专门使用Python中的AutoML解决方案，因为它是大多数第三方机器学习平台中最广泛使用的语言。R语言的使用范围略小于Python，但这并不意味着你在R中得到的结果有任何不准确性。相反，正如你可能在之前的章节中注意到的，一些仅存在于R而不存在于Python中的专门统计函数包，允许对数据进行高度灵活的操作。
- en: Simply put, working with machine learning in Python to date allows models to
    be easily shared between popular platforms. Therefore, we suggest it for Power
    BI analysts, who perhaps prefer to delegate model creation to more specialized
    platforms and then import them in Power BI.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，到目前为止，使用Python进行机器学习工作允许模型在流行的平台之间轻松共享。因此，我们建议它适用于Power BI分析师，他们可能更愿意将模型创建委托给更专业的平台，然后再将其导入Power
    BI。
- en: Let's see what AutoML tools we'll be using in the code for this chapter.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看本章代码中将使用哪些AutoML工具。
- en: PyCaret
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: PyCaret
- en: '**PyCaret** ([https://pycaret.org/](https://pycaret.org/)) is an open source,
    low-code machine learning library in Python that automates the cycle of machine
    learning experiments, democratizing access to these advanced techniques to business
    analysts and domain experts, and also helping data scientists to become more efficient
    and productive.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**PyCaret** ([https://pycaret.org/](https://pycaret.org/)) 是一个开源、低代码的Python机器学习库，它自动化了机器学习实验周期，使商业分析师和领域专家能够访问这些高级技术，同时也帮助数据科学家变得更加高效和高效。'
- en: 'The types of problems that PyCaret can solve are as follows:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: PyCaret可以解决的问题类型如下：
- en: '**Classification** (predicting a categorical target variable)'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分类**（预测一个分类目标变量）'
- en: '**Regression** (predicting a numeric target variable)'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**回归**（预测一个数值目标变量）'
- en: '**Clustering** (grouping of observations into specific sets, each with its
    own properties)'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**聚类**（将观测值分组到具有特定属性的特定集合中）'
- en: '**Anomaly Detection** (the process of finding outliers in a dataset, and which
    are far fewer in number than with usual observations)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**异常检测**（在数据集中寻找异常值的过程，这些异常值的数量远少于常规观测值）'
- en: '**Natural Language Processing** (text transformations in useful features for
    classifications and regressions)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自然语言处理**（用于分类和回归的有用特征中的文本转换）'
- en: '**Association Rules** (a rule-based technique that finds important relationships
    between features according to probability theory)'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**关联规则**（一种基于概率理论的基于规则的技巧，用于根据概率理论在特征之间找到重要关系）'
- en: For more experienced users, PyCaret also provides convenient functions for model
    ensembling and model explanation.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 对于更有经验的用户，PyCaret还提供了方便的模型集成和模型解释功能。
- en: Azure AutoML
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Azure AutoML
- en: Azure AutoML is a cloud-based service that can be used to automate the construction
    of machine learning pipelines for classification, regression, and forecasting
    tasks. Such pipelines involve a pre-processing phase of the dataset to better
    fit the training algorithms used in the next phase. After tuning and training
    multiple models, Azure AutoML selects the most accurate model among them, while
    also considering two other models resulting from the ensembling of the previously
    trained models.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: Azure AutoML是一种基于云的服务，可用于自动化构建用于分类、回归和预测任务的机器学习管道。这些管道涉及数据集的预处理阶段，以便更好地适应下一阶段使用的训练算法。在调整和训练多个模型后，Azure
    AutoML将选择其中最准确的模型，同时还会考虑由先前训练模型集成产生的另外两个模型。
- en: 'The available tasks are as follows:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 可用的任务如下：
- en: Classification
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分类
- en: Regression
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回归
- en: Time series forecasting
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 时间序列预测
- en: For more detailed coverage of this platform, please take a look at the references.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于这个平台的详细信息，请参阅参考资料。
- en: RemixAutoML for R
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: RemixAutoML for R
- en: For the sake of completeness, we also suggest one of AutoML's solutions for
    R, which is **RemixAutoML** ([https://github.com/AdrianAntico/RemixAutoML](https://github.com/AdrianAntico/RemixAutoML)).
    It is a set of functions that facilitate the use of many AutoML packages available
    for R (CatBoost, LightGBM, XGBoost, and H2O). In addition to giving the inexperienced
    analyst the ability to create machine learning models with a few lines of code
    thanks to AutoML, this library also contains very advanced features (for example,
    features for feature engineering and time series forecasting), often used by more
    experienced analysts.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 为了完整起见，我们还建议R的AutoML解决方案之一，即**RemixAutoML**（[https://github.com/AdrianAntico/RemixAutoML](https://github.com/AdrianAntico/RemixAutoML)）。这是一个函数集，它简化了R中许多AutoML包的使用（CatBoost、LightGBM、XGBoost和H2O）。除了让没有经验的分析师能够通过AutoML用几行代码创建机器学习模型之外，这个库还包含非常高级的功能（例如，用于特征工程和时间序列预测的功能），这些功能通常被更有经验的分析师使用。
- en: Let's now look at the various ways to use machine learning models in Power BI.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看在Power BI中使用机器学习模型的多种方法。
- en: Embedding training code in Power Query
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在Power Query中嵌入训练代码
- en: One of the easiest solutions to train a machine learning model is to write the
    code needed to do so directly in Power Query, right after importing a dataset
    on which you will build the model.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 训练机器学习模型的最简单解决方案之一是在导入您将构建模型的数据集后，直接在Power Query中编写所需的代码。
- en: 'Training a model on a fairly large dataset typically takes quite a bit of time
    to complete. As you embed the code in Power Query, it will run every time the
    data is refreshed, and this may result in a non-negligible delay in getting the
    data online. Hence, the following applies:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在相当大的数据集上训练模型通常需要相当长的时间来完成。当您在Power Query中嵌入代码时，它将在每次数据刷新时运行，这可能会导致在线获取数据时出现不可忽视的延迟。因此，以下适用：
- en: '**Important Note**'
  id: totrans-67
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**重要提示**'
- en: ''
  id: totrans-68
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This solution is recommended when you are certain that the time required to
    complete the model training is acceptable.
  id: totrans-69
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 当您确信完成模型训练所需的时间是可以接受的时，建议使用此解决方案。
- en: Let's now look at an example of how to write some training code using PyCaret.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看如何使用PyCaret编写一些训练代码的示例。
- en: Training and using ML models with PyCaret
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用PyCaret训练和使用ML模型
- en: Let's take the Titanic disaster dataset to train a machine learning model. Specifically,
    we want to create a model that predicts whether a passenger survives (the `Survived`
    column) based on their attributes described by the other features in the dataset.
    Evidently, this is a *binary classification* (does it survive? yes or no) that
    we can easily implement with PyCaret.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以泰坦尼克号灾难数据集为例来训练一个机器学习模型。具体来说，我们希望创建一个模型，根据数据集中其他特征描述的乘客属性来预测乘客是否幸存（`Survived`列）。显然，这是一个*二元分类*（是否幸存？是或否），我们可以很容易地使用PyCaret实现。
- en: 'As PyCaret is constantly evolving and so are all the other dependent libraries,
    you need to also install the **Visual C++ Build tools** to build the necessary
    wheels and avoid errors such as *Failed building wheel for <package>*. Here are
    all the steps needed to install PyCaret correctly for Windows:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 由于PyCaret和其他所有依赖库都在不断进化，因此您还需要安装**Visual C++ Build tools**来构建必要的轮子并避免诸如*Failed
    building wheel for <package>*之类的错误。以下是正确安装PyCaret所需的全部步骤，适用于Windows：
- en: Download the installer from [https://visualstudio.microsoft.com/visual-cpp-build-tools/](https://visualstudio.microsoft.com/visual-cpp-build-tools/)
    and run it.
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从[https://visualstudio.microsoft.com/visual-cpp-build-tools/](https://visualstudio.microsoft.com/visual-cpp-build-tools/)下载安装程序并运行它。
- en: In the next window, check just the **Desktop development with C++** option.
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在下一个窗口中，仅选择**使用C++进行桌面开发**选项。
- en: You will be prompted to restart the machine. Do so.
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您将收到提示重新启动计算机。请这样做。
- en: 'Once your laptop has restarted, run your Anaconda Prompt and enter the following
    command to create the new `pycaret_env` environment:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦您的笔记本电脑重新启动，运行您的Anaconda Prompt并输入以下命令以创建新的`pycaret_env`环境：
- en: '[PRE0]'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Enter the following command to switch to the new environment:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入以下命令以切换到新环境：
- en: '[PRE1]'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Enter the following command to install the full version of PyCaret:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入以下命令以安装PyCaret的完整版本：
- en: '[PRE2]'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Having done that, you can move on to see the training code of the model. The
    only little hiccup is the handling of missing values in the dataset (you already
    had a chance to analyze them in *Chapter 12*, *Adding Statistics Insights, Outliers,
    and Missing Values*). Unfortunately, PyCaret currently only supports handling
    missing values using the simplest methods, namely, imputation using the mean or
    median for numeric values, and imputation using the mode or a fixed string for
    categorical values. Since we want to show you how to impute missing values using
    the *K-Nearest Neighbors (KNN)* algorithm as anticipated in *Chapter 12*, *Adding
    Statistics Insights, Outliers, and Missing Values*, you will write a few more
    lines of code than usual.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 完成这些步骤后，您可以继续查看模型的训练代码。唯一的小问题是处理数据集中的缺失值（您已经在*第12章*，*添加统计洞察、异常值和缺失值*中分析过它们）。不幸的是，PyCaret目前仅支持使用最简单的方法处理缺失值，即使用均值或中位数对数值进行推断，以及使用众数或固定字符串对分类值进行推断。由于我们想要向您展示如何使用*K-Nearest
    Neighbors (KNN)*算法推断缺失值，正如*第12章*，*添加统计洞察、异常值和缺失值*中预期的那样，您将需要编写比平时更多的代码。
- en: The code used to impute the missing values via the KNN algorithm will be used
    in the first transformation step in Power BI, after importing the data from the
    Titanic dataset. You can find the code in the `01-impute-dataset-with-knn.py`
    file in the `Chapter13/Python` folder. It will take care first to operate a simple
    feature selection, eliminating those fields that could cause noise during the
    training of the model. After that, since the above imputation algorithm exposed
    by scikit-learn via the **KNNImputer** module does not handle categorical variables
    in the dataset, the code also takes care of doing the encoding of the categorical
    variables using the **ordinal encoding** technique (using a mapping of categories
    to integers) thanks to the **OrdinalEncoder** module of scikit-learn. At this
    point, the code imputes the missing values using the default distance measure,
    that is, a Euclidean distance measure that will not include NaN values when calculating
    the distance between members of the training dataset.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 用于通过KNN算法推断缺失值的代码将在Power BI中导入Titanic数据集后的第一个转换步骤中使用。您可以在`Chapter13/Python`文件夹中的`01-impute-dataset-with-knn.py`文件中找到代码。首先，代码将进行简单的特征选择，消除在模型训练过程中可能引起噪声的字段。之后，由于上述由scikit-learn通过**KNNImputer**模块公开的推断算法不处理数据集中的分类变量，代码还负责使用**ordinal
    encoding**技术（使用类别到整数的映射）对分类变量进行编码，这得益于scikit-learn的**OrdinalEncoder**模块。在此阶段，代码使用默认的距离度量来推断缺失值，即欧几里得距离度量，在计算训练数据集成员之间的距离时不会包括NaN值。
- en: Once the imputed dataset is available, you can train the model with which you
    will then score a test dataset. You can find the code in the `02-train-model-with-pycaret.py`
    file in the `Chapter13/Python` folder. For convenience, you will use 95% of the
    imputed dataset to train the model, while the remaining 5% will be used as a test
    dataset. All this will go in a transformation step following the previous one
    used for the imputation of missing values in Power BI.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦获得推断数据集，您可以使用该数据集来训练模型，然后对测试数据集进行评分。您可以在`Chapter13/Python`文件夹中的`02-train-model-with-pycaret.py`文件中找到代码。为了方便起见，您将使用推断数据集的95%来训练模型，而剩余的5%将用作测试数据集。所有这些步骤都将放在Power
    BI中用于缺失值推断的前一个转换步骤之后。
- en: You'll split the dataset into training and test sets thanks to scikit-learn's
    `train_test_split()` method. After that, the model training is done very simply
    by calling PyCaret's `setup()` and `compare_models()` functions. In the `setup()`
    function, you will define which dataframe to use for training, the target variable
    (`Survived`), and which are the categorical and which are the ordinal variables.
    Moreover, it is necessary to use silent mode, otherwise user intervention would
    be required to validate the inferred types of the other variables. The `compare_models()`
    function trains and evaluates the performance of all models provided by PyCaret
    for classification using cross-validation. In addition to returning the best-performing
    model, this function also returns the performance values of each model returned
    by cross-validation.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 你将利用 scikit-learn 的 `train_test_split()` 方法将数据集分为训练集和测试集。之后，通过调用 PyCaret 的 `setup()`
    和 `compare_models()` 函数，模型训练将非常简单。在 `setup()` 函数中，你需要定义用于训练的数据框，目标变量（`Survived`），以及哪些是分类变量，哪些是顺序变量。此外，必须使用静默模式，否则需要用户干预来验证其他变量的推断类型。`compare_models()`
    函数使用交叉验证训练并评估 PyCaret 为分类提供的所有模型的性能。除了返回表现最佳的模型外，此函数还返回交叉验证返回的每个模型的性能值。
- en: '![Figure 13.5 – Performance of all models](img/file338.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.5 – 所有模型的性能](img/file338.png)'
- en: Figure 13.5 – Performance of all models
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.5 – 所有模型的性能
- en: '*Figure 13.5* shows several typical classification metrics for each model.
    One of the most widely used is the **Area Under the ROC Curve** (**AUC** or **AUC-ROC**)
    when the dataset is balanced (in other words, when there is a slight disproportion
    between the number of observations associated with one class of the target variable
    versus the other class). The following remark applies:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 13.5* 展示了每个模型的几个典型分类指标。其中最常用的是当数据集平衡时（换句话说，当目标变量的一个类别与另一个类别的观测数之间略有不成比例时）的
    **ROC 曲线下面积**（**AUC** 或 **AUC-ROC**）。以下说明适用：'
- en: '**Important Note**'
  id: totrans-90
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**重要提示**'
- en: ''
  id: totrans-91
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The `compare_models()` function doesn’t work in Power BI unless you disable
    the parallelism, passing `n_jobs=1` into the `setup()` function. If you don’t
    assign `1` to `n_job`, by default, PyCaret assigns the value -1 (maximum parallelism)
    and behind the scenes, the best model is computed correctly using multiple threads,
    but Power BI can't trace it back to the main process, so it gets stuck.
  id: totrans-92
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`compare_models()` 函数在 Power BI 中无法正常工作，除非你禁用并行处理，通过将 `n_jobs=1` 传递给 `setup()`
    函数。如果你没有将 `1` 分配给 `n_job`，则 PyCaret 默认将其设置为 -1（最大并行性），在幕后，最佳模型会使用多个线程正确计算，但 Power
    BI 无法追踪到主进程，因此会卡住。'
- en: 'With an AUC of about 0.85 (it can vary as the process is stochastic), the **Random
    Forest Classifier** appears to be the best model obtained by training 95% of the
    imputed dataset. Then you will use the newly trained model (`best_model`) to obtain
    predictions of the remaining 5% of the dataset via PyCaret''s `predict_model()`
    function. You will get a result similar to this one:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在 AUC 大约为 0.85（由于过程是随机的，因此可能会有所变化）的情况下，**随机森林分类器**似乎是通过训练 95% 的补全数据集获得的最佳模型。然后，你将使用新训练的模型（`best_model`）通过
    PyCaret 的 `predict_model()` 函数来获取数据集剩余 5% 的预测。你将得到类似以下的结果：
- en: '![Figure 13.6 – Predictions of the test dataset](img/file339.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.6 – 测试数据集的预测](img/file339.png)'
- en: Figure 13.6 – Predictions of the test dataset
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.6 – 测试数据集的预测
- en: 'As you can see, the result generated by scoring the dataset consists of two
    new columns for classification: the `Score` column represents an estimate of a
    measure, such as the probability with which the predicted classes are those reported
    in the `Label` column. If you are interested in having a true probability estimate,
    you have to **calibrate** the model (have a look at the references for more details).
    The trained model will also be saved as a PKL file for future reuse.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，对数据集进行评分生成的结果包括两个新的分类列：`Score` 列代表一个度量值的估计，例如预测类别在 `Label` 列中报告的概率。如果你对获得真正的概率估计感兴趣，你必须**校准**模型（更多细节请参阅参考文献）。训练的模型也将保存为
    PKL 文件以供将来重用。
- en: Let's look at how to implement what's explained up here in Power BI.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何在 Power BI 中实现这里所解释的内容。
- en: Using PyCaret in Power BI
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在 Power BI 中使用 PyCaret
- en: 'First, make sure that Power BI Desktop references the new `pycaret_env` Python
    environment in **Options**. Then, follow these steps:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，确保 Power BI Desktop 在 **选项** 中引用了新的 `pycaret_env` Python 环境。然后，按照以下步骤操作：
- en: Click on **Get Data**, search for `web`, select **Web**, and then click on **Connect**.
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 **获取数据**，搜索 `web`，选择 **Web**，然后点击 **连接**。
- en: Enter the `http://bit.ly/titanic-dataset-csv` URL into the URL textbox and click
    **OK**.
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 `http://bit.ly/titanic-dataset-csv` URL 输入到 URL 文本框中，然后点击 **确定**。
- en: You’ll see a preview of the data. Then, click **Transform Data**.
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你将看到数据预览。然后，点击 **转换数据**。
- en: Click **Transform** on the ribbon and then **Run Python script**.
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在功能区点击 **转换**，然后点击 **运行 Python 脚本**。
- en: Enter the script you can find in the `01-impute-dataset-with-knn.py` file in
    the `Chapter13\Python` folder.
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `Chapter13\Python` 文件夹中的 `01-impute-dataset-with-knn.py` 文件中找到脚本并输入。
- en: We are only interested in the data in the `df_imputed` dataframe. So, click
    on its **Table** value.
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们只对 `df_imputed` 数据框中的数据进行关注。因此，点击其 **表** 值。
- en: You'll see a preview of the dataset with all the missing values imputed.
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你将看到所有缺失值已填充的数据集预览。
- en: Click **Transform** on the ribbon and then **Run Python script**.
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在功能区点击 **转换**，然后点击 **运行 Python 脚本**。
- en: Enter the script you can find in the `02-train-model-with-pycaret.py` file in
    the `Chapter13\Python` folder.
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `Chapter13\Python` 文件夹中的 `02-train-model-with-pycaret.py` 文件中找到脚本并输入。
- en: We are only interested in the data in the `predictions` dataframe. So, click
    on its **Table** value.
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们只对 `predictions` 数据框中的数据进行关注。因此，点击其 **表** 值。
- en: You'll see a preview of the dataset with the predictions generated by the model
    and the input dataset.
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你将看到由模型生成的预测和输入数据集的预览。
- en: Click **Home** on the ribbon and then click **Close & Apply**.
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在功能区点击 **主页**，然后点击 **关闭并应用**。
- en: Amazing! You have just trained a machine learning model and then scored a test
    dataset using a few lines of Python code thanks to PyCaret!
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 太棒了！你刚刚使用几行 Python 代码训练了一个机器学习模型，并使用 PyCaret 对测试数据集进行了评分！
- en: Let's now see how to proceed when the model is trained outside of Power BI.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看看当模型在 Power BI 之外训练时该如何操作。
- en: Using trained models in Power Query
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 Power Query 中使用训练好的模型
- en: 'As you already saw in *Chapter 4*, *Importing Unhandled Data Objects*, you
    used to share objects that were the result of complex, time-consuming processing
    (thus also a machine learning model) in a serialized format specific to the language
    you were using. At that point, it was very simple to deserialize the file and
    get the model ready to be used in Power Query to predict the target variable of
    new observations. However, it is important to know the dependencies needed by
    the scoring function (which gets the new observations as input and returns the
    predictions), since they are closely related to how the training of the model
    took place. For this reason, we recommend the following:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在 *第 4 章* 中所看到的，*导入未处理的数据对象*，你过去通常会将复杂、耗时处理的结果（因此也是一个机器学习模型）以你使用的语言特定的序列化格式共享。在那个阶段，反序列化文件并准备好在
    Power Query 中使用以预测新观察的目标变量是非常简单的。然而，了解评分函数（它接收新观察作为输入并返回预测）所需的依赖关系很重要，因为它们与模型的训练方式密切相关。因此，我们建议以下做法：
- en: '**Important Note**'
  id: totrans-116
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**重要提示**'
- en: ''
  id: totrans-117
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: When you need to use a serialized machine learning model provided by a third
    party, make sure that whoever developed it also provides you with a working scoring
    function in order to avoid unnecessary headaches when predicting target values
    for unknown observations.
  id: totrans-118
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 当你需要使用第三方提供的序列化机器学习模型时，确保该模型的开发者也为你提供了一个可工作的评分函数，以避免在预测未知观察的目标值时出现不必要的麻烦。
- en: If you think about it, the ability to serialize and deserialize a machine learning
    model could somehow solve the delay problem raised in the case of training the
    model directly in Power Query in the previous section. Suppose you run the embedded
    training code for the first time. Immediately afterward, you serialize the model
    and save it to disk. On the next refresh, instead of running the training code
    again, you can check whether the serialized model file exists in the expected
    path. If yes, you load the file, deserialize it, and use that model for the next
    steps; otherwise, you run the training code again.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你这么想，序列化和反序列化机器学习模型的能力可以解决在上一节中直接在 Power Query 中训练模型时提出的延迟问题。假设你第一次运行嵌入式训练代码。紧接着，将模型序列化并保存到磁盘上。在下一次刷新时，你不必再次运行训练代码，而是检查预期的路径中是否存在序列化模型文件。如果存在，则加载该文件，反序列化它，并使用该模型进行下一步；如果不存在，则再次运行训练代码。
- en: Evidently, the aforementioned process involves the intervention of an expert
    who decides to eliminate the serialized file when the model does not perform very
    well because perhaps the business data has, in the meantime, changed substantially
    such that the previous model is not accurate any longer, like it was after the
    training undertaken with the past data (a process known as **model drift**; take
    a look at the references for more details).
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，上述过程涉及到专家的干预，当模型表现不佳时，专家会决定删除序列化文件，因为在此期间，业务数据可能已经发生了重大变化，以至于之前的模型不再准确，就像使用过去数据进行的训练之后那样（这个过程被称为**模型漂移**；更多细节请参阅参考资料）。
- en: We will not go into the implementation details of this solution, but we wanted
    to provide just a tip for a possible solution to the problem raised in the previous
    section.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会深入探讨此解决方案的实现细节，但我们想提供一个针对上一个部分提出的问题的可能解决方案的提示。
- en: Let’s now implement the scoring of a dataset of unseen observations in Power
    BI using an already trained PyCaret model.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将使用已经训练好的PyCaret模型在Power BI中实现一个未见数据集的评分。
- en: Scoring observations in Power Query using a trained PyCaret model
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用训练好的PyCaret模型在Power Query中进行评分
- en: If you remember correctly, in the previous section, you saved the model trained
    in Power BI to a PKL file on disk. You also exported the test dataset calculated
    in the same code to CSV. In this session, you will directly use the serialized
    model, loading it with the `load_model()` function, and the test CSV dataset to
    be scored in Power BI. Since the model was trained using PyCaret, the scoring
    function to use is simply given by the `predict_model()` function. Keep in mind
    that the scoring function may be more complex when not using a framework such
    as PyCaret that simplifies things.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您记得正确的话，在上一个部分中，您将Power BI中训练好的模型保存到了磁盘上的PKL文件中。您还导出了相同代码中计算的测试数据集到CSV文件。在本会话中，您将直接使用序列化模型，使用`load_model()`函数加载它，以及要评分的测试CSV数据集。由于模型是使用PyCaret训练的，所以评分函数简单给出为`predict_model()`函数。请记住，当不使用像PyCaret这样的简化框架时，评分函数可能更复杂。
- en: 'These are the steps to follow in Power BI:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在Power BI中遵循以下步骤：
- en: 'Click on **Get Data**, select **Text/CSV**, and then click on **Connect**:'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**获取数据**，选择**文本/CSV**，然后点击**连接**：
- en: Select the `titanic-test.csv` file in the `Chapter13` folder and click **Open**.
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`Chapter13`文件夹中选择`titanic-test.csv`文件，然后点击**打开**。
- en: You’ll see a preview of the test data. Then, click **Transform Data**.
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您将看到测试数据的预览。然后，点击**转换数据**。
- en: Click **Transform** on the ribbon and then **Run Python script**.
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在功能区点击**转换**，然后点击**运行Python脚本**。
- en: Enter the script you can find in the `03-score-dataset-using-pycaret-model.py`
    file in the `Chapter13\Python` folder.
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`Chapter13\Python`文件夹中的`03-score-dataset-using-pycaret-model.py`文件中输入脚本。
- en: We are only interested in the `predictions` dataframe. So, click on its **Table**
    value.
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们只对`predictions`数据框感兴趣。因此，点击其**表**值。
- en: You'll see a preview of the test dataset with two additional columns – `Label`
    and `Score`.
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您将看到测试数据集的预览，其中增加了两个额外的列——`标签`和`评分`。
- en: Click **Home** on the ribbon and then click **Close & Apply**.
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在功能区点击**主页**，然后点击**关闭并应用**。
- en: 'As you can see, this is the most immediate and common way to use a custom machine
    learning model for scoring in Power BI. In fact, we recommend the following:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，这是在Power BI中使用自定义机器学习模型进行评分的最直接和最常见的方式。事实上，我们建议以下做法：
- en: '**Important Note**'
  id: totrans-135
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**重要提示**'
- en: ''
  id: totrans-136
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: It is convenient to do the training and, in general, to manage a machine learning
    model in platforms external to Power BI in order to decouple any development/tuning
    interventions of the model from the rest of the report.
  id: totrans-137
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在Power BI之外的平台进行训练和通常管理机器学习模型是很方便的，这样可以解耦模型开发/调整干预措施与报告的其他部分。
- en: Let's now see instead how to use serialized machine learning models directly
    in **Script Visuals**.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看看如何在**脚本可视化**中直接使用序列化的机器学习模型。
- en: Using trained models in Script Visuals
  id: totrans-139
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在脚本可视化中使用训练好的模型
- en: As you learned in *Chapter 4*, *Importing Unhandled Data Objects*, thanks to
    object serialization and its string representation, you can import any object
    into a Python or R visual in the form of a dataframe of strings. Once said dataframe
    is available in the script visual, you can revert it to the original object via
    inverse deserialization transformations. Since you can do what we described with
    any object, evidently you can also do it for machine learning models already trained
    outside of Power BI.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 如你在 *第4章* 中所学，*导入未处理的数据对象*，由于对象序列化和其字符串表示，你可以将任何对象以字符串数据框的形式导入到Python或R视觉中。一旦该数据框在脚本视觉中可用，你可以通过逆序列化转换将其还原为原始对象。由于你可以对任何对象执行我们描述的操作，显然你也可以对已在Power
    BI外部训练的机器学习模型执行此操作。
- en: When the appropriately deserialized model is available in the *Script Visual*
    session, new observations can be predicted immediately using the scoring function
    described in the previous section.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 当在 *Script Visual* 会话中可用适当反序列化的模型时，可以使用上一节中描述的评分函数立即预测新的观测值。
- en: 'The first thing you might ask yourself is what''s the point of being able to
    score a dataset inside a script visual when the data must always be available
    first in the Power BI data model in order to use it in the visual. In fact, if
    the data of the observations to use as input to the model is already found in
    the data model of Power BI, it could be better to apply batch scoring directly
    in Power Query and so use the predictions as a new column of the dataset. All
    of this is absolutely true. However, there are some cases in which it is convenient
    to use a script visual:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会问自己，当数据必须首先在Power BI数据模型中可用才能在视觉中使用时，在脚本视觉中评分数据集有什么意义。事实上，如果用作模型输入的观测数据已经在Power
    BI的数据模型中找到，那么直接在Power Query中应用批量评分可能更好，这样就可以将预测作为数据集的新列使用。所有这些都是绝对正确的。然而，在某些情况下，使用脚本视觉是方便的：
- en: '**Important Note**'
  id: totrans-143
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**重要提示**'
- en: ''
  id: totrans-144
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: It is convenient to use a machine learning model in a script visual when you
    need to realize some simulation reports that allow you to explore the outputs
    of the model and vary the variables in play dynamically without having to refresh
    the entire report.
  id: totrans-145
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 当你需要实现一些允许你探索模型输出并动态改变变量的模拟报告时，在脚本视觉中使用机器学习模型是方便的，而不必刷新整个报告。
- en: In this case, we suggest using **What-If parameters** ([https://bit.ly/power-bi-what-if](https://bit.ly/power-bi-what-if))
    in Power BI for numeric features, which are dynamic and give the user a very usable
    report. For categorical variables, you can enter their content manually in Power
    BI using the **Enter Data** feature, which creates a disconnected table. What-If
    parameters create disconnected tables by default in the data model.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们建议使用Power BI中的 **假设参数** ([https://bit.ly/power-bi-what-if](https://bit.ly/power-bi-what-if))
    来处理数值特征，它们是动态的，并为用户提供了一个非常实用的报告。对于分类变量，你可以使用Power BI中的 **输入数据** 功能手动输入它们的内容，这将创建一个断开连接的表。假设参数默认在数据模型中创建断开连接的表。
- en: To properly understand this paragraph, make sure you understand the content
    of *Chapter 4*, *Importing Unhandled Data Objects*. Suppose you have to provide
    observations to a machine learning model that expects two variables as input –
    a numeric one and a categorical one. When passing the information to the script
    visual’s dataframe, in addition to the fields of the serialized model’s dataframe
    (`model_id`, `chunk_id`, and `model_str`) coming from Power Query, you will also
    have to assign the associated values to both the parameter slicers related to
    the two input variables. Since only one value is selected at a time for each parameter
    when slicing, the set of all the parameters form a tuple, which in our case is
    (`numeric_value`, `category_id`). This tuple will be replicated as many times
    as the rows of the string chunk dataframe (consisting of the columns `model_id`,
    `chunk_id`, and `model_str`), and concatenated to it in order to provide the final
    dataframe that will be available in the variable named `dataset` in the Script
    Visual session.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 为了正确理解这段话，请确保你理解了 *第 4 章*，*导入未处理的数据对象* 的内容。假设你必须向一个期望两个变量作为输入的机器学习模型提供观察结果 –
    一个数值变量和一个分类变量。当将信息传递给脚本视觉的数据框时，除了来自 Power Query 的序列化模型数据框的字段（`model_id`、`chunk_id`
    和 `model_str`）之外，你还需要将相关值分配给两个输入变量相关的参数筛选器。由于在筛选时每个参数每次只能选择一个值，因此所有参数的集合形成一个元组，在我们的情况下是（`numeric_value`、`category_id`）。这个元组将根据字符串块数据框（由
    `model_id`、`chunk_id` 和 `model_str` 列组成）的行数进行复制，并将其连接到它，以提供最终的数据框，该数据框将在脚本视觉会话中名为
    `dataset` 的变量中可用。
- en: '![Figure 13.7 – Deserializing the PKL file content into a Python visual](img/file340.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.7 – 将 PKL 文件内容反序列化到 Python 视觉中](img/file340.png)'
- en: Figure 13.7 – Deserializing the PKL file content into a Python visual
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.7 – 将 PKL 文件内容反序列化到 Python 视觉中
- en: Once you have the dataset dataframe available in the script visual, you can
    apply the deserialization transformations just to the columns (`model_id`, `chunk_id`,
    and `model_str`), thereby obtaining the machine learning model ready to be used.
    Selecting instead just the columns (`number`, `category`) and applying the distinct
    function to all the rows of the resulting dataframe, you obtain back the tuple
    of parameters to provide by way of input to the deserialized model. You can therefore
    calculate the predicted value from the model, providing to it the tuple of parameters
    as input. You can then use the prediction in the graph to be shown in the script
    visual.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦在脚本视觉中有了数据集数据框，你可以仅对列（`model_id`、`chunk_id` 和 `model_str`）应用反序列化转换，从而获得可用于评分的机器学习模型。如果你选择仅对列（`number`、`category`）应用，并对结果数据框的所有行应用
    distinct 函数，你将获得作为反序列化模型输入提供的参数元组。因此，你可以从模型中计算预测值，向其提供参数元组作为输入。然后，你可以在脚本视觉中显示的图中使用这个预测。
- en: Let’s see in practice how to dynamically predict values from a machine learning
    model in a Python Script Visual.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们实际看看如何在 Python 脚本视觉中动态预测来自机器学习模型的值。
- en: Scoring observations in a script visual using a trained PyCaret model
  id: totrans-152
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在脚本视觉中使用训练好的 PyCaret 模型评分观察结果
- en: The first thing you will do is to serialize properly the machine learning models
    (in our case, only one) contained in a dictionary in Power Query. In this way,
    a dataframe containing the representation in strings of every serialized model
    of the aforementioned dictionary is obtained. So, it is possible to select the
    model of interest through a slicer in the report and to therefore use the respective
    portion of a dataframe in a Python script visual, inside which it will be possible
    to deserialize the content of the dataframe and to thereby obtain the model to
    use for scoring.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 你将要做的事情是正确序列化 Power Query 中字典中包含的机器学习模型（在我们的情况下，只有一个）。这样，就获得了一个包含上述字典中每个序列化模型字符串表示的数据框。因此，可以通过报告中的筛选器选择感兴趣的模型，并因此使用
    Python 脚本视觉中的相应数据框部分，在其中可以反序列化数据框的内容，从而获得用于评分的模型。
- en: 'So, let''s proceed to develop our report in Power BI. Make sure that Power
    BI correctly references the `pycaret_env` environment in **Options**. Here are
    the steps to follow:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，让我们继续在 Power BI 中开发我们的报告。确保 Power BI 在 **选项** 中正确引用 `pycaret_env` 环境。以下是需要遵循的步骤：
- en: Click on **Get data** and then **More…**. Start typing `script` into the search
    textbox and double-click on **Python script**. The Python Script editor will pop
    up.
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 **获取数据**，然后 **更多…**。在搜索框中开始输入 `script`，双击 **Python 脚本**。Python 脚本编辑器将弹出。
- en: Copy the content of the `04-serialize-ml-models-in-power-query.py` file into
    the `Chapter13\Python` folder. Then, paste it into the Python Script editor, changing
    the absolute path to the PKL file accordingly, and then click **OK**.
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`04-serialize-ml-models-in-power-query.py`文件的内容复制到`Chapter13\Python`文件夹中。然后，将其粘贴到
    Python 脚本编辑器中，相应地更改 PKL 文件的绝对路径，然后点击**确定**。
- en: The navigator window will open, giving you the option to select which dataframe
    to import. Select both the `model_ids_df` dataframe (containing the model IDs)
    and the `models_df` one (containing the string representation of serialized models)
    and then click **Load**. Behind the scenes, a 1:* relationship is automatically
    created between the model IDs and the serialized model dataframe via the `model_id`
    fields.
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航器窗口将打开，为您提供选择要导入哪个 dataframe 的选项。选择包含模型 ID 的`model_ids_df` dataframe 和包含序列化模型字符串表示的`models_df`
    dataframe，然后点击**加载**。在幕后，通过`model_id`字段在模型 ID 和序列化模型 dataframe 之间自动创建 1:1 关系。
- en: '![Figure 13.8 – Relationship automatically created between model tables](img/file341.png)'
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 13.8 – 模型表之间自动创建的关系](img/file341.png)'
- en: Figure 13.8 – Relationship automatically created between model tables
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 13.8 – 模型表之间自动创建的关系
- en: This relationship allows you to filter the set of rows in the **models_df**
    table to be used in the Python visual, corresponding to the ID of the model you
    select via the slicer you’ll create in the next step.
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这种关系允许您筛选**models_df**表中的行集，以便在 Python 可视化中使用，对应于您通过下一步创建的切片器选择的模型 ID。
- en: Click on the slicer visual icon.
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击切片器视觉图标。
- en: '![Figure 13.9 – Selecting the slicer visual](img/file342.png)'
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 13.9 – 选择切片器视觉](img/file342.png)'
- en: Figure 13.9 – Selecting the slicer visual
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 13.9 – 选择切片器视觉
- en: Then, click on the **model_id** measure of the **model_ids_df** table.
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 然后，点击**model_ids_df**表中的**model_id**度量值。
- en: '![Figure 13.10 – Click on the model_id measure to show it in the slicer](img/file343.png)'
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 13.10 – 点击 model_id 度量值以在切片器中显示](img/file343.png)'
- en: Figure 13.10 – Click on the model_id measure to show it in the slicer
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 13.10 – 点击 model_id 度量值以在切片器中显示
- en: Click on the downward-pointing arrow at the top right of the slicer to select
    the **Dropdown** slicer type.
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击切片器右上角的向下箭头以选择**下拉**切片器类型。
- en: '![Figure 13.11 – Selecting the Dropdown slicer type](img/file344.png)'
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 13.11 – 选择下拉切片器类型](img/file344.png)'
- en: Figure 13.11 – Selecting the Dropdown slicer type
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 13.11 – 选择下拉切片器类型
- en: Resize the bottom edge of the slicer, click on its format options, switch on
    the **Single select** one, switch off **Slicer header**, and then add the title
    `Model IDs`.
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调整切片器的底部边缘，点击其格式选项，开启**单选**选项，关闭**切片器标题**，然后添加标题`模型 ID`。
- en: '![Figure 13.12 – Setting the slicer options](img/file345.png)'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 13.12 – 设置切片器选项](img/file345.png)'
- en: Figure 13.12 – Setting the slicer options
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 13.12 – 设置切片器选项
- en: Then, move it to the top center of the report.
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 然后，将其移动到报告的顶部中央。
- en: You will now add a set of What-If parameters with their slicers associated with
    each variable to be passed as input to the model. Click on the **Modeling** tab
    on the ribbon and then on **New parameter**.
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您现在将为每个变量添加一组“假设”参数及其关联的切片器，并将它们作为输入传递给模型。点击功能区上的**建模**选项卡，然后点击**新建参数**。
- en: On the next dialog, enter `Pclass param` in the **Name** field, leave the data
    type as `Whole number`, enter `1` in the **Minimum** field, 3 in the **Maximum**
    field, leave **Increment** as 1, and enter 2 in the **Default** field.
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在下一个对话框中，在**名称**字段中输入`Pclass 参数`，将数据类型保留为`整数`，在**最小值**字段中输入`1`，在**最大值**字段中输入`3`，将**增量**保留为
    1，并在**默认值**字段中输入`2`。
- en: '![Figure 13.13 – Adding the What-if parameter for Pclass](img/file346.png)'
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 13.13 – 为 Pclass 添加“假设”参数](img/file346.png)'
- en: Figure 13.13 – Adding the What-if parameter for Pclass
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 13.13 – 为 Pclass 添加“假设”参数
- en: Keep **Add slicer to this page** selected and then click **OK**.
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 保持**将切片器添加到本页**选中，然后点击**确定**。
- en: Resize the bottom edge of the Pclass slicer. Then, click on its format options,
    switch off **Slicer header**, switch on **Title**, and enter `Passenger class`
    as the text. Then move it to the top left of your report.
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调整 Pclass 切片器的底部边缘。然后，点击其格式选项，关闭**切片器标题**，开启**标题**，并将文本输入为`乘客等级`。然后将它移动到报告的左上角。
- en: Be sure to rename the **Pclass** value of **Pclass param** to the same name
    as the variable that represents it in the model, namely, `Pclass`.
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保将**Pclass 参数**的**Pclass**值重命名为在模型中表示它的变量的相同名称，即`Pclass`。
- en: '![Figure 13.14 – Renaming the Pclass parameter value](img/file347.png)'
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 13.14 – 重命名 Pclass 参数值](img/file347.png)'
- en: Figure 13.14 – Renaming the Pclass parameter value
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图13.14 – 重命名Pclass参数值
- en: As the variable **Sex** is categorical (F or M), you’ll create a disconnected
    table for it manually. So, click on the **Home** tab in the ribbon and click on
    **Enter data**.
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于变量**Sex**是分类的（F或M），您需要手动为其创建一个不连续的表格。因此，在功能区中点击**首页**选项卡，然后点击**输入数据**。
- en: Create the first column, **Sex**, of the table and add the values 0 and 1 to
    it. Then, create the new column, **SexLabel**, and enter `Female`, where **Sex**
    is `0`, and `Male`, where **Sex** is `1`.
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建表格的第一列，**Sex**，并向其中添加值0和1。然后，创建新的列，**SexLabel**，当**Sex**为`0`时输入`Female`，当**Sex**为`1`时输入`Male`。
- en: '![Figure 13.15 – Enter data manually for Sex](img/file348.png)'
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图13.15 – 手动输入Sex的数据](img/file348.png)'
- en: Figure 13.15 – Enter data manually for Sex
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图13.15 – 手动输入Sex的数据
- en: Enter `Sex` as the table name and then click **Load**.
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 将`Sex`作为表名输入，然后点击**加载**。
- en: Let’s add a slicer for the `Sex` variable. Click on an empty spot in the report
    canvas first. Then, click the slicer visual to add a slicer to the report. Then,
    click on the **SexLabel** field and then on the **Sex** field (the order is important).
    Then, click on the downward-pointing arrow at the top right of the slicer to select
    the **Dropdown** slicer type. Also, click on its format options, switch on the
    **Single select** option in the **Selection control** group, switch off the **Slicer
    header** option, switch on **Title**, and then enter `Sex` as the text. Resize
    its bottom edge and move it under the **Passenger class** slicer.
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们为`Sex`变量添加一个筛选器。首先在报告画布上的一个空白处点击。然后，点击筛选器视觉元素以将筛选器添加到报告中。接着，点击**SexLabel**字段，然后点击**Sex**字段（顺序很重要）。然后，点击筛选器右上角的向下箭头以选择**下拉**筛选器类型。同时，点击其格式选项，在**选择控制**组中开启**单选**选项，关闭**筛选器标题**选项，开启**标题**，并将文本输入为`Sex`。调整其底部边缘并将其移动到**乘客等级**筛选器下方。
- en: '![Figure 13.16 – A new dropdown slicer for Sex](img/file349.png)'
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图13.16 – 为Sex创建的新下拉筛选器](img/file349.png)'
- en: Figure 13.16 – A new dropdown slicer for Sex
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图13.16 – 为Sex创建的新下拉筛选器
- en: Let’s create a new `What-if` parameter for the `Age` variable. Click on the
    **Modeling** tab on the ribbon and then on **New parameter**. On the next dialog,
    enter `Age param` in the **Name** field, leave the data type as `Whole number`,
    enter `1` in the **Minimum** field, `80` in the **Maximum** field, leave **Increment**
    as `1`, and enter `30` in the **Default** field. Keep **Add slicer to this page**
    selected and then click **OK**.
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们为`Age`变量创建一个新的`What-if`参数。在功能区上点击**建模**选项卡，然后点击**新建参数**。在下一个对话框中，在**名称**字段中输入`Age
    param`，保留数据类型为`整数`，在**最小值**字段中输入`1`，在**最大值**字段中输入`80`，保留**增量**为`1`，并在**默认值**字段中输入`30`。保持**添加筛选器到本页**选中，然后点击**确定**。
- en: Resize the bottom edge of the Age slicer. Then, click on its format options,
    switch off **Slicer header**, switch on **Title**, and enter `Age` as the text.
    Then, move it to the top left of your report under the Sex slicer.
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调整年龄筛选器的底部边缘。然后，点击其格式选项，关闭**筛选器标题**，开启**标题**，并将文本输入为`Age`。然后，将其移动到报告的顶部左侧，位于Sex筛选器下方。
- en: Be sure to rename the **Age** value of **Age param** to the same name as the
    variable that represents it in the model, namely, `Age`.
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 请确保将**年龄参数**的**年龄**值重命名为模型中代表它的变量的相同名称，即`Age`。
- en: '![Figure 13.17 – Renaming the Age parameter value](img/file350.png)'
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图13.17 – 重命名年龄参数值](img/file350.png)'
- en: Figure 13.17 – Renaming the Age parameter value
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图13.17 – 重命名年龄参数值
- en: Let’s create a new What-if parameter for the `SibSp` variable. Click on the
    **Modeling** tab on the ribbon and then on **New parameter**. On the next dialog,
    enter `SibSp param` in the **Name** field, leave the data type as `Whole number`,
    enter `0` in the **Minimum** field, `8` in the **Maximum** field, leave **Increment**
    as `1`, and enter `0` in the **Default** field. Keep **Add slicer to this page**
    selected and then click **OK**.
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们为`SibSp`变量创建一个新的`What-if`参数。在功能区上点击**建模**选项卡，然后点击**新建参数**。在下一个对话框中，在**名称**字段中输入`SibSp
    param`，保留数据类型为`整数`，在**最小值**字段中输入`0`，在**最大值**字段中输入`8`，保留**增量**为`1`，并在**默认值**字段中输入`0`。保持**添加筛选器到本页**选中，然后点击**确定**。
- en: Resize the bottom edge of the SibSp slicer. Then, click on its format options,
    switch off **Slicer header**, switch on **Title**, and enter `Siblings/spouse
    aboard` as the text. Then, move it to the top left of your report under the Age
    slicer.
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调整SibSp筛选器的底部边缘。然后，点击其格式选项，关闭**筛选器标题**，开启**标题**，并将文本输入为`Siblings/spouse aboard`。然后，将其移动到报告的顶部左侧，位于年龄筛选器下方。
- en: Be sure to rename the **SibSp** value of **SibSp param** to the same name as
    the variable that represents it in the model, namely, `SibSp`.
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保将**SibSp参数**的**SibSp值**重命名为它在模型中代表的变量的相同名称，即`SibSp`。
- en: '![Figure 13.18 – Renaming the SibSp parameter value](img/file351.png)'
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图13.18 – 重命名SibSp参数值](img/file351.png)'
- en: Figure 13.18 – Renaming the SibSp parameter value
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图13.18 – 重命名SibSp参数值
- en: Let’s create a new What-if parameter for the `Parch` variable. Click on the
    **Modeling** tab on the ribbon and then on **New parameter**. On the next dialog,
    enter `Parch param` in the **Name** field, and leave Whole number as the data
    type, enter `0` in the **Minimum** field, `6` in the **Maximum** field, leave
    **Increment** as `1`, and enter `0` in the **Default** field. Keep **Add slicer
    to this page** selected and then click **OK**.
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们为`Parch`变量创建一个新的What-if参数。在功能区点击**建模**选项卡，然后点击**新建参数**。在下一个对话框中，在**名称**字段中输入`Parch
    param`，保留**整数**作为数据类型，在**最小值**字段中输入`0`，在**最大值**字段中输入`6`，保留**增量**为`1`，并在**默认值**字段中输入`0`。保持**添加切片器到本页**选中，然后点击**确定**。
- en: Resize the bottom edge of the Parch slicer. Then, click on its format options,
    switch off **Slicer header**, switch on **Title**, and enter `Parents/children
    aboard` as the text. Then, move it to the top left of your report under the SibSp
    slicer.
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调整Parch切片器的底部边缘。然后，点击其格式选项，关闭**切片器标题**，开启**标题**，并将文本输入为`Parents/children aboard`。然后，将其移动到报告的顶部左侧，位于SibSp切片器下方。
- en: 'Be sure to rename the **Parch** value of **Parch param** to the same name as
    the variable that represents it in the model, namely Parch:'
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保将**Parch参数**的**Parch值**重命名为它在模型中代表的变量的相同名称，即Parch：
- en: '![Figure 13.19 – Renaming the Parch parameter value](img/file352.png)'
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图13.19 – 重命名Parch参数值](img/file352.png)'
- en: Figure 13.19 – Renaming the Parch parameter value
  id: totrans-205
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图13.19 – 重命名Parch参数值
- en: Let’s create a new What-if parameter for the `Fare` variable. Click on the **Modeling**
    tab on the ribbon and then on **New parameter**. On the next dialog, enter `Fare
    param` in the **Name** field, select `Decimal number` as the data type, enter
    `0` in the **Minimum** field, `515` in the **Maximum**, field, enter `1` in the
    **Increment** field, and then enter `250` in the **Default** field. Keep **Add
    slicer to this page** selected and then click **OK**.
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们为`Fare`变量创建一个新的What-if参数。在功能区点击**建模**选项卡，然后点击**新建参数**。在下一个对话框中，在**名称**字段中输入`Fare
    param`，选择`十进制数`作为数据类型，在**最小值**字段中输入`0`，在**最大值**字段中输入`515`，在**增量**字段中输入`1`，然后在**默认值**字段中输入`250`。保持**添加切片器到本页**选中，然后点击**确定**。
- en: Resize the bottom edge of the Fare slicer. Then, click on its format options,
    switch off **Slicer header**, switch on **Title**, and enter `Fare` as the text.
    Then, move it to the top left of your report under the Parch slicer.
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调整Fare切片器的底部边缘。然后，点击其格式选项，关闭**切片器标题**，开启**标题**，并将文本输入为`Fare`。然后，将其移动到报告的顶部左侧，位于Parch切片器下方。
- en: Be sure to rename the **Fare** value of **Fare param** to the same name as the
    variable that represents it in the model, namely, `Fare`.
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保将**Fare参数**的**Fare值**重命名为它在模型中代表的变量的相同名称，即`Fare`。
- en: '![Figure 13.20 – Renaming the Fare parameter value](img/file353.png)'
  id: totrans-209
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图13.20 – 重命名Fare参数值](img/file353.png)'
- en: Figure 13.20 – Renaming the Fare parameter value
  id: totrans-210
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图13.20 – 重命名Fare参数值
- en: Let’s add a slicer for the `Embarked` variable. As the `Embarked` variable is
    categorical (`0`, `1`, or `2`), you’ll create a disconnected table for it manually.
    So, click on the **Home** tab in the ribbon and then click on **Enter Data**.
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们为`Embarked`变量添加一个切片器。由于`Embarked`变量是分类的（`0`、`1`或`2`），你需要手动为其创建一个不连续的表格。因此，在功能区点击**主页**选项卡，然后点击**输入数据**。
- en: Create the first column, **Embarked** (this name must correspond to that of
    the model’s variable), of the table and then add the values 0, 1, and 2 to it.
    Then, create a new column, **EmbarkedLabel**, and enter `Cherbourg`, `Queenstown`,
    and `Southampton`, corresponding to `0`, `1`, and `2`, respectively.
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建表格的第一列，**Embarked**（此名称必须与模型变量的名称相对应），然后向其中添加值0、1和2。然后，创建一个新的列，**EmbarkedLabel**，并输入`Cherbourg`、`Queenstown`和`Southampton`，分别对应`0`、`1`和`2`。
- en: '![Figure 13.21 – Entering data manually for Embarked](img/file354.png)'
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图13.21 – 手动输入Embarked数据](img/file354.png)'
- en: Figure 13.21 – Entering data manually for Embarked
  id: totrans-214
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图13.21 – 手动输入Embarked数据
- en: Enter `PortEmbarkation` as the table name and then click **Load**.
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 将表格名称输入为`PortEmbarkation`，然后点击**加载**。
- en: Let’s now add a slicer for the `Embarked` variable. Click on an empty spot in
    the report canvas first. Then, click on the slicer visual in order to add a slicer
    to the report. Click first on the **EmbarkedLabel** field and then on the **Embarked**
    one (the order is important). Then, click on the downward-pointing arrow at the
    top right of the slicer to select the **Dropdown** slicer type. Also, click on
    its format options. Switch on **Single select** in the **Selection control** group,
    switch off **Slicer header**, switch on **Title**, and enter `Port of embarkation`
    as the text. Resize its bottom edge and move it under the Passenger class slicer.
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，为 `Embarked` 变量添加一个切片器。首先在报告画布上的一个空白处点击。然后，点击切片器可视化以将切片器添加到报告中。首先点击 **EmbarkedLabel**
    字段，然后点击 **Embarked** 字段（顺序很重要）。然后，点击切片器右上角的向下箭头以选择 **下拉** 切片器类型。还要点击其格式选项。在 **选择控制**
    组中开启 **单选**，关闭 **切片器标题**，开启 **标题**，并将文本输入为 `启航港`。调整其底部边缘并将其移至乘客类别切片器下方。
- en: Now, click on an empty spot in the report canvas, then on **Python Visual**
    in the **Visualizations** field, and enable it when you’re prompted to do so.
    After that, move it to the center of your report.
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，在报告画布上的一个空白处点击，然后在 **可视化** 字段中点击 **Python 可视化**，并在提示时启用它。之后，将其移动到报告的中心。
- en: Keeping it selected, click on all the three fields of the `models_df` table
    (**chunk_id**, **model_id**, and **model_str**).
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保持选中状态，点击 `models_df` 表的所有三个字段（**chunk_id**、**model_id** 和 **model_str**）。
- en: Still keeping the Python visual selected, also click on all measures (the ones
    with a calculator icon) of all the parameters entered, and on the identifying
    fields of the categorical variables (the **Embarked** and **Sex** fields). Remember
    that the names of the measures must necessarily correspond to the names of the
    variables provided by the model for the report to work. You may need to enable
    the Python visual again after selecting the measures. You can do this by simply
    clicking on the yellow button labeled **Select to enable** in the Python visual.
    At the end of the selection, you should see all the names of the measures plus
    those of the fields of the `models_df` table inside the Python visual.
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在保持 Python 可视化选中的同时，也点击所有参数的所有度量（带有计算器图标的那些），以及分类变量的识别字段（**Embarked** 和 **Sex**
    字段）。记住，度量的名称必须与模型提供的变量名称相对应，以便报告能够正常工作。在选择度量后，你可能需要再次启用 Python 可视化。你可以通过简单地点击
    Python 可视化中标记为 **选择以启用** 的黄色按钮来完成此操作。选择完成后，你应该在 Python 可视化中看到所有度量的名称以及 `models_df`
    表的字段名称。
- en: '![Figure 13.22 – Selected measure names visible in the Python visual](img/file355.png)'
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 13.22 – 在 Python 可视化中可见的选定度量名称](img/file355.png)'
- en: Figure 13.22 – Selected measure names visible in the Python visual
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 13.22 – 在 Python 可视化中可见的选定度量名称
- en: Now, click on the Python visual’s **Format** tab, expand the **Title** area,
    edit the text with the **Prediction string**, and increase the font size to 28
    point.
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，点击 Python 可视化的 **格式** 选项卡，展开 **标题** 区域，使用 **预测字符串** 编辑文本，并将字体大小增加到 28 点。
- en: Copy the code of the `05-deserialize-ml-models-in-python-visual.py` file into
    the `Chapter13\Python` folder and paste it into the Python visual script editor.
    Then, click on the **Run script** arrow icon in the top-right corner of the Python
    script editor. You’ll get a prediction (label and score) of whether a person described
    by the parameters you selected will survive.
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 `05-deserialize-ml-models-in-python-visual.py` 文件的代码复制到 `Chapter13\Python`
    文件夹中，并将其粘贴到 Python 可视化脚本编辑器中。然后，点击 Python 脚本编辑器右上角的 **运行脚本** 箭头图标。你将得到一个预测（标签和分数），预测你选择的参数描述的人是否会存活。
- en: '![Figure 13.23 – Complete prediction simulation report for the Titanic model](img/file356.png)'
  id: totrans-224
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.23 – 泰坦尼克号模型的完整预测模拟报告](img/file356.png)'
- en: Figure 13.23 – Complete prediction simulation report for the Titanic model
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.23 – 泰坦尼克号模型的完整预测模拟报告
- en: Keep in mind that the same report can be made using models trained in R with
    the same methodology followed here. In fact, for completeness, we added to the
    repository the `Chapter13\R` folder containing the scripts corresponding to those
    used in this section, which is useful for obtaining the same results you got here.
    In these scripts, we trained the model using a predefined algorithm (**Random
    Forest**) and used the recently introduced **Tidymodels** framework, which makes
    use of the Tidyverse principles. For further details, refer to the references.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，使用这里遵循的相同方法，可以使用 R 训练的模型制作相同的报告。实际上，为了完整性，我们在存储库中添加了 `Chapter13\R` 文件夹，其中包含本节中使用的脚本，这对于获得这里得到的结果非常有用。在这些脚本中，我们使用预定义的算法（**随机森林**）训练了模型，并使用了最近引入的
    **Tidymodels** 框架，该框架利用了 Tidyverse 原则。有关更多详细信息，请参阅参考文献。
- en: Wow! You've managed to create a dynamic predictive report in Power BI, something
    few developers can do!
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 哇！你已经成功在 Power BI 中创建了一个动态预测报告，这是少数开发者能够做到的！
- en: Let's now see how to invoke the AI and machine learning services exposed by
    Microsoft in Power BI even if you don't have a Premium capability, an Embedded
    capability, or a PPU license.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看看即使没有 Premium 功能、嵌入式功能或 PPU 许可证，如何调用 Microsoft 在 Power BI 中公开的 AI 和机器学习服务。
- en: Calling web services in Power Query
  id: totrans-229
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 Power Query 中调用 Web 服务
- en: 'Another way to interact with machine learning models within Power Query is
    to invoke web services. As you may already know, a machine learning model can
    be used to carry out the scoring of many observations in batch mode using a trained
    model (process described previously). Another option for being able to interact
    with a machine learning model is to deploy it to a web service so that it can
    be invoked via REST APIs. You''ve already learned how to work with external APIs
    in *Chapter 9*, *Calling External APIs to Enrich Your Data*. The following applies
    to external APIs:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Power Query 中与机器学习模型交互的另一种方式是调用 Web 服务。正如你可能已经知道的，机器学习模型可以用来批量处理多个观察值的评分，使用一个训练好的模型（之前描述的过程）。与机器学习模型交互的另一种选择是将它部署到
    Web 服务中，以便可以通过 REST API 调用它。你已经学习了如何在 *第 9 章* 中与外部 API 一起工作，*调用外部 API 以丰富您的数据*。以下内容适用于外部
    API：
- en: '**Important Note**'
  id: totrans-231
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**重要提示**'
- en: ''
  id: totrans-232
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Remember that you can't consume external services via REST API calls from a
    Python or R visual because internet access is blocked for security reasons. Therefore,
    you can only consume these services in Power Query.
  id: totrans-233
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 记住，由于出于安全原因阻止了互联网访问，你不能从 Python 或 R 可视化中通过 REST API 调用消耗外部服务。因此，你只能在 Power Query
    中消耗这些服务。
- en: As an example, in this section, you'll see how to invoke predictions from a
    released endpoint via **Azure Machine Learning** and how to use the services exposed
    by the **Azure Text Analytics** of cognitive services. You could use some M code
    in Power Query to access these services, although it's not exactly straightforward.
    Fortunately, SDKs are available, which make it much easier to access the exposed
    services. These SDKs are developed for Python, so our examples will be exclusively
    in Python.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 作为示例，在本节中，你将了解如何通过 **Azure Machine Learning** 调用已发布端点的预测，以及如何使用认知服务中 **Azure
    Text Analytics** 提供的服务。你可以在 Power Query 中使用一些 M 代码来访问这些服务，尽管这并不完全直接。幸运的是，有可用的
    SDK，这使得访问公开的服务变得容易得多。这些 SDK 是为 Python 开发的，因此我们的示例将仅限于 Python。
- en: Let's first look at how to interact with a model trained using Azure AutoML.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先看看如何与使用 Azure AutoML 训练的模型交互。
- en: Using Azure AutoML models in Power Query
  id: totrans-236
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在 Power Query 中使用 Azure AutoML 模型
- en: In this section, you'll first see how to train a machine learning model using
    the Azure AutoML GUI. After that, you will use the model released on an Azure
    container instance as a web service in Power BI.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将首先了解如何使用 Azure AutoML GUI 训练机器学习模型。之后，你将使用发布在 Azure 容器实例上的模型作为 Power
    BI 中的 Web 服务。
- en: Training a model using the Azure AutoML UI
  id: totrans-238
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用 Azure AutoML UI 训练模型
- en: 'In order to use Azure AutoML, you must first have access to an Azure subscription
    (remember you can create a free account as shown at this link: [https://bit.ly/azure-free-account](https://bit.ly/azure-free-account)).
    After that, you need to create an **Azure Machine Learning Workspace** to train
    models via the different technologies that Azure provides. You can do this by
    simply following the steps in the paragraph at this link: [https://bit.ly/create-azureml-workspace](https://bit.ly/create-azureml-workspace).
    As soon as the workspace has been allocated, you can log in to **Azure Machine
    Learning Studio**, an environment in which all the machine learning assets you''ll
    be working with are best organized. Perform the following steps to log in to Azure
    ML Studio and to start an AutoML experiment:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使用 Azure AutoML，您必须首先有权访问 Azure 订阅（记住您可以创建一个免费账户，如链接所示：[https://bit.ly/azure-free-account](https://bit.ly/azure-free-account))。之后，您需要创建一个
    **Azure 机器学习工作区**，通过 Azure 提供的不同技术来训练模型。您可以通过简单地遵循链接中的步骤来完成此操作：[https://bit.ly/create-azureml-workspace](https://bit.ly/create-azureml-workspace)。一旦工作区被分配，您就可以登录到
    **Azure 机器学习工作室**，这是一个所有您将与之工作的机器学习资产都组织得最好的环境。执行以下步骤以登录到 Azure ML Studio 并开始一个
    AutoML 实验：
- en: Go to [https://ml.azure.com/](https://ml.azure.com/).
  id: totrans-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 前往 [https://ml.azure.com/](https://ml.azure.com/)。
- en: 'You will be prompted to select an Azure subscription of yours and an Azure
    ML workspace to work on. Click on **Get started**. You will see something like
    this:'
  id: totrans-241
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您将被提示选择您的 Azure 订阅和要工作的 Azure ML 工作区。点击 **开始**。您将看到如下内容：
- en: '![Figure 13.24 – Azure ML Studio portal](img/file357.png)'
  id: totrans-242
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 13.24 – Azure ML Studio 门户](img/file357.png)'
- en: Figure 13.24 – Azure ML Studio portal
  id: totrans-243
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 13.24 – Azure ML Studio 门户
- en: First, you need to import the dataset with which to train the model. You will
    use the same dataset obtained from the missing value imputation done in the previous
    sections. Click on **Datasets** in the menu on the left and then on **Create dataset**.
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，您需要导入用于训练模型的数据库集。您将使用上一节中完成的缺失值插补所获得的相同数据集。点击左侧菜单上的 **数据集**，然后点击 **创建数据集**。
- en: '![Figure 13.25 – Creating a new dataset in Azure ML](img/file358.png)'
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 13.25 – 在 Azure ML 中创建新的数据集](img/file358.png)'
- en: Figure 13.25 – Creating a new dataset in Azure ML
  id: totrans-246
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 13.25 – 在 Azure ML 中创建新的数据集
- en: You’ll be prompted for the dataset name and type. Enter `titanic-imputed` as
    the name and leave **Tabular** as the type.
  id: totrans-247
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您将被提示输入数据集名称和类型。将名称输入为 `titanic-imputed`，并将类型保留为 **表格**。
- en: '![Figure 13.26 – Selecting your dataset name and type](img/file359.png)'
  id: totrans-248
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 13.26 – 选择数据集名称和类型](img/file359.png)'
- en: Figure 13.26 – Selecting your dataset name and type
  id: totrans-249
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 13.26 – 选择数据集名称和类型
- en: Then, click **Next**.
  id: totrans-250
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 然后，点击 **下一步**。
- en: You have to upload the CSV file containing the Titanic disaster imputed data.
    So, click on **Upload**, then on **Upload files**, and finally select the `titanic-imputed.csv`
    file in the `Chapter13` folder via the **Open file** dialog. The file will be
    uploaded to the default Azure Blob storage (`workspaceblobstore`) created behind
    the scenes when instantiating a new Azure ML workspace. Click **Next**.
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您必须上传包含泰坦尼克号灾难插补数据的 CSV 文件。因此，点击 **上传**，然后点击 **上传文件**，最后通过 **打开文件** 对话框在 `Chapter13`
    文件夹中选择 `titanic-imputed.csv` 文件。文件将被上传到在实例化新的 Azure ML 工作区时在幕后创建的默认 Azure Blob
    存储中（`workspaceblobstore`）。点击 **下一步**。
- en: On the next page, you’ll get a preview of the dataset you’re importing. The
    engine automatically selects the best import options for you. But if there is
    something you’d like to change, you can do it on this page. In this case, everything
    is already OK, so click **Next**.
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在下一页，您将预览您正在导入的数据集。引擎会自动为您选择最佳导入选项。但如果您想更改某些内容，您可以在这一页进行更改。在这种情况下，一切都已经就绪，所以点击
    **下一步**。
- en: On the following page, you can change the imputed schema of the data you’re
    reading. In this case, leave the inferred type for each field, as the exported
    CSV file has numeric values with integer and decimal numbers. Then, click **Next**.
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在下一页，您可以更改您正在读取的数据的插补模式。在这种情况下，保留每个字段的推断类型，因为导出的 CSV 文件包含整数和小数数值。然后，点击 **下一步**。
- en: A recap page will be shown. So, just click **Create** and your dataset will
    be added to Azure ML.
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将显示一个摘要页面。因此，只需点击 **创建**，您的数据集就会被添加到 Azure ML。
- en: Now you need to create a compute cluster to use for model training. Click on
    the **Compute** tab on the left menu, then click on **Compute clusters**, and
    finally click on **New**.
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，您需要创建一个用于模型训练的计算集群。点击左侧菜单上的 **计算** 选项卡，然后点击 **计算集群**，最后点击 **新建**。
- en: '![Figure 13.27 – Creating a new compute cluster](img/file360.png)'
  id: totrans-256
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图13.27 – 创建新的计算集群](img/file360.png)'
- en: Figure 13.27 – Creating a new compute cluster
  id: totrans-257
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图13.27 – 创建新的计算集群
- en: Then you can select your preferred location for the cluster and the virtual
    machine type and size to use for each cluster node. You can leave the default
    selection and click **Next**.
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，您可以选择集群的首选位置以及每个集群节点要使用的虚拟机类型和大小。您可以保留默认选择并点击**下一步**。
- en: Choose a name for your cluster (in our case, `cluster`), the minimum number
    of nodes (keep it at 0 to make it turn off automatically when not used), and the
    maximum number of nodes (set it to 2). Then, click on **Create** to allocate your
    compute cluster.
  id: totrans-259
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为您的集群选择一个名称（在我们的案例中，是`cluster`），最小节点数（保持为0以使其在未使用时自动关闭），以及最大节点数（将其设置为2）。然后，点击**创建**以分配您的计算集群。
- en: Now, click on the **Automated ML** tab on the left menu and then on **New Automated
    ML run**.
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，点击左侧菜单上的**自动机器学习**选项卡，然后点击**新建自动机器学习运行**。
- en: '![Figure 13.28 – Creating a new AutoML experiment](img/file361.png)'
  id: totrans-261
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图13.28 – 创建新的AutoML实验](img/file361.png)'
- en: Figure 13.28 – Creating a new AutoML experiment
  id: totrans-262
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图13.28 – 创建新的AutoML实验
- en: On the next page, select the **titanic-imputed** dataset and click **Next**.
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在下一页，选择**titanic-imputed**数据集并点击**下一步**。
- en: Now you can configure the run by entering the name of the new experiment (a
    virtual folder) that will contain all the AutoML runs (we used `titanic` for the
    name), the machine learning target column (`Survived`, the one to predict), and
    the compute cluster to use to execute the AutoML runs (the `cluster` one created
    previously).
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，您可以通过输入新实验（虚拟文件夹）的名称来配置运行，该实验将包含所有AutoML运行（我们使用了`titanic`作为名称），机器学习目标列（`Survived`，预测的目标），以及用于执行AutoML运行的计算集群（之前创建的`cluster`）。
- en: '![Figure 13.29 – Configuring your AutoML run](img/file362.png)'
  id: totrans-265
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图13.29 – 配置您的AutoML运行](img/file362.png)'
- en: Figure 13.29 – Configuring your AutoML run
  id: totrans-266
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图13.29 – 配置您的AutoML运行
- en: You can then declare the machine learning experiment type you would like to
    run. In our case, it is a classification.
  id: totrans-267
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您可以声明您想要运行的机器学习实验类型。在我们的案例中，它是一个分类。
- en: '![Figure 13.30 – Setting up the AutoML task type](img/file363.png)'
  id: totrans-268
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图13.30 – 设置AutoML任务类型](img/file363.png)'
- en: Figure 13.30 – Setting up the AutoML task type
  id: totrans-269
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图13.30 – 设置AutoML任务类型
- en: By clicking on **View additional configuration settings**, you can choose the
    primary metric to use in your experiment. Select the **AUC weighted** one and
    then click **Save**.
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**查看更多配置设置**，您可以选择在实验中使用的首要指标。选择**AUC加权**选项，然后点击**保存**。
- en: By clicking on **View featurization settings**, you can enable the auto-featurization
    option that AutoML provides. By default, it’s switched on. You can also choose
    the feature type for each column and the missing values impute strategy for each
    of them (the strategies are the naïve ones). Keep everything on **Auto** and then
    click **Save**.
  id: totrans-271
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过点击**查看特征化设置**，您可以启用AutoML提供的自动特征化选项。默认情况下，它是开启的。您还可以为每一列选择特征类型以及为每个缺失值填充策略（策略是简单的）。保持一切在**自动**，然后点击**保存**。
- en: You can now click **Finish** to start your AutoML experiment. You’ll be redirected
    to the **Run** page, and after a while, you‘ll see your experiment running.
  id: totrans-272
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在您可以点击**完成**以开始您的AutoML实验。您将被重定向到**运行**页面，过一会儿，您将看到实验正在运行。
- en: '![Figure 13.31 – Your AutoML experiment running](img/file364.png)'
  id: totrans-273
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图13.31 – 您的AutoML实验正在运行](img/file364.png)'
- en: Figure 13.31 – Your AutoML experiment running
  id: totrans-274
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图13.31 – 您的AutoML实验正在运行
- en: After about 30 minutes, the experiment should end. Click on the **Models** tab
    on the **AutoML Run** page and you will see the training pipelines according to
    the best-performing ones.
  id: totrans-275
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 大约30分钟后，实验应该结束。点击**AutoML运行**页面上的**模型**选项卡，您将看到根据最佳性能排序的训练管道。
- en: '![Figure 13.32 – Best performing pipelines found by AutoML](img/file365.png)'
  id: totrans-276
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图13.32 – AutoML找到的最佳性能管道](img/file365.png)'
- en: Figure 13.32 – Best performing pipelines found by AutoML
  id: totrans-277
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图13.32 – AutoML找到的最佳性能管道
- en: For the best-performing model (**VotingEnsemble**), the *Explainability Dashboard*
    is also automatically generated, which you can access by clicking on **View explanation**.
    For further details on this, check out the references. Now, click on the **VotingEnsemble**
    link to go to the specific run that trained the model using that pipeline. Then,
    click on the **Deploy** button.
  id: totrans-278
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于最佳性能模型（**VotingEnsemble**），还自动生成了**可解释性仪表板**，您可以通过点击**查看解释**来访问。有关此内容的更多详细信息，请参阅参考资料。现在，点击**VotingEnsemble**链接以转到使用该管道训练模型的特定运行。然后，点击**部署**按钮。
- en: '![Figure 13.33 – Deploying the best model to a web service](img/file366.png)'
  id: totrans-279
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图13.33 – 将最佳模型部署到Web服务](img/file366.png)'
- en: Figure 13.33 – Deploying the best model to a web service
  id: totrans-280
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图13.33 – 将最佳模型部署到Web服务
- en: A new form will appear on the right asking for information about the model to
    deploy on a web service. Just give the model endpoint a name (`titanic-model`),
    select **Azure Container Instance** as the compute type, as this will not be a
    production environment, and activate the **Enable authentication** feature. In
    the case of a production environment, *Azure Kubernetes Services* (*AKS*) is the
    best choice. Then, click on **Deploy** and wait for the model to be deployed.
    When the **Deploy status** field changes to **Succeeded** in the **Model** summary,
    click on the **titanic-model** endpoint link.
  id: totrans-281
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 右侧将出现一个新表单，要求提供有关要在Web服务上部署的模型的信息。只需给模型端点起一个名字（`titanic-model`），选择**Azure容器实例**作为计算类型，因为这将不是一个生产环境，并激活**启用认证**功能。在生产环境中，*Azure
    Kubernetes服务*（AKS）是最佳选择。然后，点击**部署**并等待模型部署。当**部署状态**字段在**模型**摘要中变为**成功**时，点击**titanic-model**端点链接。
- en: The endpoint **Details** page contains all the information about the service.
    After at least 10 minutes of deployment, it must be in a healthy deployment state
    in order to be used. You can click on the **Test** tab to test your endpoint by
    providing it with test input data. The tab we are most interested in is **Consume**,
    in which the coordinates (REST endpoint URL and authentication key) are indicated
    to invoke the REST API from an external system. Also, you can directly copy the
    code snippet that allows you to consume the service in Python in the **Consumption
    option** section. We will use a variation of this code to score test observations
    in Power Query.
  id: totrans-282
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 端点**详细信息**页面包含有关服务的所有信息。部署至少10分钟后，它必须处于健康部署状态才能使用。你可以点击**测试**选项卡，通过提供测试输入数据来测试你的端点。我们最感兴趣的选项卡是**消费**，其中指示了从外部系统调用REST
    API的坐标（REST端点URL和认证密钥）。你还可以在**消费选项**部分直接复制允许你在Python中消费服务的代码片段。我们将使用此代码的变体在Power
    Query中对测试观测值进行评分。
- en: At this point, the model is ready on a web service to be consumed via REST APIs.
    Let’s now use it in Power Query.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，模型已经准备好在Web服务上通过REST API进行消费。现在让我们在Power Query中使用它。
- en: Consuming an Azure ML deployed model in Power BI
  id: totrans-284
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 在Power BI中消费已部署的Azure ML模型
- en: Using a variation of the Python code proposed by the **Endpoint Consume** tab
    on Azure ML Studio, we created a function that accepts as parameters the endpoint
    URL, the API key, and a dataframe containing the observations to be scored. In
    the output, we get a dataframe containing just the `predicted_label` column with
    the scoring of each observation.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Azure ML Studio中**端点消费**选项卡提出的Python代码的变体，我们创建了一个函数，该函数接受端点URL、API密钥以及包含要评分观测值的dataframe作为参数。在输出中，我们得到一个只包含`predicted_label`列的dataframe，其中包含每个观测值的评分。
- en: 'Here are the steps to get the predictions of a test dataset from a model trained
    via Azure AutoML and deployed as a web service on an Azure container instance:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 从通过Azure AutoML训练并在Azure容器实例上作为Web服务部署的模型中获取测试数据集预测的步骤如下：
- en: 'Click on **Get Data**, select **Text/CSV**, and then click on **Connect**:'
  id: totrans-287
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**获取数据**，选择**文本/CSV**，然后点击**连接**：
- en: Select the `titanic-test.csv` file in the `Chapter13` folder and then click
    **Open**.
  id: totrans-288
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`Chapter13`文件夹中选择`titanic-test.csv`文件，然后点击**打开**。
- en: You’ll see a preview of the test data. Click **Transform Data**.
  id: totrans-289
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你将看到测试数据的预览。点击**转换数据**。
- en: Click **Transform** on the ribbon and then **Run Python script**.
  id: totrans-290
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在功能区点击**转换**，然后点击**运行Python脚本**。
- en: Enter the script you can find in the `06-use-azure-ml-web-service-in-power-bi.py`
    file in the `Chapter13\Python` folder. Remember to edit the endpoint URL and key
    accordingly.
  id: totrans-291
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`Chapter13\Python`文件夹中的`06-use-azure-ml-web-service-in-power-bi.py`文件中输入脚本。请记住相应地编辑端点URL和密钥。
- en: We are only interested in the `scored_df` dataframe. So, click on its **Table**
    value.
  id: totrans-292
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们只对`scored_df`数据框感兴趣。因此，点击其**表**值。
- en: You'll see a preview of the test dataset with an additional column – `predicted_label`.
  id: totrans-293
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你将看到包含一个额外列 – `predicted_label`的测试数据集的预览。
- en: Click **Home** on the ribbon and then click **Close & Apply**.
  id: totrans-294
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在功能区点击**主页**，然后点击**关闭并应用**。
- en: Amazing! You were able to consume a model trained on Azure Machine Learning
    and deployed it to an Azure container instance without having either a PPU license
    or a Premium capacity.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 太棒了！你能够在没有PPU许可证或高级容量的情况下，消费在Azure机器学习上训练并部署到Azure容器实例中的模型。
- en: Using cognitive services in Power Query
  id: totrans-296
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在 Power Query 中使用认知服务
- en: The Azure cognitive services **Text Analytics API** is a service that provides
    Natural Language Processing (NLP) functions for text mining and analysis. Features
    made available include sentiment analysis, opinion mining, key phrase extraction,
    language detection, and named entity recognition.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: Azure 认知服务 **文本分析 API** 是一种提供文本挖掘和分析自然语言处理 (NLP) 功能的服务。提供的功能包括情感分析、意见挖掘、关键词提取、语言检测和命名实体识别。
- en: First, you need to deploy the text analytics resource via the Azure portal.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，您需要通过 Azure 门户部署文本分析资源。
- en: Configuring text analytics
  id: totrans-299
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 配置文本分析
- en: 'You must have an Azure subscription to use these services. Then you need to
    create a text analytics resource by following these steps:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 您必须拥有 Azure 订阅才能使用这些服务。然后，您需要按照以下步骤创建文本分析资源：
- en: Go to the Azure portal ([https://portal.azure.com/](https://portal.azure.com/))
    and click on the **Create a resource** plus icon.
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 前往 Azure 门户 ([https://portal.azure.com/](https://portal.azure.com/)) 并点击 **创建资源**
    的加号图标。
- en: Start entering the text string in the search textbox and the **Text Analytics**
    option will appear. Click on it. Then, click on the **Create** button on the **Text
    Analytics** page.
  id: totrans-302
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在搜索框中开始输入文本字符串，**文本分析** 选项将出现。点击它。然后，点击 **文本分析** 页面上的 **创建** 按钮。
- en: Forget about selecting the **Custom question answering** option, and click on
    **Continue to create your resource** instead.
  id: totrans-303
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 忘记选择 **自定义问答** 选项，而是点击 **继续创建您的资源**。
- en: On the **Create Text Analytics** page, select the region you prefer and give
    a name to the service (in our case, `textanalytics555`; you can use a unique name
    of your choosing). Assign your resource to a new resource group with the name
    `text-analytics`. Then, select the **Free F0** pricing tier, check the **Responsible
    AI Notice** option, and click on **Review + create**. Then, click **Create** on
    the next page.
  id: totrans-304
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 **创建文本分析** 页面上，选择您喜欢的区域并给服务命名（在我们的例子中，`textanalytics555`；您可以使用您选择的唯一名称）。将您的资源分配给名为
    `text-analytics` 的新资源组。然后，选择 **免费 F0** 定价层，勾选 **负责任的 AI 通知** 选项，并点击 **审查 + 创建**。然后，在下一页上点击
    **创建**。
- en: Once the deployment of the resource is complete, click on **Go to resource**
    and click on the **API Key** link on the next page. Then, take note of the details
    of **KEY 1** (you can click on the **Copy to clipboard** icon on its right) and
    the endpoint URL. You’ll use this information in your Python code.
  id: totrans-305
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 资源部署完成后，点击 **转到资源** 并在下一页上点击 **API 密钥** 链接。然后，注意 **KEY 1** 的详细信息（您可以在其右侧点击 **复制到剪贴板**
    图标），以及端点 URL。您将在 Python 代码中使用这些信息。
- en: Your resource is now ready to be used via the dedicated Python SDK.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 您的资源现在可以通过专门的 Python SDK 使用了。
- en: Configuring your Python environment and Windows
  id: totrans-307
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 配置您的 Python 环境和 Windows
- en: 'In order to consume text analytics, you must first install the **Microsoft
    Azure Text Analytics Client Library for Python** by following these steps:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使用文本分析，您必须首先按照以下步骤安装 **Microsoft Azure Text Analytics Python 客户端库**：
- en: Open your Anaconda Prompt.
  id: totrans-309
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开您的 Anaconda Prompt。
- en: 'Switch to your PyCaret environment by entering this command: `conda activate
    pycaret_env`.'
  id: totrans-310
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过输入以下命令切换到您的 PyCaret 环境：`conda activate pycaret_env`。
- en: 'Install the client library by entering this command: `pip install azure-ai-textanalytics==5.1.0`.'
  id: totrans-311
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过输入以下命令安装客户端库：`pip install azure-ai-textanalytics==5.1.0`。
- en: 'After that, to avoid the *ssl module in Python is not available* error in Windows
    10, you need to add the `pycaret_env\Library\bin` path to the Windows environment
    `PATH` variable. These are the steps to do it:'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，为了避免在 Windows 10 中出现“*Python 的 ssl 模块不可用*”错误，您需要将 `pycaret_env\Library\bin`
    路径添加到 Windows 环境变量 `PATH` 中。以下是执行此操作的步骤：
- en: Click on the Windows **Start** icon in the bottom-left corner of your screen
    and start digitizing the x `variable`.string This will search for all Windows
    options that have the string variable in their name. Then, click on **Edit environment
    variables for your account**.
  id: totrans-313
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击屏幕左下角的 Windows **开始** 图标，并开始数字化 x `变量`.string 这将搜索所有名称中包含字符串变量的 Windows 选项。然后，点击
    **编辑您的账户的环境变量**。
- en: In the **Environment Variables** windows, double-click on the **Path** variable
    under **User variables for <your-user>** (if you installed Miniconda for all users,
    you need to change the **Path** system variable). In the **Edit environment variable**
    dialog that will appear, click on the **New** button and add the path `C:\<your-path>\miniconda3\envs\pycaret_env\Library\bin`.
    Then, click **OK** on all the windows.
  id: totrans-314
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 **环境变量** 窗口中，在 **用户变量** 下双击 **Path** 变量（如果你为所有用户安装了 Miniconda，你需要更改 **Path**
    系统变量）。在出现的 **编辑环境变量** 对话框中，点击 **新建** 按钮，并添加路径 `C:\<你的路径>\miniconda3\envs\pycaret_env\Library\bin`。然后，在所有窗口上点击
    **确定**。
- en: You need to restart your system to make the change effective.
  id: totrans-315
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你需要重新启动系统以使更改生效。
- en: You are now ready to be able to consume the service from Power Query.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在可以准备好使用 Power Query 消费服务了。
- en: Consuming the Text Analytics API in Power BI
  id: totrans-317
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 在 Power BI 中消费文本分析 API
- en: In this section, we will show you how to do sentiment analysis thanks to text
    analytics on the fictional company *Fabrikam Fiber*. It provides cable television
    and related services in the United States, allowing users to enter comments on
    their website. Your goal is to define for each comment the degree of positivity,
    neutrality, and negativity.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将向您展示如何通过在虚构公司 *Fabrikam Fiber* 上的文本分析进行情感分析。它在美国提供有线电视和相关服务，允许用户在其网站上留下评论。你的目标是定义每个评论的积极程度、中立程度和消极程度。
- en: Basically, once a client has been authenticated with a URL and key, you can
    easily carry out a sentiment analysis thanks to the `analyze_sentiment()` method
    without knowing any NLP basis. Keep in mind that the free tier of text analytics
    is limited to processing only 10 documents (in our case, comments) at a time.
    For this reason, the code we built consists of grouping the comments in groups
    of 10 and invoking the API for each group.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上，一旦客户端通过 URL 和密钥进行认证，你就可以通过 `analyze_sentiment()` 方法轻松地进行情感分析，而无需了解任何 NLP
    基础。请注意，文本分析免费层仅限于一次处理 10 个文档（在我们的案例中是评论）。因此，我们构建的代码包括将评论分成每组 10 个，并对每个组调用 API。
- en: 'Let’s see how to do that:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何做到这一点：
- en: 'Click on **Get Data**, select **Text/CSV**, and then click on **Connect**:'
  id: totrans-321
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 **获取数据**，选择 **文本/CSV**，然后点击 **连接**：
- en: Select the `FabrikamComments.csv` file in the `Chapter13` folder and click **Open**.
  id: totrans-322
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `Chapter13` 文件夹中选择 `FabrikamComments.csv` 文件，然后点击 **打开**。
- en: You’ll see a preview of the Fabrikam dataset. Then, click **Transform Data**.
  id: totrans-323
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你将看到 Fabrikam 数据集的预览。然后，点击 **转换数据**。
- en: Click **Transform** on the ribbon, followed by **Run Python script**.
  id: totrans-324
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在功能区上点击 **转换**，然后点击 **运行 Python 脚本**。
- en: Enter the script you can find in the `07-use-text-analytics-in-power-bi.py`
    file in the `Chapter13\Python` folder. Remember to appropriately replace the service
    URL and its key that you previously copied into the Azure portal.
  id: totrans-325
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `Chapter13\Python` 文件夹中找到 `07-use-text-analytics-in-power-bi.py` 文件中的脚本。请记住，要适当地替换你之前在
    Azure 门户中复制的服务 URL 和其密钥。
- en: We are only interested in the `sentiment_enriched_df` dataframe. So, click on
    its **Table** value.
  id: totrans-326
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们只对 `sentiment_enriched_df` 数据框感兴趣。所以点击它的 **表** 值。
- en: 'You''ll see a preview of the Fabrikam dataset enriched with the following additional
    columns: `comment_sentiment`, `overall_positive_score`, `overall_neutral_score`,
    and `overall_negative_score`:'
  id: totrans-327
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你将看到 Fabrikam 数据集的预览，其中增加了以下附加列：`comment_sentiment`、`overall_positive_score`、`overall_neutral_score`
    和 `overall_negative_score`：
- en: '![Figure 13.34 – Additional sentiment analysis columns](img/file367.png)'
  id: totrans-328
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 13.34 – 额外的情感分析列](img/file367.png)'
- en: Figure 13.34 – Additional sentiment analysis columns
  id: totrans-329
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 13.34 – 额外的情感分析列
- en: Click **Home** on the ribbon and then click **Close & Apply**.
  id: totrans-330
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在功能区上点击 **主页**，然后点击 **关闭并应用**。
- en: That’s amazing! Thanks to the Python library `azure.ai.textanalytics`, you were
    able, in a few lines of code, to perform sentiment analysis in a very simple way.
    With the same ease, you can also use in Power BI the other services that cognitive
    services provide thanks to other Python SDKs.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 这太棒了！多亏了 Python 库 `azure.ai.textanalytics`，你只用几行代码就能以非常简单的方式执行情感分析。同样容易，你还可以使用
    Power BI 中的其他认知服务提供的服务，这些服务通过其他 Python SDK 实现。
- en: Summary
  id: totrans-332
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you learned how Power BI interacts with Microsoft AI services
    by default through data flow features. You also learned that by using AutoML platforms,
    you can get around the licensing problem (PPU license or Premium capacity) that
    Power BI needs to interface with Microsoft AI services. You used both an on-premises
    AutoML solution (PyCaret) and Azure AutoML on the cloud to solve a binary classification
    problem. You also used cognitive services' text analytics to do some sentiment
    analysis directly using a Python SDK.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你学习了Power BI如何通过数据流功能默认与Microsoft AI服务交互。你还了解到，通过使用AutoML平台，你可以绕过Power
    BI与Microsoft AI服务接口所需的许可问题（PPU许可证或高级容量）。你使用了一个本地AutoML解决方案（PyCaret）和Azure AutoML在云端解决了一个二元分类问题。你还使用了认知服务的文本分析，直接使用Python
    SDK进行了一些情感分析。
- en: You've learned that enrichment via AI mostly happens in Power Query (which allows
    access to the internet), although you've seen a case where it may be convenient
    to use a machine learning model directly within a Python visual.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经了解到，通过人工智能的丰富功能主要发生在Power Query中（它允许访问互联网），尽管你看到过一种情况，直接在Python视图中使用机器学习模型可能更方便。
- en: In the next chapter, you will see how to implement data exploration of your
    dataset in Power BI.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，你将看到如何在Power BI中实现数据集的探索。
- en: References
  id: totrans-336
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'For additional reading, check out the following books and articles:'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 对于额外的阅读，请参阅以下书籍和文章：
- en: '*AI with data flows* ([https://docs.microsoft.com/en-us/power-bi/transform-model/dataflows/dataflows-machine-learning-integration](https://docs.microsoft.com/en-us/power-bi/transform-model/dataflows/dataflows-machine-learning-integration))'
  id: totrans-338
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*使用数据流实现AI*](https://docs.microsoft.com/en-us/power-bi/transform-model/dataflows/dataflows-machine-learning-integration)'
- en: '*A Review of Azure Automated Machine Learning (AutoML)* ([https://medium.com/microsoftazure/a-review-of-azure-automated-machine-learning-automl-5d2f98512406](https://medium.com/microsoftazure/a-review-of-azure-automated-machine-learning-automl-5d2f98512406))'
  id: totrans-339
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*《Azure自动化机器学习（AutoML）综述*](https://medium.com/microsoftazure/a-review-of-azure-automated-machine-learning-automl-5d2f98512406)'
- en: '*Automated Machine Learning with Microsoft Azure, by Dennis Michael Sawyers,
    Packt Publishing* ([https://www.amazon.com/Automated-Machine-Learning-Microsoft-Azure/dp/1800565313/](https://www.amazon.com/Automated-Machine-Learning-Microsoft-Azure/dp/1800565313/))'
  id: totrans-340
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*《使用Microsoft Azure进行自动化机器学习，作者：Dennis Michael Sawyers，Packt出版社》*](https://www.amazon.com/Automated-Machine-Learning-Microsoft-Azure/dp/1800565313/)'
- en: '*A Gentle Introduction to Concept Drift in Machine Learning* ([https://machinelearningmastery.com/gentle-introduction-concept-drift-machine-learning/)](https://machinelearningmastery.com/gentle-introduction-concept-drift-machine-learning/))'
  id: totrans-341
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*机器学习中概念漂移的温和介绍*](https://machinelearningmastery.com/gentle-introduction-concept-drift-machine-learning/)'
- en: '*Machine Learning Basics with the K-Nearest Neighbors Algorithm* ([https://towardsdatascience.com/machine-learning-basics-with-the-k-nearest-neighbors-algorithm-6a6e71d01761](https://towardsdatascience.com/machine-learning-basics-with-the-k-nearest-neighbors-algorithm-6a6e71d01761))'
  id: totrans-342
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*使用K最近邻算法进行机器学习基础知识*](https://towardsdatascience.com/machine-learning-basics-with-the-k-nearest-neighbors-algorithm-6a6e71d01761)'
- en: '*Python’s «predict_proba» Doesn’t Actually Predict Probabilities (and How to
    Fix It)* ([https://towardsdatascience.com/pythons-predict-proba-doesn-t-actually-predict-probabilities-and-how-to-fix-it-f582c21d63fc](https://towardsdatascience.com/pythons-predict-proba-doesn-t-actually-predict-probabilities-and-how-to-fix-it-f582c21d63fc))'
  id: totrans-343
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*Python的「predict_proba」实际上并不预测概率（以及如何修复它）*](https://towardsdatascience.com/pythons-predict-proba-doesn-t-actually-predict-probabilities-and-how-to-fix-it-f582c21d63fc)'
- en: '*Use the Interpretability Package to Explain ML Models and Predictions in Python*
    ([https://docs.microsoft.com/en-us/azure/machine-learning/how-to-machine-learning-interpretability-aml](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-machine-learning-interpretability-aml))'
  id: totrans-344
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*使用可解释性包在Python中解释ML模型和预测*](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-machine-learning-interpretability-aml)'
- en: '*Get Started with Tidymodels* ([https://www.tidymodels.org/start/ https://www.tidymodels.org/start/](https://www.tidymodels.org/start/))'
  id: totrans-345
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*《开始使用Tidymodels》*](https://www.tidymodels.org/start/)'
