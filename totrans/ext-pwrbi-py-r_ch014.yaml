- en: 13 Using Machine Learning without Premium or Embedded Capacity
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Thanks to the computing power now available via powerful laptops or through
    the cloud, you can enrich your analysis with insights from machine learning models
    easily and instantly. **Power BI** provides integrated tools (closely related
    to data flows) that allow you to use machine learning models developed by data
    scientists on Azure Machine Learning, models trained and deployed through **Azure
    AutoML**, or services exposed by cognitive services directly through a convenient
    graphical interface. The only drawback is that these tools (known as **Advanced
    AI**) are only enabled if you use an **Embedded** capacity, Premium capacity,
    or **Premium Per User** (**PPU**) license. Does this mean that a user using Power
    BI Desktop or simply the Power BI service with a Pro license cannot benefit from
    machine learning? Absolutely not, and we'll show you how to do it thanks to **Python**
    and **R**.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, you will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Interacting with ML in Power BI with data flows
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using AutoML solutions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Embedding training code in Power Query
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using trained models in Power Query
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using trained models in Script Visuals
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Calling web services in Power Query
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This chapter requires you to have a working internet connection and **Power
    BI Desktop** already installed on your machine. You must have properly configured
    the R and Python engines and IDEs as outlined in *Chapter 2*, *Configuring R with
    Power BI*, and *Chapter 3*, *Configuring Python with Power BI*.
  prefs: []
  type: TYPE_NORMAL
- en: Interacting with ML in Power BI with data flows
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You can access **Advanced AI features** directly through Power BI Desktop or
    you can access **Advanced AI features for dataflow** through data flows, which
    are easy-to-use tools for transforming big data into insights to be shown in dashboards.
    But, as you can imagine, both modes require the aforementioned licenses in the
    introduction.
  prefs: []
  type: TYPE_NORMAL
- en: 'These features are accessible from Power BI Desktop, in the **Power Query Home**
    ribbon:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.1 – AI insights in Power BI Desktop](img/file334.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.1 – AI insights in Power BI Desktop
  prefs: []
  type: TYPE_NORMAL
- en: The first two options (**Text Analytics** and **Vision**) you can see in *Figure
    13.1* use **Azure Cognitive Services** behind the scenes, specifically Text Analytics
    services and Computer Vision services. Basically, thanks to these features in
    Power BI, you can now use *four functions* to enrich your data through the power
    of machine learning.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.2 – Cognitive Services functions in Power BI](img/file335.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.2 – Cognitive Services functions in Power BI
  prefs: []
  type: TYPE_NORMAL
- en: 'These are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**TagImages**. Analyzes images to generate tags based on what they contain'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ExtractKeyPhrases**. Evaluates unstructured text, and for each text column,
    returns a list of key phrases'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**DetectLanguage**. Evaluates text input, and for each column, returns the
    language name and ISO identifier'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ScoreSentiment**. Evaluates text input and returns a sentiment score for
    each document, ranging from 0 (negative) to 1 (positive)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The other option of AI Insights is to be able to use models hosted in **Azure
    Machine Learning** as scoring functions in Power Query.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.3 – Azure Machine Learning functions in Power BI](img/file336.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.3 – Azure Machine Learning functions in Power BI
  prefs: []
  type: TYPE_NORMAL
- en: To top it off, the Advanced AI features also include the ability to create machine
    learning models on the fly via a GUI thanks to **AutoML for dataflows**.
  prefs: []
  type: TYPE_NORMAL
- en: 'AutoML solutions are very convenient, especially for the analyst who doesn’t
    have much experience with machine learning. You will see this in detail in the
    next section. Now you just need to know that in Power BI, you can generate three
    types of models: **classifications** (binary or multi-label), **regressions**,
    and **time series forecasting** (will be available soon).'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.4 – AutoML for data flows in Power BI](img/file337.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.4 – AutoML for data flows in Power BI
  prefs: []
  type: TYPE_NORMAL
- en: Behind the scenes, there is the Azure AutoML service that allows you to do model
    training, but by leveraging data flows, you don't need to instantiate a machine
    learning workspace to run AutoML experiments.
  prefs: []
  type: TYPE_NORMAL
- en: A user who only has a Power BI Pro license cannot access these fantastic features
    directly from the Power BI GUI. However, thanks to the introduction of Python
    and R in Power BI, it is possible to use machine learning algorithms or external
    services that facilitate their implementation with just a few lines of code.
  prefs: []
  type: TYPE_NORMAL
- en: Is it really possible that just a few lines of code are enough to train a machine
    learning model? Where is the trick!? Let's explain the mystery.
  prefs: []
  type: TYPE_NORMAL
- en: Using AutoML solutions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Writing code from scratch to do machine learning requires specific knowledge
    that a generic analyst using Power BI often doesn’t know. Therefore, we recommend
    the use of **Automated Machine Learning** (**AutoML**) processes from here on
    out for analysts who do not have a data science background. Does this mean that
    anyone can create an accurate machine learning model without knowing the theory
    behind this science simply by using AutoML algorithms? Absolutely not! The following
    applies:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Important Note**'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: An AutoML tool relieves the analyst of all those repetitive tasks typical of
    a machine learning process (hyperparameter tuning, model selection, and so on).
    Often, those that require specific theoretical knowledge on the part of the analyst
    (for example, missing value imputation, dataset balancing strategies, feature
    selection, and feature engineering) are left out of the automated steps. Therefore,
    not applying the appropriate transformations that only an expert knows to the
    dataset before starting an AutoML process leads to the generation of a baseline
    model that might be sufficiently accurate, but could not ensure product performance.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: You might think that AutoML tools are hated by data scientists. This is also
    a myth. Many of them use it as a quick and dirty prototyping tool and as an executor
    of repetitive steps while they focus on more critical tasks.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will be satisfied with obtaining discrete performance models
    (sometimes very good if we are lucky enough to have a properly transformed training
    dataset), and so the outputs provided by AutoML solutions are more than fine.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, we will exclusively use AutoML solutions in Python as it is the most
    widely used language in most third-party machine learning platforms. The R language
    is a little less widely used than Python, but that doesn't mean the results you
    get in R are any less valid. On the contrary, as you may have noticed in previous
    chapters, some specialized packages of statistical functions that allow high flexibility
    of data manipulation exist only for R and not for Python.
  prefs: []
  type: TYPE_NORMAL
- en: Simply put, working with machine learning in Python to date allows models to
    be easily shared between popular platforms. Therefore, we suggest it for Power
    BI analysts, who perhaps prefer to delegate model creation to more specialized
    platforms and then import them in Power BI.
  prefs: []
  type: TYPE_NORMAL
- en: Let's see what AutoML tools we'll be using in the code for this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: PyCaret
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**PyCaret** ([https://pycaret.org/](https://pycaret.org/)) is an open source,
    low-code machine learning library in Python that automates the cycle of machine
    learning experiments, democratizing access to these advanced techniques to business
    analysts and domain experts, and also helping data scientists to become more efficient
    and productive.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The types of problems that PyCaret can solve are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Classification** (predicting a categorical target variable)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Regression** (predicting a numeric target variable)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Clustering** (grouping of observations into specific sets, each with its
    own properties)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Anomaly Detection** (the process of finding outliers in a dataset, and which
    are far fewer in number than with usual observations)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Natural Language Processing** (text transformations in useful features for
    classifications and regressions)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Association Rules** (a rule-based technique that finds important relationships
    between features according to probability theory)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For more experienced users, PyCaret also provides convenient functions for model
    ensembling and model explanation.
  prefs: []
  type: TYPE_NORMAL
- en: Azure AutoML
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Azure AutoML is a cloud-based service that can be used to automate the construction
    of machine learning pipelines for classification, regression, and forecasting
    tasks. Such pipelines involve a pre-processing phase of the dataset to better
    fit the training algorithms used in the next phase. After tuning and training
    multiple models, Azure AutoML selects the most accurate model among them, while
    also considering two other models resulting from the ensembling of the previously
    trained models.
  prefs: []
  type: TYPE_NORMAL
- en: 'The available tasks are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Classification
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Regression
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Time series forecasting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For more detailed coverage of this platform, please take a look at the references.
  prefs: []
  type: TYPE_NORMAL
- en: RemixAutoML for R
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For the sake of completeness, we also suggest one of AutoML's solutions for
    R, which is **RemixAutoML** ([https://github.com/AdrianAntico/RemixAutoML](https://github.com/AdrianAntico/RemixAutoML)).
    It is a set of functions that facilitate the use of many AutoML packages available
    for R (CatBoost, LightGBM, XGBoost, and H2O). In addition to giving the inexperienced
    analyst the ability to create machine learning models with a few lines of code
    thanks to AutoML, this library also contains very advanced features (for example,
    features for feature engineering and time series forecasting), often used by more
    experienced analysts.
  prefs: []
  type: TYPE_NORMAL
- en: Let's now look at the various ways to use machine learning models in Power BI.
  prefs: []
  type: TYPE_NORMAL
- en: Embedding training code in Power Query
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One of the easiest solutions to train a machine learning model is to write the
    code needed to do so directly in Power Query, right after importing a dataset
    on which you will build the model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Training a model on a fairly large dataset typically takes quite a bit of time
    to complete. As you embed the code in Power Query, it will run every time the
    data is refreshed, and this may result in a non-negligible delay in getting the
    data online. Hence, the following applies:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Important Note**'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This solution is recommended when you are certain that the time required to
    complete the model training is acceptable.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Let's now look at an example of how to write some training code using PyCaret.
  prefs: []
  type: TYPE_NORMAL
- en: Training and using ML models with PyCaret
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let's take the Titanic disaster dataset to train a machine learning model. Specifically,
    we want to create a model that predicts whether a passenger survives (the `Survived`
    column) based on their attributes described by the other features in the dataset.
    Evidently, this is a *binary classification* (does it survive? yes or no) that
    we can easily implement with PyCaret.
  prefs: []
  type: TYPE_NORMAL
- en: 'As PyCaret is constantly evolving and so are all the other dependent libraries,
    you need to also install the **Visual C++ Build tools** to build the necessary
    wheels and avoid errors such as *Failed building wheel for <package>*. Here are
    all the steps needed to install PyCaret correctly for Windows:'
  prefs: []
  type: TYPE_NORMAL
- en: Download the installer from [https://visualstudio.microsoft.com/visual-cpp-build-tools/](https://visualstudio.microsoft.com/visual-cpp-build-tools/)
    and run it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the next window, check just the **Desktop development with C++** option.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You will be prompted to restart the machine. Do so.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Once your laptop has restarted, run your Anaconda Prompt and enter the following
    command to create the new `pycaret_env` environment:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Enter the following command to switch to the new environment:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Enter the following command to install the full version of PyCaret:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Having done that, you can move on to see the training code of the model. The
    only little hiccup is the handling of missing values in the dataset (you already
    had a chance to analyze them in *Chapter 12*, *Adding Statistics Insights, Outliers,
    and Missing Values*). Unfortunately, PyCaret currently only supports handling
    missing values using the simplest methods, namely, imputation using the mean or
    median for numeric values, and imputation using the mode or a fixed string for
    categorical values. Since we want to show you how to impute missing values using
    the *K-Nearest Neighbors (KNN)* algorithm as anticipated in *Chapter 12*, *Adding
    Statistics Insights, Outliers, and Missing Values*, you will write a few more
    lines of code than usual.
  prefs: []
  type: TYPE_NORMAL
- en: The code used to impute the missing values via the KNN algorithm will be used
    in the first transformation step in Power BI, after importing the data from the
    Titanic dataset. You can find the code in the `01-impute-dataset-with-knn.py`
    file in the `Chapter13/Python` folder. It will take care first to operate a simple
    feature selection, eliminating those fields that could cause noise during the
    training of the model. After that, since the above imputation algorithm exposed
    by scikit-learn via the **KNNImputer** module does not handle categorical variables
    in the dataset, the code also takes care of doing the encoding of the categorical
    variables using the **ordinal encoding** technique (using a mapping of categories
    to integers) thanks to the **OrdinalEncoder** module of scikit-learn. At this
    point, the code imputes the missing values using the default distance measure,
    that is, a Euclidean distance measure that will not include NaN values when calculating
    the distance between members of the training dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Once the imputed dataset is available, you can train the model with which you
    will then score a test dataset. You can find the code in the `02-train-model-with-pycaret.py`
    file in the `Chapter13/Python` folder. For convenience, you will use 95% of the
    imputed dataset to train the model, while the remaining 5% will be used as a test
    dataset. All this will go in a transformation step following the previous one
    used for the imputation of missing values in Power BI.
  prefs: []
  type: TYPE_NORMAL
- en: You'll split the dataset into training and test sets thanks to scikit-learn's
    `train_test_split()` method. After that, the model training is done very simply
    by calling PyCaret's `setup()` and `compare_models()` functions. In the `setup()`
    function, you will define which dataframe to use for training, the target variable
    (`Survived`), and which are the categorical and which are the ordinal variables.
    Moreover, it is necessary to use silent mode, otherwise user intervention would
    be required to validate the inferred types of the other variables. The `compare_models()`
    function trains and evaluates the performance of all models provided by PyCaret
    for classification using cross-validation. In addition to returning the best-performing
    model, this function also returns the performance values of each model returned
    by cross-validation.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.5 – Performance of all models](img/file338.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.5 – Performance of all models
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 13.5* shows several typical classification metrics for each model.
    One of the most widely used is the **Area Under the ROC Curve** (**AUC** or **AUC-ROC**)
    when the dataset is balanced (in other words, when there is a slight disproportion
    between the number of observations associated with one class of the target variable
    versus the other class). The following remark applies:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Important Note**'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The `compare_models()` function doesn’t work in Power BI unless you disable
    the parallelism, passing `n_jobs=1` into the `setup()` function. If you don’t
    assign `1` to `n_job`, by default, PyCaret assigns the value -1 (maximum parallelism)
    and behind the scenes, the best model is computed correctly using multiple threads,
    but Power BI can't trace it back to the main process, so it gets stuck.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'With an AUC of about 0.85 (it can vary as the process is stochastic), the **Random
    Forest Classifier** appears to be the best model obtained by training 95% of the
    imputed dataset. Then you will use the newly trained model (`best_model`) to obtain
    predictions of the remaining 5% of the dataset via PyCaret''s `predict_model()`
    function. You will get a result similar to this one:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.6 – Predictions of the test dataset](img/file339.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.6 – Predictions of the test dataset
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see, the result generated by scoring the dataset consists of two
    new columns for classification: the `Score` column represents an estimate of a
    measure, such as the probability with which the predicted classes are those reported
    in the `Label` column. If you are interested in having a true probability estimate,
    you have to **calibrate** the model (have a look at the references for more details).
    The trained model will also be saved as a PKL file for future reuse.'
  prefs: []
  type: TYPE_NORMAL
- en: Let's look at how to implement what's explained up here in Power BI.
  prefs: []
  type: TYPE_NORMAL
- en: Using PyCaret in Power BI
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'First, make sure that Power BI Desktop references the new `pycaret_env` Python
    environment in **Options**. Then, follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Click on **Get Data**, search for `web`, select **Web**, and then click on **Connect**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Enter the `http://bit.ly/titanic-dataset-csv` URL into the URL textbox and click
    **OK**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You’ll see a preview of the data. Then, click **Transform Data**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Transform** on the ribbon and then **Run Python script**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Enter the script you can find in the `01-impute-dataset-with-knn.py` file in
    the `Chapter13\Python` folder.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We are only interested in the data in the `df_imputed` dataframe. So, click
    on its **Table** value.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You'll see a preview of the dataset with all the missing values imputed.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Transform** on the ribbon and then **Run Python script**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Enter the script you can find in the `02-train-model-with-pycaret.py` file in
    the `Chapter13\Python` folder.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We are only interested in the data in the `predictions` dataframe. So, click
    on its **Table** value.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You'll see a preview of the dataset with the predictions generated by the model
    and the input dataset.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Home** on the ribbon and then click **Close & Apply**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazing! You have just trained a machine learning model and then scored a test
    dataset using a few lines of Python code thanks to PyCaret!
  prefs: []
  type: TYPE_NORMAL
- en: Let's now see how to proceed when the model is trained outside of Power BI.
  prefs: []
  type: TYPE_NORMAL
- en: Using trained models in Power Query
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As you already saw in *Chapter 4*, *Importing Unhandled Data Objects*, you
    used to share objects that were the result of complex, time-consuming processing
    (thus also a machine learning model) in a serialized format specific to the language
    you were using. At that point, it was very simple to deserialize the file and
    get the model ready to be used in Power Query to predict the target variable of
    new observations. However, it is important to know the dependencies needed by
    the scoring function (which gets the new observations as input and returns the
    predictions), since they are closely related to how the training of the model
    took place. For this reason, we recommend the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Important Note**'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: When you need to use a serialized machine learning model provided by a third
    party, make sure that whoever developed it also provides you with a working scoring
    function in order to avoid unnecessary headaches when predicting target values
    for unknown observations.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: If you think about it, the ability to serialize and deserialize a machine learning
    model could somehow solve the delay problem raised in the case of training the
    model directly in Power Query in the previous section. Suppose you run the embedded
    training code for the first time. Immediately afterward, you serialize the model
    and save it to disk. On the next refresh, instead of running the training code
    again, you can check whether the serialized model file exists in the expected
    path. If yes, you load the file, deserialize it, and use that model for the next
    steps; otherwise, you run the training code again.
  prefs: []
  type: TYPE_NORMAL
- en: Evidently, the aforementioned process involves the intervention of an expert
    who decides to eliminate the serialized file when the model does not perform very
    well because perhaps the business data has, in the meantime, changed substantially
    such that the previous model is not accurate any longer, like it was after the
    training undertaken with the past data (a process known as **model drift**; take
    a look at the references for more details).
  prefs: []
  type: TYPE_NORMAL
- en: We will not go into the implementation details of this solution, but we wanted
    to provide just a tip for a possible solution to the problem raised in the previous
    section.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s now implement the scoring of a dataset of unseen observations in Power
    BI using an already trained PyCaret model.
  prefs: []
  type: TYPE_NORMAL
- en: Scoring observations in Power Query using a trained PyCaret model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If you remember correctly, in the previous section, you saved the model trained
    in Power BI to a PKL file on disk. You also exported the test dataset calculated
    in the same code to CSV. In this session, you will directly use the serialized
    model, loading it with the `load_model()` function, and the test CSV dataset to
    be scored in Power BI. Since the model was trained using PyCaret, the scoring
    function to use is simply given by the `predict_model()` function. Keep in mind
    that the scoring function may be more complex when not using a framework such
    as PyCaret that simplifies things.
  prefs: []
  type: TYPE_NORMAL
- en: 'These are the steps to follow in Power BI:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on **Get Data**, select **Text/CSV**, and then click on **Connect**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the `titanic-test.csv` file in the `Chapter13` folder and click **Open**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You’ll see a preview of the test data. Then, click **Transform Data**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Transform** on the ribbon and then **Run Python script**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Enter the script you can find in the `03-score-dataset-using-pycaret-model.py`
    file in the `Chapter13\Python` folder.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We are only interested in the `predictions` dataframe. So, click on its **Table**
    value.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You'll see a preview of the test dataset with two additional columns – `Label`
    and `Score`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Home** on the ribbon and then click **Close & Apply**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'As you can see, this is the most immediate and common way to use a custom machine
    learning model for scoring in Power BI. In fact, we recommend the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Important Note**'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: It is convenient to do the training and, in general, to manage a machine learning
    model in platforms external to Power BI in order to decouple any development/tuning
    interventions of the model from the rest of the report.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Let's now see instead how to use serialized machine learning models directly
    in **Script Visuals**.
  prefs: []
  type: TYPE_NORMAL
- en: Using trained models in Script Visuals
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As you learned in *Chapter 4*, *Importing Unhandled Data Objects*, thanks to
    object serialization and its string representation, you can import any object
    into a Python or R visual in the form of a dataframe of strings. Once said dataframe
    is available in the script visual, you can revert it to the original object via
    inverse deserialization transformations. Since you can do what we described with
    any object, evidently you can also do it for machine learning models already trained
    outside of Power BI.
  prefs: []
  type: TYPE_NORMAL
- en: When the appropriately deserialized model is available in the *Script Visual*
    session, new observations can be predicted immediately using the scoring function
    described in the previous section.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first thing you might ask yourself is what''s the point of being able to
    score a dataset inside a script visual when the data must always be available
    first in the Power BI data model in order to use it in the visual. In fact, if
    the data of the observations to use as input to the model is already found in
    the data model of Power BI, it could be better to apply batch scoring directly
    in Power Query and so use the predictions as a new column of the dataset. All
    of this is absolutely true. However, there are some cases in which it is convenient
    to use a script visual:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Important Note**'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: It is convenient to use a machine learning model in a script visual when you
    need to realize some simulation reports that allow you to explore the outputs
    of the model and vary the variables in play dynamically without having to refresh
    the entire report.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In this case, we suggest using **What-If parameters** ([https://bit.ly/power-bi-what-if](https://bit.ly/power-bi-what-if))
    in Power BI for numeric features, which are dynamic and give the user a very usable
    report. For categorical variables, you can enter their content manually in Power
    BI using the **Enter Data** feature, which creates a disconnected table. What-If
    parameters create disconnected tables by default in the data model.
  prefs: []
  type: TYPE_NORMAL
- en: To properly understand this paragraph, make sure you understand the content
    of *Chapter 4*, *Importing Unhandled Data Objects*. Suppose you have to provide
    observations to a machine learning model that expects two variables as input –
    a numeric one and a categorical one. When passing the information to the script
    visual’s dataframe, in addition to the fields of the serialized model’s dataframe
    (`model_id`, `chunk_id`, and `model_str`) coming from Power Query, you will also
    have to assign the associated values to both the parameter slicers related to
    the two input variables. Since only one value is selected at a time for each parameter
    when slicing, the set of all the parameters form a tuple, which in our case is
    (`numeric_value`, `category_id`). This tuple will be replicated as many times
    as the rows of the string chunk dataframe (consisting of the columns `model_id`,
    `chunk_id`, and `model_str`), and concatenated to it in order to provide the final
    dataframe that will be available in the variable named `dataset` in the Script
    Visual session.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.7 – Deserializing the PKL file content into a Python visual](img/file340.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.7 – Deserializing the PKL file content into a Python visual
  prefs: []
  type: TYPE_NORMAL
- en: Once you have the dataset dataframe available in the script visual, you can
    apply the deserialization transformations just to the columns (`model_id`, `chunk_id`,
    and `model_str`), thereby obtaining the machine learning model ready to be used.
    Selecting instead just the columns (`number`, `category`) and applying the distinct
    function to all the rows of the resulting dataframe, you obtain back the tuple
    of parameters to provide by way of input to the deserialized model. You can therefore
    calculate the predicted value from the model, providing to it the tuple of parameters
    as input. You can then use the prediction in the graph to be shown in the script
    visual.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s see in practice how to dynamically predict values from a machine learning
    model in a Python Script Visual.
  prefs: []
  type: TYPE_NORMAL
- en: Scoring observations in a script visual using a trained PyCaret model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The first thing you will do is to serialize properly the machine learning models
    (in our case, only one) contained in a dictionary in Power Query. In this way,
    a dataframe containing the representation in strings of every serialized model
    of the aforementioned dictionary is obtained. So, it is possible to select the
    model of interest through a slicer in the report and to therefore use the respective
    portion of a dataframe in a Python script visual, inside which it will be possible
    to deserialize the content of the dataframe and to thereby obtain the model to
    use for scoring.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, let''s proceed to develop our report in Power BI. Make sure that Power
    BI correctly references the `pycaret_env` environment in **Options**. Here are
    the steps to follow:'
  prefs: []
  type: TYPE_NORMAL
- en: Click on **Get data** and then **More…**. Start typing `script` into the search
    textbox and double-click on **Python script**. The Python Script editor will pop
    up.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Copy the content of the `04-serialize-ml-models-in-power-query.py` file into
    the `Chapter13\Python` folder. Then, paste it into the Python Script editor, changing
    the absolute path to the PKL file accordingly, and then click **OK**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The navigator window will open, giving you the option to select which dataframe
    to import. Select both the `model_ids_df` dataframe (containing the model IDs)
    and the `models_df` one (containing the string representation of serialized models)
    and then click **Load**. Behind the scenes, a 1:* relationship is automatically
    created between the model IDs and the serialized model dataframe via the `model_id`
    fields.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 13.8 – Relationship automatically created between model tables](img/file341.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 13.8 – Relationship automatically created between model tables
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This relationship allows you to filter the set of rows in the **models_df**
    table to be used in the Python visual, corresponding to the ID of the model you
    select via the slicer you’ll create in the next step.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click on the slicer visual icon.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 13.9 – Selecting the slicer visual](img/file342.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 13.9 – Selecting the slicer visual
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Then, click on the **model_id** measure of the **model_ids_df** table.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 13.10 – Click on the model_id measure to show it in the slicer](img/file343.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 13.10 – Click on the model_id measure to show it in the slicer
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click on the downward-pointing arrow at the top right of the slicer to select
    the **Dropdown** slicer type.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 13.11 – Selecting the Dropdown slicer type](img/file344.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 13.11 – Selecting the Dropdown slicer type
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Resize the bottom edge of the slicer, click on its format options, switch on
    the **Single select** one, switch off **Slicer header**, and then add the title
    `Model IDs`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 13.12 – Setting the slicer options](img/file345.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 13.12 – Setting the slicer options
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Then, move it to the top center of the report.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You will now add a set of What-If parameters with their slicers associated with
    each variable to be passed as input to the model. Click on the **Modeling** tab
    on the ribbon and then on **New parameter**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: On the next dialog, enter `Pclass param` in the **Name** field, leave the data
    type as `Whole number`, enter `1` in the **Minimum** field, 3 in the **Maximum**
    field, leave **Increment** as 1, and enter 2 in the **Default** field.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 13.13 – Adding the What-if parameter for Pclass](img/file346.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 13.13 – Adding the What-if parameter for Pclass
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Keep **Add slicer to this page** selected and then click **OK**.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Resize the bottom edge of the Pclass slicer. Then, click on its format options,
    switch off **Slicer header**, switch on **Title**, and enter `Passenger class`
    as the text. Then move it to the top left of your report.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Be sure to rename the **Pclass** value of **Pclass param** to the same name
    as the variable that represents it in the model, namely, `Pclass`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 13.14 – Renaming the Pclass parameter value](img/file347.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 13.14 – Renaming the Pclass parameter value
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: As the variable **Sex** is categorical (F or M), you’ll create a disconnected
    table for it manually. So, click on the **Home** tab in the ribbon and click on
    **Enter data**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create the first column, **Sex**, of the table and add the values 0 and 1 to
    it. Then, create the new column, **SexLabel**, and enter `Female`, where **Sex**
    is `0`, and `Male`, where **Sex** is `1`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 13.15 – Enter data manually for Sex](img/file348.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 13.15 – Enter data manually for Sex
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Enter `Sex` as the table name and then click **Load**.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Let’s add a slicer for the `Sex` variable. Click on an empty spot in the report
    canvas first. Then, click the slicer visual to add a slicer to the report. Then,
    click on the **SexLabel** field and then on the **Sex** field (the order is important).
    Then, click on the downward-pointing arrow at the top right of the slicer to select
    the **Dropdown** slicer type. Also, click on its format options, switch on the
    **Single select** option in the **Selection control** group, switch off the **Slicer
    header** option, switch on **Title**, and then enter `Sex` as the text. Resize
    its bottom edge and move it under the **Passenger class** slicer.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 13.16 – A new dropdown slicer for Sex](img/file349.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 13.16 – A new dropdown slicer for Sex
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Let’s create a new `What-if` parameter for the `Age` variable. Click on the
    **Modeling** tab on the ribbon and then on **New parameter**. On the next dialog,
    enter `Age param` in the **Name** field, leave the data type as `Whole number`,
    enter `1` in the **Minimum** field, `80` in the **Maximum** field, leave **Increment**
    as `1`, and enter `30` in the **Default** field. Keep **Add slicer to this page**
    selected and then click **OK**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Resize the bottom edge of the Age slicer. Then, click on its format options,
    switch off **Slicer header**, switch on **Title**, and enter `Age` as the text.
    Then, move it to the top left of your report under the Sex slicer.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Be sure to rename the **Age** value of **Age param** to the same name as the
    variable that represents it in the model, namely, `Age`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 13.17 – Renaming the Age parameter value](img/file350.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 13.17 – Renaming the Age parameter value
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Let’s create a new What-if parameter for the `SibSp` variable. Click on the
    **Modeling** tab on the ribbon and then on **New parameter**. On the next dialog,
    enter `SibSp param` in the **Name** field, leave the data type as `Whole number`,
    enter `0` in the **Minimum** field, `8` in the **Maximum** field, leave **Increment**
    as `1`, and enter `0` in the **Default** field. Keep **Add slicer to this page**
    selected and then click **OK**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Resize the bottom edge of the SibSp slicer. Then, click on its format options,
    switch off **Slicer header**, switch on **Title**, and enter `Siblings/spouse
    aboard` as the text. Then, move it to the top left of your report under the Age
    slicer.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Be sure to rename the **SibSp** value of **SibSp param** to the same name as
    the variable that represents it in the model, namely, `SibSp`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 13.18 – Renaming the SibSp parameter value](img/file351.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 13.18 – Renaming the SibSp parameter value
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Let’s create a new What-if parameter for the `Parch` variable. Click on the
    **Modeling** tab on the ribbon and then on **New parameter**. On the next dialog,
    enter `Parch param` in the **Name** field, and leave Whole number as the data
    type, enter `0` in the **Minimum** field, `6` in the **Maximum** field, leave
    **Increment** as `1`, and enter `0` in the **Default** field. Keep **Add slicer
    to this page** selected and then click **OK**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Resize the bottom edge of the Parch slicer. Then, click on its format options,
    switch off **Slicer header**, switch on **Title**, and enter `Parents/children
    aboard` as the text. Then, move it to the top left of your report under the SibSp
    slicer.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Be sure to rename the **Parch** value of **Parch param** to the same name as
    the variable that represents it in the model, namely Parch:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 13.19 – Renaming the Parch parameter value](img/file352.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 13.19 – Renaming the Parch parameter value
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Let’s create a new What-if parameter for the `Fare` variable. Click on the **Modeling**
    tab on the ribbon and then on **New parameter**. On the next dialog, enter `Fare
    param` in the **Name** field, select `Decimal number` as the data type, enter
    `0` in the **Minimum** field, `515` in the **Maximum**, field, enter `1` in the
    **Increment** field, and then enter `250` in the **Default** field. Keep **Add
    slicer to this page** selected and then click **OK**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Resize the bottom edge of the Fare slicer. Then, click on its format options,
    switch off **Slicer header**, switch on **Title**, and enter `Fare` as the text.
    Then, move it to the top left of your report under the Parch slicer.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Be sure to rename the **Fare** value of **Fare param** to the same name as the
    variable that represents it in the model, namely, `Fare`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 13.20 – Renaming the Fare parameter value](img/file353.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 13.20 – Renaming the Fare parameter value
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Let’s add a slicer for the `Embarked` variable. As the `Embarked` variable is
    categorical (`0`, `1`, or `2`), you’ll create a disconnected table for it manually.
    So, click on the **Home** tab in the ribbon and then click on **Enter Data**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create the first column, **Embarked** (this name must correspond to that of
    the model’s variable), of the table and then add the values 0, 1, and 2 to it.
    Then, create a new column, **EmbarkedLabel**, and enter `Cherbourg`, `Queenstown`,
    and `Southampton`, corresponding to `0`, `1`, and `2`, respectively.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 13.21 – Entering data manually for Embarked](img/file354.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 13.21 – Entering data manually for Embarked
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Enter `PortEmbarkation` as the table name and then click **Load**.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Let’s now add a slicer for the `Embarked` variable. Click on an empty spot in
    the report canvas first. Then, click on the slicer visual in order to add a slicer
    to the report. Click first on the **EmbarkedLabel** field and then on the **Embarked**
    one (the order is important). Then, click on the downward-pointing arrow at the
    top right of the slicer to select the **Dropdown** slicer type. Also, click on
    its format options. Switch on **Single select** in the **Selection control** group,
    switch off **Slicer header**, switch on **Title**, and enter `Port of embarkation`
    as the text. Resize its bottom edge and move it under the Passenger class slicer.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now, click on an empty spot in the report canvas, then on **Python Visual**
    in the **Visualizations** field, and enable it when you’re prompted to do so.
    After that, move it to the center of your report.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Keeping it selected, click on all the three fields of the `models_df` table
    (**chunk_id**, **model_id**, and **model_str**).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Still keeping the Python visual selected, also click on all measures (the ones
    with a calculator icon) of all the parameters entered, and on the identifying
    fields of the categorical variables (the **Embarked** and **Sex** fields). Remember
    that the names of the measures must necessarily correspond to the names of the
    variables provided by the model for the report to work. You may need to enable
    the Python visual again after selecting the measures. You can do this by simply
    clicking on the yellow button labeled **Select to enable** in the Python visual.
    At the end of the selection, you should see all the names of the measures plus
    those of the fields of the `models_df` table inside the Python visual.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 13.22 – Selected measure names visible in the Python visual](img/file355.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 13.22 – Selected measure names visible in the Python visual
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Now, click on the Python visual’s **Format** tab, expand the **Title** area,
    edit the text with the **Prediction string**, and increase the font size to 28
    point.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Copy the code of the `05-deserialize-ml-models-in-python-visual.py` file into
    the `Chapter13\Python` folder and paste it into the Python visual script editor.
    Then, click on the **Run script** arrow icon in the top-right corner of the Python
    script editor. You’ll get a prediction (label and score) of whether a person described
    by the parameters you selected will survive.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 13.23 – Complete prediction simulation report for the Titanic model](img/file356.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.23 – Complete prediction simulation report for the Titanic model
  prefs: []
  type: TYPE_NORMAL
- en: Keep in mind that the same report can be made using models trained in R with
    the same methodology followed here. In fact, for completeness, we added to the
    repository the `Chapter13\R` folder containing the scripts corresponding to those
    used in this section, which is useful for obtaining the same results you got here.
    In these scripts, we trained the model using a predefined algorithm (**Random
    Forest**) and used the recently introduced **Tidymodels** framework, which makes
    use of the Tidyverse principles. For further details, refer to the references.
  prefs: []
  type: TYPE_NORMAL
- en: Wow! You've managed to create a dynamic predictive report in Power BI, something
    few developers can do!
  prefs: []
  type: TYPE_NORMAL
- en: Let's now see how to invoke the AI and machine learning services exposed by
    Microsoft in Power BI even if you don't have a Premium capability, an Embedded
    capability, or a PPU license.
  prefs: []
  type: TYPE_NORMAL
- en: Calling web services in Power Query
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Another way to interact with machine learning models within Power Query is
    to invoke web services. As you may already know, a machine learning model can
    be used to carry out the scoring of many observations in batch mode using a trained
    model (process described previously). Another option for being able to interact
    with a machine learning model is to deploy it to a web service so that it can
    be invoked via REST APIs. You''ve already learned how to work with external APIs
    in *Chapter 9*, *Calling External APIs to Enrich Your Data*. The following applies
    to external APIs:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Important Note**'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Remember that you can't consume external services via REST API calls from a
    Python or R visual because internet access is blocked for security reasons. Therefore,
    you can only consume these services in Power Query.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: As an example, in this section, you'll see how to invoke predictions from a
    released endpoint via **Azure Machine Learning** and how to use the services exposed
    by the **Azure Text Analytics** of cognitive services. You could use some M code
    in Power Query to access these services, although it's not exactly straightforward.
    Fortunately, SDKs are available, which make it much easier to access the exposed
    services. These SDKs are developed for Python, so our examples will be exclusively
    in Python.
  prefs: []
  type: TYPE_NORMAL
- en: Let's first look at how to interact with a model trained using Azure AutoML.
  prefs: []
  type: TYPE_NORMAL
- en: Using Azure AutoML models in Power Query
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this section, you'll first see how to train a machine learning model using
    the Azure AutoML GUI. After that, you will use the model released on an Azure
    container instance as a web service in Power BI.
  prefs: []
  type: TYPE_NORMAL
- en: Training a model using the Azure AutoML UI
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In order to use Azure AutoML, you must first have access to an Azure subscription
    (remember you can create a free account as shown at this link: [https://bit.ly/azure-free-account](https://bit.ly/azure-free-account)).
    After that, you need to create an **Azure Machine Learning Workspace** to train
    models via the different technologies that Azure provides. You can do this by
    simply following the steps in the paragraph at this link: [https://bit.ly/create-azureml-workspace](https://bit.ly/create-azureml-workspace).
    As soon as the workspace has been allocated, you can log in to **Azure Machine
    Learning Studio**, an environment in which all the machine learning assets you''ll
    be working with are best organized. Perform the following steps to log in to Azure
    ML Studio and to start an AutoML experiment:'
  prefs: []
  type: TYPE_NORMAL
- en: Go to [https://ml.azure.com/](https://ml.azure.com/).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You will be prompted to select an Azure subscription of yours and an Azure
    ML workspace to work on. Click on **Get started**. You will see something like
    this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 13.24 – Azure ML Studio portal](img/file357.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 13.24 – Azure ML Studio portal
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: First, you need to import the dataset with which to train the model. You will
    use the same dataset obtained from the missing value imputation done in the previous
    sections. Click on **Datasets** in the menu on the left and then on **Create dataset**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 13.25 – Creating a new dataset in Azure ML](img/file358.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 13.25 – Creating a new dataset in Azure ML
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You’ll be prompted for the dataset name and type. Enter `titanic-imputed` as
    the name and leave **Tabular** as the type.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 13.26 – Selecting your dataset name and type](img/file359.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 13.26 – Selecting your dataset name and type
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Then, click **Next**.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You have to upload the CSV file containing the Titanic disaster imputed data.
    So, click on **Upload**, then on **Upload files**, and finally select the `titanic-imputed.csv`
    file in the `Chapter13` folder via the **Open file** dialog. The file will be
    uploaded to the default Azure Blob storage (`workspaceblobstore`) created behind
    the scenes when instantiating a new Azure ML workspace. Click **Next**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: On the next page, you’ll get a preview of the dataset you’re importing. The
    engine automatically selects the best import options for you. But if there is
    something you’d like to change, you can do it on this page. In this case, everything
    is already OK, so click **Next**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: On the following page, you can change the imputed schema of the data you’re
    reading. In this case, leave the inferred type for each field, as the exported
    CSV file has numeric values with integer and decimal numbers. Then, click **Next**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A recap page will be shown. So, just click **Create** and your dataset will
    be added to Azure ML.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now you need to create a compute cluster to use for model training. Click on
    the **Compute** tab on the left menu, then click on **Compute clusters**, and
    finally click on **New**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 13.27 – Creating a new compute cluster](img/file360.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 13.27 – Creating a new compute cluster
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Then you can select your preferred location for the cluster and the virtual
    machine type and size to use for each cluster node. You can leave the default
    selection and click **Next**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Choose a name for your cluster (in our case, `cluster`), the minimum number
    of nodes (keep it at 0 to make it turn off automatically when not used), and the
    maximum number of nodes (set it to 2). Then, click on **Create** to allocate your
    compute cluster.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now, click on the **Automated ML** tab on the left menu and then on **New Automated
    ML run**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 13.28 – Creating a new AutoML experiment](img/file361.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 13.28 – Creating a new AutoML experiment
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: On the next page, select the **titanic-imputed** dataset and click **Next**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now you can configure the run by entering the name of the new experiment (a
    virtual folder) that will contain all the AutoML runs (we used `titanic` for the
    name), the machine learning target column (`Survived`, the one to predict), and
    the compute cluster to use to execute the AutoML runs (the `cluster` one created
    previously).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 13.29 – Configuring your AutoML run](img/file362.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 13.29 – Configuring your AutoML run
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You can then declare the machine learning experiment type you would like to
    run. In our case, it is a classification.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 13.30 – Setting up the AutoML task type](img/file363.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 13.30 – Setting up the AutoML task type
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: By clicking on **View additional configuration settings**, you can choose the
    primary metric to use in your experiment. Select the **AUC weighted** one and
    then click **Save**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: By clicking on **View featurization settings**, you can enable the auto-featurization
    option that AutoML provides. By default, it’s switched on. You can also choose
    the feature type for each column and the missing values impute strategy for each
    of them (the strategies are the naïve ones). Keep everything on **Auto** and then
    click **Save**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You can now click **Finish** to start your AutoML experiment. You’ll be redirected
    to the **Run** page, and after a while, you‘ll see your experiment running.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 13.31 – Your AutoML experiment running](img/file364.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 13.31 – Your AutoML experiment running
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: After about 30 minutes, the experiment should end. Click on the **Models** tab
    on the **AutoML Run** page and you will see the training pipelines according to
    the best-performing ones.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 13.32 – Best performing pipelines found by AutoML](img/file365.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 13.32 – Best performing pipelines found by AutoML
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: For the best-performing model (**VotingEnsemble**), the *Explainability Dashboard*
    is also automatically generated, which you can access by clicking on **View explanation**.
    For further details on this, check out the references. Now, click on the **VotingEnsemble**
    link to go to the specific run that trained the model using that pipeline. Then,
    click on the **Deploy** button.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 13.33 – Deploying the best model to a web service](img/file366.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 13.33 – Deploying the best model to a web service
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: A new form will appear on the right asking for information about the model to
    deploy on a web service. Just give the model endpoint a name (`titanic-model`),
    select **Azure Container Instance** as the compute type, as this will not be a
    production environment, and activate the **Enable authentication** feature. In
    the case of a production environment, *Azure Kubernetes Services* (*AKS*) is the
    best choice. Then, click on **Deploy** and wait for the model to be deployed.
    When the **Deploy status** field changes to **Succeeded** in the **Model** summary,
    click on the **titanic-model** endpoint link.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The endpoint **Details** page contains all the information about the service.
    After at least 10 minutes of deployment, it must be in a healthy deployment state
    in order to be used. You can click on the **Test** tab to test your endpoint by
    providing it with test input data. The tab we are most interested in is **Consume**,
    in which the coordinates (REST endpoint URL and authentication key) are indicated
    to invoke the REST API from an external system. Also, you can directly copy the
    code snippet that allows you to consume the service in Python in the **Consumption
    option** section. We will use a variation of this code to score test observations
    in Power Query.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: At this point, the model is ready on a web service to be consumed via REST APIs.
    Let’s now use it in Power Query.
  prefs: []
  type: TYPE_NORMAL
- en: Consuming an Azure ML deployed model in Power BI
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Using a variation of the Python code proposed by the **Endpoint Consume** tab
    on Azure ML Studio, we created a function that accepts as parameters the endpoint
    URL, the API key, and a dataframe containing the observations to be scored. In
    the output, we get a dataframe containing just the `predicted_label` column with
    the scoring of each observation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the steps to get the predictions of a test dataset from a model trained
    via Azure AutoML and deployed as a web service on an Azure container instance:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on **Get Data**, select **Text/CSV**, and then click on **Connect**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the `titanic-test.csv` file in the `Chapter13` folder and then click
    **Open**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You’ll see a preview of the test data. Click **Transform Data**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Transform** on the ribbon and then **Run Python script**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Enter the script you can find in the `06-use-azure-ml-web-service-in-power-bi.py`
    file in the `Chapter13\Python` folder. Remember to edit the endpoint URL and key
    accordingly.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We are only interested in the `scored_df` dataframe. So, click on its **Table**
    value.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You'll see a preview of the test dataset with an additional column – `predicted_label`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Home** on the ribbon and then click **Close & Apply**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazing! You were able to consume a model trained on Azure Machine Learning
    and deployed it to an Azure container instance without having either a PPU license
    or a Premium capacity.
  prefs: []
  type: TYPE_NORMAL
- en: Using cognitive services in Power Query
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The Azure cognitive services **Text Analytics API** is a service that provides
    Natural Language Processing (NLP) functions for text mining and analysis. Features
    made available include sentiment analysis, opinion mining, key phrase extraction,
    language detection, and named entity recognition.
  prefs: []
  type: TYPE_NORMAL
- en: First, you need to deploy the text analytics resource via the Azure portal.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring text analytics
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'You must have an Azure subscription to use these services. Then you need to
    create a text analytics resource by following these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Go to the Azure portal ([https://portal.azure.com/](https://portal.azure.com/))
    and click on the **Create a resource** plus icon.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Start entering the text string in the search textbox and the **Text Analytics**
    option will appear. Click on it. Then, click on the **Create** button on the **Text
    Analytics** page.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Forget about selecting the **Custom question answering** option, and click on
    **Continue to create your resource** instead.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: On the **Create Text Analytics** page, select the region you prefer and give
    a name to the service (in our case, `textanalytics555`; you can use a unique name
    of your choosing). Assign your resource to a new resource group with the name
    `text-analytics`. Then, select the **Free F0** pricing tier, check the **Responsible
    AI Notice** option, and click on **Review + create**. Then, click **Create** on
    the next page.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once the deployment of the resource is complete, click on **Go to resource**
    and click on the **API Key** link on the next page. Then, take note of the details
    of **KEY 1** (you can click on the **Copy to clipboard** icon on its right) and
    the endpoint URL. You’ll use this information in your Python code.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Your resource is now ready to be used via the dedicated Python SDK.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring your Python environment and Windows
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In order to consume text analytics, you must first install the **Microsoft
    Azure Text Analytics Client Library for Python** by following these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Open your Anaconda Prompt.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Switch to your PyCaret environment by entering this command: `conda activate
    pycaret_env`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Install the client library by entering this command: `pip install azure-ai-textanalytics==5.1.0`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'After that, to avoid the *ssl module in Python is not available* error in Windows
    10, you need to add the `pycaret_env\Library\bin` path to the Windows environment
    `PATH` variable. These are the steps to do it:'
  prefs: []
  type: TYPE_NORMAL
- en: Click on the Windows **Start** icon in the bottom-left corner of your screen
    and start digitizing the x `variable`.string This will search for all Windows
    options that have the string variable in their name. Then, click on **Edit environment
    variables for your account**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the **Environment Variables** windows, double-click on the **Path** variable
    under **User variables for <your-user>** (if you installed Miniconda for all users,
    you need to change the **Path** system variable). In the **Edit environment variable**
    dialog that will appear, click on the **New** button and add the path `C:\<your-path>\miniconda3\envs\pycaret_env\Library\bin`.
    Then, click **OK** on all the windows.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You need to restart your system to make the change effective.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You are now ready to be able to consume the service from Power Query.
  prefs: []
  type: TYPE_NORMAL
- en: Consuming the Text Analytics API in Power BI
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In this section, we will show you how to do sentiment analysis thanks to text
    analytics on the fictional company *Fabrikam Fiber*. It provides cable television
    and related services in the United States, allowing users to enter comments on
    their website. Your goal is to define for each comment the degree of positivity,
    neutrality, and negativity.
  prefs: []
  type: TYPE_NORMAL
- en: Basically, once a client has been authenticated with a URL and key, you can
    easily carry out a sentiment analysis thanks to the `analyze_sentiment()` method
    without knowing any NLP basis. Keep in mind that the free tier of text analytics
    is limited to processing only 10 documents (in our case, comments) at a time.
    For this reason, the code we built consists of grouping the comments in groups
    of 10 and invoking the API for each group.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s see how to do that:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on **Get Data**, select **Text/CSV**, and then click on **Connect**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the `FabrikamComments.csv` file in the `Chapter13` folder and click **Open**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You’ll see a preview of the Fabrikam dataset. Then, click **Transform Data**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Transform** on the ribbon, followed by **Run Python script**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Enter the script you can find in the `07-use-text-analytics-in-power-bi.py`
    file in the `Chapter13\Python` folder. Remember to appropriately replace the service
    URL and its key that you previously copied into the Azure portal.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We are only interested in the `sentiment_enriched_df` dataframe. So, click on
    its **Table** value.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You''ll see a preview of the Fabrikam dataset enriched with the following additional
    columns: `comment_sentiment`, `overall_positive_score`, `overall_neutral_score`,
    and `overall_negative_score`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 13.34 – Additional sentiment analysis columns](img/file367.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 13.34 – Additional sentiment analysis columns
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click **Home** on the ribbon and then click **Close & Apply**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: That’s amazing! Thanks to the Python library `azure.ai.textanalytics`, you were
    able, in a few lines of code, to perform sentiment analysis in a very simple way.
    With the same ease, you can also use in Power BI the other services that cognitive
    services provide thanks to other Python SDKs.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this chapter, you learned how Power BI interacts with Microsoft AI services
    by default through data flow features. You also learned that by using AutoML platforms,
    you can get around the licensing problem (PPU license or Premium capacity) that
    Power BI needs to interface with Microsoft AI services. You used both an on-premises
    AutoML solution (PyCaret) and Azure AutoML on the cloud to solve a binary classification
    problem. You also used cognitive services' text analytics to do some sentiment
    analysis directly using a Python SDK.
  prefs: []
  type: TYPE_NORMAL
- en: You've learned that enrichment via AI mostly happens in Power Query (which allows
    access to the internet), although you've seen a case where it may be convenient
    to use a machine learning model directly within a Python visual.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, you will see how to implement data exploration of your
    dataset in Power BI.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For additional reading, check out the following books and articles:'
  prefs: []
  type: TYPE_NORMAL
- en: '*AI with data flows* ([https://docs.microsoft.com/en-us/power-bi/transform-model/dataflows/dataflows-machine-learning-integration](https://docs.microsoft.com/en-us/power-bi/transform-model/dataflows/dataflows-machine-learning-integration))'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*A Review of Azure Automated Machine Learning (AutoML)* ([https://medium.com/microsoftazure/a-review-of-azure-automated-machine-learning-automl-5d2f98512406](https://medium.com/microsoftazure/a-review-of-azure-automated-machine-learning-automl-5d2f98512406))'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Automated Machine Learning with Microsoft Azure, by Dennis Michael Sawyers,
    Packt Publishing* ([https://www.amazon.com/Automated-Machine-Learning-Microsoft-Azure/dp/1800565313/](https://www.amazon.com/Automated-Machine-Learning-Microsoft-Azure/dp/1800565313/))'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*A Gentle Introduction to Concept Drift in Machine Learning* ([https://machinelearningmastery.com/gentle-introduction-concept-drift-machine-learning/)](https://machinelearningmastery.com/gentle-introduction-concept-drift-machine-learning/))'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Machine Learning Basics with the K-Nearest Neighbors Algorithm* ([https://towardsdatascience.com/machine-learning-basics-with-the-k-nearest-neighbors-algorithm-6a6e71d01761](https://towardsdatascience.com/machine-learning-basics-with-the-k-nearest-neighbors-algorithm-6a6e71d01761))'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Python’s «predict_proba» Doesn’t Actually Predict Probabilities (and How to
    Fix It)* ([https://towardsdatascience.com/pythons-predict-proba-doesn-t-actually-predict-probabilities-and-how-to-fix-it-f582c21d63fc](https://towardsdatascience.com/pythons-predict-proba-doesn-t-actually-predict-probabilities-and-how-to-fix-it-f582c21d63fc))'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Use the Interpretability Package to Explain ML Models and Predictions in Python*
    ([https://docs.microsoft.com/en-us/azure/machine-learning/how-to-machine-learning-interpretability-aml](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-machine-learning-interpretability-aml))'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Get Started with Tidymodels* ([https://www.tidymodels.org/start/ https://www.tidymodels.org/start/](https://www.tidymodels.org/start/))'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
