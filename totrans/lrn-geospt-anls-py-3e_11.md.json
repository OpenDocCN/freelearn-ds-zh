["```py\nNDVI = (Infrared – Red) / (Infrared + Red)\n```", "```py\nimport gdal\nfrom osgeo import gdal\nfrom osgeo import gdal_array\nfrom osgeo import ogr\ntry:\n import Image\n import ImageDraw\nexcept ImportError:\n from PIL import Image, ImageDraw\n```", "```py\ndef imageToArray(i):\n    \"\"\"\n    Converts a Python Imaging Library\n    array to a gdal_array image.\n    \"\"\"\n    a = gdal_array.numpy.fromstring(i.tobytes(), 'b')\n    a.shape = i.im.size[1], i.im.size[0]\n    return a\n```", "```py\ndef world2Pixel(geoMatrix, x, y):\n \"\"\"\n Uses a gdal geomatrix (gdal.GetGeoTransform())\n to calculate the pixel location of a\n geospatial coordinate\n \"\"\"\n ulX = geoMatrix[0]\n ulY = geoMatrix[3]\n xDist = geoMatrix[1]\n yDist = geoMatrix[5]\n rtnX = geoMatrix[2]\n rtnY = geoMatrix[4]\n pixel = int((x - ulX) / xDist)\n line = int((ulY - y) / abs(yDist))\n return (pixel, line)\n```", "```py\ndef copy_geo(array, prototype=None, xoffset=0, yoffset=0):\n \"\"\"Copy geotransfrom from prototype dataset to array but account\n for x, y offset of clipped array.\"\"\"\n ds = gdal_array.OpenArray(array)\n prototype = gdal.Open(prototype)\n gdal_array.CopyDatasetInfo(prototype, ds,\n xoff=xoffset, yoff=yoffset)\n return ds\n```", "```py\n# Multispectral image used\n# to create the NDVI. Must\n# have red and infrared\n# bands\nsource = \"farm.tif\"\n\n# Output geotiff file name\ntarget = \"ndvi.tif\"\n\n# Load the source data as a gdal_array array\nsrcArray = gdal_array.LoadFile(source)\n\n# Also load as a gdal image to\n# get geotransform info\nsrcImage = gdal.Open(source)\ngeoTrans = srcImage.GetGeoTransform()\n\n# Red and infrared (or near infrared) bands\nr = srcArray[1]\nir = srcArray[2]\n```", "```py\n# Clip a field out of the bands using a\n# field boundary shapefile\n\n# Create an OGR layer from a Field boundary shapefile\nfield = ogr.Open(\"field.shp\")\n# Must define a \"layer\" to keep OGR happy\nlyr = field.GetLayer(\"field\")\n```", "```py\n# Only one polygon in this shapefile\npoly = lyr.GetNextFeature()\n```", "```py\n# Convert the layer extent to image pixel coordinates\nminX, maxX, minY, maxY = lyr.GetExtent()\nulX, ulY = world2Pixel(geoTrans, minX, maxY)\nlrX, lrY = world2Pixel(geoTrans, maxX, minY)\n```", "```py\n# Calculate the pixel size of the new image\npxWidth = int(lrX - ulX)\npxHeight = int(lrY - ulY)\n```", "```py\n# Create a blank image of the correct size\n# that will serve as our mask\nclipped = gdal_array.numpy.zeros((3, pxHeight, pxWidth),\n gdal_array.numpy.uint8)\n```", "```py\n# Clip red and infrared to new bounds.\nrClip = r[ulY:lrY, ulX:lrX]\nirClip = ir[ulY:lrY, ulX:lrX]\n```", "```py\n# Create a new geomatrix for the image\ngeoTrans = list(geoTrans)\ngeoTrans[0] = minX\ngeoTrans[3] = maxY\n```", "```py\n# Map points to pixels for drawing\n# the field boundary on a blank\n# 8-bit, black and white, mask image.\npoints = []\npixels = []\n# Grab the polygon geometry\ngeom = poly.GetGeometryRef()\npts = geom.GetGeometryRef(0)\n```", "```py\n# Loop through geometry and turn\n# the points into an easy-to-manage\n# Python list\nfor p in range(pts.GetPointCount()):\n    points.append((pts.GetX(p), pts.GetY(p)))\n```", "```py\n# Loop through the points and map to pixels.\n# Append the pixels to a pixel list\nfor p in points:\n    pixels.append(world2Pixel(geoTrans, p[0], p[1]))\n```", "```py\n# Create the raster polygon image as a black and white 'L' mode\n# and filled as white. White=1\nrasterPoly = Image.new(\"L\", (pxWidth, pxHeight), 1)\n```", "```py\n# Create a PIL drawing object\nrasterize = ImageDraw.Draw(rasterPoly)\n\n# Dump the pixels to the image\n# as a polygon. Black=0\nrasterize.polygon(pixels, 0)\n```", "```py\n# Hand the image back to gdal/gdal_array\n# so we can use it as an array mask\nmask = imageToArray(rasterPoly)\n```", "```py\n# Clip the red band using the mask\nrClip = gdal_array.numpy.choose(mask,\n (rClip, 0)).astype(gdal_array.numpy.uint8)\n\n# Clip the infrared band using the mask\nirClip = gdal_array.numpy.choose(mask,\n (irClip, 0)).astype(gdal_array.numpy.uint8)\n```", "```py\n# We don't care about numpy warnings\n# due to NaN values from clipping\ngdal_array.numpy.seterr(all=\"ignore\")\n```", "```py\n# NDVI equation: (infrared - red) / (infrared + red)\n# *1.0 converts values to floats,\n# +1.0 prevents ZeroDivisionErrors\nndvi = 1.0 * ((irClip - rClip) / (irClip + rClip + 1.0))\n```", "```py\n# Convert any NaN values to 0 from the final product\nndvi = gdal_array.numpy.nan_to_num(ndvi)\n```", "```py\n# Save the ndvi as a GeoTIFF and copy/adjust \n# the georeferencing info\ngtiff = gdal.GetDriverByName( 'GTiff' )\ngtiff.CreateCopy(target, copy_geo(ndvi, prototype=source, xoffset=ulX, yoffset=ulY))\ngtiff = None\n```", "```py\nimport gdal_array as gd\nimport operator\nfrom functools import reduce\n```", "```py\ndef histogram(a, bins=list(range(256))):\n \"\"\"\n Histogram function for multi-dimensional array.\n a = array\n bins = range of numbers to match\n \"\"\"\n # Flatten, sort, then split our arrays for the histogram.\n fa = a.flat\n n = gd.numpy.searchsorted(gd.numpy.sort(fa), bins)\n n = gd.numpy.concatenate([n, [len(fa)]])\n hist = n[1:]-n[:-1]\n return hist\n```", "```py\ndef stretch(a):\n \"\"\"\n Performs a histogram stretch on a gdal_array array image.\n \"\"\"\n hist = histogram(a)\n lut = []\n for b in range(0, len(hist), 256):\n # step size – create equal interval bins.\n step = reduce(operator.add, hist[b:b+256]) / 255\n # create equalization lookup table\n n = 0\n for i in range(256):\n lut.append(n / step)\n n = n + hist[i+b]\n gd.numpy.take(lut, a, out=a)\n return a\n```", "```py\n# NDVI output from ndvi script\nsource = \"ndvi.tif\"\n\n# Target file name for classified\n# image image\ntarget = \"ndvi_color.tif\"\n\n# Load the image into an array\nndvi = gd.LoadFile(source).astype(gd.numpy.uint8)\n```", "```py\n# Peform a histogram stretch so we are able to\n# use all of the classes\nndvi = stretch(ndvi)\n\n# Create a blank 3-band image the same size as the ndvi\nrgb = gd.numpy.zeros((3, len(ndvi), len(ndvi[0])), gd.numpy.uint8)\n```", "```py\n# Class list with ndvi upper range values.\n# Note the lower and upper values are listed on the ends\nclasses = [58, 73, 110, 147, 184, 220, 255]\n\n# Color look-up table (lut)\n# The lut must match the number of classes\n# Specified as R, G, B tuples from dark brown to dark green\nlut = [[120, 69, 25], [255, 178, 74], [255, 237, 166], [173, 232, 94],\n [135, 181, 64], [3, 156, 0], [1, 100, 0]]\n\n# Starting value of the first class\nstart = 1\n```", "```py\n# For each class value range, grab values within range,\n# then filter values through the mask.\nfor i in range(len(classes)):\n mask = gd.numpy.logical_and(start <= ndvi,\n ndvi <= classes[i])\n for j in range(len(lut[i])):\n     rgb[j] = gd.numpy.choose(mask, (rgb[j], lut[i][j]))\n     start = classes[i]+1\n```", "```py\n# Save a geotiff image of the colorized ndvi.\noutput=gd.SaveArray(rgb, target, format=\"GTiff\", prototype=source)\noutput = None\n```", "```py\nimport numpy as np\nfrom linecache import getline\n```", "```py\ndef floodFill(c, r, mask):\n \"\"\"\n Crawls a mask array containing\n only 1 and 0 values from the\n starting point (c=column,\n r=row - a.k.a. x, y) and returns\n an array with all 1 values\n connected to the starting cell.\n This algorithm performs a 4-way\n check non-recursively.\n \"\"\"\n```", "```py\n # cells already filled\n filled = set()\n # cells to fill\n fill = set()\n fill.add((c, r))\n width = mask.shape[1]-1\n height = mask.shape[0]-1\n```", "```py\n # Our output inundation array\n flood = np.zeros_like(mask, dtype=np.int8)\n```", "```py\n # Loop through and modify the cells which\n # need to be checked.\n while fill:\n   # Grab a cell\n   x, y = fill.pop()\n```", "```py\n   if y == height or x == width or x < 0 or y < 0:\n    # Don't fill\n    continue\n```", "```py\n   if mask[y][x] == 1:\n    # Do fill\n    flood[y][x] = 1\n   filled.add((x, y))\n```", "```py\n   # Check neighbors for 1 values\n   west = (x-1, y)\n   east = (x+1, y)\n   north = (x, y-1)\n   south = (x, y+1)\n   if west not in filled:\n     fill.add(west)\n   if east not in filled:\n     fill.add(east)\n   if north not in filled:\n     fill.add(north)\n   if south not in filled:\n     fill.add(south)\n return flood\n```", "```py\nsource = \"terrain.asc\"\ntarget = \"flood.asc\"\n```", "```py\nprint(\"Opening image...\")\nimg = np.loadtxt(source, skiprows=6)\nprint(\"Image opened\")\n```", "```py\n# Mask elevations lower than 70 meters.\nwet = np.where(img < 70, 1, 0)\nprint(\"Image masked\")\n```", "```py\n# Parse the header using a loop and\n# the built-in linecache module\nhdr = [getline(source, i) for i in range(1, 7)]\nvalues = [float(h.split(\" \")[-1].strip()) for h in hdr]\ncols, rows, lx, ly, cell, nd = values\nxres = cell\nyres = cell * -1\n```", "```py\n# Starting point for the\n# flood inundation in pixel coordinates\nsx = 2582\nsy = 2057\n```", "```py\nprint(\"Beginning flood fill\")\nfld = floodFill(sx, sy, wet)\nprint(\"Finished flood fill\")\n\nheader = \"\"\nfor i in range(6):\n header += hdr[i]\n```", "```py\nprint(\"Saving grid\")\n# Open the output file, add the hdr, save the array\nwith open(target, \"wb\") as f:\n f.write(bytes(header, 'UTF-8'))\n np.savetxt(f, fld, fmt=\"%1i\")\nprint(\"Done!\")\n```", "```py\nimport gdal_array as gd\ntry:\n import Image\nexcept ImportError:\n from PIL import Image\n```", "```py\nrelief = \"relief.asc\"\ndem = \"dem.asc\"\ntarget = \"hillshade.tif\"\n```", "```py\n# Load the relief as the background image\nbg = gd.numpy.loadtxt(relief, skiprows=6)\n```", "```py\n# Load the DEM into a numpy array as the foreground image\nfg = gd.numpy.loadtxt(dem, skiprows=6)[:-2, :-2]\n```", "```py\n# Create a blank 3-band image to colorize the DEM\nrgb = gd.numpy.zeros((3, len(fg), len(fg[0])), gd.numpy.uint8)\n\n# Class list with DEM upper elevation range values.\nclasses = [356, 649, 942, 1235, 1528,\n 1821, 2114, 2300, 2700]\n\n# Color look-up table (lut)\n# The lut must match the number of classes.\n# Specified as R, G, B tuples\nlut = [[63, 159, 152], [96, 235, 155], [100, 246, 174],\n [248, 251, 155], [246, 190, 39], [242, 155, 39],\n [165, 84, 26], [236, 119, 83], [203, 203, 203]]\n\n# Starting elevation value of the first class\nstart = 1\n```", "```py\n# Process all classes.\nfor i in range(len(classes)):\n mask = gd.numpy.logical_and(start <= fg,\n fg <= classes[i])\n for j in range(len(lut[i])):\n rgb[j] = gd.numpy.choose(mask, (rgb[j], lut[i][j]))\n start = classes[i]+1\n```", "```py\n# Convert the shaded relief to a PIL image\nim1 = Image.fromarray(bg).convert('RGB')\n\n# Convert the colorized DEM to a PIL image.\n# We must transpose it from the Numpy row, col order\n# to the PIL col, row order (width, height).\nim2 = Image.fromarray(rgb.transpose(1, 2, 0)).convert('RGB')\n```", "```py\n# Blend the two images with a 40% alpha\nhillshade = Image.blend(im1, im2, .4)\n\n# Save the hillshade\nhillshade.save(target)\n```", "```py\nimport numpy as np\n\n# Width and height\n# of grids\nw = 5\nh = 5\n```", "```py\n# Start location:\n# Lower left of grid\nstart = (h-1, 0)\n\n# End location:\n# Top right of grid\ndx = w-1\ndy = 0\n```", "```py\n# Blank grid\nblank = np.zeros((w, h))\n```", "```py\n# Distance grid\ndist = np.zeros(blank.shape, dtype=np.int8)\n\n# Calculate distance for all cells\nfor y, x in np.ndindex(blank.shape):\n dist[y][x] = abs((dx-x)+(dy-y))\n```", "```py\n# \"Terrain\" is a random value between 1-16.\n# Add to the distance grid to calculate\n# The cost of moving to a cell\ncost = np.random.randint(1, 16, (w, h)) + dist\n\nprint(\"COST GRID (Value + Distance)\\n{}\\n\".format(cost))\n```", "```py\n# Our A* search algorithm\ndef astar(start, end, h, g):\n    closed_set = set()\n    open_set = set()\n    path = set()\n```", "```py\n    open_set.add(start)\n    while open_set:\n        cur = open_set.pop()\n        if cur == end:\n            return path\n        closed_set.add(cur)\n        path.add(cur)\n        options = []\n        y1 = cur[0]\n        x1 = cur[1]\n```", "```py\n        if y1 > 0:\n            options.append((y1-1, x1))\n        if y1 < h.shape[0]-1:\n            options.append((y1+1, x1))\n        if x1 > 0:\n            options.append((y1, x1-1))\n        if x1 < h.shape[1]-1:\n            options.append((y1, x1+1))\n        if end in options:\n            return path\n        best = options[0]\n        closed_set.add(options[0])\n```", "```py\n        for i in range(1, len(options)):\n            option = options[i]\n            if option in closed_set:\n                continue\n            elif h[option] <= h[best]:\n                best = option\n                closed_set.add(option)\n            elif g[option] < g[best]:\n                best = option\n                closed_set.add(option)\n            else:\n                closed_set.add(option)\n        print(best, \", \", h[best], \", \", g[best])\n        open_set.add(best)\n    return []\n```", "```py\n# Find the path\npath = astar(start, (dy, dx), cost, dist)\nprint()\n```", "```py\n# Create and populate the path grid\npath_grid = np.zeros(cost.shape, dtype=np.uint8)\nfor y, x in path:\n path_grid[y][x] = 1\npath_grid[dy][dx] = 1\n\nprint(\"PATH GRID: 1=path\")\nprint(path_grid)\n```", "```py\nCOST GRID (Value + Distance)\n[[13 10 5 15 9]\n [15 13 16 5 16]\n [17 8 9 9 17]\n [ 4 1 11 6 12]\n [ 2 7 7 11 8]]\n\n(Y,X), HEURISTIC, DISTANCE\n(3, 0) , 4 , 1\n(3, 1) , 1 , 0\n(2, 1) , 8 , 1\n(2, 2) , 9 , 0\n(2, 3) , 9 , 1\n(1, 3) , 5 , 0\n(0, 3) , 15 , 1\n\nPATH GRID: 1=path\n[[0 0 0 1 1]\n [0 0 0 1 0]\n [0 1 1 1 0]\n [1 1 0 0 0]\n [1 0 0 0 0]]\n```", "```py\nimport numpy as np\nimport math\nfrom linecache import getline\nimport pickle\n```", "```py\n# Our terrain data\nsource = \"dem.asc\"\n\n# Output file name for the path raster\ntarget = \"path.asc\"\n```", "```py\nprint(\"Opening %s...\" % source)\ncost = np.loadtxt(source, skiprows=6)\nprint(\"Opened %s.\" % source)\n```", "```py\n# Parse the header\nhdr = [getline(source, i) for i in range(1, 7)]\nvalues = [float(ln.split(\" \")[-1].strip()) for ln in hdr]\ncols, rows, lx, ly, cell, nd = values\n```", "```py\n# Starting column, row\nsx = 1006\nsy = 954\n\n# Ending column, row\ndx = 303\ndy = 109\n```", "```py\ndef e_dist(p1, p2):\n \"\"\"\n Takes two points and returns\n the Euclidian distance\n \"\"\"\n x1, y1 = p1\n x2, y2 = p2\n distance = math.sqrt((x1-x2)**2+(y1-y2)**2)\n return int(distance)\n```", "```py\ndef weighted_score(cur, node, h, start, end):\n \"\"\"\n Provides a weighted score by comparing the\n current node with a neighboring node. Loosely\n based on the Nisson Score concept: f=g+h\n In this case, the \"h\" value, or \"heuristic\",\n is the elevation value of each node.\n \"\"\"\n```", "```py\n score = 0\n # current node elevation\n cur_h = h[cur]\n # current node distance from end\n cur_g = e_dist(cur, end)\n # current node distance from\n cur_d = e_dist(cur, start)\n```", "```py\n # neighbor node elevation\n node_h = h[node]\n # neighbor node distance from end\n node_g = e_dist(node, end)\n # neighbor node distance from start\n node_d = e_dist(node, start)\n # Compare values with the highest\n # weight given to terrain followed\n # by progress towards the goal.\n if node_h < cur_h:\n score += cur_h-node_h\n if node_g < cur_g:\n score += 10\n if node_d > cur_d:\n score += 10\n return score\n```", "```py\ndef astar(start, end, h):\n \"\"\"\n A-Star (or A*) search algorithm.\n Moves through nodes in a network\n (or grid), scores each node's\n neighbors, and goes to the node\n with the best score until it finds\n the end. A* is an evolved Dijkstra\n algorithm.\n \"\"\"\n```", "```py\n # Closed set of nodes to avoid\n closed_set = set()\n # Open set of nodes to evaluate\n open_set = set()\n # Output set of path nodes\n path = set()\n```", "```py\n # Add the starting point to\n # to begin processing\n open_set.add(start)\n while open_set:\n # Grab the next node\n cur = open_set.pop()\n```", "```py\n # Return if we're at the end\n if cur == end:\n return path\n```", "```py\n # Close off this node to future\n # processing\n closed_set.add(cur)\n # The current node is always\n # a path node by definition\n path.add(cur)\n```", "```py\n # List to hold neighboring\n # nodes for processing\n options = []\n # Grab all of the neighbors\n y1 = cur[0]\n x1 = cur[1]\n if y1 > 0:\n options.append((y1-1, x1))\n if y1 < h.shape[0]-1:\n options.append((y1+1, x1))\n if x1 > 0:\n options.append((y1, x1-1))\n if x1 < h.shape[1]-1:\n options.append((y1, x1+1))\n if x1 > 0 and y1 > 0:\n options.append((y1-1, x1-1))\n if y1 < h.shape[0]-1 and x1 < h.shape[1]-1:\n options.append((y1+1, x1+1))\n if y1 < h.shape[0]-1 and x1 > 0:\n options.append((y1+1, x1-1))\n if y1 > 0 and x1 < h.shape[1]-1:\n options.append((y1-1, x1+1))\n```", "```py\n # If the end is a neighbor, return\n if end in options:\n return path\n```", "```py\n # Store the best known node\n best = options[0]\n # Begin scoring neighbors\n best_score = weighted_score(cur, best, h, start, end)\n # process the other 7 neighbors\n for i in range(1, len(options)):\n option = options[i]\n # Make sure the node is new\n if option in closed_set:\n continue\n else:\n # Score the option and compare \n # it to the best known\n option_score = weighted_score(cur, option, \n h, start, end)\n if option_score > best_score:\n best = option\n best_score = option_score\n else:\n # If the node isn't better seal it off\n closed_set.add(option)\n # Uncomment this print statement to watch\n # the path develop in real time:\n # print(best, e_dist(best, end))\n # Add the best node to the open set\n open_set.add(best)\nreturn []\n```", "```py\nprint(\"Searching for path...\")\np = astar((sy, sx), (dy, dx), cost)\nprint(\"Path found.\")\nprint(\"Creating path grid...\")\npath = np.zeros(cost.shape)\nprint(\"Plotting path...\")\nfor y, x in p:\n path[y][x] = 1\npath[dy][dx] = 1\nprint(\"Path plotted.\")\n```", "```py\nprint(\"Saving %s...\" % target)\nheader = \"\"\nfor i in range(6):\n header += hdr[i]\n\n# Open the output file, add the hdr, save the array\nwith open(target, \"wb\") as f:\n f.write(bytes(header, 'UTF-8'))\n np.savetxt(f, path, fmt=\"%4i\")\n```", "```py\nprint(\"Saving path data...\")\nwith open(\"path.p\", \"wb\") as pathFile:\n pickle.dump(p, pathFile)\nprint(\"Done!\")\n```", "```py\nimport pickle\nfrom linecache import getline\nimport shapefile\n```", "```py\ndef pix2coord(gt,x,y):\n geotransform = gt\n ox = gt[2]\n oy = gt[3]\n pw = gt[4]\n ph = gt[4]\n cx = ox + pw * x + (pw/2)\n cy = oy + pw * y + (ph/2)\n return cx, cy\n```", "```py\nwith open(\"path.p\", \"rb\") as pathFile:\n path = pickle.load(pathFile)\n```", "```py\nhdr = [getline(\"path.asc\", i) for i in range(1, 7)]\ngt = [float(ln.split(\" \")[-1].strip()) for ln in hdr]\n```", "```py\ncoords = []\n```", "```py\nfor y,x in path:\n coords.append(pix2coord(gt,x,y))\n```", "```py\nwith shapefile.Writer(\"path\", shapeType=shapefile.POLYLINE) as w:\n w.field(\"NAME\")\n w.record(\"LeastCostPath\")\n w.line([coords])\n```", "```py\npip install rasterio\npip install rio-l8qa\n```", "```py\nimport glob\nimport os\nimport rasterio\nfrom l8qa.qa import write_cloud_mask\n```", "```py\n# Directory containing landsat data\nlandsat_dir = \"l8\"\n```", "```py\nsrc_qa = glob.glob(os.path.join(landsat_dir, '*QA*'))[0]\n```", "```py\nwith rasterio.open(src_qa) as qa_raster:\n profile = qa_raster.profile\n profile.update(nodata=0)\n write_cloud_mask(qa_raster.read(1), profile, 'cloudmask.tif')\n```", "```py\nimport networkx as nx\nimport math\nfrom itertools import tee\nimport shapefile\nimport os\n```", "```py\nsavedir = \".\"\n```", "```py\ndef haversine(n0, n1):\n x1, y1 = n0\n x2, y2 = n1\n x_dist = math.radians(x1 - x2)\n y_dist = math.radians(y1 - y2)\n y1_rad = math.radians(y1)\n y2_rad = math.radians(y2)\n a = math.sin(y_dist/2)**2 + math.sin(x_dist/2)**2 \\\n * math.cos(y1_rad) * math.cos(y2_rad)\n c = 2 * math.asin(math.sqrt(a))\n distance = c * 6371\n return distance\n```", "```py\ndef pairwise(iterable):\n \"\"\"Return an iterable in tuples of two\n s -> (s0,s1), (s1,s2), (s2, s3), ...\"\"\"\n a, b = tee(iterable)\n next(b, None)\n return zip(a, b)\n```", "```py\nshp = \"road_network.shp\"\n```", "```py\nG = nx.DiGraph()\nr = shapefile.Reader(shp)\nfor s in r.shapes():\n for p1, p2 in pairwise(s.points):\n G.add_edge(tuple(p1), tuple(p2))\n```", "```py\nsg = list(nx.connected_component_subgraphs(G.to_undirected()))[0]\n```", "```py\nr = shapefile.Reader(\"start_end\")\nstart = r.shape(0).points[0]\nend = r.shape(1).points[0]\n```", "```py\nfor n0, n1 in sg.edges_iter():\n dist = haversine(n0, n1)\n sg.edge[n0][n1][\"dist\"] = dist\n```", "```py\nnn_start = None\nnn_end = None\nstart_delta = float(\"inf\")\nend_delta = float(\"inf\")\nfor n in sg.nodes():\n s_dist = haversine(start, n)\n e_dist = haversine(end, n)\n if s_dist < start_delta:\n nn_start = n\n start_delta = s_dist\n if e_dist < end_delta:\n nn_end = n \n end_delta = e_dist\n```", "```py\npath = nx.shortest_path(sg, source=nn_start, target=nn_end, weight=\"dist\")\n```", "```py\nw = shapefile.Writer(shapefile.POLYLINE)\nw.field(\"NAME\", \"C\", 40)\nw.line(parts=[[list(p) for p in path]])\nw.record(\"route\")\nw.save(os.path.join(savedir, \"route\"))\n```", "```py\nimport glob\nimport os\ntry:\n import Image\n import ImageDraw\nexcept ImportError:\n from PIL import Image\n from PIL.ExifTags import TAGS\nimport shapefile\n```", "```py\ndef exif(img):\n # extract exif data.\n exif_data = {}\n try: \n i = Image.open(img)\n tags = i._getexif()\n for tag, value in tags.items():\n decoded = TAGS.get(tag, tag)\n exif_data[decoded] = value\n except:\n pass\n return exif_data\n\ndef dms2dd(d, m, s, i):\n # convert degrees, min, sec to decimal degrees\n sec = float((m * 60) + s)\n dec = float(sec / 3600)\n deg = float(d + dec)\n if i.upper() == 'W':\n deg = deg * -1\n elif i.upper() == 'S':\n deg = deg * -1\n return float(deg)\n\ndef gps(exif):\n # get gps data from exif\n lat = None\n lon = None\n if exif['GPSInfo']: \n # Lat\n coords = exif['GPSInfo']\n i = coords[1]\n d = coords[2][0][0]\n m = coords[2][1][0]\n s = coords[2][2][0]\n lat = dms2dd(d, m, s, i)\n # Lon\n i = coords[3]\n d = coords[4][0][0]\n m = coords[4][1][0]\n s = coords[4][2][0]\n lon = dms2dd(d, m, s, i)\n return lat, lon\n```", "```py\nphotos = {}\nphoto_dir = \"./photos\"\nfiles = glob.glob(os.path.join(photo_dir, \"*.jpg\"))\nfor f in files:\n e = exif(f)\n lat, lon = gps(e)\n photos[f] = [lon, lat]\n```", "```py\nwith shapefile.Writer(\"photos\", shapefile.POINT) as w:\n    w.field(\"NAME\", \"C\", 80)\n    for f, coords in photos.items():\n        w.point(*coords)\n        w.record(f)\n```"]