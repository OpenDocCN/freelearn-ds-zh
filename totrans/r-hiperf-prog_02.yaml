- en: Chapter 2. Profiling – Measuring Code's Performance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The first step to improve the performance of R programs is to identify where
    the performance bottlenecks are occurring. To do this, we **profile** or measure
    the performance of an R program as it runs with respect to various measures such
    as execution time, memory utilization, CPU utilization, and disk I/O. This gives
    us a good idea of how the program and its parts perform, so that we can tackle
    the biggest bottlenecks first. This chapter will show you how to use a few simple
    tools to measure the performance of R programs.
  prefs: []
  type: TYPE_NORMAL
- en: The 80/20 rule is applied here. 80 percent of the possible performance improvements
    can usually be achieved by tackling 20 percent of the largest performance problems.
    We will look at how to determine which problems to solve first in order to get
    maximum improvement in the least amount of time and effort.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter covers the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Measuring the total execution time
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Profiling the execution time
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Profiling the memory utilization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitoring memory utilization, CPU utilization, and disk I/O using OS tools
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Identifying and resolving bottlenecks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Measuring total execution time
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When people say that their program is not performing well, they are often referring
    to the **execution time** or the time it takes to complete the execution of the
    program. Execution time is probably the most important performance measure in
    many contexts as it is has a direct impact on people and processes. A shorter
    execution time means the R programmer can perform his or her analysis more quickly
    to derive insights faster.
  prefs: []
  type: TYPE_NORMAL
- en: 'It turns out that execution time is also the easiest performance characteristic
    that can be measured accurately and in detail (though not always the easiest to
    solve). Therefore, we will start learning about the way to profile an R code by
    learning to measure the execution time of R programs. We will learn three different
    tools to do this: `system.time()`, `benchmark()`, and `microbenchmark()`.'
  prefs: []
  type: TYPE_NORMAL
- en: Measuring execution time with system.time()
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first profiling tool we will learn about is `system.time()`. It is a very
    useful tool that we can use to measure the execution time of any R expression.
  prefs: []
  type: TYPE_NORMAL
- en: 'Say we want to find out how long it takes to generate 100 million uniform random
    variables. Take a look at the following statement and the output when it is run
    in the R console:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The `runif(1e8)` expression generates 100 million random values between 0 and
    1\. In order to measure how long it takes to run this command, we simply pass
    this expression to `system.time()`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The output contains three elements, all measured in seconds:'
  prefs: []
  type: TYPE_NORMAL
- en: '**User time**: This element is the CPU time charged for the execution of user
    instructions of the given expression, for example, looping through an array. It
    does not include CPU time used by other processes (for example, if the computer
    happens to be running a virus scan in the background, the CPU time taken by it
    is not counted).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**System time**: System time is the CPU time charged for the execution of system
    instructions on behalf of the given expression, for example, opening and closing
    files, or allocating and freeing memory. This does not include CPU time used by
    other processes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Elapsed time**: Elapsed time is the total clock time taken to execute the
    given expression. It includes the time that the CPU has spent on other processes
    and time spent in waiting (for example, waiting for a file to be opened for reading).
    Sometimes, elapsed time is longer than the sum of user time and system time because
    the CPU is multitasking on other processes, or it has to wait for resources such
    as files and network connections to be available. At other times, elapsed time
    is shorter than the sum of user time and system time. This can happen when multiple
    threads or CPUs are used to execute the expression. For example, a task that takes
    10 seconds of user time can be completed in 5 seconds if there are two CPUs sharing
    the load.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Most of the time, we are interested in the total elapsed time to execute the
    given expression. When the expression is executed on a single thread (the default
    for R), the elapsed time is usually very close to the sum of the user time and
    system time. If that is not the case, either the expression has spent time waiting
    for resources to be available, or there were many other processes on the system
    competing for the CPU's time.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It is best to shut down any unnecessary programs and processes on the system
    before running `system.time()` in order to reduce the competition for the CPU's
    time and to get an accurate measurement. Of course, the antivirus software or
    any other critical system software should not be turned off.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `system.time()` declaration actually returns a vector with five elements
    but its `print()` function displays only the first three. To see all the five
    elements, we can call `print(unclass(system.time(expr)))`. The other two elements
    are the system and user times for the execution of any child processes spawned
    by `expr`. On Windows machines, these are not available and will always be given
    as `NA`.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is what happens when we run `system.time()` a few more times with the
    same expression:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: By running `system.time()` repeatedly, we get slightly different results each
    time because R's overheads, OS caching mechanisms, other running processes, and
    many other factors might have a slight impact on the execution time.
  prefs: []
  type: TYPE_NORMAL
- en: Repeating time measurements with rbenchmark
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It is sometimes helpful to run the same expression multiple times and get the
    average execution time, or even the distribution of execution times over multiple
    runs. The `rbenchmark` CRAN package lets us do this easily.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, install and load the `rbenchmark` package:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, use `benchmark()` to run the same random number generation task 10 times,
    by specifying `replications=10`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The results show the total elapsed system and user time taken to generate 100
    million uniform random variables over 10 repetitions. We can find the mean times
    taken per repetition using `within()` to divide the time measurements by the number
    of repetitions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'What if we want to know the execution times for each repetition, or the distribution
    of execution times over the repetitions? We can pass a vector instead of a single
    number as the `replications` parameter. For each element of this vector, `benchmark()`
    will execute the given expression the specified number of times. So we can get
    10 samples of the execution of the random number generation once, as shown in
    the following code. In addition to the elapsed user and system time, `benchmark()`
    returns an additional column, `relative`, which indicates how each repetition''s
    elapsed time is compared with the fastest one. For example, the first repetition
    took 1.011 times as long as the fastest repetition (the fourth one), or 1.1 percent
    longer to run:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Measuring distribution of execution time with microbenchmark
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The CRAN package `microbenchmark` provides yet another way to measure the execution
    time of an R expression. Though its `microbenchmark()` function only measures
    the elapsed time and not the user time or system time, it gives an idea of how
    the execution times across repeated runs are distributed. It also automatically
    corrects for the overheads related to the execution of the timing tests. The `microbenchmark()`
    function is very handy to measure short running tasks over many repetitions provided
    you do not need to measure the user or system times. We will use this tool many
    times throughout this book.
  prefs: []
  type: TYPE_NORMAL
- en: 'Install and load the `microbenchmark` package:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, run the same random number generation task 10 times using `microbenchmark()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The statistics shows the minimum, lower quartile, median, upper quartile, and
    maximum values of the elapsed time over 10 repetitions. This gives us an idea
    of the distribution of the elapsed times over different repetitions of the same
    expression.
  prefs: []
  type: TYPE_NORMAL
- en: Profiling the execution time
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we have seen how to measure the execution time of a whole R expression.
    What about a more complex expression with multiple parts such as calls to other
    functions? Is there a way to dig deeper and profile the execution time of each
    of the parts that make up the expression? R comes with the profiling tool `Rprof()`
    that allows us to do just that. Let's see how it works.
  prefs: []
  type: TYPE_NORMAL
- en: Profiling a function with Rprof()
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this example, we write the following `sampvar()` function to calculate the
    unbiased sample variance of a numeric vector. This is obviously not the best way
    to write this function (in fact R provides the `var()` function to do this), but
    it serves to illustrate how code profiling works:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Within `sampvar()`, we define two utility functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '`my.sum()`: This computes the sum of a vector by looping over the elements
    of the vector.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sq.var()`: This computes the sum of the squared deviations of a vector from
    a given mean, by looping over the elements of the vector.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `sampvar()` function first computes the sample mean, then the sum of squared
    deviations from that mean, and then the sample variance by dividing that sum by
    *n-1*.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can profile the `sampvar()` function as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'This is how the code works:'
  prefs: []
  type: TYPE_NORMAL
- en: The `runif(1e7)` expression generates a random sample of 10 million numbers.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `Rprof("Rprof.out")` expression tells R to begin profiling. `Rprof.out`
    is the name of a file in which the profiling data is stored. It will be stored
    in R's current working directory unless another file path is specified.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `sampvar(x)` expression calls the function we just created.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `Rprof(NULL)` expression tells R to stop profiling. Otherwise, it will continue
    to profile other R statements that we run but do not intend to profile.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `summaryRprof("Rprof.out")` expression prints the results of the profiling.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The profiling results
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The results are broken down into a few measures:'
  prefs: []
  type: TYPE_NORMAL
- en: The `self.time` and `self.pct` columns represent the elapsed time for each function,
    excluding the elapsed time of other functions that are called by the function.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `total.time` and `total.pct` columns represent the total elapsed time for
    each function including the time spent inside function calls.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'From the profiling data, we get some interesting observations:'
  prefs: []
  type: TYPE_NORMAL
- en: The `sampvar()` function's `self.time` is negligible (reported as zero), indicating
    that almost all the time taken to run `sampvar` is contributed by the functions
    that it calls.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While `sampvar()` spent a total of 7.52 seconds, 5.28 seconds of this time was
    contributed by `sq.var()`, and 2.24 seconds by `my.sum()` (see `total.time` of
    `sq.var()` and `my.sum()`).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `sq.var()` function took the largest chunk of time (70.21 percent) to get
    executed and looks like a good place to start improving the performance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The R operators `-`, `+`, and `*` were extremely quick, taking not more than
    a total of 0.46 seconds each, even though they were executed millions of times.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Rprof()` works by observing R''s call stack as the R expression is running,
    and taking a snapshot of the call stack at fixed intervals (every 0.02 seconds
    by default) to see which function is currently executing. From these snapshots,
    `summaryRprof()` can compute how much time was spent in each function.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For a more intuitive view of the profiling data, we can use the `proftools`
    package. We will also need to install the `graph` and `Rgraphviz` packages from
    the Bioconductor repository:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The `plotProfileCallGraph()` function generates an intuitive visual plot of
    the profile data. We use the `google.style` template which shows functions with
    longer `self.time` in bigger boxes. We also specify `score="total"` to color the
    boxes according to `total.time`. The following figure shows the output of the
    same profiling data:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The profiling results](img/9263OS_02_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Profiling data for sampvar() rendered by plotProfileCallGrah()
  prefs: []
  type: TYPE_NORMAL
- en: We can see from `sampvar()` that it has the longest `total.time` of 100 percent.
    This is expected since it is the function that is being profiled. The next longest-running
    function is `sq.var()`, which accounts for 70.21 percent of the elapsed time.
    `sq.var()` also happens to have the longest `self.time`, which can be seen from
    the size of its box. Thus, `sq.var()` seems like a good candidate for the first
    step in addressing performance problems.
  prefs: []
  type: TYPE_NORMAL
- en: The `Rprof()` function is a useful tool to understand the performance of different
    parts of R programs and quickly spot bottlenecks that we can address to improve
    the overall performance of our R code.
  prefs: []
  type: TYPE_NORMAL
- en: Profiling memory utilization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Next, let's consider how to profile the memory utilization of R code.
  prefs: []
  type: TYPE_NORMAL
- en: 'One approach is to use `Rprof()` by setting the `memory.profiling` argument
    and the corresponding `memory` argument to `summaryRprof()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The output now shows an additional column `mem.total` reporting the memory utilization
    of each function. For this example, it seems that it took 1,656 MB of memory to
    run `sampvar()`! This seems exceptionally high for computations on a numeric vector
    with 10 million elements, which would measure only 76.3 MB in the memory (you
    can check this by running `print(object.size(x), units="auto")`).
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, `mem.total` is a misleading measure because `Rprof()` attributes
    the memory usage to the function that happens to be running when it takes a snapshot,
    but the memory could have been used by other functions and not have been released
    yet. Furthermore, R's garbage collector regularly releases unused memory to the
    operating system, so the actual memory being used at any given time might be vastly
    different from that reported by `Rprof()`. In other words, `Rprof()` gives an
    indication of the total amount of memory allocated while running an R code, but
    does not take into account the memory freed by the garbage collector.
  prefs: []
  type: TYPE_NORMAL
- en: 'To see how garbage collection affects memory utilization, we can run the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The `gcinfo(TRUE)` expression tells R to inform us every time the garbage collector
    releases memory. On our machine, the garbage collector was activated 272 times
    while running `sampvar()`! Although `Rprof()` reported that 1.7 GB of the memory
    was allocated in total, the garbage collector was hard at work to release unused
    memory so that R's total memory consumption stayed manageable at around 113.9
    MB (*31.1 MB + 82.8 MB*).
  prefs: []
  type: TYPE_NORMAL
- en: Because `Rprof()` measures the cumulative allocated memory without accounting
    for garbage collection, it is not suited for determining whether an R program
    will exceed the available memory on a system. `gcinfo()` provides a clearer picture,
    albeit still an approximate one, by providing a snapshot of the memory consumption
    at every garbage collection interval.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `gcinfo()` and `gc()` functions give pretty good estimates of memory utilization
    in this case because our code uses only standard R operations. Some R packages
    use custom memory allocators that `gcinfo()` and `gc()` are not able to track,
    so memory utilization can be underreported.
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring memory utilization, CPU utilization, and disk I/O using OS tools
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Unlike execution time, R does not provide any good tools to profile CPU utilization
    and disk I/O. Even the memory profiling tools in R might not provide a complete
    or accurate picture. This is where we turn to OS-provided system monitoring tools
    to keep an eye on the computational resources as we run R programs. They are task
    manager or resource monitor in Windows, activity monitor in Mac OS X, and `top`
    in Linux. When running these tools, look for the processes that represent R (usually
    called `R` or `rsession`).
  prefs: []
  type: TYPE_NORMAL
- en: 'The information that we get varies depending on the operating system, but here
    are the key measures of R''s resource utilization to keep an eye on:'
  prefs: []
  type: TYPE_NORMAL
- en: '**% CPU or CPU usage**: The percentage of the system''s CPU time used by R'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**% memory, resident memory, or working set**: The percentage of the system''s
    physical memory used by R'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Swap size or page outs**: The size of memory used by R that is stored in
    the operating system''s swapspace'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Bytes read or written per second**: The rate of data being read or written
    from/to disk by R'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In addition, we might also want to monitor these system-wide resource utilization
    measures:'
  prefs: []
  type: TYPE_NORMAL
- en: '**% free memory**: The percentage of the system''s physical memory that is
    available for use'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Swap size or page outs**: The total size of memory that is stored in the
    OS''s swapspace'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The preceding measures are helpful in troubleshooting R''s performance problems:'
  prefs: []
  type: TYPE_NORMAL
- en: '**High CPU utilization**: A CPU is likely the main bottleneck of R''s performance.
    Use the profiling techniques in this chapter to identify which parts of the code
    are taking most of the CPU''s time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Low CPU utilization, low free system memory with large swap size, and high
    disk I/O**: The system is likely running out of physical memory and is thus swapping
    memory onto the disk. Use the memory management techniques in [Chapters 6](ch06.html
    "Chapter 6. Simple Tweaks to Use Less RAM"), *Simple Tweaks to Use Less RAM*,
    and [Chapter 7](ch07.html "Chapter 7. Processing Large Datasets with Limited RAM"),
    *Processing Large Datasets with Limited RAM*, to reduce the memory required by
    the R program.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Sufficient free system memory with high disk I/O**: The program writes/reads
    to disk very often. Check for any unnecessary I/O operations and store intermediate
    data in the memory if there is sufficient free memory.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Identifying and resolving bottlenecks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have covered the basic techniques to profile an R code, which performance
    bottlenecks should we try to solve first?
  prefs: []
  type: TYPE_NORMAL
- en: As a rule of thumb, we first try to improve the pieces of code that are causing
    the largest performance bottlenecks, whether in terms of execution time, memory
    utilization, or other measures. These can be identified with the profiling techniques
    covered earlier. Then we work our way down the list of the largest bottlenecks
    until the overall performance of the program is good enough.
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can recall, the `varsamp()` example that we profiled using `Rprof()`.
    The function with the highest `self.time` was `sq.var()`. How can we make this
    function run faster? We can write it in the form of a vector operation `my.sum((x
    - mu) ^ 2)` rather than looping through each element of `x`. As we will see in
    the next chapter, converting loops to vectorized operations is a good way to speed
    up many R operations. In fact, we can even remove the function altogether since
    the new vector expression fits in one line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: This change shaved 2.98 seconds off the elapsed time and 477 MB off the total
    memory allocated while running the function.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now the `my.sum()` function contributes to a significant 85 percent of the
    total elapsed time. Let''s replace it with the `sum()` function from R, which
    runs much faster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Voila! In two simple steps, we reduced the elapsed time of `sampvar()` from
    7.58 seconds to 0.08 seconds (a 99 percent reduction). Furthermore, the memory
    utilization as reported by `Rprof()` was also reduced from over 1.6 GB to a mere
    76.2 MB (a 95.4 percent reduction). This reduction in memory allocation and garbage
    collection also played a significant part in speeding up our code.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s compare how fast our code runs compared to the R function `var()`, which
    is written in C for optimal performance (we will learn in [Chapter 4](ch04.html
    "Chapter 4. Using Compiled Code for Greater Speed"), *Using Compiled Code for
    Greater Speed*):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: With a median elapsed time of 50 milliseconds, our function takes only 36 percent
    more time than the optimized C version that has a median of 37 milliseconds.
  prefs: []
  type: TYPE_NORMAL
- en: The preceding exercise illustrates how code profiling can be used as part of
    a workflow to identify, prioritize, and fix performance issues in R programs.
    The rest of this book will cover techniques that we can use to solve specific
    performance problems.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned how to measure the execution time of R expressions
    using `system.time()`, `benchmark()` (from the `rbenchmark` package) and `microbenchmark()`
    (from the `microbenchmark` package). We examined how to profile the execution
    time and memory usage of different parts of an R program using `Rprof()` and `summaryRprof()`
    and to display the results in an intuitive visual form using the `proftools` package.
  prefs: []
  type: TYPE_NORMAL
- en: We also saw the role of OS-provided monitoring tools to understand the overall
    performance of R programs and how these system measures can provide clues about
    the performance bottlenecks that our R programs might be facing.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we learned how to apply the profiling techniques in a practical, iterative
    workflow to identify, prioritize and resolve performance related problems in an
    R code.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will learn some simple tweaks to improve R code so that
    it runs faster.
  prefs: []
  type: TYPE_NORMAL
