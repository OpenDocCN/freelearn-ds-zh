- en: '6'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Stock Market Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we’ll introduce **temporal data** and dive into stock market
    trend analysis. To understand trends over time, we’ll return to **centrality measurements**
    on networks and introduce some more advanced algorithms. Finally, we’ll analyze
    stock pricing data over time using our centrality measurements and pinpoint changes
    in behavior over time within and across different stocks to predict spikes and
    crashes in price.
  prefs: []
  type: TYPE_NORMAL
- en: By the end of this chapter, you’ll be able to wrangle datasets with time components
    into a series of networks and analyze structural changes over time with centrality
    metrics. Many of the centrality metrics scale well to large networks, particularly
    when they are run in parallel.
  prefs: []
  type: TYPE_NORMAL
- en: 'Specifically, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to temporal data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction to centrality metrics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Application of centrality metrics across time slices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Extending network metrics for time series analytics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s get started by returning to temporal datasets and the limitations of non-network-based
    models to analyze them.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You will require Jupyter Notebook to run the practical examples in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code for this chapter is available here: [https://github.com/PacktPublishing/Modern-Graph-Theory-Algorithms-with-Python](https://github.com/PacktPublishing/Modern-Graph-Theory-Algorithms-with-Python)'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to temporal data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In [*Chapter 2*](B21087_02.xhtml#_idTextAnchor028), we briefly introduced temporal
    data or data in the form of a time series or a group of time series. **Time series
    data** tracks important metrics in many different industries: daily store sales
    volumes, weekly software product marketing lead volumes, daily incidence of an
    emerging disease, yearly behavior rates (such as smoking or vegetable consumption)
    in a population, or hourly stock prices tracking market trends. Many related factors
    can influence trends over time, and some models consider these factors directly
    if they are known in advance.'
  prefs: []
  type: TYPE_NORMAL
- en: However, consider the case of sales trends for a new gem store in a city where
    gem stores are a new phenomenon, perhaps somewhere rural between Haifa and Tel
    Aviv (*Figure 6**.1*). Thus, there is very little known about what might influence
    sales. Understanding what trends exist in the time series data is critical when
    mining for factors that might influence sales. However, time series datasets pose
    significant challenges to many supervised learning methods, such as **random forest
    models** or **linear regression**. At one point in time, sales are not independent;
    they rely on factors that influence sales in the previous days, limiting the use
    of supervised learning and many types of **unsupervised learning**. The lack of
    predictors also poses a challenge.
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 6.1 – \uFEFFAn illustration of a gem store located partway between\
    \ Tel Aviv and Haifa, Israel](img/B21087_06_01.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 6.1 – An illustration of a gem store located partway between Tel Aviv
    and Haifa, Israel
  prefs: []
  type: TYPE_NORMAL
- en: Fortunately, for our gem store, many algorithms are designed to handle time
    series data, such as **autoregressive integrated moving average models** (**ARIMA
    models**), **singular spectrum analysis** (**SSA**), and **Holt–Winters models**.
    However, changes in time series behavior (spikes, crashes, and changes in variance)
    pose a challenge to these models. Capturing and predicting these changes is critical
    if you want to create a predictive model or mine for factors influencing the time
    series values. In our gem store example, seasonality in tourism, conflicts in
    the region, and holiday travel promotions may influence traffic along the route
    in which our store is positioned.
  prefs: []
  type: TYPE_NORMAL
- en: One industry with abundant and very complex time series data is finance. Many
    social and economic factors influence stock prices, and untangling the relationships
    and randomness in stock price fluctuations underlies much of the finance industry.
    Let’s have a look at the stock market pricing data and common tasks in analyzing
    stock market pricing data.
  prefs: []
  type: TYPE_NORMAL
- en: Stock market applications
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In recent years, the financial sector has shifted from an expert-driven model
    of stock market insight to a more machine learning-based approach. Machine learning
    models sift out emerging trends and catch subtle trends that may escape a human
    pouring over the data. This tactic also allows analysts to process a much larger
    data collection than a human could process, including many different sectors,
    international stock exchanges, and even individual frontier markets. By collecting
    more insight, it is possible for investors and investment management firms to
    invest in a wider variety of markets without as much expertise in those markets.
  prefs: []
  type: TYPE_NORMAL
- en: Stock market analytics covers a vast field of applications. Investments can
    be made within certain market sectors (such as technology or agriculture) or across
    markets. They can focus on short-term gains (including those made in minutes or
    hours) and long-term gains (which may span decades). They can also focus on foreign
    markets, where stock prices may be influenced by factors very different from those
    influencing a local market’s prices. All these scenarios guide analytics efforts
    and the time scale of data collected for analysis.
  prefs: []
  type: TYPE_NORMAL
- en: 'In general, analyzing stock market data involves assessing many types of trends
    over time. Stocks can have constant prices over time, experience gradual price
    growth and reduction, crash suddenly, or grow exponentially. Each of these suggests
    a different purchase/sale strategy for investors in the short term and the long
    term. *Figure 6**.2* shows a hypothetical stock that exhibits many of these patterns:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.2 – An example of stock data trends, including stagnant periods,
    growth, shrinkage, and a crash](img/B21087_06_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.2 – An example of stock data trends, including stagnant periods, growth,
    shrinkage, and a crash
  prefs: []
  type: TYPE_NORMAL
- en: We can see in *Figure 6**.2* that Stock A begins 2022 with a consistent price
    before entering a growth phase around July 2022\. This growth phase lasts until
    early 2023, at which point it enters a constant pricing phase again. As an event
    happens in March of 2024, the price of Stock A crashes and then enters a period
    of price decline until the end of our tracked time period.
  prefs: []
  type: TYPE_NORMAL
- en: Often, these trends do not occur in isolation. The stocks of companies that
    share supply chains may exhibit similar trends. Stocks in the same industry may
    exhibit similar or opposite trends, depending on how companies relate to each
    other or news in the industry. Stocks in shared trade or defense regions may exhibit
    similar trends, as well, given the sociopolitical ties across countries and their
    markets (such as the COVID crash across most economies).
  prefs: []
  type: TYPE_NORMAL
- en: '**Tipping points**, where trends change dramatically, attract a lot of attention
    in financial analytics. These represent opportunities to invest before a period
    of accelerating growth or warnings to pull out of a market or particular investment
    before a crash. However, detecting these trends challenges many of the commonly
    used tools in market analytics.'
  prefs: []
  type: TYPE_NORMAL
- en: Thankfully, newer tools, including a few rooted in network science, identify
    tipping points more readily than traditional methods. Many tools hinge on large-scale
    coupling across markets, sectors, or stocks. As more and more stocks (or markets)
    exhibit similar behavior, the system becomes vulnerable to outside influences
    that can tip it into a crash (such as supply chain issues, new legislation, or
    a pandemic). Simply calculating the correlations among individual stocks or sectors
    of a market can provide some insight, but transforming correlations (within slices
    of time) to networks allows us to leverage many network science tools that dive
    deeper into the nature of their correlations and their changes over time. Specifically,
    centrality metrics allow us to quantify and classify relationships that exist
    within a network. Let’s explore a few of these centrality metrics.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to centrality metrics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We’ve encountered some centrality metrics in [*Chapter 3*](B21087_03.xhtml#_idTextAnchor042),
    where we learned about bridges and hubs. Many vertex-based centrality metrics
    calculate properties related to hubs—the connection of a vertex to its nearest
    neighbors and their nearest neighbors. Many edge-based centrality metrics calculate
    bridging properties, where the edges near a vertex act as connectors between different
    hubs.
  prefs: []
  type: TYPE_NORMAL
- en: Degree is the simplest **vertex-based centrality metric**, which we encountered
    in [*Chapter 5*](B21087_05.xhtml#_idTextAnchor066). **Degree centrality** is simply
    the number of vertices directly connected to the vertex of interest. Many Laplacian-based
    metrics or algorithms depend on the degree matrix within algorithm calculations.
    On the surface, this metric seems to capture important hub properties; a vertex
    with a high degree centrality will carry a lot of influence within the network
    (and, thus, might make a good intervention target). It also scales well to very
    large networks. However, one limitation of degree centrality is its lack of awareness
    of a vertex’s position beyond any immediate connections to neighbors; a vertex
    with a low degree centrality may be connected to many vertices with a high degree
    centrality, giving it more influence over network behavior and structure than
    its degree centrality suggests.
  prefs: []
  type: TYPE_NORMAL
- en: '**Eigenvector centrality** and its variants (including **PageRank** and **Katz
    centrality**) incorporate awareness about connectivity beyond immediate neighbors
    to give a more comprehensive vertex-based centrality metric. Thus, **eigenvector
    centrality** would score our hypothetical low-degree centrality vertex connected
    to high-degree centrality vertices highly, as that vertex is near very connected
    vertices. Technically, to find the eigenvector centrality of each vertex in a
    network, we can perform an eigen decomposition on the adjacency matrix. Because
    the adjacency matrix does not include negative values, we can assume that the
    first eigenvalue is the largest, and its eigenvector yields the eigenvector centrality
    scores for our vertices.'
  prefs: []
  type: TYPE_NORMAL
- en: PageRank centrality extends eigenvector centrality and increases its flexibility
    by replacing the adjacency matrix with an adjusted adjacency matrix that is constructed
    by performing a random walk across vertices to determine the adjacency properties.
    In addition, random surfer properties, where a random walk can cross the unconnected
    areas of a graph with a low probability, create an adjusted adjacency matrix that
    is connected. This adjusted adjacency matrix is then scaled before performing
    the eigen decomposition on the adjusted adjacency matrix, which is carried out
    to compute eigenvector centrality scores. PageRank centrality scores, thus, provide
    flexibility. In addition, this computation is typically easier and faster with
    the adjusted adjacency matrix, allowing the algorithm to scale well to networks
    of even hundreds of millions of vertices.
  prefs: []
  type: TYPE_NORMAL
- en: '**Edge-based centrality measures** capture network infrastructure that is important
    for spreading processes and connectivity across different hubs. **Betweenness
    centrality** is one of the most common edge-based centrality metrics, capturing
    the relative number of shortest paths that include a given vertex among all shortest
    paths that exist in the network. Consider a network with 10 shortest paths, 8
    of which include a particular vertex. Without this vertex, many of the shortest
    paths would not exist, inconveniencing the network greatly in terms of spreading
    processes on a social network or route efficiency on a transportation network.
    However, betweenness centrality does not scale well, and it should not be used
    on large networks without some sort of parallelization of the operation.'
  prefs: []
  type: TYPE_NORMAL
- en: 'One recent edge-based centrality network has proven to be an efficient tool
    for finding stock market tipping points. **Forman–Ricci curvature** is a geometry-based
    tool that considers adjacent edges in relation to an edge of interest. On an unweighted
    network, Forman–Ricci curvature is calculated by subtracting the degree centrality
    of the two vertices attached to an edge of interest from 2\. The constant, 2,
    represents the connection between the two vertices connected by the edge of interest.
    The degree centrality of both vertices connected by the edge counts the number
    of adjacent edges to our edge of interest (minus the vertices connected by that
    edge, whereby we obtain our constant of 2). In *Figures 6–3*, we see three vertices:
    two vertices with a single edge in relation to the middle vertex (both with a
    degree centrality of 1) and a middle vertex connecting to both of the outer vertices
    (with a degree centrality of 2). Both edges, thus, have a Forman–Ricci curvature
    of -1, as the sum of the vertex degree centralities for both is 3 (2 - 3 = -1).'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.3 – An example network demonstrating Forman–Ricci curvature, where
    the middle vertex is pulled from both the first and third outer vertices](img/B21087_06_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.3 – An example network demonstrating Forman–Ricci curvature, where
    the middle vertex is pulled from both the first and third outer vertices
  prefs: []
  type: TYPE_NORMAL
- en: To obtain vertex centrality metrics from this edge metric, we can sum the edge
    metrics for each vertex to score the vertices. In our example in *Figure 6**.3*,
    we have outer vertices with a Forman–Ricci vertex centrality of -1, as both only
    connect to a single edge. However, the middle vertex connects to two edges, with
    a Forman–Ricci curvature of -1, giving it a Forman–Ricci vertex centrality of
    -2\. Because this centrality metric relies on low-cost computations, it scales
    well to large networks and can be used as an alternative edge-based centrality
    score when betweenness centrality is not feasible.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s explore some stock market data and see how network science can help
    us identify key trends over time.
  prefs: []
  type: TYPE_NORMAL
- en: Application of centrality metrics across time slices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The NASDAQ stock market is an American stock exchange in New York City that
    includes publicly traded companies such as Apple, Alphabet, Nvidia, and Microsoft.
    Kaggle provides a full history of NASDAQ stock prices under a public license ([https://www.kaggle.com/datasets/jacksoncrow/stock-market-dataset?resource=download](https://www.kaggle.com/datasets/jacksoncrow/stock-market-dataset?resource=download))
    that can give us stock data for these four tech companies during the period in
    which they were all publicly traded up to April 1, 2020\. We’ve munged the data
    for you to include only these four stocks in the period from August 19, 2004,
    to April 1, 2020\. Let’s take a peek at these data to see what trends might exist
    (*Figure 6**.4*):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.4 – NASDAQ selected stock closing values from August 19, 2004, to
    April 1, 2020](img/B21087_06_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.4 – NASDAQ selected stock closing values from August 19, 2004, to April
    1, 2020
  prefs: []
  type: TYPE_NORMAL
- en: In *Figure 6**.4*, we can see that Alphabet has a consistently higher price,
    but all stocks exhibit the typical trends of constant pricing, dips, spikes, and
    upward or downward trends over this long period of trading. Of note is the 2020
    trend, where stocks experienced the COVID-19 crash. Periods of volatility include
    2008–2009 and 2016–2020.
  prefs: []
  type: TYPE_NORMAL
- en: One of the important aspects of time series analysis is **windowing** the time
    series data into overlapping pieces. While windowing can be optimized by using
    a grid search, windowing tends to be more of an art than a science. Choosing a
    window impacts the length of time in which trends can be captured. In our stock
    market data, window length limits the period in which we can search for trends
    and, thus, limits the time period after the last window in which we can forecast
    market behavior. A window that is too large can miss important trends that impact
    short-term market behavior. A window that is too small can limit forecasting to
    the immediate future.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll choose a window of 5 trading days or roughly a week’s worth of stock data.
    This allows us to capture trends relevant to day trading, where stocks are traded
    frequently based on volatility. Our network metrics should work well for volatility-based
    trading for quick gains, as they capture increasing correlations across the two
    stocks.
  prefs: []
  type: TYPE_NORMAL
- en: Another aspect that is important to windowing time series data is the choice
    of overlap. For our example, we’ll choose maximal overlap (4 days’ overlap) to
    maximize our sensitivity to day-to-day trends. In other applications, less overlap
    may be desirable to investigate longer time trends. Note that our example uses
    a path on one of our machines. Your file path will be different from ours.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s import our packages and load our data into Python with `Script 6.1` to
    get started:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have our data imported, we can add a loop that windows our time
    series to 5-day periods that overlap by 4 days across slices. This window strategy
    yields the best chance to find daily changes in trends. We’ll then create correlations
    among the four stocks within that time slice, threshold those correlations to
    limit our analysis to high correlations, create an unweighted network from those
    thresholds, and analyze Pagerank centrality, degree centrality, betweenness centrality,
    and Forman–Ricci curvature centrality across the time slices. We’ll also save
    each unweighted network for future retrieval, as well as the network metrics and
    their averages over each time slice. Let’s add these pieces to `Script 6.1`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: This script should run quickly on your machine. If you include a very large
    number of stocks in your analyses, you may wish to run the script in parallel
    to save time or exclude betweenness centrality, as betweenness centrality does
    not scale well as the number of vertices increases.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have computed our metrics, let’s examine the correlations between
    the metrics across our set of time series windows to see how the different metrics
    relate to each other. Given that Forman–Ricci curvature depends on degree centrality
    metrics, we’d expect to see a strong correlation. We can add to `Script 6.1` to
    obtain these correlations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: You should see a strong correlation between degree centrality and Forman–Ricci
    curvature centrality (-0.99 in our analysis) but fairly weak correlations among
    the other centrality metrics (-0.05 for degree and Pagerank centralities, 0.01
    for degree and betweenness centralities, 0.04 for Pagerank and betweenness centralities,
    0.04 for Pagerank and Forman–Ricci curvature centrality, and 0.05 for betweenness
    and Forman–Ricci curvature centrality). This suggests that degree centrality and
    Forman–Ricci curvature may be interchangeable in these analyses, though a more
    complex Forman–Ricci curvature metric may capture a bit more information that
    may be relevant to certain trends. It’s unclear if these correlations would hold
    for other datasets, though degree centrality and Forman–Ricci curvature on unweighted
    networks will correlate to some extent, given that the Forman–Ricci curvature
    formula depends on degree centrality.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s visualize the network metric trends over time to see if any patterns
    emerge or extreme values stand out that might indicate behavior changes in our
    stock pricing. We’ll add visualization code to `Script 6.1` to do this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'This should give you a plot similar to *Figure 6**.5*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.5 – A plot of centrality averages across time slices for our stock
    market data](img/B21087_06_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.5 – A plot of centrality averages across time slices for our stock
    market data
  prefs: []
  type: TYPE_NORMAL
- en: Note that Pagerank centrality does not show up in our plot. Pagerank and betweenness
    centrality fill a similar range of values, masking Pagerank centrality in our
    plot. However, we do see that differences in the average centrality values emerge
    regularly in our plot, suggesting that our centrality values may be capturing
    different states of the market over time.
  prefs: []
  type: TYPE_NORMAL
- en: Our Forman–Ricci curvature centrality averages suggest periods of relative stability
    in the market, where the values are near zero. Two prominent periods of relative
    stability occur at the start of our time series (roughly 2004–2006) and again
    in the mid-to-late 2010s. However, as we approach 2008 and 2020, the correlations
    among our stocks increase considerably before two major market crashes.
  prefs: []
  type: TYPE_NORMAL
- en: 'It’s probable that our choice of threshold value influences our results. To
    hone in on periods of tight coupling in terms of stock behavior, let’s raise our
    threshold value to `0.9` and rerun `Script 6.1`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can rerun our correlation analysis to understand how threshold value
    might influence any correlations among the metrics. Let’s rerun our correlation
    analysis in `Script 6.1`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: You should see some notable differences compared to our prior results with this
    new threshold. The degree and Pagerank centralities are still not correlated very
    much (-0.04), which is mirrored by the correlations between Pagerank centrality
    and betweenness centrality (0.003) and Pagerank and Forman–Ricci curvature centrality
    (0.04). However, degree and betweenness centrality are moderately correlated now
    (0.44), as are betweenness and Forman–Ricci curvature centrality (-0.39). The
    degree and Forman–Ricci curvature centralities are still highly correlated, though
    slightly less than in our prior threshold (-0.98).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s plot our new results to investigate any trends that may have been masked
    with a low threshold value in our initial analysis. We can replot this using `Script
    6.1`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'This should yield a plot that looks very different from *Figure 6**.5*. In
    *Figure 6**.6*, we can see the periods of volatility much more clearly than we
    could in *Figure 6**.5*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.6 – A plot of network centrality metrics across time slices with
    a 0.9 threshold](img/B21087_06_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.6 – A plot of network centrality metrics across time slices with a
    0.9 threshold
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 6**.6* shows many more Forman–Ricci curvature values that are near
    0, suggesting less volatility in the market during those time periods. We see
    a few periods of increasing volatility (more extreme Forman–Ricci curvature values)
    in the form of dips in our plot. Those periods of intense volatility and coupling
    precede the crashes in 2008 and 2020, as well as periods of quick rebuilding after
    crashes. These are periods of interest for investors, as large sums of money are
    either lost or gained during those periods.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In general, network metrics seem to pick up on market volatility very well,
    particularly when high thresholds are applied to the data. This suggests what
    has been stated in the recent literature: network metrics are useful tools to
    identify market volatility before crashes and exponential growth. In fact, these
    tools picked up growing market volatility long before the COVID crash of 2020,
    which could have saved gains in the months leading up to 2020 had investors heeded
    the volatility warnings and pulled out before trouble hit the market. Given the
    volatility and long period of steep growth, it’s likely that any number of factors
    would have caused a major crash. A large-scale or badly placed regional conflict,
    a breakdown in the supply chain, or a change in policy within the technology sector
    probably would have produced a major crash.'
  prefs: []
  type: TYPE_NORMAL
- en: Returning to *Figure 6**.7*, we observe very different trends before the 2008
    crash than the 2020 crash. While 2020 was preceded by a long period of growth
    with recent small crashes, 2008 was preceded by relative stability and slow growth.
    Given the increasing volatility and accelerated growth of stock prices for these
    four NASDAQ stocks, these trends make the market more vulnerable to large crashes
    in the future, and should the trends hold across other NASDAQ sectors, then we’d
    expect less certainty and more opportunities for large gains and losses in the
    near future.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.7 – Returning to the plot of the stock data](img/B21087_06_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.7 – Returning to the plot of the stock data
  prefs: []
  type: TYPE_NORMAL
- en: Given these trends in the market, network science tools are poised to play a
    critical role in stock market analytics. Relatively little work exists in terms
    of the application of these tools to stock market data or time series data more
    generally, and few centrality metrics have been studied systematically. Much of
    the existing research on the application of centrality metrics to understand stock
    market trends over time involves extensions of networks to include multi-way relationships.
    Let’s now turn our attention to an extension of applying networks to the relationships
    that exist among more than two entities.
  prefs: []
  type: TYPE_NORMAL
- en: Extending network metrics for time series analytics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Because networks are topological objects and because our correlation matrix
    can use a threshold of any value, it is possible to extend network metrics to
    the realm of topological data analysis. Networks capture the two-way relationships
    between entities. However, three-way, four-way, and even larger-way interactions
    can exist, as well. **Simplicial complexes** extend the idea of networks to capture
    these higher-numbered interactions. Three-way interactions are represented as
    faces (or triangles) outlined by two-way lines. Four-way interactions are represented
    as tetrahedra, comprised of three-way faces that have four-way interactions. This
    process can continue to any value of mutual interactions, where the lower-dimensional
    interactions form the boundaries of the higher-dimensional interactions. A simplicial
    complex collects the highest-level interactions that exist among vertices into
    a single object. *Figure 6**.8* shows an example of a three-way interaction bounded
    by mutual, two-way interactions:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.8 – A diagram showing how a three-way interaction is defined by
    mutual, two-way interactions](img/B21087_06_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.8 – A diagram showing how a three-way interaction is defined by mutual,
    two-way interactions
  prefs: []
  type: TYPE_NORMAL
- en: Just as networks can be weighted or unweighted, simplicial complexes can be
    weighted or unweighted across *n*-way interactions within the simplicial complex.
    In addition, just as networks are constructed from an adjacency matrix, so simplicial
    complexes are created from adjacency matrices at each level of *n*-way interactions
    (technically the boundary matrices). Just as we typically need to construct an
    adjacency matrix to create a network from raw data, we can use raw data to define
    the *n*-way interactions existing in that data.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, a relationship metric must be defined for the raw data. In our stock
    dataset, we chose correlation metrics. Distance metrics are also commonly used
    when constructing both networks and simplicial complexes, and many, many distance
    metrics can be defined for continuous or discrete measurements on a dataset. Once
    a metric is defined, a threshold or series of thresholds are applied to the metric
    matrix to define the relationships within a given radius of each other (defined
    by the threshold). Two main options exist for constructing the simplicial complex
    and its relationships:'
  prefs: []
  type: TYPE_NORMAL
- en: Defining the *n*-way relationships through the union of points, the radii of
    which touch (called a **Vietoris–Rips complex**)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Counting the connection points, which involves the mutual overlap of points
    within a given radius, where all connected points must lie within each other’s
    radius (called a **Čech complex**)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **filtration** of simplicial complexes involves varying the radius by different
    metric thresholds. Remember how applying different correlation thresholds produced
    different results and insights for our stock market dataset? Different filtration
    levels of simplicial complexes can produce different simplicial complexes at each
    filtration level with different properties that may contain important information
    for an analyst.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s create a function that defines the Vietoris–Rips simplicial complex for
    two-way interactions (corresponding to a network) using `Script 6.2`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can apply this to the first slice of our stock market time series data.
    We’ll choose thresholds of 1 and 10 as a starting point to understand which vertex
    pairs will be included in our simplicial complex (here, only at the two-way interaction
    level). Let’s add this to `Script 6.2` to calculate the Vietoris–Rips simplicial
    complex for the first slice of our stock market time series data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'We can examine the vertex pairs included in each filtration by adding the following
    to `Script 6.2`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'This gives us pairs of vertices for each filtration, which should show the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'We can visualize the threshold = 1 complex with two-way interactions by adding
    the following to `Script 6.2`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'This gives a figure similar to the one in *Figure 6**.9*, showing a set of
    three triangles connected by two-way interactions:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.9 – A visualization of the threshold = 1 results for two-way interactions](img/B21087_06_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.9 – A visualization of the threshold = 1 results for two-way interactions
  prefs: []
  type: TYPE_NORMAL
- en: 'Similarly, we can visualize our threshold = 10 results by adding the following
    to `Script 6.2`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'This should give a plot similar to *Figure 6**.10*, which shows a more complex
    connectivity than the threshold = 1 results:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.10 – A visualization of the threshold = 10 results for two-way interactions](img/B21087_06_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.10 – A visualization of the threshold = 10 results for two-way interactions
  prefs: []
  type: TYPE_NORMAL
- en: These results show that different radius thresholds yield different networks,
    just as our correlation thresholds produced different networks. We could build
    a full filtration from the first appearance of an edge until all possible edges
    exist in our network to track changes in network structure based on distances
    between points. We could also include three-way and four-way interactions in our
    construction of the Vietoris–Rips complex to extend our analysis to the fully
    simplicial complexes that exist in each slice of our dataset.
  prefs: []
  type: TYPE_NORMAL
- en: While simplicial complex metrics are beyond the scope of this book, many extensions
    of network metrics to simplicial complexes exist (such as Forman–Ricci curvature
    centrality) and may merit investigation in the analysis of time series data. Currently,
    very little work has elucidated the use of simplicial complex metrics or methods
    on stock market change point detection.
  prefs: []
  type: TYPE_NORMAL
- en: If you are interested, we encourage you to extend `Scripts 6.1` and `6.2` to
    include an analysis of the full time series through the lens of simplicial complexes
    and calculate the extensions of the network metrics in terms of simplicial complexes.
    Our chapter reference section includes papers that experiment with these extensions.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we’ve introduced some common uses of time series data and time
    series analytics, including stock market data. We explored several vertex- and
    edge-based centrality metrics that are common in network analytics. Then, we applied
    network metrics to a time series problem on NASDAQ stock data from 2004 to 2020
    to investigate how network metrics and time series thresholding impact the ability
    to extract useful information from time series data, such as our stock data. Finally,
    we investigated extending networks to simplicial complexes and constructed a network
    by building two simplicial complexes using the Vietoris–Rips method and various
    threshold values. In [*Chapter 7*](B21087_07.xhtml#_idTextAnchor088), we'll look
    at sales and goods pricing across both time and geography to see how network science
    can solve problems in spatiotemporal data.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'De Floriani, L., & Hui, A. (2005, July). *Data Structures for Simplicial Complexes:
    An Analysis And A Comparison*. In Symposium on Geometry Processing (pp. 119-128).'
  prefs: []
  type: TYPE_NORMAL
- en: Durbach, I., Katshunga, D., & Parker, H. (2013). *Community structure and centrality
    effects in the South African company network*. *South African Journal of Business
    Management*, 44(2), 35-43.
  prefs: []
  type: TYPE_NORMAL
- en: Estrada, E., & Ross, G. J. (2018). *Centralities in simplicial complexes. Applications
    to protein interaction networks.* *Journal of theoretical biology*, 438, 46-60.
  prefs: []
  type: TYPE_NORMAL
- en: Johansen, A., & Sornette, D. (1998). *Stock market crashes are outliers*. *The
    European Physical Journal B-Condensed Matter and Complex Systems*, 1, 141-143.
  prefs: []
  type: TYPE_NORMAL
- en: 'Rodrigues, F. A. (2019). *Network centrality: an introduction*. *A mathematical
    modeling approach from nonlinear dynamics to complex* *systems*, 177-196.'
  prefs: []
  type: TYPE_NORMAL
- en: Salnikov, V., Cassese, D., & Lambiotte, R. (2018). *Simplicial complexes and
    complex systems*. *European Journal of Physics*, 40(1), 014001.
  prefs: []
  type: TYPE_NORMAL
- en: Samal, A., Pharasi, H. K., Ramaia, S. J., Kannan, H., Saucan, E., Jost, J.,
    & Chakraborti, A. (2021). *Network geometry and market instability*. *Royal Society
    open science*, 8(2), 201734.
  prefs: []
  type: TYPE_NORMAL
- en: Valente, T. W., Coronges, K., Lakon, C., & Costenbader, E. (2008). *How correlated
    are network centrality measures?* *Connections* (Toronto, Ont.), 28(1), 16.
  prefs: []
  type: TYPE_NORMAL
- en: 'Xiong, J., & Xiao, W. (2021). *Identification of key nodes in abnormal fund
    trading network based on improved pagerank algorithm*. In *Journal of Physics*:
    Conference Series (Vol. 1774, No. 1, p. 012001). IOP Publishing.'
  prefs: []
  type: TYPE_NORMAL
