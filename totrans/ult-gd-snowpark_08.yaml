- en: '6'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '6'
- en: Deploying and Managing ML Models with Snowpark
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Snowpark部署和管理ML模型
- en: The seamless deployment and effective management of models have become pivotal
    components of developing data science with Snowpark. The previous chapter covered
    how to prepare the data and train the model. This chapter delves into the intricacies
    of leveraging Snowpark to deploy and manage **machine learning** (**ML**) models
    efficiently, from deployment to integration with feature stores and model registries,
    exploring the essentials of streamlining ML models in Snowpark.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在Snowpark中开发数据科学时，模型的无缝部署和有效管理已成为关键组成部分。上一章介绍了如何准备数据和训练模型。本章深入探讨了利用Snowpark高效部署和管理**机器学习**（**ML**）模型的复杂性，从部署到与特征存储和模型注册表的集成，探讨了在Snowpark中简化ML模型的基本要素。
- en: 'In this chapter, we’re going to cover the following main topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主要主题：
- en: Deploying ML models in Snowpark
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Snowpark中部署ML模型
- en: Managing Snowpark model data
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理Snowpark模型数据
- en: Technical requirements
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: Please refer to the *Technical requirements* section in the previous chapter
    for environment setup.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 请参考上一章的*技术要求*部分以设置环境。
- en: Supporting materials are available at [https://github.com/PacktPublishing/The-Ultimate-Guide-To-Snowpark](https://github.com/PacktPublishing/The-Ultimate-Guide-To-Snowpark).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 支持材料可在[https://github.com/PacktPublishing/The-Ultimate-Guide-To-Snowpark](https://github.com/PacktPublishing/The-Ultimate-Guide-To-Snowpark)找到。
- en: Deploying ML models in Snowpark
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Snowpark中部署ML模型
- en: In the preceding chapter, we learned about how to develop ML models. Now that
    the models are ready, we must deploy them into Snowpark. To make it easier for
    developers to deploy the models, the Snowpark ML library consists of functions
    that encompass the introduction of a new development interface and additional
    functionalities aimed at securely facilitating the deployment of both features
    and models. Snowpark MLOps seamlessly complements the Snowpark ML Development
    API by offering advanced model management capabilities and integrated deployment
    functionalities within the Snowflake ecosystem. In the following subsections,
    we will explore the model registry and deploy the model for inference to obtain
    predictions.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们学习了如何开发ML模型。现在模型已经准备好了，我们必须将它们部署到Snowpark中。为了使开发者更容易部署模型，Snowpark ML库包含了一系列函数，这些函数涵盖了引入新的开发接口以及旨在安全地促进特征和模型部署的附加功能。Snowpark
    MLOps通过提供高级模型管理能力和Snowflake生态系统内的集成部署功能，无缝地补充了Snowpark ML开发API。在以下小节中，我们将探讨模型注册表并将模型部署用于推理以获取预测。
- en: Snowpark ML model registry
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Snowpark ML模型注册表
- en: 'A **model registry** is a centralized repository that enables model developers
    to organize, share, and publish ML models efficiently. It streamlines collaboration
    among teams and stakeholders, facilitating the collaborative management of the
    lifecycle of all models within an organization. Organizing models is crucial for
    tracking various versions, quickly identifying the latest, and gaining insights
    into each model’s hyperparameters. A well-structured model registry enhances reproducibility
    and compelling comparison of results. It also allows tracking and analyzing model
    accuracy metrics, empowering informed decisions and continuous improvement. The
    following diagram shows the deployment of a model into a model registry:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**模型注册表**是一个集中式存储库，使模型开发者能够高效地组织、共享和发布ML模型。它简化了团队和利益相关者之间的协作，促进了组织内所有模型生命周期的协作管理。组织模型对于跟踪各种版本、快速识别最新版本以及深入了解每个模型的超参数至关重要。一个结构良好的模型注册表可以增强结果的复现性和有说服力的比较。它还允许跟踪和分析模型准确度指标，使决策更加明智并实现持续改进。以下图表显示了将模型部署到模型注册表的过程：'
- en: '![Figure 6.1 – Deploying a model into a model registry](img/B19923_06_1.jpg)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![图6.1 – 将模型部署到模型注册表](img/B19923_06_1.jpg)'
- en: Figure 6.1 – Deploying a model into a model registry
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.1 – 将模型部署到模型注册表
- en: The model registry is a Python API that manages models within the Snowflake
    environment, offering scalable, secure deployment and management capabilities
    for models within Snowflake. The Snowpark model registry is built upon a native
    Snowflake model entity, incorporating built-in versioning support for more streamlined
    management of models.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 模型注册表是一个Python API，它管理Snowflake环境中的模型，为Snowflake中的模型提供可扩展、安全的部署和管理能力。Snowpark模型注册表建立在原生的Snowflake模型实体之上，集成了内置的版本支持，以实现更流畅的模型管理。
- en: Preparing the model
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 准备模型
- en: To illustrate the model registration process, we’ll efficiently craft a streamlined
    XGBoost model using minimal parameters, leveraging grid search on the *Bike Sharing*
    dataset. The `BSD_TRAINING` table prepared in the previous chapter is the foundational
    dataset for constructing our XGBoost model.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明模型注册过程，我们将高效地构建一个使用最少参数的 XGBoost 模型，利用 *共享自行车* 数据集上的网格搜索。上一章中准备的 `BSD_TRAINING`
    表是我们构建 XGBoost 模型的基础数据集。
- en: 'Here, we are making a feature list and finding label and output columns:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们正在创建一个特征列表并找到标签和输出列：
- en: '[PRE0]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This will print out the following DataFrame:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这将打印出以下 DataFrame：
- en: '![Figure 6.2 – Model DataFrame](img/B19923_06_2.jpg)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.2 – 模型 DataFrame](img/B19923_06_2.jpg)'
- en: Figure 6.2 – Model DataFrame
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.2 – 模型 DataFrame
- en: 'For the sake of simplicity, we will focus on optimizing two parameters within
    XGBoost:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化，我们将专注于优化 XGBoost 中的两个参数：
- en: '[PRE1]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This code employs Snowflake’s ML module to perform a grid search for hyperparameter
    tuning on a gradient boosting regressor. It explores combinations of `max_depth`
    and `min_child_weight` within specified ranges, aiming to optimize the model based
    on the input and label columns provided.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码使用 Snowflake 的 ML 模块执行梯度提升回归器的超参数调优网格搜索。它探索了 `max_depth` 和 `min_child_weight`
    在指定范围内的组合，旨在根据提供的输入和标签列优化模型。
- en: 'The subsequent logical progression involves partitioning the dataset into training
    and testing sets:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步的逻辑进展是将数据集划分为训练集和测试集：
- en: '[PRE2]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This division is essential to facilitate model fitting, allowing us to train
    the model on the designated training dataset.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这种划分对于促进模型拟合至关重要，使我们能够在指定的训练数据集上训练模型。
- en: Extracting the optimum parameter
  id: totrans-29
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 提取最佳参数
- en: 'Having successfully trained our dataset using the XGBoost model, the next imperative
    is identifying optimal parameter values defined through grid search. Remarkably
    similar to the process in the `scikit-learn` package, Snowpark ML offers a comparable
    methodology. The ensuing code mirrors the steps in extracting these optimal parameters
    and subsequently visualizing them, demystifying the process for seamless comprehension:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 成功使用 XGBoost 模型训练我们的数据集后，下一步是确定通过网格搜索定义的最佳参数值。Snowpark ML 提供了一种与 `scikit-learn`
    包中类似的方法。接下来的代码反映了提取这些最佳参数的步骤，并随后可视化它们，使过程易于理解：
- en: '[PRE3]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The preceding code uses `pandas`, `seaborn`, and `matplotlib` to analyze and
    visualize grid search results from a Snowpark ML model. It extracts the parameters,
    such as `max_depth` and `min_child_weight`, along with the corresponding **mean
    absolute percentage error** (**MAPE**) values for evaluation. The following code
    showcases the values:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 上一段代码使用了 `pandas`、`seaborn` 和 `matplotlib` 来分析并可视化 Snowpark ML 模型的网格搜索结果。它提取了参数，例如
    `max_depth` 和 `min_child_weight`，以及相应的 **平均绝对百分比误差**（**MAPE**）值以进行评估。以下代码展示了这些值：
- en: '[PRE4]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The preceding code creates a `pandas` DataFrame named `gs_results_df` from
    listed `max_depth`, `min_child_weight`, and `mape` values. It then utilizes `seaborn`
    to generate a line plot, visualizing the relationship between learning rates,
    MAPE scores, and different numbers of estimators. Finally, the `matplotlib` `plt.show()`
    command displays the following plot:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 上一段代码从列出的 `max_depth`、`min_child_weight` 和 `mape` 值创建了一个名为 `gs_results_df` 的
    `pandas` DataFrame。然后它使用 `seaborn` 生成线图，可视化学习率、MAPE 分数和不同估计器数量之间的关系。最后，`matplotlib`
    的 `plt.show()` 命令显示了以下图表：
- en: '![Figure 6.3 – Data plot](img/B19923_06_3.jpg)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.3 – 数据图](img/B19923_06_3.jpg)'
- en: Figure 6.3 – Data plot
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.3 – 数据图
- en: 'Upon careful observation of the previous plot, it becomes evident that a `max_depth`
    value of `8` paired with a `min_child_weight` learning rate of `2` yields the
    optimal results. It’s noteworthy that, akin to `scikit-learn`, Snowpark ML offers
    streamlined methods for extracting these optimal parameters, simplifying the process
    for enhanced user convenience:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 仔细观察前面的图表，可以明显看出 `max_depth` 值为 `8` 与 `min_child_weight` 学习率为 `2` 的组合产生了最佳结果。值得注意的是，与
    `scikit-learn` 类似，Snowpark ML 提供了提取这些最佳参数的简化方法，简化了过程，提高了用户便利性：
- en: '[PRE5]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The code transforms the Snowpark ML grid search results into a format compatible
    with `scikit-learn` and then retrieves the best estimator, representing the model
    with optimal hyperparameters:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 代码将 Snowpark ML 网格搜索结果转换为与 `scikit-learn` 兼容的格式，然后检索最佳估计器，代表具有最佳超参数的模型：
- en: '![Figure 6.4 – Snowpark ML grid search result](img/B19923_06_4.jpg)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.4 – Snowpark ML 网格搜索结果](img/B19923_06_4.jpg)'
- en: Figure 6.4 – Snowpark ML grid search result
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.4 – Snowpark ML 网格搜索结果
- en: In the next section, we will use the Snowpark model registry to log the model.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将使用 Snowpark 模型注册表来记录模型。
- en: Logging the optimal model
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 记录最佳模型
- en: With our optimal model in hand, the pivotal phase of the model registry unfolds.
    Much akin to the previously created model, we can extend this process to encompass
    multiple models, registering each through the model registry. In this case, we
    will be registering only our optimal model. We’ll delve into a step-by-step exploration
    of how models can be registered and seamlessly deployed.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有我们的最佳模型在手，模型注册表的关键阶段展开。与之前创建的模型非常相似，我们可以扩展此过程以涵盖多个模型，通过模型注册表逐一注册。在这种情况下，我们将只注册我们的最佳模型。我们将深入探讨如何逐步注册和无缝部署模型。
- en: Note on the Model Registry and Feature Store
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 关于模型注册表和特征存储的说明
- en: While we write this chapter, both the Model Registry and Feature Store are in
    private preview. Once they are open to all, the API methods might be slightly
    different from what we see in this book.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们编写本章时，模型注册表和特征存储都处于私有预览阶段。一旦它们对所有用户开放，API 方法可能与我们在这本书中看到的不同。
- en: 'Next, we need to create a registry to log our model:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要创建一个注册表来记录我们的模型：
- en: '[PRE6]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The following code prepares the essential details to log a model in the model
    registry:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码准备记录模型到模型注册表所需的基本详细信息：
- en: '[PRE7]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: It extracts the optimal model, as determined by the grid search, and retrieves
    specific hyperparameters such as `max_depth`, `min_child_weight`, and optimal
    parameter values.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 它提取了网格搜索确定的最佳模型，并检索了特定的超参数，如 `max_depth`、`min_child_weight` 和最佳参数值。
- en: 'Having completed all necessary steps for model registration, the preceding
    code seamlessly integrates the gathered information to register our optimal XGBoost
    model officially in the model registry:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 完成所有必要的模型注册步骤后，前面的代码无缝地将收集到的信息整合，以正式将我们的最佳 XGBoost 模型注册到模型注册表中：
- en: '[PRE8]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The code assigns a name (`bike_model_xg_boost`) and version (`1`) to the model
    and logs it into the registry with associated details, including the sample input
    data and specific options. Additionally, it sets a custom metric, MAPE (`mean_abs_pct_err`),
    for the registered model with its corresponding value (`optimal_mape`). To verify
    successful registration, execute the following code:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 代码为模型分配了一个名称（`bike_model_xg_boost`）和一个版本（`1`），并将其与相关的详细信息（包括样本输入数据和特定选项）一起记录到注册表中。此外，它为注册的模型设置了一个自定义指标，MAPE（`mean_abs_pct_err`），以及其对应的值（`optimal_mape`）。为了验证注册成功，执行以下代码：
- en: '[PRE9]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'This will confirm whether our XGBoost model and the gradient boost model (only
    the XGBoost model are steps shown here to avoid unnecessary repetition) are appropriately
    listed in the model registry:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这将确认我们的 XGBoost 模型和梯度提升模型（此处仅展示 XGBoost 模型以避免不必要的重复）是否适当地列在模型注册表中：
- en: '![Figure 6.5 – Model registered in the model registry](img/B19923_06_5.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.5 – 已注册到模型注册表的模型](img/B19923_06_5.jpg)'
- en: Figure 6.5 – Model registered in the model registry
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.5 – 已注册到模型注册表的模型
- en: In the iterative journey of experimentation with diverse models and varied parameter
    configurations, we diligently register each model within the model registry through
    a structured methodology that ensures that each model, fine-tuned and optimized,
    is stored efficiently for future use. In the next section, we will deploy the
    model from the registry using Snowpark MLOps and predict its results.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用各种模型和参数配置进行实验的迭代旅程中，我们通过一种结构化的方法，勤奋地将每个模型在模型注册表中注册，确保每个经过微调和优化的模型都能高效地存储以供将来使用。在下一节中，我们将使用
    Snowpark MLOps 从注册表中部署模型并预测其结果。
- en: Model deployment
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型部署
- en: 'In the preceding sections, we navigated the intricate landscape of deploying
    models through complex **user-defined functions** (**UDFs**) or stored procedures.
    However, the new Snowpark model registry simplifies the cumbersome process. It
    enhances the maintainability of models by providing a streamlined and standardized
    framework for handling predictive models in a production setting. This shift in
    methodology optimizes operational efficiency and aligns seamlessly with contemporary
    practices in the dynamic field of data science. A standard model deployment would
    follow this naming convention:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们 navigated the intricate landscape of deploying models through complex
    **用户定义函数**（**UDFs**）或存储过程。然而，新的Snowpark模型注册表简化了繁琐的过程。它通过提供一个简化和标准化的框架来处理生产环境中的预测模型，从而增强了模型的可维护性。这种方法论的转变优化了运营效率，并与数据科学动态领域的当代实践无缝对接。标准的模型部署将遵循以下命名约定：
- en: '[PRE10]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'This functionality provides a comprehensive view of models transitioning from
    registration to deployment within the system:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 此功能提供了系统内从注册到部署的模型全面视图：
- en: '![Figure 6.6 – Bike model deployment](img/B19923_06_6.jpg)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![图6.6 – 自行车模型部署](img/B19923_06_6.jpg)'
- en: Figure 6.6 – Bike model deployment
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.6 – 自行车模型部署
- en: 'Now, let’s leverage our deployed model to infer predictions for the test data
    and assess the accuracy of our predictions against actual outcomes:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们利用我们的部署模型来推断测试数据的预测，并评估我们的预测与实际结果之间的准确性：
- en: '[PRE12]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The code initiates a `ModelReference` object, linking to a specific model within
    the registry by referencing its name and version. Subsequently, it leverages this
    reference to predict the provided test data using the specified deployment, resulting
    in a Snowpark DataFrame (`result_sdf`). Finally, it displays the expected results
    through the `show()` method, as shown in the following screenshot:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 代码初始化一个`ModelReference`对象，通过引用其名称和版本链接到注册表中的特定模型。随后，它利用此引用使用指定的部署预测提供的测试数据，结果生成一个Snowpark
    DataFrame（`result_sdf`）。最后，它通过`show()`方法显示预期结果，如下面的截图所示：
- en: '![Figure 6.7 – Model result DataFrame](img/B19923_06_7.jpg)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![图6.7 – 模型结果DataFrame](img/B19923_06_7.jpg)'
- en: Figure 6.7 – Model result DataFrame
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.7 – 模型结果DataFrame
- en: Having observed a comprehensive cycle encompassing model development, registration,
    and deployment, it’s noteworthy that this process is replicable for any model-building
    endeavor through the model registry. In the subsequent section, we will elucidate
    several beneficial methods inherent in the model registry, elevating its usability
    and augmenting the overall modeling experience. Now that we have deployed the
    model, we will look at other model registry methods.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在观察了涵盖模型开发、注册和部署的全面周期后，值得注意的是，此过程可以通过模型注册表复制到任何模型构建任务中。在下一节中，我们将阐明模型注册表中固有的几个有益方法，提高其可用性并增强整体建模体验。现在我们已经部署了模型，我们将探讨其他模型注册表方法。
- en: Model registry methods
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型注册表方法
- en: Beyond the functionality outlined for model deployment, the model registry extends
    its utility with several beneficial methods designed for effective model maintenance
    and housekeeping activities. In this section, we will explore a selection of these
    methods to enhance our understanding of their practical applications. We will
    start with model metrics.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 除了概述的模型部署功能外，模型注册表通过几个旨在有效维护和日常管理活动的有益方法扩展了其效用。在本节中，我们将探讨这些方法中的一些，以增强我们对其实际应用的了解。我们将从模型指标开始。
- en: Model metrics
  id: totrans-75
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 模型指标
- en: 'Linking metrics to your model version is a pivotal feature within the model
    registry. This functionality serves as a fundamental aspect, providing a systematic
    means to gauge the performance of each model version distinctly. By associating
    metrics, users gain valuable insights into the efficacy of different iterations,
    facilitating informed decision-making based on the quantitative evaluation of
    model performance across various versions. It also helps in automating the pipeline,
    thereby retraining if model metrics drop below the threshold value. This deliberate
    metrics integration enriches the comprehensive model management capabilities and
    establishes a structured framework for ongoing model evaluation and refinement:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 将指标链接到您的模型版本是模型注册库中的一个关键功能。此功能作为基本方面，提供了一种系统性的方法来区分测量每个模型版本的性能。通过关联指标，用户可以获得关于不同迭代有效性的宝贵见解，便于根据跨各个版本的模型性能的定量评估做出明智的决策。它还有助于自动化流程，如果模型指标低于阈值值，则重新训练。这种故意的指标集成丰富了全面的模型管理功能，并建立了一个结构化的框架，用于持续模型评估和改进：
- en: '[PRE13]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The preceding line sets a custom metric, `mean_abs_pct_err`, for a specific
    model version in the model registry, assigning the calculated MAPE value to quantify
    the model’s performance. It enhances the model registry’s ability to track and
    evaluate the effectiveness of different model versions:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 上一行设置了一个自定义指标 `mean_abs_pct_err`，用于模型注册库中特定模型版本，将计算出的 MAPE 值分配给该模型以量化其性能。这增强了模型注册库跟踪和评估不同模型版本有效性的能力：
- en: '[PRE14]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'This will print the following output:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这将打印以下输出：
- en: '![Figure 6.8 – MAPE value of mean_abs_pct_err](img/B19923_06_8.jpg)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.8 – mean_abs_pct_err 的 MAPE 值](img/B19923_06_8.jpg)'
- en: Figure 6.8 – MAPE value of mean_abs_pct_err
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.8 – mean_abs_pct_err 的 MAPE 值
- en: 'In addition to setting, we can retrieve the value of a specific custom metric,
    `mean_abs_pct_err`, associated with a particular model version from the model
    registry. It allows users to access and analyze quantitative performance metrics
    for practical model evaluation and comparison across different versions:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 除了设置之外，我们还可以从模型注册库中检索与特定模型版本关联的特定自定义指标 `mean_abs_pct_err` 的值。它允许用户访问和分析定量性能指标，以进行实际模型评估和不同版本之间的比较：
- en: '[PRE15]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Much like retrieving a specific metric for a deployed model, an analogous approach
    allows us to access a comprehensive list of all associated metrics for a given
    deployed model. This facilitates a holistic understanding of the model’s performance,
    providing a detailed overview of various metrics related to its evaluation and
    contributing to a thorough analysis of its effectiveness:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于检索已部署模型的特定指标，类似的方法允许我们访问给定已部署模型的所有相关指标的综合列表。这有助于全面理解模型性能，提供有关其评估的各种指标的详细概述，有助于对其有效性进行全面分析：
- en: '![Figure 6.9 – Metrics of mean_abs_pct_err](img/B19923_06_9.jpg)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.9 – mean_abs_pct_err 的指标](img/B19923_06_9.jpg)'
- en: Figure 6.9 – Metrics of mean_abs_pct_err
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.9 – mean_abs_pct_err 的指标
- en: We can find the value of metrics from the model in the registry. In the next
    section, we will cover model tags and descriptions.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在注册库中找到模型的指标值。在下一节中，我们将介绍模型标签和描述。
- en: Model tags and descriptions
  id: totrans-89
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 模型标签和描述
- en: 'Setting a tag name and description for a deployed model is crucial for effective
    experiment tracking and documentation. Tags and descriptions provide context and
    insights into the model’s purpose, configuration, and notable characteristics.
    This aids in maintaining a structured and informative record, enhancing reproducibility,
    and facilitating a more comprehensive analysis of experiment outcomes:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 为已部署模型设置标签名称和描述对于有效的实验跟踪和文档至关重要。标签和描述提供了关于模型目的、配置和显著特性的背景和见解。这有助于维护结构化和信息化的记录，提高可重复性，并促进对实验结果的更全面分析：
- en: '[PRE16]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The provided code first sets a tag named `stage` with the `experiment_1` value
    for a specific model version in the model registry. This tagging is a contextual
    marker for the model’s purpose or usage. The subsequent line retrieves and displays,
    in a tabular format, the names of all models along with their associated tags,
    showcasing the tagged information for each model:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 提供的代码首先为模型注册库中特定模型版本设置了一个名为 `stage` 的标签，值为 `experiment_1`。这种标记是模型目的或使用的上下文标记。随后的行检索并显示所有模型的名称及其相关标签，展示了每个模型的标记信息：
- en: '![Figure 6.10 – Model tags](img/B19923_06_10.jpg)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.10 – 模型标签](img/B19923_06_10.jpg)'
- en: Figure 6.10 – Model tags
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.10 – 模型标签
- en: 'Another noteworthy aspect is the flexibility to modify and remove tags as necessary,
    allowing for a dynamic adjustment of our experiment design. This capability empowers
    users to iteratively refine contextual information associated with a model, providing
    meaningful and evolving tags. The ability to alter and remove tags enhances experiment
    design flexibility. It ensures that the documentation and context surrounding
    models can adapt to changing insights and requirements throughout the experimentation
    lifecycle:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个值得注意的方面是，可以根据需要修改和删除标签，允许动态调整我们的实验设计。这种能力使用户能够迭代地改进与模型关联的上下文信息，提供有意义的、不断发展的标签。修改和删除标签的能力增强了实验设计的灵活性。它确保了模型周围的文档和上下文能够适应实验生命周期中不断变化的见解和要求：
- en: '[PRE17]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The provided code initiates the removal of a specific tag, named `usage`, from
    a particular model version within the model registry. Following this operation,
    the subsequent line retrieves and displays, in a tabular format, the names of
    all models along with their associated tags. This showcases the updated information
    after removing the specified tag, providing a comprehensive view of models and
    their altered tag configurations:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 提供的代码启动从模型注册表中删除特定标签的操作，该标签名为`usage`，针对特定模型版本。在此操作之后，下一行检索并以表格格式显示所有模型的名称及其关联的标签。这展示了删除指定标签后的更新信息，提供了模型及其更改的标签配置的全面视图：
- en: '![Figure 6.11 – Model tags removed](img/B19923_06_11.jpg)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![图6.11 – 移除的模型标签](img/B19923_06_11.jpg)'
- en: Figure 6.11 – Model tags removed
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.11 – 移除的模型标签
- en: 'We can also provide descriptive information for a deployed model, offering
    valuable context and aiding future references. The ability to furnish a meaningful
    description enhances the comprehensibility of the model’s purpose, configuration,
    or other pertinent details. The ensuing code block, which is self-explanatory
    and mirrors the process of setting tags, enables the assignment of a descriptive
    narrative to a deployed model, ensuring that vital information is encapsulated
    for reference in subsequent analyses or experiments:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以为部署的模型提供描述性信息，提供有价值的背景知识并有助于未来的参考。提供有意义的描述增强了模型目的、配置或其他相关细节的可理解性。以下代码块是自我解释的，并反映了设置标签的过程，它允许将描述性叙述分配给部署的模型，确保关键信息在后续分析或实验中得以封装：
- en: '[PRE18]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The model description is set and can be retrieved to display on the screen:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 模型描述已设置并可检索以在屏幕上显示：
- en: '![Figure 6.12 – Model description](img/B19923_06_12.jpg)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![图6.12 – 模型描述](img/B19923_06_12.jpg)'
- en: Figure 6.12 – Model description
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.12 – 模型描述
- en: Now that we have the model tags and description set, we will examine how to
    access the registry history.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经设置了模型标签和描述，我们将探讨如何访问注册表的历史记录。
- en: Registry history
  id: totrans-106
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注册表历史
- en: 'Accessing the registry history is an invaluable capability, offering a chronological
    account of model versions, associated metrics, tags, and descriptions. This historical
    perspective enhances transparency in model development and empowers data scientists
    to make informed decisions, track performance trends, and iterate on model improvements
    with precision. The ML registry, coupled with its history-tracking feature, thus
    emerges as a pivotal asset in the data science arsenal, fostering a structured
    and efficient approach to model development, deployment, and ongoing refinement:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 访问注册表历史是一项非常有价值的特性，它提供了模型版本、相关指标、标签和描述的按时间顺序的记录。这种历史视角增强了模型开发中的透明度，并使数据科学家能够做出明智的决定，跟踪性能趋势，并精确地迭代改进模型。因此，ML注册表及其历史跟踪功能成为数据科学工具箱中的关键资产，促进了模型开发、部署和持续改进的结构化和高效方法：
- en: '[PRE19]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The code retrieves and converts the entire history of the model registry into
    a `pandas` DataFrame, presenting a comprehensive tabular view of all recorded
    events and changes:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 代码检索并将模型注册表的整个历史记录转换为`pandas` DataFrame，以表格形式全面展示所有记录的事件和变更：
- en: '![Figure 6.13 – Registry history](img/B19923_06_13.jpg)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![图6.13 – 注册表历史](img/B19923_06_13.jpg)'
- en: Figure 6.13 – Registry history
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.13 – 注册表历史
- en: 'Narrowing down the search in the registry history is a common practice, and
    it can be achieved by specifying a model name and version. This targeted filtering
    allows for more focused exploration, aligning with typical preferences when navigating
    the model registry history:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在注册表历史记录中缩小搜索范围是一种常见做法，可以通过指定模型名称和版本来实现。这种有针对性的过滤允许进行更深入的探索，与在模型注册表历史记录中导航时的典型偏好相一致：
- en: '[PRE20]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'This code fetches and converts the specific history of a particular model version,
    identified by its name and version, into a `pandas` DataFrame:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码获取并转换特定模型版本的特定历史记录，通过其名称和版本标识，将其转换为`pandas` DataFrame：
- en: '![Figure 6.14 – Registry history filter](img/B19923_06_14.jpg)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.14 – 注册表历史过滤器](img/B19923_06_14.jpg)'
- en: Figure 6.14 – Registry history filter
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.14 – 注册表历史过滤器
- en: The resulting DataFrame offers a detailed chronological record of all events
    and changes associated with that specific model version within the registry. In
    the next section, we will learn about operations on the model registry.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的 DataFrame 提供了与该特定模型版本在注册表中相关的所有事件和变化的详细时间记录。在下一节中，我们将学习关于模型注册表的操作。
- en: Model registry operations
  id: totrans-118
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 模型注册表操作
- en: 'In the contemporary landscape of ML, the lifecycle of models is continually
    contracting, leading to shorter durations for deployed models. Concurrently, experiments
    with varying parameters generate many models, and their subsequent deployments
    are registered. This proliferation necessitates a thoughtful approach to model
    management, including periodic cleanup processes to maintain a streamlined and
    efficient model registry:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在当代机器学习领域，模型的生命周期正在不断缩短，导致部署模型的持续时间变短。同时，具有不同参数的实验产生了许多模型，它们的后续部署被注册。这种激增需要一种深思熟虑的方法来管理模型，包括定期的清理过程，以保持模型注册表的流畅和高效：
- en: '[PRE21]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The preceding code deletes a specific deployment instance identified by the
    model’s name, version, and deployment name from the model registry, ensuring efficient
    cleanup and management of deployed models:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 上一段代码通过模型名称、版本和部署名称从模型注册表中删除特定的部署实例，确保部署模型的清理和管理高效：
- en: '![Figure 6.15 – Deleting a specific deployment](img/B19923_06_15.jpg)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.15 – 删除特定部署](img/B19923_06_15.jpg)'
- en: Figure 6.15 – Deleting a specific deployment
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.15 – 删除特定部署
- en: 'It serves as a method to remove obsolete or undesired deployments. We can also
    delete a whole model from the registry by using the following code:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 它作为删除过时或不希望部署的方法。我们还可以使用以下代码从注册表中删除整个模型：
- en: '[PRE22]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Similar to deleting a deployment, this code will delete a model from the model
    registry:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 与删除部署类似，此代码将从模型注册表中删除一个模型：
- en: '![Figure 6.16 – Deleting a model](img/B19923_06_16.jpg)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.16 – 删除模型](img/B19923_06_16.jpg)'
- en: Figure 6.16 – Deleting a model
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.16 – 删除模型
- en: We can see that the entire model has been deleted from the registry. In the
    next section, we will look at the benefits of a model registry.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到整个模型已从注册表中删除。在下一节中，我们将探讨模型注册表的好处。
- en: Benefits of the model registry in the model lifecycle
  id: totrans-130
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型生命周期中模型注册表的好处
- en: 'The Snowpark model registry streamlines the management of ML models throughout
    their lifecycle. Let’s delve into how the model registry in Snowpark can assist
    in various stages of the ML model lifecycle:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: Snowpark 模型注册表简化了整个生命周期中机器学习模型的管理。让我们深入了解 Snowpark 中的模型注册表如何协助机器学习模型生命周期的各个阶段：
- en: '**Model development**: During the development phase, data scientists can use
    Snowpark to build, train, and validate ML models directly within Snowflake. The
    model registry provides a centralized location to store and version control these
    models, making it easier to track changes, compare performance, and collaborate
    with team members.'
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模型开发**：在开发阶段，数据科学家可以使用 Snowpark 在 Snowflake 中直接构建、训练和验证机器学习模型。模型注册表提供了一个集中位置来存储和版本控制这些模型，使得跟踪更改、比较性能和与团队成员协作变得更加容易。'
- en: '**Model deployment**: Once a model is trained and validated, it needs to be
    deployed into production environments for inference. The model registry facilitates
    seamless deployment by providing a standardized interface to deploy models across
    different environments. This ensures consistency and reliability in model deployment
    processes.'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模型部署**：一旦模型经过训练和验证，就需要将其部署到生产环境中进行推理。模型注册表通过提供跨不同环境的标准化接口来促进无缝部署，确保模型部署过程的连贯性和可靠性。'
- en: '**Model monitoring**: Monitoring the performance of deployed models is crucial
    for detecting drift and ensuring continued accuracy over time. The model registry
    can integrate with monitoring tools to track model performance metrics, such as
    accuracy, precision, recall, and F1-score, enabling proactive maintenance and
    optimization.'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模型监控**：监控已部署模型的性能对于检测漂移并确保随着时间的推移持续准确性至关重要。模型注册表可以与监控工具集成，以跟踪模型性能指标，如准确率、精确率、召回率和
    F1 分数，从而实现主动维护和优化。'
- en: '**Model governance**: Ensuring compliance with regulatory requirements and
    organizational policies is essential for responsible AI deployment. The model
    registry supports governance by providing capabilities for access control, audit
    logging, and versioning. This helps organizations maintain visibility and control
    over the entire model lifecycle.'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模型治理**：确保符合监管要求和组织政策对于负责任的AI部署至关重要。模型注册表通过提供访问控制、审计日志和版本控制等功能来支持治理，这有助于组织在整个模型生命周期中保持可见性和控制力。'
- en: '**Model retraining and updating**: ML models need to be periodically retrained
    and updated to adapt to changing data distributions and business requirements.
    The model registry simplifies this process by enabling data scientists to seamlessly
    retrain models using updated data and algorithms while preserving the lineage
    and history of model versions.'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模型再训练和更新**：机器学习模型需要定期再训练和更新以适应不断变化的数据分布和业务需求。模型注册表通过允许数据科学家使用更新的数据和算法无缝再训练模型，同时保留模型版本的世系和历史，简化了这一过程。'
- en: '**Model retirement**: As models become obsolete or are replaced by newer versions,
    they need to be retired gracefully. The model registry facilitates the retirement
    process by archiving outdated models, documenting reasons for retirement, and
    ensuring that relevant stakeholders are notified of changes.'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模型退役**：随着模型变得过时或被更新的版本所取代，它们需要优雅地退役。模型注册表通过存档过时模型、记录退役原因并确保相关利益相关者得到变更通知来简化退役过程。'
- en: The model registry offers an organized framework for model management and provides
    functionalities for efficient housekeeping, including setting and tracking metrics,
    tags, and descriptions. The registry’s history-tracking capabilities have emerged
    as a valuable feature, allowing users to gain insights into the evolution of models
    over time. Tags and descriptions offer context and facilitate experiment tracking
    for accessing and filtering the registry history, enabling a comprehensive view
    of model-related activities. Overall, the model registry emerges as a powerful
    addition to Snowpark ML, centralizing model management, facilitating experimentation,
    and ensuring a streamlined and organized approach to model development and deployment.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 模型注册表提供了一个有组织的框架用于模型管理，并提供了高效维护的功能，包括设置和跟踪指标、标签和描述。注册表的历史跟踪功能已成为一个有价值的特性，使用户能够深入了解模型随时间演化的过程。标签和描述提供了上下文，并促进了实验跟踪，以便访问和过滤注册表的历史记录，从而实现对模型相关活动的全面视图。总的来说，模型注册表成为Snowpark
    ML的一个强大补充，集中管理模型，促进实验，并确保模型开发和部署的流程流畅且有序。
- en: Overall, the model registry in Snowpark plays a pivotal role in streamlining
    the ML model lifecycle, from development and deployment to monitoring, governance,
    retraining, and retirement. By providing a centralized platform for managing models,
    it helps organizations maximize the value of their ML investments while minimizing
    operational overhead and risks.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，Snowpark中的模型注册表在简化机器学习模型的生命周期方面发挥着关键作用，从开发、部署到监控、治理、再训练和退役。通过提供一个集中平台来管理模型，它帮助组织最大化其机器学习投资的效益，同时最小化运营成本和风险。
- en: Managing Snowpark model data
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 管理Snowpark模型数据
- en: In the previous section, we covered the deployment of ML models using the model
    registry. This section will look at managing Snowpark Models using feature stores.
    Snowpark ML Feature Store simplifies the feature engineering process and is integral
    to ML, significantly influencing model performance based on the quality of features
    employed. This chapter will help us learn about using feature stores and managing
    Snowpark models.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '在上一节中，我们介绍了使用模型注册表部署机器学习模型。本节将探讨使用特征存储管理Snowpark模型。Snowpark ML特征存储简化了特征工程过程，对于机器学习至关重要，它显著影响了基于所采用特征的质量的模型性能。本章将帮助我们了解使用特征存储和管理Snowpark模型。 '
- en: Snowpark Feature Store
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Snowpark特征存储
- en: 'The Snowpark Feature Store is an integrated solution for data scientists and
    ML engineers. It facilitates the creation, storage, management, and serving of
    ML features for model training and inference and is accessible through the Snowpark
    ML library. The feature store defines, manages, and retrieves features, supported
    by a managed infrastructure for feature metadata management and continuous feature
    processing. Its primary function is to make these features readily available for
    reuse in the ongoing development of future ML models. Feature stores play a pivotal
    role in operationalizing data input, tracking, and governance within the realm
    of feature engineering for ML:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: Snowpark特征存储库是为数据科学家和机器学习工程师提供的一体化解决方案。它简化了机器学习特征在模型训练和推理过程中的创建、存储、管理和提供，并通过Snowpark机器学习库进行访问。特征存储库定义、管理和检索特征，由一个用于特征元数据管理和持续特征处理的托管基础设施支持。其主要功能是使这些特征能够方便地用于未来机器学习模型的持续开发。特征存储库在机器学习特征工程领域的数据输入、跟踪和管理中发挥着关键作用：
- en: '![Figure 6.17 – Feature Store](img/B19923_06_17.jpg)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![图6.17 – 特征存储库](img/B19923_06_17.jpg)'
- en: Figure 6.17 – Feature Store
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.17 – 特征存储库
- en: By leveraging the Snowpark Feature Store, which is designed to simplify and
    enhance this process by offering increased efficiency for data scientists and
    ML practitioners. ML teams can uphold a singular and updated source of truth for
    model training, versioning, and inference features. We will use the *Bike Sharing*
    dataset and the ML model developed in the previous section to showcase how the
    Feature Store enhances the model development and deployment cycle.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 通过利用Snowpark特征存储库，该库旨在通过提供更高的效率来简化并增强这一过程，数据科学家和机器学习从业者可以保持模型训练、版本控制和推理特征的单一、更新源。我们将使用*共享单车*数据集和前一小节中开发的机器学习模型来展示特征存储库如何增强模型开发和部署周期。
- en: Benefits of Feature Store
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征存储库的好处
- en: Utilizing feature stores provides several benefits for ML initiatives. Firstly,
    they enable feature reuse by saving developed features, allowing them to be quickly
    accessed and repurposed for new ML models, thereby saving time and effort. Secondly,
    they ensure feature consistency by providing a centralized registry for all ML
    features, maintaining consistent definitions and documentation across teams. Thirdly,
    feature stores help maintain peak model performance by centralizing feature pipelines,
    ensuring consistency between training and inference, and continuously monitoring
    data pipelines for any discrepancies.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 利用特征存储库为机器学习项目提供了几个好处。首先，它们通过保存已开发的特征，允许快速访问和重新用于新的机器学习模型，从而节省时间和精力。其次，它们通过提供一个集中注册所有机器学习特征的注册表，确保跨团队保持一致的定义和文档。第三，特征存储库通过集中管理特征管道，确保训练和推理之间的一致性，并持续监控数据管道中的任何差异，帮助维持模型的最佳性能。
- en: Furthermore, feature stores enhance security and data governance by providing
    detailed information about each ML model’s training data and deployment data,
    facilitating iteration and debugging. Integrating feature stores with cloud data
    warehouses enhances data security, ensuring the protection of both models and
    training data. Lastly, feature stores foster collaboration between teams by offering
    a centralized platform for the development, storage, modification, and sharing
    of ML features, promoting cross-team collaboration and idea-sharing for multiple
    business applications.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，特征存储库通过提供有关每个机器学习模型训练数据和部署数据的详细信息，增强了安全和数据治理，促进了迭代和调试。将特征存储库与云数据仓库集成增强了数据安全性，确保模型和训练数据都得到保护。最后，特征存储库通过提供一个集中平台，用于开发、存储、修改和共享机器学习特征，促进了团队间的协作和思想共享，适用于多种商业应用。
- en: Feature stores versus data warehouses
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征存储库与数据仓库的比较
- en: Delving into the distinction between feature stores and data warehouses sheds
    light on their collaborative role in enhancing value within ML projects.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 深入探讨特征存储库与数据仓库之间的区别，有助于了解它们在增强机器学习项目价值中的协作作用。
- en: Similarities – shared traits and functions
  id: totrans-152
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 相似性 – 共同特性和功能
- en: Both feature stores and data warehouses exhibit parallels in their operational
    methodologies. They rely on **Extract, Transform, Load** (**ETL**) pipelines to
    facilitate data management and accessibility. Additionally, they serve as repositories
    endowed with metadata, fostering seamless data sharing and utilization across
    organizational teams.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 特征存储库和数据仓库在运营方法上表现出相似之处。它们都依赖于 **提取、转换、加载**（**ETL**）管道来促进数据管理和可访问性。此外，它们作为具有元数据的存储库，促进了组织团队之间的无缝数据共享和利用。
- en: End users – tailored utility
  id: totrans-154
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 最终用户 – 定制化效用
- en: A notable deviation lies in their primary user base. Data warehouses traditionally
    cater to analysts entrenched in the generation of comprehensive business reports,
    delving into historical data for strategic insights. Conversely, feature stores
    cater specifically to data scientists immersed in the development of predictive
    ML models. While the latter may draw from data warehouses for supplementary insights,
    their core function revolves around leveraging feature stores for streamlined
    model development and inference.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 一个显著的差异在于它们的主要用户群体。数据仓库传统上服务于深陷于生成全面业务报告的分析师，深入历史数据以获取战略洞察。相反，特征存储库专门服务于沉浸在预测
    ML 模型开发中的数据科学家。虽然后者可能从数据仓库中获取补充洞察，但他们的核心功能是利用特征存储库以简化模型开发和推理。
- en: Data types – structural variances
  id: totrans-156
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据类型 – 结构差异
- en: Structurally, data warehouses house domain-specific data within relational databases
    characterized by well-defined schemas. This structured format facilitates streamlined
    querying and retrieval of pertinent information, ideal for analytical endeavors.
    Conversely, feature stores house a distinct array of feature values crucial for
    ML model training. These values encompass both quantitative and categorical variables,
    enriching the model development process with granular insights.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 结构上，数据仓库在具有良好定义模式的数据库中存储特定领域的数据。这种结构化格式简化了相关信息的查询和检索，非常适合分析工作。相反，特征存储库包含用于 ML
    模型训练的关键特征值集合。这些值包括定量和分类变量，为模型开发过程提供了细粒度的洞察。
- en: ETL pipelines – divergent trajectories
  id: totrans-158
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ETL 管道 – 分歧的轨迹
- en: The operational dynamics of ETL pipelines further accentuate the disparity between
    feature stores and data warehouses. ETL processes within data warehouses predominantly
    focus on data cleansing and transformation, ensuring data accuracy and coherence
    within the defined schema. In contrast, feature store pipelines embark on a more
    intricate journey, encompassing data extraction, transformation, and feature engineering.
    The transformations within feature stores often entail sophisticated computations
    and aggregations to distill intricate insights vital for model training and inference,
    underscoring their pivotal role in the ML lifecycle.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: ETL 管道的运营动态进一步突出了特征存储库和数据仓库之间的差异。数据仓库中的 ETL 流程主要关注数据清洗和转换，确保在定义的方案中数据的准确性和一致性。相比之下，特征存储库的管道则涉及更复杂的旅程，包括数据提取、转换和特征工程。特征存储库中的转换通常涉及复杂的计算和聚合，以提炼对模型训练和推理至关重要的复杂洞察，强调了它们在
    ML 生命周期中的关键作用。
- en: Now that we’ve grasped the essence of feature stores, comprehending their significance
    and differentiation from data warehouses, let’s delve deeper into the various
    components comprising a feature store.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经掌握了特征存储库的本质，理解了它们与数据仓库的区别和重要性，让我们更深入地探讨构成特征存储库的各个组成部分。
- en: 'In the subsequent section, we’ll embark on the creation of a rudimentary feature
    store tailored to the *Bike Sharing* dataset, focusing solely on weather-related
    features. The process entails the following:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将开始创建一个针对 *共享单车* 数据集的基本特征存储库，专注于与天气相关的特征。这个过程包括以下步骤：
- en: Feature store creation
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建特征存储库
- en: Feature entity creation
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建特征实体
- en: Selecting and transforming weather features
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择和转换天气特征
- en: Creating a feature view
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个特征视图
- en: Generating datasets enriched with the feature view
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成包含特征视图的丰富数据集
- en: Constructing an ML model empowered by the enriched dataset
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建一个由丰富数据集支持的 ML 模型
- en: Facilitating predictions based on the trained model
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 促进基于训练模型的预测
- en: Let’s discuss each of them in detail.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们详细讨论每一个。
- en: Creating a feature store
  id: totrans-170
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 创建一个特征存储库
- en: 'Initiating work with the Snowflake Feature Store involves establishing a new
    feature store or connecting to an existing one. This is accomplished by furnishing
    specific details to the `FeatureStore` constructor, including a Snowpark session,
    database name, feature store name, and default warehouse name. The `creation_mode`
    parameter is crucial in determining whether a new feature store should be created
    if it does not exist. To implement this functionality, we’ll use the following
    code:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 开始使用Snowflake特征存储涉及创建一个新的特征存储或连接到现有的一个。这是通过向`FeatureStore`构造函数提供特定细节来完成的，包括Snowpark会话、数据库名称、特征存储名称和默认仓库名称。`creation_mode`参数对于确定是否应该创建一个新特征存储（如果不存在）至关重要。为了实现这一功能，我们将使用以下代码：
- en: '[PRE23]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: This will open a session to the feature store and allow it to be accessed in
    the Snowpark session. The next step will be to set up a feature entity on this
    feature store.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 这将打开一个到特征存储的会话，并允许在Snowpark会话中访问它。下一步将是设置此特征存储上的特征实体。
- en: Creating feature entities
  id: totrans-174
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 创建特征实体
- en: 'Entities are fundamental elements linked with features and feature views, providing
    the cornerstone for feature lookups by defining join keys. Users can generate
    novel entities and formally register them within the feature store, thereby fostering
    connections and relationships between various features. This code creates an entity
    named `WEATHER` with an `ID` join key, registers it in the feature store (`fs`),
    and then displays a list of entities in the feature store:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 实体是与特征和特征视图相关的基本元素，通过定义连接键为特征查找提供基石。用户可以生成新的实体并在特征存储中正式注册它们，从而促进各种特征之间的连接和关系。此代码创建了一个名为`WEATHER`的实体，具有`ID`连接键，将其注册在特征存储（`fs`）中，然后显示特征存储中的实体列表：
- en: '[PRE24]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'This generates the following output:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成以下输出：
- en: '![Figure 6.18 – Feature entity](img/B19923_06_18.jpg)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![图6.18 – 特征实体](img/B19923_06_18.jpg)'
- en: Figure 6.18 – Feature entity
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.18 – 特征实体
- en: The `ENTITY_WEATHER` entity has been created with the ID as the join key. The
    next step is to set up feature views.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '`ENTITY_WEATHER`实体已创建，ID作为连接键。下一步是设置特征视图。'
- en: Creating feature views
  id: totrans-181
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 创建特征视图
- en: Within a feature store, feature views act as comprehensive pipelines, systematically
    transforming raw data into interconnected features at regular intervals. These
    feature views are materialized from designated source tables, ensuring incremental
    and efficient updates as fresh data is introduced. In our previous chapter, we
    explored a dataset that comprised various weather-related features. To preprocess
    this data effectively, we employed a Snowpark pipeline.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 在特征存储中，特征视图充当综合管道，系统性地将原始数据在固定时间间隔内转换为相互关联的特征。这些特征视图从指定的源表实例化，确保在引入新数据时增量且高效地更新。在我们之前的章节中，我们探索了一个包含各种天气相关特征的数据集。为了有效地预处理这些数据，我们使用了Snowpark管道。
- en: 'Through this pipeline, we performed transformations on the `SEASON` and `WEATHER`
    columns using one-hot encoding techniques. Additionally, we normalized the `TEMP`
    column to ensure consistency and facilitate model training. Given that we thoroughly
    discussed each step of this pipeline in our previous chapter, we’ll be revisiting
    it briefly, focusing more on a high-level overview rather than delving into detailed
    explanations:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这个管道，我们对`SEASON`和`WEATHER`列使用了独热编码技术进行转换。此外，我们对`TEMP`列进行了归一化，以确保一致性并便于模型训练。鉴于我们在之前的章节中详细讨论了此管道的每个步骤，我们将简要回顾它，更多地关注高级概述而不是深入解释：
- en: '[PRE25]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'This code block utilizes Snowflake’s ML capabilities for data preprocessing.
    It imports necessary modules such as preprocessing functions and the `Pipeline`
    class. The code creates a new `ID` column with unique identifiers for each row
    and drops unnecessary columns. It defines lists of categorical columns and their
    transformed versions after one-hot encoding, along with columns to be normalized.
    Additionally, it specifies categories for each categorical column, likely for
    encoding purposes, facilitating effective ML model processing:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 这个代码块利用了Snowflake的机器学习能力进行数据预处理。它导入了必要的模块，例如预处理函数和`Pipeline`类。代码创建了一个新的`ID`列，为每一行提供唯一的标识符，并删除了不必要的列。它定义了分类列及其经过独热编码后的版本列表，以及需要归一化的列。此外，它还指定了每个分类列的类别，可能用于编码目的，从而便于有效的机器学习模型处理：
- en: '[PRE26]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: In the first step, an ordinal encoder (`OE`) is applied to transform categorical
    columns specified in the `CATEGORICAL_COLUMNS` list into their one-hot encoded
    versions, as defined by the `CATEGORICAL_COLUMNS_OHE` list. The `categories` parameter
    specifies the categories for each categorical column, likely used for encoding
    purposes.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一步中，对 `CATEGORICAL_COLUMNS` 列表中指定的类别列应用有序编码器 (`OE`)，将其转换为 `CATEGORICAL_COLUMNS_OHE`
    列表中定义的独热编码版本。`categories` 参数指定每个类别列的类别，可能用于编码目的。
- en: In the second step, a min-max scaler (`MMS`) is used to normalize columns specified
    in the `MIN_MAX_COLUMNS` list. This scaler ensures that values in these columns
    are scaled to a specific range, typically between `0` and `1`, while preserving
    their relative proportions.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二步中，使用 min-max 缩放器 (`MMS`) 对 `MIN_MAX_COLUMNS` 列表中指定的列进行归一化。此缩放器确保这些列中的值缩放到特定的范围，通常是
    `0` 到 `1` 之间，同时保留它们的相对比例。
- en: 'The preprocessing pipeline is then applied to the `df` DataFrame using the
    fit-transform paradigm, where the pipeline is first fit to the data to learn parameters
    (for example, category mappings for ordinal encoding), and then applied to transform
    the DataFrame. The transformed DataFrame is then displayed using the `show()`
    method. Overall, this code prepares the DataFrame for further analysis or model
    training by preprocessing its columns using the specified pipeline. The resultant
    DataFrame is as follows:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 预处理管道随后应用于 `df` DataFrame，使用 fit-transform 模式，其中管道首先拟合到数据以学习参数（例如，用于有序编码的类别映射），然后应用于转换
    DataFrame。转换后的 DataFrame 然后使用 `show()` 方法显示。总体而言，此代码通过使用指定的管道预处理其列，为进一步分析或模型训练准备
    DataFrame。结果 DataFrame 如下所示：
- en: '![Figure 6.19 – Transformed DataFrame](img/B19923_06_19.jpg)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.19 – 转换后的 DataFrame](img/B19923_06_19.jpg)'
- en: Figure 6.19 – Transformed DataFrame
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.19 – 转换后的 DataFrame
- en: 'Throughout the model-building process, various models are constructed using
    subsets of features, such as weather features and time-related features. Additionally,
    models are developed using combined data to ascertain superior performance. To
    expedite the model-building process and reduce data engineering overheads, we’ll
    organize weather-related features into a dedicated feature view. Subsequently,
    we’ll leverage this feature view to generate datasets and construct an XGBoost
    model in the ensuing section:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 在整个模型构建过程中，使用特征子集构建了各种模型，例如天气特征和时间相关特征。此外，通过组合数据开发模型以确保卓越的性能。为了加速模型构建过程并减少数据工程开销，我们将与天气相关的特征组织到一个专用的特征视图中。随后，我们将利用这个特征视图在接下来的部分生成数据集并构建
    XGBoost 模型：
- en: '[PRE27]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The code selects specific columns from the DataFrame to create a feature DataFrame
    (`feature_df`). Then, it constructs a feature view named `WEATHER_FEATURES` associated
    with the previously defined entity and registers it in the feature store (`fs`)
    with version `V1`. The resulting DataFrame is as follows:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 代码从 DataFrame 中选择特定列以创建特征 DataFrame (`feature_df`)。然后，它构建一个名为 `WEATHER_FEATURES`
    的特征视图，与之前定义的实体相关联，并在特征存储库 (`fs`) 中以版本 `V1` 注册。结果 DataFrame 如下所示：
- en: '![Figure 6.20 – Feature DataFrame](img/B19923_06_20.jpg)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.20 – 特征 DataFrame](img/B19923_06_20.jpg)'
- en: Figure 6.20 – Feature DataFrame
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.20 – 特征 DataFrame
- en: Once developed, features can be systematically stored in the feature store,
    fostering their availability for reuse or seamless sharing among various ML models
    and teams. This functionality significantly accelerates the creation of new ML
    models, eliminating the redundancy of building each feature from scratch. In the
    same way, we can create another feature view as rental features by combining similar
    features.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦开发完成，特征可以系统地存储在特征存储库中，从而促进它们在各种机器学习模型和团队之间的重用或无缝共享。这一功能显著加速了新机器学习模型的创建，消除了从头开始构建每个特征的冗余。同样，我们可以通过组合相似的特征来创建另一个特征视图，作为租赁特征。
- en: Preparing the dataset
  id: totrans-198
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 准备数据集
- en: 'Once our feature pipelines are meticulously configured and ready, we can initiate
    their deployment to generate training data. Subsequently, these feature pipelines
    become instrumental in facilitating model prediction, marking the seamless transition
    from feature engineering to the practical application of ML models:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们的特征管道被精心配置并准备就绪，我们可以启动它们的部署以生成训练数据。随后，这些特征管道成为促进模型预测的关键工具，标志着从特征工程到机器学习模型实际应用的顺利过渡：
- en: '[PRE28]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Creating training data becomes straightforward as materialized feature views
    inherently encompass crucial metadata such as join keys and timestamps for **point-in-time**
    (**PIT**) lookup:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 创建训练数据变得简单，因为物化特征视图本身包含关键元数据，如用于**点时间**（**PIT**）查找的连接键和时间戳：
- en: '![Figure 6.21 – Training data](img/B19923_06_21.jpg)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.21 – 训练数据](img/B19923_06_21.jpg)'
- en: Figure 6.21 – Training data
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.21 – 训练数据
- en: The process primarily involves supplying spine data—termed so because it serves
    as the foundational structure enriched by feature joins. In our case, spine data
    encompasses the feature to be predicted—`COUNT`—along with the join key column
    ID. Moreover, the flexibility to generate datasets with subsets of features within
    the feature view is available through slicing. Now that we have the training data
    ready, we will use it to train the model and predict the data output using the
    feature store.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '该过程主要涉及提供脊柱数据——之所以称为脊柱数据，是因为它作为由特征连接丰富的基础结构。在我们的案例中，脊柱数据包括要预测的特征——`COUNT`——以及连接键列
    ID。此外，通过切片，可以灵活地生成包含特征视图内特征子集的数据集。现在我们已经准备好了训练数据，我们将使用它来训练模型并使用特征存储库预测数据输出。 '
- en: The preparation of all data—both for training and operational use—requires meticulous
    handling through feature pipelines. These pipelines, resembling traditional data
    pipelines, aggregate, validate, and transform data output in a format suitable
    for input into the ML model. Properly orchestrated feature pipelines ensure that
    data is refined before being fed into the model, maintaining the integrity and
    relevance of features derived from the training process.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 所有数据的准备——无论是用于训练还是运营使用——都需要通过特征管道进行细致的处理。这些管道类似于传统数据管道，它们汇总、验证和转换数据输出，使其适合输入到
    ML 模型中。适当的特征管道编排确保在数据被输入到模型之前对其进行精炼，从而保持从训练过程中提取的特征的完整性和相关性。
- en: Model training
  id: totrans-206
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 模型训练
- en: 'We covered the model-building process extensively in the previous chapter,
    so in this section, we will focus on building it using the training dataset generated
    from feature views from the feature store. We are using a similar method outlined
    in the previous chapter in training a gradient boost model but just using feature
    views:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一章中，我们详细介绍了模型构建过程，因此在本节中，我们将专注于使用从特征存储库的特征视图生成的训练数据集来构建模型。我们在训练梯度提升模型时使用了与上一章类似的方法，但只是使用了特征视图：
- en: '[PRE29]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The elegance of Snowpark surfaces in this simplicity, as no significant modifications
    are needed to train a model using feature views seamlessly. We will create testing
    data to test the model for accuracy using the following code:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: Snowpark 的优雅之处体现在这种简单性上，因为使用特征视图无缝训练模型不需要进行任何重大修改。我们将创建测试数据，使用以下代码测试模型的准确性：
- en: '[PRE30]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'This creates a test DataFrame (`test_df`) by selecting the `ID` column from
    the first three rows of `spine_df`. Then, it retrieves and displays feature values
    for the test data frame using the feature store and training data generated from
    feature views:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 这通过从 `spine_df` 的前三行中选择 `ID` 列创建了一个测试 DataFrame (`test_df`)。然后，它使用特征存储库和从特征视图生成的训练数据检索并显示测试数据框的特征值：
- en: '![Figure 6.22 – Testing data](img/B19923_06_22.jpg)'
  id: totrans-212
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.22 – 测试数据](img/B19923_06_22.jpg)'
- en: Figure 6.22 – Testing data
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.22 – 测试数据
- en: Now that the testing data is ready, we can predict the model using this data
    to get the results.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 现在测试数据已经准备好了，我们可以使用这些数据来预测模型并获取结果。
- en: Model prediction
  id: totrans-215
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 模型预测
- en: 'In this section, we will use the testing data generated from the feature store
    to make a prediction:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用从特征存储库生成的测试数据来进行预测：
- en: '[PRE31]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The prediction displays the results with the predicted count value, showing
    the number of customers using shared bikes at the given hour:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 预测结果显示了预测的计数值，显示了在给定小时使用共享自行车的客户数量：
- en: '![Figure 6.23 – Model prediction](img/B19923_06_23.jpg)'
  id: totrans-219
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.23 – 模型预测](img/B19923_06_23.jpg)'
- en: Figure 6.23 – Model prediction
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.23 – 模型预测
- en: This shows how easy and improved it is to use a feature store to build a Snowpark
    ML model. In the next section, we will highlight some benefits of using feature
    stores.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 这展示了使用特征存储库构建 Snowpark ML 模型的简便性和改进。在下一节中，我们将强调使用特征存储库的一些好处。
- en: When to utilize versus when to avoid feature stores
  id: totrans-222
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 何时使用特征存储库以及何时避免使用特征存储库
- en: 'Feature stores are particularly advantageous in ML processes when there’s a
    need for efficient feature management and reuse across multiple models or teams.
    They shine in the following scenarios:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 特征存储库在需要高效管理特征并在多个模型或团队之间重用的情况下特别有利。它们在以下场景中表现出色：
- en: '**Feature reuse**: Features need to be reused or shared between different ML
    models or teams, reducing redundant efforts in feature engineering'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特征重用**：特征需要在不同的机器学习模型或团队之间重用或共享，以减少特征工程中的重复工作'
- en: '**Consistency and governance**: Ensuring consistent definitions, documentation,
    and governance of features across diverse ML projects or teams is critical'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**一致性和治理**：确保在多样化的机器学习项目或团队中，特征的定义、文档和治理保持一致至关重要'
- en: '**Model performance**: Maintaining peak model performance by ensuring consistency
    between feature definitions in training and inference pipelines, thus avoiding
    performance degradation due to discrepancies'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型性能**：通过确保训练和推理管道中特征定义的一致性来维持模型性能的峰值，从而避免由于差异导致的性能下降'
- en: '**Data collaboration**: Fostering collaboration between different teams or
    stakeholders involved in ML projects by offering a centralized platform for feature
    development, storage, modification, and sharing'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据协作**：通过提供一个集中平台用于特征开发、存储、修改和共享，促进涉及机器学习项目的不同团队或利益相关者的协作'
- en: '**Scalability**: Handling large volumes of features and data efficiently, especially
    in environments where data is continuously evolving or being updated'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可扩展性**：高效处理大量特征和数据，尤其是在数据持续演变或更新的环境中'
- en: 'However, feature stores may not be necessary in the following scenarios:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在以下场景中，特征存储可能并非必要：
- en: '**Simple models**: For simple models with few features and minimal complexity,
    the overhead of setting up and maintaining a feature store may outweigh its benefits'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**简单模型**：对于具有少量特征和最小复杂性的简单模型，设置和维护特征存储的开销可能超过其带来的好处'
- en: '**Static data**: In cases where the data is relatively static and doesn’t require
    frequent updates or feature engineering, the need for a feature store may be limited'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**静态数据**：在数据相对静态且不需要频繁更新或特征工程的情况下，对特征存储的需求可能有限'
- en: '**Limited collaboration**: When ML projects involve a small, tightly-knit team
    working on isolated tasks without the need for extensive collaboration or feature
    sharing, the use of a feature store may be unnecessary'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**有限的协作**：当机器学习项目涉及一个规模小、紧密合作的团队，且不需要广泛协作或特征共享时，使用特征存储可能是不必要的'
- en: '**Resource constraints**: Organizations with limited resources or infrastructure
    may find it challenging to implement and maintain a feature store effectively'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**资源限制**：资源或基础设施有限的组织可能发现有效实施和维护特征存储具有挑战性'
- en: In summary, while feature stores offer numerous benefits for efficient feature
    management in ML projects, their adoption should be carefully considered based
    on the specific needs and constraints of each project or organization.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，虽然特征存储为机器学习项目中的高效特征管理提供了众多好处，但其采用应根据每个项目或组织的具体需求和限制进行仔细考虑。
- en: Summary
  id: totrans-235
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This chapter discussed the model registry and the importance of meaningful tags
    and descriptions, offering context and facilitating experiment tracking. We also
    highlighted different methods of operating with the model registry. We navigated
    through the capabilities of the Snowflake Feature Store within the Snowpark ML
    ecosystem and how to utilize it for managing Snowflake models.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 本章讨论了模型注册表以及有意义的标签和描述的重要性，提供了上下文并促进了实验跟踪。我们还强调了操作模型注册表的不同方法。我们探讨了Snowflake Feature
    Store在Snowpark ML生态系统中的功能，以及如何利用它来管理Snowflake模型。
- en: In the next chapter, we will learn about developing native applications using
    the Snowpark framework.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将学习如何使用Snowpark框架开发原生应用程序。
