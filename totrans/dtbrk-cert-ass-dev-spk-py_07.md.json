["```py\nstream = spark.readStream \\\n  .format(\"csv\") \\\n  .option(\"header\", \"true\") \\\n  .schema(initialSchema) \\\n  .load(\"data/input\")\nmergedStream = stream \\\n  .selectExpr(\"col1\", \"col2\", \"new_col AS col3\")\n```", "```py\nstream1 = spark.readStream.format(\"kafka\")\n.option(\"kafka.bootstrap.servers\", \"localhost:9092\") .option(\"subscribe\", \"topic1\") .load()\nstream2 = spark.readStream.format(\"kafka\").option(\"kafka.bootstrap.servers\",\"localhost:9092\") .option(\"subscribe\", \"topic2\") .load()\n joinedStream =stream1.join(stream2, \"common_key\")\n```", "```py\nstream =spark.readStream.format(\"kafka\")\n.option(\"kafka.bootstrap.servers\", \"localhost:9092\") .option(\"subscribe\", \"topic\") .load()\n  staticData = spark.read.format(\"csv\") .option(\"header\", \"true\") .load(\"data/static_data.csv\")\n enrichedStream = stream.join(staticData,\"common_key\")\n```"]