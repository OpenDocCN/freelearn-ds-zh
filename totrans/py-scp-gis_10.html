<html><head></head><body>
        

                            
                    <h1 class="header-title">Geoprocessing with a GPU Database</h1>
                
            
            
                
<p class="mce-root">With the emergence of multi-core GPUs, new database technologies have been developed to take advantage of this improved technology. MapD, a startup based in San Francisco, is one example of these companies. Their GPU-based database technology was made open source in 2017 and is available for use on cloud services, such as <strong>Amazon Web Services</strong> (<strong>AWS</strong>) and Microsoft Azure. By combining the parallelization potential of GPUs with a relational database, the MapD database improves the speed of database queries and visualizations based on the data. </p>
<p>MapD has created a Python 3 module, <kbd>pymapd</kbd>, that allows users to connect to the database and automate queries. This Python binding allows geospatial professionals to integrate the speed of a GPU database into an existing geospatial architecture, adding speed improvements to analysis and queries. Both of MapD's core offerings (the open source community version and the commercial enterprise version) are supported by <kbd>pymapd</kbd>. </p>
<p>In addition to the Python module, MapD has added geospatial capabilities to their database technology. Storage of points, lines, and polygons is now supported, as is a spatial analysis engine that offers distance and contains functionality. Also, MapD has developed a visualization component, <strong>Immerse</strong>, that allows for analytical dashboards to be built quickly, with the database as a backend. </p>
<p>In this chapter, we will cover the following topics:</p>
<ul>
<li>Create a GPU database in the cloud</li>
<li>Explore data visualizations using Immerse and the SQL EDITOR </li>
<li>Use <kbd>pymapd</kbd> to load spatial and tabular data into the database</li>
<li>Use <kbd>pymapd</kbd> to query the database</li>
<li>Integrate the cloud database into a GIS architecture</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Cloud geodatabase solutions</h1>
                
            
            
                
<p>Cloud storage of geospatial data has become a common part of many GIS architectures. Whether it is used as a backup to an on-premises solution, replaces an on-premises solution, or is combined with a local solution to provide internet support for an intranet-based system, the cloud is a big part of the future of GIS. </p>
<p>With ArcGIS Online, CARTO, MapBox, and now MapD, the options for a cloud data store that support geospatial data are more numerous than ever. Each offers a visualization component and a different type of data storage and each will integrate with your data and software in different ways.</p>
<p>ArcGIS Online, while also offering stand-alone options (that is, direct data upload), integrates with ArcGIS Enterprise (formerly ArcGIS Server) to consume enterprise <strong>REpresentational State Transfer</strong> (<strong>REST</strong>) web services that are stored on a local geodatabase. ArcGIS Online is built on top of <strong>Amazon Web Services</strong> (<strong>AWS</strong>) and all of the server architecture is hidden from users. Enterprise integration requires a high-level of licensing (cost), which includes a number of cloud tokens (that is credits), and storage and analysis within the cloud account itself can use lots of those tokens.</p>
<p>CARTO offers cloud PostGIS storage, allowing for geospatial data files to be uploaded. With the release of the Python package CARTOframes (covered in <a href="d8f80a31-ec1a-47f5-bcdb-015b5502a86f.xhtml" target="_blank">Chapter 14</a><a href="d8f80a31-ec1a-47f5-bcdb-015b5502a86f.xhtml"/>, <em>Cloud Geodatabase Analysis and Visualization</em>), the cloud datasets can be uploaded and updated using scripting. Using Python, a CARTO account can become a part of an enterprise solution that maintains up-to-date datasets while allowing them to be quickly deployed as custom web maps using the builder application. CARTO offers two tiers of paid accounts which have different levels of storage.</p>
<p>MapBox is focused on map tools for creating custom basemaps for mobile apps, but it also offers cloud data storage of datasets and map creation tools such as MapBox GL, the JavaScript library for maps built on the <strong>Web Graphics Library</strong> (<strong>WebGL</strong>). With the new MapBox GL—Jupyter module, the data can be accessed using Python. </p>
<p>MapD, while offering similar solutions to those mentioned, is different in a number of respects. It has an open source version of the database (MapD Core Community Edition) which can be used locally or on the cloud, and has an enterprise version for large customers. While MapD Core has a relational database schema and uses SQL for queries like a traditional RDBMS, it uses GPUs to accelerate queries. MapD Core can be cloud-deployed on AWS, Google Cloud Platform, and Microsoft Azure. MapD can be installed on servers without GPUs as well, though this reduces its effective speed gains over other geodatabases.</p>
<p>All of the geodatabases support Jupyter Notebook environments for data queries, but MapD has them integrated into the SQL EDITOR within the Immerse visualization platform. MapD uses Apache Arrow to upload data when using <kbd>pymapd</kbd> and also supports <kbd>INSERT</kbd> statements while allowing for data to be loaded using the Immerse data importer (including SHPs, GeoJSONs, and CSVs).</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Big data processing</h1>
                
            
            
                
<p>For data science analysis and geospatial analysis, encountering big data is more common than ever. MapD is incredibly fast when retrieving rows and return data to the client, making it really useful for powering real-time databases or for performing queries on huge datasets. </p>
<p>MapD offers amazing speed-ups on processing big datasets compared to CPU-bound databases. Because of the high number of cores that each GPU card contains, paralleled processes can run faster. This means that datasets numbering in the billions can be queried and analyzed in milliseconds.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">MapD architecture</h1>
                
            
            
                
<p>The architecture of MapD is a combination of MapD Core (the GPU-based database), MapD Immerse (the data visualization component), and other associated technologies and APIs that support data science operations and geospatial applications:</p>
<div><img src="img/7289cd8e-2c11-4635-8fe0-92a6caa26914.png"/></div>
<p>With the fast query speed and APIs, as well as <kbd>pymapd</kbd>, the components can be used together or separately to create geodatabases and visualizations. Drivers for multiple data importers exist to help data migration and the Thrift API can supply data for export or for communication with software packages and Immerse.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Cloud versus local versus combined</h1>
                
            
            
                
<p>With many different types of organizations depending on geodatabases, the options for architecture are also quite varied. While some organizations have moved all of their data to the cloud, storing data and analysis tools on different servers, most maintain an on-premise geodatabase as the enterprise system. </p>
<p>A third architecture style, which balances between cloud-based and local geodatabases, is also very popular. This allows for database backups to be supported by always available cloud services and for data services to reach outside of organizational firewalls while limiting the datasets and services that are exposed to the internet.</p>
<p>The balance between these solutions depends on the need for processing speed and storage costs. MapD, which can be installed and maintained locally or can be hosted in the cloud, fits all kinds of organizational requirements. The speed of queries and data processing allows cloud data resources to be used in the same manner as locally-stored datasets. With <kbd>pymapd</kbd>, datasets can easily be mirrored in the cloud while maintained locally and can be integrated into geospatial analyses by comparing locally stored data to cloud-based data. </p>
<p>The technological structure your organization chooses will depend on your needs and the size of the datasets both produced and ingested from other sources. MapD can become a part of this structure or can be the entire GIS, supporting Spatial SQL queries at blazing speeds whether located on-premise, in the cloud or both. </p>


            

            
        
    

        

                            
                    <h1 class="header-title">Creating a MapD instance in the cloud</h1>
                
            
            
                
<p>To explore the possibilities of using a mixed local and cloud-based GIS with MapD Core and MapD Immerse, let's create an instance (a virtual server) in the cloud. This cloud database will be accessed locally, using <kbd>pymapd</kbd> to perform queries and data management tasks.</p>
<p>Using AWS, we can create a server with GPU support. While I am using AWS here, MapD can be loaded into other cloud services, such as Google Cloud and Microsoft Azure, as well as installed locally. These other cloud services have a community edition available as well.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Finding the AMI</h1>
                
            
            
                
<p>I'll use the MapD Community Edition, the open source version of the platform, on a p2.xlarge AWS instance. Pre-built <strong>Amazon Machine Images</strong> (<strong>AMIs</strong>) of the community edition are available. While the core database technology is free, the p2 instance will still have costs associated with it and is not available with the AWS free tier. I chose the p2.xlarge over the recommended p2.8xlarge, reducing the costs per hour from $7 to $1. For low-cost or free evaluation of the software, download and install it on a virtual machine or a dedicated Linux server:</p>
<div><img src="img/7d76508c-0530-4449-a5e5-efa32ab2ccbd.png" style="width:62.00em;height:28.67em;"/></div>
<p>For local installation, download the community edition (both compiled and the source code) from this website: <a href="https://www.mapd.com/community/">https://www.mapd.com/community/</a>.<a href="https://www.mapd.com/community/"/></p>


            

            
        
    

        

                            
                    <h1 class="header-title">Opening an AWS account</h1>
                
            
            
                
<p>Creating the database instance will require an AWS account. Go to <a href="http://aws.amazon.com">aws.amazon.com</a> and sign up for an account. This account will require a credit or debit card that is tied to the account. </p>
<p>Explore the official documentation for installing a MapD AWS AMI here:<br/>
<a href="https://www.mapd.com/docs/latest/getting-started/get-started-aws-ami/">https://www.mapd.com/docs/latest/getting-started/get-started-aws-ami/</a>.<a href="https://www.mapd.com/docs/latest/getting-started/get-started-aws-ami/"/></p>


            

            
        
    

        

                            
                    <h1 class="header-title">Creating a key pair</h1>
                
            
            
                
<p>Generating a key pair will allow you to use secure shell or SSH connections to remote in or remotely access AWS instances. To generate the pair from the EC2 Dashboard, select Key Pairs from the NETWORK &amp;amp;amp; SECURITY group in the left panel after scrolling down:</p>
<div><img src="img/23cf9b5b-ee52-42ff-9017-32f4895dcdea.png"/></div>
<p class="mce-root CDPAlignLeft CDPAlign">Give the key pair a name and push Create to save the private key (with a <kbd>.pem</kbd> extension) in a secure location on your computer or a USB stick. This key will be required each time you connect to the instance using SSH. The corresponding public key (with a <kbd>.pub</kbd> extension) is saved in your AWS account and used to match with the private key when connecting to the instance.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Launching an instance</h1>
                
            
            
                
<p>Once the account is set up, go to EC2 from the AWS Management Console. In the EC2 Dashboard, select Launch Instance to open the AWS instance selection tool:</p>
<div><img src="img/89a29924-67b5-4323-ad02-93f33a0d1ebe.png" style="width:65.00em;height:30.00em;"/></div>


            

            
        
    

        

                            
                    <h1 class="header-title">Picking a version</h1>
                
            
            
                
<p>After clicking on AWS Marketplace on the left panel, search for the MapD database within the marketplace. Entering <kbd>MapD</kbd> into the search box brings up both versions. I chose the MapD core database community edition, as the MapD software is included for free:</p>
<div><img src="img/f047f4d1-0a90-4206-92fd-c545d084fbbf.png" style="width:58.83em;height:23.08em;"/></div>
<p>Select the version of interest by pushing the Select button and go to the Instance Types menu.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Searching for an instance</h1>
                
            
            
                
<p>Within the available Instance Types, only a few are supported. These p2 instances offer different levels of CPUs, memory, and GPUs. I chose the p2.xlarge instance for cost reasons, though the p2.8xlarge is recommended for production-level computing:</p>
<div><img src="img/1309f7f7-9231-4ef8-ba41-19ad6db36f1a.png" style="width:27.83em;height:19.00em;"/></div>
<p>After selecting the instance type, there are a few menus describing the details of the instance and allowing for backup storage within the AWS ecosystem. Set these parameters as required by your organization.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Setting up a security group</h1>
                
            
            
                
<p>The security group settings are important as they control who can access the instance, and where they can access it from. The Source tab allows you to set the machines that can connect to the instance, using IP addresses to determine who is allowed to connect:</p>
<div><img src="img/fb933da1-aba2-48c5-817b-d3ac0c93cd3c.png"/></div>
<p>For security, adjust the Source for SSH to my IP. This can be updated later to allow for connections from anywhere, that is the internet at large. Once that is complete, assign the existing key pair to the instance to ensure that it can be used for direct connections to the command line MapD Core. </p>


            

            
        
    

        

                            
                    <h1 class="header-title">Immerse environment</h1>
                
            
            
                
<p>With the instance set up, accessing the installed Immerse environment can be done using a browser. In the Immerse environment, data can be imported, dashboards can be created, and SQL queries can be executed:</p>
<div><img style="font-size: 1em;" src="img/fde677db-1c94-45a1-b139-72704bfd1a6c.png"/></div>


            

            
        
    

        

                            
                    <h1 class="header-title">Logging in to Immerse</h1>
                
            
            
                
<p>Within the EC2 Dashboard, ensure that the MapD instance is started. Copy the IP address of the instance (the Public IP address, not the Private IP) and the Instance ID, which is located underneath the instances list in the EC2 Dashboard. Ensure that the MapD instance is highlighted to ensure that the Instance ID is correct:</p>
<div><img src="img/04d0cc4e-df64-4df3-a558-c989730b875c.png" style="width:59.25em;height:29.00em;"/></div>
<p>Open a browser and enter the Public IP address in the URL bar, along with port number <kbd>8443</kbd>. Here is an example of the URL: <kbd>https://ec2-54-200-213-68.us-west-2.compute.amazonaws.com:8443/</kbd>.</p>
<p>Make sure that you are using <strong>Hyper Text Transfer Protocol Secure</strong> (<strong>HTTPS</strong>) to connect and that the port number is included. If the browser warns you that the connection is insecure, click through using the Advanced link at the bottom of the page. Once the connection is made, the login page will open with the user and database pre-populated. Add the Instance ID as the password and push Connect:</p>
<div><img src="img/40e726dc-de5e-4539-bdb9-9f2b77a6320a.png" style="width:41.00em;height:39.58em;"/></div>
<p>Read the MapD conditions, click I Agree, and enter the Immerse environment.</p>
<p>Read more about using MapD on AWS here: <a href="https://www.mapd.com/docs/latest/getting-started/get-started-aws-ami/">https://www.mapd.com/docs/latest/getting-started/get-started-aws-ami/</a>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Default dashboards</h1>
                
            
            
                
<p>Once the Immerse environment is started, explore the included default DASHBOARDS to get a sense of what is possible:</p>
<div><img src="img/954b92cf-aae6-4de6-bd4b-d133a6ae08a1.png"/></div>


            

            
        
    

        

                            
                    <h1 class="header-title">NYC taxi dataset</h1>
                
            
            
                
<p>The NYC Taxi Rides dashboard uses a database table with 13 million rows of data points to demonstrate the speed of the database. Every time the map is zoomed, the database is re-queried and the points regenerated in milliseconds. It's quite fun to explore the data and to alter the dashboard to include other chart and map types:</p>
<div><img src="img/4d48e987-1827-43df-ae15-be0530f399df.png"/></div>


            

            
        
    

        

                            
                    <h1 class="header-title">Importing a CSV</h1>
                
            
            
                
<p>Importing a dataset in CSV format is easy using the data importer built into MapD Immerse. Go to the DATA MANAGER and select Import Data. On the next page, click on the Add Files button and load the included City of Juneau addresses CSV dataset using drag and drop.</p>
<p>The data will be loaded and, once loaded, a MapD database table is generated from the uploaded data. Review the data and add a new name or accept the default name (generated from the spreadsheet name). Once Save Table is clicked, the database table will be generated:</p>
<div><img src="img/a64af924-8afe-4457-b4ce-596a9806d026.png"/></div>


            

            
        
    

        

                            
                    <h1 class="header-title">Creating a chart</h1>
                
            
            
                
<p>With a dataset now added to the database, test out MapD Immerse by selecting the DASHBOARDS tab. Here, dynamic charts, tables, histograms, heat maps and more can be created and added to a new dashboard. In this example, a simple donut chart is created using the data loaded from the CSV. The number of records associated with a city name is counted and added to the chart:</p>
<div><img src="img/fed8ddff-c055-4a43-a621-8bb770ee0fea.png"/></div>


            

            
        
    

        

                            
                    <h1 class="header-title">Selections with the SQL EDITOR</h1>
                
            
            
                
<p>Using the built-in SQL EDITOR, SQL statements can be executed. The results will appear in the SQL EDITOR in a Jupyter Notebook-like interactive table:</p>
<div><img src="img/c9b9e05e-02ae-4e1e-b9f1-6866497226f3.png"/></div>
<p>The SQL statements are executed really fast and will include spatial SQL commands that can perform analysis with an SQL select statement.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Use geospatial data</h1>
                
            
            
                
<p>MapD Core supports geometry and geography data types and can also generate interactive maps using coordinate columns to display data with <em>x</em>/<em>y</em> or longitude and latitude pairs. Point maps, heat maps, and choropleth maps can easily be generated and styled using the Immerse dashboard environment:</p>
<div><img src="img/65a2923b-f38d-4380-93cc-d0eecfc6aad7.png"/></div>
<p>This data visualization was created by loading the Calaveras County address CSV from OpenAddresses into my MapD Immerse instance using the DATA MANAGER and then using the LON and LAT columns to create a heat map.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Connecting to the database using a terminal</h1>
                
            
            
                
<p>Connect to the database using the integrated Java-based terminal, or another terminal solution. As my local machine uses Windows, and does not have a terminal integrated into the OS, I have downloaded and installed PuTTY. This free SSH software allows me to connect to Linux command line servers from a Windows machine, using the key pair generated earlier for authentication.</p>
<p>If you are using another terminal solution for Windows or using another operating system, connect to the instance using the correct SSH procedure for the terminal. The steps will be similar, except for the required private key format conversion.</p>
<p>Download the PuTTY terminal here: <a href="https://www.chiark.greenend.org.uk/~sgtatham/putty/">https://www.chiark.greenend.org.uk/~sgtatham/putty/. </a></p>


            

            
        
    

        

                            
                    <h1 class="header-title">PuTTYgen</h1>
                
            
            
                
<p>To authorize any connection to the AWS instance, the private key generated for the AWS account must be converted into a PuTTY key format using the associated program PuTTYgen. Open PuTTYgen from the Start menu, and click on the Conversions menu. From the drop-down tab, select Import Key.</p>
<p>A file dialogue will open, allowing you to select the private key downloaded from AWS. This private key will have a <kbd>.pem</kbd> extension:</p>
<div><img src="img/df08fe1a-7067-4641-b42f-902f945e5b5f.png" style="width:54.42em;height:37.67em;"/></div>
<p>Click Open, and the key will be imported. To generate the private key in the PuTTY format, supply an optional key phrase (a word or few words that further identify the user and which must be remembered), and click the Save Private Key button in the Actions section. Select a folder and save the key, which will now have a <kbd>.ppk</kbd> file extension.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Connection configuration</h1>
                
            
            
                
<p>Connecting to the instance using PuTTY requires some configuration. To create the connection, paste the public IP address of the instance into the Host Name field, check to ensure that the port is set to 22, and that the connection type is SSH. Save the settings in the Saved Sessions section by clicking the Save button:</p>
<div><img src="img/ddfc50d8-e6ef-4272-b2e4-1e31578d1423.png" style="width:35.58em;height:35.67em;"/></div>


            

            
        
    

        

                            
                    <h1 class="header-title">Using the private key</h1>
                
            
            
                
<p>Once the setting is loaded, click on the SSH drop-down on the left. In the new menu, click Auth to switch to a new menu, and then browse to the private key that we converted into PuTTY format:</p>
<div><img src="img/c24f7c6a-90e5-4e2b-9375-c04ad9fbaaf2.png" style="width:32.25em;height:32.17em;"/></div>
<p>Once the key has been located, push Open to establish the connection. To start MapD on the server, go to the <kbd>/raidStorage/prod/mapd/bin</kbd> folder and run the following code, replacing <kbd>{Instance-ID}</kbd> with your instance ID:</p>
<pre><strong>./mapdql mapd -u mapd -p {Instance-ID}</strong></pre>
<p>If you are having trouble establishing the connection, check to make sure that the security group for the AWS instance is set to allow connections from the current computer being used. If the security group setting is my IP and the IP of the computer is different, the connection cannot be made.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Installing pymapd</h1>
                
            
            
                
<p>Installing <kbd>pymapd</kbd> is simple, and supported by both <kbd>conda</kbd> and <kbd>pip</kbd>, the package installer included with Python. I am using <kbd>pip</kbd> for this chapter, but using <kbd>conda</kbd> will not cause any issues and may be recommended for integration with other <kbd>conda</kbd>-supported software.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">The conda install command</h1>
                
            
            
                
<p>Use <kbd>conda install -c conda-forge</kbd> to connect to <kbd>conda forge</kbd>, the repository where the <kbd>pymapd</kbd> module is stored. Refer to <a href="23e9b6f4-e43b-4bf7-bc80-2c1537d5f760.xhtml" target="_blank">Chapter 1</a>, <em>Package Installation and Management</em> for more information on <kbd>conda</kbd>:</p>
<pre><strong>conda install -c conda-forge pymapd</strong></pre>


            

            
        
    

        

                            
                    <h1 class="header-title">The pip install command</h1>
                
            
            
                
<p>The <kbd>pymapd</kbd> module is also available using <kbd>pip</kbd>, the Python installer package. It pulls from <a href="http://PyPi.org">PyPi.org</a>, the Python foundation's repository:</p>
<pre><strong>pip install pymapd</strong></pre>
<p>Once the install command is run, the <kbd>pymapd</kbd> wheel is downloaded and installed along with the required supporting modules:</p>
<div><img src="img/14f78d7c-c56f-4675-836c-44fb982eab45.png"/></div>
<p>Test that the module was installed by opening a Python terminal (or IDLE) and typing <kbd>import pymapd</kbd>. If no errors occur, <kbd>pymapd</kbd> has successfully been installed.</p>
<p>Another option is to download pymapd from GitHub: <a href="https://github.com/mapd/pymapd">https://github.com/mapd/pymapd.</a><a href="https://github.com/mapd/pymapd"/></p>


            

            
        
    

        

                            
                    <h1 class="header-title">Creating a connection</h1>
                
            
            
                
<p>The <kbd>pymapd</kbd> module includes a class called <kbd>connect</kbd> that requires connection information such as username, password, host server IP/domain, and database name (default value for both user and database name is <kbd>mapd</kbd>). For an AWS instance, the default password for MapD Core and MapD Immerse is the instance ID, available in the instance information section in the EC2 Dashboard, as shown earlier.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">User and password</h1>
                
            
            
                
<p>If you are connecting to the AWS AMI MapD instance, use the public IP address as the <kbd>host</kbd> and the instance ID as the <kbd>password</kbd>. Here is the <kbd>connection</kbd> pattern:</p>
<pre>from pymapd import connect<br/>connection = connect(user="mapd", password= "{password}", <br/>     host="{my.host.com}", dbname="mapd")<br/>cursor = connection.cursor()</pre>
<p>Here is an example of what a filled out <kbd>connect</kbd> instantiation could look like:</p>
<pre>connection = connect(user="mapd", password= "i-0ed5ey62se2w8eed3", <br/>  host="ec2-54-212-133-87.us-west-2.compute.amazonaws.com", dbname="mapd")</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Data cursor</h1>
                
            
            
                
<p>To execute the SQL commands (spatial or otherwise), we will create a data <kbd>cursor</kbd>. The <kbd>cursor</kbd> is part of the <kbd>connection</kbd> class and will be used to execute statements using the <kbd>execute</kbd> command. It is also used to access query results, which are converted into a list and iterated using a <kbd>for</kbd> loop:</p>
<pre>from pymapd import connect<br/>connection = connect(user="mapd", password= "{password}", <br/>     host="{my.host.com}", dbname="mapd")<br/><strong>cursor = connection.cursor()</strong><br/>sql_statement = """SELECT name FROM county;"""<br/><strong>cursor.execute(sql_statement)</strong><br/>results = <strong>list(cursor)</strong><br/>for result in results:<br/>    print(<strong>result[0]</strong>)</pre>
<p>The result is a list of tuples, which contain (in this case) only the name of the <kbd>county</kbd>, accessed using a zero index to get it out of the tuple.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Creating a table</h1>
                
            
            
                
<p>With the connection established, we can now execute SQL statements in the Python script that will generate tables in the MapD Core instance. The following statement will create a simple table called <kbd>county</kbd>, with a <kbd>MULTIPOLYGON</kbd> geometry type, an <kbd>integer id</kbd> field, and three <kbd>VARCHAR</kbd>-type fields (or strings, as they would be called in Python):</p>
<pre>from pymapd import connect<br/>connection = connect(user="mapd", password= "{password}", <br/>     host="{my.host.com}", dbname="mapd")<br/>cursor = connection.cursor()<br/>create = """CREATE TABLE county ( id integer NOT NULL, <br/>  name VARCHAR(50), statefips VARCHAR(3), <br/>  stpostal VARCHAR(3), geom MULTIPOLYGON );<br/>"""<br/>cursor.execute(create)<br/>connection.commit()</pre>
<p>The next code block will create a table called <kbd>address</kbd>, with a <kbd>POINT</kbd> geometry type, an <kbd>integer id</kbd> field, and a <kbd>VARCHAR</kbd>-type field called <kbd>address</kbd>:</p>
<pre>from pymapd import connect<br/>connection = connect(user="mapd", password= "{password}", <br/>     host="{my.host.com}", dbname="mapd")<br/>cursor = connection.cursor()<br/>create = """CREATE TABLE address ( id integer NOT NULL PRIMARY KEY, <br/>  address VARCHAR(50), geom Point );<br/>"""<br/>cursor.execute(create)<br/>connection.commit()</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Insert statements</h1>
                
            
            
                
<p>One way to add data to the database is to use SQL <kbd>INSERT</kbd> statements. These will generate rows of data within the database tables created in the last section. Using the <kbd>pyshp</kbd> module, we can read a shapefile and add the data it contains to an <kbd>INSERT</kbd> statement template. This statement is then executed by the <kbd>cursor</kbd>:</p>
<pre>from pymapd import connect<br/>import shapefile<br/>connection = connect(user="mapd", password= "{password}", <br/>     host="{my.host.com}", dbname="mapd")<br/>import shapefile<br/>import pygeoif<br/>cursor = connection.cursor()<br/>insert = """INSERT INTO county<br/>     VALUES ({cid},'{name}','12','FL','{geom}');<br/>"""<br/>countyfile = r'FloridaCounties.shp'<br/>county_shapefile = shapefile.Reader(countyfile)<br/>county_shapes = county_shapefile.shapes()<br/>county_records = county_shapefile.records()<br/>for count, record in enumerate(county_records):<br/>    name = record[3]<br/>    county_geo = county_shapes[count]<br/>    gshape = pygeoif.<strong>Polygon</strong>(pygeoif.geometry.as_shape(county_geo))<br/>    geom = gshape.wkt<br/>    <strong>insert_statement = insert.format(name=name, geom=geom,cid=count+1)</strong><br/>    <strong>cursor.execute(insert_statement)</strong></pre>
<p>This process can be time-consuming, so there are a few other ways to add data to the database.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Using Apache Arrow to load data</h1>
                
            
            
                
<p>Using the <kbd>pyarrow</kbd> module and <kbd>pandas</kbd>, data can be written to the MapD Core database:</p>
<pre>import pyarrow as pa<br/>import pandas as pd<br/>from pymapd import connect<br/>import shapefile<br/>connection = connect(user="mapd", password= "{password}", <br/>     host="{my.host.com}", dbname="mapd")<br/>cursor = connection.cursor()<br/>create = """CREATE TABLE juneau_addresses ( <br/>  LON FLOAT, LAT FLOAT, <br/>  NUMBER VARCHAR(30),STREET VARCHAR(200) );<br/>"""<br/>cursor.execute(create)<br/>df = pd.read_csv('city_of_juneau.csv')<br/>table = pa.Table.from_pandas(df)<br/>print(table)<br/>connection.load_table_arrow("juneau_addresses", table)</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Contains queries</h1>
                
            
            
                
<p>This code will test the speed of a data query against the <kbd>county</kbd> database table, using <kbd>ST_Contains</kbd>, a spatial SQL point in polygon analysis tool. The geometry column of the <kbd>county</kbd> table (called <kbd>geom</kbd>) is the first input into <kbd>ST_Contains</kbd>, and the <strong>well-known text</strong> (<strong>WKT</strong>) <kbd>point</kbd> is added second. Once the SQL statement is executed, the <kbd>point</kbd> will be compared against all of the rows in the table to find if one of the <kbd>county</kbd> geometries contains the <kbd>point</kbd> described by the WKT <kbd>point</kbd>:</p>
<pre>import pymapd<br/>from pymapd import connect<br/>connection = connect(user="mapd", password= "{password}", <br/>     host="{my.host.com}", dbname="mapd")<br/>import time<br/>point = "POINT(-80.896146 27.438610)"<br/>cursor = connection.cursor()<br/>print(time.time())<br/>sql_statement = """SELECT name FROM county where ST_Contains(geom,'{0}');""".format(point)<br/>cursor.execute(sql_statement)<br/>print(time.time())<br/>result = list(cursor)<br/>print(result)<br/>print(time.time())</pre>
<p>The result of this script is as follows:</p>
<div><img src="img/ec9cbdae-bf83-48b6-b254-3a86c8be9036.png"/></div>
<p>The geospatial query runs really fast, as you can see from the printed time signatures (in seconds). It takes only a few milliseconds to find that Okeechobee polygon contains the <kbd>point</kbd> location.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Other available spatial SQL commands</h1>
                
            
            
                
<p>The number of spatial SQL commands available within a MapD Core database is growing all the time. These include:</p>
<ul>
<li><kbd>ST_Transform</kbd> (for coordinate system transformations)</li>
<li><kbd>ST_Distance</kbd> (for distance analyses)</li>
<li><kbd>ST_Point</kbd> (to generate <kbd>point</kbd> objects)</li>
<li><kbd>ST_XMin</kbd>, <kbd>ST_XMax</kbd>, <kbd>ST_YMin</kbd>, <kbd>ST_YMax</kbd> (for bounding box access)</li>
</ul>
<p>More functionality is being added every day and will reach spatial SQL feature parity with PostGIS and other spatial databases later this year. With these SQL commands, and the unique front-end dashboard publication tool MapD Immerse, MapD is a powerful new option for geodatabase deployment.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Summary</h1>
                
            
            
                
<p>Using a cloud-based GPU database like MapD Core, and the Immerse visualization studio will pay dividends when designing and implementing a GIS. It offers speed and cloud reliability to both tabular and spatial queries and allows the data to be shared in interactive dashboards (which rely on JavaScript technologies such as <kbd>D3.js</kbd> and MapBox GL JavaScript) that are simple to create and publish. </p>
<p>With the MapD Python module, <kbd>pymapd</kbd>, cloud data can become an integrated part of a query engine. Data can be pushed to the cloud or pulled down to use locally. Analyses can be performed rapidly, using the power of GPU parallelization. It's worth installing MapD on a virtual server in the cloud, or even locally, to test out the potential of the software.</p>
<p>In the next chapter, we will explore the use of Flask, SQLAlchemy, and GeoAlchemy2 to create an interactive web map with a PostGIS geodatabase backend.</p>
<p> </p>


            

            
        
    </body></html>