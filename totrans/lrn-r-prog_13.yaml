- en: Chapter 13. High-Performance Computing
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 13 章。高性能计算
- en: In the previous chapter, you learned about a number of built-in functions and
    various packages tailored for data manipulation. Although these packages rely
    on different techniques and may be built under a different philosophy, they all
    make data filtering and aggregating much easier.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，您学习了关于数据操作的一些内置函数和针对数据操作的各种包。尽管这些包依赖于不同的技术，并且可能在不同的哲学指导下构建，但它们都使得数据过滤和聚合变得容易得多。
- en: However, data processing is more than simple filtering and aggregating. Sometimes,
    it involves simulation and other computationintensive tasks. Compared to high-performance
    programming languages such as C and C++, R is much slower due to its dynamic design
    and the current implementation that prioritizes stability, ease, and power in
    statistical analysis and visualization over performance and language features.
    However, well-written R code can still be fast enough for most purposes.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，数据处理不仅仅是简单的过滤和聚合。有时，它涉及到模拟和其他计算密集型任务。与 C 和 C++ 等高性能编程语言相比，R 由于其动态设计以及当前实现中优先考虑稳定性和在统计分析与可视化中的易用性和强大功能，而不是性能和语言特性，运行速度要慢得多。然而，编写良好的
    R 代码仍然足够快，可以满足大多数用途。
- en: 'In this chapter, I''ll demonstrate the following techniques to help you write
    R code with high performance:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我将展示以下技术，以帮助您以高性能编写 R 代码：
- en: Measuring code performance
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测量代码性能
- en: Profiling code to find bottleneck
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析代码以找到瓶颈
- en: Using built-in functions and vectorization
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用内置函数和向量化
- en: Using multiple cores by parallel computing
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过并行计算使用多个核心
- en: Writing C++ with Rcpp and related packages
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Rcpp 和相关包编写 C++
- en: Understanding code performance issues
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解代码性能问题
- en: From the very beginning, R is designed for statistical computing and data visualization
    and is widely used by academia and industry. For most data analysis purposes,
    correctness is more important than performance. In other words, getting a correct
    result in 1 minute should be better than getting an incorrect one in 20 seconds.
    A result that is three times faster is not automatically three times more valid
    than a slow but correct result. Therefore, performance should not be a concern
    before you are sure about the correctness of your code.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 从一开始，R 就是为统计计算和数据可视化而设计的，并且被学术界和工业界广泛使用。对于大多数数据分析目的，正确性比性能更重要。换句话说，在 1 分钟内得到正确的结果应该比在
    20 秒内得到错误的结果要好。一个速度快三倍的结果并不自动比一个慢但正确的结果多三倍的有效性。因此，在您确信代码的正确性之前，性能不应成为担忧的问题。
- en: 'Let''s assume that you are 100 percent sure that your code is correct but it
    runs a bit slowly. Now, is it necessary for you to optimize the code so that it
    can run faster. Well, it depends. Before making a decision, it is helpful to divide
    the time of problem solving into three parts: time of development, execution,
    and future maintenance.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 假设您百分之百确信您的代码是正确的，但运行速度有点慢。现在，您是否需要优化代码以使其运行更快？嗯，这取决于。在做出决定之前，将问题解决的时间分为三个部分是有帮助的：开发时间、执行时间和未来的维护时间。
- en: Suppose we have been working on a problem for an hour. Since we didn't take
    performance into account at the beginning, the code does not run very fast. It
    takes us 50 minutes to think about the problem and implement the solution. Then,
    it takes 1 minute to run and produce an answer. Since the code aligns well with
    the problem and looks straightforward, future improvements can be easily integrated
    into the solution, so it takes us less time to maintain.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们已经在一个问题上工作了一个小时。由于我们在一开始没有考虑性能，代码运行得并不快。我们花了 50 分钟来思考问题并实现解决方案。然后，又花了 1
    分钟来运行并产生答案。由于代码与问题匹配得很好，看起来很直接，未来的改进可以很容易地集成到解决方案中，因此我们花费的时间较少来维护。
- en: Then, suppose another developer has been working on the same problem but attempts
    to write an extremely high-performance code at the beginning. It takes time to
    work out a solution to the problem, but takes much more time to optimize the structure
    of the code so that it can run faster. It may take two hours to think of and implement
    a high-performance solution. Then, it takes 0.1 second to run and produce an answer.
    Since the code is particularly optimized to squeeze the hardware, it is probably
    not flexible for future refinement, especially when the problem is updated, which
    would cost more time to maintain.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，假设另一位开发者一直在处理相同的问题，但一开始就试图编写一个极端高性能的代码。解决问题需要时间，但优化代码结构以使其运行更快则需要更多时间。可能需要两小时来思考和实现一个高性能解决方案。然后，运行并产生答案只需要
    0.1 秒。由于代码特别优化以挤压硬件，它可能不适合未来的改进，尤其是在问题更新时，这会花费更多时间来维护。
- en: The second developer can happily claim that her code has 600 times the performance
    of our code, but it may not be worth doing so because it may cost much more human
    time. In many cases, human time is more expensive than computer time.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 第二位开发者可以高兴地宣称她的代码的性能是我们的代码的 600 倍，但这可能不值得这样做，因为它可能需要更多的人工时间。在许多情况下，人工时间比计算机时间更昂贵。
- en: However, if the code is frequently used, say, if billions of iterations are
    required, a small improvement of performance of each iteration can help save a
    large amount of time. In this case, code performance really matters.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果代码经常被使用，比如说，如果需要数十亿次迭代，每次迭代的性能微小提升可以帮助节省大量时间。在这种情况下，代码性能真的很重要。
- en: Let's take an example of a simple algorithm that produces a numeric vector of
    cumulative sum, that is, each element of the output vector is the sum of all previous
    elements of the input vector. The code will be examined in different contexts
    in the discussion that follows.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以一个简单的算法为例，该算法生成一个累积和的数值向量，即输出向量的每个元素是输入向量所有前一个元素的累加和。接下来的讨论中，代码将在不同的上下文中被检查。
- en: 'Although R provides a built-in function, `cumsum`, to do this, we will implement
    an R version at the moment to help understand performance issues. The algorithm
    is easy to implement as follows:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然R提供了一个内置函数`cumsum`来完成这个任务，但我们现在将实现一个R版本来帮助理解性能问题。算法的实现如下：
- en: '[PRE0]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The algorithm only uses a `for` loop to accumulate each element of the input
    vector `x` into `sum_x`. In each iteration, it appends `sum_x` to the output vector
    `y`. We can rewrite the algorithm as the following function:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 该算法仅使用 `for` 循环将输入向量 `x` 的每个元素累加到 `sum_x` 中。在每次迭代中，它将 `sum_x` 添加到输出向量 `y` 中。我们可以将算法重写为以下函数：
- en: '[PRE1]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'An alternative implementation is to use index to access the input vector `x`
    and access/modify the output vector `y`:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种实现方法是使用索引来访问输入向量 `x` 并访问/修改输出向量 `y`：
- en: '[PRE2]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We know that R provides a built-in function `cumsum()` to do exactly the same
    thing. The two preceding implementations should yield exactly the same results
    as `cumsum()`. Here, we will generate some random numbers and check whether they
    are consistent:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道 R 提供了一个内置函数 `cumsum()` 来执行完全相同的事情。前面的两种实现应该会产生与 `cumsum()` 完全相同的结果。在这里，我们将生成一些随机数并检查它们是否一致：
- en: '[PRE3]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: In the preceding code, `all.equal()` checks whether all corresponding elements
    of two vectors are equal. From the results, we are sure that `my_cumsum1()`, `my_cumsum2()`
    and `cumsum()` are consistent. In the next section, we'll measure the time required
    for each version of `cumsum`.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，`all.equal()` 检查两个向量的所有对应元素是否相等。从结果来看，我们可以确信 `my_cumsum1()`、`my_cumsum2()`
    和 `cumsum()` 是一致的。在下一节中，我们将测量 `cumsum` 的每个版本的执行时间。
- en: Measuring code performance
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测量代码性能
- en: Although the three functions will output the same results given the same input,
    their performance difference can be quite obvious. To reveal the difference in
    performance, we need tools to measure the execution time of code. The simplest
    one is `system.time()`.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这三个函数在给定相同输入的情况下会输出相同的结果，但它们的性能差异可能非常明显。为了揭示性能差异，我们需要工具来测量代码的执行时间。最简单的一个是
    `system.time()`。
- en: 'To measure the execution time of any expression, we just wrap the code with
    the function. Here, we will measure how much time it takes by `my_cumsum1()` to
    compute over a numeric vector of 100 elements:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 要测量任何表达式的执行时间，我们只需用函数将其包装起来。在这里，我们将测量 `my_cumsum1()` 计算一个包含 100 个元素的数值向量所需的时间：
- en: '[PRE4]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The timer results in three columns: `user`, `system`, and `elapsed`. It is
    the user time that we should pay more attention to. It measures the CPU time charged
    for executing the code. For more details, run `?proc.time` and see the difference
    between these measures.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 计时器结果显示了三列：`user`、`system` 和 `elapsed`。我们应该更加关注的是 `user` 时间。它衡量的是执行代码所花费的 CPU
    时间。对于更多细节，运行 `?proc.time` 并查看这些度量之间的差异。
- en: 'The results suggest that the code simply runs too fast to measure. We can try
    timing `my_cumsum2()`, and the results are mostly the same:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 结果表明代码运行得太快，无法进行测量。我们可以尝试计时 `my_cumsum2()`，结果大致相同：
- en: '[PRE5]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The same thing happens with the built-in function `cumsum()` too:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 对于内置函数 `cumsum()` 也是如此：
- en: '[PRE6]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The timing does not really work because the input is too small. Now, we will
    generate a vector of `1000` numbers and do it again:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 由于输入太小，计时并没有真正起作用。现在，我们将生成一个包含 `1000` 个数字的向量并再次进行测试：
- en: '[PRE7]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Now, we are sure that `my_cumsum1()` and `my_cumsum2()` indeed take some time
    to compute the results but show no remarkable contrast. However, `cumsum()` is
    still too fast to measure.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们确信 `my_cumsum1()` 和 `my_cumsum2()` 确实需要一些时间来计算结果，但它们之间没有明显的差异。然而，`cumsum()`
    函数仍然非常快，难以测量。
- en: 'We will again use a larger input for all three functions and see whether their
    performance difference can be revealed:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将再次使用更大的输入值来测试这三个函数，看看它们的性能差异是否可以被揭示：
- en: '[PRE8]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The result is quite clear: `my_cumsum1()` looks more than 10 times slower than
    `my_cumsum2()`, and `cumsum()` is still way too fast than both our implementations.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 结果非常清晰：`my_cumsum1()` 的速度看起来比 `my_cumsum2()` 慢 10 多倍，而 `cumsum()` 函数的速度仍然远远超过我们的两个实现。
- en: 'Note that the performance difference may not be constant, especially when we
    provide even larger inputs as follows:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，性能差异可能不是恒定的，尤其是当我们提供更大的输入时，如下所示：
- en: '[PRE9]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The preceding results make quite an astonishing contrast: `my_cumsum1()` can
    be 200 times slower than `my_cumsum2()` when the length of input vector is at
    100,000 level. The `cumsum()` function is consistently super fast in all previous
    results.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的结果形成了一个相当惊人的对比：当输入向量的长度达到 100,000 级别时，`my_cumsum1()` 可以比 `my_cumsum2()` 慢
    200 倍。在所有之前的结果中，`cumsum()` 函数始终非常快。
- en: The `system.time()` function can help measure the execution time of a code chunk,
    but it is not very accurate. On the one hand, each time, the measure can result
    in different values so that we should repeat the timing for enough times to make
    a valid comparison. On the other hand, the resolution of the timer may not be
    high enough to address the real difference in performance of the code of interest.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '`system.time()` 函数可以帮助测量代码块执行时间，但它并不非常准确。一方面，每次测量可能会得到不同的值，因此我们应该重复计时足够多次，以便进行有效的比较。另一方面，计时器的分辨率可能不足以反映我们感兴趣的代码的实际性能差异。'
- en: 'A package named `microbenchmark` serves as a more accurate solution to comparing
    the performance of different expressions. To install the package, run the following
    code:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 一个名为 `microbenchmark` 的包可以作为比较不同表达式性能的更准确解决方案。要安装该包，请运行以下代码：
- en: '[PRE10]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'When the package is ready, we will load the package and call `microbenchmark()`
    to directly compare the performance of the three functions:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 当包准备就绪时，我们将加载该包并调用 `microbenchmark()` 来直接比较这三个函数的性能：
- en: '[PRE11]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Note that `microbenchmark()`, by default, runs each expression 100 times so
    that it can provide more quantiles of the execution time. Maybe to your surprise,
    `my_cumsum1()` is a bit faster than `my_cumsum2()` when the input vector has 100
    elements. Also, note that the unit of the time numbers is nanoseconds (1 second
    is 1,000,000,000 nanoseconds).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，默认情况下，`microbenchmark()` 函数会运行每个表达式 100 次，以便提供更多执行时间的分位数。也许会让你感到惊讶，当输入向量为
    100 个元素时，`my_cumsum1()` 比起 `my_cumsum2()` 来说要快一点。另外，请注意，时间数字的单位是纳秒（1 秒等于 1,000,000,000
    纳秒）。
- en: 'Then, we will try an input of `1000` numbers:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将尝试一个包含 `1000` 个数字的输入：
- en: '[PRE12]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Now, `my_cumsum2()` gets a bit faster than `my_cumsum1()`, but both are way
    slower than the built-in `cumsum()`. Note that the unit becomes microseconds now.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，`my_cumsum2()` 的速度比 `my_cumsum1()` 快一点，但两者都比内置的 `cumsum()` 慢得多。请注意，单位现在变成了微秒。
- en: 'For input of `5000` numbers, the performance difference between `my_cumsum1()`
    and `my_cumsum2()` gets even greater:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 `5000` 个数字的输入，`my_cumsum1()` 和 `my_cumsum2()` 之间的性能差异变得更大：
- en: '[PRE13]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The same thing happens with an input of `10000` elements:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 当输入为 `10000` 个元素时，同样的事情发生了：
- en: '[PRE14]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: In all previous benchmarks, the performance of `cumsum()` looks very stable
    and does not increase significantly as the length of input increases.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有之前的基准测试中，`cumsum()` 的性能看起来非常稳定，并且随着输入长度的增加，性能没有显著增加。
- en: 'To better understand the performance dynamics of the three functions, we will
    create the following function to visualize how they perform, provided an input
    of different lengths:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解三个函数的性能动态，我们将创建以下函数来可视化它们在不同长度输入下的表现：
- en: '[PRE15]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The logic of the function is straightforward: `ns` is a vector of all lengths
    of input vectors we want to test with these functions. Note that `microbenchmark()`
    returns in a data frame of all tests results, and `summary(microbenchmark())`
    returns the summary table we saw previously. We tag each summary with `n`, stack
    all benchmark results, and use the `ggplot2` package to visualize the results.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 函数的逻辑非常直接：`ns` 是一个向量，包含了我们想要用这些函数测试的所有输入向量的长度。请注意，`microbenchmark()` 返回一个包含所有测试结果的数据框，而
    `summary(microbenchmark())` 返回我们之前看到的摘要表。我们用 `n` 标记每个摘要，堆叠所有基准测试结果，并使用 `ggplot2`
    包来可视化结果。
- en: 'First, we will do the benchmarking from `100` to `3000` elements of step `100`:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将从 `100` 到 `3000` 个元素，步长为 `100` 进行基准测试：
- en: '[PRE16]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Then, we will create a plot to show contrast between the performance of the
    three functions:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将创建一个图表来展示三个函数性能的对比：
- en: '[PRE17]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'This produces the following benchmarks of the three versions of `cumsum` we
    intend to compare:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这产生了以下三个版本的 `cumsum` 的基准测试，我们打算进行比较：
- en: '![Measuring code performance](img/image_13_001.jpg)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![测量代码性能](img/image_13_001.jpg)'
- en: In the preceding chart, we put together the results of all three functions.
    The dots indicate the median, and the error bar shows the 75^(th) and 25^(th)
    quantile.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的图表中，我们将三个函数的结果汇总在一起。点表示中位数，误差条表示第 75 分位数和第 25 分位数。
- en: It is very clear that the performance of `my_cumsum1()` decreases faster for
    longer input, the performance of `my_cumsum2()` almost decreases linearly as the
    input gets longer, while `cumsum(x)` is extremely fast and its performance does
    not seem to decay significantly as the input gets longer.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 很明显，`my_cumsum1()` 在较长输入下的性能下降得更快，`my_cumsum2()` 的性能几乎随着输入长度的增加而线性下降，而 `cumsum(x)`
    非常快，其性能似乎不会随着输入长度的增加而显著下降。
- en: 'For small input, `my_cumsum1()` can be faster than `my_cumsum2()`, as we demonstrated
    earlier. We can do a benchmarking that focuses more on small input:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 对于小输入，`my_cumsum1()` 可以比 `my_cumsum2()` 快，正如我们之前所展示的。我们可以进行一个更专注于小输入的基准测试：
- en: '[PRE18]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'This time, we will limit the length of input vector from `2` to `500` of stop
    `10`. Since the functions will be executed almost twice the number of times than
    the previous benchmarking, to keep the total execution time down, we will reduce
    `times` from the default `100` to `50`:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这次，我们将输入向量的长度限制在 `2` 到 `500` 个元素，停止条件为 `10`。由于函数将执行的次数几乎是之前基准测试的两倍，为了保持总执行时间较低，我们将
    `times` 从默认的 `100` 减少到 `50`：
- en: '[PRE19]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The following graphics illustrates the performance difference at smaller inputs:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的图形说明了较小输入下的性能差异：
- en: '![Measuring code performance](img/image_13_002.jpg)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![测量代码性能](img/image_13_002.jpg)'
- en: From the chart, we can see that for small input of less than around `400` numbers,
    `my_cumsum1()` is faster than `my_cumsum2()`. The performance of `my_cumsum1()`
    decays much faster than `my_cumsum2()` as the input gets more elements.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 从图表中，我们可以看到，对于小于大约 `400` 个数字的小输入，`my_cumsum1()` 比较快。随着输入元素的增加，`my_cumsum1()`
    的性能衰减比 `my_cumsum2()` 快得多。
- en: 'The dynamics of performance ranking can be better illustrated by a benchmarking
    of input from `10` to `800` elements:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 通过对从 `10` 到 `800` 个元素的输入进行基准测试，可以更好地说明性能排名的动态：
- en: '[PRE20]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The plot generated is shown as follows:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的图表如下所示：
- en: '![Measuring code performance](img/image_13_003.jpg)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![测量代码性能](img/image_13_003.jpg)'
- en: In conclusion, a small difference in implementation may result in big performance
    gaps. For a small input, the gap is usually not obvious, but when the input gets
    larger, the performance difference can be very significant and thus should not
    be ignored. To compare the performance of multiple expressions, we can use `microbenchmark`
    instead of `system.time()` to get more accurate and more useful results.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，实现上的微小差异可能会导致性能差距很大。对于小输入，差距通常不明显，但当输入变大时，性能差异可能非常显著，因此不应被忽视。为了比较多个表达式的性能，我们可以使用
    `microbenchmark` 而不是 `system.time()` 来获得更准确和更有用的结果。
- en: Profiling code
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能分析代码
- en: In the previous section, you learned how to use `microbenchmark()` to benchmark
    expressions. This can be useful when we have several alternative solutions to
    a problem and want to see which has better performance and when we optimize an
    expression and want to see whether the performance actually gets better than the
    original code.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，你学习了如何使用 `microbenchmark()` 来基准测试表达式。这在我们有几个问题解决方案的替代方案并想看到哪个性能更好，或者当我们优化一个表达式并想看到性能是否真的比原始代码更好时非常有用。
- en: However, it is usually the case that, when we feel the code is slow, it is not
    easy to locate the expression that contributes most to slowing down the entire
    program. Such an expression is called a "performance bottleneck." To improve code
    performance, it is best to resolve the bottleneck first.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，通常情况下，当我们觉得代码运行缓慢时，很难定位到对整个程序减慢贡献最大的表达式。这样的表达式被称为“性能瓶颈”。为了提高代码性能，最好先解决瓶颈。
- en: Fortunately, R provides profiling tools to help us find the bottleneck, that
    is, the code that runs most slowly, which should be the top focus for improving
    code performance.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，R 提供了分析工具来帮助我们找到瓶颈，即运行最慢的代码，这应该是提高代码性能的首要关注点。
- en: Profiling code with Rprof
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Rprof 进行代码分析
- en: R provides a built-in function, `Rprof()`, for code profiling. When profiling
    starts, a sampling procedure is running with all subsequent code until the profiling
    is ended. The sampling basically looks at which function R is executing every
    20 milliseconds by default. In this way, if a function is very slow, it is likely
    that most of the execution time is spent on that function call.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: R 提供了一个内置函数 `Rprof()` 用于代码分析。当分析开始时，会运行一个采样过程，直到分析结束。默认情况下，采样会查看 R 每隔 20 毫秒执行哪个函数。这样，如果一个函数非常慢，那么大部分执行时间可能都花在了这个函数调用上。
- en: The sampling approach may not produce very accurate results, but it serves our
    purpose in most cases. In the following example, we will use `Rprof()` to profile
    the code in which we call `my_cumsum1()` and try to find which part slows down
    the code.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 样本方法可能不会产生非常准确的结果，但在大多数情况下它都能满足我们的需求。在下面的例子中，我们将使用 `Rprof()` 来分析调用 `my_cumsum1()`
    的代码，并尝试找出哪个部分减慢了代码。
- en: 'The way of using `Rprof()` is very simple: call `Rprof()` to start profiling,
    run the code you want to profile, call `Rprof(NULL)` to stop profiling, and finally
    call `summaryRprof()` to see the profiling summary:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `Rprof()` 的方法非常简单：调用 `Rprof()` 开始分析，运行你想要分析的代码，调用 `Rprof(NULL)` 停止分析，最后调用
    `summaryRprof()` 查看分析摘要：
- en: '[PRE21]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Note that we used `tempfile()` to create a temporary file to store profiling
    data. If we don't supply such a file to `Rprof()`, it will automatically create
    `Rprof.out` in the current working directory. The default also applies to `summaryRprof()`.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们使用了 `tempfile()` 创建一个临时文件来存储分析数据。如果我们不向 `Rprof()` 提供这样的文件，它将自动在当前工作目录中创建
    `Rprof.out`。默认情况下，这也适用于 `summaryRprof()`。
- en: 'The profiling results summarize the profiling data into a readable format:
    `$by.self` sorts the timing by `self.time`, while `$by.total` sorts by `total.time`.
    More specifically, the `self.time` of a function is the time spent executing code
    in the function only, and the `total.time` of a function is the total execution
    time of the function.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 分析结果将分析数据总结成可读的格式：`$by.self` 按照执行时间 `self.time` 排序，而 `$by.total` 按照总执行时间 `total.time`
    排序。更具体地说，一个函数的 `self.time` 是该函数中执行代码所花费的时间，而一个函数的 `total.time` 是该函数的总执行时间。
- en: To figure out which part slows down the function, we should pay more attention
    to `self.time` because it addresses the independent time of execution of each
    function.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 为了找出哪个部分减慢了函数，我们应该更加关注 `self.time`，因为它涉及到每个函数执行的独立时间。
- en: The preceding profiling results show that `c` takes up a major part of the execution
    time, that is, `y <- c(y, sum_x)` contributes most to slowing down the function.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的分析结果显示，`c` 占用了主要的执行时间，也就是说，`y <- c(y, sum_x)` 对函数的减慢贡献最大。
- en: 'We can do the same thing to `my_cumsum2()`. The profiling results suggest that
    most time is spent on `my_cumsum2()`, but that is normal because that''s the only
    thing we do in the code. No particular function in `my_cumsum2()` takes up major
    part of time to execute:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以对 `my_cumsum2()` 做同样的事情。分析结果显示，大部分时间都花在了 `my_cumsum2()` 上，这是正常的，因为代码中我们只做了这件事。`my_cumsum2()`
    中没有特定的函数占用了大量的执行时间：
- en: '[PRE22]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: In a practical situation, the code we want to profile is usually complicated
    enough. It may involve many different functions. Such a profiling summary can
    be less helpful if we only see the timing of each function it tracks. Fortunately,
    `Rprof()` supports line profiling, that is, it can tell us the timing of each
    line of code when we specify `line.profiling = TRUE` and use `source(..., keep.source
    = TRUE)`.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际情况下，我们想要分析的性能代码通常足够复杂。它可能涉及许多不同的函数。如果我们只看到跟踪的每个函数的计时，这样的分析总结可能不太有帮助。幸运的是，`Rprof()`
    支持行分析，也就是说，当我们指定 `line.profiling = TRUE` 并使用 `source(..., keep.source = TRUE)`
    时，它可以告诉我们每行代码的计时。
- en: 'We will create a script file at `code/my_cumsum1.R` with the following code:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在 `code/my_cumsum1.R` 创建一个脚本文件，包含以下代码：
- en: '[PRE23]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Then, we will profile this script file with `Rprof()` and `source()`:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将使用 `Rprof()` 和 `source()` 来分析这个脚本文件：
- en: '[PRE24]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: This time, it no longer shows function names but line numbers in the script
    file. We can easily locate the lines that cost most time by looking at the top
    rows in `$by.self`. The `my_cumsum1.R#6` file refers to `y <- c(y, sum_x)`, which
    is consistent with the previous profiling results.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 这次，它不再显示函数名，而是显示脚本文件中的行号。我们可以通过查看 `$by.self` 的顶部行轻松地定位耗时最多的行。`my_cumsum1.R#6`
    文件指的是 `y <- c(y, sum_x)`，这与之前的分析结果一致。
- en: Profiling code with profvis
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 profvis 分析代码
- en: The `Rprof()` function provides useful information to help us find which part
    of the code is too slow so that we can improve the implementation. RStudio also
    released an enhanced profiling tool, `profvis` ([https://rstudio.github.io/profvis/](https://rstudio.github.io/profvis/)),
    which provides interactive visualization for profiling R code.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '`Rprof()` 函数提供了有用的信息，帮助我们找到代码中太慢的部分，以便我们可以改进实现。RStudio 还发布了一个增强的分析工具 `profvis`
    ([https://rstudio.github.io/profvis/](https://rstudio.github.io/profvis/))，它为
    R 代码提供了交互式可视化分析。'
- en: 'It is an R package and has been integrated into RStudio. To install the package,
    run the following code:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 它是一个 R 包，并且已经集成到 RStudio 中。要安装包，请运行以下代码：
- en: '[PRE25]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'As soon as the package is installed, we can use `profvis` to profile an expression
    and visualize the results:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦安装了包，我们就可以使用 `profvis` 来分析一个表达式并可视化结果：
- en: '[PRE26]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'When the profiling is finished, a new tab will appear with an interactive user
    interface:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 分析完成后，将出现一个带有交互式用户界面的新标签页：
- en: '![Profiling code with profvis](img/image_13_004.jpg)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![使用 profvis 分析代码](img/image_13_004.jpg)'
- en: The upper pane shows the code, memory usage, and timing, whereas the lower pane
    shows the timeline of function calling as well as when garbage collection occurs.
    We can click and select a certain line of code and see the timeline of function
    execution. Compared with the results produced by `summaryRprof()`, this interactive
    visualization provides much richer information that enables us to know more about
    how the code is executed over a long time. In this way, we can easily identify
    the slow code and some patterns that may induce problems.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 上半部分显示代码、内存使用和计时，而下半部分显示函数调用的时序以及垃圾回收发生的时间。我们可以点击并选择特定的代码行，查看函数执行的时序。与 `summaryRprof()`
    生成的结果相比，这种交互式可视化提供了更丰富的信息，使我们能够更多地了解代码在长时间内的执行情况。这样，我们可以轻松地识别出耗时的代码和一些可能引起问题的模式。
- en: 'We can do exactly the same thing with `my_cumsum2()`:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以用 `my_cumsum2()` 做同样的事情：
- en: '[PRE27]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'This time, the profiling results in the following statistics:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 这次，分析结果如下所示：
- en: '![Profiling code with profvis](img/image_13_005.jpg)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![使用 profvis 分析代码](img/image_13_005.jpg)'
- en: We can easily identify which part takes the most time and decide whether it
    is acceptable. In all code, there is always a part that takes most time, but this
    does not indicate that it is too slow. If the code serves our purpose and the
    performance is acceptable, then there may not be a need to optimize the performance
    at the risk of modifying the code into an incorrect version.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以轻松地识别出哪个部分耗时最多，并决定是否可以接受。在所有代码中，总有一部分耗时最多，但这并不一定意味着它太慢。如果代码满足我们的需求且性能可接受，那么可能没有必要为了修改代码而冒出错误版本的风险来优化性能。
- en: Understanding why code can be slow
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解代码为什么可能慢
- en: In the previous sections, you learned about the tools for timing and profiling
    code. To solve the same problem, one function can be blazing fast, and the other
    can be ridiculously slow. It is helpful to understand what can make code slow.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，你学习了关于代码计时和分析的工具。为了解决相同的问题，一个函数可能运行得非常快，而另一个可能运行得非常慢。了解什么因素会导致代码慢是有帮助的。
- en: First, R is a dynamic programming language. By design, it provides highly flexible
    data structures and code-execution mechanisms. Therefore, it is hard for the code
    interpreter to know in advance how to deal with the next function call until it
    is actually called. This is not the case for strong-typed static programming languages
    such as C and C++. Many things are determined at compile time rather than runtime,
    so the program knows a lot ahead of time, and optimization can be intensively
    performed. By contrast, R trades flexibility for performance, but well-written
    R code can exhibit acceptable, if not good, performance.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，R是一种动态编程语言。按照设计，它提供了高度灵活的数据结构和代码执行机制。因此，代码解释器在函数实际被调用之前很难预先知道如何处理下一个函数调用。这与强类型静态编程语言（如C和C++）的情况不同。许多事情都是在编译时而不是在运行时确定的，因此程序在事先知道很多信息的情况下，可以进行密集的优化。相比之下，R以灵活性换取性能，但编写良好的R代码可以表现出可接受，甚至良好的性能。
- en: The top reason why R code can be slow is that our code may intensively create,
    allocate, or copy data structures. This is exactly why `my_cumsum1()` and `my_cumsum2()`
    show great difference in performance when the input gets longer. The `my_cumsum1()`
    function always grows the vector, which means that in each iteration the vector
    is copied to a new address and a new element is appended. As a result, the more
    iterations we have, the more elements it has to copy, and then the code gets slower.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: R代码可能运行缓慢的最主要原因是我们可能密集地创建、分配或复制数据结构。这正是为什么当输入变长时，`my_cumsum1()`和`my_cumsum2()`在性能上表现出巨大差异的原因。`my_cumsum1()`函数始终扩展向量，这意味着在每个迭代中，向量都会被复制到新的地址，并添加一个新元素。因此，迭代次数越多，它需要复制的元素就越多，然后代码就会变慢。
- en: 'This can be made explicit by the following benchmarking: `grow_by_index` means
    we initialize an empty list. The `preallocated` function means we initialize a
    list with pre-allocated positions, that is, a list of `n NULL` values with all
    positions allocated. In both cases, we modify the `i`^(th) element of the list,
    but the difference is that we''ll grow the first list in each iteration, and this
    does not happen with the second list because it is already fully allocated:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以通过以下基准测试来明确：`grow_by_index`表示我们初始化一个空列表。`preallocated`函数表示我们初始化一个带有预分配位置的列表，即一个包含`n`个`NULL`值的列表，所有位置都已分配。在两种情况下，我们都会修改列表的第`i`个元素，但区别在于我们将在每次迭代中扩展第一个列表，而第二个列表不会发生这种情况，因为它已经完全分配了：
- en: '[PRE28]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The results are clear: intensively growing a list can significantly slow down
    the code, while modifying a pre-allocated list within range is fast. The same
    logic also applies to atomic vectors and matrices. Growing a data structure in
    R is generally slow because it triggers reallocation, that is, copying the original
    data structure to a new memory address. This is very expensive in R, especially
    when the data is large.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是清晰的：密集地扩展列表可以显著减慢代码，而在范围内修改预分配的列表则很快。同样的逻辑也适用于原子向量和矩阵。在R中扩展数据结构通常很慢，因为它会触发重新分配，即把原始数据结构复制到新的内存地址。这在R中非常昂贵，尤其是当数据量很大时。
- en: However, accurate pre-allocation is not always feasible because it requires
    that we know the total number prior to the iteration. Sometimes, we can only ask
    for a result to store repeatedly without knowing the exact total number. In this
    case, maybe it is still a good idea to pre-allocate a list or vector with a reasonable
    length. When the iteration is over, if the number of iterations does not reach
    the pre-allocated length, we can take a subset of the list or vector. In this
    way, we can avoid intensive reallocation of data structures.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，精确的预分配并不总是可行的，因为这要求我们在迭代之前知道总数。有时，我们可能只能反复请求一个结果来存储，而不知道确切的总量。在这种情况下，预先分配一个合理长度的列表或向量可能仍然是一个好主意。当迭代结束时，如果迭代次数没有达到预分配的长度，我们可以取列表或向量的子集。这样，我们可以避免数据结构的密集重新分配。
- en: Boosting code performance
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提升代码性能
- en: In the previous section, we demonstrated how to use profiling tools to identify
    a performance bottleneck in the code. In this section, you will learn about a
    number of approaches to boosting code performance.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们展示了如何使用分析工具来识别代码中的性能瓶颈。在本节中，你将了解许多提升代码性能的方法。
- en: Using built-in functions
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用内置函数
- en: 'Previously, we demonstrated the performance difference between `my_cumsum1()`,
    `my_cumsum2()` and the built-in function `cumsum()`. Although `my_cumsum2()` is
    faster than `my_cumsum1()`, when the input vector contains many numbers, `cumsum()`
    is much faster than them. Also, its performance does not decay significantly even
    as the input gets longer. If we evaluate `cumsum`, we can see that it is a primitive
    function:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 之前，我们展示了`my_cumsum1()`、`my_cumsum2()`和内置函数`cumsum()`之间的性能差异。尽管`my_cumsum2()`比`my_cumsum1()`快，但当输入向量包含许多数字时，`cumsum()`比它们快得多。而且，即使输入变长，其性能也不会显著下降。如果我们评估`cumsum`，我们可以看到它是一个原始函数：
- en: '[PRE29]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'A primitive function in R is implemented in C/C++/Fortran, compiled to native
    instructions, and thus, is extremely efficient. Another example is `diff()`. Here,
    we will implement computing vector difference sequence in R:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: R中的原始函数是用C/C++/Fortran实现的，编译成本地指令，因此效率极高。另一个例子是`diff()`。在这里，我们将实现R中的向量差分序列计算：
- en: '[PRE30]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'We can verify that the implementation is correct:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以验证实现是否正确：
- en: '[PRE31]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Therefore, both `diff_for()` and built-in `diff()` must return the same result
    for the same input:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，`diff_for()`和内置的`diff()`必须对相同的输入返回相同的结果：
- en: '[PRE32]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: However, there's a big gap in performance between the two functions.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这两个函数在性能上存在很大的差距。
- en: '[PRE33]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Built-in functions are, in most cases, way faster than equivalent R implementations.
    This is true not only for vector functions, but also for matrices. For example,
    here is a simple 3 by 4 integer matrix:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 内置函数在大多数情况下都比等效的R实现要快得多。这不仅适用于向量函数，也适用于矩阵。例如，这里是一个简单的3行4列的整数矩阵：
- en: '[PRE34]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'We can write a function to transpose the matrix:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以编写一个函数来转置矩阵：
- en: '[PRE35]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'In the function, we will first create a matrix of the same type as the input,
    but with the number and names of rows and columns exchanged, respectively. Then,
    we will iterate over columns and rows to transpose the matrix:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在函数中，我们首先创建一个与输入相同类型的矩阵，但行和列的数量和名称分别交换。然后，我们将遍历列和行以转置矩阵：
- en: '[PRE36]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The built-in function of matrix transpose is `t()`. We can easily verify that
    both functions return the same results:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵转置的内置函数是`t()`。我们可以很容易地验证这两个函数返回相同的结果：
- en: '[PRE37]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'However, they may exhibit great difference in performance:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，它们在性能上可能存在很大差异：
- en: '[PRE38]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'The performance difference gets even more significant when the input matrix
    is larger. Here, we will create a new matrix with `1000` rows and `25` columns.
    While the results are the same, the performance can be very different:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 当输入矩阵更大时，性能差异变得更加显著。在这里，我们将创建一个新的矩阵，具有`1000`行和`25`列。虽然结果相同，但性能可能会有很大差异：
- en: '[PRE39]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Note that `t()` is a generic function that works with both matrix and data
    frame. S3 dispatching to find the right method for the input, also has some overhead.
    Therefore, directly calling `t.default()` on a matrix is slightly faster:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，`t()`是一个通用函数，它既适用于矩阵也适用于数据框。S3调度以找到适合输入的正确方法，这也带来了一些开销。因此，直接在矩阵上调用`t.default()`会稍微快一些：
- en: '[PRE40]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: All previous examples show that, in most cases, it is much better to use built-in
    functions if provided than reinventing the wheel in R. These functions get rid
    of the overhead of R code and, thus, can be extremely efficient even if the input
    is huge.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 所有之前的例子都表明，在大多数情况下，如果提供了内置函数，使用它们要比在R中重新发明轮子要好得多。这些函数消除了R代码的开销，因此即使输入很大，也可以非常高效。
- en: Using vectorization
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用向量操作
- en: A special subset of built-in functions are arithmetic operators such as `+`,
    `-`, `*`, `/`, `^`, and `%%`. These operators are not only extremely efficient
    but also vectorized.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 内置函数的特殊子集是算术运算符，如`+`、`-`、`*`、`/`、`^`和`%%`。这些运算符不仅效率极高，而且支持向量操作。
- en: 'Suppose we implement `+` in R:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们在R中实现`+`操作符：
- en: '[PRE41]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Then, we would randomly generate `x` and `y`. The `add(x, y)`, and `x + y` arguments
    should return exactly the same results:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将随机生成`x`和`y`。`add(x, y)`和`x + y`参数应该返回完全相同的结果：
- en: '[PRE42]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'The following benchmarking shows that the performance difference is huge:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 以下基准测试表明性能差异巨大：
- en: '[PRE43]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Now, suppose we need to calculate the sum of the reciprocal of first `n` positive
    integers squared. We can easily implement the algorithm using a `for` loop as
    the following function `algo1_for`:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，假设我们需要计算前`n`个正整数的倒数平方和。我们可以很容易地使用`for`循环实现算法，如下面的函数`algo1_for`所示：
- en: '[PRE44]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: The function takes an input `n`, iterates `n` times to accumulate as supposed,
    and returns the result.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 该函数接受一个输入`n`，迭代`n`次以累积，然后返回结果。
- en: 'A better approach is to use vectorized calculation directly without any necessity
    of a `for` loop, just like how `algo1_vec()` is implemented:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 更好的方法是直接使用向量化计算，而不需要任何 `for` 循环的必要性，就像 `algo1_vec()` 的实现一样：
- en: '[PRE45]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'The two functions yield the same results, given an ordinary input:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个函数在普通输入下产生相同的结果：
- en: '[PRE46]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'However, their performance is very different:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，它们的性能却非常不同：
- en: '[PRE47]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: Vectorization is a highly recommended way of writing R code. It is not only
    of high performance but, also makes the code easier to understand.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 向量化是编写 R 代码的强烈推荐方式。它不仅性能高，而且使代码更容易理解。
- en: Using byte-code compiler
  id: totrans-170
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用字节码编译器
- en: In the previous section, we saw the power of vectorization. Sometimes, however,
    the problem dictates a for loop, and it is hard to vectorize the code. In this
    case, we may consider using R byte-code compiler to compile the function so that
    the function no longer needs parsing and may run faster.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们看到了向化的强大功能。然而，有时问题要求使用 for 循环，而代码难以向量化。在这种情况下，我们可能考虑使用 R 字节码编译器编译函数，这样函数就不再需要解析，可能运行得更快。
- en: 'First, we will load the compiler package, which is distributed along with R.
    We will use `cmpfun()` to compile a given R function. For example, we will compile
    `diff_for()` and store the compiled function as `diff_cmp()`:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将加载与 R 一起分发的编译器包。我们将使用 `cmpfun()` 编译给定的 R 函数。例如，我们将编译 `diff_for()` 并将编译后的函数存储为
    `diff_cmp()`：
- en: '[PRE48]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: When we look at `diff_cmp()`, it does not look very different from `diff_for()`,
    but it has an additional tag of the `bytecode` address.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们查看 `diff_cmp()` 时，它与 `diff_for()` 并没有太大的不同，但它有一个额外的 `bytecode` 地址标签。
- en: 'Then, we will run the benchmarking again with `diff_cmp()` this time:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将再次使用 `diff_cmp()` 运行基准测试：
- en: '[PRE49]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: It looks amazing that the compiled version, `diff_cmp()`, is much faster than
    `diff_for()` even though we didn't modify anything but compiled it into bytecode.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来很神奇，编译版本 `diff_cmp()` 比原始的 `diff_for()` 快得多，尽管我们没有修改任何东西，只是将其编译成字节码。
- en: 'Now, we will do the same thing with `algo1_for()`:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将使用 `algo1_for()` 做同样的事情：
- en: '[PRE50]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Then, we will conduct the benchmarking with the compiled version included:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将包含编译版本进行基准测试：
- en: '[PRE51]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: Again, the compiled version becomes more than six times faster than the original
    version, even if we didn't change a bit of code.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，编译版本比原始版本快了六倍以上，即使我们没有改变任何代码。
- en: 'However, compiling is no magic if it is used to compile a fully vectorized
    function. Here, we will compile `algo1_vec()` and compare its performance with
    the original version:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果用于编译完全向量化函数，编译并不是魔法。在这里，我们将编译 `algo1_vec()` 并将其性能与原始版本进行比较：
- en: '[PRE52]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: Note that the compiled function shows no significant performance improvement.
    To know more about how the compiler works, type `?compile` and read the documentation.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，编译函数没有显示出明显的性能提升。要了解更多关于编译器如何工作，请输入 `?compile` 并阅读文档。
- en: Using Intel MKL-powered R distribution
  id: totrans-186
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Intel MKL 驱动的 R 分发
- en: The R distribution we normally use is single threaded, that is, only one CPU
    thread is used to execute all R code. The good thing is that the execution model
    is simple and safe, but it does not take advantage of multicore computing.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通常使用的 R 分发是单线程的，也就是说，只有一个 CPU 线程用于执行所有 R 代码。好处是执行模型简单且安全，但它没有利用多核计算。
- en: Microsoft R Open (MRO, see [https://mran.microsoft.com/open/](https://mran.microsoft.com/open/))
    is an enhanced distribution of R. Powered by Intel Math Kernel Library (MKL, see [https://software.intel.com/en-us/intel-mkl](https://software.intel.com/en-us/intel-mkl)),
    MRO enhances the matrix algorithms by automatically taking advantage of multithreading
    computation. On a multicore computer, MRO can be 10-80 times faster than the official
    R implementation at matrix multiplication, Cholesky factorization, QR decomposition,
    singular value decomposition, principal component analysis, and linear discriminant
    analysis. For more details, visit [https://mran.microsoft.com/documents/rro/multithread/](https://mran.microsoft.com/documents/rro/multithread/)
    and see the benchmarking.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: Microsoft R Open (MRO，见 [https://mran.microsoft.com/open/](https://mran.microsoft.com/open/))
    是 R 的增强版分发。由 Intel Math Kernel Library (MKL，见 [https://software.intel.com/en-us/intel-mkl](https://software.intel.com/en-us/intel-mkl))
    驱动，MRO 通过自动利用多线程计算来增强矩阵算法。在多核计算机上，MRO 在矩阵乘法、Cholesky 分解、QR 分解、奇异值分解、主成分分析和线性判别分析等方面，可以比官方
    R 实现快 10-80 倍。更多详情，请访问 [https://mran.microsoft.com/documents/rro/multithread/](https://mran.microsoft.com/documents/rro/multithread/)
    并查看基准测试。
- en: Using parallel computing
  id: totrans-189
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用并行计算
- en: As we mentioned in the previous section, R is single threaded in design but
    still allows multiprocessing parallel computing, that is, running multiple R sessions
    to compute. This technique is supported by a parallel library, which is also distributed
    along with R.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在上一节中提到的，R 在设计上是单线程的，但仍然允许多进程并行计算，即运行多个 R 会话进行计算。这项技术由一个并行库支持，该库也随 R 一起分发。
- en: 'Suppose we need to do a simulation: we need to generate a random path that
    follows a certain random process and see whether at any point, the value goes
    beyond a fixed margin around the starting point.'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们需要进行一个模拟：我们需要生成一个遵循特定随机过程的随机路径，并查看在任意一点，值是否超出围绕起点的固定边界。
- en: 'The following code generates one realization:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码生成一个实现：
- en: '[PRE53]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'The plot generated is shown as follows:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的图表如下所示：
- en: '![Using parallel computing](img/image_13_006.jpg)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![使用并行计算](img/image_13_006.jpg)'
- en: The preceding graph shows the path and 10 percent margin. It is clear that between
    index 300 and 500, the value goes beyond the upper margin multiple times.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的图表显示了路径和 10% 的边界。很明显，在索引 300 到 500 之间，值多次超出上限边界。
- en: 'This is just one path. A valid simulation requires that the generator run as
    many times as necessary to produce statistically meaningful results. The following
    function parameterizes the random path generator and returns a list of summary
    indicators of interest. Note that `signal` indicates whether any point on the
    path goes beyond the margin:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是其中一条路径。一个有效的模拟需要生成器运行足够多的次数，以产生具有统计意义的成果。以下函数参数化了随机路径生成器，并返回一系列感兴趣的总结指标。请注意，`signal`
    表示路径上的任何一点是否超出边界：
- en: '[PRE54]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Then, we can run the generator for one time and see its summarized result:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以运行生成器一次，并查看其总结结果：
- en: '[PRE55]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'To perform the simulation, we need to run the function many times. In practice,
    we may need to run at least millions of realizations, which may take us a considerable
    amount of time. Here, we will measure how much time it costs to run ten thousand
    iterations of this simulation:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 要进行模拟，我们需要多次运行该函数。在实践中，我们可能需要运行至少数百万次实现，这可能会花费我们相当多的时间。在这里，我们将测量运行这个模拟的一万次迭代的耗时：
- en: '[PRE56]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'When the simulation is finished, we can convert all results into one data table:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 模拟完成后，我们可以将所有结果转换成一个数据表：
- en: '[PRE57]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'We can calculate the realized probability of `signal == TRUE`:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以计算 `signal == TRUE` 的实现概率：
- en: '[PRE58]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: What if the problem gets more practical and requires us to run millions of times?
    In this case, some researchers may turn to programming languages implemented with
    much higher performance such as C and C++, which are extremely efficient and flexible.
    They are great tools in implementing algorithms but require more effort to deal
    with the compiler, linker, and data input/output.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 如果问题变得更加实际，需要我们运行数百万次，在这种情况下，一些研究人员可能会转向使用性能更高的编程语言，如 C 和 C++，这些语言非常高效且灵活。它们在实现算法方面是很好的工具，但需要更多努力来处理编译器、链接器和数据输入/输出。
- en: Note that each iteration in the preceding simulation is completely independent
    of each other, so it is better accomplished by parallel computing.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，前面模拟中的每次迭代都是完全独立的，因此最好通过并行计算来完成。
- en: Since different operating systems have different implementations of process
    and threading model, some features that are available for Linux and MacOS are
    not available for Windows. Thus, performing parallel computing on Windows can
    be a bit more verbose.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 由于不同的操作系统对进程和线程模型有不同的实现，Linux 和 MacOS 上可用的某些功能在 Windows 上不可用。因此，在 Windows 上进行并行计算可能需要更多的说明。
- en: Using parallel computing on Windows
  id: totrans-210
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在 Windows 上使用并行计算
- en: 'On Windows, we need to create a local cluster of multiple R sessions to run
    parallel computing:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Windows 上，我们需要创建一个由多个 R 会话组成的本地集群以运行并行计算：
- en: '[PRE59]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: The `detectCores()` function returns the number of cores your computer is equipped
    with. Creating a cluster of more than that number of nodes is allowed but usually
    does no good because your computer cannot perform more tasks than that simultaneously.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '`detectCores()` 函数返回计算机配备的核心数。创建超过该数量节点的集群是允许的，但通常没有好处，因为计算机不能同时执行超过该数量的任务。'
- en: 'Then, we can call `parLapply()`, the parallel version of `lapply()`:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以调用 `parLapply()`，它是 `lapply()` 的并行版本：
- en: '[PRE60]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Note that the time consumed is reduced to more than half of the original time.
    Now, we no longer need the cluster. We can call `stopCluster()` to kill the R
    sessions just created:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，消耗的时间减少到原始时间的一半以上。现在，我们不再需要集群。我们可以调用 `stopCluster()` 来终止刚刚创建的 R 会话：
- en: '[PRE61]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'When we call `parLapply()`, it automatically schedules the task for each cluster
    node. More specifically, all cluster nodes run `simulate()` with one of `1:10000`
    exclusively at the same time so that the computation is done in parallel. Finally,
    all results are collected so that we get a list just like the results from `lapply()`:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们调用 `parLapply()` 时，它将自动为每个集群节点调度任务。更具体地说，所有集群节点同时以 `1:10000` 之一独占运行 `simulate()`，以便并行计算。最后，收集所有结果，以便我们得到一个类似于
    `lapply()` 的结果列表：
- en: '[PRE62]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'The parallel code looks simple because `simulate()` is self-contained and does
    not rely on user-defined external variables or datasets. If we run a function
    in parallel that refers to a variable in the master session (the current session
    that creates the cluster), it will not find the variable:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 并行代码看起来很简单，因为 `simulate()` 是自包含的，并且不依赖于用户定义的外部变量或数据集。如果我们并行运行一个引用主会话（创建集群的当前会话）中变量的函数，它将找不到该变量：
- en: '[PRE63]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: All nodes fail because each of them starts as a fresh R session with no user
    variables defined. To let the cluster nodes get the value of the variable they
    need, we have to export them to all nodes.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 所有节点都失败了，因为每个节点都是以一个全新的 R 会话启动的，没有定义用户变量。为了让集群节点获取它们需要的变量值，我们必须将它们导出到所有节点。
- en: 'The following example demonstrates how this works. Suppose we have a data frame
    of numbers. We want to take random samples from the data frame:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例演示了它是如何工作的。假设我们有一个数字的数据框。我们想要从这个数据框中抽取随机样本：
- en: '[PRE64]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'If we perform the sampling in parallel, all nodes must share the data frame
    and the function. To do this, we can use `clusterEvalQ()` to evaluate an expression
    on each cluster node. First, we will make a cluster just as we did earlier:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们在并行中进行抽样，所有节点必须共享数据框和函数。为此，我们可以使用 `clusterEvalQ()` 在每个集群节点上评估一个表达式。首先，我们将创建一个集群，就像我们之前做的那样：
- en: '[PRE65]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'The `Sys.getpid()` function returns the process ID of the current R session.
    Since there are four nodes in the cluster, each is an R session with a unique
    process ID. We can call `clusterEvalQ()` with `Sys.getpid()` and see the process
    ID of each node:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '`Sys.getpid()` 函数返回当前 R 会话的进程 ID。由于集群中有四个节点，每个节点都是一个具有唯一进程 ID 的 R 会话。我们可以使用
    `clusterEvalQ()` 和 `Sys.getpid()` 来查看每个节点的进程 ID：'
- en: '[PRE66]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'To see the variables in the global environment of each node, we can call `ls()`,
    just like we call in our own working environment:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看每个节点的全局环境中的变量，我们可以调用 `ls()`，就像我们在自己的工作环境中调用一样：
- en: '[PRE67]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'As we mentioned, all cluster nodes are, by default, initialized with an empty
    global environment. To export `data` and `take_sample` to each node, we can call
    `clusterExport()`:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们提到的，所有集群节点默认情况下都是初始化为空的全球环境。要将 `data` 和 `take_sample` 导出至每个节点，我们可以调用 `clusterExport()`：
- en: '[PRE68]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'Now, we can see that all nodes have `data` and `take_sample`. Now, we can let
    each node call `take_sample()`:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以看到所有节点都有 `data` 和 `take_sample`。现在，我们可以让每个节点调用 `take_sample()`：
- en: '[PRE69]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'Alternatively, we can use `clusterCall()` and `<<-` to create global variables
    in each node, while `<-` only creates local variables in the function:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，我们可以使用 `clusterCall()` 和 `<<-` 在每个节点中创建全局变量，而 `<-` 只在函数中创建局部变量：
- en: '[PRE70]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: Note that `clusterCall()` returns the returned value from each node. In the
    preceding code, we will use `invisible()` to suppress the values they return.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，`clusterCall()` 返回每个节点的返回值。在前面代码中，我们将使用 `invisible()` 来抑制它们返回的值。
- en: 'Since each cluster node is started in a fresh state, they only load basic packages.
    To let each node load the given packages, we can also use `clusterEvalQ()`. The
    following code lets each node attach the `data.table` package so that `parLapply()`
    can run a function in which `data.table` functions are used on each node:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 由于每个集群节点都是以一个全新的状态启动的，它们只加载基本包。为了让每个节点加载给定的包，我们也可以使用 `clusterEvalQ()`。以下代码让每个节点附加
    `data.table` 包，以便 `parLapply()` 可以在每个节点上运行使用 `data.table` 函数的函数：
- en: '[PRE71]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'A list of data summary is returned:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 返回一个数据摘要列表：
- en: '[PRE72]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'When we don''t need the cluster any more, we will run the following code to
    release it:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们不再需要集群时，我们将运行以下代码来释放它：
- en: '[PRE73]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: Using parallel computing on Linux and MacOS
  id: totrans-244
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在 Linux 和 MacOS 上使用并行计算
- en: 'Using parallel computing on Linux and MacOS can be much easier than on Windows.
    Without having to manually create a socket-based cluster, `mclapply()` directly
    forks the current R session into multiple R sessions, with everything preserved
    to continue running in parallel and schedule tasks for each child R session:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Linux 和 MacOS 上使用并行计算可能比在 Windows 上更容易。无需手动创建基于套接字的集群，`mclapply()` 直接将当前的
    R 会话分叉成多个 R 会话，保留所有内容以继续并行运行，并为每个子 R 会话调度任务：
- en: '[PRE74]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'Therefore, we don''t have to export the variables because they are immediately
    available in each fork process:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们不需要导出变量，因为它们在每个分叉过程中都是立即可用的：
- en: '[PRE75]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'Also, we can create jobs to be done in parallel with much flexibility. For
    example, we will create a job that generates `10` random numbers:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们可以创建具有很大灵活性的并行作业。例如，我们将创建一个生成 `10` 个随机数的作业：
- en: '[PRE76]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'As long as the job is created, we can choose to collect the results from the
    job with `mccollect()`. Then, the function will not return until the job is finished:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 只要创建了作业，我们就可以选择使用 `mccollect()` 收集作业的结果。然后，函数将不会返回，直到作业完成：
- en: '[PRE77]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'We can also programmatically create a number of jobs to run in parallel. For
    example, we create `8` jobs, and each sleeps for a random time. Then, `mccollect()`
    won''t return until all jobs are finished sleeping. Since the jobs are run in
    parallel, the time `mccollect()` takes won''t be too long:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以通过编程创建多个并行运行的作业。例如，我们创建 `8` 个作业，每个作业随机休眠一段时间。然后，`mccollect()` 不会返回，直到所有作业都完成休眠。由于作业是并行运行的，`mccollect()`
    所花费的时间不会太长：
- en: '[PRE78]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: This allows us to customize the task-scheduling mechanism.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 这允许我们自定义任务调度机制。
- en: Using Rcpp
  id: totrans-256
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Rcpp
- en: As we mentioned, parallel computing works when each iteration is independent
    so that the final results do not rely on the order of execution. However, not
    all tasks are so ideal like this. Therefore, the use of parallel computing may
    be undermined. What if we really want the algorithm to run fast and easily interact
    with R? The answer is by writing the algorithm in C++ via Rcpp ([http://www.rcpp.org/](http://www.rcpp.org/)).
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们提到的，并行计算在每次迭代都是独立的情况下才会工作，这样最终结果就不会依赖于执行顺序。然而，并非所有任务都像这样理想。因此，并行计算的使用可能会受到影响。如果我们真的希望算法运行得快并且容易与
    R 交互，答案是通过 Rcpp 将算法用 C++ 编写（[http://www.rcpp.org/](http://www.rcpp.org/))。
- en: C++ code usually runs very fast, because it is compiled to native instructions
    and is thus much closer to hardware level than a scripting language like R. Rcpp
    is a package that enables us to write C++ code with seamless R and C++ integration.
    With Rcpp, we can write C++ code in which we can call R functions and take advantage
    of R data structures. It allows us to write high-performance code and preserve
    the power of data manipulation in R at the same time.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: C++ 代码通常运行得非常快，因为它被编译成本地指令，因此比像 R 这样的脚本语言更接近硬件级别。Rcpp 是一个包，它使我们能够以无缝的方式将 R 和
    C++ 集成在一起编写 C++ 代码。通过 Rcpp，我们可以编写可以调用 R 函数并利用 R 数据结构的 C++ 代码。它允许我们编写高性能的代码，同时保留
    R 中数据操作的能力。
- en: To use Rcpp, we first need to ensure that the system is prepared for computing
    native code with the right toolchain. Under Windows, Rtools is needed and can
    be found at [https://cran.r-project.org/bin/windows/Rtools/](https://cran.r-project.org/bin/windows/Rtools/).
    Under Linux and MacOS, a properly installed C/C++ toolchain is required.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 Rcpp，我们首先需要确保系统已经准备好使用正确的工具链来计算本地代码。在 Windows 上，需要 Rtools，可以在 [https://cran.r-project.org/bin/windows/Rtools/](https://cran.r-project.org/bin/windows/Rtools/)
    找到。在 Linux 和 MacOS 上，需要正确安装的 C/C++ 工具链。
- en: 'Once the toolchain is properly installed, run the following code to install
    the package:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦工具链安装正确，运行以下代码来安装包：
- en: '[PRE79]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'Then, we will create a C++ source file at `code/rcpp-demo.cpp` with the following
    code:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将在 `code/rcpp-demo.cpp` 创建一个 C++ 源文件，其中包含以下代码：
- en: '[PRE80]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: The preceding code is written in C++. If you are not familiar with C++ syntax,
    you can quickly pick up the simplest part by going through [http://www.learncpp.com/](http://www.learncpp.com/).
    The language design and supported features are much richer and more complex than
    R. Don't expect to be an expert in a short period of time, but getting started
    with the basics usually allows you to write simple algorithms.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码是用 C++ 编写的。如果你不熟悉 C++ 语法，可以通过访问 [http://www.learncpp.com/](http://www.learncpp.com/)
    快速掌握最简单的部分。C++ 的语言设计和支持的功能比 R 更丰富、更复杂。不要期望在短时间内成为专家，但通常通过学习基础知识，你可以编写简单的算法。
- en: If you read the preceding code, it looks very different from typical R code.
    Since C++ is a strong-typed language, we need to specify the types of function
    arguments and the return type of functions. A function that is commented with
    `[[Rcpp::export]]` will be captured by Rcpp, and when we source the code in RStudio
    or use `Rcpp::sourceCpp` directly, these C++ functions will be automatically compiled
    and ported to our working environment in R.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你阅读前面的代码，它看起来与典型的R代码非常不同。由于C++是强类型语言，我们需要指定函数参数的类型和函数的返回类型。带有`[[Rcpp::export]]`注释的函数将被Rcpp捕获，当我们使用RStudio中的`source`命令或直接使用`Rcpp::sourceCpp`时，这些C++函数将被自动编译并移植到我们的R工作环境中。
- en: 'The preceding C++ function simply takes a numeric vector and returns a new
    numeric vector with all `x` elements doubled. Note that the `NumericVector` class
    is provided by `Rcpp.h` included at the beginning of the source file. In fact,
    `Rcpp.h` provides the C++ proxy of all commonly used R data structures. Now, we
    will call `Rcpp::sourceCpp()` to compile and load the source file:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的C++函数简单地接受一个数值向量，并返回一个新的数值向量，其中所有`x`元素都被加倍。请注意，`NumericVector`类是由源文件开头包含的`Rcpp.h`提供的。实际上，`Rcpp.h`提供了所有常用R数据结构的C++代理。现在，我们将调用`Rcpp::sourceCpp()`来编译和加载源文件：
- en: '[PRE81]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: 'The function compiles the source code, links it to necessary shared libraries,
    and exposes an R function to the environment. The beauty is that all of these
    are done automatically, which makes it much easier to write algorithms for non-professional
    C++ developers. Now, we have an R function to call it:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 函数编译源代码，将其链接到必要的共享库，并将R函数暴露给环境。美的是，所有这些操作都是自动完成的，这使得非专业C++开发者编写算法变得更加容易。现在，我们有一个可以调用的R函数：
- en: '[PRE82]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: 'We can see that `timeTwo` in R does not look like an ordinary function, but
    performs a native call to the C++ function. The function works with single numeric
    input:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，R中的`timeTwo`看起来不像一个普通函数，而是对C++函数的本地调用。该函数与单个数值输入一起工作：
- en: '[PRE83]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: 'It also works with a multi-element numeric vector:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 它也可以与多元素数值向量一起工作：
- en: '[PRE84]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: 'Now, we can use very simple C++ language constructs to reimplement the `algo1_for`
    algorithm in C++. Now, we will create a C++ source file at `code/rcpp-algo1.cpp`
    with the following code:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以使用非常简单的C++语言结构重新实现`algo1_for`算法。现在，我们将在`code/rcpp-algo1.cpp`创建一个C++源文件，包含以下代码：
- en: '[PRE85]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: 'Note that we don''t use any R but C++ data structures in `algo1_cpp`. When
    we source the code, Rcpp will handle all the porting for us:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们在`algo1_cpp`中没有使用任何R数据结构，而是使用C++数据结构。当我们使用`source`命令时，Rcpp将为我们处理所有移植工作：
- en: '[PRE86]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: 'The function works with a single numeric input:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 函数与单个数值输入一起工作：
- en: '[PRE87]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: 'If we supply a numeric vector, an error will occur:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们提供一个数值向量，将会发生错误：
- en: '[PRE88]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: 'Now, we can do the benchmarking again. This time, we will add `algo1_cpp` to
    the list of alternative implementations. Here, we will compare the version using
    a `for` loop in R, the byte-code compiled version using for loop in R, the vectorized
    version, and the C++ version:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以再次进行基准测试。这次，我们将`algo1_cpp`添加到替代实现列表中。在这里，我们将比较使用R中的`for`循环的版本、使用R中的for循环的字节码编译版本、矢量化版本和C++版本：
- en: '[PRE89]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: It is amazing that the C++ version is even faster than the vectorized version.
    Although the functions used by the vectorized version are primitive functions
    and are already very fast, they still have some overhead due to method dispatching
    and argument checking. Our C++ version is specialized to the task, so it can be
    slightly faster than the vectorized version.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 真是令人惊讶，C++版本甚至比矢量化版本还要快。尽管矢量化版本使用的函数是原始函数并且已经非常快，但由于方法调度和参数检查，它们仍然有一些开销。我们的C++版本针对任务进行了优化，因此可以稍微快于矢量化版本。
- en: 'Another example is the C++ implementation of `diff_for()` as the following
    code shows:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个例子是`diff_for()`的C++实现，如下所示：
- en: '[PRE90]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: 'In the preceding C++ code, `diff_cpp()` takes a numeric vector and returns
    a numeric vector. The function simply creates a new vector, and calculates and
    stores the differences between the consecutive two elements in `x` iteratively.
    Then, we will source the code file:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的C++代码中，`diff_cpp()`接受一个数值向量并返回一个数值向量。该函数简单地创建一个新的向量，并迭代地计算并存储`x`中连续两个元素之间的差异。然后，我们将源代码文件：
- en: '[PRE91]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: 'It is easy to verify whether the function works as supposed:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 很容易验证函数是否按预期工作：
- en: '[PRE92]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: 'Then, we will do the benchmarking again with five different calls: the version
    using a for loop in R (`diff_for`), the byte-code compiled version (`diff_cmp`),
    the vectorized version (`diff`), the vectorized version without method dispatch
    (`diff.default`), and our C++ version (`diff_cpp`):'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将使用五种不同的调用再次进行基准测试：在R中使用循环的版本（`diff_for`）、字节码编译版本（`diff_cmp`）、向量化版本（`diff`）、不带方法调用的向量化版本（`diff.default`）以及我们的C++版本（`diff_cpp`）：
- en: '[PRE93]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: It appears that the C++ version is the fastest.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来C++版本是最快的。
- en: In recent years, a rapidly growing number of R packages have used Rcpp to either
    boost performance or directly link to popular libraries that provide high-performance
    algorithms. For example, RcppArmadillo and RcppEigen provide high-performance
    linear algebra algorithms, RcppDE provides fast implementations for global optimization
    by differential evolution in C++, and so on.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，越来越多的R包开始使用Rcpp来提高性能或直接链接到提供高性能算法的流行库。例如，RcppArmadillo和RcppEigen提供了高性能的线性代数算法，RcppDE提供了C++中全局优化差分演化的快速实现，等等。
- en: To know more about Rcpp and related packages, visit its official website ([http://www.rcpp.org/](http://www.rcpp.org/)).
    I also recommend the book*Seamless R and C++ Integration with Rcpp* by Rcpp's
    author Dirk Eddelbuettel at [http://www.rcpp.org/book/](http://www.rcpp.org/book/).
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于Rcpp和相关包的信息，请访问其官方网站 ([http://www.rcpp.org/](http://www.rcpp.org/))。我还推荐Rcpp的作者Dirk
    Eddelbuettel所著的书籍*Seamless R and C++ Integration with Rcpp*，可在[http://www.rcpp.org/book/](http://www.rcpp.org/book/)找到。
- en: OpenMP
  id: totrans-296
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: OpenMP
- en: As we mentioned in the section on parallel computing, an R session runs in a
    single thread. However, in Rcpp code, we can use multithreading to boost the performance.
    One multithreading technique is OpenMP ([http://openmp.org](http://openmp.org)),
    which is supported by most modern C++ compilers (see [http://openmp.org/wp/openmp-compilers/](http://openmp.org/wp/openmp-compilers/)).
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在并行计算部分提到的，R会话在一个单独的线程中运行。然而，在Rcpp代码中，我们可以使用多线程来提高性能。一种多线程技术是OpenMP ([http://openmp.org](http://openmp.org))，它被大多数现代C++编译器支持（参见[http://openmp.org/wp/openmp-compilers/](http://openmp.org/wp/openmp-compilers/))）。
- en: 'Several articles discuss and demonstrate the use of OpenMP with Rcpp at [http://gallery.rcpp.org/tags/openmp/](http://gallery.rcpp.org/tags/openmp/).
    Here, we will provide a simple example. We will create a C++ source file with
    the following code at `code/rcpp-diff-openmp.cpp`:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 几篇文章讨论并展示了Rcpp与OpenMP的使用，可在[http://gallery.rcpp.org/tags/openmp/](http://gallery.rcpp.org/tags/openmp/)找到。在这里，我们将提供一个简单的示例。我们将在`code/rcpp-diff-openmp.cpp`创建一个包含以下代码的C++源文件：
- en: '[PRE94]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: Note that Rcpp will recognize the comment in the first line and add necessary
    options to the compiler so that OpenMP is enabled. To use OpenMP, we need to include
    `omp.h`. Then, we can set the number of threads by calling `omp_set_num_threads(n)`
    and use `#pragma omp parallel for` to indicate that the following for loop should
    be parallelized. If the number of threads is set to `1`, then the code also runs
    normally.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，Rcpp将识别第一行的注释并为编译器添加必要的选项，以便启用OpenMP。要使用OpenMP，我们需要包含`omp.h`。然后，我们可以通过调用`omp_set_num_threads(n)`来设置线程数，并使用`#pragma
    omp parallel for`来指示下面的循环应该并行化。如果线程数设置为`1`，则代码也可以正常运行。
- en: 'We will source the C++ code file:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将源C++代码文件：
- en: '[PRE95]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: 'First, let''s see whether the function works properly:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们看看这个函数是否工作正常：
- en: '[PRE96]'
  id: totrans-304
  prefs: []
  type: TYPE_PRE
  zh: '[PRE96]'
- en: 'Then, we will start benchmarking with a 1000-number input vector:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将使用1000个数字的输入向量开始基准测试：
- en: '[PRE97]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE97]'
- en: 'Unfortunately, even with multi-threading, `diff_cpp_omp()` is slower than its
    single-threaded C++ implementation. This is because using multithreading has some
    overhead. If the input is small, the time to initialize multiple threads may take
    a significant part of the whole computing time. However, if the input is large
    enough, the advantage of multi-threading will exceed its cost. Here, we will use
    `100000` numbers as the input vector:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，即使使用多线程，`diff_cpp_omp()`也比其单线程的C++实现慢。这是因为使用多线程有一些开销。如果输入较小，初始化多个线程所需的时间可能会占整个计算时间的很大一部分。然而，如果输入足够大，多线程的优势将超过其成本。在这里，我们将使用`100000`个数字作为输入向量：
- en: '[PRE98]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE98]'
- en: The cost of creating multiple threads is small relative to the performance boost
    of using them. As a result, the version powered by OpenMP is even faster than
    the simple C++ version.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 创建多个线程的成本相对于使用它们带来的性能提升来说是小的。因此，由OpenMP驱动的版本甚至比简单的C++版本还要快。
- en: 'In fact, the feature set of OpenMP is much richer than we have demonstrated.
    For more details, read the official documentation. For more examples, I recommend
    *Guide into OpenMP: Easy multithreading programming for C++* by Joel Yliluoma
    at [http://bisqwit.iki.fi/story/howto/openmp/](http://bisqwit.iki.fi/story/howto/openmp/).'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，OpenMP的功能集比我们所展示的丰富得多。更多详情，请参阅官方文档。更多示例，我推荐阅读Joel Yliluoma所著的*《OpenMP指南：C++的简单多线程编程》*，链接为[http://bisqwit.iki.fi/story/howto/openmp/](http://bisqwit.iki.fi/story/howto/openmp/)。
- en: RcppParallel
  id: totrans-311
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: RcppParallel
- en: Another approach to taking advantage of multi-threading with Rcpp is RcppParallel
    ([http://rcppcore.github.io/RcppParallel/](http://rcppcore.github.io/RcppParallel/)).
    This package includes Intel TBB ([https://www.threadingbuildingblocks.org/](https://www.threadingbuildingblocks.org/))
    and TinyThread ([http://tinythreadpp.bitsnbites.eu/](http://tinythreadpp.bitsnbites.eu/)).
    It provides thread-safe vector and matrix wrapper data structures as well as high-level
    parallel functions.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 利用Rcpp利用多线程的另一种方法是RcppParallel ([http://rcppcore.github.io/RcppParallel/](http://rcppcore.github.io/RcppParallel/))。这个包包括Intel
    TBB ([https://www.threadingbuildingblocks.org/](https://www.threadingbuildingblocks.org/))
    和 TinyThread ([http://tinythreadpp.bitsnbites.eu/](http://tinythreadpp.bitsnbites.eu/))。它提供了线程安全的向量和矩阵包装数据结构以及高级并行函数。
- en: To perform multi-threading parallel computing with RcppParallel, we need to
    implement a `Worker` to handle how a slice of input is transformed to the output.
    Then, RcppParallel will take care of the rest of the work such as multithreading
    task scheduling.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用RcppParallel执行多线程并行计算，我们需要实现一个`Worker`来处理如何将输入的一部分转换为输出。然后，RcppParallel将负责其余的工作，例如多线程任务调度。
- en: Here's a short demo. We will create a C++ source file with the following code
    at `code/rcpp-parallel.cpp`. Note that we need to declare to Rcpp that it depends
    on RcppParallel and uses C++ 11 for using lambda function.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个简短的演示。我们将在`code/rcpp-parallel.cpp`创建一个包含以下代码的C++源文件。请注意，我们需要向Rcpp声明它依赖于RcppParallel，并使用C++
    11来使用lambda函数。
- en: 'Here, we will implement a `Worker` called `Transformer` that transforms each
    element `x` of a matrix `to 1 / (1 + x ^ 2)`. Then, in `par_transform`, we will
    create an instance of `Transformer` and call `parallelFor` with it so that it
    automatically takes advantage of multithreading:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将实现一个名为`Transformer`的`Worker`，它将矩阵中的每个元素`x`转换为`1 / (1 + x ^ 2)`。然后，在`par_transform`中，我们将创建一个`Transformer`实例，并使用它调用`parallelFor`，以便自动利用多线程：
- en: '[PRE99]'
  id: totrans-316
  prefs: []
  type: TYPE_PRE
  zh: '[PRE99]'
- en: 'We can easily verify that the function works with a small matrix:'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以轻松地通过一个小矩阵验证该函数是否工作：
- en: '[PRE100]'
  id: totrans-318
  prefs: []
  type: TYPE_PRE
  zh: '[PRE100]'
- en: 'It produces exactly the same results as the vectorized R expression. Now, we
    can take a look at its performance when the input matrix is very large:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 它产生的结果与向量化的R表达式完全相同。现在，我们可以看看当输入矩阵非常大时它的性能表现：
- en: '[PRE101]'
  id: totrans-320
  prefs: []
  type: TYPE_PRE
  zh: '[PRE101]'
- en: It appears that the multi-threading version is almost 1x faster than the vectorized
    version.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来，多线程版本几乎比向量化版本快1倍。
- en: RcppParallel is more powerful than we have demonstrated. For more detailed introduction
    and examples, visit [http://rcppcore.github.io/RcppParallel](http://rcppcore.github.io/RcppParallel).
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: RcppParallel的功能比我们所展示的更强大。更多详细介绍和示例，请访问[http://rcppcore.github.io/RcppParallel](http://rcppcore.github.io/RcppParallel)。
- en: Summary
  id: totrans-323
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'In this chapter, you learned when performance may or may not matter, how to
    measure the performance of R code, how to use profiling tools to identify the
    slowest part of code, and why such code can be slow. Then, we introduced the most
    important ways to boost the code performance: using built-in functions if possible,
    taking advantage of vectorization, using the byte-code compiler, using parallel
    computing, writing code in C++ via Rcpp, and using multi-threading techniques
    in C++. High-performance computing is quite an advanced topic, and there''s still
    a lot more to learn if you want to apply it in practice. This chapter demonstrates
    that using R does not always mean slow code. Instead, we can achieve high performance
    if we want.'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你学习了性能可能重要或不重要的时刻，如何测量R代码的性能，如何使用分析工具来识别代码中最慢的部分，以及为什么这样的代码可能会慢。然后，我们介绍了提高代码性能最重要的方法：如果可能，使用内置函数，利用向量化，使用字节码编译器，使用并行计算，通过Rcpp用C++编写代码，以及在C++中使用多线程技术。高性能计算是一个相当高级的话题，如果你想在实践中应用它，还有很多东西要学习。本章表明，使用R并不意味着代码总是慢。相反，如果我们想，我们可以实现高性能。
- en: 'In the next chapter, we will introduce another useful topic: web scraping.
    To scrape data from webpages, we need to understand how web pages are structured
    and how to extract data from their source code. You will learn the basic idea
    and representation of HTML, XML, and CSS, and how to analyze a target webpage
    so that we can correctly extract the information we want from webpages.'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将介绍另一个有用的主题：网页抓取。要从网页中抓取数据，我们需要了解网页的结构以及如何从它们的源代码中提取数据。你将学习HTML、XML和CSS的基本概念和表示方法，以及如何分析目标网页，以便我们能够正确地从网页中提取所需的信息。
