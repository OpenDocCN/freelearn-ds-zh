- en: '*Chapter 2*: Building Our Data Engineering Infrastructure'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, you learned what data engineers do and their roles
    and responsibilities. You were also introduced to some of the tools that they
    use, primarily the different types of databases, programming languages, and data
    pipeline creation and scheduling tools.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, you will install and configure several tools that will help
    you throughout the rest of this book. You will learn how to install and configure
    two different databases – PostgreSQL and Elasticsearch – two tools to assist in
    building workflows – Airflow and Apache NiFi, and two administrative tools – pgAdmin
    for PostgreSQL and Kibana for Elasticsearch.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: With these tools, you will be able to write data engineering pipelines to move
    data from one source to another and also be able to visualize the results. As
    you learn how to build pipelines, being able to see the data and how it has transformed
    will be useful to you in debugging any errors. As you progress, you may no longer
    need these tools, but other roles and users you will support may require them,
    so having a basic understanding of the tools will be useful.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: Installing and configuring Apache NiFi
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Installing and configuring Apache Airflow
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Installing and configuring Elasticsearch
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Installing and configuring Kibana
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Installing and configuring PostgreSQL
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Installing pgAdmin 4
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Installing and configuring Apache NiFi
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Apache NiFi is the primary tool used in this book for building data engineering
    pipelines. NiFi allows you to build data pipelines using prebuilt processors that
    you can configure for your needs. You do not need to write any code to get NiFi
    pipelines working. It also provides a scheduler to set how frequently you would
    like your pipelines to run. In addition, it will handle backpressure – if one
    task works faster than another, you can slow down the task.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: 'To install Apache NiFi, you will need to download it from [https://nifi.apache.org/download.html](https://nifi.apache.org/download.html):'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: 'By using `curl`, you can download NiFi using the following command line:'
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-15
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Extract the NiFi files from the `.tar.gz` file using the following command:'
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-17
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'You will now have a folder named `nifi-1.12.1`. You can run NiFi by executing
    the following from inside the folder:'
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'If you already have Java installed and configured, when you run the status
    tool as shown in the following snippet, you will see a path set for `JAVA_HOME`:'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'If you do not see `JAVA_HOME` set, you may need to install Java using the following
    command:'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Then, you should edit `.bash_profile` to include the following line so that
    NiFi can find the `JAVA_HOME` variable:'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Lastly, reload `.bash_profile`:'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: When you run for the status on NiFi, you should now see a path for `JAVA_HOME`:![Figure
    2.1 – NiFi is running
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B15739_02_01.jpg)'
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 2.1 – NiFi is running
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'When NiFi is ready, which may take a minute, open your web browser and go to
    `http://localhost:8080/nifi/`. You should be seeing the following screen:'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 2.2 – The NiFi GUI'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15739_02_02.jpg)'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.2 – The NiFi GUI
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: 'In later chapters, you will learn about many of the available configurations
    for NiFi, but for now, you will only change the port NiFi runs on. In `conf/nifi.properties`,
    change `nifi.web.http.port=8080` under the `web properties` heading to `9300`,
    as shown:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'If your firewall is on, you may need to open the port:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Now, you can relaunch NiFi and view the GUI at `http://localhost:9300/nifi/`.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: A quick tour of NiFi
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The NiFi GUI will be blank because you have not added any processors or processor
    groups. At the top of the screen are the component toolbar and the status bar.
    The component toolbar has the tools needed for building a data flow. The status
    bar, as the title suggests, gives an overview of the current status of your NiFi
    instance:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.3 – NiFi component toolbar and status bar'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15739_02_03.jpg)'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.3 – NiFi component toolbar and status bar
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: 'The tool you will use the most is the **Processor** tool. The other tools,
    from left to right, are as follows:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: '**Input Port**'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Output Port**'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Processor Group**'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Remote Processor Group**'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Funnel**'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Template**'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Label**'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With these limited tools, you are able to build complex data flows.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: 'A NiFi data flow is made up of processors, connections, and relationships.
    NiFi has over 100 processors all ready for you to use. By clicking the **Processor**
    tool and dragging it on to the canvas, you will be prompted to select the processor
    you would like to use, as shown in the following screenshot:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.4 – Processors you can add to the canvas'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15739_02_04.jpg)'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.4 – Processors you can add to the canvas
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the search bar, you can search for `GenerateFlowFile`. Select the processor
    and it will be added to the canvas. This processor will allow you to create FlowFiles
    with text. Drag the `PutFile`, then select the processor. This processor will
    save the FlowFile to disk as a file. You should now have a canvas as in the following
    screenshot:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.5 – Processors added to the canvas – with errors'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15739_02_05.jpg)'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.5 – Processors added to the canvas – with errors
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: When you add the processors, there will be a caution symbol in the left corner
    of the box. They have not been configured, so you will get warnings and errors.
    The preceding screenshot shows that the `PutFile` processor is missing the `Directory`
    parameter, there is no upstream connection, and the relationships for success
    and failure have not been handled.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: 'To configure the processor, you can either double-click on the processor or
    right-click and select **Properties**. The following screenshot shows the properties
    for the processor:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.6 – Configuring the GenerateFlowFile processor'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15739_02_06.jpg)'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.6 – Configuring the GenerateFlowFile processor
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: 'The following steps should be followed to configure a processor:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 应遵循以下步骤来配置处理器：
- en: You must have a value set for any parameters that are bold. Each parameter has
    a question mark icon to help you.
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您必须为任何粗体的参数设置值。每个参数都有一个问号图标以帮助您。
- en: You can also right-click on the processes and select the option to use.
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您也可以右键单击进程并选择使用选项。
- en: For `GenerateFlowfile`, all the required parameters are already filled out.
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于 `GenerateFlowfile`，所有必需的参数已经填写完毕。
- en: In the preceding screenshot, I have added a value to the parameter of **Custom
    Text**. To add custom properties, you can click the plus sign at the upper-right
    of the window. You will be prompted for a name and value. I have added my property
    filename and set the value to **This is a file from nifi**.
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在前面的截图中，我已经为 **自定义文本** 参数添加了一个值。要添加自定义属性，您可以在窗口右上角单击加号。您将被提示输入名称和值。我已经添加了我的属性文件名，并将其值设置为
    **这是一个来自 nifi 的文件**。
- en: Once configured, the yellow warning icon in the box will turn into a square
    (stop button).
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦配置完成，框中的黄色警告图标将变为方形（停止按钮）。
- en: Now that you have configured the first processor, you need to create a connection
    and specify a relationship – a relationship is usually on success or failure,
    but the relationship types change based on the processor.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经配置了第一个处理器，您需要创建一个连接并指定一个关系 – 关系通常是成功或失败，但关系类型会根据处理器而变化。
- en: 'To create a connection, hover over the processor box and a circle and arrow
    will appear:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建连接，将鼠标悬停在处理器框上，会出现一个圆圈和箭头：
- en: Drag the circle to the processor underneath it (`PutFile`).
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将圆圈拖到下面的处理器下面（`PutFile`）。
- en: It will snap into place, then prompt you to specify which relationship you want
    to make this connection for. The only choice will be **Success** and it will already
    be checked.
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 它会自动定位，然后提示您指定要为此连接设置哪种关系。唯一的选择将是 **成功**，并且它已经选中。
- en: Select `GenerateFlowFile` processor and select **Run**.
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择 `GenerateFlowFile` 处理器并选择 **运行**。
- en: 'The red square icon will change to a green play button. You should now have
    a data flow as in the following screenshot:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 红色方块图标将变为绿色播放按钮。现在您应该有一个如图下截图所示的数据流：
- en: '![Figure 2.7 – Data flow half running'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.7 – 数据流半运行'
- en: '](img/B15739_02_07.jpg)'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B15739_02_07.jpg]'
- en: Figure 2.7 – Data flow half running
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.7 – 数据流半运行
- en: 'Between the two processor boxes, you can see the queue. It will show the number
    of FlowFiles and the size. If you right-click on the queue, you will see a list
    of the FlowFiles and you can get details about each one, see their contents, and
    download them. The following screenshot shows the list view of FlowFiles in a
    queue:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在两个处理器框之间，您可以看到队列。它将显示 FlowFiles 的数量和大小。如果您右键单击队列，您将看到一个 FlowFiles 列表，您可以获取每个
    FlowFile 的详细信息，查看其内容，并下载它们。以下截图显示了队列中 FlowFiles 的列表视图：
- en: '![Figure 2.8 – List of FlowFiles in the queue'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.8 – 队列中的 FlowFiles 列表'
- en: '](img/B15739_02_08.jpg)'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B15739_02_08.jpg]'
- en: Figure 2.8 – List of FlowFiles in the queue
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.8 – 队列中的 FlowFiles 列表
- en: 'You can view the details of the flow and the contents. The details view has
    two tables – details and attributes. From the **DETAILS** tab, you will see some
    of the NiFi metadata and have the ability to view or download the FlowFile. The
    **ATTRIBUTES** tab contains attributes assigned by NiFi and any attributes you
    may have created in the data pipeline. The **DETAILS** tab is shown in the following
    screenshot:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以查看流和内容的详细信息。详细信息视图有两个表格 – 详细信息和属性。从 **详细信息** 选项卡，您将看到一些 NiFi 元数据，并具有查看或下载
    FlowFile 的能力。**属性** 选项卡包含 NiFi 分配的属性以及您可能在数据管道中创建的任何属性。**详细信息** 选项卡如图下截图所示：
- en: '![Figure 2.9 – Details of a FlowFile'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.9 – FlowFile 的详细信息'
- en: '](img/B15739_02_09.jpg)'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B15739_02_09.jpg]'
- en: Figure 2.9 – Details of a FlowFile
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.9 – FlowFile 的详细信息
- en: 'From the **DETAILS** tab, if you select to view the FlowFile, you will see
    the contents in the window. This works best for text-based data, but there is
    also an option to view the FlowFile in hex format. There is also the option to
    display raw or formatted text. The following screenshot shows the raw FlowFile
    data, which is just a simple text string:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 从 **详细信息** 选项卡，如果您选择查看 FlowFile，您将在窗口中看到内容。这对于基于文本的数据效果最好，但也可以选择以十六进制格式查看 FlowFile。还有选项显示原始或格式化文本。以下截图显示了原始
    FlowFile 数据，它只是一个简单的文本字符串：
- en: '![Figure 2.10 – Contents of a FlowFile'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.10 – FlowFile 的内容'
- en: '](img/B15739_02_10.jpg)'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B15739_02_10.jpg]'
- en: Figure 2.10 – Contents of a FlowFile
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.10 – FlowFile 的内容
- en: 'The `PutFile` process saved the FlowFile as a file on your machine at `opt/nifioutput`.
    The location can be specified in the configuration of the processor. If you do
    not have root privileges, you can change the location to your home directory.
    You now have a complete data flow. It is not a very good data flow, but it will
    generate a file every 10 seconds and write it to disk, hence overwriting the old
    file. The screenshot that follows shows the directory that was configured in the
    processor, with the text file that was configured for the output. It also shows
    the contents of the file, which will match the contents of the FlowFiles generated
    by the `GenerateFlowFile` processor:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '`PutFile` 处理程序将 FlowFile 保存为机器上的文件，位于 `opt/nifioutput`。位置可以在处理器的配置中指定。如果您没有
    root 权限，您可以将其更改为您的家目录。现在您有一个完整的数据流。这不是一个非常好的数据流，但它将每 10 秒生成一个文件并将其写入磁盘，因此会覆盖旧文件。下面的截图显示了在处理器中配置的目录，以及为输出配置的文本文件。它还显示了文件的内容，这些内容将与
    `GenerateFlowFile` 处理器生成的 FlowFiles 的内容相匹配：'
- en: '![Figure 2.11 – Output of the data flow'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.11 – 数据流输出'
- en: '](img/B15739_02_11.jpg)'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B15739_02_11.jpg]'
- en: Figure 2.11 – Output of the data flow
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.11 – 数据流输出
- en: NiFi will be the primary focus of this book and you will learn much more about
    building data flows starting with the next chapter. The other tool you will learn
    about is Apache Airflow, which we will install next.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: NiFi 将是本书的主要焦点，您将在下一章开始学习更多关于构建数据流的知识。您还将学习另一个工具，Apache Airflow，我们将在下一节进行安装。
- en: PostgreSQL driver
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PostgreSQL 驱动程序
- en: Later in this chapter, you will install PostgreSQL. In order to connect to a
    PostgreSQL database using a NiFi `ExecuteSQL` processor, you need a connection
    pool, and that requires a **Java Database Connectivity** (**JDBC**) driver for
    the database you will be connecting to. This section shows you how to download
    that driver for use later. To download it, go to [https://jdbc.postgresql.org/download.html](https://jdbc.postgresql.org/download.html)
    and download the **PostgreSQL JDBC 4.2 driver, 42.2.10**.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的后面部分，您将安装 PostgreSQL。为了使用 NiFi 的 `ExecuteSQL` 处理器连接到 PostgreSQL 数据库，您需要一个连接池，而这需要您将要连接到的数据库的
    **Java 数据库连接**（**JDBC**）驱动程序。本节将向您展示如何下载该驱动程序以供以后使用。要下载它，请访问 [https://jdbc.postgresql.org/download.html](https://jdbc.postgresql.org/download.html)
    并下载 **PostgreSQL JDBC 4.2 驱动程序，版本 42.2.10**。
- en: Make a new folder in your NiFi installation directory named `drivers`. Move
    the `postgresql-42.2.10.jar` file into the folder. You will later reference this
    `jar` file in your NiFi processor.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在您的 NiFi 安装目录中创建一个名为 `drivers` 的新文件夹。将 `postgresql-42.2.10.jar` 文件移动到该文件夹中。稍后您将在
    NiFi 处理器中引用此 `jar` 文件。
- en: Installing and configuring Apache Airflow
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装和配置 Apache Airflow
- en: Apache Airflow performs the same role as Apache NiFi; however, it allows you
    to create your data flows using pure Python. If you are a strong Python developer,
    this is probably an ideal tool for you. It is currently one of the most popular
    open source data pipeline tools. What it lacks in a polished GUI – compared to
    NiFi – it more than makes up for in the power and freedom to create tasks.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Airflow 执行与 Apache NiFi 相同的角色；然而，它允许您使用纯 Python 创建数据流。如果您是一位强大的 Python
    开发者，这可能是一个理想的工具。它目前是最受欢迎的开源数据管道工具之一。与 NiFi 相比，它在精炼的 GUI 方面可能有所欠缺，但它以强大的功能和创建任务的自由度来弥补这一点。
- en: 'Installing Apache Airflow can be accomplished using `pip`. But, before installing
    Apache Airflow, you can change the location of the Airflow install by exporting
    `AIRFLOW_HOME`. If you want Airflow to install to `opt/airflow`, export the `AIRLFOW_HOME`
    variable, as shown:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `pip` 可以完成 Apache Airflow 的安装。但在安装 Apache Airflow 之前，您可以通过导出 `AIRFLOW_HOME`
    来更改 Airflow 安装的位置。如果您希望 Airflow 安装到 `opt/airflow`，请导出 `AIRLFOW_HOME` 变量，如下所示：
- en: '[PRE9]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The default location for Airflow is `~/airflow`, and for this book, this is
    the location I will use. The next consideration before installing Airflow is to
    determine which sub-packages you want to install. If you do not specify any, Airflow
    installs only what it needs to run. If you know that you will work with PostgreSQL,
    then you should install the sub-package by running the following:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: Airflow 的默认位置是 `~/airflow`，对于本书，我将使用此位置。在安装 Airflow 之前，您需要考虑的是确定您想要安装哪些子包。如果您没有指定任何子包，Airflow
    将仅安装运行所需的内容。如果您知道您将使用 PostgreSQL，那么您应该通过运行以下命令来安装子包：
- en: '[PRE10]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'There is an option to install everything using `all`, or all the databases
    using `all_dbs`. This book will install `postgreSQL`, `slack`, and `celery`. The
    following table lists all the options:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.12 – Table of all package command options'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15739_02_35.jpg)'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.12 – Table of all package command options
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: 'To install Apache Airflow, with the options for `postgreSQL`, `slack`, and
    `celery`, use the following command:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'To run Airflow, you need to initialize the database using the following:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The default database for Airflow is SQLite. This is acceptable for testing and
    running on a single machine, but to run in production and in clusters, you will
    need to change the database to something else, such as PostgreSQL.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: No Command Airflow
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: 'If the `airflow` command cannot be found, you may need to add it to your path:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The Airflow web server runs on port `8080`, the same port as Apache NiFi. You
    already changed the NiFi port to `9300` in the `nifi.properties` file, so you
    can start the Airflow web server using the following command:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'If you did not change the NiFi port, or have any other processes running on
    port `8080`, you can specify the port for Airflow using the `-p` flag, as shown:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Next, start the Airflow scheduler so that you can run your data flows at set
    intervals. Run this command in a different terminal so that you do not kill the
    web server:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Airflow will run without the scheduler, but you will receive a warning when
    you launch the web server if the scheduler is not running. The warning is shown
    in the following screenshot:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.13 – Error message. The scheduler is not running'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15739_02_36.jpg)'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.13 – Error message. The scheduler is not running
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: 'When the scheduler runs, you will see the warning about parallelism being set
    to 1 because of the use of SQLite. You can ignore this warning for now, but later,
    you will want to be able to run more than one task at a time. The warning is shown
    in the following screenshot:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.14 – Scheduler running but warning about SQLite'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15739_02_12.jpg)'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.14 – Scheduler running but warning about SQLite
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: 'With the database initialized, the web server running, and the scheduler running,
    you can now browse to `http://localhost:8080` and see the Airflow GUI. Airflow
    installs several example data flows (**Directed Acyclic Graphs** (**DAGs**)) during
    install. You should see them on the main screen, as shown:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.15 – Airflow installing several examples'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15739_02_13.jpg)'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.15 – Airflow installing several examples
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: 'Airflow DAGs are created using code, so this section will not dive deeply into
    the GUI, but you will explore it more as it is relevant in later chapters. Select
    the first DAG – `example_bash_operator` – and you will be taken to the tree view.
    Click the **Graph View** tab and you should see the DAG shown in the following
    screenshot:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.16 – Graph view of the execute_bash_operator DAG'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15739_02_14.jpg)'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.16 – Graph view of the execute_bash_operator DAG
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: 'The graph view clearly shows the dependencies in the DAG and the order in which
    tasks will run. To watch the DAG run, switch back to **Tree View**. To the left
    of the DAG name, switch the DAG to **On**. Select **Trigger DAG** and you will
    be prompted whether you want to run it now. Select **Yes** and the page will refresh.
    I have run the DAG several times, and you can see the status of those runs in
    the following screenshot:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.17 – Multiple runs of the execute_bash_operator DAG'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15739_02_15.jpg)'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.17 – Multiple runs of the execute_bash_operator DAG
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: Notice that there are two completed, successful runs of the DAG and three runs
    that are still running, with four queued tasks in those runs waiting. The examples
    are great for learning how to use the Airflow GUI, but they will be cluttered
    later. While this does not necessarily create a problem, it will be easier to
    find the tasks you created without all the extras.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: 'You can remove the examples by editing the `airflow.cfg` file. Using `vi` or
    an editor of your choice, find the following line and change `True` to `False`:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The `airflow.cfg` file is shown in the following screenshot, with the cursor
    at the line you need to edit:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.18 – Setting load_examples = False'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15739_02_16.jpg)'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.18 – Setting load_examples = False
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you have edited the `airflow.cfg` file, you must shut down the web server.
    Once the web server has stopped, the changes to the configuration need to be loaded
    into the database. Remember that you set up the database earlier as the first
    step after `pip`, installing Airflow using the following command:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'To make changes to the database, which is what you want to do after changing
    the `airflow.cfg` file, you need to reset it. You can do that using the following
    snippet:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'This will load in the changes from `airflow.cfg` to the metadata database.
    Now, you can restart the web server. When you open the GUI at `http://localhost:8080`,
    it should be empty, as shown in the following screenshot:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.19 – Clean Airflow. Not a single DAG in sight'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15739_02_17.jpg)'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.19 – Clean Airflow. Not a single DAG in sight
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: Airflow is clean and ready to load in the DAGs that you will create in the next
    chapter.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: Installing and configuring Elasticsearch
  id: totrans-162
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Elasticsearch is a search engine. In this book, you will use it as a NoSQL
    database. You will move data both to and from Elasticsearch to other locations.
    To download Elasticsearch, take the following steps:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: 'Use `curl` to download the files, as shown:'
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Extract the files using the following command:'
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'You can edit the `config/elasticsearch.yml` file to name your node and cluster.
    Later in this book, you will set up an Elasticsearch cluster with multiple nodes.
    For now, I have changed the following properties:'
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Now, you can start Elasticsearch. To start Elasticsearch, run the following:'
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Once Elasticsearch has started, you can see the results at `http://localhost:9200`.
    You should see the following output:'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 2.20 – Elasticsearch running'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15739_02_18.jpg)'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.20 – Elasticsearch running
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have a NoSQL database running, you will need a relational database
    as well.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: Installing and configuring Kibana
  id: totrans-177
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Elasticsearch does not ship with a GUI, but rather an API. To add a GUI to
    Elasticsearch, you can use Kibana. By using Kibana, you can better manage and
    interact with Elasticsearch. Kibana will allow you to access the Elasticsearch
    API in a GUI, but more importantly, you can use it to build visualizations and
    dashboards of your data held in Elasticsearch. To install Kibana, take the following
    steps:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: 'Using `wget`, add the key:'
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Then, add the repository along with it:'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Lastly, update `apt` and install Kibana:'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The configuration files for Kibana are located in `etc/kibana` and the application
    is in `/usr/share/kibana/bin`. To launch Kibana, run the following:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'When Kibana is ready, browse to `http://localhost:5601`. Kibana will look for
    any instance of Elasticsearch running on `localhost` at port `9200`. This is where
    you installed Elasticsearch earlier, and also why you did not change the port
    in the configuration. When Kibana opens, you will be asked to choose between **Try
    our sample data** and **Explore on my own**, as shown:'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 2.21 – First launch of Kibana'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15739_02_19.jpg)'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.21 – First launch of Kibana
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: '**Explore on my own** will take you to the main Kibana screen, but since you
    have not created an Elasticsearch index and have not loaded any data, the application
    will be blank.'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: 'To see the different tools available in Kibana, select **Try our sample data**,
    and choose the e-commerce data. The following screenshot shows the options for
    **Load our Sample Data**:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.22 – Load sample data and visualizations'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15739_02_20.jpg)'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.22 – Load sample data and visualizations
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you have loaded the sample data, select the **Discover** icon. From the
    **Discover** section, you are able to look at records in the data. If there are
    dates, you will see a bar chart of counts on given time ranges. You can select
    a bar or change the date ranges from this tab. Selecting a record will show the
    data as a table or the JSON representation of the document. You can also run queries
    on the data from this tab and save them as objects to be used later in visualizations.
    The following screenshot shows the main **Discover** screen:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.23 – The Discover tab'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15739_02_21.jpg)'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.23 – The Discover tab
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: 'From the data available in the **Discover** tab or from a saved query, you
    can create visualizations. The visualizations include bar charts – horizontal
    and vertical, pie/donut charts, counts, markdown, heatmaps, and even a map widget
    to handle geospatial data. The e-commerce data contains geospatial data at the
    country level, but maps can also handle coordinates. The following screenshot
    shows a region map of the e-commerce data:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.24 – A map visualization'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15739_02_22.jpg)'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.24 – A map visualization
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: 'When you have created several visualizations, from a single index or from multiple
    Elasticsearch indices, you can add them to a dashboard. Kibana allows you to load
    widgets using data from multiple indices. When you query or filter within the
    dashboard, as long as the field name exists in each of the indices, all of the
    widgets will update. The following screenshot shows a dashboard, made up of multiple
    visualizations of the e-commerce data:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.25 – A dashboard using multiple widgets from the e-commerce data'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15739_02_23.jpg)'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.25 – A dashboard using multiple widgets from the e-commerce data
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: 'The **Developer Tools** tab comes in handy to quickly test Elasticsearch queries
    before you implement them in a data engineering pipeline. From this tab, you can
    create indices and data, execute queries to filter, search, or aggregate data.
    The results are displayed in the main window. The following screenshot shows a
    record being added to an index, then a search happening for a specific ID:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.26 – A query on a single test record'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15739_02_24.jpg)'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.26 – A query on a single test record
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have installed Elasticsearch and Kibana, the next two sections
    will walk you through installing PostgreSQL and pgAdmin 4\. After that, you will
    have both a SQL and a NoSQL database to explore.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: Installing and configuring PostgreSQL
  id: totrans-213
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'PostgreSQL is an open source relational database. It compares to Oracle or
    Microsoft SQL Server. PostgreSQL also has a plugin – postGIS – which allows spatial
    capabilities in PostgreSQL. In this book, it will be the relational database of
    choice. PostgreSQL can be installed on Linux as a package:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: 'For a Debian-based system, use `apt-get`, as shown:'
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Once the packages have finished installing, you can start the database with
    the following:'
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The default user, `postgres`, does not have a password. To add one, connect
    to the default database:'
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Once connected, you can alter the user and assign a password:'
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'To create a database, you can enter the following command:'
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Using the command line is fast, but sometimes, a GUI makes life easier. PostgreSQL
    has an administration tool – pgAdmin 4\.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: Installing pgAdmin 4
  id: totrans-226
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'pgAdmin 4 will make managing PostgreSQL much easier if you are new to relational
    databases. The web-based GUI will allow you to view your data and allow you to
    visually create tables. To install pgAdmin 4, take the following steps:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: 'You need to add the repository to Ubuntu. The following commands should be
    added to the repository:'
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: You will be prompted to enter an email address for a username and then for a
    password. You should see the following screen:![Figure 2.27 – Creating a user
    for pgAdmin 4
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B15739_02_25.jpg)'
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 2.27 – Creating a user for pgAdmin 4
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'When the install has completed, you can browse to `http://localhost/pgadmin4`
    and you will be presented with the login screen, as shown in the following screenshot.
    Enter the credentials for the user you just created during the install:'
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 2.28 – Logging in to pgAdmin 4'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15739_02_26.jpg)'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.28 – Logging in to pgAdmin 4
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: Once you have logged in, you can manage your databases from the GUI. The next
    section will give you a brief tour of pgAdmin 4.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: A tour of pgAdmin 4
  id: totrans-238
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: After you log in to pgAdmin 4, you will see a dashboard with a server icon on
    the left side. There are currently no servers configured, so you will want to
    add the server you installed earlier in this chapter.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on the **Add new server** icon on the dashboard. You will see a pop-up
    window. Add the information for your PostgreSQL instance, as shown in the following
    screenshot:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.29 – Adding a new server'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15739_02_27.jpg)'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.29 – Adding a new server
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you add the server, you can expand the server icon and you should see
    the database you created earlier – `dataengineering`. Expand the `dataengineering`
    database, then `schemas`, then `public`. You will be able to right-click on **Tables**
    to add a table to the database, as shown in the following screenshot:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.30 – Creating a table'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15739_02_28.jpg)'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.30 – Creating a table
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: 'To populate the table with data, name the table, then select the **Columns**
    tab. Create a table with some information about people. The table is shown in
    the following screenshot:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.31 – Table data'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15739_02_29.jpg)'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.31 – Table data
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, you will use Python to populate this table with data using
    the `faker` library.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-253
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned how to install and configure many of the tools
    used by data engineers. Having done so, you now have a working environment in
    which you can build data pipelines. In production, you would not run all these
    tools on a single machine, but for the next few chapters, this will help you learn
    and get started quickly. You now have two working databases – Elasticsearch and
    PostgreSQL – as well as two tools for building data pipelines – Apache NiFi and
    Apache Airflow.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, you will start to use Apache NiFi and Apache Airflow (Python)
    to connect to files, as well as Elasticsearch and PostgreSQL. You will build your
    first pipeline in NiFi and Airflow to move a CSV to a database.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
