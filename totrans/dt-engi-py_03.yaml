- en: '*Chapter 2*: Building Our Data Engineering Infrastructure'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, you learned what data engineers do and their roles
    and responsibilities. You were also introduced to some of the tools that they
    use, primarily the different types of databases, programming languages, and data
    pipeline creation and scheduling tools.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, you will install and configure several tools that will help
    you throughout the rest of this book. You will learn how to install and configure
    two different databases – PostgreSQL and Elasticsearch – two tools to assist in
    building workflows – Airflow and Apache NiFi, and two administrative tools – pgAdmin
    for PostgreSQL and Kibana for Elasticsearch.
  prefs: []
  type: TYPE_NORMAL
- en: With these tools, you will be able to write data engineering pipelines to move
    data from one source to another and also be able to visualize the results. As
    you learn how to build pipelines, being able to see the data and how it has transformed
    will be useful to you in debugging any errors. As you progress, you may no longer
    need these tools, but other roles and users you will support may require them,
    so having a basic understanding of the tools will be useful.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Installing and configuring Apache NiFi
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Installing and configuring Apache Airflow
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Installing and configuring Elasticsearch
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Installing and configuring Kibana
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Installing and configuring PostgreSQL
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Installing pgAdmin 4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Installing and configuring Apache NiFi
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Apache NiFi is the primary tool used in this book for building data engineering
    pipelines. NiFi allows you to build data pipelines using prebuilt processors that
    you can configure for your needs. You do not need to write any code to get NiFi
    pipelines working. It also provides a scheduler to set how frequently you would
    like your pipelines to run. In addition, it will handle backpressure – if one
    task works faster than another, you can slow down the task.
  prefs: []
  type: TYPE_NORMAL
- en: 'To install Apache NiFi, you will need to download it from [https://nifi.apache.org/download.html](https://nifi.apache.org/download.html):'
  prefs: []
  type: TYPE_NORMAL
- en: 'By using `curl`, you can download NiFi using the following command line:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Extract the NiFi files from the `.tar.gz` file using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You will now have a folder named `nifi-1.12.1`. You can run NiFi by executing
    the following from inside the folder:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'If you already have Java installed and configured, when you run the status
    tool as shown in the following snippet, you will see a path set for `JAVA_HOME`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'If you do not see `JAVA_HOME` set, you may need to install Java using the following
    command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then, you should edit `.bash_profile` to include the following line so that
    NiFi can find the `JAVA_HOME` variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Lastly, reload `.bash_profile`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: When you run for the status on NiFi, you should now see a path for `JAVA_HOME`:![Figure
    2.1 – NiFi is running
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B15739_02_01.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 2.1 – NiFi is running
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'When NiFi is ready, which may take a minute, open your web browser and go to
    `http://localhost:8080/nifi/`. You should be seeing the following screen:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 2.2 – The NiFi GUI'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15739_02_02.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.2 – The NiFi GUI
  prefs: []
  type: TYPE_NORMAL
- en: 'In later chapters, you will learn about many of the available configurations
    for NiFi, but for now, you will only change the port NiFi runs on. In `conf/nifi.properties`,
    change `nifi.web.http.port=8080` under the `web properties` heading to `9300`,
    as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'If your firewall is on, you may need to open the port:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Now, you can relaunch NiFi and view the GUI at `http://localhost:9300/nifi/`.
  prefs: []
  type: TYPE_NORMAL
- en: A quick tour of NiFi
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The NiFi GUI will be blank because you have not added any processors or processor
    groups. At the top of the screen are the component toolbar and the status bar.
    The component toolbar has the tools needed for building a data flow. The status
    bar, as the title suggests, gives an overview of the current status of your NiFi
    instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.3 – NiFi component toolbar and status bar'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15739_02_03.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.3 – NiFi component toolbar and status bar
  prefs: []
  type: TYPE_NORMAL
- en: 'The tool you will use the most is the **Processor** tool. The other tools,
    from left to right, are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Input Port**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Output Port**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Processor Group**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Remote Processor Group**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Funnel**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Template**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Label**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With these limited tools, you are able to build complex data flows.
  prefs: []
  type: TYPE_NORMAL
- en: 'A NiFi data flow is made up of processors, connections, and relationships.
    NiFi has over 100 processors all ready for you to use. By clicking the **Processor**
    tool and dragging it on to the canvas, you will be prompted to select the processor
    you would like to use, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.4 – Processors you can add to the canvas'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15739_02_04.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.4 – Processors you can add to the canvas
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the search bar, you can search for `GenerateFlowFile`. Select the processor
    and it will be added to the canvas. This processor will allow you to create FlowFiles
    with text. Drag the `PutFile`, then select the processor. This processor will
    save the FlowFile to disk as a file. You should now have a canvas as in the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.5 – Processors added to the canvas – with errors'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15739_02_05.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.5 – Processors added to the canvas – with errors
  prefs: []
  type: TYPE_NORMAL
- en: When you add the processors, there will be a caution symbol in the left corner
    of the box. They have not been configured, so you will get warnings and errors.
    The preceding screenshot shows that the `PutFile` processor is missing the `Directory`
    parameter, there is no upstream connection, and the relationships for success
    and failure have not been handled.
  prefs: []
  type: TYPE_NORMAL
- en: 'To configure the processor, you can either double-click on the processor or
    right-click and select **Properties**. The following screenshot shows the properties
    for the processor:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.6 – Configuring the GenerateFlowFile processor'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15739_02_06.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.6 – Configuring the GenerateFlowFile processor
  prefs: []
  type: TYPE_NORMAL
- en: 'The following steps should be followed to configure a processor:'
  prefs: []
  type: TYPE_NORMAL
- en: You must have a value set for any parameters that are bold. Each parameter has
    a question mark icon to help you.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You can also right-click on the processes and select the option to use.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For `GenerateFlowfile`, all the required parameters are already filled out.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the preceding screenshot, I have added a value to the parameter of **Custom
    Text**. To add custom properties, you can click the plus sign at the upper-right
    of the window. You will be prompted for a name and value. I have added my property
    filename and set the value to **This is a file from nifi**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once configured, the yellow warning icon in the box will turn into a square
    (stop button).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now that you have configured the first processor, you need to create a connection
    and specify a relationship – a relationship is usually on success or failure,
    but the relationship types change based on the processor.
  prefs: []
  type: TYPE_NORMAL
- en: 'To create a connection, hover over the processor box and a circle and arrow
    will appear:'
  prefs: []
  type: TYPE_NORMAL
- en: Drag the circle to the processor underneath it (`PutFile`).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It will snap into place, then prompt you to specify which relationship you want
    to make this connection for. The only choice will be **Success** and it will already
    be checked.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Select `GenerateFlowFile` processor and select **Run**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The red square icon will change to a green play button. You should now have
    a data flow as in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.7 – Data flow half running'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15739_02_07.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.7 – Data flow half running
  prefs: []
  type: TYPE_NORMAL
- en: 'Between the two processor boxes, you can see the queue. It will show the number
    of FlowFiles and the size. If you right-click on the queue, you will see a list
    of the FlowFiles and you can get details about each one, see their contents, and
    download them. The following screenshot shows the list view of FlowFiles in a
    queue:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.8 – List of FlowFiles in the queue'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15739_02_08.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.8 – List of FlowFiles in the queue
  prefs: []
  type: TYPE_NORMAL
- en: 'You can view the details of the flow and the contents. The details view has
    two tables – details and attributes. From the **DETAILS** tab, you will see some
    of the NiFi metadata and have the ability to view or download the FlowFile. The
    **ATTRIBUTES** tab contains attributes assigned by NiFi and any attributes you
    may have created in the data pipeline. The **DETAILS** tab is shown in the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.9 – Details of a FlowFile'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15739_02_09.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.9 – Details of a FlowFile
  prefs: []
  type: TYPE_NORMAL
- en: 'From the **DETAILS** tab, if you select to view the FlowFile, you will see
    the contents in the window. This works best for text-based data, but there is
    also an option to view the FlowFile in hex format. There is also the option to
    display raw or formatted text. The following screenshot shows the raw FlowFile
    data, which is just a simple text string:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.10 – Contents of a FlowFile'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15739_02_10.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.10 – Contents of a FlowFile
  prefs: []
  type: TYPE_NORMAL
- en: 'The `PutFile` process saved the FlowFile as a file on your machine at `opt/nifioutput`.
    The location can be specified in the configuration of the processor. If you do
    not have root privileges, you can change the location to your home directory.
    You now have a complete data flow. It is not a very good data flow, but it will
    generate a file every 10 seconds and write it to disk, hence overwriting the old
    file. The screenshot that follows shows the directory that was configured in the
    processor, with the text file that was configured for the output. It also shows
    the contents of the file, which will match the contents of the FlowFiles generated
    by the `GenerateFlowFile` processor:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.11 – Output of the data flow'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15739_02_11.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.11 – Output of the data flow
  prefs: []
  type: TYPE_NORMAL
- en: NiFi will be the primary focus of this book and you will learn much more about
    building data flows starting with the next chapter. The other tool you will learn
    about is Apache Airflow, which we will install next.
  prefs: []
  type: TYPE_NORMAL
- en: PostgreSQL driver
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Later in this chapter, you will install PostgreSQL. In order to connect to a
    PostgreSQL database using a NiFi `ExecuteSQL` processor, you need a connection
    pool, and that requires a **Java Database Connectivity** (**JDBC**) driver for
    the database you will be connecting to. This section shows you how to download
    that driver for use later. To download it, go to [https://jdbc.postgresql.org/download.html](https://jdbc.postgresql.org/download.html)
    and download the **PostgreSQL JDBC 4.2 driver, 42.2.10**.
  prefs: []
  type: TYPE_NORMAL
- en: Make a new folder in your NiFi installation directory named `drivers`. Move
    the `postgresql-42.2.10.jar` file into the folder. You will later reference this
    `jar` file in your NiFi processor.
  prefs: []
  type: TYPE_NORMAL
- en: Installing and configuring Apache Airflow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Apache Airflow performs the same role as Apache NiFi; however, it allows you
    to create your data flows using pure Python. If you are a strong Python developer,
    this is probably an ideal tool for you. It is currently one of the most popular
    open source data pipeline tools. What it lacks in a polished GUI – compared to
    NiFi – it more than makes up for in the power and freedom to create tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 'Installing Apache Airflow can be accomplished using `pip`. But, before installing
    Apache Airflow, you can change the location of the Airflow install by exporting
    `AIRFLOW_HOME`. If you want Airflow to install to `opt/airflow`, export the `AIRLFOW_HOME`
    variable, as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The default location for Airflow is `~/airflow`, and for this book, this is
    the location I will use. The next consideration before installing Airflow is to
    determine which sub-packages you want to install. If you do not specify any, Airflow
    installs only what it needs to run. If you know that you will work with PostgreSQL,
    then you should install the sub-package by running the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'There is an option to install everything using `all`, or all the databases
    using `all_dbs`. This book will install `postgreSQL`, `slack`, and `celery`. The
    following table lists all the options:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.12 – Table of all package command options'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15739_02_35.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.12 – Table of all package command options
  prefs: []
  type: TYPE_NORMAL
- en: 'To install Apache Airflow, with the options for `postgreSQL`, `slack`, and
    `celery`, use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'To run Airflow, you need to initialize the database using the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The default database for Airflow is SQLite. This is acceptable for testing and
    running on a single machine, but to run in production and in clusters, you will
    need to change the database to something else, such as PostgreSQL.
  prefs: []
  type: TYPE_NORMAL
- en: No Command Airflow
  prefs: []
  type: TYPE_NORMAL
- en: 'If the `airflow` command cannot be found, you may need to add it to your path:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The Airflow web server runs on port `8080`, the same port as Apache NiFi. You
    already changed the NiFi port to `9300` in the `nifi.properties` file, so you
    can start the Airflow web server using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'If you did not change the NiFi port, or have any other processes running on
    port `8080`, you can specify the port for Airflow using the `-p` flag, as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, start the Airflow scheduler so that you can run your data flows at set
    intervals. Run this command in a different terminal so that you do not kill the
    web server:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Airflow will run without the scheduler, but you will receive a warning when
    you launch the web server if the scheduler is not running. The warning is shown
    in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.13 – Error message. The scheduler is not running'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15739_02_36.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.13 – Error message. The scheduler is not running
  prefs: []
  type: TYPE_NORMAL
- en: 'When the scheduler runs, you will see the warning about parallelism being set
    to 1 because of the use of SQLite. You can ignore this warning for now, but later,
    you will want to be able to run more than one task at a time. The warning is shown
    in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.14 – Scheduler running but warning about SQLite'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15739_02_12.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.14 – Scheduler running but warning about SQLite
  prefs: []
  type: TYPE_NORMAL
- en: 'With the database initialized, the web server running, and the scheduler running,
    you can now browse to `http://localhost:8080` and see the Airflow GUI. Airflow
    installs several example data flows (**Directed Acyclic Graphs** (**DAGs**)) during
    install. You should see them on the main screen, as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.15 – Airflow installing several examples'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15739_02_13.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.15 – Airflow installing several examples
  prefs: []
  type: TYPE_NORMAL
- en: 'Airflow DAGs are created using code, so this section will not dive deeply into
    the GUI, but you will explore it more as it is relevant in later chapters. Select
    the first DAG – `example_bash_operator` – and you will be taken to the tree view.
    Click the **Graph View** tab and you should see the DAG shown in the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.16 – Graph view of the execute_bash_operator DAG'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15739_02_14.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.16 – Graph view of the execute_bash_operator DAG
  prefs: []
  type: TYPE_NORMAL
- en: 'The graph view clearly shows the dependencies in the DAG and the order in which
    tasks will run. To watch the DAG run, switch back to **Tree View**. To the left
    of the DAG name, switch the DAG to **On**. Select **Trigger DAG** and you will
    be prompted whether you want to run it now. Select **Yes** and the page will refresh.
    I have run the DAG several times, and you can see the status of those runs in
    the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.17 – Multiple runs of the execute_bash_operator DAG'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15739_02_15.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.17 – Multiple runs of the execute_bash_operator DAG
  prefs: []
  type: TYPE_NORMAL
- en: Notice that there are two completed, successful runs of the DAG and three runs
    that are still running, with four queued tasks in those runs waiting. The examples
    are great for learning how to use the Airflow GUI, but they will be cluttered
    later. While this does not necessarily create a problem, it will be easier to
    find the tasks you created without all the extras.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can remove the examples by editing the `airflow.cfg` file. Using `vi` or
    an editor of your choice, find the following line and change `True` to `False`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The `airflow.cfg` file is shown in the following screenshot, with the cursor
    at the line you need to edit:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.18 – Setting load_examples = False'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15739_02_16.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.18 – Setting load_examples = False
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you have edited the `airflow.cfg` file, you must shut down the web server.
    Once the web server has stopped, the changes to the configuration need to be loaded
    into the database. Remember that you set up the database earlier as the first
    step after `pip`, installing Airflow using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'To make changes to the database, which is what you want to do after changing
    the `airflow.cfg` file, you need to reset it. You can do that using the following
    snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'This will load in the changes from `airflow.cfg` to the metadata database.
    Now, you can restart the web server. When you open the GUI at `http://localhost:8080`,
    it should be empty, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.19 – Clean Airflow. Not a single DAG in sight'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15739_02_17.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.19 – Clean Airflow. Not a single DAG in sight
  prefs: []
  type: TYPE_NORMAL
- en: Airflow is clean and ready to load in the DAGs that you will create in the next
    chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Installing and configuring Elasticsearch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Elasticsearch is a search engine. In this book, you will use it as a NoSQL
    database. You will move data both to and from Elasticsearch to other locations.
    To download Elasticsearch, take the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Use `curl` to download the files, as shown:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Extract the files using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You can edit the `config/elasticsearch.yml` file to name your node and cluster.
    Later in this book, you will set up an Elasticsearch cluster with multiple nodes.
    For now, I have changed the following properties:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, you can start Elasticsearch. To start Elasticsearch, run the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Once Elasticsearch has started, you can see the results at `http://localhost:9200`.
    You should see the following output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 2.20 – Elasticsearch running'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15739_02_18.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.20 – Elasticsearch running
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have a NoSQL database running, you will need a relational database
    as well.
  prefs: []
  type: TYPE_NORMAL
- en: Installing and configuring Kibana
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Elasticsearch does not ship with a GUI, but rather an API. To add a GUI to
    Elasticsearch, you can use Kibana. By using Kibana, you can better manage and
    interact with Elasticsearch. Kibana will allow you to access the Elasticsearch
    API in a GUI, but more importantly, you can use it to build visualizations and
    dashboards of your data held in Elasticsearch. To install Kibana, take the following
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Using `wget`, add the key:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then, add the repository along with it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Lastly, update `apt` and install Kibana:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The configuration files for Kibana are located in `etc/kibana` and the application
    is in `/usr/share/kibana/bin`. To launch Kibana, run the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'When Kibana is ready, browse to `http://localhost:5601`. Kibana will look for
    any instance of Elasticsearch running on `localhost` at port `9200`. This is where
    you installed Elasticsearch earlier, and also why you did not change the port
    in the configuration. When Kibana opens, you will be asked to choose between **Try
    our sample data** and **Explore on my own**, as shown:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 2.21 – First launch of Kibana'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15739_02_19.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.21 – First launch of Kibana
  prefs: []
  type: TYPE_NORMAL
- en: '**Explore on my own** will take you to the main Kibana screen, but since you
    have not created an Elasticsearch index and have not loaded any data, the application
    will be blank.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To see the different tools available in Kibana, select **Try our sample data**,
    and choose the e-commerce data. The following screenshot shows the options for
    **Load our Sample Data**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.22 – Load sample data and visualizations'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15739_02_20.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.22 – Load sample data and visualizations
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you have loaded the sample data, select the **Discover** icon. From the
    **Discover** section, you are able to look at records in the data. If there are
    dates, you will see a bar chart of counts on given time ranges. You can select
    a bar or change the date ranges from this tab. Selecting a record will show the
    data as a table or the JSON representation of the document. You can also run queries
    on the data from this tab and save them as objects to be used later in visualizations.
    The following screenshot shows the main **Discover** screen:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.23 – The Discover tab'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15739_02_21.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.23 – The Discover tab
  prefs: []
  type: TYPE_NORMAL
- en: 'From the data available in the **Discover** tab or from a saved query, you
    can create visualizations. The visualizations include bar charts – horizontal
    and vertical, pie/donut charts, counts, markdown, heatmaps, and even a map widget
    to handle geospatial data. The e-commerce data contains geospatial data at the
    country level, but maps can also handle coordinates. The following screenshot
    shows a region map of the e-commerce data:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.24 – A map visualization'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15739_02_22.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.24 – A map visualization
  prefs: []
  type: TYPE_NORMAL
- en: 'When you have created several visualizations, from a single index or from multiple
    Elasticsearch indices, you can add them to a dashboard. Kibana allows you to load
    widgets using data from multiple indices. When you query or filter within the
    dashboard, as long as the field name exists in each of the indices, all of the
    widgets will update. The following screenshot shows a dashboard, made up of multiple
    visualizations of the e-commerce data:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.25 – A dashboard using multiple widgets from the e-commerce data'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15739_02_23.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.25 – A dashboard using multiple widgets from the e-commerce data
  prefs: []
  type: TYPE_NORMAL
- en: 'The **Developer Tools** tab comes in handy to quickly test Elasticsearch queries
    before you implement them in a data engineering pipeline. From this tab, you can
    create indices and data, execute queries to filter, search, or aggregate data.
    The results are displayed in the main window. The following screenshot shows a
    record being added to an index, then a search happening for a specific ID:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.26 – A query on a single test record'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15739_02_24.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.26 – A query on a single test record
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have installed Elasticsearch and Kibana, the next two sections
    will walk you through installing PostgreSQL and pgAdmin 4\. After that, you will
    have both a SQL and a NoSQL database to explore.
  prefs: []
  type: TYPE_NORMAL
- en: Installing and configuring PostgreSQL
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'PostgreSQL is an open source relational database. It compares to Oracle or
    Microsoft SQL Server. PostgreSQL also has a plugin – postGIS – which allows spatial
    capabilities in PostgreSQL. In this book, it will be the relational database of
    choice. PostgreSQL can be installed on Linux as a package:'
  prefs: []
  type: TYPE_NORMAL
- en: 'For a Debian-based system, use `apt-get`, as shown:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Once the packages have finished installing, you can start the database with
    the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The default user, `postgres`, does not have a password. To add one, connect
    to the default database:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Once connected, you can alter the user and assign a password:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To create a database, you can enter the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Using the command line is fast, but sometimes, a GUI makes life easier. PostgreSQL
    has an administration tool – pgAdmin 4\.
  prefs: []
  type: TYPE_NORMAL
- en: Installing pgAdmin 4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'pgAdmin 4 will make managing PostgreSQL much easier if you are new to relational
    databases. The web-based GUI will allow you to view your data and allow you to
    visually create tables. To install pgAdmin 4, take the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'You need to add the repository to Ubuntu. The following commands should be
    added to the repository:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You will be prompted to enter an email address for a username and then for a
    password. You should see the following screen:![Figure 2.27 – Creating a user
    for pgAdmin 4
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B15739_02_25.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 2.27 – Creating a user for pgAdmin 4
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'When the install has completed, you can browse to `http://localhost/pgadmin4`
    and you will be presented with the login screen, as shown in the following screenshot.
    Enter the credentials for the user you just created during the install:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 2.28 – Logging in to pgAdmin 4'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15739_02_26.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.28 – Logging in to pgAdmin 4
  prefs: []
  type: TYPE_NORMAL
- en: Once you have logged in, you can manage your databases from the GUI. The next
    section will give you a brief tour of pgAdmin 4.
  prefs: []
  type: TYPE_NORMAL
- en: A tour of pgAdmin 4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: After you log in to pgAdmin 4, you will see a dashboard with a server icon on
    the left side. There are currently no servers configured, so you will want to
    add the server you installed earlier in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on the **Add new server** icon on the dashboard. You will see a pop-up
    window. Add the information for your PostgreSQL instance, as shown in the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.29 – Adding a new server'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15739_02_27.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.29 – Adding a new server
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you add the server, you can expand the server icon and you should see
    the database you created earlier – `dataengineering`. Expand the `dataengineering`
    database, then `schemas`, then `public`. You will be able to right-click on **Tables**
    to add a table to the database, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.30 – Creating a table'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15739_02_28.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.30 – Creating a table
  prefs: []
  type: TYPE_NORMAL
- en: 'To populate the table with data, name the table, then select the **Columns**
    tab. Create a table with some information about people. The table is shown in
    the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.31 – Table data'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15739_02_29.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.31 – Table data
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, you will use Python to populate this table with data using
    the `faker` library.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned how to install and configure many of the tools
    used by data engineers. Having done so, you now have a working environment in
    which you can build data pipelines. In production, you would not run all these
    tools on a single machine, but for the next few chapters, this will help you learn
    and get started quickly. You now have two working databases – Elasticsearch and
    PostgreSQL – as well as two tools for building data pipelines – Apache NiFi and
    Apache Airflow.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, you will start to use Apache NiFi and Apache Airflow (Python)
    to connect to files, as well as Elasticsearch and PostgreSQL. You will build your
    first pipeline in NiFi and Airflow to move a CSV to a database.
  prefs: []
  type: TYPE_NORMAL
