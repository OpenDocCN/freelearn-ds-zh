- en: '12'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Data Analysis and Visualization with R and Python in Excel – A Case Study
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this final chapter, we are going to perform an analysis—**visualization**
    and a simple model—built with data from Excel and place all those outcomes back
    into it. This can be useful when there is a lot of data, or the calculations themselves
    are best suited to being done outside of Excel.
  prefs: []
  type: TYPE_NORMAL
- en: First, we will start with importing our data and then performing some data exploration
    via visualizations. For this chapter, we are going to use the `diamonds` dataset
    from the R package called `ggplot2`. We will view the data where the price is
    the outcome and look at it via different facets of the diamond’s characteristics.
    After the visualizations are done, we will perform some simple modeling to predict
    the price of a diamond based on its characteristics.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’re going to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Getting a visualization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Performing a simple **machine learning** (**ML**) model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For this chapter, we will be using the following packages/libraries:'
  prefs: []
  type: TYPE_NORMAL
- en: '`ggplot2 3.4.4`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dplyr 1.1.4`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`healthyR 0.2.1`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`readxl 1.4.3`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tidyverse 2.0.0`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`janitor 2.2.0`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`writexl 1.5.0`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`healthyR.ai 0.0.13`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Getting visualizations with R
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we are going to go over getting some visualizations of the
    data. We will create several visualizations and give short interpretations of
    the outcomes in them. For this, we will create two histograms in base R and a
    few different visuals using the `ggplot2` library.
  prefs: []
  type: TYPE_NORMAL
- en: Getting the data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The first thing we need to do is load the libraries and get the data. I am
    working in a directory specific to this book so I can source the function directly
    from the chapter I wrote the `read_excel_sheets()?` function in; your path might
    be different. Let’s look at the code up to this point:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'What we have done here is to simply call in a few libraries into our environment,
    pull in the sheet reading function, and read in our data. We loaded the `read_excel_sheets()`
    function into our environment using the `source()` command. You might be wondering
    how the data was created for this section, and it is important because it was
    exported from the `ggplot2` library. Here is the code if you want to re-create
    the data so that the preceding code will work, and the following sections will
    also work:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Now that we have gone over how to produce and read in the data, let’s start
    taking a look at some visuals.
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing the data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We are going to use two different methods of creating graphs in this section,
    firstly, with base R and secondly with `ggplot2`. With that in mind, let’s get
    started.
  prefs: []
  type: TYPE_NORMAL
- en: Base R visuals
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The first thing that we are going to do is to create some histograms of the
    `price` column in the `diamonds` dataset. The price is the outcome variable we
    will use as the predictor in our model in the next section. First, we need to
    create a vector of breaks that will get passed to the histograms. There is much
    literature available on techniques for optimal binning strategies. The basic crux
    is that this will help provide the appropriate shape to the histogram that best
    represents the data. That is a separate topic and not one that we will pursue
    in this book, as it is a topic that can span a book unto itself. There is a function
    called `opt_bin()` from the `healthyR` package that will produce a tibble of break
    points for a `value` column that is passed to it. Let’s look at it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The purpose of doing this is to try and capture the proper density of information
    in the data. The `hist()` base function does a good job of this already with a
    standard method. Now, let’s go ahead and create the plots and see the methods
    side by side. We will use `par(mfrow = c(1, 2))` so that we can plot them side
    by side:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s take a look at what it produced:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.1 – Histogram comparison between default binning and optimal binning](img/B19142_12_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.1 – Histogram comparison between default binning and optimal binning
  prefs: []
  type: TYPE_NORMAL
- en: We can see that the shape of the histogram is slightly different, but again,
    this strategy might not work for you, or you may have another strategy that you
    employ with regularity; this was simply a way to illustrate that different methods
    do exist. That is the end of making visuals via base R; we will now move on to
    using `ggplot2`.
  prefs: []
  type: TYPE_NORMAL
- en: Visuals with ggplot2
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We are now going to make the rest of the visuals with `ggplot2` as I find the
    syntax a bit easier and the graphics one can produce are a bit more sophisticated,
    aside from the fact that the package is part of the `tidyverse`, which means it
    is interoperable with the rest of the packages in it such as `dplyr`. You may
    need to install the `hexbin` package as well. Let’s get started:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Here’s a breakdown of the code.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the data and aesthetics, this is how it goes:'
  prefs: []
  type: TYPE_NORMAL
- en: '`df |> ggplot(...)`: This starts the visualization using the data in `df`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`aes(x = carat, y = price, fill = cut)`: This defines aesthetics for the plot:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`x`: The x-axis represents the carat weight'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`y`: The y-axis represents the price'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`fill`: The color fill represents the diamond cut'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For the hexagon geometry, this is what we have:'
  prefs: []
  type: TYPE_NORMAL
- en: '`geom_hex(bins = length(breaks), alpha = 1/5)`: This plots hexagons representing
    data points.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`bins`: This controls the number of bins for the hexagonal grid. Here, it uses
    the same number as defined in `breaks` (not shown in the provided code).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`alpha`: This is the opacity of the hexagons, set to 1/5 for better visibility.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For faceting by clarity, this is what we have:'
  prefs: []
  type: TYPE_NORMAL
- en: '`facet_wrap(~ clarity, scales = "free")`: This groups data into subplots based
    on diamond clarity, with independent color scales for each plot'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'These are the themes and labels:'
  prefs: []
  type: TYPE_NORMAL
- en: '`theme_minimal()`: This applies a minimal theme for cleaner visuals'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`labs(..., title = "Diamonds Data")`: This adds labels for axes and title.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This is the code for the colorblind-friendly color scale:'
  prefs: []
  type: TYPE_NORMAL
- en: '`hr_scale_color_colorblind()`: This ensures the color palette is optimized
    for colorblind viewers'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, let’s check the output.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.2 – ggplot2 of diamonds data with hex geometry](img/B19142_12_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.2 – ggplot2 of diamonds data with hex geometry
  prefs: []
  type: TYPE_NORMAL
- en: Overall, this code visualizes the relationship between the carat weight, price,
    and cut of diamonds, considering clarity groups with a colorblind-friendly color
    scheme.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next visual we will see uses a boxplot to check the dispersion of the data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Again, let’s see the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.3 – ggplot2 boxplot of price dispersion](img/B19142_12_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.3 – ggplot2 boxplot of price dispersion
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now look at the mean price with a question to ponder: does it show the
    information accurately? Let’s refer to the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of this code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.4 – ggplot2 mean price dispersion](img/B19142_12_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.4 – ggplot2 mean price dispersion
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is another view of the mean price, but this time by looking at the mean
    price per carat:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s see what story this tells:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.5 – ggplot mean price per carat](img/B19142_12_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.5 – ggplot mean price per carat
  prefs: []
  type: TYPE_NORMAL
- en: These are very good diamonds – does it matter what the cut or color is as long
    as the clarity is better than fair? Seems like it does not.
  prefs: []
  type: TYPE_NORMAL
- en: 'Lastly, we will look at a histogram of price faceted by cut rather than colored
    by it and we are going to use the `breaks` data we created previously. See the
    following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s take a last look:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.6 – Histogram of price faceted by the cut](img/B19142_12_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.6 – Histogram of price faceted by the cut
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have created all the visuals, we can move on to the modeling phase.
  prefs: []
  type: TYPE_NORMAL
- en: Performing a simple ML model with R
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we are going to go over performing a simple ML model in R.
    There are so many different ways to do this in R that it would be impossible for
    me to list them all, however, CRAN has done this so you and I don’t have to. If
    you want to see a task view of ML on CRAN, you can follow this link: [https://cran.r-project.org/view=MachineLearning](https://cran.r-project.org/view=MachineLearning).'
  prefs: []
  type: TYPE_NORMAL
- en: For this section, we are going to use the XGBoost algorithm as implemented by
    the `healthyR.ai` package. The algorithm is not written differently, the only
    difference is how data is saved in the output. The `healthyR.ai` package also
    contains a preprocessor for the XGBoost algorithm to ensure that the input data
    matches what the algorithm is expecting before modeling. The two main functions
    that we will be using are `hai_xgboost_data_prepper()` and `hai_auto_xgboost()`.
  prefs: []
  type: TYPE_NORMAL
- en: We will not cover loading the data in again as it was covered previously. Let’s
    get started!
  prefs: []
  type: TYPE_NORMAL
- en: Data preprocessing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before we get started, we are going to preprocess our data so that it meets
    the needs of the algorithm for modeling. This is made easy by the `hai_xgboost_data_prepper()`
    function from the `healthyR.ai` library. We are going to see what the data looks
    like before and after the data is processed. Let’s see the following code and
    then the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'This is the data before processing begins. We see that there are 10 columns,
    and we can see the datatypes of each of those columns clearly in the output. Now,
    let’s create a `recipe` object by passing our data into `hai_xgboost_data_prepper()`
    and checking the output from there. This function takes two arguments: `.data`
    and `.recipe_formula`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let’s look at the processed data. We can see in the following that columns
    have been added and all the datatypes are now `<dbl>`, which is what was called
    for in the preprocessor:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Now that we have seen the data after processing, let’s use the `hai_auto_xgboost()`
    function to perform the modeling. Here is the full function call and documentation
    on it can be at [https://www.spsanderson.com/healthyR.ai/reference/hai_auto_xgboost.html:](https://www.spsanderson.com/healthyR.ai/reference/hai_auto_xgboost.html:)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: We will now create the model and check the output. I am using `.num_cores =
    10`, `.best_metric = "rsq"`, and `.model_type = "regression"`, and I do not suggest
    you run this yourself unless you have plenty of time to spare.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, perform modeling using the `hai_auto_xgboost()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'This produces a rather large object; on my machine, it is 196.1 MB, with the
    largest portion coming from `$tuned_info` sitting at `169836312 bytes`, which
    is mainly due to the `plotly` plot and the Monte Carlo cross-validation `tibble`,
    due to the size of the incoming data. We can now take a look at some of the objects
    that are exported:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: The first thing we did was pull out the fitted workflow object, which can be
    used to make predictions on data using the generic `predict()` function. We know
    it is a `workflow` object from when we ran `class(xgb_wflw_fit)`.
  prefs: []
  type: TYPE_NORMAL
- en: The final thing we do is to actually take a look at the specification of the
    fitted model itself. This will show us what the parameters were set to during
    the cross-validation process. It is important to remember that I did not use a
    seed, which means that you can obtain different results. This was meant to be
    a primer and not an exhaustive write-up of the inputs and outputs, but rather
    just a showcase of how an XGBoost model can be fitted to data from an Excel file,
    given one cannot perform such a modeling task with the ease it was done in R.
  prefs: []
  type: TYPE_NORMAL
- en: Now, we can move on to the Python section, where we will follow a similar workflow
    for the same dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Getting visualizations with Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we are going to go over visualizations of the data in Python,
    analogous to the preceding R section. We will use `plotnine` to have visualizations
    similar to those created in R using `ggplot2` and provide interpretations of the
    results.
  prefs: []
  type: TYPE_NORMAL
- en: Getting the data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Like in the earlier chapters, we will load the data using `pandas`. Just like
    before, the path to the XLSX file may be different for you from what I have, so
    adjust the `filepath` accordingly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Note that we use the raw `diamonds` dataset without spitting it first and then
    recombining it, as it was done in the R part of the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing the data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Once we have our data loaded, we can use `plotnine` to create visualizations.
    In this section, we’ll demonstrate how to visualize various aspects of the `diamonds`
    dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the dataset loaded before, we can have a first look at the data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: This Python code replicates the R code used at the beginning of the chapter
    using `plotnine` for data visualization. The `ggplot()` function initializes the
    plot, `aes()` defines the aesthetics, `geom_bin2d()` adds the geometry, `facet_wrap()`
    creates facets, `theme_minimal()` sets the theme, `labs()` adds labels, and `scale_fill_manual(values=color_palette)`
    ensures the color palette is colorblind friendly using the predefined `color_palette`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The resulting image will look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.7 – The plotnine scatterplot of the diamonds dataset](img/B19142_12_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.7 – The plotnine scatterplot of the diamonds dataset
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, the plot shows the relationship between carat weight and price
    by color-coding the cut of diamonds, using a colorblind-friendly color scheme.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s have a look at the boxplot of the data (we will not re-import all of
    the `plotnine` functions again):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'In this code, `geom_boxplot()` is used to create boxplots. The `outlier_color`
    parameter is set to `lightgrey` to change the color of outliers in the boxplot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.8 – The boxplot of the diamonds dataset](img/B19142_12_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.8 – The boxplot of the diamonds dataset
  prefs: []
  type: TYPE_NORMAL
- en: The core purpose of data visualization remains to get insights into the data
    to better understand it. What if we plot the mean price? Do we see what we need
    to see?
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use the `groupby` functionality from `pandas` to aggregate the prices,
    calculate the mean per group, and create a plot with points, lines, and smoothed
    lines to visualize the mean price by clarity and cut:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s have a look at the resulting data vizualization:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.9 – Mean price by clarity and cut](img/B19142_12_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.9 – Mean price by clarity and cut
  prefs: []
  type: TYPE_NORMAL
- en: 'For each cut, a similar curve becomes visible: the mean price first rises by
    clarity and then drops. Both rise and fall are the least relevant for the **Ideal**
    clarity while they are the strongest for **Premium** and **Very** **Good** clarities.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Could we gain more insights from plotting the mean price in a different grouping?
    Let’s take a look at the mean price per carat:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting image indeed shows some interesting things:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.10 – The mean price per carat by clarity, color, and cut](img/B19142_12_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.10 – The mean price per carat by clarity, color, and cut
  prefs: []
  type: TYPE_NORMAL
- en: For all clarities but **Fair**, we see that the D color has an extreme price
    for the IF cut but for the others, the prices remain similar. For **Fair** clarity,
    however, the prices show a clear downward trend with the only large price difference
    being between D and other colors for the I1 cut.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, before moving on to modeling, let’s have a look at the histogram of
    prices by cut:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: We use default binning because, unfortunately, the great package used for the
    R version, `healthyR`, is not available for Python (yet).
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.11 – Price histogram by cut](img/B19142_12_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.11 – Price histogram by cut
  prefs: []
  type: TYPE_NORMAL
- en: We can see that the price has a very long tail (that is, extremely high prices
    are relatively typical even though infrequent) and, surprisingly, we can see a
    second high point for **Good** and **Premium** cuts (and to a lesser extent for
    **Very Good** cut as well).
  prefs: []
  type: TYPE_NORMAL
- en: With the data better understood thanks to the visualizations, we can start with
    the modeling!
  prefs: []
  type: TYPE_NORMAL
- en: Performing a simple ML model with Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we create a simple ML model in Python. Python has grown to
    be the primary go-to language for ML work (with R as the obvious alternative)
    and the number of packages implementing ML algorithms is difficult to overestimate.
    Having said that, `sklearn` remains the most widely used so we will also choose
    it for this section. Similarly to the R part of the chapter, we will use the `xgboost`
    model because it has a great balance between performance and explainability.
  prefs: []
  type: TYPE_NORMAL
- en: We will use the data loaded in the previous section.
  prefs: []
  type: TYPE_NORMAL
- en: Data preprocessing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first thing to do for the modeling phase is to prepare the data. Fortunately,
    `sklearn` comes with a preprocessing functionality built-in!
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s review the steps involved in data preprocessing:'
  prefs: []
  type: TYPE_NORMAL
- en: '`sklearn` provides methods for imputing missing values or removing rows/columns
    with missing data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sklearn` offers utilities for scaling features, including standardization
    (scaling features to have zero mean and unit variance) and normalization (scaling
    features to a specified range).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sklearn` provides methods for one-hot encoding categorical variables or encoding
    them using ordinal labels.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sklearn` offers functions for splitting datasets into training and testing
    sets with specified proportions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sklearn` supports various feature engineering techniques, such as polynomial
    features generation, interaction terms creation, and dimensionality reduction
    using techniques such as **principal component** **analysis** (**PCA**).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: It is important to do the feature engineering in a way that doesn’t pollute
    the training data with information from the test data, just like for data cleaning
    (such as imputation).
  prefs: []
  type: TYPE_NORMAL
- en: 'We have covered data cleaning to a great extent in the dedicated chapter, so
    we will make use of the fact that the `diamonds` dataset is clean already. We
    will move on to feature scaling and the encoding of categorical variables instead:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: This code snippet demonstrates how to encode categorical variables (cut, color,
    and clarity) using one-hot encoding and scale numerical features using `StandardScaler`
    from `sklearn`. Then, it concatenates the encoded categorical features with scaled
    numerical features and splits the dataset into training and testing sets using
    `train_test_split()`.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s compare the data before and after the preprocessing.
  prefs: []
  type: TYPE_NORMAL
- en: 'The original dataset looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.12 – Raw data as read from Excel](img/B19142_12_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.12 – Raw data as read from Excel
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, the dataset contains a mix of numerical and categorical variables
    (the latter ones will be encoded using one-hot encoding).
  prefs: []
  type: TYPE_NORMAL
- en: 'After the preprocessing, the dataset looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19142_12_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.13 – Preprocessed training data
  prefs: []
  type: TYPE_NORMAL
- en: 'The preprocessed training data shown earlier has fewer rows (the rest makes
    up the test data) but more columns: while the `price` column is not present (it’s
    the variable we want to predict), the categorical variables have been replaced
    by multiple `0` and `1` values – the result of one-hot encoding. For each unique
    value of each categorical variable, a new column has been introduced that has
    `1` if the original dataset had that value and `0` if it had something else.'
  prefs: []
  type: TYPE_NORMAL
- en: The `y_train` variable has the value of the `price` column for each row in the
    train data.
  prefs: []
  type: TYPE_NORMAL
- en: 'With the preprocessed data, we can start the modeling:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'In this code, we observe the following:'
  prefs: []
  type: TYPE_NORMAL
- en: We import `GradientBoostingRegressor` from `sklearn.ensemble`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We instantiate a gradient boosting regressor (`xgb_reg`) from `scikit-learn`’s
    implementation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We train the model using the `fit` method with the training data (`X_train`
    and `y_train`).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We make predictions on the test set using the `predict` method and calculate
    the `RMSE`) between the predicted values (`y_pred`) and the actual target values
    (`y_test`).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The RMSE is a widely used metric in regression analysis that measures the average
    magnitude of the errors between predicted values and observed values. It provides
    a single numerical value to assess the goodness of fit of a regression model.
    RMSE is on the same scale (units) as the target variable (`price`).
  prefs: []
  type: TYPE_NORMAL
- en: Lower values of RMSE indicate that the model’s predictions are closer to the
    actual values, implying better performance. In other words, a lower RMSE signifies
    that the model has a smaller average deviation from the true values, which indicates
    higher accuracy and a better predictive capability.
  prefs: []
  type: TYPE_NORMAL
- en: The RMSE is particularly useful because it considers the magnitude of errors
    and penalizes larger errors more heavily than smaller ones. Therefore, minimizing
    the RMSE leads to a model that provides more precise and accurate predictions.
  prefs: []
  type: TYPE_NORMAL
- en: Overall, the RMSE serves as a valuable tool for comparing different regression
    models and assessing their predictive accuracy in real-world applications.
  prefs: []
  type: TYPE_NORMAL
- en: The model result has an RMSE of around `720`, which is significantly lower than
    the average price (`3933`) and the standard deviation of the `price` variable
    (`3989`). This is good news, indeed, as it indicates the model fit was quite good.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, you can consider other ML models (random forests, `lightgbm` or `catgbm`,
    or even **deep learning models**) and other goodness-of-fit metrics (R2, MAE,
    etc.). This section is intended to be a primer on the end-to-end workflow, so
    exploring those options is beyond the scope of this book.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs: []
  type: TYPE_NORMAL
- en: In this last chapter, we explored techniques for performing data analysis and
    visualization using R and Python with data sourced from Excel. We began by loading
    and visualizing the `diamonds` dataset and the `ggplot2` and `plotnine` libraries
    for data visualization. Through various plots such as boxplots, mean price visualizations,
    and histograms, we gained insights into the relationships between different variables
    in the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Moving on to ML modeling, we utilized the `healthyR` and the `scikit-learn`
    libraries to preprocess the data, including encoding categorical variables and
    splitting the dataset into training and testing sets. We then implemented a regression
    model using the XGBoost algorithm, assessing its performance using the RMSE metric.
  prefs: []
  type: TYPE_NORMAL
- en: By harnessing the strengths of R, Python, and Excel, users can enhance their
    analytical capabilities and derive valuable insights from their data.
  prefs: []
  type: TYPE_NORMAL
- en: Thank you for joining us on this journey through the exciting world of data
    analysis and visualization with R and Python in Excel. We hope you found the content
    engaging and the examples insightful. As you continue to explore and implement
    the knowledge gained from this book, we hope you will discover new possibilities
    and opportunities in your data-driven endeavors. Happy analyzing and visualizing!
  prefs: []
  type: TYPE_NORMAL
