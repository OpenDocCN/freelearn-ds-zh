<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" xml:lang="en-US">
<head>
<meta charset="utf-8"/>
<meta name="generator" content="packt"/>
<title>5 Using Regular Expressions in Power BI</title>
<link rel="stylesheet" type="text/css" href="../styles/stylesheet1.css"/>
<link rel="stylesheet" type="text/css" href="../styles/stylesheet2.css"/>

</head>
<body>

<section id="using-regular-expressions-in-power-bi" class="level1 pkt" data-number="6">
<h1 data-number="6">5 Using Regular Expressions in Power BI</h1>
<p>Often, many data cleansing tasks involve carrying out complex searches and substitutions between strings. The usual search and replace tools are sometimes not enough to get the desired results. For instance, let's suppose you need to match strings, not in an exact way (for instance, via equality conditions) but using similar criteria between them. Knowing how to use tools such as regular expressions (alias regex) or fuzzy string searches can make all the difference in projects that require high-quality data. Thanks to R and Python, you can add these tools to your arsenal.</p>
<p>In this chapter, we will cover the following topics:</p>
<ul>
<li>A brief introduction to regexes</li>
<li>Validating data using regex in Power BI</li>
<li>Loading complex log files using regex in Power BI</li>
<li>Extracting values from text using regex in Power BI</li>
</ul>
<section id="technical-requirements-4" class="level2" data-number="6.1">
<h2 data-number="6.1">Technical requirements</h2>
<p>This chapter requires you to have a working internet connection and <strong>Power BI Desktop</strong> already installed on your machine. You need to properly configure the R and Python engines and IDEs, as outlined in <em>Chapter 2</em>, <em>Configuring R with Power BI</em>, and <em>Chapter 3</em>, <em>Configuring Python with Power BI</em>.</p>
</section>
<section id="a-brief-introduction-to-regexes" class="level2" data-number="6.2">
<h2 data-number="6.2">A brief introduction to regexes</h2>
<p>A <strong>regular expression</strong> (usually shortened to <strong>regex</strong>) is defined by a series of characters that <em>identify an abstract search pattern</em>. Essentially, it is a mathematical technique that was developed in 1951 by experts of formal language and theoretical computer science. It is used to <strong>validate</strong> input data or to <em>search for and extract</em> information from texts.</p>
<p>If you don't know the syntax of a regex, at first glance, it might look really tricky:</p>
<figure>
<img src="../media/file112.png" alt="Figure 5.1 – An example of a regex pattern" /><figcaption aria-hidden="true">Figure 5.1 – An example of a regex pattern</figcaption>
</figure>
<p>Fortunately, there are online regex visualization tools that make it easier to understand patterns (you can find one of them at <a href="https://regexper.com">https://regexper.com</a>). For example, the regex highlighted in <em>Figure 5.1</em> can be visualized as follows:</p>
<figure>
<img src="../media/file113.png" alt="Figure 5.2 – A visualization of a regex" /><figcaption aria-hidden="true">Figure 5.2 – A visualization of a regex</figcaption>
</figure>
<p>From <em>Figure 5.2</em>, it is enough to intuit that the regex in <em>Figure 5.1</em> will identify email addresses in a piece of text.</p>
<p>Learning how to use regexes like a pro is certainly not easy, and it is not the purpose of this section. Here, we will explain the basic rules that will allow you to create simple, yet effective, search patterns. For more details, please refer to the <em>References</em> section at the end of this chapter.</p>
<section id="the-basics-of-regexes" class="level3" data-number="6.2.1">
<h3 data-number="6.2.1">The basics of regexes</h3>
<p>We will try to explain the basic principles of regexes through the use of examples, which is perhaps the most immediate way to start using them. Each subsequent subsection will explain a function of regexes. To test our regex, we will use the tool made available at <a href="https://www.regexpal.com/">https://www.regexpal.com/</a>. Let's get started!</p>
<section id="literal-characters" class="level4" data-number="6.2.1.1">
<h4 data-number="6.2.1.1">Literal characters</h4>
<p>To include one or more literal characters in a regex, it is necessary to make use of the "search" feature. Let's try searching for the <em>owe</em> string inside the <em>May the power of extending Power BI with Python and R be with you!</em> text:</p>
<figure>
<img src="../media/file114.png" alt="Figure 5.3 – Searching for &quot;owe&quot; using a regex" /><figcaption aria-hidden="true">Figure 5.3 – Searching for "owe" using a regex</figcaption>
</figure>
<p>Note that the tool uses the <strong>Global search</strong> <strong>flag</strong> in the search by default. A specific flag is indicated with a letter (in our case, <strong>g</strong>) right after the regex delimiters, <strong>/.../</strong>. The possible flags that can be used are as follows:</p>
<ul>
<li><strong>g (global)</strong>: This will match all of the occurrences, keeping the index of the last match.</li>
<li><strong>m (multiline)</strong>: When enabled, the string anchors (you'll see them later) will match the start and end of a line instead of the whole string.</li>
<li><strong>i (ignore case)</strong>: This searches the pattern irrespective of the case (lower or upper) of the string.</li>
</ul>
<p>Bear in mind that not all programming languages use flag syntax, as mentioned earlier. For example, Python's <code>re</code> package (the default one for regexes) provides parameters in the <code>search</code>, <code>match</code>, and <code>sub</code> functions:</p>
<pre><code>re.search(&#39;test&#39;, &#39;TeSt&#39;, re.IGNORECASE)
re.match(&#39;test&#39;, &#39;TeSt&#39;, re.IGNORECASE)
re.sub(&#39;test&#39;, &#39;xxxx&#39;, &#39;TesTing&#39;, flags=re.IGNORECASE)</code></pre>
<p>This is the same for R's <code>regex()</code> function of the <code>stringr</code> package:</p>
<pre><code>str_detect(&#39;tEsT this&#39;, regex(&#39;test&#39;, ignore_case=TRUE))</code></pre>
<p>You can also use <strong>global modifiers</strong> directly in line with your regex pattern. These are <code>(?i)</code> for case-insensitive and <code>(?m)</code> for multiline. For example, in R, you can also run the following script:</p>
<pre><code>str_detect(&#39;tEsT this&#39;, regex(&quot;(?i)test&quot;))</code></pre>
<p>Note that Python doesn’t allow inline global modifiers.</p>
</section>
<section id="special-characters" class="level4" data-number="6.2.1.2">
<h4 data-number="6.2.1.2">Special characters</h4>
<p>Regex uses 12 special characters (also called <strong>metacharacters</strong>) where each has a special meaning. They are the pipe, <code>|</code>; the backslash, <code>\</code>; the dollar sign, <code>$</code>; the question mark, <code>?</code>; the caret, <code>^</code>; the asterisk, <code>*</code>; the plus sign, <code>+</code>; the dot, <code>.</code>; the parentheses, <code>(</code> and <code>)</code>; the opening square bracket, <code>[</code>; and the opening curly bracket, <code>{</code>.</p>
<p>If you need to search for one of the previously mentioned characters, you have to escape it using the backslash. So, if you want to match exactly <code>123$</code>, you need to use <code>123\$</code> as the regex pattern.</p>
<p>Next, you will learn about the meaning and use of metacharacters.</p>
</section>
<section id="the-and-anchors" class="level4" data-number="6.2.1.3">
<h4 data-number="6.2.1.3">The ^ and $ anchors</h4>
<p>Anchor characters are special characters in that they are used to place the regex match at a certain position in the string. The caret, <code>^</code>, is used to indicate <em>the beginning of the string</em> (or line), and the dollar sign, <code>$</code>, is used to indicate <em>the end of the string</em> (or line). An example visualization is worth a thousand words:</p>
<figure>
<img src="../media/file115.png" alt="Figure 5.4 – Case-insensitive and global search" /><figcaption aria-hidden="true">Figure 5.4 – Case-insensitive and global search</figcaption>
</figure>
<p>In <em>Figure 5.4</em>, the "ignore case" flag is set by clicking on the <strong>flags</strong> icon and then checking "ignore case." In this way, both the occurrences are matched. Now, add a caret, <code>^</code>, before the <code>m</code> character:</p>
<figure>
<img src="../media/file116.png" alt="Figure 5.5 – Case-insensitive and global search using the caret, ^" /><figcaption aria-hidden="true">Figure 5.5 – Case-insensitive and global search using the caret, ^</figcaption>
</figure>
<p>In this case, only the first occurrence (that is, the one at the beginning of the string) is matched.</p>
<p>If you also add a dollar sign at the end of the regex, nothing will be matched, as you are asking for a match of the <code>may the power</code> string that is at the beginning and that also ends the text.</p>
</section>
<section id="or-operators" class="level4" data-number="6.2.1.4">
<h4 data-number="6.2.1.4">OR operators</h4>
<p>You might need to match one of the individual sets of characters or strings. For example, to match any of the <code>s</code> and <code>t</code> characters after the <code>ye</code> string, you should use the <strong>character class</strong> of <code>[st]</code> inside the <code>ye[st]</code> regex. This is so that it will match both the <code>yes</code> and <code>yet</code> strings. Character classes can also be used to match an occurrence in a range of characters using the hyphen, <code>-</code>. For example, <code>[0-9]</code> matches a single digit between 0 and 9, while <code>[A-Z]</code> matches a single uppercase letter from A to Z. Additionally, you can combine multiple ranges into one character class. For instance, <code>[A-Z0-9]</code> matches only a digit or an uppercase letter.</p>
<p>In order to match one of two strings, you can use the pipe, <code>|</code>, to separate them within opening and closing parentheses, such as <code>(string1|string2)</code>. Here is a complete example:</p>
<figure>
<img src="../media/file117.png" alt="Figure 5.6 – A complete example of OR operators" /><figcaption aria-hidden="true">Figure 5.6 – A complete example of OR operators</figcaption>
</figure>
<p>The character class can also be used to match any character different from a specific character that is given. This is thanks to the <strong>Negated Character Class</strong>.</p>
</section>
<section id="negated-character-classes" class="level4" data-number="6.2.1.5">
<h4 data-number="6.2.1.5">Negated character classes</h4>
<p>The caret that appears just after the opening square bracket negates the content of the character class. For example, the <code>[^"]</code> regex matches every character that isn't a double quote.</p>
</section>
<section id="shorthand-character-classes" class="level4" data-number="6.2.1.6">
<h4 data-number="6.2.1.6">Shorthand character classes</h4>
<p>There are some character classes that are used very often. For this reason, we have defined some abbreviations to allow you to include them in regexes quickly. Here is a list of the most used ones:</p>
<ul>
<li><code>\w</code>: This matches an alphanumeric character, including the underscore.</li>
<li><code>\W</code>: This is the opposite of <code>\w</code>, so it matches a single non-alphanumeric character, excluding the underscore. For example, it can match spacing and punctuation marks.</li>
<li><code>\d</code>: This matches a single digit.</li>
<li><code>\D</code>: This is the opposite of <code>\d</code>, so it matches a single non-digit character.</li>
<li><code>\s</code>: This matches "whitespace characters" such as space, tab, newline, and carriage return.</li>
</ul>
<p>We'll use shorthand character classes relatively often throughout this chapter.</p>
</section>
<section id="quantifiers" class="level4" data-number="6.2.1.7">
<h4 data-number="6.2.1.7">Quantifiers</h4>
<p>Quantifiers indicate the number of times a <em>character</em> or <em>expression</em> must be matched. Here is a list of the most used ones:</p>
<ul>
<li><p><code>+</code>: This matches what precedes it one or more times. For example, <code>test\d+</code> will match the <code>test</code> string followed by one or more digits. The <code>test(-\d\d)+</code> regex will match the <code>test</code> string followed by one or more times a dash that is then followed by two digits:</p>
<figure>
<img src="../media/file118.png" alt="Figure 5.7 – Repeating a group of characters using +" /><figcaption aria-hidden="true">Figure 5.7 – Repeating a group of characters using +</figcaption>
</figure></li>
<li><code>{n}</code>: This matches what precedes it <em>n</em> times. For example, <code>\d{4}</code> will match any integer number made up of 4 digits.</li>
<li><code>{n,m}</code>: This matches what precedes it between <em>n</em> and <em>m</em> times. For example, <code>prod-\d{2,6}</code> will match the <code>prod-</code> string followed by an integer number made up of between 2 and 6 digits.</li>
<li><code>{n,}</code>: This matches <em>n</em> or more times what precedes it.</li>
<li><code>?</code>: This matches one or zero times what precedes it. For example, <code>Mar(ch)?</code> will match both <code>March</code> and <code>Mar</code>. Alternatively, the <code>colou?red</code> regex will match both <code>colored</code> and <code>coloured</code>.</li>
<li><code>*</code>: This matches zero or more times what precedes it. For example, <code>code\d* </code>will match <code>code</code>, <code>code1</code>, or <code>code173846</code>.</li>
</ul>
</section>
<section id="the-dot" class="level4" data-number="6.2.1.8">
<h4 data-number="6.2.1.8">The dot</h4>
<p>The dot corresponds to a single character, regardless of what that character is, except for line break characters. It's a very powerful regex metacharacter and gives you a chance to be lazy. This is precisely why you have to be careful not to abuse it because, sometimes, you might include unintended results in the matches.</p>
</section>
<section id="greedy-and-lazy-matches" class="level4" data-number="6.2.1.9">
<h4 data-number="6.2.1.9">Greedy and lazy matches</h4>
<p>The <code>+</code>, <code>*</code>, and repetition of <code>{…}</code> are <strong>greedy quantifiers</strong>. Greedy means that <em>they will consume the longest possible string</em>. Let's suppose that you only want to match the tags used in the <code>&lt;em&gt;Power BI rocks&lt;/em&gt;</code> string. The first attempt a beginner would make is to use the <code>&lt;.+&gt;</code> regex, which, expressed in words, becomes "get the <code>&lt;</code>, then get any non-newline character one or more times, and finally, in the end, get the <code>&gt;</code>." The expected result is made by two matches, <code>&lt;em&gt;</code> and <code>&lt;/em&gt;</code>. Let's take a look at the result:</p>
<figure>
<img src="../media/file119.png" alt="Figure 5.8 – The greediness of .+" /><figcaption aria-hidden="true">Figure 5.8 – The greediness of .+</figcaption>
</figure>
<p>It is evident that the combination of <code>.+</code> captures everything contained between <em>the first</em> occurrence of <code>&lt;</code> and the last occurrence of <code>&gt;</code>, hence the definition of the <strong>greediness</strong> of the quantifiers.</p>
<p>So, is it possible to force a greedy quantifier to stop at the first detected occurrence of the next character, preventing it from "eating" anything until the last occurrence of the same? In other words, is it possible to turn a greedy quantifier into a <strong>lazy</strong> one? The answer is "yes," it is possible to do so by adding the <code>?</code> metacharacter just after the <code>+</code>. So, the <code>&lt;.+&gt;</code> regex becomes <code>&lt;.+?&gt;</code>. Here is the result:</p>
<figure>
<img src="../media/file120.png" alt="Figure 5.9 – Making a greedy quantifier lazy thanks to the ? metacharacter" /><figcaption aria-hidden="true">Figure 5.9 – Making a greedy quantifier lazy thanks to the ? metacharacter</figcaption>
</figure>
<p>Bear in mind, however, that <em>lazy quantifiers are underperforming</em>. Whenever possible, it is always preferable to <em>use negated character classes instead</em>. In our example, simply using the <code>&lt;[^&gt;]+&gt;</code> regex (that is, a <code>&lt;</code> character, any non-<code>&gt;</code> character one or more times, and a <code>&gt;</code> character) will achieve the same result without consuming computational resources:</p>
<figure>
<img src="../media/file121.png" alt="Figure 5.9 – Using a negated character class instead of a lazy quantifier" /><figcaption aria-hidden="true">Figure 5.9 – Using a negated character class instead of a lazy quantifier</figcaption>
</figure>
<p>So far, with what you've learned about regexes, you have the minimum foundation required to understand the more complex regexes that we'll be using in the next few examples.</p>
</section>
</section>
<section id="checking-the-validity-of-email-addresses" class="level3" data-number="6.2.2">
<h3 data-number="6.2.2">Checking the validity of email addresses</h3>
<p>If you were asked to validate an email address using the concepts you just learned, one of your first attempts might look like the following: <code>^.+@.+\..+$</code>. Translating this regex into spoken language gives us the following:</p>
<ol>
<li><code>^</code>: This matches the beginning of the string or a line if the multiline flag is enabled.</li>
<li><code>.+</code>: This matches any character one or more times, except the line break.</li>
<li><code>@</code>: This matches an "@" character.</li>
<li><code>.+</code>: This matches any character one or more times, except the line break.</li>
<li><code>\.</code>: This matches a "." character.</li>
<li><code>.+</code>: This matches any character one or more times, except the line break.</li>
</ol>
<p>Of course, this regex will validate a correct email address. But are you sure it can also detect the obvious syntactic errors of bad emails? Let's perform a test in <a href="https://www.regexpal.com/">https://www.regexpal.com/</a> with the wrong email, <code>example@example.c</code> (the top-level domain, that is, the portion of the domain after the dot, must contain a minimum of two characters):</p>
<figure>
<img src="../media/file122.png" alt="Figure 5.10 – Using a simple regex to validate a wrong email address" /><figcaption aria-hidden="true">Figure 5.10 – Using a simple regex to validate a wrong email address</figcaption>
</figure>
<p>Well, that's not much of an outcome: an obviously wrong email would pass as correct. For this reason, it is often necessary to use more complex regexes that can respect well-defined syntactic rules.</p>
<p>In this specific case, we'll use a specific regex for email validation that we often adopt in production. It also takes into account whether the domain IP is used. For the purpose of displaying it in full, the regex is as follows:</p>
<pre><code>^(([^&lt;&gt;()[\]\\.,;:\s@\&quot;&quot;]+(\.[^&lt;&gt;()[\]\\.,;:\s@\&quot;&quot;]+)*)|(\&quot;&quot;.+\&quot;&quot;))@((\[?[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\]?)|(([a-zA-Z\-0-9]+\.)+[a-zA-Z]{2,}))$</code></pre>
<p>At first glance, this regex is sure to cause confusion. However, if we attempt to break it down into its essential parts, it becomes much more readable.</p>
<p>However, if you think that this regex is really complex, take a look at the one that takes into account all, and I mean all, the syntactic rules provided by the <em>Standard for the Format of Arpa Internet Text Messages</em>, which you can find at <a href="http://www.ex-parrot.com/pdw/Mail-RFC822-Address.html">http://www.ex-parrot.com/pdw/Mail-RFC822-Address.html</a>! Pretty impressive, huh?</p>
<p>The format of an email address is defined as <em>local-part@domain</em>. You can find the complete specifications on Wikipedia at <a href="https://en.wikipedia.org/wiki/Email_address">https://en.wikipedia.org/wiki/Email_address</a>. We are going to match the minimum number of rules (not all of them!) that will allow us to validate a significantly different number of email addresses. So, considering we're going to match the domain name or the domain IP, the general structure of the regex is as follows:</p>
<figure>
<img src="../media/file123.png" alt="Figure 5.11 – The structure of the complex regex for email validation" /><figcaption aria-hidden="true">Figure 5.11 – The structure of the complex regex for email validation</figcaption>
</figure>
<p>In <em>Figure 5.11</em>, the <code>{0}</code>, <code>{1}</code>, and <code>{2}</code> strings are just placeholders, not characters to match. That said, let's start by defining each token:</p>
<ol>
<li><p>The <code>{0}</code> token matches the <strong>local-part</strong> regex of the email. In this case, it's much easier to explain what the <em>local-part</em> regex does with a diagram rather than with words. In <em>Figure 5.12</em>, the labels explain every single detail of the subparts:</p>
<figure>
<img src="../media/file124.png" alt="Figure 5.12 – The local-part regex explained in detail" /><figcaption aria-hidden="true">Figure 5.12 – The local-part regex explained in detail</figcaption>
</figure>
<p>Bear in mind that <em>parentheses group regex patterns together</em>. Parentheses allow you to apply regex operators to the entire grouped expression and to get a part of the match as a separate item in the result array. The text that corresponds to the regex expression is captured within them as a <strong>numbered group</strong>, and it can be reused with a numbered backreference. You'll learn how to use this feature later.Remember that, in order to have the match of a metacharacter be a real character, the escape backslash must be placed before it. So, for example, <code>\]</code> will be the <code>]</code> character.</p></li>
<li><p>The <code>{1}</code> token matches the <strong>domain name</strong> of the email. Again, we will use a diagram to explain what the domain name regex does:</p>
<figure>
<img src="../media/file125.png" alt="Figure 5.13 – The domain name regex explained in detail" /><figcaption aria-hidden="true">Figure 5.13 – The domain name regex explained in detail</figcaption>
</figure></li>
<li>The <code>{2}</code> token matches the <strong>domain IP</strong> of the email. It is the easier sub-regex, and you can find out what it matches by looking at <em>Figure 5.14</em>:</li>
</ol>
<figure>
<img src="../media/file126.png" alt="Figure 5.14 – The domain IP regex explained in detail" /><figcaption aria-hidden="true">Figure 5.14 – The domain IP regex explained in detail</figcaption>
</figure>
<p>If you want to view the whole regex in a visualization, please refer to the following one, which is taken from <a href="https://jex.im/regulex">https://jex.im/regulex</a>:</p>
<figure>
<img src="../media/file127.png" alt="Figure 5.14 – A visualization of the whole email regex" /><figcaption aria-hidden="true">Figure 5.14 – A visualization of the whole email regex</figcaption>
</figure>
<p>Now, let's proceed with the validation of another important type of information, which is very often subject to typing errors: <strong>dates</strong>.</p>
</section>
<section id="checking-the-validity-of-dates" class="level3" data-number="6.2.3">
<h3 data-number="6.2.3">Checking the validity of dates</h3>
<p>Even in the case of dates, the clueless regex developer might think that the following regex is enough to validate dates (in the format of <code>dd-mm-yyyy</code>): <code>^\d{1,2}([\-\/])\d{1,2}\1(?:\d{4}|\d{2})$</code>. There are two new expressions, never before encountered, that are worth exploring:</p>
<ul>
<li><code>\1</code>: This is the <strong>backreference</strong> to group 1. As we explained in the previous section, parentheses also help capture a portion of the string, which you can reference during the rest of the regex. In this case, the <code>\1</code> syntax indicates that, at exactly that position, you can expect the same portion of the string matched by the first pair of parentheses. Bear in mind that, in Python, you need to use the <code>\g&lt;1&gt;</code> syntax instead of <code>\1</code>.</li>
<li><code>(?: … )</code>: This is the so-called <strong>non-capturing group</strong>. Sometimes, you need parentheses to correctly apply a quantifier, but you don't want their contents to be reported in the results.</li>
</ul>
<p>Translating the whole regex into spoken language gives us the following:</p>
<ol>
<li><code>^</code>: This matches the beginning of the string or a line if the multiline flag is enabled.</li>
<li><code>\d{1,2}</code>: This matches any digit between 1 and 2 repetitions.</li>
<li><code>([\-\/])</code>: This matches any character between <code>-</code> and <code>/</code>, and captures the result as group 1.</li>
<li><code>\d{1,2}</code>: This matches any digit between 1 and 2 repetitions.</li>
<li><code>\1</code>: This backreferences to the captured group 1. So, it expects any character between <code>-</code> and <code>/</code>.</li>
<li><code>.+</code>: This matches any character one or more times, except the line break.</li>
<li><code>(?:\d{4}|\d{2})</code>: This matches one of the following two alternatives: any digit for exactly 4 repetitions and any digit for exactly 2 repetitions.</li>
</ol>
<p>You can visualize the whole regex as follows:</p>
<figure>
<img src="../media/file128.png" alt="Figure 5.15 – A visualization of the first attempt of a regex for validating dates" /><figcaption aria-hidden="true">Figure 5.15 – A visualization of the first attempt of a regex for validating dates</figcaption>
</figure>
<p>As you might have guessed, this regex validates dates in the following formats: <code>dd-mm-yyyy</code>, <code>dd-mm-yy</code>, <code>d-m-yyyy</code>, and <code>d-m-yy</code>, using <code>/</code> or <code>-</code> as separators. However, it does not account for errors due to invalid dates, such as February 30 or September 31.</p>
<p>If you want a regex that also accounts for these errors, then you must use the following:</p>
<pre><code>^(?:(?:31[\-\/](?:(?:0?[13578])|(1[02]))[\-\/](19|20)?\d\d)|(?:(?:29|30)[\-\/](?:(?:0?[13-9])|(?:1[0-2]))[\-\/](?:19|20)?\d\d)|(?:29[\-\/]0?2[\-\/](?:19|20)(?:(?:[02468][048])|(?:[13579][26])))|(?:(?:(?:0?[1-9])|(?:1\d)|(?:2[0-8]))[\-\/](?:(?:0?[1-9])|(?:1[0-2]))[\-\/](?:19|20)?\d\d))$</code></pre>
<p>Again, viewed in this way, this regex is difficult to interpret. However, looking at it "from above" a bit more, you realize that it consists of four alternatives:</p>
<figure>
<img src="../media/file129.png" alt="Figure 5.16 – The structure of the complex regex for date validation" /><figcaption aria-hidden="true">Figure 5.16 – The structure of the complex regex for date validation</figcaption>
</figure>
<p>Also, in this case, the <code>{0}</code>, <code>{1}</code>, <code>{2}</code>, and <code>{3}</code> strings are just placeholders, not characters to match. That said, let's start by defining the <code>{0}</code> token.</p>
<p>The <code>{0}</code> token matches the dates that have the 31st day. As in previous cases, it's much easier to explain what this regex does with a visualization rather than with words. In <em>Figure 5.17</em>, the labels explain every single detail of the subparts:</p>
<figure>
<img src="../media/file130.png" alt="Figure 5.17 – The regex part for dates that have the 31st day explained in detail" /><figcaption aria-hidden="true">Figure 5.17 – The regex part for dates that have the 31st day explained in detail</figcaption>
</figure>
<p>The regexes used for the other placeholders are very similar to the one we just explained. Therefore, we will leave the explanation of the others as an exercise for the reader. If you want to see the whole regex in a visualization, please refer to the following diagram, which is taken from <a href="https://jex.im/regulex">https://jex.im/regulex</a>:</p>
<figure>
<img src="../media/file131.png" alt="Figure 5.18 – The visualization of the whole date regex" /><figcaption aria-hidden="true">Figure 5.18 – The visualization of the whole date regex</figcaption>
</figure>
<p>The regex that we just examined allows the validation of the <code>dd-mm-yyyy</code> format with all of its variants. In the code, we will demonstrate how you can implement date validation in Power BI. Additionally, you will find regexes that allow you to validate dates in the <code>mm-dd-yyyy</code> and <code>yyyy-mm-dd</code> formats with all of their variants (where the year is made of two digits, the month is made of one digit, and so on).</p>
<p>Now that you understand what's behind the complex regexes presented earlier, let's move on to implementing them in Power BI to validate your data.</p>
</section>
</section>
<section id="validating-data-using-regex-in-power-bi" class="level2" data-number="6.3">
<h2 data-number="6.3">Validating data using regex in Power BI</h2>
<p>To date, Power BI has no native feature in Power Query to perform operations via regexes. There are cases when you can't avoid using regexes to extract useful information from data in text form. The only way to be able to use regexes is through R scripts or Python scripts. The only cons you have in this case is that, if you need to publish the report on the Power BI service, to allow Power Query to use external R or Python engines, you must also install the on-premises data gateway in personal mode.</p>
<p>However, let's get right into it with real-world examples.</p>
<p>Let's suppose you work at a retail company where there is a team dedicated to identifying fraudulent customers. As soon as a team member identifies a fraudster, they fill out an Excel spreadsheet, in which the <em>Email</em> and <em>BannedDate</em> columns are included along with others. Your task is to load the data from this Excel file into Power BI and, from other data sources, select only the fraudster's information in order to carry out specific analysis on their purchases.</p>
<p>Having the correct fraudster emails within the Excel file is critically important to be able to properly join with the other data. Having the correct ban dates is also important in order to know whether further orders from that fraudster have slipped through the cracks after that date. As you know, the filling in of an Excel file by several users is done without any kind of validation of the entered data; therefore, it is subject to human errors. So, identifying any errors when filling out certain fields and highlighting them allows the fraud team to be able to correct them. It is precisely in this case that regexes come to your aid.</p>
<section id="using-regex-in-power-bi-to-validate-emails-with-python" class="level3" data-number="6.3.1">
<h3 data-number="6.3.1">Using regex in Power BI to validate emails with Python</h3>
<p>In the repository that comes with this book, you can find the <code>Users.xlsx</code> Excel file inside the <code>Chapter05</code> folder. Its content is similar to <em>Figure 5.15</em>:</p>
<figure>
<img src="../media/file132.png" alt="Figure 5.19 – The content of the Users.xlsx file" /><figcaption aria-hidden="true">Figure 5.19 – The content of the Users.xlsx file</figcaption>
</figure>
<p>In this section, we will focus exclusively on the <code>Email</code> column. This contains the email addresses of fraudsters entered manually by the fraud team, which was described at the beginning of the section. These email addresses are not all syntactically correct. Moreover, in the Excel file, there is also the <code>IsEmailValidByDefinition</code> column, whose values (<em>1=yes</em>; <em>0=no</em>) indicate whether the email in correspondence of that value is actually valid or not.</p>
<p>Python has a built-in package, called <code>re</code>, which contains all the functions you need to work with regexes. Additionally, in <code>pandas</code>, there are several methods for a series or dataframe object, which accept regexes to find a pattern in a string. These methods work in the same way as the ones you will find in Python's <code>re</code> module. We will be using the <code>match</code> method shortly.</p>
<p>You will learn about the use of the <code>r'...'</code> syntax to create strings. This is a <strong>raw string</strong> that allows you to treat the backslash (<code>\</code>) as a literal character and not as an escape character.</p>
<p>So, open your Power BI Desktop, make sure the Python environment you use is <code>pbi_powerquery_env</code>, and let's get started:</p>
<ol>
<li><p>From the ribbon, click on the <strong>Excel</strong> icon to import data from Excel:</p>
<figure>
<img src="../media/file133.png" alt="Figure 5.20 – Importing data from Excel" /><figcaption aria-hidden="true">Figure 5.20 – Importing data from Excel</figcaption>
</figure></li>
<li>From the <strong>Open</strong> dialog box, select the previously mentioned <code>Users.xlsx</code> file.</li>
<li><p>From the <strong>Navigator</strong> window, select the <strong>Users</strong> sheet and then click on <strong>Transform Data</strong>:</p>
<figure>
<img src="../media/file134.png" alt="Figure 5.21 – Selecting the Users sheet and clicking on Transform Data" /><figcaption aria-hidden="true">Figure 5.21 – Selecting the Users sheet and clicking on Transform Data</figcaption>
</figure></li>
<li>Click on the <strong>Transform</strong> menu, and then click on <strong>Run Python Script</strong>.</li>
<li><p>Then, copy and paste the following code into the Python script editor and click on <strong>OK</strong>:</p>
<pre><code>import pandas as pd
import re
df = dataset
regex_local_part = r&#39;([^&lt;&gt;()[\]\\.,;:\s@\&quot;&quot;]+(\.[^&lt;&gt;()[\]\\.,;:\s@\&quot;&quot;]+)*)|(\&quot;&quot;.+\&quot;&quot;)&#39;
regex_domain_name = r&#39;(([a-zA-Z\-0-9]+\.)+[a-zA-Z]{2,})&#39;
regex_domain_ip_address = r&#39;(\[?[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\]?)&#39;
pattern = r&#39;^({0})@({1}|{2})$&#39;.format(regex_local_part, regex_domain_name, regex_domain_ip_address)
df[&#39;isEmailValidFromRegex&#39;] = df[&#39;Email&#39;].str.match(pattern).astype(int)</code></pre>
<p>You can also find this Python script in the <code>01-validate-emails-with-regex-with-python.py</code> file, which is inside the repository that comes with the book, in the <code>Chapter05\validating-data-using-regex</code> folder.</p></li>
<li>Power BI Desktop might display an alert that says the following: <strong>Information is required about data privacy</strong>. If so, click on <strong>Continue</strong>, and follow <em>Step 2</em>; otherwise, you can jump to <em>Step 3</em>.</li>
<li>The <strong>Privacy levels</strong> window pops up. Here, you'll specify an isolation level that defines the degree to which one data source will be isolated from other data sources. You could select to <em>ignore Privacy Levels checks</em>, but this might expose confidential data to unauthorized persons. You will be asked to select a privacy level for both the Python script and the dataset loaded from Excel. If you select the <strong>Organizational</strong> level for both, everything works fine on Power BI Desktop. However, if you plan to publish your reports to the <em>Power BI service (or Embedded)</em>, you <em>must use the "Public" level</em>. For more details, please refer to <a href="http://bit.ly/pbi-privacy-levels">http://bit.ly/pbi-privacy-levels</a>. For now, select the <strong>Organizational</strong> level for both options.</li>
<li><p>For now, we are only interested in the <code>df</code> dataset. So, click on its <strong>Table</strong> value:</p>
<figure>
<img src="../media/file135.png" alt="Figure 5.22 – Selecting the df dataset as a result of the Python script transformation" /><figcaption aria-hidden="true">Figure 5.22 – Selecting the df dataset as a result of the Python script transformation</figcaption>
</figure></li>
<li><p>As you can see, the <strong>isEmailValidFromRegex</strong> column is added and it contains the Boolean values resulting from the validation of the emails through your regex. If you do a check, you will see that they coincide with the values given by definition in the <strong>IsEmailValidByDefinition</strong> column:</p>
<figure>
<img src="../media/file136.png" alt="Figure 5.23 – The regex validation results for emails" /><figcaption aria-hidden="true">Figure 5.23 – The regex validation results for emails</figcaption>
</figure>
<p>Your regex did a great job! Now you can go back to the <strong>Home</strong> menu and click on <strong>Close &amp; Apply</strong>.</p></li>
</ol>
<p>Thanks to the <strong>isEmailValidFromRegex</strong> column, you can now appropriately filter the correct and incorrect email addresses, perhaps even reporting the matter to the fraud team in a dedicated report.</p>
</section>
<section id="using-regex-in-power-bi-to-validate-emails-with-r" class="level3" data-number="6.3.2">
<h3 data-number="6.3.2">Using regex in Power BI to validate emails with R</h3>
<p>If you want to use R for your email validation using regex, the process is pretty much the same except for a few things.</p>
<p>First of all, <em>R only allows the use of raw strings as of version 4.0.0</em>. Additionally, the syntax for raw strings is slightly different. Instead of <code>r'...'</code>, you can use <code>r'(...)'</code>, <code>r'[...]'</code>, or <code>r'{...}'</code> indiscriminately. Additionally, instead of using numeric placeholders in curly brackets inside the string and then assigning them via the <code>format()</code> function, as you would in Python, in R, you can simply use the variable names in curly brackets directly as placeholders.</p>
<p>That said, the second thing you need to pay attention to is the following: you have to be careful so that, in R, not only <code>]</code> is considered a metacharacter, but also <code>[</code>. Therefore, when you want to use both square brackets as literal characters, you must prepend the backslash escape character (<code>\</code>) for both. Therefore, the part of the regex that identifies the character class in the local-part regex of the email is slightly different:</p>
<figure>
<img src="../media/file137.png" alt="Figure 5.24 – You must escape the opened square bracket when it is a literal character in R" /><figcaption aria-hidden="true">Figure 5.24 – You must escape the opened square bracket when it is a literal character in R</figcaption>
</figure>
<p>R:Base provides two functions that enable you to use regexes: <code>grep()</code> and <code>grepl()</code>:</p>
<ul>
<li><code>grepl()</code> returns a Boolean value based on whether a pattern exists in a character string.</li>
<li><code>grep()</code> returns the indexes of the occurrences in the vector of characters that contains a match or the specific strings that have the match.</li>
</ul>
<p>Since we want to adopt the <em>Tidyverse paradigm</em>, we will use the wrapper functions provided by the <strong>stringr</strong> package, which are <code>str_detect()</code> and <code>str_which()</code>, respectively.</p>
<p>Having clarified these differences, the process to validate the emails present in the <code>Users.xlsx</code> Excel file in Power BI using the R script is practically the same as that discussed in the previous section where we used Python:</p>
<ol>
<li>Repeat <em>Steps 1 to 3</em> of the previous section to import the data contained in the <code>Users.xlsx</code> file.</li>
<li>Click on the <strong>Transform</strong> menu, and then click on <strong>Run R Script</strong>.</li>
<li><p>Then, copy and paste the following code into the R script editor and click on <strong>OK</strong>:</p>
<pre><code>library(dplyr)
library(stringr)
regex_local_part &lt;- r&#39;(([^&lt;&gt;()\[\]\\.,;:\s@\&quot;]+(\.[^&lt;&gt;()\[\]\\.,;:\s@\&quot;]+)*)|(\&quot;.+\&quot;))&#39;
regex_domain_name &lt;- r&#39;((([a-zA-Z\-0-9]+\.)+[a-zA-Z]{2,}))&#39;
regex_domain_ip_address &lt;- r&#39;((\[?[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\]?))&#39;
pattern &lt;- str_glue(
  &#39;^({regex_local_part})@({regex_domain_name}|{regex_domain_ip_address})$&#39;
)
df &lt;- df %&gt;% 
  mutate( isEmailValidFromRegex = as.integer(str_detect(Email, pattern)) )</code></pre>
<p>You also can find this R script in the <code>02-validate-emails-with-regex-with-r.R</code> file, which is the repository that comes with the book, in the <code>Chapter05\validating-data-using-regex</code> folder.</p></li>
<li><p>Power BI Desktop might display a notice that says the following: <strong>Information is required about data privacy</strong>. If so, click on <strong>Continue</strong>, and follow the instructions here. Otherwise, you can jump to <em>Step 5</em>. Also, select the <em>Organizational</em> level for R scripts. Sometimes, you might find that the compatibility levels of datasets and analytical scripts are not compatible with each other. In this case, Power BI might give you an alert, such as <strong>Formula.Firewall: Query 'XXX' (step 'YYY') is accessing data sources that have privacy levels which cannot be used together. Please rebuild this data combination</strong>. In this case, simply open the <strong>Data source settings</strong> window, as follows:</p>
<figure>
<img src="../media/file138.png" alt="Figure 5.25 – Opening the Power Query Data source settings window" /><figcaption aria-hidden="true">Figure 5.25 – Opening the Power Query Data source settings window</figcaption>
</figure>
<p>After that, you have to make sure that all data sources have the same level of privacy (in our case, <em>Organizational</em>), changing it for each of them, if necessary, through the <strong>Edit Permissions…</strong> option:</p>
<figure>
<img src="../media/file139.png" alt="Figure 5.26 – Editing the privacy permissions for the data sources" /><figcaption aria-hidden="true">Figure 5.26 – Editing the privacy permissions for the data sources</figcaption>
</figure>
<p>At this point, you can refresh the preview data by clicking on <strong>Refresh Preview</strong>.</p></li>
<li><p>Additionally, in this case, we are only interested in the <code>df</code> dataset. So, click on its <strong>Table</strong> value:</p>
<figure>
<img src="../media/file140.png" alt="Figure 5.27 – Selecting the df dataset as a result of the R script transformation" /><figcaption aria-hidden="true">Figure 5.27 – Selecting the df dataset as a result of the R script transformation</figcaption>
</figure></li>
<li>As you can see, the <code>isEmailValidFromRegex</code> column has been added, and it contains the Boolean values (transformed to 1 and 0) resulting from the validation of the emails through your regex. If you do a check, they coincide with the values given by definition in the <code>IsEmailValidByDefinition</code> column. Your regex did a great job! Now you can go back to the <strong>Home</strong> menu and click on <strong>Close &amp; Apply</strong>.</li>
</ol>
<p>Thanks to the <code>isEmailValidFromRegex</code> column, you can now appropriately filter the correct and incorrect email addresses in your reports.</p>
<p>Now, let's take a look at how to validate dates in Power BI with Python.</p>
</section>
<section id="using-regex-in-power-bi-to-validate-dates-with-python" class="level3" data-number="6.3.3">
<h3 data-number="6.3.3">Using regex in Power BI to validate dates with Python</h3>
<p>As an example of the dates to validate, we will use the <code>Users.xlsx</code> Excel file that we used earlier. It contains the <em>BannedDate</em> column that has string values representing dates in the <code>mm/dd/yyyy</code> format with all its variants. Moreover, in the Excel file, there is also the <em>IsDateValidByDefinition</em> column, whose values (<em>1=yes</em>; <em>0=no</em>) indicate whether the date matching that value is valid or not.</p>
<p>By now, you already know the Python functions needed to use a regex. So, let’s get started:</p>
<ol>
<li>Repeat <em>Steps 1 to 3</em> of the <em>Using regex in Power BI to validate emails with Python</em> section to import the data contained in the <code>Users.xlsx</code> file.</li>
<li>Click on the <strong>Transform</strong> menu and then click on <strong>Run Python Script</strong>.</li>
<li><p>Then, copy and paste the following code into the Python script editor and click on <strong>OK</strong>:</p>
<pre><code>import pandas as pd
import re
df = dataset
regex_dates_having_day_31 = r&#39;(?:(?:(?:0?[13578])|(?:1[02]))[\-\/]31[\-\/](?:19|20)?\d\d)&#39;
    regex_non_leap_dates_having_days_29_30 = r&#39;(?:(?:(?:0?[13-9])|(?:1[0-2]))[\-\/](?:29|30)[\-\/](?:19|20)?\d\d)&#39;
    regex_leap_dates_having_day_29 = r&#39;(?:0?2[\-\/]29[\-\/](?:19|20)?(?:(?:[02468][048])|(?:[13579][26])))&#39;
    regex_remaining_dates = r&#39;(?:(?:(?:0?[1-9])|(?:1[0-2]))[\-\/](?:(?:1\d)|(?:0?[1-9])|(?:2[0-8]))[\-\/](?:19|20)?\d\d)&#39;
pattern = r&#39;^(?:{0}|{1}|{2}|{3})$&#39;.format(regex_dates_having_day_31, regex_non_leap_dates_having_days_29_30, regex_leap_dates_having_day_29, regex_remaining_dates)
df[&#39;isValidDateFromRegex&#39;] = df[&#39;BannedDate&#39;].str.match(pattern).astype(int)</code></pre>
<p>You can find a more exhaustive Python script in the <code>03-validate-dates-with-regex-with-python.py</code> file, which can be found in the repository that comes with the book, in the <code>Chapter05\validating-data-using-regex</code> folder. That script handles dates in the formats of <code>mm-dd-yyyy</code>, <code>dd-mm-yyyy</code>, and <code>yyyy-mm-dd</code> with all their variances, including both <code>-</code> and <code>/</code> as separators.</p></li>
<li>If Power BI requires you to provide it with data privacy information, you already know how to proceed based on what we've discussed in the previous sections.</li>
<li><p>As you can see, the <code>isValidDateFromRegex</code> column has been added, and it contains the Boolean values resulting from the validation of the emails through your regex. If you do a check, they coincide with the values given by definition in the <code>IsDateValidByDefinition</code> column:</p>
<figure>
<img src="../media/file141.png" alt="Figure 5.28 – The regex validation results for the dates" /><figcaption aria-hidden="true">Figure 5.28 – The regex validation results for the dates</figcaption>
</figure>
<p>Your regex did a great job! Now you can go back to the <strong>Home</strong> menu and click on <strong>Close &amp; Apply</strong>.</p></li>
</ol>
<p>Thanks to the <code>isValidDateFromRegex</code> column, you can now filter the correct and incorrect email addresses and work appropriately with them.</p>
</section>
<section id="using-regex-in-power-bi-to-validate-dates-with-r" class="level3" data-number="6.3.4">
<h3 data-number="6.3.4">Using regex in Power BI to validate dates with R</h3>
<p>If you want to use R for your date validation using regex, in this case, the process is pretty much the same except for what you have already learned in the <em>Using regex in Power BI to validate emails with R</em> section. Starting from the same <code>Users.xlsx</code> Excel file that we used in the previous section, here are the steps to follow:</p>
<ol>
<li>Repeat <em>Steps 1 to 3</em> of the <em>Using regex in Power BI to validate emails with Python</em> section to import the data contained in the <code>Users.xlsx</code> file.</li>
<li>Click on the <strong>Transform</strong> menu, and then click on <strong>Run R Script</strong>.</li>
<li><p>Then, copy and paste the following code into the R script editor and click on <strong>OK</strong>:</p>
<pre><code>library(dplyr)
library(stringr)
df &lt;- dataset
regex_dates_having_day_31 &lt;- r&#39;((?:(?:(?:0?[13578])|(?:1[02]))[\-\/]31[\-\/](?:19|20)?\d\d))&#39;
regex_non_leap_dates_having_days_29_30 &lt;- r&#39;((?:(?:(?:0?[13-9])|(?:1[0-2]))[\-\/](?:29|30)[\-\/](?:19|20)?\d\d))&#39;
regex_leap_dates_having_day_29 &lt;- r&#39;((?:0?2[\-\/]29[\-\/](?:19|20)?(?:(?:[02468][048])|(?:[13579][26]))))&#39;
regex_remaining_dates &lt;- r&#39;((?:(?:(?:0?[1-9])|(?:1[0-2]))[\-\/](?:(?:1\d)|(?:0?[1-9])|(?:2[0-8]))[\-\/](?:19|20)?\d\d))&#39;
pattern &lt;- str_glue(
  &#39;^(?:{regex_dates_having_day_31}|{regex_non_leap_dates_having_days_29_30}|{regex_leap_dates_having_day_29}|{regex_remaining_dates})$&#39;
)
df &lt;- df %&gt;% 
  mutate( isDateValidFromRegex = as.integer(str_detect(BannedDate, pattern)) )</code></pre>
<p>You can find a more exhaustive R script in the <code>04-validate-dates-with-regex-with-r.R</code> file, which can be found in the repository that comes with the book, in the <code>Chapter05\validating-data-using-regex</code> folder. That script handles dates in the formats of <code>mm-dd-yyyy</code>, <code>dd-mm-yyyy</code>, and <code>yyyy-mm-dd</code> with all their variances, including both <code>-</code> and <code>/</code> as separators.</p></li>
<li>If Power BI requires you to provide it with data privacy information, you already know how to proceed based on what we've discussed in the previous sections.</li>
<li>As you can see, the <strong>isValidDateFromRegex</strong> column has been added, and it contains the Boolean values resulting from the validation of the emails through your regex. If you do a check, they coincide with the values given by definition in the <strong>IsDateValidByDefinition</strong> column. Your regex did a great job! Now you can go back to the <strong>Home</strong> menu and click on <strong>Close &amp; Apply</strong>.</li>
</ol>
<p>Thanks to the <strong>isDateValidFromRegexegex</strong> column, you can now appropriately filter the correct and incorrect dates in your reports.</p>
<p>In the next section, you will learn how to import the contents of a semi-structured log file using Python and R.</p>
</section>
</section>
<section id="loading-complex-log-files-using-regex-in-power-bi" class="level2" data-number="6.4">
<h2 data-number="6.4">Loading complex log files using regex in Power BI</h2>
<p>Log files are a very useful tool for developers and administrators of computer systems. They record what happened to the system, when it happened, and which user actually generated the event. Thanks to these files, you can find information about any system failure, thus allowing a faster diagnosis of the causes of these faults.</p>
<p>Logs are often <strong>semi-structured data</strong>, that is, information that cannot be persisted in a relational database in the format in which it is generated. In order to be analyzed with the usual tools, first, this data must be transformed into a more suitable format.</p>
<p>Since they are not structured data, it is difficult for them to be imported into Power BI as is, unless someone has developed a custom connector to do so. It is in these scenarios that using a regex in languages such as Python or R can help us get the desired results.</p>
<section id="apache-access-logs" class="level3" data-number="6.4.1">
<h3 data-number="6.4.1">Apache access logs</h3>
<p>Let's suppose your company has a website published through an Apache web server. Your manager asks you to carry out an analysis regarding which web pages of the site are the most clicked on. The only way to get this information is to analyze the <em>access log file</em>. This file records data about all requests made to the web server. Here is an example of an Apache access log:</p>
<figure>
<img src="../media/file142.png" alt="Figure 5.29 – An example of an Apache access log" /><figcaption aria-hidden="true">Figure 5.29 – An example of an Apache access log</figcaption>
</figure>
<p>As you can see, at first glance, there is a fairly organized structure to the information in this log. If no one has customized the output of the Apache log files, it uses the <strong>Common Log Format</strong> (<strong>CLF</strong>) by default. You can find a real example of an Apache access log in the <code>apache_logs.txt</code> file, which is inside the repository that comes with this book, in the <code>Chapter05\loading-complex-log-files-using-regex</code> folder. We found it in the GitHub repository at <a href="http://bit.ly/apache-access-log">http://bit.ly/apache-access-log</a> (click on <strong>Download</strong> to view it).</p>
<p>If you go ahead and read the documentation of those log files, you will deduce that the information recorded in the access log follows the <em>NCSA extended/combined log format</em>. So, the data that is recorded is as follows:</p>
<ol>
<li>The remote hostname (the IP address).</li>
<li>The remote logname (if empty, you'll find a dash; it is not used in the sample file).</li>
<li>The remote user if the request was authenticated (if empty, you'll find a dash).</li>
<li>The datetime that the request was received, in the <code>[18/Sep/2011:19:18:28 -0400]</code> format.</li>
<li>The first line of the request made to the server between double quotes.</li>
<li>The HTTP status code for the request.</li>
<li>The size of the response in bytes, excluding the HTTP headers (could be a dash).</li>
<li>The <code>Referer</code> HTTP request header, which contains the absolute or partial address of the page making the request.</li>
<li>The <code>User-Agent</code> HTTP request header, which contains a string that identifies the application, operating system, vendor, and/or version of the requesting user agent.</li>
</ol>
<p>Once you know both the nature of the information written in the log and the form in which it is written, you can take advantage of the powerful tools provided by regexes to better structure this information and import it into Power BI.</p>
</section>
<section id="importing-apache-access-logs-in-power-bi-with-python" class="level3" data-number="6.4.2">
<h3 data-number="6.4.2">Importing Apache access logs in Power BI with Python</h3>
<p>As mentioned earlier, you can find a real example of an Apache access log in the <code>apache_logs.txt</code> file, which is inside the repository that comes with this book, in the <code>Chapter05\loading-complex-log-files-using-regex</code> folder. You will load the information in this file using a Python script, not a Power BI connector.</p>
<p>Compared to what you've learned before about regexes and Python, in the <code>01-apache-access-log-parser-python.py</code> Python script (which you'll find in the preceding folder), you'll encounter these new constructs:</p>
<ul>
<li>To be able to read a text file line by line in Python, you'll use the <code>open(file, mode)</code> functions and the <code>readlines()</code> method. Specifically, you're going to read the <code>apache_logs.txt</code> file as read-only (<code>'r'</code>) and read each of its lines to store them in a list.</li>
</ul>
<p>In regexes, it is possible to refer to groups identified by round brackets not only by a numerical index but also <em>by a name.</em> This is thanks to <strong>named capturing groups</strong>. Usually, the regex syntax that is used to assign a name to a group is <code>(?&lt;group-name&gt;…)</code>. In Python, it is <code>(?P&lt;group-name&gt;…)</code>:</p>
<ul>
<li><p>In Python, you can define a list of regex parts that can be merged together (<code>join</code>) using a separator, which is defined by a regex itself (<code>\s+</code>):</p>
<pre><code>regex_parts = [
    r&#39;(?P&lt;hostName&gt;\S+)&#39;,
    r&#39;\S+&#39;,
    r&#39;(?P&lt;userName&gt;\S+)&#39;,
    r&#39;\[(?P&lt;requestDateTime&gt;[\w:/]+\s[+\-]\d{4})\]&#39;,
    r&#39;&quot;(?P&lt;requestContent&gt;\S+\s?\S+?\s?\S+?)&quot;&#39;,
    r&#39;(?P&lt;requestStatus&gt;\d{3}|-)&#39;,
    r&#39;(?P&lt;responseSizeBytes&gt;\d+|-)&#39;,
    r&#39;&quot;(?P&lt;requestReferrer&gt;[^&quot;]*)&quot;&#39;,
    r&#39;&quot;(?P&lt;requestAgent&gt;[^&quot;]*)?&quot;&#39;,
]
pattern = re.compile(r&#39;\s+&#39;.join(regex_parts) + r&#39;$&#39;)</code></pre>
<p>Note that, in this case, the <code>re.compile()</code> function is used since the match must be done many times on all lines of the log; therefore, precompiling the regex could have computational advantages.</p></li>
<li><p>Pattern matching is done for each line in the log:</p>
<pre><code>for line in access_log_lines:    
    log_data.append(pattern.match(line).groupdict())</code></pre>
<p>The <code>groupdict()</code> method returns a dictionary with the group names as the key and the matched strings as the value for that key. All the dictionaries for each line are appended to the <code>log_data</code> list.</p></li>
</ul>
<p>We leave it to the reader to interpret how each individual regex part goes about capturing the desired string.</p>
<p>Now that we've clarified a few points in the code, let's import the log into Power BI:</p>
<ol>
<li>In Power BI Desktop, be sure to use the <code>pbi_powerquery_env</code> environment.</li>
<li>Go to <strong>Get Data</strong> and select the Python script.</li>
<li>Copy and paste the script from the <code>01-apache-access-log-parser-python.py</code> file into the Python script editor and click on <strong>OK</strong>.</li>
<li><p>Then, select the <strong>df</strong> dataframe from the <strong>Navigator</strong> window and click on <strong>Load</strong>:</p>
<figure>
<img src="../media/file143.png" alt="Figure 5.30 – Selecting the df dataframe returned by the Python script" /><figcaption aria-hidden="true">Figure 5.30 – Selecting the df dataframe returned by the Python script</figcaption>
</figure></li>
<li>If you click on the <strong>Data</strong> icon, you can view the entire log loaded as a structured table:</li>
</ol>
<figure>
<img src="../media/file144.png" alt="Figure 5.31 – The Apache access log is loaded in Power BI with Python" /><figcaption aria-hidden="true">Figure 5.31 – The Apache access log is loaded in Power BI with Python</figcaption>
</figure>
<p>Awesome! Thanks to the power of regex, you've just managed to easily import into Power BI what looked like a complex log file to manage.</p>
</section>
<section id="importing-apache-access-logs-in-power-bi-with-r" class="level3" data-number="6.4.3">
<h3 data-number="6.4.3">Importing Apache access logs in Power BI with R</h3>
<p>In this section, you will load the information of the <code>apache_logs.txt</code> file, but this time, using an R script.</p>
<p>Compared to what you've learned previously about regexes in R, in the <code>02-apache-access-log-parser-r.R</code> script (which you'll find in the same preceding folder), you'll encounter these new constructs:</p>
<ul>
<li>To be able to read a text file line by line in R, you'll use the <code>read_lines()</code> function from the <code>readr</code> package. Specifically, you're going to read each line of the <code>apache_logs.txt</code> file in order to persist them to a vector.</li>
<li>In order to take full advantage of named capturing groups in R, you need to install and use the features of a new package, called <strong>namedCapture</strong>. Thanks to this package, both regex syntaxes for named groups are allowed: the standard <code>(?&lt;group-name&gt;…)</code> regex syntax and the <code>(?P&lt;group-name&gt;…)</code> regex syntax.</li>
<li><p>Just as we did in the Python script, in R, you'll also define a vector of regex parts, which you'll merge with the <code>paste(..., collapse = '...')</code> function. This function has the task of joining regex parts together through the <code>\s+</code> separator. After merging all of the parts, the <code>$</code> character is added to the end of the resulting string using the <code>paste0(…)</code> function. Remember that raw strings have a different syntax in R than in Python. In this case, we will use the <code>r'{...}'</code> syntax:</p>
<pre><code>regex_parts &lt;- c(
    r&#39;{(?P&lt;hostName&gt;\S+)}&#39;
  , r&#39;{\S+}&#39;
  , r&#39;{(?P&lt;userName&gt;\S+)}&#39;
  , r&#39;{\[(?P&lt;requestDateTime&gt;[\w:/]+\s[+\-]\d{4})\]}&#39;
  , r&#39;{&quot;(?P&lt;requestContent&gt;\S+\s?\S+?\s?\S+?)&quot;}&#39;
  , r&#39;{(?P&lt;requestStatus&gt;\d{3}|-)}&#39;
  , r&#39;{(?P&lt;responseSizeBytes&gt;\d+|-)}&#39;
  , r&#39;{&quot;(?P&lt;requestReferrer&gt;[^&quot;]*)&quot;}&#39;
  , r&#39;{&quot;(?P&lt;requestAgent&gt;[^&quot;]*)?&quot;}&#39;
)
pattern &lt;- paste0( paste(regex_parts, collapse = r&#39;{\s+}&#39;), &#39;$&#39; )</code></pre></li>
<li><p>Pattern matching is done using the <code>str_match_named()</code> function of the <code>namedCapture</code> package over the whole log vector, using a single-line command:</p>
<pre><code>df &lt;- as.data.frame( str_match_named( access_log_lines, pattern = pattern ) )</code></pre></li>
</ul>
<p>Again, we leave it to the reader to interpret how each individual regex part goes about capturing the desired string.</p>
<p>Now that we've clarified a few points in the code, let's import the log into Power BI:</p>
<ol>
<li><p>First, you need to install the <code>namedCapture</code> package. So, open RStudio and make sure that the engine being referenced is the latest one in <strong>Global Options</strong>. Then, run the following code in a new script to temporarily set CRAN as the repository to download packages from:</p>
<pre><code>local({
  r &lt;- getOption(&quot;repos&quot;)
  r[&quot;CRAN&quot;] &lt;- &quot;https://cloud.r-project.org/&quot;
  options(repos = r)
})</code></pre>
<p>All this has been done to download the latest version of the <code>namedCapture</code> package.</p></li>
<li><p>Now, go to the console and enter and run the following code:</p>
<pre><code>install.packages(&quot;namedCapture&quot;)</code></pre></li>
<li>Open Power BI Desktop, go to <strong>Get Data</strong>, and select the R script.</li>
<li>Copy and paste the script from the <code>02-apache-access-log-parser-r.R</code> file into the R script editor and then click on <strong>OK</strong>.</li>
<li><p>Then, select the <strong>df</strong> dataframe from the <strong>Navigator</strong> window and click on <strong>Load</strong>:</p>
<figure>
<img src="../media/file145.png" alt="Figure 5.32 – Selecting the df dataframe returned by the R script" /><figcaption aria-hidden="true">Figure 5.32 – Selecting the df dataframe returned by the R script</figcaption>
</figure></li>
<li>If you click on the <strong>Data</strong> icon, you can view the entire log loaded as a structured table:</li>
</ol>
<figure>
<img src="../media/file146.png" alt="Figure 5.33 – The Apache access log loaded in Power BI with R" /><figcaption aria-hidden="true">Figure 5.33 – The Apache access log loaded in Power BI with R</figcaption>
</figure>
<p>Great job! You were able to import a semi-structured log file into Power BI even with R.</p>
</section>
</section>
<section id="extracting-values-from-text-using-regex-in-power-bi" class="level2" data-number="6.5">
<h2 data-number="6.5">Extracting values from text using regex in Power BI</h2>
<p>The last use case we want to present happens very often when dealing with shipments of goods to customers. Sometimes, it happens that a fraudster manages to steal the goods addressed to a customer; therefore, the customer must be refunded by the company. The defrauded customer then contacts Customer Care to request a refund. If the management system provided to the Customer Care operator who has to manage the case does not allow you to enter the information of the refund in a structured way, the operator must resort to the only possible method: the entry of a <em>free text note</em> associated with the order, which specifies the <em>amount</em>, the <em>reason</em> and the <em>date</em> of the refund.</p>
<p>You already know that information entered in free text is every analyst's nightmare, especially when your boss asks you to analyze the very information entered in these infamous notes.</p>
<p>In the repository that comes with this book, you can find the <code>OrderNotes.xlsx</code> Excel file inside the <code>Chapter05</code> folder. Its content is similar to the content shown in <em>Figure 5.34</em>:</p>
<figure>
<img src="../media/file147.png" alt="Figure 5.34 – Free text notes entered by the operator for some orders" /><figcaption aria-hidden="true">Figure 5.34 – Free text notes entered by the operator for some orders</figcaption>
</figure>
<p>As you can see, by looking at the contents of the Excel file, the relevant information to extract from the notes is as follows:</p>
<ul>
<li>The refund amount</li>
<li>The refund reason</li>
<li>The refund date</li>
</ul>
<p>The problem is that the Customer Care operators used a lot of imagination to enter this information, without the slightest predetermined rule of how to structure it. From this, we can see the following:</p>
<ul>
<li>The refund amount was entered as <em>EUR xx.yy</em>, <em>EURxx.yy</em>, <em>xx.yy EUR</em>, <em>€ xx.yy</em>, <em>xx.yy€</em>, and <em>xx.yy €</em>.</li>
<li>The "separator" between all of the pieces of information can be made by one or more whitespaces or by a dash surrounded by one or more spaces.</li>
<li>The refund date is always in the <code>dd/mm/yyyy</code> format (you are lucky here!).</li>
<li>The refund reason could contain any text.</li>
</ul>
<p>Given all this generality of the entered notes, is it possible to correctly extract the information needed for the analysis requested by your boss? The answer is certainly "yes" if you know how to best use regexes.</p>
<section id="one-regex-to-rule-them-all" class="level3" data-number="6.5.1">
<h3 data-number="6.5.1">One regex to rule them all</h3>
<p>With the experience you gathered during the previous sections, you will immediately understand the solution we are going to propose. Consider the following regex parts:</p>
<ul>
<li><strong>Currency</strong>: <code>(?:EUR|€)</code></li>
<li><strong>Separator</strong>: <code>(?:\s+)?-?(?:\s+)?</code></li>
<li><strong>Refund amount</strong>: <code>\d{1,}\.?\d{0,2}</code></li>
<li><strong>Refund reason</strong>: <code>.*?</code></li>
<li><strong>Refund date</strong>: <code>\d{2}[\-\/]\d{2}[\-\/]\d{4}</code></li>
</ul>
<p>Remember the syntax of a <strong>non-capturing group</strong>, <code>(?:…)</code>? Well, with this syntax, you're explicitly saying to the regex engine that you don't want to capture the content inside those brackets, as this isn't important information to extract. That said, the final regex is nothing more than multiple alternative combinations of these parts, such as the one you can see in <em>Figure 5.35</em>:</p>
<figure>
<img src="../media/file148.png" alt="Figure 5.35 – The full regex structure for extracting information from notes" /><figcaption aria-hidden="true">Figure 5.35 – The full regex structure for extracting information from notes</figcaption>
</figure>
<p>If you're curious to see it in full, the final complete regex is as follows:</p>
<pre><code>^(?:(?:(?:EUR|€)(?:\s+)?-?(?:\s+)?(?P&lt;RefundAmount&gt;\d{1,}\.?\d{0,2})(?:\s+)?-?(?:\s+)?(?P&lt;RefundReason&gt;.*?)(?:\s+)?-?(?:\s+)?(?P&lt;RefundDate&gt;\d{2}[\-\/]\d{2}[\-\/]\d{4})(?:\s+)?-?(?:\s+)?)|(?:(?P&lt;RefundAmount&gt;\d{1,}\.?\d{0,2})(?:\s+)?-?(?:\s+)?(?:EUR|€)(?:\s+)?-?(?:\s+)?(?P&lt;RefundReason&gt;.*?)(?:\s+)?-?(?:\s+)?(?P&lt;RefundDate&gt;\d{2}[\-\/]\d{2}[\-\/]\d{4})(?:\s+)?-?(?:\s+)?)|(?:(?P&lt;RefundDate&gt;\d{2}[\-\/]\d{2}[\-\/]\d{4})(?:\s+)?-?(?:\s+)?(?:EUR|€)(?:\s+)?-?(?:\s+)?(?P&lt;RefundAmount&gt;\d{1,}\.?\d{0,2})(?:\s+)?-?(?:\s+)?(?P&lt;RefundReason&gt;.*?)(?:\s+)?-?(?:\s+)?)|(?:(?P&lt;RefundDate&gt;\d{2}[\-\/]\d{2}[\-\/]\d{4})(?:\s+)?-?(?:\s+)?(?P&lt;RefundAmount&gt;\d{1,}\.?\d{0,2})(?:\s+)?-?(?:\s+)?(?:EUR|€)(?:\s+)?-?(?:\s+)?(?P&lt;RefundReason&gt;.*?)(?:\s+)?-?(?:\s+)?))$</code></pre>
<p>Let's implement it in Power BI using Python.</p>
</section>
<section id="using-regex-in-power-bi-to-extract-values-with-python" class="level3" data-number="6.5.2">
<h3 data-number="6.5.2">Using regex in Power BI to extract values with Python</h3>
<p>As you saw from <em>Figure 5.35</em>, our regex contains named groups that are <em>reused multiple times</em> within it. Unfortunately, the reuse of the same named group within a regex is not supported by the Python <code>re</code> module, which, by the way, is the module that is also used behind the scenes in <code>pandas</code>. In order to use more advanced features of regex, such as the previously mentioned <em>identically named groups</em> or <em>lookbehind</em> and <em>lookahead</em> syntaxes (which are not explored in this chapter), you must use the <code>regex</code> module. So, first of all, you have to install it within your <em>pbi_powerquery_env</em> environment. Then, you have to load the <code>OrderNotes.xlsx</code> Excel file, which you can find in the <code>Chapter05</code> folder, into Power BI Desktop. After that, you can transform that dataset using a Python script. So, let's get started:</p>
<ol>
<li>Open your Anaconda Prompt, switch to your <code>pbi_powerquery_env</code> environment using the <code>conda activate pbi_powerquery_env</code> command, and then install the <code>regex</code> package using this code: <code>pip install regex</code>.</li>
<li>Open your Power BI Desktop and make sure the referenced Python environment is <code>pbi_powerquery_env</code> in the <strong>Options</strong>.</li>
<li>From the ribbon, click on the <strong>Excel</strong> icon to import data from Excel and open the <code>OrderNotes.xlsx</code> file.</li>
<li><p>Select the <strong>Sheet1</strong> dataset from the <strong>Navigator</strong> window and click on <strong>Transform Data</strong>:</p>
<figure>
<img src="../media/file149.png" alt="Figure 5.36 – Loading the order notes from Excel and transforming the data" /><figcaption aria-hidden="true">Figure 5.36 – Loading the order notes from Excel and transforming the data</figcaption>
</figure></li>
<li><p>Declare the first row of loaded data as column headers by clicking on <strong>Use First Row as Headers</strong>:</p>
<figure>
<img src="../media/file150.png" alt="Figure 5.37 – The Use First Row as Headers button" /><figcaption aria-hidden="true">Figure 5.37 – The Use First Row as Headers button</figcaption>
</figure></li>
<li>Then, go to the <strong>Transform</strong> menu and click on <strong>Run Python script</strong>.</li>
<li>Open the Python script that you can find inside the <code>01-order-notes-parser-python.py</code> file, which is in the <code>Chapter05\extracting-values-from-text-using-regex</code> folder. Copy and paste the script into the <strong>Run Python script</strong> editor and then click on <strong>OK</strong>.</li>
<li>If there are any issues with the compatibility levels of the datasets, simply open the <strong>Data source settings</strong> window and set the permissions of each dataset to <em>Organizational</em> using <strong>Edit Permissions…</strong>. Then, click on <strong>Refresh Preview</strong>.</li>
<li><p>We are only interested in the <code>df</code> dataset. So, click on its <strong>Table</strong> value:</p>
<figure>
<img src="../media/file151.png" alt="Figure 5.38 – Selecting the df dataset as a result of the Python script transformation" /><figcaption aria-hidden="true">Figure 5.38 – Selecting the df dataset as a result of the Python script transformation</figcaption>
</figure></li>
<li><p>You can see that the resulting table has three more columns, where each one is related to a named group:</p>
<figure>
<img src="../media/file152.png" alt="Figure 5.39 – The values extracted from free notes using regex with Python" /><figcaption aria-hidden="true">Figure 5.39 – The values extracted from free notes using regex with Python</figcaption>
</figure>
<p>Finally, go to the <strong>Home</strong> menu and click on <strong>Close &amp; Apply</strong>.</p></li>
</ol>
<p>Awesome! You've just managed to reorganize the data contained in the order notes using regexes in Python. Your boss will be more than satisfied!</p>
</section>
<section id="using-regex-in-power-bi-to-extract-values-with-r" class="level3" data-number="6.5.3">
<h3 data-number="6.5.3">Using regex in Power BI to extract values with R</h3>
<p>In R, we can continue to use the <code>namedCapture</code> package to manage named groups that are reused multiple times in the same regex. We can do this by putting the <code>(?J)</code> modifier in front of it (this allows multiple named capturing groups to share the same name). Unlike Python, in R, the <code>str_match_named()</code> function of the <code>namedCapture</code> package does not return a one-time result captured by the named group. It returns as many columns as the number of times it was used:</p>
<figure>
<img src="../media/file153.png" alt="Figure 5.40 – Returning as many columns as the number of times the named group is used" /><figcaption aria-hidden="true">Figure 5.40 – Returning as many columns as the number of times the named group is used</figcaption>
</figure>
<p>For this reason, we had to further manipulate the result; first, by replacing the empty characters with the null value of <code>NA</code>, and second, by applying the <code>coalesce()</code> function of <code>dplyr</code>, which merges multiple columns into one by keeping the non-null values.</p>
<blockquote>
<p><strong>Important note</strong></p>
<p>We pointed out this limitation to Toby Dylan Hocking, the author of the <code>namedCapture</code> package, who recently implemented the feature inside the new version of the package, named <code>nc</code>. You can find details of the implementation at <a href="https://github.com/tdhock/namedCapture/issues/15">https://github.com/tdhock/namedCapture/issues/15</a>. The new version of the <code>nc</code> package has not yet been published onto CRAN at the time of writing. Therefore, we thought it appropriate to keep the use of the <code>namedCapture</code> package in our code. However, feel free to adopt the new <code>nc</code> package for your future projects.</p>
</blockquote>
<p>That said, let's start to extract values from the order notes using R in Power BI:</p>
<ol>
<li>Open your Power BI Desktop and make sure the referenced R engine is the latest one (in our case, this is <em>MRO 4.0.2</em>).</li>
<li>From the ribbon, click on the <strong>Excel</strong> icon to import data from Excel, and open the <code>OrderNotes.xlsx</code> file, which you can find in the <code>Chapter05</code> folder.</li>
<li><p>Select the <strong>Sheet1</strong> dataset from the <strong>Navigator</strong> window, and click on <strong>Transform Data</strong>:</p>
<figure>
<img src="../media/file154.png" alt="Figure 5.41 – Loading the order notes from Excel and transforming the data" /><figcaption aria-hidden="true">Figure 5.41 – Loading the order notes from Excel and transforming the data</figcaption>
</figure></li>
<li>Declare the first row of loaded data as column headers by clicking on <strong>Use First Row as Headers</strong>.</li>
<li>Then, go to the <strong>Transform</strong> menu and click on <strong>Run R script</strong>.</li>
<li>Open the R script that you can find inside the <code>02-order-notes-parser-r.R</code> file, which is in the <code>Chapter05\extracting-values-from-text-using-regex</code> folder. Copy and paste the script into the <strong>Run R script</strong> editor and then click on <strong>OK</strong>.</li>
<li><p>We are only interested in the <code>df</code> dataset. So, click on its <strong>Table</strong> value:</p>
<figure>
<img src="../media/file155.png" alt="Figure 5.42 – Selecting the df dataset as a result of the R script transformation" /><figcaption aria-hidden="true">Figure 5.42 – Selecting the df dataset as a result of the R script transformation</figcaption>
</figure></li>
<li><p>You can see that the resulting table has three more columns, each one related to a named group:</p>
<figure>
<img src="../media/file156.png" alt="Figure 5.43 – The values extracted from the free notes using regex with Python" /><figcaption aria-hidden="true">Figure 5.43 – The values extracted from the free notes using regex with Python</figcaption>
</figure>
<p>Finally, go to the <strong>Home</strong> menu and click on <strong>Close &amp; Apply</strong>.</p></li>
</ol>
<p>Amazing! You've just demonstrated that you know how to rearrange data contained in the order notes using regexes even with R.</p>
</section>
</section>
<section id="summary-4" class="level2" data-number="6.6">
<h2 data-number="6.6">Summary</h2>
<p>In this chapter, you were introduced to the basics of how to use regexes. Using the bare minimum, you were able to effectively validate strings representing email addresses and dates in Power BI, using both Python and R.</p>
<p>Additionally, you learned how to extract information from semi-structured log files through the use of regexes, and how to import the extracted information, in a structured way, into Power BI.</p>
<p>Finally, you learned how to use regex in Python and R to extract information from seemingly unprocessable free text thanks to the real-world case of notes associated with sales orders.</p>
<p>In the next chapter, you'll learn how to use some de-identification techniques in Power BI to anonymize or pseudonymize datasets that show sensitive data about individuals in plain text before they are imported into Power BI.</p>
</section>
<section id="references-1" class="level2" data-number="6.7">
<h2 data-number="6.7">References</h2>
<p>For additional reading, please refer to the following books and articles:</p>
<ol>
<li><em>Regular Expressions: The Complete Tutorial, Jan Goyvaerts</em> (<a href="https://www.princeton.edu/~mlovett/reference/Regular-Expressions.pdf">https://www.princeton.edu/~mlovett/reference/Regular-Expressions.pdf</a>)</li>
<li><em>Data Privacy Settings In Power BI/Power Query, Part 1: Performance Implications</em> (<a href="https://blog.crossjoin.co.uk/2017/05/24/data-privacy-settings-in-power-bipower-query-part-1-performance-implications/">https://blog.crossjoin.co.uk/2017/05/24/data-privacy-settings-in-power-bipower-query-part-1-performance-implications/</a>)</li>
</ol>
</section>
</section>
</body>
</html>
