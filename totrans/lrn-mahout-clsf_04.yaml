- en: Chapter 4. Learning the Naïve Bayes Classification Using Mahout
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第四章：使用Mahout学习朴素贝叶斯分类
- en: 'In this chapter, we will use the Naïve Bayes classification algorithm to classify
    a set of documents. Classifying text documents is a little tricky because of the
    data preparation steps involved. In this chapter, we will explore the following
    topics:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用朴素贝叶斯分类算法对一组文档进行分类。由于涉及到的数据准备步骤，对文本文档进行分类有点棘手。在本章中，我们将探讨以下主题：
- en: Conditional probability and the Bayes rule
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 条件概率和贝叶斯定理
- en: Understanding the Naïve Bayes algorithm
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解朴素贝叶斯算法
- en: Understanding terms used in text classification
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解文本分类中使用的术语
- en: Using the Naïve Bayes algorithm in Apache Mahout
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Apache Mahout中使用朴素贝叶斯算法
- en: Introducing conditional probability and the Bayes rule
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍条件概率和贝叶斯定理
- en: Before learning the Naïve Bayes algorithm, you should have an understanding
    of conditional probability and the Bayes rule.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在学习朴素贝叶斯算法之前，你应该了解条件概率和贝叶斯定理。
- en: In very simple terms, conditional probability is the probability that something
    will happen, given that something else has already happened. It is expressed as
    *P(A/B)*, which can be read as probability of A given B, and it finds the probability
    of the occurrence of event A once event B has already happened.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 简单来说，条件概率是在已知另一件事情已经发生的情况下，某件事情发生的概率。它表示为 *P(A/B)*，可以读作在B的条件下A的概率，它找出在事件B已经发生的情况下事件A发生的概率。
- en: 'Mathematically, it is defined as follows:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 从数学上定义如下：
- en: '![Introducing conditional probability and the Bayes rule](img/4959OS_04_01.jpg)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![介绍条件概率和贝叶斯定理](img/4959OS_04_01.jpg)'
- en: For example, if you choose a card from a standard card deck and if you were
    asked about the probability for the card to be a diamond, you would quickly say
    13/52 or 0.25, as there are 13 diamond cards in the deck. However, if you then
    look at the card and declare that it is red, then we will have narrowed the possibilities
    for the card to 26 possible cards, and the probability that the card is a diamond
    now is 13/26 = 0.5\. So, if we define A as a diamond card and B as a red card,
    then *P(A/B)* will be the probability of the card being a diamond, given it is
    red.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果你从一副标准的扑克牌中抽取一张牌，如果有人问你这张牌是红桃的概率，你会很快回答 13/52 或 0.25，因为牌中有13张红桃牌。然而，如果你然后查看这张牌并宣布它是红色的，那么我们将把这张牌的可能性缩小到26张可能的牌，这张牌是红桃的概率现在是
    13/26 = 0.5。所以，如果我们定义A为红桃牌，B为红牌，那么 *P(A/B)* 将是已知这张牌是红色的条件下，这张牌是红桃的概率。
- en: Sometimes, for a given pair of events, conditional probability is hard to calculate,
    and Bayes' theorem helps us here by giving the relationship between two conditional
    probabilities.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，对于给定的一对事件，条件概率难以计算，而贝叶斯定理通过给出两个条件概率之间的关系来帮助我们。
- en: 'Bayes'' theorem is defined as follows:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯定理定义为如下：
- en: '![Introducing conditional probability and the Bayes rule](img/4959OS_04_02.jpg)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![介绍条件概率和贝叶斯定理](img/4959OS_04_02.jpg)'
- en: 'The terms in the formula are defined as follows:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 公式中的术语定义如下：
- en: '**P(A)**: This is called prior probability or prior'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**P(A)**: 这被称为先验概率或先验'
- en: '**P(B/A)**: This is called conditional probability or likelihood'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**P(B/A)**: 这被称为条件概率或似然'
- en: '**P(B)**: This is called marginal probability'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**P(B)**: 这被称为边缘概率'
- en: '**P(A/B)**: This is called posterior probability or posterior'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**P(A/B)**: 这被称为后验概率或后验'
- en: 'The following formula is derived only from the conditional probability formula.
    We can define *P(B/A)* as follows:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 以下公式仅从条件概率公式推导而来。我们可以定义 *P(B/A)* 如下：
- en: '![Introducing conditional probability and the Bayes rule](img/4959OS_04_03.jpg)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![介绍条件概率和贝叶斯定理](img/4959OS_04_03.jpg)'
- en: 'When rearranged, the formula becomes this:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 重新排列后，公式变为：
- en: '![Introducing conditional probability and the Bayes rule](img/4959OS_04_04.jpg)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![介绍条件概率和贝叶斯定理](img/4959OS_04_04.jpg)'
- en: 'Now, from the preceding conditional probability formula, we get the following:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，从先前的条件概率公式中，我们得到以下：
- en: '![Introducing conditional probability and the Bayes rule](img/4959OS_04_05.jpg)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![介绍条件概率和贝叶斯定理](img/4959OS_04_05.jpg)'
- en: Let's take an example that will help us to understand how Bayes' theorem is
    applied.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们举一个例子，这个例子将帮助我们理解贝叶斯定理是如何应用的。
- en: 'A cancer test gives a positive result with a probability of 97 percent when
    the patient is indeed affected by cancer, while it gives a negative result with
    99 percent probability when the patient is not affected by cancer. If a patient
    is drawn at random from a population where 0.2 percent of the individuals are
    affected by cancer and he or she is found to be positive, what is the probability
    that he or she is indeed affected by cancer? In probabilistic terms, what we know
    about this problem can be defined as follows:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 当患者确实受到癌症影响时，癌症测试以97%的概率给出阳性结果，而当患者未受到影响时，以99%的概率给出阴性结果。如果从一个人群中随机抽取一个患者，该人群中0.2%的人受到癌症影响，并且他被发现是阳性的，那么他或她确实受到癌症影响的概率是多少？在概率论中，我们关于这个问题的了解可以定义为以下内容：
- en: '*P (positive| cancer) = 0.97*'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '*P (阳性|癌症) = 0.97*'
- en: '*P (positive| no cancer) = 1-0.99 = 0.01*'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '*P (阳性|无癌症) = 1-0.99 = 0.01*'
- en: '*P (cancer) = 0.002*'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '*P (癌症) = 0.002*'
- en: '*P (no cancer) = 1-0.002= 0.998*'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '*P (无癌症) = 1-0.002= 0.998*'
- en: '*P (positive) = P (positive| cancer) P (cancer) + P (positive| no cancer) P
    (no cancer)*'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '*P (阳性) = P (阳性|癌症) P (癌症) + P (阳性|无癌症) P (无癌症)*'
- en: '*= 0.97*0.002 + 0.01*0.998*'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '*= 0.97*0.002 + 0.01*0.998*'
- en: '*= 0.01192*'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '*= 0.01192*'
- en: Now *P (cancer| positive) = (0.97*0.002)/0.01192 = 0.1628*
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 现在 *P (癌症|阳性) = (0.97*0.002)/0.01192 = 0.1628*
- en: So even when found positive, the probability of the patient being affected by
    cancer in this example is around 16 percent.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，即使发现阳性，在这个例子中，患者受到癌症影响的概率大约是16%。
- en: Understanding the Naïve Bayes algorithm
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解朴素贝叶斯算法
- en: 'In Bayes'' theorem, we have seen that the outcome is based only on one evidence,
    but in classification problems, we have multiple evidences and we have to predict
    the outcome. In Naïve Bayes, we uncouple multiple pieces of evidence and treat
    each one of them independently. It is defined as follows:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在贝叶斯定理中，我们了解到结果仅基于一个证据，但在分类问题中，我们有多个证据，并且我们必须预测结果。在朴素贝叶斯中，我们解耦多个证据，并独立地处理每一个。它定义如下：
- en: '*P (outcome | multiple Evidence) ) = P (Evidence 1|outcome)* P (Evidence 2|outcome)*
    P (Evidence 3|outcome) …. /P (Evidence)*'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '*P (结果 | 多个证据) ) = P (证据1|结果)* P (证据2|结果)* P (证据3|结果) …… /P (证据)*'
- en: Run this formula for each possible outcome. Since we are trying to classify,
    each outcome will be called a class. Our task is to look at the evidence (features)
    to consider how likely it is for it to be of a particular class and then assign
    it accordingly. The class that has the highest probability gets assigned to that
    combination of evidences. Let's understand this with an example.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 对每个可能的结果运行这个公式。由于我们正在尝试分类，每个结果都将被称为一个类别。我们的任务是查看证据（特征）以考虑它属于特定类别的可能性，然后相应地分配。具有最高概率的类别将被分配给该组合的证据。让我们用一个例子来理解这一点。
- en: 'Let''s say that we have data on 1,000 pieces of fruit. They happen to be bananas,
    apples, or some other fruit. We are aware of three characteristics of each fruit:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有关于1000件水果的数据。它们可能是香蕉、苹果或其他水果。我们知道每件水果的三个特征：
- en: '**Size**: They are either long or not long'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**大小**：它们要么是长，要么不是长'
- en: '**Taste**: They are either sweet or not sweet'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**味道**：它们要么是甜的，要么不是甜的'
- en: '**Color**: They are either yellow or not yellow'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**颜色**：它们要么是黄色，要么不是黄色'
- en: 'Assume that we have a dataset like the following:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个如下所示的数据集：
- en: '| Fruit type | Taste – sweet | Taste – not sweet | Color – yellow | Color –
    not yellow | Size – long | Size – not long | Total |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| 水果类型 | 味道 – 甜 | 味道 – 不甜 | 颜色 – 黄色 | 颜色 – 非黄色 | 大小 – 长 | 大小 – 非长 | 总计 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| **Banana** | 350 | 150 | 450 | 50 | 400 | 100 | 500 |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| **香蕉** | 350 | 150 | 450 | 50 | 400 | 100 | 500 |'
- en: '| **Apple** | 150 | 150 | 100 | 200 | 0 | 300 | 300 |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| **苹果** | 150 | 150 | 100 | 200 | 0 | 300 | 300 |'
- en: '| **Other** | 150 | 50 | 50 | 150 | 100 | 100 | 200 |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| **其他** | 150 | 50 | 50 | 150 | 100 | 100 | 200 |'
- en: '| **Total** | 650 | 350 | 600 | 400 | 500 | 500 | 1000 |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| **总计** | 650 | 350 | 600 | 400 | 500 | 500 | 1000 |'
- en: 'Now let''s look at the things we have:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看看我们拥有的东西：
- en: '*P (Banana) = 500/1000 = 0.5*'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '*P (香蕉) = 500/1000 = 0.5*'
- en: '*P (Apple) = 300/1000 = 0.3*'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '*P (苹果) = 300/1000 = 0.3*'
- en: '*P (Other) = 200/1000 = 0.2*'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '*P (其他) = 200/1000 = 0.2*'
- en: 'Let''s look at the probability of the features:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看特征的概率：
- en: '*P (Sweet) = 650/1000 = 0.65*'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '*P (甜) = 650/1000 = 0.65*'
- en: '*P (Yellow) = 600/1000 = 0.6*'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '*P (黄色) = 600/1000 = 0.6*'
- en: '*P (long) = 500/1000 = 0.5*'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '*P (长) = 500/1000 = 0.5*'
- en: '*P (not Sweet) = 350/1000 = 0.35*'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '*P (非甜) = 350/1000 = 0.35*'
- en: '*P (not yellow) = 400/1000= 0.4*'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '*P (非黄色) = 400/1000= 0.4*'
- en: '*P (not long) = 500/1000 = 0.5*'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '*P (非长) = 500/1000 = 0.5*'
- en: 'Now we want to know what fruit we will have if it is not yellow and not long
    and sweet. The probability of it being an apple is as follows:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们想知道如果它既不黄也不长也不甜，我们将有什么水果。它成为苹果的概率如下：
- en: '*P (Apple| sweet, not long, not yellow) = P (sweet | Apple)* P (not long |
    Apple)* P (not yellow | Apple)*P (Apple)/P (sweet)* P (not long) *P (not yellow)*'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '*P (Apple| sweet, not long, not yellow) = P (sweet | Apple)* P (not long |
    Apple)* P (not yellow | Apple)*P (Apple)/P (sweet)* P (not long) *P (not yellow)*'
- en: '*= 0.5*1*0.67*0.3/P (Evidence)*'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '*= 0.5*1*0.67*0.3/P (证据)*'
- en: '*= 0.1005/P (Evidence)*'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '*= 0.1005/P (证据)*'
- en: 'The probability of it being a banana is this:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 它成为香蕉的概率如下：
- en: '*P (banana| sweet, not long, not yellow) = P (sweet | banana)* P (not long
    | banana)* P (not yellow | banana)*P (banana)/P (sweet)* P (not long) *P (not
    yellow)*'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '*P (banana| sweet, not long, not yellow) = P (sweet | banana)* P (not long
    | banana)* P (not yellow | banana)*P (banana)/P (sweet)* P (not long) *P (not
    yellow)*'
- en: '*= 0.7*0.2*0.1*0.5/P (Evidence)*'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '*= 0.7*0.2*0.1*0.5/P (证据)*'
- en: '*= 0.007/P (Evidence)*'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '*= 0.007/P (证据)*'
- en: 'The probability of it being any other fruit is as follows:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 它成为任何其他水果的概率如下：
- en: '*P (other fruit| sweet, not long, not yellow) = P (sweet | other fruit)* P
    (not long | other fruit)* P (not yellow | other fruit) *P (other fruit)/P (sweet)*
    P (not long) *P (not yellow)*'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '*P (other fruit| sweet, not long, not yellow) = P (sweet | other fruit)* P
    (not long | other fruit)* P (not yellow | other fruit) *P (other fruit)/P (sweet)*
    P (not long) *P (not yellow)*'
- en: '*= 0.75*0.5*0.75*0.2/P (Evidence)*'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '*= 0.75*0.5*0.75*0.2/P (证据)*'
- en: '*= 0.05625/ P (Evidence)*'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '*= 0.05625/ P (证据)*'
- en: So from the results, you can see that if the fruit is sweet, not long, and not
    yellow, then the highest probability is that it will be an apple. So find out
    the highest probability and assign the unknown item to that class.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，从结果中，你可以看到如果水果是甜的、不长的、不是黄色的，那么最高的概率是它将是一个苹果。所以找出最高的概率，并将未知项分配到那个类别。
- en: Naïve Bayes is a very good choice for text classification. Before we move on
    to text classification using Naïve Bayes in Mahout, let's understand a few terms
    that are really useful for text classification.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: Naïve Bayes 是文本分类的一个非常好的选择。在我们继续在 Mahout 中使用 Naïve Bayes 进行文本分类之前，让我们了解一些对文本分类非常有用的术语。
- en: Understanding the terms used in text classification
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解文本分类中使用的术语
- en: To prepare data so that it can be used by a classifier is a complex process.
    From raw data, we can collect explanatory and target variables and encode them
    as **vectors**, which is the input of the classifier.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 准备数据以便它可以被分类器使用是一个复杂的过程。从原始数据中，我们可以收集解释变量和目标变量并将它们编码为 **向量**，这是分类器的输入。
- en: Vectors are ordered lists of values as defined in two-dimensional space. You
    can take a clue from coordinate geometry as well. A point (3, 4) is a point in
    the x and y planes. In Mahout, it is different. Here, a vector can have (3, 4)
    or 10,000 dimensions.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 向量是有序的值列表，如定义在二维空间中。你也可以从坐标几何中得到线索。点 (3, 4) 是 x 和 y 平面上的一个点。在 Mahout 中，情况不同。在这里，一个向量可以有
    (3, 4) 或 10,000 个维度。
- en: 'Mahout provides support for creating vectors. There are two types of vector
    implementations in Mahout: sparse and dense vectors. There are a few terms that
    we need to understand for text classification:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: Mahout 提供了创建向量的支持。在 Mahout 中有两种类型的向量实现：稀疏向量和密集向量。对于文本分类，我们需要了解一些术语：
- en: '**Bag of words**: This considers each document as a collection of words. This
    ignores word order, grammar, and punctuation. So, if every word is a feature,
    then calculating the feature value of the document word is represented as a token.
    It is given the value 1 if it is present or 0 if not.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**词袋模型**：这把每个文档视为单词的集合。它忽略了单词顺序、语法和标点符号。因此，如果每个单词都是一个特征，那么计算文档单词的特征值就表示为一个标记。如果存在，则赋予其值
    1，如果不存在，则赋予其值 0。'
- en: '**Term frequency**: This considers the word count in the document instead of
    0 and 1\. So the importance of a word increases with the number of times it appears
    in the document. Consider the following example sentence:'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**词频**：这考虑了文档中的单词计数而不是 0 和 1。因此，单词的重要性随着它在文档中出现的次数而增加。考虑以下示例句子：'
- en: Apple has launched iPhone and it will continue to launch such products. Other
    competitors are also planning to launch products similar to that of iPhone.
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 苹果已经推出了 iPhone，它将继续推出类似的产品。其他竞争对手也在计划推出类似 iPhone 的产品。
- en: 'The following is the table that represents term frequency:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 以下表示词频的表格：
- en: '| Term | Count |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| 术语 | 数量 |'
- en: '| --- | --- |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Apple | 1 |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| Apple | 1 |'
- en: '| Launch | 3 |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| 启动 | 3 |'
- en: '| iPhone | 2 |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| iPhone | 2 |'
- en: '| Product | 2 |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| 产品 | 2 |'
- en: '| Plan | 1 |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| 计划 | 1 |'
- en: 'The following techniques are usually applied to come up with this type of table:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 以下技术通常用于生成此类表格：
- en: '**Stemming of words**: With this, the suffix is removed from the word so "launched",
    "launches", and "launch" are all considered as "launch".'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**词干提取**：这样，从单词中移除了后缀，所以"launched"、"launches"和"launch"都被视为"launch"。'
- en: '**Case normalization**: With this, every term is converted to lowercase.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**案例归一化**：这样，每个术语都被转换为小写。'
- en: '**Stop word removal**: There are some words that are almost present in every
    document. We call these words stop words. During an important feature extraction
    from a document, these words come into account and they will not be helpful in
    the overall calculation. Examples of these words are "is, are, the, that, and
    so on." So, while extracting, we will ignore these kind of words.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**停用词去除**：有一些词几乎出现在每个文档中。我们称这些词为停用词。在从文档中提取重要特征时，这些词会被考虑，但它们对整体计算没有帮助。这些词的例子有"是、有、这、那个、等等"。所以，在提取时，我们将忽略这类词。'
- en: '**Inverse document frequency**: This is considered as the boost a term gets
    for being rare. A term should not be too common. If a term occurs in every document,
    it is not good for classification. The fewer documents in which a term occurs,
    the more significant it is likely to be for the documents it does occur in. For
    a term t, inverse document frequency is calculated as follows:'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**逆文档频率**：这被认为是术语因罕见而获得的提升。一个术语不应该太常见。如果一个术语出现在每个文档中，它对分类并不好。一个术语出现在的文档越少，它对其出现的文档的重要性可能就越大。对于一个术语t，逆文档频率的计算如下：'
- en: '*IDF (t) = 1 + log* (total number of documents/ number of documents containing
    t)'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*IDF(t) = 1 + log(总文档数/包含t的文档数)*'
- en: '**Term frequency and inverse term frequency**: This is one of the popular representations
    of the text. It is the product of term frequency and inverse document frequency,
    as follows:'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**词频和逆文档频率**：这是文本的流行表示之一。它是词频和逆文档频率的乘积，如下所示：'
- en: '*TFIDF (t, d) = TF (t, d) * IDF (t)*'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*TFIDF(t, d) = TF(t, d) * IDF(t)*'
- en: Each document is a feature vector and a collection of documents is a set of
    these feature vectors and this set works as the input for the classification.
    Now that we understand the basic concepts behind the vector creation of text documents,
    let's move on to the next section where we will classify text documents using
    the Naïve Bayes algorithm.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 每个文档都是一个特征向量，文档的集合是一组这些特征向量，这组向量作为分类的输入。现在我们已经了解了文本文档向量创建的基本概念，让我们继续到下一节，我们将使用朴素贝叶斯算法对文本文档进行分类。
- en: Using the Naïve Bayes algorithm in Apache Mahout
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Apache Mahout中使用朴素贝叶斯算法
- en: We will use a dataset of 20 newsgroups for this exercise. The 20 newsgroups
    dataset is a standard dataset commonly used for machine learning research. The
    data is obtained from transcripts of several months of postings made in 20 Usenet
    newsgroups from the early 1990s. This dataset consists of messages, one per file.
    Each file begins with header lines that specify things such as who sent the message,
    how long it is, what kind of software was used, and the subject. A blank line
    follows and then the message body follows as unformatted text.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用20个新闻组的数据集来完成这个练习。20个新闻组数据集是一个标准数据集，通常用于机器学习研究。数据来自20个Usenet新闻组在20世纪90年代初发布的几个月的帖子记录。这个数据集由消息组成，每个文件一个消息。每个文件以标题行开始，指定了诸如谁发送了消息、消息有多长、使用了什么软件以及主题等信息。随后是一个空行，然后是消息体，作为未格式化的文本。
- en: 'Download the `20news-bydate.tar.gz` dataset from [http://qwone.com/~jason/20Newsgroups/](http://qwone.com/~jason/20Newsgroups/).
    The following steps are used to build the Naïve Bayes classifier using Mahout:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 从[http://qwone.com/~jason/20Newsgroups/](http://qwone.com/~jason/20Newsgroups/)下载`20news-bydate.tar.gz`数据集。以下步骤用于使用Mahout构建朴素贝叶斯分类器：
- en: 'Create a `20newsdata` directory and unzip the data here:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个`20newsdata`目录并将数据解压到这里：
- en: '[PRE0]'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'You will see two folders under `20newsdata: 20news-bydate-test` and `20news-bydate-train`.
    Now create another directory called `20newsdataall` and merge both the training
    and test data of the 20 newsgroups.'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '在`20newsdata: 20news-bydate-test`和`20news-bydate-train`下你会看到两个文件夹。现在创建另一个名为`20newsdataall`的目录，并将20个新闻组的训练数据和测试数据合并。'
- en: 'Come out of the directory and move to the `home` directory and execute the
    following:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 退出目录并移动到`home`目录，然后执行以下操作：
- en: '[PRE1]'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Create a directory in Hadoop and save this data in HDFS format:'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Hadoop中创建一个目录并将这些数据以HDFS格式保存：
- en: '[PRE2]'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Convert the raw data into a sequence file. The `seqdirectory` command will
    generate sequence files from a directory. Sequence files are used in Hadoop. A
    sequence file is a flat file that consists of binary key/value pairs. We are converting
    the files into sequence files so that it can be processed in Hadoop, which can
    be done using the following command:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将原始数据转换为序列文件。`seqdirectory`命令将从目录生成序列文件。序列文件用于Hadoop。序列文件是一个由二进制键/值对组成的平面文件。我们将文件转换为序列文件，以便在Hadoop中处理，可以使用以下命令完成：
- en: '[PRE3]'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The output of the preceding command can be seen in the following screenshot:'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下截图显示了前一个命令的输出：
- en: '![Using the Naïve Bayes algorithm in Apache Mahout](img/4959OS_04_06.jpg)'
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![在Apache Mahout中使用Naïve Bayes算法](img/4959OS_04_06.jpg)'
- en: 'Convert the sequence file into a sparse vector using the following command:'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令将序列文件转换为稀疏向量：
- en: '[PRE4]'
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The terms used in the preceding command are as follows:'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 前一个命令中使用的术语如下：
- en: '`lnorm`: This is for the output vector to be log normalized'
  id: totrans-118
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lnorm`：这表示输出向量要进行对数归一化'
- en: '`nv`: This refers to named vectors'
  id: totrans-119
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nv`：这指的是命名向量'
- en: '`wt`: This refers to the kind of weight to use; here, we use `tfidf`'
  id: totrans-120
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wt`：这指的是要使用的权重类型；在这里，我们使用`tfidf`'
- en: 'The output of the preceding command on the console is shown in the following
    screenshot:'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下截图显示了在控制台上执行前一个命令的输出：
- en: '![Using the Naïve Bayes algorithm in Apache Mahout](img/4959OS_04_07.jpg)'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![在Apache Mahout中使用Naïve Bayes算法](img/4959OS_04_07.jpg)'
- en: 'Split the set of vectors to train and test the model:'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将向量集分为训练集和测试集：
- en: '[PRE5]'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The terms used in the preceding command are as follows:'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 前一个命令中使用的术语如下：
- en: '`randomSelectionPct`: This divides the percentage of data into testing and
    training datasets. Here, 60 percent is for testing and 40 percent for training.'
  id: totrans-126
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`randomSelectionPct`：这会将数据百分比分为测试集和训练集。在这里，60%用于测试，40%用于训练。'
- en: '`xm`: This refers to the execution method to use: sequential or mapreduce.
    The default is `mapreduce`.'
  id: totrans-127
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xm`：这指的是要使用的执行方法：顺序或mapreduce。默认为`mapreduce`。'
- en: '![Using the Naïve Bayes algorithm in Apache Mahout](img/4959OS_04_08.jpg)'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![在Apache Mahout中使用Naïve Bayes算法](img/4959OS_04_08.jpg)'
- en: 'Now train the model:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在训练模型：
- en: '[PRE6]'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Test the model using the following command:'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令测试模型：
- en: '[PRE7]'
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The output of the preceding command on the console is shown in the following
    screenshot:'
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下截图显示了在控制台上执行前一个命令的输出：
- en: '![Using the Naïve Bayes algorithm in Apache Mahout](img/4959OS_04_09.jpg)'
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![在Apache Mahout中使用Naïve Bayes算法](img/4959OS_04_09.jpg)'
- en: We get the result of our Naïve Bayes classifier for the 20 newsgroups.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到了针对20个新闻组的Naïve Bayes分类器的结果。
- en: Summary
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we discussed the Naïve Bayes algorithm. This algorithm is a
    simplistic yet highly regarded statistical model that is widely used in both industry
    and academia, and it produces good results on many occasions. We initially discussed
    conditional probability and the Bayes rule. We then saw an example of the Naïve
    Bayes algorithm. You learned about the approaches to convert text into a vector
    format, which is an input for classifiers. Finally, we used the 20 newsgroups
    dataset to build a classifier using the Naïve Bayes algorithm in Mahout. In the
    next chapter, we will continue our journey of exploring classification algorithms
    in Mahout with the Hidden Markov model implementation.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了Naïve Bayes算法。这是一种简单但备受推崇的统计模型，在工业和学术界都得到了广泛应用，并且在许多场合都产生了良好的结果。我们最初讨论了条件概率和贝叶斯定理。然后，我们看到了Naïve
    Bayes算法的一个示例。你学习了将文本转换为向量格式的各种方法，这是分类器的输入。最后，我们使用20个新闻组数据集，在Mahout中使用Naïve Bayes算法构建了一个分类器。在下一章中，我们将继续探索在Mahout中使用隐马尔可夫模型实现分类算法的旅程。
