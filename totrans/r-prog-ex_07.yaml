- en: Developing Automatic Presentations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Have you ever found yourself doing the same mechanical task over and over again?
    It's surprising how many programmers, statisticians, and scientists, in general,
    do not invest time to automate many of their activities, especially reporting
    results. Doing so would allow them to focus deeper on their core competencies.
    Furthermore, this is not unique to individuals; organizations at large still do
    not automate many of their processes, especially analytical ones. Remember the
    graph creation automation we performed in [Chapter 2](part0059.html#1O8H60-f494c932c729429fb734ce52cafce730),
    *Understanding Votes with Descriptive Statistics*, or the regressions automation
    we performed in [Chapter 3](part0076.html#28FAO0-f494c932c729429fb734ce52cafce730),
    *Predicting Votes with Linear Models*? In this chapter, we will show you how to
    automate another activity—developing presentations. By this, we don't mean to
    automate the explanations behind the results, but automate the creation of slides
    that show tables and graphs of the *current status* of a process. This a very
    high benefit/cost area that is often overlooked, and a lot of time is wasted producing
    such presentations for discussion among peers.
  prefs: []
  type: TYPE_NORMAL
- en: This is the last chapter for The Food Factory example, and here, we will automate
    an activity that people in many organizations find themselves doing over and over
    again—developing presentations for weekly updates. We will show what a content
    automation pipeline looks like in R and build a presentation that can be updated
    automatically with the latest data. To do so, we will use the results we have
    developed during the previous chapters in this example.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some of the important topics covered in this chapter are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The importance and benefits of automation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Setting up and running automation pipelines
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Communicating ideas with literate programming
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Writing static content using Markdown
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Developing dynamic content using R Markdown
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Producing presentation and web pages using knitr
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Integrating R resources efficiently
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Required packages
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are only two required packages for this chapter and you should be able
    to install them without a problem in your system. For more information take a
    look at [Appendix](part0296.html#8Q96G0-f494c932c729429fb734ce52cafce730)*, Required
    Packages*.
  prefs: []
  type: TYPE_NORMAL
- en: '| **Package** | Reason |'
  prefs: []
  type: TYPE_TB
- en: '| `ggrepel` | Avoid overlapping labels in graphs |'
  prefs: []
  type: TYPE_TB
- en: '| `rmarkdown` | Markdown documents with executable R code |'
  prefs: []
  type: TYPE_TB
- en: Why invest in automation?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Automation is an investment. It often involves taking different applications
    and integrating them to make processes happen repeatedly, hopefully seamlessly
    and effortlessly. Process automation can increase productivity by reducing the
    time taken to perform repetitive tasks, as well as reduce defects, which also
    saves time and enhances the value-creation process.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, automated systems do not get bored. It's likely that anyone who
    has to undertake a repetitive task over and over again will get bored. This will
    slow down their performance and increase the risk of defects. An automated process
    will not get bored, no matter how often it is run, so performance is not likely
    to be slowed down.
  prefs: []
  type: TYPE_NORMAL
- en: 'Scientists can leverage automation to reduce cycle time through scientific
    methods, which in turn increases learning rates, often exponentially. In my opinion,
    this is one of the most powerful consequences of automation: accelerating learning
    processes by removing us (humans) from activities to which we do not add value,
    and allowing us to focus on activities that (so far) cannot be automated, such
    as being creative or developing innovative solutions to valuable problems.'
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, people often complain about not having enough time. One effective way
    to get time back is to automate processes, and that's the ultimate benefit of
    automation—making more of your time.
  prefs: []
  type: TYPE_NORMAL
- en: Literate programming as a content creation methodology
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Automation requires us to put different pieces together in such a way that the
    process is clear for both humans and machines. The process must be reproducible
    and capable of evolving as new ideas come to us or requirements change. Automating
    content creation can be achieved with literate programming, which comes from Donald
    Knuth's *Literate Programming, 1992* ([http://www-cs-faculty.stanford.edu/~knuth/lp.html](http://www-cs-faculty.stanford.edu/~knuth/lp.html)).
    The basic idea is that a document is viewed as a combination of text and code.
    Code is divided into chunks with text surrounding the code chunks explaining what
    is going on. Text adapts as necessary to keep the ideas behind the code updated,
    clear, and accurate.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we use the words *presentation* and *document* interchangeably
    as you can create both of them with the tools we will show.
  prefs: []
  type: TYPE_NORMAL
- en: Literate programming is not a requisite for automating content creation, but
    it certainly is a great tool for it. Literate programming has the advantages of
    being easily readable, just as a manual or instruction set. Also, it allows for
    where code and natural language need to be combined. Results can be automatically
    shown as we go through the document. The document itself is simple text, which
    makes it flexible and easy to change. In general, literate programs are *weaved*
    to produce human-readable documents and *tangled* to produce machine-readable
    documents. To make this work, we only need a documentation language and a programming
    language, which are English and R in our case.
  prefs: []
  type: TYPE_NORMAL
- en: Literate programming seems to have the potential to make many tools obsolete
    that are currently being used to produce content. However, there are still better
    tools available if you need to produce documents with very accurate formatting
    or that require highly technical optimizations. This is not due to any inherent
    weaknesses in the concept of literate programming, but due to the fact that available
    tools are not as performant as specialized tools in those aspects.
  prefs: []
  type: TYPE_NORMAL
- en: When it comes to literate programming, R strikes a nice balance between technical
    complexity and simple presentations, allowing for a wide range of content automation
    to be developed, and this can produce documents that can serve very well for research
    and data analysis in general. If at some point you find that you need to make
    a change, you can easily do so, recompile, and you'll be looking at the latest
    version in a matter of seconds. That's why it's very handy to develop automated
    presentations the way we will show you in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Reproducibility as a benefit of literate programming
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In science, reproducibility is the most important element of verifying and validating
    analysis findings. The analyses, models, and algorithms we run are much more complicated
    than they used to be. Having a basic understanding of these algorithms is difficult,
    even for a sophisticated person, and it's almost impossible to describe with words
    alone. Understanding what someone did nowadays requires looking at data and code
    directly, not only at results.
  prefs: []
  type: TYPE_NORMAL
- en: Scientists write a lot of reports describing the results of data analyses. Making
    those reports reproducible is essential to have your work reviewed by your peers,
    and it is a very good way to accomplish this with literate programming. With it,
    the final report depends on code that is executed at the moment of its creation,
    and thus, reproducibility is embedded in the process. There's a clear and automatic
    path from data and code to the final report.
  prefs: []
  type: TYPE_NORMAL
- en: Literate programming for data analysis has become quite popular due to the development
    and communication efficiency it provides. In the following sections, we will show,
    how to do it using R, R Markdown, and knitr.
  prefs: []
  type: TYPE_NORMAL
- en: The basic tools for an automation pipeline
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A pipeline is a process that starts with text, code, and raw data, and ends
    with the final document or presentation we want to show or distribute. Luckily,
    much of the hard work is automated for you within R, so there's not much you need
    to do other than install these tools and set up a compilation file.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00054.gif)'
  prefs: []
  type: TYPE_IMG
- en: Our pipeline should be general enough to accommodate various use cases without
    having to be modified substantially. If it is, we can master one set of tools
    and reuse them for different projects rather than learning a new tool set each
    time. On the input side, using text, code, and data, is general enough. On the
    output side, being able to generate HTML, PDF, LaTeX, and even Word documents
    seems to be general enough so we are good to go.
  prefs: []
  type: TYPE_NORMAL
- en: Markdown is a low-overhead mark-up language ([http://spec.commonmark.org/0.28/](http://spec.commonmark.org/0.28/)).
    Its main benefit for writers is that it allows us to focus on writing as opposed
    to formatting. It has simple and minimal yet intuitive formatting elements, and
    there are many programs that can translate Markdown into HTML and PDF files, among
    many others. R Markdown is an extension of Markdown to incorporate R code ([http://rmarkdown.rstudio.com/](http://rmarkdown.rstudio.com/)).
    Documents written in R Markdown have R code nested inside, which allows us to
    create dynamic presentations. They can not be evaluated using standard Markdown
    tools. Instead, R code is evaluated as part of the processing of the R Markdown
    before the traditional Markdown tools are called.
  prefs: []
  type: TYPE_NORMAL
- en: One of the first literate programming systems in R is **Sweave**, which is used
    for creating dynamic reports and reproducible research using **LaTeX** ([https://www.latex-project.org/](https://www.latex-project.org/)).
    Sweave enables the embedding of R code within LaTeX documents to generate a PDF
    file that includes text, analysis, graphics, code, and the computation results.
    knitr (with first letter lowercase) is an R package that adds many new capabilities
    to Sweave ([https://yihui.name/knitr/](https://yihui.name/knitr/)).
  prefs: []
  type: TYPE_NORMAL
- en: R Markdown can be converted to standard markdown using the knitr package in
    R, which inserts R results into a Markdown document. Markdown can subsequently
    be converted to HTML using Pandoc (a very powerful document translator, [https://pandoc.org/](https://pandoc.org/)).
    The use of R Markdown to create reproducible reports has quickly become a core
    tool for many scientists.
  prefs: []
  type: TYPE_NORMAL
- en: We won't go into details of how Sweave, LaTeX, or Pandoc transform files among
    different formats, since you won't have to operate them directly. We will focus
    on using R Markdown and knitr. However, we still need to make sure that we have
    all these tools installed in our system before we continue. Sweave is shipped
    within any R distribution. R Markdown and knitr can be installed within R. Pandoc
    and LaTeX should be installed directly into your computer. Specific instructions
    for Windows, macOS, and Linux can be found in [Appendix](part0296.html#8Q96G0-f494c932c729429fb734ce52cafce730),
    *Required Packages*.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, you should note that these are not the only tools available to produce
    automated content. As literate programming for R has become a topic of high interest,
    naturally, many tools have been, and continue to be, developed for it. Even though
    this chapter focuses on R Markdown and knitr, there are other tools such as **R
    Studio's Presenter** (**RPres**) and **Slidify**. We have not shown this tools
    in this book because they are either more restricted in their application or more
    complex in their usage. We believe that the R Markdown-knitr combination strikes
    a very good balance between power and ease of use, and it's our combination of
    choice. However, we encourage the reader to research other tools and find the
    best fit.
  prefs: []
  type: TYPE_NORMAL
- en: A gentle introduction to Markdown
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Markdown has various syntax versions that are supported by different systems
    and platforms. The one we show here is a general one that is useful throughout
    many systems, including R Markdown.
  prefs: []
  type: TYPE_NORMAL
- en: What we show in the following examples are the basic elements to structure content
    using Markdown. The actual aesthetics depend on what styles are being applied
    to your files. The examples shown as follows don't have any aesthetics applied
    to them. We will show you how to adjust them for our presentation later in the
    chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Text
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you want simple text, you can simply write as you normally would. If you
    want to format the text, you can use pairs of asterisks (`*`) or underscores (`_`).
    The following table shows how to use pairs of asterisks. Underscores work the
    same way.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we use the following input:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'We get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: Text with *italic* text inside.
  prefs: []
  type: TYPE_NORMAL
- en: Text with **bold** text inside.
  prefs: []
  type: TYPE_NORMAL
- en: Text with ***bold and italic text***.
  prefs: []
  type: TYPE_NORMAL
- en: Headers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you want, you can have the equivalent to sections (first-level headers),
    subsections (second-level headers), sub-subsections (third-level headers), and
    so on. The organizational structures are marked using a number sign, repeated
    as many times as the depth you want to produce in the document. A string like
    `# Header` would produce a first-level header, while `### Header` would create
    a third-level header.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we use the following input:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'We get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: Header Level  1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Header Level  2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Header Level  3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Header Level  4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Lists
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Lists can be ordered, unordered, and can be marked as tasks. These cover most
    cases you'll need, and they are very simple to use. For ordered lists, you can
    use hyphens (-) or asterisks (*), and you can nest them to create nested lists.
    For ordered lists, you can use numbers and letters. Finally, to create task lists,
    you simply need to put a pair of brackets at the beginning of an item ([]). If
    the brackets contain an X, then it means that the task has been completed. If
    the brackets have a space in between them, then the item is still pending.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we use the following input:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Output
  prefs: []
  type: TYPE_NORMAL
- en: This is an ordered item
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This is an unordered item
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: This is another unordered item
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: This is another ordered item
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[ ] This is a pending task'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[X] This is a completed task'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ ] This is another incomplete task'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Which contains one ordered item
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: And one unordered item
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Tables
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Tables are one of the most cumbersome structures to create when using Markdown.
    Having said that, it's still not hard to create them. If you align them, everything
    looks normal. However, most of the time, people don't align them, and they seem
    a bit odd if you're not used to the syntax. By non-aligned tables, we mean that
    there are no padding spaces after items so that vertical lines align. The table
    shown as follows is an aligned table.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we use the following input:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'We get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **First column** | **Second column** | **Third column** |'
  prefs: []
  type: TYPE_TB
- en: '| Item one | Item two | Item three |'
  prefs: []
  type: TYPE_TB
- en: '| Item four | Item five | Item six |'
  prefs: []
  type: TYPE_TB
- en: '| Item seven | Item eight | Item nine |'
  prefs: []
  type: TYPE_TB
- en: Links
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To provide links, you can simply write the link directly. If you want to name
    links so that only the name shows but not the URL, like the ones you see in web
    pages, you can use brackets containing the name followed immediately by parenthesis
    containing the actual link , in the format "[Name](URL)".
  prefs: []
  type: TYPE_NORMAL
- en: 'If we use the following input:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'We get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[The R Project for Statistical Computing](https://www.r-project.org/)'
  prefs: []
  type: TYPE_NORMAL
- en: '[Packt Publishing](https://www.packtpub.com/)'
  prefs: []
  type: TYPE_NORMAL
- en: Images
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Images have a similar structure to links, but they are preceded by an exclamation
    mark (!). The name for the image (what is contained inside the brackets) is only
    shown if the actual image was not (for example, the file was not found in the
    specified route). The URL is replaced by the path to the image you want to show.
    By default, an image's size will be as large as possible. Under the assumption
    that the images are within a directory named images in the same directory as the
    Markdown file is, the following example works.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we use the following input:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'We get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00055.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Quotes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Quotes are very useful when trying to emphasize points to the readers. They
    are also very easy to create. All you have to do is prepend a greater-than sign
    (>) followed by a space at the beginning of a line.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we use the following input:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'We get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: Look deep into nature, and then you will understand everything better.
  prefs: []
  type: TYPE_NORMAL
- en: '- Albert Einstein'
  prefs: []
  type: TYPE_NORMAL
- en: Code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Code can be embedded within text using single backticks (`` ` ``) surrounding
    it, or can be used in independent blocks by using triple backticks ([PRE7] [PRE8]
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: add_two_numbers <- function(x, y) {
  prefs: []
  type: TYPE_NORMAL
- en: return(x + y)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '}'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: $$\Theta = \begin{pmatrix} \alpha & \beta \\ \gamma & \delta \end{pmatrix}$$
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]` [PRE13]`), knitr knows that it''s an R code block which will be identified
    with the `chunk-label` label. The chunk label is not a requirement, and if you
    do not specify one, one will be automatically created for you, but they are useful
    when trying to remember the purpose of a code block and to reference images (more
    on this later).'
  prefs: []
  type: TYPE_NORMAL
- en: Finally, you should note that whatever code you write inside a standard Markdown
    code block is not executed in any way, so it can be full of errors and nothing
    will happen. However, when using R Markdown code chunks, the code within an R
    block is actually evaluated when compiling the document, and if it contains errors,
    the document or presentation will not compile successfully until you fix them.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we use the following input:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]{r optional-label}'
  prefs: []
  type: TYPE_NORMAL
- en: 1 + 2
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'We get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Tables
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In informal reports, you may just print out a matrix or data frame rather than
    creating a formal table. If you need to, there are multiple ways to make tables
    with R Markdown that may look a bit nicer. We show how to use `kable` from the
    `knitr` package, as it's the simplest one. If you need more control, you may look
    at the `xtable` package, which gives you complete control. You need to be sure
    to use `results = "asis"` in the code chunk.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we use the following input:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]{r r-markdown-label, results = "asis"}'
  prefs: []
  type: TYPE_NORMAL
- en: library(knitr)
  prefs: []
  type: TYPE_NORMAL
- en: x <- rnorm(100)
  prefs: []
  type: TYPE_NORMAL
- en: y <- 2 * x + rnorm(100)
  prefs: []
  type: TYPE_NORMAL
- en: coeficients <- summary(lm(y ~ x))$coef
  prefs: []
  type: TYPE_NORMAL
- en: kable(coeficients, digits = 2)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'We get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | **Estimate** | **Std. error** | **t value** | **Pr(>&#124;t&#124;)** |'
  prefs: []
  type: TYPE_TB
- en: '| (Intercept) | 0.02 | 0.10 | 0.21 | 0.83 |'
  prefs: []
  type: TYPE_TB
- en: '| `x` | 2.09 | 0.09 | 22.98 | 0.00 |'
  prefs: []
  type: TYPE_TB
- en: Graphs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Creating graphs with R Markdown is as easy as creating the within R. Actually,
    you don't need to do anything extra; knitr is smart enough to do it automatically.
    If you need to, specify the width and height for your image using the corresponding
    chunk options shown in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we use the following input:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]{r basic-r-graph}'
  prefs: []
  type: TYPE_NORMAL
- en: attach(mtcars)
  prefs: []
  type: TYPE_NORMAL
- en: plot(wt, mpg)
  prefs: []
  type: TYPE_NORMAL
- en: abline(lm(mpg ~ wt))
  prefs: []
  type: TYPE_NORMAL
- en: title("Regression of MPG on Weight")
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'We get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00057.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Chunk options
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When working with chunks we have a lot of flexibility, and this flexibility
    can be seen by the many options we may adjust. Here, we will only mention the
    most common ones. To avoid including the code as output, use `echo = FALSE`. To
    avoid showing the results, use `include = FALSE`. To avoid evaluating the code
    block, use `eval = FALSE`. To avoid showing warnings, use `warning = FALSE`. To
    set the figure width and height, use `fig.height = 10` and `fig.width = 10` with
    the actual numbers you want (units are inches by default). All of these can be
    used in the code chunk header shown as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]{r some-label, include = TRUE, eval = FALSE}'
  prefs: []
  type: TYPE_NORMAL
- en: 1 + 2
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Global chunk options
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You may use global chunk options rather than repeated local chunk options.
    Whenever you need to, you can override a global chunk option by specifying a different
    local chunk option. Using the following code would make every code chunk have
    the `echo = TRUE` and `eval = FALSE` options enabled, unless otherwise specified
    at specific blocks:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]{r global-options}'
  prefs: []
  type: TYPE_NORMAL
- en: knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Caching
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we mentioned earlier, knitr is not so useful if you are writing a very long
    document or one involving complex computations. However, you may avoid some of
    these problems by using caches. The basic issue is that if you have a long document
    or one involving lengthy computations, then every time you want to *refresh* your
    document, you need to recompile it, meaning that you need to rerun all the computations.
    This may not be a problem if your document is efficient or small. However, it
    can be inefficient to sit there and wait for every computation to run every single
    time. Chunk caching is one way to avoid those lengthy computations. By setting
    the `cache = TRUE` chunk option, knitr runs the chunk once and stores the output
    in your working directory. When you *reknit* the document, instead of running
    the code in that particular chunk, knitr will reload the stored output. If the
    code in the chunk changes at all, knitr will detect it and will rerun the code,
    storing the updated results.
  prefs: []
  type: TYPE_NORMAL
- en: There are some caveats to caching. In particular, by default, dependencies between
    chunks are not checked. If the results of a cached chunk depend on a previous
    chunk that has been modified, those changes will not necessarily propagate down
    to later cached chunks. Also, chunks with significant side effects, such as those
    writing output to files or interacting with the external environment in any way,
    may not be cacheable. As long as you are careful with these, you should not have
    any issues.
  prefs: []
  type: TYPE_NORMAL
- en: Producing the final output with knitr
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Once you have a finished document or are ready to see its next iteration, you
    may compile within R Studio if you''re using it or by executing the code that
    triggers the compilation. We will show the latter since it''s more general and
    can be used by people who are not necessarily using R Studio. You simply need
    to execute the following lines, changing the filename `"document.Rmd"` with your
    own, and choosing the appropriate output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: We suggest that you create a `compile.R` file that contains those line, and
    execute it every time you want to recompile your document. The following outputs
    are available:.
  prefs: []
  type: TYPE_NORMAL
- en: '| **String** | **Output** |'
  prefs: []
  type: TYPE_TB
- en: '| `html_document` | HTML document |'
  prefs: []
  type: TYPE_TB
- en: '| `pdf_document` | PDF document |'
  prefs: []
  type: TYPE_TB
- en: '| `word_document` | Word document |'
  prefs: []
  type: TYPE_TB
- en: '| `10slides_presentation` | HTML presentation, type 1 |'
  prefs: []
  type: TYPE_TB
- en: '| `slidy_presentation` | HTML presentation, type 2 |'
  prefs: []
  type: TYPE_TB
- en: '| `beamer_presentation` | Beamer (LaTex) PDF presentation |'
  prefs: []
  type: TYPE_TB
- en: At this point, you should be able to create your own presentations. In the following
    sections, we will start building the presentation we want to actually develop
    for The Food Factory example.
  prefs: []
  type: TYPE_NORMAL
- en: Developing graphs and analysis as we normally would
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As you saw in previous sections, you can work directly with our R Markdown file
    for the presentation (`presentation.Rmd`, in our case). However, you can be more
    productive if you first develop the content for the presentation as you would
    normally work with R, taking advantage of any configurations and tooling you may
    be accustomed to. When the code has been finalized, you translate only the necessary
    parts into the R Markdown file. Even though it seems counter intuitive because
    it would be more work, it's actually faster to work this way just because you're
    used to working with R more than with R Markdown, and you'll think about producing
    modular code that can be plugged into your presentation. This allows your to produce
    higher quality and reusable code. That's exactly what we will do here. We will
    start working with our usual `main.R` and `functions.R` files to develop what
    we need. Then, in a later section, we will migrate the code into our `presentation.Rmd`
    file.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since we want to present the analysis we have developed during the last couple
    of chapters and we shouldn''t rewrite code, we will bring some of it back from
    [Chapter 4](part0091.html#2MP360-f494c932c729429fb734ce52cafce730), *Simulating
    Sales Data and Working with Databases*, as well as the data that we simulated
    for **The Food Factory**:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that using the `source()` function, as we did, loads into memory all of
    the functions we have in the functions file from [Chapter 5](part0110.html#38STS0-f494c932c729429fb734ce52cafce730),
    *Communicating Sales with Visualization*. This may or may not be what you actually
    need, and if you''re not careful, you may end up overwriting a function definition
    when doing so. In this particular case, it''s not a problem, so we''ll leave it
    as is. If it were a problem, we could always move the desired function into its
    own file and just `source` that file. The function we are interested in is the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Let's suppose that a long time has passed since you first simulated the data.
    If you execute a function call like `filter_n_days_back(data, 7)`, you are not
    guaranteed to have the data for the previous week, and you'll most likely get
    an empty result due to `n_days_back <- Sys.Date() - n` containing  data of 7 days
    back from `today`, not the last date recorded in the data. That's a problem.
  prefs: []
  type: TYPE_NORMAL
- en: 'How to deal with situations like these can take you down a long debate with
    your peers. In general, we have two options: rewrite an independent function,
    or fix the code we already have. The right answer will depend on your specific
    circumstances and context, and both of them have their advantages and disadvantages.
    In general, when you write a new function, you''ll be certain that your code works
    and that you didn''t accidentally break someone else''s code, which depended on
    the previous version. The disadvantage is that you''ll have to maintain more code
    without gaining much functionality, and over time, this can be a huge pain. Remember
    the DRY principle we mentioned before? **Don''t Repeat Yourself** (**DRY**). If
    you decide to fix the current version of the code, you will possibly end up with
    a more robust code base that you can reuse for even more cases that you initially
    anticipated without increasing too much (sometimes decreasing) the code you need
    to maintain. However, there''s also the possibility that you break code that depended
    on the previous functionality, which can be very tricky to fix down the road when
    you realize that you did.'
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two basic fundamentals that will save you from strong headaches when
    dealing with these types of situations. We have been using one of them throughout
    this book: developing small and modular code. By small, we mean code that follows
    the *Single Responsibility* principle, mentioned in [Chapter 1](part0022.html#KVCC0-f494c932c729429fb734ce52cafce730),
    *Introduction to R*. When you do, something magical happens; you start plugging
    in code to other code and you can easily modify those plugins and create new ones
    as you need them without too much trouble. The other fundamental is having unit
    tests for your code. Simply put, unit tests are pieces of code designed to test
    that other code is performing as it should. Unit testing is out of the scope for
    this book, but it''s something you should definitely study if you don''t already
    know.'
  prefs: []
  type: TYPE_NORMAL
- en: Going back to the code for this specific example, we choose to fix the code
    we already have. For us to make sure that we don't accidentally break other code
    that depends on this function, we follow the *Open-Closed* principle, which states
    that objects should be open for extensions and closed for modification ([https://www.cs.duke.edu/courses/fall07/cps108/papers/ocp.pdf](https://www.cs.duke.edu/courses/fall07/cps108/papers/ocp.pdf)).
  prefs: []
  type: TYPE_NORMAL
- en: 'Basically, we will extend the interface without modifying it in such a way
    that the output is the same when using the same previous inputs, but the extended
    version will allow us to get the new outputs we want. It sounds more cumbersome
    than it really is. As you can see, we simply add a new optional parameter with
    a default value of `NULL`. Then, instead of computing `n_days_back` with the current
    date, we check to see if any value was sent; if it was, then we use that as the
    starting point; if not, we go back to the old behavior:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Now that we have this new version of the function, we can actually use it to
    take the last week in the data by computing the maximum date we have recorded
    in it, and using that as our `from_date` parameter. Also, note how easy it is
    to take not only the data for this week, but also from last week. However, for
    this to work, we need to make sure that the `max_date` object is a `Date` object
    in R, so that we can subtract 7 from it, and it actually means 7 days. If it's
    a string instead of a date, we would get an error.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a side note, note that if were using data that is constantly being recorded,
    *this week* and *last week* would make perfect sense, but since we''re using data
    we simulated possibly a long time ago, *this week* and *last week* will vary depending
    on the dates in the actual data we''re using. That''s not a problem because we''re
    using the *maximum* date in the data, which will be adjusted accordingly for each
    situation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have the three datasets we need (`all_time`, `last_week`, and `this_week`),
    we can start developing the code that will use them to create the graphs we''re
    looking for. First, we need to get proportion tables for each variable of interest
    and for each dataset. As always, we want to wrap code that is not very explicit
    about its functionality into its own function so that we can assign a name to
    it and quickly know what it''s supposed to do. In this case, we create the `proportion_table()`
    function, which should be self-explanatory, and we apply it as mentioned. Note
    that we''re multiplying by `100`, because we want to show `20%` instead of `0.2`
    in our graphs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'At this point, each of these objects should contain a table with the percentage
    of each category within the variable of interest. Those ending with `_all` contain
    the percentages for all the data recorded. Similarly, those ending with `_last`
    and `_this` contain the percentages for last week and this week, respectively.
    The number of decimal points will depend on the actual data and your configuration.
    In all cases, the numbers should add up to 100:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'The careful reader should have noticed that `quantity_all` contains one more
    category than `quantity_last` and `quantity_this`. That''s because in the last
    two weeks in the data, there were no sales for nine items. This means that when
    we try to compare the count change in each of these categories, we will have a
    problem due to the extra category in `quantity_all`. We will deal with it by keeping
    only categories that are shared among any table pair we''re using. The `equal_length_data()` function
    receives two of these tables as `data_1` and `data_2`, then, it computes the minimum
    length (`ml`) among them and uses it to get elements up to that point in both
    `data_1` and `data_2`. Since both of them are tables at this point, we want the
    numeric array of its values, not the table object, that''s why we apply the `as.numeric()`.
    If we don''t do so, `ggplot2` will complain about not knowing how to deal with
    objects of type `table`. We don''t lose the category names by applying the `as.numeric()`
    function to the tables because we''re taking those separately in the `names` element
    of the returned list. Finally, we want to know if any categories were deleted,
    and we can know that by checking if the length of any of the data tables contains
    less categories than the `ml` number indicates. If that''s the case, `deleted`
    will be `TRUE` and will be sent, and it will be `FALSE` otherwise:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'We now have access to data with equal length, with the corresponding category
    names, and with a Boolean value indicating whether any categories were deleted.
    We can use this object as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we will focus on preparing the data for our graphs. As we will be using
    the `ggplot2` package, we know we need to create a dataframe. This dataframe should
    contain category names in `Category`, the absolute and percent differences among
    matching categories from the two tables in the `Difference` and `Percent`, respectively,
    the `Sign` and `Color` depending on whether the absolute difference is positive
    or negative, and the *before* and *after* data in `Before` and `After`, respectively.
    Note that the order in which the `parts` were computed is important for the absolute
    and percent differences, which in turn impact the color and sign. We must be careful
    of sending the latest data as `data_2` so that we get an interpretation like *compared
    to last week, this week we had X more*. Otherwise, the interpretation would be
    inverted:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'We will define two colors using hexadecimal notation so that we can call them
    by name instead of copying the hexadecimal string every time. Later, if we want
    to change the colors, we can change them in a single place instead of replacing
    them everywhere we used them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'If you read [Chapter 5](part0110.html#38STS0-f494c932c729429fb734ce52cafce730),
    *Communicating Sales with Visualizations*, the `difference_bars()` function should
    be clear. As you can see, we are computing the `parts` and `data` objects using
    the functions shown earlier, and then we use the `ggplot2` package to develop
    the graph. Note that we only add a subtitle containing the indication that some
    categories have been deleted if the `deleted` Boolean from `parts` is `TRUE`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can create some useful graphs, as follows. Keep in mind that the values
    in the *y* axis do not indicate a percentage growth, but a change in percentage
    points. This can be immediately understood by looking at the code, but it is not
    clear when looking at the graph. In reality, we would have to include some explanation
    for this in a real presentation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting graphs are shown as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00058.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The second type of graph we want to develop is a bit more complex. We will create
    vertical lines at 1 and 2 along the *x* axis, place text labels indicating where
    the percentage for each category is in the `before` and `after` data sets, and
    the change percentage in the middle. First, we create the `data` object as we
    did before. Next, we create the labels we will use for each category. The ones
    one the left are the `before_labels`, the ones in the center are the `percent_labels`,
    and the ones in the right are the `after_labels`.
  prefs: []
  type: TYPE_NORMAL
- en: The `percent_y` contains the values for the y axis where the `percent_labels`
    will be placed. The *x* axis value is fixed at 1.5 so that it's between the two
    vertical lines. To compute the `percent_y` value, we want to get the minimum between
    the before and after values for each category and add half the difference between
    them. This will make sure that the value is at the middle of the line that will
    join both values.
  prefs: []
  type: TYPE_NORMAL
- en: We are now ready to start using the `ggplot2` package. First, we define the
    data as we normally would and add a segment joining the *before* and *after* values
    for each category by starting at the `$(1, Before)$` tuple and ending at the `$(2,
    After)$` tuple, where each tuple has the form `$(x, y)$`. We will use the `Sign`
    variable as the *fill* color for the bars, and avoid showing a legend since we
    will show some labels ourselves. We will use the *scale_color_manual()* function
    to specify the colors that should be used for each line depending on whether the
    absolute difference was positive or negative.
  prefs: []
  type: TYPE_NORMAL
- en: Next come the vertical lines, which are created with the `geom_vline()` function.
    As mentioned before, they will be placed at values 1 and 2 along the *x* axis.
    We will make the line dashed to improve aesthetics and use a smaller size than
    the segment lines we created before.
  prefs: []
  type: TYPE_NORMAL
- en: Next,  we will place the labels using the `geom_text()` function. We start creating
    the label for each of the vertical lines, which are created at 0.7 and 2.3 *x*
    axis values, and a slightly increased maximum of the *before* and *after* values.
    Then, we place the labels for the categories in the left, center, and right using
    the `geom_text_repel()` function. This function is not included in the `ggplot2`
    package, and it's actually an extension for it. It is designed to *repel* (hence
    the name) labels that overlap each other. To do so, the function moves labels
    away from the point's position and draws a line that indicates which label belongs
    to each point. You can find nice examples on its website ([https://cran.r-project.org/web/packages/ggrepel/vignettes/ggrepel.html](https://cran.r-project.org/web/packages/ggrepel/vignettes/ggrepel.html)).
    In our case, we remove said line with the *segment.color = NA* parameter and indicate
    that the direction for adjustment is only along the *y* axis.
  prefs: []
  type: TYPE_NORMAL
- en: In reality, it's very hard for someone to come up with all of this code on their
    first attempt, and our case was no different. We started with some small plots
    and continuously added the elements we were looking for through iterated experimentation.
    In particular, we realized that some labels were overlapping each other, which
    doesn't look great, and so we decided to use the `geom_text_repl()` package, which
    we did not previously know, but easily found online since many people have the
    same problem and luckily someone had developed a solution for it.
  prefs: []
  type: TYPE_NORMAL
- en: The `x_adjustment` parameter is a result of similar experimentation. We realized
    that different graph's labels were overlapping the vertical lines depending on
    the number of characters in the category names. To fix that, we decided to introduce
    a new parameter that adjusts the position along the x axis that can be experimented
    with until we find a good parameter for it. All this is to say that you should
    take advantage of R's rapid experimentation cycles to iteratively produce what
    you're looking for.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we remove any text from the x and y axes and limit their range of
    values because they are unnecessary to read the graph and provide a cleaner visualization.
    It may take a bit of experimentation for you to understand exactly what each part
    of the code is doing, which is totally fine, and you should definitely do so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/00059.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, we can present some very useful and nice-looking graphs with the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: These graphs can be easily interpreted and don't seem to be as vulnerable to
    the *x* axis percentage units problem we mentioned for the previous graphs. You
    can easily see if a category increased or decreased its percentage among periods,
    and by how much percentage. Keep in mind that the plots for *all-time* also contain
    *this week* when interpreting them. In reality, this may or may not be correct
    for your specific use case.
  prefs: []
  type: TYPE_NORMAL
- en: Building our presentation with R Markdown
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we will develop our presentation''s R Markdown file. We create
    an empty file named `presentation.R` and put the following headers in. The quotation
    marks are not required unless you want to include a colon in the title. As shown
    in a previous section, using backticks (“ ’), we can execute R code. In this case,
    we put the current date automatically in the front page. Finally, we chose `ioslides_presentation`
    as an output format. Feel free to experiment with the other outputs shown previously:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'The following code sets up the default configuration for the *code chunks*
    in our presentation. We avoid showing code in the presentation with `echo = FALSE`
    and make each picture full width unless stated otherwise with `out.width = ''100%''`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]{r setup, include=FALSE}'
  prefs: []
  type: TYPE_NORMAL
- en: knitr::opts_chunk$set(echo = FALSE, out.width = '100%')
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we need to bring all the resources we need for our presentation to work.
    Specifically, we need to load the functions we have developed along the last three
    chapters. Load the data `sales` and `client_messages` data and apply the same
    transformation we have seen in previous chapters to set up the data. Note that
    in this chapter, we referenced the sales data as `all_time` instead of `sales`,
    and to avoid changing our code so that we can still easily reference our development
    files, we simply copy the `sales` object into the `all_time` object. Be careful
    when doing this if you have tight memory restrictions in your system:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]{r load-functions-and-data, include=FALSE}'
  prefs: []
  type: TYPE_NORMAL
- en: source("../functions.R")
  prefs: []
  type: TYPE_NORMAL
- en: source("../../chapter-05/functions.R")
  prefs: []
  type: TYPE_NORMAL
- en: source ("../../chapter-06/functions.R")
  prefs: []
  type: TYPE_NORMAL
- en: sales           <- readRDS("../../chapter-04/results/sales.rds")
  prefs: []
  type: TYPE_NORMAL
- en: client_messages <- readRDS("../../chapter-04/results/client_messages.rds")
  prefs: []
  type: TYPE_NORMAL
- en: sales           <- add_profits(sales)
  prefs: []
  type: TYPE_NORMAL
- en: all_time  <- sales
  prefs: []
  type: TYPE_NORMAL
- en: max_date  <- max(all_time$DATE)
  prefs: []
  type: TYPE_NORMAL
- en: this_week <- filter_n_days_back(all_time, 7, max_date)
  prefs: []
  type: TYPE_NORMAL
- en: last_week <- filter_n_days_back(all_time, 7, max_date - 7)
  prefs: []
  type: TYPE_NORMAL
- en: quantity_all   <- proportions_table(all_time, "QUANTITY")
  prefs: []
  type: TYPE_NORMAL
- en: continent_all  <- proportions_table(all_time, "CONTINENT")
  prefs: []
  type: TYPE_NORMAL
- en: protein_all    <- proportions_table(all_time, "PROTEIN_SOURCE")
  prefs: []
  type: TYPE_NORMAL
- en: quantity_last  <- proportions_table(last_week, "QUANTITY")
  prefs: []
  type: TYPE_NORMAL
- en: continent_last <- proportions_table(last_week, "CONTINENT")
  prefs: []
  type: TYPE_NORMAL
- en: protein_last   <- proportions_table(last_week, "PROTEIN_SOURCE")
  prefs: []
  type: TYPE_NORMAL
- en: quantity_this  <- proportions_table(this_week, "QUANTITY")
  prefs: []
  type: TYPE_NORMAL
- en: continent_this <- proportions_table(this_week, "CONTINENT")
  prefs: []
  type: TYPE_NORMAL
- en: protein_this   <- proportions_table(this_week, "PROTEIN_SOURCE")
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: Now that our resources have been set up, we can work on the code that will actually
    show our analysis in the presentation. We start with the slides that use the functions
    we developed previously in this chapter to show changes using bars and lines.
    Note that we are specifying different heights in each case for bar and line graphs.
    Also note that we're using a 50% width for line graphs. That's because we want
    them to appear vertically in the slide. A 50% width with a height of 10 achieves
    that distribution.
  prefs: []
  type: TYPE_NORMAL
- en: 'In reality, you may want to choose better titles for each slide, but we will
    keep them obvious for this example. Note that working this way, we avoid placing
    any logic code in our slides, and by simply reading the function titles, we know
    exactly what will be shown. This lets you easily move things around without breaking
    things up due to dependencies among pieces of code since we have abstracted that
    into separate files. If you fill your presentation files with R logic, you''ll
    quickly find it very confusing when you need to change them. It''s better to have
    that logic in an actual `.R` file, as we do with our `functions.R` file. Not to
    mention that it''s also much more reusable that way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]{r quantity-bars, fig.height = 2.5}'
  prefs: []
  type: TYPE_NORMAL
- en: difference_bars_absolute(quantity_last, quantity_this, "This week", "Last week")
  prefs: []
  type: TYPE_NORMAL
- en: difference_bars_absolute(quantity_all, quantity_this, "This week", "All-time")
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]{r quantity-lines, out.width = ''50%'', fig.height = 10}'
  prefs: []
  type: TYPE_NORMAL
- en: change_lines(quantity_last, quantity_this, "This week", "Last week", 0.2)
  prefs: []
  type: TYPE_NORMAL
- en: change_lines(quantity_all, quantity_this, "This week", "All-time", 0.2)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]{r continent-bars, fig.height = 2.5}'
  prefs: []
  type: TYPE_NORMAL
- en: difference_bars_absolute(continent_last, continent_this, "This week", "Last
    week")
  prefs: []
  type: TYPE_NORMAL
- en: difference_bars_absolute(continent_all, continent_this, "This week", "All-time")
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]{r continent-lines, out.width = ''50%'', fig.height = 10}'
  prefs: []
  type: TYPE_NORMAL
- en: change_lines(continent_last, continent_this, "This week", "Last week", 0.3)
  prefs: []
  type: TYPE_NORMAL
- en: change_lines(continent_all, continent_this, "This week", "All-time", 0.3)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]{r protein-source-bars, fig.height = 2.5}'
  prefs: []
  type: TYPE_NORMAL
- en: difference_bars_absolute(protein_last, protein_this, "This week", "Last week")
  prefs: []
  type: TYPE_NORMAL
- en: difference_bars_absolute(protein_all, protein_this, "This week", "All-time")
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]{r protein-source-lines, out.width = ''50%'', fig.height = 10}'
  prefs: []
  type: TYPE_NORMAL
- en: change_lines(protein_last, protein_this, "This week", "Last week", 0.5)
  prefs: []
  type: TYPE_NORMAL
- en: change_lines(protein_all, protein_this, "This week", "All-time", 0.5)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: Now, we will add function calls to code we developed in previous chapters. As
    you can see, the process is exactly the same since we have already loaded those
    resources at this point in the `load-functions-and-data` code chunk shown earlier.
    All we have to do is actually call the functions that produce the graphs for us.
    If you can't remember what these functions do, we suggest to go back to their
    corresponding chapters to go over the details on how they were created.
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see, the last slide from this *code chunk* calls the `graph_client_messages_interactive()`
    function that produces the interactive map you could move around in [Chapter 5](part0110.html#38STS0-f494c932c729429fb734ce52cafce730),
    *Communicating Sales with Visualizations*. A great thing about creating presentations
    this way is that you can actually play around with the map within the presentation!
    Of course, this will only work if you''re using an output format that uses the
    web browser for visualization (it will not work with PDFs or Word documents, for
    example), but it can be a fantastic way to add powerful content to your presentations
    if you''re using a web browser to visualize them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]{r sales-proft-ratio-by-continent-and-protein-source }'
  prefs: []
  type: TYPE_NORMAL
- en: graph_bars(sales, "CONTINENT", "PROFIT_RATIO", "PROTEIN_SOURCE")
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]{r price-vs-cost}'
  prefs: []
  type: TYPE_NORMAL
- en: graph_marginal_distributions(sales, "COST", "PRICE", "PROTEIN_SOURCE", "CONTINENT")
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]{r price-vs-profit-ratio}'
  prefs: []
  type: TYPE_NORMAL
- en: graph_marginal_distributions(sales, "PRICE", "PROFIT_RATIO", "PROTEIN_SOURCE",
    "CONTINENT")
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]{r date-vs-frequency-profit-and-profit-ratio, fig.height = 1.8}'
  prefs: []
  type: TYPE_NORMAL
- en: graph_last_n_days(sales, 30, color = "PROTEIN_SOURCE")
  prefs: []
  type: TYPE_NORMAL
- en: graph_last_n_days(sales, 30, "PROFIT", "PROTEIN_SOURCE")
  prefs: []
  type: TYPE_NORMAL
- en: graph_last_n_days(sales, 30, "PROFIT_RATIO", "PROTEIN_SOURCE")
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]{r top-customers-preferences}'
  prefs: []
  type: TYPE_NORMAL
- en: subset <- filter_data(sales, 30, 5, "CLIENT_ID")
  prefs: []
  type: TYPE_NORMAL
- en: graph_radar(subset, "CLIENT_ID")
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]{r customers-dynamic-map}'
  prefs: []
  type: TYPE_NORMAL
- en: graph_client_messages_interactive(client_messages, sales)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: Finally, we want to show the latest tweets using actual live Twitter data. Since
    The Food Factory company that we have alluded to during this example is fictitious,
    we can't really get data for it, but we will still search Twitter for *The Food
    Factory* phrase and show the top 5 results we get back. In reality, you can retrieve
    tweets that mention a specific account you're interested in, and be more creative
    with the querying process. We will keep it simple for this example.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first thing we must do, as shown in [Chapter 6](part0129.html#3R0OI0-f494c932c729429fb734ce52cafce730),
    *Understanding Reviews with Text Analysis*, is to identify ourselves with Twitter''s
    API so that we can retrieve data. If you don''t remember how to do so, take a
    look at said chapter. Since we want to execute this piece of code but we don''t
    want to show it or its output, we simply apply the option `include = FALSE`. Note
    that we keep the slide title on top of the authentication code as a sign to ourselves
    that this code belongs to this slide''s logic:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]{r twitter-setup, include = FALSE}'
  prefs: []
  type: TYPE_NORMAL
- en: consumer_key    <- "b9SGfRpz4b1rnHFtN2HtiQ9xl"
  prefs: []
  type: TYPE_NORMAL
- en: consumer_secret <- "YMifSUmCJ4dlgB8RVxKRNcTLQw7Y4IBwDwBRkdz2Va1vcQjOP0"
  prefs: []
  type: TYPE_NORMAL
- en: access_token    <- "171370802-RTl4RBpMDaSFdVf5q9xrSWQKxtae4Wi3y76Ka4Lz"
  prefs: []
  type: TYPE_NORMAL
- en: access_secret   <- "dHfbMtmpeA2QdOH5cYPXO5b4hF8Nj6LjxELfOMSwHoUB8"
  prefs: []
  type: TYPE_NORMAL
- en: setup_twitter_oauth(consumer_key, consumer_secret, access_token, access_secret)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we put in another *code chunk* that actually produces the output we want
    to show in the slide. We are getting data from Twitter using the `get_twitter_data()`
    we created in the previous chapter, and we pass it through the `format_tweets()`
    function we will show next:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]{r twitter-live-data, size = "footnotesize", comment = ""}'
  prefs: []
  type: TYPE_NORMAL
- en: format_tweets(get_twitter_data("The Food Factory", 5))
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: This `format_tweets()` function was necessary to print the data we are interested
    in showing in the slide. If you remember, the data we get from the `get_twitter_data()`
    function contains quite a bit of metadata around each tweet, which is very useful
    when doing analysis, but for this slide, we would rather show only the screen
    name for the person who tweeted, the tweet's timestamp, and the actual tweet.
    We also need to truncate the tweet's length to make sure that it looks fine in
    the presentation. Even though it's a small function, the code can be a bit complex
    if you haven't seen those functions before, so we will take it step by step.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `format_tweets()` function receives a single argument, which is the data
    we got back from the `get_twitter_data()` function, and we know that data structure
    contains the `created`, `text`, and `screenName` variables we''re interested in.
    Since this is vectorized code, we don''t have to use a for loop to print each
    tweet independently. We can simply use the arrays of values directly. If you don''t
    remember what vectorized code refers to, you can review it in [Chapter 1](part0022.html#KVCC0-f494c932c729429fb734ce52cafce730),
    *Introduction to R*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: The first thing you may notice is that we're not using the `print()` function.
    We are using the `write()` function passing in the `stdout()` function call. This
    means that we will *write* an object into the standard output. You can think of
    this as a *dumb* `print()` function call, where R will not do any processing for
    us, and will simply show exactly what we tell it to. What this does is avoid printing
    the numbered lines we normally get when using the print function. Remember those
    `[1], [2], ...` at the beginning of the output in the previous code? This `write(...,
    stdout())` technique avoids them. You normally don't want that, but it's useful
    for aesthetics purposes in this particular case.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we use the `paste()` function as we have been doing to put together everything
    we want to print. In this case, we start with screen names, followed by parenthesis
    enclosing the timestamp (contained in `data$created`), and followed by a combination
    that indicates a *new line*. The `\n` combination, when used inside the `write()`
    function, tells R to actually introduce a new line at that point, just as if you
    had pressed the *return* key (*Enter* key on your keyboard). Next, we pass the
    actual tweet (`data$text`) to the `substr()` function so that we can get characters
    1 through 65\. This is done, again, for aesthetic purposes since we don't want
    very long tweets to take more than one line. That output is sent to the `enc2utf8()`
    function, which sets the string's encoding to UTF-8, and this output is passed
    through the `iconv()` function with a `sub = ""` parameter, which will delete
    any non-convertible characters. Finally, we put a `"(...) \n"` string to show
    that the tweet was probably truncated, and another *new line* symbol.
  prefs: []
  type: TYPE_NORMAL
- en: When using the `iconv()` function, what happens is that it will try to convert
    characters one by one, and whenever it can't convert a character, it will replace
    it with the `sub` string we send. We need to do this because we may get characters
    from languages like Chinese or Arabic whose output, would contain a Unicode representation
    which would not make sense to people who are not familiar with these types of
    encoding issues. We're trying to produce a user-friendly presentation.
  prefs: []
  type: TYPE_NORMAL
- en: If you recompile this presentation, the messages you retrieve from Twitter will
    be different from the ones shown here because they will be retrieved at that moment.
  prefs: []
  type: TYPE_NORMAL
- en: Now, you can compile your presentation with any of the methods mentioned earlier,
    and if everything goes fine, you should see a `presentation.html` file in your
    directory. If you open that file in your web browser, you should see slides similar
    to the ones shown as follows. You may also open directly the live presentation
    in the repository for this book. Remember to play around with the interactive
    map!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we discussed the benefits of automating tasks as well as content
    creation. We showed how to integrate automation pipelines for content creation,
    how to write R Markdown documents, which provide dynamic content, and how to use
    these documents to produce documents and presentations that look nice and are
    efficient. We showed how to integrate various R resources to create content that
    can be updated automatically.
  prefs: []
  type: TYPE_NORMAL
- en: In case you want to develop documents that are more technical or lengthy, the
    `bookdown` package may be a good option for you. Its purpose is to make the creation
    of lengthy documents, such as books, easier using R Markdown. As a matter of fact,
    this book was written using `bookdown`, and the process was a really nice one.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will start a new example focused on evaluating cryptocurrency
    trades. We will start by building an object-oriented system that simulates a trading
    platform and evaluates traders' performances automatically. After that, we will
    show you how to make our algorithms run faster by using parallelization and delegation,
    and finally, in the last chapter, we will show you how to create web pages that
    contain interactive dashboards, all from within R.
  prefs: []
  type: TYPE_NORMAL
