- en: 4\. A Deep Dive into Data Wrangling with Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Overview
  prefs: []
  type: TYPE_NORMAL
- en: This chapter will cover pandas DataFrames in depth, thus teaching you how to
    perform subsetting, filtering, and grouping on DataFrames. You will be able to
    apply Boolean filtering and indexing to a DataFrame to choose specific elements
    from it. Later on in the chapter, you will learn how to perform JOIN operations
    in pandas that are analogous to the SQL command. By the end of this chapter you
    will be able to apply imputation techniques to identify missing or corrupted data
    and choose to drop it.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we learned how to use the pa`ndas`, `numpy`, and `matplotlib`
    libraries while handling various datatypes. In this chapter, we will learn about
    several advanced operations involving `pandas` DataFrames and `numpy` arrays.
    We will be working with several powerful DataFrame operations, including subsetting,
    filtering grouping, checking uniqueness, and even dealing with missing data, among
    others. These techniques are extremely useful when working with data in any way.
    When we want to look at a portion of the data, we must subset, filter, or group
    the data. `Pandas` contains the functionality to create descriptive statistics
    of the dataset. These methods will allow us to start shaping our perception of
    the data. Ideally, when we have a dataset, we want it to be complete, but in reality,
    there is often missing or corrupt data. This can happen for a variety of reasons
    that we can't control, such as user error and sensor malfunction. Pandas has built-in
    functionalities to deal with such kinds of missing data within our dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Subsetting, Filtering, and Grouping
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the most important aspects of data wrangling is to curate the data carefully
    from the deluge of streaming data that pours into an organization or business
    entity from various sources. Lots of data is not always a good thing; rather,
    data needs to be useful and of high quality to be effectively used in downstream
    activities of a data science pipeline, such as machine learning and predictive
    model building. Moreover, one data source can be used for multiple purposes, and
    this often requires different subsets of data to be processed by a data wrangling
    module. This is then passed on to separate analytics modules.
  prefs: []
  type: TYPE_NORMAL
- en: For example, let's say you are doing data wrangling on US state-level economic
    output. It is a fairly common scenario that one machine learning model may require
    data for large and populous states (such as California and Texas), while another
    model demands processed data for small and sparsely populated states (such as
    Montana or North Dakota). As the frontline of the data science process, it is
    the responsibility of the data wrangling module to satisfy the requirements of
    both these machine learning models. Therefore, as a data wrangling engineer, you
    have to filter and group data accordingly (based on the population of the state)
    before processing them and producing separate datasets as the final output for
    separate machine learning models.
  prefs: []
  type: TYPE_NORMAL
- en: Also, in some cases, data sources may be biased, or the measurement may corrupt
    the incoming data occasionally. It is a good idea to try to filter only the error-free,
    good data for downstream modeling. From these examples and discussions, it is
    clear that filtering and grouping/bucketing data is an essential skill to have
    for any engineer that's engaged in the task of data wrangling. Let's proceed to
    learn about a few of these skills with pandas.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 4.01: Examining the Superstore Sales Data in an Excel File'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this exercise, we will read and examine an Excel file called `Sample-Superstore.xls`
    and will check all the columns to check if they are useful for analysis. We'll
    use the `drop` method to delete the columns that are unnecessary from the `.xls`
    file. Then, we'll use the `shape` function to check the number of rows and columns
    in the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'The `superstore` dataset file can be found here: [https://packt.live/3dcVnMs](https://packt.live/3dcVnMs).'
  prefs: []
  type: TYPE_NORMAL
- en: 'To do so, perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'To read an Excel file into `pandas`, you will need a small package called `xlrd`
    to be installed on your system. Use the following code to install the `xlrd` package:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The `!` notation tells the Jupyter Notebook that the cell should be treated
    as a shell command.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Read the Excel file from GitHub into a `pandas` DataFrame using the `read_excel`
    method in `pandas`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Drop this column altogether from the DataFrame by using the `drop` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.2: Partial output of the Superstore dataset after dropping the ''Row
    ID'' column'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_04_02.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.2: Partial output of the Superstore dataset after dropping the ''Row
    ID'' column'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Check the number of rows and columns in the newly created dataset. We will
    use the `shape` function here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In this exercise, we can see that the dataset has `9,994` rows and `20` columns.
    We have now seen that a simple way to remove unwanted columns such as a row count
    is simple with `pandas`. Think about how hard this would be if, instead of `pandas`,
    we used a list of dictionaries? We would have to write a loop to remove the `rowid`
    element from each dictionary in the list. `pandas` makes this functionality simple
    and easy.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/2Y9ZTXW](https://packt.live/2Y9ZTXW).
  prefs: []
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/2N4dVUO](https://packt.live/2N4dVUO).
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we'll discuss how to subset a DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: Subsetting the DataFrame
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`Customer ID`, `Customer Name`, `City`, `Postal Code`, and `Sales`. For demonstration
    purposes, let''s assume that we are only interested in `5` records – rows `5-9`.
    We can subset the DataFrame to extract only this much information using a single
    line of Python code.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use the `loc` method to index the `Sample Superstore` dataset by the
    names of the columns and the indexes of the rows, as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.3: Partial data of the DataFrame indexed by the names of the columns'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15780_04_03.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 4.3: Partial data of the DataFrame indexed by the names of the columns'
  prefs: []
  type: TYPE_NORMAL
- en: We need to pass on two arguments to the `loc` method – one for indicating the
    rows, and another for indicating the columns. When passing more than one value,
    you must pass them as a list for a row or column.
  prefs: []
  type: TYPE_NORMAL
- en: For the rows, we have to pass a list, that is, `[5,6,7,8,9]`, but instead of
    writing that explicitly, we use a list comprehension, that is, `[i for i in range(5,10)]`.
  prefs: []
  type: TYPE_NORMAL
- en: Because the columns we are interested in are not continuous and we cannot just
    put in a continuous range, we need to pass on a list containing the specific names.
    So, the second argument is just a simple list with specific column names. The
    dataset shows the fundamental concepts of the process of **subsetting** a DataFrame
    based on business requirements.
  prefs: []
  type: TYPE_NORMAL
- en: Let's look at an example use case and practice subsetting a bit more.
  prefs: []
  type: TYPE_NORMAL
- en: An Example Use Case – Determining Statistics on Sales and Profit
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s take a look at a typical use case of subsetting. Suppose we want to
    calculate descriptive statistics (mean, median, standard deviation, and so on)
    of records `100-199` for sales and profit in the `SuperStore` dataset. The following
    code shows how subsetting helps us achieve that:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.4: Output of descriptive statistics of data'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15780_04_04.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 4.4: Output of descriptive statistics of data'
  prefs: []
  type: TYPE_NORMAL
- en: We simply extract records `100-199` and run the `describe` function on them
    because we don't want to process all the data. For this particular business question,
    we are only interested in sales and profit numbers, and therefore we should not
    take the easy route and run a `describe` function on all the data. For a dataset
    that's being used in machine learning analysis, the number of rows and columns
    could often be in the millions, and we don't want to compute anything that is
    not asked for in the data wrangling task. We always aim to subset the exact data
    that needs to be processed and run statistical or plotting functions on that partial
    data. One of the most intuitive ways to try and understand the data is through
    charting. This can be a critical component of data wrangling.
  prefs: []
  type: TYPE_NORMAL
- en: 'To better understand sales and profit, let''s create a box plot of the data
    using `matplotlib`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.5: Box plot of sales and profit'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15780_04_05.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 4.5: Box plot of sales and profit'
  prefs: []
  type: TYPE_NORMAL
- en: As we can see from the preceding box plot, there are some outliers for profit.
    Now, they could be normal outliers, or they could be `NaN` values. At this point,
    we can't speculate, but this could cause some further analysis to see how we want
    to treat those outliers in profit. In some cases, outliers are fine, but for some
    predictive modeling techniques such as regression, outliers can have unwanted
    effects.
  prefs: []
  type: TYPE_NORMAL
- en: Before continuing further with filtering methods, let's take a quick detour
    and explore a super useful function called `unique`. As its name suggests, this
    function is used to scan through the data quickly and extract only the unique
    values in a column or row.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 4.02: The unique Function'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the superstore sales data, you will notice that there are columns such as
    `Country`, `State`, and `City`. A natural question will be to ask how many `countries/states/cities`
    are present in the dataset. In this exercise, we''ll use the `unique` function
    to find the number of unique `countries/states/cities` in the dataset. Let''s
    go through the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'The `superstore` dataset file can be found here: [https://packt.live/3dcVnMs](https://packt.live/3dcVnMs).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the necessary libraries and read the file from GitHub by using the `read_excel`
    method in `pandas` into a DataFrame:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The highlighted path must be changed based on the location of the file on your
    system.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Extract `countries/states/cities` for which the information is in the database,
    with one simple line of code, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.6: Different states present in the dataset'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_04_06.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.6: Different states present in the dataset'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You will see a list of all the states whose data is present in the dataset.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Use the `nunique` method to count the number of unique values in the `State`
    column, like so:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This returns `49` for this dataset. So, one out of `50` states in the US does
    not appear in this dataset. Therefore, we can conclude that there's one repetition
    in the `State` column.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/2NaBkUB](https://packt.live/2NaBkUB).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/2N7NHkf](https://packt.live/2N7NHkf).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Similarly, if we run this function on the `Country` column, we get an array
    with only one element, `United States`. Immediately, we can see that we don't
    need to keep the country column at all because there is no useful information
    in that column, except that all the entries are the same. This is how a simple
    function helped us to decide about dropping a column altogether – that is, removing
    `9,994` pieces of unnecessary data.
  prefs: []
  type: TYPE_NORMAL
- en: Conditional Selection and Boolean Filtering
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Often, we don''t want to process the whole dataset and would like to select
    only a partial dataset whose contents satisfy a particular condition. This is
    probably the most common use case of any data wrangling task. In the context of
    our `superstore sales` dataset, think of these common questions that may arise
    from the daily activities of the business analytics team:'
  prefs: []
  type: TYPE_NORMAL
- en: What are the average sales and profit figures in California?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Which states have the highest and lowest total sales?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What consumer segment has the most variance in sales/profit?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Among the top five states in sales, which shipping mode and product category
    are the most popular choices?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Countless examples can be given where the business analytics team or the executive
    management wants to glean insight from a particular subset of data that meets
    certain criteria.
  prefs: []
  type: TYPE_NORMAL
- en: If you have any prior experience with SQL, you will know that these kinds of
    questions require fairly complex SQL query writing. Remember the `WHERE` clause?
  prefs: []
  type: TYPE_NORMAL
- en: We will show you how to use conditional subsetting and boolean filtering to
    answer such questions.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we need to understand the critical concept of boolean indexing. This
    process essentially accepts a conditional expression as an argument and returns
    a dataset of booleans in which the `TRUE` value appears in places where the condition
    was satisfied. A simple example is shown in the following code. For demonstration
    purposes, we''re subsetting a small dataset of `10` records and `3` columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.7: Sample dataset'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15780_04_07.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 4.7: Sample dataset'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, if we just want to know the records with sales higher than `$100`, then
    we can write the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'This produces the following `boolean` DataFrame:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.8 Records with sales higher than $100'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15780_04_08.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.8 Records with sales higher than $100
  prefs: []
  type: TYPE_NORMAL
- en: Let's take a look at the `True` and `False` entries in the `Sales` column. The
    values in the `Ship Mode` and `State` columns were not impacted by this code because
    the comparison was with a numerical quantity, and the only numeric column in the
    original DataFrame was `Sales`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s see what happens if we pass this `boolean` DataFrame as an index
    to the original DataFrame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.9: Results after passing the boolean DataFrame as an index'
  prefs: []
  type: TYPE_NORMAL
- en: to the original DataFrame
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15780_04_09.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 4.9: Results after passing the boolean DataFrame as an index to the
    original DataFrame'
  prefs: []
  type: TYPE_NORMAL
- en: We are not limited to conditional expressions involving numeric quantities only.
    Let's try to extract high sales values (`>$100`) for entries that do not involve
    `California`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can write the following code to accomplish this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Note the use of a conditional involving string. In this expression, we are joining
    two conditionals by an `&` operator. Both conditions must be wrapped inside parentheses.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first conditional expression simply matches the entries in the `State`
    column to the `California` string and assigns `TRUE`/`FALSE` accordingly. The
    second conditional is the same as before. Together, joined by the `&` operator,
    they extract only those rows for which `State` is *not* `California` and `Sales`
    is `> $100`. We get the following result:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.10: Results, where State is not California and Sales, is higher
    than $100'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15780_04_10.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 4.10: Results, where State is not California and Sales, is higher than
    $100'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Although, in theory, there is no limit to how complex a conditional you can
    build using individual expressions and the `&` (`LOGICAL AND`) and `|` (`LOGICAL
    OR`) operators, it is advisable to create intermediate boolean DataFrames with
    limited conditional expressions and build your final DataFrame step by step. This
    keeps the code legible and scalable.
  prefs: []
  type: TYPE_NORMAL
- en: In the following exercise, we'll look at a few different methods we can use
    to manipulate the DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 4.03: Setting and Resetting the Index'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this exercise, we will create a pandas DataFrame and set and reset the index.
    We''ll also add a new column and set it as the new index of this DataFrame. To
    do so, let''s go through the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the `numpy` library:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create the `matrix_data`, `row_labels`, and `column_headings` functions using
    the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Import the `pandas` library and then create a DataFrame using the `matrix_data`,
    `row_labels`, and `column_headings` functions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.11: The original DataFrame'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_04_11.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.11: The original DataFrame'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Reset the index, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.12: DataFrame after resetting the index'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_04_12.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.12: DataFrame after resetting the index'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Reset the index with `drop` set to `True`, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.13: DataFrame after resetting the index with the drop option set
    to true'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_04_13.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.13: DataFrame after resetting the index with the drop option set to
    true'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Add a new column using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.14: DataFrame after adding a new column called Profession'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_04_14.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.14: DataFrame after adding a new column called Profession'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now, set the `Profession` column as an `index` using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.15: DataFrame after setting the Profession column as an index'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_04_15.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.15: DataFrame after setting the Profession column as an index'
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, the new data was added at the end of the table.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/30QknH2](https://packt.live/30QknH2).
  prefs: []
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/37CdM4o](https://packt.live/37CdM4o).
  prefs: []
  type: TYPE_NORMAL
- en: The GroupBy Method
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**GroupBy** refers to a process involving one or more of the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Splitting the data into groups based on some criteria
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Applying a function to each group independently
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Combining the results into a data structure
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In many situations, we can split the dataset into groups and do something with
    those groups. In the apply step, we may wish to do one of the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Aggregation**: Compute a summary statistic (or statistics) for each group
    – sum, mean, and so on'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Transformation**: Perform a group-specific computation and return a like-indexed
    object – z-transformation or filling missing data with a value'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`TRUE` or `FALSE`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is, of course, a describe method for this `GroupBy` object, which produces
    the summary statistics in the form of a DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: The name GroupBy should be quite familiar to those who have used a SQL-based
    tool before.
  prefs: []
  type: TYPE_NORMAL
- en: GroupBy is not limited to a single variable. If you pass on multiple variables
    (as a list), then you will get a structure essentially similar to a Pivot Table
    (from Excel). The following exercise shows an example of where we group together
    all the states and cities from the whole dataset (the snapshot is only a partial
    view).
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 4.04: The GroupBy Method'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this exercise, we''re going to create a subset from a dataset. We will use
    the `groupBy` object to filter the dataset and calculate the mean of that filtered
    dataset. To do so, let''s go through the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'The `superstore` dataset file can be found here: [https://packt.live/3dcVnMs](https://packt.live/3dcVnMs).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the necessary Python modules and read the Excel file from GitHub by
    using the `read_excel` method in `pandas`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output (partially shown) is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.16: Partial output of the DataFrame'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_04_16.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.16: Partial output of the DataFrame'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The highlighted path must be changed based on the location of the file on your
    system.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Create a 10-record subset using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.17: 10-Record Subset'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_04_17.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.17: 10-Record Subset'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Create a `pandas` DataFrame using the `groupby` method, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be similar to:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Calculate the mean sales figure by `State` by using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.18: Output after grouping the state with the listing mean sales'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_04_18.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.18: Output after grouping the state with the listing mean sales'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Calculate the total sales figure by `State` by using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.19: The output after grouping the state with the listing sum of
    sales'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_04_19.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.19: The output after grouping the state with the listing sum of sales'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Subset that DataFrame for a particular state and show the statistics:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.20: Checking the statistics of a particular state'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_04_20.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.20: Checking the statistics of a particular state'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Perform a similar summarization by using the `Ship Mode` attribute:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.21: Checking the sales by summarizing the Ship Mode attribute'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_04_21.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.21: Checking the sales by summarizing the Ship Mode attribute'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Display the complete summary statistics of sales by every city in each state
    – all with two lines of code – by using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output (partially shown) is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.22: Partial output while checking the summary statistics of sales'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_04_22.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.22: Partial output while checking the summary statistics of sales'
  prefs: []
  type: TYPE_NORMAL
- en: Note how `pandas` has grouped the data by `State` first and then by cities under
    each state.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/2Cm9eUl](https://packt.live/2Cm9eUl).
  prefs: []
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/3fxK43c](https://packt.live/3fxK43c).
  prefs: []
  type: TYPE_NORMAL
- en: We now understand how to use `pandas` to group our dataset and then find aggregate
    values such as the mean sales return of our top employees. We also looked at how
    pandas will display descriptive statistics about our data for us. Both of these
    techniques can be used to perform analysis on our superstore data.
  prefs: []
  type: TYPE_NORMAL
- en: Detecting Outliers and Handling Missing Values
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Outlier detection and handling missing values fall under the subtle art of data
    quality checking. A modeling or data mining process is fundamentally a complex
    series of computations whose output quality largely depends on the quality and
    consistency of the input data being fed. The responsibility of maintaining and
    gatekeeping that quality often falls on the shoulders of a data wrangling team.
  prefs: []
  type: TYPE_NORMAL
- en: Apart from the obvious issue of poor-quality data, missing data can sometimes
    wreak havoc with the **Machine Learning** (**ML**) model downstream. A few ML
    models, such as Bayesian learning, are inherently robust to outliers and missing
    data, but common techniques such as Decision Trees and Random Forest have an issue
    with missing data because the fundamental splitting strategy employed by these
    techniques depends on an individual piece of data and not a cluster. Therefore,
    it is almost always imperative to impute missing data before handing it over to
    such an ML model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Outlier detection is a subtle art. Often, there is no universally agreed definition
    of an outlier. In a statistical sense, a data point that falls outside a certain
    range may often be classified as an outlier, but to apply that definition, you
    need to have a fairly high degree of certainty about the assumption of the nature
    and parameters of the inherent statistical distribution about the data. It takes
    a lot of data to build that statistical certainty and even after that, an outlier
    may not be just unimportant noise but a clue to something deeper. Let''s look
    at an example with some fictitious sales data from an American fast-food chain
    restaurant. If we want to model the daily sales data as a time series, we will
    observe an unusual spike in the data somewhere around mid-April:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.23: Fictitious sales data of an American fast-food chain restaurant'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15780_04_23.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 4.23: Fictitious sales data of an American fast-food chain restaurant'
  prefs: []
  type: TYPE_NORMAL
- en: A good data scientist or data wrangler should develop curiosity about this data
    point rather than just rejecting it just because it falls outside the statistical
    range. In the actual anecdote, the sales figure spiked that day because of an
    unusual reason. So, the data was real. But just because it was real does not mean
    it is useful. In the final goal of building a smoothly varying time series model,
    this one point should not matter and should be rejected. In this chapter, however,
    we're going to look at ways of handling outliers instead of rejecting them.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, the key to outliers is their systematic and timely detection in an
    incoming stream of millions of data or while reading data from cloud-based storage.
    In this section, we will quickly go over some basic statistical tests for detecting
    outliers and some basic imputation techniques for filling up missing data.
  prefs: []
  type: TYPE_NORMAL
- en: Missing Values in Pandas
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'One of the most useful functions for detecting missing values is `isnull`.
    We''ll use this function on a DataFrame called `df_missing` (based on the Superstore
    DataFrame we are working with), which, as the name suggests, will contain some
    missing values. You can create this DataFrame using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Don't forget to change the path (highlighted) based on the location of the file
    on your system.
  prefs: []
  type: TYPE_NORMAL
- en: 'The output will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.24: DataFrame with missing values'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15780_04_24.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 4.24: DataFrame with missing values'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can see that the missing values are denoted by `NaN`. Now let''s use the
    `isnull` function on the same DataFrame and observe the results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.25: Output highlighting the missing values'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15780_04_25.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 4.25: Output highlighting the missing values'
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see, the missing values are indicated by the Boolean value `True`.
    Now, let''s see how we can use the `isnull` function to deliver results that are
    a bit more user friendly. Here is an example of some very simple code to detect,
    count, and print out missing values in every column of a DataFrame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'This code scans every column of the DataFrame, calls the `isnull` function,
    and sums up the returned object (a `pandas` Series object, in this case) to count
    the number of missing values. If the missing value is greater than zero, it prints
    out the message accordingly. The output looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.26: Output of counting the missing values'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15780_04_26.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 4.26: Output of counting the missing values'
  prefs: []
  type: TYPE_NORMAL
- en: As we can see from the preceding output, the missing values were detected from
    the `Superstore` dataset.
  prefs: []
  type: TYPE_NORMAL
- en: To handle missing values, you should look for ways not to drop them altogether
    but to fill them somehow. The `fillna` method is a useful function for performing
    this task on `pandas` DataFrames. The `fillna` method may work for string data,
    but not for numerical columns such as sales or profits. So, we should restrict
    ourselves in regard to this fixed string replacement being used on non-numeric
    text-based columns only. The `Pad` or `ffill` function is used to fill forward
    the data, that is, copy it from the preceding data of the series. Forward fill
    is a technique where the missing value is filled with the previous value. On the
    other hand, backward fill or `bfill` uses the next value to fill in any missing
    data. Let's practice this with the following exercise.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 4.05: Filling in the Missing Values Using the fillna Method'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this exercise, we are going to perform four techniques in order to deal with
    the missing values in a dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'The `superstore` dataset file can be found here: [https://packt.live/3dcVnMs](https://packt.live/3dcVnMs).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Firstly, we are going to replace the missing values with static values using
    the `fillna` method. Then, we will use the `ffill` and `bfill` methods to replace
    the missing values. Lastly, we will calculate the average of a column and replace
    the missing value with that. To do so, let''s go through the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the necessary Python modules and read the Excel file from GitHub by
    using the `read_excel` method in `pandas`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The highlighted path must be changed based on the location of the file on your
    system.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.27: Snapshot of the dataset'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_04_27.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.27: Snapshot of the dataset'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Fill in all the missing values with the `FILL` string by using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.28: Missing values replaced with FILL'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_04_28.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.28: Missing values replaced with FILL'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Fill in the specified columns with the `FILL` string by using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.29: Specified columns replaced with FILL'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_04_29.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.29: Specified columns replaced with FILL'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In all of these cases, the function works on a copy of the original DataFrame.
    So, if you want to make the changes permanent, you have to assign the DataFrames
    that are returned by these functions to the original DataFrame object.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Fill in the values using `ffill` or forward fill by using the following command
    on the `Sales` column:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.30: Sales column using the forward fill'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_04_30.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.30: Sales column using the forward fill'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Use `bfill` to fill backward, that is, copy from the next data in the series:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.31: Sales column using the backward fill'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_04_31.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.31: Sales column using the backward fill'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Let''s compare these two series and see what happened in each case:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.32: Using forward fill and backward fill to fill in missing data'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_04_32.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.32: Using forward fill and backward fill to fill in missing data'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You can also fill by using a function average of DataFrames. For example, we
    may want to fill the missing values in `Sales` by the average sales amount.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Fill the missing values in `Sales` by the average sales amount:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.33: Sales column with average sales amount'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_04_33.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.33: Sales column with average sales amount'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot shows what happened in the preceding code:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.34: Using average to fill in missing data'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15780_04_34.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 4.34: Using average to fill in missing data'
  prefs: []
  type: TYPE_NORMAL
- en: Here, we can observe that the missing value in the cell was filled by the average
    sales amount.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/2ACDYjp](https://packt.live/2ACDYjp).
  prefs: []
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/2YNZnhh](https://packt.live/2YNZnhh).
  prefs: []
  type: TYPE_NORMAL
- en: 'With this, we have now seen how to replace missing values within a `pandas`
    DataFrame using four methods: static value, forward fill, backward fill, and the
    average. These are the fundamental techniques when cleaning data with missing values.'
  prefs: []
  type: TYPE_NORMAL
- en: The dropna Method
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This function is used to simply drop the rows or columns that contain `NaN`
    or missing values. However, there is some choice involved.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the syntax of the `dropna()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: If the `axis` parameter of a `dropna()` method is set to `0`, then rows containing
    missing values are dropped; if the axis parameter is set to `1`, then columns
    containing missing values are dropped. These are useful if we don't want to drop
    a particular row/column if the `NaN` values do not exceed a certain percentage.
  prefs: []
  type: TYPE_NORMAL
- en: 'Two arguments that are useful for the `dropna()` method are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The `how` argument determines if a row or column is removed from a DataFrame
    when we have at least one `NaN` value or all `NaN` values.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `thresh` argument requires that many non-`NaN` values to keep the row/ column.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We'll practice using the `dropna()` method in the following exercise.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 4.06: Dropping Missing Values with dropna'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this exercise, we will remove the cells in a dataset that don't contain data.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'The `superstore` dataset file can be found here: [https://packt.live/3dcVnMs](https://packt.live/3dcVnMs).'
  prefs: []
  type: TYPE_NORMAL
- en: 'We are going to use the `dropna` method in order to remove missing cells in
    a dataset. To do so, let''s go through the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the necessary Python libraries and read the Excel file from GitHub by
    using the `read_excel` method in `pandas`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The highlighted path must be changed based on the location of the file on your
    system.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.35: Superstore dataset'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_04_35.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.35: Superstore dataset'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The outputs you get will vary from the ones shown in this exercise.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'To set the `axis` parameter to `zero` and drop all missing rows, use the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.36: Dropping all the missing rows'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_04_36.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.36: Dropping all the missing rows'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'To set the `axis` parameter to `1` and drop all missing rows, use the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.37: Dropping rows or columns to handle missing data'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_04_37.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.37: Dropping rows or columns to handle missing data'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Drop the values with `axis` set to `1` and `thresh` set to `10`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.38: DataFrame with values dropped with axis=1 and thresh=10'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_04_38.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.38: DataFrame with values dropped with axis=1 and thresh=10'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, some `NaN` values still exist, but because of the minimum threshold,
    those rows were kept in place.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/2Ybvx7t](https://packt.live/2Ybvx7t).
  prefs: []
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/30RNCsY](https://packt.live/30RNCsY).
  prefs: []
  type: TYPE_NORMAL
- en: In this exercise, we looked at dropping missing values rows and columns. This
    is a useful technique for a variety of cases, including when working with machine
    learning. Some machine learning models do not handle missing data well and removing
    them ahead of time can be best practices.
  prefs: []
  type: TYPE_NORMAL
- en: Outlier Detection Using a Simple Statistical Test
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As we''ve already discussed, outliers in a dataset can occur due to many factors
    and in many ways:'
  prefs: []
  type: TYPE_NORMAL
- en: Data entry errors
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Experimental errors (data extraction related)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Measurement errors due to noise or instrumental failure
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data processing errors (data manipulation or mutations due to coding errors)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sampling errors (extracting or mixing data from wrong or various sources)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is impossible to pinpoint one universal method for outlier detection. Here,
    we will show you some simple tricks for numeric data using standard statistical
    tests.
  prefs: []
  type: TYPE_NORMAL
- en: 'Box plots may show unusual values. We can corrupt two sales values by assigning
    negatives, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'To plot the box plot, use the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'The output (which will vary with each run) is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.39: Box plot of sales and profit'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15780_04_39.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 4.39: Box plot of sales and profit'
  prefs: []
  type: TYPE_NORMAL
- en: We can create simple box plots to check for any unusual/nonsensical values.
    For example, in the preceding example, we intentionally corrupted two sales values
    so that they were negative, and they were readily caught in a box plot.
  prefs: []
  type: TYPE_NORMAL
- en: Note that profit may be negative, so those negative points are generally not
    suspicious. But sales cannot be negative in general, so they are detected as outliers.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can create a distribution of a numerical quantity and check for values that
    lie at the extreme end to see if they are truly part of the data or outlier. For
    example, if a distribution is almost normal, then any value more than four or
    five standard deviations away may be a suspect:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.40: Value away from the main outliers'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15780_04_40.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 4.40: Value away from the main outliers'
  prefs: []
  type: TYPE_NORMAL
- en: Concatenating, Merging, and Joining
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Merging and joining tables or datasets are highly common operations in the day-to-day
    job of a data wrangling professional. These operations are akin to the `JOIN`
    query in SQL for relational database tables. Often, the key data is present in
    multiple tables, and those records need to be brought into one combined table
    that matches on that common key. This is an extremely common operation in any
    type of sales or transactional data, and therefore must be mastered by a data
    wrangler. The `pandas` library offers nice and intuitive built-in methods to perform
    various types of `JOIN` queries involving multiple DataFrame objects.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 4.07: Concatenation in Datasets'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this exercise, we will concatenate DataFrames along various axes (rows or columns).
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'The `superstore` dataset file can be found here: [https://packt.live/3dcVnMs](https://packt.live/3dcVnMs).'
  prefs: []
  type: TYPE_NORMAL
- en: 'This is a very useful operation as it allows you to grow a DataFrame as the
    new data comes in or new feature columns need to be inserted into the table. To
    do so, let''s go through the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Read the Excel file from GitHub by using the `read_excel` method in `pandas`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The highlighted path must be changed based on the location of the file on your
    system.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The output (partially shown) will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.41: Partial output of the DataFrame'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_04_41.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.41: Partial output of the DataFrame'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Sample `4` records each to create three DataFrames at random from the original
    sales dataset we are working with:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a combined DataFrame with all the rows concatenated by using the following
    code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output (partially shown) is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.42: Partial output after concatenating the DataFrames'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_04_42.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.42: Partial output after concatenating the DataFrames'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: As you can see, concatenation will vertically combine multiple DataFrames. You
    can also try concatenating along the columns, although that does not make any
    practical sense for this particular example. However, `pandas` fills in the unavailable
    values with `NaN` for that operation.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The outputs you get will vary from the ones shown in this exercise.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Create a combined DataFrame with all the columns concatenated by using the
    following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output (partially shown) is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.43: Partial output after concatenating the DataFrames'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_04_43.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.43: Partial output after concatenating the DataFrames'
  prefs: []
  type: TYPE_NORMAL
- en: As we can observe, the cells in the dataset that do not contain any values are
    replaced with `NaN` values.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/3epn5aB](https://packt.live/3epn5aB).
  prefs: []
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/3edUPrh](https://packt.live/3edUPrh).
  prefs: []
  type: TYPE_NORMAL
- en: Merging by a Common Key
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Merging by a common key is an extremely common operation for data tables as
    it allows you to rationalize multiple sources of data in one master database –
    that is, if they have some common features/keys.
  prefs: []
  type: TYPE_NORMAL
- en: 'When joining and merging two DataFrames, we use two separate types: **inner**
    and **outer {left|right}**. Let''s take a look at them:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Inner**: A combining method that uses a column or key to be compared on each
    dataset. Rows that share the same column or key will be present after the join.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Outer**: A way to combine datasets such as inner, but all data on the right
    or left (depending on which is chosen) is kept, and matching data from the opposite
    side is combined.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is often the first step in building a large database for machine learning
    tasks where daily incoming data may be put into separate tables. However, at the
    end of the day, the most recent table needs to be merged with the master data
    table so that it can be fed into the backend machine learning server, which will
    then update the model and its prediction capacity. Merge is a way to combine DataFrames
    vertically, using a column to compare on. The functionality of merge and join
    are very similar; their capabilities are the same.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 4.08: Merging by a Common Key'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this exercise, we''ll create two DataFrames with the `Customer Name` common
    key from the Superstore dataset. Then, we will use the inner and outer joins to
    merge or combine these DataFrames. To do so, let''s go through the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'The Superstore file can be found here: [https://packt.live/3dcVnMs](https://packt.live/3dcVnMs).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the necessary Python libraries and read the Excel file from GitHub by
    using the `read_excel` method in `pandas`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create the `df1` DataFrame with the `Customer Name` common key:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output of the first DataFrame is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.45: Entries in table df_1'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_04_45.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.45: Entries in table df_1'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Create the second DataFrame, `df2`, with the `Customer Name` common key, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.46: Entries in table df_2'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_04_46.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.46: Entries in table df_2'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Join these two tables with an inner join by using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.47: Inner join on table df_1 and table df_2'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_04_47.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.47: Inner join on table df_1 and table df_2'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Drop the duplicates by using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.48: Inner join on table df_1 and table df_2 after dropping the duplicates'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_04_48.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.48: Inner join on table df_1 and table df_2 after dropping the duplicates'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Extract another small table called `df_3` to show the concept of an outer join:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.49: Creating table df_3'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_04_49.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.49: Creating table df_3'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Perform an inner join on `df_1` and `df_3` by using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.50: Merging table df_1 and table df_3 and dropping duplicates'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_04_50.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.50: Merging table df_1 and table df_3 and dropping duplicates'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Perform an outer join on `df_1` and `df_3` by using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.51: Outer join on table df_1 and table df_3 and dropping the duplicates'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_04_51.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.51: Outer join on table df_1 and table df_3 and dropping the duplicates'
  prefs: []
  type: TYPE_NORMAL
- en: Notice how some `NaN` and `NaT` values are inserted automatically because no
    corresponding entries could be found for those records, as those are the entries
    with unique customer names from their respective tables. `NaT` represents a `Not
    a Time` object, as the objects in the `Ship Date` column are timestamped objects.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/2Y8G5UW](https://packt.live/2Y8G5UW).
  prefs: []
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/30RNUA4](https://packt.live/30RNUA4).
  prefs: []
  type: TYPE_NORMAL
- en: With this, we have gone over how to use the `merge` method to do inner and outer joins.
  prefs: []
  type: TYPE_NORMAL
- en: The join Method
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Joining is performed based on **index keys** and is done by combining the columns
    of two potentially differently indexed DataFrames into a single one. It offers
    a faster way to accomplish merging by row indices. This is useful if the records
    in different tables are indexed differently but represent the same inherent data
    and you want to merge them into a single table:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 4.09: The join Method'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this exercise, we will create two DataFrames and perform the different kind
    of joins on these DataFrames.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'The Superstore file can be found here: [https://packt.live/3dcVnMs](https://packt.live/3dcVnMs).'
  prefs: []
  type: TYPE_NORMAL
- en: 'To complete this exercise, perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the Python libraries and load the file from GitHub by using the `read_excel`
    method in `pandas`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The highlighted path must be changed based on the location of the file on your
    system.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The partial output of the code is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.52: Partial output of the DataFrame'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_04_52.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.52: Partial output of the DataFrame'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Create `df1` with `Customer Name` as the index by using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.53: DataFrame df_1'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_04_53.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.53: DataFrame df_1'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Create `df2` with `Customer Name` as the index by using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.54: DataFrame df_2'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_04_54.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.54: DataFrame df_2'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Perform a left join on `df_1` and `df_2` by using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.55: Left join on table df_1 and table df_2 after dropping the duplicates'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_04_55.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.55: Left join on table df_1 and table df_2 after dropping the duplicates'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Perform a right join on `df_1` and `df_2` by using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.56: Right join on table df_1 and table df_2 after dropping the duplicates'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_04_56.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.56: Right join on table df_1 and table df_2 after dropping the duplicates'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Perform an inner join on `df_1` and `df_2` by using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.57: Inner join on table df_1 and table df_2 after dropping the duplicates'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_04_57.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.57: Inner join on table df_1 and table df_2 after dropping the duplicates'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Perform an outer join on `df_1` and `df_2` by using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.58: Outer join on table df_1 and table df_2 after dropping the duplicates'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_04_58.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.58: Outer join on table df_1 and table df_2 after dropping the duplicates'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/30S9nZH](https://packt.live/30S9nZH).
  prefs: []
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/2NbDweg](https://packt.live/2NbDweg).
  prefs: []
  type: TYPE_NORMAL
- en: We have now gone through the basic functionality of `pandas` DataFrame joining.
    We used inner and out joining and showed you how we can use indexes to perform
    a join and how it can help in analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Useful Methods of Pandas
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will discuss some small utility functions that are offered
    by `pandas` so that we can work efficiently with DataFrames. They don't fall under
    any particular group of functions, so they are mentioned here under the Miscellaneous
    category. Let's discuss these miscellaneous methods in detail.
  prefs: []
  type: TYPE_NORMAL
- en: Randomized Sampling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will discuss random sampling data from our DataFrames. This
    is a very common task in a variety of pipelines, one of which is machine learning.
    Sampling is often used in machine learning data-wrangling pipelines when choosing
    which data to train and which data to test against. Sampling a random fraction
    of a big DataFrame is often very useful so that we can practice other methods
    on them and test our ideas. If you have a database table of 1 million records,
    then it is not computationally effective to run your test scripts on the full
    table.
  prefs: []
  type: TYPE_NORMAL
- en: However, you may also not want to extract only the first 100 elements as the
    data may have been sorted by a particular key and you may get an uninteresting
    table back, which may not represent the full statistical diversity of the parent
    database.
  prefs: []
  type: TYPE_NORMAL
- en: In these situations, the `sample` method comes in super handy so that we can
    randomly choose a controlled fraction of the DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 4.10: Randomized Sampling'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this exercise, we are going to randomly take five samples from the Superstore
    dataset and calculate a definite fraction of the data to be sampled. To do so,
    let''s go through the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'The Superstore file can be found here: [https://packt.live/3dcVnMs](https://packt.live/3dcVnMs).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the necessary Python modules and read them from GitHub by using the
    `read_excel` method in `pandas`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The highlighted path must be changed based on the location of the file on your
    system.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The partial output will be:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.59: Partial output of the DataFrame'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_04_59.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.59: Partial output of the DataFrame'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Specify the number of samples that we require from the DataFrame by using the
    following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The random output (partially shown) is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.60: DataFrame with five samples'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_04_60.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.60: DataFrame with five samples'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The outputs you get will vary from the ones shown in this exercise.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Specify a definite fraction (percentage) of the data to be sampled by using
    the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.61: Partial output of a DataFrame with 0.1% data sampled'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_04_61.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.61: Partial output of a DataFrame with 0.1% data sampled'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You can also choose if sampling is done with replacement, that is, whether the
    same record can be chosen more than once. The default `replace` choice is `FALSE`,
    that is, no repetition and sampling will try to choose new elements only.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Choose the sampling by using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.62: DataFrame with 0.1% data sampled and repetition enabled'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_04_62.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.62: DataFrame with 0.1% data sampled and repetition enabled'
  prefs: []
  type: TYPE_NORMAL
- en: Here, as you can see, we have encouraged repetitions in the sampled data by
    setting the `replace` parameter to `True`. Therefore, the same elements could
    be chosen again while performing random sampling.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/2N7fWzt](https://packt.live/2N7fWzt).
  prefs: []
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/2YLTt0f](https://packt.live/2YLTt0f).
  prefs: []
  type: TYPE_NORMAL
- en: The value_counts Method
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We discussed the `unique` method previously, which finds and counts the unique
    records from a DataFrame. Another useful function in a similar vein is `value_counts`.
    This function returns an object containing counts of unique values. In the object
    that is returned, the first element is the most frequently used object. The elements
    are arranged in descending order.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s consider a practical application of this method to illustrate its utility.
    Suppose your manager asks you to list the top 10 customers from the big sales
    database that you have. So, the business question is: which 10 customers'' names
    occur the most frequently in the sales table? You can achieve this with a SQL
    query if the data is in an RDBMS, but in pandas, this can be done by using one
    simple function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.63: List of top 10 customers'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15780_04_63.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 4.63: List of top 10 customers'
  prefs: []
  type: TYPE_NORMAL
- en: The `value_counts` method returns a series of counts of all unique customer
    names sorted by the frequency of the count. By asking for only the first 10 elements
    of that list, this code returns a series of the most frequently occurring top
    10 customer names.
  prefs: []
  type: TYPE_NORMAL
- en: Pivot Table Functionality
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Similar to group by, pandas also offer pivot table functionality, which works
    the same as a Pivot Table in spreadsheet programs such as MS Excel. For example,
    in this sales database, you want to know the average sales, profit, and quantity
    sold by Region and State (two levels of index).
  prefs: []
  type: TYPE_NORMAL
- en: 'We can extract this information by using one simple piece of code (we sample
    100 records first to keep the computation fast and then apply the code):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows (note that your specific output may be different due
    to random sampling):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.64: Sample of 100 records'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B15780_04_64.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 4.64: Sample of 100 records'
  prefs: []
  type: TYPE_NORMAL
- en: Sorting a table by a particular column is one of the most frequently used operations
    in the daily work of an analyst. Sorting can help you understand your data better
    while presenting it in a specific view of the data. When training a machine learning
    model, the way data is sorted can impact the performance of a model based on the
    sampling that's being done. Not surprisingly, `pandas` provide a simple and intuitive
    method for sorting called the `sort_values` method. We'll practice using this
    in the following exercise.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 4.11: Sorting by Column Values – the sort_values Method'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this exercise, we will take a random sample of `15` records from the Superstore dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'The Superstore file can be found here: [https://packt.live/3dcVnMs](https://packt.live/3dcVnMs).'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will sort the column values in the dataset with respect to column names
    using the `sort_values` method. To do so, let''s go through the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the necessary Python modules and read the Excel file from GitHub by
    using the `read_excel` method in `pandas`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The highlighted path must be changed based on the location of the file on your
    system.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The output (partially shown) will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.65: Partial output of the DataFrame'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_04_65.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.65: Partial output of the DataFrame'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Take a random sample of `15` records and then sort by the `Sales` column and
    then by both the `Sales` and `State` columns together:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.66: Sample of 15 records'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_04_66.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.66: Sample of 15 records'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The outputs you get will vary from the ones shown in this exercise.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Sort the values with respect to `Sales` by using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.67: DataFrame with the Sales value sorted'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_04_67.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.67: DataFrame with the Sales value sorted'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Sort the values with respect to `Sales` and `State`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.68: DataFrame sorted with respect to Sales and State'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_04_68.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.68: DataFrame sorted with respect to Sales and State'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/3dcWNXi](https://packt.live/3dcWNXi).
  prefs: []
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/30UqwSn](https://packt.live/30UqwSn).
  prefs: []
  type: TYPE_NORMAL
- en: The `pandas` library provides great flexibility for working with user-defined
    functions of arbitrary complexity through the `apply` method. Much like the native
    Python `apply` function, this method accepts a user-defined function and additional
    arguments and returns a new column after applying the function on a particular
    column elementwise.
  prefs: []
  type: TYPE_NORMAL
- en: As an example, suppose we want to create a column of categorical features such
    as high/medium/low based on the sales price column. Note that this is a conversion
    from a numeric value into a categorical factor (string) based on certain conditions
    (threshold values of sales).
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 4.12: Flexibility of User-Defined Functions with the apply Method'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this exercise, we will create a user-defined function called `categorize_sales`
    that categorizes Sales data based on price. If the `price` is less than `50`,
    it is classified as `Low`, if the `price` is less than `200`, it is classified
    as `Medium`, or `High` if the `price` doesn't fall under either of these categories.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'The Superstore file can be found here: [https://packt.live/3dcVnMs](https://packt.live/3dcVnMs).'
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll then take 100 random samples from the `superstore` dataset and use the
    `apply` method on the `categorize_sales` function in order to create a new column
    to store the values returned by the function. To do so, perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the necessary Python modules and read the Excel file from GitHub by
    using the `read_excel` method in `pandas`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The highlighted path must be changed based on the location of the file on your
    system.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The output (partially shown) will be:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.69: Partial output of the DataFrame'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_04_69.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.69: Partial output of the DataFrame'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Create a user-defined function, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Sample `100` records randomly from the database:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.70: 100 sample records from the database'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_04_70.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.70: 100 sample records from the database'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The outputs you get will vary from the ones shown in this exercise.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Use the `apply` method to apply the categorization function to the `Sales`
    column. We need to create a new column to store the category string values that
    are returned by the function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.71: DataFrame with 10 rows after using the apply function on the
    Sales column'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_04_71.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.71: DataFrame with 10 rows after using the apply function on the Sales
    column'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The `apply` method also works with the built-in native Python functions.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'For practice, let''s create another column for storing the length of the name
    of the customer. We can do this using the familiar `len` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.72: DataFrame with a new column'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_04_72.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.72: DataFrame with a new column'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Instead of writing out a separate function, we can even insert *lambda expressions*
    directly into the `apply` method for short functions. For example, let's say we
    are promoting our product and want to show the discounted sales price if the original
    price is *> $200*.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Use a `lambda` function and the `apply` method to do so:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.73: Lambda function'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_04_73.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.73: Lambda function'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: The lambda function contains a conditional, and a discount is applied to those
    records where the original sales price is `>$200`.
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/3ddJYwa](https://packt.live/3ddJYwa).
  prefs: []
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/3d63D0Y](https://packt.live/3d63D0Y).
  prefs: []
  type: TYPE_NORMAL
- en: After going through this exercise, we know how to apply a function to a column
    in a DataFrame. This method is very useful for going beyond the basic functions
    that are present in `pandas`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 4.01: Working with the Adult Income Dataset (UCI)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this activity, we will detect outliers in the Adult Income Dataset from the
    UCI machine learning portal [https://packt.live/2N9lRUU](https://packt.live/2N9lRUU).
  prefs: []
  type: TYPE_NORMAL
- en: You can find a description of the dataset [https://packt.live/2N9lRUU](https://packt.live/2N9lRUU).
    We will use the concepts we've learned throughout this chapter, such as subsetting,
    applying user-defined functions, summary statistics, visualizations, boolean indexing,
    and group by to find a whole group of outliers in a dataset. We will create a
    bar plot to plot this group of outliers. Finally, we will merge two datasets by
    using a common key.
  prefs: []
  type: TYPE_NORMAL
- en: 'These are the steps that will help you solve this activity:'
  prefs: []
  type: TYPE_NORMAL
- en: Load the necessary libraries.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Read the adult income dataset from the following URL: [https://packt.live/2N9lRUU](https://packt.live/2N9lRUU).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a script that will read a text file line by line.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add a name of `Income` for the response variable to the dataset.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Find the missing values.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a DataFrame with only age, education, and occupation by using subsetting.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Plot a histogram of age with a bin size of `20`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a function to strip the whitespace characters.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use the `apply` method to apply this function to all the columns with string
    values, create a new column, copy the values from this new column to the old column,
    and drop the new column.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Find the number of people who are aged between `30` and `50`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Group the records based on age and education to find how the mean age is distributed.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Group by occupation and show the summary statistics of age. Find which profession
    has the oldest workers on average and which profession has its largest share of
    the workforce above the 75th percentile.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use `subset` and `groupBy` to find the outliers.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Plot the outlier values on a bar chart. It should look something like this:![Figure
    4.74: Bar plot displaying the outliers'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B15780_04_74.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.74: Bar plot displaying the outliers'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Merge the two DataFrames using common keys to drop duplicate values.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The output should look like this:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 4.75: Merged DataFrame'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B15780_04_75.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 4.75: Merged DataFrame'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: The solution for this activity can be found via [this link](B15780_Solution_Final_RK.xhtml#_idTextAnchor314).
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, we now have a single DataFrame because we have merged two DataFrames
    into one.
  prefs: []
  type: TYPE_NORMAL
- en: With that, we conclude this activity and the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we deep-dived into the `pandas` library to learn advanced data
    wrangling techniques. We started with some advanced subsetting and filtering on
    DataFrames and rounded this off by learning about boolean indexing and conditionally
    selecting a subset of data. We also covered how to set and reset the index of
    a DataFrame, especially while initializing.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we learned about a particular topic that has a deep connection with traditional
    relational database systems – the `groupBy` method. Then, we deep-dived into an
    important skill for data wrangling – checking for and handling missing data. We
    showed you how pandas helps in handling missing data using various imputation
    techniques. We also discussed methods for dropping missing values. Furthermore,
    methods and usage examples of concatenation and merging DataFrame objects were
    shown. We saw the `join` method and how it compares to a similar operation in
    SQL.
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, miscellaneous useful methods on DataFrames, such as randomized sampling,
    `unique`, `value_count`, `sort_values`, and pivot table functionality were covered.
    We also showed an example of running an arbitrary user-defined function on a DataFrame
    using the `apply` method.
  prefs: []
  type: TYPE_NORMAL
- en: After learning about the basic and advanced data wrangling techniques with the
    `numpy` and `pandas` libraries, the natural question of data acquisition rises.
    In the next chapter, we will show you how to work with a wide variety of data
    sources; that is, you will learn how to read data in tabular format in `pandas`
    from different sources.
  prefs: []
  type: TYPE_NORMAL
