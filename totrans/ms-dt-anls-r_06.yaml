- en: Chapter 6. Beyond the Linear Trend Line (authored by Renata Nemeth and Gergely
    Toth)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Linear regression models, which we covered in the previous chapter, can handle
    continuous responses that have a linear association with the predictors. In this
    chapter, we will extend these models to allow the response variable to differ
    in distribution. But, before getting our hands dirty with the generalized linear
    models, we need to stop for a while and discuss regression models in general.
  prefs: []
  type: TYPE_NORMAL
- en: The modeling workflow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: First, some words about the terminology. Statisticians call the *Y* variable
    the response, the outcome, or the dependent variable. The *X* variables are often
    called the predictors, the explanatory variables, or the independent variables.
    Some of the predictors are of our main interest, other predictors are added just
    because they are potential confounders. Continuous predictors are sometimes called
    covariates.
  prefs: []
  type: TYPE_NORMAL
- en: The GLM is a generalization of linear regression. GLM (also referred to as `glm`
    in R, from the `stats` package) allows the predictors to be related to the response
    variable via a link function, and by allowing the magnitude of the variance of
    each measurement to be a function of its predicted value.
  prefs: []
  type: TYPE_NORMAL
- en: Whatever regression model you use, the main question is, "in what form can we
    add continuous predictors to the model?" If the relationship between the response
    and the predictor does not meet the model assumptions, you can transform the variable
    in some way. For example, a logarithmic or quadratic transformation in a linear
    regression model is a very common way to solve the problem of non-linear relationships
    between the independent and dependent variables via linear formulas.
  prefs: []
  type: TYPE_NORMAL
- en: Or, you can transform the continuous predictor into a discrete one by subdividing
    its range in a proper way. When choosing the classes, one of the best options
    is to follow some convention, like choosing 18 as a cut-point in the case of age.
    Or you can follow a more technical way, for example, by categorizing the predictor
    into quantiles. An advanced way to go about this process would be to use some
    classification or regression trees, on which you will be able to read more in
    [Chapter 10](ch10.html "Chapter 10. Classification and Clustering"), *Classification
    and Clustering*.
  prefs: []
  type: TYPE_NORMAL
- en: Discrete predictors can be added to the model as dummy variables using reference
    category coding, as we have seen in the previous chapter for linear regression
    models.
  prefs: []
  type: TYPE_NORMAL
- en: 'But how do we actually build a model? We have compiled a general workflow to
    answer this question:'
  prefs: []
  type: TYPE_NORMAL
- en: First, fit the model with the main predictors and all the relevant confounders,
    and then reduce the number of confounders by dropping out the non-significant
    ones. There are some automatic procedures (such as backward elimination) for this.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
- en: The given sample size limits the number of predictors. A rule of thumb for the
    required sample size is that you should have at least 20 observations per predictor.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Decide whether to use the continuous variables in their original or categorized
    form.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Try to achieve a better fit by testing for non-linear relationships, if they
    are pragmatically relevant.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, check the model assumptions.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: And how do we find the best model? Is it as simple as the better the fit, the
    better the model? Unfortunately not. Our aim is to find the best fitting model,
    but with as few predictors as possible. A good model fit and a low number of independent
    variables are contradictory to each other.
  prefs: []
  type: TYPE_NORMAL
- en: As we have seen earlier, entering newer predictors into a linear regression
    model always increases the value of R-squared, and it may result in an over-fitted
    model. Overfitting means that the model describes the sample with its random noise,
    instead of the underlying data-generating process. Overfitting occurs, for example,
    when we have too many predictors in the model for its sample size to accommodate.
  prefs: []
  type: TYPE_NORMAL
- en: Consequently, the best model gives the desired level of fit with as few predictors
    as possible. AIC is one of those proper measures that takes into account both
    fit and parsimony. We highly recommend using it when comparing different models,
    which is very easy via the `AIC` function from the `stats` package.
  prefs: []
  type: TYPE_NORMAL
- en: Logistic regression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we have discussed linear regression models, an appropriate method to
    model continuous response variables. However, non-continuous, binary responses
    (such as being ill or healthy, being faithful or deciding to switch to a new job,
    mobile supplier or partner) are also very common. The main difference compared
    to the continuous case is that now we should rather model probability instead
    of the expected value of the response variable.
  prefs: []
  type: TYPE_NORMAL
- en: The naive solution would be to use the probability as outcome in a linear model.
    But the problem with this solution is that the probability should be always between
    0 and 1, and this bounded range is not guaranteed at all when using a linear model.
    A better solution is to fit a logistic regression model, which models not only
    the probability but also the natural logarithm of the odds, called the **logit**.
    The logit can be any (positive or negative) number, so the problem of limited
    range is eliminated.
  prefs: []
  type: TYPE_NORMAL
- en: Let's have a simple example of predicting the probability of the death penalty,
    using some information on the race of the defendant. This model relates to the
    much more complicated issue of racism in the infliction of the death penalty,
    a question with a long history in the USA. We will use the `deathpenalty` dataset
    from the `catdata` package about the judgment of defendants in cases of multiple
    murders in Florida between 1976 and 1987\. The cases are classified with respect
    to the death penalty (where 0 refers to no, 1 to yes), the race of the defendant,
    and the race of the victim (black is referred as 0, white is 1).
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we expand the frequency table into case form via the `expand.dtf` function
    from the `vcdExtra` package, then we fit our first generalized model in the dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The regression coefficient is statistically not significant, so at first sight,
    we can''t see a racial bias in the data. Anyway, for didactic purposes, let''s
    interpret the regression coefficient. It''s `0.37`, which means that the natural
    logarithm of the odds of getting a death penalty increases by 0.37 when moving
    from the black category to the white one. This difference is easily interpretable
    if you take its exponent, which is the ratio of the odds:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The odds ratio pertaining to the race of the defendant is `1.45`, which means
    that white defendants have 45 percent larger odds of getting the death penalty
    than black defendants.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Although R produces this, the odds ratio for the intercept is generally not
    interpreted.
  prefs: []
  type: TYPE_NORMAL
- en: We can say something more general. We have seen that in linear regression models,
    the regression coefficient, *b*, can be interpreted as a one unit increase in
    *X* increases *Y* by *b*. But, in logistic regression models, a one unit increase
    in *X* multiplies the odds of *Y* by `exp(b)`.
  prefs: []
  type: TYPE_NORMAL
- en: Please note that the preceding predictor was a discrete one, with values of
    0 (black) and 1 (white), so it's basically a dummy variable for white, and black
    is the reference category. We have seen the same solution for entering discrete
    variables in the case of linear regression models. If you have more than two racial
    categories, you should define a second dummy for the third race and enter it into
    the model as well. The exponent of each dummy variables' coefficients equal to
    the odds ratio, which compares the given category to the reference. If you have
    a continuous predictor, the exponent of the coefficient equals to the odds ratio
    pertaining to a one unit increase in the predictor.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s enter the race of the victim into the examination, since it''s
    a plausible confounder. Let''s control for it, and fit the logistic regression
    model with both the `DefendantRace` and `VictimRace` as predictors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'When controlling for `VictimRace`, the effect of `DefendantRace` becomes significant!
    The odds ratio is `0.42`, which means that white defendants'' odds of getting
    the death penalty are only 42 percent of the odds of black defendants, holding
    the race of the victim fixed. Also, the odds ratio of `VictimRace` (11.07) shows
    an extremely strong effect: killers of white victims are 11 times more likely
    to get a death penalty than killers of black victims.'
  prefs: []
  type: TYPE_NORMAL
- en: 'So, the effect of `DefendantRace` is exactly the opposite of what we have got
    in the one-predictor model. The reversed association may seem to be paradoxical,
    but it can be explained. Let''s have a look at the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The data seems to be homogeneous in some sense: black defendants are more likely
    to have black victims, and vice versa. If you put these pieces of information
    together, you start to see that black defendants yield a smaller proportion of
    death sentences just because they are more likely to have black victims, and those
    who have black victims are less likely to get a death penalty. The paradox disappears:
    the crude death penalty and `DefendantRace` association was confounded by `VictimRace`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To sum it up, it seems that taking the available information into account,
    you can come to the following conclusions:'
  prefs: []
  type: TYPE_NORMAL
- en: Black defendants are more likely to get the death penalty
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Killing a white person is considered to be a more serious crime than killing
    a black person
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Of course, you should draw such conclusions extremely carefully, as the question
    of racial bias needs a very thorough analysis using all the relevant information
    regarding the circumstances of the crime, and much more.
  prefs: []
  type: TYPE_NORMAL
- en: Data considerations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Logistic regression models work on the assumption that the observations are
    totally independent from each other. This assumption is violated, for example,
    if your observations are consecutive years. The deviance residuals and other diagnostic
    statistics can help validate the model and detect problems such as the misspecification
    of the link function. For further reference, see the `LogisticDx` package.
  prefs: []
  type: TYPE_NORMAL
- en: As a general rule of thumb, logistic regression models require at least 10 events
    per predictors, where an event denotes the observations belonging to the less
    frequent category in the response. In our death penalty example, death is the
    less frequent category in the response, and we have 68 death sentences in the
    database. So, the rule suggests that a maximum of 6-7 predictors are allowed.
  prefs: []
  type: TYPE_NORMAL
- en: The regression coefficients are estimated using the maximum likelihood method.
    Since there is no closed mathematical form to get these ML estimations, R uses
    an optimization algorithm instead. In some cases, you may get an error message
    that the algorithm doesn't reach convergence. In such cases, it is unable to find
    an appropriate solution. This may occur for a number of reasons, such as having
    too many predictors, too few events, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Goodness of model fit
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One measure of model fit, to evaluate the performance of the model, is the significance
    of the overall model. The corresponding likelihood ratio tests whether the given
    model fits significantly better than a model with just an intercept, which we
    call the null model.
  prefs: []
  type: TYPE_NORMAL
- en: To obtain the test results, you have to look at the residual deviance in the
    output. It measures the disagreement between the maxima of the observed and the
    fitted log likelihood functions.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Since logistic regression follows the maximal likelihood principle, the goal
    is to minimize the sum of the deviance residuals. Therefore, this residual is
    parallel to the raw residual in linear regression, where the goal is to minimize
    the sum of squared residuals.
  prefs: []
  type: TYPE_NORMAL
- en: 'The null deviance represents how well the response is predicted by a model
    with nothing but an intercept. To judge the model, you have to compare the residual
    deviance to the null deviance; the difference follows a chi-square distribution.
    The corresponding test is available in the `lmtest` package:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The *p* value indicates a highly significant decrease in deviance. This means
    that the model is significant, and the predictors have a significant effect on
    the response probability.
  prefs: []
  type: TYPE_NORMAL
- en: You can think of the likelihood ratio as the F-test in the linear regression
    models. It reveals if the model is significant, but it doesn't tell anything about
    the goodness-of-fit, which was described by the adjusted R-squared measure in
    the linear case.
  prefs: []
  type: TYPE_NORMAL
- en: 'An equivalent statistic for logistic regression models does not exist, but
    several pseudo R-squared have been developed. These usually range from 0 to 1
    with higher values indicating a better fit. We will use the `PseudoR2` function
    from the `BaylorEdPsych` package to compute this value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: But be careful, the pseudo R-squared cannot be interpreted as an OLS R-squared,
    and there are some documented problems with them as well, but they give us a rough
    picture. In our case, they say that the explanative power of the model is rather
    low, which is not surprising if we consider the fact that only two predictors
    were used in the modeling of such a complex process as judging a crime.
  prefs: []
  type: TYPE_NORMAL
- en: Model comparison
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we have seen in the previous chapter, the adjusted R-squared provides a good
    base for model comparison when dealing with nested linear regression models. For
    nested logistic regression models, you can use the likelihood ratio test (such
    as the `lrtest` function from the `lmtest` library), which compares the difference
    between the residual deviances.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '`LogLiK`, in the preceding output denotes the log-likelihood of the model;
    you got the residual deviance by multiplying it by 2.'
  prefs: []
  type: TYPE_NORMAL
- en: For un-nested models, you can use AIC, just like we did in the case of linear
    regression models, but in logistic regression models, AIC is part of the standard
    output, so there is no need to call the AIC function separately. Here, the `binom.model.1`
    has a lower AIC than `binom.model.0`, and the difference is not negligible since
    it is greater than 2.
  prefs: []
  type: TYPE_NORMAL
- en: Models for count data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Logistic regression can handle only binary responses. If you have count data,
    such as the number of deaths or failures in a given period of time, or in a given
    geographical area, you can use Poisson or negative binomial regression. These
    data types are particularly common when working with aggregated data, which is
    provided as a number of events classified in different categories.
  prefs: []
  type: TYPE_NORMAL
- en: Poisson regression
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Poisson regression models are generalized linear models with the logarithm as
    the link function, and they assume that the response has a **Poisson distribution**.
    The Poisson distribution takes only integer values. It is appropriate for count
    data, such as events occurring over a fixed period of time, that is, if the events
    are rather rare, such as a number of hard drive failures per day.
  prefs: []
  type: TYPE_NORMAL
- en: In the following example, we will use the Hard Drive Data Sets for the year
    of 2013\. The dataset was downloaded from [https://docs.backblaze.com/public/hard-drive-data/2013_data.zip](https://docs.backblaze.com/public/hard-drive-data/2013_data.zip),
    but we polished and simplified it a bit. Each record in the original database
    corresponds to a daily snapshot of one drive. The failure variable, our main point
    of interest, can be either zero (if the drive is OK), or one (on the last day
    of the hard drive before failing).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s try to determine which factors affect the appearance of a failure. The
    potential predictive factors are the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`model`: The manufacturer-assigned model number of the drive'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`capacity_bytes`: The drive capacity in bytes'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`age_month`: The drive age in the average month'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`temperature`: The hard disk drive temperature'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`PendingSector`: A logical value indicating the occurrence of unstable sectors
    (waiting for remapping on the given hard drive, on the given day)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We aggregated the original dataset by these variables, where the `freq` variable
    denotes the number of records in the given category. It''s time to load this final,
    cleansed, and aggregated dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Take a quick look at the number of failures by model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s get rid of those hard-drive models that didn''t have any failure,
    by removing all rows from the preceding table where there are only zeros beside
    the first column:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'To get a quick overview on the number of failures, let''s plot a histogram
    on a log scale by model numbers, with the help of the `ggplot2` package:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '![Poisson regression](img/2028OS_05_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Now, it's time to fit a Poisson regression model to the data, using the `model`
    number as the predictor. The model can be fitted using the `glm` function with
    the option, `family=poisson`. By default, the expected log count is modeled, so
    we use the `log` link.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the database, each observation corresponds to a group with a varying number
    of hard drives. As we need to handle the different group sizes, we will use the
    `offset` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'First, let''s interpret the coefficients. The model number is a discrete predictor,
    so we entered a number of dummy variables to represent it is as a predictor. The
    reference category is not present in the output by default, but we can query it
    at any time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'So, it turns out that the reference category is `HGST`, and the dummy variables
    compare each model with the `HGST` hard drive. For example, the coefficient of
    `Hitachi` is `1.77`, so the expected log-count for `Hitachi` drives is about 1.77
    greater than those for `HGST` drives. Or, you can compute its exponent when speaking
    about ratios instead of differences:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'So, the expected number of failures for `Hitachi` drives is 5.85 times greater
    than for `HGST` drives. In general, the interpretation goes as: a one unit increase
    in *X* multiplies *Y* by `exp(b)`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Similar to logistic regression, let''s determine the significance of the model.
    To do this, we compare the present model to the null model without any predictors,
    so the difference between the residual deviance and the null deviance can be identified.
    We expect the difference to be large enough, and the corresponding chi-squared
    test to be significant:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: And it seems that the model is significant, but we should also try to determine
    whether any of the model assumptions might fail.
  prefs: []
  type: TYPE_NORMAL
- en: Just like we did with the linear and logistic regression models, we have an
    independence assumption, where Poisson regression assumes the events to be independent.
    This means that the occurrence of one failure will not make another more or less
    likely. In the case of drive failures, this assumption holds. Another important
    assumption comes from the fact that the response has a Poisson distribution with
    an equal mean and variance. Our model assumes that the variance and the mean,
    conditioned on the predictor variables, will be approximately equal.
  prefs: []
  type: TYPE_NORMAL
- en: To decide whether the assumption holds, we can compare the residual deviance
    to its degree of freedom. For a well-fitting model, their ratio should be close
    to one. Unfortunately, the reported residual deviance is `17622` on `9844` degrees
    of freedom, so their ratio is much above one, which suggests that the variance
    is much greater than the mean. This phenomenon is called **overdispersion**.
  prefs: []
  type: TYPE_NORMAL
- en: Negative binomial regression
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In such a case, a negative binomial distribution can be used to model an over-dispersed
    count response, which is a generalization of the Poisson regression since it has
    an extra parameter to model the over-dispersion. In other words, Poisson and the
    negative binomial models are nested models; the former is a subset of the latter
    one.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following output, we use the `glm.nb` function from the `MASS` package
    to fit a negative binomial regression to our drive failure data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'To compare this model''s performance to the Poisson model, we can use the likelihood
    ratio test, since the two models are nested. The negative binomial model shows
    a significantly better fit:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: This result clearly suggests choosing the negative binomial model.
  prefs: []
  type: TYPE_NORMAL
- en: Multivariate non-linear models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: So far, the only predictor in our model was the model name, but we have other
    potentially important information about the drives as well, such as capacity,
    age, and temperature. Now let's add these to the model, and determine whether
    the new model is better than the original one.
  prefs: []
  type: TYPE_NORMAL
- en: 'Furthermore, let''s check the importance of `PendingSector` as well. In short,
    we define a two-step model building procedure with the nested models; hence we
    can use likelihood ratio statistics to test whether the model fit has significantly
    increased in both steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Both of these steps are significant, so it was worth adding each predictor
    to the model. Now, let''s interpret the best model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Each predictor is significant—with a few exceptions of some contrast in model
    type. For example, `Toshiba` doesn't differ significantly from the reference category,
    `HGST`, when controlling for age, temperature, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'The interpretation of the negative binomial regression parameters is similar
    to the Poisson model. For example, the coefficient of `age_month` is 0.048, which
    shows that a one month increase in age, increases the expected log-count of failures
    by 0.048\. Or, you can opt for using exponentials as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'So, it seems that one month in a lifetime increases the expected number of
    failures by 4.9 percent, and a larger capacity also increases the number of failures.
    On the other hand, temperature shows a reversed effect: the exponent of the coefficient
    is 0.947, which says that one degree of increased warmth decreases the expected
    number of failures by 5.3 percent.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The effect of the model name can be judged on the basis of comparison to the
    reference category, which is `HGST` in our case. One may want to change this reference.
    For example, for the most common drive: `WDC`. This can be easily done by changing
    the order of the factor levels in hard drive models, or simply defining the reference
    category in the factor via the extremely useful `relevel` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s verify if `HGST` indeed replaced `WDC` in the coefficients list,
    but instead of the lengthy output of summary, we will use the `tidy` function
    from the `broom` package, which can extract the most important features (for the
    model summary, take a look at the `glance` function) of different statistical
    models:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Use the `broom` package to extract model coefficients, compare model fit, and
    other metrics to be passed to, for example, `ggplot2`.
  prefs: []
  type: TYPE_NORMAL
- en: The effect of temperature suggests that the higher the temperature, the lower
    the number of hard drive failures. However, everyday experiences show a very different
    picture, for example, as described at [https://www.backblaze.com/blog/hard-drive-temperature-does-it-matter](https://www.backblaze.com/blog/hard-drive-temperature-does-it-matter).
    Google engineers found that temperature was not a good predictor of failure, while
    Microsoft and the University of Virginia found that it had a significant effect.
    Disk drive manufacturers suggest keeping disks at cooler temperatures.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, let''s take a closer look at this interesting question, and we will have
    the `temperature` as a predictor of drive failure. First, let''s classify temperature
    into six equal categories, and then we will draw a bar plot presenting the mean
    number of failures per categories. Note that we have to take into account the
    different groups'' sizes, so we will weight by `freq`, and as we are doing some
    data aggregation, it''s the right time to convert our dataset into a `data.table`
    object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '![Multivariate non-linear models](img/2028OS_05_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The assumption of linear relation is clearly not supported. The bar plot suggests
    using the temperature in this classified form, instead of the original continuous
    variable when entering the model. To actually see which model is better, let''s
    compare those! Since they are not nested, we have to use the AIC, which strongly
    supports the categorized version:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Well, it was really worth categorizing temperature! Now, let''s check the other
    two continuous predictors as well. Again, we will use `freq` as a weighting factor:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'As in the previous plots, we will use `ggplot2` to plot the distribution of
    these discrete variables, but instead of a bar plot, we will use a stair-line
    chart to overcome the issue of the fixed width of bar charts:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '![Multivariate non-linear models](img/2028OS_05_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The relations are again, clearly not linear. The case of `age` is particularly
    interesting; there seems to be highly risky periods in the hard drives'' lifetime.
    Now, let''s force R to use `capacity` as a nominal variable (it has only five
    values, so there is no real need to categorize it), and let''s classify `age`
    into 8 equally sized categories:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'According to the AIC, the last model with the categorized age and capacity
    is much better, and is the best fitting model so far:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'If you look at the parameter estimates, you can see that the first dummy variable
    on capacity significantly differ from the reference:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: The next three capacities are more likely to cause failures, but the trend is
    not linear. The effect of age also does not seem to be linear. In general, aging
    increases the number of failures, but there are some exceptions. For example,
    drives are significantly more likely to have a failure in the first (reference)
    age group than in the second one. This finding is plausible since drives have
    a higher failure rate at the beginning of their operation. The effect of temperature
    suggests that the middle temperature (22-30 degrees Celsius) is more likely to
    cause failures than low or high temperatures. Remember that each effect is controlled
    for every other predictor.
  prefs: []
  type: TYPE_NORMAL
- en: It would also be important to judge the effect-size of different predictors,
    comparing them to each other. As a picture is worth a thousand words, let's summarize
    the coefficients with the confidence intervals in one plot.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we have to extract the significant terms from the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, let''s identify the confidence intervals of the coefficients using the
    `confint` function and the good old `plyr` package:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Unfortunately, this resulting data frame is not yet complete. We need to add
    the term names, and also, let''s extract the grouping variables via a simple,
    regular expression:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'And now we have the confidence intervals of the coefficients in a nicely formatted
    dataset, which can be easily plotted by `ggplot`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: '![Multivariate non-linear models](img/2028OS_05_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: It can be easily seen that although each predictor is significant, the size
    of their effects strongly differ. For example, `PendingSector` has just a slight
    effect on the number of failures, but `age`, `capacity`, and `temperature` have
    a much stronger effect, and the hard drive model is the predictor that best differentiates
    the number of failures.
  prefs: []
  type: TYPE_NORMAL
- en: 'As we have mentioned in the *Logistic regression* section, different pseudo
    R-squared measures are available for nonlinear models as well. We again warn you
    to use these metrics with reservation. Anyway, in our case, they uniformly suggest
    the model''s explanative power to be pretty good:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This chapter introduced three well known nonlinear regression models: the logistic,
    Poisson, and negative binomial models, and you became familiar with the general
    logic of modeling. It was also shown how the same concepts, such as effect of
    predictors, goodness of fit, explanative power, model comparison for nested and
    non-nested models, and model building are applied in different contexts. Now,
    having spent some time on mastering the data analysis skills, in the next chapter,
    we will get back to some hardcore data science problems, such as the cleansing
    and structuring of data.'
  prefs: []
  type: TYPE_NORMAL
