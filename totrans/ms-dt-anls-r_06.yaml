- en: Chapter 6. Beyond the Linear Trend Line (authored by Renata Nemeth and Gergely
    Toth)
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Linear regression models, which we covered in the previous chapter, can handle
    continuous responses that have a linear association with the predictors. In this
    chapter, we will extend these models to allow the response variable to differ
    in distribution. But, before getting our hands dirty with the generalized linear
    models, we need to stop for a while and discuss regression models in general.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: The modeling workflow
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: First, some words about the terminology. Statisticians call the *Y* variable
    the response, the outcome, or the dependent variable. The *X* variables are often
    called the predictors, the explanatory variables, or the independent variables.
    Some of the predictors are of our main interest, other predictors are added just
    because they are potential confounders. Continuous predictors are sometimes called
    covariates.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: The GLM is a generalization of linear regression. GLM (also referred to as `glm`
    in R, from the `stats` package) allows the predictors to be related to the response
    variable via a link function, and by allowing the magnitude of the variance of
    each measurement to be a function of its predicted value.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: Whatever regression model you use, the main question is, "in what form can we
    add continuous predictors to the model?" If the relationship between the response
    and the predictor does not meet the model assumptions, you can transform the variable
    in some way. For example, a logarithmic or quadratic transformation in a linear
    regression model is a very common way to solve the problem of non-linear relationships
    between the independent and dependent variables via linear formulas.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: Or, you can transform the continuous predictor into a discrete one by subdividing
    its range in a proper way. When choosing the classes, one of the best options
    is to follow some convention, like choosing 18 as a cut-point in the case of age.
    Or you can follow a more technical way, for example, by categorizing the predictor
    into quantiles. An advanced way to go about this process would be to use some
    classification or regression trees, on which you will be able to read more in
    [Chapter 10](ch10.html "Chapter 10. Classification and Clustering"), *Classification
    and Clustering*.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: Discrete predictors can be added to the model as dummy variables using reference
    category coding, as we have seen in the previous chapter for linear regression
    models.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: 'But how do we actually build a model? We have compiled a general workflow to
    answer this question:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: First, fit the model with the main predictors and all the relevant confounders,
    and then reduce the number of confounders by dropping out the non-significant
    ones. There are some automatic procedures (such as backward elimination) for this.
  id: totrans-9
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  id: totrans-10
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
- en: The given sample size limits the number of predictors. A rule of thumb for the
    required sample size is that you should have at least 20 observations per predictor.
  id: totrans-11
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Decide whether to use the continuous variables in their original or categorized
    form.
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 决定是否使用连续变量在其原始形式或分类形式中。
- en: Try to achieve a better fit by testing for non-linear relationships, if they
    are pragmatically relevant.
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果它们在实用上相关，尝试通过测试非线性关系来提高拟合度。
- en: Finally, check the model assumptions.
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，检查模型假设。
- en: And how do we find the best model? Is it as simple as the better the fit, the
    better the model? Unfortunately not. Our aim is to find the best fitting model,
    but with as few predictors as possible. A good model fit and a low number of independent
    variables are contradictory to each other.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 那我们如何找到最佳模型呢？是不是拟合度越好，模型就越好？不幸的是并非如此。我们的目标是找到最佳拟合模型，但尽可能少地使用预测变量。良好的模型拟合和独立变量的低数量是相互矛盾的。
- en: As we have seen earlier, entering newer predictors into a linear regression
    model always increases the value of R-squared, and it may result in an over-fitted
    model. Overfitting means that the model describes the sample with its random noise,
    instead of the underlying data-generating process. Overfitting occurs, for example,
    when we have too many predictors in the model for its sample size to accommodate.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前看到的，将新的预测变量输入到线性回归模型中总是会增加R-squared的值，这可能会导致过度拟合的模型。过度拟合意味着模型描述的是样本的随机噪声，而不是潜在的数据生成过程。例如，当我们模型中的预测变量太多，以至于无法适应样本大小时，就会发生过度拟合。
- en: Consequently, the best model gives the desired level of fit with as few predictors
    as possible. AIC is one of those proper measures that takes into account both
    fit and parsimony. We highly recommend using it when comparing different models,
    which is very easy via the `AIC` function from the `stats` package.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，最佳模型以尽可能少的预测变量给出所需的拟合水平。AIC是那些考虑拟合和简洁性的适当度量之一。我们强烈建议在比较不同模型时使用它，这可以通过`stats`包中的`AIC`函数非常容易地完成。
- en: Logistic regression
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 逻辑回归
- en: So far, we have discussed linear regression models, an appropriate method to
    model continuous response variables. However, non-continuous, binary responses
    (such as being ill or healthy, being faithful or deciding to switch to a new job,
    mobile supplier or partner) are also very common. The main difference compared
    to the continuous case is that now we should rather model probability instead
    of the expected value of the response variable.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们讨论了线性回归模型，这是建模连续响应变量的适当方法。然而，非连续的二进制响应（如生病或健康，忠诚或决定换工作，移动供应商或合作伙伴）也非常常见。与连续情况相比，主要区别在于现在我们应该而不是建模响应变量的期望值，而是建模概率。
- en: The naive solution would be to use the probability as outcome in a linear model.
    But the problem with this solution is that the probability should be always between
    0 and 1, and this bounded range is not guaranteed at all when using a linear model.
    A better solution is to fit a logistic regression model, which models not only
    the probability but also the natural logarithm of the odds, called the **logit**.
    The logit can be any (positive or negative) number, so the problem of limited
    range is eliminated.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 天真的解决方案是在线性模型中将概率作为结果。但这个解决方案的问题在于概率应该始终在0和1之间，而使用线性模型时，这个有界范围根本无法保证。更好的解决方案是拟合逻辑回归模型，它不仅建模概率，还建模称为**logit**的赔率的自然对数。logit可以是任何（正或负）数字，因此消除了范围有限的问题。
- en: Let's have a simple example of predicting the probability of the death penalty,
    using some information on the race of the defendant. This model relates to the
    much more complicated issue of racism in the infliction of the death penalty,
    a question with a long history in the USA. We will use the `deathpenalty` dataset
    from the `catdata` package about the judgment of defendants in cases of multiple
    murders in Florida between 1976 and 1987\. The cases are classified with respect
    to the death penalty (where 0 refers to no, 1 to yes), the race of the defendant,
    and the race of the victim (black is referred as 0, white is 1).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用一个简单的例子来说明如何预测死刑的概率，使用一些关于被告种族的信息。这个模型与死刑执行中的种族主义问题密切相关，这是一个在美国有着悠久历史的问题。我们将使用来自`catdata`包的`deathpenalty`数据集，关于1976年至1987年佛罗里达州多起谋杀案中被告的判决。这些案件根据死刑（其中0表示没有，1表示有）进行分类，被告的种族和受害者的种族（黑人表示0，白人表示1）。
- en: 'First, we expand the frequency table into case form via the `expand.dtf` function
    from the `vcdExtra` package, then we fit our first generalized model in the dataset:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The regression coefficient is statistically not significant, so at first sight,
    we can''t see a racial bias in the data. Anyway, for didactic purposes, let''s
    interpret the regression coefficient. It''s `0.37`, which means that the natural
    logarithm of the odds of getting a death penalty increases by 0.37 when moving
    from the black category to the white one. This difference is easily interpretable
    if you take its exponent, which is the ratio of the odds:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The odds ratio pertaining to the race of the defendant is `1.45`, which means
    that white defendants have 45 percent larger odds of getting the death penalty
    than black defendants.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Although R produces this, the odds ratio for the intercept is generally not
    interpreted.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: We can say something more general. We have seen that in linear regression models,
    the regression coefficient, *b*, can be interpreted as a one unit increase in
    *X* increases *Y* by *b*. But, in logistic regression models, a one unit increase
    in *X* multiplies the odds of *Y* by `exp(b)`.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: Please note that the preceding predictor was a discrete one, with values of
    0 (black) and 1 (white), so it's basically a dummy variable for white, and black
    is the reference category. We have seen the same solution for entering discrete
    variables in the case of linear regression models. If you have more than two racial
    categories, you should define a second dummy for the third race and enter it into
    the model as well. The exponent of each dummy variables' coefficients equal to
    the odds ratio, which compares the given category to the reference. If you have
    a continuous predictor, the exponent of the coefficient equals to the odds ratio
    pertaining to a one unit increase in the predictor.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s enter the race of the victim into the examination, since it''s
    a plausible confounder. Let''s control for it, and fit the logistic regression
    model with both the `DefendantRace` and `VictimRace` as predictors:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'When controlling for `VictimRace`, the effect of `DefendantRace` becomes significant!
    The odds ratio is `0.42`, which means that white defendants'' odds of getting
    the death penalty are only 42 percent of the odds of black defendants, holding
    the race of the victim fixed. Also, the odds ratio of `VictimRace` (11.07) shows
    an extremely strong effect: killers of white victims are 11 times more likely
    to get a death penalty than killers of black victims.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: 'So, the effect of `DefendantRace` is exactly the opposite of what we have got
    in the one-predictor model. The reversed association may seem to be paradoxical,
    but it can be explained. Let''s have a look at the following output:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The data seems to be homogeneous in some sense: black defendants are more likely
    to have black victims, and vice versa. If you put these pieces of information
    together, you start to see that black defendants yield a smaller proportion of
    death sentences just because they are more likely to have black victims, and those
    who have black victims are less likely to get a death penalty. The paradox disappears:
    the crude death penalty and `DefendantRace` association was confounded by `VictimRace`.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 数据似乎在某种程度上具有同质性：黑人被告更有可能遇到黑人受害者，反之亦然。如果你将这些信息放在一起，你就会开始看到，黑人被告产生更小的死刑判决比例，仅仅是因为他们更有可能遇到黑人受害者，而那些有黑人受害者的人不太可能被判死刑。这种悖论消失了：粗略的死刑和`DefendantRace`（被告种族）关联被`VictimRace`（受害者种族）所混淆。
- en: 'To sum it up, it seems that taking the available information into account,
    you can come to the following conclusions:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，似乎在考虑可用信息的情况下，你可以得出以下结论：
- en: Black defendants are more likely to get the death penalty
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 黑人被告更有可能被判死刑
- en: Killing a white person is considered to be a more serious crime than killing
    a black person
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 杀死一个白人被认为比杀死一个黑人更严重的罪行
- en: Of course, you should draw such conclusions extremely carefully, as the question
    of racial bias needs a very thorough analysis using all the relevant information
    regarding the circumstances of the crime, and much more.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，你应该非常谨慎地得出这样的结论，因为种族偏见的问题需要使用所有与犯罪情况相关的相关信息进行非常彻底的分析，以及更多。
- en: Data considerations
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据考虑
- en: Logistic regression models work on the assumption that the observations are
    totally independent from each other. This assumption is violated, for example,
    if your observations are consecutive years. The deviance residuals and other diagnostic
    statistics can help validate the model and detect problems such as the misspecification
    of the link function. For further reference, see the `LogisticDx` package.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归模型基于观察值之间完全独立的假设。例如，如果你的观察值是连续的年份，这个假设就被违反了。偏差残差和其他诊断统计量可以帮助验证模型并检测诸如链接函数误指定等问题。有关进一步参考，请参阅`LogisticDx`包。
- en: As a general rule of thumb, logistic regression models require at least 10 events
    per predictors, where an event denotes the observations belonging to the less
    frequent category in the response. In our death penalty example, death is the
    less frequent category in the response, and we have 68 death sentences in the
    database. So, the rule suggests that a maximum of 6-7 predictors are allowed.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 一般而言，逻辑回归模型需要每个预测因子至少有10个事件，其中事件表示属于响应中较少出现类别的观察值。在我们的死刑案例中，死刑是响应中较少出现的类别，我们在数据库中有68个死刑判决。因此，规则建议最多允许6-7个预测因子。
- en: The regression coefficients are estimated using the maximum likelihood method.
    Since there is no closed mathematical form to get these ML estimations, R uses
    an optimization algorithm instead. In some cases, you may get an error message
    that the algorithm doesn't reach convergence. In such cases, it is unable to find
    an appropriate solution. This may occur for a number of reasons, such as having
    too many predictors, too few events, and so on.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 回归系数是通过最大似然法估计的。由于没有封闭的数学形式来获取这些最大似然估计，R使用优化算法。在某些情况下，你可能会收到一个错误消息，表明算法没有达到收敛。在这种情况下，它无法找到合适的解决方案。这可能是由多种原因造成的，例如预测因子太多、事件太少等等。
- en: Goodness of model fit
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型拟合优度
- en: One measure of model fit, to evaluate the performance of the model, is the significance
    of the overall model. The corresponding likelihood ratio tests whether the given
    model fits significantly better than a model with just an intercept, which we
    call the null model.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 评估模型性能的一个指标是整体模型的显著性。相应的似然比检验表明，给定的模型与仅包含截距项的模型相比，拟合得更好，我们称之为零模型。
- en: To obtain the test results, you have to look at the residual deviance in the
    output. It measures the disagreement between the maxima of the observed and the
    fitted log likelihood functions.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 要获得测试结果，你必须查看输出中的残差偏差。它衡量了观察到的最大值和拟合的对数似然函数之间的不一致性。
- en: Note
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Since logistic regression follows the maximal likelihood principle, the goal
    is to minimize the sum of the deviance residuals. Therefore, this residual is
    parallel to the raw residual in linear regression, where the goal is to minimize
    the sum of squared residuals.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 由于逻辑回归遵循最大似然原理，目标是使偏差残差的总和最小化。因此，这个残差与线性回归中的原始残差平行，在线性回归中，目标是使残差平方和最小化。
- en: 'The null deviance represents how well the response is predicted by a model
    with nothing but an intercept. To judge the model, you have to compare the residual
    deviance to the null deviance; the difference follows a chi-square distribution.
    The corresponding test is available in the `lmtest` package:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The *p* value indicates a highly significant decrease in deviance. This means
    that the model is significant, and the predictors have a significant effect on
    the response probability.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: You can think of the likelihood ratio as the F-test in the linear regression
    models. It reveals if the model is significant, but it doesn't tell anything about
    the goodness-of-fit, which was described by the adjusted R-squared measure in
    the linear case.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: 'An equivalent statistic for logistic regression models does not exist, but
    several pseudo R-squared have been developed. These usually range from 0 to 1
    with higher values indicating a better fit. We will use the `PseudoR2` function
    from the `BaylorEdPsych` package to compute this value:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: But be careful, the pseudo R-squared cannot be interpreted as an OLS R-squared,
    and there are some documented problems with them as well, but they give us a rough
    picture. In our case, they say that the explanative power of the model is rather
    low, which is not surprising if we consider the fact that only two predictors
    were used in the modeling of such a complex process as judging a crime.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: Model comparison
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we have seen in the previous chapter, the adjusted R-squared provides a good
    base for model comparison when dealing with nested linear regression models. For
    nested logistic regression models, you can use the likelihood ratio test (such
    as the `lrtest` function from the `lmtest` library), which compares the difference
    between the residual deviances.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Note
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '`LogLiK`, in the preceding output denotes the log-likelihood of the model;
    you got the residual deviance by multiplying it by 2.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: For un-nested models, you can use AIC, just like we did in the case of linear
    regression models, but in logistic regression models, AIC is part of the standard
    output, so there is no need to call the AIC function separately. Here, the `binom.model.1`
    has a lower AIC than `binom.model.0`, and the difference is not negligible since
    it is greater than 2.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: Models for count data
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Logistic regression can handle only binary responses. If you have count data,
    such as the number of deaths or failures in a given period of time, or in a given
    geographical area, you can use Poisson or negative binomial regression. These
    data types are particularly common when working with aggregated data, which is
    provided as a number of events classified in different categories.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: Poisson regression
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Poisson regression models are generalized linear models with the logarithm as
    the link function, and they assume that the response has a **Poisson distribution**.
    The Poisson distribution takes only integer values. It is appropriate for count
    data, such as events occurring over a fixed period of time, that is, if the events
    are rather rare, such as a number of hard drive failures per day.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: In the following example, we will use the Hard Drive Data Sets for the year
    of 2013\. The dataset was downloaded from [https://docs.backblaze.com/public/hard-drive-data/2013_data.zip](https://docs.backblaze.com/public/hard-drive-data/2013_data.zip),
    but we polished and simplified it a bit. Each record in the original database
    corresponds to a daily snapshot of one drive. The failure variable, our main point
    of interest, can be either zero (if the drive is OK), or one (on the last day
    of the hard drive before failing).
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s try to determine which factors affect the appearance of a failure. The
    potential predictive factors are the following:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: '`model`: The manufacturer-assigned model number of the drive'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`capacity_bytes`: The drive capacity in bytes'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`age_month`: The drive age in the average month'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`temperature`: The hard disk drive temperature'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`PendingSector`: A logical value indicating the occurrence of unstable sectors
    (waiting for remapping on the given hard drive, on the given day)'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We aggregated the original dataset by these variables, where the `freq` variable
    denotes the number of records in the given category. It''s time to load this final,
    cleansed, and aggregated dataset:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Take a quick look at the number of failures by model:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Now, let''s get rid of those hard-drive models that didn''t have any failure,
    by removing all rows from the preceding table where there are only zeros beside
    the first column:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'To get a quick overview on the number of failures, let''s plot a histogram
    on a log scale by model numbers, with the help of the `ggplot2` package:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '![Poisson regression](img/2028OS_05_01.jpg)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
- en: Now, it's time to fit a Poisson regression model to the data, using the `model`
    number as the predictor. The model can be fitted using the `glm` function with
    the option, `family=poisson`. By default, the expected log count is modeled, so
    we use the `log` link.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: 'In the database, each observation corresponds to a group with a varying number
    of hard drives. As we need to handle the different group sizes, we will use the
    `offset` function:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'First, let''s interpret the coefficients. The model number is a discrete predictor,
    so we entered a number of dummy variables to represent it is as a predictor. The
    reference category is not present in the output by default, but we can query it
    at any time:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'So, it turns out that the reference category is `HGST`, and the dummy variables
    compare each model with the `HGST` hard drive. For example, the coefficient of
    `Hitachi` is `1.77`, so the expected log-count for `Hitachi` drives is about 1.77
    greater than those for `HGST` drives. Or, you can compute its exponent when speaking
    about ratios instead of differences:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'So, the expected number of failures for `Hitachi` drives is 5.85 times greater
    than for `HGST` drives. In general, the interpretation goes as: a one unit increase
    in *X* multiplies *Y* by `exp(b)`.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: 'Similar to logistic regression, let''s determine the significance of the model.
    To do this, we compare the present model to the null model without any predictors,
    so the difference between the residual deviance and the null deviance can be identified.
    We expect the difference to be large enough, and the corresponding chi-squared
    test to be significant:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: And it seems that the model is significant, but we should also try to determine
    whether any of the model assumptions might fail.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: Just like we did with the linear and logistic regression models, we have an
    independence assumption, where Poisson regression assumes the events to be independent.
    This means that the occurrence of one failure will not make another more or less
    likely. In the case of drive failures, this assumption holds. Another important
    assumption comes from the fact that the response has a Poisson distribution with
    an equal mean and variance. Our model assumes that the variance and the mean,
    conditioned on the predictor variables, will be approximately equal.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: To decide whether the assumption holds, we can compare the residual deviance
    to its degree of freedom. For a well-fitting model, their ratio should be close
    to one. Unfortunately, the reported residual deviance is `17622` on `9844` degrees
    of freedom, so their ratio is much above one, which suggests that the variance
    is much greater than the mean. This phenomenon is called **overdispersion**.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: Negative binomial regression
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In such a case, a negative binomial distribution can be used to model an over-dispersed
    count response, which is a generalization of the Poisson regression since it has
    an extra parameter to model the over-dispersion. In other words, Poisson and the
    negative binomial models are nested models; the former is a subset of the latter
    one.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following output, we use the `glm.nb` function from the `MASS` package
    to fit a negative binomial regression to our drive failure data:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'To compare this model''s performance to the Poisson model, we can use the likelihood
    ratio test, since the two models are nested. The negative binomial model shows
    a significantly better fit:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: This result clearly suggests choosing the negative binomial model.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: Multivariate non-linear models
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: So far, the only predictor in our model was the model name, but we have other
    potentially important information about the drives as well, such as capacity,
    age, and temperature. Now let's add these to the model, and determine whether
    the new model is better than the original one.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: 'Furthermore, let''s check the importance of `PendingSector` as well. In short,
    we define a two-step model building procedure with the nested models; hence we
    can use likelihood ratio statistics to test whether the model fit has significantly
    increased in both steps:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Both of these steps are significant, so it was worth adding each predictor
    to the model. Now, let''s interpret the best model:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Each predictor is significant—with a few exceptions of some contrast in model
    type. For example, `Toshiba` doesn't differ significantly from the reference category,
    `HGST`, when controlling for age, temperature, and so on.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: 'The interpretation of the negative binomial regression parameters is similar
    to the Poisson model. For example, the coefficient of `age_month` is 0.048, which
    shows that a one month increase in age, increases the expected log-count of failures
    by 0.048\. Or, you can opt for using exponentials as well:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'So, it seems that one month in a lifetime increases the expected number of
    failures by 4.9 percent, and a larger capacity also increases the number of failures.
    On the other hand, temperature shows a reversed effect: the exponent of the coefficient
    is 0.947, which says that one degree of increased warmth decreases the expected
    number of failures by 5.3 percent.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: 'The effect of the model name can be judged on the basis of comparison to the
    reference category, which is `HGST` in our case. One may want to change this reference.
    For example, for the most common drive: `WDC`. This can be easily done by changing
    the order of the factor levels in hard drive models, or simply defining the reference
    category in the factor via the extremely useful `relevel` function:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Now, let''s verify if `HGST` indeed replaced `WDC` in the coefficients list,
    but instead of the lengthy output of summary, we will use the `tidy` function
    from the `broom` package, which can extract the most important features (for the
    model summary, take a look at the `glance` function) of different statistical
    models:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Note
  id: totrans-117
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Use the `broom` package to extract model coefficients, compare model fit, and
    other metrics to be passed to, for example, `ggplot2`.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: The effect of temperature suggests that the higher the temperature, the lower
    the number of hard drive failures. However, everyday experiences show a very different
    picture, for example, as described at [https://www.backblaze.com/blog/hard-drive-temperature-does-it-matter](https://www.backblaze.com/blog/hard-drive-temperature-does-it-matter).
    Google engineers found that temperature was not a good predictor of failure, while
    Microsoft and the University of Virginia found that it had a significant effect.
    Disk drive manufacturers suggest keeping disks at cooler temperatures.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 温度的效应表明，温度越高，硬盘故障的数量越低。然而，日常经验显示了一个非常不同的画面，例如，在[https://www.backblaze.com/blog/hard-drive-temperature-does-it-matter](https://www.backblaze.com/blog/hard-drive-temperature-does-it-matter)中描述的那样。谷歌工程师发现温度并不是故障的良好预测因子，而微软和弗吉尼亚大学发现它有显著影响。磁盘驱动器制造商建议保持磁盘在较低的温度下。
- en: 'So, let''s take a closer look at this interesting question, and we will have
    the `temperature` as a predictor of drive failure. First, let''s classify temperature
    into six equal categories, and then we will draw a bar plot presenting the mean
    number of failures per categories. Note that we have to take into account the
    different groups'' sizes, so we will weight by `freq`, and as we are doing some
    data aggregation, it''s the right time to convert our dataset into a `data.table`
    object:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，让我们更仔细地看看这个有趣的问题，我们将把`温度`作为驱动器故障的预测因子。首先，让我们将温度分为六个相等的类别，然后我们将绘制一个条形图来展示每个类别的平均故障数量。请注意，我们必须考虑到不同组的大小，因此我们将通过`freq`进行加权，并且由于我们正在进行一些数据聚合，现在是将我们的数据集转换为`data.table`对象的时候了：
- en: '[PRE22]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '![Multivariate non-linear models](img/2028OS_05_02.jpg)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![多元非线性模型](img/2028OS_05_02.jpg)'
- en: 'The assumption of linear relation is clearly not supported. The bar plot suggests
    using the temperature in this classified form, instead of the original continuous
    variable when entering the model. To actually see which model is better, let''s
    compare those! Since they are not nested, we have to use the AIC, which strongly
    supports the categorized version:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 线性关系的假设显然没有得到支持。条形图建议在模型中输入时使用这种分类形式的温度，而不是原始的连续变量。为了真正看到哪个模型更好，让我们比较一下！由于它们不是嵌套的，我们必须使用AIC，它强烈支持分类版本：
- en: '[PRE23]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Well, it was really worth categorizing temperature! Now, let''s check the other
    two continuous predictors as well. Again, we will use `freq` as a weighting factor:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 嗯，对温度进行分类真的很有价值！现在，让我们检查其他两个连续预测因子。同样，我们将使用`freq`作为权重因子：
- en: '[PRE24]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'As in the previous plots, we will use `ggplot2` to plot the distribution of
    these discrete variables, but instead of a bar plot, we will use a stair-line
    chart to overcome the issue of the fixed width of bar charts:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前的图表一样，我们将使用`ggplot2`来绘制这些离散变量的分布，但我们将使用阶梯线图而不是条形图来克服条形图固定宽度的缺点：
- en: '[PRE25]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '![Multivariate non-linear models](img/2028OS_05_03.jpg)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![多元非线性模型](img/2028OS_05_03.jpg)'
- en: 'The relations are again, clearly not linear. The case of `age` is particularly
    interesting; there seems to be highly risky periods in the hard drives'' lifetime.
    Now, let''s force R to use `capacity` as a nominal variable (it has only five
    values, so there is no real need to categorize it), and let''s classify `age`
    into 8 equally sized categories:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 这些关系显然不是线性的。`年龄`的情况尤其有趣；硬盘寿命中似乎存在高度危险的时期。现在，让我们强制R使用`容量`作为名义变量（它只有五个值，所以实际上没有必要对其进行分类），并将`年龄`分为8个大小相等的类别：
- en: '[PRE26]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'According to the AIC, the last model with the categorized age and capacity
    is much better, and is the best fitting model so far:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 根据AIC，最后一个具有分类年龄和容量的模型要好得多，是目前为止的最佳拟合模型：
- en: '[PRE27]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'If you look at the parameter estimates, you can see that the first dummy variable
    on capacity significantly differ from the reference:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你看参数估计，你可以看到容量上的第一个虚拟变量与参考值显著不同：
- en: '[PRE28]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: The next three capacities are more likely to cause failures, but the trend is
    not linear. The effect of age also does not seem to be linear. In general, aging
    increases the number of failures, but there are some exceptions. For example,
    drives are significantly more likely to have a failure in the first (reference)
    age group than in the second one. This finding is plausible since drives have
    a higher failure rate at the beginning of their operation. The effect of temperature
    suggests that the middle temperature (22-30 degrees Celsius) is more likely to
    cause failures than low or high temperatures. Remember that each effect is controlled
    for every other predictor.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: It would also be important to judge the effect-size of different predictors,
    comparing them to each other. As a picture is worth a thousand words, let's summarize
    the coefficients with the confidence intervals in one plot.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we have to extract the significant terms from the model:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Then, let''s identify the confidence intervals of the coefficients using the
    `confint` function and the good old `plyr` package:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Unfortunately, this resulting data frame is not yet complete. We need to add
    the term names, and also, let''s extract the grouping variables via a simple,
    regular expression:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'And now we have the confidence intervals of the coefficients in a nicely formatted
    dataset, which can be easily plotted by `ggplot`:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '![Multivariate non-linear models](img/2028OS_05_04.jpg)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
- en: It can be easily seen that although each predictor is significant, the size
    of their effects strongly differ. For example, `PendingSector` has just a slight
    effect on the number of failures, but `age`, `capacity`, and `temperature` have
    a much stronger effect, and the hard drive model is the predictor that best differentiates
    the number of failures.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: 'As we have mentioned in the *Logistic regression* section, different pseudo
    R-squared measures are available for nonlinear models as well. We again warn you
    to use these metrics with reservation. Anyway, in our case, they uniformly suggest
    the model''s explanative power to be pretty good:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Summary
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This chapter introduced three well known nonlinear regression models: the logistic,
    Poisson, and negative binomial models, and you became familiar with the general
    logic of modeling. It was also shown how the same concepts, such as effect of
    predictors, goodness of fit, explanative power, model comparison for nested and
    non-nested models, and model building are applied in different contexts. Now,
    having spent some time on mastering the data analysis skills, in the next chapter,
    we will get back to some hardcore data science problems, such as the cleansing
    and structuring of data.'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
