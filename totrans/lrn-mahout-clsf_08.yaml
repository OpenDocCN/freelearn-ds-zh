- en: Chapter 8. Mahout Changes in the Upcoming Release
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Mahout is a community-driven project and its community is very strong. This
    community decided on some of the major changes in the upcoming 1.0 release. In
    this chapter, we will explore the upcoming changes and developments in Apache
    Mahout. We will look at the following topics in brief:'
  prefs: []
  type: TYPE_NORMAL
- en: New changes due in Mahout 1.0
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Apache Spark
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: H20-platform-related work in Apache Mahout
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mahout new changes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Mahout was using the map reduce programming model to handle large datasets.
    From the end of April 2014, the community decided to stop the implementation of
    the new map reduce algorithm. This decision has a valid reason. Mahout's codebase
    will be moving to modern data processing systems that offer a richer programming
    model and more efficient execution than Hadoop's MapReduce.
  prefs: []
  type: TYPE_NORMAL
- en: Mahout has started its implementation on the top of **Domain Specific Language**
    (**DSL**) for linear algebraic operations. Programs written in this DSL are automatically
    optimized and executed in parallel on Apache Spark. Scala DSL and algebraic optimizer
    is Scala and Spark binding for Mahout.
  prefs: []
  type: TYPE_NORMAL
- en: Mahout Scala and Spark bindings
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With Mahout Scala bindings and Mahout Spark bindings for linear algebra subroutines,
    developers in Mahout are trying to bring semantic explicitness to Mahout's in-core
    and out-of-core linear algebra subroutines. They are doing this while adding the
    benefits of the strong programming environment of Scala and capitalizing on scalability
    benefits of Spark and GraphX. Scala binding is used to provide support for Scala
    DSL, and this will make writing machine learning programs easier.
  prefs: []
  type: TYPE_NORMAL
- en: 'Mahout Scala and Spark bindings are packages that aim to provide an R-like
    look and feel to Mahout''s in-core and out-of-core Spark-backed linear algebra.
    An important part of Spark bindings is the expression optimizer. This optimizer
    looks at the entire expression and decides on how it can be simplified and which
    physical operators should be picked. A high-level diagram of the binding stack
    is shown in the following figure ([https://issues.apache.org/jira/secure/attachment/12638098/BindingsStack.jpg](https://issues.apache.org/jira/secure/attachment/12638098/BindingsStack.jpg)):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Mahout Scala and Spark bindings](img/4959OS_08_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The Spark binding shell has also been implemented in Mahout 1.0\. Let's understand
    the Apache Spark project first and then we will revisit the Spark binding shell
    in Mahout.
  prefs: []
  type: TYPE_NORMAL
- en: Apache Spark
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Apache Spark is an open source, in-memory, general-purpose computing system.
    Spark's in-memory technique provides performance that is 100 times faster. Instead
    of Hadoop-like disk-based computation, Spark uses cluster memory to upload all
    the data into the memory, and this data can be queried repeatedly.
  prefs: []
  type: TYPE_NORMAL
- en: 'Apache Spark provides high-level APIs in Java, Python, and Scala and an optimized
    engine that supports general execution graphs. It provides the following high-level
    tools:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Spark SQL**: This is for SQL and structured data processing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**MLib**: This is Spark''s scalable machine learning library that consists
    of common learning algorithms and utilities, including classification, regression,
    clustering, collaborative filtering, dimensionality reduction, as well as the
    underlying optimization primitives.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**GraphX**: This is the new Spark API for graphs and graph-parallel computation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Spark streaming**: This can collect data from many sources and after processing
    this data, it uses complex algorithms and can push the data to filesystems, databases,
    and live dashboards.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As Spark is gaining popularity among data scientists, the Mahout community is
    also quickly working on making Mahout algorithms function on Spark's execution
    engine to speed up its calculation 10 to 100 times faster. Mahout provides several
    important building blocks to create recommendations using Spark. Spark-item similarity
    can be used to create *other people also liked these things* kind of recommendations
    and when paired with a search engine can personalize recommendations for individual
    users. Spark-row similarity can provide non-personalized content based on recommendations
    and when paired with a search engine can be used to personalize content based
    on recommendations ([http://comments.gmane.org/gmane.comp.apache.mahout.scm/6513](http://comments.gmane.org/gmane.comp.apache.mahout.scm/6513)).
  prefs: []
  type: TYPE_NORMAL
- en: Using Mahout's Spark shell
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You can use Mahout''s Spark shell by referring to the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Download Spark from [http://spark.apache.org/downloads.html](http://spark.apache.org/downloads.html).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Create a new folder with the name `spark` using the following command and move
    the downloaded file there:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Unpack the archived file in a folder using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will unzip the file `under/tmp/spark/spark-1.1.1`. Now, move to the newly
    created folder and run the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will build Spark on your system as shown in the following screenshot:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Using Mahout''s Spark shell](img/4959OS_08_02.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Now create a Mahout directory and move the file to it using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Check out the master branch of Mahout from GitHub using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output of the preceding command is shown in the following screenshot:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Using Mahout''s Spark shell](img/4959OS_08_03.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Change your directory to the newly created Mahout directory and build Mahout:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output of the preceding command is shown in the following screenshot:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Using Mahout''s Spark shell](img/4959OS_08_04.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Move to the directory where you unpacked Spark and type the following command
    to start Spark locally:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output of the preceding command is shown in the following screenshot:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Using Mahout''s Spark shell](img/4959OS_08_05.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Open a browser; point it to `http://localhost:8080/` to check whether Spark
    has successfully started. Copy the URL of the Spark master at the top of the page
    (it starts with `spark://`).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Define the following environment variables:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Finally, change to the directory where you unpacked Mahout and type `bin/mahout
    spark-shell`; you should see the shell starting and get the `mahout>` prompt.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now your Mahout Spark shell is ready and you can start playing with data. For
    more information on this topic, see the implementation section at [https://mahout.apache.org/users/sparkbindings/play-with-shell.html](https://mahout.apache.org/users/sparkbindings/play-with-shell.html).
  prefs: []
  type: TYPE_NORMAL
- en: H2O platform integration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As discussed earlier, an experimental work to integrate Mahout and the H2O platform
    is also in progress. The integration provides an H2O backend to the Mahout algebra
    DSL.
  prefs: []
  type: TYPE_NORMAL
- en: H2O makes Hadoop do math! H2O scales statistics, machine learning, and math
    over big data. It is extensible and users can build blocks using simple math legos
    in the core. H2O keeps familiar interfaces such as R, Excel, and JSON so that
    big data enthusiasts and experts can explore, munge, model, and score datasets
    using a range of simple-to-advanced algorithms. Data collection is easy, while
    decision making is hard. H2O makes it fast and easy to derive insights from your
    data through faster and better predictive modeling. It also has a vision of online
    scoring and modeling in a single platform ([http://0xdata.com/download/](http://0xdata.com/download/)).
  prefs: []
  type: TYPE_NORMAL
- en: H2O is fundamentally a peer-to-peer system. H2O nodes join together to form
    a cloud on which high-performance distributed math can be executed. Each node
    joins a cloud of a given name. Multiple clouds can exist on the same network at
    the same time as long as their names are different. Multiple nodes can exist on
    the same server as well (they can even belong to the same cloud).
  prefs: []
  type: TYPE_NORMAL
- en: The Mahout H2O integration is fit into this model by having N-1 worker nodes
    and one driver node, all belonging to the same cloud name. The default cloud name
    used for the integration is `mah2out`. Clouds have to be spun up as per their
    task/job.
  prefs: []
  type: TYPE_NORMAL
- en: More details can be found at [https://issues.apache.org/jira/browse/MAHOUT-1500](https://issues.apache.org/jira/browse/MAHOUT-1500).
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we discussed the upcoming release of Mahout 1.0, and the changes
    that are currently going on. We also glanced through Spark, Scala binding, and
    Apache Spark. We also discussed a high-level overview of H2O Mahout integration.
  prefs: []
  type: TYPE_NORMAL
- en: Now let's move on to the final chapter of this book where we will develop a
    production-ready classifier.
  prefs: []
  type: TYPE_NORMAL
