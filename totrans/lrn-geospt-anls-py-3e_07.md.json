["```py\na2 + b2 = c2\n```", "```py\nimport math\n# First point\nx1 = 456456.23\ny1 = 1279721.064\n# Second point\nx2 = 576628.34\ny2 = 1071740.33\n# X distance\nx_dist = x1 - x2\n# Y distance\ny_dist = y1 - y2\n# Pythagorean theorem\ndist_sq = x_dist**2 + y_dist**2\ndistance = math.sqrt(dist_sq)\nprint(distance)\n# 240202.66\n```", "```py\nimport math\nx1 = -90.21\ny1 = 32.31\nx2 = -88.95\ny2 = 30.43\nx_dist = math.radians(x1 - x2)\ny_dist = math.radians(y1 - y2)\ndist_sq = x_dist**2 + y_dist**2\ndist_rad = math.sqrt(dist_sq)\ndist_rad * 6371251.46\n# 251664.46\n```", "```py\nimport math\nx1 = -90.212452861859035\ny1 = 32.316272202663704\nx2 = -88.952170968942525\ny2 = 30.438559624660321\nx_dist = math.radians(x1 - x2)\ny_dist = math.radians(y1 - y2)\ny1_rad = math.radians(y1)\ny2_rad = math.radians(y2)\na = math.sin(y_dist/2)**2 + math.sin(x_dist/2)**2 \\\n * math.cos(y1_rad) * math.cos(y2_rad)\nc = 2 * math.asin(math.sqrt(a))\ndistance = c * 6371  # kilometers\nprint(distance)\n# 240.63\n```", "```py\nimport math\n```", "```py\ndistance = None\nx1 = -90.212452861859035\ny1 = 32.316272202663704\nx2 = -88.952170968942525\ny2 = 30.438559624660321\n# Ellipsoid Parameters\n# Example is NAD83\na = 6378137  # semi-major axis\nf = 1/298.257222101  # inverse flattening\nb = abs((f*a)-a)  # semi-minor axis\nL = math.radians(x2-x1)\nU1 = math.atan((1-f) * math.tan(math.radians(y1)))\nU2 = math.atan((1-f) * math.tan(math.radians(y2)))\nsinU1 = math.sin(U1)\ncosU1 = math.cos(U1)\nsinU2 = math.sin(U2)\ncosU2 = math.cos(U2)\nlam = L\n```", "```py\nfor i in range(100):\n    sinLam = math.sin(lam)\n    cosLam = math.cos(lam)\n    sinSigma = math.sqrt((cosU2*sinLam)**2 +\n                         (cosU1*sinU2-sinU1*cosU2*cosLam)**2)\n    if (sinSigma == 0):\n        distance = 0  # coincident points\n        break\n    cosSigma = sinU1*sinU2 + cosU1*cosU2*cosLam\n    sigma = math.atan2(sinSigma, cosSigma)\n    sinAlpha = cosU1 * cosU2 * sinLam / sinSigma\n    cosSqAlpha = 1 - sinAlpha**2\n    cos2SigmaM = cosSigma - 2*sinU1*sinU2/cosSqAlpha\n    if math.isnan(cos2SigmaM):\n        cos2SigmaM = 0  # equatorial line\n    C = f/16*cosSqAlpha*(4+f*(4-3*cosSqAlpha))\n    LP = lam\n    lam = L + (1-C) * f * sinAlpha *\n        (sigma + C*sinSigma*(cos2SigmaM+C*cosSigma *\n                             (-1+2*cos2SigmaM*cos2SigmaM)))\n    if not abs(lam-LP)  1e-12:\n        break\nuSq = cosSqAlpha * (a**2 - b**2) / b**2\nA = 1 + uSq/16384*(4096+uSq*(-768+uSq*(320-175*uSq)))\nB = uSq/1024 * (256+uSq*(-128+uSq*(74-47*uSq)))\ndeltaSigma = B*sinSigma*(cos2SigmaM+B/4 *\n(cosSigma*(-1+2*cos2SigmaM*cos2SigmaM) - B/6*cos2SigmaM*(-3+4*sinSigma*sinSigma) * (-3+4*cos2SigmaM*cos2SigmaM)))\ns = b*A*(sigma-deltaSigma)\n```", "```py\ndistance = s\nprint(distance)\n# 240237.66693880095\n```", "```py\nfrom math import atan2, cos, sin, degrees\n```", "```py\nlon1 = -90.21\nlat1 = 32.31\nlon2 = -88.95\nlat2 = 30.43\n```", "```py\nangle = atan2(cos(lat1)*sin(lat2)-sin(lat1) * \\\n  cos(lat2)*cos(lon2-lon1), sin(lon2-lon1)*cos(lat2))\n```", "```py\nbearing = (degrees(angle) + 360) % 360\nprint(bearing)\n309.3672990606595\n```", "```py\nimport utm\ny = 479747.0453210057\nx = 5377685.825323031\nzone = 32\nband = 'U'\nprint(utm.to_latlon(y, x, zone, band))\n# (48.55199390882121, 8.725555729071763)\n```", "```py\nimport utm\nutm.from_latlon(48.55199390882121, 8.725555729071763)\n# (479747.04524576373, 5377691.373080335, 32, 'U')\n```", "```py\nfrom osgeo import ogr\nfrom osgeo import osr\nimport os\nimport shutil\n```", "```py\nsrcName = 'NYC_MUSEUMS_LAMBERT.shp'\ntgtName = 'NYC_MUSEUMS_GEO.shp'\n```", "```py\ntgt_spatRef = osr.SpatialReference()\ntgt_spatRef.ImportFromEPSG(4326)\n```", "```py\ndriver = ogr.GetDriverByName('ESRI Shapefile')\nsrc = driver.Open(srcName, 0)\nsrcLyr = src.GetLayer()\nsrc_spatRef = srcLyr.GetSpatialRef()\n```", "```py\nif os.path.exists(tgtName):\n    driver.DeleteDataSource(tgtName)\n```", "```py\ntgt = driver.CreateDataSource(tgtName)\nlyrName = os.path.splitext(tgtName)[0]\n# Use well-known binary format (WKB) to specify geometry\ntgtLyr = tgt.CreateLayer(lyrName, geom_type=ogr.wkbPoint)\nfeatDef = srcLyr.GetLayerDefn()\ntrans = osr.CoordinateTransformation(src_spatRef, tgt_spatRef)\n```", "```py\nsrcFeat = srcLyr.GetNextFeature()\nwhile srcFeat:\n    geom = srcFeat.GetGeometryRef()\n    geom.Transform(trans)\n    feature = ogr.Feature(featDef)\n    feature.SetGeometry(geom)\n    tgtLyr.CreateFeature(feature)\n    feature.Destroy()\n    srcFeat.Destroy()\n    srcFeat = srcLyr.GetNextFeature()\nsrc.Destroy()\ntgt.Destroy()\n```", "```py\n# Convert geometry to Esri flavor of Well-Known Text (WKT) format\n# for export to the projection (prj) file.\ntgt_spatRef.MorphToESRI()\nprj = open(lyrName + '.prj', 'w')\nprj.write(tgt_spatRef.ExportToWkt())\nprj.close()\n```", "```py\nsrcDbf = os.path.splitext(srcName)[0] + '.dbf'\ntgtDbf = lyrName + '.dbf'\nshutil.copyfile(srcDbf, tgtDbf)\n```", "```py\nimport math\nimport re\n```", "```py\ndef dd2dms(lat, lon):\n    \"\"\"Convert decimal degrees to degrees, minutes, seconds\"\"\"\n    latf, latn = math.modf(lat)\n    lonf, lonn = math.modf(lon)\n    latd = int(latn)\n    latm = int(latf * 60)\n    lats = (lat - latd - latm / 60) * 3600.00\n    lond = int(lonn)\n    lonm = int(lonf * 60)\n    lons = (lon - lond - lonm / 60) * 3600.00\n    compass = {\n        'lat': ('N','S'),\n        'lon': ('E','W')\n    }\n    lat_compass = compass['lat'][0 if latd >= 0 else 1]\n    lon_compass = compass['lon'][0 if lond >= 0 else 1]\n    return '{}º {}\\' {:.2f}\" {}, {}º {}\\' {:.2f}\" \n    {}'.format(abs(latd),\n    abs(latm), abs(lats), lat_compass, abs(lond),\n    abs(lonm), abs(lons), lon_compass)\n```", "```py\ndef dms2dd(lat, lon):\n    lat_deg, lat_min, \\\n    lat_sec, lat_dir = re.split('[^\\d\\.A-Z]+', lat)\n    lon_deg, lon_min, \\\n    lon_sec, lon_dir = re.split('[^\\d\\.A-Z]+', lon)\n    lat_dd = float(lat_deg) +\\\n    float(lat_min)/60 + float(lat_sec)/(60*60);\n    lon_dd = float(lon_deg) +\\\n    float(lon_min)/60 + float(lon_sec)/(60*60);\n    if lat_dir == 'S':\n        lat_dd *= -1\n    if lon_dir == 'W':\n        lon_dd *= -1\n    return (lat_dd, lon_dd);\n```", "```py\nprint(dd2dms(35.14953, -90.04898))\n # 35º 8' 58.31\" N, 90º 2' 56.33\" W\n```", "```py\ndms2dd(\"\"\"29º 56' 0.00\" N\"\"\", \"\"\"90º 4' 12.36\" W\"\"\")\n (29.933333333333334, -90.0701)\n```", "```py\npip install area\n```", "```py\nfrom area import area\n```", "```py\n# Our points making up a polygon\npolygon = {\"type\":\"Polygon\",\"coordinates\":[[[-89.324,30.312],[-89.326,30.31],[-89.322,30.31],[-89.321,30.311],[-89.321,30.312],[-89.324,30.312]]]}\n```", "```py\na = area(polygon)\n```", "```py\nround(a, 2)\n```", "```py\nimport shapefile\n r = shapefile.Reader('MSCities_Geo_Pts')\n r\n<shapefile.Reader instance at 0x00BCB760>\n```", "```py\nr.bbox\n [-91.38804855553174, 30.29314882296931, -88.18631833931401, \n 34.96091138678437]\n r.shapeType\n # 1\n r.numRecords\n # 298\n```", "```py\nr.fields\n # [('DeletionFlag', 'C', 1, 0), ['STATEFP10', 'C', 2, 0], \n ['PLACEFP10', 'C', 5, 0],\n # ['PLACENS10', 'C', 8, 0], ['GEOID10', 'C', 7, 0], ['NAME10', 'C', \n 100, 0],\n # ['NAMELSAD10', 'C', 100, 0], ['LSAD10', 'C', 2, 0], ['CLASSFP10', \n 'C', 2, 0],\n # ['PCICBSA10', 'C', 1, 0], ['PCINECTA10', 'C', 1, 0], ['MTFCC10', \n 'C', 5, 0],\n # ['FUNCSTAT10', 'C', 1, 0], ['ALAND10', 'N', 14, 0], ['AWATER10', \n 'N', 14,0],\n # ['INTPTLAT10', 'C', 11, 0], ['INTPTLON10', 'C', 12, 0]]\n```", "```py\n[item[0] for item in r.fields[1:]]\n# ['STATEFP10', 'PLACEFP10', 'PLACENS10', 'GEOID10', 'NAME10', 'NAMELSAD10', 'LSAD10',\n# 'CLASSFP10', 'PCICBSA10', 'PCINECTA10', 'MTFCC10', 'FUNCSTAT10', 'ALAND10',\n# 'AWATER10', 'INTPTLAT10', 'INTPTLON10']\n```", "```py\nr.record(2)\n#['28', '16620', '02406337', '2816620', 'Crosby', 'Crosby town', '43', 'C1', 'N','N', # 'G4110', 'A', 5489412, 21336, '+31.2742552', '-091.0614840']\n```", "```py\nr.record(2)[4]\n# 'Crosby'\n```", "```py\nfieldNames = [item[0] for item in r.fields[1:]]\nname10 = fieldNames.index('NAME10')\nname10\n# 4\nr.record(2)[name10]\n# 'Crosby'\n```", "```py\nfieldNames = [item[0] for item in r.fields[1:]]\nfieldNames\n# ['STATEFP10', 'PLACEFP10', 'PLACENS10', 'GEOID10', 'NAME10', 'NAMELSAD10',\n# 'LSAD10', 'CLASSFP10', 'PCICBSA10', 'PCINECTA10', 'MTFCC10','FUNCSTAT10',\n# 'ALAND10','AWATER10', 'INTPTLAT10', 'INTPTLON10']\n rec = r.record(2)\n rec\n# ['28', '16620', '02406337', '2816620', 'Crosby', 'Crosby town',\n# '43', 'C1', 'N','N', 'G4110', 'A', 5489412, 21336, '+31.2742552', '-091.0614840']\n zipRec = zip(fieldNames, rec)\n list(zipRec)\n# [('STATEFP10', '28'), ('PLACEFP10', '16620'), ('PLACENS10', '02406337'),\n# ('GEOID10', '2816620'), ('NAME10', 'Crosby'), ('NAMELSAD10', 'Crosby town'),\n# ('LSAD10', '43'), ('CLASSFP10', 'C1'), ('PCICBSA10','N'),('PCINECTA10','N'),\n# ('MTFCC10', 'G4110'), ('FUNCSTAT10', 'A'), ('ALAND10', 5489412),('AWATER10', 21336),\n# ('INTPTLAT10', '+31.2742552'), ('INTPTLON10', '-091.0614840')]\nfor z in zipRec:\n    if z[0] == 'NAME10': print(z[1])\n# Crosby\n```", "```py\nfor rec in enumerate(r.records()[:3]):\n    print(rec[0]+1, ': ', rec[1])\n# 1 :  ['28', '59560', '02404554', '2859560', 'Port Gibson', 'Port Gibson city', '\n# 25', 'C1', 'N', 'N', 'G4110', 'A', 4550230, 0, '+31.9558031', '-090.9834329']\n# 2 :  ['28', '50440', '02404351', '2850440', 'Natchez', 'Natchez city', '25', 'C1',\n#      'Y', 'N', 'G4110', 'A', 34175943, 1691489, '+31.5495016', '-091.3887298']\n# 3 :  ['28', '16620', '02406337', '2816620', 'Crosby', 'Crosby town', '43', 'C1','N',\n#       'N', 'G4110', 'A', 5489412, 21336, '+31.2742552', '-091.0614840']\n```", "```py\ncounter = 0\nfor rec in r.iterRecords():\n    counter += 1\ncounter\n# 298\n```", "```py\ngeom = r.shape(0)\ngeom.points\n# [[-90.98343326763826, 31.9558035947602]]\n```", "```py\nimport shapefile\nimport utm\nr = shapefile.Reader('NYC_MUSEUMS_GEO')\nw = shapefile.Writer(r.shapeType)\nw.fields = list(r.fields)\nw.records.extend(r.records())\nfor s in r.iterShapes():\n    lon,lat = s.points[0]\n    y,x,zone,band = utm.from_latlon(lat,lon)\n    w.point(x,y)\nw.save('NYC_MUSEUMS_UTM')\n```", "```py\nprint(w.shapes()[0].points[0])\n# [4506346.393408813, 583315.4566450359, 0, 0]\n```", "```py\nfrom urllib.request import urlopen\nprj = urlopen('http://spatialreference.org/ref/epsg/26918/esriwkt/')\nwith open('NYC\\_MUSEUMS\\_UTM', 'w') as f:\n    f.write(str(prj.read()))\n```", "```py\nimport shapefile\nfile_name = \"ep202009.026_5day_pgn.shp\"\nr = shapefile.Reader(file_name)\nwith shapefile.Writer(\"test\", r.shapeType) as w: \n    w.fields = list(r.fields) \n    for rec in r.records():\n        w.record(*list(rec)) \n    for s in r.shapes():\n        w._shapeparts(parts=[s.points], shapeType=s.shapeType) \n    w.poly([[[-104, 24], [-104, 25], [-103, 25], [-103, 24], [-104, \n    24]]]) \n    w.record(\"STANLEY\", \"TD\", \"091022/1500\", \"27\", \"21\", \"48\", \"ep\")\n```", "```py\nimport shapefile\nr = shapefile.Reader('NYC_MUSEUMS_UTM')\nwith shapefile.Writer(\"test\", r.shapeType) as w:\n```", "```py\n   w.fields = list(r.fields)\n   w.field('LAT','F',8,5)\n   w.field('LON','F',8,5)\n```", "```py\n    for i in range(len(r.shapes())):\n        lon, lat = r.shape(i).points[0]\n        w.point(lon, lat)\n        w.record(*list(r.record(i)), lat, lon)\n```", "```py\nimport glob\nimport shapefile\nfiles = glob.glob('footprints_*shp')\nwith shapefile.Writer(\"Merged\") as w:\n    r = None\n    for f in files:\n        r = shapefile.Reader(f)\n        if not w.fields:\n            w.fields = list(r.fields)\n        for rec in r.records():\n            w.record(*list(rec))\n        for s in r.shapes():\n            w._shapeparts(parts=[s.points], shapeType=s.shapeType)\n```", "```py\nshapefile.POLYGON\n```", "```py\nr = shapefile.Reader('myShape')\nw = shapefile.Writer(\"myShape\", r.shapeType)\n```", "```py\nimport glob\nimport shapefile\nfrom dbfpy3 import dbf\nshp_files = glob.glob('footprints_*.shp')\nw = shapefile.Writer(shp=\"merged.shp\", shx=\"merged.shx\")\n```", "```py\n# Loop through ONLY the shp files and copy their shapes\n# to a Writer object. We avoid opening the dbf files\n# to prevent any field-parsing errors.\nfor f in shp_files:\n    print(\"Shp: {}\".format(f))\n    r = shapefile.Reader(f)\n    r = shapefile.Reader(shp=shpf)\n    for s in r.shapes():\n        w.poly([s.points])\n    print(\"Num. shapes: {}\".format(len(w.shapes())))\n```", "```py\n# Save only the shp and shx index file to the new\n# merged shapefile.\nw.close()\n```", "```py\n# Now we come back with dbfpy and merge the dbf files\ndbf\\_files = glob.glob('\\*.dbf')\n```", "```py\n# Use the first dbf file as a template\ntemplate = dbf\\_files.pop(0)\nmerged\\_dbf\\_name = 'merged.dbf'\n# Copy the entire template dbf file to the merged file\nmerged\\_dbf = open(merged\\_dbf\\_name, 'wb')\ntemp = open(template, 'rb')\nmerged\\_dbf.write(temp.read())\nmerged\\_dbf.close()\ntemp.close()\n```", "```py\n# Now read each record from the remaining dbf files\n# and use the contents to create a new record in\n# the merged dbf file.\ndb = dbf.Dbf(merged\\_dbf\\_name)\nfor f in dbf\\_files:\n    print('Dbf: {}'.format(f))\n    dba = dbf.Dbf(f)\n    for rec in dba:\n        db\\_rec = db.newRecord()\n        for k, v in list(rec.asDict().items()):\n            db\\_rec[k] = v\n        db\\_rec.store()\ndb.close()\n```", "```py\nimport shapefile\nimport utm\nr = shapefile.Reader('footprints\\_se')\nw = shapefile.Writer(r.shapeType)\nw.fields = list(r.fields)\nfor sr in r.shapeRecords():\n    utmPoints = []\n    for p in sr.shape.points:\n        x,y,band,zone = utm.from_latlon(p[1],p[0])\n        utmPoints.append([x,y])\n    area = abs(shapefile.signed_area(utmPoints))\n    if area <= 100:\n        w._shapes.append(sr.shape)\n        w.records.append(sr.record)\nw.save('footprints\\_185')\n```", "```py\nr = shapefile.Reader('footprints\\_se')\nsubset = shapefile.Reader('footprints\\_185')\nprint(r.numRecords)\n# 26447\nprint(subset.numRecords)\n# 13331\n```", "```py\ndef point_in_poly(x,y,poly):\n    # check if point is a vertex\n    if (x,y) in poly: return True\n    # check if point is on a boundary\n    for i in range(len(poly)):\n       p1 = None\n       p2 = None\n       if i==0:\n          p1 = poly[0]\n          p2 = poly[1]\n       else:\n          p1 = poly[i-1]\n          p2 = poly[i]\n       if p1[1] == p2[1] and p1[1] == y and x min(p1[0], \\\n          p2[0]) and x < max(p1[0], p2[0]):\n          return True\n    n = len(poly)\n    inside = False\n    p1x,p1y = poly[0]\n    for i in range(n+1):\n       p2x,p2y = poly[i % n]\n       if y min(p1y,p2y):\n          if y <= max(p1y,p2y):\n             if x <= max(p1x,p2x):\n                if p1y != p2y:\n                   xints = (y-p1y)*(p2x-p1x)/(p2y-p1y)+p1x\n                if p1x == p2x or x <= xints:\n                   inside = not inside\n       p1x,p1y = p2x,p2y\n    if inside: return True\n    return False\n```", "```py\n# Test a point for inclusion\nmyPolygon = [(-70.593016,-33.416032), (-70.589604,-33.415370),\n(-70.589046,-33.417340), (-70.592351,-33.417949),\n(-70.593016,-33.416032)]\n# Point to test\nlon = -70.592000\nlat = -33.416000\nprint(point_in_poly(lon, lat, myPolygon))\n# True\n```", "```py\n# test an edge point\nlon = -70.593016\nlat = -33.416032\nprint(point_in_poly(lon, lat, myPolygon))\n# True\n```", "```py\nimport shapefile\nr = shapefile.Reader('roadtrl020')\nw = shapefile.Writer(r.shapeType)\nw.fields = list(r.fields)\nxmin = -67.5\nxmax = -65.0\nymin = 17.8\nymax = 18.6\nfor road in r.iterShapeRecords():\n    geom = road.shape\n    rec = road.record\n    sxmin, symin, sxmax, symax = geom.bbox\n    if sxmin < xmin: continue\n    elif sxmax xmax: continue\n    elif symin < ymin: continue\n    elif symax ymax: continue\n    w._shapes.append(geom)\n    w.records.append(rec)\nw.save('Puerto_Rico_Roads')\n```", "```py\nimport shapefile\n# Create a reader instance\nr = shapefile.Reader('MS_UrbanAnC10')\n# Create a writer instance\nw = shapefile.Writer(r.shapeType)\n# Copy the fields to the writer\nw.fields = list(r.fields)\n# Grab the geometry and records from all features\n# with the correct population\nselection = []\nfor rec in enumerate(r.records()):\n    if rec[1][14] < 5000:\n        selection.append(rec)\n# Add the geometry and records to the writer\nfor rec in selection:\n    w._shapes.append(r.shape(rec[0]))\n    w.records.append(rec[1])\n# Save the new shapefile\nw.save('MS_Urban_Subset')\n```", "```py\nimport fiona\nwith fiona.open('MS_UrbanAnC10.shp') as sf:\n    filtered = filter(lambda f: f['properties']['POP'] < 5000, sf)\n    # Shapefile file format driver\n    drv = sf.driver\n    # Coordinate Reference System\n    crs = sf.crs\n    # Dbf schema\n    schm = sf.schema\n    subset = 'MS_Urban_Fiona_Subset.shp'\n    with fiona.open(subset, 'w',\n        driver=drv,\n        crs=crs,\n        schema=schm) as w:\n            for rec in filtered:\n                w.write(rec)\n```", "```py\n# Used OrderedDict to control the order\n# of data attributes\nfrom collections import OrderedDict\n# Import the shapely geometry classes and methods.\n# The \"mapping\" method returns a GeoJSON representation\n# of a geometry.\nfrom shapely.geometry import shape, mapping, Polygon\n# Import the shapely union function which combines\n# geometries\nfrom shapely.ops import unary_union\n# Import Fiona to read and write datasets\nimport fiona\n```", "```py\n# Open the counties dataset\nwith fiona.open('ms_counties.geojson') as src:\n    # copy the metadata\n    schema = src.meta.copy()\n    # Create a new field type for our\n    # state dataset\n    fields = {\"State\": \"str:80\"}\n```", "```py\n    # Create a new property for our dataset\n    # using the new field\n    prop = OrderedDict([(\"State\", \"Mississippi\")])\n    # Change the metadata geometry type to Polygon\n    schema['geometry'] = 'Polygon'\n    schema['schema']['geometry'] = 'Polygon'\n```", "```py\n    # Add the new field\n    schema['properties'] = fields\n    schema['schema']['properties'] = fields\n```", "```py\n# Open the output GeoJSON dataset\nwith fiona.open('combined.geojson', 'w', **schema) as dst:\n    # Extract the properties and geometry \n    # from the counties dataset\n    props, geom = zip(*[(f['properties'],shape(f['geometry'])) for\n    f in src])\n    # Write the new state dataset out while \n    # combining the polygons into a\n    # single polygon and add the new property\n    dst.write({'geometry': mapping(\\\n    Polygon(unary_union(geom).exterior)),\n    'properties': prop})\n```", "```py\nimport shapefile\nimport random\nimport pngcanvas\n```", "```py\ndef point_in_poly(x,y,poly):\n    '''Boolean: is a point inside a polygon?'''\n    # check if point is a vertex\n    if (x,y) in poly: return True\n    # check if point is on a boundary\n    for i in range(len(poly)):\n        p1 = None\n        p2 = None\n        if i==0:\n            p1 = poly[0]\n            p2 = poly[1]\n        else:\n            p1 = poly[i-1]\n            p2 = poly[i]\n        if p1[1] == p2[1] and p1[1] == y and \\\n        x min(p1[0], p2[0]) and x < max(p1[0], p2[0]):\n            return True\n    n = len(poly)\n    inside = False\n    p1x,p1y = poly[0]\n    for i in range(n+1):\n        p2x,p2y = poly[i % n]\n        if y min(p1y,p2y):\n            if y <= max(p1y,p2y):\n                if x <= max(p1x,p2x):\n                    if p1y != p2y:\n                        xints = (y-p1y)*(p2x-p1x)/(p2y-p1y)+p1x\n                    if p1x == p2x or x <= xints:\n                    inside = not inside\n        p1x,p1y = p2x,p2y\n    if inside: return True\n    else: return False\n```", "```py\ndef world2screen(bbox, w, h, x, y):\n    '''convert geospatial coordinates to pixels'''\n    minx,miny,maxx,maxy = bbox\n    xdist = maxx - minx\n    ydist = maxy - miny\n    xratio = w/xdist\n    yratio = h/ydist\n    px = int(w - ((maxx - x) * xratio))\n    py = int((maxy - y) * yratio)\n    return (px,py)\n```", "```py\n# Open the census shapefile\ninShp = shapefile.Reader('GIS_CensusTract_poly')\n# Set the output image size\niwidth = 600\niheight = 400\n```", "```py\n# Get the index of the population field\npop_index = None\ndots = []\nfor i,f in enumerate(inShp.fields):\n    if f[0] == 'POPULAT11':\n        # Account for deletion flag\n        pop_index = i-1\n```", "```py\n# Calculate the density and plot points\nfor sr in inShp.shapeRecords():\n    population = sr.record[pop_index]\n    # Density ratio - 1 dot per 100 people\n    density = population / 100\n    found = 0\n```", "```py\n# Randomly distribute points until we\n# have the correct density\nwhile found < density:\n    minx, miny, maxx, maxy = sr.shape.bbox\n    x = random.uniform(minx,maxx)\n    y = random.uniform(miny,maxy)\n    if point_in_poly(x,y,sr.shape.points):\n        dots.append((x,y))\n        found += 1\n```", "```py\n# Set up the PNG output image\nc = pngcanvas.PNGCanvas(iwidth,iheight)\n# Draw the red dots\nc.color = (255,0,0,0xff)\nfor d in dots:\n    # We use the *d notation to exand the (x,y) tuple\n    x,y = world2screen(inShp.bbox, iwidth, iheight, *d)\n    c.filled_rectangle(x-1,y-1,x+1,y+1)\n```", "```py\n# Draw the census tracts\nc.color = (0,0,0,0xff)\nfor s in inShp.iterShapes():\n    pixels = []\n    for p in s.points:\n        pixel = world2screen(inShp.bbox, iwidth, iheight, *p)\n        pixels.append(pixel)\n    c.polyline(pixels)\n```", "```py\n# Save the image\nwith open('DotDensity.png','wb') as img:\n    img.write(c.dump())\n```", "```py\nimport math\nimport shapefile\ntry:\n   import Image\n   import ImageDraw\nexcept:\n   from PIL import Image, ImageDraw\n```", "```py\ndef world2screen(bbox, w, h, x, y):\n    '''convert geospatial coordinates to pixels'''\n    minx,miny,maxx,maxy = bbox\n    xdist = maxx - minx\n    ydist = maxy - miny\n    xratio = w/xdist\n    yratio = h/ydist\n    px = int(w - ((maxx - x) * xratio))\n    py = int((maxy - y) * yratio)\n    return (px,py)\n```", "```py\n# Open our shapefile\ninShp = shapefile.Reader('GIS_CensusTract_poly')\niwidth = 600\niheight = 400\n```", "```py\n# PIL Image\nimg = Image.new('RGB', (iwidth,iheight), (255,255,255))\n# PIL Draw module for polygon fills\ndraw = ImageDraw.Draw(img)\n```", "```py\n# Get the population AND area index\npop_index = None\narea_index = None\n# Shade the census tracts\nfor i,f in enumerate(inShp.fields):\n    if f[0] == 'POPULAT11':\n        # Account for deletion flag\n        pop_index = i-1\n    elif f[0] == 'AREASQKM':\n        area_index = i-1\n```", "```py\n# Draw the polygons\nfor sr in inShp.shapeRecords():\n    density = sr.record[pop_index]/sr.record[area_index]\n    # The 'weight' is a scaled value to adjust the color\n    # intensity based on population\n    weight = min(math.sqrt(density/80.0), 1.0) * 50\n    R = int(205 - weight)\n    G = int(215 - weight)\n    B = int(245 - weight)\n    pixels = []\n    for x,y in sr.shape.points:\n        (px,py) = world2screen(inShp.bbox, iwidth, iheight, x, y)\n        pixels.append((px,py))\n        draw.polygon(pixels, outline=(255,255,255), fill=(R,G,B))\n    img.save('choropleth.png')\n```", "```py\nimport xlrd\nimport shapefile\n# Open the spreadsheet reader\nxls = xlrd.open_workbook('NYC_MUSEUMS_GEO.xls')\nsheet = xls.sheet_by_index(0)\n# Open the shapefile writer\nw = shapefile.Writer(shapefile.POINT)\n# Move data from spreadsheet to shapefile\nfor i in range(sheet.ncols):\n    # Read the first header row\n    w.field(str(sheet.cell(0,i).value), 'C', 40)\nfor i in range(1, sheet.nrows):\n    values = []\n    for j in range(sheet.ncols):\n        values.append(sheet.cell(i,j).value)\n    w.record(*values)\n    # Pull latitude/longitude from the last two columns\n    w.point(float(values[-2]),float(values[-1]))\nw.save('NYC_MUSEUMS_XLS2SHP')\n```", "```py\nimport os\nimport folium\nfrom folium.plugins import HeatMap\nf = open('bear_sightings.csv', 'r')\nlines = f.readlines()\nlines.pop(0)\ndata = []\nbears = [list(map(float, l.strip().split(','))) for l in lines]\nm = folium.Map([32.75, -89.52], tiles='stamentonerbackground', zoom_start=7, max_zoom=7, min_zoom=7)\nHeatMap(bears, max_zoom=16, radius=22, min_opacity=1, blur=30).add_to(m)\nm.save('heatmap.html')\n```", "```py\n$GPRMC,012417.859,V,1856.599,N,15145.602,W,12.0,7.27,020713,,E\\*4F\n$GPGGA,012418.859,1856.599,N,15145.602,W,0,00,,,M,,M,,\\*54\n$GPGLL,1856.599,N,15145.602,W,012419.859,V\\*35\n$GPVTG,7.27,T,,M,12.0,N,22.3,K\\*52\n$GPRMC,012421.859,V,6337.596,N,12330.817,W,66.2,23.41,020713,,E\\*74\n```", "```py\nfrom pynmea.streamer import NMEAStream\nnmeaFile = open('nmea.txt')\nnmea_stream = NMEAStream(stream_obj=nmeaFile)\nnext_data = nmea_stream.get_objects()\nnmea_objects = []\nwhile next_data:\n    nmea_objects += next_data\n    next_data = nmea_stream.get_objects()\n# The NMEA stream is parsed!\n# Let's loop through the\n# Python object types:\nfor nmea_ob in nmea_objects:\n    if hasattr(nmea_ob, 'lat'):\n        print('Lat/Lon: (%s, %s)' % (nmea_ob.lat, nmea_ob.lon))\n```", "```py\nimport geocoder\ng = geocoder.google('1403 Washington Ave, New Orleans, LA 70130')\nprint(g.geojson)\n# {'type': 'Feature', 'geometry': {'type': 'Point', 'coordinates': [-90.08421849999999, 29.9287839]},\n'bbox': {'northeast': [29.9301328802915, -90.0828695197085], 'southwest': [29.9274349197085, -90.0855674802915]},\n'properties': {'quality': 'street_address', 'lat': 29.9287839, 'city': 'New Orleans',\n'provider': 'google', 'geometry': {'type': 'Point', 'coordinates': [-90.08421849999999, 29.9287839]},\n'lng': -90.08421849999999, 'method': 'geocode', 'encoding': 'utf-8', 'confidence': 9, 'address': '1403 Washington Ave,\nNew Orleans, LA 70130, USA', 'ok': True, 'neighborhood': 'Garden District', 'county': 'Orleans Parish',\n'accuracy': 'ROOFTOP', 'street': 'Washington Ave', 'location': '1403 Washington Ave, New Orleans, LA 70130',\n'bbox': {'northeast': [29.9301328802915, -90.0828695197085], 'southwest': [29.9274349197085, -90.0855674802915]},\n'status': 'OK', 'country': 'US', 'state': 'LA', 'housenumber': '1403', 'postal': '70130'}}\nprint(g.wkt)\n# 'POINT(-90.08421849999999 29.9287839)'\n```", "```py\nfrom geopy.geocoders import Nominatim\ng = Nominatim()\nlocation = g.geocode('88360 Diamondhead Dr E, Diamondhead, MS 39525')\nrev = g.reverse('{},{}'.format(location.latitude, location.longitude))\nprint(rev)\n# NVision Solutions Inc., 88360, Diamondhead Drive East, Diamondhead, Hancock County, Mississippi, 39520,\n# United States of America\nprint(location.raw)\n# {'class': 'office', 'type': 'yes', 'lat': '30.3961962', 'licence': 'Data © OpenStreetMap contributors,\n# ODbL 1.0\\. http://www.openstreetmap.org/copyright', 'display\\_name': 'NVision Solutions Inc.,\n# 88360, Diamondhead Drive East, Diamondhead, Hancock County, Mississippi, 39520, United States of America',\n# 'lon': '-89.3462139', 'boundingbox': ['30.3961462', '30.3962462', '-89.3462639', '-89.3461639'],\n# 'osm\\_id': '2470309304', 'osm\\_type': 'node', 'place\\_id': '25470846', 'importance': 0.421}\n```", "```py\n# Import our geocoding module\nfrom geopy.geocoders import Nominatim\n# Import the multiprocessing module\nimport multiprocessing as mp\n```", "```py\n# Create our geocoder\ng = Nominatim()\n```", "```py\n# Create a function to geocode an individual address\ndef gcode(address):\n    location = g.geocode(address)\n    print(\"Geocoding: {}\".format(address))\n    return location\n```", "```py\n# Our list of cities to process\ncities = [\"New Orleans, LA\", \"Biloxi, MS\", \"Memphis, TN\",\n\"Atlanta, GA\", \"Little Rock, AR\", \"Destin, FL\"]\n```", "```py\n# Create our processor pool counting all of the processors\n# on the machine.\npool = mp.Pool(processes=mp.cpu_count())\n```", "```py\n# Map our cities list to the geocoding function\n# and allow the processor pool to split it\n# across processors\nresults = pool.map(gcode, cities)\n```", "```py\n# Now print the results\nprint(results)\n\n# [Location(New Orleans, Orleans Parish, Louisiana, USA, (29.9499323, -90.0701156, 0.0)),\n# Location(Biloxi, Harrison County, Mississippi, USA, (30.374673, -88.8459433348286, 0.0)),\n# Location(Memphis, Shelby County, Tennessee, USA, (35.1490215, -90.0516285, 0.0)),\n# Location(Atlanta, Fulton County, Georgia, USA, (33.7490987, -84.3901849, 0.0)),\n# Location(Little Rock, Arkansas, USA, (34.7464809, -92.2895948, 0.0)),\n# Location(Destin, Okaloosa County, Florida, USA, (30.3935337, -86.4957834, 0.0))]\n```"]