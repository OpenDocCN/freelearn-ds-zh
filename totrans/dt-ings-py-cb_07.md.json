["```py\nfrom pyspark.sql import SparkSession\nspark = SparkSession.builder \\\n      .master(\"local[1]\") \\\n      .appName(\"chapter7_analytical_data\") \\\n      .config(\"spark.executor.memory\", '3g') \\\n      .config(\"spark.executor.cores\", '2') \\\n      .config(\"spark.cores.max\", '2') \\\n      .getOrCreate()\n```", "```py\n    df = spark.read.parquet('chapter7_parquet_files/yellow_tripdata_2022-01.parquet')\n    ```", "```py\ndf = spark.read.parquet('chapter7_parquet_files/')\n```", "```py\n    df.printSchema()\n    ```", "```py\ndf.toPandas().head(10)\n```", "```py\nspark.read.parquet()\n```", "```py\nyellow_tripdata_2022-01.snappy.parquet\n```", "```py\nspark.stop()\n```", "```py\n    from pyspark.sql import SparkSession\n    spark = SparkSession.builder \\\n          .master(\"local[1]\") \\\n          .appName(\"chapter7_analytical_data_avro\") \\\n          .config(\"spark.executor.memory\", '3g') \\\n          .config(\"spark.executor.cores\", '2') \\\n          .config(\"spark.cores.max\", '2') \\\n          .config(\"spark.jars.packages\", 'org.apache.spark:spark-avro_2.12:2.4.4') \\\n          .getOrCreate()\n    ```", "```py\n    df = spark.read.format('avro').load('chapter7_avro_files/file.avro')\n    ```", "```py\n    df.printSchema()\n    ```", "```py\nspark.read.format('avro')\n```", "```py\n     VendorID: long\n     tpep_pickup_datetime: timestamp\n     tpep_dropoff_datetime: timestamp\n     passenger_count: double\n     trip_distance: double\n     RatecodeID: double\n     store_and_fwd_flag: string\n     PULocationID: long\n     DOLocationID: long\n     payment_type: long\n     fare_amount: double\n     extra: double\n     mta_tax: double\n     tip_amount: double\n     tolls_amount: double\n     improvement_surcharge: double\n     total_amount: double\n     congestion_surcharge: double\n    ```", "```py\n    from pyspark.sql.types import StructType, StructField, StringType, LongType, DoubleType, TimestampType\n    schema = StructType([ \\\n        StructField(\"vendorId\", LongType() ,True), \\\n        StructField(\"tpep_pickup_datetime\", TimestampType() ,True), \\\n        StructField(\"tpep_dropoff_datetime\", TimestampType() ,True), \\\n        StructField(\"passenger_count\", DoubleType() ,True), \\\n        StructField(\"trip_distance\", DoubleType() ,True), \\\n        StructField(\"ratecodeId\", DoubleType() ,True), \\\n        StructField(\"store_and_fwd_flag\", StringType() ,True), \\\n        StructField(\"puLocationId\", LongType() ,True), \\\n        StructField(\"doLocationId\", LongType() ,True), \\\n        StructField(\"payment_type\", LongType() ,True), \\\n        StructField(\"fare_amount\", DoubleType() ,True), \\\n        StructField(\"extra\", DoubleType() ,True), \\\n        StructField(\"mta_tax\", DoubleType() ,True), \\\n        StructField(\"tip_amount\", DoubleType() ,True), \\\n        StructField(\"tolls_amount\", DoubleType() ,True), \\\n        StructField(\"improvement_surcharge\", DoubleType() ,True), \\\n        StructField(\"total_amount\", DoubleType() ,True), \\\n        StructField(\"congestion_surcharge\", DoubleType() ,True), \\\n        StructField(\"airport_fee\", DoubleType() ,True), \\\n    ])\n    ```", "```py\n    df_new_schema = spark.read.schema(schema).parquet('chapter7_parquet_files/yellow_tripdata_2022-01.parquet')\n    ```", "```py\n    df_new_schema.printSchema()\n    ```", "```py\n    df_new_schema.toPandas().head(10)\n    ```", "```py\n    StructField(\"tpep_pickup_datetime\", DateType() ,True), \\\n    StructField(\"tpep_dropoff_datetime\", DateType() ,True), \\\n```", "```py\n    df = spark.read.parquet('chapter7_parquet_files/')\n    ```", "```py\n    df.groupBy(\"vendorId\").count().orderBy(\"vendorId\").show()\n    ```", "```py\n    from pyspark.sql.functions import year, month, dayofmonth\n    df.groupBy(hour(\"tpep_pickup_datetime\")).count().orderBy(\"count\").show()\n    ```", "```py\ndf.groupBy(\"vendorId\").count().orderBy(\"vendorId\").show()\n```", "```py\ndf.groupBy(hour(\"tpep_pickup_datetime\")).count().orderBy(\"count\").show()\n```", "```py\n    df.createOrReplaceTempView(\"ny_yellow_taxi_data\")\n    ```", "```py\nvendor_groupby = spark.sql(\n\"\"\"\nSELECT vendorId, COUNT(*) FROM ny_yellow_taxi_data\nGROUP BY vendorId\nORDER BY COUNT(*)\n\"\"\"\n)\n```", "```py\n    vendor_groupby.show()\n    ```", "```py\n    df_partitioned = spark.read.parquet(\"chapter7_partitioned_files/month=2/\")\n    ```", "```py\n    df_partitioned.toPandas()\n    ```", "```py\ndf.coalesce(1).write.parquet('myfile/path')\n```"]