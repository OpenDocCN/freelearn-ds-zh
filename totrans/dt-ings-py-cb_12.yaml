- en: '12'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Using Data Observability for Debugging, Error Handling, and Preventing Downtime
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We are reaching the end of our journey through the data ingestion world and
    have covered many important topics and seen how they could be applied to real-life
    projects. Now, to finish this book with a flourish, the final topic is the concept
    of **data observability**.
  prefs: []
  type: TYPE_NORMAL
- en: Data observability refers to the ability to monitor, understand, and troubleshoot
    the health, quality, and other vital aspects of data in a big organization or
    a small project. In summary, it ensures that data is accurate, reliable, and available
    when needed.
  prefs: []
  type: TYPE_NORMAL
- en: Although each recipe in this chapter can be executed separately, the goal is
    to configure tools that, when set together, create a monitoring and observability
    architecture ready to bring value to a project or team.
  prefs: []
  type: TYPE_NORMAL
- en: 'You will learn about the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Setting up StatsD for monitoring
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Setting up Prometheus for storing metrics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Setting up Grafana for monitoring
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating an observability dashboard
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Setting custom alerts or notiﬁcations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter requires that Airflow is installed on your local machine. You can
    install it directly on your **Operating System** (**OS**) or using a Docker image.
    For more information, refer to [*Chapter 1*](B19453_01.xhtml#_idTextAnchor022),
    and the *Configuring Docker for* *Airflow* recipe.
  prefs: []
  type: TYPE_NORMAL
- en: 'After following the steps described in [*Chapter 1*](B19453_01.xhtml#_idTextAnchor022),
    ensure Airflow runs correctly. You can do that by checking the Airflow UI at this
    link: `http://localhost:8080`'
  prefs: []
  type: TYPE_NORMAL
- en: 'If you are using a Docker container (as I am) to host your Airflow application,
    you can check its status in the terminal by using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the status of the container:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.1 –  Airflow containers running](img/Figure_12.01_B19453.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.1 – Airflow containers running
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.2 – Docker Desktop view of Airflow containers running](img/Figure_12.02_B19453.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.2 – Docker Desktop view of Airflow containers running
  prefs: []
  type: TYPE_NORMAL
- en: Docker images
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This chapter requires the creation of other Docker containers to build the monitoring
    and observability architecture. If you are using `docker-compose.yaml` file to
    run your Airflow application, you can add the other images addressed here to the
    same `docker-compose.yaml` file and run it all together.
  prefs: []
  type: TYPE_NORMAL
- en: If you are running Airflow locally, you can create and configure each Docker
    image separately or create a `docker-compose.yaml` file just for the monitoring
    tools approach in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up StatsD for monitoring
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As introduced in [*Chapter 10*](B19453_10.xhtml#_idTextAnchor364), **StatsD**
    is an open source daemon that gathers and aggregates metrics about application
    behaviors. Due to its flexibility and lightweight, StatsD is used on several monitoring
    and observability tools, such as **Grafana**, **Prometheus**, and **ElasticSearch**,
    to visualize and analyze the collected metrics.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we will configure StatsD using a Docker image as the first step
    in building a monitoring pipeline. Here, StatsD will collect and aggregate Airflow
    information and make it available to Prometheus, our monitoring database, in the
    *Setting up Prometheus for storing* *metrics* recipe.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Refer to the *Technical requirements* section for this recipe since we will
    handle it with the same technology.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here are the steps to perform this recipe:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s start by defining our Docker configurations for StatsD. These lines will
    be added under the `services` section inside the `docker-compose` file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, let’s set the Airflow environment variables to install StatsD and export
    the metrics to it, as you can see here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: If you need help to set these variables in Airflow, please refer to [*Chapter
    10*](B19453_10.xhtml#_idTextAnchor364), and the *Configuring logs in* *airflow.cfg*
    recipe.
  prefs: []
  type: TYPE_NORMAL
- en: 'Your Airflow variables in the `docker-compose` file should look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.3 – Airflow environment variables with StatsD configurations](img/Figure_12.03_B19453.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.3 – Airflow environment variables with StatsD configurations
  prefs: []
  type: TYPE_NORMAL
- en: Now, restart your Docker containers to apply the configurations.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Once you do so, and all containers are up and running, let’s check the `http://localhost:9102/`
    address in a browser. You should see the following page:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 12.4 – StatsD page in the browser](img/Figure_12.04_B19453.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.4 – StatsD page in the browser
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, click on **Metrics**, and a new page will appear showing something similar
    to the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 12.5 – StatsD metrics being shown in the browser](img/Figure_12.05_B19453.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.5 – StatsD metrics being shown in the browser
  prefs: []
  type: TYPE_NORMAL
- en: The lines shown in the browser confirm StatsD is successfully installed and
    collecting data from Airflow.
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As you can observe, configuring StatsD with Airflow is very straightforward.
    In fact, StatsD is not new for us since we already covered it in [*Chapter 10*](B19453_10.xhtml#_idTextAnchor364),
    in the *Designing advanced monitoring* recipe. However, let’s recap some of the
    concepts.
  prefs: []
  type: TYPE_NORMAL
- en: StatsD is an open source daemon tool built by Etsy employees that receives information
    via the **User Datagram Protocol** (**UDP**), making it fast and lightweight since
    it discards the necessity of sending a confirmation message back to the sender.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, looking at the code, the first thing we did was to set the Docker container
    to run StatsD. Alongside all the usual parameters to run a container, the key
    point is the `command` parameter, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You can check the Docker image of StatsD on the **Docker Hub** page here: [https://hub.docker.com/r/prom/statsd-exporter](https://hub.docker.com/r/prom/statsd-exporter)'
  prefs: []
  type: TYPE_NORMAL
- en: Setting up Prometheus for storing metrics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Although it is generally called a database, Prometheus is not a traditional
    database like MySQL. Instead, its structure is more similar to a time-series database
    designed for monitoring and observability purposes.
  prefs: []
  type: TYPE_NORMAL
- en: Due to its flexibility and power, this tool is widely used by DevOps and **Site
    Reliability Engineers** (**SREs**) to store metrics and other relevant information
    about systems and applications. Together with Grafana (which we will explore in
    later recipes), it is one of the most used monitoring tools in projects and by
    teams.
  prefs: []
  type: TYPE_NORMAL
- en: This recipe will configure a Docker image to run a Prometheus application. We
    will also connect it to StatsD to store all the metrics generated.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Refer to the *Technical requirements* section for this recipe since we will
    handle it with the same technology.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here are the steps to perform this recipe:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s begin by adding the following lines to our `docker-compose` file under
    the `services` section:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, create a folder named `prometheus` at the same level as your `docker-compose`
    file. Inside the folder, create a new file named `prometheus.yml` with the following
    code and save it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: On `static_configs`, make sure the target has the same name and the exposed
    port of the StatsD container. Otherwise, you will face problems in establishing
    a connection with the container.
  prefs: []
  type: TYPE_NORMAL
- en: Now, restart your Docker containers.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'When the containers are back up and running, access the following link in your
    browser: `http://localhost:9090/`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You should see a page like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.6 – Prometheus UI](img/Figure_12.06_B19453.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.6 – Prometheus UI
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, click on the list icon next to the **Execute** button on the right of
    the page. It will open a list with all metrics available to be used. If everything
    is well configured, you should see something like the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 12.7 – Prometheus available metric list](img/Figure_12.07_B19453.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.7 – Prometheus available metric list
  prefs: []
  type: TYPE_NORMAL
- en: We have successfully set up Prometheus, which is already storing the metrics
    sent by StatsD!
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s explore in more depth what we did in this exercise by examining the container
    definitions in *Step 1*. Since we already have basic knowledge of Docker, we will
    cover the most critical parts of the container settings.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first thing that draws attention is the `links` section in the `docker-compose`
    file. In this section, we declared that the Prometheus container must be connected
    and linked to the StatsD container configured in the *Setting up StatsD for* *monitoring*
    recipe:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we set `volumes` to reflect a local folder to a folder inside the container.
    This step is essential because then we can also mirror the configuration file
    of Prometheus:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, in the `command` section, we declared where the configuration file
    will be placed inside the container and other minor settings:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, the following steps were dedicated to setting the Prometheus configuration
    file, as you can see here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: By definition, Prometheus collects metrics from itself and other applications
    through an HTTP request. In other words, it parses the response and ingests the
    collected samples for storage. That’s why we used `scrape_configs`.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you look closely, you will observe that we declared two scrape jobs: one
    for Prometheus and another for StatsD. Due to that configuration, we could see
    Airflow metrics in the Prometheus metrics list. If we needed to include any other
    scrape configuration, we would just need to edit the local `prometheus.yml` file
    and restart the server.'
  prefs: []
  type: TYPE_NORMAL
- en: Many other configurations are available in Prometheus, such as setting the scrape
    interval. You can read more about its configurations on the official documentation
    page at [https://prometheus.io/docs/prometheus/latest/getting_started/](https://prometheus.io/docs/prometheus/latest/getting_started/).
  prefs: []
  type: TYPE_NORMAL
- en: There’s more…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this recipe, we saw how to set Prometheus to store metrics coming from StatsD.
    This time-series database also has other capabilities, such as creating small
    visualizations in the web UI and connecting with other client libraries, and has
    an alerting system called Alertmanager.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want to go deeper into how Prometheus works and other functionalities,
    Sudip Sengupta has a fantastic blog post about it, which you can read here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.airplane.dev/blog/prometheus-metrics](https://www.airplane.dev/blog/prometheus-metrics)'
  prefs: []
  type: TYPE_NORMAL
- en: Setting up Grafana for monitoring
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Grafana** is an open source tool built to create visualizations and monitor
    data from other systems and applications. Together with Prometheus, it is one
    of the most popular DevOps tools due to its flexibility and rich features.'
  prefs: []
  type: TYPE_NORMAL
- en: In this exercise, we will configure a Docker image to run Grafana and connect
    it to Prometheus. This configuration will not only give us the ability to explore
    the Airflow metrics even further but also the opportunity to learn in practice
    how to work with a set of the most popular tools for monitoring and observability.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Refer to the *Technical requirements* section for this recipe since we will
    handle it with the same technology.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, I will use the same `docker-compose.yaml` file of Airflow and
    will keep the configurations from the *Setting up StatsD for monitoring* and *Setting
    up Prometheus for storing metrics* recipes, to connect them and proceed with the
    monitoring and observability architecture.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Perform the following steps to try this recipe:'
  prefs: []
  type: TYPE_NORMAL
- en: 'As shown in the following, let’s add the Grafana container information to our
    `docker-compose` file as usual. Make sure it is under the `services` section:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Feel free to use a different administrator username as a password.
  prefs: []
  type: TYPE_NORMAL
- en: Now, create a folder called `grafana` on the same level as your Docker file,
    and restart your containers.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'After it is back up and running, insert the `http://localhost:3000/login` link
    in your browser. A login page similar to this will appear:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 12.8 – Grafana login page](img/Figure_12.08_B19453.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.8 – Grafana login page
  prefs: []
  type: TYPE_NORMAL
- en: It confirms Grafana is set up correctly!
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, let’s use the administrator credentials to log in to the Grafana dashboard.
    After authenticating, you should see the main page as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 12.9 – Grafana main page](img/Figure_12.09_B19453.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.9 – Grafana main page
  prefs: []
  type: TYPE_NORMAL
- en: Since it is our first login, this page has nothing to show. We will take care
    of visualizations in the *Creating an observability* *dashboard* recipe.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s add Prometheus as a data source to Grafana. On the bottom-left side
    of the page, hover your cursor over the engine icon. On the **Configuration**
    menu, select **Data sources**. See the following screenshot for reference:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 12.10 – Grafana Configuration menu](img/Figure_12.10_B19453.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.10 – Grafana Configuration menu
  prefs: []
  type: TYPE_NORMAL
- en: 'On the **Data Sources** page, select the Prometheus icon. You will be redirected
    to a new page showing fields to insert Prometheus settings, as you can see here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 12.11 – Data Sources page in Grafana](img/Figure_12.11_B19453.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.11 – Data Sources page in Grafana
  prefs: []
  type: TYPE_NORMAL
- en: Insert a name for this data source. In the `http://prometheus:9090`. Make sure
    it has the same name as your Docker container for Prometheus.
  prefs: []
  type: TYPE_NORMAL
- en: Save this configuration, and we have successfully configured Grafana with Prometheus!
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this exercise, we saw how simple it is to configure Grafana and integrate
    it with Prometheus as a data source. In fact, almost all Grafana integrations
    are very straightforward, requiring just a few pieces of information.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s now explore some of our Grafana container settings. Despite the standard
    Docker container settings, a few items require attention, as you can see here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The first things are the `environment` variables, where we define the administrator
    credentials that allow the first login. Then, we declared the path of Grafana
    provisioning, and, as you will have noticed, we also inserted this path in the
    `volumes` section.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is inside the `provisioning` folder where we will have configuration files
    for data sources connections, plugins, dashboards, and much more. A configuration
    like this allows more reliability and version control of dashboards and panels.
    We could also create the Prometheus data source connection using a .`yaml` configuration
    file and place it under the `provisioning` and `datasources` folder. It would
    look similar to this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Any additional data sources can be placed inside this YAML file. You can explore
    more about the provisioning configurations in Grafana on the official documentation
    page at [https://grafana.com/docs/grafana/latest/administration/provisioning/](https://grafana.com/docs/grafana/latest/administration/provisioning/).
  prefs: []
  type: TYPE_NORMAL
- en: 'With this, we created a simple and efficient monitoring and observability architecture
    capable of collecting metrics from Airflow (or any other application if needed),
    storing, and showing them. The architecture can be defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.12 – Monitoring and observability high-level architecture](img/Figure_12.12_B19453.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.12 – Monitoring and observability high-level architecture
  prefs: []
  type: TYPE_NORMAL
- en: We can now start creating our first dashboard and alerts in the two final recipes
    of this chapter!
  prefs: []
  type: TYPE_NORMAL
- en: There’s more…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Besides Prometheus, Grafana has built-in core data source integrations for
    many applications. It allows easy configuration and a quick setup, which brings
    a lot of value and maturity to a project. You can find more here: [https://grafana.com/docs/grafana/latest/datasources/#built-in-core-data-sources](https://grafana.com/docs/grafana/latest/datasources/#built-in-core-data-sources).'
  prefs: []
  type: TYPE_NORMAL
- en: Grafana Cloud
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Grafana Labs has also made the platform available as fully managed and deployed
    on the cloud. It is a great solution for teams that don’t have a dedicated operations
    team to support and maintain Grafana. Find more information here: [https://grafana.com/products/cloud/](https://grafana.com/products/cloud/).'
  prefs: []
  type: TYPE_NORMAL
- en: Creating an observability dashboard
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now, with our tools up and running, we can finally jump into the visualization
    dashboards. Monitoring and observability dashboards are designed to help gain
    deep insights into the health and behavior of our systems. You will observe in
    this exercise how Grafana can help us create an observability dashboard and a
    number of features inside it.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we will create our first dashboard with a few panels to better
    monitor our Airflow application. You will notice that, with a few steps, it is
    possible to have an overview of how Airflow behaves over time and be prepared
    to build your future panels.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Refer to the *Technical requirements* section for this recipe since we will
    handle it with the same technology.
  prefs: []
  type: TYPE_NORMAL
- en: To accomplish this exercise, ensure that StatsD, Prometheus, and Grafana are
    adequately configured and running.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s create our dashboard to keep track of Airflow:'
  prefs: []
  type: TYPE_NORMAL
- en: 'On the Grafana main page, hover the cursor over the four-squares icon on the
    left side panel. Then, select **New dashboard**, as you can see in the following
    screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 12.13 – Grafana Dashboards menu](img/Figure_12.13_B19453.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.13 – Grafana Dashboards menu
  prefs: []
  type: TYPE_NORMAL
- en: If you need help accessing Grafana, refer to the *Setting up Grafana for* *monitoring*
    recipe.
  prefs: []
  type: TYPE_NORMAL
- en: 'You will be redirected to an empty page with the title **New dashboard**. At
    the top right of the page, select **Save**, insert the name of your dashboard,
    and click the **Save** button again. Refer to the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 12.14 – New dashboard page](img/Figure_12.14_B19453.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.14 – New dashboard page
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s create our first panel by clicking on the **Add panel** icon at
    the top right of the dashboard page, as you can see in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 12.15 – Add panel icon](img/Figure_12.15_B19453.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.15 – Add panel icon
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s create a panel to show the number of DAGs inside Airflow. On the
    **Edit Panel** page, set the following information:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Metric**: **airflow_dagbag_size**'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Label filters**: **job**, **statsd-exporter**'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Visualization type: **Stat**'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can see the filled information in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.16 – Airflow number of DAGs panel count](img/Figure_12.16_B19453.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.16 – Airflow number of DAGs panel count
  prefs: []
  type: TYPE_NORMAL
- en: Click on **Apply** to save and return to the dashboard page.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s do the same as *Step 3* to create another panel. This time we will create
    a panel to show the number of Airflow import errors. Fill the fields with the
    following values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Metric**: **airflow_dag_processing_import_errors**'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Label filters**: **job**, **statsd-exporter**'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Visualization type: **Stat**'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can see the added information in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.17 – DAG import errors panel count](img/Figure_12.17_B19453.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.17 – DAG import errors panel count
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s create two more panels with the following information:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`airflow_executor_queued_tasks`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`job`, `statsd-exporter`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Visualization type: **Stat**'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Metric**: **airflow_scheduler_tasks_running**'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Label filters**: **job**, **statsd-exporter**'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Visualization type: **Stat**'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let’s create two more panels to show the execution time for two different DAGs.
    Create two panels with the following values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Metric**: **airflow_dag_processing_last_duration_basic_logging_dag**'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Label filters**: **quantile**, **0.99**'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Visualization type: **Time-series**'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Refer to the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.18 – basic_logging_dag execution run panel](img/Figure_12.18_B19453.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.18 – basic_logging_dag execution run panel
  prefs: []
  type: TYPE_NORMAL
- en: '**Metric**: **airflow_dag_processing_last_duration_holiday_ingest_dag**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Label filters**: **quantile**, **0.99**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Visualization type: **Time-series**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can see the completed fields in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.19 – holiday_ingest_dag execution run panel](img/Figure_12.19_B19453.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.19 – holiday_ingest_dag execution run panel
  prefs: []
  type: TYPE_NORMAL
- en: 'In the end, you will end up with a dashboard similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.20 – Complete Airflow Monitoring dashboard view](img/Figure_12.20_B19453.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.20 – Complete Airflow Monitoring dashboard view
  prefs: []
  type: TYPE_NORMAL
- en: Don’t worry if your dashboard layout does not look exactly like *Figure 12**.20*.
    You can rearrange the panel as much as you want to add your own touch!
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are many DevOps visualization tools available on the market. However,
    most require a paid subscription or trained people to build the panels. As you
    can observe in this exercise, creating the first dashboard and panels using Grafana
    can be pretty simple. Of course, as you practice and study advanced concepts in
    Grafana, you will observe many opportunities to improve and enhance your dashboard.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s explore the six panels we have created. The idea behind these panels
    was to create a small dashboard with a minimum of information that could already
    bring value.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first four panels give quick and relevant information about Airflow, as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.21 –Airflow Monitoring counter panels](img/Figure_12.21_B19453.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.21 –Airflow Monitoring counter panels
  prefs: []
  type: TYPE_NORMAL
- en: They show information about the number of DAGs, how many import errors we have,
    the number of tasks waiting to be executed, and how many are being executed, respectively.
    Even though it seems simple, these pieces of information give an overview (therefore,
    observability) of Airflow’s current behavior.
  prefs: []
  type: TYPE_NORMAL
- en: 'The last two panels show information about the duration of two DAG executions,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.22 – Airflow Monitoring time-series panels](img/Figure_12.22_B19453.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.22 – Airflow Monitoring time-series panels
  prefs: []
  type: TYPE_NORMAL
- en: Knowing how much time a DAG takes to run is vital information, and it can offer
    insight to improve the code or check whether the data used in the pipeline is
    reliable. For example, if the DAG executes all tasks in less than half the expected
    time, it can be a sign no data was processed correctly.
  prefs: []
  type: TYPE_NORMAL
- en: 'Lastly, you can create more dashboards and organize them into folders according
    to the subject. You can check the recommended best practices for dashboard organization
    in Grafana’s official documentation here: [https://grafana.com/docs/grafana/latest/dashboards/build-dashboards/best-practices/](https://grafana.com/docs/grafana/latest/dashboards/build-dashboards/best-practices/).'
  prefs: []
  type: TYPE_NORMAL
- en: There’s more…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Unfortunately, since we have limited data to show on a dashboard, this exercise
    might not be as fancy as you expected. However, you can explore Grafana panel
    configurations and master them for further projects using the Grafana playground
    here: [https://play.grafana.org/d/000000012/grafana-play-home?orgId=1](https://play.grafana.org/d/000000012/grafana-play-home?orgId=1).'
  prefs: []
  type: TYPE_NORMAL
- en: On the **Grafana Play Home** page, you will be able to see different types of
    panel applications and explore how they were built.
  prefs: []
  type: TYPE_NORMAL
- en: Setting custom alerts or notiﬁcations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After configuring our first dashboard to be aware of the Airflow application,
    we must ensure our monitoring is never left without observation. With teams busy
    with other tasks, creating alerts is the best way to guarantee we still have oversight
    over the application.
  prefs: []
  type: TYPE_NORMAL
- en: There are many ways to create alerts and notifications, and previously we implemented
    something similar to monitor our DAG by sending an email notification when an
    error occurs. Now, we will try a different approach, using an integration with
    **Telegram**.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we will integrate Grafana alerts with Telegram. Using a different
    tool to provide system alerts can help us understand the best approach to advise
    our teams and break the cycle of always using email.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Refer to the *Technical requirements* section for this recipe since we will
    handle it with the same technology.
  prefs: []
  type: TYPE_NORMAL
- en: 'To accomplish this exercise, ensure that StatsD, Prometheus, and Grafana are
    adequately configured and running. It is also required to have a Telegram account
    for this exercise. You can find the steps to create an account here: [https://www.businessinsider.com/guides/tech/how-to-make-a-telegram-account](https://www.businessinsider.com/guides/tech/how-to-make-a-telegram-account).'
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here are the steps to perform this recipe:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s start by creating a bot on Telegram to be used by Grafana to send the
    alerts. On the Telegram main page, search for `@BotFather` and start a conversation
    as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 12.23 – Telegram BotFather](img/Figure_12.23_B19453.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.23 – Telegram BotFather
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, type `/newbot` and follow the prompt instructions. BotFather will send
    you a bot token. Please keep it in a safe place; we will use it later. The message
    looks like the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 12.24 – New bot creation message](img/Figure_12.24_B19453.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.24 – New bot creation message
  prefs: []
  type: TYPE_NORMAL
- en: Next, create a group on Telegram and invite your bot to it with administrator
    privileges.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now, let’s use the Telegram API to check the channel ID where the bot is. You
    can do it by using the following address in your browser:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should see a similar output in the browser:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.25 – Telegram API message with Chat ID](img/Figure_12.25_B19453.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.25 – Telegram API message with Chat ID
  prefs: []
  type: TYPE_NORMAL
- en: We will use the `id` value later, so keep this in a safe place too.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, let’s proceed to create a Grafana notification group. On the left menu
    bar, hover your cursor over the bell icon, and select **Contact points**, shown
    as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 12.26 – Grafana Alerting menu](img/Figure_12.26_B19453.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.26 – Grafana Alerting menu
  prefs: []
  type: TYPE_NORMAL
- en: 'On the **Contact points** tab, select **Add contact point** as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 12.27 – Contact points tab in Grafana](img/Figure_12.27_B19453.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.27 – Contact points tab in Grafana
  prefs: []
  type: TYPE_NORMAL
- en: 'Add a name on the **New contact point** page and choose **Telegram** in the
    **Integration** drop-down menu. Then, complete the **Bot API Token** and **Chat
    ID** fields. You can see what it looks like here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 12.28 – New contact point page](img/Figure_12.28_B19453.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.28 – New contact point page
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s ensure we inserted the values correctly while selecting the **Test**
    button. If everything is well configured, you will receive a message on the channel
    you have your bot in, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 12.29 – Grafana test message working successfully](img/Figure_12.29_B19453.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.29 – Grafana test message working successfully
  prefs: []
  type: TYPE_NORMAL
- en: It means our bot is ready! Save the contact point and go back to the alerts
    page.
  prefs: []
  type: TYPE_NORMAL
- en: 'In **Notification policies**, edit the **Root policy** contact point to your
    Telegram bot as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 12.30 – Grafana Notification policies tab](img/Figure_12.30_B19453.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.30 – Grafana Notification policies tab
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, let’s create an alert rule to trigger an alert notification. On the
    **Alert rules** page, select **Create alert rule** to be redirected to a new page.
    Insert the following values in the fields on this page:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Rule name**: **Import errors**'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Metric**: **airflow_dag_processing_import_errors**'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Label filters**: **instance**, **statsd-exporter:9102**'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Threshold**: **Input A**, **IS** **ABOVE 1**'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Folder**: Create a new folder called **Errors** and **test_group** in **Evaluation
    group**'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Rule group evaluation interval**: **3 minutes**'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You should have something similar to the following screenshot. You can also
    use it as a reference to fill in the fields:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.31 – New alert rule for Airflow import errors on Grafana](img/Figure_12.31_B19453.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.31 – New alert rule for Airflow import errors on Grafana
  prefs: []
  type: TYPE_NORMAL
- en: Save it, and let’s simulate an import error in Airflow.
  prefs: []
  type: TYPE_NORMAL
- en: 'After creating any import error in a DAG on Airflow, you will receive a notification
    on the Telegram channel similar to the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 12.32 – Telegram bot showing a notification after being triggered
    by a Grafana alert](img/Figure_12.32_B19453.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.32 – Telegram bot showing a notification after being triggered by
    a Grafana alert
  prefs: []
  type: TYPE_NORMAL
- en: Since this is a local test, you don’t need to worry about the `Annotations`
    part for now.
  prefs: []
  type: TYPE_NORMAL
- en: Our Grafana notification works, and it is fully integrated with Telegram!
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Although this recipe has many steps, the content is not complex. This exercise
    aims to give you a practical end-to-end example of configuring a simple bot to
    create alerts whenever needed.
  prefs: []
  type: TYPE_NORMAL
- en: Bots are frequently used in DevOps as a tool for notifications of an action,
    and it was no different here. From *Step 1* to *Step 4*, we focused on configuring
    a bot in Telegram and a channel where Grafana notifications could be sent. There
    is no particular reason for choosing Telegram as our messenger, other than the
    ease of creating an account. Usually, messengers such as **Slack** or **Microsoft
    Teams** are the favorites of operation teams, and plenty of online tutorials show
    how to use them.
  prefs: []
  type: TYPE_NORMAL
- en: 'After configuring the bot, we proceeded to connect it with Grafana. The configuration
    only required a few pieces of information, such as an authentication token (to
    control the bot) and the channel’s ID. As you observed, many types of integrations
    are available, and more can be added when installing a plugin. You can see the
    complete list of plugins here: [https://grafana.com/grafana/plugins/](https://grafana.com/grafana/plugins/).'
  prefs: []
  type: TYPE_NORMAL
- en: If we needed more than one contact point, we could create it on the **Contact
    points** tab and create a notification policy to include the new contact as a
    point to be notified.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we created an alert rule based on the number of Airflow import errors.
    Import errors can impair the execution of one or more DAGs; therefore, they are
    relevant items to monitor.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two ways to create an alert and notification: on the **Alert rules**
    page and directly on a dashboard panel. The latter depends on the panel type,
    and not all of the panels support integrated alerts. The safest option, and the
    best practice, is to create an alert rule on the **Alert** **rules** page.'
  prefs: []
  type: TYPE_NORMAL
- en: Creating an alert is similar to a panel, where we need to identify metrics and
    labels, and the critical points are the **Threshold** and **Alert Evaluation**
    conditions. These two configurations will determine the limit of metric value
    acceptance and how long it can take. We set a shallow threshold with a short evaluation
    time for testing purposes and intentionally provoked an error. Still, a standard
    alert rule can have more time tolerance and a threshold based on the needs of
    the team.
  prefs: []
  type: TYPE_NORMAL
- en: In the end, with everything well set, we saw the bot in action, providing the
    alert as soon as the trigger conditions were met.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[https://dev.to/kirklewis/metrics-with-prometheus-statsd-exporter-and-grafana-5145](https://dev.to/kirklewis/metrics-with-prometheus-statsd-exporter-and-grafana-5145)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://github.com/uber/cadence/pull/4793/files#diff-32d8136ee76608ed05392cfd5e8dce9a56ebdad629f7b87961c69a13edef88ec](https://github.com/uber/cadence/pull/4793/files#diff-32d8136ee76608ed05392cfd5e8dce9a56ebdad629f7b87961c69a13edef88ec)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://databand.ai/blog/everyday-data-engineering-monitoring-airflow-with-prometheus-statsd-and-grafana/](https://databand.ai/blog/everyday-data-engineering-monitoring-airflow-with-prometheus-statsd-and-grafana/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://www.xenonstack.com/insights/observability-vs-monitoring](https://www.xenonstack.com/insights/observability-vs-monitoring)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://www.instana.com/blog/observability-vs-monitoring/](https://www.instana.com/blog/observability-vs-monitoring/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://acceldataio.medium.com/a-guide-to-evaluating-data-observability-tools-5589ad9d35ed](https://acceldataio.medium.com/a-guide-to-evaluating-data-observability-tools-5589ad9d35ed)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
