<html><head></head><body>
        

                            
                    Practical Sentiment Analysis
                
            
            
                
<p>This is going to be a fun chapter. In this chapter, we will explore and demonstrate some practical examples of using <strong>Natural Language Processing</strong> (<strong>NLP</strong>) concepts to understand how unstructured text can be turned into insights. In <a href="84b19b06-81f4-460f-8c4c-a776f4e66c24.xhtml">Chapter 10</a>, <em>Exploring Text Data and Unstructured Data</em>, we explored the <strong>Natural Language Toolkit</strong> (<strong>NLTK</strong>) library and some fundamental features of working with identifying words, phrases, and sentences. In that process of tokenizing, we learned how to work with data and classify text, but did not go beyond that. In this chapter, we will learn about sentiment analysis, which predicts the underlying tone of text that's input into an algorithm. We will break down the elements that make up an NLP model and the packages used for sentiment analysis before walking through an example together.</p>
<p>In this chapter, we will cover the following topics:</p>
<ul>
<li>Why sentiment analysis is important</li>
<li>Elements of an NLP model</li>
<li>Sentiment analysis packages</li>
<li>Sentiment analysis in action</li>
</ul>
<p>Let's get started.</p>
<h1 id="uuid-83ce730f-efae-4631-ab17-96ab67cdd771">Technical requirements</h1>
<p>You can find the GitHub repository for this book at <a href="https://github.com/PacktPublishing/Practical-Data-Analysis-using-Jupyter-Notebook/tree/master/Chapter11">https://github.com/PacktPublishing/Practical-Data-Analysis-using-Jupyter-Notebook/tree/master/Chapter11</a>.</p>
<p>You can download and install the required software for this chapter from the following link: <a href="https://www.anaconda.com/products/individual" target="_blank">https://www.anaconda.com/products/individual</a>.</p>
<h1 id="uuid-bfc0dd88-eeb3-4c7d-9d54-1c80489e1bb7" class="mce-root">Why sentiment analysis is important</h1>
<p>Today, we are all living in a digital age where data is entangled in our daily lives. However, since most of this data is unstructured and the volume of it is large, it requires statistical libraries and <strong>machine learning</strong> (<strong>ML</strong>) to apply it to technology solutions. The NLTK libraries serve as a framework for us to work with unstructured data, and sentiment analysis serves as a practical use case in NLP. <strong>Sentiment analysis</strong>, or opinion mining, is a type of supervised ML that requires a training dataset to accurately predict an input sentence, phrase, headline, or even tweet is positive, negative, or neutral. Once the model has been trained, you can pass unstructured data into it, like a function, and it will return a value between negative one and positive one. The number will output decimals, and the closer it is to an integer, the more confident the model's accuracy will be. Sentiment analysis is an evolving science, so our focus will be on using the NLTK corpus libraries. As with any NLP model, you will find inaccuracies in the predicted output if you don't have a good sample for the input training data.</p>
<p>Also, note that NLP and sentiment analysis is a deep subject and should be validated by a data scientist or ML engineering team if you plan on implementing your own models using internal company data sources. That being said, you will notice sentiment analysis in many different applications today, and the exercises in this chapter provide you with another tool for data analysis. Another benefit of learning about how to use sentiment analysis is that it allows you to argue about the data that's output from a model. The ability to defend the accuracy and predictive nature of working with unstructured data will increase your data literacy skills. For example, let's say you are analyzing a population of tweets about a restaurant for a marketing campaign that had a mix of positive and negative reviews in the past. If the results of your analysis come back as 100% positive, you should start questioning the training data, the source of the data, and the model itself. Of course, it's possible for all the tweets to be positive, especially against a small population of data, but is it likely that every single one has a positive sentiment?</p>
<p class="mce-root">This is why <strong>Knowing Your Data</strong> (<strong>KYD</strong>) remains important, as covered in <a href="0fa7e28f-7a30-4099-9bae-30dd3c86ee4f.xhtml">Chapter 1</a>, <em>Fundamentals of Data Analysis</em>, regardless of the technology and tools being used to analyze it. However, why sentiment analysis is important today needs to be stated. First, the accuracy of the models has significantly improved because the more training data there is, the better the prediction's output. The second point is that NLP models can scale beyond what a human can process in the same amount of time. Finally, the alternatives to sentiment analysis available today, such as expert systems, are more costly because of the time and resources required to implement them. Expert system development using text-based logic and wildcard keyword searches is rigid and difficult to maintain.</p>
<p>Now, let's explore what makes up the elements of NLP and the process of how it is used in sentiment analysis.</p>
<h1 id="uuid-b5180901-a91c-47e9-a223-e77ff2c3d890">Elements of an NLP model</h1>
<p>To summarize the process required to use an NLP supervised ML model for sentiment analysis, I have created the following diagram, which shows the elements in a logical progression indicated by the letters <strong>A</strong> through <strong>E</strong>:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/2ed89905-db73-4ed0-af73-182b11d8d644.png" style="width:43.92em;height:26.00em;"/></p>
<p>The process begins with our source <strong>Unstructured Input Data</strong>, which is represented in the preceding diagram with the letter A. Since unstructured data has different formats, structures, and forms such as a tweet, sentence, or paragraph, we need to perform extra steps to work with the data to gain any insights.</p>
<p>The next element is titled Text Normalization and is represented by the letter B in the preceding diagram, and involves concepts such as tokenization, n-grams, and <strong>bag-of-words</strong> (<strong>BoW</strong>), which were introduced in <a href="84b19b06-81f4-460f-8c4c-a776f4e66c24.xhtml">Chapter 10</a>, <em>Exploring Text Data and Unstructured Data</em>. Let's explore them in more detail so that we can learn how they are applied in sentiment analysis. BoW is when a string of text such as a sentence or paragraph is broken down to determine how many times a word occurs. In the process of <strong>tokenizing</strong> to create the bag-of-words representation, the location of where the word appears in a sentence, tweet, or paragraph becomes less relevant. How each word is classified, categorized, and defined using a classifier will serve as input to the next process.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p>Think of tokens and bag-of-words as raw ingredients to the sentiment analysis recipe; as in cooking, the ingredients take additional steps of refinement. Hence, the concept of classification becomes important. This is considered a <strong>Features</strong> and is represented by the letter C in the preceding diagram. Because tokens are nothing more than ASCII characters to a computer, word embedding and tagging is the process of converting the words into an input for an ML model. An example would be to classify each word with a pair value such as a one or zero to represent true or false. This process also includes finding similar words or groupings in order to interpret the context.</p>
<p>Creating <strong>Features</strong> is known as feature engineering, which is the foundation of supervised ML. Feature engineering is the process of transforming unstructured data elements into specific inputs for the prediction model. Models are abstractions where the output is only as accurate as the input data behind it. This means models need training data with extracted features to improve their accuracy. Without feature engineering, the results of a model would be random guesses. </p>
<h2 id="uuid-72e93fc4-a6cb-43f9-95b6-4092753e8220">Creating a prediction output</h2>
<p>To see how <strong>features</strong> can be extracted from unstructured data, let's walk through the NLTK gender feature, which includes some minor modifications from the original example. You can find the original source in the <em>Further reading</em> section.</p>
<p>Launch a new Jupyter Notebook and name it <kbd>ch_11_exercises</kbd>. Now, follow these steps:</p>
<ol>
<li>Import the following libraries by adding the following command to your Jupyter Notebook and run the cell. Feel free to follow along by creating your own Notebook. I have placed a copy in this book's GitHub repository for reference:</li>
</ol>
<pre style="padding-left: 60px">In[]: import nltk</pre>
<p>The library should already be available using Anaconda. Refer to <a href="e0fe6eb2-8f38-41f7-9dea-2b177578fd3c.xhtml">Chapter 2</a>, <em>Overview of Python and Installing Jupyter Notebook</em>, for help with setting up your environment.</p>
<ol start="2">
<li>Next, we need to download the specific corpus we want to use. Alternatively, you can download all the packages using the <kbd>all</kbd> parameter. If you are behind a firewall, there is an <kbd>nltk.set_proxy</kbd> option available. Check the documentation at <a href="http://www.nltk.org/">nltk.org</a> for more details:</li>
</ol>
<pre style="padding-left: 60px">In[]: nltk.download("names")</pre>
<p style="padding-left: 60px">The output will look as follows, where the package download is confirmed and the output is verified as <kbd>True</kbd>:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/9da572a5-f9b3-4b94-b621-5581c7bf8427.png" style="width:37.50em;height:6.83em;"/></p>
<ol start="3">
<li>We can use the following command to reference the corpus:</li>
</ol>
<pre style="padding-left: 60px">In[]: from nltk.corpus import names</pre>
<ol start="4">
<li>To explore the data available in this corpus, let's run the <kbd>print</kbd> command against the two input sources, <kbd>male.txt</kbd> and <kbd>female.txt</kbd>:</li>
</ol>
<pre style="padding-left: 60px">In[]: print("Count of Words in male.txt:", len(names.words('male.txt')))<br/>print("Count of Words in female.txt:", len(names.words('female.txt')))</pre>
<p style="padding-left: 60px">The output will look as follows, where a count of the number of words found in each source file is printed in the Notebook:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/82feb653-4599-4e2e-b0ff-08fddf8a04f8.png" style="width:58.92em;height:9.17em;"/></p>
<p style="padding-left: 60px">We now have a better understanding of the size of the data due to counting the number of words found in each source file. Let's continue by looking at the contents within each source, taking a look at a few samples from each gender file.</p>
<ol start="5">
<li>To see a list of the first few words found in each source, let's run the <kbd>print</kbd> command against the two input sources, <kbd>male.txt</kbd> and <kbd>female.txt</kbd>:</li>
</ol>
<pre style="padding-left: 60px">In[]: print("Sample list Male names:", names.words('male.txt')[0:5])<br/>print("Sample list Female names:", names.words('female.txt')[0:5])</pre>
<p style="padding-left: 60px">The output will look as follows, where a list of words found in each source file is printed in the Notebook:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/52eeafdf-75a9-4646-8ed6-1205b9853fdf.png" style="width:41.83em;height:6.25em;"/></p>
<p>Remember that the computer has no idea if a name actually returns a value of <kbd>male</kbd> or <kbd>female</kbd>. The corpus has defined them as two different source files as a list of values that the NLTK library has identified as words because they have been defined as such. With thousands of names defined as either male or female, you can use this data as input for sentiment analysis. However, identifying gender alone will not determine whether the sentiment is positive or negative, so additional elements are required.</p>
<p>The next element, labeled D in the first diagram, is the actual <strong>NLP supervised ML</strong> algorithm. Remember, building an accurate model involves using feature engineering, along with NLTK libraries and classifier models. When used correctly, the output will be based on the input <strong>training</strong> and <strong>test</strong> data. Models should always be validated and the accuracy should be measured. For our example, which is building a basic gender determination model, we are going to use <kbd>NaiveBayesClassifier</kbd>, which is available in the NLKT libraries. The Naïve Bayes Classifier is an ML model created from Bayes theorem that is used to determine the probability of an event happening based on how often another similar event has occurred. A classifier is a process that chooses the correct tag value or label based on an inputted feature dataset. The mathematical concepts behind these models and libraries are vast, so I have added some links in the <em>Further reading</em> section for additional reference. To complete the elements of sentiment analysis summarized in the first diagram, we will create a prediction output, so let's continue in our Jupyter Notebook session:</p>
<ol>
<li>Create a <kbd>gender_features</kbd> function that returns the last letter of any input word. The model will use this classifier feature as input to predict the output, which, based on the concept that first names that end in the letters <strong>A</strong>, <strong>E</strong>, and <strong>I</strong> are more likely to be female, while first names ending in <strong>K</strong>, <strong>O</strong>, <strong>R</strong>, <strong>S</strong>, or <strong>T</strong> are more likely to be male. There will be no output after you run the cell:</li>
</ol>
<pre style="padding-left: 60px">In[]: def gender_features(word):       <br/>    return {'last_letter': word[-1]}</pre>
<p>Remember to indent the second line in your cell so that Python can process the function.</p>
<ol start="2">
<li>To confirm the function will return a value, enter the following command, which prints the last character of any inputted name or word:</li>
</ol>
<pre style="padding-left: 60px">In[]: gender_features('Debra')</pre>
<p style="padding-left: 60px">The output will look as follows, where the last character from the inputted word <kbd>Debra</kbd> is printed in the Notebook with <kbd>Out[]</kbd>:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/f4e4784f-f863-4a4c-907f-d8cbedd7dd21.png" style="width:17.25em;height:3.58em;"/></p>
<ol start="3">
<li>Create a new variable named <kbd>labeled_names</kbd> that loops through both source gender files and assigns a <strong>name-value pair</strong> so that it can be identified as either male or female to be input into the model. To see the results after the loop has completed, we print the first few values to verify that the <kbd>labeled_names</kbd> variable contains data:</li>
</ol>
<pre style="padding-left: 60px">In[]: labeled_names = ([(name, 'male') for name in names.words('male.txt')] + [(name, 'female') for name in names.words('female.txt')])<br/>print(labeled_names[0:5])</pre>
<p style="padding-left: 60px">The output will look as follows, where each name value from the source file will be combined with a tag of <kbd>male</kbd> or <kbd>female</kbd>, depending on which text file source it came from:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/2b2b946b-a7a4-483d-b66a-bc5ee82a7279.png" style="width:61.08em;height:7.67em;"/></p>
<ol start="4">
<li>Since the model should be trained using a random list of values to avoid any bias, we will input the random function and shuffle all the name and gender combinations, which will change the sequence of how they are stored in the <kbd>labeled_names</kbd> variable. I added a <kbd>print()</kbd> statement so that you can see the difference from the output created in the prior step:</li>
</ol>
<pre style="padding-left: 60px">In[]: import random<br/>random.shuffle(labeled_names)<br/>print(labeled_names[0:5])</pre>
<p style="padding-left: 60px">The output will look as follows, where each name value from the source file will be combined with a tag of <kbd>male</kbd> or <kbd>female</kbd>, depending on which text file source it came from:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/9600fe81-df59-43a7-a7dc-4a984d8f9352.png"/></p>
<p>Note because the <kbd>random()</kbd> function is used, the results of the <kbd>print()</kbd> function will always change each time you run the cell.</p>
<ol start="5">
<li>Next, we are going to train the model by creating features for each gender using the last letter from each name in the <kbd>labeled_names</kbd> variable. We will print the new variable called <kbd>featuresets</kbd> so that you can see how the feature will be used in the next step:</li>
</ol>
<pre style="padding-left: 60px">In[]: featuresets = [(gender_features(n), gender) for (n, gender) in labeled_names]<br/>print(featuresets[0:5])</pre>
<p style="padding-left: 60px">The output will look as follows, where each combination of the last letter from the names is assigned to a gender value, thereby creating a list of name-value pairs:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/f1fe1f7d-2d16-4ba0-8b35-aa25762dcfa6.png"/></p>
<p class="mce-root"/>
<p class="mce-root"/>
<ol start="6">
<li>Next, we are going to slice the data from the <kbd>featuresets</kbd> variable list into two input datasets called <kbd>train_set</kbd> and <kbd>test_set</kbd>. Once we have those datasets separated, we can use <kbd>train_set</kbd> as an input for the classifier. We use the <kbd>len()</kbd> function to give us a sense of the size of each dataset:</li>
</ol>
<pre style="padding-left: 60px">In[]: train_set, test_set = featuresets[500:], featuresets[:500]<br/>print("Count of features in Training Set:", len(train_set))<br/>print("Count of features in Test Set:", len(test_set))</pre>
<p style="padding-left: 60px">The output will look as follows, where the results of the <kbd>len()</kbd> function provide context as to how large each dataset is compared to the others:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/da01ffe1-b381-45c6-954a-e078559ef4dc.png" style="width:33.42em;height:7.00em;"/></p>
<ol start="7">
<li>We will now pass the <kbd>train_set</kbd> variable as input to the NLTK Naïve Bayes classifier. The model is assigned the name <kbd>classifier</kbd>, so you can call it like a function in the next step. There will be no output once you run the cell:</li>
</ol>
<pre style="padding-left: 60px">In[]: classifier = nltk.NaiveBayesClassifier.train(train_set)</pre>
<ol start="8">
<li>Now, we will validate the results of the model by sending random names into the model using the following commands:</li>
</ol>
<pre style="padding-left: 60px">In[]: classifier.classify(gender_features('Aaron'))<br/>classifier.classify(gender_features('Marc'))<br/>classifier.classify(gender_features('Debra'))<br/>classifier.classify(gender_features('Deb'))<br/>classifier.classify(gender_features('Seth'))</pre>
<p style="padding-left: 60px">The output will look as follows, where the gender values of either <kbd>male</kbd> or <kbd>female</kbd> will be displayed after each name is passed as a parameter in the <kbd>classifier</kbd> model:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/6af5b410-9cd6-4b42-be43-a175cebe5b51.png" style="width:34.00em;height:26.33em;"/></p>
<p>Congratulations – you have successfully created your first supervised ML model! As you can see, the classifier model has some accuracy issues and returns incorrect values in some cases. For example, when you pass in the values of <kbd>Aaron</kbd>, <kbd>Marc</kbd>, or <kbd>Debra</kbd>, the gender results are predicted correctly. The name <kbd>Aaron</kbd> was found in the training data, so that was no surprise. However, the model shows signs of being incomplete or requiring additional features because it returns the incorrect gender when using the nickname of <kbd>Deb</kbd> for <kbd>Debra</kbd> and for the name <kbd>Seth</kbd>, who is male.</p>
<p>How do we solve this problem? There are a few approaches that can be used, all of which we will explore next.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<h1 id="uuid-24fe1c3e-4aac-4d2d-98d4-4256747db7f3">Sentiment analysis packages</h1>
<p>The NLTK libraries include a few packages to help solve the issues we experienced in the gender classifier model. The first is the <kbd>SentimentAnalyzer</kbd> module, which allows you to include additional features using built-in functions. What's special about these packages is that they go beyond traditional functions where defined parameters are passed in. In Python, arguments (<kbd>args</kbd>) and keyword arguments (<kbd>kwargs</kbd>) allow us to pass name-value pairs and multiple argument values into a function. These are represented with asterisks; for example, <kbd>*args</kbd> or <kbd>**kwargs</kbd>. The NLTK <kbd>SentimentAnalyzer</kbd> module is a useful utility for teaching purposes, so let's continue by walking through the features that are available within it.</p>
<p>The second is called <strong>VADER</strong>, which stands for <strong>Valence Aware Dictionary and Sentiment Reasoner</strong>. It was built to handle social media data. The VADER sentiment library has a dictionary known as a <strong>lexicon</strong> and includes a rule-based algorithm specifically built to process acronyms, emoticons, and slang. A nice feature available from VADER is that it already includes training data and we can use a built-in function called <kbd>polarity_scores()</kbd> that returns key insights in the output that's displayed. The first is a compound score that is between negative one and positive one. This provides you with a normalized sum of VADER's lexicon ratings in a single score. For example, if the output returns <kbd>0.703</kbd>, this would be an extremely positive sentence, while a compound score of <kbd>-0.5719</kbd> would be interpreted as negative. The next output from the VADER tool is a distribution score in terms of how positive, negative, or neutral the input is from zero to one.</p>
<p>For example, the sentence <kbd>I HATE my school!</kbd> would return the results shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/f61dda82-d3c8-4142-b5f2-e6d096eda89c.png" style="width:37.50em;height:6.17em;"/></p>
<p class="mce-root"/>
<p>As you can see, a compound value of <kbd>-0.6932</kbd> is returned, which validates the VADER model is accurately predicting the sentiment as very negative. On the same output line, you can see <kbd>'neg'</kbd>, <kbd>'neu'</kbd>, and <kbd>'pos'</kbd>, which are short for negative, neutral, and positive, respectively. Each metric next to the values provides a little more detail about how the compound score was derived. In the preceding screenshot, we can see a value of <kbd>0.703</kbd>, which means that the model prediction is 70.3% negative, with the remaining 29.7% being neutral. The model returned a value of <kbd>0.0</kbd> next to <kbd>pos</kbd>, so there is a <kbd>0%</kbd> positive sentiment based on the built-in VADER training dataset.</p>
<p>Note that the VADER sentiment analysis scoring methodology has been trained to handle social media data and informal proper grammar. For example, if a tweet includes multiple exclamation points for emphasis, the compound score will increase. Capitalization, the use of conjunctions, and the use of swear words will all be accounted for in the output from the model. So, the main benefit of using VADER is that it already includes those extra steps required to feature and train the model, but you lose the ability to customize it with additional features.</p>
<p>Now that we have a better understanding of the VADER tool, let's walk through an example of using it.</p>
<h1 id="uuid-1b5712c8-b101-4f68-b6be-abae6c157c82">Sentiment analysis in action</h1>
<p>Let's continue with our Jupyter Notebook session and walk through how to install and use the VADER sentiment analysis library. First, we will walk through an example of using manual input and then learn how to load data from a file.</p>
<h2 id="uuid-61fbe4bb-ba68-4d07-a24f-d6eacd585ee1">Manual input</h2>
<p>Follow these steps to learn how to use manual input in VADER:</p>
<ol>
<li>Import the NLTK library and download the <kbd>vader_lexicon</kbd> library so that all the necessary functions and features will be available:</li>
</ol>
<pre style="padding-left: 60px">In[]: import nltk<br/>nltk.download('vader_lexicon')</pre>
<p style="padding-left: 60px">The output will look as follows, where the package download will be confirmed and the output is verified as <kbd>True</kbd>:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/ce376473-cec8-4d0b-b699-311c081e7aa0.png" style="width:36.75em;height:12.00em;"/></p>
<ol start="2">
<li>Import <kbd>SentimentIntensityAnalyzer</kbd> from the NLTK Vader library. There will be no output when you run the cell:</li>
</ol>
<pre style="padding-left: 60px">In[]:from nltk.sentiment.vader import SentimentIntensityAnalyzer</pre>
<ol start="3">
<li>To make it easier, we will assign a variable object called <kbd>my_ analyzer</kbd> and assign it to the <kbd>SentimentIntensityAnalyzer()</kbd> model. There will be no output after you run the cell:</li>
</ol>
<pre style="padding-left: 60px">In[]:my_analyzer = SentimentIntensityAnalyzer()</pre>
<ol start="4">
<li>Next, we will create a variable named <kbd>my_input_sentence</kbd> and assign it a string value of <kbd>I HATE my school!</kbd>. On the second line, we will call the model and pass the variable as an argument to the <kbd>polarity_scores()</kbd> function:</li>
</ol>
<pre style="padding-left: 60px">In[]:my_input_sentence = "I HATE my school!"<br/>my_analyzer.polarity_scores(my_input_sentence)</pre>
<p style="padding-left: 60px">The output will look as follows, where we can see the result of the VADER sentiment analysis model:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/15c382c5-8032-48d1-b0f5-90170521b9a3.png" style="width:38.67em;height:6.33em;"/></p>
<p>Excellent—you have now utilized the VADER sentiment analysis model and returned results to determine whether a sentence is positive or negative. Now that we understand how the model works with individual input sentences, let's demonstrate how to work with a sample social media file and combine it with what we have learned using the <kbd>pandas</kbd> and <kbd>matplotlib</kbd> libraries. </p>
<p class="mce-root"/>
<p>In the next exercise, we are going to work with a text file source that you will need to import into your Jupyter Notebook. This is a small sample CSV file containing example social media type free text, including a hashtag, informal grammar, and extra punctuation.</p>
<p>It has 2 columns and 10 rows of content, with a header row for easy reference, as shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/f74ab551-8bad-452a-b028-648fee1e3293.png" style="width:45.75em;height:13.17em;"/></p>
<h2 id="uuid-462d33dc-f6f9-4c65-8abb-b94d3c99c6fe">Social media file input</h2>
<p>Let's continue working with our Jupyter Notebook session and walk through how to work with this source file so that it includes a VADER sentiment and then analyze the results:</p>
<ol>
<li>We are going to import some additional libraries so that we can work with and analyze the results, as follows:</li>
</ol>
<pre style="padding-left: 60px">In[]:import pandas as pd<br/>import numpy as np<br/>%matplotlib inline</pre>
<ol start="2">
<li>We also have to install a new library named <kbd>twython</kbd>. Use the following command to install it in your Notebook session. The <kbd>twython</kbd> library includes features to make it easier to read social media data:</li>
</ol>
<pre style="padding-left: 60px">In[]:!pip install twython</pre>
<p style="padding-left: 60px">The output will look as follows, where the resulting installation will be displayed. If you need to upgrade <kbd>pip</kbd>, you may need to run additional commands:</p>
<p class="mce-root"/>
<p class="CDPAlignCenter CDPAlign"><img src="img/f344ef7a-acd1-458c-b462-413a7dc5e532.png"/></p>
<ol start="3">
<li>If required, re-import the NLTK library and import the <kbd>SentimentIntensityAnalyzer</kbd> module. No output will be displayed after you run the cell:</li>
</ol>
<pre style="padding-left: 60px">In[]:import nltk<br/>from nltk.sentiment.vader import SentimentIntensityAnalyzer</pre>
<ol start="4">
<li>Define a variable as <kbd>analyzer</kbd> to make it easier to reference later in the code. No output will be displayed after you run the cell:</li>
</ol>
<pre style="padding-left: 60px">In[]:analyzer = SentimentIntensityAnalyzer()</pre>
<ol start="5">
<li>If required, redownload the NLTK <kbd>vader_lexicon</kbd>:</li>
</ol>
<pre style="padding-left: 60px">In[]:nltk.download('vader_lexicon')</pre>
<p style="padding-left: 60px">The output will look as follows, where the download result will be displayed:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/7fdb4ce1-5635-46ce-b0d1-6ce5e7f0ba6f.png" style="width:38.08em;height:9.08em;"/></p>
<ol start="6">
<li>Now, we will read in the <kbd>.csv</kbd> file using the <kbd>pandas</kbd> library and assign the result to a variable named <kbd>sentences</kbd>. To validate the results, you can run the <kbd>len()</kbd> function:</li>
</ol>
<pre style="padding-left: 60px">In[]:sentences = pd.read_csv('social_media_sample_file.csv')<br/>len(sentences)</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p>Be sure to upload the source CSV file in the correct file location so that you can reference it in your Jupyter Notebook.</p>
<p style="padding-left: 60px">The output will look as follows, where the value of <kbd>10</kbd> will be displayed. This matches the number of records in the source CSV file:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/c2354dda-409f-4918-931f-98122dd0d13a.png" style="width:35.92em;height:5.42em;"/></p>
<ol start="7">
<li>To preview the data and verify that your DataFrame is loaded correctly, you can run the <kbd>head()</kbd> command:</li>
</ol>
<pre style="padding-left: 60px">In[]:sentences.head()</pre>
<p style="padding-left: 60px">The output will look as follows, where the results of the <kbd>head()</kbd> function are displayed to verify that the source file is now a DataFrame:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/69ed741e-9d6d-4e4d-af6c-619ec7d5beea.png" style="width:29.00em;height:14.25em;"/></p>
<ol start="8">
<li>The following block of code includes a few steps that look through the DataFrame, analyze the text source, apply the VADER sentiment metrics, and assign the results to a <kbd>numpy</kbd> array for easier usage. No output will be displayed after you run the cell:</li>
</ol>
<pre style="padding-left: 60px">In[]:i=0 #reset counter for loop<br/><br/>#initialize variables<br/>my_vader_score_compound = [ ] <br/>my_vader_score_positive = [ ] <br/>my_vader_score_negative = [ ] <br/>my_vader_score_neutral = [ ] <br/><br/>while (i&lt;len(sentences)):<br/><br/>    my_analyzer = analyzer.polarity_scores(sentences.iloc[i]['text'])<br/>    my_vader_score_compound.append(my_analyzer['compound'])<br/>    my_vader_score_positive.append(my_analyzer['pos'])<br/>    my_vader_score_negative.append(my_analyzer['neg']) <br/>    my_vader_score_neutral.append(my_analyzer['neu']) <br/>    <br/>    i = i+1<br/>    <br/>#converting sentiment values to numpy for easier usage<br/>my_vader_score_compound = np.array(my_vader_score_compound)<br/>my_vader_score_positive = np.array(my_vader_score_positive)<br/>my_vader_score_negative = np.array(my_vader_score_negative)<br/>my_vader_score_neutral = np.array(my_vader_score_neutral)</pre>
<p>Be sure to double-check your indentations when entering multiple commands in the Jupyter Notebook input cell.</p>
<ol start="9">
<li>Now, we can extend the source DataFrame so that it includes the results from the VADER sentiment model. This will create four new columns. No output will be displayed after you run the cell:</li>
</ol>
<pre style="padding-left: 60px">In[]:sentences['my VADER Score'] = my_vader_score_compound<br/>sentences['my VADER score - positive'] = my_vader_score_positive<br/>sentences['my VADER score - negative'] = my_vader_score_negative<br/>sentences['my VADER score - neutral'] = my_vader_score_neutral</pre>
<ol start="10">
<li>To see the changes, run the <kbd>head()</kbd> function again:</li>
</ol>
<pre style="padding-left: 60px">In[]:sentences.head(10)</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p style="padding-left: 60px">The output will look as follows, where the results of the <kbd>head()</kbd> function are displayed to verify that the DataFrame now includes the new columns that were created from the loop in the previous step:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/c60b59c6-3d09-4bde-bed8-5772519b0f1c.png"/></p>
<ol start="11">
<li>While this information is useful, it still requires the user to scan through the results row by row. Let's make it easier to analyze and summarize the results by creating a new column that categorizes the compound score results. No output will be displayed after you run the cell:</li>
</ol>
<pre style="padding-left: 60px">In[]:i=0 #reset counter for loop<br/><br/>#initialize variables<br/>my_prediction = [ ] <br/><br/>while (i&lt;len(sentences)):<br/>    if ((sentences.iloc[i]['my VADER Score'] &gt;= 0.3)):<br/>        my_prediction.append('positive')<br/>    elif ((sentences.iloc[i]['my VADER Score'] &gt;= 0) &amp; (sentences.iloc[i]['my VADER Score'] &lt; 0.3)):<br/>        my_prediction.append('neutral')<br/>    elif ((sentences.iloc[i]['my VADER Score'] &lt; 0)):<br/>        my_prediction.append('negative') <br/>    <br/>    i = i+1</pre>
<ol start="12">
<li>Similar to before, we will take the results and add a new column to our DataFrame called <kbd>my prediction sentiment</kbd>. No output will be displayed after you run the cell:</li>
</ol>
<pre style="padding-left: 60px">In[]:sentences['my predicted sentiment'] = my_prediction</pre>
<ol start="13">
<li>To see the changes, run the <kbd>head()</kbd> function again:</li>
</ol>
<pre style="padding-left: 60px">In[]:sentences.head(10)</pre>
<p style="padding-left: 60px">The output will look as follows, where the results of the <kbd>head()</kbd> function are displayed to verify that the DataFrame now includes the new column that was created from the loop in the previous step:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/5b8e0078-f6f3-4dd9-89d7-d7bd8ffdfd7b.png"/></p>
<ol start="14">
<li>To make it easier to interpret the results, let's create a data visualization against the DataFrame by summarizing the results using an aggregate <kbd>groupby</kbd>. We'll use the <kbd>plot()</kbd> function from the <kbd>matplotlib</kbd> library to display a horizontal bar chart:</li>
</ol>
<pre style="padding-left: 60px">In[]:sentences.groupby('my predicted sentiment').size().plot(kind='barh');</pre>
<p style="padding-left: 60px">The output will look as follows, where a horizontal bar chart will be displayed showing a summary of the count of the text by sentiment in terms of positive, negative, and neutral:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/dd8ba209-d076-46b9-902f-58fc141d195c.png" style="width:37.50em;height:18.17em;"/></p>
<p>As you can see, we have more positive opinions in our data source. It was much faster to interpret the results like this because we visualized the results to make it easier to consume them visually. We now have a reusable workflow to analyze much larger volumes of unstructured data by looking at a source data file and applying the VADER sentiment analysis model to each record. If you replace the sample CSV file with any social media source, you can rerun the same steps and see how the analysis changes.</p>
<p>The accuracy score for VADER models is around 96%, which has been proven to be more accurate than a human interpretation according to research on the subject.</p>
<p>There is some bias in the analysis since the bins of <strong>positive</strong>, <strong>negative</strong>, and <strong>neutral</strong> can be adjusted in the code. As a good data analyst, understanding the bias can help you either adjust it for your specific needs or be able to communicate the challenges of working with free text data.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<h1 id="uuid-0f2e82a0-0082-494a-b68a-05db356bdec5">Summary</h1>
<p>Congratulations—you have successfully walked through the foundations of NLP and should have a high-level understanding of supervised ML using the NLTK libraries! Sentiment analysis is a fascinating and evolving science that has many different moving parts. I hope this introduction is a good start to your continued research so that you can utilize it in your data analysis. In this chapter, we learned about the various elements of sentiment analysis, such as feature engineering, along with the process of how an NLP ML algorithm works. We also learned how to install NLP libraries in Jupyter to work with unstructured data, along with how to analyze the results created by a classifier model. With this knowledge, we walked through an example of how to use the VADER sentiment analysis model and visualized the results for analysis. </p>
<p>In our last chapter, <a href="4a24a1e7-aff4-4812-ad21-20e5b8737bd9.xhtml">Chapter 12</a>, <em>Bringing it all Together</em>, we will bring together all the concepts we've covered in this book and walk through some real-world examples.</p>
<h1 id="uuid-146d21cf-f052-4ded-8422-a7f3d33fb5fe">Further reading</h1>
<ul>
<li>NLTK sentiment analysis example: <a href="https://www.nltk.org/howto/sentiment.html">https://www.nltk.org/howto/sentiment.html</a></li>
<li>The source code for VADER and its documentation: <a href="https://github.com/cjhutto/vaderSentiment">https://github.com/cjhutto/vaderSentiment</a></li>
<li>Bayes theorem explained: <a href="https://plato.stanford.edu/entries/bayes-theorem/">https://plato.stanford.edu/entries/bayes-theorem/</a></li>
<li>VADER sentiment analysis research: <a href="http://comp.social.gatech.edu/papers/icwsm14.vader.hutto.pdf">http://comp.social.gatech.edu/papers/icwsm14.vader.hutto.pdf</a></li>
</ul>


            

            
        
    </body></html>