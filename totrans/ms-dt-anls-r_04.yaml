- en: Chapter 4. Restructuring Data
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第4章。重新结构化数据
- en: We already covered the most basic methods for restructuring data in the [Chapter
    3](ch03.html "Chapter 3. Filtering and Summarizing Data"), *Filtering and Summarizing
    Data*, but of course, there are several other, more complex tasks that we will
    master in the forthcoming pages.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经在[第3章](ch03.html "第3章。过滤和汇总数据")中介绍了重新结构化数据的最基本方法，*过滤和汇总数据*，但当然，还有几个其他更复杂的任务，我们将在接下来的几页中掌握。
- en: 'Just to give a quick example on how diversified tools are needed for getting
    the data in a form that can be used for real data analysis: Hadley Wickham, one
    of the best known R developers and users, spent one third of his PhD thesis on
    reshaping data. As he says, "it is unavoidable before doing any exploratory data
    analysis or visualization."'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 只为了快速举例说明，为了得到可以用于实际数据分析的数据形式，需要多样化的工具：Hadley Wickham，最知名的R开发者和用户之一，将他的博士论文三分之一的时间花在重塑数据上。正如他所说，“在进行任何探索性数据分析或可视化之前是不可避免的。”
- en: 'So now, besides the previous examples of restructuring data, such as the counting
    of elements in each group, we will focus on some more advanced features, as listed
    next:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，现在，除了之前提到的重新结构化数据的例子，比如每个组中元素的计数，我们还将关注一些更高级的功能，如下所示：
- en: Transposing matrices
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 矩阵转置
- en: Splitting, applying, and joining data
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据的拆分、应用和连接
- en: Computing margins of tables
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算表格的边缘
- en: Merging data frames
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据框的合并
- en: Casting and melting data
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据的铸造和熔化
- en: Transposing matrices
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 矩阵转置
- en: 'One of the most used, but often not mentioned, methods for restructuring data
    is transposing matrices. This simply means switching the columns with rows and
    vice versa, via the `t` function:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 重新结构化数据最常用但常常不为人提及的方法之一是矩阵转置。这简单意味着通过`t`函数交换列和行，反之亦然：
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Of course, this `S3` method also works with `data.frame`, and actually, with
    any tabular object. For more advanced features, such as transposing a multi-dimensional
    table, take a look at the `aperm` function from the `base` package.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这个`S3`方法也适用于`data.frame`，实际上，适用于任何表格对象。对于更高级的功能，例如转置多维表格，请查看`base`包中的`aperm`函数。
- en: Filtering data by string matching
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过字符串匹配过滤数据
- en: Although some filtering algorithms were already discussed in the previous chapters,
    the `dplyr` package contains some magic features that have not yet been covered
    and are worth mentioning here. As we all know by this time, the `subset` function
    in `base`, or the `filter` function from `dplyr` is used for filtering rows, and
    the `select` function can be used to choose a subset of columns.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然一些过滤算法已经在之前的章节中讨论过，但`dplyr`包包含一些尚未介绍且值得在此提及的神奇功能。正如我们到这个时候所知道的，`base`中的`subset`函数或`dplyr`中的`filter`函数用于过滤行，而`select`函数可以用来选择列的子集。
- en: The function filtering rows usually takes an R expression, which returns the
    IDs of the rows to drop, similar to the `which` function. On the other hand, providing
    such R expressions to describe column names is often more problematic for the
    `select` function; it's harder if not impossible to evaluate R expressions on
    column names.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 过滤行的函数通常需要一个R表达式，该表达式返回要删除的行的ID，类似于`which`函数。另一方面，为`select`函数提供这样的R表达式来描述列名通常更成问题；在列名上评估R表达式更困难，甚至不可能。
- en: 'The `dplyr` package provides some useful functions to select some columns of
    the data, based on column name patterns. For example, we can keep only the variables
    ending with the string, `delay`:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '`dplyr`包提供了一些有用的函数，可以根据列名模式选择数据的一些列。例如，我们可以只保留以字符串`delay`结尾的变量：'
- en: '[PRE1]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Of course, there is a similar helper function to check the first characters
    of the column names with `starts_with`, and both functions can ignore (by default)
    or take into account the upper or lower case of the characters with the `ignore.case`
    parameter. And we have the more general, `contains` function, looking for substrings
    in the column names:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，还有一个类似的辅助函数`starts_with`来检查列名的前几个字符，并且这两个函数都可以通过`ignore.case`参数忽略（默认）或考虑字符的大小写。我们还有更通用的`contains`函数，它在列名中查找子字符串：
- en: '[PRE2]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The other option is that we might need a more complex approach with regular
    expressions, which is another extremely important skill for data scientists. Now,
    we will provide a regular expression to the `matches` function, which is to be
    fitted against all the columns names. Let''s select all the columns with a name
    comprising of 5 or 6 characters:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种选择是，我们可能需要一个更复杂的正则表达式方法，这对于数据科学家来说是一项极其重要的技能。现在，我们将正则表达式提供给`matches`函数，该函数将与所有列名进行匹配。让我们选择所有名称包含5个或6个字符的列：
- en: '[PRE3]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We can keep all column names that do not match a regular expression by using
    a negative sign before the expression. For example, let''s identify the most frequent
    number of characters in the columns'' names:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过在表达式前使用负号来保留所有不匹配正则表达式的列名。例如，让我们确定列名中最常见的字符数：
- en: '[PRE4]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'And then, let''s remove all the columns with 7 or 8 characters from the dataset.
    Now, we will show the column names from the filtered dataset:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，让我们从数据集中删除所有具有7个或8个字符的列。现在，我们将显示过滤后的数据集的列名：
- en: '[PRE5]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Rearranging data
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据重排
- en: Sometimes, we do not want to filter any part of the data (neither the rows,
    nor the columns), but the data is simply not in the most useful order due to convenience
    or performance issues, as we have seen, for instance, in [Chapter 3](ch03.html
    "Chapter 3. Filtering and Summarizing Data"), *Filtering and Summarizing Data*.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，我们不想过滤数据的任何部分（既不是行，也不是列），但由于便利性或性能问题，数据简单地不是最有用的顺序，正如我们在[第3章](ch03.html
    "第3章。过滤和汇总数据")中看到的，*过滤和汇总数据*。
- en: 'Besides the base `sort` and `order` functions, or providing the order of variables
    passed to the `[` operator, we can also use some SQL-like solutions with the `sqldf`
    package, or query the data in the right format directly from the database. And
    the previously mentioned `dplyr` package also provides an effective method for
    ordering data. Let''s sort the `hflights` data, based on the actual elapsed time
    for each of the quarter million flights:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 除了基本的`sort`和`order`函数，或者提供传递给`[`操作符的变量的顺序之外，我们还可以使用`sqldf`包中的类似SQL的解决方案，或者直接从数据库中以正确的格式查询数据。之前提到的`dplyr`包还提供了一种有效的方法来排序数据。让我们根据每百万次航班的实际耗时对`hflights`数据进行排序：
- en: '[PRE6]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Well, it''s pretty straightforward that flights departing to Austin are among
    the first few records shown. For improved readability, the above three R expressions
    can be called in a much nicer way with the pipe operator from the automatically
    imported `magrittr` package, which provides a simple way to pass an R object as
    the first argument of the subsequent R expression:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，很明显，飞往奥斯汀的航班记录是显示的前几条记录之一。为了提高可读性，上述三个R表达式可以通过自动导入的`magrittr`包中的管道操作符以更优雅的方式调用，该包提供了一种简单的方法将R对象作为后续R表达式的第一个参数传递：
- en: '[PRE7]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'So, instead of nesting R functions, we can now start our R command with the
    core object and pass the results of each evaluated R expression to the next one
    in the chain. In most cases, this makes the code more convenient to read. Although
    most hardcore R programmers have already gotten used to reading the nested function
    calls from inside-out, believe me, it''s pretty easy to get used to this nifty
    feature! Do not let me confuse you with the inspiring painting of René Magritte,
    which became the slogan, "This is not a pipe," and a symbol of the `magrittr`
    package:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们不再需要嵌套R函数，现在我们可以从核心对象开始我们的R命令，并将每个评估的R表达式的结果传递给链中的下一个。在大多数情况下，这使得代码更易于阅读。尽管大多数核心R程序员已经习惯了从内到外阅读嵌套函数调用，但请相信我，适应这个巧妙的功能非常容易！不要让我用雷内·马格利特的启发式画作混淆你，这幅画成为了一句口号，“这不是一个烟斗”，也是`magrittr`包的象征：
- en: '![Rearranging data](img/2028OS_06_01.jpg)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![数据重排](img/2028OS_06_01.jpg)'
- en: 'There is no limit to the number of chainable R expressions and objects one
    can have. For example, let''s also filter a few cases and variables to see how
    easy it is to follow the data restructuring steps with `dplyr`:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 一个R表达式和对象可以链式调用的数量没有限制。例如，让我们也过滤一些案例和变量，看看使用`dplyr`跟随数据重构步骤有多容易：
- en: '[PRE8]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'So, now we have filtered the original dataset a few times to see the closest
    airport after Austin, and the code is indeed easy to read and understand. This
    is a nice and efficient way to filter data, although some prefer to use nifty
    one-liners with the `data.table` package:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，现在我们已经对原始数据集进行了几次过滤，以查看奥斯汀之后的最近机场，代码确实易于阅读和理解。这是一种很好的高效过滤数据的方法，尽管有些人更喜欢使用`data.table`包的巧妙单行代码：
- en: '[PRE9]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Almost perfect! The only problem is that we got different results due to the
    missing values, which were ordered at the beginning of the dataset while we defined
    the `data.table` object to be indexed by `ActualElapsedTime`. To overcome this
    issue, let''s drop the `NA` values, and instead of specifying the column names
    as strings along with forcing the `with` parameter to be `FALSE`, let''s pass
    a list of column names:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 几乎完美！唯一的问题是，由于缺失值，我们得到了不同的结果，这些缺失值在数据集的开头被排序，而我们在定义 `data.table` 对象时将其索引设置为
    `ActualElapsedTime`。为了克服这个问题，让我们删除 `NA` 值，并且不是将列名作为字符串指定，同时强制 `with` 参数为 `FALSE`，而是传递一个列名列表：
- en: '[PRE10]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'This is exactly the same results as we have seen before. Please note that in
    this example, we have omitted the `NA` values after transforming `data.frame`
    to `data.table`, indexed by the `ActualElapsedTime` variable, which is a lot faster
    compared to calling `na.omit` on `hflights` first and then evaluating all the
    other R expressions:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这正是我们之前看到的结果。请注意，在这个例子中，我们在将 `data.frame` 转换为 `data.table` 后，省略了 `NA` 值，这些值是根据
    `ActualElapsedTime` 变量索引的，与首先在 `hflights` 上调用 `na.omit` 然后评估所有其他 R 表达式相比要快得多：
- en: '[PRE11]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: dplyr versus data.table
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: dplyr 与 data.table 的比较
- en: You might now be wondering, "which package should we use?"
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在可能想知道，“我们应该使用哪个包？”
- en: The `dplyr` and `data.table` packages provide a spectacularly different syntax
    and a slightly less determinative difference in performance. Although `data.table`
    seems to be slightly more effective on larger datasets, there is no clear winner
    in this spectrum—except for doing aggregations on a high number of groups. And
    to be honest, the syntax of `dplyr`, provided by the `magrittr` package, can be
    also used by the `data.table` objects if needed.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '`dplyr` 和 `data.table` 包提供了截然不同的语法，以及略微不那么确定的性能差异。尽管 `data.table` 在处理大型数据集时似乎略有效率，但在这一范围内并没有明显的胜者——除非是在对大量组进行聚合操作时。坦白说，`dplyr`
    的语法，由 `magrittr` 包提供，也可以用于 `data.table` 对象，如果需要的话。'
- en: Also, there is another R package that provides pipes in R, called the `pipeR`
    package, which claims to be a lot more effective on larger datasets than `magrittr`.
    This performance gain is due to the fact that the `pipeR` operators do not try
    to be smart like the F# language's `|>`-compatible operator in `magrittr`. Sometimes,
    this performance overhead is estimated to be 5-15 times more than the ones where
    no pipes are used at all.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还有一个名为 `pipeR` 的 R 包，它提供了 R 中的管道功能，声称在处理大型数据集时比 `magrittr` 更有效率。这种性能提升归因于
    `pipeR` 操作符不像 `magrittr` 中的 F# 语言兼容的 `|>` 操作符那样试图变得聪明。有时，这种性能开销估计是没有使用管道时的 5-15
    倍。
- en: One should take into account the community and support behind an R package before
    spending a reasonable amount of time learning about its usage. In a nutshell,
    the `data.table` package is now mature enough, without doubt, for production usage,
    as the development was started around 6 years ago by Matt Dowle, who was working
    for a large hedge fund at that time. The development has been continuous since
    then. Matt and Arun (co-developer of the package) release new features and performance
    tweaks from time to time, and they both seem to be keen on providing support on
    the public R forums and channels, such as mailing lists and StackOverflow.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在花费合理的时间学习其用法之前，应该考虑到 R 包背后的社区和支持。简而言之，`data.table` 包现在无疑已经足够成熟，可以用于生产环境，因为它的开发始于大约
    6 年前，当时 Matt Dowle（当时在一家大型对冲基金工作）开始了开发。从那时起，开发一直在持续进行。Matt 和 Arun（包的共同开发者）不时发布新功能和性能调整，并且他们似乎都热衷于在公共
    R 论坛和渠道，如邮件列表和 StackOverflow 上提供支持。
- en: On the other hand, `dplyr` is shipped by Hadley Wickham and RStudio, one of
    the most well-known persons and trending companies in the R community, which translates
    to an even larger user-base, community, and kind-of-instant support on StackOverflow
    and GitHub.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，`dplyr` 由 Hadley Wickham 和 RStudio 提供，他们是 R 社区中最知名的人物和趋势公司之一，这意味着拥有更大的用户群、社区，以及在
    StackOverflow 和 GitHub 上的即时支持。
- en: In short, I suggest using the packages that fit your needs best, after dedicating
    some time to discover the power and features they make available. If you are coming
    from an SQL background, you'll probably find `data.table` a lot more convenient,
    while others rather opt for the Hadleyverse (take a look at the R package with
    this name; it installs a bunch of useful R packages developed by Hadley). You
    should not mix the two approaches in a single project, as both for readability
    and performance issues, it's better to stick to only one syntax at a time.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，我建议在花时间发现它们提供的功能和力量之后，使用最适合您需求的包。如果您来自 SQL 背景，您可能会发现 `data.table` 非常方便，而其他人则更倾向于选择
    Hadleyverse（查看具有此名称的 R 包；它安装了一组由 Hadley 开发的有用 R 包）。您不应该在单个项目中混合这两种方法，因为从可读性和性能的角度来看，最好一次只坚持一种语法。
- en: To get a deeper understanding of the pros and cons of the different approaches,
    I will continue to provide multiple implementations of the same problem in the
    following few pages as well.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更深入地了解不同方法的优缺点，我将在接下来的几页中继续提供相同问题的多个实现。
- en: Computing new variables
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计算新变量
- en: One of the most trivial actions we usually perform while restructuring a dataset
    is to create a new variable. For a traditional `data.frame`, it's as simple as
    assigning a `vector` to a new variable of the R object.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在重构数据集时，我们通常执行的最简单操作之一就是创建一个新变量。对于一个传统的 `data.frame`，这就像是将一个 `vector` 分配给 R
    对象的新变量一样简单。
- en: 'Well, this method also works with `data.table`, but the usage is deprecated
    due to the fact that there is a much more efficient way of creating one, or even
    multiple columns in the dataset:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 嗯，这种方法也适用于 `data.table`，但由于有更高效的方法来创建一个或多个数据集中的列，因此该用法已被弃用：
- en: '[PRE12]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: We have just computed the distances, in kilometers, between the origin and destination
    airports with a simple division; although all the hardcore users can head for
    the `udunits2` package, which includes a bunch of conversion tools based on Unidata's
    `udunits` library.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚通过简单的除法计算了起点和目的地机场之间的距离，单位为公里；尽管所有核心用户都可以转向 `udunits2` 包，该包包含基于 Unidata
    的 `udunits` 库的一组转换工具。
- en: And as can be seen previously, data.table uses that special := assignment operator
    inside of the square brackets, which might seem strange at first glance, but you
    will love it!
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，data.table 在方括号内使用特殊的 := 赋值运算符，这乍一看可能有些奇怪，但你会爱上它的！
- en: Note
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The `:=` operator can be more than 500 times faster than the traditional `<-`
    assignment, which is based on the official `data.table` documentation. This speedup
    is due to not copying the whole dataset into the memory like R used to do before
    the 3.1 version. Since then, R has used shallow copies, which greatly improved
    the performance of column updates, but is still beaten by `data.table` powerful
    in-place updates.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '`:=` 运算符的速度可以比传统的 `<-` 赋值快500多倍，这是根据官方的 `data.table` 文档。这种加速是由于不像 R 在 3.1 版本之前那样将整个数据集复制到内存中。从那时起，R
    使用浅拷贝，这极大地提高了列更新的性能，但仍然被 `data.table` 强大的就地更新所击败。'
- en: 'Compare the speed of how the preceding computation was run with the traditional
    `<-` operator and `data.table`:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 比较以下计算使用传统 `<-` 运算符和 `data.table` 的速度：
- en: '[PRE13]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This is impressive, right? But it's worth double checking what we've just done.
    The first traditional call, of course, create/updates the `DistanceKMs` variable,
    but what happens in the second call? The `data.table` syntax did not return anything
    (visibly), but in the background, the `hflights_dt` R object was updated in-place
    due to the `:=` operator.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这很令人印象深刻，对吧？但值得我们仔细检查我们刚刚做了什么。当然，第一个传统调用创建了/更新了 `DistanceKMs` 变量，但在第二个调用中发生了什么？`data.table`
    语法没有返回任何内容（明显地），但由于 `:=` 运算符，后台的 `hflights_dt` R 对象被就地更新了。
- en: Note
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Please note that the `:=` operator can produce unexpected results when used
    inside of `knitr`, such as returning the `data.table` visible after the creation
    of a new variable, or strange rendering of the command when the return is `echo
    = TRUE`. As a workaround, Matt Dowle suggests increasing the `depthtrigger` option
    of `data.table`, or one can simply reassign the `data.table` object with the same
    name. Another solution might be to use my `pander` package over `knitr`. :)
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`:=` 运算符在 `knitr` 内部使用时可能会产生意外的结果，例如在创建新变量后返回可见的 `data.table`，或者当 `echo
    = TRUE` 时命令的渲染很奇怪。作为解决方案，Matt Dowle 建议增加 `data.table` 的 `depthtrigger` 选项，或者可以简单地用相同名称重新分配
    `data.table` 对象。另一个解决方案可能是使用我的 `pander` 包而不是 `knitr`。 :)
- en: But once again, how was it so fast?
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 但再次强调，它为什么会这么快？
- en: Memory profiling
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 内存分析
- en: The magic of the `data.table` package—besides having more than 50 percent of
    C code in the sources—is copying objects in memory only if it's truly necessary.
    This means that R often copies objects in memory while updating those, and `data.table`
    tries to keep these resource-hungry actions at a minimal level. Let's verify this
    by analyzing the previous example with the help of the `pryr` package, which provides
    convenient access to some helper functions for memory profiling and understanding
    R-internals.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '`data.table` 包的魔法——除了源代码中超过50%是C代码之外——就是仅在真正必要时才在内存中复制对象。这意味着R在更新对象时通常会复制内存中的对象，而`data.table`试图将这些资源密集型操作保持在最低水平。让我们通过`pryr`包来验证这一点，该包提供了一些方便的内存分析辅助函数，以了解R的内部机制。'
- en: 'First, let''s recreate the `data.table` object and let''s take a note of the
    pointer value (location address of the object in the memory), so that we will
    be able to verify later if the new variable simply updated the same R object,
    or if it was copied in the memory while the operation took place:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们重新创建`data.table`对象，并记录指针值（对象在内存中的位置地址），这样我们就可以在稍后验证新变量是否只是简单地更新了相同的R对象，或者在进行操作时在内存中进行了复制：
- en: '[PRE14]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Okay, so `0x62c88c0` refers to the location where `hflights_dt` is stored at
    the moment. Now, let''s check if it changes due to the traditional assignment
    operator:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，所以`0x62c88c0`指的是`hflights_dt`当前存储的位置。现在，让我们检查它是否会因为传统的赋值操作符而改变：
- en: '[PRE15]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: This is definitely a different location, which means that adding a new column
    to the R object also requires R to copy the whole object in the memory. Just imagine,
    we now moved 21 columns in memory due to adding another one.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这确实是一个不同的位置，这意味着向R对象添加新列也需要R在内存中复制整个对象。想象一下，我们现在因为添加了一个新列而在内存中移动了21列。
- en: 'Now, to bring about the usage of `:=` in `data.table`:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看如何在`data.table`中使用`:=`：
- en: '[PRE16]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The location of the R object in the memory did not change! And copying objects
    in the memory can cost you a lot of resources, thus a lot of time. Take a look
    at the following example, which is a slightly updated version of the above traditional
    variable assignment call, but with an added convenience layer of `within`:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: R对象在内存中的位置没有改变！并且内存中的对象复制可能会消耗大量资源，从而耗费大量时间。看看以下示例，这是上述传统变量赋值调用的略微更新版本，但增加了一个`within`的便利层：
- en: '[PRE17]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Here, using the `within` function probably copies the R object once more in
    the memory, and hence brings about the relatively serious performance overhead.
    Although the absolute time difference between the preceding examples might not
    seem very significant (not in the statistical context), but just imagine how the
    needless memory updates can affect the processing time of your data analysis with
    some larger datasets!
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，使用`within`函数可能在内存中再次复制R对象，从而带来相对严重的性能开销。尽管前述示例之间的绝对时间差异可能看起来并不非常显著（在统计环境中并不显著），但想象一下，不必要的内存更新如何影响大型数据集的数据分析处理时间！
- en: Creating multiple variables at a time
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一次创建多个变量
- en: 'One nice feature of `data.table` is the creation of multiple columns with a
    single command, which can be extremely useful in some cases. For example, we might
    be interested in the distance of airports in feet as well:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '`data.table`的一个不错特性是可以通过单个命令创建多个列，这在某些情况下可能非常有用。例如，我们可能对机场的英尺距离感兴趣：'
- en: '[PRE18]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'So, it''s as simple as providing a character vector of the desired variable
    names on the left-hand side and the `list` of appropriate values on the right-hand
    side of the `:=` operator. This feature can easily be used for some more complex
    tasks. For example, let''s create the dummy variables of the airline carriers:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，这就像在`:=`操作符的左侧提供一个所需的变量名称的字符向量，在右侧提供一个适当的值的`list`。这个特性可以很容易地用于一些更复杂的任务。例如，让我们创建航空公司的虚拟变量：
- en: '[PRE19]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Although it''s not a one-liner, and it also introduces a helper variable, it''s
    not that complex to see what we did:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然它不是一行代码，并且它还引入了一个辅助变量，但看到我们做了什么并不复杂：
- en: First, we saved the `unique` carrier names in a character vector.
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们将唯一的航空公司名称保存到一个字符向量中。
- en: Then, we defined the new variables' name with the help of that.
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们利用这个来定义新变量的名称。
- en: We iterated our anonymous function over this character vector as well, to return
    `TRUE` or `FALSE` if the carrier name matched the given column.
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还迭代了匿名函数对这个字符向量，以返回 `TRUE` 或 `FALSE`，如果承运人名称与给定列匹配。
- en: The given column was converted to `0` or `1` through `as.numeric`.
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 给定的列通过 `as.numeric` 转换为 `0` 或 `1`。
- en: And then, we simply checked the structure of all columns whose names start with
    `carrier`.
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们简单地检查了所有以 `carrier` 开头的列的结构。
- en: This is not perfect, as we usually leave out one label from the dummy variables
    to reduce redundancy. In the current situation, the last new column is simply
    the linear combination of the other newly created columns, thus information is
    duplicated. For this end, it's usually a good practice to leave out, for example,
    the last category by passing `-1` to the `n` argument in the `head` function.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 这并不完美，因为我们通常省略一个标签从虚拟变量中，以减少冗余。在当前情况下，最后一个新列只是其他新创建列的线性组合，因此信息被重复。为此，通常一个好的做法是通过将
    `-1` 传递给 `head` 函数中的 `n` 参数，省略例如最后一个类别。
- en: Computing new variables with dplyr
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 dplyr 计算新变量
- en: 'The usage of `mutate` from the `dplyr` package is identical to that of the
    base `within` function, although `mutate` is a lot quicker than `within`:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '`dplyr` 包中 `mutate` 的用法与基础 `within` 函数相同，尽管 `mutate` 比起 `within` 来说要快得多：'
- en: '[PRE20]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'If the analogy of `mutate` and `within` has not been made straightforward by
    the previous example, it''s probably also useful to show the same example without
    using pipes:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 如果之前的例子没有清楚地说明 `mutate` 和 `within` 的类比，那么也许展示一个不使用管道的相同例子也会很有用：
- en: '[PRE21]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Merging datasets
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 合并数据集
- en: 'Besides the previously described elementary actions on a single dataset, joining
    multiple data sources is one of the most used methods in everyday action. The
    most often used solution for such a task is to simply call the `merge` S3 method,
    which can act as a traditional SQL inner and left/right/full outer joiner of operations—represented
    in a brief summary by C.L. Moffatt (2008) as follows:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 除了之前描述的对单个数据集的基本操作外，将多个数据源连接起来是日常操作中最常用的方法之一。对于此类任务，最常用的解决方案是简单地调用 `merge` S3
    方法，它可以作为传统 SQL 内部、左/右/全外连接操作器——由 C.L. Moffatt (2008) 以以下简短总结表示：
- en: '![Merging datasets](img/2028OS_06_02.jpg)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![合并数据集](img/2028OS_06_02.jpg)'
- en: 'The `dplyr` package provides some easy ways for doing the previously presented
    join operations right from R, in an easy way:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '`dplyr` 包提供了一些简单的方法，可以直接从 R 中以简单的方式执行之前展示的连接操作：'
- en: '`inner_join`: This joins the variables of all the rows, which are found in
    both datasets'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inner_join`：这会将两个数据集中都找到的行变量连接起来'
- en: '`left_join`: This includes all the rows from the first dataset and join variables
    from the other table'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`left_join`：这包括第一个数据集中的所有行，并连接来自其他表的变量'
- en: '`semi_join`: This includes only those rows from the first dataset that are
    found in the other one as well'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`semi_join`：这仅包括那些在第一个数据集中也存在于其他数据集中的行'
- en: '`anti_join`: This is similar to `semi_join`, but includes only those rows from
    the first dataset that are not found in the other one'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`anti_join`：这与 `semi_join` 类似，但仅包括那些在第一个数据集中不存在于其他数据集中的行'
- en: Note
  id: totrans-101
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: For more examples, take a look at the *Two-table verbs* `dplyr` vignette, and
    the Data Wrangling cheat sheet listed in the *References* chapter at the end of
    the book.
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 更多示例，请参阅 *Two-table verbs* `dplyr` 章节和书中末尾的 *参考文献* 章节中列出的数据整理速查表。
- en: These features are also supported by the `mult` argument of `[` operator of
    `data.table` call, but for the time being, let's stick to the simpler use cases.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 这些特性也由 `data.table` 调用 `[` 操作符的 `mult` 参数支持，但在此阶段，让我们坚持使用更简单的用例。
- en: 'In the following example, we will merge a tiny dataset with the `hflights`
    data. Let''s create the `data.frame` demo by assigning names to the possible values
    of the `DayOfWeek` variable:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下示例中，我们将合并一个微小的数据集与 `hflights` 数据。让我们通过为 `DayOfWeek` 变量的可能值命名来创建 `data.frame`
    示例：
- en: '[PRE22]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Let''s see how we can left-join the previously defined `data.frame` with another
    `data.frame` and other tabular objects, as `merge` also supports fast operations
    on, for example, `data.table`:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何将之前定义的 `data.frame` 与另一个 `data.frame` 以及其他表格对象进行左连接，因为 `merge` 也支持对例如
    `data.table` 的快速操作：
- en: '[PRE23]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The prior example automatically merged the two tables via the `DayOfWeek` variable,
    which was part of both datasets and resulted in an extra variable in the original
    `hflights` dataset. However, we had to pass the variable name in the second example,
    as the `by` argument of `merge.data.table` defaults to the key variable of the
    object, which was missing then. One thing to note is that merging with `data.table`
    was a lot faster than the traditional tabular object type.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的例子自动通过`DayOfWeek`变量合并了两个表，这是两个数据集的一部分，并在原始的`hflights`数据集中产生了额外的变量。然而，在第二个例子中，我们必须传递变量名，因为`merge.data.table`的`by`参数默认为对象的关键变量，当时该变量缺失。需要注意的是，使用`data.table`进行合并比传统的表格对象类型要快得多。
- en: Note
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'Any ideas on how to improve the previous didactical example? Instead of merging,
    the new variable could be computed as well. See for example, the weekdays function
    from base R: `weekdays(as.Date(with(hflights, paste(Year, Month, DayofMonth, sep
    = ''-''))))`.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 对于如何改进之前的教例有什么想法吗？除了合并之外，新变量也可以被计算。例如，查看基础R中的`weekdays`函数：`weekdays(as.Date(with(hflights,
    paste(Year, Month, DayofMonth, sep = '-'))))`。
- en: A much simpler way of merging datasets is when you simply want to add new rows
    or columns to the dataset with the same structure. For this end, `rbind` and `cbind`,
    or `rBind` and `cBind` for sparse matrices, do a wonderful job.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 当你只想向数据集添加具有相同结构的新行或列时，合并数据集的简单方法。为此，`rbind`和`cbind`，或者对于稀疏矩阵的`rBind`和`cBind`，都能做得很好。
- en: One of the most often used functions along with these base commands is `do.call`,
    which can execute the `rbind` or `cbind` call on all elements of a `list`, thus
    enabling us, for example, to join a list of data frames. Such lists are usually
    created by `lapply` or the related functions from the `plyr` package. Similarly,
    `rbindlist` can be called to merge a `list` of `data.table` objects in a much
    faster way.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 与这些基本命令一起最常使用的函数之一是`do.call`，它可以在一个`list`的所有元素上执行`rbind`或`cbind`调用，从而使我们能够，例如，连接一系列数据框。这样的列表通常由`lapply`或`plyr`包的相关函数创建。同样，可以通过调用`rbindlist`以更快的方式合并一个`data.table`对象的`list`。
- en: Reshaping data in a flexible way
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 以灵活的方式重塑数据
- en: 'Hadley Wickham has written several R packages to tweak data structures, for
    example, a major part of his thesis concentrated on how to reshape data frames
    with his `reshape` package. Since then, this general aggregation and restructuring
    package has been renewed to be more efficient with the most commonly used tasks,
    and it was released with a new version number attached to the name: `reshape2`
    package.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: Hadley Wickham编写了几个R包来调整数据结构，例如，他论文的主要部分集中在如何使用他的`reshape`包来重塑数据框。从那时起，这个通用的聚合和重构包经过更新，以更高效地处理最常用的任务，并且它附带新的版本号被命名为`reshape2`包。
- en: This was a total rewrite of the `reshape` package, which improves speed at the
    cost of functionality. Currently, the most important feature of `reshape2` is
    the possibility to convert between the so-called long (narrow) and wide tabular
    data format. This basically pertains to the columns being stacked below each other,
    or arranged beside each other.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 这是对`reshape`包的全面重写，它以牺牲功能为代价提高了速度。目前，`reshape2`最重要的特性是能够在所谓的长（窄）表和宽表数据格式之间进行转换。这基本上涉及到列彼此堆叠或并排排列。
- en: 'These features were presented in Hadley''s works with the following image on
    data restructuring, with the related `reshape` functions and simple use cases:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 这些特性在Hadley的作品中通过以下关于数据重构的图像进行了展示，其中包含了相关的`reshape`函数和简单的用例：
- en: '![Reshaping data in a flexible way](img/2028OS_06_03.jpg)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![以灵活的方式重塑数据](img/2028OS_06_03.jpg)'
- en: As the `reshape` package is not under active development anymore, and its parts
    were outsourced to `reshape2`, `plyr`, and most recently to `dplyr`, we will only
    focus on the commonly used features of `reshape2` in the following pages. This
    will basically consist of the `melt` and `cast` functions, which provides a smart
    way of melting the data into a standardized form of measured and identifier variables
    (long table format), which can later be casted to a new shape for further analysis.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 由于`reshape`包不再处于积极开发状态，并且其部分已外包给`reshape2`、`plyr`和最近的`dplyr`，我们将在以下页面中仅关注`reshape2`的常用特性。这基本上包括`melt`和`cast`函数，它们提供了一种将数据熔化成测量和标识变量标准形式（长表格式）的智能方式，这些数据可以随后被铸造成新的形状以进行进一步分析。
- en: Converting wide tables to the long table format
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将宽表转换为长表格式
- en: 'Melting a data frame means that we transform the tabular data to key-value
    pairs, based on the given identifier variables. The original column names become
    the categories of the newly created `variable` column, while all numeric values
    of those (measured variables) are included in the new `value` column. Here''s
    a quick example:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据框熔化意味着我们将表格数据转换为基于给定标识变量键值对。原始的列名成为新创建的`variable`列的分类，而所有这些（测量变量）的数值都包含在新创建的`value`列中。这里有一个快速示例：
- en: '[PRE24]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: So, we have just restructured the original `data.frame`, which had 21 variables
    and a quarter of a million records, into only 7 columns and more than 3.5 million
    records. Six out of the seven columns are factor type identifier variables, and
    the last column stores all the values. But why is it useful? Why should we transform
    the traditional wide tabular format to the much longer type of data?
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们刚刚重新构建了原始的`data.frame`，它有21个变量和25万条记录，现在只有7列和超过350万条记录。其中六列是因子类型的标识变量，最后一列存储所有值。但为什么它有用？为什么我们要将传统的宽表格格式转换为更长的数据类型？
- en: For example, we might be interested in comparing the distribution of flight
    time with the actual elapsed time of the flight, which might not be straightforward
    to plot with the original data format. Although plotting a scatter plot of the
    above variables with the `ggplot2` package is extremely easy, how would you create
    two separate boxplots comparing the distributions?
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们可能对比较飞行时间与实际飞行时间的分布感兴趣，这可能不是用原始数据格式直接绘制的。尽管使用`ggplot2`包绘制上述变量的散点图非常容易，但你怎么创建两个单独的箱线图来比较分布呢？
- en: 'The problem here is that we have two separate variables for the time measurements,
    while `ggplot` requires one `numeric` and one `factor` variable, from which the
    latter will be used to provide the labels on the *x*-axis. For this end, let''s
    restructure our dataset with `melt` by specifying the two numeric variables to
    treat as measurement variables and dropping all other columns— or in other words,
    not having any identifier variables:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的问题是我们有两个独立的测量时间变量，而`ggplot`需要一个`numeric`和一个`factor`变量，后者将用于在*x*轴上提供标签。为此，让我们通过指定两个要作为测量变量处理的数值变量并删除所有其他列来使用`melt`重新构建我们的数据集——换句话说，不保留任何标识变量：
- en: '[PRE25]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Note
  id: totrans-126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: In general, it's not a good idea to melt a dataset without identifier variables,
    as casting it later becomes cumbersome, if not impossible.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，在没有标识变量的情况下熔化数据集不是一个好主意，因为后来将其铸造变得繁琐，甚至是不可能的。
- en: 'Please note that now we have exactly twice as many rows than we had before,
    and the `variable` column is a factor with only two levels, which represent the
    two measurement variables. And this resulting `data.frame` is now easy to plot
    with the two newly created columns:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，现在我们的行数是之前的两倍，而`variable`列是一个只有两个级别的因子，代表两个测量变量。现在这个结果`data.frame`使用这两个新创建的列绘图变得容易：
- en: '[PRE26]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '![Converting wide tables to the long table format](img/2028OS_06_04.jpg)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![将宽表格转换为长表格格式](img/2028OS_06_04.jpg)'
- en: Well, the previous example might not seem mission critical, and to be honest,
    I first used the `reshape` package when I needed some similar transformation to
    be able to produce some nifty `ggplot2` charts—as the previous problem simply
    does not exist if someone is using `base` graphics. For example, you can simply
    pass the two separate variables of the original dataset to the `boxplot` function.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，前面的例子可能看起来不是那么关键，说实话，我第一次使用`reshape`包是因为我需要一些类似的转换来能够制作一些巧妙的`ggplot2`图表——因为如果有人使用`base`图形，前面的这个问题根本就不存在。例如，你可以简单地将原始数据集的两个单独变量传递给`boxplot`函数。
- en: So, this is kind of entering the world of Hadley Wickham's R packages, and the
    journey indeed offers some great data analysis practices. Thus, I warmly suggest
    reading further, for example, on how using `ggplot2` is not easy, if not impossible,
    without knowing how to reshape datasets efficiently.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，这就像是进入了Hadley Wickham的R包的世界，这次旅程确实提供了一些优秀的数据分析实践。因此，我强烈建议进一步阅读，例如，了解如果不了解如何有效地重塑数据集，使用`ggplot2`可能并不容易，甚至是不可能的。
- en: Converting long tables to the wide table format
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将长表格转换为宽表格格式
- en: 'Casting a dataset is the opposite of melting, like turning key-value pairs
    into a tabular data format. But bear in mind that the key-value pairs can always
    be combined together in a variety of ways, so this process can result in extremely
    diversified outputs. Thus, you need a table and a formula to cast, for example:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 转换数据集是熔化的相反过程，就像将键值对转换为表格数据格式。但请记住，键值对可以以各种方式组合在一起，因此这个过程可以产生极其多样化的输出。因此，你需要一个表和一个公式来转换，例如：
- en: '[PRE27]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'This example shows how to aggregate the measured flight times for each month
    in 2011 with the help of melting and casting the `hflights` dataset:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 这个示例展示了如何通过熔化和转换 `hflights` 数据集来聚合 2011 年每个月测量的飞行时间：
- en: First, we melted the `data.frame` with the IDs being the `Month`, where we only
    kept two numeric variables for the flight times.
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们将 `data.frame` 转换为熔化形式，其中 ID 是 `Month`，我们只保留了两个表示飞行时间的数值变量。
- en: Then, we casted the resulting `data.frame` with a simple formula to show the
    mean of each month for all measurement variables.
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们使用一个简单的公式将结果 `data.frame` 转换为宽表格式，以显示所有测量变量每个月的平均值。
- en: 'I am pretty sure that now you can quickly restructure this data to be able
    to plot two separate lines for this basic time-series:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 我很确定你现在可以快速重新结构这些数据，以便能够绘制两条独立的线来表示这个基本的时间序列：
- en: '[PRE28]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '![Converting long tables to the wide table format](img/2028OS_06_05.jpg)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![将长表格转换为宽表格式](img/2028OS_06_05.jpg)'
- en: 'But of course, melting and casting can be used for a variety of things besides
    aggregating. For example, we can restructure our original database to have a special
    `Month`, which includes all the records of the data. This, of course, doubles
    the number of rows in the dataset, but also lets us easily generate a table on
    the data with margins. Here''s a quick example:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，除了聚合之外，熔化和转换还可以用于各种其他用途。例如，我们可以重新结构我们的原始数据库，使其具有特殊的 `Month`，该 `Month` 包含所有数据记录。当然，这会使数据集的行数翻倍，但同时也让我们能够轻松地生成带有边界的表格。以下是一个快速示例：
- en: '[PRE29]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: This is very similar to what we have seen previously, but as an intermediate
    step, we have converted the `Month` variable to be factor with a special level,
    which resulted in the last line of this table. This row represents the overall
    arithmetic average of the related measure variables.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 这与我们之前看到的情况非常相似，但作为一个中间步骤，我们将 `Month` 变量转换为具有特殊级别的因子，这导致了这张表的最后一行。这一行代表相关测量变量的整体算术平均值。
- en: Tweaking performance
  id: totrans-145
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 调整性能
- en: Some further good news on `reshape2` is that `data.table` has decent support
    for melting and casting, with highly improved performance. Matt Dowle has published
    some benchmarks with a 5-10 percent improvement in the processing times of using
    `cast` and `melt` on `data.table` objects instead of the traditional data frames,
    which is highly impressive.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 关于 `reshape2` 的另一个好消息是 `data.table` 对熔化和转换有相当的支持，并且性能有了显著提升。Matt Dowle 发布了一些基准测试，使用
    `cast` 和 `melt` 在 `data.table` 对象上而不是传统数据框上的处理时间提高了 5-10%，这非常令人印象深刻。
- en: To verify these results on your own dataset, simply transform the `data.frame`
    objects to `data.table` before calling the `reshape2` functions, as the `data.table`
    package already ships the appropriate `S3` methods to extend `reshape2`.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 要验证你自己的数据集上的这些结果，只需在调用 `reshape2` 函数之前将 `data.frame` 对象转换为 `data.table`，因为 `data.table`
    包已经包含了适当的 `S3` 方法来扩展 `reshape2`。
- en: The evolution of the reshape packages
  id: totrans-148
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '`reshape` 包的发展历程'
- en: As mentioned before, `reshape2` was a complete rewrite of the `reshape` package,
    based on around 5 years of experience in using and developing the latter. This
    update also included some trade-offs, as the original reshape tasks were split
    among multiple packages. Thus, `reshape2` now offers a lot less compared to the
    kind of magic features that were supported by `reshape`. Just check, for example
    `reshape::cast`; especially the `margins` and `add.missing` argument!
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，`reshape2` 是基于大约 5 年使用和开发 `reshape` 包的经验而进行的完全重写。这次更新也包含了一些权衡，因为原始的 `reshape`
    任务被分散到多个包中。因此，与 `reshape` 支持的那种神奇功能相比，`reshape2` 现在提供的功能要少得多。例如，检查一下 `reshape::cast`；特别是
    `margins` 和 `add.missing` 参数！
- en: 'But as it turns out, even `reshape2` offers a lot more than simply melting
    and casting data frames. The birth of the `tidyr` package was inspired by this
    fact: to have a package in the Hadleyverse that supports easy data cleaning and
    transformation between the long and wide table formats. In `tidyr` parlance, these
    operations are called `gather` and `spread`.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 但实际上，即使是 `reshape2` 也提供了比仅仅熔化和铸造数据框多得多的功能。`tidyr` 包的诞生正是受到这一事实的启发：在 Hadleyverse
    中有一个支持轻松进行数据清理和长宽表格式之间转换的包。在 `tidyr` 的术语中，这些操作被称为 `gather` 和 `spread`。
- en: 'Just to give a quick example of this new syntax, let''s re-implement the previous
    examples:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 只为了快速展示这个新语法的一个例子，让我们重新实现之前的示例：
- en: '[PRE30]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Summary
  id: totrans-153
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we focused on how to transform raw data into an appropriately
    structured format, before we could run statistical tests. This process is a really
    important part of our everyday actions, and it takes most of a data scientist's
    time. But after reading this chapter, you should be confident in how to restructure
    your data in most cases— so, this is the right time to focus on building some
    models, which we will do in the next chapter.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们专注于如何在运行统计测试之前将原始数据转换成适当的格式结构。这个过程是我们日常行动中非常重要的一部分，占据了数据科学家大部分的时间。但在阅读本章之后，你应该对如何在大多数情况下重新结构化你的数据有信心——因此，现在是专注于构建一些模型的时候了，我们将在下一章中这样做。
