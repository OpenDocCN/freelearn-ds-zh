<html><head></head><body><div><div><div><div><h1 class="title"><a id="ch03"/>Chapter 3. Simple Tweaks to Make R Run Faster</h1></div></div></div><p>Improving the speed of an R code does not necessarily involve advanced optimization techniques like parallelizing the code or making it run in the database. Indeed, there are a number of simple tweaks that, while not always obvious, can make R run significantly faster. In this chapter, some of these tweaks are described. By no means do they capture all possible simple means to optimize the R code. However, they constitute some of the most fundamental, and hence often-encountered, opportunities to gain some speedups.</p><p>This chapter presents these tweaks in the order of decreasing generality—the more general ones are those found in almost all R codes, regardless of their application. Each tweak is accompanied by an example code that is intentionally kept simple so as not to obscure the explanation of the intended concept with unnecessary application-specific knowledge. In all these examples, artificial datasets are generated using random functions in R.</p><p>This chapter covers the following topics:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Vectorization</li><li class="listitem" style="list-style-type: disc">Use of built-in functions</li><li class="listitem" style="list-style-type: disc">Preallocating memory</li><li class="listitem" style="list-style-type: disc">Use of simpler data structures</li><li class="listitem" style="list-style-type: disc">Use of hash tables for frequent lookups on large data</li><li class="listitem" style="list-style-type: disc">Seeking fast alternative packages in CRAN</li></ul></div><div><div><div><div><h1 class="title"><a id="ch03lvl1sec20"/>Vectorization</h1></div></div></div><p>Most R users <a id="id58" class="indexterm"/>should have encountered this first tweak. In essence, vectorization allows R operators to take vectors as arguments for quick processing of multiple values. This is unlike some other programming languages such as C, C++, and Java, in which the processing of multiple values is usually done by iterating through and applying operators on each element of a vector (or array). R, being a flexible language, allows users to program using either iteration or vectorization. However, most of the time, iteration incurs significant and unnecessary computational cost because R is an interpreted, not compiled, language.</p><p>Take for example, the following simple code. Its goal is simply to calculate the square of every element in the random vector <code class="literal">data</code>. The first approach is to set up a <code class="literal">for</code> loop through every element of <code class="literal">data</code> and square it individually. Many would be tempted to take this approach because this is how it is done typically in other programming languages. Yet, a far more optimized approach in R is to apply the square operator on the <code class="literal">data</code> vector directly. This gives exactly the same output as the <code class="literal">for</code> loop, but much faster:</p><div><pre class="programlisting">N &lt;- 1E5
data &lt;- sample(1:30, size=N, replace=T)
system.time({ 
  data_sq1 &lt;- numeric(N)
  for(j in 1:N) {
    data_sq1[j] &lt;- data[j]^2
  } 
})
##  user  system elapsed 
## 0.144   0.011   0.156 
system.time(data_sq2 &lt;- data^2)
##  user  system elapsed 
##     0       0       0</pre></div><p>The following table shows the performance gains as the vector size increases (in logarithmic scale) from 100,000 to 100,000,000. Notice that the compute time of the non-vectorized approach is about 200 times that of the vectorized approach, regardless of the vector size.</p><div><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/></colgroup><tbody><tr><td style="text-align: left" valign="top">
<p><strong>Vector size</strong></p>
</td><td style="text-align: left" valign="top">
<p>100,000</p>
</td><td style="text-align: left" valign="top">
<p>1,000,000</p>
</td><td style="text-align: left" valign="top">
<p>10,000,000</p>
</td><td style="text-align: left" valign="top">
<p>100,000,000</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p><strong>Non-vectorized</strong></p>
</td><td style="text-align: left" valign="top">
<p>120 ms</p>
</td><td style="text-align: left" valign="top">
<p>1.19 s</p>
</td><td style="text-align: left" valign="top">
<p>11.9 s</p>
</td><td style="text-align: left" valign="top">
<p>117 s</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p><strong>Vectorized</strong></p>
</td><td style="text-align: left" valign="top">
<p>508 μs</p>
</td><td style="text-align: left" valign="top">
<p>5.67 ms</p>
</td><td style="text-align: left" valign="top">
<p>52.5 ms</p>
</td><td style="text-align: left" valign="top">
<p>583 ms</p>
</td></tr></tbody></table></div><p>When R executes a code, it has to take many steps behind the scenes. One example is type checking. R <a id="id59" class="indexterm"/>objects such as vectors do not need to be strictly defined to be of a particular type, such as an integer or a character. One can append a character to an integer vector without triggering any error—R converts the vector into a character vector automatically. Every time an operator is applied on a vector, R needs to check the type of the vector only once, but with the use of the iteration approach, this type checking happens as many times as the number of iterations, which incurs some computational costs.</p></div></div>
<div><div><div><div><h1 class="title"><a id="ch03lvl1sec21"/>Use of built-in functions</h1></div></div></div><p>As a <a id="id60" class="indexterm"/>programming language, R comes with low-level operators, such as basic arithmetic operators that can be used to construct more complex operators or functions. While R provides the flexibility to define functions, a performance comparison between an R function versus an equivalent function in a compiled language would almost always favor the latter. However, R and some CRAN packages provide a rich set of functions that are implemented in compiled languages such as C/C++. It is usually preferable to use these functions rather than to write custom R functions to perform the same task.</p><p>Consider a simple example of how to calculate the sums of the rows of the following random matrix <code class="literal">data</code>. A code to perform these functions can be constructed by calling the <code class="literal">apply()</code> function, and setting the margin to 1 (representing a row operation) and by setting the <code class="literal">FUN</code> (or function) argument to <code class="literal">sum</code>. Alternatively, R provides a built-in function for this purpose called <code class="literal">rowSums</code>. The computational time of the former approach, as measured by <code class="literal">system.time</code>, is 11 times longer than that of the latter approach, which is an optimized and precompiled C function:</p><div><pre class="programlisting">data &lt;- rnorm(1E4*1000)
dim(data) &lt;- c(1E4,1000)
system.time(data_sum1 &lt;- apply(data, 1, sum)) 
##  user  system elapsed 
## 0.241   0.053   0.294 
system.time(data_sum2 &lt;- rowSums(data))
##  user  system elapsed 
## 0.026   0.000   0.026</pre></div><p>Speaking of optimized functions, our effort to improve the speed of an R code should not stop at precompiled functions that come with R. Over the years, the open source community has developed optimized libraries of specific functions that R can leverage. Take Basic Linear Algebra Subprograms (BLAS) for example (for more information refer to <a class="ulink" href="http://www.netlib.org/blas/">http://www.netlib.org/blas/</a>). It was developed in the 1970s for Fortran and has since gained wider use by other languages (including R) because matrix operations make up the building blocks of many algorithms in various fields. There are now many implementations of BLAS, some of which include the capability to execute matrix operations in a multithreaded manner.</p><p>For example, the <a id="id61" class="indexterm"/>Mac OS X version of R comes enabled with BLAS. The implementation of BLAS that is used is the reference BLAS from R called <code class="literal">libRblas.0.dylib</code>. Mac OS X however comes with its own version of BLAS, <code class="literal">libBLAS.dylib</code>, which is optimized for its hardware. R can be configured to use the optimized BLAS by executing the following commands in Terminal:</p><div><pre class="programlisting">$ cd /Library/Frameworks/R.framework/Resources/lib
$ ln -sf /System/Library/Frameworks/Accelerate.framework/Frameworks/vecLib.framework/Versions/Current/libBLAS.dylib libRblas.dylib</pre></div><p>To test the effect of using different BLAS libraries, the following R code performs a simple matrix multiplication on a large random matrix. Using R's default BLAS library, it took about 7 seconds for us to complete the task. After pointing R to the optimized BLAS, the same task was completed in about a tenth of the time:</p><div><pre class="programlisting">data &lt;- rnorm(1E7)
dim(data) &lt;- c(1E4, 1E3)
system.time(data_mul &lt;- t(data) %*% data)
##  user  system elapsed 
## 7.123   0.015   7.136
system.time(data_mul &lt;- t(data) %*% data) # with optimized BLAS
##  user  system elapsed 
## 1.304   0.005   0.726</pre></div><p>There are BLAS versions of Windows and Linux available for you to download. If R is compiled with an enabled BLAS, that is, by setting the configuration option to <code class="literal">--enable-BLAS-shlib</code> while compiling R from its source, swapping between BLAS versions is done in a similar manner as in Mac OS X: by replacing the default BLAS library file with the new one. In Windows, the default library is located in <code class="literal">R_HOME\bin\x64\Rblas.dll</code>; while in Linux, it is in<code class="literal"> R_HOME/lib/libRblas.so</code>.</p></div>
<div><div><div><div><h1 class="title"><a id="ch03lvl1sec22"/>Preallocating memory</h1></div></div></div><p>Most strongly <a id="id62" class="indexterm"/>typed programming languages like C, C++, and Java generally require a vector (or array) to be declared prior to any operation applied on it. This declaration in effect preallocates the memory space that the vector requires. There are special occasions where dynamic memory allocation is used, but this is seldom the first choice mainly because dynamic memory allocation slows down a program. Every time a vector is resized, the program needs to perform extra steps that include copying the vector to a larger or smaller memory block and deleting the old vector. These steps are not needed if the memory is preallocated.</p><p>When it comes to preallocating memory, R is no different from the other programming languages. However, being an interpreted language, it imposes less control, thus it is easy for users to overlook this—R will not throw any compilation error if a vector's memory is not preallocated. Nevertheless, not preallocating memory in R can result in significantly longer execution times, especially when the vector is large.</p><p>To demonstrate this, let's have a look at the following R code. It shows you two approaches to generate a series of random numbers, where each vector element is defined as the value of the previous element +/- a random integer between -5 to 5. The first approach (stores the results in <code class="literal">data_series1</code>) bypasses the preallocation of the vector's memory, that is, it starts with a vector of a single element and appends a new element at each iteration. The second approach (with results in <code class="literal">data_series2</code>) preallocates the memory by declaring a numeric vector of size<code class="literal"> N</code>. The preallocated space, as represented by the vector's index, is filled in at every iteration. By preallocating the memory, the computation time on a vector of 10,000 elements is 10 times faster than the dynamic allocation. A benchmark exercise by varying the vector size, captured in the upcoming table, shows that while the computation time increases linearly when memory is preallocated, it increases super linearly when memory is dynamically allocated. It is critical for performance therefore to avoid unnecessary dynamic memory allocation in R:</p><div><pre class="programlisting">N &lt;- 1E4
data_series1 &lt;- 1
system.time({
  for (j in 2:N) {
    data_series1 &lt;- c(data_series1,
                      data_series1[j-1]+sample(-5:5, size=1))
  }
})
##  user  system elapsed 
## 0.254   0.004   0.257 
data_series2 &lt;- numeric(N)
data_series2[1] &lt;- 1
system.time({
  for (j in 2:N) {
    data_series2[j] &lt;- data_series2[j-1]+sample(-5:5, size=1)
  }
})
##  user  system elapsed 
## 0.066   0.003   0.068</pre></div><div><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/><col style="text-align: left"/></colgroup><tbody><tr><td style="text-align: left" valign="top">
<p><strong>Vector size</strong></p>
</td><td style="text-align: left" valign="top">
<p>10</p>
</td><td style="text-align: left" valign="top">
<p>100</p>
</td><td style="text-align: left" valign="top">
<p>1000</p>
</td><td style="text-align: left" valign="top">
<p>10,000</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p><strong>Dynamic allocation</strong></p>
</td><td style="text-align: left" valign="top">
<p>0</p>
</td><td style="text-align: left" valign="top">
<p>0.006</p>
</td><td style="text-align: left" valign="top">
<p>0.288</p>
</td><td style="text-align: left" valign="top">
<p>25.373</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p><strong>Preallocated</strong></p>
</td><td style="text-align: left" valign="top">
<p>0.001</p>
</td><td style="text-align: left" valign="top">
<p>0.006</p>
</td><td style="text-align: left" valign="top">
<p>0.062</p>
</td><td style="text-align: left" valign="top">
<p>0.577</p>
</td></tr></tbody></table></div><p>At this point, it <a id="id63" class="indexterm"/>is interesting to compare the <code class="literal">apply</code> family of functions versus loops in R. Most R users would be familiar with the <code class="literal">apply()</code> function and its variants, including <code class="literal">lapply()</code>, <code class="literal">sapply()</code>, and <code class="literal">tapply()</code>. They provide the means to perform the same operation repeatedly on individual elements of a collection (for example, <code class="literal">data.frame</code>, <code class="literal">list</code>, or <code class="literal">vector</code>/<code class="literal">matrix</code>). Effectively, the <code class="literal">apply</code> family serves as a possible substitute of looping in R, provided there are no dependencies between one iteration and another. Besides simplifying the expression (it is often possible to express a multiline <code class="literal">for</code> loop as a single line <code class="literal">apply()</code> call), the <code class="literal">apply</code> family offers the benefit of automatically taking care of the memory preallocation and other housekeeping activities like deleting loop indices.</p><p>But does <code class="literal">apply</code> offer performance advantages over looping? The following code offers an answer to this. Two different approaches are used to generate a list of normally distributed random vectors whose sizes are also randomly set to values between 1 and 30. The first approach uses a <code class="literal">for</code> loop while the second uses <code class="literal">lapply()</code>. Applying <code class="literal">system.time()</code> on both approaches shows that <code class="literal">lapply()</code> is significantly faster than the <code class="literal">for</code> loop:</p><div><pre class="programlisting">N &lt;- 1E5
data &lt;- sample(1:30, size=N, replace=T)
data_rand1 &lt;- list()
system.time(for(i in 1:N) data_rand1[[i]] &lt;- rnorm(data[i]))
##   user  system elapsed 
## 33.891   1.241  35.120 
system.time(data_rand2 &lt;- lapply(data, rnorm))
##  user  system elapsed 
## 0.597   0.037   0.633</pre></div><p>But note that the <code class="literal">for</code> loop is implemented naively without preallocating the memory. The following code modifies it now with the preallocated memory. Its computation time has significantly been reduced to be just a tenth of a second slower than <code class="literal">lapply()</code>:</p><div><pre class="programlisting">data_rand3 &lt;- vector("list", N)
system.time(for(i in 1:N) data_rand3[[i]] &lt;- rnorm(data[i]))
##  user  system elapsed 
## 0.737   0.036   0.773</pre></div><p>To establish this more <a id="id64" class="indexterm"/>convincingly, the comparison was repeated using <code class="literal">microbenchmark()</code> to run each expression 100 times. The results indicate that <code class="literal">lapply()</code> offers a slight performance advantage over a <code class="literal">for</code> loop:</p><div><pre class="programlisting">microbenchmark(data_rand2 &lt;- lapply(data, rnorm),
               for(i in 1:N) data_rand3[[i]] &lt;- rnorm(data[i]))
## Unit: milliseconds
##                                              expr      min
##                 data_rand2 &lt;- lapply(data, rnorm) 441.1108
##  for (i in 1:N) data_rand3[[i]] &lt;- rnorm(data[i]) 531.1212
##       lq     mean   median       uq      max neval
## 459.9666 498.1296 477.4583 517.4329 634.7849   100
## 555.8512 603.7997 581.5236 662.2536 745.4247   100</pre></div><p>Based on this, the general view of replacing <code class="literal">for</code> loops with <code class="literal">apply</code> in R whenever possible is valid, but perhaps the performance gain would not be dramatic. In <a class="link" href="ch06.html" title="Chapter 6. Simple Tweaks to Use Less RAM">Chapter 6</a>, <em>Simple Tweaks to Use Less RAM</em>, another benefit of <code class="literal">apply</code> will be discussed—that it reveals parts of R code that can be parallelized.</p></div>
<div><div><div><div><h1 class="title"><a id="ch03lvl1sec23"/>Use of simpler data structures</h1></div></div></div><p>Many R users <a id="id65" class="indexterm"/>would agree that <code class="literal">data.frame</code> as a data structure is the workhorse of data analysis in R. It provides an intuitive way to represent a typical structured dataset with rows and columns representing observations and variables respectively. A <code class="literal">data.frame</code> object also allows more flexibility than a matrix by allowing variables of different types (such as character and numeric variables in a single <code class="literal">data.frame</code>). Furthermore, in cases where a <code class="literal">data.frame</code> stores only variables of the same type, basic matrix operations conveniently become applicable to it without any explicit coercing required. This convenience, however, can come with performance degradation.</p><p>Applying a matrix operation on a <code class="literal">data.frame</code> is slower than on a <code class="literal">matrix</code>. One of the reasons is that most matrix operations first coerce the <code class="literal">data.frame</code> into a <code class="literal">matrix</code> before performing the computation. For this reason, where possible, one should use a <code class="literal">matrix</code> in <a id="id66" class="indexterm"/>place of a <code class="literal">data.frame</code>. The next code demonstrates this point. The goal is simply to perform row summation on a matrix and its equivalent <code class="literal">data.frame</code> representation. Using a <code class="literal">matrix</code> representation results in about 3x speedup compared to using a <code class="literal">data.frame</code> representation:</p><div><pre class="programlisting">data &lt;- rnorm(1E4*1000)
dim(data) &lt;- c(1E4,1000)
system.time(data_rs1 &lt;- rowSums(data))
##  user  system elapsed 
## 0.026   0.000   0.026 
data_df &lt;- data.frame(data)
system.time(data_rs2 &lt;- rowSums(data_df))
##  user  system elapsed 
## 0.060   0.015   0.076</pre></div><p>In many cases of R however, the use of <code class="literal">data.frame</code> is unavoidable, for example, when a dataset has mixed variable types. In this case, there is also a simple tweak that can improve the speed of one of the most frequently used operations on a <code class="literal">data.frame</code>, subsetting. Subsetting a <code class="literal">data.frame</code> is commonly done by conditioning its rows (or columns) through a logical test as in the following code:</p><div><pre class="programlisting">data &lt;- rnorm(1E5*1000)
dim(data) &lt;- c(1E5,1000)
data_df &lt;- data.frame(data)
system.time(data_df[data_df$X100&gt;0 &amp; data_df$X200&lt;0,])
##  user  system elapsed 
## 2.436   0.221   2.656</pre></div><p>An alternative to this is to wrap the condition by the <code class="literal">which</code> function. The speed is improved significantly as shown follows:</p><div><pre class="programlisting">system.time(data_df[which(data_df$X100&gt;0 &amp; data_df$X200&lt;0),])
##  user  system elapsed 
## 0.245   0.086   0.331</pre></div></div>
<div><div><div><div><h1 class="title"><a id="ch03lvl1sec24"/>Use of hash tables for frequent lookups on large data</h1></div></div></div><p>One common task in <a id="id67" class="indexterm"/>data analysis is data lookup, which is often implemented via a list in R. For example, to look up customers' ages, we can define a list, say, <code class="literal">cust_age</code>, with values set to customer ages and names set to the corresponding customer names (or IDs), that is <code class="literal">names(cust_age) &lt;- cust_name</code>. In this case, to look up John Doe's age, the following can be called: <code class="literal">cust_age[["John_Doe"]]</code>. However, the implementation of lists in R is not optimized for lookup; it incurs <em>O(N)</em> time complexity to perform a lookup on a list of <em>N</em> elements. This means that the values indexed later in the list require more time to look up. As <em>N</em> grows, this effect gets stronger. When a program requires frequent lookups, the cumulative effect can be significant. An alternative to lists that offers a more optimized data lookup is a hash table. In R, this is available from the CRAN package <em>hash</em>. A hash table's lookup incurs <em>O(1)</em> time complexity.</p><p>The next code demonstrates the benefit of lookups in hash tables over lists. It simulates 1,000 lookups from a random list and its equivalent hash table representation. The total computation time required for the list is 6.14 seconds, while for the hash table is 0.31 seconds. One trade-off is that it takes more time to generate a hash table than a list. But for a program that requires frequent lookups on large data, this overhead can be insignificant:</p><div><pre class="programlisting">data &lt;- rnorm(1E6)
data_ls &lt;- as.list(data)
names(data_ls) &lt;- paste("V", c(1:1E6), sep="")
index_rand &lt;- sample(1:1E6, size=1000, replace=T)
index &lt;- paste("V", index_rand, sep="")
list_comptime &lt;- sapply(index, FUN=function(x){
  system.time(data_ls[[x]])[3]})
sum(list_comptime)
## [1] 6.144
library(hash)
data_h &lt;- hash(names(data_ls), data)
hash_comptime &lt;- sapply(index, FUN=function(x){
  system.time(data_h[[x]])[3]})
sum(hash_comptime)
## [1] 0.308</pre></div></div>
<div><div><div><div><h1 class="title"><a id="ch03lvl1sec25"/>Seeking fast alternative packages in CRAN</h1></div></div></div><p>One key <a id="id68" class="indexterm"/>advantage of R is its rich and active open source community, CRAN. As of the time of writing, there are over 6,000 R packages in CRAN. Given this, it is common that multiple packages offer the same functionalities. Some of these alternatives are designed specifically to improve the performance of a base or an existing CRAN package's performance. Others do not target performance improvement explicitly, but nevertheless achieve it as a by-product.</p><p>An example of an alternative fast package developed to achieve performance gains is the <code class="literal">fastcluster</code> package. It was developed to improve the speed of hierarchical clustering provided by the base package through the <code class="literal">hclust</code> function. Depending on how the distance matrix gets updated after every branch merging in the hierarchical clustering procedure, its time complexity can vary significantly. The <code class="literal">fastcluster</code> package is developed using an optimized C++ code that improves the speed significantly compared to the routines implemented in <code class="literal">hclust</code>. The following R code compares the performance of the two functions on a random matrix with 10,000 rows and 100 columns:</p><div><pre class="programlisting">data &lt;- rnorm(1E4*100)
dim(data) &lt;- c(1E4,100)
dist_data &lt;- dist(data)
system.time(hc_data &lt;- hclust(dist_data))
##  user  system elapsed 
## 3.488   0.200   4.081 
library(fastcluster)
system.time(hc_data &lt;- hclust(dist_data))
##  user  system elapsed 
## 1.972   0.123   2.127</pre></div><p>An example of a function that has more than one implementation, where one happens to be faster than the others as a by-product is <strong>Principal Component Analysis</strong> (<strong>PCA</strong>). PCA<a id="id69" class="indexterm"/> is a dimensionality reduction technique that achieves its goal by projecting a dataset onto orthogonal axes (called principal components) that maximize the dataset's variance. The most common approach to PCA is via the Eigenvalue decomposition of the dataset's covariance matrix. But there are alternative methods. In R, two of these alternatives materialize in two PCA functions called <code class="literal">prcomp</code> and <code class="literal">princomp</code> (both are parts of the <code class="literal">stats</code> package). A quick comparison on a random matrix with 100,000 rows and 100 columns as in the following code demonstrates that <code class="literal">princomp</code> is close to 2x faster than <code class="literal">prcomp</code>:</p><div><pre class="programlisting">data &lt;- rnorm(1E5*100)
dim(data) &lt;- c(1E5,100)
system.time(prcomp_data &lt;- prcomp(data))
##  user  system elapsed 
## 4.101   0.091   4.190 
system.time(princomp_data &lt;- princomp(data))
##  user  system elapsed 
## 2.505   0.071   2.576 </pre></div><p>There are other <a id="id70" class="indexterm"/>examples of fast packages both explicitly and implicitly. They include:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">fastmatch</code>: This provides a faster version of base R's <code class="literal">match</code> function</li><li class="listitem" style="list-style-type: disc"><code class="literal">RcppEigen</code>: This includes a faster version of linear modeling <code class="literal">lm</code></li><li class="listitem" style="list-style-type: disc"><code class="literal">data.table</code>: This offers faster data manipulation operations compared to the standard <code class="literal">data.frame</code> operations</li><li class="listitem" style="list-style-type: disc"><code class="literal">dplyr</code> : This offers a set of tools to manipulate data frame-like objects efficiently</li></ul></div></div>
<div><div><div><div><h1 class="title"><a id="ch03lvl1sec26"/>Summary</h1></div></div></div><p>This chapter described a few simple tweaks to improve the speed of an R code. Some of the tweaks are well known, but often overlooked in practice; others are less obvious. Regardless of their nature, and despite their simplicity, these low hanging fruits can offer significant performance gains and sometimes even more than the advanced optimization discussed in subsequent chapters. As such, these tweaks should be taken as the first steps in order to optimize an R code.</p><p>In the next chapter, we will see how to take R's performance even further by using compiled code.</p></div></body></html>