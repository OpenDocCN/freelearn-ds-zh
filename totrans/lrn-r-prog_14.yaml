- en: Chapter 14. Web Scraping
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: R provides a platform with easy access to statistical computing and data analysis.
    Given a data set, it is handy to perform data transformation and apply analytic
    models and numeric methods with either flexible data structures or high performance,
    as discussed in previous chapters.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, the input data set is not always as immediately available as tables
    provided by well-organized commercial databases. Sometimes, we have to collect
    data by ourselves. Web content is an important source of data for a wide range
    of research fields. To collect (scrape or harvest) data from the Internet, we
    need appropriate techniques and tools. In this chapter, we''ll introduce the basic
    knowledge and tools of web scraping, including:'
  prefs: []
  type: TYPE_NORMAL
- en: Looking inside web pages
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learning CSS and XPath selector
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Analyzing HTML code and extracting data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Looking inside web pages
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Web pages are made to present information. The following screenshot shows a
    simple web page located at `data/simple-page.html` that has a heading and a paragraph:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Looking inside web pages](img/image_14_001.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'All modern web browsers support such web pages. If you open `data/simple-page.html`
    with any text editor, it will show the code behind the web page as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code is an example of HTML (Hyper Text Markup Language). It is
    the most widely used language on the Internet. Different from any programming
    language to be finally translated into computer instructions, HTML describes the
    layout and content of a web page, and web browsers are designed to render the
    code into a web page according to web standards.
  prefs: []
  type: TYPE_NORMAL
- en: Modern web browsers use the first line of HTML to determine which standard is
    used to render the web page. In this case, the latest standard, HTML 5, is used.
  prefs: []
  type: TYPE_NORMAL
- en: If you read through the code, you'll probably notice that HTML is nothing but
    a nested structure of tags such as `<html>`, `<title>`, `<body>`, `<h1>`, and `<p>`.
    Each tag begins with `<tag>` and is closed with `</tag>`.
  prefs: []
  type: TYPE_NORMAL
- en: In fact, these tags are not arbitrarily named, nor are they allowed to contain
    other arbitrary tags. Each has a specific meaning to the web browser and is only
    allowed to contain a subset of tags, or even none.
  prefs: []
  type: TYPE_NORMAL
- en: The `<html>` tag is the root element of all HTML. It most commonly contains
    `<head>` and `<body>`. The `<head>` tag usually contains `<title>` to show on
    the title bar and browser tabs and other metadata of the web page, while `<body>`
    plays the main role in determining the layout and contents of the web page.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the `<body>` tag, tags can be nested more freely. The simple page only contains
    a level-1 heading (`<h1>`) and a paragraph (`<p>`) while the following web page
    contains a table with two rows and two columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Looking inside web pages](img/image_14_002.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The HTML code behind the web page is stored in `data/single-table.html`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that a `<table>` tag is structured row by row: `<tr>` represents a table
    row, `<th>` a table header cell, and `<td>` a table cell.'
  prefs: []
  type: TYPE_NORMAL
- en: Also notice that an HTML element such as `<table>` may have additional attributes
    in the form of `<table attr1="value1" attr2="value2">`. The attributes are not
    arbitrarily defined. Instead, each has a specific meaning according to the standard.
    In the preceding code, `id` is the identifier of the table and `border` controls
    its border width.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following page looks different from the previous ones in that it shows
    some styling of contents:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Looking inside web pages](img/image_14_003.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'If you take a look at its source code at `data/simple-products.html`, you''ll
    find some new tags such as `<div>` (a section), `<ul>` (unrecorded list), `<li>`
    (list item), and `<span>` (also a section used for applying styles); additionally,
    many HTML elements have an attribute called `style` to define their appearance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Values in style is written in the form of `property1: value1; property2: value2;`.
    However, the styles of the list items are a bit redundant because all product
    names share the same style and this is also true for all product prices. The following
    HTML at `data/products.html` uses CSS (**Cascading Style Sheets**) instead to
    avoid redundant styling definitions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Note that we add `<style>` in `<head>` to declare a global stylesheet in the
    web page. We also switch `style` to `class` for content elements (`div`, `li`,
    and `span`) to use those pre-defined styles. The syntax of CSS is briefly introduced
    in the following code.
  prefs: []
  type: TYPE_NORMAL
- en: 'Match all `<h1>` elements:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Match all elements with the `product-list` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Match all elements with the `product-list` class, and then match all nested
    elements with the `name` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Match all elements with the `product-list` class, then match all nested `<li>`
    elements with the `selected` class, and finally match all nested elements with
    the `name` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that simply using `style` cannot achieve this. The following screenshot
    shows the rendered web page:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Looking inside web pages](img/image_14_004.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Each CSS entry consists of a CSS selector (for example, `.product-list`) to
    match HTML elements and the styles (for example, `color: red;`) to apply. CSS
    selectors are not only used to apply styling, but are also commonly used to extract
    contents from web pages so the HTML elements of interest are properly matched.
    This is an underlying technique behind web scraping.'
  prefs: []
  type: TYPE_NORMAL
- en: 'CSS is much richer than demonstrated in the preceding code. For web scraping,
    we use the following examples to show the most commonly used CSS selectors:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Syntax** | **Match** |'
  prefs: []
  type: TYPE_TB
- en: '| `*` | All elements |'
  prefs: []
  type: TYPE_TB
- en: '| `h1, h2, h3` | `<h1>`,`<h2>`,`<h3>` |'
  prefs: []
  type: TYPE_TB
- en: '| `#table1` | `<* id="table1">` |'
  prefs: []
  type: TYPE_TB
- en: '| `.product-list` | `<* class="product-list">` |'
  prefs: []
  type: TYPE_TB
- en: '| `div#container` | `<div id="container">` |'
  prefs: []
  type: TYPE_TB
- en: '| `div a` | `<div><a>` and `<div><p><a>` |'
  prefs: []
  type: TYPE_TB
- en: '| `div > a` | `<div><a>` but not`<div><p><a>` |'
  prefs: []
  type: TYPE_TB
- en: '| `div > a.new` | `<div><a class="new">` |'
  prefs: []
  type: TYPE_TB
- en: '| `ul > li:first-child` | First `<li>` in`<ul>` |'
  prefs: []
  type: TYPE_TB
- en: '| `ul > li:last-child` | Last `<li>` in`<ul>` |'
  prefs: []
  type: TYPE_TB
- en: '| `ul > li:nth-child(3)` | 3rd `<li>` in`<ul>` |'
  prefs: []
  type: TYPE_TB
- en: '| `p + *` | Next element of `<p>` |'
  prefs: []
  type: TYPE_TB
- en: '| `img[title]` | `<img>` with title attribute |'
  prefs: []
  type: TYPE_TB
- en: '| `table[border=1]` | <table border="1"> |'
  prefs: []
  type: TYPE_TB
- en: In each level, `tag#id.class[]` can be used with `tag`, `#id.class`, and `[]`
    optionally. For more information on CSS selectors, visit [https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Selectors](https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Selectors).
    To learn more about HTML tags, visit [http://www.w3schools.com/tags/](http://www.w3schools.com/tags/).
  prefs: []
  type: TYPE_NORMAL
- en: Extracting data from web pages using CSS selectors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In R, the easiest-to-use package for web scraping is `rvest`. Run the following
    code to install the package from CRAN:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'First, we load the package and use `read_html()` to read `data/single-table.html`
    and try to extract the table from the web page:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Note that `single_table_page` is a parsed HTML document, which is a nested data
    structure of HTML nodes.
  prefs: []
  type: TYPE_NORMAL
- en: 'A typical process for scraping information from such a web page using `rvest`
    functions is: First, locate the HTML nodes from which we need to extract data.
    Then, use either the CSS selector or XPath expression to filter the HTML nodes
    so that the nodes we need are selected and those we don''t need are omitted. Finally,
    use proper selectors with `html_nodes()` to take a subset of nodes, `html_attrs()`
    to extract attributes, and `html_text()` to extract text from the parsed web page.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The package also provides simple functions that directly extract data from
    a web page and return a data frame. For example, to extract all `<table>` elements
    from it, we directly call `html_table()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'To extract the first `<table>` element, we use `html_node()` to select the
    first node with the CSS selector `table` and then use `html_table()` with the
    node to get a data frame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'A more natural way to do this is to use pipelines, just like using `%>%` with
    `dplyr` functions introduced in [Chapter 12](ch12.html "Chapter 12. Data Manipulation"),
    *Data Manipulation*. Recall that `%>%` basically evaluates `x %>% f(...)` as `f(x,
    ...)` so that a nested call can be unnested and become much more readable. The
    preceding code can be rewritten as the following using `%>%`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we read `data/products.html` and use `html_nodes()` to match the `<span
    class="name">` nodes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Note that the nodes we want to select are of the `name` class in `<li>` nodes
    of a node of the `product-list` class, therefore we can use `.product-list li.name`
    to select all such nodes. Go through the CSS table if you feel you are not familiar
    with the notation.
  prefs: []
  type: TYPE_NORMAL
- en: 'To extract the contents from the selected nodes, we use `html_text()`, which
    returns a character vector:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Similarly, the following code extracts the product prices:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code, `html_nodes()` returns a collection of HTML nodes while
    `html_text()` is smart enough to extract the inner text from each HTML node and
    returns a character vector.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that these prices are still in their raw format represented by a string
    rather than number. The following code extracts the same data and transforms it
    into a more useful form:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Note that the intermediate results of selected nodes can be stored as a variable
    and used repeatedly. Then the subsequent `html_nodes()` and `html_node()` calls
    only match the inner nodes.
  prefs: []
  type: TYPE_NORMAL
- en: Since product prices should be numeric values, we use `gsub()` to remove `$`
    from the raw prices and convert the results to a numeric vector. The call of `gsub()`
    in the pipeline is somehow special because the previous result (represented by
    `.`) should be put to the third argument instead of the first one.
  prefs: []
  type: TYPE_NORMAL
- en: In this case, `.product-list li .name` can be reduced to `.name` and the same
    also applies to `.product-list li .price`. In practice, however, a CSS class may
    be used extensively and such a general selector may match too many elements that
    are not desired. Therefore, it is better to use a more descriptive and sufficiently
    strict selector to match the interested nodes.
  prefs: []
  type: TYPE_NORMAL
- en: Learning XPath selectors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous section, we learned about CSS selectors and how to use them
    as well as functions provided by the `rvest` package to extract contents from
    web pages.
  prefs: []
  type: TYPE_NORMAL
- en: CSS selectors are powerful enough to serve most needs of HTML node matching.
    However, sometimes an even more powerful technique is required to select nodes
    that meet more special conditions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Take a look at the following web page a bit more complex than `data/products.html`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Learning XPath selectors](img/image_14_005.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'This web page is stored as a standalone HTML file at `data/new-products.html`.
    The full source code is long we will only show the `<body>`. here. Please go through
    the source code to get an impression of its structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The source code of the web page contains a stylesheet and a product list of
    detailed information. Each product has a description and more properties to show.
    In the following code, we load the web page as we did in the previous examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The structure of the HTML code is simple and clear. Before digging into XPath,
    we need to know a little about XML. Well-written and well-organized HTML documents
    can be basically regarded as a specialization of **XML** (**eXtensive Markup Language**)
    documents. Different from HTML, XML allows arbitrary tags and attributes. The
    following is a simple XML document:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: XPath is a technique designed for extracting data from XML documents. In this
    section, we compare XPath expressions with CSS selectors and see how they can
    be useful to extract data from web pages.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `html_node()` and `html_nodes()` support XPath expressions via the `xpath=`
    argument. The following table shows some important comparisons between CSS selectors
    and equivalent XPath expressions:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **CSS** | **XPath** | **Match** |'
  prefs: []
  type: TYPE_TB
- en: '| `li > *` | `//li/*` | All children of `<li>` |'
  prefs: []
  type: TYPE_TB
- en: '| `li[attr]` | `//li[@attr]` | All `<li>` with `attr` attribute |'
  prefs: []
  type: TYPE_TB
- en: '| `li[attr=value]` | `//li[@attr=''value'']` | `<li attr="value">` |'
  prefs: []
  type: TYPE_TB
- en: '| `li#item` | `//li[@id=''item'']` | `<li id="item">` |'
  prefs: []
  type: TYPE_TB
- en: '| `li.info` | `//li[contains(@class,''info'')]` | `<li class="info">` |'
  prefs: []
  type: TYPE_TB
- en: '| `li:first-child` | `//li[1]` | First `<li>` |'
  prefs: []
  type: TYPE_TB
- en: '| `li:last-child` | `//li[last()]` | Last `<li>` |'
  prefs: []
  type: TYPE_TB
- en: '| `li:nth-child(n)` | `//li[n]` | `n` ^(th)`<li>` |'
  prefs: []
  type: TYPE_TB
- en: '| (N/A) | `//p[a]` | All `<p>` with a child `<a>` |'
  prefs: []
  type: TYPE_TB
- en: '| (N/A) | `//p[position() <= 5]` | The first five `<p>` nodes |'
  prefs: []
  type: TYPE_TB
- en: '| (N/A) | `//p[last()-2]` | The last third last `<p>` |'
  prefs: []
  type: TYPE_TB
- en: '| (N/A) | `//li[value>0.5]` | All `<li>` with child `<value>` whose value `>
    0.5` |'
  prefs: []
  type: TYPE_TB
- en: Note that CSS selectors usually match nodes at all sub-levels. In XPath, `//` tag
    and `/` tag are defined to match nodes differently. More specifically, `//` tag
    refers to `<tag>` nodes at all sub-levels while `/` tag only refers to `<tag>`
    nodes at the first sub-level.
  prefs: []
  type: TYPE_NORMAL
- en: 'To demonstrate the usage, the following are some examples:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Select all `<p>` nodes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Select all `<li>` with the `class` attribute:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Select all `<li>` as children of `<div id="list"><ul>`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Select all `<span class="name">` as children of `<li>` inside `<div id="list">`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Select all `<span class="name">` as children in `<li class="selected">`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: All the preceding examples can be achieved with equivalent CSS selectors. The
    following examples, however, are not possible with CSS selectors.
  prefs: []
  type: TYPE_NORMAL
- en: 'Select all `<div>` with a child `<p>`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Select all `<span class="info-value">Good</span>`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Select all product names with good quality:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Select all product names with a duration greater than three years:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: XPath is very flexible and can be a powerful tool to match nodes in web pages.
    To learn more, visit [http://www.w3schools.com/xsl/xpath_syntax.aspac](http://www.w3schools.com/xsl/xpath_syntax.aspac).
  prefs: []
  type: TYPE_NORMAL
- en: Analysing HTML code and extracting data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous sections, we learned the basics of HTML, CSS, and XPath. To
    scrape real-world web pages, the problem now becomesa question of writing the
    proper CSS or XPath selectors. In this section, we introduce some simple ways
    to figure out working selectors.
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose we want to scrape all available R packages at [https://cran.rstudio.com/web/packages/available_packages_by_name.html](https://cran.rstudio.com/web/packages/available_packages_by_name.html).
    The web page looks simple. To figure out the selector expression, right-click
    on the table and select **Inspect Element** in the context menu, which should
    be available in most modern web browsers:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Analysing HTML code and extracting data](img/image_14_006.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Then the inspector panel shows up and we can see the underlying HTML of the
    web page. In Firefox and Chrome, the selected node is highlighted so it can be
    located more easily:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Analysing HTML code and extracting data](img/image_14_007.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The HTML contains a unique `<table>` so we can directly use `table` to select
    it and use `html_table()` to extract it out as a data frame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that the original table has no headers. The resulted data frame uses default
    headers instead and the first row is empty. The following code is written to fix
    these problems:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'The next example is to extract the latest stock price of MSFT at [http://finance.yahoo.com/quote/MSFT](http://finance.yahoo.com/quote/MSFT).
    Using the element inspector, we find that the price is contained by a `<span>`
    with very long classes that are generated by the program:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Analysing HTML code and extracting data](img/image_14_008.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Looking several levels up, we can find a path, `div#quote-header-info > section
    > span`, to navigate to this very node. Therefore, we can use this CSS selector
    to find and extract the stock price:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'On the right side of the web page, there is a table of corporate key statistics:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Analysing HTML code and extracting data](img/image_14_009.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Before extracting it out, we again inspect the table and its enclosing nodes,
    and try to find a selector that navigates to this table:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Analysing HTML code and extracting data](img/image_14_010.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'It is obvious that the `<table>` of interest is enclosed by a `<div id="key-statistics"`.
    Thus we can directly use `#key-statistics table` to match the table node and turn
    it into a data frame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'With similar techniques, we can create a function that returns the company
    name and price given a stock ticker symbol (for example, `MSFT`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'The CSS selectors are restrictive enough to navigate to the right HTML nodes.
    To test this function, we run the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Another example is scraping top R questions at [http://stackoverflow.com/questions/tagged/r?sort=votes](http://stackoverflow.com/questions/tagged/r?sort=votes),
    shown as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Analysing HTML code and extracting data](img/image_14_011.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'With a similar method, it is easy to find out that the question list is contained
    by a container whose `id` is `questions`. Therefore, we can load the page and
    select and store the question container with `#questions`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'To extract the question titles, we take a closer look at the HTML structure
    behind the first question:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Analysing HTML code and extracting data](img/image_14_012.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'It is easy to find out that each question title is contained in `<div class="summary"><h3>`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that `<a class="question-hyperlink">` also provides an even easier CSS
    selector that returns the same results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'If we are also interested in the votes of each question, we can again inspect
    the votes and see how they can be described with a CSS selector:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Analysing HTML code and extracting data](img/image_14_013.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Fortunately, all vote panels share the same structure and it is quite straightforward
    to find out their pattern. Each question is contained in a `<div>` with the `question-summary`
    class in which the vote is in a `<span>` with the `.vote-count-post` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Similarly, the following code extracts the number of answers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: If we go ahead with extracting the tags of each question, it becomes a bit tricky
    because different questions may have different numbers of tags. In the following
    code, we first select the tag containers of all questions and extract the tags
    in each container by iteration.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'All the preceding scraping happens in one web page. What if we need to collect
    data across multiple web pages? Suppose we visit the page of each question (for
    example, [http://stackoverflow.com/q/5963269/2906900](http://stackoverflow.com/q/5963269/2906900)).
    Notice that there is an info box on the up-right. We need to extract such info
    boxes of each question in list:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Analysing HTML code and extracting data](img/image_14_014.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Inspecting tells us `#qinfo` is the key of the info box on each question page.
    Then we can select all question hyperlinks, extract the URLs of all questions,
    iterate over them, read each question page, and extract the info box using that
    key:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: Besides all these, `rvest` also supports creating an HTTP session to simulate
    page navigation. To learn more, read the `rvest` documentation. For many scraping
    tasks, you can also simplify the finding of selectors by using the tools provided
    by [http://selectorgadget.com/](http://selectorgadget.com/).
  prefs: []
  type: TYPE_NORMAL
- en: There are more advanced techniques of web scraping such as dealing with AJAX
    and dynamic web pages using JavaScript, but they are beyond the scope of this
    chapter. For more usage, read the documentation for the `rvest` package.
  prefs: []
  type: TYPE_NORMAL
- en: Note that `rvest` is largely inspired by Python packages Robobrowser and BeautifulSoup.
    These packages are more powerful and thus popular in web scraping in some aspects
    than `rvest`. If the source is complex and large in scale, you might do well to
    learn to use these Python packages. Go to [https://www.crummy.com/software/BeautifulSoup/](https://www.crummy.com/software/BeautifulSoup/)
    for more information.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned how web pages are written in HTML and stylized by
    CSS. CSS selectors can be used to match HTML nodes so that their contents can
    be extracted. Well-written HTML documents can also be queried by XPath Expression,
    which has more features and is more flexible. Then we learned how to use the element
    inspector in modern web browsers to figure out a restrictive selector to match
    the HTML nodes of interest so that the needed data can be extracted from web pages.
  prefs: []
  type: TYPE_NORMAL
- en: In this next chapter, we will learn a series of techniques that boost your productivity,
    from R Markdown documents, diagrams, to interactive shiny apps. These tools make
    it much easier to create quality, reproducible, and interactive documents, which
    are very nice ways to present data, ideas, and prototypes.
  prefs: []
  type: TYPE_NORMAL
