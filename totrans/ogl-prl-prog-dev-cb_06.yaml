- en: Chapter 6. Developing a Sobel Edge Detection Filter
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第6章：开发Sobel边缘检测滤波器
- en: 'In this chapter, we''ll cover the following recipes:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍以下食谱：
- en: Understanding the convolution Theory
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解卷积理论
- en: Understanding convolution in 1D
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解一维卷积
- en: Understanding convolution in 2D
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解二维卷积
- en: OpenCL implementation of the Sobel edge filter
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenCL中Sobel边缘滤波器的实现
- en: Understanding profiling in OpenCL
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解OpenCL中的性能分析
- en: Introduction
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简介
- en: In this chapter, we are going to take a look at how to develop a popular image
    processing algorithm known as edge detection. This problem happens to be a part
    of solving a more general problem in image segmentation.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨如何开发一个流行的图像处理算法，即边缘检测。这个问题恰好是解决图像分割中更一般问题的部分。
- en: Note
  id: totrans-9
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Image segmentation is the process of partitioning a digital image into multiple
    segments (sets of pixels, also known as super pixels). The goal of segmentation
    is to simplify and/or change the representation of an image into something that
    is more meaningful and easier to analyze. Image segmentation is typically used
    to locate objects and boundaries (lines, curves, and so on) in images.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 图像分割是将数字图像分割成多个段（像素集，也称为超像素）的过程。分割的目标是简化图像的表示，或将其转换为更有意义且更容易分析的形式。图像分割通常用于在图像中定位对象和边界（线条、曲线等）。
- en: The Sobel operator is a discrete differentiation operator, computing an approximation
    of the gradient of the image density function. The Sobel operator is based on
    convolving the image with a small, separable, and an integer-value filter in both
    horizontal and vertical directions. Thus, it is relatively inexpensive in terms
    of computations.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Sobel算子是一个离散微分算子，用于计算图像密度函数梯度的近似值。Sobel算子基于在水平和垂直方向上使用一个小型、可分离且具有整数值的滤波器对图像进行卷积。因此，在计算方面相对较为经济。
- en: Don't worry if you don't understand these notations right away, we are going
    to step through enough theory and math, and help you realize the application in
    OpenCL.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您一开始不理解这些符号，请不要担心，我们将逐步介绍足够的理论和数学知识，并帮助您理解在OpenCL中的应用。
- en: Briefly, the Sobel filtering is a three-step process. Two 3 x 3 filters are
    applied separately and independently on every pixel and the idea is to use these
    two filters to approximate the derivatives of x and y, respectively. Using the
    results of these filters, we can finally approximate the magnitude of the gradient.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，Sobel滤波是一个三步过程。两个3x3的滤波器分别独立地应用于每个像素，其目的是使用这两个滤波器分别近似x和y的导数。使用这些滤波器的结果，我们最终可以近似梯度的幅度。
- en: The gradient computed by running Sobel's edge detector through each pixel (which
    also uses its neighboring eight pixels) will inform us whether there are changes
    in the vertical and horizontal axes (where the neighboring pixels reside).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在每个像素（以及其相邻的八个像素）上运行Sobel边缘检测器计算出的梯度将告诉我们垂直和水平轴（相邻像素所在的位置）是否存在变化。
- en: For those who are already familiar with the convolution theory, in general,
    may skip to the *How to do it* section of this recipe.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 对于已经熟悉卷积理论的人来说，一般可以跳过本食谱的*如何操作*部分。
- en: Understanding the convolution theory
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解卷积理论
- en: In the past, mathematicians developed calculus so that there's a systematic
    way to reason about how things change, and the convolution theory is really about
    measuring how these changes affect one another. At that time, the convolution
    integral was born.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去，数学家们发展了微积分，以便有一个系统的方法来推理事物变化的方式，而卷积理论实际上就是关于测量这些变化如何相互影响。那时，卷积积分应运而生。
- en: '![Understanding the convolution theory](img/4520OT_06_24.jpg)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![理解卷积理论](img/4520OT_06_24.jpg)'
- en: And the ![Understanding the convolution theory](img/4520OT_06_23.jpg) operator
    is the convolution operator used in conventional math. An astute reader will notice
    immediately that we have replaced one function with the other, and the reason
    why this is done is because of the fact that the convolution operator is commutative,
    that is, the order of computation does not matter. The computation of the integral
    can be done in discrete form, and without loss of generality, we can replace the
    integral sign ![Understanding the convolution theory](img/4520OT_06_22.jpg) with
    the summation sign ![Understanding the convolution theory](img/4520OT_06_21.jpg),
    and with that, let's see the mathematical definition of convolution in discrete
    time domain.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Later we will walk through what the following equation tells us over a discrete
    time domain:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: '![Getting ready](img/4520OT_06_20.jpg)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
- en: where *x[n]* is an input signal, *h[n]* is an impulse response, and *y[n]* is
    the output. The asterisk (***) denotes convolution. Notice that we multiply the
    terms of *x[k]* by the terms of a time-shifted *h[n]* and add them up. The key
    to understanding convolution lies behind impulse response and impulse decomposition.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In order to understand the meaning of convolution, we are going to start from
    the concept of signal decomposition. The input signal can be broken down into
    additive components, and the system response of the input signal results in by
    adding the output of these components passed through the system.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: The following section will illustrate on how convolution works in 1D, and once
    you're proficient in that, we will build on that concept and illustrate how in
    convolution works 2D and we'll see the Sobel edge detector in action!
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: Understanding convolution in 1D
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's imagine that a burst of energy (signal) have arrived into our system and
    it looks similar to the following diagram with *x[n] = {1,3,4,2,1}, for n = 0,1,2,3,4*.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: '![Understanding convolution in 1D](img/4520OT_06_01.jpg)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
- en: And let's assume that our impulse function has a non-zero value whenever **n**
    = **0** or **1**, while it'll have a zero value for all other values of **n**.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Using the preceding information, let''s work out what the output signal would
    be by quickly recalling the following equation:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it...](img/4520OT_06_19.jpg)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
- en: 'Following this equation faithfully, we realize that the output signal is amplified
    initially and quickly tapers off, and after solving this manually (yes, I mean
    evaluating the equation on a pencil and paper) we would see the following final
    output signal:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it...](img/4520OT_06_18.jpg)![How to do it...](img/4520OT_06_02.jpg)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
- en: How it works…
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Looking at the preceding equation again, this time we rearrange them and remove
    all terms that evaluate to zero. Let''s try to see whether we can discover a pattern:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works…](img/4520OT_06_17.jpg)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
- en: 'And I believe you can see that each output value is computed from its previous
    two output values (taking into account the impulse function)! And now we may conclude,
    quite comfortably, that the general formula for computing the convolution in 1D
    is in fact the following:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works…](img/4520OT_06_16.jpg)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
- en: Finally, you should be aware that (by convention) any value that is not defined
    for any *x[i-k]* is automatically given the value zero. This seemingly small,
    subtle fact will play a role in our eventual understanding of the Sobel edge detection
    filter which we'll describe next.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally for this section, let''s take a look at how a sequential convolution
    code in 1D might look like:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Examining the code again, you will probably notice that we are iterating over
    the 1D array and the most interesting code would be in `statement 1`, as this
    is where the action really lies. Let's put that new knowledge aside and move on
    to extending this to a 2D space.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: Understanding convolution in 2D
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Convolution in 2D is actually an extension of the previously described *Understanding
    convolution in 1D* section, and we do so by computing the convolution in two dimensions.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The impulse function also exists in a 2D spatial domain, so let's call this
    function. *b[x,y]* has the value 1, where x and y are zero, and zero where x,y¹0\.
    The impulse function is also referred to as filter or kernel when it's being used
    in image processing.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Using the previous example as a guide, let's start thinking from the perspective
    of a signal which can be decomposed into the sum of its components and impulse
    functions, and their double summation accounts to the fact that this runs over
    both vertical and horizontal axes in our 2D space.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it…](img/4520OT_06_15.jpg)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
- en: Next, I think it's very helpful if we use an example to illustrate how it works
    when we have two convolution kernels to represent the filters we like to apply
    on the elements in a 2D array. Let's give them names, **Sx** and **Sy**. The next
    thing is to try out how the equation would develop itself in a 2D setting, where
    the element we want to convolve is at *x[1,1]* and we make a note of its surrounding
    eight elements and then see what happens.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: If you think about why we are choosing the surrounding eight elements, it's
    the only way we can measure how big a change is with respect to every other element.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it…](img/4520OT_06_14.jpg)![How to do it…](img/4520OT_06_03.jpg)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
- en: 'Let''s give it a go:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it…](img/4520OT_06_13.jpg)![How to do it…](img/4520OT_06_12.jpg)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
- en: This results in the summation of nine elements (including the element we're
    interested in), and this process is repeated for all elements in the 2D array.
    The following diagram illustrates how convolution in 2D works in a 2D space.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You may wish to read Irwin Sobel's 1964 original doctoral thesis since he's
    the inventor, and this author had a good fortune of meeting the man himself.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: What happens when you attempt to convolve around the elements that border the
    2D array or in image processing, are they referred to as edge pixels? If you use
    this formula for computation, you will notice that the results will be inaccurate,
    because those elements are undefined and hence they're in general discounted from
    the final computation. In general, you can imagine a 3 x 3 filtering operation
    being applied to each element of the 2D array and all such computations will result
    in a new value for that element in the output data array.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: Next, you may wonder what is being done to this output array? Remember that
    this array now contains values, which basically shows how big is the change detected
    in a particular element is. And when you obtain a bunch of them in the vicinity,
    then it usually tells you major color changes, that is, edges.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it…](img/4520OT_06_04.jpg)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
- en: How it works…
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With this understanding, you can probably begin to appreciate why we took this
    effort to illustrate the theory behind a concept.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: When you want to build non-trivial OpenCL applications for your customers, one
    of the things you have to deal with is learning how to interpret a problem and
    convert it to a solution. And what that means is mostly about formulating an algorithm
    (or picking existing algorithms to suit your case) and verifying that it works.
    Most of the problems you're likely to encounter are going to involve some sort
    of mathematical understanding and your ability to learn about it. You should treat
    this as an adventure!
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we''ve armed ourselves with what convolution is in a 2D space, Let''s
    begin by taking a look at how convolution in 2D would work in regular C/C++ code
    with the following snippet:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This implementation is probably the most direct for the purpose of understanding
    the concept, although it may not be the fastest (since it's not many-core aware).
    But it works, as there are conceptually two major loops where the two outer `fo`r
    loops are for iterating over the entire 2D array space, while the two inner `for`
    loops are for iterating the filter/kernel over the element, that is, convoluting
    and storing the final value into an appropriate output array.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: Putting on our parallel algorithm developer hat now, we discover that `statement
    1` appears to be a nice target for work items to execute over. Next, let's take
    a look at how we can take what we've learnt and build the same program in OpenCL.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: OpenCL implementation of the Sobel edge filter
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that you've been armed with how convolution actually works, you should be
    able to imagine how our algorithm might look like. Briefly, we will read an input
    image assuming that it's going to be in the Windows BMP format.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Next we'll construct the necessary data structures for transporting this image
    file in the OpenCL device for convolution, and once that's done we'll read and
    write the data out to another image file, so that we can compare the two.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Optionally, you can choose to implement this using the `clCreateImage(...)`
    APIs provided by OpenCL, and we'll leave it as an exercise for the reader to make
    the attempt.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: In the following sections, you will be shown with an implementation from what
    is translated, what we have learnt so far. It won't be the most efficient algorithm,
    and that's really not our intention here. Rather, we want to show you how you
    can get this done quickly and we'll let you inject those optimizations which include
    the not withstanding, following data binning, data tiling, shared memory optimization,
    warp / wavefront-level programming, implementing 2D-convolution using fast fourier
    transformations, and so many other features.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  id: totrans-77
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A possible avenue from where I derived a lot of the latest techniques about
    solving convolution was by reading academic research papers published by AMD and
    NVIDIA, and also by visiting [gpgpu.org](http://gpgpu.org), [developer.amd.com](http://developer.amd.com),
    [developer.nvidia.com](http://developer.nvidia.com), and [developer.intel.com](http://developer.intel.com).
    Another good resource I can think of are books on image processing and computer
    vision from your favorite local bookstores. Also, books on processor and memory
    structure released by Intel are also good resources if you like.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We only show the code for the kernel found in `Ch6/sobelfilter/sobel_detector.cl`,
    since this is where our algorithm translation will reach its Xenith. And we''ve
    not shown the host code in `Ch6/sobelfilter/SobelFilter.c`, since we believe that
    you would be confident to know what typically resides in there:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'An astute reader will probably figure out by reading the code, that the derived
    values for `Gx` and `Gy` should have been as follows:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: But since we know their values will be zero, there is no need for us to include
    the computation inside it. Although we did, it's really a minor optimization.
    It shaved off some GPU processing cycles!
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: 'As before, the compilation steps are similar to that in `Ch6/sobelfilter/SobelFilter.c`
    with the following command:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: To execute the program, simply execute the executable file (`SobelFilter`) on
    the `Ch6/sobelfilter` directory, and an output image file named `OutputImage.bmp`
    would be presented (it's the output of reading in `InputImage.bmp` and conducting
    the convolution process against it).
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: The net effect is that the output contains an image that outlines the edges
    of the original input image, and you can even refer to the picture images in the
    *How it works…* section of this recipe to see how these two images are different
    from one another.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: How it works…
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: At first, we create a representation of a pixel to represent each of the channels
    in the RGBA fashion. That structure is given a simple name, `uchar4`, where it
    consists of four unsigned char data types which will correctly represent each
    color's range from [0..255] or [0x00..0xFF], since that's how each color's range
    is defined by convention.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: We omit the description of the mechanism behind pulling the pixel information
    from the input image to how we construct the final in-memory representation of
    the image. Interested readers can search on the Internet regarding the Windows
    BMP format to understand how we parse the image data or read the source code in
    the `bmp.h` file via the `load` function, and we write out the image using the
    `write` function.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: Skipping the OpenCL device memory allocation, since that by now is standard
    fare we arrived quickly at the portion where we look at how the kernel processes
    each pixel of the input data.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we do that, let''s quickly recall from the kernel launching code how
    many global work-items have been assigned and whether the work-group composition
    is like:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '`localThreads` is configured to have work-groups of sizes {256,1}, work-items
    processing a portion of the input 2D image data array.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: When the image is loaded into the device memory, the image is processed in blocks.
    Each block has a number of work-items or threads if you process the image. Each
    work-item proceeds the next to perform the convolution process on the center of
    the pixel and also on its eight neighbors. The resultant value generated by each
    work-item will be outputed as pixel value into the device memory. Pictorially,
    the following diagram illustrates what a typical work-item will perform.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You need to watch out and that is we actually used the data type conversion
    function, `convert_float4` to apply our unsigned char data values encapsulated
    within each pixel, which effectively widens the data type so that it doesn't overflow
    when the Sobel operator is applied on them.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: Finally, once we have the masked the values we need to compute the magnitude
    of this gradient and the standard way of computing that is to apply ![How it works…](img/4520OT_06_12a.jpg)
    where **Gx** = ![How it works…](img/4520OT_06_11.jpg) and **Gy** = ![How it works…](img/4520OT_06_10.jpg).
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works…](img/4520OT_06_05.jpg)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
- en: Whether this algorithm works, the only way is to check it through an image.
    The following is the side-by-side comparison, where the first image is before
    the Sobel operator is applied and the second one is after it's being applied.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works…](img/4520OT_06_06.jpg)![How it works…](img/4520OT_06_07.jpg)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
- en: However, there is another nice optimization which we could have done, and it
    would have helped if we understood that a 3 X 3 convolution kernel (for example,
    the Sobel operator) is actually equivalent to the product of two vectors. This
    realization is behind the optimization algorithm also known as separable convolution.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: Technically, a two-dimensional filter is considered to be separable if it can
    be expressed as an outer product of two vectors. Considering the Sobel operator
    here, we can actually write ![How it works…](img/4520OT_06_08.jpg) and ![How it
    works…](img/4520OT_06_09.jpg).
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  id: totrans-105
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The superscript T is the transpose of a row vector, which is equivalent to the
    column-vector and vice versa. Note that convolution is itself associative, so
    it doesn't really matter in which way you multiply the vectors against the input
    image matrix.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: Why is this important? The main reason is because we actually save processing
    cycles by using this separable convolution kernel. Let's imagine we have a X-by-Y
    image and a convolution kernel of M-by-N. Using the original method, we would
    have conducted XYMN multiples and adds while using the separable convolution technique,
    we would have actually done XY (M + N) multiples and adds. Theoretically speaking,
    applying this to our 3-by-3 convolution kernel we would have increased our performance
    to 50 percent or 1.5 times and when we use a 9-by-9 convolution kernel, we would
    have increased our performance to 81 / 18 = 4.5 or 450 percent.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: Next, we are going to talk about how you can profile your algorithms and their
    runtimes so that you can make your algorithms not only run faster, but also deepen
    your understanding of how the algorithm works and more often than not, help the
    developer develop a better intuition on how to make better use of the OpenCL device's
    capabilities.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: Understanding profiling in OpenCL
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Profiling is a relatively simple operation from the perspective of an OpenCL
    developer, since it basically means that he/she wishes to measure how long a particular
    operation took. This is important because during any software development, users
    of the system would often specify the latencies which are considered acceptable,
    and as you develop bigger and more complex systems, profiling the application
    becomes important in helping you understand the bottlenecks of the application.
    The profiling we are going to take is a look done programmatically by the developer
    to explicitly measure the pockets of code. Of course, there is another class of
    profilers which profiles your OpenCL operations on a deeper level with various
    breakdowns on the running times measured and displayed, but that is out of the
    scope of the book. But we encourage readers to download the profilers from AMD
    and Intel to check them out.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'While writing this book, AMD has made its OpenCL profiler and a generally available
    debugger named CodeXL found at [http://developer.amd.com/tools-and-sdks/heterogeneous-computing/codexl/](http://developer.amd.com/tools-and-sdks/heterogeneous-computing/codexl/).
    Intel has a similar package offered separately and you can refer to the following
    URL for more details:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: '[http://software.intel.com/en-us/vcsource/tools/opencl-sdk-2013](http://software.intel.com/en-us/vcsource/tools/opencl-sdk-2013).
    As for NVIDIA GPGPUs, you can only use the APIs provided by OpenCL.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The two operations that OpenCL allows the developer to have such insight into
    their runtimes are data transfer operations and kernel execution operations; the
    times are all measured in nanoseconds.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-116
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Since all devices cannot resolve to a nanosecond, it's important to determine
    what is the level of resolution, and you can know this by passing the `CL_DEVICE_PROFILING_TIMER_RESOLUTION`
    flag to `clGetDeviceInfo` for the appropriate device ID.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 由于所有设备都无法解析到纳秒级别，因此确定分辨率级别非常重要，你可以通过将`CL_DEVICE_PROFILING_TIMER_RESOLUTION`标志传递给`clGetDeviceInfo`以获取适当的设备ID来了解这一点。
- en: How to do it…
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到这一点…
- en: 'All you have to do is to pass the `CL_QUEUE_PROFILING_ENABLE` flag as part
    of the `properties` argument, when you create the command queue via `clCreateCommandQueue`.
    The API looks like this:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 你所需要做的就是将`CL_QUEUE_PROFILING_ENABLE`标志作为`properties`参数的一部分，在通过`clCreateCommandQueue`创建命令队列时传递。API看起来是这样的：
- en: '[PRE6]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Once the profiling is enabled, the next thing you need to do is to inject OpenCL
    events into areas of the code, where you want to know how the runtimes fare. To
    achieve this, you need to create a `cl_event` variable for the regions of code
    you wish to monitor and associate this variable with one of the following APIs:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦启用分析，接下来你需要做的是将OpenCL事件注入到代码的特定区域，你想要了解运行时间如何。为了实现这一点，你需要为你要监控的代码区域创建一个`cl_event`变量，并将此变量与以下API之一关联：
- en: 'Data transfer operations:'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据传输操作：
- en: '`clEnqueue{Read|Write|Map}Buffer`'
  id: totrans-123
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clEnqueue{Read|Write|Map}Buffer`'
- en: '`clEnqueue{Read|Write|Map}BufferRect`'
  id: totrans-124
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clEnqueue{Read|Write|Map}BufferRect`'
- en: '`clEnqueue{Read|Write|Map}Image`'
  id: totrans-125
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clEnqueue{Read|Write|Map}Image`'
- en: '`clEnqueueUnmapMemObject`'
  id: totrans-126
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clEnqueueUnmapMemObject`'
- en: '`clEnqueuCopyBuffer`'
  id: totrans-127
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clEnqueuCopyBuffer`'
- en: '`clEnqueueCopyBufferRect`'
  id: totrans-128
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clEnqueueCopyBufferRect`'
- en: '`clEnqueueCopyImage`'
  id: totrans-129
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clEnqueueCopyImage`'
- en: '`clEnqueueCopyImageToBuffer`'
  id: totrans-130
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clEnqueueCopyImageToBuffer`'
- en: '`clEnqueueCopyBufferToImage`'
  id: totrans-131
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clEnqueueCopyBufferToImage`'
- en: 'Kernel operations:'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内核操作：
- en: '`clEnqueueNDRangeKernel`'
  id: totrans-133
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clEnqueueNDRangeKernel`'
- en: '`clEnqueueTask`'
  id: totrans-134
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clEnqueueTask`'
- en: '`clEnqueueNativeTask`'
  id: totrans-135
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clEnqueueNativeTask`'
- en: How it works…
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: 'The way to obtain the runtimes for these operations is to invoke the `clGetEventProfilingInfo`
    API, passing in one of these flags: `CL_PROFILING_COMMAND_QUEUED`, `CL_PROFILING_COMMAND_SUBMIT`,
    `CL_PROFILING_COMMAND_START`, or `CL_PROFILING_COMMAND_END`. The API looks like
    this:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 获取这些操作的运行时间的方法是调用`clGetEventProfilingInfo` API，传递以下标志之一：`CL_PROFILING_COMMAND_QUEUED`、`CL_PROFILING_COMMAND_SUBMIT`、`CL_PROFILING_COMMAND_START`或`CL_PROFILING_COMMAND_END`。API看起来是这样的：
- en: '[PRE7]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: To obtain the time spent by the command in the queue, you invoke `clGetEventProfilingInfo`
    with `CL_PROFILING_COMMAND_SUBMIT` once, and at the end of the code region invoke
    `clGetEventProfilingInfo` with `CL_PROFILING_COMMAND_QUEUED` again to get the
    difference in time.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取命令在队列中花费的时间，你只需一次调用`clGetEventProfilingInfo`使用`CL_PROFILING_COMMAND_SUBMIT`，然后在代码区域的末尾再次调用`clGetEventProfilingInfo`使用`CL_PROFILING_COMMAND_QUEUED`以获取时间差。
- en: To obtain the duration that the command took to execute, invoke `clGetEventProfilingInfo`
    once with `CL_PROFILING_COMMAND_START` and invoke the same API with `CL_PROFILING_COMMAND_END`,
    from the difference in the runtimes you will obtain the value.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取命令执行所花费的时间，一次调用`clGetEventProfilingInfo`使用`CL_PROFILING_COMMAND_START`，然后使用相同的API调用`CL_PROFILING_COMMAND_END`，从运行时间的差异中你会得到值。
- en: 'The following is a small code snippet which illustrates the basic mechanism:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个小代码片段，说明了基本机制：
- en: '[PRE8]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
