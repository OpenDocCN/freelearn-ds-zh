<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Working with Vector Data – The Basics</h1>
                </header>
            
            <article>
                
<p>In this chapter, we will cover the following recipes:</p>
<ul>
<li>Working with GPS data</li>
<li>Fixing invalid geometries</li>
<li>GIS analysis with spatial joins</li>
<li>Simplifying geometries</li>
<li>Measuring distances</li>
<li>Merging polygons using a common attribute</li>
<li>Computing intersections</li>
<li>Clipping geometries to deploy data</li>
<li>Simplifying geometries with PostGIS topology</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Introduction</h1>
                </header>
            
            <article>
                
<p>In this chapter, you will work with a set of PostGIS functions and vector datasets. You will first take a look at how to use PostGIS with GPS data—you will import such datasets using <kbd>ogr2ogr</kbd> and then compose polylines from point geometries using the <kbd>ST_MakeLine</kbd> function.</p>
<p>Then, you will see how PostGIS helps you find and fix invalid geometries with functions such as <kbd>ST_MakeValid</kbd>, <kbd>ST_IsValid</kbd>, <kbd>ST_IsValidReason</kbd>, and <kbd>ST_IsValidDetails</kbd>.</p>
<p>You will then learn about one of the most powerful elements of a spatial database, spatial joins. PostGIS provides you with a rich set of operators, such as <kbd>ST_Intersects</kbd>, <kbd>ST_Contains</kbd>, <kbd>ST_Covers</kbd>, <kbd>ST_Crosses</kbd>, and <kbd>ST_DWithin</kbd>, for this purpose.</p>
<p>After that, you will use the <kbd>ST_Simplify</kbd> and <kbd>ST_SimplifyPreverveTopology</kbd> functions to simplify (generalize) geometries when you don't need too many details. While this function works well on linear geometries, topological anomalies may be introduced for polygonal ones. In such cases, you should consider using an external GIS tool such as <kbd>GRASS</kbd>.</p>
<p>You will then have a tour of PostGIS functions to make distance measurements—<kbd>ST_Distance</kbd>, <kbd>ST_DistanceSphere</kbd>, and <kbd>ST_DistanceSpheroid</kbd> are on the way.</p>
<p>One of the recipes explained in this chapter will guide you through the typical GIS workflow to merge polygons based on a common attribute; you will use the <kbd>ST_Union</kbd> function for this purpose.</p>
<p>You will then learn how to clip geometries using the <kbd>ST_Intersection</kbd> function, before deep diving into the <strong>PostGIS topology</strong> in the last recipe that was introduced in version 2.0.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Working with GPS data</h1>
                </header>
            
            <article>
                
<p>In this recipe, you will work with GPS data. This kind of data is typically saved in a <kbd>.gpx</kbd> file. You will import a bunch of <kbd>.gpx</kbd> files to PostGIS from <strong>RunKeeper</strong>, a popular social network for runners.</p>
<p>If you have an account on RunKeeper, you can export your <kbd>.gpx</kbd> files and process them by following the instructions in this recipe. Otherwise, you can use the RunKeeper <kbd>.gpx</kbd> files included in the <kbd>runkeeper-gpx.zip</kbd> file located in the <kbd>chp03</kbd> directory available in the code bundle for this book.</p>
<p>You will first create a <kbd>bash</kbd> script for importing the <kbd>.gpx</kbd> files to a PostGIS table, using <kbd>ogr2ogr</kbd>. After the import is completed, you will try to write a couple of SQL queries and test some very useful functions, such as <kbd>ST_MakeLine</kbd> to generate polylines from point geometries, <kbd>ST_Length</kbd> to compute distance, and <kbd>ST_Intersects</kbd> to perform a spatial join operation.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>Extract the <kbd>data/chp03/runkeeper-gpx.zip</kbd> file to <kbd>working/chp03/runkeeper_gpx</kbd>. In case you haven't been through <a href="38f20dd1-ca55-47e8-80cd-21670bcb32b2.xhtml"><span class="ChapterrefPACKT">Chapter 1</span></a>, <em>Moving Data In and Out of PostGIS</em>, be sure to have the <kbd>countries</kbd> dataset in the PostGIS database.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>First, be sure of the format of the <kbd>.gpx</kbd> files that you need to import to PostGIS. Open one of them and check the file structure—each file must be in the XML format composed of just one <kbd>&lt;trk&gt;</kbd> element, which contains just one <kbd>&lt;trkseg&gt;</kbd> element, which contains many <kbd>&lt;trkpt&gt;</kbd> elements (the points stored from the runner's GPS device). Import these points to a PostGIS <kbd>Point</kbd> table:</p>
<ol>
<li>Create a new schema named <kbd>chp03</kbd> to store the data for all the recipes in this chapter, using the following command:</li>
</ol>
<pre>      <strong>postgis_cookbook=# create schema chp03;</strong></pre>
<ol start="2">
<li>Create the <kbd>chp03.rk_track_points</kbd> table in PostgreSQL by executing the following command lines:</li>
</ol>
<pre><strong>      postgis_cookbook=# CREATE TABLE chp03.rk_track_points 
      ( 
        fid serial NOT NULL, 
        the_geom geometry(Point,4326), 
        ele double precision, 
        "time" timestamp with time zone, 
        CONSTRAINT activities_pk PRIMARY KEY (fid) 
      );</strong> </pre>
<ol start="3">
<li>Create the following script to import all of the <kbd>.gpx</kbd> files in the <kbd>chp03.rk_track_points</kbd> table using the GDAL <kbd>ogr2ogr</kbd> command.</li>
</ol>
<p style="padding-left: 60px"><span class="NumberedBulletWithinBulletPACKTChar">The following is the Linux version (name it</span> <kbd>working/chp03/import_gpx.sh</kbd><span class="NumberedBulletWithinBulletPACKTChar">)</span>:</p>
<pre>        #!/bin/bash 
        for f in `find runkeeper_gpx -name \*.gpx -printf "%f\n"` 
        do 
          echo "Importing gpx file $f to chp03.rk_track_points <br/>                PostGIS table..." #, ${f%.*}" 
          ogr2ogr -append -update  -f PostgreSQL<br/>          PG:"dbname='postgis_cookbook' user='me'<br/>          password='mypassword'" runkeeper_gpx/$f <br/>          -nln chp03.rk_track_points <br/>          -sql "SELECT ele, time FROM track_points" 
        done </pre>
<p style="padding-left: 60px">The following is the command for mac<span class="NumberedBulletWithinBulletPACKTChar">OS (name it</span> <kbd>working/chp03/import_gpx.sh</kbd><span class="NumberedBulletWithinBulletPACKTChar">):</span></p>
<pre>        #!/bin/bash 
        for f in `find runkeeper_gpx -name \*.gpx ` 
        do 
          echo "Importing gpx file $f to chp03.rk_track_points <br/>                PostGIS table..." #, ${f%.*}" 
          ogr2ogr -append -update  -f PostgreSQL<br/>          PG:"dbname='postgis_cookbook' user='me'<br/>          password='mypassword'" $f <br/>          -nln chp03.rk_track_points <br/>          -sql "SELECT ele, time FROM track_points" 
        done </pre>
<p style="padding-left: 60px">The following is the Windows version (name it <kbd>working/chp03/import_gpx.bat</kbd>):</p>
<pre>        @echo off 
        for %%I in (runkeeper_gpx\*.gpx*) do ( 
          echo Importing gpx file %%~nxI to chp03.rk_track_points <br/>               PostGIS table... 
          ogr2ogr -append -update -f PostgreSQL<br/>          PG:"dbname='postgis_cookbook' user='me'<br/>          password='mypassword'" runkeeper_gpx/%%~nxI <br/>          -nln chp03.rk_track_points <br/>          -sql "SELECT ele, time FROM track_points" 
        ) </pre>
<ol start="4">
<li>In Linux and macOS, don't forget to assign execution permission to the script before running it. Then, run the following script:</li>
</ol>
<pre>      <strong>$ chmod 775 import_gpx.sh</strong>
      <strong>$ ./import_gpx.sh</strong>
      <strong>Importing gpx file 2012-02-26-0930.gpx to chp03.rk_track_points <br/>        PostGIS table...</strong>
      <strong>Importing gpx file 2012-02-29-1235.gpx to chp03.rk_track_points <br/>        PostGIS table...</strong>
      <strong>...</strong>
      <strong>Importing gpx file 2011-04-15-1906.gpx to chp03.rk_track_points <br/>        PostGIS table...</strong>
  </pre>
<p style="padding-left: 60px">In Windows, just double-click on the <kbd>.bat</kbd> file or run it from the command prompt using the following command:</p>
<pre>      <strong>&gt; import_gpx.bat</strong></pre>
<ol start="5">
<li>Now, create a polyline table containing a single runner's track details using the <kbd>ST_MakeLine</kbd> function. Assume that on each distinct day, the runner had just one training session. In this table, you should include the start and end times of the track details as follows:</li>
</ol>
<pre><strong>      postgis_cookbook=# SELECT 
      ST_MakeLine(the_geom) AS the_geom, 
      run_date::date, 
      MIN(run_time) as start_time, 
      MAX(run_time) as end_time 
      INTO chp03.tracks 
      FROM ( 
        SELECT the_geom, 
        "time"::date as run_date, 
        "time" as run_time 
        FROM chp03.rk_track_points 
        ORDER BY run_time 
      ) AS foo GROUP BY run_date;</strong> </pre>
<ol start="6">
<li>Before querying the created tables, don't forget to add spatial indexes to both of the tables to improve their performance, as follows:</li>
</ol>
<pre><strong>      postgis_cookbook=# CREATE INDEX rk_track_points_geom_idx <br/>      ON chp03.rk_track_points USING gist(the_geom); 
      postgis_cookbook=# CREATE INDEX tracks_geom_idx <br/>      ON chp03.tracks USING gist(the_geom);</strong></pre>
<ol start="7">
<li>If you try to open both the spatial tables on a desktop GIS on any given day, you should see that the points from the <kbd>rk_track_points</kbd> table compose a single polyline geometry record in the <kbd>tracks</kbd> table, as shown in the following screenshot:
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/75e2ab83-d45c-4356-a7a4-96d40fb6f75f.png" style="width:27.75em;height:19.50em;"/></div>
</li>
<li>If you open all the tracks from a desktop GIS (such as QGIS), you will see the following:</li>
</ol>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/976a2634-7f01-406a-b31f-9ba46e78f269.png" style="width:28.50em;height:20.17em;"/></div>
<ol start="9">
<li class="mce-root">Now, query the <kbd>tracks</kbd> table to get a report of the total distance run (in km) by the runner for each month. For this purpose, use the <kbd>ST_Length</kbd> function, as shown in the following query:</li>
</ol>
<pre><strong>      postgis_cookbook=# SELECT 
        EXTRACT(year FROM run_date) AS run_year, 
        EXTRACT(MONTH FROM run_date) as run_month, 
        SUM(ST_Length(geography(the_geom)))/1000 AS distance <br/>        FROM chp03.tracks 
        GROUP BY run_year, run_month ORDER BY run_year, run_month;</strong> </pre>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/3c37c7e0-6d36-4fba-b9fc-5e3fef87ace9.png" style="width:20.08em;height:19.50em;"/></div>
<pre><strong>      (28 rows) </strong></pre>
<ol start="10">
<li>Using a spatial join between the <kbd>tracks</kbd> and <kbd>countries</kbd> tables, and again using the <kbd>ST_Length</kbd> function as follows, you will get a report of the distance run (in km) by the runner, per country:</li>
</ol>
<pre><strong>      postgis_cookbook=# SELECT 
        c.country_name, 
        SUM(ST_Length(geography(t.the_geom)))/1000 AS run_distance 
      FROM chp03.tracks AS t 
      JOIN chp01.countries AS c 
      ON ST_Intersects(t.the_geom, c.the_geom)</strong></pre>
<pre><strong>      GROUP BY c.country_name 
      ORDER BY run_distance DESC;</strong> </pre>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/397cdfbd-2aee-4418-a918-909e96d7a0ea.png" style="width:16.25em;height:10.25em;"/></div>
<pre><strong>      (4 rows)</strong> </pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>The <kbd>.gpx</kbd> files store all the points' details in the WGS 84 spatial reference system; therefore, we created the <kbd>rk_track_points</kbd> table with SRID (4326).</p>
<p>After creating the <kbd>rk_track_points</kbd> table, we imported all of the <kbd>.gpx</kbd> files in the <kbd>runkeeper_gpx</kbd> directory using a bash script. The bash script iterates all of the files with the extension <kbd>*.gpx</kbd> in the <kbd>runkeeper_gpx</kbd> directory. For each of these files, the script runs the <kbd>ogr2ogr</kbd> command, importing the <kbd>.gpx</kbd> files to PostGIS using the GPX GDAL driver (for more details, go to <a href="http://www.gdal.org/drv_gpx.html"><span class="URLPACKT">http://www.gdal.org/drv_gpx.html</span></a>).</p>
<p>In the GDAL's abstraction, a <kbd>.gpx</kbd> file is an OGR data source composed of several layers as follows:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/630b3479-afb7-4e3e-bcb8-af32f7a96042.png" style="width:27.08em;height:12.42em;"/></div>
<p>In the <kbd>.gpx</kbd> files (OGR data sources), you have just the <kbd>tracks</kbd> and <kbd>track_points</kbd> layers. As a shortcut, you could have imported just the <kbd>tracks</kbd> layer using <kbd>ogr2ogr</kbd>, but you would need to start from the <kbd>track_points</kbd> layer in order to generate the <kbd>tracks</kbd> layer itself, using some PostGIS functions. This is why in the <kbd>ogr2ogr</kbd> section in the bash script, we imported to the <kbd>rk_track_points</kbd> PostGIS table the point geometries from the <kbd>track_points</kbd> layer, plus a couple of useful attributes, such as <kbd>elevation</kbd> and <kbd>timestamp</kbd>.</p>
<p>Once the records were imported, we fed a new polylines table named <kbd>tracks</kbd> using a subquery and selected all of the point geometries and their dates and times from the <kbd>rk_track_points</kbd> table, grouped by date and with the geometries aggregated using the <kbd>ST_MakeLine</kbd> function. This function was able to create linestrings from point geometries (for more details, go to <a href="http://www.postgis.org/docs/ST_MakeLine.html"><span class="URLPACKT">http://www.postgis.org/docs/ST_MakeLine.html</span></a>).</p>
<p>You should not forget to sort the points in the subquery by <kbd>datetime</kbd>; otherwise, you will obtain an irregular linestring, jumping from one point to the other and not following the correct order.</p>
<p>After loading the <kbd>tracks</kbd> table, we tested the two spatial queries.</p>
<p>At first, you got a month-by-month report of the total distance run by the runner. For this purpose, you selected all of the track records grouped by date (year and month), with the total distance obtained by summing up the lengths of the single tracks (obtained with the <kbd>ST_Length</kbd> function). To get the year and the month from the <kbd>run_date</kbd> function, you used the PostgreSQL <kbd>EXTRACT</kbd> function. Be aware that if you measure the distance using geometries in the WGS 84 system, you will obtain it in degree units. For this reason, you have to project the geometries to a planar metric system designed for the specific region from which the data will be projected.</p>
<p>For large-scale areas, such as in our case where we have points that span all around Europe, as shown in the last query results, a good option is to use the <kbd>geography</kbd> data type introduced with PostGIS 1.5. The calculations may be slower, but are much more accurate than in other systems. This is the reason why you cast the geometries to the <kbd>geography</kbd> data type before making measurements.</p>
<p>The last spatial query used a spatial join with the <kbd>ST_Intersects</kbd> function to get the name of the country for each track the runner ran (with the assumption that the runner didn't run cross-border tracks). Getting the total distance run per country is just a matter of aggregating the selection on the <kbd>country_name</kbd> field and aggregating the track distances with the PostgreSQL <kbd>SUM</kbd> operator.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Fixing invalid geometries</h1>
                </header>
            
            <article>
                
<p>You will often find invalid geometries in your PostGIS database. These invalid geometries could compromise the functioning of PostGIS itself and any external tool using it, such as QGIS and MapServer. PostGIS, being compliant with the OGC Simple Feature Specification, must manage and work with valid geometries.</p>
<p>Luckily, PostGIS 2.0 offers you the <kbd>ST_MakeValid</kbd> function, which together with the <kbd>ST_IsValid</kbd>, <kbd>ST_IsValidReason</kbd>, and <kbd>ST_IsValidDetails</kbd> functions, is the ideal toolkit for inspecting and fixing geometries within the database. In this recipe, you will learn how to fix a common case of invalid geometry.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>Unzip the <kbd>data/TM_WORLD_BORDERS-0.3.zip</kbd> file into your working directory, <kbd>working/chp3</kbd>. Import the shapefile in PostGIS with the <kbd>shp2pgsql</kbd> command, as follows:</p>
<pre><strong>$ shp2pgsql -s 4326 -g the_geom -W LATIN1 -I TM_WORLD_BORDERS-0.3.shp chp03.countries &gt; countries.sql</strong>
<strong>$ psql -U me -d postgis_cookbook -f countries.sql</strong></pre>
<div class="packt_tip"><span>The file is also included with the name of <kbd>wborders</kbd> since for some operating systems, it does not work with the characters of <kbd>TM_WORLD_BORDERS-0.3.shp</kbd>.</span></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>The steps you need to perform to complete this recipe are as follows:</p>
<ol start="1">
<li>First, investigate whether or not any geometry is invalid in the imported table. As you can see in the following query, using the <kbd>ST_IsValid</kbd> and <kbd>ST_IsValidReason</kbd> functions, we find four invalid geometries that are all invalid for the same reason—ring self-intersection:</li>
</ol>
<pre><strong>      postgis_cookbook=# SELECT gid, name, ST_IsValidReason(the_geom) 
        FROM chp03.countries 
        WHERE ST_IsValid(the_geom)=false;</strong></pre>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/9d492d78-48dd-4e87-95a7-244ff828e14c.png" style="width:24.67em;height:7.42em;"/></div>
<pre><strong>      (4 rows)</strong> </pre>
<ol start="2">
<li>Now concentrate on just one of the invalid geometries, for example, in the multipolygon geometry representing Russia. Create a table containing just the ring generating the invalidity, selecting the table using the point coordinates given in the <kbd>ST_IsValidReason</kbd> response in the previous step:</li>
</ol>
<pre><strong>      postgis_cookbook=# SELECT * INTO chp03.invalid_geometries FROM ( 
        SELECT 'broken'::varchar(10) as status,</strong><br/><strong>        ST_GeometryN(the_geom, generate_series(<br/>          1, ST_NRings(the_geom)))::geometry(Polygon,4326)<br/>        as the_geom FROM chp03.countries 
        WHERE name = 'Russia') AS foo 
        WHERE ST_Intersects(the_geom, <br/>          ST_SetSRID(ST_Point(143.661926,49.31221), 4326));</strong> </pre>
<p style="padding-left: 60px"><kbd>ST_MakeValid</kbd> requires GEOS 3.3.0 or higher; check whether or not your system supports<span> </span><span>it</span><span> using the</span> <kbd>PostGIS_full_version</kbd> <span>function as follows:</span></p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/12ed12e5-57a6-44a6-831c-e467f4687927.png" style="width:24.92em;height:20.92em;"/></div>
<ol start="3">
<li>Now, using the <kbd>ST_MakeValid</kbd> function, add a new record in the previously created table with the valid version of the same geometry:</li>
</ol>
<pre><strong>      postgis_cookbook=# INSERT INTO chp03.invalid_geometries <br/>      VALUES ('repaired', (SELECT ST_MakeValid(the_geom) 
      FROM chp03.invalid_geometries));</strong> </pre>
<ol start="4">
<li>Open this geometry on your desktop GIS; the invalid geometry has just one self-intersecting ring that produces a hole in its internal. While this is accepted in the ESRI shapefile format specification (that was the original dataset you imported), the OGC standard does not allow for the self-intersecting ring, so neither does PostGIS:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="assets/3e410c76-e985-41de-b887-b34dd0790b6e.png" style="font-size: 1em;width:24.42em;height:10.75em;"/></div>
<ol start="5">
<li>Now, in the <kbd>invalid_geometries</kbd> table, you have the invalid and valid versions of the polygon. It is easy to figure out that the self-intersecting ring was removed by <kbd>ST_MakeValid</kbd> adding one supplementary ring to the original polygon, which resulted in a valid geometry, according to the OGC standard:</li>
</ol>
<pre><strong>      postgis_cookbook=# SELECT status, ST_NRings(the_geom) <br/>      FROM chp03.invalid_geometries;</strong> </pre>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/572c141e-3931-4af7-83c7-d1f7f2e2fcb0.png" style="width:11.67em;height:6.58em;"/></div>
<pre><strong>     (2 rows)</strong></pre>
<ol start="6">
<li>Now that you have identified the problem and its solution, don't forget to fix all the other invalid geometries in the <kbd>countries</kbd> table by executing the following code:</li>
</ol>
<pre><strong>      postgis_cookbook=# UPDATE chp03.countries 
      SET the_geom = ST_MakeValid(the_geom) 
      WHERE ST_IsValid(the_geom) = false;</strong> </pre>
<div class="packt_tip">A smart way to not have invalid geometries in the database at all is by adding a <kbd>CHECK</kbd> constraint on the table to check for validity. This will increase the computation time when updating or inserting new geometries, but will keep your dataset valid. For example, in the <kbd>countries</kbd> table, this can be implemented as follows:<br/>
<br/>
<kbd>ALTER TABLE chp03.countries</kbd><br/>
<kbd>ADD CONSTRAINT geometry_valid_check</kbd><br/>
<kbd>CHECK (ST_IsValid(the_geom));</kbd><br/>
<br/>
Many times in real use cases, though, you will need to remove such a constraint in order to be able to import records from a different source. After making validations with the <kbd>ST_MakeValid</kbd> function, you can safely add the constraint again.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>There are a number of reasons why an invalid geometry could result in your database; for example, rings composed of polygons must be closed and cannot self-intersect or share more than one point with another ring.</p>
<p>After importing the <kbd>country</kbd> shapefile using the <kbd>ST_IsValid</kbd> and <kbd>ST_IsValidReason</kbd> functions, you will have figured out that four of the imported geometries are invalid, all because their polygons have self-intersecting rings.</p>
<p>At this point, a good way to investigate the invalid multipolygon geometry is by decomposing the polygon in to its component rings and checking out the invalid ones. For this purpose, we have exported the geometry of the ring causing the invalidity, using the <kbd>ST_GeometryN</kbd> function, which is able to extract the <em>n</em><sup>th</sup> ring from the polygon. We coupled this function with the useful PostgreSQL <kbd>generate_series</kbd> function to iterate all of the rings composing the geometry, selecting the desired one using the <kbd>ST_Intersects</kbd> function.</p>
<p>As expected, the reason why this ring generates the invalidity is that it is self-intersecting and produces a hole in the polygon. While this adheres to the shapefile specification, it doesn't adhere to the OGC specification.</p>
<p>By running the <kbd>ST_MakeValid</kbd> function, PostGIS has been able to make the geometry valid, generating a second ring. Remember that the <kbd>ST_MakeValid</kbd> function is available only with the latest PostGIS compiled with the latest GEOS (3.3.0+). If that is not the setup for your working box and you cannot upgrade (upgrading is always recommended!), you can follow the techniques used in the past and discussed in a very popular, excellent presentation by <em>Paul Ramsey</em> at <a href="http://blog.opengeo.org/2010/09/08/tips-for-the-postgis-power-user/"><span class="URLPACKT">http://blog.opengeo.org/2010/09/08/tips-for-the-postgis-power-user/</span></a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">GIS analysis with spatial joins</h1>
                </header>
            
            <article>
                
<p>Joins for regular SQL tables have the real power in a relational database, and spatial joins are one of the most impressive features of a spatial database engine such as PostGIS.</p>
<p>Basically, it is possible to correlate information from different layers on the basis of the geometric relation of each feature from the input layers. In this recipe, we will take a tour of some common use cases of spatial joins.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<ol>
<li>First, import some data to be used as a test bed in PostGIS. Download the <kbd>.kmz</kbd> file containing information about 2012 global earthquakes from the USGS website at <a href="http://earthquake.usgs.gov/earthquakes/eqarchives/epic/kml/2012_Earthquakes_ALL.kmz"><span class="URLPACKT">http://earthquake.usgs.gov/earthquakes/eqarchives/epic/kml/2012_Earthquakes_ALL.kmz</span></a>. Save it in the <kbd>working/chp03</kbd> directory (alternatively, you can use the copy of this file included in the code bundle provided with this book).</li>
<li>A <kbd>.kmz</kbd> file is a collection of <kbd>.kml</kbd> files packaged with the ZIP compressor. Therefore, after unzipping the file (you may need to change the <kbd>.kmz</kbd> file extension to <kbd>.zip</kbd>), you may notice that it is composed of just a single <kbd>.kml</kbd> file. This file, which is in the GDAL abstraction, constitutes an OGR KML data source composed of nine different layers and containing 3D point geometries. Each layer contains earthquake data for each distinct earthquake magnitude:</li>
</ol>
<pre>      <strong>$ ogrinfo 2012_Earthquakes_ALL.kml</strong></pre>
<p style="padding-left: 60px">The output for this is as follows:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/09c70540-c0dc-4a8b-9153-fad43b3d0333.png" style="width:24.42em;height:14.25em;"/></div>
<ol start="3">
<li>Import all of those layers in a PostGIS table named <kbd>chp03.earthquakes</kbd> simultaneously by executing one of the following scripts using the <kbd>ogr2ogr</kbd> command.</li>
</ol>
<p style="padding-left: 60px">The following is the Linux version (name it <kbd>import_eq.sh</kbd>):</p>
<pre>        #!/bin/bash 
        for ((i = 1; i &lt; 9 ; i++)) ; do 
          echo "Importing earthquakes with magnitude $i <br/>                to chp03.earthquakes PostGIS table..." 
          ogr2ogr -append -f PostgreSQL -nln chp03.earthquakes <br/>          PG:"dbname='postgis_cookbook' user='me' <br/>          password='mypassword'" 2012_Earthquakes_ALL.kml <br/>          -sql "SELECT name, description, CAST($i AS integer) <br/>          AS magnitude FROM \"Magnitude $i\"" 
        done </pre>
<p style="padding-left: 60px">The following is the Windows version (name it <kbd>import_eq.bat</kbd>):</p>
<pre>        @echo off 
        for /l %%i in (1, 1, 9) do ( 
          echo "Importing earthquakes with magnitude %%i <br/>                to chp03.earthquakes PostGIS table..." 
          ogr2ogr -append -f PostgreSQL -nln chp03.earthquakes <br/>          PG:"dbname='postgis_cookbook' user='me' <br/>          password='mypassword'" 2012_Earthquakes_ALL.kml <br/>          -sql "SELECT name, description, CAST(%%i AS integer) <br/>          AS magnitude FROM \"Magnitude %%i\"" 
        )</pre>
<ol start="4">
<li>Execute the following script (for Linux, you need to add <kbd>execute</kbd> permissions to it):</li>
</ol>
<pre>      <strong>$ chmod 775 import_eq.sh</strong>
      <strong>$ ./import_eq.sh</strong>
      <strong>Importing earthquakes with magnitude 1 to chp03.earthquakes <br/>        PostGIS table...</strong>
      <strong>Importing earthquakes with magnitude 2 to chp03.earthquakes <br/>        PostGIS table...</strong>
      <strong>...</strong></pre>
<ol start="5">
<li>To maintain consistency with the book's conventions, rename the geometric column <kbd>wkb_geometry</kbd> (the default geometry output name in <kbd>ogr2ogr</kbd>) to <kbd>the_geom</kbd>, as illustrated in the following command:</li>
</ol>
<pre><strong>      postgis_cookbook=# ALTER TABLE chp03.earthquakes <br/>      RENAME wkb_geometry  TO the_geom;</strong> </pre>
<ol start="6">
<li>Download the <kbd>cities</kbd> shapefile for the USA from the <a href="https://nationalmap.gov/">https://nationalmap.gov/</a> website at <a href="http://dds.cr.usgs.gov/pub/data/nationalatlas/citiesx020_nt00007.tar.gz"><span class="URLPACKT">http://dds.cr.usgs.gov/pub/data/nationalatlas/citiesx020_nt00007.tar.gz</span></a> (this archive is also included in the code bundle provided with this book) and import it in PostGIS by executing the following code:</li>
</ol>
<pre>      <strong>$ ogr2ogr -f PostgreSQL -s_srs EPSG:4269 -t_srs EPSG:4326 <br/>      -lco GEOMETRY_NAME=the_geom -nln chp03.cities<br/>      PG:"dbname='postgis_cookbook' user='me'<br/>      password='mypassword'" citiesx020.shp</strong></pre>
<ol start="7">
<li>Download the <kbd>states</kbd> shapefile for the USA from the <a href="https://nationalmap.gov/">https://nationalmap.gov/</a> website at <a href="http://dds.cr.usgs.gov/pub/data/nationalatlas/statesp020_nt00032.tar.gz"><span class="URLPACKT">http://dds.cr.usgs.gov/pub/data/nationalatlas/statesp020_nt00032.tar.gz</span></a> (this archive is also included in the code bundle provided with this book) and import it in PostGIS by executing the following code:</li>
</ol>
<pre>      <strong>$ ogr2ogr -f PostgreSQL -s_srs EPSG:4269 -t_srs EPSG:4326 <br/>      -lco GEOMETRY_NAME=the_geom -nln chp03.states -nlt MULTIPOLYGON <br/>      PG:"dbname='postgis_cookbook' user='me'<br/>      password='mypassword'" statesp020.shp</strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>In this recipe, you will see for yourself the power of spatial SQL by solving a series of typical problems using spatial joins:</p>
<ol>
<li>First, query PostGIS to get the number of registered earthquakes in 2012 by state:</li>
</ol>
<pre><strong>      postgis_cookbook=# SELECT s.state, COUNT(*) AS hq_count 
      FROM chp03.states AS s 
        JOIN chp03.earthquakes AS e 
        ON ST_Intersects(s.the_geom, e.the_geom) 
        GROUP BY s.state 
        ORDER BY hq_count DESC;</strong> </pre>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-195 image-border" src="assets/68f320cb-5d1f-4930-8e52-6cb8eaca5a9a.png" style="width:18.50em;height:31.17em;"/></div>
<pre><strong>      (33 rows)</strong></pre>
<ol start="2">
<li>Now, to make it just a bit more complex, query PostGIS to get the number of earthquakes, grouped per magnitude, that are no further than 200 km from the cities in the USA that have more than 1 million inhabitants; execute the following code:</li>
</ol>
<pre><strong>      postgis_cookbook=# SELECT c.name, e.magnitude, count(*) as hq_count <br/>      FROM chp03.cities AS c 
        JOIN chp03.earthquakes AS e 
        ON ST_DWithin(geography(c.the_geom), geography(e.the_geom), 200000) 
        WHERE c.pop_2000 &gt; 1000000 
        GROUP BY c.name, e.magnitude 
        ORDER BY c.name, e.magnitude, hq_count;</strong> </pre>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-197 image-border" src="assets/3a3620ef-98f6-4376-bea3-ac7b00b7001d.png" style="width:23.92em;height:30.08em;"/></div>
<pre><strong>      (18 rows)</strong></pre>
<ol start="3">
<li>As a variant of the previous query, executing the following code gives you a complete list of earthquakes along with their distance from the city (in meters):</li>
</ol>
<pre><strong>      postgis_cookbook=# SELECT c.name, e.magnitude,</strong><br/><strong>        ST_Distance(geography(c.the_geom), geography(e.the_geom)) <br/>      AS distance FROM chp03.cities AS c 
        JOIN chp03.earthquakes AS e 
        ON ST_DWithin(geography(c.the_geom), geography(e.the_geom), 200000) 
        WHERE c.pop_2000 &gt; 1000000 
        ORDER BY distance;</strong> </pre>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-199 image-border" src="assets/4fcabdc0-6870-4f69-b0e6-c368d572f5b6.png" style="width:25.50em;height:25.17em;"/></div>
<pre><strong>      (488 rows)</strong> </pre>
<ol start="4">
<li>Now, ask PostGIS for the city count and the total population in each state by executing the following code:</li>
</ol>
<pre><strong>      postgis_cookbook-# SELECT s.state, COUNT(*) <br/>      AS city_count, SUM(pop_2000) AS pop_2000 <br/>      FROM chp03.states AS s 
        JOIN chp03.cities AS c 
        ON ST_Intersects(s.the_geom, c.the_geom) 
        WHERE c.pop_2000 &gt; 0 -- NULL values is -9999 on this field!</strong></pre>
<pre><strong>        GROUP BY s.state 
        ORDER BY pop_2000 DESC;</strong> </pre>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-200 image-border" src="assets/3952b72d-a6be-4a23-b81d-a0d7a732c746.png" style="width:22.75em;height:28.75em;"/></div>
<pre><strong>      (51 rows)</strong> </pre>
<ol start="5">
<li>As a final test, use a spatial join to update an existing table. You need to add the information in the <kbd>state_fips</kbd> field to the <kbd>earthquake</kbd> table from the <kbd>states</kbd> table. First, to host that kind of information, you need to create a column as shown in the following command:</li>
</ol>
<pre><strong>      postgis_cookbook-# ALTER TABLE chp03.earthquakes <br/>      ADD COLUMN state_fips character varying(2);</strong> </pre>
<ol start="6">
<li>Then, you can update the new column using a spatial join, as follows:</li>
</ol>
<pre><strong>      postgis_cookbook-# UPDATE chp03.earthquakes AS e 
        SET state_fips = s.state_fips 
        FROM chp03.states AS s 
        WHERE ST_Intersects(s.the_geom, e.the_geom);</strong> </pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>Spatial joins are one of the key features that unleash the spatial power of PostGIS. For a regular join, it is possible to relate entities from two distinct tables using a common field. For a spatial join, it is possible to relate features from two distinct spatial tables using any spatial relationship function, such as <kbd>ST_Contains</kbd>, <kbd>ST_Covers</kbd>, <kbd>ST_Crosses</kbd>, and <kbd>ST_DWithin</kbd>.</p>
<p>In the first query, we used the <kbd>ST_Intersects</kbd> function to join the earthquake points to their respective state. We grouped the query by the <kbd>state</kbd> column to obtain the number of earthquakes in the state.</p>
<p>In the second query, we used the <kbd>ST_DWithin</kbd> function to relate each city to the earthquake points within a 200 km distance of it. We filtered out the cities with a population of less than 1 million inhabitants and grouped them by city name and earthquake magnitude to get a report of the number of earthquakes per city and by magnitude.</p>
<p>The third query is similar to the second one, except it doesn't group per city and by magnitude. The distance is computed using the <kbd>ST_Distance</kbd> function. Note that as feature coordinates are stored in WGS 84, you need to cast the geometric column to a spheroid and use the spheroid to get the distance in meters. Alternatively, you could project the geometries to a planar system that is accurate for the area we are studying in this recipe (in this case, the <em>ESPG:2163</em>, <em>US National Atlas Equal Area</em> would be a good choice) using the <kbd>ST_Transform</kbd> function. However, in the case of large areas like the one we've dealt with in this recipe, casting to geography is generally the best option as it gives more accurate results.</p>
<p>The fourth query uses the <kbd>ST_Intersects</kbd> function. In this case, we grouped by the <kbd>state</kbd> column and used two aggregation SQL functions (<kbd>SUM</kbd> and <kbd>COUNT</kbd>) to get the desired results.</p>
<p>Finally, in the last query, you update a spatial table using the results of a spatial join. The concept behind this is like that of the previous query, except that it is in the context of an <kbd>UPDATE</kbd> SQL command.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Simplifying geometries</h1>
                </header>
            
            <article>
                
<p>There will be many times when you will need to generate a less detailed and lighter version of a vector dataset, as you may not need very detailed features for several reasons. Think about a case where you are going to publish the dataset to a website and performance is a concern, or maybe you need to deploy the dataset to a colleague who does not need too much detail because they are using it for a large-area map. In all these cases, GIS tools include implementations of <strong>simplification algorithms</strong> that reduce unwanted details from a given dataset. Basically, these algorithms reduce the vertex numbers comprised in a certain tolerance, which is expressed in units measuring distance.</p>
<p>For this purpose, PostGIS provides you with the <kbd>ST_Simplify</kbd> and <kbd>ST_SimplifyPreserveTopology</kbd> functions. In many cases, they are the right solutions for simplification tasks, but in some cases, especially for polygonal features, they are not the best option out there and you will need a different GIS tool, such as <kbd>GRASS</kbd> or the new PostGIS topology support.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>The steps you need to do to complete this recipe are as follows:</p>
<ol>
<li>Set the PostgreSQL <kbd>search_path</kbd> variable such that all your newly created database objects will be stored in the <kbd>chp03</kbd> schema, using the following code:</li>
</ol>
<pre><strong>      postgis_cookbook=# SET search_path TO chp03,public; </strong></pre>
<p> </p>
<p> </p>
<ol start="2">
<li>Suppose you need a less-detailed version of the <kbd>states</kbd> layer for your mapping website or to deploy to a client; you could consider using the <kbd>ST_SimplifyPreserveTopology</kbd> function as follows:</li>
</ol>
<pre><strong>      postgis_cookbook=# CREATE TABLE states_simplify_topology AS 
        SELECT ST_SimplifyPreserveTopology(ST_Transform(</strong><br/><strong>          the_geom, 2163), 500) FROM states;</strong></pre>
<ol start="3">
<li>The previous command works quickly, using a variant of the <strong>Douglas-Peucker</strong> algorithm, and effectively reduces the vertex number. But the resulting polygons, in some cases, are not adjacent any more. If you zoom in at any polygon border, you should notice something shown in the following screenshot: there are holes and overlaps along the shared border between two polygons. This is because PostGIS is using the OGC Simple Feature model, which doesn't implement topology, so the function just removes the redundant vertex without taking the adjacent polygons into consideration:</li>
</ol>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/98800160-9449-4ed8-8204-a0037db378d4.png" style="width:49.58em;height:23.25em;"/></div>
<ol start="4">
<li>It looks like the <kbd>ST_SimplifyPreserveTopology</kbd> function, while working well with linear features, produces topological anomalies with polygons. In case you want topological simplification, another approach is the following code suggested by <em>Paul Ramsey</em> (<a href="http://gis.stackexchange.com/questions/178/simplifying-adjacent-polygons"><span class="URLPACKT">http://gis.stackexchange.com/questions/178/simplifying-adjacent-polygons</span></a>) and improved in a <em>Webspaces</em> blog post (<a href="http://webspaces.net.nz/page.php?view=polygon-dissolve-and-generalise"><span class="URLPACKT">http://webspaces.net.nz/page.php?view=polygon-dissolve-and-generalise</span></a>):</li>
</ol>
<pre><strong>      SET search_path TO chp03, public; 
      -- first project the spatial table to a planar system <br/>        (recommended for simplification operations) 
      CREATE TABLE states_2163 AS SELECT ST_Transform<br/>        (the_geom, 2163)::geometry(MultiPolygon, 2163) <br/>        AS the_geom, state FROM states; 
      -- now decompose the geometries from multipolygons to polygons (2895) <br/>        using the ST_Dump function 
      CREATE TABLE polygons AS SELECT (ST_Dump(the_geom)).geom AS the_geom <br/>        FROM states_2163; 
      -- now decompose from polygons (2895) to rings (3150) <br/>        using the ST_DumpRings function 
      CREATE TABLE rings AS SELECT (ST_DumpRings(the_geom)).geom <br/>        AS the_geom FROM polygons; 
      -- now decompose from rings (3150) to linestrings (3150) <br/>        using the ST_Boundary function 
      CREATE TABLE ringlines AS SELECT(ST_boundary(the_geom)) <br/>        AS the_geom FROM rings; 
      -- now merge all linestrings (3150) in a single merged linestring <br/>        (this way duplicate linestrings at polygon borders disappear) 
      CREATE TABLE mergedringlines AS SELECT ST_Union(the_geom) <br/>        AS the_geom FROM ringlines; 
      -- finally simplify the linestring with a tolerance of 150 meters 
      CREATE TABLE simplified_ringlines AS SELECT <br/>      ST_SimplifyPreserveTopology(the_geom, 150) <br/>      AS the_geom FROM mergedringlines; 
      -- now compose a polygons collection from the linestring <br/>      using the ST_Polygonize function 
      CREATE TABLE simplified_polycollection AS SELECT <br/>        ST_Polygonize(the_geom) AS the_geom FROM simplified_ringlines; 
      -- here you generate polygons (2895) from the polygons collection <br/>        using ST_Dumps 
      CREATE TABLE simplified_polygons AS SELECT <br/>        ST_Transform((ST_Dump(the_geom)).geom, <br/>        4326)::geometry(Polygon,4326) <br/>        AS the_geom FROM simplified_polycollection; 
      -- time to create an index, to make next operations faster <br/>        CREATE INDEX simplified_polygons_gist ON simplified_polygons <br/>        USING GIST (the_geom); 
      -- now copy the state name attribute from old layer with a spatial <br/>        join using the ST_Intersects and ST_PointOnSurface function 
      CREATE TABLE simplified_polygonsattr AS SELECT new.the_geom, <br/>        old.state FROM simplified_polygons new, states old <br/>        WHERE ST_Intersects(new.the_geom, old.the_geom) <br/>        AND ST_Intersects(ST_PointOnSurface(new.the_geom), old.the_geom); 
      -- now make the union of all polygons with a common name 
      CREATE TABLE states_simplified AS SELECT ST_Union(the_geom) <br/>        AS the_geom, state FROM simplified_polygonsattr GROUP BY state;</strong></pre>
<ol start="5">
<li>This approach seems to work smoothly, but if you try to increment the simplifying tolerance from 150 to, let's say, 500 meters, you will again end up with topological anomalies (test this yourself). A better approach would be to use the PostGIS topology (you will do this in the <em>Simplifying geometries with PostGIS topology</em> recipe) or an external GIS tool that is able to manage topological operations the way <kbd>GRASS</kbd> can. For this recipe, you will use the <kbd>GRASS</kbd> approach.
<ol start="7"/>
</li>
<li>Install <kbd>GRASS</kbd> on your system if you don't have it. Then, create a directory to contain the <kbd>GRASS</kbd> database (in <kbd>GRASS</kbd> jargon, a <kbd>GISDBASE</kbd>), as follows:</li>
</ol>
<pre>      <strong>$ mkdir grass_db</strong></pre>
<ol start="7">
<li>Now, start <kbd>GRASS</kbd> by typing <kbd>grass</kbd> in the Linux command prompt or by double-clicking on the <span class="packt_screen">GRASS GUI</span> icon in Windows (<span class="packt_screen">Start</span> | <span class="packt_screen">All Programs</span> | <span class="packt_screen">OSGeo4W</span> | <span class="packt_screen">GRASS GIS 6.4.3</span> | <span class="packt_screen">GRASS 6.4.3 GUI</span>) or on <span class="packt_screen">Applications</span> in macOS. You will be prompted to select the <kbd>grass_db</kbd> database as the GIS data directory but should instead select the one you created in the previous step.
<ol start="7"/>
</li>
<li>Using the <span class="packt_screen">Location Wizard</span> button, create a location named <kbd>postgis_cookbook</kbd> with the title <kbd>PostGIS Cookbook</kbd> (<kbd>GRASS</kbd> uses subdirectories named locations, where all of the data is kept in the same coordinate system, map projection, and geographical boundaries).</li>
<li>When creating the new location, select the EPSG with SRID 2163 as the spatial reference system (you need to select the <span class="packt_screen">Select EPSG code of spatial reference system</span> option under <span class="packt_screen">Choose method for creating a new location</span>).</li>
</ol>
<ol start="10">
<li>Now start <kbd>GRASS</kbd> by clicking on the <span class="packt_screen">Start GRASS</span> button. The program's command line will start as shown in the following screenshot:</li>
</ol>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/01a70de2-a7c1-40f7-92ca-6d5994ef953e.png" style="width:37.50em;height:34.08em;"/></div>
<ol start="11">
<li>Import the <kbd>states</kbd> PostGIS spatial table to the <kbd>GRASS</kbd> location. To do so, use the <kbd>v.in.ogr GRASS</kbd> command, which will then use the OGR PostgreSQL driver (in fact, the PostGIS connection string syntax is the same):</li>
</ol>
<pre>      <strong>GRASS 6.4.1 (postgis_cookbook):~ &gt; v.in.ogr <br/>      input=PG:"dbname='postgis_cookbook' user='me' <br/>      password='mypassword'" layer=chp03.states_2163 out=states</strong></pre>
<ol start="12">
<li><kbd>GRASS</kbd> will import the OGR PostGIS table and simultaneously build the topology for this layer, which is composed of points, lines, areas, and so on. The <kbd>v.info</kbd> command can be used in combination with the <kbd>-c</kbd> option to check the attributes table and get more information on the imported layer, as follows:</li>
</ol>
<pre>      <strong>GRASS 6.4.1 (postgis_cookbook):~ &gt; v.info states</strong></pre>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/92ffb6e9-703e-430f-8fdf-6ccb5743daee.png" style="width:36.50em;height:41.75em;"/></div>
<ol start="13">
<li>Now, you can simplify the polygon geometries using the <kbd>v.generalizeGRASS</kbd> command with a tolerance (threshold) of 500 meters. If you are using the same dataset used in this recipe, you will end up with 47,191 vertices from the original 346,914 vertices, composing 1,919 polygons (areas) from the original 2,895 polygons:</li>
</ol>
<pre>      <strong>GRASS 6.4.1 (postgis_cookbook):~ &gt; v.generalize input=states <br/>      output=states_generalized_from_grass method=douglas threshold=500</strong></pre>
<ol start="14">
<li>Export the results back to PostGIS using the <kbd>v.out.ogr</kbd> command (the <kbd>v.in.ogr</kbd> counterpart) as follows:</li>
</ol>
<pre>      <strong>GRASS 6.4.1 (postgis_cookbook):~ &gt; v.out.ogr <br/>      input=states_generalized_from_grass <br/>      type=area dsn=PG:"dbname='postgis_cookbook' user='me' <br/>      password='mypassword'" olayer=chp03.states_simplified_from_grass <br/>      format=PostgreSQL</strong></pre>
<ol start="15">
<li>Now, open a desktop GIS and check for differences between the geometry simplification performed by the <kbd>ST_SimplifyPreserveTopology</kbd> PostGIS function and <kbd>GRASS</kbd>. There should be no holes or overlaps at shared polygon borders. In the following screenshot, the original layer boundaries are in red, the boundaries built by <kbd>ST_SimplifyPreserveTopology</kbd> are in blue, and those built by <kbd>GRASS</kbd> are in green:</li>
</ol>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/060b961d-896d-4c37-895b-26c439c6ff7b.png" style="width:13.00em;height:17.75em;"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>The <kbd>ST_Simplify</kbd> PostGIS function is able to simplify and generalize either a (simple or multi) linear or polygonal geometry using the Douglas-Peucker algorithm (for more details, go to <a href="http://en.wikipedia.org/wiki/Ramer%E2%80%93Douglas%E2%80%93Peucker_algorithm"><span class="URLPACKT">http://en.wikipedia.org/wiki/Ramer%E2%80%93Douglas%E2%80%93Peucker_algorithm</span></a>). Since it can create invalid geometries in some cases, it is recommended that you use its evolved version—the <kbd>ST_SimplifyPreserveTopology</kbd> function—which will produce only valid geometries.</p>
<p>While the functions are working well with (multi) linear geometries, in the case of (multi) polygons, they will most likely create topological anomalies such as overlaps and holes at shared polygon borders.</p>
<p>To get a valid, topologically simplified dataset, there are the following two choices at the time of writing:</p>
<ul>
<li>Performing the simplified process on an external GIS tool such as <kbd>GRASS</kbd></li>
<li>Using the new PostGIS topological support</li>
</ul>
<p>While you will see the new PostGIS topological features in the <em>Simplifying geometries with PostGIS topology</em> recipe, in this one you have been using <kbd>GRASS</kbd> to perform the simplification process.</p>
<p>We opened <kbd>GRASS</kbd>, created a GIS data directory and a project location, and then imported in the <kbd>GRASS</kbd> location, the polygonal PostGIS table using the <kbd>v.ogr.in</kbd> command, based on GDAL/OGR as the name suggests.</p>
<p>Until this point, you have been using the <kbd>GRASS v.generalize</kbd> command to perform the simplification of the dataset using a tolerance (threshold) expressed in meters.</p>
<p>After simplifying the dataset, you imported it back to PostGIS using the <kbd>v.ogr.out GRASS</kbd> command and then opened the derived spatial table in a desktop GIS to see whether or not the process was performed in a topologically correct way.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Measuring distances</h1>
                </header>
            
            <article>
                
<p>In this recipe, we will check out the PostGIS functions needed for distance measurements (<kbd>ST_Distance</kbd> and its variants) and find out how considering the earth's curvature makes a big difference when measuring distances between distant points.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>You should import the shapefile representing the cities from the USA that we generated in a previous recipe (the PostGIS table named <kbd>chp03.cities</kbd>). In case you haven't done so, download that shapefile from the <a href="https://nationalmap.gov/">https://nationalmap.gov/</a> website at <a href="http://dds.cr.usgs.gov/pub/data/nationalatlas/citiesx020_nt00007.tar.gz"><span class="URLPACKT">http://dds.cr.usgs.gov/pub/data/nationalatlas/citiesx020_nt00007.tar.gz</span></a> (this archive is also included in the code bundle available with this book) and import it to PostGIS:</p>
<pre><strong>$ ogr2ogr -f PostgreSQL -s_srs EPSG:4269 -t_srs EPSG:4326 -lco GEOMETRY_NAME=the_geom -nln chp03.cities PG:"dbname='postgis_cookbook' user='me' password='mypassword'" citiesx020.shp</strong>
  </pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>The steps you need to perform to complete this recipe are as follows:</p>
<ol>
<li>First, use the <kbd>ST_Distance</kbd> function to calculate the distances between cities in the USA that have more than 1 million inhabitants using the Spherical Mercator planar projection coordinate system (EPSG:900913, EPSG:3857, or EPSG:3785; all of these SRID representations are equivalent). Use the <kbd>ST_Transform</kbd> function as follows to convert the point coordinates from longitude latitude degrees (as the coordinates are originally in EPSG:4326) to a planar metric system if you want the results in meters:</li>
</ol>
<pre><strong>      postgis_cookbook=# SELECT c1.name, c2.name, 
      ST_Distance(ST_Transform(c1.the_geom, 900913), </strong><br/><strong>      ST_Transform(c2.the_geom, 900913))/1000 AS distance_900913 
      FROM chp03.cities AS c1 
      CROSS JOIN chp03.cities AS c2 
      WHERE c1.pop_2000 &gt; 1000000 AND c2.pop_2000 &gt; 1000000 <br/></strong></pre>
<pre><strong>      AND c1.name &lt; c2.name 
      ORDER BY distance_900913 DESC;</strong> </pre>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/425da6aa-4cd1-4b21-b65e-eea04e1449a3.png" style="width:21.58em;height:25.42em;"/></div>
<pre><strong>      (36 rows)</strong> </pre>
<ol start="2">
<li>Now write the same query as we did in the previous recipe, but in a more compact expression using a PostgreSQL <strong>Common Table Expression</strong> (<strong>CTE</strong>):</li>
</ol>
<pre><strong>      WITH cities AS ( 
        SELECT name, the_geom FROM chp03.cities 
        WHERE pop_2000 &gt; 1000000 ) 
      SELECT c1.name, c2.name, 
      ST_Distance(ST_Transform(c1.the_geom, 900913),<br/>      ST_Transform(c2.the_geom, 900913))/1000 AS distance_900913 
      FROM cities c1 CROSS JOIN cities c2 
      where c1.name &lt; c2.name 
      ORDER BY distance_900913 DESC;</strong></pre>
<ol start="3">
<li>For large distances such as in this case, it is not correct to use a planar spatial reference system, but you should make the calculations taking into consideration the earth's curvature. For example, the previously used Mercator planar system, while it is very good to use for map outputs, is very bad for measuring distances and areas as it assesses directions. For this purpose, it would be better to use a spatial reference system that is able to measure distance. You can also use the <kbd>ST_Distance_Sphere</kbd> or <kbd>ST_Distance_Spheroid</kbd> functions (the first being quicker, but less accurate, as it performs calculations on a sphere and not a spheroid). An even better option is converting the geometries to the geography data type, so you can use <kbd>ST_Distance</kbd> directly, as it will automatically make the calculations using the spheroid. Note that this is exactly equivalent to using <kbd>ST_DistanceSpheroid</kbd>. Try to check the difference between the various approaches, using the same query as before:</li>
</ol>
<pre><strong>      WITH cities AS ( 
        SELECT name, the_geom FROM chp03.cities 
        WHERE pop_2000 &gt; 1000000 ) 
      SELECT c1.name, c2.name, 
      ST_Distance(ST_Transform(c1.the_geom, 900913),<br/>      ST_Transform(c2.the_geom, 900913))/1000 AS d_900913,<br/>      ST_Distance_Sphere(c1.the_geom, c2.the_geom)/1000 AS d_4326_sphere, 
      ST_Distance_Spheroid(c1.the_geom, c2.the_geom,<br/>      'SPHEROID["GRS_1980",6378137,298.257222101]')/1000 <br/>      AS d_4326_spheroid, ST_Distance(geography(c1.the_geom),<br/>      geography(c2.the_geom))/1000 AS d_4326_geography 
      FROM cities c1 CROSS JOIN cities c2 
      where c1.name &lt; c2.name 
      ORDER BY d_900913 DESC;</strong></pre>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/0f7e7db6-3a36-43d1-8c4b-29218c0681e2.png" style="width:46.50em;height:28.83em;"/></div>
<pre><strong>      (36 rows)</strong> </pre>
<ol start="4">
<li>You can easily verify from the output that there is a big difference with using the planar system (EPSG:900913, as in the <kbd>d_900913</kbd> column) instead of systems that take into consideration the curvature of the earth.</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>If you need to compute the minimum Cartesian distance between two points, you can use the PostGIS <kbd>ST_Distance</kbd> function. This function accepts two-point geometries as input parameters and these geometries must be specified in the same <strong>spatial reference system</strong>.</p>
<p>If the two input geometries are using different spatial references, you can use the <kbd>ST_Transform</kbd> function on one or both of them to make them consistent with a single spatial reference system.</p>
<p>To get better results, you should consider the earth's curvature, which is mandatory when measuring large distances, and use the <kbd>ST_Distance_Sphere</kbd> or the <kbd>ST_Distance_Spheroid</kbd> functions. Alternatively, use <kbd>ST_Distance</kbd>, but cast the input geometries to the <strong>geography spatial data type</strong>, which is optimized for this kind of operation. The geography type stores the geometries in WGS 84 longitude latitude degrees, but it always returns the measurements in meters.</p>
<p>In this recipe, you have used a PostgreSQL CTE, which is a handy way to provide a subquery in the context of the main query. You can consider a CTE as a temporary table used only within the scope of the main query.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Merging polygons using a common attribute</h1>
                </header>
            
            <article>
                
<p>There are many cases in GIS workflows where you need to merge a polygonal dataset based on a common attribute. A typical example is merging the European administrative areas (which you can see at <a href="http://en.wikipedia.org/wiki/Nomenclature_of_Territorial_Units_for_Statistics"><span class="URLPACKT">http://en.wikipedia.org/wiki/Nomenclature_of_Territorial_Units_for_Statistics</span></a>), starting from <strong>Nomenclature des Units Territoriales Statistiques</strong> (<strong>NUTS</strong>) level 4 to obtain the subsequent levels up to NUTS level 1, using the NUTS code or merging the USA counties layer using the state code to obtain the states layer.</p>
<p>PostGIS lets you perform this kind of processing operation with the <kbd>ST_Union</kbd> function.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>Download the USA countries shapefile from the <a href="https://nationalmap.gov/">https://nationalmap.gov/</a> website at <a href="http://dds.cr.usgs.gov/pub/data/nationalatlas/co2000p020_nt00157.tar.gz"><span class="URLPACKT">http://dds.cr.usgs.gov/pub/data/nationalatlas/co2000p020_nt00157.tar.gz</span></a> (this archive is also included in the code bundle provided with this book) and import it in PostGIS as follows:</p>
<pre><strong>$ ogr2ogr -f PostgreSQL -s_srs EPSG:4269 -t_srs EPSG:4326 -lco GEOMETRY_NAME=the_geom -nln chp03.counties -nlt MULTIPOLYGON PG:"dbname='postgis_cookbook' user='me' password='mypassword'" co2000p020.shp</strong>
  </pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>The steps you need to perform to complete this recipe are as follows:</p>
<ol>
<li>First, check the imported table by running the following commands:</li>
</ol>
<pre><strong>      postgis_cookbook=# SELECT county, fips, state_fips<br/>      FROM chp03.counties ORDER BY county;</strong> </pre>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/788d8e93-ee09-4743-b564-769622356040.png" style="width:17.33em;height:24.08em;"/></div>
<pre><strong>      (6138 rows)</strong> </pre>
<ol start="2">
<li>Now perform the merging operation based on the <kbd>state_fips</kbd> field, using the <kbd>ST_Union</kbd> PostGIS function:</li>
</ol>
<pre><strong>      postgis_cookbook=# CREATE TABLE chp03.states_from_counties <br/>      AS SELECT ST_Multi(ST_Union(the_geom)) as the_geom, state_fips <br/>      FROM chp03.counties GROUP BY state_fips;</strong></pre>
<ol start="3">
<li>The following screenshot shows how the output PostGIS layer looks in a desktop GIS; the aggregate counties have successfully been composed by their respective state (indicated by the thick blue border):</li>
</ol>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/fb9f84b5-447f-498f-ad80-68d4c6ed1576.png" style="width:33.00em;height:17.33em;"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>You have been using the <kbd>ST_Union</kbd> PostGIS function to make a polygon merge on a common attribute. This function can be used as an aggregate PostgreSQL function (such as <kbd>SUM</kbd>, <kbd>COUNT</kbd>, <kbd>MIN</kbd>, and <kbd>MAX</kbd>) on the layer's geometric field, using the common attribute in the <kbd>GROUP BY</kbd> clause.</p>
<p>Note that <kbd>ST_Union</kbd> can also be used as a non-aggregate function to perform the union of two geometries (which are the two input parameters).</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Computing intersections</h1>
                </header>
            
            <article>
                
<p>One typical GIS geoprocessing workflow is to compute intersections generated by intersecting linear geometries.</p>
<p>PostGIS offers a rich set of functions for solving this particular type of problem and you will have a look at them in this recipe.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>For this recipe, we will use the Rivers + lake centerlines dataset of North America and Europe<span> </span><span>with a scale 1:10m</span><span>. Download the</span> <kbd>rivers</kbd> <span>dataset from</span> the <span>following</span> <kbd>naturalearthdata.com</kbd> <span>website (or use the ZIP file included in the code bundle provided with this book):</span></p>
<p><a href="http://www.naturalearthdata.com/http//www.naturalearthdata.com/download/10m/physical/ne_10m_rivers_lake_centerlines.zip"><span class="URLPACKT">http://www.naturalearthdata.com/http//www.naturalearthdata.com/download/10m/physical/ne_10m_rivers_lake_centerlines.zip</span></a></p>
<p>Or find it on the following website:</p>
<p><a href="http://www.naturalearthdata.com/downloads/10m-physical-vectors/"><span class="URLPACKT">http://www.naturalearthdata.com/downloads/10m-physical-vectors/</span></a></p>
<p>Extract the shapefile to your working directory <kbd>chp03/working</kbd>. Import the shapefile in PostGIS using <kbd>shp2pgsql</kbd> as follows:</p>
<pre><strong>$ shp2pgsql -I -W LATIN1 -s 4326 -g the_geom ne_10m_rivers_lake_centerlines.shp chp03.rivers &gt; rivers.sql</strong>
<strong>$ psql -U me -d postgis_cookbook -f rivers.sql</strong>  </pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>The steps you need to perform to complete this recipe are as follows:</p>
<ol>
<li>First, perform a self-spatial join between your <kbd>MultiLineString</kbd> dataset and the PostGIS <kbd>ST_Intersects</kbd> function and find intersections in the join context with the <kbd>ST_Intersection</kbd> PostGIS function. The following is the basic query, resulting in 1,448 records being selected:</li>
</ol>
<pre><strong>      postgis_cookbook=#  SELECT r1.gid AS gid1, r2.gid AS gid2,</strong><br/><strong>      ST_AsText(ST_Intersection(r1.the_geom, r2.the_geom)) AS the_geom 
      FROM chp03.rivers r1 
      JOIN chp03.rivers r2 
      ON ST_Intersects(r1.the_geom, r2.the_geom) 
      WHERE r1.gid != r2.gid;</strong> </pre>
<ol start="2">
<li>You may hastily assume that all of the intersections are single points, but this is not the case; if you check the geometry type of the geometric intersections using the <kbd>ST_GeometryType</kbd> function, you have three different cases of intersection, resulting in the following geometries:
<ul>
<li>An <kbd>ST_POINT</kbd> <span><span>geometry for a simple intersection between two linear geometries.</span></span></li>
</ul>
</li>
</ol>
<ul>
<li style="list-style-type: none">
<ul>
<li>An <kbd>ST_MultiPoint</kbd> <span><span>geometry, if two linear geometries intersect each other at more points.</span></span></li>
<li>An <kbd>ST_GeometryCollection</kbd> <span>geometry in cases where the two</span> <kbd>MultiLineString</kbd> <span>objects intersect and share part of the line. In such a case, the geometry collection is composed of</span> <kbd>ST_Point</kbd> <span>and/or</span> <kbd>ST_Line</kbd> <span>geometries.</span></li>
</ul>
</li>
</ul>
<ol start="3">
<li>You can check the different cases with a query, shown as follows:</li>
</ol>
<pre><strong>      postgis_cookbook=# SELECT COUNT(*), 
        ST_GeometryType(ST_Intersection(r1.the_geom, r2.the_geom)) <br/>          AS geometry_type 
        FROM chp03.rivers r1 
        JOIN chp03.rivers r2 
        ON ST_Intersects(r1.the_geom, r2.the_geom) 
        WHERE r1.gid != r2.gid 
        GROUP BY geometry_type;</strong> </pre>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/533aad33-1f44-4cb4-85d7-9bd94691ee92.png" style="width:13.75em;height:6.08em;"/></div>
<pre><strong>      (3 rows)</strong> </pre>
<ol start="4">
<li>First, try to compute the intersection for just the first two cases (intersections composed of the <kbd>ST_Point</kbd> and <kbd>ST_MultiPoint</kbd> geometries). Just generate a table with the <kbd>Point</kbd> and <kbd>MultiPoint</kbd> geometries, excluding the records that have an intersection composed of a geometric collection. By executing the following commands, 1,444 of the 1,448 records are imported (the four records with geometry collections are ignored using the <kbd>ST_GeometryType</kbd> function):</li>
</ol>
<pre><strong>      postgis_cookbook=# CREATE TABLE chp03.intersections_simple AS 
        SELECT r1.gid AS gid1, r2.gid AS gid2,</strong><br/><strong>          ST_Multi(ST_Intersection(r1.the_geom,</strong><br/><strong>          r2.the_geom))::geometry(MultiPoint, 4326) AS the_geom 
        FROM chp03.rivers r1 
        JOIN chp03.rivers r2 
        ON ST_Intersects(r1.the_geom, r2.the_geom) 
        WHERE r1.gid != r2.gid 
        AND ST_GeometryType(ST_Intersection(r1.the_geom,</strong><br/><strong>          r2.the_geom)) != 'ST_GeometryCollection';</strong></pre>
<ol start="5">
<li>In case you want to import the points from the geometry collection too (but just the points, ignoring the eventual linestrings), one way to go about it is by using the <kbd>ST_CollectionExtract</kbd> function in the context of a <kbd>SELECT</kbd><kbd>CASE</kbd> PostgreSQL conditional statement; this way, you can import all the 1,448 intersections as follows:</li>
</ol>
<pre><strong>      postgis_cookbook=# CREATE TABLE chp03.intersections_all AS</strong> 
<strong>      SELECT gid1, gid2, the_geom::geometry(MultiPoint, 4326) FROM ( 
        SELECT r1.gid AS gid1, r2.gid AS gid2, 
        CASE 
          WHEN ST_GeometryType(ST_Intersection(r1.the_geom, </strong><br/><strong>            r2.the_geom)) != 'ST_GeometryCollection' THEN 
          ST_Multi(ST_Intersection(r1.the_geom,</strong><br/><strong>            r2.the_geom))</strong><br/><strong>           ELSE ST_CollectionExtract(ST_Intersection(r1.the_geom,</strong><br/><strong>            r2.the_geom), 1) 
        END AS the_geom 
        FROM chp03.rivers r1 
        JOIN chp03.rivers r2 
        ON ST_Intersects(r1.the_geom, r2.the_geom) 
        WHERE r1.gid != r2.gid 
      ) AS only_multipoints_geometries;</strong> </pre>
<ol start="6">
<li>You may see the difference between the two processes, counting the total number of points in each of the generated tables, as follows:</li>
</ol>
<pre><strong>      postgis_cookbook=# SELECT SUM(ST_NPoints(the_geom))<br/>        FROM chp03.intersections_simple; --2268 points per 1444 records 
      postgis_cookbook=# SELECT SUM(ST_NPoints(the_geom)) <br/>        FROM chp03.intersections_all; --2282 points per 1448 records</strong></pre>
<ol start="7">
<li>In the following screenshot (taken from QGIS), you may notice the generated intersections generated by both approaches. In the case of the <kbd>intersection_all</kbd> layer, you will notice that some more intersections have been computed (in red):</li>
</ol>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-201 image-border" src="assets/5a880965-4a30-4972-b6f9-03b988419711.png" style="width:102.92em;height:67.00em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">Layers of river intersections visualized in QGIS</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>We have been using a self-spatial join of a linear PostGIS spatial layer to find intersections generated by the features of that layer.</p>
<p>To generate the self-spatial join, we used the <kbd>ST_Intersects</kbd> function. This way, we found that all of the features have at least an intersection in their respective geometries.</p>
<p>In the same self-spatial join context, we found out the intersections, using the <kbd>ST_Intersection</kbd> function.</p>
<p>The problem is that the computed intersections are not always single points. In fact, two intersecting lines can produce the origin for a single-point geometry (<kbd>ST_Point</kbd>) if the two lines just intersect once. But, the two intersecting lines can produce the origin for a point collection (<kbd>ST_MultiPoint</kbd>) or even a geometric collection if the two lines intersect at more points and/or share common parts.</p>
<p>As our target was to compute all the point intersections (<kbd>ST_Point</kbd> and <kbd>ST_MultiPoint</kbd>) using the <kbd>ST_GeometryType</kbd> function, we filtered out the values using a SQL <kbd>SELECT CASE</kbd> construct where the feature had a <kbd>GeometryCollection</kbd> geometry, for which we extracted just the points (and not the eventual linestrings) using the <kbd>ST_CollectionExtract</kbd> function (<kbd>parameter type = 1</kbd>) from the composing collections.</p>
<p>Finally, we compared the two result sets, both with plain SQL and a desktop GIS. The intersecting points computed filtered out the geometric collections from the output geometries and the intersecting points computed from all the geometries generated from the intersections, including the <kbd>GeometryCollection</kbd> features.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Clipping geometries to deploy data</h1>
                </header>
            
            <article>
                
<p>A common GIS use case is clipping a big dataset into small portions (subsets), with each perhaps representing an area of interest. In this recipe, you will export from a PostGIS layer representing the rivers in the world, with one distinct shapefile composed of rivers for each country. For this purpose, you will use the <kbd>ST_Intersection</kbd> function.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>Be sure that you have imported in PostGIS the same river dataset (a shapefile) that was used in the previous recipe.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>The steps you need to take to complete this recipe are as follows:</p>
<ol start="1">
<li>First, you will create a view to clip the river geometries for each country using the <kbd>ST_Intersection</kbd> and <kbd>ST_Intersects</kbd> functions. Name the view <kbd>rivers_clipped_by_country</kbd>:</li>
</ol>
<pre><strong>       postgis_cookbook=&gt; CREATE VIEW chp03.rivers_clipped_by_country AS 
         SELECT r.name, c.iso2, ST_Intersection(r.the_geom,</strong><br/><strong>           c.the_geom)::geometry(Geometry,4326) AS the_geom</strong><br/><strong>         FROM chp03.countries AS c 
         JOIN chp03.rivers AS r 
         ON ST_Intersects(r.the_geom, c.the_geom);</strong> </pre>
<ol start="2">
<li>Create a directory named <kbd>rivers</kbd> as follows:</li>
</ol>
<pre>      <strong>mkdir working/chp03/rivers</strong></pre>
<ol start="3">
<li>Create the following scripts to export a <kbd>rivers</kbd> shapefile for each country.</li>
</ol>
<p style="padding-left: 60px">The following is the Linux version (name it <kbd>export_rivers.sh</kbd>):</p>
<pre>        #!/bin/bash 
        for f in `ogrinfo PG:"dbname='postgis_cookbook' user='me' <br/>        password='mypassword'" -sql "SELECT DISTINCT(iso2) <br/>        FROM chp03.countries ORDER BY iso2" | grep iso2 | awk '{print $4}'` 
        do 
          echo "Exporting river shapefile for $f country..." 
          ogr2ogr rivers/rivers_$f.shp PG:"dbname='postgis_cookbook' <br/>          user='me' password='mypassword'" <br/>          -sql "SELECT * FROM chp03.rivers_clipped_by_country <br/>          WHERE iso2 = '$f'" 
        done </pre>
<p style="padding-left: 60px">The following is the Windows version (name it <kbd>export_rivers.bat</kbd>):</p>
<pre>        FOR /F "tokens=*" %%f IN ('ogrinfo <br/>        PG:"dbname=postgis_cookbook user=me password=password" <br/>        -sql "SELECT DISTINCT(iso2) FROM chp03.countries <br/>         ORDER BY iso2" ^| grep iso2 ^| gawk "{print $4}"') DO ( 
           echo "Exporting river shapefile for %%f country..." 
           ogr2ogr rivers/rivers_%%f.shp PG:"dbname='postgis_cookbook' <br/>           user='me' password='password'" </pre>
<pre>           -sql "SELECT * FROM chp03.rivers_clipped_by_country <br/>           WHERE iso2 = '%%f'" 
        )</pre>
<div class="packt_tip"><span class="packt_screen">For Windows users<br/></span>The script uses the <kbd>grep</kbd> and <kbd>awk</kbd> Linux commands, so you will need to download their Windows versions from <a href="http://unxutils.sourceforge.net/"><span class="URLPACKT">http://unxutils.sourceforge.net/</span></a>. The script was tested with the <kbd>UnxUpdates.zip</kbd> file (which includes <kbd>gawk</kbd>, but not <kbd>awk</kbd>), but you are welcome to download the full version available at <a href="https://sourceforge.net/projects/unxutils/"><span class="URLPACKT">https://sourceforge.net/projects/unxutils/</span></a>. Also remember to include the folder with the executable files on the Windows path. There's a chance that you already have them installed in your system if you have installed OSGeo4W, a binary distribution of a broad set of open source, geospatial software for win32 environments. You can find it at <a href="http://trac.osgeo.org/osgeo4w/"><span class="URLPACKT">http://trac.osgeo.org/osgeo4w/</span></a>.</div>
<ol start="4">
<li>In Windows, run the batch file:</li>
</ol>
<pre>      <strong>C:\export_rivers.bat</strong></pre>
<ol start="5">
<li>Now, run the following script (in Linux or macOS, you need to assign <kbd>execute</kbd> permissions to the script before running the shell file):</li>
</ol>
<pre>      <strong>$ chmod 775 export_rivers.sh</strong>
      <strong>$ ./export_rivers.sh</strong>
      <strong>Exporting river shapefile for AD country...</strong>
      <strong>Exporting river shapefile for AE country...</strong>
      <strong>...<br/>      Exporting river shapefile for ZM country...</strong>
      <strong>Exporting river shapefile for ZW country...</strong></pre>
<div class="packt_infobox">You could eventually skip the creation of the <kbd>rivers_clipped_by_country</kbd> view by replacing the <kbd>ogr2ogr</kbd> statement in the previous script with the following command (<kbd>ogr2ogr</kbd> passes the content of the <kbd>-sql</kbd> option directly to PostGIS); use <kbd>%%f</kbd> for Windows:<br/>
<kbd>ogr2ogr rivers/rivers_$f.shp PG:"dbname='postgis_cookbook' user='me' password='mypassword'" -sql "SELECT r.name, c.iso2, ST_Intersection(r.the_geom, c.the_geom) AS the_geom FROM chp03.countries AS c JOIN chp03.rivers AS r ON ST_Intersects(r.the_geom, c.the_geom) WHERE c.iso2 = '$f'"</kbd></div>
<ol start="6">
<li>Check the output with <kbd>ogrinfo</kbd> or a desktop GIS. The following screenshot shows how the output looks in QGIS; we have added the original PostGIS <kbd>chp03.rivers</kbd> layer and a couple of the generated shapefiles:</li>
</ol>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/dc5c0ed4-c4bd-43de-a354-d248e33ca342.png" style="width:51.92em;height:28.50em;"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>You can use the <kbd>ST_Intersection</kbd> function to clip one dataset from another. In this recipe, you first created a view, where you performed a spatial join between a polygonal layer (countries) and a linear layer (rivers) using the <kbd>ST_Intersects</kbd> function. In the context of the spatial join, you have used the <kbd>ST_Intersection</kbd> function to generate a snapshot of the rivers in every country.</p>
<p>You have then created a bash script in which you iterated every single country and pulled out to a shapefile the clipped rivers for that country, using <kbd>ogr2ogr</kbd> and the previously created view as the input layer.</p>
<p>To iterate the countries in the script, you have been using <kbd>ogrinfo</kbd> with the <kbd>-sql</kbd> option, using a SQL <kbd>SELECT DISTINCT</kbd> statement. You have used a combination of the <kbd>grep</kbd> and <kbd>awk</kbd> Linux commands, piped together to get every single country code. The <kbd>grep</kbd> command is a utility for searching plaintext datasets for lines matching a regular expression, while <kbd>awk</kbd> is an interpreted programming language designed for text processing and typically used as a data extraction and reporting tool.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Simplifying geometries with PostGIS topology</h1>
                </header>
            
            <article>
                
<p>In a previous recipe, we used the <kbd>ST_SimplifyPreserveTopology</kbd> function to try to generate a simplification of a polygonal PostGIS layer.</p>
<p>Unfortunately, while that function works well for linear layers, it produces topological anomalies (overlapping and holes) in shared polygon borders. You used an external toolset (<kbd>GRASS</kbd>) to generate a valid topological simplification.</p>
<p>In this recipe, you will use the PostGIS topology support to perform the same task within the spatial database, without needing to export the dataset to a different toolset.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>To get started, perform the following steps:</p>
<ol>
<li>Be sure that you have PostGIS topology support enabled in your database instance. This support is packaged as a separate extension and, if you are using PostgreSQL 9.1 or newer versions, you can install it using the following SQL <kbd>CREATE EXTENSION</kbd> command:</li>
</ol>
<pre>      <strong>postgis_cookbook=# CREATE EXTENSION postgis_topology;</strong></pre>
<ol start="2">
<li>Download the administrative area archive for Hungary from the <kbd>gadm.org</kbd> website at <a href="http://gadm.org/country"><span class="URLPACKT">http://gadm.org/country</span></a> (or use the copy included in the code bundle provided with this book).</li>
<li>Extract the <kbd>HUN_adm1.shp</kbd> shapefile from the archive to your working directory, <kbd>working/chp03</kbd>.</li>
</ol>
<p> </p>
<ol start="4">
<li>Import the shapefile to PostGIS using a tool such as <kbd>ogr2ogr</kbd> or <kbd>shp2pgsql</kbd>, as follows:</li>
</ol>
<pre>      <strong>ogr2ogr -f PostgreSQL -t_srs EPSG:3857 -nlt MULTIPOLYGON <br/>      -lco GEOMETRY_NAME=the_geom -nln chp03.hungary <br/>      PG:"dbname='postgis_cookbook' user='me'<br/>      password='mypassword'" HUN_adm1.shp</strong></pre>
<ol start="5">
<li>After the import process is completed, you can check the count using the following command; note that this spatial table consists of 20 multipolygons, each representing one administrative area in Hungary:</li>
</ol>
<pre><strong>      postgis_cookbook=# SELECT COUNT(*) FROM chp03.hungary;</strong> </pre>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/0257f42c-5d33-4cd0-ad04-581f630b2918.png" style="width:7.58em;height:5.92em;"/></div>
<pre><strong>      (1 row)</strong> </pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>The steps you need to take to complete this recipe are as follows:</p>
<ol>
<li>All functions and tables associated with the topology module are installed in a schema named <kbd>topology</kbd>, so let's add it to the search path to avoid prefixing it before every <kbd>topology</kbd> function or object:</li>
</ol>
<pre><strong>      postgis_cookbook=# SET search_path TO chp03, topology, public;</strong> </pre>
<ol start="2">
<li>Now you will use the <kbd>CreateTopology</kbd> function to create a new <kbd>topology</kbd> schema named <kbd>hu_topo</kbd> in which you will import the 20 administrative areas from the <kbd>hungary</kbd> table. In PostGIS topology, all the topology entities and relations needed for one topology schema are stored in a single PostgreSQL schema using the same spatial reference system. You will name this schema <kbd>hu_topo</kbd> and use the EPSG:3857 spatial reference (the one used in the original shapefile):</li>
</ol>
<pre><strong>      postgis_cookbook=# SELECT CreateTopology('hu_topo', 3857);</strong></pre>
<ol start="3">
<li>Note how a record has been added to the <kbd>topology.topology</kbd> table in the following code:</li>
</ol>
<pre><strong>      postgis_cookbook=# SELECT * FROM topology.topology;</strong> </pre>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/907e7558-c19e-4349-a68f-c3372087b596.png" style="width:30.33em;height:4.75em;"/></div>
<pre><strong>      (1 rows)</strong> </pre>
<ol start="4">
<li>Also note that four tables and one view, which are needed for storing and managing the topology, have been generated in the schema named <kbd>hu_topo</kbd>, created from the <kbd>CreateTopology</kbd> function:</li>
</ol>
<pre><strong>      postgis_cookbook=# \dtv hu_topo.*</strong> </pre>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-202 image-border" src="assets/57fcdf33-578f-49f7-98a0-8b5ab182a381.png" style="width:44.50em;height:22.25em;"/></div>
<pre><strong>      (5 rows)</strong></pre>
<ol start="5">
<li>Check the initial information for the created topology using the <kbd>topologysummary</kbd> function, as follows; still, none of the topologic entities (nodes, edges, faces, and so on) are initialized:</li>
</ol>
<pre><strong>      postgis_cookbook=# SELECT topologysummary('hu_topo');</strong> </pre>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/02280017-3cd2-4ad0-8b3f-7af9cd4bfa24.png" style="width:13.00em;height:7.50em;"/></div>
<pre><strong>       (1 row) </strong></pre>
<ol start="6">
<li>Create a new PostGIS table as follows for storing the topological administrative boundaries:</li>
</ol>
<pre><strong>      postgis_cookbook=# CREATE TABLE<br/>        chp03.hu_topo_polygons(gid serial primary key, name_1 varchar(75));</strong> </pre>
<ol start="7">
<li>Add a topological geometry column to this table as follows, using the <kbd>AddTopoGeometryColumn</kbd> function:</li>
</ol>
<pre><strong>      postgis_cookbook=# SELECT <br/>        AddTopoGeometryColumn('hu_topo', 'chp03', 'hu_topo_polygons', <br/>       'the_geom_topo', 'MULTIPOLYGON') As layer_id;</strong> </pre>
<ol start="8">
<li>Insert the polygons from the non-topological <kbd>hungary</kbd> spatial table to the topological table, using the <kbd>toTopoGeom</kbd> function:</li>
</ol>
<pre><strong>      postgis_cookbook=&gt; INSERT INTO <br/>      chp03.hu_topo_polygons(name_1, the_geom_topo) 
        SELECT name_1, toTopoGeom(the_geom, 'hu_topo', 1) 
        FROM chp03.hungary; 
        Query returned successfully: 20 rows affected,<br/>                                     10598 ms execution time.</strong></pre>
<ol start="9">
<li>Now run the following code to check out how the content of the topology schema has been modified by the <kbd>toTopoGeom</kbd> function; you would expect to have 20 faces, one for each Hungarian administrative area, but instead there are 92:</li>
</ol>
<pre><strong>      postgis_cookbook=# SELECT topologysummary('hu_topo');</strong></pre>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/698f067b-bfbd-4c6e-bf65-5fdb46f8167e.png" style="width:15.67em;height:8.92em;"/></div>
<ol start="10">
<li>The problem is easily identifiable by analyzing the <kbd>hu_topo.face</kbd> table or using a desktop GIS. If you sort the polygons from this table by area, using the <kbd>ST_Area</kbd> function, you will notice after the details of the first polygon, which has 1 null area (used by the topology screenshot in the next step) and 20 large areas (each representing one administrative area), that there are 77 very small polygons generated by topological anomalies (polygon overlaps and holes):</li>
</ol>
<pre><strong>      postgis_cookbook=# SELECT row_number() OVER <br/>      (ORDER BY ST_Area(mbr) DESC) as rownum, ST_Area(mbr)/100000 <br/>      AS area FROM hu_topo.face ORDER BY area DESC;</strong> </pre>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/167416ff-d3a3-45e6-bb14-ec4a9a1bd452.png" style="width:14.00em;height:21.75em;"/></div>
<pre><strong>      (93 rows)</strong></pre>
<ol start="11">
<li>You can eventually look at the built topology elements (nodes, edges, faces, and topological geometries, or topogeoms) using a desktop GIS. The following screenshot shows how they look in QGIS:</li>
</ol>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/85c159b9-4d66-4148-a1ca-326b71643541.png" style="width:47.58em;height:20.50em;"/></div>
<ol start="12">
<li>Now you will rebuild the topology using a small tolerance value—1 meter—as an additional parameter to the <kbd>CreateTopology</kbd> function, in order to get rid of the unnecessary faces (the tolerance will collapse the vertex together, eliminating the small polygons). First, drop your topology schema with the <kbd>DropTopology</kbd> function and the topological table with the <kbd>DROP TABLE</kbd> command, and rebuild both of them using a topology tolerance of 1 meter, as follows:</li>
</ol>
<pre><strong>      postgis_cookbook=# SELECT DropTopology('hu_topo'); 
      postgis_cookbook=# DROP TABLE chp03.hu_topo_polygons; 
      postgis_cookbook=# SELECT CreateTopology('hu_topo', 3</strong><strong>857, 1); 
      postgis_cookbook=# CREATE TABLE chp03.hu_topo_polygons(</strong><br/><strong>        gid serial primary key, name_1 varchar(75)); 
      postgis_cookbook=# SELECT AddTopoGeometryColumn('hu_topo',<br/></strong>        <strong>'chp03', 'hu_topo_polygons', 'the_geom_topo',<br/></strong>        <strong>'MULTIPOLYGON') As layer_id; 
      postgis_cookbook=# INSERT INTO <br/>      chp03.hu_topo_polygons(name_1, the_geom_topo) 
        SELECT name_1, toTopoGeom(the_geom, 'hu_topo', 1) 
        FROM chp03.hungary;</strong></pre>
<ol start="13">
<li>Now, if you check the information related to the topology using the <kbd>topologysummary</kbd> function as follows, you can see that there is one face per administrative boundary and the previous 72 faces generated by topological anomalies have been eliminated, leaving only 20:</li>
</ol>
<pre><strong>      postgis_cookbook=# SELECT topologysummary('hu_topo'); </strong></pre>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/d75f81c3-2397-441c-90d1-15e22c38b671.png" style="width:16.42em;height:9.92em;"/></div>
<pre><strong>      (1 row)</strong> </pre>
<ol start="14">
<li>Finally, simplify the polygons of the <kbd>topo_polygons</kbd> table using a tolerance of 500 meters, as follows:</li>
</ol>
<pre><strong>      postgis_cookbook=# SELECT ST_ChangeEdgeGeom('hu_topo',</strong><br/><strong>        edge_id, ST_SimplifyPreserveTopology(geom, 500)) 
        FROM hu_topo.edge;</strong> </pre>
<ol start="15">
<li>Now it's time to update the original <kbd>hungary</kbd> table using a join with the <kbd>hu_topo_polygons</kbd> table by running the following commands:</li>
</ol>
<pre><strong>      postgis_cookbook=# UPDATE chp03.hungary hu 
        SET the_geom = hut.the_geom_topo 
        FROM chp03.hu_topo_polygons hut 
        WHERE hu.name_1 = hut.name_1;</strong></pre>
<ol start="16">
<li>The simplification process should have worked smoothly and produced a valid topological dataset. The following screenshot shows how the reduced topology looks (in red) compared to the original one (in black):</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="assets/e9fdda00-3e16-4eb9-9adb-cd9aba73f140.png" style="font-size: 1em;width:18.83em;height:11.75em;"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>We created a new PostGIS topology schema using the <kbd>CreateTopology</kbd> function. This function creates a new PostgreSQL schema where all the topological entities are stored.</p>
<p>We can have more topological schemas within the same spatial database, each being contained in a different PostgreSQL schema. The PostGIS <kbd>topology.topology</kbd> table manages all the metadata for all the topological schemas.</p>
<p>Each topological schema is composed of a series of tables and views to manage the topological entities (such as edge, edge data, face, node, and topogeoms) and their relations.</p>
<p>We can have a quick look at the description of a single topological schema using the <kbd>topologysummary</kbd> function, which summarizes the main metadata information-name, SRID, and precision; the number of nodes, edges, faces, topogeoms, and topological layers; and, for each topological layer, the geometry type, and the number of topogeoms.</p>
<p>After creating the topology schema, we created a new PostGIS table and added to it a topological geometry column (<kbd>topogeom</kbd> in PostGIS topology jargon) using the <kbd>AddTopoGeometryColumn</kbd> function.</p>
<p>We then used the <kbd>ST_ChangeEdgeGeom</kbd> function to alter the geometries for the topological edges, using the <kbd>ST_SimplifyPreserveTopology</kbd> function, with a tolerance of 500 meters, and checked that this function, used in the context of a topological schema, produces topologically correct results for polygons too.</p>


            </article>

            
        </section>
    </body></html>