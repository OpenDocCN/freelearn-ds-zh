<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Developing Applications Using the Cloud</h1>
                </header>
            
            <article>
                
<p><span>In the early days of computing, CPU power and storage were very scarce, and so the cost of purchasing relevant equipment was very high. With the advances in the development of personal computing in the early 80s by Apple and Microsoft, more and more individuals and organizations have gained access to these computing devices. As the industry has developed the way chips are made and billions if not trillions of transistors are now put on single chips, the size of these computing devices has drastically reduced, from taking up entire rooms to comprising a single unit of a rack in the data center. When the computation speed and storage device capacity started increasing, individuals and enterprises started to realize that efficiently managing their computing resources was becoming a challenge.</span><br/></p>
<p>The <span>widespread use</span> of the internet has also made a significant contribution to how individuals can access resources.</p>
<p>In this chapter, we will cover the following topics:</p>
<ul>
<li>What is the Cloud?</li>
<li>Available technologies in the Cloud</li>
<li>Planning Cloud infrastructure
<ul style="padding-left: 1px">
<li>High availability in the Cloud</li>
<li>Business continuity planning in the Cloud</li>
<li>Security in the Cloud</li>
</ul>
</li>
<li>Building a Hadoop cluster in the Cloud</li>
<li>Cloud and in-house applications</li>
<li>Data access in the Cloud</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">What is the Cloud?</h1>
                </header>
            
            <article>
                
<p>Cloud computing, or simply the Cloud, is a simple way to rent and use resources such as electronic storage space, computing power, network bandwidth, IP addresses, databases, web servers, and so on, on the internet. The Cloud has promoted the <em>pay per use</em> paradigm, where customers are only billed for the use of these resources, in the same way that a power grid bills its customers for their power consumption.</p>
<p>Cloud computing has transformed the way individuals and organizations access and manage their servers and applications on the internet. Before Cloud computing, everyone used to manage their servers and applications on their own premises or in dedicated data centers. The increase in the raw computing power of computing (CPU and GPU) of multiple-cores on a single chip and the increase in the storage space (HDD and SSD) present challenges in efficiently utilizing the available computing resources.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Available technologies in the Cloud</h1>
                </header>
            
            <article>
                
<p>With the increased adoption of Cloud computing, enterprises have started building a variety of technologies and making them available to consumers. We will go through the list of organizations that have pioneered Cloud offerings, and also the different types of technologies they offer.</p>
<p>Here is a list of companies that offer Cloud services:</p>
<ul>
<li> Microsoft Azure (Azure)</li>
<li> Amazon Web Services</li>
<li> Google Cloud Platform</li>
<li> IBM</li>
<li> Salesforce</li>
<li> SAP</li>
<li> Oracle</li>
<li> VMware</li>
</ul>
<p>Various types of resources are being offered to the consumers in the form of:</p>
<ul>
<li>Platform as a Service</li>
<li>Infrastructure as a Service</li>
<li>Software as a Service</li>
<li>Backend as a Service</li>
<li>Network as a Service</li>
</ul>
<p>With the increase in offerings such as these, many organizations need not focus on the infrastructure such as real estate, servers, firewalls, load balancers, switches, power supply, and so on. But they can instead just purchase these services from Cloud providers, and then just focus on what applications they are building.</p>
<p>Now, let's see what technologies are provided by the top providers, Microsoft, Amazon, and Google:</p>
<div>
<table>
<tbody>
<tr>
<td>
<p><strong>Technology</strong></p>
</td>
<td>
<p><strong>Azure</strong></p>
</td>
<td>
<p><strong>Amazon Web Services</strong></p>
</td>
<td>
<p><strong>Google Cloud</strong></p>
</td>
<td>
<p><strong>Description</strong></p>
</td>
</tr>
<tr>
<td>
<p>Servers</p>
</td>
<td>
<p>Azure compute</p>
</td>
<td>
<p>Amazon EC2</p>
</td>
<td>
<p><strong>Google Compute Engine</strong> (<strong>GCE</strong>)</p>
</td>
<td>
<p>This technology deals with providing servers that are on demand and that can be virtualized or dedicated/baremetal in nature.</p>
</td>
</tr>
<tr>
<td>
<p>Storage</p>
</td>
<td>
<p>Azure storage</p>
</td>
<td>
<p>Amazon EBS</p>
</td>
<td>
<p>Google storage</p>
</td>
<td>
<p>This is on-demand storage that can be attached to the compute nodes as needed. Some vendors provide the ability to scale the size of these storage devices on demand.</p>
</td>
</tr>
<tr>
<td>
<p>Network</p>
</td>
<td>
<p>Azure networking</p>
</td>
<td>
<p>Yes</p>
</td>
<td>
<p>Google network services</p>
</td>
<td>
<p>Providers supply network bandwidth from 100 Mbps to 10 Gbps, depending on the network requirements of the applications.</p>
</td>
</tr>
<tr>
<td>
<p>Databases</p>
</td>
<td>
<p>Azure databases</p>
</td>
<td>
<p>Amazon RDS</p>
</td>
<td>
<p>Google Cloud SQL</p>
</td>
<td>
<p>With managed databases, we need not worry about the maintenance of the database servers as the vendors take care of the support for these automatically. Bear in mind that, in some cases, we need to plan the high availability for ourselves.</p>
</td>
</tr>
<tr>
<td>
<p>Content delivery</p>
</td>
<td>
<p>Azure CDN</p>
</td>
<td>
<p>Amazon CloudFront</p>
</td>
<td>
<p>Google Cloud CDN</p>
</td>
<td>
<p>This is very helpful if we want to push our static assets to our users by leveraging the delivery network as it brings down the latency significantly. We can also use this as a private store to store all the files such as backups, conference recordings, and so on.</p>
</td>
</tr>
<tr>
<td>
<p><strong>Domain Name System</strong> (<strong>DNS</strong>)</p>
</td>
<td>
<p>Azure DNS</p>
</td>
<td>
<p>Amazon Route S3</p>
</td>
<td>
<p>Google Cloud DNS</p>
</td>
<td>
<p>DNS is critical in running our applications on the internet. This service makes our life easier by taking care of making our servers accessible to the rest of the infrastructure, without having to run our own DNS servers.</p>
</td>
</tr>
<tr>
<td>
<p>Business mail</p>
</td>
<td>
<p>Microsoft o365</p>
</td>
<td>
<p>Amazon WorkMail</p>
</td>
<td>
<p>Google Mail</p>
</td>
<td>
<p>This is a must-have for organizations that demand access to emails and calendaring in a secure and scalable fashion.</p>
</td>
</tr>
<tr>
<td>
<p>Machine learning</p>
</td>
<td>
<p>Azure AI + machine learning</p>
</td>
<td>
<p>Amazon machine learning</p>
</td>
<td>
<p>Google ML Engine</p>
</td>
<td>
<p>Machine learning technology has become the buzzword these days. Vendors are offering several technologies that are related to machine learning, as we just have to focus on what we need to do, rather than worrying about the infrastructure that needs to run these algorithms.</p>
</td>
</tr>
<tr>
<td>
<p><strong>Distributed Denial of Service</strong> (<strong>DDoS</strong>) Protection</p>
</td>
<td>
<p>Azure DDoS Protection</p>
</td>
<td>
<p>AWS Shield</p>
</td>
<td>–</td>
<td>
<p>This is a very important thing to have for organizations that cannot afford to have downtime for their services and when large-scale denial of service attacks happen that impact regular visitors of their sites.</p>
</td>
</tr>
<tr>
<td>
<p>Monitoring</p>
</td>
<td>
<p>Azure Monitor</p>
</td>
<td>
<p>Amazon CloudWatch</p>
</td>
<td>
<p>Google monitoring</p>
</td>
<td>
<p>Without monitoring our applications and infrastructure, we can <span>fail to see how we are performing</span>. These services help us keep our business on track and to respond to events that trigger downtime of our applications, and infrastructure that runs on the Cloud.</p>
</td>
</tr>
<tr>
<td>
<p>Containers</p>
</td>
<td>
<p><strong>Azure Container Service</strong> (<strong>AKS</strong>)</p>
</td>
<td>
<p><strong>Amazon Elastic Container Service For Kubernetes</strong> (<strong>Amazon EKS</strong>)</p>
</td>
<td>
<p>Google Kubernetes Engine</p>
</td>
<td>
<p>This is infrastructure that allows you to run applications as containers, rather than owning full compute environments to run them.</p>
</td>
</tr>
</tbody>
</table>
</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Planning the Cloud infrastructure</h1>
                </header>
            
            <article>
                
<p>Traditional organizations have their own IT/infrastructure teams to manage their dedicated servers and network. When planning migration to the Cloud, we have to keep the following things in mind for better operability of the infrastructure.</p>
<p>Planning the Cloud infrastructure deals with:</p>
<ul>
<li>Dedicated or shared servers</li>
<li>High availability</li>
<li>Business continuity planning</li>
<li>Security</li>
<li>Network architecture</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Dedicated servers versus shared servers</h1>
                </header>
            
            <article>
                
<p>Cloud providers give you the option of renting servers that completely own the physical hardware or share the physical hardware with other Cloud users like us. In order to reach a decision on this, we need to understand the advantages and disadvantages of each of these models.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Dedicated servers</h1>
                </header>
            
            <article>
                
<p>These are the type of servers where the type of ownership belongs to a single user or an organization and is not shared with any other user. There are several advantages to this setup, as follows:</p>
<ul>
<li>We completely own the physical server and any further servers that we allocate will be provisioned on the same hardware</li>
<li>We might be billed more for this kind of setup</li>
<li>With Spectre and Meltdown, we are better protected as the hardware is not shared with anyone</li>
<li>We are not impacted by the neighbors as we completely own the hardware</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Shared servers</h1>
                </header>
            
            <article>
                
<p>Owning a complete server is expensive for simple experimentation. In this scenario, we can go for a shared setup where we rent a few resources in a given physical hardware. Some advantages of shared servers are as follows:</p>
<ul>
<li>We are billed only for the virtual servers that we rent on demand.</li>
<li>Even though Cloud vendors provide absolute isolation, with Spectre and Meltdown, we need to be a bit careful.</li>
<li>Easier to provision than dedicated servers.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">High availability</h1>
                </header>
            
            <article>
                
<p>Depending on the type of applications we are planning to run, we have to understand the <strong>service-level agreement</strong> (<strong>SLA</strong>) that is provided by the vendors for these applications in terms of uptime, and we need to plan our applications accordingly.</p>
<p>Let's look at a simple way of using DNS to achieve high availability of our application:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/2453572e-9d3c-45bc-9c39-7de4c295c2da.png" style="width:25.67em;height:25.67em;"/></div>
<p>In this design, the following things happen:</p>
<ul>
<li>When the user tries to connect to our website using a web browser such as Google Chrome or Firefox, it first tries to contact the DNS server</li>
<li>The DNS server is aware of our frontend servers and returns a list of all the servers</li>
<li>The browser will connect to the frontend server directly</li>
<li>The frontend server connects to the database and returns the requested resource</li>
</ul>
<p>In this design, we need to keep the following things in mind:</p>
<ul>
<li>Frontend servers are directly exposed to the internet, so we should have proper security measures in place such as a firewall or DDos protection to protect our servers</li>
<li>These frontend servers should also be patched with the latest OS software so that any attacks can be prevented</li>
<li>A database server should not be visible to the outside world, so an appropriate firewall should be in place to allow requests from the frontend servers</li>
</ul>
<div class="packt_tip">Cloud providers provide a private IP address. In order to minimize the risk of DB servers being accidentally exposed to the internet, we should block the public internet access to these servers.</div>
<p>Let's look at another design that also keeps our web servers secure from attacks on the internet:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/5b0eedd5-c5ab-454d-8b22-955ceec11684.png" style="width:28.42em;height:28.42em;"/></div>
<p>In this design, we have made the following changes when compared to the previous one:</p>
<ul>
<li>When the <strong>Browser</strong> contacts the <strong>DNS</strong> server to connect to our website, the <strong>DNS</strong> server supplies the IP address of the <strong>Load Balancer</strong> (<strong>LB</strong>)/proxy server</li>
<li>The browser connects to this <strong>LB</strong></li>
<li>The <strong>LB</strong> keeps track of which of the backend servers are available and then forwards the request to the server:
<ul>
<li>The server talks to the <strong>database</strong> (<strong>DB</strong>) and finishes building the response</li>
<li>The response is sent back to the <strong>LB</strong></li>
</ul>
</li>
<li>The <strong>LB</strong> sends the response to the <strong>Browser</strong></li>
</ul>
<p>If we look at this design carefully, we will see that these are the advantages over the previous one:</p>
<ul>
<li>The <strong>LB</strong> hides our infrastructure, so outsiders cannot easily know how many servers are there in our infrastructure</li>
<li>The <strong>LB</strong> protects our web servers from several attacks</li>
<li>The <strong>LB</strong> can do SSL offloading where all the encryption/decryption of traffic happens at the <strong>LB</strong> level and our servers can be free from the SSL overhead</li>
</ul>
<div class="packt_tip packt_infobox">Depending on the security policy of the organization, you might need to enable SSL on the web servers as well.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Business continuity planning</h1>
                </header>
            
            <article>
                
<p><strong>Business continuity planning</strong> (<strong>BCP</strong>) is a very important thing to consider when the organization is in its growth phase. Any downtime of the network, servers or databases, or any other Cloud infrastructure components can bring down the whole business.</p>
<p>There are several key things to keep in mind when planning for BCP:</p>
<ul>
<li>Infrastructure unavailability</li>
<li>Natural disasters</li>
<li>Business data</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Infrastructure unavailability</h1>
                </header>
            
            <article>
                
<p>If there is an unplanned outage of the services provided by the Cloud provider, it will take down all our services with it. In order to maximize the availability of our business, we need to build a backup setup in another geographical region. This might be expensive for some organizations as the entire setup is going to be duplicated, but in the interest of business continuity, this is an important feature to consider when planning the Cloud infrastructure.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Natural disasters</h1>
                </header>
            
            <article>
                
<p>Events such as earthquakes, floods, fire accidents, and so on are hard to predict. We therefore need<span> to make the necessary plans to keep our business running, </span><span>depending on where our servers are located on the Cloud, and on what technology standards are followed by the vendors for the data center build-out. </span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Business data</h1>
                </header>
            
            <article>
                
<p>Business data exists in several forms and is stored in the form of files, database servers, and big data systems. For BCP, we need to carefully analyze in what other remote locations we can plan to keep the copies of our data, and carry out test runs to see if our applications can be seamlessly run from either of the geographical locations with a single click of a button.</p>
<p>As we are dealing with multiple geographies here, we need to understand that, when the volume of data is huge, it takes time for things to get replicated from one data center to another. Our applications must also be redesigned in case we did not consider BCP in the original design.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">BCP design example</h1>
                </header>
            
            <article>
                
<p>This diagram tries to explain how we can achieve BCP by setting up the same applications in multiple data centers:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/f38b78bf-633e-44d1-ba17-e4b5ae996a45.png" style="width:25.58em;height:26.75em;"/></div>
<p>The system can be either:</p>
<ul>
<li>Hot–Hot</li>
<li>Hot–Cold</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The Hot–Hot system</h1>
                </header>
            
            <article>
                
<p>In the Hot-Hot system, both the data centers are active at the same time and serve the user's traffic. Here, we employ several CDN and geolocation techniques to route the user to a given data center.</p>
<p>The challenge we face in doing so is that i<span>f one region goes completely blank, the other region should have enough headroom to ensure that traffic for the other region is absorbed</span></p>
<p>The advantage of employing this system is that th<span>e user experience is a good one, as in this design the users are routed to the nearest system</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The Hot–Cold system</h1>
                </header>
            
            <article>
                
<p>In this system/design, only one of the regions is active at any time and only in the event of BCP (Business Continuity Planning) do we fall back to the other region.</p>
<p>The challenges we face in using this system are as follows:<strong><br/></strong></p>
<ul>
<li>It's easy to forget the other region until the problem comes into play; it's very important to keep using both the regions in sync w.r.t both Data &amp; Software on a continuous basis.</li>
<li>As only one region is active, the correct failover of users to another data center has to be thought through well</li>
</ul>
<p>The advantage of employing this system is that a<span>ll the writes happen in one region which keeps database designs simple.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Security</h1>
                </header>
            
            <article>
                
<p>Security is very important when you consider moving to the Cloud. The following are the things to keep in mind:</p>
<ul>
<li>Server security</li>
<li>Application security</li>
<li>Network security</li>
<li>Single Sign On</li>
<li>AAA requirements</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Server security</h1>
                </header>
            
            <article>
                
<p>As we are talking about the Cloud, we will never be able to access the servers physically (unless we get permission from the Cloud vendors). In such a scenario, we have to understand what level of policies and practices are followed by the Cloud providers to ensure the physical security of the servers on which our applications are going to be run.</p>
<p>For example, governments might need a whole set of different physical security restrictions when considering a move to the Cloud. On the same lines, there are several standards such as PCI and HIPAA which enforce even stronger rules on this model.</p>
<p>If our business needs to adhere to these standards, we need to choose the Cloud variant which supports all these.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Application security</h1>
                </header>
            
            <article>
                
<p>On the Cloud, we can either choose to host the applications on our own or use the applications provided as a service <strong>Software As A Service </strong>(<strong>SaaS</strong>). If we are hosting the applications on our own provisioned servers (either dedicated or shared), we need to enforce the correct firewall rules at server level, and also the correct user access rules to make sure that our software allows only authorized and properly authenticated users.</p>
<p>If the applications are internal, we should ensure that our employees are given 2FA or 3FA methods to log in to these services.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Network security</h1>
                </header>
            
            <article>
                
<p>In order to safeguard our servers on the Cloud, we need to enforce proper firewall rules, DNS zones, or even have our own virtual private networks to make sure all our assets are not compromised and exposed to the internet.</p>
<p>The Cloud is synonymous with the internet and there is a continuous threat to our data and infrastructure. Unless we enforce proper security measures, everything is wide open for everyone to grab whatever they like from our systems.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Single Sign On</h1>
                </header>
            
            <article>
                
<p><strong>Single Sign On</strong> (<strong>SSO</strong>) has become popular with organizations that use several applications on the Cloud for various departments. Lately, organizations have stopped building their own applications for running businesses and instead have started adopting the use of other services. When the number of such applications increases, users of these applications are constantly faced with the challenge of entering their usernames and passwords in all these websites.</p>
<p>In order to provide a seamless browsing experience, and at the same time adhere to enterprise security standards, many providers implement OAuth and SAML, as they are industry recognized.</p>
<p>These SSO/identity providers integrate with the corporate employee database to further assimilate the Cloud applications for the enterprise, as depicted here:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/78e306af-80ce-4681-b780-11abbf12d611.png" style="width:22.08em;height:31.25em;"/></div>
<p>This design tries to explain how organizations are leveraging SSO using identity providers:</p>
<ul>
<li>Organizations share the employee and organization details with the identity provider:
<ul style="padding-left: 1px">
<li>Passwords may or may not be shared as it can compromise the entire organization if there is a breach</li>
<li>SSO systems can enforce their own passwords on the employees</li>
</ul>
</li>
<li>When the user tries to open any of the applications in the organization, it redirects the user to the SSO provider</li>
<li>The SSO provider completes the authentication and shares necessary credentials with the application</li>
<li>The application authorizes the user based on the feedback from the SSO</li>
<li>The application opens the user specific details and then the user can interact with the application</li>
</ul>
<p>Now, the biggest advantage of these SSOs is that once the user has established a session with the system, they can log in to other corporate-approved applications without further logins.</p>
<p>Confidentiality is the biggest challenge when interacting with SSO providers, so organizations should carefully evaluate and pick the right solution that meets their security requirements.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The AAA requirement</h1>
                </header>
            
            <article>
                
<p>When it comes to security, it is important to understand that applications following the AAA standard will take care of many challenges that enterprises face.</p>
<p>The AAA standard deals with:</p>
<ul>
<li>Authentication</li>
<li>Authorization</li>
<li>Auditing</li>
</ul>
<p><strong>Authentication</strong> makes sure that the identity of the user is properly validated.</p>
<p><strong>Authorization</strong> further controls whether a given user is allowed to access certain resources or not, as per company policies.</p>
<p><strong>Auditing</strong> makes sure that all attempts to access and use the resources are tracked—this can also be used in case of any investigation, and provide proper accounting and billing (if needed).</p>
<p>By following these best practices, we can be sure that things run smoothly on a large scale.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Building a Hadoop cluster in the Cloud</h1>
                </header>
            
            <article>
                
<p>We saw earlier that the Cloud offers a flexible and easy way to rent resources such as servers, storage, networking, and so on. The Cloud has made it very easy for consumers with the pay-as-you-go model, but much of the complexity of the Cloud is hidden from us by the providers.</p>
<p>In order to better understand whether Hadoop is well suited to being on the Cloud, let's try to dig further and see how the Cloud is organized internally.</p>
<p>At the core of the Cloud are the following <span>mechanisms</span>:</p>
<ul>
<li>A very large number of servers with a variety of hardware configurations</li>
<li>Servers connected and made available over IP networks</li>
<li>Large data centers to host these devices</li>
<li>Data centers spanning geographies with evolved network and data center designs</li>
</ul>
<p>If we pay close attention, we are talking about the following:</p>
<ul>
<li>A very large number of different CPU architectures</li>
<li>A large number of storage devices with a variety of speeds and performance</li>
<li>Networks with varying speed and interconnectivity</li>
</ul>
<p>Let's look at a simple design of such a data center on the Cloud:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/7249b0f3-3d7d-40e8-8853-6d9f3b916f57.png" style="width:31.75em;height:28.33em;"/></div>
<p>We have the following devices in the preceding diagram:</p>
<ul>
<li><strong>S1</strong>, <strong>S2</strong>: Rack switches</li>
<li><strong>U1-U6</strong>: Rack servers</li>
<li><strong>R1</strong>: Router</li>
<li>Storage area network</li>
<li>Network attached storage</li>
</ul>
<p>As we can see, Cloud providers have a very large number of such architectures to make them scalable and flexible.</p>
<p>You would have rightly guessed that when the number of such servers increases and when we request a new server, the provider can allocate the server anywhere in the region.</p>
<p>This makes it a bit challenging for compute and storage to be together but also provides elasticity.</p>
<p>In order to address this co-location problem, some Cloud providers give the option of creating a virtual network and taking dedicated servers, and then allocating all their virtual nodes on these servers. This is somewhat closer to a data center design, but flexible enough to return resources when not needed.</p>
<p>Let's get back to Hadoop and remind ourselves that in order to get the best from the Hadoop system, we should have the CPU power closer to the storage. This means that the physical distance between the CPU and the storage should be much less, as the BUS speeds match the processing requirements.</p>
<p>The slower the I/O speed between the CPU and the storage (for example, iSCSI, storage area network, network attached storage, and so on) the poorer the performance we get from the Hadoop system, as the data is being fetched over the network, kept in memory, and then fed to the CPU for further processing.</p>
<p>This is one of the important things to keep in mind when designing Hadoop systems on the Cloud.</p>
<p>Apart from performance reasons, there are other things to consider:</p>
<ul>
<li>Scaling Hadoop</li>
<li>Managing Hadoop</li>
<li>Securing Hadoop</li>
</ul>
<p>Now, let's try to understand how we can take care of these in the Cloud environment.</p>
<p>In the previous chapters, we saw that Hadoop can be installed by the following methods:</p>
<ul>
<li>Standalone</li>
<li>Semi-distributed</li>
<li>Fully-distributed</li>
</ul>
<p>When we want to deploy Hadoop on the Cloud, we can deploy it using the following ways:</p>
<ul>
<li>Custom shell scripts</li>
<li>Cloud automation tools (Chef, Ansible, and so on)</li>
<li>Apache Ambari</li>
<li>Cloud vendor provided methods
<ul>
<li>Google Cloud Dataproc</li>
<li>Amazon EMR</li>
<li>Microsoft HDInsight</li>
</ul>
</li>
<li>Third-party managed Hadoop
<ul>
<li>Cloudera</li>
</ul>
</li>
<li>Cloud agnostic deployment
<ul>
<li>Apache Whirr</li>
</ul>
</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Google Cloud Dataproc</h1>
                </header>
            
            <article>
                
<p>In this section, we will learn how to use Google Cloud Dataproc to set up a single node Hadoop cluster.</p>
<p>The steps can be broken down into the following:</p>
<ol>
<li>Getting a Google Cloud account.</li>
<li>Activating Google Cloud Dataproc service.</li>
<li>Creating a new Hadoop cluster.</li>
<li>Logging in to the Hadoop cluster.</li>
<li>Deleting the Hadoop cluster.</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting a Google Cloud account</h1>
                </header>
            
            <article>
                
<p>This section assumes that you already have a Google Cloud account.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Activating the Google Cloud Dataproc service</h1>
                </header>
            
            <article>
                
<p>Once you log in to the Google Cloud console, you need to visit the Cloud Dataproc service. The activation screen looks something like this:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/cdc979f6-3c6e-4095-b231-d34503e1c15d.png"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating a new Hadoop cluster</h1>
                </header>
            
            <article>
                
<p>Once the Dataproc is enabled in the project, we can click on <span class="packt_screen">Create</span> to create a new Hadoop cluster.</p>
<p>After this, we see another screen where we need to configure the cluster parameters:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/42776c3a-8028-45d1-9dff-35c144ccd06f.png" style="width:39.17em;height:44.92em;"/></div>
<p>I have left most of the things to their default values. Later, we can click on the <span class="packt_screen">Create</span> button which creates a new cluster for us.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Logging in to the cluster</h1>
                </header>
            
            <article>
                
<p>After the cluster has successfully been created, we will automatically be taken to the cluster lists page. From there, we can launch an SSH window to log in to the single node cluster we have created.</p>
<p>The SSH window looks something like this:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/ece46992-7e51-4f97-8f3a-abeb7eb53fd7.png"/></div>
<p>As you can see, the Hadoop command is readily available for us and we can run any of the standard Hadoop commands to interact with the system.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Deleting the cluster </h1>
                </header>
            
            <article>
                
<p>In order to delete the cluster, click on the <span class="packt_screen">DELETE</span> button and it will display a confirmation window, as shown in the following screenshot. After this, the cluster will be deleted:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/40147432-7be4-40e8-b92d-2b1d93fdc579.png"/></div>
<p>Looks so simple, right? Yes. Cloud providers have made it very simple for users to use the Cloud and pay only for the usage.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Data access in the Cloud</h1>
                </header>
            
            <article>
                
<p>The Cloud has become an important destination for storing both personal data and business data. Depending upon the importance and the secrecy requirements of the data, organizations have started using the Cloud to store their vital datasets.</p>
<p>The following diagram tries to summarize the various access patterns of typical enterprises and how they leverage the Cloud to store their data:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/5aac2568-d830-4030-b6a7-33e862a81841.png" style="width:27.75em;height:38.33em;"/></div>
<p>Cloud providers offer different varieties of storage. Let's take a look at what these types are:</p>
<ul>
<li>Block storage</li>
<li>File-based storage</li>
<li>Encrypted storage</li>
<li>Offline storage</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Block storage</h1>
                </header>
            
            <article>
                
<p>This type of storage is primarily useful when we want to use this along with our compute servers, and want to manage the storage via the host operating system.</p>
<p>To understand this better, this type of storage is equivalent to the hard disk/SSD that comes with our laptops/MacBook when we purchase them. In case of laptop storage, if we decide to increase the capacity, we need to replace the existing disk with another one.</p>
<p>When it comes to the Cloud, if we want to add more capacity, we can just purchase another larger capacity storage and attach it to our server. This is one of the reasons why the Cloud has become popular as it has made it very easy to add or shrink the storage that we need.</p>
<p>It's good to remember that, since there are many different types of access patterns for our applications, Cloud vendors also offer block storage with varying storage/speed requirements measured with their own capacity/IOPS, and so on.</p>
<p>Let's take an example of this capacity upgrade requirement and see what we do to utilize this block storage on the Cloud.</p>
<p>In order to understand this, let's look at the example in this diagram:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/777ebbd9-e267-476d-ac5d-621ecf0ac461.png" style="width:23.25em;height:15.42em;"/></div>
<p>Imagine a server <span>created by the administrator </span><span>called</span> <strong>DB1</strong><span> with an </span><span>original capacity of <strong>100 GB</strong></span>. <span>Later, due to unexpected demand from customers, an application started consuming all the</span> <strong>100 GB</strong> <span>of storage, so the administrator has decided to increase the capacity to</span> <strong>1 TB</strong> <span>(1,024 GB).</span></p>
<p>This is what the workflow looks like in this scenario:</p>
<ol>
<li>Create a new 1 TB disk on the Cloud</li>
<li>Attach the disk to the server and mount it</li>
<li>Take a backup of the database</li>
<li>Copy the data from the existing disk to the new disk</li>
<li>Start the database</li>
<li>Verify the database</li>
<li>Destroy the data on the old disk and return the disk</li>
</ol>
<p>This process is simplified but in production this might take some time, depending upon the type of maintenance that is being performed by the administrator. But, from the Cloud perspective, acquiring new block storage is very quick.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">File storage</h1>
                </header>
            
            <article>
                
<p>Files are the basics of computing. If you are familiar with UNIX/Linux environments, you already know that, <em>everything is a file</em> in the Unix world. But don't get confused with that as every operating system has its own way of dealing with hardware resources. In this case we are not worried about how the operating system deals with hardware resources, but we are talking about the important documents that the users store as part of their day-to-day business.</p>
<p>These files can be:</p>
<ul>
<li>Movie/conference recordings</li>
<li>Pictures</li>
<li>Excel sheets</li>
<li>Word documents</li>
</ul>
<p>Even though they are simple-looking files in our computer, they can have significant business importance and should be dealt with in a careful fashion, when we think of storing these on the Cloud.</p>
<p>Most Cloud providers offer an easy way to store these simple files on the Cloud and also offer flexibility in terms of security as well.</p>
<p>A typical workflow for acquiring the storage of this form is like this:</p>
<ol>
<li>Create a new storage bucket that's uniquely identified</li>
<li>Add private/public visibility to this bucket</li>
<li>Add multi-geography replication requirement to the data that is stored in this bucket</li>
</ol>
<p>Some Cloud providers bill their customers based on the number of features they select as part of their bucket creation.</p>
<div class="packt_tip">Please choose a hard-to-discover name for buckets that contain confidential data, and also make them private.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Encrypted storage</h1>
                </header>
            
            <article>
                
<p>This is a very important requirement for business critical data as we do not want the information to be leaked outside the scope of the organization. Cloud providers offer an encryption at rest facility for us. Some vendors choose to do this automatically and some vendors also provide flexibility in letting us choose the encryption keys and methodology for the encrypting/decrypting data that we own. Depending upon the organization policy, we should follow best practices in dealing with this on the Cloud.</p>
<p>With the increase in the performance of storage devices, encryption does not add significant overhead while decrypting/encrypting files. This is depicted in the following image:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/85210543-a206-4255-990f-c6809daf8e82.png" style="width:25.25em;height:16.75em;"/></div>
<p>Continuing the same example as before, when we choose to encrypt the underlying block storage of <strong>1 TB,</strong> we can leverage the Cloud-offered encryption where they automatically encrypt and decrypt the data for us. So, we do not have to employ special software on the host operating system to do the encryption and decryption.</p>
<p>Remember that encryption can be a feature that's available in both the block storage and file-based storage offer from the vendor.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Cold storage</h1>
                </header>
            
            <article>
                
<p>This storage is very useful for storing important backups in the Cloud that are rarely accessed. Since we are dealing with a special type of data here, we should also be aware that the Cloud vendor might charge significantly high amounts for data access from this storage, as it's meant to be written once and forgetten (until it's needed). The advantage with this mechanism is that we have to pay lesser amounts to store even petabytes of data.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, <span>we looked at what Cloud computing means and saw how the Cloud has completely revolutionized how we can access and manage our servers and applications on the internet. We then walked through a list of different technologies offered on the Cloud by different providers.</span></p>
<p>We also learned how to plan our Cloud infrastructure and looked at the different steps involved in building our own Hadoop cluster on the Cloud. Finally, we saw different ways of storing and accessing our data on the Cloud.</p>
<p>In the next chapter we will take a look at some strategies and best practices to deploy your Hadoop cluster.</p>
<p> </p>


            </article>

            
        </section>
    </body></html>