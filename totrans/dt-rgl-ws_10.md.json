["```py\n    import random\n    ```", "```py\n    random_number_list = [random.randint(0, 100) \\\n                          for x in range(0, 100)]\n    ```", "```py\n    random_number_list\n    ```", "```py\n    list_with_divisible_by_3 = [a for a in \\\n                                random_number_list if a % 3 == 0]\n    list_with_divisible_by_3\n    ```", "```py\n    length_of_random_list = len(random_number_list)\n    length_of_3_divisible_list = len(list_with_divisible_by_3)\n    difference = length_of_random_list - length_of_3_divisible_list\n    difference\n    ```", "```py\n    71\n    ```", "```py\n    NUMBER_OF_EXPERIMENTS = 10\n    difference_list = []\n    for i in range(0, NUMBER_OF_EXPERIMENTS):\n        random_number_list = [random.randint(0, 100) \\\n                              for x in range(0, 100)]\n        list_with_divisible_by_3 = [a for a in random_number_list \\\n                                    if a % 3 == 0]\n\n        length_of_random_list = len(random_number_list)\n        length_of_3_divisible_list = len(list_with_divisible_by_3)\n        difference = length_of_random_list \\\n                     - length_of_3_divisible_list\n        difference_list.append(difference)\n    difference_list\n    ```", "```py\n    [64, 61, 67, 60, 73, 66, 66, 75, 70, 61]\n    ```", "```py\n    avg_diff = sum(difference_list) / float(len(difference_list))\n    avg_diff\n    ```", "```py\n    66.3\n    ```", "```py\n    type(multiline_text)\n    ```", "```py\n    str\n    ```", "```py\n    len(multiline_text)\n    ```", "```py\n    1228\n    ```", "```py\n    multiline_text = multiline_text.replace('\\n', \"\")\n    ```", "```py\n    multiline_text\n    ```", "```py\n    # remove special chars, punctuation etc.\n    cleaned_multiline_text = \"\"\n    for char in multiline_text:\n        if char == \" \":\n            cleaned_multiline_text += char\n        elif char.isalnum():  # using the isalnum() method of strings.\n            cleaned_multiline_text += char\n        else:\n            cleaned_multiline_text += \" \"\n    ```", "```py\n    cleaned_multiline_text\n    ```", "```py\n    list_of_words = cleaned_multiline_text.split()\n    list_of_words\n    ```", "```py\n    len(list_of_words)\n    ```", "```py\n    unique_words_as_dict = dict.fromkeys(list_of_words)\n    len(list(unique_words_as_dict.keys()))\n    ```", "```py\n    for word in list_of_words:\n        if unique_words_as_dict[word] is None:\n            unique_words_as_dict[word] = 1\n        else:\n            unique_words_as_dict[word] += 1\n    unique_words_as_dict\n    ```", "```py\n    top_words = sorted(unique_words_as_dict.items(), \\\n                       key=lambda key_val_tuple: key_val_tuple[1], \\\n                       reverse=True)\n    top_words[:25]\n    ```", "```py\n    from itertools import permutations, dropwhile\n    permutations?\n    dropwhile?\n    ```", "```py\n    permutations(range(3)) \n    ```", "```py\n    <itertools.permutations at 0x7f6c6c077af0>\n    ```", "```py\n    for number_tuple in permutations(range(3)):\n        print(number_tuple)\n        assert isinstance(number_tuple, tuple) \n    ```", "```py\n    (0, 1, 2)\n    (0, 2, 1)\n    (1, 0, 2)\n    (1, 2, 0)\n    (2, 0, 1)\n    (2, 1, 0)\n    ```", "```py\n    for number_tuple in permutations(range(3)):\n        print(list(dropwhile(lambda x: x <= 0, number_tuple))) \n    ```", "```py\n    [1, 2]\n    [2, 1]\n    [1, 0, 2]\n    [1, 2, 0]\n    [2, 0, 1]\n    [2, 1, 0]\n    ```", "```py\n    import math\n    def convert_to_number(number_stack):\n        final_number = 0\n        for i in range(0, len(number_stack)):\n            final_number += (number_stack.pop() \\\n                             * (math.pow(10, i)))\n        return final_number\n    for number_tuple in permutations(range(3)):\n        number_stack = list(dropwhile(lambda x: x <= 0, number_tuple))\n        print(convert_to_number(number_stack)) \n    ```", "```py\n    12.0\n    21.0\n    102.0\n    120.0\n    201.0\n    210.0\n    ```", "```py\n    from itertools import zip_longest \n    ```", "```py\n    def return_dict_from_csv_line(header, line):\n        # Zip them\n        zipped_line = zip_longest(header, line, fillvalue=None)\n        # Use dict comprehension to generate the final dict\n        ret_dict = {kv[0]: kv[1] for kv in zipped_line}\n        return ret_dict \n    ```", "```py\n    with open(\"csv file.\n    ```", "```py\n        first_line = fd.readline()\n        header = first_line.replace(\"\\n\", \"\").split(\",\")\n        for i, line in enumerate(fd):\n            line = line.replace(\"\\n\", \"\").split(\",\")\n            d = return_dict_from_csv_line(header, line)\n            print(d)\n            if i > 10:\n                break \n    ```", "```py\n    import numpy as np\n    import pandas as pd\n    import matplotlib.pyplot as plt\n    ```", "```py\n    df=pd.read_csv(\"../datasets/Boston_housing.csv\")\n    ```", "```py\n    df.head(10)\n    ```", "```py\n    df.shape\n    ```", "```py\n    (506, 14)\n    ```", "```py\n    df1=df[['CRIM','ZN','INDUS',\\\n            'RM','AGE','DIS','RAD',\\\n            'TAX','PTRATIO','PRICE']]\n    ```", "```py\n    df1.tail(7)\n    ```", "```py\n    for c in df1.columns:\n        plt.title(\"Plot of \"+c,fontsize=15)\n        plt.hist(df1[c],bins=20)\n        plt.show()\n    ```", "```py\n    plt.scatter(df1['CRIM'], df1['PRICE'])\n    plt.show()\n    ```", "```py\n    plt.scatter(np.log10(df1['CRIM']),df1['PRICE'], c='red')\n    plt.title(\"Crime rate (Log) vs. Price plot\", fontsize=18)\n    plt.xlabel(\"Log of Crime rate\",fontsize=15)\n    plt.ylabel(\"Price\",fontsize=15)\n    plt.grid(True)\n    plt.show()\n    ```", "```py\n    df1['RM'].mean()\n    ```", "```py\n    6.284634387351788\n    ```", "```py\n    df1['AGE'].median()\n    ```", "```py\n    77.5\n    ```", "```py\n    df1['DIS'].mean()\n    ```", "```py\n    3.795042687747034\n    ```", "```py\n    low_price=df1['PRICE']<20\n    print(low_price)\n    ```", "```py\n    # That many houses are priced below 20,000\\. \n    # So that is the answer. \n    low_price.mean()\n    ```", "```py\n    0.4150197628458498\n    ```", "```py\n    # You can convert that into percentage\n    # Do this by multiplying with 100\n    pcnt=low_price.mean()*100\n    print(\"\\nPercentage of house with <20,000 price is: \", pcnt)\n    ```", "```py\n    Percentage of house with <20,000 price is: 41.50197628458498\n    ```", "```py\n    import numpy as np\n    import pandas as pd\n    import matplotlib.pyplot as plt\n    ```", "```py\n    df = pd.read_csv(\"../datasets/adult_income_data.csv\")\n    df.head()\n    ```", "```py\n    names = []\n    with open('../datasets/adult_income_names.txt','r') as f:\n        for line in f:\n            f.readline()\n            var=line.split(\":\")[0]\n            names.append(var)\n    names\n    ```", "```py\n    names.append('Income')\n    ```", "```py\n    df = pd.read_csv(\"../datasets/adult_income_data.csv\", names=names)\n    df.head()\n    ```", "```py\n    df.describe()\n    ```", "```py\n    # Make a list of all variables with classes\n    vars_class = ['workclass','education','marital-status',\\\n                  'occupation','relationship','sex','native-country']\n    ```", "```py\n    for v in vars_class:\n        classes=df[v].unique()\n        num_classes = df[v].nunique()\n        print(\"There are {} classes in the \\\"{}\\\" column. \"\\\n              \"They are: {}\".format(num_classes,v,classes))\n        print(\"-\"*100)\n    ```", "```py\n    df.isnull().sum()\n    ```", "```py\n    df_subset = df[['age','education', 'occupation']]\n    df_subset.head()\n    ```", "```py\n    df_subset['age'].hist(bins=20)\n    ```", "```py\n    df_subset.boxplot(column='age',by='education',figsize=(25,10))\n    plt.xticks(fontsize=15)\n    plt.xlabel(\"Education\",fontsize=20)\n    plt.show()\n    ```", "```py\n    def strip_whitespace(s):\n        return s.strip()\n    ```", "```py\n    # Education column\n    df_subset['education_stripped'] = df['education']\\\n                                      .apply(strip_whitespace)\n    df_subset['education'] = df_subset['education_stripped']\n    df_subset.drop(labels = ['education_stripped'],\\\n                   axis=1,inplace=True)\n    # Occupation column\n    df_subset['occupation_stripped'] = df['occupation']\\\n                                       .apply(strip_whitespace)\n    df_subset['occupation'] = df_subset['occupation_stripped']\n    df_subset.drop(labels = ['occupation_stripped'],\\\n                   axis=1,inplace=True)\n    ```", "```py\n    # Conditional clauses and join them by & (AND) \n    df_filtered=df_subset[(df_subset['age']>=30) \\\n                          & (df_subset['age']<=50)]\n    ```", "```py\n    df_filtered.head()\n    ```", "```py\n    answer_1=df_filtered.shape[0]\n    answer_1\n    ```", "```py\n    16390\n    ```", "```py\n    print(\"There are {} people of age between 30 and 50 \"\\\n          \"in this dataset.\".format(answer_1))\n    ```", "```py\n    There are 16390 people of age between 30 and 50 in this dataset.\n    ```", "```py\n    df_subset.groupby('occupation').describe()['age']\n    ```", "```py\n    occupation_stats=df_subset.groupby('occupation').describe()['age']\n    ```", "```py\n    plt.figure(figsize=(15,8))\n    plt.barh(y=occupation_stats.index, \\\n             width=occupation_stats['count'])\n    plt.yticks(fontsize=13)\n    plt.show()\n    ```", "```py\n    df_1 = df[['age','workclass','occupation']]\\\n              .sample(5,random_state=101)\n    df_1.head()\n    ```", "```py\n    df_2 = df[['education','occupation']].sample(5,random_state=101)\n    df_2.head()\n    ```", "```py\n    df_merged = pd.merge(df_1,df_2,on='occupation',\\\n                         how='inner').drop_duplicates()\n    df_merged\n    ```", "```py\n    from bs4 import BeautifulSoup\n    import pandas as pd\n    ```", "```py\n    fd = open(\"../datasets/List of countries by GDP (nominal) \"\\\n              \"- Wikipedia.htm\", \"r\", encoding = \"utf-8\")\n    soup = BeautifulSoup(fd)\n    fd.close()\n    ```", "```py\n    all_tables = soup.find_all(\"table\")\n    print(\"Total number of tables are {} \".format(len(all_tables)))\n    ```", "```py\n    data_table = soup.find(\"table\", {\"class\": '\"wikitable\"|}'})\n    print(type(data_table))\n    ```", "```py\n    <class 'bs4.element.Tag'>\n    ```", "```py\n    sources = data_table.tbody.findAll('tr', recursive=False)[0]\n    sources_list = [td for td in sources.findAll('td')]\n    print(len(sources_list))\n    ```", "```py\n    3\n    ```", "```py\n    data = data_table.tbody.findAll('tr', recursive=False)[1]\\\n                                    .findAll('td', recursive=False)\n    ```", "```py\n    data_tables = []\n    for td in data:\n        data_tables.append(td.findAll('table'))\n    ```", "```py\n    len(data_tables)\n    ```", "```py\n    3\n    ```", "```py\n    source_names = [source.findAll('a')[0].getText() \\\n                    for source in sources_list]\n    print(source_names)\n    ```", "```py\n    ['International Monetary Fund', 'World Bank', 'United Nations']\n    ```", "```py\n    header1 = [th.getText().strip() for th in \\\n               data_tables[0][0].findAll('thead')[0].findAll('th')]\n    header1\n    ```", "```py\n    ['Rank', 'Country', 'GDP(US$MM)']\n    ```", "```py\n    rows1 = data_tables[0][0].findAll('tbody')[0].findAll('tr')[1:]\n    ```", "```py\n    data_rows1 = [[td.get_text().strip() for td in \\\n                   tr.findAll('td')] for tr in rows1]\n    ```", "```py\n    df1 = pd.DataFrame(data_rows1, columns=header1)\n    df1.head()\n    ```", "```py\n    header2 = [th.getText().strip() for th in data_tables[1][0]\\\n               .findAll('thead')[0].findAll('th')]\n    header2\n    ```", "```py\n    ['Rank', 'Country', 'GDP(US$MM)']\n    ```", "```py\n    rows2 = data_tables[1][0].findAll('tbody')[0].findAll('tr')\n    ```", "```py\n    def find_right_text(i, td):\n        if i == 0:\n            return td.getText().strip()\n        elif i == 1:\n            return td.getText().strip()\n        else:\n            index = td.text.find(\"♠\")\n            return td.text[index+1:].strip()\n    ```", "```py\n    data_rows2 = [[find_right_text(i, td) for i, td in \\\n                   enumerate(tr.findAll('td'))] for tr in rows2]\n    ```", "```py\n    df2 = pd.DataFrame(data_rows2, columns=header2)\n    df2.head()\n    ```", "```py\n    header3 = [th.getText().strip() for th in data_tables[2][0]\\\n               .findAll('thead')[0].findAll('th')]\n    header3\n    ```", "```py\n    ['Rank', 'Country', 'GDP(US$MM)']\n    ```", "```py\n    rows3 = data_tables[2][0].findAll('tbody')[0].findAll('tr')\n    ```", "```py\n    data_rows3 = [[find_right_text(i, td) for i, td in \\\n                   enumerate(tr.findAll('td'))] for tr in rows2]\n    ```", "```py\n    df3 = pd.DataFrame(data_rows3, columns=header3)\n    df3.head()\n    ```", "```py\n    import pandas as pd\n    import numpy as np\n    import matplotlib.pyplot as plt\n    %matplotlib inline\n    ```", "```py\n    df = pd.read_csv(\"../datasets/visit_data.csv\")\n    ```", "```py\n    df.head()\n    ```", "```py\n    print(\"First name is duplicated - {}\"\\\n          .format(any(df.first_name.duplicated())))\n    print(\"Last name is duplicated - {}\"\\\n          .format(any(df.last_name.duplicated())))\n    print(\"Email is duplicated - {}\"\\\n          .format(any(df.email.duplicated())))\n    ```", "```py\n    First name is duplicated - True\n    Last name is duplicated - True\n    Email is duplicated - False\n    ```", "```py\n    \"\"\"\n    Notice that we have different ways to \n    format boolean values for the % operator\n    \"\"\"\n    print(\"The column Email contains NaN - %r \" % \\\n          df.email.isnull().values.any())\n    print(\"The column IP Address contains NaN - %s \" % \\\n          df.ip_address.isnull().values.any())\n    print(\"The column Visit contains NaN - %s \" % \\\n          df.visit.isnull().values.any())\n    ```", "```py\n    The column Email contains NaN - False \n    The column IP Address contains NaN - False \n    The column Visit contains NaN - True \n    ```", "```py\n    \"\"\"\n    There are various ways to do this. This is just one way. We encourage you   to explore other ways. But before that we need to store the previous size of the data set and we  will compare it with the new size\n    \"\"\"\n    size_prev = df.shape\n    df = df[np.isfinite(df['visit'])] \n    #This is an inplace operation.\n    # After this operation the original DataFrame is lost.\n    size_after = df.shape\n    ```", "```py\n    # Notice how parameterized format is used.\n    # Then, the indexing is working inside the quote marks\n    print(\"The size of previous data was - {prev[0]} rows and \"\\\n          \"the size of the new one is - {after[0]} rows\"\\\n          .format(prev=size_prev, after=size_after))\n    ```", "```py\n    The size of previous data was - 1000 rows and the size of the new one is - 974 rows\n    ```", "```py\n    plt.boxplot(df.visit, notch=True)\n    ```", "```py\n    df1 = df[(df['visit'] <= 2900) & (df['visit'] >= 100)]\n    # Notice the  powerful & operator\n    \"\"\"\n    Here we abuse the fact the \n    number of variable can be greater \n    than the number of replacement targets\n    \"\"\"\n    print(\"After getting rid of outliers the new size of the data \"\\\n          \"is - {}\".format(*df1.shape))\n    ```", "```py\n    After getting rid of outliers the new size of the data is - 923\n    ```", "```py\n    import urllib.request, urllib.parse, urllib.error\n    import requests\n    from bs4 import BeautifulSoup\n    import ssl\n    import re\n    ```", "```py\n    top100url = 'https://www.gutenberg.org/browse/scores/top'\n    response = requests.get(top100url)\n    ```", "```py\n    def status_check(r):\n        if r.status_code==200:\n            print(\"Success!\")\n            return 1\n        else:\n            print(\"Failed!\")\n            return -1\n    ```", "```py\n    status_check(response)\n    ```", "```py\n    Success!\n    1\n    ```", "```py\n    contents = response.content.decode(response.encoding)\n    soup = BeautifulSoup(contents, 'html.parser')\n    ```", "```py\n    # Empty list to hold all the http links in the HTML page\n    lst_links=[]\n    # Find all href tags and store them in the list of links\n    for link in soup.find_all('a'):\n        #print(link.get('href'))\n        lst_links.append(link.get('href'))\n    ```", "```py\n    lst_links[:30]\n    ```", "```py\n    ['/wiki/Main_Page',\n     '/catalog/',\n     '/ebooks/',\n     '/browse/recent/last1',\n     '/browse/scores/top',\n     '/wiki/Gutenberg:Offline_Catalogs',\n     '/catalog/world/mybookmarks',\n     '/wiki/Main_Page',\n    'https://www.paypal.com/xclick/business=donate%40gutenberg.org&item_name=Donation+to+Project+Gutenberg',\n     '/wiki/Gutenberg:Project_Gutenberg_Needs_Your_Donation',\n     'http://www.ibiblio.org',\n     'http://www.pgdp.net/',\n     'pretty-pictures',\n     '#books-last1',\n     '#authors-last1',\n     '#books-last7',\n     '#authors-last7',\n     '#books-last30',\n     '#authors-last30',\n     '/ebooks/1342',\n     '/ebooks/84',\n     '/ebooks/1080',\n     '/ebooks/46',\n     '/ebooks/219',\n     '/ebooks/2542',\n     '/ebooks/98',\n     '/ebooks/345',\n     '/ebooks/2701',\n     '/ebooks/844',\n     '/ebooks/11']\n    ```", "```py\n    booknum=[]\n    ```", "```py\n    for i in range(19,119):\n        link=lst_links[i]\n        link=link.strip()\n        \"\"\"\n        Regular expression to find the numeric digits in the link (href) string\n        \"\"\"\n        n=re.findall('[0-9]+',link)\n        if len(n)==1:\n            # Append the filenumber casted as integer\n            booknum.append(int(n[0]))\n    ```", "```py\n    print(\"\\nThe file numbers for the top 100 ebooks\",\\\n          \"on Gutenberg are shown below\\n\"+\"-\"*70)\n    print(booknum)\n    ```", "```py\n    The file numbers for the top 100 ebooks on Gutenberg are shown below\n    ----------------------------------------------------------------------\n    [1342, 84, 1080, 46, 219, 2542, 98, 345, 2701, 844, 11, 5200, \n    43, 16328, 76, 74, 1952, 6130, 2591, 1661, 41, 174, 23, 1260, \n    1497, 408, 3207, 1400, 30254, 58271, 1232, 25344, 58269, 158, \n    44881, 1322, 205, 2554, 1184, 2600, 120, 16, 58276, 5740, 34901, \n    28054, 829, 33, 2814, 4300, 100, 55, 160, 1404, 786, 58267, 3600, \n    19942, 8800, 514, 244, 2500, 2852, 135, 768, 58263, 1251, 3825, \n    779, 58262, 203, 730, 20203, 35, 1250, 45, 161, 30360, 7370, \n    58274, 209, 27827, 58256, 33283, 4363, 375, 996, 58270, 521, \n    58268, 36, 815, 1934, 3296, 58279, 105, 2148, 932, 1064, 13415]\n    ```", "```py\n    print(soup.text[:2000])\n    ```", "```py\n    if (top != self) {\n             top.location.replace (http://www.gutenberg.org);\n             alert ('Project Gutenberg is a FREE service with NO membership required. If you paid somebody else to get here, make them give you your money back!');\n             }\n        Top 100 - Project Gutenberg\n    Online Book Catalog\n     Book  Search\n    -- Recent  Books\n    -- Top  100\n    -- Offline Catalogs\n    -- My Bookmarks\n    Main Page\n    …\n    Pretty Pictures\n    Top 100 EBooks yesterday —\n      Top 100 Authors yesterday —\n      Top 100 EBooks last 7 days —\n      Top 100 Authors last 7 days —\n      Top 100 EBooks last 30 days —\n      Top 100 Authors last 30 days\n    Top 100 EBooks yesterday\n    Pride and Prejudice by Jane Austen (1826)\n    Frankenstein; Or, The Modern Prometheus by Mary Wollstonecraft Shelley (1367)\n    A Modest Proposal by Jonathan Swift (1020)\n    A Christmas Carol in Prose; Being a Ghost Story of Christmas by Charles Dickens (953)\n    Heart of Darkness by Joseph Conrad (887)\n    Et dukkehjem. English by Henrik Ibsen (761)\n    A Tale of Two Cities by Charles Dickens (741)\n    Dracula by Bram Stoker (732)\n    Moby Dick; Or, The Whale by Herman Melville (651)\n    The Importance of Being Earnest: A Trivial Comedy for Serious People by Oscar Wilde (646)\n    Alice's Adventures in Wonderland by Lewis Carrol\n    ```", "```py\n    lst_titles_temp=[]\n    ```", "```py\n    start_idx=soup.text.splitlines().index('Top 100 EBooks yesterday')\n    ```", "```py\n    for i in range(100):\n        lst_titles_temp.append(soup.text.splitlines()[start_idx+2+i])\n    ```", "```py\n    lst_titles=[]\n    for i in range(100):\n        id1,id2=re.match('^[a-zA-Z ]*',lst_titles_temp[i]).span()\n        lst_titles.append(lst_titles_temp[i][id1:id2])\n    ```", "```py\n    for l in lst_titles:\n        print(l)\n    ```", "```py\n    Pride and Prejudice by Jane Austen \n    Frankenstein\n    A Modest Proposal by Jonathan Swift \n    A Christmas Carol in Prose\n    Heart of Darkness by Joseph Conrad \n    Et dukkehjem\n    A Tale of Two Cities by Charles Dickens \n    Dracula by Bram Stoker \n    Moby Dick\n    The Importance of Being Earnest\n    Alice\n    Metamorphosis by Franz Kafka \n    The Strange Case of Dr\n    Beowulf\n    …\n    The Russian Army and the Japanese War\n    Calculus Made Easy by Silvanus P\n    Beyond Good and Evil by Friedrich Wilhelm Nietzsche \n    An Occurrence at Owl Creek Bridge by Ambrose Bierce \n    Don Quixote by Miguel de Cervantes Saavedra \n    Blue Jackets by Edward Greey \n    The Life and Adventures of Robinson Crusoe by Daniel Defoe \n    The Waterloo Campaign \n    The War of the Worlds by H\n    Democracy in America \n    Songs of Innocence\n    The Confessions of St\n    Modern French Masters by Marie Van Vorst \n    Persuasion by Jane Austen \n    The Works of Edgar Allan Poe \n    The Fall of the House of Usher by Edgar Allan Poe \n    The Masque of the Red Death by Edgar Allan Poe \n    The Lady with the Dog and Other Stories by Anton Pavlovich Chekhov\n    ```", "```py\n    import urllib.request, urllib.parse, urllib.error\n    import json\n    ```", "```py\n    with open('APIkeys.json') as f:\n        keys = json.load(f)\n        omdbapi = keys['OMDBapi']\n    ```", "```py\n    serviceurl = 'http://www.omdbapi.com/?'\n    ```", "```py\n    apikey = '&apikey='+omdbapi\n    ```", "```py\n    def print_json(json_data):\n        list_keys = ['Title', 'Year', 'Rated', 'Released',\\\n                     'Runtime', 'Genre', 'Director', 'Writer', \\\n                     'Actors', 'Plot', 'Language', 'Country', \\\n                     'Awards', 'Ratings','Metascore', 'imdbRating', \\\n                     'imdbVotes', 'imdbID']\n        print(\"-\"*50)\n        for k in list_keys:\n            if k in list(json_data.keys()):\n                print(f\"{k}: {json_data[k]}\")\n        print(\"-\"*50)\n    ```", "```py\n    def save_poster(json_data):\n        import os\n        title = json_data['Title']\n        poster_url = json_data['Poster']\n        \"\"\"\n        Splits the poster url by '.' and \n        picks up the last string as file extension\n        \"\"\"\n        poster_file_extension=poster_url.split('.')[-1]\n        # Reads the image file from web\n        poster_data = urllib.request.urlopen(poster_url).read()\n        savelocation=os.getcwd()+'\\\\'+'Posters'+'\\\\'\n        \"\"\" \n        Creates new directory if the directory does not exist.\n        Otherwise, just use the existing path.\n        \"\"\"\n        if not os.path.isdir(savelocation):\n            os.mkdir(savelocation)\n        filename=savelocation+str(title)\\\n                 +'.'+poster_file_extension\n        f=open(filename,'wb')\n        f.write(poster_data)\n        f.close()\n    ```", "```py\n    def search_movie(title):\n        try:\n            url = serviceurl \\\n                  + urllib.parse.urlencode({'t':str(title)})+apikey\n            print(f'Retrieving the data of \"{title}\" now... ')\n            print(url)\n            uh = urllib.request.urlopen(url)\n            data = uh.read()\n            json_data=json.loads(data)\n            if json_data['Response']=='True':\n                print_json(json_data)\n                \"\"\"\n                Asks user whether to download the poster of the movie\n                \"\"\"\n                if json_data['Poster']!='N/A':\n                    save_poster(json_data)\n                else:\n                    print(\"Error encountered: \", json_data['Error'])\n        except urllib.error.URLError as e:\n            print(f\"ERROR: {e.reason}\")\n    ```", "```py\n    search_movie(\"Titanic\")\n    ```", "```py\n    http://www.omdbapi.com/?t=Titanic&apikey=<your api key> \n    --------------------------------------------------\n    Title: Titanic\n    Year: 1997\n    Rated: PG-13\n    Released: 19 Dec 1997\n    Runtime: 194 min\n    Genre: Drama, Romance\n    Director: James Cameron\n    Writer: James Cameron\n    Actors: Leonardo DiCaprio, Kate Winslet, Billy Zane, Kathy Bates\n    Plot: A seventeen-year-old aristocrat falls in love with a kind but poor artist aboard the luxurious, ill-fated R.M.S. Titanic.\n    Language: English, Swedish\n    Country: USA\n    Awards: Won 11 Oscars. Another 111 wins & 77 nominations.\n    Ratings: [{'Source': 'Internet Movie Database', 'Value': '7.8/10'}, {'Source': 'Rotten Tomatoes', 'Value': '89%'}, {'Source': 'Metacritic', 'Value': '75/100'}]\n    Metascore: 75\n    imdbRating: 7.8\n    imdbVotes: 913,780\n    imdbID: tt0120338\n    --------------------------------------------------\n    ```", "```py\n    search_movie(\"Random_error\")\n    ```", "```py\n    Retrieving the data of \"Random_error\" now...\n    http://www.omdbapi.com/?t=Random_error&apikey=<your api key> \n    Error encountered: Movie not found!\n    ```", "```py\n    import sqlite3\n    conn = sqlite3.connect(\"petsdb\")\n    ```", "```py\n    # a tiny function to make sure the connection is successful\n    def is_opened(conn):\n        try:\n            conn.execute(\"SELECT * FROM persons LIMIT 1\")\n            return True\n        except sqlite3.ProgrammingError as e:\n            print(\"Connection closed {}\".format(e))\n            return False\n    print(is_opened(conn))\n    ```", "```py\n    True\n    ```", "```py\n    conn.close()\n    ```", "```py\n    print(is_opened(conn))\n    ```", "```py\n    Connection closed Cannot operate on a closed database.\n    False\n    ```", "```py\n    conn = sqlite3.connect(\"petsdb\")\n    c = conn.cursor()\n    ```", "```py\n    for ppl, age in c.execute(\"SELECT count(*), \\\n                              age FROM persons GROUP BY age\"):\n        print(\"We have {} people aged {}\".format(ppl, age))\n    ```", "```py\n    for ppl, age in c.execute(\"SELECT count(*), age FROM persons \\\n                              GROUP BY age ORDER BY count(*)DESC\"):\n        print(\"The highest number of people is {} and \"\\\n              \"came from {} age group\".format(ppl, age))\n        break\n    ```", "```py\n    The highest number of people is 5 and came from 73 age group\n    ```", "```py\n    res = c.execute(\"SELECT count(*) FROM persons \\\n                    WHERE last_name IS null\")\n    for row in res:\n        print(row)\n    ```", "```py\n    (60,)\n    ```", "```py\n    res = c.execute(\"SELECT count(*) FROM \\\n                    (SELECT count(owner_id) FROM pets \\\n                     GROUP BY owner_id HAVING count(owner_id) >1)\")\n    for row in res:\n        print(\"{} people have more than one pets\".format(row[0]))\n    ```", "```py\n    43 People have more than one pets\n    ```", "```py\n    res = c.execute(\"SELECT count(*) FROM pets \\\n                    WHERE treatment_done=1\")\n    for row in res:\n        print(row)\n    ```", "```py\n    (36,)\n    ```", "```py\n    res = c.execute(\"SELECT count(*) FROM pets \\\n                    WHERE treatment_done=1 AND pet_type IS NOT null\")\n    for row in res:\n        print(row)\n    ```", "```py\n    (16,)\n    ```", "```py\n    res = c.execute(\"SELECT count(*) FROM pets \\\n                    JOIN persons ON pets.owner_id = persons.id \\\n                    WHERE persons.city='east port'\")\n    for row in res:\n        print(row)\n    ```", "```py\n    (49,)\n    ```", "```py\n    res = c.execute(\"SELECT count(*) FROM pets \\\n                    JOIN persons ON pets.owner_id = \\\n                    persons.id WHERE persons.city='east port' \\\n                    AND pets.treatment_done=1\")\n    for row in res:\n        print(row)\n    ```", "```py\n    (11,)\n    ```", "```py\n    import numpy as np\n    import pandas as pd\n    import matplotlib.pyplot as plt\n    import warnings\n    warnings.filterwarnings('ignore')\n    ```", "```py\n    education_data_link=\"http://data.un.org/_Docs/SYB/CSV/\"\\\n                        \"SYB61_T07_Education.csv\"\n    df1 = pd.read_csv(education_data_link)\n    ```", "```py\n    df1.head()\n    ```", "```py\n    df1 = pd.read_csv(education_data_link,skiprows=1)\n    ```", "```py\n    df1.head()\n    ```", "```py\n    df2 = df1.drop(['Region/Country/Area','Source'],axis=1)\n    ```", "```py\n    df2.columns=['Region/Country/Area','Year','Data',\\\n                 'Enrollments (Thousands)','Footnotes']\n    ```", "```py\n    df2.head()\n    ```", "```py\n    df2['Footnotes'].unique()\n    ```", "```py\n    type(df2['Enrollments (Thousands)'][0])\n    ```", "```py\n    str\n    ```", "```py\n    def to_numeric(val):\n        \"\"\"\n        Converts a given string (with one or more commas) to a numeric value\n        \"\"\"\n        if ',' not in str(val):\n            result = float(val)\n        else:\n            val=str(val)\n            val=''.join(str(val).split(','))\n            result=float(val)\n        return result\n    ```", "```py\n    df2['Enrollments (Thousands)']=df2['Enrollments (Thousands)']\\\n                                   .apply(to_numeric)\n    ```", "```py\n    df2['Data'].unique()\n    ```", "```py\n    df_primary = df2[df2['Data']=='Students enrolled in primary '\\\n                                  'education (thousands)']\n    df_secondary = df2[df2['Data']=='Students enrolled in secondary '\\\n                                    'education (thousands)']\n    df_tertiary = df2[df2['Data']=='Students enrolled in tertiary '\\\n                                   'education (thousands)']\n    ```", "```py\n    primary_enrollment_india = df_primary[df_primary\\\n                               ['Region/Country/Area']=='India']\n    primary_enrollment_USA = df_primary[df_primary\\\n                             ['Region/Country/Area']\\\n                             =='United States of America']\n    ```", "```py\n    primary_enrollment_india\n    ```", "```py\n    primary_enrollment_USA\n    ```", "```py\n    plt.figure(figsize=(8,4))\n    plt.bar(primary_enrollment_india['Year'],\\\n    primary_enrollment_india['Enrollments (Thousands)'])\n    plt.title(\"Enrollment in primary education\\nin India \"\\\n              \"(in thousands)\",fontsize=16)\n    plt.grid(True)\n    plt.xticks(fontsize=14)\n    plt.yticks(fontsize=14)\n    plt.xlabel(\"Year\", fontsize=15)\n    plt.show()\n    ```", "```py\n    plt.figure(figsize=(8,4))\n    plt.bar(primary_enrollment_USA['Year'],\\\n    primary_enrollment_USA['Enrollments (Thousands)'])\n    plt.title(\"Enrollment in primary education\\nin the \"\\\n              \"United States of America (in thousands)\",fontsize=16)\n    plt.grid(True)\n    plt.xticks(fontsize=14)\n    plt.yticks(fontsize=14)\n    plt.xlabel(\"Year\", fontsize=15)\n    plt.show()\n    ```", "```py\n    missing_years = [y for y in range(2004,2010)]\\\n                    +[y for y in range(2011,2014)]\n    ```", "```py\n    missing_years\n    ```", "```py\n    [2004, 2005, 2006, 2007, 2008, 2009, 2011, 2012, 2013]\n    ```", "```py\n    dict_missing = \\\n    {'Region/Country/Area':['India']*9,\\\n     'Year':missing_years,\\\n     'Data':'Students enrolled in primary education(thousands)'*9,\\\n     'Enrollments (Thousands)':[np.nan]*9,'Footnotes':[np.nan]*9}\n    ```", "```py\n    df_missing = pd.DataFrame(data=dict_missing)\n    ```", "```py\n    primary_enrollment_india=primary_enrollment_india\\\n                             .append(df_missing,ignore_index=True,\\\n                                     sort=True)\n    ```", "```py\n    primary_enrollment_india\n    ```", "```py\n    primary_enrollment_india.sort_values(by='Year',inplace=True)\n    primary_enrollment_india.reset_index(inplace=True,drop=True)\n    ```", "```py\n    primary_enrollment_india\n    ```", "```py\n    primary_enrollment_india.interpolate(inplace=True)\n    ```", "```py\n    primary_enrollment_india\n    ```", "```py\n    plt.figure(figsize=(8,4))\n    plt.bar(primary_enrollment_india['Year'],\\\n            primary_enrollment_india['Enrollments (Thousands)'])\n    plt.title(\"Enrollment in primary education\\nin India \"\\\n              \"(in thousands)\", fontsize=16)\n    plt.grid(True)\n    plt.xticks(fontsize=14)\n    plt.yticks(fontsize=14)\n    plt.xlabel(\"Year\", fontsize=15)\n    plt.show()\n    ```", "```py\n    missing_years = [2004]+[y for y in range(2006,2010)]\\\n                    +[y for y in range(2011,2014)]+[2016]\n    ```", "```py\n    missing_years\n    ```", "```py\n    [2004, 2006, 2007, 2008, 2009, 2011, 2012, 2013, 2016]\n    ```", "```py\n    dict_missing = \\\n    {'Region/Country/Area':['United States of America']*9,\\\n     'Year':missing_years, \\\n     'Data':'Students enrolled in primary education (thousands)'*9, \\\n     'Value':[np.nan]*9,'Footnotes':[np.nan]*9}\n    ```", "```py\n    df_missing = pd.DataFrame(data=dict_missing)\n    ```", "```py\n    primary_enrollment_USA=primary_enrollment_USA\\\n                           .append(df_missing,\\\n                                   ignore_index =True,sort=True)\n    ```", "```py\n    primary_enrollment_USA.sort_values(by='Year',inplace=True)\n    ```", "```py\n    primary_enrollment_USA.reset_index(inplace=True,drop=True)\n    ```", "```py\n    primary_enrollment_USA.interpolate(inplace=True)\n    ```", "```py\n    primary_enrollment_USA\n    ```", "```py\n    primary_enrollment_USA.interpolate(method='linear',\\\n                                       limit_direction='backward',\\\n                                       limit=1)\n    ```", "```py\n    primary_enrollment_USA\n    ```", "```py\n    plt.figure(figsize=(8,4))\n    plt.bar(primary_enrollment_USA['Year'],\\\n            primary_enrollment_USA['Enrollments (Thousands)'])\n    plt.title(\"Enrollment in primary education\\nin the \"\\\n              \"United States of America (in thousands)\",fontsize=16)\n    plt.grid(True)\n    plt.xticks(fontsize=14)\n    plt.yticks(fontsize=14)\n    plt.xlabel(\"Year\", fontsize=15)\n    plt.show()\n    ```", "```py\n    import numpy as np\n    import pandas as pd\n    import matplotlib.pyplot as plt\n    import warnings\n    warnings.filterwarnings('ignore')\n    ```", "```py\n    df3=pd.read_csv(\"error_bad_lines=False option in this kind of situation.\n    ```", "```py\n    df3=pd.read_csv(\"../datasets/India_World_Bank_Info.csv\",\\\n                    error_bad_lines=False)\n    ```", "```py\n    df3.head(10)\n    ```", "```py\n    df3=pd.read_csv(\"../datasets/India_World_Bank_Info.csv\", \\\n                    error_bad_lines=False,delimiter='\\t')\n    df3.head(10)\n    ```", "```py\n    df3=pd.read_csv(\"../datasets/India_World_Bank_Info.csv\",\\\n                    error_bad_lines=False,delimiter='\\t',\\\n                    skiprows=4)\n    df3.head(10)\n    ```", "```py\n    df4=df3[df3['Indicator Name']=='GDP per capita (current US$)'].T\n    df4.head(10)\n    ```", "```py\n    df4.reset_index(inplace=True)\n    df4.head(10)\n    ```", "```py\n    df4.drop([0,1,2],inplace=True)\n    df4.reset_index(inplace=True,drop=True)\n    df4.head(10)\n    ```", "```py\n    df4.columns=['Year','GDP']\n    df4.head(10)\n    ```", "```py\n    df4.tail(20)\n    ```", "```py\n    df_gdp=df4.iloc[[i for i in range(43,57)]]\n    df_gdp\n    ```", "```py\n    df_gdp.reset_index(inplace=True,drop=True)\n    df_gdp\n    ```", "```py\n    df_gdp['Year']\n    ```", "```py\n    df_gdp['Year']=df_gdp['Year'].apply(int)\n    ```", "```py\n    primary_enrollment_with_gdp=\\\n    primary_enrollment_india.merge(df_gdp,on='Year')\n    primary_enrollment_with_gdp\n    ```", "```py\n    primary_enrollment_with_gdp.drop(['Data','Footnotes',\\\n                                      'Region/Country/Area'],\\\n                                      axis=1,inplace=True)\n    primary_enrollment_with_gdp\n    ```", "```py\n    primary_enrollment_with_gdp = \\\n    primary_enrollment_with_gdp[['Year',\\\n                                 'Enrollments (Thousands)','GDP']]\n    primary_enrollment_with_gdp\n    ```", "```py\n    plt.figure(figsize=(8,5))\n    plt.title(\"India's GDP per capita vs primary education \"\\\n              \"enrollment\",fontsize=16)\n    plt.scatter(primary_enrollment_with_gdp['GDP'],\\\n                primary_enrollment_with_gdp['Enrollments (Thousands)'],\\\n                edgecolor='k',color='orange',s=200)\n    plt.xlabel(\"GDP per capita (US $)\",fontsize=15)\n    plt.ylabel(\"Primary enrollment (thousands)\", fontsize=15)\n    plt.xticks(fontsize=14)\n    plt.yticks(fontsize=14)\n    plt.grid(True)\n    plt.show()\n    ```", "```py\n    import sqlite3\n    with sqlite3.connect(\"Education_GDP.db\") as conn:\n        cursor = conn.cursor()\n        cursor.execute(\"CREATE TABLE IF NOT EXISTS \\\n                       education_gdp(Year INT, Enrollment \\\n                       FLOAT, GDP FLOAT, PRIMARY KEY (Year))\")\n    ```", "```py\n    with sqlite3.connect(\"Education_GDP.db\") as conn:\n        cursor = conn.cursor()\n        for i in range(14):\n            year = int(primary_enrollment_with_gdp.iloc[i]['Year'])\n            enrollment = \\\n            primary_enrollment_with_gdp.iloc[i]\\\n            ['Enrollments (Thousands)']\n            gdp = primary_enrollment_with_gdp.iloc[i]['GDP']\n            #print(year,enrollment,gdp)\n            cursor.execute(\"INSERT INTO \\\n                           education_gdp (Year,Enrollment,GDP) \\\n                           VALUES(?,?,?)\",(year,enrollment,gdp))\n    ```"]