<html><head></head><body>
<div><div><h1 class="chapter-number" id="_idParaDest-426"><a id="_idTextAnchor433"/>12</h1>
<h1 id="_idParaDest-427"><a id="_idTextAnchor434"/>Using Data Observability for Debugging, Error Handling, and Preventing Downtime</h1>
<p>We are reaching the end of our journey through the data ingestion world and have covered many important topics and seen how they could be applied to real-life projects. Now, to finish this book with a flourish, the final topic is the concept of <strong class="bold">data observability</strong>.</p>
<p>Data observability refers to the ability to monitor, understand, and troubleshoot the health, quality, and <a id="_idIndexMarker815"/>other vital aspects of data in a big organization or a small project. In summary, it ensures that data is accurate, reliable, and available when needed.</p>
<p>Although each recipe in this chapter can be executed separately, the goal is to configure tools that, when set together, create a monitoring and observability architecture ready to bring value to a project or team.</p>
<p>You will learn about the following recipes:</p>
<ul>
<li>Setting up StatsD for monitoring</li>
<li>Setting up Prometheus for storing metrics</li>
<li>Setting up Grafana for monitoring</li>
<li>Creating an observability dashboard</li>
<li>Setting custom alerts or notiﬁcations</li>
</ul>
<h1 id="_idParaDest-428"><a id="_idTextAnchor435"/>Technical requirements</h1>
<p>This chapter requires that Airflow is installed on your local machine. You can install it directly on your <strong class="bold">Operating System</strong> (<strong class="bold">OS</strong>) or using a Docker image. For more information, refer to <a href="B19453_01.xhtml#_idTextAnchor022"><em class="italic">Chapter 1</em></a>, and the <em class="italic">Configuring Docker for </em><em class="italic">Airflow</em> recipe.</p>
<p>After following the steps described in <a href="B19453_01.xhtml#_idTextAnchor022"><em class="italic">Chapter 1</em></a>, ensure Airflow runs correctly. You can do that by checking the Airflow UI at this link: <code>http://localhost:8080</code></p>
<p>If you are using a Docker container (as I am) to host your Airflow application, you can check its status in the terminal by using the following command:</p>
<pre class="source-code">
<strong class="bold">$ docker ps</strong></pre>
<p>Here is the status of the container:</p>
<div><div><img alt="Figure 12.1 –  Airflow containers running" height="131" src="img/Figure_12.01_B19453.jpg" width="1389"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.1 – Airflow containers running</p>
<div><div><img alt="Figure 12.2 – Docker Desktop view of Airflow containers running" height="455" src="img/Figure_12.02_B19453.jpg" width="1002"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.2 – Docker Desktop view of Airflow containers running</p>
<h2 id="_idParaDest-429"><a id="_idTextAnchor436"/>Docker images</h2>
<p>This chapter requires the creation of other Docker containers to build the monitoring and observability <a id="_idIndexMarker816"/>architecture. If you are using <code>docker-compose.yaml</code> file to run your Airflow application, you can add the other images addressed here to the same <code>docker-compose.yaml</code> file and run it all together.</p>
<p>If you are running Airflow locally, you can create and configure each Docker image separately or create a <code>docker-compose.yaml</code> file just for the monitoring tools approach in this chapter.</p>
<h1 id="_idParaDest-430"><a id="_idTextAnchor437"/>Setting up StatsD for monitoring</h1>
<p>As introduced in <a href="B19453_10.xhtml#_idTextAnchor364"><em class="italic">Chapter 10</em></a>, <strong class="bold">StatsD</strong> is an open source daemon that gathers and aggregates <a id="_idIndexMarker817"/>metrics about application behaviors. Due to its flexibility and lightweight, StatsD is used on several monitoring and observability tools, such as <strong class="bold">Grafana</strong>, <strong class="bold">Prometheus</strong>, and <strong class="bold">ElasticSearch</strong>, to visualize and analyze the collected metrics.</p>
<p>In this recipe, we will configure StatsD using a Docker image as the first step in building a monitoring pipeline. Here, StatsD will collect and aggregate Airflow information and make it available to Prometheus, our monitoring database, in the <em class="italic">Setting up Prometheus for storing </em><em class="italic">metrics</em> recipe.</p>
<h2 id="_idParaDest-431"><a id="_idTextAnchor438"/>Getting ready</h2>
<p>Refer to the <em class="italic">Technical requirements</em> section for this recipe since we will handle it with the same technology.</p>
<h2 id="_idParaDest-432"><a id="_idTextAnchor439"/>How to do it…</h2>
<p>Here are the steps to perform this recipe:</p>
<ol>
<li>Let’s start by defining our Docker configurations for StatsD. These lines will be added under the <code>services</code> section inside the <code>docker-compose</code> file:<pre class="source-code">
  statsd-exporter:
    image: prom/statsd-exporter
    container_name: statsd-exporter
    command: "--statsd.listen-udp=:8125 --web.listen-address=:9102"
    ports:
      - 9102:9102
      - 8125:8125/udp</pre></li>
<li>Next, let’s set the Airflow environment variables to install StatsD and export the metrics to it, as you can see here:<pre class="source-code">
# StatsD configuration
AIRFLOW__SCHEDULER__STATSD_ON: 'true'
AIRFLOW__SCHEDULER__STATSD_HOST: statsd-exporter
AIRFLOW__SCHEDULER__STATSD_PORT: 8125
AIRFLOW__SCHEDULER__STATSD_PREFIX: airflow
_PIP_ADDITIONAL_REQUIREMENTS: ${_PIP_ADDITIONAL_REQUIREMENTS:-apache-airflow[statsd]}</pre></li>
</ol>
<p>If you need help <a id="_idIndexMarker818"/>to set these variables in Airflow, please refer to <a href="B19453_10.xhtml#_idTextAnchor364"><em class="italic">Chapter 10</em></a>, and the <em class="italic">Configuring logs in </em><em class="italic">airflow.cfg</em> recipe.</p>
<p>Your Airflow variables in the <code>docker-compose</code> file should look like this:</p>
<div><div><img alt="Figure 12.3 – Airflow environment variables with StatsD configurations" height="603" src="img/Figure_12.03_B19453.jpg" width="1130"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.3 – Airflow environment variables with StatsD configurations</p>
<ol>
<li value="3">Now, restart your Docker containers to apply the configurations.</li>
<li>Once you do <a id="_idIndexMarker819"/>so, and all containers are up and running, let’s check the <code>http://localhost:9102/</code> address in a browser. You should see the following page:</li>
</ol>
<div><div><img alt="Figure 12.4 – StatsD page in the browser" height="145" src="img/Figure_12.04_B19453.jpg" width="264"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.4 – StatsD page in the browser</p>
<ol>
<li value="5">Then, click on <strong class="bold">Metrics</strong>, and a new page will appear showing something similar to the following:</li>
</ol>
<div><div><img alt="Figure 12.5 – StatsD metrics being shown in the browser" height="554" src="img/Figure_12.05_B19453.jpg" width="925"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.5 – StatsD metrics being shown in the browser</p>
<p>The lines shown in the browser confirm StatsD is successfully installed and collecting data from Airflow.</p>
<h2 id="_idParaDest-433"><a id="_idTextAnchor440"/>How it works…</h2>
<p>As you can observe, configuring StatsD with Airflow is very straightforward. In fact, StatsD is not new for us since we already covered it in <a href="B19453_10.xhtml#_idTextAnchor364"><em class="italic">Chapter 10</em></a>, in the <em class="italic">Designing advanced monitoring</em> recipe. However, let’s recap some of the concepts.</p>
<p>StatsD is an open source <a id="_idIndexMarker820"/>daemon tool built by Etsy employees that receives information via the <strong class="bold">User Datagram Protocol</strong> (<strong class="bold">UDP</strong>), making it fast and lightweight since it discards the necessity of sending a confirmation message back to the sender.</p>
<p>Now, looking at the <a id="_idIndexMarker821"/>code, the first thing we did was to set the Docker container to run StatsD. Alongside all the usual parameters to run a container, the key point is the <code>command</code> parameter, as follows:</p>
<pre class="source-code">
    command: "--statsd.listen-udp=:8125 --web.listen-address=:9102"
# StatsD configuration
AIRFLOW__SCHEDULER__STATSD_ON: 'true'
AIRFLOW__SCHEDULER__STATSD_HOST: statsd-exporter
AIRFLOW__SCHEDULER__STATSD_PORT: 8125
AIRFLOW__SCHEDULER__STATSD_PREFIX: airflow
_PIP_ADDITIONAL_REQUIREMENTS: ${_PIP_ADDITIONAL_REQUIREMENTS:-apache-airflow[statsd]}</pre>
<h2 id="_idParaDest-434"><a id="_idTextAnchor441"/>See also</h2>
<p>You can <a id="_idIndexMarker822"/>check the Docker image of StatsD on the <strong class="bold">Docker Hub</strong> page here: <a href="https://hub.docker.com/r/prom/statsd-exporter">https://hub.docker.com/r/prom/statsd-exporter</a></p>
<h1 id="_idParaDest-435"><a id="_idTextAnchor442"/>Setting up Prometheus for storing metrics</h1>
<p>Although it is <a id="_idIndexMarker823"/>generally called a database, Prometheus is not a traditional database like MySQL. Instead, its structure is more similar to a time-series database designed for monitoring and observability purposes.</p>
<p>Due to its flexibility and power, this tool is widely used by DevOps and<strong class="bold"> Site Reliability Engineers</strong> (<strong class="bold">SREs</strong>) to store metrics and other relevant information about systems and applications. Together <a id="_idIndexMarker824"/>with Grafana (which we will explore in later recipes), it is one of the most used monitoring tools in projects and by teams.</p>
<p>This recipe will configure a Docker image to run a Prometheus application. We will also connect it to StatsD to store all the metrics generated.</p>
<h2 id="_idParaDest-436"><a id="_idTextAnchor443"/>Getting ready</h2>
<p>Refer to the <em class="italic">Technical requirements</em> section for this recipe since we will handle it with the same technology.</p>
<h2 id="_idParaDest-437"><a id="_idTextAnchor444"/>How to do it…</h2>
<p>Here are the <a id="_idIndexMarker825"/>steps to perform this recipe:</p>
<ol>
<li>Let’s begin by adding the following lines to our <code>docker-compose</code> file under the <code>services</code> section:<pre class="source-code">
  prometheus:
    image: prom/prometheus
    ports:
    - 9090:9090
    links:
      - statsd-exporter # Use the same name as your statsd container
    volumes:
      - ./prometheus:/etc/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - --log.level=debug
      - --web.listen-address=:9090
      - --web.page-title='Prometheus - Airflow Metrics'</pre></li>
<li>Now, create a folder named <code>prometheus</code> at the same level as your <code>docker-compose</code> file. Inside the folder, create a new file named <code>prometheus.yml</code> with the following code and save it:<pre class="source-code">
scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['prometheus:9090']
  - job_name: 'statsd-exporter'
    static_configs:
      - targets: ['statsd-exporter:9102']</pre></li>
</ol>
<p>On <code>static_configs</code>, make sure the target has the same name and the exposed <a id="_idIndexMarker826"/>port of the StatsD container. Otherwise, you will face problems in establishing a connection with the container.</p>
<ol>
<li value="3">Now, restart your Docker containers.</li>
<li>When the containers are back up and running, access the following link in your browser: <code>http://localhost:9090/</code>.</li>
</ol>
<p>You should see a page like the following:</p>
<div><div><img alt="Figure 12.6 – Prometheus UI" height="275" src="img/Figure_12.06_B19453.jpg" width="1229"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.6 – Prometheus UI</p>
<ol>
<li value="5">Now, click on the list icon next to the <strong class="bold">Execute</strong> button on the right of the page. It will open a list with all metrics available to be used. If everything is well configured, you should see something like the following:</li>
</ol>
<div><div><img alt="Figure 12.7 – Prometheus available metric list" height="830" src="img/Figure_12.07_B19453.jpg" width="1217"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.7 – Prometheus available metric list</p>
<p>We have successfully set up Prometheus, which is already storing the metrics sent by StatsD!</p>
<h2 id="_idParaDest-438"><a id="_idTextAnchor445"/>How it works…</h2>
<p>Let’s explore in more <a id="_idIndexMarker827"/>depth what we did in this exercise by examining the container definitions in <em class="italic">Step 1</em>. Since we already have basic knowledge of Docker, we will cover the most critical parts of the container settings.</p>
<p>The first thing that draws attention is the <code>links</code> section in the <code>docker-compose</code> file. In this section, we declared that the Prometheus container must be connected and linked to the StatsD container configured in the <em class="italic">Setting up StatsD for </em><em class="italic">monitoring</em> recipe:</p>
<pre class="source-code">
    links:
      - statsd-exporter # Use the same name as your statsd container</pre>
<p>Next, we set <code>volumes</code> to reflect a local folder to a folder inside the container. This step is essential because then we can also mirror the configuration file of Prometheus:</p>
<pre class="source-code">
    volumes:
      - ./prometheus:/etc/prometheus</pre>
<p>Finally, in the <code>command</code> section, we declared where the configuration file will be placed inside <a id="_idIndexMarker828"/>the container and other minor settings:</p>
<pre class="source-code">
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - --log.level=debug
      - --web.listen-address=:9090
      - --web.page-title='Prometheus - Airflow Metrics'</pre>
<p>Then, the following steps were dedicated to setting the Prometheus configuration file, as you can see here:</p>
<pre class="source-code">
scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['prometheus:9090']
  - job_name: 'statsd-exporter'
    static_configs:
      - targets: ['statsd-exporter:9102']</pre>
<p>By definition, Prometheus collects metrics from itself and other applications through an HTTP request. In other words, it parses the response and ingests the collected samples for storage. That’s why we used <code>scrape_configs</code>.</p>
<p>If you look closely, you will observe that we declared two scrape jobs: one for Prometheus and another for StatsD. Due to that configuration, we could see Airflow metrics in the <a id="_idIndexMarker829"/>Prometheus metrics list. If we needed to include any other scrape configuration, we would just need to edit the local <code>prometheus.yml</code> file and restart the server.</p>
<p>Many other configurations are available in Prometheus, such as setting the scrape interval. You can <a id="_idIndexMarker830"/>read more about its configurations on the official documentation page at <a href="https://prometheus.io/docs/prometheus/latest/getting_started/">https://prometheus.io/docs/prometheus/latest/getting_started/</a>.</p>
<h2 id="_idParaDest-439"><a id="_idTextAnchor446"/>There’s more…</h2>
<p>In this recipe, we saw how to set Prometheus to store metrics coming from StatsD. This time-series database also has <a id="_idIndexMarker831"/>other capabilities, such as creating small visualizations in the web UI and connecting with other client libraries, and has an alerting system called Alertmanager.</p>
<p>If you want to go deeper into how Prometheus works and other functionalities, Sudip Sengupta has a fantastic blog post about it, which you can read here:</p>
<p><a href="https://www.airplane.dev/blog/prometheus-metrics">https://www.airplane.dev/blog/prometheus-metrics</a></p>
<h1 id="_idParaDest-440"><a id="_idTextAnchor447"/>Setting up Grafana for monitoring</h1>
<p><strong class="bold">Grafana</strong> is an open source tool built to create visualizations and monitor data from other systems <a id="_idIndexMarker832"/>and applications. Together with Prometheus, it is one of the most popular DevOps tools due to its flexibility and rich features.</p>
<p>In this exercise, we will configure a Docker image to run Grafana and connect it to Prometheus. This configuration will not only give us the ability to explore the Airflow metrics even further but also the opportunity to learn in practice how to work with a set of the most popular tools for monitoring and observability.</p>
<h2 id="_idParaDest-441"><a id="_idTextAnchor448"/>Getting ready</h2>
<p>Refer to the <em class="italic">Technical requirements</em> section for this recipe since we will handle it with the same technology.</p>
<p>In this recipe, I will use the same <code>docker-compose.yaml</code> file of Airflow and will keep the configurations from the <em class="italic">Setting up StatsD for monitoring</em> and <em class="italic">Setting up Prometheus for storing metrics</em> recipes, to connect them and proceed with the monitoring and observability architecture.</p>
<h2 id="_idParaDest-442"><a id="_idTextAnchor449"/>How to do it…</h2>
<p>Perform the following steps to try this recipe:</p>
<ol>
<li>As shown <a id="_idIndexMarker833"/>in the following, let’s add the Grafana container information to our <code>docker-compose</code> file as usual. Make sure it is under the <code>services</code> section:<pre class="source-code">
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    environment:
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: admin
      GF_PATHS_PROVISIONING: /grafana/provisioning
    links:
      - prometheus # use the same name of your Prometheus docker container
    ports:
      - 3000:3000
    volumes:
      - ./grafana/provisioning:/grafana/provisioning</pre></li>
</ol>
<p>Feel free to use a different administrator username as a password.</p>
<ol>
<li value="2">Now, create a folder called <code>grafana</code> on the same level as your Docker file, and restart your containers.</li>
<li>After it is back up and running, insert the <code>http://localhost:3000/login</code> link in your browser. A login page similar to this will appear:</li>
</ol>
<div><div><img alt="Figure 12.8 – Grafana login page" height="488" src="img/Figure_12.08_B19453.jpg" width="455"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.8 – Grafana login page</p>
<p>It confirms <a id="_idIndexMarker834"/>Grafana is set up correctly!</p>
<ol>
<li value="4">Then, let’s use the administrator credentials to log in to the Grafana dashboard. After authenticating, you should see the main page as follows:</li>
</ol>
<div><div><img alt="Figure 12.9 – Grafana main page" height="802" src="img/Figure_12.09_B19453.jpg" width="1650"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.9 – Grafana main page</p>
<p>Since it is our first login, this page has nothing to show. We will take care of visualizations in the <em class="italic">Creating an observability </em><em class="italic">dashboard</em> recipe.</p>
<ol>
<li value="5">Now, let’s add Prometheus as a data source to Grafana. On the bottom-left side of the page, hover <a id="_idIndexMarker835"/>your cursor over the engine icon. On the <strong class="bold">Configuration</strong> menu, select <strong class="bold">Data sources</strong>. See the following screenshot for reference:</li>
</ol>
<div><div><img alt="Figure 12.10 – Grafana Configuration menu" height="469" src="img/Figure_12.10_B19453.jpg" width="237"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.10 – Grafana Configuration menu</p>
<ol>
<li value="6">On <a id="_idIndexMarker836"/>the <strong class="bold">Data Sources</strong> page, select the Prometheus icon. You will be redirected to a new page showing fields to insert Prometheus settings, as you can see here:</li>
</ol>
<div><div><img alt="Figure 12.11 – Data Sources page in Grafana" height="719" src="img/Figure_12.11_B19453.jpg" width="781"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.11 – Data Sources page in Grafana</p>
<p>Insert a name for this data source. In the <code>http://prometheus:9090</code>. Make sure it has the same name as your Docker container for Prometheus.</p>
<p>Save this configuration, and we have successfully configured Grafana with Prometheus!</p>
<h2 id="_idParaDest-443"><a id="_idTextAnchor450"/>How it works…</h2>
<p>In this exercise, we saw how simple it is to configure Grafana and integrate it with Prometheus as a data <a id="_idIndexMarker837"/>source. In fact, almost all Grafana integrations are very straightforward, requiring just a few pieces of information.</p>
<p>Let’s now explore some of our Grafana container settings. Despite the standard Docker container settings, a few items require attention, as you can see here:</p>
<pre class="source-code">
  grafana:
    ...
    environment:
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: admin
      GF_PATHS_PROVISIONING: /grafana/provisioning
    ...
    volumes:
      - ./grafana/provisioning:/grafana/provisioning</pre>
<p>The first things are the <code>environment</code> variables, where we define the administrator credentials that allow the first login. Then, we declared the path of Grafana provisioning, and, as you will have noticed, we also inserted this path in the <code>volumes</code> section.</p>
<p>It is inside the <code>provisioning</code> folder where we will have configuration files for data sources connections, plugins, dashboards, and much more. A configuration like this allows more <a id="_idIndexMarker838"/>reliability and version control of dashboards and panels. We could also create the Prometheus data source connection using a .<code>yaml</code> configuration file and place it under the <code>provisioning</code> and <code>datasources</code> folder. It would look similar to this:</p>
<pre class="source-code">
apiVersion: 1
datasources:
  - name: Prometheus
    type: prometheus
    access: proxy
    url: http://prometheus:9090</pre>
<p>Any additional data sources can be placed inside this YAML file. You can explore more about the provisioning configurations in Grafana on the official documentation page at <a href="https://grafana.com/docs/grafana/latest/administration/provisioning/">https://grafana.com/docs/grafana/latest/administration/provisioning/</a>.</p>
<p>With this, we created a simple and efficient monitoring and observability architecture capable of collecting metrics from Airflow (or any other application if needed), storing, and showing them. The architecture can be defined as follows:</p>
<div><div><img alt="Figure 12.12 – Monitoring and observability high-level architecture" height="88" src="img/Figure_12.12_B19453.jpg" width="820"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.12 – Monitoring and observability high-level architecture</p>
<p>We can now start creating <a id="_idIndexMarker839"/>our first dashboard and alerts in the two final recipes of this chapter!</p>
<h2 id="_idParaDest-444"><a id="_idTextAnchor451"/>There’s more…</h2>
<p>Besides Prometheus, Grafana has built-in core data source integrations for many applications. It allows easy configuration and a quick setup, which brings a lot of value and <a id="_idIndexMarker840"/>maturity to a project. You can find more here: <a href="https://grafana.com/docs/grafana/latest/datasources/#built-in-core-data-sources">https://grafana.com/docs/grafana/latest/datasources/#built-in-core-data-sources</a>.</p>
<h3>Grafana Cloud</h3>
<p>Grafana Labs has also made the platform available as fully managed and deployed on the cloud. It is a great <a id="_idIndexMarker841"/>solution for teams that don’t have a dedicated <a id="_idIndexMarker842"/>operations team to support and maintain Grafana. Find more information here: <a href="https://grafana.com/products/cloud/">https://grafana.com/products/cloud/</a>.</p>
<h1 id="_idParaDest-445"><a id="_idTextAnchor452"/>Creating an observability dashboard</h1>
<p>Now, with our tools up and running, we can finally jump into the visualization dashboards. Monitoring and observability dashboards are designed to help gain deep insights into the <a id="_idIndexMarker843"/>health and behavior of our systems. You will observe in this exercise how Grafana can help us create an observability dashboard and a number of features inside it.</p>
<p>In this recipe, we will create our first dashboard with a few panels to better monitor our Airflow application. You will notice that, with a few steps, it is possible to have an overview of how Airflow behaves over time and be prepared to build your future panels.</p>
<h2 id="_idParaDest-446"><a id="_idTextAnchor453"/>Getting ready</h2>
<p>Refer to the <em class="italic">Technical requirements</em> section for this recipe since we will handle it with the same technology.</p>
<p>To accomplish <a id="_idIndexMarker844"/>this exercise, ensure that StatsD, Prometheus, and Grafana are adequately configured and running.</p>
<h2 id="_idParaDest-447"><a id="_idTextAnchor454"/>How to do it…</h2>
<p>Let’s create our dashboard to keep track of Airflow:</p>
<ol>
<li>On the Grafana main page, hover the cursor over the four-squares icon on the left side panel. Then, select <strong class="bold">New dashboard</strong>, as you can see in the following screenshot:</li>
</ol>
<div><div><img alt="Figure 12.13 – Grafana Dashboards menu" height="463" src="img/Figure_12.13_B19453.jpg" width="263"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.13 – Grafana Dashboards menu</p>
<p>If you need help accessing Grafana, refer to the <em class="italic">Setting up Grafana for </em><em class="italic">monitoring</em> recipe.</p>
<ol>
<li value="2">You will be redirected to an empty page with the title <strong class="bold">New dashboard</strong>. At the top right <a id="_idIndexMarker845"/>of the page, select <strong class="bold">Save</strong>, insert the name of your dashboard, and click the <strong class="bold">Save</strong> button again. Refer to the following screenshot:</li>
</ol>
<div><div><img alt="Figure 12.14 – New dashboard page" height="461" src="img/Figure_12.14_B19453.jpg" width="1305"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.14 – New dashboard page</p>
<ol>
<li value="3">Now, let’s create our first panel by clicking on the <strong class="bold">Add panel</strong> icon at the top right of the dashboard page, as you can see in the following screenshot:</li>
</ol>
<div><div><img alt="Figure 12.15 – Add panel icon" height="54" src="img/Figure_12.15_B19453.jpg" width="931"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.15 – Add panel icon</p>
<ol>
<li value="4">Now, let’s create a panel to show the number of DAGs inside Airflow. On the <strong class="bold">Edit Panel</strong> page, set the following information:<ul><li><strong class="bold">Metric</strong>: <strong class="bold">airflow_dagbag_size</strong></li><li><strong class="bold">Label filters</strong>: <strong class="bold">job</strong>, <strong class="bold">statsd-exporter</strong></li><li>Visualization type: <strong class="bold">Stat</strong></li></ul></li>
</ol>
<p>You can <a id="_idIndexMarker846"/>see the filled information in the following screenshot:</p>
<div><div><img alt="Figure 12.16 – Airflow number of DAGs panel count" height="739" src="img/Figure_12.16_B19453.jpg" width="953"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.16 – Airflow number of DAGs panel count</p>
<p>Click on <strong class="bold">Apply</strong> to save and return to the dashboard page.</p>
<ol>
<li value="5">Let’s do the same as <em class="italic">Step 3</em> to create another panel. This time we will create a panel <a id="_idIndexMarker847"/>to show the number of Airflow import errors. Fill the fields with the following values:<ul><li><strong class="bold">Metric</strong>: <strong class="bold">airflow_dag_processing_import_errors</strong></li><li><strong class="bold">Label filters</strong>: <strong class="bold">job</strong>, <strong class="bold">statsd-exporter</strong></li><li>Visualization type: <strong class="bold">Stat</strong></li></ul></li>
</ol>
<p>You can see the added information in the following screenshot:</p>
<div><div><img alt="Figure 12.17 – DAG import errors panel count" height="798" src="img/Figure_12.17_B19453.jpg" width="1028"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.17 – DAG import errors panel count</p>
<ol>
<li value="6">Now, let’s <a id="_idIndexMarker848"/>create two more panels with the following information:<ul><li><code>airflow_executor_queued_tasks</code></li><li><code>job</code>, <code>statsd-exporter</code></li><li>Visualization type: <strong class="bold">Stat</strong></li><li><strong class="bold">Metric</strong>: <strong class="bold">airflow_scheduler_tasks_running</strong></li><li><strong class="bold">Label filters</strong>: <strong class="bold">job</strong>, <strong class="bold">statsd-exporter</strong></li><li>Visualization type: <strong class="bold">Stat</strong></li></ul></li>
<li>Let’s create two more panels to show the execution time for two different DAGs. Create two panels with the following values:<ul><li><strong class="bold">Metric</strong>: <strong class="bold">airflow_dag_processing_last_duration_basic_logging_dag</strong></li><li><strong class="bold">Label filters</strong>: <strong class="bold">quantile</strong>, <strong class="bold">0.99</strong></li><li>Visualization type: <strong class="bold">Time-series</strong></li></ul></li>
</ol>
<p>Refer <a id="_idIndexMarker849"/>to the following screenshot:</p>
<div><div><img alt="Figure 12.18 – basic_logging_dag execution run panel" height="928" src="img/Figure_12.18_B19453.jpg" width="826"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.18 – basic_logging_dag execution run panel</p>
<ul>
<li> <strong class="bold">Metric</strong>: <strong class="bold">airflow_dag_processing_last_duration_holiday_ingest_dag</strong></li>
<li><strong class="bold">Label filters</strong>: <strong class="bold">quantile</strong>, <strong class="bold">0.99</strong></li>
<li>Visualization type: <strong class="bold">Time-series</strong></li>
</ul>
<p>You can <a id="_idIndexMarker850"/>see the completed fields in the following screenshot:</p>
<div><div><img alt="Figure 12.19 – holiday_ingest_dag execution run panel" height="975" src="img/Figure_12.19_B19453.jpg" width="931"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.19 – holiday_ingest_dag execution run panel</p>
<p>In the end, you will end up with a dashboard similar to the following:</p>
<div><div><img alt="Figure 12.20 – Complete Airflow Monitoring dashboard view" height="767" src="img/Figure_12.20_B19453.jpg" width="1652"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.20 – Complete Airflow Monitoring dashboard view</p>
<p>Don’t worry if your dashboard layout does not look exactly like <em class="italic">Figure 12</em><em class="italic">.20</em>. You can rearrange the panel as much as you want to add your own touch!</p>
<h2 id="_idParaDest-448"><a id="_idTextAnchor455"/>How it works…</h2>
<p>There are many DevOps visualization tools available on the market. However, most require a paid subscription or trained people to build the panels. As you can observe in this exercise, creating the first dashboard and panels using Grafana can be pretty simple. Of course, as you practice and study advanced concepts in Grafana, you will observe many opportunities to improve and enhance your dashboard.</p>
<p>Now, let’s <a id="_idIndexMarker851"/>explore the six panels we have created. The idea behind these panels was to create a small dashboard with a minimum of information that could already bring value.</p>
<p>The first four panels give quick and relevant information about Airflow, as follows:</p>
<div><div><img alt="Figure 12.21 –Airflow Monitoring counter panels" height="352" src="img/Figure_12.21_B19453.jpg" width="1410"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.21 –Airflow Monitoring counter panels</p>
<p>They show information about the number of DAGs, how many import errors we have, the number of tasks waiting to be executed, and how many are being executed, respectively. Even though it seems simple, these pieces of information give an overview (therefore, observability) of Airflow’s current behavior.</p>
<p>The last two panels show information about the duration of two DAG executions, as follows:</p>
<div><div><img alt="Figure 12.22 – Airflow Monitoring time-series panels" height="325" src="img/Figure_12.22_B19453.jpg" width="1327"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.22 – Airflow Monitoring time-series panels</p>
<p>Knowing how much time a DAG takes to run is vital information, and it can offer insight to improve the <a id="_idIndexMarker852"/>code or check whether the data used in the pipeline is reliable. For example, if the DAG executes all tasks in less than half the expected time, it can be a sign no data was processed correctly.</p>
<p>Lastly, you can create more dashboards and organize them into folders according to the subject. You can check the recommended best practices for dashboard organization in Grafana’s official documentation here: <a href="https://grafana.com/docs/grafana/latest/dashboards/build-dashboards/best-practices/">https://grafana.com/docs/grafana/latest/dashboards/build-dashboards/best-practices/</a>.</p>
<h2 id="_idParaDest-449"><a id="_idTextAnchor456"/>There’s more…</h2>
<p>Unfortunately, since we have limited data to show on a dashboard, this exercise might not be as fancy as you expected. However, you can explore Grafana panel configurations and master them for further projects using the Grafana playground here: <a href="https://play.grafana.org/d/000000012/grafana-play-home?orgId=1">https://play.grafana.org/d/000000012/grafana-play-home?orgId=1</a>.</p>
<p>On the <strong class="bold">Grafana Play Home</strong> page, you will be able to see different types of panel applications and explore how they were built.</p>
<h1 id="_idParaDest-450"><a id="_idTextAnchor457"/>Setting custom alerts or notiﬁcations</h1>
<p>After configuring our first dashboard to be aware of the Airflow application, we must ensure our monitoring <a id="_idIndexMarker853"/>is never left without <a id="_idIndexMarker854"/>observation. With teams busy with other tasks, creating alerts is the best way to guarantee we still have oversight over the application.</p>
<p>There are many ways to create alerts and notifications, and previously we implemented something similar to monitor our DAG by sending an email notification when an error occurs. Now, we will try a different approach, using an integration with <strong class="bold">Telegram</strong>.</p>
<p>In this recipe, we will integrate Grafana alerts with Telegram. Using a different tool to provide system alerts can help us understand the best approach to advise our teams and break the cycle of always using email.</p>
<h2 id="_idParaDest-451"><a id="_idTextAnchor458"/>Getting ready</h2>
<p>Refer to the <em class="italic">Technical requirements</em> section for this recipe since we will handle it with the same technology.</p>
<p>To accomplish this exercise, ensure that StatsD, Prometheus, and Grafana are adequately configured and running. It is also required to have a Telegram account for this exercise. You can find the steps to create an account here: <a href="https://www.businessinsider.com/guides/tech/how-to-make-a-telegram-account">https://www.businessinsider.com/guides/tech/how-to-make-a-telegram-account</a>.</p>
<h2 id="_idParaDest-452"><a id="_idTextAnchor459"/>How to do it…</h2>
<p>Here are the steps to perform this recipe:</p>
<ol>
<li>Let’s start by creating a bot on Telegram to be used by Grafana to send the alerts. On the Telegram main page, search for <code>@BotFather</code> and start a conversation as follows:</li>
</ol>
<div><div><img alt="Figure 12.23 – Telegram BotFather" height="274" src="img/Figure_12.23_B19453.jpg" width="641"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.23 – Telegram BotFather</p>
<ol>
<li value="2">Then, type <code>/newbot</code> and <a id="_idIndexMarker855"/>follow the <a id="_idIndexMarker856"/>prompt instructions. BotFather will send you a bot token. Please keep it in a safe place; we will use it later. The message looks like the following:</li>
</ol>
<div><div><img alt="Figure 12.24 – New bot creation message" height="326" src="img/Figure_12.24_B19453.jpg" width="614"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.24 – New bot creation message</p>
<ol>
<li value="3">Next, create a group on Telegram and invite your bot to it with administrator privileges.</li>
<li>Now, let’s use the Telegram API to check the channel ID where the bot is. You can do it by using the following address in your browser:<pre class="source-code">
https://api.telegram.org/bot&lt;YOUR CODE HERE&gt;/getUpdates</pre></li>
</ol>
<p>You should see a similar output in the browser:</p>
<div><div><img alt="Figure 12.25 – Telegram API message with Chat ID" height="74" src="img/Figure_12.25_B19453.jpg" width="1223"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.25 – Telegram API message with Chat ID</p>
<p>We will use the <code>id</code> value later, so keep this in a safe place too.</p>
<ol>
<li value="5">Then, let’s <a id="_idIndexMarker857"/>proceed to create a Grafana <a id="_idIndexMarker858"/>notification group. On the left menu bar, hover your cursor over the bell icon, and select <strong class="bold">Contact points</strong>, shown as follows:</li>
</ol>
<div><div><img alt="Figure 12.26 – Grafana Alerting menu" height="557" src="img/Figure_12.26_B19453.jpg" width="241"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.26 – Grafana Alerting menu</p>
<ol>
<li value="6">On <a id="_idIndexMarker859"/>the <strong class="bold">Contact points</strong> tab, select <strong class="bold">Add contact point</strong> as <a id="_idIndexMarker860"/>follows:</li>
</ol>
<div><div><img alt="Figure 12.27 – Contact points tab in Grafana" height="546" src="img/Figure_12.27_B19453.jpg" width="958"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.27 – Contact points tab in Grafana</p>
<ol>
<li value="7">Add a name <a id="_idIndexMarker861"/>on the <strong class="bold">New contact point</strong> page <a id="_idIndexMarker862"/>and choose <strong class="bold">Telegram</strong> in the <strong class="bold">Integration</strong> drop-down menu. Then, complete the <strong class="bold">Bot API Token</strong> and <strong class="bold">Chat ID</strong> fields. You can see what it looks like here:</li>
</ol>
<div><div><img alt="Figure 12.28 – New contact point page" height="412" src="img/Figure_12.28_B19453.jpg" width="568"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.28 – New contact point page</p>
<ol>
<li value="8">Now, let’s ensure we inserted the values correctly while selecting the <strong class="bold">Test</strong> button. If everything is well configured, you will receive a message on the channel you have your bot in, as follows:</li>
</ol>
<div><div><img alt="Figure 12.29 – Grafana test message working successfully" height="385" src="img/Figure_12.29_B19453.jpg" width="560"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.29 – Grafana test message working successfully</p>
<p>It means our bot is ready! Save the contact point and go back to the alerts page.</p>
<ol>
<li value="9">In <strong class="bold">Notification policies</strong>, edit the <strong class="bold">Root policy</strong> contact point to your Telegram bot as follows:</li>
</ol>
<div><div><img alt="Figure 12.30 – Grafana Notification policies tab" height="416" src="img/Figure_12.30_B19453.jpg" width="875"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.30 – Grafana Notification policies tab</p>
<ol>
<li value="10">Finally, let’s <a id="_idIndexMarker863"/>create an alert rule to trigger <a id="_idIndexMarker864"/>an alert notification. On the <strong class="bold">Alert rules</strong> page, select <strong class="bold">Create alert rule</strong> to be redirected to a new page. Insert the following values in the fields on this page:<ul><li><strong class="bold">Rule name</strong>: <strong class="bold">Import errors</strong></li><li><strong class="bold">Metric</strong>: <strong class="bold">airflow_dag_processing_import_errors</strong></li><li><strong class="bold">Label filters</strong>: <strong class="bold">instance</strong>, <strong class="bold">statsd-exporter:9102</strong></li><li><strong class="bold">Threshold</strong>: <strong class="bold">Input A</strong>, <strong class="bold">IS </strong><strong class="bold">ABOVE 1</strong></li><li><strong class="bold">Folder</strong>: Create a new folder called <strong class="bold">Errors</strong> and <strong class="bold">test_group</strong> in <strong class="bold">Evaluation group</strong></li><li><strong class="bold">Rule group evaluation interval</strong>: <strong class="bold">3 minutes</strong></li></ul></li>
</ol>
<p>You should have something similar to the following screenshot. You can also use it as a reference to fill in the fields:</p>
<div><div><img alt="Figure 12.31 – New alert rule for Airflow import errors on Grafana" height="1229" src="img/Figure_12.31_B19453.jpg" width="1100"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.31 – New alert rule for Airflow import errors on Grafana</p>
<p>Save it, and let’s <a id="_idIndexMarker865"/>simulate an import <a id="_idIndexMarker866"/>error in Airflow.</p>
<ol>
<li value="11">After creating any import error in a DAG on Airflow, you will receive a notification on the Telegram channel similar to the following:</li>
</ol>
<div><div><img alt="Figure 12.32 – Telegram bot showing a notification after being triggered by a Grafana alert" height="368" src="img/Figure_12.32_B19453.jpg" width="463"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.32 – Telegram bot showing a notification after being triggered by a Grafana alert</p>
<p>Since this is a local test, you don’t need to worry about the <code>Annotations</code> part for now.</p>
<p>Our Grafana notification works, and it is fully integrated with Telegram!</p>
<h2 id="_idParaDest-453"><a id="_idTextAnchor460"/>How it works…</h2>
<p>Although this recipe has many steps, the content is not complex. This exercise aims to give you a practical end-to-end example of configuring a simple bot to create alerts whenever needed.</p>
<p>Bots are frequently used in DevOps as a tool for notifications of an action, and it was no different <a id="_idIndexMarker867"/>here. From <em class="italic">Step 1</em> to <em class="italic">Step 4</em>, we focused on configuring a bot in Telegram and a channel where Grafana notifications could be sent. There is no particular reason for choosing Telegram as our messenger, other than the ease of creating an account. Usually, messengers such as <strong class="bold">Slack</strong> or <strong class="bold">Microsoft Teams</strong> are the favorites of operation teams, and plenty <a id="_idIndexMarker868"/>of online tutorials <a id="_idIndexMarker869"/>show how to use them.</p>
<p>After configuring the bot, we <a id="_idIndexMarker870"/>proceeded to <a id="_idIndexMarker871"/>connect it with Grafana. The configuration only required a few pieces of information, such as an authentication token (to control the bot) and the channel’s ID. As you observed, many types of integrations are available, and more can be added when installing a plugin. You can see the complete list of plugins here: <a href="https://grafana.com/grafana/plugins/">https://grafana.com/grafana/plugins/</a>.</p>
<p>If we needed more than one contact point, we could create it on the <strong class="bold">Contact points</strong> tab and create a notification policy to include the new contact as a point to be notified.</p>
<p>Finally, we created an <a id="_idIndexMarker872"/>alert rule based on the number of Airflow <a id="_idIndexMarker873"/>import errors. Import errors can impair the execution of one or more DAGs; therefore, they are relevant items to monitor.</p>
<p>There are two ways <a id="_idIndexMarker874"/>to create an alert and notification: on the <strong class="bold">Alert rules</strong> page and directly on a dashboard panel. The latter depends on the panel type, and not all of the panels support integrated alerts. The safest option, and the best practice, is to create an alert rule on the <strong class="bold">Alert </strong><strong class="bold">rules</strong> page.</p>
<p>Creating an alert is similar to a panel, where we need to identify metrics and labels, and the critical points are the <strong class="bold">Threshold</strong> and <strong class="bold">Alert Evaluation</strong> conditions. These two configurations will determine the limit of metric value acceptance and how long it can take. We set a shallow threshold with a short evaluation time for testing purposes and intentionally provoked an error. Still, a standard alert rule can have more time tolerance and a threshold based on the needs of the team.</p>
<p>In the end, with everything well set, we saw the bot in action, providing the alert as soon as the trigger conditions were met.</p>
<h1 id="_idParaDest-454"><a id="_idTextAnchor461"/>Further reading</h1>
<ul>
<li><a href="https://dev.to/kirklewis/metrics-with-prometheus-statsd-exporter-and-grafana-5145">https://dev.to/kirklewis/metrics-with-prometheus-statsd-exporter-and-grafana-5145</a></li>
<li><a href="https://github.com/uber/cadence/pull/4793/files#diff-32d8136ee76608ed05392cfd5e8dce9a56ebdad629f7b87961c69a13edef88ec">https://github.com/uber/cadence/pull/4793/files#diff-32d8136ee76608ed05392cfd5e8dce9a56ebdad629f7b87961c69a13edef88ec</a></li>
<li><a href="https://databand.ai/blog/everyday-data-engineering-monitoring-airflow-with-prometheus-statsd-and-grafana/">https://databand.ai/blog/everyday-data-engineering-monitoring-airflow-with-prometheus-statsd-and-grafana/</a></li>
<li><a href="https://www.xenonstack.com/insights/observability-vs-monitoring">https://www.xenonstack.com/insights/observability-vs-monitoring</a></li>
<li><a href="https://www.instana.com/blog/observability-vs-monitoring/">https://www.instana.com/blog/observability-vs-monitoring/</a></li>
<li><a href="https://acceldataio.medium.com/a-guide-to-evaluating-data-observability-tools-5589ad9d35ed">https://acceldataio.medium.com/a-guide-to-evaluating-data-observability-tools-5589ad9d35ed</a></li>
</ul>
</div>
</div></body></html>