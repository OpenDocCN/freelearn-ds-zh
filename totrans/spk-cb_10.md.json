["```py\n    user id | item id | rating | epoch time\n    ```", "```py\n    movie id | movie title | release date | video release date |               IMDb URL | unknown | Action | Adventure | Animation |               Children's | Comedy | Crime | Documentary | Drama | Fantasy |               Film-Noir | Horror | Musical | Mystery | Romance | Sci-Fi |               Thriller | War | Western |\n    ```", "```py\n$ hdfs dfs -put moviedata moviedata\n\n```", "```py\n944,313,5\n944,2,3\n944,1,1\n944,43,4\n944,67,4\n944,82,5\n944,96,5\n944,121,4\n944,148,4\n```", "```py\n    $ hdfs dfs -put p.data p.data\n\n    ```", "```py\n    scala> import org.apache.spark.mllib.recommendation.ALS\n    scala> import org.apache.spark.mllib.recommendation.Rating\n\n    ```", "```py\n    scala> val data = sc.textFile(\"moviedata/u.data\")\n\n    ```", "```py\n    scala> val ratings = data.map { line => \n     val Array(userId, itemId, rating, _) = line.split(\"\\t\") \n     Rating(userId.toInt, itemId.toInt, rating.toDouble) \n    }\n\n    ```", "```py\n    scala> val pdata = sc.textFile(\"p.data\")\n\n    ```", "```py\n    scala> val pratings = pdata.map { line => \n     val Array(userId, itemId, rating) = line.split(\",\")\n     Rating(userId.toInt, itemId.toInt, rating.toDouble) \n    }\n\n    ```", "```py\n    scala> val movieratings = ratings.union(pratings)\n\n    ```", "```py\n    scala> val model = ALS.train(movieratings, 10, 10, 0.01)\n\n    ```", "```py\n    scala> model.predict(sc.parallelize(Array((944,195)))).collect.foreach(println)\n    Rating(944,195,4.198642954004738)\n\n    ```", "```py\n    scala> model.predict(sc.parallelize(Array((944,402)))).collect.foreach(println)\n    Rating(944,402,2.982213836456829)\n\n    ```", "```py\n    scala> model.predict(sc.parallelize(Array((944,402)))).collect.foreach(println)\n    Rating(944,148,3.8629938805450035)\n\n    ```", "```py\n    $ hdfs dfs -mkdir songdata\n\n    ```", "```py\n    $ hdfs dfs -put kaggle_visible_evaluation_triplets.txt songdata/\n    $ hdfs dfs -put kaggle_users.txt songdata/\n    $ hdfs dfs -put kaggle_songs.txt songdata/\n\n    ```", "```py\n    scala> val songs = sc.textFile(\"songdata/kaggle_songs.txt\")\n\n    ```", "```py\n    scala> val users = sc.textFile(\"songdata/kaggle_users.txt\")\n\n    ```", "```py\n    scala> val triplets = sc.textFile(\"songdata/kaggle_visible_evaluation_triplets.txt\")\n\n    ```", "```py\n    scala> val songIndex = songs.map(_.split(\"\\\\W+\")).map(v => (v(0),v(1).toInt))\n\n    ```", "```py\n    scala> val songMap = songIndex.collectAsMap\n\n    ```", "```py\n    scala> val userIndex = users.zipWithIndex.map( t => (t._1,t._2.toInt))\n\n    ```", "```py\n    scala> val userMap = userIndex.collectAsMap\n\n    ```", "```py\n    scala> val broadcastUserMap = sc.broadcast(userMap)\n\n    ```", "```py\n    scala> val broadcastSongMap = sc.broadcast(songMap)\n\n    ```", "```py\n    scala> val tripArray = triplets.map(_.split(\"\\\\W+\"))\n\n    ```", "```py\n    scala> import org.apache.spark.mllib.recommendation.Rating\n\n    ```", "```py\n    scala> val ratings = tripArray.map { case Array(user, song, plays) =>\n     val userId = broadcastUserMap.value.getOrElse(user, 0)\n     val songId = broadcastUserMap.value.getOrElse(song, 0)\n     Rating(userId, songId, plays.toDouble)\n    }\n\n    ```", "```py\n    scala> import org.apache.spark.mllib.recommendation.ALS\n\n    ```", "```py\n    scala> val model = ALS.trainImplicit(ratings, 10, 10)\n\n    ```", "```py\n    scala> val usersSongs = ratings.map( r => (r.user, r.product) )\n\n    ```", "```py\n    scala> val predictions = model.predict(usersSongs)\n\n    ```", "```py\nsc.hadoopConfiguration.set(\"fs.s3n.awsAccessKeyId\", \"<your access key>\")\nsc.hadoopConfiguration.set(\"fs.s3n.awsSecretAccessKey\",\"<your secret key>\")\nval songs = sc.textFile(\"s3n://com.infoobjects.songdata/kaggle_songs.txt\")\nval users = sc.textFile(\"s3n://com.infoobjects.songdata/kaggle_users.txt\")\nval triplets = sc.textFile(\"s3n://com.infoobjects.songdata/kaggle_visible_evaluation_triplets.txt\")\nval songIndex = songs.map(_.split(\"\\\\W+\")).map(v => (v(0),v(1).toInt))\nval songMap = songIndex.collectAsMap\nval userIndex = users.zipWithIndex.map( t => (t._1,t._2.toInt))\nval userMap = userIndex.collectAsMap\nval broadcastUserMap = sc.broadcast(userMap)\nval broadcastSongMap = sc.broadcast(songMap)\nval tripArray = triplets.map(_.split(\"\\\\W+\"))\nimport org.apache.spark.mllib.recommendation.Rating\nval ratings = tripArray.map{ v =>\n val userId: Int = broadcastUserMap.value.get(v(0)).fold(0)(num => num)\n val songId: Int = broadcastSongMap.value.get(v(1)).fold(0)(num => num)\n Rating(userId,songId,v(2).toDouble)\n }\nimport org.apache.spark.mllib.recommendation.ALS\nval model = ALS.trainImplicit(ratings, 50, 30, 0.000001, 40)\nval usersSongs = ratings.map( r => (r.user, r.product) )\nval predictions =model.predict(usersSongs)\n\n```"]