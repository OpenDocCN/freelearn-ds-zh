["```py\nimport pycuda.driver as drv\ndrv.init()\n```", "```py\nprint 'Detected {} CUDA Capable device(s)'.format(drv.Device.count())\n```", "```py\nfor i in range(drv.Device.count()):\n\n     gpu_device = drv.Device(i)\n     print 'Device {}: {}'.format( i, gpu_device.name() )\n     compute_capability = float( '%d.%d' % gpu_device.compute_capability() )\n     print '\\t Compute Capability: {}'.format(compute_capability)\n     print '\\t Total Memory: {} megabytes'.format(gpu_device.total_memory()//(1024**2))\n```", "```py\n    device_attributes_tuples = gpu_device.get_attributes().iteritems()\n     device_attributes = {}\n\n     for k, v in device_attributes_tuples:\n         device_attributes[str(k)] = v\n```", "```py\n    num_mp = device_attributes['MULTIPROCESSOR_COUNT']\n```", "```py\n    cuda_cores_per_mp = { 5.0 : 128, 5.1 : 128, 5.2 : 128, 6.0 : 64, 6.1 : 128, 6.2 : 128}[compute_capability]\n```", "```py\n    print '\\t ({}) Multiprocessors, ({}) CUDA Cores / Multiprocessor: {} CUDA Cores'.format(num_mp, cuda_cores_per_mp, num_mp*cuda_cores_per_mp)\n```", "```py\n    device_attributes.pop('MULTIPROCESSOR_COUNT')\n\n     for k in device_attributes.keys():\n         print '\\t {}: {}'.format(k, device_attributes[k])\n```", "```py\nimport numpy as np\nimport pycuda.autoinit\nfrom pycuda import gpuarray\nfrom time import time\nhost_data = np.float32( np.random.random(50000000) )\n\nt1 = time()\nhost_data_2x =  host_data * np.float32(2)\nt2 = time()\n\nprint 'total time to compute on CPU: %f' % (t2 - t1)\ndevice_data = gpuarray.to_gpu(host_data)\n\nt1 = time()\ndevice_data_2x =  device_data * np.float32( 2 )\nt2 = time()\n\nfrom_device = device_data_2x.get()\nprint 'total time to compute on GPU: %f' % (t2 - t1)\n\nprint 'Is the host computation the same as the GPU computation? : {}'.format(np.allclose(from_device, host_data_2x) )\n```", "```py\nwith open('time_calc0.py','r') as f:\n     time_calc_code = f.read()\n```", "```py\nimport numpy as np\nimport pycuda.autoinit\nfrom pycuda import gpuarray\nfrom time import time\nfrom pycuda.elementwise import ElementwiseKernel\nhost_data = np.float32( np.random.random(50000000) )\ngpu_2x_ker = ElementwiseKernel(\n\"float *in, float *out\",\n\"out[i] = 2*in[i];\",\n\"gpu_2x_ker\")\n```", "```py\ndef speedcomparison():\n    t1 = time()\n    host_data_2x =  host_data * np.float32(2)\n    t2 = time()\n    print 'total time to compute on CPU: %f' % (t2 - t1)\n    device_data = gpuarray.to_gpu(host_data)\n    # allocate memory for output\n    device_data_2x = gpuarray.empty_like(device_data)\n    t1 = time()\n    gpu_2x_ker(device_data, device_data_2x)\n    t2 = time()\n    from_device = device_data_2x.get()\n    print 'total time to compute on GPU: %f' % (t2 - t1)\n    print 'Is the host computation the same as the GPU computation? : {}'.format(np.allclose(from_device, host_data_2x) )\n\nif __name__ == '__main__':\n    speedcomparison()\n```", "```py\ndevice_data = gpuarray.to_gpu(host_data)\n# allocate memory for output\ndevice_data_2x = gpuarray.empty_like(device_data)\n```", "```py\ngpu_2x_ker(device_data, device_data_2x)\n```", "```py\ndef gpu_mandelbrot(width, height, real_low, real_high, imag_low, imag_high, max_iters, upper_bound):\n```", "```py\n    real_vals = np.matrix(np.linspace(real_low, real_high, width), dtype=np.complex64)\n    imag_vals = np.matrix(np.linspace( imag_high, imag_low, height), dtype=np.complex64) * 1j\n    mandelbrot_lattice = np.array(real_vals + imag_vals.transpose(), dtype=np.complex64)  \n```", "```py\n    # copy complex lattice to the GPU\n    mandelbrot_lattice_gpu = gpuarray.to_gpu(mandelbrot_lattice)    \n    # allocate an empty array on the GPU\n    mandelbrot_graph_gpu = gpuarray.empty(shape=mandelbrot_lattice.shape, dtype=np.float32)\n```", "```py\n    mandel_ker( mandelbrot_lattice_gpu, mandelbrot_graph_gpu, np.int32(max_iters), np.float32(upper_bound))\n\n    mandelbrot_graph = mandelbrot_graph_gpu.get()\n\n    return mandelbrot_graph\n```", "```py\nimport pycuda.autoinit\nfrom pycuda import gpuarray\nfrom pycuda.elementwise import ElementwiseKernel\n```", "```py\nmandel_ker = ElementwiseKernel(\n\"pycuda::complex<float> *lattice, float *mandelbrot_graph, int max_iters, float upper_bound\",\n\"\"\"\nmandelbrot_graph[i] = 1;\npycuda::complex<float> c = lattice[i]; \npycuda::complex<float> z(0,0);\nfor (int j = 0; j < max_iters; j++)\n    {  \n     z = z*z + c;     \n     if(abs(z) > upper_bound)\n         {\n          mandelbrot_graph[i] = 0;\n          break;\n         }\n    }         \n\"\"\",\n\"mandel_ker\")\n```", "```py\nimport numpy as np\nimport pycuda.autoinit\nfrom pycuda import gpuarray\nfrom pycuda.scan import InclusiveScanKernel\nseq = np.array([1,2,3,4],dtype=np.int32)\nseq_gpu = gpuarray.to_gpu(seq)\nsum_gpu = InclusiveScanKernel(np.int32, \"a+b\")\nprint sum_gpu(seq_gpu).get()\nprint np.cumsum(seq)\n```", "```py\nimport numpy as np\nimport pycuda.autoinit\nfrom pycuda import gpuarray\nfrom pycuda.scan import InclusiveScanKernel\nseq = np.array([1,100,-3,-10000, 4, 10000, 66, 14, 21],dtype=np.int32)\nseq_gpu = gpuarray.to_gpu(seq)\nmax_gpu = InclusiveScanKernel(np.int32, \"a > b ? a : b\")\nprint max_gpu(seq_gpu).get()[-1]\nprint np.max(seq)\n```", "```py\ndot_prod = ReductionKernel(np.float32, neutral=\"0\", reduce_expr=\"a+b\", map_expr=\"vec1[i]*vec2[i]\", arguments=\"float *vec1, float *vec2\")\n\n```"]