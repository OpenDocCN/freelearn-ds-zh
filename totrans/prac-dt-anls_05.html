<html><head></head><body>
        <section>

                            <header class="header-title chapter-title">
                    Creating Your First pandas DataFrame
                </header>
            
            <article>
                
<p>In this chapter, we will go through the core data analysis skills of using filesystems and formats. We will explore different file formats for text data using the Python OS and string libraries to manipulate textual and numerical data from source files, such as <strong>Comma-Separated Values</strong><span> (</span><strong>CSV</strong>),<span> </span><span><strong>Extensible Markup Language</strong> </span><span>(</span><strong><span>XML</span></strong><span>), and</span><span> </span><strong>JavaScript Object Notation </strong><span>(</span><strong>JSON</strong><span>)</span><span>. You will learn what a</span> pandas <span>DataFrame is and how to create DataFrames from file sources for data analysis.</span></p>
<p>We will cover the following topics in this chapter:</p>
<ul>
<li>Techniques for manipulating tabular data</li>
<li>Understanding pandas and DataFrames</li>
<li>Handling essential data formats</li>
<li>Data dictionaries and data types</li>
<li>Creating your first DataFrame</li>
</ul>
<h1 id="uuid-d422cd78-dce6-428a-b0f5-9f7b7ca358a5">Technical requirements</h1>
<p>Here's the GitHub repository for this book: <a href="https://github.com/PacktPublishing/Practical-Data-Analysis-using-Jupyter-Notebook/tree/master/Chapter04">https://github.com/PacktPublishing/Practical-Data-Analysis-using-Jupyter-Notebook/tree/master/Chapter04</a>.</p>
<p>You can download and install the required software from the following link: <a href="https://www.anaconda.com/distribution/">https://www.anaconda.com/distribution/</a></p>
<p class="mce-root"/>
<p><a href="https://www.anaconda.com/distribution/"/></p>
<h1 id="uuid-85d77ea6-20d4-4cb2-8fde-471073393a9e">Techniques for manipulating tabular data</h1>
<p>Now that we have a better understanding of array data structures from using the NumPy library in <a href="dd40977f-7c89-4933-944f-d9760d3ca217.xhtml">Chapter 3</a>, <em>Getting Started with NumPy</em>, we can now expand our data analysis expertise. We will do this by working with tabular data and focusing on a powerful library available in Python named <kbd>pandas</kbd>, which is available to use in our Jupyter notebooks.</p>
<p>The <kbd>pandas</kbd> library extends our ability to analyze structured data and was introduced as a Python library back in 2008 by Wes McKinney. McKinney recognized the power of extending the Python language by using libraries and the need to fill the gap that existed between data preparation and data insights by <em>carrying out the entire data analysis workflow in Python without having to switch to a more domain-specific language such as R</em>.</p>
<p>The <kbd>pandas</kbd> Python library name was taken from the term <strong>panel data</strong> (by <span>McKinney</span>) by shortening and combining the terms to get <kbd><span>pan</span></kbd> and <kbd>da</kbd>. Panel data is defined as observations that can be measured over a period of time with <span>multiple dimensional values and is very common in </span>statistical studies and research papers. I have also seen panel data referred to as longitudinal data, facts panel data, or cross-sectional time-series data. Panel data is presented in tabular form with rows and columns and comes in a few different types, such as balanced, unbalanced, long, short, fixed, and rotating. </p>
<p>Each of these panel data types are based on how precisely the quantity of the dataset is represented. The total number of observations (rows of data) is commonly identified using the letter <kbd>N</kbd>. <span>The unit of the time element used, such as year, month, quarter, or date is typically identified using the letter</span> <kbd>T</kbd> <span>in either upper or lowercase. </span>The dimensions or variables (columns of data) can be represented with specific letters for each entity, such as <kbd>x</kbd> or <kbd>z</kbd>. What is measured can be represented as one or more variables and is commonly assigned to <kbd>y</kbd>. You should be able to summarize any panel data as a representative sample in descriptive terms for the consumer to understand before viewing or working with it in tabular form.</p>
<div class="packt_tip">Depending on the dataset, the dimensions may or may not change over time, so different letters, such as <kbd>k</kbd>, may be assigned to represent that distinction.</div>
<p class="mce-root"/>
<p><span>An example of panel data is a daily closing price over 3 days for three publicly traded companies, as in the following table: </span></p>
<table style="border-collapse: collapse;width: 100%" border="1">
<tbody>
<tr>
<td class="CDPAlignCenter CDPAlign">
<p><strong><span>Date</span></strong></p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p><strong><span>Stock Ticker</span></strong></p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p><strong><span>Closing Price</span></strong></p>
</td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign">
<p>12/2/2019</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>ABC</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>$50.21</p>
</td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign">
<p>12/3/2019</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>ABC</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>$52.22</p>
</td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign">
<p>12/4/2019</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>ABC</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>$51.01</p>
</td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign">
<p>12/2/2019</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>DEF</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>$24.22</p>
</td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign">
<p>12/3/2019</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>DEF</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>$26.22</p>
</td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign">
<p>12/4/2019</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>DEF</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>$29.50</p>
</td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign">
<p>12/2/2019</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>GHI</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>$61.22</p>
</td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign">
<p>12/3/2019</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>GHI</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>$65.33</p>
</td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign">
<p>12/4/2019</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>GHI</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>$75.00</p>
</td>
</tr>
</tbody>
</table>
<p> </p>
<p>Another example is the minimum, maximum, and average temperatures, in Fahrenheit, by ZIP code for the last three months (by month), as in the following table:</p>
<table style="border-collapse: collapse;width: 100%" border="1">
<tbody>
<tr>
<td class="CDPAlignCenter CDPAlign">
<p><strong>Month</strong></p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p><strong>ZIP Code</strong></p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p><strong>Minimum Temperature</strong></p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p><strong>Maximum Temperature</strong></p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p><strong>Average Temperature</strong></p>
</td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign">
<p>June</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>19901</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>75</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>88</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>82</p>
</td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign">
<p>July</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>19901</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>77</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>90</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>84</p>
</td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign">
<p>August</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>19901</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>68</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>85</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>77</p>
</td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign">
<p>June</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>08618</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>76</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>89</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>83</p>
</td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign">
<p>July</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>08618</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>78</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>91</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>85</p>
</td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign">
<p>August</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>08618</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>69</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>86</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>78</p>
</td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign">
<p>June</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>18940</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>74</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>87</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>81</p>
</td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign">
<p>July</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>18940</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>76</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>89</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>83</p>
</td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign">
<p>August</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>18940</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>67</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>84</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>76</p>
</td>
</tr>
</tbody>
</table>
<div class="packt_tip">An unbalanced panel would be one where one or more values are missing for any one of the dimensional values. A balanced panel would be an inclusive dataset where all the elements from each dimension are included across all periods of time. </div>
<p>We know from <a href="0fa7e28f-7a30-4099-9bae-30dd3c86ee4f.xhtml">Chapter 1</a>, <em>Fundamentals of Data Analysis</em>, that data comes in all shapes and sizes, so having data structured in tabular form will be the first step in the analysis process, but in many cases, not the final one. For example, in the following table, we have a summary pivot table of total sales by city over the last 3 years.</p>
<p>This summary data can be identified as a cross table, which makes it easier for the consumer of this data to quickly identify the highest and lowest sales by <span class="packt_screen">City</span> and by <span class="packt_screen">Year</span>. In this case, this would be New York in 2019 with $120,000 and Boston in 2017 with $25,000:</p>
<table style="border-collapse: collapse;width: 100%" border="1">
<tbody>
<tr>
<td class="CDPAlignCenter CDPAlign"><strong><span>City</span></strong></td>
<td class="CDPAlignCenter CDPAlign">
<p><strong>2017</strong></p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p><strong>2018</strong></p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p><strong>2019</strong></p>
</td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign">
<p>Philadelphia</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>$50,000</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>$75,000</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>$100,000</p>
</td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign">
<p>New York</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>$35,000</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>$65,000</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>$120,000</p>
</td>
</tr>
<tr>
<td class="CDPAlignCenter CDPAlign">
<p>Boston</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>$25,000</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>$40,000</p>
</td>
<td class="CDPAlignCenter CDPAlign">
<p>$ 90,000</p>
</td>
</tr>
</tbody>
</table>
<p> </p>
<p>If this tabular form of data had a limited number of rows and columns, this would be the final step in your analysis because you can quickly answer most business questions without additional manipulation, such as which city has the highest sales. However, what if the number of records increased to display over 100 cities and we increased the number of years to the last 10? What if you wanted to get more details to better understand the sales, breaking down the amount by increasing the number of dimensions, such as the product, store number, date of the transaction, time of the day, and method of payment?</p>
<p>Increasing the number of columns would make it challenging and time-consuming to answer a simple business question, such as what is the average sales across all cities across all years? Therefore, the ability to scale your analysis is dependent on your ability to manipulate the data beyond how the source is received.</p>
<p>A best practice in data analysis is <em>to begin with the end in mind</em>. So, for this example, the output table we want to produce will look similar to the following table, where we have transposed the columns into rows to make it easier for additional analysis to be carried out and so that we are prepared to handle a larger volume of data:</p>
<div class="packt_tip">A large scale of data volume is a subjective term but the techniques used should support analyzing millions or billions of rows of data. You will need additional infrastructure beyond the limits of your personal workstation's available RAM and CPU.</div>
<table style="border-collapse: collapse;width: 100%" border="1">
<tbody>
<tr>
<td style="width: 145px" class="CDPAlignCenter CDPAlign">
<p><strong>City</strong></p>
</td>
<td style="width: 94px" class="CDPAlignCenter CDPAlign">
<p><strong>Year</strong></p>
</td>
<td style="width: 170px" class="CDPAlignCenter CDPAlign">
<p><strong>Sales</strong></p>
</td>
</tr>
<tr>
<td style="width: 145px" class="CDPAlignCenter CDPAlign">
<p>Philadelphia</p>
</td>
<td style="width: 94px" class="CDPAlignCenter CDPAlign">
<p>2017</p>
</td>
<td style="width: 170px" class="CDPAlignCenter CDPAlign">
<p>$50,000</p>
</td>
</tr>
<tr>
<td style="width: 145px" class="CDPAlignCenter CDPAlign"/>
<td style="width: 94px" class="CDPAlignCenter CDPAlign">
<p>2018</p>
</td>
<td style="width: 170px" class="CDPAlignCenter CDPAlign">
<p>$75,000</p>
</td>
</tr>
<tr>
<td style="width: 145px" class="CDPAlignCenter CDPAlign"/>
<td style="width: 94px" class="CDPAlignCenter CDPAlign">
<p>2019</p>
</td>
<td style="width: 170px" class="CDPAlignCenter CDPAlign">
<p>$100,000</p>
</td>
</tr>
<tr>
<td style="width: 145px" class="CDPAlignCenter CDPAlign">
<p>New York</p>
</td>
<td style="width: 94px" class="CDPAlignCenter CDPAlign">
<p>2017</p>
</td>
<td style="width: 170px" class="CDPAlignCenter CDPAlign">
<p>$35,000</p>
</td>
</tr>
<tr>
<td style="width: 145px" class="CDPAlignCenter CDPAlign"/>
<td style="width: 94px" class="CDPAlignCenter CDPAlign">
<p>2018</p>
</td>
<td style="width: 170px" class="CDPAlignCenter CDPAlign">
<p>$65,000</p>
</td>
</tr>
<tr>
<td style="width: 145px" class="CDPAlignCenter CDPAlign"/>
<td style="width: 94px" class="CDPAlignCenter CDPAlign">
<p>2019</p>
</td>
<td style="width: 170px" class="CDPAlignCenter CDPAlign">
<p>$120,000</p>
</td>
</tr>
<tr>
<td style="width: 145px" class="CDPAlignCenter CDPAlign">
<p>Boston</p>
</td>
<td style="width: 94px" class="CDPAlignCenter CDPAlign">
<p>2017</p>
</td>
<td style="width: 170px" class="CDPAlignCenter CDPAlign">
<p>$25,000</p>
</td>
</tr>
<tr>
<td style="width: 145px" class="CDPAlignCenter CDPAlign"/>
<td style="width: 94px" class="CDPAlignCenter CDPAlign">
<p>2018</p>
</td>
<td style="width: 170px" class="CDPAlignCenter CDPAlign">
<p>$40,000</p>
</td>
</tr>
<tr>
<td style="width: 145px" class="CDPAlignCenter CDPAlign"/>
<td style="width: 94px" class="CDPAlignCenter CDPAlign">
<p>2019</p>
</td>
<td style="width: 170px" class="CDPAlignCenter CDPAlign">
<p>$90,000</p>
</td>
</tr>
</tbody>
</table>
<p> </p>
<p class="mce-root">From the preceding output, we can see that:</p>
<ul>
<li>The first advantage of having data structured similar to the way it is in the preceding output table is that there is a single conformed data type for each column, which is also known as a dimension or axis.</li>
<li>The second advantage is that it becomes much easier for statistical analysis to be carried out because each dimension can be treated as an independent array of values of the same data type where calculations can be performed using NumPy, as covered in <a href="dd40977f-7c89-4933-944f-d9760d3ca217.xhtml">Chapter 3</a>, <em>Getting Started with NumPy</em>.</li>
<li>The third advantage is the ability to sort by any field in the table without worrying about the data values in each row/tuple becoming misaligned or inconsistent.</li>
<li>Keeping the integrity of your data builds trust in your process and ensures your analysis will be accurate.</li>
</ul>
<p>It is recommended that you break down each step during the manipulation of data to allow the repeatability of the process—for example, if you were asked to go through the process after a few months had passed or if you had to troubleshoot anomalies that exist in the underlining source data, which is very common.</p>
<h1 id="uuid-10c2e50c-85ea-451b-ba28-c083face14cd">Understanding pandas and DataFrames</h1>
<p>Now that we have a better understanding of tabular data and we have provided some background about panel data and the origins of why the <kbd>pandas</kbd> library was created, let's dive into some examples using <kbd>pandas</kbd> and explain how DataFrames are used.</p>
<p class="mce-root"/>
<p>The <kbd>pandas</kbd> library is a powerful Python library used for changing and analyzing data. A <kbd>pandas</kbd> DataFrame is a feature available in the library and is defined as a two-dimensional, size-mutable, potentially heterogeneous tabular data structure with labeled axes (rows and columns). A DataFrame is a two-dimensional data structure—that is, data is aligned in a tabular fashion in rows and columns. It is commonly known that <kbd>pandas</kbd> DataFrame consists of three principal components: the data, the rows, and the columns. Being a visual learner myself, I created an example of this with the following diagram, which we can go through now:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/0a2ad74d-0276-47cd-a0e4-a28c7ee5d006.png" style="width:51.50em;height:26.33em;"/></p>
<p>DataFrames can be compared to a spreadsheet, such as Microsoft Excel or Google Sheets, a single database SQL table found in any <strong>Relational Database Management System</strong> (<strong>RDBMS</strong>), or even a <span><strong>QlikView Data</strong> </span>(<strong>QVD</strong>) file. The previous examples all include a common element of a <strong>header row</strong> that defines a label and alignment for your data, <strong>rows</strong> (with each one identified as a single record), <strong>columns</strong> that categorize the structure of each field value, and <strong>data</strong> that contains numeric and/or text values. </p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>In our example, each row includes an identity record of the <kbd>ID</kbd> field, but that is not a requirement in a <kbd>pandas</kbd> DataFrame. DataFrames are treated as objects<span> </span><span>in Python</span><span> and support loading data from files or SQL sources directly into memory for additional manipulation and analysis. Some key benefits of using DataFrames include the following:</span></p>
<ul>
<li>It allows you to convert all source files into readable data objects for easier merging and analysis.</li>
<li>It provides auto- or defined indexing to help with looking up a value or selecting a cross selection from your DataFrame, which is also known as a data slice.</li>
<li>Each column can be treated as a single NumPy array, which can collectively have multiple data types.</li>
<li>It really excels at fixing data alignment and missing data elements, which are displayed and referenced as <strong>Not a Number </strong>(<strong>NaN</strong>).</li>
<li>It allows pivoting and reshaping data without going back to the source of record for each dataset.</li>
<li>It is easy to add, remove, or change data using single Python commands to expedite the analysis of one or more data sources.</li>
<li>Allows aggregations, such as <kbd>Group By</kbd>, and other calculations against metrics, such as <kbd>sum</kbd>, <kbd>min</kbd>, <kbd>max</kbd>, can all be performed against the DataFrame.</li>
<li>Allows merging, sorting, joining, and filtering against one or more DataFrames.</li>
<li>It is scalable to support a repeatable workflow of analysis. For example, the following <span>pseudo</span>-code steps are easy to replicate in a Jupyter notebook:</li>
</ul>
<ol>
<li style="padding-left: 30px">Import the <kbd>pandas</kbd> library.</li>
<li style="padding-left: 30px">Load the source file into a new DataFrame.</li>
<li style="padding-left: 30px">Create a second DataFrame that drops duplicate rows or columns from the original.</li>
<li style="padding-left: 30px">Create summary metrics.</li>
<li style="padding-left: 30px">Save the second DataFrame as a new file.</li>
</ol>
<p>What I enjoy about using <kbd>pandas</kbd> and DataFrames is the flexibility of the built-in commands that are provided to you as a data analyst. Let's walk through a few examples. To create a DataFrame from scratch on a limited number of records, you can simply add them with a few commands:</p>
<ol>
<li>To load <kbd>pandas</kbd>, you just need to add the following command to your Jupyter notebook and run the cell. Feel free to follow along by creating your own notebook; I have added a copy to GitHub for reference:</li>
</ol>
<pre style="padding-left: 60px">In[]: import pandas as pd</pre>
<ol start="2">
<li>Next, we have a few products—<kbd>a</kbd>, <kbd>b</kbd>, and <kbd>c</kbd>—along with the quantity sold, and we assign this input data to a variable named <kbd>product_data</kbd>:</li>
</ol>
<pre style="padding-left: 60px">product_data = {<br/>   'product a': [13, 20, 0, 10],<br/>   'project b': [10, 30, 17, 20],<br/>   'project c': [6, 9, 10, 0]<br/>}</pre>
<div class="packt_tip">When loading data manually, note the placement of square brackets to encapsulate the values for each column label and how the arrays must all be of the same length.</div>
<ol start="3">
<li>Then, we want to load the DataFrame by calling the command using the <kbd>pd</kbd> shortcut to reference the <kbd>pandas</kbd> library, along with the <kbd>DataFrame()</kbd> command. We assign the DataFrame input data as a second variable for easier reference, called <kbd>purchase_data</kbd>. The <kbd>In[]</kbd> cell will look like this:</li>
</ol>
<pre style="line-height: 24pt;padding-left: 60px"><span>purchase_data = pd.DataFrame(product_data)</span></pre>
<ol start="4">
<li>To validate the results, you can run the <kbd>head()</kbd> function to display the first five rows of data using the following command:</li>
</ol>
<pre style="padding-left: 60px">purchase_data.head()</pre>
<p style="padding-left: 60px">After executing the preceding code, we can see that:</p>
<ul>
<li style="padding-left: 30px">The output would look as in the following screenshot, where the individual arrays' by-products have been converted into a DataFrame with a labeled header row, and each of the quantity sold values are aligned for easy reference. </li>
<li style="padding-left: 30px">Notice that a new index column has been created to the left of <kbd>product a</kbd> with assigned sequential values, starting at <kbd>0</kbd>:</li>
</ul>
<p class="CDPAlignCenter CDPAlign"><img src="assets/95c7af78-b9e4-401d-9cdb-3377f17f493d.png" style="width:14.58em;height:9.00em;"/></p>
<ol start="5">
<li>Having the indexed values are useful for reference, but if we want to define them as we create the DataFrame, we can include a relevant command during its creation, as follows:</li>
</ol>
<pre style="padding-left: 60px">purchase_data = pd.DataFrame(product_data, index=['Ronny,' 'Bobby,' 'Ricky,' 'Mike'])</pre>
<ol start="6">
<li>Now, if you run the <kbd>head()</kbd> command to display the results, you will see specific values assigned to each indexed number, which will display as in the following screenshot:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="assets/02f922c7-2ff0-412a-aa5a-c4878054b2d2.png" style="width:15.42em;height:8.42em;"/></p>
<ol start="7">
<li>To select a specific row from the DataFrame, you use the <kbd>loc</kbd> function to retrieve the results by index, as follows:</li>
</ol>
<pre style="padding-left: 60px">purchase_data.loc['Ronny']</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p style="padding-left: 60px">This will have an output, as in the following screenshot, where the individual values from the row assigned to <kbd>Ronny</kbd> are displayed in summary format, with each column and value presented by a row with a final description that includes the name of the index with a data type of the values (<kbd>dtype:  int64</kbd>):</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/9559a898-4514-4abf-876c-ecac8cb6257e.png" style="width:14.92em;height:5.25em;"/></p>
<div class="packt_tip">Once the index is labeled, you must access the <kbd>loc[]</kbd> function with the name in single quotes; however, you can use the <kbd>iloc[]</kbd> or <kbd>ix[]</kbd> functions to reference the row index by a number, with the first row starting with <kbd>0</kbd>. So, <kbd>purchase_data.iloc[0]</kbd> or <kbd>purchase_data.ix[0]</kbd> will both return the same results as in the preceding screenshot.</div>
<h1 id="uuid-ca4d2e27-b944-431c-8e65-f3dc4e4a461c">Handling essential data formats</h1>
<p>With a better understanding of the power of using the <kbd>pandas</kbd> library and the DataFrames feature, let's explore working with multiple data formats, including from source files such as CSV, JSON, and XML. We briefly covered these different file formats as part of understanding structured data in <a href="0fa7e28f-7a30-4099-9bae-30dd3c86ee4f.xhtml">Chapter 1</a>, <em>Fundamentals of Data Analysis</em>, so let's dive <span>deep</span><span> </span><span>into each source file type and learn some essential skills when working with them.</span></p>
<h2 id="uuid-6cb6ecdf-af58-4014-a40b-5cc1f7e8f1eb">CSV</h2>
<p>First, we have CSV, which has been an industry standard for most of my career. The way to identify CSV files is typically by the <kbd>.csv</kbd><span> </span><span>file extension</span><span>; however, you will learn, over time, that this is not always the case, nor is the delimiter used to separate values always a comma within data records. CSV files are popular because they are portable and technologically agnostic from the source system that created them. </span></p>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p>This means a CSV file could have been created with any coding language, such as Python, C++, or Java. Also, the same OS used to create the CSV file, such as Windows, Unix, Linux, or macOS, is not required to read the file. <span>This has helped with its adoption for many different use cases by IT professionals because it helps move data between systems in and out of the organization as needed. </span></p>
<p>Because of its longevity, you will find <span>that</span><span> </span><span>many different variations and standards have been adopted over the years. For example, records may or may not include a header row and the delimiter between each field/column could be a tab, a pipe (</span><kbd>|</kbd><span>), or any other ASCII or UTF-8 character value. </span></p>
<div class="packt_tip CDPAlignLeft CDPAlign"><strong><span>American Standard Code for Information Interchange</span></strong> (<strong>ASCII</strong>) is a common character-encoding standard used by computers to interpret keyboard values digitally. <strong>Unicode Transformation Format</strong> (<strong>UTF-8</strong>) <span>is the universal character-encoding standard and is backward-compatible with ASCII. Both standards are popular and commonly used.</span></div>
<p>There are some rules defined for proper CSV format, but the more you continue to work with them, the more you will probably find exceptions. Some of the rules that were published by Y. Shafranovich in <em>The Internet Society</em> (2005) include the following:</p>
<ul>
<li>Each record in the CSV file should be independent and include a line break (<kbd>CRLF</kbd>) to identify each row.</li>
<li>It is optional to have a line break with the last record, but some kind of <strong>End of File</strong> (<strong>EOF</strong>) signifier would help with reading data between systems.</li>
<li>A header row is optional but should include the same number of fields/columns as the corresponding record level data.</li>
<li>Each record should have a consistent delimiter, such as a comma (<kbd>,</kbd>), a semicolon (<kbd>;</kbd>), a pipe (<kbd>|</kbd>), or a tab.</li>
<li>The inclusion of double quotes between each field value is optional but is recommended to avoid misalignment or confusion, especially when reading in large, descriptive text data that includes a comma in the field value itself, such as <kbd>Also, Stacy enjoys watching movies</kbd>.</li>
<li>Leading and trailing spaces between each field are optional as well but should be used consistently throughout the entire file.</li>
<li>The size of a CSV file will vary but can be quite large and is dependent on the density of the data (the number of distinct values, the number of rows, and the number of fields).</li>
</ul>
<div class="packt_tip">Depending on the OS, such as Linux, a CSV would only include a <strong>line feed</strong> (<strong>LF</strong>) and not a <strong>carriage return</strong> (<strong>CR</strong>) for each row.</div>
<p>In the following screenshot, I have included a few examples of samples rows within a CSV file that all include the exact same information but using different formats to delimit the fields within the file:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/f0e69553-5f93-426b-85b9-08d49d9dba47.png"/></p>
<p>One big advantage of consuming or producing CSV over any other format is the capability to share between other tools used for data analysis. For example, spreadsheet solutions such as Excel can easily read a CSV file without the need to convert the file or use a third-party extension. However, a disadvantage is the loss of defined data types for each column, which could lead to misrepresenting values in your analysis. For example, a value in a column of <kbd>1</kbd> or <kbd>0</kbd> could represent a Boolean flag or a user hit count from a website.</p>
<h2 id="uuid-36e8e894-31e1-4e48-a99f-6153fa5c1596">XML</h2>
<p>The XML file format was introduced as a standard format in the 1990s. I still remember how early on in my career XML was proposed as a replacement to CSV or even to the use of databases as a data repository. XML is flexible as a solution for developers to create web applications and, similar to CSV, is used to move data between systems in and out of the organization. XML is open source and has a defined standard that is maintained by the <strong>World Wide Web Consortium</strong> (<strong>WC3</strong>) organization. Some key characteristics of XML file format are as follows:</p>
<ul>
<li>It is most commonly identified with a file extension of <kbd>.xml</kbd>.</li>
<li>The first line should include a declaration with encoding details and the <kbd>.xml</kbd> version, such as <kbd>&lt;?xml version = "1.0" encoding="UTF-8" ?&gt;</kbd>.</li>
<li>It uses tags around each element that are similar to HTML tag code, using a beginning tag of <kbd>&lt;</kbd> and <kbd>&gt;</kbd> or <kbd>/&gt;</kbd>.</li>
<li>It contains elements, which are the defined fields or columns of the structured data.</li>
<li>It contains attributes, which are the data values within each defined element.</li>
<li>It is optional but recommended to include a <span><strong>Document Type Definition</strong> </span>(<strong>DTD</strong>), which provides details and helps define how the elements should be used, along with the data types</li>
</ul>
<p>A sample XML file is shown in the following screenshot. Here, I converted <kbd>evolution_of_data_analysis.csv</kbd> into XML format and displayed a few sample records:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/4470b4ad-7061-4f18-bfbe-e621d0b9ddcb.png" style="width:51.50em;height:23.17em;"/></p>
<p>While a disadvantage of XML is a larger file size, due to adding tags and definitions to each element, an advantage of using the XML format is the ability to support data hierarchies and a defined schema. Let's break down those two points.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<h3 id="uuid-e84cc893-a20b-4020-8789-abf9fbf21c35">Data hierarchy</h3>
<p>Data hierarchies are defined and consistent groupings of data fields or records. The hierarchy can be obvious—for example, a son has a father and a mother—but from a data perspective, that relationship must be defined. In XML file format, you use a concept called an XML tree. The tree is defined by elements within the XML file that have a defined relationship. In the case of the <kbd>Evolution of Data Analysis.xml</kbd> file, each milestone has the details grouped together. Now, we can easily identify that the milestone event of <kbd>John von Neumann / array</kbd> was created in 1945, along with the rest of the supporting elements that are tagged, such as <kbd>&lt;Decade&gt;</kbd>, <kbd>&lt;Milestone Title&gt;</kbd>, <kbd>&lt;Milestone Event&gt;</kbd>, <kbd>&lt;Why Important&gt;</kbd>, <kbd>&lt;Reference&gt;</kbd>, and <kbd>&lt;People Process or Technology Tag&gt;</kbd>. This hierarchy relationship is commonly known as a <strong>parent-child</strong> relationship, where each indented element is a child to the <em>parent</em> element, <kbd>Evolution_of_Data_Milestone</kbd>. </p>
<h3 id="uuid-222a0376-38fa-40c0-b95b-5a202bde161b">Defined schema</h3>
<p>A defined schema means the data elements will also include metadata (data about the data) to help with the conformity of each element and attribute. This concept was required in most RDBMSes, but XML offers the concept of a DTD file to be included with one or more XML files. The file extension is <kbd>.xsd</kbd>, and it should complement each XML file. </p>
<p>The contents of the XSD file can be complex and very dense, depending on the complexity of records found in the XML file and the need to define a rigid structure when consuming the XML data. For example, a defined data type for each element would help you to better understand how to use the data during analysis. For example, say with <kbd>type="xs:decimal"</kbd> you know the attribute value in each element <em>must</em> contain numeric values and any text values should <em>not</em> exist. Another useful schema definition would be the definition for an element of <kbd>use="required"</kbd>, which means specific elements must always have a value and should <em>not</em> contain any null/empty attributes.</p>
<p>There are more details on this topic available on the W3C website, which you can find in the <em>Further reading</em> section of this chapter.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<h2 id="uuid-e40d8332-271e-4a3c-b578-5273071f8fed">JSON</h2>
<p>JSON is another open source file standard for the communication of data between systems. It was created by Douglas Crockford around 2001 to improve communication between computers and web browsers using a concept called <strong>stateless</strong>. This means your computer's web browser, which is known as the <strong>client</strong>, doesn't have to wait for the <strong>server</strong> to respond, and vice versa.<span> This is also known as <strong>Representational State Transfer</strong> (<strong>REST</strong>) architecture and is very common in web, API, and modern technologies because it scales to support millions of concurrent users.</span></p>
<p>Once REST became a popular web architecture, the need to find a faster and more efficient communication protocol drove the adoption of JSON data, which can either be streamed or persisted as a file. Having many websites that use JavaScript and a JavaScript-friendly notation also increased JSON's popularity.</p>
<p>Similar to XML and CSV, JSON is readable by humans as well as many different types of computer systems and languages, such as Python. This also means JSON is not a binary file format, which means it does not require the file to be compiled for use by a computer. I included JSON as a milestone in the <em>"The evolution of data analysis and why it is important"</em> section in <a href="0fa7e28f-7a30-4099-9bae-30dd3c86ee4f.xhtml">Chapter 1</a>, <em>Fundamentals of Data Analysis,</em> because of its contributions to advancing how we communicate using data. A sample JSON format is shown in the following screenshot, which is very similar to the XML format sample from the previous <em>XML</em> section because you now see the data organized and grouped by record using curly brackets (<kbd>{</kbd> and <kbd>}</kbd><span>) </span><span>to encapsulate</span><span> each row from the original CSV file. Each grouping using curly brackets is identified as an object:</span></p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/311002fb-5349-4cbf-870e-70a3544c673b.png"/></p>
<p class="mce-root"/>
<p>One important concept to understand with JSON data is that it evolved from XML but streamlines many of the complexities that could exist in XML formats. <span>Like XML, it benefits from the ability to define a data hierarchy and includes a defined schema that supports a concept called <strong>schema on read</strong>.</span></p>
<p>In traditional solutions that have a defined schema, the producer was forced to establish a schema before any data is loaded or transferred between systems. This process required expertise and extra steps during data ingestion and delayed the delivery of data to the consumer. With JSON and the concept of schema on read, the producer can send over the data along with all the metadata at the same time. All the details, such as field names, data types (<kbd>dtype</kbd>) for each field, and, in some cases, a full data dictionary, will be included. Providing this level of detail helps the consumer of the data to better understand the relationships within each element and attribute.</p>
<p>You will find, in a lot of JSON-formatted data, the concept of <kbd>name: value</kbd> pairs, which are also used in the example in the previous screenshot. This concept allows values to be assigned within the identification of the field within each record while still maintaining the hierarchy, rather than breaking out the records across multiple rows. Each field name is identified to the left of the colon (<kbd>:</kbd>) and the value is found to the right. </p>
<p>Each <kbd>name: value</kbd> relationship is separated by a comma and many examples will have a unique record identity, which helps with carrying out analysis on one-to-many relationships. So, you can nest many different relationships deep within a JSON structure and still have a way to identify which record the <kbd>name: value</kbd> pair belongs. If an array of values are required to be stored in a JSON file, they use square brackets (<kbd>[</kbd> and <kbd>]</kbd>) to define the list of values.</p>
<p>Defining a schema forces the data to have controls and context beyond what is observed. It removes assumptions about the data attributes and helps with interpreting how the data values should be used for analysis. For example, a value of <kbd>20191219</kbd> could be easily understood to be an integer value or could be the representation of the <kbd>12/19/2019</kbd><span> </span><span>date</span><span> with the format stored as <kbd>YYYYMMDD</kbd>. Without having a defined schema to reference, along with details about how and why that field is supposed to be used, your analysis of the data could be flawed.</span></p>
<p class="mce-root"/>
<h1 id="uuid-4b6435f1-d35f-4b9c-8b45-896689c42fde">Data dictionaries and data types</h1>
<p>Throughout the book, I will continue to re-enforce the need to have a data dictionary to help with the analysis of data. As with any data we have uncovered so far, a data dictionary will come in all shapes and sizes. This means it could be documented outside the source file, which is common on a help page, a wiki, or a blog or within the source data, as we discussed with XML and JSON files.</p>
<p>Having the data defined and documented will aid you in the journey to understand it but will not be the only method required to become a domain expert for a dataset. Domain expertise comes from experience with understanding how the data is used, along with the business or purpose behind the underlining source data. We covered some of these concepts in <a href="0fa7e28f-7a30-4099-9bae-30dd3c86ee4f.xhtml">Chapter 1</a>, <em>Fundamentals of Data Analysis</em>, looking at how <strong>Know Your Data</strong> (<strong>KYD</strong>) and having a data dictionary available aids in the effort to learn more about the underlying dataset.</p>
<div class="packt_tip">The analysis of data and the KYD concept should be applied throughout the process of analyzing data, so be sure to check the numbers and verify that the results match up to how the data is defined to build trust and confidence in your insights.</div>
<p>Data dictionaries are common for legacy systems, RDBMS, and traditional <strong>Enterprise Data Warehouses</strong> (<strong>EDW</strong>). It is common to have a data catalog available and, in many cases, they are required to build communication data pipelines between different systems. In some cases, a data dictionary is required as part of regulatory requirements or as part of a governed corporate policy.</p>
<p>In modern systems, <strong><span>Application Programming Interfaces</span></strong><span> (</span><strong><span>APIs</span></strong><span>) have become the central repository for metadata and the de facto data dictionary because JSON is a popular communication vehicle where the schema is defined and should be well documented. However, in practice, I find that documentation is written for programmers by programmers, so it may not meet all the needs to fully understand the data and answer all the business questions during analysis.</span></p>
<p class="mce-root"/>
<p>It is also common to version a data dictionary as part of a <strong>Master Data Management</strong> (<strong>MDM</strong>) or data governance solution. Within these versions, you will uncover details behind the <em>what</em> and the <em>why</em> for the data. For example, a field may be defined as inactive but still available, so it becomes sparsely populated because the application/system used to populate it changed.</p>
<p>Having that level of detail may help to identify data gaps or to better understand how to build a data bridge by combining values from two different fields at different periods of time for accurate historical analysis. I worked with a client once who was replacing a large enterprise legacy system, which cost millions of dollars, with consulting hardware and software. The consulting time was calculated by the hour, with dozens of specialists traveling every week to the client site. </p>
<p>There was a pivotal moment in the project where it was determined infeasible and too costly to migrate all the legacy supply chain, accounting, and HR details from the old system to the new one. To avoid delays, we proposed an analytics solution where both the legacy system data and the new system data were merged together daily. A rolling window of time logic was built in so that after 7 years, the legacy data would no longer be used for analysis, but during that timeframe, a blend of both systems, which included different fields and records, would be presented for analysis.</p>
<p>Having a data dictionary was a must for this type of solution, and providing additional documentation was required to ensure the audience understood where the source of the data came from depending on the time period of the reporting and analysis. Part of that documentation required details behind the different fields and variations in the data types. Some systems will allow a mix of different data types or, as in Python, will default to specific data types. </p>
<p>Just remember that you may need to convert a data type between multiple sources, especially when blending between different systems and file formats. For example, in JSON, a number defined as <kbd>real</kbd> would be called <kbd>float</kbd> in Python. If you run into issues with converting data types during the loading of data, you may need to go back to the data source provider and request it to be resent in a format that would be easier to consume. </p>
<p>As you continue increasing your data literacy, you need to understand that different technologies and data formats will lead to different data types, which will require translation to ensure accurate analysis of the data, especially from multiple sources.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<h1 id="uuid-c53858d0-6161-40e5-aab8-08dd708894cd">Creating our first DataFrame </h1>
<p>Before we begin with some hands-on examples, some useful commands to run in <kbd>pandas</kbd> are as follows:</p>
<ul>
<li><kbd>pd.read_csv(‘inport_filename.csv', header=1)</kbd>: Reads data from a CSV file directly into a <kbd>pandas</kbd> DataFrame</li>
<li><kbd>my_df.to_csv(‘export_filename')</kbd>: Directly exports the DataFrame to a CSV file to your workstation</li>
<li><kbd>my_df.shape</kbd>: Provides the number of rows and columns of your DataFrame</li>
<li><kbd>my_df.info()</kbd>: Provides metadata about your DataFrame, including data types for each column</li>
<li><kbd>my_df.describe()</kbd>: Includes statistical details with a column that includes the count, mean, <strong>standard deviation</strong> (<strong>std</strong>), minimum, maximum, and percentiles (25th, 50th, and 75th) for any numeric column</li>
<li><kbd>my_df.head(2)</kbd>: Displays the first two records from the DataFrame</li>
<li><kbd>my_df.tail(2)</kbd>: Displays the last two records from the DataFrame</li>
<li><kbd>my_df.sort_index(1)</kbd>: Sorts by the labels along an axis—in this example, by the column label headers alphabetically from left to right</li>
<li><kbd>my_df.isnull()</kbd>: Displays a list of all rows with a <kbd>True</kbd>/<kbd>False</kbd> indicator if any of the values by column are null</li>
</ul>
<p>Our first example will load data from a CSV file into a <kbd>pandas</kbd> DataFrame that has a pipe (<kbd>|</kbd>) delimiter and will run some of the preceding commands: </p>
<ol>
<li>Launch Jupyter and create a new Python notebook. </li>
<li>To stay consistent with the best practices, be sure to rename the notebook <kbd>exploring_the_pandas_library</kbd> before moving forward.</li>
<li>Type <kbd>import pandas as pd</kbd> into the <kbd>In []:</kbd><span> </span><span>cell.</span></li>
<li>Run the cell. No output will be displayed after you run the cell.</li>
<li>Type <kbd>my_df = pd.read_csv('evolution_of_data_analysis.csv', header=0, sep="|")</kbd> into the next <kbd>In []:</kbd><span> </span><span>cell.</span></li>
<li>Run the cell. <span>No output will be displayed after you run the cell.</span></li>
<li>Type <kbd>my_df.shape</kbd> into the next <kbd>In []:</kbd><span> </span>cell.</li>
</ol>
<ol start="8">
<li>Verify that the output cell displays <kbd>Out []</kbd><span>.</span> <kbd>(42, 7)</kbd> will be displayed, which tells you that there are 42 rows and 7 columns, as in the following screenshot:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="assets/69507b5f-7127-4047-a8e2-8aa796b8335e.png" style="width:37.50em;height:8.83em;"/></p>
<ol start="9">
<li>Type <kbd>my_df.info()</kbd> into the <span>next</span><span> </span><kbd>In []:</kbd><span> </span><span>cell.</span></li>
<li>Run the cell.</li>
<li>Verify that the output cell displays <kbd>Out []</kbd><span>. </span>There will be multiple rows, including data types for all seven columns, as in the following screenshot:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="assets/83180595-25be-40d2-8f20-cb4c3336e5e6.png" style="width:28.67em;height:14.00em;"/></p>
<ol start="12">
<li>Type <kbd>my_df.describe()</kbd> into the <span>next</span><span> </span><kbd>In []:</kbd><span> </span><span>cell.</span></li>
<li>Run the cell.</li>
<li>Verify that the output cell <span>displays</span><span> </span><kbd>Out []</kbd><span>. </span>There will be multiple rows of output, with one column with a header of <kbd>Year</kbd>, as in the following screenshot. Statistical values from the <kbd>Year</kbd> field will be displayed, including <kbd>count</kbd>, <kbd>mean</kbd>, and <kbd>max</kbd>:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="assets/7ae6f147-9d56-4fc6-a33f-c37987100ff2.png" style="width:14.42em;height:18.42em;"/></p>
<ol start="15">
<li>Type <kbd>my_df.head(2)</kbd> into the <span>next</span><span> </span><kbd>In []:</kbd><span> </span><span>cell and r</span>un the cell.</li>
<li>Verify that the output cell <span>displays</span><span> </span><kbd>Out []</kbd><span>: </span></li>
</ol>
<ul>
<li style="padding-left: 30px">The output should include an index in the first column with a starting row of <kbd>0</kbd>, as in the following screenshot.</li>
<li style="padding-left: 30px">All seven columns will be displayed, along with the first two rows from the source file:</li>
</ul>
<p class="CDPAlignCenter CDPAlign"><img src="assets/b26064fe-3ea5-4f38-8294-1e5af795a209.png" style="width:63.00em;height:16.33em;"/></p>
<ol start="17">
<li>Type <kbd>my_df.tail(2)</kbd> into the <span>next</span><span> </span><kbd>In []:</kbd><span> </span><span>cell and r</span>un the cell.</li>
<li>Verify that the output cell <span>displays</span><span> </span><kbd>Out []</kbd><span>. </span>The output should include an index in the first column with a starting row of <kbd>40</kbd>, as in the following screenshot. All seven columns will be displayed, along with the last two rows from the source file:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="assets/df2d7257-fa2f-437f-9542-8250dd22ddf8.png" style="width:61.33em;height:15.00em;"/></p>
<ol start="19">
<li>Type <kbd>my_df.sort_index(1)</kbd> into the <span>next</span><span> </span><kbd>In []:</kbd><span> </span><span>cell and </span>run the cell.</li>
<li>Verify that the output cell <span>displays</span><span> </span><kbd>Out []</kbd><span>. </span>The output should include an index in the first column with a starting row of <kbd>0</kbd>, as in the following screenshot. All seven columns will be displayed, but the order of the columns has changed to alphabetically sort from left to right, starting with <kbd>Decade</kbd> and ending with <kbd>Year</kbd>:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="assets/aaaa3dee-104e-47de-b3d8-568c3954f2d6.png" style="width:68.75em;height:24.50em;"/></p>
<p>In the next example, let's answer a few business questions from the data by exploring some of the features available in <kbd>pandas</kbd>. The first question is <em>how many milestone events occurred by decade?</em> To answer this question, we need to use the <kbd>groupby</kbd> feature, so let's go through the steps to provide the answer.</p>
<p>The steps to reproduce this example are as follows:</p>
<ol>
<li>Launch Jupyter and create a new Python notebook. </li>
<li>To stay consistent with the best practices, be sure to rename the notebook <kbd>exploring_the_pandas_library_example_2</kbd> before moving forward.</li>
<li>Type <kbd>import pandas as pd</kbd><span> </span>into the <kbd>In []:</kbd><span> </span><span>cell and r</span>un the cell.</li>
<li>Type <kbd>my_df = pd.read_csv('evolution_of_data_analysis.csv', header=0, sep="|")</kbd> into the next<span> </span><kbd>In []:</kbd><span> </span><span>cell and run the cell.</span></li>
<li>Type <kbd>my_df.head(2)</kbd> into the<span> </span><span>next</span><span> </span><kbd>In []:</kbd><span> </span><span>cell and r</span>un the cell.</li>
<li>Verify that the output cell<span> </span><span>displays</span><span> </span><kbd>Out []</kbd><span>:</span></li>
</ol>
<ul>
<li style="padding-left: 30px">The output should include an index in the first column with a starting row of <kbd>0</kbd>.</li>
<li style="padding-left: 30px">All seven columns will be displayed, along with the first two rows from the source file.</li>
</ul>
<ol start="7">
<li>Type <kbd>my_df.groupby(['Decade']).agg({'Year':'count'})</kbd><strong> </strong><span>into the </span><kbd>In []:</kbd><span> </span><span>cell and r</span>un the cell.</li>
<li><span>Verify that the output cell </span><span>displays</span><span> </span><kbd>Out []</kbd><span>:</span></li>
</ol>
<ul>
<li style="padding-left: 30px">The output will display 10 rows of data with 2 columns.</li>
<li style="padding-left: 30px">The header row in the first column will be <kbd>Decade</kbd> and will be <kbd>Year</kbd> for the second column.</li>
<li style="padding-left: 30px">The results will match the following screenshot:</li>
</ul>
<p class="CDPAlignCenter CDPAlign"><img src="assets/f40d7cae-2447-491e-9f33-f428151156e7.png" style="width:58.58em;height:38.25em;"/></p>
<p>In the preceding screenshot, we followed the previous steps to load the CSV file as a DataFrame named <kbd>my_df</kbd>. To verify that the DataFrame loaded correctly, we ran the <kbd>head()</kbd> function and included the parameter of <kbd>2</kbd> to limit the number of rows displayed in the notebook. The last command is to run <kbd>groupby</kbd> against the <kbd>Decade</kbd> column and combine it with an aggregation to count the values from the <kbd>Milestone Event</kbd> field/column. We can now answer some questions about this dataset, such as that 14 milestone events occurred during the 2000s or that the first decade to have any milestone events was the 1940s because that is the first row that has any values.</p>
<h1 id="uuid-630bb784-7c8d-445b-9473-2785bf091909">Summary</h1>
<p><span>Congratulations, you have now created your first DataFrame using the <kbd>pandas</kbd> library! We started the chapter by introducing you to the concepts of structured tabular data and the different techniques available to manipulate it by transposing and pivoting the data. More importantly, we discussed the importance of why data should be in tabular form. We then introduced the <kbd>pandas</kbd> library and defined a DataFrame, and demonstrated the many benefits of this powerful feature that are available for you during data analysis. In the handling of essential data formats, we went through the different data formats available by going through the details of the CSV, XML, and JSON file formats. Before we ended the chapter by creating our first DataFrame, we discussed the importance of data dictionaries and how different data types improve your data literacy, as well as why they are important before, during, and after the data analysis workflow has completed.</span></p>
<p class="mce-root"><span>In the next chapter, <a href="bea8a62c-4469-47e3-a668-10fbb91815ea.xhtml"/><a href="bea8a62c-4469-47e3-a668-10fbb91815ea.xhtml">Chapter 5</a>, <em>Gathering and Loading Data in Python</em>, we will introduce you to how to load data from databases using SQL and continue working with the features available in <kbd>pandas</kbd> and DataFrames.</span></p>
<h1 id="uuid-46908d16-b839-4dd4-a6b4-6fc82101bba1">Further reading</h1>
<ul>
<li><span>McKinney, W., <em>Data Structures for Statistical Computing in Python</em>, </span><em><span>Proceedings of the 9th Python in Science Conference</span></em><span>, Vol. 445 (2010)</span></li>
<li><span>Torres-Reyna, O., </span><em>Panel Data Analysis Fixed and Random Effects using Stata</em> (v. 4.2),<span> <em>Princeton.edu</em>, (2007), available at <a href="https://www.princeton.edu/~otorres/Panel101.pdf">https://www.princeton.edu/~otorres/Panel101.pdf</a> [accessed 23 Dec. 2019]</span></li>
<li><strong>National Longitudinal Surveys</strong> (<strong>NLSes</strong>) for examples of panel data: <a href="https://www.bls.gov/nls/home.htm">https://www.bls.gov/nls/home.htm</a></li>
<li>A definition of a <kbd>pandas</kbd> DataFrame:<span> </span><a href="https://www.geeksforgeeks.org/python-pandas-dataframe/">https://www.geeksforgeeks.org/python-pandas-dataframe</a></li>
<li>Quick details about the QVD file format: <a href="https://help.qlik.com/en-US/sense/June2019/Subsystems/Hub/Content/Sense_Hub/Scripting/work-with-QVD-files.htm">https://help.qlik.com/en-US/sense/June2019/Subsystems/Hub/Content/Sense_Hub/Scripting/work-with-QVD-files.htm</a></li>
<li>ASCII stands: <a href="https://www.ansi.org/about_ansi/overview/overview?menuid=1">https://www.ansi.org/about_ansi/overview/overview?menuid=1</a></li>
<li>Unicode format and encoding standards: <a href="https://home.unicode.org/">https://home.unicode.org/</a></li>
<li>CSV rules and standards: <a href="https://tools.ietf.org/html/rfc4180">https://tools.ietf.org/html/rfc4180</a></li>
<li>The W3C organization standards: <a href="https://www.w3.org/">https://www.w3.org/</a><a href="https://www.w3.org/"/></li>
<li><span>The REST standards:</span> <a href="https://www.ics.uci.edu/~fielding/pubs/dissertation/rest_arch_style.htm#sec_5_1_3">https://www.ics.uci.edu/~fielding/pubs/dissertation/rest_arch_style.htm#sec_5_1_3</a></li>
<li>History of Unicode: <a href="https://docs.python.org/3.4/howto/unicode.html">https://docs.python.org/3.4/howto/unicode.html</a></li>
</ul>


            </article>

            
        </section>
    </body></html>