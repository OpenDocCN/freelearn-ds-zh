["```py\n#import packages needed\nimport pandas as pd\nfrom sklearn.cluster import KMeans\nimport igraph as ig\nfrom igraph import Graph\nimport numpy as np\nimport os\n#import file\nFile =\"<YourPath>/Friendship_Factors.csv\"\npwd = os.getcwd()\nos.chdir(os.path.dirname(File))\nmydata =\n    pd.read_csv(os.path.basename(File),encoding='latin1')\n#k-means model\nX=mydata[mydata.columns.drop('Individual ID')]\nkm=KMeans(n_clusters=3,init='random',n_init=5)\nkm_model=km.fit_predict(X)\n#explore k-means model\nkm_model\n#add to dataset as first solution\nkm_1=np.array(km_model)+1\nmydata['km_1']=km_1\n```", "```py\n#create network via Pearson correlation\ncor=np.corrcoef(X)\ncor[cor>=0.5]=1\ncor[cor<0.5]=0\nX2=np.asmatrix(cor)\n#create graph with self-loops removed\nfriends=Graph.Adjacency(X2)\nedge_list=friends.get_edgelist()\nself_loop=[]\nfor i in range(0,25):\n    self=(i,i)\n    self_loop.append(self)\nto_remove=[]\nfor i in edge_list:\n    for j in self_loop:\n        if i==j:\n            to_remove.append(i)\nfriends.delete_edges(to_remove)\nig.plot(friends)\n```", "```py\n#create scaled metrics and attach to X\nd=np.array(Graph.degree(friends))/10\np=np.array(Graph.pagerank(friends))*20\nX['degree']=d\nX['pagerank']=p\n#create new k-means model with graph metrics added\nkm2=KMeans(n_clusters=3,init='random',n_init=5)\nkm_model2=km2.fit_predict(X)\n#explore new k-means model\nkm_model2\n#add to dataset as first solution\nkm_2=np.array(km_model2)+1\nmydata['km_2']=km_2\n```", "```py\n#import packages needed\nfrom sklearn.cluster import SpectralClustering\nfrom sklearn import metrics\n#perform spectral clustering and attach to dataset\nsc = SpectralClustering(3, affinity='precomputed',n_init=5)\nsp_clust=sc.fit(cor)\nmydata['sp']=sp_clust.labels_\nsp_clust.labels_\n```", "```py\n#install packages if you have not installed them on your machine\n#!pip install dgl\n#!pip install torch\n#import packages\nimport dgl\nimport dgl.data\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport itertools\nfrom dgl.nn import SAGEConv\n#import Karate Club dataset with instructor/administrator labels\ndataset = dgl.data.KarateClubDataset()\nnum_classes = dataset.num_classes\ng = dataset[0]\n```", "```py\n#embed vertices with a dimension of 6\nvert_em = nn.Embedding(g.number_of_nodes(),6)\ninputs = vert_em.weight\nnn.init.xavier_uniform_(inputs)\n```", "```py\n#obtain labels and denote available labels for GNN learning\n#(here: 1, 3, 5, 12, 15, 32)\nlabels = g.ndata['label']\nlabeled_nodes = [1, 3, 5, 12, 15, 32]\n```", "```py\n#build a three-layer GraphSAGE model\nclass GraphSAGE(nn.Module):\n    def __init__(self, in_feats, h_feats1, h_feats2,\n        num_classes):\n        super(GraphSAGE, self).__init__()\n        self.conv1 = SAGEConv(in_feats, h_feats1, 'mean')\n        self.conv2 = SAGEConv(h_feats1, h_feats2, 'mean')\n        self.conv3 = SAGEConv(h_feats2, num_classes,'mean')\n    def forward(self, g, in_feat):\n        h = self.conv1(g, in_feat)\n        h = F.relu(h)\n        h = self.conv2(g, h)\n        h = F.relu(h)\n        h = self.conv3(g, h)\n        return h\n#6 embedding dimensions as input,\n#a hidden layers of 8 and 6 nodes, and 2 classes to output\nnet = GraphSAGE(6,8,6,2)\n#GNN training parameters\noptimizer=torch.optim.SGD(\n    itertools.chain(\n        net.parameters(), vert_em.parameters()),\n        lr=0.01, momentum=0.8)\nall_logits = []\n#train GNN\nfor e in range(990):\n    logits = net(g, inputs)\n    logp = F.log_softmax(logits, 1)\n    loss = F.nll_loss(logp[labeled_nodes],labels[labeled_nodes])\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    all_logits.append(logits.detach())\n    if e % 90 == 0:\n        print('In epoch {}, loss: {}'.format(e, loss))\n```", "```py\n#obtain accuracy statistics\npred = torch.argmax(logits, axis=1)\nprint('Accuracy',(pred == labels).sum().item() / len(pred))\n```"]