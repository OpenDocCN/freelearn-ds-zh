- en: Chapter 4. SciPy for Numerical Analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Practically all the different areas of numerical analysis are contemplated in
    some SciPy module. For example, in order to compute values of special functions,
    we use the `scipy.special` module. The `scipy.interpolate` module takes care of
    interpolation, extrapolation, and regression. For optimization, we have the `scipy.optimize`
    module, and finally, we have the `scipy.integrate` module for numerical evaluation
    of integrals. This last module serves as the interface to perform numerical solutions
    of ordinary differential equations as well.
  prefs: []
  type: TYPE_NORMAL
- en: Thus, in this chapter, we will first extensively explore how to use SciPy to
    numerically evaluate the special functions that are commonly found in the field
    of mathematical physics. Then, we will discuss the modules available in SciPy
    to tackle regression, interpolation, and optimization problems.
  prefs: []
  type: TYPE_NORMAL
- en: The chapter ends with a solution of the chaotic Lorenz system as an illustration
    of the capabilities included in SciPy to find numerical solutions of ordinary
    differential equations. The corresponding IPython Notebook will help you to try
    the functionalities of the modules involved in the computations and to modify
    each illustrative example according to your specific needs.
  prefs: []
  type: TYPE_NORMAL
- en: The evaluation of special functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `scipy.special` module contains numerically stable definitions of useful
    functions. Most often, the straightforward evaluation of a function at a single
    value is not very efficient. For instance, we would rather use a Horner scheme
    ([http://en.wikipedia.org/wiki/Horner%27s_method](http://en.wikipedia.org/wiki/Horner%27s_method))
    to find the value of a polynomial at a point than use the raw formula. The NumPy
    and SciPy modules ensure that this optimization is always guaranteed with the
    definition of all its functions, whether by means of Horner schemes or with more
    advanced techniques.
  prefs: []
  type: TYPE_NORMAL
- en: Convenience and test functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: All the convenience functions are designed to facilitate a computational environment
    where the user does not need to worry about relative errors. The functions seem
    to be pointless at first sight, but behind their codes, there are state-of-the-art
    ideas that offer faster and more reliable results.
  prefs: []
  type: TYPE_NORMAL
- en: We have convenience functions beyond the ones defined in the NumPy libraries
    to find the solutions of trigonometric functions in degrees (`cosdg`, `sindg`,
    `tandg`, and `cotdg`); to compute angles in radians from their expressions in
    degrees, minutes, and seconds (`radian`); common powers (`exp2` for *2**x*, and
    `exp10` for *10**x*); and common functions for small values of the variable (`log1p`
    for *log(1 + x)*, `expm1` for *exp(x) - 1*, and `cosm1` for *cos(x) - 1*).
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, in the following code snippet, `the log1p` function computes
    the natural logarithm of *1 + x*. Why not simply add 1 to the value of *x* and
    then take the logarithm instead? Let''s compare:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let''s use `log1p()` on `a`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: While the absolute error of the first computation is small, the relative error
    is 100 percent.
  prefs: []
  type: TYPE_NORMAL
- en: In the same way as Lena image is regarded as the performance test in image processing,
    we have a few functions that are used to test different algorithms in different
    scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, it is customary to test minimization codes against the Rosenbrock''s
    banana function ([http://en.wikipedia.org/wiki/Rosenbrock_function](http://en.wikipedia.org/wiki/Rosenbrock_function)):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Convenience and test functions](img/7702OS_04_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The corresponding optimization module, `scipy.optimize`, has a routine to accurately
    evaluate this function (`rosen`), its derivative (`rosen_der`), its **Hessian**
    matrix (`rosen_hess`), or the product of the latter with a vector (`rosen_hess_prod`).
  prefs: []
  type: TYPE_NORMAL
- en: Univariate polynomials
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Polynomials are defined in SciPy as a NumPy class, `poly1d`. This class has
    a handful of methods associated to compute the coefficients of the polynomial
    (`coeffs` or simply `c`), to compute the roots of the polynomial (`r`), to compute
    its derivative (`deriv`), to compute the symbolic integral (`integ`), and to obtain
    the degree (`order` or simply `o`), as well as a method (`variable`) that provides
    a string holding the name of the variable we would like to use in the proper definition
    of the polynomial (see the example involving `P2`).
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to define a polynomial, we must indicate either its coefficients or
    its roots:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let''s find roots, order, and derivative of `P1`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s use the `poly1d` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s use the `poly1d` class with the `variable` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'We may evaluate polynomials by treating them either as (vectorized) functions,
    or with the `__call__ method`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s issue the `__call__` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'An immediate application of these ideas is to verify the computation of the
    natural logarithm of *1 + x* used in the preceding example . When *x* is close
    to zero, the natural logarithm can be approximated by the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Univariate polynomials](img/7702OS_04_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'This expression can be entered and evaluated in Python using the ideas just
    presented, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s have a look on the value stored in variable `a`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The output for value stored in `a` is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'We now use `Px` (which contains one-dimensional polynomial form) on `a` in
    the following line of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: The result is the same as that obtained before using the SciPy function `scipy.special.log1p`,
    which verifies the computation.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are also a few routines associated with polynomials: `roots` (to compute
    zeros), `polyder` (to compute derivatives), `polyint` (to compute integrals),
    `polyadd` (to add polynomials), `polysub` (to subtract polynomials), `polymul`
    (to multiply polynomials), `polydiv` (to perform polynomial division), `polyval`
    (to evaluate polynomials), and `polyfit` (to compute the best fit polynomial of
    certain order for two given arrays of data).'
  prefs: []
  type: TYPE_NORMAL
- en: 'The usual binary operators +, -, *, and / perform the corresponding operations
    with polynomials. In addition, once a polynomial is created, any list of values
    that interacts with them is immediately casted to a polynomial. Therefore, the
    following four commands are equivalent:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The output for the preceding lines of code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s take a look at the following `print()` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s take a look at the following `print()` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s take a look at the following `print()` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s take a look at the following `print()` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Note how the polynomial division offers both the quotient and reminder values,
    for example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'This can also be written as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Univariate polynomials](img/7702OS_04_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: A family of polynomials is said to be orthogonal with respect to an inner product
    if for any two polynomials in the family, their inner product is zero. Sequences
    of these functions are used as the backbone of extremely fast algorithms of quadrature
    (for numerical integration of general functions). The `scipy.special` module contains
    the `poly1d` definitions and allows fast evaluation of the families of orthogonal
    polynomials, such as **Legendre** (`legendre`), **Chebyshev** (`chebyt`, `chebyu`,
    `chebyc`, and `chebys`), **Jacobi** (`jacobi`), **Laguerre** and its generalized
    version (`laguerre` and `genlaguerre`), **Hermite** and its normalized version
    (`hermite` and `hermitenorm`), and **Gegenbauer** (`gegenbauer`). There are also
    shifted versions of some of them, such as `sh_legendre`, `sh_chebyt`, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'The usual evaluation of polynomials can be improved for orthogonal polynomials,
    thanks to their rich mathematical structure. In such cases, we never evaluate
    them with the generic call methods presented previously. Instead, we employ the
    `eval_` syntax. For example, we use the following command for Jacobi polynomials:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'In order to obtain the graph of the Jacobi polynomial of order `n = 3` for
    `alpha = 0` and `beta = 1`, for a thousand values of `x` uniformly spaced from
    -1 to 1, we could issue the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Univariate polynomials](img/7702OS_04_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The gamma function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The gamma function is a logarithmic, convex, smooth function operating on complex
    numbers, which interpolates the factorial function for all nonnegative integers.
    It is not defined at zero or any negative integer. This is the most common special
    function and is widely used in many different applications, either by itself or
    as the main ingredient in the definition of many other functions. The gamma function
    is used in diverse fields such as quantum physics, astrophysics, statistics, and
    fluid dynamics.
  prefs: []
  type: TYPE_NORMAL
- en: 'The gamma function is defined by the improper integral, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The gamma function](img/7702OS_04_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Evaluation of gamma at integer values gives shifted factorials, and that is
    precisely how the factorials are coded in SciPy.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `scipy.special` module has algorithms to obtain a fast evaluation of the
    gamma function at any permissible value. It also contains routines to perform
    evaluation of the most common compositions of the gamma functions appearing in
    the literature: `gammaln` for the natural logarithm of the absolute value of gamma,
    `rgamma` for the value one over gamma, `beta` for quotients, and `betaln` for
    the natural logarithm of the latter. We also have implementations of the logarithm
    of its derivative (`psi`).'
  prefs: []
  type: TYPE_NORMAL
- en: 'An obvious application of gamma functions is the ability to perform computations
    that are virtually impossible for a computer if approached in a direct way. For
    instance, in statistical applications we often work with ratios of factorials.
    If these factorials are too large for the precision of a computer, we resort to
    expressions involving their logarithms instead. Even then, computing *ln(a! /
    b!)* can prove to be an impossible task (try, for example, with *a = 10**15* and
    *b = a - 10**10*). An elegant solution uses the digamma function `psi` by an application
    of the mean value theorem on the `ln(gamma(x))` function. With proper estimation,
    we obtain the excellent approximation (for this case of choice of *a* and *b*):'
  prefs: []
  type: TYPE_NORMAL
- en: '![The gamma function](img/7702OS_04_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s take a look at the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: The Riemann zeta function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The Riemann zeta function is very important in analytic number theory and has
    applications in physics and the probability theory as well. It computes the p-series
    for any complex value *p*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The Riemann zeta function](img/7702OS_04_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The definition coded in SciPy allows a more flexible generalization of this
    function, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The Riemann zeta function](img/7702OS_04_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Among others, this function has applications in the field of particle physics
    and in dynamical systems ([http://en.wikipedia.org/wiki/Hurwitz_zeta_function](http://en.wikipedia.org/wiki/Hurwitz_zeta_function))
  prefs: []
  type: TYPE_NORMAL
- en: Airy and Bairy functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'These are solutions of the Stokes equation and are obtained by solving the
    following differential equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Airy and Bairy functions](img/7702OS_04_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'This equation has two linearly independent solutions, both of them defined
    as an improper integral for real values of the independent variable. The `airy`
    command computes both functions (`Ai` and `Bi`) as well as their corresponding
    derivatives (`Aip` and `Bip`, respectively). In the following code, we take advantage
    of the `contourf` command in `matplotlib.pyplot` to present an image of the real
    part of the output of the Bairy function `Bi` for an array of 801 x 801 complex
    values uniformly spaced in the square from *-4 - 4j* to *4 + 4j*. We also offer
    this graph as a surface plot using the `mplot3d` module of `mpl_toolkits`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Airy and Bairy functions](img/7702OS_04_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The Bessel and Struve functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Bessel** functions are both of the canonical solutions to Bessel''s homogeneous
    differential equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The Bessel and Struve functions](img/7702OS_04_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'These equations arise naturally in the solution of Laplace''s equation in cylindrical
    coordinates. The solutions of the non-homogeneous Bessel differential equation
    shown in the following diagram are called **Struve** functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The Bessel and Struve functions](img/7702OS_04_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: In either case, the order of the equation is the complex number `alpha` which
    acts as a parameter. Depending on the canonical solution and the order, the Bessel
    and Struve functions are addressed (and computed) differently.
  prefs: []
  type: TYPE_NORMAL
- en: 'For Bessel functions, we have algorithms to produce Bessel functions of the
    first kind (`jv`) and second kind (`yn` and `yv`), Hankel functions of the first
    and second kind (`hankel1` and `hankel2`), and the modified Bessel functions of
    the first and second kind (`iv`, `kn`, and `kv`). Their syntax is similar in all
    cases: first parameter is the order and second parameter the independent variable.
    The component *n* in the definition indicates that an integer is to be used as
    the order (since they are optimally coded for that situation):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'The `scipy.special` module also contains fast versions of the most common Bessel
    functions (those of orders 0 and 1): `j0(x)`, `j1(x)` (first kind `y0(x)`and second
    kind `y1(x)`), and so on. There are definitions of the spherical Bessel functions,
    such as `sph_jn(n,z)` and `sph_yn(z)`; the Riccati-Bessel functions, such as `riccati_jn(n,x)`
    and `riccati_yn(n,x)`; and derivatives of all the basic ones, such as `jvp`, `yvp`,
    `kvp`, `ivp`, `h1vp`, and `h2vp`.'
  prefs: []
  type: TYPE_NORMAL
- en: For Struve functions, we have fast algorithms to compute solutions of the differential
    equation of order *v*:(`struve(v,x)` and `modstruve(v,x)`).
  prefs: []
  type: TYPE_NORMAL
- en: Other special functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are more special functions included in the `scipy.special` module that
    are of great use in many applications in both pure and applied mathematics. An
    exhaustive list would be too large for the scope of this chapter, and I encourage
    you to use the different utilities for each set of special functions. Among the
    most interesting ones, we have elliptic functions, **Gauss hypergeometric functions**,
    **parabolic cylinder functions**, **Mathieu functions**, **spheroidal wave functions**,
    and **Kelvin functions**.
  prefs: []
  type: TYPE_NORMAL
- en: Interpolation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Interpolation is a basic method in numerical computation that is obtained from
    a discrete set of data points, intended to find an interpolation function which
    represents some higher order structure that contains the data. The best known
    example is the interpolation of a sequence of points (*x_k* and *y_k*) in a plane
    to obtain a curve that goes through all the points in the order dictated by the
    sequence.
  prefs: []
  type: TYPE_NORMAL
- en: If the points in the previous sequence are in the right position and order,
    it is possible to find a univariate function *y = f(x)* for which *y_k = f(x_k)*.
    It is often reasonable to request this interpolating function to be a polynomial,
    or a rational function, or a more complex functional object. Interpolation is
    also possible in higher dimensions, of course. The objective of the `scipy.interpolate`
    module is to offer a complete set of optimally coded applications to address this
    problem in different settings.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s address the easiest way of interpolating data to obtain a polynomial:
    lagrange interpolation. Given a sequence of different *x* values of size *n* and
    a sequence of arbitrary real values *y* of the same size *n*, we seek a polynomial
    *p(x)* of the degree of *n - 1* that satisfies the *n* constraints *p(x[k]) =
    y[k]* for all k from 0 to *n - 1*. The following code illustrates how to obtain
    a polynomial of degree 9 that interpolates the 10 uniformly spaced values of sine
    in the interval (-1, 1):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'We will obtain the following `plot` showing the Lagrange interpolation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Interpolation](img/7702OS_04_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: There are numerous issues with Lagrange interpolation. The first obvious drawback
    is that the user cannot specify the degree of the interpolation; this depends
    solely on the data. The procedure is also highly unstable numerically, especially
    for datasets with size over 20 points. This issue can be addressed by allowing
    the algorithm to depend on different properties of the dataset, rather than just
    the size and location of the points.
  prefs: []
  type: TYPE_NORMAL
- en: 'Also, it is inconvenient when we need to update the dataset by adding a few
    more instances; the procedure needs to be repeated again from the beginning. This
    proves impractical if the datasets are increasing in size and are updated frequently.
    To address this issue, `BarycentricInterpolator` has the `add_xi` and `set_yi`
    methods. For example, in the next session we start by interpolating 10 uniformly
    spaced values of the sine function between 1 and 10\. Once done, we update the
    interpolating polynomial with 10 more uniformly spaced values between 1.5 and
    10.5\. As expected, this operation reduces the (percent) relative error of an
    interpolation computed at points within the interpolating ones. The following
    commands are used:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the output for `exactValues`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s find the value of `interpolatedValues` by issuing following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s find the value of `PercentRelativeError` by issuing following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we find what `interpolatedValues2` holds:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s find the value of `PercentRelativeError`, keeping in consideration `interpolatedValues2`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: It is possible to interpolate data not only by point location, but also with
    the derivatives at those locations. The `KroghInterpolator` command allows this
    by including repeated *x* values and indicating the location and successive derivatives
    in order on the corresponding *y* values.
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, if we desire to construct a polynomial that is zero at the origin,
    one at *x = 1*, two at *x = 2*, and has horizontal tangent lines at each of these
    three locations, we issue the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'This renders the following graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Interpolation](img/7702OS_04_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: More advanced one-dimensional interpolation is possible with piecewise polynomials
    (`PiecewisePolynomial`). This allows control over the degrees of different pieces
    as well as the derivatives at their intersections. Other interpolation options
    in the `scipy.interpolate` module are **PCHIP monotonic cubic interpolation**
    (`pchip`) or even **univariate splines** (`InterpolatedUnivariateSpline`).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s examine an example with univariate splines. Its syntax is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: The `x` and `y` arrays contain dependent and independent data, respectively.
    The array `w` contains positive weights for spline fitting. The two-sequence `bbox`
    parameter specifies the boundary of the approximation interval. The last option
    indicates the degree of the smoothing polynomials (`k`).
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose we want to interpolate five points as shown in the following example.
    These points are ordered by strictly increasing `x` values. We need to perform
    this interpolation with four cubic polynomials (one for every two consecutive
    points) in such a way that at least the first derivative of each two consecutive
    pieces agree on their intersection. We will proceed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'This offers the following plot showing interpolation with univariate splines:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Interpolation](img/7702OS_04_15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: SciPy excels at interpolating in two-dimensional grids as well. It performs
    well with simple piecewise polynomials (`LinearNDInterpolator`), piecewise constants
    (`NearestNDInterpolator`), or more advanced splines (`BivariateSpline`). It is
    capable of carrying out spline interpolation on rectangular meshes in a plane
    (`RectBivariateSpline`) or on the surface of a sphere (`RectSphereBivariateSpline`).
    For unstructured data, besides the basic `scipy.interpolate.BivariateSpline`,
    it is capable of computing smooth approximations (`SmoothBivariateSpline`) or
    more involved weighted least-squares splines (`LSQBivariateSpline`).
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code creates a 10 x 10 grid of uniformly spaced points in the
    square from (0, 0) to (9, 9), and evaluates the function `sin(x) * cos(y)` on
    the points. We use these points to create a `scipy.interpolate.BivariateSpline`
    and evaluate the resulting function on the square for all values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows, and it shows the interpolation of 2D data with bivariate
    splines:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Interpolation](img/7702OS_04_16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Regression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Regression is similar to interpolation. In this case, we assume that the data
    is imprecise, and we require an object of predetermined structure to fit the data
    as closely as possible. The most basic example is univariate polynomial regression
    to a sequence of points. We obtain that with the `polyfit` command, which we discussed
    briefly in the *Univariate polynomials* section of this chapter. For instance,
    if we want to compute the regression line in the least-squares sense for a sequence
    of 10 uniformly spaced points in the interval (0, *π*/2) and their values under
    the `sin` function, we will issue the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'This gives the following plot that shows linear regression with `polyfit`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Regression](img/7702OS_04_17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Curve fitting is also possible with splines if we use the parameters wisely.
    For example, in the case of univariate spline fitting that we introduced before,
    we can play around with the weights, smoothing factor, the degree of the smoothing
    spline, and so on. If we want to fit a parabolic spline for the same data as the
    previous example, we could issue the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'This gives the following graph that shows curve fitting with splines:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Regression](img/7702OS_04_18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'For regression from the point of view of curve fitting, there is a generic
    routine: `curve_fit` in the `scipy.optimize` module. This routine minimizes the
    sum of squares of a set of equations using the **Levenberg-Marquardt** algorithm
    and offers a best fit from any kind of functions (not only polynomials or splines).
    The syntax is simple:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: The `f` parameter is a callable function that represents the function we seek,
    and `xdata` and `ydata` are arrays of the same length that contain the *x* and
    *y* coordinates of the points to be fit. The tuple `p0` holds an initial guess
    for the values to be found, and `sigma` is a vector of weights that could be used
    instead of the standard deviation of the data, if necessary.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will show its usage with a good example. We will start by generating some
    points on a section of a sine wave with amplitude `A=18`, angular frequency *w=3π*,
    and phase `h=0.5`. We corrupt the data in the array `y` with some small random
    noise:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'We want to estimate the values of `A`, `w`, and `h` from the corrupted data,
    hence technically finding a curve fit from the set of sine waves. We start by
    gathering the three parameters in a list and initializing them to some values,
    for example, `A = 20`, *w = 2π*, and `h = 1`. We also construct a callable expression
    of the target function (`target_function`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'We feed these, together with the fitting data, to `curve_fit` in order to find
    the required values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'A sample of `pF` run on any of our experiments should give an accurate result
    for the three requested values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'The output for the preceding command is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'This means that `A` was estimated to about 18.14, `w` was estimated very close
    to 3*π*, and `h` was between 0.46 and 0.55\. The output of the initial data together
    with a computation of the sine wave is as follows, in which original data (in
    blue on the left-hand side graph), corrupted (in red in both graphs), and computed
    sine wave (in black in the right-hand side) are shown in following plots:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Regression](img/7702OS_04_19.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The code is too long to be included here. Instead, the full code (intermediate
    plots that are produced are not shown here) can be found in the corresponding
    electronic resource IPython Notebook for this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Optimization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Optimization involves finding extreme values of functions or their roots. We
    have already seen the power of optimization in the curve-fitting arena, but it
    does not stop there. There are applications to virtually every single branch of
    engineering, and robust algorithms to perform these tasks are a must in every
    scientist's toolbox.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `curve_fit` routine is actually syntactic sugar for the general algorithm
    that performs least-squares minimization, `leastsq`, with the imposing syntax:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'For instance, the `curve_fit` routine could have been called with a `leastsq`
    call instead:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, `error_function` is equal to `lambda p,x,y: target_function(x,p[0],p[1],p[2])-y`'
  prefs: []
  type: TYPE_NORMAL
- en: The implementation is given in the corresponding section on the IPython Notebook
    of this chapter. Most of the optimization routines in SciPy can be accessed from
    either native Python code, or as wrappers for Fortran or C classical implementations
    of their corresponding algorithms. Technically, we are still using the same packages
    we did under Fortran or C, but from within Python. For instance, the minimization
    routine that implements the truncated `Newton` method can be called with `fmin_ncg`
    (and this is purely Python) or as `fmin_tnc` (and this one is a wrap of a C implementation).
  prefs: []
  type: TYPE_NORMAL
- en: Minimization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For general minimization problems, SciPy has many different algorithms. So far,
    we have covered the least-squares algorithm (`leastsq`), but we also have brute
    force (`brute`), **simulated annealing** (`anneal`), **Brent** or **Golden** methods
    for scalar functions (`brent` or `golden`), the **downhill simplex** algorithm
    (`fmin`), **Powell's** method (`fmin_powell`), **nonlinear conjugate gradient**
    or Newton's version of it (`fmin_cg`, `fmin_ncg`), and the **BFGS** algorithm
    (`fmin_bfgs`).
  prefs: []
  type: TYPE_NORMAL
- en: Constrained minimization is also possible computationally, and SciPy has routines
    that implement the **L-BFGS-S** algorithm (`fmin_l_bfgs_s`), truncated Newton's
    algorithm (`fmin_tnc`), **COBYLA** (`fmin_cobyla`), or sequential least-squares
    programming (`fmin_slsqp`).
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code, for example, compares the output of all different methods
    to finding a local minimum of the Rosenbrock function, `scipy.optimize.rosen`,
    near the origin using the downhill simplex algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'Since the Version 0.11 of SciPy, all minimization routines can be called from
    the generic `scipy.optimize.minimize`, with the `method` parameter pointing to
    one of the strings, such as `Nelder-Mead` (for the downhill simplex), `Powell`,
    `CG`, `Newton-CG`, `BFGS`, or `anneal`. For constrained minimization, the corresponding
    strings are one of `L-BFGS-S`, `TNC` (for truncated Newton''s), `COBYLA`, or `SLSQP`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: Roots
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For most special functions included in the `scipy.specia`l module, we have
    accurate algorithms that allow us to their zeros. For instance, for the Bessel
    function of first kind with integer order, `jn_zeros`, offers as many roots as
    desired (in ascending order). We may obtain the first three roots of the Bessel
    J-function of order four by issuing the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: For nonspecial scalar functions, the `scipy.optimize` module allows approximation
    to the roots through a great deal of different algorithms. For scalar functions,
    we have the **crude bisection** method (`bisect`), the **classical secant** method
    of **Newton-Raphson** (`newton`), and more accurate and faster methods such as
    **Ridders**' algorithm (`ridder`), and two versions of the Brent method (`brentq`
    and `brenth`).
  prefs: []
  type: TYPE_NORMAL
- en: 'Finding roots for functions of several variables is very challenging in many
    ways; the larger the dimension, the more difficult it is. The effectiveness of
    any of these algorithms depends on the problem, and it is a good idea to invest
    some time and resources in knowing them all. Since Version 0.11 of SciPy, it is
    possible to call any of the designed methods with the same routine `scipy.optimize.root`,
    which has the following syntax:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: The different methods are obtained upon changing the value of the `method` parameter
    to a method's string. We may choose from methods such as `'hybr'` for a modified
    hybrid Powell's method; `'lm'` for a modified least-squares method; `'broyden1'`
    or `'broyden2'` for Broyden's good and bad methods, respectively; `'diagbroyden'`
    for the diagonal Broyden Jacobian approximation; `'anderson'` for Anderson's extended
    mixing; `'Krylov'` for Krylov approximation of the Jacobian; `'linearmixing'`
    for scalar Jacobian approximation; and `'excitingmixing'` for a tuned diagonal
    Jacobian approximation.
  prefs: []
  type: TYPE_NORMAL
- en: For large-scale problems, both the Krylov approximation of the Jacobian or the
    Anderson extended mixing are usually the best options.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s present an illustrative example of the power of these techniques. Consider
    the following system of differential equations:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Roots](img/7702OS_04_20.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'We use the plot routine quiver from the matplotlib.pyplot libraries to visualize
    a slope field for values of `x` and `y` between -0.5 and 2.5, and hence identify
    the location of the possible critical points in that region:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Roots](img/7702OS_04_21.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Note how there is a whole region of the plane in which the slopes are extremely
    small. Because of the degrees of the polynomials involved, there are at most four
    different possible critical points. In this area, we should be able to identify
    two such points (as a matter of fact there are only two noncomplex solutions).
    One of them seems to be near (0, 1) and the second one is near (2, 0). We use
    these two locations as initial guesses for our searches:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s look at second case:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: In the first case, we converged successfully to (-0.22221456, 0.99380842). In
    the second case, we converged to (1.90067673, 0.31121857). The routine gives us
    the details of the convergence and the properties of the approximation. For instance,
    `nfev` tells us about the number of function calls performed, and `fun` indicates
    the output of the function at the found location. The other items in the output
    reflect the matrices used in the procedure, such as `qtf`, `r`, and `fjac`.
  prefs: []
  type: TYPE_NORMAL
- en: Integration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: SciPy is capable of performing very robust numerical integration. Definite integrals
    of a set of special functions are evaluated accurately with routines in the `scipy.special`
    module. For other functions, there are several different algorithms to obtain
    reliable approximations in the `scipy.integrate` module.
  prefs: []
  type: TYPE_NORMAL
- en: Exponential/logarithm integrals
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A summary of the indefinite and definite integrals in the category of exponential/logarithm
    is presented here: the exponential integrals (`expn`, `expi`, and `exp1`), **Dawson''s**
    integral (`dawsn`), and **Gauss error functions** (`erf` and `erfc`). We also
    have **Spence''s** dilogarithm (also known as Spence''s integral). Let''s have
    a look at the following formulas:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Exponential/logarithm integrals](img/7702OS_04_22.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Trigonometric and hyperbolic trigonometric integrals
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the category of trigonometric and hyperbolic trigonometric integrals, we
    have Fresnel sine and cosine integrals, as well as the sinc and hyperbolic trigonometric
    integrals. Let''s have a look at the following formulas:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Trigonometric and hyperbolic trigonometric integrals](img/7702OS_04_23.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'In the definitions given in the preceding list of integrals, the gamma symbol
    denotes the Euler-Mascheroni constant:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Trigonometric and hyperbolic trigonometric integrals](img/7702OS_04_24.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Elliptic integrals
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Elliptic integrals arise naturally when computing the arc length of ellipses.
    SciPy follows the argument notation for elliptic integrals: complete (one argument)
    and incomplete (two arguments). Let''s have a look at the following formulas:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Elliptic integrals](img/7702OS_04_25.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Gamma and beta integrals
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the category of gamma and beta integrals, we have one incomplete gamma function,
    one complemented incomplete gamma integral, and one incomplete beta integral.
    These are some of the most useful functions in this category. Let''s have a look
    at the following formulas:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Gamma and beta integrals](img/7702OS_04_26.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Numerical integration
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For any other functions, we are content with approximating definite integrals
    with quadrature formulae, such as `quad` (adaptive quadrature), `fixed_quad` (fixed-order
    Gaussian quadrature), `quadrature` (fixed-tolerance Gaussian quadrature), and
    `romberg`, (Romberg integration). For functions with more than one variable, we
    have `dbquad` (double integral) and `tplquad` (triple integral) methods. The syntax
    in all cases is a variation of `quad`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: 'If we have samples instead of functions, we may use routines such as `trapz`,
    `cumtrapz` (composite trapezoidal rule and its cumulative version), `romb` (Romberg
    integration again), and `simps` (Simpson''s rule) instead. In these routines,
    the syntax is simpler and changes the order of the parameters. For example, this
    is how we call `simps`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: Those of us familiar with the **QUADPACK** libraries will find similar syntax,
    usage, and performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'For extra information, run the `scipy.integrate.quad_explain()` command. In
    the IPython Notebook for this chapter, the alternative help command, `scipy.integrate.quad`,
    is executed and its output is displayed in the corresponding section. This explains
    with great detail all the different outputs of the quadrature integrals included
    in the module result, the estimation of absolute error and convergence, and explanation
    of the used weightings, if necessary. Let''s give at least one meaningful example
    where we integrate a special function and compare the output of a quadrature formula
    against the more accurate value of the routines given in `scipy.special`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s take a look at following `print` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s look further into the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: 'To use a routine that integrates from samples, we have the flexibility of assigning
    the frequency and length of the data. For the following problem, we could try
    with 10,000 samples in the same interval:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: Ordinary differential equations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As with integration, SciPy has some extremely accurate general-purpose solvers
    for systems of ordinary differential equations of first order:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Ordinary differential equations](img/7702OS_04_27.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'For real-valued functions, we have basically two flavors: `ode` (with options
    passed with the `set_integrator` method) and `odeint` (simpler interface). The
    syntax of `ode` is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: The first parameter, `f`, is the function to be integrated, and the second parameter,
    `jac`, refers to the matrix of partial derivatives with respect to the dependent
    variables (the Jacobian). This creates an `ode` object, with different methods
    to indicate the algorithm to solve the system (`set_integrator`), the initial
    conditions (`set_initial_value`), and different parameters to be sent to the function
    or its Jacobian.
  prefs: []
  type: TYPE_NORMAL
- en: The options for integration algorithm are `'vode'` for real-valued variable
    coefficient ODE solver, with fixed-leading-coefficient implementation (it provides
    Adam's method for non-stiff problems and BDF for stiff); `'zvode'` for complex-valued
    variable coefficient ODE solver, with similar options as the preceding option;
    `'dopri5'` for a **Runge-Kutta** method of order (4)5; `'dop853'` for a Runge-Kutta
    method of order 8(5, 3).
  prefs: []
  type: TYPE_NORMAL
- en: 'The next code snippet presents an example of usage of the `scipy.integrate.ode`
    to solve the initial value problem using the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Ordinary differential equations](img/7702OS_04_28.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'We compute each step sequentially and compare it with the actual solution,
    which is known. You will notice that virtually there is no difference:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: 'Once run, the preceding code gives us the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: The full output is displayed on the corresponding section of the IPython Notebook
    for this chapter. For systems of differential equations of first order with complex-valued
    functions, we have a wrapper of `ode`, which we call with the `complex_ode` command.
    Syntax and usage are similar to those of `ode`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The syntax of `odeint` is much more intuitive, and more Python friendly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: The most impressive part of this routine is that one is able to indicate not
    only the Jacobian, but also whether this is banded and how many nonzero diagonals
    are under or over the main diagonal we have (with the `ml` and `mu` options).
    This speeds up computations by a huge factor. Another amazing feature of `odeint`
    is the possibility to indicate critical points for the integration (`tcrit`).
  prefs: []
  type: TYPE_NORMAL
- en: We will now introduce an application to analyze Lorentz attractors with the
    routines presented in this section.
  prefs: []
  type: TYPE_NORMAL
- en: Lorenz attractors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: No book on scientific computing is complete without revisiting Lorenz attractors;
    SciPy excels both at computation of solutions and presentation of ideas based
    upon systems of differential equations, of course, and we will show how and why
    in this section.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider a two-dimensional fluid cell that is heated from underneath and cooled
    from above, much like what occurs with the Earth''s atmosphere. This creates convection
    that can be modeled by a single partial differential equation, for which a decent
    approximation has the form of the following system of ordinary differential equations:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Lorenz attractors](img/7702OS_04_29.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The variable *x* represents the rate of convective overturning. The variables
    *y* and *z* stand for the horizontal and vertical temperature variations, respectively.
    This system depends on four physical parameters, the descriptions of which are
    far beyond the scope of this book. The important point is that we may model Earth's
    atmosphere with these equations, and in that case a good choice for the parameters
    is given by `sigma = 10.0`, and `b = 8/3.0`. For certain values of the third parameter,
    we have systems for which the solutions behave chaotically. Let's explore this
    effect with the help of SciPy.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following code snippet, we will use one of the solvers in the `scipy.integrate`
    module as well as the plotting utilities:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s choose a time interval `t` large enough with a sufficiently dense partition
    and any initial condition, `y0`. Then, issue the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: 'If we want to plot a 3D rendering of the solution obtained, we can do so as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: 'This produces the following graph that shows a Lorenz attractor:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Lorenz attractors](img/7702OS_04_30.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'This is most illustrative and shows precisely the chaotic behavior of the solutions.
    Let''s observe the fluctuations of the vertical temperature in detail, along with
    the fluctuation of horizontal temperature against vertical. Issue the following
    commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: 'This produces the following the plots that show vertical temperature with respect
    to time (left-hand side plot) and horizontal versus vertical temperature (right-hand
    side plot):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Lorenz attractors](img/7702OS_04_31.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter explored special functions, integration, interpolation, and optimization
    through the corresponding modules (`special`, `integrate`, `interpolate`, and
    `optimize`), as well as discussed solutions of systems of ordinary differential
    equations.
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 5](ch05.html "Chapter 5. SciPy for Signal Processing"), *SciPy for
    Signal Processing*, we will describe the functionality of SciPy modules to analyze
    processes involving time series and spatial signals, including how to perform
    on numerical data the discrete Fourier transform, how to construct signals, how
    to apply filters on data, and how to interpolate images.
  prefs: []
  type: TYPE_NORMAL
