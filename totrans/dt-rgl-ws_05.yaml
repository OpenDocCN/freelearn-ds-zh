- en: 5\. Getting Comfortable with Different Kinds of Data Sources
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5. 熟悉不同类型的数据源
- en: Overview
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 概述
- en: This chapter will provide you with the skills to read CSV, Excel, and JSON files
    into pandas DataFrames. You will learn how to read PDF documents and HTML tables
    into pandas DataFrames and perform basic web scraping operations using powerful
    yet easy-to-use libraries such as Beautiful Soup. You will also see how to extract
    structured and textual information from portals. By the end of this chapter, you
    will be able to implement data wrangling techniques such as web scraping in the
    real world.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将为您提供将 CSV、Excel 和 JSON 文件读取到 pandas DataFrame 的技能。您将学习如何将 PDF 文档和 HTML 表格读取到
    pandas DataFrame 中，并使用如 Beautiful Soup 这样功能强大且易于使用的库执行基本的网络抓取操作。您还将了解如何从门户网站中提取结构和文本信息。到本章结束时，您将能够将网络抓取等数据整理技术应用于现实世界。
- en: Introduction
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简介
- en: So far in this book, we have focused on studying pandas DataFrame objects as
    the main data structure for the application of wrangling techniques. In this chapter,
    we will learn about various techniques by which we can read data into a DataFrame
    from external sources. Some of these sources could be text-based (such as CSV,
    HTML, and JSON), whereas others could be binary (that is, not in ASCII format;
    for example, from Excel or PDFs). We will also learn how to deal with data that
    is present in web pages or HTML documents.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，在这本书中，我们一直专注于研究 pandas DataFrame 对象作为应用整理技术的主体数据结构。在本章中，我们将学习各种技术，通过这些技术我们可以从外部源将数据读取到
    DataFrame 中。其中一些来源可能是基于文本的（例如 CSV、HTML 和 JSON），而其他来源可能是二进制的（即不是 ASCII 格式；例如，来自
    Excel 或 PDF）。我们还将学习如何处理存在于网页或 HTML 文档中的数据。
- en: Being able to deal with and extract meaningful data from various sources is
    of paramount interest to a data practitioner. Data can, and often does, come in
    various forms and flavors. It is essential to be able to get the data into a form
    that is useful for performing predictive or other kinds of downstream tasks.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 能够处理和从各种来源提取有意义的数据对数据从业者来说至关重要。数据可以，并且经常以各种形式和风味出现。能够将数据转换为对执行预测或其他下游任务有用的形式是至关重要的。
- en: As we have gone through detailed examples of basic operations with NumPy and
    pandas, in this chapter, we will often skip trivial code snippets such as viewing
    a table, selecting a column, and plotting. Instead, we will focus on showing code
    examples for the new topics we aim to learn about here.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们详细介绍了使用 NumPy 和 pandas 进行基本操作，在本章中，我们将经常跳过一些琐碎的代码片段，例如查看表格、选择列和绘图。相反，我们将专注于展示我们在此处想要学习的新主题的代码示例。
- en: Reading Data from Different Sources
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从不同来源读取数据
- en: One of the most valued and widely used skills of a data wrangling professional
    is the ability to extract and read data from a diverse array of sources into a
    structured format. Modern analytics pipelines depend on the ability and skills
    of those professionals to build a robust system that can scan and absorb a variety
    of data sources to build and analyze a pattern-rich model. Such kinds of feature-rich,
    multi-dimensional models will have high predictive and generalization accuracy.
    They will be valued by stakeholders and end users alike in any data-driven product.
    In the first part of this chapter, we will go through various data sources and
    how they can be imported into `pandas` DataFrames, thus imbuing data wrangling
    professionals with extremely valuable data ingestion knowledge.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 数据整理专业人士最宝贵且最广泛使用的技能之一是能够从各种来源提取和读取数据到结构化格式。现代分析管道依赖于这些专业人士的能力和技能，构建一个强大的系统，可以扫描和吸收各种数据源，以构建和分析富含模式模型。这类特征丰富、多维度的模型将具有高度的预测和泛化准确性。在任何数据驱动产品中，它们都将受到利益相关者和最终用户的重视。在本章的第一部分，我们将探讨各种数据源以及它们如何被导入到
    pandas DataFrame 中，从而赋予数据整理专业人士极其宝贵的数据摄取知识。
- en: Data Files Provided with This Chapter
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 本章节提供的数据文件
- en: As this topic is about reading from various data sources, we will use small
    files of various types in the following exercises. All the data files are provided,
    along with the Jupyter notebook, in the code repository.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这个主题是关于从各种数据源读取数据，在接下来的练习中，我们将使用各种类型的小文件。所有数据文件都包含在代码仓库中，以及 Jupyter 笔记本。
- en: Note
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'All the data files can be accessed from the following link: [https://packt.live/3fAWg3f](https://packt.live/3fAWg3f).'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 所有数据文件都可以通过以下链接访问：[https://packt.live/3fAWg3f](https://packt.live/3fAWg3f)。
- en: Libraries to Install for This Chapter
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 本章节需要安装的库
- en: As this chapter deals with reading files of various formats, we need to have
    the support of additional libraries and software platforms to accomplish our goals.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 由于本章涉及读取各种格式的文件，我们需要额外的库和软件平台的支持来实现我们的目标。
- en: 'Before we install these libraries, ensure that **Java Development Kit (JDK)**
    is installed on your system. If not, go to the following link to install it:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们安装这些库之前，请确保您的系统上已安装 **Java 开发工具包 (JDK)**。如果没有，请访问以下链接进行安装：
- en: '[https://www.oracle.com/in/java/technologies/javase-downloads.html](https://www.oracle.com/in/java/technologies/javase-downloads.html).'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.oracle.com/in/java/technologies/javase-downloads.html](https://www.oracle.com/in/java/technologies/javase-downloads.html).'
- en: Once you are on the website, click the link that says `JDK Download`. Then,
    proceed to download and install JDK based on your operating system. Once installation
    completes, ensure that you restart your system, especially if you are using Windows.
    In case you face issues after installation, check if you've set the PATH system
    variable correctly. To learn how to do that, refer [https://www.java.com/en/download/help/path.xml](https://www.java.com/en/download/help/path.xml).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您进入网站，点击名为“JDK 下载”的链接。然后，根据您的操作系统下载并安装 JDK。安装完成后，请确保重启您的系统，尤其是如果您正在使用 Windows。如果在安装后遇到问题，请检查您是否已正确设置
    PATH 系统变量。要了解如何做到这一点，请参阅 [https://www.java.com/en/download/help/path.xml](https://www.java.com/en/download/help/path.xml)。
- en: 'Once JDK is installed, go ahead and install the necessary libraries. Execute
    the following command in your Jupyter Notebook cells:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦 JDK 安装完成，继续安装必要的库。在您的 Jupyter Notebook 单元中执行以下命令：
- en: '[PRE0]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Note
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Don't forget the `!` before each line of code. This little exclamation sign
    in front of each command lets the Jupyter runtime know that what is in the cell
    is a `bash` command and not a line of Python code.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 不要忘记每行代码前的 `!`。这个位于每个命令前面的感叹号让 Jupyter 运行时知道单元格中的内容是一个 `bash` 命令，而不是 Python
    代码的一行。
- en: Reading Data Using Pandas
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Pandas 读取数据
- en: The `pandas` library provides a simple method called `read_csv` to read data
    in a tabular format from a comma-separated text file, or `.csv`. This is particularly
    useful because `.csv` is a lightweight yet extremely handy data exchange format
    for many applications, including such domains where machine-generated data is
    involved. It is not a proprietary format and therefore is universally used by
    a variety of data-generating sources.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '`pandas` 库提供了一个名为 `read_csv` 的简单方法，用于从逗号分隔的文本文件或 `.csv` 中读取表格格式的数据。这特别有用，因为
    `.csv` 是一种轻量级但极其方便的数据交换格式，适用于许多应用程序，包括涉及机器生成数据的领域。它不是专有格式，因此被各种数据生成源普遍使用。'
- en: Generally, a `.csv` file has two sections. The first line of a `.csv` file is
    usually treated as a header line. So, each column (each word, or words, between
    two consecutive commas) in the first line should indicate the name of the column.
    This is very valuable information because without it, it would often be impossible
    to say what kind of data each of them represents. After the first line, we have
    data rows where each line represents one data point and each column represents
    values of those data points.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，`.csv` 文件有两个部分。`.csv` 文件的第 一行通常被视为标题行。因此，第一行中的每个列（两个连续逗号之间的每个单词或单词组）都应该指示列的名称。这是非常有价值的信息，因为没有它，通常很难说每个代表什么类型的数据。在第一行之后，我们有数据行，其中每一行代表一个数据点，每一列代表这些数据点的值。
- en: 'Exercise 5.01: Working with Headers When Reading Data from a CSV File'
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 5.01：从 CSV 文件中读取数据时的标题处理
- en: 'In this exercise, you will see how to read data from a `.csv` file. The file
    can be found here [https://packt.live/3fDMCNp](https://packt.live/3fDMCNp). This
    exercise acts as a demonstration of how to work with headers and what to do when
    the headers are missing. At times, you will encounter situations where headers
    are not present, and you may have to add proper headers or column names of your
    own. Let''s have a look at how this can be done:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，您将看到如何从 `.csv` 文件中读取数据。该文件可在此处找到 [https://packt.live/3fDMCNp](https://packt.live/3fDMCNp)。这个练习演示了如何处理标题以及当标题缺失时应该做什么。有时，您会遇到标题不存在的情况，您可能需要添加适当的标题或自己的列名。让我们看看如何做到这一点：
- en: 'Open a new Jupyter Notebook and read the example `.csv` file (with a header)
    using the following code and examine the resulting DataFrame, as follows:'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个新的 Jupyter Notebook，并使用以下代码读取示例 `.csv` 文件（带有标题），然后检查生成的 DataFrame，如下所示：
- en: '[PRE1]'
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Note
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: Throughout this exercise, don't forget to change the path (highlighted) of the
    CSV file based on its location on your system.
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在整个练习过程中，不要忘记根据系统中的位置更改CSV文件的路径（突出显示）。
- en: 'The output is as follows:'
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 5.1: Output of the example CSV file'
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图5.1：示例CSV文件的输出]'
- en: '](img/B15780_05_01.jpg)'
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片 B15780_05_01.jpg]'
- en: 'Figure 5.1: Output of the example CSV file'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图5.1：示例CSV文件的输出
- en: 'Read a `.csv` file with no header using a `pandas` DataFrame:'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`pandas` DataFrame读取没有标题的`.csv`文件：
- en: '[PRE2]'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Read the `.csv` file by setting the `header` to `None`, as follows:'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过将`header`设置为`None`来读取`.csv`文件，如下所示：
- en: '[PRE3]'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Add the `names` argument to get the correct headers:'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加`names`参数以获取正确的标题：
- en: '[PRE4]'
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Finally, you will get a DataFrame that will look like this:'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 最后，您将得到一个看起来像这样的DataFrame：
- en: '![Figure 5.4: CSV file with correct column header'
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图5.4：具有正确列标题的CSV文件]'
- en: '](img/B15780_05_04.jpg)'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片 B15780_05_04.jpg]'
- en: 'Figure 5.4: CSV file with correct column header'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.4：具有正确列标题的CSV文件
- en: As you can see in the preceding figure, the headers have been added in the right
    places.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，标题已添加到正确的位置。
- en: Note
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/3hxmAgm](https://packt.live/3hxmAgm).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参阅[https://packt.live/3hxmAgm](https://packt.live/3hxmAgm)。
- en: You can also run this example online at [https://packt.live/3eaToda](https://packt.live/3eaToda).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以在[https://packt.live/3eaToda](https://packt.live/3eaToda)在线运行此示例。
- en: Up until now, we've been comfortable reading from files where a comma acts as
    a delimiter. Let's look at the following exercise, where we will be reading from
    a CSV file where the values are not separated by commas.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们一直很舒服地从以逗号作为分隔符的文件中读取。让我们看看以下练习，我们将从不以逗号分隔值的CSV文件中读取。
- en: 'Exercise 5.02: Reading from a CSV File Where Delimiters Are Not Commas'
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习5.02：从不以逗号为分隔符的CSV文件中读取
- en: It is fairly common to encounter raw data files where the separator/delimiter
    is a character and not a comma. This exercise will demonstrate how you can read
    data from a file in such a case.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 遇到原始数据文件，其中分隔符/定界符是字符而不是逗号的情况相当普遍。本练习将演示在这种情况下如何从文件中读取数据。
- en: Note
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'The file can be found here: [https://packt.live/2YPEJgO](https://packt.live/2YPEJgO).'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 文件可在此处找到：[https://packt.live/2YPEJgO](https://packt.live/2YPEJgO)。
- en: 'Let''s go through the following steps:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们按以下步骤进行：
- en: 'Read a `.csv` file using `pandas` DataFrames:'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`pandas` DataFrames读取`.csv`文件：
- en: '[PRE5]'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Specify the delimiter:'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指定分隔符：
- en: '[PRE6]'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The output is as follows:'
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 5.6: Semicolons removed from the DataFrame'
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图5.6：从DataFrame中移除的分号]'
- en: '](img/B15780_05_06.jpg)'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片 B15780_05_06.jpg]'
- en: 'Figure 5.6: Semicolons removed from the DataFrame'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.6：从DataFrame中移除的分号
- en: As we can see, it is fairly simple to read from a csv file when the delimiter
    is specified in the `read_csv` function.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，当在`read_csv`函数中指定分隔符时，从csv文件中读取相当简单。
- en: Note
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/2Na4oM0](https://packt.live/2Na4oM0).
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参阅[https://packt.live/2Na4oM0](https://packt.live/2Na4oM0)。
- en: You can also run this example online at [https://packt.live/3fvdm2g](https://packt.live/3fvdm2g).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以在[https://packt.live/3fvdm2g](https://packt.live/3fvdm2g)上运行此示例。
- en: In the following exercise, we will see how to bypass the headers if your CSV
    file already comes with headers.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下练习中，我们将看到如果您的CSV文件已经包含标题，如何跳过标题。
- en: 'Exercise 5.03: Bypassing and Renaming the Headers of a CSV File'
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习5.03：跳过并重命名CSV文件的标题
- en: 'This exercise will demonstrate how to bypass the headers of a CSV file and
    put in your own. To do that, you have to specifically set `header=0`. If you try
    to set the `names` variable to your `header` list, unexpected things can happen.
    Follow these steps:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 本练习将演示如何跳过CSV文件的标题并添加自己的标题。为此，您必须特别设置`header=0`。如果您尝试将`names`变量设置为您的`header`列表，可能会发生意外的事情。请按照以下步骤操作：
- en: 'Add `names` to a `.csv` file that has headers, as follows:'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向具有标题的`.csv`文件添加`names`，如下所示：
- en: '[PRE7]'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Note
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: Throughout this exercise, don't forget to change the path (highlighted) of the
    CSV file based on its location on your system.
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在整个练习过程中，不要忘记根据系统中的位置更改CSV文件的路径（突出显示）。
- en: 'The output is as follows:'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 5.7: A CSV file with headers overlapped'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图5.7：具有重叠标题的CSV文件]'
- en: '](img/B15780_05_07.jpg)'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片 B15780_05_07.jpg]'
- en: 'Figure 5.7: A CSV file with headers overlapped'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图5.7：具有重叠标题的CSV文件
- en: 'To avoid this, set `header` to zero and provide a `names` list:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了避免这种情况，将`header`设置为0并提供一个`names`列表：
- en: '[PRE8]'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The output is as follows:'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 5.8: A CSV file with defined headers'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图5.8：具有定义标题的CSV文件'
- en: '](img/B15780_05_08.jpg)'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B15780_05_08.jpg)'
- en: 'Figure 5.8: A CSV file with defined headers'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.8：具有定义标题的CSV文件
- en: Keep in mind that this representation is just in memory at the moment and only
    available in the present session of the notebook; it is not reflected in the physical
    CSV file. The original file has not changed due to our manipulation.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，这种表示目前只是在内存中，并且仅在笔记本的当前会话中可用；它不会反映在物理CSV文件中。原始文件由于我们的操作而未发生变化。
- en: Note
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/30QwEeA](https://packt.live/30QwEeA).
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参阅 [https://packt.live/30QwEeA](https://packt.live/30QwEeA)。
- en: You can also run this example online at [https://packt.live/315gOgr](https://packt.live/315gOgr).
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以在此在线运行此示例 [https://packt.live/315gOgr](https://packt.live/315gOgr)。
- en: We observed some operations that we can do on the headers in a file. However,
    some CSV files may have an even more complex structure than the simple ones that
    we have been using so far. In the following exercise, we will discover some tricks
    to deal with such complex structures.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我们观察了一些可以在文件标题上进行的操作。然而，一些CSV文件的结构可能比我们迄今为止使用的简单结构更复杂。在接下来的练习中，我们将发现一些处理这种复杂结构的技巧。
- en: 'Exercise 5.04: Skipping Initial Rows and Footers When Reading a CSV File'
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习5.04：在读取CSV文件时跳过初始行和页脚
- en: 'In this exercise, we will skip the first few rows because, most of the time,
    the first few rows of a CSV data file are metadata about the data source or similar
    information, which is not read into the table. Also, we will go ahead and remove
    the footer of the file, which might sometimes contain information that''s not
    very useful. Let''s see how we can do that using the example shown in the following
    screenshot:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将跳过前几行，因为，大多数情况下，CSV数据文件的前几行是关于数据源或类似信息的元数据，这些信息不会被读入表格。此外，我们还将删除文件的页脚，有时页脚可能包含不太有用的信息。让我们看看我们如何使用以下截图中的示例来完成这项操作：
- en: '![Figure 5.9: Contents of the CSV file'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.9：CSV文件的内容'
- en: '](img/B15780_05_09.jpg)'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B15780_05_09.jpg)'
- en: 'Figure 5.9: Contents of the CSV file'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.9：CSV文件的内容
- en: Note
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The first two lines in the CSV file are irrelevant data. The file can be found
    here [https://packt.live/30SdvJh](https://packt.live/30SdvJh)
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: CSV文件的前两行是不相关的数据。文件可以在这里找到 [https://packt.live/30SdvJh](https://packt.live/30SdvJh)
- en: 'Read the CSV file and examine the results:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 读取CSV文件并检查结果：
- en: '[PRE9]'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Note
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: Throughout this exercise, don't forget to change the path (highlighted) of the
    CSV file based on its location on your system.
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在整个练习过程中，不要忘记根据您系统上CSV文件的位置更改路径（突出显示）。
- en: 'The output is as follows:'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 5.10: DataFrame with an unexpected error'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图5.10：带有意外错误的DataFrame'
- en: '](img/B15780_05_10.jpg)'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B15780_05_10.jpg)'
- en: 'Figure 5.10: DataFrame with an unexpected error'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图5.10：带有意外错误的DataFrame
- en: 'Skip the first two rows and read the file:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 跳过前两行并读取文件：
- en: '[PRE10]'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Use the `skipfooter` option in Python:'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Python中使用`skipfooter`选项：
- en: '[PRE11]'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The output is as follows:'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 5.13: DataFrame without a footer'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图5.13：没有页脚的DataFrame'
- en: '](img/B15780_05_013.jpg)'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B15780_05_013.jpg)'
- en: 'Figure 5.13: DataFrame without a footer'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.13：没有页脚的DataFrame
- en: Note
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/2CbehGO](https://packt.live/2CbehGO).
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参阅 [https://packt.live/2CbehGO](https://packt.live/2CbehGO)。
- en: You can also run this example online at [https://packt.live/2Ycw0Gp](https://packt.live/2Ycw0Gp).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以在此在线运行此示例 [https://packt.live/2Ycw0Gp](https://packt.live/2Ycw0Gp)。
- en: We've now seen how to read values skipping the headers and footers from a file.
    It can very often be very handy while dealing with data collected from several
    different sources, especially in situations where a file contains unnecessary
    and junk information.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到了如何从文件中读取值，跳过标题和页脚。在处理来自多个不同来源收集的数据时，这通常非常有用，尤其是在文件包含不必要和垃圾信息的情况下。
- en: Reading Only the First N Rows
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 只读取前N行
- en: In many situations, we may not want to read a whole data file but only the first
    few rows. This is particularly useful for extremely large data files, where we
    may just want to read the first couple of hundred rows to check an initial pattern
    and then decide to read the whole of the data afterward. Reading the entire file
    can take a long time and can slow down the entire data wrangling pipeline.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多情况下，我们可能不想读取整个数据文件，而只想读取前几行。这对于非常大的数据文件尤其有用，我们可能只想读取前几百行来检查初始模式，然后决定之后读取整个数据。读取整个文件可能需要很长时间，并且可能会减慢整个数据处理管道的速度。
- en: 'A simple option, called `nrows`, in the `read_csv` function, enables us to
    do just that. We will specify the number of rows we want to read and pass it as
    an argument to `nrows` like so:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在`read_csv`函数中有一个简单的选项，称为`nrows`，它使我们能够做到这一点。我们将指定我们想要读取的行数，并将其作为参数传递给`nrows`，如下所示：
- en: '[PRE12]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Note
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 备注
- en: The path (highlighted) would need to be changed based on where the file is saved
    on your system.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 路径（已突出显示）需要根据文件在系统中的保存位置进行更改。
- en: 'The output is as follows:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 5.14: DataFrame with the first few rows of the CSV file'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.14：包含CSV文件前几行的DataFrame]'
- en: '](img/B15780_05_014.jpg)'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B15780_05_014.jpg]'
- en: 'Figure 5.14: DataFrame with the first few rows of the CSV file'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.14：包含CSV文件前几行的DataFrame
- en: The ability to be able to read only a selected number of rows is useful, specifically
    if you are dealing with large CSV files.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 只读取选定行数的能力非常有用，特别是当你处理大型CSV文件时。
- en: 'Exercise 5.05: Combining skiprows and nrows to Read Data in Small Chunks'
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习5.05：结合skiprows和nrows以小块读取数据
- en: 'This exercise will demonstrate how we can read from a very large data file.
    To do that, we can cleverly combine `skiprows` and `nrows` to read in a large
    file in small chunks of pre-determined sizes. We will read from the `Boston_housing.csv`
    file, which contains data about the pricing of houses in the Boston area in the
    US. It contains information such as per capita crime rate by town and the average
    number of rooms per dwelling. To do this, let''s go through the following steps:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 本练习将演示我们如何从一个非常大的数据文件中读取。要做到这一点，我们可以巧妙地结合`skiprows`和`nrows`来以预定的块大小读取大文件。我们将从包含美国波士顿地区房价数据的`Boston_housing.csv`文件中读取。它包含有关城镇人均犯罪率和每栋住宅平均房间数量的信息。为此，让我们按照以下步骤进行：
- en: Note
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 备注
- en: Each exercise continues directly from the previous one. You do not need to open
    a new Jupyter Notebook each time.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 每个练习都直接从上一个练习继续。你不需要每次都打开一个新的Jupyter Notebook。
- en: 'The dataset can be found here: [https://packt.live/3fEIH2z](https://packt.live/3fEIH2z)'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集可以在以下位置找到：[https://packt.live/3fEIH2z](https://packt.live/3fEIH2z)
- en: 'Create a list where DataFrames will be stored:'
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个列表来存储将要存储的DataFrames：
- en: '[PRE13]'
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Store the number of rows to be read into a variable:'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将要读取的行数存储到变量中：
- en: '[PRE14]'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Create a variable to store the number of chunks to be read:'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个变量来存储要读取的块的数量：
- en: '[PRE15]'
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Create a dummy DataFrame to get the column names:'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个虚拟DataFrame以获取列名：
- en: '[PRE16]'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Note
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 备注
- en: Throughout this exercise, don't forget to change the path (highlighted) of the
    CSV file based on its location on your system.
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在整个练习过程中，不要忘记根据系统中的位置更改CSV文件的路径（已突出显示）。
- en: 'Loop over the CSV file to read only a fixed number of rows at a time:'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 遍历CSV文件以每次只读取固定数量的行：
- en: '[PRE17]'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Note
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 备注
- en: This particular step will not show any output as the values are getting appended
    to the list.
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个特定的步骤不会显示任何输出，因为值正在被追加到列表中。
- en: Note how the `iterator` variable is set up inside the `range` function to break
    it into chunks. Say the number of chunks is `5` and the rows per chunk is `10`,
    then the iterator will have a range of `(0,5*10,10)`, where the final `10` is
    step-size, that is, it will iterate with indices of `(0,9,19,29,39,49)`.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 注意观察在`range`函数内部如何设置`iterator`变量以将其分割成块。假设块的数量为`5`，每个块中的行数为`10`，那么迭代器的范围将是`(0,5*10,10)`，其中最后的`10`是步长，即它将以`(0,9,19,29,39,49)`的索引进行迭代。
- en: Note
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 备注
- en: To access the source code for this specific section, please refer to [https://packt.live/3fGmBwZ](https://packt.live/3fGmBwZ).
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参阅[https://packt.live/3fGmBwZ](https://packt.live/3fGmBwZ)。
- en: You can also run this example online at [https://packt.live/3hDbVAJ](https://packt.live/3hDbVAJ).
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以在[https://packt.live/3hDbVAJ](https://packt.live/3hDbVAJ)上在线运行此示例。
- en: Setting the skip_blank_lines Option
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置skip_blank_lines选项
- en: 'By default, `read_csv` ignores blank lines, which means if there are row entries
    with `NaN` values, the `read_csv` function will not read that data. However, in
    some situations, you may want to read them in as `NaN` so that you can count how
    many blank entries were present in the raw data file. In some situations, this
    is an indicator of the default data streaming quality and consistency. For this,
    you have to disable the `skip_blank_lines` option:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，`read_csv`忽略空白行，这意味着如果有行条目包含`NaN`值，`read_csv`函数将不会读取该数据。然而，在某些情况下，您可能希望将它们读取为`NaN`，以便您可以计算原始数据文件中存在的空白条目数量。在某些情况下，这是默认数据流质量一致性的指标。为此，您必须禁用`skip_blank_lines`选项：
- en: '[PRE18]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The output is as follows:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: Note
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The path (highlighted) would need to be changed based on where the file is located
    on your system.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 路径（已突出显示）需要根据文件在系统中的位置进行更改。
- en: '![Figure 5.15: DataFrame of a .csv file that has blank rows'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.15：包含空白行的.csv文件的DataFrame'
- en: '](img/B15780_05_015.jpg)'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15780_05_015.jpg)'
- en: 'Figure 5.15: DataFrame of a .csv file that has blank rows'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.15：包含空白行的.csv文件的DataFrame
- en: In the next section, we are going to read CSV data from a zip file.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将从ZIP文件中读取CSV数据。
- en: Reading CSV Data from a Zip File
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从ZIP文件中读取CSV数据
- en: This is an awesome feature of `pandas`, and it allows you to read directly from
    a compressed file, such as `.zip`, `.gz`, `.bz2`, or `.xz`. The only requirement
    is that the intended data file (`CSV`) should be the only file inside the compressed
    file. For example, we might need to compress a large csv file, and in that case,
    it will be the only file inside the `.zip` folder.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 这是`pandas`的一个很棒的功能，它允许您直接从压缩文件（如`.zip`、`.gz`、`.bz2`或`.xz`）中读取。唯一的要求是，目标数据文件（CSV）应该是压缩文件中的唯一文件。例如，我们可能需要压缩一个大的csv文件，在这种情况下，它将是`.zip`文件夹中的唯一文件。
- en: 'In this example, we compressed the example CSV file with the `7-Zip` program
    and read from it directly using the `read_csv` method:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在本例中，我们使用`7-Zip`程序压缩了示例CSV文件，并直接使用`read_csv`方法从中读取：
- en: '[PRE19]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The output is as follows:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 5.16: DataFrame of a compressed CSV file'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.16：压缩CSV文件的DataFrame'
- en: '](img/B15780_05_016.jpg)'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15780_05_016.jpg)'
- en: 'Figure 5.16: DataFrame of a compressed CSV file'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.16：压缩CSV文件的DataFrame
- en: Next, we will turn our attention to a Microsoft Excel file. It turns out that
    most of the options and methods we learned about in the previous exercises with
    the CSV file apply directly to reading Excel files too.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将把注意力转向Microsoft Excel文件。结果证明，我们在之前的CSV文件练习中学到的许多选项和方法也直接适用于读取Excel文件。
- en: Reading from an Excel File Using sheet_name and Handling a Distinct sheet_name
  id: totrans-169
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用sheet_name读取Excel文件和处理不同的sheet_name
- en: In this section, we will focus on the differences between the methods of reading
    from an Excel file. An Excel file can consist of multiple worksheets, and we can
    read a specific sheet by passing in a particular argument, that is, `sheet_name`.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将关注读取Excel文件的方法之间的差异。Excel文件可以包含多个工作表，我们可以通过传递特定的参数（即`sheet_name`）来读取特定的工作表。
- en: 'For example, in the `Housing_data.xlsx` file, we have three worksheets. The
    following code reads them one by one into three separate DataFrames:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在`Housing_data.xlsx`文件中，我们有三个工作表。以下代码将它们逐个读取到三个单独的DataFrame中：
- en: '[PRE20]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: If the Excel file has multiple distinct worksheets but the `sheet_name` argument
    is set to `None`, then an ordered dictionary will be returned by the `read_excel`
    function. That ordered `dict` will have the data from all the worksheets, and
    the top-level keys will indicate the name of the worksheet. Thereafter, we can
    simply iterate over that dictionary or its keys to retrieve individual DataFrames.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 如果Excel文件有多个不同的工作表，但`sheet_name`参数设置为`None`，则`read_excel`函数将返回一个有序字典。这个有序的`dict`将包含所有工作表的数据，顶级键将指示工作表的名称。之后，我们可以简单地遍历该字典或其键来检索单个DataFrame。
- en: 'Let''s consider the following example:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑以下示例：
- en: '[PRE21]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The output is as follows:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE22]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Therefore, we can access these individual worksheets using the distinct keys.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们可以使用不同的键访问这些单独的工作表。
- en: 'Exercise 5.06: Reading a General Delimited Text File'
  id: totrans-179
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习5.06：读取通用分隔文本文件
- en: 'In this exercise, we will read from general delimited text files and see that
    this can be done as easily as reading from CSV files. However, we will have to
    use the right separator if it is anything other than a whitespace or a tab. To
    see this in action, let''s go through the following steps:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将从通用定界文本文件中读取，并看到这可以像读取CSV文件一样容易。然而，如果我们使用的是空格或制表符之外的任何分隔符，我们必须使用正确的分隔符。为了展示其作用，让我们按照以下步骤进行：
- en: 'Read the data from a `.txt` file using the `read_table` command:'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`read_table`命令从`.txt`文件中读取数据：
- en: '[PRE23]'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Set the separator as a comma in the `sep` variable as follows:'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`sep`变量中将分隔符设置为逗号，如下所示：
- en: '[PRE24]'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The output is as follows:'
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 5.18: A DataFrame read using a comma separator'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图5.18：使用逗号分隔符读取的DataFrame'
- en: '](img/B15780_05_018.jpg)'
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15780_05_018.jpg)'
- en: 'Figure 5.18: A DataFrame read using a comma separator'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.18：使用逗号分隔符读取的DataFrame
- en: We can see in the figure that the data is read as expected from the `.txt` file.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以从图中看到数据已按预期从`.txt`文件中读取。
- en: Note
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/30UUdD8](https://packt.live/30UUdD8).
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参阅[https://packt.live/30UUdD8](https://packt.live/30UUdD8)。
- en: You can also run this example online at [https://packt.live/37F57ho](https://packt.live/37F57ho).
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以在[https://packt.live/37F57ho](https://packt.live/37F57ho)上在线运行此示例。
- en: Now that we have seen the various ways of reading data from `csv` files, in
    the next section, let's focus on reading data directly from a URL.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经看到了从`csv`文件中读取数据的各种方法，在下一节中，让我们专注于直接从URL读取数据。
- en: Reading HTML Tables Directly from a URL
  id: totrans-194
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 直接从URL读取HTML表格
- en: The `pandas` library allows us to read HTML tables directly from a URL. This
    means that the library already has some kind of built-in HTML parser that processes
    the HTML content of a given page and tries to extract various tables from the
    page.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '`pandas`库允许我们直接从URL读取HTML表格。这意味着该库已经内置了一种HTML解析器，它会处理给定页面的HTML内容并尝试从页面中提取各种表格。'
- en: Note
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The `read_html` method from the `pandas` library returns a list of DataFrames
    (even if the page has a single DataFrame) and you have to extract the relevant
    tables from the list.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '`pandas`库中的`read_html`方法返回一个DataFrame列表（即使页面只有一个DataFrame），你必须从列表中提取相关的表格。'
- en: 'Consider the following example:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下示例：
- en: '[PRE25]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'These results are shown in the following DataFrame:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 这些结果如下所示的数据框中：
- en: '![Figure 5.19: Results of reading HTML tables'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.19：读取HTML表格的结果'
- en: '](img/B15780_05_019.jpg)'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15780_05_019.jpg)'
- en: 'Figure 5.19: Results of reading HTML tables'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.19：读取HTML表格的结果
- en: In the following exercise, we'll explore some more wrangling techniques to get
    the data in the desired format. As discussed in the preceding exercise, `read_html`,
    the HTML-reading function, almost always returns more than one table for a given
    HTML page, and we have to further parse through the list to extract the particular
    table we are interested in.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下练习中，我们将探索更多整理技术以获取所需格式的数据。正如前一个练习中讨论的，`read_html`这个HTML读取函数几乎总是为给定HTML页面返回多个表格，我们必须进一步解析列表以提取我们感兴趣的特定表格。
- en: 'Exercise 5.07: Further Wrangling to Get the Desired Data'
  id: totrans-205
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习5.07：进一步整理以获取所需数据
- en: 'In this exercise, we will work with the table of the 2016 Summer Olympics medal
    tally (by nation). We can easily search to get a page on Wikipedia containing
    this data that we can pass on to `pandas`. We will apply a few wrangling techniques
    on this data to get the output. To do so, let''s go through the following steps:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将处理2016年夏季奥运会奖牌榜（按国家划分）的表格。我们可以轻松搜索以获取包含这些数据的维基百科页面，然后将其传递给`pandas`。我们将对这个数据应用一些整理技术以获得输出。为此，让我们按照以下步骤进行：
- en: 'Use the `read_html` command to read from the Wikipedia page containing Summer
    Olympics records from 2016:'
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`read_html`命令从包含2016年夏季奥运会记录的维基百科页面中读取：
- en: '[PRE26]'
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Check the length of the list returned. We will see that it is `7`:'
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查返回列表的长度。我们会看到它是`7`：
- en: '[PRE27]'
  id: totrans-210
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The output is as follows:'
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE28]'
  id: totrans-212
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'To look for the particular table, run a simple loop. We are using the `shape`
    property of a DataFrame to examine the number of rows and the number of columns
    of each of them:'
  id: totrans-213
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要查找特定的表格，运行一个简单的循环。我们使用DataFrame的`shape`属性来检查每个DataFrame的行数和列数：
- en: '[PRE29]'
  id: totrans-214
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The output is as follows:'
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE30]'
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: It looks like the second element in this list is the table we are looking for.
  id: totrans-217
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 看起来这个列表中的第二个元素就是我们正在寻找的表格。
- en: 'Extract the second element from the table:'
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从表格中提取第二个元素：
- en: '[PRE31]'
  id: totrans-219
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The output is as follows:'
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 5.20: Output of the data in the second table'
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 5.20：第二张表的数据输出'
- en: '](img/B15780_05_020.jpg)'
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15780_05_020.jpg)'
- en: 'Figure 5.20: Output of the data in the second table'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.20：第二张表的数据输出
- en: As we can observe from the preceding table, data containing the records of the
    Wikipedia page has been read in a table format.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的表格中，我们可以观察到包含维基百科页面记录的数据已以表格格式读取。
- en: Note
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 备注
- en: To access the source code for this specific section, please refer to [https://packt.live/3de6LYw](https://packt.live/3de6LYw).
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参阅 [https://packt.live/3de6LYw](https://packt.live/3de6LYw)。
- en: You can also run this example online at [https://packt.live/2Bk9e6q](https://packt.live/2Bk9e6q).
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以在 [https://packt.live/2Bk9e6q](https://packt.live/2Bk9e6q) 上在线运行此示例。
- en: Reading from a JSON file
  id: totrans-228
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从 JSON 文件读取
- en: Over the last 15 years, JSON has become ubiquitous for data exchange on the
    web. Today, it is the format of choice for almost every publicly available web
    API, and it is frequently used for private web APIs as well. It is a schema-less,
    text-based representation of structured data that is based on key-value pairs
    and ordered lists. The `pandas` library provides excellent support for reading
    data from a JSON file directly into a DataFrame.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去 15 年中，JSON 已经成为网络数据交换的通用格式。如今，它几乎成为所有公开可用的网络 API 的首选格式，并且也常用于私有网络 API。它是一种基于键值对和有序列表的无模式、基于文本的结构化数据表示。`pandas`
    库提供了将数据直接从 JSON 文件读取到 DataFrame 的出色支持。
- en: 'Exercise 5.08: Reading from a JSON File'
  id: totrans-230
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 5.08：从 JSON 文件读取
- en: 'In this exercise, we will read data from the `movies.json` file. This file
    contains the cast, genre, title, and year (of release) information for almost
    all major movies since `1900`. Let''s go through the following steps:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将从 `movies.json` 文件中读取数据。这个文件包含了自 1900 年以来几乎所有主要电影的演员阵容、类型、标题和发行年份信息。让我们按以下步骤进行：
- en: Note
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 备注
- en: The `.json` file could be found at [https://packt.live/3d7DO0l](https://packt.live/3d7DO0l).
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '`.json` 文件可以在 [https://packt.live/3d7DO0l](https://packt.live/3d7DO0l) 找到。'
- en: Extract the list of movies from the file into a DataFrame.
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将文件中的电影列表提取到 DataFrame 中。
- en: '[PRE32]'
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Note
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 备注
- en: Don't forget to change the path (highlighted) of the JSON file based on its
    location on your system.
  id: totrans-237
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 不要忘记根据您系统上的位置更改 JSON 文件的路径（已突出显示）。
- en: 'The output is as follows:'
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 5.21: DataFrame displaying the movie list'
  id: totrans-239
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 5.21：显示电影列表的 DataFrame'
- en: '](img/B15780_05_021.jpg)'
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15780_05_021.jpg)'
- en: 'Figure 5.21: DataFrame displaying the movie list'
  id: totrans-241
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.21：显示电影列表的 DataFrame
- en: 'To look for the cast where the title is `Avengers`, use filtering:'
  id: totrans-242
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要查找标题为“复仇者联盟”的演员阵容，请使用过滤：
- en: '[PRE33]'
  id: totrans-243
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The output will be as follows:'
  id: totrans-244
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '[PRE34]'
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Note
  id: totrans-246
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 备注
- en: To access the source code for this specific section, please refer to [https://packt.live/37ISQJ8](https://packt.live/37ISQJ8).
  id: totrans-247
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参阅 [https://packt.live/37ISQJ8](https://packt.live/37ISQJ8)。
- en: You can also run this example online at [https://packt.live/2YeymVv](https://packt.live/2YeymVv).
  id: totrans-248
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您也可以在 [https://packt.live/2YeymVv](https://packt.live/2YeymVv) 上在线运行此示例。
- en: Reading a PDF File
  id: totrans-249
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 读取 PDF 文件
- en: Among the various types of data sources, the PDF format is probably the most
    difficult to parse in general. While there are some popular packages in Python
    for working with PDF files for general page formatting, the best library to use
    for table extraction from PDF files is `tabula-py`.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 在各种数据源类型中，PDF 格式通常是最难解析的。虽然有一些流行的 Python 包用于处理 PDF 文件的一般页面格式，但用于从 PDF 文件中提取表格的最佳库是
    `tabula-py`。
- en: From the GitHub page of this package, `tabula-py` is a simple Python wrapper
    of `tabula-java`, which can read a table from a PDF. You can read tables from
    PDFs and convert them into `pandas` DataFrames. The `tabula-py` library also enables
    you to convert a PDF file into a CSV/TSV/JSON file.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 从 GitHub 页面来看，`tabula-py` 是 `tabula-java` 的简单 Python 封装，可以从 PDF 中读取表格。您可以从 PDF
    中读取表格并将它们转换为 `pandas` DataFrame。`tabula-py` 库还允许您将 PDF 文件转换为 CSV/TSV/JSON 文件。
- en: Note
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 备注
- en: Make sure you've installed `tabula` based on the instructions detailed in the
    section titled *Libraries to Install for This Chapter*.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 确保您已根据本章标题为“本章需要安装的库”中详细说明的说明安装了 `tabula`。
- en: 'You will also need the following packages installed on your system before you
    can run this, but they are free and easy to install; you can use `pip install`
    to install them from the notebook session as you did in the past:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行此代码之前，您还需要在系统上安装以下包，但它们是免费且易于安装的；您可以使用 `pip install` 从笔记本会话中安装它们，就像您过去所做的那样：
- en: '`urllib3`'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`urllib3`'
- en: '`pandas`'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pandas`'
- en: '`pytest`'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pytest`'
- en: '`flake8`'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`flake8`'
- en: '`distro`'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`distro`'
- en: '`pathlib`'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pathlib`'
- en: 'Exercise 5.09: Reading Tabular Data from a PDF File'
  id: totrans-261
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习5.09：从PDF文件中读取表格数据
- en: In this exercise, we will first read from two different pages of a PDF file
    from [https://packt.live/2Ygj4j7](https://packt.live/2Ygj4j7) in tabular format,
    and then we will perform a few simple operations to handle the headers of these
    files.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们将首先从 [https://packt.live/2Ygj4j7](https://packt.live/2Ygj4j7) 的PDF文件的两个不同页面以表格格式读取，然后我们将执行一些简单的操作来处理这些文件的标题。
- en: Note
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Before proceeding, make sure you've installed `tabula` based on the instructions
    detailed in an earlier section titled *Libraries to Install for This Chapter*.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，请确保您已根据本章早期标题为 *本章需要安装的库* 中详细说明的说明安装了 `tabula`。
- en: 'Let''s go through the following steps to do so:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们按以下步骤进行：
- en: 'The following code retrieves the tables from two pages and joins them to make
    one table:'
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下代码从两页中检索表格并将它们连接成一个表格：
- en: '[PRE35]'
  id: totrans-267
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Note
  id: totrans-268
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: Throughout this exercise, don't forget to change the path (highlighted) of the
    PDF based on its location on your system.
  id: totrans-269
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在整个练习过程中，不要忘记根据您的系统上PDF的位置更改路径（突出显示）。
- en: 'The output is as follows:'
  id: totrans-270
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 5.22: DataFrame with a table derived by merging a table flowing over'
  id: totrans-271
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图5.22：通过合并PDF中跨越的表格得到的DataFrame]'
- en: two pages in a PDF
  id: totrans-272
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: PDF中的两页
- en: '](img/B15780_05_022.jpg)'
  id: totrans-273
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![img/B15780_05_022.jpg]'
- en: 'Figure 5.22: DataFrame with a table derived by merging a table flowing over
    two pages in a PDF'
  id: totrans-274
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图5.22：通过合并PDF中跨越两页的表格得到的DataFrame
- en: 'Retrieve the table from another page of the same PDF by using the following command:'
  id: totrans-275
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令从同一PDF的另一个页面检索表格：
- en: '[PRE36]'
  id: totrans-276
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The output is as follows:'
  id: totrans-277
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 5.23: DataFrame displaying a table from another page'
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图5.23：显示来自另一页面的表格的DataFrame]'
- en: '](img/B15780_05_023.jpg)'
  id: totrans-279
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![img/B15780_05_023.jpg]'
- en: 'Figure 5.23: DataFrame displaying a table from another page'
  id: totrans-280
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图5.23：显示来自另一页面的表格的DataFrame
- en: 'To concatenate the tables that were derived from the first two steps, execute
    the following code:'
  id: totrans-281
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要连接从前两个步骤中得到的表格，执行以下代码：
- en: '[PRE37]'
  id: totrans-282
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'The output is as follows:'
  id: totrans-283
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 5.24: DataFrame derived by concatenating two tables'
  id: totrans-284
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图5.24：通过连接两个表格得到的DataFrame]'
- en: '](img/B15780_05_024.jpg)'
  id: totrans-285
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![img/B15780_05_024.jpg]'
- en: 'Figure 5.24: DataFrame derived by concatenating two tables'
  id: totrans-286
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图5.24：通过连接两个表格得到的DataFrame
- en: With PDF extraction, most of the time, headers will be difficult to extract automatically.
  id: totrans-287
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在PDF提取过程中，大多数情况下，标题将难以自动提取。
- en: 'Pass on the list of headers with the `names` argument in the `read-pdf` function
    set to `pandas_option`, as follows:'
  id: totrans-288
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `read-pdf` 函数中将 `names` 参数设置为 `pandas_option` 以传递列名列表，如下所示：
- en: '[PRE38]'
  id: totrans-289
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'The output is as follows:'
  id: totrans-290
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 5.25: DataFrame with the correct column headers for PDF data'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.25：具有正确列标题的PDF数据DataFrame]'
- en: '](img/B15780_05_025.jpg)'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B15780_05_025.jpg]'
- en: 'Figure 5.25: DataFrame with the correct column headers for PDF data'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.25：具有正确列标题的PDF数据DataFrame
- en: Note
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/2YcHz0v](https://packt.live/2YcHz0v).
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问本节的具体源代码，请参阅 [https://packt.live/2YcHz0v](https://packt.live/2YcHz0v)。
- en: This section does not currently have an online interactive example, and will
    need to be run locally.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 本节目前还没有在线交互示例，需要本地运行。
- en: We will have a full activity on reading tables from a PDF report and processing
    them at the end of this chapter. Let's dive into web page scraping and the library
    used to do that, Beautiful Soup 4\.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本章末尾进行一个完整的活动，即从PDF报告中读取表格并处理它们。让我们深入了解网页抓取以及用于此目的的库Beautiful Soup 4。
- en: Introduction to Beautiful Soup 4 and Web Page Parsing
  id: totrans-298
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Beautiful Soup 4 和网页解析简介
- en: The ability to read and understand web pages is of paramount interest to a person
    collecting and formatting data. For example, consider the task of gathering data
    about movies and then formatting it for a downstream system. Data from movie databases
    is best obtained from websites such as IMDb, and that data does not come pre-packaged
    in nice forms (such as CSV or JSON), so you need to know how to download and read
    a web page.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 对于收集和格式化数据的人来说，阅读和理解网页的能力至关重要。例如，考虑收集关于电影并为其下游系统格式化数据这项任务。从IMDb等网站获取电影数据库的数据最佳，而这些数据并非以良好的形式（如CSV或JSON）预先打包，因此你需要知道如何下载和读取网页。
- en: You also need to be equipped with the knowledge of the structure of a web page
    so that you can design a system that can search for (query) a particular piece
    of information from a whole web page and get the value from it. This involves
    understanding the grammar of markup languages and being able to write something
    that can parse them. Doing this, and keeping all the edge cases in mind, for something
    like HTML is already incredibly complex, and if you extend the scope of the bespoke
    markup language to include XML as well, then it becomes full-time work for a team
    of people.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 你还需要具备网页结构的知识，这样你才能设计一个系统，可以从整个网页中搜索（查询）特定的信息，并从中获取其值。这涉及到理解标记语言的语法，并能够编写可以解析它们的代码。做这件事，同时考虑到所有边缘情况，对于像
    HTML 这样的事情来说已经非常复杂了，如果你将定制标记语言的范围扩展到包括 XML，那么这将成为一个团队的全职工作。
- en: Thankfully, we are using Python, and Python has a very mature and stable library
    that does all the complicated tasks for us. This library is called `BeautifulSoup`
    (it is, at present, in version 4, and thus we will call it `bs4` for short from
    now on). `bs4` is a library for getting data from HTML or XML documents, and it
    gives you a nice, normalized, idiomatic way of navigating and querying a document.
    It does not include a parser but it supports different ones.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，我们正在使用 Python，Python 有一个非常成熟和稳定的库，为我们处理所有复杂的任务。这个库叫做 `BeautifulSoup`（目前处于第
    4 版，因此从现在起我们将简称为 `bs4`）。`bs4` 是一个从 HTML 或 XML 文档中获取数据的库，它为你提供了一种优雅、规范、惯用的方式来导航和查询文档。它不包含解析器，但它支持不同的解析器。
- en: Structure of HTML
  id: totrans-302
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: HTML 的结构
- en: 'Before we jump into `bs4` and start working with it, we need to examine the
    structure of an HTML document. **H**yper **T**ext **M**arkup **L**anguage is a
    structured way of telling web browsers about the organization of a web page, meaning
    which kinds of elements (text, image, video, and so on) come from where, where
    inside the page they should appear, what they look like, what they contain, and
    how they will behave with user input. HTML5 is the latest version of HTML. An
    HTML document can be viewed as a tree, as we can see in the following diagram:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们跳入 `bs4` 并开始使用它之前，我们需要检查 HTML 文档的结构。**超**文本**标记****语言**是一种向网络浏览器说明网页组织结构的方式，意味着哪些类型的元素（文本、图像、视频等）来自哪里，它们在页面内的位置，它们的样式，它们包含的内容，以及它们如何响应用户输入。HTML5
    是 HTML 的最新版本。一个 HTML 文档可以被看作是一棵树，正如我们可以在以下图中看到的那样：
- en: '![Figure 5.26: HTML structure'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.26：HTML 结构'
- en: '](img/B15780_05_026.jpg)'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B15780_05_026.jpg](img/B15780_05_026.jpg)'
- en: 'Figure 5.26: HTML structure'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.26：HTML 结构
- en: Each node of the tree represents one element in the document. An element is
    anything that starts with `<` and ends with `>`. For example, `<html>`, `<head>`,
    `<p>`, `<br>`, `<img>`, and so on are various HTML elements. Some elements have
    a start and end element, where the end element begins with `</` and has the same
    name as the start element, such as `<p>` and `</p>`, and they can contain an arbitrary
    number of elements of other types in them. Some elements do not have an ending
    part, such as the `<br/>` element, and they cannot contain anything within them.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 树的每个节点代表文档中的一个元素。元素是以 `<` 开头并以 `>` 结尾的任何东西。例如，`<html>`、`<head>`、`<p>`、`<br>`、`<img>`
    等都是各种 HTML 元素。一些元素有起始和结束元素，其中结束元素以 `</` 开头，并且与起始元素具有相同的名称，例如 `<p>` 和 `</p>`，它们可以包含任意数量的其他类型的元素。一些元素没有结束部分，例如
    `<br/>` 元素，它们不能包含任何内容。
- en: 'The only other thing that we need to know about an element at this point is
    the fact that elements can have attributes, which are there to modify the default
    behavior of an element. For example, an `<a>` anchor element requires a `href`
    attribute to tell the browser which website it should navigate to when that particular
    `<a>` is clicked, like this: `<a href="http://cnn.com">`. `The CNN news channel`,
    `</a>`, will take you to [cnn.com](http://cnn.com) when clicked:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，我们还需要了解关于元素的其他唯一信息是，元素可以具有属性，这些属性用于修改元素的默认行为。例如，一个 `<a>` 锚点元素需要一个 `href`
    属性来告诉浏览器当点击特定的 `<a>` 时应该导航到哪个网站，如下所示：`<a href="http://cnn.com">`。“CNN 新闻频道”，`</a>`，当点击时会带你到
    [cnn.com](http://cnn.com)：
- en: '![Figure 5.27: CNN news channel hyperlink'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.27：CNN 新闻频道超链接'
- en: '](img/B15780_05_027.jpg)'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B15780_05_027.jpg](img/B15780_05_027.jpg)'
- en: 'Figure 5.27: CNN news channel hyperlink'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.27：CNN 新闻频道的超链接
- en: So, when you are at a particular element of the tree, you can visit all the
    children of that element to get their contents and attributes.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，当你处于树的某个特定元素时，你可以访问该元素的子元素以获取它们的内容和属性。
- en: Equipped with this knowledge, let's see how we can read and query data from
    an HTML document.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 带着这些知识，让我们看看我们如何从HTML文档中读取和查询数据。
- en: In this topic, we will cover the reading and parsing of web pages, but we do
    not request them from a live website. Instead, we read them from disk. A section
    on reading them from the internet will follow in a future chapter.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个主题中，我们将介绍网页的读取和解析，但我们不会从实时网站请求它们。相反，我们从磁盘读取它们。关于从互联网读取它们的章节将在未来的章节中介绍。
- en: 'Exercise 5.10: Reading an HTML File and Extracting Its Contents Using Beautiful
    Soup'
  id: totrans-315
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习5.10：使用Beautiful Soup读取HTML文件并提取其内容
- en: 'In this exercise, we will do the simplest thing possible. We will import the
    `Beautiful Soup` or `bs4` library and then use it to read an HTML document. Then,
    we will examine the different kinds of objects it returns. While doing the exercises
    for this topic, you should have the example HTML file (called `test.html`) open
    in a text editor so that you can check for the different tags and their attributes
    and contents:'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将做最简单的事情。我们将导入`Beautiful Soup`或`bs4`库，然后使用它来读取HTML文档。然后，我们将检查它返回的不同类型的对象。在完成这个主题的练习时，你应该在文本编辑器中打开示例HTML文件（称为`test.html`），以便你可以检查不同的标签及其属性和内容：
- en: 'Import the `bs4` library:'
  id: totrans-317
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`bs4`库：
- en: '[PRE39]'
  id: totrans-318
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Please download the following test HTML file and save it on your disk, and
    then use `bs4` to read it from the disk:'
  id: totrans-319
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 请下载以下测试HTML文件并将其保存到您的磁盘上，然后使用`bs4`从磁盘读取它：
- en: '[PRE40]'
  id: totrans-320
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Print the contents of the file in a nice way, by which we mean that the printing
    will keep some kind of nice indentation by using the `prettify` method from the
    class, like this:'
  id: totrans-321
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用类中的`prettify`方法以美观的方式打印文件内容，这意味着打印将保持某种类型的良好缩进，如下所示：
- en: '[PRE41]'
  id: totrans-322
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'The output is as follows:'
  id: totrans-323
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 5.28: Contents of the HTML file'
  id: totrans-324
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图5.28：HTML文件的内容'
- en: '](img/B15780_05_028.jpg)'
  id: totrans-325
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15780_05_028.jpg)'
- en: 'Figure 5.28: Contents of the HTML file'
  id: totrans-326
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图5.28：HTML文件的内容
- en: 'The same information can also be obtained by using the `soup.contents` member
    variable. The differences are: first, it won''t print anything pretty and, second,
    it is essentially a list.'
  id: totrans-327
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 同样的信息也可以通过使用`soup.contents`成员变量来获取。区别在于：首先，它不会打印出任何美观的内容，其次，它本质上是一个列表。
- en: If we look carefully at the contents of the HTML file in a separate text editor,
    we will see that there are many paragraph tags, or `<p>` tags. Let's read content
    from one such `<p>` tag. We can do that using the simple `.` access modifier as
    we would have done for a normal member variable of a class.
  id: totrans-328
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果我们仔细查看HTML文件的内容（在单独的文本编辑器中），我们会看到有很多段落标签，或`<p>`标签。让我们从一个这样的`<p>`标签中读取内容。我们可以使用简单的`.`访问修饰符来完成，就像我们会对类的普通成员变量做的那样。
- en: The magic of `bs4` is the fact that it gives us this excellent way to dereference
    tags as member variables of the `BeautifulSoup` class instance. In the following
    few steps, we are going to read an HTML file and then pass the file handler returned
    by Python's `open` call directly to the constructor of the `BeautifulSoup` class.
    It does a lot of things (including reading the content and then parsing it) and
    returns an instance of the class that we can then use.
  id: totrans-329
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`bs4`的魔力在于它为我们提供了将标签作为`BeautifulSoup`类实例的成员变量进行解引用的出色方式。在接下来的几个步骤中，我们将读取一个HTML文件，然后将Python的`open`调用返回的文件句柄直接传递给`BeautifulSoup`类的构造函数。它做了很多事情（包括读取内容然后解析），并返回一个类的实例，我们可以使用它。'
- en: 'Read the HTML file:'
  id: totrans-330
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 读取HTML文件：
- en: '[PRE42]'
  id: totrans-331
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Use the `findall` method to extract the content from the tag:'
  id: totrans-332
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`findall`方法从标签中提取内容：
- en: '[PRE43]'
  id: totrans-333
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Now we will see how to get the contents of a particular HTML tag:'
  id: totrans-334
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们将看看如何获取特定HTML标签的内容：
- en: '[PRE44]'
  id: totrans-335
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'The first way is by using the `children` generator from any `bs4` instance,
    as follows:'
  id: totrans-336
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一种方式是通过使用任何`bs4`实例的`children`生成器，如下所示：
- en: '[PRE45]'
  id: totrans-337
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'To do that, we use the `descendants` generator from the `bs4` instance, as follows:'
  id: totrans-338
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要做到这一点，我们使用`bs4`实例的`descendants`生成器，如下所示：
- en: '[PRE46]'
  id: totrans-339
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'The output is as follows:'
  id: totrans-340
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE47]'
  id: totrans-341
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: The comparison print at the end of the code block will show us the difference
    between `children` and `descendants`. The length of the list we got from `children`
    is only `9`, whereas the length of the list we got from `descendants` is `61`.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 代码块末尾的比较打印将显示`children`和`descendants`之间的差异。我们从`children`得到的列表长度仅为`9`，而从`descendants`得到的列表长度为`61`。
- en: Note
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/2N994l6](https://packt.live/2N994l6).
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问本节的具体源代码，请参阅[https://packt.live/2N994l6](https://packt.live/2N994l6)。
- en: You can also run this example online at [https://packt.live/2UT2p2K](https://packt.live/2UT2p2K).
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以在[https://packt.live/2UT2p2K](https://packt.live/2UT2p2K)上在线运行此示例。
- en: So far, we have seen some basic ways to navigate the tags inside an HTML document
    using `bs4`. Now, we are going to go one step further and use the power of `bs4`
    combined with the power of `pandas` to generate a DataFrame out of a plain HTML
    table. With the knowledge we will acquire now, it will be fairly easy for us to
    prepare a `pandas` DataFrame to perform `BeautifulSoup` library.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经看到了使用`bs4`在HTML文档内部导航标签的一些基本方法。现在，我们将更进一步，结合`bs4`的力量和`pandas`的力量，从纯HTML表格生成DataFrame。通过我们现在将获得的知识，我们将能够轻松地准备一个`pandas`
    DataFrame来执行`BeautifulSoup`库。
- en: 'Exercise 5.11: DataFrames and BeautifulSoup'
  id: totrans-347
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习5.11：DataFrame和BeautifulSoup
- en: 'In this exercise, we will extract the data from the `test.html` page using
    the `BeautifulSoup` library. We will then perform a few operations for data preparation
    and display the data in an easily readable tabular format. To do that, let''s
    go through the following steps:'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将使用`BeautifulSoup`库从`test.html`页面中提取数据。然后，我们将进行一些数据准备操作，并以易于阅读的表格格式显示数据。为此，让我们按照以下步骤进行：
- en: 'Import `pandas` and read the document, as follows:'
  id: totrans-349
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照以下方式导入`pandas`并读取文档：
- en: '[PRE48]'
  id: totrans-350
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Check the original table structure in the HTML source. You will see that the
    first row is the column heading and all of the following rows are the data from
    the HTML source. We''ll assign two different variables for the two sections, as
    follows:'
  id: totrans-351
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查HTML源中的原始表格结构。你会看到第一行是列标题，所有随后的行都是HTML源中的数据。我们将为这两个部分分配两个不同的变量，如下所示：
- en: '[PRE49]'
  id: totrans-352
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'The output is as follows:'
  id: totrans-353
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE50]'
  id: totrans-354
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: Note
  id: totrans-355
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: Keep in mind that the art of scraping an HTML page goes hand in hand with an
    understanding of the source HTML structure. So, whenever you want to scrape a
    page, the first thing you need to do is right-click on it and then use `View Source`
    from the browser to see the source HTML.
  id: totrans-356
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 请记住，抓取HTML页面的艺术与理解源HTML结构密不可分。因此，每次你想抓取一个页面时，你首先需要右键点击它，然后从浏览器中使用“查看源代码”来查看源HTML。
- en: 'Once we have separated the two sections, we need two list comprehensions to
    make them ready to go in a DataFrame. For the header, this is easy:'
  id: totrans-357
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦我们分离了这两个部分，我们需要两个列表推导来使它们准备好放入DataFrame中。对于标题，这很简单：
- en: '[PRE51]'
  id: totrans-358
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'The output is as follows:'
  id: totrans-359
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE52]'
  id: totrans-360
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: Data preparation is a bit tricky for a `pandas` DataFrame. You need to have
    a two-dimensional list, which is a list of lists. We accomplish that in the following
    way, using the tricks we learned earlier about list comprehension.
  id: totrans-361
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于`pandas` DataFrame的数据准备来说有点棘手。你需要有一个二维列表，这是一个列表的列表。我们通过以下方式完成它，使用我们之前学到的关于列表推导的技巧。
- en: 'Use the `for…in` loop to iterate over the data:'
  id: totrans-362
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`for…in`循环遍历数据：
- en: '[PRE53]'
  id: totrans-363
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'The output is as follows:'
  id: totrans-364
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 5.32: Output as a two-dimensional list'
  id: totrans-365
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图5.32：以二维列表形式输出'
- en: '](img/B15780_05_032.jpg)'
  id: totrans-366
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片 B15780_05_032.jpg]'
- en: 'Figure 5.32: Output as a two-dimensional list'
  id: totrans-367
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图5.32：以二维列表形式输出
- en: 'Invoke the `pd.DataFrame` method and supply the right arguments by using the
    following code:'
  id: totrans-368
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调用`pd.DataFrame`方法，并使用以下代码提供正确的参数：
- en: '[PRE54]'
  id: totrans-369
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'The output is as follows:'
  id: totrans-370
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 5.33: Output in tabular format with column headers'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.33：带有列头的表格格式输出'
- en: '](img/B15780_05_033.jpg)'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B15780_05_033.jpg]'
- en: 'Figure 5.33: Output in tabular format with column headers'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.33：带有列头的表格格式输出
- en: Thus, we conclude our exercise on creating a data frame from an HTML table.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们得出结论，我们的从HTML表格创建数据框的练习结束。
- en: Note
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/30QyE6A](https://packt.live/30QyE6A).
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参阅[https://packt.live/30QyE6A](https://packt.live/30QyE6A)。
- en: You can also run this example online at [https://packt.live/3hBPFY5](https://packt.live/3hBPFY5).
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以在[https://packt.live/3hBPFY5](https://packt.live/3hBPFY5)上在线运行此示例。
- en: In the following exercise, we'll export a DataFrame as an Excel file.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下练习中，我们将导出DataFrame为Excel文件。
- en: 'Exercise 5.12: Exporting a DataFrame as an Excel File'
  id: totrans-379
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习5.12：将DataFrame导出为Excel文件
- en: In this exercise, we will see how we can save a DataFrame as an Excel file.
    `Pandas` can do this natively, but it needs the help of the `openpyxl` library
    to achieve this goal. `openpyxl` is a Python library for reading/writing Excel
    2010 `xlsx/xlsm/xltx/xltm` files.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将看到如何将DataFrame保存为Excel文件。`Pandas`可以原生地做到这一点，但它需要`openpyxl`库的帮助来实现这一目标。`openpyxl`是一个用于读取/写入Excel
    2010 `xlsx/xlsm/xltx/xltm`文件的Python库。
- en: Note
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: This exercise is continued from the previous exercise. You'll need to continue
    in the same Jupyter Notebook.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 这个练习是从上一个练习继续的。你需要在同一个 Jupyter Notebook 中继续。
- en: 'Let''s perform the following steps:'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们执行以下步骤：
- en: 'Install the `openpyxl` library by using the following command:'
  id: totrans-384
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令安装 `openpyxl` 库：
- en: '[PRE55]'
  id: totrans-385
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'To save the DataFrame as an Excel file, use the following command from inside
    of the Jupyter notebook:'
  id: totrans-386
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要将 DataFrame 保存为 Excel 文件，请在 Jupyter notebook 中使用以下命令：
- en: '[PRE56]'
  id: totrans-387
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: This is the way in which we can export a `pandas` DataFrame to Excel. Given
    that Excel is a very popular format among many types of users, this is a very
    important trick you need to master.
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们可以将 `pandas` DataFrame 导出为 Excel 的方法。鉴于 Excel 在许多类型的用户中都非常受欢迎，这是一个你需要掌握的重要技巧。
- en: Note
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/2YcSdV6](https://packt.live/2YcSdV6).
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参阅 [https://packt.live/2YcSdV6](https://packt.live/2YcSdV6)。
- en: You can also run this example online at [https://packt.live/2YZTXjJ](https://packt.live/2YZTXjJ).
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以在 [https://packt.live/2YZTXjJ](https://packt.live/2YZTXjJ) 上在线运行此示例。
- en: In the previous chapters, when we were discussing the stack, we explained how
    important it is to have a stack that we can push the URLs from a web page to so
    that we can pop them at a later time to follow each of them. The following exercise
    will demonstrate how to do that.
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，当我们讨论栈时，我们解释了拥有一个可以推送网页 URL 到其中以便稍后弹出以跟踪每个 URL 的栈是多么重要。以下练习将演示如何做到这一点。
- en: 'Exercise 5.13: Stacking URLs from a Document Using bs4'
  id: totrans-393
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 5.13：使用 bs4 从文档中堆叠 URL
- en: In this exercise, we will append the URLs one after the other from the `test.html`
    web page. In that file, HTML file links or `<a>` tags are under a `<ul>` tag,
    and each of them is contained inside a `</li>` tag. We are going to find all the
    `<a>` tags and create a stack with them.
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将从 `test.html` 网页依次追加 URL。在该文件中，HTML 文件链接或 `<a>` 标签位于 `<ul>` 标签下，每个都包含在
    `<li>` 标签内。我们将找到所有的 `<a>` 标签并创建一个包含它们的栈。
- en: Note
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: This exercise is continued from the previous exercise. You'll need to continue
    in the same Jupyter Notebook.
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 这个练习是从上一个练习继续的。你需要在同一个 Jupyter Notebook 中继续。
- en: 'To do so, let''s go through the following steps:'
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 要做到这一点，让我们按照以下步骤进行：
- en: 'Find all the `<a>` tags by using the following command:'
  id: totrans-398
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令找到所有的 `<a>` 标签：
- en: '[PRE57]'
  id: totrans-399
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: Note
  id: totrans-400
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: Don't forget to change the path (highlighted) of the HTML file based on its
    location on your system.
  id: totrans-401
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 不要忘记根据其在系统中的位置更改 HTML 文件的路径（已高亮显示）。
- en: 'Define a stack before you start the loop. Then, inside the loop, use the `append`
    method to push the links in the stack:'
  id: totrans-402
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在开始循环之前定义一个栈。然后，在循环内部，使用 `append` 方法将链接推入栈中：
- en: '[PRE58]'
  id: totrans-403
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'Print the stack:'
  id: totrans-404
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印栈：
- en: '[PRE59]'
  id: totrans-405
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'The output is as follows:'
  id: totrans-406
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE60]'
  id: totrans-407
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: Note
  id: totrans-408
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/3hCCAOj](https://packt.live/3hCCAOj).
  id: totrans-409
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参阅 [https://packt.live/3hCCAOj](https://packt.live/3hCCAOj)。
- en: You can also run this example online at [https://packt.live/3fCYNd0](https://packt.live/3fCYNd0).
  id: totrans-410
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你也可以在 [https://packt.live/3fCYNd0](https://packt.live/3fCYNd0) 上在线运行此示例。
- en: Let's put together everything we have learned so far in this chapter and get
    started with an activity.
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将本章到目前为止所学的一切整合起来，并开始一个活动。
- en: 'Activity 5.01: Reading Tabular Data from a Web Page and Creating DataFrames'
  id: totrans-412
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动 5.01：从网页读取表格数据并创建 DataFrame
- en: In this activity, you have been given a Wikipedia page where you have the GDP
    of all countries listed. You have to create three `DataFrames` from the three
    sources mentioned on the page ([https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal](https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal))).
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个活动中，你已经得到了一个包含所有国家 GDP 列表的维基百科页面。你必须从页面上提到的三个来源（[https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal](https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal)））创建三个
    `DataFrame`。
- en: 'You will have to do the following:'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 你必须执行以下操作：
- en: Open the page in a separate Chrome/Firefox tab and use something like an `Inspect
    Element` tool to view the source HTML and understand its structure.
  id: totrans-415
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在单独的 Chrome/Firefox 标签中打开页面，并使用类似“检查元素”的工具查看源 HTML 并了解其结构。
- en: Read the page using `bs4`.
  id: totrans-416
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `bs4` 读取页面。
- en: Find the table structure you will need to deal with (how many tables are there?).
  id: totrans-417
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 找到你将需要处理的表格结构（有多少个表格？）。
- en: Find the right table using `bs4`.
  id: totrans-418
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `bs4` 找到正确的表格。
- en: Separate the source names and their corresponding data.
  id: totrans-419
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将源名称及其对应的数据分开。
- en: Get the source names from the list of sources you have created.
  id: totrans-420
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从你创建的源列表中获取源名称。
- en: Separate the header and data from the data that you separated before for the
    first source only, and then create a DataFrame using that.
  id: totrans-421
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 仅对第一个数据源，将标题和数据从之前分离的数据中分离出来，然后使用这些数据创建一个DataFrame。
- en: Repeat the last task for the other two data sources.
  id: totrans-422
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对其他两个数据源重复最后一个任务。
- en: 'The output should look like this:'
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 输出应该看起来像这样：
- en: '![Figure 5.34: Final output'
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.34：最终输出'
- en: '](img/B15780_05_034.jpg)'
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15780_05_034.jpg)'
- en: 'Figure 5.34: Final output'
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.34：最终输出
- en: Note
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The solution for this activity can be found via [this link](B15780_Solution_Final_RK.xhtml#_idTextAnchor317).
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 本活动的解决方案可以通过[此链接](B15780_Solution_Final_RK.xhtml#_idTextAnchor317)找到。
- en: Summary
  id: totrans-429
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we have looked into several different types of data formats
    and how to work with them. These formats include CSV, PDF, Excel, Plain Text,
    and HTML. HTML documents are the cornerstone of the World Wide Web and, given
    the amount of data that's contained in it, we can easily infer the importance
    of HTML as a data source.
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了多种不同的数据格式以及如何处理它们。这些格式包括CSV、PDF、Excel、纯文本和HTML。HTML文档是万维网的基础，考虑到其中包含的数据量，我们可以轻易推断出HTML作为数据源的重要性。
- en: We learned about `bs4` (`BeautifulSoup 4`), a Python library that gives us Pythonic
    ways to read and query HTML documents. We used bs4 to load an HTML document and
    explored several different ways to navigate the loaded document.
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 我们学习了`bs4`（`BeautifulSoup 4`），这是一个Python库，它为我们提供了以Pythonic方式读取和查询HTML文档的方法。我们使用了bs4来加载一个HTML文档，并探索了多种不同的方法来导航加载的文档。
- en: We also looked at how we can create a `pandas` DataFrame from an HTML document
    (which contains a table). Although there are some built-in ways to do this job
    in `pandas`, they fail as soon as the target table is encoded inside a complex
    hierarchy of elements. So, the knowledge we gathered in this topic to transform
    an HTML table into a `pandas` DataFrame in a step-by-step manner is invaluable.
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还探讨了如何从HTML文档（包含表格）创建一个`pandas` DataFrame。尽管`pandas`中有一些内置的方法来完成这项工作，但一旦目标表格被编码在一个复杂的元素层次结构中，它们就会失败。因此，我们在本主题中积累的知识，即逐步将HTML表格转换为`pandas`
    DataFrame，是无价的。
- en: Finally, we looked at how we can create a stack in our code, where we push all
    the URLs that we encounter while reading the HTML file and then use them at a
    later time. In the next chapter, we will discuss list comprehensions, the `.zip`
    format, and outlier detection and cleaning.
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们探讨了如何在代码中创建一个栈，将我们在读取HTML文件时遇到的全部URL推入栈中，然后在稍后使用它们。在下一章中，我们将讨论列表推导式、`.zip`格式以及异常值检测和清理。
