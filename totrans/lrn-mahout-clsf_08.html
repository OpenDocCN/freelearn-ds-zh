<html><head></head><body><div class="chapter" title="Chapter&#xA0;8.&#xA0;Mahout Changes in the Upcoming Release"><div class="titlepage"><div><div><h1 class="title"><a id="ch08"/>Chapter 8. Mahout Changes in the Upcoming Release</h1></div></div></div><p>Mahout is a community-driven project and its community is very strong. This community decided on some of the major changes in the upcoming 1.0 release. In this chapter, we will explore the upcoming changes and developments in Apache Mahout. We will look at the following topics in brief:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">New changes due in Mahout 1.0</li><li class="listitem" style="list-style-type: disc">Apache Spark</li><li class="listitem" style="list-style-type: disc">H20-platform-related work in Apache Mahout</li></ul></div><div class="section" title="Mahout new changes"><div class="titlepage"><div><div><h1 class="title"><a id="ch08lvl1sec38"/>Mahout new changes</h1></div></div></div><p>Mahout was <a id="id300" class="indexterm"/>using the map reduce programming model to handle large datasets. From the end of April 2014, the community decided to stop the implementation of the new map reduce algorithm. This decision has a valid reason. Mahout's codebase will be moving to modern data processing systems that offer a richer programming model and more efficient execution than Hadoop's MapReduce.</p><p>Mahout <a id="id301" class="indexterm"/>has started its implementation on the top of <span class="strong"><strong>Domain Specific Language</strong></span> (<span class="strong"><strong>DSL</strong></span>) for linear algebraic operations. Programs written in this DSL are automatically optimized and executed in parallel on Apache Spark. Scala DSL and algebraic optimizer is Scala and Spark binding for Mahout.</p><div class="section" title="Mahout Scala and Spark bindings"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec23"/>Mahout Scala and Spark bindings</h2></div></div></div><p>With Mahout <a id="id302" class="indexterm"/>Scala bindings and Mahout Spark bindings for linear algebra <a id="id303" class="indexterm"/>subroutines, developers in Mahout are trying to <a id="id304" class="indexterm"/>bring semantic explicitness to Mahout's in-core and <a id="id305" class="indexterm"/>out-of-core linear algebra subroutines. They are doing this while adding the benefits of the strong programming environment of Scala and capitalizing on scalability benefits of Spark and GraphX. Scala binding is used to provide support for Scala DSL, and this will make writing machine learning programs easier.</p><p>Mahout Scala and Spark bindings are packages that aim to provide an R-like look and feel to Mahout's in-core and out-of-core Spark-backed linear algebra. An important part of Spark bindings is the <a id="id306" class="indexterm"/>expression optimizer. This optimizer looks at the <a id="id307" class="indexterm"/>entire expression and decides on how it can be simplified and which physical operators should be picked. A high-level <a id="id308" class="indexterm"/>diagram <a id="id309" class="indexterm"/>of the binding stack <a id="id310" class="indexterm"/>is shown in the following figure (<a class="ulink" href="https://issues.apache.org/jira/secure/attachment/12638098/BindingsStack.jpg">https://issues.apache.org/jira/secure/attachment/12638098/BindingsStack.jpg</a>):</p><div class="mediaobject"><img src="graphics/4959OS_08_01.jpg" alt="Mahout Scala and Spark bindings"/></div><p>The Spark binding shell has also been implemented in Mahout 1.0. Let's understand the Apache Spark project first and then we will revisit the Spark binding shell in Mahout.</p></div></div></div>
<div class="section" title="Apache Spark"><div class="titlepage"><div><div><h1 class="title"><a id="ch08lvl1sec39"/>Apache Spark</h1></div></div></div><p>Apache Spark is an <a id="id311" class="indexterm"/>open source, in-memory, general-purpose computing system. Spark's in-memory technique provides performance that is 100 times faster. Instead of Hadoop-like disk-based computation, Spark uses cluster memory to upload all the data into the memory, and this data can be queried repeatedly.</p><p>Apache Spark provides high-level APIs in Java, Python, and Scala and an optimized engine that supports general execution graphs. It provides the following high-level tools:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Spark SQL</strong></span>: This <a id="id312" class="indexterm"/>is for SQL and structured <a id="id313" class="indexterm"/>data processing.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>MLib</strong></span>: This is <a id="id314" class="indexterm"/>Spark's scalable machine learning library <a id="id315" class="indexterm"/>that consists of common learning algorithms and utilities, including classification, regression, clustering, collaborative filtering, dimensionality reduction, as well as the underlying optimization primitives.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>GraphX</strong></span>: This is <a id="id316" class="indexterm"/>the new Spark API for graphs and <a id="id317" class="indexterm"/>graph-parallel computation.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Spark streaming</strong></span>: This <a id="id318" class="indexterm"/>can collect data from many sources and after processing this data, it uses complex algorithms and <a id="id319" class="indexterm"/>can push the data to filesystems, databases, and live dashboards.</li></ul></div><p>As Spark is gaining popularity among data scientists, the Mahout community is also quickly working on making Mahout algorithms function on Spark's execution engine to speed up its calculation 10 to 100 times faster. Mahout provides several important building blocks to <a id="id320" class="indexterm"/>create recommendations using Spark. Spark-item similarity can be used to create <span class="emphasis"><em>other people also liked these things</em></span> kind of recommendations and when paired with a search engine can personalize recommendations for individual users. Spark-row similarity can provide non-personalized content based <a id="id321" class="indexterm"/>on recommendations and when paired with a search engine can be used to personalize content based on recommendations (<a class="ulink" href="http://comments.gmane.org/gmane.comp.apache.mahout.scm/6513">http://comments.gmane.org/gmane.comp.apache.mahout.scm/6513</a>).</p><div class="section" title="Using Mahout's Spark shell"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec24"/>Using Mahout's Spark shell</h2></div></div></div><p>You can use <a id="id322" class="indexterm"/>Mahout's Spark shell by referring to the following steps:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Download <a id="id323" class="indexterm"/>Spark from <a class="ulink" href="http://spark.apache.org/downloads.html">http://spark.apache.org/downloads.html</a>.</li><li class="listitem">Create a new <a id="id324" class="indexterm"/>folder with the name <code class="literal">spark</code> using the following command and move the downloaded file there:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>mkdir /tmp/spark</strong></span>
<span class="strong"><strong>mv ~/Downloads/spark-1.1.1.tgz/tmp/spark</strong></span>
</pre></div></li><li class="listitem">Unpack the archived file in a folder using the following command:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>cd /tmp/spark</strong></span>
<span class="strong"><strong>tar xzf spark-1.1.1.tgz</strong></span>
</pre></div></li><li class="listitem">This will unzip the file <code class="literal">under/tmp/spark/spark-1.1.1</code>. Now, move to the newly created folder and run the following command:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>cd /spark-1.1.1</strong></span>
<span class="strong"><strong>sbt/sbt assembly</strong></span>
</pre></div><p>This <a id="id325" class="indexterm"/>will build Spark on your system as <a id="id326" class="indexterm"/>shown in the following screenshot:</p><div class="mediaobject"><img src="graphics/4959OS_08_02.jpg" alt="Using Mahout's Spark shell"/></div></li><li class="listitem">Now create a Mahout directory and move the file to it using the following command:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>mkdir /tmp/Mahout</strong></span>
</pre></div></li><li class="listitem">Check out the master branch of Mahout from GitHub using the following command:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>git clone https://github.com/apache/mahout mahout</strong></span>
</pre></div><p>The output of the preceding command is shown in the following screenshot:</p><div class="mediaobject"><img src="graphics/4959OS_08_03.jpg" alt="Using Mahout's Spark shell"/></div></li><li class="listitem">Change your directory to the newly created Mahout directory and build Mahout:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>cd mahout</strong></span>
<span class="strong"><strong>mvn -DskipTests clean install</strong></span>
</pre></div><p>The <a id="id327" class="indexterm"/>output of the preceding command is <a id="id328" class="indexterm"/>shown in the following screenshot:</p><div class="mediaobject"><img src="graphics/4959OS_08_04.jpg" alt="Using Mahout's Spark shell"/></div></li><li class="listitem">Move to the directory where you unpacked Spark and type the following command to start Spark locally:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>cd /tmp/spark/spark-1.1.1</strong></span>
<span class="strong"><strong>sbin/start-all-sh</strong></span>
</pre></div><p>The output of the preceding command is shown in the following screenshot:</p><div class="mediaobject"><img src="graphics/4959OS_08_05.jpg" alt="Using Mahout's Spark shell"/></div></li><li class="listitem">Open a browser; point it to <code class="literal">http://localhost:8080/</code> to check whether Spark has successfully started. Copy the URL of the Spark master at the top of the page (it starts with <code class="literal">spark://</code>).</li><li class="listitem">Define the <a id="id329" class="indexterm"/>following environment variables:<div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>export MAHOUT_HOME=[directory into which you checked out Mahout]</strong></span>
<span class="strong"><strong>export SPARK_HOME=[directory where you unpacked Spark]</strong></span>
<span class="strong"><strong>export MASTER=[url of the Spark master]</strong></span>
</pre></div></li><li class="listitem">Finally, change to the directory where you unpacked Mahout and type <code class="literal">bin/mahout spark-shell</code>; you should see the shell starting and get the <code class="literal">mahout&gt;</code> prompt.</li></ol></div><p>Now your Mahout Spark <a id="id330" class="indexterm"/>shell is ready and you can start playing with data. For more <a id="id331" class="indexterm"/>information on this topic, see the implementation section at <a class="ulink" href="https://mahout.apache.org/users/sparkbindings/play-with-shell.html">https://mahout.apache.org/users/sparkbindings/play-with-shell.html</a>.</p></div></div>
<div class="section" title="H2O platform integration"><div class="titlepage"><div><div><h1 class="title"><a id="ch08lvl1sec40"/>H2O platform integration</h1></div></div></div><p>As discussed <a id="id332" class="indexterm"/>earlier, an experimental work to integrate Mahout <a id="id333" class="indexterm"/>and the H2O platform is also in progress. The integration provides an H2O backend to the Mahout algebra DSL.</p><p>H2O makes Hadoop do math! H2O scales statistics, machine learning, and math over big data. It is extensible and users can build blocks using simple math legos in the core. H2O keeps familiar interfaces such as R, Excel, and JSON so that big data enthusiasts and experts can explore, munge, model, and score datasets using a range of simple-to-advanced algorithms. Data collection is easy, while decision making is hard. H2O makes it fast and easy to derive insights from your data through faster and better predictive modeling. It also has a <a id="id334" class="indexterm"/>vision of online scoring and modeling in a single platform (<a class="ulink" href="http://0xdata.com/download/">http://0xdata.com/download/</a>).</p><p>H2O is fundamentally a peer-to-peer system. H2O nodes join together to form a cloud on which high-performance distributed math can be executed. Each node joins a cloud of a given name. Multiple clouds can exist on the same network at the same time as long as their names are different. Multiple nodes can exist on the same server as well (they can even belong to the same cloud).</p><p>The Mahout H2O <a id="id335" class="indexterm"/>integration is fit into this model by having N-1 worker nodes and one driver node, all belonging to the same cloud name. The default cloud name <a id="id336" class="indexterm"/>used for the integration is <code class="literal">mah2out</code>. Clouds have to be spun up as per their task/job.</p><p>More details can be found at <a class="ulink" href="https://issues.apache.org/jira/browse/MAHOUT-1500">https://issues.apache.org/jira/browse/MAHOUT-1500</a>.</p></div>
<div class="section" title="Summary"><div class="titlepage"><div><div><h1 class="title"><a id="ch08lvl1sec41"/>Summary</h1></div></div></div><p>In this chapter, we discussed the upcoming release of Mahout 1.0, and the changes that are currently going on. We also glanced through Spark, Scala binding, and Apache Spark. We also discussed a high-level overview of H2O Mahout integration.</p><p>Now let's move on to the final chapter of this book where we will develop a production-ready classifier.</p></div></body></html>