# 第六章。减少 RAM 使用量的简单调整

到目前为止，我们已经学习了克服 CPU 限制并提高 R 程序速度的技术。如您从 第一章 回忆的那样，*理解 R 的性能 – 为什么 R 程序有时运行缓慢？* 另一个 R 的关键约束是内存。R 程序执行任务所需的所有数据都必须加载到计算机的内存或 RAM 中。RAM 也用于任何中间计算，因此处理给定数据集所需的 RAM 量可能是数据集大小的多倍，这取决于正在执行的任务或算法的类型。当需要处理大型数据集或可用 RAM 很少时，这可能会成为一个问题。

在本章和下一章中，我们将学习如何优化 R 程序的 RAM 利用率，以便成功执行内存密集型任务。

本章涵盖了：

+   重复使用对象而不占用更多内存

+   当不再需要时删除中间数据

+   在线计算值而不是持久存储它们

+   交换活跃和非活跃数据

# 重复使用对象而不占用更多内存

第一个调整利用了 R 如何使用 **copy-on-modification** 模型来管理对象的内存。在这个模型中，当创建一个对象 `x` 的副本时，例如使用 `y <- x`，实际上在内存中并没有进行复制。相反，新变量 `y` 简单地指向包含 `x` 的同一块内存。当 `y` 第一次被修改时，R 会将数据复制到一个新的内存块中，这样 `x` 和 `y` 就有了它们自己的数据副本。这就是为什么这种内存管理模型被称为 copy-on-modification。这意味着有时可以从现有对象中创建新对象，而无需占用额外的内存。为了识别潜在的内存瓶颈并管理 R 程序的内存利用率，了解 R 在何时复制数据以及何时不复制数据是有帮助的。

以以下代码为例，它生成一个包含 100 万个元素的数值向量 `x` 并创建一个包含 `x` 两个副本的列表 `y`。我们可以使用 `object.size()` 函数检查对象的大小：

```py
x <- runif(1e6)
print(object.size(x), units = "auto")
## 7.6 Mb
y <- list(x, x)
print(object.size(y), units = "auto")
## 15.3 Mb
```

乍一看，似乎有两个对象：`x`，它占用了 7.6 MB 的内存，而 `y`，它占用了 15.3 MB。然而，内存利用率可以通过不同的方式来衡量，并且结果令人惊讶：

```py
library(pryr)
object_size(x)
## 8 MB
object_size(y)
## 8 MB
```

来自 CRAN 包 `pryr` 的 `object_size()` 函数比基础 R 的 `object.size()` 函数稍微不同且更准确地测量了 `x` 和 `y` 的大小。它报告说 `y`，包含两个数值向量，只占用了 8 MB 的内存——与 `x` 相同，`x` 是一个长度相同的单个数值向量。这怎么可能呢？来自 `pryr` 包的 `address()` 函数揭示了每个对象指向的实际内存块：

```py
address(x)
## [1] "0x10f992000"
address(y)
## [1] "0x7ff18b30e478"
address(y[[1]])
## [1] "0x10f992000"
address(y[[2]])
## [1] "0x10f992000"
```

如预期，列表 `y` 指向的内存位置与数值向量 `x` 不同，表明它是一个不同的对象。但是，`y` 的两个元素在内存中指向原始对象 `x`。R 在不必要的情况下不会复制对象。在这种情况下，它只是在 `y` 中创建了两个指向 `x` 的指针。这种方式非常高效，实际上，`x` 和 `y` 合并在一起只占用 8 MB，这是 `x` 的大小！

```py
object_size(x, y)
## 8 MB
```

### 注意

实际上，需要一点额外的内存来存储 `y` 和它对 `x` 的指针，但这可以忽略不计，并且不会出现在这个测量中。

当 `y` 中的某个向量被修改时，R 会创建一个新的副本，因为这个向量现在与 `x` 不同：

```py
y[[1]][1] <- 0
address(x)
## [1] "0x10f992000"
address(y[[1]])
## [1] "0x110134000"
address(y[[2]])
## [1] "0x10f992000"
object_size(y)
## 16 MB
object_size(x, y)
## 16 MB
```

`y[[1]]` 向量现在指向内存中与 `x` 和 `y[[2]]` 不同的向量。因此，`y` 占用 16 MB 的 RAM，而 `x` 和 `y` 合并在一起仍然只占用 16 MB（因为 `y[[2]]` 仍然指向 `x`）。另一种跟踪这个情况的方法是在对象被复制到使用 `tracemem()` 时，它会随时给出警告，表明正在跟踪的对象被复制。看看当 `y[[2]]` 被修改时会发生什么：

```py
tracemem(y[[2]])
## [1] "<0x10f992000>"
y[[2]][1] <- 0
## tracemem[0x10f992000 -> 0x1108d6000]: 
untracemem(y[[2]])
```

`tracemem[0x10f992000 -> 0x1108d6000]` 这一行表示在修改向量 `y[[2]]` 时创建了一个副本，并给出了新副本的内存地址。现在，`x`、`y[[1]]` 和 `y[[2]]` 在内存中是不同的对象，因此 `x` 和 `y` 所使用的总内存为 24 MB：

```py
address(x)
## [1] "0x10f992000"
address(y[[1]])
## [1] "0x110134000"
address(y[[2]])
## [1] "0x1108d6000"
object_size(y)
## 16 MB
object_size(x, y)
## 24 MB
```

当修改 `y` 的一个元素时，需要创建 `x` 的副本以确保原始对象 `x` 保持不变。否则，修改一个对象可能会无意中修改另一个对象，导致程序中可能出现难以发现的错误。

R 判断一个对象是否应该被复制的方式是通过跟踪是否有其他对象引用它。当 `y` 被创建时，R 知道 `x` 正在别处被使用，并且在修改时需要创建一个副本。

### 注意

R 只计算到两个引用，这对于它判断是否复制对象是足够的。只要两个或更多变量引用同一个对象，R 在修改时会复制它。

现在，当我们第一次修改 `x` 时，R 会创建它的一个副本，因为 `x` 之前已经被 `y` 引用。尽管 `y` 现在有自己的数据副本，但 R 为了谨慎起见，仍然创建 `x` 的副本以避免潜在的冲突。然而，随后的对 `x` 的修改不会导致不必要的复制，因为新的 `x` 副本没有在其他地方使用，正如这个例子所示：

```py
tracemem(x)
## [1] "<0x10f992000>"
x[1]<- 1
## tracemem[0x10f992000 -> 0x111078000]: 
x[1]<- 1
x[1]<- 0.5
x[2] <- 0.3
untracemem(x)
```

通常，只要一个向量没有被其他任何对象引用，R 允许它原地修改，从而避免复制向量的 CPU 和 RAM 开销。

### 注意

这个例子在 RStudio 中不起作用：

```py
tracemem(x)
## [1] "<0x10e73c000>"
x[1] <- 0
## tracemem[0x10e73c000 -> 0x110d66000]: 
x[2] <- 1
## tracemem[0x110d66000 -> 0x115478000]: 
x[3] <- 0.5
## tracemem[0x115478000 -> 0x115c79000]: 
untracemem(x)
```

这是因为 RStudio 在其自己的环境中保留每个对象的引用，所以 R 认为在别处有对 `x` 的引用。每次修改时，它都会创建 `x` 的一个副本以确保安全。

现在我们已经了解了 R 何时复制数据，我们可以优化 R 程序以避免不必要地复制数据。例如，假设我们有两个包含一百万客户年龄和性别的向量：

```py
customer.age <- sample(18:100, 1e6, replace=TRUE)
customer.gender <- sample(c("Male", "Female"), 1e6, TRUE)
```

零售商使用"`cust #"`作为客户 ID。我们希望为每个向量标记客户 ID，这样我们就可以通过客户 ID 轻松查找信息，使用像`customer.age["cust 1"]`这样的表达式。一种方法是为每个向量单独构造名称。然后，这两个向量组合将占用 84 MB 的内存：

```py
names(customer.age) <- paste("cust", 1:1e6)
names(customer.gender) <- paste("cust", 1:1e6)
object_size(customer.age, customer.gender)
## 84 MB
```

或者，名称可以存储在一个单独的向量中，年龄和性别向量随后可以引用：

```py
customer.names <- paste("cust", 1:1e6)
names(customer.age) <- customer.names
names(customer.gender) <- customer.names
object_size(customer.age, customer.gender, customer.names)
## 76 MB
```

这个简单的更改节省了 8 MB 的内存。在更大的、更复杂的数据结构上，这些从避免不必要地复制数据中节省下来的内存可以非常显著。

相同的按修改复制行为也适用于函数参数。当一个对象传递给函数时，它不会被复制；R 只是提供了一个指向该对象的指针。然而，如果对象在函数内部被修改，R 会在函数的环境中创建该对象的副本，以确保原始对象在函数外部不会被以任何方式修改。在编程语言术语中，这被称为**按值传递**，因为函数被赋予了它们的参数值。这是 R 作为*函数式编程语言*设计的一部分。与此相对的是**按引用传递**，这在其他编程语言中有时被使用，例如 Java 和 C/C++，在这些语言中，函数可以接收对内存地址的引用或指针。在这种情况下，函数可以修改它们的参数，而无需在内存中创建额外的副本，并且修改在函数退出后仍然持续。

R 函数按值传递模型的一个后果是，许多函数需要复制它们接收到的数据。例如，调用`sort(x)`返回一个包含`x`排序值的新的向量，而不是就地排序值（这在 Java 和 C/C++中通常是做法）。调用像`sort()`这样的函数通常需要额外的内存，至少与原始数据一样大，有时更大。

# 当不再需要中间数据时移除它

在大型 R 程序中，对象通常在多个地方创建。通常，在程序早期部分创建的对象在程序的后期部分不再需要。当面临内存限制时，释放不再需要的对象占用的内存是有用的，这样程序的后续部分可以成功运行。

用于此的主要工具是`rm()`函数，它从当前 R 环境中移除给定列表的对象。

在下面的示例中，我们有一个包含来自零售店的 50 万个交易的 DataFrame 以及每个交易中的商品。DataFrame 的每一行代表在销售数据库中发生的唯一交易项对。尽管我们不得不在真实业务环境中生成这个示例的数据，但这些数据可以从零售商的销售数据库中提取：

```py
trans.lengths <- rpois(5e5, 3) + 1L
trans <- rep.int(1:5e5, trans.lengths)
items <- unlist(lapply(trans.lengths, sample.int, n = 1000))
sales.data <- data.frame(trans = trans, item = items)
```

数据看起来像这样，例如，前九行表明交易 1 包含商品 680、846、196 等（你生成数据可能看起来不同）：

```py
head(sales.data, 15)
##    trans item
## 1      1  680
## 2      1  846
## 3      1  196
## 4      1  191
## 5      1   20
## 6      1  852
## 7      1  623
## 8      1  206
## 9      1  775
## 10     2  624
## 11     2   31
## 12     2  718
## 13     2  190
## 14     3  482
## 15     3  946
```

我们的任务是找到常见的商品篮子，即在同一交易中频繁一起出现的商品，或者频繁项集。`arules` CRAN 包中的`apriori()`函数可以用来找到这些频繁项集。但它不接受从销售数据库中提取的交易项对形式的数据。相反，`arules`定义了它接受的输入`transactions`类。我们需要将数据框的商品列拆分为不同的交易，然后将生成的列表强制转换为`transactions`对象：

```py
library(arules)
trans.list <- split(sales.data$item, sales.data$trans)
trans.arules <- as(trans.list, "transactions")
```

我们现在可以调用`apriori()`函数来找到频繁项集。在这个例子中，我们想要支持度至少为 0.3 的项集，即至少在 30%的交易中出现的商品集合。

```py
freq.itemsets <- apriori(trans.arules, list(support = 0.3))
```

当我们从交易项对的数据框开始时，我们必须将其转换为几种不同的格式，然后数据才能被`apriori()`使用。这些中间数据结构都占用了宝贵的内存：

```py
object_size(sales.data)
## 16 MB
object_size(trans.list)
## 62.1 MB
object_size(trans.arules)
## 44 MB
```

当数据集很大或内存不足时，`apriori()`可能会因为内存不足而无法执行。在这种情况下，可以在调用`apriori()`之前或甚至在每个数据转换步骤之间使用`rm()`来释放内存，通过删除不需要的对象。以下代码说明了这一点：

```py
trans.list <- split(sales.data$item, sales.data$trans)
rm(sales.data)
trans.arules <- as(trans.list, "transactions")
rm(trans.list)
freq.itemsets <- apriori(trans.arules, list(support = 0.3))
```

自动删除临时变量的另一种技术是将代码封装在函数中。这样，在函数中创建的任何变量在函数结束时都会自动删除。例如，如果我们只需要在调用`apriori()`之前删除临时变量，因为那时代码往往会遇到内存限制。我们可以将所有之前的代码行封装在一个函数中：

```py
# Automatically remove temporary variables by encapsulating code
# in a function
prepare_data <- function(sales.data) {
    trans.list <- split(sales.data$item, sales.data$trans)
    trans.arules <- as(trans.list, "transactions")
    return(trans.arules)
}
trans.arules <- prepare_data(sales.data)
freq.itemsets <- apriori(trans.arules, list(support = 0.3))
```

在调用`prepare_data()`之后，不需要显式调用`rm()`，其中的任何临时变量都会被删除。在这种情况下，只有一个临时变量`trans.list`被删除。但同样的技术也可以在函数中声明更多临时变量时使用。这种方法不仅方便删除临时变量，而且使代码更易于阅读和维护。

在大型 R 程序中，定期删除大型数据结构可以帮助最小化整体内存使用。当调用 `rm()` 时，内存可能不会立即释放并返回给操作系统。相反，R 的 **垃圾回收器**会在需要时自动释放内存，或者当从移除的对象中释放的内存量超过阈值时。

# 在线计算值而不是持久存储

在执行 R 程序时，有时方便将程序所需的所有数据，包括中间计算结果，在执行前缓存到 RAM 中。在执行过程中，当程序需要访问数据的任何部分时，由于所有数据都已加载到 R 工作空间中，因此可以非常快速地进行。在 RAM 中缓存中间结果可以显著节省计算时间，尤其是在频繁访问时，因为避免了数据的重复计算。

当缓存的数据可以适应 RAM 时，这不是问题。然而，当没有足够的内存空间来容纳数据时，它就变成了问题。好消息是，在许多情况下，程序不需要同时访问数据的所有部分。一种解决方案是在 RAM 和硬盘之间交换数据的部分。因为磁盘 I/O 很慢，正如我们在第一章中确立的，*理解 R 的性能 – 为什么 R 程序有时运行缓慢？*，这种方法可能会导致执行缓慢。更好的解决方案是计算和重新计算当前需要的部分数据。是的，计算需要计算时间，但通常比磁盘 I/O 成本低。

让我们从一个数据科学中常见的任务举例：层次聚类。在一些常用的层次聚类变体中，例如单链接、完全链接和平均链接，算法中的一个重要步骤是计算数据集中每对观测值之间的距离矩阵，然后决定哪一对观测值彼此最接近。这一步骤可以通过以下代码实现，其中我们人为地创建了一个随机数据集 `A`，包含 10,000 个观测值（行）和 10 个特征（列）。代码首先计算 `A` 的距离矩阵，将距离矩阵的对角线元素设置为 `NA`，因为观测值总是最接近自身的，最后使用 `which()` 函数找到最近的观测值对。在这个例子中，发现观测值 6778 和 6737 是最近的一对。要执行此程序，大约需要 801 MB 的 RAM，如下代码中 `object_size()` 的输出所示。这是因为尽管数据集只占用 800 KB，但其距离矩阵需要大约原空间的平方量，因为它存储了所有成对距离：

```py
A <- matrix(rnorm(1E5), 1E4, 10)
dist_mat <- as.matrix(dist(A))
diag(dist_mat) <- NA
res1 <- which(dist_mat == min(dist_mat, na.rm=T), arr.ind = T)[1,]
res1
##  row  col 
## 6778 6737 
object_size(A)
## 800 kB
object_size(dist_mat)
## 801 MB
```

仔细观察后，我们实际上并不需要一次性获取整个距离矩阵来找到最近的一对。可以计算第一个观测值与剩余观测值之间的成对距离，以获取该集合的最小对；对第二个观测值重复此过程，然后比较两个集合的最小值，依此类推。这样做会带来额外的步骤，因此计算时间会更长，但与前面的代码相比，它只需要占用很小一部分 RAM（因为一次只维护距离矩阵的一小部分）。下面的代码展示了如何执行此操作。它首先使用 `pdist` 包计算 `A` 中所有观测值与观测值 1 之间的距离，然后只为此块找到并保存最近的对到临时列表 `output`。使用 `lapply` 对 `A` 中的观测值 2、3、…、10,000 重复此过程。每个块的最接近对集合存储在 `temp_res` 列表中。最后一步是找到这个集合中的最小对并将其存储在变量 `res2` 中。评估 `res2` 的输出会显示与前面代码找到的结果相同。然而，这次我们只需要 `temp_res` 列表占用 2.7 MB 的内存。

```py
library(pdist)
temp_res <- lapply(1:nrow(A), function(x) {
  temp <- as.matrix(pdist(X = A, Y = A[x,]));
  temp[x] <- NA;
  output_val <- min(temp, na.rm=T);
  output_ind <- c(x, which(temp == output_val));
  output <- list(val = output_val, ind = output_ind);
})
val_vec <- sapply(temp_res, FUN=function(x) x$val)
ind_vec <- sapply(temp_res, FUN=function(x) x$ind)
res2 <- ind_vec[, which.min(val_vec)]
res2
## [1] 6778 6737
object_size(temp_res)
## 2.72 MB
object_size(val_vec)
## 80 kB
object_size(ind_vec)
## 80.2 kB
```

确实，第二种方法所需的时间更长。我们可以通过并行化代码来加快速度，例如，用 `parallel` 包中的 `parLApply()` 替换 `lapply()`（参见第八章 Multiplying Performance with Parallel Computing，*使用并行计算提高性能*）。在实践中，对于寻找最接近的一对观测值且不存储完整距离矩阵的特定情况，我们可以利用优化的 k 近邻函数，如 `FNN` 包中的 `knn()` 函数。如果这样的替代优化包不可用，那么像前面代码中所示的计算即时值的做法对于减少内存使用是有用的。

# 交换活跃和非活跃数据

在某些情况下，为了在程序中稍后使用而移除以释放内存的大对象是必需的。R 提供了将数据保存到磁盘并在有足够内存时稍后重新加载的工具。回到零售销售数据示例，假设我们在挖掘频繁项集之后需要 `sales.data` 数据框进行进一步处理。我们可以使用 `saveRDS()` 将其保存到磁盘，然后使用 `readRDS()` 在稍后重新加载：

```py
trans.list <- split(sales.data$item, sales.data$trans)
saveRDS(sales.data, "sales.data.rds")
rm(sales.data)
trans.arules <- as(trans.list, "transactions")
rm(trans.list)
freq.itemsets <- apriori(trans.arules, list(support = 0.3))
sales.data <- readRDS("sales.data.rds")
# Perform further processing with sales.data
```

`saveRDS()` 和 `readRDS()` 函数每次保存一个对象，而不保存对象名称。例如，名称 `sales.data` 不会被保存。然而，列名称 `trans` 和 `items` 被保存。作为替代，可以使用 `save()` 和 `load()` 函数来处理多个对象，甚至是一个环境中所有对象及其变量名称。

# 摘要

在本章中，我们学习了 R 内存管理的修改时复制语义。对这一机制的良好理解使我们能够找到减少 R 程序内存消耗的机会。

我们还看到了如何在不必要时从环境中移除临时变量和中间计算，以释放内存供后续计算使用。除了显式地移除临时变量外，我们还学习了两种自动管理临时变量的方法。首先，即时计算在内存中不创建持久变量的情况下产生中间数据。其次，函数是分组相关操作的有用方式，当退出函数时可以自动移除临时变量。

最后，我们看到了如何将数据保存到磁盘上以释放内存，并在需要时重新加载它们。

在下一章中，我们将探讨更多高级技术，以优化内存消耗，并允许 R 程序处理更大的数据集，甚至那些太大而无法装入内存的数据。
