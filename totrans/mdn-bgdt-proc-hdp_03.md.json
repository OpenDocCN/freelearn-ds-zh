["```py\nJava -version\nJava(TM) SE Runtime Environment (build 1.8.0_144-b01)\nJava HotSpot(TM) 64-Bit Server VM (build 25.144-b01, mixed mode)\nYou need to have Java 1.6 onwards \n```", "```py\nuseradd hadoop\npasswd hadoop1 \n```", "```py\nvi /etc/hosts--   \n```", "```py\nNameNode 192.168.11.1\nDataNode1 192.168.11.2\nDataNode2 192.168.11.3\nDataNode3 192.168.11.4 \n```", "```py\nsu - hadoop\nssh-keygen -t rsa\nssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@namenode\nssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@datanode1\nssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@datanode2\nssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@datanode3\nchmod 0600 ~/.ssh/authorized_keys\nexit\n```", "```py\nmkdir /opt/hadoop\ncd /opt/hadoop\nwget http://www-eu.apache.org/dist/hadoop/common/hadoop-2.7.3/hadoop-2.7.3.tar.gz\ntar -xvf hadoop-2.7.3.tar.gz \nmv Hadoop-2.7.3 hadoop\nchown -R hadoop /opt/hadoop\ncd /opt/hadoop/Hadoop\n```", "```py\ncd /opt/Hadoop/conf\n\nvi core-site.xml  \n```", "```py\n    vi masters\n    namenode\n\n    vi slaves\n    datanode1\n    datanode2\n    datanode3\n\n```", "```py\n cd /opt/Hadoop/Hadoop/bin\n\n    hadoop -namenode  -format \n```", "```py\n    ./start-all.sh\n\n```", "```py\nexport HADOOP_CONF_DIR=\"${HADOOP_CONF_DIR:-$YARN_HOME/etc/hadoop}\"\nexport HADOOP_COMMON_HOME=\"${HADOOP_COMMON_HOME:-$YARN_HOME}\"\nexport HADOOP_HDFS_HOME=\"${HADOOP_HDFS_HOME:-$YARN_HOME}\"  \n```", "```py\n<?xml version=\"1.0\"?>\n<configuration>\n  <property>\n    <name>yarn.nodemanager.aux-services</name>\n    <value>mapreduce.shuffle</value>\n  </property>\n  <property>\n    <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>\n    <value>org.apache.hadoop.mapred.ShuffleHandler</value>\n  </property>\n</configuration> \n```", "```py\n<?xml version=\"1.0\"?>\n<?xml-stylesheet href=\"configuration.xsl\"?>\n<configuration>\n  <property>\n    <name>mapreduce.framework.name </name>\n    <value>yarn</value>\n  </property>\n</configuration>  \n```", "```py\nyarn resourcemanager\nyarn nodemanager \n```"]