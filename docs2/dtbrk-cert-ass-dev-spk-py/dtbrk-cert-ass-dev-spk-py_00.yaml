- en: Preface
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 前言
- en: Welcome to the comprehensive guide for aspiring developers seeking certification
    in Apache Spark with Python through Databricks.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 欢迎您加入 Apache Spark Python 认证的综合指南，这是为有志于通过 Databricks 获得认证的开发者准备的。
- en: In this book, *Databricks Certified Associate Developer for Apache Spark Using
    Python*, I have distilled years of expertise and practical wisdom into a comprehensive
    guide to navigate the complexities of data science, AI, and cloud technologies
    and help you prepare for Spark certification. Through insightful anecdotes, actionable
    insights, and proven strategies, I will equip you with the tools and knowledge
    needed to thrive in an ever-evolving technological landscape of big data and artificial
    intelligence.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，《使用 Python 的 Apache Spark 认证 Databricks 认证助理开发者》，我将多年的专业知识和实践经验提炼成一本全面指南，以帮助您导航数据科学、人工智能和云计算技术的复杂性，并帮助您为
    Spark 认证做准备。通过有洞察力的轶事、可操作的见解和经过验证的策略，我将为您提供在不断发展的大数据和人工智能技术领域中茁壮成长的工具和知识。
- en: Apache Spark has emerged as the go-to framework to process large-scale data,
    enabling organizations to extract valuable insights and drive informed decision-making.
    With its robust capabilities and versatility, Spark has become a cornerstone in
    the toolkit of data engineers, analysts, and scientists worldwide. This book is
    designed to be your comprehensive companion on the journey to mastering Apache
    Spark with Python, providing a structured approach to understanding the core concepts,
    advanced techniques, and best practices for leveraging Spark’s full potential.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Spark 已成为处理大规模数据的首选框架，使组织能够提取有价值的见解并推动明智的决策制定。凭借其强大的功能和多功能性，Spark 已成为全球数据工程师、分析师和科学家工具箱中的基石。本书旨在成为您掌握
    Apache Spark 的全面伴侣，通过结构化的方法来理解核心概念、高级技术和利用 Spark 全部潜力的最佳实践。
- en: This book is meticulously crafted to guide you on the journey to becoming a
    certified Apache Spark developer. With a focus on certification preparation, I
    offer a structured approach to mastering Apache Spark with Python, ensuring that
    you’re well-equipped to ace the certification exam and validate your expertise.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本书精心制作，旨在指导您走上成为认证 Apache Spark 开发者的旅程。专注于认证准备，我提供了一种结构化的方法来掌握使用 Python 的 Apache
    Spark，确保您为通过认证考试和验证您的专业知识做好了充分准备。
- en: Who this book is for
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书面向的对象
- en: This book is tailored for individuals aspiring to become certified developers
    in Apache Spark using Python. Whether you’re a seasoned data professional looking
    to validate your expertise or a newcomer eager to delve into the world of big
    data analytics, this guide caters to all skill levels. From beginners seeking
    a solid foundation in Spark to experienced practitioners aiming to fine-tune their
    skills and prepare for certification, this book serves as a valuable resource
    for anyone passionate about harnessing the power of Apache Spark.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本书专为有志于成为使用 Python 进行 Apache Spark 认证的开发者而定制。无论您是一位经验丰富的数据专业人士，希望验证您的专业知识，还是一位渴望深入了解大数据分析的新手，本指南都能满足所有技能水平的需求。从寻求在
    Spark 中建立坚实基础的新手到希望提高技能并为认证做准备的经验丰富的从业者，本书为任何热衷于利用 Apache Spark 力量的个人提供了宝贵的资源。
- en: Whether you’re aiming to enhance your career prospects, validate your skills,
    or secure new opportunities in the data engineering landscape, this guide is tailored
    to meet your certification goals. With a focus on exam preparation, we provide
    targeted resources and practical insights to ensure your success in the certification
    journey.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 无论您是希望提升职业前景、验证您的技能，还是在数据工程领域寻求新的机会，本指南都针对您的认证目标量身定制。专注于考试准备，我们提供针对性的资源和实用见解，以确保您在认证旅程中的成功。
- en: The book provides prescriptive guidance and associated methodologies to make
    your mark in big data space with working knowledge of Spark and help you pass
    your Spark certification exam. This book expects you to have a working knowledge
    of Python, but it does not expect any prior Spark knowledge, although having a
    working knowledge of PySpark would be very beneficial.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本书提供了指导性的建议和相关方法，帮助您在拥有 Spark 工作知识的基础上在大数据领域留下足迹，并帮助您通过 Spark 认证考试。本书期望您具备 Python
    的工作知识，但不需要任何先前的 Spark 知识，尽管拥有 PySpark 的工作知识将非常有帮助。
- en: What this book covers
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书涵盖的内容
- en: In the following chapters, we will cover the following topics.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将涵盖以下主题。
- en: '[*Chapter 1*](B19176_01.xhtml#_idTextAnchor016), *Overview of the Certification
    Guide and Exam*, introduces the basics of the certification exam in PySpark and
    how to prepare for it.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第1章*](B19176_01.xhtml#_idTextAnchor016)，*认证指南和考试概述*，介绍了PySpark认证考试的基础知识以及如何准备考试。'
- en: '[*Chapter 2*](B19176_02.xhtml#_idTextAnchor030), *Understanding Apache Spark
    and Its Applications*, delves into the fundamentals of Apache Spark, exploring
    its core functionalities, ecosystem, and real-world applications. It introduces
    Spark’s versatility in handling diverse data processing tasks, such as batch processing,
    real-time analytics, machine learning, and graph processing. Practical examples
    illustrate how Spark is utilized across industries and its evolving role in modern
    data architectures.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第2章*](B19176_02.xhtml#_idTextAnchor030)，*理解Apache Spark及其应用*，深入探讨了Apache
    Spark的基本原理，探讨了其核心功能、生态系统和实际应用。它介绍了Spark在处理各种数据处理任务中的多功能性，如批量处理、实时分析、机器学习和图处理。实际示例说明了Spark在各个行业中的应用以及其在现代数据架构中的演变角色。'
- en: '[*Chapter 3*](B19176_03.xhtml#_idTextAnchor053), *Spark Architecture and Transformations*,
    deep-dives into the architecture of Apache Spark, elucidating the RDD (Resilient
    Distributed Dataset) abstraction, Spark’s execution model, and the significance
    of transformations and actions. It explores the concepts of narrow and wide transformations,
    their impact on performance, and how Spark’s execution plan optimizes distributed
    computations. Practical examples elucidate these concepts for better comprehension.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第3章*](B19176_03.xhtml#_idTextAnchor053)，*Spark架构和转换*，深入剖析了Apache Spark的架构，阐述了RDD（弹性分布式数据集）抽象、Spark的执行模型以及转换和操作的重要性。它探讨了窄转换和宽转换的概念，它们对性能的影响，以及Spark的执行计划如何优化分布式计算。实际示例有助于更好地理解这些概念。'
- en: '[*Chapter 4*](B19176_04.xhtml#_idTextAnchor071), *Spark DataFrames and their
    Operations*, focuses on Spark’s DataFrame API and explores its role in structured
    data processing and analytics. It covers DataFrame creation, manipulation, and
    various operations, such as filtering, aggregations, joins, and groupings. Illustrative
    examples demonstrate the ease of use and advantages of the DataFrame API in handling
    structured data.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第4章*](B19176_04.xhtml#_idTextAnchor071)，*Spark DataFrame及其操作*，专注于Spark的DataFrame
    API，并探讨了它在结构化数据处理和分析中的作用。它涵盖了DataFrame的创建、操作以及各种操作，如过滤、聚合、连接和分组。示例说明了DataFrame
    API在处理结构化数据中的易用性和优势。'
- en: '[*Chapter 5*](B19176_05.xhtml#_idTextAnchor115), *Advanced Operations and Optimizations
    in Spark and Optimization*, expands on your foundational knowledge and delves
    into advanced Spark operations, including broadcast variables, accumulators, custom
    partitioning, and working with external libraries. It explores techniques to handle
    complex data types, optimize memory usage, and leverage Spark’s extensibility
    for advanced data processing tasks.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第5章*](B19176_05.xhtml#_idTextAnchor115)，*Spark的高级操作和优化*，在扩展你的基础知识的基础上，深入探讨了Spark的高级操作，包括广播变量、累加器、自定义分区以及与外部库协同工作。它探讨了处理复杂数据类型、优化内存使用以及利用Spark的可扩展性进行高级数据处理任务的技术。'
- en: This chapter also delves into performance optimization strategies in Spark,
    emphasizing the significance of adaptive query execution. It explores techniques
    for optimizing Spark jobs dynamically, including runtime query planning, adaptive
    joins, and data skew handling. Practical tips and best practices are provided
    to fine-tune Spark jobs for enhanced performance.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 本章还探讨了Spark的性能优化策略，强调了自适应查询执行的重要性。它探讨了优化Spark作业动态技术，包括运行时查询规划、自适应连接和数据倾斜处理。提供了实用技巧和最佳实践，以微调Spark作业以增强性能。
- en: '[*Chapter 6*](B19176_06.xhtml#_idTextAnchor164), *SQL Queries in Spark*, focuses
    on Spark’s SQL module and explores the SQL-like querying capabilities within Spark.
    It covers the DataFrame API’s interoperability with SQL, enabling users to run
    SQL queries on distributed datasets. Examples showcase how to express complex
    data manipulations and analytics using SQL queries in Spark.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第6章*](B19176_06.xhtml#_idTextAnchor164)，*Spark中的SQL查询*，专注于Spark的SQL模块，并探讨了Spark中类似SQL的查询能力。它涵盖了DataFrame
    API与SQL的互操作性，使用户能够在分布式数据集上运行SQL查询。示例展示了如何使用SQL查询在Spark中表达复杂的数据操作和分析。'
- en: '[*Chapter 7*](B19176_07.xhtml#_idTextAnchor183), *Structured Streaming in Spark*,
    focuses on real-time data processing and introduces Structured Streaming, Spark’s
    API for handling continuous data streams. It covers concepts such as event time
    processing, watermarking, triggers, and output modes. Practical examples demonstrate
    how to build and deploy streaming applications using Structured Streaming.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第7章*](B19176_07.xhtml#_idTextAnchor183)，*Spark 中的结构化流*，专注于实时数据处理，并介绍了 Spark
    处理连续数据流的 API——结构化流。它涵盖了事件时间处理、水印、触发器和输出模式等概念。实际示例演示了如何使用结构化流构建和部署流应用程序。'
- en: This chapter is not included in the Spark certification exam, but it is beneficial
    to understand streaming concepts, since they are a core concept in the modern
    data engineering world.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 本章不包括在 Spark 认证考试中，但了解流式处理概念是有益的，因为它们是现代数据工程世界中的核心概念。
- en: '[*Chapter 8*](B19176_08.xhtml#_idTextAnchor220), *Machine Learning with Spark
    ML*, explores Spark’s machine learning library, Spark ML, diving into supervised
    and unsupervised machine learning techniques. It covers model building, evaluation,
    and hyperparameter tuning for various algorithms. Practical examples illustrate
    the application of Spark ML in real-world machine learning tasks.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第8章*](B19176_08.xhtml#_idTextAnchor220)，*使用 Spark ML 进行机器学习*，探讨了 Spark 的机器学习库
    Spark ML，深入监督和无监督机器学习技术。它涵盖了各种算法的模型构建、评估和超参数调整。实际示例说明了 Spark ML 在现实世界机器学习任务中的应用。'
- en: This chapter is not included in the Spark certification exam, but it is beneficial
    to understand machine learning concepts in Spark, since they are a core concept
    in the modern data science world.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 本章不包括在 Spark 认证考试中，但了解 Spark 中的机器学习概念是有益的，因为它们是现代数据科学世界中的核心概念。
- en: '[*Chapter 9*](B19176_09.xhtml#_idTextAnchor242), *Mock Test 1*, provides you
    with the first mock test to prepare for the actual certification exam.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第9章*](B19176_09.xhtml#_idTextAnchor242)，*模拟测试1*，为你提供了第一个模拟测试，以备实际认证考试之用。'
- en: '[*Chapter 10*](B19176_10.xhtml#_idTextAnchor246), *Mock Test 2*, provides you
    with the second mock test to prepare for the actual certification exam.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第10章*](B19176_10.xhtml#_idTextAnchor246)，*模拟测试2*，为你提供了第二个模拟测试，以备实际认证考试之用。'
- en: To get the most out of this book
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 要充分利用本书
- en: Before diving into the chapters, it’s essential to have a basic understanding
    of Python programming and familiarity with fundamental data processing concepts.
    Additionally, a grasp of distributed computing principles and experience with
    data manipulation and analysis will be beneficial. Throughout the book, we’ll
    assume a working knowledge of Python and foundational concepts in data engineering
    and analytics. With these prerequisites in place, you’ll be well-equipped to embark
    on your journey to becoming a certified Apache Spark developer.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入研究章节之前，对 Python 编程的基本理解以及熟悉基本数据处理概念是必不可少的。此外，掌握分布式计算原理以及数据操作和分析经验将大有裨益。全书假设您具备
    Python 的工作知识以及数据工程和数据分析的基础概念。具备这些先决条件后，您将准备好开始您的 Apache Spark 认证开发者之旅。
- en: '| **Software/hardware covered in** **the book** | **Operating** **system requirements**
    |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| **本书涵盖的软件/硬件** | **操作系统要求** |'
- en: '| Python | Windows, macOS, or Linux |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| Python | Windows、macOS 或 Linux |'
- en: '| Spark |  |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| Spark |  |'
- en: '*The code will work best if you sign up for the community edition of Databricks
    and import the python* *files into* *your account.*'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '*代码在您注册 Databricks 社区版并导入您的账户中的 python* *文件时将运行最佳。*'
- en: '**If you are using the digital version of this book, we advise you to type
    the code yourself or access the code from the book’s GitHub repository (a link
    is available in the next section). Doing so will help you avoid any potential
    errors related to the copying and pasting** **of code.**'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**如果您使用的是本书的数字版，我们建议您亲自输入代码或从本书的 GitHub 仓库（下一节中提供链接）获取代码。这样做将有助于避免与代码复制和粘贴相关的任何潜在错误。**'
- en: Download the example code files
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下载示例代码文件
- en: You can download the example code files for this book from GitHub at [https://github.com/PacktPublishing/Databricks-Certified-Associate-Developer-for-Apache-Spark-Using-Python](https://github.com/PacktPublishing/Databricks-Certified-Associate-Developer-for-Apache-Spark-using-Python).
    If there’s an update to the code, it will be updated in the GitHub repository.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从GitHub下载本书的示例代码文件 [https://github.com/PacktPublishing/Databricks-Certified-Associate-Developer-for-Apache-Spark-Using-Python](https://github.com/PacktPublishing/Databricks-Certified-Associate-Developer-for-Apache-Spark-using-Python)。如果代码有更新，它将在GitHub仓库中更新。
- en: We also have other code bundles from our rich catalog of books and videos available
    at [https://github.com/PacktPublishing/](https://github.com/PacktPublishing/).
    Check them out!
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还有其他来自我们丰富的书籍和视频目录的代码包可供使用，请访问 [https://github.com/PacktPublishing/](https://github.com/PacktPublishing/)。查看它们！
- en: Conventions used
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用的约定
- en: There are a number of text conventions used throughout this book.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中使用了多种文本约定。
- en: '`Code in text`: Indicates code words in text, database table names, folder
    names, filenames, file extensions, pathnames, dummy URLs, user input, and Twitter
    handles. Here is an example: “The `createOrReplaceTempView()` method allows us
    to save the processed data as a view in Spark SQL.”'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '`文本中的代码`: 表示文本中的代码单词、数据库表名、文件夹名、文件名、文件扩展名、路径名、虚拟URL、用户输入和Twitter昵称。以下是一个示例：“`createOrReplaceTempView()`
    方法允许我们将处理后的数据作为视图保存在Spark SQL中。”'
- en: 'A block of code is set as follows:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 代码块设置如下：
- en: '[PRE0]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '**Bold**: Indicates a new term, an important word, or words that you see on
    screen. For instance, words in menus or dialog boxes appear in **bold**. Here
    is an example: “The exam consists of **60 questions**. The time you’re given to
    attempt these questions is **120 minutes**.”'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**粗体**: 表示新术语、重要单词或您在屏幕上看到的单词。例如，菜单或对话框中的单词以**粗体**显示。以下是一个示例：“考试由**60个问题**组成。您尝试这些问题的时间是**120分钟**。”'
- en: Tips or important notes
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 小贴士或重要提示
- en: Appear like this.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来像这样。
- en: Get in touch
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 联系我们
- en: Feedback from our readers is always welcome.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 读者反馈始终欢迎。
- en: '**General feedback**: If you have questions about any aspect of this book,
    email us at [customercare@packtpub.com](http://customercare@packtpub.com) and
    mention the book title in the subject of your message.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**一般反馈**: 如果您对本书的任何方面有疑问，请通过电子邮件发送至 [customercare@packtpub.com](http://customercare@packtpub.com)，并在邮件主题中提及书名。'
- en: '**Errata**: Although we have taken every care to ensure the accuracy of our
    content, mistakes do happen. If you have found a mistake in this book, we would
    be grateful if you would report this to us. Please visit [www.packtpub.com/support/errata](http://www.packtpub.com/support/errata)
    and fill in the form.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**勘误**: 尽管我们已经尽最大努力确保内容的准确性，但错误仍然可能发生。如果您在这本书中发现了错误，如果您能向我们报告，我们将不胜感激。请访问 [www.packtpub.com/support/errata](http://www.packtpub.com/support/errata)
    并填写表格。'
- en: '**Piracy**: If you come across any illegal copies of our works in any form
    on the internet, we would be grateful if you would provide us with the location
    address or website name. Please contact us at [copyright@packt.com](http://copyright@packt.com)
    with a link to the material.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**盗版**: 如果您在互联网上以任何形式发现我们作品的非法副本，如果您能提供位置地址或网站名称，我们将不胜感激。请通过电子邮件发送至 [copyright@packt.com](http://copyright@packt.com)
    并附上材料的链接。'
- en: '**If you are interested in becoming an author**: If there is a topic that you
    have expertise in and you are interested in either writing or contributing to
    a book, please visit [authors.packtpub.com](http://authors.packtpub.com).'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**如果您有兴趣成为作者**: 如果您在某个领域有专业知识，并且您有兴趣撰写或为书籍做出贡献，请访问 [authors.packtpub.com](http://authors.packtpub.com)。'
- en: Share Your Thoughts
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分享您的想法
- en: Now you’ve finished *Databricks Certified Associate Developer for Apache Spark
    using Python*, we’d love to hear your thoughts! [If you purchased the book from
    Amazon, please click here to go straight to the Amazon review page for this book
    and share your feedback or leave a review](https://packt.link/r/1-804-61978-7)
    on the site that you purchased it from.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经完成了 *Databricks认证的Apache Spark使用Python的副开发人员*，我们很乐意听听您的想法！[如果您从亚马逊购买了这本书，请点击此处直接进入本书的亚马逊评论页面并分享您的反馈或留下评论](https://packt.link/r/1-804-61978-7)。
- en: Your review is important to us and the tech community and will help us make
    sure we’re delivering excellent quality content.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 您的评论对我们和科技社区都至关重要，并将帮助我们确保我们提供高质量的内容。
- en: Download a free PDF copy of this book
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下载本书的免费PDF副本
- en: Thanks for purchasing this book!
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢您购买本书！
- en: Do you like to read on the go but are unable to carry your print books everywhere?
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 您喜欢在路上阅读，但无法携带您的印刷书籍到处走吗？
- en: Is your eBook purchase not compatible with the device of your choice?
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 您的电子书购买是否与您选择的设备不兼容？
- en: Don’t worry, now with every Packt book you get a DRM-free PDF version of that
    book at no cost.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 请放心，现在每购买一本Packt书籍，您都可以免费获得该书的DRM免费PDF版本。
- en: Read anywhere, any place, on any device. Search, copy, and paste code from your
    favorite technical books directly into your application.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何地方、任何地点、任何设备上阅读。直接从您最喜欢的技术书籍中搜索、复制和粘贴代码到您的应用程序中。
- en: The perks don’t stop there, you can get exclusive access to discounts, newsletters,
    and great free content in your inbox daily
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 优惠不仅限于此，您还可以获得独家折扣、新闻通讯和每天收件箱中的优质免费内容。
- en: 'Follow these simple steps to get the benefits:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下简单步骤获取福利：
- en: Scan the QR code or visit the link below
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 扫描二维码或访问以下链接
- en: '![](img/B19176_QR_Free_PDF.jpg)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B19176_QR_Free_PDF.jpg)'
- en: '[https://packt.link/free-ebook/9781804619780](https://packt.link/free-ebook/9781804619780)'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/free-ebook/9781804619780](https://packt.link/free-ebook/9781804619780)'
- en: Submit your proof of purchase
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提交您的购买证明
- en: That’s it! We’ll send your free PDF and other benefits to your email directly
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 就这样！我们将直接将您的免费PDF和其他福利发送到您的邮箱
- en: 'Part 1: Exam Overview'
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第1部分：考试概述
- en: This part will show the basics of the certification exam for PySpark and the
    rules that need to be kept in mind. It will show the various types of questions
    asked in the exam and how to prepare for them.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这一部分将展示PySpark认证考试的基础知识和需要牢记的规则。它将展示考试中提出的不同类型的问题以及如何准备这些问题。
- en: 'This part has the following chapter:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 这一部分包含以下章节：
- en: '[*Chapter 1*](B19176_01.xhtml#_idTextAnchor016), *Overview of the Certification
    Guide and Exam*'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第1章*](B19176_01.xhtml#_idTextAnchor016)，*认证指南和考试概述*'
