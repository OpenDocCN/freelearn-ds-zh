- en: 4 Importing Unhandled Data Objects
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4 导入未处理的数据对象
- en: 'In this chapter, you''ll look at using R and Python in what is typically the
    first phase of report creation: **data ingestion**. Power BI is a very powerful
    tool from this point of view, because it has many connectors to various data sources
    out of the box. In addition to being able to import data directly by connecting
    to data sources, you can easily solve more complex data loading scenarios with
    Power BI. For example, you can merge multiple CSV files or multiple Excel Workbook’s
    sheets dynamically directly from Power BI, even using the **M language** to apply
    special logic to the merge step. You can also scrape any web page by just clicking
    on web page contents without using any code. All this is possible thanks to Power
    BI''s standard features, without having to use R or Python.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将探讨在报告创建通常的第一阶段使用R和Python：**数据摄取**。从这一角度看，Power BI是一个非常强大的工具，因为它自带了许多连接到各种数据源的工具。除了能够通过连接数据源直接导入数据外，您还可以使用Power
    BI轻松解决更复杂的数据加载场景。例如，您可以直接从Power BI中动态合并多个CSV文件或多个Excel工作簿的多个工作表，甚至可以使用**M语言**在合并步骤中应用特殊逻辑。您还可以通过仅点击网页内容而不使用任何代码来抓取任何网页。所有这一切都归功于Power
    BI的标准功能，无需使用R或Python。
- en: There are, however, cases in which the data to be imported and used in Power
    BI comes from **processing done on external systems**, which persist data in formats
    that are not directly managed by Power BI. Imagine being a Power BI report developer
    and having to interface with a team of data scientists. Some complex processing
    done by them on fairly large datasets might require non-trivial run times. That's
    why data scientists often **serialize the result** of such processing in files
    of an acceptable size, so they can deserialize them very quickly if needed. Now
    suppose the data scientist team provides you with one of these files serialized
    in R or Python and asks you to use it for some calculations needed to create a
    visual in your report. How would you do it?
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有些情况下，要导入并用于Power BI中的数据来自**外部系统上进行的处理**，这些系统以Power BI无法直接管理的数据格式持久化数据。想象一下，您是一名Power
    BI报告开发者，需要与一组数据科学家进行接口。他们可能对相当大的数据集进行的某些复杂处理可能需要非平凡的运行时间。这就是为什么数据科学家经常将此类处理的**结果序列化**到可接受大小的文件中，以便在需要时可以非常快速地进行反序列化。现在假设数据科学家团队向您提供了一个用R或Python序列化的这些文件之一，并要求您使用它来完成报告创建中所需的某些计算。您将如何做？
- en: 'In this chapter, you will see how to work with serialized files from R (`.rds`)
    and Python (`.pkl`) in Power BI. The following topics will be discussed in this
    chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将了解如何在Power BI中处理来自R（`.rds`）和Python（`.pkl`）的序列化文件。本章将讨论以下主题：
- en: Importing RDS files in R
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在R中导入RDS文件
- en: Importing PKL files in Python
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Python中导入PKL文件
- en: Technical requirements
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 技术要求
- en: This chapter requires you to have a working internet connection and **Power
    BI Desktop** already installed on your machine. You must have properly configured
    the R and Python engines and IDEs as outlined in *Chapter 2, Configuring R with
    Power BI*, and *Chapter 3, Configuring Python with Power BI*.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 本章要求您在计算机上已经安装了可用的互联网连接和**Power BI Desktop**。您必须已按照*第2章，配置Power BI中的R*和*第3章，配置Power
    BI中的Python*中概述的方式正确配置了R和Python引擎以及IDE。
- en: Importing RDS files in R
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在R中导入RDS文件
- en: 'In this section, you will develop mainly R code, and in the various examples,
    we will give you an overview of what we are going to do. If you have little experience
    with R, you should familiarize yourself with the data structures that R provides
    by starting with this quickstart: [http://bit.ly/r-data-struct-quickstart](http://bit.ly/r-data-struct-quickstart).
    Take a look at the *References* section for more in-depth information.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，您将主要开发R代码，在各个示例中，我们将为您概述我们将要做什么。如果您对R的经验不多，您应该通过以下快速入门来熟悉R提供的数据结构：[http://bit.ly/r-data-struct-quickstart](http://bit.ly/r-data-struct-quickstart)。查看*参考*部分以获取更深入的信息。
- en: A brief introduction to Tidyverse
  id: totrans-10
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Tidyverse简介
- en: A data scientist using R as an analytical language for data analysis and data
    science must know the set of packages that goes by the name of **Tidyverse** ([https://www.tidyverse.org](https://www.tidyverse.org)).
    It provides everything needed for data wrangling and data visualization, giving
    the analyst a consistent approach to the entire ecosystem of packages it provides.
    In this way, it tries to heal the initial situation of "chaos" of R functionalities
    provided by packages developed by developers who had not agreed on a common framework.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 R 作为数据分析语言和数据科学分析的数据科学家必须了解名为 **Tidyverse** 的软件包集合（[https://www.tidyverse.org](https://www.tidyverse.org)）。它提供了数据整理和可视化的所有必需工具，为分析师提供了一个对其提供的整个软件包生态系统的统一方法。这样，它试图解决由未达成共同框架的开发者开发的软件包提供的
    R 功能的“混乱”初始情况。
- en: '**Note**'
  id: totrans-12
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**注意**'
- en: ''
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'If you are new to R, you might want to start with this quickstart by Software
    Carpentry to get familiar with the main concepts: [http://bit.ly/tidy-quickstart](http://bit.ly/tidy-quickstart).
    The *References* section also contains links to in-depth information about Tidyverse.'
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果你刚开始使用 R，你可能想从 Software Carpentry 的这个快速入门开始，熟悉主要概念：[http://bit.ly/tidy-quickstart](http://bit.ly/tidy-quickstart)。*参考文献*部分还包含有关
    Tidyverse 的深入信息的链接。
- en: The fundamental data type to know about in Tidyverse to be able to work with
    tabular data is the **tibble**. Tibbles (the New Zealand way of pronouncing "tables")
    are a modern version of R **dataframes**. Starting from a tibble, you can perform
    all the data transformations you want with simple functions provided by the Tidyverse
    packages.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Tidyverse 中，要能够处理表格数据，需要了解的基本数据类型是 **tibble**。Tibbles（新西兰人发音“tables”的方式）是
    R 的 **dataframes** 的现代版本。从 tibble 开始，你可以使用 Tidyverse 包提供的简单函数执行所有想要的数据转换。
- en: Today, you will often find the use of the **%>% pipe** (the R language allows
    symbols wrapped in `%` to be defined as functions and the `>` implies a chaining)
    in data analyses performed in the Tidyverse world. Borrowed from the **magrittr**
    package included in Tidyverse, the pipe has the function of forwarding the object
    on its left inside the function on its right as the first parameter. In short,
    if you need to select the `my_col` column from a `my_tbl` tibble, instead of using
    `select( my_tbl, my_col )`, you can use the piped form `my_tbl %>% select( my_col
    )`, making the code much more readable.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你经常会在 Tidyverse 世界中进行的数据分析中看到 **%>% 管道**（R 语言允许用 `%` 包裹的符号定义为函数，`>` 表示链式操作）的使用。这个管道是从
    Tidyverse 包中包含的 **magrittr** 包借用的，它具有将左侧对象作为右侧函数的第一个参数传递的功能。简而言之，如果你需要从 `my_tbl`
    tibble 中选择 `my_col` 列，而不是使用 `select(my_tbl, my_col)`，你可以使用管道形式 `my_tbl %>% select(my_col)`，使代码更易于阅读。
- en: '**Important Note**'
  id: totrans-17
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**重要提示**'
- en: ''
  id: totrans-18
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Currently, R Core is planning to introduce a new graphical form of the pipe,
    which is `|>`. So, be ready to use it when they make it available.
  id: totrans-19
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 目前，R Core 正在计划引入一个新的管道图形形式，即 `|>`。所以，当它们使其可用时，请准备好使用它。
- en: For the purpose of summarily understanding the code used in this section, we
    will describe it piece by piece, explaining the functionality of each R object
    used.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简要理解本节中使用的代码，我们将逐块描述它，解释每个 R 对象的功能。
- en: Creating a serialized R object
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创建序列化的 R 对象
- en: Now imagine for a moment that you are part of the data scientist team that has
    to do the complex processing of a dataset and then serialize the result obtained
    in a file to be reused as needed. The first thing to do is to configure the environment
    to install the latest version of Tidyverse.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 现在想象一下，你是一名数据科学家团队的一员，需要处理数据集的复杂处理，然后将获得的结果序列化到文件中以便按需重用。首先要做的事情是配置环境以安装 Tidyverse
    的最新版本。
- en: Configuring the environment and installing Tidyverse
  id: totrans-23
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 配置环境和安装 Tidyverse
- en: 'Open RStudio and proceed as shown here:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 打开 RStudio，按照以下步骤操作：
- en: Make sure the most recent R engine (4.0.2 in our case) is selected (**Tools**
    and **Global Options…**).
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保选择了最新的 R 引擎（在我们的例子中是 4.0.2），通过 **工具** 和 **全局选项…** 进行选择。
- en: 'Create a new project by clicking on the **Project** icon in the upper-right
    corner and then **New Project...**:'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过点击右上角的 **项目** 图标，然后选择 **新建项目...** 来创建一个新的项目：
- en: '![Figure 4.1 – Create a new RStudio project](img/file72.png)'
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 4.1 – 创建一个新的 RStudio 项目](img/file72.png)'
- en: Figure 4.1 – Create a new RStudio project
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.1 – 创建一个新的 RStudio 项目
- en: An RStudio project makes it straightforward to divide your work into multiple
    contexts, each with its own working directory, workspace, history, and source
    documents.
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: RStudio项目使得将你的工作分成多个上下文变得简单，每个上下文都有自己的工作目录、工作空间、历史记录和源文档。
- en: Click on **New Directory** and then on **New Project**.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**新建目录**然后点击**新建项目**。
- en: 'Now enter a name for the project folder, choose in which folder do you want
    to place it, and click **Create Project**:'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在为项目文件夹输入一个名称，选择你想要放置它的文件夹，然后点击**创建项目**：
- en: '![Figure 4.2 – Create a new project folder](img/file73.png)'
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图4.2 – 创建新的项目文件夹](img/file73.png)'
- en: Figure 4.2 – Create a new project folder
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图4.2 – 创建新的项目文件夹
- en: 'You can also find this project ready for you in the GitHub repository here:
    `Chapter04\importing-rds-files\importing-rds-files.Rproj`.RStudio will restart
    the R session and the project folder you have just created will become the working
    directory of your project.'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你也可以在这里找到为你准备好的项目在GitHub仓库中：`Chapter04\importing-rds-files\importing-rds-files.Rproj`。RStudio将重新启动R会话，你刚刚创建的项目文件夹将成为你的项目工作目录。
- en: If you recall, back in *Chapter 3, Configuring Python with Power BI*, you already
    disabled the MRO restriction on using a snapshot made at an earlier date from
    which to download packages. This was meant to install the latest versions of the
    packages. The problem is that the effect of that operation was temporary. In order
    to see that, run the `getOption("repos")` command in the console right now. You'll
    see that the default repository is still the snapshot set by MRO.
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你还记得，在*第3章，配置Power BI中的Python*中，你已经禁用了使用较早日期创建的快照来下载包的MRO限制。这是为了安装包的最新版本。问题是，该操作的效果是临时的。为了看到这一点，现在在控制台中运行`getOption("repos")`命令。你会看到默认仓库仍然是MRO设置的快照。
- en: 'In order to permanently override the repository at the project level, you must
    write the same code you used previously inside an `.Rprofile` file located in
    the project folder. To do this, go to the console and type `file.edit(".Rprofile")`.
    This will create the `.Rprofile` file in the project folder if it does not exist,
    and will open it in an editor window in RStudio. At that point, enter the following
    code:'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了在项目级别永久覆盖仓库，你必须将之前使用的相同代码写入项目文件夹中的`.Rprofile`文件。为此，前往控制台并输入`file.edit(".Rprofile")`。如果不存在，这将创建项目文件夹中的`.Rprofile`文件，并在RStudio的编辑器窗口中打开它。此时，输入以下代码：
- en: '[PRE0]'
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Now save the `.Rprofile` file by pressing *Ctrl + S* (or **File** | **Save**)
    and then close the project by clicking on the **Project** icon (a cube containing
    “R”) in the upper-right corner, and then click **Close Project**:'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在通过按*Ctrl + S*（或**文件** | **保存**）保存`.Rprofile`文件，然后通过点击右上角的**项目**图标（一个包含“R”的立方体）关闭项目，然后点击**关闭项目**：
- en: '![Figure 4.3 – Close the current RStudio project](img/file74.png)'
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图4.3 – 关闭当前的RStudio项目](img/file74.png)'
- en: Figure 4.3 – Close the current RStudio project
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图4.3 – 关闭当前的RStudio项目
- en: Reopen the project you just closed (you can find it in the list in the usual
    project menu at the top right, or you can find the `.Rproj` file in the project
    folder). You will notice that the message *"Default repo replaced with 'https://cloud.r-project.org/'"*
    will appear in the console.
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新打开你刚刚关闭的项目（你可以在右上角常规项目菜单中的列表中找到它，或者你可以在项目文件夹中找到`.Rproj`文件）。你会在控制台中注意到消息："默认仓库已替换为'https://cloud.r-project.org/'"。
- en: 'Type the `getOption("repos")` command again in the console and press *Enter*.
    Now you’ll see the new CRAN repository as the default one:'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再次在控制台中输入`getOption("repos")`命令并按*Enter*。现在你会看到新的CRAN仓库作为默认仓库：
- en: '![Figure 4.4 – The new CRAN repository set as default](img/file75.png)'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图4.4 – 将新的CRAN仓库设置为默认](img/file75.png)'
- en: Figure 4.4 – The new CRAN repository set as default
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图4.4 – 将新的CRAN仓库设置为默认
- en: 'Now let''s install all Tidyverse packages by simply running the following command
    on the console: `install.packages("tidyverse")` (it’s equivalent to installing
    it through the GUI by clicking on the **Packages** tab at the bottom right and
    then on **Install**).'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，只需在控制台中运行以下命令即可安装所有Tidyverse包：`install.packages("tidyverse")`（它相当于通过GUI点击右下角的**包**选项卡然后点击**安装**来安装）。
- en: Awesome! Now you are sure that you have installed the latest version of Tidyverse.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 太棒了！现在你确定你已经安装了Tidyverse的最新版本。
- en: Creating the RDS files
  id: totrans-47
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 创建RDS文件
- en: 'We will now walk you through creating the serialization of an R object in an
    RDS file. Assume that the computational time required to create this object is
    very large. We will also have you create an object that is not a simple tibble,
    which could have been easily exported first to CSV and then imported into Power
    BI. Let’s start:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将指导你创建 R 对象的序列化到 RDS 文件中。假设创建此对象所需的计算时间非常长。我们还将让你创建一个不是简单 tibble 的对象，这个对象可以首先导出为
    CSV 文件，然后导入到 Power BI 中。让我们开始：
- en: Open a new R script in your project by pressing *Ctrl + Shift + N* (or by clicking
    the **+** **New File** icon and then **R Script**).
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过按 *Ctrl + Shift + N*（或点击 **+** **新建文件** 图标然后选择 **R 脚本**）在你的项目中打开一个新的 R 脚本。
- en: 'Now you will load in memory both the Tidyverse packages (using the `library`
    command) and the *growth population* tibble contained in the **tidyr** package
    (using the `data` command), consisting of a subset of data taken from the *World
    Health Organization Global Tuberculosis Report*:'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，你将使用 `library` 命令加载 Tidyverse 包，并使用 `data` 命令加载包含在 **tidyr** 包中的 *growth
    population* tibble（人口增长数据），这些数据是从 *世界卫生组织全球结核病报告* 中选取的子集：
- en: '[PRE1]'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The latest command (which matches the name of the tibble) allows you to observe
    the contents of the first few lines of the tibble and its columns’ data types.
    Highlight all the commands and press *Ctrl + Enter* (or click on the **Run** icon
    on the top right of the panel) to run them. You will see the following result:'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 最后一条命令（与 tibble 的名称匹配）允许你观察 tibble 的前几行内容及其列的数据类型。突出显示所有命令并按 *Ctrl + Enter*（或在面板右上角点击
    **运行** 图标）来运行它们。你会看到以下结果：
- en: '![Figure 4.5 – Load the “population” tibble](img/file76.png)'
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 4.5 – 加载“population” tibble](img/file76.png)'
- en: Figure 4.5 – Load the “population” tibble
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.5 – 加载“population” tibble
- en: Everything that follows **#** is a comment.
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 所有以 **#** 开头的都是注释。
- en: 'Now let’s check how many distinct countries there are in the tibble. You’ll
    use the `distinct` function and then the `pull` one in order to extract the single
    column of distinct countries from the tibble in vector format:'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让我们检查 tibble 中有多少个不同的国家。你将使用 `distinct` 函数，然后使用 `pull` 函数来提取 tibble 中的单个不同国家列，并以向量格式提取：
- en: '[PRE2]'
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'You’ll see a list of all the distinct countries, like this one:'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你将看到所有不同的国家列表，如下所示：
- en: '![Figure 4.6 – List of distinct countries](img/file77.png)'
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 4.6 – 不同国家的列表](img/file77.png)'
- en: Figure 4.6 – List of distinct countries
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.6 – 不同国家的列表
- en: Try highlighting the code only up to and including `distinct(country)` and running
    the highlighted code. You will always see distinct countries, but still as part
    of a tibble.
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 尝试突出显示代码直到包括 `distinct(country)` 并运行突出显示的代码。你将始终看到不同的国家，但仍然作为 tibble 的一部分。
- en: 'Now we want to group the year and population information into separate tibbles
    for each country. In short, we want to have a tibble that contains the countries
    and for each of them another tibble with the demographic information by year.
    You can do that using the `nest` function:'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们想要将年份和人口信息分组到每个国家的单独 tibble 中。简而言之，我们想要有一个包含国家的 tibble，并为每个国家创建另一个包含按年份的人口信息的
    tibble。你可以使用 `nest` 函数做到这一点：
- en: '[PRE3]'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'You have just assigned the `nested_population_tbl` variable the new tibble
    containing the nested demographic data. Observe that we made the `nest` function
    call explicit by calling it from its `tidyr` source package using `::`. Also,
    observe how easy it is to "nest" everything except the country column into a list
    of tibbles contained in the new `demografic_data` column. Highlighting and running
    the previous chunk of code, you’ll see the following result:'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你刚刚将 `nested_population_tbl` 变量分配给包含嵌套人口数据的新的 tibble。观察我们如何通过从 `tidyr` 源包调用
    `::` 来显式调用 `nest` 函数。同时，观察将除国家列之外的所有内容“嵌套”到新 `demografic_data` 列中的 tibble 列表是多么容易。突出显示并运行前面的代码块，你会看到以下结果：
- en: '![Figure 4.7 – Tibble of nested demographic data](img/file78.png)'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 4.7 – 嵌套人口数据表](img/file78.png)'
- en: Figure 4.7 – Tibble of nested demographic data
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.7 – 嵌套人口数据表
- en: Note that the new `demographic_data` column is a list of tibbles.
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意，新的 `demographic_data` 列是一个 tibble 的列表。
- en: 'Now you can finally serialize the `nested_population_tbl` object into an RDS
    file using the `saveRDS` function:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，你可以最终使用 `saveRDS` 函数将 `nested_population_tbl` 对象序列化到 RDS 文件中：
- en: '[PRE4]'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: You can find the R code shown here in the GitHub repository associated with
    the book in the `Chapter04\importing-rds-files\01-create-object-to-serialize.R`
    file. To properly execute the code contained in the file, you should first open
    the RStudio project, double-clicking on the `Chapter04\importing-rds-files\importing-rds-files.Rproj`
    file. Then you can open the previously mentioned R script using the **Files**
    tab in the bottom-right panel of RStudio.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在与本书相关的 GitHub 仓库中找到这里显示的 R 代码，在 `Chapter04\importing-rds-files\01-create-object-to-serialize.R`
    文件中。为了正确执行文件中的代码，你应该首先打开 RStudio 项目，双击 `Chapter04\importing-rds-files\importing-rds-files.Rproj`
    文件。然后你可以使用 RStudio 右下角的 **文件** 选项卡打开之前提到的 R 脚本。
- en: 'Awesome! You can verify that a file has been serialized correctly by taking
    a look at the same panel:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 太棒了！你可以通过查看相同的面板来验证文件是否已正确序列化：
- en: '![Figure 4.8 – The RDS file correctly created](img/file79.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.8 – 正确创建的 RDS 文件](img/file79.png)'
- en: Figure 4.8 – The RDS file correctly created
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.8 – 正确创建的 RDS 文件
- en: 'In the same way, you’ll create an RDS object that contains time series views
    for four selected countries. The time series data is the same as the population
    growth data you saw earlier. Let''s see how you can generate this file:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 同样地，你将创建一个包含四个选定国家时间序列视图的 RDS 对象。时间序列数据与之前看到的人口增长数据相同。让我们看看你如何生成这个文件：
- en: 'Install the fantastic **timetk** package by Matt Dancho by entering the `install.packages("timetk")`
    command into the RStudio console. It makes it easy to visualize, wrangle, and
    feature engineer time series data for forecasting and machine learning predictions.
    For more details, take a look here: [https://business-science.github.io/timetk/](https://business-science.github.io/timetk/).'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过在 RStudio 控制台中输入 `install.packages("timetk")` 命令安装由 Matt Dancho 开发的出色的 **timetk**
    包。它使得可视化、整理和特征工程时间序列数据以进行预测和机器学习预测变得容易。更多详情请查看这里：[https://business-science.github.io/timetk/](https://business-science.github.io/timetk/)。
- en: Open the `Chapter04\importing-rds-files\04-create-plots-object-to-serialize.R`
    file in RStudio. The first part of the file contains code already seen in the
    previous section and is used to generate the nested tibble of the population.
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 RStudio 中打开 `Chapter04\importing-rds-files\04-create-plots-object-to-serialize.R`
    文件。文件的前一部分包含在上一节中已经看到的代码，用于生成人口嵌套 tibble。
- en: 'Immediately after creating the nested tibble, you’ll see how to plot the time
    series data related to country Sweden. Every single R function used is explained
    in the code:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在创建嵌套 tibble 立即之后，你将看到如何绘制与瑞典相关的时序数据。每个使用的 R 函数都在代码中有解释：
- en: '[PRE5]'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Here is the result:'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是结果：
- en: '![Figure 4.9 – Population growth time series plot for Sweden](img/file80.png)'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 4.9 – 瑞典人口增长时间序列图](img/file80.png)'
- en: Figure 4.9 – Population growth time series plot for Sweden
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.9 – 瑞典人口增长时间序列图
- en: 'You will now create a time series graph for each country in the nested tibble
    following the previous example. The great thing is that thanks to the power of
    **functional programming** provided by the **map functions** of the `purrr` package,
    you can do this in one go using only one function. As always, you’ll find detailed
    explanations in the code:'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，你将根据之前的示例为嵌套 tibble 中的每个国家创建一个时间序列图。好事是，多亏了 `purrr` 包中 **map 函数** 提供的 **函数式编程**
    的力量，你可以通过一个函数一次性完成这个操作。像往常一样，你将在代码中找到详细的解释：
- en: '[PRE6]'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'After that, only the plots list extracted by the `nested_population_plots_tbl`
    tibble is serialized in an RDS file:'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 之后，只有由 `nested_population_plots_tbl` tibble 提取的图表列表被序列化到一个 RDS 文件中：
- en: '[PRE7]'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Well done! You've serialized your R objects into RDS files. If you want to try
    deserializing them, you can follow the code in the `02-deserialize-object-from-rds.R`
    and `05-deserialize-plots-object-from-rds.R` files you can found in the GitHub
    repository.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 干得好！你已经将你的 R 对象序列化到了 RDS 文件中。如果你想尝试反序列化它们，你可以按照 GitHub 仓库中的 `02-deserialize-object-from-rds.R`
    和 `05-deserialize-plots-object-from-rds.R` 文件中的代码进行操作。
- en: You are now ready to use the nested tibble serialized in a file directly in
    Power BI.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你已经准备好直接在 Power BI 中使用文件中序列化的嵌套 tibble。
- en: Using an RDS file in Power BI
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在 Power BI 中使用 RDS 文件
- en: 'It is clear that an RDS file must necessarily be used via R scripts in Power
    BI. As you may have learned by now, there are two Power BI objects through which
    you can use R scripts: **Power Query Editor** and **R visuals**. Let''s start
    with the simplest case, which is to import the RDS file into Power Query Editor.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 很明显，必须通过 R 脚本在 Power BI 中使用 RDS 文件。如您现在可能已经学到的，有两种 Power BI 对象可以通过它们使用 R 脚本：**Power
    Query 编辑器**和**R 可视化**。让我们从最简单的情况开始，即将 RDS 文件导入 Power Query 编辑器。
- en: Importing an RDS file into Power Query Editor
  id: totrans-90
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 将 RDS 文件导入 Power Query 编辑器
- en: 'You''ll import a serialized R object into Power Query Editor when you know
    *you can extract tabular information from the object* and want to persist it in
    the Power BI data model. Let''s see how it''s done:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 当您知道*可以从对象中提取表格信息*并希望将其持久化到 Power BI 数据模型中时，您将导入一个序列化的 R 对象到 Power Query 编辑器中。让我们看看它是如何完成的：
- en: Go to RStudio and create a new R script into the project by pressing *Ctrl +
    Shift + N*. You could copy and paste the content of the `02-deserialize-object-from-rds.R`
    file (or open it directly if you used the GitHub `.Rproj` file to open the project).
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开 RStudio 并通过按 *Ctrl + Shift + N* 创建一个新的 R 脚本到项目中。您可以复制并粘贴 `02-deserialize-object-from-rds.R`
    文件的内容（或者如果您使用了 GitHub `.Rproj` 文件打开项目，可以直接打开它）。
- en: 'Load the RDS file via the `readRDS` function and assign it to the new `deserialized_tbl`
    variable like so:'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过 `readRDS` 函数加载 RDS 文件，并将其分配给新的 `deserialized_tbl` 变量，如下所示：
- en: '[PRE8]'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Note that we are using an absolute path to read the RDS file, even though we
    are in an RStudio project and could have referenced the file without a path. This
    is because *Power BI does not have the concept of "projects" that RStudio does
    and therefore needs an absolute path* to locate the file correctly. Also, note
    that in R you can use either the double-backslash (`\\`) or the simple slash (`/`)
    as a separator in path strings.
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意，我们正在使用绝对路径来读取 RDS 文件，尽管我们处于 RStudio 项目中并且可以不使用路径引用该文件。这是因为*Power BI 没有RStudio那样的“项目”概念，因此需要绝对路径*来正确定位文件。另外，请注意，在
    R 中，您可以使用双反斜杠（`\\`）或简单斜杠（`/`）作为路径字符串中的分隔符。
- en: 'Now try extracting the demographics of Sweden from the nested tibble as follows:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在尝试以下方式从嵌套的 tibble 中提取瑞典的人口统计数据：
- en: '[PRE9]'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'In this piece of code, we are assigning to the `sweden_population_tbl` variable
    the content of the `deserialized_tbl` variable, to which we apply the following
    transformations:a) We filter it for the country Sweden through the filter function
    (thus obtaining the row associated with the country Sweden).b) From this row,
    we detach the content of the `demographic_data` field from the original tibble
    using the `pull` function (you’ll get a list).c) Since the content of the `demographic_data`
    column is a list containing only one tibble, the content must be unlisted using
    the `pluck` function. The result is the Sweden demographic data organized in one
    tibble, as shown in *Figure 4.11*:'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这段代码中，我们将 `sweden_population_tbl` 变量分配给 `deserialized_tbl` 变量的内容，我们对它应用以下转换：a)
    使用过滤函数过滤国家瑞典（从而获得与瑞典相关的行）。b) 从该行中，使用 `pull` 函数从原始 tibble 中分离出 `demographic_data`
    字段的内容（您将得到一个列表）。c) 由于 `demographic_data` 列的内容是一个只包含一个 tibble 的列表，因此必须使用 `pluck`
    函数取消列表。结果是组织在一个 tibble 中的瑞典人口数据，如图 *4.11* 所示：
- en: '![Figure 4.10 – The content of the Sweden demographic data organized in a tibble](img/file81.png)'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 4.10 – 以 tibble 格式组织的瑞典人口数据内容](img/file81.png)'
- en: Figure 4.10 – The content of the Sweden demographic data organized in a tibble
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.10 – 以 tibble 格式组织的瑞典人口数据内容
- en: Now open Power BI Desktop and make sure it is referencing the earliest MRO.
    Click then on **Get data** and then **More…**. Start typing `script` into the
    search textbox and double-click on R script. The R script editor will pop up.
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，打开 Power BI Desktop 并确保它引用的是最早的 MRO。然后点击**获取数据**，然后点击**更多…**。在搜索框中开始键入 `script`，然后双击
    R 脚本。R 脚本编辑器将会弹出。
- en: Copy and paste the content of the `03-deserialize-object-from-rds-in-power-bi.R`
    file into the R script editor, changing the absolute path to the RDS file accordingly,
    and then click on **OK**.
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 `03-deserialize-object-from-rds-in-power-bi.R` 文件的内容复制并粘贴到 R 脚本编辑器中，相应地更改
    RDS 文件的绝对路径，然后点击**确定**。
- en: 'The **Navigator** window will open, giving you the option to select which dataframe
    to import:'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将会打开**导航器**窗口，您可以选择要导入哪个数据框：
- en: '![Figure 4.11 – Import the deserialized dataframe into Power BI](img/file82.png)'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 4.11 – 将反序列化的数据框导入 Power BI](img/file82.png)'
- en: Figure 4.11 – Import the deserialized dataframe into Power BI
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.11 – 将反序列化的数据框导入 Power BI
- en: You will see as many dataframes (remember that tibbles are specializations of
    dataframes) as you have defined within your script. Select the **sweden_population_tbl**
    dataframe and click **Load**.
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你将在你的脚本中定义了多少个dataframe（记住tibbles是dataframe的特殊化），就会看到多少个dataframe。选择**sweden_population_tbl**
    dataframe并点击**Load**。
- en: 'When loading is finished, click on the table icon on the left menu of Power
    BI Desktop to verify that the data has been imported correctly in tabular form:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当加载完成后，点击Power BI Desktop左侧菜单中的表格图标，以验证数据是否已正确以表格形式导入：
- en: '![Figure 4.12 – The dataframe is correctly imported](img/file83.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![图4.12 – dataframe已正确导入](img/file83.png)'
- en: Figure 4.12 – The dataframe is correctly imported
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.12 – dataframe已正确导入
- en: Great! You have correctly imported your RDS file into Power BI to use its contents
    with Power Query in the most appropriate way.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 太棒了！你已经正确地将你的RDS文件导入Power BI，以便以最合适的方式使用Power Query中的内容。
- en: '**Important Note**'
  id: totrans-111
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**重要提示**'
- en: ''
  id: totrans-112
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: As you may have noticed, *the only R data structure that Power BI can work with
    are dataframes (or datatable) with columns that have standard data types*. It
    is not possible to import any other type of R objects. If you had imported the
    *deserialized_tbl* dataframe directly, the values in the *demographic_data* column
    would have generated an error and would have been unavailable.
  id: totrans-113
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如你所注意到的，*Power BI可以工作的唯一R数据结构是具有标准数据类型的dataframe（或datatable）*。无法导入任何其他类型的R对象。如果你直接导入了*deserialized_tbl*
    dataframe，那么*demographic_data*列中的值将生成错误，并且将不可用。
- en: Sometimes it may happen that you don't have the ability to deserialize an RDS
    file in Power Query Editor and extract its information in a tabular format in
    order to persist it in the Power BI data model. You may need to deserialize the
    content of an RDS file on the fly in an R visual in order to use its information
    in a visualization. You'll see how to solve this scenario in the next section.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候可能发生这样的情况，你无法在Power Query编辑器中反序列化RDS文件，以将其信息以表格格式提取出来，以便在Power BI数据模型中持久化。你可能需要在R视觉中动态地反序列化RDS文件的内容，以便在可视化中使用其信息。你将在下一节中看到如何解决这种情况。
- en: Importing an RDS file in an R visual
  id: totrans-115
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 在R视觉中导入RDS文件
- en: Now suppose you have received the RDS file containing the time series charts
    for each country from the data scientists team. Your goal is to allow the report
    user to view the charts by selecting a country.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 现在假设你从数据科学家团队那里收到了包含每个国家时间序列图表的RDS文件。你的目标是允许报告用户通过选择一个国家来查看图表。
- en: 'The problem you are facing is as follows: you know that in order to import
    any information from Power Query Editor via the R script, it must be in tabular
    format and must use standard data types. The charts made available by the data
    scientists are grouped in a list in the *ggplot* format (**ggplot** offers a powerful
    graphics language for creating elegant and complex plots in R), which in itself
    is not a standard data type. How do you import them into Power BI? You’ll need
    a little bit of *lateral thinking*.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 你面临的问题是：你知道，为了通过R脚本从Power Query编辑器导入任何信息，它必须以表格格式，并且必须使用标准数据类型。数据科学家提供的图表以*ggplot*格式分组在一个列表中（**ggplot**为R提供了创建优雅且复杂的图形的强大图形语言），它本身不是标准数据类型。你该如何将它们导入Power
    BI？你需要一点*横向思维*。
- en: '**Important Note**'
  id: totrans-118
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**重要提示**'
- en: ''
  id: totrans-119
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: As you probably already know, it is possible to serialize any programming object
    in its **byte representation** (raw vector in R). The byte representation can
    in turn be transformed into its **string representation**. Once you have strings
    (a standard data type), you can organize them into a dataframe. After that's done,
    you can import that dataframe into Power BI.
  id: totrans-120
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如你可能已经知道的，在R中可以将任何编程对象序列化为它的**字节表示**（R中的原始向量）。字节表示可以进一步转换为它的**字符串表示**。一旦你有字符串（这是一个标准数据类型），你就可以将它们组织成一个dataframe。完成之后，你可以将这个dataframe导入Power
    BI。
- en: 'The moment you need to "feed" an R visual with data, keep the following considerations
    in mind:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 当你需要“提供”R视觉数据时，请记住以下考虑因素：
- en: '**Important Note**'
  id: totrans-122
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**重要提示**'
- en: ''
  id: totrans-123
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: When you select more than one column from more than one table in the Power BI
    data model (there must be a relationship between them) as values of an R visual,
    these values *will form a single dataframe (deduplicated)* to be referenced in
    the R script of the visual.
  id: totrans-124
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 当你在Power BI数据模型中选择多个表中的多个列（它们之间必须有关系）作为R视觉的值时，这些值*将形成一个单一的dataframe（去重后）*，在视觉的R脚本中引用。
- en: 'Also, keep the following in mind:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，请记住以下事项：
- en: '**Tip**'
  id: totrans-126
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**提示**'
- en: ''
  id: totrans-127
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In some cases, you may want to *not delete duplicate rows*. In that case, you
    can add an index field to your dataset (row number) that causes all rows to be
    considered unique and prevents grouping.
  id: totrans-128
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在某些情况下，你可能想 *不删除重复行*。在这种情况下，你可以在你的数据集中添加一个索引字段（行号），这将使所有行都被视为唯一，并防止分组。
- en: It wouldn't make sense to import a dataframe containing a string representation
    of something in Power Query Editor if you couldn't transform it back to the original
    object. Fortunately, the previously mentioned direct transformation operations
    are all invertible, so you can use the inverse transformations within an R visual
    to extract and display plots appropriately. Also added to this process is a limitation
    of the data handled in R visuals that appears to be undocumented.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在 Power Query 编辑器中导入包含某种字符串表示的数据框，却无法将其转换回原始对象，那就没有意义。幸运的是，之前提到的直接转换操作都是可逆的，因此你可以在
    R 可视化中使用逆转换来适当地提取和显示图表。此外，这个过程还包括了 R 可视化中处理数据的一个似乎未记录的限制。
- en: '**Important Note**'
  id: totrans-130
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**重要提示**'
- en: ''
  id: totrans-131
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: If a string is longer than 32,766 characters, once passed into the default dataframe
    to be referenced within an R visual, *it is truncated*. To avoid truncation, it
    is necessary to split the string into smaller chunks (we chose an arbitrary length
    of 10,000) and persist those chunks in a dataframe column before using the data
    into the R visual.
  id: totrans-132
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果一个字符串长度超过 32,766 个字符，一旦传递到默认的数据框以在 R 可视化中引用，*它将被截断*。为了避免截断，有必要将字符串拆分成更小的块（我们选择了一个任意的长度为
    10,000）并在使用数据到 R 可视化之前将这些块持久化到数据框的列中。
- en: 'That said, in summary, what you will be doing in this section is as follows:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，总的来说，在本节中你将执行以下操作：
- en: Import the RDS file containing the named list of plots in **Power Query Editor**.
    From it, extract a dataframe of country names and a dataframe containing plots
    information.
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 **Power Query 编辑器** 中导入包含命名列表的图表的 RDS 文件。从中，提取包含国家名称的数据框和包含图表信息的数据框。
- en: Use the countries dataframe in a slicer with a single choice.
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用具有单选选项的筛选器中的国家数据框。
- en: Each time a country is selected from the slicer, the **R visual** will display
    the plot of the time series of the population growth of that country.
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每次从筛选器中选择一个国家时，**R 可视化**将显示该国家人口增长的时间序列图。
- en: 'Let’s summarize all the processes of wrangling the plots data in a figure that
    contains the functions you will find in the code:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在一个包含你将在代码中找到的函数的图中总结处理图表数据的所有过程：
- en: '![Figure 4.13 – Deserialize the RDS file content into an R visual](img/file84.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.13 – 将 RDS 文件内容反序列化为 R 可视化](img/file84.png)'
- en: Figure 4.13 – Deserialize the RDS file content into an R visual
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.13 – 将 RDS 文件内容反序列化为 R 可视化
- en: '**Important Note**'
  id: totrans-140
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**重要提示**'
- en: ''
  id: totrans-141
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: It hasn’t been possible to directly import the single dataframe containing both
    the country names and the corresponding plots, because the R engine returns a
    mysterious **ENVSXP Error**. A named list works like a charm.
  id: totrans-142
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 由于 R 引擎返回了一个神秘的 **ENVSXP 错误**，无法直接导入包含国家名称和相应图表的单一数据框。一个命名列表工作得很好。
- en: 'In the following steps, we will not explain in detail all the functions used,
    simply because we will refer to the code shared in the GitHub associated with
    this book, in which every single detail is commented. So, let’s start:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下步骤中，我们不会详细解释所有使用的函数，仅仅是因为我们将参考与本书相关的 GitHub 中共享的代码，其中每个细节都有注释。所以，让我们开始：
- en: Open Power BI Desktop and go to **Get data**, then **More…**, then **R Script**
    to import the RDL files.
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开 Power BI Desktop，转到 **获取数据**，然后 **更多…**，然后 **R 脚本** 以导入 RDL 文件。
- en: Open the `06-deserialize-plots-object-from-rds-in-power-bi.R` file from the
    GitHub repository, copy the content, changing the absolute path to the RDL file
    accordingly, paste it into the R Script editor, and click **OK**.
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 GitHub 仓库打开 `06-deserialize-plots-object-from-rds-in-power-bi.R` 文件，复制内容，相应地更改
    RDL 文件的绝对路径，将其粘贴到 R 脚本编辑器中，然后点击 **确定**。
- en: 'Power Query will detect three dataframes created into your script. Select only
    the **plots_df** dataframe (the one containing the string representation of bytes
    of plots), and the **selected_countries_df** one. Then click **Load**:'
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Power Query 将检测到你在脚本中创建的三个数据框。仅选择 **plots_df** 数据框（包含图表字节的字符串表示），以及 **selected_countries_df**
    数据框。然后点击 **加载**：
- en: '![Figure 4.14 – Select the two dataframes containing useful data](img/file85.png)'
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 4.14 – 选择包含有用数据的两个数据框](img/file85.png)'
- en: Figure 4.14 – Select the two dataframes containing useful data
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.14 – 选择包含有用数据的两个数据框
- en: 'Click on the **Data** icon on the left ribbon and then click on the **Manage
    relationships** button:'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击左侧工具栏上的**数据**图标，然后点击**管理关系**按钮：
- en: '![Figure 4.15 – The Manage relationships button](img/file86.png)'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 4.15 – 管理关系按钮](img/file86.png)'
- en: Figure 4.15 – The Manage relationships button
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.15 – 管理关系按钮
- en: 'The engine has automatically created the relationship between the two imported
    tables:'
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 引擎已自动创建了两个导入表之间的关系：
- en: '![Figure 4.16 – Relation between tables automatically detected](img/file87.png)'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 4.16 – 自动检测到的表格之间的关系](img/file87.png)'
- en: Figure 4.16 – Relation between tables automatically detected
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.16 – 自动检测到的表格之间的关系
- en: Click **Close**.
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 点击**关闭**。
- en: 'Go back to the report canvas clicking on the **Report** icon on the left ribbon:'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击左侧工具栏上的**报告**图标返回报告画布：
- en: '![Figure 4.17 – The Report icon](img/file88.png)'
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 4.17 – 报告图标](img/file88.png)'
- en: Figure 4.17 – The Report icon
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.17 – 报告图标
- en: 'Now click on the **Slicer** icon:'
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在点击**切片器**图标：
- en: '![Figure 4.18 – The Slicer icon](img/file89.png)'
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 4.18 – 切片器图标](img/file89.png)'
- en: Figure 4.18 – The Slicer icon
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.18 – 切片器图标
- en: 'Keeping the **Slicer** visual region selected into the canvas, click on the
    **selected_countries_df** table on the **Fields** panel, and select the **country**
    field:'
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在画布中保持**切片器**视觉区域选中，点击**字段**面板上的**selected_countries_df**表，并选择**country**字段：
- en: '![Figure 4.19 – Select the country_name column for the Slicer visual](img/file90.png)'
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 4.19 – 为切片器视觉选择 country_name 列](img/file90.png)'
- en: Figure 4.19 – Select the country_name column for the Slicer visual
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.19 – 为切片器视觉选择 country_name 列
- en: 'Then click the **Format** icon of the **Slicer** and enable the **Single select**
    option:'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后点击**切片器**的**格式**图标并启用**单选**选项：
- en: '![Figure 4.20 – Allow only a single selection](img/file91.png)'
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 4.20 – 只允许单选](img/file91.png)'
- en: Figure 4.20 – Allow only a single selection
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.20 – 只允许单选
- en: It is very important to set **Single select**, because *the logic inside the
    R visual will manage the deserialization of a single plot*.
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 设置**单选**非常重要，因为**R 视觉内部的逻辑将管理单个图表的反序列化**。
- en: 'Now the Slicer visual will show all the countries contained in the **selected_countries_tbl**:'
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，切片器视觉将显示包含在**selected_countries_tbl**中的所有国家：
- en: '![Figure 4.21 – This is what the Slicer visual looks like](img/file92.png)'
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 4.21 – 这就是切片器视觉的样子](img/file92.png)'
- en: Figure 4.21 – This is what the Slicer visual looks like
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.21 – 这就是切片器视觉的样子
- en: 'Click on the report canvas in order to deselect the **Slicer** visual and click
    then on the **R script visual** icon:'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击报告画布以取消选择**切片器**视觉元素，然后点击**R 脚本视觉**图标：
- en: '![Figure 4.22 – The R script visual icon](img/file93.png)'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 4.22 – R 脚本视觉图标](img/file93.png)'
- en: Figure 4.22 – The R script visual icon
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.22 – R 脚本视觉图标
- en: The usual **Enable script visuals** window pops up. Click on **Enable**.
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 常规的**启用脚本视觉**窗口弹出。点击**启用**。
- en: 'Move and stretch the R visual borders in order to cover almost all the report
    canvas. Keeping it selected, click on the **plots_df** table into the **Fields**
    panel and select the **chunk_id**, **country_id**, and **plot_str** fields:'
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 移动并拉伸 R 视觉的边框，使其几乎覆盖整个报告画布。保持选中状态，点击**字段**面板中的**plots_df**表，并选择**chunk_id**、**country_id**和**plot_str**字段：
- en: '![Figure 4.23 – Select the fields to use in the R visual](img/file94.png)'
  id: totrans-177
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.23 – 选择要在 R 视觉中使用的字段](img/file94.png)'
- en: Figure 4.23 – Select the fields to use in the R visual
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.23 – 选择要在 R 视觉中使用的字段
- en: Feel free to turn the R visual title off in the **Format** tab.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在**格式**选项卡中，你可以自由地关闭 R 视觉的标题。
- en: Open the `07-deserialize-plots-df-into-r-visual.R` file from the GitHub repository,
    copy the content, and paste it into the R visual’s script editor. Then click on
    the **Run** icon on the top right of the R script editor.
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 GitHub 仓库打开`07-deserialize-plots-df-into-r-visual.R`文件，复制内容，并将其粘贴到 R 视觉的脚本编辑器中。然后点击
    R 脚本编辑器右上角的**运行**图标。
- en: 'Now you can click on each country into the Slicer in order to see its population
    time series:'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，你可以点击切片器中的每个国家，以查看其人口时间序列：
- en: '![Figure 4.24 – Showing the population growth for Italy](img/file95.png)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.24 – 显示意大利的人口增长](img/file95.png)'
- en: Figure 4.24 – Showing the population growth for Italy
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.24 – 显示意大利的人口增长
- en: Outstanding! You have just created a report that very few could have made.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 太棒了！你刚刚创建了一个很少有人能做出来的报告。
- en: '**Important Note**'
  id: totrans-185
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**重要提示**'
- en: ''
  id: totrans-186
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This technique can be very useful when you need to build complex visualizations
    in R that require the use of packages not provided by the R visual in Power BI
    Service. These visualizations can be made "offline," serialized to file, and then
    used on a shared report on the service.
  id: totrans-187
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 当你需要构建R中需要使用Power BI服务中R视觉未提供的包的复杂可视化时，这种技术非常有用。这些可视化可以制作成“离线”的，序列化到文件，然后在服务上的共享报告中使用。
- en: You've just seen how to import an RDS file despite not being able to do so out
    of the box in Power BI, and how you can then use it directly within an R visual.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 你刚刚看到了如何在Power BI中导入RDS文件，尽管它不是Power BI的默认功能，以及如何直接在R视觉中使用它。
- en: In the next section, you'll see how you can do the same thing for files serialized
    with Python.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，你将看到如何对使用Python序列化的文件执行相同操作。
- en: Importing PKL files in Python
  id: totrans-190
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在Python中导入PKL文件
- en: 'Let’s give you an overview of what you''re going to implement using the Python
    code on GitHub. If you are not familiar with Python, you should familiarize yourself
    with the basic structures through this tutorial: [http://bit.ly/py-data-struct-quickstart](http://bit.ly/py-data-struct-quickstart).
    For a more detailed study of how to implement algorithms and data structures in
    Python, we suggest this free e-book: [http://bit.ly/algo-py-ebook](http://bit.ly/algo-py-ebook).'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过GitHub上的Python代码概述你要实现的内容。如果你不熟悉Python，你应该通过这个教程熟悉基本结构：[http://bit.ly/py-data-struct-quickstart](http://bit.ly/py-data-struct-quickstart)。对于如何实现Python中的算法和数据结构的更详细研究，我们建议这本免费电子书：[http://bit.ly/algo-py-ebook](http://bit.ly/algo-py-ebook)。
- en: A very short introduction to the PyData world
  id: totrans-192
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 对PyData世界的简要介绍
- en: 'The **PyData** world is made up of users and developers who are passionate
    about data analytics and love to use open source data tools. The PyData community
    also loves to share best practices, new approaches, and emerging technologies
    for managing, processing, analyzing, and visualizing data. The most important
    and popular packages used by the Python data management community are as follows:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '**PyData**世界由对数据分析充满热情并喜欢使用开源数据工具的用户和开发者组成。PyData社区还喜欢分享数据管理、处理、分析和可视化的最佳实践、新方法和新兴技术。Python数据管理社区使用的重要且流行的包如下：'
- en: '**NumPy**: This is the main library for scientific computing in Python. It
    provides a high-performance multidimensional array object and tools for working
    with data.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**NumPy**：这是Python中科学计算的主要库。它提供了一个高性能的多维数组对象以及用于处理数据的工具。'
- en: '**Pandas**: The *Python Data Analysis Library* (pandas comes from *panel data*)
    is built upon NumPy and takes data in a tabular format (such as a CSV file, TSV
    file, or SQL database table) in order to create a Python object with rows and
    columns called a **DataFrame**. This object is very similar to a table in statistical
    software and people familiar with R conceptually equate the pandas DataFrame with
    R''s dataframe data type.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Pandas**：*Python数据分析库*（pandas来自*面板数据*）建立在NumPy之上，以表格格式（如CSV文件、TSV文件或SQL数据库表）接收数据，以便创建一个具有行和列的Python对象，称为**DataFrame**。此对象与统计软件中的表格非常相似，熟悉R概念的人将pandas
    DataFrame与R的dataframe数据类型概念上等同起来。'
- en: '**Matplotlib**: This is a Python package used to produce plots. It began as
    a project in the early 2000s to use Python to visualize electronic signals in
    the brains of patients with epilepsy. The creator of Matplotlib was a neurobiologist
    and was looking for a way to replicate MATLAB''s graphing capabilities with Python.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Matplotlib**：这是一个用于生成图表的Python包。它始于2000年代初的一个项目，旨在使用Python可视化癫痫患者大脑中的电子信号。Matplotlib的创建者是一位神经生物学家，他正在寻找一种方法来使用Python复制MATLAB的绘图功能。'
- en: '**Scikit-learn**: Also known as **sklearn**, this derives its name from the
    fusion of the two words *"SciPy"* and *"Toolkit."* It is a free and robust machine
    learning library for Python designed to interact with the NumPy, SciPy, pandas,
    and Matplotlib, among others.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Scikit-learn**：也称为**sklearn**，其名称来源于两个词“SciPy”和“Toolkit”的结合。这是一个为Python设计的免费且强大的机器学习库，旨在与NumPy、SciPy、pandas、Matplotlib等库交互。'
- en: Going into detail about what is possible using these libraries is not the purpose
    of this book.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 详细介绍这些库可以做什么不是本书的目的。
- en: '**Note**'
  id: totrans-199
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**注意**'
- en: 'If you want to start learning how to work with data in Python by taking advantage
    of these libraries, we recommend starting with this free book: [http://bit.ly/data-science-py-ebook](http://bit.ly/data-science-py-ebook).
    After that, for further study, you can''t miss the opportunity to study this fantastic
    book: *Python Machine Learning: Machine Learning and Deep Learning with Python,
    Scikit-Learn, and TensorFlow 2, Third Edition*, by Sebastian Raschka, Packt.'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '如果您想通过利用这些库来开始学习如何在Python中处理数据，我们建议从这本免费书籍开始：[http://bit.ly/data-science-py-ebook](http://bit.ly/data-science-py-ebook)。在那之后，为了进一步学习，您绝对不能错过这本精彩的书：Sebastian
    Raschka所著的*Python Machine Learning: Machine Learning and Deep Learning with Python,
    Scikit-Learn, and TensorFlow 2, 第三版*，由Packt出版。'
- en: In order to summarily understand the code used in this section, we will try
    to describe its functionality piece by piece, referring you to the comments in
    the code on GitHub for more details.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简要了解本节中使用的代码，我们将尝试逐块描述其功能，并请您参考GitHub代码中的注释以获取更多详细信息。
- en: Creating a serialized Python object
  id: totrans-202
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创建一个序列化的Python对象
- en: As done in the previous section, now imagine that you are part of another team
    of data scientists that needs to do some complex, time-consuming data analysis
    with Python. Needing to reuse the results obtained in other processes, the team
    decides to use a **Pickle file** (PKL). It is obtained by serializing and then
    writing to a file any Python object, using the **pickle** library. As you have
    already seen in the previous section, serializing means converting an object in
    memory into a stream of bytes that can be either saved to disk or sent over a
    network. Obviously, this is an easily reversible operation. In fact, there is
    the possibility to deserialize a serialized object.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 如前节所述，现在假设您是另一支需要使用Python进行一些复杂、耗时数据分析的数据科学家团队的一员。由于需要重复使用在其他过程中获得的结果，团队决定使用**Pickle文件**（PKL）。这是通过使用**pickle**库将任何Python对象序列化然后写入文件来获得的。正如您在前一节中已经看到的，序列化意味着将内存中的对象转换为可以保存到磁盘或通过网络发送的字节流。显然，这是一个容易逆转的操作。事实上，还有可能反序列化一个序列化的对象。
- en: '**Important Note**'
  id: totrans-204
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**重要提示**'
- en: ''
  id: totrans-205
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Before you start, make sure that the path where you unzipped the GitHub repository
    ZIP file **doesn't contain any spaces in the names of the folders that make it
    up**, otherwise the Python script execution will give an error.
  id: totrans-206
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在开始之前，请确保您解压GitHub仓库ZIP文件的路径**不包含任何包含在其中的文件夹名称中的空格**，否则Python脚本执行将会出现错误。
- en: So, let’s start to install what we need in our environment and initialize the
    IDE appropriately.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，让我们开始安装我们环境中需要的东西，并适当地初始化IDE。
- en: Configuring the environment and installing the PyData packages
  id: totrans-208
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 配置环境和安装PyData包
- en: 'Open your **Anaconda Prompt** (from the **Start** menu) and proceed as follows:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 打开您的**Anaconda Prompt**（从**开始**菜单），按照以下步骤操作：
- en: 'Make sure to use the `pbi_powerquery_env` environment, entering this code:'
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保使用`pbi_powerquery_env`环境，输入以下代码：
- en: '[PRE10]'
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Now you will install some missing packages that are necessary to be able to
    use the code in this section.
  id: totrans-212
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在您将安装一些必要的缺失包，以便能够使用本节中的代码。
- en: 'Enter the following command to install **matplotlib**: `pip install matplotlib`.'
  id: totrans-213
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入以下命令来安装**matplotlib**：`pip install matplotlib`。
- en: 'Great! Your Python environment is now ready to run your scripts. Now open Visual
    Studio Code and proceed as shown:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 太好了！您的Python环境现在已准备好运行您的脚本。现在打开Visual Studio Code，按照以下步骤操作：
- en: Go to **File** and then **Open Folder…**. Make sure to choose the **importing-pkl-files**
    folder contained in the GitHub repository you previously unzipped, under the **Chapter04**
    folder. Click **Select Folder**.
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 前往**文件**，然后**打开文件夹…**。确保选择包含在您之前解压的GitHub仓库中的**importing-pkl-files**文件夹，位于**Chapter04**文件夹下。点击**选择文件夹**。
- en: Open the `01-create-object-to-serialize-in-pkl.py` file, clicking on it into
    the Explorer on the right, under the selected folder.
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开`01-create-object-to-serialize-in-pkl.py`文件，在右侧的选定的文件夹中点击它。
- en: 'Remember you have to choose the environment in which to run your script. So,
    press *Ctrl + Shift + P* to open the Visual Studio Code palette and start entering
    the text “interpreter.” Then, select **Python: Select Interpreter**, and then
    choose the `pbi_powerquery_env` environment.'
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '记住您必须选择运行脚本的环境。因此，按*Ctrl + Shift + P*打开Visual Studio Code调色板，并开始输入文本“interpreter。”然后，选择**Python:
    Select Interpreter**，然后选择`pbi_powerquery_env`环境。'
- en: Excellent! Now you are ready to serialize your first Python object.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 极好！现在您已准备好序列化您的第一个Python对象。
- en: Creating the PKL files
  id: totrans-219
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 创建PKL文件
- en: Two of the most commonly used data structures in Python are **lists** and **dictionaries**.
    While by now you're familiar with lists, which you've seen before in R, if you've
    never developed in a programming language, perhaps dictionaries might sound new
    to you. Dictionaries are data structures that consist of a collection of **key-value
    pairs**. You can define them using curly braces (`{…}`). Specifically, in this
    section, you will create a dictionary with key-value pairs that consists of the
    country name and a dataframe containing data about the growth of the country’s
    population.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: Python 中最常用的两种数据结构是 **列表** 和 **字典**。到目前为止，您已经熟悉列表，您在 R 中之前已经见过，如果您从未在编程语言中开发过，那么字典可能对您来说可能是个新概念。字典是由一组
    **键值对** 组成的数据结构。您可以使用花括号（`{…}`）来定义它们。具体来说，在本节中，您将创建一个包含国家名称和包含该国人口增长数据的 dataframe
    的键值对字典。
- en: 'The data you will use is the same data you used in the previous section. This
    time, instead of loading it from a package in memory, you''ll do it directly from
    a CSV file. Let’s go:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 您将使用的数据与上一节中使用的数据相同。这次，您将直接从 CSV 文件中加载它，而不是从内存中的包中加载。让我们开始吧：
- en: Since the `01-create-object-to-serialize-in-pkl.py` file is already open in
    Visual Studio Code, just run the code via the green arrow icon in the upper-right
    corner (**Run Python File in Terminal**). This way, the whole script will be executed.
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于 `01-create-object-to-serialize-in-pkl.py` 文件已经在 Visual Studio Code 中打开，只需通过右上角的绿色箭头图标（**在终端中运行
    Python 文件**）运行代码即可。这样，整个脚本将会执行。
- en: 'You won''t see anything particular in the console, just the command that runs
    `python.exe` with the current script path as a parameter. But if you look in the
    explorer on the left, you will see that the `nested_population_dict.pkl` file
    has been created correctly:'
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在控制台中您不会看到任何特别的内容，只有运行 `python.exe` 并将当前脚本路径作为参数的命令。但如果您在左侧的资源管理器中查看，您会看到 `nested_population_dict.pkl`
    文件已正确创建：
- en: '![Figure 4.25 – Your first PKL file has been created](img/file96.png)'
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 4.25 – 您的第一个 PKL 文件已创建](img/file96.png)'
- en: Figure 4.25 – Your first PKL file has been created
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.25 – 您的第一个 PKL 文件已创建
- en: 'Just like in Rstudio, you can only run pieces of code by highlighting them
    and pressing *Ctrl + Enter*. You need to change a settings option in order to
    allow the use of the **interactive window** with Python. Go to **Settings**, pressing
    *Ctrl + ,* (comma), then start entering `Send Selection To Interactive Window`
    in the search bar and check the selected option:'
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 就像在 Rstudio 中一样，您只能通过突出显示代码并按 *Ctrl + Enter* 来运行代码片段。您需要更改一个设置选项，以便允许使用 Python
    的 **交互窗口**。转到 **设置**，按 *Ctrl + ,*（逗号），然后在搜索栏中开始输入 `Send Selection To Interactive
    Window` 并检查选定的选项：
- en: '![Figure 4.26 – Enable the execution of Python code chunks in the Jupyter interactive
    window](img/file97.png)'
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 4.26 – 在 Jupyter 交互窗口中启用 Python 代码块的执行](img/file97.png)'
- en: Figure 4.26 – Enable the execution of Python code chunks in the Jupyter interactive
    window
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.26 – 在 Jupyter 交互窗口中启用 Python 代码块的执行
- en: 'Now you have to install the *IPython kernel* (`ipykernel`) into your `pbi_powerquery_env`
    environment. Usually, this operation is done automatically by Visual Studio Code,
    but sometimes you can run into errors. So, it’s better to do it manually. Open
    your Anaconda Prompt and enter the following command: `conda install --name pbi_powerquery_env
    ipykernel -y`.'
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，您需要将 *IPython 内核* (`ipykernel`) 安装到您的 `pbi_powerquery_env` 环境中。通常，这个操作会由
    Visual Studio Code 自动完成，但有时您可能会遇到错误。因此，手动操作会更好。打开您的 Anaconda Prompt 并输入以下命令：`conda
    install --name pbi_powerquery_env ipykernel -y`。
- en: 'Now select the code from the beginning (`import pandas as pd`) to the line
    where `countries` are defined (`countries = population_df.country.unique()`),
    then press *Shift + Enter*. Your chunk of code will be sent to the interactive
    window:'
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，选择从开始（`import pandas as pd`）到定义 `countries` 的行（`countries = population_df.country.unique()`），然后按
    *Shift + Enter*。您的代码块将会发送到交互窗口：
- en: '![Figure 4.27 – Run selected chunks of script in Visual Studio Code](img/file98.png)'
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 4.27 – 在 Visual Studio Code 中运行选定的脚本块](img/file98.png)'
- en: Figure 4.27 – Run selected chunks of script in Visual Studio Code
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.27 – 在 Visual Studio Code 中运行选定的脚本块
- en: Clicking on the **Variables** icon into the interactive windows as shown in
    *Figure 4.28*, you can also inspect the content of each variable.
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如 *图 4.28* 所示，在交互窗口中点击 **变量** 图标，您也可以检查每个变量的内容。
- en: Hey, maybe you didn't notice, but with minimal effort, you have just created
    your first PLK file! You can train yourself to deserialize the newly created PKL
    file by running the code in the `02-deserialize-object-from-pkl.py` file.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 嘿，可能你没有注意到，但只需付出最小的努力，你就已经创建了你的第一个 PLK 文件！你可以通过运行 `02-deserialize-object-from-pkl.py`
    文件中的代码来训练自己反序列化新创建的 PKL 文件。
- en: 'Now we will now guide you in creating a second PKL file that contains a serialized
    dictionary with pairs composed of the country and the respective time series on
    population growth. This time, though, you will keep only four countries in the
    dictionary for simplicity. Let''s proceed:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将指导你创建一个包含序列化字典的第二个 PKL 文件，该字典由国家和相应的人口增长时间序列的成对组成。这次，为了简单起见，你将只保留字典中的四个国家。让我们继续：
- en: Open the `04-create-plots-object-to-serialize-in-pkl.py` file from the explorer
    on the left.
  id: totrans-236
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从左侧的资源管理器打开 `04-create-plots-object-to-serialize-in-pkl.py` 文件。
- en: 'You can run the code a piece at a time to better understand how it works. About
    halfway through the script, you will find the following code:'
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可以分步骤运行代码，以更好地理解其工作原理。在脚本大约一半的地方，你会找到以下代码：
- en: '[PRE11]'
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'After running that piece of code, an interactive window will open in which
    the time series graph of Sweden is shown:'
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行那部分代码后，将打开一个交互式窗口，显示瑞典的时间序列图：
- en: '![Figure 4.28 – Interactive window showing the time series plot of Sweden](img/file99.png)'
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 4.28 – 显示瑞典时间序列图的交互式窗口](img/file99.png)'
- en: Figure 4.28 – Interactive window showing the time series plot of Sweden
  id: totrans-241
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.28 – 显示瑞典时间序列图的交互式窗口
- en: Keep it open if you want to create new figures, otherwise you might get a weird
    error.
  id: totrans-242
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果你想要创建新的图形，请保持打开状态，否则你可能会遇到奇怪的错误。
- en: 'The last piece of code creates a new dictionary containing graphs for each
    country and serializes it to file. Once executed, you can see the `nested_population_plots_dict.pkl`
    file in the explorer on the left:'
  id: totrans-243
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后一段代码创建了一个包含每个国家图形的新字典，并将其序列化到文件中。一旦执行，你可以在左侧的资源管理器中看到 `nested_population_plots_dict.pkl`
    文件：
- en: '![Figure 4.29 – The new dictionary is correctly serialized in a PKL file](img/file100.png)'
  id: totrans-244
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.29 – 新的字典已正确序列化到 PKL 文件中](img/file100.png)'
- en: Figure 4.29 – The new dictionary is correctly serialized in a PKL file
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.29 – 新的字典已正确序列化到 PKL 文件中
- en: Amazing! You serialized your second dictionary as well. You can practice deserializing
    it using the code in the `05-deserialize-plots-object-from-pkl.py` script.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 太棒了！你也序列化了第二个字典。你可以使用 `05-deserialize-plots-object-from-pkl.py` 脚本中的代码来练习反序列化它。
- en: Now you're ready to test your PKL files in Power BI, either in Power Query Editor
    or in Python visuals.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你已准备好在 Power BI 中测试你的 PKL 文件，无论是在 Power Query 编辑器中还是在 Python 可视化中。
- en: Using a PKL file in Power BI
  id: totrans-248
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在 Power BI 中使用 PKL 文件
- en: 'It is clear that a PKL file must necessarily be used through Python scripts
    in Power BI. So, there are two Power BI objects through which you can use Python
    scripts: **Power Query Editor** and **Python visuals**. Let''s start with the
    simplest case, which is to import the PKL file into Power Query Editor.'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 很明显，在 Power BI 中必须通过 Python 脚本来使用 PKL 文件。因此，有两个 Power BI 对象可以通过它们使用 Python 脚本：**Power
    Query 编辑器**和**Python 可视化**。让我们从最简单的情况开始，即将 PKL 文件导入到 Power Query 编辑器中。
- en: Importing a PKL file in Power Query Editor
  id: totrans-250
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 在 Power Query 编辑器中导入 PKL 文件
- en: 'You will import a serialized Python object into Power Query Editor once you
    know how to extract tabular information from the object and then persist it in
    the Power BI data model. Let''s take a look at how to do this:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 当你知道如何从对象中提取表格信息并将其持久化到 Power BI 数据模型中后，你将把一个序列化的 Python 对象导入到 Power Query 编辑器中。让我们看看如何做：
- en: Open Power BI Desktop and make sure it is referencing the `pbi_powerquery_env`
    environment. Then click on **Get** **data** and then **More…**. Start typing `script`
    into the search textbox and double-click on Python script. The Python script editor
    will pop up.
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开 Power BI Desktop，并确保它引用的是 `pbi_powerquery_env` 环境。然后点击**获取数据**，然后**更多…**。在搜索框中开始输入
    `script`，然后双击 Python 脚本。Python 脚本编辑器将弹出。
- en: Open the `03-deserialize-object-from-pkl-in-power-bi.py` file in Visual Studio
    Code and copy its content. Then paste it into the Python script editor in Power
    BI Desktop, changing the absolute path to the PKL file accordingly, and click
    **OK**.
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Visual Studio Code 中打开 `03-deserialize-object-from-pkl-in-power-bi.py` 文件，并复制其内容。然后将其粘贴到
    Power BI Desktop 中的 Python 脚本编辑器中，相应地更改 PKL 文件的绝对路径，并点击**确定**。
- en: 'The **Navigator** window will open, giving you the option to select which dataframe
    to import:'
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**导航器**窗口将打开，让你选择要导入哪个 dataframe：'
- en: '![Figure 4.30 – Import the deserialized dataframe into Power BI](img/file101.png)'
  id: totrans-255
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.30 – 将反序列化的数据框导入 Power BI](img/file101.png)'
- en: Figure 4.30 – Import the deserialized dataframe into Power BI
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.30 – 将反序列化的数据框导入 Power BI
- en: Select the **sweden_population_tbl** dataframe and click **Load**.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 选择 **sweden_population_tbl** 数据框并点击 **加载**。
- en: 'When loading is finished, click on the table icon on the left menu of Power
    BI Desktop to verify that the data has been imported correctly in tabular form:'
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载完成后，点击 Power BI Desktop 左侧菜单中的表格图标以验证数据是否已正确以表格形式导入：
- en: '![Figure 4.31 – The dataframe is correctly imported](img/file102.png)'
  id: totrans-259
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.31 – 数据框已正确导入](img/file102.png)'
- en: Figure 4.31 – The dataframe is correctly imported
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.31 – 数据框已正确导入
- en: Nice job! You have correctly imported your PKL file into Power BI to use its
    contents with Power Query in the most appropriate way.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 干得好！你已经正确地将你的 PKL 文件导入到 Power BI 中，以便以最合适的方式使用其内容 与 Power Query。
- en: '**Important Note**'
  id: totrans-262
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**重要提示**'
- en: ''
  id: totrans-263
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: As with R scripts, **the only Python data structure that Power BI can work with
    are pandas DataFrames with columns that have standard data types**. It is not
    possible to import any other type of Python object. That’s exactly why you couldn't
    import the dictionary directly.
  id: totrans-264
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 与 R 脚本一样，**Power BI 能够处理的数据结构只有具有标准数据类型的 pandas DataFrame**。无法导入任何其他类型的 Python
    对象。这就是为什么你无法直接导入字典的原因。
- en: As should be clear to you by now from the previous section, it can happen that
    a PKL file doesn’t contain information in tabular format that can be extracted
    in Power Query Editor. You may need to deserialize the contents of a PKL file
    directly within a Python visual in order to use that information to create a chart.
    You will see how to solve this scenario in the next section.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，可能发生 PKL 文件不包含可以在 Power Query 编辑器中提取的表格格式信息的情况。你可能需要在 Python 可视化中直接反序列化
    PKL 文件的内容，以便使用这些信息创建图表。你将在下一节中看到如何解决这种情况。
- en: Importing a PKL file in a Python visual
  id: totrans-266
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 在 Python 可视化中导入 PKL 文件
- en: Now let's assume that you received a PKL file containing the time series graphs
    for each country from the data scientists team. Your goal is to allow the report
    user to view the graphs by selecting a country.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 现在假设你收到了数据科学家团队发送的包含每个国家时间序列图的 PKL 文件。你的目标是允许报告用户通过选择一个国家来查看这些图表。
- en: 'The problem you face is the following: you know that in order to import any
    information into Power Query Editor via Python scripts, it must be in tabular
    format and must use standard data types. The charts provided by the data scientists
    are grouped in a dictionary in the **figure format** of **Matplotlib**, which
    itself is not a standard data type. So, how do you import the dictionary into
    Power BI? The same "trick" used with R in the previous section applies.'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 你面临的问题是这样的：你知道为了通过 Python 脚本将任何信息导入 Power Query 编辑器，它必须是表格格式，并且必须使用标准数据类型。数据科学家提供的图表以
    **Matplotlib** 的 **图像格式**分组在字典中，而 Matplotlib 本身不是标准数据类型。那么，你如何将字典导入 Power BI 呢？与之前章节中用于
    R 的相同“技巧”适用。
- en: 'In summary, what you will do in this section is this:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，在本节中你将执行以下操作：
- en: Import the PKL file containing the dictionary of plots in Power Query Editor.
    Extract its keys (countries) and expose them in a dataframe. Use its byte stream
    representation to fill another dataframe.
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Power Query 编辑器中导入包含图表字典的 PKL 文件。提取其键（国家）并在数据框中公开它们。使用其字节流表示形式填充另一个数据框。
- en: Use the countries dataframe as a slicer with a single choice.
  id: totrans-271
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用包含国家的数据框作为单选切片器。
- en: Each time a country is selected from the slicer, the Python visual will deserialize
    the byte stream into the input dataframe and it will display the plot of the time
    series of the population growth of that country.
  id: totrans-272
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每次从切片器中选择一个国家时，Python 可视化将反序列化字节流到输入数据框中，并显示该国人口增长的时间序列图。
- en: '**Important Note**'
  id: totrans-273
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**重要提示**'
- en: ''
  id: totrans-274
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Also, in this case, when you select more than one column from more than one
    table in the Power BI data model (there must be a relationship between them) as
    values of a Python visual, these values *will form a single dataframe (deduplicated)*
    to be referenced in the Python script of the Visual.
  id: totrans-275
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 此外，在这种情况下，当你从 Power BI 数据模型中的多个表（它们之间必须有关系）中选择多个列作为 Python 可视化的值时，这些值 *将形成一个单一的数据框（去重后）*，在视觉的
    Python 脚本中引用。
- en: 'In addition, the same suggestion as was made for the R dataframe input applies:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，适用于 R 数据框输入的相同建议也适用：
- en: '**Tip**'
  id: totrans-277
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**技巧**'
- en: ''
  id: totrans-278
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In some cases, you may want to *not delete duplicate rows*. In that case, you
    can add an index field to your Pandas dataset (row number) that causes all rows
    to be considered unique and prevents grouping.
  id: totrans-279
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在某些情况下，你可能不想 *删除重复行*。在这种情况下，你可以在你的 Pandas 数据集中添加一个索引字段（行号），这将使所有行都被视为唯一，并防止分组。
- en: 'Again, even the Python visuals add a size limitation to the data it imports
    that appears to be undocumented:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，即使是 Python 可视化也对其导入的数据添加了一个似乎未记录的大小限制：
- en: '**Important Note**'
  id: totrans-281
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**重要提示**'
- en: ''
  id: totrans-282
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: If a string is longer than 32,766 characters, *it is truncated* once passed
    into the input dataframe of a Python visual. To avoid truncation, we need to split
    the string into chunks of 32,000 characters each (this is an arbitrary value chosen
    by us) and persist these chunks in a column of the dataframe before using the
    data in the Python visual.
  id: totrans-283
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果字符串长度超过 32,766 个字符，*它将被截断*，一旦传递到 Python 可视化的输入数据框中。为了避免截断，我们需要将字符串分成每个 32,000
    个字符的块（这是我们选择的任意值），并在使用 Python 可视化中的数据之前将这些块持久化到数据框的列中。
- en: 'Here is the process summarised in a figure that contains the functions you
    will find in the code:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 这里用一张图总结了整个过程，图中包含了你将在代码中找到的函数：
- en: '![Figure 4.32 – Deserialize the PKL file content into a Python visual](img/file103.png)'
  id: totrans-285
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.32 – 将 PKL 文件内容反序列化为 Python 可视化](img/file103.png)'
- en: Figure 4.32 – Deserialize the PKL file content into a Python visual
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.32 – 将 PKL 文件内容反序列化为 Python 可视化
- en: 'In the following steps, we will not explain in detail all the Python functions
    used, simply because we will refer to the code shared in the GitHub repository
    associated with this book, where every single detail is commented. So, let''s
    get started:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下步骤中，我们不会详细解释所有使用的 Python 函数，仅仅因为我们将会参考与本书相关的 GitHub 仓库中共享的代码，其中每个细节都有注释。所以，让我们开始吧：
- en: Open Power BI Desktop and go to **Get data**, then **More…**, and then **Python
    Script** to import the PKL files.
  id: totrans-288
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开 Power BI Desktop，转到 **获取数据**，然后 **更多…**，然后 **Python 脚本** 以导入 PKL 文件。
- en: Open the `06-deserialize-plots-object-from-pkl-in-power-bi.py` file from the
    GitHub repository, copy the content, paste it into the Python script editor, changing
    the absolute path to the PKL file accordingly, and click **OK**.
  id: totrans-289
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 GitHub 仓库打开 `06-deserialize-plots-object-from-pkl-in-power-bi.py` 文件，复制内容，将其粘贴到
    Python 脚本编辑器中，相应地更改 PKL 文件的绝对路径，然后点击 **确定**。
- en: 'Power Query will detect three dataframes created in your script. Select only
    the `plots_df` (the one containing the chunks of byte strings of each plot) and
    selected `_countries_df` (the one containing the country names) dataframes:'
  id: totrans-290
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Power Query 将检测到你在脚本中创建的三个数据框。仅选择 `plots_df`（包含每个图表的字节字符串块的）和 selected `_countries_df`（包含国家名称的）数据框：
- en: '![Figure 4.33 – Selecting the two dataframes containing useful data](img/file104.png)'
  id: totrans-291
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 4.33 – 选择包含有用数据的两个数据框](img/file104.png)'
- en: Figure 4.33 – Selecting the two dataframes containing useful data
  id: totrans-292
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.33 – 选择包含有用数据的两个数据框
- en: Then click **Load**.
  id: totrans-293
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 然后点击 **加载**。
- en: 'Click on the **Data** icon in the left ribbon and then click on the **Manage
    relationships** button:'
  id: totrans-294
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在左侧工具栏中点击 **数据** 图标，然后点击 **管理关系** 按钮：
- en: '![Figure 4.34 – The Manage relationships button](img/file105.png)'
  id: totrans-295
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 4.34 – 管理关系按钮](img/file105.png)'
- en: Figure 4.34 – The Manage relationships button
  id: totrans-296
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.34 – 管理关系按钮
- en: 'The engine has automatically created the relationship between the two imported
    tables:'
  id: totrans-297
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 引擎已自动创建了两个导入表之间的关系：
- en: '![Figure 4.35 – Relationship between tables automatically detected](img/file106.png)'
  id: totrans-298
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 4.35 – 表格之间自动检测到的关系](img/file106.png)'
- en: Figure 4.35 – Relationship between tables automatically detected
  id: totrans-299
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.35 – 表格之间自动检测到的关系
- en: Click **Close** and go back to the report canvas using the **Report** icon in
    the left ribbon.
  id: totrans-300
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 点击 **关闭** 并使用左侧工具栏中的 **报告** 图标返回报告画布。
- en: 'Now click on the **Slicer** visual icon:'
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在点击 **Slicer** 可视化图标：
- en: '![Figure 4.36 – The Slicer visual icon](img/file107.png)'
  id: totrans-302
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 4.36 – Slicer 可视化图标](img/file107.png)'
- en: Figure 4.36 – The Slicer visual icon
  id: totrans-303
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.36 – Slicer 可视化图标
- en: 'Keeping the Slicer visual region selected into the canvas, click on the **selected_countries_df**
    table on the **Fields** panel and select the **country_name** field:'
  id: totrans-304
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在画布上保持 Slicer 可视化区域被选中，点击 **字段** 面板上的 **selected_countries_df** 表，并选择 **country_name**
    字段：
- en: '![Figure 4.37 – Select the country_name column for the Slicer visual](img/file108.png)'
  id: totrans-305
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 4.37 – 为 Slicer 可视化选择 country_name 列](img/file108.png)'
- en: Figure 4.37 – Select the country_name column for the Slicer visual
  id: totrans-306
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.37 – 为 Slicer 可视化选择 country_name 列
- en: Then click the **Format** icon of the Slicer as you did in the previous section
    and enable the **Single select** option. The Slicer visual will show all the country
    names contained in the **selected_countries_df** table. It is very important to
    set **Single select**, because *the logic inside the Python visual will manage
    the deserialization of a single plot*.
  id: totrans-307
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，像上一节那样点击Slicer的**格式**图标，并启用**单选**选项。Slicer可视化将显示包含在**selected_countries_df**表中的所有国家名称。设置**单选**非常重要，因为*Python可视化内部的逻辑将管理单个图表的反序列化*。
- en: 'Click on the report canvas in order to deselect the Slicer visual region and
    click on the **Python visual** icon:'
  id: totrans-308
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击报告画布以取消选择Slicer可视化区域，然后点击**Python可视化**图标：
- en: '![Figure 4.39 – The Python visual icon](img/file109.png)'
  id: totrans-309
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图4.39 – Python可视化图标](img/file109.png)'
- en: Figure 4.39 – The Python visual icon
  id: totrans-310
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图4.39 – Python可视化图标
- en: The usual **Enable script visuals** window pops up. Click on **Enable**.
  id: totrans-311
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 常见的**启用脚本可视化**窗口弹出。点击**启用**。
- en: 'Move and stretch the Python visual borders in order to cover almost all the
    report canvas. Keeping it selected, click on the **plots_df** table in the **Fields**
    panel and select all three `chunk_id`, `country_id`, and `plot_str` fields:'
  id: totrans-312
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 移动并拉伸Python可视化边框，以便几乎覆盖整个报告画布。保持选中状态，点击**字段**面板中的**plots_df**表，并选择所有三个`chunk_id`、`country_id`和`plot_str`字段：
- en: '![Figure 4.40 – Select the fields to use in the Python visual](img/file110.png)'
  id: totrans-313
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图4.40 – 选择在Python可视化中使用的字段](img/file110.png)'
- en: Figure 4.40 – Select the fields to use in the Python visual
  id: totrans-314
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图4.40 – 选择在Python可视化中使用的字段
- en: Feel free to turn the Python visual title off in the **Format** tab.
  id: totrans-315
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在**格式**选项卡中，你可以自由地关闭Python可视化标题。
- en: Open the `07-deserialize-plots-df-into-python-visual.py` file from the GitHub
    repository, copy the content, and paste it into the Python visual’s script editor.
    Then, click on the **Run** icon on the top right of the Python script editor.
  id: totrans-316
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从GitHub仓库打开`07-deserialize-plots-df-into-python-visual.py`文件，复制内容，并将其粘贴到Python可视化脚本编辑器中。然后，点击Python脚本编辑器右上角的**运行**图标。
- en: 'Now you can click on each country in the Slider in order to see the population
    time series:'
  id: totrans-317
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，你可以点击滑块中的每个国家，以查看人口时间序列：
- en: '![Figure 4.41 – Showing the population growth for Germany](img/file111.png)'
  id: totrans-318
  prefs: []
  type: TYPE_IMG
  zh: '![图4.41 – 显示德国的人口增长](img/file111.png)'
- en: Figure 4.41 – Showing the population growth for Germany
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.41 – 显示德国的人口增长
- en: Brilliant! You've just created a report using a methodology that few people
    in the world know about.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 太棒了！你刚刚使用了一种世界上很少有人知道的方法创建了一份报告。
- en: '**Important Note**'
  id: totrans-321
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**重要提示**'
- en: ''
  id: totrans-322
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This technique can be very useful when you need to build complex visualizations
    in Python that require the use of packages not provided by Python visuals in Power
    BI Service. These visualizations can be made offline, serialized to a file, and
    then used on a shared report on the service.
  id: totrans-323
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 当你需要使用Power BI服务中Python可视化未提供的包来构建复杂可视化时，这项技术非常有用。这些可视化可以离线制作，序列化到文件中，然后在该服务的共享报告中使用。
- en: Summary
  id: totrans-324
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you got to learn about the Tidyverse approach to R development
    and how to serialize R objects to files. After that, you learned how to use these
    serialized files, both in Power Query Editor and in R visuals.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你学习了Tidyverse方法在R开发中的应用，以及如何将R对象序列化到文件中。之后，你学习了如何在Power Query编辑器和R可视化中使用这些序列化文件。
- en: You then approached the same issues using Python. Specifically, you learned
    which packages are most used by the PyData community, learned how to serialize
    Python objects to files, and how to use them in Power BI, both in Power Query
    Editor and in Python visuals.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 你随后使用Python解决了相同的问题。具体来说，你学习了PyData社区最常用的包，学习了如何将Python对象序列化到文件中，以及如何在Power
    BI中（在Power Query编辑器和Python可视化中）使用它们。
- en: In the next chapter, you'll have a chance to learn how powerful regular expressions
    and fuzzy string matching are and what benefits they can bring to your Power BI
    reports.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，你将有机会了解正则表达式和模糊字符串匹配有多么强大，以及它们可以为你的Power BI报告带来哪些好处。
- en: References
  id: totrans-328
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'For additional reading, check out the following books and articles:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 对于额外的阅读，请参阅以下书籍和文章：
- en: '*“An Introduction to R” by R Core* ([https://cran.r-project.org/doc/manuals/r-release/R-intro.html](https://cran.r-project.org/doc/manuals/r-release/R-intro.html)).'
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*《R入门》* by R Core ([https://cran.r-project.org/doc/manuals/r-release/R-intro.html](https://cran.r-project.org/doc/manuals/r-release/R-intro.html))。'
- en: '*“R for Data Science”* by Hadley Wickham ([https://r4ds.had.co.nz/index.html](https://r4ds.had.co.nz/index.html)).'
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*《数据科学中的R》* by Hadley Wickham ([https://r4ds.had.co.nz/index.html](https://r4ds.had.co.nz/index.html))。'
- en: '*“Machine Learning with R: Expert techniques for predictive modeling, 3rd Edition”*
    by Brett Lantz, Packt Publishing ([https://www.packtpub.com/product/mastering-machine-learning-with-r-third-edition/9781789618006](https://www.packtpub.com/product/mastering-machine-learning-with-r-third-edition/9781789618006)).'
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*《使用R进行机器学习：预测建模的高级技巧，第3版》* 由Brett Lantz著，Packt Publishing出版 ([https://www.packtpub.com/product/mastering-machine-learning-with-r-third-edition/9781789618006](https://www.packtpub.com/product/mastering-machine-learning-with-r-third-edition/9781789618006)).'
