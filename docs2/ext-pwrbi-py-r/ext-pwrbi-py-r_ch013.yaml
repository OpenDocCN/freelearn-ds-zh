- en: '12 Adding Statistics Insights: Outliers and Missing Values'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 12 添加统计洞察：异常值和缺失值
- en: In an effort to extend the data enrichment possibilities in Power BI through
    statistical functions, we will explore some methodologies to detect univariate
    and multivariate outliers in your dataset. In addition, advanced methodologies
    to impute possible missing values in datasets and time-series will be explored.
    Knowledge of these techniques is critical for the experienced analyst because
    Power BI does not provide useful tools for this purpose by default.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 为了通过统计函数扩展Power BI中的数据丰富可能性，我们将探讨一些在您的数据集中检测单变量和多变量异常值的方法。此外，还将探讨在数据集和时间序列中插补可能缺失值的高级方法。对于经验丰富的分析师来说，了解这些技术至关重要，因为Power
    BI默认不提供此类目的的有用工具。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: What outliers are and how to deal with them
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 异常值是什么以及如何处理它们
- en: Identifying outliers
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别异常值
- en: Implementing outlier detection algorithms
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实施异常值检测算法
- en: What missing values are and how to deal with them
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缺失值是什么以及如何处理它们
- en: Diagnosing missing values
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 诊断缺失值
- en: Implementing missing value imputation algorithms
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实施缺失值插补算法
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 技术要求
- en: This chapter requires you to have a working internet connection and **Power
    BI Desktop** installed on your machine. You must have properly configured the
    R and Python engines and IDEs as outlined in *Chapter 2, Configuring R With Power
    BI*, and *Chapter 3, Configuring Python with Power BI*.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章要求您拥有有效的互联网连接，并在您的机器上安装**Power BI桌面版**。您必须已按照*第2章，配置Power BI中的R*和*第3章，配置Power
    BI中的Python*中概述的配置了R和Python引擎以及IDE。
- en: What outliers are and how to deal with them
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 异常值是什么以及如何处理它们
- en: Generally, outliers are defined as those observations that lie at an *abnormal
    distance* from other observations in a data sample. In other words, they are *uncommon
    values* in a dataset. The abnormal distance we're talking about obviously doesn't
    have a fixed measurement but is strictly dependent on the dataset you're analyzing.
    Simply put, it will be the analyst who decides the distance beyond which to consider
    other abnormal distances based on their experience and functional knowledge of
    the business reality represented by the dataset.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，异常值被定义为那些与其他数据样本中的观察值距离异常远的观察值。换句话说，它们是数据集中的*不常见值*。我们所说的异常距离显然没有固定的测量标准，而是严格依赖于您正在分析的数据集。简单来说，这将由分析师根据他们的经验和业务现实的功能知识来决定，即基于数据集的异常距离，超过这个距离将考虑其他异常距离。
- en: '**Important Note**'
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**重要提示**'
- en: ''
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: It makes sense to talk about outliers for numeric variables or for numeric variables
    grouped by elements of categorical variables. It makes no sense to talk about
    outliers for categorical variables only.
  id: totrans-15
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 对于数值变量或按分类变量的元素分组的数值变量来说，讨论异常值是有意义的。仅对分类变量讨论异常值是没有意义的。
- en: 'But why is there so much focus on managing outliers? The answer is that very
    often they cause undesirable macroscopic effects on some statistical operations.
    The most striking example is that of a linear correlation in the presence of an
    outlier in an "uncomfortable" position and the same calculated by eliminating
    the outlier:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 但为什么会有这么多关注于管理异常值？答案是，它们往往会对某些统计操作产生不希望看到的宏观影响。最显著的例子是在“不舒服”位置存在异常值时的线性相关，以及消除异常值后计算出的相同结果：
- en: '![Figure 12.1 – A simple scatterplot](img/file304.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![图12.1 – 一个简单的散点图](img/file304.png)'
- en: Figure 12.1 – A simple scatterplot
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.1 – 一个简单的散点图
- en: 'As is evident in *Figure 12.1* and from what you learned from *Chapter 11,
    Adding Statistics Insights: Associations*, Pearson''s correlation *r* suffers
    greatly from outliers.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 如*图12.1*所示，以及从*第11章，添加统计洞察：关联*中学到的，皮尔逊相关系数*r*很容易受到异常值的影响。
- en: But then, is it always sufficient to remove outliers *apriori* in order to solve
    any problems you might find downstream in your analysis? As you can imagine, the
    answer is “no,” because it all depends on the type of outlier you are dealing
    with.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 但然后，是否总是足够通过**事先**移除异常值来解决您在分析中可能遇到的问题？正如您所想象的那样，答案是“不”，因为这完全取决于您正在处理的异常值类型。
- en: The causes of outliers
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 异常值产生的原因
- en: 'Before considering any action to be applied to the outliers of a variable,
    it is necessary to consider what might have generated them. Once the cause is
    established, it may be immediate to fix the outliers. Here is a possible categorization
    of the causes of outliers:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在考虑对变量的异常值采取任何行动之前，有必要考虑可能产生它们的原因。一旦确定了原因，可能立即就可以修复异常值。以下是可能的原因分类：
- en: '**Data entry errors**: There may be an analyst collecting the data who made
    mistakes compiling it. If the analyst is collecting the birth dates of a group
    of people, it may be, for example, that instead of writing 1977, they write 177\.
    If the dates that they have collected belong to the range from 1900 to 2100, it
    is quite easy to correct the outlier that has been created due to the entry error.
    Other times, it is not possible to recover the correct value.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据录入错误**：可能存在一个分析师在收集数据时犯了错误。例如，如果一个分析师正在收集一组人的出生日期，他们可能会错误地写成177而不是1977。如果他们收集的日期属于1900到2100的范围，那么纠正由于录入错误而造成的异常值相当容易。在其他情况下，可能无法恢复正确的值。'
- en: '**Intentional outliers**: Very often, the introduction of "errors" is intentional
    by the individuals to whom the measurements apply. For example, adolescents typically
    do not accurately report the amount of alcohol they consume.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**有意异常值**：非常常见的是，受测量影响的个人有意引入“错误”。例如，青少年通常不会准确报告他们消费的酒精量。'
- en: '**Data processing errors**: Data transformation processes that are usually
    applied to analytics solutions can introduce unintended errors, which in turn
    can give rise to possible outliers.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据处理错误**：通常应用于分析解决方案的数据转换过程可能会引入意外的错误，这反过来又可能导致可能的异常值。'
- en: '**Sampling errors**: Sometimes, the data on which you perform your analysis
    must be sampled from a much larger dataset. It may be in this case that the analyst
    does not select a subset of data representing the entire population of data. For
    example, you need to measure the height of athletes, and, by mistake, you include
    some basketball players in your dataset.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**抽样误差**：有时，你进行分析的数据必须是从一个更大的数据集中抽取的样本。在这种情况下，分析师可能没有选择代表整个数据集总体的数据子集。例如，你需要测量运动员的身高，但错误地包括了某些篮球运动员在你的数据集中。'
- en: '**Natural outliers**: So-called “natural” outliers exist because they are part
    of the nature of business and are not the result of any kind of error. For example,
    it''s pretty much a given that shopping malls sell more products at Christmas
    time.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自然异常值**：所谓的“自然”异常值存在，因为它们是商业性质的一部分，而不是任何错误的结果。例如，圣诞节期间购物中心销售更多产品几乎是肯定的。'
- en: Once the nature of specific outliers is identified, it is certainly easier to
    try to correct them as much as possible. How do we proceed? There are a few common
    ways to correct outliers that can be considered.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦确定了特定异常值的性质，当然更容易尝试尽可能多地纠正它们。我们如何进行？有一些常见的纠正异常值的方法可以考虑。
- en: Dealing with outliers
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 处理异常值
- en: 'The most widely used approaches to deal with outliers are as follows:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 处理异常值的最常用方法如下：
- en: '**Dropping them**: The analyst concludes that eliminating the outliers altogether
    guarantees better results in the final analysis.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**删除它们**：分析师得出结论，完全消除异常值可以保证最终分析结果更好。'
- en: '**Capping them**: It is common to use the strategy of assigning a fixed extreme
    value (cap) to all those observations that exceed it (in absolute value) when
    it is certain that all extreme observations behave in the same way as those with
    the cap value.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对它们进行上限处理**：当确定所有极端观测值的行为与具有上限值的观测值相同的情况下，通常会对超过该值（绝对值）的所有观测值分配一个固定的极端值（上限）。'
- en: '**Assigning a new value**: In this case, outliers are eliminated by replacing
    them with null values, and these null values are imputed using one of the simplest
    techniques: the replacement of null values with a fixed value that could be, for
    example, the mean or median of the variable in question. You''ll see more complex
    imputation strategies in the next sections.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分配新值**：在这种情况下，通过用空值替换异常值来消除异常值，并使用最简单的一种技术对这些空值进行估计：用固定值替换空值，例如，可以是所讨论变量的均值或中位数。你将在下一节中看到更复杂的估计策略。'
- en: '**Transforming the data**: When the analyst is dealing with natural outliers,
    very often the histogram of the variable''s distribution takes on a skewed shape.
    Right-skewed distributions are very common, and if they were used as they appeared,
    many statistical tests that assume a normal distribution would give incorrect
    results. In this case, it is often used to transform the variable by applying
    a monotonic function, which in some way "straightens out" the imbalance (this
    is the case of the `log()` function, for example). Once transformed, the new variable
    satisfies the requirements of the tests and can therefore be analyzed without
    errors. Once the results have been obtained from the transformed variable, they
    must be transformed again by the inverse function of the one used at the beginning
    (if `log()` was used, then the inverse is `exp()`) in order to have values that
    are consistent with the business variable under analysis.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**转换数据**：当分析师处理自然异常值时，变量分布的直方图往往呈现出偏斜的形状。右偏分布非常常见，如果直接使用这些分布，许多假设正态分布的统计测试将给出错误的结果。在这种情况下，通常通过应用单调函数来转换变量，这种方式在某种程度上“校正”了不平衡（例如，`log()`
    函数就是这样）。一旦转换，新的变量满足测试的要求，因此可以无错误地进行分析。一旦从转换后的变量中获得结果，必须使用最初使用的函数的逆函数再次转换（如果使用了
    `log()`，则逆函数是 `exp()`），以便得到与所分析的业务变量一致的价值。'
- en: Now that you know the most common ways of dealing with outliers, you need to
    figure out how to identify them.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经了解了处理异常值最常见的方法，你需要弄清楚如何识别它们。
- en: Identifying outliers
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 识别异常值
- en: There are different methods used to detect outliers depending on whether you
    are analyzing one variable at a time (**univariate analysis**) or multiple variables
    at once (**multivariate analysis**). In the univariate case, the analysis is fairly
    straightforward. The multivariate case, however, is more complex. Let's examine
    them in detail.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 根据你是逐个分析变量（**单变量分析**）还是同时分析多个变量（**多元分析**），有不同的方法用于检测异常值。在单变量情况下，分析相对简单。然而，多元情况则更为复杂。让我们详细考察它们。
- en: Univariate outliers
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 单变量异常值
- en: 'One of the most direct and widely used ways to identify outliers for a single
    variable is to make use of boxplots, which you learned about in *Chapter 11, Adding
    Statistics Insights: Associations*. Some of the key points of a boxplot are the
    **interquartile range** (**IQR**), defined as the distance from the **first quartile**
    (**Q1**) to the **third quartile** (**Q3**), the **lower whisker** (Q1 - 1.5 x
    IQR), and the **upper whisker** (Q3 + 1.5 x IQR):'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 识别单个变量的异常值最直接且广泛使用的方法之一是利用箱形图，这是你在*第11章，添加统计洞察：关联*中学到的。箱形图的一些关键点是**四分位距**（**IQR**），定义为从**第一四分位数**（**Q1**）到**第三四分位数**（**Q3**）的距离，**下须**（Q1
    - 1.5 x IQR），和**上须**（Q3 + 1.5 x IQR）：
- en: '![Figure 12.2 – Boxplot’s main characteristics](img/file305.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![图12.2 – 盒形图的主要特征](img/file305.png)'
- en: Figure 12.2 – Boxplot’s main characteristics
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.2 – 盒形图的主要特征
- en: Specifically, all observations that are before the lower whisker and after the
    upper whisker are identified as outliers. This one is also known as **Tukey’s
    method**.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，所有在下须之前和上须之后的观测值都被识别为异常值。这也被称为**图基方法**。
- en: Identification becomes more complicated when dealing with more than one variable.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 当处理多个变量时，识别变得更加复杂。
- en: Multivariate outliers
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 多元异常值
- en: Identifying outliers when you are handling more than one variable (**multivariate
    outliers**) is not always straightforward. It depends on the number of variables
    in play and their data type.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 当你处理多个变量（**多元异常值**）时，识别异常值并不总是直接的。这取决于涉及的变量数量和数据类型。
- en: Numeric variable and categorical variable
  id: totrans-46
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 数值变量和分类变量
- en: 'As long as you need to analyze how a numerical variable is distributed among
    the different elements of a categorical variable, it is still feasible with the
    tools seen so far. In fact, just plot a boxplot for the values of the numeric
    variable grouped by each element of the categorical variable:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 只要你需要分析数值变量如何在分类变量的不同元素之间分布，使用到目前为止看到的工具仍然是可行的。事实上，只需为按分类变量的每个元素分组的数值变量的值绘制箱形图即可：
- en: '![Figure 12.3 – Numeric versus categorical variables](img/file306.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![图12.3 – 数值变量与分类变量](img/file306.png)'
- en: Figure 12.3 – Numeric versus categorical variables
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.3 – 数值变量与分类变量
- en: In fact, it may be that the numerical variable does not present any outliers
    but reveals some when it is broken down by the elements of the categorical variable.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，可能数值变量本身并没有显示出任何异常值，但当它被按分类变量的元素分解时，却揭示了一些异常值。
- en: All numeric variables
  id: totrans-51
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 所有数值变量
- en: Generally, the inexperienced analyst tends to simplify the determination of
    outliers in multidimensional cases when there are only numeric variables.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，没有经验的分析师在只有数值变量的情况下，倾向于简化多维情况中异常值的确定。
- en: '**Important Note**'
  id: totrans-53
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**重要提示**'
- en: ''
  id: totrans-54
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'One might assume that an observation that is extreme in any variable is also
    a multivariate outlier, and this is often true. However, the opposite is not true:
    when variables are correlated, one can have a multivariate outlier that is not
    a univariate outlier in any variable.'
  id: totrans-55
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 一个人可能会假设在任何变量中极端的观测值也是多变量异常值，这通常是正确的。然而，情况并非总是如此：当变量相关时，可以有一个在任一变量中都不是单变量异常值的多变量异常值。
- en: 'When dealing with only numeric variables, it is still possible to use algorithms
    that measure the distance from the center of the distribution. Let''s take the
    case of two numerical variables, which allows us to visualize the outliers using
    a scatterplot:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 当只处理数值变量时，仍然可以使用测量分布中心距离的算法。让我们以两个数值变量的情况为例，这使我们能够通过散点图可视化异常值：
- en: '![Figure 12.4 – Scatterplot of two numeric variables](img/file307.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![图12.4 – 两个数值变量的散点图](img/file307.png)'
- en: Figure 12.4 – Scatterplot of two numeric variables
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.4 – 两个数值变量的散点图
- en: As you can see in *Figure 12.4*, we have also added in the margin the two boxplots
    for every single variable under analysis to verify that for each of them there
    are no outliers, except for the one detected at the bottom. You can also see that
    there is one outlier that is clearly different from all other observations but
    is not detected as an outlier by the two boxplots.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在*图12.4*中可以看到的，我们在边缘也添加了每个分析变量的两个箱线图，以验证对于每一个，都没有异常值，除了底部检测到的那个。你还可以看到有一个异常值，它显然与其他所有观测值不同，但并未被两个箱线图检测到。
- en: 'Imagine fixing a hypothetical center of the distribution and defining a distance
    from the center (Euclidean distance) above which the observations are to be considered
    outliers:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下固定一个假设的分布中心，并定义一个距离（欧几里得距离），超过这个距离的观测值将被认为是异常值：
- en: '![Figure 12.5 – Euclidean distance from the center of the distribution](img/file308.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![图12.5 – 分布中心的欧几里得距离](img/file308.png)'
- en: Figure 12.5 – Euclidean distance from the center of the distribution
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.5 – 分布中心的欧几里得距离
- en: The above rule defines a circle centered at the center of the distribution.
    Considering a circle with the radius you see in *Figure 12.5*, you are going to
    identify several outliers (perhaps false positives?) that were not identified
    by looking at the boxplots alone, but the outlier you failed to identify before
    remains unidentified in this case as well. As you can well understand, the problem
    is that the distribution has an ellipsoidal shape that is distributed along the
    main diagonal of the Cartesian plane. Using a circle is certainly ill-suited to
    fit a distribution of a different shape.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 上述规则定义了一个以分布中心为中心的圆。考虑到*图12.5*中看到的半径，你将识别出一些（可能是假阳性？）异常值，这些异常值仅通过查看箱线图是无法识别的，但之前未能识别的异常值在此情况下仍然未被识别。正如你可以很好地理解的那样，问题是分布具有沿笛卡尔平面主对角线分布的椭圆形形状。使用圆形来拟合不同形状的分布显然是不合适的。
- en: 'What if there was a distance that also considered the shape of the distribution?
    This is precisely the case with the **Mahalanobis distance**. This new distance
    differs from the others because it considers the **covariance** between the two
    variables. Covariance and Pearson’s correlation are two quantities associated
    with very similar concepts, so in some cases they are interchangeable (take a
    look at the references). The fact that the Mahalanobis distance accounts for the
    correlation between the two variables is evident in *Figure 12.6*:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 如果有一种距离同时考虑了分布的形状呢？这正是**马氏距离**的情况。这种新的距离与其他距离的不同之处在于它考虑了两个变量之间的**协方差**。协方差和皮尔逊相关系数是与非常相似的概念相关的两个量，因此在某些情况下它们可以互换（参考相关文献）。马氏距离考虑两个变量之间的相关性的事实在*图12.6*中显而易见：
- en: '![Figure 12.6 – Mahalanobis distance from the center of the distribution](img/file309.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![图12.6 – 分布中心的马氏距离](img/file309.png)'
- en: Figure 12.6 – Mahalanobis distance from the center of the distribution
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.6 – 分布中心的马氏距离
- en: 'For the curious, this is the formula to calculate it:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 对于好奇者，这是计算它的公式：
- en: '![Figure 12.7 – Mahalanobis distance formula](img/file310.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![图12.7 – 马氏距离公式](img/file310.png)'
- en: Figure 12.7 – Mahalanobis distance formula
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.7 – 马氏距离公式
- en: 'is a multivariate observation, is the multivariate mean of all observations,
    and *S* is the covariance matrix. The fact that the Mahalanobis distance depends
    on the mean of all observations (a very unstable measure, very sensitive to outliers)
    and the covariance matrix makes you realize that the same limitations encountered
    for the Pearson’s coefficient apply, which are as follows:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 是一个多变量观察值，是所有观察值的多变量均值，*S* 是协方差矩阵。马氏距离依赖于所有观察值的均值（一个非常不稳定的度量，对异常值非常敏感）和协方差矩阵，这让你意识到对于皮尔逊系数遇到的相同限制也适用，如下所示：
- en: Possible outliers at inconvenient locations could greatly affect the multivariate
    center defined by the mean of all observations. If the center is not well calculated,
    it is very likely that the resulting application of the Mahalanobis distance will
    identify erroneous outliers. This is easily solved by computing the center via
    a median-based formula, which is much more robust to the presence of extreme observations.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在不便利的位置出现的可能异常值可能会极大地影响由所有观察值的均值定义的多变量中心。如果中心计算不当，那么使用马氏距离的结果很可能识别出错误的异常值。这个问题可以通过通过基于中位数的方法计算中心来解决，这种方法对极端观察值的出现更加稳健。
- en: If extreme outliers are present, the covariance matrix may also be negatively
    affected. This problem is also solved by adopting a robust version of the covariance
    matrix using the **Minimum Covariance Determinant** (**MCD**). This method, in
    addition to providing a robust covariance matrix, also returns a robust estimate
    of the center of the observations.
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果存在极端异常值，协方差矩阵也可能受到负面影响。这个问题也可以通过采用协方差矩阵的稳健版本（**最小协方差行列式**，**MCD**）来解决。除了提供稳健的协方差矩阵外，这种方法还返回观察值中心的稳健估计。
- en: It is very likely that the usage of the Mahalanobis distance will return false
    outliers in case of *skewed*, *nonlinear*, or *heteroscedastic* distributions.
    These are the cases in which it is necessary to resort to transformations of the
    variables involved, as far as possible, before applying distance calculations.
    The goal of the transformations is to obtain distributions that are as normal
    as possible and to make the associations between the various variables as linear
    as possible. In these cases, **Box-Cox transformations** or **Yeo-Johnson transformations**
    are used.
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在存在偏斜、非线性或异方差分布的情况下，使用马氏距离很可能返回错误的异常值。在这些情况下，有必要在应用距离计算之前尽可能地对涉及的变量进行变换。变换的目标是获得尽可能正常的分布，并使各种变量之间的关联尽可能线性。在这些情况下，使用**Box-Cox变换**或**Yeo-Johnson变换**。
- en: The identification of outliers becomes much more complicated when dealing with
    mixed variables (numerical and categorical) in numbers greater than two. It is
    necessary to use different data science techniques (feature engineering techniques
    for categorical variables, handling of unbalanced datasets, and so on) and to
    apply specific machine learning anomaly detection algorithms. For this reason,
    cases of this type are out of scope.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 当处理大于两个的混合变量（数值和分类变量）时，识别异常值变得更加复杂。有必要使用不同的数据科学技术（用于分类变量的特征工程技术、处理不平衡数据集等）并应用特定的机器学习异常检测算法。因此，这类情况超出了范围。
- en: Once the outliers (both univariate and multivariate) are identified, it is up
    to the analyst to decide which method to adopt to try to fix it, if possible.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦识别出异常值（单变量和多变量），分析师就有责任决定采用哪种方法来尝试修复它，如果可能的话。
- en: Let's now see how to implement outlier detection algorithms according to what
    you learned in the previous sections.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看看如何根据前面章节中学到的知识来实现异常检测算法。
- en: Implementing outlier detection algorithms
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实现异常检测算法
- en: The first thing you'll do is implement what you've just studied in Python.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 你首先需要做的是在Python中实现你刚刚学到的内容。
- en: Implementing outlier detection in Python
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在Python中实现异常检测
- en: In this section, we will use the *Wine Quality* dataset created by Paulo Cortez
    et al. ([https://archive.ics.uci.edu/ml/datasets/wine+quality](https://archive.ics.uci.edu/ml/datasets/wine+quality))
    to show how to detect outliers in Python. The dataset contains as many observations
    as the different types of red wine, each described by the organoleptic properties
    measured by the variables, except for the `quality` one, which provides a measure
    of the quality of the product using a discrete grade scale from 1 to 10.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用由 Paulo Cortez 等人创建的 *Wine Quality* 数据集（[https://archive.ics.uci.edu/ml/datasets/wine+quality](https://archive.ics.uci.edu/ml/datasets/wine+quality)）来展示如何在
    Python 中检测异常值。该数据集包含与不同类型的红葡萄酒一样多的观测值，每种红葡萄酒都由变量测量的感官特性描述，除了 `quality` 变量，它使用从
    1 到 10 的离散等级尺度来衡量产品的质量。
- en: You'll find the code used in this section in the `01-detect-outliers-in-python.py`
    file into the `Chapter12\Python` folder.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在 `Chapter12\Python` 文件夹中的 `01-detect-outliers-in-python.py` 文件中找到本节使用的代码。
- en: 'Once you have loaded the data from the `winequality-red.csv` file directly
    from the web into the `df` variable, let''s start by examining the `sulphates`
    variable. Let''s check if it contains any outliers by displaying its boxplot,
    which was obtained through a wrapper function that we have defined in the code:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您将来自 `winequality-red.csv` 文件的数据直接加载到 `df` 变量中，让我们首先检查 `sulphates` 变量。让我们通过显示其箱线图来检查它是否包含任何异常值，该箱线图是通过我们定义在代码中的包装函数获得的：
- en: '![Figure 12.8 – Sulphates boxplot](img/file311.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![图 12.8 – 硫酸盐箱线图](img/file311.png)'
- en: Figure 12.8 – Sulphates boxplot
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.8 – 硫酸盐箱线图
- en: 'Apparently there are plenty of values after 1.0\. To be able to locate them
    in the dataset, we created a function that accepts a dataframe as input and the
    name of the numeric column to be considered, and as output returns the dataframe
    with the addition of a column of Boolean values, containing `True` when the value
    of the column is an outlier, and `False` otherwise:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，在 1.0 之后有很多值。为了能够在数据集中定位它们，我们创建了一个函数，该函数接受一个数据框作为输入以及要考虑的数值列的名称，作为输出返回添加了布尔值列的数据框，当列的值为异常值时包含
    `True`，否则为 `False`：
- en: '[PRE0]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Once we have identified the outliers of the initial distribution of the `sulphates`
    variable, we can draw its boxplot by removing the outliers to see what changes:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们确定了 `sulphates` 变量的初始分布的异常值，我们可以通过移除异常值来绘制其箱线图，以查看发生了什么变化：
- en: '[PRE1]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The resulting boxplot is as follows:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 结果箱线图如下：
- en: '![Figure 12.9 – Sulphates boxplot once outliers were removed](img/file312.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![图 12.9 – 移除异常值后的硫酸盐箱线图](img/file312.png)'
- en: Figure 12.9 – Sulphates boxplot once outliers were removed
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.9 – 移除异常值后的硫酸盐箱线图
- en: As you can see, some outliers are still visible. This is due to the fact that
    removing the outliers from the initial distribution caused the distribution to
    change (its statistical properties changed). So, what you see in *Figure 12.9*
    are the outliers of the new distribution that was created.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，一些异常值仍然可见。这是由于从初始分布中移除异常值导致分布发生变化（其统计特性发生了变化）。因此，*图 12.9* 中显示的是新创建的分布的异常值。
- en: 'As already explained, it is up to the analyst to figure out if the outliers
    identified can be corrected in some way, eliminated, or left where they are. Suppose
    in this case that the outliers in the second distribution are natural outliers.
    Let''s try to break the new distribution down to the individual values of the
    `quality` variable and draw a boxplot for each of them:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，分析师需要确定识别出的异常值是否可以以某种方式纠正、消除或保留在原处。假设在这种情况下，第二个分布中的异常值是自然异常值。让我们尝试将新的分布分解为
    `quality` 变量的单个值，并为每个值绘制一个箱线图：
- en: '![Figure 12.10 – Sulphates boxplots for each quality value](img/file313.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![图 12.10 – 每个质量值的硫酸盐箱线图](img/file313.png)'
- en: Figure 12.10 – Sulphates boxplots for each quality value
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.10 – 每个质量值的硫酸盐箱线图
- en: As shown in *Figure 12.10*, the distribution of sulphates for wines that received
    a grade of 5 has several outliers. This could induce the analyst to try to understand
    how much the presence of sulphates affects the final rating given by users to
    the wine, paying particular attention to the case of a wine considered of average
    quality.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 如 *图 12.10* 所示，获得 5 等级的葡萄酒的硫酸盐分布有几个异常值。这可能会促使分析师试图了解硫酸盐的存在对用户给予葡萄酒的最终评分影响有多大，特别关注到被认为是平均质量的葡萄酒的情况。
- en: 'If, on the other hand, we wanted to identify multivariate outliers for all
    numerical variables in the dataset, excluding the quality variable, we need to
    change our approach by trying to apply the Mahalanobis distance, as you learned
    in the previous section. We assume that the elimination of outliers for each individual
    variable has been validated. So, let’s now try to figure out if multivariate outliers
    are present for the numeric variables in the `df_no_outliers’` dataframe. First,
    however, it is necessary to check whether the distributions of the variables under
    analysis are skewed. Therefore, we try to draw a histogram for each of the variables:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，如果我们想识别数据集中所有数值变量的多元异常值，排除质量变量，我们需要改变方法，尝试应用马氏距离，正如你在上一节中学到的。我们假设每个变量的异常值消除已经得到验证。因此，现在让我们尝试确定`df_no_outliers`数据框中的数值变量是否存在多元异常值。首先，然而，有必要检查分析变量的分布是否偏斜。因此，我们尝试为每个变量绘制直方图：
- en: '[PRE2]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The resulting plot is as follows:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 结果的图表如下：
- en: '![Figure 12.11 – Histograms of all the wine quality variables without outliers](img/file314.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![图12.11 – 无异常值的所有葡萄酒质量变量的直方图](img/file314.png)'
- en: Figure 12.11 – Histograms of all the wine quality variables without outliers
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.11 – 无异常值的所有葡萄酒质量变量的直方图
- en: It is evident that some of them are extremely right-skewed (*residual sugar*,
    *chlorides*, *total sulfur dioxide*, etc.), therefore it is necessary to try to
    apply transformations that attempt to “normalize” the single distributions. Generally,
    *Box-Cox transformations* are applied. But since in this case some values of the
    distributions are not positive, it is not possible to apply them. It is therefore
    necessary to use other transformations that have the same objective, named *Yeo-Johnson*.
    For more details on these transformations, check out the references.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 很明显，其中一些变量（如*残留糖分*、*氯化物*、*总二氧化硫*等）极端右偏斜，因此有必要尝试应用尝试“标准化”单个分布的变换。通常，应用*Box-Cox变换*。但由于在这种情况下，分布的一些值不是正数，因此无法应用它们。因此，有必要使用其他具有相同目标的变换，称为*Yeo-Johnson*。有关这些变换的更多详细信息，请参阅参考文献。
- en: 'For convenience, we created a wrapper function that transforms a pandas dataframe
    of only numeric variables by applying Yeo-Johnson transformations and also returns
    the corresponding lambda values:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 为了方便起见，我们创建了一个包装函数，该函数通过应用Yeo-Johnson变换将仅包含数值变量的pandas数据框进行转换，并返回相应的lambda值：
- en: '[PRE3]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Then, once you''ve transformed the dataframe into an object, you can try drawing
    histograms of the distributions of the transformed variables to see if the skewness
    has been smoothed out:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，一旦将数据框转换成对象，你可以尝试绘制变换后变量的分布直方图，以查看偏斜是否已经平滑：
- en: '[PRE4]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'This is the plot you get:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 这是你得到的图表：
- en: '![Figure 12.12 – Histograms of all the wine quality variables transformed](img/file315.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![图12.12 – 所有葡萄酒质量变量变换后的直方图](img/file315.png)'
- en: Figure 12.12 – Histograms of all the wine quality variables transformed
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.12 – 所有葡萄酒质量变量变换后的直方图
- en: It is quite evident that now the distributions look more like the "bells" of
    normal distributions. You can now calculate Mahalanobis distances with the surety
    that it will detect outliers with fewer errors.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 很明显，现在分布看起来更像是正态分布的“钟形”。现在你可以计算马氏距离，有把握它会以更少的错误检测到异常值。
- en: 'The identification of outliers is done using a robust estimator of covariance,
    the *MCD*. Since the squared Mahalanobis distance behaves as a Chi-Squared distribution
    (see the references), we can calculate the threshold value above which to consider
    an observation an outlier thanks to this distribution, passing the desired cutoff
    value to its *percent point function* (`ppf()`):'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 异常值的识别使用的是协方差的鲁棒估计器，即*MCD*。由于平方马氏距离的行为类似于卡方分布（见参考文献），我们可以通过传递给其*百分位数函数*（`ppf()`）所需的截止值来计算高于该值的阈值，将其视为异常值：
- en: '[PRE5]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Once you have determined the threshold value, you can add two columns to the
    dataframe: a column that identifies whether the observation (the row) is an outlier
    according to Mahalanobis and a column that reports the probability that an observation
    is not an outlier by chance:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦确定了阈值值，你可以在数据框中添加两列：一列用于标识观察值（行）是否为马氏距离的异常值，另一列报告观察值非异常值的概率：
- en: '[PRE6]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'You''ll see a dataframe chunk like this:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 你将看到一个类似以下的数据框块：
- en: '![Figure 12.13 – Outliers information shown in the dataframe](img/file316.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![图12.13 – 数据框中显示的异常值信息](img/file316.png)'
- en: Figure 12.13 – Outliers information shown in the dataframe
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.13 – 数据框中显示的异常值信息
- en: Wow! With a minimum of statistics knowledge, you were able to identify multivariate
    outliers of numeric variables in Python.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 哇！仅凭最少的统计学知识，您就能在Python中识别出数值变量的多元异常值。
- en: It is possible to get the same results with R. Let's see how.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 使用R也可以得到相同的结果。让我们看看如何做到。
- en: Implementing outlier detection in R
  id: totrans-120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在R中实现异常值检测
- en: 'You''ll find the code used in this section in the `01-detect-outliers-in-r.R`
    file in the `Chapter12\R` folder. In order to run it properly, you need to install
    new packages:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在`Chapter12\R`文件夹中的`01-detect-outliers-in-r.R`文件中找到本节使用的代码。为了正确运行，您需要安装新包：
- en: Open RStudio and make sure it is referencing your latest CRAN R (version 4.0.2
    in our case).
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开RStudio并确保它引用的是您最新的CRAN R（在我们的案例中是版本4.0.2）。
- en: 'Click on the **Console** window and enter this command: `install.packages(''robust'')`.
    Then press *Enter*.'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**控制台**窗口并输入以下命令：`install.packages('robust')`。然后按*Enter*键。
- en: 'Enter this command: `install.packages(''recipes'')`. Then press *Enter*.'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入以下命令：`install.packages('recipes')`。然后按*Enter*键。
- en: 'Once you have loaded the data from the `winequality-red.csv` file directly
    from the web into the `df` variable, you’ll draw the boxplot of the `sulphates`
    variable using the `boxPlot()` wrapper function:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您已将`winequality-red.csv`文件中的数据直接加载到`df`变量中，您将使用`boxPlot()`包装函数绘制`sulphates`变量的箱线图：
- en: '![Figure 12.14 – Boxplot of the sulphates variable](img/file317.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![图12.14 – 硫酸盐变量的箱线图](img/file317.png)'
- en: Figure 12.14 – Boxplot of the sulphates variable
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.14 – 硫酸盐变量的箱线图
- en: 'Since there are many outliers visible in *Figure 12.14*, they are identified
    using the `add_is_outlier_IQR()` function, which adds an identifier column to
    the dataframe. As the name indicates, the function determines the outliers based
    on the interquartile range. At this point, the boxplot of the same variable is
    drawn again, this time eliminating the previously identified outliers:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 由于*图12.14*中存在许多异常值，它们使用`add_is_outlier_IQR()`函数被识别，该函数向数据框添加一个标识列。正如其名称所示，该函数基于四分位数范围确定异常值。在此阶段，再次绘制相同变量的箱线图，这次消除了之前识别出的异常值：
- en: '![Figure 12.15 – Boxplot of the sulphates variable after removing outliers](img/file318.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![图12.15 – 移除异常值后的硫酸盐变量箱线图](img/file318.png)'
- en: Figure 12.15 – Boxplot of the sulphates variable after removing outliers
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.15 – 移除异常值后的硫酸盐变量箱线图
- en: 'Assuming you now want to identify multivariate outliers, it is worthwhile to
    first look at the histograms of the individual variables to see if significant
    skewness is present. The histograms are drawn using the following `dataframeHist()`
    function:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 假设您现在想识别多元异常值，首先查看各个变量的直方图以查看是否存在显著的偏度是有意义的。直方图使用以下`dataframeHist()`函数绘制：
- en: '[PRE7]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'A special feature of this function is the use of the `pivot_longer()` function
    of the `tidyr` package on all columns to verticalize their names in the new `name`
    column, to which correspond the initial values in the new `value` column. The
    result is as follows:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 该函数的一个特殊功能是使用`tidyr`包的`pivot_longer()`函数对所有列进行操作，以将它们的名称垂直化到新的`name`列中，对应于新`value`列中的初始值。结果如下：
- en: '![Figure 12.16 – Multiple histograms for each numeric variable](img/file319.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![图12.16 – 每个数值变量的多个直方图](img/file319.png)'
- en: Figure 12.16 – Multiple histograms for each numeric variable
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.16 – 每个数值变量的多个直方图
- en: Since the skewness is obvious, you can apply Yeo-Johnson transformations thanks
    to the `yeo_johnson_transf()` wrapper function we created for you. The peculiarity
    of this function is that it makes use of a ready-made step in the `recipes` package,
    which facilitates the whole pre-processing phase. To learn more about the use
    of `recipes`, take a look at the references.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 由于偏度明显，您可以使用我们为您创建的`yeo_johnson_transf()`包装函数应用Yeo-Johnson变换。这个函数的特殊之处在于它利用了`recipes`包中的一个现成步骤，这简化了整个预处理阶段。要了解更多关于`recipes`的使用，请查看参考文献。
- en: 'As you learned in the previous section, the Yeo-Johnson transformations solve
    the skewness problem quite well in this case. Therefore, it is possible to try
    applying Mahalanobis distance to detect outliers via the following code:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 如前节所述，Yeo-Johnson变换在此情况下很好地解决了偏度问题。因此，可以尝试通过以下代码应用马氏距离来检测异常值：
- en: '[PRE8]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'At this point, given a cutoff value associated with the statistical significance
    with which we want to determine outliers, you can obtain the corresponding threshold
    value above which to consider an observation an outlier. Once the threshold is
    calculated, it is trivial to create an indicator column for the outliers. It is
    also possible to add a column indicating the probability with which an observation
    can be considered an outlier not by chance thanks to the `pchisq()` function:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在此阶段，给定一个与我们要用来确定异常值的统计显著性相关的截止值，您可以获得相应的阈值，超过该阈值即可认为观察值是异常值。一旦计算了阈值，创建一个用于异常值的指示列就变得非常简单。还可以通过`pchisq()`函数添加一个列，表示观察值可能不是偶然地被认为是异常值的概率：
- en: '[PRE9]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The final result partially presents this output:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 最终结果部分展示了以下输出：
- en: '![Figure 12.17 – Final tibble containing the multivariate outliers’ information](img/file320.png)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![图12.17 – 包含多变量异常值信息的最终tibble](img/file320.png)'
- en: Figure 12.17 – Final tibble containing the multivariate outliers’ information
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.17 – 包含多变量异常值信息的最终tibble
- en: Way to go! You were able to identify multivariate outliers in R as well.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 干得好！您能够在R中识别出多变量异常值。
- en: At this point, it is trivial to apply the Python and R code seen so far to Power
    BI.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，将Python和R代码应用于Power BI是显而易见的。
- en: Implementing outlier detection in Power BI
  id: totrans-146
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在Power BI中实现异常值检测
- en: 'Power BI has tools that allow you to view outliers graphically and then analyze
    them by hovering. One of these was introduced in the November 2020 release and
    is the **Anomaly Detection** feature. The other one is the **Outliers Detection**
    custom visual. Let''s see what the main differences are:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: Power BI有工具允许您通过悬停来图形化地查看异常值并进行分析。其中之一是在2020年11月发布的，是**异常检测**功能。另一个是**异常值检测**自定义可视化。让我们看看它们的主要区别：
- en: '**Anomaly Detection** is available directly in Power BI once you enable it
    as a preview feature (at the moment, it is in preview). It is *only supported
    for line chart visuals* containing *time-series data* in the Axis field.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**异常检测**功能一旦作为预览功能启用（目前处于预览状态），即可直接在Power BI中使用。它**仅支持包含轴字段中时间序列数据的折线图可视化**。'
- en: '**Outliers Detection** is an open source R custom visual, and it has to be
    installed separately ([https://bit.ly/power-bi-outliers-detection](https://bit.ly/power-bi-outliers-detection)).
    There are five different implemented methods to detect outliers, and it works
    well for univariate and bivariate datasets. Multivariate datasets are to be avoided.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**异常值检测**是一个开源的R自定义可视化工具，需要单独安装（[https://bit.ly/power-bi-outliers-detection](https://bit.ly/power-bi-outliers-detection)）。它实现了五种不同的异常值检测方法，并且对于单变量和双变量数据集表现良好。应避免使用多变量数据集。'
- en: As you may have noticed, both of these tools are Power BI visuals.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所注意到的，这两个工具都是Power BI可视化工具。
- en: '**Important Note**'
  id: totrans-151
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**重要提示**'
- en: ''
  id: totrans-152
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: All transformations performed within Python or R visuals modify the dataframe
    that will later be the object of visualization, but the changes cannot be persisted
    in the data model in any way.
  id: totrans-153
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在Python或R可视化中执行的所有转换都会修改将来的可视化对象的数据框，但这些更改不能以任何方式持久保存在数据模型中。
- en: It is precisely for this reason that we have decided to illustrate some methods
    for detecting outliers that can be applied in Power Query using Python or R. This
    way, you can identify observations that are outliers by simply filtering your
    data model tables appropriately. Due to the simplicity of the code, in this case
    we will also implement the correlation coefficients in both Python and R in one
    project.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 正是因为这个原因，我们决定展示一些可以在Power Query中使用Python或R实现的检测异常值的方法。这样，您只需通过适当过滤数据模型表即可识别出异常值。由于代码的简单性，在这种情况下，我们还将在一个项目中实现Python和R中的相关系数。
- en: 'First, make sure that Power BI Desktop references the correct versions of Python
    and R in the **Options**. Then follow these steps:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，请确保Power BI桌面版在**选项**中引用了正确的Python和R版本。然后按照以下步骤操作：
- en: 'Click on **Get Data**, search for `web`, select **Web**, and click on **Connect**:'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**获取数据**，搜索`web`，选择**Web**，然后点击**连接**：
- en: Enter [https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv](https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv)
    into the URL textbox and click **OK**.
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将[https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv](https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv)输入到URL文本框中，然后点击**确定**。
- en: You’ll see a preview of the data. Then click **Transform Data**.
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您将看到数据的预览。然后点击**转换数据**。
- en: Click **Transform** on the ribbon and then **Run Python script**.
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在功能区点击**转换**，然后**运行Python脚本**。
- en: Enter the script you can find in the `02-detect-outliers-in-power-bi-with-python
    copy.py` file in the `Chapter12\Python` folder.
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`Chapter12\Python`文件夹中的`02-detect-outliers-in-power-bi-with-python copy.py`文件中输入脚本。
- en: We are only interested in the data in `dataset`. So, click on its **Table**
    value.
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们只对`dataset`中的数据感兴趣。因此，点击其**表格**值。
- en: You'll see a preview of the dataset that also has the new columns to identify
    outliers.
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你将看到数据集的预览，其中也包含用于识别异常值的新列。
- en: Click **Home** on the ribbon and then click **Close & Apply**.
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在功能区点击**主页**，然后点击**关闭并应用**。
- en: Repeat steps 1 to 3.
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复步骤1到3。
- en: Click **Transform** on the ribbon and then **Run R script**.
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在功能区点击**转换**，然后**运行R脚本**。
- en: Enter the script you can find in the `02-detect-outliers-in-power-bi-with-r.R`
    file in the `Chapter12\R` folder.
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`Chapter12\R`文件夹中的`02-detect-outliers-in-power-bi-with-r.R`文件中输入脚本。
- en: We are only interested in the `data` tibble. So, click on its **Table** value.
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们只对`data` tibble感兴趣。因此，点击其**表格**值。
- en: You’ll see the preview of the dataset that also has the new columns to identify
    outliers.
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你将看到数据集的预览，其中也包含用于识别异常值的新列。
- en: Click **Home** on the ribbon and then click **Close & Apply**.
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在功能区点击**主页**，然后点击**关闭并应用**。
- en: Amazing! You have just identified outliers of a numeric dataset in Power BI
    with both Python and R!
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 太棒了！你刚刚使用Python和R在Power BI中识别了一个数值数据集的异常值！
- en: What missing values are and how to deal with them
  id: totrans-171
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 缺失值是什么以及如何处理它们
- en: Data describing real-world phenomena often has a lot of missing data. Lack of
    data is a fact that cannot be overlooked, especially if the analyst wants to do
    an advanced study of the dataset to understand how much the variables in it are
    correlated.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 描述现实世界现象的数据通常有很多缺失数据。数据不足是一个不容忽视的事实，尤其是如果分析师想要对数据集进行高级研究，以了解其中变量之间的相关性程度。
- en: 'The consequences of mishandling missing values can be many:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 处理缺失值不当的后果可能很多：
- en: The *statistical power* of variables with missing values is diminished, especially
    when a substantial number of values is missing for a single variable.
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 具有缺失值的变量的*统计功效*会降低，尤其是在单个变量缺失大量值时。
- en: The *representativeness of the dataset* subject to missing values may also be
    diminished, and thus the dataset in question may not correctly represent the substantive
    characteristics of the set of all observations of a phenomenon.
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缺失值的数据集的*代表性*也可能降低，因此，所讨论的数据集可能无法正确代表现象所有观察值的实质性特征。
- en: Any statistical estimates may not converge to whole population values, thus
    *generating bias*.
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任何统计估计可能不会收敛到整个总体的值，从而*产生偏差*。
- en: The results of the analysis conducted may not be correct.
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 进行分析的结果可能不正确。
- en: But let's see what the causes could be that generate missing values in a dataset.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 但让我们看看可能导致数据集中缺失值的原因可能是什么。
- en: The causes of missing values
  id: totrans-179
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 缺失值的原因
- en: 'There can be many causes for a lack of values, determined by intentional or
    unintentional behaviors. Here is a non-exhaustive list:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 缺失值可能有许多原因，由故意或无意的行为决定。以下是一个非详尽的列表：
- en: Corruption of data due to errors in writing, reading, or transmitting it
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于书写、读取或传输过程中的错误导致的数据损坏
- en: Replacing outliers that excessively skew the dataset with null values
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用空值替换过度扭曲数据集的异常值
- en: Refusing to answer a question on a survey
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 拒绝回答调查中的问题
- en: Lack of knowledge of the issues asked in a survey question
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对调查问题中提出的问题缺乏了解
- en: 'However, all of these causes can be summarized into *four types of cases*:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，所有这些原因都可以总结为*四种情况*：
- en: '**Missing Completely at Random** (**MCAR**): The causes that generate the null
    values are totally independent both of the hypothetical values they would have
    if valorized (Y) and of the values of the other variables in the dataset (X).
    They just depend on external variables (Z). The advantage of data that is MCAR
    from a statistical perspective is that the dataset consisting of only complete
    values for both variables X and Y is an *unbiased sample* of the entire population.
    Unfortunately, MCAR cases are rarely found in real-world data.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**完全随机缺失**（**MCAR**）：产生空值的成因完全独立于如果赋值（Y）的假设值，以及数据集中其他变量的值（X）。它们仅依赖于外部变量（Z）。从统计角度来看，MCAR数据的优势在于，仅包含变量X和Y完整值的整个数据集是整个总体的**无偏样本**。不幸的是，MCAR案例在现实世界数据中很少见。'
- en: '**Missing At Random** (**MAR**): The missing data of a partially incomplete
    variable (Y) is related to some other variables in the dataset that do not have
    null values (X), but not to the values of the incomplete variable itself (Y).
    The dataset consisting of only complete values for both variables X and Y in the
    MAR case constitutes a *biased sample* of the entire population because it will
    surely miss all those values of X on which the null values of Y depend, resulting
    in a dataset that is not representative of the entire phenomenon. MAR is a more
    realistic assumption than MCAR.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**随机缺失（MAR**）：部分不完整变量（Y）的缺失数据与数据集中某些其他变量（X）有关，这些变量没有空值，但与不完整变量本身的值（Y）无关。在MAR情况下，仅包含X和Y两个变量完整值的样本数据集构成了整个总体的**有偏样本**，因为它肯定会错过所有那些Y的空值所依赖的X的值，从而导致一个不能代表整个现象的数据集。MAR比MCAR是一个更现实的假设。'
- en: '**Missing Not at Random due to external variables Z** (**MNAR Z**): The missing
    data of a partially incomplete variable (Y) depends on variables not included
    in the dataset (external variables). For example, given a dataset without the
    variable “sex,” there may be observations for which the age value is zero. It
    could be possible that the respondents not providing this information are mostly
    women, since they stereotypically do not want to reveal their age. Therefore,
    eliminating observations that have non-null values for the “age” variable would
    generate a *biased dataset*.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**由于外部变量Z导致的非随机缺失（MNAR Z**）：部分不完整变量（Y）的缺失数据依赖于数据集中未包含的变量（外部变量）。例如，给定一个没有“性别”变量的数据集，可能会有年龄值为零的观测值。可能的情况是，不提供此信息的受访者大多是女性，因为她们典型地不愿意透露自己的年龄。因此，消除“年龄”变量非空值的观测值将生成一个**有偏的数据集**。'
- en: '**Missing Not at Random due to missing values Y** (**MNAR Y**): The missing
    data of a partially incomplete variable (Y) depends on the hypothetical values
    they would have if valorized. For example, it is well known that adolescents tend
    to never disclose the fact that they consume alcohol. Therefore, if we remove
    from the dataset those observations for which the value for alcohol consumption
    is null, implicitly we risk removing from the dataset most of the observations
    pertaining to adolescents, thus obtaining a *biased dataset*.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**由于缺失值Y导致的非随机缺失（MNAR Y**）：部分不完整变量（Y）的缺失数据依赖于它们如果被赋值时的假设值。例如，众所周知，青少年倾向于从不透露他们饮酒的事实。因此，如果我们从数据集中移除那些酒精消费值为空的观测值，我们隐含地冒着从数据集中移除大多数与青少年相关的观测值的风险，从而获得一个**有偏的数据集**。'
- en: There are also statistical tests that allow you to understand if the distribution
    of missing data is MCAR (look at the references). But, as already mentioned, cases
    of MCAR are so rare that it is better to assume that the distribution of missing
    values of a dataset under consideration is either MAR or MNAR.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 也有一些统计测试可以帮助你理解缺失数据的分布是否为MCAR（参见参考文献）。但是，如前所述，MCAR的情况非常罕见，因此最好假设考虑中的数据集缺失值的分布要么是MAR，要么是MNAR。
- en: Depending on the type of missing data distribution, specific strategies can
    be employed to sanitize the missing values.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 根据缺失数据分布的类型，可以采用特定的策略来清理缺失值。
- en: Handling missing values
  id: totrans-192
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 处理缺失值
- en: The first thing to do, when possible, is to understand together with the referent
    of the data the reason for the missing values in the dataset, and whether it is
    possible to recover them. Unfortunately, most of the time it is not possible to
    recover missing data from the source and therefore different strategies must be
    adopted, depending on the case.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 当可能时，首先要做的是与数据的相关方一起了解数据集中缺失值的原因，以及是否有可能恢复它们。不幸的是，大多数时候无法从源数据中恢复缺失数据，因此必须根据具体情况采用不同的策略。
- en: Easy imputation by hand
  id: totrans-194
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 简单的手动推断
- en: There may be cases of variables that are *obvious to impute by hand*. For example,
    in correspondence of the “blue” value of the variable “color” you will notice
    that the variable “weight” always takes the value of 2.4, except in a few cases
    where it is null. In those cases, it is easy to impute the missing values of the
    variable “weight” in relation to the “blue” color with the value 2.4.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 可能存在一些变量，它们的手动**推断**是**显而易见的**。例如，在“颜色”变量的“蓝色”值对应的情况下，你会注意到“重量”变量总是取值为2.4，除了少数几个值为空的情况。在这些情况下，根据“蓝色”颜色值为2.4，很容易推断出“重量”变量的缺失值。
- en: Discarding data
  id: totrans-196
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 丢弃数据
- en: 'The first solution to the missing values that comes to the analyst''s mind
    is surely to eliminate the problem at the source, that is, to eliminate missing
    values. There are several ways to eliminate them:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 分析师首先想到的缺失值解决方案无疑是消除问题的根源，即消除缺失值。消除它们有几种方法：
- en: '**Listwise** or **Complete-Case Analysis** (**CCA**) **deletion**: This method
    involves *deleting any observation (row) that contains at least one missing data
    element in any variable*. It is often applied when the number of missing values
    is low, and the number of observations is sufficiently large. As you have seen
    in the classification of the four types of missing data, the only case in which
    adopting this solution doesn’t result in a biased dataset is the MCAR, a very
    rare case among datasets describing real-world phenomena. Listwise deletion is
    therefore not a good strategy when you are not faced with a case of MCAR with
    a sufficiently high number of observations in the dataset.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**完全案例分析**（**CCA**）**删除**：这种方法涉及**删除任何包含至少一个缺失数据元素的观测值（行）**。当缺失值的数量较少，观测值数量足够大时，通常应用这种方法。正如你在四种缺失数据类型的分类中所看到的，唯一不会导致数据集有偏的情况是MCAR，这在描述现实世界现象的数据集中是非常罕见的。因此，当数据集中观测值的数量足够高时，面对MCAR的情况，列表删除并不是一个好的策略。'
- en: '**Pairwise** or **Available-Case Analysis** (**ACA**) **deletion**: Depending
    on the variables considered in a statistical analysis, this method *eliminates
    only those observations (rows) that have null values for the only variables involved*.
    Null values present in variables that are not involved in the analysis are not
    a reason to eliminate observations. Again, adopting this method does not generate
    a biased dataset only if the case under analysis is MCAR. The most obvious disadvantage
    of this method is that if you need to compare different analyses, you cannot apply
    it because the number of observations in the sample varies as the variables involved
    in the different analyses vary.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**成对**或**可用案例分析**（**ACA**）**删除**：根据统计分析中考虑的变量，这种方法**仅删除那些对于涉及的唯一变量具有空值的观测值（行）**。不涉及分析的变量中的空值不是删除观测值的原因。同样，只有当分析中的案例是MCAR时，采用这种方法才不会生成有偏的数据集。这种方法最明显的缺点是，如果你需要比较不同的分析，你不能应用它，因为样本中观测值的数量会随着不同分析中涉及的变量的变化而变化。'
- en: '**Variable deletion**: This method considers *removing the entire variable
    from the analysis* under study (and not from the dataset a priori!) when the proportion
    of missing values ranges is 60% and above. It makes sense to eliminate a variable
    if, after careful study, it is concluded that it does not contain important information
    for the analysis at hand. Otherwise, it is always preferable to try a method of
    imputation. Generally, the elimination of a variable is always the last option
    and should only be considered if the final analysis actually benefits from it.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**变量删除**：这种方法考虑在研究分析中**从分析中删除整个变量**（而不是从先验数据集中删除！）当缺失值的比例在60%及以上时。如果在仔细研究后得出结论，该变量不包含当前分析的重要信息，那么删除变量是有意义的。否则，始终更倾向于尝试插补方法。一般来说，删除变量总是最后的选项，并且只有在最终分析确实从中受益时才应考虑。'
- en: When the analyst still has to heal the problem of missing values, even after
    trying to apply these elimination techniques, they must then resort to imputation
    techniques. Let's look at the most commonly used methods.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 即使在尝试应用这些消除技术之后，分析师仍然必须解决缺失值的问题，他们必须求助于插补技术。让我们看看最常用的方法。
- en: Mean, median, and mode imputation
  id: totrans-202
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 均值、中位数和众数插补
- en: This is an intuitively attractive method, also known as **single imputation**,
    for which you fill missing values with predefined values. Simplicity is unfortunately
    countered by some not negligible issues.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个直观吸引人的方法，也称为**单值插补**，其中你用预定义的值填充缺失值。不幸的是，简单性被一些不可忽视的问题所抵消。
- en: Perhaps the most common substitution of null values is with the **mean** value
    of the variable's distribution resulting from ignoring missing values. The motivation
    behind this choice is that *the mean is a reasonable estimate of an observation
    drawn at random from a normal distribution*. However, if the distribution in question
    is skewed, the analyst runs the risk of making severely biased estimates even
    if the dataset’s missing value distribution is MCAR.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 可能最常用的缺失值替代方法是使用变量的分布**均值**，这是在忽略缺失值的情况下得到的。这种选择的动机在于*均值是随机从正态分布中抽取的观察值的合理估计*。然而，如果所讨论的分布是偏斜的，即使数据集的缺失值分布是MCAR，分析师也有可能做出严重偏颇的估计。
- en: The skewness problem can be solved by using the **median** of the variable.
    However, the fact remains that the common problem in single imputation is replacing
    a missing value with a single value and then treating it as if it were a true
    value. As a result, single imputation ignores uncertainty and almost always underestimates
    variance (remember that variance is synonymous with information; a variable with
    0 variance is a constant value variable that usually does not enrich statistical
    analyses).
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过使用变量的**中位数**来解决偏斜问题。然而，事实仍然是，单次插补的常见问题是用一个单一值来替代缺失值，然后将其视为真实值。因此，单次插补忽略了不确定性，并且几乎总是低估方差（记住方差与信息同义；方差为0的变量是常数值变量，通常不会丰富统计分析）。
- en: '**Mode** (the value that is repeated most often) imputation is often used with
    categorical data represented as numbers. Even this method, when used without having
    strong theoretical grounds, introduces bias, so much so that sometimes analysts
    prefer to create a new category specifically for missing values.'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '**众数**（出现频率最高的值）插补通常用于表示为数字的分类数据。即使这种方法在没有强有力的理论依据的情况下使用，也会引入偏差，以至于有时分析师更愿意为缺失值创建一个新的类别。'
- en: Multiple imputation is often preferable to single imputation as it overcomes
    the problems of underestimating variance by considering both within-imputation
    and between-imputation variance. Let's see what this is all about.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 多重插补通常比单次插补更可取，因为它通过考虑插补内和插补间方差来克服低估方差的问题。让我们看看这是怎么回事。
- en: Multiple imputation
  id: totrans-208
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 多重插补
- en: 'It is thanks to Donald B. Rubin that in 1987 a methodology to deal with the
    problem of underestimation of variance in the case of single imputation was made
    public. This methodology goes by the name of **multiple imputation** and consists
    of the following steps:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 多亏了Donald B. Rubin，1987年公开了一种处理单次插补情况下方差低估问题的方法。这种方法被称为**多重插补**，包括以下步骤：
- en: '**Imputation**: This step is very similar to the single imputation step, except
    that this time, values are extracted *m* times from a distribution for each missing
    value. The result of this operation is a set of *m* imputed datasets, for which
    all observed values are always the same, with different imputed values depending
    on the uncertainty of the respective distributions.'
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**插补**：这一步骤与单次插补步骤非常相似，只是这次，对于每个缺失值，从分布中提取*m*次值。这一操作的结果是一组*m*个插补数据集，其中所有观测值始终相同，而插补值则根据各自分布的不确定性而不同。'
- en: '**Analysis**: You use all *m* imputed datasets for the statistical analysis
    you need to do. The result of this step is a set of *m* results (or analyses)
    obtained by applying the analysis in question to each of the *m* imputed datasets.'
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**分析**：您使用所有*m*个插补数据集进行所需的统计分析。这一步骤的结果是通过对每个*m*个插补数据集应用相关分析而获得的*m*个结果（或分析）。'
- en: '**Pooling**: The *m* results are combined in order to obtain unbiased estimates
    with the correct statistical properties. The *m* estimates of each missing value
    are pooled in order to have an estimated variance that combines the usual sampling
    variance (**within-imputation variance**) and the extra variance caused by missing
    data (**between-imputation variance**).'
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**合并**：将*m*个结果合并，以获得具有正确统计特性的无偏估计。将每个缺失值的*m*个估计值合并，以便得到一个估计方差，该方差结合了通常的抽样方差（**插补内方差**）和由缺失数据引起的额外方差（**插补间方差**）。'
- en: 'The whole process can be summarized by *Figure 12.18*:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 整个过程可以用*图12.18*来概括：
- en: '![Figure 12.18 – Multiple imputation process](img/file321.png)'
  id: totrans-214
  prefs: []
  type: TYPE_IMG
  zh: '![图12.18 – 多重插补过程](img/file321.png)'
- en: Figure 12.18 – Multiple imputation process
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.18 – 多重插补过程
- en: Multiple imputation can be used in cases where the data is MCAR, MAR, and even
    when the data is MNAR if there are enough auxiliary variables.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据是MCAR（完全随机缺失）、MAR（条件随机缺失）甚至当数据是MNAR（非随机缺失）且有足够辅助变量的情况下，可以使用多重插补。
- en: 'The most common implementations of multiple imputation are as follows:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 多重插补最常见的实现方式如下：
- en: '**Multivariate Imputation by Chained Equations** (**MICE**): This imputes missing
    values focusing on one variable at a time. Once the focus is on one variable,
    MICE uses all other variables in the dataset (or an appropriately chosen subset
    of those variables) to predict missing values in that variable. Predictions of
    missing values are based on linear regression models for numerical variables and
    logistic regression models for categorical variables.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**链式方程多重插补**（**MICE**）：这种方法专注于一次填补一个变量的缺失值。一旦专注于一个变量，MICE将使用数据集中的所有其他变量（或适当选择的这些变量的子集）来预测该变量的缺失值。缺失值的预测基于数值变量的线性回归模型和分类变量的逻辑回归模型。'
- en: '**Amelia II**: This is named after Amelia Mary Earhart, an American aviation
    pioneer who, during an attempt to become the first woman to complete a global
    circumnavigation flight in 1937, disappeared over the central Pacific Ocean. Amelia
    II combines a bootstrapping-based algorithm and an **Expectation–Maximization**
    (**EM**) algorithm, making it fast and reliable. It also works very well for time-series
    data.'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Amelia II**：这个名字是为了纪念阿梅莉亚·埃尔哈特，一位美国航空先驱，她在1937年尝试成为首位完成全球环球飞行第一人时，在太平洋中央失踪。Amelia
    II结合了基于自助法的算法和**期望最大化**（**EM**）算法，使其快速且可靠。它也非常适合时间序列数据。'
- en: Recently, multiple imputation has been implemented using deep learning algorithms
    as well. In particular, the **Multiple Imputation with Denoising Autoencoders**
    (**MIDAS**) algorithm offers significant advantages in terms of accuracy and efficiency
    over other multiple imputation strategies, particularly when applied to large
    datasets with complex features.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，已经使用深度学习算法实现了多重插补。特别是，**去噪自编码器多重插补**（**MIDAS**）算法在准确性和效率方面相较于其他多重插补策略具有显著优势，尤其是在应用于具有复杂特征的大型数据集时。
- en: Univariate time-series imputation
  id: totrans-221
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 单变量时间序列插补
- en: The problem of missing data afflicts not only multivariate tabular datasets,
    but also time-series datasets. For example, sensors that constantly collect data
    about a phenomenon could stop working at any time, generating holes in the series.
    Often, the analyst is faced with a time-series that has missing values and must
    somehow impute these values because the processes to which to submit the series
    do not handle null values.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 缺失数据的问题不仅困扰着多元表格数据集，也影响着时间序列数据集。例如，持续收集现象数据的传感器可能在任何时候停止工作，从而在序列中产生空缺。通常，分析师面对的是含有缺失值的时间序列，必须以某种方式对这些值进行插补，因为提交序列的流程无法处理空值。
- en: 'The constraint of the consequentiality of events given by the temporal dimension
    forces the analyst to use specific imputation methods for time-series. Let''s
    look at the most commonly used methods:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 时间维度给出的事件后果约束迫使分析师使用特定的插补方法来处理时间序列。让我们看看最常用的方法：
- en: '**Last Observation Carried Forward (LOCF), Next Observation Carried Backward
    (NOCB)**: In the LOCF method, the last observed (that is, non-null) measure of
    the variable in question is used for all subsequent missing values. The only condition
    in which LOCF is unbiased is when the missing data is completely random, and the
    data used as the basis for LOCF imputation has exactly the same distribution as
    the unknown missing data. Since it can never be proven that these distributions
    are exactly the same, all analyses that make use of LOCF are suspect and will
    almost certainly generate biased results.The NOCB method is a similar approach
    to LOCF, but works in the opposite direction, taking the first (non-null) observation
    after the missing value and replacing it with the missing value. It obviously
    has the same limitations as LOCF.'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**最后观测值前推（LOCF）和下一观测值后推（NOCB）**：在LOCF方法中，使用变量最后观测到的（即非空）测量值来填补所有后续的缺失值。LOCF无偏的唯一条件是缺失数据完全随机，且用作LOCF插补基础的数据与未知缺失数据的分布完全相同。由于无法证明这些分布完全相同，所有利用LOCF的分析都存在嫌疑，并且几乎肯定会生成有偏的结果。NOCB方法与LOCF类似，但方向相反，它使用缺失值之后的第一个（非空）观测值来替换缺失值。显然，它具有与LOCF相同的局限性。'
- en: '**Exponentially Weighted Moving Average (EMWA)**: In general, the moving average
    is commonly used in time-series to smooth out fluctuations due to short-term effects
    and to highlight long-term trends or cycles. EWMA is designed such that older
    observations are given lower weights. The weights decrease exponentially as the
    observation gets older (hence the name “exponentially weighted”). Missing values
    are imputed using the values of the resulting “smoothed” time-series.'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**指数加权移动平均（EMWA）**：一般来说，移动平均在时间序列中常用于平滑短期效应引起的波动，并突出长期趋势或周期。EWMA的设计使得较老的观测值赋予较低的权重。随着观测值的变老，权重呈指数下降（因此得名“指数加权”）。缺失值通过使用结果“平滑”时间序列的值进行插补。'
- en: '**Interpolation**: The interpolation technique is one of the most widely used
    techniques to impute missing data from a time-series. The basic idea is to use
    a simple function (such as a linear function, a polynomial function, or a spline
    function) that fits with the non-zero points near the missing value, then interpolate
    the value for the missing observation.'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**插值**：插值技术是从时间序列中插补缺失数据最广泛使用的技术之一。基本思想是使用一个简单的函数（例如线性函数、多项式函数或样条函数）来拟合缺失值附近的非零点，然后对缺失观测值进行插值。'
- en: '**Seasonally Decomposed Imputation**: If the time-series under analysis has
    seasonality, this method could give very good results. The procedure adopted is
    to remove the seasonal component from the time-series, perform the imputation
    on the seasonally adjusted series, and then add the seasonal component back.'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**季节分解插补**：如果分析的时间序列具有季节性，这种方法可能会给出非常好的结果。采用的程序是从时间序列中移除季节性成分，对季节调整后的序列进行插补，然后将季节性成分加回。'
- en: There are also algorithms to impute missing values for multivariate time-series.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 对于多变量时间序列，也有用于插补缺失值的算法。
- en: Multivariate time-series imputation
  id: totrans-229
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 多变量时间序列插补
- en: This topic is beyond the scope of this chapter, but we simply wanted to specify
    that the *Amelia II* algorithm we discussed earlier is also used to impute missing
    values in a multivariate time-series, whereas it is not suitable for imputation
    on univariate time-series.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 这个主题超出了本章的范围，但我们只是想说明，我们之前讨论的*Amelia II*算法也用于多变量时间序列的缺失值插补，而它不适用于单变量时间序列的插补。
- en: In order to figure out whether to impute missing values, we must first identify
    them in the dataset. Let's see how to do that.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确定是否要插补缺失值，我们必须首先在数据集中识别它们。让我们看看如何做到这一点。
- en: Diagnosing missing values in R and Python
  id: totrans-232
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在R和Python中诊断缺失值
- en: Before thinking about imputing missing values in a dataset, we must first know
    the extent to which the missing values affect each individual variable.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 在考虑在数据集中插补缺失值之前，我们必须首先了解缺失值对每个变量影响的程度。
- en: 'You can find the code used in this section in the `Chapter12\R\03-diagnose-missing-values-in-r.R`
    and `Chapter12\Python\03-diagnose-missing-values-in-python.py` files. In order
    to properly run the code and the code of the following sections, you need to install
    the requisite R and Python packages as follows:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在本节的`Chapter12\R\03-diagnose-missing-values-in-r.R`和`Chapter12\Python\03-diagnose-missing-values-in-python.py`文件中找到使用的代码。为了正确运行代码以及后续章节的代码，您需要按照以下方式安装所需的R和Python包：
- en: Open the Anaconda prompt.
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开Anaconda提示符。
- en: Enter the `conda activate pbi_powerquery_env` command.
  id: totrans-236
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入`conda activate pbi_powerquery_env`命令。
- en: Enter the `pip install missingno` command.
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入`pip install missingno`命令。
- en: Enter the `pip install upsetplot` command.
  id: totrans-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入`pip install upsetplot`命令。
- en: Then, open RStudio and make sure it is referencing your latest CRAN R (version
    4.0.2 in our case).
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，打开RStudio并确保它正在引用您最新的CRAN R（在我们的案例中是版本4.0.2）。
- en: Click on the **Console** window and enter `install.packages('naniar')`. Then
    press *Enter*.
  id: totrans-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**控制台**窗口并输入`install.packages('naniar')`。然后按*Enter*。
- en: Enter `install.packages('imputeTS')`. Then press *Enter*.
  id: totrans-241
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入`install.packages('imputeTS')`。然后按*Enter*。
- en: Enter `install.packages('forecast')`. Then press *Enter*.
  id: totrans-242
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入`install.packages('forecast')`。然后按*Enter*。
- en: Enter `install.packages('ggpubr')`. Then press *Enter*.
  id: totrans-243
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入`install.packages('ggpubr')`。然后按*Enter*。
- en: Enter `install.packages('missForest')`. Then press *Enter*.
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入`install.packages('missForest')`。然后按*Enter*。
- en: Enter `install.packages('mice')`. Then press *Enter*.
  id: totrans-245
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入`install.packages('mice')`。然后按*Enter*。
- en: Enter `install.packages('miceadds')`. Then press *Enter*.
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入`install.packages('miceadds')`。然后按*Enter*。
- en: Let's see at this point what features will come in handy when you face the analysis
    of missing values in a dataset.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看在您面对数据集中缺失值分析时，哪些功能会派上用场。
- en: 'The R package `naniar` provides the `vis_miss()` function, which displays in
    a single image the missing values of the whole dataframe:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: R包`naniar`提供了`vis_miss()`函数，该函数可以在单个图像中显示整个数据框的缺失值：
- en: '![Figure 12.19 – Plot of missing values in the entire dataset](img/file322.png)'
  id: totrans-249
  prefs: []
  type: TYPE_IMG
  zh: '![图12.19 – 整个数据集中缺失值的图](img/file322.png)'
- en: Figure 12.19 – Plot of missing values in the entire dataset
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.19 – 整个数据集中缺失值的图
- en: You can draw similar graphs in Python thanks to the `missingno` library ([https://github.com/ResidentMario/missingno](https://github.com/ResidentMario/missingno)).
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以利用`missingno`库在Python中绘制类似的图表（[https://github.com/ResidentMario/missingno](https://github.com/ResidentMario/missingno)）。
- en: 'Knowing only the percentage value of the number of missing values compared
    to the total number of values of the variable under consideration can be limiting.
    That''s why it''s often useful to also know the details for each column via the
    `miss_var_summary()` function:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 仅知道与考虑的变量的总值相比的缺失值百分比可能有限。这就是为什么通常还很有用通过`miss_var_summary()`函数了解每个列的详细信息：
- en: '![Figure 12.20 – Missing values summary](img/file323.png)'
  id: totrans-253
  prefs: []
  type: TYPE_IMG
  zh: '![图12.20 – 缺失值摘要](img/file323.png)'
- en: Figure 12.20 – Missing values summary
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.20 – 缺失值摘要
- en: We developed a similar function in Python in the code you can find in the repository.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在代码库中开发了一个类似的功能。
- en: 'It would be interesting to be able to visualize combinations of missing values
    and missing intersections between variables. The R package `naniar` ([https://github.com/njtierney/naniar](https://github.com/njtierney/naniar))
    allows you to do just this kind of analysis thanks to the `gg_miss_upset()` function:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 能够可视化缺失值组合以及变量之间的缺失交集将很有趣。R包`naniar`（[https://github.com/njtierney/naniar](https://github.com/njtierney/naniar)）通过`gg_miss_upset()`函数允许您进行此类分析：
- en: '![Figure 12.21 – UpSet plot of dataset’s missing values](img/file324.png)'
  id: totrans-257
  prefs: []
  type: TYPE_IMG
  zh: '![图12.21 – 数据集缺失值的UpSet图](img/file324.png)'
- en: Figure 12.21 – UpSet plot of dataset’s missing values
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.21 – 数据集缺失值的UpSet图
- en: To achieve the same plot in Python, the process is a bit more complicated. You
    must first use the `upsetplot` module ([https://github.com/jnothman/UpSetPlot](https://github.com/jnothman/UpSetPlot)).
    The problem lies in providing the `UpSet()` function exposed by this package with
    an input dataframe in the required format. For this reason, we made the helper
    function `upsetplot_miss()` that you will find in the code to easily create the
    upset plot of missing values in Python as well.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 要在Python中实现相同的图，过程要复杂一些。您必须首先使用`upsetplot`模块（[https://github.com/jnothman/UpSetPlot](https://github.com/jnothman/UpSetPlot)）。问题在于提供该包暴露的`UpSet()`函数所需的输入数据框格式。因此，我们创建了辅助函数`upsetplot_miss()`，您可以在代码中找到它，以便在Python中轻松创建缺失值的upset图。
- en: 'In case you need to get an idea of the missing values in a time-series, the
    `imputeTS` R package provides the `ggplot_na_distribution()` function, which shows
    very clearly the holes in the time-series:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您需要了解时间序列中的缺失值，`imputeTS` R包提供的`ggplot_na_distribution()`函数可以非常清楚地显示时间序列中的空洞：
- en: '![Figure 12.22 – Detecting missing values in a time-series](img/file325.png)'
  id: totrans-261
  prefs: []
  type: TYPE_IMG
  zh: '![图12.22 – 时间序列中检测缺失值](img/file325.png)'
- en: Figure 12.22 – Detecting missing values in a time-series
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.22 – 时间序列中检测缺失值
- en: 'If, on the other hand, you need to get more complete details about the statistics
    of missing values in a time-series, the `statsNA()` function is for you:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您需要获取关于时间序列中缺失值统计的更完整细节，`statsNA()`函数就是您所需要的：
- en: '![Figure 12.23 – Statistics of missing values in a time-series](img/file326.png)'
  id: totrans-264
  prefs: []
  type: TYPE_IMG
  zh: '![图12.23 – 时间序列中缺失值的统计](img/file326.png)'
- en: Figure 12.23 – Statistics of missing values in a time-series
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.23 – 时间序列中缺失值的统计
- en: Once you have carefully studied the distributions of the missing values of each
    variable and their intersections, you can decide which variables to leave in the
    dataset and which to submit to the various imputation strategies. Let's see how
    to do imputation in R and Python.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您仔细研究了每个变量的缺失值分布及其交集，您就可以决定在数据集中保留哪些变量，以及将哪些变量提交给各种插补策略。让我们看看如何在R和Python中实现插补。
- en: Implementing missing value imputation algorithms
  id: totrans-267
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实现缺失值插补算法
- en: From here on, all missing value analysis will be done in R because very statistically
    specialized and simple-to-use packages that do not exist in the Python ecosystem
    have been developed for this language.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 从现在开始，所有缺失值分析都将使用R来完成，因为为这种语言开发了非常统计专业且易于使用的包，而在Python生态系统中不存在这些包。
- en: Suppose we need to calculate the Pearson correlation coefficient between the
    two numerical variables, `Age` and `Fare`, of the Titanic disaster dataset. Let's
    first consider the case where missing values are eliminated.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们需要计算泰坦尼克号灾难数据集中两个数值变量`Age`和`Fare`之间的皮尔逊相关系数。让我们首先考虑删除缺失值的情况。
- en: Removing missing values
  id: totrans-270
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 删除缺失值
- en: 'The impact of applying listwise and pairwise deletion techniques is evident
    in the calculation of Pearson''s correlation between numerical variables in the
    Titanic dataset. Let''s load the data and select only numeric features:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 应用列表和成对删除技术对泰坦尼克号数据集中数值变量之间的皮尔逊相关系数计算的影响是明显的。让我们加载数据并仅选择数值特征：
- en: '[PRE10]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'If you now calculate the correlation matrix for the two techniques separately,
    you will notice the differences:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你现在分别计算两种技术的相关矩阵，你会注意到差异：
- en: '[PRE11]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'You will see the following result:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 你将看到以下结果：
- en: '![Figure 12.24 – Correlation matrix calculated using listwise and pairwise
    deletion](img/file327.png)'
  id: totrans-276
  prefs: []
  type: TYPE_IMG
  zh: '![图12.24 – 使用列表和成对删除计算的相关矩阵](img/file327.png)'
- en: Figure 12.24 – Correlation matrix calculated using listwise and pairwise deletion
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.24 – 使用列表和成对删除计算的相关矩阵
- en: Let's see how to impute missing values in the case of a tabular dataset.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何在表格数据集的情况下插补缺失值。
- en: Imputing tabular data
  id: totrans-279
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 插补表格数据
- en: You can find the code used in this section in the `Chapter12\R\04-handle-tabular-missing-values-in-r.R`
    file.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在`Chapter12\R\04-handle-tabular-missing-values-in-r.R`文件中找到本节使用的代码。
- en: Again, starting with the Titanic disaster dataset, the first thing you need
    to do is remove the `Name` and `Ticket` columns because they have a high number
    of distinct values.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，从泰坦尼克号灾难数据集开始，你需要做的第一件事是删除`Name`和`Ticket`列，因为它们有大量的不同值。
- en: '**Important Note**'
  id: totrans-282
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**重要提示**'
- en: ''
  id: totrans-283
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: It is important to eliminate categorical variables that have a high number of
    distinct values because otherwise, the MICE algorithm would fail due to the excessive
    RAM required. Generally, variables with high cardinality are not useful for the
    imputation of null values of other variables. There are cases in which the information
    contained in these variables could be fundamental for the imputation (for example,
    zip codes). In this case, it is necessary to use transformations that reduce the
    cardinality without losing the information contained in the variables. For further
    information, take a look at the references.
  id: totrans-284
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 重要的是要消除具有大量不同值的分类变量，否则MICE算法会因为所需的RAM过多而失败。通常，高基数变量对于其他变量的缺失值插补没有用。在某些情况下，这些变量中包含的信息对于插补可能是基本的（例如，邮政编码）。在这种情况下，需要使用变换来降低基数，同时不丢失变量中包含的信息。有关更多信息，请参阅参考文献。
- en: 'Since the missing values in the `Cabin` column represent more than 70% of all
    values, we decided to remove that as well. After that, the categorical variables
    `Survived`, `Sex`, and `Embarked` are transformed as factors:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 由于`Cabin`列中的缺失值占所有值的70%以上，我们决定也删除它。之后，分类变量`Survived`、`Sex`和`Embarked`被转换为因子：
- en: '[PRE12]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'At this point, it is possible to calculate the Pearson correlation for each
    pair of numerical variables by applying the pooling technique provided by Rubin
    in multiple imputations. The `miceadds` package exposes wrapper functions that
    simplify this operation for the most common statistical analysis given the result
    of the `mice()` function as a parameter. In our case, the function of interest
    is `micombine.cor()`, and we use it in our `corr_impute_missing_values()` function:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，可以通过应用Rubin在多次插补中提供的池化技术来计算每对数值变量的皮尔逊相关系数。`miceadds`包暴露了包装函数，简化了以`mice()`函数的结果作为参数的最常见统计分析操作。在我们的情况下，感兴趣的函数是`micombine.cor()`，我们在`corr_impute_missing_values()`函数中使用它：
- en: '[PRE13]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'It is easy therefore to obtain the aforementioned correlations:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，很容易获得上述相关系数：
- en: '[PRE14]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Here’s the result:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是结果：
- en: '![Figure 12.25 – Statistical inference for correlations for multiple imputed
    datasets](img/file328.png)'
  id: totrans-292
  prefs: []
  type: TYPE_IMG
  zh: '![图12.25 – 多次插补数据集的相关性统计推断](img/file328.png)'
- en: Figure 12.25 – Statistical inference for correlations for multiple imputed datasets
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.25 – 多次插补数据集的相关性统计推断
- en: Without going into too much detail about the other fields, the correlation coefficient
    between the variables is given by the `r` column. Since the *r* coefficient is
    the result of a process of inference, the `lower95` and `upper95` columns define
    the upper and lower 95% confidence interval bounds.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 不深入其他领域的细节，变量之间的相关系数由`r`列给出。由于*r*系数是推断过程的结果，`lower95`和`upper95`列定义了上下95%置信区间的界限。
- en: '**Important Note**'
  id: totrans-295
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**重要提示**'
- en: ''
  id: totrans-296
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'If you get an error such as **Error in matchindex(yhatobs, yhatmis, donors)
    : function ''Rcpp_precious_remove'' not provided by package ''Rcpp''**, it is
    likely that you are running a recent version of a package compiled with an earlier
    version of `Rcpp`. Updating `Rcpp` with the `install.packages(''Rcpp'')` command
    should fix it.'
  id: totrans-297
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '如果你遇到像**Error in matchindex(yhatobs, yhatmis, donors) : function ''Rcpp_precious_remove''
    not provided by package ''Rcpp''**这样的错误，那么很可能是你正在运行一个使用较早版本的`Rcpp`编译的包的最新版本。使用`install.packages(''Rcpp'')`命令更新`Rcpp`应该可以解决这个问题。'
- en: Sometimes, the goal of your analysis is not to get results from statistical
    functions, but to simply fill in the holes left by missing values because the
    dataset in question must then be used to train a machine learning algorithm that
    does not admit null values. The latest versions of scikit-learn (currently in
    the experimental phase) expose the impute module with its `SimpleImputer`, `KNNImputer`,
    and `IterativeImputer` methods. In this way, it is possible to impute the missing
    values of a dataset through machine learning algorithms (k-nearest neighbors;
    linear regression) among other more naïve methods (substitutions with fixed values,
    mean, median, or mode), and also to have an average score of how the algorithm
    performs in general (cross-validated mean squared error). You’ll see an example
    of one of these methods in *Chapter 13, Using Machine Learning without Premium
    or Embedded Capacity*.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，分析的目标不是从统计函数中获得结果，而是简单地填补缺失值留下的空白，因为相关的数据集必须用于训练一个不允许空值的机器学习算法。scikit-learn的最新版本（目前处于实验阶段）公开了带有`SimpleImputer`、`KNNImputer`和`IterativeImputer`方法的插补模块。这样，就可以通过机器学习算法（k-最近邻；线性回归）以及其他更简单的方法（使用固定值、均值、中位数或众数替换）来插补数据集的缺失值，并且还可以获得算法整体表现的平均分数（交叉验证均方误差）。你将在*第13章，使用无高级或嵌入式容量的机器学习*中看到一个这些方法的例子。
- en: If, on the other hand, you need to impute missing values from a univariate time-series,
    how would you proceed? Let's see it.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 如果，另一方面，你需要从一元时间序列中插补缺失值，你会怎么做？让我们看看。
- en: Imputing time-series data
  id: totrans-300
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 插补时间序列数据
- en: You can find the code used in this section in the `Chapter12\R\05-handle-time-series-missing-values-in-r.R`
    file.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在`Chapter12\R\05-handle-time-series-missing-values-in-r.R`文件中找到本节使用的代码。
- en: 'We consider a time-series of the average number of aircraft passengers per
    month. Let''s duplicate it and eliminate from it 10% of the values randomly and,
    in addition, let''s eliminate a couple of duplicated values by hand. Then, we’ll
    merge the two time-series into a single tibble:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 我们考虑一个每月平均飞机乘客数量的时间序列。让我们复制它，并从中随机删除10%的值，此外，我们手动删除几个重复的值。然后，我们将两个时间序列合并成一个单一的tibble：
- en: '[PRE15]'
  id: totrans-303
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The result can be seen in *Figure 12.22*. The `imputeTS` package exposes convenient
    functions that implement the missing value imputations already described in the
    *Univariate time-series imputation* section. Once the values are imputed using
    the different algorithms and parameters, it is possible to calculate the accuracy
    because you also know the complete time-series. We use the `accuracy()` function
    exposed by the `forecast` package to calculate the final accuracy using various
    metrics, such as *mean absolute error* and *root mean squared error*:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 结果可以在*图12.22*中看到。`imputeTS`包公开了方便的函数，实现了在*一元时间序列插补*部分已描述的缺失值插补。一旦使用不同的算法和参数插补了值，就可以计算准确性，因为你也知道完整的时间序列。我们使用`forecast`包公开的`accuracy()`函数，使用各种指标（如*平均绝对误差*和*均方根误差*）来计算最终的准确性：
- en: '![Figure 12.24 – Error metrics for imputed values in a time-series](img/file329.png)'
  id: totrans-305
  prefs: []
  type: TYPE_IMG
  zh: '![图12.24 – 时间序列中插补值的误差指标](img/file329.png)'
- en: Figure 12.24 – Error metrics for imputed values in a time-series
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.24 – 时间序列中插补值的误差指标
- en: 'The **Seasonally Decomposed Imputation** (**seadec**) strategy seems to be
    the best one. Here’s the plot of missing values according to this strategy:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: '**季节分解插补**（**seadec**）策略似乎是最好的。以下是根据此策略绘制缺失值的图表：'
- en: '![Figure 12.25 – Representation of imputed values in the time-series](img/file330.png)'
  id: totrans-308
  prefs: []
  type: TYPE_IMG
  zh: '![图12.25 – 时间序列中插补值的表示](img/file330.png)'
- en: Figure 12.25 – Representation of imputed values in the time-series
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.25 – 时间序列中插补值的表示
- en: Let's now look at how to use what we've learned so far about missing values
    in Power BI.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看看如何在Power BI中应用我们迄今为止关于缺失值的所学知识。
- en: Imputing missing values in Power BI
  id: totrans-311
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在Power BI中插补缺失值
- en: We have delved into the theory and techniques of imputing missing values, whether
    you are dealing with a tabular dataset or a time-series, precisely because in
    Power BI there is no way to adopt them through native tools, except for the naïve
    solution of replacing them with a default value (such as fixed value, mean, or
    median). In fact, when the business analyst finds themselves needing to fill in
    the gaps in the data, they often ask for the help of a data scientist or someone
    with the statistical knowledge to tackle the problem. Now that you’ve studied
    this chapter, you’re able to tackle it on your own!
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 我们深入探讨了缺失值插补的理论和技术，无论是处理表格数据集还是时间序列数据，这正是因为在Power BI中，除了用默认值（如固定值、平均值或中位数）替换它们的简单解决方案外，没有其他原生工具可以采用它们。实际上，当业务分析师发现自己需要填补数据中的空白时，他们通常会寻求数据科学家或具有统计知识的人的帮助来解决该问题。现在你已经学习了这一章，你能够自己解决这个问题了！
- en: 'Let’s apply what we did in the previous sections for tabular and time-series
    data in Power BI:'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们应用我们在前几节中为Power BI中的表格和时间序列数据所做的操作：
- en: Open Power BI Desktop and make sure it is referencing the latest engine.
  id: totrans-314
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开Power BI桌面版，并确保它引用的是最新引擎。
- en: Click **Get data**, search for `web`, and double-click on the **Web** connector.
  id: totrans-315
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**获取数据**，搜索`web`，然后双击**Web**连接器。
- en: 'Enter the following URL and click **OK**: [http://bit.ly/titanic-dataset-csv](http://bit.ly/titanic-dataset-csv).'
  id: totrans-316
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入以下URL并点击**确定**：[http://bit.ly/titanic-dataset-csv](http://bit.ly/titanic-dataset-csv)。
- en: On the next import screen, click **Transform Data**.
  id: totrans-317
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在下一个导入屏幕上，点击**转换数据**。
- en: Go to the **Transform** tab, click on **Run R script**, copy the script in the
    `06-impute-tabular-missing-values-in-power-bi-with-r.R` file in the `Chapter12\R`
    folder, paste it into the editor, and then click **OK**.
  id: totrans-318
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 切换到**转换**选项卡，点击**运行R脚本**，复制`Chapter12\R`文件夹中的`06-impute-tabular-missing-values-in-power-bi-with-r.R`文件中的脚本，将其粘贴到编辑器中，然后点击**确定**。
- en: You may be asked to configure the privacy levels of the R script and the CSV
    file. In this case, select both the **Organizational** and **Public** level.
  id: totrans-319
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可能需要配置R脚本和CSV文件的隐私级别。在这种情况下，选择**组织**和**公共**级别。
- en: We are only interested in the data in `corr_tbl`. So, click on its **Table**
    value.
  id: totrans-320
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们只对`corr_tbl`中的数据感兴趣。因此，点击其**表**值。
- en: 'As a result, you’ll see the table containing the correlation coefficients calculated
    using MICE and the pooling method provided by the multivariate imputation technique:'
  id: totrans-321
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 因此，你会看到包含使用MICE和多元插补技术提供的池化方法计算的相关系数的表格：
- en: '![Figure 12.26 – Correlation table calculated with the multivariate imputation
    technique](img/file331.png)'
  id: totrans-322
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图12.26 – 使用多元插补技术计算的相关表](img/file331.png)'
- en: Figure 12.26 – Correlation table calculated with the multivariate imputation
    technique
  id: totrans-323
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图12.26 – 使用多元插补技术计算的相关表
- en: Go to the **Home** tab and click **Close & Apply**.
  id: totrans-324
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 切换到**主页**标签页，然后点击**关闭并应用**。
- en: Click **Get data** and double-click on the **Text/CSV** connector.
  id: totrans-325
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**获取数据**，然后双击**文本/CSV**连接器。
- en: Select the `air.csv` file you can find in the `Chapter12` folder and click **Open**.
  id: totrans-326
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**Chapter12**文件夹中找到`air.csv`文件，然后点击**打开**。
- en: On the next import screen, click **Transform Data**.
  id: totrans-327
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在下一个导入屏幕上，点击**转换数据**。
- en: 'Power BI automatically interprets the `date` text field as a date field, and
    therefore applies a **Changed Type** operation from Text to Date. In order to
    correctly process dates within an R script with the `lubridate` package, you must
    delete the **Changed Type** step by clicking on the red cross before inserting
    the R script:'
  id: totrans-328
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Power BI自动将`date`文本字段解释为日期字段，因此应用了一个从文本到日期的**更改类型**操作。为了正确处理使用`lubridate`包的R脚本中的日期，你必须删除**更改类型**步骤，在插入R脚本之前点击红色的叉号：
- en: '![Figure 12.27 – Delete the Changed Type step](img/file332.png)'
  id: totrans-329
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图12.27 – 删除更改类型步骤](img/file332.png)'
- en: Figure 12.27 – Delete the Changed Type step
  id: totrans-330
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图12.27 – 删除更改类型步骤
- en: Go to the **Transform** tab, click on **Run R script**, copy the script in the
    `07-impute-time-series-missing-values-in-power-bi-with-r.R` file in the `Chapter12\R`
    folder, paste it into the editor, and then click **OK**.
  id: totrans-331
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 转到**转换**选项卡，点击**运行R脚本**，复制`Chapter12\R`文件夹中`07-impute-time-series-missing-values-in-power-bi-with-r.R`文件中的脚本，将其粘贴到编辑器中，然后点击**确定**。
- en: You may be asked to configure the privacy levels of the R script and the CSV
    file. In this case, select both the **Organizational** and **Public** level.
  id: totrans-332
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可能需要您配置R脚本和CSV文件的隐私级别。在这种情况下，请选择**组织**和**公共**级别。
- en: 'As a result, you’ll see the table containing the original time-series (the
    `value` column) and other time-series obtained through different imputation algorithms
    (each in a different column):'
  id: totrans-333
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 因此，您将看到包含原始时间序列（`value`列）和通过不同插补算法获得的其他时间序列（每个都在不同的列中）的表格：
- en: '![Figure 12.28 – Table with imputed time-series](img/file333.png)'
  id: totrans-334
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图12.28 – 填充时间序列的表格](img/file333.png)'
- en: Figure 12.28 – Table with imputed time-series
  id: totrans-335
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图12.28 – 填充时间序列的表格
- en: Go to the **Home** tab and click **Close & Apply**.
  id: totrans-336
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 转到**主页**选项卡，然后点击**关闭并应用**。
- en: Impressive! You managed to apply the most complex missing value imputation algorithms
    to a tabular dataset and a time-series in Power BI with minimal effort. Congratulations!
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 太棒了！您成功地将最复杂的缺失值插补算法应用于Power BI中的表格数据集和时间序列，而且几乎不费吹灰之力。恭喜您！
- en: Summary
  id: totrans-338
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you learned what outliers are, what causes them generally,
    and how they are treated. You also learned how to identify them based on the number
    of variables involved and their given type, both in Python and in R.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您学习了什么是异常值，它们通常由什么引起，以及如何处理它们。您还学习了如何根据涉及的变量数量和它们的给定类型，在Python和R中识别它们。
- en: Another important topic you covered was how to impute missing values in tabular
    and time-series datasets. You learned how to diagnose them and impute them with
    R.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 您还涉及的一个重要主题是如何在表格和时间序列数据集中填充缺失值。您学习了如何诊断它们并使用R进行插补。
- en: After that, you implemented the value imputation algorithms in Power BI.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，您在Power BI中实现了值插补算法。
- en: In the next chapter, you will see how to use machine learning algorithms in
    Power BI without the need for Premium or Embedded capabilities.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，您将了解如何在Power BI中使用机器学习算法，而无需使用高级版或嵌入式功能。
- en: References
  id: totrans-343
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'For additional reading, check out the following books and articles:'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 对于额外的阅读，请参阅以下书籍和文章：
- en: '*Add Marginal Plot to ggplot2 Scatterplot Using ggExtra Package in R* ([https://statisticsglobe.com/ggplot2-graphic-with-marginal-plot-in-r](https://statisticsglobe.com/ggplot2-graphic-with-marginal-plot-in-r))'
  id: totrans-345
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*在R中使用ggExtra包将边际图添加到ggplot2散点图* ([https://statisticsglobe.com/ggplot2-graphic-with-marginal-plot-in-r](https://statisticsglobe.com/ggplot2-graphic-with-marginal-plot-in-r))'
- en: '*5 Things You Should Know About Covariance* ([https://towardsdatascience.com/5-things-you-should-know-about-covariance-26b12a0516f1](https://towardsdatascience.com/5-things-you-should-know-about-covariance-26b12a0516f1))'
  id: totrans-346
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*关于协方差你应该知道的5件事* ([https://towardsdatascience.com/5-things-you-should-know-about-covariance-26b12a0516f1](https://towardsdatascience.com/5-things-you-should-know-about-covariance-26b12a0516f1))'
- en: '*Mahalanobis Distance and its Limitations* ([https://rpubs.com/jjsuarestra99/mahalanobis](https://rpubs.com/jjsuarestra99/mahalanobis))'
  id: totrans-347
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*马氏距离及其局限性* ([https://rpubs.com/jjsuarestra99/mahalanobis](https://rpubs.com/jjsuarestra99/mahalanobis))'
- en: '*Box-Cox Transformation Explained* ([https://towardsdatascience.com/box-cox-transformation-explained-51d745e34203](https://towardsdatascience.com/box-cox-transformation-explained-51d745e34203))'
  id: totrans-348
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*Box-Cox转换解释* ([https://towardsdatascience.com/box-cox-transformation-explained-51d745e34203](https://towardsdatascience.com/box-cox-transformation-explained-51d745e34203))'
- en: '*How to Use Power Transforms for Machine Learning* ([https://machinelearningmastery.com/power-transforms-with-scikit-learn/](https://machinelearningmastery.com/power-transforms-with-scikit-learn/))'
  id: totrans-349
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*如何在R中使用Power Transforms进行机器学习* ([https://machinelearningmastery.com/power-transforms-with-scikit-learn/](https://machinelearningmastery.com/power-transforms-with-scikit-learn/))'
- en: '*The Relationship between the Mahalanobis Distance and the Chi-Squared Distribution*
    ([https://markusthill.github.io/mahalanbis-chi-squared/](https://markusthill.github.io/mahalanbis-chi-squared/))'
  id: totrans-350
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*马氏距离与卡方分布的关系* ([https://markusthill.github.io/mahalanbis-chi-squared/](https://markusthill.github.io/mahalanbis-chi-squared/))'
- en: '*Using the recipes package for easy pre-processing* ([http://www.rebeccabarter.com/blog/2019-06-06_pre_processing/](http://www.rebeccabarter.com/blog/2019-06-06_pre_processing/))'
  id: totrans-351
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*使用recipes包进行简单的预处理* ([http://www.rebeccabarter.com/blog/2019-06-06_pre_processing/](http://www.rebeccabarter.com/blog/2019-06-06_pre_processing/))'
- en: '*Anomaly detection* ([https://docs.microsoft.com/en-us/power-bi/visuals/power-bi-visualization-anomaly-detection](https://docs.microsoft.com/en-us/power-bi/visuals/power-bi-visualization-anomaly-detection))'
  id: totrans-352
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*异常检测* ([https://docs.microsoft.com/en-us/power-bi/visuals/power-bi-visualization-anomaly-detection](https://docs.microsoft.com/en-us/power-bi/visuals/power-bi-visualization-anomaly-detection))'
- en: '*Missing data: mechanisms, methods, and messages* ([http://www.i-deel.org/uploads/5/2/4/1/52416001/chapter_4.pdf](http://www.i-deel.org/uploads/5/2/4/1/52416001/chapter_4.pdf))'
  id: totrans-353
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*缺失数据：机制、方法和信息* ([http://www.i-deel.org/uploads/5/2/4/1/52416001/chapter_4.pdf](http://www.i-deel.org/uploads/5/2/4/1/52416001/chapter_4.pdf))'
- en: '*Multiple imputation by chained equations: what is it and how does it work?*
    ([https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3074241/](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3074241/))'
  id: totrans-354
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*多重插补通过链式方程：它是怎样的，以及它是如何工作的？* ([https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3074241/](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3074241/))'
- en: '*Amelia II: A Program for Missing Data* ([https://www.jstatsoft.org/article/view/v045i07](https://www.jstatsoft.org/article/view/v045i07))'
  id: totrans-355
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*Amelia II：缺失数据处理程序* ([https://www.jstatsoft.org/article/view/v045i07](https://www.jstatsoft.org/article/view/v045i07))'
- en: '*All about Categorical Variable Encoding* ([https://towardsdatascience.com/all-about-categorical-variable-encoding-305f3361fd02](https://towardsdatascience.com/all-about-categorical-variable-encoding-305f3361fd02))'
  id: totrans-356
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*关于分类变量编码的所有内容* ([https://towardsdatascience.com/all-about-categorical-variable-encoding-305f3361fd02](https://towardsdatascience.com/all-about-categorical-variable-encoding-305f3361fd02))'
