- en: Chapter 4. Classifying UFO Sightings
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第四章：UFO目击分类
- en: In this chapter, we're going to look at a dataset of UFO sightings. Sometimes,
    data analysis begins with a specific question or problem. Sometimes, however,
    it's more nebulous and vague. We'll engage with this UFO sighting dataset, and
    along the way, we'll learn more about data exploration, data visualization, and
    topic modeling before we dive into Naïve Bayesian classification.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将研究一个UFO目击数据集。有时，数据分析从具体的问题或问题开始。有时，然而，它可能更加模糊和含糊。我们将与这个UFO目击数据集互动，并在深入研究朴素贝叶斯分类之前，了解更多关于数据探索、数据可视化和主题建模的知识。
- en: This dataset was collected by the **National UFO Reporting Center** (**NUFORC)**,
    and is available at [http://www.nuforc.org/](http://www.nuforc.org/). They have
    included dates, rough locations, shapes, and descriptions of the sightings. We'll
    download and pull in this dataset. We'll see how to extract more structured data
    from messy, free-form text. And from there, we'll see how to visualize, analyze,
    and gain insights into our data.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 这个数据集是由**国家不明飞行物报告中心**（**NUFORC**）收集的，可在[http://www.nuforc.org/](http://www.nuforc.org/)找到。他们包括了目击日期、大致位置、形状和目击描述。我们将下载并引入这个数据集。我们将了解如何从混乱的自由格式文本中提取更多结构化数据。然后，我们将了解如何可视化、分析和深入了解我们的数据。
- en: In the process, we'll discover when is the best time to look for UFOs. We'll
    also learn what their important characteristics are. And we'll learn how to tell
    a description of a possible hoax sighting from one that may be real. In the end,
    hopefully, we'll be better prepared for seeing one of these ourselves. After all,
    we'll know when to look and for what to look.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个过程中，我们将发现何时是寻找UFO的最佳时间。我们还将了解它们的重要特征。我们还将学习如何区分可能的骗局目击描述和可能的真实目击描述。最终，希望我们能更好地准备自己看到其中之一。毕竟，我们将知道何时寻找以及寻找什么。
- en: Getting the data
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 获取数据
- en: 'For this chapter, actually acquiring the data will be relatively easy. In other
    chapters, this step involves screen scraping, SPARQL, or other data extraction,
    munging, and cleaning techniques. For this dataset, we''ll just download it from
    Infochimps ([http://www.infochimps.com/](http://www.infochimps.com/)). Infochimps
    is a company (and their website) devoted to Big Data and doing more with data
    analysis. They provide a collection of datasets that are online and freely available.
    To download this specific dataset, browse to [http://www.infochimps.com/datasets/60000-documented-ufo-sightings-with-text-descriptions-and-metada](http://www.infochimps.com/datasets/60000-documented-ufo-sightings-with-text-descriptions-and-metada)
    and download the data from the link there, as shown in the following screenshot:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本章，实际上获取数据将会相对容易。在其他章节中，这一步涉及到屏幕抓取、SPARQL或其他数据提取、整理和清洗技术。对于这个数据集，我们只需从Infochimps（[http://www.infochimps.com/](http://www.infochimps.com/)）下载即可。Infochimps是一家公司（以及他们的网站），致力于大数据和数据分析。他们提供了一系列在线且免费可用的数据集。要下载这个特定的数据集，请浏览到[http://www.infochimps.com/datasets/60000-documented-ufo-sightings-with-text-descriptions-and-metada](http://www.infochimps.com/datasets/60000-documented-ufo-sightings-with-text-descriptions-and-metada)，然后从那里下载数据，如下面的截图所示：
- en: '![Getting the data](img/4139OS_04_01.jpg)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![获取数据](img/4139OS_04_01.jpg)'
- en: The data is in a ZIP-compressed file. This expands the files into the `chimps_16154-2010-10-20_14-33-35`
    directory. This contains a file that lists metadata for the dataset as well as
    the data itself in several different formats. For the purposes of this chapter,
    we'll use the **tab separated values** (**TSV**) file. It's similar to a **comma
    separated values** (**CSV**) file, but it uses the tab character as a delimiter
    instead of a comma. This works nicely, because the tab character is used less
    often in text files in general, so it's often possible to use this data format
    without escaping many, if any, fields.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 数据在一个ZIP压缩文件中。它将文件扩展到`chimps_16154-2010-10-20_14-33-35`目录。这个目录包含一个列出数据集元数据的文件以及以几种不同格式存储的数据本身。为了本章的目的，我们将使用**制表符分隔值**（**TSV**）文件。它与**逗号分隔值**（**CSV**）文件类似，但使用制表符作为分隔符而不是逗号。这很好，因为制表符在文本文件中通常使用得较少，因此通常可以在不转义许多（如果有的话）字段的情况下使用这种数据格式。
- en: 'If we open the `16154.yaml` file, we''ll see metadata and other information
    about the dataset. And we learn that the fields in the dataset are as follows:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们打开`16154.yaml`文件，我们将看到关于数据集的元数据和其它信息。我们还将了解到数据集中的字段如下：
- en: '`sighted_at`: The date (as YYYYMMDD) the sighting happened'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sighted_at`：目击发生的日期（格式为YYYYMMDD）'
- en: '`reported_at`: The date the sighting was reported to NUFORC'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`reported_at`：目击报告给NUFORC的日期'
- en: '`location`: The city and state the event happened in'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`location`: 事件发生的城市和州'
- en: '`shape`: The shape of the object'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`shape`: 物体的形状'
- en: '`duration`: The duration the event lasted'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`duration`: 事件持续的时间'
- en: '`description`: A longer description of the sighting as a raw text string'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`description`: 对目击事件的更详细描述，以原始文本字符串形式'
- en: 'We can get a better feel for this data by examining a row from the downloaded
    file. The following table represents what the fields contain for that record:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过检查下载的文件中的一行来更好地了解这些数据。以下表格表示该记录的字段包含的内容：
- en: '| Field | Value |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| 字段 | 值 |'
- en: '| --- | --- |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `sighted_at` | 19950202 |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| `sighted_at` | 19950202 |'
- en: '| `reported_at` | 19950203 |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| `reported_at` | 19950203 |'
- en: '| `location` | Denmark, WI |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| `location` | 丹麦，威斯康星州 |'
- en: '| `shape` | Cone |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| `shape` | 锥形 |'
- en: '| `duration` | 75 min |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| `duration` | 75 min |'
- en: '| `description` | Caller, and apparently several other people, witnessed multiple
    strange craft streaking through the night sky in the vicinity of Denmark and Mirabel,
    WI. Craft were seen to streak overhead, as well as to descend vertically, as fast
    as a meteorite, then stop suddenly just above the ground. During the last 30 minutes
    of the sighting, aircraft, which appeared to be US military craft, were seen either
    pursuing, or chaperoning, the strange craft. The objects were cone shaped, with
    a red nose and a green tail (sic). |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| `description` | 叫声者，以及显然还有其他一些人，目击了多架不明飞行物在丹麦和威斯康星州米尔贝尔附近夜空中划过。飞行物被看到在天空中划过，以及垂直下降，速度如同流星，然后突然在地面上方停止。在目击的最后30分钟内，可以看到看起来像是美国军事飞机的飞机在追逐或陪伴这些不明飞行物。这些物体呈锥形，前端红色，尾部绿色（原文如此）。|'
- en: Browsing through other rows, you will observe that some important fields—shape
    and duration—may be missing data. The description has XML entities and abbreviations
    such as *w/* and *repts*.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 浏览其他行时，你会注意到一些重要字段——形状和持续时间——可能缺少数据。描述中包含XML实体和缩写，如*w/*和*repts*。
- en: Let's see what we can do with that.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们能用它做什么。
- en: Extracting the data
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提取数据
- en: 'Before we go further, let''s look at the following Leiningen 2 ([http://leiningen.org/](http://leiningen.org/))
    `project.clj` file that we''ll use for this chapter:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续之前，让我们看看以下用于本章的Leiningen 2 ([http://leiningen.org/](http://leiningen.org/))
    `project.clj`文件：
- en: '[PRE0]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The preceding code shows that over the course of this chapter, we'll parse time
    with the `clj-time` library ([https://github.com/clj-time/clj-time](https://github.com/clj-time/clj-time)).
    This provides a rich, robust date and time library. We'll also use ClojureScript
    ([https://github.com/clojure/clojurescript](https://github.com/clojure/clojurescript))
    for the visualizations.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码表明，在本章的整个过程中，我们将使用`clj-time`库([https://github.com/clj-time/clj-time](https://github.com/clj-time/clj-time))来解析时间。这是一个丰富、健壮的日期和时间库。我们还将使用ClojureScript
    ([https://github.com/clojure/clojurescript](https://github.com/clojure/clojurescript))进行可视化。
- en: 'Our first step in working with this data is to load it from the data file.
    To facilitate this, we''ll read it into a record type that we''ll define just
    to store the UFO sightings. We''ll work with the `model.clj` file placed at `src/ufo_data/`.
    The following is a namespace declaration with the imports and requirements that
    we''ll use in this module:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们处理这些数据的第一步是从数据文件中加载它。为了方便起见，我们将将其读入一个我们专门定义来存储UFO目击的记录类型。我们将使用位于`src/ufo_data/`的`model.clj`文件。以下是一个命名空间声明，其中包含了我们在本模块中使用的导入和要求：
- en: '[PRE1]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Now we''ll define the record. It simply lists the same fields that we walked
    through earlier. We also include a few new fields. We''ll use these to parse the
    year, month, and season from the `reported_at` field as follows:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将定义记录。它简单地列出了我们之前走过的相同字段。我们还包含了一些新字段。我们将使用这些字段从`reported_at`字段中解析年份、月份和季节，如下所示：
- en: '[PRE2]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now, when we take a row from the TSV file, we''ll need to parse it into one
    of these structures. Because each line of input only has six fields, we''ll make
    sure that it''s padded out to nine fields. We''ll also verify that there are exactly
    six input fields. If there are more or less, we''ll take steps to either further
    pad the fields or to join some of the fields, as shown in the following code:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，当我们从TSV文件中取出一行时，我们需要将其解析为这些结构之一。因为输入的每一行只有六个字段，所以我们将确保将其填充到九个字段。我们还将验证是否有恰好六个输入字段。如果字段更多或更少，我们将采取措施进一步填充字段或合并一些字段，如下面的代码所示：
- en: '[PRE3]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Some of the fields (the most important ones, actually) are dates, and we''ll
    want to parse them into valid date objects. To do this, we''ll use the excellent
    `clj-time` library ([https://github.com/clj-time/clj-time](https://github.com/clj-time/clj-time)).
    This provides a more "Clojuresque" interface for the Joda time library ([http://joda-time.sourceforge.net/](http://joda-time.sourceforge.net/)).
    The code that does this takes a custom date format and attempts to parse the dates.
    If any fail, we just fall back on using `nil`. Look at the following code:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 一些字段（实际上是最重要的字段）是日期，我们将想要将它们解析成有效的日期对象。为此，我们将使用出色的`clj-time`库([https://github.com/clj-time/clj-time](https://github.com/clj-time/clj-time))。它为Joda时间库([http://joda-time.sourceforge.net/](http://joda-time.sourceforge.net/))提供了一个更“Clojuresque”的接口。执行此操作的代码接受一个自定义日期格式并尝试解析日期。如果任何失败，我们则回退到使用`nil`。看看以下代码：
- en: '[PRE4]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We use the following function to coerce the raw string date fields into the
    more useful date objects that Joda time provides:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用以下函数将原始字符串日期字段强制转换为Joda时间提供的更有用的日期对象：
- en: '[PRE5]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'That''s all that we need to load the data. Now we can write the function that
    will actually take care of reading the data from the file on disk into a sequence
    of records, as follows:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是我们加载数据所需的所有内容。现在我们可以编写一个函数，该函数将实际负责从磁盘上的文件读取数据到记录序列中，如下所示：
- en: '[PRE6]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Now that we can read in the data, we can start picking it apart and learn about
    the data that we have.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们能够读取数据，我们可以开始分析它并了解我们所拥有的数据。
- en: Dealing with messy data
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理杂乱的数据
- en: The first thing that we need to deal with is qualitative data from the `shape`
    and `description` fields.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先需要处理的是来自`shape`和`description`字段的定性数据。
- en: 'The `shape` field seems like a likely place to start. Let''s see how many items
    have good data for it:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '`shape`字段似乎是一个开始的好地方。让我们看看有多少项目有关于它的良好数据：'
- en: '[PRE7]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'So 4 percent of the data does not have the `shape` field set to meaningful
    data. Let''s see what the most popular values for that field are:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，4%的数据没有将`shape`字段设置为有意义的值。让我们看看这个字段最流行的值是什么：
- en: '[PRE8]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Interesting! The most frequent shape isn't a shape at all. The values `other`
    and `unknown` also rank pretty high. We can use the `shape` field, but we need
    to keep these things in mind.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣！出现频率最高的并不是一个形状。`other`和`unknown`这两个值也排名相当高。我们可以使用`shape`字段，但我们需要记住这些事情。
- en: Visualizing UFO data
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可视化UFO数据
- en: 'We''ll spend a good bit of time visualizing the data, and we''ll use the same
    system that we have in the previous chapters: a bit of HTML, a splash of CSS,
    and a lot of JavaScript, which we''ll generate from ClojureScript.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在可视化数据上花费相当多的时间，并且我们将使用与之前章节相同的方法：一点HTML，一点CSS，以及大量的JavaScript，这些我们将从ClojureScript生成。
- en: 'We''ve already taken care of the configuration for using ClojureScript in the
    `project.clj` file that I mentioned earlier. The rest of it involves a couple
    of more parts:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经在之前提到的`project.clj`文件中处理了使用ClojureScript的配置。其余的部分涉及几个更多部分：
- en: The code to generate the JSON data for the graph. This will be in the `src/ufo_data/analysis.clj`
    file. We'll write this code first.
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成图表JSON数据的代码。这将位于`src/ufo_data/analysis.clj`文件中。我们首先编写这段代码。
- en: An HTML page that loads the JavaScript libraries that we'll use—jQuery ([https://jquery.org/](https://jquery.org/))
    and D3 ([http://d3js.org/](http://d3js.org/))—and creates a `div` container in
    which to put the graph itself.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个加载我们将要使用的JavaScript库（jQuery [https://jquery.org/](https://jquery.org/) 和 D3
    [http://d3js.org/](http://d3js.org/)）的HTML页面，并创建一个`div`容器来放置图表本身。
- en: The source code for the graph. This will include a namespace for utilities in
    `src-cljs/ufo-data/utils.cljs` and the main namespace at `src-cljs/ufo-data/viz.cljs`.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图表的源代码。这包括`src-cljs/ufo-data/utils.cljs`中的工具命名空间和`src-cljs/ufo-data/viz.cljs`中的主命名空间。
- en: With these prerequisites in place, we can start creating the graph of the frequencies
    of the different shapes.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些先决条件就绪后，我们可以开始创建不同形状频率的图表。
- en: 'First, we need to make sure we have what we need for this namespace. This will
    be in the `src/ufo_data/analysis.clj` file. The following code gives the `ns`
    declaration. Most of these dependencies won''t be needed immediately, but we will
    use them at some point in this chapter:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要确保我们拥有这个命名空间所需的一切。这将在`src/ufo_data/analysis.clj`文件中。以下代码给出了`ns`声明。这些依赖中的大多数在短期内不会用到，但我们将在这个章节的某个地方使用它们：
- en: '[PRE9]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Now, we''ll define a rather long function that takes the input data. It will
    pull out the `shape` field, remove blanks, break it into words, and count their
    frequencies. A few of the functions that this function uses aren''t listed here,
    but they''re available in the code download for this chapter. Then, the following
    function will remove any shapes that don''t occur at least once, reverse-sort
    them by their frequencies, and finally turn them into map structures in a vector:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将定义一个相当长的函数，该函数接受输入数据。它将提取 `shape` 字段，删除空白，将其分解成单词，并计算它们的频率。这个函数使用的几个函数没有在这里列出，但它们可以在本章的代码下载中找到。然后，以下函数将删除至少未出现一次的任何形状，按频率降序排列，并将其最终转换为向量中的映射结构：
- en: '[PRE10]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We can then use the `clojure.data.json` package ([https://github.com/clojure/data.json](https://github.com/clojure/data.json))
    to save it to disk. I saved it to `www/term-freqs.json`. The following is a small
    sample of the first two records:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以使用 `clojure.data.json` 包 ([https://github.com/clojure/data.json](https://github.com/clojure/data.json))
    将其保存到磁盘。我将其保存到 `www/term-freqs.json`。以下是最初两个记录的小样本：
- en: '[PRE11]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Now we need a web page in which to draw the graph. I downloaded a template
    from the HTML 5 Boilerplate project ([http://html5boilerplate.com/](http://html5boilerplate.com/))
    and saved it as `www/term-freqs.html`. I removed almost everything inside the
    `body` tag. I left only the following `div` tag and a string of `script` tags:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们需要一个网页来绘制图表。我从 HTML 5 Boilerplate 项目 ([http://html5boilerplate.com/](http://html5boilerplate.com/))
    下载了一个模板，并将其保存为 `www/term-freqs.html`。我在 `body` 标签内几乎删除了所有内容。我只留下了以下 `div` 标签和一串
    `script` 标签：
- en: '[PRE12]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This takes care of the HTML page, so we can move on to the ClojureScript that
    will create the graph.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这就处理了 HTML 页面，因此我们可以继续到创建图表的 ClojureScript。
- en: All of the ClojureScript files for this chapter will be in the `src-cljs` directory.
    Under this directory is a tree of Clojure namespaces, similar to how the code
    in `src` is organized for Clojure. Most of the ClojureScript for this chapter
    will be in the `src-cljs/ufo-data/viz.cljs` file. There are a number of utility
    functions in another namespace, but those are primarily boilerplate, and you can
    find them in the code download for this chapter. The following function loads
    the data and creates the graph. We'll walk through it step-by-step.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的所有 ClojureScript 文件都将位于 `src-cljs` 目录下。在这个目录下是一个 Clojure 命名空间树，类似于 `src`
    目录中 Clojure 代码的组织方式。本章的大部分 ClojureScript 都将位于 `src-cljs/ufo-data/viz.cljs` 文件中。在另一个命名空间中有一些实用函数，但它们主要是样板代码，你可以在本章的代码下载中找到它们。以下函数加载数据并创建图表。我们将一步一步地介绍它。
- en: '[PRE13]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The part of the function before the highlighting sets up the axes, the scales,
    and the parent SVG element. Then, we load the data from the server. Once it's
    loaded, we set the domains on the axes and draw the axes themselves.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 函数中突出显示之前的部分设置了坐标轴、刻度和父 SVG 元素。然后，我们从服务器加载数据。一旦加载完成，我们就在坐标轴上设置域，并绘制坐标轴本身。
- en: 'The main part of the function is highlighted. This creates the bars in the
    SVG element. All these tasks take place in the following manner:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 函数的主要部分被突出显示。这将在 SVG 元素中创建条形图。所有这些任务都以以下方式完成：
- en: '`(selectAll ".bar") (data data)`: This command selects all elements with the
    `bar` class. Currently, there aren''t any elements to select because we haven''t
    created any, but that''s all right. Then it joins those elements with the data.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`(selectAll ".bar") (data data)`: 这个命令选择所有具有 `bar` 类的元素。目前还没有任何元素可供选择，因为我们还没有创建任何元素，但这没关系。然后它将这些元素与数据连接起来。'
- en: '`(enter)`: This command starts processing any data rows that don''t have previously
    created `.bar` elements.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`(enter)`: 这个命令开始处理任何之前未创建 `.bar` 元素的数据行。'
- en: '`(append "rect")`: For each row of data with no `.bar` elements, this command
    appends a `rect` tag to the element.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`(append "rect")`: 对于没有 `.bar` 元素的数据行，这个命令将一个 `rect` 标签附加到元素上。'
- en: '`(attr "id" #(str "id" (get-shape %))) (attr "class" "bar")`: This line of
    code adds the `ID` and `class` attributes to the rectangle.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`(attr "id" #(str "id" (get-shape %))) (attr "class" "bar")`: 这行代码为矩形添加了 `ID`
    和 `class` 属性。'
- en: '`(attr "x" (comp x get-shape)) (attr "y" (comp y get-count))`: This line of
    code populates the *x* and *y* attributes with values from each data row, projected
    onto the graph''s pixel grid.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`(attr "x" (comp x get-shape)) (attr "y" (comp y get-count))`: 这行代码使用来自每个数据行的值填充
    `x` 和 `y` 属性，这些值投影到图表的像素网格上。'
- en: '`(attr "width" (.rangeBand x)) (attr "height" #(- u/height (y (get-count %)))))`:
    This line of code finally sets the height and width for each rectangle.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`(attr "width" (.rangeBand x)) (attr "height" #(- u/height (y (get-count %)))))`:
    这行代码最终为每个矩形设置了高度和宽度。'
- en: 'These commands together create the graph. There''s a little bit of CSS involved,
    also. Refer to the code download for all the details. But in the end, the graph
    looks as follows:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 这些命令共同创建了这个图表。还有一些CSS的参与。有关所有详细信息的代码下载请参阅。但最终，图表看起来如下：
- en: '![Visualizing UFO data](img/4139OS_04_02.jpg)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![可视化UFO数据](img/4139OS_04_02.jpg)'
- en: This set of files acts as a framework for all of the visualizations and charts
    that we'll see in this chapter. Although bar charts are simple, once in place,
    this framework can be used for much more complex and sophisticated types of graphs.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这组文件作为本章中我们将看到的全部可视化和图表的框架。虽然条形图很简单，但一旦放置，这个框架可以用于更复杂和高级类型的图表。
- en: 'This graph shows us more clearly what the quick frequency dump at the REPL
    also showed us: most of the people listed the shape as *light*. More than twice
    as many people listed the shape of *light* as listed the runner-up, *triangle*.
    In fact, almost one in five observations listed that as the shape.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这个图表更清楚地显示了我们之前在REPL中快速频率转储所看到的内容：大多数人将形状描述为*光*。将形状描述为*光*的人数是第二名*三角形*的两倍多。事实上，几乎五分之一的现象都被列为此形状。
- en: Now let's try to get a feel for some other facts about this data.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们尝试了解一些关于这些数据的其他事实。
- en: 'First, when have UFOs been observed? To find this out, we have to group the
    observations by the year from the `sighted-at` field. We group the items under
    each year, and then we save that to graph it. The following are the functions
    in `ufo-data.analysis` that will take care of getting the right data for us:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，UFO何时被观测到？为了找出这个，我们必须根据`sighted-at`字段中的年份对观测进行分组。我们将每个年份下的项目分组，然后将其保存以进行绘图。以下是在`ufo-data.analysis`中处理获取正确数据的函数：
- en: '[PRE14]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Once we''ve created the graph from this data, the following is the output:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们从这个数据中创建出图表，以下就是输出：
- en: '![Visualizing UFO data](img/4139OS_04_03.jpg)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![可视化UFO数据](img/4139OS_04_03.jpg)'
- en: This graph suggests that the number of observations in the dataset increased
    dramatically in the mid-1990s, and that they have continued to increase. NUFORC,
    the organization that collects the data, was established in 1974\. I was unable
    to discover when they began collecting data online, but the increased widespread
    use of the Internet could also be a factor in the increase in reported sightings.
    Also, wider cultural trends, such as the popularity of X-Files, may have contributed
    to a greater awareness of UFOs during this time period.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 这个图表表明，数据集中的观测数量在1990年代中期急剧增加，并且一直在增加。收集这些数据的组织NUFORC成立于1974年。我无法发现他们何时开始在线收集数据，但互联网的广泛使用也可能导致了报告的目击事件增加。此外，更广泛的文化趋势，如《X档案》的流行，可能也在这段时间内增加了对UFO的认识。
- en: As we continue to get to know our data, another interesting distribution is
    looking at the number of sightings each month. The process for getting this data
    is very similar to the process for getting the number of sightings by year, so
    we won't go into that now.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们继续了解我们的数据，另一个有趣的分布是查看每个月的目击次数。获取这些数据的过程与按年份获取目击次数的过程非常相似，所以我们现在不会深入讨论。
- en: '![Visualizing UFO data](img/4139OS_04_04.jpg)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![可视化UFO数据](img/4139OS_04_04.jpg)'
- en: The preceding graph shows that the summer, starting in June, is a good time
    to see a UFO. One explanation for this is that during these months, people are
    outside more in the evenings.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的图表显示，从6月开始，夏天是看到UFO的好时机。一个解释是，在这些月份，人们在晚上更多地待在外面。
- en: Description
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 描述
- en: While the *shape* field is important, the *description* has more information.
    Let's see what we can do with it.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然形状字段很重要，但描述字段包含更多信息。让我们看看我们能用它做什么。
- en: 'First, let''s examine a few and see what some of them look like. The following
    example is one that I selected randomly:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们考察几个例子，看看它们的样子。以下是我随机选择的一个例子：
- en: '*Large boomerang shaped invisible object blocked starlight while flying across
    sky. I have a sketch and noted the year was 1999, but did not write down the day.
    The sighting took place in the late evening when it was completely dark and the
    sky was clear and full of stars. Out of the corner of my eye, I noticed movement
    in the sky from the north moving to the south. When I looked closer, however,
    it wasn&rsquo;t an object that I was seeing move, rather it was the disappearance
    and reappearance of stars behind an object. The object itself was black or invisible
    with no lights. Given the area of stars that were blocked out, I would say the
    object was five times larger than a jet. It was completely silent. It was shaped
    like a boomerang only a little more rounded in front rather than triangle and
    a slightly sharper points on the &ldquo;wing&rdquo; tips. Since the object was
    invisible, I can only suggest the shape based on the black area absent of stars
    like a silhouette as it moved across the sky. If the object was indeed five times
    the size of a jet and flying at about the attitude of a jet, then it was moving
    much faster than a jet. I blinked a couple times, looked away and looked back,
    and then followed the object across the remainder of the horizon until it was
    out of sight. In all it took about 8-10 seconds to span the sky and flew at the
    same altitude the whole time. Given the triangular shape, I suppose it could have
    been a low-flying Stealth Bomber that just appeared much larger if flying low.
    But is a Stealth completely silent? Also, Stealth Bombers have three triangles
    pointing backwards from the mid section. The object I saw did not seem to have
    any mid section as such.((NUFORC Note: Witness indicates that date of incident
    is approximate. PD))*'
  id: totrans-92
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*一个大型回旋镖形状的无形物体在穿越天空时阻挡了星光。我有一张草图，并记下了年份是1999年，但没有写下具体日期。目击事件发生在傍晚时分，当时完全黑暗，天空清澈且繁星点点。我从眼角注意到天空从北到南有移动。然而，当我仔细观察时，我看到的并不是移动的物体，而是星星在物体背后的消失和再次出现。物体本身是黑色或无形的，没有灯光。考虑到被阻挡的星星区域，我认为这个物体比喷气式飞机大五倍。它完全无声。它的形状像回旋镖，只是前端略微圆润，而不是三角形，并且在“翼”尖上略微尖锐。由于物体是无形的，我只能根据它在天空中移动时缺少星星的黑色区域来推测形状，就像一个轮廓一样。如果物体确实比喷气式飞机大五倍，并且以大约喷气式飞机的姿态飞行，那么它的速度比喷气式飞机快得多。我眨了几次眼，转移了视线，然后又回过头来看，并跟随物体穿越剩余的地平线，直到它消失。总的来说，它用了大约8-10秒的时间横跨天空，并且整个过程中都在同一高度飞行。考虑到三角形的形状，我猜想它可能是一架低飞的隐形轰炸机，如果低飞的话，看起来会大得多。但是隐形轰炸机是完全无声的吗？而且，隐形轰炸机在中间部分有三个向后指的三角形。我看到的物体似乎没有这样的中间部分。（NUFORC备注：目击者表示事件日期是近似的。PD）*'
- en: 'So we can see that some examples are fairly long, and they may have characters
    encoded as HTML/XML entities (`&ldquo;` and `&rdquo;` in this example). And this
    quote is relatively clean: some have two or more words jammed together with just
    punctuation—often several periods—stuck between the words.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们可以看到一些例子相当长，并且它们可能包含作为HTML/XML实体编码的字符（例如本例中的`&ldquo;`和`&rdquo;`）。而且这个引用相对干净：有些单词只是用标点符号（通常是几个句号）挤在一起，中间没有空格。
- en: In order to deal with this data, we'll need to clean it up some and break the
    words out, or tokenize it. You can see the details of this in the code download,
    most of which is just pasting together a lot of string manipulation methods, but
    it's helpful to remind ourselves with what we're working and how we need to deal
    with it. I also filtered on a standard English stop-words list, which I augmented
    by adding a few words that are specific to the *description* fields, such as *PD*
    and *NUFORC*.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 为了处理这些数据，我们需要对其进行一些清理，并将单词拆分出来，或者说进行分词。您可以在代码下载中看到这方面的详细信息，其中大部分只是粘贴了许多字符串操作方法，但这对我们提醒自己在做什么以及如何处理这些数据是有帮助的。我还基于标准的英语停用词列表进行了过滤，并添加了一些特定于*描述*字段的单词，例如*PD*和*NUFORC*。
- en: 'Let''s see what the most frequent words are in the description fields:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看描述字段中最常见的单词有哪些：
- en: '[PRE15]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: This seems more like what we'd expect. The most frequent word is *object*, which
    seems appropriate for a corpus made up of people talking about things that they
    can't identify. The next two words are *light* and *lights*, which would be expected,
    especially since *light* is the most common item in the *shape* field.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 这似乎更符合我们的预期。最常见的单词是*object*，这对于由人们谈论他们无法识别的事物组成的语料库来说是合适的。接下来的两个单词是*light*和*lights*，这是可以预料的，尤其是由于*light*是*形状*字段中最常见的项目。
- en: 'Let''s graph these terms too. We won''t be able to see the details of the words''
    frequencies but it will give us a better feel for their distribution. There are
    enough tokens; however, we''ll only look at the 75 most frequent ones in the following
    graph:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们也将这些术语绘制成图。我们可能看不到单词频率的细节，但它将让我们更好地了解它们的分布。有足够的标记；然而，在下面的图表中，我们只查看75个最频繁的：
- en: '![Description](img/4139OS_04_05.jpg)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![描述](img/4139OS_04_05.jpg)'
- en: The distribution of these words seems very similar. In fact, it very roughly
    conforms to Zipf's law, which predicts the power-law distribution of many types
    of physical and social data, including language frequencies.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这些单词的分布看起来非常相似。事实上，它们非常粗略地符合Zipf定律，该定律预测了许多类型的物理和社会数据的幂律分布，包括语言频率。
- en: Topic modeling descriptions
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 主题建模描述
- en: Another way to gain a better understanding of the descriptions is to use topic
    modeling. We learned about this text mining and machine learning algorithm in
    [Chapter 3](ch03.html "Chapter 3. Topic Modeling – Changing Concerns in the State
    of the Union Addresses"), *Topic Modeling – Changing Concerns in the State of
    the Union Addresses*. In this case, we'll see if we can use it to create topics
    over these descriptions and to pull out the differences, trends, and patterns
    from this set of texts.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种更好地理解描述的方法是使用主题建模。我们在[第三章](ch03.html "第三章。主题建模——国情咨文中关注点的变化")中学习了这种文本挖掘和机器学习算法，*主题建模——国情咨文中关注点的变化*。在这种情况下，我们将看看我们是否可以使用它来创建这些描述的主题，并从中提取差异、趋势和模式。
- en: 'First, we''ll create a new namespace to handle our topic modeling. We''ll use
    the `src/ufo_data/tm.clj` file. The following is the namespace declaration for
    it:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将创建一个新的命名空间来处理我们的主题建模。我们将使用`src/ufo_data/tm.clj`文件。以下是对其的命名空间声明：
- en: '[PRE16]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The process for generating the topic model is very similar to the process that
    we used in [Chapter 3](ch03.html "Chapter 3. Topic Modeling – Changing Concerns
    in the State of the Union Addresses"), *Topic Modeling – Changing Concerns in
    the State of the Union Addresses*. The first change that we need to make is that
    we'll load the instances from the in-memory data that we read earlier in this
    chapter. We'll create a function that pushes an input collection into an array
    and uses `ArrayIterator` to then feed that array into the processing pipeline.
    The function to train the data is the same as it was in the previous chapter.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 生成主题模型的过程与我们之前在[第三章](ch03.html "第三章。主题建模——国情咨文中关注点的变化")中使用的过程非常相似。我们需要做的第一个改变是，我们将从本章早期读取的内存数据中加载实例。我们将创建一个函数，该函数将输入集合推送到数组中，然后使用`ArrayIterator`将数组喂入处理管道。训练数据的函数与上一章相同。
- en: 'In this chapter, we''ll look at more functions that help us introspect on the
    trained model, the instances, and the probabilities and keywords that are important
    to each topic. The first function returns the words that apply to a topic and
    their weights. We get the feature vectors from the model, and the words themselves
    from the instance list as follows:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨更多有助于我们内省训练模型、实例以及每个主题重要概率和关键词的功能。第一个功能返回适用于主题的单词及其权重。我们如下从模型获取特征向量，从实例列表中获取单词本身：
- en: '[PRE17]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The other reporting function that we''ll use ranks the instances by their probabilities
    for each topic. We can use this to look at the documents that are most likely
    to apply to any particular topic:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用的另一个报告功能按每个主题的概率对实例进行排名。我们可以使用这个功能来查看最有可能适用于任何特定主题的文档：
- en: '[PRE18]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: We can use these functions—as well as a few others based on these—from the REPL
    to explore our data.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用这些功能——以及基于这些功能的一些其他功能——从REPL中探索我们的数据。
- en: Generally, when deciding how many topics to use, we'll want to use some kind
    of objective metric to find a good definition of the sets. However, for exploring
    in an off-the-cuff way, we'll use something more subjective. First, after playing
    around with the number of topics, I chose to use a topic count of twelve. Since
    all of these are really about just one thing, UFO sightings, I didn't expect there
    to be too many meaningful topics, even at a fairly detailed, narrow level. At
    twelve topics, there still seemed to be some vague, less helpful topics, but the
    more interesting topics that I'd seen before were still there. When I attempted
    fewer topics, some of those interesting topics disappeared.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，在决定使用多少主题时，我们会想使用某种客观指标来找到一个好的集合定义。然而，为了即兴探索，我们会使用更主观的东西。首先，在玩弄主题数量后，我选择使用12个主题。由于所有这些实际上都只是关于一件事，即UFO目击，我并不期望在相当详细和狭窄的层面上会有太多有意义的主题。在12个主题中，似乎还有一些模糊、不太有帮助的主题，但我之前看到的一些更有趣的主题仍然存在。当我尝试使用更少的主题时，一些有趣的主题消失了。
- en: 'So to get started, let''s see the topics and the top 10 words for each. Remember
    that the topic descriptions here aren''t generated by the computer. I came up
    with them after looking at the top words and the top few descriptions for those
    topics. Some of these are not obvious, given the small sample of terms included
    here. However, diving further into the topic terms, the documents themselves gave
    these categorizations. In some cases, I''ve included notes in parentheses as follows:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，为了开始，让我们看看主题和每个主题的前10个单词。记住，这里的主题描述不是由计算机生成的。我是在查看这些主题的前几个单词和描述后想出来的。鉴于这里包含的术语样本很小，其中一些可能不是很明显。然而，进一步深入研究主题术语，文档本身给出了这些分类。在某些情况下，我已在括号中包含了一些注释，如下所示：
- en: '**Remembering childhood experiences**: back time house craft car looked years
    remember road home'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**回忆童年经历**：时光房屋手工艺车看起来年岁记忆回家的路'
- en: '**Lots of NUFORC notes, thanks to other organizations or local chapters**:
    report witness nuforc note ufo sighting pd date reported object'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多亏了其他组织或地方分会，有很多NUFORC笔记**：报告目击者NUFORC笔记UFO目击日期报告物体'
- en: '**Bright, silent objects in the sky**: light sky bright lights white star object
    red moving looked'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**天空中明亮的、无声的物体**：光线天空明亮的光白色物体红色移动看起来'
- en: '**Visual descriptions**: lights sky light time night red minutes objects back
    bright (this one doesn''t have a clear topic as it''s commonly defined)'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**视觉描述**：天空光线时间夜晚红色分钟物体背后明亮（这个主题没有明确的主题，因为它通常是这样定义的）'
- en: '**White, red, and reddish-orange lights**: light sky lights looked bright moving
    object back red white'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**白色、红色和橙红色的灯光**：光线天空灯光看起来明亮移动物体背后红色白色'
- en: '**Very fast, bright objects in the sky, compared to airplanes and meteors**:
    lights sky object aircraft light west north appeared flying south'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**与飞机和流星相比，天空中非常快、明亮的物体**：光线天空物体飞机灯光西方北方出现南方飞行'
- en: '**NUFORC notes. "Witness elects to remain totally anonymous"**: nuforc note
    pd witness date sky light anonymous remain approximate'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**NUFORC笔记。“目击者选择保持完全匿名”**：NUFORC笔记日期目击者日期天空光线匿名保持近似'
- en: '**Vague**: ufo camera air object picture time pictures photo photos day (again,
    the subject of this topic isn''t clear)'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模糊**：UFO相机空气物体照片时间照片照片照片白天（这个主题的主题不是很清楚）'
- en: '**Objects in the sky, no lights, or not mentioned**: object driving road car
    lights shaped craft looked side feet'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**天空中没有灯光或未提及的物体**：驾驶道路汽车灯光形状飞船看起来侧面脚'
- en: '**Abductions, visitations, fear. Close encounters of the fourth kind**: time
    night back looked light house thing window lights sound'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**绑架、访问、恐惧。第四类近距离遭遇**：时间夜晚回望光线房子东西窗户灯光声音'
- en: '**Sightings. Moving in different directions**: lights object craft light flying
    white north south east moving'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**目击。在不同方向移动**：灯光物体飞船灯光飞行白色北方南方东方移动'
- en: '**Technical descriptions**: object sky light moving objects appeared bright
    time high north'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**技术描述**：物体天空光线移动物体出现明亮时间高北方'
- en: Several of these topics, for instance, the third, fifth, sixth, and ninth bullet,
    seem to be pretty generic descriptions of sightings. They describe lots of moving
    lights in the sky.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一些主题，例如第三、第五、第六和第九个要点，似乎是对目击的相当通用的描述。它们描述了天空中许多移动的光。
- en: 'Other topics are more interesting. Topic one contained a number of descriptions
    written by people looking back at their childhood or college years. For instance,
    in the following paragraph, someone describes having a close encounter when they
    were about six years old. There are a number of spelling mistakes, and part of
    the reason I''ve kept it in is to illustrate just how messy this data can be:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 其他主题更有趣。第一个主题包含了许多回顾童年或大学时期的人写的描述。例如，在以下段落中，有人描述了他们大约六岁时的一次近距离遭遇。有很多拼写错误，我保留这部分内容是为了说明这些数据有多么混乱：
- en: '*Blus light, isolated road, possible missing timeI was six years old at the
    time, and even now, if I concentrate, I can recall what happened. My mother, her
    best friend, and myself were driving on a section of road called "Grange Road."
    Today, there are a lot of houses, but at the time, it was all farmland with maybe
    one or two houses. It was just after midnight, and I remember waking up. I was
    alseep in the back seat, and I woke up feeling very frightened. I sat up, and
    my mother and her friend were obviously worried. The car we were in was cutting
    in-and-out, and finally died. As soon as the car stopped, we all saw a blue light
    directly ahead, maybe about 20 feet off of the ground, and about a football field
    legnth away. It glided towards us, made no noise, and as it got to within 15 feet,
    it stopped in midair, hoovering. My mom grabbed me from the backseat and held
    on, and her friend was crying. I was crying, too, because whatever it was, it
    was making us all upset. After about five minutes, I don''t recall what happened,
    because for whatever reason, I fell alseep. Weird, I know, but I swear it happened.
    I woke up sometime later, and we three were sitting there, shocked, and the light
    was gone. My mom and her friend - to this day - swear they had missing time, about
    10 minutes worth. I hope this helps...((NUFORC Note: Witness indicates that date
    of sighting is approximate. PD))*'
  id: totrans-127
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*蓝色灯光，孤立的道路，可能失去的时间当时我六岁，即使现在，如果我集中注意力，我还能回忆起发生的事情。我的母亲、她的最好朋友和我正在“格兰奇路”的一段路上开车。今天，这里有很多房子，但当时，这里全是农田，可能只有一两个房子。那是午夜过后不久，我记得我醒了。我当时在后座睡觉，醒来时感到非常害怕。我坐起来，我母亲和她朋友显然很担心。我们开的车在时开时停，最后熄火了。车一停下来，我们都看到前方大约20英尺远的地方有一个蓝色灯光，大约是足球场长度。它滑向我们，没有发出声音，当它距离我们大约15英尺时，它在空中停下来，悬浮着。我母亲从后座把我抱起来，紧紧地抱着我，她的朋友在哭。我也在哭，因为不管是什么，它让我们所有人都感到不安。大约五分钟后，我不记得发生了什么，因为不管什么原因，我睡着了。我知道这很奇怪，但我发誓这是真的。后来我醒来，我们三个人坐在那里，震惊不已，灯光已经消失了。我母亲和她的朋友——直到今天——都坚称他们失去了大约10分钟的时间。希望这能有所帮助...（NUFORC备注：目击者表示目击日期是近似的。PD）*'
- en: And some topics are puzzling, number eight, for instance. The top 10 documents
    for it had nothing obvious that appeared to make them a coherent subject. There
    may be something about some of the subtler vocabulary selection that was getting
    identified, but it wasn't readily apparent.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 有些主题令人困惑，比如第八个主题。关于它的前10份文件没有明显的东西表明它们是一个连贯的主题。可能有一些关于一些更细微的词汇选择被识别出来，但并不明显。
- en: Hoaxes
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 恶作剧
- en: 'One of the most interesting finds in this was topic seven. This topic was focused
    on annotations added to the descriptions for which the witnesses wished to remain
    anonymous. But its most likely document was the following:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在这次调查中最有趣的发现之一是第七个主题。这个主题关注的是那些希望保持匿名的目击者添加到描述中的注释。但最有可能的文件如下：
- en: '*Round, lighted object over Shelby, NC, hovered then zoomed away. It was my
    birthday party and me and my friends were walking around the block about 21:30\.
    I just happened to look up and I saw a circular object with white and bright blue
    lights all over the bottom of it. It hovered in place for about 8 seconds then
    shot off faster than anything I have ever seen.((NUFORC Note: Witness elects to
    remain totally anonymous; provides no contact information. Possible hoax?? PD))((NUFORC
    Note: Source of report indicates that the date of the sighting is approximate.
    PD))*'
  id: totrans-131
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*在北卡罗来纳州谢尔比上空，一个圆形发光物体悬浮然后迅速飞走。那是我生日派对，我和我的朋友们大约在21:30时分在街区散步。我刚好抬头看，看到一个底部布满白色和明亮的蓝色灯光的圆形物体。它在原地悬浮了大约8秒，然后以我见过的任何东西都无法比拟的速度飞走。（NUFORC备注：目击者选择完全匿名；未提供任何联系方式。可能是恶作剧？PD）（NUFORC备注：报告来源表明目击日期是近似的。PD）*'
- en: What caught my attention was the note "Possible hoax??" Several other descriptions
    in this topic had similar notes, often including the word *hoax*.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 引起我注意的是笔记“可能是骗局？？”这个主题中的其他几个描述也有类似的笔记，通常包括单词*骗局*。
- en: 'Finding this raised an interesting possibility: could we train a classifier
    to recognize possible hoaxes? My initial reaction was to be skeptical. But I still
    thought it would be an interesting experiment.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 发现这一点引发了一个有趣的可能性：我们能否训练一个分类器来识别可能的骗局？我的最初反应是怀疑。但我想这仍然是一个有趣的实验。
- en: Eventually, we'll want to load this data and process it with MALLET ([http://mallet.cs.umass.edu/](http://mallet.cs.umass.edu/)).
    MALLET works a little easier with data that's kept in a particular directory format.
    The template for this is `base-directory/tag/data-file.txt`. In fact, we'll include
    a directory above these, and for `base-directory`, we'll define a directory for
    training data and one for test data.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，我们将想要加载这些数据，并用MALLET（[http://mallet.cs.umass.edu/](http://mallet.cs.umass.edu/))进行处理。MALLET在特定目录格式保存的数据上工作起来更简单。这个模板是`base-directory/tag/data-file.txt`。实际上，我们将在这些目录之上包含一个目录，并为`base-directory`定义一个用于训练数据的目录和一个用于测试数据的目录。
- en: The training group is used to train the classifier, and the test group is used
    to evaluate the classifier after it's been trained in order to determine how successful
    it is. Having two different groups for these tasks helps to find whether the classifier
    is over-fitting, that is, whether it has learned the training group so well that
    it performs poorly on new data.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 训练组用于训练分类器，测试组用于在训练后评估分类器，以确定其成功程度。有两个不同的组来完成这些任务有助于发现分类器是否过拟合，也就是说，它是否对训练组学得太好，以至于在新数据上表现不佳。
- en: Preparing the data
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备数据
- en: 'So before we get started, we''ll preprocess the data to put it into a directory
    structure such as `src/ufo_data/`. All the code for this will go into the `model.clj`
    file. The namespace declaration for this is as follows:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在我们开始之前，我们将预处理数据，将其放入类似于`src/ufo_data/`的目录结构中。所有这些代码都将放入`model.clj`文件中。这个命名空间声明如下：
- en: '[PRE19]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Now, to process this dataset into a form that MALLET can deal with easily,
    we''re going to put it through the following steps:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，为了将这个数据集处理成MALLET可以轻松处理的形式，我们将进行以下步骤：
- en: Read the data into a sequence of data records.
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据读入一系列数据记录。
- en: Split out the NUFORC comments.
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将NUFORC评论拆分出来。
- en: Categorize the documents based on the comments.
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据评论对文档进行分类。
- en: Partition them into directories based on the categories.
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据类别将它们分区到目录中。
- en: Divide them into training and test sets.
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将它们分成训练集和测试集。
- en: Let's see how we'll put these together.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们将如何将这些放在一起。
- en: Reading the data into a sequence of data records
  id: totrans-146
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将数据读入一系列数据记录
- en: The data in the downloaded file has a number of problems with values that can't
    be escaped properly. I've cleaned this up and made a new data file, available
    at [http://www.ericrochester.com/clj-data-master/data/ufo.json](http://www.ericrochester.com/clj-data-master/data/ufo.json).
    I've saved this into my `data` directory and bound that path to the name `*data-file*`.
    You can find this and a few other definitions in the code download for this chapter.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 下载的文件中的数据存在一些问题，值无法正确转义。我已经清理了这些问题，并制作了一个新的数据文件，可在[http://www.ericrochester.com/clj-data-master/data/ufo.json](http://www.ericrochester.com/clj-data-master/data/ufo.json)找到。我已经将这个文件保存在我的`data`目录中，并将该路径绑定到名称`*data-file*`。你可以在本章的代码下载中找到这个以及其他一些定义。
- en: 'But primarily, I''d like to focus on the data record for a minute. This just
    contains the fields from the JSON objects being read in. The following definition
    will serve as documentation of our data and make working with the rows a little
    easier:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 但主要的是，我想专注于数据记录一分钟。这仅仅包含从读取的JSON对象中读取的字段。以下定义将作为我们数据的文档，并使处理行变得更容易：
- en: '[PRE20]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The data as we read it in from the JSON file won''t be quite right, however.
    We''ll still need to convert date strings into data objects. We''ll do that with
    `read-date`, which parses a single date string, and with `coerce-fields`, which
    coordinates the calling of `read-date` on the appropriate fields in `UfoSighting`,
    as shown in the following code:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从JSON文件中读取的数据可能并不完全正确。我们仍然需要将日期字符串转换为数据对象。我们将使用`read-date`来完成这项工作，它解析单个日期字符串，以及使用`coerce-fields`来协调在`UfoSighting`的适当字段上调用`read-date`，如下面的代码所示：
- en: '[PRE21]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Now we can use these functions to read and parse each line of the input data
    file. As shown in the following code, each line is a separate JSON object:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以使用这些函数来读取和解析输入数据文件的每一行。如下面的代码所示，每一行都是一个单独的 JSON 对象：
- en: '[PRE22]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Now we can use these on the REPL to load the data file. As shown in the following
    code, in this session, `model` is bound to `ufo-data.model`:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以使用这些在 REPL 中加载数据文件。如下面的代码所示，在这个会话中，`model` 绑定到 `ufo-data.model`：
- en: '[PRE23]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Looks good. We're ready to start processing the descriptions further.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来不错。我们现在可以开始进一步处理描述了。
- en: Splitting the NUFORC comments
  id: totrans-157
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分割 NUFORC 评论
- en: 'Many of the descriptions contain comments by NUFORC ([http://www.nuforc.org/](http://www.nuforc.org/)).
    These contain editorial remarks – some of them about the authenticity of the report.
    The following is a sample description with NUFORC commentary:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 许多描述包含 NUFORC ([http://www.nuforc.org/](http://www.nuforc.org/)) 的评论。这些包含编辑评论——其中一些关于报告的真实性。以下是一个带有
    NUFORC 评论的示例描述：
- en: '*Telephoned Report:Husband and wife were awakened by a very bright light outside
    their house in Rio Vista area of McCall. It was so bright, it was &quot;like being
    inside a football stadium.&quot; No sound. Ground was covered with snow at the
    time. It lasted for 10 seconds.((NUFORC Note: We spoke with the husband and wife,
    and found them to be quite credible and convincing in their description of what
    they allegedly had seen. Both have responsible jobs. PD))*'
  id: totrans-159
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*电话报告：一对夫妇在里奥维斯塔地区的房子外面被非常明亮的光线惊醒。它非常明亮，就像在足球场内一样。“没有声音。”当时地面覆盖着雪。持续了 10 秒。（NUFORC
    注记：我们与夫妇进行了交谈，并发现他们在描述他们声称看到的事情时非常可信和令人信服。他们都有负责任的工作。PD）*'
- en: 'This is a standard format for these comments: They''re enclosed in double parentheses
    and begin with "NUFORC." We can leverage this information, and a regular expression,
    to pull all the notes out of the document.'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 这是这些评论的标准格式：它们被双括号包围，并以 "NUFORC." 开头。我们可以利用这些信息以及正则表达式来从文档中提取所有注释。
- en: 'To do this, we''ll go a little deeper into the Java regular expression API
    than Clojure has utility functions defined to do. Let''s see what we need to do,
    and then we can take it apart after the following code listing:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 要做到这一点，我们需要比 Clojure 中定义的实用函数更深入地了解 Java 正则表达式 API。让我们看看我们需要做什么，然后我们可以在以下代码列表之后将其拆解：
- en: '[PRE24]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: So first we create a regular expression that picks out text enclosed in double
    parentheses. We also create `java.lang.StringBuffer`. We'll use this to accumulate
    the description of the UFO sighting, with the NUFORC comments stripped out.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们首先创建一个正则表达式，用于选择双括号内的文本。我们还创建了 `java.lang.StringBuffer`。我们将使用它来累积 UFO 目击描述，并移除
    NUFORC 评论。
- en: The body of the function is a loop that has a single parameter, a vector named
    `accum`. This will accumulate the NUFORC comments.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 函数的主体是一个循环，它有一个单个参数，一个名为 `accum` 的向量。这个向量将累积 NUFORC 评论。
- en: Inside the loop, every time the regular expression finds a match, we extract
    the NUFORC comment out of the original string and replace the match with an empty
    string in `StringBuffer`. Finally, when there are no more matches on the regular
    expression, we append the rest of the string onto `StringBuffer`, and we can retrieve
    its contents and the comments, joined together.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 在循环内部，每次正则表达式找到匹配项时，我们都会从原始字符串中提取 NUFORC 评论，并在 `StringBuffer` 中用空字符串替换匹配项。最后，当正则表达式上没有更多匹配项时，我们将字符串的其余部分追加到
    `StringBuffer` 中，然后我们可以检索其内容以及合并在一起的评论。
- en: 'Let''s see what happens when we strip the NUFORC comments from the description
    quoted earlier:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看当我们从前面引用的描述中移除 NUFORC 评论时会发生什么：
- en: '[PRE25]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: So we can see that the first item in the pair returned by `split-nuforc` contains
    the description by itself, and the second item is the comments.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们可以看到 `split-nuforc` 返回的成对中的第一个项目是单独的描述，第二个项目是评论。
- en: Now we can use the comments to categorize the descriptions in the first part.
    And we'll use that to figure out where to save the cleaned-up descriptions.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以使用这些评论来对第一部分的描述进行分类。然后我们将使用这些信息来确定保存清理后的描述的位置。
- en: Categorizing the documents based on the comments
  id: totrans-170
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 根据评论对文档进行分类
- en: 'Categorizing the documents is relatively easy. We''ll use a `tokenize` function,
    which can be found in the code download for this chapter, in the namespace `ufo-data.text`
    (which is aliased to `t` in the code). We can convert the words in the comment
    to a set of tokens and then look for the word `"`*hoax*`"`. If found, we''ll categorize
    it as follows:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 文档分类相对简单。我们将使用一个`tokenize`函数，该函数可以在本章的代码下载中找到，位于`ufo-data.text`命名空间中（在代码中用`t`表示）。我们可以将评论中的单词转换为标记集，然后查找单词`"`*hoax*`"`.
    如果找到，我们将将其分类如下：
- en: '[PRE26]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'When called with the tokens of a comment, it returns the category of the description
    as follows:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 当调用评论的标记时，它将返回描述的类别，如下所示：
- en: '[PRE27]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Of course, this is very rough, but it should be all right for this experiment.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这非常粗糙，但应该适合这个实验。
- en: Partitioning the documents into directories based on the categories
  id: totrans-176
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 根据类别将文档分割到目录中
- en: Now that they're in categories, we can use those categories to save the descriptions
    into files. Each description will be in its own file.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，它们已经分类了，我们可以使用这些类别将描述保存到文件中。每个描述都将保存在自己的文件中。
- en: Initially, we'll put all of the files into one pair of directories. In the next
    step, we'll divide them further into test and training sets.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 初始时，我们将所有文件放入一对目录中。在下一步中，我们将进一步将它们分为测试集和训练集。
- en: 'The first function for this section will take a base directory, a number, and
    the document pair, as returned by `ufo-data.model/split-nuforc`. From there, it
    will save the text to a file and return the file''s category and filename, as
    shown in the following code:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 本节的第一项功能将接受一个基本目录、一个数字和由`ufo-data.model/split-nuforc`返回的文档对，作为输入。从那里，它将文本保存到文件中，并返回文件的类别和文件名，如下面的代码所示：
- en: '[PRE28]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The next function, `make-dirtree-sighting`, will do a lot of the work. It will
    take an instance of `UfoSighting` and will split out the NUFORC commentary, tokenize
    both parts, get the category, and use it to save the filename, as shown in the
    following code:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个函数`make-dirtree-sighting`将做很多工作。它将接受一个`UfoSighting`实例，并将NUFORC评论分割出来，对两部分进行标记化，获取类别，并使用它来保存文件名，如下面的代码所示：
- en: '[PRE29]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'This will handle saving each file individually into one pair of directories:
    one for hoaxes and one for non-hoaxes. We''ll want to process all of the UFO sightings,
    however, and we''ll want to divide the two sets of documents into a test set and
    a training set. We''ll do all of this in the next section.'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 这将处理将每个文件单独保存到一对目录中：一个用于骗局，一个用于非骗局。然而，我们还想处理所有的UFO目击事件，并将这两组文档分为测试集和训练集。我们将在下一节中完成所有这些操作。
- en: Dividing them into training and test sets
  id: totrans-184
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将它们分为训练集和测试集
- en: 'Now, we can divide the data that we have into a training set and a test set.
    We''ll need the following two utility functions to do this:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以将我们拥有的数据分为训练集和测试集。为此，我们需要以下两个实用函数：
- en: 'We''ll need to create subdirectories for the categories several times. Let''s
    put that into the following function:'
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要多次创建类别的子目录。让我们将这个操作放入以下函数中：
- en: '[PRE30]'
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: We'll also need to divide a collection into two groups by ratio, as shown in
    the following code. That is, one subgroup will be 80 percent of the original and
    the other subgroup will be 20 percent of the original.
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还需要按比例将一组数据分成两组，如下面的代码所示。也就是说，一个子组将是原始数据的80%，另一个子组将是原始数据的20%。
- en: '[PRE31]'
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Now, the function to move a collection of files into a stage''s subdirectory
    (testing or training) will be `mv-stage`. The collection of files is generated
    by `save-document`, so it''s a collection of maps, each containing the category
    and filename of the file, as shown in the following code:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，将一组文件移动到某个阶段的子目录（测试或训练）的函数将是`mv-stage`。文件集合由`save-document`生成，因此它是一组映射，每个映射包含文件的类别和文件名，如下面的代码所示：
- en: '[PRE32]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'To control this whole process, we''ll use `make-dirtree`. This will take a
    collection of instances of `UfoSighting` and process them into separate text files.
    All of the files will be in the `basedir` directory, and then they''ll be divided
    into a training set and a test set. These will be put into sibling directories
    under `basedir` as shown in the following code:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 为了控制整个过程，我们将使用`make-dirtree`。这将接受`UfoSighting`实例的集合，并将它们处理成单独的文本文件。所有文件都将位于`basedir`目录下，然后它们将被分为训练集和测试集。这些将被放在`basedir`下的兄弟目录中，如下面的代码所示：
- en: '[PRE33]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Now, let''s use this to divide out sightings data into groups and save them
    into the `bayes-data` directory as follows:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们使用这个方法将目击数据分组，并按照以下方式保存到`bayes-data`目录中：
- en: '[PRE34]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: We have the data now, and it's in a shape that MALLET can use. Let's look at
    how we're going to leverage that library for Naïve Bayesian classification.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在有了数据，并且它的形状是MALLET可以使用的那种。让我们看看我们如何利用这个库进行朴素贝叶斯分类。
- en: Classifying the data
  id: totrans-197
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据分类
- en: Bayesian inference can seem off-putting at first, but at its most basic level,
    it's how we tend to deal with the world. We start out with an idea of how likely
    something is, and then we update that expectation as we receive more information.
    In this case, depending on our background, training, history, and tendencies,
    we may think that all UFO reports are hoaxes or that most of them are. We may
    think that few UFO reports are hoaxes, or we may be completely undecided and assume
    that about half of them are hoaxes and half are true. But as we hear reports that
    we know the truth of, we change our opinions and expectations of the other reports.
    We may notice patterns, too. Hoaxes may talk about green men, while true reports
    may talk about grays. So you may also further refine your intuition based on that.
    Now, when you see a report that talks about little green men, you're more likely
    to think it's a hoax than when you see a report that talks about little gray men.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯推断一开始可能让人望而却步，但就其最基本层面而言，这是我们处理世界的方式。我们开始时有一个关于某事可能性的想法，然后随着我们获取更多信息，我们更新那个预期。在这种情况下，根据我们的背景、培训、历史和倾向，我们可能会认为所有UFO报告都是骗局，或者大多数都是。我们可能会认为很少的UFO报告是骗局，或者我们可能完全不确定，并假设其中一半是骗局，一半是真的。但随着我们听到我们知道真相的报告，我们会改变对其他报告的观点和预期。我们可能也会注意到模式。骗局可能会提到绿色人，而真实的报告可能会提到灰色人。因此，你可能会根据这一点进一步细化你的直觉。现在，当你看到提到小绿人的报告时，你更有可能认为它是一个骗局，而不是当你看到提到小灰人的报告时。
- en: You may also notice that triangular UFOs are considered hoaxes, while circular
    UFOs are not. Now, when you read another document, this observation then further
    influences your beliefs about whether that document is a hoax or not.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能还会注意到，三角形的UFO被认为是骗局，而圆形的UFO则不是。现在，当你阅读另一份文档时，这个观察结果进一步影响了你对该文档是否是骗局的观点。
- en: In Bayesian terms, our original expectation that a document is a hoax or not
    is called the **prior or assumed probability**, and its notation is *P(H)*, where
    *H* is the probability that the document is considered a hoax. The updated expectation
    after seeing the color of the aliens in the description, *C*, is called the **conditional
    probability**, and its notation is *P(C|H)*, which is read as *the probability
    of C given H*. In this case, it's the probability distribution over the alien's
    color, given that the document is a hoax.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 在贝叶斯术语中，我们最初对文档是骗局或不是的预期被称为**先验或假设概率**，其表示为 *P(H)*，其中 *H* 是文档被认为是骗局的概率。在看到描述中描述的外星人颜色
    *C* 后更新的预期称为**条件概率**，其表示为 *P(C|H)*，读作*在H的条件下C的概率*。在这种情况下，它是给定文档是骗局的条件下外星人颜色的概率分布。
- en: Bayes' theorem is a way of swapping the conditions for a set of conditional
    probabilities. That is, we can now find *P(H|C)*, or the probability distribution
    over the document's being a hoax, given that the alien is green or gray.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯定理是一种交换一组条件概率条件的方法。也就是说，我们现在可以找到 *P(H|C)*，即给定外星人绿色或灰色时文档是骗局的概率分布。
- en: 'The formula to do this is pretty simple. To compute the probability that the
    document is a hoax, given the aliens'' color, consider the following conditions:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 进行这种计算的公式相当简单。要计算给定外星人颜色的文档是骗局的概率，考虑以下条件：
- en: The probability of the aliens' color, given that the document is a hoax or not
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 给定文档是骗局或不是，外星人的颜色概率。
- en: The probability that the document is a hoax
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文档是骗局的可能性
- en: The probability of the aliens' color.
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 外星人的颜色概率。
- en: 'For Naïve Bayesian classification, we make an important assumption: we assume
    that the features in a document are independent. This means that the probability
    that whether aliens are green or gray in a document is independent of whether
    the UFO is a disk or a triangle.'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 对于朴素贝叶斯分类，我们做出一个重要的假设：我们假设文档中的特征是独立的。这意味着文档中是否是绿色或灰色外星人的概率与UFO是圆盘形还是三角形是独立的。
- en: In spite of this assumption, Naïve Bayesian classifiers often work well in the
    real world. We can train them easily and quickly, and they classify new data quickly
    and often perform well enough to be useful.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管有这个假设，朴素贝叶斯分类器在现实世界中通常表现良好。我们可以轻松快速地训练它们，并且它们可以快速分类新数据，并且通常表现良好，足以有用。
- en: So with that understanding, let's look at how MALLET handles Naïve Bayesian
    classification.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，有了这个理解，让我们看看 MALLET 如何处理朴素贝叶斯分类。
- en: Coding the classifier interface
  id: totrans-209
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 编码分类器接口
- en: 'Before we begin the next part of this chapter, it''s probably a good time to
    start a new namespace for the following code to live in. Let''s put it into the
    `src/ufo_data/bayes.clj` file. The `ns` declaration is as follows:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始本章的下一部分之前，可能是一个好时机来为以下代码创建一个新的命名空间。让我们将其放入 `src/ufo_data/bayes.clj` 文件中。`ns`
    声明如下：
- en: '[PRE35]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: With the preceding code in place, let's see what we need to do.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 在放置了前面的代码之后，让我们看看我们需要做什么。
- en: Setting up the Pipe and InstanceList
  id: totrans-213
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 设置 Pipe 和 InstanceList
- en: MALLET processes all input through `Pipe`. Pipes represent a series of transformations
    over the text. When you're working with a classifier, the data that's used for
    training, testing, and later for classifying new documents, all need to be put
    through the same pipe of processes. Also, all of them must use the same set of
    features and labels. MALLET calls these *alphabets*.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: MALLET 通过 `Pipe` 处理所有输入。管道代表对文本的一系列转换。当你使用分类器时，用于训练、测试以及后来用于分类新文档的数据，都需要通过相同的管道处理。此外，它们都必须使用相同的特征和标签集。MALLET
    将这些称为 *字母表*。
- en: Each data document, at whatever stage of processing, is stored in an `Instance`
    object, and corpora of these are kept in `InstanceList`. `Pipe` objects are associated
    with `InstanceList` objects. This makes sure that all `Instance` objects in a
    collection are processed consistently.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 每个数据文档，无论处于处理哪个阶段，都存储在 `Instance` 对象中，而这些文档的语料库保存在 `InstanceList` 中。`Pipe` 对象与
    `InstanceList` 对象相关联。这确保了集合中所有 `Instance` 对象的处理是一致的。
- en: 'In order to keep things straight, we''ll define `make-pipe-list`. This will
    create the `Pipe` object as shown in the following code:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 为了保持清晰，我们将定义 `make-pipe-list`。这将创建如以下代码所示的 `Pipe` 对象：
- en: '[PRE36]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'This processing pipeline performs the following steps:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 此处理管道执行以下步骤：
- en: '`Target2Label` takes the category from the directory path and assigns it to
    the `Instance` object''s label. Labels are the categories or classes used for
    classification.'
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`Target2Label` 从目录路径中获取类别并将其分配给 `Instance` 对象的标签。标签是用于分类的类别或类别。'
- en: '`SaveDataInSource` takes the path name, which is currently in the data property,
    and puts it into the `Instance` object''s source property.'
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`SaveDataInSource` 将路径名（目前位于数据属性中）放入 `Instance` 对象的源属性中。'
- en: '`Input2CharSequence` reads the data from the filename and replaces it with
    the file''s contents.'
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`Input2CharSequence` 从文件名读取数据并将其替换为文件的内容。'
- en: '`CharSequence2TokenSequence` tokenizes the file''s contents.'
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`CharSequence2TokenSequence` 对文件的 内容进行分词。'
- en: '`TokenSequenceLowercase` converts all uppercase characters in the tokens to
    lowercase.'
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`TokenSequenceLowercase` 将标记中的所有大写字符转换为小写。'
- en: '`TokenSequenceRemoveStoplist` removes common English words so that the classifier
    can focus on content words.'
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`TokenSequenceRemoveStoplist` 移除常见的英语单词，以便分类器可以专注于内容单词。'
- en: '`TokenSequence2FeatureSequence` categorizes the tokens as sequences. Each unique
    word is assigned a unique integer identifier.'
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`TokenSequence2FeatureSequence` 将标记分类为序列。每个独特的单词被分配一个唯一的整数标识符。'
- en: '`FeatureSequence2AugmentableFeatureVector` converts the sequence of tokens
    into a vector. The token''s feature identifier is that token''s index in the feature
    vector.'
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`FeatureSequence2AugmentableFeatureVector` 将标记序列转换为向量。标记的特征标识符是该标记在特征向量中的索引。'
- en: MALLET's classifier expects feature vectors as input, so this is the appropriate
    pipeline to use.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: MALLET 的分类器期望输入特征向量，因此这是合适的管道使用方式。
- en: 'Now we need to take an input directory, generate `Instance` objects from it,
    and associate their processing with a pipeline. In the following code, we''ll
    use the `add-input-directory` function to do all of that:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们需要从一个输入目录中获取输入，生成 `Instance` 对象，并将它们的处理与管道相关联。在以下代码中，我们将使用 `add-input-directory`
    函数来完成所有这些操作：
- en: '[PRE37]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: The regular expression in the last line takes the name of the file's directory
    and uses that as the `Instance` object's classification. We can use these two
    functions to handle the loading and processing of the inputs.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一行的正则表达式取文件目录的名称，并将其用作 `Instance` 对象的分类。我们可以使用这两个函数来处理输入的加载和处理。
- en: Training
  id: totrans-231
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 训练
- en: 'Training is pretty simple. We create an instance of `NaiveBayesTrainer`. Its
    `train` method returns an instance of `NaiveBayes`, which is the classifier. We''ll
    wrap this in the following function to make it slightly easier to use:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 训练相当简单。我们创建一个`NaiveBayesTrainer`的实例。它的`train`方法返回一个`NaiveBayes`实例，即分类器。我们将在这个函数中包装它，使其使用起来稍微容易一些：
- en: '[PRE38]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Wrapping it in this way provides a Clojure-native way of dealing with this library.
    It also keeps users of our module from needing to import `NaiveBayesTrainer` and
    the other classes from MALLET directly.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 以这种方式包装提供了一种Clojure-native的方式来处理这个库。它还防止了我们的模块用户直接导入`NaiveBayesTrainer`和其他MALLET类。
- en: Classifying
  id: totrans-235
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 分类
- en: 'Just like training, classifying is also easy. The classifier returned by the
    `train` function just defers to the `classify` method as follows:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 就像训练一样，分类也很容易。`train`函数返回的分类器只是将调用推迟到`classify`方法，如下所示：
- en: '[PRE39]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: The preceding code will return an instance of type `cc.mallet.classify.Classification`.
    This returns not only the best label and the probabilities associated with it,
    but also the probabilities of the other labels and the classifier and document
    instance involved.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码将返回一个类型为`cc.mallet.classify.Classification`的实例。这不仅返回了最佳标签及其概率，还返回了其他标签的概率以及分类器和文档实例。
- en: Validating
  id: totrans-239
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 验证
- en: We can now train a classifier and run it on new documents. We'd like to be able
    to test it as well, by comparing our expectations from preclassified documents
    with how the classifier actually performs.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以训练一个分类器并在新文档上运行它。我们希望能够通过比较我们对预分类文档的预期与分类器实际表现来对其进行测试。
- en: 'At the lowest level, we''ll want to compare the expected classification with
    the actual classification and keep a count of each pairing of these values. We
    can do that with `validate1`. This gets the expected and actual labels, and it
    creates a vector pair of them. The `confusion-matrix` function then gets the frequency
    of those pairs as follows:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 在最低级别，我们需要比较预期的分类与实际分类，并记录这些值每一对的计数。我们可以通过`validate1`来实现这一点。它会获取预期的和实际的标签，并创建一个包含它们的向量对。然后`confusion-matrix`函数会按照以下方式获取这些对的出现频率：
- en: '[PRE40]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: A confusion matrix is a table with the counts of the correctly classified instances
    (expected and actual match), the false positives (expected is to not classify,
    but the actual is to classify it), and the false negatives (expected is to classify
    the instance, but the actual is to not classify it). This provides an easy-to-comprehend
    overview of the performance of a classifier.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 混淆矩阵是一个表格，其中包含正确分类的实例（预期和实际匹配）的计数、假阳性（预期是不分类，但实际是分类它）和假阴性（预期是分类实例，但实际是不分类它）。这提供了一个易于理解的分类器性能概述。
- en: Tying it all together
  id: totrans-244
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 将所有部分整合在一起
- en: In the following code, we'll create a `bayes` function that creates, trains,
    and tests a classifier on a directory of data. It will take the hash map of information
    returned by `validate` and add the classifier and the `Pipe` object to it. Having
    the pipe object available later will be necessary to run the classifier on more
    data in the future.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下代码中，我们将创建一个`bayes`函数，该函数在数据目录上创建、训练和测试分类器。它将`validate`返回的信息哈希表添加到其中。稍后拥有管道对象将有必要在将来对更多数据进行分类。
- en: '[PRE41]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Now that we have all the pieces in place, let's see how to run the classifier.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好了所有部件，让我们看看如何运行分类器。
- en: Running the classifier and examining the results
  id: totrans-248
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 运行分类器并检查结果
- en: For this section, I've loaded the `ufo-data.bayes` namespace into the REPL and
    aliased it with the name `bayes`.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本节，我已经将`ufo-data.bayes`命名空间加载到REPL中，并用`bayes`作为别名。
- en: 'We can pass to the `bayes` function the test and training directories that
    we created from the sightings as shown in the following code:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将测试和训练目录传递给`bayes`函数，这些目录如以下代码所示由目击事件创建：
- en: '[PRE42]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Let''s put this into a more traditional form for this information. The expected
    values have their labels across the top of the table. The actual values have theirs
    down the side. Look at the following table:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将这些信息放入一个更传统的形式。预期的值在表格的顶部有它们的标签。实际的值在侧面有它们的标签。看看以下表格：
- en: '|   | Hoax | Non-hoax |'
  id: totrans-253
  prefs: []
  type: TYPE_TB
  zh: '|   | 骗局 | 非骗局 |'
- en: '| --- | --- | --- |'
  id: totrans-254
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Hoax | 0 | 31 |'
  id: totrans-255
  prefs: []
  type: TYPE_TB
  zh: '| 骗局 | 0 | 31 |'
- en: '| Non-hoax | 83 | 12100 |'
  id: totrans-256
  prefs: []
  type: TYPE_TB
  zh: '| 非骗局 | 83 | 12100 |'
- en: Well, that seems pretty useless. Evidently, my previous skepticism was warranted.
    The classifier managed to identify no hoaxes correctly, and it incorrectly identified
    31 non-hoaxes as hoaxes (false positives).
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 嗯，这似乎没什么用。显然，我之前的怀疑是有根据的。这个分类器未能正确识别任何骗局，并且错误地将31个非骗局识别为骗局（假阳性）。
- en: 'But that''s not all that we can learn about this. Instances of `NaiveBayes`
    also include a way to print out the top-weighted words for each category. Let''s
    see what the top 10 words for each classification are:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 但这并不是我们能学到的全部。`NaiveBayes`的实例还包括了一种打印出每个类别中权重最高的单词的方法。让我们看看每个分类的前10个单词是什么：
- en: '[PRE43]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: So the terms are in slightly different order, but the vocabulary describing
    hoaxes and non-hoaxes is almost identical. Both mention *object*, *light*, *lights*,
    *sky*, and *looked*. So, based on the features we've selected here (single-word
    tokens), it's not surprising that we didn't get good results.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，术语的顺序略有不同，但描述骗局和非骗局的词汇几乎相同。两者都提到了*物体*、*光*、*灯光*、*天空*和*看起来*。所以，基于我们在这里选择的特点（单词标记），我们没有得到好的结果并不奇怪。
- en: However, the primary thing that we can learn is that hoaxes are considered to
    be extremely rare, and the decision that a sighting is a hoax or not is often
    based on external data. Consider the sighting quoted earlier. To support the judgment
    that the sighting is not a hoax, the commenter mentions that they have a stable
    job, even though that's not mentioned in the description itself.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们可以学习到的最主要的事情是，骗局被认为是极其罕见的，而判断一个目击事件是否为骗局通常是基于外部数据。考虑前面引用的目击事件。为了支持这个判断，评论者提到他们有一份稳定的工作，尽管这一点在描述中并没有提到。
- en: Summary
  id: totrans-262
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This has been a wandering and hopefully fun trip through the UFO sightings dataset.
    We've learned something about the language used in describing close encounters,
    and we've learned about how to use visualizations, exploratory data analysis,
    and Naïve Bayesian classification to learn more about the data.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 这已经是一次漫游，希望是一次有趣的旅程，通过UFO目击数据集。我们了解了一些关于描述近距离遭遇的语言，我们也了解了一些如何使用可视化、探索性数据分析以及朴素贝叶斯分类来了解更多数据的方法。
- en: But the primary impression I have of this is the feedback analysis, visualization,
    and exploration. The visualization led us to topic modeling, and something we
    discovered there led us to Bayesian classification. This is typical of data analysis,
    where one thing we learn informs and motivates the next stage in the analysis.
    Each answer can raise further questions and drive us back into the data.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 但我对这次经历的主要印象是反馈分析、可视化和探索。可视化引导我们进行主题建模，而我们在这里发现的东西引导我们进行贝叶斯分类。这在数据分析中很典型，我们学到的东西可以指导和激励分析的下一阶段。每个答案都可以提出更多问题，并驱使我们回到数据中。
