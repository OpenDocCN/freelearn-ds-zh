- en: Chapter 6. Learning Random Forest Using Mahout
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 6 章. 使用 Mahout 学习随机森林
- en: 'Random forest is one of the most popular techniques in classification. It starts
    with a machine learning technique called **decision tree**. In this chapter, we
    will explore the following topics:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林是分类中最受欢迎的技术之一。它从一个称为**决策树**的机器学习技术开始。在本章中，我们将探讨以下主题：
- en: Decision tree
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 决策树
- en: Random forest
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机森林
- en: Using Mahout for Random forest
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Mahout 进行随机森林
- en: Decision tree
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 决策树
- en: A decision tree is used for classification and regression problems. In simple
    terms, it is a predictive model that uses binary rules to calculate the target
    variable. In a decision tree, we use an iterative process of splitting the data
    into partitions, then we split it further on branches. As in other classification
    model creation processes, we start with the training dataset in which target variables
    or class labels are defined. The algorithm tries to break all the records in training
    datasets into two parts based on one of the explanatory variables. The partitioning
    is then applied to each new partition, and this process is continued until no
    more partitioning can be done. The core of the algorithm is to find out the rule
    that determines the initial split. There are algorithms to create decision trees,
    such as **Iterative** **Dichotomiser 3** (**ID3**), **Classification and Regression
    Tree** (**CART**), **Chi-squared Automatic Interaction** **Detector** (**CHAID**),
    and so on. A good explanation for ID3 can be found at [http://www.cse.unsw.edu.au/~billw/cs9414/notes/ml/06prop/id3/id3.html](http://www.cse.unsw.edu.au/~billw/cs9414/notes/ml/06prop/id3/id3.html).
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树用于分类和回归问题。简单来说，它是一个使用二元规则计算目标变量的预测模型。在决策树中，我们使用迭代过程将数据分割成分区，然后在分支上进一步分割。与其他分类模型创建过程一样，我们从定义目标变量或类标签的训练数据集开始。算法试图根据一个解释变量将训练数据集中的所有记录分成两部分。然后将分区应用于每个新的分区，这个过程一直持续到不能再进行分区为止。算法的核心是找出决定初始分割的规则。有创建决策树的算法，例如**迭代二分器
    3**（**ID3**）、**分类和回归树**（**CART**）、**卡方自动交互检测器**（**CHAID**）等。可以在[http://www.cse.unsw.edu.au/~billw/cs9414/notes/ml/06prop/id3/id3.html](http://www.cse.unsw.edu.au/~billw/cs9414/notes/ml/06prop/id3/id3.html)找到对
    ID3 的良好解释。
- en: Forming the explanatory variables to choose the best splitter in a node, the
    algorithm considers each variable in turn. Every possible split is considered
    and tried, and the best split is the one that produces the largest decrease in
    diversity of the classification label within each partition. This is repeated
    for all variables, and the winner is chosen as the best splitter for that node.
    The process is continued in the next node until we reach a node where we can make
    the decision.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在节点中选择最佳分割器的解释变量形成过程中，算法依次考虑每个变量。考虑并尝试了所有可能的分割，最佳分割是产生每个分区中分类标签多样性最大减少的那个分割。这个过程对所有变量重复进行，胜出的变量被选为该节点的最佳分割器。这个过程在下一个节点中继续，直到我们达到一个可以做出决策的节点。
- en: We create a decision tree from a training dataset so it can suffer from the
    overfitting problem. This behavior creates a problem with real datasets. To improve
    this situation, a process called **pruning** is used. In this process, we remove
    the branches and leaves of the tree to improve the performance. Algorithms used
    to build the tree work best at the starting or root node since all the information
    is available there. Later on, with each split, data is less and towards the end
    of the tree, a particular node can show patterns that are related to the set of
    data which is used to split. These patterns create problems when we use them to
    predict the real dataset. Pruning methods let the tree grow and remove the smaller
    branches that fail to generalize. Now take an example to understand the decision
    tree.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从训练数据集中创建决策树，因此它可能会出现过拟合问题。这种行为在真实数据集中造成问题。为了改善这种情况，使用了一个称为**剪枝**的过程。在这个过程中，我们移除树的分支和叶子来提高性能。用于构建树的算法在起始或根节点上效果最好，因为那里有所有信息。随后，随着每次分割，数据越来越少，到树的末端，特定的节点可能会显示出与用于分割的数据集相关的模式。这些模式在用于预测真实数据集时会产生问题。剪枝方法允许树生长并移除无法泛化的较小分支。现在举一个例子来理解决策树。
- en: Consider we have a iris flower dataset. This dataset is hugely popular in the
    machine learning field. It was introduced by Sir Ronald Fisher. It contains 50
    samples from each of three species of iris flower (Iris setosa, Iris virginica,
    and Iris versicolor). The four explanatory variables are the length and width
    of the sepals and petals in centimeters, and the target variable is the class
    to which the flower belongs.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑我们有一个鸢尾花数据集。这个数据集在机器学习领域非常流行。它是由罗纳德·费舍尔爵士引入的。它包含来自三种鸢尾花物种（鸢尾花、Iris virginica和Iris
    versicolor）的50个样本。四个解释变量是萼片和花瓣的长度和宽度（以厘米为单位），目标变量是花朵所属的类别。
- en: '![Decision tree](img/4959OS_06_01.jpg)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![决策树](img/4959OS_06_01.jpg)'
- en: As you can see in the preceding diagram, all the groups were earlier considered
    as Sentosa species and then the explanatory variable and petal length were further
    used to divide the groups. At each step, the calculation for misclassified items
    was also done, which shows how many items were wrongly classified. Moreover, the
    petal width variable was taken into account. Usually, items at leaf nodes are
    correctly classified.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，所有组最初都被认为是Sentosa物种，然后进一步使用解释变量和花瓣长度来划分组。在每一步，也会进行误分类项的计算，这显示了有多少项被错误分类。此外，还考虑了花瓣宽度变量。通常，叶节点上的项目被正确分类。
- en: Random forest
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 随机森林
- en: The Random forest algorithm was developed by Leo Breiman and Adele Cutler. Random
    forests grow many classification trees. They are an ensemble learning method for
    classification and regression that constructs a number of decision trees at training
    time and also outputs the class that is the mode of the classes outputted by individual
    trees.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林算法是由Leo Breiman和Adele Cutler开发的。随机森林生长出许多分类树。它们是用于分类和回归的集成学习方法，在训练时构建多个决策树，并输出由单个树输出的类别的众数。
- en: 'Single decision trees show the bias–variance tradeoff. So they usually have
    high variance or high bias. The following are the parameters in the algorithm:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 单个决策树显示了偏差-方差权衡。因此，它们通常具有高方差或高偏差。以下是算法中的参数：
- en: '**Bias**: This is an error caused by an erroneous assumption in the learning
    algorithm'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**偏差**: 这是由学习算法中的错误假设引起的误差'
- en: '**Variance**: This is an error that ranges from sensitivity to small fluctuations
    in the training set'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**方差**: 这是一种误差，它从对训练集中微小波动的敏感性到较大的波动'
- en: Random forests attempt to mitigate this problem by averaging to find a natural
    balance between two extremes. A Random forest works on the idea of bagging, which
    is to average noisy and unbiased models to create a model with low variance. A
    Random forest algorithm works as a large collection of decorrelated decision trees.
    To understand the idea of a Random forest algorithm, let's work with an example.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林试图通过平均来减轻这个问题，以在两个极端之间找到自然的平衡。随机森林基于袋装的思想，即平均噪声和无偏模型以创建一个低方差模型。随机森林算法作为一个大量
    decorrelated 决策树的集合工作。为了理解随机森林算法的概念，让我们通过一个例子来操作。
- en: 'Consider we have a training dataset that has lots of features (explanatory
    variables) and target variables or classes:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑我们有一个包含大量特征（解释变量）和目标变量或类别的训练数据集：
- en: '![Random forest](img/4959OS_06_02.jpg)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![随机森林](img/4959OS_06_02.jpg)'
- en: 'We create a sample set from the given dataset:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从给定的数据集中创建一个样本集：
- en: '![Random forest](img/4959OS_06_03.jpg)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![随机森林](img/4959OS_06_03.jpg)'
- en: 'A different set of random features were taken into account to create the random
    sub-dataset. Now, from these sub-datasets, different decision trees will be created.
    So actually we have created a forest of the different decision trees. Using these
    different trees, we will create a ranking system for all the classifiers. To predict
    the class of a new unknown item, we will use all the decision trees and separately
    find out which class these trees are predicting. See the following diagram for
    a better understanding of this concept:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 为了创建随机子数据集，考虑了不同的一组随机特征。现在，从这些子数据集中，将创建不同的决策树。所以实际上我们已经创建了一个不同决策树的森林。使用这些不同的树，我们将为所有分类器创建一个排名系统。为了预测一个新未知项的类别，我们将使用所有决策树并分别找出这些树预测的类别。参见以下图表以更好地理解这个概念：
- en: '![Random forest](img/4959OS_06_04.jpg)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![随机森林](img/4959OS_06_04.jpg)'
- en: Different decision trees to predict the class of an unknown item
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 用于预测未知项类别的不同决策树
- en: 'In this particular case, we have four different decision trees. We predict
    the class of an unknown dataset with each of the trees. As per the preceding figure,
    the first decision tree provides class 2 as the predicted class, the second decision
    tree predicts class 5, the third decision tree predicts class 5, and the fourth
    decision tree predicts class 3\. Now, a Random forest will vote for each class.
    So we have one vote each for class 2 and class 3 and two votes for class 5\. Therefore,
    it has decided that for the new unknown dataset, the predicted class is class
    5\. So the class that gets a higher vote is decided for the new dataset. A Random
    forest has a lot of benefits in classification and a few of them are mentioned
    in the following list:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个特定案例中，我们有四个不同的决策树。我们使用每个树来预测未知数据集的类别。根据前面的图示，第一个决策树预测类别2，第二个决策树预测类别5，第三个决策树预测类别5，第四个决策树预测类别3。现在，随机森林将为每个类别投票。因此，类别2和类别3各获得一票，类别5获得两票。因此，它决定对于新的未知数据集，预测的类别是类别5。所以，获得更高投票的类别被决定用于新的数据集。随机森林在分类中有许多优点，以下列举了一些：
- en: Combination of learning models increases the accuracy of the classification
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习模型的组合增加了分类的准确性
- en: Runs effectively on large datasets as well
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在大型数据集上也能有效运行
- en: The generated forest can be saved and used for other datasets as well
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成的森林可以保存并用于其他数据集
- en: Can handle a large amount of explanatory variables
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以处理大量的解释变量
- en: Now that we have understood the Random forest theoretically, let's move on to
    Mahout and use the Random forest algorithm, which is available in Apache Mahout.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经从理论上了解了随机森林，让我们继续使用 Mahout，并使用 Apache Mahout 中可用的随机森林算法。
- en: Using Mahout for Random forest
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Mahout 进行随机森林
- en: Mahout has implementation for the Random forest algorithm. It is very easy to
    understand and use. So let's get started.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: Mahout 对随机森林算法有实现。它非常容易理解和使用。所以，让我们开始吧。
- en: '**Dataset**'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据集**'
- en: 'We will use the NSL-KDD dataset. Since 1999, KDD''99 has been the most widely
    used dataset for the evaluation of anomaly detection methods. This dataset is
    prepared by S. J. Stolfo and is built based on the data captured in the DARPA''98
    IDS evaluation program (*R. P. Lippmann, D. J. Fried, I. Graf, J. W. Haines, K.
    R. Kendall, D. McClung, D. Weber, S. E. Webster, D. Wyschogrod, R. K. Cunningham,
    and M. A. Zissman, "Evaluating intrusion detection systems: The 1998 darpa off-line
    intrusion detection evaluation," discex, vol. 02, p. 1012, 2000*).'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '我们将使用 NSL-KDD 数据集。自 1999 年以来，KDD''99 已经成为评估异常检测方法最广泛使用的数据集。这个数据集由 S. J. Stolfo
    准备，并基于在 DARPA''98 IDS 评估计划中捕获的数据构建（*R. P. Lippmann, D. J. Fried, I. Graf, J. W.
    Haines, K. R. Kendall, D. McClung, D. Weber, S. E. Webster, D. Wyschogrod, R.
    K. Cunningham, and M. A. Zissman, "Evaluating intrusion detection systems: The
    1998 darpa off-line intrusion detection evaluation," discex, vol. 02, p. 1012,
    2000*）。'
- en: DARPA'98 is about 4 GB of compressed raw (binary) tcp dump data of 7 weeks of
    network traffic, which can be processed into about 5 million connection records,
    each with about 100 bytes. The two weeks of test data have around 2 million connection
    records. The KDD training dataset consists of approximately 4,900,000 single connection
    vectors, each of which contains 41 features and is labeled as either normal or
    an attack, with exactly one specific attack type.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: DARPA'98 是关于 7 周网络流量的约 4 GB 压缩原始（二进制）tcp 捕包数据，可以处理成约 500 万个连接记录，每个记录大约有 100
    字节。两周的测试数据大约有 200 万个连接记录。KDD 训练数据集由大约 4,900,000 个单独的连接向量组成，每个向量包含 41 个特征，并标记为正常或攻击，具体为一种特定的攻击类型。
- en: NSL-KDD is a dataset suggested to solve some of the inherent problems of the
    KDD'99 dataset. You can download this dataset from [http://nsl.cs.unb.ca/NSL-KDD/](http://nsl.cs.unb.ca/NSL-KDD/).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: NSL-KDD 是一个数据集，建议解决 KDD'99 数据集的一些固有问题。您可以从 [http://nsl.cs.unb.ca/NSL-KDD/](http://nsl.cs.unb.ca/NSL-KDD/)
    下载此数据集。
- en: We will download the **KDDTrain+_20Percent.ARFF** and **KDDTest+.ARFF** datasets.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将下载 **KDDTrain+_20Percent.ARFF** 和 **KDDTest+.ARFF** 数据集。
- en: '![Using Mahout for Random forest](img/4959OS_06_05.jpg)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![使用 Mahout 进行随机森林](img/4959OS_06_05.jpg)'
- en: Note
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: In **KDDTrain+_20Percent.ARFF** and **KDDTest+.ARFF**, remove the first 44 lines
    (that is, all lines starting with @attribute). If this is not done, we will not
    be able to generate a descriptor file.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在 **KDDTrain+_20Percent.ARFF** 和 **KDDTest+.ARFF** 文件中，删除前44行（即所有以 @attribute
    开头的行）。如果不这样做，我们将无法生成描述符文件。
- en: '![Using Mahout for Random forest](img/4959OS_06_06.jpg)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![使用 Mahout 进行随机森林](img/4959OS_06_06.jpg)'
- en: Steps to use the Random forest algorithm in Mahout
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 Mahout 中使用随机森林算法的步骤
- en: 'The steps to implement the Random forest algorithm in Apache Mahout are as
    follows:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Apache Mahout 中实现随机森林算法的步骤如下：
- en: 'Transfer the test and training datasets to `hdfs` using the following commands:'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令将测试和训练数据集传输到 `hdfs`：
- en: '[PRE0]'
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Generate the descriptor file. Before you build a Random forest model based
    on the training data in **KDDTrain+.arff**, a descriptor file is required. This
    is because all information in the training dataset needs to be labeled. From the
    labeled dataset, the algorithm can understand which one is numerical and categorical.
    Use the following command to generate descriptor file:'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成描述符文件。在基于 **KDDTrain+.arff** 中的训练数据构建随机森林模型之前，需要一个描述符文件。这是因为训练数据集中的所有信息都需要标记。从标记的数据集中，算法可以理解哪些是数值的，哪些是分类的。使用以下命令生成描述符文件：
- en: '[PRE1]'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Jar: Mahout core jar (`xyz` stands for version). If you have directly installed
    Mahout, it can be found under the `/usr/lib/mahout` folder. The main class `Describe`
    is used here and it takes three parameters:'
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'Jar: Mahout 核心jar (`xyz` 代表版本)。如果你直接安装了 Mahout，它可以在 `/usr/lib/mahout` 文件夹下找到。这里使用的主类是
    `Describe`，它接受三个参数：'
- en: The `p` path for the data to be described.
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`p` 代表要描述的数据的路径。'
- en: The `f` location for the generated descriptor file.
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`f` 代表生成的描述符文件的位置。'
- en: '`d` is the information for the attribute on the data. N 3 C 2 N C 4 N C 8 N
    2 C 19 N L defines that the dataset is starting with a numeric (N), followed by
    three categorical attributes, and so on. In the last, L defines the label.'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`d` 是数据属性上的信息。N 3 C 2 N C 4 N C 8 N 2 C 19 N L 定义了数据集以数值 (N) 开头，后面跟着三个分类属性，等等。最后，L
    定义了标签。'
- en: 'The output of the previous command is shown in the following screenshot:'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上一条命令的输出如下所示：
- en: '![Steps to use the Random forest algorithm in Mahout](img/4959OS_06_07.jpg)'
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![在 Mahout 中使用随机森林算法的步骤](img/4959OS_06_07.jpg)'
- en: 'Build the Random forest using the following command:'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令构建随机森林：
- en: '[PRE2]'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Jar: Mahout example jar (`xyz` stands for version). If you have directly installed
    Mahout, it can be found under the `/usr/lib/mahout` folder. The main class `build
    forest` is used to build the forest with other arguments, which are shown in the
    following list:'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'Jar: Mahout 示例 jar (`xyz` 代表版本)。如果你直接安装了 Mahout，它可以在 `/usr/lib/mahout` 文件夹下找到。主类
    `build forest` 用于构建森林，其他参数如下所示：'
- en: '`Dmapred.max.split.size` indicates to Hadoop the maximum size of each partition.'
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`Dmapred.max.split.size` 通知 Hadoop 每个分区的最大大小。'
- en: '`d` stands for the data path.'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`d` 代表数据路径。'
- en: '`ds` stands for the location of the descriptor file.'
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`ds` 代表描述符文件的位置。'
- en: '`sl` is a variable to select randomly at each tree node. Here, each tree is
    built using five randomly selected attributes per node.'
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`sl` 是在每个树节点随机选择的变量。在这里，每个树节点使用五个随机选择的属性来构建。'
- en: '`p` uses partial data implementation.'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`p` 使用部分数据实现。'
- en: '`t` stands for the number of trees to grow. Here, the commands build 100 trees
    using partial implementation.'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`t` 代表要生长的树的数量。在这里，使用部分实现构建了 100 棵树。'
- en: '`o` stands for the output path that will contain the decision forest.'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`o` 代表包含决策森林的输出路径。'
- en: '![Steps to use the Random forest algorithm in Mahout](img/4959OS_06_08.jpg)'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![在 Mahout 中使用随机森林算法的步骤](img/4959OS_06_08.jpg)'
- en: 'In the end, the process will show the following result:'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 最后，过程将显示以下结果：
- en: '![Steps to use the Random forest algorithm in Mahout](img/4959OS_06_09.jpg)'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![在 Mahout 中使用随机森林算法的步骤](img/4959OS_06_09.jpg)'
- en: 'Use this model to classify the new dataset:'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用此模型对新数据集进行分类：
- en: '[PRE3]'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Jar: Mahout example jar (`xyz` stands for version). If you have directly installed
    Mahout, it can be found under the `/usr/lib/mahout` folder. The class to test
    the forest has the following parameters:'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'Jar: Mahout 示例 jar (`xyz` 代表版本)。如果你直接安装了 Mahout，它可以在 `/usr/lib/mahout` 文件夹下找到。用于测试森林的类有以下参数：'
- en: '`I` indicates the path for the test data'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`I` 表示测试数据的路径'
- en: '`ds` stands for the location of the descriptor file'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`ds` 代表描述符文件的位置'
- en: '`m` stands for the location of the generated forest from the previous command'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`m` 代表上一条命令生成的森林的位置'
- en: '`a` informs to run the analyzer to compute the confusion matrix'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`a` 通知运行分析器以计算混淆矩阵'
- en: '`mr` informs hadoop to distribute the classification'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`mr` 通知 Hadoop 分发分类'
- en: '`o` stands for the location to store the predictions in'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`o` 代表存储预测结果的存储位置'
- en: '![Steps to use the Random forest algorithm in Mahout](img/4959OS_06_10.jpg)'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![在 Mahout 中使用随机森林算法的步骤](img/4959OS_06_10.jpg)'
- en: 'The job provides the following confusion matrix:'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该作业提供了以下混淆矩阵：
- en: '![Steps to use the Random forest algorithm in Mahout](img/4959OS_06_11.jpg)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![在Mahout中使用随机森林算法的步骤](img/4959OS_06_11.jpg)'
- en: So, from the confusion matrix, it is clear that 9,396 instances were correctly
    classified and 315 normal instances were incorrectly classified as anomalies.
    And the accuracy percentage is 77.7635 (correctly classified instances by the
    model / classified instances). The output file in the prediction folder contains
    the list where 0 and 1\. 0 defines the normal dataset and 1 defines the anomaly.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，从混淆矩阵中可以清楚地看出，有9,396个实例被正确分类，315个正常实例被错误地分类为异常。准确率百分比为77.7635（模型正确分类的实例数
    / 分类实例数）。预测文件夹中的输出文件包含一个列表，其中0和1。0表示正常数据集，1表示异常。
- en: Summary
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we discussed the Random forest algorithm. We started our discussion
    by understanding the decision tree and continued with an understanding of the
    Random forest. We took up the NSL-KDD dataset, which is used to build predictive
    systems for cyber security. We used Mahout to build the Random forest tree, and
    used it with the test dataset and generated the confusion matrix and other statistics
    for the output.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了随机森林算法。我们首先通过理解决策树开始我们的讨论，然后继续理解随机森林。我们使用了NSL-KDD数据集，该数据集用于构建网络安全预测系统。我们使用Mahout构建随机森林树，并用测试数据集进行测试，生成了混淆矩阵和其他统计数据。
- en: In the next chapter, we will look at the final classification algorithm available
    in Apache Mahout. So stay tuned!
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将探讨Apache Mahout中可用的最终分类算法。所以请保持关注！
