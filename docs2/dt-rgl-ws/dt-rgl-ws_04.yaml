- en: 4\. A Deep Dive into Data Wrangling with Python
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4. 使用Python深入数据整理
- en: Overview
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 概述
- en: This chapter will cover pandas DataFrames in depth, thus teaching you how to
    perform subsetting, filtering, and grouping on DataFrames. You will be able to
    apply Boolean filtering and indexing to a DataFrame to choose specific elements
    from it. Later on in the chapter, you will learn how to perform JOIN operations
    in pandas that are analogous to the SQL command. By the end of this chapter you
    will be able to apply imputation techniques to identify missing or corrupted data
    and choose to drop it.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将深入探讨pandas DataFrame，从而教你如何在DataFrame上执行子集、过滤和分组。你将能够应用布尔过滤和索引来选择DataFrame中的特定元素。在本章的后面部分，你将学习如何在pandas中执行与SQL命令类似的JOIN操作。到本章结束时，你将能够应用插补技术来识别缺失或损坏的数据，并选择删除它。
- en: Introduction
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简介
- en: In the previous chapter, we learned how to use the pa`ndas`, `numpy`, and `matplotlib`
    libraries while handling various datatypes. In this chapter, we will learn about
    several advanced operations involving `pandas` DataFrames and `numpy` arrays.
    We will be working with several powerful DataFrame operations, including subsetting,
    filtering grouping, checking uniqueness, and even dealing with missing data, among
    others. These techniques are extremely useful when working with data in any way.
    When we want to look at a portion of the data, we must subset, filter, or group
    the data. `Pandas` contains the functionality to create descriptive statistics
    of the dataset. These methods will allow us to start shaping our perception of
    the data. Ideally, when we have a dataset, we want it to be complete, but in reality,
    there is often missing or corrupt data. This can happen for a variety of reasons
    that we can't control, such as user error and sensor malfunction. Pandas has built-in
    functionalities to deal with such kinds of missing data within our dataset.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们学习了如何在处理各种数据类型时使用`pandas`、`numpy`和`matplotlib`库。在本章中，我们将学习涉及`pandas`
    DataFrame和`numpy`数组的一些高级操作。我们将使用几个强大的DataFrame操作，包括子集、过滤、分组、检查唯一性，甚至处理缺失数据等。这些技术在处理数据时非常有用。当我们想要查看数据的一部分时，我们必须对数据进行子集、过滤或分组。`Pandas`包含创建数据集描述性统计的功能。这些方法将使我们开始塑造对数据的感知。理想情况下，当我们有一个数据集时，我们希望它是完整的，但在现实中，经常存在缺失或损坏的数据。这可能是由我们无法控制的各种原因造成的，例如用户错误和传感器故障。Pandas内置了处理数据集中这种缺失数据的功能。
- en: Subsetting, Filtering, and Grouping
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 子集、过滤和分组
- en: One of the most important aspects of data wrangling is to curate the data carefully
    from the deluge of streaming data that pours into an organization or business
    entity from various sources. Lots of data is not always a good thing; rather,
    data needs to be useful and of high quality to be effectively used in downstream
    activities of a data science pipeline, such as machine learning and predictive
    model building. Moreover, one data source can be used for multiple purposes, and
    this often requires different subsets of data to be processed by a data wrangling
    module. This is then passed on to separate analytics modules.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 数据整理最重要的方面之一是从来自各种来源涌入组织或商业实体的数据洪流中精心整理数据。大量的数据并不总是好事；相反，数据需要有用且质量高，才能在数据科学管道的下游活动中有效使用，例如机器学习和预测模型构建。此外，一个数据源可以用于多个目的，这通常需要数据整理模块处理不同的数据子集。然后，这些数据被传递到单独的分析模块。
- en: For example, let's say you are doing data wrangling on US state-level economic
    output. It is a fairly common scenario that one machine learning model may require
    data for large and populous states (such as California and Texas), while another
    model demands processed data for small and sparsely populated states (such as
    Montana or North Dakota). As the frontline of the data science process, it is
    the responsibility of the data wrangling module to satisfy the requirements of
    both these machine learning models. Therefore, as a data wrangling engineer, you
    have to filter and group data accordingly (based on the population of the state)
    before processing them and producing separate datasets as the final output for
    separate machine learning models.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设您正在对美国州级经济产出进行数据整理。这是一个相当常见的场景，一个机器学习模型可能需要大型和人口众多的州（如加利福尼亚州和德克萨斯州）的数据，而另一个模型则要求为小型和人口稀少的州（如蒙大拿州或北达科他州）处理数据。作为数据科学流程的前线，数据整理模块有责任满足这两个机器学习模型的要求。因此，作为一名数据整理工程师，您必须在处理并生成最终输出之前，根据州的
    人口进行数据过滤和分组。
- en: Also, in some cases, data sources may be biased, or the measurement may corrupt
    the incoming data occasionally. It is a good idea to try to filter only the error-free,
    good data for downstream modeling. From these examples and discussions, it is
    clear that filtering and grouping/bucketing data is an essential skill to have
    for any engineer that's engaged in the task of data wrangling. Let's proceed to
    learn about a few of these skills with pandas.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，在某些情况下，数据源可能存在偏差，或者测量偶尔会损坏传入的数据。尝试仅过滤出无错误的良好数据用于下游建模是一个好主意。从这些示例和讨论中可以看出，过滤和分组/分桶数据是任何从事数据整理任务的工程师必备的一项基本技能。让我们继续学习
    pandas 中的一些这些技能。
- en: 'Exercise 4.01: Examining the Superstore Sales Data in an Excel File'
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 4.01：检查 Excel 文件中的 Superstore 销售数据
- en: In this exercise, we will read and examine an Excel file called `Sample-Superstore.xls`
    and will check all the columns to check if they are useful for analysis. We'll
    use the `drop` method to delete the columns that are unnecessary from the `.xls`
    file. Then, we'll use the `shape` function to check the number of rows and columns
    in the dataset.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将读取并检查一个名为 `Sample-Superstore.xls` 的 Excel 文件，并检查所有列是否对分析有用。我们将使用 `drop`
    方法删除 `.xls` 文件中不必要的列。然后，我们将使用 `shape` 函数检查数据集中的行数和列数。
- en: Note
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'The `superstore` dataset file can be found here: [https://packt.live/3dcVnMs](https://packt.live/3dcVnMs).'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '`superstore` 数据集文件可以在以下位置找到：[https://packt.live/3dcVnMs](https://packt.live/3dcVnMs)。'
- en: 'To do so, perform the following steps:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 要这样做，请执行以下步骤：
- en: 'To read an Excel file into `pandas`, you will need a small package called `xlrd`
    to be installed on your system. Use the following code to install the `xlrd` package:'
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要将 Excel 文件读入 `pandas`，您需要在您的系统上安装一个名为 `xlrd` 的小型包。使用以下代码安装 `xlrd` 包：
- en: '[PRE0]'
  id: totrans-15
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Note
  id: totrans-16
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: The `!` notation tells the Jupyter Notebook that the cell should be treated
    as a shell command.
  id: totrans-17
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`!` 符号告诉 Jupyter Notebook 将该单元格视为一个 shell 命令。'
- en: 'Read the Excel file from GitHub into a `pandas` DataFrame using the `read_excel`
    method in `pandas`:'
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `pandas` 中的 `read_excel` 方法从 GitHub 读取 Excel 文件到 DataFrame：
- en: '[PRE1]'
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Drop this column altogether from the DataFrame by using the `drop` method:'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `drop` 方法从 DataFrame 中完全删除此列：
- en: '[PRE2]'
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The output is as follows:'
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 4.2: Partial output of the Superstore dataset after dropping the ''Row
    ID'' column'
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.2：删除 ''Row ID'' 列后的 Superstore 数据集部分输出](img/B15780_04_02.jpg)'
- en: '](img/B15780_04_02.jpg)'
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15780_04_02.jpg)'
- en: 'Figure 4.2: Partial output of the Superstore dataset after dropping the ''Row
    ID'' column'
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.2：删除 'Row ID' 列后的 Superstore 数据集部分输出
- en: 'Check the number of rows and columns in the newly created dataset. We will
    use the `shape` function here:'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查新创建的数据集中的行数和列数。这里我们将使用 `shape` 函数：
- en: '[PRE3]'
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The output is as follows:'
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '[PRE4]'
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: In this exercise, we can see that the dataset has `9,994` rows and `20` columns.
    We have now seen that a simple way to remove unwanted columns such as a row count
    is simple with `pandas`. Think about how hard this would be if, instead of `pandas`,
    we used a list of dictionaries? We would have to write a loop to remove the `rowid`
    element from each dictionary in the list. `pandas` makes this functionality simple
    and easy.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们可以看到数据集有 `9,994` 行和 `20` 列。我们已经看到，使用 `pandas` 删除如行计数等不想要的列是一种简单的方法。想想如果不用
    `pandas`，而使用字典列表会多么困难？我们不得不编写一个循环来从列表中的每个字典中删除 `rowid` 元素。`pandas` 使这一功能变得简单且易于实现。
- en: Note
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/2Y9ZTXW](https://packt.live/2Y9ZTXW).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参阅 [https://packt.live/2Y9ZTXW](https://packt.live/2Y9ZTXW)。
- en: You can also run this example online at [https://packt.live/2N4dVUO](https://packt.live/2N4dVUO).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以在 [https://packt.live/2N4dVUO](https://packt.live/2N4dVUO) 上在线运行此示例。
- en: In the next section, we'll discuss how to subset a DataFrame.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将讨论如何子集化 DataFrame。
- en: Subsetting the DataFrame
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 子集化 DataFrame
- en: '`Customer ID`, `Customer Name`, `City`, `Postal Code`, and `Sales`. For demonstration
    purposes, let''s assume that we are only interested in `5` records – rows `5-9`.
    We can subset the DataFrame to extract only this much information using a single
    line of Python code.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '`客户 ID`，`客户名称`，`城市`，`邮政编码`和 `销售额`。为了演示目的，让我们假设我们只对 `5` 条记录——行 `5-9` 感兴趣。我们可以使用一行
    Python 代码来子集化 DataFrame，以提取这么多的信息。'
- en: 'We can use the `loc` method to index the `Sample Superstore` dataset by the
    names of the columns and the indexes of the rows, as shown in the following code:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 `loc` 方法通过列名和行索引来索引 `Sample Superstore` 数据集，如下面的代码所示：
- en: '[PRE5]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The output is as follows:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.3: Partial data of the DataFrame indexed by the names of the columns'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.3：按列名索引的 DataFrame 的部分数据'
- en: '](img/B15780_04_03.jpg)'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B15780_04_03.jpg)'
- en: 'Figure 4.3: Partial data of the DataFrame indexed by the names of the columns'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.3：按列名索引的 DataFrame 的部分数据
- en: We need to pass on two arguments to the `loc` method – one for indicating the
    rows, and another for indicating the columns. When passing more than one value,
    you must pass them as a list for a row or column.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要向 `loc` 方法传递两个参数——一个用于指示行，另一个用于指示列。当传递多个值时，你必须将它们作为一个列表传递给行或列。
- en: For the rows, we have to pass a list, that is, `[5,6,7,8,9]`, but instead of
    writing that explicitly, we use a list comprehension, that is, `[i for i in range(5,10)]`.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 对于行，我们必须传递一个列表，即 `[5,6,7,8,9]`，但不必明确写出，我们可以使用列表推导式，即 `[i for i in range(5,10)]`。
- en: Because the columns we are interested in are not continuous and we cannot just
    put in a continuous range, we need to pass on a list containing the specific names.
    So, the second argument is just a simple list with specific column names. The
    dataset shows the fundamental concepts of the process of **subsetting** a DataFrame
    based on business requirements.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我们所感兴趣的列不是连续的，我们不能简单地放入一个连续的范围，所以我们需要传递一个包含特定名称的列表。因此，第二个参数只是一个包含特定列名的简单列表。该数据集展示了根据业务需求对
    DataFrame 进行 **子集化** 的基本概念。
- en: Let's look at an example use case and practice subsetting a bit more.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一个示例用例，并进一步练习子集化。
- en: An Example Use Case – Determining Statistics on Sales and Profit
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一个示例用例 – 确定销售额和利润的统计数据
- en: 'Let''s take a look at a typical use case of subsetting. Suppose we want to
    calculate descriptive statistics (mean, median, standard deviation, and so on)
    of records `100-199` for sales and profit in the `SuperStore` dataset. The following
    code shows how subsetting helps us achieve that:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看子集化的一个典型用例。假设我们想要计算 `SuperStore` 数据集中销售额和利润记录 `100-199` 的描述性统计（均值、中位数、标准差等）。下面的代码展示了子集化如何帮助我们实现这一点：
- en: '[PRE6]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The output is as follows:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.4: Output of descriptive statistics of data'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.4：数据描述性统计的输出'
- en: '](img/B15780_04_04.jpg)'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B15780_04_04.jpg)'
- en: 'Figure 4.4: Output of descriptive statistics of data'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.4：数据描述性统计的输出
- en: We simply extract records `100-199` and run the `describe` function on them
    because we don't want to process all the data. For this particular business question,
    we are only interested in sales and profit numbers, and therefore we should not
    take the easy route and run a `describe` function on all the data. For a dataset
    that's being used in machine learning analysis, the number of rows and columns
    could often be in the millions, and we don't want to compute anything that is
    not asked for in the data wrangling task. We always aim to subset the exact data
    that needs to be processed and run statistical or plotting functions on that partial
    data. One of the most intuitive ways to try and understand the data is through
    charting. This can be a critical component of data wrangling.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们简单地提取记录`100-199`并对它们运行`describe`函数，因为我们不想处理所有数据。对于这个特定业务问题，我们只对销售和利润数字感兴趣，因此我们不应该走捷径，对全部数据进行`describe`函数。对于在机器学习分析中使用的数据集，行和列的数量可能经常达到数百万，我们不希望计算数据整理任务中未要求的数据。我们始终旨在子集需要处理的确切数据，并在该部分数据上运行统计或绘图函数。尝试理解数据的最直观方法之一是通过图表。这可能是数据整理的一个关键组成部分。
- en: 'To better understand sales and profit, let''s create a box plot of the data
    using `matplotlib`:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解销售和利润，让我们使用`matplotlib`创建数据的箱形图：
- en: '[PRE7]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The output is as follows:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.5: Box plot of sales and profit'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '![图4.5：销售和利润的箱形图'
- en: '](img/B15780_04_05.jpg)'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B15780_04_05.jpg)'
- en: 'Figure 4.5: Box plot of sales and profit'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.5：销售和利润的箱形图
- en: As we can see from the preceding box plot, there are some outliers for profit.
    Now, they could be normal outliers, or they could be `NaN` values. At this point,
    we can't speculate, but this could cause some further analysis to see how we want
    to treat those outliers in profit. In some cases, outliers are fine, but for some
    predictive modeling techniques such as regression, outliers can have unwanted
    effects.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们从前面的箱形图中所见，利润存在一些异常值。现在，这些可能是正常的异常值，也可能是`NaN`值。在这个阶段，我们无法猜测，但这可能会引起进一步的分析，看看我们如何处理这些利润中的异常值。在某些情况下，异常值是可以接受的，但对于某些预测建模技术，如回归，异常值可能会产生不良影响。
- en: Before continuing further with filtering methods, let's take a quick detour
    and explore a super useful function called `unique`. As its name suggests, this
    function is used to scan through the data quickly and extract only the unique
    values in a column or row.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续进行过滤方法之前，让我们快速偏离一下，探索一个非常有用的函数，称为`unique`。正如其名所示，此函数用于快速扫描数据并提取列或行中的唯一值。
- en: 'Exercise 4.02: The unique Function'
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习4.02：唯一函数
- en: 'In the superstore sales data, you will notice that there are columns such as
    `Country`, `State`, and `City`. A natural question will be to ask how many `countries/states/cities`
    are present in the dataset. In this exercise, we''ll use the `unique` function
    to find the number of unique `countries/states/cities` in the dataset. Let''s
    go through the following steps:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在超市销售数据中，您会注意到存在诸如`国家`、`州`和`城市`之类的列。一个自然的问题将是询问数据集中有多少`国家/州/城市`。在这个练习中，我们将使用`unique`函数来查找数据集中独特的`国家/州/城市`数量。让我们按以下步骤进行：
- en: Note
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'The `superstore` dataset file can be found here: [https://packt.live/3dcVnMs](https://packt.live/3dcVnMs).'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '`superstore`数据集文件可以在这里找到：[https://packt.live/3dcVnMs](https://packt.live/3dcVnMs)。'
- en: 'Import the necessary libraries and read the file from GitHub by using the `read_excel`
    method in `pandas` into a DataFrame:'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入必要的库，并使用`pandas`中的`read_excel`方法从GitHub读取文件到一个DataFrame中：
- en: '[PRE8]'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Note
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: The highlighted path must be changed based on the location of the file on your
    system.
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 高亮路径必须根据您系统上文件的位置进行更改。
- en: 'Extract `countries/states/cities` for which the information is in the database,
    with one simple line of code, as follows:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用一行简单的代码提取数据库中包含信息的`国家/州/城市`，如下所示：
- en: '[PRE9]'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The output is as follows:'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.6: Different states present in the dataset'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图4.6：数据集中存在的不同状态'
- en: '](img/B15780_04_06.jpg)'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B15780_04_06.jpg)'
- en: 'Figure 4.6: Different states present in the dataset'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图4.6：数据集中存在的不同状态
- en: You will see a list of all the states whose data is present in the dataset.
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您将看到数据集中所有状态的列表。
- en: 'Use the `nunique` method to count the number of unique values in the `State`
    column, like so:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`nunique`方法来计算`州`列中唯一值的数量，如下所示：
- en: '[PRE10]'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The output is as follows:'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE11]'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This returns `49` for this dataset. So, one out of `50` states in the US does
    not appear in this dataset. Therefore, we can conclude that there's one repetition
    in the `State` column.
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个数据集返回`49`。所以，在美国的`50`个州中，有一个州没有出现在这个数据集中。因此，我们可以得出结论，`State`列中有一个重复项。
- en: Note
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/2NaBkUB](https://packt.live/2NaBkUB).
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要访问本节的具体源代码，请参阅[https://packt.live/2NaBkUB](https://packt.live/2NaBkUB)。
- en: You can also run this example online at [https://packt.live/2N7NHkf](https://packt.live/2N7NHkf).
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您也可以在[https://packt.live/2N7NHkf](https://packt.live/2N7NHkf)上在线运行此示例。
- en: Similarly, if we run this function on the `Country` column, we get an array
    with only one element, `United States`. Immediately, we can see that we don't
    need to keep the country column at all because there is no useful information
    in that column, except that all the entries are the same. This is how a simple
    function helped us to decide about dropping a column altogether – that is, removing
    `9,994` pieces of unnecessary data.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，如果我们对`Country`列运行这个函数，我们得到一个只有一个元素的数组，`United States`。立即，我们可以看到我们根本不需要保留国家列，因为该列中没有任何有用的信息，除了所有条目都相同。这就是一个简单的函数如何帮助我们决定完全删除一列——也就是说，删除`9,994`条不必要的数据。
- en: Conditional Selection and Boolean Filtering
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 条件选择和布尔过滤
- en: 'Often, we don''t want to process the whole dataset and would like to select
    only a partial dataset whose contents satisfy a particular condition. This is
    probably the most common use case of any data wrangling task. In the context of
    our `superstore sales` dataset, think of these common questions that may arise
    from the daily activities of the business analytics team:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，我们不想处理整个数据集，而只想选择满足特定条件的部分数据集。这可能是任何数据整理任务中最常见的用例。在我们的`superstore sales`数据集的背景下，想想业务分析团队日常活动中可能出现的这些常见问题：
- en: What are the average sales and profit figures in California?
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加利福尼亚州的平均销售额和利润数字是多少？
- en: Which states have the highest and lowest total sales?
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 哪些州的总销售额最高和最低？
- en: What consumer segment has the most variance in sales/profit?
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 哪个消费群体的销售额/利润变化最大？
- en: Among the top five states in sales, which shipping mode and product category
    are the most popular choices?
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在销售额排名前五的州中，哪种运输方式和产品类别最受欢迎？
- en: Countless examples can be given where the business analytics team or the executive
    management wants to glean insight from a particular subset of data that meets
    certain criteria.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 可以给出无数例子，其中业务分析团队或高管希望从满足某些标准的数据子集中获得洞察。
- en: If you have any prior experience with SQL, you will know that these kinds of
    questions require fairly complex SQL query writing. Remember the `WHERE` clause?
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你之前有SQL的使用经验，你会知道这类问题需要相当复杂的SQL查询编写。还记得`WHERE`子句吗？
- en: We will show you how to use conditional subsetting and boolean filtering to
    answer such questions.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将向您展示如何使用条件子集和布尔过滤来回答这些问题。
- en: 'First, we need to understand the critical concept of boolean indexing. This
    process essentially accepts a conditional expression as an argument and returns
    a dataset of booleans in which the `TRUE` value appears in places where the condition
    was satisfied. A simple example is shown in the following code. For demonstration
    purposes, we''re subsetting a small dataset of `10` records and `3` columns:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要理解布尔索引的关键概念。这个过程本质上接受一个条件表达式作为参数，并返回一个布尔数据集，其中`TRUE`值出现在条件得到满足的地方。以下代码中展示了简单示例。为了演示目的，我们正在对包含`10`条记录和`3`个列的小数据集进行子集化：
- en: '[PRE12]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The output is as follows:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.7: Sample dataset'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '![图4.7：样本数据集'
- en: '](img/B15780_04_07.jpg)'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15780_04_07.jpg)'
- en: 'Figure 4.7: Sample dataset'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.7：样本数据集
- en: 'Now, if we just want to know the records with sales higher than `$100`, then
    we can write the following:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果我们只想知道销售额超过`$100`的记录，我们可以编写以下代码：
- en: '[PRE13]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'This produces the following `boolean` DataFrame:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 这会产生以下`boolean`数据框：
- en: '![Figure 4.8 Records with sales higher than $100'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '![图4.8 销售额超过100美元的记录'
- en: '](img/B15780_04_08.jpg)'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15780_04_08.jpg)'
- en: Figure 4.8 Records with sales higher than $100
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.8 销售额超过100美元的记录
- en: Let's take a look at the `True` and `False` entries in the `Sales` column. The
    values in the `Ship Mode` and `State` columns were not impacted by this code because
    the comparison was with a numerical quantity, and the only numeric column in the
    original DataFrame was `Sales`.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看 `Sales` 列中的 `True` 和 `False` 条目。由于比较的是数值量，且原始 DataFrame 中唯一的数值列是 `Sales`，因此此代码对
    `Ship Mode` 和 `State` 列中的值没有影响。
- en: 'Now, let''s see what happens if we pass this `boolean` DataFrame as an index
    to the original DataFrame:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看如果我们把这个 `boolean` DataFrame 作为索引传递给原始 DataFrame 会发生什么：
- en: '[PRE14]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The output is as follows:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.9: Results after passing the boolean DataFrame as an index'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.9：将布尔 DataFrame 作为索引传递后的结果'
- en: to the original DataFrame
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 到原始 DataFrame
- en: '](img/B15780_04_09.jpg)'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15780_04_09.jpg)'
- en: 'Figure 4.9: Results after passing the boolean DataFrame as an index to the
    original DataFrame'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.9：将布尔 DataFrame 作为索引传递给原始 DataFrame 后的结果
- en: We are not limited to conditional expressions involving numeric quantities only.
    Let's try to extract high sales values (`>$100`) for entries that do not involve
    `California`.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不仅限于只涉及数值量的条件表达式。让我们尝试提取不涉及 `California` 的销售值（`>$100`）。
- en: 'We can write the following code to accomplish this:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以编写以下代码来完成此操作：
- en: '[PRE15]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Note the use of a conditional involving string. In this expression, we are joining
    two conditionals by an `&` operator. Both conditions must be wrapped inside parentheses.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 注意使用涉及字符串的条件。在这个表达式中，我们通过 `&` 运算符连接两个条件。两个条件都必须用括号括起来。
- en: 'The first conditional expression simply matches the entries in the `State`
    column to the `California` string and assigns `TRUE`/`FALSE` accordingly. The
    second conditional is the same as before. Together, joined by the `&` operator,
    they extract only those rows for which `State` is *not* `California` and `Sales`
    is `> $100`. We get the following result:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个条件表达式简单地匹配 `State` 列中的条目与 `California` 字符串，并相应地分配 `TRUE`/`FALSE`。第二个条件与之前相同。两者通过
    `&` 运算符连接，提取出 `State` 不是 `California` 且 `Sales` 大于 `$100` 的行。我们得到以下结果：
- en: '![Figure 4.10: Results, where State is not California and Sales, is higher
    than $100'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.10：结果，其中 State 不是 California 且 Sales 大于 $100'
- en: '](img/B15780_04_10.jpg)'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15780_04_10.jpg)'
- en: 'Figure 4.10: Results, where State is not California and Sales, is higher than
    $100'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.10：结果，其中 State 不是 California 且 Sales 大于 $100
- en: Note
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Although, in theory, there is no limit to how complex a conditional you can
    build using individual expressions and the `&` (`LOGICAL AND`) and `|` (`LOGICAL
    OR`) operators, it is advisable to create intermediate boolean DataFrames with
    limited conditional expressions and build your final DataFrame step by step. This
    keeps the code legible and scalable.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然理论上，你可以使用单个表达式和 `&` (`逻辑与`) 和 `|` (`逻辑或`) 运算符构建任意复杂的条件，但建议创建具有有限条件表达式的中间布尔
    DataFrame，并逐步构建最终的 DataFrame。这使代码易于阅读和扩展。
- en: In the following exercise, we'll look at a few different methods we can use
    to manipulate the DataFrame.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的练习中，我们将探讨我们可以用来操作 DataFrame 的几种不同方法。
- en: 'Exercise 4.03: Setting and Resetting the Index'
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 4.03：设置和重置索引
- en: 'In this exercise, we will create a pandas DataFrame and set and reset the index.
    We''ll also add a new column and set it as the new index of this DataFrame. To
    do so, let''s go through the following steps:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将创建一个 pandas DataFrame，并设置和重置索引。我们还将添加一个新列，并将其设置为该 DataFrame 的新索引。为此，让我们按照以下步骤进行：
- en: 'Import the `numpy` library:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入 `numpy` 库：
- en: '[PRE16]'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Create the `matrix_data`, `row_labels`, and `column_headings` functions using
    the following commands:'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令创建 `matrix_data`、`row_labels` 和 `column_headings` 函数：
- en: '[PRE17]'
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Import the `pandas` library and then create a DataFrame using the `matrix_data`,
    `row_labels`, and `column_headings` functions:'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入 `pandas` 库，然后使用 `matrix_data`、`row_labels` 和 `column_headings` 函数创建 DataFrame：
- en: '[PRE18]'
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The output is as follows:'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.11: The original DataFrame'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.11：原始 DataFrame'
- en: '](img/B15780_04_11.jpg)'
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15780_04_11.jpg)'
- en: 'Figure 4.11: The original DataFrame'
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.11：原始 DataFrame
- en: 'Reset the index, as follows:'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按如下方式重置索引：
- en: '[PRE19]'
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The output is as follows:'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.12: DataFrame after resetting the index'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.12：重置索引后的 DataFrame'
- en: '](img/B15780_04_12.jpg)'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15780_04_12.jpg)'
- en: 'Figure 4.12: DataFrame after resetting the index'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.12：重置索引后的 DataFrame
- en: 'Reset the index with `drop` set to `True`, as follows:'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 `drop` 设置为 `True` 重置索引，如下所示：
- en: '[PRE20]'
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The output is as follows:'
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.13: DataFrame after resetting the index with the drop option set
    to true'
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.13：使用 drop 选项设置为 true 重置索引后的 DataFrame]'
- en: '](img/B15780_04_13.jpg)'
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15780_04_13.jpg)'
- en: 'Figure 4.13: DataFrame after resetting the index with the drop option set to
    true'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.13：使用 drop 选项设置为 true 重置索引后的 DataFrame
- en: 'Add a new column using the following command:'
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令添加新列：
- en: '[PRE21]'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The output is as follows:'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.14: DataFrame after adding a new column called Profession'
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.14：添加了名为 Profession 的新列后的 DataFrame]'
- en: '](img/B15780_04_14.jpg)'
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15780_04_14.jpg)'
- en: 'Figure 4.14: DataFrame after adding a new column called Profession'
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.14：添加了名为 Profession 的新列后的 DataFrame
- en: 'Now, set the `Profession` column as an `index` using the following code:'
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用以下代码将 `Profession` 列设置为 `index`：
- en: '[PRE22]'
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The output is as follows:'
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.15: DataFrame after setting the Profession column as an index'
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.15：将 Profession 列设置为索引后的 DataFrame]'
- en: '](img/B15780_04_15.jpg)'
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15780_04_15.jpg)'
- en: 'Figure 4.15: DataFrame after setting the Profession column as an index'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.15：将 Profession 列设置为索引后的 DataFrame
- en: As we can see, the new data was added at the end of the table.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，新数据被添加到表的末尾。
- en: Note
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/30QknH2](https://packt.live/30QknH2).
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参阅 [https://packt.live/30QknH2](https://packt.live/30QknH2)。
- en: You can also run this example online at [https://packt.live/37CdM4o](https://packt.live/37CdM4o).
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以在 [https://packt.live/37CdM4o](https://packt.live/37CdM4o) 上在线运行此示例。
- en: The GroupBy Method
  id: totrans-167
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GroupBy 方法
- en: '**GroupBy** refers to a process involving one or more of the following steps:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '**GroupBy** 指的是涉及以下一个或多个步骤的过程：'
- en: Splitting the data into groups based on some criteria
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据某些标准将数据分成组
- en: Applying a function to each group independently
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对每个组独立应用函数
- en: Combining the results into a data structure
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将结果合并到数据结构中
- en: 'In many situations, we can split the dataset into groups and do something with
    those groups. In the apply step, we may wish to do one of the following:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多情况下，我们可以将数据集分成组，并对这些组进行一些操作。在应用步骤中，我们可能希望执行以下操作之一：
- en: '**Aggregation**: Compute a summary statistic (or statistics) for each group
    – sum, mean, and so on'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**聚合**：对每个组计算汇总统计量（或统计量） - 总和、平均值等'
- en: '**Transformation**: Perform a group-specific computation and return a like-indexed
    object – z-transformation or filling missing data with a value'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**转换**：执行特定组的计算并返回一个类似索引的对象 - z 转换或用值填充缺失数据'
- en: '`TRUE` or `FALSE`'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TRUE` 或 `FALSE`'
- en: There is, of course, a describe method for this `GroupBy` object, which produces
    the summary statistics in the form of a DataFrame.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，对于这个 `GroupBy` 对象有一个描述方法，它以 DataFrame 的形式产生汇总统计信息。
- en: Note
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The name GroupBy should be quite familiar to those who have used a SQL-based
    tool before.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 对于那些之前使用过基于 SQL 的工具的人来说，名称 GroupBy 应该相当熟悉。
- en: GroupBy is not limited to a single variable. If you pass on multiple variables
    (as a list), then you will get a structure essentially similar to a Pivot Table
    (from Excel). The following exercise shows an example of where we group together
    all the states and cities from the whole dataset (the snapshot is only a partial
    view).
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '`GroupBy` 并不仅限于单个变量。如果你传递多个变量（作为一个列表），那么你将得到一个本质上类似于交叉表的结构（来自 Excel）。以下练习展示了我们将整个数据集（快照仅为部分视图）中的所有州和城市分组在一起的一个例子。'
- en: 'Exercise 4.04: The GroupBy Method'
  id: totrans-180
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 4.04：GroupBy 方法
- en: 'In this exercise, we''re going to create a subset from a dataset. We will use
    the `groupBy` object to filter the dataset and calculate the mean of that filtered
    dataset. To do so, let''s go through the following steps:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将从一个数据集中创建一个子集。我们将使用 `groupBy` 对象来过滤数据集并计算该过滤数据集的平均值。为此，让我们按照以下步骤进行：
- en: Note
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'The `superstore` dataset file can be found here: [https://packt.live/3dcVnMs](https://packt.live/3dcVnMs).'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '`superstore` 数据集文件可以在以下位置找到：[https://packt.live/3dcVnMs](https://packt.live/3dcVnMs)。'
- en: 'Import the necessary Python modules and read the Excel file from GitHub by
    using the `read_excel` method in `pandas`:'
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入必要的 Python 模块，并使用 `pandas` 中的 `read_excel` 方法从 GitHub 读取 Excel 文件：
- en: '[PRE23]'
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The output (partially shown) is as follows:'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出（部分显示）如下：
- en: '![Figure 4.16: Partial output of the DataFrame'
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.16：DataFrame 的部分输出]'
- en: '](img/B15780_04_16.jpg)'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15780_04_16.jpg)'
- en: 'Figure 4.16: Partial output of the DataFrame'
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.16：DataFrame 的部分输出
- en: Note
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: The highlighted path must be changed based on the location of the file on your
    system.
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 高亮显示的路径必须根据您系统上文件的位置进行更改。
- en: 'Create a 10-record subset using the following command:'
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令创建一个包含 10 条记录的子集：
- en: '[PRE24]'
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The output will be as follows:'
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 4.17: 10-Record Subset'
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图4.17：10条记录的子集]'
- en: '](img/B15780_04_17.jpg)'
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图B15780_04_17.jpg](img/B15780_04_17.jpg)'
- en: 'Figure 4.17: 10-Record Subset'
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图4.17：10条记录的子集
- en: 'Create a `pandas` DataFrame using the `groupby` method, as follows:'
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`groupby`方法创建`pandas` DataFrame，如下所示：
- en: '[PRE25]'
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The output will be similar to:'
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果将与以下类似：
- en: '[PRE26]'
  id: totrans-201
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Calculate the mean sales figure by `State` by using the following command:'
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令通过`State`计算平均销售额：
- en: '[PRE27]'
  id: totrans-203
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The output is as follows:'
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 4.18: Output after grouping the state with the listing mean sales'
  id: totrans-205
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图4.18：按销售列表平均销售额分组状态后的输出]'
- en: '](img/B15780_04_18.jpg)'
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图B15780_04_18.jpg](img/B15780_04_18.jpg)'
- en: 'Figure 4.18: Output after grouping the state with the listing mean sales'
  id: totrans-207
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图4.18：按销售列表平均销售额分组状态后的输出
- en: 'Calculate the total sales figure by `State` by using the following command:'
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令通过`State`计算总销售额：
- en: '[PRE28]'
  id: totrans-209
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The output is as follows:'
  id: totrans-210
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 4.19: The output after grouping the state with the listing sum of
    sales'
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图4.19：按销售列表总和分组状态后的输出]'
- en: '](img/B15780_04_19.jpg)'
  id: totrans-212
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图B15780_04_19.jpg](img/B15780_04_19.jpg)'
- en: 'Figure 4.19: The output after grouping the state with the listing sum of sales'
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图4.19：按销售列表总和分组状态后的输出
- en: 'Subset that DataFrame for a particular state and show the statistics:'
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为特定州的数据框创建子集并显示统计数据：
- en: '[PRE29]'
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The output is as follows:'
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 4.20: Checking the statistics of a particular state'
  id: totrans-217
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图4.20：检查特定状态的统计数据]'
- en: '](img/B15780_04_20.jpg)'
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图B15780_04_20.jpg](img/B15780_04_20.jpg)'
- en: 'Figure 4.20: Checking the statistics of a particular state'
  id: totrans-219
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图4.20：检查特定状态的统计数据
- en: 'Perform a similar summarization by using the `Ship Mode` attribute:'
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`Ship Mode`属性执行类似的总结：
- en: '[PRE30]'
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The output will be as follows:'
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 4.21: Checking the sales by summarizing the Ship Mode attribute'
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图4.21：通过汇总`Ship Mode`属性检查销售]'
- en: '](img/B15780_04_21.jpg)'
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图B15780_04_21.jpg](img/B15780_04_21.jpg)'
- en: 'Figure 4.21: Checking the sales by summarizing the Ship Mode attribute'
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图4.21：通过汇总`Ship Mode`属性检查销售
- en: 'Display the complete summary statistics of sales by every city in each state
    – all with two lines of code – by using the following command:'
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令通过两行代码显示每个州每个城市的完整销售汇总统计信息：
- en: '[PRE31]'
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The output (partially shown) is as follows:'
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果（部分显示）如下：
- en: '![Figure 4.22: Partial output while checking the summary statistics of sales'
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图4.22：检查销售汇总统计信息时的部分输出]'
- en: '](img/B15780_04_22.jpg)'
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图B15780_04_22.jpg](img/B15780_04_22.jpg)'
- en: 'Figure 4.22: Partial output while checking the summary statistics of sales'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.22：检查销售汇总统计信息时的部分输出
- en: Note how `pandas` has grouped the data by `State` first and then by cities under
    each state.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 注意`pandas`首先按`State`分组，然后在每个州下按城市分组。
- en: Note
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/2Cm9eUl](https://packt.live/2Cm9eUl).
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参阅[https://packt.live/2Cm9eUl](https://packt.live/2Cm9eUl)。
- en: You can also run this example online at [https://packt.live/3fxK43c](https://packt.live/3fxK43c).
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以在[https://packt.live/3fxK43c](https://packt.live/3fxK43c)上在线运行此示例。
- en: We now understand how to use `pandas` to group our dataset and then find aggregate
    values such as the mean sales return of our top employees. We also looked at how
    pandas will display descriptive statistics about our data for us. Both of these
    techniques can be used to perform analysis on our superstore data.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在了解了如何使用`pandas`对数据集进行分组，然后找到诸如我们顶级员工的平均销售退货率之类的汇总值。我们还探讨了`pandas`将如何为我们显示数据的描述性统计信息。这两种技术都可以用来对我们超市数据进行分析。
- en: Detecting Outliers and Handling Missing Values
  id: totrans-237
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检测异常值和处理缺失值
- en: Outlier detection and handling missing values fall under the subtle art of data
    quality checking. A modeling or data mining process is fundamentally a complex
    series of computations whose output quality largely depends on the quality and
    consistency of the input data being fed. The responsibility of maintaining and
    gatekeeping that quality often falls on the shoulders of a data wrangling team.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 异常值检测和处理缺失值属于数据质量检查的微妙艺术。建模或数据挖掘过程本质上是一系列复杂的计算，其输出质量在很大程度上取决于输入数据的质量和一致性。维护和守护这种质量的责任通常落在数据整理团队的肩上。
- en: Apart from the obvious issue of poor-quality data, missing data can sometimes
    wreak havoc with the **Machine Learning** (**ML**) model downstream. A few ML
    models, such as Bayesian learning, are inherently robust to outliers and missing
    data, but common techniques such as Decision Trees and Random Forest have an issue
    with missing data because the fundamental splitting strategy employed by these
    techniques depends on an individual piece of data and not a cluster. Therefore,
    it is almost always imperative to impute missing data before handing it over to
    such an ML model.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 除了明显的数据质量问题外，缺失数据有时会对下游的**机器学习**（**ML**）模型造成破坏。一些机器学习模型，如贝叶斯学习，对异常值和缺失数据具有固有的鲁棒性，但常见的决策树和随机森林等技术对缺失数据有问题，因为这些技术的根本分割策略依赖于单个数据点而不是集群。因此，在将数据交给这样的机器学习模型之前，几乎总是必须插补缺失数据。
- en: 'Outlier detection is a subtle art. Often, there is no universally agreed definition
    of an outlier. In a statistical sense, a data point that falls outside a certain
    range may often be classified as an outlier, but to apply that definition, you
    need to have a fairly high degree of certainty about the assumption of the nature
    and parameters of the inherent statistical distribution about the data. It takes
    a lot of data to build that statistical certainty and even after that, an outlier
    may not be just unimportant noise but a clue to something deeper. Let''s look
    at an example with some fictitious sales data from an American fast-food chain
    restaurant. If we want to model the daily sales data as a time series, we will
    observe an unusual spike in the data somewhere around mid-April:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 异常值检测是一种微妙的艺术。通常，没有关于异常值的普遍认同定义。从统计意义上讲，一个落在某个范围之外的数据点可能经常被归类为异常值，但为了应用这个定义，你需要对数据内在统计分布的性质和参数有一个相当高的确定性。这需要大量的数据来建立这种统计确定性，即使如此，异常值可能不仅仅是无关紧要的噪声，而是对更深层次事物的线索。让我们看看一些虚构的美国快餐连锁餐厅的销售数据的例子。如果我们想将每日销售数据建模为时间序列，我们将在大约4月中旬观察到数据中的一个异常峰值：
- en: '![Figure 4.23: Fictitious sales data of an American fast-food chain restaurant'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: '![图4.23：美国快餐连锁餐厅的虚构销售数据'
- en: '](img/B15780_04_23.jpg)'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B15780_04_23.jpg)'
- en: 'Figure 4.23: Fictitious sales data of an American fast-food chain restaurant'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.23：美国快餐连锁餐厅的虚构销售数据
- en: A good data scientist or data wrangler should develop curiosity about this data
    point rather than just rejecting it just because it falls outside the statistical
    range. In the actual anecdote, the sales figure spiked that day because of an
    unusual reason. So, the data was real. But just because it was real does not mean
    it is useful. In the final goal of building a smoothly varying time series model,
    this one point should not matter and should be rejected. In this chapter, however,
    we're going to look at ways of handling outliers instead of rejecting them.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 一个好的数据科学家或数据整理员应该对数据点产生好奇心，而不是仅仅因为它们超出了统计范围就拒绝它们。在实际情况中，当天的销售额激增是由于一个不寻常的原因。因此，数据是真实的。但仅仅因为数据是真实的，并不意味着它是有用的。在构建平稳变化的时间序列模型的最终目标中，这个点不应该很重要，应该被拒绝。然而，在本章中，我们将探讨处理异常值而不是拒绝它们的方法。
- en: Therefore, the key to outliers is their systematic and timely detection in an
    incoming stream of millions of data or while reading data from cloud-based storage.
    In this section, we will quickly go over some basic statistical tests for detecting
    outliers and some basic imputation techniques for filling up missing data.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，异常值的关键在于在数百万数据流中系统及时地检测它们，或者在从基于云的存储中读取数据时。在本节中，我们将快速介绍一些用于检测异常值的基本统计测试和一些用于填充缺失数据的基本插补技术。
- en: Missing Values in Pandas
  id: totrans-246
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Pandas中的缺失值
- en: 'One of the most useful functions for detecting missing values is `isnull`.
    We''ll use this function on a DataFrame called `df_missing` (based on the Superstore
    DataFrame we are working with), which, as the name suggests, will contain some
    missing values. You can create this DataFrame using the following command:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 检测缺失值最有用的函数之一是 `isnull`。我们将使用这个函数在一个名为 `df_missing` 的 DataFrame 上（基于我们正在处理的
    Superstore DataFrame），正如其名所示，它将包含一些缺失值。你可以使用以下命令创建这个 DataFrame：
- en: '[PRE32]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Note
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Don't forget to change the path (highlighted) based on the location of the file
    on your system.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 不要忘记根据你系统上文件的位置更改路径（已突出显示）。
- en: 'The output will be as follows:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '![Figure 4.24: DataFrame with missing values'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: '![图4.24：包含缺失值的DataFrame'
- en: '](img/B15780_04_24.jpg)'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片](img/B15780_04_24.jpg)'
- en: 'Figure 4.24: DataFrame with missing values'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.24：包含缺失值的 DataFrame
- en: 'We can see that the missing values are denoted by `NaN`. Now let''s use the
    `isnull` function on the same DataFrame and observe the results:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，缺失值用 `NaN` 表示。现在，让我们在同一个 DataFrame 上使用 `isnull` 函数并观察结果：
- en: '[PRE33]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The output is as follows:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.25: Output highlighting the missing values'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.25：突出显示缺失值的输出'
- en: '](img/B15780_04_25.jpg)'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15780_04_25.jpg)'
- en: 'Figure 4.25: Output highlighting the missing values'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.25：突出显示缺失值的输出
- en: 'As you can see, the missing values are indicated by the Boolean value `True`.
    Now, let''s see how we can use the `isnull` function to deliver results that are
    a bit more user friendly. Here is an example of some very simple code to detect,
    count, and print out missing values in every column of a DataFrame:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，缺失值由布尔值 `True` 表示。现在，让我们看看如何使用 `isnull` 函数提供更用户友好的结果。以下是一些非常简单的代码示例，用于检测、计数并打印出
    DataFrame 中每一列的缺失值：
- en: '[PRE34]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'This code scans every column of the DataFrame, calls the `isnull` function,
    and sums up the returned object (a `pandas` Series object, in this case) to count
    the number of missing values. If the missing value is greater than zero, it prints
    out the message accordingly. The output looks as follows:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码扫描 DataFrame 的每一列，调用 `isnull` 函数，并将返回的对象（在这种情况下是一个 `pandas` Series 对象）求和，以计算缺失值的数量。如果缺失值大于零，则相应地打印出消息。输出如下：
- en: '![Figure 4.26: Output of counting the missing values'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.26：缺失值的计数输出'
- en: '](img/B15780_04_26.jpg)'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15780_04_26.jpg)'
- en: 'Figure 4.26: Output of counting the missing values'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.26：缺失值计数的输出
- en: As we can see from the preceding output, the missing values were detected from
    the `Superstore` dataset.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述的输出所示，缺失值是从 `Superstore` 数据集中检测到的。
- en: To handle missing values, you should look for ways not to drop them altogether
    but to fill them somehow. The `fillna` method is a useful function for performing
    this task on `pandas` DataFrames. The `fillna` method may work for string data,
    but not for numerical columns such as sales or profits. So, we should restrict
    ourselves in regard to this fixed string replacement being used on non-numeric
    text-based columns only. The `Pad` or `ffill` function is used to fill forward
    the data, that is, copy it from the preceding data of the series. Forward fill
    is a technique where the missing value is filled with the previous value. On the
    other hand, backward fill or `bfill` uses the next value to fill in any missing
    data. Let's practice this with the following exercise.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 处理缺失值时，你应该寻找方法不是完全删除它们，而是以某种方式填充它们。`fillna` 方法是用于在 `pandas` DataFrame 上执行此任务的有用函数。`fillna`
    方法可能适用于字符串数据，但不适用于销售或利润等数值列。因此，我们应该仅限于在非数值文本列上使用此固定的字符串替换。`Pad` 或 `ffill` 函数用于向前填充数据，即从序列的前一个数据中复制它。前向填充是一种技术，其中缺失值用前一个值填充。另一方面，后向填充或
    `bfill` 使用下一个值来填充任何缺失数据。让我们通过以下练习来练习这个：
- en: 'Exercise 4.05: Filling in the Missing Values Using the fillna Method'
  id: totrans-269
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 4.05：使用 `fillna` 方法填充缺失值
- en: In this exercise, we are going to perform four techniques in order to deal with
    the missing values in a dataset.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将按顺序执行四种技术来处理数据集中的缺失值。
- en: Note
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'The `superstore` dataset file can be found here: [https://packt.live/3dcVnMs](https://packt.live/3dcVnMs).'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: '`superstore` 数据集文件可以在以下位置找到：[https://packt.live/3dcVnMs](https://packt.live/3dcVnMs)。'
- en: 'Firstly, we are going to replace the missing values with static values using
    the `fillna` method. Then, we will use the `ffill` and `bfill` methods to replace
    the missing values. Lastly, we will calculate the average of a column and replace
    the missing value with that. To do so, let''s go through the following steps:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将使用 `fillna` 方法将缺失值替换为静态值。然后，我们将使用 `ffill` 和 `bfill` 方法来替换缺失值。最后，我们将计算一列的平均值，并用该平均值替换缺失值。为此，请按照以下步骤进行：
- en: 'Import the necessary Python modules and read the Excel file from GitHub by
    using the `read_excel` method in `pandas`:'
  id: totrans-274
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入必要的 Python 模块，并使用 `pandas` 中的 `read_excel` 方法从 GitHub 读取 Excel 文件：
- en: '[PRE35]'
  id: totrans-275
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Note
  id: totrans-276
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: The highlighted path must be changed based on the location of the file on your
    system.
  id: totrans-277
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 高亮显示的路径必须根据您系统上文件的位置进行更改。
- en: 'The output is as follows:'
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.27: Snapshot of the dataset'
  id: totrans-279
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.27：数据集快照'
- en: '](img/B15780_04_27.jpg)'
  id: totrans-280
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15780_04_27.jpg)'
- en: 'Figure 4.27: Snapshot of the dataset'
  id: totrans-281
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.27：数据集快照
- en: 'Fill in all the missing values with the `FILL` string by using the following command:'
  id: totrans-282
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令将所有缺失值填充为 `FILL` 字符串：
- en: '[PRE36]'
  id: totrans-283
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The output is as follows:'
  id: totrans-284
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.28: Missing values replaced with FILL'
  id: totrans-285
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图4.28：缺失值被替换为FILL](img/B15780_04_28.jpg)'
- en: '](img/B15780_04_28.jpg)'
  id: totrans-286
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![img/B15780_04_28.jpg](img/B15780_04_28.jpg)'
- en: 'Figure 4.28: Missing values replaced with FILL'
  id: totrans-287
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图4.28：缺失值被替换为FILL
- en: 'Fill in the specified columns with the `FILL` string by using the following command:'
  id: totrans-288
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令使用`FILL`字符串填充指定的列：
- en: '[PRE37]'
  id: totrans-289
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'The output is as follows:'
  id: totrans-290
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.29: Specified columns replaced with FILL'
  id: totrans-291
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图4.29：指定的列被替换为FILL](img/B15780_04_29.jpg)'
- en: '](img/B15780_04_29.jpg)'
  id: totrans-292
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![img/B15780_04_29.jpg](img/B15780_04_29.jpg)'
- en: 'Figure 4.29: Specified columns replaced with FILL'
  id: totrans-293
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图4.29：指定的列被替换为FILL
- en: Note
  id: totrans-294
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: In all of these cases, the function works on a copy of the original DataFrame.
    So, if you want to make the changes permanent, you have to assign the DataFrames
    that are returned by these functions to the original DataFrame object.
  id: totrans-295
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在所有这些情况下，函数都是在原始DataFrame的副本上工作的。因此，如果您想使更改永久生效，您必须将这些函数返回的DataFrame赋值给原始DataFrame对象。
- en: 'Fill in the values using `ffill` or forward fill by using the following command
    on the `Sales` column:'
  id: totrans-296
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令在`Sales`列上使用`ffill`或前向填充来填充值：
- en: '[PRE38]'
  id: totrans-297
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'The output is as follows:'
  id: totrans-298
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.30: Sales column using the forward fill'
  id: totrans-299
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图4.30：使用前向填充的销售列](img/B15780_04_30.jpg)'
- en: '](img/B15780_04_30.jpg)'
  id: totrans-300
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![img/B15780_04_30.jpg](img/B15780_04_30.jpg)'
- en: 'Figure 4.30: Sales column using the forward fill'
  id: totrans-301
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图4.30：使用前向填充的销售列
- en: 'Use `bfill` to fill backward, that is, copy from the next data in the series:'
  id: totrans-302
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`bfill`向后填充，即从序列中的下一个数据复制：
- en: '[PRE39]'
  id: totrans-303
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The output is as follows:'
  id: totrans-304
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.31: Sales column using the backward fill'
  id: totrans-305
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图4.31：使用后向填充的销售列](img/B15780_04_31.jpg)'
- en: '](img/B15780_04_31.jpg)'
  id: totrans-306
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![img/B15780_04_31.jpg](img/B15780_04_31.jpg)'
- en: 'Figure 4.31: Sales column using the backward fill'
  id: totrans-307
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图4.31：使用后向填充的销售列
- en: 'Let''s compare these two series and see what happened in each case:'
  id: totrans-308
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 让我们比较这两个序列并查看每种情况发生了什么：
- en: '![Figure 4.32: Using forward fill and backward fill to fill in missing data'
  id: totrans-309
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图4.32：使用前向填充和后向填充填充缺失数据](img/B15780_04_32.jpg)'
- en: '](img/B15780_04_32.jpg)'
  id: totrans-310
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![img/B15780_04_32.jpg](img/B15780_04_32.jpg)'
- en: 'Figure 4.32: Using forward fill and backward fill to fill in missing data'
  id: totrans-311
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图4.32：使用前向填充和后向填充填充缺失数据
- en: You can also fill by using a function average of DataFrames. For example, we
    may want to fill the missing values in `Sales` by the average sales amount.
  id: totrans-312
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您也可以使用DataFrame的平均值函数进行填充。例如，我们可能希望使用平均销售额填充`Sales`中的缺失值。
- en: 'Fill the missing values in `Sales` by the average sales amount:'
  id: totrans-313
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用平均销售额填充`Sales`中的缺失值：
- en: '[PRE40]'
  id: totrans-314
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'The output is as follows:'
  id: totrans-315
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.33: Sales column with average sales amount'
  id: totrans-316
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图4.33：带有平均销售额的销售列](img/B15780_04_33.jpg)'
- en: '](img/B15780_04_33.jpg)'
  id: totrans-317
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![img/B15780_04_33.jpg](img/B15780_04_33.jpg)'
- en: 'Figure 4.33: Sales column with average sales amount'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.33：带有平均销售额的销售列
- en: 'The following screenshot shows what happened in the preceding code:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了前面代码中发生的情况：
- en: '![Figure 4.34: Using average to fill in missing data'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: '![图4.34：使用平均值填充缺失数据](img/B15780_04_34.jpg)'
- en: '](img/B15780_04_34.jpg)'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B15780_04_34.jpg](img/B15780_04_34.jpg)'
- en: 'Figure 4.34: Using average to fill in missing data'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.34：使用平均值填充缺失数据
- en: Here, we can observe that the missing value in the cell was filled by the average
    sales amount.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以观察到单元格中的缺失值被平均销售额填充。
- en: Note
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/2ACDYjp](https://packt.live/2ACDYjp).
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参阅[https://packt.live/2ACDYjp](https://packt.live/2ACDYjp)。
- en: You can also run this example online at [https://packt.live/2YNZnhh](https://packt.live/2YNZnhh).
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以在[https://packt.live/2YNZnhh](https://packt.live/2YNZnhh)上运行此示例。
- en: 'With this, we have now seen how to replace missing values within a `pandas`
    DataFrame using four methods: static value, forward fill, backward fill, and the
    average. These are the fundamental techniques when cleaning data with missing values.'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这种方式，我们已经了解了如何在`pandas` DataFrame中使用四种方法来替换缺失值：静态值、前向填充、后向填充和平均值。这些是在处理缺失值数据时的基本技术。
- en: The dropna Method
  id: totrans-328
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: dropna 方法
- en: This function is used to simply drop the rows or columns that contain `NaN`
    or missing values. However, there is some choice involved.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数用于简单地删除包含`NaN`或缺失值的行或列。然而，这里有一些选择。
- en: 'The following is the syntax of the `dropna()` method:'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 以下为`dropna()`方法的语法：
- en: '[PRE41]'
  id: totrans-331
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: If the `axis` parameter of a `dropna()` method is set to `0`, then rows containing
    missing values are dropped; if the axis parameter is set to `1`, then columns
    containing missing values are dropped. These are useful if we don't want to drop
    a particular row/column if the `NaN` values do not exceed a certain percentage.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 `dropna()` 方法的 `axis` 参数设置为 `0`，则包含缺失值的行将被删除；如果 `axis` 参数设置为 `1`，则包含缺失值的列将被删除。如果
    `NaN` 值不超过一定百分比，这些操作非常有用，如果我们不想删除特定的行/列。
- en: 'Two arguments that are useful for the `dropna()` method are as follows:'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 `dropna()` 方法，有两个有用的参数如下：
- en: The `how` argument determines if a row or column is removed from a DataFrame
    when we have at least one `NaN` value or all `NaN` values.
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`how` 参数确定当我们至少有一个 `NaN` 值或所有 `NaN` 值时，是否从 DataFrame 中删除行或列。'
- en: The `thresh` argument requires that many non-`NaN` values to keep the row/ column.
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`thresh` 参数要求保留行/列的许多非 `NaN` 值。'
- en: We'll practice using the `dropna()` method in the following exercise.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在以下练习中练习使用 `dropna()` 方法。
- en: 'Exercise 4.06: Dropping Missing Values with dropna'
  id: totrans-337
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 4.06：使用 dropna 删除缺失值
- en: In this exercise, we will remove the cells in a dataset that don't contain data.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们将删除数据集中不包含数据的单元格。
- en: Note
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'The `superstore` dataset file can be found here: [https://packt.live/3dcVnMs](https://packt.live/3dcVnMs).'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: '`superstore` 数据集文件可以在以下位置找到：[https://packt.live/3dcVnMs](https://packt.live/3dcVnMs)。'
- en: 'We are going to use the `dropna` method in order to remove missing cells in
    a dataset. To do so, let''s go through the following steps:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 `dropna` 方法来删除数据集中的缺失单元格。为此，让我们按照以下步骤进行：
- en: 'Import the necessary Python libraries and read the Excel file from GitHub by
    using the `read_excel` method in `pandas`:'
  id: totrans-342
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入必要的 Python 库，并使用 `pandas` 中的 `read_excel` 方法从 GitHub 读取 Excel 文件：
- en: '[PRE42]'
  id: totrans-343
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Note
  id: totrans-344
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: The highlighted path must be changed based on the location of the file on your
    system.
  id: totrans-345
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 高亮显示的路径必须根据您系统上文件的位置进行更改。
- en: 'The output is as follows:'
  id: totrans-346
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.35: Superstore dataset'
  id: totrans-347
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.35：Superstore 数据集'
- en: '](img/B15780_04_35.jpg)'
  id: totrans-348
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B15780_04_35.jpg)'
- en: 'Figure 4.35: Superstore dataset'
  id: totrans-349
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.35：Superstore 数据集
- en: Note
  id: totrans-350
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: The outputs you get will vary from the ones shown in this exercise.
  id: totrans-351
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你得到的输出将与本练习中显示的输出不同。
- en: 'To set the `axis` parameter to `zero` and drop all missing rows, use the following command:'
  id: totrans-352
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要将 `axis` 参数设置为 `zero` 并删除所有缺失行，请使用以下命令：
- en: '[PRE43]'
  id: totrans-353
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'The output is as follows:'
  id: totrans-354
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.36: Dropping all the missing rows'
  id: totrans-355
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.36：删除所有缺失行'
- en: '](img/B15780_04_36.jpg)'
  id: totrans-356
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B15780_04_36.jpg)'
- en: 'Figure 4.36: Dropping all the missing rows'
  id: totrans-357
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.36：删除所有缺失行
- en: 'To set the `axis` parameter to `1` and drop all missing rows, use the following command:'
  id: totrans-358
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要将 `axis` 参数设置为 `1` 并删除所有缺失行，请使用以下命令：
- en: '[PRE44]'
  id: totrans-359
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'The output is as follows:'
  id: totrans-360
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.37: Dropping rows or columns to handle missing data'
  id: totrans-361
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.37：删除行或列以处理缺失数据'
- en: '](img/B15780_04_37.jpg)'
  id: totrans-362
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B15780_04_37.jpg)'
- en: 'Figure 4.37: Dropping rows or columns to handle missing data'
  id: totrans-363
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.37：删除行或列以处理缺失数据
- en: 'Drop the values with `axis` set to `1` and `thresh` set to `10`:'
  id: totrans-364
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `axis` 设置为 `1` 和 `thresh` 设置为 `10` 删除值：
- en: '[PRE45]'
  id: totrans-365
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'The output is as follows:'
  id: totrans-366
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.38: DataFrame with values dropped with axis=1 and thresh=10'
  id: totrans-367
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.38：使用 axis=1 和 thresh=10 删除值的 DataFrame'
- en: '](img/B15780_04_38.jpg)'
  id: totrans-368
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B15780_04_38.jpg)'
- en: 'Figure 4.38: DataFrame with values dropped with axis=1 and thresh=10'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.38：使用 axis=1 和 thresh=10 删除值的 DataFrame
- en: As you can see, some `NaN` values still exist, but because of the minimum threshold,
    those rows were kept in place.
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，一些 `NaN` 值仍然存在，但由于最小阈值，这些行被保留在原位。
- en: Note
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/2Ybvx7t](https://packt.live/2Ybvx7t).
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参阅 [https://packt.live/2Ybvx7t](https://packt.live/2Ybvx7t)。
- en: You can also run this example online at [https://packt.live/30RNCsY](https://packt.live/30RNCsY).
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以在 [https://packt.live/30RNCsY](https://packt.live/30RNCsY) 上运行此示例。
- en: In this exercise, we looked at dropping missing values rows and columns. This
    is a useful technique for a variety of cases, including when working with machine
    learning. Some machine learning models do not handle missing data well and removing
    them ahead of time can be best practices.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们探讨了删除缺失值行和列。这是一个在多种情况下都很有用的技术，包括在处理机器学习时。一些机器学习模型处理缺失数据不佳，提前删除它们可能是最佳实践。
- en: Outlier Detection Using a Simple Statistical Test
  id: totrans-375
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用简单统计测试进行异常值检测
- en: 'As we''ve already discussed, outliers in a dataset can occur due to many factors
    and in many ways:'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们已经讨论过的，数据集中的异常值可能由于许多因素以多种方式出现：
- en: Data entry errors
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据录入错误
- en: Experimental errors (data extraction related)
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实验误差（数据提取相关）
- en: Measurement errors due to noise or instrumental failure
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于噪声或仪器故障导致的测量误差
- en: Data processing errors (data manipulation or mutations due to coding errors)
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据处理错误（由于编码错误导致的数据操作或突变）
- en: Sampling errors (extracting or mixing data from wrong or various sources)
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 抽样误差（从错误或各种来源提取或混合数据）
- en: It is impossible to pinpoint one universal method for outlier detection. Here,
    we will show you some simple tricks for numeric data using standard statistical
    tests.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 对于异常值检测，不可能找到一个通用的方法。在这里，我们将向您展示一些使用标准统计测试对数值数据进行的一些简单技巧。
- en: 'Box plots may show unusual values. We can corrupt two sales values by assigning
    negatives, as follows:'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 箱线图可能显示异常值。我们可以通过分配负值来破坏两个销售值，如下所示：
- en: '[PRE46]'
  id: totrans-384
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'To plot the box plot, use the following code:'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 要绘制箱线图，请使用以下代码：
- en: '[PRE47]'
  id: totrans-386
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'The output (which will vary with each run) is as follows:'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 输出（每次运行都会变化）如下：
- en: '![Figure 4.39: Box plot of sales and profit'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.39：销售和利润的箱线图'
- en: '](img/B15780_04_39.jpg)'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15780_04_39.jpg)'
- en: 'Figure 4.39: Box plot of sales and profit'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.39：销售和利润的箱线图
- en: We can create simple box plots to check for any unusual/nonsensical values.
    For example, in the preceding example, we intentionally corrupted two sales values
    so that they were negative, and they were readily caught in a box plot.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以创建简单的箱线图来检查任何异常或不合逻辑的值。例如，在上面的例子中，我们故意破坏了两个销售值，使它们变为负数，它们在箱线图中很容易被发现。
- en: Note that profit may be negative, so those negative points are generally not
    suspicious. But sales cannot be negative in general, so they are detected as outliers.
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，利润可能是负数，所以这些负点通常不是可疑的。但一般来说，销售额不能是负数，所以它们被检测为异常值。
- en: 'We can create a distribution of a numerical quantity and check for values that
    lie at the extreme end to see if they are truly part of the data or outlier. For
    example, if a distribution is almost normal, then any value more than four or
    five standard deviations away may be a suspect:'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以创建一个数值量的分布，并检查位于极端值处的值，以查看它们是否真正是数据的一部分或异常值。例如，如果分布几乎呈正态分布，那么任何超过四个或五个标准差之外的值可能是有问题的：
- en: '![Figure 4.40: Value away from the main outliers'
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.40：远离主要异常值的价值'
- en: '](img/B15780_04_40.jpg)'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15780_04_40.jpg)'
- en: 'Figure 4.40: Value away from the main outliers'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.40：远离主要异常值的价值
- en: Concatenating, Merging, and Joining
  id: totrans-397
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 连接、合并和连接
- en: Merging and joining tables or datasets are highly common operations in the day-to-day
    job of a data wrangling professional. These operations are akin to the `JOIN`
    query in SQL for relational database tables. Often, the key data is present in
    multiple tables, and those records need to be brought into one combined table
    that matches on that common key. This is an extremely common operation in any
    type of sales or transactional data, and therefore must be mastered by a data
    wrangler. The `pandas` library offers nice and intuitive built-in methods to perform
    various types of `JOIN` queries involving multiple DataFrame objects.
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 合并和连接表或数据集是数据整理专业人士日常工作中非常常见的操作。这些操作类似于关系数据库表中的 `JOIN` 查询。通常，关键数据存在于多个表中，这些记录需要被合并到一个匹配该公共键的单一表中。这在任何类型的销售或交易数据中都是一种极其常见的操作，因此数据整理者必须掌握。`pandas`
    库提供了执行涉及多个 DataFrame 对象的各种类型 `JOIN` 查询的便捷且直观的内置方法。
- en: 'Exercise 4.07: Concatenation in Datasets'
  id: totrans-399
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 4.07：数据集的连接
- en: In this exercise, we will concatenate DataFrames along various axes (rows or columns).
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将沿着各个轴（行或列）连接 DataFrames。
- en: Note
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'The `superstore` dataset file can be found here: [https://packt.live/3dcVnMs](https://packt.live/3dcVnMs).'
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: '`superstore` 数据集文件可以在以下位置找到：[https://packt.live/3dcVnMs](https://packt.live/3dcVnMs)。'
- en: 'This is a very useful operation as it allows you to grow a DataFrame as the
    new data comes in or new feature columns need to be inserted into the table. To
    do so, let''s go through the following steps:'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个非常有用的操作，因为它允许你在新数据到来或需要将新特征列插入表中时扩展 DataFrame。为此，让我们按以下步骤进行：
- en: 'Read the Excel file from GitHub by using the `read_excel` method in `pandas`:'
  id: totrans-404
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `pandas` 中的 `read_excel` 方法从 GitHub 读取 Excel 文件：
- en: '[PRE48]'
  id: totrans-405
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: Note
  id: totrans-406
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: The highlighted path must be changed based on the location of the file on your
    system.
  id: totrans-407
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 高亮显示的路径必须根据文件在您系统中的位置进行更改。
- en: 'The output (partially shown) will be as follows:'
  id: totrans-408
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出（部分显示）将如下所示：
- en: '![Figure 4.41: Partial output of the DataFrame'
  id: totrans-409
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.41：DataFrame 的部分输出'
- en: '](img/B15780_04_41.jpg)'
  id: totrans-410
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15780_04_41.jpg)'
- en: 'Figure 4.41: Partial output of the DataFrame'
  id: totrans-411
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.41：DataFrame 的部分输出
- en: 'Sample `4` records each to create three DataFrames at random from the original
    sales dataset we are working with:'
  id: totrans-412
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从我们正在处理的原始销售数据集中随机创建三个 DataFrame，每个样本包含 4 条记录：
- en: '[PRE49]'
  id: totrans-413
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Create a combined DataFrame with all the rows concatenated by using the following
    code:'
  id: totrans-414
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下代码创建一个包含所有行连接的合并 DataFrame：
- en: '[PRE50]'
  id: totrans-415
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'The output (partially shown) is as follows:'
  id: totrans-416
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出（部分显示）如下：
- en: '![Figure 4.42: Partial output after concatenating the DataFrames'
  id: totrans-417
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.42：连接 DataFrame 后的部分输出]'
- en: '](img/B15780_04_42.jpg)'
  id: totrans-418
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![img/B15780_04_42.jpg]'
- en: 'Figure 4.42: Partial output after concatenating the DataFrames'
  id: totrans-419
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.42：连接 DataFrame 后的部分输出
- en: As you can see, concatenation will vertically combine multiple DataFrames. You
    can also try concatenating along the columns, although that does not make any
    practical sense for this particular example. However, `pandas` fills in the unavailable
    values with `NaN` for that operation.
  id: totrans-420
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如你所见，连接将垂直组合多个 DataFrame。你也可以尝试按列连接，尽管对于这个特定的例子来说，这没有任何实际意义。然而，`pandas` 在该操作中用
    `NaN` 填充不可用的值。
- en: Note
  id: totrans-421
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: The outputs you get will vary from the ones shown in this exercise.
  id: totrans-422
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你得到的输出将与本练习中显示的输出不同。
- en: 'Create a combined DataFrame with all the columns concatenated by using the
    following code:'
  id: totrans-423
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下代码创建一个包含所有列连接的合并 DataFrame：
- en: '[PRE51]'
  id: totrans-424
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'The output (partially shown) is as follows:'
  id: totrans-425
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出（部分显示）如下：
- en: '![Figure 4.43: Partial output after concatenating the DataFrames'
  id: totrans-426
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.43：连接 DataFrame 后的部分输出]'
- en: '](img/B15780_04_43.jpg)'
  id: totrans-427
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![img/B15780_04_43.jpg]'
- en: 'Figure 4.43: Partial output after concatenating the DataFrames'
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.43：连接 DataFrame 后的部分输出
- en: As we can observe, the cells in the dataset that do not contain any values are
    replaced with `NaN` values.
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，数据集中不包含任何值的单元格被替换为 `NaN` 值。
- en: Note
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/3epn5aB](https://packt.live/3epn5aB).
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参阅 [https://packt.live/3epn5aB](https://packt.live/3epn5aB)。
- en: You can also run this example online at [https://packt.live/3edUPrh](https://packt.live/3edUPrh).
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以在 [https://packt.live/3edUPrh](https://packt.live/3edUPrh) 上在线运行此示例。
- en: Merging by a Common Key
  id: totrans-433
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过公共键合并
- en: Merging by a common key is an extremely common operation for data tables as
    it allows you to rationalize multiple sources of data in one master database –
    that is, if they have some common features/keys.
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 通过公共键合并是数据表的一个极其常见的操作，因为它允许你在主数据库中合理化多个数据源 – 即，如果它们有一些公共特征/键。
- en: 'When joining and merging two DataFrames, we use two separate types: **inner**
    and **outer {left|right}**. Let''s take a look at them:'
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: 在连接和合并两个 DataFrame 时，我们使用两种不同的类型：**内部**和**外部 {左|右}**。让我们来看看它们：
- en: '**Inner**: A combining method that uses a column or key to be compared on each
    dataset. Rows that share the same column or key will be present after the join.'
  id: totrans-436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**内部**：一种使用列或键进行比较的合并方法。在合并后，具有相同列或键的行将存在。'
- en: '**Outer**: A way to combine datasets such as inner, but all data on the right
    or left (depending on which is chosen) is kept, and matching data from the opposite
    side is combined.'
  id: totrans-437
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**外部**：一种类似于内部合并数据集的方法，但保留右侧或左侧（取决于选择哪一侧）的所有数据，并将来自另一侧的匹配数据合并。'
- en: This is often the first step in building a large database for machine learning
    tasks where daily incoming data may be put into separate tables. However, at the
    end of the day, the most recent table needs to be merged with the master data
    table so that it can be fed into the backend machine learning server, which will
    then update the model and its prediction capacity. Merge is a way to combine DataFrames
    vertically, using a column to compare on. The functionality of merge and join
    are very similar; their capabilities are the same.
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: 这通常是构建用于机器学习任务的大型数据库的第一步，其中每日传入的数据可能被放入单独的表中。然而，最终，最新的表需要与主数据表合并，以便它可以被输入到后端机器学习服务器，然后更新模型及其预测能力。合并是一种通过列比较来垂直组合
    DataFrame 的方法。合并和连接的功能非常相似；它们的能力相同。
- en: 'Exercise 4.08: Merging by a Common Key'
  id: totrans-439
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 4.08：通过公共键合并
- en: 'In this exercise, we''ll create two DataFrames with the `Customer Name` common
    key from the Superstore dataset. Then, we will use the inner and outer joins to
    merge or combine these DataFrames. To do so, let''s go through the following steps:'
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将使用来自 Superstore 数据集的“客户名称”公共键创建两个 DataFrame。然后，我们将使用内部和外部连接来合并或组合这些
    DataFrame。为此，让我们按照以下步骤进行：
- en: Note
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'The Superstore file can be found here: [https://packt.live/3dcVnMs](https://packt.live/3dcVnMs).'
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: Superstore 文件可以在以下位置找到：[https://packt.live/3dcVnMs](https://packt.live/3dcVnMs)。
- en: 'Import the necessary Python libraries and read the Excel file from GitHub by
    using the `read_excel` method in `pandas`:'
  id: totrans-443
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入必要的 Python 库，并使用 `pandas` 中的 `read_excel` 方法从 GitHub 读取 Excel 文件：
- en: '[PRE52]'
  id: totrans-444
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Create the `df1` DataFrame with the `Customer Name` common key:'
  id: totrans-445
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `Customer Name` 公共键创建 `df1` DataFrame：
- en: '[PRE53]'
  id: totrans-446
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'The output of the first DataFrame is as follows:'
  id: totrans-447
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第一个 DataFrame 的输出结果如下：
- en: '![Figure 4.45: Entries in table df_1'
  id: totrans-448
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.45：表 df_1 的条目'
- en: '](img/B15780_04_45.jpg)'
  id: totrans-449
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B15780_04_45.jpg)'
- en: 'Figure 4.45: Entries in table df_1'
  id: totrans-450
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.45：表 df_1 的条目
- en: 'Create the second DataFrame, `df2`, with the `Customer Name` common key, as follows:'
  id: totrans-451
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下方式创建第二个 DataFrame，`df2`，并带有`Customer Name`公共键：
- en: '[PRE54]'
  id: totrans-452
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'The output is as follows:'
  id: totrans-453
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 4.46: Entries in table df_2'
  id: totrans-454
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.46：表 df_2 的条目'
- en: '](img/B15780_04_46.jpg)'
  id: totrans-455
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B15780_04_46.jpg)'
- en: 'Figure 4.46: Entries in table df_2'
  id: totrans-456
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.46：表 df_2 的条目
- en: 'Join these two tables with an inner join by using the following command:'
  id: totrans-457
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令通过内连接将这两个表连接起来：
- en: '[PRE55]'
  id: totrans-458
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'The output is as follows:'
  id: totrans-459
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 4.47: Inner join on table df_1 and table df_2'
  id: totrans-460
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.47：在表 df_1 和表 df_2 上进行内连接'
- en: '](img/B15780_04_47.jpg)'
  id: totrans-461
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B15780_04_47.jpg)'
- en: 'Figure 4.47: Inner join on table df_1 and table df_2'
  id: totrans-462
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.47：在表 df_1 和表 df_2 上进行内连接
- en: 'Drop the duplicates by using the following command:'
  id: totrans-463
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令删除重复项：
- en: '[PRE56]'
  id: totrans-464
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'The output is as follows:'
  id: totrans-465
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 4.48: Inner join on table df_1 and table df_2 after dropping the duplicates'
  id: totrans-466
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.48：删除重复项后，在表 df_1 和表 df_2 上进行内连接'
- en: '](img/B15780_04_48.jpg)'
  id: totrans-467
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B15780_04_48.jpg)'
- en: 'Figure 4.48: Inner join on table df_1 and table df_2 after dropping the duplicates'
  id: totrans-468
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.48：删除重复项后，在表 df_1 和表 df_2 上进行内连接
- en: 'Extract another small table called `df_3` to show the concept of an outer join:'
  id: totrans-469
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提取另一个名为 `df_3` 的小表来展示外连接的概念：
- en: '[PRE57]'
  id: totrans-470
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'The output is as follows:'
  id: totrans-471
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 4.49: Creating table df_3'
  id: totrans-472
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B15780_04_49.jpg)'
- en: '](img/B15780_04_49.jpg)'
  id: totrans-473
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B15780_04_49.jpg)'
- en: 'Figure 4.49: Creating table df_3'
  id: totrans-474
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.49：创建表 df_3
- en: 'Perform an inner join on `df_1` and `df_3` by using the following command:'
  id: totrans-475
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令通过内连接在 `df_1` 和 `df_3` 上执行操作：
- en: '[PRE58]'
  id: totrans-476
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'The output is as follows:'
  id: totrans-477
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 4.50: Merging table df_1 and table df_3 and dropping duplicates'
  id: totrans-478
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.50：合并表 df_1 和表 df_3 并删除重复项'
- en: '](img/B15780_04_50.jpg)'
  id: totrans-479
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B15780_04_50.jpg)'
- en: 'Figure 4.50: Merging table df_1 and table df_3 and dropping duplicates'
  id: totrans-480
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.50：合并表 df_1 和表 df_3 并删除重复项
- en: 'Perform an outer join on `df_1` and `df_3` by using the following command:'
  id: totrans-481
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令通过外连接在 `df_1` 和 `df_3` 上执行操作：
- en: '[PRE59]'
  id: totrans-482
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'The output is as follows:'
  id: totrans-483
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 4.51: Outer join on table df_1 and table df_3 and dropping the duplicates'
  id: totrans-484
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.51：在表 df_1 和表 df_3 上进行外连接并删除重复项'
- en: '](img/B15780_04_51.jpg)'
  id: totrans-485
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片](img/B15780_04_51.jpg)'
- en: 'Figure 4.51: Outer join on table df_1 and table df_3 and dropping the duplicates'
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.51：在表 df_1 和表 df_3 上进行外连接并删除重复项
- en: Notice how some `NaN` and `NaT` values are inserted automatically because no
    corresponding entries could be found for those records, as those are the entries
    with unique customer names from their respective tables. `NaT` represents a `Not
    a Time` object, as the objects in the `Ship Date` column are timestamped objects.
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，由于找不到与这些记录对应的条目，因此自动插入了一些 `NaN` 和 `NaT` 值，这些条目来自各自表中的唯一客户名称。`NaT` 代表 `Not
    a Time` 对象，因为 `Ship Date` 列中的对象是时间戳对象。
- en: Note
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/2Y8G5UW](https://packt.live/2Y8G5UW).
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参阅[https://packt.live/2Y8G5UW](https://packt.live/2Y8G5UW)。
- en: You can also run this example online at [https://packt.live/30RNUA4](https://packt.live/30RNUA4).
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以在[https://packt.live/30RNUA4](https://packt.live/30RNUA4)上在线运行此示例。
- en: With this, we have gone over how to use the `merge` method to do inner and outer joins.
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这种方式，我们已经介绍了如何使用 `merge` 方法进行内连接和外连接。
- en: The join Method
  id: totrans-492
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 连接方法
- en: 'Joining is performed based on **index keys** and is done by combining the columns
    of two potentially differently indexed DataFrames into a single one. It offers
    a faster way to accomplish merging by row indices. This is useful if the records
    in different tables are indexed differently but represent the same inherent data
    and you want to merge them into a single table:'
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: 根据索引键进行连接，通过将两个可能具有不同索引的 DataFrame 的列组合成一个单一的数据帧来完成。这提供了一种基于行索引合并数据帧的更快方式。如果不同表中的记录索引不同但代表相同的基本数据，并且您希望将它们合并到一个表中，这很有用：
- en: 'Exercise 4.09: The join Method'
  id: totrans-494
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 4.09：连接方法
- en: In this exercise, we will create two DataFrames and perform the different kind
    of joins on these DataFrames.
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将创建两个 DataFrame 并在这些 DataFrame 上执行不同类型的连接。
- en: Note
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'The Superstore file can be found here: [https://packt.live/3dcVnMs](https://packt.live/3dcVnMs).'
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: 超市文件可在此处找到：[https://packt.live/3dcVnMs](https://packt.live/3dcVnMs)。
- en: 'To complete this exercise, perform the following steps:'
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: 完成此练习，请执行以下步骤：
- en: 'Import the Python libraries and load the file from GitHub by using the `read_excel`
    method in `pandas`:'
  id: totrans-499
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`pandas`的`read_excel`方法导入Python库并从GitHub加载文件：
- en: '[PRE60]'
  id: totrans-500
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: Note
  id: totrans-501
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: The highlighted path must be changed based on the location of the file on your
    system.
  id: totrans-502
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 高亮路径必须根据您系统上文件的位置进行更改。
- en: 'The partial output of the code is as follows:'
  id: totrans-503
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 代码的部分输出如下：
- en: '![Figure 4.52: Partial output of the DataFrame'
  id: totrans-504
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图4.52：DataFrame的部分输出'
- en: '](img/B15780_04_52.jpg)'
  id: totrans-505
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15780_04_52.jpg)'
- en: 'Figure 4.52: Partial output of the DataFrame'
  id: totrans-506
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图4.52：DataFrame的部分输出
- en: 'Create `df1` with `Customer Name` as the index by using the following command:'
  id: totrans-507
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令创建以“客户名称”为索引的`df1`：
- en: '[PRE61]'
  id: totrans-508
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'The output is as follows:'
  id: totrans-509
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.53: DataFrame df_1'
  id: totrans-510
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图4.53：DataFrame df_1'
- en: '](img/B15780_04_53.jpg)'
  id: totrans-511
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15780_04_53.jpg)'
- en: 'Figure 4.53: DataFrame df_1'
  id: totrans-512
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图4.53：DataFrame df_1
- en: 'Create `df2` with `Customer Name` as the index by using the following command:'
  id: totrans-513
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令创建以“客户名称”为索引的`df2`：
- en: '[PRE62]'
  id: totrans-514
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'The output is as follows:'
  id: totrans-515
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.54: DataFrame df_2'
  id: totrans-516
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图4.54：DataFrame df_2'
- en: '](img/B15780_04_54.jpg)'
  id: totrans-517
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15780_04_54.jpg)'
- en: 'Figure 4.54: DataFrame df_2'
  id: totrans-518
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图4.54：DataFrame df_2
- en: 'Perform a left join on `df_1` and `df_2` by using the following command:'
  id: totrans-519
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令通过`df_1`和`df_2`执行左连接：
- en: '[PRE63]'
  id: totrans-520
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'The output is as follows:'
  id: totrans-521
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.55: Left join on table df_1 and table df_2 after dropping the duplicates'
  id: totrans-522
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图4.55：删除重复项后df_1和df_2的左连接'
- en: '](img/B15780_04_55.jpg)'
  id: totrans-523
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15780_04_55.jpg)'
- en: 'Figure 4.55: Left join on table df_1 and table df_2 after dropping the duplicates'
  id: totrans-524
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图4.55：删除重复项后df_1和df_2的左连接
- en: 'Perform a right join on `df_1` and `df_2` by using the following command:'
  id: totrans-525
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令通过`df_1`和`df_2`执行右连接：
- en: '[PRE64]'
  id: totrans-526
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'The output is as follows:'
  id: totrans-527
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.56: Right join on table df_1 and table df_2 after dropping the duplicates'
  id: totrans-528
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图4.56：删除重复项后df_1和df_2的右连接'
- en: '](img/B15780_04_56.jpg)'
  id: totrans-529
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15780_04_56.jpg)'
- en: 'Figure 4.56: Right join on table df_1 and table df_2 after dropping the duplicates'
  id: totrans-530
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图4.56：删除重复项后df_1和df_2的右连接
- en: 'Perform an inner join on `df_1` and `df_2` by using the following command:'
  id: totrans-531
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令通过`df_1`和`df_2`执行内部连接：
- en: '[PRE65]'
  id: totrans-532
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'The output is as follows:'
  id: totrans-533
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.57: Inner join on table df_1 and table df_2 after dropping the duplicates'
  id: totrans-534
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图4.57：删除重复项后df_1和df_2的内部连接'
- en: '](img/B15780_04_57.jpg)'
  id: totrans-535
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15780_04_57.jpg)'
- en: 'Figure 4.57: Inner join on table df_1 and table df_2 after dropping the duplicates'
  id: totrans-536
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图4.57：删除重复项后df_1和df_2的内部连接
- en: 'Perform an outer join on `df_1` and `df_2` by using the following command:'
  id: totrans-537
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令通过`df_1`和`df_2`执行外部连接：
- en: '[PRE66]'
  id: totrans-538
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'The output is as follows:'
  id: totrans-539
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.58: Outer join on table df_1 and table df_2 after dropping the duplicates'
  id: totrans-540
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图4.58：删除重复项后df_1和df_2的外部连接'
- en: '](img/B15780_04_58.jpg)'
  id: totrans-541
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15780_04_58.jpg)'
- en: 'Figure 4.58: Outer join on table df_1 and table df_2 after dropping the duplicates'
  id: totrans-542
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.58：删除重复项后df_1和df_2的外部连接
- en: Note
  id: totrans-543
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/30S9nZH](https://packt.live/30S9nZH).
  id: totrans-544
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参阅[https://packt.live/30S9nZH](https://packt.live/30S9nZH)。
- en: You can also run this example online at [https://packt.live/2NbDweg](https://packt.live/2NbDweg).
  id: totrans-545
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以在此处在线运行此示例：[https://packt.live/2NbDweg](https://packt.live/2NbDweg)。
- en: We have now gone through the basic functionality of `pandas` DataFrame joining.
    We used inner and out joining and showed you how we can use indexes to perform
    a join and how it can help in analysis.
  id: totrans-546
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经了解了`pandas` DataFrame连接的基本功能。我们使用了内部和外部连接，并展示了如何使用索引来执行连接以及它如何有助于分析。
- en: Useful Methods of Pandas
  id: totrans-547
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Pandas的有用方法
- en: In this section, we will discuss some small utility functions that are offered
    by `pandas` so that we can work efficiently with DataFrames. They don't fall under
    any particular group of functions, so they are mentioned here under the Miscellaneous
    category. Let's discuss these miscellaneous methods in detail.
  id: totrans-548
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论`pandas`提供的一些小型实用函数，以便我们能够高效地与DataFrame一起工作。它们不属于任何特定的函数组，因此在这里在杂项类别下提及。让我们详细讨论这些杂项方法。
- en: Randomized Sampling
  id: totrans-549
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 随机抽样
- en: In this section, we will discuss random sampling data from our DataFrames. This
    is a very common task in a variety of pipelines, one of which is machine learning.
    Sampling is often used in machine learning data-wrangling pipelines when choosing
    which data to train and which data to test against. Sampling a random fraction
    of a big DataFrame is often very useful so that we can practice other methods
    on them and test our ideas. If you have a database table of 1 million records,
    then it is not computationally effective to run your test scripts on the full
    table.
  id: totrans-550
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论从我们的 DataFrames 中随机采样数据。这在各种管道中是一个非常常见的任务，其中之一是机器学习。在机器学习数据整理管道中选择要训练的数据和要测试的数据时，采样通常被使用。从大
    DataFrame 中随机采样一个随机分数通常非常有用，这样我们就可以在它们上练习其他方法并测试我们的想法。如果你有一个包含 100 万条记录的数据库表，那么在完整表上运行你的测试脚本可能不是计算上有效的。
- en: However, you may also not want to extract only the first 100 elements as the
    data may have been sorted by a particular key and you may get an uninteresting
    table back, which may not represent the full statistical diversity of the parent
    database.
  id: totrans-551
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，你可能也不希望只提取前 100 个元素，因为数据可能已经根据某个特定的键排序，你可能会得到一个不有趣的表格，这可能无法代表父数据库的完整统计多样性。
- en: In these situations, the `sample` method comes in super handy so that we can
    randomly choose a controlled fraction of the DataFrame.
  id: totrans-552
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些情况下，`sample` 方法非常有用，这样我们就可以随机选择 DataFrame 的一个受控分数。
- en: 'Exercise 4.10: Randomized Sampling'
  id: totrans-553
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 4.10：随机采样
- en: 'In this exercise, we are going to randomly take five samples from the Superstore
    dataset and calculate a definite fraction of the data to be sampled. To do so,
    let''s go through the following steps:'
  id: totrans-554
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将从 Superstore 数据集中随机抽取五个样本，并计算要采样的数据的确切分数。为此，让我们按照以下步骤进行：
- en: Note
  id: totrans-555
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'The Superstore file can be found here: [https://packt.live/3dcVnMs](https://packt.live/3dcVnMs).'
  id: totrans-556
  prefs: []
  type: TYPE_NORMAL
  zh: Superstore 文件可以在以下位置找到：[https://packt.live/3dcVnMs](https://packt.live/3dcVnMs)。
- en: 'Import the necessary Python modules and read them from GitHub by using the
    `read_excel` method in `pandas`:'
  id: totrans-557
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入必要的 Python 模块，并使用 `pandas` 中的 `read_excel` 方法从 GitHub 读取它们：
- en: '[PRE67]'
  id: totrans-558
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE67]'
- en: Note
  id: totrans-559
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: The highlighted path must be changed based on the location of the file on your
    system.
  id: totrans-560
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 高亮显示的路径必须根据你系统上文件的位置进行更改。
- en: 'The partial output will be:'
  id: totrans-561
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 部分输出将如下：
- en: '![Figure 4.59: Partial output of the DataFrame'
  id: totrans-562
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.59：DataFrame 的部分输出'
- en: '](img/B15780_04_59.jpg)'
  id: totrans-563
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片 B15780_04_59.jpg](img/B15780_04_59.jpg)'
- en: 'Figure 4.59: Partial output of the DataFrame'
  id: totrans-564
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.59：DataFrame 的部分输出'
- en: 'Specify the number of samples that we require from the DataFrame by using the
    following command:'
  id: totrans-565
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令指定从 DataFrame 中需要的样本数量：
- en: '[PRE68]'
  id: totrans-566
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'The random output (partially shown) is as follows:'
  id: totrans-567
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 随机输出（部分显示）如下：
- en: '![Figure 4.60: DataFrame with five samples'
  id: totrans-568
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.60：包含五个样本的 DataFrame'
- en: '](img/B15780_04_60.jpg)'
  id: totrans-569
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片 B15780_04_60.jpg](img/B15780_04_60.jpg)'
- en: 'Figure 4.60: DataFrame with five samples'
  id: totrans-570
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.60：包含五个样本的 DataFrame
- en: Note
  id: totrans-571
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: The outputs you get will vary from the ones shown in this exercise.
  id: totrans-572
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你得到的结果将与本练习中显示的不同。
- en: 'Specify a definite fraction (percentage) of the data to be sampled by using
    the following command:'
  id: totrans-573
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令指定要采样的数据的确切分数（百分比）：
- en: '[PRE69]'
  id: totrans-574
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'The output is as follows:'
  id: totrans-575
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.61: Partial output of a DataFrame with 0.1% data sampled'
  id: totrans-576
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.61：采样 0.1% 数据的 DataFrame 部分输出'
- en: '](img/B15780_04_61.jpg)'
  id: totrans-577
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片 B15780_04_61.jpg](img/B15780_04_61.jpg)'
- en: 'Figure 4.61: Partial output of a DataFrame with 0.1% data sampled'
  id: totrans-578
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.61：采样 0.1% 数据的 DataFrame 部分输出
- en: You can also choose if sampling is done with replacement, that is, whether the
    same record can be chosen more than once. The default `replace` choice is `FALSE`,
    that is, no repetition and sampling will try to choose new elements only.
  id: totrans-579
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你还可以选择是否进行带替换的采样，即是否可以选择相同的记录多次。默认的 `replace` 选择是 `FALSE`，即无重复，采样将尝试只选择新元素。
- en: 'Choose the sampling by using the following command:'
  id: totrans-580
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令选择采样：
- en: '[PRE70]'
  id: totrans-581
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'The output is as follows:'
  id: totrans-582
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.62: DataFrame with 0.1% data sampled and repetition enabled'
  id: totrans-583
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.62：采样 0.1% 数据并启用重复的 DataFrame'
- en: '](img/B15780_04_62.jpg)'
  id: totrans-584
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图片 B15780_04_62.jpg](img/B15780_04_62.jpg)'
- en: 'Figure 4.62: DataFrame with 0.1% data sampled and repetition enabled'
  id: totrans-585
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.62：采样 0.1% 数据并启用重复的 DataFrame'
- en: Here, as you can see, we have encouraged repetitions in the sampled data by
    setting the `replace` parameter to `True`. Therefore, the same elements could
    be chosen again while performing random sampling.
  id: totrans-586
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，正如你所看到的，我们通过将 `replace` 参数设置为 `True` 来鼓励采样数据中的重复。因此，在执行随机采样时，可以选择相同的元素。
- en: Note
  id: totrans-587
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/2N7fWzt](https://packt.live/2N7fWzt).
  id: totrans-588
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参阅 [https://packt.live/2N7fWzt](https://packt.live/2N7fWzt)。
- en: You can also run this example online at [https://packt.live/2YLTt0f](https://packt.live/2YLTt0f).
  id: totrans-589
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以在 [https://packt.live/2YLTt0f](https://packt.live/2YLTt0f) 上在线运行此示例。
- en: The value_counts Method
  id: totrans-590
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '`value_counts` 方法'
- en: We discussed the `unique` method previously, which finds and counts the unique
    records from a DataFrame. Another useful function in a similar vein is `value_counts`.
    This function returns an object containing counts of unique values. In the object
    that is returned, the first element is the most frequently used object. The elements
    are arranged in descending order.
  id: totrans-591
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前讨论了 `unique` 方法，该方法从 DataFrame 中查找并计数唯一记录。在类似的方法中，另一个有用的函数是 `value_counts`。此函数返回一个包含唯一值计数的对象。在返回的对象中，第一个元素是最常用的对象。元素按降序排列。
- en: 'Let''s consider a practical application of this method to illustrate its utility.
    Suppose your manager asks you to list the top 10 customers from the big sales
    database that you have. So, the business question is: which 10 customers'' names
    occur the most frequently in the sales table? You can achieve this with a SQL
    query if the data is in an RDBMS, but in pandas, this can be done by using one
    simple function:'
  id: totrans-592
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑这个方法的一个实际应用来展示它的实用性。假设你的经理要求你列出大销售数据库中的前 10 位客户。所以，业务问题是：哪些 10 位客户的姓名在销售表中出现频率最高？如果数据在关系型数据库管理系统（RDBMS）中，你可以使用
    SQL 查询来实现这一点，但在 pandas 中，可以通过使用一个简单的函数来完成：
- en: '[PRE71]'
  id: totrans-593
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'The output is as follows:'
  id: totrans-594
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.63: List of top 10 customers'
  id: totrans-595
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 4.63: Top 10 customers list](img/B15780_04_63.jpg)'
- en: '](img/B15780_04_63.jpg)'
  id: totrans-596
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B15780_04_63.jpg](img/B15780_04_63.jpg)'
- en: 'Figure 4.63: List of top 10 customers'
  id: totrans-597
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.63：前 10 位客户列表
- en: The `value_counts` method returns a series of counts of all unique customer
    names sorted by the frequency of the count. By asking for only the first 10 elements
    of that list, this code returns a series of the most frequently occurring top
    10 customer names.
  id: totrans-598
  prefs: []
  type: TYPE_NORMAL
  zh: '`value_counts` 方法返回一个按计数频率排序的所有唯一客户名称计数的序列。通过只请求该列表的前 10 个元素，此代码返回了一个包含出现频率最高的前
    10 位客户名称的序列。'
- en: Pivot Table Functionality
  id: totrans-599
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 交叉表功能
- en: Similar to group by, pandas also offer pivot table functionality, which works
    the same as a Pivot Table in spreadsheet programs such as MS Excel. For example,
    in this sales database, you want to know the average sales, profit, and quantity
    sold by Region and State (two levels of index).
  id: totrans-600
  prefs: []
  type: TYPE_NORMAL
  zh: 与分组类似，pandas 还提供了交叉表功能，它的工作方式与电子表格程序（如 MS Excel）中的交叉表相同。例如，在这个销售数据库中，你想知道按地区和州（两个索引级别）的平均销售额、利润和销售数量。
- en: 'We can extract this information by using one simple piece of code (we sample
    100 records first to keep the computation fast and then apply the code):'
  id: totrans-601
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过使用一段简单的代码来提取这些信息（我们首先抽取 100 条记录以保持计算快速，然后应用代码）：
- en: '[PRE72]'
  id: totrans-602
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'The output is as follows (note that your specific output may be different due
    to random sampling):'
  id: totrans-603
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下（请注意，由于随机抽样，你的具体输出可能会有所不同）：
- en: '![Figure 4.64: Sample of 100 records'
  id: totrans-604
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 4.64: Sample of 100 records](img/B15780_04_64.jpg)'
- en: '](img/B15780_04_64.jpg)'
  id: totrans-605
  prefs: []
  type: TYPE_NORMAL
  zh: '![img/B15780_04_64.jpg](img/B15780_04_64.jpg)'
- en: 'Figure 4.64: Sample of 100 records'
  id: totrans-606
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.64：100 条记录的样本
- en: Sorting a table by a particular column is one of the most frequently used operations
    in the daily work of an analyst. Sorting can help you understand your data better
    while presenting it in a specific view of the data. When training a machine learning
    model, the way data is sorted can impact the performance of a model based on the
    sampling that's being done. Not surprisingly, `pandas` provide a simple and intuitive
    method for sorting called the `sort_values` method. We'll practice using this
    in the following exercise.
  id: totrans-607
  prefs: []
  type: TYPE_NORMAL
  zh: 按特定列对表格进行排序是分析师日常工作中最常用的操作之一。排序可以帮助你更好地理解数据，并在特定的数据视图中展示它。在训练机器学习模型时，数据的排序方式可能会影响基于所进行的采样的模型性能。不出所料，`pandas`
    提供了一种简单直观的排序方法，称为 `sort_values` 方法。我们将在下面的练习中练习使用它。
- en: 'Exercise 4.11: Sorting by Column Values – the sort_values Method'
  id: totrans-608
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 4.11：按列值排序 – sort_values 方法
- en: In this exercise, we will take a random sample of `15` records from the Superstore dataset.
  id: totrans-609
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将从超市数据集中随机抽取 `15` 条记录。
- en: Note
  id: totrans-610
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'The Superstore file can be found here: [https://packt.live/3dcVnMs](https://packt.live/3dcVnMs).'
  id: totrans-611
  prefs: []
  type: TYPE_NORMAL
  zh: 超市文件可以在这里找到：[https://packt.live/3dcVnMs](https://packt.live/3dcVnMs)。
- en: 'We will sort the column values in the dataset with respect to column names
    using the `sort_values` method. To do so, let''s go through the following steps:'
  id: totrans-612
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用`sort_values`方法根据列名对数据集中的列值进行排序。为此，让我们按照以下步骤进行：
- en: 'Import the necessary Python modules and read the Excel file from GitHub by
    using the `read_excel` method in `pandas`:'
  id: totrans-613
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入必要的Python模块，并使用`pandas`中的`read_excel`方法从GitHub读取Excel文件：
- en: '[PRE73]'
  id: totrans-614
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE73]'
- en: Note
  id: totrans-615
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: The highlighted path must be changed based on the location of the file on your
    system.
  id: totrans-616
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 高亮路径必须根据文件在您系统中的位置进行更改。
- en: 'The output (partially shown) will be as follows:'
  id: totrans-617
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出（部分显示）将如下：
- en: '![Figure 4.65: Partial output of the DataFrame'
  id: totrans-618
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图4.65：DataFrame的部分输出'
- en: '](img/B15780_04_65.jpg)'
  id: totrans-619
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![img/B15780_04_65.jpg](img/B15780_04_65.jpg)'
- en: 'Figure 4.65: Partial output of the DataFrame'
  id: totrans-620
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图4.65：DataFrame的部分输出
- en: 'Take a random sample of `15` records and then sort by the `Sales` column and
    then by both the `Sales` and `State` columns together:'
  id: totrans-621
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 抽取15条记录的随机样本，然后按`Sales`列排序，然后按`Sales`和`State`列一起排序：
- en: '[PRE74]'
  id: totrans-622
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'The output is as follows:'
  id: totrans-623
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.66: Sample of 15 records'
  id: totrans-624
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图4.66：15条记录的样本'
- en: '](img/B15780_04_66.jpg)'
  id: totrans-625
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![img/B15780_04_66.jpg](img/B15780_04_66.jpg)'
- en: 'Figure 4.66: Sample of 15 records'
  id: totrans-626
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图4.66：15条记录的样本
- en: Note
  id: totrans-627
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: The outputs you get will vary from the ones shown in this exercise.
  id: totrans-628
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您将获得的输出将与本练习中显示的输出不同。
- en: 'Sort the values with respect to `Sales` by using the following command:'
  id: totrans-629
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令按`Sales`排序值：
- en: '[PRE75]'
  id: totrans-630
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'The output is as follows:'
  id: totrans-631
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.67: DataFrame with the Sales value sorted'
  id: totrans-632
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图4.67：按销售值排序的DataFrame'
- en: '](img/B15780_04_67.jpg)'
  id: totrans-633
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![img/B15780_04_67.jpg](img/B15780_04_67.jpg)'
- en: 'Figure 4.67: DataFrame with the Sales value sorted'
  id: totrans-634
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图4.67：按销售值排序的DataFrame
- en: 'Sort the values with respect to `Sales` and `State`:'
  id: totrans-635
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照以下命令按`Sales`和`State`排序值：
- en: '[PRE76]'
  id: totrans-636
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'The output is as follows:'
  id: totrans-637
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.68: DataFrame sorted with respect to Sales and State'
  id: totrans-638
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图4.68：按销售和州排序的DataFrame'
- en: '](img/B15780_04_68.jpg)'
  id: totrans-639
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![img/B15780_04_68.jpg](img/B15780_04_68.jpg)'
- en: 'Figure 4.68: DataFrame sorted with respect to Sales and State'
  id: totrans-640
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.68：按销售和州排序的DataFrame
- en: Note
  id: totrans-641
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/3dcWNXi](https://packt.live/3dcWNXi).
  id: totrans-642
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参阅[https://packt.live/3dcWNXi](https://packt.live/3dcWNXi)。
- en: You can also run this example online at [https://packt.live/30UqwSn](https://packt.live/30UqwSn).
  id: totrans-643
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以在此处在线运行此示例：[https://packt.live/30UqwSn](https://packt.live/30UqwSn)。
- en: The `pandas` library provides great flexibility for working with user-defined
    functions of arbitrary complexity through the `apply` method. Much like the native
    Python `apply` function, this method accepts a user-defined function and additional
    arguments and returns a new column after applying the function on a particular
    column elementwise.
  id: totrans-644
  prefs: []
  type: TYPE_NORMAL
  zh: '`pandas`库通过`apply`方法提供了处理任意复杂度的用户定义函数的巨大灵活性。与原生的Python `apply`函数类似，此方法接受用户定义的函数和额外的参数，并在对特定列的每个元素应用函数后返回一个新列。'
- en: As an example, suppose we want to create a column of categorical features such
    as high/medium/low based on the sales price column. Note that this is a conversion
    from a numeric value into a categorical factor (string) based on certain conditions
    (threshold values of sales).
  id: totrans-645
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设我们想要根据销售价格列创建一个如高/中/低之类的分类特征列。请注意，这是一个基于某些条件（销售阈值）将数值值转换为分类因子（字符串）的过程。
- en: 'Exercise 4.12: Flexibility of User-Defined Functions with the apply Method'
  id: totrans-646
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习4.12：使用apply方法的用户定义函数的灵活性
- en: In this exercise, we will create a user-defined function called `categorize_sales`
    that categorizes Sales data based on price. If the `price` is less than `50`,
    it is classified as `Low`, if the `price` is less than `200`, it is classified
    as `Medium`, or `High` if the `price` doesn't fall under either of these categories.
  id: totrans-647
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将创建一个名为`categorize_sales`的用户定义函数，该函数根据价格对销售数据进行分类。如果`价格`小于`50`，则归类为`低`，如果`价格`小于`200`，则归类为`中`，如果没有落入这两个类别之一，则归类为`高`。
- en: Note
  id: totrans-648
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'The Superstore file can be found here: [https://packt.live/3dcVnMs](https://packt.live/3dcVnMs).'
  id: totrans-649
  prefs: []
  type: TYPE_NORMAL
  zh: Superstore文件可在此处找到：[https://packt.live/3dcVnMs](https://packt.live/3dcVnMs)。
- en: 'We''ll then take 100 random samples from the `superstore` dataset and use the
    `apply` method on the `categorize_sales` function in order to create a new column
    to store the values returned by the function. To do so, perform the following steps:'
  id: totrans-650
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将从`superstore`数据集中抽取100个随机样本，并使用`apply`方法在`categorize_sales`函数上创建一个新列来存储函数返回的值。为此，执行以下步骤：
- en: 'Import the necessary Python modules and read the Excel file from GitHub by
    using the `read_excel` method in `pandas`:'
  id: totrans-651
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`pandas`中的`read_excel`方法导入必要的Python模块并从GitHub读取Excel文件：
- en: '[PRE77]'
  id: totrans-652
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE77]'
- en: Note
  id: totrans-653
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: The highlighted path must be changed based on the location of the file on your
    system.
  id: totrans-654
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 高亮显示的路径必须根据您系统上文件的位置进行更改。
- en: 'The output (partially shown) will be:'
  id: totrans-655
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出（部分显示）将如下：
- en: '![Figure 4.69: Partial output of the DataFrame'
  id: totrans-656
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图4.69：DataFrame的部分输出'
- en: '](img/B15780_04_69.jpg)'
  id: totrans-657
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15780_04_69.jpg)'
- en: 'Figure 4.69: Partial output of the DataFrame'
  id: totrans-658
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图4.69：DataFrame的部分输出
- en: 'Create a user-defined function, as follows:'
  id: totrans-659
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个用户定义的函数，如下所示：
- en: '[PRE78]'
  id: totrans-660
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'Sample `100` records randomly from the database:'
  id: totrans-661
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从数据库中随机抽取`100`条样本记录：
- en: '[PRE79]'
  id: totrans-662
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'The output is as follows:'
  id: totrans-663
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.70: 100 sample records from the database'
  id: totrans-664
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图4.70：数据库中的100个样本记录'
- en: '](img/B15780_04_70.jpg)'
  id: totrans-665
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15780_04_70.jpg)'
- en: 'Figure 4.70: 100 sample records from the database'
  id: totrans-666
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图4.70：数据库中的100个样本记录
- en: Note
  id: totrans-667
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: The outputs you get will vary from the ones shown in this exercise.
  id: totrans-668
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你得到的结果将与本练习中显示的结果不同。
- en: 'Use the `apply` method to apply the categorization function to the `Sales`
    column. We need to create a new column to store the category string values that
    are returned by the function:'
  id: totrans-669
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`apply`方法将分类函数应用于`Sales`列。我们需要创建一个新列来存储函数返回的分类字符串值：
- en: '[PRE80]'
  id: totrans-670
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE80]'
- en: 'The output is as follows:'
  id: totrans-671
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.71: DataFrame with 10 rows after using the apply function on the
    Sales column'
  id: totrans-672
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图4.71：使用apply函数在Sales列上操作后的10行DataFrame'
- en: '](img/B15780_04_71.jpg)'
  id: totrans-673
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15780_04_71.jpg)'
- en: 'Figure 4.71: DataFrame with 10 rows after using the apply function on the Sales
    column'
  id: totrans-674
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图4.71：使用apply函数在Sales列上操作后的10行DataFrame
- en: The `apply` method also works with the built-in native Python functions.
  id: totrans-675
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`apply`方法也可以与内置的Python原生函数一起使用。'
- en: 'For practice, let''s create another column for storing the length of the name
    of the customer. We can do this using the familiar `len` function:'
  id: totrans-676
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了练习，让我们创建另一个列来存储客户名称的长度。我们可以使用熟悉的`len`函数来完成此操作：
- en: '[PRE81]'
  id: totrans-677
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE81]'
- en: 'The output is as follows:'
  id: totrans-678
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.72: DataFrame with a new column'
  id: totrans-679
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图4.72：包含新列的DataFrame'
- en: '](img/B15780_04_72.jpg)'
  id: totrans-680
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15780_04_72.jpg)'
- en: 'Figure 4.72: DataFrame with a new column'
  id: totrans-681
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图4.72：包含新列的DataFrame
- en: Instead of writing out a separate function, we can even insert *lambda expressions*
    directly into the `apply` method for short functions. For example, let's say we
    are promoting our product and want to show the discounted sales price if the original
    price is *> $200*.
  id: totrans-682
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们甚至可以直接将*lambda表达式*插入到`apply`方法中，以缩短函数的编写。例如，假设我们正在推广我们的产品，并且如果原始价格大于* $200*，我们想显示折扣后的销售价格。
- en: 'Use a `lambda` function and the `apply` method to do so:'
  id: totrans-683
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`lambda`函数和`apply`方法来完成：
- en: '[PRE82]'
  id: totrans-684
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE82]'
- en: 'The output is as follows:'
  id: totrans-685
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 4.73: Lambda function'
  id: totrans-686
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图4.73：Lambda函数'
- en: '](img/B15780_04_73.jpg)'
  id: totrans-687
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15780_04_73.jpg)'
- en: 'Figure 4.73: Lambda function'
  id: totrans-688
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.73：Lambda函数
- en: Note
  id: totrans-689
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The lambda function contains a conditional, and a discount is applied to those
    records where the original sales price is `>$200`.
  id: totrans-690
  prefs: []
  type: TYPE_NORMAL
  zh: Lambda函数包含一个条件，并且对原始销售价格大于`>$200`的记录应用折扣。
- en: To access the source code for this specific section, please refer to [https://packt.live/3ddJYwa](https://packt.live/3ddJYwa).
  id: totrans-691
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参阅[https://packt.live/3ddJYwa](https://packt.live/3ddJYwa)。
- en: You can also run this example online at [https://packt.live/3d63D0Y](https://packt.live/3d63D0Y).
  id: totrans-692
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以在[https://packt.live/3d63D0Y](https://packt.live/3d63D0Y)上在线运行此示例。
- en: After going through this exercise, we know how to apply a function to a column
    in a DataFrame. This method is very useful for going beyond the basic functions
    that are present in `pandas`.
  id: totrans-693
  prefs: []
  type: TYPE_NORMAL
  zh: 通过完成这个练习，我们知道了如何将函数应用于DataFrame的列。这种方法对于超越`pandas`中存在的基函数非常有用。
- en: 'Activity 4.01: Working with the Adult Income Dataset (UCI)'
  id: totrans-694
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动四.01：处理成人收入数据集（UCI）
- en: In this activity, we will detect outliers in the Adult Income Dataset from the
    UCI machine learning portal [https://packt.live/2N9lRUU](https://packt.live/2N9lRUU).
  id: totrans-695
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个活动中，我们将从UCI机器学习门户[https://packt.live/2N9lRUU](https://packt.live/2N9lRUU)的成人收入数据集中检测异常值。
- en: You can find a description of the dataset [https://packt.live/2N9lRUU](https://packt.live/2N9lRUU).
    We will use the concepts we've learned throughout this chapter, such as subsetting,
    applying user-defined functions, summary statistics, visualizations, boolean indexing,
    and group by to find a whole group of outliers in a dataset. We will create a
    bar plot to plot this group of outliers. Finally, we will merge two datasets by
    using a common key.
  id: totrans-696
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在[https://packt.live/2N9lRUU](https://packt.live/2N9lRUU)找到数据集的描述。我们将使用本章学到的概念，例如子集、应用用户定义的函数、汇总统计、可视化、布尔索引和按组分组，来在一个数据集中找到整个异常值组。我们将创建一个条形图来绘制这个异常值组。最后，我们将使用公共键合并两个数据集。
- en: 'These are the steps that will help you solve this activity:'
  id: totrans-697
  prefs: []
  type: TYPE_NORMAL
  zh: 这些步骤将帮助您解决这个活动：
- en: Load the necessary libraries.
  id: totrans-698
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载必要的库。
- en: 'Read the adult income dataset from the following URL: [https://packt.live/2N9lRUU](https://packt.live/2N9lRUU).'
  id: totrans-699
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从以下URL读取成人收入数据集：[https://packt.live/2N9lRUU](https://packt.live/2N9lRUU)。
- en: Create a script that will read a text file line by line.
  id: totrans-700
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个脚本，该脚本将逐行读取文本文件。
- en: Add a name of `Income` for the response variable to the dataset.
  id: totrans-701
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将响应变量的名称添加为`Income`到数据集中。
- en: Find the missing values.
  id: totrans-702
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查找缺失值。
- en: Create a DataFrame with only age, education, and occupation by using subsetting.
  id: totrans-703
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过子集创建只包含年龄、教育和职业的DataFrame。
- en: Plot a histogram of age with a bin size of `20`.
  id: totrans-704
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以`20`为区间绘制年龄的直方图。
- en: Create a function to strip the whitespace characters.
  id: totrans-705
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个用于删除空白字符的函数。
- en: Use the `apply` method to apply this function to all the columns with string
    values, create a new column, copy the values from this new column to the old column,
    and drop the new column.
  id: totrans-706
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`apply`方法将此函数应用于所有具有字符串值的列，创建一个新列，将新列的值复制到旧列中，并删除新列。
- en: Find the number of people who are aged between `30` and `50`.
  id: totrans-707
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 找出年龄在`30`到`50`之间的人数。
- en: Group the records based on age and education to find how the mean age is distributed.
  id: totrans-708
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据年龄和教育分组记录，以找出平均年龄的分布情况。
- en: Group by occupation and show the summary statistics of age. Find which profession
    has the oldest workers on average and which profession has its largest share of
    the workforce above the 75th percentile.
  id: totrans-709
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按职业分组并显示年龄的汇总统计。找出平均年龄最大的职业以及在其劳动力中占比最大的75百分位数以上的职业。
- en: Use `subset` and `groupBy` to find the outliers.
  id: totrans-710
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`subset`和`groupBy`来查找异常值。
- en: 'Plot the outlier values on a bar chart. It should look something like this:![Figure
    4.74: Bar plot displaying the outliers'
  id: totrans-711
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在条形图上绘制异常值。它应该看起来像这样：![图4.74：显示异常值的条形图
- en: '](img/B15780_04_74.jpg)'
  id: totrans-712
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15780_04_74.jpg)'
- en: 'Figure 4.74: Bar plot displaying the outliers'
  id: totrans-713
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图4.74：显示异常值的条形图
- en: Merge the two DataFrames using common keys to drop duplicate values.
  id: totrans-714
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用公共键合并两个DataFrame以删除重复值。
- en: 'The output should look like this:'
  id: totrans-715
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出应该看起来像这样：
- en: '![Figure 4.75: Merged DataFrame'
  id: totrans-716
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图4.75：合并后的DataFrame'
- en: '](img/B15780_04_75.jpg)'
  id: totrans-717
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15780_04_75.jpg)'
- en: 'Figure 4.75: Merged DataFrame'
  id: totrans-718
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.75：合并后的DataFrame
- en: Note
  id: totrans-719
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The solution for this activity can be found via [this link](B15780_Solution_Final_RK.xhtml#_idTextAnchor314).
  id: totrans-720
  prefs: []
  type: TYPE_NORMAL
  zh: 本活动的解决方案可以通过[此链接](B15780_Solution_Final_RK.xhtml#_idTextAnchor314)找到。
- en: As you can see, we now have a single DataFrame because we have merged two DataFrames
    into one.
  id: totrans-721
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，我们现在有一个单一的DataFrame，因为我们已经将两个DataFrame合并成了一个。
- en: With that, we conclude this activity and the chapter.
  id: totrans-722
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些，我们就完成了这个活动和本章。
- en: Summary
  id: totrans-723
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we deep-dived into the `pandas` library to learn advanced data
    wrangling techniques. We started with some advanced subsetting and filtering on
    DataFrames and rounded this off by learning about boolean indexing and conditionally
    selecting a subset of data. We also covered how to set and reset the index of
    a DataFrame, especially while initializing.
  id: totrans-724
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们深入研究了`pandas`库，以学习高级数据处理技术。我们从DataFrame的高级子集和过滤开始，通过学习布尔索引和条件选择数据子集来结束。我们还介绍了如何设置和重置DataFrame的索引，尤其是在初始化时。
- en: Next, we learned about a particular topic that has a deep connection with traditional
    relational database systems – the `groupBy` method. Then, we deep-dived into an
    important skill for data wrangling – checking for and handling missing data. We
    showed you how pandas helps in handling missing data using various imputation
    techniques. We also discussed methods for dropping missing values. Furthermore,
    methods and usage examples of concatenation and merging DataFrame objects were
    shown. We saw the `join` method and how it compares to a similar operation in
    SQL.
  id: totrans-725
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们学习了一个与传统的数据库系统有着深刻联系的特定主题——`groupBy`方法。然后，我们深入探讨了数据整理的重要技能——检查和处理缺失数据。我们展示了pandas如何使用各种插补技术来处理缺失数据。我们还讨论了删除缺失值的方法。此外，还展示了连接和合并DataFrame对象的方法和用法示例。我们看到了`join`方法，以及它与SQL中类似操作的比较。
- en: Lastly, miscellaneous useful methods on DataFrames, such as randomized sampling,
    `unique`, `value_count`, `sort_values`, and pivot table functionality were covered.
    We also showed an example of running an arbitrary user-defined function on a DataFrame
    using the `apply` method.
  id: totrans-726
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们涵盖了DataFrame上的各种有用方法，例如随机抽样、`unique`、`value_count`、`sort_values`和交叉表功能。我们还展示了如何使用`apply`方法在DataFrame上运行任意用户定义的函数的示例。
- en: After learning about the basic and advanced data wrangling techniques with the
    `numpy` and `pandas` libraries, the natural question of data acquisition rises.
    In the next chapter, we will show you how to work with a wide variety of data
    sources; that is, you will learn how to read data in tabular format in `pandas`
    from different sources.
  id: totrans-727
  prefs: []
  type: TYPE_NORMAL
  zh: 在学习了使用`numpy`和`pandas`库的基本和高级数据整理技术之后，数据获取的自然问题随之而来。在下一章中，我们将向您展示如何处理各种数据源；也就是说，您将学习如何在`pandas`中从不同的来源读取表格格式的数据。
