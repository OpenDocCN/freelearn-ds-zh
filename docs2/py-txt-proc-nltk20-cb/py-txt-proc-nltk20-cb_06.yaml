- en: Chapter 6. Transforming Chunks and Trees
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第6章：转换块和树
- en: 'In this chapter, we will cover:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖：
- en: Filtering insignificant words
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 过滤不重要的单词
- en: Correcting verb forms
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 纠正动词形式
- en: Swapping verb phrases
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 交换动词短语
- en: Swapping noun cardinals
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 交换名词基数
- en: Swapping infinitive phrases
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 交换不定式短语
- en: Singularizing plural nouns
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使复数名词变为单数
- en: Chaining chunk transformations
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 连接块转换
- en: Converting a chunk tree to text
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将块树转换为文本
- en: Flattening a deep tree
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 展平一个深树
- en: Creating a shallow tree
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个浅树
- en: Converting tree nodes
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 转换树节点
- en: Introduction
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简介
- en: Now that you know how to get chunks/phrases from a sentence, what do you do
    with them? This chapter will show you how to do various transforms on both chunks
    and trees. The chunk transforms are for grammatical correction and rearranging
    phrases without loss of meaning. The tree transforms give you ways to modify and
    flatten deep parse trees.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经知道了如何从句子中获取块/短语，你将如何使用它们？本章将向你展示如何对块和树进行各种转换。块转换用于语法纠正和重新排列短语而不丢失意义。树转换为你提供了修改和展平深层解析树的方法。
- en: The functions detailed in these recipes modify data, as opposed to learning
    from it. That means it's not safe to apply them indiscriminately. A thorough knowledge
    of the data you want to transform, along with a few experiments, should help you
    decide which functions to apply and when.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这些菜谱中详细说明的功能是修改数据，而不是从数据中学习。这意味着不能不加区分地应用它们。对您想要转换的数据有深入的了解，以及一些实验，应该有助于您决定应用哪些函数以及何时应用。
- en: Whenever the term **chunk** is used in this chapter, it could refer to an actual
    chunk extracted by a chunker, or it could simply refer to a short phrase or sentence
    in the form of a list of tagged words. What's important in this chapter is what
    you can do with a chunk, not where it came from.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，当使用术语**chunk**时，它可能指的是由分块器提取的实际块，或者它可能仅仅是指由标记词组成的列表形式的一个短语或句子。本章重要的是你能用块做什么，而不是它从哪里来。
- en: Filtering insignificant words
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 过滤不重要的单词
- en: Many of the most commonly used words are insignificant when it comes to discerning
    the meaning of a phrase. For example, in the phrase "the movie was terrible",
    the most *significant* words are "movie" and "terrible", while "the" and "was"
    are almost useless. You could get the same meaning if you took them out, such
    as "movie terrible" or "terrible movie". Either way, the sentiment is the same.
    In this recipe, we'll learn how to remove the insignificant words, and keep the
    significant ones, by looking at their part-of-speech tags.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 许多最常用的单词在区分短语含义时都是不重要的。例如，在短语“the movie was terrible”中，最**重要**的单词是“movie”和“terrible”，而“the”和“was”几乎毫无用处。如果你把它们去掉，你仍然可以得到相同的意思，比如“movie
    terrible”或“terrible movie”。无论如何，情感都是一样的。在本菜谱中，我们将学习如何通过查看它们的词性标记来移除不重要的单词，并保留重要的单词。
- en: Getting ready
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'First, we need to decide which part-of-speech tags are significant and which
    are not. Looking through the `treebank` corpus for `stopwords` yields the following
    table of insignificant words and tags:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要决定哪些词性标记是重要的，哪些不是。通过查看`treebank`语料库中的`stopwords`得到以下不重要的单词和标记表：
- en: '| Word | Tag |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| Word | Tag |'
- en: '| --- | --- |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| a | DT |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| a | DT |'
- en: '| all | PDT |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| all | PDT |'
- en: '| an | DT |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| an | DT |'
- en: '| and | CC |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| and | CC |'
- en: '| or | CC |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| or | CC |'
- en: '| that | WDT |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| that | WDT |'
- en: '| the | DT |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| the | DT |'
- en: Other than CC, all the tags end with DT. This means we can filter out insignificant
    words by looking at the tag's suffix.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 除了CC之外，所有标记都以DT结尾。这意味着我们可以通过查看标记的后缀来过滤掉不重要的单词。
- en: How to do it...
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到...
- en: In `transforms.py` there is a function called `filter_insignificant()`. It takes
    a single chunk, which should be a list of tagged words, and returns a new chunk
    without any insignificant tagged words. It defaults to filtering out any tags
    that end with DT or CC.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在`transforms.py`中有一个名为`filter_insignificant()`的函数。它接受一个单独的块，该块应是一个标记词的列表，并返回一个不包含任何不标记单词的新块。它默认过滤掉以DT或CC结尾的任何标记。
- en: '[PRE0]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Now we can use it on the part-of-speech tagged version of "the terrible movie".
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以将其应用于“the terrible movie”的词性标记版本。
- en: '[PRE1]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: As you can see, the word "the" is eliminated from the chunk.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，单词“the”已从块中删除。
- en: How it works...
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: '`filter_insignificant()` iterates over the tagged words in the chunk. For each
    tag, it checks if that tag ends with any of the `tag_suffixes`. If it does, then
    the tagged word is skipped. However if the tag is ok, then the tagged word is
    appended to a new good chunk that is returned.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '`filter_insignificant()` 遍历块中的标记词。对于每个标签，它检查该标签是否以任何 `tag_suffixes` 结尾。如果是，则跳过标记词。但如果标签是可接受的，则将标记词追加到返回的新良好块中。'
- en: There's more...
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'The way `filter_insignificant()` is defined, you can pass in your own tag suffixes
    if DT and CC are not enough, or are incorrect for your case. For example, you
    might decide that possessive words and pronouns such as "you", "your", "their",
    and "theirs" are no good but DT and CC words are ok. The tag suffixes would then
    be PRP and PRP$. Following is an example of this function:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 根据 `filter_insignificant()` 的定义，如果你觉得 DT 和 CC 不够，或者对于你的情况不正确，你可以传递自己的标签后缀。例如，你可能会决定所有格词和代词，如
    "you"、"your"、"their" 和 "theirs" 都不好，而 DT 和 CC 词是可接受的。标签后缀将是 PRP 和 PRP$。以下是这个函数的一个示例：
- en: '[PRE2]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Filtering insignificant words can be a good complement to stopword filtering
    for purposes such as search engine indexing, querying, and text classification.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 过滤不重要的词可以作为停止词过滤的良好补充，用于搜索引擎索引、查询和文本分类等目的。
- en: See also
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: This recipe is analogous to the *Filtering stopwords in a tokenized sentence*
    recipe in [Chapter 1](ch01.html "Chapter 1. Tokenizing Text and WordNet Basics"),
    *Tokenizing Text and WordNet Basics*.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这个配方与 [第1章](ch01.html "第1章。文本分词和WordNet基础知识") 中 *Filtering stopwords in a tokenized
    sentence* 配方类似，*Tokenizing Text and WordNet Basics*。
- en: Correcting verb forms
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 修正动词形式
- en: It's fairly common to find incorrect verb forms in real-world language. For
    example, the correct form of "is our children learning?" is "are our children
    learning?". The verb "is" should only be used with singular nouns, while "are"
    is for plural nouns, such as "children". We can correct these mistakes by creating
    verb correction mappings that are used depending on whether there's a plural or
    singular noun in the chunk.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在现实世界的语言中找到错误的动词形式相当常见。例如，"is our children learning?" 的正确形式是 "are our children
    learning?"。动词 "is" 应仅与单数名词一起使用，而 "are" 用于复数名词，如 "children"。我们可以通过创建根据块中是否有复数或单数名词来使用的动词修正映射来纠正这些错误。
- en: Getting ready
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: We first need to define the verb correction mappings in `transforms.py`. We'll
    create two mappings, one for plural to singular, and another for singular to plural.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先需要在 `transforms.py` 中定义动词修正映射。我们将创建两个映射，一个用于复数到单数，另一个用于单数到复数。
- en: '[PRE3]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Each mapping has a tagged verb that maps to another tagged verb. These initial
    mappings cover the basics of mapping, is to are, was to were, and vice versa.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 每个映射都有一个标记动词映射到另一个标记动词。这些初始映射涵盖了映射的基础，包括 is to are，was to were，反之亦然。
- en: How to do it...
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: In `transforms.py` there is a function called `correct_verbs()`. Pass it a chunk
    with incorrect verb forms, and you'll get a corrected chunk back. It uses a helper
    function `first_chunk_index()` to search the chunk for the position of the first
    tagged word where `pred` returns `True`.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `transforms.py` 中有一个名为 `correct_verbs()` 的函数。传递一个包含错误动词形式的块，你将得到一个修正后的块。它使用辅助函数
    `first_chunk_index()` 在块中搜索 `pred` 返回 `True` 的第一个标记词的位置。
- en: '[PRE4]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: When we call it on a part-of-speech tagged "is our children learning" chunk,
    we get back the correct form, "are our children learning".
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在一个部分标记为 "is our children learning" 的块上调用它时，我们得到正确的形式，"are our children learning"。
- en: '[PRE5]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: We can also try this with a singular noun and an incorrect plural verb.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以尝试用单数名词和错误的复数动词。
- en: '[PRE6]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: In this case, "were" becomes "was" because "child" is a singular noun.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，"were" 变为 "was"，因为 "child" 是一个单数名词。
- en: How it works...
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The `correct_verbs()` function starts by looking for a verb in the chunk. If
    no verb is found, the chunk is returned with no changes. Once a verb is found,
    we keep the verb, its tag, and its index in the chunk. Then we look on either
    side of the verb to find the nearest noun, starting on the right, and only looking
    to the left if no noun is found on the right. If no noun is found at all, the
    chunk is returned as is. But if a noun is found, then we lookup the correct verb
    form depending on whether or not the noun is plural.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '`correct_verbs()` 函数首先在块中寻找一个动词。如果没有找到动词，则块保持不变并返回。一旦找到动词，我们就保留动词、其标签和其在块中的索引。然后我们在动词的两侧寻找最近的名词，从右侧开始，如果右侧没有找到名词，则向左查找。如果没有找到任何名词，则块保持原样返回。但如果找到了名词，那么我们将根据名词是否为复数来查找正确的动词形式。'
- en: Recall from [Chapter 4](ch04.html "Chapter 4. Part-of-Speech Tagging"), *Part-of-Speech
    Tagging*, that plural nouns are tagged with NNS, while singular nouns are tagged
    with NN. This means we can check the plurality of a noun by seeing if its tag
    ends with S. Once we get the corrected verb form, it is inserted into the chunk
    to replace the original verb form.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 回忆一下[第4章](ch04.html "第4章。词性标注")中的*词性标注*，复数名词用NNS标注，而单数名词用NN标注。这意味着我们可以通过查看名词的标注是否以S结尾来检查名词的复数性。一旦我们得到修正后的动词形式，它就被插入到块中，以替换原始的动词形式。
- en: To make searching through the chunk easier, we define a function called `first_chunk_index()`.
    It takes a chunk, a `lambda` predicate, the starting index, and a step increment.
    The predicate function is called with each tagged word until it returns `True`.
    If it never returns `True`, then `None` is returned. The starting index defaults
    to zero and the step increment to one. As you'll see in upcoming recipes, we can
    search backwards by overriding `start` and setting `step` to -1\. This small utility
    function will be a key part of subsequent transform functions.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使在块中搜索更容易，我们定义了一个名为`first_chunk_index()`的函数。它接受一个块、一个`lambda`谓词、起始索引和步长增量。谓词函数对每个标注词进行调用，直到它返回`True`。如果它从未返回`True`，则返回`None`。起始索引默认为零，步长增量默认为1。正如你将在接下来的菜谱中看到的，我们可以通过覆盖`start`并设置`step`为-1来向后搜索。这个小的实用函数将是后续转换函数的关键部分。
- en: See also
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: The next four recipes all make use of `first_chunk_index()` to perform chunk
    transformations.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的四个菜谱都使用`first_chunk_index()`来执行块转换。
- en: Swapping verb phrases
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 交换动词短语
- en: Swapping the words around a verb can eliminate the passive voice from particular
    phrases. For example, "the book was great" can be transformed into "the great
    book".
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 交换动词周围的词可以消除特定短语中的被动语态。例如，“the book was great”可以转换为“the great book”。
- en: How to do it...
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到...
- en: In `transforms.py` there is a function called `swap_verb_phrase()`. It swaps
    the right-hand side of the chunk with the left-hand side, using the verb as the
    *pivot* point. It uses the `first_chunk_index()` function defined in the previous
    recipe to find the verb to pivot around.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在`transforms.py`中有一个名为`swap_verb_phrase()`的函数。它使用动词作为*支点*，将块的右侧与左侧交换。它使用前一个菜谱中定义的`first_chunk_index()`函数来找到要围绕其进行转换的动词。
- en: '[PRE7]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Now we can see how it works on the part-of-speech tagged phrase "the book was
    great".
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以看到它如何在词性标注的短语“the book was great”上工作。
- en: '[PRE8]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The result is "great the book". This phrase clearly isn't grammatically correct,
    so read on to learn how to fix it.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是“伟大的书”。这个短语显然在语法上不正确，所以请继续阅读，了解如何修复它。
- en: How it works...
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: Using `first_chunk_index()` from the previous recipe, we start by finding the
    first matching verb that is not a gerund (a word that ends in "ing") tagged with
    VBG. Once we've found the verb, we return the chunk with the right side before
    the left, and remove the verb.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 使用前一个菜谱中的`first_chunk_index()`，我们首先找到第一个匹配的动词，该动词不是现在分词（以“ing”结尾的词）并标注为VBG。一旦我们找到动词，我们就返回带有正确左右顺序的块，并移除动词。
- en: 'The reason we don''t want to pivot around a gerund is that gerunds are commonly
    used to describe nouns, and pivoting around one would remove that description.
    Here''s an example where you can see how not pivoting around a gerund is a good
    thing:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不希望围绕现在分词进行转换的原因是，现在分词通常用来描述名词，围绕一个现在分词进行转换会移除那个描述。以下是一个例子，说明为什么不在现在分词周围进行转换是一个好事：
- en: '[PRE9]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: If we had pivoted around the gerund, the result would be "book is fantastic
    this", and we'd lose the gerund "gripping".
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们围绕现在分词进行转换，结果将是“book is fantastic this”，我们会失去现在分词“gripping”。
- en: There's more...
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: Filtering insignificant words makes the final result more readable. By filtering
    either before or after `swap_verb_phrase()`, we get "fantastic gripping book"
    instead of "fantastic this gripping book".
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 过滤掉不重要的词可以使最终结果更易读。通过在`swap_verb_phrase()`之前或之后过滤，我们得到“精彩的扣人心弦的书”，而不是“精彩的这本书扣人心弦”。
- en: '[PRE10]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Either way, we get a shorter grammatical chunk with no loss of meaning.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 不论哪种方式，我们都能得到一个没有意义损失但更短的语法块。
- en: See also
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: The previous recipe defines `first_chunk_index()`, which is used to find the
    verb in the chunk.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 前一个菜谱定义了`first_chunk_index()`，它用于在块中找到动词。
- en: Swapping noun cardinals
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 交换名词基数
- en: In a chunk, a **cardinal** word—tagged as CD—refers to a number, such as "10".
    These cardinals often occur before or after a noun. For normalization purposes,
    it can be useful to always put the cardinal before the noun.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个块中，一个**基数词**（标记为 CD）指的是一个数字，例如“10”。这些基数词通常位于名词之前或之后。为了归一化目的，始终将基数词放在名词之前可能很有用。
- en: How to do it...
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: The function `swap_noun_cardinal()` is defined in `transforms.py`. It swaps
    any cardinal that occurs immediately after a noun with the noun, so that the cardinal
    occurs immediately before the noun.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 函数 `swap_noun_cardinal()` 定义在 `transforms.py` 中。它将任何紧接在名词之后的基数词与名词交换，使得基数词紧接在名词之前。
- en: '[PRE11]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Let's try it on a date, such as "Dec 10", and another common phrase "the top
    10".
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在日期“Dec 10”和另一个常见短语“the top 10”上试一试。
- en: '[PRE12]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The result is that the numbers are now in front of the noun, creating "10 Dec"
    and "the 10 top".
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是数字现在位于名词之前，形成了“10 Dec”和“the 10 top”。
- en: How it works...
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: We start by looking for a CD tag in the chunk. If no CD is found, or if the
    CD is at the beginning of the chunk, then the chunk is returned as is. There must
    also be a noun immediately before the CD. If we do find a CD with a noun preceding
    it, then we swap the noun and cardinal in place.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先在块中寻找 CD 标签。如果没有找到 CD，或者 CD 位于块的开头，则块将按原样返回。CD 前面也必须有一个名词。如果我们找到一个 CD，其前面有名词，那么我们将名词和基数词就地交换。
- en: See also
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: The *Correcting verb forms* recipe defines the `first_chunk_index()` function,
    used to find tagged words in a chunk.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '*纠正动词形式* 菜谱定义了 `first_chunk_index()` 函数，用于在块中查找标记的单词。'
- en: Swapping infinitive phrases
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 交换不定式短语
- en: An infinitive phrase has the form "A of B", such as "book of recipes". These
    can often be transformed into a new form while retaining the same meaning, such
    as "recipes book".
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 不定式短语的形式为“A of B”，例如“book of recipes”。这些短语通常可以转换成新的形式，同时保留相同的意思，例如“recipes book”。
- en: How to do it...
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: An infinitive phrase can be found by looking for a word tagged with IN. The
    function `swap_infinitive_phrase()`, defined in `transforms.py`, will return a
    chunk that swaps the portion of the phrase after the IN word with the portion
    before the IN word.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 通过寻找标记为 IN 的单词，可以找到一个不定式短语。在 `transforms.py` 中定义的函数 `swap_infinitive_phrase()`
    将返回一个交换了 IN 词之后短语部分与 IN 词之前短语部分的块。
- en: '[PRE13]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The function can now be used to transform "book of recipes" into "recipes book".
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 该函数现在可以用来将“book of recipes”转换成“recipes book”。
- en: '[PRE14]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: How it works...
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: 'This function is similar to the `swap_verb_phrase()` function described in
    the *Swapping verb phrases* recipe. The `inpred lambda` is passed to `first_chunk_index()`
    to look for a word whose tag is IN. Next, `nnpred` is used to find the first noun
    that occurs before the IN word, so we can insert the portion of the chunk after
    the IN word between the noun and the beginning of the chunk. A more complicated
    example should demonstrate this:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数与 *交换动词短语* 菜谱中描述的 `swap_verb_phrase()` 函数类似。`inpred lambda` 被传递给 `first_chunk_index()`
    以查找标记为 IN 的单词。然后使用 `nnpred` 查找 IN 词之前出现的第一个名词，这样我们就可以在 IN 词之后、名词和块的开头之间插入块的部分。一个更复杂的例子应该可以演示这一点：
- en: '[PRE15]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: We don't want the result to be "recipes delicious book". Instead, we want to
    insert "recipes" before the noun "book", but after the adjective "delicious".
    Hence, the need to find the `nnidx` occurring before the `inidx`.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不希望结果是“recipes delicious book”。相反，我们希望在名词“book”之前、形容词“delicious”之后插入“recipes”。因此，需要找到
    `nnidx` 发生在 `inidx` 之前。
- en: There's more...
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 更多内容...
- en: 'You''ll notice that the `inpred lambda` checks to make sure the word is not
    "like". That''s because "like" phrases must be treated differently, as transforming
    them the same way will result in an ungrammatical phrase. For example, "tastes
    like chicken" should not be transformed into "chicken tastes":'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 你会注意到 `inpred lambda` 会检查单词是否不是“like”。这是因为“like”短语必须以不同的方式处理，因为以相同的方式转换会导致不规则的短语。例如，“tastes
    like chicken”不应该转换成“chicken tastes”。
- en: '[PRE16]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: See also
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: In the next recipe, we'll learn how to transform "recipes book" into the more
    normal form "recipe book".
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个菜谱中，我们将学习如何将“recipes book”转换成更常见的“recipe book”形式。
- en: Singularizing plural nouns
  id: totrans-112
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 单复数名词
- en: As we saw in the previous recipe, the transformation process can result in phrases
    such as "recipes book". This is a NNS followed by an NN, when a more proper version
    of the phrase would be "recipe book", which is an NN followed by another NN. We
    can do another transform to correct these improper plural nouns.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在之前的食谱中看到的，转换过程可能导致诸如 "recipes book" 这样的短语。这是一个 NNS 后跟一个 NN，当短语的一个更合适的版本是
    "recipe book"，这是一个 NN 后跟另一个 NN。我们可以进行另一个转换来纠正这些不正确的复数名词。
- en: How to do it...
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: '`transforms.py` defines a function called `singularize_plural_noun()`, which
    will de-pluralize a plural noun (tagged with NNS) that is followed by another
    noun.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '`transforms.py` 定义了一个名为 `singularize_plural_noun()` 的函数，该函数将去复数化一个复数名词（标记为
    NNS），它后面跟着另一个名词。'
- en: '[PRE17]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Using it on "recipes book", we get the more correct form, "recipe book".
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在 "recipes book" 上使用它，我们得到更正确的形式，"recipe book"。
- en: '[PRE18]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: How it works...
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: We start by looking for a plural noun with the tag NNS. If found, and if the
    next word is a noun (determined by making sure the tag starts with NN), then we
    de-pluralize the plural noun by removing an "s" from the right side of both the
    tag and the word.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先寻找带有标签 NNS 的复数名词。如果找到，并且下一个词是一个名词（通过确保标签以 NN 开头来确定），那么我们就通过从标签和单词的右侧都去掉
    "s" 来去复数化复数名词。
- en: The tag is assumed to be capitalized, so an uppercase "S" is removed from the
    right side of the tag, while a lowercase "s" is removed from the right side of
    the word.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 假设标签是大写的，所以从标签的右侧去掉一个 "S"，同时从单词的右侧去掉一个 "s"。
- en: See also
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: The previous recipe shows how a transformation can result in a plural noun followed
    by a singular noun, though this could also occur naturally in real-world text.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的食谱展示了如何一个转换可以导致一个复数名词后面跟着一个单数名词，尽管这在现实世界的文本中也可能自然发生。
- en: Chaining chunk transformations
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 连接块转换
- en: The transform functions defined in the previous recipes can be chained together
    to normalize chunks. The resulting chunks are often shorter with no loss of meaning.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的食谱中定义的转换函数可以连接起来以规范化块。结果块通常更短，但不会失去意义。
- en: How to do it...
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: In `transforms.py` is the function `transform_chunk()`. It takes a single chunk
    and an optional list of transform functions. It calls each transform function
    on the chunk, one at a time, and returns the final chunk.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `transforms.py` 中是 `transform_chunk()` 函数。它接受一个单独的块和一个可选的转换函数列表。它对块上的每个转换函数逐一调用，并返回最终的块。
- en: '[PRE19]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Using it on the phrase "the book of recipes is delicious", we get "delicious
    recipe book":'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '在短语 "the book of recipes is delicious" 上使用它，我们得到 "delicious recipe book":'
- en: '[PRE20]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: How it works...
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'The `transform_chunk()` function defaults to chaining the following functions
    in order:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '`transform_chunk()` 函数默认按顺序链接以下函数：'
- en: '`filter_insignificant()`'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`filter_insignificant()`'
- en: '`swap_verb_phrase()`'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`swap_verb_phrase()`'
- en: '`swap_infinitive_phrase()`'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`swap_infinitive_phrase()`'
- en: '`singularize_plural_noun()`'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`singularize_plural_noun()`'
- en: Each function transforms the chunk that results from the previous function,
    starting with the original chunk.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 每个函数都转换由前一个函数产生的块，从原始块开始。
- en: Note
  id: totrans-138
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The order in which you apply transform functions can be significant. Experiment
    with your own data to determine which transforms are best, and in which order
    they should be applied.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 应用转换函数的顺序可能很重要。通过实验自己的数据来确定哪些转换最好，以及它们应该按什么顺序应用。
- en: There's more...
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 更多内容...
- en: You can pass `trace=1` into `transform_chunk()` to get an output at each step.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以将 `trace=1` 传递给 `transform_chunk()` 以在每个步骤得到输出。
- en: '[PRE21]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: This shows you the result of each transform function, which is then passed in
    to the next transform function until a final chunk is returned.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 这显示了每个转换函数的结果，然后这些结果被传递到下一个转换函数，直到返回一个最终块。
- en: See also
  id: totrans-144
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: The transform functions used were defined in the previous recipes of this chapter.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 使用的转换函数在上一章的食谱中定义。
- en: Converting a chunk tree to text
  id: totrans-146
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将块树转换为文本
- en: At some point, you may want to convert a `Tree` or sub-tree back to a sentence
    or chunk string. This is mostly straightforward, except when it comes to properly
    outputting punctuation.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在某个时候，你可能想将一个 `Tree` 或子树转换回句子或块字符串。这通常很简单，除了在正确输出标点符号时。
- en: How to do it...
  id: totrans-148
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: We'll use the first `Tree` of the `treebank_chunk` as our example. The obvious
    first step is to join all the words in the tree with a space.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 `treebank_chunk` 的第一个 `Tree` 作为我们的例子。显然的第一步是将树中的所有单词用空格连接起来。
- en: '[PRE22]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: As you can see, the punctuation isn't quite right. The commas and period are
    treated as individual words, and so get the surrounding spaces as well. We can
    fix this using regular expression substitution. This is implemented in the `chunk_tree_to_sent()`
    function found in `transforms.py`.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，标点符号并不完全正确。逗号和句号被当作单独的单词处理，因此也获得了周围的空格。我们可以使用正则表达式替换来修复这个问题。这已经在`transforms.py`中找到的`chunk_tree_to_sent()`函数中实现。
- en: '[PRE23]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Using this function results in a much cleaner sentence, with no space before
    each punctuation mark:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个函数可以得到一个更干净的句子，每个标点符号前都没有空格：
- en: '[PRE24]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: How it works...
  id: totrans-155
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: To correct the extra spaces in front of the punctuation, we create a regular
    expression `punct_re` that will match a space followed by any of the known punctuation
    characters. We have to escape both '.' and '?' with a '\' since they are special
    characters. The punctuation is surrounded by parenthesis so we can use the matched
    group for substitution.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 为了纠正标点符号前的额外空格，我们创建了一个正则表达式`punct_re`，它将匹配一个空格后跟任何已知的标点符号字符。由于`.`和`?`是特殊字符，我们必须用`\`来转义它们。标点符号被括号包围，这样我们就可以使用匹配的组来进行替换。
- en: Once we have our regular expression, we define `chunk_tree_to_sent()`, whose
    first step is to join the words by a concatenation character that defaults to
    a space. Then we can call `re.sub()` to replace all the punctuation matches with
    just the punctuation group. This eliminates the space in front of the punctuation
    characters, resulting in a more correct string.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了我们的正则表达式，我们就定义了`chunk_tree_to_sent()`函数，其第一步是使用默认为空格的连接字符将单词连接起来。然后我们可以调用`re.sub()`来替换所有标点符号匹配项，只保留标点符号组。这消除了标点符号前的空格，从而得到一个更正确的字符串。
- en: There's more...
  id: totrans-158
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 更多...
- en: We can simplify this function a little by using `nltk.tag.untag()` to get words
    from the tree's leaves, instead of using our own list comprehension.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过使用`nltk.tag.untag()`来简化这个函数，以获取树叶中的单词，而不是使用我们自己的列表推导。
- en: '[PRE25]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: See also
  id: totrans-161
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: The `nltk.tag.untag()` function was covered at the end of the *Default tagging*
    recipe in [Chapter 4](ch04.html "Chapter 4. Part-of-Speech Tagging"), *Part-of-Speech
    Tagging*.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '`nltk.tag.untag()`函数在[第4章](ch04.html "第4章。词性标注")的*默认标注*食谱的结尾进行了介绍，*词性标注*。'
- en: Flattening a deep tree
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 展平深层树
- en: Some of the included corpora contain parsed sentences, which are often deep
    trees of nested phrases. Unfortunately, these trees are too deep to use for training
    a chunker, since IOB tag parsing is not designed for nested chunks. To make these
    trees usable for chunker training, we must flatten them.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一些包含的语料库包含解析句子，这些句子通常是嵌套短语的深层树。不幸的是，这些树太深了，不能用于训练chunker，因为IOB标签解析不是为嵌套chunk设计的。为了使这些树可用于chunker训练，我们必须将它们展平。
- en: Getting ready
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备中
- en: 'We''re going to use the first parsed sentence of the `treebank` corpus as our
    example. Here''s a diagram showing how deeply nested this tree is:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用`treebank`语料库的第一个解析句子作为我们的例子。以下是一个显示这个树有多深嵌套的图示：
- en: '![Getting ready](img/3609_06_01.jpg)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![准备中](img/3609_06_01.jpg)'
- en: You may notice that the part-of-speech tags are part of the tree structure,
    instead of being included with the word. This will be handled next using the `Tree.pos()`
    method, which was designed specifically for combining words with pre-terminal
    `Tree` nodes such as part-of-speech tags.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会注意到词性标签是树结构的一部分，而不是与单词一起包含。这将在使用`Tree.pos()`方法时得到处理，该方法专门用于将单词与预终端`Tree`节点（如词性标签）结合。
- en: How to do it...
  id: totrans-169
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: In `transforms.py` there is a function named `flatten_deeptree()`. It takes
    a single `Tree` and will return a new `Tree` that keeps only the lowest level
    trees. It uses a helper function `flatten_childtrees()` to do most of the work.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在`transforms.py`中有一个名为`flatten_deeptree()`的函数。它接受一个单个`Tree`，并将返回一个新的`Tree`，该`Tree`只保留最低级别的树。它使用一个辅助函数`flatten_childtrees()`来完成大部分工作。
- en: '[PRE26]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'We can use it on the first parsed sentence of the `treebank` corpus to get
    a flatter tree:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在`treebank`语料库的第一个解析句子上使用它来得到一个更平展的树：
- en: '[PRE27]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The result is a much flatter `Tree` that only includes NP phrases. Words that
    are not part of a NP phrase are separated. This flatter tree is shown as follows:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是一个更平展的`Tree`，它只包括NP短语。不是NP短语部分的单词被分开。这个更平展的树如下所示：
- en: '![How to do it...](img/3609_06_02.jpg)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![如何操作...](img/3609_06_02.jpg)'
- en: This `Tree` is quite similar to the first chunk `Tree` from the `treebank_chunk`
    corpus. The main difference is that the rightmost NP `Tree` is separated into
    two sub-trees in the previous diagram, one of them named NP-TMP.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 这个 `Tree` 与 `treebank_chunk` 语料库中的第一个块 `Tree` 非常相似。主要区别在于，在之前的图中，最右边的 NP `Tree`
    被分成了两个子树，其中一个被命名为 NP-TMP。
- en: 'The first tree from `treebank_chunk` is shown as follows for comparison:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是将 `treebank_chunk` 中的第一个树显示出来以供比较：
- en: '![How to do it...](img/3609_06_03.jpg)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![如何做...](img/3609_06_03.jpg)'
- en: How it works...
  id: totrans-179
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何工作...
- en: 'The solution is composed of two functions: `flatten_deeptree()` returns a new
    `Tree` from the given tree by calling `flatten_childtrees()` on each of the given
    tree''s children.'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 解决方案由两个函数组成：`flatten_deeptree()` 通过对给定树的每个子树调用 `flatten_childtrees()` 来从给定的树返回一个新的
    `Tree`。
- en: '`flatten_childtrees()` is a recursive function that drills down into the `Tree`
    until it finds child trees whose `height()` is equal to or less than three. A
    `Tree` whose `height()` is less than three looks like this:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '`flatten_childtrees()` 是一个递归函数，它深入到 `Tree` 中，直到找到高度等于或小于三的子树。高度小于三的 `Tree`
    看起来像这样：'
- en: '[PRE28]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '![How it works...](img/3609_06_04.jpg)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
  zh: '![如何工作...](img/3609_06_04.jpg)'
- en: These short trees are converted into lists of tuples using the `pos()` function.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 这些短树通过 `pos()` 函数被转换成元组的列表。
- en: '[PRE29]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Trees whose `height()` is equal to three are the lowest level trees that we''re
    interested in keeping. These trees look like this:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 我们感兴趣保留的最低级别的树的高度等于三。这些树看起来像这样：
- en: '[PRE30]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '![How it works...](img/3609_06_05.jpg)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![如何工作...](img/3609_06_05.jpg)'
- en: 'When we call `pos()` on that tree, we get:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在那个树上调用 `pos()` 时，我们得到：
- en: '[PRE31]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: The recursive nature of `flatten_childtrees()` eliminates all trees whose height
    is greater than three.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '`flatten_childtrees()` 的递归性质消除了所有高度大于三的树。'
- en: There's more...
  id: totrans-192
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 更多...
- en: Flattening a deep `Tree` allows us to call `nltk.chunk.util.tree2conlltags()`
    on the flattened `Tree`, a necessary step to train a chunker. If you try to call
    this function before flattening the `Tree`, you get a `ValueError` exception.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 展平深层 `Tree` 允许我们在展平的 `Tree` 上调用 `nltk.chunk.util.tree2conlltags()`，这是训练分块器的一个必要步骤。如果你在展平
    `Tree` 之前尝试调用此函数，你会得到一个 `ValueError` 异常。
- en: '[PRE32]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'However, after flattening there''s no problem:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在展平之后没有问题：
- en: '[PRE33]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Being able to flatten trees, opens up the possibility of training a chunker
    on corpora consisting of deep parse trees.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 能够展平树，为在由深层解析树组成的语料库上训练分块器打开了可能性。
- en: CESS-ESP and CESS-CAT treebank
  id: totrans-198
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: CESS-ESP 和 CESS-CAT 树库
- en: The `cess_esp` and `cess_cat` corpora have parsed sentences, but no chunked
    sentences. In other words, they have deep trees that must be flattened in order
    to train a chunker. In fact, the trees are so deep that a diagram can't be shown,
    but the flattening can be demonstrated by showing the `height()` of the tree before
    and after flattening.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '`cess_esp` 和 `cess_cat` 语料库有解析过的句子，但没有分块句子。换句话说，它们有必须展平以训练分块器的深层树。实际上，树太深了，无法用图表显示，但可以通过显示展平前后的树的高度来演示展平过程。'
- en: '[PRE34]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: See also
  id: totrans-201
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考也
- en: The *Training a tagger-based chunker* recipe in [Chapter 5](ch05.html "Chapter 5. Extracting
    Chunks"), *Extracting Chunks* covers training a chunker using IOB tags.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [第 5 章](ch05.html "第 5 章。提取分块") 的 *基于标签器的分块器训练* 菜谱中，*提取分块* 覆盖了使用 IOB 标签训练分块器。
- en: Creating a shallow tree
  id: totrans-203
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建浅层树
- en: In the previous recipe, we flattened a deep `Tree` by only keeping the lowest
    level sub-trees. In this recipe, we'll keep only the highest level sub-trees instead.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一个菜谱中，我们通过仅保留最低级别的子树来展平了一个深层的 `Tree`。在这个菜谱中，我们将只保留最高级别的子树。
- en: How to do it...
  id: totrans-205
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'We''ll be using the first parsed sentence from the `treebank` corpus as our
    example. Recall from the previous recipe that the sentence `Tree` looks like this:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 `treebank` 语料库中的第一个解析句子作为我们的示例。回想一下，上一个菜谱中的句子 `Tree` 看起来像这样：
- en: '![How to do it...](img/3609_06_01.jpg)'
  id: totrans-207
  prefs: []
  type: TYPE_IMG
  zh: '![如何做...](img/3609_06_01.jpg)'
- en: The `shallow_tree()` function defined in `transforms.py` eliminates all the
    nested sub-trees, keeping only the top tree nodes.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `transforms.py` 中定义的 `shallow_tree()` 函数消除了所有嵌套的子树，只保留顶层树节点。
- en: '[PRE35]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Using it on the first parsed sentence in `treebank` results in a `Tree` with
    only two sub-trees.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `treebank` 中的第一个解析句子上使用它，结果得到一个只有两个子树的 `Tree`。
- en: '[PRE36]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'We can visually and programmatically see the difference, as shown in the following
    diagram and code:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以直观地看到差异，如下面的图表和代码所示：
- en: '![How to do it...](img/3609_06_06.jpg)'
  id: totrans-213
  prefs: []
  type: TYPE_IMG
  zh: '![如何做...](img/3609_06_06.jpg)'
- en: '[PRE37]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: As in the previous recipe, the height of the new tree is three so it can be
    used for training a chunker.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 与前一个示例一样，新树的高度为三，因此它可以用于训练分块器。
- en: How it works...
  id: totrans-216
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: The `shallow_tree()` function iterates over each of the top-level sub-trees
    in order to create new child trees. If the `height()` of a sub-tree is less than
    three, then that sub-tree is replaced by a list of its part-of-speech tagged children.
    All other sub-trees are replaced by a new `Tree` whose children are the part-of-speech
    tagged leaves. This eliminates all nested sub-trees while retaining the top-level
    sub-trees.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '`shallow_tree()` 函数按顺序遍历每个顶级子树以创建新的子树。如果一个子树的 `height()` 小于三个，则该子树被替换为其词性标注的子节点列表。所有其他子树都被替换为一个新的
    `Tree`，其子节点是词性标注的叶子节点。这消除了所有嵌套的子树，同时保留了顶级子树。'
- en: This function is an alternative to `flatten_deeptree()` from the previous recipe,
    for when you want to keep the higher level tree nodes and ignore the lower level
    nodes.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数是前一个示例中的 `flatten_deeptree()` 的替代方案，当你想要保留高级别的树节点并忽略低级别节点时使用。
- en: See also
  id: totrans-219
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: The previous recipe covers how to flatten a `Tree` and keep the lowest level
    sub-trees, as opposed to keeping the highest level sub-trees.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 前一个示例介绍了如何展平 `Tree` 并保留最低级别的子树，而不是保留最高级别的子树。
- en: Converting tree nodes
  id: totrans-221
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 转换树节点
- en: As you've seen in previous recipes, parse trees often have a variety of `Tree`
    node types that are not present in chunk trees. If you want to use the parse trees
    to train a chunker, then you'll probably want to reduce this variety by converting
    some of these tree nodes to more common node types.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 如前文示例所示，解析树通常具有各种 `Tree` 节点类型，这些类型在块树中并不存在。如果你想使用解析树来训练一个分块器，那么你可能希望通过将这些树节点转换为更常见的节点类型来减少这种多样性。
- en: Getting ready
  id: totrans-223
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'First, we have to decide what `Tree` nodes need to be converted. Let''s take
    a look at that first `Tree` again:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们必须决定哪些 `Tree` 节点需要被转换。让我们再次看看那个第一个 `Tree`：
- en: '![Getting ready](img/3609_06_01.jpg)'
  id: totrans-225
  prefs: []
  type: TYPE_IMG
  zh: '![准备工作](img/3609_06_01.jpg)'
- en: 'Immediately you can see that there are two alternative NP sub-trees: NP-SBJ
    and NP-TMP. Let''s convert both of those to NP. The mapping will be as follows:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 立刻就可以看到有两个可选的 NP 子树：NP-SBJ 和 NP-TMP。让我们将这两个都转换为 NP。映射将如下所示：
- en: '| Original Node | New Node |'
  id: totrans-227
  prefs: []
  type: TYPE_TB
  zh: '| 原始节点 | 新节点 |'
- en: '| --- | --- |'
  id: totrans-228
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| NP-SBJ | NP |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '| NP-SBJ | NP |'
- en: '| NP-TMP | NP |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '| NP-TMP | NP |'
- en: How to do it...
  id: totrans-231
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现...
- en: 'In `transforms.py` there is a function `convert_tree_nodes()`. It takes two
    arguments: the `Tree` to convert, and a node conversion `mapping`. It returns
    a new `Tree` with all matching nodes replaced based on the values in the `mapping`.'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `transforms.py` 中有一个名为 `convert_tree_nodes()` 的函数。它接受两个参数：要转换的 `Tree` 和节点转换
    `映射`。它返回一个新的 `Tree`，其中所有匹配的节点根据 `映射` 中的值被替换。
- en: '[PRE38]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Using the mapping table shown earlier, we can pass it in as a `dict` to `convert_tree_nodes()`
    and convert the first parsed sentence from `treebank`.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 使用前面显示的映射表，我们可以将其作为 `dict` 传递给 `convert_tree_nodes()` 并将 `treebank` 的第一个解析句子进行转换。
- en: '[PRE39]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'In the following diagram, you can see that the NP-* sub-trees have been replaced
    with NP sub-trees:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的图中，你可以看到 NP-* 子树已被替换为 NP 子树：
- en: '![How to do it...](img/3609_06_07.jpg)'
  id: totrans-237
  prefs: []
  type: TYPE_IMG
  zh: '![如何实现...](img/3609_06_07.jpg)'
- en: How it works...
  id: totrans-238
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: '`convert_tree_nodes()` recursively converts every child sub-tree using the
    `mapping`. The `Tree` is then rebuilt with the converted nodes and children until
    the entire `Tree` has been converted.'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: '`convert_tree_nodes()` 递归地使用 `映射` 转换每个子树。然后，使用转换后的节点和子节点重建 `Tree`，直到整个 `Tree`
    被转换。'
- en: The result is a brand new `Tree` instance with new sub-trees whose nodes have
    been converted.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是一个全新的 `Tree` 实例，其中新的子树节点已被转换。
- en: See also
  id: totrans-241
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: The previous two recipes cover different methods of flattening a parse `Tree`,
    both of which can produce sub-trees that may require mapping before using them
    to train a chunker. Chunker training is covered in the *Training a tagger-based
    chunker* recipe in [Chapter 5](ch05.html "Chapter 5. Extracting Chunks"), *Extracting
    Chunks*.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 前两个示例介绍了不同的解析 `Tree` 展平方法，这两种方法都可以产生在使用它们来训练分块器之前可能需要映射的子树。分块器训练在 [第 5 章](ch05.html
    "第 5 章。提取分块") 的 *基于标签器的分块器训练* 示例中介绍，*提取分块*。
