- en: 9\. Interpreting a Machine Learning Model
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 9\. 解释机器学习模型
- en: Overview
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 概述
- en: This chapter will show you how to interpret a machine learning model's results
    and get deeper insights into the patterns it found. By the end of the chapter,
    you will be able to analyze weights from linear models and variable importance
    for `RandomForest`. You will be able to implement variable importance via permutation
    to analyze feature importance. You will use a partial dependence plot to analyze
    single variables and make use of the lime package for local interpretation.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将向你展示如何解释机器学习模型的结果，并深入了解它所发现的模式。通过本章学习后，你将能够分析线性模型的权重和`RandomForest`的变量重要性。你还将能够通过置换法实现变量重要性分析，分析特征的重要性。你将使用部分依赖图（partial
    dependence plot）来分析单一变量，并使用lime包进行局部解释。
- en: Introduction
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: In the previous chapter, you saw how to find the optimal hyperparameters of
    some of the most popular machine learning algorithms in order to get better predictive
    performance (that is, more accurate predictions).
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，你已经学习了如何找到一些最流行机器学习算法的最佳超参数，以获得更好的预测性能（即，更准确的预测）。
- en: Machine learning algorithms are always referred to as black box where we can
    only see the inputs and outputs and the implementation inside the algorithm is
    quite opaque, so people don't know what is happening inside.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习算法通常被称为“黑箱”，我们只能看到输入和输出，而算法内部的实现非常不透明，因此人们不知道其内部发生了什么。
- en: With each day that passes, we can sense the elevated need for more transparency
    in machine learning models. In the last few years, we have seen some cases where
    algorithms have been accused of discriminating against groups of people. For instance,
    a few years ago, a not-for-profit news organization called ProPublica highlighted
    bias in the COMPAS algorithm, built by the Northpointe company. The objective
    of the algorithm is to assess the likelihood of re-offending for a criminal. It
    was shown that the algorithm was predicting a higher level of risk for specific
    groups of people based on their demographics rather than other features. This
    example highlighted the importance of interpreting the results of your model and
    its logic properly and clearly.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 随着时间的推移，我们可以感受到对机器学习模型更高透明度的需求日益增加。在过去几年中，我们看到一些算法被指控歧视特定群体。例如，几年前，一个名为ProPublica的非盈利新闻机构揭示了由Northpointe公司开发的COMPAS算法中的偏见。该算法的目的是评估罪犯再次犯罪的可能性。研究表明，该算法根据人口统计特征而非其他特征，为某些群体预测了较高的风险水平。这个例子突显了正确、清晰地解释模型结果及其逻辑的重要性。
- en: Luckily, some machine learning algorithms provide methods to understand the
    parameters they learned for a given task and dataset. There are also some functions
    that are model-agnostic and can help us to better understand the predictions made.
    So, there are different techniques that are either model-specific or model-agnostic
    for interpreting a model.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，一些机器学习算法提供了方法，帮助我们理解它们为特定任务和数据集学习到的参数。也有一些模型无关的函数，可以帮助我们更好地理解模型做出的预测。因此，解释模型的方法有很多种，既有针对特定模型的，也有通用的。
- en: These techniques can also differ in their scope. In the literature, we either
    have a global or local interpretation. A global interpretation means we are looking
    at the variables for all observations from a dataset and we want to understand
    which features have the biggest overall influence on the target variable. For
    instance, if you are predicting customer churn for a telco company, you may find
    the most important features for your model are customer usage and the average
    monthly amount paid. Local interpretation, on the other hand, focuses only on
    a single observation and analyzes the impact of the different variables. We will
    look at a single specific case and see what led the model to make its final prediction.
    For example, you will look at a specific customer who is predicted to churn and
    will discover that they usually buy the new iPhone model every year, in September.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 这些技术的适用范围也有所不同。在文献中，我们通常分为全局解释和局部解释。全局解释意味着我们关注整个数据集中所有观测值的变量，目的是了解哪些特征对目标变量有最大的整体影响。例如，如果你正在预测电信公司客户流失率，你可能会发现模型最重要的特征是客户使用情况和每月平均支付金额。而局部解释则只关注单一观测值，并分析不同变量的影响。我们将查看一个具体的案例，了解模型做出最终预测的原因。例如，你会查看一个被预测会流失的客户，发现他每年9月都会购买新的iPhone型号。
- en: In this chapter, we will go through some techniques on how to interpret your
    models or their results.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论一些技术，帮助你如何解读模型或其结果。
- en: Linear Model Coefficients
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性模型系数
- en: 'In *Chapter 2, Regression*, and *Chapter 3, Binary Classification*, you saw
    that linear regression models learn function parameters in the form of the following:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第二章，回归*和*第三章，二分类*中，你看到了线性回归模型是如何学习以下形式的函数参数的：
- en: '![Figure 9.1: Function parameters for linear regression models'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.1: 线性回归模型的函数参数'
- en: '](img/B15019_09_01.jpg)'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_09_01.jpg)'
- en: 'Figure 9.1: Function parameters for linear regression models'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '图 9.1: 线性回归模型的函数参数'
- en: The objective is to find the best parameters (w1, w2 …, wn) that will get the
    predictions, ŷ̂, very close to the actual target values, `y`. So, once you have
    trained your model and are getting good predictive performance without much overfitting,
    you can use these parameters (or coefficients) to understand which variables largely
    impacted the predictions. If a coefficient is close to 0, this means the related
    feature didn't impact much the outcome. On the other hand, if it is quite high
    (positively or negatively), it means its feature is influencing the prediction
    outcome vastly.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 目标是找到最优参数（w1, w2 …, wn），使得预测值 ŷ̂ 非常接近实际目标值 `y`。因此，一旦你训练了模型，并且在没有过拟合的情况下得到了良好的预测性能，你可以利用这些参数（或系数）来理解哪些变量对预测产生了较大影响。如果某个系数接近
    0，这意味着相关特征对结果的影响较小。另一方面，如果系数较高（无论是正的还是负的），这意味着该特征对预测结果有很大的影响。
- en: 'Let''s take the example of the following function: `100 + 0.2 * x`1 `+ 200
    * x`2 `- 180 * x`3\. The coefficient of x1 is only **0.2**. It is quite low compared
    to the other ones. It doesn''t have much impact on the final outcome. The coefficient
    of x2 is positive, so it will positively impact the prediction. It is the opposite
    of the x3 coefficient because the x3 coefficient is negative.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们以以下函数为例：`100 + 0.2 * x`1 `+ 200 * x`2 `- 180 * x`3。x1 的系数只有**0.2**，与其他系数相比非常低，对最终结果的影响较小。x2
    的系数为正，因此它会对预测产生正面影响。它与 x3 的系数相反，因为 x3 的系数为负。
- en: But to be able to compare apples versus apples, you need to rescale the features
    so that they have the same scale so you can compare their coefficients. If not,
    then maybe x1 ranges from 1 million to 5 million, while x2 and x3 are between
    **1** and **88**. In this case, even though the x1 coefficient is small, a small
    change in the x1 value has a drastic impact on the prediction. On the other hand,
    if all 3 coefficients are between -1 and 1, then we can say the key drivers in
    predicting the target variable are the features x2 and x3.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，为了能够比较“苹果与苹果”，你需要重新缩放特征，使它们具有相同的尺度，这样你就可以比较它们的系数。如果不这样做，可能 x1 的范围是从 100 万到
    500 万，而 x2 和 x3 的范围是**1**到**88**。在这种情况下，尽管 x1 的系数较小，但 x1 值的微小变化对预测有很大影响。另一方面，如果三个系数都在
    -1 到 1 之间，那么我们可以说，预测目标变量的主要驱动因素是特征 x2 和 x3。
- en: 'In `sklearn`, it is extremely easy to get the coefficient of a linear model;
    you just need to call the `coef_` attribute. Let''s implement this on a real example
    with the Diabetes dataset from `sklearn`:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在`sklearn`中，获取线性模型的系数非常简单，你只需要调用 `coef_` 属性。让我们用 `sklearn` 中的糖尿病数据集做一个实际的例子：
- en: '[PRE0]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The output will be as follows:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '![Figure 9.2: Coefficients of the linear regression parameters'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.2: 线性回归参数的系数'
- en: '](img/B15019_09_02.jpg)'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_09_02.jpg)'
- en: 'Figure 9.2: Coefficients of the linear regression parameters'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '图 9.2: 线性回归参数的系数'
- en: 'Let''s create a DataFrame with these values and column names:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建一个包含这些值和列名的 DataFrame：
- en: '[PRE1]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The output will be as follows:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '![Figure 9.3: Coefficients of the linear regression model'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.3: 线性回归模型的系数'
- en: '](img/B15019_09_03.jpg)'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_09_03.jpg)'
- en: 'Figure 9.3: Coefficients of the linear regression model'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '图 9.3: 线性回归模型的系数'
- en: A large positive or a large negative number for a feature coefficient means
    it has a strong influence on the outcome. On the other hand, if the coefficient
    is close to 0, this means the variable does not have much impact on the prediction.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 对于特征系数而言，较大的正数或负数意味着它对结果有强烈的影响。另一方面，如果系数接近 0，则意味着该变量对预测的影响较小。
- en: 'From this table, we can see that column `s1` has a very low coefficient (a
    large negative number) so it negatively influences the final prediction. If `s1`
    increases by a unit of 1, the prediction value will decrease by `-792.184162`.
    On the other hand, `bmi` has a large positive number (`519.839787`) on the prediction,
    so the risk of diabetes is highly linked to this feature: an increase in body
    mass index (BMI) means a significant increase in the risk of diabetes.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 从这张表格中，我们可以看到列 `s1` 的系数非常低（一个大负数），所以它对最终预测有负面影响。如果 `s1` 增加 1 单位，预测值将减少 `-792.184162`。另一方面，`bmi`
    在预测中有一个较大的正数（`519.839787`），因此糖尿病的风险与该特征高度相关：体重指数（BMI）的增加意味着糖尿病风险显著增加。
- en: 'Exercise 9.01: Extracting the Linear Regression Coefficient'
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 9.01：提取线性回归系数
- en: In this exercise, we will train a linear regression model to predict the customer
    drop-out ratio and extract its coefficients.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在本次练习中，我们将训练一个线性回归模型来预测客户流失率，并提取其系数。
- en: Note
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'The dataset we will be using is shared by Carl Rasmussen from the University
    of Toronto: [https://packt.live/37hInDr](https://packt.live/37hInDr).'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用的数据集由多伦多大学的 Carl Rasmussen 分享：[https://packt.live/37hInDr](https://packt.live/37hInDr)。
- en: This dataset was synthetically generated from a simulation for predicting the
    fraction of bank customers who leave a bank because of long queues.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这个数据集是通过模拟合成生成的，用于预测因为长时间排队而离开银行的客户比例。
- en: 'The CSV version of this dataset can be found here: [https://packt.live/3kZrggU](https://packt.live/3kZrggU).'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集的 CSV 版本可以在此找到：[https://packt.live/3kZrggU](https://packt.live/3kZrggU)。
- en: 'A data dictionary presenting the variables in this dataset can be found here:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这个数据集的变量数据字典可以在此找到：
- en: '[https://packt.live/3aBGhQD](https://packt.live/3aBGhQD).'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.live/3aBGhQD](https://packt.live/3aBGhQD)。'
- en: 'The following steps will help you complete the exercise:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤将帮助你完成练习：
- en: Open a new Colab notebook.
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个新的 Colab 笔记本。
- en: 'Import the following packages: `pandas`, `train_test_split` from `sklearn.model_selection`,
    `StandardScaler` from `sklearn.preprocessing`, `LinearRegression` from `sklearn.linear_model`,
    `mean_squared_error` from `sklearn.metrics`, and `altair`:'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入以下包：`pandas`、`train_test_split` 来自 `sklearn.model_selection`、`StandardScaler`
    来自 `sklearn.preprocessing`、`LinearRegression` 来自 `sklearn.linear_model`、`mean_squared_error`
    来自 `sklearn.metrics` 和 `altair`：
- en: '[PRE2]'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Create a variable called `file_url` that contains the URL to the dataset:'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为 `file_url` 的变量，包含数据集的 URL：
- en: '[PRE3]'
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Load the dataset into a DataFrame called `df` using `.read_csv()`:'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `.read_csv()` 将数据集加载到名为 `df` 的 DataFrame 中：
- en: '[PRE4]'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Print the first five rows of the DataFrame:'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印 DataFrame 的前五行：
- en: '[PRE5]'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'You should get the following output:'
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 9.4: First five rows of the loaded DataFrame'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 9.4：加载的 DataFrame 前五行](img/B15019_09_04.jpg)'
- en: '](img/B15019_09_04.jpg)'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_09_04.jpg)'
- en: 'Figure 9.4: First five rows of the loaded DataFrame'
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 9.4：加载的 DataFrame 前五行
- en: Note
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: The output has been truncated for presentation purposes. Please refer [https://packt.live/3kZrggU](https://packt.live/3kZrggU)
    for complete output.
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了展示的方便，输出已被截断。请参考 [https://packt.live/3kZrggU](https://packt.live/3kZrggU)
    获取完整的输出。
- en: 'Extract the `rej` column using `.pop()` and save it into a variable called
    `y`:'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `.pop()` 提取 `rej` 列，并将其保存为名为 `y` 的变量：
- en: '[PRE6]'
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Print the summary of the DataFrame using `.describe()`.
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `.describe()` 打印 DataFrame 的摘要。
- en: '[PRE7]'
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'You should get the following output:'
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 9.5: Statistical measures of the DataFrame'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 9.5：DataFrame 的统计测量](img/B15019_09_05.jpg)'
- en: '](img/B15019_09_05.jpg)'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_09_05.jpg)'
- en: 'Figure 9.5: Statistical measures of the DataFrame'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 9.5：DataFrame 的统计测量
- en: Note
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: The preceding figure is a truncated version of the output.
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述图表是输出的简化版本。
- en: From this output, we can see the data is not standardized. The variables have
    different scales.
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从这个输出中，我们可以看到数据没有经过标准化。变量的尺度不同。
- en: 'Split the DataFrame into training and testing sets using `train_test_split()`
    with `test_size=0.3` and `random_state = 1`:'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `train_test_split()` 将 DataFrame 分割成训练集和测试集，`test_size=0.3` 和 `random_state
    = 1`：
- en: '[PRE8]'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Instantiate `StandardScaler`:'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化 `StandardScaler`：
- en: '[PRE9]'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Train `StandardScaler` on the training set and standardize it using `.fit_transform()`:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在训练集上训练 `StandardScaler` 并使用 `.fit_transform()` 标准化数据：
- en: '[PRE10]'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Standardize the testing set using `.transform()`:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `.transform()` 标准化测试集：
- en: '[PRE11]'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Instantiate `LinearRegression` and save it to a variable called `lr_model`:'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化 `LinearRegression` 并将其保存为名为 `lr_model` 的变量：
- en: '[PRE12]'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Train the model on the training set using `.fit()`:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在训练集上使用 `.fit()` 训练模型：
- en: '[PRE13]'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'You should get the following output:'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 9.6: Logs of LinearRegression'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 9.6：线性回归的日志](img/B15019_09_06.jpg)'
- en: '](img/B15019_09_06.jpg)'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_09_06.jpg)'
- en: 'Figure 9.6: Logs of LinearRegression'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 9.6：线性回归日志
- en: 'Predict the outcomes of the training and testing sets using `.predict()`:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`.predict()`预测训练集和测试集的结果：
- en: '[PRE14]'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Calculate the mean squared error on the training set and print its value:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算训练集的均方误差并打印其值：
- en: '[PRE15]'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'You should get the following output:'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 9.7: MSE score of the training set'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 9.7：训练集的MSE得分'
- en: '](img/B15019_09_07.jpg)'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_09_07.jpg)'
- en: 'Figure 9.7: MSE score of the training set'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 9.7：训练集的MSE得分
- en: We achieved quite a low MSE score on the training set.
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们在训练集上获得了相当低的MSE得分。
- en: 'Calculate the mean squared error on the testing set and print its value:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算测试集的均方误差并打印其值：
- en: '[PRE16]'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'You should get the following output:'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 9.8: MSE score of the testing set'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 9.8：测试集的MSE得分'
- en: '](img/B15019_09_08.jpg)'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_09_08.jpg)'
- en: 'Figure 9.8: MSE score of the testing set'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 9.8：测试集的MSE得分
- en: We also have a low MSE score on the testing set that is very similar to the
    training one. So, our model is not overfitting.
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们在测试集上的MSE得分也很低，并且与训练集的得分非常相似。所以，我们的模型并没有出现过拟合。
- en: Note
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注
- en: You may get slightly different outputs than those present here. However, the
    values you would obtain should largely agree with those obtained in this exercise.
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你可能会得到与此处显示的稍有不同的输出。不过，你得到的值应该与本练习中得到的值大致一致。
- en: 'Print the coefficients of the linear regression model using `.coef_`:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`.coef_`打印线性回归模型的系数：
- en: '[PRE17]'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'You should get the following output:'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 9.9: Coefficients of the linear regression model'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 9.9：线性回归模型的系数'
- en: '](img/B15019_09_09.jpg)'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_09_09.jpg)'
- en: 'Figure 9.9: Coefficients of the linear regression model'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 9.9：线性回归模型的系数
- en: 'Create an empty DataFrame called `coef_df`:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`coef_df`的空DataFrame：
- en: '[PRE18]'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Create a new column called `feature` for this DataFrame with the name of the
    columns of `df` using `.columns`:'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为此DataFrame创建一个名为`feature`的新列，列值为`df`的列名，使用`.columns`：
- en: '[PRE19]'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Create a new column called `coefficient` for this DataFrame with the coefficients
    of the linear regression model using `.coef_`:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`.coef_`为此DataFrame创建一个名为`coefficient`的新列，列值为线性回归模型的系数：
- en: '[PRE20]'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Print the first five rows of `coef_df`:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印`coef_df`的前五行：
- en: '[PRE21]'
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'You should get the following output:'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 9.10: The first five rows of coef_df'
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 9.10：`coef_df`的前五行'
- en: '](img/B15019_09_10.jpg)'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_09_10.jpg)'
- en: 'Figure 9.10: The first five rows of coef_df'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 9.10：`coef_df`的前五行
- en: From this output, we can see the variables `a1sx` and `a1sy` have the lowest
    value (the biggest negative value) so they are contributing more to the prediction
    than the three other variables shown here.
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从这个输出中，我们可以看到变量`a1sx`和`a1sy`的值最低（最负值），因此它们对预测的贡献大于此处显示的其他三个变量。
- en: 'Plot a bar chart with Altair using `coef_df` and `coefficient` as the `x` axis
    and `feature` as the `y` axis:'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用Altair绘制一个条形图，使用`coef_df`和`coefficient`作为`x`轴，`feature`作为`y`轴：
- en: '[PRE22]'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'You should get the following output:'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 9.11: Graph showing the coefficients of the linear regression model'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 9.11：显示线性回归模型系数的图'
- en: '](img/B15019_09_11.jpg)'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_09_11.jpg)'
- en: 'Figure 9.11: Graph showing the coefficients of the linear regression model'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.11：显示线性回归模型系数的图
- en: 'From this output, we can see the variables that impacted the prediction the
    most were:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个输出中，我们可以看到对预测影响最大的变量是：
- en: '`a2pop`, which corresponds to the population of area 2'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`a2pop`，表示区域2的人口'
- en: '`a1pop`, which corresponds to the population of area 1'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`a1pop`，表示区域1的人口'
- en: '`a3pop`, which corresponds to the population of area 3'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`a3pop`，表示区域3的人口'
- en: '`mxql`, which is the maximum length of the queues'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mxql`，表示队列的最大长度'
- en: '`b1eff`, which is the level of efficiency of bank 1'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`b1eff`，表示银行1的效率水平'
- en: '`temp`, which is the temperature'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`temp`，表示温度'
- en: 'The first three variables impacted the outcome positively (increasing the target
    variable value). This means as the population grows in any of the three areas,
    the chance of customer churn increases. On the other hand, the last three features
    negatively impacted the target variable (decreasing the target variable value):
    if the maximum length, bank-1 efficiency level, or temperature increases, the
    risk of customers leaving decreases.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 前三个变量对结果产生了正向影响（增加目标变量值）。这意味着，在这三个区域中，任何一个区域的人口增长都会增加客户流失的可能性。另一方面，后三个特征对目标变量产生了负向影响（降低目标变量值）：如果最大队列长度、银行1的效率水平或温度增加，客户流失的风险会降低。
- en: Note
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 注
- en: To access the source code for this specific section, please refer to [https://packt.live/3kZrggU](https://packt.live/3kZrggU).
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问这一特定章节的源代码，请参考[https://packt.live/3kZrggU](https://packt.live/3kZrggU)。
- en: This section does not currently have an online interactive example, but can
    be run as usual on Google Colab.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 本节目前没有在线互动示例，但可以像往常一样在Google Colab上运行。
- en: In this exercise, you learned how to extract the coefficients learned by a linear
    regression model and identified which variables make the biggest contribution
    to the prediction.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，你学会了如何提取线性回归模型学到的系数，并识别出哪些变量对预测做出了最大贡献。
- en: RandomForest Variable Importance
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 随机森林变量重要性
- en: '*Chapter 4*, *Multiclass Classification with RandomForest*, introduced you
    to a very powerful tree-based algorithm: `RandomForest`. It is one of the most
    popular algorithms in the industry, not only because it achieves very good results
    in terms of prediction but also for the fact that it provides several tools for
    interpreting it, such as variable importance.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '*第4章*，*基于随机森林的多类别分类*，介绍了一种非常强大的树形算法：`RandomForest`。它是行业中最流行的算法之一，不仅因为它在预测方面取得了非常好的结果，还因为它提供了多个工具来解释其结果，例如变量重要性。'
- en: Remember from *Chapter 4*, *Multiclass Classification with RandomForest*, that
    `RandomForest` builds multiple independent trees and then averages their results
    to make a final prediction. We also learned that it creates nodes in each tree
    to find the best split that will clearly separate the observations into two groups.
    `RandomForest` uses different measures to find the best split. In `sklearn`, you
    can either use the Gini or Entropy measure for the classification task and MSE
    or MAE for regression. Without going into the details of each of them, these measures
    calculate the level of impurity of a given split. This level of impurity looks
    at how different the observations are from each other within a node. For instance,
    if a group has all the same values within a feature, it will have a high level
    of purity. On the other hand, if the group has a lot of different values, it will
    have a high level of impurity.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 记住在*第4章*，*基于随机森林的多类别分类*中，我们学到`RandomForest`构建多个独立的树，然后将它们的结果平均以做出最终预测。我们还学到，它会在每棵树中创建节点，找到能够清晰地将观测值分成两组的最佳切分点。`RandomForest`使用不同的度量来找到最佳切分点。在`sklearn`中，你可以使用基尼指数或熵度量进行分类任务，使用均方误差（MSE）或平均绝对误差（MAE）进行回归。我们不深入讲解这些度量，它们都计算给定切分的杂质程度。杂质度量观察的是节点内的观测值彼此之间有多大的不同。例如，如果一个组内的某个特征的值完全相同，那么它的纯度很高；反之，如果组内的值差异较大，则杂质较高。
- en: Each sub-tree built will decrease this impurity score. So, we can use this impurity
    score to assess the importance of each variable for the final prediction. This
    technique is not specific to `RandomForest` only; it can be applied to any tree-based
    algorithm, such as decision tree or gradient-boosted tree.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 每个构建的子树都会降低这个杂质评分。因此，我们可以使用这个杂质评分来评估每个变量对最终预测的重要性。这种技术不仅仅适用于`RandomForest`，还可以应用于任何基于树的算法，如决策树或梯度提升树。
- en: After training `RandomForest`, you can assess its variable importance (or feature
    importance) with the `feature_importances_` attribute.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练完`RandomForest`后，你可以通过`feature_importances_`属性评估其变量重要性（或特征重要性）。
- en: 'Let''s see how to extract this information from the Breast Cancer dataset from `sklearn`:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何从`sklearn`的乳腺癌数据集中提取这些信息：
- en: '[PRE23]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The output will be as shown in the following figure:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下图所示：
- en: '![Figure 9.12: Feature importance of a Random Forest model'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '![图9.12：随机森林模型的特征重要性'
- en: '](img/B15019_09_12.jpg)'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_09_12.jpg)'
- en: 'Figure 9.12: Feature importance of a Random Forest model'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.12：随机森林模型的特征重要性
- en: Note
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Due to randomization, you may get a slightly different result.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 由于随机化，你可能会得到略有不同的结果。
- en: 'It might be a little difficult to evaluate which importance value corresponds
    to which variable from this output. Let''s create a DataFrame that will contain
    these values with the name of the columns:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个输出中评估哪个重要性值对应于哪个变量可能有点困难。让我们创建一个DataFrame，里面包含这些值并显示列名：
- en: '[PRE24]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The output will be as follows:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '![Figure 9.13: RandomForest variable importance for the first five features'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '![图9.13：乳腺癌数据集前五个特征的随机森林变量重要性'
- en: of the Breast Cancer dataset
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 乳腺癌数据集的结果
- en: '](img/B15019_09_13.jpg)'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_09_13.jpg)'
- en: 'Figure 9.13: RandomForest variable importance for the first five features of
    the Breast Cancer dataset'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.13：乳腺癌数据集前五个特征的随机森林变量重要性
- en: From this output, we can see that `mean radius` and `mean perimeter` have the
    highest scores, which means they are the most important in predicting the target
    variable. The `mean smoothness` column has a very low value, so it seems it doesn't
    influence the model much to predict the output.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 从输出结果中，我们可以看到`mean radius`和`mean perimeter`的得分最高，这意味着它们在预测目标变量时最为重要。`mean smoothness`列的值非常低，因此它似乎对模型的输出预测影响不大。
- en: Note
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The range of values of variable importance is different for datasets; it is
    not a standardized measure.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 变量重要性的值范围对于不同数据集是不同的；它不是一个标准化的度量。
- en: 'Let''s plot these variable importance values onto a graph using `altair`:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用`altair`将这些变量重要性值绘制成图：
- en: '[PRE25]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The output will be as follows:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 9.14: Graph showing RandomForest variable importance'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.14: 显示随机森林变量重要性的图'
- en: '](img/B15019_09_14.jpg)'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_09_14.jpg)'
- en: 'Figure 9.14: Graph showing RandomForest variable importance'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '图 9.14: 显示随机森林变量重要性的图'
- en: From this graph, we can see the most important features for this Random Forest
    model are `worst perimeter`, `worst area`, and `worst concave points`. So now
    we know these features are the most important ones in predicting whether a tumor
    is benign or malignant for this Random Forest model.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个图表中，我们可以看到，对于这个随机森林模型来说，最重要的特征是`worst perimeter`、`worst area`和`worst concave
    points`。所以现在我们知道，这些特征在预测肿瘤是良性还是恶性方面最为重要。
- en: 'Exercise 9.02: Extracting RandomForest Feature Importance'
  id: totrans-168
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '练习 9.02: 提取随机森林特征重要性'
- en: In this exercise, we will extract the feature importance of a Random Forest
    classifier model trained to predict the customer drop-out ratio.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 在本次练习中，我们将提取一个训练好的随机森林分类器模型的特征重要性，该模型用于预测客户流失率。
- en: We will be using the same dataset as in the previous exercise.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用与上一节相同的数据集。
- en: 'The following steps will help you complete the exercise:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤将帮助你完成本次练习：
- en: Open a new Colab notebook.
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个新的 Colab 笔记本。
- en: 'Import the following packages: `pandas`, `train_test_split` from `sklearn.model_selection`,
    and `RandomForestRegressor` from `sklearn.ensemble`:'
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入以下包：`pandas`，`train_test_split`来自`sklearn.model_selection`，以及`RandomForestRegressor`来自`sklearn.ensemble`：
- en: '[PRE26]'
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Create a variable called `file_url` that contains the URL to the dataset:'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`file_url`的变量，其中包含数据集的 URL：
- en: '[PRE27]'
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Load the dataset into a DataFrame called `df` using `.read_csv()`:'
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`.read_csv()`将数据集加载到名为`df`的 DataFrame 中：
- en: '[PRE28]'
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Extract the `rej` column using `.pop()` and save it into a variable called
    `y`:'
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`.pop()`提取`rej`列，并将其保存为变量`y`：
- en: '[PRE29]'
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Split the DataFrame into training and testing sets using `train_test_split()`
    with `test_size=0.3` and `random_state = 1`:'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`train_test_split()`将数据集拆分为训练集和测试集，设置`test_size=0.3`和`random_state=1`：
- en: '[PRE30]'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Instantiate `RandomForestRegressor` with `random_state=1`, `n_estimators=50`,
    `max_depth=6`, and `min_samples_leaf=60`:'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`random_state=1`、`n_estimators=50`、`max_depth=6`和`min_samples_leaf=60`实例化`RandomForestRegressor`：
- en: '[PRE31]'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Train the model on the training set using `.fit()`:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`.fit()`在训练集上训练模型：
- en: '[PRE32]'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'You should get the following output:'
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 9.15: Logs of the Random Forest model'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 9.15: 随机森林模型的日志'
- en: '](img/B15019_09_15.jpg)'
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_09_15.jpg)'
- en: 'Figure 9.15: Logs of the Random Forest model'
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '图 9.15: 随机森林模型的日志'
- en: 'Predict the outcomes of the training and testing sets using `.predict()`:'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`.predict()`预测训练集和测试集的结果：
- en: '[PRE33]'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Calculate the mean squared error on the training set and print its value:'
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算训练集的均方误差并打印其值：
- en: '[PRE34]'
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'You should get the following output:'
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 9.16: MSE score of the training set'
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 9.16: 训练集的均方误差得分'
- en: '](img/B15019_09_16.jpg)'
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_09_16.jpg)'
- en: 'Figure 9.16: MSE score of the training set'
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '图 9.16: 训练集的均方误差得分'
- en: We achieved quite a low MSE score on the training set.
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们在训练集上取得了一个相当低的均方误差得分。
- en: 'Calculate the MSE on the testing set and print its value:'
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算测试集上的均方误差并打印其值：
- en: '[PRE35]'
  id: totrans-201
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'You should get the following output:'
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 9.17: MSE score of the testing set'
  id: totrans-203
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 9.17: 测试集的均方误差得分'
- en: '](img/B15019_09_17.jpg)'
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_09_17.jpg)'
- en: 'Figure 9.17: MSE score of the testing set'
  id: totrans-205
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '图 9.17: 测试集的均方误差得分'
- en: We also have a low MSE score on the testing set that is very similar to the
    training one. So, our model is not overfitting.
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们在测试集上也得到了一个很低的均方误差得分，这个得分与训练集的得分非常相似。所以我们的模型并没有发生过拟合。
- en: 'Print the variable importance using `.feature_importances_`:'
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`.feature_importances_`打印变量重要性：
- en: '[PRE36]'
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'You should get the following output:'
  id: totrans-209
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 9.18: MSE score of the testing set'
  id: totrans-210
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 9.18: 测试集的均方误差得分'
- en: '](img/B15019_09_18.jpg)'
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_09_18.jpg)'
- en: 'Figure 9.18: MSE score of the testing set'
  id: totrans-212
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '图 9.18: 测试集的均方误差得分'
- en: 'Create an empty DataFrame called `varimp_df`:'
  id: totrans-213
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为 `varimp_df` 的空 DataFrame：
- en: '[PRE37]'
  id: totrans-214
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Create a new column called `feature` for this DataFrame with the name of the
    columns of `df`, using `.columns`:'
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为此 DataFrame 创建一个名为 `feature` 的新列，并使用 `.columns` 获取 `df` 的列名：
- en: '[PRE38]'
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Print the first five rows of `varimp_df`:'
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印 `varimp_df` 的前五行：
- en: '[PRE39]'
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'You should get the following output:'
  id: totrans-219
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 9.19: Variable importance of the first five variables'
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 9.19：前五个变量的重要性'
- en: '](img/B15019_09_19.jpg)'
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_09_19.jpg)'
- en: 'Figure 9.19: Variable importance of the first five variables'
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 9.19：前五个变量的重要性
- en: From this output, we can see the variables `a1cy` and `a1sy` have the highest
    value, so they are more important for predicting the target variable than the
    three other variables shown here.
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从此输出中，我们可以看到变量 `a1cy` 和 `a1sy` 具有最高值，因此它们对预测目标变量比这里显示的其他三个变量更为重要。
- en: 'Plot a bar chart with Altair using `coef_df` and `importance` as the `x` axis
    and `feature` as the `y` axis:'
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 Altair 绘制条形图，`coef_df` 和 `importance` 为 `x` 轴，`feature` 为 `y` 轴：
- en: '[PRE40]'
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'You should get the following output:'
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 9.20: Graph showing the variable importance of the first five variables'
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 9.20：显示前五个变量重要性的图表'
- en: '](img/B15019_09_20.jpg)'
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_09_20.jpg)'
- en: 'Figure 9.20: Graph showing the variable importance of the first five variables'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.20：显示前五个变量重要性的图表
- en: From this output, we can see the variables that impact the prediction the most
    for this Random Forest model are `a2pop`, `a1pop`, `a3pop`, `b1eff`, and `temp`,
    by decreasing order of importance.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 从此输出中，我们可以看到对于这个 Random Forest 模型，最能影响预测的变量按重要性递减的顺序是 `a2pop`、`a1pop`、`a3pop`、`b1eff`
    和 `temp`。
- en: Note
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/327Pi0i](https://packt.live/327Pi0i).
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问此特定章节的源代码，请参考 [https://packt.live/327Pi0i](https://packt.live/327Pi0i)。
- en: This section does not currently have an online interactive example, but can
    be run as usual on Google Colab.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 本节目前没有在线交互示例，但可以像往常一样在 Google Colab 上运行。
- en: In this exercise, you learned how to extract the feature importance learned
    by a Random Forest model and identified which variables are the most important
    for its predictions.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，你学习了如何提取 Random Forest 模型所学到的特征重要性，并确定哪些变量对其预测最为重要。
- en: Variable Importance via Permutation
  id: totrans-235
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过置换评估变量的重要性
- en: In the previous section, we saw how to extract feature importance for RandomForest.
    There is actually another technique that shares the same name, but its underlying
    logic is different and can be applied to any algorithm, not only tree-based ones.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们看到如何提取 Random Forest 的特征重要性。实际上，还有另一种技术也称为特征重要性置换，但它的基本逻辑不同，适用于任何算法，而不仅限于树模型。
- en: This technique can be referred to as variable importance via permutation. Let's
    say we trained a model to predict a target variable with five classes and achieved
    an accuracy of 0.95\. One way to assess the importance of one of the features
    is to remove and train a model and see the new accuracy score. If the accuracy
    score dropped significantly, then we could infer that this variable has a significant
    impact on the prediction. On the other hand, if the score slightly decreased or
    stayed the same, we could say this variable is not very important and doesn't
    influence the final prediction much. So, we can use this difference between the
    model's performance to assess the importance of a variable.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 该技术可称为通过置换评估变量的重要性。假设我们训练了一个模型来预测一个有五个类别的目标变量，并且获得了 0.95 的准确率。评估某个特征的重要性的一种方法是移除该特征并重新训练模型，查看新的准确率。如果准确率显著下降，那么我们可以推断该变量对预测有重要影响。另一方面，如果准确率略微下降或保持不变，那么我们可以认为该变量并不重要，对最终预测的影响不大。因此，我们可以通过模型性能的变化来评估变量的重要性。
- en: The drawback of this method is that you need to retrain a new model for each
    variable. If it took you a few hours to train the original model and you have
    100 different features, it would take quite a while to compute the importance
    of each variable. It would be great if we didn't have to retrain different models.
    So, another solution would be to generate noise or new values for a given column
    and predict the final outcomes from this modified data and compare the accuracy
    score. For example, if you have a column with values between 0 and 100, you can
    take the original data and randomly generate new values for this column (keeping
    all other variables the same) and predict the class for them.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法的缺点是需要为每个变量重新训练一个新模型。如果你花了几个小时训练了原始模型，而你有100个不同的特征，那么计算每个变量的重要性将花费相当长的时间。如果我们不必重新训练不同的模型，那将是非常棒的。因此，另一种解决方案是生成噪声或给定列的新值，从这些修改过的数据中预测最终结果并比较准确度分数。例如，如果你有一个值在0到100之间的列，你可以取原始数据并随机生成该列的新值（保持其他变量不变），然后预测它们的类别。
- en: This option also has a catch. The randomly generated values can be very different
    from the original data. Going back to the same example we saw before, if the original
    range of values for a column is between 0 and 100 and we generate values that
    can be negative or take a very high value, it is not very representative of the
    real distribution of the original data. So, we will need to understand the distribution
    of each variable before generating new values.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 这个选项也有一个问题。随机生成的值可能与原始数据非常不同。回到我们之前看到的同一个例子，如果一个列的原始值范围在0到100之间，而我们生成的值可能是负数或者非常高的值，这就不太能代表原始数据的真实分布。因此，我们在生成新值之前，需要理解每个变量的分布情况。
- en: 'Rather than generating random values, we can simply swap (or permute) values
    of a column between different rows and use these modified cases for predictions.
    Then, we can calculate the related accuracy score and compare it with the original
    one to assess the importance of this variable. For example, we have the following
    rows in the original dataset:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 与生成随机值不同，我们可以简单地交换（或置换）不同行之间某一列的值，并使用这些修改后的案例进行预测。然后，我们可以计算相关的准确度分数，并将其与原始分数进行比较，以评估该变量的重要性。例如，我们在原始数据集中有以下几行：
- en: '![Figure 9.21: Example of the dataset'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: '![图9.21：数据集的示例'
- en: '](img/B15019_09_21.jpg)'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_09_21.jpg)'
- en: 'Figure 9.21: Example of the dataset'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.21：数据集的示例
- en: 'We can swap the values for the X1 column and get a new dataset:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以交换X1列的值并得到一个新的数据集：
- en: '![Figure 9.22: Example of a swapped column from the dataset'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: '![图9.22：数据集中交换列的示例'
- en: '](img/B15019_09_22.jpg)'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_09_22.jpg)'
- en: 'Figure 9.22: Example of a swapped column from the dataset'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.22：数据集中交换列的示例
- en: 'The `mlxtend` package provides a function to perform variable permutation and
    calculate variable importance values: `feature_importance_permutation`. Let''s
    see how to use it with the Breast Cancer dataset from `sklearn`.'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: '`mlxtend`包提供了一个函数来执行变量置换并计算变量重要性值：`feature_importance_permutation`。让我们看看如何使用它与`sklearn`中的乳腺癌数据集。'
- en: 'First, let''s load the data and train a Random Forest model:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们加载数据并训练一个随机森林模型：
- en: '[PRE41]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Then, we will call the `feature_importance_permutation` function from `mlxtend.evaluate`.
    This function takes the following parameters:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将调用`mlxtend.evaluate`中的`feature_importance_permutation`函数。该函数接受以下参数：
- en: '`predict_method`: A function that will be called for model prediction. Here,
    we will provide the `predict` method from our trained `rf_model` model.'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`predict_method`：用于模型预测的函数。在这里，我们将提供训练好的`rf_model`模型的`predict`方法。'
- en: '`X`: The features from the dataset. It needs to be in NumPy array form.'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`X`：数据集中的特征。它需要是NumPy数组形式。'
- en: '`y`: The target variable from the dataset. It needs to be in `Numpy` array
    form.'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`y`：数据集中的目标变量。它需要是`Numpy`数组形式。'
- en: '`metric`: The metric used for comparing the performance of the model. For the
    classification task, we will use accuracy.'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`metric`：用于比较模型性能的度量标准。对于分类任务，我们将使用准确率。'
- en: '`num_round`: The number of rounds `mlxtend` will perform permutation on the
    data and assess the performance change.'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_round`：`mlxtend`将对数据执行置换操作并评估性能变化的轮次。'
- en: '`seed`: The seed set for getting reproducible results.'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`seed`：用于获取可重复结果的种子。'
- en: 'Consider the following code snippet:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下代码片段：
- en: '[PRE42]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'The output should be as follows:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 输出应如下所示：
- en: '![Figure 9.23: Variable importance by permutation'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: '![图9.23：通过置换获得的变量重要性'
- en: '](img/B15019_09_23.jpg)'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_09_23.jpg)'
- en: 'Figure 9.23: Variable importance by permutation'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.23：通过置换计算的变量重要性
- en: 'Let''s create a DataFrame containing these values and the names of the features
    and plot them on a graph with `altair`:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建一个包含这些值和特征名称的DataFrame，并使用`altair`在图表上绘制它们：
- en: '[PRE43]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'The output should be as follows:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 输出应如下所示：
- en: '![Figure 9.24: Graph showing variable importance by permutation'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: '![图9.24：通过置换显示的变量重要性图](img/B15019_09_25.jpg)'
- en: '](img/B15019_09_24.jpg)'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_09_24.jpg)'
- en: 'Figure 9.24: Graph showing variable importance by permutation'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.24：通过置换显示的变量重要性图
- en: These results are different from the ones we got from `RandomForest` in the
    previous section. Here, worst concave points is the most important, followed by
    worst area, and worst perimeter has a higher value than mean radius. So, we got
    the same list of the most important variables but in a different order. This confirms
    these three features are indeed the most important in predicting whether a tumor
    is malignant or not. The variable importance from `RandomForest` and the permutation
    have different logic, therefore, you might get different outputs when you run
    the code given in the preceding section.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 这些结果与我们在前一节中从`RandomForest`得到的结果不同。在这里，最重要的是最差的凹点，其次是最差的面积，最差的周长的值高于平均半径。因此，我们得到了相同的最重要变量列表，但顺序不同。这验证了这三个特征确实是预测肿瘤是否恶性的最重要特征。`RandomForest`的变量重要性和置换方法有不同的逻辑，因此，当你运行前一节中给出的代码时，可能会得到不同的输出。
- en: 'Exercise 9.03: Extracting Feature Importance via Permutation'
  id: totrans-271
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习9.03：通过置换提取特征重要性
- en: In this exercise, we will compute and extract feature importance by permutating
    a Random Forest classifier model trained to predict the customer drop-out ratio.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们将计算并提取通过置换训练的随机森林分类器模型的特征重要性，以预测客户流失率。
- en: We will using the same dataset as in the previous exercise.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用与前一节相同的数据集。
- en: 'The following steps will help you complete the exercise:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤将帮助你完成练习：
- en: Open a new Colab notebook.
  id: totrans-275
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个新的Colab笔记本。
- en: 'Import the following packages: `pandas`, `train_test_split` from `sklearn.model_selection`,
    `RandomForestRegressor` from `sklearn.ensemble`, `feature_importance_permutation`
    from `mlxtend.evaluate`, and `altair`:'
  id: totrans-276
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入以下包：`pandas`，`train_test_split`来自`sklearn.model_selection`，`RandomForestRegressor`来自`sklearn.ensemble`，`feature_importance_permutation`来自`mlxtend.evaluate`，以及`altair`：
- en: '[PRE44]'
  id: totrans-277
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Create a variable called `file_url` that contains the URL of the dataset:'
  id: totrans-278
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`file_url`的变量，包含数据集的URL：
- en: '[PRE45]'
  id: totrans-279
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Load the dataset into a DataFrame called `df` using `.read_csv()`:'
  id: totrans-280
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`.read_csv()`将数据集加载到一个名为`df`的DataFrame中：
- en: '[PRE46]'
  id: totrans-281
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Extract the `rej` column using `.pop()` and save it into a variable called
    `y`:'
  id: totrans-282
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`.pop()`提取`rej`列，并将其保存到一个名为`y`的变量中：
- en: '[PRE47]'
  id: totrans-283
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Split the DataFrame into training and testing sets using `train_test_split()`
    with `test_size=0.3` and `random_state = 1`:'
  id: totrans-284
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`train_test_split()`将DataFrame拆分为训练集和测试集，`test_size=0.3`，并设置`random_state=1`：
- en: '[PRE48]'
  id: totrans-285
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Instantiate `RandomForestRegressor` with `random_state=1`, `n_estimators=50`,
    `max_depth=6`, and `min_samples_leaf=60`:'
  id: totrans-286
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化`RandomForestRegressor`，设置`random_state=1`，`n_estimators=50`，`max_depth=6`，`min_samples_leaf=60`：
- en: '[PRE49]'
  id: totrans-287
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Train the model on the training set using `.fit()`:'
  id: totrans-288
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`.fit()`在训练集上训练模型：
- en: '[PRE50]'
  id: totrans-289
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'You should get the following output:'
  id: totrans-290
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应得到以下输出：
- en: '![Figure 9.25: Logs of RandomForest'
  id: totrans-291
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图9.25：随机森林日志](img/B15019_09_25.jpg)'
- en: '](img/B15019_09_25.jpg)'
  id: totrans-292
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_09_25.jpg)'
- en: 'Figure 9.25: Logs of RandomForest'
  id: totrans-293
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图9.25：随机森林日志
- en: 'Extract the feature importance via permutation using `feature_importance_permutation`
    from `mlxtend` with the Random Forest model, the testing set, `r2` as the metric
    used, `num_rounds=1`, and `seed=2`. Save the results into a variable called `imp_vals`
    and print its values:'
  id: totrans-294
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`mlxtend`中的`feature_importance_permutation`通过置换提取特征重要性，采用随机森林模型、测试集、`r2`作为使用的指标，`num_rounds=1`，并设置`seed=2`。将结果保存到一个名为`imp_vals`的变量中，并打印其值：
- en: '[PRE51]'
  id: totrans-295
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'You should get the following output:'
  id: totrans-296
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应得到以下输出：
- en: '![Figure 9.26: Variable importance by permutation'
  id: totrans-297
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图9.26：通过置换计算的变量重要性](img/B15019_09_26.jpg)'
- en: '](img/B15019_09_26.jpg)'
  id: totrans-298
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_09_26.jpg)'
- en: 'Figure 9.26: Variable importance by permutation'
  id: totrans-299
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图9.26：通过置换计算的变量重要性
- en: It is quite hard to interpret the raw results. Let's plot the variable importance
    by permutating the model on a graph.
  id: totrans-300
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 原始结果相当难以解读。让我们通过在图表上置换模型来绘制变量重要性。
- en: 'Create a DataFrame called `varimp_df` with two columns: `feature` containing
    the name of the columns of `df`, using `.columns` and `''importance''` containing
    the values of `imp_vals`:'
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`varimp_df`的DataFrame，包含两列：`feature`，其中包含`df`的列名，使用`.columns`，以及`importance`，其中包含`imp_vals`的值：
- en: '[PRE52]'
  id: totrans-302
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Plot a bar chart with Altair using `coef_df` and `importance` as the `x` axis
    and `feature` as the `y` axis:'
  id: totrans-303
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 Altair 绘制条形图，`coef_df` 和 `importance` 作为 `x` 轴，`feature` 作为 `y` 轴：
- en: '[PRE53]'
  id: totrans-304
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'You should get the following output:'
  id: totrans-305
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 9.27: Graph showing the variable importance by permutation'
  id: totrans-306
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 9.27：通过置换显示变量重要性的图表](img/B15019_09_27.jpg)'
- en: '](img/B15019_09_27.jpg)'
  id: totrans-307
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_09_27.jpg)'
- en: 'Figure 9.27: Graph showing the variable importance by permutation'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.27：通过置换显示变量重要性的图表
- en: 'From this output, we can see the variables that impact the prediction the most
    for this Random Forest model are: `a2pop`, `a1pop`, `a3pop`, `b1eff`, and `temp`,
    in decreasing order of importance. This is very similar to the results of *Exercise
    9.02*, *Extracting RandomForest Feature Importance*.'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个输出结果中，我们可以看到，对这个随机森林模型预测影响最大的变量是：`a2pop`、`a1pop`、`a3pop`、`b1eff` 和 `temp`，按重要性递减排序。这与*练习
    9.02*中提到的*提取随机森林特征重要性*结果非常相似。
- en: Note
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/2YdstY9](https://packt.live/2YdstY9).
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参考 [https://packt.live/2YdstY9](https://packt.live/2YdstY9)。
- en: This section does not currently have an online interactive example, but can
    be run as usual on Google Colab.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 本节目前没有在线交互示例，但可以像往常一样在 Google Colab 上运行。
- en: You successfully extracted the feature importance by permutating this model
    and identified which variables are the most important for its predictions.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 你成功地通过置换这个模型提取了特征重要性，并识别出哪些变量对预测最为重要。
- en: Partial Dependence Plots
  id: totrans-314
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部分依赖图
- en: 'Another tool that is model-agnostic is a partial dependence plot. It is a visual
    tool for analyzing the effect of a feature on the target variable. To achieve
    this, we can plot the values of the feature we are interested in analyzing on
    the `x`-axis and the target variable on the `y`-axis and then show all the observations
    from the dataset on this graph. Let''s try it on the Breast Cancer dataset from
    `sklearn`:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种与模型无关的工具是部分依赖图。它是一个用于分析特征对目标变量影响的可视化工具。为了实现这一点，我们可以将我们感兴趣的特征值绘制在 `x` 轴上，将目标变量绘制在
    `y` 轴上，然后将数据集中的所有观测结果显示在这个图表上。让我们尝试一下在 `sklearn` 的乳腺癌数据集上进行分析：
- en: '[PRE54]'
  id: totrans-316
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Now that we have loaded the data and converted it to a DataFrame, let''s have
    a look at the worst concave points column:'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经加载数据并将其转换为 DataFrame，让我们看看最差凹点列：
- en: '[PRE55]'
  id: totrans-318
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'The resulting plot is as follows:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的图表如下所示：
- en: '![Figure 9.28: Scatter plot of the worst concave points and target variables'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.28：最差凹点和目标变量的散点图](img/B15019_09_28.jpg)'
- en: '](img/B15019_09_28.jpg)'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_09_28.jpg)'
- en: 'Figure 9.28: Scatter plot of the worst concave points and target variables'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.28：最差凹点和目标变量的散点图
- en: Note
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The preceding code and figure are just examples. We encourage you to analyze
    different features by changing the values assigned to `x` and `y` in the preceding
    code. For example, you can possibly analyze worst concavity versus worst perimeter
    by setting `x='worst concavity'` and `y='worst perimeter'` in the preceding code.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码和图形只是示例。我们鼓励你通过改变代码中 `x` 和 `y` 的值来分析不同的特征。例如，你可以通过将 `x='worst concavity'`
    和 `y='worst perimeter'` 设置在上述代码中，可能分析最差凹度与最差周长之间的关系。
- en: 'From this plot, we can see:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个图中，我们可以看到：
- en: Most cases with 1 for the target variable have values under 0.16 for the worst
    concave points column.
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 目标变量为 1 的大多数情况，其最差凹点的值低于 0.16。
- en: Cases with a 0 value for the target have values of over 0.08 for worst concave points.
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 目标值为 0 的情况，其最差凹点的值超过 0.08。
- en: With this plot, we are not too sure about which outcome (0 or 1) we will get
    for the values between 0.08 and 0.16 for worst concave points. There are multiple
    possible reasons why the outcome of the observations within this range of values
    is uncertain, such as the fact that there are not many records that fall into
    this case, or other variables might influence the outcome for these cases. This
    is where a partial dependence plot can help.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这个图，我们不太确定在最差凹点的值介于 0.08 和 0.16 之间时，会得到哪种结果（0 或 1）。该范围内观测结果不确定的原因可能有多种，比如在该范围内的记录较少，或者其他变量可能会影响这些情况的结果。这就是部分依赖图可以帮助的地方。
- en: 'The logic is very similar to variable importance via permutation but rather
    than randomly replacing the values in a column, we will test every possible value
    within that column for all observations and see what predictions it leads to.
    If we take the example from figure 9.21, from the three observations we had originally,
    this method will create six new observations by keeping columns `X2` and `X3`
    as they were and replacing the values of `X1`:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑与通过置换计算变量重要性非常相似，不同的是，我们不是随机替换列中的值，而是测试该列中所有可能的值对所有观测值的预测结果。如果我们以图 9.21 的例子为例，原本的三条观测数据，使用这种方法会生成六条新记录，保持
    `X2` 和 `X3` 列不变，而替换 `X1` 的值：
- en: '![Figure 9.29: Example of records generated from a partial dependence plot'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.29：从部分依赖图生成的记录示例'
- en: '](img/B15019_09_29.jpg)'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_09_29.jpg)'
- en: 'Figure 9.29: Example of records generated from a partial dependence plot'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.29：从部分依赖图生成的记录示例
- en: With this new data, we can see, for instance, whether the value 12 really has
    a strong influence on predicting 1 for the target variable. The original records,
    with the values 42 and 1 for the `X1` column, lead to outcome 0 and only value
    12 generated a prediction of 1\. But if we take the same observations for `X1`,
    equal to 42 and 1, and replace that value with 12, we can see whether the new
    predictions will lead to 1 for the target variable. This is exactly the logic
    behind a partial dependence plot, and it will assess all the permutations possible
    for a column and plot the average of the predictions.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这组新数据，我们可以看到，例如，值 12 是否真的对预测目标变量为 1 有强烈影响。原始记录中，`X1` 列的值为 42 和 1 时，预测结果为 0，只有值
    12 生成了预测为 1。但如果我们取相同的观测数据，`X1` 等于 42 和 1，然后将该值替换为 12，我们就可以看到新的预测是否会将目标变量预测为 1。这正是部分依赖图背后的逻辑，它会评估列的所有排列组合，并绘制预测值的平均值。
- en: '`sklearn` provides a function called `plot_partial_dependence()` to display
    the partial dependence plot for a given feature. Let''s see how to use it on the
    Breast Cancer dataset. First, we need to get the index of the column we are interested
    in. We will use the `.get_loc()` method from `pandas` to get the index for the
    `worst concave points` column:'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: '`sklearn` 提供了一个名为 `plot_partial_dependence()` 的函数，用于显示给定特征的部分依赖图。我们来看看如何在乳腺癌数据集上使用它。首先，我们需要获取我们感兴趣列的索引。我们将使用
    `pandas` 的 `.get_loc()` 方法来获取 `最差凹点` 列的索引：'
- en: '[PRE56]'
  id: totrans-335
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Now we can call the `plot_partial_dependence()` function. We need to provide
    the following parameters: the trained model, the training set, and the indices
    of the features to be analyzed:'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以调用 `plot_partial_dependence()` 函数。我们需要提供以下参数：训练好的模型、训练集以及要分析的特征索引：
- en: '[PRE57]'
  id: totrans-337
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: '![Figure 9.30: Partial dependence plot for the worst concave points column'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.30：最差凹点列的部分依赖图'
- en: '](img/B15019_09_30.jpg)'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_09_30.jpg)'
- en: 'Figure 9.30: Partial dependence plot for the worst concave points column'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.30：最差凹点列的部分依赖图
- en: This partial dependence plot shows us that, on average, all the observations
    with a value under 0.17 for the worst concave points column will most likely lead
    to a prediction of 1 for the target (probability over 0.5) and all the records
    over 0.17 will have a prediction of 0 (probability under 0.5).
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 这个部分依赖图展示了，平均而言，所有“最差凹点”列值小于0.17的观测值很可能会预测目标为1（概率超过0.5），而所有大于0.17的记录则预测为0（概率低于0.5）。
- en: 'Exercise 9.04: Plotting Partial Dependence'
  id: totrans-342
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 9.04：绘制部分依赖图
- en: In this exercise, we will plot partial dependence plots for two variables, `a1pop`
    and `temp`, from a Random Forest classifier model trained to predict the customer
    drop-out ratio.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将为两个变量`a1pop`和`temp`绘制部分依赖图，这些变量来自一个训练好的随机森林分类器模型，用于预测客户流失率。
- en: We will using the same dataset as in the previous exercise.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用与上一个练习相同的数据集。
- en: Open a new Colab notebook.
  id: totrans-345
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个新的 Colab 笔记本。
- en: 'Import the following packages: `pandas`, `train_test_split` from `sklearn.model_selection`,
    `RandomForestRegressor` from `sklearn.ensemble`, `plot_partial_dependence` from
    `sklearn.inspection`, and `altair`:'
  id: totrans-346
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入以下包：`pandas`、`train_test_split`（来自 `sklearn.model_selection`）、`RandomForestRegressor`（来自
    `sklearn.ensemble`）、`plot_partial_dependence`（来自 `sklearn.inspection`）和 `altair`：
- en: '[PRE58]'
  id: totrans-347
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'Create a variable called `file_url` that contains the URL for the dataset:'
  id: totrans-348
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为 `file_url` 的变量，包含数据集的 URL：
- en: '[PRE59]'
  id: totrans-349
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Load the dataset into a DataFrame called `df` using `.read_csv()`:'
  id: totrans-350
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `.read_csv()` 将数据集加载到名为 `df` 的 DataFrame 中：
- en: '[PRE60]'
  id: totrans-351
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Extract the `rej` column using `.pop()` and save it into a variable called
    `y`:'
  id: totrans-352
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `.pop()` 提取 `rej` 列，并将其保存到一个名为 `y` 的变量中：
- en: '[PRE61]'
  id: totrans-353
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Split the DataFrame into training and testing sets using `train_test_split()`
    with `test_size=0.3` and `random_state = 1`:'
  id: totrans-354
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`train_test_split()`将数据框分割为训练集和测试集，`test_size=0.3`，`random_state=1`：
- en: '[PRE62]'
  id: totrans-355
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Instantiate `RandomForestRegressor` with `random_state=1`, `n_estimators=50`,
    `max_depth=6`, and `min_samples_leaf=60`:'
  id: totrans-356
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`random_state=1`、`n_estimators=50`、`max_depth=6`和`min_samples_leaf=60`实例化`RandomForestRegressor`：
- en: '[PRE63]'
  id: totrans-357
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Train the model on the training set using `.fit()`:'
  id: totrans-358
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`.fit()`在训练集上训练模型：
- en: '[PRE64]'
  id: totrans-359
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'You should get the following output:'
  id: totrans-360
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到如下输出：
- en: '![Figure 9.31: Logs of RandomForest'
  id: totrans-361
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 9.31：随机森林日志'
- en: '](img/B15019_09_31.jpg)'
  id: totrans-362
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_09_31.jpg)'
- en: 'Figure 9.31: Logs of RandomForest'
  id: totrans-363
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 9.31：随机森林日志
- en: 'Plot the partial dependence plot using `plot_partial_dependence()` from `sklearn`
    with the Random Forest model, the testing set, and the index of the `a1pop` column:'
  id: totrans-364
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用来自`sklearn`的`plot_partial_dependence()`，结合随机森林模型、测试集和`a1pop`列的索引，绘制部分依赖图：
- en: '[PRE65]'
  id: totrans-365
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'You should get the following output:'
  id: totrans-366
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到如下输出：
- en: '![Figure 9.32: Partial dependence plot for a1pop'
  id: totrans-367
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 9.32：a1pop的部分依赖图'
- en: '](img/B15019_09_32.jpg)'
  id: totrans-368
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_09_32.jpg)'
- en: 'Figure 9.32: Partial dependence plot for a1pop'
  id: totrans-369
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 9.32：a1pop的部分依赖图
- en: This partial dependence plot shows that, on average, the `a1pop` variable doesn't
    affect the target variable much when its value is below 2, but from there the
    target increases linearly by 0.04 for each unit increase of `a1pop`. This means
    if the population size of area 1 is below the value of 2, the risk of churn is
    almost null. But over this limit, every increment of population size for area
    1 increases the chance of churn by `4%`.
  id: totrans-370
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个部分依赖图显示，平均而言，当`a1pop`变量的值低于2时，它对目标变量的影响不大，但从这个值开始，目标变量会随着`a1pop`每增加一个单位而线性增加0.04。这意味着，如果区域1的人口规模低于2，流失风险几乎为零。但超过这个临界值后，区域1每增加一个人口单位，流失的机会将增加`4%`。
- en: 'Plot the partial dependence plot using `plot_partial_dependence()` from `sklearn`
    with the Random Forest model, the testing set, and the index of the `temp` column:'
  id: totrans-371
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用来自`sklearn`的`plot_partial_dependence()`，结合随机森林模型、测试集和`temp`列的索引，绘制部分依赖图：
- en: '[PRE66]'
  id: totrans-372
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'You should get the following output:'
  id: totrans-373
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到如下输出：
- en: '![Figure 9.33: Partial dependence plot for temp'
  id: totrans-374
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 9.33：temp的部分依赖图'
- en: '](img/B15019_09_33.jpg)'
  id: totrans-375
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_09_33.jpg)'
- en: 'Figure 9.33: Partial dependence plot for temp'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.33：temp的部分依赖图
- en: 'This partial dependence plot shows that, on average, the `temp` variable has
    a negative linear impact on the target variable: when `temp` increases by 1, the
    target variable will decrease by 0.12\. This means if the temperature increases
    by a degree, the chance of leaving the queue decreases by 12%.'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 这个部分依赖图显示，平均而言，`temp`变量对目标变量有负线性影响：当`temp`增加1时，目标变量将减少0.12。这意味着，如果温度升高1度，离开队列的机会将减少12%。
- en: Note
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/2DWnSmn](https://packt.live/2DWnSmn).
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问该特定部分的源代码，请参考[https://packt.live/2DWnSmn](https://packt.live/2DWnSmn)。
- en: You can also run this example online at [https://packt.live/2DWnUL1](https://packt.live/2DWnUL1).
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以在[https://packt.live/2DWnUL1](https://packt.live/2DWnUL1)上在线运行这个示例。
- en: You learned how to plot and analyze a partial dependence plot for the `a1pop`
    and `temp` features. In this exercise, we saw that `a1pop` has a positive linear
    impact on the target, while `temp` has a negative linear influence.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经学会了如何绘制并分析`a1pop`和`temp`特征的部分依赖图。在本次练习中，我们看到`a1pop`对目标变量有正向线性影响，而`temp`则有负向线性影响。
- en: Local Interpretation with LIME
  id: totrans-382
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用LIME进行局部解释
- en: 'After training our model, we usually use it for predicting outcomes on unseen
    data. The global interpretations we saw earlier, such as model coefficient, variable
    importance, and the partial dependence plot, gave us a lot of information on the
    features at an overall level. Sometimes we want to understand what has influenced
    the model for a specific case to predict a specific outcome. For instance, if
    your model is to assess the risk of offering credit to a new client, you may want
    to understand why it rejected the case for a specific lead. This is what local
    interpretation is for: analyzing a single observation and understanding the rationale
    behind the model''s decision. In this section, we will introduce you to a technique
    called **Locally Interpretable Model-Agnostic Explanations** (**LIME**).'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 训练完我们的模型后，我们通常会用它来预测未见数据的结果。我们之前看到的全局解释方法，如模型系数、变量重要性和部分依赖图，提供了关于特征的整体信息。有时候，我们希望了解在特定情况下是什么因素影响了模型的预测结果。例如，如果你的模型是用来评估为新客户提供信用的风险，你可能想了解为什么它拒绝了某个特定客户的申请。这就是局部解释的作用：分析单个观测值并理解模型决策背后的逻辑。在本节中，我们将向你介绍一种名为**局部可解释模型无关解释**（**LIME**）的技术。
- en: 'If we are using a linear model, it is extremely easy to understand the contribution
    of each variable to the predicted outcome. We just need to look at the coefficients
    of the model. For instance, the model will learn the following function: `y =
    100 + 0.2 * x`1 `+ 200 * x`2 `- 180 * x`3\. So, if we received an observation
    of x1=0, x2=2 and x3=1, we would know the contribution of:'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们使用线性模型，那么理解每个变量对预测结果的贡献是非常简单的。我们只需要查看模型的系数。例如，模型将学习如下的函数：`y = 100 + 0.2
    * x`1 `+ 200 * x`2 `- 180 * x`3。假设我们收到一个观测值：x1=0，x2=2，x3=1，我们就可以知道：
- en: x1 was 0.2 * 0 = 0
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: x1的贡献是0.2 * 0 = 0
- en: x2 was 200 * 2 = +400
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: x2的贡献是200 * 2 = +400
- en: x3 was -180 * 1 = -180
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: x3的贡献是-180 * 1 = -180
- en: So, the final prediction (100 +0 + 400 -180 = 320) was mainly driven by x2\.
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，最终的预测结果（100 + 0 + 400 - 180 = 320）主要是由x2驱动的。
- en: But for a nonlinear model, it is quite hard to get such a clear view. LIME is
    one way to get more visibility in such cases. The underlying logic of LIME is
    to approximate the original nonlinear model with a linear one. Then, it uses the
    coefficients of that linear model in order to explain the contribution of each
    variable, as we just saw in the preceding example. But rather than trying to approximate
    the entire model for the whole dataset, LIME tries to approximate it locally around
    the observation you are interested in. LIME uses the trained model to predict
    new data points near your observation and then fit a linear regression on that
    predicted data.
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 但是对于一个非线性模型来说，要获得如此清晰的视图是相当困难的。LIME是一种在这种情况下提高可见性的方式。LIME的基本逻辑是用线性模型来逼近原始的非线性模型。然后，它使用该线性模型的系数来解释每个变量的贡献，正如我们在前面的例子中所看到的那样。但LIME并不是尝试为整个数据集逼近整个模型，而是尝试在你感兴趣的观测值周围进行局部逼近。LIME使用训练好的模型来预测靠近你观测值的新数据点，然后在这些预测数据上拟合一个线性回归模型。
- en: 'Let''s see how we can use it on the Breast Cancer dataset. First, we will load
    the data and train a Random Forest model:'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何在乳腺癌数据集上使用它。首先，我们将加载数据并训练一个随机森林模型：
- en: '[PRE67]'
  id: totrans-391
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'The `lime` package is not directly accessible on Google Colab, so we need to
    manually install it with the following command:'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: '`lime`包在Google Colab上无法直接访问，因此我们需要使用以下命令手动安装它：'
- en: '[PRE68]'
  id: totrans-393
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'The output will be as follows:'
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 9.34: Installation logs for the lime package'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.34：LIME包的安装日志'
- en: '](img/B15019_09_34.jpg)'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_09_34.jpg)'
- en: 'Figure 9.34: Installation logs for the lime package'
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.34：LIME包的安装日志
- en: 'Once installed, we will instantiate the `LimeTabularExplainer` class by providing
    the training data, the names of the features, the names of the classes to be predicted,
    and the task type (in this example, it is `classification`):'
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 安装完成后，我们将通过提供训练数据、特征名称、要预测的类别名称和任务类型（在本例中是`分类`）来实例化`LimeTabularExplainer`类：
- en: '[PRE69]'
  id: totrans-399
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'Then, we will call the `.explain_instance()` method with the observations we
    are interested in (here, it will be the second observation from the testing set)
    and the function that will predict the outcome probabilities (here, it is `.predict_proba()`).
    Finally, we will call the `.show_in_notebook()` method to display the results
    from `lime`:'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将调用`.explain_instance()`方法，传入我们感兴趣的观测值（这里是测试集中的第二个观测值）和用于预测结果概率的函数（这里是`.predict_proba()`）。最后，我们将调用`.show_in_notebook()`方法来显示`lime`的结果：
- en: '[PRE70]'
  id: totrans-401
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'The output will be as follows:'
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 9.35: Output of LIME'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.35：LIME 输出'
- en: '](img/B15019_09_35.jpg)'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_09_35.jpg)'
- en: 'Figure 9.35: Output of LIME'
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.35：LIME 输出
- en: Note
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Your output may differ slightly. This is due to the random sampling process
    of LIME.
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 你的输出可能会略有不同。这是由于 LIME 的随机采样过程所致。
- en: 'There is a lot of information in the preceding output. Let''s go through it
    a bit at a time. The left-hand side shows the prediction probabilities for the
    two classes of the target variable. For this observation, the model thinks there
    is a 0.85 probability that the predicted value will be malignant:'
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的输出包含了大量信息。我们来逐步分析。左侧显示了目标变量两个类别的预测概率。对于此观察，模型认为预测值为恶性的概率为 0.85：
- en: '![Figure 9.36: Prediction probabilities from LIME'
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.36：来自 LIME 的预测概率'
- en: '](img/B15019_09_36.jpg)'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_09_36.jpg)'
- en: 'Figure 9.36: Prediction probabilities from LIME'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.36：来自 LIME 的预测概率
- en: 'The right-hand side shows the value of each feature for this observation. Each
    feature is color-coded to highlight its contribution toward the possible classes
    of the target variable. The list sorts the features by decreasing importance.
    In this example, the mean perimeter, mean area, and area error contributed to
    the model to increase the probability toward class 1\. All the other features
    influenced the model to predict outcome 0:'
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 右侧显示了该观察的每个特征的值。每个特征都用颜色编码，以突出其对目标变量可能类别的贡献。列表按特征重要性递减排序。在这个例子中，`mean perimeter`、`mean
    area` 和 `area error` 特征对模型的贡献使得预测类别 1 的概率增加。所有其他特征则促使模型预测结果为 0：
- en: '![Figure 9.37: Value of the feature for the observation of interest'
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.37：感兴趣观察的特征值'
- en: '](img/B15019_09_37.jpg)'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_09_37.jpg)'
- en: 'Figure 9.37: Value of the feature for the observation of interest'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.37：感兴趣观察的特征值
- en: 'Finally, the central part shows how each variable contributed to the final
    prediction. In this example, the `worst concave points` and `worst compactness`
    variables led to an increase of, respectively, 0.10 and 0.05 probability in predicting
    outcome 0\. On the other hand, `mean perimeter` and `mean area` both contributed
    to an increase of 0.03 probability of predicting class 1:'
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，中央部分显示了每个变量对最终预测的贡献。在这个例子中，`worst concave points` 和 `worst compactness` 变量分别导致了预测结果
    0 的概率分别增加了 0.10 和 0.05。另一方面，`mean perimeter` 和 `mean area` 两个变量分别对预测类别 1 的概率增加了
    0.03：
- en: '![Figure 9.38: Contribution of each feature to the final prediction'
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.38：各特征对最终预测的贡献'
- en: '](img/B15019_09_38.jpg)'
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15019_09_38.jpg)'
- en: 'Figure 9.38: Contribution of each feature to the final prediction'
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.38：各特征对最终预测的贡献
- en: It's as simple as that. With LIME, we can easily see how each variable impacted
    the probabilities of predicting the different outcomes of the model. As you saw,
    the LIME package not only computes the local approximation but also provides a
    visual representation of its results. It is much easier to interpret than looking
    at raw outputs. It is also very useful for presenting your findings and illustrating
    how different features influenced the prediction of a single observation.
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 就这么简单。使用 LIME，我们可以轻松查看每个变量如何影响预测模型不同结果的概率。如你所见，LIME 包不仅计算了局部近似，还提供了其结果的可视化表示。比查看原始输出更容易解释。它也非常有助于展示你的发现并说明不同特征如何影响单个观察的预测。
- en: 'Exercise 9.05: Local Interpretation with LIME'
  id: totrans-421
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 9.05：使用 LIME 进行局部解释
- en: In this exercise, we will analyze some predictions from a Random Forest classifier
    model trained to predict the customer drop-out ratio using LIME.
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们将分析一个训练好的随机森林分类模型的预测结果，该模型用于使用 LIME 预测客户流失率。
- en: We will be using the same dataset as in the previous exercise.
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用与前一个练习相同的数据集。
- en: Open a new Colab notebook.
  id: totrans-424
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个新的 Colab 笔记本。
- en: 'Import the following packages: `pandas`, `train_test_split` from `sklearn.model_selection`,
    and `RandomForestRegressor` from `sklearn.ensemble`:'
  id: totrans-425
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入以下包：`pandas`、`train_test_split` 来自 `sklearn.model_selection` 和 `RandomForestRegressor`
    来自 `sklearn.ensemble`：
- en: '[PRE71]'
  id: totrans-426
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'Create a variable called `file_url` that contains the URL of the dataset:'
  id: totrans-427
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为 `file_url` 的变量，包含数据集的 URL：
- en: '[PRE72]'
  id: totrans-428
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'Load the dataset into a DataFrame called `df` using `.read_csv()`:'
  id: totrans-429
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `.read_csv()` 将数据集加载到一个名为 `df` 的 DataFrame 中：
- en: '[PRE73]'
  id: totrans-430
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'Extract the `rej` column using `.pop()` and save it into a variable called
    `y`:'
  id: totrans-431
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `.pop()` 提取 `rej` 列并将其保存到一个名为 `y` 的变量中：
- en: '[PRE74]'
  id: totrans-432
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'Split the DataFrame into training and testing sets using `train_test_split()`
    with `test_size=0.3` and `random_state = 1`:'
  id: totrans-433
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`train_test_split()`将DataFrame分割为训练集和测试集，`test_size=0.3`，`random_state=1`：
- en: '[PRE75]'
  id: totrans-434
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'Instantiate `RandomForestRegressor` with `random_state=1`, `n_estimators=50`,
    `max_depth=6`, and `min_samples_leaf=60`:'
  id: totrans-435
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`random_state=1`、`n_estimators=50`、`max_depth=6`和`min_samples_leaf=60`实例化`RandomForestRegressor`：
- en: '[PRE76]'
  id: totrans-436
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'Train the model on the training set using `.fit()`:'
  id: totrans-437
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`.fit()`在训练集上训练模型：
- en: '[PRE77]'
  id: totrans-438
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'You should get the following output:'
  id: totrans-439
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您应该获得以下输出：
- en: '![Figure 9.39: Logs of RandomForest'
  id: totrans-440
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图9.39：随机森林日志'
- en: '](img/B15019_09_39.jpg)'
  id: totrans-441
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_09_39.jpg)'
- en: 'Figure 9.39: Logs of RandomForest'
  id: totrans-442
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图9.39：随机森林日志
- en: 'Install the lime package using the `!pip` install command:'
  id: totrans-443
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`!pip`安装命令安装lime包：
- en: '[PRE78]'
  id: totrans-444
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'Import `LimeTabularExplainer` from `lime.lime_tabular`:'
  id: totrans-445
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`lime.lime_tabular`导入`LimeTabularExplainer`：
- en: '[PRE79]'
  id: totrans-446
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'Instantiate `LimeTabularExplainer` with the training set and `mode=''regression''`:'
  id: totrans-447
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用训练集和`mode='regression'`实例化`LimeTabularExplainer`：
- en: '[PRE80]'
  id: totrans-448
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE80]'
- en: 'Display the LIME analysis on the first row of the testing set using `.explain_instance()`
    and `.show_in_notebook()`:'
  id: totrans-449
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`.explain_instance()`和`.show_in_notebook()`显示测试集第一行的LIME分析：
- en: '[PRE81]'
  id: totrans-450
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE81]'
- en: 'You should get the following output:'
  id: totrans-451
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您应该获得以下输出：
- en: '![Figure 9.40: LIME output for the first observation of the testing set'
  id: totrans-452
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图9.40：测试集第一行的LIME输出'
- en: '](img/B15019_09_40.jpg)'
  id: totrans-453
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_09_40.jpg)'
- en: 'Figure 9.40: LIME output for the first observation of the testing set'
  id: totrans-454
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图9.40：测试集第一行的LIME输出
- en: This output shows that the predicted value for this observation is a 0.02 chance
    of customer drop-out and it has been mainly influenced by the `a1pop`, `a3pop`,
    `a2pop`, and `b2eff` features. For instance, the fact that `a1pop` was under 0.87
    has decreased the value of the target variable by 0.01.
  id: totrans-455
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此输出显示，针对该观察值，预测的结果是客户流失的概率为0.02，这主要受`a1pop`、`a3pop`、`a2pop`和`b2eff`特征的影响。例如，`a1pop`低于0.87使目标变量的值减少了0.01。
- en: 'Display the LIME analysis on the third row of the testing set using `.explain_instance()`
    and `.show_in_notebook()`:'
  id: totrans-456
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`.explain_instance()`和`.show_in_notebook()`显示测试集第三行的LIME分析：
- en: '[PRE82]'
  id: totrans-457
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE82]'
- en: 'You should get the following output:'
  id: totrans-458
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您应该获得以下输出：
- en: '![Figure 9.41: LIME output for the third observation of the testing set'
  id: totrans-459
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图9.41：测试集第三行的LIME输出'
- en: '](img/B15019_09_41.jpg)'
  id: totrans-460
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_09_41.jpg)'
- en: 'Figure 9.41: LIME output for the third observation of the testing set'
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.41：测试集第三行的LIME输出
- en: This output shows that the predicted value for this observation is a 0.09 chance
    of customer drop-out and it has been mainly influenced by the `a2pop`, `a3pop`,
    `a1pop`, and `b1eff` features. For instance, the fact that `b1eff` was under 0.87
    has increased the value of the target variable by 0.01\. The `b1eff` feature represents
    the level of efficiency of bank 1, so the results from LIME are telling us that
    the chance of customers leaving increases if this level of efficiency goes lower
    than 0.87.
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: 此输出显示，针对该观察值，预测的结果是客户流失的概率为0.09，这主要受`a2pop`、`a3pop`、`a1pop`和`b1eff`特征的影响。例如，`b1eff`低于0.87使目标变量的值增加了0.01。`b1eff`特征代表银行1的效率水平，因此LIME的结果告诉我们，如果该效率水平低于0.87，客户流失的概率就会增加。
- en: Note
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/2Q5i3Fp](https://packt.live/2Q5i3Fp).
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参考[https://packt.live/2Q5i3Fp](https://packt.live/2Q5i3Fp)。
- en: You can also run this example online at [https://packt.live/327Nl3Z](https://packt.live/327Nl3Z).
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以通过[https://packt.live/327Nl3Z](https://packt.live/327Nl3Z)在线运行此示例。
- en: You have completed the last exercise of this chapter. You saw how to use LIME
    to interpret the prediction of single observations. We learned that the `a1pop`,
    `a2pop`, and `a3pop` features have a strong negative impact on the first and third
    observations of the training set.
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: 您已完成本章的最后一个练习。您了解了如何使用LIME解释单个观察值的预测结果。我们了解到，`a1pop`、`a2pop`和`a3pop`特征对训练集的第一行和第三行观察值有很强的负面影响。
- en: 'Activity 9.01: Train and Analyze a Network Intrusion Detection Model'
  id: totrans-467
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动9.01：训练并分析网络入侵检测模型
- en: You are working for a cybersecurity company and you have been tasked with building
    a model that can recognize network intrusion then analyze its feature importance,
    plot partial dependence, and perform local interpretation on a single observation
    using LIME.
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: 您为一家网络安全公司工作，您的任务是构建一个能够识别网络入侵的模型，然后分析其特征重要性，绘制部分依赖图，并使用LIME对单个观察值进行局部解释。
- en: The dataset provided contains data from 7 weeks of network traffic.
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: 提供的数据集包含7周网络流量的数据。
- en: Note
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'The dataset used in this activity is from KDD Cup 1999:'
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: 本活动中使用的数据集来自KDD Cup 1999：
- en: '[https://packt.live/2tFKUIV](https://packt.live/2tFKUIV).'
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.live/2tFKUIV](https://packt.live/2tFKUIV)'
- en: 'The CSV version of this dataset can be found here:'
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集的CSV版本可以在这里找到：
- en: '[https://packt.live/2RyVsBm](https://packt.live/2RyVsBm).'
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.live/2RyVsBm](https://packt.live/2RyVsBm)'
- en: 'The following steps will help you to complete this activity:'
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤将帮助你完成此活动：
- en: Download and load the dataset using `.read_csv()` from `pandas`.
  id: totrans-476
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`pandas`中的`.read_csv()`下载并加载数据集。
- en: Extract the response variable using `.pop()` from `pandas`.
  id: totrans-477
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`pandas`中的`.pop()`提取响应变量。
- en: Split the dataset into training and test sets using `train_test_split()` from
    `sklearn.model_selection`.
  id: totrans-478
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`sklearn.model_selection`中的`train_test_split()`将数据集划分为训练集和测试集。
- en: Create a function that will instantiate and fit `RandomForestClassifier` using
    `.fit()` from `sklearn.ensemble`.
  id: totrans-479
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个函数，使用`sklearn.ensemble`中的`.fit()`实例化并拟合`RandomForestClassifier`。
- en: Create a function that will predict the outcome for the training and testing
    sets using `.predict()`.
  id: totrans-480
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个函数，使用`.predict()`来预测训练集和测试集的结果。
- en: Create a function that will print the accuracy score for the training and testing
    sets using `accuracy_score()` from `sklearn.metrics`.
  id: totrans-481
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个函数，使用`sklearn.metrics`中的`accuracy_score()`来打印训练集和测试集的准确率。
- en: Compute the feature importance via permutation with `feature_importance_permutation()`
    and display it on a bar chart using `altair`.
  id: totrans-482
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`feature_importance_permutation()`通过置换计算特征重要性，并使用`altair`在条形图上展示。
- en: Plot the partial dependence plot using `plot_partial_dependence` on the `src_bytes`
    variable.
  id: totrans-483
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`plot_partial_dependence`绘制`src_bytes`变量的部分依赖图。
- en: Install `lime` using `!pip install`.
  id: totrans-484
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`!pip install`安装`lime`。
- en: Perform a LIME analysis on row `99893` with `explain_instance()`.
  id: totrans-485
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对行`99893`进行LIME分析，使用`explain_instance()`。
- en: 'The output should be as follows:'
  id: totrans-486
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出应如下所示：
- en: '![Figure 9.42: Output for LIME analysis'
  id: totrans-487
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 9.42：LIME分析的输出](img/B15019_09_42.jpg)'
- en: '](img/B15019_09_42.jpg)'
  id: totrans-488
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15019_09_42.jpg)'
- en: 'Figure 9.42: Output for LIME analysis'
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.42：LIME分析的输出
- en: You have successfully trained a Random Forest model to predict the type of network
    connection. You have also analyzed which features are the most important for this
    Random Forest model and learned that it mainly relies on the `src_bytes` feature.
    We also analyzed the partial dependence plot for this feature in order to understand
    its impact on the `normal` class. Finally, we used LIME to analyze a single observation
    and found out which variables led to the predicted outcome.
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经成功训练了一个随机森林模型来预测网络连接类型。你还分析了哪些特征对这个随机森林模型最为重要，发现它主要依赖于`src_bytes`特征。我们还分析了该特征的部分依赖图，以了解其对`normal`类别的影响。最后，我们使用LIME分析了一个单独的观测值，找出了导致预测结果的变量。
- en: Summary
  id: totrans-491
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'In this chapter, we learned a few techniques for interpreting machine learning
    models. We saw that there are techniques that are specific to the model used:
    coefficients for linear models and variable importance for tree-based models.
    There are also some methods that are model-agnostic, such as variable importance
    via permutation.'
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了一些机器学习模型解释技术。我们看到有些技术是特定于使用的模型的：线性模型的系数和树模型的变量重要性。也有一些方法是模型无关的，例如通过置换计算变量重要性。
- en: All these techniques are global interpreters, which look at the entire dataset
    and analyze the overall contribution of each variable to predictions. We can use
    this information not only to identify which variables have the most impact on
    predictions but also to shortlist them. Rather than keeping all features available
    from a dataset, we can just keep the ones that have a stronger influence. This
    can significantly reduce the computation time for training a model or calculating
    predictions.
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些技术都是全局解释器，它们查看整个数据集并分析每个变量对预测的整体贡献。我们可以利用这些信息来识别哪些变量对预测影响最大，并将其筛选出来。与其保留数据集中所有的特征，不如只保留那些影响力较大的特征。这可以显著减少训练模型或计算预测时的计算时间。
- en: We also went through a local interpreter scenario with LIME, which analyzes
    a single observation. It helped us to better understand the decisions made by
    the model in predicting the final outcome for a given case. This is a very powerful
    tool to assess whether a model is biased toward a specific variable that could
    contain sensitive information such as personal details or demographic data. We
    can also use it to compare two different observations and understand the rationale
    for getting different outcomes from the model.
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还通过LIME进行了本地解释器场景的分析，该方法分析了单个观察值。它帮助我们更好地理解模型在预测给定案例的最终结果时所做的决策。这是一个非常强大的工具，可以评估模型是否对某些可能包含敏感信息（如个人详细信息或人口统计数据）的变量存在偏向。我们还可以使用它比较两个不同的观察值，并理解模型产生不同结果的原因。
- en: In the next chapter, we will be focusing on analyzing a dataset and will learn
    exploratory data analysis and data visualization techniques to get a good understanding
    of the information it contains.
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将重点分析一个数据集，并学习探索性数据分析和数据可视化技术，以便深入了解其中包含的信息。
