- en: '11'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '11'
- en: Consuming Time Series Data
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 消耗时间序列数据
- en: In this chapter about time series analysis, we will explore the fundamental
    concepts, methodologies, and practical applications of time series across various
    industries. Time series analysis involves studying data points collected over
    time to identify patterns and trends and make predictions.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章关于时间序列分析的内容中，我们将探索时间序列的基本概念、方法论以及在不同行业中的实际应用。时间序列分析涉及研究随时间收集的数据点，以识别模式和趋势并进行预测。
- en: 'In this chapter, we will deep dive into the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将深入探讨以下主题：
- en: Understanding the components of time series data
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解时间序列数据的组成部分
- en: Types of time series data
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 时间序列数据的类型
- en: Identifying missing values in time series data
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别时间序列数据中的缺失值
- en: Handling missing values in time series data
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理时间序列数据中的缺失值
- en: Analyzing time series data
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析时间序列数据
- en: Dealing with outliers
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理离群值
- en: Feature engineering with time series data
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用时间序列数据进行特征工程
- en: Applying time series techniques in different industries
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在不同行业应用时间序列技术
- en: Technical requirements
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: The complete code for this chapter can be found in this book’s GitHub repository
    at [https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/tree/main/chapter11](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/tree/main/chapter11).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的完整代码可以在本书的 GitHub 仓库中找到，网址为 [https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/tree/main/chapter11](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/tree/main/chapter11)。
- en: 'Run the following code to install all the necessary libraries we will use in
    this chapter:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 运行以下代码以安装我们在本章中将使用的所有必要库：
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Understanding the components of time series data
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解时间序列数据的组成部分
- en: Time series data refers to a sequence of observations or measurements that are
    collected and recorded *over time*. Unlike non-sequential data, where observations
    are taken at a single point in time, time series data captures information at
    multiple points in a sequential order. Each data point in a time series is associated
    with a specific timestamp, creating a temporal structure that allows trends, patterns,
    and dependencies to be analyzed over time. Let’s discuss the different components
    of the time series data, starting with the trend.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列数据是指一系列在*时间*上收集和记录的观察值或测量值。与非顺序数据不同，后者的观察值是在单一时间点采集的，时间序列数据则是在多个时间点按顺序捕捉信息。时间序列中的每个数据点都与特定的时间戳相关联，从而形成一个时间结构，允许分析随时间变化的趋势、模式和依赖关系。接下来，我们将讨论时间序列数据的不同组成部分，从趋势开始。
- en: Trend
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 趋势
- en: The **trend** component represents the long-term movement or direction in the
    data. It reflects the overall pattern that persists over an extended period, indicating
    whether the values are generally increasing, decreasing, or remaining relatively
    constant.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**趋势**组件表示数据中的长期变化或方向。它反映了一个持续较长时间的整体模式，指示值是普遍增加、减少，还是相对保持恒定。'
- en: 'Trends have the following characteristics:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 趋势具有以下特征：
- en: '**Upward trend**: Values systematically increase over time'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**上升趋势**：数值随时间系统性增加'
- en: '**Downward trend**: Values systematically decrease over time'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**下降趋势**：数值随时间系统性减少'
- en: '**Flat trend**: Values remain relatively constant over time'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**平稳趋势**：数值在时间上保持相对恒定'
- en: Identifying the trend is essential for making informed decisions about the long-term
    behavior of the phenomenon being observed. It provides insights into the overall
    direction and can be valuable for forecasting future trends. In the following
    section, we will present a use case inspired by the data world that focuses on
    the trend component.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 确定趋势对做出关于所观察现象长期行为的明智决策至关重要。它提供了整体方向的洞察，并且对预测未来趋势具有重要价值。在接下来的部分中，我们将呈现一个灵感来自数据世界的用例，重点关注趋势组件。
- en: Analyzing long-term sales trends
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分析长期销售趋势
- en: 'In this use case, we aim to analyze a decade-long sales trend to understand
    the growth pattern of a business from 2010 to 2020\. You can find the code for
    this example in this book’s GitHub repository at [https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter11/1.decomposing_time_series/trend.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter11/1.decomposing_time_series/trend.py).
    Let’s get started:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个案例中，我们旨在分析十年来的销售趋势，以了解 2010 到 2020 年间企业的增长模式。你可以在本书的 GitHub 仓库中找到此示例的代码：[https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter11/1.decomposing_time_series/trend.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter11/1.decomposing_time_series/trend.py)。让我们开始吧：
- en: 'We will start by generating a date range and corresponding sales data for each
    month over 10 years:'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将首先生成一个日期范围，并为每个月生成相应的销售数据，覆盖 10 年：
- en: '[PRE1]'
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Then, we must plot the data to visualize the upward trend:'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们必须绘制数据以可视化上升趋势：
- en: '[PRE2]'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'This will result in the following graph:'
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将产生以下图表：
- en: '![Figure 11.1 – Monthly sales data with upward trend](img/B19801_11_1.jpg)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.1 – 具有上升趋势的月度销售数据](img/B19801_11_1.jpg)'
- en: Figure 11.1 – Monthly sales data with upward trend
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.1 – 具有上升趋势的月度销售数据
- en: '*Figure 11**.1* shows a consistent upward trend in sales over the decade. This
    indicates that the business has been growing steadily.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 11.1* 显示了十年来销售额的持续上升趋势。这表明业务一直在稳步增长。'
- en: In our initial analysis, we focused on understanding the overall upward trend
    in sales data over a decade. This provided us with valuable insights into the
    long-term growth of the business.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的初步分析中，我们集中在理解销售数据中十年间的总体上升趋势。这为我们提供了有关企业长期增长的宝贵洞察。
- en: Often, businesses experience fluctuations that recur regularly within specific
    periods, such as months or quarters. This is known as seasonality. Recognizing
    these seasonal patterns can be just as crucial as understanding the overall trend
    as it helps businesses anticipate and prepare for periods of high or low demand.
    To illustrate this, let’s extend our analysis so that it includes seasonality
    in the sales data.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，企业会经历在特定时间段内定期出现的波动，如月份或季度。这被称为季节性。识别这些季节性模式和理解整体趋势同样重要，因为它可以帮助企业预测并为高需求或低需求时期做好准备。为了说明这一点，我们将扩展我们的分析，加入销售数据中的季节性因素。
- en: Seasonality
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 季节性
- en: '**Seasonality** refers to the repetitive and predictable patterns that occur
    at regular intervals within the time series. These patterns often correspond to
    specific time frames, such as days, months, or seasons, and can be influenced
    by external factors such as weather, holidays, or cultural events.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**季节性** 是指在时间序列中定期出现的重复且可预测的模式。这些模式通常对应于特定的时间段，如天、月或季节，并且可能受外部因素如天气、假期或文化事件的影响。'
- en: Unlike long-term trends, seasonality spans shorter time frames, exerting a short-term
    influence on the data. This recurring nature of seasonality allows businesses
    to anticipate and plan for fluctuations in demand, thereby optimizing their operations
    and strategies.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 与长期趋势不同，季节性跨越较短的时间框架，对数据产生短期影响。季节性的这种周期性特征使得企业能够预测并规划需求波动，从而优化其运营和战略。
- en: Important note
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: Understanding seasonality helps in identifying recurring patterns and predicting
    when certain behaviors or events are likely to occur. This information is crucial
    for accurate forecasting and planning.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 了解季节性有助于识别重复出现的模式，并预测某些行为或事件可能发生的时间。这些信息对于准确的预测和规划至关重要。
- en: In the following section, we will extend the sales use case presented previously
    while focusing on the seasonal component.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分，我们将扩展之前提出的销售案例，同时关注季节性因素。
- en: Analyzing long-term sales trends with seasonality
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分析带有季节性的长期销售趋势
- en: 'In this part of the use case, we aim to analyze a decade-long sales trend that
    includes seasonal variations. You can find the full code example here: [https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter11/1.decomposing_time_series/seasonality.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter11/1.decomposing_time_series/seasonality.py).
    Let’s get started:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个用例的这一部分，我们旨在分析包括季节性变化的十年销售趋势。你可以在这里找到完整的代码示例：[https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter11/1.decomposing_time_series/seasonality.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter11/1.decomposing_time_series/seasonality.py)。让我们开始吧：
- en: 'We will start by generating a date range and corresponding sales data for each
    month over 10 years:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将从为每个月生成一个日期范围，并相应地生成销售数据开始，覆盖 10 年：
- en: '[PRE3]'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Then, we must plot the data to visualize the seasonal component:'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们必须绘制数据，以可视化季节性成分：
- en: '![Figure 11.2 – Monthly sales data with seasonality](img/B19801_11_2.jpg)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.2 – 带有季节性因素的月度销售数据](img/B19801_11_2.jpg)'
- en: Figure 11.2 – Monthly sales data with seasonality
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.2 – 带有季节性因素的月度销售数据
- en: '*Figure 11**.2* reveals a repeating pattern every 12 months, indicating a clear
    seasonality in sales. Sales peak around mid-year and drop toward the end and beginning
    of the year, suggesting higher sales in summer and lower sales in winter. This
    pattern’s consistency over the years can aid in predicting future sales cycles.
    Understanding these seasonal trends is valuable for inventory management, marketing
    campaigns, and resource allocation during peak sales periods, allowing businesses
    to optimize their strategies accordingly.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 11.2* 显示了每 12 个月重复的模式，表明销售中存在明显的季节性。销售在年中达到高峰，并在年末和年初下降，暗示着夏季的销售较高，冬季的销售较低。这一模式在多年中的一致性有助于预测未来的销售周期。了解这些季节性趋势对库存管理、营销活动和在销售高峰期的资源分配非常有价值，帮助企业相应优化策略。'
- en: 'While identifying trends and seasonality provides valuable insights into sales
    patterns, real-world data often contains another critical component: noise. In
    the following section, we will deep dive into noise and extend the sales use case
    so that it explores how noise affects sales.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然识别趋势和季节性提供了对销售模式的宝贵见解，但现实世界的数据通常还包含另一个关键成分：噪声。在接下来的部分，我们将深入探讨噪声，并扩展销售用例，以探索噪声如何影响销售。
- en: Noise
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 噪声
- en: '**Noise**, also known as residuals or errors, represents the random fluctuations
    or irregularities in the time series data that cannot be attributed to the trend
    or seasonality. It reflects the variability in the data that is not explained
    by the underlying patterns.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**噪声**，也称为残差或误差，代表时间序列数据中无法归因于趋势或季节性的随机波动或不规则性。它反映了数据中的变化性，这些变化性无法通过基础模式来解释。'
- en: Important note
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 重要说明
- en: While noise is often considered unwanted, it is a natural part of any real-world
    data. Recognizing and isolating noise is essential for building accurate models
    and understanding the inherent uncertainty in the time series.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然噪声通常被认为是不需要的，但它是任何现实世界数据的自然组成部分。识别并隔离噪声对于构建准确的模型和理解时间序列中固有的不确定性至关重要。
- en: In the following section, we will extend the sales use case presented previously
    while focusing on noise.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分，我们将扩展前面介绍的销售用例，并重点关注噪声。
- en: Analyzing sales data with noise
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分析带噪声的销售数据
- en: 'In this use case, we aim to analyze sales data that includes noise, in addition
    to trends and seasonality. This will help us understand how random fluctuations
    impact our ability to identify underlying patterns. To follow along with this
    example, take a look at the following code: [https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter11/1.decomposing_time_series/noise.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter11/1.decomposing_time_series/noise.py).
    Let’s get started:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个用例中，我们旨在分析包含噪声的销售数据，除了趋势和季节性因素外。这将帮助我们理解随机波动如何影响我们识别潜在模式的能力。要跟随这个示例，请查看以下代码：[https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter11/1.decomposing_time_series/noise.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter11/1.decomposing_time_series/noise.py)。让我们开始吧：
- en: 'Let’s import the required libraries:'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们导入所需的库：
- en: '[PRE4]'
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We will start by generating a date range for each month over 10 years:'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将从生成一个覆盖 10 年的每月日期范围开始：
- en: '[PRE5]'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Then, we must create sales data with noise:'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们必须创建带噪声的销售数据：
- en: '[PRE6]'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Now, we must plot the data to visualize the noise:'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们必须绘制数据以可视化噪声：
- en: '![Figure 11.3 – Monthly sales data with noise](img/B19801_11_3.jpg)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.3 – 带噪声的每月销售数据](img/B19801_11_3.jpg)'
- en: Figure 11.3 – Monthly sales data with noise
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.3 – 带噪声的每月销售数据
- en: '*Figure 11**.3* shows random, unpredictable variations that do not follow any
    specific pattern. These fluctuations occur over short timeframes, creating instability
    in the data and making it harder to see any patterns.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 11.3* 显示了随机、不可预测的变化，这些变化没有遵循任何特定模式。这些波动发生在短时间内，导致数据的不稳定，使得更难看出任何模式。'
- en: Now that we can identify the different time series components, let’s have a
    look at the different types of time series.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以识别不同的时间序列组件，让我们来看看不同类型的时间序列。
- en: Types of time series data
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 时间序列数据的类型
- en: In this section, we will quickly revise the types of time series data – univariate
    and multivariate – while clarifying their distinctions and showcasing their applications.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将简要回顾时间序列数据的类型——单变量和多变量——同时阐明它们的区别，并展示它们的应用。
- en: Univariate time series data
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 单变量时间序列数据
- en: '**Univariate time series data** consists of a single variable or observation
    recorded over time. It is a one-dimensional time-ordered sequence, making it simpler
    to analyze compared to multivariate time series data.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '**单变量时间序列数据**由单个变量或观察值在时间上记录而成。它是一个一维的按时间顺序排列的序列，相较于多变量时间序列数据，它更易于分析。'
- en: 'Consider a univariate time series representing the monthly average temperature
    in a city over several years. You can find the full code here: [https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter11/2.types/univariate.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter11/2.types/univariate.py).'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个单变量时间序列，表示一个城市多年来每月的平均温度。你可以在这里找到完整的代码：[https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter11/2.types/univariate.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter11/2.types/univariate.py)。
- en: 'Let’s generate our univariate time series data:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们生成我们的单变量时间序列数据：
- en: 'First, we will create the data range we want, in this case from `2010-01-01`
    to `2020-12-31`:'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们将创建我们需要的数据范围，在这个例子中是从`2010-01-01`到`2020-12-31`：
- en: '[PRE7]'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Then, we must create the corresponding values for the temperatures by adding
    noise using a **normal distribution** (also known as a Gaussian distribution):'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们必须通过使用**正态分布**（也称为高斯分布）添加噪声，来创建温度的相应值：
- en: '[PRE8]'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Let’s understand the value parameters:'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 让我们理解值参数：
- en: '`20`: This is the `5`: This is the **standard deviation** of the normal distribution.
    The noise values will typically vary by about ±5 units from the mean. A larger
    standard deviation means the noise will be more spread out, while a smaller standard
    deviation means the noise values are closer to the mean.'
  id: totrans-81
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`20`：这是`5`：这是正态分布的**标准差**。噪声值通常会围绕均值波动约±5个单位。较大的标准差意味着噪声会更分散，而较小的标准差意味着噪声值更接近均值。'
- en: The date range we created previously is passed as an index to the DataFrame.
  id: totrans-82
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们之前创建的日期范围被作为索引传递给数据框。
- en: 'Now, let’s plot the univariate time series data:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们绘制单变量时间序列数据：
- en: '[PRE9]'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'This will output the following plot:'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将输出以下图表：
- en: '![Figure 11.4 – Univariate temperature data](img/B19801_11_4.jpg)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.4 – 单变量温度数据](img/B19801_11_4.jpg)'
- en: Figure 11.4 – Univariate temperature data
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.4 – 单变量温度数据
- en: In this example, the univariate time series represents the monthly average temperature.
    Since the data is randomly generated with a mean of 20°C and some variation (a
    standard deviation of 5°C), the plot will exhibit random fluctuations around this
    average temperature.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，单变量时间序列代表了每月的平均温度。由于数据是随机生成的，均值为20°C，并有一定的波动（标准差为5°C），因此图表将表现出围绕该平均温度的随机波动。
- en: Understanding the complexities of univariate time series data lays a solid foundation
    for delving into multivariate time series analysis. Unlike univariate data, which
    involves observing a single variable over time, multivariate time series data
    involves monitoring multiple interrelated variables simultaneously.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 理解单变量时间序列数据的复杂性为深入研究多变量时间序列分析打下了坚实的基础。与单变量数据只观察单一变量随时间的变化不同，多变量时间序列数据涉及同时监测多个相互关联的变量。
- en: Multivariate time series data
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多元时间序列数据
- en: '**Multivariate time series data** involves multiple variables or observations
    recorded over time. Each variable is a time-ordered sequence, and the variables
    may be interdependent, capturing more complex relationships.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '**多元时间序列数据**涉及多个变量或观察值，这些变量或观察值是随着时间记录的。每个变量都是一个按时间顺序排列的序列，并且这些变量可能是相互依赖的，从而捕捉到更复杂的关系。'
- en: 'Consider a multivariate time series representing both the monthly average temperature
    and monthly rainfall in a city over several years. You can find the code for this
    example at [https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter11/2.types/multivariate.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter11/2.types/multivariate.py).
    Let’s get started:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个多元时间序列，表示一个城市在多年中的月平均温度和月降水量。你可以在[https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter11/2.types/multivariate.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter11/2.types/multivariate.py)找到这个示例的代码。让我们开始吧：
- en: 'Let’s add the required libraries for this example:'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们为这个示例添加所需的库：
- en: '[PRE10]'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Now, let’s generate an example of multivariate time series data by using the
    temperature data we created previously and adding a new time series in the same
    DataFrame representing the rainfall data with different mean and standard deviation
    values:'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们通过使用之前创建的温度数据并在同一个 DataFrame 中添加一条新的时间序列数据（表示降水量数据，具有不同的均值和标准差值），来生成一个多元时间序列数据示例：
- en: '[PRE11]'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Combine all the time series into the same DataFrame, making sure to include
    both temperature and rainfall data:'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将所有时间序列合并到同一个 DataFrame 中，确保包含温度和降水量数据：
- en: '[PRE12]'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The combined time series DataFrame is shown here:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 合并后的时间序列 DataFrame 如下所示：
- en: '[PRE13]'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Finally, let’s plot the multivariate time series data:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，让我们绘制多元时间序列数据：
- en: '![Figure 11.5 – Multivariate data](img/B19801_11_5.jpg)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.5 – 多元数据](img/B19801_11_5.jpg)'
- en: Figure 11.5 – Multivariate data
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.5 – 多元数据
- en: In this example, the multivariate time series includes both temperature and
    rainfall data, providing a more comprehensive view of environmental conditions.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，多元时间序列包括温度和降水量数据，提供了一个更全面的环境条件视角。
- en: Overall, univariate data is simpler to work with, while multivariate data allows
    us to capture more complex relationships and dependencies between variables over
    time. Multivariate analysis is essential for tackling real-world challenges in
    diverse fields such as economics, finance, environmental science, and healthcare,
    where understanding multifaceted relationships among variables is crucial.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，单变量数据较易处理，而多元数据使我们能够捕捉到随时间变化的变量之间更复杂的关系和依赖性。多元分析在解决经济学、金融、环境科学和医疗健康等各个领域的现实挑战时至关重要，在这些领域中，理解变量之间的多方面关系至关重要。
- en: Now that we have a strong understanding of time series data, we can explore
    methods for cleaning and managing this type of data effectively.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们对时间序列数据有了较强的理解，可以探索有效清理和管理这种数据的方法。
- en: Identifying missing values in time series data
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 识别时间序列数据中的缺失值
- en: Identifying missing values in time series data is somewhat like identifying
    missing values in other types of data, but there are specific considerations due
    to the temporal nature of time series. Since we covered some of these techniques
    in [*Chapter 8*](B19801_08.xhtml#_idTextAnchor195), *Detecting and Handling Missing
    Values and Outliers*, let’s summarize them here and highlight their specific adaptations
    for analyzing time series data using a stock market analysis use case.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 识别时间序列数据中的缺失值有点类似于识别其他类型数据中的缺失值，但由于时间序列的时间性特征，存在一些特定的注意事项。由于我们在[*第 8 章*](B19801_08.xhtml#_idTextAnchor195)《检测和处理缺失值和异常值》中讨论过其中的一些技术，让我们在这里总结它们，并重点说明这些技术在分析时间序列数据时的具体应用，使用股票市场分析作为示例。
- en: 'Let’s consider a use case where we have daily stock prices (open, high, low,
    and close) for a particular company over several years. Our goal is to identify
    missing data in this time series to ensure the integrity of the dataset. You can
    find the code for this example here: [https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter11/3.missing_values/1.identify_missing_values.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter11/3.missing_values/1.identify_missing_values.py).'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有某公司多年来每日的股价数据（开盘价、最高价、最低价和收盘价）。我们的目标是识别这些时间序列中的缺失数据，以确保数据集的完整性。你可以在这里找到该示例的代码：[https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter11/3.missing_values/1.identify_missing_values.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter11/3.missing_values/1.identify_missing_values.py)。
- en: 'Let’s start by generating the data:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从生成数据开始：
- en: 'First, we will generate a date range for business days from January 1, 2020,
    to December 31, 2023\. Here, `freq=''B''` is used to generate a range of dates
    that includes only *business days* (weekdays, excluding weekends):'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们将生成从2020年1月1日到2023年12月31日的工作日日期范围。这里，`freq='B'`用于生成仅包括*工作日*（即排除周末）的日期范围：
- en: '[PRE14]'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Next, we must generate random stock prices for the date range with a length
    of *n*:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们必须为日期范围生成随机股价，长度为*n*：
- en: '[PRE15]'
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Next, we must create a DataFrame by passing all the separate data points that
    were created in the previous step:'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们必须通过传递在上一步创建的所有单独数据点来创建一个DataFrame：
- en: '[PRE16]'
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Now, let’s introduce random NaN values to simulate some missing values in the
    data:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们引入随机的NaN值，以模拟数据中的一些缺失值：
- en: '[PRE17]'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Next, drop random dates to simulate missing timestamps:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，随机丢弃一些日期，以模拟缺失的时间戳：
- en: '[PRE18]'
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Finally, display the first few rows of the DataFrame:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，显示DataFrame的前几行：
- en: '[PRE19]'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The key thing to notice here is that we have two kinds of missing data:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 这里需要注意的关键点是，我们有两种缺失数据：
- en: Complete rows missing, so one full date index is not available
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 完整的行缺失，因此没有完整的日期索引可用
- en: Some observations in some of the columns are missing for the current date
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当前日期的某些列中的部分观测值缺失
- en: We will mainly address the first case here as we covered the second case in
    [*Chapter 8*](B19801_08.xhtml#_idTextAnchor195)*, Detecting and Handling Missing
    Values and Outliers*. Let’s start with the simple but effective `isnull()` method.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在这里主要处理第一种情况，因为第二种情况在[*第8章*](B19801_08.xhtml#_idTextAnchor195)*《检测和处理缺失值与异常值》中已经讲过了。让我们从简单而有效的`isnull()`方法开始。
- en: Checking for NaNs or null values
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 检查NaN或空值
- en: 'Unlike regular datasets, time series data points are ordered in time. Missing
    values can break the continuity and affect the analysis of trends and seasonal
    patterns. Let’s use the `isnull()` method to identify missing timestamps. Here,
    we are looking to find complete rows that are missing from the dataset:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 与常规数据集不同，时间序列数据点按时间顺序排列。缺失的值可能会破坏数据的连续性，影响趋势和季节模式的分析。我们可以使用`isnull()`方法来识别缺失的时间戳。这里，我们要查找数据集中缺失的完整行：
- en: 'To check which dates are missing from a time series DataFrame, we need to create
    a full date range (with no missing values) in the frequency of our current DataFrame
    index and compare it against the date range we have in our current DataFrame.
    Here, we are creating a complete date range for business days:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要检查时间序列DataFrame中哪些日期缺失，我们需要创建一个完整的日期范围（没有缺失值），并且该日期范围的频率与当前DataFrame索引的频率一致，然后将其与当前DataFrame中的日期范围进行对比。这里，我们正在为工作日创建一个完整的日期范围：
- en: '[PRE20]'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'To quickly see the missing index points, the DataFrame must be reindexed to
    this complete date range so that we can identify any missing timestamps:'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了快速查看缺失的索引点，必须将DataFrame重新索引到这个完整的日期范围，以便识别任何缺失的时间戳：
- en: '[PRE21]'
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Now, we can use the `isnull()` method to identify any missing timestamps:'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以使用`isnull()`方法来识别任何缺失的时间戳：
- en: '[PRE22]'
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Here, we can see that there are some missing timestamps in the data:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到数据中有一些缺失的时间戳：
- en: '[PRE23]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The analysis so far tells us that we have complete dates missing from the dataset.
    Now, let’s add some visual plots to help us better see the gaps in the data.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止的分析告诉我们，我们的数据集中缺失了完整的日期。现在，让我们添加一些可视化图表，帮助我们更好地看到数据中的空白。
- en: Note
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: As presented in [*Chapter 8*](B19801_08.xhtml#_idTextAnchor195)*, Detecting
    and Handling Missing Values and Outliers*, you can use the `isnull()` method to
    see how many nulls we have in each column – for example, `missing_values =` `df.isnull().sum()`.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 如在[*第 8 章*](B19801_08.xhtml#_idTextAnchor195)*，检测与处理缺失值和异常值*中所述，你可以使用`isnull()`方法查看每列中缺失的数量——例如，`missing_values
    =` `df.isnull().sum()`。
- en: Visual inspection
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 目视检查
- en: Visualizing the data can help us identify missing values and patterns of missingness.
    Plots can reveal gaps in data that are not immediately obvious from a tabular
    inspection.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化数据有助于我们识别缺失值及缺失模式。图表能够揭示数据中的缺口，而这些缺口在表格检查中可能不易察觉。
- en: 'Continuing with the example from the previous section, let’s plot our time
    series data and mark any missing values on our graph:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 继续前一部分的例子，让我们绘制时间序列数据并在图表上标出任何缺失值：
- en: 'Plot the closing prices:'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制闭盘价格图：
- en: '[PRE24]'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Mark missing timestamps with vertical lines:'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用垂直线标记缺失的时间戳：
- en: '[PRE25]'
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'This will result in the following plot:'
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将生成以下图表：
- en: '![Figure 11.6 – Daily closing prices with missing timestamps highlighted](img/B19801_11_6.jpg)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.6 – 日闭盘价及缺失时间戳高亮显示](img/B19801_11_6.jpg)'
- en: Figure 11.6 – Daily closing prices with missing timestamps highlighted
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.6 – 日闭盘价及缺失时间戳高亮显示
- en: In *Figure 11**.6*, the closing prices are plotted in blue with markers, while
    missing timestamps are highlighted with dotted lines, making it easy to see gaps
    in the data. Now, let’s explore the final method, known as lagged analysis. In
    this method, we create a lagged version of the series and compare it with the
    original to detect inconsistencies.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图 11.6*中，闭盘价格用蓝色标记显示，而缺失的时间戳用虚线高亮，便于识别数据中的缺口。现在，让我们探讨最后一种方法，称为滞后分析。在这种方法中，我们创建一个滞后的序列版本，并与原始数据进行比较，以检测不一致之处。
- en: Note
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: In [*Chapter 3*](B19801_03.xhtml#_idTextAnchor064), *Data Profiling – Understanding
    Data Structure, Quality, and Distribution* we demonstrated various data profiling
    methods. You can apply similar techniques to time series data by using the built-in
    gap analysis feature. Simply pass `tsmode=True` when creating the profile report
    – for example, `profile =` `ProfileReport(df, tsmode=True)`.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第 3 章*](B19801_03.xhtml#_idTextAnchor064)，*数据剖析 – 理解数据结构、质量和分布*中，我们演示了多种数据剖析方法。你可以通过使用内建的缺口分析功能，将类似的方法应用于时间序列数据。只需在创建报告时传递`tsmode=True`即可——例如，`profile
    =` `ProfileReport(df, tsmode=True)`。
- en: As we move forward, it’s essential to explore effective strategies for handling
    missing data in time series.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们深入，探索有效的时间序列缺失数据处理策略变得至关重要。
- en: Handling missing values in time series data
  id: totrans-154
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理时间序列数据中的缺失值
- en: 'Missing values are a common challenge in time series data and can arise due
    to various reasons, such as sensor failures, data transmission issues, or simply
    the absence of recorded observations. As we’ve discussed, two main scenarios often
    arise:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 缺失值是时间序列数据中常见的问题，可能由于多种原因产生，比如传感器故障、数据传输问题，或只是记录观察值的缺失。如我们所讨论的，通常会出现两种主要情况：
- en: '**Some null values in features**: Imagine a stock market analysis where daily
    trading data is collected. While all trading days are accounted for, the volume
    of shares traded on certain days may be missing due to reporting errors. This
    scenario presents a challenge: how do you maintain the integrity of the dataset
    while ensuring that analyses remain robust?'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**某些特征中的空值**：想象一下股票市场分析，其中收集了每日交易数据。虽然所有交易日都已记录，但某些日子的成交量可能由于报告错误而缺失。这种情况带来了一个挑战：如何在确保分析保持稳健的同时，保持数据集的完整性？'
- en: '**Complete rows are missing**: Conversely, consider a weather monitoring system
    that records daily temperatures. If entire days of data are missing – perhaps
    due to sensor failures – this poses a significant issue. Missing timestamps means
    you cannot simply fill in values; the absence of data for those days disrupts
    the entire time series.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**完整行缺失**：相反，考虑一个天气监测系统，它记录每日气温。如果某些完整天的数据缺失——可能是由于传感器故障——这就构成了一个重大问题。缺失的时间戳意味着你不能简单地填充数据；这些天的数据缺失会打乱整个时间序列。'
- en: In the next section, we will focus on solving the first scenario and consider
    the existence of null values in some features. Once we have done this, we can
    adjust it for the second one.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一部分中，我们将重点解决第一种情况，考虑某些特征中缺失值的存在。完成这一步后，我们可以调整方法来处理第二种情况。
- en: Removing missing data
  id: totrans-159
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 删除缺失数据
- en: 'Removing missing data is a straightforward approach, but it should be done
    with caution while considering the impact on the overall dataset. Here are some
    scenarios where removal might be appropriate:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 删除缺失数据是一个直接的方法，但应该谨慎操作，并考虑其对整体数据集的影响。以下是一些可能适合删除数据的场景：
- en: If the missing values constitute a small percentage of the dataset (for example,
    less than 5%), removing them might be feasible. This approach works well if the
    data loss does not significantly impact the analysis or the conclusions drawn
    from the dataset. For example, in a dataset with 10,000 time points, if 50 points
    are missing, removing these 50 points (0.5% of the data) might not significantly
    affect the overall analysis.
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果缺失值占数据集的比例很小（例如，少于5%），删除它们可能是可行的。如果数据丢失不会显著影响分析结果或从数据集得出的结论，这种方法效果较好。例如，在一个包含10,000个时间点的数据集中，如果有50个时间点缺失，删除这50个数据点（占数据的0.5%）可能不会显著影响整体分析。
- en: If imputing missing values would introduce too much uncertainty, especially
    if the values are critical and cannot be accurately estimated. This scenario is
    common when the missing values are highly unpredictable data, making imputation
    unreliable.
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果插补缺失值会引入过多的不确定性，特别是当这些值非常重要且无法准确估计时。这种情况通常出现在缺失值是高度不可预测的数据时，插补结果不可靠。
- en: If missing values occur completely at random and do not follow any systematic
    pattern. An example of this is sensor data where occasional random failures cause
    missing readings, but there is no underlying pattern to these failures.
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果缺失值完全是随机发生的，并且没有遵循任何系统的模式。例如，传感器数据中偶尔出现的随机故障导致缺失读数，但这些故障没有任何潜在的规律。
- en: Let’s revisit the stock market use case and see how we can drop the null values
    to see what effect this has on the dataset.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们重新审视股票市场的使用案例，看看如何删除null值，并观察这对数据集的影响。
- en: Removing missing data in the stock market use case
  id: totrans-165
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 删除缺失数据在股票市场使用案例中的应用
- en: 'In our stock prices data scenario, we will add some NaN values and evaluate
    the impact of removing them. You can find the full code here: [https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter11/3.missing_values/2.remove_missing_values.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter11/3.missing_values/2.remove_missing_values.py).
    Let’s get started:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的股票价格数据场景中，我们将添加一些NaN值，并评估删除这些值的影响。你可以在这里找到完整的代码：[https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter11/3.missing_values/2.remove_missing_values.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter11/3.missing_values/2.remove_missing_values.py)。让我们开始吧：
- en: 'Continuing with the example from the previous section, we will create the stock
    data with the different features. Then, we will randomly select some indexes from
    specific features (for example, `close` and `open`) so that we can map the values
    for each feature of that index to a NaN value:'
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 继续使用上一节的示例，我们将创建具有不同特征的股票数据。然后，我们将从特定特征（例如，`close`和`open`）中随机选择一些索引，以便将该索引的每个特征的值映射为NaN值：
- en: '[PRE26]'
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Then, we will map the indices that were randomly selected before to NaN values:'
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将之前随机选择的索引映射为NaN值：
- en: '[PRE27]'
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Let’s check how many NaNs or null values are available in the data:'
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们检查数据中有多少NaN或null值：
- en: '[PRE28]'
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: As expected, some null values were introduced on the `open` and `close` features.
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 正如预期的那样，`open`和`close`特征中引入了一些null值。
- en: 'Let’s check how many rows we have before removing any based on the nulls we
    have in the dataset:'
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在删除数据集中的任何行之前，让我们先检查一下包含null值的数据行数：
- en: '[PRE29]'
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'At this stage, we will drop any rows that have NaN values in either the `close`
    or `low` columns:'
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这个阶段，我们将删除在`close`或`low`列中包含NaN值的任何行：
- en: '[PRE30]'
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Let’s plot the time series data:'
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们绘制时间序列数据：
- en: '![Figure 11.7 – Daily closing prices with missing data to be dropped/flagged](img/B19801_11_7.jpg)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
  zh: '![图11.7 – 删除/标记缺失数据后的每日收盘价格](img/B19801_11_7.jpg)'
- en: Figure 11.7 – Daily closing prices with missing data to be dropped/flagged
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.7 – 删除/标记缺失数据后的每日收盘价格
- en: As shown in *Figure 11**.7*, the original closing prices are plotted, and points
    that were dropped due to missing values are highlighted with red “x” markers.
    Remember that even with selective dropping, removing rows can lead to a loss of
    useful information as it reduces the sample size, which can decrease the statistical
    power of the analysis and affect the generalizability of the results.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 如*图 11.7*所示，原始的收盘价已被绘制，因缺失值被丢弃的点通过红色“x”标记突出显示。请记住，即使是选择性丢弃，删除行也可能会导致有用信息的丧失，因为它减少了样本大小，从而可能降低分析的统计功效并影响结果的普适性。
- en: In scenarios where retaining every timestamp is crucial but missing values within
    features need to be addressed, forward and backward filling offer practical solutions.
    These methods allow us to maintain the chronological integrity of time series
    data while efficiently filling in missing values based on adjacent observations.
    Let’s explore how forward and backward filling can effectively handle missing
    data in time series analyses.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 在需要保留每个时间戳，但需要解决特征中的缺失值的场景中，前向和后向填充提供了实用的解决方案。这些方法允许我们保持时间序列数据的时间顺序完整性，同时根据相邻的观测值高效地填补缺失值。让我们探索一下前向和后向填充如何有效地处理时间序列分析中的缺失数据。
- en: Forward and backward fill
  id: totrans-183
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 前向填充和后向填充
- en: '**Forward fill** (**ffill**) and **backward fill** (**bfill**) are methods
    of imputing missing values by propagating the last known value forward or the
    next known value backward in the time series, respectively.'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '**Forward fill**（**ffill**）和**backward fill**（**bfill**）是通过将最后已知值向前传播或将下一个已知值向后传播来填补缺失值的两种方法，分别用于时间序列中的缺失数据。'
- en: 'When dealing with time series backfilling, the choice between ffill and bfill
    depends on several factors and use cases. Here’s an overview of when to use each
    approach and the thought process behind these decisions:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理时间序列反向填充时，选择**ffill**和**bfill**之间的方式取决于多个因素和使用场景。以下是何时使用每种方法的概述，以及做出这些决策时的思考过程：
- en: '**Ffill**: Forward filling, also known as **last observation carried forward**
    (**LOCF**), propagates the last known value forward to fill in missing data points.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Ffill**：前向填充，也称为**最后观测值向前填充**（**LOCF**），是将最后已知值向前传播以填补缺失的数据点。'
- en: 'Here’s when you should use it:'
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是你应该使用它的情况：
- en: When you believe the most recent known value is the best predictor of missing
    future values
  id: totrans-188
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当你认为最近已知的值是预测未来缺失值的最佳依据时
- en: In financial time series, where carrying forward the last known price is often
    a reasonable assumption
  id: totrans-189
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在金融时间序列中，将最后已知价格向前传播通常是一个合理的假设
- en: When dealing with slowly changing variables where persistence is a good assumption
  id: totrans-190
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在处理缓慢变化的变量时，如果假设其持续性较好
- en: In scenarios where you want to maintain the most recent state until new information
    becomes available
  id: totrans-191
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在你希望保持最近状态，直到新的信息变得可用时
- en: 'If you’re still uncertain or find yourself pondering which method to use, answering
    “yes” to at least two of the following three questions can guide you in the right
    direction:'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果你仍然不确定，或者在思考该使用哪种方法时，回答以下三个问题中的至少两个“是”将帮助你做出正确的决策：
- en: Is the variable likely to remain relatively stable over short periods?
  id: totrans-193
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该变量是否可能在短时间内保持相对稳定？
- en: Would using the last known value be a reasonable assumption for the missing
    data?
  id: totrans-194
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用最后已知值作为缺失数据的合理假设吗？
- en: Is it more important to reflect the most recent known state rather than potential
    future changes?
  id: totrans-195
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是不是更重要的是反映最近已知的状态，而不是潜在的未来变化？
- en: '**Bfill**, on the other hand, propagates the next known value backward to fill
    in missing data points.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Bfill**：与此相反，后向填充是将下一个已知值向后传播以填补缺失的数据点。'
- en: 'Here’s when you should use it:'
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是你应该使用它的情况：
- en: When you have more confidence in future values than past values
  id: totrans-198
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当你对未来的值比过去的值更有信心时
- en: In scenarios where you want to retroactively apply known outcomes to previous
    missing periods
  id: totrans-199
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在你希望将已知的结果追溯性地应用于之前缺失的时间段时
- en: When you’re dealing with lagged effects where future events influence past missing
    data
  id: totrans-200
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当你处理滞后效应时，未来的事件会影响过去的缺失数据
- en: In cases where you want to align data with the next known state rather than
    the previous one
  id: totrans-201
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在你希望将数据与下一个已知状态对齐，而不是与之前的状态对齐时
- en: 'If you’re still uncertain or find yourself pondering which method to use, answering
    “yes” to the following questions will guide you in the right direction:'
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果你仍然不确定，或者在思考该使用哪种方法时，回答以下问题中的“是”将帮助你做出正确的决策：
- en: Is the next known value likely to be more representative of the missing data
    than the previous known value?
  id: totrans-203
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 下一个已知值是否更有可能代表缺失数据而不是前一个已知值？
- en: Are you dealing with a scenario where future information should inform past
    missing values?
  id: totrans-204
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您是否处理一种情况，即未来信息应该通知过去的缺失值？
- en: Would aligning with the next known state provide more meaningful insights for
    your analysis?
  id: totrans-205
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是否与下一个已知状态对齐能为您的分析提供更有意义的见解？
- en: In practice, choosing between ffill and bfill often requires a combination of
    domain expertise, understanding of the data generation process, and consideration
    of the specific analytical goals. It’s also worth experimenting with both methods
    and comparing the results to see which provides more meaningful and accurate insights
    for your particular use case.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，选择 ffill 和 bfill 通常需要结合领域专业知识、对数据生成过程的理解以及考虑特定分析目标。同时，值得尝试两种方法并比较结果，看哪一种为您的特定用例提供更有意义和准确的见解。
- en: 'As always, there are some important considerations when using ffill and bfill
    in time series data. Let’s expand on those:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 ffill 和 bfill 处理时间序列数据时，始终有一些重要的考虑因素。让我们扩展一下：
- en: '**Sequential nature**: The sequential nature of time series data is indeed
    crucial for both ffill and bfill methods. Both methods rely on the assumption
    that adjacent data points are related, which is fundamental to time series analysis.'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**顺序性质**：时间序列数据的顺序性质对于 ffill 和 bfill 方法确实至关重要。这两种方法都依赖于相邻数据点相关的假设，这是时间序列分析的基础。'
- en: '**Ffill and increasing trends**: Ffill can be appropriate for increasing trends
    as it carries forward the last known value, potentially underestimating the true
    value in an upward trend. However, it may lead to a “staircase” effect in strongly
    increasing trends, potentially understating the rate of increase.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Ffill 和上升趋势**：Ffill 可适用于上升趋势，因为它向前延续最后已知的值，可能在上升趋势中低估真实值。然而，在强烈上升趋势中可能会导致“阶梯”效应，可能低估增长率。'
- en: '**Bfill and decreasing trends**: Bfill can be suitable for decreasing trends
    as it pulls back future lower values, potentially overestimating the true value
    in a downward trend. It may create a similar “staircase” effect in strongly decreasing
    trends, potentially overstating the rate of decrease.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Bfill 和下降趋势**：Bfill 可适用于下降趋势，因为它会拉回未来更低的值，可能在下降趋势中高估真实值。在强烈下降趋势中可能会产生类似的“阶梯”效应，可能会夸大下降率。'
- en: The choice between ffill and bfill should consider not just the direction of
    the trend, but also its *strength* and the *length* of missing data periods. For
    subtle trends, either method might be appropriate, and the choice may depend more
    on other factors, such as the nature of the data or the specific analysis goals.
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在选择 ffill 和 bfill 时，应考虑趋势的方向以及缺失数据期间的**强度**和**长度**。对于微妙的趋势，任一方法都可能适用，选择可能更多地取决于其他因素，如数据的性质或具体的分析目标。
- en: Both methods can indeed propagate errors if the missing values are inconsistent
    with surrounding data points. This is particularly problematic for long stretches
    of missing data, where the filled values may significantly deviate from the true
    underlying pattern.
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果缺失值与周围数据点不一致，这两种方法确实可能传播错误。对于长时间的缺失数据，填充值可能会显著偏离真实的基础模式。
- en: '**Handling outliers**: If an outlier precedes or follows a stretch of missing
    data, ffill or bfill can propagate this anomalous value, distorting the series.'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**处理异常值**：如果异常值在一段缺失数据之前或之后，ffill 或 bfill 可能会传播这种异常值，扭曲系列。'
- en: '**Assumption of data continuity**: Both methods assume that the missing data
    can be **reasonably approximated** by adjacent known values, which may not always
    be true. For variables that can change abruptly or have discontinuities, these
    methods may be inappropriate.'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据连续性的假设**：这两种方法都假设缺失的数据可以通过相邻的已知值**合理地逼近**，但这并不总是正确的。对于可能突然改变或存在不连续性的变量，这些方法可能不适用。'
- en: Let’s revisit the stock prices example and see how we can fill the missing values
    on the columns with nulls.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们重新看一下股票价格的例子，并看看如何填补空值列。
- en: Filling nulls in the stock market use case
  id: totrans-216
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在股市使用案例中填充空值
- en: 'In this example, we will not be focusing on missing indexes, just on the missing
    data in some of the features available. Let’s deep dive into the code – as always,
    you can find the full end-to-end code at [https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter11/3.missing_values/3.back_forward_fill.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter11/3.missing_values/3.back_forward_fill.py):'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将不关注缺失的索引，只关注一些特征中缺失的数据。让我们深入研究代码——和往常一样，你可以在[https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter11/3.missing_values/3.back_forward_fill.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter11/3.missing_values/3.back_forward_fill.py)找到完整的端到端代码：
- en: 'This code introduces random missing values into the `close` and `open` columns
    of a DataFrame (`df`). It begins by randomly selecting 50 indices from the DataFrame’s
    index using `np.random.choice`. The selected indices are stored in two variables,
    `nan_indices_close` and `nan_indices_open`, which correspond to the rows where
    missing values will be inserted:'
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这段代码将随机缺失值引入DataFrame（`df`）的`close`和`open`列。它首先使用`np.random.choice`从DataFrame的索引中随机选择50个索引。选中的索引存储在两个变量`nan_indices_close`和`nan_indices_open`中，这些变量对应于缺失值将被插入的行：
- en: '[PRE31]'
  id: totrans-219
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The following code uses the `.loc` accessor to assign NaN to the `close` column
    at the indices specified by `nan_indices_close`, and similarly to the `open` column
    at the indices specified by `nan_indices_open`. Effectively, this creates 50 random
    missing values in each of these columns, which can be useful for simulating real-world
    data scenarios or testing data handling techniques:'
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下代码使用`.loc`访问器在`nan_indices_close`指定的索引处将`NaN`赋值给`close`列，类似地，在`nan_indices_open`指定的索引处将`NaN`赋值给`open`列。实际上，这将在这两列中创建50个随机的缺失值，这对于模拟真实世界数据场景或测试数据处理技术非常有用：
- en: '[PRE32]'
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Fill NaN values using ffill and bfill:'
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用ffill和bfill填充NaN值：
- en: '[PRE33]'
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Let’s see the result:'
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们来看一下结果：
- en: '[PRE34]'
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'This will display the following output:'
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将显示以下输出：
- en: '[PRE35]'
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: As we can see, on `2020-01-07` and `2020-01-15`, there are missing values (NaN)
    in the `close` column. This indicates that the closing prices for these dates
    were not recorded or are otherwise unavailable.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所见，在`2020-01-07`和`2020-01-15`，`close`列中有缺失值（NaN）。这表示这两个日期的收盘价没有被记录或无法获取。
- en: 'As we’ve learned, the ffill method (`close_ffill`) fills missing values with
    the last valid observation:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所学，ffill方法（`close_ffill`）通过最后一个有效观测值填充缺失值：
- en: For `2020-01-07`, the closing price is filled with the last known value from
    `2020-01-06` (`193.27`)
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于`2020-01-07`，收盘价使用来自`2020-01-06`的最后一个已知值（`193.27`）进行填充。
- en: For `2020-01-15`, the missing value is filled with the last valid price from
    `2020-01-14` (`152.14`)
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于`2020-01-15`，缺失值使用来自`2020-01-14`的最后一个有效价格（`152.14`）进行填充。
- en: 'On the other hand, the bfill method (`close_bfill`) fills missing values with
    the next valid observation:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，bfill方法（`close_bfill`）通过下一个有效观测值填充缺失值：
- en: For `2020-01-07`, since no subsequent valid price is recorded immediately, it
    takes the closing price from `2020-01-08` (`120.03`)
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于`2020-01-07`，由于没有立即记录下一个有效价格，它使用`2020-01-08`的收盘价（`120.03`）进行填充。
- en: For `2020-01-15`, the value is filled with the next known price from `2020-01-16`
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于`2020-01-15`，该值使用来自`2020-01-16`的下一个已知价格进行填充。
- en: 'Let’s take a closer look at what happened in the data after we performed the
    different filling methods:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们仔细看看在执行不同填充方法后，数据发生了什么变化：
- en: On `2020-01-07`, ffill overestimates the missing value compared to bfill, which
    aligns more closely with the next known value
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在`2020-01-07`，ffill方法相比bfill方法高估了缺失值，bfill则与下一个已知值更为接近。
- en: On `2020-01-15`, ffill and bfill provide different estimates, with ffill potentially
    overestimating the value compared to bfill
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在`2020-01-15`，ffill和bfill提供了不同的估算结果，ffill可能高估了该值，而bfill则较为准确。
- en: As a general recommendation, we need to investigate the pattern of missing values.
    If the missing values are *random and sparse*, either method might be appropriate.
    However, if there is a systematic pattern, more sophisticated imputation methods
    might be needed, such as *interpolation*. Interpolation allows us to estimate
    missing data points by leveraging the existing values in the dataset, providing
    a more nuanced approach that can capture trends and patterns over time. We’ll
    discuss this in more detail next.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 一般建议，我们需要调查缺失值的模式。如果缺失值是*随机且稀疏*的，任一方法可能都合适。然而，如果存在系统性的模式，可能需要更复杂的插值方法，例如*插值*。插值允许我们通过利用数据集中的现有值来估算缺失的数据点，提供了一种更为细致的方式，能够捕捉随时间变化的趋势和模式。接下来我们将更详细地讨论这一点。
- en: Interpolation
  id: totrans-239
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 插值
- en: '**Interpolation** is a method for estimating missing values by filling in the
    gaps based on the surrounding data points. Unlike ffill and bfill, which copy
    existing values, interpolation uses mathematical techniques to estimate missing
    values. There are different interpolation techniques and applications. So, let’s
    have a look at the available options, along with their considerations:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: '**插值**是一种通过根据周围数据点填补缺口来估算缺失值的方法。与前向填充（ffill）和后向填充（bfill）不同，后者是复制现有值，插值使用数学技术来估算缺失值。插值有不同的技术和应用。所以，让我们看一下可用的选项及其考虑因素：'
- en: '**Linear interpolation**: Linear interpolation connects two adjacent known
    data points with a straight line and estimates the missing values along this line.
    It is the simplest form of interpolation and assumes a linear relationship between
    the data points. It is suitable for datasets where changes between data points
    are expected to be linear or nearly linear. It is commonly used in financial data,
    temperature readings, and other environmental data where gradual changes are expected.'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**线性插值**：线性插值通过一条直线连接两个相邻的已知数据点，并沿此线估算缺失值。它是最简单的插值形式，假设数据点之间存在线性关系。它适用于数据点之间的变化预计为线性或近似线性的情况。常用于金融数据、温度读数和其他预期逐渐变化的环境数据中。'
- en: '**Polynomial interpolation**: Polynomial interpolation fits a polynomial function
    to the known data points and uses this function to estimate missing values. Higher-order
    polynomials can capture more complex relationships between data points. It is
    suitable for datasets with non-linear trends, and it is usually used in scientific
    and engineering applications, where data follows a polynomial trend.'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多项式插值**：多项式插值将一个多项式函数拟合到已知的数据点，并使用这个函数来估计缺失值。更高阶的多项式可以捕捉数据点之间更复杂的关系。它适用于具有非线性趋势的数据集，通常用于科学和工程应用中，其中数据遵循多项式趋势。'
- en: '**Spline interpolation**: Spline interpolation uses piecewise polynomials,
    typically cubic splines, to fit the data points, ensuring smoothness at the data
    points and providing a smooth curve through the data. It is suitable for datasets
    requiring smooth transitions between data points and is commonly used in computer
    graphics, signal processing, and environmental data.'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**样条插值**：样条插值使用分段多项式，通常是三次样条，来拟合数据点，确保数据点的平滑性，并通过数据提供平滑的曲线。它适用于需要数据点之间平滑过渡的数据集，常用于计算机图形学、信号处理和环境数据中。'
- en: Let’s use interpolation in our use case.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在我们的用例中使用插值。
- en: Interpolation in the stock market use case
  id: totrans-245
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 股票市场用例中的插值
- en: 'Consider the same time series dataset presented previously with missing values.
    In this case, we want to impute these missing values using different interpolation
    methods. You can find the full code examples in this book’s GitHub repository:
    [https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter11/3.missing_values/4.interpolation.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter11/3.missing_values/4.interpolation.py).
    Let’s get started:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到之前提到的同一时间序列数据集，其中存在缺失值。在这种情况下，我们希望使用不同的插值方法来填补这些缺失值。你可以在本书的GitHub仓库中找到完整的代码示例：[https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter11/3.missing_values/4.interpolation.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter11/3.missing_values/4.interpolation.py)。让我们开始吧：
- en: 'The following code introduces random missing values into the `close` and `open`
    columns of our DataFrame (`df`), as we did in the previous section:'
  id: totrans-247
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下代码将随机缺失值引入我们的数据框（`df`）中的 `close` 和 `open` 列，就像在上一节中所做的那样：
- en: '[PRE36]'
  id: totrans-248
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The following line of code is used to fill in missing values in the `close`
    column of our DataFrame (`df`) using linear interpolation. The code specifically
    employs **linear interpolation**, where the missing values are estimated by drawing
    a straight line between the nearest known data points before and after the missing
    value:'
  id: totrans-249
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下代码行用于通过线性插值填充我们的DataFrame（`df`）中`close`列的缺失值。该代码特别使用**线性插值**，其中通过在缺失值前后最近的已知数据点之间画一条直线来估算缺失值：
- en: '[PRE37]'
  id: totrans-250
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'We can interpolate missing values using polynomial interpolation by changing
    the method argument to `method=''polynomial''`. This specifies that the interpolation
    should be done using a polynomial function of `order=3`. The `order` argument
    indicates the degree of the polynomial to be used. In this case, a cubic polynomial
    (third degree) is used, which means the function that estimates the missing values
    will be a curve, potentially providing a better fit for more complex data trends
    compared to a simple straight line (as in linear interpolation):'
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以通过将方法参数更改为`method='polynomial'`来使用多项式插值填充缺失值。这指定插值应使用`order=3`的多项式函数。`order`参数表示要使用的多项式的次数。在这种情况下，使用三次多项式（三次方），意味着估算缺失值的函数将是一个曲线，可能比简单的直线（如线性插值）提供更好的拟合，以适应更复杂的数据趋势：
- en: '[PRE38]'
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'We can interpolate missing values using spline interpolation by changing the
    method to `method=''spline''`. This specifies that the interpolation should be
    done using spline interpolation, which is a piecewise polynomial function that
    ensures smoothness at the data points. The `order=3` argument indicates the degree
    of the polynomial used in each piece of the spline. In this case, a cubic spline
    (third-degree polynomial) is used, meaning that the interpolation will involve
    fitting cubic polynomials to segments of the data:'
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以通过将方法更改为`method='spline'`来使用样条插值填充缺失值。这指定插值应使用样条插值，这是一种分段的多项式函数，确保数据点处的平滑性。`order=3`参数表示每段样条使用的多项式的次数。在这种情况下，使用三次样条（第三次多项式），意味着插值将涉及拟合三次多项式到数据的各个段落：
- en: '[PRE39]'
  id: totrans-254
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Now, let’s plot the interpolated data:'
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们绘制插值后的数据：
- en: '![Figure 11.8 – Daily closing prices interpolated](img/B19801_11_8.jpg)'
  id: totrans-256
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.8 – 日闭盘价插值](img/B19801_11_8.jpg)'
- en: Figure 11.8 – Daily closing prices interpolated
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.8 – 日闭盘价插值
- en: 'In *Figure 11**.8*, we can see how the data changes with the different interpolation
    methods. To better grasp the differences, let’s have a look at the actual data
    after interpolation, as shown in *Figure 11**.9*:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图 11.8*中，我们可以看到不同插值方法下数据的变化。为了更好地理解这些差异，让我们看看插值后的实际数据，如*图 11.9*所示：
- en: '![Figure 11.9 – Table of the daily closing prices interpolated](img/B19801_11_9.jpg)'
  id: totrans-259
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.9 – 日闭盘价插值表](img/B19801_11_9.jpg)'
- en: Figure 11.9 – Table of the daily closing prices interpolated
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.9 – 日闭盘价插值表
- en: 'Let’s compare the different interpolation methods and come to some conclusions:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们比较不同的插值方法并得出一些结论：
- en: 'On 2020-01-07, we have the following:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 在2020-01-07，我们有以下数据：
- en: '**Linear** **interpolation**: 156.649626'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**线性插值**：156.649626'
- en: '**Polynomial** **interpolation**: 142.704592'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多项式插值**：142.704592'
- en: '**Spline** **interpolation**: 143.173016'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**样条插值**：143.173016'
- en: 'On 2020-01-15, we have the following:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 在2020-01-15，我们有以下数据：
- en: '**Linear** **interpolation**: 144.628098'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**线性插值**：144.628098'
- en: '**Polynomial** **interpolation**: 127.403857'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多项式插值**：127.403857'
- en: '**Spline** **interpolation**: 128.666028'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**样条插值**：128.666028'
- en: Based on this data, linear interpolation seems to provide higher estimates compared
    to polynomial and spline interpolation. It assumes a linear trend between data
    points, which might not be accurate for non-linear data. Polynomial interpolation
    seems to provide lower estimates and capture more complex relationships but can
    be prone to overfitting. Finally, spline interpolation provides smooth estimates
    that are intermediate between linear and polynomial interpolation, offering a
    balance between simplicity and accuracy. In this specific case, we would go with
    spline interpolation as it provides a smooth curve that avoids abrupt changes,
    and the results are more realistic and closely aligned with the expected trends
    in the data. While spline interpolation is recommended based on the provided data,
    it is essential to validate the interpolated values against known data points
    or domain knowledge.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 根据这些数据，线性插值似乎提供了比多项式和样条插值更高的估计值。它假设数据点之间存在线性趋势，这对于非线性数据可能并不准确。多项式插值似乎提供了较低的估计值并能够捕捉更复杂的关系，但也容易过拟合。最后，样条插值提供了平滑的估计值，介于线性插值和多项式插值之间，提供了简单性与准确性之间的平衡。在这种具体情况下，我们会选择样条插值，因为它提供了一条平滑的曲线，避免了突变，结果更现实，更接近数据中预期的趋势。虽然基于提供的数据推荐使用样条插值，但验证插值结果与已知数据点或领域知识的符合性仍然是至关重要的。
- en: Note
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Interpolation methods such as linear, polynomial, and spline interpolation can
    also be used to deal with *outliers* in time series data.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 插值方法，如线性插值、多项式插值和样条插值，也可以用来处理时间序列数据中的*异常值*。
- en: Choosing and tuning interpolation arguments for filling missing values involves
    understanding the characteristics of your data and the specific needs of your
    analysis. For straightforward data with a linear trend, linear interpolation is
    efficient and effective. However, if your data exhibits non-linear patterns, polynomial
    interpolation can provide a better fit, with the degree of the polynomial (`order`)
    influencing the complexity of the curve; lower orders work well for simpler trends,
    while higher orders may capture more detail but risk overfitting. Spline interpolation
    offers a smooth and flexible approach, with cubic splines (`order=3`) being commonly
    used for their balance of smoothness and flexibility. To tune these methods, start
    with simpler approaches and test more complex ones progressively while monitoring
    for overfitting and ensuring the fit aligns with the data’s underlying trends.
    Employ cross-validation, visual inspection, and statistical metrics to evaluate
    and refine your interpolation choices.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 选择和调整插值参数来填充缺失值，需要理解数据的特征和分析的具体需求。对于具有线性趋势的简单数据，线性插值既高效又有效。然而，如果数据表现出非线性模式，多项式插值可能提供更好的拟合，且多项式的阶数（`order`）会影响曲线的复杂度；较低的阶数适用于简单趋势，而较高的阶数可能能捕捉更多的细节，但也有过拟合的风险。样条插值提供了一种平滑而灵活的方法，立方样条（`order=3`）因其平滑性和灵活性而被广泛使用。调优这些方法时，可以从较简单的方法开始，逐步测试更复杂的方法，同时监控过拟合现象，并确保拟合与数据的潜在趋势一致。采用交叉验证、视觉检查和统计指标来评估和优化插值选择。
- en: Now that we have explored the various techniques for handling missing data in
    time series, it’s essential to summarize the different filling methods to understand
    their unique applications and effectiveness.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经探讨了时间序列中处理缺失数据的各种技术，接下来总结不同的填充方法是非常重要的，以便理解它们独特的应用和有效性。
- en: Comparing the different methods for missing values
  id: totrans-275
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 比较不同的缺失值处理方法
- en: 'Handling missing values in time series data is an involved process that requires
    thoughtful consideration of the specific context and characteristics of the dataset.
    The decision to drop values, use bfill, or apply interpolation should be guided
    by a careful assessment of the impact on subsequent analyses and the preservation
    of critical information within the time series. The following table summarizes
    the different techniques and can be used as a guide:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 处理时间序列数据中的缺失值是一个复杂的过程，需要仔细考虑数据集的具体背景和特征。决定是丢弃值、使用bfill，还是应用插值，应根据对后续分析影响的仔细评估以及保留时间序列中关键信息的需要来指导。下表总结了不同的技术，并可作为指导：
- en: '| **Method** | **When** **to Use** | **Pros** | **Cons** |'
  id: totrans-277
  prefs: []
  type: TYPE_TB
  zh: '| **方法** | **使用时机** | **优点** | **缺点** |'
- en: '| Dropping missing values | A small percentage of missing values | - Simplicity-
    Avoids imputation uncertainty | - Information loss- Potential bias |'
  id: totrans-278
  prefs: []
  type: TYPE_TB
  zh: '| 填充缺失值 | 小比例的缺失值 | - 简单性- 避免插值不确定性 | - 信息丢失- 潜在偏差 |'
- en: '| Bfill | Missing values are expected to precede consistent values | - Preserves
    the general trend- Suitable for increasing trends | - Propagates errors if missing
    values are not similar to the following values |'
  id: totrans-279
  prefs: []
  type: TYPE_TB
  zh: '| 向后填充（Bfill） | 缺失值预计之前有一致的值 | - 保留总体趋势- 适用于递增趋势 | - 如果缺失值与随后的值不同，可能会传播错误 |'
- en: '| Ffill | Missing values are expected to follow consistent values | - Simple
    to implement- Maintains recent state until new data is available | - Can misrepresent
    data if trends change- Propagates errors if missing values differ from previous
    values |'
  id: totrans-280
  prefs: []
  type: TYPE_TB
  zh: '| 向前填充（Ffill） | 缺失值预计遵循一致的值 | - 实现简单- 保持最近状态直到新数据可用 | - 如果趋势变化，可能会误导数据- 如果缺失值与之前的值不同，则会传播错误
    |'
- en: '| Linear interpolation | Missing values need to be estimated based on neighboring
    data points | - Simple and easy to implement- Preserves overall trend | - May
    not capture non-linear trends- Sensitive to outliers |'
  id: totrans-281
  prefs: []
  type: TYPE_TB
  zh: '| 线性插值 | 缺失值需要根据相邻的数据点进行估算 | - 实现简单易懂- 保留整体趋势 | - 可能无法捕捉非线性趋势- 对离群值敏感 |'
- en: '| Polynomial interpolation | Missing values need to be estimated with more
    complex relationships | - Captures complex relationships- Flexible with polynomial
    order | - Can lead to overfitting and oscillations- Computationally intensive
    |'
  id: totrans-282
  prefs: []
  type: TYPE_TB
  zh: '| 多项式插值 | 缺失值需要通过更复杂的关系进行估算 | - 捕捉复杂关系- 对多项式阶数具有灵活性 | - 可能导致过拟合和振荡- 计算量大 |'
- en: '| Spline interpolation | Missing values need to be estimated with smooth transitions
    | - Provides a smooth curve- Avoids oscillations of high-order polynomials | -
    More complex to implement- Computationally intensive |'
  id: totrans-283
  prefs: []
  type: TYPE_TB
  zh: '| 样条插值 | 缺失值需要通过平滑过渡来估算 | - 提供平滑曲线- 避免高阶多项式的振荡 | - 实现较为复杂- 计算量大 |'
- en: Table 11.1 – Comparison of the different methods to handle missing data in time
    series
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 表 11.1 – 不同时间序列缺失数据处理方法的比较
- en: 'Having examined the various methods for filling missing values in time series
    data, it is equally important to address another critical aspect: the correlation
    of a time series with its own lagged values.'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 在研究了填充时间序列数据缺失值的各种方法之后，另一个同样重要的方面是：时间序列与其自身滞后值的相关性。
- en: Analyzing time series data
  id: totrans-286
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 时间序列数据分析
- en: '**Autocorrelation** and **partial autocorrelation** are crucial tools in time
    series analysis that provide insights into data patterns and guide model selection.
    For outlier detection, they help distinguish between genuine anomalies and expected
    variations, leading to more accurate and context-aware outlier identification.'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: '**自相关**和**偏自相关**是时间序列分析中的关键工具，它们提供了数据模式的洞察并指导模型选择。在离群值检测中，它们有助于区分真实的异常和预期的变动，从而实现更准确、更具上下文感知的离群值识别。'
- en: Autocorrelation and partial autocorrelation
  id: totrans-288
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自相关和偏自相关
- en: '**Autocorrelation** refers to correlating a time series with its own lagged
    values. Simply put, it measures how each observation in a time series is related
    to its past observations. Autocorrelation is a crucial concept in understanding
    the temporal dependencies and patterns present in time series data.'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: '**自相关**是指将时间序列与其自身滞后值进行相关分析。简而言之，它衡量时间序列中每个观察值与其过去观察值的关系。自相关是理解时间序列数据中存在的时间依赖性和模式的关键概念。'
- en: '**Partial autocorrelation function** (**PACF**), on the other hand, is a statistical
    tool that’s used in time series analysis to measure the correlation *between a
    time series and its lagged values after removing the effects of intermediate lags*.
    It provides a more direct measure of the relationship between observations at
    different time points, excluding the indirect effects of shorter lags.'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: '**偏自相关函数**（**PACF**）是时间序列分析中的一种统计工具，用于衡量*在去除中间滞后效应后，时间序列与其滞后值之间的相关性*。它提供了一个更直接的衡量不同时间点观察值之间关系的方式，排除了较短滞后效应的间接影响。'
- en: 'Both autocorrelation and partial autocorrelation help in the following cases:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 自相关和偏自相关在以下情况中有帮助：
- en: '**Temporal patterns**: They help identify patterns that repeat over time. This
    is crucial for understanding the inherent structure of the time series data.'
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**时间模式**：它们有助于识别随时间重复的模式。这对于理解时间序列数据的固有结构至关重要。'
- en: '**Stationarity assessment**: They help in assessing the stationarity of a time
    series. A lack of stationarity can impact the reliability of statistical analyses
    and model predictions.'
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**平稳性评估**：它们有助于评估时间序列的平稳性。缺乏平稳性可能会影响统计分析的可靠性以及模型预测的准确性。'
- en: '**Lag selection for models**: They guide the selection of appropriate lags
    for time series models, such as **autoregressive** (**AR**) components in **autoregressive
    moving average** (**ARIMA**) models.'
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型的滞后选择**：它们指导时间序列模型中适当滞后的选择，如**自回归**（**AR**）分量在**自回归滑动平均**（**ARIMA**）模型中的应用。'
- en: '**Seasonality detection**: Significant peaks in the **autocorrelation function**
    (**ACF**) plot at specific lags indicate the presence of seasonality, providing
    insights for further analysis.'
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**季节性检测**：在特定滞后期的**自相关函数**（**ACF**）图中出现显著峰值，表明存在季节性，为进一步分析提供了线索。'
- en: '**Anomaly detection**: Unusual patterns in the autocorrelation function may
    suggest anomalies or outliers in the data, prompting investigation and cleaning.'
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**异常检测**：自相关函数中出现不寻常的模式可能表明数据中存在异常值或离群点，需要进一步调查和清理。'
- en: Now, let’s perform an ACF and PACF analysis on the `close_filled` series from
    our stock price dataset. This analysis will help us determine the appropriate
    parameters (`p` and `q`) for the ARIMA modeling we will perform in the following
    section.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们对来自股票价格数据集的`close_filled`序列进行ACF和PACF分析。此分析将帮助我们确定适当的参数（`p`和`q`），以便在接下来的部分中进行ARIMA建模。
- en: ACT and PACF in the stock market use case
  id: totrans-298
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 股票市场案例中的ACF和PACF
- en: 'We will continue with the example we’ve used so far and add the ACT and PACF
    charts. As always, you can have a look at the full code here: [https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter11/4.analisis/autocorrelation.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter11/4.analisis/autocorrelation.py).
    Let’s get started:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将继续使用到目前为止的示例，并添加ACT和PACF图表。像往常一样，您可以查看完整代码：[https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter11/4.analisis/autocorrelation.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter11/4.analisis/autocorrelation.py)。让我们开始吧：
- en: 'Create an autocorrelation plot:'
  id: totrans-300
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建自相关图：
- en: '[PRE40]'
  id: totrans-301
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Create a partial autocorrelation plot:'
  id: totrans-302
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建部分自相关图：
- en: '[PRE41]'
  id: totrans-303
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'The resultant plots are shown here:'
  id: totrans-304
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果图如下所示：
- en: '![Figure 11.10 – ACF and PACF plots](img/B19801_11_10.jpg)'
  id: totrans-305
  prefs: []
  type: TYPE_IMG
  zh: '![图11.10 – ACF和PACF图](img/B19801_11_10.jpg)'
- en: Figure 11.10 – ACF and PACF plots
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.10 – ACF和PACF图
- en: 'Let’s explain what we can see in the preceding charts. Here’s what we can see
    for ACF:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们解释一下前面图表中可以看到的内容。对于自相关函数（ACF），我们可以看到以下内容：
- en: The ACF plot shows the correlation between the series and its lagged values
    at various lags (`lags=40`, in this example). The *X*-axis of the ACF plot represents
    the number of lags, indicating how many points back in time the correlation is
    being calculated.
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ACF图显示了序列与其滞后值在不同滞后期（本例中`lags=40`）的相关性。ACF图的*X*轴表示滞后期的数量，指示计算相关性时回溯的时间点数。
- en: The *Y*-axis of the ACF plot represents the correlation coefficients between
    the original time series and its lagged values. The correlation values range from
    -1 to 1.
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ACF图的*Y*轴表示原始时间序列与其滞后值之间的相关系数。相关值的范围从-1到1。
- en: The blue shaded area represents the confidence interval. Bars that extend beyond
    the shaded area are considered statistically significant and indicate strong autocorrelation
    at those lags, which suggest potential values for the *q parameter in the ARIMA
    model* (MA order), as we will see in the following section.
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 蓝色阴影区域表示置信区间。超出阴影区域的柱状条被认为具有统计显著性，表明在这些滞后期存在强烈的自相关性，并可能为*ARIMA模型中的q参数*（MA阶数）提供潜在的值，正如我们在接下来的部分中将看到的。
- en: Significant peaks at regular intervals indicate the presence of *seasonality*
    in the time series data.
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在固定间隔处出现显著峰值表明时间序列数据中存在*季节性*。
- en: If there is a significant autocorrelation at lag 1 in the ACF plot (a spike
    that goes beyond the blue-shaded region, as in our case), it suggests that the
    series has a strong correlation *with its immediate previous value*. This might
    indicate that the series is *not stationary* and may need differencing (d > 0).
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果ACF图在滞后1期存在显著的自相关（如我们案例中的蓝色阴影区域之外的尖峰），则表明该序列与其*即时前值*之间有很强的相关性。这可能意味着该序列是*非平稳的*，可能需要差分（d
    > 0）。
- en: 'Here’s what we can see for PACF:'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 对于PACF，我们可以看到以下内容：
- en: The PACF plot shows the correlation between the series and its lagged values
    after removing the effects explained by shorter lags.
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PACF 图显示了时间序列与其滞后值之间的相关性，去除了由较短滞后解释的效应。
- en: Significant spikes in the PACF plot indicate that lag 1 and potentially lag
    2 could be good candidates for the *p parameter in the ARIMA model* (AR order).
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PACF 图中的显著峰值表明滞后 1 和潜在的滞后 2 可能是 ARIMA 模型中*p 参数*（AR 阶数）的良好候选项。
- en: Note
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: When we specify `lags=40` in the context of ACF and PACF plots, we are examining
    the autocorrelation and partial autocorrelation of the time series at 40 different
    lag intervals. This means we will see how the series is correlated with itself
    from *lag 1 up to* *lag 40*.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在 ACF 和 PACF 图中指定`lags=40`时，我们是在检查时间序列在 40 个不同滞后区间的自相关和偏自相关。这意味着我们将看到序列如何与自身在*滞后
    1 到* *滞后 40*之间的相关性。
- en: ACF and PACF plots are crucial for identifying the underlying structure in a
    time series. In the next section, we will link the ACF and PACF analysis to outlier
    detection and handling to ensure our time series model captures the underlying
    patterns accurately.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: ACF 和 PACF 图对于识别时间序列中的基本结构至关重要。在接下来的部分中，我们将把 ACF 和 PACF 分析与异常值检测和处理联系起来，确保我们的时间序列模型准确捕捉到潜在模式。
- en: Dealing with outliers
  id: totrans-319
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理异常值
- en: Time series data often exhibit seasonal patterns (for example, sales spikes
    during holidays) and trends (for example, gradual growth over the years). An outlier
    in this context might not be an anomaly; rather, it could reflect a normal seasonal
    effect or a change in the underlying trend. For example, a sudden spike in retail
    sales during Black Friday is expected and should not be treated as an outlier.
    Techniques such as **seasonal decomposition of time series** (**STL**), autocorrelation,
    and seasonal indices can aid in understanding the expected behavior of the data,
    thus providing a clearer basis for identifying outliers.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列数据通常表现出季节性模式（例如，假期期间的销售峰值）和趋势（例如，多年来的逐步增长）。在这种情况下，异常值可能并不是异常现象；它可能反映了正常的季节性效应或基础趋势的变化。例如，黑色星期五期间零售销售的突然激增是可以预期的，不应视为异常值。诸如**时间序列季节性分解**（**STL**）、自相关和季节性指数等技术可以帮助理解数据的预期行为，从而为识别异常值提供更清晰的基础。
- en: Identifying outliers with seasonal decomposition
  id: totrans-321
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用季节性分解识别异常值
- en: 'One way to identify outliers in time series is to decompose the series into
    trend, seasonality, and residual components, as outliers are often identified
    in the residual component. To decompose the series into trend, seasonality, and
    residual components, we can use the STL method. This method helps in identifying
    and handling outliers by analyzing the residual component, which ideally should
    be white noise. Let’s see how we can do this using the stock market data. You
    can find the full code example at [https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter11/5.outliers/1.seasonal_decomposition.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter11/5.outliers/1.seasonal_decomposition.py):'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 识别时间序列中的异常值的一种方法是将序列分解为趋势、季节性和残差组件，因为异常值通常出现在残差组件中。要将序列分解为趋势、季节性和残差组件，我们可以使用
    STL 方法。该方法通过分析残差组件（理想情况下应该是白噪声）来帮助识别和处理异常值。让我们看看如何使用股市数据来实现这一点。你可以在[https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter11/5.outliers/1.seasonal_decomposition.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter11/5.outliers/1.seasonal_decomposition.py)找到完整的代码示例：
- en: '[PRE42]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'In this code snippet, we decompose the time series while assuming there are
    252 business days in a year. We will also calculate the Z-scores of residuals
    to identify outliers using the following code:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 在这段代码中，我们在假设每年有 252 个工作日的情况下对时间序列进行分解。我们还将计算残差的 Z 值，以便使用以下代码识别异常值：
- en: '[PRE43]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Finally, let’s plot the decomposed series:'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们绘制分解后的序列：
- en: '![Figure 11.11 – Decomposed time series](img/B19801_11_11.jpg)'
  id: totrans-327
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.11 – 分解后的时间序列](img/B19801_11_11.jpg)'
- en: Figure 11.11 – Decomposed time series
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.11 – 分解后的时间序列
- en: 'Outliers can be detected by analyzing the residual component. Significant deviations
    from zero or sudden spikes in the residual component indicate potential outliers:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过分析残差组件来检测异常值。残差组件中显著偏离零的值或突增表示潜在的异常值：
- en: '![Figure 11.12 – Table of decomposed values](img/B19801_11_12.jpg)'
  id: totrans-330
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.12 – 分解值表](img/B19801_11_12.jpg)'
- en: Figure 11.12 – Table of decomposed values
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.12 – 分解值表
- en: 'Based on the decomposed time series in *Figure 11**.11*, we can analyze the
    outliers by examining the `residual` and `resid_z` columns. Typically, Z-scores
    with an absolute value greater than 2 or 3 are considered potential outliers.
    In this dataset, the largest positive residuals are observed on `2020-01-06` (Z-score:
    1.468043), `2020-01-17` (Z-score: 1.300488), and `2020-01-27` (Z-score: 1.172529),
    while the largest negative residuals are on `2020-01-15` (Z-score: -1.721474)
    and `2020-01-22` (Z-score: -1.082559). Although these values indicate some deviations
    from the trend and seasonal components, none of the Z-scores exceed the typical
    threshold of ±2 or ±3, suggesting that there are no extreme outliers in this dataset.
    The residuals appear to be relatively well-distributed around zero, indicating
    a good fit for the decomposition model. However, the dates with the largest deviations
    (`2020-01-06`, `2020-01-15`, and `2020-01-17`) might be worth investigating further
    for any unusual events or factors that could explain their deviation from the
    expected values.'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 基于*图11.11*中的分解时间序列，我们可以通过检查`残差`和`resid_z`列来分析异常值。通常，绝对值大于2或3的Z分数被视为潜在的异常值。在该数据集中，最大正残差出现在`2020-01-06`（Z分数：1.468043）、`2020-01-17`（Z分数：1.300488）和`2020-01-27`（Z分数：1.172529）上，而最大负残差出现在`2020-01-15`（Z分数：-1.721474）和`2020-01-22`（Z分数：-1.082559）上。尽管这些数值显示出与趋势和季节性成分的某些偏差，但没有一个Z分数超过典型的±2或±3阈值，表明该数据集没有极端异常值。残差似乎相对均匀地分布在零周围，表明分解模型拟合良好。然而，具有最大偏差的日期（`2020-01-06`、`2020-01-15`和`2020-01-17`）可能值得进一步调查，看看是否有任何异常事件或因素可以解释它们偏离预期值的原因。
- en: 'On digging deeper into this data to understand the reasons behind the fluctuations
    and upon closer inspection, we can see that the deviations on these dates were
    due to specific events and system issues:'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 深入挖掘这些数据以了解波动背后的原因，并仔细检查后，我们可以看到这些日期的偏差是由特定事件和系统问题引起的：
- en: Disclaimer!
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 免责声明！
- en: The following events correspond to made-up events!
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 以下事件对应的是虚构事件！
- en: '`2020-01-06`: A technical glitch in the stock exchange’s trading system caused
    a temporary spike in prices'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`2020-01-06`：股市交易系统的技术故障导致价格暂时激增'
- en: '`2020-01-15`: An erroneous trade input led to a sudden drop in prices, which
    was later corrected'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`2020-01-15`：错误的交易输入导致价格突然下跌，随后被修正'
- en: '`2020-01-17`: A major economic announcement led to increased volatility and
    a brief surge in stock prices'
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`2020-01-17`：一次重大经济公告导致波动性增加，并使股价短暂上涨'
- en: '`2020-01-22`: A miscommunication about quarterly earnings results caused temporary
    panic selling'
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`2020-01-22`：关于季度财报结果的误传引发了暂时的恐慌性抛售'
- en: '`2020-01-27`: Rumors of a merger and acquisition led to speculative buying,
    temporarily inflating the prices'
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`2020-01-27`：关于并购的谣言引发了投机性购买，暂时抬高了价格'
- en: These findings helped us understand that the residuals’ deviations were not
    random but were due to specific, identifiable events. While these events did not
    qualify as significant outliers statistically, they highlighted the inherent volatility
    and noise in stock price data. Given the noisy nature of stock prices, even without
    significant outliers, smoothing techniques become crucial!
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 这些发现帮助我们理解到，残差的偏差并非随机发生，而是由于特定的、可识别的事件所致。虽然这些事件在统计上不符合显著异常值的标准，但它们突显了股价数据中固有的波动性和噪声。鉴于股价的噪声特性，即使没有显著的异常值，平滑技术仍然变得至关重要！
- en: Handling outliers – model-based approaches – ARIMA
  id: totrans-342
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 处理异常值 – 基于模型的方法 – ARIMA
- en: 'ARIMA models are widely used for forecasting time series data. They predict
    future values based on past observations, making them effective tools for identifying
    outliers by comparing actual values against predicted values. The ARIMA model
    consists of three main components:'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: ARIMA模型广泛用于时间序列数据的预测。它们根据过去的观测值预测未来的数值，使得通过将实际值与预测值进行比较，从而有效地识别异常值。ARIMA模型由三个主要部分组成：
- en: '**Autoregressive** (**AR**): Uses the dependency between an observation and
    several lagged observations (p)'
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自回归**（**AR**）：利用观测值与多个滞后观测值之间的依赖关系（p）'
- en: '**Integrated** (**I**): Uses differencing of observations to make the time
    series stationary (d)'
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**集成**（**I**）：通过对观测值的差分处理，使时间序列平稳化（d）'
- en: '**Moving average** (**MA**): Uses dependency between an observation and a residual
    error from a moving average model applied to lagged observations (q)'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**移动平均**（**MA**）：利用观测值与应用于滞后观测值的移动平均模型的残差误差之间的依赖关系（q）'
- en: 'ARIMA models are effective in handling the following outliers:'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: ARIMA模型在处理以下异常值时有效：
- en: '**Additive outliers** (**AO**): Sudden spikes or drops in the time series'
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**加性异常值**（**AO**）：时间序列中的突升或突降'
- en: '**Innovative outliers** (**IO**): Changes that affect the entire series from
    the point of occurrence onwards'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**创新异常值**（**IO**）：影响整个序列的变化，从发生点开始向后延伸'
- en: 'Let’s discuss how the ARIMA model can be used for outlier detection and smoothing
    in the context of the stock price data example we’ve been working with. You can
    find the full example at [https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter11/5.outliers/3.arima.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter11/5.outliers/3.arima.py):'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们讨论一下 ARIMA 模型如何在我们一直在处理的股票价格数据示例中用于异常值检测和平滑。您可以在 [https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter11/5.outliers/3.arima.py](https://github.com/PacktPublishing/Python-Data-Cleaning-and-Preparation-Best-Practices/blob/main/chapter11/5.outliers/3.arima.py)
    找到完整示例：
- en: 'Fit the ARIMA model to the `close_filled` series:'
  id: totrans-351
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对`close_filled`序列拟合 ARIMA 模型：
- en: '[PRE44]'
  id: totrans-352
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Calculate the residuals and Z-scores:'
  id: totrans-353
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算残差和 Z 分数：
- en: '[PRE45]'
  id: totrans-354
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Identify any outliers based on the Z-score threshold (for example, ±3):'
  id: totrans-355
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 基于 Z 分数阈值（例如，±3）识别任何异常值：
- en: '[PRE46]'
  id: totrans-356
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Visualize the original `close_filled` series and the smoothed series that was
    obtained from the ARIMA model:'
  id: totrans-357
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可视化原始 `close_filled` 序列和从 ARIMA 模型获得的平滑序列：
- en: '[PRE47]'
  id: totrans-358
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Here’s the output:'
  id: totrans-359
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下是输出结果：
- en: '![Figure 11.13 – ARIMA smoothing and outlier detection](img/B19801_11_13.jpg)'
  id: totrans-360
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.13 – ARIMA 平滑和异常值检测](img/B19801_11_13.jpg)'
- en: Figure 11.13 – ARIMA smoothing and outlier detection
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.13 – ARIMA 平滑和异常值检测
- en: 'Generate diagnostic plots to evaluate the model fit, including residual analysis,
    a **Quantile-Quantile** (**Q-Q**) plot, and standardized residuals:'
  id: totrans-362
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成诊断图以评估模型拟合，包括残差分析、**分位数-分位数**（**Q-Q**）图和标准化残差：
- en: '[PRE48]'
  id: totrans-363
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'The resulting plots are shown here:'
  id: totrans-364
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 结果图如下：
- en: '![Figure 11.14 – Residual analysis, Q-Q plot, and standardized residuals](img/B19801_11_14.jpg)'
  id: totrans-365
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.14 – 残差分析、Q-Q 图和标准化残差](img/B19801_11_14.jpg)'
- en: Figure 11.14 – Residual analysis, Q-Q plot, and standardized residuals
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.14 – 残差分析、Q-Q 图和标准化残差
- en: 'Let’s dive a bit deeper into the diagnostic plots shown in *Figure 11**.14*:'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入探讨一下 *图 11.14* 中显示的诊断图：
- en: '**Standardized residuals**: Standardized residuals are the residuals from the
    ARIMA model scaled by their standard deviation. For the ARIMA model to be considered
    a good fit, the standardized residuals *should resemble white noise, meaning they
    should have no discernible pattern*. This implies that the residuals are randomly
    distributed with a mean of zero and constant variance. If a pattern is visible
    in the residuals, it suggests that the model has not captured some underlying
    structure in the data, and further refinement may be necessary. In our case, the
    *residuals* look like white noise.'
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**标准化残差**：标准化残差是通过其标准差对 ARIMA 模型的残差进行缩放得到的。为了使 ARIMA 模型被认为是一个良好的拟合，标准化残差*应当像白噪声一样，意味着它们不应显示出明显的模式*。这意味着残差是随机分布的，均值为零，方差恒定。如果残差中出现模式，则表明模型未能捕捉到数据中的某些潜在结构，可能需要进一步的调整。在我们的案例中，*残差*看起来像白噪声。'
- en: '**Histogram plus KDE**: The histogram, combined with the **kernel density estimate**
    (**KDE**) plot of the residuals, provides a visual assessment of their distribution.
    For a well-fitted ARIMA model, the residuals should follow a normal distribution.
    The histogram should resemble the familiar bell curve, and the KDE plot should
    overlay a smooth curve that matches this shape. Deviations from the normal distribution,
    such as skewness or heavy tails, indicate that the residuals are not normally
    distributed, suggesting potential issues with the model. In our case, we don’t
    see any significant skewness or tails in the residuals.'
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**直方图加核密度估计（KDE）**：结合残差的**核密度估计（KDE）**图，提供了对残差分布的可视化评估。对于拟合良好的 ARIMA 模型，残差应遵循正态分布。直方图应呈现典型的钟形曲线，KDE
    图应叠加一条与之匹配的平滑曲线。若与正态分布存在偏差，如偏态或重尾，表明残差不是正态分布，这暗示模型可能存在问题。在我们的案例中，我们没有看到残差中有显著的偏态或尾部。'
- en: '**Normal Q-Q plot**: The Q-Q plot compares the quantiles of the residuals to
    the quantiles of a normal distribution. If the residuals are normally distributed,
    the points on the Q-Q plot will lie along the 45-degree line. Significant deviations
    from this line indicate departures from normality. In our case, we don’t see any
    significant deviations.'
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**正态 Q-Q 图**：Q-Q 图将残差的分位数与正态分布的分位数进行比较。如果残差服从正态分布，Q-Q 图上的点将沿着 45 度线排列。显著偏离这条线的点表示偏离正态分布。在我们的案例中，我们没有看到任何显著的偏差。'
- en: '**Correlogram** (**ACF of residuals**): The correlogram displays the ACF of
    the residuals. For a properly specified ARIMA model, the residuals should show
    no significant autocorrelation. This means that none of the lags should have statistically
    significant correlation coefficients. Significant spikes in the ACF plot indicate
    that the residuals are still correlated with their past values, suggesting that
    the model has not fully captured the time series’ structure. This can guide further
    model refinement, such as increasing the order of the AR or MA components. In
    our case, everything looks good.'
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自相关图**（**残差的自相关函数（ACF）**）：自相关图展示了残差的自相关函数（ACF）。对于一个合理指定的 ARIMA 模型，残差应该没有显著的自相关。这意味着没有任何滞后项的自相关系数应该具有统计学上的显著性。ACF
    图中的显著峰值表明残差仍然与其过去的值相关，暗示模型尚未完全捕捉到时间序列的结构。这可以指导进一步的模型优化，比如增加 AR 或 MA 组件的阶数。在我们的案例中，一切看起来都很好。'
- en: What is lag 0?
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 什么是滞后 0？
- en: In the correlogram (ACF plot), the term **lag 0** refers to the autocorrelation
    of the time series with itself at lag 0, which is essentially the correlation
    of the time series with itself at the same time point. By definition, this correlation
    is always 1, because any time series is perfectly correlated with itself at lag
    0\. This means the autocorrelation value at lag 0 is always 1, which is why you
    see a spike at lag 0 in the ACF plot.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 在自相关图（ACF 图）中，**滞后 0** 是指时间序列与自身在滞后 0 时的自相关，实际上是时间序列与自身在相同时间点的相关性。根据定义，这个相关性总是
    1，因为任何时间序列在滞后 0 时与自身完全相关。这意味着滞后 0 时的自相关值总是 1，这就是为什么在 ACF 图中滞后 0 处会看到一个峰值的原因。
- en: It is a good idea to go and play with the different settings and see their effect
    on the ARIMA model and the residuals.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 玩弄不同的设置并观察它们对 ARIMA 模型和残差的影响是一个好主意。
- en: Having explored the ARIMA method to detect and handle outliers in our stock
    price dataset, we have seen that outliers can significantly affect the accuracy
    and reliability of our time series model. While the ARIMA method helps in identifying
    and adjusting for these sudden changes, it’s also valuable to consider other approaches
    to robust outlier detection and handling. One such approach involves using moving
    window techniques, as we will see in the next section.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 在探索使用 ARIMA 方法检测和处理我们股票价格数据集中的异常值后，我们发现异常值会显著影响我们时间序列模型的准确性和可靠性。虽然 ARIMA 方法有助于识别和调整这些突变，但考虑其他稳健的异常值检测和处理方法也非常重要。接下来的部分我们将介绍其中一种方法，即使用移动窗口技术。
- en: Moving window techniques
  id: totrans-376
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 移动窗口技术
- en: Moving window techniques, also known as rolling or sliding window methods, involve
    analyzing a fixed-size subset or “window” of data that moves sequentially across
    a larger dataset. At each position of the window, a specific calculation or function
    is applied, such as computing the mean, median, sum, or more complex statistical
    measures. As the window shifts by one or more data points, the calculation is
    updated with the new subset of data. This method is particularly robust in time
    series analysis, where it is often used for smoothing data, identifying trends,
    or detecting anomalies over time.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 移动窗口技术，也称为滚动或滑动窗口方法，涉及分析一个固定大小的数据子集或“窗口”，该窗口会在较大的数据集上顺序移动。在窗口的每个位置，都会应用特定的计算或函数，例如计算均值、中位数、总和或更复杂的统计量。当窗口通过一个或多个数据点滑动时，计算会使用新的数据子集进行更新。该方法在时间序列分析中尤其稳健，通常用于平滑数据、识别趋势或检测随时间变化的异常值。
- en: The robustness of moving window techniques lies in their ability to provide
    localized analysis while maintaining a connection to the broader dataset. For
    example, when smoothing a time series, a moving average can reduce noise and highlight
    underlying trends without distorting the overall signal. Similarly, in financial
    data, moving windows can be used to compute rolling averages or volatilities,
    offering a real-time view of market conditions.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 移动窗口技术的优势在于它能够提供局部分析，同时与更广泛的数据集保持联系。例如，在平滑时间序列时，移动平均可以减少噪声并突出底层趋势，而不会扭曲整体信号。类似地，在金融数据中，移动窗口可以用来计算滚动平均值或波动性，提供市场条件的实时视图。
- en: 'In this section, we will focus on two primary methods: **simple moving average**
    (**SMA**) and **exponential moving average** (**EMA**). Both can act as a basis
    that you can adjust with other statistics such as the median later.'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将重点介绍两种主要方法：**简单移动平均**（**SMA**）和**指数加权移动平均**（**EMA**）。这两者都可以作为基础，稍后可以通过其他统计量（如中位数）进行调整。
- en: SMA
  id: totrans-380
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: SMA
- en: 'The **SMA** is a commonly used statistical calculation that represents the
    average of a set of data points over a specified time. It is a type of moving
    average that smoothens out fluctuations in data to identify trends more easily.
    The SMA is calculated by summing up a set of values and dividing the sum by the
    number of data points. More advanced methods such as Kalman smoothing can estimate
    missing values by modeling the underlying process:'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: '**SMA**是常用的统计计算，表示一组数据点在指定时间内的平均值。它是一种移动平均，通过平滑数据中的波动，更容易识别趋势。SMA通过将一组值相加，并将总和除以数据点的数量来计算。更先进的方法，如卡尔曼平滑，可以通过建模底层过程来估计缺失值：'
- en: '*SMA*t = (*X*t + *X*t–1 + *X*t–2 + ...+ *X*t–n+1)/*n*'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: '*SMA*t = (*X*t + *X*t–1 + *X*t–2 + ...+ *X*t–n+1)/*n*'
- en: 'Here, we have the following:'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们有如下公式：
- en: '*SMA*t is the SMA at time *t*'
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*SMA*t是时刻*t*的SMA。'
- en: '*X*t + *X*t–1 + *X*t–2 + ...+ *X*t–n+1 are the values for the time period'
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*X*t + *X*t–1 + *X*t–2 + ...+ *X*t–n+1 是该时间段的数据值。'
- en: '*n* is the number of periods included in the calculations'
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*n*是参与计算的周期数。'
- en: Now, let’s introduce the exponential moving average so that we can compare the
    two.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们介绍指数加权移动平均（EMA），以便我们可以对比这两者。
- en: EMA
  id: totrans-388
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: EMA
- en: 'The **EMA** gives more weight to recent data points and less weight to older
    data points. It uses an exponential decay formula:'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: '**EMA**对最近的数据点赋予更多的权重，对较早的数据点赋予较少的权重。它使用指数衰减公式：'
- en: '*EM**A*t = *α* • *X*t + (1 – *α*) • *EM**A*t–1'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: '*EMA*t = *α* • *X*t + (1 – *α*) • *EMA*t–1'
- en: Here, *α* is the smoothing factor.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，*α*是平滑因子。
- en: Now, let’s discuss how the SMA and EMA can be used for outlier detection and
    smoothing in the context of the stock price data example we’ve been working with.
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们讨论一下SMA和EMA如何在我们一直在使用的股票价格数据示例中进行异常值检测和平滑。
- en: Smoothing with SMA and EMA on the stock price use case
  id: totrans-393
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用SMA和EMA对股票价格进行平滑
- en: 'Continuing with the stock price data example we presented previously, let’s
    see the effect that SMA and EMA have on the data:'
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 继续使用我们之前呈现的股票价格数据示例，让我们看看SMA和EMA对数据的影响：
- en: 'First, let’s calculate the SMA with a window of 12 months:'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们计算12个月窗口的SMA：
- en: 'Define the `window` size for SMA and the `span` size for EMA:'
  id: totrans-396
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义SMA的`窗口`大小和EMA的`跨度`大小：
- en: '[PRE49]'
  id: totrans-397
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Calculate the SMA:'
  id: totrans-398
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算SMA：
- en: '[PRE50]'
  id: totrans-399
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Calculate the EMA:'
  id: totrans-400
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算EMA：
- en: '[PRE51]'
  id: totrans-401
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Calculate the residuals for the SMA and EMA:'
  id: totrans-402
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算SMA和EMA的残差：
- en: '[PRE52]'
  id: totrans-403
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Plot the original time series and the SMA:'
  id: totrans-404
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制原始时间序列和SMA：
- en: '![Figure 11.15 – SMA and EMA](img/B19801_11_15.jpg)'
  id: totrans-405
  prefs: []
  type: TYPE_IMG
  zh: '![图11.15 – SMA和EMA](img/B19801_11_15.jpg)'
- en: Figure 11.15 – SMA and EMA
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.15 – SMA和EMA
- en: In this example, we calculated the SMA and EMA using a window size of 20 and
    a span of 20, respectively. The window size for SMA determines how many previous
    data points are included in calculating the average at each point in time. Just
    like SMA, the frequency of your data points influences the choice of span. If
    your data is daily, a span zone of 20 might represent roughly 20 days of historical
    data.
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们使用20的窗口大小和20的跨度分别计算了SMA和EMA。SMA的窗口大小决定了在每个时间点计算平均值时包含多少个之前的数据点。和SMA一样，你数据点的频率会影响跨度的选择。如果你的数据是按日计的，跨度20大约代表过去20天的历史数据。
- en: 'Let’s discuss the generated plot a little more:'
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再多讨论一下生成的图表：
- en: '**SMA**:'
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**SMA**：'
- en: '**Smoothing effect**: The SMA smooths the time series data by averaging the
    values within the window, reducing noise, and highlighting the underlying trend'
  id: totrans-410
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**平滑效果**：SMA通过对窗口内的值进行平均来平滑时间序列数据，减少噪声，突出底层趋势。'
- en: '**Outlier impact**: While SMA reduces the impact of outliers, it can still
    be influenced by them since it considers all values within the window equally'
  id: totrans-411
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**异常值影响**：虽然SMA减少了异常值的影响，但它仍可能会受到异常值的影响，因为它对窗口内的所有值赋予相同的权重。'
- en: '**EMA**:'
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**EMA**：'
- en: '**Smoothing effect**: The EMA also smooths the data but gives more weight to
    recent observations, making it more responsive to recent changes'
  id: totrans-413
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**平滑效果**：EMA也对数据进行了平滑处理，但对最近的观察值赋予更多的权重，使其对近期变化更具响应性。'
- en: '**Outlier impact**: EMA is less influenced by older outliers but can be more
    affected by recent ones due to its weighting scheme'
  id: totrans-414
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**异常值影响**：EMA不太受较旧异常值的影响，但由于其加权机制，可能更容易受到近期异常值的影响。'
- en: Finding a balance between smoothness and responsiveness
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 在平滑度和响应性之间找到平衡
- en: Larger window sizes result in smoother moving averages but may lag behind changes
    in the data. Smaller window sizes make the moving average more responsive to short-term
    fluctuations but might introduce more noise.
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 较大的窗口大小会导致更平滑的移动平均，但可能会滞后于数据的变化。较小的窗口大小使得移动平均对短期波动更具响应性，但可能引入更多噪声。
- en: 'Remember the autocorrelation plot we created in *Figure 11**.10*? We can use
    the analysis to adjust the span or window size based on the observed autocorrelation
    patterns. The following points will help you guide the selection of the window
    size and span:'
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 记得我们在*图 11.10*中创建的自相关图吗？我们可以利用该分析，根据观察到的自相关模式来调整跨度或窗口大小。以下几点将帮助你选择窗口大小和跨度：
- en: Consider the frequency of your data points (daily, weekly, monthly).
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 考虑数据点的频率（每日、每周、每月）。
- en: If the autocorrelation plot shows significant autocorrelation at shorter lags,
    a smaller span in EMA or a smaller window size in SMA can help maintain responsiveness
    to recent changes while mitigating the influence of short-term noise.
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果自相关图显示在较短滞后期存在显著的自相关，EMA采用较小跨度或SMA采用较小窗口大小可以帮助保持对近期变化的响应，同时减少短期噪声的影响。
- en: If your data exhibits seasonal patterns, you might choose a window size or span
    that aligns with the seasonal cycle. For example, if there’s a weekly seasonality,
    you might consider a window size of 5 or 7\. Use the autocorrelation chart to
    figure this out.
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你的数据呈现季节性模式，你可能会选择与季节周期相符的窗口大小或跨度。例如，如果存在每周季节性，可能考虑使用5或7的窗口大小。可以使用自相关图来帮助确定这一点。
- en: 'To evaluate how well the window models perform, we can use the **mean absolute
    error** (**MAE**), as well as the **mean squared error** (**MSE**) and **root
    mean squared error** (**RMSE**). We can compare the errors between the original
    data and the smoothed values generated by these models, as shown in the following
    figure:'
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估窗口模型的表现，我们可以使用**平均绝对误差**（**MAE**），以及**均方误差**（**MSE**）和**均方根误差**（**RMSE**）。我们可以比较原始数据和这些模型生成的平滑值之间的误差，如下图所示：
- en: '![Figure 11.16 – Performance metrics for SMA and EMA](img/B19801_11_16.jpg)'
  id: totrans-422
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.16 – SMA 和 EMA 的性能指标](img/B19801_11_16.jpg)'
- en: Figure 11.16 – Performance metrics for SMA and EMA
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.16 – SMA 和 EMA 的性能指标
- en: 'To make sure we have a clear understanding of the different metrics presented
    in *Figure 11**.16*, let’s look at this in more detail:'
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保我们清楚理解*图 11.16*中呈现的不同指标，让我们更详细地看一下：
- en: '**MAE**: This represents the average magnitude of the errors in a set of predictions,
    providing a simple average of the absolute differences between predicted and actual
    values'
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**MAE**：这表示一组预测中的平均误差幅度，提供了预测值和实际值之间绝对差异的简单平均值。'
- en: '**MSE**: This measures the average squared differences between predicted and
    actual values, penalizing larger errors more heavily than MAE'
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**MSE**：该指标衡量预测值和实际值之间的平均平方差，比MAE更重视较大的误差。'
- en: '**RMSE**: RMSE is the square root of MSE, offering an interpretable measure
    of the average magnitude of error, aligning with the scale of the original data'
  id: totrans-427
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**RMSE**：RMSE是MSE的平方根，提供了一个可解释的平均误差幅度度量，与原始数据的尺度一致。'
- en: Now that we know what these terms represent, let’s unpick what they show for
    our stock prices use case. Lower MAE, MSE, and RMSE values indicate better performance
    of the smoothing method. While MAE and RMSE are very close for SMA and EMA, the
    MSE is lower for the exponential method.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道这些术语的含义，让我们来解读它们在股票价格案例中的应用。较低的MAE、MSE和RMSE值表示平滑方法的表现更好。虽然SMA和EMA的MAE和RMSE值非常接近，但指数加权法（EMA）的MSE值较低。
- en: 'The following table compares and summarizes when to use the SMA and EMA:'
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 下表对何时使用SMA和EMA进行了比较和总结：
- en: '| **Criteria** | **SMA** | **EMA** |'
  id: totrans-430
  prefs: []
  type: TYPE_TB
  zh: '| **标准** | **SMA** | **EMA** |'
- en: '| Type of smoothing | Simple and uniform smoothing of data points over a window
    | More responsive and adaptable, giving more weight to recent data points |'
  id: totrans-431
  prefs: []
  type: TYPE_TB
  zh: '| 平滑类型 | 对数据点进行简单和均匀的平滑处理 | 更敏感和适应性强，对近期数据点赋予更大权重 |'
- en: '| Weighing data points | Equal weight to all data points in the window | More
    weight to recent observations; older observations receive exponentially decreasing
    weights |'
  id: totrans-432
  prefs: []
  type: TYPE_TB
  zh: '| 数据点加权 | 对窗口中的所有数据点赋予相等权重 | 对近期观察值赋予更多权重；较老的观察值获得指数递减的权重 |'
- en: '| Responsiveness to changes | Lagging indicator; slower to respond to recent
    changes | More responsive to recent changes; adapts quickly to shifts in the data
    |'
  id: totrans-433
  prefs: []
  type: TYPE_TB
  zh: '| 对变化的响应性 | 滞后指标；对近期变化响应较慢 | 对近期变化更敏感；快速适应数据的变化 |'
- en: '| Suitability for stability | Suitable for stable and less volatile time series
    | Suitable for volatile or rapidly changing time series |'
  id: totrans-434
  prefs: []
  type: TYPE_TB
  zh: '| 稳定性适应性 | 适合稳定且波动较小的时间序列 | 适合波动性较大或变化迅速的时间序列 |'
- en: '| Adaptability to trends | Smooths out long-term trends, suitable for identifying
    overall patterns | Adapts quickly to shifting trends, suitable for capturing recent
    changes |'
  id: totrans-435
  prefs: []
  type: TYPE_TB
  zh: '| 对趋势的适应性 | 平滑长期趋势，适合识别整体模式 | 对变化趋势的适应较快，适合捕捉近期变化 |'
- en: '| Use case example | Analyzing long-term trends and identifying seasonality
    patterns | Capturing short-term fluctuations and reacting to market volatility
    |'
  id: totrans-436
  prefs: []
  type: TYPE_TB
  zh: '| 使用场景示例 | 分析长期趋势和识别季节性模式 | 捕捉短期波动并对市场波动做出反应 |'
- en: '| Calculation complexity | Simpler calculation and easier to understand and
    implement | More complex calculations involve a smoothing factor |'
  id: totrans-437
  prefs: []
  type: TYPE_TB
  zh: '| 计算复杂性 | 计算较简单，易于理解和实现 | 更复杂的计算涉及平滑因子 |'
- en: Table 11.2 – Comparison between SMA and EMA
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: 表11.2 – SMA与EMA的比较
- en: Beyond moving average techniques, exploring advanced feature engineering steps
    such as lags and differencing can significantly enrich our understanding and predictive
    capabilities. We’ll explore those in the next section.
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 除了移动平均技术之外，探索高级特征工程步骤，如滞后和差分，可以显著丰富我们对数据的理解和预测能力。我们将在下一节中进行探讨。
- en: Feature engineering for time series data
  id: totrans-440
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 时间序列数据的特征工程
- en: Effective feature engineering is essential in time series analysis to uncover
    meaningful patterns and enhance predictive accuracy. It involves transforming
    raw data into informative features that capture temporal dependencies, seasonal
    variations, and other relevant aspects of the time series. The first technique
    we are going to explore is creating lags of features.
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 有效的特征工程在时间序列分析中至关重要，可以揭示有意义的模式并提高预测准确性。它涉及将原始数据转化为能够捕捉时间依赖性、季节性变化以及时间序列其他相关方面的信息特征。我们要探索的第一个技术是创建特征的滞后。
- en: Lag features and their importance
  id: totrans-442
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 滞后特征及其重要性
- en: 'Lag features are a crucial aspect of time series feature engineering as they
    allow us to transform time series data into a format suitable for supervised learning
    models. Lag features involve creating new variables that represent past observations
    of the target variable:'
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: 滞后特征是时间序列特征工程中的关键部分，因为它们允许我们将时间序列数据转换为适合监督学习模型的格式。滞后特征涉及创建代表目标变量过去观察值的新变量：
- en: '**Lag 1**: The value from the previous time step'
  id: totrans-444
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Lag 1**：来自上一个时间步的值'
- en: '**Lag 2**: The value from two time steps ago'
  id: totrans-445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Lag 2**：来自两个时间步之前的值'
- en: '**Lag k**: The value from k time steps ago'
  id: totrans-446
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Lag k**：来自k个时间步之前的值'
- en: By shifting the time series data by a specified number of time steps (referred
    to as the lag), these past values are included as features in the model at the
    current timestamp. As we know, time series data often exhibits temporal dependencies,
    where the current value is related to past observations. Lag features help capture
    these dependencies, allowing the model to learn from historical patterns.
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将时间序列数据按指定的时间步数（称为滞后）进行平移，这些过去的值会作为当前时间戳的特征包含在模型中。正如我们所知道的，时间序列数据通常表现出时间依赖性，即当前值与过去的观察值相关。滞后特征有助于捕捉这些依赖关系，使模型能够从历史模式中学习。
- en: Now, let’s discuss how the lag features can be used in the context of the stock
    price data example we’ve been working with.
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们讨论如何在我们一直在使用的股价数据示例中应用滞后特征。
- en: Creating lag features in the stock price use case
  id: totrans-449
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在股价使用案例中创建滞后特征
- en: 'Continuing with the stock price data example we presented previously, let’s
    see the effect lag features have on the data:'
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: 继续我们之前提出的股价数据示例，让我们看看滞后特征对数据的影响：
- en: 'First, introduce more aggressive outliers in the `close` column:'
  id: totrans-451
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，在`close`列中引入更多激进的离群值：
- en: '[PRE53]'
  id: totrans-452
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Use the following function to create lagged features:'
  id: totrans-453
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下函数创建滞后特征：
- en: '[PRE54]'
  id: totrans-454
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Create lagged features for the `close` column:'
  id: totrans-455
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为`close`列创建滞后特征：
- en: '[PRE55]'
  id: totrans-456
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Plot the original time series and lagged datasets:'
  id: totrans-457
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制原始时间序列和滞后数据集：
- en: '![Figure 11.17 – Original versus lagged features](img/B19801_11_17.jpg)'
  id: totrans-458
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.17 – 原始特征与滞后特征](img/B19801_11_17.jpg)'
- en: Figure 11.17 – Original versus lagged features
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.17 – 原始特征与滞后特征
- en: As we can see in *Figure 11**.17*, lag 1 (`close_lag_1`) represents the closing
    price from the previous day, lag 5 (`close_lag_5`) represents the closing price
    from 5 days ago, and so on. You can observe how each lag captures the historical
    values of the target variable. When adding lagged features to a time series, the
    start date of the data shifts forward because the first few data points cannot
    be used until the specified lag period is complete. This shift means that if you
    add more lags, the number of initial data points that lack complete lagged data
    increases, effectively pushing the start date forward.
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在*图 11.17*中所看到的，滞后1（`close_lag_1`）表示前一天的收盘价，滞后5（`close_lag_5`）表示5天前的收盘价，依此类推。你可以观察每个滞后值如何捕捉目标变量的历史值。添加滞后特征到时间序列时，数据的起始日期会向前移动，因为在指定的滞后期结束之前，前几个数据点不能使用。这种偏移意味着，如果你添加更多的滞后，缺乏完整滞后数据的初始数据点数量会增加，从而有效地将起始日期向前推移。
- en: Feel free to experiment with different lag values and see the effect on the
    dataset. Adjusting the lag values allows you to capture different degrees of temporal
    dependencies and trends in the data.
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 可以自由尝试不同的滞后值，查看其对数据集的影响。调整滞后值可以帮助你捕捉数据中的不同时间依赖关系和趋势。
- en: Differencing time series
  id: totrans-462
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 时间序列差分
- en: In [*Chapter 4*](B19801_04.xhtml#_idTextAnchor116), *Cleaning Messy Data and
    Data Manipulation*, we discussed how calculating the time difference between two
    datetime objects using the `diff()` function can help us measure the time elapsed
    between consecutive events. This technique is useful for understanding the temporal
    gaps in a sequence of timestamps. Similarly, in time series analysis, differencing
    is a powerful technique that’s used to stabilize the mean of a time series by
    removing changes in the level of a time series, thus eliminating trend and seasonality.
    Just as we calculated the time elapsed in the previous chapter, we can apply differencing
    to our stock market data to highlight changes over time. However, we will also
    introduce a new term – seasonal differencing.
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第4章*](B19801_04.xhtml#_idTextAnchor116)《清理杂乱数据与数据操作》中，我们讨论了如何使用`diff()`函数计算两个日期时间对象之间的时间差，这有助于我们测量连续事件之间经过的时间。这个技巧有助于理解时间戳序列中的时间间隔。类似地，在时间序列分析中，差分是一种强大的技术，通过去除时间序列的水平变化，稳定时间序列的均值，从而消除趋势和季节性。正如我们在上一章中计算了时间差一样，我们可以将差分应用于股市数据，以突出随时间变化的变化。然而，我们还将引入一个新术语——季节性差分。
- en: Seasonal differencing
  id: totrans-464
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 季节性差分
- en: '**Seasonal differencing** is a technique that’s used to remove seasonal patterns
    from time series data, making it more stationary and suitable for analysis and
    forecasting. Seasonal differencing involves subtracting the value of an observation
    from a previous observation at a lag equal to the **seasonal** period. So, we
    need to identify the seasonal period with all the tools we provided previously
    and then take the seasonal period and difference the data on that.'
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: '**季节性差分**是一种用于去除时间序列数据中的季节性模式的技术，使其更加平稳，适合分析和预测。季节性差分通过将某个观测值与相隔季节性周期的前一个观测值相减来实现。因此，我们需要借助之前提供的工具识别季节性周期，然后取该季节性周期对数据进行差分。'
- en: 'For monthly data with an annual seasonal pattern, we can use the following
    formula:'
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: 对于具有年度季节性模式的月度数据，我们可以使用以下公式：
- en: '*y*''t =*y*t – *y*t–12'
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: '*y*''t = *y*t – *y*t–12'
- en: 'For quarterly data, we can use the following formula:'
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: 对于季度数据，我们可以使用以下公式：
- en: '*y*''t =*y*t – *y*t–4'
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: '*y*''t = *y*t – *y*t–4'
- en: Here, is the seasonally differenced series and is the original series.
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是季节性差分后的序列，和原始序列。
- en: Now, let’s discuss how the difference can be used in the context of the stock
    price data example we’ve been working with.
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们讨论如何在我们一直在处理的股价数据示例中使用差分。
- en: Differencing the stock price data
  id: totrans-472
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 对股价数据进行差分
- en: 'To showcase the seasonal differencing, we will introduce some seasonality in
    the stock market data. Based on the analysis we’ve done so far, there is not a
    big seasonal component in the data. Let’s get started:'
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示季节性差分，我们将在股票市场数据中引入一些季节性。根据我们目前的分析，数据中并没有明显的季节性成分。让我们开始吧：
- en: 'Create a seasonal component (weekly seasonality with higher amplitude):'
  id: totrans-474
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个季节性成分（每周季节性，幅度较大）：
- en: '[PRE56]'
  id: totrans-475
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Generate random stock prices with added seasonality:'
  id: totrans-476
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成加入季节性的随机股票价格：
- en: '[PRE57]'
  id: totrans-477
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Calculate the first difference:'
  id: totrans-478
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算第一次差分：
- en: '[PRE58]'
  id: totrans-479
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'Calculate the second difference:'
  id: totrans-480
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算第二次差分：
- en: '[PRE59]'
  id: totrans-481
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Finally, calculate the seasonal difference (weekly seasonality):'
  id: totrans-482
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，计算季节性差分（每周季节性）：
- en: '[PRE60]'
  id: totrans-483
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Let’s demonstrate differencing by plotting the first, second, and seasonal
    differences:'
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过绘制第一次、第二次和季节性差分来演示差分操作：
- en: '![Figure 11.18 – Original versus differenced series](img/B19801_11_18.jpg)'
  id: totrans-485
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.18 – 原始序列与差分序列](img/B19801_11_18.jpg)'
- en: Figure 11.18 – Original versus differenced series
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.18 – 原始序列与差分序列
- en: In *Figure 11**.18*, we can observe the first, second, and seasonal differencing.
    We can see that in the original plot, there is some seasonality, but after the
    first difference, we can see that the seasonal component is minimized. But how
    can we evaluate this more statistically? Let’s perform some statistical tests
    to check for stationarity in the time series.
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图 11.18*中，我们可以观察到第一次、第二次和季节性差分。我们可以看到在原始图中，存在一些季节性，但在第一次差分后，季节性成分被最小化了。但我们如何从统计学角度评估这一点呢？让我们进行一些统计检验，检查时间序列的平稳性。
- en: The Augmented Dickey-Fuller (ADF) test
  id: totrans-488
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 增广的迪基-富勒（ADF）检验
- en: The **ADF** test is a statistical test that’s used to determine whether a time
    series is stationary or not. The ADF test examines the null hypothesis that a
    unit root is present in a time series sample. The presence of a unit root indicates
    that the time series is non-stationary. The alternative hypothesis is that the
    time series is stationary. For the ADF test, a more negative value indicates stronger
    evidence against the null hypothesis.
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: '**ADF**检验是一种用于确定时间序列是否平稳的统计检验。ADF检验检验原假设：时间序列样本中存在单位根。单位根的存在表示时间序列是非平稳的。备择假设是时间序列是平稳的。对于ADF检验，数值越负，表明反对原假设的证据越强。'
- en: The p-value represents the probability of obtaining test results at least as
    extreme as the observed results, assuming that the null hypothesis is true. In
    the case of the ADF test, we want to see *a small p-value to reject the null hypothesis*
    *of non-stationarity*.
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: p值表示假设原假设为真时，获得至少与观察结果一样极端的检验结果的概率。在ADF检验中，我们希望看到*一个小的p值来拒绝原假设* *即非平稳性*。
- en: 'To conclude that a time series is stationary, we typically want to see the
    following:'
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: 要得出一个时间序列是平稳的结论，我们通常需要看到以下几点：
- en: '**p-value < 0.05**: This is the most common threshold that’s used in statistical
    testing. If p < 0.05, we reject the null hypothesis at the 5% significance level.
    This means we have strong evidence to conclude the series is stationary.'
  id: totrans-492
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**p值 < 0.05**：这是统计检验中最常用的阈值。如果p < 0.05，我们会在5%的显著性水平上拒绝原假设。这意味着我们有足够的证据得出该序列是平稳的结论。'
- en: '**Even smaller p-values**: p < 0.01 (1% significance level) and p < 0.001 (0.1%
    significance level) provide even stronger evidence of stationarity.'
  id: totrans-493
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**更小的p值**：p < 0.01（1%显著性水平）和p < 0.001（0.1%显著性水平）提供了更强的平稳性证据。'
- en: 'Let’s code up this test:'
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们编写代码进行这个检验：
- en: '[PRE61]'
  id: totrans-495
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Now, it’s time for the results! We will run the test for the original time
    series (to check if it is stationary or not) and then for each of the differenced
    time series. Let’s explain the results:'
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候查看结果了！我们将对原始时间序列进行检验（检查它是否平稳），然后对每个差分后的时间序列进行检验。让我们解释一下这些结果：
- en: '[PRE62]'
  id: totrans-497
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'The ADF statistic of -3.5899 is less than the 5% critical value of -2.8644,
    and the p-value is below 0.05\. This indicates that we can reject the null hypothesis
    of the presence of a unit root, suggesting that *the original series is likely
    stationary*. However, the result is relatively close to the critical value, indicating
    *borderline stationarity*:'
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: ADF统计量-3.5899小于5%的临界值-2.8644，且p值低于0.05。这表明我们可以拒绝单位根存在的原假设，暗示*原始序列可能是平稳的*。然而，结果相对接近临界值，表明*平稳性接近临界*：
- en: '[PRE63]'
  id: totrans-499
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'The ADF statistic of -11.7864 is well below the 5% critical value of -2.8644,
    and the p-value is extremely small. This strongly suggests that the first-differenced
    series is stationary. The significant drop in the ADF statistic compared to the
    original series indicates that first differencing has effectively removed any
    remaining trends or unit roots:'
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: ADF统计量为-11.7864，远低于5%的临界值-2.8644，且p值极小。这强烈表明第一次差分后的序列是平稳的。与原始序列相比，ADF统计量的显著下降表明第一次差分有效去除了剩余的趋势或单位根：
- en: '[PRE64]'
  id: totrans-501
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'The ADF statistic of -14.9569 is much lower than the 5% critical value, and
    the p-value is extremely small. This result suggests that the second-differenced
    series is also stationary. However, *over-differencing can lead to loss of meaningful
    patterns and increase noise*, so it’s essential to balance between achieving stationarity
    and maintaining the integrity of the series:'
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
  zh: ADF统计量为-14.9569，远低于5%的临界值，且p值极小。该结果表明第二次差分后的序列也是平稳的。然而，*过度差分可能导致有意义的模式丧失并增加噪声*，因此，在实现平稳性和保持序列的完整性之间必须保持平衡：
- en: '[PRE65]'
  id: totrans-503
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: Finally, the ADF statistic of -11.4833 is well below the 5% critical value,
    and the p-value is very small. This indicates that seasonal differencing has successfully
    made the series stationary. Seasonal differencing is particularly useful if the
    series exhibits periodic patterns at specific intervals.
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，ADF统计量为-11.4833，远低于5%的临界值，且p值非常小。这表明季节性差分成功地使得序列平稳。如果序列在特定的时间间隔内表现出周期性模式，季节性差分特别有效。
- en: 'Given these results, the first difference appears to be the most appropriate
    choice for the following reasons:'
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: 根据这些结果，第一次差分似乎是最合适的选择，原因如下：
- en: The original series is already stationary at the 1% level, but first differencing
    significantly improves stationarity
  id: totrans-506
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 原始序列在1%的显著性水平下已经是平稳的，但第一次差分显著提高了平稳性。
- en: 'The first difference yields a highly significant result (p-value: 1.006e-21)
    without risking over-differencing'
  id: totrans-507
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一次差分产生了一个非常显著的结果（p值：1.006e-21），且不会导致过度差分的风险。
- en: While the second difference shows an even more significant result, it may lead
    to over-differencing, which can introduce unnecessary complexity and potentially
    remove important information from the series
  id: totrans-508
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 虽然第二次差分显示出更为显著的结果，但它可能导致过度差分，从而引入不必要的复杂性，并可能移除序列中的重要信息。
- en: Seasonal differencing also shows strong results, but unless there’s a clear
    seasonal pattern in your data, the simpler first difference method is generally
    preferred
  id: totrans-509
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 季节性差分也显示出强劲的结果，但除非数据中有明确的季节性模式，否则通常更倾向于使用较为简单的第一次差分方法。
- en: In conclusion, first difference strikes a good balance between achieving stationarity
    and avoiding over-differencing. Now, it’s time to discuss some of the most common
    use cases in the time series space.
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，第一次差分在实现平稳性和避免过度差分之间取得了良好的平衡。现在，接下来我们讨论一些在时间序列领域最常见的应用场景。
- en: Applying time series techniques in different industries
  id: totrans-511
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在不同的行业中应用时间序列技术
- en: 'The ability to analyze temporal patterns provides a competitive advantage in
    today’s data-driven world across various industries. Here are some popular use
    cases across various industries:'
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
  zh: 能够分析时间模式为各行各业提供了竞争优势，尤其是在今天数据驱动的世界中。以下是一些不同行业中的常见应用场景：
- en: '| **Sector** | **Use Case** | **Explanation** |'
  id: totrans-513
  prefs: []
  type: TYPE_TB
  zh: '| **领域** | **应用场景** | **解释** |'
- en: '| Finance | Stock market analysis | Analyzing historical stock prices and trading
    volumes to make informed investment decisions |'
  id: totrans-514
  prefs: []
  type: TYPE_TB
  zh: '| 金融 | 股票市场分析 | 分析历史股价和交易量，以做出明智的投资决策 |'
- en: '| Portfolio management | Assessing the performance of investment portfolios
    over time to optimize asset allocation |'
  id: totrans-515
  prefs: []
  type: TYPE_TB
  zh: '| 投资组合管理 | 评估投资组合的表现，以优化资产配置 |'
- en: '| Risk assessment | Modeling and forecasting financial risks such as market
    volatility and credit defaults |'
  id: totrans-516
  prefs: []
  type: TYPE_TB
  zh: '| 风险评估 | 建模和预测金融风险，如市场波动和信用违约 |'
- en: '| Healthcare | Patient monitoring | Continuously tracking vital signs and health
    metrics for early detection of abnormalities |'
  id: totrans-517
  prefs: []
  type: TYPE_TB
  zh: '| 医疗健康 | 患者监测 | 持续跟踪生命体征和健康指标，及早发现异常 |'
- en: '| Epidemiology | Analyzing temporal patterns of disease spread and predicting
    outbreaks |'
  id: totrans-518
  prefs: []
  type: TYPE_TB
  zh: '| 流行病学 | 分析疾病传播的时间模式并预测疫情爆发 |'
- en: '| Treatment effectiveness | Assessing the impact of medical interventions over
    time |'
  id: totrans-519
  prefs: []
  type: TYPE_TB
  zh: '| 治疗效果 | 评估医学干预措施随时间的效果 |'
- en: '| Meteorology | Weather forecasting | Analyzing historical weather patterns
    to predict future conditions |'
  id: totrans-520
  prefs: []
  type: TYPE_TB
  zh: '| 气象学 | 天气预报 | 分析历史天气模式以预测未来气候 |'
- en: '| Climate change studies | Monitoring long-term trends and variations in climate
    data |'
  id: totrans-521
  prefs: []
  type: TYPE_TB
  zh: '| 气候变化研究 | 监测气候数据中的长期趋势和变化 |'
- en: '| Natural disaster prediction | Early detection of potential disasters such
    as hurricanes, floods, and droughts |'
  id: totrans-522
  prefs: []
  type: TYPE_TB
  zh: '| 自然灾害预测 | 早期检测潜在灾害，如飓风、洪水和干旱 |'
- en: '| Manufacturing | Production planning | Forecasting demand and optimizing production
    schedules |'
  id: totrans-523
  prefs: []
  type: TYPE_TB
  zh: '| 制造业 | 生产计划 | 预测需求并优化生产计划 |'
- en: '| Quality control | Monitoring and ensuring product quality over time |'
  id: totrans-524
  prefs: []
  type: TYPE_TB
  zh: '| 质量控制 | 监控并确保产品质量 |'
- en: '| Equipment maintenance | Predictive maintenance based on the performance history
    of machinery |'
  id: totrans-525
  prefs: []
  type: TYPE_TB
  zh: '| 设备维护 | 基于机械性能历史的预测性维护 |'
- en: '| Marketing | Sales forecasting | Predicting future sales based on historical
    data |'
  id: totrans-526
  prefs: []
  type: TYPE_TB
  zh: '| 营销 | 销售预测 | 基于历史数据预测未来销售 |'
- en: '| Customer engagement | Analyzing patterns of customer interaction with products
    and services |'
  id: totrans-527
  prefs: []
  type: TYPE_TB
  zh: '| 客户参与度 | 分析客户与产品和服务的互动模式 |'
- en: '| Campaign optimization | Evaluating the impact of marketing initiatives over
    time |'
  id: totrans-528
  prefs: []
  type: TYPE_TB
  zh: '| 活动优化 | 评估营销活动随时间的影响 |'
- en: '| **Sector** | **Use Case** | **Explanation** |'
  id: totrans-529
  prefs: []
  type: TYPE_TB
  zh: '| **领域** | **用例** | **说明** |'
- en: '| Transportation | Traffic flow analysis | Monitoring and optimizing traffic
    patterns in urban areas |'
  id: totrans-530
  prefs: []
  type: TYPE_TB
  zh: '| 交通运输 | 交通流量分析 | 监控并优化城市地区的交通模式 |'
- en: '| Vehicle tracking | Tracking the movement and efficiency of transportation
    fleets |'
  id: totrans-531
  prefs: []
  type: TYPE_TB
  zh: '| 车辆追踪 | 追踪运输车队的移动和效率 |'
- en: '| Supply chain optimization | Forecasting demand and optimizing the movement
    of goods over time |'
  id: totrans-532
  prefs: []
  type: TYPE_TB
  zh: '| 供应链优化 | 预测需求并优化商品在时间中的流动 |'
- en: Table 11.3 – Time series techniques use cases
  id: totrans-533
  prefs: []
  type: TYPE_NORMAL
  zh: 表 11.3 – 时间序列技术应用场景
- en: With that, we can summarize this chapter.
  id: totrans-534
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些，我们可以总结这一章的内容。
- en: Summary
  id: totrans-535
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: Time series analysis plays a pivotal role in extracting meaningful insights
    and making informed decisions in a wide range of industries. As technology advances,
    sophisticated time series techniques will become increasingly integral to understanding
    complex temporal patterns and trends. Whether in finance, healthcare, or transportation,
    the ability to analyze and forecast time-dependent data empowers organizations
    to adapt, optimize, and make strategic decisions in an ever-evolving landscape.
  id: totrans-536
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列分析在从各种行业中提取有意义的见解并做出明智决策中起着至关重要的作用。随着技术的发展，复杂的时间序列技术将变得越来越重要，用于理解复杂的时间模式和趋势。无论是在金融、医疗保健还是交通运输中，分析和预测时间依赖数据的能力使组织能够适应、优化并在不断变化的环境中做出战略决策。
- en: In this chapter, we covered techniques for handling missing values and outliers,
    differencing methods, and feature engineering in time series analysis. We learned
    how to use ffill and bfill for missing values and compared their effects on stock
    price data. Differencing techniques, including first, second, and seasonal differencing,
    were applied to achieve stationarity and were evaluated using ADF tests. We also
    explored lagged features for capturing temporal dependencies and assessed model
    performance using metrics such as MAE, MSE, and RMSE. These skills will prepare
    you so that you can manage and analyze time series data effectively.
  id: totrans-537
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们介绍了处理缺失值和异常值的技术、差分方法，以及时间序列分析中的特征工程。我们学习了如何使用ffill和bfill处理缺失值，并比较了它们对股票价格数据的影响。我们还应用了包括一阶、二阶和季节性差分在内的差分技术，以实现平稳性，并通过ADF检验进行评估。我们还探索了滞后特征以捕捉时间依赖关系，并使用MAE、MSE和RMSE等指标评估了模型性能。这些技能将使你能够有效地管理和分析时间序列数据。
- en: In the next chapter, we will pivot to a different type of data – text. Analyzing
    text data involves unique challenges and methodologies distinct from those used
    for numerical time series. We will deep dive into text preprocessing and cover
    text cleaning techniques, tokenization strategies, and spelling correction approaches,
    all of which are essential for any **natural language processing** (**NLP**) task.
  id: totrans-538
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将转向另一种类型的数据——文本。分析文本数据涉及独特的挑战和方法，这些方法与用于数字时间序列的数据分析不同。我们将深入探讨文本预处理，涵盖文本清理技术、分词策略和拼写修正方法，这些对于任何**自然语言处理**（**NLP**）任务都是至关重要的。
- en: 'Part 3: Downstream Data Cleaning – Consuming Unstructured Data'
  id: totrans-539
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第三部分：下游数据清洗——消费非结构化数据
- en: This part focuses on the challenges and techniques involved in processing unstructured
    data, such as text, images, and audio, in the context of modern machine learning,
    particularly **large language models** (**LLMs**). It provides a comprehensive
    overview of how to prepare unstructured data types for machine learning applications,
    ensuring that the data is properly preprocessed for analysis and model training.
    The chapters cover essential preprocessing methods for text, as well as image
    and audio data, offering readers the tools to work with more complex and varied
    datasets in today’s AI-driven landscape.
  id: totrans-540
  prefs: []
  type: TYPE_NORMAL
  zh: 本部分聚焦于处理非结构化数据（如文本、图像和音频）时面临的挑战和技术，特别是在现代机器学习环境下，尤其是**大型语言模型**（**LLMs**）。它全面概述了如何为机器学习应用准备非结构化数据类型，确保数据经过适当预处理以便分析和模型训练。各章节涵盖了文本、图像和音频数据的基本预处理方法，为读者提供了在当今由AI驱动的环境中处理更复杂和多样化数据集的工具。
- en: 'This part has the following chapters:'
  id: totrans-541
  prefs: []
  type: TYPE_NORMAL
  zh: 本部分包含以下章节：
- en: '[*Chapter 12*](B19801_12.xhtml#_idTextAnchor277)*, Text Preprocessing in the
    Era of LLMs*'
  id: totrans-542
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第12章*](B19801_12.xhtml#_idTextAnchor277)*，LLMs时代的文本预处理*'
- en: '[*Chapter 13*](B19801_13.xhtml#_idTextAnchor302)*, Image and Audio Preprocessing
    with LLMs*'
  id: totrans-543
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第13章*](B19801_13.xhtml#_idTextAnchor302)*，使用LLMs进行图像和音频预处理*'
