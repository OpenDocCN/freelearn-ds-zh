- en: '*Chapter 4*: Configuring the Workspace'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第 4 章*：配置工作区'
- en: In this chapter, you will work inside the **Azure Machine Learning** (**ML**)
    Studio web interface and learn how to configure the infrastructure needed to run
    an experiment inside its workspace. Then, you will learn how to provision or attach
    to existing compute resources and establish the connection between the Azure ML
    workspace and the various datastores that host your data. With these resources
    configured, you will be able to register a dataset and explore the capabilities
    offered in Azure ML to monitor those datasets.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将进入 **Azure 机器学习**（**ML**）Studio 网页界面，并学习如何配置运行实验所需的基础设施。接着，您将学习如何配置或附加到现有的计算资源，并建立
    Azure ML 工作区与托管您数据的各种数据存储之间的连接。配置好这些资源后，您将能够注册数据集并探索 Azure ML 提供的监控数据集的功能。
- en: 'In this chapter, we''re going to cover the following main topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主要主题：
- en: Provisioning compute resources
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置计算资源
- en: Connecting to datastores
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 连接到数据存储
- en: Working with datasets
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用数据集
- en: Technical requirements
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: You will need to have access to an Azure subscription. Within that subscription,
    you will need a `packt-azureml-rg`. You will need to have either a `Contributor`
    or `Owner` `packt-learning-mlw`, as described in [*Chapter 2*](B16777_02_Final_VK_ePub.xhtml#_idTextAnchor026),
    *Deploying Azure Machine Learning Workspace Resources*.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要拥有一个 Azure 订阅。在该订阅中，您需要一个 `packt-azureml-rg`。您需要拥有 `Contributor` 或 `Owner`
    权限的 `packt-learning-mlw`，如[*第 2 章*](B16777_02_Final_VK_ePub.xhtml#_idTextAnchor026)所述，*部署
    Azure 机器学习工作区资源*。
- en: Provisioning compute resources
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置计算资源
- en: 'Compute resources allow you to execute code scripts during your data exploratory
    analysis, the training phase, and when operationalizing ML models. The **Azure
    ML** workspace offers the following types of compute resources:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 计算资源使您能够在数据探索分析、训练阶段以及在操作化机器学习模型时执行代码脚本。**Azure ML** 工作区提供以下类型的计算资源：
- en: '**Compute instances**: These are virtual machines dedicated to each data scientist
    that is working in the **Azure ML workspace**.'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**计算实例**：这些是专门为每位在 **Azure ML 工作区** 中工作的数据科学家配置的虚拟机。'
- en: '**Compute clusters**: These are scalable computer clusters that can run multiple
    training or inference steps in parallel.'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**计算集群**：这些是可扩展的计算集群，可以并行运行多个训练或推理步骤。'
- en: '**Inference clusters**: These are **Azure Kubernetes Service** (**AKS**) clusters
    that can operationalize Docker images, which expose your models through a REST
    API.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**推理集群**：这些是 **Azure Kubernetes 服务**（**AKS**）集群，可以将 Docker 镜像转化为可操作的服务，通过 REST
    API 暴露您的模型。'
- en: '**Attached compute**: These are existing compute resources, such as Ubuntu
    **Virtual Machines** (**VMs**) or **Synapse Spark pools**, that can be attached
    to the workspace to execute some of the steps of your training or inference pipelines.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**附加计算**：这些是现有的计算资源，如 Ubuntu **虚拟机**（**VMs**）或 **Synapse Spark 池**，可以附加到工作区中，用于执行训练或推理管道的某些步骤。'
- en: 'When you visit the **Manage** | **Compute** section of Azure ML Studio, you
    will see and be able to manage each of these types by selecting the corresponding
    tab, as shown in the following screenshot:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 当您访问 **管理** | **计算** 部分时，您将能够查看并管理这些类型，通过选择相应的标签，如下图所示：
- en: '![Figure 4.1 – Compute types in Azure ML Studio'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.1 – Azure ML Studio 中的计算类型'
- en: '](img/B16777_04_001.jpg)'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_04_001.jpg)'
- en: Figure 4.1 – Compute types in Azure ML Studio
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.1 – Azure ML Studio 中的计算类型
- en: In the following sections, you will discover each of these compute types and
    understand the important configuration parameters that you must be aware of.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，您将发现每种计算类型，并了解您必须注意的重要配置参数。
- en: Important note
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 重要说明
- en: Provisioning and attaching compute resources can also be done through the Azure
    ML CLI and the Azure ML Python SDK. You will see examples of provisioning the
    same resources via the Python SDK in [*Chapter 7*](B16777_07_Final_VK_ePub.xhtml#_idTextAnchor102),
    *The Azure ML Python SDK*.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 配置和附加计算资源也可以通过 Azure ML CLI 和 Azure ML Python SDK 完成。您将在[*第 7 章*](B16777_07_Final_VK_ePub.xhtml#_idTextAnchor102)中看到通过
    Python SDK 配置相同资源的示例，*Azure ML Python SDK*。
- en: Compute instances
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 计算实例
- en: A compute instance is a VM that will facilitate your daily work as a data scientist.
    This is a managed, Ubuntu-based workstation that comes preconfigured with data
    science tools such as Jupyter Labs, RStudio, and various deep learning frameworks
    such as **PyTorch** and **TensorFlow**. *Managed* means that you won't have to
    manually update the operating system or ensure that it is patched against the
    latest security vulnerabilities.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 计算实例是一个虚拟机，将为您作为数据科学家的日常工作提供支持。这是一个基于 Ubuntu 的托管工作站，预先配置了数据科学工具，如 Jupyter Labs、RStudio
    以及各种深度学习框架，如 **PyTorch** 和 **TensorFlow**。*托管*意味着您无需手动更新操作系统或确保其修补最新的安全漏洞。
- en: Important note
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 重要说明
- en: Compute instances are ideal for corporate users who may not be able to install
    Python on their corporate computers. Compute instances only require you to have
    a modern web browser and internet access. Once you are connected to a compute
    instance, you have access to all the software packages you will need to work with
    your Azure ML workspace.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 计算实例非常适合那些可能无法在公司电脑上安装 Python 的企业用户。计算实例仅要求您具备现代网页浏览器和互联网连接。连接到计算实例后，您将能够访问所有工作
    Azure ML 工作区所需的软件包。
- en: 'All your files and preferences are securely stored within the `/home/<username>/cloudfiles/code/`
    folder of the VM. This folder is not part of the VM''s disk, but it is mounted
    from a remote file share located in your Azure ML storage account, as shown in
    the following diagram. This file share allows you to share code files and notebooks
    across multiple compute instances, and you can even mount that folder locally
    on your own computer:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 您的所有文件和偏好设置都安全地存储在虚拟机的`/home/<username>/cloudfiles/code/`文件夹中。此文件夹不属于虚拟机的磁盘，但它是从您
    Azure ML 存储帐户中位于远程文件共享的位置挂载的，如下图所示。此文件共享允许您跨多个计算实例共享代码文件和笔记本，您甚至可以在自己的计算机上本地挂载该文件夹：
- en: '![Figure 4.2 – Remote file share mounted on multiple compute instances'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.2 – 挂载到多个计算实例上的远程文件共享'
- en: '](img/B16777_04_002.jpg)'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_04_002.jpg)'
- en: Figure 4.2 – Remote file share mounted on multiple compute instances
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.2 – 挂载到多个计算实例上的远程文件共享
- en: Compute instances primarily enable the **Notebooks** experience of the studio
    web interface, but they can also be used for training and inferencing at a small
    scale. In fact, compute instances provide job queuing capabilities and allow you
    to run up to two jobs per core, something that's very useful for testing and debugging
    scenarios. You will use your compute instance to perform data drift analysis in
    the *Data drift detection* section, later in this chapter. In the next section,
    you will learn how to provision your first compute instance.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 计算实例主要用于支持 Studio 网页界面的 **笔记本** 功能，但它们也可以用于小规模的训练和推理。实际上，计算实例提供了作业排队功能，允许您每个核心运行多达两个作业，这对于测试和调试场景非常有用。稍后在本章的
    *数据漂移检测* 部分，您将使用计算实例执行数据漂移分析。在下一节中，您将学习如何配置您的第一个计算实例。
- en: Provisioning a compute instance
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 配置计算实例
- en: 'Let''s learn how to provision an instance:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们学习如何配置一个实例：
- en: 'In the studio web interface, navigate to the **Manage** | **Compute** section
    and select the **Compute instances** tab. If no compute instances have been provisioned,
    you will see a short introduction to compute instances: you can click the **New**
    button to start the compute provisioning wizard, as shown on the left-hand side
    of *Figure 4.3*. If other compute instances have already been provisioned in the
    workspace, you can start the same wizard by clicking on the **New** button from
    the top menu, as shown on the right-hand side of the following screenshot:![Figure
    4.3 – Starting the compute instance provisioning wizard'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Studio 网页界面中，导航至 **管理** | **计算** 部分并选择 **计算实例** 标签。如果尚未配置计算实例，您将看到计算实例的简短介绍：您可以点击
    **新建** 按钮启动计算配置向导，如 *图 4.3* 左侧所示。如果工作区中已经配置了其他计算实例，您可以通过点击顶部菜单中的 **新建** 按钮启动相同的向导，如下图右侧所示：![图
    4.3 – 启动计算实例配置向导
- en: '](img/B16777_04_003.jpg)'
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16777_04_003.jpg)'
- en: Figure 4.3 – Starting the compute instance provisioning wizard
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.3 – 启动计算实例配置向导
- en: The first thing you will need to select is the virtual machine's size. You can
    specify whether you need GPU-enabled machines or normal CPU machines. If you plan
    to run computer vision experiments or deep neural network training, a GPU machine
    can accelerate the training and inference process if the framework supports GPUs.
    Moreover, you can add filters to limit the list based on the minimum requirements
    you have for your workspace. In our case, we will select a CPU-only compute instance
    that has at least 14 GB of RAM and at least 4 cores, as shown in the following
    screenshot:![Figure 4.4 – The first page of the compute instance provisioning
    wizard
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，您需要选择虚拟机的大小。您可以指定是否需要启用 GPU 的机器或普通的 CPU 机器。如果您计划运行计算机视觉实验或深度神经网络训练，GPU 机器可以加速训练和推理过程，前提是框架支持
    GPU。此外，您可以添加过滤器来限制列表，以满足您工作空间的最低要求。在我们的例子中，我们将选择一台仅包含 CPU 的计算实例，且至少配备 14 GB 的内存和
    4 核心，如下图所示：![图 4.4 – 计算实例配置向导的第一页
- en: '](img/B16777_04_004.jpg)'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16777_04_004.jpg)'
- en: Figure 4.4 – The first page of the compute instance provisioning wizard
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.4 – 计算实例配置向导的第一页
- en: In the results table, you can review the characteristics of each VM and get
    an estimation of how much it will cost per hour.
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在结果表中，您可以查看每个虚拟机的特性，并估算其每小时的费用。
- en: Important note
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 重要提示
- en: Virtual machines' costs depend on their size, but also on the region where they
    are provisioned. For example, while authoring this book, East US 2 had the lowest
    average price in USD per hour, while West Europe was among the most expensive
    regions.
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 虚拟机的费用取决于其大小，同时也取决于其配置所在的区域。例如，在编写本书时，东部美国 2 区的每小时平均价格最低，而西欧是最昂贵的区域之一。
- en: 'The following table contains a bit more information about the first three virtual
    machine sizes that appear in the result list. The main difference between the
    **Standard_D3_v2** and **Standard_DS3_v2** virtual machines is the premium storage
    disk. This provides disk caching capabilities, something that allows the VM to
    achieve performance levels that exceed the underlying disk performance. Therefore,
    by default, the wizard suggests that you select the **Standard_DS3_v2** virtual
    machine size:'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下表包含了关于结果列表中前几个虚拟机大小的更多信息。**Standard_D3_v2** 和 **Standard_DS3_v2** 虚拟机的主要区别在于其使用的高级存储磁盘。这种磁盘提供了磁盘缓存功能，使得虚拟机能够实现超越底层磁盘性能的表现。因此，向导默认建议选择
    **Standard_DS3_v2** 虚拟机大小：
- en: '![Figure 4.5 – Comparison of compute sizes based on the docs.microsoft.com
    site'
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.5 – 基于 docs.microsoft.com 网站的计算实例大小比较'
- en: '](img/B16777_04_005.jpg)'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16777_04_005.jpg)'
- en: Figure 4.5 – Comparison of compute sizes based on the docs.microsoft.com site
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.5 – 基于 docs.microsoft.com 网站的计算实例大小比较
- en: Leave the **Standard_DS3_v2** size selected and click **Next** to configure
    the advanced settings for the compute instance:![Figure 4.6 – The second page
    of the compute instance provisioning wizard
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保持选择 **Standard_DS3_v2** 大小，然后点击 **下一步** 来配置计算实例的高级设置：![图 4.6 – 计算实例配置向导的第二页
- en: '](img/B16777_04_006.jpg)'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16777_04_006.jpg)'
- en: Figure 4.6 – The second page of the compute instance provisioning wizard
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.6 – 计算实例配置向导的第二页
- en: Important note
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 重要提示
- en: If you are on a free trial, then you have a fixed core quota, which you cannot
    change unless you switch to a pay-as-you-go subscription. You may need to select
    **Standard_DS2_v2** to reduce the number of cores your compute instance will be
    using. You will need at least two more cores for the computer cluster you will
    be provisioning in [*Chapter 7*](B16777_07_Final_VK_ePub.xhtml#_idTextAnchor102),
    *The Azure ML Python SDK*.
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果您使用的是免费试用版，则您将有一个固定的核心配额，除非切换到按需付费订阅，否则无法更改。您可能需要选择 **Standard_DS2_v2** 以减少计算实例使用的核心数量。您将需要至少两个核心来为第
    [*第 7 章*](B16777_07_Final_VK_ePub.xhtml#_idTextAnchor102) 中要配置的计算集群提供支持，*《Azure
    ML Python SDK》*。
- en: Now, you need to provide a computer name. This is the name you will be using
    to reference the specific computer. The compute name should be unique within the
    Azure region. This means that you may need to change the name to something unique,
    potentially by adding some numbers in the name; for example, `ds-021-workstation`.
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，您需要提供计算机名称。这是您将用来引用特定计算机的名称。计算机名称在 Azure 区域内应该是唯一的。这意味着您可能需要将名称更改为一个唯一的名称，可能是通过在名称中添加一些数字，例如
    `ds-021-workstation`。
- en: Optionally, enable the SSH access flag. This option allows you to specify the
    public portion of the SSH key, which will give you remote access to the compute
    instance. The wizard allows you to generate that key directly within the wizard.
    Alternatively, you can generate one by following the instructions provided in
    the *Generating an SSH key pair* section. This option is not needed if you only
    plan to use the studio experience to conduct your data science experiments:![Figure
    4.7 – Enabling SSH access to the compute instance
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可选地，启用 SSH 访问标志。此选项允许你指定 SSH 密钥的公钥部分，从而使你能够远程访问计算实例。向导允许你在向导内直接生成该密钥。或者，你可以按照
    *生成 SSH 密钥对* 部分中的说明生成密钥。如果你仅计划使用工作室体验进行数据科学实验，则不需要此选项：![图 4.7 – 启用计算实例的 SSH 访问](img/B16777_04_007.jpg)
- en: '](img/B16777_04_007.jpg)'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16777_04_009.jpg)'
- en: Figure 4.7 – Enabling SSH access to the compute instance
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.7 – 启用计算实例的 SSH 访问
- en: Click on the **Create** button to provision the compute instance. This will
    complete the wizard. At this point, the compute instance will be created and then
    start:![Figure 4.8 – Waiting for the compute instance to be created and transition
    to the Running state
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 **创建** 按钮以配置计算实例。这将完成向导。在此时，计算实例将被创建并启动：![图 4.8 – 等待计算实例创建并过渡到运行状态](img/B16777_04_008.jpg)
- en: '](img/B16777_04_008.jpg)'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16777_04_007.jpg)'
- en: Figure 4.8 – Waiting for the compute instance to be created and transition to
    the Running state
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.8 – 等待计算实例创建并过渡到运行状态
- en: In the following sections, you will be given a brief introduction to SSH key-based
    authentication and how to generate an SSH key if you are not familiar with the
    process. Moreover, you will explore the advanced options of the wizard, options
    we will not need for the purposes of this book.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，如果你不熟悉生成 SSH 密钥的过程，将简要介绍基于 SSH 密钥的认证以及如何生成 SSH 密钥。此外，你还将探索向导的高级选项，这些选项本书不需要使用。
- en: Generating an SSH key pair
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 生成 SSH 密钥对
- en: 'An SSH key pair consists of two files – a private key and a public key. This
    key pair allows end users to encrypt text using the public portion of the key.
    The encrypted text can only be decrypted by the private portion of the SSH key,
    as shown in the following diagram. The private portion of the SSH key needs to
    be stored in a secure place, while the public portion of the key can be freely
    distributed to anyone:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: SSH 密钥对由两个文件组成——一个私钥和一个公钥。该密钥对允许终端用户使用公钥部分加密文本。加密后的文本只能由 SSH 密钥的私钥部分解密，如下图所示。SSH
    密钥的私钥部分需要存储在安全的位置，而公钥部分则可以自由分发给任何人：
- en: '![Figure 4.9 – A private key can decrypt information that''s been encrypted
    with a public key'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.9 – 私钥可以解密使用公钥加密的信息'
- en: '](img/B16777_04_009.jpg)'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_04_009.jpg)'
- en: Figure 4.9 – A private key can decrypt information that's been encrypted with
    a public key
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.9 – 私钥可以解密使用公钥加密的信息
- en: Using this property of the SSH key pair, you can configure your public key with
    a server so that it can use it for authentication. In a nutshell, when you try
    to connect to the server, the server will create a random challenge and encrypt
    it using the public portion of your key – the one you configured while provisioning
    the compute instance. You will have to decrypt that challenge using the private
    portion of the key, and then respond with an answer that will validate that you
    managed to decrypt the server's message. This flow will grant you access to the
    remote server over SSH.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 利用 SSH 密钥对的这个特性，你可以将公钥配置到服务器上，从而使服务器能够使用它进行认证。简而言之，当你尝试连接到服务器时，服务器将创建一个随机的挑战，并使用你在配置计算实例时设置的公钥部分进行加密。你需要使用私钥部分解密该挑战，并以正确的答案回应，验证你成功解密了服务器的消息。这个流程将允许你通过
    SSH 访问远程服务器。
- en: 'There are multiple open source tools that can help you generate an SSH key
    pair on your local machine. Azure offers a very easy way to generate an SSH key
    pair on your browser, and then store the public portion of the key as a resource
    in the Azure portal. Let''s take a look:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 有多个开源工具可以帮助你在本地计算机上生成 SSH 密钥对。Azure 提供了一种非常简单的方法，可以通过浏览器生成 SSH 密钥对，并将密钥的公钥部分作为资源存储在
    Azure 门户中。让我们来看看：
- en: Navigate to [https://portal.azure.com](https://portal.azure.com) and click on
    the `SSH Key` resource and click on **Create**:![Figure 4.10 – SSH key resource
    in the marketplace
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 访问 [https://portal.azure.com](https://portal.azure.com)，点击 `SSH 密钥` 资源并点击 **创建**：![图
    4.10 – 市场中的 SSH 密钥资源
- en: '](img/B16777_04_010.jpg)'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16777_04_010.jpg)'
- en: Figure 4.10 – SSH key resource in the marketplace
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.10 – 市场中的 SSH 密钥资源
- en: Select the `packt-azureml-rg` resource group and provide a key-pair name, such
    as `azureml-compute`. Click on **Review + create** to navigate to the last step
    of the wizard:![Figure 4.11 – Generating an SSH key pair
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择 `packt-azureml-rg` 资源组并提供一个密钥对名称，例如 `azureml-compute`。点击 **查看 + 创建** 进入向导的最后一步：![图
    4.11 – 生成 SSH 密钥对
- en: '](img/B16777_04_011.jpg)'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16777_04_011.jpg)'
- en: Figure 4.11 – Generating an SSH key pair
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.11 – 生成 SSH 密钥对
- en: 'Select `azureml-compute.pem`. Make sure you store the file in a secure location:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择 `azureml-compute.pem`。确保将文件存储在安全的位置：
- en: '![Figure 4.12 – Storing the private portion of the SSH key'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.12 – 存储 SSH 密钥的私钥部分'
- en: '](img/B16777_04_012.jpg)'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_04_012.jpg)'
- en: Figure 4.12 – Storing the private portion of the SSH key
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.12 – 存储 SSH 密钥的私钥部分
- en: 'Once this process is done, an SSH key resource will appear in the resource
    group you selected on the wizard:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 完成此过程后，SSH 密钥资源将在你在向导中选择的资源组中显示：
- en: '![Figure 4.13 – The SSH key resource you deployed'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.13 – 你部署的 SSH 密钥资源'
- en: '](img/B16777_04_013.jpg)'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_04_013.jpg)'
- en: Figure 4.13 – The SSH key resource you deployed
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.13 – 你部署的 SSH 密钥资源
- en: 'In that resource, you can find the public portion of the SSH key, which you
    can copy and then paste into the compute instance provision wizard step you saw
    in the *Provisioning a compute instance* section:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在该资源中，你可以找到 SSH 密钥的公钥部分，你可以将其复制并粘贴到你在*配置计算实例*部分看到的计算实例配置向导步骤中：
- en: '![Figure 4.14 – The public portion of the generated key pair. At the top,'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.14 – 生成的密钥对的公钥部分。在顶部，'
- en: you can see the downloaded private portion
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到已下载的私钥部分
- en: '](img/B16777_04_014.jpg)'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_04_014.jpg)'
- en: Figure 4.14 – The public portion of the generated key pair. At the top, you
    can see the downloaded private portion
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.14 – 生成的密钥对的公钥部分。在顶部，你可以看到已下载的私钥部分
- en: Important note
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: The SSH key resource requires the `Microsoft.Compute` provider to be registered
    in the Azure subscription that you are planning to use. If you are the owner of
    the subscription, Azure will automatically register the providers for you when
    you deploy the resources; otherwise, you will need to request the subscription
    owner to register this provider for you while following the instructions provided
    in [*Chapter 2*](B16777_02_Final_VK_ePub.xhtml#_idTextAnchor026), *Deploying Azure
    Machine Learning Workspace Resources*.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: SSH 密钥资源要求 `Microsoft.Compute` 提供程序在你计划使用的 Azure 订阅中注册。如果你是订阅的所有者，Azure 会在你部署资源时自动为你注册提供程序；否则，你需要请求订阅所有者为你注册该提供程序，并按照[*第
    2 章*](B16777_02_Final_VK_ePub.xhtml#_idTextAnchor026)中提供的说明进行操作，*部署 Azure 机器学习工作区资源*。
- en: So far, you have learned how to provision a compute instance and configure an
    SSH key, which will allow you to remote connect to that compute. You can also
    use this SSH key to connect to remote clusters, which you will provision in the
    next section, *Compute clusters*. In the following subsection, you will learn
    about the advanced configuration options of the compute instance provisioning
    wizard.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你已经学习了如何配置计算实例并配置 SSH 密钥，这将允许你远程连接到该计算实例。你还可以使用这个 SSH 密钥连接到远程集群，接下来你将在*计算集群*部分进行配置。在接下来的子章节中，你将了解计算实例配置向导的高级配置选项。
- en: Advanced compute instance settings
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 高级计算实例设置
- en: 'In the compute provisioning wizard, you can optionally configure some advanced
    settings. One of them, is the **Enable virtual network** option, which allows
    you to attach the provisioned compute within a virtual network and to a specific
    subnet of that network, as shown in the following screenshot:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算资源配置向导中，你可以选择性地配置一些高级设置。其中之一是**启用虚拟网络**选项，它允许你将配置好的计算资源附加到一个虚拟网络中，并连接到该网络的特定子网，如下图所示：
- en: '![Figure 4.15 – Attaching the compute instance to a specific subnet'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.15 – 将计算实例附加到特定子网'
- en: '](img/B16777_04_015.jpg)'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_04_015.jpg)'
- en: Figure 4.15 – Attaching the compute instance to a specific subnet
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.15 – 将计算实例附加到特定子网
- en: 'This feature unlocks multiple advanced networking topologies. The most common
    one is when you are planning to access data sources that are not accessible over
    the internet. For example, if you have a storage account that you have firewall-protected
    to deny access over the internet, you normally deploy a **private endpoint** in
    a specific subnet to allow access to that specific storage account. When you provision
    your compute instance and configure it to be on the same subnet using the preceding
    option, the compute instance will be able to access the protected storage account,
    as shown in the following diagram:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 此功能解锁了多种高级网络拓扑。最常见的情况是当你计划访问无法通过互联网访问的数据源时。例如，如果你有一个存储帐户，并且该帐户的防火墙设置为禁止互联网访问，通常会在特定子网中部署一个**私有端点**，以允许访问该存储帐户。当你配置计算实例并通过上述选项将其设置为与该子网相同时，计算实例将能够访问受保护的存储帐户，如下图所示：
- en: '![Figure 4.16 – Accessing a storage account that is only accessible through
    a private endpoint'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '![图4.16 – 通过私有端点访问仅可通过私有端点访问的存储帐户'
- en: '](img/B16777_04_016.jpg)'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_04_016.jpg)'
- en: Figure 4.16 – Accessing a storage account that is only accessible through a
    private endpoint
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.16 – 通过私有端点访问仅可通过私有端点访问的存储帐户
- en: 'Another advanced option shown in the wizard is **Assign to another user**.
    This option ties back to the *Creating custom roles* section of [*Chapter 2*](B16777_02_Final_VK_ePub.xhtml#_idTextAnchor026),
    *Deploying Azure Machine Learning Workspace Resources*, where you learned how
    to create custom roles for your Azure ML workspace. In enterprise environments,
    it is common to not allow end users to deploy whatever compute instance they want.
    This is done by creating a custom role and allowing only the following operations
    for the virtual machines:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 向导中显示的另一个高级选项是**分配给其他用户**。此选项与[*第二章*](B16777_02_Final_VK_ePub.xhtml#_idTextAnchor026)中*创建自定义角色*部分相关，该部分介绍了如何为你的
    Azure ML 工作区创建自定义角色。在企业环境中，通常不允许最终用户自行部署任何计算实例。这是通过创建自定义角色并仅允许以下虚拟机操作来实现的：
- en: '**Microsoft.Compute/virtualMachines/start/action**'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Microsoft.Compute/virtualMachines/start/action**'
- en: '**Microsoft.Compute/virtualMachines/restart/action**'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Microsoft.Compute/virtualMachines/restart/action**'
- en: '**Microsoft.Compute/virtualMachines/deallocate/action**'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Microsoft.Compute/virtualMachines/deallocate/action**'
- en: 'In those environments, an administrator (or someone who has the **Microsoft.Compute/virtualMachines/write**
    permission) can provision compute instances and assign them to a specific person
    who may not be able to provision the compute instance on their own, as shown in
    the following screenshot:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些环境中，管理员（或具有**Microsoft.Compute/virtualMachines/write**权限的人）可以配置计算实例并将其分配给某个可能无法自行配置计算实例的特定人员，如下图所示：
- en: '![Figure 4.17 – Assigning the provisioned compute instance to a fellow data
    scientist'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '![图4.17 – 将已配置的计算实例分配给另一位数据科学家'
- en: '](img/B16777_04_017.jpg)'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_04_017.jpg)'
- en: Figure 4.17 – Assigning the provisioned compute instance to a fellow data scientist
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.17 – 将已配置的计算实例分配给另一位数据科学家
- en: Although this is a nice feature that the web interface wizard provides, it doesn't
    scale well when you need to provision multiple compute instances for multiple
    data scientists. Therefore, most of the time, administrators prefer to deploy
    compute instances through **ARM template** deployment. They can generate and download
    the template through this wizard and then deploy it for multiple users using the
    **Azure CLI** and pass the user ID as a parameter, as you saw in [*Chapter 2*](B16777_02_Final_VK_ePub.xhtml#_idTextAnchor026),
    *Deploying Azure Machine Learning Workspace Resources*.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这是网页界面向导提供的一个很好的功能，但当你需要为多个数据科学家配置多个计算实例时，它的扩展性较差。因此，大多数情况下，管理员更喜欢通过**ARM模板**部署计算实例。管理员可以通过该向导生成并下载模板，然后使用**Azure
    CLI**将其部署给多个用户，并将用户ID作为参数传递，正如你在[*第二章*](B16777_02_Final_VK_ePub.xhtml#_idTextAnchor026)中所见，*部署
    Azure 机器学习工作区资源*。
- en: So far, you have seen how to provision a compute instance. In the next section,
    you will learn how to manage compute instances.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你已经了解了如何配置计算实例。在下一节中，你将学习如何管理计算实例。
- en: Managing your compute instances
  id: totrans-106
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 管理计算实例
- en: 'Once you have provisioned at least a single compute instance, the **Manage**
    | **Compute** | **Compute instances** interface changes to a list that shows the
    available instances in the workspace. By default, the list is filtered to show
    only the instances that you can use, meaning those that you provisioned on your
    own or someone else provisioned on your behalf:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你至少配置了一个计算实例，**管理** | **计算** | **计算实例**界面将变成一个列表，显示工作区中可用的实例。默认情况下，列表会过滤，仅显示你可以使用的实例，也就是说那些你自己配置的或其他人代表你配置的实例：
- en: '![Figure 4.18 – Compute instances list'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.18 – 计算实例列表'
- en: '](img/B16777_04_018.jpg)'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_04_018.jpg)'
- en: Figure 4.18 – Compute instances list
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.18 – 计算实例列表
- en: From here, you can start, stop, restart, and delete the compute instances. When
    you start a compute instance, the resource's status changes to **Running** and
    the **Applications** column offers links to open a Terminal on the compute instance
    or open the Jupyter, JupyterLab, RStudio, and VS Code third-party authoring experiences.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 从这里，你可以启动、停止、重启和删除计算实例。当你启动一个计算实例时，资源的状态会变为**运行中**，并且**应用程序**列会提供链接，打开该计算实例的终端，或者打开
    Jupyter、JupyterLab、RStudio 和 VS Code 等第三方创作体验。
- en: 'Before you open any of those three editing experiences, you will have to accept
    an important notice regarding the code you can execute in those environments,
    as shown in the following screenshot:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在你打开这些三种编辑体验之前，你必须接受一个重要的通知，关于你可以在这些环境中执行的代码，如下图所示：
- en: '![Figure 4.19 – Warning message about the code you execute within Azure ML
    Studio'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.19 – 关于你在 Azure ML Studio 执行代码的警告消息'
- en: '](img/B16777_04_019.jpg)'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_04_019.jpg)'
- en: Figure 4.19 – Warning message about the code you execute within Azure ML Studio
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.19 – 关于你在 Azure ML Studio 执行代码的警告消息
- en: It is important for you to understand that if you download a random script from
    the internet, it may contain malicious code, which may enable others to steal
    data or even access tokens from your account, something that may enable them to
    access Azure resources on your behalf.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要理解，如果你从互联网下载一个随机脚本，它可能包含恶意代码，可能会让其他人窃取数据或甚至访问你账户的令牌，这可能使他们能够代表你访问 Azure 资源。
- en: JupyterLab and Jupyter are very popular authoring experiences for Jupyter notebooks,
    Python script editing, and accessing the terminal to execute various commands,
    as shown in the following screenshot. When you click to open these editing experiences,
    a new browser tab will open. If you take a look at the URL on the new browser
    tab, you will notice that it consists of the compute instance's name, the region
    where this compute instance is located, and the suffix **instances.azureml.ms**.
    This is the reason why, in the previous section, *Provisioning a compute instance*,
    when you were provisioning a compute instance, you had to select a name that had
    to be unique within the Azure region where you are deploying the specific compute
    instance.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: JupyterLab 和 Jupyter 是非常流行的 Jupyter 笔记本创作体验、Python 脚本编辑以及访问终端执行各种命令的工具，如下图所示。当你点击打开这些编辑体验时，会打开一个新的浏览器标签页。如果你查看新标签页上的
    URL，你会注意到它由计算实例的名称、该计算实例所在的区域以及后缀**instances.azureml.ms**组成。这就是为什么在前面一节中，*配置计算实例*时，当你配置计算实例时，必须选择一个在你所在
    Azure 区域内唯一的名称的原因。
- en: 'All these third-party authoring experiences have a strong community around
    them, and you can use them if you are already familiar with them. However, note
    that Azure ML offers the **Author** | **Notebooks** experience, an augmented editing
    experience on top of JupyterLab that adds capabilities such as IntelliSense, something
    you will be using from [*Chapter 7*](B16777_07_Final_VK_ePub.xhtml#_idTextAnchor102),
    *The Azure ML Python SDK*, onward:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些第三方创作体验都有着强大的社区支持，你可以在已经熟悉的情况下使用它们。然而，请注意，Azure ML 提供了**作者** | **笔记本**体验，这是基于
    JupyterLab 的增强编辑体验，增加了像 IntelliSense 这样的功能，从[*第 7 章*](B16777_07_Final_VK_ePub.xhtml#_idTextAnchor102)《Azure
    ML Python SDK》开始，你将使用到这些功能：
- en: '![Figure 4.20 – The JupyterLab editing experience'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.20 – JupyterLab 编辑体验'
- en: '](img/B16777_04_020.jpg)'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_04_020.jpg)'
- en: Figure 4.20 – The JupyterLab editing experience
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.20 – JupyterLab 编辑体验
- en: 'Clicking on the **Terminal** link in the **Applications** columns will open
    a new browser tab. You will be transferred to the **Author** | **Notebooks** section.
    Here, a web-based terminal will open, allowing you to issue commands to the compute
    instance:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 点击**应用程序**栏中的**终端**链接将打开一个新的浏览器标签页。你将被转到**作者** | **笔记本**部分。在这里，会打开一个基于 Web 的终端，允许你向计算实例发出命令：
- en: '![Figure 4.21 – Getting access to a terminal through the browser'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.21 – 通过浏览器获取终端访问'
- en: '](img/B16777_04_021.jpg)'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_04_021.jpg)'
- en: Figure 4.21 – Getting access to a terminal through the browser
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.21 – 通过浏览器获取终端访问
- en: When you don't need the compute instance, such as during the weekend, you can
    stop it to avoid incurring costs. The compute instance will transition to the
    **Stopped** status and the **Applications** links will be disabled. Starting a
    stopped compute instance takes some time.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 当你不需要计算实例时，比如在周末，你可以停止它以避免产生费用。计算实例将转为**已停止**状态，且**应用程序**链接将被禁用。启动已停止的计算实例需要一些时间。
- en: If you have finished working with a compute instance, such as when the research
    phase of the project has been completed, you can **Delete** it to deallocate the
    reserved CPU cores that count against your subscription's quota. You can view
    the current quota by clicking on the corresponding **View quota** option from
    the menu shown in *Figure 4.18*.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你已经完成了与计算实例的工作，例如项目的研究阶段已经结束，你可以**删除**它，以释放占用的 CPU 核心，这些核心会计入你订阅的配额。你可以通过点击菜单中相应的**查看配额**选项来查看当前的配额，如*图
    4.18*所示。
- en: 'For now, you can stop your compute instance. You will start it again in the
    *Data drift detection* section:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你可以停止你的计算实例。你将在*数据漂移检测*部分重新启动它：
- en: '![Figure 4.22 – Stopped compute instance'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.22 – 已停止的计算实例'
- en: '](img/B16777_04_022.jpg)'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_04_022.jpg)'
- en: Figure 4.22 – Stopped compute instance
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.22 – 已停止的计算实例
- en: In this section, you learned how to provision and manage a compute instance
    that will provide you with the necessary computational power to author notebooks
    and scripts, as well as potentially execute small-scale training and inference
    pipelines. In the next section, you will learn how to provision a compute cluster,
    a compute resource that will be able to scale up and down to accommodate multiple
    training and inference pipelines in parallel.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你学会了如何配置和管理计算实例，这些实例将为你提供必要的计算能力，用于编写笔记本和脚本，并可能执行小规模的训练和推理管道。在下一节中，你将学习如何配置计算集群，这是一种计算资源，能够根据需要进行扩展或缩减，以同时支持多个训练和推理管道。
- en: Compute clusters
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 计算集群
- en: A compute cluster is a group of interconnected virtual machines that scale out
    and in to accommodate a queue of tasks. This means that the cluster can have only
    a few or even zero nodes in it to avoid incurring costs when it's not needed,
    and it can also scale out to multiple nodes when you want to run a lot of tasks
    in parallel or perform a distributed ML training process.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 计算集群是一组相互连接的虚拟机，这些虚拟机可以根据任务队列的需要进行扩展或缩减。这意味着，集群在不需要时可以只有几个节点，甚至没有节点，从而避免产生不必要的费用；而在需要运行大量任务并行处理或执行分布式机器学习训练过程时，它也可以扩展到多个节点。
- en: 'The creation process is very similar to provisioning a compute instance. Let''s
    take a look:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 创建过程与配置计算实例非常相似。让我们来看看：
- en: Start by clicking the **New** button in the corresponding **Compute clusters**
    tab, as shown in *Figure 4.23*.![Figure 4.23 – Creating a new compute cluster
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，点击**计算集群**标签页中的**新建**按钮，如*图 4.23*所示。![图 4.23 – 创建新的计算集群
- en: '](img/B16777_04_023.jpg)'
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16777_04_023.jpg)'
- en: Figure 4.23 – Creating a new compute cluster
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.23 – 创建新的计算集群
- en: You will notice that the compute cluster provisioning wizard offers one additional
    option in comparison to the compute instances called **Virtual machine priority**,
    as shown in the following screenshot. Low-priority virtual machines take advantage
    of the surplus capacity in the Azure region where you want to provision a compute
    cluster. These virtual machines offer a significantly reduced price compared to
    dedicated VMs, but the compute nodes are not guaranteed to be available when you
    need them, or even if they will remain in your possession until the scheduled
    job is completed. This means that you may need to wait a long time until you can
    allocate such a VM, and a step in your training process may stop in the middle
    of its execution. Given these characteristics of low-priority VMs, you normally
    use this type of cluster when you have jobs that are not time-sensitive and consist
    of small running steps, or steps that automatically persist their state and can
    resume execution if they are evicted. For the purposes of this book, you can select
    the **Dedicated** option to avoid unexpected long waiting times when allocating
    compute nodes.
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您会注意到，与计算实例相比，计算集群配置向导提供了一个额外的选项，称为**虚拟机优先级**，如下图所示。低优先级虚拟机利用您希望配置计算集群的 Azure
    区域中的剩余容量。这些虚拟机的价格相比专用虚拟机大幅降低，但计算节点在您需要时可能无法提供，甚至可能在计划任务完成之前就被回收。这意味着，您可能需要等待较长时间才能分配到这样的虚拟机，而且在训练过程中某个步骤可能会中断执行。由于低优先级虚拟机具有这些特点，通常在您有一些对时间不敏感的任务，且这些任务由小的运行步骤组成，或者这些步骤能够自动保存其状态并在被驱逐后恢复执行时，您会使用这种类型的集群。为了本书的目的，您可以选择**专用**选项，以避免在分配计算节点时出现意外的长时间等待。
- en: In the **Virtual machine type** option, select **GPU** and select the cheapest
    VM size available from the **Select from recommended options** list seen in *Figure
    4.24*.
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**虚拟机类型**选项中，选择**GPU**，并从**从推荐选项中选择**列表中选择最便宜的虚拟机大小，如*图 4.24*所示。
- en: Important note
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 重要提示
- en: By default, free trial subscriptions do not allow you to provision GPU computes.
    Even if you change to a pay-as-you-go subscription, you will need to make a request
    through the Azure portal to increase your quota. If you run into a lack of quota
    issue, you can select CPU-based computes instead of GPU-based ones. For the purposes
    of this book, you do not need GPU-based clusters.
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 默认情况下，免费试用订阅不允许您配置 GPU 计算。即使您更改为按需订阅，您仍然需要通过 Azure 门户提交请求以增加配额。如果遇到配额不足的问题，您可以选择基于
    CPU 的计算，而不是基于 GPU 的计算。为了本书的目的，您无需使用基于 GPU 的集群。
- en: '![Figure 4.24 – The first page of the compute cluster provisioning wizard'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.24 – 计算集群配置向导的第一页'
- en: '](img/B16777_04_024.jpg)'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16777_04_024.jpg)'
- en: Figure 4.24 – The first page of the compute cluster provisioning wizard
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.24 – 计算集群配置向导的第一页
- en: 'Click **Next** to continue to the second page of the wizard:'
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 单击**下一步**以继续进入向导的第二页：
- en: On the second page of the wizard, you will need to specify a cluster name. This
    name is going to be how you reference this cluster in the web experience and through
    code, so make sure it's something that represents what this cluster is meant for,
    such as `gpu-cluster`:![Figure 4.25 – The second page of the compute cluster provisioning
    wizard
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在向导的第二页中，您需要指定一个集群名称。这个名称将在网页界面和代码中用于引用该集群，因此请确保选择一个能代表该集群用途的名称，例如 `gpu-cluster`：![图
    4.25 – 计算集群配置向导的第二页
- en: '](img/B16777_04_025.jpg)'
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16777_04_025.jpg)'
- en: Figure 4.25 – The second page of the compute cluster provisioning wizard
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.25 – 计算集群配置向导的第二页
- en: You can also tweak the minimum and maximum number of nodes and the idle seconds
    before the cluster scales down. Every time you request the cluster to perform
    a job, the tasks of the job are added to the cluster's scheduler. If the cluster
    doesn't have enough nodes to execute the scheduled tasks, it will scale out by
    adding a compute node to the cluster. Adding a node to the cluster takes some
    time, as you need to allocate the VM. Therefore, instead of deallocating the VM
    immediately once the scheduled tasks have completed, the cluster can wait for
    the defined idle period, just in case a new task gets scheduled.
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您还可以调整节点的最小和最大数量，以及在集群缩减之前的空闲秒数。每次请求集群执行任务时，任务将添加到集群的调度器中。如果集群没有足够的节点来执行调度的任务，它将通过向集群添加计算节点来进行扩展。向集群添加节点需要一些时间，因为您需要分配虚拟机。因此，在调度任务完成后，集群不会立即释放虚拟机，而是可以等待定义的空闲时间，以防新的任务被调度。
- en: 'Similar to the compute instances, you can **Enable SSH access** if you want
    to remotely connect to the compute cluster nodes to troubleshoot job executions.
    Due to the ephemeral nature of the cluster nodes, the wizard allows you to specify
    an **Admin password** if you want, instead of a **SSH public key**, as shown in
    the following screenshot:'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 与计算实例类似，如果您希望远程连接到计算集群节点以排查作业执行问题，您可以 **启用 SSH 访问**。由于集群节点是临时的，向导允许您指定 **管理员密码**，如果您希望的话，而不是使用
    **SSH 公钥**，如下图所示：
- en: '![Figure 4.26 – Compute clusters allow you to use an Admin password instead
    of an SSH public key'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.26 – 计算集群允许您使用管理员密码而不是 SSH 公钥'
- en: '](img/B16777_04_026.jpg)'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16777_04_026.jpg)'
- en: Figure 4.26 – Compute clusters allow you to use an Admin password instead of
    an SSH public key
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.26 – 计算集群允许您使用管理员密码而不是 SSH 公钥
- en: 'Under **Advanced settings**, you can find the **Enable virtual network** option,
    which you saw when we looked at compute instances in the previous section. In
    addition to that option, you have the option to **Assign a managed identity**
    to the compute cluster:'
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在 **高级设置** 下，您可以找到 **启用虚拟网络** 选项，您在上一节查看计算实例时也看到了这个选项。除了这个选项，您还有一个选项是 **为计算集群分配托管身份**：
- en: '![Figure 4.27 – Assigning a managed identity to the compute cluster'
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.27 – 为计算集群分配托管身份'
- en: '](img/B16777_04_027.jpg)'
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16777_04_027.jpg)'
- en: Figure 4.27 – Assigning a managed identity to the compute cluster
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.27 – 为计算集群分配托管身份
- en: Azure allows you to attach an **Azure Active Directory** (**AAD**) identity
    to the compute cluster nodes, allowing the code that executes in those VMs to
    access Azure resources using that identity. **Managed identities** eliminate the
    need to have credentials stored within your scripts. The identity is attached
    to the specific VM, and your code can request AAD access tokens through the Azure
    Instance Metadata Service or through the Python SDK without a password, as long
    as the code is executed within that specific VM.
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Azure 允许您为计算集群节点附加 **Azure Active Directory**（**AAD**）身份，这样在这些虚拟机中执行的代码可以使用该身份访问
    Azure 资源。**托管身份**消除了在脚本中存储凭据的需求。身份与特定的虚拟机关联，您的代码可以通过 Azure 实例元数据服务或 Python SDK
    请求 AAD 访问令牌，无需密码，只要代码在该特定虚拟机中执行。
- en: 'For the purposes of this book, you will not modify any option here. Name the
    cluster `gpu-cluster` and click on **Create** to create your first zero node,
    GPU-based compute cluster:'
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 本书的目的下，您不需要在此修改任何选项。将集群命名为 `gpu-cluster`，然后点击 **创建** 来创建您的第一个零节点 GPU 基础计算集群：
- en: '![Figure 4.28 – Your first GPU-based compute cluster is ready to use'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.28 – 您的第一个基于 GPU 的计算集群已准备好使用'
- en: '](img/B16777_04_028.jpg)'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_04_028.jpg)'
- en: Figure 4.28 – Your first GPU-based compute cluster is ready to use
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.28 – 您的第一个基于 GPU 的计算集群已准备好使用
- en: 'Notice that in the preceding screenshot, the compute cluster has been provisioned
    successfully but that there are 0 nodes in it, which means that it doesn''t incur
    any cost. You can also see the following metrics in this list:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在前面的截图中，计算集群已成功配置，但其中没有节点，这意味着它不会产生任何费用。您还可以在此列表中看到以下指标：
- en: '**Idle nodes**: These are the nodes waiting for a task to be scheduled or to
    be de-allocated once the idle time has passed.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**空闲节点**：这些是等待任务调度或在空闲时间过去后等待被释放的节点。'
- en: '**Busy nodes**: These are the nodes that are currently executing a task.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**忙碌节点**：这些是当前正在执行任务的节点。'
- en: '**Unprovisioned nodes**: These are the nodes that haven''t been allocated yet
    but can potentially be allocated if the number of scheduled tasks increases.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**未配置的节点**：这些是尚未分配的节点，但如果计划任务的数量增加，它们可能会被分配。'
- en: From this list, you can delete the cluster if you don't want it anymore.
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从此列表中，你可以删除集群，如果你不再需要它的话。
- en: 'If you click on the compute cluster''s name, you will be able to see the cluster''s
    details, as shown in the following screenshot. From this view, you can edit the
    minimum and maximum number of nodes, the idle seconds before the cluster scales
    down, and change how the managed identity that you configured previously is assigned.
    In fact, it is common for data science teams to modify their predefined compute
    clusters in the morning so that they have at least one node in them. It helps
    them avoid waiting for the first node to be allocated. When the day is over, they
    change the setting down to zero to save on costs:'
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果你点击计算集群的名称，你将能够看到集群的详细信息，如下图所示。从此视图，你可以编辑最小和最大节点数、集群缩减前的空闲秒数，并更改之前配置的托管身份分配方式。事实上，数据科学团队通常会在早晨修改他们预定义的计算集群配置，以便确保集群中至少有一个节点，这样他们就不必等待第一个节点分配。当一天结束时，他们会将设置改为零，以节省成本：
- en: '![Figure 4.29 – Compute cluster''s details about where you can edit its configuration'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.29 – 计算集群的详细信息，展示你可以编辑其配置的位置'
- en: '](img/B16777_04_029.jpg)'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_04_029.jpg)'
- en: Figure 4.29 – Compute cluster's details about where you can edit its configuration
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.29 – 计算集群的详细信息，展示你可以编辑其配置的位置
- en: In this section, you learned how to provision a compute cluster. These clusters
    are used to perform training jobs and batch inferences. In the next section, you
    will learn how to provision an **Azure Kubernetes Service** (**AKS**), which allows
    you to perform real-time inferences at a large scale.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，你学习了如何配置计算集群。这些集群用于执行训练任务和批量推理。在下一部分，你将学习如何配置**Azure Kubernetes 服务**（**AKS**），它允许你在大规模上执行实时推理。
- en: Inference clusters
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 推理集群
- en: Kubernetes is a portable, extensible, open source platform for managing containerized
    workloads and services. It has been widely used to operationalize various forms
    of applications, from web applications to model inference REST APIs, due to its
    ability to auto scale and auto recover from failures. **Azure Kubernetes Service**
    (**AKS**) is the managed version of the Kubernetes cluster in Azure, a service
    that lets you focus on your workload and let Azure manage the operating bits of
    the cluster, such as its master nodes.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 是一个便携、可扩展的开源平台，用于管理容器化的工作负载和服务。由于其能够自动扩展并能从故障中自动恢复，它已被广泛用于将各种应用投入生产环境，从
    Web 应用到模型推理 REST API。**Azure Kubernetes 服务**（**AKS**）是 Azure 中的 Kubernetes 集群的托管版本，一项让你专注于工作负载并让
    Azure 管理集群操作部分（例如其主节点）的服务。
- en: 'If you are not familiar with AKS, then don''t worry – the following diagram
    provides a high-level overview of the components involved. In a nutshell, you
    can configure **Node pools**, a group of virtual machines that have the same configuration;
    for example, virtual machines with GPU cards on them. These pools can have one
    **node** (or more), which is a virtual machine. Within each node, you can host
    one or more **pods**. Each pod consists of a couple of **Docker images**, which
    form an application unit, one of which may be the model you want to operationalize.
    Each pod can be replicated into multiple nodes, either to accommodate increased
    load or for resiliency reasons in the case a node goes down:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你不熟悉 AKS，不用担心——下面的图表提供了涉及组件的高级概览。简而言之，你可以配置**节点池**，即一组配置相同的虚拟机；例如，配置有 GPU
    卡的虚拟机。这些池可以包含一个**节点**（或更多节点），节点即为虚拟机。在每个节点内，你可以托管一个或多个**Pod**。每个 Pod 包含一对**Docker
    镜像**，这些镜像组成一个应用单元，其中一个镜像可能是你想要投入运营的模型。每个 Pod 可以在多个节点中进行复制，既可以是为了应对更高的负载，也可以是在某个节点出现故障时增加容错性：
- en: '![Figure 4.30 – High-level overview of AKS concepts showing Pod X being replicated
    in two nodes'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.30 – AKS 概念的高级概览，展示 Pod X 在两个节点中复制'
- en: '](img/B16777_04_030.jpg)'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_04_030.jpg)'
- en: Figure 4.30 – High-level overview of AKS concepts showing Pod X being replicated
    in two nodes
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.30 – AKS 概念的高级概览，展示 Pod X 在两个节点中复制
- en: 'From within Azure ML Studio, you can create or attach an existing AKS cluster
    to your workspace. You do *not* need to create an AKS cluster for the purposes
    of this book. Let''s get started:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Azure ML Studio 中，你可以创建或将现有的 AKS 集群附加到你的工作区。你*不需要*为本书的目的创建 AKS 集群。让我们开始吧：
- en: The creation wizard can be invoked by clicking on the **New** button in the
    **Inference clusters** tab, seen in *Figure 4.31*:![Figure 4.31 – Create or attach
    an AKS cluster to the Azure ML workspace
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建向导可以通过点击**新建**按钮，在**推理集群**标签页中启动，如*图4.31*所示：![图4.31 – 创建或将AKS集群附加到Azure ML工作区
- en: '](img/B16777_04_031.jpg)'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16777_04_031.jpg)'
- en: Figure 4.31 – Create or attach an AKS cluster to the Azure ML workspace
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图4.31 – 创建或将AKS集群附加到Azure ML工作区
- en: Important note
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 重要说明
- en: When you provision an AKS cluster, a new resource group is created within your
    Azure subscription that hosts all the components needed for AKS to work. This
    requires additional permissions at the subscription level. If you can't create
    resource groups, AKS cluster provisioning will fail.
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 当您配置AKS集群时，一个新的资源组将在您的Azure订阅中创建，托管AKS工作所需的所有组件。这需要在订阅级别的额外权限。如果您无法创建资源组，AKS集群配置将失败。
- en: In the first step of the wizard, you can either attach an existing AKS cluster
    or create a new one. If you choose to create one, you will have to specify the
    Azure region where you want the AKS cluster to be deployed. You will also need
    to specify the node pool's VM size, similar to what you did when you deployed
    a compute instance:![Figure 4.32 – Step 1 of provisioning an inference AKS cluster
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在向导的第一步中，您可以选择附加一个现有的AKS集群或创建一个新的集群。如果选择创建一个新的集群，您将需要指定希望AKS集群部署的Azure区域。您还需要指定节点池的虚拟机大小，类似于您部署计算实例时所做的操作：![图4.32
    – 配置推理AKS集群的步骤1
- en: '](img/B16777_04_032.jpg)'
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16777_04_032.jpg)'
- en: Figure 4.32 – Step 1 of provisioning an inference AKS cluster
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图4.32 – 配置推理AKS集群的步骤1
- en: Clicking **Next** will bring you to the **Settings** page, where you need to
    specify the name of the AKS cluster. You also need to specify the purpose of the
    cluster. If this is a production cluster, the number of virtual CPUs in the cluster
    must be more than 12; this means that if you selected a 4 core VM size, you will
    need at least three nodes to be able to provision a production-ready AKS cluster.
    If this cluster is for development and testing, you can provision just one node.
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**下一步**将带您进入**设置**页面，在此页面中，您需要指定AKS集群的名称。同时，您还需要指定集群的用途。如果这是一个生产集群，则集群中的虚拟CPU数量必须大于12；这意味着如果您选择了4核虚拟机大小，您将需要至少三个节点才能配置一个生产就绪的AKS集群。如果此集群用于开发和测试，您只需配置一个节点即可。
- en: Besides the name and the number of nodes in the node pool, you can configure
    the networking options of the cluster and the SSL certificate that will be used
    to secure the connection to the applications, if you want to expose them through
    an HTTPS endpoint. For the purposes of this book, you do not need to modify any
    of those options:![Figure 4.33 – Step 2 of provisioning an inference AKS cluster
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 除了节点池的名称和节点数外，您还可以配置集群的网络选项和用于保护与应用程序连接的SSL证书，如果您希望通过HTTPS端点公开它们。为了本书的目的，您无需修改这些选项：![图4.33
    – 配置推理AKS集群的步骤2
- en: '](img/B16777_04_033.jpg)'
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16777_04_033.jpg)'
- en: Figure 4.33 – Step 2 of provisioning an inference AKS cluster
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图4.33 – 配置推理AKS集群的步骤2
- en: 'Once your cluster has been created, you will be able to delete it or detach
    it from the workspace through the list shown in the following screenshot:'
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦集群创建完成，您将能够通过以下截图所示的列表删除或将其从工作区中分离：
- en: '![Figure 4.34 – List of AKS inference clusters'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '![图4.34 – AKS推理集群列表'
- en: '](img/B16777_04_034.jpg)'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_04_034.jpg)'
- en: Figure 4.34 – List of AKS inference clusters
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.34 – AKS推理集群列表
- en: Important note
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 重要说明
- en: AKS is the production-ready way of deploying real-time endpoints. In the exam,
    when you are asked where you would deploy a production load, AKS should be the
    right answer. Nonetheless, because an AKS cluster is an expensive resource, this
    book will not use it in its examples. If you are using a free subscription, you
    will probably not have enough cores quota to be able to provision one. If you
    did provision one, make sure you keep an eye on the cost to avoid running out
    of credit.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: AKS是部署实时端点的生产就绪方式。在考试中，当被问到将生产负载部署在哪里时，AKS应该是正确答案。尽管如此，由于AKS集群是一种昂贵的资源，本书的示例不会使用它。如果您使用的是免费订阅，您可能没有足够的核心配额来配置一个。如果您配置了一个，请确保关注成本，以免用完信用额度。
- en: In this section, you learned about how Azure ML can help you attach to or provision
    an AKS cluster so that you can host your production real-time inference endpoints.
    In the next section, you will learn how to attach existing compute resources to
    your workspace.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你了解了如何使用 Azure ML 帮助你连接或配置 AKS 集群，以便托管生产实时推理端点。在下一节中，你将学习如何将现有的计算资源附加到你的工作区。
- en: Attached compute
  id: totrans-200
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附加的计算资源
- en: If you already have compute resources provisioned, not necessarily in the subscription
    you have deployed your Azure ML workspace, you can attach them to your workspace.
    Attaching those resources allows you to reuse them, especially in cases where
    they are underutilized. A common scenario is for a department to have an Ubuntu-based
    **Data Science Virtual Machine** (**DSVM**), which may be running 24 hours, 7
    days of the week, to serve a legacy web application. You can reuse this resource
    in your experiments by attaching it to your workspace and then referencing it
    to execute various tasks, the same way you would reference a compute cluster to
    perform a task.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你已经配置了计算资源，且不一定是在你部署 Azure ML 工作区的订阅中，你可以将它们附加到你的工作区。附加这些资源可以让你重新利用它们，特别是在它们未被充分利用的情况下。一种常见的情况是，一个部门拥有一个基于
    Ubuntu 的 **数据科学虚拟机** (**DSVM**)，可能每天 24 小时、每周 7 天都在运行，以服务于一个遗留的 Web 应用程序。你可以通过将其附加到工作区并在实验中引用它来重用这个资源，执行各种任务，就像你引用计算集群来执行任务一样。
- en: 'The studio experience allows you to attach multiple types of computes, including
    the following popular targets:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 工作室体验允许你附加多种类型的计算资源，包括以下流行目标：
- en: '**Virtual machines**: You can attach existing Ubuntu-based virtual machines
    that are publicly accessible over the internet. This option includes potential
    DSVMs you may already have.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**虚拟机**：你可以附加现有的基于 Ubuntu 的虚拟机，这些虚拟机通过互联网公开可访问。这个选项包括你可能已经拥有的 DSVM。'
- en: '**Azure Databricks** and **HDInsights**: These options allow you to attach
    existing **Apache Spark**-based computes to your workspace.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Azure Databricks** 和 **HDInsights**：这些选项允许你将现有的基于 **Apache Spark** 的计算资源连接到你的工作区。'
- en: '**Azure Data Factory**: The Azure Data Factory resource allows you to perform
    copy activities from one data source to another. For example, you can copy from
    a storage account to a SQL database using that resource. Azure Data Factory is
    currently only supported through the Azure ML SDK and not from the studio experience.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Azure Data Factory**：Azure Data Factory 资源允许你从一个数据源执行复制操作到另一个数据源。例如，你可以使用该资源将数据从存储帐户复制到
    SQL 数据库。Azure Data Factory 目前仅通过 Azure ML SDK 支持，而不支持通过工作室体验。'
- en: 'For the purposes of the DP100 exam, you will not need to attach any resources.
    The following screenshot shows how you can initiate the attach wizard from within
    the studio experience:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 DP100 考试而言，你无需附加任何资源。以下截图展示了你如何从工作室体验中启动附加向导：
- en: '![Figure 4.35 – Attaching existing compute resources to your workspace'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.35 – 将现有计算资源附加到你的工作区'
- en: '](img/B16777_04_035.jpg)'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_04_035.jpg)'
- en: Figure 4.35 – Attaching existing compute resources to your workspace
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.35 – 将现有计算资源附加到你的工作区
- en: In this section, you learned how to provision and attach compute resources to
    your Azure ML workspace. This allows you to execute code during the data exploration,
    model training, and model inference phases of your data science projects. In the
    next section, you will learn how to configure connectivity to various data sources,
    something that will enable you to access data.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你了解了如何配置和附加计算资源到你的 Azure ML 工作区。这使得你可以在数据探索、模型训练和模型推理阶段执行代码。在下一节中，你将学习如何配置与各种数据源的连接，这将使你能够访问数据。
- en: Connecting to datastores
  id: totrans-211
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 连接到数据存储
- en: 'Datastores are the engines where your data resides and provide access to anyone
    authorized to do so. In most Python examples you see on the internet, there is
    a connection string that contains the credentials to connect to a database or
    a blob store. There are a couple of drawbacks associated with this technique:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 数据存储是存放你数据的引擎，并为任何有权限的人提供访问权限。在大多数你在互联网上看到的 Python 示例中，都会有一个连接字符串，其中包含连接到数据库或
    Blob 存储的凭证。这个技术有几个缺点：
- en: The credentials stored within these scripts are considered a security violation,
    and you can accidentally expose your protected datasets by publishing a script
    in a public repository such as GitHub.
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 存储在这些脚本中的凭证被视为安全违规行为，通过将脚本发布到公共存储库（如 GitHub）可能会意外暴露你受保护的数据集。
- en: You need to manually update all the scripts when the credentials change.
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当凭据发生变化时，你需要手动更新所有脚本。
- en: Azure ML allows you to have a single centralized location where you define the
    connection properties to various stores. Your credentials are securely stored
    as **secrets** within the workspace's associated **key vault**. In your scripts,
    you reference the datastore using its name and you can access its data without
    having to specify the credentials. If, at some point in time, the credentials
    of a datastore change, you can centrally update them, and all your scripts and
    pipelines will continue to work.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: Azure ML 允许你拥有一个集中式的位置，在那里你可以定义与各种存储的连接属性。你的凭据作为**机密**安全存储在工作区关联的**密钥库**中。在你的脚本中，你通过其名称引用数据存储，并可以访问其数据，而无需指定凭据。如果某个时刻，数据存储的凭据发生变化，你可以在中央位置更新它们，所有的脚本和管道将继续正常工作。
- en: 'You can view all the registered datastores by navigating to the **Manage**
    | **Datastores** section of the studio:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过导航到工作室的**管理** | **数据存储**部分来查看所有注册的数据存储：
- en: '![Figure 4.36 – List of registered datastores in the workspace'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.36 – 工作区中已注册数据存储的列表'
- en: '](img/B16777_04_036.jpg)'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_04_036.jpg)'
- en: Figure 4.36 – List of registered datastores in the workspace
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.36 – 工作区中已注册数据存储的列表
- en: Note that, by default, you already have two datastores registered. The default
    one, named `workspaceblobstore`, is the default blob storage where all the pipeline
    metrics and artifacts are stored. Your workspace needs to have a default datastore.
    As you will see in [*Chapter 7*](B16777_07_Final_VK_ePub.xhtml#_idTextAnchor102),
    *The Azure ML Python SDK*, you can even reference that store very easily through
    the Python SDK. The other store, named `workspacefilestore`, is a file share datastore
    that you can mount on your local machine and upload files to.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，默认情况下，你已经注册了两个数据存储。默认的那个，名为`workspaceblobstore`，是默认的 Blob 存储，用于存储所有的管道指标和工件。你的工作区需要有一个默认的数据存储。正如你将在[*第
    7 章*](B16777_07_Final_VK_ePub.xhtml#_idTextAnchor102)《Azure ML Python SDK》中看到的，你甚至可以通过
    Python SDK非常方便地引用该存储。另一个存储，名为`workspacefilestore`，是一个文件共享数据存储，你可以将其挂载到本地计算机并上传文件。
- en: 'From this list, you can do the following:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 从此列表中，你可以执行以下操作：
- en: 'Update the credentials of a datastore: You need to click on the name of the
    datastore, which will get you its registration details. From there, you can click
    on **Update credentials** to specify the updated value or change the type of authentication,
    something you will see in the next section.'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更新数据存储的凭据：你需要点击数据存储的名称，查看其注册详情。从那里，你可以点击**更新凭据**来指定更新的值，或者更改身份验证类型，这些内容将在下一节中看到。
- en: '**Unregister** a datastore: You can unregister any datastore that is not marked
    as the default datastore.'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**注销**数据存储：你可以注销任何未标记为默认数据存储的数据存储。'
- en: '**Set as default datastore**: Change the default datastore to the one you selected
    from the list.'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**设置为默认数据存储**：将默认数据存储更改为你从列表中选择的存储。'
- en: 'Finally, from this list, you can create a **New datastore** registration, an
    action that activates the new datastore wizard shown in the following screenshot:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，从这个列表中，你可以创建一个**新的数据存储**注册，这是启动新的数据存储向导的操作，如下图所示：
- en: '![Figure 4.37 – New datastore wizard'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.37 – 新的数据存储向导'
- en: '](img/B16777_04_037.jpg)'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_04_037.jpg)'
- en: Figure 4.37 – New datastore wizard
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.37 – 新的数据存储向导
- en: Here, you need to specify a unique datastore name within the Azure ML workspace.
    You must do this to reference this store in your scripts and the various components
    of the studio experience. The next thing you need to select is the datastore type.
    There are a couple of Azure-native datastores that are supported by the Azure
    ML workspace, something you will explore in the next section.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，你需要在 Azure ML 工作区中指定一个唯一的数据存储名称。你必须这样做，以便在脚本和工作室体验的各个组件中引用该存储。接下来，你需要选择数据存储类型。Azure
    ML 工作区支持几种 Azure 本地数据存储，这些内容将在下一节中探讨。
- en: Types of datastores
  id: totrans-230
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据存储类型
- en: 'Azure ML supports two categories of datastores: the ones based on files, such
    as blob storage, file shares, and data lake stores, and relational databases,
    such as Azure SQL and Azure PostgreSQL.'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: Azure ML 支持两类数据存储：基于文件的存储，例如 Blob 存储、文件共享和数据湖存储，以及关系型数据库，例如 Azure SQL 和 Azure
    PostgreSQL。
- en: 'The currently supported datastores are shown in the following diagram:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 当前支持的数据存储如下面的图示所示：
- en: '![Figure 4.38 – Azure ML supported datastores'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.38 – Azure ML 支持的数据存储'
- en: '](img/B16777_04_038.jpg)'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_04_038.jpg)'
- en: Figure 4.38 – Azure ML supported datastores
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.38 – Azure ML 支持的数据存储
- en: The recommendation is to use **Azure Blob Storage**-based datastores. These
    stores are the most cost-effective ones. They provide multiple tiers, such as
    the more expensive premium one, which provides you with increased throughput speeds,
    something that can reduce your training times if you are processing large volumes
    of data.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐使用基于**Azure Blob Storage**的数据存储。这些存储是最具成本效益的存储。它们提供多个层级，例如更昂贵的高级存储，它提供更高的吞吐速度，这可以减少处理大量数据时的训练时间。
- en: On the other hand, **Azure Data Lake Storage Gen 2** builds on top of **Azure
    Blob Storage** by adding hierarchical namespaces. This feature allows data lakes
    to assign access permissions at a folder level. Large enterprises usually structure
    their data lakes with various zones where they store their data. Each zone has
    its own **Access Control List** (**ACL**), which gives permissions to specific
    groups of people. This means that you may be able to see the contents of one folder
    and not the contents of another, while in **Azure Blob Storage**, once you get
    access to a container, you can see all the data within it.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，**Azure Data Lake Storage Gen 2** 在**Azure Blob Storage**的基础上，增加了层次命名空间。这一功能使得数据湖可以在文件夹级别分配访问权限。大型企业通常会按照不同的区域结构来组织数据湖，存储不同的数据。每个区域都有自己的**访问控制列表**（**ACL**），为特定的用户组提供权限。这意味着你可能能够看到某个文件夹的内容，而看不到另一个文件夹的内容，而在**Azure
    Blob Storage**中，一旦你获得了容器的访问权限，就可以看到该容器中的所有数据。
- en: 'If your data resides in a datastore that is not supported out of the box by
    Azure ML, you can copy the data over to an **Azure Blob Storage** or **Azure Data
    Lake Storage Gen 2** easily using the copy tool from **Azure Data Factory**. **Azure
    Data Factory** allows you to copy data from almost anywhere, even if it resides
    within on-premises databases, as shown in the following diagram:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的数据存储不被 Azure ML 开箱即用地支持，你可以通过**Azure Data Factory**的复制工具轻松将数据复制到**Azure
    Blob Storage**或**Azure Data Lake Storage Gen 2**。**Azure Data Factory** 允许你从几乎任何地方复制数据，即使数据存储在本地数据库中，如下图所示：
- en: '![Figure 4.39 – Copying on-premises data to an Azure ML supported datastore
    using Azure Data Factory and the Self-Hosted Integration Runtime'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.39 – 使用 Azure Data Factory 和自托管集成运行时将本地数据复制到 Azure ML 支持的数据存储'
- en: '](img/B16777_04_039.jpg)'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_04_039.jpg)'
- en: Figure 4.39 – Copying on-premises data to an Azure ML supported datastore using
    Azure Data Factory and the Self-Hosted Integration Runtime
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.39 – 使用 Azure Data Factory 和自托管集成运行时将本地数据复制到 Azure ML 支持的数据存储
- en: Important note
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 重要说明
- en: In the *Attached compute* section, you saw that you can attach an `DataTransferStep`.
    Copying data from the on-premises network can be done in the same ADF, but you
    will have to author, execute, and monitor the data pulling pipeline from within
    ADF.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 在*附加计算*部分，你看到了你可以附加一个`DataTransferStep`。从本地网络复制数据也可以在同一个 ADF 中完成，但你需要在 ADF 中编写、执行和监控数据拉取管道。
- en: In this section, you look at the types of datastores supported by Azure ML.
    In the next section, you will learn about the various authentication methods supported
    by those datastores.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 本节介绍了 Azure ML 支持的各种数据存储类型。在下一节中，你将了解这些数据存储支持的各种身份验证方法。
- en: Datastore security considerations
  id: totrans-245
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据存储安全性考虑
- en: 'Depending on the datastore, you will have to specify different type of credentials
    to register it in the Azure ML workspace. For the Azure Blob and Azure File Share
    datastores, you can use the following credentials:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 根据数据存储类型，你需要为其注册到 Azure ML 工作区时指定不同的凭据。对于 Azure Blob 和 Azure 文件共享数据存储，你可以使用以下凭据：
- en: '**Account key**: This gives access to the entire Azure Storage Account.'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**账户密钥**：这授予对整个 Azure 存储账户的访问权限。'
- en: '**Shared Access Signature** (**SAS**) **token**: This is a more granular way
    to assign permissions to the various services of the storage account. Using the
    **Account key**, you can generate an SAS token that allows access to only a specific
    blob container and only for a limited amount of time.'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**共享访问签名**（**SAS**）**令牌**：这是一种更加细粒度的权限分配方式，允许你为存储账户的各种服务分配权限。使用**账户密钥**，你可以生成一个
    SAS 令牌，使其只能访问特定的 blob 容器，并且只能在有限的时间内使用。'
- en: For Azure Data Lake Storage datastores, due to their advanced security features,
    you will need to provide an `tenant_id`) where this entity is registered and has
    a unique ID (referred to as `client_id`). This identity has a password (referred
    to as `client_secret`) that enables your code to access the datastores impersonating
    that identity.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 Azure Data Lake Storage 数据存储，鉴于其高级安全功能，您需要提供一个`tenant_id`，该实体已注册并具有唯一 ID（称为`client_id`）。此身份拥有一个密码（称为`client_secret`），它使得您的代码能够模拟该身份访问数据存储。
- en: For the relational database datastores, you will need to specify the database's
    name, the server's name, and the server port to connect to. For credentials, you
    can either provide a **service principal**, if the datastore supports it, or provide
    the necessary **SQL authentication** credentials, which consist of a database
    user ID and a password.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 对于关系数据库数据存储，您需要指定数据库的名称、服务器的名称和服务器端口进行连接。对于凭证，您可以提供**服务主体**，如果数据存储支持此功能，或者提供必要的**SQL
    身份验证**凭证，后者包括数据库用户 ID 和密码。
- en: 'Some of the datastores allow you to use the workspace''s managed identity for
    data preview and profiling. This option adds the system assigned managed identity
    that has been assigned to the workspace as a Reader to the specific resource,
    allowing the workspace to load a preview of the data within the studio experience.
    This option is available on the datastore registration page, as shown in the following
    screenshot:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 一些数据存储允许您使用工作区的托管身份进行数据预览和分析。此选项会将分配给工作区的系统分配托管身份作为读取者，添加到特定资源中，从而允许工作区在工作室环境中加载数据预览。此选项可在数据存储注册页面上找到，如下图所示：
- en: '![Figure 4.40 – Granting access to the workspace''s managed identity'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.40 – 授予工作区的托管身份访问权限'
- en: '](img/B16777_04_040.jpg)'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_04_040.jpg)'
- en: Figure 4.40 – Granting access to the workspace's managed identity
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.40 – 授予工作区的托管身份访问权限
- en: So far, you have learned how to register various datastores in an Azure ML workspace.
    In the next section, you will learn how to use these registrations to define datasets.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，您已学习了如何在 Azure ML 工作区中注册各种数据存储。在下一节中，您将学习如何利用这些注册信息来定义数据集。
- en: Working with datasets
  id: totrans-256
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用数据集
- en: 'In the previous sections, you were configuring compute and datastore resources
    under the **Manage** section of the studio. With this infrastructure configured,
    you can start pulling data into your registered datastores and register datasets
    in the **Assets** section of the studio:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，您在工作室的**管理**部分配置了计算和数据存储资源。配置好这些基础设施后，您可以开始将数据导入到注册的数据存储中，并在工作室的**资产**部分注册数据集：
- en: '![Figure 4.41 – Datasets in the Assets section of the Azure ML Studio experience'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.41 – 在 Azure ML Studio 中的资产部分的数据集'
- en: '](img/B16777_04_041.jpg)'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_04_041.jpg)'
- en: Figure 4.41 – Datasets in the Assets section of the Azure ML Studio experience
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.41 – 在 Azure ML Studio 中的资产部分的数据集
- en: '**Datasets** is an abstraction layer on top of the data that you are using
    for training and inference. It contains a reference to the physical data''s location
    and provides a series of metadata that can help you understand their shape and
    statistical properties. When you want to access the dataset, you can reference
    it via its name, and you don''t have to worry about credentials or exact file
    paths. Moreover, all the data scientists working on the same workspace can access
    the same datasets, allowing them to experiment on the same data in parallel.'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据集**是您用于训练和推理的基础数据之上的抽象层。它包含指向物理数据位置的引用，并提供一系列元数据，帮助您理解其形状和统计特性。当您想要访问数据集时，可以通过名称引用它，且无需担心凭证或确切的文件路径。此外，所有在同一工作区的
    data scientists 都可以访问相同的数据集，从而允许他们在相同数据上并行进行实验。'
- en: There are two types of datasets – file-based ones and tabular ones. File datasets
    reference a list of files in a datastore. For example, if you are building a computer
    vision model, you will need images that can be downloaded or mounted to your compute
    as a `FileDataset`. The Tabular dataset represents tabular data residing in either
    file-based datastores or relational database datastores. For example, you can
    reference a couple of folders containing `TabularDataset` construct, without having
    to parse the physical files.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集有两种类型——基于文件的和基于表格的。文件数据集引用数据存储中的文件列表。例如，如果你正在构建一个计算机视觉模型，你需要图像，这些图像可以作为`FileDataset`下载或挂载到计算资源上。表格数据集表示存储在文件型数据存储或关系型数据库数据存储中的表格数据。例如，你可以引用包含`TabularDataset`结构的几个文件夹，而不需要解析物理文件。
- en: Another feature of datasets is that you can snapshot their properties and metadata
    using versions. Imagine that you have a folder structure that follows the `weather/<year>/<month>/`
    pattern. For example, you would find the weather measurements for January 2021
    stored under `weather/2021/01/measurements.parquet`. As time flies, you will be
    getting more and more folders, each containing a single file under them. To reproduce
    your training results, you will want to reference the dataset that only contains
    files up to January 2021\. This is exactly where dataset versioning comes in handy.
    While training a model, you register a version of the dataset that contains all
    the files you used for training. Later, you can refer to the dataset and request
    a specific version of it, which will give you a reference to all the files that
    used to be available back then.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集的另一个特点是你可以通过版本快照它们的属性和元数据。假设你有一个遵循`weather/<year>/<month>/`模式的文件夹结构。例如，你会发现2021年1月的天气测量数据存储在`weather/2021/01/measurements.parquet`下。随着时间的推移，你会获得越来越多的文件夹，每个文件夹下面都有一个文件。为了重现你的训练结果，你可能希望引用一个只包含到2021年1月为止文件的数据集。这正是数据集版本控制的用武之地。在训练模型时，你注册一个数据集版本，该版本包含你用于训练的所有文件。稍后，你可以引用该数据集并请求它的特定版本，从而获得对当时可用的所有文件的引用。
- en: Important note
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 重要说明
- en: Dataset versions do *not* copy the underlying data. They only store a reference
    to the actual files and the dataset metadata you will read about in the upcoming
    sections. This means that if you change the contents of a file instead of adding
    a new file, the dataset version will not load the same data.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集版本*不*复制底层数据。它们只存储对实际文件的引用以及你将在接下来的章节中阅读到的数据集元数据。这意味着，如果你更改了文件的内容而不是添加新文件，数据集版本将不会加载相同的数据。
- en: Registering datasets
  id: totrans-266
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 注册数据集
- en: 'You can register datasets from various sources, as shown in the following screenshot,
    including from the datastore you learned how to register in the *Connecting to
    datastores* section:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从多个来源注册数据集，如下图所示，包括你在*连接数据存储*部分学到的如何注册的存储库：
- en: '![Figure 4.42 – Possible options for registering datasets'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.42 – 注册数据集的可能选项'
- en: '](img/B16777_04_042.jpg)'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_04_042.jpg)'
- en: Figure 4.42 – Possible options for registering datasets
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.42 – 注册数据集的可能选项
- en: 'To get a better understanding of how the dataset registration process works,
    we are going to register two tabular datasets that are hosted on the web. These
    datasets consist of a single **parquet** file each. We will use these two datasets
    later in this chapter to understand the data drift detection feature. Let''s get
    started:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解数据集注册过程，我们将注册两个托管在 Web 上的表格数据集。这些数据集每个都包含一个**parquet**文件。我们将在本章后续部分使用这两个数据集来了解数据漂移检测功能。让我们开始吧：
- en: Select **From web files** from the menu shown in the preceding screenshot to
    start the **Create dataset from web files** wizard.
  id: totrans-272
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从前面的截图中选择**从 Web 文件**菜单项，开始**从 Web 文件创建数据集**向导。
- en: 'On the first page of the wizard, provide the following information:'
  id: totrans-273
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在向导的第一页，提供以下信息：
- en: '`survey-drift-base`'
  id: totrans-274
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`survey-drift-base`'
- en: '`Tabular`'
  id: totrans-275
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Tabular`'
- en: Click **Next**:![Figure 4.43 – The first step of the dataset registration wizard
  id: totrans-276
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**下一步**：![图 4.43 – 数据集注册向导的第一步
- en: '](img/B16777_04_043.jpg)'
  id: totrans-277
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16777_04_043.jpg)'
- en: Figure 4.43 – The first step of the dataset registration wizard
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.43 – 数据集注册向导的第一步
- en: The wizard will parse the file and figure out the file type and the schema of
    your dataset. You will need to validate the selection by clicking **Next**. Note
    that the wizard supports multiple file formats, as shown in the following screenshot:![Figure
    4.44 – The second step of the dataset registration wizard
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向导将解析文件并确定文件类型和数据集的模式。你需要通过点击**下一步**来验证选择。请注意，向导支持多种文件格式，如下图所示：![图 4.44 – 数据集注册向导的第二步
- en: '](img/B16777_04_044.jpg)'
  id: totrans-280
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16777_04_044.jpg)'
- en: Figure 4.44 – The second step of the dataset registration wizard
  id: totrans-281
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.44 – 数据集注册向导的第二步
- en: In the next step, you can define advanced options regarding the schema. For
    the baseline dataset, leave the default options as-is. Click **Next**, which will
    lead you to the confirmation step.
  id: totrans-282
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在下一步骤中，你可以定义有关模式的高级选项。对于基准数据集，保持默认选项不变。点击**下一步**，你将进入确认步骤。
- en: 'In this step, you can review your selections in the previous steps, and you
    can also schedule your first data science analysis task – profiling the dataset.
    This process generates the profile that you will explore in the next section.
    Enable the option and select `gpu-cluster`, which you provisioned in the previous
    section, as shown in the following screenshot:'
  id: totrans-283
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在此步骤中，你可以查看前面步骤中的选择，还可以安排你的首个数据科学分析任务——数据集概况分析。此过程将生成你将在下一部分中探索的概况。启用此选项，并选择你在前一部分中配置的`gpu-cluster`，如下图所示：
- en: Important note
  id: totrans-284
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 重要提示
- en: Within the **Select compute for profiling** option, you can select from both
    the compute instances and the compute clusters you provisioned in the *Compute
    instances* and *Compute clusters* sections. Selecting the compute cluster will
    force the cluster to scale from zero nodes to one node, analyze the dataset, and
    then scale down to zero nodes again. If you want, you can navigate to the **Manage**
    | **Compute** section and observe this scale out by clicking on the compute cluster's
    name. If you select the compute instance instead of the compute cluster, the job
    will be scheduled, and it will be executed when the compute instance starts.
  id: totrans-285
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在**选择用于概况分析的计算资源**选项中，你可以从你在*计算实例*和*计算集群*部分配置的计算实例和计算集群中进行选择。选择计算集群将强制集群从零个节点扩展到一个节点，分析数据集，然后再缩减回零个节点。如果你愿意，可以导航到**管理**
    | **计算**部分，通过点击计算集群的名称来观察这一扩展过程。如果你选择计算实例而不是计算集群，则任务将被安排，并将在计算实例启动时执行。
- en: '![Figure 4.45 – Last step of the dataset registration process'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.45 – 数据集注册过程的最后一步'
- en: '](img/B16777_04_045.jpg)'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_04_045.jpg)'
- en: Figure 4.45 – Last step of the dataset registration process
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.45 – 数据集注册过程的最后一步
- en: 'You will need to register one more dataset. The process here is almost identical,
    only this time, you will mark the dataset as a time series one:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要再注册一个数据集。此过程几乎相同，只不过这次你将数据集标记为时间序列数据集：
- en: Click on **Create dataset** and select **From web files**, as shown in the following
    screenshot:![Figure 4.46 – Create dataset menu in the dataset list
  id: totrans-290
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**创建数据集**并选择**从网页文件**，如下图所示：![图 4.46 – 数据集列表中的创建数据集菜单
- en: '](img/B16777_04_046.jpg)'
  id: totrans-291
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16777_04_046.jpg)'
- en: Figure 4.46 – Create dataset menu in the dataset list
  id: totrans-292
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.46 – 数据集列表中的创建数据集菜单
- en: 'Follow the same steps as you did previously and input the following information:'
  id: totrans-293
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照之前的步骤操作，输入以下信息：
- en: '`survey-drift-target`'
  id: totrans-294
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`survey-drift-target`'
- en: During the schema step, make sure that you select **Timestamp** from the **Properties**
    section of the **inference_date** column, as shown in the following screenshot.
    This option flags this tabular dataset as a **time series** dataset, something
    that allows you to perform additional analysis, as you will see in the *Data drift
    detection* section:![Figure 4.47 – Configuring a tabular dataset so that it becomes
    a time series dataset
  id: totrans-295
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在模式步骤中，请确保从**inference_date**列的**Properties**部分选择**时间戳**（**Timestamp**），如下图所示。此选项将此表格数据集标记为**时间序列**数据集，允许你执行额外的分析，正如你将在*数据漂移检测*部分看到的那样：![图
    4.47 – 配置一个表格数据集，使其成为时间序列数据集
- en: '](img/B16777_04_047.jpg)'
  id: totrans-296
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16777_04_047.jpg)'
- en: Figure 4.47 – Configuring a tabular dataset so that it becomes a time series
    dataset
  id: totrans-297
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.47 – 配置一个表格数据集，使其成为时间序列数据集
- en: Schedule data profile analysis and complete the dataset registration process.
  id: totrans-298
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安排数据概况分析并完成数据集注册过程。
- en: Important note
  id: totrans-299
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 重要提示
- en: If you are following along, you may notice that for the `year=2021/month=05/day=01/data.parquet`,
    you can create a virtual column through that path pattern and define that as your
    **Partition timestamp**. This improves the importance of time series functionality
    and allows you to load specific dates by selectively reading the required files
    only.
  id: totrans-300
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果你跟随教程，你可能会注意到，对于 `year=2021/month=05/day=01/data.parquet`，你可以通过该路径模式创建一个虚拟列，并将其定义为**分区时间戳**。这样可以提升时间序列功能的重要性，并允许你通过有选择性地读取所需文件来加载特定日期的数据。
- en: 'You should be able to see two registered datasets, as shown in the following
    screenshot:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该能够看到两个已注册的数据集，如下图所示：
- en: '![Figure 4.48 – List of registered datasets in the Azure ML workspace'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.48 – 在 Azure ML 工作区注册的数据集列表'
- en: '](img/B16777_04_048.jpg)'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_04_048.jpg)'
- en: Figure 4.48 – List of registered datasets in the Azure ML workspace
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.48 – 在 Azure ML 工作区注册的数据集列表
- en: From this view, you can select a dataset and then click on the **Unregister**
    button to remove the registration. Upon clicking on a dataset, you can view more
    details about it, including the profile analysis you performed on top of the datasets,
    something you will see in the next section.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 在此视图中，你可以选择一个数据集，然后点击**取消注册**按钮来移除注册。点击数据集后，你可以查看有关该数据集的更多详细信息，包括你在数据集上执行的分析，这些内容将在下一节中显示。
- en: Exploring the dataset
  id: totrans-306
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索数据集
- en: 'In the dataset list, click on the **survey-drift-target** dataset to open its
    details. In the first tab, **Details**, you can modify the description of the
    dataset and specify tags that are associated with the dataset. Tags are name-value
    pairs. In the following screenshot, you can see that we specified **survey** as
    the value of the **experiment** tag:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据集列表中，点击**survey-drift-target**数据集以查看其详细信息。在第一个标签页**详情**中，你可以修改数据集的描述，并指定与数据集相关联的标签。标签是名称-值对。在下面的截图中，你可以看到我们将**survey**指定为**experiment**标签的值：
- en: '![Figure 4.49 – Dataset details showing all the metadata associated with the
    specific dataset'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.49 – 显示与特定数据集相关的所有元数据的数据显示'
- en: '](img/B16777_04_049.jpg)'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_04_049.jpg)'
- en: Figure 4.49 – Dataset details showing all the metadata associated with the specific
    dataset
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.49 – 显示与特定数据集相关的所有元数据的数据显示
- en: 'In the **Consume** tab, you can copy the Python SDK code that you are going
    to use in [*Chapter 7*](B16777_07_Final_VK_ePub.xhtml#_idTextAnchor102), *The
    Azure ML Python SDK*, to get access to the dataset:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 在**消费**标签页中，你可以复制你将在[*第七章*](B16777_07_Final_VK_ePub.xhtml#_idTextAnchor102)中使用的
    Python SDK 代码，以便访问数据集：
- en: '![Figure 4.50 – Consuming a snippet that gives access to the dataset'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.50 – 消耗一个代码片段以访问数据集'
- en: '](img/B16777_04_050.jpg)'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_04_050.jpg)'
- en: Figure 4.50 – Consuming a snippet that gives access to the dataset
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.50 – 消耗一个代码片段以访问数据集
- en: 'In the **Explore** tab, you will be able to preview a sample of the data that
    is included in the dataset, exactly as you saw during the registration process:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 在**探索**标签页中，你将能够预览数据集中包含的样本数据，正如你在注册过程中所看到的：
- en: '![Figure 4.51 – Previewing a sample of the dataset'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.51 – 预览数据集的样本'
- en: '](img/B16777_04_051.jpg)'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_04_051.jpg)'
- en: Figure 4.51 – Previewing a sample of the dataset
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.51 – 预览数据集的样本
- en: 'If you click on the **Profile** tab, you will be able to see the statistical
    analysis of the dataset, as shown in the following screenshot:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你点击**分析**标签页，你将能够查看数据集的统计分析，正如下图所示：
- en: '![Figure 4.52 – Statistical analysis of the dataset'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.52 – 数据集的统计分析'
- en: '](img/B16777_04_052.jpg)'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_04_052.jpg)'
- en: Figure 4.52 – Statistical analysis of the dataset
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.52 – 数据集的统计分析
- en: Important note
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: If your dataset contains fewer than 10,000 rows, profiling is done automatically
    for you, without you having to schedule the processing aspect for the dataset.
    If the dataset contains more than 10,000 rows, then Azure ML performs an analysis
    on the first 10,000 rows and shows a warning message that prompts you to schedule
    a complete profiling analysis, something you can do by clicking on the **Generate
    profile** button from the menu.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的数据集包含少于 10,000 行，系统会自动为你执行数据分析，而无需你手动调度数据集的处理过程。如果数据集包含超过 10,000 行，Azure
    ML 会对前 10,000 行进行分析，并显示一条警告消息，提示你调度完整的分析过程，你可以通过点击菜单中的**生成分析**按钮来执行此操作。
- en: Finally, on the **Models** tab, you can see the models that relate to this dataset,
    something that you will do in [*Chapter 5*](B16777_05_Final_VK_ePub.xhtml#_idTextAnchor072),
    *Letting Machines do the Model Training*, when you will be registering the best
    model that you will be deploying as a web service.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在**模型**标签下，你可以看到与此数据集相关的模型，这是你在[*第5章*](B16777_05_Final_VK_ePub.xhtml#_idTextAnchor072)，*让机器进行模型训练*时，将注册并部署为
    Web 服务的最佳模型。
- en: Having registered a dataset, you can configure periodic monitoring for the dataset
    for data drifting, something you will learn about in the next section.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 注册了数据集后，你可以为该数据集配置周期性的漂移监控，这是你将在下一节中学习到的内容。
- en: Data drift detection
  id: totrans-327
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据漂移检测
- en: 'Data drift detection is a technique that allows you to compare a time series
    dataset with a reference dataset, and then check whether the statistical properties
    of the features you are comparing have changed significantly. For example, let''s
    assume that you trained an ML model that predicts if someone is going to participate
    in a survey based on their age. You used the `survey-drift-base` dataset to train
    that model. The following graph shows a density curve, which shows the distribution
    of age in the training dataset:'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 数据漂移检测是一种技术，允许你将时间序列数据集与参考数据集进行比较，然后检查你比较的特征的统计属性是否发生了显著变化。例如，假设你训练了一个 ML 模型，预测某人是否会参与调查，基于他们的年龄。你使用了`survey-drift-base`数据集来训练该模型。下图展示了一个密度曲线，显示了训练数据集中年龄的分布：
- en: '![Figure 4.53 – Negative skewed unimodal distribution of the age feature in
    the training dataset'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.53 – 训练数据集中年龄特征的负偏斜单峰分布'
- en: '](img/B16777_04_053.jpg)'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_04_053.jpg)'
- en: Figure 4.53 – Negative skewed unimodal distribution of the age feature in the
    training dataset
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.53 – 训练数据集中年龄特征的负偏斜单峰分布
- en: 'When you operationalized the model, you kept track of the inferences that it
    made on a weekly basis, and you logged this information in the `survey-drift-target`
    dataset, which you registered previously. This dataset contains the inferences
    that you did during the first 2 weeks of 2020\. Data drift detection enables you
    to detect if the distribution of the input features changed over time. Let''s
    take a look:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 当你将模型投入生产时，你每周跟踪它做出的推断，并将此信息记录在之前注册的`survey-drift-target`数据集中。该数据集包含了你在2020年初的前两周进行的推断。数据漂移检测能够帮助你发现输入特征的分布是否随着时间变化。我们来看看：
- en: Navigate to **Assets** | **Datasets** | **Dataset monitors** and click on the
    **Create** button to start the dataset monitor wizard:![Figure 4.54 – Creating
    a new dataset monitor
  id: totrans-333
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到**资产** | **数据集** | **数据集监控**，点击**创建**按钮以启动数据集监控向导：![图 4.54 – 创建新的数据集监控
- en: '](img/B16777_04_054.jpg)'
  id: totrans-334
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16777_04_054.jpg)'
- en: Figure 4.54 – Creating a new dataset monitor
  id: totrans-335
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.54 – 创建新的数据集监控
- en: On the target dataset, you will see all the registered time series datasets
    you want to monitor for data drift. This is the inference that your model has
    been doing in production. Select `survey-drift-target (Version:1)` and click **Next**:![Figure
    4.55 – The first step in data drift monitor configuration
  id: totrans-336
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在目标数据集上，你将看到所有已注册的时间序列数据集，这些数据集是你希望监控数据漂移的对象。这是你的模型在生产环境中所做的推断。选择`survey-drift-target
    (Version:1)`并点击**下一步**：![图 4.55 – 数据漂移监控配置的第一步
- en: '](img/B16777_04_055.jpg)'
  id: totrans-337
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16777_04_055.jpg)'
- en: Figure 4.55 – The first step in data drift monitor configuration
  id: totrans-338
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.55 – 数据漂移监控配置的第一步
- en: On the next page, you need to select your reference point. This can either be
    a specific point in time from within the time series tabular dataset or a specific
    dataset. In your case, select the `survey-drift-base (Version:1)` dataset, which
    is the dataset that was used to train the ML model:![Figure 4.56 – Selecting the
    baseline dataset during the data drift monitor configuration
  id: totrans-339
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在下一页中，你需要选择参考点。这可以是时间序列表格数据集中的某个特定时间点，或者是一个特定的数据集。在你的情况下，选择`survey-drift-base
    (Version:1)`数据集，这是用于训练 ML 模型的数据集：![图 4.56 – 在数据漂移监控配置中选择基线数据集
- en: '](img/B16777_04_056.jpg)'
  id: totrans-340
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16777_04_056.jpg)'
- en: Figure 4.56 – Selecting the baseline dataset during the data drift monitor configuration
  id: totrans-341
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.56 – 在数据漂移监控配置中选择基线数据集
- en: 'In the last step of the wizard, you need to define the following information:'
  id: totrans-342
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在向导的最后一步，你需要定义以下信息：
- en: '`survey-drift-monitor`.'
  id: totrans-343
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`survey-drift-monitor`。'
- en: '**Features**: Select one or more common features between the two datasets to
    monitor their distributions and whether there is data drift. In this case, the
    only common feature between the two datasets is the age feature.'
  id: totrans-344
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特征**：选择两个数据集之间一个或多个共同特征，以监控它们的分布情况以及是否存在数据漂移。在此案例中，两个数据集之间唯一的共同特征是年龄特征。'
- en: '**Compute target**: The cluster that will be spinning up and down to perform
    the analysis.'
  id: totrans-345
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**计算目标**：将启动和停止以执行分析的集群。'
- en: '**Frequency**: The frequency specifies the time interval for the target data
    to be examined for drift. This property cannot be changed once the monitor has
    been created. You can choose between day, week, or month. Keep in mind that you
    need at fewer 50 samples per time interval to perform data drift analysis. This
    means that if you have less than 50 rows per day, you cannot use that as your
    frequency and you should opt for week, or even month, instead.'
  id: totrans-346
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**频率**：频率指定检查目标数据是否有漂移的时间间隔。一旦监控器创建，无法更改此属性。您可以选择按天、按周或按月进行。请记住，每个时间间隔至少需要50个样本才能进行数据漂移分析。这意味着如果每天少于50行数据，您不能将其作为频率，应该选择按周或按月进行。'
- en: '**Latency**: It is common to have a delay between the actual scoring of a row
    and refreshing the target dataset. In this field, you specify how long to wait
    before assuming that the target dataset got the latest records; then, the monitor
    can perform data drift analysis.'
  id: totrans-347
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**延迟**：通常会在实际对行进行评分和刷新目标数据集之间有一个延迟。在此字段中，您需要指定在假设目标数据集已经获得最新记录之前的等待时间；然后，监控器就可以执行数据漂移分析。'
- en: '**Email address**: This is where to send an email if the dataset has drifted
    more than what''s been specified for the **Threshold** parameter.'
  id: totrans-348
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**电子邮件地址**：如果数据集的漂移超过了**阈值**参数所指定的范围，邮件将发送至此地址。'
- en: For the purposes of this book, you can disable the schedule, as shown in the
    following screenshot. You will manually run the data drift analysis.
  id: totrans-349
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 本书中，您可以禁用计划，如下截图所示。您将手动运行数据漂移分析。
- en: Click on the **Create** button to create the monitor:![Figure 4.57 – Data drift
    monitor settings
  id: totrans-350
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**创建**按钮以创建监控器：![图4.57 – 数据漂移监控器设置
- en: '](img/B16777_04_057.jpg)'
  id: totrans-351
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16777_04_057.jpg)'
- en: Figure 4.57 – Data drift monitor settings
  id: totrans-352
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图4.57 – 数据漂移监控器设置
- en: 'Click on the name of the new monitor you created from the monitor list:'
  id: totrans-353
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从监控器列表中点击您创建的新监控器名称：
- en: '![Figure 4.58 – Data drift monitors list'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: '![图4.58 – 数据漂移监控器列表'
- en: '](img/B16777_04_058.jpg)'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_04_058.jpg)'
- en: Figure 4.58 – Data drift monitors list
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.58 – 数据漂移监控器列表
- en: 'The data drift monitor is meant to run on a schedule for new data. In your
    case, you want to analyze the existing data in the target dataset. Let''s take
    a look:'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 数据漂移监控器旨在根据计划对新数据进行分析。在您的情况下，您想分析目标数据集中的现有数据。让我们来看看：
- en: Click on the **Analyze existing data** button, which will bring up the backfill
    wizard shown in the following screenshot:![Figure 4.59 – Manually starting an
    analysis of past dates
  id: totrans-358
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**分析现有数据**按钮，这将显示以下截图中的回填向导：![图4.59 – 手动启动对过去日期的分析
- en: '](img/B16777_04_059.jpg)'
  id: totrans-359
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16777_04_059.jpg)'
- en: Figure 4.59 – Manually starting an analysis of past dates
  id: totrans-360
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图4.59 – 手动启动对过去日期的分析
- en: Select from December 31, 2019 to January 15, 2020\. This is the time range that
    contains all the records from the target dataset.
  id: totrans-361
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择从2019年12月31日到2020年1月15日。这是包含目标数据集所有记录的时间范围。
- en: Select the compute cluster that will do the analysis.
  id: totrans-362
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择将进行分析的计算集群。
- en: Click **Submit**.
  id: totrans-363
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**提交**。
- en: 'Once the analysis is complete, a process that will take some time, you will
    be able to see the data drift results, which indicate that a big data drift has
    been observed in our dataset. Note that the summary is referring to the latest
    inferences, which were done on January 5, 2020\. You can manually select previous
    periods by clicking on the graphs for the corresponding dates:'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦分析完成（这个过程需要一些时间），您将能够看到数据漂移的结果，结果表明我们的数据集观察到了大规模的数据漂移。请注意，摘要指的是最新的推理结果，这些推理是在2020年1月5日完成的。您可以通过点击对应日期的图表手动选择之前的时间段：
- en: '![Figure 4.60 – Data drift detected between the base dataset and the target
    one'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: '![图4.60 – 基础数据集与目标数据集之间检测到的数据漂移'
- en: '](img/B16777_04_060.jpg)'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_04_060.jpg)'
- en: Figure 4.60 – Data drift detected between the base dataset and the target one
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.60 – 基础数据集与目标数据集之间检测到的数据漂移
- en: 'If you scroll down to the feature distribution, you will be able to clearly
    see the distribution drift on the age feature. This indicates that the model is
    making inferences on a population that has different characteristics from the
    one it was trained on. This is a good indication that you may need to retrain
    the model, to bring it up to date with the new feature distribution:'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你向下滚动到特征分布部分，你将能够清楚地看到年龄特征的分布漂移。这表明模型正在对一个与其训练数据集特征不同的群体进行推理。这是一个很好的指示，表明你可能需要重新训练模型，以便使其与新的特征分布保持同步。
- en: '![Figure 4.61 – The baseline is a negative skewed distribution, while the latest
    inferences follow a positive skewed distribution'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.61 – 基准线是一个负偏态分布，而最新的推断遵循一个正偏态分布'
- en: '](img/B16777_04_061.jpg)'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_04_061.jpg)'
- en: Figure 4.61 – The baseline is a negative skewed distribution, while the latest
    inferences follow a positive skewed distribution
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.61 – 基准线是一个负偏态分布，而最新的推断遵循一个正偏态分布
- en: In this section, you learned how to configure data drift detection, which you
    did by comparing the data that your model was observing in production against
    the dataset that was used to train the model. This is a powerful feature that
    allows you to determine whether you need to retrain the model with newer data,
    especially if the feature distribution has changed/drifted over time.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，你学习了如何配置数据漂移检测，这一过程是通过将你在生产环境中观察到的数据与用于训练模型的数据集进行比较来完成的。这是一个强大的功能，它可以帮助你判断是否需要使用更新的数据重新训练模型，尤其是当特征分布随时间发生变化或漂移时。
- en: Summary
  id: totrans-373
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, you learned how to provision and attach compute resources to
    your Azure ML workspace. You also learned how you can register various datastores
    so that you can access data in a secure manner. Finally, you explored the dataset
    registration capabilities of Azure ML Studio, something that allows you to easily
    access the data for your experiments. Having registered the datasets, you can
    configure data drift monitors, which warn you if the features' distribution changes
    over time, something that could indicate that the ML model that was trained on
    that dataset needs to be retrained. You should now feel comfortable configuring
    your Azure ML workspace, one of the key skills that's measured in the DP-100 certification.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，你学习了如何为你的 Azure ML 工作区提供和附加计算资源。你还学会了如何注册各种数据存储，以便安全地访问数据。最后，你探索了 Azure
    ML Studio 的数据集注册功能，它使你能够轻松访问用于实验的数据。注册数据集后，你可以配置数据漂移监控器，当特征分布随时间变化时，它会提醒你，这可能表明在该数据集上训练的机器学习模型需要重新训练。现在你应该已经能够舒适地配置你的
    Azure ML 工作区，这是 DP-100 认证中考察的关键技能之一。
- en: In the next chapter, you will learn how to leverage the datasets that you registered
    in the workspace to perform **Auto ML** analysis, a process that will run multiple
    ML experiments on top of the compute clusters you provisioned to detect the best
    algorithm for your dataset.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，你将学习如何利用你在工作区中注册的数据集进行**自动化机器学习（Auto ML）**分析，这一过程将在你提供的计算集群上运行多个机器学习实验，以检测适合你数据集的最佳算法。
- en: Questions
  id: totrans-376
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: 'In each chapter, you will find a couple of questions so that you can test your
    knowledge regarding what was covered in this chapter:'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 在每一章中，你会找到一些问题，以便测试你对本章内容的理解：
- en: How many data scientists can work on a single compute instance that has 8 cores
    and 56 GB of RAM?
  id: totrans-378
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个拥有 8 核心和 56 GB 内存的计算实例上最多可以有多少个数据科学家同时工作？
- en: a. Only one.
  id: totrans-379
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a. 只有一个。
- en: b. Up to two.
  id: totrans-380
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b. 最多两个。
- en: c. Up to five.
  id: totrans-381
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c. 最多五个。
- en: d. As many as they want, as long as they don't deplete the compute resources.
  id: totrans-382
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: d. 只要不耗尽计算资源，人数不限。
- en: What type of credentials do you need to provide to access a data lake store
    that's either Gen 1 or Gen 2?
  id: totrans-383
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你需要提供哪种类型的凭证才能访问 Gen 1 或 Gen 2 的数据湖存储？
- en: a. A **Personal Access Token** (**PAT**)
  id: totrans-384
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a. **个人访问令牌**（**PAT**）
- en: b. A service principal's client ID and secret
  id: totrans-385
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b. 服务主体的客户端 ID 和密钥
- en: c. Your own AAD user credentials
  id: totrans-386
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c. 你的个人 AAD 用户凭证
- en: d. No credentials are needed
  id: totrans-387
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: d. 不需要凭证
- en: Which of the following Azure tools can help you orchestrate data moving from
    an on-premises environment?
  id: totrans-388
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下哪种 Azure 工具可以帮助你协调将数据从本地环境迁移的工作？
- en: a. Blob storage
  id: totrans-389
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a. Blob 存储
- en: b. Azure Active Directory
  id: totrans-390
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b. Azure Active Directory
- en: c. Azure Data Factory
  id: totrans-391
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c. Azure 数据工厂
- en: d. Azure ML workspace
  id: totrans-392
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: d. Azure ML 工作区
- en: Further reading
  id: totrans-393
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'This section offers a list of useful web resources that will help you augment
    your knowledge and understanding of the topics discussed in this chapter:'
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 本节提供了一个有用的网络资源列表，帮助你增强对本章讨论主题的理解和知识：
- en: 'You can learn more about how to use managed identity from within a compute
    cluster at the following link: [https://docs.microsoft.com/azure/machine-learning/how-to-create-attach-compute-cluster?tabs=python#managed-identity-usage](https://docs.microsoft.com/azure/machine-learning/how-to-create-attach-compute-cluster?tabs=python#managed-identity-usage).'
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以通过以下链接了解更多关于如何在计算集群中使用托管身份的信息：[https://docs.microsoft.com/azure/machine-learning/how-to-create-attach-compute-cluster?tabs=python#managed-identity-usage](https://docs.microsoft.com/azure/machine-learning/how-to-create-attach-compute-cluster?tabs=python#managed-identity-usage)。
- en: The instance metadata service allows you to request tokens for Azure resources
    using the attached managed identity. You can learn more about this at [https://docs.microsoft.com/azure/virtual-machines/linux/instance-metadata-service](https://docs.microsoft.com/azure/virtual-machines/linux/instance-metadata-service).
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实例元数据服务允许你使用附加的托管身份请求Azure资源的令牌。你可以通过[https://docs.microsoft.com/azure/virtual-machines/linux/instance-metadata-service](https://docs.microsoft.com/azure/virtual-machines/linux/instance-metadata-service)了解更多信息。
- en: You can learn more about the access control model of Azure Data Lake Storage
    Gen2 at [https://docs.microsoft.com/azure/storage/blobs/data-lake-storage-access-control-model](https://docs.microsoft.com/azure/storage/blobs/data-lake-storage-access-control-model).
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以通过[https://docs.microsoft.com/azure/storage/blobs/data-lake-storage-access-control-model](https://docs.microsoft.com/azure/storage/blobs/data-lake-storage-access-control-model)了解更多关于Azure
    Data Lake Storage Gen2的访问控制模型。
- en: You can learn how to easily copy data and configure regular data ingestions
    using Azure Data Factory's copy data tool at [https://docs.microsoft.com/azure/data-factory/quickstart-create-data-factory-copy-data-tool](https://docs.microsoft.com/azure/data-factory/quickstart-create-data-factory-copy-data-tool).
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以通过[https://docs.microsoft.com/azure/data-factory/quickstart-create-data-factory-copy-data-tool](https://docs.microsoft.com/azure/data-factory/quickstart-create-data-factory-copy-data-tool)学习如何使用Azure
    Data Factory的复制数据工具轻松复制数据并配置定期数据摄取。
- en: You can learn how to grant limited access to Azure Storage Accounts using SAS
    tokens at [https://docs.microsoft.com/azure/storage/common/storage-sas-overview](https://docs.microsoft.com/azure/storage/common/storage-sas-overview).
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以通过[https://docs.microsoft.com/azure/storage/common/storage-sas-overview](https://docs.microsoft.com/azure/storage/common/storage-sas-overview)学习如何使用SAS令牌为Azure存储账户授予有限访问权限。
- en: You can learn more about service principals, which can be used to access Azure
    Data Lake datastores, at [https://docs.microsoft.com/azure/active-directory/develop/app-objects-and-service-principals](https://docs.microsoft.com/azure/active-directory/develop/app-objects-and-service-principals).
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以通过[https://docs.microsoft.com/azure/active-directory/develop/app-objects-and-service-principals](https://docs.microsoft.com/azure/active-directory/develop/app-objects-and-service-principals)了解更多关于服务主体的信息，服务主体可用于访问Azure
    Data Lake数据存储。
