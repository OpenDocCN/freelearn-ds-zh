- en: Chapter 5. Writing Consumers
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第5章。编写消费者
- en: Consumers are the applications that consume the messages published by Kafka
    producers and process the data extracted from them. Like producers, consumers
    can also be different in nature, such as applications doing real-time or near
    real-time analysis, applications with NoSQL or data warehousing solutions, backend
    services, consumers for Hadoop, or other subscriber-based solutions. These consumers
    can also be implemented in different languages such as Java, C, and Python.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 消费者是消费Kafka生产者发布的消息并处理从中提取的数据的应用程序。与生产者一样，消费者也可以是不同性质的，例如进行实时或准实时分析的应用程序、具有NoSQL或数据仓库解决方案的应用程序、后端服务、用于Hadoop的消费者或其他基于订阅者的解决方案。这些消费者也可以用不同的语言实现，如Java、C和Python。
- en: 'In this chapter, we will focus on the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将重点关注以下主题：
- en: The Kafka Consumer API
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kafka消费者API
- en: Java-based Kafka consumers
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于Java的Kafka消费者
- en: Java-based Kafka consumers consuming partitioned messages
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于Java的Kafka消费者消费分区消息
- en: At the end of the chapter, we will explore some of the important properties
    that can be set for a Kafka consumer. So, let's start.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章末尾，我们将探讨一些可以为Kafka消费者设置的重要属性。所以，让我们开始吧。
- en: '![Writing Consumers](img/3090OS_05_01.jpg)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![编写消费者](img/3090OS_05_01.jpg)'
- en: The preceding diagram explains the high-level working of the Kafka consumer
    when consuming the messages. The consumer subscribes to the message consumption
    from a specific topic on the Kafka broker. The consumer then issues a fetch request
    to the lead broker to consume the message partition by specifying the message
    offset (the beginning position of the message offset). Therefore, the Kafka consumer
    works in the pull model and always pulls all available messages after its current
    position in the Kafka log (the Kafka internal data representation).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的图解释了Kafka消费者在消费消息时的高级工作原理。消费者订阅来自Kafka经纪人特定主题的消息消费。然后，消费者通过指定消息偏移量（消息偏移量的起始位置）向领导经纪人发出获取请求以消费消息分区。因此，Kafka消费者以拉模型工作，并始终在Kafka日志（Kafka内部数据表示）中当前位置之后拉取所有可用的消息。
- en: While subscribing, the consumer connects to any of the live nodes and requests
    metadata about the leaders for the partitions of a topic. This allows the consumer
    to communicate directly with the lead broker receiving the messages. Kafka topics
    are divided into a set of ordered partitions and each partition is consumed by
    one consumer only. Once a partition is consumed, the consumer changes the message
    offset to the next partition to be consumed. This represents the states about
    what has been consumed and also provides the flexibility of deliberately rewinding
    back to an old offset and re-consuming the partition. In the next few sections,
    we will discuss the API provided by Kafka for writing Java-based custom consumers.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在订阅时，消费者连接到任何活动节点，并请求有关主题分区领导者的元数据。这允许消费者直接与接收消息的领导经纪人通信。Kafka主题被分成一组有序的分区，每个分区只能被一个消费者消费。一旦分区被消费，消费者就会将消息偏移量更改为下一个要消费的分区。这代表了已经被消费的状态，并且还提供了有意地倒带到旧偏移量并重新消费分区的灵活性。在接下来的几节中，我们将讨论Kafka为编写基于Java的自定义消费者提供的API。
- en: Note
  id: totrans-10
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: All the Kafka classes referred to in this book are actually written in Scala.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中提到的所有Kafka类实际上都是用Scala编写的。
- en: Kafka consumer APIs
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kafka消费者API
- en: 'Kafka provides two types of API for Java consumers:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka为Java消费者提供了两种类型的API：
- en: High-level API
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高级API
- en: Low-level API
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 低级API
- en: The high-level consumer API
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 高级消费者API
- en: The high-level consumer API is used when only data is needed and the handling
    of message offsets is not required. This API hides broker details from the consumer
    and allows effortless communication with the Kafka cluster by providing an abstraction
    over the low-level implementation. The high-level consumer stores the last offset
    (the position within the message partition where the consumer left off consuming
    the message), read from a specific partition in Zookeeper. This offset is stored
    based on the consumer group name provided to Kafka at the beginning of the process.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 当只需要数据而不需要处理消息偏移量时，使用高级消费者API。此API将经纪人的细节隐藏在消费者之外，并通过提供对低级实现的抽象来轻松与Kafka集群通信。高级消费者在Zookeeper中存储最后的偏移量（消费者离开消费消息的消息分区内的位置），并且基于在进程开始时提供给Kafka的消费者组名称存储此偏移量。
- en: The consumer group name is unique and global across the Kafka cluster and any
    new consumers with an in-use consumer group name may cause ambiguous behavior
    in the system. When a new process is started with the existing consumer group
    name, Kafka triggers a rebalance between the new and existing process threads
    for the consumer group. After the rebalance, some messages that are intended for
    a new process may go to an old process, causing unexpected results. To avoid this
    ambiguous behavior, any existing consumers should be shut down before starting
    new consumers for an existing consumer group name.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 消费者组名称在Kafka集群中是唯一且全局的，任何具有正在使用的消费者组名称的新消费者可能会导致系统中的模糊行为。当使用现有的消费者组名称启动新进程时，Kafka会在消费者组的新旧进程线程之间触发重新平衡。重新平衡后，一些意图用于新进程的消息可能会发送到旧进程，导致意外结果。为避免这种模糊行为，在启动现有消费者组名称的新消费者之前，应关闭任何现有的消费者。
- en: 'The following are the classes that are imported to write Java-based basic consumers
    using the high-level consumer API for a Kafka cluster:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是导入的类，用于使用Kafka集群的高级消费者API编写基于Java的基本消费者：
- en: '`ConsumerConnector`: Kafka provides the `ConsumerConnector` interface (`interface
    ConsumerConnector`) that is further implemented by the `ZookeeperConsumerConnector`
    class (`kafka.javaapi.consumer.ZookeeperConsumerConnector`). This class is responsible
    for all the interaction a consumer has with ZooKeeper.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ConsumerConnector`：Kafka提供了`ConsumerConnector`接口（`interface ConsumerConnector`），该接口由`ZookeeperConsumerConnector`类（`kafka.javaapi.consumer.ZookeeperConsumerConnector`）进一步实现。该类负责消费者与ZooKeeper的所有交互。'
- en: 'The following is the class diagram for the `ConsumerConnector` class:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是`ConsumerConnector`类的类图：
- en: '![The high-level consumer API](img/3090OS_05_02.jpg)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![高级消费者API](img/3090OS_05_02.jpg)'
- en: '`KafkaStream`: Objects of the `kafka.consumer.KafkaStream` class are returned
    by the `createMessageStreams` call from the `ConsumerConnector` implementation.
    This list of the `KafkaStream` objects is returned for each topic, which can further
    create an iterator over messages in the stream. The following is the Scala-based
    class declaration:'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`KafkaStream`：`kafka.consumer.KafkaStream`类的对象是由`ConsumerConnector`实现的`createMessageStreams`调用返回的。这些`KafkaStream`对象的列表是为每个主题返回的，可以进一步在流中创建迭代器。以下是基于Scala的类声明：'
- en: '[PRE0]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Here, the parameters `K` and `V` specify the type for the partition key and
    message value, respectively.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，参数`K`和`V`分别指定了分区键和消息值的类型。
- en: In the create call from the `ConsumerConnector` class, clients can specify the
    number of desired streams, where each stream object is used for single-threaded
    processing. These stream objects may represent the merging of multiple unique
    partitions.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在`ConsumerConnector`类的create调用中，客户端可以指定所需流的数量，其中每个流对象用于单线程处理。这些流对象可以表示多个唯一分区的合并。
- en: '`ConsumerConfig`: The `kafka.consumer.ConsumerConfig` class encapsulates the
    property values required for establishing the connection with ZooKeeper, such
    as ZooKeeper URL, ZooKeeper session timeout, and ZooKeeper sink time. It also
    contains the property values required by the consumer such as group ID and so
    on.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ConsumerConfig`：`kafka.consumer.ConsumerConfig`类封装了与ZooKeeper建立连接所需的属性值，例如ZooKeeper
    URL、ZooKeeper会话超时和ZooKeeper接收时间。它还包含了消费者所需的属性值，例如组ID等。'
- en: A high-level API-based working consumer example is discussed after the next
    section.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节之后将讨论基于高级API的工作消费者示例。
- en: The low-level consumer API
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 低级消费者API
- en: The high-level API does not allow consumers to control interactions with brokers.
    Also known as "simple consumer API", the low-level consumer API is stateless and
    provides fine grained control over the communication between Kafka broker and
    the consumer. It allows consumers to set the message offset with every request
    raised to the broker and maintains the metadata at the consumer's end. This API
    can be used by both online as well as offline consumers such as Hadoop. These
    types of consumers can also perform multiple reads for the same message or manage
    transactions to ensure the message is consumed only once.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 高级API不允许消费者控制与代理的交互。低级消费者API也称为“简单消费者API”，它是无状态的，并且提供了对Kafka代理和消费者之间通信的精细控制。它允许消费者在向代理发出的每个请求中设置消息偏移量，并在消费者端维护元数据。这个API可以被在线和离线消费者（如Hadoop）使用。这些类型的消费者也可以对同一消息执行多次读取，或者管理事务以确保消息只被消费一次。
- en: Compared to the high-level consumer API, developers need to put in extra effort
    to gain low-level control within consumers by keeping track of offsets, figuring
    out the lead broker for the topic and partition, handling lead broker changes,
    and so on.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 与高级消费者API相比，开发人员需要付出额外的努力来获得消费者内的低级控制，例如跟踪偏移量、找出主题和分区的领导代理、处理领导代理变更等。
- en: 'In the low-level consumer API, consumers first query the live broker to find
    out the details about the lead broker. Information about the live broker can be
    passed on to the consumers either using a properties file or from the command
    line. The `topicsMetadata()` method of the `kafka.javaapi.TopicMetadataResponse`
    class is used to find out metadata about the topic of interest from the lead broker.
    For message partition reading, the `kafka.api.OffsetRequest` class defines two
    constants: `EarliestTime` and `LatestTime`, to find the beginning of the data
    in the logs and the new messages stream. These constants also help consumers to
    track which messages are already read.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在低级消费者API中，消费者首先查询活动代理以了解有关领导代理的详细信息。有关活动代理的信息可以通过属性文件或命令行传递给消费者。`kafka.javaapi.TopicMetadataResponse`类的`topicsMetadata()`方法用于从领导代理那里找到感兴趣的主题的元数据。对于消息分区读取，`kafka.api.OffsetRequest`类定义了两个常量：`EarliestTime`和`LatestTime`，用于查找日志中数据的开始和新消息流。这些常量还帮助消费者跟踪已经读取的消息。
- en: 'The main class used within the low-level consumer API is the `SimpleConsumer`
    (`kafka.javaapi.consumer.SimpleConsumer`) class. The following is the class diagram
    for the `SimpleConsumer` class:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 低级消费者API中使用的主要类是`SimpleConsumer`（`kafka.javaapi.consumer.SimpleConsumer`）类。以下是`SimpleConsumer`类的类图：
- en: '![The low-level consumer API](img/3090OS_05_03.jpg)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![低级消费者API](img/3090OS_05_03.jpg)'
- en: A simple consumer class provides a connection to the lead broker for fetching
    the messages from the topic and methods to get the topic metadata and the list
    of offsets.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 简单消费者类提供了与领导代理建立连接以从主题获取消息以及获取主题元数据和偏移量列表的方法。
- en: A few more important classes for building different request objects are `FetchRequest`
    (`kafka.api.FetchRequest`), `OffsetRequest` (`kafka.javaapi.OffsetRequest`), `OffsetFetchRequest`
    (`kafka.javaapi.OffsetFetchRequest`), `OffsetCommitRequest` (`kafka.javaapi.OffsetCommitRequest`),
    and `TopicMetadataRequest` (`kafka.javaapi.TopicMetadataRequest`).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 用于构建不同请求对象的几个重要类是`FetchRequest`（`kafka.api.FetchRequest`）、`OffsetRequest`（`kafka.javaapi.OffsetRequest`）、`OffsetFetchRequest`（`kafka.javaapi.OffsetFetchRequest`）、`OffsetCommitRequest`（`kafka.javaapi.OffsetCommitRequest`）和`TopicMetadataRequest`（`kafka.javaapi.TopicMetadataRequest`）。
- en: Note
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: All the examples in this chapter are based on the high-level consumer API. For
    examples based on the low-level consumer API, refer to [https://cwiki.apache.org/confluence/display/KAFKA/0.8.0+SimpleConsumer+Example](https://cwiki.apache.org/confluence/display/KAFKA/0.8.0+SimpleConsumer+Example).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的所有示例都是基于高级消费者API的。有关基于低级消费者API的示例，请参阅[https://cwiki.apache.org/confluence/display/KAFKA/0.8.0+SimpleConsumer+Example](https://cwiki.apache.org/confluence/display/KAFKA/0.8.0+SimpleConsumer+Example)。
- en: Simple Java consumers
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简单Java消费者
- en: Now we will start writing a single-threaded simple Java consumer developed using
    the high-level consumer API for consuming the messages from a topic. This `SimpleHLConsumer`
    class is used to fetch a message from a specific topic and consume it, assuming
    that there is a single partition within the topic.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将开始编写一个使用高级消费者 API 开发的单线程简单的 Java 消费者，用于从主题中消费消息。`SimpleHLConsumer` 类用于从特定主题获取消息并消费它，假设主题内有一个单个分区。
- en: Importing classes
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 导入类
- en: 'As a first step, we need to import the following classes:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要导入以下类：
- en: '[PRE1]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Defining properties
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义属性
- en: 'As a next step, we need to define properties for making a connection with Zookeeper
    and pass these properties to the Kafka consumer using the following code:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 作为下一步，我们需要定义用于与 Zookeeper 建立连接的属性，并使用以下代码将这些属性传递给 Kafka 消费者：
- en: '[PRE2]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now let us see the major properties mentioned in the code:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看一下代码中提到的主要属性：
- en: '`zookeeper.connect`: This property specifies the ZooKeeper `<node:port>` connection
    detail that is used to find the Zookeeper running instance in the cluster. In
    the Kafka cluster, Zookeeper is used to store offsets of messages consumed for
    a specific topic and partition by this consumer group.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`zookeeper.connect`：此属性指定了用于在集群中查找运行的 Zookeeper 实例的 ZooKeeper `<node:port>`
    连接详细信息。在 Kafka 集群中，Zookeeper 用于存储此消费者组消费的特定主题和分区的偏移量。'
- en: '`group.id`: This property specifies the name for the consumer group shared
    by all the consumers within the group. This is also the process name used by Zookeeper
    to store offsets.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`group.id`：此属性指定了消费者组的名称，该组由组内的所有消费者共享。这也是 Zookeeper 用于存储偏移量的进程名称。'
- en: '`zookeeper.session.timeout.ms`: This property specifies the Zookeeper session
    timeout in milliseconds and represents the amount of time Kafka will wait for
    Zookeeper to respond to a request before giving up and continuing to consume messages.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`zookeeper.session.timeout.ms`：此属性指定了 Zookeeper 会话超时时间（以毫秒为单位），表示 Kafka 等待
    Zookeeper 响应请求的时间量，然后放弃并继续消费消息。'
- en: '`zookeeper.sync.time.ms`: This property specifies the ZooKeeper sync time in
    milliseconds between the ZooKeeper leader and the followers.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`zookeeper.sync.time.ms`：此属性指定了 ZooKeeper 领导者和跟随者之间的 ZooKeeper 同步时间（以毫秒为单位）。'
- en: '`auto.commit.interval.ms`: This property defines the frequency in milliseconds
    at which consumer offsets get committed to Zookeeper.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`auto.commit.interval.ms`：此属性定义了消费者偏移量提交到 Zookeeper 的频率（以毫秒为单位）。'
- en: Reading messages from a topic and printing them
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从主题中读取消息并打印它们
- en: 'As a final step, we need to read the message using the following code:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一步，我们需要使用以下代码读取消息：
- en: '[PRE3]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'So the complete program will look like the following code:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，完整的程序将如下代码所示：
- en: '[PRE4]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Before running this, make sure you have created the topic `kafkatopic` from
    the command line:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行此命令之前，请确保您已从命令行创建了主题 `kafkatopic`：
- en: '[PRE5]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Note
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'Before compiling and running a Java-based Kafka program in the console, make
    sure you download the `slf4j-1.7.7.tar.gz` file from [http://www.slf4j.org/download.html](http://www.slf4j.org/download.html)
    and copy `slf4j-log4j12-1.7.7.jar` contained within `slf4j-1.7.7.tar.gz` to the
    `/opt/kafka_2.9.2-0.8.1.1/libs` directory. Also add all the libraries available
    in `/opt/kafka_2.9.2-0.8.1.1/libs` to the classpath using the following commands:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在控制台中编译和运行基于 Java 的 Kafka 程序之前，请确保您从 [http://www.slf4j.org/download.html](http://www.slf4j.org/download.html)
    下载了 `slf4j-1.7.7.tar.gz` 文件，并将 `slf4j-1.7.7.tar.gz` 中包含的 `slf4j-log4j12-1.7.7.jar`
    复制到 `/opt/kafka_2.9.2-0.8.1.1/libs` 目录。还要使用以下命令将 `/opt/kafka_2.9.2-0.8.1.1/libs`
    中的所有库添加到类路径中：
- en: '[PRE6]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Also run the `SimpleProducer` class developed in [Chapter 4](ch04.html "Chapter 4. Writing
    Producers"), *Writing Producers*, which takes two arguments: first, the topic
    name and second, the number of messages to be published as follows:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 还要运行在[第 4 章](ch04.html "第 4 章。编写生产者") *编写生产者* 中开发的 `SimpleProducer` 类，它需要两个参数：第一个是主题名称，第二个是要发布的消息数量，如下所示：
- en: '[PRE7]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Compile the preceding `SimpleHLConsumer` class using the following command:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令编译上述的 `SimpleHLConsumer` 类：
- en: '[PRE8]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Run the simple high-level consumer using the following command in a separate
    console window:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在单独的控制台窗口中使用以下命令运行简单的高级消费者：
- en: '[PRE9]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'For successful execution, the `SimpleHLConsumer` class takes three arguments:
    first, the Zookeeper connection string `<host:port>`; second, the unique group
    ID; and third, the Kafka topic name.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 为了成功执行，`SimpleHLConsumer` 类需要三个参数：第一个是 Zookeeper 连接字符串 `<host:port>`；第二个是唯一的组
    ID；第三个是 Kafka 主题名称。
- en: Multithreaded Java consumers
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多线程 Java 消费者
- en: The previous example is a very basic example of a consumer that consumes messages
    from a single broker with no explicit partitioning of messages within the topic.
    Let's jump to the next level and write another program that consumes messages
    from multiple partitions connecting to single/multiple topics.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 上一个例子是一个非常基本的消费者示例，它从单个代理消费消息，主题内没有明确的消息分区。让我们跳到下一个级别，编写另一个程序，从单个/多个主题连接到多个分区来消费消息。
- en: A multithreaded, high-level, consumer-API-based design is usually based on the
    number of partitions in the topic and follows a one-to-one mapping approach between
    the thread and the partitions within the topic. For example, if four partitions
    are defined for any topic, as a best practice, only four threads should be initiated
    with the consumer application to read the data; otherwise, some conflicting behavior,
    such as threads never receiving a message or a thread receiving messages from
    multiple partitions, may occur. Also, receiving multiple messages will not guarantee
    that the messages will be placed in order. For example, a thread may receive two
    messages from the first partition and three from the second partition, then three
    more from the first partition, followed by some more from the first partition,
    even if the second partition has data available.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 基于多线程、高级、基于消费者API的设计通常基于主题中的分区数，并遵循线程与主题内分区之间的一对一映射方法。例如，如果为任何主题定义了四个分区，作为最佳实践，应该使用消费者应用程序启动只有四个线程，否则可能会发生一些冲突行为，例如线程永远不会接收到消息或线程从多个分区接收消息。此外，接收多个消息不会保证消息按顺序放置。例如，一个线程可能从第一个分区接收两条消息，从第二个分区接收三条消息，然后从第一个分区再接收三条消息，然后再从第一个分区接收更多消息，即使第二个分区有可用数据。
- en: Let's move further on.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续前进。
- en: Importing classes
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 导入类
- en: 'As a first step, we need to import the following classes:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 作为第一步，我们需要导入以下类：
- en: '[PRE10]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Defining properties
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义属性
- en: 'As the next step, we need to define properties for making a connection with
    Zookeeper and pass these properties to the Kafka consumer using the following
    code:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 作为下一步，我们需要为与Zookeeper建立连接定义属性，并使用以下代码将这些属性传递给Kafka消费者：
- en: '[PRE11]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The preceding properties have already been discussed in the previous example.
    For more details on Kafka consumer properties, refer to the last section of this
    chapter.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的属性已经在前面的示例中讨论过。有关Kafka消费者属性的更多详细信息，请参阅本章的最后一节。
- en: Reading the message from threads and printing it
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从线程中读取消息并打印它
- en: 'The only difference in this section from the previous section is that we first
    create a thread pool and get the Kafka streams associated with each thread within
    the thread pool, as shown in the following code:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 此部分与上一部分的唯一区别在于我们首先创建一个线程池，并在线程池内的每个线程中获取与每个线程相关联的Kafka流，如下面的代码所示：
- en: '[PRE12]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The complete program listing for the multithread Kafka consumer based on the
    Kafka high-level consumer API is as follows:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 基于Kafka高级消费者API的多线程Kafka消费者的完整程序列表如下：
- en: '[PRE13]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Compile the preceding program, and before running it, read the following tip.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 编译上述程序，并在运行之前阅读以下提示。
- en: Tip
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: Before we run this program, we need to make sure our cluster is running as a
    multi-broker cluster (comprising either single or multiple nodes). For more information
    on how to set up single node—multiple broker cluster, refer to [Chapter 2](ch02.html
    "Chapter 2. Setting Up a Kafka Cluster"), *Setting Up a Kafka Cluster*.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行此程序之前，我们需要确保我们的集群作为多代理集群（包括单个或多个节点）正在运行。有关如何设置单节点-多代理集群的更多信息，请参阅[第2章](ch02.html
    "第2章。设置Kafka集群"), *设置Kafka集群*。
- en: 'Once your multi-broker cluster is up, create a topic with four partitions and
    set the replication factor to `2` before running this program using the following
    command:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您的多代理集群启动，使用以下命令创建一个具有四个分区并将复制因子设置为`2`的主题，然后运行此程序：
- en: '[PRE14]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Also, run the `SimpleProducer` class developed in [Chapter 4](ch04.html "Chapter 4. Writing
    Producers"), *Writing Producers*, which takes two arguments: first, the topic
    name and second, the number of messages to be published, as follows:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，运行在[第4章](ch04.html "第4章。编写生产者")中开发的`SimpleProducer`类，*编写生产者*，它需要两个参数：首先是主题名称，其次是要发布的消息数量，如下所示：
- en: '[PRE15]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Compile the preceding `MultiThreadHLConsumer` class using the following command:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令编译前述`MultiThreadHLConsumer`类：
- en: '[PRE16]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Now run the multithreaded high-level consumer using the following command in
    a separate console window:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 现在在单独的控制台窗口中使用以下命令运行多线程高级消费者：
- en: '[PRE17]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'For successful execution, the `SimpleHLConsumer` class takes four arguments:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 为了成功执行，`SimpleHLConsumer`类需要四个参数：
- en: The Zookeeper connection string `<host:port>`
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zookeeper连接字符串`<host:port>`
- en: The unique group ID
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 唯一的组ID
- en: The Kafka topic name
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kafka主题名称
- en: The thread count
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线程计数
- en: This program will print all partitions of messages associated with each thread.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 此程序将打印与每个线程相关联的所有消息的所有分区。
- en: The Kafka consumer property list
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kafka消费者属性列表
- en: The following lists of a few important properties that can be configured for
    high-level, consumer-API-based Kafka consumers. The Scala class `kafka.consumer.ConsumerConfig`
    provides implementation-level details for consumer configurations. For a complete
    list, visit [http://kafka.apache.org/documentation.html#consumerconfigs](http://kafka.apache.org/documentation.html#consumerconfigs).
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些可以为基于高级消费者API的Kafka消费者配置的重要属性列表。Scala类`kafka.consumer.ConsumerConfig`提供了消费者配置的实现级细节。要获取完整列表，请访问[http://kafka.apache.org/documentation.html#consumerconfigs](http://kafka.apache.org/documentation.html#consumerconfigs)。
- en: '| Property name | Description | Default value |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| 属性名称 | 描述 | 默认值 |'
- en: '| --- | --- | --- |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| `group.id` | This property defines a unique identity for the set of consumers
    within the same consumer group. |   |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| `group.id` | 此属性为同一消费者组内的一组消费者定义了唯一标识。 |   |'
- en: '| `consumer.id` | This property is specified for the Kafka consumer and generated
    automatically if not defined. | `null` |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| `consumer.id` | 此属性为Kafka消费者指定，如果未定义，则会自动生成。 | `null` |'
- en: '| `zookeeper.connect` | This property specifies the Zookeeper connection string,
    `< hostname:port/chroot/path>`. Kafka uses Zookeeper to store offsets of messages
    consumed for a specific topic and partition by the consumer group. `/chroot/path`
    defines the data location in a global zookeeper namespace. |   |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| `zookeeper.connect` | 此属性指定Zookeeper连接字符串，`<hostname:port/chroot/path>`。Kafka使用Zookeeper来存储消费者组对特定主题和分区消耗的消息的偏移量。`/chroot/path`定义了全局zookeeper命名空间中的数据位置。
    |   |'
- en: '| `client.id` | The `client.id` value is specified by the Kafka client with
    each request and is used to identify the client making the requests. | `${group.id}`
    |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| `client.id` | 每个请求都由 Kafka 客户端指定 `client.id` 值，并用于标识发出请求的客户端。 | `${group.id}`
    |'
- en: '| `zookeeper.session.timeout.ms` | This property defines the time (in milliseconds)
    for a Kafka consumer to wait for a Zookeeper pulse before it is declared dead
    and rebalance is initiated. | `6000` |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| `zookeeper.session.timeout.ms` | 此属性定义了 Kafka 消费者在等待 Zookeeper 脉冲之前的时间（以毫秒为单位），在此时间内如果没有脉冲，消费者将被声明为死亡并启动重新平衡。
    | `6000` |'
- en: '| `zookeeper.connection.timeout.ms` | This value defines the maximum waiting
    time (in milliseconds) for the client to establish a connection with ZooKeeper.
    | `6000` |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| `zookeeper.connection.timeout.ms` | 此值定义了客户端与 ZooKeeper 建立连接的最长等待时间（以毫秒为单位）。
    | `6000` |'
- en: '| `zookeeper.sync.time.ms` | This property defines the time it takes to sync
    a Zookeeper follower with the Zookeeper leader (in milliseconds). | `2000` |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| `zookeeper.sync.time.ms` | 此属性定义了将 Zookeeper 跟随者与 Zookeeper 领导者同步所需的时间（以毫秒为单位）。
    | `2000` |'
- en: '| `auto.commit.enable` | This property enables a periodical commit of message
    offsets to the Zookeeper that are already fetched by the consumer. In the event
    of consumer failures, these committed offsets are used as a starting position
    by the new consumers. | `true` |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| `auto.commit.enable` | 此属性启用了定期将消费者已获取的消息偏移量提交到 Zookeeper。在消费者故障的情况下，这些提交的偏移量将被新的消费者用作起始位置。
    | `true` |'
- en: '| `auto.commit.interval.ms` | This property defines the frequency (in milliseconds)
    for the consumed offsets to get committed to ZooKeeper. | `60 * 1000` |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| `auto.commit.interval.ms` | 此属性定义了将消费的偏移量提交到 ZooKeeper 的频率（以毫秒为单位）。 | `60
    * 1000` |'
- en: '| `auto.offset.reset` | This property defines the offset value if an initial
    offset is available in Zookeeper or the offset is out of range. Possible values
    are:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '| `auto.offset.reset` | 此属性定义了如果在 Zookeeper 中有初始偏移量或偏移量超出范围时的偏移值。可能的值有：'
- en: '`largest`: reset to largest offset'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`largest`: 重置为最大偏移量'
- en: '`smallest`: reset to smallest offset'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`smallest`: 重置为最小偏移量'
- en: 'anything else: throw an exception'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其他任何值：抛出异常
- en: '| `largest` |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| `largest` |'
- en: '| `consumer.timeout.ms` | This property throws an exception to the consumer
    if no message is available for consumption after the specified interval. | `-1`
    |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| `consumer.timeout.ms` | 如果在指定的时间间隔后没有消息可供消费，此属性将向消费者抛出异常。 | `-1` |'
- en: Summary
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we have learned how to write basic consumers and learned about
    some advanced levels of Java consumers that consume messages from partitions.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们已经学习了如何编写基本的消费者，并了解了一些从分区消费消息的高级 Java 消费者。
- en: In the next chapter, we will learn how to integrate Kafka with Storm and Hadoop.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将学习如何将 Kafka 与 Storm 和 Hadoop 集成。
