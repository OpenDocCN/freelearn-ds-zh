- en: '1'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '1'
- en: What Are Time Series?
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是时间序列？
- en: “Time is the wisest counselor of all.” – Pericles
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: “时间是最智慧的顾问。” – 伯里克勒斯
- en: History is fascinating. It offers a profound narrative of our origins, the journey
    we are on, and the destination we strive toward. History equips us with learnings
    from the past to better face the future.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 历史是迷人的。它提供了我们起源的深刻叙述，展现了我们所走的路和我们奋斗的目标。历史赋予我们从过去汲取的教训，使我们更好地面对未来。
- en: Let’s take, for example, the impact of meteorological data on history. Disruptions
    in weather patterns, starting in the Middle Ages and worsened by the Laki volcanic
    eruption in 1783, caused widespread hardship in France. This climatic upheaval
    contributed to the social unrest that ultimately led to the French Revolution
    in 1789\. (Find out more about this in the *Further* *reading* section.)
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以气象数据对历史的影响为例。天气模式的变化，从中世纪开始，直到1783年拉基火山爆发后加剧，给法国带来了广泛的困苦。这场气候动荡加剧了社会的不安，最终导致了1789年的法国大革命。（关于这一点，详细内容请参考*进一步*
    *阅读*部分。）
- en: Time series embody this narrative with numbers echoing our past. **They are
    history quantified**, a numerical narrative of our collective past, with lessons
    for the future.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列体现了这一叙事，数字回响着我们的过去。**它们是历史的量化**，是我们集体过去的数值化叙事，为未来提供了宝贵的经验。
- en: This book takes you on a comprehensive journey with time series, starting with
    foundational concepts, guiding you through practical data preparation and model
    building techniques, and culminating in advanced topics such as scaling, and deploying
    to production, while staying abreast of recent developments for cutting-edge applications
    across industries. By the end of this book, you will be equipped to build robust
    time series models, in combination with Apache Spark, to meet the requirements
    of the use cases in your industry.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本书将带你进行一段全面的时间序列之旅，从基础概念开始，指导你进行实践中的数据准备和模型构建技巧，最终涵盖诸如扩展性和部署到生产等高级主题，同时跟进跨行业的尖端应用最新进展。通过本书的学习，你将能够结合Apache
    Spark构建强大的时间序列模型，以满足你所在行业应用场景的需求。
- en: As a start on this journey, this chapter introduces the fundamental concepts
    of time series data, exploring its sequential nature and the unique challenges
    it poses. The content covers key components such as trend and seasonality, providing
    a foundation to embark on time series analysis at scale using the Spark framework.
    This knowledge is crucial for data scientists and analysts as it forms the basis
    for leveraging Spark’s distributed computing capabilities in effectively analyzing
    and forecasting time-dependent data and making informed decisions in various domains
    such as finance, healthcare, and marketing.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 本章作为本书旅程的起点，介绍了时间序列数据的基本概念，探讨了其顺序性质和所面临的独特挑战。内容涵盖了趋势和季节性等关键组成部分，为使用Spark框架进行大规模时间序列分析奠定了基础。对于数据科学家和分析师来说，这些知识至关重要，它为有效利用Spark的分布式计算能力来分析和预测时间相关数据，并在金融、医疗保健、营销等多个领域做出明智决策提供了基础。
- en: 'We will cover the following topics in this chapter:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Introduction to time series
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 时间序列简介
- en: Breaking time series into their components
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将时间序列分解成其组成部分
- en: Additional considerations with time series analysis
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 时间序列分析中的额外考虑
- en: Technical requirements
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'In the first part of the book, which sets the foundations, you can follow along
    without participating in hands-on examples (although it’s recommended). The latter
    part of the book will be more practice-driven. If you want to get hands-on from
    the beginning, the code for this chapter can be found in the GitHub repository
    of this book at:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的第一部分，奠定了基础，你可以不参与实际操作示例而跟随阅读（尽管推荐参与）。本书后半部分将更加侧重于实践。如果你希望从一开始就进行实际操作，本章的代码可以在本书的GitHub仓库中找到，地址为：
- en: '[https://github.com/PacktPublishing/Time-Series-Analysis-with-Spark/tree/main/](https://github.com/PacktPublishing/Time-Series-Analysis-with-Spark/tree/main/ch1)ch1'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Time-Series-Analysis-with-Spark/tree/main/](https://github.com/PacktPublishing/Time-Series-Analysis-with-Spark/tree/main/ch1)ch1'
- en: Note
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Refer to this GitHub repository for the latest revisions of the code, which
    will be commented on if updated post-publication. The updated code (if any) might
    differ from what is presented in the book's code sections.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 请参考此GitHub仓库，以获取最新版本的代码，若在出版后有更新，将会进行注释说明。更新后的代码（如果有）可能与书中展示的代码部分有所不同。
- en: The following hands-on sections will give you further details to get started
    with time series analysis.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 以下动手实践部分将提供更多细节，帮助你开始进行时间序列分析。
- en: Introduction to time series
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 时间序列简介
- en: In this section, we will develop an understanding of what time series are and
    some related terms. This will be illustrated by hands-on examples to visualize
    time series. We will look at different types of time series and what characterizes
    them. This knowledge of the nature of time series is necessary for us to choose
    the appropriate time series analysis approach in the upcoming chapters.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们将了解什么是时间序列以及一些相关术语。通过动手实践的示例来可视化时间序列。我们将查看不同类型的时间序列及其特点。了解时间序列的性质对于我们在接下来的章节中选择合适的时间序列分析方法是必要的。
- en: Let’s start with an example of a time series with the average temperature in
    Mauritius every year since 1950\. A short sample of the data is shown in *Table
    1.1*.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从一个例子开始，这个时间序列表示的是自1950年以来毛里求斯每年的平均气温。数据的一个简短示例如*表 1.1*所示。
- en: '| **Year** | **Average temperature** |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| **年份** | **平均气温** |'
- en: '| --- | --- |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 1950 | 22.66 |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| 1950 | 22.66 |'
- en: '| 1951 | 22.35 |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| 1951 | 22.35 |'
- en: '| 1952 | 22.50 |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| 1952 | 22.50 |'
- en: '| 1953 | 22.71 |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| 1953 | 22.71 |'
- en: '| 1954 | 22.61 |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| 1954 | 22.61 |'
- en: '| 1955 | 22.40 |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| 1955 | 22.40 |'
- en: '| 1956 | 22.22 |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| 1956 | 22.22 |'
- en: '| 1957 | 22.53 |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| 1957 | 22.53 |'
- en: '| 1958 | 22.71 |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| 1958 | 22.71 |'
- en: '| 1959 | 22.49 |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| 1959 | 22.49 |'
- en: 'Table 1.1: Sample time series data – average temperature'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1.1：样本时间序列数据——平均气温
- en: While visualizing and explaining this example, we will be introduced to some
    terms related to time series. The code to visualize this dataset is covered in
    the hands-on section of this chapter.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在可视化并解释这个例子时，我们将接触到一些与时间序列相关的术语。用于可视化这个数据集的代码将在本章的动手部分讲解。
- en: In *the following figure*, we see the change in temperature over the years since
    1950\. If we focus on the period after 1980, we can observe the variations more
    closely, with similarly increasing temperatures over the years (trend – shown
    with a dashed line in both figures) to the current temperature.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在*下图*中，我们可以看到自1950年以来气温的变化。如果我们将注意力集中在1980年后的这段时间，我们可以更仔细地观察到温度的变化，呈现出类似的逐年升高的趋势（趋势——在两图中用虚线表示），直到当前的温度。
- en: '![](img/B18568_01_01.jpg)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18568_01_01.jpg)'
- en: 'Figure 1.1: Average temperature in Mauritius since 1950'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.1：自1950年以来毛里求斯的平均气温
- en: If the temperature continues to increase in the same way, we are heading to
    a warmer future, a manifestation of what is now widely accepted as global warming.
    At the same time as the temperature has been increasing over the years, it also
    goes up every summer and down during the winter months (**seasonality**). We will
    visualize this and other components of temperature time series in the hands-on
    section of this chapter.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 如果气温继续以相同的方式上升，我们正走向一个更温暖的未来，这也正是当前广泛接受的全球变暖的表现。与气温逐年上升的同时，每年夏季气温也会上升，冬季则会下降（**季节性**）。我们将在本章的动手部分可视化这一现象及温度时间序列的其他组成部分。
- en: With the temperatures getting warmer over the years (**trend**), global warming
    has an impact (**causality**) on our planet and its inhabitants. This impact can
    also be represented with time series – for example, sea level or rainfall measurements.
    The consequences of global warming can be dramatic and irreversible, which further
    highlights the importance of understanding this trend.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 随着多年来气温逐渐升高（**趋势**），全球变暖对我们星球及其居民产生了影响（**因果关系**）。这一影响也可以通过时间序列来表示——例如海平面或降水量的测量。全球变暖的后果可能是剧烈的和不可逆的，这进一步突显了理解这一趋势的重要性。
- en: These time-over-time readings of temperature form what we call a time series.
    Analysis and understanding of such a time series is critical for our future.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这些时间序列的温度读数构成了我们所称的时间序列。对这种时间序列的分析和理解对我们的未来至关重要。
- en: So, what is a time series in more general terms? It is simply a *chronological
    series of measurements together with the specific time at which it was generated
    by a source system*. In the example of temperature, the source system is the thermometer
    at a specific geographical location.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，更一般地说，什么是时间序列呢？它仅仅是一个*按时间顺序排列的测量序列，以及每个测量值由源系统生成的特定时间*。在温度的例子中，源系统是位于特定地理位置的温度计。
- en: Time series can also be represented in an aggregated form, such as the average
    temperature every year, as shown in *Table 1.1*.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列也可以以聚合形式表示，例如每年的平均气温，如*表 1.1*所示。
- en: From this definition, illustrated with an example, let’s now probe further into
    the nature of time series. We will also cover in further detail in the rest of
    this book the terms introduced here, such as trend, seasonality, and causality.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这个定义，并结合一个示例，我们将进一步探讨时间序列的性质。我们还将在本书的其余部分详细介绍这里提到的术语，如趋势、季节性和因果关系。
- en: Chronological order
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 时间顺序
- en: At the beginning of the chapter, we mentioned chronological order while defining
    time series, this is because it is a major factor that differentiates the approach
    when working with time series data compared to other datasets. One of the main
    reasons why order matters is due to potential auto-correlation within time series,
    where measurement at time `t` is related to measurement at `n` time steps earlier
    (**lag**). Ignoring this order will make our analysis incomplete and even incorrect.
    We will look at the method to identify auto-correlation later, in [*Chapter 6*](B18568_06.xhtml#_idTextAnchor116)
    on exploratory data analysis.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章开头，我们在定义时间序列时提到时间顺序，这是因为它是处理时间序列数据时与其他数据集的主要区别之一。顺序重要的一个主要原因是时间序列中的潜在自相关性，其中在时间`t`的测量值与`n`个时间步之前的测量值相关（**滞后**）。忽视这一顺序会使我们的分析不完整，甚至不正确。稍后我们将研究识别自相关性的方法，在[*第6章*](B18568_06.xhtml#_idTextAnchor116)的探索性数据分析中详细讨论。
- en: It is worth noting that, in many cases with time series, auto-correlation tends
    to make measurements closer in time closer in value, as compared to measurements
    further apart in time.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，在许多时间序列的情况下，自相关往往使得时间上较近的测量值之间的值更加接近，而与时间上较远的测量值相比，值的差异较大。
- en: Another reason to respect chronological order is to avoid data leakage during
    model training. In some of the analysis and forecasting methods, we will be training
    models on past data to predict value at a future target date. We need to ensure
    that all data points used are prior to the target date. Data leakage during training,
    often tricky to spot with time series data, will invalidate the integrity of the
    approach and create models that perform misleadingly well during development,
    then not so well when faced with new unseen data.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 尊重时间顺序的另一个原因是避免在模型训练过程中发生数据泄露。在一些分析和预测方法中，我们会使用过去的数据训练模型，以预测未来目标日期的值。我们需要确保所有使用的数据点都在目标日期之前。时间序列数据中的数据泄露往往难以发现，这会破坏方法的完整性，并在开发阶段让模型表现得过于理想，而在面对新的未见数据时表现不佳。
- en: Terms introduced here, such as auto-correlation, lags, and data leakage, will
    be further explained in the rest of the book.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的其余部分将进一步解释在这里提到的术语，如自相关、滞后和数据泄露。
- en: Chronological order, discussed here, is one defining characteristic of time
    series. In the next section, we will highlight regularity or the lack of it, which
    is another characteristic.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 本节讨论的时间顺序是时间序列的一个定义特征。在下一节中，我们将重点讨论规律性或其缺乏，这是另一个特征。
- en: Regular and irregular
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定期和不定期
- en: Time series can be regular or irregular with regard to the interval of their
    measurements.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列可以是定期的或不定期的，这取决于它们的测量间隔。
- en: Regular time series have values expected at regular intervals in time, say every
    minute, hour, month, and so on. This is usually the case for source systems generating
    a continuous value, which is then measured at a regular interval. This regularity
    is expected, but not guaranteed, as these time series can have gaps or values
    at zero, due to missing data points or just the measurement itself being zero.
    In this case, they will still be considered of a regular nature.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 定期时间序列在时间上的值是按规律的时间间隔预期的，比如每分钟、每小时、每月等等。这通常是源系统生成连续值的情况，这些值随后在规律的时间间隔内进行测量。这种规律性是预期的，但并不保证，因为这些时间序列可能会有间隔或值为零的情况，这可能是由于缺失的数据点或测量值本身为零造成的。在这种情况下，它们仍然会被视为定期的。
- en: Irregular time series are when measurements are not generated at regular intervals
    at the source. This is usually the case of events occurring at irregular points
    in time, for which events some type of value is then measured. These irregular
    interval values can be resampled to a regular interval with a lower frequency—effectively
    turning into a regular time series. For example, an irregular event not occurring
    every minute may have a likelihood of occurring every hour and be considered regular
    in nature at the hourly rate.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 非规则时间序列是指在源头上测量的时间间隔不规则的情况。这通常发生在事件在不规则的时间点发生，并且会测量某种类型的值。这些不规则时间间隔的值可以通过降频重采样转换为规则间隔，从而变成规则时间序列。例如，一个不按每分钟发生的事件，可能每小时发生一次，按小时来看的话，它是规则的。
- en: This book will primarily focus on regular time series. After the regularity
    of time series, another characteristic we will consider in the next section is
    stationarity.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 本书将主要关注规则时间序列。在时间序列的规则性之后，我们将在下一节考虑的另一个特征是平稳性。
- en: Stationary and non-stationary
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 平稳与非平稳
- en: Considering the statistical properties of time series over time, they can be
    further categorized as stationary or non-stationary.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到时间序列的统计性质随时间的变化，它们可以进一步分为平稳和非平稳。
- en: '**Stationary time series** are those for which statistical properties such
    as mean and variance do not vary over time.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '**平稳时间序列**是指那些统计性质（如均值和方差）随时间变化不大的时间序列。'
- en: '**Non-stationary time series** have changing statistical properties. These
    time series can be converted to stationary by a combination of methods: for example,
    one or more orders of differencing to stabilize the mean and using the log value
    to stabilize the variance. This distinction is important as it will determine
    which analysis method can be used. For instance, if an analysis method is based
    on the assumption of stationary series, the above conversion can be applied to
    non-stationary data first. You will learn about the method to identify stationarity
    in [*Chapter 6*](B18568_06.xhtml#_idTextAnchor116) on exploratory data analysis.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**非平稳时间序列**具有变化的统计性质。这些时间序列可以通过多种方法转换为平稳序列，例如，通过对差分进行一阶或多阶差分来稳定均值，使用对数值来稳定方差。这个区分非常重要，因为它决定了可以使用哪种分析方法。例如，如果某种分析方法假设时间序列是平稳的，那么可以先对非平稳数据进行上述转换。你将在[*第6章*](B18568_06.xhtml#_idTextAnchor116)中学习如何识别平稳性。'
- en: Note
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Converting a non-stationary time series to a stationary one removes the trend
    and seasonal components, which may not be what we want if we want to analyze these
    components.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 将非平稳时间序列转换为平稳时间序列可以去除趋势和季节性成分，但如果我们想分析这些成分，可能就不符合我们的需求。
- en: This section was an important one to understand the underlying nature of time
    series, which is a prerequisite to identifying the right analysis method to use
    in the later part of this book. *Figure 1**.2* summarizes the types of time series
    and conversation operations that can be used.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 本节内容对于理解时间序列的基本特性非常重要，这是在本书后半部分选择合适的分析方法的前提。*图1.2*总结了可以使用的时间序列类型和转换操作。
- en: '![](img/B18568_01_02.jpg)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18568_01_02.jpg)'
- en: 'Figure 1.2: Types of time series'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.2：时间序列类型
- en: This concludes the theoretical part of this chapter. In the next section, we
    will have our first hands-on experience, setting up the coding environment along
    the way. We will start with visualizing and decomposing time series in this chapter.
    We will get into different types of time series analysis and when they are used
    in the next chapter.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这部分结束了本章的理论内容。在接下来的部分，我们将进行第一次动手实践，同时设置编码环境。本章将从可视化和分解时间序列开始。我们将在下一章深入探讨不同类型的时间序列分析及其使用场景。
- en: 'Hands-on: Loading and visualizing time series'
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 动手实践：加载和可视化时间序列
- en: Let’s go through the hands-on exercise to load a time series dataset and visualize
    it. We will try to create the visual representation we’ve already seen in *Figure
    1**.1*.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过动手练习加载一个时间序列数据集并进行可视化。我们将尝试创建之前在*图1.1*中看到的可视化表示。
- en: Development environment
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 开发环境
- en: In order to run the code, you will need a Python development environment where
    you can install Apache Spark and other required libraries. Specific libraries
    will be detailed, together with installation instructions, in the corresponding
    chapters when required.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 为了运行代码，你需要一个Python开发环境，在其中安装Apache Spark和其他所需的库。具体的库和安装说明将在相关章节中详细介绍。
- en: PaaS
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: PaaS
- en: An easy way to get going with these requirements is by using Databricks Community
    Edition, which is free. This comes with a notebook-based development interface,
    as well as compute with pre-installed Spark and some other libraries.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 一个简单的方法是使用免费的 Databricks Community Edition，它包含一个基于笔记本的开发界面，并且预安装了 Spark 和其他一些库。
- en: 'The instructions to sign up for Databricks Community Edition can be found here:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 注册 Databricks Community Edition 的说明可以在这里找到：
- en: '[https://docs.databricks.com/en/getting-started/community-edition.html](https://docs.databricks.com/en/getting-started/community-edition.html)'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://docs.databricks.com/en/getting-started/community-edition.html](https://docs.databricks.com/en/getting-started/community-edition.html)'
- en: Community Edition’s compute size is limited as it is a free cloud-based PaaS.
    You can also sign up for a 14-day free trial of Databricks, which, depending on
    the signup option you choose, may require you to first have an account with a
    cloud provider. Some cloud providers may have promotions with some free credits
    at the start. This will give you access to more resources than on Community Edition,
    for a limited time.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: Community Edition 的计算能力是有限的，因为它是一个免费的基于云的 PaaS。你还可以注册 Databricks 的 14 天免费试用版，具体取决于你选择的注册选项，可能需要你首先拥有云服务提供商的账户。一些云服务提供商可能会有一些免费积分的促销活动，供你在开始时使用。这将为你提供比
    Community Edition 更多的资源，时间有限。
- en: 'Sign up for the free trial to Databricks at the following URL: [https://www.databricks.com/try-databricks](https://www.databricks.com/try-databricks)'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过以下网址注册 Databricks 的免费试用版：[https://www.databricks.com/try-databricks](https://www.databricks.com/try-databricks)
- en: The folks at Databricks are the original creators of Apache Spark, so you will
    be in a good place there.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: Databricks 的开发团队是 Apache Spark 的原创作者，因此在这里工作会是一个不错的选择。
- en: The examples in the early chapters will use Community Edition and the open source
    version of Apache Spark. We will use the full Databricks platform in [*Chapter
    8*](B18568_08.xhtml#_idTextAnchor151) and [*Chapter 10*](B18568_10.xhtml#_idTextAnchor190).
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 早期章节中的示例将使用 Community Edition 和 Apache Spark 的开源版本。我们将在 [*第 8 章*](B18568_08.xhtml#_idTextAnchor151)
    和 [*第 10 章*](B18568_10.xhtml#_idTextAnchor190) 中使用完整的 Databricks 平台。
- en: Custom
  id: totrans-77
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 自定义
- en: Alternatively, you can build your own environment, setting up the full stack,
    for instance, in a Docker container. This will be covered in [*Chapter 3*](B18568_03.xhtml#_idTextAnchor063),
    *Introduction to* *Apache Spark*.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，你可以搭建自己的环境，设置完整的技术栈，例如在 Docker 容器中。这将在 [*第 3 章*](B18568_03.xhtml#_idTextAnchor063)
    中介绍，*Apache Spark 简介*。
- en: Code
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 代码
- en: The code for this section is in the following notebook file titled `ts-spark_ch1_1.dbc`
    in the `ch1` folder of this book’s GitHub repository, as per the *Technical* *requirements*
    section.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 本节的代码位于本书 GitHub 仓库的 `ch1` 文件夹中的名为 `ts-spark_ch1_1.dbc` 的笔记本文件中，具体参考 *技术要求*
    部分。
- en: 'The location URL is as follows: [https://github.com/PacktPublishing/Time-Series-Analysis-with-Spark/raw/main/ch1/ts-spark_ch1_1.dbc](https://github.com/PacktPublishing/Time-Series-Analysis-with-Spark/raw/main/ch1/ts-spark_ch1_1.dbc)'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集的下载链接如下：[https://github.com/PacktPublishing/Time-Series-Analysis-with-Spark/raw/main/ch1/ts-spark_ch1_1.dbc](https://github.com/PacktPublishing/Time-Series-Analysis-with-Spark/raw/main/ch1/ts-spark_ch1_1.dbc)
- en: Dataset
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据集
- en: Once the development and runtime environment are chosen, the other consideration
    is the dataset. The one we will be using is the observed annual average mean surface
    air temperature of Mauritius, available on the Climate Change Knowledge Portal
    at [https://climateknowledgeportal.worldbank.org/country/mauritius](https://climateknowledgeportal.worldbank.org/country/mauritius).
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦选择了开发和运行时环境，另一个需要考虑的因素是数据集。我们将使用的是毛里求斯年均地表空气温度数据，可以在气候变化知识门户网站上找到，网址为 [https://climateknowledgeportal.worldbank.org/country/mauritius](https://climateknowledgeportal.worldbank.org/country/mauritius)。
- en: A copy of the dataset (in the file titled `ts-spark_ch1_ds1.csv`) is available
    in the `ch1` GitHub folder. It can be downloaded using the code mentioned earlier.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集的副本（文件名为 `ts-spark_ch1_ds1.csv`）可以在 GitHub 上的 `ch1` 文件夹中找到。可以使用前面提到的代码进行下载。
- en: Next, you will be working on the Databricks Community Edition workspace, which
    will be your own self-contained environment.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，你将在 Databricks Community Edition 工作区中工作，这将是你自己的独立环境。
- en: 'Step-by-step: Loading and visualizing time series'
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤：加载和可视化时间序列
- en: 'Now that we have everything set up, let’s get our hands on the first coding
    exercise. First, log in to Databricks Community Edition to import the code, create
    a cluster, and finally run the code:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经完成了所有设置，让我们开始第一个编程练习。首先，登录 Databricks Community Edition 导入代码，创建一个集群，并最终运行代码：
- en: 'Log in to Databricks Community Edition, shown in *Figure 1**.3*, using your
    credentials as specified during the signup process. Access the login page at the
    following URL: [https://community.cloud.databricks.com/](https://community.cloud.databricks.com/)'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用你在注册过程中指定的凭证登录到 Databricks Community Edition，如*图 1.3*所示。访问登录页面的 URL 为：[https://community.cloud.databricks.com/](https://community.cloud.databricks.com/)
- en: Refer to the *Development environment* section on how to sign up if you have
    not already done so.
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果你还没有注册，请参考*开发环境*部分，了解如何进行注册。
- en: '![](img/B18568_01_03.jpg)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18568_01_03.jpg)'
- en: 'Figure 1.3: Sign in to Databricks Community Edition'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.3：登录 Databricks Community Edition
- en: Once in the workspace, click on **Create a notebook**. See *Figure 1**.4*.
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 进入工作区后，点击**创建笔记本**。见*图 1.4*。
- en: '![](img/B18568_01_04.jpg)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18568_01_04.jpg)'
- en: 'Figure 1.4: Create a notebook'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.4：创建笔记本
- en: From here, we will get into the code, first importing the `ts-spark_ch1_1.dbc`
    notebook provided for [*Chapter 1*](B18568_01.xhtml#_idTextAnchor016) on GitHub,
    as per *Figure 1**.5*.
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从这里开始，我们将进入代码部分，首先导入提供的`ts-spark_ch1_1.dbc`笔记本，该笔记本可以在 GitHub 上找到，链接为[*第一章*](B18568_01.xhtml#_idTextAnchor016)，如*图
    1.5*所示。
- en: '![](img/B18568_01_05.jpg)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18568_01_05.jpg)'
- en: 'Figure 1.5: Import a notebook'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.5：导入笔记本
- en: 'Note that you can either download the file from the GitHub URL for [*Chapter
    1*](B18568_01.xhtml#_idTextAnchor016), provided in the *Technical requirements*
    section, to your local machines and then import it from there, or you can specify
    the following raw file URL for the import, as per *Figure* *1**.6*: [https://github.com/PacktPublishing/Time-Series-Analysis-with-Spark/raw/main/ch1/ts-spark_ch1_1.dbc](https://github.com/PacktPublishing/Time-Series-Analysis-with-Spark/raw/main/ch1/ts-spark_ch1_1.dbc)'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 请注意，你可以从*技术要求*部分提供的 GitHub URL 下载[*第一章*](B18568_01.xhtml#_idTextAnchor016)的文件到本地计算机，然后从那里导入，或者可以按*图
    1.6*所示，指定以下原始文件 URL 进行导入：[https://github.com/PacktPublishing/Time-Series-Analysis-with-Spark/raw/main/ch1/ts-spark_ch1_1.dbc](https://github.com/PacktPublishing/Time-Series-Analysis-with-Spark/raw/main/ch1/ts-spark_ch1_1.dbc)
- en: '![](img/B18568_01_06.jpg)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18568_01_06.jpg)'
- en: 'Figure 1.6: Import a notebook from the file or URL'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.6：从文件或 URL 导入笔记本
- en: We get to the actual code at this point. You should now have a notebook with
    code as per *Figure 1**.7*.
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 到现在为止，我们已经进入了实际的代码部分。你应该现在已经有了一个带有代码的笔记本，如*图 1.7*所示。
- en: '![](img/B18568_01_07.jpg)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18568_01_07.jpg)'
- en: 'Figure 1.7: Notebook with code'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.7：带代码的笔记本
- en: Finally, let’s run the code. Click on **Run all** as per *Figure 1**.8*.
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，让我们运行代码。点击**全部运行**，如*图 1.8*所示。
- en: '![](img/B18568_01_08.jpg)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18568_01_08.jpg)'
- en: 'Figure 1.8: Run all code in the notebook'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.8：运行笔记本中的所有代码
- en: In case you do not have a cluster already started, you will have to create and
    start a new one. Note that clusters are automatically terminated when not in use
    on Databricks Community Edition, in which case you will see the **Attached cluster
    is terminated** message, as per *Figure 1**.9*, and you will have to select another
    resource.
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你还没有启动集群，你需要创建并启动一个新的集群。请注意，在 Databricks Community Edition 中，当集群未使用时会自动终止，在这种情况下，你将看到**附加集群已终止**的消息，如*图
    1.9*所示，你需要选择另一个资源。
- en: '![](img/B18568_01_09.jpg)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18568_01_09.jpg)'
- en: 'Figure 1.9: Attached cluster is terminated'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.9：附加集群已终止
- en: From this point, you can either attach to another active cluster (non-terminated
    one) or choose to create a new resource as per *Figure 1**.10*.
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从此时起，你可以选择连接到另一个活动集群（非终止状态的集群），或者选择创建一个新的资源，如*图 1.10*所示。
- en: '![](img/B18568_01_10.jpg)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18568_01_10.jpg)'
- en: 'Figure 1.10: Compute – Create new resource'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.10：计算 – 创建新资源
- en: Next, you will need to specify a name for the cluster and which version of Spark
    you want to use, as per *Figure 1**.11*. The recommendation here is to use the
    latest version unless, for portability to another environment reasons, you need
    the code to work with an earlier version.
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，你需要为集群指定一个名称，并选择你想要使用的 Spark 版本，如*图 1.11*所示。这里的推荐做法是使用最新版本，除非由于需要在其他环境中运行的兼容性原因，你需要让代码在旧版本上工作。
- en: '![](img/B18568_01_11.jpg)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18568_01_11.jpg)'
- en: 'Figure 1.11: Compute – Create, Attach, & Run'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.11：计算 – 创建、附加并运行
- en: Once the cluster is created and started, which may take a few minutes in this
    free environment, the code will run, and you will see the chart in *Figure 1**.1*,
    toward the beginning of the chapter, as output. The graphical library used to
    create and display the chart provides you with an interactive interface, allowing
    you – for instance – to zoom into a specific time period.
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦集群创建并启动（在这个免费环境中可能需要几分钟时间），代码就会运行，你将看到章节开头的*图1.1*所示的图表作为输出。用于创建和显示图表的图形库提供了交互式界面，使你可以进行例如放大特定时间段的操作。
- en: As this is the first hands-on, we have gone into the step-by-step details. In
    future hands-on sections, we will be focusing on specific datasets and code as
    the rest will be very similar. Additional instructions will be provided whenever
    they differ.
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于这是第一次动手实践，我们已经详细介绍了逐步操作。在未来的实践部分，我们将专注于特定的数据集和代码，因为其他部分将非常相似。只要有差异，会提供额外的说明。
- en: 'Now that we have executed the code, let’s go over the main sections. We will
    keep it high level in this introductory section and go into further details in
    upcoming chapters once Apache Spark concepts have been introduced:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经执行了代码，接下来我们将回顾主要部分。在本介绍性部分，我们将保持高层次的讨论，待介绍完Apache Spark概念后，后续章节将进一步深入细节：
- en: 'The `import` statements add libraries for date format conversion and for drawing
    graphs:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`import`语句添加了日期格式转换和绘制图表的库：'
- en: '[PRE0]'
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We then use `spark.read` to read the CSV data file into a table:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们使用` spark.read`将CSV数据文件读取到表中：
- en: '[PRE1]'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The `spark.sql` statement chooses a subset of the dataset based on the year
    column, named `Category` in the source dataset:'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`spark.sql`语句基于源数据集中的年份列（命名为`Category`）选择数据集的一个子集：'
- en: '[PRE2]'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Finally, we plot the time series as well as the trendline based on **Ordinary
    Least Squares** (**OLS**) regression, as per *Figure 1**.1*:'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们根据**普通最小二乘法**（**OLS**）回归绘制时间序列以及趋势线，如*图1.1*所示：
- en: '[PRE3]'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The plotting library used, `plotly`, allows interactivity on the user interface,
    such as mouseover information on the data points and zooming in and out.
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用的绘图库`plotly`允许在用户界面上实现互动，例如鼠标悬停时显示数据点信息以及缩放。
- en: From this point on, feel free to experiment with the code and the Databricks
    Community Edition environment, which we will be using for most of the initial
    chapters of this book.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 从这一点开始，随时可以在代码和Databricks社区版环境中进行实验，我们将在本书的大部分初始章节中使用该环境。
- en: In this section, you had your first introduction to time series and the coding
    environment, starting with a simple exercise. In the next section, we will go
    into detail about some of the concepts introduced so far and break down a time
    series into its components.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，你首次接触了时间序列和编码环境，从一个简单的练习开始。在下一节中，我们将详细讲解到目前为止介绍的一些概念，并将时间序列分解为其组成部分。
- en: Breaking a time series down into its components
  id: totrans-130
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将时间序列分解为其组成部分
- en: This section aims to further your understanding of a time series by analyzing
    its components and detailing several terms introduced so far. This will set you
    on track for the rest of the book, to use the right methods based on the nature
    of the time series you are analyzing.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 本节旨在通过分析时间序列的组成部分，进一步加深对时间序列的理解，并详细说明迄今为止介绍的几个术语。这将为接下来的章节奠定基础，使你能够根据分析的时间序列特性使用正确的方法。
- en: 'Time series models can be broken down into three main components: trend, seasonality,
    and residuals:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列模型可以分解为三个主要组成部分：趋势、季节性和残差：
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi>T</mi><mi>i</mi><mi>m</mi><mi>e</mi><mi>S</mi><mi>e</mi><mi>r</mi><mi>i</mi><mi>e</mi><mi>s</mi><mo>=</mo><mi>T</mi><mi>r</mi><mi>e</mi><mi>n</mi><mi>d</mi><mo>+</mo><mi>S</mi><mi>e</mi><mi>a</mi><mi>s</mi><mi>o</mi><mi>n</mi><mi>a</mi><mi>l</mi><mi>i</mi><mi>t</mi><mi>y</mi><mo>+</mo><mi>R</mi><mi>e</mi><mi>s</mi><mi>i</mi><mi>d</mi><mi>u</mi><mi>a</mi><mi>l</mi><mi>s</mi></mrow></mrow></math>](img/1.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mi>T</mi><mi>i</mi><mi>m</mi><mi>e</mi><mi>S</mi><mi>e</mi><mi>r</mi><mi>i</mi><mi>e</mi><mi>s</mi><mo>=</mo><mi>T</mi><mi>r</mi><mi>e</mi><mi>n</mi><mi>d</mi><mo>+</mo><mi>S</mi><mi>e</mi><mi>a</mi><mi>s</mi><mi>o</mi><mi>n</mi><mi>a</mi><mi>l</mi><mi>i</mi><mi>t</mi><mi>y</mi><mo>+</mo><mi>R</mi><mi>e</mi><mi>s</mi><mi>i</mi><mi>d</mi><mi>u</mi><mi>a</mi><mi>l</mi><mi>s</mi></mrow></mrow></math>](img/1.png)'
- en: Note
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'The mathematical representations in this book will follow a simplified English
    notation, in favour of a broad audience. Refer to the following great resource
    on time series for mathematical formulations: *Forecasting: Principles and* *Practice*:
    [https://otexts.com/fpp3/](https://otexts.com/fpp3/).'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中的数学表示将采用简化的英文符号，以便于广泛的受众。关于时间序列的数学公式，请参考以下优秀资源：*《预测：原理与实践》*：[https://otexts.com/fpp3/](https://otexts.com/fpp3/)。
- en: As you will see in the next hands-on section, this breakdown into components
    is derived from the model fitted to the time series data. For most real-life datasets,
    the breakdown is only an approximation of reality by the model. As such, each
    model will come up with its own identification and approximation of the components.
    The whole idea is to find the best model that fits the time series. This is what
    we will be building up to and covering in [*Chapter 7*](B18568_07.xhtml#_idTextAnchor133)
    on building and testing models.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您将在接下来的实践部分看到的那样，这种成分的划分是基于拟合到时间序列数据的模型得出的。对于大多数实际数据集来说，这种分解仅仅是模型对现实的近似。因此，每个模型都会有自己对这些成分的识别和近似。整个目标是找到最适合时间序列的模型。这就是我们在[*第7章*](B18568_07.xhtml#_idTextAnchor133)中将要构建和测试的内容。
- en: Let’s go over each of the components, defining what they mean and visualizing
    them based on an example dataset, as in *Figure 1**.12*.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐一分析这些成分，定义它们的含义，并根据一个示例数据集进行可视化，如*图1.12*所示。
- en: '![](img/B18568_01_12.jpg)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18568_01_12.jpg)'
- en: 'Figure 1.12: Time series decomposition'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.12：时间序列分解
- en: Systematic and non-systematic components
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 系统性和非系统性成分
- en: The level, trend, seasonality, and cycle are called the **systematic** components.
    They represent the underlying structure of the time series, which can be modeled
    and hence forecast.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 水平、趋势、季节性和周期性被称为**系统性**成分。它们代表了时间序列的基础结构，可以进行建模，因此可以预测。
- en: In addition to the systematic components, there is a **non-systematic** part
    that cannot be modeled, which is called residual, noise, or error. The goal of
    time series modeling is to find the model with the best match for the systematic
    components while minimizing the residuals.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 除了系统成分外，还有一个**非系统性**部分无法建模，这部分被称为残差、噪声或误差。时间序列建模的目标是找到最适合系统成分的模型，同时最小化残差。
- en: We will now go into the details of each of the systematic and non-systematic
    parts.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将详细介绍每个系统性和非系统性部分。
- en: Level
  id: totrans-144
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 水平
- en: '**Level**, also referred to as the base level, is the mean of the series, acting
    as a baseline on which the effects of the other components are added. Sometimes,
    it is explicitly added to the preceding formula as an additional component. However,
    the level is not always shown in the formula, as it may not be the primary focus
    of the analysis, or the decomposition method may implicitly account for it within
    other components.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '**水平**，也称为基准水平，是序列的均值，作为基线，其他成分的效应会在其上叠加。有时，它会作为额外成分明确加入到前面的公式中。然而，水平并不总是出现在公式中，因为它可能不是分析的主要焦点，或者分解方法可能已经将其隐含在其他成分中。'
- en: Trend
  id: totrans-146
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 趋势
- en: '**Trend** is the component indicating the general direction in which the values
    in the time series go over a time period: increasing, decreasing, or flat. This
    change can be linear, as in *Figure 1**.1* and *Figure 1**.12*, or non-linear.
    The trend itself can change at different points in time, as what we can refer
    to as trend changepoints. More broadly, changepoints refer to points on the timeline
    when the statistical properties of the time series change. This can have a significant
    impact on the model parameters or even the model we use to analyze the time series.'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '**趋势**是指时间序列中值在一段时间内的总体变化方向：上升、下降或平稳。这种变化可以是线性的，如*图1.1*和*图1.12*所示，也可以是非线性的。趋势本身可以在不同的时间点发生变化，我们可以将其称为趋势变化点。更广泛地说，变化点是指时间序列的统计特性发生变化的时间点。这可能对模型参数，甚至我们用来分析时间序列的模型产生显著影响。'
- en: Seasonalities and cycles
  id: totrans-148
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 季节性和周期性
- en: '**Seasonality** indicates changes to a time series at regular time intervals.
    This is usually due to seasonal calendar events. Using our example with temperature,
    every summer month the temperature goes up compared to the rest of the year, and
    down during the winter months, as can be seen in *Figure 1**.12*. Similarly, a
    time series for sales of gift items will likely show an increase in sales every
    Christmas period in its seasonality pattern.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '**季节性**表示时间序列在固定时间间隔内的变化。这通常是由季节性日历事件引起的。以我们的温度例子为例，每年夏季的温度都会相对于其他季节升高，冬季则下降，如*图
    1.12*所示。类似地，礼品销售的时间序列可能会在每个圣诞节期间显示出销售的增加，形成其季节性模式。'
- en: Multiple seasonalities (intervals and amplitudes) can have a combined effect
    within the same time series, as illustrated in *Figure 1**.13*. For example, with
    temperatures, in addition to the ups and downs of summers and winters, the temperature
    goes up during the day and down every night.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 多重季节性（间隔和振幅）可以在同一时间序列中产生组合效应，如*图 1.13*所示。例如，在温度的例子中，除了夏冬季的起伏变化外，白天温度升高，夜间温度下降。
- en: '![](img/B18568_01_13.jpg)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18568_01_13.jpg)'
- en: 'Figure 1.13: Multiple overlapping seasonalities (synthetic data)'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.13：多重重叠的季节性（合成数据）
- en: '**Cycles** are changes that happen at intervals, similar to seasonality, with
    the difference of being at irregular intervals. Cycles in time series are reflective
    of external cycles impacting the series. For example, recessions occur every certain
    number of years and have an impact on economic indicators. We don’t know when
    in advance and it is different from the seasonality of Christmas, which just occurs
    predictably every December 25.'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '**周期性**是指类似季节性在不规则间隔发生的变化。时间序列中的周期性反映了外部周期对序列的影响。例如，经济衰退每隔若干年发生一次，并对经济指标产生影响。我们无法提前预测其发生时间，这与圣诞节的季节性不同，后者每年12月25日都能预测发生。'
- en: Remainders or residuals
  id: totrans-154
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 残差或剩余项
- en: '**Remainders** or **residuals** are what remains once the model has accounted
    for trends, seasonalities, and cycles. Remainders can be modeled using **autoregression**
    (**AR**) or **moving average** (**MA**) methods. What is still residual at this
    point, also referred to as noise or error, is random in nature and is the part
    that can’t be modeled. You can visualize residuals in the topmost graph of *Figure
    1**.12*, as the distance between the data points and the modeled line. We will
    look at the method to test for residuals in [*Chapter 6*](B18568_06.xhtml#_idTextAnchor116)
    on exploratory data analysis.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '**残差**或**剩余项**是指在模型已考虑了趋势、季节性和周期性之后所剩下的部分。残差可以使用**自回归**（**AR**）或**移动平均**（**MA**）方法进行建模。此时剩余的部分，也被称为噪声或误差，具有随机性，无法被建模。在*图
    1.12*的最上方图表中，你可以将残差可视化为数据点与拟合线之间的距离。我们将在[第6章](B18568_06.xhtml#_idTextAnchor116)中介绍如何测试残差，内容涉及探索性数据分析。'
- en: Note
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: While with residuals only a component of the time series is random, a whole
    series can be completely random or can be a random walk. A completely random series
    will have no dependency on earlier time values, whereas for a random walk, the
    value at time `t` is dependent on the value at `t-1` (plus some drift and a random
    component).
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 当残差只是时间序列中的一部分随机时，整个序列可能完全是随机的，或者是一个随机游走。完全随机的序列将不依赖于先前的时间值，而对于随机游走，时间`t`的值依赖于`t-1`时的值（加上一些漂移和随机成分）。
- en: Additive or multiplicative
  id: totrans-158
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 加法型或乘法型
- en: Time series can be **additive** (the preceding formula) or **multiplicative**.
    In the first case, the seasonality and residual components are not dependent on
    the trend. In the second case, they change with the trend and can be seen as changing
    amplitude of the seasonal component – for example, higher peaks and lower troughs.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列可以是**加法型**（前述公式）或**乘法型**。在加法型的情况下，季节性和残差成分不依赖于趋势。而在乘法型的情况下，它们随趋势变化，可以视为季节性成分的振幅变化——例如，较高的峰值和较低的谷值。
- en: Now that we have gone through the components of time series, let’s put this
    into practice with code.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了时间序列的各个组成部分，接下来我们通过代码来实践一下。
- en: 'Hands-on: Decomposing time series'
  id: totrans-161
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实践操作：分解时间序列
- en: To demonstrate `ts-spark_ch1_2fp.dbc`.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 以演示`ts-spark_ch1_2fp.dbc`为例。
- en: 'The location URL is as follows: [https://github.com/PacktPublishing/Time-Series-Analysis-with-Spark/raw/main/ch1/ts-spark_ch1_2fp.dbc](https://github.com/PacktPublishing/Time-Series-Analysis-with-Spark/raw/main/ch1/ts-spark_ch1_2fp.dbc)'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 位置 URL 如下：[https://github.com/PacktPublishing/Time-Series-Analysis-with-Spark/raw/main/ch1/ts-spark_ch1_2fp.dbc](https://github.com/PacktPublishing/Time-Series-Analysis-with-Spark/raw/main/ch1/ts-spark_ch1_2fp.dbc)
- en: 'The dataset we will be using is the daily minimum temperature from 1981 to
    1990 in Melbourne, Australia, originally from the Australian Bureau of Meteorology,
    and available on Kaggle at the following URL: [https://www.kaggle.com/datasets/samfaraday/daily-minimum-temperatures-in-me](https://www.kaggle.com/datasets/samfaraday/daily-minimum-temperatures-in-me)'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用的数据集是 1981 到 1990 年间澳大利亚墨尔本的每日最低温度，原始数据来自澳大利亚气象局，并可在 Kaggle 上通过以下链接获取：[https://www.kaggle.com/datasets/samfaraday/daily-minimum-temperatures-in-me](https://www.kaggle.com/datasets/samfaraday/daily-minimum-temperatures-in-me)
- en: A copy of the dataset is provided in the GitHub folder under the name `ts-spark_ch1_ds2.csv`.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集的副本已提供在 GitHub 文件夹中，文件名为`ts-spark_ch1_ds2.csv`。
- en: 'We will keep it high-level in this chapter, with selected extracts from the
    notebook, and go into further details in upcoming chapters once further concepts
    of forecasting models have been introduced:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将保持高层次的讨论，选取笔记本中的一些内容进行讲解，之后会在接下来的章节中详细介绍预测模型的其他概念：
- en: 'The `import` statements add libraries for forecasting models and for drawing
    graphs:'
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`import` 语句添加了用于预测模型和绘制图表的库：'
- en: '[PRE4]'
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The forecasting library used is `Prophet`, which is an open source library by
    Facebook. It is accessible to both experts and non-experts, providing automatic
    forecasting for time series data.
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用的预测库是 `Prophet`，它是 Facebook 开源的库。无论是专家还是非专家，都可以使用它进行时间序列数据的自动预测。
- en: 'We then use `spark.read` to read the CSV data file into a table:'
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们使用 `spark.read` 将 CSV 数据文件读入表格中：
- en: '[PRE5]'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The `spark.sql` statement converts the `date` and `daily_min_temperature` columns
    into the correct format and column name, which is required by `Prophet`:'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`spark.sql` 语句将 `date` 和 `daily_min_temperature` 列转换为正确的格式和列名，这是 `Prophet`
    所要求的：'
- en: '[PRE6]'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We then use the `Prophet` library to create a forecasting model on the basis
    of a seasonality of 12 months and fit it to the data:'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们使用 `Prophet` 库根据 12 个月的季节性创建一个预测模型，并将其拟合到数据上：
- en: '[PRE7]'
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The model is then used to predict temperatures for future dates:'
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该模型随后用于预测未来日期的温度：
- en: '[PRE8]'
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Finally, we plot the components of the time series as identified by the model,
    as shown in *Figure 1**.12*:'
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们绘制了模型识别出的时间序列成分，如*图 1.12*所示：
- en: '[PRE9]'
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Now that we have had a basic discussion on components and forecasting, let’s
    explore the case of overlapping seasonalities.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经对成分和预测做了基本讨论，让我们来探讨一下重叠季节性案例。
- en: Multiple overlapping seasonalities
  id: totrans-181
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多重重叠季节性
- en: We will be going through the code to create the data visualization in *Figure
    1**.13*. The code for this section is in the notebook file named `ts-spark_ch1_3.dbc`.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过代码来创建*图 1.13*中的数据可视化。此部分代码位于名为 `ts-spark_ch1_3.dbc` 的笔记本文件中。
- en: 'The location URL is as follows: [https://github.com/PacktPublishing/Time-Series-Analysis-with-Spark/raw/main/ch1/ts-spark_ch1_3.dbc](https://github.com/PacktPublishing/Time-Series-Analysis-with-Spark/raw/main/ch1/ts-spark_ch1_3.dbc)'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 位置 URL 如下：[https://github.com/PacktPublishing/Time-Series-Analysis-with-Spark/raw/main/ch1/ts-spark_ch1_3.dbc](https://github.com/PacktPublishing/Time-Series-Analysis-with-Spark/raw/main/ch1/ts-spark_ch1_3.dbc)
- en: The dataset is synthetic and generated as three different sine curves representing
    three overlapping seasonalities.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集是合成的，生成了三条不同的正弦曲线，代表三种重叠的季节性。
- en: 'The following code is an extract from the notebook. Let’s look at it at a high
    level:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码摘自笔记本。让我们从高层次进行查看：
- en: 'The `import` statements add libraries for numerical calculations and for drawing
    graphs:'
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`import` 语句添加了用于数值计算和绘图的库：'
- en: '[PRE10]'
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: NumPy is an open source Python library for scientific computing significantly
    more efficient in terms of computation and memory use than standard Python. We
    will use it here for its mathematical functions.
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: NumPy 是一个开源的 Python 科学计算库，相比标准 Python，它在计算和内存使用上显著更高效。我们将在此使用它的数学函数。
- en: 'We then generate a number of sine curves, using `np.sin`, to represent different
    seasonalities and add them together:'
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们生成多个正弦曲线，使用`np.sin`来表示不同的季节性，并将它们叠加在一起：
- en: '[PRE11]'
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Finally, we plot the individual seasonalities as well as the combined one,
    as per *Figure 1**.13*:'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们绘制了各个季节性以及它们的合成季节性，如*图 1.13*所示：
- en: '[PRE12]'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: From here on, feel free to experiment with the full code in the notebooks.
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从现在开始，尽管在笔记本中自由地尝试完整的代码。
- en: In this section, we started our journey analyzing time series, probing the underlying
    structure, and paving the way for further analysis with the most appropriate method
    based on their nature. In the next section, we will cover several key considerations
    and challenges to factor into our journey.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们开始了分析时间序列的旅程，探讨了其潜在结构，并根据数据的性质铺平了进一步分析的道路。在下一节中，我们将涵盖一些关键的考虑因素和挑战，帮助你在整个过程中做好准备。
- en: Additional considerations with time series analysis
  id: totrans-195
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 时间序列分析的额外考虑因素
- en: This section is probably the most important in this early part of the book.
    In the introductory section, we mentioned some key considerations for time series,
    such as the preservation of chronological order, regularity, and stationarity.
    Here, we map out the key challenges and additional considerations when analyzing
    time series in real-life projects. In doing so, it allows you to plan your learning
    and practice accordingly, with guidance in the relevant sections of this book
    as well as further reading.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 本节可能是本书早期部分中最重要的一节。在导言部分，我们提到了一些时间序列的关键考虑因素，例如保持时间顺序、规律性和稳定性。在这里，我们列出了在实际项目中分析时间序列时遇到的关键挑战和额外的考虑因素。通过这样做，你可以根据本书中相关部分的指导以及进一步阅读来规划自己的学习和实践。
- en: According to *Hidden Technical Debt in Machine Learning Systems* a well-known
    paper published in 2015, only a fraction of the effort is with the code in advanced
    analytics projects. The rest of the time is mostly spent on other considerations
    such as data preparation and infrastructure.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 根据2015年发表的著名论文《机器学习系统中的隐性技术债务》，在高级分析项目中，只有一小部分工作与代码相关。剩余的时间大多数用于其他考虑因素，如数据准备和基础设施建设。
- en: The solutions to these challenges are very specific to your context. The aim
    in this chapter is to bring these considerations, as summarized in *Figure 1**.14*,
    to your awareness.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 这些挑战的解决方案是非常具体的，依赖于你的具体背景。本章的目的是让你意识到这些考虑因素，如*图 1.14*所总结的。
- en: '![](img/B18568_01_14.jpg)'
  id: totrans-199
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18568_01_14.jpg)'
- en: 'Figure 1.14: Considerations and challenges with time series analysis'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.14：时间序列分析中的考虑因素和挑战
- en: While the majority of these considerations are shared in common with non-time-series
    analytics such as machine learning, time series analysis tends to be the most
    challenging of advanced analytics methods. We will go into detail on some of the
    solutions to these challenges in the rest of the book.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这些考虑因素大多数与非时间序列分析（如机器学习）共享，但时间序列分析通常是高级分析方法中最具挑战性的。我们将在本书的其余部分详细讨论一些应对这些挑战的解决方案。
- en: Facing data challenges
  id: totrans-202
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 面对数据挑战
- en: As with all data science and machine learning projects, data is key. The analysis
    you run and the model you build are going to be only as good as the data. Data
    challenges are varied and very dependent on your own specific context and dataset.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 与所有数据科学和机器学习项目一样，数据是关键。你运行的分析和构建的模型的效果将取决于数据的质量。数据挑战各式各样，且非常依赖于你的具体环境和数据集。
- en: 'We will list some of the common ones here:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在这里列出一些常见的问题：
- en: '**Access** to data is probably where it all starts. For the purpose of this
    book, we will be using several freely accessible datasets, so this will not be
    an issue. In real-life projects, the ownership of the dataset you need may sit
    in another part of your organization or even with another organization altogether.
    In this case, you will have to go through the process of acquiring the dataset,
    potentially at a financial cost, and transferring it reliably, with acceptable
    speed and freshness. The transfer pipeline will have its own cost to build as
    well as the transfer cost itself. The transfer mechanism will have to be production
    grade to support operational requirements: robust, recoverable, monitored, and
    so on.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据访问** 可能是所有问题的起点。对于本书而言，我们将使用几个免费访问的数据集，因此这不是问题。在实际项目中，所需数据集的所有权可能属于你所在组织的其他部门，甚至可能完全属于另一家组织。在这种情况下，你将不得不经历获取数据集的过程，可能会涉及财务成本，并确保数据能够以可靠的方式进行传输，同时保证传输速度和数据的新鲜度。传输管道的构建将有其自身的成本，以及传输本身的成本。传输机制必须具备生产级别的能力，以支持操作需求：稳健、可恢复、可监控等。'
- en: Initially, your data access requirement will be for exploratory data analysis
    and model training. A batch dump may be sufficient. Moving to production, you
    may need access to the data in real or near-real time. The considerations then
    are vastly different.
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 最初，你的数据访问需求将用于探索性数据分析和模型训练。批量导出可能足够。进入生产阶段后，你可能需要实时或近实时的数据访问。那时，考虑因素将完全不同。
- en: 'Once data is ingested, the next requirement is to store it in a secure and
    usable way. Using a specialized time series database is an option that is optimized
    for performance, though for the majority of cases, general-purpose storage is
    sufficient:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦数据被摄取，接下来的要求是以安全且可用的方式存储它。使用专门的时间序列数据库是一个优化性能的选择，尽管对于大多数情况，通用存储已足够：
- en: '**Sensitivity** is another key aspect. Again, here, there will likely be different
    requirements in development and production. In many cases, though, a subset of
    production data is used in development and testing. Certain columns with **Personally
    Identifiable Information** (**PII**) will require masking or encryption to comply
    with regulations such as GDPR in Europe. In highly sensitive cases, the whole
    dataset may be encrypted. This can be a challenge for large-scale processing,
    as every access to data may require decryption and re-encryption. This will have
    a processing overhead.'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**敏感性**是另一个关键方面。在这里，开发和生产中可能会有不同的要求。然而，在许多情况下，开发和测试中使用的是生产数据的子集。某些包含**个人身份信息**（**PII**）的列需要进行遮蔽或加密，以遵守如欧洲GDPR等法规。在高度敏感的情况下，整个数据集可能需要加密。这对大规模处理来说是一个挑战，因为每次访问数据都可能需要解密和重新加密。这会带来处理开销。'
- en: In summary, end-to-end security and data governance will be high on your requirement
    list, and this starts from day one. You want to avoid security and compliance
    risks at all stages, including during development, even more so if you are dealing
    with sensitive data.
  id: totrans-209
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 总结来说，端到端的安全性和数据治理将成为你的高优先级需求，这从第一天就开始了。你希望在每个阶段都避免安全性和合规性风险，包括开发阶段，尤其是当你处理敏感数据时。
- en: The **volume** and **frequency** of data feeds at high volume in real or near-real
    time will require the right platform to enable quick processing without data loss.
    This may not be initially apparent in a pre-production environment due to the
    smaller scale. Performance and reliability issues then tend to surface late when
    ramping up in production. We will discuss scaling and streaming once we have introduced
    Apache Spark, which will help you avoid such issues.
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据量**和**频率**在实时或近实时的大流量数据源中，将需要合适的平台来实现快速处理而不丢失数据。在预生产环境中，这一点可能不太明显，因为规模较小。性能和可靠性问题通常会在生产环境扩展时才显现出来。我们将在介绍Apache
    Spark时讨论扩展和流处理，这将帮助你避免此类问题。'
- en: '**Data quality** is a challenge we will face very early on, as soon as data
    access is resolved, and we start working with the data during the exploratory
    phase and in development. Challenges include gaps in data, corrupt data, noisy
    data, and – even more pertinent for time series – delayed and out-of-order data.
    As mentioned in the earlier section, it is important to preserve the chronological
    order for time series data. We will go further into resolving data quality issues
    when we discuss data preparation.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据质量**是我们早期将面临的挑战，一旦数据访问问题解决，我们开始在探索阶段和开发中处理数据。挑战包括数据缺失、数据损坏、数据噪声，甚至对于时间序列数据来说，更为相关的是数据延迟和乱序。如前所述，对于时间序列数据，保持时间顺序非常重要。在我们讨论数据准备时，我们将进一步探讨解决数据质量问题的方法。'
- en: Moving on from the data challenges, the next area of focus is choosing the right
    approach and model for the problem that needs solving.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据挑战之后，下一步的重点是为需要解决的问题选择正确的方法和模型。
- en: Using the right model
  id: totrans-213
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用正确的模型
- en: This may be more of a challenge for those new to time series. As we have seen
    so far, time series have different statistical properties. Some analysis and modeling
    methods are created based on assumptions about the statistical properties of time
    series, with stationarity as a common assumption. The method used will not work
    as intended or lead to misleading results if used with the incorrect type of time
    series. Handling multiple overlapping seasonalities, assuming you have identified
    them in the first place, can also be a challenge for some methods. *Figure 1**.14*
    gives a recap of the types of time series and analytical models. The choice of
    model will be discussed further in [*Chapter 7*](B18568_07.xhtml#_idTextAnchor133),
    *Building and* *Testing Models*.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 这对于那些刚接触时间序列的人来说可能是一个更大的挑战。正如我们到目前为止所看到的，时间序列具有不同的统计特性。一些分析和建模方法是基于对时间序列统计特性的假设而创建的，其中平稳性是常见的假设。如果使用不正确类型的时间序列，这些方法将无法按预期工作，甚至可能导致误导性结果。如果你已经识别出多个重叠的季节性，某些方法处理这些季节性也可能会是一个挑战。*图
    1.14* 回顾了时间序列和分析模型的类型。模型的选择将在[*第 7 章*](B18568_07.xhtml#_idTextAnchor133)，*构建和*
    *测试模型* 中进一步讨论。
- en: Selecting the right model is also very much dependent on what we want to achieve
    as an outcome, whether it is forecasting one or many time steps into the future,
    or analyzing one (univariate) or more (multivariate) series at the same time.
    For some domains, such as regulated industries, there is usually an additional
    requirement for explainability, which can be difficult with some models, such
    as black-box models. We will go further into the outcomes of time series analysis
    and choosing the right model, including for anomaly and pattern detection, in
    addition to predictive modeling, in the next chapter on why time series matter.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 选择正确的模型也在很大程度上取决于我们希望实现的结果，无论是预测未来一个或多个时间步长，还是同时分析一个（单变量）或多个（多变量）序列。对于一些领域，如受监管行业，通常还需要可解释性，而某些模型（如黑箱模型）可能难以满足这一要求。我们将在下一章《为什么时间序列重要》中进一步讨论时间序列分析的结果及如何选择合适的模型，包括用于异常和模式检测以及预测建模的模型。
- en: Maintaining spatial and temporal hierarchy
  id: totrans-216
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 维持空间和时间层次结构
- en: Note that another key consideration is the hierarchy in which the data is collected
    and analyzed. This needs to be consistent between different levels. To illustrate
    this point, let’s use an example of time series forecasting of the sales volume
    of different products by a multi-store retailer. Spatial hierarchies here will
    likely be at product and product category levels, as well as at specific stores
    and regional levels. Temporal hierarchies will correspond to sales every hour,
    every day, every quarter, and so on. The challenge in this case is to ensure the
    consistency of forecasts for individual products and product categories, as well
    as, say, daily forecasts adding up and being consistent with the quarterly forecast.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，另一个关键考虑因素是数据收集和分析的层次结构。这需要在不同层级之间保持一致性。为了说明这一点，让我们以一个多店零售商销售不同产品的时间序列预测为例。这里的空间层次结构可能位于产品和产品类别层级，以及特定商店和区域层级。时间层次结构将对应于每小时、每日、每季度等的销售情况。在这种情况下的挑战是确保单个产品和产品类别的预测一致性，以及例如，日度预测与季度预测的一致性。
- en: Finally, the right model depends on the volume of data as we will see in our
    discussion on building models in later chapters.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，选择正确的模型取决于数据量，正如我们将在后续章节中讨论的构建模型的内容。
- en: Tackling scalability
  id: totrans-219
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决可扩展性问题
- en: 'There are primarily two factors impacting scalability: data volume and processing
    complexity. Earlier, we discussed data volume as a data challenge. Let’s consider
    processing complexity here. **Complexity** can arise from the extent of data transformations
    required to prepare the data for use, as well as the number, hierarchy, and size
    of models that need to be managed:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 主要有两个因素影响可扩展性：数据量和处理复杂性。之前，我们讨论了数据量作为数据挑战。这里我们来考虑处理复杂性。**复杂性**可能来自于准备数据所需的数据转换的程度，以及需要管理的模型的数量、层次结构和大小：
- en: '**Large number and complex hierarchy of models**: As you work on actual projects,
    it will not be uncommon for you to have to run tens to even thousands of models
    in parallel within a relatively short time period – say, if you work in a store
    and need to forecast the next day’s sales and stock level for each of the thousands
    of items sold in the store. This need for parallelism is one of the key reasons
    for using Apache Spark, as we will see further in this book.'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**大量和复杂的模型层次结构**：在实际项目中工作时，您可能需要在相对较短的时间内并行运行数十甚至数千个模型 - 比如，如果您在商店工作并需要为商店中销售的成千上万种商品预测第二天的销售和库存水平。这种并行性的需求是使用Apache
    Spark的主要原因之一，我们将在本书中进一步了解。'
- en: '**Size of the model**: Another requirement for scalability comes from the size
    of the model itself, which can be very large and have high compute requirements
    if we are using deep learning techniques with many layers and nodes.'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型的大小**：可扩展性的另一个要求来自模型本身的大小，如果我们使用具有许多层和节点的深度学习技术，模型可能会非常庞大，并且具有高计算要求。'
- en: We will dedicate a whole chapter to scaling later in the book.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本书后面专门讨论扩展。
- en: Approaching real time
  id: totrans-224
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 接近实时
- en: Earlier, we identified high-frequency data as a significant data challenge.
    Approaching real time requires not just data-level adjustments but also a processing
    pipeline designed to handle such demands. Typically, models are trained on a batch
    of data collected over time, before being deployed for tasks such as forecasting
    or anomaly detection, where real-time processing becomes critical. For instance,
    in detecting fraudulent transactions, it’s essential to identify anomalies as
    close to the event occurrence as possible. A viable solution for near-instant
    data processing is Apache Spark Structured Streaming, a topic we’ll explore when
    we discuss Apache Spark later in the book.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 早些时候，我们确定高频数据是一个重要的数据挑战。接近实时不仅需要数据级别的调整，还需要一个设计用于处理这种需求的处理管道。通常，模型是在一段时间内收集的数据批次上进行训练，然后部署到诸如预测或异常检测等任务中，其中实时处理变得至关重要。例如，在检测欺诈交易时，尽可能接近事件发生时识别异常是至关重要的。近乎即时数据处理的可行解决方案是Apache
    Spark结构化流，这是我们在本书后面讨论Apache Spark时将探讨的一个主题。
- en: Managing production
  id: totrans-226
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生产管理
- en: The preceding considerations apply to the production environment as well. In
    addition, moving the developed solution into a production environment has several
    specific requirements. These can cause challenges if not managed properly.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 前述考虑也适用于生产环境。此外，将开发的解决方案移入生产环境还有一些特定要求。如果管理不当，这些要求可能会带来挑战。
- en: Once the right model has been trained and is ready for use, the next step is
    to package it together with any required API wrapper, as well as the data pipeline
    and model-consuming application code. This means an end-to-end process involving
    DataOps, ModelOps, and DevOps. We will go into more on these in[*Chapter 9*](B18568_09.xhtml#_idTextAnchor169)when
    we discuss production.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦正确的模型已经训练好并准备好使用，下一步是将其与任何必需的API包装器一起打包，以及数据管道和消耗模型的应用程序代码。这意味着一个涉及DataOps、ModelOps和DevOps的端到端过程。在我们讨论生产时，我们将在[*第9章*](B18568_09.xhtml#_idTextAnchor169)更详细地讨论这些内容。
- en: Monitoring and addressing drift
  id: totrans-229
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 监控和解决漂移
- en: 'Once a model is in use, changes happen over time, resulting in the model not
    being fit for purpose anymore. These changes are broadly categorized as follows:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦模型投入使用，随着时间的推移会发生变化，导致模型不再适合使用。这些变化大致分为以下几类：
- en: Changes in the nature of the dataset (**data drift**)
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据集性质的变化（**数据漂移**）
- en: Changes in the relationship between input and output (**concept drift**)
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输入和输出之间关系的变化（**概念漂移**）
- en: Unexpected events such as COVID, or impactful events missed out during the modeling
    process (**sudden drift**, a type of concept drift)
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 意外事件，如COVID，或在建模过程中遗漏的重要事件（**突发漂移**，一种概念漂移）
- en: These drifts will impact the model’s performance and, as such, need to be monitored.
    The solution in this case is usually to retrain the model on the new data or find
    a new model with better performance on the updated dataset.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 这些漂移将影响模型的性能，因此需要进行监控。在这种情况下的解决方案通常是根据新数据重新训练模型或找到在更新的数据集上性能更好的新模型。
- en: This section gave an overview of the considerations and challenges when working
    with time series. There are lots of commonalities with working on other datasets,
    so the guidance here will be useful in a broader context. As we saw in the introductory
    section, though, time series have their own set of specific considerations.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 本节概述了处理时间序列时的考虑因素和挑战。与处理其他数据集的通用性有很多共同之处，因此这里的指导在更广泛的背景下也将非常有用。然而，正如我们在介绍部分看到的那样，时间序列也有其特定的考虑因素。
- en: Summary
  id: totrans-236
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: Time series are everywhere, and this chapter gave us an introduction to what
    they are, their components, and the challenges in working with them. We started
    with some simple code to explore time series, setting the foundation for further
    practice in upcoming chapters. The concepts discussed in this first chapter will
    be built upon to get us to the point of analyzing time series at scale by the
    end of this book.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列随处可见，本章介绍了它们的基本概念、组成部分以及处理中的挑战。我们从一些简单的代码开始探索时间序列，为后续章节的进一步实践奠定基础。本书的第一章讨论的概念将逐步加深，最终使我们能够扩展到大规模分析时间序列的程度。
- en: Now that you understand the “what” for time series, in the next chapter, we
    will be looking at the “why,” which will pave the way to applications in various
    domains.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经理解了时间序列的“是什么”，在下一章中，我们将探讨“为什么”，这将为在各个领域中应用打下基础。
- en: Further reading
  id: totrans-239
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'This section serves as a repository of sources that can help you build on your
    understanding of the topic:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 本节作为资源库，可帮助您进一步了解该主题：
- en: '*Climate Chaos Helped Spark the French* *Revolution*: [https://time.com/6107671/french-revolution-history-climate/](https://time.com/6107671/french-revolution-history-climate/)'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*气候混乱助长了法国* *大革命*：[https://time.com/6107671/french-revolution-history-climate/](https://time.com/6107671/french-revolution-history-climate/)'
- en: 'Databricks Community Edition: [https://docs.databricks.com/en/getting-started/community-edition.html](https://docs.databricks.com/en/getting-started/community-edition.html)'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Databricks社区版: [https://docs.databricks.com/en/getting-started/community-edition.html](https://docs.databricks.com/en/getting-started/community-edition.html)'
- en: 'Climate Change Knowledge Portal: [https://climateknowledgeportal.worldbank.org/country/mauritius](https://climateknowledgeportal.worldbank.org/country/mauritius)'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 气候变化知识门户：[https://climateknowledgeportal.worldbank.org/country/mauritius](https://climateknowledgeportal.worldbank.org/country/mauritius)
- en: '*Forecasting: Principles and Practice* by Rob J Hyndman and George Athanasopoulos:
    [https://otexts.com/fpp3/](https://otexts.com/fpp3/)'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*预测: 原理与实践* 由Rob J Hyndman和George Athanasopoulos: [https://otexts.com/fpp3/](https://otexts.com/fpp3/)'
- en: '*Hidden Technical Debt in Machine Learning Systems* (Sculley et al., 2015):
    [https://papers.neurips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf](https://papers.neurips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf)'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*机器学习系统中的隐藏技术债务* (Sculley et al., 2015): [https://papers.neurips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf](https://papers.neurips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf)'
- en: Join our community on Discord
  id: totrans-246
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们的Discord社区
- en: 'Join our community’s Discord space for discussions with the authors and other
    readers:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 加入我们社区的Discord空间，与作者和其他读者讨论：
- en: '[https://packt.link/ds](https://packt.link/ds)'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/ds](https://packt.link/ds)'
- en: '![](img/ds_(1).jpg)'
  id: totrans-249
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ds_(1).jpg)'
