- en: Chapter 5. Spark Data Analysis with Python
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第5章 Spark与Python的数据分析
- en: The ultimate goal of processing data is to use the results for answering business
    questions. It is very important to understand the data that is being used to answer
    the business questions. To understand the data better, various tabulation methods,
    charting, and plotting techniques are used. Visual representation of the data
    reinforces the understanding of the underlying data. Because of this, data visualization
    is used extensively in data analysis.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 处理数据的最终目标是利用结果回答业务问题。理解用于回答业务问题的数据至关重要。为了更好地理解数据，采用了各种制表方法、图表和绘图技术。数据的可视化表示强化了对底层数据的理解。因此，数据可视化在数据分析中得到了广泛应用。
- en: There are different terms that are used in various publications to mean the
    analysis of data for answering business questions. Data analysis, data analytics,
    and business intelligence, are some of the ubiquitous terms floating around. This
    chapter is not going to delve into the discussion on the meaning, similarities,
    or differences of these terms. On the other hand, the focus is going to be on
    how to bridge the gap between two major activities typically done by data scientists
    or data analysts. The first one being data processing. The second one is the use
    of the processed data to do analysis with the help of charting and plotting. Data
    analysis is the forte of data analysts and data scientists. This chapter is going
    to focus on the usage of Spark and Python to process the data, and produce charts
    and plots.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在各种出版物中，用于表示分析数据以回答业务问题的术语各不相同。数据分析、数据分析和商业智能是一些普遍存在的术语。本章不会深入讨论这些术语的含义、相似之处或差异。相反，重点将放在如何弥合数据科学家或数据分析师通常执行的两个主要活动之间的差距。第一个是数据处理。第二个是利用处理过的数据借助图表和绘图进行分析。数据分析是数据分析师和数据科学家的专长。本章将重点介绍使用Spark和Python处理数据，并生成图表和图形。
- en: In many data analysis use cases, a super-set of data is processed and the reduced
    resultant dataset is used for the data analysis. This is specifically valid in
    the case of big data analysis where a small set of processed data is used for
    analysis. Depending on the use case, for various data analysis needs, appropriate
    data processing is done as a prerequisite. Most of the use cases that are going
    to be covered in this chapter fall into this model, where the first step deals
    with the necessary data processing, and the second step deals with the charting
    and plotting required for the data analysis.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多数据分析用例中，处理一个超集数据，并将缩减后的结果数据集用于数据分析。在大数据分析中，这一点尤为正确，其中一小部分处理过的数据用于分析。根据用例，针对各种数据分析需求，作为前提条件进行适当的数据处理。本章将要涵盖的大多数用例都属于这种模式，其中第一步涉及必要的数据处理，第二步涉及数据分析所需的图表和绘图。
- en: In typical data analysis use cases, the chain of activities involves an extensive
    and multi-staged **Extract**, **Transform**, and **Load** (**ETL**) pipeline ending
    with a data analysis platform or application. The end result of this chain of
    activities includes, but is not limited to, tables of summary data and various
    visual representations of the data in the form of charts and plots. Since Spark
    can process data from heterogeneous distributed data sources very effectively,
    the huge ETL pipeline that existed in legacy data analysis applications can be
    consolidated into self-contained applications that do the data processing and
    data analysis.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在典型的数据分析用例中，活动链涉及一个广泛且多阶段的**提取**、**转换**和**加载**（**ETL**）管道，最终形成一个数据分析平台或应用程序。这一系列活动链的最终结果包括但不限于汇总数据表以及以图表和图形形式呈现的各种数据可视化。由于Spark能非常有效地处理来自异构分布式数据源的数据，因此在传统数据分析应用中存在的庞大ETL管道可以整合为自包含的应用程序，进行数据处理和数据分析。
- en: 'We will cover the following topics in this chapter:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们将探讨以下主题：
- en: Charting and plotting libraries
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图表和绘图库
- en: Setting up a dataset
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置数据集
- en: Capturing the high-level details of the data analysis use cases
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 捕捉数据分析用例的高层次细节
- en: Various charts and plots
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 各种图表和图形
- en: Charting and plotting libraries
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图表和绘图库
- en: Python is a programming language heavily used by data analysts and data scientists
    these days. There are numerous scientific and statistical data processing libraries
    available, as well as charting and plotting libraries, that can be used in Python
    programs. Python is also widely used as a programming language to develop data
    processing applications in Spark. This brings in a great flexibility to have a
    unified data processing and data analysis framework with Spark, Python and Python
    libraries, enabling us to do scientific and statistical processing, and charting
    and plotting. There are numerous such libraries that work with Python. Out of
    all those, the**NumPy** and **SciPy **libraries are being used here to do numerical,
    statistical, and scientific data processing. The **matplotlib **library is being
    used here to do the charting and plotting that produces 2D images.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Python是当今数据分析师和数据科学家广泛使用的编程语言。有众多科学和统计数据处理库，以及图表和绘图库，可在Python程序中使用。Python也广泛用于开发Spark中的数据处理应用程序。这为使用Spark、Python及其库实现统一的数据处理和分析框架提供了极大的灵活性，使我们能够进行科学和统计处理，以及图表和绘图。有许多与Python兼容的此类库。其中，**NumPy**和**SciPy**库在此用于数值、统计和科学数据处理。**matplotlib**库在此用于生成2D图像的图表和绘图。
- en: Tip
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: It is very important to make sure that the  **NumPy**, **SciPy** and **matplotlib**
    Python libraries are working fine with the Python installation before attempting
    the code samples given in this chapter. This has to be tested and verified in
    isolation before using it in Spark applications.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 确保**NumPy**、**SciPy**和**matplotlib** Python库与Python安装正常工作非常重要，然后再尝试本章给出的代码示例。这需要在将其用于Spark应用程序之前进行测试和验证。
- en: 'The block diagram shown in *Figure 1* gives the overall structure of the application
    stack:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 如图*图1*所示的框图给出了应用程序堆栈的整体结构：
- en: '![Charting and plotting libraries](img/image_05_002.jpg)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![图表和绘图库](img/image_05_002.jpg)'
- en: Figure 1
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 图1
- en: Setting up a dataset
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置数据集
- en: There are many public Datasets available for the consumption of the general
    public that can be used for education, research, and development purposes. The
    MovieLens website lets users rate and personalize movie recommendations. GroupLens
    Research published the rating Datasets from MovieLens. These datasets are available
    for download from their website, [http://grouplens.org/datasets/movielens/](http://grouplens.org/datasets/movielens/).
    In this chapter, the MovieLens 100K Dataset is being used to demonstrate the usage
    of distributed data processing with Spark in conjunction with Python, NumPy, SciPy,
    and matplotlib.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多公共数据集可供公众用于教育、研究和开发目的。MovieLens网站允许用户对电影进行评分并个性化推荐。GroupLens Research发布了来自MovieLens的评分数据集。这些数据集可从其网站[http://grouplens.org/datasets/movielens/](http://grouplens.org/datasets/movielens/)下载。本章使用MovieLens
    100K数据集来演示如何结合Python、NumPy、SciPy和matplotlib使用Spark进行分布式数据处理。
- en: Tip
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: On the GroupLens Research website for the dataset download, apart from the preceding
    dataset, there are more voluminous datasets such as MovieLens 1M dataset, MovieLens
    10M dataset, MovieLens 20M dataset, and MovieLens latest datasets available for
    download. Once the reader is quite familiar with the programs and has achieved
    a sufficient level of comfort playing around with data, these additional datasets
    can be used by the reader to do their own analysis work to strengthen the knowledge
    acquired from this chapter.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在GroupLens Research网站上，除了上述数据集外，还有更多庞大的数据集可供下载，如MovieLens 1M数据集、MovieLens 10M数据集、MovieLens
    20M数据集以及MovieLens最新数据集。一旦读者对程序相当熟悉，并在处理数据时达到足够的舒适度，就可以利用这些额外数据集进行自己的分析工作，以巩固本章所获得的知识。
- en: 'The MovieLens 100K dataset has data in multiple files. The following are the
    ones that are going to be used in the data analysis use cases of this chapter:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: MovieLens 100K数据集包含多个文件中的数据。以下是本章数据分析用例中将使用的文件：
- en: '`u.user`: The demographic information about the users who have rated movies.
    The structure of the dataset is given as follows, reproduced as it is from the
    README file accompanying the dataset:'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`u.user`：关于对电影进行评分的用户的用户人口统计信息。数据集的结构如下所示，与数据集附带的README文件中复制的相同：'
- en: User ID
  id: totrans-23
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户ID
- en: Age
  id: totrans-24
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 年龄
- en: Gender
  id: totrans-25
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 性别
- en: Occupation
  id: totrans-26
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 职业
- en: Zip code
  id: totrans-27
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 邮政编码
- en: '`u.item`: The information about the movies that are rated by the users. The
    structure of the dataset is given as follows, reproduced as it is from the README
    file accompanying the dataset:'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`u.item`：关于用户评分的电影信息。数据集的结构如下所示，从随数据集提供的 README 文件中复制而来：'
- en: Movie ID
  id: totrans-29
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 电影 ID
- en: Movie title
  id: totrans-30
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 电影标题
- en: Release date
  id: totrans-31
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发行日期
- en: Video release date
  id: totrans-32
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 视频发行日期
- en: IMDb URL
  id: totrans-33
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: IMDb 链接
- en: Unknown
  id: totrans-34
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 未知类型
- en: Action
  id: totrans-35
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 动作片
- en: Adventure
  id: totrans-36
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 冒险片
- en: Animation
  id: totrans-37
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 动画片
- en: Children's
  id: totrans-38
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 儿童片
- en: Comedy
  id: totrans-39
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 喜剧片
- en: Crime
  id: totrans-40
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 犯罪片
- en: Documentary
  id: totrans-41
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 纪录片
- en: Drama
  id: totrans-42
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 剧情片
- en: Fantasy
  id: totrans-43
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 奇幻片
- en: Film-Noir
  id: totrans-44
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 黑色电影
- en: Horror
  id: totrans-45
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 恐怖片
- en: Musical
  id: totrans-46
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 音乐片
- en: Mystery
  id: totrans-47
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 悬疑片
- en: Romance
  id: totrans-48
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 爱情片
- en: Sci-Fi
  id: totrans-49
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 科幻片
- en: Thriller
  id: totrans-50
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 惊悚片
- en: War
  id: totrans-51
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 战争片
- en: Western
  id: totrans-52
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 西部片
- en: Data analysis use cases
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据分析用例
- en: 'The following list captures the high-level details of the data analysis use
    cases. Most of the use cases are revolving around the creation of various charts
    and plots:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 以下列表捕捉了数据分析用例的高级细节。大多数用例都围绕创建各种图表和图形展开：
- en: Plot the age distribution of the users who have rated the movies using a histogram.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用直方图绘制对电影进行评分的用户的年龄分布。
- en: Plot the age probability density chart of the users using the same data used
    to plot the histogram.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用与直方图相同的数据，绘制用户的年龄概率密度图。
- en: Plot the summary of the age distribution data to find the minimum, 25^(th) percentile,
    median, 75^(th) percentile, and maximum ages of the users.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 绘制年龄分布数据的摘要，以找到用户的最低年龄、第 25 百分位数、中位数、第 75 百分位数和最高年龄。
- en: Plot multiple charts or plots on the same figure to have a side-by-side comparison
    of the data.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在同一图上绘制多个图表或图形，以便对数据进行并排比较。
- en: Create a bar chart capturing the top 10 occupations in terms of the number of
    users who have rated the movies.
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个条形图，捕捉对电影进行评分的用户数量最多的前 10 个职业。
- en: Create a stacked bar chart capturing the number of male and female users by
    their occupation who have rated the movies.
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个堆叠条形图，按职业显示对电影进行评分的男性和女性用户数量。
- en: Create a pie chart capturing the bottom 10 occupations in terms of the number
    of who have rated the movies.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个饼图，捕捉对电影进行评分的用户数量最少的 10 个职业。
- en: Create a donut chart capturing the top 10 zip codes in terms of the number of
    who have rated the movies.
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个圆环图，捕捉对电影进行评分的用户数量最多的前 10 个邮政编码。
- en: Using three occupation categories, create box plots capturing the summary statistics
    of the users who have rated the movies. All three box plots have to be drawn on
    a single figure to enable comparison.
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用三个职业类别，创建箱线图，捕捉对电影进行评分的用户的汇总统计信息。所有三个箱线图都必须在单个图上绘制，以便进行比较。
- en: Create a bar chart capturing the number of movies by their genre.
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个条形图，按电影类型捕捉电影数量。
- en: Create a scatter plot capturing the top 10 years in terms of the number of movies
    released in each year.
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个散点图，捕捉每年发行电影数量最多的前 10 年。
- en: Create a scatter plot capturing the top 10 years in terms of the number of movies
    released in each year. In this plot, instead of points in the plot, create circles
    with the area proportional to the number of movies released in that year.
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个散点图，捕捉每年发行电影数量最多的前 10 年。在这个图中，不是用点来表示，而是创建与该年发行电影数量成比例的圆形区域。
- en: Create a line graph with two datasets with one dataset being the number of action
    movies released over the last 10 years and the other dataset being the number
    of drama movies released over the last 10 years to facilitate a comparison.
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一条折线图，包含两个数据集，一个数据集是过去 10 年发行的动作片数量，另一个数据集是过去 10 年发行的剧情片数量，以便进行比较。
- en: Tip
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: In all the preceding use cases, when it comes to implementation, Spark is used
    to process the data and prepare the required dataset. Once the required processed
    data is available in Spark DataFrame, it is collected into the driver program.
    In other words, the data is transferred from the distributed collection of Spark
    into a local collection, as tuples in the Python program, for charting and plotting.
    For charting and plotting, Python needs the data locally. It cannot use Spark
    DataFrames directly to do charting and plotting.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在前述所有用例中，当涉及实施时，Spark 用于处理数据并准备所需的数据集。一旦所需的已处理数据在 Spark DataFrame 中可用，它就会被收集到驱动程序中。换句话说，数据从
    Spark 的分布式集合转移到本地集合，在 Python 程序中作为元组，用于制图和绘图。对于制图和绘图，Python 需要本地数据。它不能直接使用 Spark
    DataFrames 进行制图和绘图。
- en: Charts and plots
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图表和图形
- en: 'This section is going to focus on creating various charts and plots to visually
    represent various aspects of the MovieLens 100K Dataset that are related to the
    use cases described in the preceding section. The charts and plots drawing process
    described throughout this chapter follows a pattern. Here are the important steps
    in that pattern of activities:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将重点介绍创建各种图表和图形，以直观地表示与前述部分描述的用例相关的MovieLens 100K数据集的各个方面。本章描述的图表和图形绘制过程遵循一种模式。以下是该活动模式中的重要步骤：
- en: Read data from the data file using Spark.
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用Spark从数据文件读取数据。
- en: Make the data available in a Spark DataFrame.
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使数据在Spark DataFrame中可用。
- en: Apply the necessary data processing using DataFrame API.
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用DataFrame API应用必要的数据处理。
- en: The processing is mainly to make available only the minimal and required data
    for charting and plotting purposes.
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 处理主要是为了仅提供制图和绘图所需的最小和必要数据。
- en: Transfer the processed data from Spark DataFrame to the local Python collection
    object in the Spark Driver program.
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将处理后的数据从Spark DataFrame传输到Spark驱动程序中的本地Python集合对象。
- en: Use the charting and plotting libraries to generate the figures using the data
    available in the Python collection objects.
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用图表和绘图库，利用Python集合对象中的数据生成图形。
- en: Histogram
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 直方图
- en: A histogram is generally used to show how a given numerical dataset is distributed
    over consecutive non-overlapping intervals of equal size. The interval or bin
    size is chosen based on the dataset. The bin or interval represents the ranges
    of data. In this use case, the dataset consists of the ages of the users. In this
    case it does not make sense to have a bin size of 100 as there will be only one
    bin and the entire dataset will fall into it. The height of the bars representing
    the bins indicates the frequency of data items in that bin or interval.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 直方图通常用于展示给定数值数据集在连续且不重叠的等宽区间上的分布情况。区间或箱宽的选择基于数据集。箱或区间代表数据的范围。在此用例中，数据集包含用户的年龄。在这种情况下，设置100的箱宽没有意义，因为只会得到一个箱，整个数据集都会落入其中。代表箱的条形的高度表示该箱或区间内数据项的频率。
- en: 'The following set of commands are used to bring up the Python REPL of Spark,
    followed by the programs to do the data processing, charting, and plotting:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令集用于启动Spark的Python REPL，随后是进行数据处理、制图和绘图的程序：
- en: '[PRE0]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'In the preceding section, the user dataset was read line by line to form the
    RDD. From the RDD, a Spark DataFrame was created. Using Spark SQL, another Spark
    DataFrame was created containing only the age column. The summary of that Spark
    DataFrame was displayed to show the summary statistics of the contents; the contents
    were collected into a local Python collection object. Using the collected data,
    a histogram of the age column was plotted, as given in *Figure 2*:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在前述部分，用户数据集被逐行读取以形成RDD。从RDD创建了一个Spark DataFrame。使用Spark SQL，创建了另一个仅包含年龄列的Spark
    DataFrame。显示了该Spark DataFrame的摘要，以展示内容的摘要统计信息；内容被收集到本地Python集合对象中。使用收集的数据，绘制了年龄列的直方图，如*图2*所示：
- en: '![Histogram](img/image_05_003.jpg)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![直方图](img/image_05_003.jpg)'
- en: Figure 2
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 图2
- en: Density plot
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 密度图
- en: There is another plot that is very close to a histogram. It is the density plot.
    Whenever there is a finite data sample with a need to estimate the probability
    density function of a random variable, density plots are used heavily. A histogram
    doesn't show when data smooths out or when there is continuity in the data points.
    For that purpose, density plots are used.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一种图表与直方图非常接近，那就是密度图。每当有有限的数据样本需要估计随机变量的概率密度函数时，密度图被广泛使用。直方图无法显示数据何时平滑或数据点何时连续。为此，使用密度图。
- en: Note
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Since a histogram and density plot are used for similar purposes, but show different
    behavior for the same data, generally, a histogram and density plot are used side
    by side in many applications.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 由于直方图和密度图用于类似目的，但对相同数据表现出不同行为，通常，直方图和密度图在很多应用中并排使用。
- en: '*Figure 3* is a density plot drawn for the same dataset that is used to plot
    the histogram.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '*图3*是为绘制直方图的同一数据集绘制的密度图。'
- en: 'As a continuation of the same Python REPL of Spark, run the following commands:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在同一Spark的Python REPL中继续运行以下命令：
- en: '[PRE1]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![Density plot](img/image_05_004.jpg)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![密度图](img/image_05_004.jpg)'
- en: Figure 3
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 图3
- en: In the preceding section, the same Spark DataFrame that was created containing
    only the age column was used and the contents were collected into a local Python
    collection object. Using the collected data, a density plot of the age column
    was plotted as given in *Figure 3*, with the line space from 0 to 100 representing
    the age.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一节中，使用了仅包含年龄列的同一Spark DataFrame，并将内容收集到本地Python集合对象中。利用收集的数据，绘制了年龄列的密度图，如*图3*所示，其中0到100的线间距代表年龄。
- en: If multiple charts or plots are to be looked at side by side, the **matplotlib**
    library provides ways to do that. Figure 4 shows a histogram and a box plot side
    by side.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 如果需要并排查看多个图表或图，**matplotlib**库提供了实现这一目的的方法。图4展示了并排的直方图和箱线图。
- en: 'As a continuation of the same Python REPL of Spark, run the following commands:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 作为同一Python REPL的Spark的延续，运行以下命令：
- en: '[PRE2]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![Density plot](img/image_05_005.jpg)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![密度图](img/image_05_005.jpg)'
- en: Figure 4
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 图4
- en: In the preceding section, the same Spark DataFrame that was created containing
    only the age column was used, and the contents were collected into a local Python
    collection object. Using the collected data, a histogram of the age column was
    plotted along with a box plot containing indicators for the minimum, 25^(th) percentile,
    median, 75^(th) percentile, and maximum values, as given in *Figure 4*. When drawing
    multiple charts or plots in one figure, for a way to control the layout, look
    at the method call `plt.subplot(121)`. This is talking about the selection of
    the plot laid out in one row and two columns, and selects the first one. In the
    same way, `plt.subplot(122)` talks about the selection of the plot laid out in
    one row and two columns, and selects the second one.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一节中，使用了仅包含年龄列的同一Spark DataFrame，并将内容收集到本地Python集合对象中。利用收集的数据，绘制了年龄列的直方图以及包含最小值、第25百分位数、中位数、第75百分位数和最大值指示器的箱线图，如*图4*所示。当在同一图形中绘制多个图表或图时，为了控制布局，请查看方法调用`plt.subplot(121)`。这是关于一行两列布局中图表选择的讨论，并选择了第一个。同样，`plt.subplot(122)`讨论了一行两列布局中的图表选择，并选择了第二个。
- en: Bar chart
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 条形图
- en: Bar charts can be drawn in different ways. The most common one is where the
    bars are standing vertically on the *X* axis. Another variation is where the bars
    are drawn on the *Y* axis and have the bars laid out horizontally. *Figure 5*
    shows a horizontal bar chart.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 条形图可以以不同方式绘制。最常见的是条形垂直于*X*轴站立。另一种变体是条形绘制在*Y*轴上，条形水平排列。*图5*展示了一个水平条形图。
- en: Note
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: It is very common to get confused between a histogram and bar chart. The important
    difference is that a histogram is used to plot continuous but finite numerical
    values, but a bar chart is used to represent categorical data.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 人们常常混淆直方图和条形图。重要的区别在于，直方图用于绘制连续但有限的数值，而条形图用于表示分类数据。
- en: 'As a continuation of the same Python REPL of Spark, run the following commands:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 作为同一Python REPL的Spark的延续，运行以下命令：
- en: '[PRE3]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![Bar chart](img/image_05_006.jpg)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![条形图](img/image_05_006.jpg)'
- en: Figure 5
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 图5
- en: In the preceding section, a Spark DataFrame was created containing the top 10
    occupations of the users in terms of the number of users who have rated movies.
    The data was collected into a Python collection object to plot the bar chart.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一节中，创建了一个Spark DataFrame，其中包含按用户评分电影数量排名的前10种职业。数据被收集到一个Python集合对象中，用于绘制条形图。
- en: Stacked bar chart
  id: totrans-110
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 堆叠条形图
- en: The bar chart that was drawn in the preceding section gives the top 10 user
    occupations in terms of the number of users. But that does not give details about
    how that number is made up in terms of the gender of the users. In this kind of
    situation, it is good to use a stacked bar chart with each bar showing the counts
    by gender. *Figure 6* shows a stacked bar chart.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一节中绘制的条形图展示了按用户数量排名的前10种用户职业。但这并未提供关于该数字如何按用户性别构成的详细信息。在这种情况下，使用堆叠条形图是很好的选择，每个条形图显示按性别统计的数量。*图6*展示了一个堆叠条形图。
- en: 'As a continuation of the same Python REPL of Spark, run the following commands:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 作为同一Python REPL的Spark的延续，运行以下命令：
- en: '[PRE4]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![Stacked bar chart](img/image_05_007.jpg)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![堆叠条形图](img/image_05_007.jpg)'
- en: Figure 6
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 图6
- en: In the preceding section, a Spark DataFrame was created containing only the
    occupation and gender columns. A cross-tab operation was done on that to produce
    another Spark DataFrame, which produced columns for occupation, male user count,
    and female user count. In the first Spark DataFrame, containing the occupation
    and gender columns, both are non-numerical columns and, because of that, it doesn't
    make sense to draw as chart or plot based on that data. But if a cross-tab operation
    is done on these two column values, for every distinct occupation field, then
    the counts of values of the gender column will be available. In this way, the
    occupation field becomes a categorical variable and it makes sense to draw a bar
    chart with the data. Since there are only two gender values in this data, it makes
    sense to have a stacked bar chart to see the total as well as the proportions
    of male and female user counts in each occupation category.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在前述部分中，创建了一个仅包含职业和性别列的Spark DataFrame。对其实施了交叉表操作，生成了另一个Spark DataFrame，该DataFrame包含了职业、男性用户数和女性用户数列。在最初的Spark
    DataFrame中，职业和性别列均为非数值列，因此基于这些数据绘制图表或图形并无意义。但若对这两列的值进行交叉表操作，针对每个不同的职业字段，性别列的值计数将得以呈现。如此一来，职业字段便成为了一个分类变量，此时绘制条形图便合乎逻辑。鉴于数据中仅有两种性别值，采用堆叠条形图既能显示总数，又能展示各职业类别中男女用户数的比例，显得合情合理。
- en: There are many statistical and mathematical functions available within DataFrames
    in Spark. The cross-tab operation on a Spark DataFrame comes in very handy in
    this kind of situation. With huge datasets, the cross-tab operation can become
    very processor-intensive and time consuming, but the distributed processing capabilities
    of Spark are a great help in this kind of situation.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在Spark DataFrame中，有许多统计和数学函数可供使用。在这种情境下，交叉表操作显得尤为便捷。对于庞大的数据集，交叉表操作可能会非常耗费处理器资源和时间，但Spark的分布式处理能力在此类情况下提供了极大的帮助。
- en: 'Spark SQL comes with lots of mathematical and statistical data processing capabilities.
    The preceding sections used the `describe().show()` method on the `SparkDataFrame`
    objects. In those Spark DataFrames, the preceding method acted on the available
    numeric columns. There will be situations where there are multiple numeric columns
    and, in those situations, the preceding method has the ability to pick and choose
    the desired columns for getting the summary statistics. Similarly, there are methods
    to find covariance, correlation, and so on, on the data from the Spark DataFrame.
    The following code snippet demonstrates these methods:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: Spark SQL具备丰富的数学和统计数据处理功能。前述部分使用了`SparkDataFrame`对象上的`describe().show()`方法。在这些Spark
    DataFrames中，该方法作用于现有的数值列。在存在多个数值列的情况下，该方法能够选择所需的列以获取汇总统计信息。同样，也有方法可以计算来自Spark
    DataFrame的数据的协方差、相关性等。以下代码片段展示了这些方法：
- en: '[PRE5]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Pie chart
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 饼图
- en: If there is a need to visually represent a dataset to explain the whole-part
    relationship, a pie chart is very commonly used. *Figure 7* shows a pie chart.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 若需通过视觉手段展示数据集以阐明整体与部分的关系，饼图是常用的选择。*图7*展示了一个饼图。
- en: 'As a continuation of the same Python REPL of Spark, run the following commands:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在同一Python REPL的Spark会话中，执行以下命令：
- en: '[PRE6]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![Pie chart](img/image_05_008.jpg)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![饼图](img/image_05_008.jpg)'
- en: Figure 7
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '*图7*'
- en: In the preceding section, a Spark DataFrame was created containing the bottom
    10 occupations of the users in terms of the number of users who have rated movies.
    The data was collected into a Python collection object to plot the pie chart.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在前述部分中，创建了一个Spark DataFrame，其中包含了用户按评分电影数量排名的底部10种职业。数据被收集到一个Python集合对象中，以便绘制饼图。
- en: Donut chart
  id: totrans-127
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 环形图
- en: Pie charts can be drawn in different forms. One such form, the donut chart,
    is often used these days. Figure 8 shows this donut chart variation of the pie
    chart.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 饼图可以有多种绘制形式。其中一种形式，即环形图，近年来颇受欢迎。*图8*展示了这种饼图的环形图变体。
- en: 'As a continuation of the same Python REPL of Spark, run the following commands:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在同一Python REPL的Spark会话中，执行以下命令：
- en: '[PRE7]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![Donut chart](img/image_05_009.jpg)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![环形图](img/image_05_009.jpg)'
- en: Figure 8
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '*图8*'
- en: In the preceding section, a Spark DataFrame was created containing the top 10
    zip codes of the users in terms of the number of users who live in that area and
    who have rated movies. The data was collected into a Python collection object
    to plot the donut chart.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的部分中，创建了一个包含用户居住地区和评价电影的用户数量最多的前10个邮政编码的 Spark DataFrame。数据被收集到一个 Python
    集合对象中以绘制圆环图。
- en: Tip
  id: totrans-134
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: Compared to the other figures in this book, the title of *Figure 8* is given
    in the middle. It is done using the `text()` method rather than using the `title()`
    method. This method can be used to print watermark text on the charts and plots.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他图表相比，*图8*的标题位于中间。这是使用`text()`方法而不是`title()`方法完成的。此方法可用于在图表和绘图上打印水印文本。
- en: Box plot
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 箱形图
- en: Frequently, it is a common requirement to compare the summary statistics of
    different datasets in one figure. The box plot is a very common plot used to capture
    the summary statistics of a dataset in an intuitive way. The following section
    does exactly the same, and to do this, *Figure 9* shows multiple box plots on
    a single figure.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在单个图表中比较不同数据集的汇总统计信息是一个常见需求。箱形图是一种常用的图表，用于直观地捕捉数据集的汇总统计信息。接下来的部分正是这样做的，*图9*展示了单个图表上的多个箱形图。
- en: 'As a continuation of the same Python REPL of Spark, run the following commands:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在同一 Python REPL 的 Spark 中继续，运行以下命令：
- en: '[PRE8]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![Box plot](img/image_05_010.jpg)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![箱形图](img/image_05_010.jpg)'
- en: Figure 9
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 图9
- en: 'In the preceding section, a Spark DataFrame was created with occupation and
    age columns for each of three occupations: administrator, engineer, and programmer.
    Box plots were created for each of these datasets on one figure, which contains
    indicators for the minimum, 25^(th) percentile, median, 75^(th) percentile, maximum,
    and outlier values for each of the datasets to facilitate comparison. The box
    plot for the programmer occupation shows two value points represented by the `+`
    symbol. They are outlier values.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的部分中，使用职业和年龄列为管理员、工程师和程序员三种职业创建了一个 Spark DataFrame。在一张图上为每个数据集创建了箱形图，该图包含每个数据集的最小值、第25百分位数、中位数、第75百分位数、最大值和异常值的指示器，以便于比较。程序员职业的箱形图显示了两个由`+`符号表示的值点。它们是异常值。
- en: Vertical bar chart
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 垂直条形图
- en: In the preceding sections, the main dataset used for eliciting various charting
    and plotting use cases was the user data. The dataset that is taken up next is
    the movie dataset. In many datasets, to produce various charts and plots it will
    be a requirement to make the data suitable for the appropriate figure. Spark is
    rich with features to do the data processing.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的部分中，用于引出各种图表和绘图用例的主要数据集是用户数据。接下来要处理的数据集是电影数据集。在许多数据集中，为了制作各种图表和绘图，需要对数据进行适当的处理以适应相应的图表。Spark
    提供了丰富的功能来进行数据处理。
- en: The following use case demonstrates the preparation of data by applying some
    aggregation and using Spark SQL; the desired dataset is prepared for a classic
    bar chart containing the counts of movies by genre. *Figure 10* shows the bar
    chart after applying the aggregation operation on the movie data.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的用例展示了通过应用一些聚合并使用 Spark SQL 来准备数据，为包含按类型统计电影数量的经典条形图准备了所需的数据集。*图10*展示了在电影数据上应用聚合操作后的条形图。
- en: 'As a continuation of the same Python REPL of Spark, run the following commands:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在同一 Python REPL 的 Spark 中继续，运行以下命令：
- en: '[PRE9]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![Vertical bar chart](img/image_05_011.jpg)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![垂直条形图](img/image_05_011.jpg)'
- en: Figure 10
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 图10
- en: In the preceding section, a `SparkDataFrame` was created with the movie dataset.
    The genre of the movie was captured in separate columns. Across the dataset, an
    aggregation was done using Spark SQL, a new `SparkDataFrame` summary was created,
    and the data values were collected into a Python collection object. Since there
    are too many columns in the dataset, a Python function was used to convert that
    kind of data structure into a dictionary object containing the column name as
    the key and the selected single row value is the value of the key. From that dictionary,
    two datasets were created and a bar chart is drawn.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的部分中，使用电影数据集创建了一个 `SparkDataFrame`。电影类型被捕获在单独的列中。在整个数据集中，使用 Spark SQL 进行了聚合，创建了一个新的
    `SparkDataFrame` 摘要，并将数据值收集到一个 Python 集合对象中。由于数据集中列太多，使用了一个 Python 函数将这种数据结构转换为包含列名作为键和选定单行值作为键值的词典对象。从该词典中，创建了两个数据集，并绘制了一个条形图。
- en: Tip
  id: totrans-151
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: When working with Spark, Python is used to develop data analysis applications,
    and it is almost certain that there are going to be many charts and plots. Instead
    of trying out all the code samples given in this chapter on the Python REPL for
    Spark, it is better to use IPython notebook as the IDE so that the code and the
    results can be seen together. The download section of this book contains the IPython
    notebook that contains all this code and the results. Readers can directly start
    using this.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用Spark进行数据分析应用开发时，Python几乎肯定会用到许多图表和图形。与其尝试在本章中给出的所有代码示例在Spark的Python REPL中运行，不如使用IPython笔记本作为IDE，以便代码和结果可以一起查看。本书的下载部分包含一个包含所有这些代码和结果的IPython笔记本。读者可以直接开始使用它。
- en: Scatter plot
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 散点图
- en: Scatter plots are very commonly used for plotting values that have two variables,
    such as a point in Cartesian space having an `X` value and `Y` value. In this
    movie dataset, the number of movies released in a given year shows this kind of
    behavior. In the scatter plots, typically, the values represented at the intersection
    points of the `X` coordinate and `Y` coordinate are points. Because of recent
    technology developments and the availability of sophisticated graphics packages,
    many use different shapes and colors to represent the points. In the following
    scatter plot, shown in *Figure 11*, small circles having a uniform area with random
    colors have been used to represent the values. When employing such intuitive and
    clever techniques to represent the points in scatter plots, care must be taken
    to make sure that it does not defeat the purpose and loses the simplicity that
    scatter plots offer to convey the behavior of the data. Simple and elegant shapes
    that do not clutter the Cartesian space are ideal for such non-point representations
    of the values.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 散点图常用于绘制具有两个变量的值，例如笛卡尔空间中的一个点，它具有`X`值和`Y`值。在本电影数据集中，某一年发布的电影数量就表现出这种特性。在散点图中，通常`X`坐标和`Y`坐标的交点处表示的值是点。由于近期技术的发展和高级图形包的可用性，许多人使用不同的形状和颜色来表示这些点。在下面的散点图中，如*图11*所示，使用了具有统一面积和随机颜色的小圆圈来表示这些值。当采用这些直观且巧妙的技术在散点图中表示点时，必须确保它不会违背散点图的初衷，也不会失去散点图传达数据行为所提供的简洁性。简单而优雅的形状，不会使笛卡尔空间显得杂乱，是这种非点表示值的理想选择。
- en: 'As a continuation of the same Python REPL of Spark, run the following commands:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在同一Python REPL中继续使用Spark，运行以下命令：
- en: '[PRE10]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '![Scatter plot](img/image_05_012.jpg)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![散点图](img/image_05_012.jpg)'
- en: Figure 11
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 图11
- en: In the preceding section, a `SparkDataFrame` was used to collect the top 10
    years in terms of the number of movies released in that year and the values were
    collected into a Python collection object and a scatter plot was drawn.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一节中，使用了一个`SparkDataFrame`来收集按电影发布数量排名的前10年，并将这些值收集到一个Python集合对象中，并绘制了一个散点图。
- en: Enhanced scatter plot
  id: totrans-160
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 增强型散点图
- en: '*Figure 11* is a very simple and elegant scatter plot, but it does not really
    convey the comparative behavior of a given plotted value as compared to the other
    values in the same space. For that, instead of representing the points as fixed-radius
    circles, if the points are drawn as circles with the area proportional to the
    value, that will give a different perspective. Figure 12 is going to show the
    scatter plot with the same data, but with circles that have a proportional area
    to represent the points.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '*图11*是一个非常简单而优雅的散点图，但它并没有真正传达出与同一空间中其他值相比，给定绘制值的比较行为。为此，与其将点表示为固定半径的圆，不如将点绘制为面积与值成比例的圆，这将提供一个不同的视角。图12将展示具有相同数据但用面积与值成比例的圆来表示点的散点图。'
- en: 'As a continuation in the same Python REPL of Spark, run the following commands:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在同一Python REPL中继续使用Spark，运行以下命令：
- en: '[PRE11]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '![Enhanced scatter plot](img/image_05_013.jpg)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
  zh: '![增强型散点图](img/image_05_013.jpg)'
- en: Figure 12
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 图12
- en: In the preceding section, the same dataset was used for *Figure 11* to draw
    the same scatter plot. Instead of plotting the points with uniform area circles,
    the points were drawn with proportionate area circles.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一节中，使用相同的数据集为*图11*绘制了相同的散点图。与使用统一面积的圆圈绘制点不同，这些点是用面积与值成比例的圆圈绘制的。
- en: Tip
  id: totrans-167
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: In all these code samples, the charts and plots are displayed using the show
    method. There are methods in matplotlib to save the generated charts and plots
    to disk, and they can be used for e-mailing, publishing to dashboards, and more.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些代码示例中，图表和图形都是通过show方法展示的。matplotlib中有方法可以将生成的图表和图形保存到磁盘，这些图表和图形可用于电子邮件发送、发布到仪表板等。
- en: Line graph
  id: totrans-169
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 折线图
- en: There are similarities between a scatter plot and a line graph. A scatter plot
    is ideal for representing individual data points, but taking all the points together
    gives a trend. A line graph also represents individual data points, but the points
    are connected. This is ideal for seeing the transition from one point to another
    point. In one figure, multiple line graphs can be drawn, enabling the comparison
    of two datasets. The preceding use case used a scatter plot to represent the number
    of movies released over a few years. Those numbers are just discrete data points
    plotted on one figure. If the need is to see a trend of how movie releases are
    changing over the years, a line graph is ideal. Similarly, if there is a need
    to compare movie releases over the years for two different genres, then one line
    can be used for each genre and both can be plotted on a single line graph. *Figure
    13* is a line graph with multiple datasets.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 散点图与折线图之间存在相似之处。散点图非常适合表示单个数据点，但将所有点放在一起可以显示趋势。折线图也代表单个数据点，但这些点是相连的。这对于观察从一个点到另一个点的过渡非常理想。在一张图中，可以绘制多个折线图，便于比较两个数据集。前面的用例使用散点图来表示几年内发行的电影数量。这些数字只是绘制在一张图上的离散数据点。如果需要查看多年来电影发行的趋势，折线图是理想的选择。同样，如果需要比较两个不同类型电影的发行情况，则可以为每个类型使用一条线，并将两者都绘制在单个折线图上。*图13*是一个包含多个数据集的折线图。
- en: 'As a continuation of the same Python REPL of Spark, run the following commands:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 作为同一Python REPL会话中Spark的延续，运行以下命令：
- en: '[PRE12]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '![Line graph](img/image_05_014.jpg)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![折线图](img/image_05_014.jpg)'
- en: Figure 13
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 图13
- en: In the preceding section, Spark DataFrames were created to get the datasets
    for the number of action movies and drama movies released over the period of the
    last 10 years. The data was collected into Python collection objects and line
    graphs were drawn in the same figure.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一部分中，创建了Spark DataFrames以获取过去10年中动作电影和剧情电影的发行数据集。数据被收集到Python集合对象中，并在同一图像中绘制了折线图。
- en: Python, in conjunction with the matplotlib library, is very rich in terms of
    methods to produce publication-quality charts and plots. Spark can be used as
    the workhorse for processing the data coming from heterogeneous sources of data,
    and the results can also be saved to a wide variety of data formats.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: Python结合matplotlib库，在生成出版质量的图表和图形方面非常丰富。Spark可以作为处理来自异构数据源的数据的工具，并且结果也可以保存为多种数据格式。
- en: Those who are exposed to the Python data analysis library **pandas** will find
    it easy to understand the material covered in this chapter because Spark DataFrames
    designed from the ground up by taking inspiration from the R DataFrame as well
    as **pandas**.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 那些熟悉Python数据分析库**pandas**的人会发现本章内容易于理解，因为Spark DataFrames的设计灵感来源于R DataFrame以及**pandas**。
- en: This chapter has covered only a few sample charts and plots that can be created
    using the **matplotlib** library. The main idea of this chapter was to help the
    reader understand the capability of using this library in conjunction with Spark,
    where Spark is doing the data processing, and **matplotlib** is doing the charting
    and plotting.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 本章仅涵盖了使用**matplotlib**库可以创建的几种示例图表和图形。本章的主要目的是帮助读者理解将此库与Spark结合使用的能力，其中Spark负责数据处理，而**matplotlib**负责图表和图形的绘制。
- en: The data file used in this chapter is read from a local filesystem. Instead
    of this, it can be read from HDFS or any other Spark-supported data source.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 本章使用的数据文件是从本地文件系统读取的。除此之外，它也可以从HDFS或任何其他Spark支持的数据源读取。
- en: When using Spark as the primary framework for data processing, the most important
    point to keep in mind is that any possible data processing is to be done by Spark,
    mainly because Spark can do data processing in the best way. Only the processed
    data is to be returned to the Spark driver program for doing the charting and
    plotting.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用Spark作为数据处理的主要框架时，最重要的是要记住，任何可能的数据处理都应该由Spark完成，主要是因为Spark能以最佳方式进行数据处理。只有经过处理的数据才会返回给Spark驱动程序，用于绘制图表和图形。
- en: References
  id: totrans-181
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'For more information please refer to following links:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 如需更多信息，请参考以下链接：
- en: '[http://www.numpy.org/](http://www.numpy.org/)'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://www.numpy.org/](http://www.numpy.org/)'
- en: '[http://www.scipy.org/](http://www.scipy.org/)'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://www.scipy.org/](http://www.scipy.org/)'
- en: '[http://matplotlib.org/](http://matplotlib.org/)'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://matplotlib.org/](http://matplotlib.org/)'
- en: '[https://movielens.org/](https://movielens.org/)'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://movielens.org/](https://movielens.org/)'
- en: '[http://grouplens.org/datasets/movielens/](http://grouplens.org/datasets/movielens/)'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://grouplens.org/datasets/movielens/](http://grouplens.org/datasets/movielens/)'
- en: '[http://pandas.pydata.org/](http://pandas.pydata.org/)'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://pandas.pydata.org/](http://pandas.pydata.org/)'
- en: Summary
  id: totrans-189
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: Processed data is used for data analysis. Data analysis requires a deep understanding
    of the processed data. Charts and plots enhance the understanding of the characteristics
    of the underlying data. In essence, for a data analysis application, data processing,
    charting, and plotting are essential. This chapter has covered the usage of Spark
    with Python, in conjunction with Python charting and plotting libraries, for developing
    data analysis applications.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 处理后的数据用于数据分析。数据分析需要对处理后的数据有深入的理解。图表和绘图增强了理解底层数据特征的能力。本质上，对于一个数据分析应用来说，数据处理、制图和绘图是必不可少的。本章涵盖了使用Python与Spark结合，以及Python制图和绘图库，来开发数据分析应用的内容。
- en: In most organizations, business requirements are driving the need to build data
    processing applications involving the real-time ingestion of data, in various
    shapes and forms, with tremendous velocity. This mandates the need to process
    a stream of incoming data to the organizational data sink. The next chapter is
    going to discuss Spark Streaming, which is a library that works on top of Spark
    and enables the processing of various types of data streams.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数组织中，业务需求推动了构建涉及实时数据摄取的数据处理应用的需求，这些数据以各种形式和形态，以极高的速度涌入。这要求对流入组织数据池的数据流进行处理。下一章将讨论Spark
    Streaming，这是一个建立在Spark之上的库，能够处理各种类型的数据流。
