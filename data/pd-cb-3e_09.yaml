- en: '9'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '9'
- en: Temporal Data Types and Algorithms
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 时间数据类型和算法
- en: 'Properly working with temporal data (i.e., dates and times) may appear straightforward,
    but, the further you dive into it, the further you realize how surprisingly complex
    it is. Here are just a few issues that come to mind:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 正确处理时间数据（即日期和时间）可能看起来很直接，但深入了解后，你会发现它比预想的复杂得多。以下是我想到的一些问题：
- en: Some users measure time in the span of years; others measure in nanoseconds
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一些用户按年计算时间；其他用户按纳秒计算
- en: Some users ignore timezones; others need to coordinate events around the world
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一些用户忽略时区问题；而其他人需要协调全球的事件
- en: Not every country has multiple timezones, even if they are wide enough to have
    them (e.g., China)
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并非每个国家都有多个时区，即使它们足够大有时区（例如：中国）
- en: Not every country observes daylight saving time; those that do cannot agree
    on when
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并非每个国家都实行夏令时；即使实行，国家之间也无法达成统一的时间
- en: In countries that observe daylight saving time, not every region participates
    (e.g., Arizona in the United States (US))
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在实行夏令时的国家，并非每个地区都会参与（例如，美国的亚利桑那州）
- en: Different operating systems and versions time differently (see also the Year
    2038 problem at [https://en.wikipedia.org/wiki/Year_2038_problem](https://en.wikipedia.org/wiki/Year_2038_problem))
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不同的操作系统和版本对时间的处理方式不同（另见[2038年问题](https://en.wikipedia.org/wiki/Year_2038_problem)）
- en: These problems are really just the tip of the iceberg, and, in spite of all
    of the potential data quality problems, temporal data is invaluable for purposes
    of monitoring, trend detection, and forecasting. Fortunately, pandas makes it
    so that you don’t need to be an expert in dates and times to draw insights from
    your data. By using the features and abstractions pandas offers, you can very
    easily cleanse and interpolate your temporal data so that you can focus less on
    the “problems” of dates and times, and more on the insights that your data has
    to offer.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 这些问题其实只是冰山一角，尽管存在众多潜在的数据质量问题，时间数据在监控、趋势检测和预测方面是无价的。幸运的是，pandas使得你不需要成为日期和时间的专家就能从数据中提取洞察。通过使用pandas提供的功能和抽象，你可以轻松清洗和插补时间数据，从而减少对日期和时间“问题”的关注，更多地关注数据所能提供的洞察。
- en: While we introduced some of the temporal types pandas has to offer back in *Chapter
    3*, *Data Types*, in the section *Temporal types – datetime*, this chapter will
    start by focusing on things that pandas offers to augment the utility of those
    types. Beyond that, we will talk about the different ways you can cleanse and
    interpolate your temporal data, before finishing the chapter with a focus on practical
    applications.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们在*第3章*《数据类型》中的*时间类型 - datetime*部分介绍了一些pandas提供的时间类型，本章将首先关注pandas提供的增强这些类型功能的内容。除此之外，我们将讨论如何清洗和插补你的时间数据，最后以实际应用为重点结束本章。
- en: 'We are going to cover the following recipes in this chapter:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将介绍以下几个内容：
- en: Timezone handling
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 时区处理
- en: DateOffsets
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 日期偏移
- en: Datetime selection
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 日期时间选择
- en: Resampling
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重采样
- en: Aggregating weekly crime and traffic accidents
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 聚合每周的犯罪和交通事故数据
- en: Calculating year over year changes in crime by category
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 按类别计算犯罪的年同比变化
- en: Accurately measuring sensor-collected events with missing values
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准确测量传感器收集的具有缺失值的事件
- en: Timezone handling
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 时区处理
- en: By far, the most common mistakes with temporal data that I come across stem
    from a misunderstanding of timezones. On the East Coast of the US where I live,
    I’ve witnessed many users try to read what they think is a date of 2024-01-01
    out of a database, yet ironically end up with a date of 2023-12-31 in their analysis.
    While that is only offset by a day, the effects of that misalignment can greatly
    skew summaries that group dates into weekly, monthly, quarterly, or yearly buckets.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 迄今为止，我遇到的关于时间数据的最常见错误，源于对时区的误解。在我居住的美国东海岸，我见过很多用户尝试从数据库中读取他们认为是2024-01-01的日期，然而讽刺的是，他们分析出来的日期却是2023-12-31。尽管这个偏差仅仅是一天，但这种不对齐的影响可能会极大地扭曲将日期按周、月、季或年分组的汇总数据。
- en: For those that have been bitten by an issue like that before, you may have already
    come to realize that the source system you were communicating with probably did
    give you a timestamp of 2024-01-01 00:00:00, presumed to be at midnight UTC. Somewhere
    along the line, an analyst on the East Coast of the US where I live may have had
    that translated into their *local* time, which is either four hours offset from
    UTC during daylight saving time, or five hours offset during standard time. As
    a result, the timestamp ended up being viewed as 2023-12-31 20:00:00 or 2023-12-31
    19:00:00 in EDT/EST, respectively, and the user may have inadvertently tried to
    convert that to a date.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 对于那些之前遇到过类似问题的人，你可能已经意识到，你所通信的源系统可能确实给你提供了一个2024-01-01 00:00:00的时间戳，假设它是午夜UTC时间。某个环节中，住在美国东海岸的分析师可能将该时间戳转换成了他们的*本地*时间，这个时间可能会因为夏令时而比UTC快四小时，或者因为标准时间而比UTC快五小时。结果，时间戳在EDT/EST时区分别被显示为2023-12-31
    20:00:00或2023-12-31 19:00:00，而用户可能无意中尝试将其转换为一个日期。
- en: To avoid these types of issues when working with temporal data, it is critical
    to understand when you are working with *timezone-aware* datetimes (i.e., those
    tied to a timezone like UTC or `America/New_York`), and *timezone-naive* objects,
    which have no timezone information attached to them. In this recipe, we will show
    you how to create and recognize both types of datetimes, while also diving deeper
    into the utilities pandas offers that let you convert between different timezones,
    and from timezone-aware to timezone-naive.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免在处理时间数据时出现这些问题，理解你何时正在处理*时区感知*日期时间（即那些与时区相关的日期时间，如UTC或`America/New_York`），以及*时区无关*对象（没有附带时区信息的对象）是至关重要的。在本章中，我们将展示如何创建和识别这两种类型的日期时间，并深入探讨pandas提供的工具，帮助你在不同的时区之间进行转换，以及从时区感知转换为时区无关。
- en: How to do it
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作
- en: 'Back in *Chapter 3*, *Data Types*, we learned how to create a `pd.Series` with
    datetime data. Let’s take a closer look at that same example:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第3章*，*数据类型*中，我们学习了如何创建带有日期时间数据的`pd.Series`。让我们更详细地看看这个例子：
- en: '[PRE0]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: These timestamps represent events that occurred at or close to midnight on days
    ranging from January 1 through January 3, 2024\. However, what these datetimes
    cannot tell us is *where* these events occurred; midnight in New York City happens
    at a different point in time than in Dubai, so it is tough to pinpoint an exact
    point in time that these events happened. Without that extra metadata, these datetimes
    are *timezone-naive*.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这些时间戳表示的是发生在2024年1月1日至1月3日之间午夜时分或接近午夜时分的事件。然而，这些日期时间无法告诉我们的是这些事件发生的*地点*；纽约市的午夜时间与迪拜的午夜时间是不同的，因此很难确定这些事件发生的确切时间。没有额外的元数据，这些日期时间是*时区无关的*。
- en: 'For programmatic confirmation that your datetimes are timezone-naive, you can
    use `pd.Series.dt.tz`, which will return `None`:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 要通过编程确认你的日期时间是时区无关的，你可以使用`pd.Series.dt.tz`，它将返回`None`：
- en: '[PRE2]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'With the `pd.Series.dt.tz_localize` method, we could assign an **Internet Assigned
    Numbers Authority (IANA**) timezone identifier to these datetimes to make them
    *timezone-aware*. For example, to specify that these events happened on the East
    Coast of the US, we could write:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`pd.Series.dt.tz_localize`方法，我们可以为这些日期时间分配一个**互联网号码分配局（IANA）**时区标识符，使它们变得*时区感知*。例如，要指定这些事件发生在美国东海岸，我们可以写：
- en: '[PRE4]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'If you try to use `pd.Series.dt.tz` on this `pd.Series`, it will report back
    that you are working with a timezone of `America/New_York`:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你尝试在这个`pd.Series`上使用`pd.Series.dt.tz`，它将报告你正在使用`America/New_York`时区：
- en: '[PRE6]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Now that our `pd.Series` is timezone-aware, the datetimes contained therein
    can be mapped to a point in time anywhere around the world. By using `pd.Series.dt.tz_convert`,
    you can easily translate these events into another timezone:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们的`pd.Series`已经具备时区感知能力，其中包含的日期时间可以映射到世界上任何地方的某个时间点。通过使用`pd.Series.dt.tz_convert`，你可以轻松地将这些事件转换为另一个时区的时间：
- en: '[PRE8]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'As a matter of practice, it is usually best to keep your datetimes attached
    to a timezone, which will mitigate the risk of being misinterpreted on a different
    date or at a different point in time. However, not all systems and databases that
    you may interact with will be able to retain this information, forcing you to
    drop it for interoperability. In case such a need arises, you could do this by
    passing `None` as an argument to `pd.Series.dt.tz_localize`:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 实际操作中，通常最好将日期时间与时区绑定，这样可以减少在不同日期或不同时间点被误解的风险。然而，并非所有系统和数据库都能够保留这些信息，这可能迫使你在进行互操作时去除时区信息。如果遇到这种需求，你可以通过将`None`作为参数传递给`pd.Series.dt.tz_localize`来实现：
- en: '[PRE10]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'If you are forced to drop the timezone from your datetime, I would strongly
    recommend storing the timezone as a string in another column in your `pd.DataFrame`
    and database:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你被迫从日期时间中去除时区信息，我强烈建议将时区作为字符串存储在`pd.DataFrame`和数据库的另一个列中：
- en: '[PRE12]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'When roundtripping data like this, you can recreate the original `pd.Series`
    by applying the value from the `timezone` column to the data in the `datetime`
    column. For added safety, the following code sample uses the combination of `pd.Series.drop_duplicates`
    with `pd.Series.squeeze` to extract the single value of `America/Los_Angeles`
    from the `timezone` column before passing it to `pd.Series.dt.tz_localize`:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种数据往返操作时，你可以通过将`timezone`列中的值应用到`datetime`列的数据来重建原始的`pd.Series`。为了增加安全性，下面的代码示例结合了`pd.Series.drop_duplicates`和`pd.Series.squeeze`，从`timezone`列中提取出`America/Los_Angeles`的单一值，然后传递给`pd.Series.dt.tz_localize`：
- en: '[PRE14]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: DateOffsets
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 日期偏移
- en: In the *Temporal types – Timedelta* recipe back in *Chapter 3*, *Data Types*,
    we introduced the `pd.Timedelta` type and mentioned how it could be used to shift
    datetimes by a finite duration, like 10 seconds or 5 days. However, a `pd.Timedelta`
    cannot be used to offset a date or datetime by say *one month* because a month
    does not always represent the same duration of time. In the Gregorian calendar,
    months can range in duration from 28–31 days. The month of February is usually
    28 days but extends to 29 days for every year that is divisible by 4, unless the
    year is divisible by 100 but not by 400.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在*时间类型 – Timedelta*的章节中（见*第3章*，*数据类型*），我们介绍了`pd.Timedelta`类型，并提到它如何用于将日期时间按有限的时间跨度进行偏移，例如10秒或5天。然而，`pd.Timedelta`不能用于偏移日期或日期时间，比如说*一个月*，因为一个月的长度并不总是相同。在公历中，月份的天数通常在28到31天之间。2月通常有28天，但对于每个能被4整除的年份，它会扩展到29天，除非该年能被100整除但不能被400整除。
- en: Thinking about these issues all of the time would be rather tedious. Fortunately,
    pandas takes care of all of the mundane details and just lets you shift dates
    according to a calendar through the use of the `pd.DateOffset` object, which we
    will explore in this recipe.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 如果总是思考这些问题会显得非常繁琐。幸运的是，pandas处理了所有这些繁琐的细节，只需使用`pd.DateOffset`对象，你就可以根据日历来移动日期，我们将在本节中进一步探讨。
- en: How to do it
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作
- en: 'To build a foundational knowledge of how this works, let’s start with a very
    simple `pd.Series` containing the first few days of 2024:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 为了构建对这个功能的基础理解，让我们从一个非常简单的`pd.Series`开始，包含2024年初几天的日期：
- en: '[PRE16]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Shifting these dates by one month would typically mean keeping the same day
    of the month, but just placing the dates in February instead of January. With
    `pd.DateOffset`, you can pass in an argument to `months=` that dictates the number
    of months you want to move the dates by; so, let’s see how it looks with an argument
    of `1`:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 将这些日期偏移一个月通常意味着保持同样的日期，只是把日期从1月移到2月。使用`pd.DateOffset`，你可以传入一个`months=`的参数，来指定你希望偏移的月份数；例如，我们可以看一下传入`1`作为参数的效果：
- en: '[PRE18]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[PRE19]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Shifting by two months would mean moving these dates from January to March.
    We shouldn’t really care that there were 31 days in January but 29 in February
    2024; the `pd.DateOffset` takes care of this for us:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 将日期偏移两个月意味着将这些日期从1月移到3月。我们不需要关心1月有31天，而2月2024年有29天；`pd.DateOffset`会为我们处理这些差异：
- en: '[PRE20]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[PRE21]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'For dates that wouldn’t exist (e.g., trying to shift January 30 to February
    30), `pd.DateOffset` will try and match to the closest date that does exist within
    the target month:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 对于不存在的日期（例如，试图将1月30日移到2月30日），`pd.DateOffset`会尝试匹配目标月份中最近的有效日期：
- en: '[PRE22]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[PRE23]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'You can also step backward through the calendar with a negative argument to
    `months=`:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以通过向`months=`传递负数的参数，倒退日期到前一个月：
- en: '[PRE24]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '[PRE25]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The `pd.DateOffset` is flexible enough to accept more than just one keyword
    argument at a time. For instance, if you wanted to offset your dates by one month,
    two days, three hours, four minutes, and five seconds, you could do that all in
    one expression:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '`pd.DateOffset` 足够灵活，可以同时接受多个关键字参数。例如，如果你想将日期偏移一个月、两天、三小时、四分钟和五秒钟，你可以在一个表达式中完成：'
- en: '[PRE26]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[PRE27]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Alongside the `pd.DateOffset` class, pandas offers you the ability to shift
    dates to the beginning or the end of a period with various classes exposed in
    the `pd.offsets` module. For instance, if you want to shift your dates to the
    end of the month, you can use `pd.offsets.MonthEnd`:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 除了 `pd.DateOffset` 类，pandas 还提供了通过 `pd.offsets` 模块中的不同类，将日期移动到某一时期的开始或结束的功能。例如，如果你想将日期移动到月末，可以使用
    `pd.offsets.MonthEnd`：
- en: '[PRE28]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '[PRE29]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '`pd.offsets.MonthBegin` will move the dates to the beginning of the next month:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '`pd.offsets.MonthBegin` 将日期移动到下个月的开始：'
- en: '[PRE30]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '[PRE31]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '`pd.offsets.SemiMonthBegin`, `pd.offsets.SemiMonthEnd`, `pd.offsets.QuarterBegin`,
    `pd.offsets.QuarterEnd`, `pd.offsets.YearBegin`, and `pd.offsets.YearEnd` all
    offer similar behavior to shift your dates to the beginning or end of different
    periods.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '`pd.offsets.SemiMonthBegin`、`pd.offsets.SemiMonthEnd`、`pd.offsets.QuarterBegin`、`pd.offsets.QuarterEnd`、`pd.offsets.YearBegin`
    和 `pd.offsets.YearEnd` 都提供类似的功能，可以将日期移动到不同时间段的开始或结束。'
- en: There’s more…
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多……
- en: The `pd.DateOffset`, by default, works against the Gregorian calendar, but different
    subclasses of this can provide more customized functionality.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，`pd.DateOffset` 是基于公历工作的，但它的不同子类可以提供更多自定义功能。
- en: 'One of the most used subclasses is the `pd.offsets.BusinessDay`, which, by
    default, only counts the standard “business days” of Monday through Friday when
    offsetting dates. To see how this works, let’s consider the day of the week each
    of our dates in `ser` fall on:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 最常用的子类之一是 `pd.offsets.BusinessDay`，默认情况下，它仅将周一到周五的标准“工作日”计入日期偏移。为了看看它是如何工作的，让我们考虑
    `ser` 中每个日期对应的星期几：
- en: '[PRE32]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '[PRE33]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Now, let’s see what happens when we add three business days to our dates:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看在给日期添加了三个工作日后会发生什么：
- en: '[PRE34]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '[PRE35]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'We can use the same `pd.Series.dt.day_name` method to check the new days of
    the week that these dates fall on:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用相同的 `pd.Series.dt.day_name` 方法来检查这些日期新的星期几：
- en: '[PRE36]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '[PRE37]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: After having added three business days, our dates that started on Monday and
    Tuesday ended up falling on the Thursday and Friday of the same week, respectively.
    The Wednesday date we started with was pushed to the Monday of the following week,
    as neither Saturday nor Sunday qualifies as a business day.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在添加了三个工作日之后，我们从周一和周二开始的日期，分别落在了同一周的周四和周五。我们从周三开始的日期被推到了下周一，因为周六和周日都不算作工作日。
- en: 'If you work with a business that has different business days from Monday to
    Friday, you could use the `pd.offsets.CustomBusinessDay` to set up your own rules
    for how offsetting should work. The argument to `weekmask=` will dictate the days
    of the week that are considered business days:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的业务在周一到周五的工作日与常规工作日不同，你可以使用 `pd.offsets.CustomBusinessDay` 来设定你自己的偏移规则。`weekmask=`
    参数将决定哪些星期几被视为工作日：
- en: '[PRE38]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '[PRE39]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'You can even add a `holidays=` argument to account for days when your business
    may be closed:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 你甚至可以添加 `holidays=` 参数来考虑你的业务可能关闭的日子：
- en: '[PRE40]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '[PRE41]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'For the Gregorian calendar, we have already seen `pd.offsets.MonthEnd` and
    `pd.offsets.MonthBegin` classes that help you move dates to the beginning or end
    of a month, respectively. Similar classes exist for you to use when attempting
    to shift dates toward the beginning or end of business months:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 对于公历，我们已经看过 `pd.offsets.MonthEnd` 和 `pd.offsets.MonthBegin` 类，分别帮助你将日期移动到一个月的开始或结束。类似的类也可以用于在尝试将日期移动到工作月的开始或结束时：
- en: '[PRE42]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '[PRE43]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Datetime selection
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 日期时间选择
- en: Back in *Chapter 2*, *Selection and Assignment*, we discussed the many robust
    ways that pandas allows you to select data from a `pd.Series` or `pd.DataFrame`
    by interacting with their associated row `pd.Index`. If you happen to create a
    `pd.Index` using datetime data, it ends up being represented as a special subclass
    called a `pd.DatetimeIndex`. This subclass overrides some functionality of the
    `pd.Index.loc` method to give you more flexible selection options tailored to
    temporal data.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第二章*，*选择和赋值*中，我们讨论了 pandas 提供的多种强大方法，帮助你通过与相关行 `pd.Index` 的交互，从 `pd.Series`
    或 `pd.DataFrame` 中选择数据。如果你创建了一个包含日期时间数据的 `pd.Index`，它将作为一种名为 `pd.DatetimeIndex`
    的特殊子类进行表示。这个子类重写了 `pd.Index.loc` 方法的一些功能，给你提供了更灵活的选择选项，专门针对时间数据。
- en: How to do it
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作
- en: '`pd.date_range` is a convenient function that helps you quickly generate a
    `pd.DatetimeIndex`. One of the ways to use this function is to specify a starting
    date with the `start=` parameter, specify a step frequency with the `freq=` parameter,
    and specify the desired length of your `pd.DatetimeIndex` with the `periods=`
    argument.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '`pd.date_range` 是一个方便的函数，帮助你快速生成 `pd.DatetimeIndex`。使用此函数的一种方式是通过 `start=`
    参数指定起始日期，使用 `freq=` 参数指定步长频率，并通过 `periods=` 参数指定所需的 `pd.DatetimeIndex` 长度。'
- en: 'For instance, to generate a `pd.DatetimeIndex` that starts on December 27,
    2023, and provides 5 days in total with 10 days between each record, you would
    write:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，要生成一个从 2023 年 12 月 27 日开始、总共提供 5 天且每条记录之间间隔 10 天的 `pd.DatetimeIndex`，你可以写：
- en: '[PRE44]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '[PRE45]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'A frequency string of `"2W"` will generate dates spaced two weeks apart. If
    the `start=` parameter is a Sunday, the dates will begin from that date exactly;
    otherwise, the next Sunday begins the sequence:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '`"2W"` 的频率字符串将生成间隔为两周的日期。如果 `start=` 参数是一个星期天，日期将从该日期开始；否则，下一个星期天将作为序列的起点：'
- en: '[PRE46]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: '[PRE47]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'You could even control the day of the week being used to anchor the dates by
    appending a suffix like `"-WED"`, which will generate dates on Wednesday instead
    of Sunday:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 你甚至可以通过添加像 `"-WED"` 这样的后缀来控制用于锚定日期的星期几，这将生成每周三的日期，而不是每周日：
- en: '[PRE48]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: '[PRE49]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'A `freq=` argument of `"WOM-3THU"` will give you the third Thursday of every
    month:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '`"WOM-3THU"` 的 `freq=` 参数将为你生成每个月的第三个星期四：'
- en: '[PRE50]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: '[PRE51]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'The first and fifteenth day of each month can be generated with an argument
    of `"SMS"`:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 每月的第一天和第十五天可以通过 `"SMS"` 参数生成：
- en: '[PRE52]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: '[PRE53]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: As you can see, there are countless frequency strings that can be used to describe
    what pandas refers to as **date offsets**. For a more complete listing, be sure
    to reference the pandas documentation at [https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#dateoffset-objects](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#dateoffset-objects).
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，有无数的频率字符串可以用来描述 pandas 所称的 **日期偏移**。欲获取更完整的列表，务必参考 pandas 文档：[https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#dateoffset-objects](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#dateoffset-objects)。
- en: 'Each element of the `pd.DatetimeIndex` is actually a `pd.Timestamp`. When using
    this for selection from a `pd.Series` or `pd.DataFrame`, users may at first be
    tempted to write something like the following to select all records up to and
    including a date like 2024-01-18:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '`pd.DatetimeIndex` 的每个元素实际上是一个 `pd.Timestamp`。当从 `pd.Series` 或 `pd.DataFrame`
    中进行选择时，用户可能最初会倾向于写出如下的代码，以选择像 2024-01-18 这样的日期及其之前的所有记录：'
- en: '[PRE54]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: '[PRE55]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Similarly, users may be tempted to write the following to select a range of
    dates:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，用户可能会倾向于写出如下代码来选择一个日期范围：
- en: '[PRE56]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: '[PRE57]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'However, these methods of selecting from a `pd.DatetimeIndex` are rather verbose.
    For convenience, pandas lets you pass in strings to represent the desired dates,
    instead of `pd.Timestamp` instances:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，从 `pd.DatetimeIndex` 中进行选择的方法较为冗长。为了方便，pandas 允许你传入字符串来表示所需的日期，而不是使用 `pd.Timestamp`
    实例：
- en: '[PRE58]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: '[PRE59]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'You also are not required to specify the entire date in YYYY-MM-DD format.
    For instance, if you wanted to select all of the dates that fall in February 2024,
    you could just pass the string `2024-02` to your `pd.Series.loc` call:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 你也不需要指定完整的日期（YYYY-MM-DD 格式）。例如，如果你想选择所有发生在 2024 年 2 月的日期，你只需将字符串 `2024-02` 传递给
    `pd.Series.loc` 调用：
- en: '[PRE60]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: '[PRE61]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Slicing will be intelligent enough to recognize this pattern, making it easy
    to select all of the records in both February and March:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 切片操作足够智能，能够识别这种模式，便于选择二月和三月中的所有记录：
- en: '[PRE62]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: '[PRE63]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'You can take this abstraction a step further and select an entire year:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以将这种抽象化再进一步，选择整个年份：
- en: '[PRE64]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: '[PRE65]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: There’s more…
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多……
- en: 'A `pd.DatetimeIndex` can also be associated with a timezone by providing a
    `tz=` argument:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以通过提供 `tz=` 参数，将 `pd.DatetimeIndex` 与时区相关联：
- en: '[PRE66]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: '[PRE67]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'When using strings to select from a timezone-aware `pd.DatetimeIndex`, be aware
    that pandas will implicitly convert your string argument into the timezone of
    the `pd.DatetimeIndex`. For instance, the following code will only select one
    element from our data:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用字符串从带有时区感知的 `pd.DatetimeIndex` 中进行选择时，需注意 pandas 会隐式地将你的字符串参数转换为 `pd.DatetimeIndex`
    的时区。例如，下面的代码将只从我们的数据中选择一个元素：
- en: '[PRE68]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: '[PRE69]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'Whereas the following code will correctly select both elements:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 而下面的代码将正确地选择两个元素：
- en: '[PRE70]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: '[PRE71]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: These both work in spite of the fact that our dates are five hours offset from
    UTC, and our string makes no indication of the expected timezone. In this way,
    pandas makes it very easy to express selection from a `pd.DatetimeIndex`, whether
    it is timezone-aware or timezone-naive.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们的日期与UTC相差五小时，且字符串中没有指明期望的时区，这两种方法仍然有效。这样，pandas使得从`pd.DatetimeIndex`中进行选择变得非常简单，无论它是时区感知的还是时区非感知的。
- en: Resampling
  id: totrans-148
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 重采样
- en: Back in *Chapter 8*, *Group By*, we went in-depth into the group by functionality
    that pandas has to offer. A Group By allows you to *split* your data based on
    unique value combinations in your dataset, *apply* an algorithm to those splits,
    and combine the results back together.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第8章*，*分组操作*中，我们深入探讨了pandas提供的分组功能。通过分组，你可以根据数据集中唯一值的组合来*拆分*数据，*应用*算法到这些拆分上，并将结果重新合并。
- en: A *resample* is very similar to a Group By, with the only difference happening
    during the *split* phase. Instead of generating groups from unique value combinations,
    a resample lets you take datetimes and group them into increments like *every
    5 seconds* or *every 10 minutes*.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '*重采样*与分组操作非常相似，唯一的区别发生在*拆分*阶段。与根据唯一值组合生成分组不同，重采样允许你将日期时间数据按增量进行分组，例如*每5秒*或*每10分钟*。'
- en: How to do it
  id: totrans-151
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现
- en: 'Let’s once again reach for the `pd.date_range` function we were introduced
    to back in the *Datetime selection* recipe, but this time, we are going to generate
    a `pd.DatetimeIndex` with a frequency of seconds instead of days:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再次使用在*日期时间选择*示例中介绍过的`pd.date_range`函数，不过这次我们将生成一个以秒为频率的`pd.DatetimeIndex`，而不是以天为频率：
- en: '[PRE72]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: '[PRE73]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'If viewing this data every second was deemed too granular, `pd.Series.resample`
    can be used to *downsample* the data into a different increment, like *every 3
    seconds*. Resampling also requires the use of an aggregation function to dictate
    what happens to all records that fall within each increment; for simplicity, we
    can start with summation:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 如果每秒查看数据被认为过于细致，可以使用`pd.Series.resample`对数据进行*降采样*，以获得不同的增量，例如*每3秒*。重采样还需要使用聚合函数来指示在每个增量内所有记录的处理方式；为了简便起见，我们可以从求和开始：
- en: '[PRE74]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: '[PRE75]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: In this particular case, `resample` creates buckets using the ranges of `[00:00:00-00:00:03)`,
    `[00:00:03-00:00:06)`, `[00:00:06-00:00:09)`, and `[00:00:09-00:00:12)`. For each
    of those intervals, the left square bracket indicates that the interval is closed
    on the left side (i.e., it includes those values). By contrast, the right parentheses
    indicate an open interval that does not include the value.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个特定的例子中，`resample`会使用`[00:00:00-00:00:03)`、`[00:00:03-00:00:06)`、`[00:00:06-00:00:09)`和`[00:00:09-00:00:12)`这些区间来创建桶。对于每一个区间，左方括号表示该区间在左侧是闭合的（即包括这些值）。相反，右侧的圆括号表示该区间是开放的，不包括该值。
- en: 'Technically speaking, all of these intervals created by the resample with a
    frequency of `"3s"` are “left-closed” by default, but the `closed=` argument can
    be used to change that behavior, effectively producing intervals with the values
    of `(23:59:57-00:00:00]`, `(00:00:00-00:00:03]`, `(00:00:03-00:00:06]`, and `(00:00:06-00:00:09]`:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 从技术角度来说，所有这些通过`"3s"`频率重采样创建的区间默认是“左闭合”的，但可以通过`closed=`参数改变这种行为，从而生成如`(23:59:57-00:00:00]`、`(00:00:00-00:00:03]`、`(00:00:03-00:00:06]`和`(00:00:06-00:00:09]`这样的区间：
- en: '[PRE76]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: '[PRE77]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'With the frequency of `"3s"`, the left value of the interval is used as the
    value in the resulting row index. That behavior can also be changed through the
    use of the `label=` argument:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 对于`"3s"`频率，区间的左值会作为结果行索引中的值。这个行为也可以通过使用`label=`参数来改变：
- en: '[PRE78]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: '[PRE79]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'One last caveat you may want to be aware of is that the default values for
    the `closed=` and `label=` arguments depend upon the frequency that you have chosen.
    Our frequency of `"3s"` creates left-closed intervals, and uses the left interval
    value in the row index. However, if we had chosen a frequency that is oriented
    toward the end of a period, like `ME` or `YE` (month-end and year-end, respectively),
    pandas will instead produce right-closed intervals and use the right label:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一个需要注意的陷阱是，`closed=`和`label=`参数的默认值依赖于你选择的频率。我们选择的`"3s"`频率创建的是左闭合区间，并在行索引中使用左侧区间值。然而，如果我们选择了一个面向周期结束的频率，比如`ME`或`YE`（月末和年末），pandas将会生成右闭合区间，并使用右侧标签：
- en: '[PRE80]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: '[PRE81]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: 'While we are on the topic of downsampling, let’s take a look at a different
    frequency, like days (`"D"`). At this level, `pd.Series.resample` can be a convenient
    way to aggregate daily events into weekly buckets. To see how this works, let’s
    just look at the first 10 days of 2024:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们在讨论下采样，让我们来看一种不同的频率，比如天数（`"D"`）。在这个级别，`pd.Series.resample`可以方便地将每日事件聚合到每周时间段中。为了看看这怎么运作，我们只需要查看
    2024 年的前 10 天：
- en: '[PRE82]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: '[PRE83]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: 'Without looking up which day of the week each of these falls on, we can use
    `pd.DatetimeIndex.dt.day_name()` to ground ourselves:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在不查找每个日期对应星期几的情况下，我们可以使用`pd.DatetimeIndex.dt.day_name()`来帮助我们定位：
- en: '[PRE84]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: '[PRE85]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: 'By default, resampling into weekly buckets will create periods that *end* on
    a Sunday:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，重采样为每周的时间段将会创建以周日为*结束*的周期：
- en: '[PRE86]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: '[PRE87]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: 'You are free, however, to pick any day of the week for your period to end on.
    In the US, considering Saturday to be the end of the week is arguably more common
    than Sunday:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，你可以自由选择一周中的任何一天作为周期的结束日。在美国，认为周六是周末的结束日，实际上比周日更常见：
- en: '[PRE88]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: '[PRE89]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: 'Though, you can pick any day of the week:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，你也可以选择一周中的任何一天：
- en: '[PRE90]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: '[PRE91]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: Now that we have covered the topic of *downsampling* (i.e., going from a more
    granular to a less granular frequency), let’s take a look at going in the opposite
    direction with the process of *upsampling*. Our data shows events that happen
    every day, but what if we wanted to create a time series that measured events
    every 12 hours?
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经讲解了*下采样*（即从更精细的频率转为更粗略的频率）的主题，接下来我们来看看相反的方向——*上采样*过程。我们的数据展示了每天发生的事件，但如果我们想创建一个每
    12 小时记录事件的时间序列，该怎么办呢？
- en: 'Fortunately, the API to achieve this is not all that different. You can still
    use `pd.Series.resample` to start, but will subsequently want to chain in a call
    to `pandas.core.resample.Resampler.asfreq`:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，实现这一目标的 API 并不会有太大区别。你仍然可以使用`pd.Series.resample`开始，但接下来需要链式调用`pandas.core.resample.Resampler.asfreq`：
- en: '[PRE92]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: '[PRE93]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: Intervals generated during the *upsample*, which have no associated activity,
    are assigned a missing value. Left alone, there is likely not a ton of value to
    upsampling like this. However, pandas offers a few ways to fill in this missing
    data.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在*上采样*过程中生成的时间间隔，如果没有对应的活动，会被分配为缺失值。如果不做处理，像这样的上采样可能没有太大价值。然而，pandas 提供了几种填充这些缺失数据的方法。
- en: The first approach to handle missing data may be to forward fill or backward
    fill values, so that missing values are just replaced with whatever record came
    `preceding or following`, respectively.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 处理缺失数据的第一种方法可能是向前填充或向后填充值，这样缺失值就会分别被前一个或后一个记录替代。
- en: 'A forward fill will generate values of `[0, 0, 1, 1, 2, 2, ...]`:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 向前填充会生成`[0, 0, 1, 1, 2, 2, ...]`的值：
- en: '[PRE94]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: '[PRE95]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: 'Whereas a backward fill yields `[0, 1, 1, 2, 2, 3, ...]`:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 而向后填充则会得到`[0, 1, 1, 2, 2, 3, ...]`：
- en: '[PRE96]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE96]'
- en: '[PRE97]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE97]'
- en: 'An arguably more robust solution can be had in the form of *interpolation*,
    where the values preceding and following a missing value can be used to mathematically
    guess the missing value. The default interpolation will be *linear*, essentially
    taking the average of the value before and after each missing value:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 一个更强健的解决方案是使用*插值*，其中可以利用缺失值前后的值来通过数学方式推测缺失的值。默认的插值方法是*线性插值*，本质上是取缺失值前后的平均值：
- en: '[PRE98]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE98]'
- en: '[PRE99]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE99]'
- en: There’s more…
  id: totrans-198
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多内容……
- en: In the introduction to this recipe, we mentioned that a resample was similar
    to a Group By. In fact, you could rewrite a resample using `pd.DataFrame.groupby`
    with a `pd.Grouper` argument.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节的介绍中，我们提到过，重采样类似于分组（Group By）。实际上，你可以通过`pd.DataFrame.groupby`和`pd.Grouper`参数重写一个重采样操作。
- en: 'Let’s once again look at a `pd.Series` with 10 records occurring every second:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再次看一个包含 10 条记录的`pd.Series`，这些记录每秒发生一次：
- en: '[PRE100]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE100]'
- en: '[PRE101]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE101]'
- en: 'A resample into three-second increments looks as follows:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 三秒增量的重采样结果如下所示：
- en: '[PRE102]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE102]'
- en: '[PRE103]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE103]'
- en: 'This would be rewritten to get the same result by passing in `"3s"` to the
    `freq=` argument of a `pd.Grouper`:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将 `"3s"` 传递给`pd.Grouper`的`freq=`参数，重写后的代码可以得到相同的结果：
- en: '[PRE104]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE104]'
- en: '[PRE105]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE105]'
- en: There is no requirement that you use `pd.DataFrame.resample`, and, in fact,
    you will find that the `pd.Grouper` approach works better when you must also group
    by non-datetime values. We will see this in action in the *Calculating year-over-year
    changes in crime by category* recipe later in this chapter.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 并不要求你必须使用`pd.DataFrame.resample`，实际上，当你还需要按非日期时间值进行分组时，你会发现`pd.Grouper`方法效果更好。我们将在本章稍后的*按类别计算犯罪的年同比变化*示例中看到这一点。
- en: Aggregating weekly crime and traffic accidents
  id: totrans-210
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 聚合每周的犯罪和交通事故数据
- en: So far in this chapter, we have taken a basic tour of pandas’ offerings for
    dealing with temporal data. Starting with small sample datasets has made it easy
    to visually inspect the output of our operations, but we are now at the point
    where we can start focusing on applications to “real world” datasets.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经对 pandas 在处理时间数据方面的功能进行了基本的了解。从小型样本数据集开始，使我们能够轻松地检查操作的输出，但现在我们已经进入了可以开始关注如何应用于“真实世界”数据集的阶段。
- en: The Denver crime dataset is huge, with over 460,000 rows each marked with a
    datetime of when the crime was reported. As you will see in this recipe, we can
    use pandas to easily resample these events and ask questions like *How many crimes
    were reported in a given week*?.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 丹佛市的犯罪数据集庞大，共有超过46万行，每行都标注了犯罪报告的日期时间。正如你将看到的，在这个示例中，我们可以使用 pandas 轻松地重新采样这些事件，并提出类似*在某一周内报告了多少起犯罪*的问题。
- en: How to do it
  id: totrans-213
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现
- en: 'To start, let’s read in the crime dataset, setting our index as the `REPORTED_DATE`.
    This dataset was saved using pandas extension types, so there is no need to specify
    the `dtype_backend=` argument:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们读取犯罪数据集，并将索引设置为`REPORTED_DATE`。该数据集是使用 pandas 扩展类型保存的，因此无需指定`dtype_backend=`参数：
- en: '[PRE106]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE106]'
- en: '[PRE107]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE107]'
- en: 'To count the number of crimes per week, we need to form a group for each week,
    which we know we can do with `pd.DataFrame.resample`. Chaining a call to the `.size`
    method will count the number of crimes within each week for us:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 为了计算每周的犯罪数量，我们需要按周形成一个分组，我们知道可以通过`pd.DataFrame.resample`来实现。链式调用`.size`方法将计算每周的犯罪数：
- en: '[PRE108]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE108]'
- en: '[PRE109]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE109]'
- en: 'We now have the weekly crime count as a `pd.Series` with the new index incrementing
    one week at a time. There are a few things that happen by default that are very
    important to understand. Sunday is chosen as the last day of the week and is also
    the date used to label each element in the resulting `pd.Series`. For instance,
    the first index value, January 8, 2012, is a Sunday. There were 877 crimes committed
    during that week ending on the 8th. The week of Monday, January 9, to Sunday,
    January 15, recorded 1,071 crimes. Let’s do some sanity checks and ensure that
    our resampling is doing this:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们得到了每周犯罪数量的`pd.Series`，新索引每次递增一周。有几个默认发生的事情非常重要，需要理解。星期日被选为每周的最后一天，并且也是在生成的`pd.Series`中用于标记每个元素的日期。例如，第一个索引值2012年1月8日是一个星期日。那一周（截至1月8日）共发生了877起犯罪。而1月9日星期一至1月15日星期日的一周，记录了1,071起犯罪。让我们进行一些合理性检查，确保我们的重新采样做到了这一点：
- en: '[PRE110]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE110]'
- en: '[PRE111]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE111]'
- en: '[PRE112]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE112]'
- en: '[PRE113]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE113]'
- en: 'To get an overall understanding of the trend, it would be helpful to create
    a plot from our resampled data:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 为了全面了解趋势，从重新采样的数据中创建一个图表会很有帮助：
- en: '[PRE114]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE114]'
- en: '![](img/B31091_09_01.png)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B31091_09_01.png)'
- en: 'The Denver crime dataset has all crime and traffic accidents together in one
    table and separates them through the binary columns `IS_CRIME` and `IS_TRAFFIC`.
    Using `pd.DataFrame.resample`, we can select just these two columns and summarize
    them over a given period. For a quarterly summary, you would write:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 丹佛市的犯罪数据集将所有犯罪和交通事故放在一个表中，并通过二进制列`IS_CRIME`和`IS_TRAFFIC`进行区分。通过`pd.DataFrame.resample`，我们可以仅选择这两列，并对其进行特定时期的汇总。对于季度汇总，你可以写成：
- en: '[PRE115]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE115]'
- en: '[PRE116]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE116]'
- en: 'Once again, a line plot to understand the trend may be more helpful:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 再次来说，使用折线图来了解趋势可能会更加有帮助：
- en: '[PRE117]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE117]'
- en: '![](img/B31091_09_02.png)'
  id: totrans-233
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B31091_09_02.png)'
- en: Calculating year-over-year changes in crime by category
  id: totrans-234
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 按类别计算犯罪的年变化
- en: Often, users want to know *How much did this change year over year?* or *…quarter
    over quarter?*. In spite of the frequency with which these questions are asked,
    writing algorithms to try and answer them can be rather complex and time-intensive.
    Fortunately, pandas gives you much of this functionality out of the box, trivializing
    much of the effort.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 用户经常想知道*这种变化年复一年有多少？*或者*…季度与季度之间的变化是多少？*。尽管这些问题经常被提及，但编写算法来回答这些问题可能相当复杂且耗时。幸运的是，pandas
    为你提供了许多现成的功能，简化了很多工作。
- en: To try and make things more complicated, in this recipe, we are going to ask
    the question of *how much did it change by category*? Adding *by category* into
    the equation will prevent us from directly using `pd.DataFrame.resample`, but
    as you will see, pandas can still very easily help you answer these detailed types
    of questions.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让事情更复杂一些，在这个示例中，我们将提出*按类别变化有多少*的问题？将*按类别*纳入计算将使我们无法直接使用`pd.DataFrame.resample`，但正如你将看到的，pandas
    仍然可以非常轻松地帮助你回答这类详细的问题。
- en: How to do it
  id: totrans-237
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现
- en: 'Let’s read in the crime dataset, but this time, we are not going to set the
    `REPORTED_DATE` as our index:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们加载犯罪数据集，但这次我们不会将`REPORTED_DATE`作为索引：
- en: '[PRE118]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE118]'
- en: '[PRE119]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE119]'
- en: By now, you should be comfortable enough with reshaping to answer questions
    like, *How many crimes happened in a given year?*. But what if we wanted to drill
    into that analysis and decide how it changed within each `OFFENSE_CATEGORY_ID`?
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 到现在为止，你应该已经对数据重塑感到足够熟悉，可以回答类似于*某一年发生了多少起犯罪？*这样的问题了。但如果我们想进一步分析，了解每个`OFFENSE_CATEGORY_ID`内的变化情况该怎么做呢？
- en: 'Since `pd.DataFrame.resample` just works with a `pd.DatetimeIndex`, it cannot
    be used to help us group by `OFFENSE_CATEGORY_ID` and `REPORTED_DATE`. However,
    the combination of `pd.DataFrame.groupby` with a `pd.Grouper` argument can help
    us express this:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 由于`pd.DataFrame.resample`仅适用于`pd.DatetimeIndex`，因此无法帮助我们按`OFFENSE_CATEGORY_ID`和`REPORTED_DATE`进行分组。不过，`pd.DataFrame.groupby`与`pd.Grouper`参数的组合可以帮助我们实现这一点：
- en: '[PRE120]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE120]'
- en: '[PRE121]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE121]'
- en: As a technical aside, the `observed=True` argument suppresses a warning about
    using categorical data types in a Group By in the pandas 2.x release; future readers
    may not need to specify this argument, as it will become the default.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 顺便提一下，`observed=True`参数可以抑制在pandas 2.x版本中使用分类数据类型进行分组时的警告；未来的读者可能不需要指定此参数，因为它将成为默认设置。
- en: 'To add in the “year over year” component, we can try out the `pd.Series.pct_change`
    method, which expresses each record as a percentage of the one directly preceding
    it:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 为了加入“同比”部分，我们可以尝试使用`pd.Series.pct_change`方法，它将每条记录表示为直接前一条记录的百分比：
- en: '[PRE122]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE122]'
- en: '[PRE123]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE123]'
- en: Unfortunately, this is not giving us exactly what we want. If you look closely
    at the first `yoy_change` value for all-other-crimes, it shows 0.183541\. However,
    this value is taken by dividing 1999 by 1689, with 1689 coming from the aggravated-assault
    category. By default, `pd.Series.pct_change` is not doing anything intelligent
    – it just divides the current row by the former.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，这并没有给我们准确的结果。如果你仔细观察所有其他犯罪类别的第一个`yoy_change`值，它显示为0.183541。然而，这个值是通过将1999除以1689得到的，1689来自加重攻击犯罪类别。默认情况下，`pd.Series.pct_change`并没有做任何智能的操作——它只是将当前行与前一行相除。
- en: 'Fortunately, there is a way to fix that, by once again using a Group By. Because
    our `OFFENSE_CATEGORY_ID` is the first index level, we can use a second Group
    By with `level=0` and call the `.pct_change` method on that. This will prevent
    us from accidentally comparing `all-other-crimes` to `aggravated-assault`:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，有一种方法可以解决这个问题，再次使用分组操作。因为我们的`OFFENSE_CATEGORY_ID`是第一个索引级别，所以我们可以用第二个分组操作，设置`level=0`并在此基础上调用`.pct_change`方法。这样可以避免我们错误地将`all-other-crimes`与`aggravated-assault`进行比较：
- en: '[PRE124]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE124]'
- en: '[PRE125]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE125]'
- en: For a more visual representation, we may want to plot out the total crime and
    year-over-year change side by side for all of our different groups, building off
    of what we learned about visualizations back in *Chapter 6*, *Visualization*.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得更直观的展示，我们可能希望将所有不同分组的总犯罪数和年同比变化并排绘制，基于我们在*第6章*，*数据可视化*中学到的知识进行构建。
- en: 'For brevity and to save some visual space, we are just going to plot a few
    crime types:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简洁并节省视觉空间，我们只会绘制几种犯罪类型：
- en: '[PRE126]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE126]'
- en: '![](img/B31091_09_03.png)'
  id: totrans-256
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B31091_09_03.png)'
- en: Accurately measuring sensor-collected events with missing values
  id: totrans-257
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准确衡量带有缺失值的传感器收集事件
- en: Missing data can have an immense impact on your data analysis, but it may not
    always be clear when and to what extent. With detailed and high-volume transactions,
    it won’t always be immediately obvious that a dataset is incomplete. Extra attention
    must be paid to measure and appropriately impute missing transactions; otherwise,
    any aggregations performed on such datasets may show an incomplete or even entirely
    wrong picture of what happened.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 缺失数据可能对数据分析产生巨大影响，但有时并不容易判断缺失数据的发生时间和程度。在详细且大量的交易数据中，数据集是否完整可能并不明显。必须格外注意衡量和恰当地填补缺失的交易数据；否则，对这样的数据集进行任何聚合可能会展示出不完整甚至完全错误的情况。
- en: For this recipe, we are going to use the *Smart Green Infrastructure Monitoring
    Sensors - Historical* dataset provided by the Chicago Data Portal. This dataset
    contains a collection of sensors that measured different environmental factors
    in the city of Chicago, like water runoff and temperature. In theory, the sensors
    should have constantly run and reported back values, but in practice, they were
    prone to intermittent outages that resulted in a loss of data.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个案例，我们将使用芝加哥数据门户提供的*智能绿色基础设施监测传感器 - 历史数据*数据集。该数据集包含了测量芝加哥市不同环境因素的传感器集合，如水流量和温度。理论上，传感器应该持续运行并反馈数值，但实际上，它们易于发生间歇性故障，导致数据丢失。
- en: How to do it
  id: totrans-260
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作
- en: 'While the Chicago Data Portal provides the source data as a CSV file spanning
    the years 2017 and 2018, for this book, we are going to work with a curated Parquet
    file that only covers the months of June 2017 through October 2017\. This alone
    provides almost 5 million rows of data, which we can load with a simple `pd.read_parquet`
    call:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然芝加哥数据门户提供了覆盖2017年和2018年的CSV格式源数据，但本书中我们将使用一个精心整理的Parquet文件，它仅覆盖了2017年6月到2017年10月的几个月数据。仅此数据就有近500万行记录，我们可以通过简单的`pd.read_parquet`调用加载它：
- en: '[PRE127]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE127]'
- en: '[PRE128]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE128]'
- en: 'The `Measurement Time` column should contain the datetime data for when each
    event occurred, but upon closer inspection, you will see that pandas did not recognize
    this as a datetime type:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: '`Measurement Time`列应包含每个事件发生时的日期时间数据，但经过仔细检查后，你会发现pandas并未将其识别为日期时间类型：'
- en: '[PRE129]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE129]'
- en: '[PRE130]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE130]'
- en: 'As such, the first step in exploring our data will be to convert this to the
    real datetime type using `pd.to_datetime`. While it isn’t clear from the data
    itself, the Chicago Data Portal documentation notes that these values are local
    to the Chicago timezone, which we can use `pd.Series.dt.tz_localize` to set:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，探索数据的第一步将是使用`pd.to_datetime`将其转换为实际的日期时间类型。虽然从数据本身不容易看出，但芝加哥数据门户文档指出，这些值是芝加哥时区的本地时间，我们可以使用`pd.Series.dt.tz_localize`来进行时区设置：
- en: '[PRE131]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE131]'
- en: '[PRE132]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE132]'
- en: 'As mentioned, this dataset collects feedback from sensors that measure different
    environmental factors, like water runoff and temperature. Inspecting the `Measurement
    Type` and `Units` column should give us a better idea of what we are looking at:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，该数据集收集了来自传感器的反馈，这些传感器测量了不同的环境因素，如水流量和温度。检查`Measurement Type`和`Units`列应能让我们更好地理解我们正在查看的数据：
- en: '[PRE133]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE133]'
- en: '[PRE134]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE134]'
- en: 'Because the different sensors produce different measurements for different
    types of data, we must be careful not to compare more than one sensor at a time.
    For this analysis, we are going to just focus on the `TM1 Temp Sensor`, which
    only measures the temperature using a unit of millivolts. Additionally, we are
    going to single in on one `Data Stream ID`, which the Chicago Data Portal documents
    as:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 由于不同的传感器对于不同类型的数据会产生不同的测量结果，我们必须小心，避免一次比较多个传感器。为了这次分析，我们将只专注于`TM1 Temp Sensor`，它仅使用毫伏作为单位来测量温度。此外，我们将只关注一个`Data
    Stream ID`，在芝加哥数据门户中文档中描述为：
- en: An identifier for the measurement type and location. All records with the same
    value should be comparable.
  id: totrans-274
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 一个用于标识测量类型和位置的标识符。所有具有相同值的记录应该是可以比较的。
- en: '[PRE135]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE135]'
- en: '[PRE136]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE136]'
- en: 'For this analysis, we are going to only look at `Data Stream ID` `39176`. After
    filtering, we are also going to set `Measurement Time` as our row index and sort
    it:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 对于此次分析，我们将只查看`Data Stream ID` `39176`。过滤后，我们还将设置`Measurement Time`为行索引并进行排序：
- en: '[PRE137]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE137]'
- en: '[PRE138]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE138]'
- en: 'The `Measurement Value` column contains the actual millivolts reading from
    the sensors. Let’s start by resampling to the daily level and using mean aggregation
    on that column to try and understand our data at a higher level:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: '`Measurement Value`列包含传感器的实际毫伏数值。我们可以通过将数据重采样到每日级别，并对该列进行均值聚合，来尝试更高层次地理解我们的数据：'
- en: '[PRE139]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE139]'
- en: '![](img/B31091_09_04.png)'
  id: totrans-282
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B31091_09_04.png)'
- en: Almost immediately, we can see some issues with our data. Most notably, there
    are two gaps where the lines break toward the end of July and middle of October,
    which are almost assuredly records that were not collected due to the sensors
    being down.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 几乎立刻，我们就能看到数据中的一些问题。最显著的是，7月底和10月中旬有两个间隙，几乎可以确定这些记录是由于传感器停机而未收集的。
- en: 'Let’s try narrowing our date range so that we can more clearly see what days
    are missing from our dataset:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试缩小日期范围，以便更清楚地看到数据集中缺失的日期：
- en: '[PRE140]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE140]'
- en: '[PRE141]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE141]'
- en: 'As you can see, we have no data collected at all for July 31, 2017\. To fix
    this, we can simply chain in a call to `pd.Series.interpolate`, which will fill
    in the missing days with the average of the values directly preceding and following:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，我们在2017年7月31日完全没有收集到任何数据。为了解决这个问题，我们可以简单地调用`pd.Series.interpolate`，它将使用前后值的平均数填补缺失的日期：
- en: '[PRE142]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE142]'
- en: '![](img/B31091_09_05.png)'
  id: totrans-289
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B31091_09_05.png)'
- en: Voila! Now, we no longer have any gaps in our data collection, yielding a visually
    appealing, fully drawn-in visual.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 完成了！现在，我们的数据收集没有任何间隙，呈现出一个视觉上令人愉悦、完整的图表。
- en: There’s more…
  id: totrans-291
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多…
- en: How you handle missing data also depends on the aggregation function that you
    are using. In this recipe, the mean is a relatively forgiving function; missing
    transactions can be masked by the fact that they do not materially change the
    average being produced.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 你如何处理缺失数据也取决于你使用的聚合函数。在这个例子中，平均数是一个相对宽容的函数；缺失的交易可以通过它们不显著改变生成的平均数来掩盖。
- en: 'However, if we were looking to measure the daily summation of our readings,
    we would still have some more work to do. For starters, let’s see what a daily-resampled
    summation of these readings looks like:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果我们要测量每天的读数总和，仍然需要做一些额外的工作。首先，让我们看看这些读数的每日重采样总和是怎样的：
- en: '[PRE143]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE143]'
- en: '![](img/B31091_09_06.png)'
  id: totrans-295
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B31091_09_06.png)'
- en: 'Things look more dire than in the case of wanting the average. We still see
    huge dips in late July and October, which we know go back to a lack of data. However,
    when we dive into the data at the end of July that we saw before, the summation
    will reveal a few more interesting things about our data:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 情况比想要计算平均值时更加严峻。我们仍然看到7月和10月末有巨大的跌幅，这显然是数据缺失造成的。然而，当我们深入研究之前看到的7月末数据时，求和将揭示一些关于数据的更有趣的内容：
- en: '[PRE144]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE144]'
- en: '[PRE145]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE145]'
- en: It wasn’t just the day of July 31 when we had an outage. The mean aggregation
    we did before masked the fact that the sensors went down sometime after 15:50:46
    on July 30 and did not come back online until 15:21:33 on August 1 – an outage
    of almost 2 full days.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 不仅仅是7月31日那天我们发生了停机。我们之前做的平均聚合掩盖了一个事实，即传感器在7月30日15:50:46之后出现故障，并且直到8月1日15:21:33才恢复在线——几乎停机了整整两天。
- en: 'Another interesting thing to try and measure is the expected frequency with
    which our data should be populated. From an initial glance at our data, it appears
    as if each minute should supply a data point, but if you try to measure how many
    events were collected each hour, you will see a different story:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个有趣的事情是尝试测量我们的数据应该以什么频率被填充。初步查看我们的数据时，似乎每分钟都应该提供一个数据点，但如果你尝试测量每小时收集到多少事件，你会看到另一个结果：
- en: '[PRE146]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE146]'
- en: '![](img/B31091_09_07.png)'
  id: totrans-302
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B31091_09_07.png)'
- en: 'Many of the hourly intervals appear to have close to 60 events collected, although
    surprisingly, only 1 hour actually collected a full 60:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 很多小时间隔看起来收集了接近60个事件，尽管令人惊讶的是，只有1小时实际上收集了满满的60个事件。
- en: '[PRE147]'
  id: totrans-304
  prefs: []
  type: TYPE_PRE
  zh: '[PRE147]'
- en: '[PRE148]'
  id: totrans-305
  prefs: []
  type: TYPE_PRE
  zh: '[PRE148]'
- en: 'To fix this, let’s try once again to resample our data by the minute and interpolate
    where results are missing:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，我们再次尝试按分钟重采样数据，并在结果缺失的地方进行插值：
- en: '[PRE149]'
  id: totrans-307
  prefs: []
  type: TYPE_PRE
  zh: '[PRE149]'
- en: '[PRE150]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE150]'
- en: There is a slight caveat users should be aware of with the summation of missing
    values. By default, pandas will sum all missing values to `0` instead of a missing
    value. In the case of our resample to minutes, the data point at 2017-10-30 23:57:00
    had no values to sum, so pandas returned the value of `0` instead of a missing
    value indicator.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 用户需要注意的是，缺失值的总和存在一个小的注意事项。默认情况下，pandas会将所有缺失值求和为`0`，而不是缺失值。在我们按分钟重采样的情况下，2017年10月30日23:57:00的数据点没有值可供求和，因此pandas返回了`0`，而不是缺失值指示符。
- en: 'We need a missing value indicator for the resample to work. Luckily, we can
    still get this by providing the `sum` method with a `min_count=` argument that
    is `1` (or greater), essentially establishing how many non-missing values must
    be seen to yield a non-missing result:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要一个缺失值指示符来使重采样工作顺利进行。幸运的是，我们仍然可以通过给`sum`方法提供`min_count=`参数并设置为`1`（或更大值）来实现这一点，实际上是设定了必须看到多少个非缺失值才能得到一个非缺失的结果：
- en: '[PRE151]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE151]'
- en: '[PRE152]'
  id: totrans-312
  prefs: []
  type: TYPE_PRE
  zh: '[PRE152]'
- en: As you can see, the value for 2017-10-30 23:57:00 now shows as `3293`, which
    was interpolated by taking both the preceding and following values.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，2017年10月30日23:57:00的值现在显示为`3293`，这是通过取前后的值进行插值得到的。
- en: 'With that out of the way, let’s now confirm that we always see 60 events per
    hour:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 完成这些之后，让我们确认我们每小时总是收集到60个事件：
- en: '[PRE153]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE153]'
- en: '![](img/B31091_09_08.png)'
  id: totrans-316
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B31091_09_08.png)'
- en: 'That check looks good, so now, we can try to downsample again back to the daily
    level and see what the overall summation trend looks like:'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 这个检查看起来很好，现在，我们可以尝试再次将数据降采样到日级别，看看整体求和趋势是什么样的：
- en: '[PRE154]'
  id: totrans-318
  prefs: []
  type: TYPE_PRE
  zh: '[PRE154]'
- en: '![](img/B31091_09_09.png)'
  id: totrans-319
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B31091_09_09.png)'
- en: This is a drastically different graph from what we started with. We not only
    removed the extreme outliers from influencing the *y*-axis of our graph but we
    can also see a general lift in the lower bounds of values. In our original graph,
    the lower bound of the total millivolts measured was commonly in the range of
    3.5–4 million per day, but now, our lower bound appears somewhere around 4.74
    million.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 这张图表与我们最初的图表大不相同。我们不仅去除了极端异常值对图表 *y* 轴的影响，还可以看到数值下限的普遍上升。在我们最初的图表中，总计的毫伏值下限通常在每天
    350 万到 400 万之间，但现在，我们的下限大约在 474 万左右。
- en: In effect, by paying attention to and handling missing values in our time series
    data, we were able to yield many different insights from our dataset. In relatively
    few lines of code, pandas has helped us clearly and concisely get our data to
    a much better place than where we started.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，通过关注和处理我们时间序列数据中的缺失值，我们能够从数据集中获得许多不同的见解。在相对少量的代码行中，pandas 帮助我们清晰简洁地将数据处理到比开始时更好的状态。
- en: Join our community on Discord
  id: totrans-322
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们在 Discord 的社区
- en: 'Join our community’s Discord space for discussions with the authors and other
    readers:'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 加入我们社区的 Discord 空间，与作者和其他读者进行讨论：
- en: '[https://packt.link/pandas](https://packt.link/pandas)'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/pandas](https://packt.link/pandas)'
- en: '![](img/QR_Code5040900042138312.png)'
  id: totrans-325
  prefs: []
  type: TYPE_IMG
  zh: '![](img/QR_Code5040900042138312.png)'
- en: Leave a Review!
  id: totrans-326
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 留下您的评价！
- en: Thank you for purchasing this book from Packt Publishing—we hope you enjoy it!
    Your feedback is invaluable and helps us improve and grow. Once you’ve completed
    reading it, please take a moment to leave an Amazon review; it will only take
    a minute, but it makes a big difference for readers like you.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢您从 Packt Publishing 购买本书——我们希望您喜欢它！您的反馈对我们非常宝贵，能够帮助我们改进和成长。在阅读完本书后，请抽空在 Amazon
    上留下评价；这只需一分钟，但对像您这样的读者来说意义重大。
- en: Scan the QR code below to receive a free ebook of your choice.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 扫描下面的二维码，获得你选择的免费电子书。
- en: '[https://packt.link/NzOWQ](Chapter_9.xhtml)'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/NzOWQ](Chapter_9.xhtml)'
- en: '![](img/QR_Code1474021820358918656.png)'
  id: totrans-330
  prefs: []
  type: TYPE_IMG
  zh: '![](img/QR_Code1474021820358918656.png)'
