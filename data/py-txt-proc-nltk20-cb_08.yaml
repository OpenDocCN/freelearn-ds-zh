- en: Chapter 8. Distributed Processing and Handling Large Datasets
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第8章 分布式处理和大型数据集处理
- en: 'In this chapter, we will cover:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍：
- en: Distributed tagging with execnet
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用execnet进行分布式标记
- en: Distributed chunking with execnet
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用execnet进行分布式分块
- en: Parallel list processing with execnet
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用execnet进行并行列表处理
- en: Storing a frequency distribution in Redis
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Redis中存储频率分布
- en: Storing a conditional frequency distribution in Redis
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Redis中存储条件频率分布
- en: Storing an ordered dictionary in Redis
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Redis中存储有序字典
- en: Distributed word scoring with Redis and execnet
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Redis和execnet进行分布式单词评分
- en: Introduction
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简介
- en: NLTK is great for in-memory single-processor natural language processing. However,
    there are times when you have a lot of data to process and want to take advantage
    of multiple CPUs, multi-core CPUs, and even multiple computers. Or perhaps you
    want to store frequencies and probabilities in a persistent, shared database so
    multiple processes can access it simultaneously. For the first case, we'll be
    using execnet to do parallel and distributed processing with NLTK. For the second
    case, you'll learn how to use the Redis data structure server/database to store
    frequency distributions and more.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: NLTK非常适合内存中的单处理器自然语言处理。然而，有时你有很多数据要处理，并想利用多个CPU、多核CPU甚至多台计算机。或者你可能想在一个持久、共享的数据库中存储频率和概率，以便多个进程可以同时访问它。对于第一种情况，我们将使用execnet进行NLTK的并行和分布式处理。对于第二种情况，你将学习如何使用Redis数据结构服务器/数据库来存储频率分布等。
- en: Distributed tagging with execnet
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用execnet进行分布式标记
- en: '**Execnet** is a distributed execution library for python. It allows you to
    create gateways and channels for remote code execution. A **gateway** is a connection
    from the calling process to a remote environment. The remote environment can be
    a local subprocess or an SSH connection to a remote node. A **channel** is created
    from a gateway and handles communication between the channel creator and the remote
    code.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**Execnet**是一个用于Python的分布式执行库。它允许你创建用于远程代码执行的网关和通道。**网关**是从调用进程到远程环境的连接。远程环境可以是本地子进程或到远程节点的SSH连接。**通道**是从网关创建的，用于处理通道创建者与远程代码之间的通信。'
- en: Since many NLTK processes require 100 percent CPU utilization during computation,
    execnet is an ideal way to distribute that computation for maximum resource usage.
    You can create one gateway per CPU core, and it doesn't matter whether the cores
    are in your local computer or spread across remote machines. In many situations,
    you only need to have the trained objects and data on a single machine, and can
    send the objects and data to the remote nodes as needed.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 由于许多NLTK过程在计算期间需要100%的CPU利用率，execnet是分配这种计算以实现最大资源使用的一个理想方式。你可以为每个CPU核心创建一个网关，无论这些核心是在你的本地计算机上还是分布在远程机器上。在许多情况下，你只需要在单个机器上拥有训练好的对象和数据，并在需要时将对象和数据发送到远程节点。
- en: Getting ready
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: You'll need to install execnet for this to work. It should be as simple as `sudo
    pip install execnet` or `sudo easy_install execnet`. The current version of execnet,
    as of this writing, is `1.0.8`. The execnet homepage, which has API documentation
    and examples, is at [http://codespeak.net/execnet/](http://codespeak.net/execnet/).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要安装execnet才能使它工作。这应该像`sudo pip install execnet`或`sudo easy_install execnet`一样简单。截至本文写作时，execnet的当前版本是`1.0.8`。execnet的主页，其中包含API文档和示例，位于[http://codespeak.net/execnet/](http://codespeak.net/execnet/)。
- en: How to do it...
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现...
- en: We start by importing the required modules, as well as an additional module
    `remote_tag.py` that will be explained in the next section. We also need to import
    `pickle` so we can serialize the tagger. Execnet does not natively know how to
    deal with complex objects such as a part-of-speech tagger, so we must dump the
    tagger to a string using `pickle.dumps()`. We'll use the default tagger that's
    used by the `nltk.tag.pos_tag()` function, but you could load and dump any pre-trained
    part-of-speech tagger as long as it implements the `TaggerI` interface.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先导入所需的模块，以及将在下一节中解释的附加模块`remote_tag.py`。我们还需要导入`pickle`，这样我们就可以序列化标记器。Execnet本身不知道如何处理诸如词性标记器之类的复杂对象，因此我们必须使用`pickle.dumps()`将标记器转储为字符串。我们将使用`nltk.tag.pos_tag()`函数使用的默认标记器，但你也可以加载并转储任何实现了`TaggerI`接口的预训练词性标记器。
- en: Once we have a serialized tagger, we start execnet by making a gateway with
    `execnet.makegateway()`. The default gateway creates a Python *subprocess*, and
    we can call the `remote_exec()` method with the `remote_tag` module to create
    a `channel`. With an open channel, we send over the serialized tagger and then
    the first tokenized sentence of the `treebank` corpus.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了序列化的标记器，我们就通过使用 `execnet.makegateway()` 创建网关来启动 execnet。默认网关创建一个 Python
    *子进程*，我们可以使用 `remote_exec()` 方法并传递 `remote_tag` 模块来创建一个 `channel`。有了开放的通道，我们发送序列化的标记器和
    `treebank` 语料库的第一个标记句子。
- en: Note
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: You don't have to do any special serialization of simple types such as lists
    and tuples, since execnet already knows how to handle serializing the built-in
    types.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 对于列表和元组等简单类型，您无需进行任何特殊的序列化，因为 execnet 已经知道如何处理内置类型的序列化。
- en: Now if we call `channel.receive()`, we get back a tagged sentence that is equivalent
    to the first tagged sentence in the `treebank` corpus, so we know the tagging
    worked. We end by exiting the gateway, which closes the channel and kills the
    subprocess.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 现在如果我们调用 `channel.receive()`，我们会得到一个标记的句子，它与 `treebank` 语料库中的第一个标记句子等效，因此我们知道标记是成功的。我们通过退出网关结束，这会关闭通道并杀死子进程。
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Visually, the communication process looks like this:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 从视觉上看，通信过程看起来像这样：
- en: '![How to do it...](img/3609OS_08_01.jpg)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![如何做...](img/3609OS_08_01.jpg)'
- en: How it works...
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'The gateway''s `remote_exec()` method takes a single argument that can be one
    of the following three types:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 网关的 `remote_exec()` 方法接受一个参数，该参数可以是以下三种类型之一：
- en: A string of code to execute remotely.
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要在远程执行的代码字符串。
- en: The name of a **pure** **function** that will be serialized and executed remotely.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将要序列化和远程执行的一个**纯**函数的名称。
- en: The name of a **pure** **module** whose source will be executed remotely.
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个**纯**模块的名称，其源将在远程执行。
- en: 'We use the third option with the `remote_tag.py` module, which is defined as
    follows:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 `remote_tag.py` 模块的第三个选项，该模块定义如下：
- en: '[PRE1]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: A pure module is a module that is self-contained. It can only access Python
    modules that are available where it executes, and does not have access to any
    variables or states that exist wherever the gateway is initially created. To detect
    that the module is being executed by `execnet`, you can look at the `__name__`
    variable. If it's equal to `'__channelexec__'`, then it is being used to create
    a remote channel. This is similar to doing `if __name__ == '__main__'` to check
    if a module is being executed on the command line.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 一个纯模块是一个自包含的模块。它只能访问它在执行时可以访问的 Python 模块，并且无法访问网关最初创建位置存在的任何变量或状态。要检测模块是否由 `execnet`
    执行，您可以查看 `__name__` 变量。如果它等于 `'__channelexec__'`，则它被用于创建远程通道。这与执行 `if __name__
    == '__main__'` 来检查模块是否在命令行上执行类似。
- en: The first thing we do is call `channel.receive()` to get the serialized `tagger`,
    which we load using `pickle.loads()`. You may notice that `channel` is not imported
    anywhere—that's because it is included in the global namespace of the module.
    Any module that `execnet` executes remotely has access to the `channel` variable
    in order to communicate with the `channel` creator.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先调用 `channel.receive()` 来获取序列化的 `tagger`，然后使用 `pickle.loads()` 加载它。您可能会注意到
    `channel` 没有在任何地方导入——这是因为它包含在模块的全局命名空间中。任何 `execnet` 在远程执行的模块都可以访问 `channel` 变量，以便与
    `channel` 创建者通信。
- en: Once we have the `tagger`, we iteratively `tag()` each tokenized sentence that
    we receive from the channel. This allows us to tag as many sentences as the sender
    wants to send, as iteration will not stop until the `channel` is closed. What
    we've essentially created is a compute node for part-of-speech tagging that dedicates
    100 percent of its resources to tagging whatever sentences it receives. As long
    as the `channel` remains open, the node is available for processing.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了 `tagger`，我们就迭代地对从通道接收到的每个标记句子进行 `tag()` 操作。这允许我们标记发送者想要发送的任意数量的句子，因为迭代不会停止，直到
    `channel` 关闭。我们实际上创建的是一个用于词性标注的计算节点，该节点将100%的资源用于标注它接收到的任何句子。只要 `channel` 保持开放，节点就可供处理。
- en: There's more...
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 更多...
- en: This is a simple example that opens a single gateway and channel. But execnet
    can do a lot more, such as opening multiple channels to increase parallel processing,
    as well as opening gateways to remote hosts over SSH to do distributed processing.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个简单的示例，它打开一个网关和一个通道。但 execnet 可以做更多的事情，例如打开多个通道以增加并行处理，以及通过 SSH 打开远程主机的网关以进行分布式处理。
- en: Multiple channels
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 多个通道
- en: We can create multiple channels, one per gateway, to make the processing more
    parallel. Each gateway creates a new subprocess (or remote interpreter if using
    an SSH gateway) and we use one channel per gateway for communication. Once we've
    created two channels, we can combine them using the `MultiChannel` class, which
    allows us to iterate over the channels, and make a receive queue to receive messages
    from each channel.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以创建多个通道，每个网关一个，以使处理更加并行。每个网关创建一个新的子进程（如果使用SSH网关，则为远程解释器），我们使用每个网关的一个通道进行通信。一旦我们创建了两个通道，我们可以使用`MultiChannel`类将它们组合起来，这允许我们遍历通道，并创建一个接收队列以接收来自每个通道的消息。
- en: After creating each channel and sending the tagger, we cycle through the channels
    to send an even number of sentences to each channel for tagging. Then we collect
    all the responses from the `queue`. A call to `queue.get()` will return a 2-tuple
    of `(channel, message)` in case you need to know which channel the message came
    from.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建每个通道并发送标记器之后，我们遍历通道，为每个通道发送相同数量的句子进行标记。然后我们收集`queue`中的所有响应。调用`queue.get()`将返回一个包含`(channel,
    message)`的2元组，以防你需要知道消息来自哪个通道。
- en: Tip
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: If you don't want to wait forever, you can also pass a `timeout` keyword argument
    with the maximum number of seconds you want to wait, as in `queue.get(timeout=4)`.
    This can be a good way to handle network errors.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你不想永远等待，你也可以传递一个`timeout`关键字参数，指定你想要等待的最大秒数，例如`queue.get(timeout=4)`。这可以是一种处理网络错误的好方法。
- en: 'Once all the tagged sentences have been collected, we can exit the gateways.
    Here''s the code:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦收集到所有标记的句子，我们就可以退出网关。以下是代码：
- en: '[PRE2]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Local versus remote gateways
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本地与远程网关
- en: The default gateway spec is `popen`, which creates a Python subprocess on the
    local machine. This means `execnet.makegateway()` is equivalent to `execnet.makegateway('popen')`.
    If you have passwordless SSH access to a remote machine, then you can create a
    remote gateway using `execnet.makegateway('ssh=remotehost')` where `remotehost`
    should be the hostname of the machine. A SSH gateway spawns a new Python interpreter
    for executing the code remotely. As long as the code you're using for remote execution
    is **pure**, you only need a Python interpreter on the remote machine.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 默认网关规范是`popen`，它在本地机器上创建一个Python子进程。这意味着`execnet.makegateway()`等价于`execnet.makegateway('popen')`。如果你有对远程机器的无密码SSH访问权限，那么你可以使用`execnet.makegateway('ssh=remotehost')`创建一个远程网关，其中`remotehost`应该是机器的主机名。SSH网关为远程执行代码启动一个新的Python解释器。只要你在远程执行中使用的代码是**纯**的，你只需要在远程机器上有一个Python解释器。
- en: Channels work exactly the same no matter what kind of gateway is used; the only
    difference will be communication time. This means you can mix and match local
    subprocesses with remote interpreters to distribute your computations across many
    machines in a network. There are many more details on gateways in the API documentation
    at [http://codespeak.net/execnet/basics.html](http://codespeak.net/execnet/basics.html).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 无论使用哪种网关，通道的工作方式都完全相同；唯一的区别将是通信时间。这意味着你可以将本地子进程与远程解释器混合匹配，以在网络中的多台机器上分配你的计算。有关网关的更多详细信息，请参阅API文档中的[http://codespeak.net/execnet/basics.html](http://codespeak.net/execnet/basics.html)。
- en: See also
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: Part-of-speech tagging and taggers are covered in detail in [Chapter 4](ch04.html
    "Chapter 4. Part-of-Speech Tagging"), *Part-of-Speech Tagging*. In the next recipe,
    we'll use `execnet` to do distributed chunk extraction.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第4章](ch04.html "第4章。词性标注")“词性标注”中详细介绍了词性标注和标记器。在下一个菜谱中，我们将使用`execnet`进行分布式分块提取。
- en: Distributed chunking with execnet
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用execnet进行分布式分块
- en: In this recipe, we'll do chunking and tagging over an `execnet` gateway. This
    will be very similar to the tagging in the previous recipe, but we'll be sending
    two objects instead of one, and we will be receiving a `Tree` instead of a list,
    which requires pickling and unpickling for serialization.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将对`execnet`网关进行分块和标记。这将与前一个菜谱中的标记非常相似，但我们将会发送两个对象而不是一个，并且我们将接收一个`Tree`而不是一个列表，这需要序列化和反序列化。
- en: Getting ready
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: As in the previous recipe, you must have `execnet` installed.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 如前一个菜谱中所述，你必须安装`execnet`。
- en: How to do it...
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: The setup code is very similar to the last recipe, and we'll use the same pickled
    `tagger` as well. First we'll pickle the default `chunker` used by `nltk.chunk.ne_chunk()`,
    though any chunker would do. Next, we make a gateway for the `remote_chunk` module,
    get a `channel`, and send the pickled `tagger` and `chunker` over. Then we receive
    back a pickled `Tree`, which we can unpickle and inspect to see the result. Finally,
    we exit the gateway.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 设置代码与上一个菜谱非常相似，我们也将使用相同的序列化（pickled）`tagger`。首先，我们将序列化`nltk.chunk.ne_chunk()`使用的默认`chunker`，尽管任何chunker都可以。接下来，我们为`remote_chunk`模块创建一个网关，获取一个`channel`，并将序列化的`tagger`和`chunker`发送过去。然后我们接收回一个序列化的`Tree`，我们可以反序列化并检查结果。最后，我们退出网关。
- en: '[PRE3]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The communication this time is slightly different.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这次通信略有不同。
- en: '![How to do it...](img/3609OS_08_02.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![如何做...](img/3609OS_08_02.jpg)'
- en: How it works...
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The `remote_chunk.py` module is just a little bit more complicated than the
    `remote_tag.py` module from the previous recipe. In addition to receiving a pickled
    `tagger`, it also expects to receive a pickled `chunker` that implements the `ChunkerI`
    interface. Once it has both a `tagger` and a `chunker`, it expects to receive
    any number of tokenized sentences, which it tags and parses into a `Tree`. This
    `tree` is then pickled and sent back over the `channel`.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '`remote_chunk.py`模块比上一个菜谱中的`remote_tag.py`模块稍微复杂一些。除了接收一个序列化的`tagger`，它还期望接收一个实现了`ChunkerI`接口的序列化`chunker`。一旦它有了`tagger`和`chunker`，它期望接收任意数量的分词句子，它会对这些句子进行标记并将它们解析成一个`Tree`。然后这个`tree`会被序列化并通过`channel`发送回去。'
- en: '[PRE4]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Note
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The `Tree` must be pickled because it is not a simple built-in type.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 由于`Tree`不是一个简单的内置类型，因此必须将其序列化（pickled）。
- en: There's more...
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: Note that the `remote_chunk` module is pure. Its only external dependency is
    the `pickle` (or `cPickle`) module, which is part of the Python standard library.
    It doesn't need to import any NLTK modules in order to use the `tagger` or `chunker`,
    because all the necessary data is pickled and sent over the `channel`. As long
    as you structure your remote code like this, with no external dependencies, you
    only need NLTK to be installed on a single machine—the one that starts the gateway
    and sends the objects over the channel.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，`remote_chunk`模块是纯的。它的唯一外部依赖是`pickle`（或`cPickle`）模块，它是Python标准库的一部分。它不需要导入任何NLTK模块来使用`tagger`或`chunker`，因为所有必要的数据都是序列化并通过`channel`发送的。只要你的远程代码结构是这样的，没有外部依赖，你只需要在单个机器上安装NLTK——即启动网关并通过`channel`发送对象的机器。
- en: Python subprocesses
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Python子进程
- en: If you look at your task/system monitor (or `top` in `*nix`) while running the
    `execnet` code, you may notice a few extra python Processes. Every gateway spawns
    a new, self-contained, *shared-nothing* Python interpreter process, which is killed
    when you call the `exit()` method. Unlike with threads, there is no shared memory
    to worry about, and no global interpreter lock to slow things down. All you have
    are separate communicating processes. This is true whether the processes are local
    or remote. Instead of locking and synchronization, all you have to worry about
    is the order in which the messages are sent and received.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 当你在运行`execnet`代码时查看你的任务/系统监视器（或在`*nix`中的`top`），你可能会注意到一些额外的Python进程。每个网关都会产生一个新的、自包含的、*无共享资源*的Python解释器进程，当你调用`exit()`方法时，该进程会被终止。与线程不同，这里没有共享内存需要担心，也没有全局解释器锁来减慢速度。你所拥有的只是独立的通信进程。这无论是对于本地进程还是远程进程都是成立的。你不需要担心锁定和同步，你只需要关注消息的发送和接收顺序。
- en: See also
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: The previous recipe explains `execnet` gateways and channels in detail. In the
    next recipe, we'll use `execnet` to process a list in parallel.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的菜谱详细解释了`execnet`网关和通道。在下一个菜谱中，我们将使用`execnet`并行处理一个列表。
- en: Parallel list processing with execnet
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用execnet进行并行列表处理
- en: This recipe presents a pattern for using `execnet` to process a list in parallel.
    It's a function pattern for mapping each element in the list to a new value, using
    `execnet` to do the mapping in parallel.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这个菜谱展示了使用`execnet`并行处理列表的模式。这是一个函数模式，用于将列表中的每个元素映射到一个新值，使用`execnet`并行执行映射。
- en: How to do it...
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: First, we need to decide exactly what we want to do. In this example, we'll
    just double integers, but we could do any pure computation. Following is the module
    `remote_double.py`, which will be executed by `execnet`. It receives a 2-tuple
    of `(i, arg)`, assumes `arg` is a number, and sends back `(i, arg*2)`. The need
    for `i` will be explained in the next section.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要决定我们确切想要做什么。在这个例子中，我们将只是将整数加倍，但我们可以进行任何纯计算。以下是由`execnet`执行的模块`remote_double.py`，它接收一个`(i,
    arg)`的2元组，假设`arg`是一个数字，并发送回`(i, arg*2)`。`i`的需求将在下一节中解释。
- en: '[PRE5]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: To use this module to double every element in a list, we import the `plists`
    module (explained in the next section) and call `plists.map()` with the `remote_double`
    module, and a list of integers to double.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用此模块将列表中的每个元素加倍，我们需要导入`plists`模块（下一节将解释），并使用`remote_double`模块和要加倍的整数列表调用`plists.map()`。
- en: '[PRE6]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Communication between channels is very simple, as shown in the following diagram:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 通道之间的通信非常简单，如下面的图所示：
- en: '![How to do it...](img/3609OS_08_03.jpg)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![如何做...](img/3609OS_08_03.jpg)'
- en: How it works...
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The `map()` function is defined in `plists.py`. It takes a pure module, a list
    of arguments, and an optional list of 2-tuples consisting of `(spec, count)`.
    The default `specs` are `[('popen', 2)]` , which means we'll open two local gateways
    and channels. Once these channels are opened, we put them into an `itertools`
    cycle, which creates an infinite iterator that cycles back to the beginning once
    it hits the end.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '`map()`函数定义在`plists.py`中。它接受一个纯模块、一个参数列表以及一个可选的由`(spec, count)`组成的2元组列表。默认的`specs`是`[(''popen'',
    2)]`，这意味着我们将打开两个本地网关和通道。一旦这些通道打开，我们将它们放入一个`itertools`循环中，这创建了一个无限迭代器，一旦到达末尾就会回到开始。'
- en: Now we can send each argument in `args` to a `channel` for processing, and since
    the channels are cycled, each channel gets an almost even distribution of arguments.
    This is where `i` comes in—we don't know in what order we'll get the results back,
    so `i`, as the index of each `arg` in the list, is passed to the channel and back
    so we can combine the results in the original order. We then wait for results
    with a `MultiChannel` receive queue and insert them into a pre-filled list that's
    the same length as the original `args`. Once we have all the expected results,
    we can exit the gateways and return the results.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以将`args`中的每个参数发送到`channel`进行处理，由于通道是循环的，每个通道都会获得几乎均匀分布的参数。这就是`i`的作用——我们不知道结果将以什么顺序返回，所以将作为列表中每个`arg`的索引的`i`传递到通道并返回，以便我们可以按原始顺序组合结果。然后我们使用`MultiChannel`接收队列等待结果，并将它们插入一个与原始`args`长度相同的预填充列表中。一旦我们有了所有预期的结果，我们就可以退出网关并返回结果。
- en: '[PRE7]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: There's more...
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'You can increase the parallelization by modifying the specs, as follows:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过修改规格来增加并行化，如下所示：
- en: '[PRE8]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: However, more parallelization does not necessarily mean faster processing. It
    depends on the available resources, and the more gateways and channels you have
    open, the more overhead is required. Ideally there should be one gateway and channel
    per CPU core.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，更多的并行化并不一定意味着更快的处理速度。它取决于可用的资源，并且你打开的网关和通道越多，所需的开销就越大。理想情况下，每个CPU核心应该有一个网关和通道。
- en: You can use `plists.map()` with any pure module as long as it receives and sends
    back 2-tuples where `i` is the first element. This pattern is most useful when
    you have a bunch of numbers to crunch, and want to process them as quickly as
    possible.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 只要接收并返回包含`i`作为第一个元素的2元组，您就可以使用`plists.map()`与任何纯模块一起使用。这种模式在您有一堆数字要处理，并希望尽可能快速地处理它们时最有用。
- en: See also
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: The previous recipes cover `execnet` features in greater detail.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的菜谱更详细地介绍了`execnet`的功能。
- en: Storing a frequency distribution in Redis
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Redis中存储频率分布
- en: The `nltk.probability.FreqDist` class is used in many classes throughout NLTK
    for storing and managing frequency distributions. It's quite useful, but it's
    all in-memory, and doesn't provide a way to persist the data. A single `FreqDist`
    is also not accessible to multiple processes. We can change all that by building
    a `FreqDist` on top of Redis.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: NLTK中的许多类都使用了`nltk.probability.FreqDist`类来存储和管理频率分布。它非常有用，但它全部是在内存中，并且不提供持久化数据的方式。单个`FreqDist`也无法被多个进程访问。我们可以通过在Redis之上构建一个`FreqDist`来改变这一切。
- en: Redis is a **data** **structure** **server** that is one of the more popular
    *NoSQL* databases. Among other things, it provides a network accessible database
    for storing dictionaries (also known as *hash maps*). Building a `FreqDist` interface
    to a Redis hash map will allow us to create a persistent `FreqDist` that is accessible
    to multiple local and remote processes at the same time.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: Redis 是一个 **数据结构** **服务器**，是更受欢迎的 *NoSQL* 数据库之一。除了其他功能外，它提供了一个网络可访问的数据库来存储字典（也称为
    *哈希表*）。通过将 `FreqDist` 接口构建到 Redis 哈希表中，我们可以创建一个持久化的 `FreqDist`，它同时可供多个本地和远程进程访问。
- en: Note
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Most Redis operations are **atomic**, so it's even possible to have multiple
    processes write to the `FreqDist` concurrently.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数 Redis 操作都是 **原子性** 的，因此甚至可以同时有多个进程向 `FreqDist` 写入。
- en: Getting ready
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: For this and subsequent recipes, we need to install both `Redis` and `redis-py`.
    A quick start install guide for Redis is available at [http://code.google.com/p/redis/wiki/QuickStart](http://code.google.com/p/redis/wiki/QuickStart).
    To use hash maps, you should install at least version `2.0.0` (the latest version
    as of this writing).
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个和随后的食谱，我们需要安装 `Redis` 和 `redis-py`。Redis 的快速入门安装指南可在 [http://code.google.com/p/redis/wiki/QuickStart](http://code.google.com/p/redis/wiki/QuickStart)
    找到。为了使用哈希表，你应该安装至少版本 `2.0.0`（截至本文写作时的最新版本）。
- en: The `Redis` Python driver `redis-py` can be installed using `pip install redis`
    or `easy_install redis`. Ensure you install at least version `2.0.0` to use hash
    maps. The `redis-py` homepage is at [http://github.com/andymccurdy/redis-py/](http://github.com/andymccurdy/redis-py/).
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用 `pip install redis` 或 `easy_install redis` 安装 `Redis` Python 驱动 `redis-py`。确保你安装至少版本
    `2.0.0` 以使用哈希表。`redis-py` 的主页是 [http://github.com/andymccurdy/redis-py/](http://github.com/andymccurdy/redis-py/)。
- en: Once both are installed and a `redis-server` process is running, you're ready
    to go. Let's assume `redis-server` is running on `localhost` on port `6379` (the
    default host and port).
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦安装完成并且 `redis-server` 进程正在运行，你就可以开始了。假设 `redis-server` 在 `localhost` 的 `6379`
    端口上运行（默认的主机和端口）。
- en: How to do it...
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现...
- en: 'The `FreqDist` class extends the built-in `dict` class, which makes a `FreqDist`
    an enhanced dictionary. The `FreqDist` class provides two additional key methods:
    `inc()` and `N()`. The `inc()` method takes a single `sample` argument for the
    key, along with an optional `count` keyword argument that defaults to `1`, and
    increments the value at `sample` by `count`. `N()` returns the number of sample
    outcomes, which is the sum of all the values in the frequency distribution.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '`FreqDist` 类扩展了内置的 `dict` 类，这使得 `FreqDist` 成为一个增强的字典。`FreqDist` 类提供了两个额外的键方法：`inc()`
    和 `N()`。`inc()` 方法接受一个 `sample` 参数作为键，以及一个可选的 `count` 关键字参数，默认为 `1`，并将 `sample`
    的值增加 `count`。`N()` 返回样本结果的数量，这是频率分布中所有值的总和。'
- en: We can create an API-compatible class on top of Redis by extending a `RedisHashMap`
    (that will be explained in the next section), then implementing the `inc()` and
    `N()` methods. Since the `FreqDist` only stores integers, we also override a few
    other methods to ensure values are always integers. This `RedisHashFreqDist` (defined
    in `redisprob.py`) uses the `hincrby` command for the `inc()` method to increment
    the `sample` value by `count`, and sums all the values in the hash map for the
    `N()` method.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过扩展 `RedisHashMap`（将在下一节中解释）并在其上创建一个 API 兼容的类，然后实现 `inc()` 和 `N()` 方法来在
    Redis 上创建一个 API 兼容的类。由于 `FreqDist` 只存储整数，我们还覆盖了一些其他方法，以确保值始终是整数。这个 `RedisHashFreqDist`（在
    `redisprob.py` 中定义）使用 `hincrby` 命令来为 `inc()` 方法增加 `sample` 值，并使用 `N()` 方法对哈希表中的所有值求和。
- en: '[PRE9]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: We can use this class just like a `FreqDist`. To instantiate it, we must pass
    a `Redis` connection and the `name` of our hash map. The `name` should be a unique
    reference to this particular `FreqDist` so that it doesn't clash with any other
    keys in `Redis`.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将这个类当作一个 `FreqDist` 来使用。要实例化它，我们必须传递一个 `Redis` 连接和我们的哈希表的 `name`。`name`
    应该是这个特定 `FreqDist` 的唯一引用，这样就不会与 `Redis` 中的任何其他键冲突。
- en: '[PRE10]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Note
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The name of the hash map and the sample keys will be encoded to replace whitespace
    and `&` characters with `_`. This is because the `Redis` protocol uses these characters
    for communication. It's best if the name and keys don't include whitespace to
    begin with.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 哈希表的名字和样本键将被编码以替换空格和 `&` 字符为 `_`。这是因为 `Redis` 协议使用这些字符进行通信。最好一开始就不在名字和键中包含空格。
- en: How it works...
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'Most of the work is done in the `RedisHashMap` class, found in `rediscollections.py`,
    which extends `collections.MutableMapping`, then overrides all methods that require
    Redis-specific commands. Here''s an outline of each method that uses a specific
    `Redis` command:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 大部分工作都是在 `rediscollections.py` 中的 `RedisHashMap` 类中完成的，它扩展了 `collections.MutableMapping`，然后覆盖了所有需要
    Redis 特定命令的方法。以下是使用特定 `Redis` 命令的每个方法的概述：
- en: '`__len__()`: Uses the `hlen` command to get the number of elements in the hash
    map'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`__len__()`: 使用 `hlen` 命令获取哈希表中的元素数量'
- en: '`__contains__()`: Uses the `hexists` command to check if an element exists
    in the hash map'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`__contains__()`: 使用 `hexists` 命令检查哈希表中是否存在一个元素'
- en: '`__getitem__()`: Uses the `hget` command to get a value from the hash map'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`__getitem__()`: 使用 `hget` 命令从哈希表中获取一个值'
- en: '`__setitem__()`: Uses the `hset` command to set a value in the hash map'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`__setitem__()`: 使用 `hset` 命令在哈希表中设置一个值'
- en: '`__delitem__()`: Uses the `hdel` command to remove a value from the hash map'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`__delitem__()`: 使用 `hdel` 命令从哈希表中删除一个值'
- en: '`keys()`: Uses the `hkeys` command to get all the keys in the hash map'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`keys()`: 使用 `hkeys` 命令获取哈希表中的所有键'
- en: '`values()`: Uses the `hvals` command to get all the values in the hash map'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`values()`: 使用 `hvals` 命令获取哈希表中的所有值'
- en: '`items()`: Uses the `hgetall` command to get a dictionary containing all the
    keys and values in the hash map'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`items()`: 使用 `hgetall` 命令获取包含哈希表中所有键和值的字典'
- en: '`clear()`: Uses the `delete` command to remove the entire hash map from `Redis`'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clear()`: 使用 `delete` 命令从 `Redis` 中删除整个哈希表'
- en: Note
  id: totrans-117
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Extending `collections.MutableMapping` provides a number of other `dict` compatible
    methods based on the previous methods, such as `update()` and `setdefault()`,
    so we don't have to implement them ourselves.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 扩展 `collections.MutableMapping` 提供了基于先前方法的许多其他 `dict` 兼容方法，例如 `update()` 和 `setdefault()`，因此我们不必自己实现它们。
- en: The initialization used for the `RedisHashFreqDist` is actually implemented
    here, and requires a `Redis` connection and a name for the hash map. The connection
    and name are both stored internally to use with all the subsequent commands. As
    mentioned before, whitespace is replaced by underscore in the name and all keys,
    for compatibility with the Redis network protocol.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 用于 `RedisHashFreqDist` 的初始化实际上在这里实现，需要一个 `Redis` 连接和一个哈希表名称。连接和名称都存储在内部，以便与所有后续命令一起使用。如前所述，名称和所有键中的空白字符被下划线替换，以与
    Redis 网络协议兼容。
- en: '[PRE11]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: There's more...
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: The `RedisHashMap` can be used by itself as a persistent key-value dictionary.
    However, while the hash map can support a large number of keys and arbitrary string
    values, its storage structure is more optimal for integer values and smaller numbers
    of keys. However, don't let that stop you from taking full advantage of Redis.
    It's very fast (for a network server) and does its best to efficiently encode
    whatever data you throw at it.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '`RedisHashMap` 可以作为一个持久化的键值字典单独使用。然而，虽然哈希表可以支持大量的键和任意字符串值，但其存储结构对于整数值和较小的键数量更为优化。但是，不要因此阻碍你充分利用
    Redis。它非常快（对于网络服务器来说），并且尽力高效地编码你抛给它的任何数据。'
- en: Note
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: While Redis is quite fast for a network database, it will be significantly slower
    than the in-memory `FreqDist`. There's no way around this, but while you sacrifice
    speed, you gain persistence and the ability to do concurrent processing.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 Redis 对于网络数据库来说相当快，但它将比内存中的 `FreqDist` 慢得多。这是无法避免的，但当你牺牲速度时，你将获得持久性和并发处理的能力。
- en: See also
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: In the next recipe, we'll create a conditional frequency distribution based
    on the `Redis` frequency distribution created here.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个配方中，我们将基于这里创建的 `Redis` 频率分布创建一个条件频率分布。
- en: Storing a conditional frequency distribution in Redis
  id: totrans-127
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 存储条件频率分布到 Redis
- en: The `nltk.probability.ConditionalFreqDist` class is a container for `FreqDist`
    instances, with one `FreqDist` per condition. It is used to count frequencies
    that are dependent on another condition, such as another word or a class label.
    We used this class in the *Calculating high information words* recipe in [Chapter
    7](ch07.html "Chapter 7. Text Classification"), *Text Classification*. Here, we'll
    create an API-compatible class on top of `Redis` using the `RedisHashFreqDist`
    from the previous recipe.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '`nltk.probability.ConditionalFreqDist` 类是一个 `FreqDist` 实例的容器，每个条件对应一个 `FreqDist`。它用于计算依赖于另一个条件的频率，例如另一个单词或类标签。我们在第7章的“计算高信息词”配方中使用了这个类，*文本分类*。在这里，我们将使用前一个配方中的
    `RedisHashFreqDist` 在 `Redis` 上创建一个兼容API的类。'
- en: Getting ready
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: As in the previous recipe, you'll need to have `Redis` and `redis-py` installed
    with an instance of `redis-server` running.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 如前一个示例，你需要安装`Redis`和`redis-py`，并运行一个`redis-server`实例。
- en: How to do it...
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: We define a `RedisConditionalHashFreqDist` class in `redisprob.py` that extends
    `nltk.probability.ConditionalFreqDist` and overrides the `__contains__()` and
    `__getitem__()` methods. We then override `__getitem__()` so we can create an
    instance of `RedisHashFreqDist` instead of a `FreqDist`, and override `__contains__()`
    so we can call `encode_key()` from the `rediscollections` module before checking
    if the `RedisHashFreqDist` exists.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在`redisprob.py`中定义了一个`RedisConditionalHashFreqDist`类，它扩展了`nltk.probability.ConditionalFreqDist`并重写了`__contains__()`和`__getitem__()`方法。然后我们重写`__getitem__()`以便我们可以创建一个`RedisHashFreqDist`的实例而不是`FreqDist`，并重写`__contains__()`以便在检查`RedisHashFreqDist`是否存在之前，从`rediscollections`模块调用`encode_key()`。
- en: '[PRE12]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: An instance of this class can be created by passing in a `Redis` connection
    and a *base name*. After that, it works just like a `ConditionalFreqDist`.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 通过传递一个`Redis`连接和一个*基本名称*，可以创建这个类的实例。之后，它的工作方式就像一个`ConditionalFreqDist`。
- en: '[PRE13]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: How it works...
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The `RedisConditionalHashFreqDist` uses *name prefixes* to reference `RedisHashFreqDist`
    instances. The name passed in to the `RedisConditionalHashFreqDist` is a *base
    name* that is combined with each condition to create a unique name for each `RedisHashFreqDist`.
    For example, if the *base name* of the `RedisConditionalHashFreqDist` is `'condhash'`,
    and the *condition* is `'cond1'`, then the final name for the `RedisHashFreqDist`
    is `'condhash:cond1'`. This naming pattern is used at initialization to find all
    the existing hash maps using the `keys` command. By searching for all keys matching
    `'condhash:*'`, we can identify all the existing conditions and create an instance
    of `RedisHashFreqDist` for each.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '`RedisConditionalHashFreqDist`使用*名称前缀*来引用`RedisHashFreqDist`实例。传递给`RedisConditionalHashFreqDist`的名称是一个*基本名称*，它与每个条件结合，为每个`RedisHashFreqDist`创建一个唯一的名称。例如，如果`RedisConditionalHashFreqDist`的*基本名称*是`''condhash''`，而*条件*是`''cond1''`，那么`RedisHashFreqDist`的最终名称就是`''condhash:cond1''`。这种命名模式在初始化时用于使用`keys`命令查找所有现有的哈希映射。通过搜索所有匹配`''condhash:*''`的键，我们可以识别所有现有的条件并为每个创建一个`RedisHashFreqDist`实例。'
- en: Note
  id: totrans-138
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Combining strings with colons is a common naming convention for `Redis` keys
    as a way to define *namespaces*. In our case, each `RedisConditionalHashFreqDist`
    instance defines a single namespace of hash maps.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 使用冒号组合字符串是`Redis`键的常见命名约定，作为定义*命名空间*的方式。在我们的情况下，每个`RedisConditionalHashFreqDist`实例定义了一个单独的哈希映射命名空间。
- en: The `ConditionalFreqDist` class stores an internal dictionary at `self._fdists`
    that is a mapping of `condition` to `FreqDist`. The `RedisConditionalHashFreqDist`
    class still uses `self._fdists`, but the values are instances of `RedisHashFreqDist`
    instead of `FreqDist`. `self._fdists` is created when we call `ConditionalFreqDist.__init__()`,
    and values are initialized as necessary in the `__getitem__()` method.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '`ConditionalFreqDist`类在`self._fdists`中存储一个内部字典，它将`condition`映射到`FreqDist`。`RedisConditionalHashFreqDist`类仍然使用`self._fdists`，但值是`RedisHashFreqDist`的实例而不是`FreqDist`。`self._fdists`在调用`ConditionalFreqDist.__init__()`时创建，并在`__getitem__()`方法中根据需要初始化值。'
- en: There's more...
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 更多...
- en: '`RedisConditionalHashFreqDist` also defines a `clear()` method. This is a helper
    method that calls `clear()` on all the internal `RedisHashFreqDist` instances.
    The `clear()` method is not defined in `ConditionalFreqDist`.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '`RedisConditionalHashFreqDist`还定义了一个`clear()`方法。这是一个辅助方法，它会在所有内部`RedisHashFreqDist`实例上调用`clear()`。`clear()`方法在`ConditionalFreqDist`中未定义。'
- en: See also
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: The previous recipe covers the `RedisHashFreqDist` in detail. Also see the *Calculating
    high information words* recipe in [Chapter 7](ch07.html "Chapter 7. Text Classification"),
    *Text Classification*, for example usage of a `ConditionalFreqDist`.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 前一个示例详细介绍了`RedisHashFreqDist`。例如，在[第7章](ch07.html "第7章。文本分类")的*计算高信息词*示例中，可以看到`ConditionalFreqDist`的使用。
- en: Storing an ordered dictionary in Redis
  id: totrans-145
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Redis中存储有序字典
- en: An ordered dictionary is like a normal `dict`, but the keys are ordered by an
    ordering function. In the case of `Redis`, it supports ordered dictionaries whose
    *keys are strings* and whose *values are floating point scores*. This structure
    can come in handy for cases such as calculating information gain (covered in the
    *Calculating high information words* recipe in [Chapter 7](ch07.html "Chapter 7. Text
    Classification"), *Text Classification*) when you want to store all the words
    and scores for later use.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 有序字典就像一个普通的 `dict`，但键是按排序函数排序的。在 `Redis` 的情况下，它支持有序字典，其 *键是字符串*，其 *值是浮点分数*。这种结构在需要存储所有单词和分数以供以后使用的情况下非常有用，例如在计算信息增益时（如第
    7 章 *Calculating high information words* 中的配方所述，*文本分类*）。
- en: Getting ready
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: Again, you'll need `Redis` and `redis-py` installed, with an instance of `redis-server`
    running.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，您需要安装 `Redis` 和 `redis-py`，并且有一个 `redis-server` 实例正在运行。
- en: How to do it...
  id: totrans-149
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: The `RedisOrderedDict` class in `rediscollections.py` extends `collections.MutableMapping`
    to get a number of `dict` compatible methods for free. Then it implements all
    the key methods that require `Redis` ordered set (also known as **Zset**) commands.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '`rediscollections.py` 中的 `RedisOrderedDict` 类扩展了 `collections.MutableMapping`
    以免费获得许多 `dict` 兼容的方法。然后它实现了所有需要 `Redis` 有序集合（也称为 **Zset**）命令的关键方法。'
- en: '[PRE14]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: You can create an instance of `RedisOrderedDict` by passing in a `Redis` connection
    and a unique name.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过传递一个 `Redis` 连接和一个唯一名称来创建 `RedisOrderedDict` 的实例。
- en: '[PRE16]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: How it works...
  id: totrans-155
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'Much of the code may look similar to the `RedisHashMap`, which is to be expected
    since they both extend `collections.MutableMapping`. The main difference here
    is that `RedisOrderedSet` orders keys by floating point values, and so is not
    suited for arbitrary key-value storage like the `RedisHashMap`. Here''s an outline
    explaining each key method and how it works with `Redis`:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 大部分代码可能看起来与 `RedisHashMap` 类似，这是可以预料的，因为它们都扩展了 `collections.MutableMapping`。这里的主要区别在于
    `RedisOrderedSet` 按浮点值对键进行排序，因此不适合像 `RedisHashMap` 那样存储任意键值。以下是一个概述，解释了每个关键方法及其如何与
    `Redis` 一起工作：
- en: '`__len__()`: Uses the `zcard` command to get the number of elements in the
    ordered set.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`__len__()`: 使用 `zcard` 命令来获取有序集合中的元素数量。'
- en: '`__getitem__()`: Uses the `zscore` command to get the score of a key, and returns
    `0` if the key does not exist.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`__getitem__()`: 使用 `zscore` 命令获取键的分数，如果键不存在，则返回 `0`。'
- en: '`__setitem__()`: Uses the `zadd` command to add a key to the ordered set with
    the given score, or updates the score if the key already exists.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`__setitem__()`: 使用 `zadd` 命令将键添加到有序集合中，并带有给定的分数，如果键已存在，则更新分数。'
- en: '`__delitem__()`: Uses the `zrem` command to remove a key from the ordered set.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`__delitem__()`: 使用 `zrem` 命令从有序集合中删除一个键。'
- en: '`keys()`: Uses the `zrevrange` command to get all the keys in the ordered set,
    sorted by highest score. It takes two optional keyword arguments `start` and `end`
    to more efficiently get a slice of the ordered keys.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`keys()`: 使用 `zrevrange` 命令获取有序集合中的所有键，按最高分数排序。它接受两个可选关键字参数 `start` 和 `end`，以更有效地获取有序键的切片。'
- en: '`values()`: Extracts all the scores from the `items()` method.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`values()`: 从 `items()` 方法中提取所有分数。'
- en: '`items()`: Uses the `zrevrange` command to get the scores of each key in order
    to return a list of 2-tuples ordered by highest score. Like `keys()`, it takes
    `start` and `end` keyword arguments to efficiently get a slice.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`items()`: 使用 `zrevrange` 命令来获取每个键的分数，以便按最高分数返回一个由 2-元组组成的列表。与 `keys()` 类似，它接受
    `start` 和 `end` 关键字参数，以有效地获取一个切片。'
- en: '`clear()`: Uses the `delete` command to remove the entire ordered set from
    `Redis`.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clear()`: 使用 `delete` 命令从 `Redis` 中删除整个有序集合。'
- en: Note
  id: totrans-165
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The default ordering of items in a `Redis` ordered set is *low-to-high*, so
    that the key with the lowest score comes first. This is the same as Python's default
    list ordering when you call `sort()` or `sorted()`, but it's not what we want
    when it comes to *scoring*. For storing *scores*, we expect items to be sorted
    from *high-to-low*, which is why `keys()` and `items()` use `zrevrange` instead
    of `zrange`.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '`Redis` 有序集合中项的默认排序是 *从低到高*，因此分数最低的键排在第一位。这与您调用 `sort()` 或 `sorted()` 时 Python
    的默认列表排序相同，但当我们谈到 *评分* 时，这不是我们想要的。对于存储 *分数*，我们期望项按 *从高到低* 排序，这就是为什么 `keys()` 和
    `items()` 使用 `zrevrange` 而不是 `zrange`。'
- en: There's more...
  id: totrans-167
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'As mentioned previously, the `keys()` and `items()` methods take optional `start`
    and `end` keyword arguments to get a slice of the results. This makes the `RedisOrderedDict`
    optimal for storing scores, then getting the top N keys. Here''s a simple example
    where we assign three word scores, then get the top two:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，`keys()`和`items()`方法接受可选的`start`和`end`关键字参数，以获取结果的一部分。这使得`RedisOrderedDict`非常适合存储得分，然后获取前N个键。以下是一个简单的例子，我们分配了三个词频得分，然后获取前两个：
- en: '[PRE17]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: See also
  id: totrans-170
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: '*Calculating high information words* recipe in [Chapter 7](ch07.html "Chapter 7. Text
    Classification"), *Text Classification,* describes how to calculate information
    gain, which is a good case for storing word scores in a `RedisOrderedDict`. The
    *Storing a frequency distribution in Redis* recipe introduces `Redis` and the
    `RedisHashMap`.'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第7章](ch07.html "第7章。文本分类")的*计算高信息词*配方中，*文本分类*描述了如何计算信息增益，这是一个在`RedisOrderedDict`中存储词频的好例子。*在Redis中存储频率分布*配方介绍了`Redis`和`RedisHashMap`。
- en: Distributed word scoring with Redis and execnet
  id: totrans-172
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Redis和execnet进行分布式词频计算
- en: We can use `Redis` and `execnet` together to do distributed word scoring. In
    the *Calculating high information words* recipe in [Chapter 7](ch07.html "Chapter 7. Text
    Classification"), *Text Classification*, we calculated the information gain of
    each word in the `movie_reviews` corpus using a `FreqDist` and `ConditionalFreqDist`.
    Now that we have `Redis`, we can do the same thing using a `RedisHashFreqDist`
    and a `RedisConditionalHashFreqDist`, then store the scores in a `RedisOrderedDict`.
    We can use `execnet` to distribute the counting in order to get better performance
    out of `Redis`.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`Redis`和`execnet`一起进行分布式词频计算。在第7章的*计算高信息词*配方中，*文本分类*，我们使用`FreqDist`和`ConditionalFreqDist`计算了`movie_reviews`语料库中每个单词的信息增益。现在我们有了`Redis`，我们可以使用`RedisHashFreqDist`和`RedisConditionalHashFreqDist`做同样的事情，然后将得分存储在`RedisOrderedDict`中。我们可以使用`execnet`来分配计数，以便从`Redis`中获得更好的性能。
- en: Getting ready
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: '`Redis`, `redis-py`, and `execnet` must be installed, and an instance of `redis-server`
    must be running on `localhost`.'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 必须安装`Redis`、`redis-py`和`execnet`，并且必须在`localhost`上运行`redis-server`实例。
- en: How to do it...
  id: totrans-176
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: We start by getting a list of `(label, words)` tuples for each label in the
    `movie_reviews` corpus (which only has `pos` and `neg` labels). Then we get the
    `word_scores` using `score_words()` from the `dist_featx` module. `word_scores`
    is an instance of `RedisOrderedDict`, and we can see that the total number of
    words is 39,764\. Using the `keys()` method, we can then get the top 1000 words,
    and inspect the top five just to see what they are. Once we have all we want from
    `word_scores`, we can delete the keys in `Redis` as we no longer need the data.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先为`movie_reviews`语料库中的每个标签获取`(label, words)`元组的列表（该语料库只有`pos`和`neg`标签）。然后，我们使用`dist_featx`模块中的`score_words()`函数获取`word_scores`。`word_scores`是一个`RedisOrderedDict`的实例，我们可以看到总共有39,764个单词。使用`keys()`方法，我们可以获取前1000个单词，并检查前五个单词以了解它们是什么。一旦我们从`word_scores`中获取了我们想要的所有信息，我们就可以删除`Redis`中的键，因为我们不再需要这些数据了。
- en: '[PRE18]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The `score_words()` function in `dist_featx` can take a while to complete, so
    expect to wait a couple of minutes. The overhead of using `execnet` and `Redis`
    means it will take significantly longer than a non-distributed in-memory version
    of the function.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '`dist_featx`模块中的`score_words()`函数可能需要一段时间才能完成，因此请预计需要等待几分钟。使用`execnet`和`Redis`的开销意味着它将比非分布式内存版本的功能花费更长的时间。'
- en: How it works...
  id: totrans-180
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'The `dist_featx.py` module contains the `score_words()` function, which does
    the following:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '`dist_featx.py`模块包含`score_words()`函数，该函数执行以下操作：'
- en: Opens gateways and channels, sending initialization data to each.
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开网关和通道，向每个发送初始化数据。
- en: Sends each `(label, words)` tuple over a channel for counting.
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过通道发送每个`(label, words)`元组进行计数。
- en: Sends a `done` message to each channel, waits for a `done` reply back, then
    closes the channels and gateways.
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向每个通道发送`done`消息，等待收到`done`回复，然后关闭通道和网关。
- en: Calculates the score of each word based on the counts and stores in a `RedisOrderedDict`.
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据单词计数计算每个单词的得分，并将其存储在`RedisOrderedDict`中。
- en: 'In our case of counting words in the `movie_reviews` corpus, calling `score_words()`
    opens two gateways and channels, one for counting the `pos` words, and the other
    for counting the `neg` words. The communication is as follows:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们计算`movie_reviews`语料库中单词的案例中，调用`score_words()`打开两个网关和通道，一个用于计数`pos`单词，另一个用于计数`neg`单词。通信如下：
- en: '![How it works...](img/3609OS_08_04.jpg)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
  zh: '![它是如何工作的...](img/3609OS_08_04.jpg)'
- en: 'Once the counting is finished, we can score all the words and store the results.
    The code itself is as follows:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦计数完成，我们可以对所有单词进行评分并存储结果。代码如下：
- en: '[PRE19]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Note
  id: totrans-190
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Note that this scoring method will only be accurate when there are two labels.
    If there are more than two labels, then word scores for each label should be stored
    in separate `RedisOrderedDict` instances, one per label.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，这种方法只有在有两个标签时才会准确。如果有超过两个标签，则每个标签的单词评分应存储在单独的`RedisOrderedDict`实例中，每个标签一个实例。
- en: 'The `remote_word_count.py` module looks as follows:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '`remote_word_count.py`模块看起来如下所示：'
- en: '[PRE20]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'You''ll notice this is not a pure module as it requires being able to import
    both `redis` and `redisprob`. The reason is that instances of `RedisHashFreqDist`
    and `RedisConditionalHashFreqDist` cannot be pickled and sent over the `channel`.
    Instead, we send the host name and key names over the channel so we can create
    the instances in the remote module. Once we have the instances, there are two
    kinds of data we can receive over the channel:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 你会注意到这不仅仅是一个纯模块，因为它需要能够导入`redis`和`redisprob`。原因是`RedisHashFreqDist`和`RedisConditionalHashFreqDist`的实例不能被序列化并通过`channel`发送。相反，我们通过`channel`发送主机名和键名，以便在远程模块中创建实例。一旦我们有了实例，我们就可以通过`channel`接收两种类型的数据：
- en: A `done` message, which signals that there is no more data coming in over the
    channel. We reply back with another `done` message, then exit the loop to close
    the channel.
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个`done`消息，表示通过`channel`没有更多数据传入。我们回复另一个`done`消息，然后退出循环以关闭`channel`。
- en: A 2-tuple of `(label, words)`, which we then iterate over to increment counts
    in both the `RedisHashFreqDist` and `RedisConditionalHashFreqDist`.
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个包含`(label, words)`的2元组，然后我们遍历它来增加`RedisHashFreqDist`和`RedisConditionalHashFreqDist`中的计数。
- en: There's more...
  id: totrans-197
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: In this particular case, it would be faster to compute the scores without using
    `Redis` or `execnet`. However, by using `Redis`, we can store the scores persistently
    for later examination and usage. Being able to inspect all the word counts and
    scores manually is a great way to learn about your data. We can also tweak feature
    extraction without having to re-compute the scores. For example, you could use
    `featx.bag_of_words_in_set()` (found in [Chapter 7](ch07.html "Chapter 7. Text
    Classification"), Text Classification) with the top `N` words from the `RedisOrderedDict`,
    where `N` could be 1,000, 2,000, or whatever number you want. If our data size
    is much greater, the benefits of `execnet` will be much more apparent. Horizontal
    scalability using `execnet` or some other method to distribute computations across
    many nodes becomes more valuable, as the size of the data you need to process
    increases.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个特定情况下，不使用`Redis`或`execnet`计算评分会更快。然而，通过使用`Redis`，我们可以持久化存储评分，以便稍后检查和使用。能够手动检查所有单词计数和评分是了解数据的好方法。我们还可以调整特征提取，而无需重新计算评分。例如，你可以使用`featx.bag_of_words_in_set()`（在[第7章](ch07.html
    "第7章。文本分类")，*文本分类*中找到）与`RedisOrderedDict`中的前`N`个单词，其中`N`可以是1,000、2,000或任何你想要的数字。如果我们的数据量很大，`execnet`的好处将更加明显。随着需要处理的数据量的增加，使用`execnet`或其他方法在多个节点之间分配计算的水平扩展变得更有价值。
- en: See also
  id: totrans-199
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: The *Calculating high information words* recipe in [Chapter 7](ch07.html "Chapter 7. Text
    Classification"), *Text Classification* introduces information gain scoring of
    words for feature extraction and classification. The first three recipes of this
    chapter show how to use `execnet`, while the next three recipes describe `RedisHashFreqDist`,
    `RedisConditionalHashFreqDist`, and `RedisOrderedDict` respectively.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第7章](ch07.html "第7章。文本分类")的*计算高信息词*食谱中，*文本分类*介绍了用于特征提取和分类的单词信息增益评分。本章的前三个食谱展示了如何使用`execnet`，而接下来的三个食谱分别描述了`RedisHashFreqDist`、`RedisConditionalHashFreqDist`和`RedisOrderedDict`。
