- en: Preface
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 前言
- en: '*Spark for Python Developers* aims to combine the elegance and flexibility
    of Python with the power and versatility of Apache Spark. Spark is written in
    Scala and runs on the Java virtual machine. It is nevertheless polyglot and offers
    bindings and APIs for Java, Scala, Python, and R. Python is a well-designed language
    with an extensive set of specialized libraries. This book looks at PySpark within
    the PyData ecosystem. Some of the prominent PyData libraries include Pandas, Blaze,
    Scikit-Learn, Matplotlib, Seaborn, and Bokeh. These libraries are open source.
    They are developed, used, and maintained by the data scientist and Python developers
    community. PySpark integrates well with the PyData ecosystem, as endorsed by the
    Anaconda Python distribution. The book puts forward a journey to build data-intensive
    apps along with an architectural blueprint that covers the following steps: first,
    set up the base infrastructure with Spark. Second, acquire, collect, process,
    and store the data. Third, gain insights from the collected data. Fourth, stream
    live data and process it in real time. Finally, visualize the information.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '*Python开发人员的Spark*旨在将Python的优雅和灵活性与Apache Spark的强大和多功能性相结合。Spark是用Scala编写的，并在Java虚拟机上运行。然而，它是多语言的，并为Java、Scala、Python和R提供了绑定和API。Python是一种设计良好的语言，具有广泛的专业库。本书探讨了PySpark在PyData生态系统中的应用。一些著名的PyData库包括Pandas、Blaze、Scikit-Learn、Matplotlib、Seaborn和Bokeh。这些库是开源的。它们由数据科学家和Python开发人员社区开发、使用和维护。PySpark与PyData生态系统很好地集成在一起，得到了Anaconda
    Python发行版的认可。本书提出了一个构建数据密集型应用程序的旅程，以及涵盖以下步骤的架构蓝图：首先，使用Spark建立基础设施。其次，获取、收集、处理和存储数据。第三，从收集的数据中获得见解。第四，实时传输数据并实时处理。最后，可视化信息。'
- en: The objective of the book is to learn about PySpark and PyData libraries by
    building apps that analyze the Spark community's interactions on social networks.
    The focus is on Twitter data.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的目标是通过构建分析社交网络上Spark社区互动的应用程序来学习PySpark和PyData库。重点是Twitter数据。
- en: What this book covers
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书内容
- en: '[Chapter 1](ch01.html "Chapter 1. Setting Up a Spark Virtual Environment"),
    *Setting Up a Spark Virtual Environment*, covers how to create a segregated virtual
    machine as our sandbox or development environment to experiment with Spark and
    PyData libraries. It covers how to install Spark and the Python Anaconda distribution,
    which includes PyData libraries. Along the way, we explain the key Spark concepts,
    the Python Anaconda ecosystem, and build a Spark word count app.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 第1章，“设置Spark虚拟环境”，介绍了如何创建一个分隔的虚拟机作为我们的沙盒或开发环境，以实验Spark和PyData库。它涵盖了如何安装Spark和Python
    Anaconda发行版，其中包括PyData库。在此过程中，我们解释了关键的Spark概念、Python Anaconda生态系统，并构建了一个Spark词频统计应用程序。
- en: '[Chapter 2](ch02.html "Chapter 2. Building Batch and Streaming Apps with Spark"),
    *Building Batch and Streaming Apps with Spark*, lays the foundation of the *Data
    Intensive Apps Architecture*. It describes the five layers of the apps architecture
    blueprint: infrastructure, persistence, integration, analytics, and engagement.
    We establish API connections with three social networks: Twitter, GitHub, and
    Meetup. This chapter provides the tools to connect to these three nontrivial APIs
    so that you can create your own data mashups at a later stage.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 第2章，“使用Spark构建批处理和流处理应用程序”，奠定了*数据密集型应用程序架构*的基础。它描述了应用程序架构蓝图的五个层次：基础设施、持久性、集成、分析和参与。我们与三个社交网络建立了API连接：Twitter、GitHub和Meetup。本章提供了连接到这三个非平凡API的工具，以便您在以后阶段创建自己的数据混搭。
- en: '[Chapter 3](ch03.html "Chapter 3. Juggling Data with Spark"), *Juggling Data
    with Spark*, covers how to harvest data from Twitter and process it using Pandas,
    Blaze, and SparkSQL with their respective implementations of the dataframe data
    structure. We proceed with further investigations and techniques using Spark SQL,
    leveraging on the Spark dataframe data structure.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 第3章，“使用Spark处理数据”，介绍了如何从Twitter收集数据，并使用Pandas、Blaze和SparkSQL以及它们各自的数据框架数据结构进行处理。我们继续使用Spark
    SQL进行进一步的调查和技术，利用Spark数据框架数据结构。
- en: '[Chapter 4](ch04.html "Chapter 4. Learning from Data Using Spark"), *Learning
    from Data Using Spark*, gives an overview of the ever expanding library of algorithms
    of Spark MLlib. It covers supervised and unsupervised learning, recommender systems,
    optimization, and feature extraction algorithms. We put the Twitter harvested
    dataset through a Python Scikit-Learn and Spark MLlib K-means clustering in order
    to segregate the *Apache Spark* relevant tweets.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 第4章，“使用Spark从数据中学习”，概述了Spark MLlib算法库的不断扩展。它涵盖了监督学习和无监督学习、推荐系统、优化和特征提取算法。我们通过Python
    Scikit-Learn和Spark MLlib K-means聚类将Twitter收集的数据集进行了处理，以区分与*Apache Spark*相关的推文。
- en: '[Chapter 5](ch05.html "Chapter 5. Streaming Live Data with Spark"), *Streaming
    Live Data with Spark*, lays down the foundation of streaming architecture apps
    and describes their challenges, constraints, and benefits. We illustrate the streaming
    concepts with TCP sockets, followed by live tweet ingestion and processing directly
    from the Twitter firehose. We also describe Flume, a reliable, flexible, and scalable
    data ingestion and transport pipeline system. The combination of Flume, Kafka,
    and Spark delivers unparalleled robustness, speed, and agility in an ever-changing
    landscape. We end the chapter with some remarks and observations on two streaming
    architectural paradigms, the Lambda and Kappa architectures.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 第5章，“使用Spark流式传输实时数据”，奠定了流式架构应用程序的基础，并描述了它们的挑战、约束和好处。我们用TCP套接字来说明流式传输的概念，然后直接从Twitter
    firehose进行实时推文摄取和处理。我们还描述了Flume，这是一个可靠、灵活和可扩展的数据摄取和传输管道系统。Flume、Kafka和Spark的结合在不断变化的环境中提供了无与伦比的稳健性、速度和灵活性。我们在本章结束时对两种流式架构范式——Lambda和Kappa架构进行了一些评论和观察。
- en: '[Chapter 6](ch06.html "Chapter 6. Visualizing Insights and Trends"), *Visualizing
    Insights and Trends*, focuses on a few key visualization techniques. It covers
    how to build word clouds and expose their intuitive power to reveal a lot of the
    key words, moods, and memes carried through thousands of tweets. We then focus
    on interactive mapping visualizations using Bokeh. We build a world map from the
    ground up and create a scatter plot of critical tweets. Our final visualization
    is to overlay an actual Google map of London, highlighting upcoming meetups and
    their respective topics.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '[第6章](ch06.html "第6章。可视化洞察和趋势")，*可视化洞察和趋势*，侧重于一些关键的可视化技术。它涵盖了如何构建词云并展示它们直观的力量，以揭示成千上万条推文中携带的关键词、情绪和表情。然后，我们专注于使用Bokeh进行交互式地图可视化。我们从零开始构建世界地图，并创建关键推文的散点图。我们最终的可视化是将伦敦的实际谷歌地图叠加在一起，突出即将举行的聚会及其各自的主题。'
- en: What you need for this book
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书所需内容
- en: You need inquisitiveness, perseverance, and passion for data, software engineering,
    application architecture and scalability, and beautiful succinct visualizations.
    The scope is broad and wide.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要好奇心、毅力和对数据、软件工程、应用架构和可扩展性以及简洁美观的可视化的热情。范围广泛。
- en: You need a good understanding of Python or a similar language with object-oriented
    and functional programming capabilities. Preliminary experience of data wrangling
    with Python, R, or any similar tool is helpful.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要对Python或具有面向对象和函数式编程能力的类似语言有很好的理解。有使用Python、R或任何类似工具进行数据整理的初步经验会有所帮助。
- en: You need to appreciate how to conceive, build, and scale data applications.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要欣赏如何构想、构建和扩展数据应用程序。
- en: Who this book is for
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书的受众
- en: 'The target audience includes the following:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 目标受众包括以下内容：
- en: Data scientists are the primary interested parties. This book will help you
    unleash the power of Spark and leverage your Python, R, and machine learning background.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据科学家是主要的利益相关方。本书将帮助您释放Spark的力量，并利用您的Python、R和机器学习背景。
- en: Software developers with a focus on Python will readily expand their skills
    to create data-intensive apps using Spark as a processing engine and Python visualization
    libraries and web frameworks.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 专注于Python的软件开发人员将很容易扩展他们的技能，使用Spark作为处理引擎和Python可视化库和Web框架创建数据密集型应用程序。
- en: Data architects who can create rapid data pipelines and build the famous Lambda
    architecture that encompasses batch and streaming processing to render insights
    on data in real time, using the Spark and Python rich ecosystem, will also benefit
    from this book.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据架构师可以创建快速数据管道，并构建包含批处理和流处理的著名Lambda架构，以实时渲染数据洞察，使用Spark和Python丰富的生态系统，也将受益于本书。
- en: Conventions
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 约定
- en: In this book, you will find a number of styles of text that distinguish between
    different kinds of information. Here are some examples of these styles, and an
    explanation of their meaning.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，您会发现一些区分不同类型信息的文本样式。以下是一些这些样式的示例，以及它们的含义解释。
- en: Code words in text, database table names, folder names, filenames, file extensions,
    pathnames, dummy URLs, user input, and Twitter handles are shown as follows "Launch
    PySpark with `IPYNB` in directory `examples/AN_Spark` where the Jupyter or IPython
    Notebooks are stored".
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 文本中的代码词、数据库表名、文件夹名、文件名、文件扩展名、路径名、虚拟URL、用户输入和Twitter句柄显示如下：“在存储Jupyter或IPython笔记本的目录`examples/AN_Spark`中使用`IPYNB`启动PySpark”。
- en: 'A block of code is set as follows:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 代码块设置如下：
- en: '[PRE0]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Any command-line input or output is written as follows:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 任何命令行输入或输出都以以下方式编写：
- en: '[PRE1]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '**New terms** and **important words** are shown in bold. Words that you see
    on the screen, in menus or dialog boxes for example, appear in the text like this:
    "After installing VirtualBox, let''s open the Oracle VM VirtualBox Manager and
    click the **New** button."'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**新术语**和**重要单词**以粗体显示。例如，屏幕上看到的单词，比如菜单或对话框中的单词，会在文本中以这种方式出现：“安装VirtualBox后，让我们打开Oracle
    VM VirtualBox Manager并单击**New**按钮。”'
- en: Note
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Warnings or important notes appear in a box like this.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 警告或重要说明会以这种方式出现在一个框中。
- en: Tip
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: Tips and tricks appear like this.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 提示和技巧会以这种方式出现。
- en: Reader feedback
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 读者反馈
- en: Feedback from our readers is always welcome. Let us know what you think about
    this book—what you liked or may have disliked. Reader feedback is important for
    us to develop titles that you really get the most out of.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们始终欢迎读者的反馈。让我们知道您对本书的看法——您喜欢或可能不喜欢的地方。读者的反馈对我们开发您真正受益的标题非常重要。
- en: To send us general feedback, simply send an e-mail to `<[feedback@packtpub.com](mailto:feedback@packtpub.com)>`,
    and mention the book title via the subject of your message.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 要向我们发送一般反馈，只需发送电子邮件至`<[feedback@packtpub.com](mailto:feedback@packtpub.com)>`，并在消息主题中提及书名。
- en: If there is a topic that you have expertise in and you are interested in either
    writing or contributing to a book, see our author guide on [www.packtpub.com/authors](http://www.packtpub.com/authors).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在某个专题上有专业知识，并且有兴趣撰写或为书籍做出贡献，请参阅我们的作者指南[www.packtpub.com/authors](http://www.packtpub.com/authors)。
- en: Customer support
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 客户支持
- en: Now that you are the proud owner of a Packt book, we have a number of things
    to help you to get the most from your purchase.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您是Packt书籍的自豪所有者，我们有许多事情可以帮助您充分利用您的购买。
- en: Downloading the example code
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 下载示例代码
- en: You can download the example code files for all Packt books you have purchased
    from your account at [http://www.packtpub.com](http://www.packtpub.com). If you
    purchased this book elsewhere, you can visit [http://www.packtpub.com/support](http://www.packtpub.com/support)
    and register to have the files e-mailed directly to you.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从您在[http://www.packtpub.com](http://www.packtpub.com)购买的所有Packt书籍中下载示例代码文件。如果您在其他地方购买了本书，您可以访问[http://www.packtpub.com/support](http://www.packtpub.com/support)并注册，以便直接通过电子邮件接收文件。
- en: Errata
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 勘误
- en: Although we have taken every care to ensure the accuracy of our content, mistakes
    do happen. If you find a mistake in one of our books—maybe a mistake in the text
    or the code—we would be grateful if you would report this to us. By doing so,
    you can save other readers from frustration and help us improve subsequent versions
    of this book. If you find any errata, please report them by visiting [http://www.packtpub.com/submit-errata](http://www.packtpub.com/submit-errata),
    selecting your book, clicking on the **errata** **submission** **form** link,
    and entering the details of your errata. Once your errata are verified, your submission
    will be accepted and the errata will be uploaded on our website, or added to any
    list of existing errata, under the Errata section of that title. Any existing
    errata can be viewed by selecting your title from [http://www.packtpub.com/support](http://www.packtpub.com/support).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们已经非常小心地确保了内容的准确性，但错误是难免的。如果您在我们的书籍中发现错误——可能是文本或代码中的错误，我们将不胜感激地接受您的报告。通过这样做，您可以帮助其他读者避免挫折，并帮助我们改进后续版本的书籍。如果您发现任何勘误，请访问[http://www.packtpub.com/submit-errata](http://www.packtpub.com/submit-errata)，选择您的书籍，点击**勘误提交表**链接，并输入您的勘误详情。一旦您的勘误经过验证，您的提交将被接受，并且勘误将被上传到我们的网站上，或者添加到该书籍的现有勘误列表中的勘误部分。您可以通过访问[http://www.packtpub.com/support](http://www.packtpub.com/support)来查看任何现有的勘误。
- en: Piracy
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 盗版
- en: Piracy of copyright material on the Internet is an ongoing problem across all
    media. At Packt, we take the protection of our copyright and licenses very seriously.
    If you come across any illegal copies of our works, in any form, on the Internet,
    please provide us with the location address or website name immediately so that
    we can pursue a remedy.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 互联网上的版权盗版是所有媒体都面临的持续问题。在Packt，我们非常重视版权和许可的保护。如果您在互联网上发现我们作品的任何非法副本，请立即向我们提供位置地址或网站名称，以便我们采取补救措施。
- en: Please contact us at `<[copyright@packtpub.com](mailto:copyright@packtpub.com)>`
    with a link to the suspected pirated material.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您发现了涉嫌盗版的材料，请通过`<[copyright@packtpub.com](mailto:copyright@packtpub.com)>`与我们联系。
- en: We appreciate your help in protecting our authors, and our ability to bring
    you valuable content.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们感谢您帮助保护我们的作者，以及我们为您提供有价值内容的能力。
- en: Questions
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: You can contact us at `<[questions@packtpub.com](mailto:questions@packtpub.com)>`
    if you are having a problem with any aspect of the book, and we will do our best
    to address it.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在阅读书籍的过程中遇到任何问题，请通过`<[questions@packtpub.com](mailto:questions@packtpub.com)>`与我们联系，我们将尽力解决。
