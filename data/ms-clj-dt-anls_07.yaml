- en: Chapter 7. Null Hypothesis Tests – Analyzing Crime Data
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第7章. 假设检验 – 分析犯罪数据
- en: Getting started with data analysis can be so easy. We just plug numbers into
    a function or library and retrieve the results. But sometimes, it's easy to forget
    that we have to pay attention to how the data and experiments are constructed
    and how the questions are framed. Much of the reliability of statistics comes
    from following good practices and developed processes for framing and executing
    the tests and experiments.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 数据分析入门可能非常简单。我们只需将数字输入函数或库中，然后获取结果。但有时，我们很容易忘记我们必须注意数据和方法是如何构建的，以及问题是如何界定的。统计学的可靠性很大程度上来自于遵循良好的实践和制定测试和实验的框架和执行过程。
- en: Of course, there's a lot to setting up statistical experiments and following
    best practices in gathering data and applying statistical tests. We won't be able
    to do more than cursorily glance at this topic. Hopefully, either it will serve
    as a reminder of things you already know or it will outline what you need to know
    and point you in the right direction to learn more.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，设置统计实验以及遵循最佳实践来收集数据和应用统计测试有很多内容。我们无法对这个主题进行深入的探讨。希望这能作为你已知内容的提醒，或者概述你需要了解的内容，并为你指明进一步学习的正确方向。
- en: Over the course of this chapter, we'll move back and forth between looking at
    the problem we're tackling and seeing what null hypothesis testing is, how it
    can help us, and how we can apply it.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将在这两个主题之间来回切换：一方面是观察我们正在解决的问题，另一方面是了解零假设检验是什么，它如何帮助我们，以及我们如何应用它。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Introducing confirmatory data analysis
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍验证性数据分析
- en: Understanding null hypothesis testing
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解零假设检验
- en: Understanding crime
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解犯罪
- en: Getting the data
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取数据
- en: Transforming the data
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 转换数据
- en: Conducting the experiment
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 进行实验
- en: Interpreting the results
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释结果
- en: So without any further delay, let's learn about the techniques and the problems
    we'll address with these methods in this chapter.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，无需进一步延迟，让我们来了解本章中我们将使用这些方法解决的技术和问题。
- en: Introducing confirmatory data analysis
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍验证性数据分析
- en: Oftentimes, data analysis seems like a menu of analyses applied to problems,
    but lacking an overall structure. Of course, this isn't the case, but it seems
    that way to programmers without a strong background in statistics.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，数据分析看起来像是对问题应用一系列分析，但缺乏整体结构。当然，情况并非如此，但对于没有强大统计学背景的程序员来说，这似乎是真实的情况。
- en: Frameworks such as **confirmatory data analysis** and **null hypothesis testing**
    provide the structure that may be missing. Generally, when you begin working with
    data, you start by generating some summary statistics that highlight some of the
    basic characteristics of the data. Afterwards, you probably generate some graphs
    that further elucidate the essential qualities of the data. This all falls into
    the realm of **exploratory data analysis**.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 像**验证性数据分析**和**零假设检验**这样的框架提供了可能缺失的结构。通常，当你开始处理数据时，你会生成一些总结统计量，突出数据的某些基本特征。之后，你可能还会生成一些图表，进一步阐明数据的基本性质。所有这些都属于**探索性数据分析**的范畴。
- en: However, as the exploration wraps up, you'll probably start to think of some
    theories about the data that you'd like to test. You'll generate some hypotheses,
    and you'll need to test whether they're true or not. And based on those tests,
    you'll further refine your knowledge of the data, what's in it, and what it means.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，随着探索的结束，你可能会开始思考一些关于数据的理论，你想要对其进行测试。你会生成一些假设，并需要测试它们是否为真。基于这些测试，你将进一步深化对数据的理解，了解其中包含的内容及其含义。
- en: This more formal stage of data analysis represents confirmatory data analysis.
    At this stage, you're concerned with using reliable tests that match your data,
    and you're trying to determine how representative your sample is. You are minimizing
    error and trying to get a **pvalue**—the probability that a result so extreme
    could have happened by chance—that means that the results are statistically significant.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这个更正式的数据分析阶段代表了验证性数据分析。在这个阶段，你关注的是使用与你的数据相匹配的可靠测试，并试图确定你的样本代表性如何。你正在最小化错误，并试图得到一个**p值**——一个如此极端的结果可能偶然发生的概率——这意味着结果是统计显著的。
- en: But what does all this mean, exactly? How do we go about conceptualizing, planning,
    and executing these tests?
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 但这一切究竟意味着什么？我们如何进行概念化、规划和执行这些测试？
- en: Understanding null hypothesis testing
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解零假设检验
- en: One common way of structuring and processing these tests is to use null hypothesis
    testing. This represents a **frequentist** approach to statistical inference.
    This draws inferences based upon the frequencies or proportions in the data, paying
    attention to confidence intervals and error rates. Another approach is Bayesian
    inference, which focuses on degrees of belief, but we won't go into that in this
    chapter.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 一种常见的构建和处理这些测试的方式是使用零假设检验。这代表了**经验主义**的统计推断方法。它基于数据中的频率或比例进行推断，关注置信区间和误差率。另一种方法是贝叶斯推断，它关注信念程度，但本章不会涉及这一点。
- en: Frequentist inference has been very successful. Its use is assumed in many fields,
    such as the social sciences and biology. Its techniques are widely implemented
    in many libraries and software packages, and it's relatively easy to start using
    it. It's the approach we'll use in this chapter.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 经验主义推断非常成功。它在许多领域中被假设使用，如社会科学和生物学。其技术被广泛应用于许多库和软件包中，并且相对容易开始使用。这是我们本章将使用的方法。
- en: Understanding the process
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解过程
- en: 'To use the null hypothesis process, we should understand what we''ll be doing
    at each step of the way. The following is the basic process that we''ll work through
    in this chapter:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用零假设过程，我们应该了解在每个步骤中我们将做什么。以下是我们将在本章中工作的基本过程：
- en: Formulate an initial hypothesis.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建初始假设。
- en: State the null (*H[0]*) and alternative (*H[1]*) hypotheses.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 陈述零假设（*H[0]*)和备择假设（*H[1]*)。
- en: Identify the statistical assumptions in the sample.
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 识别样本中的统计假设。
- en: Determine which tests (*T*) are appropriate.
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确定哪些测试（*T*）是合适的。
- en: Select the significance level (*a*), such as *p<0.05* or *p<0.01*.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择显著性水平（*a*），例如 *p<0.05* 或 *p<0.01*。
- en: Determine the critical region, that is, the region of the distribution in which
    the null hypothesis will be rejected.
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确定临界区域，即分布中零假设将被拒绝的区域。
- en: Calculate the test statistic and the probability of the observation under the
    null hypothesis (*p*).
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算检验统计量和在零假设下的观测概率（*p*）。
- en: Either reject the null hypothesis or fail to reject it.
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要么拒绝零假设，要么不拒绝它。
- en: We'll go into these step-by-step, and we'll walk through this process twice
    to get a good feel for how it works. Most of this is pretty simple, really.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将逐步进行，并且将这个过程走两次，以便更好地了解它是如何工作的。实际上，大部分内容都很简单。
- en: Formulating an initial hypothesis
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 构建初始假设
- en: Before we can start testing a theory about our data, we need to have something
    to test. This is generally something that might be true or false, and we want
    to determine which of the two it is. Some examples of initial hypotheses might
    be height correlating to diet, speed limit correlating to accident mortality,
    or a Super Bowl win for an old American Football League team (AFC division) correlating
    to a declining stock market (the so-called Super Bowl indicator).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始测试关于我们数据的理论之前，我们需要有可以测试的东西。这通常是可能为真或为假的东西，我们想要确定它是哪一个。一些初始假设的例子可能包括身高与饮食的相关性、速度限制与事故死亡率的相关性，或者一个老美国橄榄球联盟队伍（AFC分区）赢得超级碗与股市下跌（所谓的超级碗指标）的相关性。
- en: Stating the null and alternative hypotheses
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 陈述零假设和备择假设
- en: Now we have to reformulate the initial hypothesis into the statistical phrases
    that we'll use more directly the rest of the time. This is a useful point that
    helps to clarify the rest of the process.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们必须将初始假设重新表述为我们将更直接使用的统计术语。这是一个有用的观点，有助于阐明整个过程。
- en: In this case, the null hypothesis is the control, or what we're trying to disprove.
    It's the opposite of the alternative hypothesis, which is what we want to prove.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，零假设是控制，或者我们试图反驳的东西。它是备择假设的对立面，即我们想要证明的东西。
- en: 'For example, in the last example from the previous section, the Super Bowl
    indicator, the re-cast hypotheses might be as follows:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在上一个章节的最后一个例子中，超级碗指标，重新构建的假设可能如下：
- en: '**Null hypothesis**: Who wins the Super Bowl has no effect upon the stock market.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**零假设**：超级碗的赢家对股市没有影响。'
- en: '**Alternative hypothesis**: When an AFC division team wins the Super Bowl,
    the stock market will decline; when an NFC division team wins the Super Bowl,
    the stock market will be up.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**备择假设**：当一个AFC分区队伍赢得超级碗时，股市将下跌；当一个NFC分区队伍赢得超级碗时，股市将上涨。'
- en: 'For the rest of the process, we will concern ourselves with rejecting the null
    hypothesis. That can only happen when we''ve determined two things: first, that
    the data we have supports the alternative hypothesis, and second, that this is
    very unlikely to be a mistake; that is, the results we see probably are not a
    sample that misrepresents the underlying population.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的过程中，我们将关注拒绝零假设。这只能在我们确定两件事时发生：首先，我们拥有的数据支持备择假设，其次，这几乎不可能是一个错误；也就是说，我们看到的这些结果很可能不是一个代表潜在总体的样本。
- en: This is going to keep coming up, so let's unpack it a little.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这将会反复出现，所以让我们稍微解释一下。
- en: 'You''re interested in making an observation about a population—all men; all
    women; all people; all statisticians; or past, present, and future stock market
    trends—but obviously you can''t make an observation for every person or aspect
    in the population. So instead, you select a sample. It should be random. The question
    then becomes: does the sample accurately represent the population? Say you''re
    interested in people''s heights. How close is the sample''s average height to
    the population''s average height?'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能对关于一个总体——所有男人；所有女人；所有人；所有统计学家；或者过去、现在和未来的股市趋势——的观察感兴趣，但显然你不能对总体中的每个人或方面进行观察。因此，你选择一个样本。它应该是随机的。那么问题就变成了：这个样本是否准确地代表了总体？比如说，你对人们的高度感兴趣。样本的平均高度与总体平均高度有多接近？
- en: Let's assume that what we're interested in falls on a normal distribution, as
    height generally does. What would this look like? For the following chart, I generated
    some random height data. The blue bars (appearing as dark gray in physical books)
    represent the histogram for the population, and the red bars (appearing as light
    gray in physical books) are the histogram for the sample.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们感兴趣的是正态分布，就像高度通常那样。这会是什么样子？对于下面的图表，我生成了一些随机的高度数据。蓝色条形图（在实体书中呈现为深灰色）代表总体的直方图，而红色条形图（在实体书中呈现为浅灰色）是样本的直方图。
- en: '![Stating the null and alternative hypotheses](img/4139OS_07_01.jpg)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![陈述零假设和备择假设](img/4139OS_07_01.jpg)'
- en: We can see from the preceding graph that the distributions are similar, but
    certainly not the same. And in fact, the mean for the population is 6.01, while
    the mean for the sample is 5.94\. They're not too far apart in this case, but
    some samples would be much further off.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以从前面的图表中看出，分布是相似的，但肯定不是相同的。实际上，总体的均值是6.01，而样本的均值是5.94。在这种情况下，它们并不太远，但有些样本会偏离得更远。
- en: 'It has been proven theoretically that the difference between the population
    mean and the possible sample means will fall on a normal distribution. The following
    is the plot for the difference in the means from 500 sets of samples drawn from
    the same population:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 从理论上已经证明，总体均值与可能样本均值之间的差异将落在正态分布上。以下是从同一总体中抽取的500个样本的均值差异的图表：
- en: '![Stating the null and alternative hypotheses](img/4139OS_07_02.jpg)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![陈述零假设和备择假设](img/4139OS_07_02.jpg)'
- en: This histogram makes it clear that large differences between the population
    mean and the sample mean are unlikely, and the larger the difference, the more
    improbable it is. This is important for several reasons. First, if we know the
    distribution of the differences of means, it allows us to set constraints on results.
    If we are working with sample data, we know that the same values for the population
    will fall within a set bound.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这个直方图清楚地表明，总体均值与样本均值之间的大差异是不太可能的，差异越大，其可能性就越小。这一点有几个重要原因。首先，如果我们知道均值差异的分布，它允许我们设定结果上的约束。如果我们正在处理样本数据，我们知道对于总体来说，相同的值将落在一定的范围内。
- en: Also, if we know the distribution of differences, then we know if our results
    are significant. This means that we can reject the null hypothesis that the averages
    are the same. Any two sample means should fall within the same boundaries. Large
    differences between any two sets of sample means are similarly improbable.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，如果我们知道差异的分布，那么我们就知道我们的结果是否具有显著性。这意味着我们可以拒绝均值相同的零假设。任何两个样本均值都应该落在相同的边界内。任何两组样本均值之间的大差异同样是不太可能的。
- en: For example, one sample would be the control data, and one would be the test
    data. If the difference between the two samples is large enough to be improbable,
    then we can infer that the test behavior produced a significant difference (assuming
    the rest of the experiment is well designed and other things aren't complicating
    the experiment). If it's unlikely enough, then we say that it's significant, and
    we reject the null hypothesis.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，一个样本将是对照组数据，另一个将是测试数据。如果这两个样本之间的差异足够大，以至于不太可能发生，那么我们可以推断测试行为产生了显著差异（假设实验的其他部分设计良好，其他因素没有使实验复杂化）。如果不太可能，那么我们说它是显著的，我们拒绝零假设。
- en: 'Depending on what we''re testing, we may be interested in results that are
    on the left-hand side of the graph, the right-hand side, or either. That is, the
    test statistic for the alternative hypothesis may be significantly less than,
    significantly greater than, or equal to the null hypothesis. We express this in
    notation using one of the following three forms. (These use the character mu,
    *μ*, using the sample mean as the test statistic.) In each of these notations,
    the first line states the null hypothesis, and the second states the alternative
    hypothesis. For instance, the first pair in the following notation says that the
    null hypothesis is that the test sample''s mean should be greater than or equal
    to the control sample''s mean, and the alternative hypothesis is that the test
    sample''s mean should be less than the control sample''s mean:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们正在测试的内容，我们可能对图表的左侧、右侧或两侧的结果感兴趣。也就是说，备择假设的测试统计量可能显著小于、显著大于或等于零假设。我们使用以下三种形式之一在符号中表达这一点。（这些使用字符mu，*μ*，使用样本均值作为测试统计量。）在这些符号中的每一项，第一行陈述零假设，第二行陈述备择假设。例如，以下符号中的第一对表示零假设是测试样本的均值应该大于或等于对照组的均值，备择假设是测试样本的均值应该小于对照组的均值：
- en: '![Stating the null and alternative hypotheses](img/4139OS_07_03.jpg)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![提出零假设和备择假设](img/4139OS_07_03.jpg)'
- en: We've taken our time to understand this more thoroughly because it's fundamental
    to the rest of the process. However, if you don't understand it at this point,
    throughout the rest of the chapter, we'll keep going over this. By the end, you
    should have a good understanding of this graph of sample mean differences and
    what it implies.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们花时间更深入地理解这一点，因为它对于整个过程的其余部分是基本的。然而，如果你在这个时候还不理解，在整个章节的其余部分，我们还会继续讲解这一点。到结束时，你应该对样本均值差异的图表及其含义有一个很好的理解。
- en: Determining appropriate tests
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 确定适当的测试
- en: 'Another aspect of your data that you''ll need to pay attention to is the shape
    of the data. This can often be easily visualized using a histogram. For example,
    the following screenshot shows a normal distribution and two distributions that
    are skewed:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 你还需要注意的另一个数据方面是数据的形状。这通常可以通过直方图轻松可视化。例如，下面的截图显示了一个正态分布和两个偏斜的分布：
- en: '![Determining appropriate tests](img/4139OS_07_04.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![确定适当的测试](img/4139OS_07_04.jpg)'
- en: The red curve is skewed left (appearing as dark gray), and the yellow curve
    is skewed right (appearing as white). The blue curve (appearing as light gray)
    is a normal distribution with no skew.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 红色曲线左偏（看起来是深灰色），黄色曲线右偏（看起来是白色）。蓝色曲线（看起来是浅灰色）是一个没有偏斜的正态分布。
- en: Many statistical tests are designed for normal data, and they won't give good
    results for skewed data. For example, t-test and regression analysis both give
    good results only for normally distributed data.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 许多统计测试是为正态数据设计的，它们对于偏斜数据不会给出好的结果。例如，t检验和回归分析仅对正态分布的数据给出好的结果。
- en: Selecting the significance level
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 选择显著性水平
- en: Next, we need to select the significance level that we want to achieve for our
    test. This is the level of certainty that we'll need to have before we can reject
    the null hypothesis. More to the point, this is the maximum chance that the results
    could be an outlying sample from the population, which would cause you to incorrectly
    reject the null hypothesis.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要选择我们想要在测试中达到的显著性水平。这是我们可以在拒绝零假设之前需要的确定性水平。更具体地说，这是结果可能是来自总体中异常样本的最大可能性，这会导致你错误地拒绝零假设。
- en: Often, the significance level, usually given as the p-value, is given as *p<0.05*
    or *p<0.01*. This means that the results have a less than 5 percent or 1 percent
    chance of being caused by a sample with an outlying mean.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，显著性水平，通常表示为 p 值，给出为 *p<0.05* 或 *p<0.01*。这意味着结果有不到5%或1%的可能性是由具有异常平均值的样本引起的。
- en: If we look at the graph of sample mean differences given earlier, we can see
    that we're looking at differences of about 2.4 inches to be significant. In other
    words, based on this population, the average difference in height would need to
    be more than 2 inches for it to be considered statistically significant.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们查看之前给出的样本均值差异图，我们可以看到我们正在查看大约2.4英寸的差异以被认为是显著的。换句话说，基于这个总体，平均身高差异需要超过2英寸才能被认为是统计上显著的。
- en: Say we wanted to see if men and women were on average, of different heights.
    If the average height difference were only 1 inch, that could likely be the result
    of the samples that we picked. However, if the average height difference were
    2.4 inches or more, that would be unlikely to have come from the sample.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想看看男性和女性的平均身高是否有差异。如果平均身高差异只有1英寸，那可能是我们挑选的样本的结果。然而，如果平均身高差异是2.4英寸或更多，那就不太可能是样本的结果。
- en: Determining the critical region
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 确定临界区域
- en: 'Now we have determined two important pieces of information: we''ve expressed
    our null and alternative hypotheses, and we''ve decided on a needed level of significance.
    We can use these two to determine the critical region for the test results, that
    is, the region for which we can reject the null hypothesis.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经确定了两个重要的信息：我们表达了我们零假设和备择假设，并且决定了一个所需的显著性水平。我们可以使用这两个信息来确定测试结果的临界区域，即我们可以拒绝零假设的区域。
- en: 'Remember that our hypotheses can take one of three forms. The following conditions
    determine where our critical region is:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，我们的假设可以采取三种形式。以下条件决定了我们的临界区域在哪里：
- en: For the alternative hypothesis that the two samples' means are not equal, we'll
    perform a two-tailed test.
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于两个样本均值不等的备择假设，我们将进行双尾测试。
- en: For the alternative hypothesis that the test sample's mean is less than the
    control sample's, we'll perform a one-tailed test with the critical region on
    the left-hand side of the graph.
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于测试样本的平均值小于控制样本的平均值的备择假设，我们将进行单尾测试，临界区域位于图表的左侧。
- en: And for the alternative hypothesis that the test sample's mean is greater than
    the control sample's, we'll perform a one-tailed test with the critical region
    on the right-hand side of the graph.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 而对于测试样本的平均值大于控制样本的平均值的备择假设，我们将进行单尾测试，临界区域位于图表的右侧。
- en: The following hypothetical graph highlights the part of the curve in which the
    critical regions occur. The curve represents the distribution of the test statistic
    for the sample, and the shaded parts will be the areas that the critical region(s)
    might come from.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的假设图表突出了曲线中临界区域发生的部分。曲线代表样本测试统计量的分布，阴影部分将是临界区域可能来自的区域。
- en: '![Determining the critical region](img/4139OS_07_05.jpg)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![确定临界区域](img/4139OS_07_05.jpg)'
- en: The exact size of the critical regions is determined by the *p* value that we
    decided upon. In all cases, the area of the critical regions is the *p* percentage
    of the entire curve. That is, if we've decided that we're trying for *p<0.05*,
    and the area under the whole curve is 100, the area in the critical region will
    be 5.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 临界区域的精确大小由我们决定的 *p* 值确定。在所有情况下，临界区域的面积是整个曲线的 *p* 百分比。也就是说，如果我们决定尝试 *p<0.05*，整个曲线下的面积是100，那么临界区域的面积将是5。
- en: If we are performing a two-tailed test, then that area will be divided into
    two, so in the example we just outlined, each side will have an area of 2.5\.
    However, for one-tailed tests, the entire critical region will fall on one side.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们正在进行双尾测试，那么该区域将分为两部分，所以在我们刚才概述的例子中，每边将有2.5的面积。然而，对于单尾测试，整个临界区域将落在一边。
- en: Calculating the test statistics and its probability
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 计算测试统计量和其概率
- en: Now we have to calculate the test statistic. Depending on the nature of the
    data, the sample, and on what you're trying to answer, this could involve comparing
    means, a student's t-test, X² test, or any number of other tests.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们必须计算测试统计量。根据数据的性质、样本以及你试图回答的问题，这可能涉及比较均值、学生t检验、X²检验或其他许多测试。
- en: These tests will give you a number, but interpreting it directly is often not
    helpful. Instead, you then need to calculate the value of *p* for that test's
    distribution. If you're doing things by hand, this can involve either looking
    up the value in tables or if you're using a software program, this is often done
    for you and returned as a part of the results.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这些测试会给你一个数字，但直接解释它通常并不有帮助。相反，你需要计算该测试分布的 *p* 值。如果你是手动操作，这可能涉及在表中查找值，或者如果你使用软件程序，这通常作为结果的一部分自动完成。
- en: We'll use Incanter in several sections later in this chapter, starting with
    calculating the test statistic and its probability. Its functions generally return
    both the test value and the *p* value.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的几个部分中，我们将使用 Incanter，从计算测试统计量和其概率开始。它的函数通常返回测试值和 *p* 值。
- en: Deciding whether to reject the null hypothesis or not
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 决定是否拒绝零假设
- en: Now we can find the value of *p* in relation to the critical regions and determine
    whether we can reject the null hypothesis or not.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以找到 *p* 的值与临界区域的关系，并确定我们是否可以拒绝零假设。
- en: For instance, say that we've decided that the level of significance that we
    want to achieve is *p<0.05* and the actual value of *p* is *0.001*. This will
    allow us to reject the null hypothesis.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设我们决定我们想要达到的显著性水平是 *p<0.05*，而实际的 *p* 值是 *0.001*。这将使我们能够拒绝零假设。
- en: However, if the value of *p* is *0.055*, we would fail to reject the null hypothesis.
    We would have to assume that the alternative hypothesis is incorrect, at least
    until more information is available.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果 *p* 的值为 *0.055*，我们将无法拒绝零假设。我们不得不假设备择假设是错误的，至少直到有更多信息为止。
- en: Flipping coins
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 抛硬币
- en: Now that we've been over the process of null hypothesis testing, let's walk
    through the process one more time with an example. This should be simple and straightforward
    enough that we can focus on the process, and not on the test itself.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了零假设检验的过程，让我们再通过一个例子来回顾一下这个过程。这应该足够简单明了，这样我们就可以专注于过程，而不是测试本身。
- en: For that purpose, we'll test whether a dice is loaded or not. If it is balanced,
    then the expected probability of any given side should be 1/6, or about 16 percent.
    However, if the die is loaded, then the probability for rolling one side should
    be greater than 16 percent, and the probabilities for rolling the other sides
    would be less than 16 percent.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 为了这个目的，我们将测试骰子是否是公平的。如果它是平衡的，那么任何给定面的期望概率应该是 1/6，或者说大约 16%。然而，如果骰子是偏心的，那么掷出某一面的概率应该大于
    16%，而掷出其他面的概率应该小于 16%。
- en: Of course, generally this isn't something that you would worry about. But before
    you agree to play craps with the dice that your friend 3D printed, you may want
    to test them.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，通常这不是你需要担心的事情。但在你同意和你朋友一起用3D打印的骰子玩骰子游戏之前，你可能想测试一下它们。
- en: 'For this test, I''ve rolled one die 1,000 times. The following is the table
    of how many times each side came up:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个测试，我掷了一次骰子1,000次。以下是如何每次出现每个面的次数的表格：
- en: '| Side | Frequency |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| 面数 | 频率 |'
- en: '| --- | --- |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 1 | 157 |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 157 |'
- en: '| 2 | 151 |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 151 |'
- en: '| 3 | 175 |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 175 |'
- en: '| 4 | 187 |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 187 |'
- en: '| 5 | 143 |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 143 |'
- en: '| 6 | 187 |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| 6 | 187 |'
- en: So we can see that the frequencies are relatively close, within a range of 44,
    but they aren't exactly the same. This is what we'd expect. The question is whether
    they're different enough that we can say with some certainty that the die is loaded.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们可以看到频率相对接近，在 44 的范围内，但它们并不完全相同。这正是我们所预期的。问题是它们是否足够不同，以至于我们可以有把握地说骰子是偏心的。
- en: Formulating an initial hypothesis
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 制定初始假设
- en: 'So we suspect that our test die is fair, but we don''t know that. We''ll frame
    our hypothesis this way: on any roll, all sides have an equal chance of appearing.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们怀疑我们的测试骰子是公平的，但我们不知道。我们将这样设定我们的假设：在每次掷骰子时，所有面出现的概率都是相等的。
- en: Stating the null and alternative hypotheses
  id: totrans-99
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 陈述零假设和备择假设
- en: 'Our initial hypothesis can act as our null hypothesis. And in this case, we
    expect to fail to reject it. Let''s state both hypotheses explicitly:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的初始假设可以作为我们的零假设。在这种情况下，我们预计无法拒绝它。让我们明确地陈述这两个假设：
- en: '*H[0]*: All sides have an equal chance of appearing on any roll.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*H[0]*：所有面出现的概率在每次掷骰子时都是相等的。'
- en: '*H[1]*: One side has a greater chance of appearing on any roll.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*H[1]*：某一面的出现概率大于其他面。'
- en: In this case, we let *H[0]* be such that the two sides are equal because we
    want there to be more latitude in what counts as fair, and we want to enforce
    a high burden of proof before we declare a die loaded.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们让 *H[0]* 等于两边的值相等，因为我们希望有更大的范围来定义什么是公平，并且在宣布骰子被加载之前，我们希望有很高的证明负担。
- en: Identifying the statistical assumptions in the sample
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 识别样本中的统计假设
- en: 'For our sample, we''ll roll the die in question 1,000 times. We''ll assume
    that each roll is identical: that it''s being done with approximately the same
    arm and hand movements, and that the die is landing on a flat surface. We''ll
    also assume that before being thrown, the die is being shaken enough to be appropriately
    random.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的样本，我们将对有问题的骰子投掷 1,000 次。我们假设每次投掷都是相同的：使用大约相同的臂和手的动作，并且骰子落在平坦的表面上。我们还将假设在投掷之前，骰子被摇动得足够充分，以产生适当的随机性。
- en: This way, no biases are introduced because of the mechanics of how the die is
    being thrown.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 这样做，就不会因为骰子投掷的机制而引入偏差。
- en: Determining appropriate tests
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 确定适当的测试
- en: For this, we'll use a Pearson's Χ² goodness-of-fit test. This is used to test
    whether an observed frequency distribution matches a theoretical distribution.
    It works by calculating a normalized sum of squared deviations. We're trying to
    test whether some observations match an expected distribution, so this test is
    a great fit.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个，我们将使用皮尔逊 Χ² 好拟合度测试。这个测试用于检验观察到的频率分布是否与理论分布相匹配。它是通过计算平方偏差的归一化总和来工作的。我们试图检验一些观察值是否与预期分布相匹配，因此这个测试非常适合。
- en: We'll see exactly how to apply this test in a minute.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一分钟看到如何应用这个测试。
- en: Selecting the significance level
  id: totrans-110
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 选择显著性水平
- en: Proving that a die is loaded does require a higher burden of proof than assuming
    that it's fair, but we don't want the bar to be too high. Because of that, we'll
    use *p<0.05* for this.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 证明骰子被加载确实需要比假设它是公平的更高的证明负担，但我们不希望门槛过高。因此，我们将使用 *p<0.05*。
- en: Determining the critical region
  id: totrans-112
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 确定临界区域
- en: The output of the Χ² test fits an Χ² distribution, not a normal distribution,
    so the graph won't look the same. Also, Χ² tests are intrinsically one sided.
    When the number is too far out on the right, then it indicates that the data fits
    the theoretical values poorly. A value to the left on the Χ² distribution just
    indicates that the fit is very good, which isn't really a problem.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: Χ² 测试的输出符合 Χ² 分布，而不是正态分布，因此图表看起来不会相同。此外，Χ² 测试本质上是一侧的。当数值在右侧太远时，这表明数据与理论值匹配得不好。Χ²
    分布左侧的值仅表明拟合非常好，这实际上并不是问题。
- en: 'The following is a graph comparing the normal distribution, centered on 50,
    with the X² distribution, with 3 degrees of freedom:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的图表比较了以 50 为中心的正态分布与具有 3 个自由度的 Χ² 分布：
- en: '![Determining the critical region](img/4139OS_07_06.jpg)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![确定临界区域](img/4139OS_07_06.jpg)'
- en: Either way, the statistics library that we're going to use (Incanter) will take
    care of this for us.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 无论哪种方式，我们将使用的统计库（Incanter）将为我们处理这个问题。
- en: Calculating the test statistic and its probability
  id: totrans-117
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 计算测试统计量和其概率
- en: 'So let''s fire up the Leiningen REPL and see what we can do. For this project,
    we''re going to use the following `project.clj` file:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，让我们启动 Leiningen REPL 并看看我们能做什么。对于这个项目，我们将使用以下 `project.clj` 文件：
- en: '[PRE0]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'First, we''ll load Incanter, then we''ll create a matrix containing our data,
    and finally we''ll run an Χ² test over it with the following code:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将加载 Incanter，然后创建一个包含我们数据的矩阵，最后用以下代码运行 Χ² 测试：
- en: '[PRE1]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Let''s look at this code in more detail:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地看看这段代码：
- en: The function `incanter.stats/chisq-test` returns a lot of information, including
    its own input. So, before displaying it at the end, I filtered out most of the
    data and only returned the three keys that we're particularly interested in. The
    following are those keys and the values that they returned.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 函数 `incanter.stats/chisq-test` 返回大量信息，包括其自身的输入。因此，在最后显示之前，我过滤掉了大部分数据，只返回了我们特别感兴趣的三个键。以下就是这些键及其返回的值。
- en: '`:X-sq`: This is the Χ² statistic. Higher values of this indicate that the
    data does not fit their expected values.'
  id: totrans-124
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`:X-sq`：这是 Χ² 统计量。这个量的值越高，表明数据与预期值不匹配。'
- en: '`:df`: This is the degrees of freedom. This represents the number of parameters
    that are free to vary. For nominal data (data without natural ordering), such
    as rolls of dice, this is the number of values that the data can take, minus one.
    In this case, since it''s a six-sided die, the degree of freedom is five.'
  id: totrans-125
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`:df`：这是自由度。这代表可以自由变化的参数数量。对于没有自然排序的名称数据（如骰子的滚动），这是数据可以取的值的数量减一。在这种情况下，由于它是一个六面的骰子，自由度是五。'
- en: '`:p-value`: This is the value of *p* that we''ve been talking about. This is
    the probability that we''d see these results from the Χ² test if the null hypothesis
    were true.'
  id: totrans-126
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`:p-value`：这是我们一直在谈论的*p*的值。这是如果零假设为真，我们从Χ²检验中看到这些结果的概率。'
- en: Now that we have these numbers, how do we apply them to our hypotheses?
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了这些数字，我们如何将它们应用到我们的假设中？
- en: Deciding whether to reject the null hypothesis or not
  id: totrans-128
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 决定是否拒绝零假设
- en: In this case, since *p>0.05*, we fail to reject the null hypothesis. We can't
    really rule it out, but we don't have enough evidence to support it either. In
    this case, we can assume that the die is fair.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，由于*p>0.05*，我们未能拒绝零假设。我们无法真正排除它，但也没有足够的证据来支持它。在这种情况下，我们可以假设骰子是公平的。
- en: Hopefully, this example gives you a better understanding of the null hypothesis
    testing process and how it works. With that under our belts, let's turn our attention
    to a bigger, more meaningful problem than the fairness of imaginary dice.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 希望这个例子能让你更好地理解零假设检验过程及其工作原理。有了这些知识，让我们将注意力转向比想象中的骰子公平性更大的、更有意义的问题。
- en: Understanding burglary rates
  id: totrans-131
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解盗窃率
- en: Understanding crime seems like a universal problem. Earlier, societies grappled
    with the problem of evil in the universe from a theological perspective; today,
    sociologists and criminologists construct theories and study society using a variety
    of tools and techniques. However the problem is cast, the aim is to better understand
    why some people violate social norms in ways that are often violent and harmful
    to those around them and even themselves. By better understanding this problem,
    ultimately we'd like to be able to create social programs and government policies
    that minimize the damage and create a safer and hopefully more just society for
    all involved.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 理解犯罪似乎是一个普遍存在的问题。以前，社会从神学的角度处理宇宙中的邪恶问题；今天，社会学家和犯罪学家使用各种工具和技术构建理论并研究社会。然而，无论问题如何表述，目标都是更好地理解为什么有些人以往往具有暴力和对周围人甚至对自己有害的方式违反社会规范。通过更好地理解这个问题，我们最终希望能够创建社会项目和政府政策，以最大限度地减少损害，并为所有相关方创造一个更安全、更公正的社会。
- en: Of course, as data scientists and programmers engaging in data analysis, we're
    inclined to approach this problem as a data problem. That's what we'll do in the
    rest of this chapter. We'll gather some crime and economic data and look for a
    tie between the two. In the course of our analysis, we'll explore the data, tentatively
    suggest a hypothesis, and test it against the data.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，作为从事数据分析的数据科学家和程序员，我们倾向于将这个问题作为一个数据问题来处理。这就是我们将在本章的其余部分所做的事情。我们将收集一些犯罪和经济数据，并寻找两者之间的联系。在分析过程中，我们将探索数据，试探性地提出一个假设，并对其进行数据检验。
- en: We'll look at crime data from the United Nations and see what relationships
    it has with data from the World Bank data site.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将查看联合国提供的犯罪数据，并观察它与世界银行数据网站的数据之间有什么关系。
- en: Getting the data
  id: totrans-135
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 获取数据
- en: 'In order to get the data, perform the following steps:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获取数据，请执行以下步骤：
- en: First, we need to download the data.
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要下载数据。
- en: For the crime data, we'll go to the website of the United Nations Office on
    Drugs and Crime ([http://www.unodc.org/](http://www.unodc.org/)). It publishes
    crime data for countries around the world over a number of years. Their data page,
    [http://www.unodc.org/unodc/en/data-and-analysis/statistics/data.html](http://www.unodc.org/unodc/en/data-and-analysis/statistics/data.html),
    has links to Excel files for a number of different categories of crime in the
    section of the page labeled **Statistics on crime**.
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于犯罪数据，我们将访问联合国毒品和犯罪办公室（[http://www.unodc.org/](http://www.unodc.org/)）的网站。它发布了几年来世界各国犯罪数据。他们数据页面上的[http://www.unodc.org/unodc/en/data-and-analysis/statistics/data.html](http://www.unodc.org/unodc/en/data-and-analysis/statistics/data.html)，在页面标记为**犯罪统计**的部分提供了多个不同类别犯罪的Excel文件链接。
- en: You should download each of these and save them to the directory `unodc-data`.
    You can extract the data from these in a minute. First, you can get the data that
    we want to correlate to the crime data.
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您应该下载这些文件并将它们保存到`unodc-data`目录中。您可以在一分钟内从这些文件中提取数据。首先，您可以获取我们想要与犯罪数据相关联的数据。
- en: 'We''ll get this data from the World Bank''s data site ([http://data.worldbank.org/](http://data.worldbank.org/)).
    Navigating the site is a little complicated, and in my experience it changes regularly.
    For the moment, at least, this seems to be the easiest way to get the data:'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将从世界银行的数据网站（[http://data.worldbank.org/](http://data.worldbank.org/)）获取这些数据。导航网站有点复杂，并且在我的经验中，它经常变化。至少目前，这似乎是获取数据的最简单方法：
- en: Visit the **Indicators** page at [http://data.worldbank.org/indicator](http://data.worldbank.org/indicator).
  id: totrans-141
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 访问[指标](http://data.worldbank.org/indicator)页面。
- en: 'In the search box, enter `land area` and select **Land area (sq. km)**, as
    shown in the following screenshot:'
  id: totrans-142
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在搜索框中输入`land area`并选择**土地面积（平方公里**），如图所示：
- en: '![Getting the data](img/4139OS_07_07.jpg)'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![获取数据](img/4139OS_07_07.jpg)'
- en: Then hit the **Go** button.
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后点击**Go**按钮。
- en: On the next page, you'll be given the option to download the dataset in a number
    of formats. Choose **CSV**.
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在下一页，您可以选择以下几种格式下载数据集。选择**CSV**。
- en: Download the data and unzip it into a directory named `ag.lnd`, based on the
    indicator codes that the World Bank uses. (You can use a different directory name,
    but you'll need to modify the directions that follow.)![Getting the data](img/4139OS_07_08.jpg)
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载数据并将其解压到名为`ag.lnd`的目录中，基于世界银行使用的指标代码。（您可以使用不同的目录名，但您需要修改随后的说明。）![获取数据](img/4139OS_07_08.jpg)
- en: 'We''ll also want some economic data. To get that, perform the following steps:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还想要一些经济数据。为了获取这些数据，执行以下步骤：
- en: Go back to the **Indicators** page.
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 返回到**指标**页面。
- en: Search for **GNI per capita** (it's the default selection for the search box).
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 搜索**人均国民总收入**（它是搜索框的默认选择）。
- en: From the filtered results, select **GNI per capita, Atlas method (current US$)**.
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从过滤后的结果中选择**人均国民总收入，Atlas方法（当前美元**）。
- en: Click on **Go**.
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**Go**。
- en: Download the data as CSV again.
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再次将数据作为CSV下载。
- en: Unzip the data into a directory named `ny.gnp`.
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据解压到名为`ny.gnp`的目录中。
- en: 'At this point, you should have a directory with several subdirectories containing
    data files. The structure should look something like the following screenshot:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你应该有一个包含多个子目录的数据文件目录。结构应该类似于以下截图：
- en: '![Getting the data](img/4139OS_07_09.jpg)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![获取数据](img/4139OS_07_09.jpg)'
- en: Some of the data is ready to go, but before we use it, we need to extract the
    data from the Excel files. Let's turn our attention there.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 一些数据已经准备好了，但在我们使用它之前，我们需要从Excel文件中提取数据。让我们把注意力转向那里。
- en: Parsing the Excel files
  id: totrans-157
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解析Excel文件
- en: 'Before we can extract the data from the Excel files, we need to find out what
    our input for this will be. If we open up one of the Excel files, in this case
    `CTS_Assault.xls`, we''ll see something similar to the following screenshot:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们能够从Excel文件中提取数据之前，我们需要弄清楚我们的输入将是什么。如果我们打开其中一个Excel文件，例如`CTS_Assault.xls`，我们会看到以下截图类似的内容：
- en: '![Parsing the Excel files](img/4139OS_07_10.jpg)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![解析Excel文件](img/4139OS_07_10.jpg)'
- en: 'Let''s list out some of the features of the sheets that we''ll need to take
    into account:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们列出一些我们需要考虑的工作表特征：
- en: There are about thirteen rows of headers, most of which are hidden in the preceding
    screenshot.
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大约有十三行标题，其中大部分在先前的截图中被隐藏。
- en: Again, not shown in the preceding screenshot, but some of the files have more
    than one tab of data.
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 再次，先前的截图中没有显示，但一些文件有多个数据标签。
- en: There are some hidden columns between columns A and D.
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在A列和D列之间有一些隐藏的列。
- en: The subregion isn't listed on each row, so we'll need some way to carry this
    over.
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 子区域没有列在每个行上，所以我们需要某种方式来传递这个信息。
- en: All the years for each crime and country combination are listed on one row.
    We'll probably want to pivot that so that there's a column for the crime, one
    for the country, one for the year, and one for the data value.
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个犯罪和国家的组合的年份都列在了一行上。我们可能希望将其转换，以便有一个犯罪列、一个国家列、一个年份列和一个数据值列。
- en: There is a lot of missing data. We can filter that out.
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有很多缺失数据。我们可以过滤掉这些数据。
- en: To get into the Excel files, we'll use the Apache POI project ([http://poi.apache.org/](http://poi.apache.org/)).
    This library provides access to file formats of Microsoft Office's suites.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 要进入Excel文件，我们将使用Apache POI项目([http://poi.apache.org/](http://poi.apache.org/))。这个库提供了对Microsoft
    Office套件文件格式的访问。
- en: 'We''ll use this library to extract the data from the Excel files in several
    stages, as follows:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用这个库在几个阶段从Excel文件中提取数据，如下所示：
- en: Pull raw data rows out of the Excel files
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从Excel文件中提取原始数据行
- en: Populate a tree of data that groups the data hierarchically by region, subregion,
    and country
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按地区、子地区和国家层次结构分组填充数据树
- en: Flatten the hierarchically arranged data back into a sequence of maps containing
    all the data for each row
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将层次结构排列的数据扁平化回包含每行所有数据的映射序列
- en: Wrap all of this in one easy-to-use function
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将所有这些封装在一个易于使用的函数中
- en: Let's follow the preceding steps for the rest of this section, and in the end
    we'll add a controller function that pulls it all together.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们按照前面的步骤继续本节的其余部分，最后我们将添加一个控制器函数来整合所有内容。
- en: We'll keep all of this code in a single module. The following namespace declaration
    for this will include all the dependencies that we'll need. For the fully specified
    `project.clj` file that includes all of these, refer to the code download for
    this chapter. I named the project `nullh`, so the file that I'm working with here
    is named `src/nullh/unodc.clj`.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将所有这些代码保存在一个单独的模块中。下面的命名空间声明将包括我们需要的所有依赖项。对于包含所有这些内容的完整`project.clj`文件，请参考本章的代码下载。我给这个项目命名为`nullh`，所以我正在处理的文件名为`src/nullh/unodc.clj`。
- en: '[PRE2]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Now we can start populating this namespace.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以开始填充这个命名空间。
- en: Pulling out raw data
  id: totrans-177
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 提取原始数据
- en: For the first stage of the process, in which we read the data into a series
    of raw data rows, we'll use a couple of record types, as shown in the following
    code. The first, `sheet-data`, associates the title of the worksheet with the
    data in it. The second, `xl-row`, simply stores the data in each row's cells into
    named fields.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理过程的第一个阶段，我们将使用几个记录类型将数据读入一系列原始数据行，如下面的代码所示。第一个，`sheet-data`，将工作表的标题与其中的数据关联起来。第二个，`xl-row`，简单地存储每行单元格中的数据到命名字段中。
- en: '[PRE3]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'As we interact with the worksheet''s data and API, we''ll use a number of utilities
    that makes access to the worksheet objects more like working with native Clojure
    objects. The following are some of those utilities:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们与工作表的数据和API交互时，我们将使用许多使访问工作表对象更像使用本地Clojure对象的一些实用工具。以下是一些这样的实用工具：
- en: '[PRE4]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We''ll spend a lot of time accessing cells'' values. We''ll want to make a
    simpler, more Clojure-like wrapper around the Java library''s API for accessing
    them. How we do this will depend on the cell''s type, and we can use *multimethods*
    to handle dispatching for it, as shown in the following code:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将花费大量时间访问单元格的值。我们希望围绕Java库的API创建一个更简单、更Clojure风格的包装器来访问它们。我们如何做将取决于单元格的类型，我们可以使用*多方法*来处理它的分派，如下面的代码所示：
- en: '[PRE5]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Now, with these methods in place, we can easily read the data into a sequence
    of data rows. First, we''ll need to open the workbook file with the following
    code:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，有了这些方法，我们可以轻松地将数据读入一系列数据行。首先，我们需要使用以下代码打开工作簿文件：
- en: '[PRE6]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'And we can take each sheet and read it into a `sheet-data` record with the
    following code:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用以下代码将每个工作表读入`sheet-data`记录中：
- en: '[PRE7]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The rows themselves will need to go through a number of transformations, all
    without touching the sheet name field. To facilitate this, we''ll define a higher
    order function that maps a function over the rows field, as follows:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 行本身将需要经过一系列的转换，所有这些转换都不涉及工作表名称字段。为了方便起见，我们将定义一个高阶函数，它将函数映射到行字段上，如下所示：
- en: '[PRE8]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The first row transformation will involve skipping the header rows for each
    sheet, as shown in the following code:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 第一行转换将涉及跳过每个工作表的头行，如下面的代码所示：
- en: '[PRE9]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Now we can take the sequence of `sheet-data` records and flatten them by adding
    the sheet name onto the row data as follows:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以将`sheet-data`记录的序列取出来，通过将工作表名称添加到行数据中来进行扁平化，如下所示：
- en: '[PRE10]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We do need to take each row and clean it up by rearranging the field order,
    making sure it has exactly the right number of fields with the help of the following
    code:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 我们确实需要逐行处理并重新排列字段顺序，确保它有恰好正确的字段数量，如下面的代码所示：
- en: '[PRE11]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Now that we''ve hardened our data a little, we can take the Clojure vectors
    and populate the `xl-row` records with them as follows:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经稍微加固了数据，我们可以将Clojure向量填充到`xl-row`记录中，如下所示：
- en: '[PRE12]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Finally, we have a fairly clean sequence of row data.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们有一系列相当干净的行数据。
- en: Growing a data tree
  id: totrans-199
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 构建数据树
- en: Unfortunately, we haven't yet dealt with some problems, such as the subregion
    not being populated in every row. Let's take care of that now.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，我们还没有解决一些问题，例如子区域在每一行中并未被填充。现在让我们来处理这个问题。
- en: 'We''ll tackle that problem by changing the sequence of records into a hierarchical
    tree of data. The tree is represented by a number of record types as shown in
    the following code:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过将记录序列转换为数据层次树来解决这个问题。树由多个记录类型表示，如下述代码所示：
- en: '[PRE13]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: To build the tree, we'll have a number of functions. Each takes a group of data
    that will go into one tree or subtree. It populates that part of the tree and
    returns it.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 要构建树，我们将有一系列函数。每个函数都接受将进入一个树或子树的组数据。它填充树的这部分并返回它。
- en: 'The first of these functions is `xl-rows->regions`. It takes a sequence of
    `xl-rows`, groups them by region, and constructs a tree of `region` records for
    it as shown in the following code:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 这些函数中的第一个是`xl-rows->regions`。它接受一个`xl-rows`序列，按区域分组，并为它构建一个`region`记录的树，如下述代码所示：
- en: '[PRE14]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The most complicated part of building this tree is dealing with the missing
    subregions. We''ll use three functions to deal with that. The first, `conj-into`,
    conjugates onto a value in a map, or adds a new vector containing the data if
    there''s no data for that key. The second, `fold-sub-region`, folds each row into
    a map based on either the subregion referred to in the row, or the last specified
    subregion. Finally, `xl-rows->sub-regions` takes a sequence of rows from one region,
    divides them into subregions, and creates the `sub-region` records for them, as
    shown in the following code:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 构建此树最复杂的部分是处理缺失的子区域。我们将使用三个函数来处理这个问题。第一个函数`conj-into`，将数据结合到映射中的一个值上，或者如果没有该键的数据，则添加一个包含数据的新的向量。第二个函数`fold-sub-region`，根据行中引用的子区域或最后指定的子区域将每一行折叠到一个映射中。最后，`xl-rows->sub-regions`从一个区域的行序列中取出，将它们划分为子区域，并为它们创建`sub-region`记录，如下述代码所示：
- en: '[PRE15]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Now that we have the subregions identified, we can build a tree for each country.
    For that, we''ll pull the count data and the rate data into their own structures
    and put it all together into a `country` record with the following code:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经确定了子区域，我们可以为每个国家构建一个树。为此，我们将计数数据和比率数据拉入它们自己的结构中，并使用以下代码将它们全部组合到一个`country`记录中：
- en: '[PRE16]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The counts and rates are represented by the same record type, so we''ll use
    a shared function to pull the fields from the row that populate the fields in
    the type as shown in the following code:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 计数和比率由相同的记录类型表示，因此我们将使用一个共享函数从行中提取字段，以填充类型中的字段，如下述代码所示：
- en: '[PRE17]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: These functions all build the hierarchy of data that's stored in the worksheets.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 这些函数都构建了存储在表格中的数据层次结构。
- en: Cutting down the data tree
  id: totrans-213
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 剪枝数据树
- en: We reverse the process to flatten the data again. In the process, this implicitly
    populates the missing subregions into all of the rows. Let's see how this works.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 我们反转这个过程以再次展平数据。在这个过程中，这隐式地将缺失的子区域填充到所有行中。让我们看看这是如何工作的。
- en: 'To begin with, we take a sequence of regions and convert each one into a sequence
    of `xl-row` records, as shown in the following code:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们取一个区域序列，并将其转换为`xl-row`记录序列，如下述代码所示：
- en: '[PRE18]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Just as before, this work will be delegated to other functions; in this case,
    `sub-regions->xl-rows`, which again delegates to `country->xl-rows`. The second
    function in the following code is a little long (and so I''ve omitted some lines
    from it), but both are conceptually simple:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 就像之前一样，这项工作将被委派给其他功能；在这种情况下，`sub-regions->xl-rows`，它再次委派给`country->xl-rows`。在下述代码中的第二个函数稍微长一些（因此我已经从中省略了一些行），但它们在概念上都很简单：
- en: '[PRE19]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: At this point, we have a sequence of data rows with the missing subregions supplied.
    But we're still not done.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们有一个包含缺失子区域的数据行序列。但我们还没有完成。
- en: Putting it all together
  id: totrans-220
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将一切整合起来
- en: 'We''ll provide several levels of function to make this easier. First, one that
    ties together everything that we''ve seen so far. It takes a filename and returns
    a sequence of `xl-row` records as follows:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将提供几个级别的函数来简化这个过程。首先，一个将我们迄今为止看到的一切联系起来的函数。它接受一个文件名，并返回一个`xl-row`记录序列，如下所示：
- en: '[PRE20]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'That''s it. We have our data read in. It''s been processed a little, but it''s
    still pretty raw. The following is an example row:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样。我们已经读入了数据。它已经经过了一些处理，但仍然相当原始。以下是一个示例行：
- en: '[PRE21]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: We still need to clean it up a little and pivot the data to put each data value
    into its own row. Instead of having one row with `:count-2003`, `:count-2004`,
    and so on, we'll have many rows, each with `:count` and `:year`.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 我们仍然需要稍作清理并将数据透视，以便将每个数据值放入单独的行中。而不是有一个包含 `:count-2003`、`:count-2004` 等等的行，我们将有多个行，每个行都有
    `:count` 和 `:year`。
- en: Let's turn our attention there next.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们把注意力转向那里。
- en: Transforming the data
  id: totrans-227
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据转换
- en: So far, we've only lightly cleaned part of our data. We haven't even looked
    at the data that we want to correlate the crime data with. Also, the shape of
    the data is awkward for the analyses that we want to conduct, so we'll need to
    pivot it the way we described earlier. We'll see more about this in a minute.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们只是轻微地清理了我们数据的一部分。我们甚至还没有查看我们想要与犯罪数据相关联的数据。此外，数据的形状对于我们想要进行的分析来说很尴尬，因此我们需要按照之前描述的方式对其进行数据透视。我们将在下一分钟了解更多关于这一点。
- en: 'For this stage of processing, we want to put all of the code into a new file.
    We''ll name this file `src/nullh/data.clj`, and the namespace declaration for
    it looks as follows:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个处理阶段，我们希望将所有代码放入一个新的文件中。我们将把这个文件命名为 `src/nullh/data.clj`，其命名空间声明如下：
- en: '[PRE22]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: We'll now start working with Incanter datasets. We haven't used Incanter much
    so far in this book, and that's a little unusual, because Incanter is one of the
    go-to libraries for working with numbers and statistics in Clojure. It's powerful
    and flexible, and it makes working with data easy.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将开始使用 Incanter 数据集。到目前为止，这本书中我们并没有太多使用 Incanter，这有点不寻常，因为 Incanter 是 Clojure
    中处理数字和统计数据的常用库之一。它功能强大且灵活，使得数据处理变得容易。
- en: 'Let''s take the data that we read from the Excel files and import it into an
    Incanter dataset. We need to read the data into one long sequence, pull out the
    keys for the data fields, and then create the dataset as follows:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们把从 Excel 文件中读取的数据导入到 Incanter 数据集中。我们需要将数据读入一个长序列，提取数据字段的键，然后按照以下方式创建数据集：
- en: '[PRE23]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Now we can read the data that we downloaded from the World Bank into another
    dataset. Both data files have roughly the same fields, so we can use the same
    function for both. Unfortunately, we need to load the CSV ourselves, because Incanter''s
    introspection doesn''t quite give us the results that we want. Because of this,
    we''ll also include a few functions for converting the data into doubles as we
    read it in, and we''ll define those columns that the data contains, as follows:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以将我们从世界银行下载的数据读入另一个数据集中。这两个数据文件具有大致相同的字段，因此我们可以为两者使用相同的函数。不幸的是，我们需要自己加载
    CSV，因为 Incanter 的自省并没有给我们想要的结果。因此，我们还将包括一些函数，在读取数据时将其转换为双精度浮点数，并定义数据包含的列，如下所示：
- en: '[PRE24]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: We can use the `read-indicator-data` function to load data from the two World
    Bank indicators that we downloaded earlier.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 `read-indicator-data` 函数来加载我们之前下载的两个世界银行指标的数据。
- en: Now we want to put all the data from UNODC together with either of the World
    Bank datasets. As we do that, we'll also pivot the data tables so that instead
    of one column for each year, there's one column containing the year and one containing
    the value for that year. At the same time, we'll remove rows with missing data
    and aggregate the counts for all of the crimes for a country for each year.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们希望将联合国毒品和犯罪问题办公室的所有数据与任何一个世界银行数据集合并。在我们这样做的时候，我们也会将数据表进行数据透视，这样就不会为每年的每个年份有一个列，而是一个包含年份和一个包含该年值的列。同时，我们将删除缺失数据的行，并汇总每个国家每年所有犯罪的计数。
- en: Joining the data sources
  id: totrans-238
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据源合并
- en: 'Bringing the two data sources together is relatively simple and can be done
    with the following code:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 将两个数据源合并相对简单，可以使用以下代码完成：
- en: '[PRE25]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Basically, we just let Incanter join the two data structures on the fields by
    matching the World Bank data's `:country-name` field with the UNODC data's `:country`
    field.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，我们只是让 Incanter 通过匹配世界银行数据的 `:country-name` 字段和联合国毒品和犯罪问题办公室数据的 `:country`
    字段，在字段上合并两个数据结构。
- en: Pivoting the data
  id: totrans-242
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据透视
- en: 'Now that the data has been joined, we can pivot it. In the end, we want to
    have the following fields on every row:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 现在数据已经合并，我们可以进行数据透视。最终，我们希望每行都有以下字段：
- en: '`region`'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`region`'
- en: '`subregion`'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`subregion`'
- en: '`country`'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`country`'
- en: '`country-code`'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`country-code`'
- en: '`indicator`'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`indicator`'
- en: '`indicator-code`'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`indicator-code`'
- en: '`crime`'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`crime`'
- en: '`year`'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`year`'
- en: '`count`'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`count`'
- en: '`rate`'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rate`'
- en: '`indicator-value`'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`indicator-value`'
- en: As you can see, some of these fields are from the UNODC data and some are from
    the World Bank data.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，其中一些字段来自联合国毒品和犯罪问题办公室数据，而另一些来自世界银行数据。
- en: 'We''ll do this translation on a sequence of maps instead of the dataset. We''ll
    get started with the following code:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在一系列映射上执行此翻译，而不是在数据集上。我们将从以下代码开始：
- en: '[PRE26]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: First, we use `->maps` to convert the dataset to a sequence of maps. Then, pass
    the processing off to `pivot-map`. This function pivots the data for each year.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们使用`->maps`将数据集转换为映射序列。然后，将处理工作委托给`pivot-map`函数。这个函数为每年的数据执行数据透视。
- en: We pivot the data for each year separately. We do this by repeatedly transforming
    the data map for a row. This is a great example of how Clojure's immutability
    makes things easier. We don't have to worry about copying the map or clobbering
    any data. We can just modify the original data multiple times, saving the result
    of each transformation process as a separate, new data row.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 我们分别对每年的数据进行数据透视。我们通过反复转换数据映射的行来实现这一点。这是一个很好的例子，说明了Clojure的不可变性如何使事情变得简单。我们不必担心复制映射或覆盖任何数据。我们只需修改原始数据多次，并将每次转换过程的结果保存为单独的新数据行。
- en: 'The process itself is fairly simple. First, we use the year to create keywords
    for the fields that we are interested in. Next, we select the rows that we want
    to keep from the original data map. Then we rename a few to make them clearer.
    And finally, we add the year to the output map as follows:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程本身相当简单。首先，我们使用年份为感兴趣的领域创建关键词。接下来，我们从原始数据映射中选择我们想要保留的行。然后我们重命名几个，使它们更清晰。最后，我们将年份添加到输出映射中，如下所示：
- en: '[PRE27]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: That's it. This should make the data easier to work with. We can do some more
    transformations on the data and clean it up a bit further.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样。这应该会使数据处理更容易。我们可以在数据上做一些更多的转换，并进一步清理一下。
- en: Filtering the missing data
  id: totrans-263
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 过滤缺失数据
- en: 'First, there are a lot of holes in the data, and we don''t want to have to
    worry about that. So if a row is missing any of the three data fields (`:count`,
    `:rate`,or `:indicator-value`), let''s get rid of it with the following code:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，数据中有很多空白，我们不希望为此担心。因此，如果某行缺少三个数据字段中的任何一个（`:count`、`:rate`或`:indicator-value`），让我们用以下代码将其删除：
- en: '[PRE28]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: We just check whether any of these fields has a `nil` value. If any of them
    do, we remove that row.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只是检查这些字段中是否有`nil`值。如果有，我们就删除该行。
- en: Putting it all together
  id: totrans-267
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 整合所有内容
- en: 'Let''s make a wrapper function around this process. That''ll help us stay consistent
    and make the library easier to use. This loads the data from UNODC and one of
    the World Bank datasets. It joins, pivots, and removes the missing rows before
    returning an Incanter dataset, as shown in the following code:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们围绕这个过程创建一个包装函数。这将帮助我们保持一致性，并使库更容易使用。这个函数从UNODC和世界银行的一个数据集中加载数据。在返回Incanter数据集之前，它将数据连接、数据透视和删除缺失的行，如下面的代码所示：
- en: '[PRE29]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Let''s use these functions to load up one of the datasets as follows:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用这些函数来加载一个数据集，如下所示：
- en: '[PRE30]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: At this point, the data is in decent shape—actually, as good as this data is
    probably going to get (more about that near the end of this chapter). So let's
    see what's in the data and what it has to tell us.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，数据已经处于相当好的状态——实际上，这可能是这些数据可能达到的最佳状态（更多关于这一点将在本章末尾讨论）。所以，让我们看看数据中有什么，以及它能告诉我们什么。
- en: Exploring the data
  id: totrans-273
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索数据
- en: Let's explore a little and try to get a feel for the data. First, let's try
    to get some summary statistics for the various datasets. Afterward, we'll generate
    some graphs to get a more intuitive sense for what's in the data and how they're
    related.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们探索一下，尝试了解数据的感受。首先，让我们尝试为各种数据集获取一些汇总统计。之后，我们将生成一些图表，以更直观地了解数据中包含的内容以及它们之间的关系。
- en: Generating summary statistics
  id: totrans-275
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成汇总统计
- en: Incanter makes generating summary statistics easy. You can pass a dataset to
    the `incanter.stats/summary` function. It returns a sequence of maps. Each map
    represents the summary data for each column in the original dataset. This includes
    whether the data is numeric or not. For nominal data, it returns some sample items
    and their counts. For numeric data, it returns the mean, median, minimum, and
    maximum.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: Incanter使生成汇总统计变得容易。您可以将数据集传递给`incanter.stats/summary`函数。它返回一个映射序列。每个映射代表原始数据集中每列的汇总数据。这包括数据是否为数值。对于名义数据，它返回一些样本项及其计数。对于数值数据，它返回平均值、中位数、最小值和最大值。
- en: Summarizing UNODC crime data
  id: totrans-277
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 汇总UNODC犯罪数据
- en: 'If we load the data and filter it for the crime of "burglary", we can get the
    summary statistics for those fields as follows:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们加载数据并过滤“盗窃”犯罪，我们可以如下获取这些字段的汇总统计：
- en: '[PRE31]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'And if we pick apart the data structures that it outputs, the following are
    the summary statistics for the primary data fields:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们分解它输出的数据结构，以下是对主要数据字段的摘要统计：
- en: '| Column | Minimum | Maximum | Mean | Median |'
  id: totrans-281
  prefs: []
  type: TYPE_TB
  zh: '| 列 | 最小值 | 最大值 | 平均值 | 中位数 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-282
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| **Rate** | 0.1 | 1939.23 | 376.4 | 292.67 |'
  id: totrans-283
  prefs: []
  type: TYPE_TB
  zh: '| **比率** | 0.1 | 1939.23 | 376.4 | 292.67 |'
- en: '| **Count** | 11 | 443010 | 60380 | 17184 |'
  id: totrans-284
  prefs: []
  type: TYPE_TB
  zh: '| **计数** | 11 | 443010 | 60380 | 17184 |'
- en: So, from the preceding table, we see that both fields have wide variance and
    are skewed somewhat, based on the differences between the means and the medians.
    These two having similar distributions is to be expected, since the rate is derived
    from the count.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，从前面的表中，我们看到这两个字段都有很大的变异性，并且有些偏斜，基于平均值和中位数之间的差异。这两个具有相似的分布是可以预料的，因为比率是从计数中派生出来的。
- en: Charts and graphs can also help to understand our data better. Incanter makes
    generating charts quite simple. Let's see how to do that.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 图表和图形也有助于更好地理解我们的数据。Incanter使生成图表变得相当简单。让我们看看如何做到这一点。
- en: 'First, we''ll load the data and pivot it, since that will make it easier to
    pull the data out of the graph. For this example, we''ll load the UNODC crime
    data joined to the World Bank land area data as follows:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将加载数据并旋转它，因为这将使从图表中提取数据更容易。在这个例子中，我们将加载与世界银行土地面积数据相结合的UNODC犯罪数据，如下所示：
- en: '[PRE32]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Next, we''ll filter the dataset to contain only the burglary data as shown
    in the following code:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将过滤数据集，只包含以下代码所示的盗窃数据：
- en: '[PRE33]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Finally, we use the `incanter.charts/histogram` function to create the graph,
    and the `incanter.core/view` function to display it to the screen with the following
    code:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们使用`incanter.charts/histogram`函数创建图表，并使用`incanter.core/view`函数以下代码将其显示在屏幕上：
- en: '[PRE34]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The following is the histogram of the `:count` field:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是对`:count`字段的直方图：
- en: '![Summarizing UNODC crime data](img/4139OS_07_11.jpg)'
  id: totrans-294
  prefs: []
  type: TYPE_IMG
  zh: '![总结UNODC犯罪数据](img/4139OS_07_11.jpg)'
- en: From this graph, we can see that this data does not follow a normal distribution.
    How does the other data correspond?
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 从这张图中，我们可以看到这些数据并不遵循正态分布。其他数据如何对应？
- en: Summarizing World Bank land area and GNI data
  id: totrans-296
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 总结世界银行土地面积和GNI数据
- en: 'We can use the same function, `incanter.stats/summary`, to generate the same
    statistics for the land area data that is given in the following table:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用相同的函数`incanter.stats/summary`来生成以下表格中给出的土地面积数据的相同统计信息：
- en: '| Column | Minimum | Maximum | Mean | Median |'
  id: totrans-298
  prefs: []
  type: TYPE_TB
  zh: '| 列 | 最小值 | 最大值 | 平均值 | 中位数 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-299
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| **Land area** | 300 | 16381390 | 822324 | 100250 |'
  id: totrans-300
  prefs: []
  type: TYPE_TB
  zh: '| **土地面积** | 300 | 16381390 | 822324 | 100250 |'
- en: '| **GNI** | 240 | 88500 | 17170 | 8140 |'
  id: totrans-301
  prefs: []
  type: TYPE_TB
  zh: '| **GNI** | 240 | 88500 | 17170 | 8140 |'
- en: 'The World Bank land area data has a distribution that is similar to the crime
    data. Smaller, less wealthy countries are, of course, more numerous. The distribution
    of the land area values is given as follows:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 世界银行土地面积数据的分布与犯罪数据相似。当然，较小、较不富裕的国家更多。土地面积值的分布如下所示：
- en: '![Summarizing World Bank land area and GNI data](img/4139OS_07_12.jpg)'
  id: totrans-303
  prefs: []
  type: TYPE_IMG
  zh: '![总结世界银行土地面积和GNI数据](img/4139OS_07_12.jpg)'
- en: 'The following is the distribution of the GNI values:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是对GNI值的分布：
- en: '![Summarizing World Bank land area and GNI data](img/4139OS_07_13.jpg)'
  id: totrans-305
  prefs: []
  type: TYPE_IMG
  zh: '![总结世界银行土地面积和GNI数据](img/4139OS_07_13.jpg)'
- en: 'This gives us some feel for the data. All of these follow an exponential distribution,
    as we can see in the next graph:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 这让我们对数据有了些了解。所有这些都遵循指数分布，正如我们可以在下一个图表中看到的那样：
- en: '![Summarizing World Bank land area and GNI data](img/4139OS_07_14.jpg)'
  id: totrans-307
  prefs: []
  type: TYPE_IMG
  zh: '![总结世界银行土地面积和GNI数据](img/4139OS_07_14.jpg)'
- en: This makes it clear that all graphs with exponential distribution start with
    a steep drop and quickly flatten out into a near-flat line.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 这清楚地表明，所有具有指数分布的图表都以陡峭的下降开始，并迅速平坦化成接近直线。
- en: Generating more charts and graphs
  id: totrans-309
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成更多图表和图形
- en: Some more charts can help us begin to understand the relationship between some
    of these variables. We'll write a function to plot any crime against the World
    Bank indicator data joined into the current dataset.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 一些更多的图表可以帮助我们开始理解这些变量之间的关系。我们将编写一个函数来绘制任何犯罪与世界银行指标数据结合到当前数据集中的关系图。
- en: 'First, however, we''ll need a utility function to filter the data rows by the
    crime. This is a data-oriented function, so we''ll store it in `nullh.data`, as
    shown in the following code:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要一个实用函数来根据犯罪过滤数据行。这是一个面向数据的函数，因此我们将它存储在`nullh.data`中，如下代码所示：
- en: '[PRE35]'
  id: totrans-312
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The next function, `plot-crime`, pulls out the data points and then passes
    everything to the `incanter.charts/scatter-plot` function to generate the graph:'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个函数 `plot-crime` 提取数据点，然后将所有内容传递给 `incanter.charts/scatter-plot` 函数以生成图表：
- en: '[PRE36]'
  id: totrans-314
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: This makes it easy to get a quick, visual comparison of data about different
    types of crimes and how they relate to the World Bank indicator data.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得快速、直观地比较不同类型犯罪的数据及其与世界银行指标数据的关系变得容易。
- en: 'For example, the following code shows us how the burglary ("CTS 2012 Burglary")
    relates to the land area data (the `plot-crime` function is in the `nullh.charts`
    namespace, which is aliased as `n-ch`):'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，以下代码显示了盗窃（"CTS 2012 Burglary"）与土地面积数据（`plot-crime` 函数位于 `nullh.charts` 命名空间中，别名为
    `n-ch`）之间的关系：
- en: '[PRE37]'
  id: totrans-317
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'The preceding code produces the following graph:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码生成以下图表：
- en: '![Generating more charts and graphs](img/4139OS_07_15.jpg)'
  id: totrans-319
  prefs: []
  type: TYPE_IMG
  zh: '![生成更多图表和图形](img/4139OS_07_15.jpg)'
- en: This data appears to have some strange artifacts. Look at the line of data points
    where the land area is around 9,000,000, stretching from about 500 burglaries
    per year to almost 1,000 burglaries. What is that about?
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 这组数据似乎有一些奇怪的特征。看看土地面积大约为 9,000,000 的数据点行，从每年约 500 起盗事件延伸到近 1,000 起盗事件。这是怎么回事？
- en: Well, when we think about it, the land area of a country rarely changes, but
    if a country has burglary data for several years, we'll have the land area represented
    those many times. We could simplify the data by getting the average of the data.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，当我们思考这个问题时，一个国家的土地面积很少改变，但如果一个国家有几年的盗窃数据，我们将多次表示该土地面积。我们可以通过获取数据的平均值来简化数据。
- en: 'In order to do this, we aggregate all of the year data for each country. To
    do that, we''ll use the following function:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 为了做到这一点，我们将每个国家的所有年度数据汇总。为此，我们将使用以下函数：
- en: '[PRE38]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: The preceding code uses the `incanter.core/$rollup` function to get each country's
    average for each data column. It then uses `reduce` and `incanter.core/$join`
    to fold the data back into one dataset.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码使用 `incanter.core/$rollup` 函数获取每个国家的每个数据列的平均值。然后使用 `reduce` 和 `incanter.core/$join`
    将数据折叠回一个数据集。
- en: 'When we graph aggregated data, we get the following graph:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们绘制汇总数据时，我们得到以下图表：
- en: '![Generating more charts and graphs](img/4139OS_07_16.jpg)'
  id: totrans-326
  prefs: []
  type: TYPE_IMG
  zh: '![生成更多图表和图形](img/4139OS_07_16.jpg)'
- en: This makes it clearer that there is probably no relationship between these two
    variables.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得这两个变量之间可能不存在关系的可能性更加明确。
- en: The following graph compares the burglary data to the GNI per capita. Since
    that indicator doesn't typically vary much over the time span represented in the
    data (China and a few other countries not withstanding), we have again aggregated
    each country's data.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表比较了盗窃数据与人均国民总收入。由于该指标通常在数据所代表的时间跨度内变化不大（中国和一些其他国家除外），我们再次汇总了每个国家的数据。
- en: '![Generating more charts and graphs](img/4139OS_07_17.jpg)'
  id: totrans-329
  prefs: []
  type: TYPE_IMG
  zh: '![生成更多图表和图形](img/4139OS_07_17.jpg)'
- en: This data appears to possibly have a correlation between these two variables,
    although it may not be very strong. This is something we can test.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 这组数据似乎在这两个变量之间存在某种相关性，尽管可能不是很强。这是我们能够测试的。
- en: Conducting the experiment
  id: totrans-331
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进行实验
- en: Now we're ready to frame and perform the experiment. Let's walk through the
    steps to do that one more time.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经准备好制定和执行实验。让我们再次回顾执行这些步骤。
- en: Formulating an initial hypothesis
  id: totrans-333
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 制定初步假设
- en: In this case, our hypothesis is that *there is a relationship between the per
    capita gross national income and the rate of burglaries*. We could go further
    and make the hypothesis stronger by specifying that higher GNI correlates to a
    higher burglary rate, somewhat counter-intuitively.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们的假设是*人均国民总收入与盗窃率之间存在关系*。我们可以进一步强化这个假设，具体说明更高的国民总收入与更高的盗窃率相关，这在某种程度上是反直觉的。
- en: Stating the null and alternative hypotheses
  id: totrans-335
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 提出零假设和备择假设
- en: Given that statement of our working hypothesis, we can now formulate the null
    and alternative hypotheses.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的工作假设陈述的基础上，我们现在可以制定零假设和备择假设。
- en: '*H[0]*: There is no relationship between the per capita gross national income
    and a country''s burglary rate.'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*H[0]*：人均国民总收入与国家的盗窃率之间没有关系。'
- en: '*H[1]*: There is a relationship between the per capita gross national income
    and the country''s burglary rate.'
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*H[1]*：人均国民总收入与国家的盗窃率之间存在关系。'
- en: These statements will now guide us through the rest of the process.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 这些陈述将引导我们完成剩余的过程。
- en: Identifying the statistical assumptions in the sample
  id: totrans-340
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 识别样本中的统计假设
- en: There are a number of assumptions in this data that we need to be aware of.
    First, since the crime data comes from multiple sources, there's going to be very
    little consistency in it.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个数据中，有一些假设我们需要注意。首先，由于犯罪数据来自多个来源，其中的一致性将非常小。
- en: To start with, the very definitions of these crimes may vary widely between
    different countries. Also, data collection procedures and practices will make
    the reliability of those numbers difficult.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，这些犯罪的定义在不同国家之间可能差异很大。此外，数据收集程序和实践将使这些数字的可靠性变得困难。
- en: The World Bank data is perhaps more consistent—things like land area can be
    measured and validated externally—but GNI can be reliant upon the own country's
    reporting, and that may often be inflated, as countries attempt to make themselves
    look more important and influential.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 世界银行的数据可能更一致——像土地面积这样的东西可以测量和外部验证——但国民总收入（GNI）可能依赖于本国自己的报告，而这可能经常被夸大，因为各国试图让自己看起来更重要、更有影响力。
- en: Moreover, there are also a lot of holes in the data. Because we haven't normalized
    the country names, there are no observations for the United States. It's listed
    as "United States" in one dataset and as "United States of America" in the other.
    And while this single instance would be simple to correct, we really have to do
    a more thorough audit of the country names.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，数据中还有很多漏洞。因为我们没有对国家名称进行标准化，所以没有美国的观测数据。在一个数据集中它被列为“United States”，而在另一个数据集中则被列为“United
    States of America”。虽然这个单一实例很容易纠正，但我们真的需要对国家名称进行更彻底的审计。
- en: So while there's nothing systematic that we need to take into account, there
    are several problems with the data that we need to keep in mind. We'll revisit
    these closer to the end of this chapter.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，虽然我们没有需要考虑的系统性的东西，但数据中存在几个问题，我们需要记住。我们将在本章末尾更详细地回顾这些问题。
- en: Determining which tests are appropriate
  id: totrans-346
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 确定适当的测试
- en: Now we have to determine which tests to run. Some tests are appropriate to different
    types of data and to different distributions of data. For example, nominal and
    numeric data require very different analyses.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们必须确定要运行哪些测试。有些测试适用于不同类型的数据和不同的数据分布。例如，名义数据和数值数据需要非常不同的分析。
- en: If the relationship were known to be linear, we could use Pearson's correlation
    coefficient. Unfortunately, the relationship in our data appears to be more complicated
    than that.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 如果关系已知是线性的，我们可以使用皮尔逊相关系数。不幸的是，我们数据中的关系似乎比这更复杂。
- en: In this case, our data is continuous numeric data. And we're interested in the
    relationship between two variables, but neither is truly independent, because
    we're not really sure exactly how the *sampling* was done, based on the description
    of the assumptions given earlier.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们的数据是连续的数值数据。我们感兴趣的是两个变量之间的关系，但它们都不是真正独立的，因为我们根据前面给出的假设描述，并不真正确定采样是如何进行的。
- en: Because of all these factors, we'll use Spearman's rank correlation.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 由于所有这些因素，我们将使用斯皮尔曼秩相关。
- en: How did I pick this? It's fairly simple, but just complicated enough that we
    will not go into the details here.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 我是如何选择的？这相当简单，但复杂到我们不会在这里详细介绍细节。
- en: The main point is that which statistical test you use is highly dependent on
    the nature of your data. Much of this knowledge comes from learning and experience,
    but once you've determined your data, a good statistical textbook or any of a
    number of online flowcharts can help you pick the right test.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 主要观点是，你使用的统计测试很大程度上取决于你数据的性质。这部分知识主要来自学习和经验，但一旦你确定了你的数据，一本好的统计教科书或任何在线流程图都可以帮助你选择正确的测试。
- en: But what is Spearman's rank correlation? Let's take a minute and find out.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 但斯皮尔曼秩相关系数是什么？让我们花一分钟时间来了解一下。
- en: Understanding Spearman's rank correlation coefficient
  id: totrans-354
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 理解斯皮尔曼秩相关系数
- en: Spearman's rank correlation coefficient measures the association between two
    variables. It is particularly useful when only the rank of the data is known,
    but it can also be useful in other situations. For instance, it isn't thrown off
    by outliers, because it only looks at the rank.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 斯皮尔曼秩相关系数衡量两个变量之间的关联。当只有数据的秩是已知的时候，它特别有用，但它也可以在其他情况下有用。例如，它不会被异常值所影响，因为它只看秩。
- en: 'The formula for this statistic is as follows:'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 这个统计量的公式如下：
- en: '![Understanding Spearman''s rank correlation coefficient](img/4139OS_07_18.jpg)'
  id: totrans-357
  prefs: []
  type: TYPE_IMG
  zh: '![理解斯皮尔曼秩相关系数](img/4139OS_07_18.jpg)'
- en: The value of *n* is the size of the sample. The value of *d* is each observation's
    difference in rank for the two variables. For example, in the data we've been
    looking at, Denmark ranks first for burglary (interesting), but third for per
    capita GNI. So Spearman's rank correlation would look at *3 – 1 = 2*.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: '*n* 的值是样本的大小。*d* 的值是两个变量每个观测值的等级差。例如，在我们一直在看的数据中，丹麦在盗窃方面排名第一（有趣），但在人均 GNI 方面排名第三。因此，斯皮尔曼等级相关系数将查看
    *3 – 1 = 2*。'
- en: 'A coefficient of *0* means there is no relationship between the two variables,
    and a coefficient of *-1* or *+1* means that the two variables are perfectly related.
    That is, the data can be perfectly described using a **monotonic** function: a
    function from one variable to the other that preserves the order of the items.
    The function doesn''t have to be linear. In fact, it could easily describe a curve.
    But it does capture the data.'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: '*0* 系数表示两个变量之间没有关系，而 *-1* 或 *+1* 系数表示两个变量完全相关。也就是说，数据可以用一个 **单调** 函数完美描述：一个从变量到另一个变量的函数，它保留了项目的顺序。该函数不必是线性的。事实上，它很容易描述一个曲线。但它确实捕捉了数据。'
- en: 'The coefficient doesn''t give us statistical significance (the *p* value),
    however. To get that, we just need to know that the Spearman''s rank correlation
    coefficient is distributed approximately normally, when *n ≥ 10*. It has a mean
    of *0* and a standard deviation given as follows:'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 系数并没有给我们统计显著性（*p* 值）。为了得到它，我们只需要知道当 *n ≥ 10* 时，斯皮尔曼等级相关系数近似服从正态分布。它的均值为 *0*，标准差如下所示：
- en: '![Understanding Spearman''s rank correlation coefficient](img/4139OS_07_19.jpg)'
  id: totrans-361
  prefs: []
  type: TYPE_IMG
  zh: '![理解斯皮尔曼等级相关系数](img/4139OS_07_19.jpg)'
- en: With these formulae, we can compute the *z* score of coefficient for our test.
    The *z* score is the distance of a data point from the mean, measured in standard
    deviations. The *p* value is closely related to the *z* score. So if we know the
    *z* score, we also know the *p* value.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些公式，我们可以计算测试系数的 *z* 分数。*z* 分数是数据点与均值的距离，以标准差为单位。*p* 值与 *z* 分数密切相关。因此，如果我们知道
    *z* 分数，我们也知道 *p* 值。
- en: Selecting the significance level
  id: totrans-363
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 选择显著性水平
- en: Now we need to select how high of a bar we need the significance to rise to.
    The target *p* value is known as the *α* value. In general, *α = 0.05* is commonly
    used, although if you want to be extra careful, *α = 0.01* is also normal.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们需要选择显著性需要达到多高的标准。目标 *p* 值被称为 *α* 值。通常，*α = 0.05* 是常用的，尽管如果你想要更加小心，*α =
    0.01* 也是正常的。
- en: For this test, we'll just use *α = 0.05*.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个测试，我们将使用 *α = 0.05*。
- en: Determining the critical region
  id: totrans-366
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 确定临界区域
- en: We'll accept any kind of relationship for rejecting the null hypothesis, so
    this will be a two-tailed test. That means that the critical region will come
    from both sides of the curve, with their areas being 0.05 divided equally for
    0.025 on each side.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 为了拒绝零假设，我们将接受任何类型的关系，因此这将是一个双尾测试。这意味着临界区域将来自曲线的两侧，其面积被平均分配到每侧的 0.025。
- en: This corresponds to a *z* score of *z < -1.96* or *z > 1.96*.
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 这对应于一个 *z* 分数小于 *-1.96* 或大于 *1.96*。
- en: Calculating the test statistic and its probability
  id: totrans-369
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 计算测试统计量和其概率
- en: We can use Incanter's function, `incanter.stats/spearmans-rho`, to calculate
    the Spearman's coefficient. However, it doesn't only calculate the *z* score.
    We can easily create the following function that wraps all of these calculations.
    We'll put this into `src/nullh/stats.clj`. We'll name the function `spearmans`.
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 Incanter 的函数 `incanter.stats/spearmans-rho` 来计算斯皮尔曼系数。然而，它不仅计算 *z* 分数。我们可以轻松创建以下封装所有这些计算的函数。我们将将其放入
    `src/nullh/stats.clj`。我们将命名该函数为 `spearmans`。
- en: '[PRE39]'
  id: totrans-371
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Now, we can run this on the dataset. Let''s start from the beginning and load
    the datasets from the disk with the following commands:'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以在数据集上运行这个测试。让我们从开始，使用以下命令从磁盘加载数据集：
- en: '[PRE40]'
  id: totrans-373
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: The preceding commands allowed us to see the process from front to back, and
    we can take the output and consider how the test went.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的命令使我们能够从前到后查看过程，我们可以考虑输出结果来了解测试情况。
- en: Deciding whether to reject the null hypothesis or not
  id: totrans-375
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 决定是否拒绝零假设
- en: The final *z*-score was 16.03\. Going by the book, a *z*-score this high is
    usually not even included on the charts. This would be a significant result, which
    would allow us to reject the null hypothesis. So, from this we can conclude that
    there is a relationship between the per capita GNI and the burglary rate.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 最终的 *z* 分数是 16.03。按照书本上的说法，这么高的 *z* 分数通常甚至不会包含在图表中。这将是一个显著的结果，这将使我们能够拒绝零假设。因此，我们可以得出结论，人均
    GNI 与盗窃率之间存在关系。
- en: Interpreting the results
  id: totrans-377
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结果的解释
- en: Of course, the results don't tell us a whole lot. For one, we have to remember
    that just because there's a relationship, that doesn't imply causality. Moreover,
    because the result is so significant, we should probably be skeptical about the
    results and whether they're caused by some artifact in the data or the procedures.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，结果并没有告诉我们太多。首先，我们必须记住，仅仅因为存在关系，并不意味着因果关系。此外，由于结果非常显著，我们可能应该对结果及其是否由数据或程序中的某些错误引起持怀疑态度。
- en: We've already talked about the problems in the data, and some of them may be
    at fault. Particularly, some of the data is missing because of normalization problems,
    which may change the results. Another possibility is that industrialized nations
    keep better records, so they would appear to have more burglaries.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经讨论了数据中的问题，其中一些可能是有责任的。特别是，由于标准化问题，一些数据缺失，这可能会改变结果。另一种可能性是，工业化国家记录得更好，因此它们似乎有更多的盗窃案。
- en: Summary
  id: totrans-380
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: So, in this chapter, we learned how null hypothesis testing can help us structure
    our analyses. Having a well thought out and standard procedure also ensures that
    we are thorough in our analysis. For example, in this chapter, we were forced
    to confront the ugly truths about the data we were working with, and that gave
    us insights into the results that we achieved later.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在本章中，我们学习了如何通过零假设检验来帮助我们构建分析。有一个经过深思熟虑和标准化的程序也确保我们在分析中是彻底的。例如，在本章中，我们被迫面对我们所处理的数据的丑陋真相，这使我们对我们后来取得的结果有了深刻的见解。
- en: In the next chapter, we'll actually get a chance to use these techniques again,
    when we look at conducting A/B testing on websites.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将有机会再次使用这些技术，当我们研究在网站上执行 A/B 测试时。
