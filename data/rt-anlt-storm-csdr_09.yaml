- en: Chapter 9. Storm Management and Maintenance
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第9章。风暴管理和维护
- en: In this chapter, you will understand scaling of the Storm cluster. You will
    also see how to adapt the Storm topology worker and parallelism.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将了解Storm集群的扩展。您还将看到如何调整Storm拓扑的工作节点和并行性。
- en: 'We will cover the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将涵盖以下主题：
- en: Adding new supervisor nodes
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加新的监督员节点
- en: Setting up workers and parallelism to enhance processing
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置工作节点和并行性以增强处理
- en: Troubleshooting
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 故障排除
- en: Scaling the Storm cluster – adding new supervisor nodes
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 扩展Storm集群-添加新的监督员节点
- en: 'In production, one of the most common scenarios one can run into is when the
    processing need outgrows the size of the cluster. Scaling then becomes necessary;
    there are two options: we can perform vertical scaling wherein we can add more
    compute capability, or we can use horizontal scaling where we add more nodes.
    The latter is more cost-effective and also makes the cluster more robust.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在生产中，最常见的情况之一是处理需求超过了集群的大小。此时需要进行扩展；有两种选择：我们可以进行垂直扩展，在其中可以添加更多的计算能力，或者我们可以使用水平扩展，在其中添加更多的节点。后者更具成本效益，也使集群更加健壮。
- en: 'Here are the steps to be executed to add a new node to the Storm cluster:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是要执行的步骤，以将新节点添加到Storm集群中：
- en: Download and install the 0.9.2 version of Storm as it is used in the rest of
    the cluster by extracting the downloaded ZIP file.
  id: totrans-9
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载并安装Storm的0.9.2版本，因为它是集群中其余部分使用的，通过解压下载的ZIP文件。
- en: 'Create the required directories:'
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建所需的目录：
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: All Storm nodes, the Nimbus nodes, and the supervisor require a location on
    to store a small amount of data related to configurations on the local disk. Please
    ensure you create the directory and assign read/write permissions on all Storm
    nodes.
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 所有Storm节点、Nimbus节点和监督员都需要一个位置来存储与本地磁盘上的配置相关的少量数据。请确保在所有Storm节点上创建目录并分配读/写权限。
- en: 'Create the required directories for the logs, as follows:'
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建日志所需的目录，如下所示：
- en: '[PRE1]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Update the `storm.yaml` file with necessary changes for Nimbus and Zookeeper:'
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新`storm.yaml`文件，对Nimbus和Zookeeper进行必要的更改：
- en: '[PRE2]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The values of the slots of the supervisor ports are as follows:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 监督员端口的插槽值如下：
- en: '| `supervisor.slots.ports` |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| `supervisor.slots.ports` |'
- en: '| - 6700 |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| - 6700 |'
- en: '| - 6701 |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| - 6701 |'
- en: '| - 6702 |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| - 6702 |'
- en: '| - 6703 |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| - 6703 |'
- en: 'Set the `STORM_HOME` environment in the `~/.bashrc` file and add Storm''s `bin`
    directory in the `PATH` environment variable. This is added to execute Storm binaries
    from any location. The entry to be added is as follows:'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`~/.bashrc`文件中设置`STORM_HOME`环境，并将Storm的`bin`目录添加到`PATH`环境变量中。这样可以从任何位置执行Storm二进制文件。要添加的条目如下：
- en: '[PRE3]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Update `/etc/hosts` on each of the following machines and the node:'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在以下每台机器和节点上更新`/etc/hosts`：
- en: 'The nimbus machine: This is done to add an entry for the new supervisor that''s
    being added'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: nimbus机器：这是为了为正在添加的新监督员添加条目
- en: 'All existing supervisor machines: This is done to add an entry for the new
    supervisor that''s being added'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有现有的监督员机器：这是为了为正在添加的新监督员添加条目
- en: 'The new supervisor node: This is done to add the nimbus entry, to add the entry
    for all other supervisors, and to add an entry for the Zookeeper node'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 新的监督员节点：这是为了添加nimbus条目，为所有其他监督员添加条目，并为Zookeeper节点添加条目
- en: '[PRE4]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Once the supervisor has been added, start the process and it should be visible
    on the UI, as shown in the following screenshot:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦监督员被添加，启动进程，它应该在UI上可见，如下面的截图所示：
- en: '![Scaling the Storm cluster – adding new supervisor nodes](img/00057.jpeg)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![扩展Storm集群-添加新的监督员节点](img/00057.jpeg)'
- en: Note that the first row in the preceding screenshot points to the newly added
    supervisor; it has 16 slots in total and `0` slots are being used as it has been
    just added to the cluster.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，前面截图中的第一行指向新添加的监督员；它总共有16个插槽，目前使用`0`个插槽，因为它刚刚添加到集群中。
- en: Scaling the Storm cluster and rebalancing the topology
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 扩展Storm集群和重新平衡拓扑
- en: Once a new supervisor is added, the next obvious step would be to rebalance
    the topologies, which are executed on the cluster so that the load could be shared
    across to the newly added supervisor.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦添加了新的监督员，下一个明显的步骤将是重新平衡在集群上执行的拓扑，以便负载可以在新添加的监督员之间共享。
- en: Rebalancing using the GUI
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用GUI重新平衡
- en: 'Rebalance option is available on the Nimbus UI where you can choose the topology
    that is to be rebalanced, and then use the option from the GUI. The topology drains
    as per the specified time-out. During that duration, it stops accepting any messages
    from the spout and the ones in the internal queues are processed and once completely
    clear, the workers and tasks are redistributed. The user also has option to increase
    or decrease the parallelism for various bolts and spouts using the rebalance options.
    The following screenshot describes how to rebalance a topology using the Storm
    UI options:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 重新平衡选项在Nimbus UI上可用，您可以选择要重新平衡的拓扑，然后使用GUI中的选项。拓扑会根据指定的超时时间排空。在此期间，它停止接受来自spout的任何消息，并处理内部队列中的消息，一旦完全清除，工作节点和任务将重新分配。用户还可以使用重新平衡选项增加或减少各种螺栓和spout的并行性。以下截图描述了如何使用Storm
    UI选项重新平衡拓扑：
- en: '![Rebalancing using the GUI](img/00058.jpeg)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![使用GUI重新平衡](img/00058.jpeg)'
- en: Rebalancing using the CLI
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用CLI重新平衡
- en: 'The second option for rebalancing is using the Storm CLI. The command for this
    is as follows:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 重新平衡的第二个选项是使用Storm CLI。其命令如下：
- en: '[PRE6]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Here, `–n` specifies the number of workers allocated to the topology post-rebalance,
    `-e my-spout` refers to parallelism assigned to the spout, and similarly `–e my-bolt`
    refers to parallelism to be assigned to the bolt. In the preceding command, we
    executed the Storm shell from the `bin` directory under the Storm installation
    JAR, and while rebalancing the Storm topology by changing the parallelism of the
    spout and bolts as well.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`-n`指定了重新平衡后分配给拓扑的工作器数量，`-e my-spout`指的是分配给spout的并行性，同样`-e my-bolt`指的是要分配给螺栓的并行性。在前面的命令中，我们从Storm安装JAR的`bin`目录下执行了Storm
    shell，并在重新平衡Storm拓扑时同时改变了spout和螺栓的并行性。
- en: The changes to the execution of the preceding commands can be verified from
    the Storm UI.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 可以从Storm UI验证对前面命令的执行更改。
- en: Setting up workers and parallelism to enhance processing
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置工作器和并行性以增强处理
- en: 'Storm is a highly scalable, distributed, and fault tolerant real-time parallel
    processing compute framework. Note that the emphasis is on scalability, distributed,
    and parallel processing—well, we already know that Storm operates in clustered
    mode and is therefore distributed in its basic nature. Scalability was covered
    in the previous section; now, let''s have a closer look at parallelism. We introduced
    you to this concept in an earlier chapter, but now we''ll get you acquainted with
    how to tweak it to achieve the desired performance. The following points are the
    key criteria for this:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: Storm是一个高度可扩展、分布式和容错的实时并行处理计算框架。请注意，重点是可扩展性、分布式和并行处理——好吧，我们已经知道Storm以集群模式运行，因此在基本性质上是分布式的。可扩展性在前一节中已经涵盖了；现在，让我们更仔细地看看并行性。我们在早些时候的章节中向您介绍了这个概念，但现在我们将让您了解如何调整它以实现所需的性能。以下几点是实现这一目标的关键标准：
- en: A topology is allocated a certain number of workers at the time it's started.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 拓扑在启动时被分配了一定数量的工作器。
- en: Each component in the topology (bolts and spouts) has a specified number of
    executors associated with it. These executors specify the number or degree of
    parallelism for each running component of the topology.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 拓扑中的每个组件（螺栓和spout）都有指定数量的执行者与之关联。这些执行者指定了拓扑的每个运行组件的并行性数量或程度。
- en: 'The whole efficiency and speed factor of Storm are driven by the parallelism
    feature of Storm, but we need to understand one thing: all the executors that
    attribute to parallelism are running within the limited set of workers allocated
    to the topology. So, one needs to understand that increasing the parallelism would
    help achieve efficiency only to a point, but beyond that the executors will struggle
    for resource is the intention. Going beyond this increasing parallelism would
    not fetch efficiency, but increasing the workers allocated to the topology would
    would make computation efficient.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Storm的整体效率和速度因素都受Storm的并行性特性驱动，但我们需要明白一件事：所有归因于并行性的执行者都在拓扑分配的有限工作器集合内运行。因此，需要理解增加并行性只能在一定程度上提高效率，但超过这一点后，执行者将争夺资源。超过这一点增加并行性将无法提高效率，但增加分配给拓扑的工作器将使计算更加高效。
- en: Another point to understand in terms of efficiency is network latency; we'll
    explore this in the following sections.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在效率方面，另一个需要理解的点是网络延迟；我们将在接下来的部分中探讨这一点。
- en: Scenario 1
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 场景1
- en: 'This following figure illustrates a simple topology with three moving components:
    one spout and two bolts. Here, all the components are executing on separate nodes
    in the cluster, thus every tuple has to do two network hops to complete its execution.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示了一个简单的拓扑，有三个移动组件：一个spout和两个螺栓。在这里，所有组件都在集群中的不同节点上执行，因此每个元组必须经过两次网络跳转才能完成执行。
- en: '![Scenario 1](img/00059.jpeg)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![场景1](img/00059.jpeg)'
- en: 'Let''s say we are not satisfied with the throughput and decide to increase
    the parallelism. The moment we try to move into this technique, the question that
    arises is where to increase it and by how much. That could be computed based on
    the capacity of the bolt, which should be visible from the Storm UI. The following
    screenshot illustrates this:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们对吞吐量不满意，并决定增加并行性。一旦我们尝试采用这种技术，就会出现一个问题，即在哪里增加以及增加多少。这可以根据螺栓的容量来计算，这应该可以从Storm
    UI中看到。以下截图说明了这一点：
- en: '![Scenario 1](img/00060.jpeg)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![场景1](img/00060.jpeg)'
- en: Here, the circled value is the capacity of the second bolt, which is around
    0.9 and it's already in red, which means this bolt is over-worked and increasing
    parallelism here should help. Any topology would actually break and stop acking
    when the bolt capacity crosses `1`. To fix this, let's see the next scenario,
    which provides a solution for this issue.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，圈出的值是第二个螺栓的容量，大约为0.9，已经是红色的，这意味着这个螺栓超负荷工作，增加并行性应该有所帮助。任何拓扑实际上都会在螺栓容量超过`1`时中断并停止确认。为了解决这个问题，让我们看看下一个场景，为这个问题提供一个解决方案。
- en: Scenario 2
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 场景2
- en: 'Here, we have acted on the realization that **Bolt B** is overloaded and has
    increased the parallelism, as shown in the following figure:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们已经意识到**Bolt B**超负荷，并增加了并行性，如下图所示：
- en: '![Scenario 2](img/00061.jpeg)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![场景2](img/00061.jpeg)'
- en: The preceding figure describes one scenario capturing the distribution of various
    instances of the bolts and spouts across different nodes in the cluster. Here,
    we have acted on the realization that a bolt is overloaded and we observed the
    capacity, and by brute force, increased the parallelism of only that bolt.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的图描述了一个场景，捕捉了集群中不同节点上各种螺栓和spout实例的分布。在这里，我们已经意识到一个螺栓超负荷，并观察了容量，通过强制手段，只增加了该螺栓的并行性。
- en: 'Now, having done this, we have achieved the required parallelism; let''s now
    have a look at the network latency, in terms of how many tuples are moving between
    nodes (internode communication is a mandatory element in a distributed computing
    setup):'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，做到了这一点，我们已经实现了所需的并行性；现在让我们来看看网络延迟，即元组在节点之间移动的数量（节点间通信是分布式计算设置中的一个必要元素）：
- en: 50 percent of the traffic is hopping between spouts on **Machine 1** and **Machine
    2**
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 50％的流量在**Machine 1**和**Machine 2**之间跳转
- en: 50 percent of the traffic is hopping between **Machine 1** and **Machine 3**
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 50％的流量在**Machine 1**和**Machine 3**之间跳转
- en: 100 percent of the traffic is hopping between **Machine 2** and **Machine 3**
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 100％的流量在**Machine 2**和**Machine 3**之间跳转
- en: Now let's see another illustration with a slight variation in the parallelism.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看另一个示例，稍微改变并行性。
- en: Scenario 3
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 场景3
- en: 'The scenario 3 is the most optimal scenario that is possible in the setup in
    the example where we use network and parallelism very efficiently, as shown in
    the following figure:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 场景3是在示例设置中可能出现的最佳场景，我们可以非常有效地使用网络和并行性，如下图所示：
- en: '![Scenario 3](img/00062.jpeg)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![场景3](img/00062.jpeg)'
- en: Now, the preceding figure is an illustration of where we get the maximum benefit
    of parallelism usage. If you look at the preceding figure, you'll see that we
    have achieved efficiency and no network hop; the best of both the worlds.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，上图是一个示例，展示了我们如何最大程度地利用并行性。如果您看一下上图，您会发现我们已经实现了效率，没有网络跳数；两全其美。
- en: What I am trying to illustrate is that parallelism should be changed judicially
    keeping the impact of network latency, hops, and the speed of localized processing
    in mind.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我试图说明的是，并行性应该在考虑网络延迟、跳数和本地处理速度的影响下进行审慎更改。
- en: Storm troubleshooting
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Storm故障排除
- en: 'As developers, we need to accept the reality that things do go wrong and debugging
    is required. This section is going to equip you to handle such situations effectively
    and efficiently. The first thing is to understand two root mantras of the programming
    world:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 作为开发人员，我们需要接受现实，事情确实会出错，需要调试。本节将使您能够有效和高效地处理这种情况。首先要理解编程世界的两个根本口诀：
- en: Work as if everything that could break will break
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 假设一切可能出问题的地方都会出问题
- en: Anything that could break can be fixed
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任何可能出现问题的地方都可以修复
- en: Having accepted the reality, let's address the situation first by understanding
    what could fail and then have a clear understanding of where we should start the
    analysis to help us handle any situation with the Storm cluster. Let's get to
    grips with the various pointers that show us the problems and thus guide us to
    prospective solutions.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 接受现实，首先通过了解可能出现问题的地方，然后清楚地了解我们应该从哪里开始分析，以帮助我们处理Storm集群中的任何情况。让我们了解一下各种指针，显示出问题，并引导我们找到潜在的解决方案。
- en: The Storm UI
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Storm UI
- en: First of all, let's understand which statistics and indicators are present on
    the UI itself. The latest UI has scores of indicators that give us an insight
    into what is going on in the cluster and what could go wrong (just in case things
    break).
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们了解UI本身存在哪些统计数据和指标。最新的UI有大量指标，让我们洞悉集群中正在发生的事情以及可能出现问题的地方（以防出现故障）。
- en: 'Let''s look at Storm UI where the **Cluster Summary** entails, for example,
    `http:// ip of nimbus:8080` in my case is `http://10.4.2.122:8080` and my UI process
    executes on the nimbus machine that has this IP: 10.4.2.122.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下Storm UI，其中**Cluster Summary**包括，例如，`http:// nimbus的IP:8080`在我的情况下是`http://10.4.2.122:8080`，我的UI进程在具有此IP的nimbus机器上执行：10.4.2.122。
- en: '![The Storm UI](img/00063.jpeg)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![Storm UI](img/00063.jpeg)'
- en: 'In the preceding screenshot, we can see the following parameters:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的屏幕截图中，我们可以看到以下参数：
- en: The version of Storm being used is in the first column.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用的Storm版本在第一列中。
- en: The uptime of Nimbus (second column) tells us how long the Nimbus node has been
    running since the last restart. Nimbus, as we know, is required only at the time
    when the topology is submitted or when a supervisor or worker has gone down and
    the tasks are being delegated again. Nimbus is also required to be up during the
    rebalancing of the topology.
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nimbus的正常运行时间（第二列）告诉我们自上次重启以来Nimbus节点已经运行了多长时间。正如我们所知，Nimbus只在拓扑被提交时或监督者或工作人员下线并且任务再次被委派时才需要。在拓扑重平衡期间，Nimbus也是必需的。
- en: The third column gives us the number of supervisors on the cluster.
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第三列给出了集群中监督者的数量。
- en: Columns four, five, and six show the number of used worker slots, number of
    free worker slots, and total number of worker slots across the Storm supervisors.
    This is a very important statistic. In any production grade cluster, one should
    always have a provision for some of the workers going down or one or two supervisors
    being killed. So, I recommend that you always have enough free slots on your cluster
    to accommodate such sudden failures.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第四、五和六列显示了Storm监督者中已使用的工作槽的数量、空闲工作槽的数量和工作槽的总数。这是一个非常重要的统计数据。在任何生产级别的集群中，应该始终为一些工作人员下线或一两个监督者被杀死做好准备。因此，我建议您始终在集群上有足够的空闲槽，以容纳这种突发故障。
- en: Column seven and column eight specify the moving tasks in the topology, that
    is, in terms of the number of tasks and executors running in the system.
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第七列和第八列指定了拓扑中正在移动的任务，即系统中运行的任务和执行者的数量。
- en: 'Let''s have a look at the second section on the Storm UI opening page; this
    one captures the topology summary:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下Storm UI开启页面上的第二部分；这部分捕获了拓扑摘要：
- en: '![The Storm UI](img/00064.jpeg)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![Storm UI](img/00064.jpeg)'
- en: 'This section depicts various parameters Storm captures and displays at the
    topology level:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 本节描述了Storm在拓扑级别捕获和显示的各种参数：
- en: Column one and column two display the **Name** field of the topology and the
    **Id** field of topology, respectively.
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一列和第二列分别显示了拓扑的**Name**字段和拓扑的**Id**字段。
- en: Column three reads the status of the topology, which is **ACTIVE** for a topology
    that's executing and processing.
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第三列显示了拓扑的状态，对于正在执行和处理的拓扑来说，状态是**ACTIVE**。
- en: Column four displays the uptime since the topology has been started.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第四列显示了自拓扑启动以来的正常运行时间。
- en: The next three columns display **Numworkers**, **Num tasks**, and **Num executors**;
    these are very important aspects for the performance of the topology. While tuning
    the performance, one has to realize that just increasing the **Num tasks** and
    **Num executors** field value may not result in greater efficiency. If the number
    of workers is low, and we just increase the number of executors and tasks, then
    the starvation of resource high because of the limited number of workers, so the
    topology performance will deteriorate.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接下来的三列显示**Numworkers**，**Num tasks**和**Num executors**；这些是拓扑性能的非常重要的方面。在调整性能时，人们必须意识到仅仅增加**Num
    tasks**和**Num executors**字段的值可能不会导致更高的效率。如果工作人员的数量很少，而我们只增加执行器和任务的数量，那么由于工作人员数量有限，资源的匮乏会导致拓扑性能下降。
- en: Similarly, if we assign too many workers to a topology with not enough executors
    and tasks to utilize all of them, we'd waste the precious resources by keeping
    them blocked and idle.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，如果我们将太多的工作人员分配给一个拓扑结构，而没有足够的执行器和任务来利用所有这些工作人员，我们将浪费宝贵的资源，因为它们被阻塞和空闲。
- en: On the other hand, if we have a high number of workers and a high number of
    executors and tasks, the chances are that performance may degrade due to network
    latency.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，如果我们有大量的工作人员和大量的执行器和任务，那么由于网络延迟，性能可能会下降。
- en: Having stated these facts, I want to emphasize the fact that the performance
    tuning should be done cautiously and judiciously to arrive at what number works
    for the use case we are trying to implement.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在陈述了这些事实之后，我想强调性能调优应该谨慎和审慎地进行，以确定适用于我们正在尝试实施的用例的数量。
- en: 'The following screenshot captures the details about the supervisors, in terms
    of the statistics, with the corresponding information:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图捕获了有关监督者的详细信息，以及相应信息的统计数据：
- en: '![The Storm UI](img/00065.jpeg)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![The Storm UI](img/00065.jpeg)'
- en: Column one has the **Id** field for the supervisors, and column two has the
    names of the **hosts** field that have supervisor processes running.
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一列是**Id**字段，用于监督者，第二列是运行监督者进程的**hosts**字段的名称。
- en: Column three captures the amount of time the supervisor has been running for.
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第三列显示了监督者运行的时间。
- en: Columns five and six capture the number of slots available on the supervisor
    and the number of slots used respectively. These two numbers provide a very important
    metric in terms of how many slots are available and how many are used. They help
    us judge and understand what capacity the supervisors are operating at and how
    much bandwidth they have to handle the scenarios of failures; for instance, all
    my supervisors are operating at 100 percent capacity, so in that case, my cluster
    can't handle any failures.
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第五列和第六列分别捕获了监督者上可用插槽的数量和已使用的插槽的数量。这两个数字在判断和理解监督者的运行容量以及它们处理故障情况的带宽方面提供了非常重要的指标；例如，我的所有监督者都以100%的容量运行，所以在这种情况下，我的集群无法处理任何故障。
- en: 'The following screenshot is captured from the Storm UI depicting supervisors
    and their attributes:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图是从Storm UI中捕获的，显示了监督者及其属性：
- en: '![The Storm UI](img/00066.jpeg)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![The Storm UI](img/00066.jpeg)'
- en: 'The preceding section gives us details about the supervisor slots, timeouts,
    and so on. These values are specified on `storm.yaml`, but can be verified from
    the UI. For example, `http:// ip of nimbus:8080` in my case is `http://10.4.2.122:8080`,
    and my UI process executes on the Nimbus machine that has this IP: 10.4.2.122,
    as shown in the following screenshot:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的部分为我们提供了有关监督者插槽、超时等的详细信息。这些值在`storm.yaml`中指定，但可以从UI中验证。例如，在我的情况下，`http://
    nimbus的IP:8080`是`http://10.4.2.122:8080`，我的UI进程在具有此IP的Nimbus机器上执行：10.4.2.122，如下图所示：
- en: '![The Storm UI](img/00067.jpeg)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![The Storm UI](img/00067.jpeg)'
- en: 'Now in the section depicted in the following screenshot one can get into by
    drilling deeper into the topology details. This can be achieved on the Storm UI
    by clicking on any of the topology names. This section holds the details about
    the components of the topology including the level of bolts, spouts, and details
    about them, as shown in the following screenshot:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在下面的截图所示的部分中，可以通过在Storm UI上单击任何拓扑名称来深入了解拓扑详细信息。这一部分包含了有关拓扑组件的详细信息，包括螺栓、喷口的级别以及有关它们的详细信息，如下图所示：
- en: '![The Storm UI](img/00068.jpeg)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![The Storm UI](img/00068.jpeg)'
- en: The preceding screenshot has details ranging from the number of executors or
    tasks allocated to each component, to the number of tuples emitted by the bolts
    or spouts and the number of tuples transferred to the next component in the **Directed
    Acyclic Graph** (**DAG**).
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的截图显示了有关每个组件分配的执行器或任务数量，以及螺栓或喷口发射的元组数量以及传输到**有向无环图**（**DAG**）中下一个组件的元组数量。
- en: 'Other notable details one should observe on the topology detail page are as
    follows:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 拓扑详细页面上应该注意的其他重要细节如下：
- en: '**Capacity** of bolts in the last 10 minutes: This should be well below 1.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 过去10分钟内螺栓的**容量**：这个值应该远低于1。
- en: '**Execute latency** is time in milliseconds: This determines how long it would
    take to execute a tuple through this component. If this value is too high, then
    we would probably want to break the execution into two or more bolts to utilize
    parallelism and have better efficiency.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**执行延迟**以毫秒为单位：这决定了通过该组件执行元组所需的时间。如果这个值太高，那么我们可能希望将执行分成两个或更多的螺栓，以利用并行性并提高效率。'
- en: '**Executed**: This stores the number of tuples executed successfully by this
    component.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**已执行**：这个值存储了该组件成功执行的元组数量。'
- en: '**Process latency**: This value displays the average total time taken to execute
    a tuple by the component. This value should be analyzed with the execute latency.
    These are practical cases that may happen:'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**处理延迟**：这个值显示了组件执行元组所需的平均总时间。这个值应该与执行延迟一起分析。以下是可能发生的实际情况：'
- en: '**Execute latency** and **Process latency** are both low (that''s the best
    possible case)'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**执行延迟**和**处理延迟**都很低（这是最理想的情况）'
- en: '**Execute latency** is low but process latency is very high (that means actual
    execution time is lower in comparison to the total execution time and increasing
    parallelism might help achieve efficiency)'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**执行延迟**很低，但**处理延迟**非常高（这意味着实际执行时间较短，与总执行时间相比较高，并且增加并行性可能有助于提高效率）'
- en: Both **Execute latency** and **Process latency** are high (again, increasing
    parallelism might help)
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**执行延迟**和**处理延迟**都很高（再次增加并行性可能有所帮助）'
- en: Storm logs
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Storm日志
- en: 'The next place to debug if things don''t go as expected is the Storm log. First
    of all, one needs to know the location for Storm logs, which also update the path
    on `cluster.xml` at `storm-0.9.2-incubating.zip\apache-storm-0.9.2-incubating\logback\cluster.xml`:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 如果事情不如预期，下一个调试的地方就是Storm日志。首先，需要知道Storm日志的位置，还需要在`cluster.xml`的`storm-0.9.2-incubating.zip\apache-storm-0.9.2-incubating\logback\cluster.xml`中更新路径：
- en: '[PRE7]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Now the line in bold gets you the path/location where the Storm logs will be
    created. Let's take a closer look to find out what kinds of logs are created by
    different Storm daemons.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 现在粗体字的那一行会告诉你Storm日志将被创建的路径/位置。让我们仔细看看不同Storm守护程序创建了哪些类型的日志。
- en: 'The Nimbus node logs can be obtained by using the following commands on shell:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用以下命令在shell上获取Nimbus节点日志：
- en: '[PRE8]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The listing of the Nimbus log directory is shown in the following screenshot:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: Nimbus日志目录的列表如下截图所示：
- en: '![Storm logs](img/00069.jpeg)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![Storm logs](img/00069.jpeg)'
- en: Notice that we have `nimbus.log`, which has details about Nimbus' startup, error,
    and info logs; `ui.log` is created on the node where we start the Storm UI application.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 注意我们有`nimbus.log`，其中包含有关Nimbus启动、错误和信息日志的详细信息；`ui.log`是在启动Storm UI应用程序的节点上创建的。
- en: 'The logs on the supervisor nodes can be obtained by using the following commands
    on shell:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用以下命令在shell上获取监督者节点的日志：
- en: '[PRE9]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The listing of the supervisor log directory is shown in the following screenshot:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 监督者日志目录的列表如下截图所示：
- en: '![Storm logs](img/00070.jpeg)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![Storm logs](img/00070.jpeg)'
- en: One can see supervisor logs and worker logs. The supervisor logs capture the
    details about the supervisor starting up, any errors, and so on. The worker logs
    are the ones where the developer's topology logs appear along with Storm logs
    for various bolts and spouts.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 可以查看监督者日志和工作日志。监督者日志记录了监督者启动的详细信息，任何错误等。工作日志是开发人员拓扑日志和各种螺栓和喷口的Storm日志所在的地方。
- en: So if we want to troubleshoot the Storm daemon processes, we would look at `nimbus.log`
    and `supervisor.log`. If you're having issues, then you need to debug using the
    corresponding worker log. The scenario of nimbus and worker node failures has
    been covered in [Chapter 4](part0032_split_000.html#page "Chapter 4. Storm in
    a Clustered Mode"), *Storm in a Clustered Mode*.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果我们想要调试Storm守护进程，我们会查看`nimbus.log`和`supervisor.log`。如果你遇到问题，那么你需要使用相应的工作日志进行调试。Nimbus和工作节点故障的情况已在[第4章](part0032_split_000.html#page
    "Chapter 4. Storm in a Clustered Mode")中进行了介绍，*集群模式下的Storm*。
- en: 'Now let''s imagine a scenario. I am a developer whose topology is not behaving
    as expected, and I doubt that one of the bolts is not functioning as expected.
    So we need to debug the worker logs and find the root cause. Now we need to find
    out which worker log to look at out of multiple supervisors and numerous worker
    logs; we''ll get this information from the Storm UI. Perform the following steps:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们想象一个场景。我是一个开发人员，我的拓扑结构表现不如预期，我怀疑其中一个螺栓的功能不如预期。因此，我们需要调试工作日志并找出根本原因。现在我们需要找出多个监督者和众多工作日志中要查看哪个工作日志；我们将从Storm
    UI中获取这些信息。执行以下步骤：
- en: Open **Storm UI** and click on the troublesome topology.
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开**Storm UI**并点击有问题的拓扑。
- en: Click on the suspected bolt or spout of the topology. A screen analogous to
    what is shown in this screenshot should appear:![Storm logs](img/00071.jpeg)
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击拓扑的疑似螺栓或喷口。屏幕上会出现与此截图相似的内容：![Storm logs](img/00071.jpeg)
- en: Here is the clue to debug what's happening in this bolt; I will look into `Supervisor5`
    and `Supervisor6`, of `worker-6705.log` on `supervisor5` and `supervisor6`.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 这是调试这个螺栓发生的情况的线索；我将查看`Supervisor5`和`Supervisor6`，`supervisor5`和`supervisor6`上的`worker-6705.log`。
- en: Quiz time
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测验时间
- en: 'Q.1\. State whether the following statements are true or false:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: Q.1\. 判断以下陈述是真还是假：
- en: Storm nodes can't be added to the cluster with topologies being executed.
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在执行拓扑的情况下，无法将Storm节点添加到集群中。
- en: A topology can't survive the Storm node failure.
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 拓扑无法在Storm节点故障时生存。
- en: Storm logs are created on each node in the cluster.
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Storm日志在集群中的每个节点上创建。
- en: The location of the Storm log creation is configurable.
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Storm日志创建的位置是可配置的。
- en: 'Q.2\. Fill in the blanks:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: Q.2\. 填空：
- en: _______________ is the heartbeat tracker of the cluster.
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: _______________是集群的心跳跟踪器。
- en: _______________ is the daemon that's mandatory for topology submission and rebalancing.
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: _______________是拓扑提交和重平衡所必需的守护程序。
- en: The ___________ file holds the worker configuration for the topology.
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ___________文件保存了拓扑的工作配置。
- en: 'Q.3\. Execute the following use cases to see the internals of Storm:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: Q.3\. 执行以下用例以查看Storm的内部情况：
- en: Start nimbus and check `nimbus.log` to see what a successful startup should
    look like.
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动Nimbus并检查`nimbus.log`，查看成功启动的情况。
- en: Start the supervisor and check `Supervisor.log` to see what a successful startup
    should look like.
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动监督者并检查`Supervisor.log`，查看成功启动的情况。
- en: Submit the topology, say a simple `WordCount` topology, and figure out the `worker.log`
    file creation.
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提交拓扑，比如一个简单的`WordCount`拓扑，并找出`worker.log`文件的创建情况。
- en: Update `log4j.properties` to change the logging level and verify its impact.
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新`log4j.properties`以更改日志级别并验证其影响。
- en: Summary
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we have covered the maintenance concepts of Storm in terms
    of adding new nodes, rebalancing, and killing topologies. We have understood and
    tweaked internals such as `numtasks` and parallelism in combination with to `numworkers`
    and network latency. You learned to locate and decipher logs of Storm components.
    You also understood the metrics of the Storm UI and their implications on topology
    performance.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们已经涵盖了Storm的维护概念，包括添加新节点、重新平衡和终止拓扑。我们已经了解并调整了诸如`numtasks`和并行性与`numworkers`和网络延迟相结合的内部机制。您学会了定位和解读Storm组件的日志。您还了解了Storm
    UI的指标及其对拓扑性能的影响。
- en: In the next chapter, we will discuss advanced concepts of Storm, including micro-batching
    and Trident APIs.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将讨论Storm的高级概念，包括微批处理和Trident API。
