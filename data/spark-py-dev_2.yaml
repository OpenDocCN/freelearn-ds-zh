- en: Chapter 2. Building Batch and Streaming Apps with Spark
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第2章。使用Spark构建批处理和流处理应用
- en: The objective of the book is to teach you about PySpark and the PyData libraries
    by building an app that analyzes the Spark community's interactions on social
    networks. We will gather information on Apache Spark from GitHub, check the relevant
    tweets on Twitter, and get a feel for the buzz around Spark in the broader open
    source software communities using **Meetup**.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的目标是通过构建一个应用程序来分析社交网络上Spark社区的互动，教会你关于PySpark和PyData库。我们将从GitHub收集有关Apache
    Spark的信息，在Twitter上检查相关的推文，并通过Meetup感受Spark在更广泛的开源软件社区中的热度。
- en: In this chapter, we will outline the various sources of data and information.
    We will get an understanding of their structure. We will outline the data processing
    pipeline, from collection to batch and streaming processing.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将概述各种数据和信息来源。我们将了解它们的结构。我们将概述从收集到批处理和流处理的数据处理流程。
- en: 'In this section, we will cover the following points:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们将涵盖以下要点：
- en: Outline data processing pipelines from collection to batch and stream processing,
    effectively depicting the architecture of the app we are planning to build.
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从收集到批处理和流处理的数据处理流程，有效地描述我们计划构建的应用程序的架构。
- en: Check out the various data sources (GitHub, Twitter, and Meetup), their data
    structure (JSON, structured information, unstructured text, geo-location, time
    series data, and so on), and their complexities. We also discuss the tools to
    connect to three different APIs, so you can build your own data mashups. The book
    will focus on Twitter in the following chapters.
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查看各种数据来源（GitHub、Twitter和Meetup）、它们的数据结构（JSON、结构化信息、非结构化文本、地理位置、时间序列数据等）以及它们的复杂性。我们还讨论了连接三种不同API的工具，这样你就可以构建自己的数据混搭。本书将在接下来的章节中重点关注Twitter。
- en: Architecting data-intensive apps
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 架构数据密集型应用
- en: 'We defined the data-intensive app framework architecture blueprint in the previous
    chapter. Let''s put back in context the various software components we are going
    to use throughout the book in our original framework. Here''s an illustration
    of the various components of software mapped in the data-intensive architecture
    framework:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在上一章中定义了数据密集型应用框架架构蓝图。让我们重新将我们原始框架中将在整本书中使用的各种软件组件放回到上下文中。以下是数据密集型架构框架中映射的各种软件组件的示意图：
- en: '![Architecting data-intensive apps](img/B03986_02_01.jpg)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![架构数据密集型应用](img/B03986_02_01.jpg)'
- en: Spark is an extremely efficient, distributed computing framework. In order to
    exploit its full power, we need to architect our solution accordingly. For performance
    reasons, the overall solution needs to also be aware of its usage in terms of
    CPU, storage, and network.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: Spark是一个非常高效的分布式计算框架。为了充分利用其功能，我们需要相应地设计我们的解决方案。出于性能原因，整体解决方案还需要考虑其在CPU、存储和网络方面的使用情况。
- en: 'These imperatives drive the architecture of our solution:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这些要求驱动我们解决方案的架构：
- en: '**Latency**: This architecture combines slow and fast processing. Slow processing
    is done on historical data in batch mode. This is also called data at rest. This
    phase builds precomputed models and data patterns that will be used by the fast
    processing arm once live continuous data is fed into the system. Fast processing
    of data or real-time analysis of streaming data refers to data in motion. Data
    at rest is essentially processing data in batch mode with a longer latency. Data
    in motion refers to the streaming computation of data ingested in real time.'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**延迟**：这种架构结合了慢速和快速处理。慢速处理是在批处理模式下对历史数据进行处理。这也被称为静态数据。这个阶段构建了将由快速处理部分在实时连续数据输入系统后使用的预先计算的模型和数据模式。数据的快速处理或实时分析是指处理运动中的数据。静态数据实际上是以批处理模式处理数据，具有较长的延迟。运动中的数据是指实时摄取的数据的流式计算。'
- en: '**Scalability**: Spark is natively linearly scalable through its distributed
    in-memory computing framework. Databases and data stores interacting with Spark
    need to be also able to scale linearly as data volume grows.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可扩展性**：Spark通过其分布式内存计算框架本身具有线性可扩展性。与Spark交互的数据库和数据存储也需要能够随着数据量的增长而线性扩展。'
- en: '**Fault tolerance**: When a failure occurs due to hardware, software, or network
    reasons, the architecture should be resilient enough and provide availability
    at all times.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**容错性**：当由于硬件、软件或网络原因发生故障时，架构应具有足够的弹性，并始终提供可用性。'
- en: '**Flexibility**: The data pipelines put in place in this architecture can be
    adapted and retrofitted very quickly depending on the use case.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**灵活性**：在这种架构中建立的数据流程可以根据用例迅速进行调整和改装。'
- en: Spark is unique as it allows batch processing and streaming analytics on the
    same unified platform.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: Spark独特之处在于它允许在同一统一平台上进行批处理和流式分析。
- en: 'We will consider two data processing pipelines:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将考虑两种数据处理流程：
- en: The first one handles data at rest and is focused on putting together the pipeline
    for batch analysis of the data
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一个处理静态数据，并专注于构建批量分析数据的流程。
- en: The second one, data in motion, targets real-time data ingestion and delivering
    insights based on precomputed models and data patterns
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二个流程是处理运动中的数据，目标是实时数据摄取和基于预先计算的模型和数据模式提供洞察力
- en: Processing data at rest
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 处理静态数据
- en: Let's get an understanding of the data at rest or batch processing pipeline.
    The objective in this pipeline is to ingest the various datasets from Twitter,
    GitHub, and Meetup; prepare the data for Spark MLlib, the machine learning engine;
    and derive the base models that will be applied for insight generation in batch
    mode or in real time.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们了解一下静态数据或批处理流程。这个流程的目标是从Twitter、GitHub和Meetup中摄取各种数据集；为Spark MLlib准备数据，这是机器学习引擎；并推导出将在批处理模式或实时模式下应用的基本模型。
- en: 'The following diagram illustrates the data pipeline in order to enable processing
    data at rest:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表说明了数据流程，以便处理静态数据：
- en: '![Processing data at rest](img/B03986_02_02.jpg)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![处理静态数据](img/B03986_02_02.jpg)'
- en: Processing data in motion
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 处理运动中的数据
- en: Processing data in motion introduces a new level of complexity, as we are introducing
    a new possibility of failure. If we want to scale, we need to consider bringing
    in distributed message queue systems such as Kafka. We will dedicate a subsequent
    chapter to understanding streaming analytics.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 处理运动数据引入了新的复杂性，因为我们引入了新的失败可能性。如果我们想要扩展，我们需要考虑引入分布式消息队列系统，如Kafka。我们将专门讨论理解流式分析的后续章节。
- en: 'The following diagram depicts a data pipeline for processing data in motion:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表描述了用于处理运动数据的数据管道：
- en: '![Processing data in motion](img/B03986_02_03.jpg)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![处理运动数据](img/B03986_02_03.jpg)'
- en: Exploring data interactively
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 交互式地探索数据
- en: Building a data-intensive app is not as straightforward as exposing a database
    to a web interface. During the setup of both the data at rest and data in motion
    processing, we will capitalize on Spark's ability to analyse data interactively
    and refine the data richness and quality required for the machine learning and
    streaming activities. Here, we will go through an iterative cycle of data collection,
    refinement, and investigation in order to get to the dataset of interest for our
    apps.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 构建数据密集型应用程序并不像将数据库暴露给Web界面那样简单。在静态数据和运动数据处理的设置过程中，我们将利用Spark分析数据的能力，以交互方式分析和细化所需的机器学习和流处理活动所需的数据丰富性和质量。在这里，我们将进行数据收集、细化和调查的迭代循环，以获取我们应用程序感兴趣的数据集。
- en: Connecting to social networks
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 连接到社交网络
- en: 'Let''s delve into the first steps of the data-intensive app architecture''s
    integration layer. We are going to focus on harvesting the data, ensuring its
    integrity and preparing for batch and streaming data processing by Spark at the
    next stage. This phase is described in the five process steps: *connect*, *correct*,
    *collect*, *compose*, and *consume*. These are iterative steps of data exploration
    that will get us acquainted with the data and help us refine the data structure
    for further processing.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入探讨数据密集型应用程序架构集成层的第一步。我们将专注于收集数据，确保其完整性，并为Spark在下一阶段的批处理和流处理数据做准备。这个阶段描述了五个处理步骤：*连接*，*校正*，*收集*，*组合*和*消费*。这些是数据探索的迭代步骤，将使我们熟悉数据，并帮助我们为进一步处理调整数据结构。
- en: 'The following diagram depicts the iterative process of data acquisition and
    refinement for consumption:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表描述了用于消费的数据采集和细化的迭代过程：
- en: '![Connecting to social networks](img/B03986_02_04.jpg)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![连接到社交网络](img/B03986_02_04.jpg)'
- en: 'We connect to the social networks of interest: Twitter, GitHub, and Meetup.
    We will discuss the mode of access to the **APIs** (short for **Application Programming
    Interface**) and how to create a RESTful connection with those services while
    respecting the rate limitation imposed by the social networks. **REST** (short
    for **Representation State Transfer**) is the most widely adopted architectural
    style on the Internet in order to enable scalable web services. It relies on exchanging
    messages predominantly in **JSON** (short for **JavaScript Object Notation**).
    RESTful APIs and web services implement the four most prevalent verbs `GET`, `PUT`,
    `POST`, and `DELETE`. `GET` is used to retrieve an element or a collection from
    a given `URI`. `PUT` updates a collection with a new one. `POST` allows the creation
    of a new entry, while `DELETE` eliminates a collection.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们连接到感兴趣的社交网络：Twitter、GitHub和Meetup。我们将讨论如何访问**APIs**（应用程序编程接口）的方式，以及如何与这些服务创建RESTful连接，同时尊重社交网络施加的速率限制。**REST**（表示状态转移）是互联网上最广泛采用的架构风格，以实现可扩展的Web服务。它依赖于主要以**JSON**（JavaScript对象表示）交换消息。RESTful
    APIs和Web服务实现了四种最常见的动词`GET`，`PUT`，`POST`和`DELETE`。`GET`用于从给定的`URI`检索元素或集合。`PUT`使用新的集合更新一个集合。`POST`允许创建新条目，而`DELETE`则删除一个集合。
- en: Getting Twitter data
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 获取Twitter数据
- en: Twitter allows access to registered users to its search and streaming tweet
    services under an authorization protocol called OAuth that allows API applications
    to securely act on a user's behalf. In order to create the connection, the first
    step is to create an application with Twitter at [https://apps.twitter.com/app/new](https://apps.twitter.com/app/new).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: Twitter允许注册用户访问其搜索和流式推文服务，使用名为OAuth的授权协议，允许API应用程序安全地代表用户进行操作。为了创建连接，第一步是在Twitter上创建一个应用程序，网址为[https://apps.twitter.com/app/new](https://apps.twitter.com/app/new)。
- en: '![Getting Twitter data](img/B03986_02_05.jpg)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![获取Twitter数据](img/B03986_02_05.jpg)'
- en: 'Once the application has been created, Twitter will issue the four codes that
    will allow it to tap into the Twitter hose:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序创建后，Twitter将发出四个代码，允许其接入Twitter的数据流：
- en: '[PRE0]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'If you wish to get a feel for the various RESTful queries offered, you can
    explore the Twitter API on the dev console at [https://dev.twitter.com/rest/tools/console](https://dev.twitter.com/rest/tools/console):'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想了解提供的各种RESTful查询，可以在开发控制台上探索Twitter API，网址为[https://dev.twitter.com/rest/tools/console](https://dev.twitter.com/rest/tools/console)：
- en: '![Getting Twitter data](img/B03986_02_06.jpg)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![获取Twitter数据](img/B03986_02_06.jpg)'
- en: We will make a programmatic connection on Twitter using the following code,
    which will activate our OAuth access and allows us to tap into the Twitter API
    under the rate limitation. In the streaming mode, the limitation is for a GET
    request.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用以下代码在Twitter上进行程序化连接，这将激活我们的OAuth访问，并允许我们在速率限制下接入Twitter API。在流模式下，限制是针对GET请求的。
- en: Getting GitHub data
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 获取GitHub数据
- en: 'GitHub uses a similar authentication process to Twitter. Head to the developer
    site and retrieve your credentials after duly registering with GitHub at [https://developer.github.com/v3/](https://developer.github.com/v3/):'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: GitHub使用类似的身份验证流程来Twitter。前往开发者网站，在[https://developer.github.com/v3/](https://developer.github.com/v3/)上注册GitHub后，检索您的凭据：
- en: '![Getting GitHub data](img/B03986_02_07.jpg)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![获取GitHub数据](img/B03986_02_07.jpg)'
- en: Getting Meetup data
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 获取Meetup数据
- en: 'Meetup can be accessed using the token issued in the developer resources to
    members of Meetup.com. The necessary token or OAuth credential for Meetup API
    access can be obtained on their developer''s website at [https://secure.meetup.com/meetup_api](https://secure.meetup.com/meetup_api):'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用在Meetup.com成员的开发资源中发行的令牌来访问Meetup。可以在他们的开发者网站上获取Meetup API访问所需的令牌或OAuth凭据：[https://secure.meetup.com/meetup_api](https://secure.meetup.com/meetup_api)。
- en: '![Getting Meetup data](img/B03986_02_08.jpg)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![获取Meetup数据](img/B03986_02_08.jpg)'
- en: Analyzing the data
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分析数据
- en: Let's get a first feel for the data extracted from each of the social networks
    and get an understanding of the data structure from each these sources.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先感受一下从每个社交网络中提取的数据，并了解来自这些来源的数据结构。
- en: Discovering the anatomy of tweets
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 发现推文的结构
- en: 'In this section, we are going to establish connection with the Twitter API.
    Twitter offers two connection modes: the REST API, which allows us to search historical
    tweets for a given search term or hashtag, and the streaming API, which delivers
    real-time tweets under the rate limit in place.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将建立与Twitter API的连接。Twitter提供两种连接模式：REST API，允许我们搜索给定搜索词或标签的历史推文，以及流API，它在限制速率下提供实时推文。
- en: 'In order to get a better understanding of how to operate with the Twitter API,
    we will go through the following steps:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地了解如何操作Twitter API，我们将按照以下步骤进行：
- en: Install the Twitter Python library.
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装Twitter Python库。
- en: Establish a connection programmatically via OAuth, the authentication required
    for Twitter.
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过OAuth以编程方式建立连接，这是Twitter所需的身份验证。
- en: Search for recent tweets for the query *Apache Spark* and explore the results
    obtained.
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 搜索查询*Apache Spark*的最新推文并探索所获得的结果。
- en: Decide on the key attributes of interest and retrieve the information from the
    JSON output.
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 决定感兴趣的关键属性，并从JSON输出中检索信息。
- en: 'Let''s go through it step-by-step:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们一步一步地进行这个过程：
- en: 'Install the Python Twitter library. In order to install it, you need to write
    `pip install twitter` from the command line:'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装Python Twitter库。为了安装它，您需要从命令行中编写`pip install twitter`：
- en: '[PRE1]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Create the Python Twitter API class and its base methods for authentication,
    searching, and parsing the results. `self.auth` gets the credentials from Twitter.
    It then creates a registered API as `self.api`. We have implemented two methods:
    the first one to search Twitter with a given query and the second one to parse
    the output to retrieve relevant information such as the tweet ID, the tweet text,
    and the tweet author. The code is as follows:'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建Python Twitter API类及其用于身份验证、搜索和解析结果的基本方法。`self.auth`从Twitter获取凭据。然后创建一个注册的API作为`self.api`。我们实现了两种方法：第一种是使用给定的查询搜索Twitter，第二种是解析输出以检索相关信息，如推文ID、推文文本和推文作者。代码如下：
- en: '[PRE2]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Instantiate the class with the required authentication:'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用所需的身份验证实例化类：
- en: '[PRE3]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Run a search on the query term *Apache Spark*:'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在查询词*Apache Spark*上运行搜索：
- en: '[PRE4]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Analyze the JSON output:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 分析JSON输出：
- en: '[PRE5]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Parse the Twitter output to retrieve key information of interest:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解析Twitter输出以检索感兴趣的关键信息：
- en: '[PRE6]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Exploring the GitHub world
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索GitHub世界
- en: 'In order to get a better understanding on how to operate with the GitHub API,
    we will go through the following steps:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地了解如何操作GitHub API，我们将按照以下步骤进行：
- en: Install the GitHub Python library.
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装GitHub Python库。
- en: Access the API by using the token provided when we registered in the developer
    website.
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过使用在开发者网站上注册时提供的令牌来访问API。
- en: Retrieve some key facts on the Apache foundation that is hosting the spark repository.
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检索有关托管spark存储库的Apache基金会的一些关键事实。
- en: 'Let''s go through the process step-by-step:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们一步一步地进行这个过程：
- en: 'Install the Python PyGithub library. In order to install it, you need to `pip
    install PyGithub` from the command line:'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装Python PyGithub库。为了安装它，您需要从命令行中`pip install PyGithub`：
- en: '[PRE7]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Programmatically create a client to instantiate the GitHub API:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过编程方式创建客户端来实例化GitHub API：
- en: '[PRE8]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Retrieve key facts from the Apache User. There are 640 active Apache repositories
    in GitHub:'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从Apache用户检索关键事实。GitHub中有640个活跃的Apache存储库：
- en: '[PRE9]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Retrieve key facts from the Spark repository, The programing languages used
    in the Spark repo are given here under:'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从Spark存储库检索关键事实，Spark存储库中使用的编程语言在此处给出：
- en: '[PRE10]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Retrieve a few key participants of the wide Spark GitHub repository network.
    There are 3,738 stargazers in the Apache Spark repository at the time of writing.
    The network is immense. The first stargazer is *Matei Zaharia*, the cofounder
    of the Spark project when he was doing his PhD in Berkeley.
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检索广泛的Spark GitHub存储库网络中的一些关键参与者。在撰写本文时，Apache Spark存储库中有3,738名关注者。这个网络是巨大的。第一个关注者是*Matei
    Zaharia*，他在伯克利读博士期间是Spark项目的联合创始人。
- en: '[PRE11]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Understanding the community through Meetup
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过Meetup了解社区
- en: 'In order to get a better understanding of how to operate with the Meetup API,
    we will go through the following steps:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地了解如何操作Meetup API，我们将按照以下步骤进行：
- en: Create a Python program to call the Meetup API using an authentication token.
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个Python程序，使用身份验证令牌调用Meetup API。
- en: Retrieve information of past events for meetup groups such as *London Data Science*.
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检索Meetup小组的过去事件信息，例如*London Data Science*。
- en: Retrieve the profile of the meetup members in order to analyze their participation
    in similar meetup groups.
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检索Meetup成员的个人资料，以分析他们参与类似Meetup小组的情况。
- en: 'Let''s go through the process step-by-step:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们一步一步地进行这个过程：
- en: 'As there is no reliable Meetup API Python library, we will programmatically
    create a client to instantiate the Meetup API:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于没有可靠的Meetup API Python库，我们将通过编程方式创建一个客户端来实例化Meetup API：
- en: '[PRE12]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Then, we will retrieve past events from a given Meetup group:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将从给定的Meetup小组中检索过去的事件：
- en: '[PRE13]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Get information about the Meetup members:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取有关Meetup成员的信息：
- en: '[PRE14]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Previewing our app
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预览我们的应用程序
- en: 'Our challenge is to make sense of the data retrieved from these social networks,
    finding the key relationships and deriving insights. Some of the elements of interest
    are as follows:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的挑战是理解从这些社交网络中检索到的数据，找到关键关系并得出见解。一些感兴趣的元素如下：
- en: 'Visualizing the top influencers: Discover the top influencers in the community:'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可视化顶级影响者：发现社区中的顶级影响者：
- en: Heavy Twitter users on *Apache Spark*
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Apache Spark*上的重度Twitter用户'
- en: Committers in GitHub
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GitHub的提交者
- en: Leading Meetup presentations
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 领先的Meetup演示
- en: 'Understanding the Network: Network graph of GitHub committers, watchers, and
    stargazers'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 了解网络：GitHub提交者、观察者和星标用户的网络图
- en: 'Identifying the Hot Locations: Locating the most active location for Spark'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定热门位置：定位Spark最活跃的位置
- en: 'The following screenshot provides a preview of our app:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图提供了我们应用程序的预览：
- en: '![Previewing our app](img/B03986_02_09.jpg)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![预览我们的应用程序](img/B03986_02_09.jpg)'
- en: Summary
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'In this chapter, we laid out the overall architecture of our app. We explained
    the two main paradigms of processing data: batch processing, also called data
    at rest, and streaming analytics, referred to as data in motion. We proceeded
    to establish connections to three social networks of interest: Twitter, GitHub,
    and Meetup. We sampled the data and provided a preview of what we are aiming to
    build. The remainder of the book will focus on the Twitter dataset. We provided
    here the tools and API to access three social networks, so you can at a later
    stage create your own data mashups. We are now ready to investigate the data collected,
    which will be the topic of the next chapter.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们阐述了我们应用程序的总体架构。我们解释了处理数据的两种主要范例：批处理，也称为静态数据，和流式分析，也称为动态数据。我们继续建立与三个感兴趣的社交网络的连接：Twitter、GitHub和Meetup。我们对数据进行了抽样，并提供了我们的构建目标的预览。本书的其余部分将专注于Twitter数据集。我们在这里提供了访问三个社交网络的工具和API，这样你就可以在以后创建自己的数据混搭。我们现在准备调查收集的数据，这将是下一章的主题。
- en: In the next chapter, we will delve deeper into data analysis, extracting the
    key attributes of interest for our purposes and managing the storage of the information
    for batch and stream processing.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将深入研究数据分析，提取我们感兴趣的关键属性，并管理批处理和流处理的信息存储。
