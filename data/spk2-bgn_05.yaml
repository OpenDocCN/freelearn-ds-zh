- en: Chapter 5. Spark Data Analysis with Python
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第5章：使用Python进行Spark数据分析
- en: The ultimate goal of processing data is to use the results for answering business
    questions. It is very important to understand the data that is being used to answer
    the business questions. To understand the data better, various tabulation methods,
    charting, and plotting techniques are used. Visual representation of the data
    reinforces the understanding of the underlying data. Because of this, data visualization
    is used extensively in data analysis.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 数据处理的最终目的是使用结果来回答业务问题。理解用于回答业务问题的数据非常重要。为了更好地理解数据，使用了各种表格方法、图表和图形技术。数据的可视化表示加强了底层数据的理解。正因为如此，数据可视化在数据分析中被广泛使用。
- en: There are different terms that are used in various publications to mean the
    analysis of data for answering business questions. Data analysis, data analytics,
    and business intelligence, are some of the ubiquitous terms floating around. This
    chapter is not going to delve into the discussion on the meaning, similarities,
    or differences of these terms. On the other hand, the focus is going to be on
    how to bridge the gap between two major activities typically done by data scientists
    or data analysts. The first one being data processing. The second one is the use
    of the processed data to do analysis with the help of charting and plotting. Data
    analysis is the forte of data analysts and data scientists. This chapter is going
    to focus on the usage of Spark and Python to process the data, and produce charts
    and plots.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在各种出版物中，使用不同的术语来表示为回答业务问题而进行的数据分析。数据分析、数据分析和企业智能是一些普遍使用的术语。本章不会深入讨论这些术语的含义、相似性或差异。另一方面，重点是解决数据科学家或数据分析师通常进行的两个主要活动之间的差距。第一个是数据处理。第二个是使用处理后的数据，在图表和图形的帮助下进行分析。数据分析是数据分析师和数据科学家的强项。本章将专注于使用Spark和Python处理数据，并生成图表和图形。
- en: In many data analysis use cases, a super-set of data is processed and the reduced
    resultant dataset is used for the data analysis. This is specifically valid in
    the case of big data analysis where a small set of processed data is used for
    analysis. Depending on the use case, for various data analysis needs, appropriate
    data processing is done as a prerequisite. Most of the use cases that are going
    to be covered in this chapter fall into this model, where the first step deals
    with the necessary data processing, and the second step deals with the charting
    and plotting required for the data analysis.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多数据分析用例中，处理数据集的超集，并使用减少后的结果数据集进行数据分析。这在大数据分析的情况下特别适用，其中使用一小部分处理后的数据进行分析。根据用例，为了满足各种数据分析需求，作为先决条件进行适当的数据处理。本章将要涵盖的大多数用例都符合这种模式，其中第一步涉及必要的数据处理，第二步涉及数据分析所需的图表和图形绘制。
- en: In typical data analysis use cases, the chain of activities involves an extensive
    and multi-staged **Extract**, **Transform**, and **Load** (**ETL**) pipeline ending
    with a data analysis platform or application. The end result of this chain of
    activities includes, but is not limited to, tables of summary data and various
    visual representations of the data in the form of charts and plots. Since Spark
    can process data from heterogeneous distributed data sources very effectively,
    the huge ETL pipeline that existed in legacy data analysis applications can be
    consolidated into self-contained applications that do the data processing and
    data analysis.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在典型的数据分析用例中，活动链涉及一个广泛的多阶段**提取**、**转换**和**加载**（**ETL**）管道，以数据分析和平台或应用程序结束。这一活动链的最终结果包括但不限于汇总数据的表格和各种以图表和图形形式表示的数据可视化。由于Spark可以非常有效地处理来自异构分布式数据源的数据，因此传统数据分析应用程序中存在的巨大ETL管道可以整合成自包含的应用程序，这些应用程序执行数据处理和数据分析。
- en: 'We will cover the following topics in this chapter:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Charting and plotting libraries
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图表和图形库
- en: Setting up a dataset
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置数据集
- en: Capturing the high-level details of the data analysis use cases
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 捕获数据分析用例的高级细节
- en: Various charts and plots
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 各种图表和图形
- en: Charting and plotting libraries
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图表和图形库
- en: Python is a programming language heavily used by data analysts and data scientists
    these days. There are numerous scientific and statistical data processing libraries
    available, as well as charting and plotting libraries, that can be used in Python
    programs. Python is also widely used as a programming language to develop data
    processing applications in Spark. This brings in a great flexibility to have a
    unified data processing and data analysis framework with Spark, Python and Python
    libraries, enabling us to do scientific and statistical processing, and charting
    and plotting. There are numerous such libraries that work with Python. Out of
    all those, the**NumPy** and **SciPy **libraries are being used here to do numerical,
    statistical, and scientific data processing. The **matplotlib **library is being
    used here to do the charting and plotting that produces 2D images.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Python是一种目前被数据分析师和数据科学家广泛使用的编程语言。Python中有许多科学和统计数据处理库，以及图表和绘图库，可以在Python程序中使用。Python也被广泛用作在Spark中开发数据处理应用程序的编程语言。这为Spark、Python和Python库提供了一个统一的数据处理和分析框架，使我们能够进行科学和统计处理、图表和绘图。有大量的此类库与Python一起工作。在所有这些库中，这里使用**NumPy**和**SciPy**库来进行数值、统计和科学数据处理。这里使用**matplotlib**库来进行生成2D图像的图表和绘图。
- en: Tip
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: It is very important to make sure that the  **NumPy**, **SciPy** and **matplotlib**
    Python libraries are working fine with the Python installation before attempting
    the code samples given in this chapter. This has to be tested and verified in
    isolation before using it in Spark applications.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在尝试本章给出的代码示例之前，确保**NumPy**、**SciPy**和**matplotlib**Python库与Python安装正常工作非常重要。这必须在将其用于Spark应用程序之前单独测试和验证。
- en: 'The block diagram shown in *Figure 1* gives the overall structure of the application
    stack:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 如*图1*所示的整体应用堆栈结构图：
- en: '![Charting and plotting libraries](img/image_05_002.jpg)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![图表和绘图库](img/image_05_002.jpg)'
- en: Figure 1
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 图1
- en: Setting up a dataset
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置数据集
- en: There are many public Datasets available for the consumption of the general
    public that can be used for education, research, and development purposes. The
    MovieLens website lets users rate and personalize movie recommendations. GroupLens
    Research published the rating Datasets from MovieLens. These datasets are available
    for download from their website, [http://grouplens.org/datasets/movielens/](http://grouplens.org/datasets/movielens/).
    In this chapter, the MovieLens 100K Dataset is being used to demonstrate the usage
    of distributed data processing with Spark in conjunction with Python, NumPy, SciPy,
    and matplotlib.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多公共数据集可供公众消费，可用于教育、研究和开发目的。MovieLens网站允许用户对电影进行评分并个性化电影推荐。GroupLens Research发布了来自MovieLens的评分数据集。这些数据集可以从他们的网站[http://grouplens.org/datasets/movielens/](http://grouplens.org/datasets/movielens/)下载。在本章中，使用MovieLens
    100K数据集来演示使用Spark结合Python、NumPy、SciPy和matplotlib进行分布式数据处理的使用方法。
- en: Tip
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: On the GroupLens Research website for the dataset download, apart from the preceding
    dataset, there are more voluminous datasets such as MovieLens 1M dataset, MovieLens
    10M dataset, MovieLens 20M dataset, and MovieLens latest datasets available for
    download. Once the reader is quite familiar with the programs and has achieved
    a sufficient level of comfort playing around with data, these additional datasets
    can be used by the reader to do their own analysis work to strengthen the knowledge
    acquired from this chapter.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据集下载的GroupLens Research网站上，除了前面提到的数据集外，还有更多大量数据集可供下载，如MovieLens 1M数据集、MovieLens
    10M数据集、MovieLens 20M数据集以及最新的MovieLens数据集。一旦读者对程序非常熟悉，并且达到了足够的舒适度来处理数据，这些额外的数据集就可以被读者用来进行自己的分析工作，以加强从本章获得的知识。
- en: 'The MovieLens 100K dataset has data in multiple files. The following are the
    ones that are going to be used in the data analysis use cases of this chapter:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: MovieLens 100K数据集包含多个文件中的数据。以下是在本章数据分析用例中将要使用的一些文件：
- en: '`u.user`: The demographic information about the users who have rated movies.
    The structure of the dataset is given as follows, reproduced as it is from the
    README file accompanying the dataset:'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`u.user`: 关于已评分电影的用户的统计数据信息。数据集的结构如下，直接从数据集附带的README文件中复制而来：'
- en: User ID
  id: totrans-23
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户ID
- en: Age
  id: totrans-24
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 年龄
- en: Gender
  id: totrans-25
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 性别
- en: Occupation
  id: totrans-26
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 职业
- en: Zip code
  id: totrans-27
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 邮编
- en: '`u.item`: The information about the movies that are rated by the users. The
    structure of the dataset is given as follows, reproduced as it is from the README
    file accompanying the dataset:'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`u.item`：关于用户评分的电影信息。数据集的结构如下，直接从数据集附带的README文件中复制，保持原样：'
- en: Movie ID
  id: totrans-29
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 电影ID
- en: Movie title
  id: totrans-30
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 电影标题
- en: Release date
  id: totrans-31
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发布日期
- en: Video release date
  id: totrans-32
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 视频发布日期
- en: IMDb URL
  id: totrans-33
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: IMDb URL
- en: Unknown
  id: totrans-34
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 未知
- en: Action
  id: totrans-35
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 动作
- en: Adventure
  id: totrans-36
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 冒险片
- en: Animation
  id: totrans-37
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 动画片
- en: Children's
  id: totrans-38
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 儿童片
- en: Comedy
  id: totrans-39
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 喜剧片
- en: Crime
  id: totrans-40
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 犯罪片
- en: Documentary
  id: totrans-41
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 纪录片
- en: Drama
  id: totrans-42
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 剧情
- en: Fantasy
  id: totrans-43
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 奇幻片
- en: Film-Noir
  id: totrans-44
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 黑色电影
- en: Horror
  id: totrans-45
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 恐怖片
- en: Musical
  id: totrans-46
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 音乐片
- en: Mystery
  id: totrans-47
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 悬疑片
- en: Romance
  id: totrans-48
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 爱情
- en: Sci-Fi
  id: totrans-49
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 科幻片
- en: Thriller
  id: totrans-50
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 惊悚片
- en: War
  id: totrans-51
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 战争片
- en: Western
  id: totrans-52
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 西部片
- en: Data analysis use cases
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据分析用例
- en: 'The following list captures the high-level details of the data analysis use
    cases. Most of the use cases are revolving around the creation of various charts
    and plots:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 以下列表捕获了数据分析用例的高级细节。大多数用例都是围绕创建各种图表和图形进行的：
- en: Plot the age distribution of the users who have rated the movies using a histogram.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用直方图绘制评分用户的年龄分布。
- en: Plot the age probability density chart of the users using the same data used
    to plot the histogram.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用与绘制直方图相同的数据，绘制用户的年龄概率密度图。
- en: Plot the summary of the age distribution data to find the minimum, 25^(th) percentile,
    median, 75^(th) percentile, and maximum ages of the users.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 绘制年龄分布数据的摘要，以找到用户的年龄最小值、25%分位数、中位数、75%分位数和最大值。
- en: Plot multiple charts or plots on the same figure to have a side-by-side comparison
    of the data.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在同一图上绘制多个图表或图形，以便进行数据并排比较。
- en: Create a bar chart capturing the top 10 occupations in terms of the number of
    users who have rated the movies.
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个柱状图，展示按电影评分人数排名前10的职业。
- en: Create a stacked bar chart capturing the number of male and female users by
    their occupation who have rated the movies.
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个堆积柱状图，展示按职业划分的男性和女性用户对电影的评分数量。
- en: Create a pie chart capturing the bottom 10 occupations in terms of the number
    of who have rated the movies.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个饼图，展示按电影评分人数排名后10的职业。
- en: Create a donut chart capturing the top 10 zip codes in terms of the number of
    who have rated the movies.
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个饼图，展示按电影评分人数排名前10的邮编。
- en: Using three occupation categories, create box plots capturing the summary statistics
    of the users who have rated the movies. All three box plots have to be drawn on
    a single figure to enable comparison.
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用三个职业类别，创建箱线图，展示评分用户的汇总统计信息。所有三个箱线图必须绘制在单个图上，以便进行比较。
- en: Create a bar chart capturing the number of movies by their genre.
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个柱状图，展示按电影类型划分的电影数量。
- en: Create a scatter plot capturing the top 10 years in terms of the number of movies
    released in each year.
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个散点图，展示按每年上映电影数量排名前10的年份。
- en: Create a scatter plot capturing the top 10 years in terms of the number of movies
    released in each year. In this plot, instead of points in the plot, create circles
    with the area proportional to the number of movies released in that year.
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个散点图，展示按每年上映电影数量排名前10的年份。在这个图中，用与该年上映电影数量成比例的圆形代替图中的点。
- en: Create a line graph with two datasets with one dataset being the number of action
    movies released over the last 10 years and the other dataset being the number
    of drama movies released over the last 10 years to facilitate a comparison.
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个折线图，包含两个数据集，其中一个数据集是过去10年上映的动作电影数量，另一个数据集是过去10年上映的剧情电影数量，以便进行比较。
- en: Tip
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: In all the preceding use cases, when it comes to implementation, Spark is used
    to process the data and prepare the required dataset. Once the required processed
    data is available in Spark DataFrame, it is collected into the driver program.
    In other words, the data is transferred from the distributed collection of Spark
    into a local collection, as tuples in the Python program, for charting and plotting.
    For charting and plotting, Python needs the data locally. It cannot use Spark
    DataFrames directly to do charting and plotting.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '在所有前面的用例中，当涉及到实现时，使用Spark处理数据并准备所需的数据集。一旦所需的处理数据在Spark DataFrame中可用，就收集到驱动程序中。换句话说，数据从Spark的分布式集合转移到Python程序中的本地集合，作为元组，用于图表和绘图。对于图表和绘图，Python需要本地数据。它不能直接使用Spark
    DataFrame进行图表和绘图。 '
- en: Charts and plots
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图表和图形
- en: 'This section is going to focus on creating various charts and plots to visually
    represent various aspects of the MovieLens 100K Dataset that are related to the
    use cases described in the preceding section. The charts and plots drawing process
    described throughout this chapter follows a pattern. Here are the important steps
    in that pattern of activities:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将专注于创建各种图表和绘图，以直观地表示与上一节中描述的用例相关的MovieLens 100K数据集的各个方面。本章中描述的图表和绘图绘制过程遵循一个模式。以下是该活动模式中的重要步骤：
- en: Read data from the data file using Spark.
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用Spark从数据文件中读取数据。
- en: Make the data available in a Spark DataFrame.
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据在Spark DataFrame中可用。
- en: Apply the necessary data processing using DataFrame API.
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用DataFrame API应用必要的数据处理。
- en: The processing is mainly to make available only the minimal and required data
    for charting and plotting purposes.
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 处理主要是为了仅提供图表和绘图所需的最低限度和必要的数据。
- en: Transfer the processed data from Spark DataFrame to the local Python collection
    object in the Spark Driver program.
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将处理后的数据从Spark DataFrame传输到Spark Driver程序中的本地Python集合对象。
- en: Use the charting and plotting libraries to generate the figures using the data
    available in the Python collection objects.
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用图表和绘图库，通过Python集合对象中的数据生成图形。
- en: Histogram
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 直方图
- en: A histogram is generally used to show how a given numerical dataset is distributed
    over consecutive non-overlapping intervals of equal size. The interval or bin
    size is chosen based on the dataset. The bin or interval represents the ranges
    of data. In this use case, the dataset consists of the ages of the users. In this
    case it does not make sense to have a bin size of 100 as there will be only one
    bin and the entire dataset will fall into it. The height of the bars representing
    the bins indicates the frequency of data items in that bin or interval.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 直方图通常用于显示给定数值数据集在连续的非重叠等大小区间上的分布情况。区间或区间大小基于数据集选择。区间或区间代表数据的范围。在本用例中，数据集由用户的年龄组成。在这种情况下，区间大小为100没有意义，因为只有一个区间，整个数据集都将落入其中。表示区间的柱状图的高度表示该区间或区间中数据项的频率。
- en: 'The following set of commands are used to bring up the Python REPL of Spark,
    followed by the programs to do the data processing, charting, and plotting:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令集用于启动Spark的Python REPL，随后是进行数据处理、图表和绘图的程序：
- en: '[PRE0]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'In the preceding section, the user dataset was read line by line to form the
    RDD. From the RDD, a Spark DataFrame was created. Using Spark SQL, another Spark
    DataFrame was created containing only the age column. The summary of that Spark
    DataFrame was displayed to show the summary statistics of the contents; the contents
    were collected into a local Python collection object. Using the collected data,
    a histogram of the age column was plotted, as given in *Figure 2*:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，用户数据集被逐行读取以形成RDD。从RDD中创建了一个Spark DataFrame。使用Spark SQL，创建了一个只包含年龄列的另一个Spark
    DataFrame。该Spark DataFrame的摘要被显示出来，以展示内容的摘要统计；内容被收集到一个本地的Python集合对象中。使用收集到的数据，绘制了年龄列的直方图，如图*图2*所示：
- en: '![Histogram](img/image_05_003.jpg)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![直方图](img/image_05_003.jpg)'
- en: Figure 2
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 图2
- en: Density plot
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 密度图
- en: There is another plot that is very close to a histogram. It is the density plot.
    Whenever there is a finite data sample with a need to estimate the probability
    density function of a random variable, density plots are used heavily. A histogram
    doesn't show when data smooths out or when there is continuity in the data points.
    For that purpose, density plots are used.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 另有一个与直方图非常相似的图表。它是密度图。当存在有限的数据样本且需要估计随机变量的概率密度函数时，密度图被大量使用。直方图无法显示数据平滑或数据点连续的情况。为此目的，使用密度图。
- en: Note
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Since a histogram and density plot are used for similar purposes, but show different
    behavior for the same data, generally, a histogram and density plot are used side
    by side in many applications.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 由于直方图和密度图用于类似的目的，但对于相同的数据显示不同的行为，通常在许多应用中直方图和密度图是并排使用的。
- en: '*Figure 3* is a density plot drawn for the same dataset that is used to plot
    the histogram.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '*图3*是为与绘制直方图相同的同一数据集绘制的密度图。'
- en: 'As a continuation of the same Python REPL of Spark, run the following commands:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 作为同一Python REPL的Spark的延续，运行以下命令：
- en: '[PRE1]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![Density plot](img/image_05_004.jpg)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![密度图](img/image_05_004.jpg)'
- en: Figure 3
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 图3
- en: In the preceding section, the same Spark DataFrame that was created containing
    only the age column was used and the contents were collected into a local Python
    collection object. Using the collected data, a density plot of the age column
    was plotted as given in *Figure 3*, with the line space from 0 to 100 representing
    the age.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，使用了只包含年龄列的相同 Spark DataFrame，并将内容收集到本地的 Python 集合对象中。使用收集到的数据，绘制了年龄列的密度图，如图
    *3* 所示，线空间从 0 到 100 代表年龄。
- en: If multiple charts or plots are to be looked at side by side, the **matplotlib**
    library provides ways to do that. Figure 4 shows a histogram and a box plot side
    by side.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 如果需要并排查看多个图表或图形，**matplotlib** 库提供了实现这一功能的方法。图 4 展示了并排的直方图和箱线图。
- en: 'As a continuation of the same Python REPL of Spark, run the following commands:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 作为与 Spark 相同的 Python REPL 的延续，运行以下命令：
- en: '[PRE2]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![Density plot](img/image_05_005.jpg)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![密度图](img/image_05_005.jpg)'
- en: Figure 4
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4
- en: In the preceding section, the same Spark DataFrame that was created containing
    only the age column was used, and the contents were collected into a local Python
    collection object. Using the collected data, a histogram of the age column was
    plotted along with a box plot containing indicators for the minimum, 25^(th) percentile,
    median, 75^(th) percentile, and maximum values, as given in *Figure 4*. When drawing
    multiple charts or plots in one figure, for a way to control the layout, look
    at the method call `plt.subplot(121)`. This is talking about the selection of
    the plot laid out in one row and two columns, and selects the first one. In the
    same way, `plt.subplot(122)` talks about the selection of the plot laid out in
    one row and two columns, and selects the second one.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，使用了只包含年龄列的相同 Spark DataFrame，并将内容收集到本地的 Python 集合对象中。使用收集到的数据，绘制了年龄列的直方图，以及包含最小值、25^(th)
    分位数、中位数、75^(th) 分位数和最大值的箱线图，如图 *4* 所示。当在一个图中绘制多个图表或图形时，为了控制布局，可以查看方法调用 `plt.subplot(121)`。这指的是在一行两列布局中选择的图形，并选择了第一个。同样，`plt.subplot(122)`
    指的是在一行两列布局中选择的图形，并选择了第二个。
- en: Bar chart
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 条形图
- en: Bar charts can be drawn in different ways. The most common one is where the
    bars are standing vertically on the *X* axis. Another variation is where the bars
    are drawn on the *Y* axis and have the bars laid out horizontally. *Figure 5*
    shows a horizontal bar chart.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 条形图可以以不同的方式绘制。最常见的一种是条形垂直于 *X* 轴站立。另一种变化是条形绘制在 *Y* 轴上，条形水平排列。*图 5* 展示了一个水平条形图。
- en: Note
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: It is very common to get confused between a histogram and bar chart. The important
    difference is that a histogram is used to plot continuous but finite numerical
    values, but a bar chart is used to represent categorical data.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 很容易将直方图和条形图混淆。重要的区别在于，直方图用于绘制连续但有限的数值，而条形图用于表示分类数据。
- en: 'As a continuation of the same Python REPL of Spark, run the following commands:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 作为与 Spark 相同的 Python REPL 的延续，运行以下命令：
- en: '[PRE3]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![Bar chart](img/image_05_006.jpg)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![条形图](img/image_05_006.jpg)'
- en: Figure 5
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5
- en: In the preceding section, a Spark DataFrame was created containing the top 10
    occupations of the users in terms of the number of users who have rated movies.
    The data was collected into a Python collection object to plot the bar chart.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，创建了一个包含用户按评价电影数量排名前 10 的职业的 Spark DataFrame。数据被收集到 Python 集合对象中，用于绘制条形图。
- en: Stacked bar chart
  id: totrans-110
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 堆叠条形图
- en: The bar chart that was drawn in the preceding section gives the top 10 user
    occupations in terms of the number of users. But that does not give details about
    how that number is made up in terms of the gender of the users. In this kind of
    situation, it is good to use a stacked bar chart with each bar showing the counts
    by gender. *Figure 6* shows a stacked bar chart.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 前面章节中绘制的条形图显示了按用户数量排名的前 10 位用户职业。但这并没有给出关于用户性别构成的具体细节。在这种情况下，使用堆叠条形图是一个好主意，其中每个条形都显示了按性别划分的计数。*图
    6* 展示了一个堆叠条形图。
- en: 'As a continuation of the same Python REPL of Spark, run the following commands:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 作为与 Spark 相同的 Python REPL 的延续，运行以下命令：
- en: '[PRE4]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![Stacked bar chart](img/image_05_007.jpg)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![堆叠条形图](img/image_05_007.jpg)'
- en: Figure 6
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6
- en: In the preceding section, a Spark DataFrame was created containing only the
    occupation and gender columns. A cross-tab operation was done on that to produce
    another Spark DataFrame, which produced columns for occupation, male user count,
    and female user count. In the first Spark DataFrame, containing the occupation
    and gender columns, both are non-numerical columns and, because of that, it doesn't
    make sense to draw as chart or plot based on that data. But if a cross-tab operation
    is done on these two column values, for every distinct occupation field, then
    the counts of values of the gender column will be available. In this way, the
    occupation field becomes a categorical variable and it makes sense to draw a bar
    chart with the data. Since there are only two gender values in this data, it makes
    sense to have a stacked bar chart to see the total as well as the proportions
    of male and female user counts in each occupation category.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，创建了一个只包含职业和性别列的Spark DataFrame。对这个DataFrame进行了交叉表操作，生成了另一个Spark DataFrame，其中包含了职业、男性用户数量和女性用户数量列。在第一个包含职业和性别列的Spark
    DataFrame中，这两个都是非数值列，因此基于这些数据绘制图表或图形没有意义。但是，如果对这两个列值进行交叉表操作，对于每个不同的职业字段，性别列的值计数将可用。这样，职业字段就变成了一个分类变量，使用数据绘制条形图是有意义的。由于数据中只有两个性别值，因此使用堆叠条形图来查看每个职业类别中男性和女性用户数量的总数和比例是有意义的。
- en: There are many statistical and mathematical functions available within DataFrames
    in Spark. The cross-tab operation on a Spark DataFrame comes in very handy in
    this kind of situation. With huge datasets, the cross-tab operation can become
    very processor-intensive and time consuming, but the distributed processing capabilities
    of Spark are a great help in this kind of situation.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在Spark的DataFrame中有很多统计和数学函数可用。在这种情况下，对Spark DataFrame进行交叉表操作非常有用。对于大型数据集，交叉表操作可能会非常消耗处理器资源且耗时，但Spark的分布式处理能力在这种情况下非常有帮助。
- en: 'Spark SQL comes with lots of mathematical and statistical data processing capabilities.
    The preceding sections used the `describe().show()` method on the `SparkDataFrame`
    objects. In those Spark DataFrames, the preceding method acted on the available
    numeric columns. There will be situations where there are multiple numeric columns
    and, in those situations, the preceding method has the ability to pick and choose
    the desired columns for getting the summary statistics. Similarly, there are methods
    to find covariance, correlation, and so on, on the data from the Spark DataFrame.
    The following code snippet demonstrates these methods:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: Spark SQL自带了许多数学和统计数据处理能力。在上一节中，使用了`describe().show()`方法对`SparkDataFrame`对象进行了操作。在这些Spark
    DataFrame中，上述方法作用于可用的数值列。在存在多个数值列的情况下，上述方法具有选择所需列以获取汇总统计信息的能力。同样，还有方法可以在Spark
    DataFrame的数据上找到协方差、相关性等。以下代码片段演示了这些方法：
- en: '[PRE5]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Pie chart
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 饼图
- en: If there is a need to visually represent a dataset to explain the whole-part
    relationship, a pie chart is very commonly used. *Figure 7* shows a pie chart.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 如果需要以视觉方式表示数据集来解释整体与部分的关系，饼图是非常常用的。*图7*展示了饼图。
- en: 'As a continuation of the same Python REPL of Spark, run the following commands:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 作为与Spark相同的Python REPL的延续，运行以下命令：
- en: '[PRE6]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![Pie chart](img/image_05_008.jpg)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![饼图](img/image_05_008.jpg)'
- en: Figure 7
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 图7
- en: In the preceding section, a Spark DataFrame was created containing the bottom
    10 occupations of the users in terms of the number of users who have rated movies.
    The data was collected into a Python collection object to plot the pie chart.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，创建了一个包含用户按评价电影数量排名前10的职业的Spark DataFrame。数据被收集到一个Python集合对象中，以绘制饼图。
- en: Donut chart
  id: totrans-127
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 环形图
- en: Pie charts can be drawn in different forms. One such form, the donut chart,
    is often used these days. Figure 8 shows this donut chart variation of the pie
    chart.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 饼图可以以不同的形式绘制。其中一种形式，即环形图，现在经常被使用。图8展示了这种饼图的环形图变体。
- en: 'As a continuation of the same Python REPL of Spark, run the following commands:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 作为与Spark相同的Python REPL的延续，运行以下命令：
- en: '[PRE7]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![Donut chart](img/image_05_009.jpg)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![环形图](img/image_05_009.jpg)'
- en: Figure 8
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 图8
- en: In the preceding section, a Spark DataFrame was created containing the top 10
    zip codes of the users in terms of the number of users who live in that area and
    who have rated movies. The data was collected into a Python collection object
    to plot the donut chart.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，创建了一个包含用户按居住在该地区并评分的电影数量排名前10的邮政编码的Spark DataFrame。数据被收集到一个Python集合对象中，以绘制饼图。
- en: Tip
  id: totrans-134
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: Compared to the other figures in this book, the title of *Figure 8* is given
    in the middle. It is done using the `text()` method rather than using the `title()`
    method. This method can be used to print watermark text on the charts and plots.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 与本书中的其他图表相比，*图8*的标题位于中间。这是使用`text()`方法而不是使用`title()`方法完成的。此方法可用于在图表和绘图上打印水印文本。
- en: Box plot
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 箱线图
- en: Frequently, it is a common requirement to compare the summary statistics of
    different datasets in one figure. The box plot is a very common plot used to capture
    the summary statistics of a dataset in an intuitive way. The following section
    does exactly the same, and to do this, *Figure 9* shows multiple box plots on
    a single figure.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 经常需要在一个图表中比较不同数据集的摘要统计信息。箱线图是一种非常常见的图表，用于以直观的方式捕捉数据集的摘要统计信息。接下来的部分正是如此，为了做到这一点，*图9*在一个图表上显示了多个箱线图。
- en: 'As a continuation of the same Python REPL of Spark, run the following commands:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 作为与Spark相同Python REPL的延续，运行以下命令：
- en: '[PRE8]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![Box plot](img/image_05_010.jpg)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![箱线图](img/image_05_010.jpg)'
- en: Figure 9
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 图9
- en: 'In the preceding section, a Spark DataFrame was created with occupation and
    age columns for each of three occupations: administrator, engineer, and programmer.
    Box plots were created for each of these datasets on one figure, which contains
    indicators for the minimum, 25^(th) percentile, median, 75^(th) percentile, maximum,
    and outlier values for each of the datasets to facilitate comparison. The box
    plot for the programmer occupation shows two value points represented by the `+`
    symbol. They are outlier values.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，创建了一个包含三个职业（管理员、工程师和程序员）的职业和年龄列的Spark DataFrame。在一个图表上为这些数据集创建了箱线图，其中包含每个数据集的最小值、25%分位数、中位数、75%分位数、最大值和异常值指标，以方便比较。程序员职业的箱线图显示了两个由`+`符号表示的值点。它们是异常值。
- en: Vertical bar chart
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 竖直条形图
- en: In the preceding sections, the main dataset used for eliciting various charting
    and plotting use cases was the user data. The dataset that is taken up next is
    the movie dataset. In many datasets, to produce various charts and plots it will
    be a requirement to make the data suitable for the appropriate figure. Spark is
    rich with features to do the data processing.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，用于引发各种图表和绘图用例的主要数据集是用户数据。接下来要使用的数据集是电影数据集。在许多数据集中，为了生成各种图表和绘图，需要使数据适合适当的图形。Spark拥有丰富的数据处理功能。
- en: The following use case demonstrates the preparation of data by applying some
    aggregation and using Spark SQL; the desired dataset is prepared for a classic
    bar chart containing the counts of movies by genre. *Figure 10* shows the bar
    chart after applying the aggregation operation on the movie data.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 以下用例演示了通过应用一些聚合和使用Spark SQL来准备数据；为包含按类型计数的电影数量的经典条形图准备所需的数据集。*图10*显示了在电影数据上应用聚合操作后的条形图。
- en: 'As a continuation of the same Python REPL of Spark, run the following commands:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 作为与Spark相同Python REPL的延续，运行以下命令：
- en: '[PRE9]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![Vertical bar chart](img/image_05_011.jpg)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![竖直条形图](img/image_05_011.jpg)'
- en: Figure 10
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 图10
- en: In the preceding section, a `SparkDataFrame` was created with the movie dataset.
    The genre of the movie was captured in separate columns. Across the dataset, an
    aggregation was done using Spark SQL, a new `SparkDataFrame` summary was created,
    and the data values were collected into a Python collection object. Since there
    are too many columns in the dataset, a Python function was used to convert that
    kind of data structure into a dictionary object containing the column name as
    the key and the selected single row value is the value of the key. From that dictionary,
    two datasets were created and a bar chart is drawn.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，使用电影数据集创建了一个`SparkDataFrame`。电影的类型被捕获在单独的列中。在整个数据集上使用Spark SQL进行了聚合，创建了一个新的`SparkDataFrame`摘要，并将数据值收集到一个Python集合对象中。由于数据集中列太多，使用Python函数将这种数据结构转换为包含列名作为键，所选单行值作为键的值的字典对象。从这个字典中创建了两个数据集，并绘制了一个条形图。
- en: Tip
  id: totrans-151
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: When working with Spark, Python is used to develop data analysis applications,
    and it is almost certain that there are going to be many charts and plots. Instead
    of trying out all the code samples given in this chapter on the Python REPL for
    Spark, it is better to use IPython notebook as the IDE so that the code and the
    results can be seen together. The download section of this book contains the IPython
    notebook that contains all this code and the results. Readers can directly start
    using this.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用Spark时，Python用于开发数据分析应用程序，几乎可以肯定会有很多图表和图形。与其在本章中尝试所有给出的代码示例在Spark的Python
    REPL上，不如使用IPython笔记本作为IDE，这样代码和结果就可以一起查看。本书的下载部分包含了包含所有这些代码和结果的IPython笔记本。读者可以直接开始使用。
- en: Scatter plot
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 散点图
- en: Scatter plots are very commonly used for plotting values that have two variables,
    such as a point in Cartesian space having an `X` value and `Y` value. In this
    movie dataset, the number of movies released in a given year shows this kind of
    behavior. In the scatter plots, typically, the values represented at the intersection
    points of the `X` coordinate and `Y` coordinate are points. Because of recent
    technology developments and the availability of sophisticated graphics packages,
    many use different shapes and colors to represent the points. In the following
    scatter plot, shown in *Figure 11*, small circles having a uniform area with random
    colors have been used to represent the values. When employing such intuitive and
    clever techniques to represent the points in scatter plots, care must be taken
    to make sure that it does not defeat the purpose and loses the simplicity that
    scatter plots offer to convey the behavior of the data. Simple and elegant shapes
    that do not clutter the Cartesian space are ideal for such non-point representations
    of the values.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 散点图非常常用，用于绘制具有两个变量的值，例如在笛卡尔空间中具有`X`值和`Y`值的点。在这个电影数据集中，给定年份上映的电影数量显示了这种行为。在散点图中，通常，在`X`坐标和`Y`坐标的交点处表示的值是点。由于最近的技术发展和复杂图形包的可用性，许多人使用不同的形状和颜色来表示点。在下面的散点图中，如图*图11*所示，使用了具有均匀面积和随机颜色的细小圆圈来表示值。当在散点图中使用这种直观且巧妙的技术来表示点时，必须注意确保它不会破坏目的，并失去散点图提供的简单性，以传达数据的这种行为。简单且优雅的形状，不会使笛卡尔空间杂乱无章，是这种非点值表示的理想选择。
- en: 'As a continuation of the same Python REPL of Spark, run the following commands:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 作为Spark相同Python REPL的延续，运行以下命令：
- en: '[PRE10]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '![Scatter plot](img/image_05_012.jpg)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![散点图](img/image_05_012.jpg)'
- en: Figure 11
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 图11
- en: In the preceding section, a `SparkDataFrame` was used to collect the top 10
    years in terms of the number of movies released in that year and the values were
    collected into a Python collection object and a scatter plot was drawn.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，使用`SparkDataFrame`收集了按当年上映电影数量排名前十的年份，并将值收集到Python集合对象中，并绘制了散点图。
- en: Enhanced scatter plot
  id: totrans-160
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 增强散点图
- en: '*Figure 11* is a very simple and elegant scatter plot, but it does not really
    convey the comparative behavior of a given plotted value as compared to the other
    values in the same space. For that, instead of representing the points as fixed-radius
    circles, if the points are drawn as circles with the area proportional to the
    value, that will give a different perspective. Figure 12 is going to show the
    scatter plot with the same data, but with circles that have a proportional area
    to represent the points.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '*图11*是一个非常简单且优雅的散点图，但它并没有真正传达给定绘图值与其他相同空间内值的比较行为。为了做到这一点，如果将点绘制为面积与值成比例的圆圈，那么这将提供不同的视角。图12将展示具有相同数据的散点图，但圆圈具有成比例的面积来表示点。'
- en: 'As a continuation in the same Python REPL of Spark, run the following commands:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 作为Spark相同Python REPL的延续，运行以下命令：
- en: '[PRE11]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '![Enhanced scatter plot](img/image_05_013.jpg)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
  zh: '![增强散点图](img/image_05_013.jpg)'
- en: Figure 12
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 图12
- en: In the preceding section, the same dataset was used for *Figure 11* to draw
    the same scatter plot. Instead of plotting the points with uniform area circles,
    the points were drawn with proportionate area circles.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，使用相同的数据集为*图11*绘制了相同的散点图。而不是用均匀面积的圆圈绘制点，而是用成比例面积的圆圈绘制点。
- en: Tip
  id: totrans-167
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: In all these code samples, the charts and plots are displayed using the show
    method. There are methods in matplotlib to save the generated charts and plots
    to disk, and they can be used for e-mailing, publishing to dashboards, and more.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有这些代码示例中，图表和图形都是通过 show 方法显示的。matplotlib 中有方法可以将生成的图表和图形保存到磁盘上，可用于电子邮件、发布到仪表板等。
- en: Line graph
  id: totrans-169
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 折线图
- en: There are similarities between a scatter plot and a line graph. A scatter plot
    is ideal for representing individual data points, but taking all the points together
    gives a trend. A line graph also represents individual data points, but the points
    are connected. This is ideal for seeing the transition from one point to another
    point. In one figure, multiple line graphs can be drawn, enabling the comparison
    of two datasets. The preceding use case used a scatter plot to represent the number
    of movies released over a few years. Those numbers are just discrete data points
    plotted on one figure. If the need is to see a trend of how movie releases are
    changing over the years, a line graph is ideal. Similarly, if there is a need
    to compare movie releases over the years for two different genres, then one line
    can be used for each genre and both can be plotted on a single line graph. *Figure
    13* is a line graph with multiple datasets.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 散点图和折线图之间存在相似之处。散点图非常适合表示单个数据点，但将所有点综合起来则可以显示出趋势。折线图也代表单个数据点，但点之间是相连的。这对于观察从一个点到另一个点的过渡非常理想。在一个图中可以绘制多个折线图，从而实现两个数据集的比较。前面的用例使用散点图来表示过去几年内上映的电影数量。这些数字只是在一个图中绘制的离散数据点。如果需要看到电影发行随年份变化的趋势，折线图是理想的。同样，如果需要比较不同类型电影随年份的发行情况，则可以使用一条线表示每个类型，并将它们绘制在同一个折线图上。*图
    13* 是一个包含多个数据集的折线图。
- en: 'As a continuation of the same Python REPL of Spark, run the following commands:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 作为与 Spark 相同的 Python REPL 的延续，运行以下命令：
- en: '[PRE12]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '![Line graph](img/image_05_014.jpg)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![折线图](img/image_05_014.jpg)'
- en: Figure 13
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13
- en: In the preceding section, Spark DataFrames were created to get the datasets
    for the number of action movies and drama movies released over the period of the
    last 10 years. The data was collected into Python collection objects and line
    graphs were drawn in the same figure.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，创建了 Spark DataFrames 来获取过去 10 年内动作电影和剧情电影发行的数据集。数据被收集到 Python 集合对象中，并在同一图中绘制了折线图。
- en: Python, in conjunction with the matplotlib library, is very rich in terms of
    methods to produce publication-quality charts and plots. Spark can be used as
    the workhorse for processing the data coming from heterogeneous sources of data,
    and the results can also be saved to a wide variety of data formats.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: Python 与 matplotlib 库结合使用，在生成出版物质量图表和图形的方法上非常丰富。Spark 可以用作处理来自异构数据源数据的动力源，并且结果也可以保存到多种数据格式中。
- en: Those who are exposed to the Python data analysis library **pandas** will find
    it easy to understand the material covered in this chapter because Spark DataFrames
    designed from the ground up by taking inspiration from the R DataFrame as well
    as **pandas**.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 对于接触过 Python 数据分析库 **pandas** 的人来说，会发现理解本章涵盖的材料很容易，因为 Spark DataFrames 是从底层设计的，灵感来源于
    R DataFrame 以及 **pandas**。
- en: This chapter has covered only a few sample charts and plots that can be created
    using the **matplotlib** library. The main idea of this chapter was to help the
    reader understand the capability of using this library in conjunction with Spark,
    where Spark is doing the data processing, and **matplotlib** is doing the charting
    and plotting.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 本章仅介绍了使用 **matplotlib** 库可以创建的一些示例图表和图形。本章的主要思想是帮助读者理解结合 Spark 使用此库的能力，其中 Spark
    负责数据处理，而 **matplotlib** 负责图表和图形的绘制。
- en: The data file used in this chapter is read from a local filesystem. Instead
    of this, it can be read from HDFS or any other Spark-supported data source.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 本章使用的数据文件是从本地文件系统读取的。相反，它也可以从 HDFS 或任何其他 Spark 支持的数据源读取。
- en: When using Spark as the primary framework for data processing, the most important
    point to keep in mind is that any possible data processing is to be done by Spark,
    mainly because Spark can do data processing in the best way. Only the processed
    data is to be returned to the Spark driver program for doing the charting and
    plotting.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用 Spark 作为数据处理的主体框架时，需要记住的最重要的一点是，任何可能的数据处理都应该由 Spark 完成，主要是因为 Spark 可以以最佳方式处理数据。只有处理过的数据需要返回给
    Spark 驱动程序进行图表和图形的绘制。
- en: References
  id: totrans-181
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'For more information please refer to following links:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 如需更多信息，请参阅以下链接：
- en: '[http://www.numpy.org/](http://www.numpy.org/)'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://www.numpy.org/](http://www.numpy.org/)'
- en: '[http://www.scipy.org/](http://www.scipy.org/)'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://www.scipy.org/](http://www.scipy.org/)'
- en: '[http://matplotlib.org/](http://matplotlib.org/)'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://matplotlib.org/](http://matplotlib.org/)'
- en: '[https://movielens.org/](https://movielens.org/)'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://movielens.org/](https://movielens.org/)'
- en: '[http://grouplens.org/datasets/movielens/](http://grouplens.org/datasets/movielens/)'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://grouplens.org/datasets/movielens/](http://grouplens.org/datasets/movielens/)'
- en: '[http://pandas.pydata.org/](http://pandas.pydata.org/)'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://pandas.pydata.org/](http://pandas.pydata.org/)'
- en: Summary
  id: totrans-189
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Processed data is used for data analysis. Data analysis requires a deep understanding
    of the processed data. Charts and plots enhance the understanding of the characteristics
    of the underlying data. In essence, for a data analysis application, data processing,
    charting, and plotting are essential. This chapter has covered the usage of Spark
    with Python, in conjunction with Python charting and plotting libraries, for developing
    data analysis applications.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 处理后的数据用于数据分析。数据分析需要深入理解处理后的数据。图表和图形增强了理解底层数据特性的能力。本质上，对于数据分析应用来说，数据处理、图表制作和图形绘制是必不可少的。本章已涵盖使用Python与Spark结合，以及与Python图表和图形库结合，开发数据分析应用的使用方法。
- en: In most organizations, business requirements are driving the need to build data
    processing applications involving the real-time ingestion of data, in various
    shapes and forms, with tremendous velocity. This mandates the need to process
    a stream of incoming data to the organizational data sink. The next chapter is
    going to discuss Spark Streaming, which is a library that works on top of Spark
    and enables the processing of various types of data streams.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数组织中，业务需求推动着构建涉及实时数据摄入的数据处理应用，这些数据以各种形状和形式出现，速度极快。这要求处理流向组织数据汇聚点的数据流。下一章将讨论Spark
    Streaming，这是一个在Spark之上工作的库，它能够处理各种类型的数据流。
