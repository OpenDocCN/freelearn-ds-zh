- en: '6'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '6'
- en: Preparing and Exploring Our Data
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备和探索我们的数据
- en: Data preparation is a common theme in data science, extending beyond its association
    with the machine learning pipeline. It takes on various monikers such as data
    wrangling, data cleaning, and data preprocessing for feature engineering.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 数据准备是数据科学中的一个常见主题，超出了与机器学习流程的关联。它有各种不同的名称，如数据整理、数据清洗和特征工程的数据预处理。
- en: Here, we emphasize that significant time will be invested in data cleaning,
    feature engineering, and exploratory analysis, and we recognize the positive impact
    of robust preprocessing on outcomes, whether for a presentation for business stakeholders
    or its integration to a machine learning model.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们强调将会投入大量时间进行数据清洗、特征工程和探索性分析，并且我们认识到强有力的预处理对结果的积极影响，无论是面向业务利益相关者的展示，还是与机器学习模型的整合。
- en: '**Data cleaning** encompasses tasks focused on identifying and rectifying data
    issues, particularly errors and artifacts. Errors result from data loss in the
    acquisition pipeline, while artifacts arise from the system that generates the
    data. Cleaning involves addressing missing data, handling outliers, removing duplicates,
    and performing necessary translations for data readability and conversion.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据清洗**包括专注于识别和修正数据问题的任务，特别是错误和伪影。错误通常是由于在获取过程中数据丢失，而伪影则来源于生成数据的系统。清洗的工作涉及处理缺失数据、处理异常值、去除重复数据，以及为数据的可读性和转换执行必要的翻译。'
- en: '**Data preparation** spans tasks such as understanding and transforming received
    data to align with subsequent pipeline steps. This chapter delves into common
    scenarios that arise when working to understand, preprocess, and extract information
    from on-chain data. Specific topics include decimal treatment, approaches to smart
    contract evolution, and checksum validation. Additionally, the chapter introduces
    the **Exploratory Data Analysis** (**EDA**) concept and employs techniques for
    summary statistics and outlier detection to illustrate its advantages and insights.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据准备**涵盖了理解和转化接收到的数据，以使其与后续的流程步骤对接。这一章节深入探讨了在理解、预处理和从链上数据中提取信息时常见的情景。具体话题包括十进制处理、智能合约演变的方法和校验和验证。此外，本章还介绍了**探索性数据分析**（**EDA**）的概念，并利用汇总统计和异常值检测技术来展示其优势和见解。'
- en: This chapter explores the intricacies of preparing on-chain data and introduces
    the concept of EDA, facilitating the transition from analytics to machine learning.
    It does not aim to provide an exhaustive overview of all tools and methods, due
    to the extensive nature of this field of data science.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本章探讨了准备链上数据的复杂性，并引入了 EDA 概念，促进了从分析到机器学习的过渡。由于这个数据科学领域的广泛性，本章并不旨在提供所有工具和方法的详尽概述。
- en: 'In summary, this chapter will cover the following topics:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，本章将涵盖以下主题：
- en: On-chain data preparation
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 链上数据准备
- en: Introduction to Exploratory Data Analysis
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索性数据分析介绍
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: We extensively use the Pandas library, a popular and useful Python library for
    working with DataFrames and series. Pandas offers numerous functions to analyze,
    summarize, explore, normalize, and manipulate them. Series are one-dimensional
    array-like objects, and DataFrames are two-dimensional table structures with rows
    and columns. We use Pandas throughout this book’s exercises to perform the aforementioned
    activities.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们广泛使用 Pandas 库，它是一个流行且实用的 Python 库，用于处理 DataFrame 和系列。Pandas 提供了众多函数来分析、总结、探索、归一化和操作它们。系列是一个一维的类似数组的对象，而
    DataFrame 是一个二维的表格结构，包含行和列。本书中的所有练习都将使用 Pandas 来执行上述活动。
- en: 'If you haven’t installed Pandas yet, you can do so with the following code
    snippet:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你还没有安装 Pandas，可以通过以下代码片段来安装：
- en: '[PRE0]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The documentation for Pandas is available at [https://pandas.pydata.org/docs/](https://pandas.pydata.org/docs/).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas 的文档可以在 [https://pandas.pydata.org/docs/](https://pandas.pydata.org/docs/)
    查阅。
- en: For data visualization, we use the Matplotlib and Seaborn libraries. Matplotlib
    provides a wide range of tools and control over the images we build. Seaborn is
    built on top of Matplotlib and is more user-friendly but has less flexibility.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 对于数据可视化，我们使用 Matplotlib 和 Seaborn 库。Matplotlib 提供了广泛的工具和对我们构建图像的控制，而 Seaborn
    构建在 Matplotlib 之上，更加用户友好，但灵活性较差。
- en: The documentation for both libraries can be found at [https://seaborn.pydata.org/](https://seaborn.pydata.org/)
    and [https://matplotlib.org/](https://matplotlib.org/), respectively.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 两个库的文档分别可以在[https://seaborn.pydata.org/](https://seaborn.pydata.org/)和[https://matplotlib.org/](https://matplotlib.org/)找到。
- en: You can find all the data and code files for this chapter in the book’s GitHub
    repository at [https://github.com/PacktPublishing/Data-Science-for-Web3/tree/main/Chapter06](https://github.com/PacktPublishing/Data-Science-for-Web3/tree/main/Chapter06).
    We recommend that you read through the code files in the `Chapter06` folder to
    follow along.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在本书的GitHub仓库中找到本章的所有数据和代码文件，网址为[https://github.com/PacktPublishing/Data-Science-for-Web3/tree/main/Chapter06](https://github.com/PacktPublishing/Data-Science-for-Web3/tree/main/Chapter06)。我们建议你阅读`Chapter06`文件夹中的代码文件，以便跟随学习。
- en: Data preparation
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据准备
- en: When dealing with information collected from diverse data sources, it is crucial
    to ensure consistency and uniformity across all records and fields before extracting
    insights or feeding the data into a machine learning model. In this section, we
    will explore various data preparation tasks that are particularly relevant to
    on-chain data.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理来自不同数据源的信息时，确保所有记录和字段的一致性和统一性非常关键，这样才能提取出有价值的见解或将数据输入到机器学习模型中。在这一部分，我们将探索与链上数据特别相关的各种数据准备任务。
- en: Hex values
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 十六进制值
- en: Hexadecimal notation is a base 16 system, utilizing symbols to represent numerical
    values from 0 to 9 and letters from A to F. In contrast, our everyday decimal
    notation employs 10 symbols to represent numerical values (0–9). Hexadecimal notation
    extends the range by including A to F, representing values from 10 to 15\. This
    notation is often used for data storage purposes due to its efficiency in representing
    binary numbers with each hex digit representing 4 bits.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 十六进制表示法是一个基于16的系统，使用符号表示从0到9的数字值和从A到F的字母值。相比之下，我们日常使用的十进制表示法使用10个符号表示数字值（0-9）。十六进制表示法通过包括A到F，将范围扩展到10到15。这种表示法通常用于数据存储，因为它能够高效地表示二进制数字，每个十六进制数字表示4位二进制数。
- en: In the example presented in `Chapter06/Preparation`, we retrieve the latest
    block number from the Rootstock public node by following the documentation available
    at [https://developers.rsk.co/rsk/public-nodes/](https://developers.rsk.co/rsk/public-nodes/).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在`Chapter06/Preparation`中的示例中，我们通过遵循[https://developers.rsk.co/rsk/public-nodes/](https://developers.rsk.co/rsk/public-nodes/)提供的文档，从Rootstock公共节点检索最新的区块编号。
- en: 'The resulting value is presented in the form of a hex number, such as `0x4e07d0`:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 结果值以十六进制数字的形式呈现，例如`0x4e07d0`：
- en: '![Figure 6.1 – Hexadecimal block number](img/B19446_06_01.jpg)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![图6.1 – 十六进制区块编号](img/B19446_06_01.jpg)'
- en: Figure 6.1 – Hexadecimal block number
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.1 – 十六进制区块编号
- en: 'This hex number can be decoded into a decimal number providing the base (`16`)
    using the following code snippet:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这个十六进制数字可以通过以下代码片段解码为十进制数字，基数为（`16`）：
- en: '![Figure 6.2 – Hexadecimal block number decoded](img/B19446_06_02.jpg)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![图6.2 – 解码后的十六进制区块编号](img/B19446_06_02.jpg)'
- en: Figure 6.2 – Hexadecimal block number decoded
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.2 – 解码后的十六进制区块编号
- en: 'Following those steps, we are able to translate the hex response from the RSK
    node into our decimal system. To verify the accuracy of the translated information,
    we can compare our findings with the chain explorer available at [https://explorer.rsk.co/blocks](https://explorer.rsk.co/blocks)
    or [https://rootstock.blockscout.com/](https://rootstock.blockscout.com/). We
    will see that the block was added to the chain just a moment ago:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 按照这些步骤，我们能够将RSK节点返回的十六进制响应转换为我们的十进制系统。为了验证转换后的信息的准确性，我们可以将结果与链上浏览器中的数据进行对比，浏览器网址为[https://explorer.rsk.co/blocks](https://explorer.rsk.co/blocks)或[https://rootstock.blockscout.com/](https://rootstock.blockscout.com/)。我们会看到该区块刚刚被添加到链上：
- en: '![Figure 6.3 – Block explorer](img/B19446_06_03.jpg)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![图6.3 – 区块浏览器](img/B19446_06_03.jpg)'
- en: Figure 6.3 – Block explorer
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.3 – 区块浏览器
- en: Certain SQL database engines have the capability to convert hex values into
    a human-readable format directly within the query. For example, the ClickHouse
    system used by Covalent provides the `unhex` method. You can find more details
    in the documentation at [https://clickhouse.com/docs/en/sql-reference/functions/encoding-functions#unhex](https://clickhouse.com/docs/en/sql-reference/functions/encoding-functions#unhex).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 某些SQL数据库引擎具备将十六进制值直接转换为人类可读格式的能力。例如，Covalent使用的ClickHouse系统提供了`unhex`方法。你可以在[https://clickhouse.com/docs/en/sql-reference/functions/encoding-functions#unhex](https://clickhouse.com/docs/en/sql-reference/functions/encoding-functions#unhex)的文档中找到更多详情。
- en: Checksum
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 校验和
- en: Checksum is an algorithm that hashes the address, enabling Ethereum to verify
    whether it is a valid address. In Ethereum, a checksummed address contains both
    uppercase and lowercase letters in a specific pattern.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 校验和是一种哈希地址的算法，使得以太坊可以验证地址是否有效。在以太坊中，校验和地址包含了特定模式的大小写字母。
- en: '| **Checksum address** | **Non-checksum address** |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| **校验和地址** | **非校验和地址** |'
- en: '| `0x95222290DD7278Aa3Ddd389Cc1E1d 165CC4BAfe5` | `0x95222290dd7278aa3ddd389cc1e1
    d165cc4bafe5` |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| `0x95222290DD7278Aa3Ddd389Cc1E1d 165CC4BAfe5` | `0x95222290dd7278aa3ddd389cc1e1
    d165cc4bafe5` |'
- en: Table 6.1 – Difference between addresses
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 表6.1 – 地址之间的区别
- en: Ethereum treats both lowercase and checksummed addresses as valid, and funds
    sent to either version will be directed to the same recipient. However, using
    a checksummed address provides an additional layer of security by preventing the
    accidental sending of funds to non-existent addresses.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 以太坊将小写字母和校验和地址视为有效地址，发送到任一版本的资金将会被定向到同一接收者。然而，使用校验和地址能提供额外的安全层，防止意外地将资金发送到不存在的地址。
- en: This section holds significance on two fronts. Firstly, Python, like many SQL
    engines, is case-sensitive. So, it becomes imperative to manage the differentiation
    between lowercase and checksummed addresses when comparing or merging data from
    diverse sources. This guarantees compatibility and precision in data analysis.
    The second dimension pertains to the differentiation between valid and invalid
    addresses, a crucial aspect in maintaining data integrity and making our queries
    faster to run.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 本节有两个重要的意义。首先，Python 和许多 SQL 引擎一样，区分大小写。因此，在比较或合并来自不同源的数据时，管理小写和校验和地址之间的差异变得至关重要。这可以保证数据分析的兼容性和精确性。第二个方面是区分有效和无效地址，这在保持数据完整性和加速查询方面非常关键。
- en: In `Chapter06/Preparation`, we test whether an address is a valid checksummed
    Ethereum address. For this purpose, we utilize the `test()` function allows us
    to convert a lowercase address into its checksummed version.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `Chapter06/Preparation` 中，我们测试一个地址是否是有效的校验和以太坊地址。为此，我们利用 `test()` 函数将一个小写字母地址转换为其校验和版本。
- en: For another example, please refer to `Chapter10/EDA`, where we demonstrate the
    application of checksum addresses within a filter to remove invalid Ethereum addresses.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个例子请参见`Chapter10/EDA`，在该章节中我们演示了如何在过滤器中应用校验和地址，以移除无效的以太坊地址。
- en: Decimal treatment
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 小数处理
- en: 'Solidity is the most commonly used smart contract programming language for
    EVM-based blockchains, but it does not support floats. To express decimals in
    Solidity, we use integers with the `Chapter04/Art` in Jupyter Notebook, in the
    *Chainlink* section, we can see the response from the oracle expressed in the
    following way:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: Solidity 是 EVM 区块链中最常用的智能合约编程语言，但它不支持浮动数值。为了在 Solidity 中表示小数，我们使用整数。在 Jupyter
    Notebook 中的 `Chapter04/Art` 部分，在 *Chainlink* 小节中，我们可以看到来自预言机的响应是以以下方式表示的：
- en: '![Figure 6.4 – Chainlink floor price response](img/B19446_06_04.jpg)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![图6.4 – Chainlink 底价响应](img/B19446_06_04.jpg)'
- en: Figure 6.4 – Chainlink floor price response
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.4 – Chainlink 底价响应
- en: Such a large number is not meaningful in an economic context and cannot be directly
    included in a dashboard or report. Therefore, it is necessary to translate it
    into our decimal system to make it more useful.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这样大的数字在经济学背景下没有意义，无法直接包含在仪表盘或报告中。因此，有必要将其转换为我们的十进制系统，使其更具实用性。
- en: 'Smart contracts provide the number of decimals through a specific function.
    In the case of Chainlink’s data-feed smart contract, the `decimals()` function
    informs us about the fixed point, or, in practical terms, how many decimal places
    we have to shift the comma to the left to convert the response into our decimal
    system. The steps to query the smart contract are explained in the [*Chapter 2*](B19446_02.xhtml#_idTextAnchor073)
    section *Exploring state data*, and as shown in the Jupyter Notebook, the result
    is `18`:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 智能合约通过特定的函数提供小数位数。在 Chainlink 的数据馈送智能合约中，`decimals()` 函数告知我们定点数，或者在实际应用中，告诉我们应该将小数点向左移动多少位才能将响应转换为我们的十进制系统。在[*第2章*](B19446_02.xhtml#_idTextAnchor073)
    *探索状态数据* 一节中解释了如何查询智能合约，正如 Jupyter Notebook 中所展示的，结果是 `18`：
- en: '![Figure 6.5 – The data-feed decimal](img/B19446_06_05.jpg)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![图6.5 – 数据馈送小数](img/B19446_06_05.jpg)'
- en: Figure 6.5 – The data-feed decimal
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.5 – 数据馈送小数
- en: 'The following figure showcases the transformed number that we can use in subsequent
    parts of a data pipeline:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图展示了我们可以在数据管道后续部分使用的转换后的数字：
- en: '![Figure 6.6 – The result](img/B19446_06_06.jpg)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.6 – 结果](img/B19446_06_06.jpg)'
- en: Figure 6.6 – The result
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.6 – 结果
- en: 'The same result can be achieved by applying the `fromWei()` function as per
    the following code snippet:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 通过应用`fromWei()`函数，可以按照以下代码片段实现相同的结果：
- en: '[PRE1]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The decimal treatment we just explored is also relevant for tokens. `decimal()`,
    which *returns the number of decimal places the token uses, for example 8, which
    means to divide the token amount by 100000000 (10 to the power 8) to get its*
    *user representation*.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚探讨的小数处理方法对于代币也同样适用。`decimal()`，它*返回代币使用的小数位数，例如 8，这意味着将代币数量除以 100000000（10
    的 8 次方）来获得其* *用户表示*。
- en: More of this standard was analyzed in [*Chapter 5*](B19446_05.xhtml#_idTextAnchor168).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 更多标准内容已在[*第 5 章*](B19446_05.xhtml#_idTextAnchor168)中进行了分析。
- en: Note on decimals
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 小数位说明
- en: The most common decimal denominator for Ethereum smart contracts is 18, while
    Bitcoin uses 8 and USDT utilizes 6 decimals.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 以太坊智能合约最常见的十进制基数是 18，而比特币使用 8，USDT 则使用 6 个小数位。
- en: In this section, we have learned that consuming on-chain data often requires
    extensive transformations. If our dataset contains excessively large strings that
    lack economic meaning, we may need to search for the smart contract’s decimal
    value to properly position the decimal point. Additionally, if our dataset includes
    hex values, we need to decode them into our decimal system. Lastly, we have discovered
    how to transform lowercase addresses into checksum addresses to ensure compatibility
    with case-sensitive programming languages.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们了解到，消费链上数据通常需要进行大量转换。如果我们的数据集包含过于庞大的字符串且缺乏经济意义，我们可能需要查找智能合约的十进制值，以正确定位小数点位置。此外，如果我们的数据集包含十六进制值，我们需要将其解码为十进制系统。最后，我们还发现了如何将小写地址转换为校验和地址，以确保与区分大小写的编程语言兼容。
- en: From Unix timestamps to datetime formats
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从 Unix 时间戳到日期时间格式
- en: Unix timestamps are commonly used in data analysis, but for visualization purposes
    in dashboards and reports, it is necessary to convert them into a human-readable
    format. Unix time represents the number of seconds that have passed since January
    1, 1970, providing a system to track time using a single integer value.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: Unix 时间戳在数据分析中常被使用，但为了在仪表盘和报告中进行可视化，需要将其转换为人类可读的格式。Unix 时间表示自 1970 年 1 月 1 日以来已过去的秒数，提供了一种通过单一整数值来追踪时间的系统。
- en: In most SQL engines, the `truncate` function can be utilized to extract the
    relevant date part from the timestamp.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数 SQL 引擎中，可以利用`truncate`函数从时间戳中提取相关的日期部分。
- en: In Python, we can use the `datetime` module’s `fromtimestamp()` function, which
    converts Unix timestamps to local datetime, and the `utcfromtimestamp()` function,
    which converts them to UTC datetimes.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Python 中，我们可以使用`datetime`模块的`fromtimestamp()`函数，将 Unix 时间戳转换为本地日期时间，使用`utcfromtimestamp()`函数，将其转换为
    UTC 日期时间。
- en: 'In the Jupyter Notebook’s `Chapter06/Preparation` section, we translate a Unix
    timestamp with the following code:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Jupyter Notebook 的`Chapter06/Preparation`部分，我们使用以下代码将 Unix 时间戳转换为日期时间：
- en: '![Figure 6.7 – Datetime translation](img/B19446_06_07.jpg)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.7 – 日期时间转换](img/B19446_06_07.jpg)'
- en: Figure 6.7 – Datetime translation
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.7 – 日期时间转换
- en: 'To validate our results, we can compare them with those obtained from [https://www.unixtimestamp.com/](https://www.unixtimestamp.com/),
    a popular tool that shows the same information:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 为了验证我们的结果，我们可以将其与[https://www.unixtimestamp.com/](https://www.unixtimestamp.com/)网站上的数据进行对比，该工具展示了相同的信息：
- en: '![Figure 6.8 – Unix timestamp translator](img/B19446_06_08.jpg)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.8 – Unix 时间戳转换器](img/B19446_06_08.jpg)'
- en: Figure 6.8 – Unix timestamp translator
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.8 – Unix 时间戳转换器
- en: Evolution of smart contracts
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 智能合约的演变
- en: Smart contracts, like any software product, may undergo changes and require
    upgrades for various reasons such as business necessity, security incidents, or
    to reduce gas costs. However, by design, everything deployed on the blockchain
    is immutable. The following information, sourced from [Ethereum.org](http://Ethereum.org),
    outlines multiple approaches to enable an upgrade. The content is quoted under
    the **Creative Commons Attribution 4.0 International** (**CC BY 4.0**) license,
    in compliance with the terms of use. The original document can be found in the
    *Further reading* section of this chapter.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 智能合约和任何软件产品一样，可能会因为业务需求、安全事件或减少燃气费用等多种原因而发生变化和需要升级。然而，根据设计，区块链上部署的一切都是不可变的。以下信息来自[Ethereum.org](http://Ethereum.org)，概述了多种实现升级的方法。内容引用自**创意共享署名
    4.0 国际**（**CC BY 4.0**）许可协议，符合使用条款。原文可以在本章的*进一步阅读*部分找到。
- en: 'Smart contract upgrades can be achieved via the following methods:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 智能合约的升级可以通过以下方式实现：
- en: Creating multiple versions of a smart contract and migrating state (i.e., data)
    from the old contract to a new instance of the contract
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建多个版本的智能合约，并将状态（即数据）从旧合约迁移到新合约实例
- en: Creating separate contracts to store business logic and state
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建独立的合约来存储业务逻辑和状态
- en: Using proxy patterns to delegate function calls from an immutable proxy contract
    to a modifiable logic contract
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用代理模式将函数调用从不可变的代理合约委托给可修改的逻辑合约
- en: Creating an immutable main contract that interfaces with and relies on flexible
    satellite contracts to execute specific functions
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个不可变的主合约，该合约通过灵活的卫星合约执行特定功能
- en: Using the diamond pattern to delegate function calls from a proxy contract to
    logic contracts
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用钻石模式将代理合约的函数调用委托给逻辑合约
- en: In conclusion, the ways to upgrade a smart contract do not involve modifying
    the deployed code. Rather, it entails substituting one contract for another. Currently,
    the most popular method for upgrading smart contracts is the **proxy pattern**.
    This pattern involves a separation between the proxy contract and the execution
    contract that holds the logic. The proxy acts on behalf of the logic smart contract
    redirecting transactions from the frontend to the correct smart contract in the
    backend. It is possible to swap the logic smart contract in the backend and update
    the proxy to start redirecting transactions to the newly deployed smart contract
    with the latest logic.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，升级智能合约的方法并不涉及修改已部署的代码，而是用一个合约替代另一个。目前，升级智能合约最流行的方法是**代理模式**。这种模式将代理合约和包含逻辑的执行合约分离。代理合约代表逻辑智能合约，将前端的交易重定向到后端正确的智能合约。可以在后端交换逻辑智能合约，并更新代理合约，使其开始将交易重定向到新部署的智能合约，该合约包含最新的逻辑。
- en: The fact that contracts may change implies that our queries need to adapt to
    reflect those changes. For example, if a smart contract starts emitting an event
    at a certain block, we need to be aware of it to capture the new information.
    As we saw in [*Chapter 2*](B19446_02.xhtml#_idTextAnchor073), we need the **Application
    Binary Interface** (**ABI**) to decode smart contracts that need to be duly updated
    to decode transactions after an upgrade. Not being aware that the contract we
    are parsing has changed may cause us to miss certain events and may negatively
    impact our analysis.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 合约可能发生变化，这意味着我们的查询需要适应这些变化。例如，如果一个智能合约在某个区块开始触发事件，我们需要意识到这一点，以便捕捉新的信息。正如我们在[*第2章*](B19446_02.xhtml#_idTextAnchor073)中看到的，我们需要**应用程序二进制接口**（**ABI**）来解码智能合约，这些合约需要在升级后适当地更新以解码交易。如果我们没有意识到正在解析的合约已经发生了变化，可能会错过某些事件，并且可能对我们的分析产生负面影响。
- en: When analyzing a specific project, it’s important to follow press releases,
    project representatives, and official information channels for news of any development
    launched to direct our queries to the smart contract that is less prone to changes.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在分析具体项目时，重要的是要关注新闻发布、项目代表和官方信息渠道，了解是否有任何新开发，这样我们可以将查询指向更不容易变动的智能合约。
- en: In conclusion, while smart contracts are designed to be immutable, there are
    circumstances where upgrades and changes become necessary, and we need to be prepared
    to adapt our queries or code to these changes. For example, if we were analyzing
    Ethereum, we would need to be aware that the entire chain changed with the Merge,
    which occurred in September 2022 and has an impact at the data level.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，尽管智能合约设计为不可更改，但在某些情况下，升级和更改变得必要，我们需要做好准备，调整我们的查询或代码以适应这些变化。例如，如果我们正在分析以太坊，我们需要意识到整个区块链在2022年9月的合并（Merge）后发生了变化，并且这种变化会在数据层面产生影响。
- en: Exploratory Data Analysis
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索性数据分析
- en: 'Between the data cleaning phase and the modeling or formal statistical analysis,
    there exists an intermediate step known as EDA, which is a fundamental aspect
    of data science. EDA serves as the primary approach to understanding and making
    sense of a dataset, providing insights into the “population out of the sample”
    and transforming raw data into actionable information for businesses. EDA can
    include various techniques and methods:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据清洗阶段和建模或正式统计分析之间，存在一个中间步骤，称为EDA，这是数据科学的一个基本方面。EDA作为理解和解释数据集的主要方法，提供了关于“样本之外的总体”的洞察，并将原始数据转化为可供企业使用的可操作信息。EDA可以包括多种技术和方法：
- en: '**Data summary or descriptive statistics**: Used to summarize central tendencies
    within the dataset.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据摘要或描述性统计**：用于总结数据集中的中心趋势。'
- en: '**Data visualization**: Graphical techniques such as histograms, box plots,
    scatter plots, and line plots are employed to visualize the data, aiding in pattern
    identification, outlier detection, and understanding the relationship between
    variables. Furthermore, data visualization is particularly effective when presenting
    conclusions to a non-technical audience.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据可视化**：采用直方图、箱形图、散点图和折线图等图形技术来可视化数据，帮助识别模式、检测异常值，并理解变量之间的关系。此外，数据可视化在向非技术性观众展示结论时特别有效。'
- en: '**Data exploration**: Helps us understand the distribution of variables, assess
    their shapes and skewness, and identify the presence of anomalies.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据探索**：帮助我们理解变量的分布，评估其形态和偏斜度，识别异常的存在。'
- en: '**Handling missing data**: This allows us to identify missing rows and assess
    their impact on the results. It helps to determine patterns in missing values
    and to develop strategies for handling them effectively.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**处理缺失数据**：这使我们能够识别缺失的行并评估它们对结果的影响。它有助于确定缺失值的模式，并制定有效处理它们的策略。'
- en: '**Outlier detection**: Identifying values that significantly deviate from the
    rest of the dataset and evaluating their influence on the analysis. These outliers
    can result from various causes, which we will discuss in the subsequent section.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**异常值检测**：识别与数据集其他部分显著偏离的值，并评估其对分析的影响。这些异常值可能来自多种原因，我们将在后续部分讨论这些原因。'
- en: '**Correlations and patterns**: Explores the relationships between variables
    using techniques such as correlation analysis and scatter plots. Additionally,
    they help identify trends or seasonality in the data over time.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**相关性和模式**：通过相关分析和散点图等技术，探索变量之间的关系。此外，它们有助于识别数据随时间变化的趋势或季节性。'
- en: 'A concise description of EDA can be found at [https://towardsdatascience.com/exploratory-data-analysis-8fc1cb20fd15](https://towardsdatascience.com/exploratory-data-analysis-8fc1cb20fd15):
    "*Exploratory Data Analysis refers to the critical process of performing initial
    investigations on data so as to discover patterns, to spot anomalies, to test
    hypothesis and to check assumptions with the help of summary statistics and* *graphical
    representations."*'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 有关EDA的简要描述可以在[https://towardsdatascience.com/exploratory-data-analysis-8fc1cb20fd15](https://towardsdatascience.com/exploratory-data-analysis-8fc1cb20fd15)找到：“*探索性数据分析是指对数据进行初步调查，以发现模式、识别异常、测试假设和检查假设，借助于汇总统计和*
    *图形表示法。*"
- en: In this chapter, we will provide a brief introduction to summary statistics
    and outlier detection with the aid of graphical representations. We chose those
    two topics as they are probably transversals to all the datasets we will encounter
    in our journey. For further exploration of EDA topics, feel free to refer to the
    books in the *Further reading* section that are very useful.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将简要介绍汇总统计和利用图形表示法进行异常值检测。我们选择这两个主题，因为它们可能适用于我们在旅程中遇到的所有数据集。有关EDA主题的进一步探索，欢迎参考*进一步阅读*部分中的书籍，它们非常有用。
- en: To exemplify the concepts learned in this section, we will use the **Witches**
    dataset available on Kaggle ([https://www.kaggle.com/datasets/harrywang/crypto-coven?select=witches.csv](https://www.kaggle.com/datasets/harrywang/crypto-coven?select=witches.csv)).
    It contains information about the Crypto Coven NFT project, where each row represents
    one witch NFT. The Witches project’s main page can be found at [https://www.cryptocoven.xyz/](https://www.cryptocoven.xyz/).
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 为了举例说明本节中学到的概念，我们将使用Kaggle上提供的**Witches**数据集（[https://www.kaggle.com/datasets/harrywang/crypto-coven?select=witches.csv](https://www.kaggle.com/datasets/harrywang/crypto-coven?select=witches.csv)）。该数据集包含关于Crypto
    Coven NFT项目的信息，每一行代表一个女巫NFT。Witches项目的主页可以在[https://www.cryptocoven.xyz/](https://www.cryptocoven.xyz/)找到。
- en: Summarizing data
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据汇总
- en: Our datasets will contain categorical or quantitative variables. Categorical
    variables are those that can be divided into groups, such as colors or brands.
    On the other hand, quantitative variables represent numerical amounts, such as
    prices or the number of sales. The `df.describe()` code snippet returns the quantitative
    variables and their distribution.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的数据集将包含分类变量或定量变量。分类变量是指可以分为组的变量，例如颜色或品牌。另一方面，定量变量代表数值量，例如价格或销售数量。`df.describe()`代码片段返回定量变量及其分布情况。
- en: Calculating the distribution of categorical data involves determining the frequency
    of each category. This analysis can provide meaningful insights. For example,
    in marketing, understanding the distribution of categorical variables such as
    age groups, income levels, or consumer preferences can help businesses segment
    their target audience effectively and create more targeted and successful campaigns.
    Another example is in fraud detection, where categorical variables such as transaction
    types or user behavior patterns can be crucial in detecting fraudulent activities.
    By studying the distribution of these variables, anomalies or unusual patterns
    can be identified, enabling organizations to develop effective fraud-detection
    models and strategies.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 计算分类数据的分布涉及确定每个类别的频率。这种分析可以提供有意义的见解。例如，在市场营销中，理解年龄组、收入水平或消费者偏好等分类变量的分布可以帮助企业有效地细分目标受众，并制定更具针对性和成功的营销活动。另一个例子是在欺诈检测中，分类变量如交易类型或用户行为模式在识别欺诈活动中至关重要。通过研究这些变量的分布，可以识别出异常或不寻常的模式，从而使组织能够开发出有效的欺诈检测模型和策略。
- en: An application in the NFT space is to help determine whether a collection is
    owned by the retail public or whether it is held by a small group of collectors
    (centralized). This knowledge about an art collection’s ownership characteristics
    can help an investor assess whether a project’s price aligns with the market value
    or whether it is susceptible to manipulation. A more decentralized ownership structure
    implies a price closer to the market value.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在NFT领域中的一个应用是帮助确定一个系列是由零售公众拥有，还是由少数收藏者（集中化）持有。关于艺术品收藏的所有权特征的了解，可以帮助投资者评估项目价格是否与市场价值一致，或者是否容易受到操控。更加去中心化的所有权结构意味着价格更接近市场价值。
- en: 'In `Chapter06/EDA.ipynb`, we investigate the distribution of NFTs by creating
    two categories of holders: those with more than three NFTs of the same collection,
    which we name *collectors*, and those with fewer than three NFTs, that is, the
    *general public*. We follow three steps:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在`Chapter06/EDA.ipynb`中，我们通过创建两类持有者来研究NFT的分布：那些拥有超过三个同系列NFT的地址，我们称之为*收藏者*，以及那些持有少于三个NFT的地址，也就是*普通公众*。我们遵循三个步骤：
- en: We count how many NFTs each address has, equivalent to a `GROUP BY` operation
    in a SQL query. This allows us to understand the holdings of each address.
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们统计每个地址持有的NFT数量，相当于SQL查询中的`GROUP BY`操作。这使我们能够了解每个地址的持有情况。
- en: We create a list of addresses that hold more than three NFTs from the same collection.
    The number of NFTs per address criteria is part of our analysis and a decision
    we make during the EDA. These micro-decisions impact the final result, and it
    is good practice to document them.
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们创建了一个地址列表，这些地址持有来自同一系列的超过三个NFT。每个地址持有的NFT数量是我们分析的一部分，也是我们在EDA过程中做出的决策。这些微小的决策会影响最终结果，文档化它们是一个良好的实践。
- en: We build two separate `collectors_df` and `distributed_df` datasets depending
    on whether the address is in the list from Step 2.
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们根据地址是否在步骤2的列表中，分别构建`collectors_df`和`distributed_df`数据集。
- en: With these straightforward steps, we can calculate the percentage of collectors
    and distributed owners for the project. *Figure 6**.9* reveals that the collector
    percentage is only 32%, while the remaining 68% is held by the public.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这些简单的步骤，我们可以计算项目中收藏者和分布所有者的百分比。*图 6.9* 显示，收藏者的百分比只有 32%，而其余的 68% 是由公众持有的。
- en: '![Figure 6.9 – Collector and distributed percentages](img/B19446_06_09.jpg)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.9 – 收藏者和分布百分比](img/B19446_06_09.jpg)'
- en: Figure 6.9 – Collector and distributed percentages
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.9 – 收藏者和分布百分比
- en: To summarize quantitative variables, we introduce concepts such as the mean,
    average, deviations, outliers, and others. Let’s start with measures of central
    tendency or summary statistics, which are used to describe a set of values with
    a single value. These include the mean, median, and mode.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 为了总结定量变量，我们引入了均值、平均值、偏差、异常值等概念。我们从集中趋势或总结性统计量开始，它们用于用单一的数值来描述一组值。这些统计量包括均值、中位数和众数。
- en: 'The **mean**, or average, is the most commonly used measure. It is calculated
    by summing all the values in a dataset and dividing it by the number of values:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '**平均数**，即算术平均数，是最常用的度量方式。它是通过将数据集中所有值相加，并除以值的个数来计算的：'
- en: '[PRE2]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'For example: if we have `5`, `7`, `2`, `10`, and `6` as values, the mean would
    be (5 + 7 + 2 + 10 + 6) / 5 = 6.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 例如：如果我们的值是 `5`、`7`、`2`、`10` 和 `6`，则平均数为 (5 + 7 + 2 + 10 + 6) / 5 = 6。
- en: 'Pandas provides the `mean()` function, which returns the mean value for a column
    passed. If we calculate the mean of prices in the Witch dataset, we will add all
    prices and divide the result by the number of rows. Please see the following code
    snippet in `Chapter06/EDA.ipynb`, where we calculated the mean for the `price`
    column:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas 提供了 `mean()` 函数，它返回传递给列的均值。如果我们计算 Witch 数据集中的价格均值，我们将所有价格相加，然后将结果除以行数。请参见
    `Chapter06/EDA.ipynb` 中的以下代码片段，我们在其中计算了 `price` 列的均值：
- en: '[PRE3]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: To calculate the mean, all values are considered, but the resulting number may
    not be in the analyzed sample. Another important aspect is that the mean value
    is heavily influenced by outliers. Therefore, it is necessary to clean the dataset
    and remove outliers before calculating it.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 计算均值时，所有值都会被考虑在内，但计算出的数值可能不在分析的样本中。另一个重要的方面是，均值受到异常值的强烈影响。因此，在计算均值之前，需要清理数据集并删除异常值。
- en: The mean value is not a perfect measure of central tendency when the data is
    skewed. A better alternative is the median.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据存在偏斜时，均值并不是集中趋势的完美度量。一个更好的替代方案是中位数。
- en: 'The **median** is defined as the middle value of a column when arranged in
    order of magnitude, from smallest to largest. To manually calculate the median,
    we would follow these steps:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '**中位数**被定义为按大小顺序排列后的列的中间值，从最小到最大。要手动计算中位数，我们可以按照以下步骤进行：'
- en: Take all values from the `price` column and order them from smallest to largest.
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 `price` 列中的所有值从小到大排序。
- en: 'Find the number situated in the center that divides the dataset into two equal
    parts:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 找到位于数据集中心的数值，将数据集分成两部分：
- en: '`Formula (odd number of values): Median =` `Middle value`'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`公式（奇数个值）：中位数 =` `中间值`'
- en: '`Formula (even number of values): Median = (Sum of two middle values) / 2`'
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`公式（偶数个值）：中位数 = （两个中间值的总和）/ 2`'
- en: 'For example: for the `5`, `7`, `2`, `10`, and `6` dataset, when arranged in
    ascending order, the median would be 6.'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 例如：对于数据集 `5`、`7`、`2`、`10` 和 `6`，当按升序排列时，中位数将是 6。
- en: 'Pandas provides the `median()` function to perform this calculation. For instance,
    to calculate the median for the `price` column, we can use the following code
    snippet, which is also shown in `Chapter06/EDA.ipynb`:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas 提供了 `median()` 函数来执行这个计算。例如，要计算 `price` 列的中位数，我们可以使用以下代码片段，这也显示在 `Chapter06/EDA.ipynb`
    中：
- en: '[PRE4]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The median is often preferred over the mean when dealing with skewed data or
    data with outliers.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理偏斜数据或存在异常值的数据时，中位数通常优于均值。
- en: 'In `Chapter04/Art.ipynb`, when summarizing the data to find the floor price
    from multiple marketplaces over a set period of time, we chose to show the median
    instead of the average and the result is the following:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `Chapter04/Art.ipynb` 中，当总结数据以寻找多个市场在一段时间内的最低价格时，我们选择显示中位数而不是平均值，结果如下：
- en: '![Figure 6.10 – Median floor price by marketplace](img/B19446_06_10.jpg)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.10 – 按市场划分的中位数最低价格](img/B19446_06_10.jpg)'
- en: Figure 6.10 – Median floor price by marketplace
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.10 – 按市场划分的中位数最低价格
- en: If we had used the average, the graphic would have shown significant variations
    between marketplaces, as depicted in *Figure 6**.11*. Analyzing the floor price
    based on the average would not have been accurate, especially when referring to
    the OpenSea offer.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们使用平均值，图形将显示市场之间的显著差异，如*图 6.11* 所示。基于平均值分析地板价格并不准确，特别是当我们提到 OpenSea 报价时。
- en: '![Figure 6.11 – Average floor price by marketplace](img/B19446_06_11.jpg)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.11 – 各市场的平均地板价格](img/B19446_06_11.jpg)'
- en: Figure 6.11 – Average floor price by marketplace
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.11 – 各市场的平均地板价格
- en: 'The **mode** is another measure of central tendency that represents the most
    frequently occurring value in the dataset. Graphically speaking, it is represented
    by the highest bar in the histogram. It can also be used with categorical variables.
    To calculate the mode manually, we would identify the most repeated price in our
    dataset:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '**众数**是另一种集中趋势的度量，表示数据集中最频繁出现的值。从图形上讲，它由直方图中最高的柱形表示。它也可以与分类变量一起使用。要手动计算众数，我们需要识别数据集中最常出现的价格：'
- en: '[PRE5]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: For example, in the `15`, `20`, `18`, `22`, `15`, `20`, `18`, `20`, `22`, and
    `25` dataset, the value that appears most frequently is 20\. It appears three
    times.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在 `15`、`20`、`18`、`22`、`15`、`20`、`18`、`20`、`22` 和 `25` 的数据集中，出现频率最高的值是 20\。它出现了三次。
- en: 'Pandas provides the `mode()` function to calculate the mode for a column, as
    shown in the following code snippet from `Chapter06/EDA.ipynb`:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas 提供了 `mode()` 函数来计算某列的众数，如 `Chapter06/EDA.ipynb` 中的以下代码片段所示：
- en: '[PRE6]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: A note on missing prices
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 缺失价格的说明
- en: Measures of central tendency not only assist us in summarizing our dataset but
    also prove helpful in addressing missing values within the dataset.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 集中趋势的度量不仅有助于总结我们的数据集，还能帮助解决数据集中的缺失值问题。
- en: For instance, during periods of extreme volatility, certain trading houses may
    suspend commercialization. This holds true for both traditional markets and centralized
    crypto exchanges. If our database happens to source prices from such an exchange,
    it is possible that there will be missing rows of data. In such scenarios, pandas
    functions such as `fillna()` or `interpolate()` can be employed to impute missing
    values. With the `fillna()` function, we can specify whether to complete the NaN
    values with the mean or the median.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在极端波动期间，某些交易所可能会暂停商业化。这适用于传统市场和集中化的加密货币交易所。如果我们的数据库恰好从这种交易所获取价格数据，可能会出现缺失的数据行。在这种情况下，可以使用
    pandas 函数，如 `fillna()` 或 `interpolate()`，来填充缺失值。使用 `fillna()` 函数，我们可以指定是否用均值或中位数来填充
    NaN 值。
- en: In conclusion, in our EDA, we have explored measures of central tendency such
    as the mean, median, and mode, which provide insights into the distribution and
    characteristics of our data.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，在我们的 EDA 中，我们探讨了集中趋势的度量方法，如均值、中位数和众数，这些方法提供了关于我们数据分布和特征的洞察。
- en: Building upon our exploration of central tendency, we now turn our attention
    to outlier detection. Outliers are data points that deviate significantly from
    the overall pattern of the dataset, and they can have a substantial impact on
    our analysis and interpretation. In the next section, we will delve into various
    techniques and approaches for identifying outliers.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们探讨集中趋势的基础上，现在我们将注意力转向异常值检测。异常值是偏离数据集整体模式的数据点，它们可能对我们的分析和解释产生重大影响。在接下来的部分中，我们将深入研究识别异常值的各种技术和方法。
- en: Outlier detection
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 异常值检测
- en: According to the book *Introduction to Data Science* by Rafael A. Irizarry,
    outliers are defined as *“data samples with a value that is far from the central
    tendency*." While outliers are not inherently good or bad, they can significantly
    impact our analysis and lead to incorrect conclusions. This is particularly true
    when working with prices, where market volatility can distort the true value of
    assets transacted. Prices are used as proxies for value, but it’s important to
    recognize that some prices deviate significantly from the actual value, making
    them outliers.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 根据 Rafael A. Irizarry 的《数据科学导论》一书，异常值被定义为 *“与集中趋势相差较远的数据样本”*。虽然异常值本身既不一定是好也不一定是坏的，但它们可以显著影响我们的分析，并导致不正确的结论。特别是在处理价格时，市场波动性可能会扭曲交易资产的真实价值。价格作为价值的代理，但重要的是要认识到，有些价格显著偏离实际价值，成为异常值。
- en: In certain instances, the primary goal is to identify and analyze outliers,
    which is typically the focus in anomaly detection techniques such as those discussed
    in [*Chapter 4*](B19446_04.xhtml#_idTextAnchor145), specifically for uncovering
    fraud or money laundering.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，主要目标是识别和分析异常值，这通常是异常检测技术的重点，例如在[*第4章*](B19446_04.xhtml#_idTextAnchor145)中讨论的技术，特别是用于揭露欺诈或洗钱。
- en: 'There are several reasons why outliers may occur:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 异常值出现的原因有多种：
- en: An instrument measurement error such as a disconnected API or an unbalanced
    scale
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 仪器测量误差，如API断开或不平衡的秤
- en: Data entry errors
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据录入错误
- en: Working with samples or populations that are less homogeneous than initially
    assumed
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理的样本或群体比最初假设的要不均匀
- en: 'Let’s explore some techniques to identify outliers in our dataset:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们探索一些识别数据集异常值的技巧：
- en: '**Box plot** (**whisker plot**): This graphical representation summarizes the
    data using five important numbers: minimum, first quartile, median, third quartile,
    and maximum. We can identify outliers as those that are far from the box:'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**箱线图**（**胡须图**）：这种图形表示法通过五个重要数字总结数据：最小值、第一个四分位数、中位数、第三个四分位数和最大值。我们可以将远离箱体的数据点识别为异常值：'
- en: '![Figure 6.12 – Parts of the box plot](img/B19446_06_12.jpg)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![图6.12 – 箱线图的部分](img/B19446_06_12.jpg)'
- en: Figure 6.12 – Parts of the box plot
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.12 – 箱线图的部分
- en: 'This image can be automatically generated by Pandas with the following code
    snippet:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 这张图像可以通过以下代码片段由Pandas自动生成：
- en: '[PRE7]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
