- en: Declaring the Objectives
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 声明目标
- en: This chapter introduces and explains (yet again, from a developer's perspective)
    the basic objectives behind statistics for data science and introduces the reader
    to the important terms and key concepts (with explanations and examples) that
    are used throughout the book.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍并解释了（再次从开发者的角度）数据科学统计学的基本目标，并向读者介绍了书中使用的关键术语和概念（带有解释和示例）。
- en: 'In this chapter, we''ve broken things down into the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将内容拆解为以下几个主题：
- en: A primer on the key objectives of data science
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据科学的关键目标入门
- en: Bringing statistics into data science
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将统计学引入数据科学
- en: Common terminologies used with statistics and data science
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 统计学和数据科学中常用的术语
- en: Key objectives of data science
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据科学的关键目标
- en: As mentioned in [Chapter 1](7f3dc6b3-d483-4ffc-b330-22b36da9bdc7.xhtml), *Transitioning
    from Data Developer to Data Scientist*, the idea of how data science is defined
    is a matter of opinion.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 如[第1章](7f3dc6b3-d483-4ffc-b330-22b36da9bdc7.xhtml)中所提到的，*从数据开发者到数据科学家的过渡*，数据科学如何定义是一个主观问题。
- en: 'I personally like the explanation that data science is a progression or, even
    better, an evolution of thought or steps, as shown in the following figure:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我个人喜欢的解释是，数据科学是思想或步骤的进程，甚至更好的是，它是一个演变过程，如下图所示：
- en: '![](img/f97c563f-aee0-496d-ae4b-68c4eee48a35.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f97c563f-aee0-496d-ae4b-68c4eee48a35.png)'
- en: 'This data science evolution (depicted in the preceding figure) consists of
    a series of steps or phases that a data scientist tracks, comprising the following:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这种数据科学的演变（如前图所示）由一系列步骤或阶段组成，数据科学家在其中跟踪进展，包括以下内容：
- en: Collecting data
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据收集
- en: Processing data
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据处理
- en: Exploring and visualizing data
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索和可视化数据
- en: Analyzing (data) and/or applying machine learning (to data)
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据分析和/或应用机器学习（于数据）
- en: Deciding (or planning) based on acquired insight
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于获得的见解做决策（或规划）
- en: Although a progression or evolution implies a sequential journey, in practice,
    this is an extremely fluid process; each of the phases may inspire the data scientist
    to reverse and repeat one or more of the phases until they are satisfied. In other
    words, all or some phases of the process may be repeated until the data scientist
    determines that the desired outcome is reached.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管“进展”或“演变”暗示了一个顺序性的旅程，但在实践中，这是一个非常流动的过程；每个阶段都可能激发数据科学家反向并重复一个或多个阶段，直到他们感到满意。换句话说，过程中的所有或部分阶段可能会被重复，直到数据科学家认为已达成期望的结果。
- en: For example, after a careful review of a generated visualization (during the
    *Exploring and visualizing data* phase), one may determine that additional processing
    of the data is required or that additional data needs to be collected before any
    reasonable analysis or learning could be of value.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在仔细审查生成的可视化图表后（在*探索和可视化数据*阶段），可能会发现需要对数据进行额外处理，或者在进行任何合理的分析或学习之前，需要收集更多的数据。
- en: You might loosely compare the data science process to the agile software development
    mythology where a developer performs various tasks, the results are analyzed,
    more work is done, the work is again reviewed, and the process is repeated until
    the desired results or outcomes are obtained.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以大致将数据科学过程与敏捷软件开发方法论进行比较，在这种方法中，开发者执行各种任务，分析结果，继续工作，重新审视工作，直到获得期望的结果或成果。
- en: Let's explain each of the phases of the data science evolution.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们解释数据科学演变的每一个阶段。
- en: Collecting data
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据收集
- en: This should be somewhat obvious—without (at least some) data, we cannot perform
    any of the subsequent steps (although one might argue the point of inference,
    that would be inappropriate. There is no magic in data science. We, as data scientists,
    don't make something from anything. Inference (which we'll define later in this
    chapter) requires at least some data to begin with.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这一点应该是显而易见的——没有（至少一些）数据，我们无法执行任何后续步骤（尽管有人可能会争论推断问题，但那是不合适的。数据科学中没有魔法。我们，作为数据科学家，不是从任何东西中创造出东西。推断（我们将在本章稍后定义）至少需要一些数据作为起点。
- en: Some new concepts for collecting data include the fact that data can be collected
    from ample of sources, and the number and types of data sources continue to grow
    daily. In addition, how data is collected might require a perspective new to a
    data developer; data for data science isn't always sourced from a relational database,
    rather from machine-generated logging files, online surveys, performance statistics,
    and so on; again, the list is ever evolving.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 收集数据的一些新概念包括数据可以来自各种来源，数据源的数量和类型每天都在增长。此外，数据的收集方式可能需要数据开发者一种全新的视角；数据科学中的数据并不总是来自关系型数据库，而是来自机器生成的日志文件、在线调查、性能统计等；再次强调，这个列表仍在不断发展。
- en: Another point to ponder—collecting data also involves supplementation. For example,
    a data scientist might determine that he or she needs to be adding additional
    demographics to a particular pool of application data previously collected, processed,
    and reviewed.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个值得思考的点是，收集数据也涉及补充。例如，数据科学家可能会发现需要为先前收集、处理和审核过的特定应用数据池添加额外的群体统计数据。
- en: Processing data
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理数据
- en: The processing (or transformation) of data is where the data scientist's programming
    skills will come in to play (although you can often find a data scientist performing
    some sort of processing in other steps, like collecting, visualizing, or learning).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 数据的处理（或转换）是数据科学家编程技能发挥作用的地方（尽管你通常可以看到数据科学家在其他步骤中执行某种形式的处理，例如收集、可视化或学习）。
- en: Keep in mind that there are many aspects of processing that occur within data
    science. The most common are formatting (and reformatting), which involves activities
    such as mechanically setting data types, aggregating values, reordering or dropping
    columns, and so on, cleansing (or addressing the quality of the data), which is
    solving for such things as default or missing values, incomplete or inapposite
    values, and so on, and profiling, which adds context to the data by creating a
    statistical understanding of the data.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，数据科学中涉及的处理方面有很多。最常见的包括格式化（和重新格式化），其涉及的活动如机械地设置数据类型、汇总值、重新排序或删除列等；数据清理（或处理数据质量），解决诸如默认值或缺失值、不完整或不合适的值等问题；以及数据分析，生成统计性的数据理解，为数据提供背景信息。
- en: The processing to be completed on the data can be simple (for example, it can
    be a very simple and manual event requiring repetitious updates to data in an
    MS Excel worksheet), or complex (as with the use of programming languages such
    as R or Python), or even more sophisticated (as when processing logic is coded
    into routines that can then be scheduled and rerun automatically on new populations
    of data).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 对数据进行的处理可以是简单的（例如，可能是一个非常简单且手动的事件，需要对MS Excel工作表中的数据进行重复更新），也可以是复杂的（如使用R或Python等编程语言），甚至更复杂（例如，当处理逻辑被编写到程序中时，这些程序可以被调度，并在新的数据群体上自动重新运行）。
- en: Exploring and visualizing data
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索与可视化数据
- en: During this phase or step in the overall data science pipeline process, the
    data scientist will use various methods to dig deeper into the data. Typically,
    several graphical representations are created (again, either manually or through
    a programming script or tool) emphasizing or validating a data scientist's observation,
    a particular point, or belief. This is a significant step in the overall data
    science process as the data scientist may come to understand that additional processing
    should be done on the data, or additional data needs to be collected, or perhaps
    the original theories appear to be validated. These findings will be cause for
    a pause, reflecting on the next steps that need to be taken. Should the data scientist
    proceed with the formal analysis process, perhaps creating a predictive model
    for automated learning? Or, should the scientist revisit a previous step, collecting
    additional (or different) data for processing?
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在整体数据科学流程的这一阶段或步骤中，数据科学家将使用各种方法深入挖掘数据。通常，会创建几个图形化的表示（再次强调，这些可能是手动完成的，也可能是通过编程脚本或工具生成的），以强调或验证数据科学家的观察、某个特定的观点或信念。这是数据科学流程中的一个重要步骤，因为数据科学家可能会意识到数据需要进一步处理，或者需要收集更多的数据，亦或是原始理论似乎得到了验证。这些发现将促使数据科学家停下来，反思接下来的步骤。数据科学家是否应该继续正式的分析过程，或许是创建一个自动化学习的预测模型？还是应该回到之前的步骤，收集更多（或不同的）数据进行处理？
- en: '**Data visualization** is a key technique permitting data scientists to perform
    analyses, identify key trends or events, and make more confident decisions much
    more quickly.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据可视化**是一项关键技术，它使数据科学家能够快速执行分析，识别关键趋势或事件，并做出更有信心的决策。'
- en: Analyzing the data and/or applying machine learning to the data
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分析数据和/或将机器学习应用于数据
- en: In this phase, quite a bit of analysis takes place as the data scientist (driven
    by a high level of scientific curiosity and experience) attempts to shape a story
    based upon an observation or the interpretation of their understanding of the
    data (up to this point). The data scientist continues to slice and dice the data,
    using analytics or BI packages—such as Tableau or Pentaho or an open source solution
    such as R or Python—to create a concrete data storyline. Once again, based on
    these analysis results, the data scientist may elect to again go back to a prior
    phase, pulling new data, processing and reprocessing, and creating additional
    visualizations. At some point, when appropriate progress has been made, the data
    scientist may decide that the data is at such point where data analysis can begin.
    Machine learning (defined further later in this chapter) has evolved over time
    from being more of an exercise in pattern recognition to now being defined as
    utilizing a selected statistical method to dig deeper, using the data and results
    of the analysis of this phase to learn and make a prediction, on the project data.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一阶段，数据科学家（受到强烈的科学好奇心和经验驱动）会进行大量分析，试图基于观察或对数据理解的解释，构建一个故事。数据科学家继续切分和分析数据，使用分析或商业智能工具（如
    Tableau、Pentaho，或者使用开源解决方案如 R 或 Python），创建具体的数据故事线。再次根据这些分析结果，数据科学家可能会选择返回到先前的阶段，提取新数据，进行处理和再处理，并创建额外的可视化效果。到了某个阶段，当进展适当时，数据科学家可能会决定开始数据分析。机器学习（将在本章后续详细定义）随着时间的推移，已从最初的模式识别演变为现在使用选定的统计方法深入挖掘，利用数据及本阶段分析的结果进行学习并做出预测。
- en: The ability of a data scientist to extract a quantitative result from data through
    machine learning and express it as something that everyone (not just other data
    scientists) can understand immediately is an invaluable skill, and we will talk
    more about this throughout this book.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家通过机器学习从数据中提取定量结果，并将其以每个人（不仅仅是其他数据科学家）能够立即理解的方式表达出来，这是一个宝贵的技能，我们将在本书中进一步探讨这一点。
- en: Deciding (or planning) based upon acquired insight
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于获得的洞察做决策（或规划）
- en: In this step, the data scientist hopes to obtain value from their efforts in
    the form of an insight. The insight is gained by performing the preceding described
    phases, aimed at gaining an understanding of a particular situation or phenomena.
    The idea is that this insight can then be used as input to make better decisions.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在此步骤中，数据科学家希望通过努力获得价值，并以洞察的形式呈现出来。通过执行之前描述的阶段，获得对特定情况或现象的理解，从而得到这个洞察。这个洞察随后可以作为输入，用于做出更好的决策。
- en: A fun example that illustrates a creative use of insights mined from data is
    the (as of this writing, experimental) Roztayger personality match process powered
    by IBM Watson. Using either your Facebook or Twitter feeds (or you can enter a
    short bio), Watson will, on-the-fly, perform an analysis of your personality.
    The results are interesting and pretty spot on, and these insights are then used
    to suggest designer labels that may best suit you and your personal style.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 一个有趣的例子，展示了从数据中挖掘洞察并创造性使用的过程，就是由 IBM Watson 支持的（截至本文撰写时，仍为实验性）Roztayger 人格匹配过程。使用你的
    Facebook 或 Twitter 动态（或者你也可以输入简短的个人简介），Watson 会即时对你的个性进行分析。结果既有趣又非常精准，这些洞察随后被用来推荐最适合你及你个人风格的设计师品牌。
- en: You can find this feature at [http://roztayger.com/match](http://roztayger.com/match).
    The Personality Insights service extracts personality characteristics based on
    how a person writes. You can use the service to match individuals to other individuals,
    opportunities, and products, or tailor their experience with personalized messaging
    and recommendations. Characteristics include the Big 5 Personality Traits, Values,
    and Needs. At least 1,200 words of input text are recommended when using this
    service.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[http://roztayger.com/match](http://roztayger.com/match)找到这个功能。个性洞察服务根据一个人的写作方式提取个性特征。你可以使用该服务将个体与其他个体、机会和产品进行匹配，或通过个性化信息和推荐来定制他们的体验。特征包括大五人格特质、价值观和需求。建议使用至少1,200个字的输入文本。
- en: 'Once the (real-time) data science analysis is complete, the aforementioned
    website not only provides its recommendations but also shares the data behind
    its insights, showing an easy-to-understand, well-organized tabular view of the
    results, and an eye-catching visualization as well, as shown in the following
    figure:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦（实时）数据科学分析完成，前述网站不仅提供建议，还分享其洞察背后的数据，以易于理解、条理清晰的表格视图展示结果，同时也提供引人注目的可视化效果，如下图所示：
- en: '![](img/91dbe2fb-1ece-4522-88c4-0dd8a8d7096b.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](img/91dbe2fb-1ece-4522-88c4-0dd8a8d7096b.png)'
- en: This illustrates another key aspect of this phase of the data science progression,
    that is, once the data scientist identifies an insight, he must clearly present
    and communicate those data insights/findings.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这展示了数据科学进展阶段的另一个关键方面，也就是，一旦数据科学家识别出某个洞察，他们必须清晰地展示和传达这些数据洞察/发现。
- en: Thinking like a data scientist
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 像数据科学家一样思考
- en: As we've already stressed, agreement on the concepts of what a data scientist
    is and does are still just emerging. The entire field of data science is at best
    roughly defined. Transitioning to data science is perhaps as much about finding
    an organization or group whose needs match your skills as it is about understanding
    what skills and concepts are involved in data science and then working towards
    developing those skills.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前强调的，数据科学家的定义和职责的共识仍在逐步形成。数据科学领域的整体定义至多是粗略的。转型为数据科学家的过程，也许更像是寻找一个与自己技能匹配的组织或团队，而不仅仅是理解数据科学所涉及的技能和概念，并朝着这些技能努力。
- en: Just as a data developer stays up to date and knowledgeable on the trends and
    tools in and around the manipulation of and access to data, so should the would-be
    data scientist.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 就像数据开发人员保持对数据操作和访问趋势及工具的了解一样，未来的数据科学家也应该如此。
- en: Bringing statistics into data science
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将统计学引入数据科学
- en: 'Depending on your sources and individual beliefs, you may say the following:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 根据你的来源和个人信念，你可能会说以下内容：
- en: '*Statistics is data science, and data science is statistics*.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '*统计学就是数据科学，数据科学就是统计学*。'
- en: To clarify this, note that there is a popular opinion that statistics might
    be thought of as a study or process that covers the collection, analysis, interpretation,
    presentation, and organization of data. As you can see, that definition is pretty
    similar to the data science process we described in the previous section of this
    chapter.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 为了澄清这一点，请注意有一种流行的观点认为，统计学可以被视为一个涵盖数据收集、分析、解释、展示和组织的研究或过程。正如你所看到的，这一定义与我们在本章上一节中描述的数据科学过程非常相似。
- en: Digging deeper into this topic, one will find that statistics always involves
    (or a collection of) techniques or approaches used to help analyze and present
    data (again, this understanding could also be used to describe data science).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 深入探讨这个话题，我们会发现统计学总是涉及（或包含）一些技术或方法，用于帮助分析和展示数据（同样，这种理解也可以用来描述数据科学）。
- en: It is commonly accepted that the terms data science and statistics have the
    same meaning, at least within some circles. Again, alignment of terms and concepts
    is still evolving among data scientists.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在一些圈子里，人们普遍认为数据科学和统计学是同义词。当然，数据科学家之间对术语和概念的统一仍在不断演进。
- en: Common terminology
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 常见术语
- en: 'Based upon personal experience, research, and various industry experts'' advice,
    someone delving into the art of data science should take every opportunity to
    understand and gain experience as well as proficiency with the following list
    of common data science terms:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 根据个人经验、研究以及各行各业专家的建议，深入学习数据科学的人应该抓住每一个机会，理解并积累以下常见数据科学术语的经验和熟练度：
- en: Statistical population
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 统计学总体
- en: Probability
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 概率
- en: False positives
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 假阳性
- en: Statistical inference
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 统计推断
- en: Regression
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回归
- en: Fitting
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 拟合
- en: Categorical data
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分类数据
- en: Classification
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分类
- en: Clustering
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 聚类
- en: Statistical comparison
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 统计比较
- en: Coding
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编码
- en: Distributions
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分布
- en: Data mining
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据挖掘
- en: Decision trees
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 决策树
- en: Machine learning
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习
- en: Munging and wrangling
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据清洗和整理
- en: Visualization
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可视化
- en: D3
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: D3
- en: Regularization
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正则化
- en: Assessment
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估
- en: Cross-validation
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 交叉验证
- en: Neural networks
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 神经网络
- en: Boosting
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提升
- en: Lift
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提升率
- en: Mode
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 众数
- en: Outlier
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 异常值
- en: Predictive modeling
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测建模
- en: Big data
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大数据
- en: Confidence interval
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 置信区间
- en: Writing
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 写作
- en: Statistical population
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 统计总体
- en: You can perhaps think of a statistical population as a recordset (or a set of
    records). This set or group of records will be of similar items or events that
    are of interest to the data scientist for some experiment.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 你或许可以将统计总体看作一个记录集（或一组记录）。这组记录将包含一些类似的项目或事件，数据科学家对此感兴趣，用于某些实验。
- en: For a data developer, a population of data may be a recordset of all sales transactions
    for a month, and the interest might be reporting to the senior management of an
    organization which products are the fastest sellers and at which time of the year.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 对于数据开发人员来说，数据总体可能是某个月份的所有销售交易记录，而关注点可能是向公司高层报告哪些产品是最快的畅销产品，以及在一年中的哪个时间段。
- en: For a data scientist, a population may be a recordset of all emergency room
    admissions during a month, and the area of interest might be to determine the
    statistical demographics for emergency room use.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 对于数据科学家来说，总体可能是某个月所有急诊室入院的记录，而关注点可能是确定急诊室使用的统计人口特征。
- en: Typically, the terms **statistical population** and **statistical model** are
    or can be used interchangeably. Once again, data scientists continue to evolve
    with their alignment on their use of common terms.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，**统计总体**和**统计模型**这两个术语可以互换使用。再次强调，数据科学家们在使用这些常用术语时不断发展和统一。
- en: Another key point concerning statistical populations is that the recordset may
    be a group of (actually) existing objects or a hypothetical group of objects.
    Using the preceding example, you might draw a comparison of actual objects as
    those actual sales transactions recorded for the month while the hypothetical
    objects as sales transactions are expected, forecast, or presumed (based upon
    observations or experienced assumptions or other logic) to occur during a month.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个关于统计总体的关键点是，记录集可能是一个（实际上）存在的对象组，或者是一个假设的对象组。以之前的例子为例，实际对象可以是该月记录的实际销售交易，而假设对象则是预计、预测或假定（基于观察或经验假设或其他逻辑）将在一个月内发生的销售交易。
- en: Finally, through the use of statistical inference (explained later in this chapter),
    the data scientist can select a portion or subset of the recordset (or population)
    with the intention that it will represent the total population for a particular
    area of interest. This subset is known as a **statistical sample**.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，通过使用统计推断（将在本章后面解释），数据科学家可以选择记录集（或总体）的一部分或子集，目的是使其代表某一特定领域的总总体。这个子集被称为**统计样本**。
- en: If a sample of a population is chosen accurately, characteristics of the entire
    population (that the sample is drawn from) can be estimated from the corresponding
    characteristics of the sample.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 如果准确地选择了一个总体样本，可以根据样本的相应特征估算整个总体（该样本所来自的总体）的特征。
- en: Probability
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概率
- en: Probability is concerned with the laws governing random events.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 概率关注的是支配随机事件的法则。
- en: -www.britannica.com
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: -www.britannica.com
- en: When thinking of probability, you think of possible upcoming events and the
    likelihood of them actually occurring. This compares to a statistical thought
    process that involves analyzing the frequency of past events in an attempt to
    explain or make sense of the observations. In addition, the data scientist will
    associate various individual events, studying the relationship of these events.
    How these different events relate to each other governs the methods and rules
    that will need to be followed when we're studying their probabilities.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在思考概率时，你会想到可能发生的事件以及它们实际上发生的可能性。这与统计思维过程相比较，后者涉及分析过去事件的频率，以试图解释或理解观察到的现象。此外，数据科学家还会关联各种个体事件，研究这些事件之间的关系。这些不同事件之间的关系决定了我们在研究它们的概率时需要遵循的方法和规则。
- en: A probability distribution is a table that is used to show the probabilities
    of various outcomes in a sample population or recordset.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 概率分布是一个表格，用于显示样本总体或记录集中的各种结果的概率。
- en: False positives
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 假阳性
- en: The idea of false positives is a very important statistical (data science) concept.
    A false positive is a mistake or an errored result. That is, it is a scenario
    where the results of a process or experiment indicate a fulfilled or true condition
    when, in fact, the condition is not true (not fulfilled). This situation is also
    referred to by some data scientists as a false alarm and is most easily understood
    by considering the idea of a recordset or statistical population (which we discussed
    earlier in this section) that is determined not only by the accuracy of the processing
    but by the characteristics of the sampled population. In other words, the data
    scientist has made errors during the statistical process, or the recordset is
    a population that does not have an appropriate sample (or characteristics) for
    what is being investigated.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 假阳性的概念是一个非常重要的统计学（数据科学）概念。假阳性是一个错误或失误的结果。也就是说，这是一个场景，其中过程或实验的结果表明条件已满足或为真，但实际上该条件并不成立（未满足）。这种情况也被一些数据科学家称为假警报，最容易理解的是考虑记录集或统计总体的概念（我们在本节前面讨论过），它不仅由处理的准确性决定，还由所抽取样本总体的特征决定。换句话说，数据科学家在统计过程中犯了错误，或者记录集是一个没有适当样本（或特征）的总体，无法满足正在研究的条件。
- en: Statistical inference
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 统计推断
- en: What developer at some point in his or her career, had to create a sample or
    test data? For example, I've often created a simple script to generate a random
    number (based upon the number of possible options or choices) and then used that
    number as the selected option (in my test recordset). This might work well for
    data development, but with statistics and data science, this is not sufficient.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 哪个开发者在职业生涯中某个时刻没有创建过样本或测试数据？例如，我常常会创建一个简单的脚本来生成一个随机数（基于可能的选项或选择的数量），然后将这个数字作为选中的选项（在我的测试记录集中）。这在数据开发中可能运作得很好，但在统计学和数据科学中，这是不够的。
- en: To create sample data (or a sample population), the data scientist will use
    a process called **statistical inference**, which is the process of deducing options
    of an underlying distribution through analysis of the data you have or are trying
    to generate for. The process is sometimes called **inferential statistical analysis**
    and includes testing various hypotheses and deriving estimates.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 为了创建样本数据（或样本总体），数据科学家将使用一个叫做**统计推断**的过程，这个过程通过分析你拥有或尝试生成的数据来推断潜在分布的选项。这个过程有时也称为**推断统计分析**，包括测试各种假设并得出估计值。
- en: When the data scientist determines that a recordset (or population) should be
    larger than it actually is, it is assumed that the recordset is a sample from
    a larger population, and the data scientist will then utilize statistical inference
    to make up the difference.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据科学家确定记录集（或总体）应比实际更大时，假设该记录集是来自更大总体的样本，数据科学家会利用统计推断来弥补差距。
- en: The data or recordset in use is referred to by the data scientist as the observed
    data. Inferential statistics can be contrasted with descriptive statistics, which
    is only concerned with the properties of the observed data and does not assume
    that the recordset came from a larger population.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 正在使用的数据或记录集被数据科学家称为观测数据。推断统计学可以与描述性统计学进行对比，后者仅关注观测数据的属性，并不假设记录集来自更大的总体。
- en: Regression
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回归
- en: Regression is a process or method (selected by the data scientist as the best
    fit technique for the experiment at hand) used for determining the relationships
    among variables. If you're a programmer, you have a certain understanding of what
    a variable is, but in statistics, we use the term differently. Variables are determined
    to be either dependent or independent.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 回归是一个过程或方法（由数据科学家根据当前实验的需要选定为最佳拟合技术），用于确定变量之间的关系。如果你是程序员，你对变量有一定的理解，但在统计学中，我们对这个术语的使用有所不同。变量被判定为依赖变量或独立变量。
- en: An independent variable (also known as a **predictor**) is the one that is manipulated
    by the data scientist in an effort to determine its relationship with a dependent
    variable. A dependent variable is a variable that the data scientist is measuring.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 独立变量（也称为**预测变量**）是数据科学家操控的变量，目的是确定它与依赖变量的关系。依赖变量是数据科学家正在测量的变量。
- en: It is not uncommon to have more than one independent variable in a data science
    progression or experiment.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据科学的进程或实验中，出现多个自变量并不罕见。
- en: More precisely, regression is the process that helps the data scientist comprehend
    how the typical value of the dependent variable (or criterion variable) changes
    when any one or more of the independent variables is varied while the other independent
    variables are held fixed.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 更准确地说，回归是一个帮助数据科学家理解当一个或多个自变量变化时，而其他自变量保持固定时，因变量（或标准变量）的典型值如何变化的过程。
- en: Fitting
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 拟合
- en: Fitting is the process of measuring how well a statistical model or process
    describes a data scientist's observations pertaining to a recordset or experiment.
    These measures will attempt to point out the discrepancy between observed values
    and probable values. The probable values of a model or process are known as a
    distribution or a probability distribution.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 拟合是衡量统计模型或过程如何描述数据科学家关于记录集或实验的观察结果的过程。这些度量将试图指出观察值和可能值之间的差异。模型或过程的可能值称为分布或概率分布。
- en: Therefore, a probability distribution fitting (or distribution fitting) is when
    the data scientist fits a probability distribution to a series of data concerning
    the repeated measurement of a variable phenomenon.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，概率分布拟合（或分布拟合）是指数据科学家将概率分布拟合到关于变量现象重复测量的一系列数据上。
- en: The object of a data scientist performing a distribution fitting is to predict
    the probability or to forecast the frequency of, the occurrence of the phenomenon
    at a certain interval.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家进行分布拟合的目标是预测某一现象在特定时间间隔内发生的概率或预测其发生频率。
- en: One of the most common uses of fitting is to test whether two samples are drawn
    from identical distributions.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 拟合的一个常见用途是测试两个样本是否来自相同的分布。
- en: There are numerous probability distributions a data scientist can select from.
    Some will fit better to the observed frequency of the data than others will. The
    distribution giving a close fit is supposed to lead to good predictions; therefore,
    the data scientist needs to select a distribution that suits the data well.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家可以选择的概率分布有很多种。一些分布比其他分布更适合观察到的数据频率。拟合得较好的分布应该能做出好的预测；因此，数据科学家需要选择适合数据的分布。
- en: Categorical data
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分类数据
- en: Earlier, we explained how variables in your data can be either independent or
    dependent. Another type of variable definition is a categorical variable. This
    type of variable is one that can take on one of a limited, and typically fixed,
    number of possible values, thus assigning each individual to a particular category.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 之前，我们解释了数据中的变量可以是自变量或因变量。另一种变量定义是分类变量。这种变量是指可以取有限且通常固定的可能值之一，从而将每个个体分配到特定类别。
- en: Often, the collected data's meaning is unclear. Categorical data is a method
    that a data scientist can use to put meaning to the data.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 经常情况下，收集到的数据含义不明确。分类数据是数据科学家可以用来为数据赋予含义的一种方法。
- en: 'For example, if a numeric variable is collected (let''s say the values found
    are 4, 10, and 12), the meaning of the variable becomes clear if the values are
    categorized. Let''s suppose that based upon an analysis of how the data was collected,
    we can group (or categorize) the data by indicating that this data describes university
    students, and there is the following number of players:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果收集了一个数值变量（假设发现的值为4、10和12），如果这些值被分类，变量的含义就会变得清晰。假设根据对数据收集方式的分析，我们可以通过指明这些数据描述的是大学生，并且以下是运动员的数量：
- en: 4 tennis players
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 4名网球运动员
- en: 10 soccer players
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 10名足球运动员
- en: 12 football players
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 12名足球运动员
- en: Now, because we grouped the data into categories, the meaning becomes clear.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，因为我们将数据分组为类别，含义变得清晰。
- en: Some other examples of categorized data might be individual pet preferences
    (grouped by the type of pet), or vehicle ownership (grouped by the style of a
    car owned), and so on.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 其他一些分类数据的例子可能是个人宠物偏好（按宠物类型分组），或汽车拥有情况（按所拥有的汽车类型分组）等等。
- en: So, categorical data, as the name suggests, is data grouped into some sort of
    category or multiple categories. Some data scientists refer to categories as sub-populations
    of data.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，分类数据，顾名思义，是将数据分组到某种类别或多个类别中。一些数据科学家将类别称为数据的子人群。
- en: Categorical data can also be data that is collected as a yes or no answer. For
    example, hospital admittance data may indicate that patients either smoke or do
    not smoke.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 分类数据也可以是收集的是“是”或“否”的答案。例如，医院接纳数据可能表明患者是否吸烟。
- en: Classification
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分类
- en: Statistical classification of data is the process of identifying which category
    (discussed in the previous section) a data point, observation, or variable should
    be grouped into. The data science process that carries out a classification process
    is known as a **classifier**.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 数据的统计分类是识别数据点、观测值或变量应归入哪个类别（在前一部分讨论过）的过程。执行分类过程的数据科学过程被称为**分类器**。
- en: Determining whether a book is fiction or non-fiction is a simple example classification.
    An analysis of data about restaurants might lead to the classification of them
    among several genres.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 判断一本书是小说还是非小说是一个简单的分类例子。对餐馆数据的分析可能会将它们分类为多个类型。
- en: Clustering
  id: totrans-127
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 聚类
- en: Clustering is the process of dividing up the data occurrences into groups or
    homogeneous subsets of the dataset, not a predetermined set of groups as in classification
    (described in the preceding section) but groups identified by the execution of
    the data science process based upon similarities that it found among the occurrences.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类是将数据出现的实例划分为组或同质子集的过程，不同于分类（如前一部分所述）中预设的组，而是通过执行数据科学过程，基于它在实例中发现的相似性来识别的组。
- en: Objects in the same group (a group is also referred to as a cluster) are found
    to be more analogous (in some sense or another) to each other than to those objects
    found in other groups (or found in other clusters). The process of clustering
    is found to be very common in exploratory data mining and is also a common technique
    for statistical data analysis.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 位于同一组中的对象（该组也称为簇）被发现比与其他组中的对象（或其他簇中的对象）相比更为相似（在某种程度上）。聚类过程在探索性数据挖掘中非常常见，也是统计数据分析中的常用技术。
- en: Statistical comparison
  id: totrans-130
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 统计比较
- en: Simply put, when you hear the term statistical comparison, one is usually referring
    to the act of a data scientist performing a process of analysis to view the similarities
    or variances of two or more groups or populations (or recordsets).
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，当你听到统计比较这个术语时，通常指的是数据科学家执行分析过程，以查看两个或多个组或种群（或记录集）之间的相似性或差异。
- en: As a data developer, one might be familiar with various utilities such as FC
    Compare, UltraCompare, or WinDiff, which aim to provide the developer with a line-by-line
    comparison of the contents of two or more (even binary) files.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 作为数据开发人员，可能熟悉各种工具，如FC Compare、UltraCompare或WinDiff，它们旨在为开发人员提供两个或更多文件（甚至二进制文件）内容的逐行比较。
- en: In statistics (data science), this process of comparing is a statistical technique
    to compare populations or recordsets. In this method, a data scientist will conduct
    what is called an **Analysis of Variance** (**ANOVA**), compare categorical variables
    (within the recordsets), and so on.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在统计学（数据科学）中，这一比较过程是一种统计技术，用于比较种群或记录集。在这种方法中，数据科学家将执行所谓的**方差分析**（**ANOVA**），比较分类变量（在记录集内）等。
- en: ANOVA is an assortment of statistical methods that are used to analyze the differences
    among group means and their associated procedures (such as variations among and
    between groups, populations, or recordsets). This method eventually evolved into
    the Six Sigma dataset comparisons.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: ANOVA是一种统计方法，用于分析组均值之间的差异及其相关过程（例如组间、组内或记录集之间的变异）。该方法最终演变为六西格玛数据集比较。
- en: Coding
  id: totrans-135
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 编码
- en: Coding or statistical coding is again a process that a data scientist will use
    to prepare data for analysis. In this process, both quantitative data values (such
    as income or years of education) and qualitative data (such as race or gender)
    are categorized or coded in a consistent way.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 编码或统计编码是数据科学家在准备数据进行分析时使用的过程。在这个过程中，定量数据值（如收入或教育年限）和定性数据（如种族或性别）都以一致的方式进行分类或编码。
- en: 'Coding is performed by a data scientist for various reasons such as follows:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家进行编码的原因有多种，具体如下：
- en: More effective for running statistical models
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更有效地运行统计模型
- en: Computers understand the variables
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算机理解变量
- en: Accountability--so the data scientist can run models blind, or without knowing
    what variables stand for, to reduce programming/author bias
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 责任制——使数据科学家能够盲目地运行模型，或者在不知晓变量代表什么的情况下运行，以减少编程/作者偏见。
- en: You can imagine the process of coding as the means to transform data into a
    form required for a system or application.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以将编码过程视为将数据转化为系统或应用所需形式的手段。
- en: Distributions
  id: totrans-142
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分布
- en: The distribution of a statistical recordset (or of a population) is a visualization
    showing all the possible values (or sometimes referred to as intervals) of the
    data and how often they occur. When a distribution of categorical data (which
    we defined earlier in this chapter) is created by a data scientist, it attempts
    to show the number or percentage of individuals in each group or category.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 统计记录集（或人口）的分布是一个可视化，展示数据的所有可能值（或有时称为区间）及其发生频率。当数据科学家创建分类数据的分布（我们在本章前面定义过的分类数据）时，试图展示每个组或类别中的个体数量或百分比。
- en: Linking an earlier defined term with this one, a probability distribution, stated
    in simple terms, can be thought of as a visualization showing the probability
    of occurrence of different possible outcomes in an experiment.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 将之前定义的术语与此术语“概率分布”联系起来，简单来说，概率分布可以被看作是一个可视化图，展示在实验中不同可能结果发生的概率。
- en: Data mining
  id: totrans-145
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据挖掘
- en: In [Chapter 1](7f3dc6b3-d483-4ffc-b330-22b36da9bdc7.xhtml), *Transitioning from
    Data Developer to Data Scientist*, we said, with data mining, one is usually more
    absorbed in the data relationships (or the potential relationships between points
    of data, sometimes referred to as variables) and cognitive analysis.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第1章](7f3dc6b3-d483-4ffc-b330-22b36da9bdc7.xhtml)《从数据开发者到数据科学家》中，我们提到，数据挖掘通常更专注于数据关系（或数据点之间的潜在关系，有时称为变量）和认知分析。
- en: To further define this term, we can mention that data mining is sometimes more
    simply referred to as knowledge discovery or even just discovery, based upon processing
    through or analyzing data from new or different viewpoints and summarizing it
    into valuable insights that can be used to increase revenue, cuts costs, or both.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步定义这一术语，我们可以提到，数据挖掘有时更简单地被称为知识发现，甚至仅称为发现，基于从新的或不同的视角处理或分析数据，并将其总结为可用于增加收入、削减成本或两者兼得的有价值的见解。
- en: Using software dedicated to data mining is just one of several analytical approaches
    to data mining. Although there are tools dedicated to this purpose (such as IBM
    Cognos BI and Planning Analytics, Tableau, SAS, and so on.), data mining is all
    about the analysis process finding correlations or patterns among dozens of fields
    in the data and that can be effectively accomplished using tools such as MS Excel
    or any number of open source technologies.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 使用专门的用于数据挖掘的软件只是数据挖掘几种分析方法之一。尽管有专门的工具（如IBM Cognos BI和Planning Analytics、Tableau、SAS等），数据挖掘的核心是通过分析过程发现数据中的字段之间的相关性或模式，这可以通过MS
    Excel或其他许多开源技术有效完成。
- en: A common technique to data mining is through the creation of custom scripts
    using tools such as R or Python. In this way, the data scientist has the ability
    to customize the logic and processing to their exact project needs.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 数据挖掘的一种常见技术是通过使用如R或Python之类的工具创建自定义脚本。通过这种方式，数据科学家能够根据项目的具体需求定制逻辑和处理过程。
- en: Decision trees
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 决策树
- en: A statistical decision tree uses a diagram that looks like a tree. This structure
    attempts to represent optional decision paths and a predicted outcome for each
    path selected. A data scientist will use a decision tree to support, track, and
    model decision making and their possible consequences, including chance event
    outcomes, resource costs, and utility. It is a common way to display the logic
    of a data science process.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 统计决策树使用一种看起来像树的图示结构。这种结构试图表示可选的决策路径以及每个选定路径的预测结果。数据科学家将使用决策树来支持、跟踪和建模决策制定及其可能的后果，包括偶然事件结果、资源成本和效用。这是一种常见的数据科学过程逻辑展示方式。
- en: Machine learning
  id: totrans-152
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习
- en: Machine learning is one of the most intriguing and exciting areas of data science.
    It conjures all forms of images around artificial intelligence which includes
    Neural Networks, **Support Vector Machines** (**SVMs**), and so on.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是数据科学中最具吸引力和令人兴奋的领域之一。它唤起了与人工智能相关的各种形象，包括神经网络、**支持向量机**（**SVM**）等。
- en: Fundamentally, we can describe the term machine learning as a method of training
    a computer to make or improve predictions or behaviors based on data or, specifically,
    relationships within that data. Continuing, machine learning is a process by which
    predictions are made based upon recognized patterns identified within data, and
    additionally, it is the ability to continuously learn from the data's patterns,
    therefore continuingly making better predictions.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 从根本上说，我们可以将机器学习这一术语描述为一种训练计算机的方法，通过数据或更具体地说，数据中的关系来做出或改善预测或行为。继续来说，机器学习是一个基于在数据中识别到的模式进行预测的过程，并且它具有从数据模式中持续学习的能力，因此能够不断做出更好的预测。
- en: It is not uncommon for someone to mistake the process of machine learning for
    data mining, but data mining focuses more on exploratory data analysis and is
    known as **unsupervised learning**.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 有人将机器学习的过程误认为数据挖掘并不罕见，但数据挖掘更多地侧重于探索性数据分析，并被称为**无监督学习**。
- en: Machine learning can be used to learn and establish baseline behavioral profiles
    for various entities and then to find meaningful anomalies.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习可以用来学习并建立各种实体的基线行为特征，然后寻找有意义的异常情况。
- en: 'Here is the exciting part: the process of machine learning (using data relationships
    to make predictions) is known as **predictive analytics**.'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是激动人心的部分：机器学习的过程（使用数据关系做出预测）被称为**预测分析**。
- en: Predictive analytics allow the data scientists to produce reliable, repeatable
    decisions and results and uncover hidden insights through learning from historical
    relationships and trends in the data.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 预测分析使数据科学家能够通过从历史关系和数据中的趋势中学习，做出可靠的、可重复的决策和结果，并揭示隐藏的见解。
- en: Munging and wrangling
  id: totrans-159
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据清洗和整理
- en: The terms **munging** and **wrangling** are buzzwords or jargon meant to describe
    one's efforts to affect the format of data, recordset, or file in some way in
    an effort to prepare the data for continued or otherwise processing and/or evaluations.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据清洗**和**数据整理**这两个术语是时髦词或行话，旨在描述某人在某种程度上对数据、记录集或文件格式进行调整的努力，以便为后续的处理和/或评估做准备。'
- en: With data development, you are most likely familiar with the idea of **Extract**,
    **Transform**, and** Load** (**ETL**). In somewhat the same way, a data developer
    may mung or wrangle data during the transformation steps within an ETL process.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据开发中，您很可能已经熟悉了**提取**、**转换**和**加载**（**ETL**）的概念。在某种程度上，数据开发人员可能会在ETL过程中的转换步骤中对数据进行清洗或整理。
- en: Common munging and wrangling may include removing punctuation or HTML tags,
    data parsing, filtering, all sorts of transforming, mapping, and tying together
    systems and interfaces that were not specifically designed to interoperate. Munging
    can also describe the processing or filtering of raw data into another form, allowing
    for more convenient consumption of the data elsewhere.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 常见的数据清洗和整理可能包括去除标点符号或HTML标签、数据解析、过滤、各种转换、映射，以及将不专门设计为互操作的系统和接口结合起来。数据清洗还可以描述将原始数据处理或过滤成另一种形式，以便在其他地方更方便地使用。
- en: Munging and wrangling might be performed multiple times within a data science
    process and/or at different steps in the evolving process. Sometimes, data scientists
    use munging to include various data visualization, data aggregation, training
    a statistical model, as well as much other potential work. To this point, munging
    and wrangling may follow a flow beginning with extracting the data in a raw form,
    performing the munging using various logic, and lastly, placing the resulting
    content into a structure for use.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 数据清洗和整理可能在数据科学过程中多次执行，或者在不断发展的过程中不同的步骤中进行。有时，数据科学家使用数据清洗来包括各种数据可视化、数据聚合、训练统计模型以及其他许多潜在的工作。至此，数据清洗和整理可能遵循一个流程，从提取原始数据开始，使用各种逻辑进行数据清洗，最后将结果内容放入结构中以供使用。
- en: Although there are many valid options for munging and wrangling data, preprocessing
    and manipulation, a tool that is popular with many data scientists today is a
    product named **Trifecta**, which claims that it is the number one (data) wrangling
    solution in many industries.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然有许多有效的选项可以进行数据清洗和整理、预处理和操作，但目前许多数据科学家喜爱的工具是名为**Trifecta**的产品，它声称是许多行业中排名第一的数据整理解决方案。
- en: Trifecta can be downloaded for your personal evaluation from [https://www.trifacta.com/](https://www.trifacta.com/).
    Check it out!
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trifecta**可以从[https://www.trifacta.com/](https://www.trifacta.com/)下载进行个人评估。去看看吧！'
- en: Visualization
  id: totrans-166
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可视化
- en: The main point (although there are other goals and objectives) when leveraging
    a data visualization technique is to make something complex appear simple. You
    can think of visualization as any technique for creating a graphic (or similar)
    to communicate a message.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 使用数据可视化技术的主要目的是让复杂的内容看起来简单（尽管还有其他目标）。你可以把可视化看作是任何一种创建图形（或类似的方式）以传达信息的技术。
- en: 'Other motives for using data visualization include the following:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 使用数据可视化的其他动机包括以下几点：
- en: To explain the data or put the data in context (which is to highlight demographical
    statistics)
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释数据或将数据置于上下文中（即突出显示人口统计统计信息）
- en: To solve a specific problem (for example, identifying problem areas within a
    particular business model)
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解决特定问题（例如，识别特定商业模型中的问题领域）
- en: To explore the data to reach a better understanding or add clarity (such as
    what periods of time do this data span?)
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索数据以更好地理解或增加清晰度（例如，这些数据跨越了哪些时间段？）
- en: To highlight or illustrate otherwise invisible data (such as isolating outliers
    residing in the data)
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 突出或说明那些无法直接看见的数据（例如，隔离数据中的异常值）
- en: To predict, such as potential sales volumes (perhaps based upon seasonality
    sales statistics)
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 进行预测，例如潜在的销售量（可能基于季节性销售统计数据）
- en: And others
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以及其他
- en: Statistical visualization is used in almost every step in the data science process,
    within the obvious steps such as exploring and visualizing, analyzing and learning,
    but can also be leveraged during collecting, processing, and the end game of using
    the identified insights.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 统计可视化几乎应用于数据科学过程中的每一个步骤，包括显而易见的步骤如探索和可视化、分析和学习，但也可以在收集、处理以及使用识别出的洞察力的最终阶段发挥作用。
- en: D3
  id: totrans-176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: D3
- en: D3 or `D3.js`, is essentially an open source JavaScript library designed with
    the intention of visualizing data using today's web standards. D3 helps put life
    into your data, utilizing **Scalable Vector Graphics** (**SVG**), Canvas, and
    standard HTML.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: D3或`D3.js`本质上是一个开源的JavaScript库，旨在使用现代网络标准可视化数据。D3通过使用**可缩放矢量图形**（**SVG**）、Canvas和标准HTML来帮助赋予数据生命。
- en: D3 combines powerful visualization and interaction techniques with a data-driven
    approach to DOM manipulation, providing data scientists with the full capabilities
    of modern browsers and the freedom to design the right visual interface that best
    depicts the objective or assumption.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: D3结合了强大的可视化和交互技术，并采用基于数据的DOM操作方法，为数据科学家提供了现代浏览器的全部功能，并且有自由设计出最佳视觉界面的能力，以最准确地展现目标或假设。
- en: In contrast to many other libraries, `D3.js` allows inordinate control over
    the visualization of data. D3 is embedded within an HTML webpage and uses prebuilt
    JavaScript functions to select elements, create SVG objects, style them, or add
    transitions, dynamic effects, and so on.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 与许多其他库不同，`D3.js`允许对数据可视化进行极高的控制。D3嵌入在HTML网页中，并使用预构建的JavaScript函数选择元素、创建SVG对象、设置样式、或添加过渡、动态效果等。
- en: Regularization
  id: totrans-180
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 正则化
- en: Regularization is one possible approach that a data scientist may use for improving
    the results generated from a statistical model or data science process, such as
    when addressing a case of overfitting in statistics and data science.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 正则化是数据科学家用来改善统计模型或数据科学过程生成的结果的一种可能方法，尤其是在处理统计学和数据科学中的过拟合问题时。
- en: We defined fitting earlier in this chapter (fitting describes how well a statistical
    model or process describes a data scientist's observations). Overfitting is a
    scenario where a statistical model or process seems to fit too well or appears
    to be too close to the actual data.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本章之前定义了拟合（拟合描述了统计模型或过程如何很好地描述数据科学家对观察结果的解释）。过拟合是一种情况，在这种情况下，统计模型或过程似乎拟合得过于完美，或者看起来与实际数据过于接近。
- en: Overfitting usually occurs with an overly simple model. This means that you
    may have only two variables and are drawing conclusions based on the two. For
    example, using our previously mentioned example of *daffodil sales*, one might
    generate a model with temperature as an independent variable and sales as a dependent
    one. You may see the model fail since it is not as simple as concluding that warmer
    temperatures will always generate more sales.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 过拟合通常发生在一个过于简单的模型中。这意味着你可能只有两个变量，并且根据这两个变量得出结论。例如，使用我们之前提到的*水仙花销售*的例子，可能会生成一个以温度为自变量，以销售为因变量的模型。你可能会看到该模型失败，因为简单地得出温暖的天气总是带来更多的销售并不成立。
- en: In this example, there is a tendency to add more data to the process or model
    in hopes of achieving a better result. The idea sounds reasonable. For example,
    you have information such as average rainfall, pollen count, fertilizer sales,
    and so on; could these data points be added as explanatory variables?
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，通常会通过向过程或模型中添加更多数据来希望获得更好的结果。这个想法听起来是合理的。例如，你有一些信息，如平均降水量、花粉计数、化肥销售量等；这些数据点可以作为解释变量添加进来吗？
- en: An explanatory variable is a type of independent variable with a subtle difference.
    When a variable is independent, it is not affected at all by any other variables.
    When a variable isn't independent for certain, it's an explanatory variable.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 解释变量是一种独立变量，但有着微妙的区别。当一个变量是独立的时，它完全不受任何其他变量的影响。当一个变量不完全独立时，它就是一个解释变量。
- en: Continuing to add more and more data to your model will have an effect but will
    probably cause overfitting, resulting in poor predictions since it will closely
    resemble the data, which is mostly just background noise.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 继续向模型中添加更多数据会产生一定效果，但可能会导致过拟合，导致预测结果不准确，因为它会与数据高度相似，而这些数据大多只是背景噪声。
- en: To overcome this situation, a data scientist can use regularization, introducing
    a tuning parameter (additional factors such as a data points mean value or a minimum
    or maximum limitation, which gives you the ability to change the complexity or
    smoothness of your model) into the data science process to solve an ill-posed
    problem or to prevent overfitting.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 为了克服这种情况，数据科学家可以使用正则化，引入一个调节参数（附加因素，如数据点的均值或最小/最大限制，使你能够改变模型的复杂度或平滑度），以解决不适定问题或防止过拟合。
- en: Assessment
  id: totrans-188
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估
- en: When a data scientist evaluates a model or data science process for performance,
    this is referred to as assessment. Performance can be defined in several ways,
    including the model's growth of learning or the model's ability to improve (with)
    learning (to obtain a better score) with additional experience (for example, more
    rounds of training with additional samples of data) or accuracy of its results.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据科学家评估一个模型或数据科学过程的性能时，这被称为评估。性能可以通过多种方式定义，包括模型学习的增长，或模型通过额外经验（例如更多轮训练以及更多数据样本）来改进学习的能力（以获得更好的分数），或结果的准确性。
- en: One popular method of assessing a model or processes performance is called **bootstrap
    sampling**. This method examines performance on certain subsets of data, repeatedly
    generating results that can be used to calculate an estimate of accuracy (performance).
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 评估模型或过程性能的一个流行方法被称为**自助法抽样**。这种方法通过反复生成结果，来检查在特定数据子集上的表现，这些结果可以用来计算准确度（性能）的估算值。
- en: The bootstrap sampling method takes a random sample of data, splits it into
    three files--a training file, a testing file, and a validation file. The model
    or process logic is developed based on the data in the training file and then
    evaluated (or tested) using the testing file. This tune and then test process
    is repeated until the data scientist is comfortable with the results of the tests.
    At that point, the model or process is again tested, this time using the validation
    file, and the results should provide a true indication of how it will perform.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 自助法抽样方法（bootstrap sampling）从数据中随机抽取样本，将其分成三个文件——训练文件、测试文件和验证文件。模型或过程逻辑是基于训练文件中的数据开发的，然后使用测试文件进行评估（或测试）。这个“调优然后测试”的过程会重复进行，直到数据科学家对测试结果感到满意。到那时，模型或过程会再次进行测试，这次使用的是验证文件，结果应该能真实反映其表现如何。
- en: You can imagine using the bootstrap `sampling` method to develop program logic
    by analyzing test data to determine logic flows and then running (or testing)
    your logic against the test data file. Once you are satisfied that your logic
    handles all of the conditions and exceptions found in your testing data, you can
    run a final test on a new, never-before-seen data file for a final validation
    test.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以想象使用自助法`抽样`方法通过分析测试数据来开发程序逻辑，确定逻辑流程，然后将你的逻辑与测试数据文件进行对比测试。一旦你确信你的逻辑处理了测试数据中的所有条件和异常，你可以对一个新的、未曾见过的数据文件进行最终验证测试。
- en: Cross-validation
  id: totrans-193
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 交叉验证
- en: Cross-validation is a method for assessing a data science process performance.
    Mainly used with predictive modeling to estimate how accurately a model might
    perform in practice, one might see cross-validation used to check how a model
    will potentially generalize, in other words, how the model can apply what it infers
    from samples to an entire population (or recordset).
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉验证是一种评估数据科学过程性能的方法。主要用于预测建模，以估计模型在实际中的表现准确性，交叉验证通常用于检查模型如何潜在地进行泛化，换句话说，就是模型如何将从样本中推断出的信息应用到整个群体（或记录集）上。
- en: With cross-validation, you identify a (known) dataset as your validation dataset
    on which training is run along with a dataset of unknown data (or first seen data)
    against which the model will be tested (this is known as your **testing dataset**).
    The objective is to ensure that problems such as overfitting (allowing non-inclusive
    information to influence results) are controlled and also provide an insight into
    how the model will generalize a real problem or on a real data file.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在交叉验证中，你需要确定一个（已知的）数据集作为验证数据集，在这个数据集上进行训练，并使用一个未知数据集（或首次出现的数据）对模型进行测试（这就是你的**测试数据集**）。其目的是确保诸如过拟合（允许不完全的信息影响结果）等问题得到控制，同时提供有关模型如何在实际问题或实际数据文件上进行泛化的洞察。
- en: The cross-validation process will consist of separating data into samples of
    similar subsets, performing the analysis on one subset (called the **training
    set**) and validating the analysis on the other subset (called the **validation
    set** or **testing set**). To reduce variability, multiple iterations (also called
    **folds** or **rounds**) of cross-validation are performed using different partitions,
    and the validation results are averaged over the rounds. Typically, a data scientist
    will use a models stability to determine the actual number of rounds of cross-validation
    that should be performed.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉验证过程将包括将数据划分为相似子集的样本，对一个子集（称为**训练集**）进行分析，并在另一个子集（称为**验证集**或**测试集**）上验证分析结果。为了减少变异性，交叉验证会进行多次迭代（也称为**折叠**或**轮次**），使用不同的划分方式，验证结果会在多个轮次中求平均。通常，数据科学家会利用模型的稳定性来确定应执行多少轮交叉验证。
- en: Neural networks
  id: totrans-197
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 神经网络
- en: Neural networks are also called **artificial neural networks** (**ANNs**), and
    the objective is to solve problems in the same way that the human brain would.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络也被称为**人工神经网络**（**ANNs**），其目标是以与人类大脑相同的方式解决问题。
- en: 'Google will provide the following explanation of ANN as stated in *Neural Network
    Primer: Part I, by Maureen Caudill, AI Expert, Feb. 1989*:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: Google将在《神经网络入门：第一部分，Maureen Caudill，AI专家，1989年2月》中提供以下关于ANN的解释：
- en: A computing system made up of several simple, highly interconnected processing
    elements, which process information by their dynamic state response to external
    inputs.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 一个计算系统由多个简单且高度互联的处理元素组成，这些处理元素通过对外部输入的动态状态响应来处理信息。
- en: To oversimplify the idea of neural networks, recall the concept of software
    encapsulation, and consider a computer program with an input layer, a processing
    layer, and an output layer. With this thought in mind, understand that neural
    networks are also organized in a network of these layers, usually with more than
    a single processing layer.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化神经网络的概念，可以回想一下软件封装的概念，考虑一个包含输入层、处理层和输出层的计算机程序。理解这一点后，你会明白，神经网络也组织成这些层的网络，通常不止一个处理层。
- en: Patterns are presented to the network by way of the input layer, which then
    communicates to one (or more) of the processing layers (where the actual processing
    is done). The processing layers then link to an output layer where the result
    is presented.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 模式通过输入层呈现给网络，随后传递给一个或多个处理层（实际处理发生的地方）。处理层再与输出层相连接，结果在此呈现。
- en: Most neural networks will also contain some form of learning rule that modifies
    the weights of the connections (in other words, the network learns which processing
    nodes perform better and gives them a heavier weight) per the input patterns that
    it is presented with. In this way (in a sense), neural networks learn by example
    as a child learns to recognize a cat from being exposed to examples of cats.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数神经网络还会包含某种形式的学习规则，通过该规则根据所呈现的输入模式修改连接的权重（换句话说，网络会学习哪些处理节点表现更好，并给予其更大的权重）。通过这种方式（从某种意义上说），神经网络像孩子通过接触猫的例子来学习识别猫一样，通过示例进行学习。
- en: Boosting
  id: totrans-204
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提升法
- en: In a manner of speaking, boosting is a process generally accepted in data science
    for improving the accuracy of a weak learning data science process.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 可以说，提升是数据科学中普遍接受的一种过程，用于提高弱学习数据科学过程的准确性。
- en: Data science processes defined as weak learners are those that produce results
    that are only slightly better than if you would randomly guess the outcome. Weak
    learners are basically thresholds or a 1-level decision tree.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 被定义为弱学习者的数据科学过程是指那些产生的结果仅比随机猜测的结果略好。弱学习者基本上是阈值或单层决策树。
- en: Specifically, boosting is aimed at reducing bias and variance in supervised
    learning.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，提升的目标是在监督学习中减少偏差和方差。
- en: What do we mean by bias and variance? Before going on further about boosting,
    let's take note of what we mean by bias and variance.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 我们所说的偏差和方差是什么意思？在进一步讨论提升之前，让我们先了解一下偏差和方差的含义。
- en: Data scientists describe bias as a level of favoritism that is present in the
    data collection process, resulting in uneven, disingenuous results and can occur
    in a variety of different ways. A `sampling` method is called **biased** if it
    systematically favors some outcomes over others.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家将偏差描述为在数据收集过程中存在的一种偏爱程度，导致结果不均衡、不真实，并且可能以多种不同的方式发生。如果一个`采样`方法系统地偏向某些结果而非其他结果，则称该方法为**有偏的**。
- en: A variance may be defined (by a data scientist) simply as the distance from
    a variable mean (or how far from the average a result is).
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 方差可以简单地定义为一个变量均值的距离（或者结果距离平均值的远近）。
- en: The boosting method can be described as a data scientist repeatedly running
    through a data science process (that has been identified as a weak learning process),
    with each iteration running on different and random examples of data sampled from
    the original population recordset. All the results (or classifiers or residue)
    produced by each run are then combined into a single merged result (that is a
    gradient).
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 提升方法可以描述为数据科学家反复执行数据科学过程（该过程已被确定为弱学习过程），每次迭代都使用从原始总体记录集随机抽取的不同数据样本。每次运行产生的所有结果（或分类器或残差）随后会被合并为一个单一的合并结果（即梯度）。
- en: This concept of using a random subset of the original recordset for each iteration
    originates from bootstrap sampling in bagging and has a similar variance-reducing
    effect on the combined model.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 每次迭代使用原始记录集的随机子集这一概念，源自于袋装法中的自助采样，并对合并模型具有类似的方差降低效果。
- en: In addition, some data scientists consider boosting a means to convert weak
    learners into strong ones; in fact, to some, the process of boosting simply means
    turning a weak learner into a strong learner.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，一些数据科学家认为提升是将弱学习者转化为强学习者的一种方式；事实上，对于某些人来说，提升过程仅仅意味着将弱学习者转化为强学习者。
- en: Lift
  id: totrans-214
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提升
- en: In data science, the term lift compares the frequency of an observed pattern
    within a recordset or population with how frequently you might expect to see that
    same pattern occur within the data by chance or randomly.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据科学中，"提升"（lift）一词用于比较记录集或总体中观察到的模式的频率与通过随机或偶然方式在数据中出现该模式的预期频率。
- en: If the lift is very low, then typically, a data scientist will expect that there
    is a very good probability that the pattern identified is occurring just by chance.
    The larger the lift, the more likely it is that the pattern is real.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 如果提升值非常低，那么通常，数据科学家会认为识别出的模式很可能只是偶然发生的。提升值越大，模式越有可能是真实的。
- en: Mode
  id: totrans-217
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 众数
- en: In statistics and data science, when a data scientist uses the term mode, he
    or she refers to the value that occurs most often within a sample of data. Mode
    is not calculated but is determined manually or through processing of the data.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 在统计学和数据科学中，当数据科学家使用“众数”一词时，他或她指的是在数据样本中出现频率最高的值。众数不是通过计算得到的，而是通过手动确定或通过处理数据来确定的。
- en: Outlier
  id: totrans-219
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 异常值
- en: 'Outliers can be defined as follows:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 异常值可以定义如下：
- en: A data point that is way out of keeping with the others
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与其他数据点差异极大的数据点
- en: That piece of data that doesn't fit
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 那些不符合其他数据点的异常数据
- en: Either a very high value or a very low value
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个非常高的值或非常低的值
- en: Unusual observations within the data
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据中的异常观察
- en: An observation point that is distant from all others
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与其他所有数据点相距较远的观察点
- en: Predictive modeling
  id: totrans-226
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预测建模
- en: The development of statistical models and/or data science processes to predict
    future events is called **predictive modeling**.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 统计模型和/或数据科学过程的发展，旨在预测未来事件，称为**预测建模**。
- en: Big Data
  id: totrans-228
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 大数据
- en: Again, we have some variation of the definition of big data. A large assemblage
    of data, data sets that are so large or complex that traditional data processing
    applications are inadequate, and data about every aspect of our lives have all
    been used to define or refer to big data. In 2001, then Gartner analyst Doug Laney
    introduced the 3V's concept.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 再次提到，我们对于大数据的定义有所不同。大数据通常被定义为数据量庞大或复杂，以至于传统的数据处理应用无法胜任，并且涉及我们生活的各个方面。2001年，时任Gartner分析师的Doug
    Laney提出了3V概念。
- en: 'You can refer to the link: [http://blogs.gartner.com/doug-laney/files/2012/01/ad949-3D-Data-Management-Controlling-Data-Volume-Velocity-and-Variety.pdf</span>](http://blogs.gartner.com/doug-laney/files/2012/01/ad949-3D-Data-Management-Controlling-Data-Volume-Velocity-and-Variety.pdf)'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以参考这个链接：[http://blogs.gartner.com/doug-laney/files/2012/01/ad949-3D-Data-Management-Controlling-Data-Volume-Velocity-and-Variety.pdf</span>](http://blogs.gartner.com/doug-laney/files/2012/01/ad949-3D-Data-Management-Controlling-Data-Volume-Velocity-and-Variety.pdf)
- en: 'The 3V''s, as per Laney, are volume, variety, and velocity. The V''s make up
    the dimensionality of big data: volume (or the measurable amount of data), variety
    (meaning the number of types of data), and velocity (referring to the speed of
    processing or dealing with that data).'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 根据Laney的定义，3V是体积、种类和速度。3V构成了大数据的维度：体积（或数据的可衡量数量）、种类（即数据的类型数量）和速度（指处理或处理数据的速度）。
- en: Confidence interval
  id: totrans-232
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 置信区间
- en: The confidence interval is a range of values that a data scientist will specify
    around an estimate to indicate their margin of error, combined with a probability
    that a value will fall in that range. In other words, confidence intervals are
    good estimates of the unknown population parameter.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 置信区间是数据科学家在估算值周围指定的一系列值，用于表示他们的误差范围，并结合一个概率，表示某个值落入该范围的可能性。换句话说，置信区间是对未知总体参数的良好估计。
- en: Writing
  id: totrans-234
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 写作
- en: Although visualizations grab much more of the limelight when it comes to presenting
    the output or results of a data science process or predictive model, writing skills
    are still not only an important part of how a data scientist communicates but
    still considered an essential skill for all data scientists to be successful.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管在展示数据科学过程或预测模型的输出或结果时，可视化通常更为引人注目，但写作技巧仍然是数据科学家交流的重要部分，而且仍然被认为是所有数据科学家成功的关键技能。
- en: Summary
  id: totrans-236
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we said that, currently, how data science is defined is a matter
    of opinion. A practical explanation is that data science is a progression or,
    even better, an evolution of thought, consisting of collecting, processing, exploring,
    and visualizing data, analyzing (data) and/or applying machine learning (to the
    data), and then deciding (or planning) based upon acquired insight(s).
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们提到，当前数据科学的定义是一个意见问题。一个实际的解释是，数据科学是思想的一种进展，甚至更好地说，是一种演变，包括收集、处理、探索和可视化数据，分析（数据）和/或应用机器学习（到数据中），然后基于获得的洞察做出决策（或规划）。
- en: Then, with the goal of thinking like a data scientist, we introduced and defined
    a number of common terms and concepts a data scientist should be comfortable with.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 接着，为了让你像数据科学家一样思考，我们介绍并定义了一些数据科学家应该熟悉的常见术语和概念。
- en: In the next chapter, we will present and explain how a data developer might
    understand and approach the topic of data cleaning using several common statistical
    methods.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将介绍并解释数据开发人员如何使用几种常见的统计方法理解和处理数据清洗的主题。
