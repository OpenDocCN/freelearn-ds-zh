- en: Storm Integration with Redis, Elasticsearch, and HBase
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Storm与Redis、Elasticsearch和HBase的集成
- en: In the previous chapter, we covered an overview of Apache Hadoop and its various
    components. We also presented an overview of Storm-YARN, and looked at deploying
    Storm-YARN on Apache Hadoop.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们介绍了Apache Hadoop及其各个组件的概述。我们还介绍了Storm-YARN的概述，并介绍了如何在Apache Hadoop上部署Storm-YARN。
- en: In this chapter, we will explain how you can integrate Storm with other databases
    for storing the data, and how we can use Esper inside a Storm bolt to support
    the windowing operation.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将解释如何将Storm与其他数据库集成以存储数据，以及如何在Storm bolt中使用Esper来支持窗口操作。
- en: 'The following are the key points we are going to cover in this chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是本章将要涵盖的关键点：
- en: Integration of Storm with HBase
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将Storm与HBase集成
- en: Integration of Storm with Redis
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将Storm与Redis集成
- en: Integration of Storm with Elasticsearch
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将Storm与Elasticsearch集成
- en: Integration of Storm with Esper to perform the windowing operation
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将Storm与Esper集成以执行窗口操作
- en: Integrating Storm with HBase
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将Storm与HBase集成
- en: As explained in earlier chapters, Storm is meant for real-time data processing.
    However, in most cases, you will need to store the processed data in a data store
    so that you can use the stored data for further batch analysis and execute the
    batch analysis query on the data stored. This section explains how you can store
    the data processed by Storm in HBase.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 如前几章所述，Storm用于实时数据处理。然而，在大多数情况下，您需要将处理后的数据存储在数据存储中，以便将存储的数据用于进一步的批量分析，并在存储的数据上执行批量分析查询。本节解释了如何将Storm处理的数据存储在HBase中。
- en: 'Before going to the implementation, I want to give a little overview of what
    HBase is. HBase is a NoSQL, multidimensional, sparse, horizontally scalable database that
    is modeled after **Google** **BigTable**. HBase is built on top of Hadoop, which
    means it relies on Hadoop and integrates with the MapReduce framework very well.
    Hadoop provides the following benefits to HBase:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在实施之前，我想简要介绍一下HBase是什么。HBase是一个NoSQL、多维、稀疏、水平可扩展的数据库，模型类似于**Google** **BigTable**。HBase建立在Hadoop之上，这意味着它依赖于Hadoop，并与MapReduce框架很好地集成。Hadoop为HBase提供以下好处：
- en: A distributed data store that runs on top of the commodity hardware
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在通用硬件上运行的分布式数据存储
- en: Fault tolerance
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容错
- en: We will assume that you have HBase installed and running on your system. You
    can refer to the article on HBase installation at [https://hbase.apache.org/cygwin.html](https://hbase.apache.org/cygwin.html).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我们假设您已经在系统上安装并运行了HBase。您可以参考[HBase安装文章](https://hbase.apache.org/cygwin.html)。
- en: 'We will create a sample Storm topology that shows how you can store the data
    processed by Storm to HBase using the following steps:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将创建一个示例Storm拓扑，演示如何使用以下步骤将Storm处理的数据存储到HBase：
- en: Create a Maven project using `com.stormadvance` for the group ID and `stormhbase`
    for the artifact ID.
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`com.stormadvance`作为组ID和`stormhbase`作为artifact ID创建一个Maven项目。
- en: 'Add the following dependencies and repositories to the `pom.xml` file:'
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将以下依赖项和存储库添加到`pom.xml`文件中：
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Create an `HBaseOperations` class in the `com.stormadvance.stormhbase` package.
    The `HBaseOperations` class contains two methods:'
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`com.stormadvance.stormhbase`包中创建一个`HBaseOperations`类。`HBaseOperations`类包含两个方法：
- en: '`createTable(String tableName, List<String> ColumnFamilies)`: This method takes
    the name of the table and the HBase column family list as input to create a table
    in HBase.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`createTable(String tableName, List<String> ColumnFamilies)`: 此方法将表名和HBase列族列表作为输入，以在HBase中创建表。'
- en: '`insert(Map<String, Map<String, Object>> record, String rowId)`: This method
    takes the record and its `rowID` parameter as input and inserts the input record
    to HBase. The following is the structure of the input record:'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`insert(Map<String, Map<String, Object>> record, String rowId)`: 此方法将记录及其`rowID`参数作为输入，并将输入记录插入HBase。以下是输入记录的结构：'
- en: '[PRE1]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Here, `columnfamily1` and `columnfamily2` are the names of HBase column families,
    and `column1`, `column2`, `column3`, and `column4` are the names of columns.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，`columnfamily1`和`columnfamily2`是HBase列族的名称，`column1`、`column2`、`column3`和`column4`是列的名称。
- en: The `rowId` parameter is the HBase table row key that is used to uniquely identify
    each record in HBase.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '`rowId`参数是HBase表行键，用于唯一标识HBase中的每条记录。'
- en: 'The following is the source code of the `HBaseOperations` class:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '`HBaseOperations`类的源代码如下：'
- en: '[PRE2]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Create a `SampleSpout` class in the `com.stormadvance.stormhbase` package.
    This class generates random records and passes them to the next action (bolt)
    in the topology. The following is the format of the record generated by the `SampleSpout`
    class:'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`com.stormadvance.stormhbase`包中创建一个`SampleSpout`类。此类生成随机记录并将其传递给拓扑中的下一个操作（bolt）。以下是`SampleSpout`类生成的记录的格式：
- en: '[PRE3]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The following is the source code of the `SampleSpout` class:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '`SampleSpout`类的源代码如下：'
- en: '[PRE4]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Create a `StormHBaseBolt` class in the `com.stormadvance.stormhbase` package.
    This bolt receives the tuples emitted by `SampleSpout` and then calls the `insert()`
    method of the `HBaseOperations` class to insert the record into HBase. The following
    is the source code of the `StormHBaseBolt` class:'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`com.stormadvance.stormhbase`包中创建一个`StormHBaseBolt`类。此bolt接收`SampleSpout`发出的元组，然后调用`HBaseOperations`类的`insert()`方法将记录插入HBase。`StormHBaseBolt`类的源代码如下：
- en: '[PRE5]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The constructor of the `StormHBaseBolt` class takes the HBase table name, column
    families list, ZooKeeper IP address, and ZooKeeper port as an argument and sets
    the class level variables. The `prepare()` method of the `StormHBaseBolt` class
    will create an instance of the `HBaseOperatons` class.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '`StormHBaseBolt`类的构造函数以HBase表名、列族列表、ZooKeeper IP地址和ZooKeeper端口作为参数，并设置类级变量。`StormHBaseBolt`类的`prepare()`方法将创建`HBaseOperatons`类的实例。'
- en: The `execute()` method of the `StormHBaseBolt` class takes an input tuple as
    an argument and converts it into the HBase structure format. It also uses the
    `java.util.UUID` class to generate the HBase row ID.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '`StormHBaseBolt`类的`execute()`方法以输入元组作为参数，并将其转换为HBase结构格式。它还使用`java.util.UUID`类生成HBase行ID。'
- en: 'Create a `Topology` class in the `com.stormadvance.stormhbase` package. This
    class creates an instance of the spout and bolt classes and chains them together
    using a `TopologyBuilder` class. The following is the implementation of the main
    class:'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`com.stormadvance.stormhbase`包中创建一个`Topology`类。这个类创建`spout`和`bolt`类的实例，并使用`TopologyBuilder`类将它们链接在一起。以下是主类的实现：
- en: '[PRE6]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: In this section, we covered how you can integrate Storm with a NoSQL database,
    HBase. In the next section, we are going to cover the integration of Storm with
    Redis.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们介绍了如何将Storm与NoSQL数据库HBase集成。在下一节中，我们将介绍如何将Storm与Redis集成。
- en: Integrating Storm with Redis
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将Storm与Redis集成
- en: 'Redis is a key value data store. The key values can be strings, lists, sets,
    hashes, and so on. It is extremely fast because the entire dataset is stored in
    the memory. The following are the steps to install Redis:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: Redis是一个键值数据存储。键值可以是字符串、列表、集合、哈希等。它非常快，因为整个数据集存储在内存中。以下是安装Redis的步骤：
- en: 'First, you will need to install `make`, `gcc`, and `cc` to compile the Redis
    code using the following command:'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，您需要安装`make`、`gcc`和`cc`来编译Redis代码，使用以下命令：
- en: '[PRE7]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Download, unpack, and make Redis, and copy it to `/usr/local/bin` using the
    following commands:'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载、解压并制作Redis，并使用以下命令将其复制到`/usr/local/bin`：
- en: '[PRE8]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Execute the following commands to make Redis a service:'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下命令将Redis设置为服务：
- en: '[PRE9]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Now, run the following commands to add the service to `chkconfig`, set it to
    autostart, and actually start the service:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，运行以下命令将服务添加到`chkconfig`，设置为自动启动，并实际启动服务：
- en: '[PRE10]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Check the installation of Redis with the following command:'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令检查Redis的安装情况：
- en: '[PRE11]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: If the result of the test command is `PONG`, then the installation has been
    successful.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 如果测试命令的结果是`PONG`，则安装已成功。
- en: We will assume that you have the Redis service up and running.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们假设您已经启动并运行了Redis服务。
- en: Next, we will create a sample Storm topology that will explain how you can store
    the data processed by Storm in Redis.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将创建一个示例Storm拓扑，以解释如何将Storm处理的数据存储在Redis中。
- en: Create a Maven project using `com.stormadvance` for the `groupID` and `stormredis`
    for the `artifactID`.
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`com.stormadvance`作为`groupID`，`stormredis`作为`artifactID`创建一个Maven项目。
- en: 'Add the following dependencies and repositories in the `pom.xml` file:'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`pom.xml`文件中添加以下依赖和存储库：
- en: '[PRE12]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Create a `RedisOperations` class in the `com.stormadvance.stormredis` package.
    The `RedisOperations` class contains the following method:'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`com.stormadvance.stormredis`包中创建一个`RedisOperations`类。`RedisOperations`类包含以下方法：
- en: '`insert(Map<String, Object> record, String id)`: This method takes the record
    and ID as input and inserts the input record in Redis. In the `insert()` method,
    we will first serialize the record into a string using the Jackson library and
    then store the serialized record into Redis. Each record must have a unique ID
    because it is used to retrieve the record from Redis.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`insert(Map<String, Object> record, String id)`: 此方法接受记录和ID作为输入，并将输入记录插入Redis。在`insert()`方法中，我们将首先使用Jackson库将记录序列化为字符串，然后将序列化记录存储到Redis中。每个记录必须具有唯一的ID，因为它用于从Redis中检索记录。'
- en: 'The following is the source code of the `RedisOperations` class:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是`RedisOperations`类的源代码：
- en: '[PRE13]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: We will use the same `SampleSpout` class created in the *Integrating Storm with
    HBase* section.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用在*将Storm与HBase集成*部分中创建的相同的`SampleSpout`类。
- en: 'Create a `StormRedisBolt` class in the `com.stormadvance.stormredis` package.
    This bolt receives the tuples emitted by the `SampleSpout` class, converts them
    to the Redis structure, and then calls the `insert()` method of the `RedisOperations`
    class to insert the record into Redis. The following is the source code of the
    `StormRedisBolt` class:'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`com.stormadvance.stormredis`包中创建一个`StormRedisBolt`类。这个bolt接收`SampleSpout`类发出的元组，将它们转换为Redis结构，然后调用`RedisOperations`类的`insert()`方法将记录插入Redis。以下是`StormRedisBolt`类的源代码：
- en: '[PRE14]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: In the `StormRedisBolt` class, we use the `java.util.UUID` class to generate
    the Redis key.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在`StormRedisBolt`类中，我们使用`java.util.UUID`类生成Redis键。
- en: 'Create a `Topology` class in the `com.stormadvance.stormredis` package. This
    class creates an instance of the `spout` and `bolt` classes and chains them together
    using a `TopologyBuilder` class. The following is the implementation of the main
    class:'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`com.stormadvance.stormredis`包中创建一个`Topology`类。这个类创建`spout`和`bolt`类的实例，并使用`TopologyBuilder`类将它们链接在一起。以下是主类的实现：
- en: '[PRE15]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: In this section, we covered the installation of Redis and how we can integrate
    Storm with Redis.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们介绍了Redis的安装以及如何将Storm与Redis集成。
- en: Integrating Storm with Elasticsearch
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将Storm与Elasticsearch集成
- en: In this section, we are going to cover the installation of Storm with Elasticsearch.
    Elasticsearch is an open source, distributed search engine platform developed
    on Lucene. It provides a multitenant-capable, full-text search engine capability.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将介绍如何将Storm与Elasticsearch集成。Elasticsearch是一个基于Lucene开发的开源分布式搜索引擎平台。它提供了多租户能力、全文搜索引擎功能。
- en: 'We are assuming that Elasticsearch is running on your environment. Please refer
    to [https://www.elastic.co/guide/en/elasticsearch/reference/2.3/_installation.html](https://www.elastic.co/guide/en/elasticsearch/reference/2.3/_installation.html)
    to install Elasticsearch on any of the boxes if you don''t have any running Elasticsearch
    cluster. Go through the following steps to integrate Storm with Elasticsearch:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们假设Elasticsearch正在您的环境中运行。如果您没有任何正在运行的Elasticsearch集群，请参考[https://www.elastic.co/guide/en/elasticsearch/reference/2.3/_installation.html](https://www.elastic.co/guide/en/elasticsearch/reference/2.3/_installation.html)在任何一个框中安装Elasticsearch。按照以下步骤将Storm与Elasticsearch集成：
- en: Create a Maven project using `com.stormadvance` for the `groupID` and `storm_elasticsearch`
    for the `artifactID`.
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`com.stormadvance`作为`groupID`，`storm_elasticsearch`作为`artifactID`创建一个Maven项目。
- en: 'Add the following dependencies and repositories to the `pom.xml` file:'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`pom.xml`文件中添加以下依赖和存储库：
- en: '[PRE16]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Create an `ElasticSearchOperation` class in the `com.stormadvance.storm_elasticsearch`
    package. The `ElasticSearchOperation` class contains the following method:'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`com.stormadvance.storm_elasticsearch`包中创建一个`ElasticSearchOperation`类。`ElasticSearchOperation`类包含以下方法：
- en: '`insert(Map<String, Object> data, String indexName, String indexMapping, String
    indexId)`: This method takes the record data, `indexName`, `indexMapping`, and
    `indexId` as input, and inserts the input record in Elasticsearch.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`insert(Map<String, Object> data, String indexName, String indexMapping, String
    indexId)`: 这个方法以记录数据、`indexName`、`indexMapping`和`indexId`作为输入，并将输入记录插入Elasticsearch。'
- en: 'The following is the source code of the `ElasticSearchOperation` class:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是`ElasticSearchOperation`类的源代码：
- en: '[PRE17]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: We will use the same `SampleSpout` class created in the *Integrating Storm with
    HBas*e section.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用在*将Storm与HBase集成*部分中创建的相同的`SampleSpout`类。
- en: 'Create an `ESBolt` class in the `com.stormadvance.storm_elasticsearch` package.
    This bolt receives the tuples emitted by the `SampleSpout` class, converts it
    to the `Map` structure, and then calls the `insert()` method of the `ElasticSearchOperation`
    class to insert the record into Elasticsearch. The following is the source code
    of the `ESBolt` class:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`com.stormadvance.storm_elasticsearch`包中创建一个`ESBolt`类。这个bolt接收`SampleSpout`类发出的元组，将其转换为`Map`结构，然后调用`ElasticSearchOperation`类的`insert()`方法将记录插入Elasticsearch。以下是`ESBolt`类的源代码：
- en: '[PRE18]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Create an `ESTopology` class in the `com.stormadvance.storm_elasticsearch`
    package. This class creates an instance of the `spout` and `bolt` classes and
    chains them together using a `TopologyBuilder` class. The following is the implementation
    of the main class:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`com.stormadvance.storm_elasticsearch`包中创建一个`ESTopology`类。这个类创建了`spout`和`bolt`类的实例，并使用`TopologyBuilder`类将它们链接在一起。以下是主类的实现：
- en: '[PRE19]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: In this section, we covered how we can store the data into Elasticsearch by
    making the connection with Elasticsearch nodes inside the Storm bolts.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们介绍了如何通过在Storm bolts内部与Elasticsearch节点建立连接来将数据存储到Elasticsearch中。
- en: Integrating Storm with Esper
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将Storm与Esper集成
- en: In this section, we are going to cover how we can use the windowing operation
    inside Storm by using Esper. Esper is an open source event series analysis and
    event correlation engine for **complex event processing** (**CEP**).
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将介绍如何在Storm中使用Esper进行窗口操作。Esper是一个用于**复杂事件处理**（**CEP**）的开源事件序列分析和事件关联引擎。
- en: 'Please refer to [http://www.espertech.com/products/esper.php](http://www.espertech.com/products/esper.php)
    to read more details about Esper. Go through the following steps to integrate
    Storm with Esper:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 请参阅[http://www.espertech.com/products/esper.php](http://www.espertech.com/products/esper.php)了解更多关于Esper的详细信息。按照以下步骤将Storm与Esper集成：
- en: Create a Maven project using `com.stormadvance` for the `groupID` and `storm_esper`
    for the `artifactID`.
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`com.stormadvance`作为`groupID`，`storm_esper`作为`artifactID`创建一个Maven项目。
- en: 'Add the following dependencies and repositories in the `pom.xml` file:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`pom.xml`文件中添加以下依赖项和存储库：
- en: '[PRE20]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Create an `EsperOperation` class in the `com.stormadvance.storm_elasticsearch`
    package. The `EsperOperation` class contains the following method:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`com.stormadvance.storm_elasticsearch`包中创建一个`EsperOperation`类。`EsperOperation`类包含以下方法：
- en: '`esperPut(Stock stock)`: This method takes the stock bean as an input and sends
    the event to the Esper listener.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`esperPut(Stock stock)`: 这个方法以股票bean作为输入，将事件发送给Esper监听器。'
- en: The constructor of the `EsperOperation` class initializes the Esper listener
    and sets the Esper query. The Esper query buffers the events over 5 minutes and
    returns the total sales of each product during the 5 minutes window. Here, we
    are using the fixed batch window.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '`EsperOperation`类的构造函数初始化了Esper监听器并设置了Esper查询。Esper查询在5分钟内缓冲事件并返回每个产品在5分钟窗口期内的总销售额。在这里，我们使用了固定批处理窗口。'
- en: 'The following is the source code of the `EsperOperation` class:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是`EsperOperation`类的源代码：
- en: '[PRE21]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Create a `SampleSpout` class in the `com.stormadvance.storm_esper` package.
    This class generates random records and passes them to the next action (bolt)
    in the topology. The following is the format of the record generated by the `SampleSpout`
    class:'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`com.stormadvance.storm_esper`包中创建一个`SampleSpout`类。这个类生成随机记录并将它们传递给拓扑中的下一个操作（bolt）。以下是`SampleSpout`类生成的记录的格式：
- en: '[PRE22]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The following is the source code of the `SampleSpout` class:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是`SampleSpout`类的源代码：
- en: '[PRE23]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Create an `EsperBolt` class in the `com.stormadvance.storm_esper` package.
    This bolt receives the tuples emitted by the `SampleSpout` class, converts it
    to the stock bean, and then calls the `esperPut()` method of the `EsperBolt` class
    to pass the data to the Esper engine. The following is the source code of the
    `EsperBolt` class:'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`com.stormadvance.storm_esper`包中创建一个`EsperBolt`类。这个bolt接收`SampleSpout`类发出的元组，将其转换为股票bean，然后调用`EsperBolt`类的`esperPut()`方法将数据传递给Esper引擎。以下是`EsperBolt`类的源代码：
- en: '[PRE24]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Create an `EsperTopology` class in the `com.stormadvance.storm_esper` package.
    This class creates an instance of the `spout` and `bolt` classes and chains them
    together using a `TopologyBuilder` class. The following is the implementation
    of the main class:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`com.stormadvance.storm_esper`包中创建一个`EsperTopology`类。这个类创建了`spout`和`bolt`类的实例，并使用`TopologyBuilder`类将它们链接在一起。以下是主类的实现：
- en: '[PRE25]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Summary
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we mostly focused on the integration of Storm with other databases.
    Also, we covered how we can use Esper inside Storm to perform the windowing operation.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们主要关注了Storm与其他数据库的集成。此外，我们还介绍了如何在Storm中使用Esper执行窗口操作。
- en: In the next chapter, we will cover the Apache log processing case study. We
    will explain how you can generate business information by processing log files
    through Storm.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将介绍Apache日志处理案例研究。我们将解释如何通过Storm处理日志文件来生成业务信息。
