- en: '8'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '8'
- en: Markov Chain
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 马尔可夫链
- en: The Markov chain is one of the most important stochastic processes and solves
    real-world problems with probabilities. A Markov chain is a model of random movement
    in a discrete set of possible locations (states), in other words, a model of transition
    from one location (state) to another with a certain probability. It is named after
    Andrey Markov, the Russian mathematician who is best known for his work on stochastic
    processes. It is a mathematical system describing a sequence of events in which
    the probability of each event depends only on the previous event.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 马尔可夫链是最重要的随机过程之一，能够通过概率解决现实世界中的问题。马尔可夫链是一个离散位置集合中的随机运动模型，换句话说，它是一个从一个位置（状态）到另一个位置（状态）过渡的模型，并且具有一定的概率。它以俄罗斯数学家安德雷·马尔可夫（Andrey
    Markov）的名字命名，他以在随机过程上的工作而著名。它是一个数学系统，用于描述一系列事件，其中每个事件的概率仅依赖于前一个事件。
- en: “The future depends only upon the present, not upon the past.”
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: “未来仅依赖于当前，而非过去。”
- en: The events or states can be written as {![](img/Formula_08_001.png), where ![](img/Formula_08_002.png)
    is the state at time t. The process {} has a property, which is ![](img/Formula_08_003.png)
    , which depends only on ![](img/Formula_08_004.png) and does not depend on {![](img/Formula_08_005.png).
    Such a process is called a Markovian or Markov chain. It is a random walk to traverse
    a system of states. A two-state Markov chain is one in which a state can transition
    onto itself (that is, staying in the same state). It is shown in *Figure 8**.1*
    (which is a state diagram). An example of a Markov chain is the PageRank algorithm,
    which is used by Google to determine the order of results for a search.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 事件或状态可以表示为 {![](img/Formula_08_001.png)，其中 ![](img/Formula_08_002.png) 是时刻 t
    的状态。该过程 {} 具有一个性质，即 ![](img/Formula_08_003.png)，它仅依赖于 ![](img/Formula_08_004.png)，并且不依赖于
    {![](img/Formula_08_005.png)}。这样的过程称为马尔可夫过程或马尔可夫链。它是遍历一组状态的随机游走。二状态马尔可夫链是一种状态可以转换为自身（即保持在同一状态）。如
    *图8.1*（状态图）所示。马尔可夫链的一个例子是 PageRank 算法，它被谷歌用来确定搜索结果的排序。
- en: '![Figure 8.1: Two-state (A and E) Markov chain](img/Figure_08_01_B18943.jpg)'
  id: totrans-5
  prefs: []
  type: TYPE_IMG
  zh: '![图8.1：二状态（A 和 E）马尔可夫链](img/Figure_08_01_B18943.jpg)'
- en: 'Figure 8.1: Two-state (A and E) Markov chain'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.1：二状态（A 和 E）马尔可夫链
- en: Markov chains are quite powerful when it comes to including real-world phenomena
    in computer simulations. It is a class of probabilistic graphical models representing
    a dynamic process, the limitation being that it can only take on a finite number
    of states. Markov chains have no long-term memory (are memory-less, in short)
    and hence know no past states. Therefore, the only state determining the future
    state in a Markov chain is the present, and this is called a Markov property.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及将现实世界的现象融入计算机仿真时，马尔可夫链非常强大。它是一类表示动态过程的概率图模型，限制在于它只能采用有限数量的状态。马尔可夫链没有长期记忆（简而言之是无记忆的），因此无法知道过去的状态。因此，在马尔可夫链中，唯一决定未来状态的状态是当前状态，这就是所谓的马尔可夫性质。
- en: 'This chapter covers the following topics:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖以下主题：
- en: Discrete-time Markov chain
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 离散时间马尔可夫链
- en: '**Markov Chain Monte** **Carlo** (**MCMC**)'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**马尔可夫链蒙特卡洛** (**MCMC**)'
- en: The following section discusses the very foundation of a Markov chain, which
    is a discrete-time stochastic process.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 以下部分讨论了马尔可夫链的基本原理，马尔可夫链是一个离散时间的随机过程。
- en: Discrete-time Markov chain
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 离散时间马尔可夫链
- en: For a discrete-time Markov process, ![](img/Formula_08_006.png) while in continuous
    time ![](img/Formula_08_007.png) is replaced by ![](img/Formula_08_008.png) where
    ![](img/Formula_08_009.png) runs until infinity. Given the present state, past
    and future states are independent in a Markov chain, which in turn means that
    the future is only dependent on the present. In the following subsections, we
    will learn about the transition matrix and an application of the Markov chain
    in time-series data for short-term forecasting.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 对于离散时间马尔可夫过程，![](img/Formula_08_006.png) 在连续时间中，![](img/Formula_08_007.png)
    被 ![](img/Formula_08_008.png) 替代，其中 ![](img/Formula_08_009.png) 会持续到无穷大。在马尔可夫链中，给定当前状态，过去和未来的状态是独立的，这也意味着未来仅依赖于当前状态。在以下小节中，我们将学习转移矩阵以及马尔可夫链在时间序列数据中的应用，特别是在短期预测中的应用。
- en: Transition probability
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 转移概率
- en: The transition probabilities between Markov states are captured in a state transition
    matrix. The dimension of the transition matrix is determined by the number of
    states in the state space. Every state is included as a row and a column, and
    each cell in the matrix gives the probability of transition from its row’s state
    to its column’s state, as shown in *Figure 8**.2*. In order to forecast one step
    ahead, one must know the transition matrix and the current state. The transition
    probability (matrix element) is typically established from historical sequential
    data.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 马尔科夫状态之间的转移概率被捕捉在状态转移矩阵中。转移矩阵的维度由状态空间中的状态数量决定。每个状态都作为一行和一列包含在内，矩阵中的每个单元格给出了从其行状态到其列状态的转移概率，如
    *图 8.2* 所示。为了预测一步后的状态，必须知道转移矩阵和当前状态。转移概率（矩阵元素）通常通过历史序列数据来建立。
- en: '![Figure 8.2: Transition matrix for the two states](img/Figure_08_02_B18943.jpg)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.2：两个状态的转移矩阵](img/Figure_08_02_B18943.jpg)'
- en: 'Figure 8.2: Transition matrix for the two states'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.2：两个状态的转移矩阵
- en: Application of the Markov chain
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 马尔科夫链的应用
- en: Markov chains model the behavior of a random process. They can be used for text
    prediction in order to autocomplete sentences or to model the evolution of time-series
    data, for example, modeling the behavior of financial markets.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 马尔科夫链用于建模随机过程的行为。它们可以用于文本预测，例如自动完成句子，或者建模时间序列数据的演变，例如建模金融市场的行为。
- en: 'An example of modeling the price of stock using a Markov chain is depicted
    in the following Python code. A set of states (in the order `increase`, `decrease`,
    and `stable`) is defined for the time evolution of the stock price with the probability
    of transition between these states. The transition matrix is used to predict the
    probable future (next state) price:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 以下 Python 代码展示了如何使用马尔科夫链建模股票价格。为股票价格的时间演变定义了一组状态（按顺序为 `increase`、`decrease`
    和 `stable`），并给出了这些状态之间的转移概率。转移矩阵用于预测未来的可能（下一个状态）价格：
- en: '[PRE0]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The output is a sequence of future states, shown in *Figure 8**.3*, given a
    current state. A different output is obtained if the current state is set to `decrease`
    or `stable` (initial state) while executing the function in the code. The sequence
    of states depicts the evolution of the stock price over time. Caution must be
    exercised when the system does not exhibit stationary behavior, that is, the transition
    probabilities between states change over time. In that case, a complex Markov
    model or a different model altogether may be used to capture the system's behavior.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 输出是一系列未来的状态，如 *图 8.3* 所示，基于当前状态。如果在执行代码中的函数时，当前状态设置为 `decrease` 或 `stable`（初始状态），则会得到不同的输出。状态序列展示了股票价格随时间的变化。需要注意的是，当系统未表现出平稳行为时（即状态之间的转移概率随时间变化），应当小心处理。在这种情况下，可以使用更复杂的马尔科夫模型或完全不同的模型来捕捉系统的行为。
- en: '![Figure 8.3: Output of the example code in Python](img/Figure_08_03_B18943.jpg)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.3：Python 示例代码的输出](img/Figure_08_03_B18943.jpg)'
- en: 'Figure 8.3: Output of the example code in Python'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.3：Python 示例代码的输出
- en: 'If ![](img/Formula_08_010.png) is the number of times the sequence is in state
    ![](img/Formula_08_011.png) (state is observed) and ![](img/Formula_08_012.png)
    is the number of times there is a transition from state *i* to state *j*, then
    the transition probability is defined as follows:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 ![](img/Formula_08_010.png) 是序列处于状态 ![](img/Formula_08_011.png)（观察到状态）的次数，而
    ![](img/Formula_08_012.png) 是从状态 *i* 到状态 *j* 之间发生转移的次数，那么转移概率定义如下：
- en: '![](img/Formula_08_013.jpg)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_08_013.jpg)'
- en: In the next section, we will learn about a sampling method, MCMC, which is used
    for high-dimensional probability distributions wherein the next sample is dependent
    on the current sample drawn randomly from a population. In short, the samples
    drawn from the distribution are probabilistically dependent on each other. The
    volume of a sample space increases exponentially with the number of parameters
    or dimensions, and modeling such a space could easily be inaccurate with the usage
    of straightforward methods such as Monte Carlo sampling. The MCMC method is an
    attempt to harness the properties of a random problem and construct the corresponding
    Markov process efficiently.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将学习一种用于高维概率分布的采样方法MCMC，其中下一个样本依赖于当前从一个人群中随机抽取的样本。简而言之，从分布中抽取的样本在概率上是相互依赖的。样本空间的体积随着参数或维度的增加而呈指数增长，使用蒙特卡罗采样等直接方法建模这样的空间可能会不准确。MCMC方法尝试利用随机问题的属性，并高效地构建相应的马尔可夫过程。
- en: Markov Chain Monte Carlo
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 马尔可夫链蒙特卡罗
- en: MCMC is a method of random sampling from a target population/distribution defined
    by high-dimensional probability definition. It is a large-scale statistical method
    that draws samples randomly from a complex probabilistic space to approximate
    the distribution of attributes over a range of future states. It helps gauge the
    distribution of a future outcome and the sample averages help approximate expectations.
    A Markov chain is a **graph** of states over which a sampling algorithm takes
    a random walk.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: MCMC是一种从高维概率定义所定义的目标人群/分布中进行随机采样的方法。这是一种大规模统计方法，从复杂的概率空间中随机抽取样本，以近似未来状态范围内属性的分布。它有助于评估未来结果的分布，样本均值帮助近似期望值。马尔可夫链是一个**状态图**，采样算法在其上执行随机游走。
- en: The most known MCMC algorithm is perhaps Gibbs sampling. The algorithms are
    nothing but different methodologies for constructing the Markov chain. The most
    general MCMC algorithm is Metropolis-Hastings and has flexibility in many ways.
    These two algorithms will be discussed in the next subsections.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 最著名的MCMC算法可能是吉布斯采样。这些算法只是构建马尔可夫链的不同方法论。最通用的MCMC算法是Metropolis-Hastings算法，具有多种灵活性。这两个算法将在接下来的小节中讨论。
- en: Gibbs sampling algorithm
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 吉布斯采样算法
- en: In Gibbs sampling, the probability of the next sample in the Markov chain is
    calculated as the conditional probability of the prior sample. Samples in the
    Markov chain are constructed by changing one random variable at a time (conditioned
    on other variables in the distribution), meaning subsequent samples in the search
    space are closer. Gibbs sampling is most appropriate with a discrete (not continuous)
    distribution, which has a parametric form that allows sampling and calculating
    the conditional probability. An example of sampling with Gibbs sampler is shown
    in *Figure 8**.4*, which reproduces the desired distribution.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在吉布斯采样中，马尔可夫链中下一个样本的概率被计算为前一个样本的条件概率。马尔可夫链中的样本是通过每次改变一个随机变量来构建的（以分布中的其他变量为条件），这意味着后续样本在搜索空间中会更接近。吉布斯采样最适用于离散（而非连续）分布，这种分布具有允许采样并计算条件概率的参数形式。吉布斯采样的一个示例显示在*图
    8.4*中，它再现了期望的分布。
- en: '![Figure 8.4: Gibbs sampler reproducing a desired Gaussian mixture](img/Figure_08_04_B18943.jpg)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.4：吉布斯采样器再现期望的高斯混合](img/Figure_08_04_B18943.jpg)'
- en: 'Figure 8.4: Gibbs sampler reproducing a desired Gaussian mixture'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.4：吉布斯采样器再现期望的高斯混合
- en: A Gibbs sampler is more efficient than a Metropolis-Hastings algorithm (discussed
    in the next subsection). It starts with a proposal distribution and a proposal
    is always accepted; that is, the acceptance probability is always 1\. We will
    use an example of the bivariate Gaussian distribution to illustrate a Gibbs sampler
    with Python code in the last subsection.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 吉布斯采样器比Metropolis-Hastings算法（将在下一个小节中讨论）更高效。它从一个提议分布开始，并且提议总是被接受；也就是说，接受概率始终为1。我们将在最后一个小节中使用二维高斯分布的例子，结合Python代码来演示吉布斯采样器。
- en: Metropolis-Hastings algorithm
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Metropolis-Hastings算法
- en: The Metropolis-Hastings algorithm is used for probabilistic models where Gibbs
    sampling cannot be used. It does not assume that the state of the next sample
    can be generated from a target distribution, which is the main assumption in Gibbs
    sampling. This algorithm involves using a surrogate probability distribution,
    also called the kernel, and an acceptance criterion that helps decide whether
    the new sample can be accepted into the Markov chain or has to be rejected. The
    proposed distribution (surrogate) is suggestive of an arbitrary next sample and
    the acceptance criterion ensures an appropriate limiting direction in getting
    closer to the true or desired the state of the next sample. The starting points
    of these algorithms are important and different proposal distributions can be
    explored.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: Metropolis-Hastings 算法用于吉布斯抽样无法使用的概率模型。它不假设下一个样本的状态可以从目标分布生成，这是吉布斯抽样中的主要假设。该算法使用了一个代理概率分布，也叫做核函数，并通过接受准则帮助决定是否将新样本接受到马尔科夫链中，或者是否必须拒绝它。提议分布（代理）是对下一个样本的任意建议，接受准则确保在接近真实或期望的下一个样本状态时，能沿着适当的方向收敛。算法的起始点非常重要，可以探索不同的提议分布。
- en: How does this algorithm work?
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这个算法是如何工作的？
- en: We start with a random state.
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们从一个随机状态开始。
- en: Based on the proposal probability, we randomly pick a new state.
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 基于提议的概率，我们随机选择一个新的状态。
- en: We calculate the acceptance probability of the proposed new state.
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们计算提议新状态的接受概率。
- en: For example, say the probability of a flipped coin landing on heads is the acceptance
    probability. If it lands on heads, we accept the sample; otherwise, we reject
    it.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设投币正面朝上的概率就是接受概率。如果投币正面朝上，我们接受该样本；否则，拒绝它。
- en: We repeat the process for a long time.
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们重复这个过程很长时间。
- en: We discard the initial few samples as the chain does not reach its stationary
    state. The period before the chain reaches its stationary state is called the
    burn-in period (see *Figure 8**.5*). The accepted draws will converge to the stationary
    distribution after some time.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们丢弃最初的几个样本，因为链条尚未达到其平稳状态。链条达到平稳状态之前的阶段称为烧入期（见*图 8.5*）。经过一段时间后，接受的抽样将会收敛到平稳分布。
- en: '![Figure 8.5: Markov chain](img/Figure_08_05_B18943.jpg)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.5：马尔科夫链](img/Figure_08_05_B18943.jpg)'
- en: 'Figure 8.5: Markov chain'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.5：马尔科夫链
- en: The stationary distribution shows the probability of being at any state X at
    any given time and is always reached if a very large number of samples is generated.
    This distribution is exactly the posterior distribution we’re looking for. A posterior
    distribution is proportional to the product of likelihood and prior distribution.
    The Metropolis-Hastings algorithm is analogous to a diffusion process wherein
    all states are communicating (by design) and hence the system eventually settles
    into an equilibrium state, which is the same as converging to a stationary state.
    This property is called **ergodicity**.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 平稳分布展示了在任意给定时间处于任意状态 X 的概率，如果生成大量样本，始终可以达到该分布。这个分布就是我们要寻找的后验分布。后验分布与似然函数和先验分布的乘积成正比。Metropolis-Hastings
    算法类似于扩散过程，其中所有状态都在相互交流（设计使然），因此系统最终会趋于一个平衡状态，这与收敛到平稳状态是一样的。这一性质称为**遍历性**。
- en: In the next subsection, we illustrate the Metropolis-Hastings sampling algorithm,
    also with Python code, using the example of bivariate distribution.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的小节中，我们通过 Python 代码使用双变量分布的例子来说明 Metropolis-Hastings 抽样算法。
- en: Illustration of MCMC algorithms
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MCMC 算法的示意图
- en: 'The working of the Gibbs sampling algorithm is shown with a simple bivariate
    Gaussian distribution in the following code. We pass the two parameters (mu and
    sigma) for the conditional probability distribution and discard a part of initially
    sampled values for the algorithm to converge even if the starting (guess) value
    is way off. This part of the sample is known as burn-in:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 吉布斯抽样算法的工作原理通过以下代码展示了一个简单的双变量高斯分布。我们传递两个参数（mu 和 sigma）用于条件概率分布，并丢弃一部分最初采样的值，以便算法收敛，即使起始（猜测）值偏差很大。这部分样本称为烧入期：
- en: '[PRE1]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: We run the code and the Gibbs sampler yields an output, shown in *Figure 8**.6a*,
    in two forms, namely, a kernel distribution estimation plot and a linear regression
    fit. The output is the resulting (target) distribution based on sampled values
    using the Gibbs sampling algorithm.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们运行代码，Gibbs采样器生成了一个输出，如*图8.6a*所示，输出有两种形式，即核密度估计图和线性回归拟合图。输出是基于使用Gibbs采样算法的采样值所得到的结果（目标）分布。
- en: '![Figure 8.6a: Target distribution from the Gibbs sampling algorithm](img/Figure_08_06_B18943.jpg)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![图8.6a：Gibbs采样算法的目标分布](img/Figure_08_06_B18943.jpg)'
- en: 'Figure 8.6a: Target distribution from the Gibbs sampling algorithm'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.6a：Gibbs采样算法的目标分布
- en: 'We run a similar setup (bivariate distribution) for Metropolis-Hastings sampler.
    The Python code and output are given as follows. To begin with, we plot the true
    distribution and then use the multivariate normal distribution as the proposal.
    *Figure 8**.6b* is the output (target distribution) based on sampling using the
    algorithm:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为Metropolis-Hastings采样器运行了一个类似的设置（二元分布）。Python代码和输出如下所示。首先，我们绘制真实分布，然后使用多元正态分布作为提议分布。*图8.6b*
    是基于使用该算法采样的输出（目标分布）：
- en: '[PRE2]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![Figure 8.6b: True distribution (L) and target distribution (R) from the Metropolis-Hastings
    sampling algorithm](img/Figure_08_07_B18943.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![图8.6b：Metropolis-Hastings采样算法的真实分布（L）和目标分布（R）](img/Figure_08_07_B18943.jpg)'
- en: 'Figure 8.6b: True distribution (L) and target distribution (R) from the Metropolis-Hastings
    sampling algorithm'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.6b：Metropolis-Hastings采样算法的真实分布（L）和目标分布（R）
- en: For finite (discrete as well as continuous) state spaces, the existence of a
    unique stationary state is guaranteed. We start from a prior probability distribution
    and end with a stationary distribution, which is the posterior or target distribution
    based on sampled values.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 对于有限（离散的以及连续的）状态空间，保证存在一个唯一的平稳状态。我们从一个先验概率分布开始，最终得到一个平稳分布，即基于采样值得到的后验或目标分布。
- en: Summary
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we learned about the Markov chain, which is utilized to model
    special types of stochastic processes, such as problems wherein one can assume
    the entire past is encoded in the present, which in turn can be leveraged to determine
    the next (future) state. An application of the Markov chain in modeling time-series
    data was illustrated. The most common MCMC algorithm (Metropolis-Hastings) for
    sampling was also covered with code to illustrate. If a system exhibits non-stationary
    behavior (transition probability changes with time), then a Markov chain is not
    the appropriate model and a more complex model may be required to capture the
    behavior of the dynamic system.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了马尔科夫链，它被用来建模特殊类型的随机过程，比如那些假设整个过去已经编码在当前状态中的问题，这反过来可以用于确定下一个（未来）状态。我们还展示了马尔科夫链在建模时间序列数据中的应用。我们还介绍了最常见的MCMC算法（Metropolis-Hastings），并用代码进行了说明。如果一个系统表现出非平稳行为（转移概率随时间变化），那么马尔科夫链就不是合适的模型，可能需要更复杂的模型来捕捉动态系统的行为。
- en: With this chapter, we conclude the second part of the book. In the next chapter,
    we will explore fundamental optimization techniques, some of which are used in
    machine learning. We will touch upon evolutionary optimization, optimization in
    operations research, and that are leveraged in training neural networks.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 本章结束后，我们完成了本书的第二部分。在下一章中，我们将探讨基本的优化技术，其中一些技术在机器学习中得到了应用。我们将讨论进化优化、运筹学中的优化，以及在神经网络训练中应用的优化方法。
- en: Part 3:Mathematical Optimization
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第3部分：数学优化
- en: In this part, you will have exposure to optimization techniques that lay the
    foundation for machine learning, deep learning, and other models used in operations
    research. Optimization techniques are extremely powerful for predictive and prescriptive
    analytics and find applications in several complex problems in heavy industry.
    Additionally, blending classical mathematical modeling with machine learning often
    allows for the extraction of more meaningful insights for specific sensitive business
    problems.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在本部分，你将接触到为机器学习、深度学习以及运筹学中使用的其他模型奠定基础的优化技术。优化技术在预测性和规范性分析中具有极大的威力，并应用于重工业中的许多复杂问题。此外，将经典数学建模与机器学习相结合，通常可以为特定的敏感商业问题提取出更有意义的洞察。
- en: 'This part has the following chapters:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 本部分包括以下章节：
- en: '[*Chapter 9*](B18943_09.xhtml#_idTextAnchor098), *Exploring Optimization Techniques*'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第9章*](B18943_09.xhtml#_idTextAnchor098)，*探索优化技术*'
- en: '[*Chapter 10*](B18943_10.xhtml#_idTextAnchor107), *Optimization Techniques
    for Machine Learning*'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第10章*](B18943_10.xhtml#_idTextAnchor107)，*机器学习的优化技术*'
