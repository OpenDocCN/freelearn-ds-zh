- en: SQL, Math, and Wrapping it up
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: SQL、数学及总结
- en: Databases are attractive solutions for storing and accessing data. They supply
    the developer with an API that allows the structured organization of data, the
    ability to search that data in flexible ways, and the ability to store new data.
    When a database's capabilities are a requirement, there's often little room left
    for negotiation; the question is which database and not whether we should use
    one.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 数据库是存储和访问数据的理想解决方案。它们为开发者提供了一个 API，允许数据的结构化组织、以灵活的方式搜索数据以及存储新数据。当数据库的功能成为必需时，通常没有太多的谈判空间；问题不在于是否使用数据库，而是选择哪个数据库。
- en: Despite this fact, the Unix command line provides a suite of tools that lets
    a developer view streams or files in many of the same ways as they would view
    a database. Given one or more files with data in it, we can use these tools to
    query that data without ever having to maintain a database or any of the things
    that go along with it, such as fixed schemas. Often, we can use this method for
    processing data instead of standing up a database server and dealing with the
    issues associated with the **Extract**, **Transformation**, and **Load** (**ETL**)
    of data into that database. Even better, our pipeline, and therefore our view
    of the data, can change over time, unlike the relatively static schemas of traditional
    databases.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，Unix 命令行提供了一系列工具，使得开发者可以以多种方式查看流或文件，类似于查看数据库。给定一个或多个包含数据的文件，我们可以使用这些工具查询数据，而无需维护数据库或与之相关的任何内容，如固定的模式。通常，我们可以使用这种方法来处理数据，而不是启动一个数据库服务器并处理与**提取**、**转换**和**加载**（**ETL**）数据到数据库相关的问题。更好的是，我们的管道，以及我们对数据的视图，可以随时间变化，而不像传统数据库的相对静态模式。
- en: Often, you'll need to perform computations on numerical data in your workflows.
    The command line has several tools that enable us to do this.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 经常，你需要在工作流中对数值数据进行计算。命令行有多种工具可以帮助我们完成这一操作。
- en: Bash itself has the capability to do some math in shell scripts. When a little
    more capability is required, two command-line tools, `bc` and `awk`, are capable
    of doing many types of calculations.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Bash 本身具备在 shell 脚本中进行一些数学运算的能力。当需要更多功能时，两个命令行工具 `bc` 和 `awk` 能够执行多种类型的计算。
- en: Sometimes, we may need the full power of a programming language and mathematics
    packages, such as Python and Pandas. While this isn't a tutorial on how to do
    data science in Python, in this chapter, we'll see how to interface your Python
    routines in line with other command-line tools and build a custom pipeline for
    your needs.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，我们可能需要编程语言和数学包的完整功能，如 Python 和 Pandas。虽然这不是关于如何在 Python 中进行数据科学的教程，但在本章中，我们将看到如何将你的
    Python 程序与其他命令行工具接口，并根据需要构建自定义的管道。
- en: We'll also be using many of the tools that we have seen in this book to perform
    some real-world analysis on weather data.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将使用本书中看到的许多工具对天气数据进行一些实际分析。
- en: 'So, to sum it up, in this chapter we will be looking at:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，在本章中，我们将研究：
- en: Viewing data as columns using `cut`
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `cut` 查看数据作为列
- en: Using `grep` as a `WHERE` clause
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `grep` 作为 `WHERE` 子句
- en: Joining different sets of data using the `join` command
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `join` 命令连接不同的数据集
- en: Simulating `SELECT` clauses using `awk`
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `awk` 模拟 `SELECT` 子句
- en: Learning how to use SQLite when a more fully-featured database is needed
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习如何在需要更全面功能的数据库时使用 SQLite
- en: Bash variable assignment
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bash 变量赋值
- en: Basic bash arithmetic and comparisons
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基础 Bash 算术和比较
- en: Math using `bc`
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `bc` 进行数学计算
- en: Streaming calculations with `awk`
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`awk`进行流式计算
- en: Interfacing with python routines
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与 Python 程序进行接口
- en: Looking at the contents of a publicly available weather API
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查看一个公开的天气 API 的内容
- en: Scraping the API and storing the results in lightweight databases
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 抓取 API 并将结果存储到轻量级数据库中
- en: Using the tools discussed in the previous chapters to analyze the data in the
    databases we've created
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用前面章节讨论的工具分析我们创建的数据库中的数据
- en: Drawing some conclusions about how accurate the weather forecast is
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 得出关于天气预报准确性的结论
- en: cut and viewing data as columnar
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 `cut` 将数据视图化为列
- en: The first thing you will likely need to do is partition data in files into rows
    of data and columns of data. We saw some transformations in the previous chapters
    that allow us to manipulate data one row at a time. For this chapter, we'll assume
    the rows of your data correspond with the lines of data in your files. If this
    isn't the case, this may be the first thing you want to do in your pipeline.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能首先需要做的事情是将文件中的数据分割成数据行和数据列。我们在前面的章节中看到了一些转换方法，允许我们逐行处理数据。在本章中，我们假设你的数据行对应文件中的数据行。如果情况并非如此，这可能是你在管道中要做的第一件事。
- en: Given that we have some rows of data in our file or stream, we would like to
    view those rows in a columnar fashion, such as a traditional database. We can
    do this using the help of the `cut` command. `cut` will allow us to chop the lines
    of the file into columns by a delimiter, and to select which of those columns
    get passed through to the output.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们在文件或数据流中有一些数据行，我们希望以列的形式查看这些数据，就像传统的数据库一样。我们可以借助`cut`命令来实现这一点。`cut`可以帮助我们通过分隔符将文件中的行切割成列，并选择哪些列传递到输出中。
- en: 'If your data is a comma-separated or tab-separated file, `cut` is quite simple:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的数据是以逗号分隔或制表符分隔的文件，`cut` 非常简单：
- en: '[PRE0]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The preceding code produces these results:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的代码产生了以下结果：
- en: '![](img/7950562c-771d-46d9-b458-5cdb9ebd0a68.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7950562c-771d-46d9-b458-5cdb9ebd0a68.png)'
- en: 'In this command, we''re telling `cut` that the delimiter is using `-d$''\t''`.
    Also, we use the `-f2,8` option to tell `cut` which of the columns we would like
    to pass from the input to the output. Note that we captured the header row of
    the data, which probably isn''t desired. To skip it, add `tail -n +2` to the pipe:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在此命令中，我们告诉 `cut` 使用 `-d$'\t'` 作为分隔符。此外，我们使用 `-f2,8` 选项告诉 `cut` 选择哪些列从输入传递到输出。请注意，我们捕获了数据的标题行，这通常是我们不希望的。为了跳过它，可以在管道中添加
    `tail -n +2`：
- en: '[PRE1]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The preceding code produces these results:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的代码产生了以下结果：
- en: '![](img/29c188b8-b3b5-44c1-9e8e-b1ff9d0b9a2a.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](img/29c188b8-b3b5-44c1-9e8e-b1ff9d0b9a2a.png)'
- en: 'If your line is more complicated than a CSV or TSV, you may have to do more
    than one pass using cut, or possibly an intervening step using `awk` or `sed`.
    For example, in the book-review dataset, say we want to output the date field,
    but in year-month-date order. We can first select down to the date field, re-cut
    the date field into its constituent parts, and output them in the desired order:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的行比 CSV 或 TSV 更复杂，你可能需要使用 `cut` 多次，或者可能需要使用 `awk` 或 `sed` 进行中间处理。例如，在书籍评论数据集中，假设我们想要输出日期字段，但需要按年-月-日顺序输出。我们可以首先选取日期字段，再将日期字段重新切割成其组成部分，并按所需的顺序输出：
- en: '[PRE2]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The preceding code produces these results:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的代码产生了以下结果：
- en: '![](img/fba937fa-eb7d-43a1-a016-dfde2e6b7686.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fba937fa-eb7d-43a1-a016-dfde2e6b7686.png)'
- en: '`cut` can also cut particular bytes or characters from a stream if you have
    fixed-width fields:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '`cut` 还可以从流中切割特定的字节或字符，如果你有固定宽度的字段：'
- en: '[PRE3]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The preceding code produces these results:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的代码产生了以下结果：
- en: '![](img/c4538db4-1f6d-4769-8a84-7b80e30107dc.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c4538db4-1f6d-4769-8a84-7b80e30107dc.png)'
- en: In the case of the book data, this isn't going to make much sense since the
    fields are variable-width, but sometimes it's just what you need.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在书籍数据的情况下，这样做并不太有意义，因为字段是可变宽度的，但有时它正是你所需要的。
- en: Using `cut` in this fashion will be your tool for a SQL-like `SELECT` of particular
    characters in each row of your data.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 以这种方式使用 `cut` 将是你进行 SQL 类似的 `SELECT` 操作，选择每行数据中特定字符的工具。
- en: WHERE clauses
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: WHERE 子句
- en: 'The powerful grep regular-expression-matching tool we discussed in a previous
    chapter allows us to perform `WHERE` clauses on our files. The clause may be a
    bit less intuitive than a SQL `WHERE` clause, but we can do as much or more with
    grep as we can with the SQL `WHERE` clause. For example, perhaps we only care
    about accounts starting with the number `3`:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在前一章中讨论的强大 `grep` 正则表达式匹配工具可以帮助我们在文件中执行 `WHERE` 子句。这个子句可能没有 SQL 的 `WHERE`
    子句那么直观，但我们可以使用 `grep` 做到与 SQL `WHERE` 子句一样多，甚至更多。例如，假设我们只关心以数字 `3` 开头的账户：
- en: '[PRE4]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The following will be displayed on your screen:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 以下内容将显示在你的屏幕上：
- en: '![](img/b17384d7-b377-4f51-8776-1776fc96bf5a.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b17384d7-b377-4f51-8776-1776fc96bf5a.png)'
- en: Join, for joining data
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Join，连接数据
- en: Join works how an `INNER JOIN` might work in your SQL-style database. Two sorted
    files or streams are passed to the `join` command (see the section on sort to
    see how to `sort` your streams). The lines of the files must be sorted on the
    field you are attempting to join on. The `join` command will then output the results
    of the inner join on these two files, where if there's a matching field it will
    output the `join` key along with the remainder of the data lines of the first
    file concatenated with the second.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '`join`的工作原理类似于在 SQL 样式数据库中的`INNER JOIN`。两个已排序的文件或流被传递给`join`命令（参见排序部分，了解如何对流进行`sort`）。文件的行必须根据你想要连接的字段进行排序。`join`命令将输出这两个文件的内部连接结果，如果存在匹配字段，它将输出`join`键以及第一个文件的剩余数据行与第二个文件连接后的结果。'
- en: 'For example, say we would like to find users who are present both in the first
    review file and the second, and how many reviews they have in each. We can run
    the following `join` command:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 比如，我们想要查找同时出现在第一个和第二个评审文件中的用户，以及他们在每个文件中的评审数量。我们可以运行以下`join`命令：
- en: '[PRE5]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The preceding code produces these results:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码产生了以下结果：
- en: '![](img/4ee4b7a3-0e09-4690-b5e5-f56271cf9f5d.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4ee4b7a3-0e09-4690-b5e5-f56271cf9f5d.png)'
- en: Here, we're using process substitution to slice the review files' data. This
    is done in parallel, increasing the speed of the process.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用过程替代来切分评审文件的数据。这是并行执行的，能够提高处理速度。
- en: Group by and ordering
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 按组和排序
- en: 'We can perform a `GROUP BY` operation by using `sort` piped to `uniq -c` (as
    discussed in [Chapter 5](df05c890-510b-4e7e-8cc2-200f68f2febf.xhtml), *Loops,
    Functions, and String Processing*):'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过使用`sort`并管道连接到`uniq -c`来执行`GROUP BY`操作（如在[第5章](df05c890-510b-4e7e-8cc2-200f68f2febf.xhtml)，*循环、函数和字符串处理*中所讨论的）：
- en: '[PRE6]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The preceding code produces these results:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码产生了以下结果：
- en: '![](img/b7a2eabd-a1eb-48f2-b4f4-4ea27d0c84a7.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b7a2eabd-a1eb-48f2-b4f4-4ea27d0c84a7.png)'
- en: 'In the preceding example, we are simply counting how many reviews each user
    made. We might want to get the average review of each user, which can be done
    using `awk` associative arrays:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，我们只是简单地统计了每个用户提交了多少次评审。我们可能还希望获取每个用户的平均评审，这可以通过`awk`关联数组来完成：
- en: '[PRE7]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The preceding code produces these results:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码产生了以下结果：
- en: '![](img/937340b2-4a8b-4126-a4cc-48930c9c597d.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](img/937340b2-4a8b-4126-a4cc-48930c9c597d.png)'
- en: Here, the output of the command is the ID, the sum of the reviews, the count
    of the reviews, and the average review for each user.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，命令的输出是每个用户的ID、评审总数、评审数量和每个用户的平均评审。
- en: 'We can also sort the resulting data using the same tool, `sort`. For example,
    we can take our preceding `GROUP BY` example, and `ORDER BY` the number of reviews
    each user made to find the most prolific reviewers:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用相同的工具`sort`对结果数据进行排序。例如，我们可以使用前面的`GROUP BY`示例，并按每个用户提交的评审数量`ORDER BY`，以找到最多评审的用户：
- en: '[PRE8]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The preceding code produces these results:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码产生了以下结果：
- en: '![](img/c226f381-1029-4d67-ad2b-edee031027c1.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c226f381-1029-4d67-ad2b-edee031027c1.png)'
- en: The number of reviews each user made to find the most prolific reviewers
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 每个用户提交的评审数量，用于找到最多评审的用户
- en: Simulating selects
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模拟选择操作
- en: 'In the previous sections, we saw how to `SELECT` data, inner `JOIN` data, and
    even do `GROUP BY` and `ORDER BY` operations on flat files or streams of data.
    Rounding out the commonly-used operations, we can also create sub-selected tables
    of data by simply wrapping a set of calls into a stream and then processing them
    further. This is what we''ve been doing using the piping model, but to illustrate
    a point, say we wanted to sub-select out of the grouped-by reviews only those
    reviewers who had between `100` and `200` reviews. We can take the command in
    the preceding example and `awk` it once more:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的部分，我们已经看到如何在数据上执行`SELECT`、内连接`JOIN`，甚至对平面文件或数据流进行`GROUP BY`和`ORDER BY`操作。作为常用操作的补充，我们还可以通过简单地将一组调用包装成流并进一步处理它们，来创建子选择的数据表。这就是我们一直在通过管道模型执行的操作，但为了说明一个问题，假设我们想从按组汇总的评审中选择出那些评审数量在`100`到`200`之间的评审者。我们可以再次执行前面示例中的命令，并使用`awk`：
- en: '[PRE9]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The preceding code produces these results:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码产生了以下结果：
- en: '![](img/a1a328d6-07c8-486d-b271-fc58abeea197.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a1a328d6-07c8-486d-b271-fc58abeea197.png)'
- en: Sub-selecting out of the grouped-by reviews only those reviewers who had between
    100 and 200 reviews
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 从按组汇总的评审中选择出那些评审数量在100到200之间的评审者
- en: Using all of these tools, you saw how we can simulate most of the common SQL
    expressions on rows of file or stream data using the command line.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 利用这些工具，你已经看到了如何通过命令行模拟大部分常见的 SQL 表达式，针对文件或流数据的行进行操作。
- en: Keys to the kingdom
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 王国之钥
- en: Now that we can explore data with the command line and have mastered transforming
    text, we'll provide you with the keys to the kingdom. SQLite is a public domain
    library that implements a SQL engine and provides a `sqlite` command shell for
    interacting with database files. Unlike Oracle, MySQL, and other database engines
    that provide a network endpoint, sqlite is offline and locally driven by library
    calls to interact with a single file that is the entire database. This makes backups
    easy. Backups can be created by doing ``cp database.sq3 backups/`date +%F`-database.sq3``.
    One can version control it, but that's unlikely to compress well with delta comparisons.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经掌握了如何使用命令行探索数据并转换文本，我们将为你提供“王国之钥”。SQLite是一个公共领域库，实现了一个SQL引擎，并提供一个`sqlite`命令行工具，用于与数据库文件进行交互。与Oracle、MySQL和其他提供网络端点的数据库引擎不同，sqlite是离线的，通过库调用与一个单一的数据库文件进行交互。这使得备份变得非常简单。备份可以通过执行``cp
    database.sq3 backups/`date +%F`-database.sq3``来创建。可以对其进行版本控制，但使用增量比较时不太可能压缩得很好。
- en: Using SQLite
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用SQLite
- en: 'Easy import of CSV files (with custom delimiter):'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 简单导入CSV文件（支持自定义分隔符）：
- en: '[PRE10]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The data needs some massaging to get it into CSV format—it has a few problematic
    characters in the dataset – let''s use some shell hackery to make it uniform:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 数据需要一些处理才能转换为CSV格式——数据集中有一些有问题的字符——让我们用一些Shell技巧来使它统一：
- en: '[PRE11]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Show the tables by using the following command:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令显示表格：
- en: '[PRE12]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The preceding code shows the tables in the database:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的代码显示了数据库中的表格：
- en: '![](img/38620955-256e-4f22-9ad6-45c5b3355570.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![](img/38620955-256e-4f22-9ad6-45c5b3355570.png)'
- en: 'To show the datatypes for the table columns, run the following:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 要显示表格列的数据类型，请运行以下命令：
- en: '[PRE13]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The preceding code produces this output:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的代码生成了以下输出：
- en: '![](img/6544e972-38fc-465d-9cbf-1ba65f3a7be8.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6544e972-38fc-465d-9cbf-1ba65f3a7be8.png)'
- en: Showing the datatypes for the table columns
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 显示表格列的数据类型
- en: 'Load 20 lines of Amazon reviews into the sqlite database, named `reviews.sq3`,
    into the `aws_reviews` table:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 将20行亚马逊评论加载到名为`reviews.sq3`的sqlite数据库中的`aws_reviews`表格：
- en: '[PRE14]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: We read the first 21 lines. Our stream editor strips the first line (the header),
    escapes any double-quotes with a second pair of quotes (funky escaping, we know),
    and replaces the "tab" delimiter with a value separator that terminates the string
    and indicates it has a following element.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们读取了前21行。我们的流编辑器去除了第一行（表头），用一对双引号转义了所有的双引号（我们知道这有点奇怪），并将“tab”分隔符替换成一个值分隔符，该分隔符终止字符串并表示后面有一个元素。
- en: Then we convert the read `LINE` into our input `VALUES` by prepending a double-quote
    and appending a double-quote to finish properly formatting our values. Finally,
    our data is ready to insert into the table.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们通过在读取的`LINE`前后添加双引号，将其转换为输入的`VALUES`，以正确格式化数据。最终，我们的数据就准备好可以插入到表格中。
- en: Note that sqlite3 uses a second quote character as a quote-escape sequence,
    similar to using `%%` with `printf` to get a literal `%` character.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，sqlite3使用第二个引号字符作为引号转义序列，类似于使用`%%`与`printf`来获取字面意义上的`%`字符。
- en: 'Now we can query the data like any traditional database, because sqlite is
    a database engine in library form:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以像任何传统数据库一样查询数据，因为sqlite是以库的形式提供的数据库引擎：
- en: '[PRE15]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Math in bash itself
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Bash本身的数学运算
- en: Bash itself is able to do simple integer arithmetic. There are at least three
    different ways to accomplish this in bash.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: Bash本身能够执行简单的整数算术运算。在bash中至少有三种不同的方式来实现这一点。
- en: Using let
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用let
- en: 'You can use the let command to do simple bash arithmetic:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用`let`命令进行简单的bash算术运算：
- en: '[PRE16]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Basic arithmetic
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基本算术
- en: You can do addition, subtraction, multiplication (be sure to escape the `*`
    operator with `\*`) and integer division*:*
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以进行加法、减法、乘法（确保使用`\*`来转义`*`运算符）和整数除法*：*
- en: '[PRE17]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The numbers must be separated by spaces.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 数字必须由空格分隔。
- en: Double-parentheses
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 双括号
- en: 'Similar to let, you can do simple integer arithmetic in bash using doubled
    parentheses:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于`let`，你也可以使用双括号在bash中进行简单的整数算术运算：
- en: '[PRE18]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'To see the full range of operations available in the shell, check out the GNU
    reference page: [https://www.gnu.org/software/bash/manual/html_node/Shell-Arithmetic.html](https://www.gnu.org/software/bash/manual/html_node/Shell-Arithmetic.html).'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看Shell中可用的所有操作，请查看GNU参考页面：[https://www.gnu.org/software/bash/manual/html_node/Shell-Arithmetic.html](https://www.gnu.org/software/bash/manual/html_node/Shell-Arithmetic.html)。
- en: bc, the unix basic calculator
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: bc，Unix基本计算器
- en: '`bc` is a calculator scripting language. Scripts in `bc` can be executed with
    the `bc` command. Imagine a `test.bc` file contains the following code:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '`bc`是一个计算器脚本语言。可以通过`bc`命令执行`bc`脚本。假设一个`test.bc`文件包含以下代码：'
- en: '[PRE19]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'That means you can run `bc` like this:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着你可以像这样运行`bc`：
- en: '[PRE20]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '`bc` can do far more than just divide two numbers. It''s a fully-fledged scripting
    language on its own and you can do arbitrarily complex things with a `bc` script.
    A `bc` script might be the ending point of a pipeline of data, where, initially,
    the data files are massaged into a stream of data rows, and then a `bc` script
    is used to compute the values we''re looking for. Let''s illustrate this with
    a simple example.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '`bc`不仅仅能进行两个数字的除法计算。它本身是一个完全成熟的脚本语言，你可以通过`bc`脚本做任意复杂的事情。`bc`脚本可能是数据管道的终点，在此之前，数据文件已被处理成数据行流，然后通过`bc`脚本计算我们需要的数值。让我们通过一个简单的例子来说明这一点。'
- en: In this example, we need to take a CSV data file and compute the average of
    the second number in each row, and also compute the sum of the fourth number in
    each row. Say we have a `bc` function to compute something interesting on these
    two numbers, such as a harmonic mean. We can use `awk` to output the numbers into
    a `bc` script and then feed the result into `bc` using a pipe.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们需要处理一个CSV数据文件，计算每一行中第二个数字的平均值，并计算每一行中第四个数字的总和。假设我们有一个`bc`函数来计算这两个数字的某些有趣内容，比如调和均值。我们可以使用`awk`将这些数字输出到一个`bc`脚本中，然后通过管道将结果传递给`bc`。
- en: 'So, say our `bc` function to compute the harmonic mean of two numbers looks
    like this:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们计算两个数字调和均值的`bc`函数如下所示：
- en: '[PRE21]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'We can use `awk` to find the two numbers and construct the `bc` script, and
    then pipe it to `bc` to execute:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`awk`来找到这两个数字并构造`bc`脚本，然后通过管道传递给`bc`执行：
- en: '[PRE22]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: See the `bc` documentation at [https://www.gnu.org/software/bc/manual/html_mono/bc.html](https://www.gnu.org/software/bc/manual/html_mono/bc.html)
    for more things you could do with `bc`.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 详情请参见`bc`文档：[https://www.gnu.org/software/bc/manual/html_mono/bc.html](https://www.gnu.org/software/bc/manual/html_mono/bc.html)，了解更多你可以用`bc`做的事情。
- en: Math in (g)awk
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在(g)awk中的数学运算
- en: '`awk` (including the `gnu` implementation, `gawk`) is designed to stream text
    processing, data extraction, and reporting. A large percentage of practical statistics
    is made up of counting things in specific ways, and this is one of the things
    `awk` excels at. Tallying totals, histograms, and grouped counts are all very
    easy in `awk`.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '`awk`（包括`gnu`实现版本，`gawk`）旨在进行流式文本处理、数据提取和报告。大量实际统计学都涉及以特定方式计数，而这正是`awk`擅长的领域。统计总数、直方图和分组计数在`awk`中都非常容易实现。'
- en: 'An `awk` program is structured as a set of patterns that are matched, and actions
    to take when those patterns are matched:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 一个`awk`程序是由一组匹配的模式和在匹配这些模式时采取的动作组成的：
- en: '[PRE23]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: For each record (usually each line of text passed to `awk`), each pattern is
    tested to see whether the record matches, and if so, the action is taken. Additionally,
    each record is automatically split into a list of fields by a delimiter. The default
    action, if none is given, is to print the record. The default pattern is to match
    everything. There are two special patterns, `BEGIN` and `END`, which are matched
    only before any records are processed, or after, respectively.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每一条记录（通常是传递给`awk`的每一行文本），都会测试每个模式，看该记录是否匹配，如果匹配，则采取相应的动作。此外，每条记录会自动被分割成由分隔符组成的字段列表。如果没有给出动作，默认的动作是打印记录。默认的模式是匹配所有内容。有两个特殊的模式：`BEGIN`和`END`，分别只会在处理任何记录之前和之后匹配。
- en: 'The power of `awk` lies in its variables: variables can be used without a declaration.
    There''s some special variables already available to you that are useful for math:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '`awk`的强大之处在于它的变量：变量可以在不声明的情况下使用。已经有一些对数学运算有用的特殊变量可以供你使用：'
- en: '[PRE24]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Additionally, you can assign values to your own variables. `awk` natively supplies
    variables that can hold strings, integers, floating point numbers, and regular
    expressions and associative arrays.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，你可以将值分配给你自己的变量。`awk`本身提供了一些可以存储字符串、整数、浮动点数、正则表达式和关联数组的变量。
- en: 'As an example, say we want to count the word frequency in the reviews of our
    test data. Run this code:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设我们想要计算测试数据评论中的单词频率。运行以下代码：
- en: '[PRE25]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'It will produce these results:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 它将产生这些结果：
- en: '![](img/731421e3-4a37-4ed0-8f2b-bac5e8d90b95.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![](img/731421e3-4a37-4ed0-8f2b-bac5e8d90b95.png)'
- en: Counting the word frequency in the reviews of our test data
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 计算我们测试数据中评论的单词频率
- en: 'Say we''d like to compute a histogram of the star values of the reviews. This
    is also very easy with `awk`:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想要计算评论中星级的直方图。使用`awk`也非常简单：
- en: '[PRE26]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The preceding code produces this:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码会产生如下结果：
- en: '![](img/02dd2478-2f99-4129-bbae-36bc45a1d83d.png)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![](img/02dd2478-2f99-4129-bbae-36bc45a1d83d.png)'
- en: Computing a histogram of the star values of the reviews
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 计算评论的星级直方图
- en: We can see that four- and five-star reviews dominate this dataset.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，四星和五星评论在这个数据集中占主导地位。
- en: 'Besides counting, `awk` is also great for manipulating the format of strings:
    look back at [Chapter 5](df05c890-510b-4e7e-8cc2-200f68f2febf.xhtml), *Loops,
    Functions, and String Processing*, for some examples of using `awk` for string
    manipulation.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 除了计数，`awk`也非常适合处理字符串格式：可以回顾[第5章](df05c890-510b-4e7e-8cc2-200f68f2febf.xhtml)，*循环、函数和字符串处理*，查看一些使用`awk`进行字符串处理的示例。
- en: Python (pandas, numpy, scikit-learn)
  id: totrans-145
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Python（pandas、numpy、scikit-learn）
- en: Counting things often gets you to where you need to be, but sometimes more complex
    tools are required to do the job. Fortunately, we can write our own tools in the
    UNIX paradigm and use them in our workstream pipes along with our other command-line
    tools if we so desire.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 计数通常能帮助我们达到目标，但有时候需要更复杂的工具来完成任务。幸运的是，我们可以在UNIX范式下编写自己的工具，并将它们与其他命令行工具一起在工作流管道中使用。
- en: One such tool is python, along with popular data science libraries such as `pandas`,
    `numpy`, and `scikit-learn`. This isn't a text on all the great things those libraries
    can do for you (if you'd like to learn, a good place to start is the official
    python tutorial ([https://docs.python.org/3/tutorial/](https://docs.python.org/3/tutorial/))
    and the basics of Pandas data structures in the Pandas documentation ([https://pandas.pydata.org/pandas-docs/stable/basics.html](https://pandas.pydata.org/pandas-docs/stable/basics.html)).
    Make sure you have Python, `pip`, and `pandas` installed before you continue (see
    [Chapter 1](d26c5d26-6302-4b9d-b6ce-62b1ab13db0d.xhtml), *Data Science at the
    Command Line and Setting It Up*).
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一个工具是python，以及流行的数据科学库，如`pandas`、`numpy`和`scikit-learn`。这不是一篇介绍这些库能为你做的所有伟大事情的文章（如果你想学习，可以从官方的python教程（[https://docs.python.org/3/tutorial/](https://docs.python.org/3/tutorial/)）和Pandas文档中关于Pandas数据结构的基础知识（[https://pandas.pydata.org/pandas-docs/stable/basics.html](https://pandas.pydata.org/pandas-docs/stable/basics.html)）开始）。在继续之前，确保你已经安装了Python、`pip`和`pandas`（见[第1章](d26c5d26-6302-4b9d-b6ce-62b1ab13db0d.xhtml)，*命令行中的数据科学及其设置*）。
- en: 'If you want to connect your python program to a piped stream however, of course
    there are ways to do it. A simple method is to use the `sys` library. Say we have
    a small pandas program tuned to our dataset that computes the mean of a couple
    of the columns that we know are in the data:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果你想将python程序连接到管道流，当然也有方法可以实现。一种简单的方法是使用`sys`库。假设我们有一个小型的pandas程序，专门针对我们的数据集，它计算了我们知道的某些列的平均值：
- en: '[PRE27]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Note how we get the data directly from the `sys.stdin` stream and pass that
    right to pandas'' `read_csv` method (using tab as a separator). If we use this
    method, we can pipe the data right into the script:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 注意我们是如何直接从`sys.stdin`流中获取数据，并将其传递给pandas的`read_csv`方法（使用制表符作为分隔符）。如果使用这种方法，我们可以将数据直接传输到脚本中：
- en: '[PRE28]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The preceding code produces this output:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码会产生如下输出：
- en: '![](img/b437f3e9-be78-4c1b-b5be-21aff1aeaad3.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b437f3e9-be78-4c1b-b5be-21aff1aeaad3.png)'
- en: Analyzing weather data in bash
  id: totrans-154
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在bash中分析天气数据
- en: The National Weather Service has an API to get weather data: [https://forecast-v3.weather.gov/documentation](https://forecast-v3.weather.gov/documentation) .
    The API delivers forecast data over a lightweight HTTP interface. If you pass
    the correct URL and parameters to the web endpoint, the service will return JSON-formatted
    weather data. Let's take a look at an example of some data exploration we can
    do with this rich dataset.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 美国国家气象局提供了一个API来获取天气数据：[https://forecast-v3.weather.gov/documentation](https://forecast-v3.weather.gov/documentation)。该API通过轻量级的HTTP接口提供天气预报数据。如果你将正确的URL和参数传递给Web端点，服务将返回JSON格式的天气数据。让我们看一下可以利用这个丰富数据集进行数据探索的一个示例。
- en: The NWS provides both current weather data and forecasts. Let's say I'd like
    to see just how accurate NWS forecasts are. I'd like to do this over some amount
    of time, say a week. I'd like to save tomorrow's forecast, and then later on,
    compare those forecasts to what the temperature really was. For this example,
    let's look at the forecast highs, and the actual high temperatures. I'd like to
    do this for a single point in lat-lon.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: NWS提供当前天气数据和预报。假设我想看NWS的预报准确性。我想在一段时间内查看，比如一周。我想保存明天的预报，然后稍后将这些预报与实际温度进行比较。对于这个示例，让我们看一下预报的高温和实际的最高温度。我希望对某个单一的经纬度点进行操作。
- en: Our overall plan will be to record the forecasts for the next day's high temperatures
    once a day in a CSV file. Once an hour, we'll record the actual temperature in
    another CSV file. Then, we'll write a script that compares these two files and
    computes the accuracy of each type of forecast (one-day forecast, two-day forecast,
    and so on) over multiple days.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的总体计划是每天记录明天的最高温度预报，并将其保存到CSV文件中。每小时，我们将记录实际温度，并保存到另一个CSV文件中。接着，我们将编写一个脚本，比较这两个文件，并计算每种预报类型（一天预报、两天预报等）在多天内的准确性。
- en: 'First, we need to be able to query the right endpoint in the API. The weather
    service data is gridded into a set of grid locations. To find the grid for a particular
    lat-lon point, we can query the API:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要能够查询API中的正确端点。天气服务数据被分成一组网格位置。为了找到特定经纬度点的网格，我们可以查询API：
- en: '[PRE29]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Querying the API returns the following:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 查询API返回以下结果：
- en: '[PRE30]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'There''s a lot of extraneous information in JSON, when we really only want
    the grid coordinates and the forecast region. Let''s use the `jq` UNIX tool to
    parse this JSON and extract the relevant information:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: JSON中包含了大量不必要的信息，而我们实际上只需要网格坐标和预报区域。让我们使用`jq`这个UNIX工具来解析这个JSON，并提取相关信息：
- en: '[PRE31]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The relevant information looks like this:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 相关信息如下所示：
- en: '![](img/737ef681-b54a-48c8-931d-5ff08789a98d.png)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![](img/737ef681-b54a-48c8-931d-5ff08789a98d.png)'
- en: 'Here, we''ve used `jq` to parse and format a bit of text that we could then
    insert into a URL, which we can re-curl for the forecast. Helpfully, however,
    the API actually gives us the entire URL of the forecast inside the JSON, in the
    `properties.forecastGridData` feature:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用了`jq`来解析和格式化一部分文本，随后我们可以将其插入到一个URL中，然后再次使用`curl`请求该URL以获取天气预报。然而，API实际上会在JSON中的`properties.forecastGridData`特性内直接提供完整的预报URL：
- en: '[PRE32]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The preceding code produces this output:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码产生了如下输出：
- en: '[PRE33]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'We''re going to take this URL, `curl` it into `jq` again, and extract the high
    temperature forecasts for the next day. Using `jq`, we''re going to format these
    into a CSV line that we''ll later on append to our flat file data table. For this
    example, we''re going to ignore time zones, and assume days start and end on Zulu
    time. Run this code:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将获取这个URL，再次用`curl`请求它，并提取第二天的高温预报。使用`jq`，我们将把这些预报格式化为CSV行，之后将它们附加到我们的平面数据表中。对于这个示例，我们将忽略时区，并假设每天从Zulu时间开始和结束。运行此代码：
- en: '[PRE34]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'It produces the following output:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 它产生了如下输出：
- en: '[PRE35]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: The output will be different since you're running this after 2018-06-22.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 由于你是在2018-06-22之后运行此操作，输出将会有所不同。
- en: 'Looks great! Save this command as is to a bash script, say `forecast.sh`, using
    the editor of your choice. Be sure to make the script executable with the `chmod`
    command:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来不错！将这个命令按原样保存为bash脚本，命名为`forecast.sh`，并使用你喜欢的编辑器。确保使用`chmod`命令使脚本可执行：
- en: '[PRE36]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'And let''s `cat` the file to view the contents:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 然后让我们使用`cat`命令查看文件内容：
- en: '[PRE37]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Let''s add this to a cron[1] task and run this once a day at noon, and append
    the resulting line to a `.csv` file. Cron is a system utility that will run a
    command on a schedule. The schedules look something like this:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将这个添加到一个cron[1]任务中，并每天中午运行一次，将结果行附加到`.csv`文件中。Cron是一个系统工具，用于定时运行命令。定时任务的格式大致如下：
- en: '[PRE38]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'So, if we''d like to run this once a day, we want to run it on a particular
    minute of a particular hour, but on every day, month, and day of week giving the
    following cron pattern, if say, we''d like to run at noon every day:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果我们希望每天运行此任务，我们需要在某个特定小时的某个特定分钟执行它，但这需要每天、每月和每周的所有日期运行，给出如下的cron模式，例如，如果我们希望每天中午执行一次：
- en: '[PRE39]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'To add a script to cron''s list, the `crontab` you''ll need to run the command:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 要将脚本添加到cron的任务列表中，你需要运行以下命令：
- en: '[PRE40]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Add the following line to your `crontab`:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 将以下行添加到你的`crontab`中：
- en: '[PRE41]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Now, every day the forecast will be appended to the file you specified.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，每天的预报将会被附加到你指定的文件中。
- en: 'To get the current weather data, we need to find the closest weather station
    to our gridpoint:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取当前天气数据，我们需要找到最接近我们网格点的天气站：
- en: '[PRE42]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'The preceding code produces this output:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码生成了这个输出：
- en: '[PRE43]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'The current weather is located at the following API point:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 当前天气位于以下API点：
- en: '[PRE44]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'From this API point, we can grab a timestamp and current temperature:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个API点，我们可以获取时间戳和当前温度：
- en: '[PRE45]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Add this to a script file, and to your crontab as well, set to run every hour.
    To do this, we need to specify a minute but wildcard everything else in the cron
    pattern:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 将此添加到脚本文件中，并且也添加到您的crontab中，设置为每小时运行。为此，我们需要指定一个分钟，但在cron模式中通配其他所有内容：
- en: '[PRE46]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: We let this run for a couple of weeks to build our dataset.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 我们让这个运行几个星期来构建我们的数据集。
- en: 'Now, we want to take the maximum temperature we record each day, join that
    to the forecast we recorded for that day, and compute the difference. To find
    the max temperature for any given day, we can once again use `gawk`:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们想要每天记录的最高温度，将其与该日的预测记录结合，并计算差异。要找到任意给定日期的最高温度，我们可以再次使用`gawk`：
- en: '[PRE47]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Then, we can join this result back to our forecasts. Since the output is already
    sorted by date in a sortable YYYY-MM-DD order, we don''t need to pre-sort. Run
    the following:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以将这个结果与我们的预测结果合并。由于输出已按日期以可排序的YYYY-MM-DD顺序排序，我们无需预先排序。运行以下命令：
- en: '[PRE48]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'The preceding code produces the following output:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码生成了以下输出：
- en: '[PRE49]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'And we can pipe this stream to `awk` to compute the difference between the
    actual and predicted temperatures:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将这个流传输到`awk`中，以计算实际温度和预测温度之间的差异：
- en: '[PRE50]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'The preceding code results in the following:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码导致以下结果：
- en: '[PRE51]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: We grabbed real data from the Internet, massaged it using a workflow, stored
    it into files, and computed numeric values with the data in the tables we made!
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从互联网获取了真实数据，使用工作流程加工它，将其存储到文件中，并使用表中的数据计算数值！
- en: Summary
  id: totrans-210
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we used `cut`, `grep`, `awk`, and `sort` to deeply inspect
    our data, as one would in a more traditional database. We then saw how sqlite
    can provide a lightweight alternative to other databases. Using these tools together,
    we were able to mine useful knowledge from our raw files.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们使用了`cut`、`grep`、`awk`和`sort`来深入检查我们的数据，就像在传统数据库中一样。然后我们看到sqlite可以作为其他数据库的轻量级替代品。将这些工具结合使用，我们能够从我们的原始文件中挖掘出有用的知识。
- en: We also saw how the command line offers several options for doing arithmetic
    and other mathematical operations. Simple arithmetic and grouped tallies can be
    performed using bash itself or `awk`. More complex mathematics can be done using
    a scripting language, such as `bc` or python, and be called like other command-line
    workflow tools.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还看到命令行提供了几种选项来执行算术和其他数学运算。可以使用bash本身或`awk`执行简单的算术和分组计数。使用脚本语言（如`bc`或Python）可以进行更复杂的数学运算，并像其他命令行工作流工具一样调用。
- en: Finally, we used many of the tools we discussed to produce a useful and interesting
    result from publicly-available data.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们使用了我们讨论过的许多工具，从公开可用的数据中产生了一个有用且有趣的结果。
- en: We hope that this book broadens your understanding of just how powerful the
    command line actually is, especially for data science. However, this is only the
    very beginning. There's a number of tools and other commands we haven't even mentioned,
    which are very powerful and deserve to be mentioned. `BashHTTPD` ([https://github.com/avleen/bashttpd](https://github.com/avleen/bashttpd))
    is a web server in bash; it may sound silly, but the shell can really do amazing
    things. `BashReduce` ([https://github.com/erikfrey/bashreduce](https://github.com/erikfrey/bashreduce))
    gives the user the ability to run bash commands over multiple machines/cores.
    You might have noticed some of the commands took a little while to run. We recommend
    taking a look at `BashReduce` to speed things up. Those who are familiar with
    the `MapReduce` concept should have no issue picking up and working with `BashReduce`.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望这本书能够拓宽您对命令行实际上有多强大的理解，特别是对于数据科学。然而，这只是一个开始。还有一些我们甚至没有提到的工具和其他命令，它们非常强大，值得一提。`BashHTTPD`
    ([https://github.com/avleen/bashttpd](https://github.com/avleen/bashttpd)) 是一个bash中的Web服务器；听起来可能有些愚蠢，但shell确实可以做一些令人惊讶的事情。`BashReduce`
    ([https://github.com/erikfrey/bashreduce](https://github.com/erikfrey/bashreduce))
    给用户提供了在多台机器/核心上运行bash命令的能力。您可能已经注意到其中一些命令运行起来有点慢。我们建议您看看`BashReduce`来加快速度。那些熟悉`MapReduce`概念的人应该没有问题使用`BashReduce`。
- en: We also want to mention that there are so many other great command-line tools
    out there; we could write about them forever. However, for this book, we decided
    to focus on the everyday commands and provide examples on how to use them. We
    hope you enjoyed this book!
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还想提到，外面有许多其他优秀的命令行工具；我们可以一直写下去。然而，对于本书，我们决定专注于日常命令，并提供如何使用它们的示例。希望你喜欢这本书！
