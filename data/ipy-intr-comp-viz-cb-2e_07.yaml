- en: Chapter 7. Statistical Data Analysis
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第7章。统计数据分析
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Exploring a dataset with pandas and matplotlib
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用pandas和matplotlib探索数据集
- en: Getting started with statistical hypothesis testing – a simple z-test
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开始进行统计假设检验——简单的z检验
- en: Getting started with Bayesian methods
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开始使用贝叶斯方法
- en: Estimating the correlation between two variables with a contingency table and
    a chi-squared test
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用列联表和卡方检验估计两个变量之间的相关性
- en: Fitting a probability distribution to data with the maximum likelihood method
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用最大似然法拟合数据的概率分布
- en: Estimating a probability distribution nonparametrically with a kernel density
    estimation
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用核密度估计法非参数地估计概率分布
- en: Fitting a Bayesian model by sampling from a posterior distribution with a Markov
    chain Monte Carlo method
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过马尔可夫链蒙特卡洛方法从后验分布中抽样拟合贝叶斯模型
- en: Analyzing data with the R programming language in the IPython notebook
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在IPython笔记本中使用R编程语言分析数据
- en: Introduction
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: In the previous chapters, we reviewed technical aspects of high-performance
    interactive computing in Python. We now begin the second part of this book by
    illustrating a variety of scientific questions that can be tackled with Python.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们回顾了Python中高性能交互式计算的技术方面。现在，我们开始本书的第二部分，展示可以使用Python解决的各种科学问题。
- en: In this chapter, we introduce statistical methods for data analysis. In addition
    to covering statistical packages such as pandas, statsmodels, and PyMC, we will
    explain the basics of the underlying mathematical principles. Therefore, this
    chapter will be most profitable if you have basic experience with probability
    theory and calculus.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了用于数据分析的统计方法。除了涉及诸如pandas、statsmodels和PyMC等统计包外，我们还将解释这些方法背后的数学原理基础。因此，如果你有一定的概率论和微积分基础，本章将会最有益。
- en: The next chapter, [Chapter 8](ch08.html "Chapter 8. Machine Learning"), *Machine
    Learning*, is closely related; the underlying mathematics is very similar, but
    the goals are slightly different. In this chapter, we show how to gain insight
    into real-world data and how to make informed decisions in the presence of uncertainty.
    In the next chapter, the goal is to *learn from data*, that is, to generalize
    and to predict outcomes from partial observations.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章，[第8章](ch08.html "第8章。机器学习")，*机器学习*，与本章密切相关；其基础数学非常相似，但目标略有不同。在本章中，我们展示了如何从现实世界数据中获得洞见，以及如何在不确定性面前做出明智的决策。而在下一章，目标是*从数据中学习*，即从部分观察中进行归纳和预测结果。
- en: In this introduction, we will give a broad, high-level overview of the methods
    we will see in this chapter.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在本引言中，我们将对本章中所涉及的方法进行广泛的、高层次的概述。
- en: What is statistical data analysis?
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是统计数据分析？
- en: The goal of statistical data analysis is to understand a complex, real-world
    phenomenon from partial and uncertain observations. The uncertainty in the data
    results in uncertainty in the knowledge we get about the phenomenon. A major goal
    of the theory is to *quantify* this uncertainty.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 统计数据分析的目标是从部分和不确定的观察中理解复杂的现实现象。数据中的不确定性导致我们对现象的知识也存在不确定性。理论的主要目标是*量化*这种不确定性。
- en: It is important to make the distinction between the mathematical theory underlying
    statistical data analysis, and the decisions made after conducting an analysis.
    The former is perfectly rigorous; perhaps surprisingly, mathematicians were able
    to build an exact mathematical framework to deal with uncertainty. Nevertheless,
    there is a subjective part in the way statistical analysis yields actual human
    decisions. Understanding the risk and the uncertainty behind statistical results
    is critical in the decision-making process.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行统计数据分析时，重要的是区分数学理论与分析后做出的决策。前者是完美严谨的；或许令人惊讶的是，数学家们能够建立一个精确的数学框架来处理不确定性。然而，统计分析得出的实际人类决策中有主观的部分。在决策过程中，理解统计结果背后的风险和不确定性至关重要。
- en: In this chapter, we will see the basic notions, principles, and theories behind
    statistical data analysis, covering in particular how to make decisions with a
    quantified risk. Of course, we will always show how to implement these methods
    with Python.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将看到统计数据分析背后的基本概念、原则和理论，特别是如何在量化风险的情况下做出决策。当然，我们将始终展示如何使用Python实现这些方法。
- en: A bit of vocabulary
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一些术语
- en: There are many terms that need introduction before we get started with the recipes.
    These notions allow us to classify statistical techniques within multiple dimensions.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始这些食谱之前，有许多术语需要介绍。这些概念使我们能够在多个维度上对统计技术进行分类。
- en: Exploration, inference, decision, and prediction
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 探索、推断、决策和预测
- en: '**Exploratory methods** allow us to get a preliminary look at a dataset through
    basic statistical aggregates and interactive visualization. We covered these basic
    methods in the first chapter of this book and in the book *Learning IPython for
    Interactive Computing and Data Visualization*, *Packt Publishing*. The first recipe
    of this chapter, *Exploring a dataset with pandas and matplotlib*, shows another
    example.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**探索性方法** 使我们能够通过基本的统计聚合和交互式可视化对数据集进行初步查看。我们在本书的第一章以及《学习 IPython 用于交互式计算和数据可视化》一书（*Packt
    Publishing*）中介绍了这些基本方法。本章的第一条食谱，*使用 pandas 和 matplotlib 探索数据集*，展示了另一个例子。'
- en: '**Statistical inference** consists of getting information about an unknown
    process through partial and uncertain observations. In particular, **estimation**
    entails obtaining approximate quantities for the mathematical variables describing
    this process. Three recipes in this chapter deal with statistical inference:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**统计推断** 是通过部分和不确定的观察获取关于未知过程的信息。特别地，**估计** 是指为描述该过程的数学变量获得近似值。本章的三条食谱涉及统计推断：'
- en: The *Fitting a probability distribution to data with the maximum likelihood
    method* recipe
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*通过最大似然法拟合概率分布* 食谱'
- en: The *Estimating a probability distribution nonparametrically with a kernel density
    estimation* recipe
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*通过核密度估计非参数地估计概率分布* 食谱'
- en: The *Fitting a Bayesian model by sampling from a posterior distribution with
    a Markov chain Monte Carlo method* recipe
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*通过从后验分布中采样来拟合贝叶斯模型，使用马尔可夫链蒙特卡罗方法* 食谱'
- en: '**Decision theory** allows us to make decisions about an unknown process from
    random observations, with a controlled risk. The following two recipes show how
    to make statistical decisions:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**决策理论** 使我们能够通过随机观察在可控风险下对未知过程做出决策。以下两条食谱展示了如何做出统计决策：'
- en: 'The *Getting started with statistical hypothesis testing: a simple z-test*
    recipe'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*开始进行统计假设检验：简单的 z 检验* 食谱'
- en: The *Estimating the correlation between two variables with a contingency table
    and a chi-squared test* recipe
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*通过列联表和卡方检验估计两个变量之间的相关性* 食谱'
- en: '**Prediction** consists of learning from data, that is, predicting the outcomes
    of a random process based on a limited number of observations. This is the topic
    of the next chapter, [Chapter 8](ch08.html "Chapter 8. Machine Learning"), *Machine
    Learning*.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**预测** 是指从数据中学习，即根据有限的观察预测随机过程的结果。这是下章的主题，[第 8 章](ch08.html "第 8 章：机器学习")，*机器学习*。'
- en: Univariate and multivariate methods
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 单变量和多变量方法
- en: 'In most cases, you can consider two dimensions in your data:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数情况下，你可以考虑数据中的两个维度：
- en: '**Observations** (or **samples**, for machine learning people)'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**观察值**（或 **样本**，对于机器学习人员）'
- en: '**Variables** (or **features**)'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**变量**（或 **特征**）'
- en: Typically, observations are independent realizations of the same random process.
    Each observation is made of one or several variables. Most of the time, variables
    are either numbers, or elements belonging to a finite set (that is, taking a finite
    number of values). The first step in an analysis is to understand what your observations
    and variables are.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，观察值是同一随机过程的独立实现。每个观察值由一个或多个变量组成。大多数时候，变量要么是数字，要么是属于有限集合的元素（即取有限数量的值）。分析的第一步是理解你的观察值和变量是什么。
- en: Your problem is **univariate** if you have one variable. It is **bivariate**
    if you have two variables and **multivariate** if you have at least two variables.
    Univariate methods are typically simpler. That being said, univariate methods
    may be used on multivariate data, using one dimension at a time. Although interactions
    between variables cannot be explored in that case, it is often an interesting
    first approach.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有一个变量，则你的问题是 **单变量**。如果你有两个变量，则是 **双变量**，如果你至少有两个变量，则是 **多变量**。单变量方法通常较为简单。话虽如此，单变量方法也可以应用于多变量数据，每次使用一个维度。尽管这种方法无法探索变量之间的相互作用，但它通常是一个有趣的初步方法。
- en: Frequentist and Bayesian methods
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 频率学派和贝叶斯方法
- en: There are at least two different ways of considering uncertainty, resulting
    in two different classes of methods for inference, decision, and other statistical
    questions. These are called **frequentist and** **Bayesian methods**. Some people
    prefer frequentist methods, while others prefer Bayesian methods.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 至少有两种不同的方式来考虑不确定性，从而产生两类用于推断、决策和其他统计问题的方法。它们分别被称为**频率派方法**和**贝叶斯方法**。一些人偏好频率派方法，而另一些人则偏好贝叶斯方法。
- en: Frequentists interpret a probability as a **statistical average** across many
    independent realizations (law of large numbers). Bayesians interpret it as a **degree
    of belief** (no need for many realizations). The Bayesian interpretation is very
    useful when only a single trial is considered. In addition, Bayesian theory takes
    into account our **prior knowledge** about a random process. This prior probability
    distribution is updated into a posterior distribution as we get more and more
    data.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 频率派解释概率为多个独立试验的**统计平均**（大数法则）。贝叶斯派则解释为**信念程度**（不需要多个试验）。贝叶斯解释在只考虑单次试验时非常有用。此外，贝叶斯理论还考虑了我们对随机过程的**先验知识**。随着数据的增加，先验概率分布会被更新为后验分布。
- en: Both frequentist and Bayesian methods have their advantages and disadvantages.
    For instance, one could say that frequentist methods might be easier to apply
    than Bayesian methods, but more difficult to interpret. For classic misuses of
    frequentist methods, see [www.refsmmat.com/statistics/](http://www.refsmmat.com/statistics/).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 频率派和贝叶斯派方法各有其优缺点。例如，有人可能会说，频率派方法比贝叶斯方法更容易应用，但解释起来更为困难。有关频率派方法的经典误用，见[www.refsmmat.com/statistics/](http://www.refsmmat.com/statistics/)。
- en: In any case, if you are a beginner in statistical data analysis, you probably
    want to learn the basics of both approaches before choosing sides. This chapter
    introduces you to both types of methods.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 无论如何，如果你是统计数据分析的初学者，你可能希望在选择立场之前学习这两种方法的基础知识。本章将向你介绍这两种方法。
- en: 'The following recipes are exclusively Bayesian:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 以下的配方完全是贝叶斯方法：
- en: The *Getting started with Bayesian methods* recipe
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*入门贝叶斯方法*配方'
- en: The *Fitting a Bayesian model by sampling from a posterior distribution with
    a Markov chain Monte Carlo method* recipe
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*通过马尔可夫链蒙特卡洛方法从后验分布中采样拟合贝叶斯模型*配方'
- en: Jake Vanderplas has written several blog posts about frequentism and Bayesianism,
    with examples in Python. The first post of the series is available at [http://jakevdp.github.io/blog/2014/03/11/frequentism-and-bayesianism-a-practical-intro/](http://jakevdp.github.io/blog/2014/03/11/frequentism-and-bayesianism-a-practical-intro/).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: Jake Vanderplas曾写过几篇关于频率派和贝叶斯派的博客文章，并且在文章中提供了Python的示例。该系列的第一篇文章可以在[http://jakevdp.github.io/blog/2014/03/11/frequentism-and-bayesianism-a-practical-intro/](http://jakevdp.github.io/blog/2014/03/11/frequentism-and-bayesianism-a-practical-intro/)找到。
- en: Parametric and nonparametric inference methods
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 参数化和非参数化推断方法
- en: In many cases, you base your analysis on a **probabilistic model**. This model
    describes how your data is generated. A probabilistic model has no reality; it
    is only a mathematical object that guides you in your analysis. A good model can
    be helpful, whereas a bad model may misguide you.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多情况下，你会基于**概率模型**来进行分析。该模型描述了你的数据是如何生成的。概率模型并没有实际存在；它仅是一个数学对象，指导你进行分析。一个好的模型是有帮助的，而一个不好的模型可能会误导你。
- en: With a **parametric method**, you assume that your model belongs to a known
    family of probability distributions. The model has one or multiple numerical *parameters*
    that you can *estimate*.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 使用**参数化方法**时，你假设你的模型属于一个已知的概率分布族。该模型有一个或多个数值的*参数*，你可以对其进行*估计*。
- en: With a **nonparametric model**, you do not make such an assumption in your model.
    This gives you more flexibility. However, these methods are typically more complicated
    to implement and to interpret.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 使用**非参数化模型**时，你的模型不需要做出这样的假设。这给你带来了更多的灵活性。然而，这些方法通常实现起来更为复杂，且难以解释。
- en: 'The following recipes are parametric and nonparametric, respectively:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 以下配方分别是参数化和非参数化的：
- en: The *Fitting a probability distribution to data with the maximum likelihood
    method* recipe
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用最大似然法拟合概率分布*配方'
- en: The *Estimating a probability distribution nonparametrically with a kernel density
    estimation* recipe
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用核密度估计非参数化估计概率分布*配方'
- en: 'This chapter only gives you an idea of the wide range of possibilities that
    Python offers for statistical data analysis. You can find many books and online
    courses that cover statistical methods in much greater detail, such as:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 本章仅为你提供了 Python 在统计数据分析方面广泛可能性的一个大致概念。你可以找到许多书籍和在线课程，详细讲解统计方法，例如：
- en: Statistics on WikiBooks at [http://en.wikibooks.org/wiki/Statistics](http://en.wikibooks.org/wiki/Statistics)
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 维基教科书上的统计学内容：[http://en.wikibooks.org/wiki/Statistics](http://en.wikibooks.org/wiki/Statistics)
- en: Free statistical textbooks available at [http://stats.stackexchange.com/questions/170/free-statistical-textbooks](http://stats.stackexchange.com/questions/170/free-statistical-textbooks)
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 免费的统计学教材可以在 [http://stats.stackexchange.com/questions/170/free-statistical-textbooks](http://stats.stackexchange.com/questions/170/free-statistical-textbooks)
    找到
- en: Exploring a dataset with pandas and matplotlib
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 pandas 和 matplotlib 探索数据集
- en: In this first recipe, we will show how to conduct a preliminary analysis of
    a dataset with pandas. This is typically the first step after getting access to
    the data. pandas lets us load the data very easily, explore the variables, and
    make basic plots with matplotlib.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在这第一个食谱中，我们将展示如何使用 pandas 对数据集进行初步分析。这通常是在获得数据后进行的第一步。pandas 让我们能够非常轻松地加载数据、探索变量，并使用
    matplotlib 创建基本的图表。
- en: We will take a look at a dataset containing all ATP matches played by four tennis
    players until 2012\. Here, we will focus on Roger Federer.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将查看一个数据集，该数据集包含了四名网球选手直到 2012 年为止的所有 ATP 比赛。在这里，我们将重点关注罗杰·费德勒。
- en: Getting ready
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: Download the *Tennis* dataset from the book's GitHub repository at [https://github.com/ipython-books/cookbook-data](https://github.com/ipython-books/cookbook-data),
    and extract it to the current directory.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 从本书的 GitHub 仓库 [https://github.com/ipython-books/cookbook-data](https://github.com/ipython-books/cookbook-data)
    下载 *Tennis* 数据集，并将其解压到当前目录。
- en: How to do it...
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'We import NumPy, pandas, and matplotlib:'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们导入 NumPy、pandas 和 matplotlib：
- en: '[PRE0]'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The dataset is a CSV file, that is, a text file with comma-separated values.
    pandas lets us load this file with a single function:'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据集是一个 CSV 文件，即一个以逗号分隔值的文本文件。pandas 让我们能够用一个函数加载这个文件：
- en: '[PRE1]'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We can have a first look at this dataset by just displaying it in the IPython
    notebook:'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以通过在 IPython 笔记本中直接显示数据集来进行首次查看：
- en: '[PRE2]'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'There are many columns. Each row corresponds to a match played by Roger Federer.
    Let''s add a Boolean variable indicating whether he has won the match or not.
    The `tail()` method displays the last rows of the column:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据集有很多列。每一行对应罗杰·费德勒的一场比赛。我们来添加一个布尔变量，表示他是否赢得了比赛。`tail()` 方法显示列的最后几行：
- en: '[PRE3]'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '`df[''win'']` is a `Series` object. It is very similar to a NumPy array, except
    that each value has an index (here, the match index). This object has a few standard
    statistical functions. For example, let''s look at the proportion of matches won:'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`df[''win'']` 是一个 `Series` 对象。它与 NumPy 数组非常相似，只是每个值都有一个索引（这里是比赛索引）。这个对象具有一些标准的统计函数。例如，让我们查看获胜比赛的比例：'
- en: '[PRE4]'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Now, we are going to look at the evolution of some variables across time. The
    `df[''start date'']` field contains the start date of the tournament as a string.
    We can convert the type to a date type using the `pd.to_datetime()` function:'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将观察一些变量随时间的变化。`df['start date']` 字段包含了比赛的开始日期，格式为字符串。我们可以使用 `pd.to_datetime()`
    函数将其转换为日期类型：
- en: '[PRE5]'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: We are now looking at the proportion of double faults in each match (taking
    into account that there are logically more double faults in longer matches!).
    This number is an indicator of the player's state of mind, his level of self-confidence,
    his willingness to take risks while serving, and other parameters.
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在正在查看每场比赛中的双误比例（考虑到在更长时间的比赛中，双误通常更多！）。这个数字是球员心理状态的一个指标，反映了他的自信水平、在发球时的冒险精神以及其他一些参数。
- en: '[PRE6]'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: We can use the `head()` and `tail()` methods to take a look at the beginning
    and the end of the column, and `describe()` to get summary statistics. In particular,
    let's note that some rows have NaN values (that is, the number of double faults
    is not available for all matches).
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以使用 `head()` 和 `tail()` 方法查看列的开头和结尾，并使用 `describe()` 获取摘要统计数据。特别地，我们需要注意，有些行包含
    NaN 值（即，并不是所有比赛的双误数据都有记录）。
- en: '[PRE7]'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'A very powerful feature in pandas is `groupby()`. This function allows us to
    group together rows that have the same value in a particular column. Then, we
    can aggregate this group by value to compute statistics in each group. For instance,
    here is how we can get the proportion of wins as a function of the tournament''s
    surface:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: pandas中的一个非常强大的功能是`groupby()`。这个函数允许我们将具有相同列值的行组合在一起。然后，我们可以通过该值对该组进行聚合，计算每个组中的统计数据。例如，下面是我们如何根据比赛场地表面类型来获取胜利比例：
- en: '[PRE8]'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Now, we are going to display the proportion of double faults as a function
    of the tournament date, as well as the yearly average. To do this, we also use
    `groupby()`:'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将显示双误差的比例与比赛日期的关系，以及每年的平均值。为此，我们也使用`groupby()`：
- en: '[PRE9]'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '`gb` is a `GroupBy` instance. It is similar to a `DataFrame` object, but there
    are multiple rows per group (all matches played in each year). We can aggregate
    these rows using the `mean()` operation. We use the matplotlib `plot_date()` function
    because the x-axis contains dates:'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`gb`是一个`GroupBy`实例。它类似于`DataFrame`对象，但每个组中有多行（每年比赛的所有场次）。我们可以使用`mean()`操作对这些行进行聚合。我们使用matplotlib的`plot_date()`函数，因为x轴包含日期：'
- en: '[PRE10]'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '![How to do it...](img/4818OS_07_01.jpg)'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![如何实现...](img/4818OS_07_01.jpg)'
- en: There's more...
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: pandas is an excellent tool for data wrangling and exploratory analysis. pandas
    accepts all sorts of formats (text-based, and binary files) and it lets us manipulate
    tables in many ways. In particular, the `groupby()` function is extremely powerful.
    This library is covered in much greater detail in a book by Wes McKinney, *Python
    for Data Analysis*.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: pandas是一个用于数据整理和探索性分析的优秀工具。pandas支持各种格式（文本格式和二进制文件），并允许我们以多种方式操作表格。特别是，`groupby()`函数非常强大。Wes
    McKinney的《*Python for Data Analysis*》一书对这个库进行了更为详细的讲解。
- en: What we covered here is only the first step in a data-analysis process. We need
    more advanced statistical methods to obtain reliable information about the underlying
    phenomena, make decisions and predictions, and so on. This is the topic of the
    following recipes.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里所讲述的仅仅是数据分析过程中的第一步。我们需要更高级的统计方法来获得关于基础现象的可靠信息，做出决策和预测，等等。这个内容将在接下来的章节中讨论。
- en: In addition, more complex datasets demand more sophisticated analysis methods.
    For example, digital recordings, images, sounds, and videos require specific signal
    processing treatments before we can apply statistical techniques. These questions
    will be covered in subsequent chapters.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，更复杂的数据集需要更复杂的分析方法。例如，数字记录、图像、声音和视频在应用统计技术之前需要特定的信号处理处理。这些问题将在后续章节中讨论。
- en: Getting started with statistical hypothesis testing – a simple z-test
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开始统计假设检验——一个简单的z检验
- en: '**Statistical hypothesis testing** allows us to make decisions in the presence
    of incomplete data. By definition, these decisions are uncertain. Statisticians
    have developed rigorous methods to evaluate this risk. Nevertheless, some subjectivity
    is always involved in the decision-making process. The theory is just a tool that
    helps us make decisions in an uncertain world.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '**统计假设检验**使我们能够在数据不完全的情况下做出决策。根据定义，这些决策是有不确定性的。统计学家已经开发了严格的方法来评估这种风险。然而，决策过程中总是涉及一些主观性。理论只是帮助我们在不确定的世界中做出决策的工具。'
- en: 'Here, we introduce the most basic ideas behind statistical hypothesis testing.
    We will follow an extremely simple example: coin tossing. More precisely, we will
    show how to perform a **z-test**, and we will briefly explain the mathematical
    ideas underlying it. This kind of method (also called the *frequentist method*),
    although widely used in science, is subject to many criticisms. We will show later
    a more modern approach based on Bayesian theory. It is very helpful to understand
    both approaches, because many studies and publications still follow frequentist
    methods.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们介绍统计假设检验背后的最基本思想。我们将跟随一个极其简单的例子：抛硬币。更准确地说，我们将展示如何进行**z检验**，并简要解释其背后的数学思想。这种方法（也称为*频率主义方法*）尽管在科学中被广泛使用，但也受到了许多批评。稍后我们将展示一种基于贝叶斯理论的更现代的方法。理解这两种方法非常有帮助，因为许多研究和出版物仍然采用频率主义方法。
- en: Getting ready
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: You need to have a basic knowledge of probability theory for this recipe (random
    variables, distributions, expectancy, variance, central limit theorem, and so
    on).
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要具备基本的概率论知识（随机变量、分布、期望、方差、中心极限定理等）才能理解此方法。
- en: How to do it...
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现...
- en: 'Many frequentist methods for hypothesis testing roughly involve the following
    steps:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 许多频率主义假设检验方法大致包括以下步骤：
- en: Writing down the hypotheses, notably the **null hypothesis**, which is the *opposite*
    of the hypothesis we want to prove (with a certain degree of confidence).
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 写下假设，特别是**零假设**，它是我们想要证明的假设的*对立面*（以一定的置信度）。
- en: Computing a **test statistic**, a mathematical formula depending on the test
    type, the model, the hypotheses, and the data.
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算**检验统计量**，这是一个依赖于检验类型、模型、假设和数据的数学公式。
- en: Using the computed value to accept the hypothesis, reject it, or fail to conclude.
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用计算得出的值来接受假设、拒绝假设或无法得出结论。
- en: Here, we flip a coin *n* times and we observe *h* heads. We want to know whether
    the coin is fair (null hypothesis). This example is extremely simple yet quite
    useful for pedagogical purposes. Besides, it is the basis of many more complex
    methods.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个实验中，我们抛掷硬币*n*次，并观察到*h*次正面朝上。我们想知道硬币是否公平（零假设）。这个例子非常简单，但对于教学目的非常有用。此外，它是许多更复杂方法的基础。
- en: We denote the Bernoulli distribution by *B(q)* with the unknown parameter *q*.
    You can refer to [http://en.wikipedia.org/wiki/Bernoulli_distribution](http://en.wikipedia.org/wiki/Bernoulli_distribution)
    for more information.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们用*B(q)*表示伯努利分布，其中未知参数为*q*。您可以访问[http://en.wikipedia.org/wiki/Bernoulli_distribution](http://en.wikipedia.org/wiki/Bernoulli_distribution)获取更多信息。
- en: 'A Bernoulli variable is:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 伯努利变量是：
- en: 0 (tail) with probability *1-q*
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 0（反面）出现的概率为*1-q*
- en: 1 (head) with probability *q*
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1（正面朝上）出现的概率为*q*
- en: 'Here are the steps required to conduct a simple statistical *z*-test:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是进行简单统计*z*-检验所需的步骤：
- en: 'Let''s suppose that after *n=100* flips, we get *h=61* heads. We choose a significance
    level of 0.05: is the coin fair or not? Our null hypothesis is: *the coin is fair
    (q = 1/2)*:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 假设我们抛掷了*n=100*次硬币，得到了*h=61*次正面朝上。我们选择显著性水平为0.05：硬币是否公平？我们的零假设是：*硬币是公平的（q = 1/2）*：
- en: '[PRE11]'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Let's compute the **z-score**, which is defined by the following formula (`xbar`
    is the estimated average of the distribution). We will explain this formula in
    the next section, *How it works…*.
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们计算**z分数**，它由以下公式定义（`xbar`是分布的估计平均值）。我们将在下一部分*它是如何工作的...*中解释此公式。
- en: '[PRE12]'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Now, from the z-score, we can compute the p-value as follows:'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，根据z分数，我们可以按以下方式计算p值：
- en: '[PRE13]'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This p-value is less than 0.05, so we reject the null hypothesis and conclude
    that *the coin is probably not fair*.
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该p值小于0.05，因此我们拒绝零假设，并得出结论：*硬币可能不公平*。
- en: How it works...
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The coin tossing experiment is modeled as a sequence of *n* independent random
    variables ![How it works...](img/4818OS_07_46.jpg) following the Bernoulli distribution
    *B(q)*. Each *x[i]* represents one coin flip. After our experiment, we get actual
    values (samples) for these variables. A different notation is sometimes used to
    distinguish between the random variables (probabilistic objects) and the actual
    values (samples).
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 投币实验被建模为一系列*独立的随机变量*，![它是如何工作的...](img/4818OS_07_46.jpg)，遵循伯努利分布*B(q)*。每个*x[i]*代表一次投币实验。经过我们的实验后，我们获得这些变量的实际值（样本）。有时为了区分随机变量（概率对象）和实际值（样本），会使用不同的符号表示。
- en: 'The following formula gives the **sample mean** (proportion of heads here):'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 以下公式给出了**样本均值**（这里是正面朝上的比例）：
- en: '![How it works...](img/4818OS_07_02.jpg)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![它是如何工作的...](img/4818OS_07_02.jpg)'
- en: 'Knowing the expectancy ![How it works...](img/4818OS_07_39.jpg) and variance
    ![How it works...](img/4818OS_07_40.jpg) of the distribution *B(q)*, we compute:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 知道分布*B(q)*的期望值![它是如何工作的...](img/4818OS_07_39.jpg)和方差![它是如何工作的...](img/4818OS_07_40.jpg)，我们计算：
- en: '![How it works...](img/4818OS_07_03.jpg)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![它是如何工作的...](img/4818OS_07_03.jpg)'
- en: 'The z-test is the normalized version of ![How it works...](img/4818OS_07_41.jpg)
    (we remove its mean, and divide by the standard deviation, thus we get a variable
    with mean 0 and standard deviation 1):'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: z检验是![它是如何工作的...](img/4818OS_07_41.jpg)的标准化版本（我们去除其均值，并除以标准差，因此我们得到一个均值为0，标准差为1的变量）：
- en: '![How it works...](img/4818OS_07_04.jpg)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![它是如何工作的...](img/4818OS_07_04.jpg)'
- en: 'Under the null hypothesis, what is the probability of obtaining a z-test higher
    than some quantity *z[0]*? This probability is called the (two-sided) **p-value**.
    According to the central limit theorem, the z-test approximately follows a standard
    Gaussian distribution *N(0,1)* for large *n*, so we get:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在零假设下，获得大于某个数量*z[0]*的z检验的概率是多少？这个概率称为（双尾）**p值**。根据中心极限定理，当*n*较大时，z检验大致服从标准正态分布*N(0,1)*，因此我们得到：
- en: '![How it works...](img/4818OS_07_05.jpg)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![它是如何工作的...](img/4818OS_07_05.jpg)'
- en: 'The following diagram illustrates the z-score and the p-value:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了z分数和p值：
- en: '![How it works...](img/4818OS_07_06.jpg)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![它是如何工作的...](img/4818OS_07_06.jpg)'
- en: Illustration of the z-score and the p-value
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: z分数和p值的示意图
- en: 'In this formula, ![How it works...](img/4818OS_07_42.jpg) is the **cumulative
    distribution function** of a standard normal distribution. In SciPy, we can get
    it with `scipy.stats.norm.cdf`. So, given the z-test computed from the data, we
    compute the p-value: the probability of observing a z-test more extreme than the
    observed test, under the null hypothesis.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个公式中，![它是如何工作的...](img/4818OS_07_42.jpg) 是标准正态分布的**累积分布函数**。在SciPy中，我们可以通过
    `scipy.stats.norm.cdf` 获取它。因此，给定从数据中计算得出的z检验，我们计算p值：在原假设下，观察到比所观察到的检验值更极端的z检验的概率。
- en: 'If the p-value is less than five percent (a frequently-chosen significance
    level, for arbitrary and historical reasons), we conclude that either:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 如果p值小于5%（这是一个常用的显著性水平，出于任意和历史原因），我们得出结论：
- en: The null hypothesis is false, thus we conclude that the coin is unfair.
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 原假设为假，因此我们得出结论：硬币是不公平的。
- en: The null hypothesis is true, and it's just bad luck if we obtained these values.
    We cannot make a conclusion.
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 原假设为真，如果我们得到了这些值，那就是运气不好。我们无法得出结论。
- en: We cannot disambiguate between these two options in this framework, but typically
    the first option is chosen. We hit the limits of frequentist statistics, although
    there are ways to mitigate this problem (for example, by conducting several independent
    studies and looking at all of their conclusions).
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个框架中，我们无法对这两个选项进行歧义消解，但通常选择第一个选项。我们达到了频率主义统计的极限，尽管有一些方法可以缓解这个问题（例如，通过进行几项独立研究并查看它们的所有结论）。
- en: There's more...
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多内容...
- en: Many statistical tests following this pattern exist. Reviewing all those tests
    is largely beyond the scope of this book, but you can take a look at the reference
    at [http://en.wikipedia.org/wiki/Statistical_hypothesis_testing](http://en.wikipedia.org/wiki/Statistical_hypothesis_testing).
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 存在许多遵循这种模式的统计检验。回顾所有这些检验远超出本书的范围，但你可以查看 [http://en.wikipedia.org/wiki/Statistical_hypothesis_testing](http://en.wikipedia.org/wiki/Statistical_hypothesis_testing)
    中的参考资料。
- en: As a p-value is not easy to interpret, it can lead to wrong conclusions, even
    in peer-reviewed scientific publications. For an in-depth treatment of the subject,
    see [www.refsmmat.com/statistics/](http://www.refsmmat.com/statistics/).
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 由于p值不容易解释，它可能导致错误的结论，即使是在同行评审的科学出版物中也是如此。关于该主题的深入探讨，请参见 [www.refsmmat.com/statistics/](http://www.refsmmat.com/statistics/)。
- en: See also
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: The *Getting started with Bayesian methods* recipe
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*入门贝叶斯方法*部分'
- en: Getting started with Bayesian methods
  id: totrans-135
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 入门贝叶斯方法
- en: In the last recipe, we used a frequentist method to test a hypothesis on incomplete
    data. Here, we will see an alternative approach based on **Bayesian theory**.
    The main idea is to consider that *unknown parameters are random variables*, just
    like the variables describing the experiment. Prior knowledge about the parameters
    is integrated into the model. This knowledge is updated as more and more data
    is observed.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一个例子中，我们使用了频率主义方法对不完全数据进行假设检验。在这里，我们将看到一种基于**贝叶斯理论**的替代方法。主要思想是认为*未知参数是随机变量*，就像描述实验的变量一样。关于这些参数的先验知识被整合到模型中。随着数据的不断增加，这些知识会被更新。
- en: Frequentists and Bayesians interpret probabilities differently. Frequentists
    interpret a probability as a limit of frequencies when the number of samples tends
    to infinity. Bayesians interpret it as a belief; this belief is updated as more
    and more data is observed.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 频率主义者和贝叶斯主义者对概率的解释不同。频率主义者将概率解释为样本数量趋于无穷大时频率的极限。而贝叶斯主义者则将其解释为一种信念；随着观察到的数据越来越多，这种信念会不断更新。
- en: Here, we revisit the previous coin flipping example with a Bayesian approach.
    This example is sufficiently simple to permit an analytical treatment. In general,
    as we will see later in this chapter, analytical results cannot be obtained and
    numerical methods become essential.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，我们以贝叶斯方法重新审视之前的抛硬币例子。这个例子足够简单，可以进行分析处理。通常，如我们将在本章后面看到的，无法得到解析结果，数值方法变得至关重要。
- en: Getting ready
  id: totrans-139
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备开始
- en: This is a math-heavy recipe. Knowledge of basic probability theory (random variables,
    distributions, Bayes formula) and calculus (derivatives, integrals) is recommended.
    We use the same notations as in the previous recipe.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个数学密集的过程。建议具备基本概率论（随机变量、分布、贝叶斯公式）和微积分（导数、积分）的知识。我们使用与前一个方法相同的符号。
- en: How to do it...
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: Let *q* be the probability of obtaining a head. Whereas *q* was just a fixed
    number in the previous recipe, we consider here that it is a **random variable**.
    Initially, this variable follows a distribution called the **prior probability
    distribution**. It represents our knowledge about *q* before we start flipping
    the coin. We will update this distribution after each trial (posterior distribution).
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 让*q*表示获得正面的概率。而在之前的公式中，*q*只是一个固定的数字，在这里我们认为它是一个**随机变量**。最初，这个变量遵循一种被称为**先验概率分布**的分布。它表示我们在开始抛硬币之前，对*q*的知识。我们将在每次试验后更新这个分布（即后验分布）。
- en: 'First, we assume that *q* is a *uniform* random variable in the interval [0,
    1]. That''s our prior distribution: for all *q*, *P(q)=1*.'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们假设*q*是区间[0, 1]上的一个*均匀*随机变量。这是我们的先验分布：对于所有*q*，*P(q)=1*。
- en: Then, we flip our coin *n* times. We note *x[i]* the outcome of the *i*th flip
    (0 for tail and 1 for head).
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们抛硬币*n*次。我们用*x[i]*表示第*i*次抛掷的结果（0代表反面，1代表正面）。
- en: What is the probability distribution of *q* knowing the observations *x[i]*?
    **Bayes' theorem** allows us to compute the **posterior distribution** analytically
    (see the next section for the mathematical details):![How to do it...](img/4818OS_07_07.jpg)
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 知道观察到的结果*x[i]*后，*q*的概率分布是多少？**贝叶斯定理**使我们能够解析地计算出**后验分布**（数学细节见下一部分）：![如何操作...](img/4818OS_07_07.jpg)
- en: We define the posterior distribution according to the previous mathematical
    formula. We remark that this expression is *(n+1)* times the **probability mass
    function** (**PMF**) of the binomial distribution, which is directly available
    in `scipy.stats`. (For more information on Binomial distribution, refer to [http://en.wikipedia.org/wiki/Binomial_distribution](http://en.wikipedia.org/wiki/Binomial_distribution).)
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们根据之前的数学公式定义后验分布。我们注意到，这个表达式是*(n+1)*倍的**概率质量函数**（**PMF**）二项分布的形式，二项分布可以直接通过`scipy.stats`获得。（有关二项分布的更多信息，请参见[http://en.wikipedia.org/wiki/Binomial_distribution](http://en.wikipedia.org/wiki/Binomial_distribution)。）
- en: '[PRE14]'
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Let''s plot this distribution for an observation of *h=61* heads and *n=100*
    total flips:'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们为观察到*h=61*次正面朝上的结果和*n=100*次抛掷总数，绘制这个分布：
- en: '[PRE15]'
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '![How to do it...](img/4818OS_07_08.jpg)'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![如何操作...](img/4818OS_07_08.jpg)'
- en: This curve represents our belief about the parameter *q* after we have observed
    61 heads.
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个曲线表示我们在观察到61次正面朝上的结果后，对参数*q*的信念。
- en: How it works...
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In this section, we explain Bayes' theorem, and we give the mathematical details
    underlying this example.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们解释了贝叶斯定理，并给出了这个例子背后的数学细节。
- en: Bayes' theorem
  id: totrans-154
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 贝叶斯定理
- en: There is a very general idea in data science that consists of explaining data
    with a mathematical model. This is formalized with a one-way process, *model →
    data*.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学中有一个非常通用的思想，那就是用数学模型来解释数据。这通过一个单向过程*模型 → 数据*来形式化。
- en: Once this process is formalized, the task of the data scientist is to exploit
    the data to recover information about the model. In other words, we want to *invert*
    the original process and get *data → model*.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦这个过程被形式化，数据科学家的任务就是利用数据恢复关于模型的信息。换句话说，我们希望*逆转*原始过程并得到*数据 → 模型*。
- en: In a probabilistic setting, the direct process is represented as a **conditional
    probability distribution** *P(data|model)*. This is the probability of observing
    the data when the model is entirely specified.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个概率设置中，直接过程表示为**条件概率分布** *P(data|model)*。这是在模型完全指定的情况下，观察到数据的概率。
- en: Similarly, the inverse process is *P(model|data)*. It gives us information about
    the model (what we're looking for), knowing the observations (what we have).
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，逆向过程是*P(model|data)*。它在知道观察结果（我们拥有的数据）的基础上，给我们关于模型（我们所寻找的）的信息。
- en: 'Bayes'' theorem is at the core of a general framework for inverting a probabilistic
    process of *model → data*. It can be stated as follows:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯定理是一个通用框架的核心，用于逆转*模型 → 数据*的概率过程。它可以表述如下：
- en: '![Bayes'' theorem](img/4818OS_07_09.jpg)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![贝叶斯定理](img/4818OS_07_09.jpg)'
- en: This equation gives us information about our model, knowing the observed data.
    Bayes' equation is widely used in signal processing, statistics, machine learning,
    inverse problems, and in many other scientific applications.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 这个方程为我们提供了关于模型的信息，前提是我们知道观测数据。贝叶斯方程广泛应用于信号处理、统计学、机器学习、逆问题以及许多其他科学领域。
- en: In Bayes' equation, *P(model)* reflects our prior knowledge about the model.
    Also, *P(data)* is the distribution of the data. It is generally expressed as
    an integral of *P(data|model)P(model)*.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在贝叶斯方程中，*P(model)* 反映了我们关于模型的先验知识。同时，*P(data)* 是数据的分布。通常它表示为 *P(data|model)P(model)*
    的积分。
- en: 'In conclusion, Bayes'' equation gives us a general roadmap for data inference:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，贝叶斯方程为我们提供了数据推断的总体路线图：
- en: Specify a mathematical model for the direct process *model → data* (the *P(data|model)*
    term).
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为直接过程 *model → data* 指定一个数学模型（*P(data|model)* 项）。
- en: Specify a prior probability distribution for the model (*P(model) term*).
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为模型指定一个先验概率分布 (*P(model) 项*)。
- en: Perform analytical or numerical calculations to solve this equation.
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行解析或数值计算以求解这个方程。
- en: Computation of the posterior distribution
  id: totrans-167
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 后验分布的计算
- en: 'In this recipe''s example, we found the posterior distribution with the following
    equation (deriving directly from Bayes'' theorem):'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们通过以下方程（直接源自贝叶斯定理）找到了后验分布：
- en: '![Computation of the posterior distribution](img/4818OS_07_10.jpg)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![后验分布的计算](img/4818OS_07_10.jpg)'
- en: 'Knowing that the *x[i]* are independent, we get (*h* being the number of heads):'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 *x[i]* 是独立的，我们得到（*h* 为正面次数）：
- en: '![Computation of the posterior distribution](img/4818OS_07_11.jpg)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![后验分布的计算](img/4818OS_07_11.jpg)'
- en: 'In addition, we can compute analytically the following integral (using an integration
    by parts and an induction):'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们可以解析计算以下积分（使用分部积分法和归纳法）：
- en: '![Computation of the posterior distribution](img/4818OS_07_12.jpg)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![后验分布的计算](img/4818OS_07_12.jpg)'
- en: 'Finally, we get:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们得到：
- en: '![Computation of the posterior distribution](img/4818OS_07_13.jpg)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![后验分布的计算](img/4818OS_07_13.jpg)'
- en: Maximum a posteriori estimation
  id: totrans-176
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 最大后验估计
- en: We can get a point estimate from the posterior distribution. For example, the
    **maximum a posteriori** (**MAP**) estimation consists of considering the *maximum*
    of the posterior distribution as an estimate for *q*. We can find this maximum
    analytically or numerically. For more information on MAP, refer to [http://en.wikipedia.org/wiki/Maximum_a_posteriori_estimation](http://en.wikipedia.org/wiki/Maximum_a_posteriori_estimation).
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以从后验分布中得到一个点估计。例如，**最大后验估计** (**MAP**) 是通过考虑后验分布的 *最大* 值来作为 *q* 的估计。我们可以通过解析方法或数值方法找到这个最大值。有关MAP的更多信息，请参阅
    [http://en.wikipedia.org/wiki/Maximum_a_posteriori_estimation](http://en.wikipedia.org/wiki/Maximum_a_posteriori_estimation)。
- en: 'Here, we can get this estimate analytically by deriving the posterior distribution
    with respect to *q*. We get (assuming *1* ![Maximum a posteriori estimation](img/4818OS_08_40.jpg)
    *h* ![Maximum a posteriori estimation](img/4818OS_08_40.jpg) * n-1*):'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以通过对 *q* 求导直接推导出后验分布，得到这个估计（假设 *1* ![最大后验估计](img/4818OS_08_40.jpg) *h*
    ![最大后验估计](img/4818OS_08_40.jpg) * n-1*）：
- en: '![Maximum a posteriori estimation](img/4818OS_07_14.jpg)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
  zh: '![最大后验估计](img/4818OS_07_14.jpg)'
- en: This expression is equal to zero when *q = h/n*. This is the MAP estimate of
    the parameter *q*. This value happens to be the proportion of heads obtained in
    the experiment.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 当 *q = h/n* 时，该表达式为零。这就是参数 *q* 的MAP估计。这个值恰好是实验中获得的正面比例。
- en: There's more...
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: In this recipe, we showed a few basic notions in Bayesian theory. We illustrated
    them with a simple example. The fact that we were able to derive the posterior
    distribution analytically is not very common in real-world applications. This
    example is nevertheless informative because it explains the core mathematical
    ideas behind the complex numerical methods we will see later.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们展示了贝叶斯理论中的一些基本概念，并通过一个简单的例子进行说明。我们能够解析推导出后验分布在现实应用中并不常见。尽管如此，这个例子仍然具有启发性，因为它解释了我们接下来将看到的复杂数值方法背后的核心数学思想。
- en: Credible interval
  id: totrans-183
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 可信区间
- en: The posterior distribution indicates the plausible values for *q* given the
    observations. We could use it to derive a **credible interval**, likely to contain
    the actual value. Credible intervals are the Bayesian analog to confidence intervals
    in frequentist statistics. For more information on credible intervals, refer to
    [http://en.wikipedia.org/wiki/Credible_interval](http://en.wikipedia.org/wiki/Credible_interval).
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 后验分布表示在给定观察值的情况下 *q* 的合理取值。我们可以利用它推导出 **可信区间**，它很可能包含实际值。可信区间是贝叶斯统计中的类比于频率统计中的置信区间。有关可信区间的更多信息，请参阅
    [http://en.wikipedia.org/wiki/Credible_interval](http://en.wikipedia.org/wiki/Credible_interval)。
- en: Conjugate distributions
  id: totrans-185
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 共轭分布
- en: In this recipe, the prior and posterior distributions are **conjugate**, meaning
    that they belong to the same family (the beta distribution). For this reason,
    we were able to compute the posterior distribution analytically. You will find
    more details about conjugate distributions at [http://en.wikipedia.org/wiki/Conjugate_prior](http://en.wikipedia.org/wiki/Conjugate_prior).
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 在这道菜谱中，先验分布和后验分布是**共轭**的，意味着它们属于同一个分布族（即贝塔分布）。因此，我们能够解析计算后验分布。你可以在[http://en.wikipedia.org/wiki/Conjugate_prior](http://en.wikipedia.org/wiki/Conjugate_prior)找到有关共轭分布的更多细节。
- en: Non-informative (objective) prior distributions
  id: totrans-187
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 非信息性（客观）先验分布
- en: 'We chose a uniform distribution as prior distribution for the unknown parameter
    *q*. It is a simple choice and it leads to tractable computations. It reflects
    the intuitive fact that we do not favor any particular value a priori. However,
    there are rigorous ways of choosing completely uninformative priors (see [http://en.wikipedia.org/wiki/Prior_probability#Uninformative_priors](http://en.wikipedia.org/wiki/Prior_probability#Uninformative_priors)).
    An example is the Jeffreys prior, based on the idea that the prior distribution
    should not depend on the parameterization of the parameters. For more information
    on Jeffreys prior, refer to [http://en.wikipedia.org/wiki/Jeffreys_prior](http://en.wikipedia.org/wiki/Jeffreys_prior).
    In our example, the Jeffreys prior is:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 我们选择了均匀分布作为未知参数*q*的先验分布。这是一个简单的选择，它使得计算变得可处理。它反映了一个直观的事实，即我们在先验上并不偏向任何特定的值。然而，也有一些严格的选择完全无信息性先验的方法（参见[http://en.wikipedia.org/wiki/Prior_probability#Uninformative_priors](http://en.wikipedia.org/wiki/Prior_probability#Uninformative_priors)）。一个例子是Jeffreys先验，基于这样的思想：先验分布不应依赖于参数化的选择。更多关于Jeffreys先验的信息，请参阅[http://en.wikipedia.org/wiki/Jeffreys_prior](http://en.wikipedia.org/wiki/Jeffreys_prior)。在我们的例子中，Jeffreys先验为：
- en: '![Non-informative (objective) prior distributions](img/4818OS_07_15.jpg)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
  zh: '![非信息性（客观）先验分布](img/4818OS_07_15.jpg)'
- en: See also
  id: totrans-190
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: The *Fitting a Bayesian model by sampling from a posterior distribution with
    a Markov chain Monte Carlo method* recipe
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*通过马尔科夫链蒙特卡罗方法从后验分布中抽样拟合贝叶斯模型*菜谱'
- en: Estimating the correlation between two variables with a contingency table and
    a chi-squared test
  id: totrans-192
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用列联表和卡方检验估计两个变量之间的相关性
- en: Whereas univariate methods deal with single-variable observations, multivariate
    methods consider observations with several features. Multivariate datasets allow
    the study of *relations* between variables, more particularly their correlation
    or lack thereof (that is, independence).
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 而单变量方法处理的是单一变量的观测数据，多变量方法则考虑包含多个特征的观测数据。多变量数据集允许研究变量之间的*关系*，特别是它们之间的相关性或独立性。
- en: In this recipe, we will take a look at the same tennis dataset as in the first
    recipe of this chapter. Following a frequentist approach, we will estimate the
    correlation between the number of aces and the proportion of points won by a tennis
    player.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 在本菜谱中，我们将查看本章第一道菜谱中的相同网球数据集。采用频率学派方法，我们将估计发球得分数与网球选手获胜的点数比例之间的相关性。
- en: Getting ready
  id: totrans-195
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: Download the *Tennis* dataset on the book's GitHub repository at [https://github.com/ipython-books/cookbook-data](https://github.com/ipython-books/cookbook-data),
    and extract it in the current directory.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 从本书的GitHub仓库下载*网球*数据集，链接为[https://github.com/ipython-books/cookbook-data](https://github.com/ipython-books/cookbook-data)，并将其解压到当前目录。
- en: How to do it...
  id: totrans-197
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Let''s import NumPy, pandas, SciPy.stats, and matplotlib:'
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们导入NumPy、pandas、SciPy.stats和matplotlib：
- en: '[PRE16]'
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'We load the dataset corresponding to Roger Federer:'
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们加载对应于罗杰·费德勒的数据集：
- en: '[PRE17]'
  id: totrans-201
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Each row corresponds to a match, and the 70 columns contain many player characteristics
    during that match:'
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每行对应一场比赛，70列包含该比赛中许多选手的特征：
- en: '[PRE18]'
  id: totrans-203
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Here, we only look at the proportion of points won, and the (relative) number
    of aces:'
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这里，我们仅关注获胜点数的比例和（相对的）发球得分数：
- en: '[PRE19]'
  id: totrans-205
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '![How to do it...](img/4818OS_07_16.jpg)'
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![如何操作...](img/4818OS_07_16.jpg)'
- en: If the two variables were independent, we would not see any trend in the cloud
    of points. On this plot, it is a bit hard to tell. Let's use pandas to compute
    a coefficient correlation.
  id: totrans-207
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果这两个变量是独立的，我们就不会在点云中看到任何趋势。在这个图上，稍微有点难以看出。让我们使用pandas计算一个相关系数。
- en: 'We create a new `DataFrame` object with only these fields (note that this step
    is not compulsory). We also remove the rows where one field is missing (using
    `dropna()`):'
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们创建一个新的`DataFrame`对象，仅包含这些字段（请注意，这一步不是强制性的）。我们还删除了缺失某个字段的行（使用`dropna()`）：
- en: '[PRE20]'
  id: totrans-209
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Let''s compute the Pearson''s correlation coefficient between the relative
    number of aces in the match, and the number of points won:'
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们计算比赛中A球的相对数量与赢得的点数之间的皮尔逊相关系数：
- en: '[PRE21]'
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: A correlation of ~0.26 seems to indicate a positive correlation between our
    two variables. In other words, the more aces in a match, the more points the player
    wins (which is not very surprising!).
  id: totrans-212
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 约为0.26的相关性似乎表明我们的两个变量之间存在正相关关系。换句话说，在一场比赛中A球越多，球员赢得的点数就越多（这并不令人惊讶！）。
- en: Now, to determine if there is a *statistically significant* correlation between
    the variables, we use a **chi-squared test** of the independence of variables
    in a **contingency table**.
  id: totrans-213
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，为了确定变量之间是否存在*统计上显著*的相关性，我们使用**卡方检验**来检验**列联表**中变量的独立性。
- en: 'First, we binarize our variables. Here, the value corresponding to the number
    of aces is `True` if the player is serving more aces than usual in a match, and
    `False` otherwise:'
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们将变量二值化。在这里，如果球员在比赛中发球A球比平常多，值为`True`，否则为`False`：
- en: '[PRE22]'
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Then, we create a contingency table, with the frequencies of all four possibilities
    (True and True, True and False, and so on):'
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们创建一个列联表，其中包含所有四种可能性（真和真，真和假，依此类推）的频率：
- en: '[PRE23]'
  id: totrans-217
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Finally, we compute the chi-squared test statistic and the associated p-value.
    The null hypothesis is the independence between the variables. SciPy implements
    this test in `scipy.stats.chi2_contingency`, which returns several objects. We''re
    interested in the second result, which is the p-value:'
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们计算卡方检验统计量和相关的P值。零假设是变量之间的独立性。SciPy在`scipy.stats.chi2_contingency`中实现了这个测试，返回了几个对象。我们对第二个结果感兴趣，即P值：
- en: '[PRE24]'
  id: totrans-219
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: The p-value is much lower than 0.05, so we reject the null hypothesis and conclude
    that there is a statistically significant correlation between the proportion of
    aces and the proportion of points won in a match (for Roger Federer!).
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: P值远低于0.05，因此我们拒绝零假设，并得出结论：在一场比赛中赢得的点数与赢得的A球比例之间存在统计学上显著的相关性（对于罗杰·费德勒！）。
- en: Tip
  id: totrans-221
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: As always, correlation does not imply causation. Here, it is likely that external
    factors influence both variables. See [http://en.wikipedia.org/wiki/Correlation_does_not_imply_causation](http://en.wikipedia.org/wiki/Correlation_does_not_imply_causation)
    for more details.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 如常，相关性并不意味着因果关系。在这里，外部因素很可能影响两个变量。有关更多细节，请参阅[http://en.wikipedia.org/wiki/Correlation_does_not_imply_causation](http://en.wikipedia.org/wiki/Correlation_does_not_imply_causation)。
- en: How it works...
  id: totrans-223
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: We give here a few details about the statistical concepts used in this recipe.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里提供了一些有关本文中使用的统计概念的细节。
- en: Pearson's correlation coefficient
  id: totrans-225
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 皮尔逊相关系数
- en: 'Pearson''s correlation coefficient measures the linear correlation between
    two random variables, *X* and *Y*. It is a normalized version of the covariance:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 皮尔逊相关系数衡量了两个随机变量*X*和*Y*之间的线性相关性。它是协方差的归一化版本：
- en: '![Pearson''s correlation coefficient](img/4818OS_07_17.jpg)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![皮尔逊相关系数](img/4818OS_07_17.jpg)'
- en: It can be estimated by substituting, in this formula, the expectancy with the
    sample mean, and the variance with the sample variance. More details about its
    inference can be found at [http://en.wikipedia.org/wiki/Pearson_product-moment_correlation_coefficient](http://en.wikipedia.org/wiki/Pearson_product-moment_correlation_coefficient).
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过将这个公式中的期望值替换为样本均值，方差替换为样本方差来估计。关于其推断的更多细节可以在[http://en.wikipedia.org/wiki/Pearson_product-moment_correlation_coefficient](http://en.wikipedia.org/wiki/Pearson_product-moment_correlation_coefficient)找到。
- en: Contingency table and chi-squared test
  id: totrans-229
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 列联表和卡方检验
- en: 'The contingency table contains the frequencies *O[ij]* of all combinations
    of outcomes, when there are multiple random variables that can take a finite number
    of values. Under the null hypothesis of independence, we can compute the *expected*
    frequencies *E[ij]*, based on the marginal sums (sums in each row). The chi-squared
    statistic, by definition, is:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 列联表包含所有组合结果的频率*O[ij]*，当存在多个随机变量可以取有限数量的值时。在独立性的零假设下，我们可以基于边际和（每行的总和）计算*期望*频率*E[ij]*。卡方统计量的定义如下：
- en: '![Contingency table and chi-squared test](img/4818OS_07_18.jpg)'
  id: totrans-231
  prefs: []
  type: TYPE_IMG
  zh: '![列联表和卡方检验](img/4818OS_07_18.jpg)'
- en: When there are sufficiently many observations, this variable approximately follows
    a chi-squared distribution (the distribution of the sum of normal variables squared).
    Once we get the p-value, as explained in the *Getting started with statistical
    hypothesis testing – a simple z-test* recipe, we can reject or accept the null
    hypothesis of independence. Then, we can conclude (or not) that there exists a
    significant correlation between the variables.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 当观察足够多时，这个变量大致遵循卡方分布（正态变量平方和的分布）。一旦我们得到了p值，就像*开始统计假设检验 - 一个简单的z检验*中所解释的那样，我们可以拒绝或接受独立性的零假设。然后，我们可以得出（或不得出）变量之间存在显著相关性的结论。
- en: There's more...
  id: totrans-233
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'There are many other sorts of chi-squared tests, that is, tests where the test
    statistic follows a chi-squared distribution. These tests are widely used for
    testing the goodness-of-fit of a distribution, or testing the independence of
    variables. More information can be found in the following pages:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 还有许多其他类型的卡方检验，即测试统计量遵循卡方分布的测试。这些测试广泛用于测试分布的拟合度，或测试变量的独立性。更多信息可以在以下页面找到：
- en: Chi2 test in SciPy documentation available at [http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html](http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html)
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SciPy文档中的Chi2测试可在[http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html](http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html)找到
- en: Contingency table introduced at [http://en.wikipedia.org/wiki/Contingency_table](http://en.wikipedia.org/wiki/Contingency_table)
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在[http://en.wikipedia.org/wiki/Contingency_table](http://en.wikipedia.org/wiki/Contingency_table)介绍的列联表
- en: Chi-squared test introduced at [http://en.wikipedia.org/wiki/Pearson's_chi-squared_test](http://en.wikipedia.org/wiki/Pearson's_chi-squared_test)
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在[http://en.wikipedia.org/wiki/Pearson's_chi-squared_test](http://en.wikipedia.org/wiki/Pearson's_chi-squared_test)介绍的卡方检验
- en: See also
  id: totrans-238
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: The *Getting started with statistical hypothesis testing – a simple z-test*
    recipe
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*开始统计假设检验 - 一个简单的z检验*食谱'
- en: Fitting a probability distribution to data with the maximum likelihood method
  id: totrans-240
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用最大似然方法将概率分布拟合到数据
- en: A good way to explain a dataset is to apply a probabilistic model to it. Finding
    an adequate model can be a job in its own. Once a model is chosen, it is necessary
    to compare it to the data. This is what statistical estimation is about. In this
    recipe, we apply the **maximum likelihood method** on a dataset of survival times
    after heart transplant (1967-1974 study).
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 解释数据集的一个好方法是对其应用概率模型。找到一个合适的模型可能是一项工作。选择模型后，有必要将其与数据进行比较。这就是统计估计的内容。在这个食谱中，我们对心脏移植后存活时间（1967-1974年研究）的数据集应用**最大似然方法**。
- en: Getting ready
  id: totrans-242
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: As usual in this chapter, a background in probability theory and real analysis
    is recommended. In addition, you need the statsmodels package to retrieve the
    test dataset. For more information on statsmodels, refer to [http://statsmodels.sourceforge.net](http://statsmodels.sourceforge.net).
    On Anaconda, you can install statsmodel with the `conda install statsmodels` command.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 与本章中通常一样，建议具有概率论和实分析背景。此外，您需要statsmodels包来检索测试数据集。有关statsmodels的更多信息，请参考[http://statsmodels.sourceforge.net](http://statsmodels.sourceforge.net)。在Anaconda上，您可以使用`conda
    install statsmodels`命令安装statsmodel。
- en: How to do it...
  id: totrans-244
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'statsmodels is a Python package for conducting statistical data analyses. It
    also contains real-world datasets that we can use when experimenting with new
    methods. Here, we load the *heart* dataset:'
  id: totrans-245
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: statsmodels是一个用于进行统计数据分析的Python包。它还包含我们在尝试新方法时可以使用的真实数据集。在这里，我们加载*heart*数据集：
- en: '[PRE25]'
  id: totrans-246
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Let''s take a look at this `DataFrame`:'
  id: totrans-247
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们来看看这个`DataFrame`：
- en: '[PRE26]'
  id: totrans-248
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'This dataset contains censored and uncensored data: a censor of 0 means that
    the patient was alive at the end of the study, and thus we don''t know the exact
    survival time. We only know that the patient survived *at least* the indicated
    number of days. For simplicity here, we only keep uncensored data (we thereby
    introduce a bias toward patients that did not survive very long after their transplant):'
  id: totrans-249
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个数据集包含被审查和未被审查的数据：0的审查意味着患者在研究结束时仍然存活，因此我们不知道确切的存活时间。我们只知道患者至少存活了指定的天数。为简单起见，我们只保留未被审查的数据（这样我们就引入了对未能在移植后存活很长时间的患者的偏见）：
- en: '[PRE27]'
  id: totrans-250
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Let''s take a look at the data graphically, by plotting the raw survival data
    and the histogram:'
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们通过绘制原始存活数据和直方图来以图形方式查看数据：
- en: '[PRE28]'
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '![How to do it...](img/4818OS_07_19.jpg)'
  id: totrans-253
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![如何做...](img/4818OS_07_19.jpg)'
- en: We observe that the histogram is decreasing very rapidly. Fortunately, the survival
    rates today are much higher (~70 percent after 5 years). Let's try to fit an exponential
    distribution (more information on the exponential distribution is available at
    [http://en.wikipedia.org/wiki/Exponential_distribution](http://en.wikipedia.org/wiki/Exponential_distribution))
    to the data. According to this model, *S* (number of days of survival) is an exponential
    random variable with the parameter ![How to do it...](img/4818OS_07_43.jpg), and
    the observations *s[i]* are sampled from this distribution. Let the sample mean
    be:![How to do it...](img/4818OS_07_20.jpg)The likelihood function of an exponential
    distribution is as follows, by definition (see proof in the next section):![How
    to do it...](img/4818OS_07_21.jpg)
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们观察到直方图正在迅速下降。幸运的是，今天的生存率要高得多（5年后的生存率约为70%）。让我们尝试将指数分布拟合到数据中（关于指数分布的更多信息可以参见[http://en.wikipedia.org/wiki/Exponential_distribution](http://en.wikipedia.org/wiki/Exponential_distribution)）。根据这个模型，*S*（生存天数）是一个带有参数![How
    to do it...](img/4818OS_07_43.jpg)的指数随机变量，观察值*s[i]*是从这个分布中抽样得到的。令样本均值为：![How to
    do it...](img/4818OS_07_20.jpg)指数分布的似然函数如下，按照定义（证明见下节）：![How to do it...](img/4818OS_07_21.jpg)
- en: The **maximum likelihood estimate** for the rate parameter is, by definition,
    the value ![How to do it...](img/4818OS_07_43.jpg) that maximizes the likelihood
    function. In other words, it is the parameter that maximizes the probability of
    observing the data, assuming that the observations are sampled from an exponential
    distribution.
  id: totrans-255
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**最大似然估计**对于速率参数的定义是：值![How to do it...](img/4818OS_07_43.jpg)，它最大化了似然函数。换句话说，这是最大化观察到数据的概率的参数，假设这些观察值是从指数分布中抽样得到的。'
- en: 'Here, it can be shown that the likelihood function has a maximum value when
    ![How to do it...](img/4818OS_07_44.jpg), which is the maximum likelihood estimate
    for the rate parameter. Let''s compute this parameter numerically:'
  id: totrans-256
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，可以证明当![How to do it...](img/4818OS_07_44.jpg)时，似然函数取得最大值，这就是速率参数的最大似然估计。让我们通过数值方法计算这个参数：
- en: '[PRE29]'
  id: totrans-257
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'To compare the fitted exponential distribution to the data, we first need to
    generate linearly spaced values for the x-axis (days):'
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了将拟合的指数分布与数据进行比较，我们首先需要为x轴（天数）生成线性间隔的值：
- en: '[PRE30]'
  id: totrans-259
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: We can obtain the probability density function of the exponential distribution
    with SciPy. The parameter is the scale, the inverse of the estimated rate.
  id: totrans-260
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以使用SciPy获得指数分布的概率密度函数。参数是尺度，即估计速率的倒数。
- en: '[PRE31]'
  id: totrans-261
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Now, let''s plot the histogram and the obtained distribution. We need to rescale
    the theoretical distribution to the histogram (depending on the bin size and the
    total number of data points):'
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们绘制直方图和得到的分布。我们需要将理论分布重新缩放到直方图上（这取决于箱子大小和数据点的总数）：
- en: '[PRE32]'
  id: totrans-263
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '![How to do it...](img/4818OS_07_22.jpg)'
  id: totrans-264
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![How to do it...](img/4818OS_07_22.jpg)'
- en: The fit is far from perfect. We were able to find an analytical formula for
    the maximum likelihood estimate here. In more complex situations, that is not
    always possible. Thus we may need to resort to numerical methods. SciPy actually
    integrates numerical maximum likelihood routines for a large number of distributions.
    Here, we use this other method to estimate the parameter of the exponential distribution.
  id: totrans-265
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 拟合结果远非完美。我们能够找到最大似然估计的解析公式。在更复杂的情况下，这并不总是可能的。因此，我们可能需要求助于数值方法。SciPy实际上集成了针对大量分布的数值最大似然程序。在这里，我们使用这种其他方法来估计指数分布的参数。
- en: '[PRE33]'
  id: totrans-266
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: We can use these parameters to perform a **Kolmogorov-Smirnov test**, which
    assesses the goodness of fit of the distribution with respect to the data. This
    test is based on a distance between the **empirical distribution function** of
    the data and the **cumulative distribution function** (**CDF**) of the reference
    distribution.
  id: totrans-267
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以使用这些参数进行**Kolmogorov-Smirnov检验**，该检验评估分布相对于数据的拟合优度。这个检验是基于数据的**经验分布函数**与参考分布的**累积分布函数**（**CDF**）之间的距离。
- en: '[PRE34]'
  id: totrans-268
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The second output value is the p-value. Here, it is very low: the null hypothesis
    (stating that the observed data stems from an exponential distribution with a
    maximum likelihood rate parameter) can be rejected with high confidence. Let''s
    try another distribution, the **Birnbaum-Sanders distribution**, which is typically
    used to model failure times. (More information on the Birnbaum-Sanders distribution
    is available at [http://en.wikipedia.org/wiki/Birnbaum-Saunders_distribution](http://en.wikipedia.org/wiki/Birnbaum-Saunders_distribution).)'
  id: totrans-269
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第二个输出值是p值。在这里，它非常低：零假设（即观察到的数据来自具有最大似然速率参数的指数分布）可以被高置信度地拒绝。我们试试另一个分布，**Birnbaum-Sanders分布**，它通常用于建模故障时间。（关于Birnbaum-Sanders分布的更多信息，请访问[http://en.wikipedia.org/wiki/Birnbaum-Saunders_distribution](http://en.wikipedia.org/wiki/Birnbaum-Saunders_distribution)。）
- en: '[PRE35]'
  id: totrans-270
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'This time, the p-value is 0.07, so that we would not reject the null hypothesis
    with a five percent confidence level. When plotting the resulting distribution,
    we observe a better fit than with the exponential distribution:'
  id: totrans-271
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这次，p值是0.07，因此我们在5%的置信水平下不会拒绝零假设。绘制结果分布时，我们观察到比指数分布更好的拟合：
- en: '[PRE36]'
  id: totrans-272
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '![How to do it...](img/4818OS_07_23.jpg)'
  id: totrans-273
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![它是如何做的...](img/4818OS_07_23.jpg)'
- en: How it works...
  id: totrans-274
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'Here, we give the calculations leading to the maximum likelihood estimation
    of the rate parameter for an exponential distribution:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们给出了计算过程，推导出指数分布的速率参数的最大似然估计：
- en: '![How it works...](img/4818OS_07_24.jpg)'
  id: totrans-276
  prefs: []
  type: TYPE_IMG
  zh: '![它是如何工作的...](img/4818OS_07_24.jpg)'
- en: Here, ![How it works...](img/4818OS_07_45.jpg) is the sample mean. In more complex
    situations, we would require numerical optimization methods in which the principle
    is to maximize the likelihood function using a standard numerical optimization
    algorithm (see [Chapter 9](ch09.html "Chapter 9. Numerical Optimization"), *Numerical
    Optimization*).
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，![它是如何工作的...](img/4818OS_07_45.jpg) 是样本均值。在更复杂的情况下，我们将需要数值优化方法，其中的原理是使用标准的数值优化算法来最大化似然函数（请参阅[第9章](ch09.html
    "第9章 数值优化")，*数值优化*）。
- en: 'To find the maximum of this function, let''s compute its derivative function
    with respect to ![How it works...](img/4818OS_07_43.jpg):'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 为了找到该函数的最大值，我们需要计算它关于 ![它是如何工作的...](img/4818OS_07_43.jpg) 的导数：
- en: '![How it works...](img/4818OS_07_25.jpg)'
  id: totrans-279
  prefs: []
  type: TYPE_IMG
  zh: '![它是如何工作的...](img/4818OS_07_25.jpg)'
- en: The root of this derivative is therefore ![How it works...](img/4818OS_07_44.jpg)
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，这个导数的根是 ![它是如何工作的...](img/4818OS_07_44.jpg)
- en: There's more...
  id: totrans-281
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多内容...
- en: 'Here are a few references:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 这里列出了一些参考资料：
- en: Maximum likelihood on Wikipedia, available at [http://en.wikipedia.org/wiki/Maximum_likelihood](http://en.wikipedia.org/wiki/Maximum_likelihood)
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最大似然法在维基百科上的介绍，详情请见[http://en.wikipedia.org/wiki/Maximum_likelihood](http://en.wikipedia.org/wiki/Maximum_likelihood)
- en: Kolmogorov-Smirnov test on Wikipedia, available at [http://en.wikipedia.org/wiki/Kolmogorov-Smirnov_test](http://en.wikipedia.org/wiki/Kolmogorov-Smirnov_test)
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kolmogorov-Smirnov检验在维基百科上的介绍，详情请见[http://en.wikipedia.org/wiki/Kolmogorov-Smirnov_test](http://en.wikipedia.org/wiki/Kolmogorov-Smirnov_test)
- en: Goodness of fit at [http://en.wikipedia.org/wiki/Goodness_of_fit](http://en.wikipedia.org/wiki/Goodness_of_fit)
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 拟合优度在[http://en.wikipedia.org/wiki/Goodness_of_fit](http://en.wikipedia.org/wiki/Goodness_of_fit)上有详细介绍
- en: 'The maximum likelihood method is *parametric*: the model belongs to a prespecified
    parametric family of distributions. In the next recipe, we will see a nonparametric
    kernel-based method.'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 最大似然法是*参数化的*：模型属于一个预先指定的参数分布族。在下一个方法中，我们将看到一种基于核的方法，它是非参数化的。
- en: See also
  id: totrans-287
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: The *Estimating a probability distribution nonparametrically with a kernel density
    estimation* recipe
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*通过核密度估计非参数地估计概率分布* 的方法'
- en: Estimating a probability distribution nonparametrically with a kernel density
    estimation
  id: totrans-289
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用核密度估计法非参数地估计概率分布
- en: In the previous recipe, we applied a **parametric estimation method**. We had
    a statistical model (the exponential distribution) describing our data, and we
    estimated a single parameter (the rate of the distribution). **Nonparametric estimation**
    deals with statistical models that do not belong to a known family of distributions.
    The parameter space is then *infinite-dimensional* instead of finite-dimensional
    (that is, we estimate *functions* rather than *numbers*).
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的方法中，我们应用了**参数估计方法**。我们有一个统计模型（指数分布）来描述我们的数据，并且我们估计了一个参数（分布的速率）。**非参数估计**处理那些不属于已知分布族的统计模型。这样，参数空间就是*无限维的*，而不是有限维的（也就是说，我们估计的是*函数*而不是*数值*）。
- en: Here, we use a **kernel density estimation** (**KDE**) to estimate the density
    of probability of a spatial distribution. We look at the geographical locations
    of tropical cyclones from 1848 to 2013, based on data provided by the NOAA, the
    US' National Oceanic and Atmospheric Administration.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用 **核密度估计** (**KDE**) 来估算空间分布的概率密度。我们查看了 1848 到 2013 年期间热带气旋的地理位置，数据由
    NOAA（美国国家海洋和大气管理局）提供。
- en: Getting ready
  id: totrans-292
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: Download the *Storms* dataset from the book's GitHub repository at [https://github.com/ipython-books/cookbook-data](https://github.com/ipython-books/cookbook-data),
    and extract it in the current directory. The data was obtained from [www.ncdc.noaa.gov/ibtracs/index.php?name=wmo-data](http://www.ncdc.noaa.gov/ibtracs/index.php?name=wmo-data).
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 从本书的 GitHub 仓库下载 *Storms* 数据集 [https://github.com/ipython-books/cookbook-data](https://github.com/ipython-books/cookbook-data)，并将其解压到当前目录。数据来自
    [www.ncdc.noaa.gov/ibtracs/index.php?name=wmo-data](http://www.ncdc.noaa.gov/ibtracs/index.php?name=wmo-data)。
- en: You also need matplotlib's toolkit **basemap**, available at [http://matplotlib.org/basemap/](http://matplotlib.org/basemap/).
    With Anaconda, you can install it with conda install basemap. Windows users can
    also find an installer at [www.lfd.uci.edu/~gohlke/pythonlibs/](http://www.lfd.uci.edu/~gohlke/pythonlibs/).
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 你还需要 matplotlib 的工具包 **basemap**，可以通过 [http://matplotlib.org/basemap/](http://matplotlib.org/basemap/)
    获取。使用 Anaconda，你可以通过 `conda install basemap` 安装它。Windows 用户还可以在 [www.lfd.uci.edu/~gohlke/pythonlibs/](http://www.lfd.uci.edu/~gohlke/pythonlibs/)
    找到安装程序。
- en: How to do it...
  id: totrans-295
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Let''s import the usual packages. The kernel density estimation with a Gaussian
    kernel is implemented in SciPy.stats:'
  id: totrans-296
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们导入常用的包。使用高斯核的核密度估计在 SciPy.stats 中有实现：
- en: '[PRE37]'
  id: totrans-297
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Let''s open the data with pandas:'
  id: totrans-298
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们使用 pandas 打开数据：
- en: '[PRE38]'
  id: totrans-299
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: The dataset contains information about most storms since 1848\. A single storm
    may appear multiple times across several consecutive days.
  id: totrans-300
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据集包含了自 1848 年以来大多数风暴的信息。单个风暴可能在多个连续的日子中出现多次。
- en: '[PRE39]'
  id: totrans-301
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'We use pandas'' `groupby()` function to obtain the average location of every
    storm:'
  id: totrans-302
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用 pandas 的 `groupby()` 函数获取每个风暴的平均位置：
- en: '[PRE40]'
  id: totrans-303
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: We display the storms on a map with basemap. This toolkit allows us to easily
    project the geographical coordinates on the map.
  id: totrans-304
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用 basemap 在地图上显示风暴。这个工具包让我们能够轻松地将地理坐标投影到地图上。
- en: '[PRE41]'
  id: totrans-305
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '![How to do it...](img/4818OS_07_26.jpg)'
  id: totrans-306
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![如何操作...](img/4818OS_07_26.jpg)'
- en: 'To perform the kernel density estimation, we stack the `x` and `y` coordinates
    of the storms into a `(2, N)` array:'
  id: totrans-307
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了执行核密度估计，我们将风暴的 `x` 和 `y` 坐标堆叠成一个形状为 `(2, N)` 的数组：
- en: '[PRE42]'
  id: totrans-308
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'The `gaussian_kde()` routine returned a Python function. To see the results
    on a map, we need to evaluate this function on a 2D grid spanning the entire map.
    We create this grid with `meshgrid()`, and we pass the `x` and `y` values to the
    `kde` function. `kde` accepts a `(2, N)` array as input, requiring us to tweak
    the shape of the array:'
  id: totrans-309
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`gaussian_kde()` 函数返回了一个 Python 函数。为了在地图上查看结果，我们需要在覆盖整个地图的二维网格上评估该函数。我们通过 `meshgrid()`
    创建此网格，并将 `x` 和 `y` 值传递给 `kde` 函数。`kde` 接受一个形状为 `(2, N)` 的数组作为输入，因此我们需要调整数组的形状：'
- en: '[PRE43]'
  id: totrans-310
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Finally, we display the estimated density with `imshow()`:'
  id: totrans-311
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们使用 `imshow()` 显示估算的密度：
- en: '[PRE44]'
  id: totrans-312
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '![How to do it...](img/4818OS_07_27.jpg)'
  id: totrans-313
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![如何操作...](img/4818OS_07_27.jpg)'
- en: How it works...
  id: totrans-314
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'The **kernel density estimator** of a set of *n* points *{x[i]}* is given as:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 一组 *n* 点 *{x[i]}* 的 **核密度估计器** 表示为：
- en: '![How it works...](img/4818OS_07_28.jpg)'
  id: totrans-316
  prefs: []
  type: TYPE_IMG
  zh: '![它是如何工作的...](img/4818OS_07_28.jpg)'
- en: Here, *h>0* is a scaling parameter (the **bandwidth**) and *K(u)* is the **kernel**,
    a symmetric function that integrates to 1\. This estimator is to be compared with
    a classical histogram, where the kernel would be a *top-hat* function (a rectangle
    function taking its values in *{0,1}*), but the blocks would be located on a regular
    grid instead of the data points. For more information on kernel density estimator,
    refer to [http://en.wikipedia.org/wiki/Kernel_density_estimation](http://en.wikipedia.org/wiki/Kernel_density_estimation).
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*h>0* 是一个缩放参数（**带宽**），*K(u)* 是 **核函数**，它是一个对称函数，其积分为 1。这个估算器与经典的直方图进行比较，其中核是一个
    *顶帽* 函数（一个取值在 *{0,1}* 中的矩形函数），但是这些块将位于规则的网格上，而不是数据点上。关于核密度估计器的更多信息，请参考 [http://en.wikipedia.org/wiki/Kernel_density_estimation](http://en.wikipedia.org/wiki/Kernel_density_estimation)。
- en: Multiple kernels can be chosen. Here, we chose a **Gaussian kernel**, so that
    the KDE is the superposition of Gaussian functions centered on all the data points.
    It is an estimation of the density.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 可以选择多个核。这里，我们选择了 **高斯核**，因此 KDE 是以所有数据点为中心的高斯函数的叠加，它是密度的估算。
- en: 'The choice of the bandwidth is not trivial; there is a tradeoff between a too
    low value (small bias, high variance: overfitting) and a too high value (high
    bias, small variance: underfitting). We will return to this important concept
    of **bias-variance tradeoff** in the next chapter. For more information on the
    bias-variance tradeoff, refer to [http://en.wikipedia.org/wiki/Bias-variance_dilemma](http://en.wikipedia.org/wiki/Bias-variance_dilemma).'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 带宽的选择并非 trivial（简单的）；它在一个过低的值（小偏差，高方差：过拟合）和一个过高的值（高偏差，小方差：欠拟合）之间存在权衡。我们将在下一章回到这个重要的**偏差-方差权衡**概念。有关偏差-方差权衡的更多信息，请参考[http://en.wikipedia.org/wiki/Bias-variance_dilemma](http://en.wikipedia.org/wiki/Bias-variance_dilemma)。
- en: The following figure illustrates the KDE. The dataset contains four points in
    *[0,1]* (black lines). The estimated density is a smooth curve, represented here
    with multiple bandwidth values.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示意了KDE。数据集包含四个位于* [0,1] *的点（黑线）。估计的密度是平滑曲线，这里使用了多个带宽值表示。
- en: '![How it works...](img/4818OS_07_29.jpg)'
  id: totrans-321
  prefs: []
  type: TYPE_IMG
  zh: '![它是如何工作的...](img/4818OS_07_29.jpg)'
- en: Kernel density estimation
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 核密度估计
- en: Tip
  id: totrans-323
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: There are other KDE implementations in statsmodels and scikit-learn. You can
    find more information at [http://jakevdp.github.io/blog/2013/12/01/kernel-density-estimation/](http://jakevdp.github.io/blog/2013/12/01/kernel-density-estimation/).
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 在statsmodels和scikit-learn中有其他的KDE实现。你可以在[http://jakevdp.github.io/blog/2013/12/01/kernel-density-estimation/](http://jakevdp.github.io/blog/2013/12/01/kernel-density-estimation/)找到更多信息。
- en: See also
  id: totrans-325
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: The *Fitting a probability distribution to data with the maximum likelihood
    method* recipe
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用最大似然法拟合概率分布到数据*食谱'
- en: Fitting a Bayesian model by sampling from a posterior distribution with a Markov
    chain Monte Carlo method
  id: totrans-327
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过从后验分布中采样，使用马尔可夫链蒙特卡罗方法拟合贝叶斯模型
- en: In this recipe, we illustrate a very common and useful method for characterizing
    a posterior distribution in a Bayesian model. Imagine that you have some data
    and you want to obtain information about the underlying random phenomenon. In
    a frequentist approach, you could try to fit a probability distribution within
    a given family of distributions, using a parametric method such as the maximum
    likelihood method. The optimization procedure would yield parameters that maximize
    the probability of observing the data if given the null hypothesis.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 在本食谱中，我们展示了一种非常常见且有用的贝叶斯模型后验分布特征化方法。假设你有一些数据，想要获取关于潜在随机现象的信息。在频率学派的方法中，你可以尝试在给定的分布族中拟合一个概率分布，使用类似最大似然法的参数化方法。优化过程将得出最大化观察数据的概率的参数，假设为零假设。
- en: In a Bayesian approach, you consider the parameters themselves as random variables.
    Their prior distributions reflect your initial knowledge about these parameters.
    After the observations, your knowledge is updated, and this is reflected in the
    posterior distributions of the parameters.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 在贝叶斯方法中，你将参数本身视为随机变量。它们的先验分布反映了你对这些参数的初始知识。在观察后，你的知识得到更新，并在参数的后验分布中体现出来。
- en: A typical goal for Bayesian inference is to characterize the posterior distributions.
    Bayes' theorem gives an analytical way to do this, but it is often impractical
    in real-world problems due to the complexity of the models and the number of dimensions.
    A **Markov chain** **Monte Carlo** method, such as the **Metropolis-Hastings algorithm**,
    gives a numerical method to approximate a posterior distribution.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯推断的一个典型目标是特征化后验分布。贝叶斯定理提供了一种分析方法来实现这一目标，但由于模型的复杂性和维度的数量，它在实际问题中通常不切实际。**马尔可夫链**
    **蒙特卡罗**方法，例如**Metropolis-Hastings算法**，提供了一种数值方法来逼近后验分布。
- en: Here, we introduce the **PyMC** package, which gives an effective and natural
    interface for fitting a probabilistic model to data in a Bayesian framework. We
    will look at the annual frequency of storms in the northern Atlantic Ocean since
    the 1850s using data from NOAA, the US' National Oceanic and Atmospheric Administration.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，我们介绍了**PyMC**包，它提供了一种有效且自然的接口，用于在贝叶斯框架中拟合数据的概率模型。我们将使用来自美国国家海洋和大气管理局（NOAA）的数据，研究自1850年代以来北大西洋地区风暴的年频率。
- en: This recipe is largely inspired by a tutorial on PyMC's website (see the link
    in the *There's more…* section).
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 本食谱主要受PyMC官网教程的启发（请参见*更多内容...*部分的链接）。
- en: Getting ready
  id: totrans-333
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: You can find the instructions to install PyMC on the package's website. In this
    recipe, we will use PyMC2\. The new version (PyMC3) is still in development at
    the time of writing, and it is likely to be significantly different. For more
    information on PyMC, refer to [http://pymc-devs.github.io/pymc/](http://pymc-devs.github.io/pymc/).
    With Anaconda, you can try `conda install -c https://conda.binstar.org/pymc pymc`.
    Windows users can also find an installer at [www.lfd.uci.edu/~gohlke/pythonlibs/](http://www.lfd.uci.edu/~gohlke/pythonlibs/).
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在该软件包的网站上找到安装 PyMC 的说明。在本示例中，我们将使用 PyMC2。新版本（PyMC3）在编写时仍在开发中，可能会有显著差异。有关
    PyMC 的更多信息，请参阅[http://pymc-devs.github.io/pymc/](http://pymc-devs.github.io/pymc/)。对于
    Anaconda 用户，可以尝试`conda install -c https://conda.binstar.org/pymc pymc`。Windows
    用户也可以在[www.lfd.uci.edu/~gohlke/pythonlibs/](http://www.lfd.uci.edu/~gohlke/pythonlibs/)找到安装程序。
- en: You also need to download the *Storms* dataset from the book's GitHub repository
    at [https://github.com/ipython-books/cookbook-data](https://github.com/ipython-books/cookbook-data)
    and extract it in the current directory.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 你还需要从书籍的 GitHub 仓库下载*风暴*数据集，链接为[https://github.com/ipython-books/cookbook-data](https://github.com/ipython-books/cookbook-data)，并将其解压到当前目录。
- en: How to do it...
  id: totrans-336
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Let''s import the standard packages and PyMC:'
  id: totrans-337
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们导入标准包和 PyMC：
- en: '[PRE45]'
  id: totrans-338
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Let''s import the data with pandas:'
  id: totrans-339
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们使用 pandas 导入数据：
- en: '[PRE46]'
  id: totrans-340
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'With pandas, it only takes a single line of code to get the annual number of
    storms in the North Atlantic Ocean. We first select the storms in that basin (`NA`),
    then we group the rows by year (`Season`), and then we take the number of unique
    storms (`Serial_Num`), as each storm can span several days (the `nunique()` method):'
  id: totrans-341
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 pandas，只需一行代码就能得到北大西洋地区的年风暴数。我们首先选择该海域的风暴（`NA`），然后按年份（`Season`）对行进行分组，再计算独特风暴的数量（`Serial_Num`），因为每个风暴可能跨越几天（使用`nunique()`方法）：
- en: '[PRE47]'
  id: totrans-342
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: '![How to do it...](img/4818OS_07_30.jpg)'
  id: totrans-343
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![如何操作...](img/4818OS_07_30.jpg)'
- en: Now, we define our probabilistic model. We assume that storms arise following
    a time-dependent Poisson process with a deterministic rate. We assume that this
    rate is a piecewise-constant function that takes a first value `early_mean` before
    a switch point `switchpoint`, and a second value `late_mean` after that point.
    These three unknown parameters are treated as random variables (we will describe
    them more in the *How it works…* section).
  id: totrans-344
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们定义我们的概率模型。我们假设风暴遵循时间依赖的泊松过程，并且具有一个确定性的速率。我们假设该速率是一个分段常数函数，在切换点`switchpoint`之前取值`early_mean`，在切换点之后取值`late_mean`。这三个未知参数被视为随机变量（我们将在*它是如何工作的…*部分中详细描述）。
- en: Tip
  id: totrans-345
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: 'A Poisson process ([http://en.wikipedia.org/wiki/Poisson_process](http://en.wikipedia.org/wiki/Poisson_process))
    is a particular **point process**, that is, a stochastic process describing the
    random occurrence of instantaneous events. The Poisson process is fully random:
    the events occur independently at a given rate. See also [Chapter 13](ch13.html
    "Chapter 13. Stochastic Dynamical Systems"), *Stochastic Dynamical Systems*.'
  id: totrans-346
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 泊松过程（[http://en.wikipedia.org/wiki/Poisson_process](http://en.wikipedia.org/wiki/Poisson_process)）是一种特殊的**点过程**，即描述瞬时事件随机发生的随机过程。泊松过程是完全随机的：事件以给定速率独立发生。另见[第13章](ch13.html
    "第13章. 随机动力学系统")，*随机动力学系统*。
- en: '[PRE48]'
  id: totrans-347
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'We define the piecewise-constant rate as a Python function:'
  id: totrans-348
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将分段常数速率定义为一个 Python 函数：
- en: '[PRE49]'
  id: totrans-349
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: Finally, the observed variable is the annual number of storms. It follows a
    Poisson variable with a random mean (the rate of the underlying Poisson process).
    This fact is a known mathematical property of Poisson processes.
  id: totrans-350
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，观察变量是年风暴数。它遵循一个具有随机均值的泊松变量（底层泊松过程的速率）。这是泊松过程的一个已知数学性质。
- en: '[PRE50]'
  id: totrans-351
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Now, we use the MCMC method to sample from the posterior distribution, given
    the observed data. The `sample()` method launches the fitting iterative procedure:'
  id: totrans-352
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们使用 MCMC 方法从后验分布中进行采样，给定观察数据。`sample()`方法启动拟合的迭代过程：
- en: '[PRE51]'
  id: totrans-353
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: Let's plot the sampled Markov chains. Their stationary distribution corresponds
    to the posterior distribution we want to characterize.
  id: totrans-354
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们绘制采样的马尔科夫链。它们的平稳分布对应我们想要表征的后验分布。
- en: '[PRE52]'
  id: totrans-355
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: '![How to do it...](img/4818OS_07_31.jpg)'
  id: totrans-356
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![如何操作...](img/4818OS_07_31.jpg)'
- en: 'We also plot the distribution of the samples, which correspond to the posterior
    distributions of our parameters, after the data points have been taken into account:'
  id: totrans-357
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还绘制了样本的分布，这些样本对应我们参数的后验分布，数据点已被考虑在内：
- en: '[PRE53]'
  id: totrans-358
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: '![How to do it...](img/4818OS_07_32.jpg)'
  id: totrans-359
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![如何操作...](img/4818OS_07_32.jpg)'
- en: 'Taking the sample mean of these distributions, we get posterior estimates for
    the three unknown parameters, including the year where the frequency of storms
    suddenly increased:'
  id: totrans-360
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过这些分布的样本均值，我们得到三个未知参数的后验估计，包括风暴频率突然增加的年份：
- en: '[PRE54]'
  id: totrans-361
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Now, we can plot the estimated rate on top of the observations:'
  id: totrans-362
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以将估计的比率绘制在观察数据之上：
- en: '[PRE55]'
  id: totrans-363
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: '![How to do it...](img/4818OS_07_33.jpg)'
  id: totrans-364
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![如何做…](img/4818OS_07_33.jpg)'
- en: How it works...
  id: totrans-365
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: 'The general idea is to define a Bayesian probabilistic model and to fit it
    to the data. This model may be the starting point of an estimation or decision
    task. The model is essentially described by stochastic or deterministic variables
    linked together within a **direct acyclic graph** (**DAG**). *A* is linked to
    *B* if *B* is entirely or partially determined by *A*. The following figure shows
    the graph of the model used in this recipe:'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 一般思路是定义一个贝叶斯概率模型，并将其拟合到数据中。该模型可能是估计或决策任务的起点。模型本质上由通过**有向无环图**（**DAG**）连接的随机或确定性变量描述。*A*与*B*相连，如果*B*完全或部分由*A*决定。下图展示了本示例中使用的模型图：
- en: '[PRE56]'
  id: totrans-367
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: '![How it works...](img/4818OS_07_34.jpg)'
  id: totrans-368
  prefs: []
  type: TYPE_IMG
  zh: '![它是如何工作的…](img/4818OS_07_34.jpg)'
- en: Tip
  id: totrans-369
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: 'As you can see, PyMC can create graph representations of the models. You need
    to install GraphViz (refer to [www.graphviz.org](http://www.graphviz.org)), pydot,
    and pyparsing. Because of an unfortunate bug, you might need to install a specific
    version of pyparsing:'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，PyMC可以创建模型的图形表示。你需要安装GraphViz（参考[www.graphviz.org](http://www.graphviz.org)）、pydot和pyparsing。由于一个不幸的bug，你可能需要安装pyparsing的特定版本：
- en: '[PRE57]'
  id: totrans-371
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: Stochastic variables follow distributions that can be parameterized by fixed
    numbers or other variables in the model. Parameters may be random variables themselves,
    reflecting knowledge prior to the observations. This is the core of Bayesian modeling.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 随机变量遵循可以通过模型中的固定数字或其他变量进行参数化的分布。参数本身也可以是随机变量，反映了观察之前的知识。这是贝叶斯建模的核心。
- en: The goal of the analysis is to include the observations into the model in order
    to update our knowledge as more and more data is available. Although Bayes' theorem
    gives us an exact way to compute those posterior distributions, it is rarely practical
    in real-world problems. This is notably due to the complexity of the models. Alternatively,
    numerical methods have been developed in order to tackle this problem.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 分析的目标是将观察结果纳入模型中，以便随着更多数据的可用，更新我们的知识。尽管贝叶斯定理为我们提供了计算后验分布的精确方法，但在现实世界的问题中很少能实际应用。这主要是由于模型的复杂性。为了应对这一问题，已经开发了数值方法。
- en: The **Markov chain Monte Carlo** (**MCMC**) method used here allows us to sample
    from a complex distribution by simulating a Markov chain that has the desired
    distribution as its equilibrium distribution. The **Metropolis-Hastings algorithm**
    is a particular application of this method to our current example.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 这里使用的**马尔科夫链蒙特卡洛**（**MCMC**）方法使我们能够通过模拟一个具有所需分布作为平衡分布的马尔科夫链，从复杂的分布中采样。**梅特罗波利斯-哈斯廷斯算法**是这种方法在当前示例中的具体应用。
- en: This algorithm is implemented in the `MCMC` class in PyMC. The `burn` parameter
    determines how many initial iterations are thrown away. This is necessary because
    it takes a number of iterations for the Markov chain to converge to its equilibrium
    distribution. The `thin` parameter corresponds to the number of steps to skip
    in the evaluation of the distribution so as to minimize the autocorrelation of
    the samples. You will find more information at [http://pymc-devs.github.io/pymc/modelfitting.html](http://pymc-devs.github.io/pymc/modelfitting.html).
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 该算法在PyMC的`MCMC`类中实现。`burn`参数决定丢弃多少初始迭代次数。这是必要的，因为马尔科夫链需要经过若干次迭代才能收敛到其平衡分布。`thin`参数对应于在评估分布时跳过的步数，以尽量减少样本的自相关性。你可以在[http://pymc-devs.github.io/pymc/modelfitting.html](http://pymc-devs.github.io/pymc/modelfitting.html)找到更多信息。
- en: There's more...
  id: totrans-376
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多内容……
- en: 'Here are a few references:'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些参考资料：
- en: A great PyMC tutorial that we largely took inspiration from is available at
    [http://pymc-devs.github.io/pymc/tutorial.html](http://pymc-devs.github.io/pymc/tutorial.html)
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们大量借鉴的一个优秀的PyMC教程可以在[http://pymc-devs.github.io/pymc/tutorial.html](http://pymc-devs.github.io/pymc/tutorial.html)找到。
- en: A must-read free e-book on the subject, by Cameron Davidson-Pilon, entirely
    written in the IPython notebook, available at [http://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/](http://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/)
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由Cameron Davidson-Pilon撰写的关于该主题的必读免费电子书，完全使用IPython笔记本编写，可通过[http://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/](http://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/)获取。
- en: The Markov chain Monte Carlo method introduced at [http://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo](http://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo)
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在[http://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo](http://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo)介绍的马尔可夫链蒙特卡洛方法
- en: The Metropolis-Hastings algorithm introduced at [http://en.wikipedia.org/wiki/Metropolis-Hastings_algorithm](http://en.wikipedia.org/wiki/Metropolis-Hastings_algorithm)
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在[http://en.wikipedia.org/wiki/Metropolis-Hastings_algorithm](http://en.wikipedia.org/wiki/Metropolis-Hastings_algorithm)介绍的Metropolis-Hastings算法
- en: See also
  id: totrans-382
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: The *Getting started with Bayesian methods* recipe
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*贝叶斯方法入门*配方'
- en: Analyzing data with the R programming language in the IPython notebook
  id: totrans-384
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在IPython笔记本中使用R编程语言分析数据
- en: R ([www.r-project.org](http://www.r-project.org)) is a free domain-specific
    programming language for statistics. Its syntax is well-adapted to statistical
    modeling and data analysis. By contrast, Python's syntax is typically more convenient
    for general-purpose programming. Luckily, IPython allows you to have the best
    of both worlds. For example, you can insert R code snippets anywhere in a normal
    IPython notebook. You can continue using Python and pandas for data loading and
    wrangling, and switch to R to design and fit statistical models. Using R instead
    of Python for these tasks is more than a matter of programming syntax; R comes
    with an impressive statistical toolbox that is still unmatched by Python.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: R ([www.r-project.org](http://www.r-project.org))是一种免费的特定领域编程语言，用于统计学。其语法非常适合统计建模和数据分析。相比之下，Python的语法通常更适用于通用编程。幸运的是，IPython使你可以同时享受两者的优势。例如，你可以在普通的IPython笔记本中随时插入R代码片段。你可以继续使用Python和pandas进行数据加载和整理，然后切换到R来设计和拟合统计模型。使用R代替Python进行这些任务，不仅仅是语法问题；R自带一个令人印象深刻的统计工具箱，目前Python尚无匹敌。
- en: In this recipe, we will show how to use R from IPython, and we illustrate the
    most basic capabilities of R with a simple data analysis example.
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配方中，我们将展示如何在IPython中使用R，并通过一个简单的数据分析示例来展示R的最基本功能。
- en: Getting ready
  id: totrans-387
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: You need the statsmodels package for this recipe. You can find installation
    instructions in the previous recipe, *Fitting a probability distribution to data
    with the maximum likelihood method*.
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要statsmodels包来进行此配方的操作。你可以在之前的配方中找到安装说明，*使用最大似然方法拟合概率分布到数据*。
- en: You also need R. There are three steps to use R from IPython. First, install
    R and rpy2 (R to Python interface). Of course, you only need to do this step once.
    Then, to use R in an IPython session, you need to load the IPython R extension.
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 你还需要安装R。使用R从IPython的步骤有三个。首先，安装R和rpy2（R到Python的接口）。当然，这一步只需要做一次。然后，为了在IPython会话中使用R，你需要加载IPython的R扩展。
- en: Download R for your operating system from [http://cran.r-project.org/mirrors.html](http://cran.r-project.org/mirrors.html)
    and install it. On Ubuntu, you can do `sudo apt-get install r-base-dev`.
  id: totrans-390
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从[http://cran.r-project.org/mirrors.html](http://cran.r-project.org/mirrors.html)下载适合你操作系统的R并进行安装。在Ubuntu上，你可以执行`sudo
    apt-get install r-base-dev`。
- en: Download rpy2 from [http://rpy.sourceforge.net/rpy2.html](http://rpy.sourceforge.net/rpy2.html)
    and install it. With Anaconda on Linux, you can try `conda install -c https://conda.binstar.org/r
    rpy2`. Alternatively, you can do `pip install rpy2`.
  id: totrans-391
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从[http://rpy.sourceforge.net/rpy2.html](http://rpy.sourceforge.net/rpy2.html)下载rpy2并进行安装。在Linux上使用Anaconda时，你可以尝试`conda
    install -c https://conda.binstar.org/r rpy2`。或者，你也可以执行`pip install rpy2`。
- en: Then, to execute R code in an IPython notebook, execute `%load_ext rmagic` first.
  id: totrans-392
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，要在IPython笔记本中执行R代码，首先执行`%load_ext rmagic`。
- en: Tip
  id: totrans-393
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: rpy2 does not appear to work well on Windows. We recommend using Linux or Mac
    OS X.
  id: totrans-394
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: rpy2似乎在Windows上不太兼容。我们建议使用Linux或Mac OS X。
- en: How to do it...
  id: totrans-395
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Here, we will use the following workflow: first, we load data from Python.
    Then, we use R to design and fit a model, and to make some plots in the IPython
    notebook. We could also load data from R, or design and fit a statistical model
    with Python''s statsmodels package, and so on. In particular, the analysis we
    do here could be done entirely in Python, without resorting to the R language.
    This recipe merely shows the basics of R and illustrates how R and Python can
    play together within an IPython session.'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将使用以下工作流程：首先，从 Python 加载数据。然后，使用 R 设计和拟合模型，并在 IPython 笔记本中绘制一些图表。我们也可以从
    R 加载数据，或者使用 Python 的 statsmodels 包设计和拟合统计模型，等等。特别地，我们在这里做的分析本可以完全在 Python 中进行，而无需依赖
    R 语言。这个示例仅展示了 R 的基础知识，并说明了 R 和 Python 如何在 IPython 会话中协同工作。
- en: 'Let''s load the *longley* dataset with the statsmodels package. This dataset
    contains a few economic indicators in the US from 1947 to 1962\. We also load
    the IPython R extension:'
  id: totrans-397
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们使用 statsmodels 包加载 *longley* 数据集。这个数据集包含了美国从 1947 年到 1962 年的一些经济指标。我们还加载了
    IPython 的 R 扩展：
- en: '[PRE58]'
  id: totrans-398
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: We define `x` and `y` as the exogeneous (independent) and endogenous (dependent)
    variables, respectively. The endogenous variable quantifies the total employment
    in the country.
  id: totrans-399
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将 `x` 和 `y` 定义为外生（自变量）和内生（因变量）变量。内生变量量化了国家的总就业量。
- en: '[PRE59]'
  id: totrans-400
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'For convenience, we add the endogenous variable to the `x` DataFrame:'
  id: totrans-401
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了方便，我们将内生变量添加到 `x` 数据框中：
- en: '[PRE60]'
  id: totrans-402
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'We will make a simple plot in R. First, we need to pass Python variables to
    R. We can use the `%R -i var1,var2` magic. Then, we can call R''s `plot()` command:'
  id: totrans-403
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将在 R 中绘制一个简单的图表。首先，我们需要将 Python 变量传递给 R。我们可以使用 `%R -i var1,var2` 魔法。然后，我们可以调用
    R 的 `plot()` 命令：
- en: '[PRE61]'
  id: totrans-404
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: '![How to do it...](img/4818OS_07_35.jpg)'
  id: totrans-405
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![如何操作...](img/4818OS_07_35.jpg)'
- en: 'Now that the data has been passed to R, we can fit a linear model to the data.
    The `lm()` function lets us perform a linear regression. Here, we want to express
    `totemp` (total employment) as a function of the country''s GNP:'
  id: totrans-406
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，数据已传递给 R，我们可以对数据进行线性回归。`lm()` 函数让我们进行线性回归。在这里，我们希望将 `totemp`（总就业）表示为国家 GNP
    的函数：
- en: '[PRE62]'
  id: totrans-407
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: '![How to do it...](img/4818OS_07_36.jpg)'
  id: totrans-408
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![如何操作...](img/4818OS_07_36.jpg)'
- en: How it works...
  id: totrans-409
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The `-i` and `-o` options of the `%R` magic allow us to pass variables back
    and forth between IPython and R. The variable names need to be separated by commas.
    You can find more information about the `%R` magic in the documentation available
    at [http://rpy.sourceforge.net/](http://rpy.sourceforge.net/).
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: '`%R` 魔法中的 `-i` 和 `-o` 选项允许我们在 IPython 和 R 之间传递变量。变量名称需要用逗号分隔。你可以在 [http://rpy.sourceforge.net/](http://rpy.sourceforge.net/)
    的文档中找到有关 `%R` 魔法的更多信息。'
- en: 'In R, the tilde (`~`) expresses the dependence of a dependent variable upon
    one or several independent variables. The `lm()` function allows us to fit a simple
    linear regression model to the data. Here, `totemp` is expressed as a function
    of `gnp`:'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 在 R 中，波浪符号 (`~`) 表示因变量对一个或多个自变量的依赖关系。`lm()` 函数允许我们对数据拟合一个简单的线性回归模型。在这里，`totemp`
    被表示为 `gnp` 的函数：
- en: '![How it works...](img/4818OS_07_37.jpg)'
  id: totrans-412
  prefs: []
  type: TYPE_IMG
  zh: '![它是如何工作的...](img/4818OS_07_37.jpg)'
- en: Here, *b* (intercept) and *a* are the coefficients of the linear regression
    model. These two values are returned by `fit$coefficients` in R, where `fit` is
    the fitted model.
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*b*（截距）和 *a* 是线性回归模型的系数。这两个值由 `fit$coefficients` 在 R 中返回，其中 `fit` 是拟合的模型。
- en: 'Our data points do not satisfy this relation exactly, of course. The coefficients
    are chosen so as to minimize the error between this linear prediction and the
    actual values. This is typically done by minimizing the following least squares
    error:'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我们的数据点并不完全满足这个关系。系数的选择是为了最小化这个线性预测与实际值之间的误差。这通常通过最小化以下最小二乘误差来完成：
- en: '![How it works...](img/4818OS_07_38.jpg)'
  id: totrans-415
  prefs: []
  type: TYPE_IMG
  zh: '![它是如何工作的...](img/4818OS_07_38.jpg)'
- en: 'The data points are *(gnp[i]**, totemp[i])* here. The coefficients *a* and
    *b* that are returned by `lm()` make this sum minimal: they fit the data best.'
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 数据点是 *(gnp[i], totemp[i])*。由 `lm()` 返回的系数 *a* 和 *b* 使得这个和最小化：它们最适合数据。
- en: There's more...
  id: totrans-417
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'Regression is an important statistical concept that we will see in greater
    detail in the next chapter. Here are a few references:'
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 回归分析是一个重要的统计概念，我们将在下一章中详细讨论。以下是一些参考资料：
- en: Regression analysis on Wikipedia, available at [http://en.wikipedia.org/wiki/Regression_analysis](http://en.wikipedia.org/wiki/Regression_analysis)
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 维基百科上的回归分析，链接：[http://en.wikipedia.org/wiki/Regression_analysis](http://en.wikipedia.org/wiki/Regression_analysis)
- en: Least squares method on Wikipedia, available at [en.wikipedia.org/wiki/Linear_least_squares_(mathematics)](http://en.wikipedia.org/wiki/Linear_least_squares_(mathematics))
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 维基百科上的最小二乘法，网址为 [en.wikipedia.org/wiki/Linear_least_squares_(mathematics)](http://en.wikipedia.org/wiki/Linear_least_squares_(mathematics))
- en: R is an excellent platform for advanced statistics. Python has a few statistical
    packages such as pandas and statsmodels that implement many common features, but
    the number of statistical toolboxes in R remains unmatched by Python at this time.
    Yet, Python has a much wider range of possibilities outside of statistics and
    is an excellent general-purpose language that comes with an impressive number
    of various packages.
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: R 是一个非常适合高级统计分析的平台。虽然 Python 有一些统计包，如 pandas 和 statsmodels，能够实现许多常见功能，但目前 R
    提供的统计工具箱数量仍然无可匹敌。然而，Python 在统计学以外有着更广泛的应用范围，并且是一个出色的通用编程语言，配备了大量不同的包。
- en: Thanks to the multilanguage capabilities of IPython, you don't necessarily have
    to choose between those languages. You can keep using Python and switch to R when
    you need highly specific statistical features that are still missing in Python.
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 IPython 支持多种语言，你不必在这些语言之间做出选择。你可以继续使用 Python，在需要 Python 仍未涵盖的高度特定统计功能时，切换到
    R。
- en: 'Here are a few references about R:'
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些关于 R 的参考资料：
- en: Introduction to R available at [http://cran.r-project.org/doc/manuals/R-intro.html](http://cran.r-project.org/doc/manuals/R-intro.html)
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: R 介绍，网址为 [http://cran.r-project.org/doc/manuals/R-intro.html](http://cran.r-project.org/doc/manuals/R-intro.html)
- en: R tutorial available at [www.cyclismo.org/tutorial/R/](http://www.cyclismo.org/tutorial/R/)
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: R 教程，网址为 [www.cyclismo.org/tutorial/R/](http://www.cyclismo.org/tutorial/R/)
- en: CRAN, or Comprehensive R Archive Network, containing many packages for R, available
    at [http://cran.r-project.org](http://cran.r-project.org)
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CRAN（综合 R 存档网络），包含许多 R 包，网址为 [http://cran.r-project.org](http://cran.r-project.org)
- en: IPython and R tutorial available at [http://nbviewer.ipython.org/github/ipython/ipython/blob/master/examples/Builtin%20Extensions/R%20Magics.ipynb](http://nbviewer.ipython.org/github/ipython/ipython/blob/master/examples/Builtin%20Extensions/R%20Magics.ipynb)
  id: totrans-427
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以在 [http://nbviewer.ipython.org/github/ipython/ipython/blob/master/examples/Builtin%20Extensions/R%20Magics.ipynb](http://nbviewer.ipython.org/github/ipython/ipython/blob/master/examples/Builtin%20Extensions/R%20Magics.ipynb)
    查阅 IPython 和 R 教程
- en: See also
  id: totrans-428
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参见
- en: The *Exploring a dataset with pandas and matplotlib* recipe
  id: totrans-429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用 pandas 和 matplotlib 探索数据集* 方案'
