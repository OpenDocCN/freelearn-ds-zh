- en: Distributed Computing, Parallel Computing, and HPCC
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分布式计算、并行计算和 HPCC
- en: Since our society has entered a data-intensive era (that is, a big data era),
    we face larger and larger datasets. For this reason, companies and users are considering
    what kinds of tools they could use to speed up the process when dealing with data.
    One obvious solution is to increase their data storage capacity. Unfortunately,
    there is a huge cost associated with this. The other solutions include distributed
    computing and some ways to accelerate our process.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们的社会已经进入数据密集型时代（即大数据时代），我们面临着越来越大的数据集。因此，企业和用户正在考虑在处理数据时可以使用哪些工具来加速过程。一个显而易见的解决方案是增加他们的数据存储容量。不幸的是，这涉及到巨大的成本。其他解决方案包括分布式计算以及一些加速我们的过程的方法。
- en: 'In this chapter, we''ll cover the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论以下主题：
- en: Introduction to distributed versus parallel computing
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分布式计算与并行计算的简介
- en: Understanding MPI
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解 MPI
- en: Parallel processing in Python
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python 中的并行处理
- en: Compute nodes
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算节点
- en: Anaconda add-ons
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Anaconda 附加组件
- en: Introduction to HPCC
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: HPCC 简介
- en: Introduction to distributed versus parallel computing
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分布式计算与并行计算的简介
- en: Distributed computing is a subfield of computer science that studies distributed
    systems and models in which components located on networked computers communicate
    and coordinate their actions by passing messages. The components interact with
    each other in order to achieve a common goal.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式计算是计算机科学的一个子领域，研究分布式系统和模型，其中位于网络计算机上的组件通过传递消息进行通信和协调操作。这些组件相互作用，以实现共同的目标。
- en: 'It is worthwhile to discuss another phrase: parallel computing. Parallel computing
    is more tightly coupled to multi-threading, or how to make full use of a single
    CPU, while distributed computing refers to the notion of divide and conquer, executing
    subtasks on different machines, and then merging the results.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 值得讨论的另一个短语是：并行计算。并行计算与多线程紧密相关，或如何充分利用单个 CPU，而分布式计算则涉及分而治之的概念，在不同的机器上执行子任务，然后合并结果。
- en: Since we have entered a so-called big data era, it seems that the distinction
    is melting. In fact, nowadays, many systems use a combination of parallel and
    distributed computing.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们已经进入了所谓的大数据时代，似乎这种区分正在消失。事实上，现在许多系统采用了并行计算和分布式计算的结合方式。
- en: Task view for parallel processing
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 并行处理的任务视图
- en: For R, there is a task view called **High-Performance and Parallel Computing
    with R**. Recall that a task view is a set of R programs around a specific topic.
    To find the task view for **High-Performance and parallel computing using R**,
    we go to [http://r-project.org](http://r-project.org), click on CRAN on the left-hand
    side, choose a nearby mirror location, and click on Packages and Task Views.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 R，存在一个任务视图叫做**使用 R 进行高性能和并行计算**。回顾一下，任务视图是围绕特定主题的一组 R 程序。为了找到**使用 R 进行高性能和并行计算**的任务视图，我们访问
    [http://r-project.org](http://r-project.org)，点击左侧的 CRAN，选择一个附近的镜像位置，然后点击 Packages
    和 Task Views。
- en: 'After double-clicking on Task Views, we can see the following list—to save
    space, only the top task views are shown:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 双击任务视图后，我们可以看到以下列表——为了节省空间，仅显示了顶部的任务视图：
- en: '![](img/d1975c7c-6005-4f4b-b03c-1d708bbc33b5.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d1975c7c-6005-4f4b-b03c-1d708bbc33b5.png)'
- en: 'After double-clicking on the related task view (**HighPerformanceComputing**),
    we can see the following screenshot—to save space, only the top few lines are
    shown:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 双击相关的任务视图（**HighPerformanceComputing**）后，我们可以看到以下截图——为了节省空间，仅显示了顶部几行：
- en: '**![](img/d90b13fd-6d24-43a1-97a9-2d76077101a1.png)**'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**![](img/d90b13fd-6d24-43a1-97a9-2d76077101a1.png)**'
- en: 'The preceding task view contains a list of packages, grouped by various topics
    that could be useful for **high-performance computing** (**HPC**) with R. In this
    context, the task view maintainers define high-performance computing quite loosely
    as just about anything related to pushing R a little further: using compiled code,
    parallel computing (in both explicit and implicit modes), working with large objects
    as well as profiling. The aforementioned task view can be downloaded at [https://CRAN.R-project.org/view=HighPerformanceComputing](https://CRAN.R-project.org/view=HighPerformanceComputing).
    As we have discussed in previous chapters, we could use the following command
    to install all related R packages:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的任务视图包含了一些包的列表，这些包按照不同的主题进行分组，可能对**高性能计算**（**HPC**）与R语言的结合有用。在此背景下，任务视图的维护者将高性能计算的定义相当宽泛，只要是与推动R向前发展相关的内容，都会涉及其中：使用编译代码、并行计算（包括显式和隐式模式）、处理大对象以及性能分析。上述任务视图可以在[https://CRAN.R-project.org/view=HighPerformanceComputing](https://CRAN.R-project.org/view=HighPerformanceComputing)下载。如前几章所讨论的，我们可以使用以下命令来安装所有相关的R包：
- en: '[PRE0]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: On May 14, 2018, by running the previous code, 217 related R packages were downloaded
    and installed.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 2018年5月14日，通过运行之前的代码，下载并安装了217个相关的R包。
- en: Sample programs in Python
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Python中的示例程序
- en: 'For Python programs in parallel computing, we can visit the *IPython in-depth
    Tutorial* at [https://github.com/ipython/ipython-in-depth](https://github.com/ipython/ipython-in-depth).
    After downloading the ZIP file and unzipping it, we can find programs related
    to parallel computing (refer to the following two screenshot):'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Python并行计算程序，我们可以访问*IPython深入教程*，网址为[https://github.com/ipython/ipython-in-depth](https://github.com/ipython/ipython-in-depth)。下载ZIP文件并解压后，我们可以找到与并行计算相关的程序（参考下面的两张截图）：
- en: '![](img/73fc867a-93cb-481c-b9d0-39c60d129af7.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](img/73fc867a-93cb-481c-b9d0-39c60d129af7.png)'
- en: 'The preceding screenshot shows a few subdirectories, while the following one
    shows 19 programs including both Jupyter Notebook and Python programs:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的截图显示了几个子目录，而下面的截图展示了包括Jupyter Notebook和Python程序在内的19个程序：
- en: '![](img/4c367b33-a0f3-4d3a-b1e4-570d71e336b9.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4c367b33-a0f3-4d3a-b1e4-570d71e336b9.png)'
- en: Understanding MPI
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解MPI
- en: Usually, a parallel algorithm needs to move data between different engines.
    One way to do so is by doing a pull and then a push using the direct view. However,
    this method is quite slow since all the data has to go through the controller
    to the client and then back through the controller, to its final destination.
    A much better way of moving data between engines is to use a message passing library,
    such as the **Message Passing Interface** (**MPI**). IPython's parallel computing
    architecture has been designed to integrate with MPI. To download and install
    Windows MPI, readers can refer to [https://msdn.microsoft.com/en-us/library/bb524831%28v=vs.85%29.aspx.](https://msdn.microsoft.com/en-us/library/bb524831%28v=vs.85%29.aspx)
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，平行算法需要在不同引擎之间移动数据。做到这一点的一个方法是通过直接视图先进行拉取再推送。然而，这种方法非常缓慢，因为所有数据都必须经过控制器到达客户端，然后再通过控制器返回到最终目标。一个更好的方法是使用消息传递库，比如**消息传递接口**（**MPI**）。IPython的并行计算架构已经设计成可以与MPI集成。要下载并安装Windows版本的MPI，读者可以参考[https://msdn.microsoft.com/en-us/library/bb524831%28v=vs.85%29.aspx](https://msdn.microsoft.com/en-us/library/bb524831%28v=vs.85%29.aspx)。
- en: In addition, you could install the `mpi4py` package.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，你还可以安装`mpi4py`包。
- en: R package Rmpi
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: R包 Rmpi
- en: 'To find a demo associated with the `Rmpi` package, we could issue the following
    two lines:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 要找到与`Rmpi`包相关的示例，我们可以执行以下两行代码：
- en: '[PRE1]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'After hitting *Enter*, we will see the following output:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 按下*Enter*键后，我们将看到以下输出：
- en: '![](img/0a82682f-9ddf-4a78-b981-d30b6cd9321a.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0a82682f-9ddf-4a78-b981-d30b6cd9321a.png)'
- en: 'For the first function, called `cslavePI`, we know that we should copy `cslavePI.c`
    in Rmpi library directory to your working directory and compile it as `mpicc -o
    cslavePI cslavePI.c`. To find the path of Rmpi, we issue the `find.package()`
    function (refer to the code and the result in the following code):'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第一个函数，叫做`cslavePI`，我们知道应该将`cslavePI.c`从Rmpi库目录复制到工作目录，并使用`mpicc -o cslavePI
    cslavePI.c`编译它。要找到Rmpi的路径，我们可以执行`find.package()`函数（参考以下代码和结果）：
- en: '[PRE2]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Note that different readers will get quite different paths. We can use `demo(cslavePI)`
    to find out its function. Refer to the code and the related output, as follows:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，不同的读者将得到不同的路径。我们可以使用`demo(cslavePI)`来查找它的功能。参考代码和相关的输出，如下所示：
- en: '![](img/682f484b-36c5-45e7-b627-2d1c26fa579f.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](img/682f484b-36c5-45e7-b627-2d1c26fa579f.png)'
- en: The mpicc software is used to compile and link MPI programs written in C.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: mpicc软件用于编译和链接用C语言编写的MPI程序。
- en: R package plyr
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: R包plyr
- en: 'The objective of the `plyr` R package is about the split-apply-combine paradigm
    for R. This is quite common in data analysis: we solve a complex problem by breaking
    it down into small pieces, doing something to each piece, and then combining the
    results back together again. The following is an example borrowed from its menu
    with a minor modification:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '`plyr` R包的目标是实现R中的拆分-应用-组合范式。这在数据分析中非常常见：我们通过将一个复杂问题分解为小块，对每个块做一些处理，然后将结果重新合并。以下是一个来自其菜单的示例，经过小幅修改：'
- en: '[PRE3]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'To save space, only the graph is shown here:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 为了节省空间，这里仅显示图形：
- en: '![](img/0a600249-cef2-49df-9ae0-b0c3f73ea2d1.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0a600249-cef2-49df-9ae0-b0c3f73ea2d1.png)'
- en: 'The `arrange()` function orders a data frame by its columns (refer to the following
    code):'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '`arrange()`函数按数据框的列进行排序（参考以下代码）：'
- en: '[PRE4]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: R package parallel
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: R包parallel
- en: 'First, let''s look at the simple usage of an R function called `lapply()` (refer
    to the following code):'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们看一下R函数`lapply()`的简单用法（参考以下代码）：
- en: '[PRE5]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The meaning is clear: we have an input size of `1`, `2`, and `3` and we assign
    them to three functions. The following example is a slightly more complex one:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 含义很明确：我们有`1`、`2`和`3`这三个输入值，并将它们分配给三个函数。以下示例稍微复杂一些：
- en: '[PRE6]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The first couple of lines are shown here:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 前几行输出如下所示：
- en: '![](img/c2d63458-d0d0-4d95-871a-572d99c2fc8f.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c2d63458-d0d0-4d95-871a-572d99c2fc8f.png)'
- en: 'The following example is borrowed from *Gordon* (2015):'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例来自于*Gordon*（2015）：
- en: '[PRE7]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'In the preceding code, the `makeCluster()` function will set up the cluster.
    The `parLapply()` function calls the parallel version of `lapply()` or `parLapply()`
    functions. The output is shown here:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，`makeCluster()`函数将设置集群。`parLapply()`函数调用`lapply()`的并行版本或`parLapply()`函数。输出如下所示：
- en: '[PRE8]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'For the following code, we will see an error message:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 对于以下代码，我们将看到一个错误信息：
- en: '[PRE9]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The error message is as follows:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 错误信息如下：
- en: '[PRE10]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: To correct it, the base variable will be added (refer to the following code).
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 为了修正这个问题，将添加基变量（参考以下代码）。
- en: '[PRE11]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'To save space, the output will not be shown here. The following is another
    example to see the difference between calling the `lapply()` and `mclapply()`
    functions:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 为了节省空间，输出将在此不显示。以下是另一个示例，展示调用`lapply()`和`mclapply()`函数之间的区别：
- en: '[PRE12]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The output is shown here:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下所示：
- en: '[PRE13]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'In the preceding code, the `lappy()` and `mclappy()` functions are used. The
    `mclapply()` function is a parallelized version of the `lapply()` function. It
    returns a list of the same length as `X`, each element of which is the result
    of applying `FUN` to the corresponding element of `X`. The following program is
    borrowed from [http://www.smart-stats.org/wiki/parallel-computing-cluster-using-r](http://www.smart-stats.org/wiki/parallel-computing-cluster-using-r)
    with minor modifications. Note that the program is run on a UNIX instead of a
    PC:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，使用了`lappy()`和`mclappy()`函数。`mclapply()`函数是`lapply()`函数的并行化版本。它返回一个与`X`长度相同的列表，每个元素都是将`FUN`应用于`X`中相应元素的结果。以下程序来自于[http://www.smart-stats.org/wiki/parallel-computing-cluster-using-r](http://www.smart-stats.org/wiki/parallel-computing-cluster-using-r)，并经过了少量修改。请注意，程序是在UNIX上运行的，而不是PC：
- en: '[PRE14]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The related output is shown here:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 相关输出如下所示：
- en: '[PRE15]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: R package snow
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: R包snow
- en: 'This package is for **Simple Network of Workstations** (**SNOW**). Let''s take
    a look at a program associated with destruction:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 该包用于**简单工作站网络**（**SNOW**）。让我们来看一个与销毁相关的程序：
- en: '[PRE16]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The `makeSOCKcluster()` function is used to start and stop a `snow` cluster
    and to set default cluster options. The `clusterApply()` calls the function on
    the first cluster node with arguments `seq[[1]] and ...`, on the second node with
    `seq[[2]] and ...`, and so on. If the length of `seq` is greater than the number
    of nodes in the cluster, then cluster nodes are recycled. A list of the results
    is returned; the length of the result list will be equal to the length of `seq`.
    The `clusterCall()` calls a function with identical arguments on each node in
    the cluster `cl` and returns a list of the results. The `clusterEvalQ()` function
    evaluates a literal expression on each cluster node. It's a cluster version of
    `evalq`, and is a convenience function defined in terms of `clusterCall()`.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '`makeSOCKcluster()` 函数用于启动和停止 `snow` 集群，并设置默认的集群选项。`clusterApply()` 在第一个集群节点上调用该函数，参数为
    `seq[[1]] and ...`，在第二个节点上调用 `seq[[2]] and ...`，以此类推。如果 `seq` 的长度大于集群节点的数量，则会回收集群节点。返回一个结果列表；结果列表的长度将等于
    `seq` 的长度。`clusterCall()` 在集群 `cl` 中每个节点上使用相同的参数调用函数，并返回结果列表。`clusterEvalQ()`
    函数在每个集群节点上评估一个字面表达式。它是 `evalq` 的集群版本，是一个基于 `clusterCall()` 的便捷函数。'
- en: Parallel processing in Python
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Python 中的并行处理
- en: The following example is about computing π digits and is borrowed from the website [http://ipyparallel.readthedocs.io/en/latest/demos.html#parallel-examples](http://ipyparallel.readthedocs.io/en/latest/demos.html#parallel-examples).
    Since the first part needs a program called `one_digit_freqs()` function, we could
    run a Python program called `pidigits.py` contained at `.../ipython-ipython-in-depth-4d98937\examples\Parallel
    Computing\pi`, and this path depends on where the reader downloaded and saved
    his/her files.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例关于计算 π 的数字，摘自网站 [http://ipyparallel.readthedocs.io/en/latest/demos.html#parallel-examples](http://ipyparallel.readthedocs.io/en/latest/demos.html#parallel-examples)。由于第一部分需要一个名为
    `one_digit_freqs()` 的函数，我们可以运行一个名为 `pidigits.py` 的 Python 程序，该程序包含在 `.../ipython-ipython-in-depth-4d98937\examples\Parallel
    Computing\pi` 路径下，该路径取决于读者下载并保存文件的位置。
- en: 'To complete our part, we simply include it in the first part of the program,
    as shown here:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 为了完成我们的部分，我们只需将其包含在程序的第一部分，如下所示：
- en: '[PRE17]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The related graph is shown here:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 相关的图表如下所示：
- en: '![](img/b303d68c-8b04-4977-85cf-315fd84d7a40.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b303d68c-8b04-4977-85cf-315fd84d7a40.png)'
- en: Parallel processing for word frequency
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 词频的并行处理
- en: 'First, let''s look at a simple Python program to find out the first most frequently
    used word in an input text file. We randomly chose Da Vinci Code at [http://www.gutenberg.org/files/5000/5000-8.txt](http://www.gutenberg.org/files/5000/5000-8.txt).
    Assume that the downloaded novel is saved under `c:/temp/daVinci.txt`. The following
    Python code will list the top 10 most frequent words:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们来看一个简单的 Python 程序，找出输入文本文件中最常用的单词。我们随机选择了《达·芬奇密码》，可以在 [http://www.gutenberg.org/files/5000/5000-8.txt](http://www.gutenberg.org/files/5000/5000-8.txt)
    找到。假设下载的小说保存在 `c:/temp/daVinci.txt` 下。以下 Python 代码将列出最常用的前 10 个单词：
- en: '[PRE18]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The related output is shown here:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 相关的输出结果如下所示：
- en: '[PRE19]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Parallel Monte-Carlo options pricing
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 并行蒙特卡洛期权定价
- en: This example is from the sample programs in Python discussed earlier. The notebook
    shows how to use the `ipyparallel` package to do Monte-Carlo options pricing in
    parallel. The notebook computes the price of a large number of options for different
    strike prices and volatilities.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这个示例来自之前讨论的 Python 示例程序。该笔记本展示了如何使用 `ipyparallel` 包进行蒙特卡洛期权定价的并行计算。该笔记本计算了不同执行价格和波动率下大量期权的价格。
- en: 'To save space, only the first several lines of code are given here:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 为了节省空间，这里只给出了代码的前几行：
- en: '[PRE20]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'To run it, click on IPython Clusters. After clicking IPython Clusters on the
    right-hand side, we will see the following screenshot:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行它，点击 IPython Clusters。在右侧点击 IPython Clusters 后，我们将看到以下截图：
- en: '![](img/e6bb005d-ba65-4693-8d5e-3f64735b711b.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e6bb005d-ba65-4693-8d5e-3f64735b711b.png)'
- en: 'We can click on Start for the default. The number of engines will show a value
    of `4`, as follows:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以点击“启动”以使用默认设置。引擎数量会显示为 `4`，如下所示：
- en: '![](img/cc7c234c-79b1-4f87-a690-0d9993eadedf.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![](img/cc7c234c-79b1-4f87-a690-0d9993eadedf.png)'
- en: 'Now, we go back to our uploaded Jupyter Notebook for the parallel monte-carlo
    options pricing. In total, there are four output images. To save space, only the
    first one is shown here:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们回到我们上传的 Jupyter Notebook，进行并行蒙特卡洛期权定价。总共有四个输出图像。为了节省空间，这里只显示第一个：
- en: '![](img/14427f22-3abb-43e0-802b-841df9ec89c9.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](img/14427f22-3abb-43e0-802b-841df9ec89c9.png)'
- en: 'Note that the payoff function for an Asian put using stock average price as
    the final terminal price is given here, where *Put(Asian)* is the Asian put option,
    *K* is the exercise price, and ![](img/0c79a345-2dd8-47c8-a4a3-7529f93e9281.png) is
    the average price over the path:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，使用股票平均价格作为最终终端价格的亚洲看跌期权的支付函数如下所示，其中 *Put(Asian)* 是亚洲看跌期权，*K* 是执行价格，而 ![](img/0c79a345-2dd8-47c8-a4a3-7529f93e9281.png)
    是路径上的平均价格：
- en: '![](img/e1554d15-5e87-4001-945f-93db9761280c.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e1554d15-5e87-4001-945f-93db9761280c.png)'
- en: Compute nodes
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计算节点
- en: A compute node provides the ephemeral storage, networking, memory, and processing
    resources that can be consumed by virtual machine instances. The cloud system
    supports two types of compute nodes: **ESX clusters**, where clusters are created
    in VMware vCenter Server, and **KVM compute nodes**, where KVM compute nodes are
    created manually. In the previous chapter, we mentioned the concept of the cloud.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 计算节点提供短暂存储、网络、内存和处理资源，这些资源可以被虚拟机实例消耗。云系统支持两种类型的计算节点：**ESX 集群**，其中集群在 VMware
    vCenter Server 中创建，以及 **KVM 计算节点**，其中 KVM 计算节点是手动创建的。在前一章中，我们提到了云的概念。
- en: Within a cloud environment, which is quite useful for a more complex project,
    compute nodes form the core of resources. Typically, these notes supply the processing,
    memory, network, and storage that virtual machine instances need. When an instance
    is created, it is matched to a compute node with the available resources. A compute
    node can host multiple instances until all of its resources are consumed.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在云环境中，这对于更复杂的项目非常有用，计算节点是资源的核心。通常，这些节点提供虚拟机实例所需的处理、内存、网络和存储。当实例被创建时，它会与具有可用资源的计算节点匹配。一个计算节点可以托管多个实例，直到其所有资源被消耗完。
- en: Anaconda add-on
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Anaconda 附加组件
- en: The following information is from the Anaconda Addon Development Guide.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 以下信息来自 Anaconda 附加组件开发指南。
- en: An Anaconda add-on is a Python package containing a directory with an `__init__.py`
    file and other source directories (sub packages) inside. Because Python allows
    importing each package name only once, the package top-level directory name must
    be unique. At the same time, the name can be arbitrary, because add-ons are loaded
    regardless of their name; the only requirement is that they must be placed in
    a specific directory.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: Anaconda 附加组件是一个 Python 包，其中包含一个包含 `__init__.py` 文件和其他源目录（子包）的目录。因为 Python 只允许每个包名称导入一次，所以包的顶级目录名称必须是唯一的。同时，名称可以是任意的，因为附加组件会根据名称加载；唯一的要求是它们必须放在特定的目录中。
- en: 'The suggested naming convention for add-ons is therefore similar to that of
    Java packages or D-Bus service names: prefix the add-on name with the reversed
    domain name of your organization, using underscores (_) instead of dots so that
    the directory name is a valid identifier for a Python package. An example add-on
    name following these suggestions would therefore be, for example, `org_fedora_hello_world`.
    This convention follows the recommended naming scheme for Python package and module
    names. Interested readers can find lots of information about Anaconda add-ons
    at [https://rhinstaller.github.io/anaconda-addon-development-guide/index.html#sect-anaconda-introduction-addons](https://rhinstaller.github.io/anaconda-addon-development-guide/index.html#sect-anaconda-introduction-addons).'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，建议的附加组件命名约定类似于 Java 包或 D-Bus 服务名称：将附加组件名称的前缀设置为贵组织的反向域名，使用下划线（_）代替点号，这样目录名称就是一个有效的
    Python 包标识符。根据这些建议的命名约定，附加组件名称示例如 `org_fedora_hello_world`。此命名约定遵循了 Python 包和模块名称的推荐命名方案。感兴趣的读者可以在
    [https://rhinstaller.github.io/anaconda-addon-development-guide/index.html#sect-anaconda-introduction-addons](https://rhinstaller.github.io/anaconda-addon-development-guide/index.html#sect-anaconda-introduction-addons)
    查找有关 Anaconda 附加组件的更多信息。
- en: Introduction to HPCC
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: HPCC 简介
- en: HPCC stands for **High-Performance Computing Cluster**. It is also known as
    **Data Analytics Supercomputer** (**DAS**), an open source, data-intensive computing
    system platform developed by LexisNexis Risk Solutions. The HPCC platform incorporates
    a software architecture implemented on computing clusters to provide high-performance,
    data-parallel processing design for various applications using big data. The HPCC
    platform includes system configurations to support both parallel batch data processing
    (Thor) and high-performance online query applications using indexed data files
    (Roxie). The HPCC platform also includes a data-centric declarative programming
    language for parallel data processing called ECL.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: HPCC 代表 **高性能计算集群**。它也被称为 **数据分析超级计算机** (**DAS**)，是 LexisNexis Risk Solutions
    开发的一个开源、数据密集型计算系统平台。HPCC 平台包含一种在计算集群上实现的软件架构，提供高性能、数据并行处理设计，用于使用大数据的各种应用。HPCC
    平台包括支持并行批量数据处理（Thor）和高性能在线查询应用程序（Roxie）的系统配置，这些应用程序使用索引数据文件。HPCC 平台还包括一种数据中心声明式编程语言，用于并行数据处理，称为
    ECL。
- en: You can see a simple example of using Wharton's HPCC system at [https://research-it.wharton.upenn.edu/documentation/](https://research-it.wharton.upenn.edu/documentation/).
    Wharton's HPC Cluster (HPCC) provides access to advanced computational research
    hardware and software for Wharton faculty, faculty collaborators and research
    assistants, and Wharton doctoral candidates. It is designed for simple and parallel
    processing across a large set of tightly integrated hardware with dedicated networking
    and storage.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在 [https://research-it.wharton.upenn.edu/documentation/](https://research-it.wharton.upenn.edu/documentation/)
    查看 Wharton HPCC 系统的一个简单示例。Wharton 的 HPC 集群（HPCC）为 Wharton 教职工、教职工合作者、研究助理以及 Wharton
    博士生提供先进的计算研究硬件和软件。它旨在通过一组紧密集成的硬件，配备专用的网络和存储，进行简单且并行的处理。
- en: 'For more information about the hardware, refer to the Hardware page. HPCC users
    have access to a number of scientific, mathematics, and analytic software, including
    MATLAB, Mathematica, R, Stata, and SAS. MySQL server access can be provided as
    well. The HPCC also has Fortran, C, and C++ compilers in GNU and Intel versions.
    The following is a simple procedure to link to their HPCC platform:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 关于硬件的更多信息，请参阅硬件页面。HPCC 用户可以访问多种科学、数学和分析软件，包括 MATLAB、Mathematica、R、Stata 和 SAS。也可以提供
    MySQL 服务器访问权限。HPCC 还具备 GNU 和 Intel 版本的 Fortran、C 和 C++ 编译器。以下是连接到 HPCC 平台的简单步骤：
- en: First, download and install FortClient and MobaXterm software
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，下载并安装 FortClient 和 MobaXterm 软件
- en: 'Connect to the Wharton VPN via FortClient (as shown in the following screenshot):'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过 FortClient 连接到 Wharton VPN（如下图所示）：
- en: '![](img/43d91c0d-f130-4be2-8c89-87cdbca7bb73.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![](img/43d91c0d-f130-4be2-8c89-87cdbca7bb73.png)'
- en: 'After connecting, the following screen will appear:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 连接后，以下界面将出现：
- en: '![](img/5d7368e8-3d4f-4aa4-b302-7c36789c8295.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5d7368e8-3d4f-4aa4-b302-7c36789c8295.png)'
- en: 'Use MobaXterm software to connect to Wharton''s HPCC platform. Here, we assume
    that you have an account with Wharton (refer to the following screenshot):'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 MobaXterm 软件连接到 Wharton 的 HPCC 平台。这里假设你已经有 Wharton 的账号（参见下图）：
- en: '![](img/076af6c0-16d0-4c35-b086-c4f286b5839f.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![](img/076af6c0-16d0-4c35-b086-c4f286b5839f.png)'
- en: 'Now, we can connect, as shown in the following screenshot:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以进行连接，如下图所示：
- en: '![](img/60abcd45-55a4-4969-8956-1104013ad39c.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![](img/60abcd45-55a4-4969-8956-1104013ad39c.png)'
- en: Now, the users will write their own programs to take advantage of HPCC to speed
    up their research and experiments. For more information, refer to the documentation
    at [https://research-it.wharton.upenn.edu/documentation/](https://research-it.wharton.upenn.edu/documentation/).
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，用户将编写自己的程序，利用 HPCC 加速他们的研究和实验。更多信息，请参考 [https://research-it.wharton.upenn.edu/documentation/](https://research-it.wharton.upenn.edu/documentation/)
    上的文档。
- en: Summary
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we have discussed several R packages such as `plyr`, `snow`,
    `Rmpi`, and `parallel`, and the Python package `ipyparallel`. In addition, we
    mentioned compute nodes, project add-ons, parallel processing, and HPCC.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了几个 R 包，如 `plyr`、`snow`、`Rmpi` 和 `parallel`，以及 Python 包 `ipyparallel`。此外，我们还提到了计算节点、项目插件、并行处理和
    HPCC。
- en: Now we've arrived at the end of our journey. We wish you good luck for the amazing
    endeavors you'll be taking up with the knowledge you've got from this book.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经走到了旅程的尽头。我们祝愿你在未来的冒险中好运，并且能够利用从本书中学到的知识去做一些了不起的事情。
- en: Review questions and exercises
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回顾问题和练习
- en: What is distributed computing? Why it is useful?
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是分布式计算？它有什么用？
- en: From where could we get a task view for parallel computing?
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以从哪里获得并行计算的任务视图？
- en: From the task view related to parallel computing, we can find many R packages.
    Identify a few of them. Install two and find a few examples of using these two
    packages.
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从与并行计算相关的任务视图中，我们可以找到许多 R 包。找出其中的一些包。安装两个并展示使用这两个包的示例。
- en: 'Conduct a word frequency analysis using: The Count of Monte Cristo by Alexandre
    Dumas (input file is at [http://www.gutenberg.org/files/1184/1184-0.txt](http://www.gutenberg.org/files/1184/1184-0.txt)).'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下方式进行词频分析：亚历山大·仲马的《基督山伯爵》（输入文件在 [http://www.gutenberg.org/files/1184/1184-0.txt](http://www.gutenberg.org/files/1184/1184-0.txt)）。
- en: From where could we find more information about Anaconda add-ons?
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以从哪里找到更多关于 Anaconda 插件的信息？
- en: What is HPCC and how does it work?
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是 HPCC，它是如何工作的？
- en: How do we find the path of an installed R package?
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们如何找到已安装的 R 包的路径？
- en: 'In the sample Jupyter notebook about parallel Monte-Carlo options pricing,
    the related Asian options are defined here, where `call(Asian)` is the Asian put
    option, `Put(Asian)`, *K* is the exercise price, and ![](img/67daf5c0-5b94-4153-8c39-3bd8ce0c65c0.png) is
    the average price over the path:'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在关于并行蒙特卡洛期权定价的示例 Jupyter 笔记本中，相关的亚洲期权在此定义，其中 `call(Asian)` 是亚洲看跌期权，`Put(Asian)`，*K*
    是行使价格，且 ![](img/67daf5c0-5b94-4153-8c39-3bd8ce0c65c0.png) 是路径上的平均价格：
- en: '![](img/3f973221-3119-4640-a6f2-e2e066b0c4f8.png)![](img/e4300d58-1141-4032-8b57-f16d53141e02.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3f973221-3119-4640-a6f2-e2e066b0c4f8.png)![](img/e4300d58-1141-4032-8b57-f16d53141e02.png)'
- en: 'Write a Jupyter notebook to use the following definitions of Asian options:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 编写一个 Jupyter 笔记本，使用以下亚洲期权的定义：
- en: '![](img/8e51ae73-ccd6-44c8-b4be-02834221af98.png)![](img/32cafa72-593a-4f75-833d-89c737bd1aa0.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8e51ae73-ccd6-44c8-b4be-02834221af98.png)![](img/32cafa72-593a-4f75-833d-89c737bd1aa0.png)'
- en: 'In this chapter, we mentioned that the following three lines could be used
    to download all R packages related to high-performance computing:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在本章中，我们提到可以使用以下三行代码来下载与高性能计算相关的所有 R 包：
- en: '[PRE21]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Try this and report how many R packages are downloaded.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试这个并报告下载了多少个 R 包。
- en: Find more examples associated with the R package called `Rmpi`.
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查找与 R 包 `Rmpi` 相关的更多示例。
- en: Run the sample Jupyter notebook called `Using MPI` with `IPython Parallel.ipynb`.
    Explain its meaning.
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行名为 `Using MPI` 的示例 Jupyter 笔记本，文件为 `IPython Parallel.ipynb`。解释其含义。
- en: The R `doRNG` package provides functions to perform reproducible parallel `foreach`
    loops, using independent random streams as generated by the package `rstream`,
    suitable for the different `foreach` back ends. Download and install this and
    other related packages. Show a few examples.
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: R 的 `doRNG` 包提供了执行可重现的并行 `foreach` 循环的函数，使用由 `rstream` 包生成的独立随机流，适用于不同的 `foreach`
    后端。下载并安装此包及其他相关包。展示一些示例。
