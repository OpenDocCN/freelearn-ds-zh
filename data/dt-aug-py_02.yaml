- en: '2'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '2'
- en: Biases in Data Augmentation
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据增强中的偏差
- en: As **artificial intelligence** (**AI**) becomes embedded in our society, biases
    in AI systems will adversely affect your quality of life. These AI systems, particularly
    in **deep learning** (**DL**) and generative AI, depend on the input data you
    are using to extend data augmentation.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 随着 **人工智能**（**AI**）在我们的社会中逐渐深入，它在 AI 系统中的偏差将不利于你的生活质量。这些 AI 系统，特别是在 **深度学习**（**DL**）和生成式
    AI 中，依赖于你用来扩展数据增强的输入数据。
- en: AI systems rely heavily on data to make decisions, and if the data used to train
    the system is biased, then the AI system will make unfair decisions. It will lead
    to the unjust treatment of individuals or groups and perpetuate systemic inequalities.
    AI plays a decisive role in life-changing decisions, such as how much your monthly
    mortgage insurance rate is, whether you can be approved for a car loan, your application
    qualification for a job, who will receive government assistance, how much you
    pay for milk, what you read on social media newsfeeds, and how much oil your country
    will import or export, to name a few.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: AI 系统在做出决策时高度依赖数据，如果用于训练系统的数据存在偏差，那么 AI 系统将做出不公平的决策。这将导致对个人或群体的不公正对待，并 perpetuate
    系统性的不平等。AI 在改变生活的决策中扮演着决定性角色，例如每月的房贷保险费是多少，是否可以获得汽车贷款批准，求职资格，谁能获得政府援助，牛奶的价格，你在社交媒体新闻源上看到的内容，以及你国家的石油进口或出口量，等等。
- en: By learning data biases before diving deep into learning data augmentation,
    you will be able to help develop ethical and fair AI systems that benefit society.
    It will help you make informed decisions about the data they use and prevent the
    perpetuation of existing biases and inequalities. Additionally, understanding
    data bias will help you make informed decisions about the data collection process
    and ensure it’s representative and unbiased.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在深入学习数据增强之前了解数据偏差，你将能够帮助开发出有益于社会的道德和公平的 AI 系统。这将帮助你做出关于数据使用的明智决策，防止现有偏差和不平等的延续。此外，理解数据偏差将帮助你做出关于数据收集过程的明智决策，确保数据具有代表性且不带偏见。
- en: Data biases may be problematic for data scientists and college students because
    they are seldom discussed or unavailable in college courses. There is no ready-made
    fairness matrix to follow programmatically for data augmentation. Maybe by using
    the latest generative AI, the biases may even originate from computer systems
    and not be so heavily due to humans.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 数据偏差可能对数据科学家和大学生来说是一个问题，因为它们很少在大学课程中讨论或没有提供。没有现成的公平矩阵可以用于数据增强的编程。也许通过使用最新的生成式
    AI，偏差甚至可能来源于计算机系统，而不完全是由人类造成的。
- en: There are many strategies to provide protected and safe software products and
    services, but AI systems require new processes and perspectives. Trustworthy and
    responsible AI is about fairness, ethical design, and minimizing biases. Achieving
    trustworthy AI starts with transparency, datasets, **test, evaluation, validation,
    and verification** (**TEVV**), as defined by the *Standard for Identifying and
    Managing Bias in Artificial Intelligence, National Institute of Standards and
    Technology (NIST)* special publication 1270.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 提供受保护和安全的软件产品与服务有许多策略，但 AI 系统需要新的流程和视角。值得信赖和负责任的 AI 是关于公平、道德设计以及最小化偏差。实现值得信赖的
    AI 从透明度、数据集、**测试、评估、验证和确认**（**TEVV**）开始，正如 *《人工智能偏差识别与管理标准，国家标准与技术研究所（NIST）》*
    特别出版物 1270 所定义。
- en: Fun fact
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 趣闻
- en: In 2016, Twitter corrupted the Microsoft AI chatbot **Tay** in 1 day. Microsoft
    created Tay for online casual and playful conversation. Tay was designed to learn
    and take input from raw, uncurated data and comments from the web. The Twitter
    community thought it would be fun to teach Tay with misogynistic, racist, and
    violent tweets. To this day, Tay is a poster child for lessons learned in data
    bias input for AI. As one blogger put it, “*Flaming garbage pile in, flaming garbage*
    *pile out*.”
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 2016 年，Twitter 在 1 天内让微软的 AI 聊天机器人 **Tay** 变得堕落。微软创建 Tay 主要用于在线的休闲和玩乐对话。Tay
    被设计为从网络中的未经整理的数据和评论中学习和获取输入。Twitter 社区觉得用厌女症、种族主义和暴力的推文来教 Tay 很有趣。直到今天，Tay 仍然是关于数据偏差输入教训的典型案例。正如一位博主所说：“*火焰垃圾堆进，火焰垃圾堆出*。”
- en: This chapter will provide a crash course on recognizing the differences in **computation**,
    **human**, and **systemic** biases. We will learn about bias but not practice
    how to compute bias programmatically. The fairness and confusion matrixes are
    used to gauge AI’s prediction in terms of **true-positive**, **false-positive**,
    **true-negative**, and **false-negative**. However, the fairness and confusion
    matrixes are used for building AI systems, not data augmentation. While looking
    at real-world text datasets, we will attempt to write Python code for a fairness
    matrix with word counts and misspelled words, but for the most part, we will rely
    on Pluto and your observations to name the biases in image and text data.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将为你提供一个快速教程，帮助你认识到**计算**、**人类**和**系统性**偏差的区别。我们将了解偏差的概念，但不会练习如何编程计算偏差。公平性和混淆矩阵用于衡量AI预测的**真正正例**、**假正例**、**真负例**和**假负例**。然而，公平性和混淆矩阵是用于构建AI系统的，而不是数据增强。在观察真实世界的文本数据集时，我们将尝试编写Python代码来生成包含单词计数和拼写错误的公平性矩阵，但大多数情况下，我们将依赖Pluto和你的观察来命名图像和文本数据中的偏差。
- en: The Python code in this chapter will focus on helping you learn how to download
    real-world datasets from the *Kaggle* website. The later chapters will reuse the
    helper and wrapper functions shown in this chapter.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的Python代码将重点帮助你学习如何从*Kaggle*网站下载真实世界的数据集。后续章节将重复使用本章中展示的辅助函数和封装函数。
- en: 'By the end of this chapter, you will have a deeper appreciation for a balanced
    dataset. In particular, we will cover the following topics:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将更加深刻地理解平衡数据集。特别是，我们将涵盖以下主题：
- en: Computational biases
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算偏差
- en: Human biases
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人类偏差
- en: Systemic biases
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 系统性偏差
- en: Python Notebook
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python Notebook
- en: Image biases
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像偏差
- en: Text biases
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文本偏差
- en: Pluto will begin with the easier of the three biases – computational biases.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 冥王星将从三种偏差中最容易的——计算偏差开始。
- en: Computational biases
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计算偏差
- en: Before we start, a fair warning is that you will not be learning how to write
    Python code to calculate a numeric score for computational bias in datasets. The
    primary focus of this chapter is to help you learn how to fetch real-world datasets
    from the Kaggle website and use observation to spot biases in data. There will
    be some coding to calculate the fairness or balance in the datasets.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始之前，提前提醒一下，你不会学习如何编写Python代码来计算数据集中的计算偏差的数值评分。本章的主要目的是帮助你学习如何从Kaggle网站获取真实世界的数据集，并通过观察来发现数据中的偏差。虽然会有一些代码用于计算数据集中的公平性或平衡性，但重点还是在观察。
- en: For example, we will compute the word counts per record and the misspelled words
    in the text datasets.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 比如，我们将计算文本数据集中每条记录的单词计数和拼写错误的单词。
- en: You may think all biases are the same, but it helps to break them into three
    distinct categories. The bias categories’ differences can be subtle when first
    reading about data biases. One method to help distinguish the differences is to
    think about how you could remove or reduce the error in AI forecasting. For example,
    computational biases can be resolved by changing the datasets, while systemic
    biases can be fixed by changing the deployment and access strategy of the AI system.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能认为所有的偏差都是一样的，但将它们分为三类会更有帮助。偏差类别之间的差异在初次阅读数据偏差时可能很微妙。一个帮助区分这些差异的方法是思考你如何去除或减少AI预测中的误差。例如，计算偏差可以通过改变数据集来解决，而系统性偏差则可以通过改变AI系统的部署和访问策略来解决。
- en: Computational biases originate from the unevenness in the dataset for the general
    population. In other words, it favors or underrepresents one group or data category.
    The prejudices could be unintentional or deep-seated. The data is skewed higher
    than the usual randomness. As a result, the algorithm will be plagued with higher
    false-positive and false-negative predictions.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 计算偏差源于数据集中针对一般人群的不均衡。换句话说，它偏向或低估了某个群体或数据类别。这些偏见可能是无意的，也可能是根深蒂固的。数据比通常的随机性更为偏斜。因此，算法将面临更高的假正例和假负例预测问题。
- en: '**Dataset representation** (**DR**) and **machine learning algorithms** (**MLAs**)
    are two types of computation biases. DR is easier to understand and more closely
    related to augmenting data. Many of the examples in this section are from DR biases.
    MLA is specific to a project and can’t be generalized.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据集表示** (**DR**) 和 **机器学习算法** (**MLAs**) 是两种计算偏差。DR更容易理解，并且与数据增强更为密切相关。本节中的许多例子都来自DR偏差。MLA则特定于某个项目，无法广泛推广。'
- en: 'Here are a few examples of computational biases:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些计算偏差的例子：
- en: '*Kodak’s Shirley Cards Set Photography’s Skin-Tone Standard* from the mid-1970s
    is one of the more famous examples of technology biases. The **Shirley card**
    from Kodak is used to calibrate the image, such as skin tone and shadow, before
    printing people’s pictures. It is a part of the setting up process and is frequently
    used at the printing facility. Shirley is the name of an employee at Kodak. Because
    of this innocent and unintentional discrimination, for three decades, photos printed
    in the USA did not show the true skin tone of anyone who did not have a white
    skin tone.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*从1970年代中期开始的柯达“雪莉卡片”设定了摄影的肤色标准*是技术偏见中较为著名的例子之一。**雪莉卡片**是柯达用来校准图像的工具，如肤色和阴影，目的是在打印人们的照片之前进行调整。它是设置过程的一部分，并且在打印设施中经常使用。雪莉是柯达的一名员工的名字。由于这种无心且非故意的歧视，三十年来，美国打印的照片并未显示出非白人肤色的真实肤色。'
- en: '*Google Open AI DALL-E 2*, from 2022, is an AI model that generates pictures
    from texts. For example, you can type the input as *a hippo eating broccoli wearing
    a pink polka dot swimsuit*, and DALL-E 2 will generate the picture. Even with
    this highly touted technology breakthrough, there are prejudices, as reported
    by the *NBC Tech* news written by Jake Traylor in the article *No quick fix: How
    OpenAI’s DALL-E 2 illustrated the challenges of bias in AI*. For example, in DALL-E,
    a builder produced images featuring only men, while the caption of a flight attendant
    generated only images of women. DALL-E 2 additionally inherits various biases
    from its training data, and its outputs sometimes reinforce societal stereotypes.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*谷歌开放AI DALL-E 2*，是2022年发布的一个AI模型，可以根据文本生成图片。例如，你可以输入*一只吃西兰花穿粉色波点泳衣的河马*，DALL-E
    2就会生成这张图片。尽管这一技术突破备受推崇，但也存在偏见，正如*NBC科技*新闻的杰克·特雷洛（Jake Traylor）在文章《没有快捷解决方案：OpenAI的DALL-E
    2如何揭示AI偏见的挑战》中所报道的那样。例如，在DALL-E中，某个构建者生成的图像只展示了男性，而某个航班乘务员的标题则只生成了女性的图像。DALL-E
    2还继承了其训练数据中的各种偏见，有时其生成的结果会加剧社会刻板印象。'
- en: The United Kingdom’s **Information Commissioner’s Office** (**ICO**) disclosed
    on July 2022 that AI automation’s potential discrimination could have grave consequences
    for society. For example, it could result in unfair or biased job rejection, bank
    loans, or university acceptance. In addition, coinciding with the ICO is the *Guardian
    newspaper* article *UK data watchdog investigates whether AI systems show racial
    bias*, by Dan Milmo. The ICO’s goal is to create a fair and ethical AI system
    guideline.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 英国**信息专员办公室**（**ICO**）在2022年7月披露，AI自动化的潜在歧视可能会对社会产生严重后果。例如，这可能导致不公平或带有偏见的工作拒绝、银行贷款或大学录取。此外，与ICO同时发布的还有*卫报*的文章《英国数据监管机构调查AI系统是否存在种族偏见》，由丹·米尔莫（Dan
    Milmo）撰写。ICO的目标是制定一个公平且符合伦理的AI系统指南。
- en: Fun fact
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的事实
- en: 'Using generative AI and **Stable Diffusion** on *GitHub*, forked by Duc Haba
    on Python Notebook, Pluto wrote, “*A cute adorable baby hippo made of crystal
    ball with low poly eye surrounded by glowing aura highly detailed intricated concept
    art trending art station 8k eating broccoli in the city wearing pink polka dots.*”
    After running repeatedly with slightly altering wordings, his favorite generated
    images were created. These are the original images:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 使用生成式AI和**稳定扩散**在*GitHub*上的Python Notebook，由Duc Haba分支，冥王星写道：“*一只用水晶球做成的可爱小河马，带有低多边形的眼睛，四周环绕着发光的光晕，细节精致复杂的概念艺术，流行艺术站点8K，吃西兰花，身穿粉色波点衣服，位于城市中。*”经过多次运行并稍微调整措辞后，他最喜欢的生成图像被创作出来。这些是原始图像：
- en: '![Figure 2.1 – Generative AI, Stable Diffusion forked](img/B17990_02_01.jpg)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.1 – 生成式AI，稳定扩散分支](img/B17990_02_01.jpg)'
- en: Figure 2.1 – Generative AI, Stable Diffusion forked
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.1 – 生成式AI，稳定扩散分支
- en: '*Figure 2**.1* displays a hippo eating broccoli. On that fun note, we have
    concluded this section on computational biases. Pluto is a digital dog but can
    speak about human biases, which he’ll do in the next section.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 2**.1* 显示了一只吃西兰花的河马。在这个有趣的插曲后，我们已结束关于计算偏见的这一部分。冥王星是一个数字狗，但它能讲述人类的偏见，接下来它将在下一部分进行讲解。'
- en: Human biases
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人类偏见
- en: Human biases are even harder to calculate using Python code. There is no Python
    or other language library for computing a numeric score for human bias in a dataset.
    We rely on observation to spot such human biases. It is time-consuming to manually
    study a particular dataset before deriving possible human biases. We could argue
    that it is not a programmer’s or data scientist’s job because there is no programable
    method to follow.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Python 代码计算人类偏见更为困难。没有 Python 或其他编程语言库可以计算数据集中的人类偏见的数值评分。我们依赖观察来识别这些人类偏见。在推导出可能的人类偏见之前，手动研究特定数据集非常耗时。我们可以辩称，这不是程序员或数据科学家的工作，因为没有可编程的方法可供遵循。
- en: Human biases reflect systematic errors in human thought. In other words, when
    you develop an AI system, you are limited by the algorithm and data chosen by
    you. Thus, the prediction of a limited outcome could be biased by your selections.
    These prejudices are implicit in individuals, groups, institutions, businesses,
    education, and government.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 人类偏见反映了人类思维中的系统性错误。换句话说，当你开发一个人工智能系统时，你会受到你所选择的算法和数据的限制。因此，有限结果的预测可能会因为你的选择而产生偏见。这些偏见在个人、群体、机构、企业、教育和政府中隐性存在。
- en: There is a wide variety of human biases. Cognitive and perceptual biases show
    themselves in all domains and are not unique to human interactions with AI. There
    is an entire field of study centered around biases and heuristics in thinking,
    decision-making, and behavioral economics, such as anchoring bias and confirmation
    bias.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 人类偏见种类繁多。认知偏见和感知偏见在各个领域都表现得很明显，并不仅限于人类与人工智能的互动。围绕思维、决策和行为经济学中的偏见与启发式方法，有一个专门的研究领域，如锚定偏见和确认偏见。
- en: As data scientists that are augmenting data, by simply being aware of the inherent
    human prejudices, we can call out the flaws in the data before developing and
    training the model.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 作为增强数据的数据科学家，仅仅意识到固有的人类偏见，我们就可以在开发和训练模型之前指出数据中的缺陷。
- en: 'Here are a few examples of human biases in real-world AI systems:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是现实世界中人工智能系统中人类偏见的几个例子：
- en: The **People’s Republic of China** (**PRC**) implemented facial recognition
    AI in the province of Xinjiang to monitor ethnic minorities such as the Uyghurs.
    It is the first known example of a government using AI specifically for racial
    profiling. The system is flawed with discrimination as it identifies the poor
    and the old as ethnic minorities in false-positive predictions. Compounding the
    problem is when Myanmar bought the PRC system to crack down on political dissidents,
    as the **Council on Foreign Relations** reported in their *The Importance of International
    Norms in Artificial Intelligence Ethics* article in 2022.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**中华人民共和国**（**PRC**）在新疆省实施了面部识别人工智能，用于监控少数民族，如维吾尔族。这是已知的第一个政府专门使用人工智能进行种族画像的例子。该系统存在缺陷，存在歧视，因为它将贫穷和年长的人误判为少数民族的假阳性预测。问题的复杂化在于缅甸购买了中国的系统来打压政治异见者，正如**外交关系委员会**在其2022年发表的《人工智能伦理中国际规范的重要性》一文中所报告的那样。'
- en: To stop advertisers from abusing the AI Facebook newsfeed, Meta limited the
    target algorithm from using health, race, ethnicity, political affiliation, religion,
    and sexual orientation. **NPR** reported in the article that Facebook had scrapped
    advertised targeting based on politics, race, and other “*sensitive*” topics.
    The changes took effect on January 10 across Meta’s apps, including Facebook,
    Instagram, Messenger, and the Audience Network. It is reported that advertisers
    microtargeted people with tailored messages. In other words, the advertisers excluded
    people based on protected characteristics and targeted advertisements using anti-Semitic
    phrases.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了阻止广告商滥用 Facebook 新闻推送算法，Meta 限制了广告定向算法，禁止使用健康、种族、民族、政治立场、宗教和性取向等信息。**NPR**在文章中报道，Facebook已经取消了基于政治、种族及其他“*敏感*”话题的广告定向。此项变化已于1月10日生效，涵盖
    Meta 的所有应用程序，包括 Facebook、Instagram、Messenger 和 Audience Network。据报道，广告商对人群进行了微定向，传递量身定制的信息。换句话说，广告商基于受保护的特征排除了某些人群，并使用反犹太的短语定向广告。
- en: The article *Racial Bias Found in a Major Health Care Risk Algorithm*, published
    by **Scientific American** on October 4, 2019, found many biases in the healthcare
    system. Black patients would pay more for interventions and emergency visits.
    In addition to incurring higher costs, black patients would receive lesser-quality
    care. AI scientists used race and wealth in historical data to train the healthcare
    system. Thus, the system displayed prejudice toward minority groups and affected
    200 million Americans.
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 《**科学美国人**》于2019年10月4日发布的文章《在一个主要的医疗风险算法中发现种族偏见》揭示了医疗系统中的许多偏见。黑人患者在干预和急诊就诊时支付更多费用。除了支付更高的费用，黑人患者还会获得较低质量的护理。AI科学家使用历史数据中的种族和财富信息来训练医疗系统。因此，该系统对少数群体表现出偏见，影响了2亿美国人。
- en: Fun challenge
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 趣味挑战
- en: 'This challenge is a thought experiment. How could you build an AI without biases,
    given a substantial budget and ample time? Hint: think about when we had world
    peace or no crime in our city. It can’t be an absolute answer. It has to be a
    level of acceptance.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这个挑战是一个思想实验。如果给定充足的预算和时间，你如何建立一个没有偏见的AI？提示：想想我们曾经拥有过世界和平或没有犯罪的城市的时候。它不可能是一个绝对的答案。它必须是一个接受度的水平。
- en: It may be challenging to see the differences between human and computational
    biases. Some biases are not one or the other. In other words, they are not mutually
    exclusive – you can have both human and computational biases in one AI system.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 看清人类偏见与计算偏见之间的区别可能具有挑战性。有些偏见并不是单一的。换句话说，它们不是互相排斥的——你可以在一个AI系统中同时存在人类偏见和计算偏见。
- en: Human biases are difficult to identify because they shape our perception of
    the world. However, systemic biases may be easier to address in theory, but may
    be challenging to put into practice.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 人类偏见很难识别，因为它们塑造了我们对世界的感知。然而，系统性偏见在理论上可能更容易解决，但在实践中可能具有挑战性。
- en: Systemic biases
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 系统性偏见
- en: If we cannot conceive a method to calculate computational and human biases,
    then it is impossible to devise an algorithm to compute systemic biases programmatically.
    We must rely on human judgment to spot the systemic bias in the dataset. Furthermore,
    it has to be specific to a particular dataset with a distinct AI prediction goal.
    There are no generalization rules and no fairness matrix to follow.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们无法构思出一种方法来计算计算偏见和人类偏见，那么就不可能设计出一个算法来程序化地计算系统性偏见。我们必须依赖人类判断来发现数据集中的系统性偏见。此外，它必须特定于某个特定的数据集，并具有明确的AI预测目标。没有通用的规则，也没有公平矩阵可循。
- en: Systemic biases in AI are the most notorious of all AI biases. Simply put, systemic
    discrimination is when a business, institution, or government limits access to
    AI benefits to a group and excludes other underserved groups. It is insidious
    because it hides behind society’s existing rules and norms. Institutional racism
    and sexism are the most common examples. Another AI accessibility issue in everyday
    occurrences is limiting or excluding admission to people with disabilities, such
    as the sight and hearing impaired.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: AI中的系统性偏见是所有AI偏见中最臭名昭著的一种。简单来说，系统性歧视指的是当一个企业、机构或政府限制某一群体获得AI的利益，同时排除其他弱势群体时的情况。它具有隐蔽性，因为它隐藏在社会现有的规则和规范背后。制度性种族主义和性别歧视是最常见的例子。另一个在日常生活中常见的AI可及性问题是限制或排除残疾人士的入场，比如视力和听力受限的人群。
- en: The poor and the underserved have no representation in the process of developing
    the AI system, but they are forced to accept the AI’s prediction or forecast.
    These AIs make significant life decisions, including those for the poor and underserved,
    such as how much to pay for a car or health insurance, options for housing or
    a business bank loan, or whether they are eligible for medical treatments.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 贫困群体和弱势群体在AI系统开发过程中没有代表权，但他们却被迫接受AI的预测或预测结果。这些AI会做出重大生活决策，包括针对贫困和弱势群体的决策，比如汽车或健康保险的费用、住房或商业银行贷款的选择，或者是否有资格接受医疗治疗。
- en: 'Here are a few real-world examples of AI systemic biases:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些AI系统性偏见的现实例子：
- en: The article *Researchers use AI to predict crime, biased policing in major U.S.
    cities like L.A.*, published by The Los Angeles Times on July 4, 2022, found AI
    biases in policing crimes. The University of Chicago’s AI crime prediction system
    does not address law enforcement systemic biases. The forecast for possible crime
    locations, or hot spots, is based on flawed input and environmental factors associated
    with poor neighborhoods, rather than the actual locations where crimes are committed.
    The AI reflects the systemic bias in law enforcement practices and procedures.
    Thus, it forecasts a higher crime rate in poor neighborhoods because of the police’s
    prior systemic biases.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 2022年7月4日，《洛杉矶时报》发布的文章*研究人员利用人工智能预测犯罪，揭示洛杉矶等美国大城市的偏见性执法*发现了执法中的人工智能偏见。芝加哥大学的AI犯罪预测系统没有解决执法中的系统性偏见。对潜在犯罪地点或热点的预测基于有缺陷的输入和与贫困社区相关的环境因素，而不是犯罪发生的实际地点。人工智能反映了执法实践和程序中的系统性偏见。因此，它预测贫困社区的犯罪率较高，因为警察在过去的系统性偏见。
- en: The US Department of Justice reviewed the **Prisoner Assessment Tool Targeting
    Estimated Risk and Needs** (**PATTERN**) and found systemic bias in who can access
    PATTERN. This was discussed in *Addressing an Algorithmic PATTERN of Bias*, published
    by the Regulatory Review on May 10, 2020\. The report reinforces the Justice Department’s
    biased view that low-risk criminals should be the only ones eligible for early
    release. PATTERN classifies inmates as low, medium, or high risk, which forecasts
    if those individuals would engage in crime after release. Since PATTERN is limited
    to a particular group, it precludes other inmates from early release.
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 美国司法部审查了**囚犯评估工具：估算风险和需求**（**PATTERN**），并发现谁能使用PATTERN存在系统性偏见。此问题在2020年5月10日由《监管审查》发布的*解决算法性PATTERN偏见*一文中进行了讨论。报告强化了司法部对低风险罪犯应为唯一符合提前释放条件的偏见观点。PATTERN将囚犯分为低、中、高风险，预测这些人是否会在释放后再次犯罪。由于PATTERN仅限于特定群体，它排除了其他囚犯的提前释放机会。
- en: The article *The Potential For Bias In Machine Learning And Opportunities For
    Health Insurers To Address It* reports growing concerns about how ML can reflect
    and perpetuate past and present systemic inequities and biases. This was published
    by Health Affairs in February 2022 published the article. Limited access to the
    likelihood of hospitalization, admission to pharmacies, and missing or incomplete
    data are a few systemic biases for racism and underrepresented populations. Thus,
    the AI predictions may reflect those systemic biases, and the policy decisions
    based on the forecast risk reinforcing and exacerbating existing inequities.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文章*机器学习中的偏见潜力及健康保险公司应对的机会*报告了关于机器学习如何反映并延续过去和现在的系统性不公正与偏见的日益关注。该文于2022年2月由《健康事务》杂志发布。对住院可能性、药房入驻情况以及缺失或不完整数据的有限访问是种族主义和代表性不足群体的几种系统性偏见。因此，人工智能的预测可能会反映这些系统性偏见，而基于这些预测风险做出的政策决策可能会加剧现有的不平等。
- en: Fun challenge
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 趣味挑战
- en: 'This challenge is a thought experiment. Which category of biases is easier
    to spot? Hint: think about company profit.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这个挑战是一个思想实验。哪个类别的偏见更容易发现？提示：考虑公司利润。
- en: Computation, human, and systemic biases have similarities and are not mutually
    exclusive. There is no algorithm or libraries to guide you in coding. It relies
    on your observation from studying the datasets. At this point, Pluto is ready
    to learn about fetching real-world datasets from the *Kaggle* website. Optionally,
    he will ask you to spot the biases in the datasets.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 计算偏见、人为偏见和系统性偏见有相似之处，并且它们不是相互排斥的。没有算法或库来指导你的编码工作，它依赖于你通过学习数据集所做的观察。此时，Pluto已经准备好学习如何从*Kaggle*网站获取真实世界的数据集。作为选择性任务，他将要求你在数据集中发现偏见。
- en: Python Notebook
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Python笔记本
- en: This chapter’s coding lessons primarily focus on downloading real-world datasets
    from the *Kaggle* website. The later chapters rely on or reuse these fetching
    functions.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的编码课程主要集中在从*Kaggle*网站下载真实世界的数据集。后续章节将依赖或重用这些数据获取功能。
- en: In the previous chapter, you learned about this book’s general rules for development
    on the Python Notebook. The object-oriented class named **Pluto** contains the
    methods and attributes, and you add new methods to Pluto as you learn new concepts
    and techniques. Review [*Chapter 1*](B17990_01.xhtml#_idTextAnchor016) if you
    are uncertain about the development philosophy.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，你学习了本书关于在 Python Notebook 上进行开发的一般规则。名为 **Pluto** 的面向对象类包含方法和属性，你在学习新概念和技术时将向
    Pluto 添加新的方法。如果你不确定开发理念，可以回顾 [*第 1 章*](B17990_01.xhtml#_idTextAnchor016)。
- en: In this book, the term **P****ython Notebook** is used synonymously for **Jupyter
    Notebook**, **JupyterLab**, and **Google** **Colab Notebook**.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，**Python Notebook** 一词与 **Jupyter Notebook**、**JupyterLab** 和 **Google
    Colab Notebook** 同义使用。
- en: Fun challenge
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的挑战
- en: Pluto challenges you to change the object’s name from `pluto.draw_batch_image()`
    becomes `sandy.draw_batch_image()`.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: Pluto 挑战你将对象的名称从 `pluto.draw_batch_image()` 改为 `sandy.draw_batch_image()`。
- en: 'Starting with this chapter, the setup process for using the Python Notebook
    will be the same for every chapter. The goal of this chapter is to help you gain
    a deeper understanding of the datasets and not to write Python code for calculating
    the bias value for each dataset. The setup steps are as follows:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 从本章开始，使用 Python Notebook 的设置过程将在每一章中保持一致。本章的目标是帮助你更深入地理解数据集，而不是编写用于计算每个数据集偏差值的
    Python 代码。设置步骤如下：
- en: Load Python Notebook.
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载 Python Notebook。
- en: Clone GitHub.
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 克隆 GitHub。
- en: Instantiate Pluto.
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化 Pluto。
- en: Verify Pluto.
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证 Pluto。
- en: Create Kaggle ID.
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建 Kaggle ID。
- en: Download real-world datasets.
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载真实世界的数据集。
- en: Let’s start with loading the Python Notebook.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从加载 Python Notebook 开始。
- en: Python Notebook
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Python Notebook
- en: The first step is to locate the `data_augmentation_with_python_chapter_2.ipynb`
    file. It is in this book’s GitHub repository at [https://github.com/PacktPublishing/Data-Augmentation-with-Python](https://github.com/PacktPublishing/Data-Augmentation-with-Python).
    Refer to [*Chapter 1*](B17990_01.xhtml#_idTextAnchor016) if you forgot how to
    load the Python Notebook.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是定位 `data_augmentation_with_python_chapter_2.ipynb` 文件。该文件位于本书的 GitHub 仓库中，链接为
    [https://github.com/PacktPublishing/Data-Augmentation-with-Python](https://github.com/PacktPublishing/Data-Augmentation-with-Python)。如果你忘记了如何加载
    Python Notebook，请参考 [*第 1 章*](B17990_01.xhtml#_idTextAnchor016)。
- en: The next step is to clone the GitHub repository.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是克隆 GitHub 仓库。
- en: GitHub
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GitHub
- en: The second step is locating the `~/Data-Augmentation-with-Python/pluto/pluto_chapter_1.py`
    file. It’s in the main GitHub repository for this book, under the `pluto` folder.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 第二步是定位 `~/Data-Augmentation-with-Python/pluto/pluto_chapter_1.py` 文件。该文件位于本书的主要
    GitHub 仓库中的 `pluto` 文件夹下。
- en: Pluto is using the Python Notebook on **Google Colab**. It starts with a new
    session every time – that is, no permanent storage is saved from the previous
    session. Thus, the faster and easier method to load all the required files is
    to clone the GitHub repository. It could be this book’s GitGub or the GitHub repository
    that you forked.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: Pluto 在 **Google Colab** 上使用 Python Notebook。每次都会启动一个新的会话——也就是说，不会保存上次会话的永久存储。因此，加载所有所需文件的更快、更简单的方法是克隆
    GitHub 仓库。它可以是本书的 GitHub 仓库，或者是你自己 Fork 的 GitHub 仓库。
- en: From this point onward, all commands, code, and references are from the `data_augmentation_with_python_chapter_2.ipynb`
    Python Notebook.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 从这一点开始，所有命令、代码和引用都来自 `data_augmentation_with_python_chapter_2.ipynb` Python
    Notebook。
- en: 'Pluto uses the`!git clone {url}` command to clone a GitHub repository, where
    `{url}` is the link for the GitHub repository. The code snippet is as follows:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: Pluto 使用 `!git clone {url}` 命令来克隆一个 GitHub 仓库，其中 `{url}` 是 GitHub 仓库的链接。代码片段如下：
- en: '[PRE0]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: In the Python Notebook, any code cell that begins with an exclamation point
    (`!`) will tell the system to run as a system shell command line. For Google Colab,
    it is a `%`) are special commands. They are called **magic keywords** or **magic
    commands**.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Python Notebook 中，任何以感叹号（`!`）开头的代码单元将告诉系统将其作为系统 shell 命令行运行。对于 Google Colab，它是
    `%`）这样的特殊命令，它们被称为 **魔法关键词** 或 **魔法命令**。
- en: Fun fact
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的事实
- en: Jupyter Notebook’s built-in magic commands provide convenience functions to
    the underlying `%`). For example, `%ldir` is for listing the current directory
    files, `%cp` is for copying files in your local directory, `%debug` is for debugging,
    and so on. The helpful `%lsmagic` command is for listing all the available magic
    commands supported by your current Python Notebook environment. The exclamation
    character (`!`) is for running the underlying OS command-line function. For example,
    in a Linux system, `!ls -la` is for listing the files in the current directory,
    while `!pip` is for installing Python libraries.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: Jupyter Notebook 的内置魔法命令为底层 `%` 提供了便捷的功能。例如，`%ldir` 用于列出当前目录文件，`%cp` 用于复制本地目录中的文件，`%debug`
    用于调试，等等。一个有用的 `%lsmagic` 命令用于列出当前 Python Notebook 环境支持的所有可用魔法命令。感叹号字符 (`!`) 用于运行底层操作系统命令行功能。例如，在
    Linux 系统中，`!ls -la` 用于列出当前目录中的文件，而 `!pip` 用于安装 Python 库。
- en: Now that you have downloaded the Pluto Python code, the next step is to instantiate
    Pluto.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经下载了 Pluto 的 Python 代码，下一步是实例化 Pluto。
- en: Pluto
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Pluto
- en: 'The Python Notebook’s magic command for instantiating Pluto is as follows:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 实例化 Pluto 的 Python Notebook 魔法命令如下：
- en: '[PRE1]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The output is as follows:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE2]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The next-to-last step in the setup process is to verify that Pluto is running
    with the correct version.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 设置过程中的倒数第二步是验证 Pluto 是否正在运行正确版本。
- en: Verifying Pluto
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 验证 Pluto
- en: 'For double-checking, Pluto runs the following function:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进行双重检查，Pluto 运行以下函数：
- en: '[PRE3]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The results should be similar to the following output:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 结果应与以下输出类似：
- en: '[PRE4]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Since this code is from [*Chapter 1*](B17990_01.xhtml#_idTextAnchor016), the
    Pluto version is **1.0**. Before Pluto can download the dataset from the *Kaggle*
    website, he needs Kaggle’s **key** and **access token**.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这段代码来自于[*第一章*](B17990_01.xhtml#_idTextAnchor016)，Pluto 的版本是**1.0**。在 Pluto
    从 *Kaggle* 网站下载数据集之前，他需要 Kaggle 的 **密钥** 和 **访问令牌**。
- en: Kaggle ID
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kaggle ID
- en: Pluto uses Kaggle datasets because he wants to learn how to retrieve real-world
    data for learning data augmentation. It is more impactful than using a small set
    of dummy data. Thus, the first two steps are installing the library to aid in
    downloading the Kaggle data and signing up with [Kaggle.com](https://Kaggle.com).
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: Pluto 使用 Kaggle 数据集，因为他想学习如何获取用于数据增强的真实世界数据。这比使用一小套虚拟数据更有影响力。因此，前两步是安装库以帮助下载
    Kaggle 数据并在[Kaggle.com](https://Kaggle.com)上注册。
- en: 'The code for installing and importing can be found in the open source **opendatasets**
    library by **Jovian**. The function code is in the Python Notebook; here is a
    code snippet from it:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 安装和导入的代码可以在开源 **opendatasets** 库中找到，该库由 **Jovian** 提供。功能代码位于 Python Notebook
    中；以下是其中的一个代码片段：
- en: '[PRE5]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'After you create an account on [Kaggle.com](http://Kaggle.com), you will have
    a **Kaggle username** and receive a **Kaggle key**. Next, go to the **Account**
    page, scroll down to the **API** section, and click on the **Create New API Token**
    button to generate the **Kaggle key**:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在你在[Kaggle.com](http://Kaggle.com)上创建账户后，你将拥有一个 **Kaggle 用户名** 并收到一个 **Kaggle
    密钥**。接下来，进入 **账户** 页面，向下滚动到 **API** 部分，点击 **创建新 API 令牌** 按钮以生成 **Kaggle 密钥**：
- en: '![Figure 2.2 – Kaggle Account page – new token](img/B17990_02_02.jpg)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.2 – Kaggle 账户页面 – 新的令牌](img/B17990_02_02.jpg)'
- en: Figure 2.2 – Kaggle Account page – new token
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.2 – Kaggle 账户页面 – 新的令牌
- en: 'Once you have a `remember_kaggle_access_key()` wrapper method to store the
    attributes inside the object. The code uses the Python `self` keyword to store
    this information – for example, `self.kaggle_username`. The method’s definition
    is as follows:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你有了 `remember_kaggle_access_key()` 包装方法来存储对象中的属性。代码使用 Python 的 `self` 关键字来存储这些信息
    – 例如，`self.kaggle_username`。该方法的定义如下：
- en: '[PRE6]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Other methods will use these attributes automatically. Pluto runs the following
    method to remember your Kaggle username and key:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 其他方法将自动使用这些属性。Pluto 运行以下方法来记住你的 Kaggle 用户名和密钥：
- en: '[PRE7]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The `_write_kaggle_credit()` method writes your Kaggle username and key in two
    locations – `~/.kaggle/kaggle.json` and `./kaggle.json`. It also changes the file
    attribute to `0o600`. This function begins with an underscore; hence, it is a
    helper function used primarily by other methods.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '`_write_kaggle_credit()` 方法将你的 Kaggle 用户名和密钥写入两个位置 – `~/.kaggle/kaggle.json`
    和 `./kaggle.json`。它还会将文件属性更改为 `0o600`。这个函数以一个下划线开头；因此，它是一个主要供其他方法使用的辅助函数。'
- en: 'There are two methods for Pluto to fetch data from Kaggle: `fetch_kaggle_comp_data(competition_name)`,
    where `competition_name` is the title of the contest, and `fetch_kaggle_dataset(url)`,
    where `url` is the link to the dataset.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: Pluto从Kaggle抓取数据有两种方法：`fetch_kaggle_comp_data(competition_name)`，其中`competition_name`是比赛的名称，和`fetch_kaggle_dataset(url)`，其中`url`是数据集的链接。
- en: 'In the `fetch_kaggle_comp_data()` wrapper method, the primary code line that
    does most of the work is as follows:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在`fetch_kaggle_comp_data()`包装方法中，完成大部分工作的主要代码行如下：
- en: '[PRE8]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'In the `fetch_kaggle_dataset()` method, the primary code line that does most
    of the work is as follows:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在`fetch_kaggle_dataset()`方法中，完成大部分工作的主要代码行如下：
- en: '[PRE9]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Fun fact
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的事实
- en: As of 2022, there are over 2,500 past and current competitions on the Kaggle
    website and more than 150,000 datasets. These datasets are diverse, from medical
    and financial to other industry-specific datasets.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 截至2022年，Kaggle网站上有超过2500个历史和当前的比赛，超过150,000个数据集。这些数据集涵盖了从医学、金融到其他行业的各种领域。
- en: Image biases
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图像偏差
- en: 'Pluto has access to thousands of datasets, and downloading these datasets is
    as simple as replacing the **URL**. In particular, he will download the following
    datasets:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: Pluto可以访问成千上万的数据集，下载这些数据集就像替换**URL**一样简单。特别是，他将下载以下数据集：
- en: The *State Farm distracted drivers detection (**SFDDD)* dataset
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*State Farm distracted drivers detection（**SFDDD**）* 数据集'
- en: The *Nike* *shoes* dataset
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Nike* *shoes* 数据集'
- en: The *Grapevine* *leaves* dataset
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Grapevine* *leaves* 数据集'
- en: Let’s start with the SFDDD dataset.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从SFDDD数据集开始。
- en: State Farm distracted drivers detection
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: State Farm distracted drivers detection
- en: To start, Pluto will slow down and explain every step in downloading the real-world
    datasets, even though he will use a wrapper function, which seems deceptively
    simple. Pluto will not write any Python code for programmatically computing the
    bias fairness matrix values. He relies on your observation to spot the biases
    in the dataset.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 开始时，Pluto会慢下来并解释下载真实世界数据集的每一个步骤，尽管他将使用一个包装函数，看起来非常简单。Pluto不会写任何用于程序化计算偏差公正矩阵值的Python代码。他依赖于你的观察力来发现数据集中的偏差。
- en: 'Give Pluto a command to fetch, and he will download and **unzip** or **untar**
    the data to your local disk space. For example, in retrieving data from a competition,
    ask Pluto to fetch it with the following command:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 给Pluto一个命令让他去抓取数据，他会将数据下载并**解压**或**解tar**到你的本地磁盘。例如，在从比赛中获取数据时，要求Pluto通过以下命令去抓取：
- en: '[PRE10]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Since this data is from a competition, you must join the State Farm competition
    before downloading the dataset. You should go to the **State Farm Distracted Driver
    Detection** competition and click the **Join** button. The description for the
    competition from the *Kaggle* website is as follows:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 由于此数据来自比赛，必须加入State Farm比赛才能下载数据集。你应该前往**State Farm Distracted Driver Detection**比赛并点击**Join**按钮。比赛的描述来自*Kaggle*网站，如下所示：
- en: “State Farm hopes to improve these alarming statistics and better insure their
    customers by testing whether dashboard cameras can automatically detect drivers
    engaging in distracting behaviors. Given a dataset of 2D dashboard camera images,
    State Farm is challenging Kagglers to classify each driver’s behavior.”
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: “State Farm希望通过测试仪表盘摄像头是否能自动检测驾驶员的分心行为来改善这些令人担忧的统计数据，并更好地为客户提供保险。给定一个2D仪表盘摄像头图像数据集，State
    Farm正在挑战Kaggler们对每个驾驶员的行为进行分类。”
- en: '*State Farm* provided the dataset, announced in 2016\. The rules and usage
    licenses can be found at [https://www.kaggle.com/competitions/state-farm-distracted-driver-detection/rules](https://www.kaggle.com/competitions/state-farm-distracted-driver-detection/rules).'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '*State Farm*提供了该数据集，并于2016年发布。规则和使用许可可以在[https://www.kaggle.com/competitions/state-farm-distracted-driver-detection/rules](https://www.kaggle.com/competitions/state-farm-distracted-driver-detection/rules)找到。'
- en: Fun fact
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的事实
- en: You have to join a Kaggle competition to download competition data, but you
    don’t need to enter a competition to download a Kaggle dataset.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 你必须加入Kaggle比赛才能下载比赛数据，但下载Kaggle数据集时无需参加比赛。
- en: 'Not all the methods are in the Python Notebook’s `pluto`. For example, you
    can’t do the following:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 不是所有方法都在Python笔记本的`pluto`中。例如，你不能这样做：
- en: '**# example of** **wrong syntax**'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '**# 错误语法示例**'
- en: '[PRE11]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'However, using the `pluto` prefix is correct, as shown here:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，使用`pluto`前缀是正确的，如下所示：
- en: '[PRE12]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Before Pluto displays the image in batches, he must write a few simple code
    lines to check if the downloads are correct:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在Pluto批量显示图像之前，他必须写几行简单的代码来检查下载是否正确：
- en: '[PRE13]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The output is as follows:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 2.3 – State Farm Distracted driver](img/B17990_02_03.jpg)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.3 – State Farm 分心驾驶员](img/B17990_02_03.jpg)'
- en: Figure 2.3 – State Farm Distracted driver
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.3 – State Farm 分心驾驶员
- en: 'The SFDDD dataset consists of 22,423 images, and viewing one photo at a time,
    as shown in *Figure 2**.3*, will not help Pluto to see the biases. Pluto loves
    putting lists and tabular data into the Python pandas library. Luckily, the State
    Farm competition comes with a `fetch_df(self, csv)` method easier. The relevant
    line of code is as follows:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: SFDDD 数据集包含 22,423 张图像，每次查看一张照片，如*图 2.3*所示，并不能帮助 Pluto 看到偏差。Pluto 喜欢将列表和表格数据放入
    Python pandas 库中。幸运的是，State Farm 比赛自带 `fetch_df(self, csv)` 方法，使这一过程更简单。相关的代码行如下：
- en: '[PRE14]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Pluto uses the `fetch_df(self, csv)` wrapper function to download the data,
    and he uses Pandas to display the last three rows. The code is as follows:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: Pluto 使用 `fetch_df(self, csv)` 封装函数来下载数据，并使用 Pandas 显示最后三行。代码如下：
- en: '[PRE15]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The result is as follows:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如下：
- en: '![Figure 2.4 – State Farm data – last three rows](img/B17990_02_04.jpg)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.4 – State Farm 数据 – 最后三行](img/B17990_02_04.jpg)'
- en: Figure 2.4 – State Farm data – last three rows
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.4 – State Farm 数据 – 最后三行
- en: 'Pluto likes the data in the original CSV file, shown in *Figure 2**.4*, but
    it does not have a column with a full path to an image file. Pandas makes creating
    a new column containing the full image path super easy. There are no complicated
    `build_sf_fname(self, df)`, where `df` is the original DataFrame. The code snippet
    is as follows:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: Pluto 喜欢原始 CSV 文件中的数据，如*图 2.4*所示，但它没有包含图像文件完整路径的列。Pandas 使得创建包含完整图像路径的新列变得非常容易。没有复杂的`build_sf_fname(self,
    df)`，其中 `df` 是原始 DataFrame。代码片段如下：
- en: '[PRE16]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The full function code can be found in the Python Notebook. Pluto adds the
    full path name column and displays the first three rows with the following code:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的功能代码可以在 Python Notebook 中找到。Pluto 添加了完整路径列，并使用以下代码显示前 3 行：
- en: '[PRE17]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The result is as follows:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如下：
- en: '![Figure 2.5 – State Farm data – full path image name](img/B17990_02_05.jpg)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.5 – State Farm 数据 – 完整路径图像名称](img/B17990_02_05.jpg)'
- en: Figure 2.5 – State Farm data – full path image name
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.5 – State Farm 数据 – 完整路径图像名称
- en: 'For double-checking, Pluto writes a few lines of simple code to display an
    image from the pandas `fname` column, as shown in *Figure 2**.5*, using the **PIL**
    library. The code is as follows:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 为了双重检查，Pluto 写了几行简单的代码来显示来自 pandas `fname` 列的图像，如*图 2.5*所示，使用 **PIL** 库。代码如下：
- en: '[PRE18]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The resulting image is as follows:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 结果图像如下：
- en: '![Figure 2.6 – State Farm data – the fname column](img/B17990_02_06.jpg)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.6 – State Farm 数据 – fname 列](img/B17990_02_06.jpg)'
- en: Figure 2.6 – State Farm data – the fname column
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.6 – State Farm 数据 – fname 列
- en: '*Figure 2**.6* shows a driver. Using the `fname` column, drawing a batch or
    collection of images is relatively easy. The `draw_batch()` wrapper function’s
    definition is as follows:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 2.6* 显示了一个驾驶员。使用 `fname` 列，绘制一个批次或图像集合相对容易。`draw_batch()` 封装函数的定义如下：'
- en: '[PRE19]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: = `df_filenames` is the list of file =names, and it is in a pandas DataFrame.
    `disp_max` defaults to 10, which is an increment of 5, as in five photos per row.
    `is_shuffle` defaults to `False`. If you can set it to `True`, each batch is randomly
    selected. Lastly, `figsize` is the size of the output from the `(16,8)`.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: = `df_filenames` 是文件名列表，存储在 pandas DataFrame 中。`disp_max` 默认值为 10，这是一个增量为 5
    的值，例如每行 5 张照片。`is_shuffle` 默认为 `False`。如果设置为 `True`，每个批次将是随机选择的。最后，`figsize` 是输出图像的大小，默认为
    `(16,8)`。
- en: 'Using the `draw_batch()` wrapper method, Pluto can draw any photo collection.
    For example, Pluto can draw 10 random images from the SFDDD competition with the
    following code:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `draw_batch()` 封装方法，Pluto 可以绘制任何照片集合。例如，Pluto 可以使用以下代码从 SFDDD 比赛中绘制 10 张随机图像：
- en: '[PRE20]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The result is as follows:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如下：
- en: "![Figure 2.7 – State F\uFEFFarm data – draw_patch()](img/B17990_02_07.jpg)"
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.7 – State Farm 数据 – draw_patch()](img/B17990_02_07.jpg)'
- en: Figure 2.7 – State Farm data – draw_patch()
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.7 – State Farm 数据 – draw_patch()
- en: 'Pluto runs the code repeatedly to see different images in the dataset, as shown
    in *Figure 2**.7*. For example, he can draw 20 random images at a time using the
    following code:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: Pluto 重复运行代码来查看数据集中的不同图像，如*图 2.7*所示。例如，他可以一次性使用以下代码随机绘制 20 张图片：
- en: '[PRE21]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The output is as follows:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 2.8 – State Farm data – 20 randomly selected images](img/B17990_02_08.jpg)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.8 – State Farm 数据 – 随机选择的 20 张图片](img/B17990_02_08.jpg)'
- en: Figure 2.8 – State Farm data – 20 randomly selected images
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.8 – State Farm 数据 – 随机选择的 20 张图片
- en: '*Figure 2**.8* displays 20 photos of drivers. Using the `fetch_kaggle_comp_data()`,
    `fetch_df()`, and `draw_batch()` wrapper functions, Pluto can retrieve any of
    the thousand real-world datasets from Kaggle.'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '*图2**.8*显示了20张司机的照片。通过使用`fetch_kaggle_comp_data()`、`fetch_df()`和`draw_batch()`包装函数，Pluto可以从Kaggle获取任何千余个真实世界的数据集。'
- en: Fun challenge
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的挑战
- en: This challenge is a thought experiment. Before reading Pluto’s answer, what
    biases do you see in the images? It is optional, and there is no algorithm or
    library that you can use to compute the bias fairness value. It relies on your
    observation.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 这个挑战是一个思维实验。在阅读Pluto的答案之前，你在图像中看到了哪些偏见？这是可选的，没有算法或库可以用来计算偏见公平性值。这依赖于你的观察。
- en: 'Pluto read the SFDDD’s goal and thought about computational, human, and systemic
    biases. The following bullet points are not errors to be fixed, but they could
    be biases. These biases are observations from *Figure 2**.7* of underrepresented
    groups. Pluto assumes the long-term goal of the SFDDD is for it to be deployed
    across the United States:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: Pluto阅读了SFDDD的目标，并考虑了计算偏见、人为偏见和系统偏见。以下要点不是需要修复的错误，但它们可能是偏见。这些偏见来自*图2**.7*，关于代表性不足群体的观察。Pluto假设SFDDD的长期目标是将其部署到美国：
- en: Pluto does not see any older adults as drivers in the dataset.
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pluto在数据集中没有看到任何年长的成年人作为司机。
- en: The driver demographic distribution is limited. There are about a dozen drivers
    represented in the dataset, and the long-term goal is to deploy this AI system
    in the United States. Therefore, the AI system will be trained on a limited number
    of drivers.
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 司机的人口统计分布是有限的。数据集中约有十几位司机，长期目标是将该AI系统部署到美国。因此，AI系统将基于有限数量的司机进行训练。
- en: There are few vehicle types represented in the dataset. They are primary sedans,
    compacts, or SUVs. A sports car or truck interior is different, which might affect
    the prediction of false positives or false negatives.
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据集中表示的车辆类型较少，主要是轿车、紧凑型车或SUV。跑车或卡车的内部结构不同，可能会影响假阳性或假阴性的预测。
- en: There are other distracting activities while driving that are not represented,
    such as eating ice cream, watching an event unfolding outside of the car, head
    or hair grooming, and so on.
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 驾驶时有其他干扰活动没有在数据集中表示出来，比如吃冰淇淋、观看车外发生的事件、梳理头发或整理发型等。
- en: All drivers in the dataset wear urban-style clothing. More elaborate or ethnic-centric
    clothing styles might cause the AI to predict false positives or false negatives.
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据集中的所有司机都穿着城市风格的衣服。更精致或以民族为中心的衣服风格可能会导致AI预测出假阳性或假阴性。
- en: The goal is to save lives. Thus, a systemic bias could be affordable access
    to everyone, not just the tech-savvy urban elites.
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 目标是拯救生命。因此，系统性偏见可能是让每个人都能负担得起，而不仅仅是技术精通的城市精英。
- en: Fun challenge
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的挑战
- en: This challenge is a thought experiment. Can you find other biases? There are
    no absolute right or wrong answers. The biases listed here can’t be spotted programmatically.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 这个挑战是一个思维实验。你能找到其他的偏见吗？没有绝对正确或错误的答案。这里列出的偏见无法通过编程方式发现。
- en: That was a detailed discussion of the SFDDD dataset. Pluto will fetch another
    dataset from the *Kaggle* website, the *Nike* *shoes* dataset.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一段关于SFDDD数据集的详细讨论。Pluto将从*Kaggle*网站获取另一个数据集——*Nike* *鞋子*数据集。
- en: Nike shoes
  id: totrans-186
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Nike鞋子
- en: The Nike shoes dataset was chosen because it will show different biases. Like
    the State Farm photos, there is no algorithm or library to compute the fairness
    matrix. We rely on Pluto and your observations.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 选择Nike鞋子数据集是因为它将展示不同的偏见。像State Farm的照片一样，没有算法或库来计算公平性矩阵。我们依赖于Pluto和你的观察。
- en: 'The *Nike, Adidas, and Converse Shoes Images* (Nike) dataset contains images
    in folders; there is no **CSV** file. The Nike dataset’s description on the Kaggle
    website is as follows:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '*Nike，Adidas和Converse鞋子图片*（Nike）数据集包含按文件夹组织的图像，没有**CSV**文件。Nike数据集在Kaggle网站上的描述如下：'
- en: “*This dataset is ideal for performing multiclass classification with deep neural
    networks such as CNNs or simpler machine learning classification models. You can
    use TensorFlow, its high-level API Keras, sklearn, PyTorch, or other deep/machine*
    *learning libraries.*”
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: “*这个数据集非常适合使用深度神经网络（如CNNs）或更简单的机器学习分类模型进行多分类。你可以使用TensorFlow及其高级API Keras，sklearn，PyTorch或其他深度/机器学习库。*”
- en: 'The author is *Iron486*, and the license is **CC0: Public** **Domain**: [https://creativecommons.org/publicdomain/zero/1.0/](https://creativecommons.org/publicdomain/zero/1.0/).'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '作者是 *Iron486*，许可协议为 **CC0: 公共领域**：[https://creativecommons.org/publicdomain/zero/1.0/](https://creativecommons.org/publicdomain/zero/1.0/)。'
- en: Since there is no CSV file for Pluto to import into pandas, Pluto has written
    the `build_df_fname(self,` `start_path)` method, where `start_path` is the directory
    where the data is stored.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 Pluto 没有 CSV 文件可以导入到 pandas 中，Pluto 编写了 `build_df_fname(self,` `start_path)`
    方法，其中 `start_path` 是数据存储的目录。
- en: 'The key code line is the `os.walk()` function:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 关键代码行是 `os.walk()` 函数：
- en: '[PRE22]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Pluto will perform the three familiar steps for reviewing the Nike dataset.
    They are as follows:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: Pluto 将执行查看 Nike 数据集的三步熟悉操作，具体如下：
- en: '[PRE23]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The output is as follows:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 2.9 – Nike data – 20 randomly selected images](img/B17990_02_09.jpg)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.9 – Nike 数据 – 随机选择的 20 张图片](img/B17990_02_09.jpg)'
- en: Figure 2.9 – Nike data – 20 randomly selected images
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.9 – Nike 数据 – 随机选择的 20 张图片
- en: 'The following is Pluto’s list of data biases observations from *Figure 2**.9*:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是 Pluto 从 *图 2.9* 提取的数据偏见观察列表：
- en: The shoes are too clean. Where are the muddy or dirty shoes?
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 鞋子太干净了。哪里有泥泞或脏的鞋子？
- en: The photos are professionally taken. Thus, when the AI-powered app is deployed,
    people might find their app giving a wrong prediction because their pictures are
    taken haphazardly.
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 照片拍摄得非常专业。因此，当 AI 驱动的应用程序部署时，人们可能会发现他们的应用程序做出错误预测，因为他们的照片拍摄得很随意。
- en: There is a lack of shoe images in urban, farming, or hiking settings.
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在城市、农业或远足环境中缺少鞋子的图片。
- en: Let’s ask Pluto to grab one more image dataset before switching gears and digging
    into the text dataset.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们让 Pluto 再抓取一个图像数据集，然后再切换到文本数据集的分析。
- en: Grapevine leaves
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 葡萄藤叶
- en: The Grapevine leaves dataset is the third and last example of a real-world image
    dataset Pluto will fetch from the Kaggle website. The primary goal is for you
    to practice downloading datasets and importing the metadata into pandas. Incidentally,
    Pluto will use the Grapevine leaves dataset to name other types of data biases
    through observation. He does not rely on defining a fairness matrix through coding
    because it not yet feasible. Maybe the next level of generative AI will be able
    to process all the photos in a dataset and deduce the biases.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 葡萄藤叶数据集是 Pluto 从 Kaggle 网站抓取的第三个也是最后一个真实世界图像数据集。主要目的是让你练习下载数据集并将元数据导入 pandas。顺便说一下，Pluto
    将使用葡萄藤叶数据集通过观察命名其他类型的数据偏见。他不依赖于通过编码定义公平性矩阵，因为这尚不可行。也许下一代生成性 AI 将能够处理数据集中的所有照片，并推断出偏见。
- en: 'Here is an excerpt from the Grapevine leaves dataset:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 这是来自葡萄藤叶数据集的摘录：
- en: “The main product of grapevines is grapes that are consumed fresh or processed.
    In addition, grapevine leaves are harvested once a year as a by-product. The species
    of grapevine leaves are important in terms of price and taste.”
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: “葡萄藤的主要产品是鲜食或加工的葡萄。此外，葡萄藤叶作为副产品每年采摘一次。葡萄藤叶的品种在价格和口感上非常重要。”
- en: 'The authors are *Koklu M., Unlersen M. F., Ozkan I. A., Aslan M. F., and Sabanci
    K.*, and the license is **CC0: Public** **Domain**: [https://creativecommons.org/publicdomain/zero/1.0/](https://creativecommons.org/publicdomain/zero/1.0/).'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '作者是 *Koklu M.、Unlersen M. F.、Ozkan I. A.、Aslan M. F. 和 Sabanci K.*，许可协议为 **CC0:
    公共领域**：[https://creativecommons.org/publicdomain/zero/1.0/](https://creativecommons.org/publicdomain/zero/1.0/)。'
- en: 'The filenames in the Grapevine dataset contains a space character in the filename,
    which may confuse many Python libraries. Thus, Pluto runs a few simple Linux scripts
    to convert the space into an underscore. The code snippet is as follows:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 葡萄藤数据集中的文件名包含空格字符，这可能会使许多 Python 库混淆。因此，Pluto 运行了几个简单的 Linux 脚本，将空格转换为下划线。代码片段如下：
- en: '[PRE24]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'After cleaning up the filenames, Pluto will perform the three familiar steps
    for fetching, importing, and displaying the Grapevine dataset. The images are
    in the same folder structure as the Nike photos. Thus, Pluto reuses the same `pluto.fetch_df()`
    method:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 清理完文件名后，Pluto 将执行三步熟悉的操作：获取、导入和显示葡萄藤数据集。图片与 Nike 照片位于相同的文件夹结构中。因此，Pluto 重用了相同的
    `pluto.fetch_df()` 方法：
- en: '[PRE25]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The output is as follows:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 2.10 – Grapevine data – 20 randomly selected images](img/B17990_02_10.jpg)'
  id: totrans-214
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.10 – 葡萄藤数据 – 随机选择的 20 张图片](img/B17990_02_10.jpg)'
- en: Figure 2.10 – Grapevine data – 20 randomly selected images
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.10 – 葡萄藤数据 – 随机选择的 20 张图片
- en: 'The following is Pluto’s list of data biases from *Figure 2**.10*:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是 Pluto 从 *图 2.10* 提取的数据偏见列表：
- en: The photos are too perfect, and undoubtedly, they are uncomplicated to augment
    and train, but how does the general public use the AI system? If the winemakers
    access the AI system through an iPhone, the grapevine leaf pictures they take
    are nothing like the flawless photos in the dataset. The resulting predictions
    could be false positives.
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些照片太完美了，无疑它们非常容易增强和训练，但普通用户是如何使用 AI 系统的呢？如果酿酒师通过 iPhone 访问 AI 系统，他们拍摄的葡萄藤叶照片与数据集中的完美照片完全不同。结果可能会产生假阳性。
- en: Similar to the perfect photo bias, the leaf is flat, and the background is white,
    which is not common in real-world usage. The training cycle will achieve high
    accuracy, but it is unsuitable for real-world use.
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 类似于完美照片偏差，叶子是平的，背景是白色的，这在现实世界的使用中并不常见。训练周期能够达到高准确度，但这对于实际使用来说并不适用。
- en: If the model is trained as-is and deployed, then the resulting AI will have
    a systemic bias, only being available for lab technicians and not farmers.
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果模型按原样训练并部署，那么生成的 AI 将具有系统性偏差，仅适用于实验室技术人员，而不适用于农民。
- en: Fun challenge
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 趣味挑战
- en: There are thousands of image datasets on the *Kaggle* website. Pluto challenges
    you to select, download, display, and list the biases for three different image
    datasets.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *Kaggle* 网站上有成千上万的图像数据集。Pluto 挑战你选择、下载、展示并列出三个不同图像数据集的偏差。
- en: Other than Distracted Drivers, Nike shoes, and Grapevine Leaves, there are more
    examples in the Python Notebook. However, next, Pluto will move on from biases
    to text augmentation.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 除了分心的司机、耐克鞋和葡萄藤叶外，Python 笔记本中还有更多的例子。不过接下来，Pluto 会从偏差转到文本增强。
- en: Text biases
  id: totrans-223
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 文本偏差
- en: By now, you should recognize the patterns for fetching real-world image datasets
    and importing metadata into pandas. It is the same pattern for text datasets.
    Pluto will guide you through two sessions and use his power of observation to
    name the biases. He could employ the latest in generative AI such as OpenAI GPT3
    or GPT4 to list the biases in the text. Maybe he will do that later, but for now,
    he will use his noggin. Nevertheless, Pluto will attempt to write Python code
    to gain insight into the texts' structures, such as the word count and misspelled
    words. It is not the fairness matrix but a step in the right direction.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你应该已经能识别出获取真实世界图像数据集和导入元数据到 pandas 的模式。文本数据集也是相同的模式。Pluto 会通过两节课程带领你，利用他的观察力来命名偏差。他可能会使用最新的生成
    AI，如 OpenAI GPT3 或 GPT4，列出文本中的偏差。也许他以后会这么做，但现在，他会用自己的大脑来处理。不过，Pluto 会尝试编写 Python
    代码，洞察文本的结构，如单词计数和拼写错误。这里并不是公平性矩阵，而是朝着正确方向迈出的第一步。
- en: Pluto searches the Kaggle website for the **Natural Language Processing** (**NLP**)
    dataset, and the result consists of over 2,000 datasets. He chooses the *Netflix
    Shows* and the *Amazon Reviews* datasets. Retrieving and viewing the NLP dataset
    follows the same fetching, importing, and printing steps outlined in the image
    dataset.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: Pluto 在 Kaggle 网站上搜索 **自然语言处理** (**NLP**) 数据集，结果显示超过 2,000 个数据集。他选择了 *Netflix
    Shows* 和 *Amazon Reviews* 数据集。获取和查看 NLP 数据集的步骤与图像数据集的获取、导入和打印步骤相同。
- en: Let’s start with the Netflix data.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从 Netflix 数据开始。
- en: Netflix
  id: totrans-227
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Netflix
- en: 'Pluto reuses the wrapper function to download the data. The command is as follows:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: Pluto 重用包装函数来下载数据。命令如下：
- en: '[PRE26]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The Netflix dataset’s description from the Kaggle website is as follows:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: Netflix 数据集的描述来自 Kaggle 网站，如下所示：
- en: “The raw data is web scrapped through Selenium. It contains unlabelled text
    data of around 9,000 Netflix shows and movies, along with full details such as
    cast, release year, rating, description, and so on.”
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: “原始数据是通过 Selenium 网络爬虫抓取的。它包含了大约 9,000 部 Netflix 电视剧和电影的未标注文本数据，以及完整的详细信息，如演员表、发行年份、评分、描述等。”
- en: 'The author is *InFamousCoder*, and the license is **CC0: Public** **Domain**:
    [https://creativecommons.org/publicdomain/zero/1.0/](https://creativecommons.org/publicdomain/zero/1.0/).'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: '作者是 *InFamousCoder*，许可协议为 **CC0: 公共领域**：[https://creativecommons.org/publicdomain/zero/1.0/](https://creativecommons.org/publicdomain/zero/1.0/).'
- en: 'The second step is to import the data into a pandas DataFrame. The Netflix
    data comes with a `fetch_df()` method to import the Netflix reviews into the DataFrame
    and displays the first three rows, as follows:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 第二步是将数据导入到 pandas DataFrame 中。Netflix 数据自带一个 `fetch_df()` 方法，可以将 Netflix 评论导入到
    DataFrame，并显示前三行，如下所示：
- en: '[PRE27]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The result is as follows:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如下：
- en: '![Figure 2.11 – Netflix data, left columns](img/B17990_02_11.jpg)'
  id: totrans-236
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.11 – Netflix 数据，左侧列](img/B17990_02_11.jpg)'
- en: Figure 2.11 – Netflix data, left columns
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.11 – Netflix 数据，左侧列
- en: '*Figure 2**.11* displays the Netflix metadata. The first two steps do not require
    Pluto to write new code, but Pluto has to write code for the third step, which
    is to display the movie’s title and description. The goal is for Pluto to find
    any biases in the movie description.'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 2**.11* 显示了Netflix元数据。前两步不需要 Pluto 编写新代码，但 Pluto 需要为第三步编写代码，即显示电影的标题和描述。目标是让
    Pluto 查找电影描述中的任何偏见。'
- en: 'Pandas made writing the `display_batch_text()` wrapper method effortless. The
    method has no **loops**, **index counter**, **shuffle algorithm**, **or if-else**
    statements. There are just three lines of code, so Pluto displays the code in
    its entirety here:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas 使得编写 `display_batch_text()` 包装方法变得轻松。这段方法没有**循环**、**索引计数器**、**洗牌算法**、**if-else**
    语句。它只有三行代码，因此 Pluto 在这里展示了完整的代码：
- en: '[PRE28]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Pluto displays the Netflix movies’ titles and descriptions in batch using the
    following code:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: Pluto 使用以下代码批量显示 Netflix 电影的标题和描述：
- en: '[PRE29]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The result is as follows:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如下：
- en: '![Figure 2.12 – Netflix movie title and description](img/B17990_02_12.jpg)'
  id: totrans-244
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.12 – Netflix 电影标题和描述](img/B17990_02_12.jpg)'
- en: Figure 2.12 – Netflix movie title and description
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.12 – Netflix 电影标题和描述
- en: Fun fact
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的事实
- en: Every time Pluto runs the `print_batch_text()` wrapper function, movie titles
    and descriptions are displayed. It would be best to run the wrapper function repeatedly
    to gain more insight into the data.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 每次 Pluto 运行 `print_batch_text()` 包装函数时，都会显示电影标题和描述。最好多次运行该包装函数，以便更深入地了解数据。
- en: '*Figure 2**.12* displays a text batch. Pluto has read hundreds of movie descriptions
    and found no apparent bias. It is a job for a linguist. In general, the English
    language can have the following biases:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 2**.12* 显示了一个文本批次。Pluto 已经阅读了数百个电影描述，未发现明显的偏见。这是语言学家的工作。一般来说，英语语言可能存在以下偏见：'
- en: Religious bias
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 宗教偏见
- en: Gender bias
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 性别偏见
- en: Ethnicity bias
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 民族偏见
- en: Racial bias
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 种族偏见
- en: Age bias
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 年龄偏见
- en: Mental health bias
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 精神健康偏见
- en: Former felon bias
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 前科偏见
- en: Elitism bias
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 精英主义偏见
- en: LGBTQ bias
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LGBTQ 偏见
- en: Disability bias
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 残障偏见
- en: Pluto is not a linguist, but there are other data attributes could contribute
    to language biases, such as word count and misspelled words. In other words, are
    the Netflix movie descriptions all relatively the same length? And are there many
    misspelled words?
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: Pluto 不是语言学家，但其他数据属性可能会影响语言偏见，如单词数和拼写错误的单词。换句话说，Netflix 的电影描述是否大体相同长度？并且是否有很多拼写错误的单词？
- en: 'This is an attempt to code a small fraction of the fairness matrix. When using
    a pandas DataFrame, the `count_words()` method has one line of code. It is as
    follows:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 这是尝试编码公平矩阵的一小部分。当使用 pandas DataFrame 时，`count_words()` 方法只有一行代码。其内容如下：
- en: '[PRE30]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Pluto counted the number of words in the Netflix movie and double-checked the
    result by using the following code:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: Pluto 计算了 Netflix 电影的单词数，并通过以下代码重新检查了结果：
- en: '[PRE31]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The result is as follows:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如下：
- en: '![Figure 2.13 – Movie description word count](img/B17990_02_13.jpg)'
  id: totrans-265
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.13 – 电影描述字数](img/B17990_02_13.jpg)'
- en: Figure 2.13 – Movie description word count
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.13 – 电影描述字数
- en: '*Figure 2**.13* displays the word count for each record. The next step is to
    plot the word count using the `draw_word_count()` function are as follows:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 2**.13* 显示了每个记录的字数。下一步是使用 `draw_word_count()` 函数绘制字数分布，结果如下：'
- en: '[PRE32]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The full function code can be found in the Python Notebook. Pluto draws the
    BoxPlot and Histogram graphs with the following code:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的函数代码可以在 Python Notebook 中找到。Pluto 使用以下代码绘制 BoxPlot 和直方图：
- en: '[PRE33]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The result is as follows:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如下：
- en: '![Figure 2.14 – Netflix movie description word count](img/B17990_02_14.jpg)'
  id: totrans-272
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.14 – Netflix 电影描述字数](img/B17990_02_14.jpg)'
- en: Figure 2.14 – Netflix movie description word count
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.14 – Netflix 电影描述字数
- en: As shown in *Figure 2**.14*, the BoxPlot and Histogram plots show that the distribution
    is even. There are a few outliers, the mean is 23.88, and the bulk of the Netflix
    movie descriptions are between 22 and 25 words. Thus, there is no bias here. Pluto
    investigates the misspelled words next.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 如 *图 2**.14* 所示，BoxPlot 和直方图显示分布均匀。有少数异常值，均值为 23.88，Netflix 电影描述的大部分字数在 22 到
    25 字之间。因此，这里没有偏见。接下来 Pluto 将检查拼写错误的单词。
- en: 'Pluto uses the `pip` command to install the `spellchecker` class. The `check_spelling()`
    method takes the pandas DataFrame and the designated column as parameters. The
    function key code lines are as follows:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: Pluto 使用 `pip` 命令安装 `spellchecker` 类。`check_spelling()` 方法将 pandas DataFrame
    和指定的列作为参数。函数的关键代码行如下：
- en: '[PRE34]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Pluto checks the Netflix movie descriptions'' spelling and uses the `print_batch_text()`
    function to display the result. The code is as follows:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: Pluto 检查了 Netflix 电影描述的拼写，并使用 `print_batch_text()` 函数显示结果。代码如下：
- en: '[PRE35]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The result is as follows:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如下：
- en: '![Figure 2.15 – Netflix misspelled words](img/B17990_02_15.jpg)'
  id: totrans-280
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.15 – Netflix 错别字](img/B17990_02_15.jpg)'
- en: Figure 2.15 – Netflix misspelled words
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.15 – Netflix 错别字
- en: '*Figure 2**.15* displays the misspelled words. Pluto displays this data in
    graphs by reusing the same `draw_word_count()` function, as follows:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 2**.15* 显示了错别字。Pluto 通过重用相同的 `draw_word_count()` 函数，在图表中展示这些数据，如下所示：'
- en: '[PRE36]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The result is as follows:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如下：
- en: '![Figure 2.16 – Netflix misspelled words graph](img/B17990_02_16.jpg)'
  id: totrans-285
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.16 – Netflix 错别字图](img/B17990_02_16.jpg)'
- en: Figure 2.16 – Netflix misspelled words graph
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.16 – Netflix 错别字图
- en: The misspelled words are mostly person or product names, as shown in *Figure
    2**.16*. The average is 0.92 per Netflix movie description and there are only
    a handful of outliners. Without a linguist’s help, Pluto can’t find any biases
    in the Netflix movie description. Let’s move on to the Amazon reviews and see
    if we can find any biases.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 错别字大多数是人名或产品名，如 *图 2**.16* 所示。Netflix 的电影描述平均每个有 0.92 个错别字，且只有少数几个异常值。没有语言学家的帮助，Pluto
    无法在 Netflix 电影描述中发现任何偏差。接下来我们来看一下亚马逊评论，看看是否能找到任何偏差。
- en: Amazon reviews
  id: totrans-288
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 亚马逊评论
- en: The Amazon reviews dataset is the last real-world text dataset to download for
    this chapter. Pluto follows the same pattern, and you should now be comfortable
    with the code and ready to download any real-world datasets from the Kaggle website.
    In addition, as with the Netflix data, Pluto will use his powerful insight, as
    a digital dog, to find the biases in the text. He will use the same techniques
    and library to programmatically find the word count and misspelled words.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊评论数据集是本章下载的最后一个真实世界文本数据集。Pluto 按照相同的模式进行处理，你现在应该已经熟悉这些代码，并准备好从 Kaggle 网站下载任何真实世界的数据集。此外，像处理
    Netflix 数据一样，Pluto 将利用他作为数字狗的强大洞察力，找出文本中的偏差。他将使用相同的技术和库，程序化地找到单词计数和错别字。
- en: 'Pluto will not explain how the code is written for the Amazon reviews because
    he re-used the same functions in the Netflix data. The complete code can be found
    in the Python Notebook. The bare code snippet is as follows:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: Pluto 不会解释如何为亚马逊评论编写代码，因为他在 Netflix 数据中重用了相同的函数。完整的代码可以在 Python Notebook 中找到。以下是代码片段：
- en: '[PRE37]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'The data description of the Amazon reviews dataset on Kaggle is as follows:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊评论数据集在 Kaggle 上的数据描述如下：
- en: “One of the most important problems in eCommerce is the correct calculation
    of the points given to after-sales products. The solution to this problem is to
    provide greater customer satisfaction for the eCommerce site, product prominence
    for sellers, and a seamless shopping experience for buyers. Another problem is
    the correct ordering of the comments given to the products. The prominence of
    misleading comments will cause both financial losses and customer losses.”
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: “电子商务中最重要的问题之一是正确计算售后产品的积分。解决这个问题的方法是为电子商务网站提供更高的客户满意度，为卖家提供产品的突出展示，并为买家提供无缝的购物体验。另一个问题是正确排序产品的评论。误导性评论的突出展示将导致财务损失和客户流失。”
- en: 'The author is *Tarık kaan Koç*, and the license is **CC BY-NC-SA** **4.0**:
    [https://creativecommons.org/licenses/by-nc-sa/4.0/](https://creativecommons.org/licenses/by-nc-sa/4.0/).'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 作者是 *Tarık kaan Koç*，并且许可证是 **CC BY-NC-SA** **4.0**：[https://creativecommons.org/licenses/by-nc-sa/4.0/](https://creativecommons.org/licenses/by-nc-sa/4.0/)。
- en: 'Pluto prints the batch using the following code:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: Pluto 使用以下代码打印批次：
- en: '[PRE38]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'The result is as follows:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如下：
- en: '![Figure 2.17 – Amazon reviews misspelled words](img/B17990_02_17.jpg)'
  id: totrans-298
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.17 – 亚马逊评论错别字](img/B17990_02_17.jpg)'
- en: Figure 2.17 – Amazon reviews misspelled words
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.17 – 亚马逊评论错别字
- en: 'Pluto has chosen to display two data columns in the `print_batch` function,
    as shown in *Figure 2**.17*, but there are 12 data columns in the dataset. They
    are as follows:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: Pluto 选择在 `print_batch` 函数中显示两列数据，如 *图 2**.17* 所示，但数据集中有 12 列数据。它们如下：
- en: '`reviewerName`'
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`reviewerName`'
- en: '`overall`'
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`overall`'
- en: '`reviewText`'
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`reviewText`'
- en: '`reviewTime`'
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`reviewTime`'
- en: '`day_diff`'
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`day_diff`'
- en: '`helpful_yes`'
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`helpful_yes`'
- en: '`helpful_no`'
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`helpful_no`'
- en: '`total_vote`'
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`total_vote`'
- en: '`score_pos_neg_diff`'
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`score_pos_neg_diff`'
- en: '`score_average_rating`'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`score_average_rating`'
- en: '`wilson_lower_bound`'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wilson_lower_bound`'
- en: 'Pluto draws the word counts and the misspelled words using the following code:'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: Pluto 使用以下代码绘制单词计数和错别字：
- en: '[PRE39]'
  id: totrans-313
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The result for the word counts is as follows:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 单词计数的结果如下：
- en: '![Figure 2.18 – Amazon reviews word count](img/B17990_02_18.jpg)'
  id: totrans-315
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.18 – 亚马逊评论字数](img/B17990_02_18.jpg)'
- en: Figure 2.18 – Amazon reviews word count
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.18 – 亚马逊评论字数
- en: 'Here is the graph for the misspelled words:'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 这是拼写错误单词的图表：
- en: "![Figure 2.19 – Amazon reviews misspelled\uFEFF words graph](img/B17990_02_19.jpg)"
  id: totrans-318
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.19 – 亚马逊评论拼写错误单词图表](img/B17990_02_19.jpg)'
- en: Figure 2.19 – Amazon reviews misspelled words graph
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.19 – 亚马逊评论拼写错误单词图表
- en: 'Pluto notices that the biases in the Amazon reviews, as shown in *Figures 2.17*,
    *2.18*, and *2.19*, are as follows:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 普鲁托（Pluto）注意到，亚马逊评论中的偏见，如*图 2.17*、*2.18*和*2.19*所示，具体如下：
- en: There are more grammatical errors in the Amazon reviews than in the Netflix
    movie description. Thus, there could be bias against well-written reviews.
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 亚马逊评论中的语法错误比 Netflix 电影描述中的更多。因此，可能会对写得好的评论产生偏见。
- en: There are many more technical product names and jargon in the reviews. Therefore,
    there could be bias against non-technical reviewers.
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评论中有更多的技术产品名称和术语。因此，可能会对非技术性评论者产生偏见。
- en: There are many outlines. The mean is 50.46 words per review, with the bulk feedback
    between 20 and 180 words. It is worth digging deeper using other columns, such
    as `helpful_yes`, `total_vote`, and `score_pos_neg_diff`, to see if there is bias
    in the review length per category.
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评论中有很多大纲。平均每条评论有 50.46 个单词，反馈大多集中在 20 到 180 个单词之间。通过其他列（如 `helpful_yes`、`total_vote`
    和 `score_pos_neg_diff`）进行更深入的挖掘，看看每个类别的评论长度是否存在偏见，是很有意义的。
- en: The Amazon reviews have more misspelled words than the Netflix movie description,
    reinforcing the well-written reviewer’s bias.
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 亚马逊评论中的拼写错误单词比 Netflix 电影描述中的更多，这强化了对写得好的评论者的偏见。
- en: Before jumping into the summary, here is a fun fact.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 在进入总结之前，有一个有趣的事实。
- en: Fun fact
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的事实
- en: 'Cathy O’Neil’s book, *Weapons of Math Destruction: How Big Data Increases Inequality
    and Threatens Democracy*, published in 2016, describes many biases in algorithms
    and AI, and it is a must-read for data scientists and college students. The two
    prominent examples are an accomplished teacher fired by a computer algorithm and
    a qualified college student rejected by the candidate screening software.'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 凯西·奥尼尔（Cathy O’Neil）在2016年出版的书籍《**数学毁灭武器：大数据如何增加不平等并威胁民主**》描述了算法和人工智能中的许多偏见，这本书是数据科学家和大学生的必读书。书中有两个突出示例：一位经验丰富的教师被计算机算法解雇，一位合格的大学生被候选人筛选软件拒绝。
- en: Summary
  id: totrans-328
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: This chapter was not a typical one in this book because we discussed more theory
    than practical data augmentation techniques. At first, the link between data biases
    and data augmentation seems tenuous. Still, as you begin to learn about computational,
    human, and systemic biases, you see the strong connection because they all share
    the same goal of ensuring successful ethical AI system usage and acceptance.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 本章不同于本书的其他章节，因为我们讨论了更多的理论内容，而非实际的数据增强技术。起初，数据偏见和数据增强之间的联系似乎微弱。然而，随着你开始了解计算偏见、人为偏见和系统性偏见，你会看到它们之间有着强烈的联系，因为它们都有确保成功的伦理
    AI 系统使用和接受的共同目标。
- en: In other words, data augmentation increases the AI’s prediction accuracy while
    reducing the data biases in augmenting, ensuring the AI forecast has fewer false-negative
    and true-negative outcomes.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，数据增强提高了 AI 的预测准确性，同时减少了数据增强中的偏见，确保了 AI 预测的假阴性和真阴性结果更少。
- en: The computational, human, and systemic biases are similar but are not mutually
    exclusive. However, providing plenty of examples of real-world biases and observing
    three real-world image datasets and two real-world text datasets made these biases
    easier to understand.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 计算偏见、人为偏见和系统性偏见虽然相似，但并不互相排斥。然而，通过提供大量现实世界中的偏见示例，并观察三个现实世界的图像数据集和两个现实世界的文本数据集，这些偏见变得更加容易理解。
- en: The nature of data bias in augmenting makes it challenging to compute biases
    programmatically. However, you learned to write Python code for the fairness matrix
    in the text dataset using word counts and misspelled word techniques. You could
    use generative AI, such as Stable Diffusion or DALL-E, to automatically spot the
    biases in the photo and use OpenAI GPT3, GPT4, or Google Bard to compute the biases
    in text data. Unfortunately, generative AI is outside the scope of this book.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 数据增强中的偏见性质使得编程计算偏见变得具有挑战性。然而，你已经学会了如何使用单词计数和拼写错误单词技术为文本数据集编写 Python 代码来生成公平性矩阵。你还可以使用生成型
    AI，如 Stable Diffusion 或 DALL-E，自动识别照片中的偏见，并使用 OpenAI GPT3、GPT4 或 Google Bard 来计算文本数据中的偏见。不幸的是，生成型
    AI 超出了本书的讨论范围。
- en: Initially, Pluto tended to go slow with step-by-step explanations, but as you
    learned, he shortened the justification and showed only the bare minimum code.
    The complete code can be found in the Python Notebook.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 最初，Pluto 倾向于通过一步一步的解释来讲解，但随着学习的深入，他简化了论证过程，只展示了最基础的代码。完整的代码可以在 Python Notebook
    中找到。
- en: Most of the Python code is devoted to teaching you how to download real-world
    datasets from the *Kaggle* website and importing the metadata into pandas. The
    later chapters will reuse these helper and wrapper functions.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 大部分 Python 代码都用于教你如何从 *Kaggle* 网站下载真实世界的数据集，并将元数据导入 pandas。后续章节将复用这些助手和包装函数。
- en: Throughout this chapter, there were *fun facts* and *fun challenges*. Pluto
    hopes you will take advantage of these and expand your experience beyond the scope
    of this chapter.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，有许多*有趣的事实*和*有趣的挑战*。Pluto 希望你能充分利用这些，并将你的经验扩展到本章之外。
- en: Pluto looks forward to [*Chapter 3*](B17990_03.xhtml#_idTextAnchor058), where
    he will play with image augmentation in Python.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: Pluto 期待着[*第 3 章*](B17990_03.xhtml#_idTextAnchor058)，他将在那里展示如何在 Python 中进行图像增强。
- en: 'Part 2: Image Augmentation'
  id: totrans-337
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 2 部分：图像增强
- en: 'This part includes the following chapters:'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 本部分包括以下章节：
- en: '[*Chapter 3*](B17990_03.xhtml#_idTextAnchor058), *Image Augmentation for Classification*'
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第 3 章*](B17990_03.xhtml#_idTextAnchor058)，*用于分类的图像增强*'
- en: '[*Chapter 4*](B17990_04.xhtml#_idTextAnchor082), *Image Augmentation for Segmentation*'
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第 4 章*](B17990_04.xhtml#_idTextAnchor082)，*用于分割的图像增强*'
