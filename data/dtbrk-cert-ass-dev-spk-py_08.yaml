- en: '8'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '8'
- en: Machine Learning with Spark ML
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Spark ML进行机器学习
- en: Machine learning has gained popularity in recent times. In this chapter, we
    will do a comprehensive exploration of Spark **Machine Learning** (**ML**), a
    powerful framework for scalable ML on Apache Spark. We will delve into the foundational
    concepts of ML and how Spark ML leverages these principles to enable efficient
    and scalable data-driven insights.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，机器学习越来越受欢迎。在本章中，我们将全面探索Apache Spark上的强大框架Spark **机器学习**（**ML**），它是一个用于可扩展机器学习的框架。我们将深入研究机器学习的基础概念以及Spark
    ML如何利用这些原则来实现高效和可扩展的数据驱动洞察。
- en: 'We will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将涵盖以下主题：
- en: Key concepts in ML
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习的关键概念
- en: Different types of ML
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习的不同类型
- en: ML with Spark
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Spark进行机器学习
- en: Considering the ML life cycle with the help of a real-world example
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过一个真实世界的例子考虑机器学习生命周期
- en: Different case studies for ML
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习的不同案例研究
- en: Future trends in Spark ML and distributed ML
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Spark ML和分布式机器学习的未来趋势
- en: ML encompasses diverse methodologies tailored to different data scenarios. We
    will start by learning about different key concepts in ML.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习包含针对不同数据场景的多种方法。我们将从学习机器学习的不同关键概念开始。
- en: Introduction to ML
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习简介
- en: ML is a field of study that focuses on the development of algorithms and models
    that enable computer systems to learn and make predictions or decisions without
    being explicitly programmed. It is a subset of **artificial intelligence** (**AI**)
    that aims to provide systems with the ability to automatically learn and improve
    from data and experience.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是一个研究领域，专注于开发算法和模型，使计算机系统能够在没有被明确编程的情况下学习和做出预测或决策。它是**人工智能**（**AI**）的一个子集，旨在为系统提供自动从数据和经验中学习和改进的能力。
- en: In today’s world, where vast amounts of data are being generated at an unprecedented
    rate, ML plays a critical role in extracting meaningful insights, making accurate
    predictions, and automating decision-making processes. As data grows, machines
    can learn the patterns better, thus making it even easier to gain insights from
    this data. It finds applications in various domains, including finance, healthcare,
    marketing, image and speech recognition, recommendation systems, and many more.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在今天这个数据以前所未有的速度产生的大量数据的世界里，机器学习在提取有意义的洞察、做出准确预测和自动化决策过程中发挥着关键作用。随着数据的增长，机器可以更好地学习模式，从而更容易从这些数据中获得洞察。它在金融、医疗保健、营销、图像和语音识别、推荐系统等多个领域都有应用。
- en: The key concepts of ML
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习的核心概念
- en: To understand ML, it is important to grasp the fundamental concepts that underpin
    its methodology.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解机器学习，重要的是要掌握支撑其方法论的基本概念。
- en: Data
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据
- en: Data is the foundation of any ML process. It can be structured, semi-structured,
    or unstructured and encompasses various types, such as numerical, categorical,
    text, images, and more. ML algorithms require high-quality, relevant, and representative
    data to learn patterns and make accurate predictions. When dealing with ML problems,
    it is imperative to have data that can answer the question that we’re trying to
    solve. The quality of data used in any analysis or model-building process significantly
    impacts the outcomes and decisions derived from it. Bad or poor-quality data can
    lead to inaccurate, unreliable, or misleading results, ultimately affecting the
    overall performance and credibility of any analysis or model.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 数据是任何机器学习过程的基础。它可以是有结构的、半结构的或非结构的，并包括各种类型，如数值、分类、文本、图像等。机器学习算法需要高质量、相关和代表性的数据来学习模式和做出准确的预测。在处理机器学习问题时，拥有能够回答我们试图解决的问题的数据至关重要。在任何分析或模型构建过程中使用的数据质量将显著影响其结果和决策。不良或低质量的数据可能导致不准确、不可靠或误导性的结果，最终影响任何分析或模型的总体性能和可信度。
- en: An ML model trained on bad data is likely to make inaccurate predictions or
    classifications. For instance, a model trained on incomplete or biased data might
    incorrectly identify loyal customers as potential churners or vice versa.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在不良数据上训练的机器学习模型可能会做出不准确或错误的预测或分类。例如，在不完整或具有偏见的数据上训练的模型可能会错误地将忠诚的客户识别为潜在的流失者，反之亦然。
- en: Decision-makers relying on flawed or biased analysis derived from bad data might
    implement strategies based on inaccurate insights. For instance, marketing campaigns
    targeting the wrong customer segments due to flawed churn predictions can lead
    to wasted resources and missed opportunities.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 依赖于从不良数据中得出的有缺陷或偏见的分析决策者可能会实施基于不准确洞察的策略。例如，由于有缺陷的流失预测而针对错误客户群体的营销活动可能导致资源浪费和错失机会。
- en: Therefore, we need to make sure that the data we’re using for ML problems is
    representative of the population that we want to build the models for. The other
    thing to note is that data might have some inherent biases in it. It is our responsibility
    to look for them and be aware of them when using this data to build ML models.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们需要确保用于机器学习问题的数据能够代表我们想要构建模型的受众群体。另外一点需要注意的是，数据可能存在一些固有的偏差。我们有责任寻找这些偏差，并在使用这些数据构建机器学习模型时保持警觉。
- en: Features
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 特征
- en: Features are the measurable properties or characteristics of the data that the
    ML algorithm uses to make predictions or decisions. They are the variables or
    attributes that capture the relevant information from the data. Out of the vast
    amounts of data that are present, we want to understand which features of this
    data would be useful for solving a particular problem. Relevant features would
    generate better models.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 特征是机器学习算法用于做出预测或决策的数据的可测量属性或特征。它们是捕获数据中相关信息的变量或属性。在大量的数据中，我们希望了解哪些特征对解决特定问题是有用的。相关的特征会生成更好的模型。
- en: Feature engineering, the process of selecting, extracting, and transforming
    features, plays a crucial role in improving the performance of ML models.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 特征工程，即选择、提取和转换特征的过程，在提高机器学习模型性能方面起着至关重要的作用。
- en: Labels and targets
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 标签和目标
- en: Labels or targets are the desired outputs or outcomes that the ML model aims
    to predict or classify. In supervised learning, where the model learns from labeled
    data, the labels represent the correct answers or class labels associated with
    the input data. In unsupervised learning, the model identifies patterns or clusters
    in the data without any explicit labels.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 标签或目标是指机器学习模型旨在预测或分类的期望输出或结果。在监督学习中，模型从标记数据中学习，标签代表与输入数据相关的正确答案或类别标签。在无监督学习中，模型在数据中识别模式或簇，而不需要任何明确的标签。
- en: Training and testing
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 训练和测试
- en: In ML, models are trained using a subset of the available data, which is called
    the **training set**. The training process involves feeding the input data and
    corresponding labels to the model, which learns from this data to make predictions.
    Once the model is trained, its performance is evaluated using a separate subset
    of data called the testing set. This evaluation helps assess the model’s ability
    to generalize and make accurate predictions on unseen data.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中，模型使用可用数据的一个子集进行训练，这个子集被称为**训练集**。训练过程涉及将输入数据和相应的标签输入到模型中，模型从这些数据中学习以做出预测。一旦模型训练完成，其性能将使用另一个称为测试集的独立数据子集进行评估。这种评估有助于评估模型泛化能力和在未见数据上做出准确预测的能力。
- en: Algorithms and models
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 算法和模型
- en: ML algorithms are mathematical or statistical procedures that learn patterns
    and relationships in the data and make predictions or decisions. They can be categorized
    into various types, including regression, classification, clustering, dimensionality
    reduction, and reinforcement learning. These algorithms, when trained on data,
    generate models that capture the learned patterns and can be used to make predictions
    on new, unseen data.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习算法是学习数据中的模式和关系的数学或统计过程，并做出预测或决策。它们可以分为各种类型，包括回归、分类、聚类、降维和强化学习。这些算法在数据上训练后，会生成捕获学习模式的模型，可用于对新未见数据做出预测。
- en: Discussing different ML algorithms in depth is beyond the scope of this book.
    We will talk about different types of ML problems in the next section.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 深入讨论不同的机器学习算法超出了本书的范围。我们将在下一节讨论不同类型的机器学习问题。
- en: Types of ML
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习的类型
- en: ML problems can be broadly categorized into two distinct categories. In this
    section, we will explore both of them.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习问题可以大致分为两大类。在本节中，我们将探讨这两类。
- en: Supervised learning
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 监督学习
- en: Supervised learning is a type of ML where the algorithm learns from labeled
    training data to make predictions or decisions. In supervised learning, the training
    data consists of input features and corresponding output labels or target values.
    The goal is to learn a mapping function that can accurately predict the output
    for new, unseen inputs.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习是一种机器学习方法，其中算法从标记的训练数据中学习以做出预测或决策。在监督学习中，训练数据包括输入特征和相应的输出标签或目标值。目标是学习一个映射函数，可以准确地预测新输入的输出。
- en: 'The process of supervised learning involves the following steps:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习的过程包括以下步骤：
- en: '**Data preparation**: The first step is to collect and preprocess the training
    data. This includes cleaning the data, handling missing values, and transforming
    the data into a suitable format for the learning algorithm. The data should be
    split into features (input variables) and labels (output variables).'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**数据准备**：第一步是收集和预处理训练数据。这包括清理数据、处理缺失值以及将数据转换成适合学习算法的格式。数据应分为特征（输入变量）和标签（输出变量）。'
- en: '**Model training**: Once the data has been prepared, the supervised learning
    algorithm is trained on the labeled training data. The algorithm learns the patterns
    and relationships between the input features and the corresponding output labels.
    The goal is to find a model that can generalize well to unseen data and make accurate
    predictions.'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模型训练**：一旦数据已经准备好，监督学习算法就在标记的训练数据上训练。算法学习输入特征和相应输出标签之间的模式和关系。目标是找到一个可以很好地泛化到未见数据并做出准确预测的模型。'
- en: '**Model evaluation**: After training the model, it needs to be evaluated to
    assess its performance. This is done using a separate set of data called the testing
    or validation set. The model’s predictions are compared with the actual labels
    in the testing set, and various evaluation metrics such as accuracy, precision,
    recall, or mean squared error are calculated.'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模型评估**：在训练模型后，需要评估其性能。这是通过使用称为测试集或验证集的单独数据集来完成的。将模型的预测与测试集中的实际标签进行比较，并计算各种评估指标，如准确率、精确率、召回率或均方误差。'
- en: '**Model deployment and prediction**: Once the model is trained and evaluated,
    it can be deployed to make predictions on new, unseen data. The trained model
    takes the input features of the new data and produces predictions or decisions
    based on what it has learned during the training phase.'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模型部署和预测**：一旦模型经过训练和评估，就可以部署到对新数据做出预测。训练好的模型接受新数据的输入特征，并根据训练阶段学到的知识产生预测或决策。'
- en: 'Examples of supervised learning algorithms include linear regression, logistic
    regression, **support vector machines** (**SVM**), decision trees, random forests,
    gradient boosting, and neural networks. Again, going in-depth on these algorithms
    is beyond the scope of this book. You can read more about them here: [https://spark.apache.org/docs/latest/ml-classification-regression.html](https://spark.apache.org/docs/latest/ml-classification-regression.html).'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习算法的例子包括线性回归、逻辑回归、**支持向量机**（**SVM**）、决策树、随机森林、梯度提升和神经网络。再次强调，深入探讨这些算法超出了本书的范围。你可以在这里了解更多关于它们的信息：[https://spark.apache.org/docs/latest/ml-classification-regression.html](https://spark.apache.org/docs/latest/ml-classification-regression.html)。
- en: Unsupervised Learning
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 无监督学习
- en: Unsupervised learning is a type of ML where the algorithm learns patterns and
    relationships in the data without any labeled output. In unsupervised learning,
    the training data consists only of input features, and the goal is to discover
    hidden patterns, structures, or clusters within the data.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 无监督学习是一种机器学习类型，其中算法在没有任何标记输出的情况下学习数据中的模式和关系。在无监督学习中，训练数据仅由输入特征组成，目标是发现数据中的隐藏模式、结构或聚类。
- en: 'The process of unsupervised learning involves the following steps:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 无监督学习的过程包括以下步骤：
- en: '**Data preparation**: Similar to supervised learning, the first step is to
    collect and preprocess the data. However, in unsupervised learning, there are
    no labeled output values or target variables. The data is transformed and prepared
    in a way that it’s suitable for the specific unsupervised learning algorithm.'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**数据准备**：与监督学习类似，第一步是收集和预处理数据。然而，在无监督学习中，没有标记的输出值或目标变量。数据需要以适合特定无监督学习算法的方式转换和准备。'
- en: '**Model training**: In unsupervised learning, the algorithm is trained on the
    input features without any specific target variable. The algorithm explores the
    data and identifies patterns or clusters based on statistical properties or similarity
    measures. The goal is to extract meaningful information from the data without
    any predefined labels.'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模型训练**：在无监督学习中，算法在没有任何特定目标变量的输入特征上训练。算法通过统计属性或相似度度量探索数据，并识别模式或聚类。目标是提取数据中的有意义信息，而不需要任何预定义的标签。'
- en: '**Model evaluation** (optional): Unlike supervised learning, unsupervised learning
    does not have a direct evaluation metric based on known labels. Evaluation in
    unsupervised learning is often subjective and depends on the specific task or
    problem domain. It is also a more manual process than it is in supervised learning.
    Evaluation can involve visualizing the discovered clusters, assessing the quality
    of dimensionality reduction, or using domain knowledge to validate the results.'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模型评估**（可选）：与监督学习不同，无监督学习没有基于已知标签的直接评估指标。无监督学习中的评估通常是主观的，并取决于特定的任务或问题领域。它也比监督学习更手动。评估可能包括可视化发现的聚类、评估降维的质量或使用领域知识来验证结果。'
- en: '**Pattern discovery and insights**: The primary objective of unsupervised learning
    is to discover hidden patterns, structures, or clusters in the data. Unsupervised
    learning algorithms can reveal insights about the data, identify anomalies or
    outliers, perform dimensionality reduction, or generate recommendations.'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模式发现和洞察**：无监督学习的主要目标是发现数据中的隐藏模式、结构或聚类。无监督学习算法可以揭示关于数据的洞察，识别异常或离群值，执行降维或生成推荐。'
- en: Examples of unsupervised learning algorithms include K-means clustering, hierarchical
    clustering, **principal component analysis** (**PCA**), association rule mining,
    and **self-organizing** **maps** (**SOM**).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 无监督学习算法的例子包括 K-means 聚类、层次聚类、**主成分分析**（PCA）、关联规则挖掘和**自组织映射**（SOM）。
- en: In conclusion, supervised learning and unsupervised learning are two key types
    of ML. Supervised learning relies on labeled data to learn patterns and make predictions,
    while unsupervised learning discovers patterns and structures in unlabeled data.
    Both types have their own set of algorithms and techniques, as well as different
    choices. Discussing unsupervised learning in depth is beyond the scope of this
    book.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，监督学习和无监督学习是机器学习中的两种关键类型。监督学习依赖于标记数据来学习模式和进行预测，而无监督学习则在未标记数据中探索模式和结构。这两种类型都有它们自己的算法和技术，以及不同的选择。深入讨论无监督学习超出了本书的范围。
- en: In the next section, we will explore supervised ML, a cornerstone in the realm
    of AI and data science that represents a powerful approach to building predictive
    models and making data-driven decisions.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将探讨监督机器学习，这是人工智能和数据科学领域的一个基石，代表了构建预测模型和做出数据驱动决策的强大方法。
- en: Types of supervised learning
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 监督学习类型
- en: As we know, supervised learning is a branch of ML where algorithms learn patterns
    and relationships from labeled training data. It involves teaching or supervising
    the model by presenting input data along with corresponding output labels, allowing
    the algorithm to learn the mapping between the input and output variables. We’ll
    explore three key types of supervised learning – classification, regression, and
    time series.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所知，监督学习是机器学习的一个分支，其中的算法从标记的训练数据中学习模式和关系。它涉及通过展示输入数据及其相应的输出标签来教授或监督模型，使算法能够学习输入和输出变量之间的映射。我们将探讨三种关键的监督学习类型——分类、回归和时间序列。
- en: Classification
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分类
- en: Classification is a type of ML task where the goal is to categorize or classify
    data into predefined classes or categories based on its features. The algorithm
    learns from labeled training data to build a model that can predict the class
    label of new, unseen data instances.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 分类是一种机器学习任务，其目标是根据其特征将数据分类或归类到预定义的类别或类别中。算法从标记的训练数据中学习，以构建一个可以预测新、未见数据实例类别标签的模型。
- en: In classification, the output is discrete and represents class labels. Some
    common algorithms that are used for classification tasks include logistic regression,
    decision trees, random forests, SVM, and naive Bayes.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在分类中，输出是离散的，代表类别标签。用于分类任务的一些常见算法包括逻辑回归、决策树、随机森林、SVM和朴素贝叶斯。
- en: For example, consider a spam email classification task, where the goal is to
    predict whether an incoming email is spam or not. The algorithm is trained on
    a dataset of labeled emails, where each email is associated with a class label
    indicating whether it is spam or not. The trained model can then classify new
    emails as spam or non-spam based on their features, such as the content, subject,
    or sender.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑一个垃圾邮件分类任务，其目标是预测一封 incoming 邮件是否为垃圾邮件。算法在标记的邮件数据集上训练，其中每封邮件都与一个表示是否为垃圾邮件的类别标签相关联。训练好的模型可以根据其特征（如内容、主题或发件人）将新的邮件分类为垃圾邮件或非垃圾邮件。
- en: Regression
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 回归
- en: Regression is another type of ML task that focuses on predicting continuous
    or numerical values based on input features. In regression, the algorithm learns
    from labeled training data to build a model that can estimate or forecast the
    numerical value of a target variable given a set of input features.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 回归是另一种机器学习任务，它侧重于根据输入特征预测连续或数值值。在回归中，算法从标记的训练数据中学习，以构建一个模型，该模型可以估计或预测给定一组输入特征的目标变量的数值。
- en: Regression models are used when the output is a continuous value, such as predicting
    house prices, stock market trends, or predicting the sales of a product based
    on historical data. Some commonly used regression algorithms include linear regression,
    decision trees, random forests, gradient boosting, and neural networks.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 当输出是一个连续值时，例如预测房价、股票市场趋势或根据历史数据预测产品的销售，就会使用回归模型。一些常用的回归算法包括线性回归、决策树、随机森林、梯度提升和神经网络。
- en: For example, consider a case where you want to predict the price of a house
    based on its various features, such as the area, number of bedrooms, location,
    and so on. In this case, the algorithm is trained on a dataset of labeled house
    data, where each house is associated with its corresponding price. The trained
    regression model can then predict the price of a new house based on its features.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑一个案例，你想要根据房屋的各种特征（如面积、卧室数量、位置等）来预测房价。在这种情况下，算法是在一个标记的房屋数据集上训练的，其中每座房屋都与相应的价格相关联。训练好的回归模型可以基于新房屋的特征来预测其价格。
- en: Time series
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 时间序列
- en: Time series analysis is a specialized area of ML that deals with data collected
    over time, where the order of observations is important. In time series analysis,
    the goal is to understand and forecast the patterns, trends, and dependencies
    within the data.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列分析是机器学习的一个专门领域，它处理随时间收集的数据，其中观察的顺序很重要。在时间序列分析中，目标是理解和预测数据中的模式、趋势和依赖关系。
- en: Time series models are used to predict future values based on historical data
    points. They are widely used in fields such as finance, stock market prediction,
    weather forecasting, and demand forecasting. Some popular time series algorithms
    include **Autoregressive Integrated Moving Average** (**ARIMA**), exponential
    smoothing methods, and **long short-term memory** (**LSTM**) networks.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列模型用于根据历史数据点预测未来值。它们在金融、股票市场预测、天气预报和需求预测等领域得到广泛应用。一些流行的时序算法包括**自回归积分移动平均**（**ARIMA**）、指数平滑方法和**长短期记忆**（**LSTM**）网络。
- en: For example, suppose you have historical stock market data for a particular
    company, including the date and the corresponding stock prices. The time series
    algorithm can analyze the patterns and trends in the data and make predictions
    about future stock prices based on historical price fluctuations.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设你有一个特定公司的历史股票市场数据，包括日期和相应的股票价格。时间序列算法可以分析数据中的模式和趋势，并根据历史价格波动预测未来的股票价格。
- en: In conclusion, supervised learning encompasses various types, including classification,
    regression, and time series analysis. Each type addresses specific learning tasks
    and requires different algorithms and techniques. Understanding these types helps
    in choosing the appropriate algorithms and approaches for specific data analysis
    and prediction tasks.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，监督学习包括各种类型，如分类、回归和时间序列分析。每种类型都针对特定的学习任务，并需要不同的算法和技术。了解这些类型有助于选择适合特定数据分析与预测任务的最佳算法和方法。
- en: Next, we will explore how to leverage Spark for ML tasks.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将探讨如何利用Spark进行机器学习任务。
- en: ML with Spark
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Spark机器学习
- en: Spark provides a powerful and scalable platform for performing large-scale ML
    tasks. Spark’s **ML library**, also known as **MLlib**, offers a wide range of
    algorithms and tools for building and deploying ML models.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: Spark提供了一个强大且可扩展的平台，用于执行大规模机器学习任务。Spark的**ML库**，也称为**MLlib**，提供了一系列算法和工具，用于构建和部署机器学习模型。
- en: The advantages of using Spark for ML include its distributed computing capabilities,
    efficient data processing, scalability, and integration with other Spark components,
    such as Spark SQL and Spark Streaming. Spark’s MLlib supports both batch and streaming
    data processing, enabling the development of real-time ML applications.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Spark进行机器学习的优点包括其分布式计算能力、高效的数据处理、可扩展性和与其他Spark组件（如Spark SQL和Spark Streaming）的集成。Spark的MLlib支持批处理和流数据处理，使得实时机器学习应用的开发成为可能。
- en: ML is a transformative field that enables computers to learn from data and make
    predictions or decisions. By understanding the key concepts and leveraging tools
    such as Spark’s MLlib, we can harness the power of ML to gain insights, automate
    processes, and drive innovation across various domains.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是一个变革性的领域，它使计算机能够从数据中学习并做出预测或决策。通过理解关键概念并利用Spark的MLlib等工具，我们可以利用机器学习的力量来获得洞察力，自动化流程，并在各个领域推动创新。
- en: Now, let’s take a look at the benefits of using Spark for ML tasks.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来看看使用Spark进行机器学习任务的好处。
- en: Advantages of Apache Spark for large-scale ML
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Apache Spark在大规模机器学习中的优势
- en: 'By leveraging Spark’s distributed computing capabilities and rich ecosystem,
    data scientists and engineers can effectively tackle complex ML challenges on
    massive datasets. It offers various advantages due to its distributed computing
    capabilities, some of which are as follows:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 通过利用Spark的分布式计算能力和丰富的生态系统，数据科学家和工程师可以有效地解决大规模数据集上的复杂机器学习挑战。由于其分布式计算能力，它提供了各种优势，以下是一些：
- en: '**Speed and performance**: One of the key advantages of Apache Spark is its
    ability to handle large-scale data processing with exceptional speed. Spark leverages
    in-memory computing and optimized data processing techniques, such as **data parallelism**
    and **task pipelining**, to accelerate computations. This makes it highly efficient
    for iterative algorithms often used in ML, reducing the overall processing time
    significantly.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**速度和性能**：Apache Spark的一个关键优势是它能够以非凡的速度处理大规模数据。Spark利用内存计算和优化的数据处理技术，如**数据并行**和**任务管道化**，来加速计算。这使得它在机器学习中常用的迭代算法中效率极高，显著减少了整体处理时间。'
- en: '**Distributed computing**: Spark’s distributed computing model allows it to
    distribute data and computations across multiple nodes in a cluster, enabling
    parallel processing. This distributed nature enables Spark to scale horizontally,
    leveraging the computing power of multiple machines and processing data in parallel.
    This makes it well-suited for large-scale ML tasks that require processing massive
    volumes of data.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分布式计算**：Spark的分布式计算模型允许它在集群的多个节点上分配数据和计算，实现并行处理。这种分布式特性使得Spark能够水平扩展，利用多台机器的计算能力并行处理数据。这使得它非常适合需要处理大量数据的机器学习任务。'
- en: '**Fault tolerance**: Another advantage of Apache Spark is its built-in fault
    tolerance mechanism. Spark automatically tracks the lineage of **Resilient Distributed
    Datasets** (**RDDs**), which are the fundamental data abstraction in Spark, allowing
    it to recover from failures and rerun failed tasks. This ensures the reliability
    and resilience of Spark applications, making it a robust platform for handling
    large-scale ML workloads.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**容错性**：Apache Spark的另一个优点是其内置的容错机制。Spark自动跟踪**弹性分布式数据集**（RDDs）的 lineage，RDDs是Spark中的基本数据抽象，这使得它能够从故障中恢复并重新运行失败的任务。这确保了Spark应用程序的可靠性和弹性，使其成为处理大规模机器学习工作负载的强大平台。'
- en: '**Versatility and flexibility**: Spark provides a wide range of APIs and libraries
    that facilitate various data processing and analytics tasks, including ML. Spark’s
    MLlib library offers a rich set of distributed ML algorithms and utilities, making
    it easy to develop and deploy scalable ML models. Additionally, Spark integrates
    well with other popular data processing frameworks and tools, enabling seamless
    integration into existing data pipelines and ecosystems.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**通用性和灵活性**：Spark提供了一整套API和库，这些库简化了各种数据处理和分析任务，包括机器学习。Spark的MLlib库提供了一套丰富的分布式机器学习算法和实用工具，使得开发可扩展的机器学习模型变得容易。此外，Spark与流行的数据处理框架和工具集成良好，能够无缝集成到现有的数据管道和生态系统中。'
- en: '**Real-time and streaming capabilities**: As we discussed in the previous chapter,
    Spark extends its capabilities beyond batch processing with its streaming component
    called Spark Streaming. This is particularly valuable in scenarios where immediate
    insights or decisions are required based on continuously arriving data, such as
    real-time fraud detection, sensor data analysis, or sentiment analysis on social
    media streams.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**实时和流处理能力**：正如我们在上一章中讨论的，Spark通过其名为Spark Streaming的流组件扩展了其批处理之外的特性。这在需要基于持续到达的数据立即获得洞察或决策的场景中特别有价值，例如实时欺诈检测、传感器数据分析或社交媒体流上的情感分析。'
- en: '**Ecosystem and community support**: Apache Spark has a vibrant and active
    community of developers and contributors, ensuring continuous development, improvement,
    and support. Spark benefits from a rich ecosystem of tools and extensions, providing
    additional functionality and integration options. The community-driven nature
    of Spark ensures a wealth of resources, documentation, tutorials, and online forums
    for learning and troubleshooting.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生态系统和社区支持**：Apache Spark 拥有一个充满活力和活跃的开发者和贡献者社区，确保了持续的开发、改进和支持。Spark 从丰富的工具和扩展生态系统中受益，提供了额外的功能性和集成选项。Spark
    的社区驱动特性确保了丰富的资源、文档、教程和在线论坛，用于学习和故障排除。'
- en: Therefore, Apache Spark offers significant advantages for large-scale ML tasks.
    Its speed, scalability, fault tolerance, versatility, and real-time capabilities
    make it a powerful framework for processing big data and developing scalable ML
    models.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，Apache Spark 为大规模 ML 任务提供了显著的优势。其速度、可扩展性、容错性、多功能性和实时能力使其成为处理大数据和开发可扩展 ML
    模型的强大框架。
- en: Now let’s take a look at different libraries that Spark provides to make use
    of ML capabilities in the distributed framework.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看 Spark 提供的不同库，以在分布式框架中利用 ML 功能。
- en: Spark MLlib versus Spark ML
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Spark MLlib 与 Spark ML
- en: 'Apache Spark provides two libraries for ML: Spark MLlib and Spark ML. Although
    they share a similar name, there are some key differences between the two libraries
    in terms of their design, APIs, and functionality. Let’s compare Spark MLlib and
    Spark ML to understand their characteristics and use cases.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Spark 为 ML 提供了两个库：Spark MLlib 和 Spark ML。尽管它们名称相似，但在设计、API 和功能方面，这两个库之间有一些关键差异。让我们比较
    Spark MLlib 和 Spark ML，以了解它们的特性和用例。
- en: Spark MLlib
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Spark MLlib
- en: Spark MLlib is the original ML library in Apache Spark. It was introduced in
    earlier versions of Spark and provides a rich set of distributed ML algorithms
    and utilities. MLlib is built on top of the RDD API, which is the core data abstraction
    in Spark.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: Spark MLlib 是 Apache Spark 中的原始 ML 库。它在 Spark 的早期版本中引入，提供了一套丰富的分布式 ML 算法和实用工具。MLlib
    是建立在 RDD API 之上的，这是 Spark 中的核心数据抽象。
- en: 'Spark MLlib has a few key features that set it apart from other non-distributed
    ML libraries such as `scikit-learn`. Let’s look at a few of them:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: Spark MLlib 与其他非分布式 ML 库（如 `scikit-learn`）相比，有几个关键特性使其脱颖而出。让我们看看其中的一些：
- en: '**RDD-based API**: MLlib leverages the RDD abstraction for distributed data
    processing, making it suitable for batch processing and iterative algorithms.
    The RDD API allows for efficient distributed computing but can be low-level and
    complex for some use cases.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于RDD的API**：MLlib 利用 RDD 抽象进行分布式数据处理，使其适用于批量处理和迭代算法。RDD API 允许进行高效的分布式计算，但对于某些用例来说可能低级且复杂。'
- en: '**Diverse algorithms**: MLlib offers a wide range of distributed ML algorithms,
    including classification, regression, clustering, collaborative filtering, dimensionality
    reduction, and more. These algorithms are implemented to work with large-scale
    data and can handle various tasks in the ML pipeline.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多样化的算法**：MLlib 提供了广泛的分布式 ML 算法，包括分类、回归、聚类、协同过滤、降维等。这些算法旨在处理大规模数据，并且可以在 ML
    管道中处理各种任务。'
- en: '**Feature engineering**: MLlib provides utilities for feature extraction, transformation,
    and selection. It includes methods for handling categorical and numerical features,
    text processing, and feature scaling.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特征工程**：MLlib 提供了特征提取、转换和选择的实用工具。它包括处理分类和数值特征、文本处理和特征缩放的方法。'
- en: '**Model persistence**: MLlib supports model persistence, allowing trained models
    to be saved to disk and loaded later for deployment or further analysis.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型持久化**：MLlib 支持模型持久化，允许将训练好的模型保存到磁盘，并在以后用于部署或进一步分析。'
- en: In the next section, we will explore the Spark ML library. This is the newer
    library that also provides ML capabilities.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将探讨 Spark ML 库。这是另一个也提供 ML 功能的新库。
- en: Spark ML
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: Spark ML
- en: Spark ML, introduced in Spark 2.0, is the newer ML library in Apache Spark.
    It is designed to be more user-friendly, with a higher-level API and a focus on
    DataFrames, which are a structured and optimized distributed data collection introduced
    in Spark SQL.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: Spark ML 是在 Spark 2.0 中引入的 Apache Spark 中的较新 ML 库。它旨在更易于使用，具有高级 API 并专注于 DataFrame，这是
    Spark SQL 中引入的具有结构和优化的分布式数据集合。
- en: 'The key features of Spark ML are as follows:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: Spark ML 的关键特性如下：
- en: '**DataFrame-based API**: Spark ML leverages the DataFrame API, which provides
    a more intuitive and higher-level interface compared to the RDD API. DataFrames
    offer a structured and tabular data representation, making it easier to work with
    structured data and integrate with Spark SQL.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于DataFrame的API**：Spark ML利用DataFrame API，它比RDD API提供了更直观和更高层次的接口。DataFrame提供了结构化和表格化的数据表示，使得处理结构化数据以及与Spark
    SQL集成变得更加容易。'
- en: '**Pipelines**: Spark ML introduces the concept of pipelines, which provides
    a higher-level abstraction for constructing ML workflows. Pipelines enable the
    chaining of multiple data transformations and model training stages into a single
    pipeline, simplifying the development and deployment of complex ML pipelines.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**管道**：Spark ML引入了管道的概念，为构建机器学习工作流程提供了更高层次的抽象。管道允许将多个数据转换和模型训练阶段链接成一个单一的管道，简化了复杂机器学习管道的开发和部署。'
- en: '**Integrated feature transformers**: Spark ML includes a rich set of feature
    transformers, such as StringIndexer, OneHotEncoder, VectorAssembler, and more.
    These transformers seamlessly integrate with DataFrames and simplify the feature
    engineering process.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**集成特征转换器**：Spark ML包含了一系列特征转换器，如StringIndexer、OneHotEncoder、VectorAssembler等。这些转换器与DataFrame无缝集成，简化了特征工程过程。'
- en: '**Unified API**: Spark ML unifies the APIs for different ML tasks, such as
    classification, regression, clustering, and recommendation. This provides a consistent
    and cohesive programming interface across different algorithms and simplifies
    the learning curve.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**统一API**：Spark ML统一了不同机器学习任务的API，例如分类、回归、聚类和推荐。这为不同算法提供了一个一致且统一的编程接口，简化了学习曲线。'
- en: Now that we know the key features of both Spark MLlib and Spark ML, let’s explore
    when to use each of them.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经了解了Spark MLlib和Spark ML的关键特性，让我们来探讨何时使用它们。
- en: 'You would benefit from using Spark MLlib in the following scenarios:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下场景中，使用Spark MLlib将受益：
- en: You are working with older versions of Spark that do not support Spark ML
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你正在使用不支持Spark ML的Spark旧版本
- en: You require low-level control and need to work directly with RDDs
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你需要低级控制，并需要直接与RDDs工作
- en: You need access to a specific algorithm or functionality that is not available
    in Spark ML
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你需要访问Spark ML中不可用的特定算法或功能
- en: 'You should prefer to use Spark ML in the following scenarios:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下场景中，你应该优先使用Spark ML：
- en: You are using Spark 2.0 or later versions
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你正在使用Spark 2.0或更高版本
- en: You prefer a higher-level API and want to leverage DataFrames and Spark SQL
    capabilities
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你偏好更高层次的API，并希望利用DataFrames和Spark SQL的功能
- en: You need to build end-to-end ML pipelines with integrated feature transformers
    and pipelines
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你需要构建包含集成特征转换器和管道的端到端机器学习管道
- en: Both Spark MLlib and Spark ML provide powerful ML capabilities in Apache Spark.
    As we’ve seen, Spark MLlib is the original library with a rich set of distributed
    algorithms, while Spark ML is a newer library with a more user-friendly API and
    integration with DataFrames. The choice between the two depends on your Spark
    version, preference for API style, and specific requirements of your ML tasks.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: Spark MLlib和Spark ML都在Apache Spark中提供了强大的机器学习功能。正如我们所见，Spark MLlib是原始库，拥有丰富的分布式算法集，而Spark
    ML是一个更新的库，具有更用户友好的API和与DataFrames的集成。两者之间的选择取决于你的Spark版本、对API风格的偏好以及你机器学习任务的具体要求。
- en: ML life cycle
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习生命周期
- en: 'The ML life cycle encompasses the end-to-end process of developing and deploying
    ML models. It involves several stages, each with its own set of tasks and considerations.
    Understanding the ML life cycle is crucial for building robust and successful
    ML solutions. In this section, we will explore the key stages of the ML life cycle:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习生命周期涵盖了开发和部署机器学习模型的端到端过程。它包括几个阶段，每个阶段都有其自身的任务和考虑因素。理解机器学习生命周期对于构建稳健且成功的机器学习解决方案至关重要。在本节中，我们将探讨机器学习生命周期的关键阶段：
- en: '**Problem definition**: The first stage of the ML life cycle is problem definition.
    It involves clearly defining the problem you want to solve and understanding the
    goals and objectives of your ML project. This stage requires collaboration between
    domain experts and data scientists to identify the problem, define success metrics,
    and establish the scope of the project.'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**问题定义**：机器学习生命周期的第一阶段是问题定义。这涉及到明确界定你想要解决的问题，以及理解你的机器学习项目的目标和目的。这一阶段需要领域专家和数据科学家之间的协作，以识别问题、定义成功指标和确定项目的范围。'
- en: '**Data acquisition and understanding**: Once the problem has been defined,
    the next step is to acquire the necessary data for training and evaluation. Data
    acquisition may involve collecting data from various sources, such as databases,
    APIs, or external datasets. It is important to ensure data quality, completeness,
    and relevance to the problem at hand. Additionally, data understanding involves
    exploring and analyzing the acquired data to gain insights into its structure,
    distributions, and potential issues.'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**数据获取和理解**：一旦问题被定义，下一步就是获取用于训练和评估的必要数据。数据获取可能涉及从数据库、API或外部数据集中收集数据。确保数据质量、完整性和与当前问题的相关性非常重要。此外，数据理解涉及探索和分析获取到的数据，以深入了解其结构、分布和潜在问题。'
- en: '**Data preparation and feature engineering**: Data preparation and feature
    engineering are crucial steps in the ML life cycle. It involves transforming and
    preprocessing the data to make it suitable for training ML models. This includes
    tasks such as cleaning the data, handling missing values, encoding categorical
    variables, scaling features, and creating new features through feature engineering
    techniques. Proper data preparation and feature engineering significantly impact
    the performance and accuracy of ML models.'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**数据准备和特征工程**：数据准备和特征工程是机器学习生命周期中的关键步骤。它涉及转换和预处理数据，使其适合训练机器学习模型。这包括诸如清理数据、处理缺失值、编码分类变量、缩放特征以及通过特征工程技术创建新特征等任务。适当的数据准备和特征工程对机器学习模型的性能和准确性有重大影响。'
- en: '**Model training and evaluation**: In this stage, ML models are trained on
    the prepared data. Model training involves selecting an appropriate algorithm,
    defining the model architecture, and optimizing its parameters using training
    data. The trained model is then evaluated using evaluation metrics and validation
    techniques to assess its performance. This stage often requires iterating and
    fine-tuning the model to achieve the desired accuracy and generalization.'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模型训练和评估**：在这个阶段，机器学习模型在准备好的数据上进行训练。模型训练涉及选择合适的算法、定义模型架构，并使用训练数据优化其参数。然后使用评估指标和验证技术对训练好的模型进行评估，以评估其性能。这个阶段通常需要迭代和微调模型，以达到所需的准确性和泛化能力。'
- en: '**Model deployment**: Once the model has been trained and evaluated, it is
    ready for deployment. Model deployment involves integrating the model into the
    production environment, making predictions on new data, and monitoring its performance.
    This may involve setting up APIs, creating batch or real-time inference systems,
    and ensuring the model’s scalability and reliability. Deployment also includes
    considerations for model versioning, monitoring, and retraining to maintain the
    model’s effectiveness over time.'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模型部署**：一旦模型经过训练和评估，它就准备好进行部署。模型部署包括将模型集成到生产环境中，对新数据进行预测，并监控其性能。这可能涉及设置API、创建批量或实时推理系统，并确保模型的可扩展性和可靠性。部署还包括对模型版本控制、监控和重新训练的考虑，以保持模型随时间保持有效性。'
- en: '**Model monitoring and maintenance**: Once the model has been deployed, it
    is important to continuously monitor its performance and maintain its effectiveness.
    Monitoring involves tracking model predictions, detecting anomalies, and collecting
    feedback from users or domain experts. It also includes periodic retraining of
    the model using new data to adapt to changing patterns or concepts. Model maintenance
    involves addressing model drift, updating dependencies, and managing the model’s
    life cycle in the production environment.'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模型监控和维护**：一旦模型部署，持续监控其性能并保持其有效性至关重要。监控包括跟踪模型预测、检测异常，并从用户或领域专家那里收集反馈。它还包括使用新数据定期重新训练模型，以适应变化的模式或概念。模型维护涉及解决模型漂移、更新依赖项，并在生产环境中管理模型的生命周期。'
- en: '**Model iteration and improvement**: The ML life cycle is an iterative process,
    and models often require improvement over time. Based on user feedback, performance
    metrics, and changing business requirements, models may need to be updated, retrained,
    or replaced. Iteration and improvement are essential for keeping the models up-to-date
    and ensuring they continue to deliver accurate predictions.'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模型迭代和改进**：机器学习生命周期是一个迭代的过程，模型通常需要随着时间的推移进行改进。基于用户反馈、性能指标和不断变化的企业需求，模型可能需要更新、重新训练或替换。迭代和改进对于保持模型更新并确保它们继续提供准确的预测至关重要。'
- en: The ML life cycle involves problem definition, data acquisition, data preparation,
    model training, model deployment, model monitoring, and model iteration. Each
    stage plays a critical role in developing successful ML solutions. By following
    a well-defined life cycle, organizations can effectively build, deploy, and maintain
    ML models to solve complex problems and derive valuable insights from their data.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习生命周期包括问题定义、数据获取、数据准备、模型训练、模型部署、模型监控和模型迭代。每个阶段在开发成功的机器学习解决方案中都发挥着关键作用。通过遵循一个定义良好的生命周期，组织可以有效地构建、部署和维护机器学习模型，以解决复杂问题并从其数据中提取有价值的见解。
- en: Problem statement
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题陈述
- en: 'Let’s dive into a case study where we’ll explore the art of predicting house
    prices using historical data. Picture this: we have a treasure trove of valuable
    information about houses, including details such as zoning, lot area, building
    type, overall condition, year built, and sale price. Our goal is to harness the
    power of ML to accurately forecast the price of a new house that comes our way.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入一个案例研究，我们将探讨使用历史数据预测房价的艺术。想象一下：我们有一座关于房屋的宝贵信息宝库，包括分区、地块面积、建筑类型、整体状况、建造年份和销售价格等细节。我们的目标是利用机器学习的力量，准确预测即将到来的新房屋的价格。
- en: To accomplish this feat, we’ll embark on a journey to construct an ML model
    exclusively designed for predicting house prices. This model will leverage the
    existing historical data and incorporate additional features. By carefully analyzing
    and understanding the relationships between these features and the corresponding
    sale prices, our model will become a reliable tool for estimating the value of
    any new house that enters the market.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 为了完成这一壮举，我们将踏上构建一个专门用于预测房价的机器学习模型的旅程。该模型将利用现有的历史数据并纳入额外的特征。通过仔细分析和理解这些特征与相应销售价格之间的关系，我们的模型将成为估计任何新进入市场的房屋价值的可靠工具。
- en: To achieve this, we will go through some of the steps defined in the previous
    section, where we talked about the ML life cycle. Since housing prices are continuous,
    we will use a linear regression model to predict these prices.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这一点，我们将回顾上一节中定义的一些步骤，其中我们讨论了机器学习生命周期。由于房价是连续的，我们将使用线性回归模型来预测这些价格。
- en: We will start by preparing the data to make it usable for an ML model.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先准备数据，使其可用于机器学习模型。
- en: Data preparation and feature engineering
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据准备和特征工程
- en: As we know, data preparation and feature engineering are crucial steps in the
    ML process. Proper data preparation and feature engineering techniques can significantly
    improve the performance and accuracy of models. In this section, we will explore
    common data preparation and feature engineering tasks with code examples.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所知，数据准备和特征工程是机器学习过程中的关键步骤。适当的数据准备和特征工程技术可以显著提高模型的性能和准确性。在本节中，我们将通过代码示例探索常见的数据准备和特征工程任务。
- en: Introduction to the dataset
  id: totrans-126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据集介绍
- en: The first step in building a model is to find the relevant data. We are going
    to use house price data (located at [https://docs.google.com/spreadsheets/d/1caaR9pT24GNmq3rDQpMiIMJrmiTGarbs/edit#gid=1150341366](https://docs.google.com/spreadsheets/d/1caaR9pT24GNmq3rDQpMiIMJrmiTGarbs/edit#gid=1150341366))
    for this purpose. This data has 2,920 rows and 13 columns.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 构建模型的第一步是找到相关数据。我们将为此目的使用房价数据（位于[https://docs.google.com/spreadsheets/d/1caaR9pT24GNmq3rDQpMiIMJrmiTGarbs/edit#gid=1150341366](https://docs.google.com/spreadsheets/d/1caaR9pT24GNmq3rDQpMiIMJrmiTGarbs/edit#gid=1150341366)）。这些数据有2,920行和13列。
- en: 'This dataset has the following columns:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集有以下列：
- en: '`Id`: Unique identifier for each row of the data'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Id`: 数据表中每行的唯一标识符'
- en: '`MSSubClass`: Subclass of the property'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MSSubClass`: 房地产的子类'
- en: '`MSZoning`: Zoning of the property'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MSZoning`: 房地产的分区'
- en: '`LotArea`: Total area of the lot where the property is situated'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`LotArea`: 该房产所在地块的总面积'
- en: '`LotConfig`: Configuration of the lot – for example, if it’s a corner lot'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`LotConfig`: 地块配置 – 例如，是否为角地块'
- en: '`BldgType`: Type of home – for example, single, family, and so on'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`BldgType`: 住宅类型 – 例如，单户住宅、联排别墅等'
- en: '`OverallCond`: General condition of the house'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`OverallCond`: 房屋的一般状况'
- en: '`YearBuilt`: The year the house was built in'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`YearBuilt`: 房屋建造的年份'
- en: '`YearRemodAdd`: The year any remodeling was done'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`YearRemodAdd`: 进行任何翻修的年份'
- en: '`Exterior1st`: Type of exterior – for example, vinyl, siding, and so on'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Exterior1st`: 外部类型 – 例如，乙烯基、外墙板等'
- en: '`BsmtFinSF2`: Total size of finished basement'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`BsmtFinSF2`: 完成地下室的总面积'
- en: '`TotalBsmtSF`: Total size of basement'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TotalBsmtSF`: 地下室的总面积'
- en: '`SalePrice`: The sale price of the house'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`SalePrice`: 房屋的销售价格'
- en: We will download this data from the link provided at the beginning of this section.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从本节开头提供的链接下载这些数据。
- en: Now that we know some of the data points that exist in the data, let’s learn
    how to load it.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了一些数据中的数据点，让我们学习如何加载数据。
- en: Loading data
  id: totrans-144
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 加载数据
- en: 'At this point, we already have the data downloaded on our computer and to our
    Databricks environment as a CSV file. As you may recall from the previous chapters,
    we learned how to load a dataset into a DataFrame through various techniques.
    We will use a CSV file here to load the data:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经在我们的计算机和Databricks环境中下载了数据，并以CSV文件的形式存在。如您从前面的章节中回忆起来，我们学习了如何通过各种技术将数据集加载到DataFrame中。在这里，我们将使用CSV文件来加载数据：
- en: '[PRE0]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We can see the result in Figure 8.1\. Please note that we can see only part
    of the result in the image since the dataset is too large to be displayed in full.:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在图8.1中看到结果。请注意，由于数据集太大，无法全部显示，我们只能看到部分结果：
- en: '![](img/B19176_08_1.jpg)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B19176_08_1.jpg)'
- en: 'Let’s print the schema of this dataset:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们打印这个数据集的模式：
- en: '[PRE1]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We will get the following schema:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将得到以下模式：
- en: '[PRE2]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: As you may have noticed, some of the column types are strings. We will clean
    up this data in the next section.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 如您可能已经注意到的，一些列的类型是字符串。我们将在下一节中清理这些数据。
- en: Cleaning data
  id: totrans-154
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 清洗数据
- en: 'Cleaning the data involves handling missing values, outliers, and inconsistent
    data. Before we clean up the data, we will see how many rows are in the data.
    We can do this by using the `count()` function:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 数据清洗涉及处理缺失值、异常值和不一致的数据。在我们清理数据之前，我们将查看数据中有多少行。我们可以通过使用`count()`函数来完成：
- en: '[PRE3]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The result of this statement is shown here:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 该语句的结果如下所示：
- en: '[PRE4]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'This means the data contains 2,919 rows before we apply any cleaning. Now,
    we will drop missing values from this dataset, like so:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着在我们应用任何清洗之前，数据中包含2,919行。现在，我们将从该数据集中删除缺失值，如下所示：
- en: '[PRE5]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The result of this code is as follows:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是该代码的结果：
- en: '[PRE6]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This shows that we have dropped some rows of data and that the data size is
    smaller now.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 这表明我们删除了一些数据行，现在数据量变小了。
- en: In the next section, we will discuss categorical variables and how to handle
    them, specifically those represented as strings in our example.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将讨论分类变量以及如何处理它们，特别是我们例子中用字符串表示的那些。
- en: Handling categorical variables
  id: totrans-165
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 处理分类变量
- en: In the realm of statistics and data analysis, a categorical variable is a type
    of variable that represents categories or groups and can take on a limited, fixed
    number of distinct values or levels. These variables signify qualitative characteristics
    and do not possess inherent numerical significance or magnitude. Instead, they
    represent different attributes or labels that classify data into specific groups
    or classes. Categorical variables need to be encoded to numerical values before
    training machine learning models.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在统计学和数据分析领域，分类变量是一种表示类别或组别的变量类型，它可以取有限、固定的不同值或级别。这些变量表示定性特征，不具有固有的数值意义或大小。相反，它们代表不同的属性或标签，将数据分类到特定的组或类别中。在训练机器学习模型之前，分类变量需要被编码成数值。
- en: In our example, we have a few columns that are string types. Those need to be
    encoded into numerical values so that the model can correctly use them. For this
    purpose, we’ll use Spark’s `StringIndexer` library to index the string columns.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的例子中，我们有一些是字符串类型的列。这些需要被编码成数值，以便模型能够正确使用它们。为此，我们将使用Spark的`StringIndexer`库来索引字符串列。
- en: 'The following code shows how to use `StringIndexer`:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码显示了如何使用`StringIndexer`：
- en: '[PRE7]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: In the preceding code, we are taking the `MSZoning` column and converting it
    into an indexed column. To achieve this, we created a `StringIndexer` value by
    the name of `mszoning` indexer. We gave it `MSZoning` as the input column to work
    on. The output column’s name is `MSZoningIndex`. We will use this output column
    in the next step. After that, we’ll fit `mszoning_indexer` to `cleaned_data`.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们正在将`MSZoning`列转换为索引列。为了实现这一点，我们创建了一个名为`mszoning`的`StringIndexer`值。我们将其`MSZoning`作为要处理的输入列。输出列的名称是`MSZoningIndex`。我们将在下一步中使用这个输出列。之后，我们将`mszoning_indexer`拟合到`cleaned_data`。
- en: In the resulting DataFrame, you will notice that one additional column was added
    by the name of `MSZoningIndex`.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在生成的DataFrame中，您将注意到增加了一个名为`MSZoningIndex`的额外列。
- en: Now, we will use a pipeline to transform all the features in the DataFrame.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将使用管道来转换DataFrame中的所有特征。
- en: A **pipeline** brings together a series of essential steps, each contributing
    to transforming raw data into valuable predictions and analyses. The pipeline
    serves as a structured pathway, composed of distinct stages or components, arranged
    in a specific order. Each stage represents a unique operation or transformation
    that refines the data, molding it into a more suitable format for ML tasks.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '**管道**汇集了一系列必要的步骤，每个步骤都致力于将原始数据转换为有价值的预测和分析。管道作为一个结构化的路径，由不同的阶段或组件组成，按照特定的顺序排列。每个阶段代表一个独特的操作或转换，它精炼数据，使其更适合机器学习任务。'
- en: At the heart of a pipeline lies its ability to seamlessly connect these stages,
    forming a well-coordinated flow of transformations. This orchestration ensures
    that the data flows effortlessly through each stage, with the output of one stage
    becoming the input for the next. It eradicates the need for manual intervention,
    automating the entire process and saving us valuable time and effort. We integrate
    a variety of operations into the pipeline, such as data cleaning, feature engineering,
    encoding categorical variables, scaling numerical features, and much more. Each
    operation plays its part in transforming the data, to make it usable for the ML
    model.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 管道（pipeline）的核心在于其无缝连接这些阶段的能力，形成一个协调一致的转换流程。这种编排确保数据能够轻松地通过每个阶段，一个阶段的输出成为下一个阶段的输入。它消除了手动干预的需要，自动化整个过程，节省了我们宝贵的时间和精力。我们将各种操作集成到管道中，如数据清洗、特征工程、编码分类变量、缩放数值特征等等。每个操作都在转换数据，使其可用于机器学习模型。
- en: The ML pipeline empowers us to streamline our workflows, experiment with different
    combinations of transformations, and maintain consistency in our data processing
    tasks. It provides a structured framework that allows us to effortlessly reproduce
    and share our work, fostering collaboration and fostering a deeper understanding
    of the data transformation process.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习管道使我们能够简化我们的工作流程，尝试不同的转换组合，并在数据处理任务中保持一致性。它提供了一个结构化的框架，使我们能够轻松地重现和分享我们的工作，促进协作，并加深我们对数据转换过程的理解。
- en: In ML and data preprocessing, a **one-hot encoder** is a technique that’s used
    to convert categorical variables into a numerical format, allowing algorithms
    to better understand and process categorical data. It’s particularly useful when
    working with categorical features that lack ordinal relationships or numerical
    representation.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习和数据预处理中，**独热编码器**是一种将分类变量转换为数值格式的技术，使算法能够更好地理解和处理分类数据。当处理缺乏序数关系或数值表示的分类特征时，它特别有用。
- en: 'We will use `StringIndexer` and `OneHotEncoder` in this pipeline. Let’s see
    how we can achieve this:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在管道中使用 `StringIndexer` 和 `OneHotEncoder`。让我们看看我们如何实现这一点：
- en: '[PRE8]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: To begin our code, we import the required modules from the PySpark library.
    The `StringIndexer` and `OneHotEncoder` modules will be used to handle the string
    columns of the housing dataset.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始我们的代码，我们需要从 PySpark 库中导入所需的模块。`StringIndexer` 和 `OneHotEncoder` 模块将被用来处理住房数据集的字符串列。
- en: As we embark on the process of transforming categorical columns into numerical
    representations that can be understood by ML algorithms, let’s take a closer look
    at the magic happening in our code.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们开始将分类列转换为机器学习算法可以理解的数值表示的过程时，让我们更仔细地看看代码中发生的魔法。
- en: The first step is to create `StringIndexer` instances for each categorical column
    we wish to transform. Each instance takes an input column, such as `MSZoning`
    or `LotConfig`, and produces a corresponding output column with a numerical index.
    For example, the `MSZoningIndex` column captures the transformed index values
    of the `MSZoning` column.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是为我们希望转换的每个分类列创建 `StringIndexer` 实例。每个实例接受一个输入列，例如 `MSZoning` 或 `LotConfig`，并生成一个相应的输出列，带有数值索引。例如，`MSZoningIndex`
    列捕获了 `MSZoning` 列的转换索引值。
- en: With the categorical columns successfully indexed, we progress to the next stage.
    Now, we want to convert these indices into binary vectors. For that, we can use
    `OneHotEncoder`. The resulting vectors represent each categorical value as a binary
    array, with a value of 1 indicating the presence of that category and 0 otherwise.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 分类列成功索引后，我们进入下一阶段。现在，我们希望将这些索引转换为二进制向量。为此，我们可以使用 `OneHotEncoder`。生成的向量将每个分类值表示为一个二进制数组，其中值为
    1 表示该类别的存在，否则为 0。
- en: We create `OneHotEncoder` instances for each indexed column, such as `MSZoningIndex`
    or `LotConfigIndex`, and generate new output columns holding the binary vector
    representations. These output columns, such as `MSZoningVector` or `LotConfigVector`,
    are used to capture the encoded information.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为每个索引列创建 `OneHotEncoder` 实例，例如 `MSZoningIndex` 或 `LotConfigIndex`，并生成包含二进制向量表示的新输出列。这些输出列，如
    `MSZoningVector` 或 `LotConfigVector`，用于捕获编码信息。
- en: As our code progresses, we assemble a pipeline – a sequence of transformations
    – where each transformation represents a stage. In our case, each stage encompasses
    the steps of indexing and one-hot encoding for a specific categorical column.
    We arrange the stages in the pipeline, ensuring the correct order of transformations.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 随着代码的进展，我们组装了一个管道——一系列转换，其中每个转换代表一个阶段。在我们的案例中，每个阶段包括特定分类列的索引和独热编码步骤。我们在管道中安排这些阶段，确保转换的正确顺序。
- en: By structuring our pipeline, we orchestrate a seamless flow of operations. The
    pipeline connects the dots between different stages, making it effortless to apply
    these transformations to our dataset as a whole. Our pipeline acts as a conductor,
    leading our data through the transformations, ultimately making it into a format
    ready for ML.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 通过构建我们的管道，我们协调了操作的流畅流程。管道连接了不同阶段之间的点，使得将这些转换应用到整个数据集上变得毫不费力。我们的管道充当指挥，引导数据通过转换，最终使其成为适合机器学习的格式。
- en: 'Now, we will fit this pipeline to our cleaned dataset so that all the columns
    can be transformed together:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将此管道拟合到我们的清理数据集，以便所有列都可以一起转换：
- en: '[PRE9]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The resulting DataFrame will have the additional columns that we created in
    the pipeline with transformation. We have created index and vector columns for
    each of the string columns.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 结果 DataFrame 将包含我们在管道中通过转换创建的附加列。我们为每个字符串列创建了索引和向量列。
- en: Now, we need to remove the unnecessary and redundant columns from our dataset.
    We will do this in the next section.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们需要从我们的数据集中删除不必要的冗余列。我们将在下一节中这样做。
- en: Data cleanup
  id: totrans-190
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据清理
- en: In this step, we will make sure that we are only using the features needed by
    ML. To achieve this, we will remove different additional columns, such as the
    identity column, which don’t serve the model. Moreover, we will also remove the
    features that we have already applied transformations to, such as string columns.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一步中，我们将确保我们只使用 ML 所需的特征。为了实现这一点，我们将删除不同的附加列，例如不服务于模型的身份列。此外，我们还将删除我们已经应用了转换的特征，例如字符串列。
- en: 'The following code shows how to delete the columns:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码展示了如何删除列：
- en: '[PRE10]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Here’s the result:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 这是结果：
- en: '[PRE11]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: As you can see from the resulting column list, the `Id`, `MSZoning`, `LotConfig`,
    `BldgType`, and `Exterior1st` columns have been deleted from the resulting DataFrame.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 如您从结果列列表中看到的，`Id`、`MSZoning`、`LotConfig`、`BldgType` 和 `Exterior1st` 列已从结果 DataFrame
    中删除。
- en: The next step in the process is assembling the data.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 过程中的下一步是组装数据。
- en: Assembling the vector
  id: totrans-198
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 组装向量
- en: In this step, we will assemble a vector based on the features that we want.
    This step is necessary for Spark ML to work with data.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一步中，我们将根据我们想要的特性组装一个向量。这一步对于 Spark ML 与数据一起工作来说是必要的。
- en: 'The following code captures how we can achieve this:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码捕捉了我们如何实现这一点：
- en: '[PRE12]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: In the preceding code block, we have created a features column that contains
    the assembled vector. We will use this column for our model training after scaling
    it.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码块中，我们创建了一个包含组装向量的 `features` 列。在对其进行缩放后，我们将使用此列进行模型训练。
- en: Once the vector has been assembled, the next step in the process is to scale
    the data.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 向量组装完成后，过程的下一步是对数据进行缩放。
- en: Feature scaling
  id: totrans-204
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 特征缩放
- en: Feature scaling ensures that all features are on a similar scale, preventing
    certain features from dominating the learning process.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 特征缩放确保所有特征都在相似的尺度上，防止某些特征主导学习过程。
- en: 'For this, we can use the following code:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 为了做到这一点，我们可以使用以下代码：
- en: '[PRE13]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The following code selects only the scaled features and the target column –
    that is, `SalePrice`:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码仅选择缩放后的特征和目标列——即 `SalePrice`：
- en: '[PRE14]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We’ll get the following output:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将得到以下输出：
- en: '[PRE15]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: As you can see, `df_model_final` now only has two columns. `SalePrice` is the
    column that we’re going to predict so that is our target column. `scaledFeatures`
    contains all the features that we are going to use to train our ML model.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，`df_model_final` 现在只有两列。`SalePrice` 是我们将要预测的列，因此是我们的目标列。`scaledFeatures`
    包含我们将用于训练 ML 模型的所有特征。
- en: These examples demonstrate common data preparation and feature engineering tasks
    using PySpark. However, the specific techniques and methods applied may vary,
    depending on the dataset and the requirements of the ML task. It is essential
    to understand the characteristics of the data and choose appropriate techniques
    to preprocess and engineer features effectively. Proper data preparation and feature
    engineering lay the foundation for building accurate and robust ML models.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 这些示例展示了使用PySpark进行常见的数据准备和特征工程任务。然而，具体的技术和方法可能因数据集和机器学习任务的要求而异。理解数据的特征并选择适当的预处理和特征工程技术至关重要。适当的数据准备和特征工程是构建准确和稳健的机器学习模型的基础。
- en: The next step in this process is training and evaluating the ML model.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 此过程的下一步是训练和评估机器学习模型。
- en: Model training and evaluation
  id: totrans-215
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型训练和评估
- en: Model training and evaluation are crucial steps in the ML process. In this section,
    we will explore how to train ML models and evaluate their performance using various
    metrics and techniques. We will use PySpark as the framework for model training
    and evaluation.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 模型训练和评估是机器学习过程中的关键步骤。在本节中，我们将探讨如何使用各种指标和技术来训练机器学习模型并评估其性能。我们将使用PySpark作为模型训练和评估的框架。
- en: Splitting the data
  id: totrans-217
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据拆分
- en: 'Before training a model, it is important to split the dataset into training
    and testing sets. The training set is used to train the model, while the testing
    set is used to evaluate its performance. Here’s an example of how to split the
    data using PySpark:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练模型之前，将数据集拆分为训练集和测试集非常重要。训练集用于训练模型，而测试集用于评估其性能。以下是如何使用PySpark拆分数据的示例：
- en: '[PRE16]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: In the preceding code, we are doing a random split of the data, putting 75%
    of the data into the training set and 25% of the data into the test set. There
    are other split techniques as well. You should look at your data carefully and
    then define the split that works best for your data and model training.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们正在进行数据的随机拆分，将75%的数据放入训练集，将25%的数据放入测试集。还有其他拆分技术。你应该仔细查看你的数据，然后定义最适合你的数据和模型训练的拆分方式。
- en: The reason we split the data is that once we train the model, we want to see
    how the trained model predicts on a dataset that it has never seen. In this case,
    that is our test dataset. This would help us evaluate the model and determine
    the quality of the model. Based on this, we can deploy different techniques to
    improve our model.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 我们拆分数据的原因是，一旦我们训练了模型，我们想看看训练好的模型在它从未见过的数据集上的预测效果如何。在这种情况下，那就是我们的测试数据集。这将帮助我们评估模型并确定模型的质量。基于此，我们可以采用不同的技术来改进我们的模型。
- en: The next step is model training.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是模型训练。
- en: Model training
  id: totrans-223
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型训练
- en: Once the data has been split, we can train an ML model on the training data.
    PySpark provides a wide range of algorithms for various types of ML tasks. For
    this example, we are going to use linear regression as our model of choice.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 数据拆分后，我们可以在训练数据上训练一个机器学习模型。PySpark为各种类型的机器学习任务提供了一系列算法。在这个例子中，我们将使用线性回归作为我们的选择模型。
- en: 'Here’s an example of training a linear regression model:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个训练线性回归模型的示例：
- en: '[PRE17]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: In the preceding code, we are using the training data and fitting it into a
    linear regressor model. We also added a parameter for `labelCol` that tells the
    model that this is the column that is our target column to predict.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们正在使用训练数据并将其拟合到线性回归模型中。我们还添加了一个名为`labelCol`的参数，告诉模型这是我们的目标列，用于预测。
- en: Once the model has been trained, the next step is to determine how good the
    model is. We’ll do this in the next section by evaluating the model.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 模型训练完成后，下一步是确定模型的好坏。我们将在下一节通过评估模型来完成这一步。
- en: Model evaluation
  id: totrans-229
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型评估
- en: After training the model, we need to evaluate its performance on the test data.
    Evaluation metrics provide insights into how well the model is performing.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 模型训练后，我们需要评估其在测试数据上的性能。评估指标提供了关于模型性能的见解。
- en: '**Mean squared error** (**MSE**) is a fundamental statistical metric that’s
    used to evaluate the performance of regression models by quantifying the average
    of the squared differences between predicted and actual values.'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: '**均方误差**（**MSE**）是一个基本的统计指标，用于通过量化预测值和实际值之间平方差的平均值来评估回归模型的性能。'
- en: '**R-squared**, often denoted as **R2**, is a statistical measure that represents
    the proportion of the variance in the dependent variable that is predictable or
    explained by the independent variables in a regression model. It serves as an
    indicator of how well the independent variables explain the variability of the
    dependent variable.'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: '**R平方**，通常表示为**R2**，是一个统计量，表示在回归模型中，因变量的方差中有多少是可预测的或由自变量解释的。它作为独立变量解释因变量变异性好坏的指标。'
- en: 'Here’s an example of evaluating a regression model using the MSE and R2 metrics:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是使用均方误差（MSE）和R2指标评估回归模型的一个示例：
- en: '[PRE18]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Here’s the result:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是结果：
- en: '[PRE19]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'We can check the test data’s performance as depicted here:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以检查测试数据的性能，如图所示：
- en: '[PRE20]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Here’s the result:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是结果：
- en: '[PRE21]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Based on the results of the model, we can tune it further. We’ll see some of
    the techniques to achieve this in the next section.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 根据模型的结果，我们可以进一步调整它。我们将在下一节中看到实现这一目标的一些技术。
- en: Cross-validation
  id: totrans-242
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 交叉验证
- en: Cross-validation is one of the different methods to improve an ML model’s performance.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉验证是提高机器学习模型性能的不同方法之一。
- en: Cross-validation is used to assess the model’s performance more robustly by
    dividing the data into multiple subsets for training and evaluation. So, instead
    of just using train and test data, we use a validation set as well, where the
    model never sees that data and is only used for measuring performance.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将数据分成多个子集进行训练和评估，交叉验证用于更稳健地评估模型性能。因此，我们不仅使用训练和测试数据，还使用一个验证集，模型从未见过这些数据，仅用于衡量性能。
- en: 'Cross-validation follows a simple principle: rather than relying on a single
    train-test split, we divide our dataset into multiple subsets, or **folds**. Each
    fold acts as a mini train-test split, with a portion of the data used for training
    and the remainder reserved for testing. By rotating the folds, we ensure that
    every data point gets an opportunity to be part of the test set, thereby mitigating
    biases and providing a more representative evaluation.'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉验证遵循一个简单的原则：而不是依赖于单一的训练-测试分割，我们将数据集分成多个子集，或称为**折**。每个折作为一个迷你训练-测试分割，其中一部分数据用于训练，其余部分保留用于测试。通过旋转折，我们确保每个数据点都有机会成为测试集的一部分，从而减轻偏差，提供更具有代表性的评估。
- en: The most common form of cross-validation is **k-fold cross-validation**. In
    this method, the dataset is divided into k equal-sized folds. The model is trained
    and evaluated k times, with each fold serving as the test set once while the remaining
    folds collectively form the training set. By averaging the performance metrics
    obtained from each iteration, we obtain a more robust estimation of our model’s
    performance.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 最常见的交叉验证形式是**k折交叉验证**。在这种方法中，数据集被分为k个大小相等的折。模型被训练和评估k次，每次每个折作为测试集，而其余的折共同组成训练集。通过平均每次迭代获得的表现指标，我们得到对模型性能的更稳健估计。
- en: Through cross-validation, we gain valuable insights into the generalization
    capabilities of our model. It allows us to gauge its performance across different
    subsets of the data, capturing the inherent variations and nuances that exist
    within our dataset. This technique helps us detect potential issues such as **overfitting**,
    where the model performs exceptionally well on the training set but fails to generalize
    to unseen data.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 通过交叉验证，我们获得了关于模型泛化能力的宝贵见解。它使我们能够衡量模型在不同数据子集中的性能，捕捉数据集中存在的固有变化和细微差别。这种技术帮助我们检测潜在的**过拟合**问题，即模型在训练集上表现异常出色，但无法泛化到未见过的数据。
- en: In addition to k-fold cross-validation, there are variations and extensions
    tailored to specific scenarios. **Stratified cross-validation** ensures that each
    fold maintains the same class distribution as the original dataset, preserving
    the representativeness of the splits. **Leave-one-out cross-validation**, on the
    other hand, treats each data point as a separate fold, providing a stringent evaluation
    but at the cost of increased computational complexity.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 除了k折交叉验证之外，还有针对特定场景的变体和扩展。**分层交叉验证**确保每个折保持与原始数据集相同的类别分布，从而保持分割的代表性。另一方面，**留一法交叉验证**将每个数据点视为一个单独的折，提供严格的评估，但代价是增加了计算复杂性。
- en: Next, we will learn about hyperparameter tuning.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将学习超参数调优。
- en: Hyperparameter tuning
  id: totrans-250
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 超参数调优
- en: '**Hyperparameter tuning** is the process of optimizing the hyperparameters
    of an ML algorithm to improve its performance. Hyperparameters are settings or
    configurations that are external to the model and cannot be learned from the training
    data directly. Unlike model parameters, which are learned during the training
    process, hyperparameters need to be specified beforehand and are crucial in determining
    the behavior and performance of an ML model. We will use hyperparameter tuning
    to improve model performance. **Hyperparameters** are parameters that are not
    learned from the data but are set before training. Tuning hyperparameters can
    significantly impact the model’s performance.'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: '**超参数调优**是优化机器学习算法超参数的过程，以提高其性能。超参数是模型外部的设置或配置，不能直接从训练数据中学习。与在训练过程中学习的模型参数不同，超参数需要在事先指定，并在确定机器学习模型的行为和性能方面至关重要。我们将使用超参数调优来提高模型性能。**超参数**是在训练之前设置的参数，不是从数据中学习的。调整超参数可以显著影响模型的表现。'
- en: 'Picture this: our model is a complex piece of machinery, composed of various
    knobs and levers known as hyperparameters. These hyperparameters govern the behavior
    and characteristics of our model, influencing its ability to learn, generalize,
    and make accurate predictions. However, finding the optimal configuration for
    these hyperparameters is no easy feat.'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下：我们的模型是一个复杂的机械装置，由各种被称为超参数的旋钮和杠杆组成。这些超参数控制着我们的模型的行为和特征，影响着其学习、泛化和做出准确预测的能力。然而，找到这些超参数的最佳配置并非易事。
- en: Hyperparameter tuning is the art of systematically searching and selecting the
    best combination of hyperparameters for our model. It allows us to venture beyond
    default settings and discover the configurations that align harmoniously with
    our data, extracting the most meaningful insights and delivering superior performance.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 超参数调优是系统地搜索和选择最佳超参数组合的艺术。它使我们能够超越默认设置，发现与我们的数据和谐一致的配置，提取最有意义的见解并实现卓越的性能。
- en: The goal of hyperparameter tuning is to get optimal values. We explore different
    hyperparameter settings, traversing through a multidimensional landscape of possibilities.
    This exploration can take various forms, such as grid search, random search, or
    more advanced techniques such as Bayesian optimization or genetic algorithms.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 超参数调优的目标是获得最佳值。我们探索不同的超参数设置，穿越一个可能性的多维景观。这种探索可以采取多种形式，例如网格搜索、随机搜索，或者更高级的技术，如贝叶斯优化或遗传算法。
- en: '**Grid search**, a popular method, involves defining a grid of potential values
    for each hyperparameter. The model is then trained and evaluated for every possible
    combination within the grid. By exhaustively searching through the grid, we unearth
    the configuration that yields the highest performance, providing us with a solid
    foundation for further refinement.'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: '**网格搜索**是一种流行的方法，它涉及为每个超参数定义一个潜在值的网格。然后，模型在网格中的每个可能组合上进行训练和评估。通过彻底搜索网格，我们发现了产生最高性能的配置，为我们进一步优化提供了坚实的基础。'
- en: Random search takes a different approach. It samples hyperparameter values randomly
    from predefined distributions and evaluates the model’s performance for each sampled
    configuration. This randomized exploration enables us to cover a wider range of
    possibilities, potentially discovering unconventional yet highly effective configurations.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 随机搜索采取不同的方法。它从预定义的分布中随机采样超参数值，并对每个采样的配置评估模型的性能。这种随机探索使我们能够覆盖更广泛的可能范围，可能发现非常规但非常有效的配置。
- en: These examples demonstrate the process of model training and evaluation using
    PySpark. However, the specific algorithms, evaluation metrics, and techniques
    applied may vary, depending on the ML task at hand. It is important to understand
    the problem domain, select appropriate algorithms, and choose relevant evaluation
    metrics to train and evaluate models effectively.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 这些例子展示了使用 PySpark 进行模型训练和评估的过程。然而，具体算法、评估指标和技术可能因所面临的机器学习任务而异。理解问题域、选择合适的算法和选择相关的评估指标对于有效地训练和评估模型至关重要。
- en: Model deployment
  id: totrans-258
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型部署
- en: 'Model deployment is the process of making trained ML models available for use
    in production environments. In this section, we will explore various approaches
    and techniques for deploying ML models effectively:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 模型部署是将训练好的机器学习模型用于生产环境的过程。在本节中，我们将探讨有效部署机器学习模型的多种方法和技巧：
- en: '**Serialization and persistence**: Once a model has been trained, it needs
    to be serialized and persisted to disk for later use. Serialization is the process
    of converting the model object into a format that can be stored, while persistence
    involves saving the serialized model to a storage system.'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**序列化和持久化**：一旦模型被训练，它需要被序列化并持久化到磁盘以供以后使用。序列化是将模型对象转换为可以存储的格式的过程，而持久化涉及将序列化的模型保存到存储系统中。'
- en: '**Model serving**: Model serving involves making the trained model available
    as an API endpoint or service that can receive input data and return predictions.
    This allows other applications or systems to integrate and use the model for real-time
    predictions.'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型服务**：模型服务涉及将训练好的模型作为API端点或服务提供，该服务可以接收输入数据并返回预测结果。这允许其他应用程序或系统集成并使用该模型进行实时预测。'
- en: Model monitoring and management
  id: totrans-262
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型监控和管理
- en: 'Once a model has been deployed, it is important to monitor its performance
    and behavior in the production environment and maintain its effectiveness over
    time. Monitoring can help identify issues such as data drift, model degradation,
    or anomalies. Additionally, model management involves versioning, tracking, and
    maintaining multiple versions of the deployed models. These practices ensure that
    models remain up to date and perform optimally over time. In this section, we
    will explore the key aspects of model monitoring and maintenance:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦模型被部署，重要的是要监控其在生产环境中的性能和行为，并保持其长期的有效性。监控可以帮助识别数据漂移、模型退化或异常等问题。此外，模型管理涉及版本控制、跟踪和维护已部署模型的多个版本。这些做法确保模型保持最新状态，并随着时间的推移保持最佳性能。在本节中，我们将探讨模型监控和维护的关键方面：
- en: '**Scalability and performance**: When deploying ML models, scalability and
    performance are essential considerations. Models should be designed and deployed
    in a way that allows for efficient processing of large volumes of data and can
    handle high throughput requirements. Technologies such as Apache Spark provide
    distributed computing capabilities that enable scalable and high-performance model
    deployment.'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可扩展性和性能**：在部署机器学习模型时，可扩展性和性能是至关重要的考虑因素。模型应设计并部署为能够高效处理大量数据并满足高吞吐量需求的方式。例如，Apache
    Spark等技术提供了分布式计算能力，使得可扩展且高性能的模型部署成为可能。'
- en: '**Model updates and retraining**: ML models may need to be updated or retrained
    periodically to adapt to changing data patterns or improve performance. Deployed
    models should have mechanisms in place to facilitate updates and retraining without
    interrupting the serving process. This can involve automated processes, such as
    monitoring for data drift or retraining triggers based on specific conditions.'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型更新和重新训练**：机器学习模型可能需要定期更新或重新训练，以适应变化的数据模式或提高性能。部署的模型应具备机制，以便在不中断服务流程的情况下方便地进行更新和重新训练。这可能涉及自动化流程，例如监控数据漂移或基于特定条件的重新训练触发器。'
- en: '**Performance metrics**: To monitor a deployed model, it is important to define
    and track relevant performance metrics. These metrics can vary, depending on the
    type of ML problem and the specific requirements of the application. Some commonly
    used performance metrics include accuracy, precision, recall, F1 score, and **area
    under the ROC curve** (**AUC**). By regularly evaluating these metrics, deviations
    from the expected performance can be identified, indicating the need for further
    investigation or maintenance actions.'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**性能指标**：为了监控已部署的模型，定义和跟踪相关的性能指标非常重要。这些指标可能因机器学习问题的类型和应用程序的具体要求而异。一些常用的性能指标包括准确率、精确率、召回率、F1分数和**ROC曲线下面积**（**AUC**）。通过定期评估这些指标，可以识别出与预期性能的偏差，这表明需要进行进一步调查或维护操作。'
- en: '**Data drift detection**: Data drift refers to the phenomenon where the statistical
    properties of the input data change over time, leading to a degradation in model
    performance. Monitoring for data drift is crucial to ensure that the deployed
    model continues to provide accurate predictions. Techniques such as statistical
    tests, feature distribution comparison, and outlier detection can be employed
    to detect data drift. When data drift is detected, it may be necessary to update
    the model or retrain it using more recent data.'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据漂移检测**：数据漂移是指输入数据的统计属性随时间变化的现象，这会导致模型性能下降。监控数据漂移对于确保部署的模型持续提供准确预测至关重要。可以使用诸如统计测试、特征分布比较和异常值检测等技术来检测数据漂移。当检测到数据漂移时，可能需要更新模型或使用更近期的数据进行重新训练。'
- en: '**Model performance monitoring**: Monitoring the performance of a deployed
    model involves tracking its predictions and comparing them with ground truth values.
    This can be done by periodically sampling a subset of the predictions and evaluating
    them against the actual outcomes. Monitoring can also include analyzing prediction
    errors, identifying patterns or anomalies, and investigating the root causes of
    any performance degradation. By regularly monitoring the model’s performance,
    issues can be identified early on and corrective actions can be taken.'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型性能监控**：监控部署模型的性能涉及跟踪其预测并将其与真实值进行比较。这可以通过定期采样预测子集并评估其实际结果来实现。监控还可以包括分析预测错误、识别模式或异常以及调查任何性能下降的根本原因。通过定期监控模型的性能，可以及早发现问题并采取纠正措施。'
- en: '**Model retraining and updates**: Models that are deployed in production may
    require periodic updates or retraining to maintain their effectiveness. When new
    data becomes available or significant changes occur in the application domain,
    retraining the model with fresh data can help improve its performance. Additionally,
    bug fixes, feature enhancements, or algorithmic improvements may necessitate updating
    the deployed model. It is important to have a well-defined process and infrastructure
    in place to handle model retraining and updates efficiently.'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型重新训练和更新**：在生产中部署的模型可能需要定期更新或重新训练以保持其有效性。当有新数据可用或应用领域发生重大变化时，使用新鲜数据重新训练模型可以帮助提高其性能。此外，错误修复、功能增强或算法改进可能需要更新部署的模型。建立良好的流程和基础设施来高效地处理模型重新训练和更新至关重要。'
- en: '**Versioning and model governance**: Maintaining proper versioning and governance
    of deployed models is crucial for tracking changes, maintaining reproducibility,
    and ensuring regulatory compliance. Version control systems can be used to manage
    model versions, track changes, and provide a historical record of model updates.
    Additionally, maintaining documentation related to model changes, dependencies,
    and associated processes contributes to effective model governance.'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**版本控制和模型治理**：维护部署模型的适当版本控制和治理对于跟踪变更、保持可重复性和确保合规性至关重要。版本控制系统可用于管理模型版本、跟踪变更并提供模型更新的历史记录。此外，维护与模型变更、依赖关系和相关流程相关的文档有助于有效的模型治理。'
- en: '**Collaboration and feedback**: Model monitoring and maintenance often involve
    collaboration among different stakeholders, including data scientists, engineers,
    domain experts, and business users. Establishing channels for feedback and communication
    can facilitate the exchange of insights, identification of issues, and implementation
    of necessary changes. Regular meetings or feedback loops can help align the model’s
    performance with the evolving requirements of the application.'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**协作与反馈**：模型监控和维护通常涉及不同利益相关者之间的协作，包括数据科学家、工程师、领域专家和业务用户。建立反馈和沟通渠道可以促进见解的交流、问题的识别和必要变更的实施。定期的会议或反馈循环有助于将模型的性能与应用的演变需求保持一致。'
- en: Overall, model deployment is a critical step in the ML life cycle. It involves
    serializing and persisting trained models, serving them as APIs or services, monitoring
    their performance, ensuring scalability and performance, and managing updates
    and retraining.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，模型部署是机器学习生命周期中的关键步骤。它涉及序列化和持久化训练好的模型，将它们作为API或服务提供，监控其性能，确保可扩展性和性能，以及管理更新和重新训练。
- en: By actively monitoring and maintaining deployed models, organizations can ensure
    that their ML systems continue to provide accurate and reliable predictions. Effective
    model monitoring techniques, coupled with proactive maintenance strategies, enable
    timely identification of performance issues and support the necessary actions
    to keep the models up to date and aligned with business objectives.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 通过积极监控和维护部署的模型，组织可以确保其机器学习系统持续提供准确和可靠的预测。有效的模型监控技术与主动维护策略相结合，能够及时识别性能问题，并支持必要的行动，以保持模型更新并与业务目标保持一致。
- en: Model iteration and improvement
  id: totrans-274
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型迭代与改进
- en: 'Model iteration and improvement is a crucial phase in the ML life cycle that
    focuses on enhancing the performance and effectiveness of deployed models. By
    continuously refining and optimizing models, organizations can achieve better
    predictions and drive greater value from their ML initiatives. In this section,
    we will explore the key aspects of model iteration and improvement:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 模型迭代与改进是机器学习生命周期中的一个关键阶段，专注于提升部署模型的性能和有效性。通过持续优化和改进模型，组织可以实现更好的预测，并从其机器学习项目中获得更大的价值。在本节中，我们将探讨模型迭代和改进的关键方面：
- en: '**Collecting feedback and gathering insights**: The first step in model iteration
    and improvement is to gather feedback from various stakeholders, including end
    users, domain experts, and business teams. Feedback can provide valuable insights
    into the model’s performance, areas for improvement, and potential issues encountered
    in real-world scenarios. This feedback can be collected through surveys, user
    interviews, or monitoring the model’s behavior in the production environment.'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**收集反馈和获取洞察**：模型迭代和改进的第一步是从各种利益相关者那里收集反馈，包括最终用户、领域专家和业务团队。反馈可以提供有关模型性能、改进领域和在实际场景中遇到的潜在问题的宝贵见解。可以通过调查、用户访谈或在生产环境中监控模型的运行行为来收集此类反馈。'
- en: '**Analyzing model performance**: To identify areas for improvement, it is important
    to thoroughly analyze the model’s performance. This includes examining performance
    metrics, evaluating prediction errors, and conducting in-depth analyses of misclassified
    or poorly predicted instances. By understanding the strengths and weaknesses of
    the model, data scientists can focus their efforts on specific areas that require
    attention.'
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分析模型性能**：为了确定改进领域，重要的是要彻底分析模型的性能。这包括检查性能指标、评估预测误差以及深入分析被错误分类或预测不佳的实例。通过了解模型的优点和缺点，数据科学家可以将精力集中在需要关注的特定领域。'
- en: '**Exploring new features and data**: One way to improve model performance is
    by incorporating new features or utilizing additional data sources. Exploratory
    data analysis can help identify potential features that may have a strong impact
    on predictions. Feature engineering techniques, such as creating interaction terms,
    scaling, or transforming variables, can also be employed to enhance the representation
    of the data. Additionally, incorporating new data from different sources can provide
    fresh insights and improve the model’s generalization capabilities.'
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**探索新特征和数据**：提升模型性能的一种方法是通过整合新特征或利用额外的数据源。探索性数据分析有助于识别可能对预测有重大影响的潜在特征。可以使用特征工程技术，如创建交互项、缩放或转换变量，来增强数据的表示。此外，整合来自不同来源的新数据可以提供新的见解并提高模型的一般化能力。'
- en: '**Algorithm selection and hyperparameter tuning**: Experimenting with different
    algorithms and hyperparameters can lead to significant improvements in model performance.
    Data scientists can explore alternative algorithms or variations of the existing
    algorithm to identify the best approach for the given problem. Hyperparameter
    tuning techniques, such as grid search or Bayesian optimization, can be used to
    find optimal values for model parameters. This iterative process helps identify
    the best algorithm and parameter settings that yield superior results.'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**算法选择和超参数调整**：通过实验不同的算法和超参数，可以显著提升模型性能。数据科学家可以探索替代算法或现有算法的变体，以确定针对特定问题的最佳方法。可以使用网格搜索或贝叶斯优化等超参数调整技术来找到模型参数的最优值。这一迭代过程有助于确定最佳算法和参数设置，从而产生更优的结果。'
- en: '**Ensemble methods**: Ensemble methods involve combining multiple models to
    create a more robust and accurate prediction. Techniques such as bagging, boosting,
    or stacking can be applied to build an ensemble model from multiple base models.
    Ensemble methods can often improve model performance by reducing bias, variance,
    and overfitting. Experimenting with different ensemble strategies and model combinations
    can lead to further enhancements in prediction accuracy.'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**集成方法**：集成方法涉及结合多个模型以创建更稳健和准确的预测。可以应用诸如 bagging、boosting 或 stacking 等技术，从多个基础模型构建集成模型。集成方法通常可以通过减少偏差、方差和过拟合来提高模型性能。尝试不同的集成策略和模型组合可以进一步提高预测准确性。'
- en: '**A/B testing and controlled experiments**: A/B testing or controlled experiments
    can be conducted to evaluate the impact of model improvements in a controlled
    setting. By randomly assigning users or data samples to different versions of
    the model, organizations can measure the performance of the new model against
    the existing one. This approach provides statistically significant results to
    determine if the proposed changes lead to desired improvements or not.'
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**A/B 测试和受控实验**：可以在受控环境中进行 A/B 测试或受控实验，以评估模型改进的影响。通过随机分配用户或数据样本到不同版本的模型，组织可以衡量新模型与现有模型的性能。这种方法提供了具有统计学意义的成果，以确定所提出的更改是否导致了预期的改进。'
- en: '**Continuous monitoring and evaluation**: Once the improved model has been
    deployed, continuous monitoring and evaluation are essential to ensure its ongoing
    performance. Monitoring for data drift, analyzing performance metrics, and conducting
    periodic evaluations help identify potential degradation or the need for further
    improvements. This feedback loop allows for continuous iteration and refinement
    of the deployed model.'
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**持续监控与评估**：一旦改进后的模型部署，持续的监控与评估对于确保其持续性能至关重要。监控数据漂移、分析性能指标以及定期评估有助于识别潜在的退化或进一步改进的需求。这个反馈循环允许对部署的模型进行持续迭代和优化。'
- en: By embracing a culture of iteration and improvement, organizations can continuously
    enhance the performance and accuracy of their ML models. Through collecting feedback,
    analyzing model performance, exploring new features and algorithms, conducting
    experiments, and continuous monitoring, models can be iteratively refined to achieve
    better predictions and drive tangible business outcomes.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 通过拥抱迭代和改进的文化，组织可以持续提升其机器学习模型的性能和准确性。通过收集反馈、分析模型性能、探索新的特性和算法、进行实验以及持续监控，模型可以迭代优化以实现更好的预测并推动可衡量的业务成果。
- en: Case studies and real-world examples
  id: totrans-284
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 案例研究和现实世界案例
- en: 'In this section, we will explore two prominent use cases of ML: customer churn
    prediction and fraud detection. These examples demonstrate the practical applications
    of ML techniques in addressing real-world challenges and achieving significant
    business value.'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探讨机器学习的两个突出用例：客户流失预测和欺诈检测。这些示例展示了机器学习技术在解决现实世界挑战和实现显著商业价值方面的实际应用。
- en: Customer churn prediction
  id: totrans-286
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 客户流失预测
- en: Customer churn refers to the phenomenon where customers discontinue their relationship
    with a company, typically by canceling a subscription or switching to a competitor.
    Predicting customer churn is crucial for businesses as it allows them to proactively
    identify customers who are at risk of leaving and take appropriate actions to
    retain them. ML models can analyze various customer attributes and behavior patterns
    to predict churn likelihood. Let’s dive into a customer churn prediction case
    study.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 客户流失是指客户与公司终止关系的现象，通常是通过取消订阅或转向竞争对手来实现的。预测客户流失对商业至关重要，因为它允许企业主动识别有离开风险的客户并采取适当的措施来留住他们。机器学习模型可以分析各种客户属性和行为模式来预测流失的可能性。让我们深入了解一个客户流失预测案例研究。
- en: Case study – telecommunications company
  id: totrans-288
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 案例研究 – 电信公司
- en: 'A telecommunications company wants to reduce customer churn by predicting which
    customers are most likely to cancel their subscriptions. The company collects
    extensive customer data, including demographics, call records, service usage,
    and customer complaints. By leveraging ML, they aim to identify key indicators
    of churn and build a predictive model to forecast future churners:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 一家电信公司希望通过预测哪些客户最有可能取消他们的订阅来降低客户流失率。公司收集了大量的客户数据，包括人口统计信息、通话记录、服务使用情况和客户投诉。通过利用机器学习，他们旨在识别客户流失的关键指标并构建一个预测模型来预测未来的流失者：
- en: '**Data preparation**: The company gathers and preprocesses the customer data,
    ensuring it is cleaned, formatted, and ready for analysis. They combine customer
    profiles with historical churn information to create a labeled dataset.'
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据准备**：公司收集并预处理客户数据，确保数据清洁、格式化并准备好分析。他们将客户档案与历史流失信息相结合，创建标记数据集。'
- en: '**Feature engineering**: To capture meaningful patterns, the company engineers
    relevant features from the available data. These features may include variables
    such as average call duration, number of complaints, monthly service usage, and
    tenure.'
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特征工程**：为了捕捉有意义的模式，公司从可用数据中工程相关特征。这些特征可能包括平均通话时长、投诉数量、月度服务使用量和任期等变量。'
- en: '**Model selection and training**: The company selects an appropriate ML algorithm,
    such as logistic regression, decision trees, or random forests, to build the churn
    prediction model. They split the dataset into training and testing sets, train
    the model on the training data, and evaluate its performance on the testing data.'
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型选择和训练**：公司选择合适的机器学习算法，例如逻辑回归、决策树或随机森林，来构建流失预测模型。他们将数据集分为训练集和测试集，在训练数据上训练模型，并在测试数据上评估其性能。'
- en: '**Model evaluation**: The model’s performance is assessed using evaluation
    metrics such as accuracy, precision, recall, and F1 score. The company analyzes
    the model’s ability to correctly identify churners and non-churners, striking
    a balance between false positives and false negatives.'
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型评估**：使用评估指标如准确率、精确率、召回率和F1分数来评估模型的表现。公司分析模型正确识别流失客户和非流失客户的能力，在误报和漏报之间取得平衡。'
- en: '**Model deployment and monitoring**: Once the model meets the desired performance
    criteria, it is deployed into the production environment. The model continuously
    monitors incoming customer data, generates churn predictions, and triggers appropriate
    retention strategies for at-risk customers.'
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型部署和监控**：一旦模型达到预期的性能标准，它就被部署到生产环境中。模型持续监控传入的客户数据，生成流失预测，并为处于风险中的客户触发适当的保留策略。'
- en: Fraud detection
  id: totrans-295
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 欺诈检测
- en: Fraud detection is another critical application of ML that aims to identify
    fraudulent activities and prevent financial losses. ML models can learn patterns
    of fraudulent behavior from historical data and flag suspicious transactions or
    activities in real time. Let’s explore a fraud detection case study.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 欺诈检测是机器学习的另一个关键应用，旨在识别欺诈活动并防止财务损失。机器学习模型可以从历史数据中学习欺诈行为的模式，并在实时中标记可疑的交易或活动。让我们探讨一个欺诈检测案例研究。
- en: Case study – financial institution
  id: totrans-297
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**案例研究 - 金融机构**'
- en: 'A financial institution wants to detect fraudulent transactions in real time
    to protect its customers and prevent monetary losses. The institution collects
    transaction data, including transaction amounts, timestamps, merchant information,
    and customer details. By leveraging ML algorithms, they aim to build a robust
    fraud detection system:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 一家金融机构希望实时检测欺诈交易，以保护其客户并防止货币损失。该机构收集交易数据，包括交易金额、时间戳、商户信息和客户详情。通过利用机器学习算法，他们旨在构建一个强大的欺诈检测系统：
- en: '**Data preprocessing**: The financial institution processes and cleans the
    transaction data, ensuring data integrity and consistency. They may also enrich
    the data by incorporating additional information, such as IP addresses or device
    identifiers, to enhance fraud detection capabilities.'
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据预处理**：金融机构处理和清理交易数据，确保数据完整性和一致性。他们还可能通过整合额外的信息，如IP地址或设备标识符，来增强欺诈检测能力。'
- en: '**Feature engineering**: Relevant features are extracted from the transaction
    data to capture potential indicators of fraudulent activity. These features may
    include transaction amounts, frequency, geographical location, deviation from
    typical spending patterns, and customer transaction history.'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特征工程**：从交易数据中提取相关特征，以捕捉潜在的欺诈活动指标。这些特征可能包括交易金额、频率、地理位置、与典型消费模式的偏差以及客户交易历史。'
- en: '**Model training**: The financial institution selects suitable ML algorithms,
    such as anomaly detection techniques or supervised learning methods (for example,
    logistic regression and gradient boosting), to train the fraud detection model.
    The model is trained on historical data labeled as fraudulent or non-fraudulent.'
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型训练**：金融机构选择合适的机器学习算法，例如异常检测技术或监督学习方法（例如，逻辑回归和梯度提升），以训练欺诈检测模型。该模型在标记为欺诈或非欺诈的历史数据上训练。'
- en: '**Real-time monitoring**: Once the model has been trained, it is deployed to
    analyze incoming transactions in real time. The model assigns a fraud probability
    score to each transaction, and transactions exceeding a certain threshold are
    flagged for further investigation or intervention.'
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**实时监控**：一旦模型经过训练，它就会被部署以实时分析传入的交易。模型为每笔交易分配一个欺诈概率分数，超过一定阈值的交易将被标记为需要进一步调查或干预。'
- en: '**Continuous improvement**: The financial institution continuously refines
    the fraud detection model by monitoring its performance and incorporating new
    data. They periodically evaluate the model’s effectiveness, adjust thresholds,
    and update the model to adapt to evolving fraud patterns and techniques.'
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**持续改进**：金融机构通过监控其性能并整合新数据，持续优化欺诈检测模型。他们定期评估模型的有效性，调整阈值，并更新模型以适应不断变化的欺诈模式和技巧。'
- en: By applying ML techniques to customer churn prediction and fraud detection,
    organizations can enhance their decision-making processes, improve customer retention,
    and mitigate financial risks. These case studies highlight the practical application
    of ML in real-world scenarios, demonstrating its value in various industries.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将 ML 技术应用于客户流失预测和欺诈检测，组织可以增强其决策过程，提高客户保留率，并减轻财务风险。这些案例研究突出了 ML 在现实场景中的实际应用，展示了其在各个行业中的价值。
- en: Future trends in Spark ML and distributed ML
  id: totrans-305
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Spark ML 和分布式 ML 的未来趋势
- en: 'As the field of ML continues to evolve, there are several future trends and
    advancements that we can expect in Spark ML and distributed ML. Here are a few
    key areas to watch:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 随着机器学习领域的持续发展，我们可以在 Spark ML 和分布式 ML 领域期待一些未来的趋势和进步。以下是一些关键领域值得关注：
- en: '**Deep learning integration**: Spark ML is likely to see deeper integration
    with deep learning frameworks such as TensorFlow and PyTorch. This will enable
    users to seamlessly incorporate deep learning models into their Spark ML pipelines,
    unlocking the power of neural networks for complex tasks such as image recognition
    and natural language processing.'
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**深度学习集成**：Spark ML 很可能将更深入地与深度学习框架（如 TensorFlow 和 PyTorch）集成。这将使用户能够无缝地将深度学习模型集成到他们的
    Spark ML 管道中，释放神经网络在复杂任务（如图像识别和自然语言处理）中的力量。'
- en: '**Automated ML**: Automation will play a significant role in simplifying and
    accelerating the machine learning process. We can anticipate advancements in automated
    feature engineering, hyperparameter tuning, and model selection techniques within
    Spark ML. These advancements will make it easier for users to build high-performing
    models with minimal manual effort.'
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自动化机器学习**：自动化将在简化并加速机器学习过程中发挥重要作用。我们可以在 Spark ML 中期待自动化特征工程、超参数调整和模型选择技术的进步。这些进步将使用户能够以最小的手动努力构建高性能模型。'
- en: '**Explainable AI**: As the demand for transparency and interpretability in
    machine learning models grows, Spark ML is likely to incorporate techniques for
    model interpretability. This will enable users to understand and explain the predictions
    made by their models, making them more trustworthy and compliant with regulatory
    requirements.'
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可解释人工智能**：随着机器学习模型中透明度和可解释性的需求增长，Spark ML 很可能将采用模型可解释性的技术。这将使用户能够理解和解释模型做出的预测，使模型更加可靠，并符合监管要求。'
- en: '**Generative AI (GenAI):** GenAI is the latest rage. As use cases for GenAI
    become more in demand, the current platforms may incorporate some of the LLMs
    that are used in GenAI.'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生成式人工智能（GenAI）**：GenAI 是当前的热门话题。随着 GenAI 用例的需求增加，现有平台可能会整合一些用于 GenAI 的 LLMs（大型语言模型）。'
- en: '**Edge computing and IoT**: With the rise of edge computing and the **Internet
    of Things** (**IoT**), Spark ML is expected to extend its capabilities to support
    ML inference and training on edge devices. This will enable real-time, low-latency
    predictions and distributed learning across edge devices, opening up new possibilities
    for applications in areas like smart cities, autonomous vehicles, and industrial
    IoT.'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**边缘计算和物联网**：随着边缘计算和 **物联网（IoT）** 的兴起，Spark ML 预计将扩展其功能，以支持在边缘设备上进行 ML 推理和训练。这将实现实时、低延迟的预测和跨边缘设备的分布式学习，为智能城市、自动驾驶汽车和工业物联网等领域的应用开辟新的可能性。'
- en: And with that we’ve concluded the learning portion of the book. Let’s briefly
    recap what we’ve covered.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 由此，我们结束了本书的学习部分。让我们简要回顾一下我们所学的内容。
- en: Summary
  id: totrans-313
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概述
- en: In conclusion, Spark ML provides a powerful and scalable framework for distributed
    ML tasks. Its integration with Apache Spark offers significant advantages in terms
    of processing large-scale datasets, parallel computing, and fault tolerance. Throughout
    this chapter, we explored the key concepts, techniques, and real-world examples
    of Spark ML.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，Spark ML为分布式机器学习任务提供了一个强大且可扩展的框架。它与Apache Spark的集成在处理大规模数据集、并行计算和容错方面提供了显著优势。在本章中，我们探讨了Spark
    ML的关键概念、技术和实际应用案例。
- en: We discussed the ML life cycle, emphasizing the importance of data preparation,
    model training, evaluation, deployment, monitoring, and continuous improvement.
    We also compared Spark MLlib and Spark ML, highlighting their respective features
    and use cases.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 我们讨论了机器学习生命周期，强调了数据准备、模型训练、评估、部署、监控和持续改进的重要性。我们还比较了Spark MLlib和Spark ML，突出了它们各自的特点和用例。
- en: Throughout this chapter, we discussed various key concepts and techniques related
    to Spark ML. We explored different types of ML, such as classification, regression,
    time series analysis, supervised learning, and unsupervised learning. We highlighted
    the importance of data preparation and feature engineering in building effective
    ML pipelines. We also touched upon fault-tolerance and reliability aspects in
    Spark ML, ensuring robustness and data integrity.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了与Spark ML相关的各种关键概念和技术。我们探讨了不同类型的机器学习，如分类、回归、时间序列分析、监督学习和无监督学习。我们强调了数据准备和特征工程在构建有效的机器学习管道中的重要性。我们还简要提到了Spark
    ML中的容错和可靠性方面，确保了鲁棒性和数据完整性。
- en: Furthermore, we examined real-world use cases, including customer churn prediction
    and fraud detection, to demonstrate the practical applications of Spark ML in
    solving complex business challenges. These case studies showcased how organizations
    can leverage Spark ML to enhance decision-making, improve customer retention,
    and mitigate financial risks.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们考察了实际应用案例，包括客户流失预测和欺诈检测，以展示Spark ML在解决复杂商业挑战中的实际应用。这些案例研究展示了组织如何利用Spark
    ML来增强决策能力、提高客户保留率并减轻财务风险。
- en: As you continue your journey in ML with Spark ML, it is important to keep the
    iterative and dynamic nature of the field in mind. Stay updated with the latest
    advancements, explore new techniques, and embrace a mindset of continuous learning
    and improvement.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 在你继续使用Spark ML进行机器学习之旅时，重要的是要记住该领域的迭代和动态特性。保持对最新进展的了解，探索新技术，并拥抱持续学习和改进的心态。
- en: By harnessing the power of Spark ML, you can unlock valuable insights from your
    data, build sophisticated ML models, and make informed decisions that drive business
    success. So, leverage the capabilities of Spark ML, embrace the future trends,
    and embark on your journey toward mastering distributed ML.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 通过利用Spark ML的力量，你可以从数据中解锁有价值的见解，构建复杂的机器学习模型，并做出推动业务成功的明智决策。因此，利用Spark ML的能力，拥抱未来趋势，踏上掌握分布式机器学习的旅程。
- en: That concludes this chapter. Hopefully, it will help you on your exciting journey
    in the world of ML models. The next two chapters are mock tests to prepare you
    for the certification exam.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 本章到此结束。希望它能帮助你在机器学习模型世界的精彩旅程中取得进步。接下来的两章是模拟测试，旨在帮助你为认证考试做好准备。
- en: 'Part 5: Mock Papers'
  id: totrans-321
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第5部分：模拟试卷
- en: This part will provide two mock papers to help readers prepare for the certification
    exam by practicing questions.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 本部分将提供两份模拟试卷，帮助读者通过练习题目来准备认证考试。
- en: 'This part has the following chapters:'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 本部分包含以下章节：
- en: '[*Chapter 9*](B19176_09.xhtml#_idTextAnchor242)*,* *Mock Paper 1*'
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第9章*](B19176_09.xhtml#_idTextAnchor242)*,* *模拟试卷1*'
- en: '[*Chapter 10*](B19176_10.xhtml#_idTextAnchor246)*,* *Mock Paper 2*'
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第10章*](B19176_10.xhtml#_idTextAnchor246)*,* *模拟试卷2*'
