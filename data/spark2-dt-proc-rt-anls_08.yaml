- en: Spark Tuning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 火花调优
- en: 'In this chapter, we will dig deeper into Apache Spark internals and see that
    while Spark is great in making us feel like we are using just another Scala collection,
    we don''t have to forget that Spark actually runs in a distributed system. Therefore,
    some extra care should be taken. In a nutshell, the following topics will be covered
    in this chapter:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将深入探讨Apache Spark的内部机制，并看到尽管Spark让我们感觉像是在使用另一个Scala集合，但我们不应忘记Spark实际上运行在一个分布式系统中。因此，需要格外小心。简而言之，本章将涵盖以下主题：
- en: Monitoring Spark jobs
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控火花作业
- en: Spark configuration
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Spark配置
- en: Common mistakes in Spark app development
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 火花应用开发中的常见错误
- en: Optimization techniques
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优化技术
- en: Monitoring Spark jobs
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监控火花作业
- en: Spark provides web UI for monitoring all the jobs running or completed on computing
    nodes (drivers or executors). In this section, we will discuss in brief how to
    monitor Spark jobs using Spark web UI with appropriate examples. We will see how
    to monitor the progress of jobs (including submitted, queued, and running jobs).
    All the tabs in the Spark web UI will be discussed briefly. Finally, we will discuss
    the logging procedure in Spark for better tuning.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Spark提供Web UI来监控计算节点（驱动程序或执行程序）上运行或完成的全部作业。在本节中，我们将简要讨论如何使用适当的示例通过Spark Web
    UI监控Spark作业。我们将看到如何监控作业的进度（包括已提交、排队和运行中的作业）。我们将简要讨论Spark Web UI中的所有标签页。最后，我们将讨论Spark中的日志记录过程以进行更好的调优。
- en: Spark web interface
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Spark Web界面
- en: The web UI (also known as Spark UI) is the web interface for running Spark applications
    to monitor the execution of jobs on a web browser such as Firefox or Google Chrome.
    When a SparkContext launches, a web UI that displays useful information about
    the application gets started on port 4040 in standalone mode. The Spark web UI
    is available in different ways depending on whether the application is still running
    or has finished its execution.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: Web UI（也称为Spark UI）是运行Spark应用程序的Web界面，用于在Firefox或Google Chrome等Web浏览器上监控作业的执行。当SparkContext启动时，在独立模式下，一个显示应用程序有用信息的Web
    UI会在端口4040上启动。根据应用程序是否仍在运行或已完成执行，Spark Web UI有不同的访问方式。
- en: Also, you can use the web UI after the application has finished its execution
    by persisting all the events using `EventLoggingListener`. The `EventLoggingListener`,
    however, cannot work alone, and the incorporation of the Spark history server
    is required. Combining these two features, the ...
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，您可以在应用程序执行完毕后通过使用`EventLoggingListener`持久化所有事件来使用Web UI。然而，`EventLoggingListener`不能单独工作，需要结合Spark历史服务器。结合这两个功能，...
- en: Jobs
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 作业
- en: 'Depending upon the SparkContext, the Jobs tab shows the status of all the Spark
    jobs in a Spark application. When you access the Jobs tab on the Spark UI using
    a web browser at `http://localhost:4040` (for standalone mode), you should observe
    the following options:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 根据SparkContext，Jobs标签页显示Spark应用程序中所有Spark作业的状态。当您通过Web浏览器在`http://localhost:4040`（独立模式）访问Spark
    UI的Jobs标签页时，您应该会看到以下选项：
- en: 'User: This shows the active user who has submitted the Spark job'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 显示提交Spark作业的活跃用户
- en: 'Total Uptime: This shows the total uptime for the jobs'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 总运行时间：显示作业的总运行时间
- en: 'Scheduling Mode: In most cases, it is first-in-first-out (aka FIFO)'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调度模式：大多数情况下，它是先进先出（FIFO）
- en: 'Active Jobs: This shows the number of active jobs'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 活跃作业：显示活跃作业的数量
- en: 'Completed Jobs: This shows the number of completed jobs'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 已完成作业：显示已完成作业的数量
- en: 'Event Timeline: This shows the timeline of a job that has completed its execution'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 事件时间线：显示已完成执行的作业的时间线
- en: 'Internally, the Jobs tab is represented by the `JobsTab` class, which is a
    custom SparkUI tab with the jobs prefix. The Jobs tab uses `JobProgressListener`
    to access statistics about the Spark jobs to display the above information on
    the page. Take a look at the following screenshot:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 内部，Jobs标签页由`JobsTab`类表示，这是一个带有jobs前缀的自定义SparkUI标签页。Jobs标签页使用`JobProgressListener`来访问Spark作业的统计信息，以在页面上显示上述信息。请看以下截图：
- en: '![](img/bf303fd3-cd31-4810-bd34-b61193c1b848.png)**Figure 2:** The jobs tab
    in the Spark web UI'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/bf303fd3-cd31-4810-bd34-b61193c1b848.png)**图2：**Spark Web UI中的Jobs标签页'
- en: 'If you further expand the Active Jobs option in the Jobs tab, you will be able
    to see the execution plan, status, number of completed stages, and the job ID
    of that particular job as DAG Visualization, as shown in the following:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在Jobs标签页中进一步展开Active Jobs选项，您将能够看到该特定作业的执行计划、状态、已完成阶段数和作业ID，如DAG可视化所示：
- en: '![](img/bf74a871-39d8-4be0-b374-ef2554b65faf.png)**Figure 3:** The DAG visualization
    for task in the Spark web UI (abridged)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bf74a871-39d8-4be0-b374-ef2554b65faf.png)**图3：** Spark Web UI中任务的DAG可视化（简略版）'
- en: When a user enters the code in the Spark console (for example, Spark shell or
    using Spark submit), Spark Core creates an operator graph. This is basically what
    happens when a user executes an action (for example, reduce, collect, count, first,
    take, countByKey, saveAsTextFile) or transformation (for example, map, flatMap,
    filter, mapPartitions, sample, union, intersection, distinct) on an RDD (which
    are immutable objects) at a particular node.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 当用户在Spark控制台中输入代码时（例如，Spark shell或使用Spark submit），Spark Core会创建一个操作符图。这基本上是用户在特定节点上对RDD（不可变对象）执行操作（例如，reduce、collect、count、first、take、countByKey、saveAsTextFile）或转换（例如，map、flatMap、filter、mapPartitions、sample、union、intersection、distinct）时发生的情况。
- en: '![](img/2f67f963-d847-4179-b308-ac80fee4bf39.png)**Figure 4:** DAG scheduler
    transforming RDD lineage into stage DAG'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/2f67f963-d847-4179-b308-ac80fee4bf39.png)**图4：** DAG调度器将RDD血统转换为阶段DAG'
- en: During the transformation or action, **Directed Acyclic Graph** (**DAG**) information
    is used to restore the node to last transformation and actions (refer to *Figure
    4* and *Figure 5* for a clearer picture) to maintain the data resiliency. Finally,
    the graph is submitted to a DAG scheduler.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在转换或操作期间，使用**有向无环图**（**DAG**）信息来恢复到最后一个转换和操作的节点（参见*图4*和*图5*以获得更清晰的图像），以保持数据弹性。最后，图形被提交给DAG调度器。
- en: How does Spark compute the DAG from the RDD and subsequently execute the task?
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 如何从RDD计算DAG，然后执行任务？
- en: At a high level, when any action is called on the RDD, Spark creates the DAG
    and submits it to the DAG scheduler. The DAG scheduler divides operators into
    stages of tasks. A stage comprises tasks based on partitions of the input data.
    The DAG scheduler pipelines operators together. For example, many map operators
    can be scheduled in a single stage. The final result of a DAG scheduler is a set
    of stages. The stages are passed on to the task scheduler. The task scheduler
    launches tasks through the cluster manager (Spark Standalone/YARN/Mesos). The
    task scheduler doesn't know about the dependencies of the stages. The worker executes
    the tasks on the stage.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 从高层次来看，当对RDD调用任何操作时，Spark会创建DAG并将其提交给DAG调度器。DAG调度器将操作符划分为任务阶段。一个阶段根据输入数据的分区包含任务。DAG调度器将操作符流水线化。例如，可以在一个阶段中调度多个映射操作符。DAG调度器的最终结果是一组阶段。这些阶段被传递给任务调度器。任务调度器通过集群管理器（Spark
    Standalone/YARN/Mesos）启动任务。任务调度器不知道阶段的依赖关系。工作节点在阶段上执行任务。
- en: The DAG scheduler then keeps track of which RDDs the stage outputs materialized
    from. It then finds a minimal schedule to run jobs and divides the related operators
    into stages of tasks. Based on the partitions of the input data, a stage comprises
    multiple tasks. Then, operators are pipelined together with the DAG scheduler.
    Practically, more than one map or reduce operator (for example) can be scheduled
    in a single stage.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 有向无环图（DAG）调度器随后跟踪哪些阶段输出的RDD被物化。接着，它找到一个最小调度来运行作业，并将相关操作符划分为任务阶段。根据输入数据的分区，一个阶段包含多个任务。然后，操作符与DAG调度器一起流水线化。实际上，一个阶段中可以调度多个映射或归约操作符（例如）。
- en: '![](img/f80b883b-bc62-4898-be8f-232d5fe2755b.png)**Figure 5:** Executing action
    leads to new ResultStage and ActiveJob in DAGScheduler'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/f80b883b-bc62-4898-be8f-232d5fe2755b.png)**图5：** 执行操作导致DAG调度器中新的ResultStage和ActiveJob'
- en: Two fundamental concepts in DAG scheduler are jobs and stages. Thus, it has
    to track them through internal registries and counters. Technically speaking,
    DAG scheduler is a part of SparkContext's initialization that works exclusively
    on the driver (immediately after the task scheduler and scheduler backend are
    ready). DAG scheduler is responsible for three major tasks in Spark execution.
    It computes an execution DAG, that is, DAG of stages, for a job. It determines
    the preferred node to run each task on and handles failures due to shuffle output
    files being lost.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: DAG调度器中的两个基本概念是作业和阶段。因此，它必须通过内部注册表和计数器来跟踪它们。从技术上讲，DAG调度器是SparkContext初始化的一部分，它专门在驱动程序上工作（在任务调度器和调度器后端准备好之后立即）。DAG调度器负责Spark执行中的三个主要任务。它为作业计算执行DAG，即阶段的DAG。它确定运行每个任务的首选节点，并处理由于洗牌输出文件丢失而导致的故障。
- en: '![](img/249b0e98-ac9a-4690-9542-3461582235a8.png)**Figure 6:** DAGScheduler
    as created by SparkContext with other services'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/249b0e98-ac9a-4690-9542-3461582235a8.png)**图6：** SparkContext创建的DAGScheduler与其他服务'
- en: The final result of a DAG scheduler is a set of stages. Therefore, most of the
    statistics and the status of the job can be seen using this visualization, for
    example, execution plan, status, number of completed stages, and the job ID of
    that particular job.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: DAG调度器的最终结果是一组阶段。因此，大多数统计数据和作业状态可以通过这种可视化查看，例如执行计划、状态、已完成阶段的数量以及该特定作业的作业ID。
- en: Stages
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 阶段
- en: 'The Stages tab in Spark UI shows the current status of all stages of all jobs
    in a Spark application, including two optional pages for the tasks and statistics
    for a stage and pool details. Note that this information is available only when
    the application works in a fair scheduling mode. You should be able to access
    the Stages tab at `http://localhost:4040/stages`. Note that when there are no
    jobs submitted, the tab shows nothing but the title. The Stages tab shows the
    stages in a Spark application. The following stages can be seen in this tab:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: Spark UI中的阶段选项卡显示了Spark应用程序中所有作业的所有阶段的当前状态，包括一个阶段的任务和统计数据的两个可选页面以及池详细信息。请注意，此信息仅在应用程序以公平调度模式工作时可用。你应该能够通过`http://localhost:4040/stages`访问阶段选项卡。请注意，当没有提交作业时，该选项卡仅显示标题。阶段选项卡显示了Spark应用程序中的阶段。以下阶段可以在该选项卡中看到：
- en: Active Stages
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 活跃阶段
- en: Pending Stages
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 待处理阶段
- en: Completed Stages
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 已完成阶段
- en: 'For example, when you submit a Spark job locally, you should be able to see
    the following status:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，当你在本地提交一个Spark作业时，你应该能看到以下状态：
- en: '**Figure 7:** The stages for all jobs in the Spark ...'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**图7：**Spark中所有作业的阶段...'
- en: Storage
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 存储
- en: 'The Storage tab shows the size and memory use for each RDD, DataFrame, or Dataset.
    You should be able to see the storage-related information of RDDs, DataFrames,
    or Datasets. The following figure shows storage metadata such as RDD name, storage
    level, the number of cache partitions, the percentage of a fraction of the data
    that was cached, and the size of the RDD in the main memory:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 存储选项卡显示了每个RDD、DataFrame或Dataset的大小和内存使用情况。你应该能够看到RDDs、DataFrames或Datasets的存储相关信息。下图显示了存储元数据，如RDD名称、存储级别、缓存分区数量、缓存数据的比例以及RDD在主内存中的大小：
- en: '![](img/bce60273-1b2f-421d-830f-797c3cf2c647.png)**Figure 9:** Storage tab
    shows space consumed by an RDD in disk'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/bce60273-1b2f-421d-830f-797c3cf2c647.png)**图9：**存储选项卡显示了磁盘上RDD所占用的空间。'
- en: Note that if the RDD cannot be cached in the main memory, disk space will be
    used instead. A more detailed discussion will be carried out in a later section
    of this chapter.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，如果RDD无法缓存在主内存中，将使用磁盘空间。本章后面将对此进行更详细的讨论。
- en: '![](img/79827dae-e0cc-405e-a5c0-b40830657142.png)**Figure 10:** Data distribution
    and the storage used by the RDD in disk'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/79827dae-e0cc-405e-a5c0-b40830657142.png)**图10：**数据分布以及磁盘上RDD使用的存储空间。'
- en: Environment
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 环境
- en: The Environment tab shows the environmental variables that are currently set
    on your machine (that is, driver). More specifically, runtime information such
    as Java Home, Java Version, and Scala Version can be seen under Runtime Information.
    Spark properties such as Spark application ID, app name, and driver host information,
    driver port, executor ID, master URL, and the schedule mode can be seen. Furthermore,
    other system-related properties and job properties such as AWT toolkit version,
    file encoding type (for example, UTF-8), and file encoding package information
    (for example, sun.io) can be seen under System Properties.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 环境选项卡展示了当前机器（即驱动程序）上设置的环境变量。更具体地说，运行时信息如Java Home、Java版本和Scala版本可以在运行时信息下查看。Spark属性如Spark应用ID、应用名称、驱动程序主机信息、驱动程序端口、执行器ID、主URL和调度模式也可以看到。此外，其他与系统相关的属性和作业属性，如AWT工具包版本、文件编码类型（例如，UTF-8）和文件编码包信息（例如，sun.io）可以在系统属性下查看。
- en: '![](img/e96ff1b2-89ee-450c-ba39-90f3574b04af.png)**Figure ...**'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/e96ff1b2-89ee-450c-ba39-90f3574b04af.png)**图...**'
- en: Executors
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 执行器
- en: 'The Executors tab uses `ExecutorsListener` to collect information about executors
    for a Spark application. An executor is a distributed agent that is responsible
    for executing tasks. Executors are instantiated in different ways. For example,
    they can be instantiated when `CoarseGrainedExecutorBackend` receives `RegisteredExecutor`
    message for Spark Standalone and YARN. The second case is when a Spark job is
    submitted to Mesos. The Mesos''s `MesosExecutorBackend` gets registered. The third
    case is when you run your Spark jobs locally, that is, `LocalEndpoint` is created.
    An executor typically runs for the entire lifetime of a Spark application, which
    is called static allocation of executors, although you can also opt in for dynamic
    allocation. The executor backends exclusively manage all the executors in a computing
    node or clusters. An executor reports heartbeat and partial metrics for active
    tasks to the **HeartbeatReceiver** RPC endpoint on the driver periodically and
    the results are sent to the driver. They also provide in-memory storage for RDDs
    that are cached by user programs through block manager. Refer to the following
    figure for a clearer idea on this:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 执行器选项卡使用`ExecutorsListener`收集有关Spark应用程序执行器的信息。执行器是一种分布式代理，负责执行任务。执行器以不同方式实例化。例如，当`CoarseGrainedExecutorBackend`收到Spark
    Standalone和YARN的`RegisteredExecutor`消息时，执行器被实例化。第二种情况是当Spark作业提交给Mesos时，Mesos的`MesosExecutorBackend`被注册。第三种情况是当你在本地运行Spark作业时，即创建了`LocalEndpoint`。执行器通常在整个Spark应用程序生命周期内运行，这称为执行器的静态分配，尽管你也可以选择动态分配。执行器后端专门管理计算节点或集群中的所有执行器。执行器定期向驱动程序上的**HeartbeatReceiver**
    RPC端点报告心跳和活动任务的部分指标，并将结果发送给驱动程序。它们还通过块管理器为用户程序缓存的RDD提供内存存储。请参考下图以更清晰地了解这一点：
- en: '![](img/d0402ed6-9387-4afd-92d0-ba718b425723.png)**Figure 12:** Spark driver
    instantiates an executor that is responsible for HeartbeatReceiver''s Heartbeat
    message handler'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/d0402ed6-9387-4afd-92d0-ba718b425723.png)**图12**：Spark驱动程序实例化一个负责处理HeartbeatReceiver心跳消息的执行器。'
- en: 'When an executor starts, it first registers with the driver and communicates
    directly to execute tasks, as shown in the following figure:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 当执行器启动时，它首先向驱动程序注册，并直接通信以执行任务，如下所示：
- en: '![](img/0a0491c0-ba58-42f2-b664-1cf715bff81a.png)**Figure 13:** Launching tasks
    on executor using TaskRunners'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/0a0491c0-ba58-42f2-b664-1cf715bff81a.png)**图13**：使用TaskRunners在执行器上启动任务。'
- en: You should be able to access the Executors tab at `http://localhost:4040/executors`.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该能够访问`http://localhost:4040/executors`上的执行器选项卡。
- en: '![](img/7c502d08-b8ab-478f-9600-010dbf8890b8.png)**Figure 14:** Executor tab
    on Spark web UI'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/7c502d08-b8ab-478f-9600-010dbf8890b8.png)**图14**：Spark Web UI上的执行器选项卡。'
- en: As shown in the preceding figure, Executor ID, Address, Status, RDD Blocks,
    Storage Memory, Disk Used, Cores, Active Tasks, Failed Tasks, Complete Tasks,
    Total Tasks, Task Time (GC Time), Input, Shuffle Read, Shuffle Write, and Thread
    Dump about the executor can be seen.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，可以查看执行器ID、地址、状态、RDD块、存储内存、磁盘使用、核心、活动任务、失败任务、完成任务、总任务、任务时间（GC时间）、输入、洗牌读取、洗牌写入和关于执行器的线程转储。
- en: SQL
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: SQL
- en: The SQL tab in the Spark UI displays all the accumulator values per operator.
    You should be able to access the SQL tab at `http://localhost:4040/SQL/`. It displays
    all the SQL query executions and underlying information by default. However, the
    SQL tab displays the details of the SQL query execution only after a query has
    been selected.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: Spark UI中的SQL选项卡显示每个操作符的所有累加器值。你应该能够访问`http://localhost:4040/SQL/`上的SQL选项卡。它默认显示所有SQL查询执行及其底层信息。但是，SQL选项卡仅在选择查询后显示SQL查询执行的详细信息。
- en: A detailed discussion on SQL is out of the scope of this chapter. Interested
    readers should refer to [http://spark.apache.org/docs/latest/sql-programming-guide.html#sql](http://spark.apache.org/docs/latest/sql-programming-guide.html#sql)
    for more on how to submit an SQL query and see its result output.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 本章不涉及对SQL的详细讨论。感兴趣的读者可参考[Spark SQL编程指南](http://spark.apache.org/docs/latest/sql-programming-guide.html#sql)，了解如何提交SQL查询并查看其结果输出。
- en: Visualizing Spark application using web UI
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Web UI可视化Spark应用程序
- en: 'When a Spark job is submitted for execution, a web application UI is launched
    that displays useful information about the application. An event timeline displays
    the relative ordering and interleaving of application events. The timeline view
    is available on three levels: across all jobs, within one job, and within one
    stage. The timeline also shows executor allocation and deallocation.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 当提交Spark作业执行时，会启动一个Web应用程序UI，显示有关该应用程序的有用信息。事件时间线展示了应用程序事件的相对顺序和交错情况。时间线视图有三个级别：跨所有作业、单个作业和单个阶段。时间线还显示了执行器的分配和解除分配。
- en: '![](img/84681c1c-41e5-4ac1-a74a-6702e1401d2b.png)**Figure 15:** Spark jobs
    executed as DAG on Spark web UI'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/84681c1c-41e5-4ac1-a74a-6702e1401d2b.png)**图15**：在Spark Web UI上以DAG形式执行的Spark作业'
- en: Observing the running and completed Spark jobs
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 观察正在运行和已完成的Spark作业
- en: To access and observe the running and the completed Spark jobs, open `http://spark_driver_host:4040`
    in a web browser. Note that you will have to replace `spark_driver_host` with
    an IP address or hostname accordingly.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问和观察正在运行和已完成的Spark作业，请在Web浏览器中打开`http://spark_driver_host:4040`。请注意，您需要将`spark_driver_host`替换为相应的IP地址或主机名。
- en: Note that if multiple SparkContexts are running on the same host, they will
    bind to successive ports beginning with 4040, 4041, 4042, and so on. By default,
    this information will be available for the duration of your Spark application
    only. This means that when your Spark job finishes its execution, the binding
    will no longer be valid or accessible.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，如果同一主机上运行了多个SparkContext，它们将绑定到从4040开始的连续端口，如4041、4042等。默认情况下，此信息仅在您的Spark应用程序运行期间可用。这意味着当您的Spark作业执行完毕后，绑定将不再有效或可访问。
- en: Now, to access the active jobs that are still executing, click on the Active
    Jobs link and you will see the related information of those ...
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，要访问仍在执行的活动作业，请点击“Active Jobs”链接，您将看到与这些作业相关的信息...
- en: Debugging Spark applications using logs
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用日志调试Spark应用程序
- en: 'Seeing the information about all running Spark applications depends on which
    cluster manager you are using. You should follow these instructions while debugging
    your Spark application:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 查看所有正在运行的Spark应用程序的信息取决于您使用的集群管理器。在调试Spark应用程序时，应遵循以下说明：
- en: '**Spark Standalone**: Go to the Spark master UI at `http://master:18080`. The
    master and each worker show cluster and the related job statistics. In addition,
    a detailed log output for each job is also written to the working directory of
    each worker. We will discuss how to enable the logging manually using the `log4j`
    with Spark.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Spark Standalone**：访问`http://master:18080`上的Spark master UI。master和每个worker都会显示集群和相关作业统计信息。此外，每个作业的详细日志输出也会写入每个worker的工作目录。我们将讨论如何使用`log4j`手动启用Spark的日志记录。'
- en: '**YARN**: If your cluster manager is YARN, and suppose that you are running
    your Spark jobs on the Cloudera (or any other YARN-based platform), then go to
    the YARN applications page in the Cloudera Manager Admin Console. Now, to debug
    Spark applications running on YARN, view the logs for the Node Manager role. To
    make this happen, open the log event viewer and then filter the event stream to
    choose a time window and log level and to display the Node Manager source. You
    can access logs through the command as well. The format of the command is as follows:'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**YARN**：如果您的集群管理器是YARN，并且假设您在Cloudera（或其他基于YARN的平台）上运行Spark作业，则请转到Cloudera
    Manager Admin Console中的YARN应用程序页面。现在，要调试在YARN上运行的Spark应用程序，请查看Node Manager角色的日志。为此，打开日志事件查看器，然后过滤事件流以选择时间窗口、日志级别并显示Node
    Manager源。您也可以通过命令访问日志。命令格式如下：'
- en: '[PRE0]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'For example, the following are the valid commands for these IDs:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，以下是针对这些ID的有效命令：
- en: '[PRE1]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Note that the user IDs are different. However, this is only true if `yarn.log-aggregation-enable`
    is true in `yarn-site.xml` and the application has already finished the execution.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，用户ID可能不同。但是，仅当`yarn-site.xml`中的`yarn.log-aggregation-enable`为true且应用程序已完成执行时，此情况才成立。
- en: Logging with log4j with Spark
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Spark使用log4j进行日志记录
- en: Spark uses `log4j` for its own logging. All the operations that happen backend
    get logged to the Spark shell console (which is already configured to the underlying
    storage). Spark provides a template of `log4j` as a property file, and we can
    extend and modify that file for logging in Spark. Move to the `SPARK_HOME/conf`
    directory and you should see the `log4j.properties.template` file. This could
    help us as the starting point for our own logging system.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: Spark使用`log4j`进行自身日志记录。所有后端发生的操作都会被记录到Spark shell控制台（该控制台已配置到基础存储）。Spark提供了一个`log4j`的属性文件模板，我们可以扩展和修改该文件以在Spark中进行日志记录。转到`SPARK_HOME/conf`目录，您应该会看到`log4j.properties.template`文件。这可以作为我们自己日志系统的起点。
- en: 'Now, let''s create our own custom logging system while running a Spark job.
    When you are done, rename the file as `log4j.properties` and put it under the
    same directory (that is, project tree). A sample snapshot of the file can be seen
    as follows:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们在运行Spark作业时创建自己的自定义日志系统。完成后，将文件重命名为`log4j.properties`并将其放在同一目录下（即项目树）。文件的示例快照如下所示：
- en: '**Figure 17:** A snap of the ...'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '**图17:** 快照...'
- en: Spark configuration
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Spark配置
- en: 'There are a number of ways to configure your Spark jobs. In this section, we
    will discuss these ways. More specifically, according to Spark 2.x release, there
    are three locations to configure the system:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 有多种方法可以配置您的Spark作业。在本节中，我们将讨论这些方法。更具体地说，根据Spark 2.x版本，有三个位置可以配置系统：
- en: Spark properties
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Spark属性
- en: Environmental variables
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 环境变量
- en: Logging
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 日志记录
- en: Spark properties
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Spark属性
- en: 'As discussed previously, Spark properties control most of the application-specific
    parameters and can be set using a `SparkConf` object of Spark. Alternatively,
    these parameters can be set through the Java system properties. `SparkConf` allows
    you to configure some of the common properties as follows:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，Spark属性控制大多数应用程序特定参数，并可以使用`SparkConf`对象设置。或者，这些参数可以通过Java系统属性设置。`SparkConf`允许您配置一些常见属性，如下所示：
- en: '[PRE2]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: An application can be configured to use a number of available cores on your
    machine. For example, we ...
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序可以配置为使用机器上可用的多个核心。例如，我们...
- en: Environmental variables
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 环境变量
- en: 'Environment variables can be used to set the setting in the computing nodes
    or machine settings. For example, IP address can be set through the `conf/spark-env.sh`
    script on each computing node. The following table lists the name and the functionality
    of the environmental variables that need to be set:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 环境变量可用于设置计算节点或机器设置。例如，IP地址可以通过每个计算节点上的`conf/spark-env.sh`脚本设置。下表列出了需要设置的环境变量的名称和功能：
- en: '![](img/9ed855bc-8bb8-450c-b96c-f8403758e021.png)**Figure 18:** Environmental
    variables and their meaning'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/9ed855bc-8bb8-450c-b96c-f8403758e021.png)**图18:** 环境变量及其含义'
- en: Logging
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 日志记录
- en: 'Finally, logging can be configured through the `log4j.properties` file under
    your Spark application tree, as discussed in the preceding section. Spark uses
    log4j for logging. There are several valid logging levels supported by log4j with
    Spark; they are as follows:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，日志可以通过位于Spark应用程序树下的`log4j.properties`文件进行配置，如前一节所述。Spark使用log4j进行日志记录。log4j支持的几个有效日志级别如下：
- en: '| **Log Level** | **Usages** |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| **日志级别** | **用途** |'
- en: '| OFF | This is the most specific, which allows no logging at all |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| OFF | 这是最具体的，不允许任何日志记录 |'
- en: '| FATAL | This is the most specific one that shows fatal errors with little
    data |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| FATAL | 这是最具体的，显示致命错误，数据量较少 |'
- en: '| ERROR | This shows only the general errors |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| ERROR | 这仅显示一般错误 |'
- en: '| WARN | This shows warnings that are recommended to be fixed but not mandatory
    |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| WARN | 这显示了建议修复但非强制性的警告 |'
- en: '| INFO | This shows the information required for your Spark job |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| INFO | 这显示了Spark作业所需的信息 |'
- en: '| DEBUG | While debugging, those logs will be printed |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| DEBUG | 调试时，这些日志将被打印 |'
- en: '| TRACE | This provides the least specific error trace with a lot of data |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| TRACE | 这提供了最不具体的错误跟踪，包含大量数据 |'
- en: '| ALL ... |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| ALL ... |'
- en: Common mistakes in Spark app development
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 常见的Spark应用程序开发错误
- en: Common mistakes that happen often are application failure, a slow job that gets
    stuck due to numerous factors, mistakes in the aggregation, actions or transformations,
    an exception in the main thread and, of course, **Out Of Memory** (**OOM**).
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 常见且经常发生的错误包括应用程序失败、由于多种因素导致的工作缓慢且卡住、聚合、操作或转换中的错误、主线程中的异常，当然还有**内存溢出**（**OOM**）。
- en: Application failure
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 应用程序失败
- en: 'Most of the time, application failure happens because one or more stages fail
    eventually. As discussed earlier in this chapter, Spark jobs comprise several
    stages. Stages aren''t executed independently: for instance, a processing stage
    can''t take place before the relevant input-reading stage. So, suppose that stage
    1 executes successfully but stage 2 fails to execute, the whole application fails
    eventually. This can be shown as follows:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数情况下，应用程序失败是因为一个或多个阶段最终失败。如本章前面所述，Spark作业包含多个阶段。阶段并非独立执行：例如，处理阶段不能在相关输入读取阶段之前进行。因此，假设阶段1成功执行，但阶段2未能执行，整个应用程序最终会失败。这可以表示如下：
- en: '![](img/ddf18574-e882-40eb-ab58-eb8c9a11da46.png)**Figure 19:** Two stages
    in a typical Spark job'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/ddf18574-e882-40eb-ab58-eb8c9a11da46.png)**图19：**典型Spark作业中的两个阶段'
- en: To show an example, suppose you have the following three RDD operations as stages.
    The same can be visualized as shown in *Figure 20*, *Figure 21 ...*
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 为了举例说明，假设您有以下三个RDD操作作为阶段。同样可以如图*20*、*21*等所示：
- en: Slow jobs or unresponsiveness
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 慢作业或无响应
- en: 'Sometimes, if the SparkContext cannot connect to a Spark standalone master,
    then the driver may display errors such as the following:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，如果SparkContext无法连接到Spark独立主节点，驱动程序可能会显示以下错误：
- en: '[PRE3]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: At other times, the driver is able to connect to the master node but the master
    is unable to communicate back to the driver. Then, multiple attempts to connect
    are made even though the driver will report that it could not connect to the Master's
    log directory.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在其他时候，驱动程序能够连接到主节点，但主节点无法与驱动程序通信。然后，尽管驱动程序会报告无法连接到Master的日志目录，但仍会进行多次连接尝试。
- en: 'Furthermore, you might often experience very slow performance and progress
    in your Spark jobs. This happens because your driver program is not that fast
    to compute your jobs. As discussed earlier, sometimes a particular stage may take
    a longer time than usual because there might be a shuffle, map, join, or aggregation
    operation involved. Even if the computer is running out of disk storage or main
    memory, you may experience these issues. For example, if your master node does
    not respond or you experience unresponsiveness from the computing nodes for a
    certain period of time, you might think that your Spark job has halted and become
    stagnant at a certain stage:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，您可能会经常遇到Spark作业性能和进度非常缓慢的情况。这是因为您的驱动程序计算作业的速度不够快。如前所述，有时某个特定阶段可能比平常花费更长时间，因为可能涉及洗牌、映射、连接或聚合操作。即使计算机磁盘存储或主内存耗尽，您也可能会遇到这些问题。例如，如果主节点没有响应，或者在一段时间内计算节点没有响应，您可能会认为Spark作业已停止，并在某个阶段停滞不前：
- en: '![](img/482c7d9e-b096-418d-8d15-a43d37bd08f7.png)**Figure 24:** An example
    log for executor/driver unresponsiveness'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/482c7d9e-b096-418d-8d15-a43d37bd08f7.png)**图24：**执行器/驱动程序无响应的示例日志'
- en: 'Potential solutions could be several, including the following:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 可能的解决方案有多种，包括以下内容：
- en: 'Check to make sure that workers and drivers are correctly configured to connect
    to the Spark master on the exact address listed in the Spark master web UI/logs.
    Then, explicitly supply the Spark cluster''s master URL when starting your Spark
    shell:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 请确保工作者和驱动程序正确配置以连接到Spark主节点上列出的确切地址，并在启动Spark shell时明确提供Spark集群的主URL：
- en: '[PRE4]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Set `SPARK_LOCAL_IP` to a cluster-addressable hostname for the driver, master,
    and worker processes.
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`SPARK_LOCAL_IP`设置为驱动程序、主节点和工作进程的集群可访问主机名。
- en: Sometimes, we experience some issues due to hardware failure. For example, if
    the filesystem in a computing node closes unexpectedly, that is, an I/O exception,
    your Spark job will eventually fail too. This is obvious because your Spark job
    cannot write the resulting RDDs or data to store to the local filesystem or HDFS.
    This also implies that DAG operations cannot be performed due to the stage failures.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，我们因硬件故障而遇到一些问题。例如，如果计算节点上的文件系统意外关闭，即发生I/O异常，您的Spark作业最终也会失败。这是显而易见的，因为您的Spark作业无法将结果RDD或数据写入本地文件系统或HDFS。这也意味着由于阶段失败，DAG操作无法执行。
- en: 'Sometimes, this I/O exception occurs due to an underlying disk failure or other
    hardware failures. This often provides logs, as follows:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，由于底层磁盘故障或其他硬件故障，会发生此I/O异常。这通常会提供以下日志：
- en: '![](img/b76e59df-f159-4e9e-a174-8e8e8c7885b1.png)**Figure 25:** An example
    filesystem closed'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/b76e59df-f159-4e9e-a174-8e8e8c7885b1.png)**图25：**文件系统关闭示例'
- en: Nevertheless, you often experience slow job computing performance because your
    Java GC is somewhat busy with, or cannot do, the GC fast. For example, the following
    figure shows that for task 0, it took 10 hours to finish the GC! I experienced
    this issue in 2014, when I was new to Spark. Control of these types of issues,
    however, is not in our hands. Therefore, our recommendation is that you should
    make the JVM free and try submitting the jobs again.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，您经常遇到作业计算性能缓慢，因为Java GC在处理GC时有些繁忙，或者无法快速完成GC。例如，下图显示任务0完成GC耗时10小时！我在2014年刚接触Spark时遇到过这个问题。然而，控制这类问题并不在我们手中。因此，我们的建议是您应该让JVM空闲，并尝试重新提交作业。
- en: '![](img/c73396c2-4006-4cf1-8359-8a6081c4baa5.png)**Figure 26:** An example
    where GC stalled in between'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/c73396c2-4006-4cf1-8359-8a6081c4baa5.png)**图26：**GC在中间卡顿的一个示例'
- en: The fourth factor could be the slow response or slow job performance is due
    to the lack of data serialization. This will be discussed in the next section.
    The fifth factor could be the memory leak in the code that will tend to make your
    application consume more memory, leaving the files or logical devices open. Therefore,
    make sure that there is no option that tends to be a memory leak. For example,
    it is a good practice to finish your Spark application by calling `sc.stop()`
    or `spark.stop()`. This will make sure that one SparkContext is still open and
    active. Otherwise, you might get unwanted exceptions or issues. The sixth issue
    is that we often keep too many open files, and this sometimes creates `FileNotFoundException`
    in the shuffle or merge stage.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 第四个因素可能是由于缺乏数据序列化导致的响应缓慢或作业性能低下。这一点将在下一节讨论。第五个因素可能是代码中的内存泄漏，这将导致应用程序消耗更多内存，并保持文件或逻辑设备打开状态。因此，务必确保没有可能导致内存泄漏的选项。例如，通过调用`sc.stop()`或`spark.stop()`来结束Spark应用程序是一个好习惯。这将确保只有一个SparkContext保持打开和活跃状态。否则，您可能会遇到意外的异常或问题。第六个问题是，我们经常保持过多的打开文件，这有时会在洗牌或合并阶段引发`FileNotFoundException`。
- en: Optimization techniques
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优化技术
- en: There are several aspects of tuning Spark applications toward better optimization
    techniques. In this section, we will discuss how we can further optimize our Spark
    applications by applying data serialization by tuning the main memory with better
    memory management. We can also optimize performance by tuning the data structure
    in your Scala code while developing Spark applications. The storage, on the other
    hand, can be maintained well by utilizing serialized RDD storage.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 有多种方法可以针对更好的优化技术调整Spark应用程序。在本节中，我们将讨论如何通过调整主内存与更好的内存管理相结合，应用数据序列化来进一步优化我们的Spark应用程序。我们还可以通过在开发Spark应用程序时调整Scala代码中的数据结构来优化性能。另一方面，通过利用序列化的RDD存储，可以很好地维护存储。
- en: One of the most important aspects is garbage collection, and it's tuning if
    you have written your Spark application using Java or Scala. We will look at how
    we can also tune this for optimized performance. For distributed environment-
    and cluster-based ...
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 垃圾回收及其调整是Spark应用程序使用Java或Scala编写时最重要的方面之一。我们将探讨如何针对优化性能进行调整。对于分布式环境和基于集群的...
- en: Data serialization
  id: totrans-126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据序列化
- en: Serialization is an important tuning for performance improvement and optimization
    in any distributed computing environment. Spark is not an exception, but Spark
    jobs are often data and computing extensive. Therefore, if your data objects are
    not in a good format, then you first need to convert them into serialized data
    objects. This demands a large number of bytes of your memory. Eventually, the
    whole process will slow down the entire processing and computation drastically.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 序列化是任何分布式计算环境中性能改进和优化的重要调整。Spark也不例外，但Spark作业通常数据和计算密集。因此，如果您的数据对象格式不佳，那么您首先需要将它们转换为序列化数据对象。这需要大量内存字节。最终，整个过程将大大减慢整个处理和计算速度。
- en: As a result, you often experience a slow response from the computing nodes.
    This means that we sometimes fail to make 100% utilization of the computing resources.
    It is true that Spark tries to keep a balance between convenience and performance.
    This also implies that data serialization should be the first step in Spark tuning
    for better performance.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，您经常遇到计算节点响应缓慢的问题。这意味着我们有时未能充分利用计算资源。确实，Spark试图在便利性和性能之间保持平衡。这也意味着数据序列化应该是Spark调优以提高性能的第一步。
- en: 'Spark provides two options for data serialization: Java serialization and Kryo
    serialization libraries:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: Spark提供了两种数据序列化选项：Java序列化和Kryo序列化库：
- en: '**Java serialization:** Spark serializes objects using Java''s `ObjectOutputStream`
    framework. You handle the serialization by creating any class that implements
    `java.io.Serializable`. Java serialization is very flexible but often quite slow,
    which is not suitable for large data object serialization.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Java序列化**：Spark使用Java的`ObjectOutputStream`框架来序列化对象。你通过创建任何实现`java.io.Serializable`的类来处理序列化。Java序列化非常灵活，但通常速度很慢，不适合大型数据对象的序列化。'
- en: '**Kryo serialization:** You can also use Kryo library to serialize your data
    objects more quickly. Compared to Java serialization, Kryo serialization is much
    faster, with 10x speedup and is compact than that of Java. However, it has one
    issue, that is, it does not support all the serializable types, but you need to
    require your classes to be registered.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Kryo序列化**：你还可以使用Kryo库更快地序列化你的数据对象。与Java序列化相比，Kryo序列化快10倍，且比Java序列化更紧凑。然而，它有一个问题，即不支持所有可序列化类型，但你需要要求你的类被注册。'
- en: 'You can start using Kryo by initializing your Spark job with a `SparkConf`
    and calling `conf.set(spark.serializer, org.apache.spark.serializer.KryoSerializer)`.
    To register your own custom classes with Kryo, use the `registerKryoClasses` method,
    as follows:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过初始化你的Spark作业并调用`conf.set(spark.serializer, org.apache.spark.serializer.KryoSerializer)`来开始使用Kryo。要向Kryo注册你自己的自定义类，请使用`registerKryoClasses`方法，如下所示：
- en: '[PRE5]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: If your objects are large, you may also need to increase the `spark.kryoserializer.buffer`
    config. This value needs to be large enough to hold the largest object you serialize.
    Finally, if you don't register your custom classes, Kryo still works; however,
    the full class name with each object needs to be stored, which is wasteful indeed.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的对象很大，你可能还需要增加`spark.kryoserializer.buffer`配置。这个值需要足够大，以容纳你序列化的最大对象。最后，如果你没有注册你的自定义类，Kryo仍然可以工作；但是，每个对象都需要存储完整的类名，这确实是浪费的。
- en: 'For example, in the logging subsection at the end of the monitoring Spark jobs
    section, the logging and computing can be optimized using the `Kryo` serialization.
    At first, just create the `MyMapper` class as a normal class (that is, without
    any serialization), as follows:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在监控Spark作业部分的日志记录子部分中，可以使用`Kryo`序列化优化日志记录和计算。首先，只需将`MyMapper`类创建为普通类（即没有任何序列化），如下所示：
- en: '[PRE6]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Now, let''s register this class as a `Kyro` serialization class and then set
    the `Kyro` serialization as follows:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们将这个类注册为`Kyro`序列化类，然后按照以下方式设置`Kyro`序列化：
- en: '[PRE7]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'That''s all you need. The full source code of this example is given in the
    following. You should be able to run and observe the same output, but an optimized
    one as compared to the previous example:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是你所需要的。以下给出了这个示例的完整源代码。你应该能够运行并观察到相同的输出，但与前一个示例相比，这是一个优化版本：
- en: '[PRE8]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The output is as follows:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE9]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Well done! Now let's have a quick look at how to tune the memory. We will look
    at some advanced strategies to make sure the efficient use of the main memory
    in the next section.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 做得好！现在让我们快速了解一下如何调整内存。在下一节中，我们将探讨一些高级策略，以确保主内存的高效使用。
- en: Memory tuning
  id: totrans-144
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 内存调优
- en: In this section, we will discuss some advanced strategies that can be used by
    users like you to make sure that an efficient use of memory is carried out while
    executing your Spark jobs. More specifically, we will show how to calculate the
    memory usages of your objects. We will suggest some advanced ways to improve it
    by optimizing your data structures or by converting your data objects in a serialized
    format using Kryo or Java serializer. Finally, we will look at how to tune Spark's
    Java heap size, cache size, and the Java garbage collector.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论一些高级策略，这些策略可以被像你这样的用户用来确保在执行Spark作业时进行高效的内存使用。更具体地说，我们将展示如何计算你的对象的内存使用量。我们将建议一些高级方法来通过优化你的数据结构或通过使用Kryo或Java序列化器将你的数据对象转换为序列化格式来改进它。最后，我们将探讨如何调整Spark的Java堆大小、缓存大小和Java垃圾收集器。
- en: 'There are three considerations in tuning memory usage:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 调整内存使用时有三个考虑因素：
- en: 'The amount of memory used by your objects: You may even want your entire dataset
    to fit in the memory'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你的对象使用的内存量：你可能甚至希望你的整个数据集都能适应内存
- en: The cost of accessing those ...
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 访问那些...
- en: Memory usage and management
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 内存使用和管理
- en: Memory usages by your Spark application and underlying computing nodes can be
    categorized as execution and storage. Execution memory is used during the computation
    in merge, shuffles, joins, sorts, and aggregations. On the other hand, storage
    memory is used for caching and propagating internal data across the cluster. In
    short, this is due to the large amount of I/O across the network.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 你的 Spark 应用程序及其底层计算节点的内存使用可分为执行和存储两类。执行内存用于合并、洗牌、连接、排序和聚合等计算过程中的使用。另一方面，存储内存用于缓存和在集群间传播内部数据。简而言之，这是由于网络间的大量
    I/O 造成的。
- en: Technically, Spark caches network data locally. While working with Spark iteratively
    or interactively, caching or persistence are optimization techniques in Spark.
    This two help in saving interim partial results so that they can be reused in
    subsequent stages. Then these interim results (as RDDs) can be kept in memory
    (default) or more solid storage, such as a disk, and/or replicated. Furthermore,
    RDDs can be cached using cache operations too. They can also be persisted using
    a persist operation. The difference between cache and persist operations is purely
    syntactic. The cache is a synonym of persisting or persists (`MEMORY_ONLY`), that
    is, the cache is merely persisted with the default storage level `MEMORY_ONLY`.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 从技术上讲，Spark 会将网络数据缓存在本地。在迭代或交互式地使用 Spark 时，缓存或持久化是 Spark 中的优化技巧。这两者有助于保存中间部分结果，以便在后续阶段重用。然后，这些中间结果（作为
    RDD）可以保存在内存中（默认），或更稳定的存储介质，如磁盘，以及/或进行复制。此外，RDD 也可以通过缓存操作进行缓存。它们还可以使用持久化操作进行持久化。缓存和持久化操作之间的区别纯粹是语法上的。缓存是持久化或持久（`MEMORY_ONLY`）的同义词，即缓存仅以默认存储级别
    `MEMORY_ONLY` 进行持久化。
- en: If you go under the Storage tab in your Spark web UI, you should observe the
    memory/storage used by an RDD, DataFrame, or Dataset object, as shown in *Figure
    10*. Although there are two relevant configurations for tuning memory in Spark,
    users do not need to readjust them. The reason is that the default values set
    in the configuration files are enough for your requirements and workloads.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在 Spark 网页界面的存储标签下查看，你应该能看到 RDD、DataFrame 或 Dataset 对象使用的内存/存储，如图 *10* 所示。尽管
    Spark 中有两个与内存调优相关的配置，但用户无需调整它们。原因在于配置文件中设置的默认值足以满足你的需求和负载。
- en: spark.memory.fraction is the size of the unified region as a fraction of (JVM
    heap space - 300 MB) (default 0.6). The rest of the space (40%) is reserved for
    user data structures, internal metadata in Spark, and safeguarding against OOM
    errors in case of sparse and unusually large records. On the other hand, `spark.memory.storageFraction`
    expresses the size of R storage space as a fraction of the unified region (default
    is 0.5). The default value of this parameter is 50% of Java heap space, that is,
    300 MB.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: spark.memory.fraction 表示统一区域大小占（JVM 堆空间 - 300 MB）的比例（默认值为 0.6）。剩余空间（40%）用于用户数据结构、Spark
    内部元数据，以及防范因稀疏和异常大的记录导致的 OOM 错误。另一方面，`spark.memory.storageFraction` 表示 R 存储空间占统一区域的比例（默认值为
    0.5）。此参数的默认值为 Java 堆空间的 50%，即 300 MB。
- en: 'Now, one question might arise in your mind: which storage level to choose?
    To answer this question, Spark storage levels provide you with different trade-offs
    between memory usage and CPU efficiency. If your RDDs fit comfortably with the
    default storage level (MEMORY_ONLY), let your Spark driver or master go with it.
    This is the most memory-efficient option, allowing operations on the RDDs to run
    as fast as possible. You should let it go with this because this is the most memory-efficient
    option. This also allows numerous operations on the RDDs to be done as fast as
    possible.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你心中可能浮现一个问题：应该选择哪种存储级别？针对这个问题，Spark 存储级别提供了不同内存使用与 CPU 效率之间的权衡。如果你的 RDD 能舒适地适应默认存储级别（MEMORY_ONLY），就让
    Spark 驱动器或主节点采用它。这是最节省内存的选项，能让 RDD 上的操作尽可能快地运行。你应该选择这个，因为它是最节省内存的选项。这也使得 RDD 上的众多操作能以最快速度完成。
- en: If your RDDs do not fit the main memory, that is, if `MEMORY_ONLY` does not
    work out, you should try using `MEMORY_ONLY_SER`. It is strongly recommended to
    not spill your RDDs to disk unless your **UDF** (aka **user-defined function**
    that you have defined for processing your dataset) is too expensive. This also
    applies if your UDF filters a large amount of the data during the execution stages.
    In other cases, recomputing a partition, that is, repartition may be faster for
    reading data objects from disk. Finally, if you want fast fault recovery, use
    the replicated storage levels.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的RDD不适合主内存，即`MEMORY_ONLY`不起作用，您应该尝试使用`MEMORY_ONLY_SER`。强烈建议不要将RDD溢出到磁盘，除非您的**UDF**（即您为处理数据集定义的**用户定义函数**）成本过高。如果您的UDF在执行阶段过滤掉大量数据，这也适用。在其他情况下，重新计算分区，即重新分区，可能比从磁盘读取数据对象更快。最后，如果您需要快速故障恢复，请使用复制存储级别。
- en: 'In summary, there are the following StorageLevels available and supported in
    Spark 2.x: (number _2 in the name denotes 2 replicas):'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，Spark 2.x支持以下StorageLevels：（名称中的数字_2表示2个副本）：
- en: '`DISK_ONLY`: This is for disk-based operation for RDDs'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`DISK_ONLY`：这是为RDD进行磁盘操作'
- en: '`DISK_ONLY_2`: This is for disk-based operation for RDDs for 2 replicas'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`DISK_ONLY_2`：这是为RDD进行磁盘操作，有2个副本'
- en: '`MEMORY_ONLY`: This is the default for cache operation in memory for RDDs'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MEMORY_ONLY`：这是RDD在内存中进行缓存操作的默认设置'
- en: '`MEMORY_ONLY_2`: This is the default for cache operation in memory for RDDs
    with 2 replicas'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MEMORY_ONLY_2`：这是RDD在内存中进行缓存操作的默认设置，有2个副本'
- en: '`MEMORY_ONLY_SER`: If your RDDs do not fit the main memory, that is, if `MEMORY_ONLY`
    does not work out, this option particularly helps in storing data objects in a
    serialized form'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MEMORY_ONLY_SER`：如果您的RDD不适合主内存，即`MEMORY_ONLY`不起作用，此选项特别有助于以序列化形式存储数据对象'
- en: '`MEMORY_ONLY_SER_2`: If your RDDs do not fit the main memory, that is, if `MEMORY_ONLY`
    does not work out with 2 replicas, this option also helps in storing data objects
    in a serialized form'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MEMORY_ONLY_SER_2`：如果您的RDD不适合主内存，即`MEMORY_ONLY`在2个副本下不起作用，此选项也有助于以序列化形式存储数据对象'
- en: '`MEMORY_AND_DISK`: Memory and disk (aka combined) based RDD persistence'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MEMORY_AND_DISK`：基于内存和磁盘（即组合）的RDD持久化'
- en: '`MEMORY_AND_DISK_2`: Memory and disk (aka combined) based RDD persistence with
    2 replicas'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MEMORY_AND_DISK_2`：基于内存和磁盘（即组合）的RDD持久化，有2个副本'
- en: '`MEMORY_AND_DISK_SER`: If `MEMORY_AND_DISK` does not work, it can be used'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MEMORY_AND_DISK_SER`：如果`MEMORY_AND_DISK`不起作用，可以使用它'
- en: '`MEMORY_AND_DISK_SER_2`: If `MEMORY_AND_DISK` does not work with 2 replicas,
    this option can be used'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MEMORY_AND_DISK_SER_2`：如果`MEMORY_AND_DISK`在2个副本下不起作用，可以使用此选项'
- en: '`OFF_HEAP`: Does not allow writing into Java heap space'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`OFF_HEAP`：不允许写入Java堆空间'
- en: Note that cache is a synonym of persist (`MEMORY_ONLY`). This means that cache
    is solely persisted with the default storage level, that is, `MEMORY_ONLY`. Detailed
    information can be found at [https://jaceklaskowski.gitbooks.io/mastering-apache-spark/content/spark-rdd-StorageLevel.html](https://jaceklaskowski.gitbooks.io/mastering-apache-spark/content/spark-rdd-StorageLevel.html).
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，缓存是持久化（`MEMORY_ONLY`）的同义词。这意味着缓存仅以默认存储级别持久化，即`MEMORY_ONLY`。详细信息请参见[https://jaceklaskowski.gitbooks.io/mastering-apache-spark/content/spark-rdd-StorageLevel.html](https://jaceklaskowski.gitbooks.io/mastering-apache-spark/content/spark-rdd-StorageLevel.html)。
- en: Tuning the data structures
  id: totrans-169
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 调整数据结构
- en: The first way to reduce extra memory usage is to avoid some features in the
    Java data structure that impose extra overheads. For example, pointer-based data
    structures and wrapper objects contribute to nontrivial overheads. To tune your
    source code with a better data structure, we provide some suggestions here, which
    can be useful.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 减少额外内存使用的第一种方法是避免Java数据结构中的一些特性，这些特性会带来额外的开销。例如，基于指针的数据结构和包装对象会导致非平凡的开销。为了使用更好的数据结构调整您的源代码，我们在这里提供了一些建议，这些建议可能会有所帮助。
- en: First, design your data structures such that you use arrays of objects and primitive
    types more. Thus, this also suggests using standard Java or Scala collection classes
    like `Set`, `List`, `Queue`, `ArrayList`, `Vector`, `LinkedList`, `PriorityQueue`,
    `HashSet`, `LinkedHashSet`, and `TreeSet` more frequently.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，设计您的数据结构，以便更多地使用对象和基本类型的数组。因此，这也建议更频繁地使用标准Java或Scala集合类，如`Set`、`List`、`Queue`、`ArrayList`、`Vector`、`LinkedList`、`PriorityQueue`、`HashSet`、`LinkedHashSet`和`TreeSet`。
- en: Second, when possible, avoid using nested structures with a lot of small objects
    and pointers so ...
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，在可能的情况下，避免使用包含大量小对象和指针的嵌套结构，以便...
- en: Serialized RDD storage
  id: totrans-173
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 序列化RDD存储
- en: As discussed already, despite other types of memory tuning, when your objects
    are too large to fit in the main memory or disk efficiently, a simpler and better
    way of reducing memory usage is storing them in a serialized form.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，尽管有其他类型的内存调整，但当你的对象太大而无法有效地放入主内存或磁盘时，减少内存使用的一个更简单、更好的方法是将其存储在序列化形式中。
- en: This can be done using the serialized storage levels in the RDD persistence
    API, such as `MEMORY_ONLY_SER`. For more information, refer to the previous section
    on memory management and start exploring available options.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以通过RDD持久化API中的序列化存储级别来实现，例如`MEMORY_ONLY_SER`。有关更多信息，请参阅上一节关于内存管理的介绍，并开始探索可用的选项。
- en: If you specify using `MEMORY_ONLY_SER`, Spark will then store each RDD partition
    as one large byte array. However, the only downside of this approach is that it
    can slow down data access times. This is reasonable and obvious too; fairly speaking,
    there's no way to avoid it since each object needs to deserialize on the flyback
    while reusing.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你指定使用`MEMORY_ONLY_SER`，Spark将把每个RDD分区存储为一个大的字节数组。然而，这种方法的唯一缺点是可能会减慢数据访问时间。这是合理的，也是显而易见的；公平地说，由于每个对象在重用时都需要在回弹时进行反序列化，因此无法避免这一点。
- en: As discussed previously, we highly recommend using Kryo serialization instead
    of Java serialization to make data access a bit faster.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们强烈建议使用Kryo序列化而不是Java序列化，以使数据访问更快一些。
- en: Garbage collection tuning
  id: totrans-178
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 垃圾收集调优
- en: Although it is not a major problem in your Java or Scala programs that just
    read an RDD sequentially or randomly once and then execute numerous operations
    on it, **Java Virtual Machine** (**JVM**) GC can be problematic and complex if
    you have a large amount of data objects w.r.t RDDs stored in your driver program.
    When the JVM needs to remove obsolete and unused objects from the old objects
    to make space for the newer ones, it is mandatory to identify them and remove
    them from the memory eventually. However, this is a costly operation in terms
    of processing time and storage. You might be wondering, that the cost of GC is
    proportional to the number of Java objects stored in your main memory. Therefore,
    we strongly suggest ...
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管在你的Java或Scala程序中，只是顺序或随机地读取一次RDD，然后对其执行大量操作，这并不是一个主要问题，但如果你在驱动程序中存储了大量与RDD相关的数据对象，**Java虚拟机**（**JVM**）GC可能会成为一个问题且复杂。当JVM需要从旧对象中删除过时和未使用的对象，为新对象腾出空间时，必须识别它们并最终从内存中删除它们。然而，这在处理时间和存储方面是一个代价高昂的操作。你可能会想知道，GC的成本与存储在主内存中的Java对象数量成正比。因此，我们强烈建议...
- en: Level of parallelism
  id: totrans-180
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 并行度级别
- en: Although you can control the number of map tasks to be executed through optional
    parameters to the `SparkContext.text` file, Spark sets the same on each file according
    to its size automatically. In addition to this, for a distributed `reduce` operation
    such as `groupByKey` and `reduceByKey`, Spark uses the largest parent RDD's number
    of partitions. However, sometimes, we make one mistake, that is, not utilizing
    the full computing resources for your nodes in a computing cluster. As a result,
    the full computing resources will not be fully exploited unless you set and specify
    the level of parallelism for your Spark job explicitly. Therefore, you should
    set the level of parallelism as the second argument.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然你可以通过`SparkContext.text`文件的可选参数来控制要执行的映射任务数量，但Spark会根据文件大小自动为每个文件设置相同的数量。此外，对于`groupByKey`和`reduceByKey`等分布式`reduce`操作，Spark使用最大父RDD的分区数。然而，有时我们会犯一个错误，即没有充分利用计算集群中节点的全部计算资源。因此，除非你明确设置并指定Spark作业的并行度级别，否则无法充分利用全部计算资源。因此，你应该将并行度级别设置为第二个参数。
- en: For more on this option, please refer to [https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.PairRDDFunctions.](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.PairRDDFunctions)
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 关于此选项的更多信息，请参考[https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.PairRDDFunctions](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.PairRDDFunctions)。
- en: Alternatively, you can do it by setting the config property spark.default.parallelism
    to change the default. For operations such as parallelizing with no parent RDDs,
    the level of parallelism depends on the cluster manager, that is, standalone,
    Mesos, or YARN. For the local mode, set the level of parallelism equal to the
    number of cores on the local machine. For Mesos or YARN, set the fine-grained
    mode to 8\. In other cases, the total number of cores on all executor nodes or
    2, whichever is larger, and in general, 2-3 tasks per CPU core in your cluster
    is recommended.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，您可以通过设置配置属性 spark.default.parallelism 来更改默认值。对于没有父 RDD 的并行化等操作，并行度取决于集群管理器，即独立、Mesos
    或 YARN。对于本地模式，将并行度设置为本地机器上的核心数。对于 Mesos 或 YARN，将细粒度模式设置为 8。在其他情况下，将所有执行器节点上的核心总数或
    2 中较大的一个设置为并行度，并建议在集群中每个 CPU 核心上运行 2-3 个任务。
- en: Broadcasting
  id: totrans-184
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 广播
- en: A broadcast variable enables a Spark developer to keep a read-only copy of an
    instance or class variable cached on each driver program, rather than transferring
    a copy of its own with the dependent tasks. However, an explicit creation of a
    broadcast variable is useful only when tasks across multiple stages need the same
    data in deserialize form.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 广播变量使 Spark 开发者能够在每个驱动程序上缓存一个只读副本的实例或类变量，而不是将副本与其依赖任务一起传输。然而，仅当多个阶段中的任务需要以反序列化形式使用相同数据时，显式创建广播变量才有用。
- en: In Spark application development, using the broadcasting option of SparkContext
    can reduce the size of each serialized task greatly. This also helps to reduce
    the cost of initiating a Spark job in a cluster. If you have a certain task in
    your Spark job that uses large objects from the driver program, you should turn
    it into a broadcast variable.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Spark 应用程序开发中，使用 SparkContext 的广播选项可以大幅减少每个序列化任务的大小。这也有助于降低在集群中启动 Spark 作业的成本。如果在
    Spark 作业中有一个任务使用了来自驱动程序的大对象，应将其转换为广播变量。
- en: To use a broadcast variable in a Spark ...
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Spark 中使用广播变量...
- en: Data locality
  id: totrans-188
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据局部性
- en: Data locality means how close the data is to the code to be processed. Technically,
    data locality can have a nontrivial impact on the performance of a Spark job to
    be executed locally or in cluster mode. As a result, if the data and the code
    to be processed are tied together, computation is supposed to be much faster.
    Usually, shipping a serialized code from a driver to an executor is much faster
    since the code size is much smaller than that of data.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 数据局部性意味着数据与待处理代码的接近程度。从技术上讲，数据局部性可以对本地或集群模式下执行的 Spark 作业的性能产生显著影响。因此，如果数据和待处理代码紧密相连，计算速度应该会快得多。通常，从驱动程序向执行器发送序列化代码要快得多，因为代码大小远小于数据大小。
- en: 'In Spark application development and job execution, there are several levels
    of locality. In order from closest to farthest, the level depends on the current
    location of the data you have to process:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Spark 应用程序开发和作业执行中，存在多个级别的局部性。从最近到最远，级别取决于您需要处理的数据的当前位置：
- en: '| **Data Locality** | **Meaning** | **Special Notes** |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '| **数据局部性** | **含义** | **特别说明** |'
- en: '| `PROCESS_LOCAL` | Data and code are in the same location | Best locality
    possible |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| `PROCESS_LOCAL` | 数据和代码位于同一位置 | 最佳局部性 |'
- en: '| `NODE_LOCAL` | Data and the code are on the same node, for example, data
    stored on HDFS | A bit slower than `PROCESS_LOCAL` since the data has to propagate
    across the processes and network |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| `NODE_LOCAL` | 数据和代码位于同一节点，例如存储在 HDFS 上的数据 | 比 `PROCESS_LOCAL` 稍慢，因为数据需要在进程和网络之间传播
    |'
- en: '| `NO_PREF` | The data is accessed equally from somewhere else | Has no locality
    preference |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| `NO_PREF` | 数据从其他地方等同访问 | 没有局部性偏好 |'
- en: '| `RACK_LOCAL` | The data is on the same rack of servers over the network |
    Suitable for large-scale data processing |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| `RACK_LOCAL` | 数据位于同一机架的服务器上 | 适用于大规模数据处理 |'
- en: '| `ANY` | The data is elsewhere on the network and not in the same rack | Not
    recommended unless there are no other options available |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| `ANY` | 数据位于网络上的其他地方，不在同一机架内 | 除非没有其他选择，否则不推荐使用 |'
- en: '**Table 2:** Data locality and Spark'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '**表 2：** 数据局部性与 Spark'
- en: 'Spark is developed such that it prefers to schedule all tasks at the best locality
    level, but this is not guaranteed and not always possible either. As a result,
    based on the situation in the computing nodes, Spark switches to lower locality
    levels if available computing resources are too occupied. Moreover, if you would
    like to have the best data locality, there are two choices for you:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: Spark 被设计成倾向于在最佳局部性级别调度所有任务，但这并不能保证，也不总是可能的。因此，根据计算节点的实际情况，如果可用计算资源过于繁忙，Spark
    会切换到较低的局部性级别。此外，如果你想获得最佳的数据局部性，你有两个选择：
- en: Wait until a busy CPU gets free to start a task on your data on the same server
    or same node
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 等待繁忙的 CPU 空闲下来，以便在同一服务器或同一节点上启动处理你的数据的任务
- en: Immediately start a new one, which requires moving data there
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 立即开始一个新的，这需要将数据迁移过去
- en: Summary
  id: totrans-201
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we discussed some advanced topics of Spark toward making your
    Spark job's performance better. We discussed some basic techniques to tune your
    Spark jobs. We discussed how to monitor your jobs by accessing Spark web UI. We
    discussed how to set Spark configuration parameters. We also discussed some common
    mistakes made by Spark users and provided some recommendations. Finally, we discussed
    some optimization techniques that help tune Spark applications.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了使 Spark 作业性能更优的一些高级主题。我们讨论了一些基本技术来调整你的 Spark 作业。我们讨论了如何通过访问 Spark
    Web UI 来监控你的作业。我们讨论了如何设置 Spark 配置参数。我们还讨论了一些 Spark 用户常犯的错误，并提供了一些建议。最后，我们讨论了一些有助于调整
    Spark 应用程序的优化技术。
