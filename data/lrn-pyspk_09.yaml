- en: Chapter 9. Polyglot Persistence with Blaze
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第9章. 使用Blaze的多语言持久化
- en: Our world is complex and no single approach exists that solves all problems.
    Likewise, in the data world one cannot solve all problems with one piece of technology.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的世界是复杂的，没有一种单一的方法可以解决所有问题。同样，在数据世界中，也不能用一种技术来解决所有问题。
- en: Nowadays, any big technology company uses (in one form or another) a MapReduce
    paradigm to sift through terabytes (or even petabytes) of data collected daily.
    On the other hand, it is much easier to store, retrieve, extend, and update information
    about products in a document-type database (such as MongoDB) than it is in a relational
    database. Yet, persisting transaction records in a relational database aids later
    data summarizing and reporting.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，任何大型科技公司（以某种形式）都使用MapReduce范式来筛选每天收集的数以千计（甚至数以万计）的数据。另一方面，在文档型数据库（如MongoDB）中存储、检索、扩展和更新产品信息比在关系型数据库中要容易得多。然而，在关系型数据库中持久化交易记录有助于后续的数据汇总和报告。
- en: Even these simple examples show that solving a vast array of business problems
    requires adapting to different technologies. This means that you, as a database
    manager, data scientist, or data engineer, would have to learn all of these separately
    if you were to solve your problems with the tools that are designed to solve them
    easily. This, however, does not make your company agile and is prone to errors
    and lots of tweaking and hacking needing to be done to your system.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 即使这些简单的例子也表明，解决各种商业问题需要适应不同的技术。这意味着，如果你作为数据库管理员、数据科学家或数据工程师，想要用设计来轻松解决这些问题的工具来解决这些问题，你就必须分别学习所有这些技术。然而，这并不使你的公司变得敏捷，并且容易出错，需要对你的系统进行大量的调整和破解。
- en: Blaze abstracts most of the technologies and exposes a simple and elegant data
    structure and API.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Blaze抽象了大多数技术，并暴露了一个简单而优雅的数据结构和API。
- en: 'In this chapter, you will learn:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将学习：
- en: How to install Blaze
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何安装Blaze
- en: What polyglot persistence is about
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多语言持久化的含义
- en: How to abstract data stored in files, pandas DataFrames, or NumPy arrays
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何抽象存储在文件、pandas DataFrame或NumPy数组中的数据
- en: How to work with archives (GZip)
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何处理归档（GZip）
- en: How to connect to SQL (PostgreSQL and SQLite) and No-SQL (MongoDB) databases
    with Blaze
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用Blaze连接到SQL（PostgreSQL和SQLite）和No-SQL（MongoDB）数据库
- en: How to query, join, sort, and transform the data, and perform simple summary
    statistics
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何查询、连接、排序、转换数据，并执行简单的汇总统计
- en: Installing Blaze
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装Blaze
- en: 'If you run Anaconda it is easy to install Blaze. Just issue the following command
    in your CLI (see the Bonus [Chapter 1](ch01.html "Chapter 1. Understanding Spark"),
    *Installing Spark* if you do not know what a CLI is):'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你运行Anaconda，安装Blaze很容易。只需在你的CLI（如果你不知道CLI是什么，请参阅奖励章节[第1章](ch01.html "第1章.
    理解Spark")，*安装Spark*）中发出以下命令：
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Once the command is issued, you will see a screen similar to the following
    screenshot:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦发出命令，你将看到类似于以下截图的屏幕：
- en: '![Installing Blaze](img/B05793_09_01.jpg)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![安装Blaze](img/B05793_09_01.jpg)'
- en: We will later use Blaze to connect to the PostgreSQL and MongoDB databases,
    so we need to install some additional packages that Blaze will use in the background.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将稍后使用Blaze连接到PostgreSQL和MongoDB数据库，因此我们需要安装一些Blaze在后台使用的附加包。
- en: 'We will install SQL Alchemy and PyMongo, both of which are part of Anaconda:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将安装SQLAlchemy和PyMongo，它们都是Anaconda的一部分：
- en: '[PRE1]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'All that is now left to do is to import Blaze itself in our notebook:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 现在剩下的只是在我们笔记本中导入Blaze本身：
- en: '[PRE2]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Polyglot persistence
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多语言持久化
- en: Neal Ford introduced the, somewhat similar, term polyglot programming in 2006\.
    He used it to illustrate the fact that there is no such thing as a one-size-fits-all
    solution and advocated using multiple programming languages that were more suitable
    for certain problems.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: Neal Ford于2006年引入了“多语言编程”这一概念，用以说明没有一种万能的解决方案，并提倡使用多种更适合特定问题的编程语言。
- en: In the parallel world of data, any business that wants to remain competitive
    needs to adapt a range of technologies that allows it to solve the problems in
    a minimal time, thus minimizing the costs.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据并行的世界中，任何想要保持竞争力的企业都需要适应一系列技术，以便在尽可能短的时间内解决问题，从而最小化成本。
- en: Storing transactional data in Hadoop files is possible, but makes little sense.
    On the other hand, processing petabytes of Internet logs using a **Relational
    Database Management System** (**RDBMS**) would also be ill-advised. These tools
    were designed to tackle specific types of tasks; even though they can be co-opted
    to solve other problems, the cost of adapting the tools to do so would be enormous.
    It is a virtual equivalent of trying to fit a square peg in a round hole.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在Hadoop文件中存储事务数据是可能的，但意义不大。另一方面，使用**关系数据库管理系统**（**RDBMS**）处理PB级的互联网日志也是不明智的。这些工具是为了解决特定类型的任务而设计的；尽管它们可以被用来解决其他问题，但适应这些工具以解决这些问题的成本将是巨大的。这就像试图将方钉塞入圆孔一样。
- en: 'For example, consider a company that sells musical instruments and accessories
    online (and in a network of shops). At a high-level, there are a number of problems
    that a company needs to solve to be successful:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑一家在线销售乐器和配件的公司（以及一系列商店）。从高层次来看，公司需要解决许多问题才能成功：
- en: Attract customers to its stores (both virtual and physical).
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 吸引客户到其商店（无论是虚拟的还是实体的）。
- en: Present them with relevant products (you would not try to sell a drum kit to
    a pianist, would you?!).
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向他们展示相关的产品（你不会试图向钢琴家卖鼓组，对吧？！）。
- en: Once they decide to buy, process the payment and organize shipping.
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦他们决定购买，处理付款并安排运输。
- en: 'To solve these problems a company might choose from a number of available technologies
    that were designed to solve these problems:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这些问题，公司可能会选择一系列旨在解决这些问题的技术：
- en: 'Store all the products in a document-based database such as MongoDB, Cassandra,
    DynamoDB, or DocumentDB. There are multiple advantages of document databases:
    flexible schema, sharding (breaking bigger databases into a set of smaller, more
    manageable ones), high availability, and replication, among others.'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将所有产品存储在文档数据库中，如MongoDB、Cassandra、DynamoDB或DocumentDB。文档数据库具有多个优点：灵活的模式、分片（将更大的数据库分解为一系列更小、更易于管理的数据库）、高可用性和复制等。
- en: 'Model the recommendations using a graph-based database (such as Neo4j, Tinkerpop/Gremlin,
    or GraphFrames for Spark): such databases reflect the factual and abstract relationships
    between customers and their preferences. Mining such a graph is invaluable and
    can produce a more tailored offering for a customer.'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用基于图数据库（如Neo4j、Tinkerpop/Gremlin或Spark的GraphFrames）来建模推荐：此类数据库反映了客户及其偏好的事实和抽象关系。挖掘这样的图非常有价值，可以为客户提供更个性化的服务。
- en: For searching, a company might use a search-tailored solution such as Apache
    Solr or ElasticSearch. Such a solution provides fast, indexed text searching capabilities.
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于搜索，公司可能会使用定制的搜索解决方案，如Apache Solr或ElasticSearch。此类解决方案提供快速、索引的文本搜索功能。
- en: Once a product is sold, the transaction normally has a well-structured schema
    (such as product name, price, and so on.) To store such data (and later process
    and report on it) relational databases are best suited.
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦产品售出，交易通常有一个结构良好的模式（例如产品名称、价格等）。为了存储此类数据（以及稍后对其进行处理和报告），关系数据库是最适合的。
- en: With polyglot persistence, a company always chooses the right tool for the right
    job instead of trying to coerce a single technology into solving all of its problems.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 使用多语言持久性，公司总是选择最适合的工具来完成工作，而不是试图将单一技术强加于解决所有问题。
- en: Blaze, as we will see, abstracts these technologies and introduces a simple
    API to work with, so you do not have to learn the APIs of each and every technology
    you want to use. It is, in essence, a great working example of polyglot persistence.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，Blaze将这些技术抽象化，并引入了一个简单的API来与之交互，因此您不需要学习每个想要使用的技术的API。本质上，它是一个多语言持久性的优秀工作示例。
- en: Note
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 备注
- en: To see how others do it, check out [http://www.slideshare.net/Couchbase/couchbase-at-ebay-2014](http://www.slideshare.net/Couchbase/couchbase-at-ebay-2014)
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解其他人如何做，请查看[http://www.slideshare.net/Couchbase/couchbase-at-ebay-2014](http://www.slideshare.net/Couchbase/couchbase-at-ebay-2014)
- en: or
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 或者
- en: '[http://www.slideshare.net/bijoor1/case-study-polyglotpersistence-in-pharmaceutical-industry](https://www.slideshare.net/bijoor1/case-study-polyglot-persistence-in-pharmaceutical-industry).'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://www.slideshare.net/bijoor1/case-study-polyglotpersistence-in-pharmaceutical-industry](https://www.slideshare.net/bijoor1/case-study-polyglot-persistence-in-pharmaceutical-industry).'
- en: Abstracting data
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 抽象化数据
- en: Blaze can abstract many different data structures and expose a single, easy-to-use
    API. This helps to get a consistent behavior and reduce the need to learn multiple
    interfaces to handle data. If you know pandas, there is not really that much to
    learn, as the differences in the syntax are subtle. We will go through some examples
    to illustrate this.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: Blaze 可以抽象许多不同的数据结构，并暴露一个单一、易于使用的 API。这有助于获得一致的行为并减少学习多个接口来处理数据的需要。如果你熟悉 pandas，实际上没有多少东西需要学习，因为语法上的差异是细微的。我们将通过一些示例来说明这一点。
- en: Working with NumPy arrays
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 NumPy 数组
- en: 'Getting data from a NumPy array into the DataShape object of Blaze is extremely
    easy. First, let''s create a simple NumPy array: we first load NumPy and then
    create a matrix with two rows and three columns:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据从 NumPy 数组放入 Blaze 的 DataShape 对象中非常容易。首先，让我们创建一个简单的 NumPy 数组：我们首先加载 NumPy，然后创建一个两行三列的矩阵：
- en: '[PRE3]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now that we have an array, we can abstract it with Blaze''s DataShape structure:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了数组，我们可以使用 Blaze 的 DataShape 结构来抽象它：
- en: '[PRE4]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: That's it! Simple enough.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样！简单得令人难以置信。
- en: 'In order to peek inside the structure you can use the .`peek()` method:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 为了窥视结构，你可以使用 .`peek()` 方法：
- en: '[PRE5]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'You should see an output similar to what is shown in the following screenshot:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该看到以下截图所示的类似输出：
- en: '![Working with NumPy arrays](img/B05793_09_02.jpg)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![使用 NumPy 数组](img/B05793_09_02.jpg)'
- en: You can also use (familiar to those of you versed in pandas' syntax) the .`head(...)`
    method.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以使用（对于那些熟悉 pandas 语法的人来说很熟悉）的 .`head(...)` 方法。
- en: Note
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The difference between `.peek()` and `.head(...)` is that `.head(...)` allows
    the specification of the number of rows as its only parameter, whereas `.peek()`
    does not allow that and will always print the top 10 records.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '`.peek()` 和 `.head(...)` 之间的区别在于 `.head(...)` 允许指定行数作为其唯一参数，而 `.peek()` 不允许这样做，并且总是打印前
    10 条记录。'
- en: 'If you want to retrieve the first column of your DataShape, you can use indexing:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要检索你的 DataShape 的第一列，你可以使用索引：
- en: '[PRE6]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'You should see a table, as shown here:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该看到一个表格，就像这里所示：
- en: '![Working with NumPy arrays](img/B05793_09_03.jpg)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![使用 NumPy 数组](img/B05793_09_03.jpg)'
- en: 'On the other hand, if you were interested in retrieving a row, all you would
    have to do (like in NumPy) is transpose your DataShape:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，如果你对检索一行感兴趣，你所要做的（就像在 NumPy 中一样）就是转置你的 DataShape：
- en: '[PRE7]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'What you will then get is presented in the following figure:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 你将得到的结果如下所示：
- en: '![Working with NumPy arrays](img/B05793_09_04.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![使用 NumPy 数组](img/B05793_09_04.jpg)'
- en: 'Notice that the name of the column is `None`. DataShapes, just like pandas''
    DataFrames, support named columns. Thus, let''s specify the names of our fields:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 注意到列的名称是 `None`。DataShapes，就像 pandas 的 DataFrames 一样，支持命名列。因此，让我们指定我们字段的名称：
- en: '[PRE8]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Now you can retrieve the data simply by calling the column by its name:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你可以通过调用列的名称来简单地检索数据：
- en: '[PRE9]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'In return, you will get the following output:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 作为回报，你将得到以下输出：
- en: '![Working with NumPy arrays](img/B05793_09_05.jpg)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![使用 NumPy 数组](img/B05793_09_05.jpg)'
- en: As you can see, defining the fields transposes the NumPy array and, now, each
    element of the array forms a *row*, unlike when we first created the `simpleData_np`.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，定义字段会转置 NumPy 数组，现在，数组的每个元素都形成一个 *行*，这与我们最初创建的 `simpleData_np` 不同。
- en: Working with pandas' DataFrame
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 pandas 的 DataFrame
- en: Since pandas' DataFrameinternally uses NumPy data structures, translating a
    DataFrame to DataShape is effortless.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 pandas 的 DataFrame 内部使用 NumPy 数据结构，将 DataFrame 转换为 DataShape 是轻而易举的。
- en: 'First, let''s create a simple DataFrame. We start by importing pandas:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们创建一个简单的 DataFrame。我们首先导入 pandas：
- en: '[PRE10]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Next, we create a DataFrame:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们创建一个 DataFrame：
- en: '[PRE11]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We then transform it into a DataShape:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将它转换成一个 DataShape：
- en: '[PRE12]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'You can retrieve data in the same manner as with the DataShape created from
    the NumPy array. Use the following command:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用与从 NumPy 数组创建的 DataShape 相同的方式检索数据。使用以下命令：
- en: '[PRE13]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Then, it will produce the following output:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，它将产生以下输出：
- en: '![Working with pandas'' DataFrame](img/B05793_09_06.jpg)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![使用 pandas 的 DataFrame](img/B05793_09_06.jpg)'
- en: Working with files
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用文件
- en: A DataShape object can be created directly from a `.csv` file. In this example,
    we will use a dataset that consists of 404,536 traffic violations that happened
    in the Montgomery county of Maryland.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: DataShape 对象可以直接从 `.csv` 文件创建。在这个例子中，我们将使用一个包含 404,536 蒙哥马利县马里兰州发生的交通违规行为的数据集。
- en: Note
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: We downloaded the data from [https://catalog.data.gov/dataset/traffic-violations-56dda](https://catalog.data.gov/dataset/traffic-violations-56dda)
    on 8/23/16; the dataset is updated daily, so the number of traffic violations
    might differ if you retrieve the dataset at a later date.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们于 2016 年 8 月 23 日从 [https://catalog.data.gov/dataset/traffic-violations-56dda](https://catalog.data.gov/dataset/traffic-violations-56dda)
    下载了数据；数据集每日更新，因此如果你在稍后的日期检索数据集，交通违规的数量可能会有所不同。
- en: 'We store the dataset in the `../Data` folder locally. However, we modified
    the dataset slightly so we could store it in the MongoDB: in its original form,
    with date columns, reading data back from MongoDB caused errors. We filed a bug
    with Blaze to fix this issue [https://github.com/blaze/blaze/issues/1580](https://github.com/blaze/blaze/issues/1580):'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将数据集存储在本地 `../Data` 文件夹中。然而，我们稍微修改了数据集，以便我们可以将其存储在 MongoDB 中：在其原始形式中，带有日期列，从
    MongoDB 中读取数据会导致错误。我们向 Blaze 提交了一个错误报告 [https://github.com/blaze/blaze/issues/1580](https://github.com/blaze/blaze/issues/1580)：
- en: '[PRE14]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'If you do not know the names of the columns in any dataset, you can get these
    from the DataShape. To get a list of all the fields, you can use the following
    command:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你不知道任何数据集的列名，你可以从 DataShape 中获取这些信息。要获取所有字段的列表，可以使用以下命令：
- en: '[PRE15]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '![Working with files](img/B05793_09_07.jpg)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![处理文件](img/B05793_09_07.jpg)'
- en: Tip
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: Those of you familiar with pandas would easily recognize the similarity between
    the `.fields` and `.columns` attributes, as these work in essentially the same
    way - they both return the list of columns (in the case of pandas DataFrame),
    or the list of fields, as columns are called in the case of Blaze DataShape.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 对于熟悉 pandas 的你们来说，很容易识别 `.fields` 和 `.columns` 属性之间的相似性，因为它们基本上以相同的方式工作——它们都返回列的列表（在
    pandas DataFrame 的情况下），或者称为 Blaze DataShape 中的字段列表。
- en: 'Blaze can also read directly from a `GZipped` archive, saving space:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: Blaze 还可以直接从 `GZipped` 归档中读取，节省空间：
- en: '[PRE16]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'To validate that we get exactly the same data, let''s retrieve the first two
    records from each structure. You can either call the following:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 为了验证我们得到的确切相同的数据，让我们从每个结构中检索前两个记录。你可以调用以下之一：
- en: '[PRE17]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Or you can choose to call:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，你也可以选择调用：
- en: '[PRE18]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'It produces the same results (columns abbreviated here):'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 它产生相同的结果（此处省略列名）：
- en: '![Working with files](img/B05793_09_08.jpg)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![处理文件](img/B05793_09_08.jpg)'
- en: It is easy to notice, however, that it takes significantly more time to retrieve
    the data from the archived file because Blaze needs to decompress the data.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，很容易注意到从归档文件中检索数据需要显著更多的时间，因为 Blaze 需要解压缩数据。
- en: You can also read from multiple files at one time and create one big dataset.
    To illustrate this, we have split the original dataset into four `GZipped` datasets
    by year of violation (these are stored in the `../Data/Years` folder).
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以一次从多个文件中读取并创建一个大数据集。为了说明这一点，我们将原始数据集按违规年份分割成四个 `GZipped` 数据集（这些存储在 `../Data/Years`
    文件夹中）。
- en: 'Blaze uses `odo` to handle saving DataShapesto a variety of formats. To save
    `traffic` data for traffic violations by year you can call `odo` like this:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: Blaze 使用 `odo` 来处理将 DataShape 保存到各种格式。要保存按年份划分的交通违规数据，你可以这样调用 `odo`：
- en: '[PRE19]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The preceding instruction saves the data into a `GZip` archive, but you can
    save it to any of the formats mentioned earlier. The first argument to the `.odo(...)`
    method specifies the input object (in our case, the DataShapewith traffic violations
    that occurred in 2013), the second argument is the output object - the path to
    the file we want to save the data to. As we are about to learn - storing data
    is not limited to files only.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 上述指令将数据保存到 `GZip` 归档中，但你也可以将其保存到前面提到的任何格式。`.odo(...)` 方法的第一个参数指定输入对象（在我们的例子中，是2013年发生的交通违规的
    DataShape），第二个参数是输出对象——我们想要保存数据的文件路径。正如我们即将学习的——存储数据不仅限于文件。
- en: 'To read from multiple files you can use the asterisk character `*`:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 要从多个文件中读取，可以使用星号字符 `*`：
- en: '[PRE20]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The preceding snippet, once again, will produce a familiar table:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码片段，再次，将生成一个熟悉的表格：
- en: '![Working with files](img/B05793_09_09.jpg)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![处理文件](img/B05793_09_09.jpg)'
- en: 'Blaze reading capabilities are not limited to `.csv` or `GZip` files only:
    you can read data from JSON or Excel files (both, `.xls` and `.xlsx`), HDFS, or
    bcolz formatted files.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: Blaze 的读取能力不仅限于 `.csv` 或 `GZip` 文件：你可以从 JSON 或 Excel 文件（`.xls` 和 `.xlsx`）、HDFS
    或 bcolz 格式的文件中读取数据。
- en: Tip
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: To learn more about the bcolz format, check its documentation at [https://github.com/Blosc/bcolz](https://github.com/Blosc/bcolz).
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于 bcolz 格式的信息，请查看其文档 [https://github.com/Blosc/bcolz](https://github.com/Blosc/bcolz)。
- en: Working with databases
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 处理数据库
- en: Blaze can also easily read from SQL databases such as PostgreSQL or SQLite.
    While SQLite would normally be a local database, the PostgreSQL can be run either
    locally or on a server.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: Blaze 也可以轻松地从 SQL 数据库（如 PostgreSQL 或 SQLite）中读取。虽然 SQLite 通常是一个本地数据库，但 PostgreSQL
    可以在本地或服务器上运行。
- en: Blaze, as mentioned earlier, uses `odo` in the background to handle the communication
    to and from the databases.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，Blaze 在后台使用 `odo` 来处理与数据库的通信。
- en: Note
  id: totrans-117
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '`odo` is one of the requirements for Blaze and it gets installed along with
    the package. Check it out here [https://github.com/blaze/odo](https://github.com/blaze/odo).'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '`odo` 是 Blaze 的一个要求，它将与包一起安装。在此处查看 [https://github.com/blaze/odo](https://github.com/blaze/odo)。'
- en: 'In order to execute the code in this section, you will need two things: a running
    local instance of a PostgreSQL database, and a locally running MongoDB database.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 为了执行本节中的代码，您需要两样东西：一个运行中的本地 PostgreSQL 数据库实例，以及一个本地运行的 MongoDB 数据库。
- en: Tip
  id: totrans-120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: In order to install PostgreSQL, download the package from [http://www.postgresql.org/download/](http://www.postgresql.org/download/)
    and follow the installation instructions for your operating system found there.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 为了安装 PostgreSQL，从 [http://www.postgresql.org/download/](http://www.postgresql.org/download/)
    下载包，并遵循那里找到的适用于您操作系统的安装说明。
- en: To install MongoDB, go to [https://www.mongodb.org/downloads](https://www.mongodb.org/downloads)
    and download the package; the installation instructions can be found here [http://docs.mongodb.org/manual/installation/](http://docs.mongodb.org/manual/installation/).
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 要安装 MongoDB，请访问 [https://www.mongodb.org/downloads](https://www.mongodb.org/downloads)
    并下载包；安装说明可以在 [http://docs.mongodb.org/manual/installation/](http://docs.mongodb.org/manual/installation/)
    找到。
- en: Before you proceed, we assume that you have a PostgreSQL database up and running
    at `http://localhost:5432/`, and MongoDB database running at `http://localhost:27017`.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在您继续之前，我们假设您已经在 `http://localhost:5432/` 上运行了一个 PostgreSQL 数据库，并且 MongoDB 数据库在
    `http://localhost:27017` 上运行。
- en: We have already loaded the traffic data to both of the databases and stored
    them in the `traffic` table (PostgreSQL) or the `traffic` collection (MongoDB).
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经将交通数据加载到两个数据库中，并将它们存储在 `traffic` 表（PostgreSQL）或 `traffic` 集合（MongoDB）中。
- en: Tip
  id: totrans-125
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: If you do not know how to upload your data, I have explained this in my other
    book [https://www.packtpub.com/big-data-and-business-intelligence/practical-data-analysis-cookbook](https://www.packtpub.com/big-data-and-business-intelligence/practical-data-analysis-cookbook).
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您不知道如何上传数据，我在我的另一本书中解释了这一点 [https://www.packtpub.com/big-data-and-business-intelligence/practical-data-analysis-cookbook](https://www.packtpub.com/big-data-and-business-intelligence/practical-data-analysis-cookbook)。
- en: Interacting with relational databases
  id: totrans-127
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 与关系数据库交互
- en: Let's read the data from the PostgreSQL database now. The **Uniform Resource
    Identifier** (**URI**) for accessing a PostgreSQL database has the following syntax
    `postgresql://<user_name>:<password>@<server>:<port>/<database>::<table>`.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们从 PostgreSQL 数据库中读取数据。访问 PostgreSQL 数据库的 **统一资源标识符**（**URI**）具有以下语法 `postgresql://<user_name>:<password>@<server>:<port>/<database>::<table>`。
- en: 'To read the data from PostgreSQL, you just wrap the URI around `.Data(...)`
    - Blaze will take care of the rest:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 要从 PostgreSQL 读取数据，只需将 URI 包裹在 `.Data(...)` 中 - Blaze 将处理其余部分：
- en: '[PRE21]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: We use Python's `.format(...)` method to fill in the string with the appropriate
    data.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 Python 的 `.format(...)` 方法来填充字符串以包含适当的数据。
- en: Tip
  id: totrans-132
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: Substitute your credentials to access your PostgreSQL database in the previous
    example. If you want to read more about the `.format(...)` method, you can check
    out the Python 3.5 documentation [https://docs.python.org/3/library/string.html#format-string-syntax](https://docs.python.org/3/library/string.html#format-string-syntax).
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中替换您的凭据以访问 PostgreSQL 数据库。如果您想了解更多关于 `.format(...)` 方法的知识，可以查看 Python
    3.5 文档 [https://docs.python.org/3/library/string.html#format-string-syntax](https://docs.python.org/3/library/string.html#format-string-syntax)。
- en: 'It is quite easy to output the data to either the PostgreSQL or SQLite databases.
    In the following example, we will output traffic violations that involved cars
    manufactured in 2016 to both PostgreSQL and SQLite databases. As previously noted,
    we will use `odo` to manage the transfers:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据输出到 PostgreSQL 或 SQLite 数据库相当简单。在下面的示例中，我们将输出涉及 2016 年生产的汽车的交通违规数据到 PostgreSQL
    和 SQLite 数据库。如前所述，我们将使用 `odo` 来管理传输：
- en: '[PRE22]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: In a similar fashion to pandas, to filter the data, we effectively select the
    `Year` column (the `traffic_psql['Year']` part of the first line) and create a
    Boolean flag by checking whether each and every record in that column equals `2016`.
    By indexing the `traffic_psql` object with such a truth vector, we extract only
    the records where the corresponding value equals `True`.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 与pandas类似，为了过滤数据，我们实际上选择了`Year`列（第一行的`traffic_psql['Year']`部分）并创建一个布尔标志，通过检查该列中的每个记录是否等于`2016`。通过将`traffic_psql`对象索引为这样的真值向量，我们提取了对应值等于`True`的记录。
- en: The two commented out lines should be uncommented if you already have the `traffic2016`
    tables in your databases; otherwise `odo` will append the data to the end of the
    table.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您数据库中已经存在`traffic2016`表，则应取消注释以下两行；否则`odo`将数据追加到表末尾。
- en: The URI for SQLite is slightly different than the one for PostgreSQL; it has
    the following syntax `sqlite://</relative/path/to/db.sqlite>::<table_name>`.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: SQLite的URI与PostgreSQL略有不同；它的语法如下`sqlite://</relative/path/to/db.sqlite>::<table_name>`。
- en: 'Reading data from the SQLite database should be trivial for you by now:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 到现在为止，从SQLite数据库读取数据应该对您来说很简单：
- en: '[PRE23]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Interacting with the MongoDB database
  id: totrans-141
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 与MongoDB数据库交互
- en: 'MongoDB has gained lots of popularity over the years. It is a simple, fast,
    and flexible document-based database. The database is a go-to storage solution
    for all full-stack developers, using the `MEAN.js` stack: M here stands for Mongo
    (see [http://meanjs.org](http://meanjs.org)).'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: MongoDB多年来获得了大量的流行度。它是一个简单、快速且灵活的文档型数据库。对于使用`MEAN.js`堆栈的所有全栈开发者来说，该数据库是一个首选的存储解决方案：这里的M代表Mongo（见[http://meanjs.org](http://meanjs.org)）。
- en: 'Since Blaze is meant to work in a very familiar way no matter what your data
    source, reading from MongoDB is very similar to reading from PostgreSQL or SQLite
    databases:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 由于Blaze旨在以非常熟悉的方式工作，无论数据源如何，从MongoDB读取与从PostgreSQL或SQLite数据库读取非常相似：
- en: '[PRE24]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Data operations
  id: totrans-145
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据操作
- en: We have already presented some of the most common methods you will use with
    DataShapes (for example, `.peek()`), and ways to filter the data based on the
    column value. Blaze has implemented many methods that make working with any data
    extremely easy.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经介绍了一些您将使用DataShapes（例如，`.peek()`）的最常见方法，以及根据列值过滤数据的方式。Blaze实现了许多使处理任何数据变得极其容易的方法。
- en: In this section, we will review a host of other commonly used ways of working
    with data and methods associated with them. For those of you coming from `pandas`
    and/or SQL, we will provide a respective syntax where equivalents exist.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将回顾许多其他常用的数据处理方式和与之相关的方法。对于来自`pandas`和/或SQL的您，我们将提供相应的语法，如果存在等效项。
- en: Accessing columns
  id: totrans-148
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 访问列
- en: 'There are two ways of accessing columns: you can get a single column at a time
    by accessing them as if they were a DataShape attribute:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 有两种访问列的方式：您可以一次获取一个列，就像访问DataShape属性一样：
- en: '[PRE25]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The preceding script produces the following output:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 上述脚本将产生以下输出：
- en: '![Accessing columns](img/B05793_09_10.jpg)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![访问列](img/B05793_09_10.jpg)'
- en: 'You can also use indexing that allows the selection of more than one column
    at a time:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以使用索引，允许一次选择多个列：
- en: '[PRE26]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'This generates the following output:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成以下输出：
- en: '![Accessing columns](img/B05793_09_11.jpg)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![访问列](img/B05793_09_11.jpg)'
- en: 'The preceding syntax would be the same for pandas DataFrames. For those of
    you unfamiliar with Python and pandas API, please note three things here:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 上述语法对于pandas DataFrames也是相同的。对于不熟悉Python和pandas API的您，请注意以下三点：
- en: 'To specify multiple columns, you need to enclose them in another list: note
    the double brackets `[[` and `]]`.'
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要指定多个列，您需要将它们放在另一个列表中：注意双括号`[[`和`]]`。
- en: 'If the chain of all methods does not fit on one line (or you want to break
    the chain for better readability) you have two choices: either enclose the whole
    chain of methods in brackets `(...)` where the `...` is the chain of all methods,
    or, before breaking into the new line, put the backslash character `\` at the
    end of every line in the chain. We prefer the latter and will use that in our
    examples from now on.'
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果所有方法的链不适合一行（或者您想为了更好的可读性而断开链），您有两个选择：要么将整个方法链用括号`(...)`括起来，其中`...`是所有方法的链，或者，在换行前，在每个方法链的行末放置反斜杠字符`\`。我们更喜欢后者，并将在我们的示例中继续使用它。
- en: 'Note that the equivalent SQL code would be:'
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 注意，等效的SQL代码将是：
- en: '[PRE27]'
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Symbolic transformations
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 符号变换
- en: The beauty of Blaze comes from the fact that it can operate *symbolically*.
    What this means is that you can specify transformations, filters, or other operations
    on your data and store them as object(s). You can then *feed* such object with
    almost any form of data conforming to the original schema, and Blaze will return
    the transformed data.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: Blaze的美丽之处在于它可以**符号化**地操作。这意味着您可以在数据上指定变换、过滤器或其他操作，并将它们作为对象存储。然后，您可以用几乎任何符合原始模式的数据形式**提供**这样的对象，Blaze将返回变换后的数据。
- en: 'For example, let''s select all the traffic violations that occurred in 2013,
    and return only the `''Arrest_Type''`, `''Color''`, and `` ''Charge` `` columns.
    First, if we could not reflect the schema from an already existing object, we
    would have to specify the schema manually. To do this, we will use the `.symbol(...)`
    method to achieve that; the first argument to the method specifies a symbolic
    name of the transformation (we prefer keeping it the same as the name of the object,
    but it can be anything), and the second argument is a long string that specifies
    the schema in a `<column_name>: <column_type>` fashion, separated by commas:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '例如，让我们选择所有发生在2013年的交通违规行为，并仅返回`''Arrest_Type''`、`''Color''`和`''Charge''`列。首先，如果我们不能从一个已存在的对象中反映模式，我们就必须手动指定模式。为此，我们将使用`.symbol(...)`方法来实现；该方法的第一参数指定了变换的符号名称（我们倾向于保持与对象名称相同，但可以是任何名称），第二个参数是一个长字符串，以`<column_name>:
    <column_type>`的形式指定模式，用逗号分隔：'
- en: '[PRE28]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Now, you could use the `schema_example` object and specify some transformations.
    However, since we already have an existing `traffic` dataset, we can *reuse* the
    schema by using `traffic.dshape` and specifying our transformations:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您可以使用`schema_example`对象并指定一些变换。然而，由于我们已经有了一个现有的`traffic`数据集，我们可以通过使用`traffic.dshape`并指定我们的变换来**重用**该模式：
- en: '[PRE29]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'To present how this works, let''s read the original dataset into pandas'' `DataFrame`:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示这是如何工作的，让我们将原始数据集读入pandas的`DataFrame`：
- en: '[PRE30]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Once read, we pass the dataset directly to the `traffic_2013` object and perform
    the computation using the `.compute(...)` method of Blaze; the first argument
    to the method specifies the transformation object (ours is `traffic_2013`) and
    the second parameter is the data that the transformations are to be performed
    on:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦读取，我们直接将数据集传递给`traffic_2013`对象，并使用Blaze的`.compute(...)`方法进行计算；该方法的第一参数指定了变换对象（我们的对象是`traffic_2013`），第二个参数是要对变换执行的数据：
- en: '[PRE31]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Here is the output of the preceding snippet:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是前一个代码片段的输出：
- en: '![Symbolic transformations](img/B05793_09_12.jpg)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![符号化变换](img/B05793_09_12.jpg)'
- en: 'You can also pass a list of lists or a list of NumPy arrays. Here, we use the
    `.values` attribute of the DataFrame to access the underlying list of NumPy arrays
    that form the DataFrame:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以传递一个列表的列表或一个NumPy数组的列表。在这里，我们使用DataFrame的`.values`属性来访问构成DataFrame的底层NumPy数组列表：
- en: '[PRE32]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'This code will produce precisely what we would expect:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码将产生我们预期的精确结果：
- en: '![Symbolic transformations](img/B05793_09_13.jpg)'
  id: totrans-177
  prefs: []
  type: TYPE_IMG
  zh: '![符号化变换](img/B05793_09_13.jpg)'
- en: Operations on columns
  id: totrans-178
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 列操作
- en: 'Blaze allows for easy mathematical operations to be done on numeric columns.
    All the traffic violations cited in the dataset occurred between 2013 and 2016\.
    You can check that by getting all the distinct values for the `Stop_year` column
    using the `.distinct()` method. The `.sort()` method sorts the results in an ascending
    order:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: Blaze允许对数值列进行简单的数学运算。数据集中引用的所有交通违规行为都发生在2013年至2016年之间。您可以通过使用`.distinct()`方法获取`Stop_year`列的所有不同值来检查这一点。`.sort()`方法按升序排序结果：
- en: '[PRE33]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The preceding code produces the following output table:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码生成了以下输出表：
- en: '![Operations on columns](img/B05793_09_14.jpg)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![列操作](img/B05793_09_14.jpg)'
- en: 'An equivalent syntax for pandas would be as follows:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 对于pandas，等效的语法如下：
- en: '[PRE34]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'For SQL, use the following code:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 对于SQL，请使用以下代码：
- en: '[PRE35]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'You can also make some mathematical transformations/arithmetic to the columns.
    Since all the traffic violations occurred after year `2000`, we can subtract `2000`
    from the `Stop_year` column without losing any accuracy:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以对列进行一些数学变换/算术运算。由于所有交通违规行为都发生在2000年之后，我们可以从`Stop_year`列中减去`2000`，而不会丢失任何精度：
- en: '[PRE36]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Here is what you should get in return:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 这是您应该得到的结果：
- en: '![Operations on columns](img/B05793_09_15.jpg)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![列操作](img/B05793_09_15.jpg)'
- en: 'The same could be attained from pandas `DataFrame` with an identical syntax
    (assuming `traffic` was of pandas `DataFrame` type). For SQL, the equivalent would
    be:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 使用pandas `DataFrame`可以通过相同的语法达到相同的效果（假设`traffic`是pandas `DataFrame`类型）。对于SQL，等效的代码如下：
- en: '[PRE37]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: However, if you want to do some more complex mathematical operations (for example,
    `log` or `pow`) then you first need to use the one provided by Blaze (that, in
    the background, will translate your command to a suitable method from NumPy, math,
    or pandas).
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果你想要进行一些更复杂的数学运算（例如，`log` 或 `pow`），那么你首先需要使用Blaze提供的（在后台，它将你的命令转换为NumPy、math或pandas的合适方法）。
- en: 'For example, if you wanted to log-transform the `Stop_year` you need to use
    this code:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果你想要对`Stop_year`进行对数转换，你需要使用以下代码：
- en: '[PRE38]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'This will produce the following output:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '![Operations on columns](img/B05793_09_16.jpg)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
  zh: '![列操作](img/B05793_09_16.jpg)'
- en: Reducing data
  id: totrans-198
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 减少数据
- en: 'Some reduction methods are also available, such as `.mean()` (that calculates
    the average), `.std` (that calculates standard deviation), or `.max()` (that returns
    the maximum from the list). Executing the following code:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 一些减少方法也是可用的，例如`.mean()`（计算平均值）、`.std`（计算标准差）或`.max()`（从列表中返回最大值）。执行以下代码：
- en: '[PRE39]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'It will return the following output:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 它将返回以下输出：
- en: '![Reducing data](img/B05793_09_17.jpg)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
  zh: '![减少数据](img/B05793_09_17.jpg)'
- en: 'If you had a pandas DataFrame you can use the same syntax, whereas for SQL
    the same could be done with the following code:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有一个pandas DataFrame，你可以使用相同的语法，而对于SQL，可以使用以下代码完成相同操作：
- en: '[PRE40]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: It is also quite easy to add more columns to your dataset. Say, you wanted to
    calculate the age of the car (in years) at the time when the violation occurred.
    First, you would take the `Stop_year` and subtract the `Year` of manufacture.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 向你的数据集中添加更多列也非常简单。比如说，你想要计算在违规发生时汽车的年龄（以年为单位）。首先，你会从`Stop_year`中减去制造年份的`Year`。
- en: In the following code snippet, the first argument to the `.transform(...)` method
    is the DataShape, the transformation is to be performed on, and the other(s) would
    be a list of transformations.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的代码片段中，`.transform(...)`方法的第一个参数是要执行转换的DataShape，其他参数会是转换列表。
- en: '[PRE41]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Note
  id: totrans-208
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: In the source code of the `.transform(...)` method such lists would be expressed
    as `*args` as you could specify more than one column to be created in one go.
    The `*args` argument to any method would take any number of subsequent arguments
    and treat it as if it was a list.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 在`.transform(...)`方法的源代码中，这样的列表会被表示为`*args`，因为你可以一次指定多个要创建的列。任何方法的`*args`参数可以接受任意数量的后续参数，并将其视为列表。
- en: 'The above code produces the following table:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码产生以下表格：
- en: '![Reducing data](img/B05793_09_18.jpg)'
  id: totrans-211
  prefs: []
  type: TYPE_IMG
  zh: '![减少数据](img/B05793_09_18.jpg)'
- en: 'An equivalent operation in pandas could be attained through the following code:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 在pandas中，可以通过以下代码实现等效操作：
- en: '[PRE42]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'For SQL you can use the following code:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 对于SQL，你可以使用以下代码：
- en: '[PRE43]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'If you wanted to calculate the average age of the car involved in a fatal traffic
    violation and count the number of occurrences, you can perform a `group by` operation
    using the `.by(...)` operation:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要计算涉及致命交通事故的汽车的平均年龄并计算发生次数，你可以使用`.by(...)`操作执行`group by`操作：
- en: '[PRE44]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: The first argument to `.by(...)` specifies the column of the DataShape to perform
    the aggregation by, followed by a series of aggregations we want to get. In this
    example, we select the `Age_of_car` column and calculate an average and count
    the number of rows per each value of the `'Fatal'` column.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '`.by(...)`的第一个参数指定了DataShape中要执行聚合的列，后面跟着一系列我们想要得到的聚合。在这个例子中，我们选择了`Age_of_car`列，并计算了每个`''Fatal''`列值的平均值和行数。'
- en: 'The preceding script produces the following aggregation:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的脚本生成了以下聚合结果：
- en: '![Reducing data](img/B05793_09_19.jpg)'
  id: totrans-220
  prefs: []
  type: TYPE_IMG
  zh: '![减少数据](img/B05793_09_19.jpg)'
- en: 'For pandas, an equivalent would be as follows:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 对于pandas，等效的代码如下：
- en: '[PRE45]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'For SQL, it would be as follows:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 对于SQL，代码如下：
- en: '[PRE46]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: Joins
  id: totrans-225
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 连接
- en: 'Joining two `DataShapes` is straightforward as well. To present how this is
    done, although the same result could be attained differently, we first select
    all the traffic violations by violation type (the `violation` object) and the
    traffic violations involving belts (the `belts` object):'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 连接两个`DataShapes`同样简单。为了展示如何进行这一操作，尽管可以通过不同的方式得到相同的结果，我们首先通过违规类型（`violation`对象）和涉及安全带的违规（`belts`对象）选择所有交通违规：
- en: '[PRE47]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: Now, we join the two objects on the six date and time columns.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将两个对象在六个日期和时间列上连接起来。
- en: Note
  id: totrans-229
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'The same effect could have been attained if we just simply selected the two
    columns: `Violation_type` and `Belts` in one go. However, this example is to show
    the mechanics of the `.join(...)` method, so bear with us.'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们只是简单地一次性选择了两个列：`Violation_type` 和 `Belts`，同样可以达到相同的效果。然而，这个例子是为了展示 `.join(...)`
    方法的机制，所以请耐心等待。
- en: 'The first argument to the `.join(...)` method is the first DataShape we want
    to join with, the second argument is the second DataShape, while the third argument
    can be either a single column or a list of columns to perform the join on:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: '`.join(...)` 方法的第一个参数是我们想要连接的第一个 DataShape，第二个参数是第二个 DataShape，而第三个参数可以是单个列或列的列表，用于执行连接操作：'
- en: '[PRE48]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Once we have the full dataset in place, let''s check how many traffic violations
    involved belts and what sort of punishment was issued to the driver:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了完整的数据集，让我们检查有多少交通违规涉及安全带，以及司机受到了什么样的惩罚：
- en: '[PRE49]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Here''s the output of the preceding script:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 这是前面脚本的输出：
- en: '![Joins](img/B05793_09_20.jpg)'
  id: totrans-236
  prefs: []
  type: TYPE_IMG
  zh: '![Joins](img/B05793_09_20.jpg)'
- en: 'The same could be achieved in pandas with the following code:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下代码在 pandas 中可以实现相同的效果：
- en: '[PRE50]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'With SQL, you would use the following snippet:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 SQL，您将使用以下片段：
- en: '[PRE51]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: Summary
  id: totrans-241
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概述
- en: The concepts presented in this chapter are just the beginning of the road to
    using Blaze. There are many other ways it can be used and data sources it can
    connect with. Treat this as a starting point to build your understanding of polyglot
    persistence.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中介绍的概念只是使用 Blaze 的道路起点。还有许多其他的使用方式和可以连接的数据源。将其视为构建你对多语言持久性的理解的基础。
- en: 'Note, however, that these days most of the concepts explained in this chapter
    can be attained natively within Spark, as you can use SQLAlchemy directly within
    Spark making it easy to work with a variety of data sources. The advantage of
    doing so, despite the initial investment of learning the API of SQLAlchemy, is
    that the data returned will be stored in a Spark DataFrame and you will have access
    to everything that PySpark has to offer. This, by no means, implies that you never
    should never use Blaze: the choice, as always, is yours.'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，请注意，如今本章中解释的大多数概念都可以在 Spark 中原生获得，因为您可以直接在 Spark 中使用 SQLAlchemy，这使得与各种数据源一起工作变得容易。尽管需要投入学习
    SQLAlchemy API 的初始成本，但这样做的好处是返回的数据将存储在 Spark DataFrame 中，您将能够访问 PySpark 提供的一切。这绝对不意味着您永远不应该使用
    Blaze：选择，一如既往，是您的。
- en: 'In the next chapter, you will learn about streaming and how to do it with Spark.
    Streaming has become an increasingly important topic these days, as, daily (true
    as of 2016), the world produces roughly 2.5 exabytes of data (source: [http://www.northeastern.edu/levelblog/2016/05/13/how-much-data-produced-every-day/](http://www.northeastern.edu/levelblog/2016/05/13/how-much-data-produced-every-day/))
    that need to be ingested, processed and made sense of.'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，您将学习关于流式处理以及如何使用 Spark 进行流式处理。流式处理在当今已经成为一个越来越重要的主题，因为，每天（截至 2016 年为真），世界大约产生约
    2.5 兆字节的数据（来源：[http://www.northeastern.edu/levelblog/2016/05/13/how-much-data-produced-every-day/](http://www.northeastern.edu/levelblog/2016/05/13/how-much-data-produced-every-day/))，这些数据需要被摄取、处理并赋予意义。
