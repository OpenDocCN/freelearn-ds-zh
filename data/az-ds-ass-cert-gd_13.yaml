- en: '[*Chapter 10*](B16777_10_Final_VK_ePub.xhtml#_idTextAnchor147): Understanding
    Model Results'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[*第10章*](B16777_10_Final_VK_ePub.xhtml#_idTextAnchor147)：理解模型结果'
- en: In this chapter, you will learn how to analyze the results of your machine learning
    models to interpret why the model made the inference it did. Understanding why
    the model predicted a value is the key to avoiding black box model deployments
    and to be able to understand the limitations your model may have. In this chapter,
    you will learn about the available interpretation features of Azure Machine Learning
    and visualize the model explanation results. You will also learn how to analyze
    potential model errors and detect cohorts where the model is performing poorly.
    Finally, you will explore tools that will help you assess your model's fairness
    and allow you to mitigate potential issues.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将学习如何分析机器学习模型的结果，以理解模型为何做出该推断。理解模型为何预测某个值是避免黑箱模型部署的关键，并且能够理解模型可能存在的局限性。在本章中，你将学习Azure机器学习的可用解释功能，并可视化模型解释结果。你还将学习如何分析潜在的模型错误，检测模型表现不佳的群体。最后，你将探索一些工具，帮助你评估模型的公平性，并让你能够缓解潜在问题。
- en: 'In this chapter, we''re going to cover the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Creating responsible machine learning models
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建负责任的机器学习模型
- en: Interpreting the predictions of the model
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释模型的预测
- en: Analyzing model errors
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析模型错误
- en: Detecting potential model fairness issues
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检测潜在的模型公平性问题
- en: Technical requirements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: You will need to have access to an Azure subscription. Within that subscription,
    you will need a `packt-azureml-rg`. You will need to have either a `Contributor`
    or `Owner` `packt-learning-mlw`. These resources should be available to you if
    you followed the instructions in [*Chapter 2*](B16777_02_Final_VK_ePub.xhtml#_idTextAnchor026),
    *Deploying Azure Machine Learning Workspace Resources*.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要拥有一个Azure订阅。在该订阅中，你需要有一个名为`packt-azureml-rg`的资源组。你还需要有`Contributor`或`Owner`权限的`packt-learning-mlw`。如果你按照[*第2章*](B16777_02_Final_VK_ePub.xhtml#_idTextAnchor026)
    *部署Azure机器学习工作区资源*中的指引操作，这些资源应该可以获得。
- en: You will also need to have a basic understanding of the **Python** language.
    The code snippets in this chapter target Python version 3.6 or later. You should
    also be familiar with working in the notebook experience within Azure Machine
    Learning Studio, something that was covered in the previous chapters.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 你还需要对**Python**语言有基本了解。本章中的代码片段针对Python 3.6或更高版本。你还应该熟悉在Azure机器学习工作室中的Notebook体验，这部分内容已在之前的章节中介绍。
- en: This chapter assumes you have created a compute cluster named `cpu-sm-cluster`,
    as described in the *Working with compute targets* section of [*Chapter 7*](B16777_07_Final_VK_ePub.xhtml#_idTextAnchor102),
    *The AzureML Python SDK*.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章假设你已经创建了一个名为`cpu-sm-cluster`的计算集群，如[*第7章*](B16777_07_Final_VK_ePub.xhtml#_idTextAnchor102)
    *使用AzureML Python SDK*中“与计算目标协作”部分所述。
- en: You can find all the notebooks and code snippets for this chapter in this book's
    repository at [http://bit.ly/dp100-ch10](http://bit.ly/dp100-ch10).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在本书的仓库中找到本章的所有Notebook和代码片段，链接为[http://bit.ly/dp100-ch10](http://bit.ly/dp100-ch10)。
- en: Creating responsible machine learning models
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建负责任的机器学习模型
- en: 'Machine learning allows you to create models that can influence decisions and
    shape the future. With great power comes great responsibility, and this is where
    AI governance becomes a necessity, something commonly referred to as responsible
    AI principles and practices. Azure Machine Learning offers tools to support the
    responsible creation of AI under the following three pillars:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习使你能够创建可以影响决策并塑造未来的模型。拥有强大的能力意味着肩负巨大的责任，这也是AI治理成为必需的原因，通常被称为负责任的AI原则与实践。Azure机器学习提供了支持负责任AI创建的工具，具体体现在以下三个支柱上：
- en: '**Understand**: Before publishing any machine learning model, you need to be
    able to interpret and explain the model''s behavior. Moreover, you need to assess
    and mitigate potential model unfairness against specific cohorts. This chapter
    focuses on the tools that assist you in understanding your models.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**理解**：在发布任何机器学习模型之前，你需要能够解释和说明模型的行为。此外，你还需要评估并缓解针对特定群体的潜在模型不公平性。本章重点介绍那些帮助你理解模型的工具。'
- en: '**Protect**: Here, you put mechanisms in place to protect people and their
    data. When training a model, data from real people is used. For example, in [*Chapter
    8*](B16777_08_Final_VK_ePub.xhtml#_idTextAnchor117), *Experimenting with Python
    Code*, you trained a model on top of medical data from diabetic patients. Although
    the specific training dataset didn''t have any **Personally Identifiable Information**
    (**PII**), the original dataset contained this sensitive information. There are
    open source libraries such as **SmartNoise** that offer basic building blocks
    that can be used to implement data handling mechanisms using vetted and mature
    differential privacy research techniques.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**保护**：在这里，你部署了保护个人及其数据的机制。在训练模型时，使用的是来自真实人的数据。例如，在[*第8章*](B16777_08_Final_VK_ePub.xhtml#_idTextAnchor117)《实验Python代码》中，你在糖尿病患者的医疗数据上训练了一个模型。尽管具体的训练数据集没有包含任何**个人可识别信息**（**PII**），原始数据集却包含了这些敏感信息。有一些开源库，如**SmartNoise**，提供了基本的构建模块，能够利用经过验证和成熟的差分隐私研究技术来实现数据处理机制。'
- en: 'For example, a querying engine built with SmartNoise could allow data scientists
    to perform aggregate queries on top of sensitive data and add statistical *noise*
    in the results to prevent accidental identification of a single row within the
    dataset. Other open source libraries, such as **presidio**, offer a different
    approach to data protection, allowing you to quickly identify and anonymize private
    information such as credit card numbers, names, locations, financial data, and
    more. These libraries are more focused on raw text inputs, inputs you generally
    use when building **Natural Language Processing** (**NLP**) models. They offer
    modules you can use to anonymize your data before using them to train a model.
    Another approach to protecting people and their data is to encrypt the data and
    perform the entire model training process using the encrypted dataset without
    decrypting it. This is feasible through **Homomorphic Encryption** (**HE**), which
    is an encryption technique that allows certain mathematical operations to be performed
    on top of the encrypted data without requiring access to the private (decryption)
    key. The results of the computations are encrypted and can only be revealed by
    the owner of the private key. This means that using **HE**, you can add two encrypted
    values, **A** and **B**, and get the value **C**, which can only be decrypted
    by the private key that encrypted values **A** and **B**, as shown in the following
    diagram:'
  id: totrans-16
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 例如，使用SmartNoise构建的查询引擎可以让数据科学家在敏感数据上执行聚合查询，并在结果中添加统计*噪声*，以防止意外识别数据集中某一行的单个数据。其他开源库，如**presidio**，提供了一种不同的数据保护方法，允许你快速识别并匿名化私密信息，如信用卡号、姓名、地点、财务数据等。这些库更多地关注原始文本输入，这是你在构建**自然语言处理**（**NLP**）模型时通常使用的输入。它们提供了可以用来匿名化数据的模块，便于在训练模型之前处理数据。另一种保护个人及其数据的方法是加密数据，并使用加密数据集进行整个模型训练过程，而无需解密。这可以通过**同态加密**（**HE**）实现，这是一种加密技术，允许在加密数据上执行某些数学操作，而无需访问私有（解密）密钥。计算结果是加密的，只有私钥的持有者才能揭示。这意味着，使用**HE**，你可以将两个加密值**A**和**B**相加，得到一个值**C**，这个值只能通过加密值**A**和**B**的私钥解密，如下图所示：
- en: '![Figure 10.1 – Using HE to perform operations on top of encrypted data'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '![图10.1 – 使用HE在加密数据上执行操作'
- en: '](img/B16777_10_001.jpg)'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_10_001.jpg)'
- en: Figure 10.1 – Using HE to perform operations on top of encrypted data
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.1 – 使用HE在加密数据上执行操作
- en: '**Control**: Controlling and documenting the end-to-end process is an essential
    principle in all software engineering activities. DevOps practices are commonly
    used to ensure end-to-end process automation and governance. One of the key practices
    in DevOps is to document the right information in each step of the process, allowing
    you to make responsible decisions at each stage. An Azure Machine Learning workspace
    allows you to tag and add descriptions to the various artifacts you create in
    your end-to-end machine learning process. The following diagram shows how you
    can add a description to the **AutoML** run you performed in [*Chapter 9*](B16777_09_Final_VK_ePub.xhtml#_idTextAnchor136),
    *Optimizing the ML Model*:'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**控制**：控制和记录端到端过程是所有软件工程活动中的一个基本原则。DevOps 实践通常用于确保端到端过程的自动化和治理。DevOps 中的一个关键实践是记录每个步骤中的关键信息，让你在每个阶段做出负责任的决策。Azure
    机器学习工作区允许你为你在端到端机器学习过程中的各种工件添加标签和描述。下图展示了你如何为在 [*第9章*](B16777_09_Final_VK_ePub.xhtml#_idTextAnchor136)
    中执行的 **AutoML** 运行添加描述，*优化机器学习模型*：'
- en: '![Figure 10.2 – Adding descriptions to runs to document them'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.2 – 为运行添加描述以进行文档记录'
- en: '](img/B16777_10_002.jpg)'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_10_002.jpg)'
- en: Figure 10.2 – Adding descriptions to runs to document them
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.2 – 为运行添加描述以进行文档记录
- en: 'Similar to adding descriptions to runs, you can add tags to the various artifacts
    you produce, such as the models. Tags are key/value pairs, such as `PyTorch` being
    the value of the `Framework` tag key. You might want to document the following
    information as part of a model **datasheet**:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于为运行添加描述，你可以为你生产的各种工件（如模型）添加标签。标签是键/值对，例如 `PyTorch` 是 `Framework` 标签键的值。你可能希望将以下信息作为模型
    **数据表** 的一部分进行记录：
- en: The intended use of the model
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型的预期用途
- en: The model architecture, including the framework used
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型架构，包括使用的框架
- en: Training and evaluation data used
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用的训练和评估数据
- en: Trained model performance metrics
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练模型性能指标
- en: Fairness information, which you will read about in this chapter
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 公平性信息，你将在本章中阅读到
- en: This information can be part of tags, and the **datasheet** can be a Markdown
    document that's automatically generated through these tags.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这些信息可以作为标签的一部分，而 **数据表** 可以是一个通过这些标签自动生成的 Markdown 文档。
- en: In this section, you got an overview of the tools and the technologies that
    can help you create responsible AI. All three pillars are equally important, but
    for the DP100 exam, you will focus on the tools in the understand category, starting
    with model interpretability, which you will learn more about in the next section.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 本节中，你对帮助创建负责任 AI 的工具和技术进行了概述。所有三个支柱同等重要，但对于 DP100 考试，你将专注于理解类别中的工具，从模型可解释性开始，你将在下一节中深入了解。
- en: Interpreting the predictions of the model
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解释模型的预测结果
- en: Being able to interpret the predictions of a model helps data scientists, auditors,
    and business leaders understand model behavior by looking at the top important
    factors that drive the model's predictions. It also enables them to perform what-if
    analysis to validate the impact of features on predictions. The Azure Machine
    Learning workspace integrates with **InterpretML** to provide these capabilities.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 能够解释模型的预测结果有助于数据科学家、审计员和商业领袖通过查看驱动模型预测的主要因素来理解模型行为。它还使他们能够进行假设分析，以验证特征对预测的影响。Azure
    机器学习工作区与 **InterpretML** 集成，提供这些功能。
- en: 'InterpretML is an open source community that provides tools to perform model
    interpretability. The community contains a couple of projects. The most famous
    ones are as follows:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: InterpretML 是一个开源社区，提供用于执行模型可解释性的工具。社区包含几个项目，其中最著名的如下：
- en: '**Interpret** and **Interpret-Community** repositories, which focus on interpreting
    models that use tabular data, such as the diabetes dataset you have been working
    on within this book. You are going to work with the interpret-community repository
    in this section.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Interpret** 和 **Interpret-Community** 仓库，专注于解释使用表格数据的模型，例如你在本书中所使用的糖尿病数据集。你将在本节中使用
    interpret-community 仓库。'
- en: '**interpret-text** extends the interpretability efforts into text classification
    models.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**interpret-text** 扩展了解释工作到文本分类模型。'
- en: '**Diverse Counterfactual Explanations** (**DiCE**) for machine learning allows
    you to detect the minimum number of changes that you need to perform in a data
    row to change the model''s output. For example, suppose you have a loan approval
    model that just rejected a loan application. The customer asks what can be done
    to get the loan approved. **DiCE** could provide the minimum changes to approve
    the loan, such as reducing the number of credit cards or increasing the annual
    salary by 1%.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多样化反事实解释**（**DiCE**）用于机器学习，可以帮助你检测在数据行中需要进行的最少修改，以改变模型的输出。例如，假设你有一个贷款审批模型，它刚刚拒绝了一笔贷款申请。客户问有什么可以做的来让贷款获得批准。**DiCE**可以提供批准贷款的最少修改，例如减少信用卡数量或将年薪提高1%。'
- en: 'There are two approaches when it comes to interpreting machine learning models:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 解释机器学习模型时有两种方法：
- en: '`DecisionTreeClassifier` offers the `feature_importances_` attribute, which
    allows you to understand how features affect the model''s predictions. The **InterpretML**
    community provides a couple more advanced **glassbox** model implementations.
    These models, once trained, allow you to retrieve an explainer and review which
    feature is driving what result, also known as **interpretability results**. Explainers
    for these models are lossless, meaning that they explain the importance of each
    feature accurately.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`DecisionTreeClassifier` 提供了 `feature_importances_` 属性，允许你理解特征如何影响模型的预测。**InterpretML**
    社区提供了几种更先进的**玻璃盒**模型实现。这些模型一旦训练完成，允许你获取解释器并查看哪些特征驱动了什么结果，这也被称为**可解释性结果**。这些模型的解释器是无损的，意味着它们准确地解释了每个特征的重要性。'
- en: '**Black box explanations**: If the model you are training doesn''t come with
    a native explainer, you can create a black box explainer to interpret the model''s
    results. You must provide the trained model and a test dataset, and the explainer
    observes how the value permutations affect the model''s predictions. For example,
    in the loan approval model, this may tweak the age and the income of a rejected
    record to observe whetherthat changes the prediction. The information that''s
    gained by performing these experiments is used to produce interpretations of the
    feature''s importance. This technique can be applied to any machine learning model,
    so it is considered model agnostic. Due to their nature, these explainers are
    lossy, meaning that they may not accurately represent each feature''s importance.
    There are a couple of well-known black-box techniques in the scientific literature,
    such as **Shapley Additive Explanations** (**SHAP**), **Local Interpretable Model-Agnostic
    Explanations** (**LIME**), **Partial Dependence** (**PD**), **Permutation Feature
    Importance** (**PFI**), **feature interaction**, and **Morris sensitivity analysis**.
    A subcategory of the black box explainers is the **gray box explainers**, which
    utilize information regarding the model''s structure to get better and faster
    explanations. For example, there are specialized explainers for tree models (**tree
    explainer**), linear models (**linear explainer**), and even deep neural networks
    (**deep explainer**).'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**黑盒解释**：如果你训练的模型没有内置的解释器，你可以创建一个黑盒解释器来解释模型的结果。你需要提供训练好的模型和一个测试数据集，解释器会观察特征值的变化如何影响模型的预测。例如，在贷款审批模型中，这可能会调整一个被拒绝记录的年龄和收入，观察这些变化是否会改变预测结果。通过这些实验获取的信息可以用来生成特征重要性的解释。这项技术可以应用于任何机器学习模型，因此被认为是与模型无关的。由于它们的性质，这些解释器是有损的，意味着它们可能无法准确表示每个特征的重要性。在科学文献中，有一些著名的黑盒技术，例如**Shapley加法解释**（**SHAP**）、**局部可解释模型无关解释**（**LIME**）、**部分依赖**（**PD**）、**置换特征重要性**（**PFI**）、**特征交互**和**莫里斯敏感性分析**。黑盒解释器的一个子类别是**灰盒解释器**，它利用模型结构的相关信息来获得更好、更快的解释。例如，有专门针对树模型（**树解释器**）、线性模型（**线性解释器**）甚至深度神经网络（**深度解释器**）的解释器。'
- en: 'Model explainers can provide two types of explanations:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 模型解释器可以提供两种类型的解释：
- en: '**Local-** or **instance-level feature importance** focuses on the contribution
    of features for a specific prediction. For example, it can assist in answering
    why the model denied a particular customer''s loan. Not all techniques support
    local explanations. For instance, **PFI**-based ones do not support instance-level
    feature importance.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**局部**或**实例级特征重要性**侧重于特征对特定预测的贡献。例如，它可以帮助回答为什么模型拒绝了某个特定客户的贷款申请。并非所有技术都支持局部解释。例如，基于**PFI**的方法不支持实例级特征重要性。'
- en: '**Global-** or **aggregate-level feature importance** explains how the model
    performs overall, considering all predictions done by the model. For example,
    it can answer which feature is the most important one regarding loan approval.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**全局** 或 **聚合级特征重要性** 解释了模型整体的表现，考虑到模型所做的所有预测。例如，它可以回答哪个特征对于贷款批准来说最为重要。'
- en: Now that you have the basic theory behind model interpretation, it is time for
    you to get some hands-on experience. You will start by training a simple **sklearn**
    model.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你已经了解了模型解释的基本理论，是时候获得一些实践经验了。你将从训练一个简单的 **sklearn** 模型开始。
- en: Training a loans approval model
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练贷款批准模型
- en: 'In this section, you will train a classification model against a loans approval
    dataset that you will generate. You will use this model in the upcoming sections
    to analyze its results. Let''s get started:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将对一个你将生成的贷款批准数据集训练一个分类模型。你将在接下来的章节中使用该模型分析其结果。让我们开始吧：
- en: Navigate to the `chapter10` and then create a notebook called `chapter10.ipynb`,
    as shown here:![Figure 10.3 – Creating the chapter10 notebook in the chapter10
    folder
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到 `chapter10`，然后创建一个名为 `chapter10.ipynb` 的笔记本，如下所示：![图 10.3 – 在 chapter10
    文件夹中创建 chapter10 笔记本
- en: '](img/B16777_10_003.jpg)'
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16777_10_003.jpg)'
- en: Figure 10.3 – Creating the chapter10 notebook in the chapter10 folder
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 10.3 – 在 chapter10 文件夹中创建 chapter10 笔记本
- en: You will need to install the latest packages of the `interpret-community` library,
    Microsoft's responsible AI widgets, and `#` or delete the cell:![Figure 10.4 –
    Restarting the Jupyter kernel after installing the necessary packages
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你需要安装 `interpret-community` 库的最新包、微软的负责任 AI 小部件，以及 `#` 或删除该单元格：![图 10.4 – 在安装必要的包后重新启动
    Jupyter 内核
- en: '](img/B16777_10_004.jpg)'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16777_10_004.jpg)'
- en: Figure 10.4 – Restarting the Jupyter kernel after installing the necessary packages
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 10.4 – 在安装必要的包后重新启动 Jupyter 内核
- en: 'After restarting you kernel, add a new cell in the notebook. Generate a loans
    dataset using the following code:'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在重新启动内核后，在笔记本中添加一个新单元格。使用以下代码生成一个贷款数据集：
- en: '[PRE0]'
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This code will generate a dataset with the following normally distributed features:'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这段代码将生成一个包含以下正态分布特征的数据集：
- en: '`income` with a minimum value of `0` and a maximum value of `10000`.'
  id: totrans-56
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`income` 的最小值为 `0`，最大值为 `10000`。'
- en: '`credit_cards` with a minimum value of `0` and a maximum value of `10`.'
  id: totrans-57
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`credit_cards` 的最小值为 `0`，最大值为 `10`。'
- en: '`age` with a minimum value of `18` and a maximum value of `85`.'
  id: totrans-58
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`age` 的最小值为 `18`，最大值为 `85`。'
- en: The label you will be predicting is `approved_loan`, which is a Boolean, and
    only 30% (`weights`) of the 500 samples (`n_samples`) are approved loans.
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你将预测的标签是 `approved_loan`，这是一个布尔值，且在 500 个样本（`n_samples`）中，只有 30%（`weights`）是批准的贷款。
- en: 'Later in this chapter, you are going to run an **AutoML** experiment against
    this dataset. Register the dataset, as you saw in [*Chapter 7*](B16777_07_Final_VK_ePub.xhtml#_idTextAnchor102),
    *The AzureML Python SDK*. Add the following code in your notebook:'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在本章后面，你将针对这个数据集运行一个 **AutoML** 实验。注册数据集，正如你在 [*第 7 章*](B16777_07_Final_VK_ePub.xhtml#_idTextAnchor102)
    中看到的，*AzureML Python SDK*。在你的笔记本中添加以下代码：
- en: '[PRE1]'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'If you visit the registered dataset, you can view the profile of the dataset,
    as shown here:'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果你访问注册的数据集，可以查看数据集的简介，如下所示：
- en: '![Figure 10.5 – Generated dataset profile'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 10.5 – 生成的数据集简介'
- en: '](img/B16777_10_005.jpg)'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16777_10_005.jpg)'
- en: Figure 10.5 – Generated dataset profile
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 10.5 – 生成的数据集简介
- en: 'To be able to train and evaluate the model, you will need to split the dataset
    into train and test datasets. Use the following code to do so:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了能够训练和评估模型，你需要将数据集分割成训练集和测试集。使用以下代码来完成此操作：
- en: '[PRE2]'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: First, you split the dataset into two, one with the features and one with the
    label you are trying to predict. Then, you use the `train_test_split` method to
    split the 500-sample data into one that contains 500 * 0.2 = 100 test records
    and the train set, which contains the remaining 400 samples.
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 首先，将数据集分成两部分，一部分包含特征，另一部分包含你要预测的标签。然后，使用 `train_test_split` 方法将 500 个样本的数据分割成包含
    500 * 0.2 = 100 个测试记录的数据集，以及包含剩余 400 个样本的训练集。
- en: The next step is to initialize the model and fit it against the training dataset.
    In [*Chapter 9*](B16777_09_Final_VK_ePub.xhtml#_idTextAnchor136), *Optimizing
    the ML Model*, you learned how Azure Machine Learning's `datatransformer` step
    is a `ColumnTransformer` that applies `MinMaxScaler` to all features. This transformer
    scales each feature's values.
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是初始化模型，并将其拟合到训练数据集。在[*第9章*](B16777_09_Final_VK_ePub.xhtml#_idTextAnchor136)《优化ML模型》中，你学习了Azure机器学习的`datatransformer`步骤是一个`ColumnTransformer`，它对所有特征应用`MinMaxScaler`。这个转换器会缩放每个特征的值。
- en: The `model` step is the actual model you are training, which is a `RandomForestClassifier`.
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`model`步骤是你正在训练的实际模型，即`RandomForestClassifier`。'
- en: Then, you must call the `fit` method of the instantiated pipeline to train it
    against the training dataset.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，你必须调用已实例化的管道的`fit`方法，将其训练与训练数据集对齐。
- en: Important note
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: You do not need to use `Pipeline` to benefit from the interpretability features
    discussed in this chapter. Instead of creating a pipeline, you could have used
    the model directly by assigning it to the `model_pipeline` variable; for example,
    `model_pipeline=RandomForestClassifier()`. The addition of the `datatransformer`
    step was done to help you understand how AutoML constructs its pipelines. Using
    `MinMaxScaler` also increases the accuracy of the resulting model. Feel free to
    try different scalers to observe the differences in the resulting model.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 你不需要使用`Pipeline`来受益于本章讨论的可解释性特性。你可以直接通过将模型赋值给`model_pipeline`变量来使用该模型，例如`model_pipeline=RandomForestClassifier()`。添加`datatransformer`步骤是为了帮助你理解AutoML是如何构建管道的。使用`MinMaxScaler`还提高了结果模型的准确性。你可以随意尝试不同的缩放器，以观察结果模型的差异。
- en: 'Now that you have a trained model, you can test it. Let''s test against three
    fictional customers:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在你已经有了一个训练好的模型，可以进行测试。让我们测试三个虚构的客户：
- en: A 45-year-old who has two credit cards and a monthly income of `2000`
  id: totrans-75
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一位45岁、有两张信用卡、月收入为`2000`的人。
- en: A 45-year-old who has nine credit cards and a monthly income of `2000`
  id: totrans-76
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一位45岁、有九张信用卡、月收入为`2000`的人。
- en: A 45-year-old who has two credit cards and a monthly income of `10000`
  id: totrans-77
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一位45岁、有两张信用卡、月收入为`10000`的人。
- en: 'To do that, use the following code in a new notebook cell:'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要做到这一点，请在新的笔记本单元格中使用以下代码：
- en: '[PRE3]'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The printed result is `[0 1 1]`, which means that the first customer's loan
    will be rejected while the second and the third ones will be approved. This indicates
    that the `income` and `credit_cards` features may play an important role in the
    prediction of the model.
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 打印结果是`[0 1 1]`，这意味着第一个客户的贷款将被拒绝，而第二个和第三个客户的贷款将被批准。这表明`income`和`credit_cards`特征可能在模型预测中起着重要作用。
- en: 'Since the trained model is a decision tree and belongs to the glassbox model
    category, you can get the importance of the features that were calculated during
    the training process. Use the following code in a new notebook cell:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于训练后的模型是一个决策树，属于玻璃盒模型类别，你可以获取在训练过程中计算出的特征重要性。使用以下代码在新的笔记本单元格中：
- en: '[PRE4]'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This code gets a reference to the actual `RandomForestClassifier` instance and
    invokes a `feature_importances_`. The output of this is something like `array([0.66935129,
    0.11090936, 0.21973935])`, which shows that `income` (the first value) is the
    most important feature, but it seems that `age` (the third value) is more important
    than `credit_cards` (the second value) in contrast to the observations we made
    in *Step 7*.
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这段代码获取实际的`RandomForestClassifier`实例，并调用`feature_importances_`。其输出类似于`array([0.66935129,
    0.11090936, 0.21973935])`，这显示`income`（第一个值）是最重要的特征，但与我们在*步骤7*中观察到的情况相比，`age`（第三个值）似乎比`credit_cards`（第二个值）更为重要。
- en: Important note
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 重要提示
- en: The model's training process is not deterministic, meaning that your results
    will be different from the results seen in this book's examples. The numbers should
    be similar but not the same.
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型的训练过程是非确定性的，这意味着你的结果与书中示例中的结果会有所不同。数值应该相似，但不完全相同。
- en: In this section, you trained a simple `feature_importances_` attribute. In the
    next section, you will use a more advanced technique that allows you to explain
    any model.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你训练了一个简单的`feature_importances_`属性。在下一节中，你将使用一种更高级的技术，允许你解释任何模型。
- en: Using the tabular explainer
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用表格解释器
- en: 'So far, you have used the capabilities of the **sklearn** library to train
    and understand the results of the model. From this point on, you will use the
    interpret community''s package to interpret your trained model more accurately.
    You will use **SHAP**, a black box technique that tells you which features play
    what role in moving a prediction from **Rejected** to **Approved** and vice versa.
    Let''s get started:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你已经使用**sklearn**库的功能来训练并理解模型的结果。从现在开始，你将使用解释社区的包来更准确地解释你训练好的模型。你将使用**SHAP**，这是一种黑箱技术，可以告诉你哪些特征在将预测从**拒绝**转为**批准**（或反之）的过程中发挥了什么作用。让我们开始吧：
- en: 'In a new notebook cell, add the following code:'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在一个新的笔记本单元格中，添加以下代码：
- en: '[PRE5]'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: This code creates a `TabularExplainer`, which is a wrapper class around the
    SHAP interpretation techniques. This means that this object will select the best
    SHAP interpretation method, depending on the passed-in model. In this case, since
    the model is a tree-based one, it will choose the **tree explainer**.
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这段代码创建了一个`TabularExplainer`，它是SHAP解释技术的一个封装类。这意味着该对象会根据传入的模型选择最合适的SHAP解释方法。在这种情况下，由于模型是基于树的，它将选择**树解释器**（tree
    explainer）。
- en: 'Using this explainer, you are going to get the **local** or **instance-level
    feature importance** to gain more insights into why the model gave the results
    it did in *Step 7* of the *Training a loans approval model* section. In a new
    notebook cell, add the following code:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用这个解释器，你将获得**局部**或**实例级别的特征重要性**，以便更深入地理解模型在*训练贷款批准模型*部分的*步骤7*中为什么会给出这样的结果。在一个新的笔记本单元格中，添加以下代码：
- en: '[PRE6]'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'This code produces the results shown in the following screenshot. If you focus
    on **Test sample number 2**, you will notice that it shows that the **credit_cards**
    feature was the most important reason (see the **0.33** value) for the specific
    sample to be predicted as **Approved** (**The prediction was 1**). The negative
    values for **income** (whose value is approximately **-0.12**) in the same sample
    indicate that this feature was pushing the model to **reject** the loan:'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这段代码生成了以下截图所示的结果。如果你关注**测试样本 2**，你会注意到它显示**信用卡数**（**credit_cards**）是该特定样本被预测为**批准**（**预测值为1**）的最重要原因（见**0.33**的值）。同样样本中**收入**（其值大约为**-0.12**）的负值表明该特征推动模型**拒绝**贷款：
- en: '![Figure 10.6 – Local importance features show the importance of each feature
    for each test sample'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 10.6 – 局部重要性特征展示了每个特征对每个测试样本的重要性'
- en: '](img/B16777_10_006.jpg)'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16777_10_006.jpg)'
- en: Figure 10.6 – Local importance features show the importance of each feature
    for each test sample
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 10.6 – 局部重要性特征展示了每个特征对每个测试样本的重要性
- en: 'You can also get the `income`, `age`, and then `credit_cards`, whose corresponding
    importance values are approximately `0.28`, `0.09`, and `0.06`, respectively (the
    actual values may differ in your execution). Note that these values are not the
    same as the ones you got in *Step 8* of the *Training a loans approval model*
    section, although the order remains the same. This is normal since `Method used:
    shap.tree`, which indicates that `TabularExplainer` interpreted the model using
    the **tree explainer**, as mentioned in *Step 1* of this section.'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你还可以看到`收入`（`income`）、`年龄`（`age`）以及`信用卡数`（`credit_cards`），它们对应的重要性值分别约为`0.28`、`0.09`和`0.06`（实际值可能与你的执行结果有所不同）。请注意，这些值与*训练贷款批准模型*部分的*步骤8*中获得的值不同，尽管顺序保持一致。这是正常现象，因为`使用方法：shap.tree`，这表明`TabularExplainer`使用**树解释器**对模型进行了解释，如本节*步骤1*所提到的。
- en: 'Finally, you must render the explanation dashboard to review the `global_explanation`
    results you generated in *Step 3*. Add the following code in your notebook:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，你必须渲染解释仪表板，以查看你在*步骤3*中生成的`global_explanation`结果。在笔记本中添加以下代码：
- en: '[PRE7]'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'This will render an interactive widget that you can use to understand your
    model''s predictions against the test dataset that you provided. Clicking on the
    **Aggregate feature importance** tab, you should see the same results you saw
    in *Step 3*:'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将渲染一个交互式小部件，你可以用它来理解模型对你提供的测试数据集的预测。点击**特征重要性汇总**（**Aggregate feature importance**）标签，你应该会看到在*步骤3*中看到的相同结果：
- en: '![Figure 10.7 – The explanation dashboard provided by the interpret community'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.7 – 解释社区提供的解释仪表板'
- en: '](img/B16777_10_007.jpg)'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_10_007.jpg)'
- en: Figure 10.7 – The explanation dashboard provided by the interpret community
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.7 – 解释社区提供的解释仪表板
- en: You will explore this dashboard in more detail in the *Reviewing the interpretation
    results* section.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 你将在*查看解释结果*部分更详细地探索这个仪表板。
- en: So far, you have trained a model and used the **SHAP** interpretation technique
    to explain the feature importance of your model's predictions, either at a global
    or local level for specific inferences. In the next section, you will learn more
    about the alternative interpretation techniques available in the Interpret-Community
    package.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你已经训练了一个模型，并使用 **SHAP** 解释技术解释了模型预测的特征重要性，无论是在全局还是局部层面上进行特定推理。接下来的部分，你将了解
    Interpret-Community 包中可用的其他解释技术。
- en: Understanding the tabular data interpretation techniques
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解表格数据的解释技术
- en: 'In the previous section, you used the tabular explainer to automatically select
    one of the available **SHAP** techniques. Currently, the interpret community supports
    the following SHAP explainers:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，你使用了表格解释器自动选择了一个可用的 **SHAP** 技术。目前，解释社区支持以下 **SHAP** 解释器：
- en: '**Tree explainer** is used to explain decision tree models.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Tree explainer** 用于解释决策树模型。'
- en: '**Linear explainer** explains linear models and can also explain inter-feature
    correlations.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Linear explainer** 解释线性模型，并且也可以解释特征间的相关性。'
- en: '**Deep explainer** provides approximate explanations for deep learning models.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Deep explainer** 为深度学习模型提供近似解释。'
- en: '**Kernel explainer** is the most generic and the slowest one. It can explain
    any function''s output, making it suitable for any model.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Kernel explainer** 是最通用且最慢的解释器。它可以解释任何函数的输出，使其适用于任何模型。'
- en: 'An alternative to the **SHAP** interpretation techniques is to build an easier-to-explain
    surrogate model, such as the **glassbox** models that the interpret community
    offers, to reproduce the output of the given black box and then explain that surrogate.
    This technique is used by the **Mimic** explainer, and you need to provide one
    of the following glass box models:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '**SHAP** 解释技术的替代方法是构建一个更容易解释的代理模型，例如解释社区提供的**玻璃盒子**模型，来重现给定黑盒的输出，并解释该代理模型。这个技术被**Mimic**
    解释器使用，你需要提供以下的一个玻璃盒子模型：'
- en: '**LGBMExplainableModel**, which is a **LightGBM** (a fast, high-performance
    framework based on decision trees) explainable model'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**LGBMExplainableModel**，这是一个 **LightGBM**（一个基于决策树的快速高效框架）可解释模型'
- en: '**LinearExplainableModel**, which is a linear explainable model'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**LinearExplainableModel**，这是一个线性可解释模型'
- en: '**SGDExplainableModel**, which is a stochastic gradient descent explainable
    model'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**SGDExplainableModel**，这是一个随机梯度下降可解释模型'
- en: '**DecisionTreeExplainableModel**, which is a decision tree explainable model'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**DecisionTreeExplainableModel**，这是一个决策树可解释模型'
- en: 'If you wanted to use Mimic explainer in *Step 1* of the previous section, the
    code for this would look like this:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想在上一节的*步骤 1* 中使用 Mimic 解释器，代码会像这样：
- en: '[PRE8]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'You can select any surrogate model from the `import` statement you can see
    in *line 1*. In this sample, you are using the `DecisionTreeExplainableModel`
    one. To get the global explanations, the code is the same as the code you wrote
    in *Step 3* and looks like this:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从*第 1 行*中的 `import` 语句中选择任何代理模型。在这个示例中，你使用的是 `DecisionTreeExplainableModel`。要获取全局解释，代码与在*步骤
    3* 中编写的代码相同，像这样：
- en: '[PRE9]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Although the order of the feature importance is the same, the calculated feature
    importance values are different, as shown here:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管特征重要性的顺序相同，但计算出来的特征重要性值是不同的，如下所示：
- en: '![Figure 10.8 – Mimic explainer feature importance calculated using the decision
    tree glassbox model'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.8 – 使用决策树玻璃盒子模型计算的 Mimic 解释器特征重要性'
- en: '](img/B16777_10_008.jpg)'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_10_008.jpg)'
- en: Figure 10.8 – Mimic explainer feature importance calculated using the decision
    tree glassbox model
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.8 – 使用决策树玻璃盒子模型计算的 Mimic 解释器特征重要性
- en: 'Similar to the `mimic_explainer` to calculate **local** or **instance-level
    feature importance** using the same code as in *Step 2* in the previous section.
    The explanations can be seen in the following screenshot:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于 `mimic_explainer` 使用相同的代码来计算**局部**或**实例级别的特征重要性**，就像在上一节的*步骤 2* 中所做的那样。解释可以在以下屏幕截图中看到：
- en: '![Figure 10.9 – Local feature importance calculated using the decision'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.9 – 使用决策树玻璃盒子模型计算的局部特征重要性'
- en: tree glassbox model of the Mimic explainer
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: Mimic 解释器的决策树玻璃盒子模型
- en: '](img/B16777_10_009.jpg)'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_10_009.jpg)'
- en: Figure 10.9 – Local feature importance calculated using the decision tree glassbox
    model of the Mimic explainer
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.9 – 使用 Mimic 解释器的决策树玻璃盒子模型计算的局部特征重要性
- en: 'The last interpretation technique offered by the interpret community is the
    one based on **PFI**. This technique permutates the values of each feature and
    observes how the model''s predictions change. To create a PFI explainer to interpret
    your model, you will need the following code:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: Interpret-Community 提供的最后一个解释技术是基于**PFI**的技术。该技术会通过改变每个特征的值，观察模型预测的变化。要创建一个
    PFI 解释器来解释你的模型，你需要以下代码：
- en: '[PRE10]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Getting the global explanations requires passing in the `true_labels` parameter,
    which is the ground truth for the dataset, which are the actual values:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 获取全局解释需要传入`true_labels`参数，这是数据集的真实标签，即实际值：
- en: '[PRE11]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The result of this code can be seen here. Due to the way `credit_cards` and
    `age` features may be the other way around in your results, since they have very
    similar feature importance values:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码的结果可以在此处查看。由于`credit_cards`和`age`特征的重要性值非常相似，结果中它们的顺序可能会互换：
- en: '![Figure 10.10 – Global feature importance calculated by the PFI explainer'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.10 – 通过 PFI 解释器计算的全局特征重要性'
- en: '](img/B16777_10_010.jpg)'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_10_010.jpg)'
- en: Figure 10.10 – Global feature importance calculated by the PFI explainer
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.10 – 通过 PFI 解释器计算的全局特征重要性
- en: Important note
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: Due to the nature of the **PFI** explainer, you *cannot* use it to create **local**
    or **instance-level feature importance**. Keep that in mind if, during the exam,
    you are asked whetherthis technique could provide local explanations.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 由于**PFI** 解释器的性质，你*不能*使用它来创建**局部**或**实例级特征重要性**。如果在考试中被问到该技术是否能提供局部解释，记住这一点。
- en: In this section, you looked at all the interpretation techniques that are supported
    by the Interpret-Community package. In the next section, you will explore the
    capabilities that the explanation dashboard offers and how this dashboard is embedded
    within Azure Machine Learning Studio.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你了解了 Interpret-Community 包支持的所有解释技术。在下一节中，你将探索解释仪表板所提供的功能，以及该仪表板如何嵌入到 Azure
    机器学习工作室中。
- en: Reviewing the interpretation results
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 审查解释结果
- en: 'Azure Machine Learning offers rich integration with the interpret community''s
    efforts. One of those integration points is the explanation dashboard, which is
    embedded in every run. You can use `ExplanationClient` from the `azureml.interpret`
    package to upload and download model explanations to and from your workspace.
    To upload the global explanations that you created using `TabularExplainer` in
    the *Using the tabular explainer* section, navigate to the `chapter10.ipynb` notebook,
    and add a new cell at the end of the file with the following code:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: Azure 机器学习与 Interpret-Community 的工作有着丰富的集成点。其中一个集成点是解释仪表板，它嵌入在每个运行中。你可以使用来自`azureml.interpret`包的`ExplanationClient`上传和下载模型解释到工作区。如果你使用`TabularExplainer`在*使用表格解释器*一节中创建了全局解释，导航至`chapter10.ipynb`笔记本，在文件末尾添加一个新单元格，并输入以下代码：
- en: '[PRE12]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This code starts a new run within the `chapter10` experiment. From that run,
    you create an `ExplanationClient`, which you use to upload the model explanations
    you generated and the ground truth (`true_ys`), which helps the dashboard evaluate
    the model's performance.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码在`chapter10`实验中启动一个新的运行。通过该运行，你创建一个`ExplanationClient`，用来上传你生成的模型解释和真实标签（`true_ys`），这些有助于仪表板评估模型的表现。
- en: 'If you visit the portal link that this code prints out, you will navigate to
    a run, where, in the **Explanations** tab, you will need to select **Explanation
    ID** on the left and then review the explanation dashboard by visiting the **Aggregate
    feature importance** tab, as shown here:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你访问此代码输出的门户链接，你将进入一个运行页面，在**解释**标签中，你需要选择左侧的**解释 ID**，然后访问**聚合特征重要性**标签以查看解释仪表板，如下所示：
- en: '![Figure 10.11 – Reviewing the global explanations stored within the Azure
    Machine Learning workspace'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.11 – 审查存储在 Azure 机器学习工作区中的全局解释'
- en: '](img/B16777_10_011.jpg)'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_10_011.jpg)'
- en: Figure 10.11 – Reviewing the global explanations stored within the Azure Machine
    Learning workspace
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.11 – 审查存储在 Azure 机器学习工作区中的全局解释
- en: '`ExplanationClient` is used by Azure Machine Learning''s `chapter10.ipynb`
    notebook and add the following code block in a new cell:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '`ExplanationClient`由 Azure 机器学习的`chapter10.ipynb`笔记本使用，并在新单元格中添加以下代码块：'
- en: '[PRE13]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This code looks very similar to the code you used in [*Chapter 9*](B16777_09_Final_VK_ePub.xhtml#_idTextAnchor136),
    *Optimizing the ML Model*, in the *Running AutoML experiments with code* section.
    In this code block, you are getting a reference to the Azure Machine Learning
    workspace, the `loans` dataset, and then you are splitting the dataset into training
    and validation sets.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码看起来非常类似于你在[*第 9 章*](B16777_09_Final_VK_ePub.xhtml#_idTextAnchor136)中使用的代码，*优化机器学习模型*，位于*使用代码运行
    AutoML 实验*部分。在这段代码中，你正在获取 Azure 机器学习工作区的引用，以及`loans`数据集，然后将数据集分割为训练集和验证集。
- en: 'In the same or a new cell, add the following code block:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在相同或新建的单元格中，添加以下代码块：
- en: '[PRE14]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'In this code block, you are kicking off `model_explainability` (which is `True`
    by default). This option schedules a model explanation of the best model once
    the **AutoML** process concludes. Once the run completes, navigate to the run''s
    UI and open the **Models** tab, as shown here:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在这段代码中，你正在启动`model_explainability`（默认值为`True`）。这个选项会在**AutoML**过程完成后安排最佳模型的说明。一旦运行完成，转到该运行的
    UI，并打开**模型**标签，如下图所示：
- en: '![Figure 10.12 – Explanations become available for the best model in the AutoML
    run'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.12 – AutoML 运行中最佳模型的说明已可用'
- en: '](img/B16777_10_012.jpg)'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_10_012.jpg)'
- en: Figure 10.12 – Explanations become available for the best model in the AutoML
    run
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.12 – AutoML 运行中最佳模型的说明已可用
- en: 'Click on the **View explanation** link of the best model to navigate to the
    **Explanations** tab of the child run that trained the specific model. Once you
    land in the **Explanations** tab, you will notice that **AutoML** stored two global
    explanations: one for the raw features and one for the engineered features. You
    can switch between those two explanations by selecting the appropriate ID on the
    left-hand side of the screen, as shown in the following screenshot. Raw features
    are the ones from the original dataset. Engineered features are the ones you get
    after preprocessing. The engineered features are the internal inputs to the model.
    If you select the lower **explanation ID** and visit the **Aggregate feature importance**
    area, you will notice that **AutoML** has converted the credit card number into
    a categorical feature. Moreover, the model''s input is 12 features compared to
    the three features you produced in your model training.'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 点击最佳模型的**查看说明**链接，进入训练该特定模型的子运行的**说明**标签。当你进入**说明**标签时，你会注意到**AutoML**存储了两个全局说明：一个是原始特征的说明，另一个是工程特征的说明。你可以通过选择屏幕左侧的适当
    ID，在这两个说明之间切换，如下图所示。原始特征是来自原始数据集的特征。工程特征是经过预处理后得到的特征。这些工程特征是模型的内部输入。如果你选择较低的**说明
    ID**并查看**聚合特征重要性**区域，你会注意到**AutoML**已将信用卡号转换为分类特征。此外，与模型训练中产生的三个特征相比，模型的输入是 12
    个特征。
- en: 'You can review those features and their corresponding feature importance here:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在这里查看这些特征及其相应的特征重要性：
- en: '![Figure 10.13 – Global explanations for engineered features'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.13 – 工程特征的全局说明'
- en: '](img/B16777_10_013.jpg)'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_10_013.jpg)'
- en: Figure 10.13 – Global explanations for engineered features
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.13 – 工程特征的全局说明
- en: 'Since the engineered features are more difficult to understand, go to the top
    **explanation ID**, which is where you have the three raw features you have worked
    with so far. Navigate to the **Dataset explorer** tab, as shown here:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 由于工程特征较难理解，请转到顶部的**说明 ID**，这是你目前为止使用的三个原始特征所在的位置。点击**数据集浏览器**标签，如下图所示：
- en: '![Figure 10.14 – Dataset explorer in the raw features explanations'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.14 – 数据集浏览器中的原始特征说明'
- en: '](img/B16777_10_014.jpg)'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_10_014.jpg)'
- en: Figure 10.14 – Dataset explorer in the raw features explanations
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.14 – 数据集浏览器中的原始特征说明
- en: 'Here, we can see the following:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到以下内容：
- en: The **Mimic** explainer was used to explain the specific model (which is an
    **XGBoostClassifier**, as seen in *Figure 10.12*). The **glassbox** model that
    was used as a surrogate model was an **LGBMExplainableModel**, as shown at the
    top left of the preceding screenshot.
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Mimic**解释器用于解释特定的模型（这是一个**XGBoostClassifier**，如*图 10.12*所示）。作为替代模型的**glassbox**模型是一个**LGBMExplainableModel**，如前面截图的左上角所示。'
- en: You can edit the cohorts or define new ones to be able to focus your analysis
    on specific subgroups by selecting them from the **Select a dataset cohort to
    explore** dropdown. To define a new cohort, you need to specify the dataset filtering
    criteria you want to apply. For example, in the preceding screenshot, we have
    defined a cohort named **age_45**, which has a single filter (age == 45). There
    are **4 datapoints** in the test dataset that are used by this explanation dashboard.
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您可以编辑队列或定义新的队列，以便通过从 **选择要探索的数据集队列** 下拉菜单中选择它们来专注于特定的子组。要定义一个新的队列，您需要指定要应用的数据集过滤条件。例如，在前述截图中，我们定义了一个名为
    **年龄_45** 的队列，它有一个单一的过滤器（年龄 == 45）。在测试数据集中有 **4 个数据点** 由此解释仪表板使用。
- en: You can modify the *x*-axis and *y*-axis fields by clicking on the highlighted
    areas marked as **3** in the preceding screenshot. This allows you to change the
    view and get insights about the correlations of the features with the predicted
    values or the ground truth, the correlation between features, and any other view
    that makes sense for your model understanding analysis.
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您可以通过点击前述截图中标记为 **3** 的高亮区域来修改 *x* 轴和 *y* 轴字段。这使您可以改变视图并获得关于特征与预测值或基本事实之间相关性的见解，特征之间的相关性以及对您的模型理解分析有意义的任何其他视图。
- en: 'In the **Aggregate feature importance** tab, as shown here, you can view the
    feature importance for all the data or for the specific cohorts you have defined:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 在**聚合特征重要性**选项卡中，如所示，您可以查看您定义的所有数据或特定队列的特征重要性：
- en: '![Figure 10.15 – Aggregate feature importance for the raw features with'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 10.15 – Aggregate feature importance for the raw features with'
- en: the cohorts and dependency of the rejected loans based on income
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 收入依赖性与被拒绝的贷款队列
- en: '](img/B16777_10_015.jpg)'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_10_015.jpg)'
- en: Figure 10.15 – Aggregate feature importance for the raw features with the cohorts
    and dependency of the rejected loans based on income
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.15 – 根据收入的原始特征与队列和依赖关系的聚合特征重要性
- en: In this example, the **income** feature is more important for the **age_45**
    cohort than the general public, which is represented by **All data**. If you click
    on a feature importance bar, the graph below updates to show you how this feature
    is affecting the model's decision to reject a loan request (**Class 0**). In this
    example, you can see that incomes that are from 0 up to a bit more than 5,000
    *push* the model to reject the loan, while incomes from 6,000 onward have a negative
    impact, which means that they try to *push* the model to approve the loan.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在本例中，**收入** 特征对于 **年龄_45** 队列比一般公众更重要，由 **所有数据** 表示。如果您点击特征重要性条，下面的图表会更新，显示这个特征如何影响模型决定拒绝贷款请求（**类别
    0**）。在这个例子中，您可以看到从 0 到略高于 5,000 的收入*推动*模型拒绝贷款，而从 6,000 开始的收入则产生负面影响，这意味着它们试图*推动*模型批准贷款。
- en: There are plenty of features in the explanation dashboard, and new features
    appear all the time as contributions to the interpret community. In this section,
    you reviewed the most important features of the dashboard, which have helped you
    understand why the model makes the predictions it does and how to potentially
    debug corner cases where it performs poorly.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 解释仪表板中有大量的功能，而且随着对解释社区的贡献，新功能会不断出现。在本节中，您回顾了仪表板的最重要功能，这些功能帮助您理解模型为什么会做出预测以及如何可能调试性能不佳的边缘案例。
- en: In the next section, you will learn about error analysis, which is part of Microsoft's
    overall responsible AI widgets package. This tool allows you to understand the
    blind spots of your models, which are the cases where your model is performing
    poorly.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，您将学习错误分析，这是微软整体负责人工智能小部件包的一部分。这个工具允许您了解模型的盲点，即模型表现不佳的情况。
- en: Analyzing model errors
  id: totrans-180
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分析模型错误
- en: '**Error analysis** is a model assessment/debugging tool that enables you to
    gain a deeper understanding of your machine learning model errors. Error analysis
    helps you identify cohorts within your dataset with higher error rates than the
    rest of the records. You can observe the misclassified and erroneous data points
    more closely to investigate whether any systematic patterns can be spotted, such
    as whether no data is available for a specific cohort. Error analysis is also
    a powerful way to describe the current shortcomings of the system and communicate
    that to other stakeholders and auditors.'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '**错误分析** 是一种模型评估/调试工具，可以帮助你更深入地了解机器学习模型的错误。错误分析帮助你识别数据集中错误率高于其他记录的群体。你可以更密切地观察被错误分类和有误的数据点，查看是否能发现任何系统性模式，例如是否某些群体没有数据可用。错误分析也是描述当前系统缺陷并与其他利益相关者和审计人员沟通的有效方式。'
- en: The tool consists of several visualization components that can help you understand
    where the errors appear.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 该工具由多个可视化组件组成，可以帮助你了解错误出现的位置。
- en: 'Navigate to the `chapter10.ipynb` notebook. From **Menu**, in the **Editors**
    sub-menu, click **Edit in Jupyter** to open the same notebook in Jupyter and continue
    editing it there, as shown here:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 导航到 `chapter10.ipynb` 笔记本。在 **菜单** 中，点击 **编辑器** 子菜单下的 **在 Jupyter 中编辑**，以便在
    Jupyter 中打开相同的笔记本并继续编辑，如下所示：
- en: '![Figure 10.16 – Editing a notebook in Jupyter for better compatibility with
    the widget'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.16 – 在 Jupyter 中编辑笔记本以更好地与小部件兼容'
- en: '](img/B16777_10_016.jpg)'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_10_016.jpg)'
- en: Figure 10.16 – Editing a notebook in Jupyter for better compatibility with the
    widget
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.16 – 在 Jupyter 中编辑笔记本以更好地与小部件兼容
- en: Important note
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 重要说明
- en: At the time of writing this book, the error analysis dashboard doesn't work
    on the Notebooks experience due to security restrictions imposed by the Notebooks
    experience that prevent certain features from working properly. If you try to
    run it within Notebooks, it doesn't produce the necessary visualizations. This
    is why you are going to open the notebook in Jupyter, something that may not be
    needed by the time you read this book.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在编写本书时，由于笔记本体验的安全限制，错误分析面板无法在笔记本环境中运行，这些限制会妨碍某些功能的正常工作。如果你尝试在笔记本中运行，它不会生成必要的可视化效果。因此，你需要在
    Jupyter 中打开笔记本，而这一步在你阅读本书时可能不再需要。
- en: 'In the Jupyter environment, add a new cell at the end of the file with the
    following code:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Jupyter 环境中，在文件末尾添加一个新的单元格并输入以下代码：
- en: '[PRE15]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Notice that this code is very similar to the code you used to trigger the explanation
    dashboard.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这段代码与你用来触发解释面板的代码非常相似。
- en: Important note
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 重要说明
- en: Make sure that you close the notebook from any other editing experience you
    may have, such as the Notebooks experience within Azure Machine Learning Studio.
    If the file is modified accidentally from another editor, you may lose some of
    your code.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 确保你关闭所有其他编辑环境中的笔记本，比如在 Azure 机器学习工作室中的笔记本体验。如果笔记本被其他编辑器意外修改，你可能会丢失部分代码。
- en: 'The tool opens in the global view, as shown here:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 该工具以全局视图打开，如下所示：
- en: '![Figure 10.17 – The error analysis dashboard loaded within the Jupyter environment'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.17 – 错误分析面板在 Jupyter 环境中的加载情况'
- en: '](img/B16777_10_017.jpg)'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_10_017.jpg)'
- en: Figure 10.17 – The error analysis dashboard loaded within the Jupyter environment
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.17 – 错误分析面板在 Jupyter 环境中的加载情况
- en: In this view, you are looking at the model's error rates on overall data. In
    this view, you can see a binary tree that depicts data partitions between interpretable
    subgroups, which have unexpectedly high or low error rates. In our example, all
    the errors of the model occur for incomes less than or equal to **6144**, which
    accounts for a **7.25%** error rate, meaning that **7.25%** of the loans with
    monthly incomes less than **6144** were misclassified. Error coverage is the portion
    of all errors that fall into the node, and in this case, all the errors are located
    in this node (**100%**). The numbers within the node show the data representation.
    Here, **5** samples were wrong out of **69** records that belong in that node.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 在此视图中，你可以查看模型在整个数据集上的错误率。在这个视图中，你可以看到一棵二叉树，描述了在可解释子群体之间的数据分区，这些子群体具有出乎意料的高或低错误率。在我们的示例中，模型的所有错误都发生在收入小于或等于
    **6144** 的数据中，这占 **7.25%** 的错误率，意味着 **7.25%** 的月收入小于 **6144** 的贷款被错误分类。错误覆盖率是所有错误中落入此节点的部分，在这种情况下，所有错误都位于该节点中（**100%**）。节点中的数字表示数据的分布情况。这里，**69**
    条记录中有 **5** 条是错误的，它们属于这个节点。
- en: 'Once you have selected a node in **Tree map**, you can click on **Cohort settings**
    or **Cohort info** and save those records as a cohort of interest. This cohort
    can be used in the explanation dashboard. By clicking on the **Explanation** button,
    you will be taken to the **Data explorer** view, as shown here:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你选择了**树图**中的某个节点，你可以点击**群体设置**或**群体信息**，并将这些记录保存为一个感兴趣的群体。这个群体可以用于解释仪表板。在点击**解释**按钮后，你将进入**数据探索器**视图，如下所示：
- en: '![Figure 10.18 – The data explorer for the specific cohort selected in the
    tree map'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.18 – 针对树图中选择的特定群体的数据探索器'
- en: '](img/B16777_10_018.jpg)'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_10_018.jpg)'
- en: Figure 10.18 – The data explorer for the specific cohort selected in the tree
    map
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.18 – 针对树图中选择的特定群体的数据探索器
- en: This view has preselected the node's cohort. It has similar functionality to
    the explanation dashboard, such as seeing the feature importance that impacts
    the overall model predictions for a selected cohort. This view also offers the
    **Local explanation** tab, which allows you to understand individual error records
    and even perform what-if analysis to understand when the model would classify
    that record correctly.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 此视图已经预选了节点的群体。它具有类似于解释仪表板的功能，比如查看影响所选群体整体模型预测的特征重要性。此视图还提供了**局部解释**标签，允许你理解个别错误记录，甚至进行假设分析，了解模型何时会正确分类该记录。
- en: 'By clicking on the **Error explorer** link at the top-left corner of the widget,
    you will navigate back to the **Tree map** view. From the **Error explorer:**
    dropdown, select **Heat map** instead of **Tree map**, which is currently selected.
    This will lead you to the error heat map view, as shown here:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 通过点击小部件左上角的**错误探索器**链接，你将返回**树图**视图。在**错误探索器：**下拉菜单中，选择**热力图**，而不是当前选中的**树图**。这将引导你到错误热力图视图，如下所示：
- en: '![Figure 10.19 – Error heat map view'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.19 – 错误热力图视图'
- en: '](img/B16777_10_019.jpg)'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_10_019.jpg)'
- en: Figure 10.19 – Error heat map view
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.19 – 错误热力图视图
- en: This view slices the data in a one- or two-dimensional way based on the features
    selected on the top left-hand side. The heat map visualizes cells with higher
    errors with a darker red color to bring the user's attention to regions with high
    error discrepancies. The cells with stripes indicate that no samples were evaluated,
    potentially indicating hidden pockets of errors.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 此视图根据左上角选定的特征，以一维或二维的方式对数据进行切分。热力图通过较深的红色来可视化具有较高错误的单元格，以引起用户对高错误差异区域的注意。带有条纹的单元格表示没有评估样本，这可能表明存在隐藏的错误区域。
- en: In this section, you were provided with an overview of the capabilities of the
    error analysis dashboard and how it can help you understand where your model is
    making errors. This tool can help you identify those error pockets and mitigate
    them by designing new features, collecting better data, discarding some of the
    current training data, or performing better hyperparameter tuning.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们提供了错误分析仪表板的功能概述，并展示了它如何帮助你理解模型的错误发生位置。该工具可以帮助你识别这些错误区域，并通过设计新特征、收集更好的数据、舍弃部分当前的训练数据，或进行更好的超参数调整来减轻它们。
- en: In the next section, you will learn about Fairlearn, a tool that will help you
    assess your model's fairness and mitigate any observed unfairness issues.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分，你将了解Fairlearn，这是一种工具，能帮助你评估模型的公平性并缓解任何观察到的不公平问题。
- en: Detecting potential model fairness issues
  id: totrans-211
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检测潜在的模型公平性问题
- en: 'Machine learning models can behave unfairly due to multiple reasons:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型可能由于多种原因表现不公平：
- en: Historical bias in society may be reflected in the data that was used to train
    the model.
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 社会中的历史偏见可能会反映在用于训练模型的数据中。
- en: The decisions made by the developers of the model may have been skewed.
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型开发者所做的决策可能存在偏差。
- en: Lack of representative data used to train the model. For example, there may
    be too few data points from a specific group of people.
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于训练模型的数据缺乏代表性。例如，某一特定人群的数据点可能太少。
- en: 'Since it is hard to identify the actual reasons that cause the model to behave
    unfairly, the definition of a model behaving unfairly is defined by its impact
    on people. There are two significant types of harm that a model can cause:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 由于很难确定导致模型表现不公平的实际原因，因此定义模型不公平行为的标准是根据它对人们的影响来判断的。模型可能造成的两种显著伤害类型是：
- en: '**Allocation harm**: This happens when the model withholds opportunities, resources,
    or information from a group of people. For example, during the hiring process
    or the loan lending example we have been working on so far, you may not have the
    opportunity to be hired or get a loan.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**资源分配损害**：这是指模型拒绝为某个群体提供机会、资源或信息。例如，在招聘过程中或我们迄今为止处理的贷款贷款示例中，某些群体可能没有被聘用或获得贷款的机会。'
- en: '**Quality-of-service harm**: This happens when the system doesn''t offer everyone
    the same quality of service. For example, it has reduced accuracy in terms of
    face detection for specific groups of people.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**服务质量损害**：这是指系统未能为每个人提供相同的服务质量。例如，面部识别在某些人群中的准确度较低。'
- en: Based on that, it is evident that model fairness issues cannot be solved automatically
    because there is no mathematical formulation. **Fairlearn** is a toolkit that
    provides tools that help assess and mitigate the fairness of the predictions of
    classification and regression models.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 基于此，很明显，模型公平性问题不能通过自动化解决，因为没有数学公式。**Fairlearn**是一个工具包，提供帮助评估和缓解分类和回归模型预测公平性的问题的工具。
- en: 'In our case, if we treat age groups as a sensitive feature, we can analyze
    the model''s behavior based on its accuracy with the following code:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的案例中，如果将年龄分组视为一个敏感特征，我们可以使用以下代码分析模型基于准确率的行为：
- en: '[PRE16]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'This code gets the predictions of the model you trained in the *Training a
    loans approval model* section and creates the predictions for the `x_test` dataset.
    Then, it assigns all values from the `x_test[''age'']` feature to the `age` variable.
    Then, by using `MetricFrame`, we can calculate the `accuracy_score` metric of
    the model either for the entire test dataset, which is stored in the `overall`
    attribute, or the accuracy by group, which is stored in the `by_group` attribute.
    This code prints the overall accuracy score and the accuracy score for the groups
    with less than 1\. The results are shown in the following screenshot:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码获取了你在*训练贷款批准模型*部分中训练的模型的预测结果，并为`x_test`数据集生成预测结果。然后，它将`x_test['age']`特征的所有值分配给`age`变量。接着，使用`MetricFrame`，我们可以计算模型的`accuracy_score`指标，既可以计算整个测试数据集的准确率（存储在`overall`属性中），也可以按组计算准确率（存储在`by_group`属性中）。这段代码会打印整体准确率和分组准确率，后者的值小于1。结果显示在下面的截图中：
- en: '![Figure 10.20 – The model has a 0.96 accuracy but for 65-year-olds its accuracy
    is 0.5'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.20 – 该模型的准确率为0.96，但对于65岁的人群，其准确率为0.5'
- en: '](img/B16777_10_020.jpg)'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_10_020.jpg)'
- en: Figure 10.20 – The model has a 0.96 accuracy but for 65-year-olds its accuracy
    is 0.5
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.20 – 该模型的准确率为0.96，但对于65岁的人群，其准确率为0.5
- en: Although the dataset was generated, you can see that the model's accuracy for
    65-year-olds is only 50%. Note that although the model was trained with ages 18
    to 85, only 35 subgroups were detected in the dataset, indicating that we may
    not be testing it accurately.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管数据集已经生成，但你可以看到该模型对65岁的人群的准确率只有50%。请注意，尽管该模型是在18至85岁之间的年龄段进行训练的，但数据集中只检测到35个子组，这表明我们可能没有对其进行准确测试。
- en: Similar to `ExplanationDashboard` and `ErrorAnalysisDashboard`, the responsible
    AI widgets (`raiwidgets`) package offers a `FairnessDashboard`, which can be used
    to analyze the fairness of the model results.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 与`ExplanationDashboard`和`ErrorAnalysisDashboard`类似，负责任的AI小部件（`raiwidgets`）包提供了一个`FairnessDashboard`，可以用来分析模型结果的公平性。
- en: Important note
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: At the time of writing this book, `FairnessDashboard` works in Jupyter. In the
    Notebooks experience, there are some technical glitches. Open your notebook in
    Jupyter to get the best experience out of `FairnessDashboard`.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 在编写本书时，`FairnessDashboard`在Jupyter中工作。在Notebook体验中，存在一些技术问题。为了获得最佳体验，请在Jupyter中打开你的Notebook。
- en: 'In a new cell, add the following code to invoke the fairness dashboard using
    the age-sensitive feature you defined in the preceding code:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个新单元格中，添加以下代码以调用公平性仪表板，使用你在前面的代码中定义的年龄敏感特征：
- en: '[PRE17]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'After the launch, the widget will guide you through the fairness assessment
    process, where you will need to define the following:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 启动后，该小部件将引导你完成公平性评估过程，在此过程中你需要定义以下内容：
- en: '**Sensitive features**: Here, you must configure the sensitive features. Sensitive
    features are used to split your data into groups, as we saw previously. In this
    case, it will prompt you to create five bins for the age groups (18-29, 30-40,
    41-52, 53-64, and 64-75), and you can modify the binning process or even request
    it to treat each age on its own by selecting the **Treat as categorical** option
    it provides.'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**敏感特征**：在这里，你必须配置敏感特征。敏感特征用于将数据分组，正如我们之前看到的那样。在这种情况下，它将提示你为年龄组创建五个区间（18-29岁、30-40岁、41-52岁、53-64岁和64-75岁），你可以修改分箱过程，甚至选择提供的**视为分类变量**选项，以让每个年龄单独处理。'
- en: '**Performance metrics**: Performance metrics are used to evaluate the quality
    of your model overall and in each group. In this case, you can select accuracy
    as we did previously. You can change this even after the wizard finishes.'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**性能指标**：性能指标用于评估模型在总体和每个组中的质量。在这种情况下，你可以选择准确度，就像我们之前所做的那样。即使向导完成后，你也可以更改这个选项。'
- en: '**Fairness metrics**: Fairness metrics represent either the difference or ratio
    between the extreme values of a performance metric, or simply the worst value
    of any group. An example of such a metric is **Accuracy score ratio**, which is
    the minimum ratio accuracy score between any two groups. You can change this even
    after the wizard finishes.'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**公平性指标**：公平性指标表示性能指标的极端值之间的差异或比率，或者仅仅是任何组的最差值。此类指标的一个示例是**准确度比率**，它是任何两个组之间的最小准确度比率。即使向导完成后，你也可以更改这个选项。'
- en: 'The resulting dashboard allows you to drill through your model''s impact on
    the subgroups. It consists of two areas – the summarization table and the visualization
    area – where you can select different graphical representations, as shown here:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的仪表板允许你深入了解模型对各子组的影响。它由两个区域组成——总结表格和可视化区域——你可以在这里选择不同的图形表示方式，如下所示：
- en: '![Figure 10.21 – Fairness dashboard showing the accuracy of the model in various
    age groups'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.21 – 展示不同年龄组中模型准确度的公平性仪表板'
- en: '](img/B16777_10_021.jpg)'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16777_10_021.jpg)'
- en: Figure 10.21 – Fairness dashboard showing the accuracy of the model in various
    age groups
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.21 – 展示不同年龄组中模型准确度的公平性仪表板
- en: 'Once you have identified a fairness issue with your model, you can use the
    **Fairlearn** library to mitigate them. The **Fairlearn** library offers two approaches:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你确定了模型中的公平性问题，你可以使用**Fairlearn**库来缓解这些问题。**Fairlearn**库提供了两种方法：
- en: '`ThresholdOptimizer`, adjust the output of the underlying model to achieve
    an explicit constraint, such as the constrain of equalizing odds. Equalizing odds
    in our binary classification model means that true-positive and false-positive
    rates should match across groups.'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ThresholdOptimizer`，调整底层模型的输出以实现显式约束，比如均衡赔率的约束。在我们的二元分类模型中，均衡赔率意味着在各组之间，真正例和假正例的比率应该匹配。'
- en: '`sample_weight` parameter that the `fit` **sklearn** method accepts.'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sample_weight` 参数是 `fit` **sklearn** 方法接受的。'
- en: Using these techniques, you can balance the fairness of your model by sacrificing
    some of your model's performance to meet the needs of your business.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些技术，你可以通过牺牲一些模型的性能来平衡模型的公平性，以满足你的业务需求。
- en: The **Fairlearn** package is constantly evolving and has been integrated within
    the Azure Machine Learning SDK and the Studio web experience, enabling data scientists
    to upload model fairness insights into the Azure Machine Learning run history
    and observe the **Fairlearn** dashboard within Azure Machine Learning Studio.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: '**Fairlearn**包正在不断发展，已经集成到Azure机器学习SDK和Studio Web体验中，允许数据科学家将模型公平性洞察上传到Azure机器学习运行历史记录中，并在Azure机器学习Studio中查看**Fairlearn**仪表板。'
- en: In this section, you learned how to detect potential unfair behaviors that your
    model may have. You also read about the possible mitigation techniques that can
    be implemented within the **Fairlearn** package. This concludes the tools provided
    by the Azure Machine Learning workspace and the open source communities that allow
    you to understand your models and assist you in creating AI.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你学习了如何检测模型可能存在的潜在不公平行为。你还了解了可以在**Fairlearn**包中实现的潜在缓解技术。这总结了由Azure机器学习工作区和开源社区提供的工具，它们帮助你理解模型并协助你创建人工智能。
- en: Summary
  id: totrans-246
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, you were given an overview of the various tools that can help
    you understand your models. You started with the Interpret-Community package,
    which allows you to understand why the model is making its predictions. You learned
    about the various interpretation techniques and explored the explanation dashboard,
    which provides views such as feature importance. You then saw the error analysis
    dashboard, which allows you to determine where the model is performing poorly.
    Finally, you learned about the fairness evaluation techniques, the corresponding
    dashboard that enables you to explore potentially unfair results, and the methods
    you can use to mitigate potential fairness issues.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 本章为你概述了几种可以帮助你理解模型的工具。你首先了解了Interpret-Community包，它能够帮助你理解模型做出预测的原因。你学习了各种解释技术，并探索了解释仪表板，其中提供了诸如特征重要性等视图。接着，你看到了错误分析仪表板，它能够帮助你确定模型表现不佳的地方。最后，你学习了公平性评估技术、相应的仪表板，能够让你探索潜在的不公平结果，并了解如何采取措施来缓解潜在的公平性问题。
- en: In the next chapter, you will learn about Azure Machine Learning pipelines,
    which allow you to orchestrate model training and model results interpretation
    in a repeatable manner.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，你将学习关于 Azure 机器学习管道的内容，管道可以让你以可重复的方式编排模型训练和模型结果的解释。
- en: Questions
  id: totrans-249
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: 'In each chapter, you will find a couple of questions to help you conduct a
    knowledge check regarding the topics that have been discussed in each chapter:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 在每一章中，你会发现一些问题，帮助你对每章讨论的主题进行知识检查：
- en: You are using `TabularExplainer` to interpret a `DecisionTreeClassifier`. Which
    underlying SHAP explainer will be used?
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你正在使用 `TabularExplainer` 来解释 `DecisionTreeClassifier`。将使用哪种底层的 SHAP 解释器？
- en: a. `DecisionTreeExplainer`
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a. `DecisionTreeExplainer`
- en: b. `TreeExplainer`
  id: totrans-253
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b. `TreeExplainer`
- en: c. `KernelExplainer`
  id: totrans-254
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c. `KernelExplainer`
- en: d. `LinearExplainer`
  id: totrans-255
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: d. `LinearExplainer`
- en: You want to interpret a `DecisionTreeClassifier` using `MimicExplainer`. Which
    of the following models can you use for the `explainable_model` parameter?
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你想使用 `MimicExplainer` 来解释 `DecisionTreeClassifier`。你可以使用以下哪种模型作为 `explainable_model`
    参数？
- en: a. `LGBMExplainableModel`
  id: totrans-257
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a. `LGBMExplainableModel`
- en: b. `LinearExplainableModel`
  id: totrans-258
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b. `LinearExplainableModel`
- en: c. `SGDExplainableModel`
  id: totrans-259
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c. `SGDExplainableModel`
- en: d. `DecisionTreeExplainableModel`
  id: totrans-260
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: d. `DecisionTreeExplainableModel`
- en: e. All of the above
  id: totrans-261
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: e. 上述所有选项
- en: Can you use `PFIExplainer` to produce local feature importance values?
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你能使用 `PFIExplainer` 来生成局部特征重要性值吗？
- en: a. Yes
  id: totrans-263
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a. 是的
- en: b. No
  id: totrans-264
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b. 否
- en: Further reading
  id: totrans-265
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'This section offers a list of useful web resources that will help you augment
    your knowledge of the Azure Machine Learning SDK and the various code snippets
    that were used in this chapter:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 本节提供了一些有用的网络资源，帮助你增强对 Azure 机器学习 SDK 以及本章中使用的各种代码片段的理解：
- en: '**The SmartNoise** library for differential privacy: [https://github.com/opendp/smartnoise-core](https://github.com/opendp/smartnoise-core)'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**SmartNoise** 库，用于差分隐私：[https://github.com/opendp/smartnoise-core](https://github.com/opendp/smartnoise-core)'
- en: 'HE resources: [https://www.microsoft.com/en-us/research/project/homomorphic-encryption/](https://www.microsoft.com/en-us/research/project/homomorphic-encryption/)'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 同态加密资源：[https://www.microsoft.com/en-us/research/project/homomorphic-encryption/](https://www.microsoft.com/en-us/research/project/homomorphic-encryption/)
- en: 'Deploying an encrypted inference web service: [https://docs.microsoft.com/en-us/azure/machine-learning/how-to-homomorphic-encryption-seal](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-homomorphic-encryption-seal)'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署加密推理 Web 服务：[https://docs.microsoft.com/en-us/azure/machine-learning/how-to-homomorphic-encryption-seal](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-homomorphic-encryption-seal)
- en: '**Presidio**, the data protection and anonymization API: [https://github.com/Microsoft/presidio](https://github.com/Microsoft/presidio)'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Presidio**，数据保护和匿名化 API：[https://github.com/Microsoft/presidio](https://github.com/Microsoft/presidio)'
- en: 'Sample repository for aDevOps process in data science projects, also known
    as **MLOps**: [https://aka.ms/mlOps](https://aka.ms/mlOps)'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于数据科学项目中 aDevOps 过程的示例代码库，也称为**MLOps**：[https://aka.ms/mlOps](https://aka.ms/mlOps)
- en: '**Model Cards for Model Reporting**: [https://arxiv.org/pdf/1810.03993.pdf](https://arxiv.org/pdf/1810.03993.pdf)'
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型报告的模型卡**：[https://arxiv.org/pdf/1810.03993.pdf](https://arxiv.org/pdf/1810.03993.pdf)'
- en: 'The **InterpretML** website, with links to the GitHub repository of the community:
    [https://interpret.ml/](https://interpret.ml/)'
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**InterpretML** 网站，提供了社区的 GitHub 仓库链接：[https://interpret.ml/](https://interpret.ml/)'
- en: 'The **Error Analysis** home page, including guides on how to use the toolkit:
    [https://erroranalysis.ai/](https://erroranalysis.ai/)'
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**错误分析**主页，包括如何使用工具包的指南：[https://erroranalysis.ai/](https://erroranalysis.ai/)'
- en: 'The **Fairlearn** home page: [https://fairlearn.org/](https://fairlearn.org/)'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Fairlearn**主页：[https://fairlearn.org/](https://fairlearn.org/)'
