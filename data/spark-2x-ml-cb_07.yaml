- en: Recommendation Engine that Scales with Spark
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Spark扩展的推荐引擎
- en: 'In this chapter, we will cover:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖：
- en: Setting up the required data for a scalable recommendation engine in Spark 2.0
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Spark 2.0中设置可扩展的推荐引擎所需的数据
- en: Exploring the movies data details for the recommendation system in Spark 2.0
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Spark 2.0中探索推荐系统的电影数据细节
- en: Exploring the ratings data details for the recommendation system in Spark 2.0
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Spark 2.0中探索推荐系统的评分数据细节
- en: Building a scalable recommendation engine using collaborative filtering in Spark
    2.0
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Spark 2.0中构建可扩展的协同过滤推荐引擎
- en: Introduction
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引言
- en: In the previous chapters, we used short recipes and extremely simplified code
    to demonstrate basic building blocks and concepts governing the Spark machine
    library. In this chapter, we present a more developed application that addresses
    specific machine learning library domains using Spark's API and facilities. The
    number of recipes are less in this chapter; however, we get into a more ML application
    setting.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的章节中，我们使用简短的配方和极其简化的代码来演示Spark机器库的基本构建块和概念。在本章中，我们提出了一个更为发展的应用程序，该应用程序使用Spark的API和设施来解决特定的机器学习库领域。本章的配方数量较少；然而，我们进入了更多的机器学习应用设置。
- en: In this chapter, we explore the recommendation system and its implementation
    using a matrix factorization technique that draws on latent factor models called
    **alternating least square** (**ALS**). In a nutshell, when we try to factorize
    a large matrix of user-item ratings into two lower ranked, skinnier matrices,
    we often face a non-linear or non-convex optimization problem that is very difficult
    to solve. It happens that we are very good at solving convex optimization problems
    by fixing one leg and partially solving the other and then going back and forth
    (hence alternating); we can solve this factorization (hence discovering a set
    of latent factors) much better using known optimization techniques in parallel.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了推荐系统及其实现，使用了一种称为交替最小二乘法（ALS）的矩阵分解技术，该技术依赖于称为潜在因子模型的潜在因子。简而言之，当我们尝试将用户-物品评分的大矩阵因子分解为两个较低排名、较瘦的矩阵时，我们经常面临一个非线性或非凸优化问题，这是非常难以解决的。我们很擅长通过固定一个腿并部分解决另一个腿，然后来回进行（因此交替）来解决凸优化问题；我们可以使用已知的优化技术并行地更好地解决这种因子分解（因此发现一组潜在因子）。
- en: We use a popular dataset (movie lens dataset) to implement the recommendation
    engine, but unlike in other chapters, we use two recipes to explore the data,
    and also show how you can introduce graphical elements such as the JFreeChart
    popular library to your Spark machine learning toolkit.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用一个流行的数据集（电影镜头数据集）来实现推荐引擎，但与其他章节不同的是，我们使用两个配方来探索数据，并展示如何将图形元素（例如JFreeChart流行库）引入到您的Spark机器学习工具包中。
- en: 'The following figure shows the flow of the concepts and recipes in this chapter
    to demonstrate an ALS recommendation application:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图显示了本章中概念和配方的流程，以演示ALS推荐应用程序：
- en: '![](img/00140.jpeg)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00140.jpeg)'
- en: Recommendation engines have been around for a long time and were used in early
    e-commerce systems of the 1990s, using techniques ranging from hardcoded product
    association to content-based recommendations driven by profiling. The modern systems
    use **collaboration filtering** (**CF**) to address the shortcomings of the early
    systems and also to address the scale and latency (for example, 100 ms max and
    less) that is necessary to compete in modern commerce systems (for example, Amazon,
    Netflix, eBay, News, and so on).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐引擎已经存在很长时间，并且在20世纪90年代的早期电子商务系统中使用，使用的技术范围从硬编码产品关联到基于内容的推荐，由个人资料驱动。现代系统使用协同过滤（CF）来解决早期系统的缺点，并解决现代商业系统（例如亚马逊、Netflix、eBay、新闻等）中必须竞争的规模和延迟（例如，最大100毫秒及以下）。
- en: The modern systems use CF based on historical interactions and records (page
    view, purchases, rating, and so on). These systems address two major issues, mainly
    scalability and sparseness (that is, we do not have all the ratings for all movies
    or songs). Most systems use a variation of Alternating Least Square with Weighted
    Lambda Regularization that can be parallelized on most major platforms (for example,
    Spark). Having said that, a practical system implemented for commercial purposes
    uses many augmentations to deal with bias (that is, not all movies and users are
    equal) and temporal issues (that is, users' choice will change and the inventory
    of items will change) that are present in today's ecosystem. Having worked on
    a smart and leading edge e-commerce system, building a competitive recommender
    is not a purist approach, but a practical one that uses multiple techniques, arriving
    at the affinity matrix/heat map as the context utilizing all three techniques
    (collaborative filtering, content-based filtering, and similarity) at the minimum.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 现代系统使用基于历史互动和记录的协同过滤（CF）（页面浏览、购买、评分等）。这些系统主要解决两个主要问题，即可扩展性和稀疏性（也就是说，我们并没有所有电影或歌曲的所有评分）。大多数系统使用交替最小二乘法与加权λ正则化的变体，可以在大多数主要平台上并行化（例如Spark）。话虽如此，为了商业目的实施的实际系统使用许多增强功能来处理偏见（也就是说，并非所有电影和用户都是平等的）和时间问题（也就是说，用户的选择会改变，物品的库存也会改变），这些问题存在于今天的生态系统中。在智能和领先的电子商务系统上工作过后，构建一个有竞争力的推荐系统并不是一种纯粹的方法，而是一种实用的方法，它使用多种技术，最少使用协同过滤、基于内容的过滤和相似性这三种技术，以亲和矩阵/热图作为上下文。
- en: The reader is encouraged to look up white papers and material that refer to
    the problem of cold start in recommendation systems.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 鼓励读者查阅有关推荐系统中冷启动问题的白皮书和资料。
- en: To set the context, the following figure provides a high-level taxonomy of methods
    that are available to build recommendation systems. We briefly cover some of the
    pros and cons of each system, but concentrate on matrix factorization (latent
    factor model) that is available in Spark. While both **single value decomposition** (**SVD**)
    and **alternative least squares** (**ALS**) are available, we concentrate on ALS
    implementation with MovieLens data due to the shortcomings of SVD in handling
    missing data among other things. We will explore SVD in detail in [Chapter 11](part0494.html#EN3LS0-4d291c9fed174a6992fd24938c2f9c77), *Curse
    of High-Dimensionality in Big Data*.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 为了设定背景，以下图表提供了可用于构建推荐系统的方法的高级分类。我们简要介绍了每种系统的优缺点，但集中讨论了在Spark中可用的矩阵分解（潜在因子模型）。虽然**单值分解**（**SVD**）和**交替最小二乘法**（**ALS**）都可用，但由于SVD在处理缺失数据等方面的缺点，我们集中讨论了MovieLens数据中的ALS实现。我们将在[第11章](part0494.html#EN3LS0-4d291c9fed174a6992fd24938c2f9c77)中详细探讨SVD，*大数据中的高维度问题*。
- en: '![](img/00141.gif)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00141.gif)'
- en: The recommendation engine techniques in use are explained in the following section.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 下一节将解释所使用的推荐引擎技术。
- en: Content filtering
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 内容过滤
- en: Content filtering is one of the original techniques for recommendation engines.
    It relies on user profiles to make recommendations. This approach relies mostly
    on pre-existing profiles for users (type, demographics, income, geo-location,
    ZIP code) and inventory (characteristics of a product, movie, or a song) to infer
    attribution which then can be filtered and acted upon. The main issue is that
    the pre-existing knowledge is often incomplete and expensive to source. This technique
    is more than a decade old and is still being practiced.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 内容过滤是推荐引擎的最初技术之一。它依赖于用户档案来进行推荐。这种方法主要依赖于用户的预先存在的档案（类型、人口统计学、收入、地理位置、邮政编码）和库存的特征（产品、电影或歌曲的特征）来推断属性，然后进行过滤和采取行动。主要问题是预先存在的知识通常是不完整的并且获取成本高昂。这种技术已有十多年历史，但仍在使用中。
- en: Collaborative filtering
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 协同过滤
- en: Collaborative filtering is the workhorse of modern recommendation systems and
    relies on user interaction in the ecosystem rather than profiles to make recommendations.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 协同过滤是现代推荐系统的主要工具，它依赖于生态系统中用户的互动而不是档案来进行推荐。
- en: This technique relies on past user behavior and product ratings and does not
    assume any pre-existing knowledge. In short, users rate the inventory items and
    the assumption is that customer taste will remain relatively constant over time,
    which can be exploited to provide recommendations. Having said that, an intelligent
    system will augment and reorder recommendations with any available context (for
    example, the user is a female who has logged in from China).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这种技术依赖于过去的用户行为和产品评分，并不假设任何预先存在的知识。简而言之，用户对库存商品进行评分，假设是客户口味随时间相对稳定，这可以被利用来提供推荐。话虽如此，一个智能系统将会根据任何可用的上下文（例如，用户是从中国登录的女性）来增强和重新排序推荐。
- en: The main issue with this class of techniques is cold start, but its advantages
    of being domain free, with more accuracy and easy scalability, has made it a winner
    in the age of big data.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这类技术的主要问题是冷启动，但其无领域限制、更高的准确性和易扩展性的优势使其在大数据时代成为赢家。
- en: Neighborhood method
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 邻域方法
- en: This technique is mostly implemented as **weighted local neighborhood**. In
    its core, it is a similarity technique and relies heavily on assumptions about
    items and users. While it is easy to understand and implement the technique, the
    algorithm suffers from a lack of scalability and accuracy.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这种技术主要作为**加权本地邻域**实现。在其核心，它是一种相似性技术，且在对商品和用户的假设上依赖较多。虽然这种技术易于理解和实现，但该算法在可扩展性和准确性方面存在缺陷。
- en: Latent factor models techniques
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 潜在因子模型技术
- en: This technique attempts to explain users' ratings of inventory items (for example,
    products on Amazon) by inferring a secondary set of latent factors which are inferred
    from ratings. The power comes from the fact that you do not need to know the factors
    ahead of time (similar to PCA techniques), but they are simply inferred from the
    ratings themselves. We derive the latent factors using matrix factorization techniques
    which are popular due to the extreme scalability, accuracy of predictions, and
    flexibility (they allow for bias and the temporal nature of the user and inventory).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这种技术试图通过推断从评分中推断出的次要潜在因子集来解释用户对库存商品（例如，亚马逊上的产品）的评分。其优势在于不需要提前了解这些因子（类似于PCA技术），而是仅仅从评分中推断出来。我们使用矩阵分解技术来推导潜在因子，这种技术因其极端的可扩展性、预测的准确性和灵活性（允许偏差和用户和库存的时间特性）而备受欢迎。
- en: '**Singular Value Decomposition (SVD)**: SVD has been available in Spark from
    the early days, but we recommend not to use it as a core technique due to the
    problem of its ability to deal with sparseness of data in real life (for example,
    a user will not usually rate everything), overfitting, and order (do we really
    need to produce the bottom 1,000 recommendations?).'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**奇异值分解（SVD）**：SVD从早期就在Spark中可用，但由于其在处理现实生活中数据稀疏性（例如，用户通常不会对所有东西进行评分）、过拟合和顺序（我们真的需要生成底部的1,000个推荐吗？）等问题，我们建议不将其作为核心技术使用。'
- en: '**Stochastic Gradient Decent** (**SGD**): SGD is easy to implement and has
    faster running times due to its approach of looking at one movie and one user/item
    vector at a time (pick a movie and update the profile a little bit for that user
    versus a batch approach). We can implement this using the matrix facility and
    SGD in Spark as needed.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**随机梯度下降**（**SGD**）：SGD易于实现，并且由于其一次查看一个电影和一个用户/商品向量的方法（选择一个电影并为该用户更新配置文件），因此具有更快的运行时间。我们可以根据需要在Spark中使用矩阵设施和SGD来实现这一点。'
- en: '**Alternating Least Square** (**ALS**): Please see ALS before you take on this
    journey. Available in Spark, ALS can take advantage of parallelization from the
    start. Spark implements full matrix factorization under the hood, contrary to
    the common belief that Spark uses half factorization. We encourage the reader
    to refer to the source code to verify this for themselves. Spark provides API
    for both **explicit** (rating available) and **implicit** (an indirect inference
    needed--for example, the length of time a track is played rather than a rating).
    We discuss the bias and temporal issues in the recipe itself, by introducing mathematics
    and intuition to make our point.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**交替最小二乘法**（**ALS**）：在开始这个旅程之前，请参阅ALS。在Spark中，ALS可以从一开始就利用并行化。Spark在内部实现了完整的矩阵分解，与常见的观点相反，即Spark使用了一半的分解。我们鼓励读者参考源代码，以验证这一点。Spark提供了用于**显式**（可用评分）和**隐式**（需要间接推断的）的API，例如，播放曲目的时间长度而不是评分。我们通过在示例中引入数学和直觉来讨论偏差和时间问题，以阐明我们的观点。'
- en: Setting up the required data for a scalable recommendation engine in Spark 2.0
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Spark 2.0中设置可扩展推荐引擎所需的数据
- en: In this recipe, we examine downloading the MovieLens public dataset and take
    a first exploratory view of the data. We will use the explicit data based on customer
    ratings from the MovieLens dataset. The MovieLens dataset contains 1,000,000 ratings
    of 4,000 movies from 6,000 users.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将检查下载MovieLens公共数据集，并首次探索数据。我们将使用MovieLens数据集中基于客户评分的显式数据。MovieLens数据集包含来自6,000个用户对4,000部电影的1,000,000个评分。
- en: 'You will need one of the following command line tools to retrieve the specified
    data: `curl` (recommended for Mac) or `wget` (recommended for Windows or Linux).'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 您将需要以下一种命令行工具来检索指定的数据：`curl`（Mac推荐）或`wget`（Windows或Linux推荐）。
- en: How to do it...
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'You can start with downloading the dataset using either of the following commands:'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您可以使用以下任一命令开始下载数据集：
- en: '[PRE0]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'You can also use the following command:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以使用以下命令：
- en: '[PRE1]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Now you need to decompress the ZIP:'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在您需要解压缩ZIP：
- en: '[PRE2]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The command will create a directory named `ml-1m` with data files decompressed
    inside.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 该命令将创建一个名为`ml-1m`的目录，并在其中解压缩数据文件。
- en: 'Change into the directory `m1-1m`:'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 切换到`m1-1m`目录：
- en: '[PRE3]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now we begin our first steps of data exploration by verifying how the data
    in `movies.dat` is formatted:'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们开始通过验证`movies.dat`中的数据格式来进行数据探索的第一步：
- en: '[PRE4]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Now we take a look at the ratings data to know how it is formatted:'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们来看一下评分数据，了解它的格式：
- en: '[PRE5]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: How it works...
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: The MovieLens dataset is an excellent alternative to the original Netflix KDD
    cup dataset. This dataset comes in multiple sets ranging from small (100 K set)
    to large (1 M and 20 M set). For those users interested in tweaking the source
    code to add their own augmentation (for example, the change regularization technique),
    the range of the dataset makes it easy to study the scaling effect and look at
    the performance curve versus Spark utilization per executive, as the data scales
    from 100 K to 20 M.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: MovieLens数据集是原始Netflix KDD杯数据集的一个很好的替代品。该数据集包含多个集合，从小（100K集）到大（1M和20M集）。对于那些有兴趣调整源代码以添加自己的增强（例如，更改正则化技术）的用户来说，数据集的范围使得研究从100K到20M的数据规模效果和Spark利用率与执行者性能曲线变得容易。
- en: The URL to download is [http://grouplens.org/datasets/movielens/](http://grouplens.org/datasets/movielens/).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 下载的URL是[http://grouplens.org/datasets/movielens/](http://grouplens.org/datasets/movielens/)。
- en: There's more...
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: Take a closer look at where we downloaded the data from, because more datasets
    are available for use at [http://files.grouplens.org/datasets/](http://files.grouplens.org/datasets/).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 仔细查看我们从哪里下载数据，因为在[http://files.grouplens.org/datasets/](http://files.grouplens.org/datasets/)上还有更多数据集可供使用。
- en: The following figure depicts the size and extent of the data. For this chapter,
    we use the small set so it can easily run on a small laptop with limited resources.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表描述了数据的大小和范围。在本章中，我们使用小数据集，因此它可以轻松运行在资源有限的小型笔记本电脑上。
- en: '![](img/00142.jpeg)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00142.jpeg)'
- en: 'Source: MovieLens'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：MovieLens
- en: See also
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: Please read through the README file contained within the directory that you
    unzipped the data to. The README file contains information about data file formats
    and data descriptions.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 请阅读解压数据的目录中包含的README文件。README文件包含有关数据文件格式和数据描述的信息。
- en: There is also a MovieLens genome tag set that can be used for reference.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一个MovieLens基因标签集，可用于参考。
- en: Computed tag-movie 11 million
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算标签电影1100万
- en: Relevance scores from a pool of 1,100 tags
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从1100个标签中获取相关性分数
- en: Applied to 10,000 movies
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用于10000部电影
- en: For those interested in exploring the original Netflix dataset, please see the
    [http://academictorrents.com/details/9b13183dc4d60676b773c9e2cd6de5e5542cee9a](http://academictorrents.com/details/9b13183dc4d60676b773c9e2cd6de5e5542cee9a) URL.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 对于那些有兴趣探索原始Netflix数据集的用户，请参阅[http://academictorrents.com/details/9b13183dc4d60676b773c9e2cd6de5e5542cee9a](http://academictorrents.com/details/9b13183dc4d60676b773c9e2cd6de5e5542cee9a) URL。
- en: Exploring the movies data details for the recommendation system in Spark 2.0
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Spark 2.0中探索用于推荐系统的电影数据细节
- en: In this recipe, we will begin to explore the movie data file by parsing data
    into a Scala `case` class and generating a simple metric. The key here is to acquire
    an understanding of our data, so in the later stages, if nebulous results arise,
    we will have some insight to make an informed conclusion about the correctness
    of our results.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将开始通过将数据解析为Scala `case`类并生成一个简单的度量来探索电影数据文件。关键在于获得对我们的数据的理解，因此在后期阶段，如果出现模糊的结果，我们将有一些见解，以便对我们结果的正确性做出知情的结论。
- en: This is the first of the two recipes which explore the movie dataset. Data exploration
    is an important first step in statistical analysis and machine learning.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这是探索电影数据集的两个示例中的第一个。数据探索是统计分析和机器学习中的重要第一步。
- en: One of the best ways to understand the data quickly is to generate a data visualization
    of it, and we will use JFreeChart to do that. It is very important to make sure
    you feel comfortable with the data and understand firsthand what is in each file,
    and the story it tries to tell.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 快速了解数据的最佳方法之一是生成其数据可视化，我们将使用JFreeChart来实现这一点。确保您对数据感到舒适，并首先了解每个文件中的内容以及它试图传达的故事非常重要。
- en: We must always explore, understand, and visualize the data before we do anything
    else. Most performances and misses with ML and others systems can be traced to
    a lack of understanding of how the data is laid out and how it changes over time.
    If we look at the chart given in step 14 in this recipe, one immediately realizes
    that the distribution of movies over the years is not uniform, but skewed with
    high kurtosis. While we are not going to explore this property for optimization
    and sampling in this book, it makes an important point about the nature of the
    movie data.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们做任何其他事情之前，我们必须始终探索、理解和可视化数据。大多数机器学习和其他系统的性能和缺失都可以追溯到对数据布局及其随时间变化的理解不足。如果我们看一下这个配方中第14步中给出的图表，就会立即意识到电影随年份分布不均匀，而是呈高峰态偏斜。虽然我们不打算在本书中探索此属性以进行优化和抽样，但这一点对于电影数据的性质非常重要。
- en: How to do it...
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: Start a new project in IntelliJ or in an IDE of your choice. Make sure the necessary
    JAR files are included.
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在IntelliJ或您选择的IDE中启动一个新项目。确保包含必要的JAR文件。
- en: JFreeChart JAR can be downloaded from the [https://sourceforge.net/projects/jfreechart/files/](https://sourceforge.net/projects/jfreechart/files/) site.
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: JFreeChart JAR可以从[https://sourceforge.net/projects/jfreechart/files/](https://sourceforge.net/projects/jfreechart/files/)网站下载。
- en: Please make sure that the JFreeChart library and its dependencies (JCommon)
    are on the classpath for the chapter.
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 请确保JFreeChart库及其依赖项（JCommon）在本章的类路径上。
- en: 'We define the package information for the Scala program:'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们为Scala程序定义包信息：
- en: '[PRE6]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Import the necessary packages:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入必要的包：
- en: '[PRE7]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We now define a Scala `case class` to model movie data:'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们定义一个Scala`case class`来建模电影数据：
- en: '[PRE8]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Let''s define a function to display a JFreeChart within a window that will
    be invoked later. There are many options for charts and plots in this package
    that can be explored:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们定义一个函数，在稍后将调用它来在窗口中显示JFreeChart。此软件包中有许多图表和绘图选项可供探索：
- en: '[PRE9]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'In this step, we define a function for parsing a single line of data from the
    `movie.dat` file into our movie `case class`:'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这一步中，我们定义了一个函数，用于将`movie.dat`文件中的单行数据解析为我们的电影`case class`：
- en: '[PRE10]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We are ready to start building our `main` function, so let''s start with defining
    the location of our `movie.dat` file:'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们准备开始构建我们的`main`函数，所以让我们从定义我们的`movie.dat`文件的位置开始：
- en: '[PRE11]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Create Spark''s session object and setup configuration:'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建Spark的会话对象并设置配置：
- en: '[PRE12]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The interleaving of log messages leads to hard-to-read output; therefore, set
    the logging level to `ERROR`:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 日志消息的交错导致输出难以阅读；因此，将日志级别设置为`ERROR`：
- en: '[PRE13]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Create a dataset of all the movies from the data file:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个包含数据文件中所有电影的数据集：
- en: '[PRE14]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Group all the movies by year, released using Spark SQL:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用Spark SQL将所有电影按年份分组：
- en: '[PRE15]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We now display a histogram chart with the movies grouped by the year of release:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们显示一个按发行年份分组的直方图图表：
- en: '[PRE16]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: See the chart produced to get a good feel for the movie dataset. There are at
    least two to four other ways that data can be visualized, which can be explored
    by the reader.
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看生成的图表，以对电影数据集有一个良好的了解。读者可以探索至少另外两到四种可视化数据的方法。
- en: '![](img/00143.jpeg)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00143.jpeg)'
- en: 'We close the program by stopping the Spark session:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过停止Spark会话来关闭程序：
- en: '[PRE17]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: How it works...
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: When the program started to execute, we initialized a SparkContext in our driver
    program to start the task of processing the data. This implies that the data must
    fit in the driver's memory (user's station), which is not a server requirement
    in this case. Alternative methods of divide and conquer must be devised to deal
    with extreme datasets (partial retrieval and the assembly at destination).
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 当程序开始执行时，我们在驱动程序中初始化了一个SparkContext，以开始处理数据的任务。这意味着数据必须适合驱动程序的内存（用户站点），这在这种情况下不是服务器要求。必须设计替代的分割和征服方法来处理极端数据集（部分检索和在目的地进行组装）。
- en: We continued by loading and parsing the data file into a dataset with the data
    type of the movies. The movie dataset was then grouped by year, yielding a map
    of movies keyed by year, with buckets of associated movies attached.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们继续加载和解析数据文件，将其转换为具有电影数据类型的数据集。然后，电影数据集按年份分组，生成了一个以年份为键的电影映射，附有相关电影的桶。
- en: '![](img/00144.jpeg)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00144.jpeg)'
- en: Next, we extracted the year with the count of the number of movies associated
    with the specific year to generate our histogram. We then collected the data,
    causing the entire resulting data collection to materialize on the driver, and
    passed it to JFreeChart to build the data visualization.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们提取了与特定年份关联的电影数量的年份，以生成我们的直方图。然后我们收集了数据，导致整个结果数据集在驱动程序上实现，并将其传递给JFreeChart来构建数据可视化。
- en: There's more...
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: You need to be cognizant of our use of Spark SQL because of its flexibility.
    More information is available at [http://spark.apache.org/docs/latest/sql-programming-guide.html#running-sql-queries-programmatically](http://spark.apache.org/docs/latest/sql-programming-guide.html#running-sql-queries-programmatically).
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 由于其灵活性，您需要注意我们对Spark SQL的使用。更多信息可在[http://spark.apache.org/docs/latest/sql-programming-guide.html#running-sql-queries-programmatically](http://spark.apache.org/docs/latest/sql-programming-guide.html#running-sql-queries-programmatically)上找到。
- en: See also
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: For more on using JFreechart, refer to the JFreeChart API documentation at [http://www.jfree.org/jfreechart/api.html](http://www.jfree.org/jfreechart/api.html).
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 有关使用JFreechart的更多信息，请参阅JFreeChart API文档[http://www.jfree.org/jfreechart/api.html](http://www.jfree.org/jfreechart/api.html)。
- en: You can find a good tutorial on JFreeChart at the [http://www.tutorialspoint.com/jfreechart/](http://www.tutorialspoint.com/jfreechart/) link.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在[http://www.tutorialspoint.com/jfreechart/](http://www.tutorialspoint.com/jfreechart/)链接找到关于JFreeChart的良好教程。
- en: The link for the JFreeChart itself is [http://www.jfree.org/index.html](http://www.jfree.org/index.html).
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: JFreeChart本身的链接是[http://www.jfree.org/index.html](http://www.jfree.org/index.html)。
- en: Exploring the ratings data details for the recommendation system in Spark 2.0
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索Spark 2.0中推荐系统的评分数据细节
- en: In this recipe, we explore the data from the user/rating perspective to understand
    the nature and property of our data file. We will start to explore the ratings
    data file by parsing data into a Scala case class and generating visualization
    for insight. The ratings data will be used a little later to generate features
    for our recommendation engine. Again, we stress that the first step in any data
    science/machine learning exercise should be visualization and exploration of the
    data.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在本示例中，我们从用户/评分的角度探索数据，以了解数据文件的性质和属性。我们将开始通过将数据解析为Scala case class并生成可视化来探索评分数据文件。稍后将使用评分数据生成推荐引擎的特征。再次强调，任何数据科学/机器学习练习的第一步应该是数据的可视化和探索。
- en: Once again, the best way of understanding data quickly is to generate a data
    visualization of it, and we will use a JFreeChart scatterplot to do this. A quick
    look at the chart of *users by ratings* produced by the JFreeChart plot shows
    a resemblance to a multinomial distribution with outliers, and an increasing sparsity
    when ratings are increased in magnitude.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，快速了解数据的最佳方法是生成其数据可视化，我们将使用JFreeChart散点图来实现这一点。通过JFreeChart绘制的*用户评分*图表显示出与多项分布和异常值相似的特征，以及随着评分增加而增加的稀疏性。
- en: How to do it...
  id: totrans-112
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: Start a new project in IntelliJ or in an IDE of your choice. Make sure the necessary
    JAR files are included.
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在IntelliJ或您选择的IDE中启动一个新项目。确保包含必要的JAR文件。
- en: 'We define the package information for the Scala program:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们为Scala程序定义包信息：
- en: '[PRE18]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Import the necessary packages:'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入必要的包：
- en: '[PRE19]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'We now define a Scala `case class` to model the ratings data:'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们定义一个Scala `case class`来建模评分数据：
- en: '[PRE20]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Let''s define a function to display a JFreeChart within a window:'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们定义一个函数，在窗口中显示一个JFreeChart：
- en: '[PRE21]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'In this step, we define a function for parsing a single line of data from the
    `ratings.dat` file into the rating `case class`:'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在此步骤中，我们定义了一个函数，用于将`ratings.dat`文件中的单行数据解析为评分`case class`：
- en: '[PRE22]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'We are ready to begin building our `main` function, so let''s start with the
    location of our `ratings.dat` file:'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们准备开始构建我们的`main`函数，所以让我们从我们的`ratings.dat`文件的位置开始：
- en: '[PRE23]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Create Spark''s configuration, SparkSession. In this example, we show for the
    first time how to set the Spark executor memory (for example, 2 gig) on a small
    laptop. You must increase this allocation if you want to use the large dataset
    (the 144 MB set):'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建Spark的配置，SparkSession。在本例中，我们首次展示如何在小型笔记本电脑上设置Spark执行器内存（例如2GB）。如果要使用大型数据集（144MB集），必须增加此分配：
- en: '[PRE24]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The interleaving of log messages leads to hard to-read output; therefore, set
    the logging level to `ERROR`:'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 日志消息的交错导致输出难以阅读；因此，将日志级别设置为`ERROR`：
- en: '[PRE25]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Create a dataset of all the ratings from the data file:'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个包含数据文件中所有评分的数据集：
- en: '[PRE26]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Now we convert the ratings dataset into a memory table view, where we can execute
    the Spark SQL query:'
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们将评分数据集转换为内存表视图，可以在其中执行Spark SQL查询：
- en: '[PRE27]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'We now produce a list of all user ratings grouped by user, with their totals:'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们生成一个按用户分组的所有用户评分列表，以及它们的总数：
- en: '[PRE28]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'From the console output:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 从控制台输出：
- en: '![](img/00145.gif)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00145.gif)'
- en: Display a scatterplot chart with ratings per user. We choose a scatterplot to
    demonstrate a different way to look at the data from the previous recipe. We encourage
    readers to explore standardization techniques (for example, remove mean) or a
    volatility varying regime (for example, GARCH) to explore the autoregressive conditional
    heteroscedasticity property of this dataset (which is beyond the scope of this
    book). The reader is advised to consult any advanced time series book to develop
    an understanding of time varying volatility of the time series and how to correct
    this before usage.
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 显示一个散点图表，显示每个用户的评分。我们选择散点图来展示从上一个示例中不同的数据观察方式。我们鼓励读者探索标准化技术（例如，去除均值）或波动性变化制度（例如，GARCH）来探索此数据集的自回归条件异方差性质（这超出了本书的范围）。建议读者参考任何高级时间序列书籍，以了解时间变化波动性和如何在使用之前进行纠正。
- en: '[PRE29]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Display the chart:'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 显示图表：
- en: '[PRE30]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '![](img/00146.jpeg)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00146.jpeg)'
- en: 'We close the program by stopping the Spark session:'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过停止Spark会话来关闭程序：
- en: '[PRE31]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: How it works...
  id: totrans-145
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: We began by loading and parsing the data file into a dataset with the data type
    ratings, and finally converted it to a DataFrame. The DataFrame was then used
    to execute a Spark SQL query that grouped all the ratings by user with their totals.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先加载和解析数据文件，将其转换为具有数据类型评分的数据集，最后将其转换为DataFrame。然后使用DataFrame执行了一个Spark SQL查询，按用户对其总数对所有评分进行了分组。
- en: We explored Dataset/DataFrame in Chapter 3, *Spark's Three Data Musketeers for
    Machine Learning - Perfect Together*, but we encourage the user to refresh and
    dig deeper into the Dataset/DataFrame API. A full understanding of the API and
    its concepts (lazy instantiation, staging, pipelining, and caching) is critical
    for every Spark developer.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在第3章“Spark的三大数据武士——机器学习完美结合”中探索了数据集/DataFrame，但我们鼓励用户刷新并深入了解数据集/DataFrame
    API。对API及其概念（延迟实例化、分阶段、流水线和缓存）的充分理解对每个Spark开发人员至关重要。
- en: '![](img/00147.jpeg)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00147.jpeg)'
- en: Finally, we passed the result set of data to the JFreeChart scatterplot component
    to display our chart.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将结果集传递给JFreeChart散点图组件以显示我们的图表。
- en: There's more...
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: A Spark DataFrame is a distributed collection of data organized into named columns.
    All DataFrame operations are also automatically parallelized and distributed on
    clusters. Also, DataFrames are lazily evaluated like RDDs.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: Spark DataFrame是一个分布式的数据集合，组织成命名列。所有DataFrame操作也会自动并行化和分布在集群上。此外，DataFrame像RDD一样是惰性评估的。
- en: See also
  id: totrans-152
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: Documentation on DataFrames can be found at [http://spark.apache.org/docs/latest/sql-programming-guide.html](http://spark.apache.org/docs/latest/sql-programming-guide.html).
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 可以在[http://spark.apache.org/docs/latest/sql-programming-guide.html](http://spark.apache.org/docs/latest/sql-programming-guide.html)找到有关DataFrame的文档。
- en: A good tutorial on JFreeChart can be found at the [http://www.tutorialspoint.com/jfreechart/](http://www.tutorialspoint.com/jfreechart/) linking.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 可以在[http://www.tutorialspoint.com/jfreechart/](http://www.tutorialspoint.com/jfreechart/)找到关于JFreeChart的很好的教程。
- en: JFreeChart can be downloaded from the [http://www.jfree.org/index.html](http://www.jfree.org/index.html) URL.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: JFreeChart可以从[http://www.jfree.org/index.html](http://www.jfree.org/index.html) URL下载。
- en: Building a scalable recommendation engine using collaborative filtering in Spark
    2.0
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Spark 2.0中构建可扩展的协同过滤推荐引擎
- en: In this recipe, we will be demonstrating a recommendation system that utilizes
    a technique known as collaborative filtering. At the core, collaborative filtering
    analyzes the relationship between users themselves and the dependencies between
    the inventory (for example, movies, books, news articles, or songs) to identify
    user-to-item relationships based on a set of secondary factors called **latent
    factors** (for example, female/male, happy/sad, active/passive). The key here
    is that you do not need to know the latent factors in advance.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将演示一个利用协同过滤技术的推荐系统。在核心上，协同过滤分析用户之间的关系以及库存之间的依赖关系（例如，电影、书籍、新闻文章或歌曲），以识别基于一组称为**潜在因素**的次要因素的用户与项目之间的关系（例如，女性/男性，快乐/悲伤，活跃/
    pass）。关键在于您不需要提前知道潜在因素。
- en: The recommendation will be produced via the ALS algorithm which is a collaborative
    filtering technique. At a high level, collaborative filtering entails making predictions
    of what a user may be interested in based on collecting previously known preferences,
    combined with the preferences of many other users. We will be using the ratings
    data from the MovieLens dataset and will convert it into input features for the
    recommendation algorithm.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐将通过ALS算法生成，这是一种协同过滤技术。在高层次上，协同过滤涉及根据收集到的先前已知偏好以及许多其他用户的偏好来预测用户可能感兴趣的内容。我们将使用MovieLens数据集的评分数据，并将其转换为推荐算法的输入特征。
- en: How to do it...
  id: totrans-159
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: Start a new project in IntelliJ or in an IDE of your choice. Make sure the necessary
    JAR files are included.
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在IntelliJ或您选择的IDE中开始一个新项目。确保包含必要的JAR文件。
- en: 'We define the package information for the Scala program:'
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们为Scala程序定义包信息：
- en: '[PRE32]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Import the necessary packages:'
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入必要的包：
- en: '[PRE33]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'We now define two Scala case classes, to model movie and ratings data:'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们定义两个Scala案例类，来建模电影和评分数据：
- en: '[PRE34]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'In this step, we define functions for parsing a single line of data from the
    `ratings.dat` file into the ratings `case class`, and for parsing a single line
    of data from the `movies.dat` file into the movie `case class`:'
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这一步中，我们定义了用于将`ratings.dat`文件中的单行数据解析为评分`case class`的函数，以及用于将`movies.dat`文件中的单行数据解析为电影`case
    class`的函数：
- en: '[PRE35]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'We are ready to begin building our `main` function, so let''s start with the
    locations of the `movie.dat` and `ratings.dat` file:'
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们准备开始构建我们的`main`函数，所以让我们从`movie.dat`和`ratings.dat`文件的位置开始：
- en: '[PRE36]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Create a SparkSession object and its related configuration:'
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个SparkSession对象及其相关配置：
- en: '[PRE37]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'The interleaving of log messages leads to hard-to-read output; therefore, set
    the logging level to `ERROR`:'
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 日志消息的交错导致输出难以阅读；因此，将日志级别设置为`ERROR`：
- en: '[PRE38]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Create a dataset of all the ratings and register it as a temporary view in
    memory so it can be queried with SQL:'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建所有评分的数据集，并将其注册为内存中的临时视图，以便可以使用SQL进行查询：
- en: '[PRE39]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Execute the SQL query against the view:'
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对视图执行SQL查询：
- en: '[PRE40]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'From the console output:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 从控制台输出：
- en: '![](img/00148.gif)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00148.gif)'
- en: 'We categorize the ratings data into training and test datasets. The training
    data will be used to train the alternate least squares recommendation machine
    learning algorithm, and the test data will be used later to evaluate the accuracy
    between the predictions and the test data:'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将评分数据分类为训练和测试数据集。训练数据将用于训练交替最小二乘推荐机器学习算法，而测试数据将稍后用于评估预测和测试数据之间的准确性：
- en: '[PRE41]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Now create a fictitious user with a user ID of zero, generating a dataset of
    several ratings. This user will allow us later to better understand the predictions
    computed by the ALS algorithm:'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在创建一个虚构的用户，用户ID为零，生成几个评分的数据集。稍后这个用户将帮助我们更好地理解ALS算法计算的预测：
- en: '[PRE42]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Append `testWithOurUser` to the original training set utilizing the dataset
    union method. Also, use the `unpersist` method on the original training set and
    the test set of free resources:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用数据集联合方法将`testWithOurUser`附加到原始训练集。还要在原始训练集和测试集上使用`unpersist`方法释放资源：
- en: '[PRE43]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Create the ALS object and set up the parameters.
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建ALS对象并设置参数。
- en: Use the train dataset to get the model.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 使用训练数据集获取模型。
- en: '[PRE44]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'We let the model work on the test dataset:'
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让模型在测试数据集上运行：
- en: '[PRE45]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'From the console output:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 从控制台输出：
- en: '![](img/00149.gif)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00149.gif)'
- en: 'Build an in-memory table which has all the predictions for the Spark SQL query:'
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建一个内存表，其中包含Spark SQL查询的所有预测：
- en: '[PRE46]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Retrieve the ratings and predictions from the table and display the first 20
    rows in the console:'
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从表中检索评分和预测，并在控制台中显示前20行：
- en: '[PRE47]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'From the console output:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 从控制台输出：
- en: '![](img/00150.gif)'
  id: totrans-199
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00150.gif)'
- en: 'Now get a specific user''s movie prediction:'
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在获取特定用户的电影预测：
- en: '[PRE48]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'From the console output:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 从控制台输出：
- en: '![](img/00151.gif)'
  id: totrans-203
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00151.gif)'
- en: 'We close the program by stopping the Spark session:'
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过停止Spark会话来关闭程序：
- en: '[PRE49]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: How it works...
  id: totrans-206
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: Due to the complex nature of the program, we provide a conceptual explanation
    and then proceed to explain the details of the program.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 由于程序的复杂性，我们提供了一个概念性的解释，然后继续解释程序的细节。
- en: 'The following figure depicts a conceptual view of ALS and how it factorizes
    the user/movie/rating matrix, which is a high-ranking order matrix to a lower
    order tall and skinny matrix, and a vector of latent factors: f(users) and f(movies).'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示了ALS的概念视图以及它是如何将用户/电影/评分矩阵进行因式分解的，这是一个高阶矩阵，分解为一个较低阶的高瘦矩阵和一个潜在因素的向量：f(用户)和f(电影)。
- en: '![](img/00152.jpeg)'
  id: totrans-209
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00152.jpeg)'
- en: 'Another way to think about it is that these factors can be used to place the
    movie in an *n* dimensional space that will be matched to a given recommendation
    for a given user. It is always desirable to view machine learning as a search
    query in a dimensional variable space. The point to remember is that the latent
    factor (learned geometry space) is not pre-defined and can be as low as 10 to
    100 or 1,000 depending on what is being searched or factorized. Our recommendation,
    then, can be viewed as placing a probability mass within the n-dimensional space.
    The following figure provides an extremely simplified view of a possible two-factor
    model (two-dimensional) to demonstrate the point:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种思考方式是，这些因素可以用来将电影放置在一个*n*维空间中，以便与给定用户的推荐匹配。将机器学习视为在一个维度变量空间中进行搜索查询总是令人满意的。要记住的是，潜在因素（学习的几何空间）并非预先定义，可以低至10到100或1000，具体取决于正在搜索或进行因式分解的内容。因此，我们的推荐可以被视为在n维空间中放置概率质量。以下图提供了一个可能的两因子模型（二维）的极其简化的视图，以证明这一点：
- en: '![](img/00153.jpeg)'
  id: totrans-211
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00153.jpeg)'
- en: 'While the implementation of ALS can vary a bit from system to system, at its
    core it is an iterative full-factorization method (in Spark) with weighed regularization.
    Spark''s documentation and tutorials provide an insight into the actual math and
    the nature of the algorithm. It depicts the algorithm as follows:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然ALS的实现在不同系统中可能有所不同，但在其核心是一个带有加权正则化的迭代全因子分解方法（在Spark中）。Spark的文档和教程提供了对实际数学和算法性质的见解。它描述了算法如下：
- en: '![](img/00154.jpeg)'
  id: totrans-213
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00154.jpeg)'
- en: The best way to understand this formula/algorithm is to think of it as an iterating
    apparatus which is trying to discover the latent factors by alternating between
    inputs (that is, fix one of the inputs and then approximate/optimize the other--and
    then back and forth), while trying to minimize the least square error (MSE) with
    respect to a regularization penalty of weighted lambda. A more detailed explanation
    is provided in the next section.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 理解这个公式/算法的最佳方法是将其视为一个迭代装置，它通过在输入之间交替（即固定一个输入，然后近似/优化另一个输入，然后来回进行），试图发现潜在因素，同时试图最小化与加权lambda的正则化惩罚相关的最小二乘误差（MSE）。更详细的解释将在下一节中提供。
- en: 'The program flow is as follows:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 程序流程如下：
- en: The example started by loading the ratings and movie data from the MovieLens
    dataset. The loaded data was then transformed into Scala case classes for further
    processing. The next step was to partition the ratings data into a training set
    and test set. The training set data was used to train the machine learning algorithm.
    Training is the process in machine learning used to build a model so it can provide
    the appropriate results needed. The test data will be used to validate the results
    in the final step.
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 示例从MovieLens数据集中加载了评分和电影数据。加载的数据随后被转换为Scala案例类以进行进一步处理。下一步是将评分数据分成训练集和测试集。训练集数据用于训练机器学习算法。训练是机器学习中用于构建模型以便提供所需结果的过程。测试数据将用于验证最终结果。
- en: The fictitious users, or user ID zero, step configured a single user not included
    in the original dataset to help lend insight to the results by creating a dataset
    on the fly with random information, and finally appending it to the training set.
    The ALS algorithm was invoked by passing the training set data to it, comprised
    of the user ID, movie ID, and rating, subsequently yielding a matrix factorization
    model from Spark. The prediction generation was performed for the user ID zero
    and test dataset.
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 虚构的用户，或者用户ID为零，配置了一个未包含在原始数据集中的单个用户，以帮助通过在现有数据集上创建一个包含随机信息的数据集，并最终将其附加到训练集中，从而为结果提供见解。然后，通过将训练集数据传递给ALS算法，包括用户ID、电影ID和评分，从Spark中产生了一个矩阵因子分解模型。对用户ID为零和测试数据集进行了预测生成。
- en: The final results were displayed by combining rating information with the movie
    data so the results could be understood and displayed in the original rating next
    to the estimated rating. The final step was to compute the root mean squared error
    of the generated rating, with the existing rating contained within the test dataset.
    The RMSE will tell us how accurate the train model is.
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最终结果是通过将评分信息与电影数据相结合，以便在原始评分旁边理解和显示结果。最后一步是计算生成评分的均方根误差，其中包含在测试数据集中的现有评分。RMSE将告诉我们训练模型的准确性。
- en: There's more...
  id: totrans-219
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: People often struggle with ALS even though at its core it is a simple linear
    algebra operation with an added regularization penalty. What makes ALS powerful
    is its ability to be parallelized and to deal with scale (for example, Spotify).
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管在本质上ALS是一个带有额外正则化惩罚的简单线性代数运算，但人们经常在处理ALS时遇到困难。ALS之所以强大，是因为它能够并行化处理规模（例如Spotify）。
- en: 'ALS in layman''s language involves the following:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 用通俗的语言来说，ALS涉及以下内容：
- en: With ALS, you basically want to factorize a large matrix of ratings X (100 million
    plus users is not a stretch at all) and user product ratings into two matrices
    of A and B, with lower ranks (see any introductory linear algebra book). The problem
    is that it often becomes a very hard non-linear optimization problem to solve.
    To remedy with ALS, you introduce a simple solution (**A** for **Alternating**)
    in which you fix one of the matrices and partially solve the other leg (the other
    matrix) using the least square methods for optimization (**LS** stands for **Least
    Square**). Once this step is complete, you then alternate, but this time you fix
    the second leg (matrix) and solve the first.
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用ALS，基本上要对评级矩阵X（1亿多用户根本不是问题）和用户产品评级进行因式分解为A和B两个矩阵，其秩较低（参见任何入门线性代数书）。问题在于，通常它变成了一个非常难解的非线性优化问题。为了解决ALS，引入了一个简单的解决方案（**A**代表**Alternating**），其中你固定其中一个矩阵并部分解决另一个（另一个矩阵）使用最小二乘法进行优化（**LS**代表**Least
    Square**）。一旦这一步完成，然后交替进行，但这次你固定第二个矩阵并解决第一个。
- en: To control overfitting, we introduce a regularization leg to the original equation.
    This step is usually a weighted regularization and is controlled by a parameter
    lambda that controls the amount of penalty or flattening.
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了控制过拟合，我们在原方程中引入了一个正则化项。这一步通常是加权正则化，并由参数lambda控制惩罚或平滑的程度。
- en: In short, what makes this interesting is the fact that this method matrix factorization
    lends itself very well to parallel operations, which is Spark's speciality at
    its core.
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 简而言之，这一方法的矩阵因式分解非常适合并行操作，这是Spark在其核心的特长。
- en: 'For a deep understanding of the ALS algorithm, we cite two original papers
    that are considered to be classics in this area:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 为了深入理解ALS算法，我们引用了两篇被认为是这一领域经典的原始论文：
- en: From the ACM Digital Library using [http://dl.acm.org/citation.cfm?id=1608614](http://dl.acm.org/citation.cfm?id=1608614)
    link.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 从ACM数字图书馆使用[http://dl.acm.org/citation.cfm?id=1608614](http://dl.acm.org/citation.cfm?id=1608614)链接。
- en: From the IEEE Digital Library [http://ieeexplore.ieee.org/xpl/login.jsp?tp=&arnumber=5197422&url=http%3A%2F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D5197422](http://ieeexplore.ieee.org/xpl/login.jsp?tp=&arnumber=5197422&url=http%3A%2F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D5197422).
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 从IEEE数字图书馆[http://ieeexplore.ieee.org/xpl/login.jsp?tp=&arnumber=5197422&url=http%3A%2F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D5197422](http://ieeexplore.ieee.org/xpl/login.jsp?tp=&arnumber=5197422&url=http%3A%2F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D5197422)。
- en: 'The following figure shows ALS from a more mathematical view, from the original
    paper cited previously:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图显示了从数学角度更深入地理解ALS，这是之前引用的原始论文：
- en: '![](img/00155.jpeg)'
  id: totrans-229
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00155.jpeg)'
- en: 'Use the RankingMetrics metrics class to evaluate the model performance. Parameters
    are similar to classes used for evaluation (binary and multinomial) of the regression
    models:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 使用RankingMetrics类来评估模型性能。参数与用于评估回归模型（二元和多项式）的类相似：
- en: Recall
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Recall
- en: Precision
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Precision
- en: fMeasure
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: fMeasure
- en: The RankingMetrics class provided by MLlib can be used for evaluating models
    and quantifying model effectiveness.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: MLlib提供的RankingMetrics类可用于评估模型并量化模型的有效性。
- en: The RankingMetrics API documentation can be found at [http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.evaluation.RankingMetrics](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.evaluation.RankingMetrics).
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: RankingMetrics API文档可在[http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.evaluation.RankingMetrics](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.evaluation.RankingMetrics)找到。
- en: See also
  id: totrans-236
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另见
- en: 'Spark 2.0 ML documentation to explore the ALS API:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: Spark 2.0 ML文档可用于探索ALS API：
- en: '[https://spark.apache.org/docs/latest/mllib-collaborative-filtering.html](https://spark.apache.org/docs/latest/mllib-collaborative-filtering.html)'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://spark.apache.org/docs/latest/mllib-collaborative-filtering.html](https://spark.apache.org/docs/latest/mllib-collaborative-filtering.html)'
- en: '[https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.ml.recommendation.ALS](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.ml.recommendation.ALS)'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.ml.recommendation.ALS](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.ml.recommendation.ALS)'
- en: '[https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.ml.recommendation.ALSModel](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.ml.recommendation.ALSModel)'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.ml.recommendation.ALSModel](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.ml.recommendation.ALSModel)'
- en: Spark 2.0 MLlib documentation is available at [https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.recommendation.ALS](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.recommendation.ALS).
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: Spark 2.0 MLlib文档可在[https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.recommendation.ALS](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.mllib.recommendation.ALS)找到。
- en: 'ALS parameters and their default constructs an ALS instance with default parameters
    as follows:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: ALS参数及其默认构造形成了一个具有默认参数的ALS实例，如下所示：
- en: '[PRE50]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: Dealing with implicit input for training
  id: totrans-244
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理隐式输入以进行训练
- en: There are times when the actual observations (ratings) are not available and
    one must deal with implied feedback parameters. This can be as simple as which
    audio track was listened to during an engagement to how long a movie was watched,
    or the context (indexed in advance) or what caused a switch (a Netflix movie abandoned
    in the beginning, middle, or near a specific scene). The example provided in the
    third recipe deals with explicit feedback via the use of `ALS.train()`.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 有时实际观察（评级）不可用，必须处理暗示的反馈参数。这可以是简单的，比如在参与期间听哪个音轨，看了多长时间的电影，或者上下文（提前索引）或者导致切换的原因（Netflix电影在开始、中间或接近特定场景时被放弃）。第三个示例中提供的示例通过使用`ALS.train()`来处理显式反馈。
- en: The Spark ML library provides an alternative method, `ALS.trainImplicit()`,
    with four hyper parameters to control the algorithm and address the implicit data.
    If you are interested in testing this (it is very similar to the explicit method),
    you can use the 1,000,000 song dataset for easy training and prediction purposes.
    You can download the dataset for experimentation from the [http://labrosa.ee.columbia.edu/millionsong/](http://labrosa.ee.columbia.edu/millionsong/) URL.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: Spark ML库提供了一种替代方法`ALS.trainImplicit()`，有四个超参数来控制算法并解决隐式数据问题。如果您有兴趣测试这个方法（它与显式方法非常相似），您可以使用100万首歌曲数据集进行简单的训练和预测。您可以从[http://labrosa.ee.columbia.edu/millionsong/](http://labrosa.ee.columbia.edu/millionsong/) URL下载用于实验的数据集。
- en: 'The collaborative filtering pros and cons are as follows:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 协同过滤的优缺点如下：
- en: '| **Pros** | **Cons** |'
  id: totrans-248
  prefs: []
  type: TYPE_TB
  zh: '| **优点** | **缺点** |'
- en: '| Scalable | Cold start problem'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: '| 可扩展 | 冷启动问题'
- en: New items added to the inventory
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 库存中添加了新项目
- en: New users added to the ecosystem
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生态系统中添加了新用户
- en: '|'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Discovers hard to find and often illusive data properties without profiles
    | Requires a decent amount of data |'
  id: totrans-253
  prefs: []
  type: TYPE_TB
  zh: '| 发现难以找到且常常难以捉摸的数据属性，而无需配置文件 | 需要相当数量的数据 |'
- en: '| More accurate |  |'
  id: totrans-254
  prefs: []
  type: TYPE_TB
  zh: '| 更准确 |  |'
- en: '| Portable |  |'
  id: totrans-255
  prefs: []
  type: TYPE_TB
  zh: '| 便携 |  |'
