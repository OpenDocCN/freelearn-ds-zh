- en: Chapter 5. Streaming Live Data with Spark
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第5章。使用Spark进行实时数据流
- en: In this chapter, we will focus on live streaming data flowing into Spark and
    processing it. So far, we have discussed machine learning and data mining with
    batch processing. We are now looking at processing continuously flowing data and
    detecting facts and patterns on the fly. We are navigating from a lake to a river.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将专注于流入Spark并进行处理的实时流数据。到目前为止，我们已经讨论了批处理的机器学习和数据挖掘。现在我们正在处理持续流动的数据，并在飞行中检测事实和模式。我们正在从湖泊转向河流。
- en: We will first investigate the challenges arising from such a dynamic and ever
    changing environment. After laying the grounds on the prerequisite of a streaming
    application, we will investigate various implementations using live sources of
    data such as TCP sockets to the Twitter firehose and put in place a low latency,
    high throughput, and scalable data pipeline combining Spark, Kafka and Flume.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先调查在这样一个动态和不断变化的环境中出现的挑战。在奠定流应用的先决条件的基础上，我们将调查使用实时数据源（如TCP套接字到Twitter firehose）进行各种实现，并建立一个低延迟、高吞吐量和可扩展的数据管道，结合Spark、Kafka和Flume。
- en: 'In this chapter, we will cover the following points:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下几点：
- en: Analyzing a streaming application's architectural challenges, constraints, and
    requirements
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析流应用的架构挑战、约束和要求
- en: Processing live data from a TCP socket with Spark Streaming
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Spark Streaming从TCP套接字处理实时数据
- en: Connecting to the Twitter firehose directly to parse tweets in quasi real time
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 直接连接到Twitter firehose以准实时解析推文
- en: Establishing a reliable, fault tolerant, scalable, high throughput, low latency
    integrated application using Spark, Kafka, and Flume
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 建立一个可靠、容错、可扩展、高吞吐量、低延迟的集成应用，使用Spark、Kafka和Flume
- en: Closing remarks on Lambda and Kappa architecture paradigms
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关于Lambda和Kappa架构范式的结束语
- en: Laying the foundations of streaming architecture
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 奠定流架构的基础
- en: As customary, let's first go back to our original drawing of the data-intensive
    apps architecture blueprint and highlight the Spark Streaming module that will
    be the topic of interest.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 按照惯例，让我们首先回到我们最初的数据密集型应用架构蓝图，并突出Spark Streaming模块，这将是我们感兴趣的主题。
- en: The following diagram sets the context by highlighting the Spark Streaming module
    and interactions with Spark SQL and Spark MLlib within the overall data-intensive
    apps framework.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表通过突出Spark Streaming模块及其与整体数据密集型应用框架中的Spark SQL和Spark MLlib的交互来设定上下文。
- en: '![Laying the foundations of streaming architecture](img/B03968_05_01.jpg)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![奠定流架构的基础](img/B03968_05_01.jpg)'
- en: Data flows from stock market time series, enterprise transactions, interactions,
    events, web traffic, click streams, and sensors. All events are time-stamped data
    and urgent. This is the case for fraud detection and prevention, mobile cross-sell
    and upsell, or traffic alerts. Those streams of data require immediate processing
    for monitoring purposes, such as detecting anomalies, outliers, spam, fraud, and
    intrusion; and also for providing basic statistics, insights, trends, and recommendations.
    In some cases, the summarized aggregated information is sufficient to be stored
    for later usage. From an architecture paradigm perspective, we are moving from
    a service-oriented architecture to an event-driven architecture.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 数据来自股市时间序列、企业交易、互动、事件、网站流量、点击流和传感器。所有事件都是时间戳数据且紧急。这适用于欺诈检测和预防、移动交叉销售和升级，或者交通警报。这些数据流需要立即处理以进行监控，例如检测异常、异常值、垃圾邮件、欺诈和入侵；同时也需要提供基本统计数据、见解、趋势和建议。在某些情况下，汇总的聚合信息足以存储以供以后使用。从架构范式的角度来看，我们正在从面向服务的架构转向事件驱动的架构。
- en: 'Two models emerge for processing streams of data:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 有两种模型用于处理数据流：
- en: Processing one record at a time as they come in. We do not buffer the incoming
    records in a container before processing them. This is the case of Twitter's Storm,
    Yahoo's S4, and Google's MillWheel.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 按照记录的实时到达一个接一个地处理记录。在处理之前，我们不会将传入的记录缓冲在容器中。这是Twitter的Storm、Yahoo的S4和Google的MillWheel的情况。
- en: Micro-batching or batch computations on small intervals as performed by Spark
    Streaming and Storm Trident. In this case, we buffer the incoming records in a
    container according to the time window prescribed in the micro-batching settings.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微批处理或在小时间间隔上进行批处理计算，如Spark Streaming和Storm Trident所执行的。在这种情况下，我们根据微批处理设置中规定的时间窗口将传入的记录缓冲在一个容器中。
- en: Spark Streaming has often been compared against Storm. They are two different
    models of streaming data. Spark Streaming is based on micro-batching. Storm is
    based on processing records as they come in. Storm also offers a micro-batching
    option, with its Storm Trident option.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: Spark Streaming经常与Storm进行比较。它们是两种不同的流数据模型。Spark Streaming基于微批处理。Storm基于处理记录的实时到达。Storm还提供了微批处理选项，即其Storm
    Trident选项。
- en: The driving factor in a streaming application is latency. Latency varies from
    the milliseconds range in the case of **RPC** (short for **Remote Procedure Call**)
    to several seconds or minutes for micro batching solution such as Spark Streaming.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 流应用中的驱动因素是延迟。延迟范围从**RPC**（远程过程调用的缩写）的毫秒级到微批处理解决方案（如Spark Streaming）的几秒或几分钟。
- en: RPC allows synchronous operations between the requesting programs waiting for
    the results from the remote server's procedure. Threads allow concurrency of multiple
    RPC calls to the server.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: RPC允许请求程序之间的同步操作，等待远程服务器过程的结果。线程允许对服务器进行多个RPC调用的并发。
- en: An example of software implementing a distributed RPC model is Apache Storm.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 实现分布式RPC模型的软件示例是Apache Storm。
- en: Storm implements stateless sub millisecond latency processing of unbounded tuples
    using topologies or directed acyclic graphs combining spouts as source of data
    streams and bolts for operations such as filter, join, aggregation, and transformation.
    Storm also implements a higher level abstraction called **Trident** which, similarly
    to Spark, processes data streams in micro batches.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: Storm使用拓扑结构或有向无环图来实现无界元组的无状态亚毫秒延迟处理，结合了作为数据流源的喷口和用于过滤、连接、聚合和转换等操作的螺栓。Storm还实现了一个称为**Trident**的更高级抽象，类似于Spark，可以处理微批次数据流。
- en: So, looking at the latency continuum, from sub millisecond to second, Storm
    is a good candidate. For seconds to minutes scale, Spark Streaming and Storm Trident
    are excellent fits. For several minutes onward, Spark and a NoSQL database such
    as Cassandra or HBase are adequate solutions. For ranges beyond the hour and with
    high volume of data, Hadoop is the ideal contender.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，从亚毫秒到秒的延迟连续性来看，Storm是一个很好的选择。对于秒到分钟的规模，Spark Streaming和Storm Trident都是很好的选择。对于几分钟以上的范围，Spark和诸如Cassandra或HBase的NoSQL数据库都是合适的解决方案。对于超过一小时且数据量大的范围，Hadoop是理想的竞争者。
- en: Although throughput is correlated to latency, it is not a simple inversely linear
    relationship. If processing a message takes 2 ms, which determines the latency,
    then one would assume the throughput is limited to 500 messages per sec. Batching
    messages allows for higher throughput if we allow our messages to be buffered
    for 8 ms more. With a latency of 10 ms, the system can buffer up to 10,000 messages.
    For a bearable increase in latency, we have substantially increased throughput.
    This is the magic of micro-batching that Spark Streaming exploits.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管吞吐量与延迟相关，但它并不是简单的反比线性关系。如果处理一条消息需要2毫秒，这决定了延迟，那么人们会认为吞吐量受限于每秒500条消息。如果我们允许消息缓冲8毫秒，批处理消息可以实现更高的吞吐量。在延迟为10毫秒的情况下，系统可以缓冲高达10,000条消息。通过容忍可接受的延迟增加，我们大大提高了吞吐量。这就是Spark
    Streaming利用的微批处理的魔力。
- en: Spark Streaming inner working
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Spark Streaming内部工作
- en: The Spark Streaming architecture leverages the Spark core architecture. It overlays
    on the **SparkContext** a **StreamingContext** as the entry point to the Stream
    functionality. The Cluster Manager will dedicate at least one worker node as Receiver,
    which will be an executor with a *long task* to process the incoming stream. The
    Executor creates Discretized Streams or DStreams from input data stream and replicates
    by default, the DStream to the cache of another worker. One receiver serves one
    input data stream. Multiple receivers improve parallelism and generate multiple
    DStreams that Spark can unite or join Resilient Distributed Datasets (RDD).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: Spark Streaming架构利用了Spark核心架构。它在**SparkContext**上叠加了一个**StreamingContext**作为流功能的入口点。集群管理器将至少一个工作节点指定为接收器，这将是一个执行器，具有处理传入流的*长任务*。执行器从输入数据流创建离散化流或DStreams，并默认情况下将DStream复制到另一个工作节点的缓存中。一个接收器服务于一个输入数据流。多个接收器提高了并行性，并生成多个Spark可以合并或连接的离散分布式数据集（RDD）。
- en: The following diagram gives an overview of the inner working of Spark Streaming.
    The client interacts with the Spark Cluster via the cluster manager, while Spark
    Streaming has a dedicated worker with a long running task ingesting the input
    data stream and transforming it into discretized streams or DStreams. The data
    is collected, buffered and replicated by a receiver and then pushed to a stream
    of RDDs.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 下图概述了Spark Streaming的内部工作。客户端通过集群管理器与Spark集群交互，而Spark Streaming有一个专用的工作节点，运行长时间的任务，摄取输入数据流并将其转换为离散化流或DStreams。数据由接收器收集、缓冲和复制，然后推送到一系列RDD的流中。
- en: '![Spark Streaming inner working](img/B03968_05_02.jpg)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![Spark Streaming内部工作](img/B03968_05_02.jpg)'
- en: Spark receivers can ingest data from many sources. Core input sources range
    from TCP socket and HDFS/Amazon S3 to Akka Actors. Additional sources include
    Apache Kafka, Apache Flume, Amazon Kinesis, ZeroMQ, Twitter, and custom or user-defined
    receivers.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: Spark接收器可以从许多来源获取数据。核心输入来源包括TCP套接字和HDFS/Amazon S3到Akka Actors。其他来源包括Apache Kafka、Apache
    Flume、Amazon Kinesis、ZeroMQ、Twitter和自定义或用户定义的接收器。
- en: We distinguish between reliable resources that acknowledges receipt of data
    to the source and replication for possible resend, versus unreliable receivers
    who do not acknowledge receipt of the message. Spark scales out in terms of the
    number of workers, partition and receivers.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们区分了可靠的资源，它们确认接收到数据并进行复制以便可能的重发，与不确认消息接收的不可靠接收者。Spark在工作节点、分区和接收者方面进行了扩展。
- en: 'The following diagram gives an overview of Spark Streaming with the possible
    sources and the persistence options:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 下图概述了Spark Streaming的内部工作，以及可能的来源和持久性选项：
- en: '![Spark Streaming inner working](img/B03968_05_03.jpg)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![Spark Streaming内部工作](img/B03968_05_03.jpg)'
- en: Going under the hood of Spark Streaming
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 深入了解Spark Streaming
- en: Spark Streaming is composed of Receivers and powered by Discretized Streams
    and Spark Connectors for persistence.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: Spark Streaming由接收器组成，并由离散化流和用于持久性的Spark连接器提供支持。
- en: As for Spark Core, the essential data structure is the RDD, the fundamental
    programming abstraction for Spark Streaming is the Discretized Stream or DStream.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 至于Spark Core，其基本数据结构是RDD，而Spark Streaming的基本编程抽象是离散化流或DStream。
- en: The following diagram illustrates the Discretized Streams as continuous sequences
    of RDDs. The batch intervals of DStream are configurable.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 下图说明了离散化流作为RDD的连续序列。DStream的批次间隔是可配置的。
- en: '![Going under the hood of Spark Streaming](img/B03968_05_04.jpg)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![深入了解Spark Streaming](img/B03968_05_04.jpg)'
- en: DStreams snapshots the incoming data in batch intervals. Those time steps typically
    range from 500 ms to several seconds. The underlying structure of a DStream is
    an RDD.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: DStreams在批次间隔中快照传入的数据。这些时间步骤通常在500毫秒到几秒之间。DStream的基本结构是RDD。
- en: A DStream is essentially a continuous sequence of RDDs. This is powerful as
    it allows us to leverage from Spark Streaming all the traditional functions, transformations
    and actions available in Spark Core and allows us to dialogue with Spark SQL,
    performing SQL queries on incoming streams of data and Spark MLlib. Transformations
    similar to those on generic and key-value pair RDDs are applicable. The DStreams
    benefit from the inner RDDs lineage and fault tolerance. Additional transformation
    and output operations exist for discretized stream operations. Most generic operations
    on DStream are **transform** and **foreachRDD**.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: DStream本质上是一系列连续的RDD。这很强大，因为它允许我们利用Spark Streaming中所有传统的函数、转换和Spark Core中可用的操作，并允许我们与Spark
    SQL对话，对传入的数据流执行SQL查询，并使用Spark MLlib。类似于通用和键值对RDD上的转换是适用的。DStreams受益于内部RDD的谱系和容错性。离散流操作还存在其他转换和输出操作。大多数DStream上的通用操作是**transform**和**foreachRDD**。
- en: 'The following diagram gives an overview of the lifecycle of DStreams. From
    creation of the micro-batches of messages materialized to RDDs on which `transformation`
    function and actions that trigger Spark jobs are applied. Breaking down the steps
    illustrated in the diagram, we read the diagram top down:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表概述了DStreams的生命周期。从创建消息的微批处理到应用`transformation`函数和触发Spark作业的RDD。分解图表中的步骤，我们从上到下阅读图表：
- en: In the Input Stream, the incoming messages are buffered in a container according
    to the time window allocated for the micro-batching.
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在输入流中，传入的消息根据微批处理的时间窗口分配在容器中进行缓冲。
- en: In the discretized stream step, the buffered micro-batches are transformed as
    DStream RDDs.
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在离散化流步骤中，缓冲的微批处理被转换为DStream RDD。
- en: The Mapped DStream step is obtained by applying a transformation function to
    the original DStream. These first three steps constitute the transformation of
    the original data received in predefined time windows. As the underlying data
    structure is the RDD, we conserve the data lineage of the transformations.
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 映射的DStream步骤是通过将转换函数应用于原始DStream而获得的。这前三个步骤构成了在预定义时间窗口中接收到的原始数据的转换。由于底层数据结构是RDD，我们保留了转换的数据谱系。
- en: The final step is an action on the RDD. It triggers the Spark job.
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后一步是对RDD的操作。它触发Spark作业。
- en: '![Going under the hood of Spark Streaming](img/B03968_05_05.jpg)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![深入了解Spark Streaming](img/B03968_05_05.jpg)'
- en: Transformation can be stateless or stateful. *Stateless* means that no state
    is maintained by the program, while *stateful* means the program keeps a state,
    in which case previous transactions are remembered and may affect the current
    transaction. A stateful operation modifies or requires some state of the system,
    and a stateless operation does not.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 转换可以是无状态的或有状态的。*无状态*意味着程序不维护状态，而*有状态*意味着程序保持状态，这种情况下，先前的事务被记住并可能影响当前事务。有状态操作修改或需要系统的某些状态，而无状态操作则不需要。
- en: Stateless transformations process each batch in a DStream at a time. Stateful
    transformations process multiple batches to obtain results. Stateful transformations
    require the checkpoint directory to be configured. Check pointing is the main
    mechanism for fault tolerance in Spark Streaming to periodically save data and
    metadata about an application.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 无状态转换一次处理DStream中的每个批处理。有状态转换处理多个批次以获得结果。有状态转换需要配置检查点目录。检查点是Spark Streaming中容错的主要机制，用于定期保存有关应用程序的数据和元数据。
- en: 'There are two types of stateful transformations for Spark Streaming: `updateStateByKey`
    and windowed transformations.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: Spark Streaming有两种类型的有状态转换：`updateStateByKey`和窗口转换。
- en: '`updateStateByKey` are transformations that maintain state for each key in
    a stream of Pair RDDs. It returns a new *state* DStream where the state for each
    key is updated by applying the given function on the previous state of the key
    and the new values of each key. An example would be a running count of given hashtags
    in a stream of tweets.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '`updateStateByKey`是维护流中每个键的状态的转换。它返回一个新的*state* DStream，其中每个键的状态都通过将给定函数应用于键的先前状态和每个键的新值来更新。一个示例是在推文流中给定标签的运行计数。'
- en: Windowed transformations are carried over multiple batches in a sliding window.
    A window has a defined length or duration specified in time units. It must be
    a multiple of a DStream batch interval. It defines how many batches are included
    in a windowed transformation.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 窗口转换在滑动窗口中跨多个批次进行。窗口具有指定的长度或持续时间，以时间单位指定。它必须是DStream批处理间隔的倍数。它定义了窗口转换中包括多少批次。
- en: A window has a sliding interval or sliding duration specified in time units.
    It must be a multiple of a DStream batch interval. It defines how many batches
    to slide a window or how frequently to compute a windowed transformation.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 窗口具有指定的滑动间隔或滑动持续时间。它必须是DStream批处理间隔的倍数。它定义了滑动窗口或计算窗口转换的频率。
- en: 'The following schema depicts the windowing operation on DStreams to derive
    window DStreams with a given length and sliding interval:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 以下模式描述了在DStreams上进行窗口操作，以获得具有给定长度和滑动间隔的窗口DStreams：
- en: '![Going under the hood of Spark Streaming](img/B03968_05_06.jpg)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![深入了解Spark Streaming](img/B03968_05_06.jpg)'
- en: A sample function is `countByWindow` (`windowLength`, `slideInterval`). It returns
    a new DStream in which each RDD has a single element generated by counting the
    number of elements in a sliding window over this DStream. An illustration in this
    case would be a running count of given hashtags in a stream of tweets every 60
    seconds. The window time frame is specified.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 一个示例函数是`countByWindow`（`windowLength`，`slideInterval`）。它返回一个新的DStream，其中每个RDD都有一个由计算此DStream上的滑动窗口中的元素数量生成的单个元素。在这种情况下，一个示例是在推文流中每60秒对给定标签的运行计数。窗口时间范围是指定的。
- en: Minute scale window length is reasonable. Hour scale window length is not recommended
    as it is compute and memory intensive. It would be more convenient to aggregate
    the data in a database such as Cassandra or HBase.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 分钟级窗口长度是合理的。小时级窗口长度不建议，因为它会消耗大量计算和内存。更方便的做法是在诸如Cassandra或HBase之类的数据库中聚合数据。
- en: Windowed transformations compute results based on window length and window slide
    interval. Spark performance is primarily affected by on window length, window
    slide interval, and persistence.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 窗口转换根据窗口长度和窗口滑动间隔计算结果。Spark的性能主要受窗口长度、窗口滑动间隔和持久性的影响。
- en: Building in fault tolerance
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 建立容错
- en: Real-time stream processing systems must be operational 24/7\. They need to
    be resilient to all sorts of failures in the system. Spark and its RDD abstraction
    are designed to seamlessly handle failures of any worker nodes in the cluster.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 实时流处理系统必须24/7运行。它们需要对系统中的各种故障具有弹性。Spark及其RDD抽象设计成无缝处理集群中任何工作节点的故障。
- en: Main Spark Streaming fault tolerance mechanisms are check pointing, automatic
    driver restart, and automatic failover. Spark enables recovery from driver failure
    using check pointing, which preserves the application state.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 主要的Spark Streaming容错机制是检查点、自动驱动程序重启和自动故障转移。Spark通过检查点实现了从驱动程序故障中恢复，从而保留了应用程序状态。
- en: Write ahead logs, reliable receivers, and file streams guarantees zero data
    loss as of Spark Version 1.2\. Write ahead logs represent a fault tolerant storage
    for received data.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 写前日志、可靠的接收器和文件流保证了从Spark版本1.2开始的零数据丢失。写前日志代表了一个容错的存储接收到的数据。
- en: Failures require recomputing results. DStream operations have exactly-one semantics.
    Transformations can be recomputed multiple times but will yield the same result.
    DStream output operations have at least once semantics. Output operations may
    be executed multiple times.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 故障需要重新计算结果。DStream操作具有精确一次的语义。转换可以多次重新计算，但结果将是相同的。DStream输出操作具有至少一次的语义。输出操作可能会被执行多次。
- en: Processing live data with TCP sockets
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用TCP套接字处理实时数据
- en: As a stepping stone to the overall understanding of streaming operations, we
    will first experiment with TCP socket. TCP socket establishes two-way communication
    between client and server, and it can exchange data through the established connection.
    WebSocket connections are long lived, unlike typical HTTP connections. HTTP is
    not meant to keep an open connection from the server to push continuously data
    to the web browsers. Most web applications hence resorted to long polling via
    frequent **Asynchronous JavaScript** (**AJAX**) and XML requests. WebSockets,
    standardized and implemented in HTML5, are moving beyond web browsers and are
    becoming a cross-platform standard for real-time communication between client
    and server.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 作为对流操作整体理解的一个基础，我们将首先尝试使用TCP套接字进行实验。TCP套接字在客户端和服务器之间建立双向通信，可以通过已建立的连接交换数据。WebSocket连接是长期存在的，不像典型的HTTP连接。HTTP不适用于保持从服务器到Web浏览器的开放连接以持续推送数据。因此，大多数Web应用程序通过频繁的**异步JavaScript**（**AJAX**）和XML请求采用了长轮询。WebSocket在HTML5中标准化和实现，正在超越Web浏览器，成为客户端和服务器之间实时通信的跨平台标准。
- en: Setting up TCP sockets
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置TCP套接字
- en: 'We create a TCP Socket Server by running `netcat`, a small utility found in
    most Linux systems, as a data server with the command `> nc -lk 9999`, where `9999`
    is the port where we are sending data:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过运行`netcat`创建一个TCP套接字服务器，`netcat`是大多数Linux系统中的一个小型实用程序，作为数据服务器使用命令`> nc -lk
    9999`，其中`9999`是我们发送数据的端口：
- en: '[PRE0]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Once netcat is running, we will open a second console with our Spark Streaming
    client to receive the data and process. As soon as the Spark Streaming client
    console is listening, we start typing the words to be processed, that is, `hello
    world`.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦netcat运行起来，我们将打开第二个控制台，使用我们的Spark Streaming客户端接收和处理数据。一旦Spark Streaming客户端控制台开始监听，我们就开始输入要处理的单词，即`hello
    world`。
- en: Processing live data
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 处理实时数据
- en: 'We will be using the example program provided in the Spark bundle for Spark
    Streaming called `network_wordcount.py`. It can be found on the GitHub repository
    under [https://github.com/apache/spark/blob/master/examples/src/main/python/streaming/network_wordcount.py](https://github.com/apache/spark/blob/master/examples/src/main/python/streaming/network_wordcount.py).
    The code is as follows:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用Spark捆绑包中提供的Spark Streaming示例程序`network_wordcount.py`。它可以在GitHub存储库[https://github.com/apache/spark/blob/master/examples/src/main/python/streaming/network_wordcount.py](https://github.com/apache/spark/blob/master/examples/src/main/python/streaming/network_wordcount.py)中找到。代码如下：
- en: '[PRE1]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Here, we explain the steps of the program:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们解释了程序的步骤：
- en: 'The code first initializes a Spark Streaming Context with the command:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 代码首先使用以下命令初始化Spark Streaming上下文：
- en: '[PRE2]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Next, the streaming computation is set up.
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，设置流计算。
- en: 'One or more DStream objects that receive data are defined to connect to localhost
    or `127.0.0.1` on `port 9999`:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义了一个或多个接收数据的DStream对象，以连接到本地主机或`127.0.0.1`上的`端口9999`：
- en: '[PRE3]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The DStream computation is defined: transformations and output operations:'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 已定义DStream计算：转换和输出操作：
- en: '[PRE4]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Computation is started:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算已经开始：
- en: '[PRE5]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Program termination is pending manual or error processing completion:'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 程序终止等待手动或错误处理完成：
- en: '[PRE6]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Manual completion is an option when a completion condition is known:'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 手动完成是一个选项，当已知完成条件时：
- en: '[PRE7]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We can monitor the Spark Streaming application by visiting the Spark monitoring
    home page at `localhost:4040`.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过访问Spark监控主页`localhost:4040`来监视Spark Streaming应用程序。
- en: 'Here''s the result of running the program and feeding the words on the `netcat`
    4server console:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 这是运行程序并在`netcat`服务器控制台上输入单词的结果：
- en: '[PRE8]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Run the Spark Streaming `network_count` program by connecting to the socket
    localhost on `port 9999`:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 通过连接到`端口9999`上的本地主机运行Spark Streaming `network_count`程序：
- en: '[PRE9]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Thus, we have established connection through the socket on `port 9999`, streamed
    the data sent by the `netcat` server, and performed a word count on the messages
    sent.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们已经通过`端口9999`上的套接字建立了连接，流式传输了`netcat`服务器发送的数据，并对发送的消息进行了字数统计。
- en: Manipulating Twitter data in real time
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实时操作Twitter数据
- en: Twitter offers two APIs. One search API that essentially allows us to retrieve
    past tweets based on search terms. This is how we have been collecting our data
    from Twitter in the previous chapters of the book. Interestingly, for our current
    purpose, Twitter offers a live streaming API which allows to ingest tweets as
    they are emitted in the blogosphere.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: Twitter提供两种API。一种是搜索API，基本上允许我们根据搜索词检索过去的tweets。这就是我们在本书的前几章中从Twitter收集数据的方式。有趣的是，对于我们当前的目的，Twitter提供了一个实时流API，允许我们摄取博客圈中发布的tweets。
- en: Processing Tweets in real time from the Twitter firehose
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实时处理来自Twitter firehose的Tweets
- en: 'The following program connects to the Twitter firehose and processes the incoming
    tweets to exclude deleted or invalid tweets and parses on the fly only the relevant
    ones to extract `screen name`, the actual tweet, or `tweet text`, `retweet` count,
    `geo-location` information. The processed tweets are gathered into an RDD Queue
    by Spark Streaming and then displayed on the console at a one-second interval:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 以下程序连接到Twitter firehose并处理传入的tweets，排除已删除或无效的tweets，并实时解析只提取`screen name`，实际tweet或`tweet
    text`，`retweet`计数，`geo-location`信息。处理后的tweets由Spark Streaming收集到RDD队列中，然后以一秒的间隔显示在控制台上：
- en: '[PRE10]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'When we run this program, it delivers the following output:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们运行这个程序时，它会产生以下输出：
- en: '[PRE11]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: So, we got an example of streaming tweets with Spark and processing them on
    the fly.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们得到了使用Spark流处理实时tweets并实时处理它们的示例。
- en: Building a reliable and scalable streaming app
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建可靠且可扩展的流媒体应用程序
- en: Ingesting data is the process of acquiring data from various sources and storing
    it for processing immediately or at a later stage. Data consuming systems are
    dispersed and can be physically and architecturally far from the sources. Data
    ingestion is often implemented manually with scripts and rudimentary automation.
    It actually calls for higher level frameworks like Flume and Kafka.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 摄取数据是从各种来源获取数据并立即或以后进行处理的过程。数据消费系统分散并且可能在物理上和架构上远离来源。数据摄取通常使用脚本和基本自动化手段手动实现。实际上需要像Flume和Kafka这样的更高级框架。
- en: The challenges of data ingestion arise from the fact that the sources are physically
    spread out and are transient which makes the integration brittle. Data production
    is continuous for weather, traffic, social media, network activity, shop floor
    sensors, security, and surveillance. Ever increasing data volumes and rates coupled
    with ever changing data structure and semantics makes data ingestion ad hoc and
    error prone.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 数据摄取的挑战在于数据来源分散且瞬息万变，这使得集成变得脆弱。天气、交通、社交媒体、网络活动、车间传感器、安全和监控的数据生产是持续不断的。不断增加的数据量和速率，再加上不断变化的数据结构和语义，使得数据摄取变得临时性和容易出错。
- en: The aim is to become more agile, reliable, and scalable. Agility, reliability,
    and scalability of the data ingestion determine the overall health of the pipeline.
    Agility means integrating new sources as they arise and incorporating changes
    to existing sources as needed. In order to ensure safety and reliability, we need
    to protect the infrastructure against data loss and downstream applications from
    silent data corruption at ingress. Scalability avoids ingest bottlenecks while
    keeping cost tractable.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 目标是变得更加敏捷、可靠和可扩展。数据摄取的敏捷性、可靠性和可扩展性决定了管道的整体健康状况。敏捷性意味着随着新来源的出现进行集成，并根据需要对现有来源进行更改。为了确保安全性和可靠性，我们需要保护基础设施免受数据丢失的影响，并防止数据入口处对下游应用程序造成静默数据损坏。可扩展性可以避免摄取瓶颈，同时保持成本可控。
- en: '| Ingest Mode | Description | Example |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '|摄取模式|描述|示例|'
- en: '| --- | --- | --- |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Manual or Scripted | File copy using command line interface or GUI interface
    | HDFS Client, Cloudera Hue |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '|手动或脚本|使用命令行界面或图形界面进行文件复制|HDFS客户端，Cloudera Hue|'
- en: '| Batch Data Transport | Bulk data transport using tools | DistCp, Sqoop |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '|批量数据传输|使用工具进行批量数据传输|DistCp，Sqoop|'
- en: '| Micro Batch | Transport of small batches of data | Sqoop, Sqoop2Storm |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '|微批处理|小批量数据传输|Sqoop，Sqoop2Storm|'
- en: '| Pipelining | Flow like transport of event streams | Flume Scribe |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '|流水线|流式事件传输|Flume Scribe|'
- en: '| Message Queue | Publish Subscribe message bus of events | Kafka, Kinesis
    |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '|消息队列|发布订阅事件总线|Kafka，Kinesis|'
- en: In order to enable an event-driven business that is able to ingest multiple
    streams of data, process it in flight, and make sense of it all to get to rapid
    decisions, the key driver is the Unified Log.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现能够摄取多个数据流、在飞行中处理数据并理解所有内容以做出快速决策的事件驱动业务，统一日志是关键驱动因素。
- en: A Unified Log is a centralized enterprise structured log available for real-time
    subscription. All the organization's data is put in a central log for subscription.
    Records are numbered beginning with zero in the order that they are written. It
    is also known as a commit log or journal. The concept of the *Unified Log* is
    the central tenet of the Kappa architecture.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 统一日志是一个集中的企业结构化日志，可供实时订阅。所有组织的数据都放在一个中央日志中进行订阅。记录按照它们被写入的顺序从零开始编号。它也被称为提交日志或日志。*统一日志*的概念是Kappa架构的核心原则。
- en: 'The properties of the Unified Log are as follows:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 统一日志的属性如下：
- en: '**Unified**: There is a single deployment for the entire organization'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**统一的**：整个组织只有一个部署'
- en: '**Append only**: Events are immutable and are appended'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**仅追加的**：事件是不可变的并且是追加的'
- en: '**Ordered**: Each event has a unique offset within a shard'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**有序的**：每个事件在分片内具有唯一的偏移量'
- en: '**Distributed**: For fault tolerance purpose, the Unified Log is distributed
    redundantly on a cluster of computers'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分布式的**：为了容错目的，统一日志在计算机集群上进行冗余分布'
- en: '**Fast**: The systems ingests thousands of messages per second'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**快速的**：系统每秒摄取数千条消息'
- en: Setting up Kafka
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置Kafka
- en: In order to isolate downstream particular consumption of data from the vagaries
    of upstream emission of data, we need to decouple the providers of data from the
    receivers or consumers of data. As they are living in two different worlds with
    different cycles and constraints, Kafka decouples the data pipelines.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将数据的下游特定消费与数据的上游发射隔离开来，我们需要将数据的提供者与数据的接收者或消费者解耦。 由于它们生活在两个不同的世界，具有不同的周期和约束条件，Kafka解耦了数据管道。
- en: Apache Kafka is a distributed publish subscribe messaging system rethought as
    a distributed commit log. The messages are stored by topic.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Kafka是一个经过重新构想的分布式发布订阅消息系统，被重新构想为分布式提交日志。 消息按主题存储。
- en: 'Apache Kafka has the following properties. It supports:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Kafka具有以下属性。 它支持：
- en: High throughput for high volume of events feeds
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高吞吐量，适用于大量事件源
- en: Real-time processing of new and derived feeds
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实时处理新的和派生的数据源
- en: Large data backlogs and persistence for offline consumption
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大数据积压和离线消费的持久性
- en: Low latency as enterprise wide messaging system
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 低延迟作为企业范围的消息传递系统
- en: Fault tolerance thanks to its distributed nature
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于其分布式性质，具有容错能力
- en: Messages are stored in partition with a unique sequential ID called `offset`.
    Consumers track their pointers via tuple of (`offset`, `partition`, `topic`).
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 消息存储在具有唯一顺序ID的分区中，称为“偏移量”。 消费者通过元组（“偏移量”，“分区”，“主题”）跟踪它们的指针。
- en: Let's dive deeper in the anatomy of Kafka.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入了解Kafka的结构。
- en: 'Kafka has essentially three components: *producers*, *consumers* and *brokers*.
    Producers push and write data to brokers. Consumers pull and read data from brokers.
    Brokers do not push messages to consumers. Consumers pull message from brokers.
    The setup is distributed and coordinated by Apache Zookeeper.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka基本上有三个组件：*生产者*，*消费者*和*代理*。 生产者将数据推送并写入代理。 消费者从代理中拉取和读取数据。 代理不会将消息推送给消费者。
    消费者从代理中拉取消息。 设置是由Apache Zookeeper分布和协调的。
- en: The brokers manage and store the data in topics. Topics are split in replicated
    partitions. The data is persisted in the broker, but not removed upon consumption,
    but until retention period. If a consumer fails, it can always go back to the
    broker to fetch the data.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 代理在主题中管理和存储数据。 主题分为复制分区。 数据在代理中持久存在，但在消费之前不会被删除，而是在保留期间。 如果消费者失败，它可以随时返回代理以获取数据。
- en: Kafka requires Apache ZooKeeper. ZooKeeper is a high-performance coordination
    service for distributed applications. It centrally manages configuration, registry
    or naming service, group membership, lock, and synchronization for coordination
    between servers. It provides a hierarchical namespace with metadata, monitoring
    statistics, and state of the cluster. ZooKeeper can introduce brokers and consumers
    on the fly and then rebalances the cluster.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka需要Apache ZooKeeper。 ZooKeeper是分布式应用程序的高性能协调服务。 它集中管理配置，注册表或命名服务，组成员资格，锁定以及服务器之间的协调同步。
    它提供具有元数据，监视统计信息和集群状态的分层命名空间。 ZooKeeper可以动态引入代理和消费者，然后重新平衡集群。
- en: Kafka producers do not need ZooKeeper. Kafka brokers use ZooKeeper to provide
    general state information as well elect leader in case of failure. Kafka consumers
    use ZooKeeper to track message offset. Newer versions of Kafka will save the consumers
    to go through ZooKeeper and can retrieve the Kafka special topics information.
    Kafka provides automatic load balancing for producers.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka生产者不需要ZooKeeper。 Kafka代理使用ZooKeeper提供一般状态信息，并在故障时选举领导者。 Kafka消费者使用ZooKeeper跟踪消息偏移量。
    较新版本的Kafka将保存消费者通过ZooKeeper并可以检索Kafka特殊主题信息。 Kafka为生产者提供自动负载平衡。
- en: 'The following diagram gives an overview of the Kafka setup:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表概述了Kafka的设置：
- en: '![Setting up Kafka](img/B03968_05_07.jpg)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![设置Kafka](img/B03968_05_07.jpg)'
- en: Installing and testing Kafka
  id: totrans-134
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 安装和测试Kafka
- en: 'We will download the Apache Kafka binaries from the dedicated web page at [http://kafka.apache.org/downloads.html](http://kafka.apache.org/downloads.html)
    and install the software in our machine using the following steps:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从专用网页[http://kafka.apache.org/downloads.html](http://kafka.apache.org/downloads.html)下载Apache
    Kafka二进制文件，并使用以下步骤在我们的机器上安装软件：
- en: Download the code.
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载代码。
- en: 'Download the 0.8.2.0 release and `un-tar` it:'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载0.8.2.0版本并“解压”它：
- en: '[PRE12]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Start `zooeeper`. Kafka uses ZooKeeper so we need to first start a ZooKeeper
    server. We will use the convenience script packaged with Kafka to get a single-node
    ZooKeeper instance.
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动`zooeeper`。 Kafka使用ZooKeeper，因此我们需要首先启动ZooKeeper服务器。 我们将使用Kafka打包的便利脚本来获取单节点ZooKeeper实例。
- en: '[PRE13]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Now launch the Kafka server:'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在启动Kafka服务器：
- en: '[PRE14]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Create a topic. Let''s create a topic named test with a single partition and
    only one replica:'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个主题。 让我们创建一个名为test的主题，其中只有一个分区和一个副本：
- en: '[PRE15]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We can now see that topic if we run the `list` topic command:'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果我们运行`list`主题命令，我们现在可以看到该主题：
- en: '[PRE16]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Check the Kafka installation by creating a producer and consumer. We first
    launch a `producer` and type a message in the console:'
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过创建生产者和消费者来检查Kafka安装。 我们首先启动一个“生产者”并在控制台中输入消息：
- en: '[PRE17]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'We then launch a consumer to check that we receive the message:'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们启动一个消费者来检查我们是否收到消息：
- en: '[PRE18]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The messages were appropriately received by the consumer:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 消息已被消费者正确接收：
- en: 'Check Kafka and Spark Streaming consumer. We will be using the Spark Streaming
    Kafka word count example provided in the Spark bundle. A word of caution: we have
    to bind the Kafka packages, `--packages org.apache.spark:spark-streaming-kafka_2.10:1.5.0`,
    when we submit the Spark job. The command is as follows:'
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查Kafka和Spark Streaming消费者。 我们将使用Spark捆绑包中提供的Spark Streaming Kafka单词计数示例。 警告：当我们提交Spark作业时，我们必须绑定Kafka软件包“--packages
    org.apache.spark:spark-streaming-kafka_2.10:1.5.0”。 命令如下：
- en: '[PRE19]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'When we launch the Spark Streaming word count program with Kafka, we get the
    following output:'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当我们使用Kafka启动Spark Streaming单词计数程序时，我们会得到以下输出：
- en: '[PRE20]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Install the Kafka Python driver in order to be able to programmatically develop
    Producers and Consumers and interact with Kafka and Spark using Python. We will
    use the road-tested library from David Arthur, aka, Mumrah on GitHub ([https://github.com/mumrah](https://github.com/mumrah)).
    We can pip install it as follows:'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装Kafka Python驱动程序，以便能够以编程方式开发生产者和消费者，并使用Python与Kafka和Spark进行交互。我们将使用David Arthur的经过测试的库，也就是GitHub上的Mumrah（[https://github.com/mumrah](https://github.com/mumrah)）。我们可以使用pip进行安装，如下所示：
- en: '[PRE21]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Developing producers
  id: totrans-158
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 开发生产者
- en: 'The following program creates a Simple Kafka Producer that will emit the message
    *this is a message sent from the Kafka producer:* five times, followed by a time
    stamp every second:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 以下程序创建了一个简单的Kafka生产者，它将发送消息*this is a message sent from the Kafka producer:*五次，然后每秒跟一个时间戳：
- en: '[PRE22]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'When we run this program, the following output is generated:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们运行此程序时，会生成以下输出：
- en: '[PRE23]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: It tells us there were no errors and gives the offset of the messages given
    by the Kafka broker.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 它告诉我们没有错误，并给出了Kafka代理给出的消息的偏移量。
- en: Developing consumers
  id: totrans-164
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 开发消费者
- en: 'To fetch the messages from the Kafka brokers, we develop a Kafka consumer:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 为了从Kafka代理获取消息，我们开发了一个Kafka消费者：
- en: '[PRE24]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'When we run this program, we effectively confirm that the consumer received
    all the messages:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们运行此程序时，我们有效地确认消费者接收了所有消息：
- en: '[PRE25]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Developing a Spark Streaming consumer for Kafka
  id: totrans-169
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 为Kafka开发Spark Streaming消费者
- en: 'Based on the example code provided in the Spark Streaming bundle, we will create
    a Spark Streaming consumer for Kafka and perform a word count on the messages
    stored with the brokers:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 根据Spark Streaming包中提供的示例代码，我们将为Kafka创建一个Spark Streaming消费者，并对存储在代理中的消息进行词频统计：
- en: '[PRE26]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Run this program with the following Spark submit command:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下Spark提交命令运行此程序：
- en: '[PRE27]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'We get the following output:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到以下输出：
- en: '[PRE28]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Exploring flume
  id: totrans-176
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索flume
- en: Flume is a continuous ingestion system. It was originally designed to be a log
    aggregation system, but it evolved to handle any type of streaming event data.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: Flume是一个持续的摄入系统。最初设计为日志聚合系统，但它发展到处理任何类型的流式事件数据。
- en: Flume is a distributed, reliable, scalable, and available pipeline system for
    efficient collection, aggregation, and transport of large volumes of data. It
    has built-in support for contextual routing, filtering replication, and multiplexing.
    It is robust and fault tolerant, with tunable reliability mechanisms and many
    failover and recovery mechanisms. It uses a simple extensible data model that
    allows for real time analytic application.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: Flume是一个分布式、可靠、可扩展和可用的管道系统，用于高效地收集、聚合和传输大量数据。它内置支持上下文路由、过滤复制和多路复用。它是强大且容错的，具有可调节的可靠性机制和许多故障转移和恢复机制。它使用简单可扩展的数据模型，允许实时分析应用。
- en: 'Flume offers the following:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: Flume提供以下内容：
- en: Guaranteed delivery semantics
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保证交付语义
- en: Low latency reliable data transfer
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 低延迟可靠数据传输
- en: Declarative configuration with no coding required
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无需编码的声明性配置
- en: Extendable and customizable settings
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可扩展和可定制的设置
- en: Integration with most commonly used end-points
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与最常用的端点集成
- en: 'The anatomy of Flume contains the following elements:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: Flume的结构包括以下元素：
- en: '**Event**: An event is the fundamental unit of data that is transported by
    Flume from source to destination. It is like a message with a byte array payload
    opaque to Flume and optional headers used for contextual routing.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Event**：事件是由Flume从源到目的地传输的基本数据单元。它类似于一个带有字节数组有效负载的消息，对Flume不透明，并且可选的标头用于上下文路由。'
- en: '**Client**: A client produces and transmits events. A client decouples Flume
    from the data consumers. It is an entity that generates events and sends them
    to one or more agents. Custom client or Flume log4J append program or embedded
    application agent can be client.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Client**：客户端生成并传输事件。客户端将Flume与数据消费者解耦。它是生成事件并将其发送到一个或多个代理的实体。自定义客户端或Flume
    log4J附加程序或嵌入式应用代理可以是客户端。'
- en: '**Agent**: An agent is a container hosting sources, channels, sinks, and other
    elements that enable the transportation of events from one place to the other.
    It provides configuration, life cycle management and monitoring for hosted components.
    An agent is a physical Java virtual machine running Flume.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Agent**：代理是承载源、通道、sink和其他元素的容器，使事件从一个地方传输到另一个地方。它为托管组件提供配置、生命周期管理和监控。代理是运行Flume的物理Java虚拟机。'
- en: '**Source**: Source is the entity through which Flume receives events. Sources
    require at least one channel to function in order to either actively poll data
    or passively wait for data to be delivered to them. A variety of sources allow
    data to be collected, such as log4j logs and syslogs.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Source**：源是Flume接收事件的实体。源至少需要一个通道才能工作，以主动轮询数据或被动等待数据传递给它们。各种源允许收集数据，例如log4j日志和syslogs。'
- en: '**Sink**: Sink is the entity that drains data from the channel and delivers
    it to the next destination. A variety of sinks allow data to be streamed to a
    range of destinations. Sinks support serialization to user''s format. One example
    is the HDFS sink that writes events to HDFS.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Sink**：Sink是从通道中排出数据并将其传递到下一个目的地的实体。各种不同的sink允许数据流向各种目的地。Sink支持序列化为用户的格式。一个例子是将事件写入HDFS的HDFS
    sink。'
- en: '**Channel**: Channel is the conduit between the source and the sink that buffers
    incoming events until drained by sinks. Sources feed events into the channel and
    the sinks drain the channel. Channels decouple the impedance of upstream and downstream
    systems. Burst of data upstream is damped by the channels. Failures downstream
    are transparently absorbed by the channels. Sizing the channel capacity to cope
    with these events is key to realizing these benefits. Channels offer two levels
    of persistence: either memory channel, which is volatile if the JVM crashes, or
    File channel backed by Write Ahead Log that stores the information to disk. Channels
    are fully transactional.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**通道**：通道是源和汇之间的导管，缓冲传入事件，直到被汇耗尽。源将事件馈送到通道，而汇则耗尽通道。通道解耦了上游和下游系统的阻抗。上游的数据突发通过通道被抑制。下游的故障被通道透明地吸收。调整通道容量以应对这些事件是实现这些好处的关键。通道提供两种持久性级别：内存通道，如果JVM崩溃则是易失性的，或者由预写日志支持的文件通道，将信息存储到磁盘上。通道是完全事务性的。'
- en: 'Let''s illustrate all these concepts:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们说明所有这些概念：
- en: '![Exploring flume](img/B03968_05_08.jpg)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
  zh: '![探索水槽](img/B03968_05_08.jpg)'
- en: Developing data pipelines with Flume, Kafka, and Spark
  id: totrans-194
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Flume、Kafka和Spark开发数据管道
- en: Building resilient data pipeline leverages the learnings from the previous sections.
    We are plumbing together data ingestion and transport with Flume, data brokerage
    with a reliable and sophisticated publish and subscribe messaging system such
    as Kafka, and finally process computation on the fly using Spark Streaming.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 构建具有弹性的数据管道利用了前几节的经验。我们正在使用Flume将数据摄取和传输，使用Kafka作为可靠和复杂的发布和订阅消息系统进行数据经纪，最后使用Spark
    Streaming进行实时处理计算。
- en: 'The following diagram illustrates the composition of streaming data pipelines
    as sequence of *connect*, *collect*, *conduct*, *compose*, *consume*, *consign*,
    and *control* activities. These activities are configurable based on the use case:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示了流数据管道的组成，作为*connect*、*collect*、*conduct*、*compose*、*consume*、*consign*和*control*活动的序列。这些活动根据用例进行配置：
- en: Connect establishes the binding with the streaming API.
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 连接建立与流式API的绑定。
- en: Collect creates collection threads.
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 收集创建收集线程。
- en: Conduct decouples the data producers from the consumers by creating a buffer
    queue or publish-subscribe mechanism.
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Conduct通过创建缓冲队列或发布-订阅机制将数据生产者与消费者解耦。
- en: Compose is focused on processing the data.
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Compose专注于处理数据。
- en: Consume provisions the processed data for the consuming systems. Consign takes
    care of the data persistence.
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Consume为消费系统提供处理后的数据。Consign负责数据持久性。
- en: Control caters to governance and monitoring of the systems, data, and applications.
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 控制满足系统、数据和应用程序的治理和监控。
- en: '![Developing data pipelines with Flume, Kafka, and Spark](img/B03968_05_09.jpg)'
  id: totrans-203
  prefs: []
  type: TYPE_IMG
  zh: '![使用Flume、Kafka和Spark开发数据管道](img/B03968_05_09.jpg)'
- en: 'The following diagram illustrates the concepts of the streaming data pipelines
    with its key components: Spark Streaming, Kafka, Flume, and low latency databases.
    In the consuming or controlling applications, we are monitoring our systems in
    real time (depicted by a monitor) or sending real-time alerts (depicted by red
    lights) in case certain thresholds are crossed.'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示了流数据管道的概念及其关键组件：Spark Streaming、Kafka、Flume和低延迟数据库。在消费或控制应用程序中，我们正在实时监控我们的系统（由监视器表示），或者在某些阈值被突破时发送实时警报（由红灯表示）。
- en: '![Developing data pipelines with Flume, Kafka, and Spark](img/B03968_05_10.jpg)'
  id: totrans-205
  prefs: []
  type: TYPE_IMG
  zh: '![使用Flume、Kafka和Spark开发数据管道](img/B03968_05_10.jpg)'
- en: The following diagram illustrates Spark's unique ability to process in a single
    platform data in motion and data at rest while seamlessly interfacing with multiple
    persistence data stores as per the use case requirement.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示了Spark在单一平台上处理运动数据和静态数据的独特能力，同时根据用例要求与多个持久性数据存储无缝接口。
- en: This diagram brings in one unified whole all the concepts discussed up to now.
    The top part describes the streaming processing pipeline. The bottom part describes
    the batch processing pipeline. They both share a common persistence layer in the
    middle of the diagram depicting the various modes of persistence and serialization.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 这张图将到目前为止讨论的所有概念统一在一起。顶部描述了流处理管道，底部描述了批处理管道。它们都在图中间共享一个持久性层，描述了各种持久性和序列化模式。
- en: '![Developing data pipelines with Flume, Kafka, and Spark](img/B03968_05_11.jpg)'
  id: totrans-208
  prefs: []
  type: TYPE_IMG
  zh: '![使用Flume、Kafka和Spark开发数据管道](img/B03968_05_11.jpg)'
- en: Closing remarks on the Lambda and Kappa architecture
  id: totrans-209
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关于Lambda和Kappa架构的结束语
- en: 'Two architecture paradigms are currently in vogue: the Lambda and Kappa architectures.'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 目前流行的有两种架构范式：Lambda和Kappa架构。
- en: Lambda is the brainchild of the Storm creator and main committer, Nathan Marz.
    It essentially advocates building a functional architecture on all data. The architecture
    has two branches. The first is a batch arm envisioned to be powered by Hadoop,
    where historical, high-latency, high-throughput data are pre-processed and made
    ready for consumption. The real-time arm is envisioned to be powered by Storm,
    and it processes incrementally streaming data, derives insights on the fly, and
    feeds aggregated information back to the batch storage.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: Lambda是Storm的创始人和主要贡献者Nathan Marz的心血结晶。它基本上主张在所有数据上构建一个功能架构。该架构有两个分支。第一个是批处理分支，旨在由Hadoop提供动力，其中历史、高延迟、高吞吐量的数据被预处理并准备好供消费。实时分支旨在由Storm提供动力，它处理增量流数据，实时推导见解，并将聚合信息反馈到批处理存储。
- en: Kappa is the brainchild of one the main committer of Kafka, Jay Kreps, and his
    colleagues at Confluent (previously at LinkedIn). It is advocating a full streaming
    pipeline, effectively implementing, at the enterprise level, the unified log enounced
    in the previous pages.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: Kappa是Kafka的主要贡献者之一Jay Kreps及其在Confluent（以前在LinkedIn）的同事的心血结晶。它主张一个完整的流水线，有效地在企业级别实现了前几页中所述的统一日志。
- en: Understanding Lambda architecture
  id: totrans-213
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解Lambda架构
- en: 'Lambda architecture combines batch and streaming data to provide a unified
    query mechanism on all available data. Lambda architecture envisions three layers:
    a batch layer where precomputed information are stored, a speed layer where real-time
    incremental information is processed as data streams, and finally the serving
    layer that merges batch and real-time views for ad hoc queries. The following
    diagram gives an overview of the Lambda architecture:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: Lambda架构将批处理和流式数据结合，以提供对所有可用数据的统一查询机制。Lambda架构设想了三个层次：批处理层存储预先计算的信息，速度层处理实时增量信息作为数据流，最后是服务层，将批处理和实时视图合并用于自由查询。以下图表概述了Lambda架构：
- en: '![Understanding Lambda architecture](img/B03968_05_12.jpg)'
  id: totrans-215
  prefs: []
  type: TYPE_IMG
  zh: '![理解Lambda架构](img/B03968_05_12.jpg)'
- en: Understanding Kappa architecture
  id: totrans-216
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解Kappa架构
- en: The Kappa architecture proposes to drive the full enterprise in streaming mode.
    The Kappa architecture arose from a critique from Jay Kreps and his colleagues
    at LinkedIn at the time. Since then, they moved and created Confluent with Apache
    Kafka as the main enabler of the Kappa architecture vision. The basic tenet is
    to move in all streaming mode with a Unified Log as the main backbone of the enterprise
    information architecture.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: Kappa架构提议以流式模式驱动整个企业。Kappa架构起源于LinkedIn的Jay Kreps及其同事的批评。自那时起，他们转移并创建了以Apache
    Kafka为主要支持者的Confluent，以实现Kappa架构愿景。其基本原则是以统一日志作为企业信息架构的主要支撑，在全流式模式下运行。
- en: A Unified Log is a centralized enterprise structured log available for real-time
    subscription. All the organization's data is put in a central log for subscription.
    Records are numbered beginning with zero so that they are written. It is also
    known as a commit log or journal. The concept of the Unified Log is the central
    tenet of the Kappa architecture.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 统一日志是一个集中的企业结构化日志，可供实时订阅。所有组织的数据都放在一个中央日志中进行订阅。记录从零开始编号，以便写入。它也被称为提交日志或日志。统一日志的概念是Kappa架构的核心原则。
- en: 'The properties of the unified log are as follows:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 统一日志的属性如下：
- en: '**Unified**: There is a single deployment for the entire organization'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**统一的**：整个组织只有一个部署'
- en: '**Append only**: Events are immutable and are appended'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**仅追加**：事件是不可变的，会被追加'
- en: '**Ordered**: Each event has a unique offset within a shard'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**有序的**：每个事件在一个分片内有唯一的偏移量'
- en: '**Distributed**: For fault tolerance purpose, the unified log is distributed
    redundantly on a cluster of computers'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分布式**：为了容错目的，统一日志在计算机集群上进行冗余分布'
- en: '**Fast**: The systems ingests thousands of messages per second'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**快速的**：系统每秒摄入数千条消息'
- en: The following screenshot captures the moment Jay Kreps announced his reservations
    about the Lambda architecture. His main reservation about the Lambda architecture
    is implementing the same job in two different systems, Hadoop and Storm, with
    each of their specific idiosyncrasies, and with all the complexities that come
    along with it. Kappa architecture processes the real-time data and reprocesses
    historical data in the same framework powered by Apache Kafka.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图捕捉了Jay Kreps对Lambda架构的保留意见。他对Lambda架构的主要保留意见是在两个不同的系统Hadoop和Storm中实现相同的作业，每个系统都有其特定的特点，并伴随着所有相关的复杂性。Kappa架构在由Apache
    Kafka提供支持的同一框架中处理实时数据并重新处理历史数据。
- en: '![Understanding Kappa architecture](img/B03968_05_13.jpg)'
  id: totrans-226
  prefs: []
  type: TYPE_IMG
  zh: '![理解Kappa架构](img/B03968_05_13.jpg)'
- en: Summary
  id: totrans-227
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we laid out the foundations of streaming architecture apps
    and described their challenges, constraints, and benefits. We went under the hood
    and examined the inner working of Spark Streaming and how it fits with Spark Core
    and dialogues with Spark SQL and Spark MLlib. We illustrated the streaming concepts
    with TCP sockets, followed by live tweet ingestion and processing directly from
    the Twitter firehose. We discussed the notions of decoupling upstream data publishing
    from downstream data subscription and consumption using Kafka in order to maximize
    the resilience of the overall streaming architecture. We also discussed Flume—a
    reliable, flexible, and scalable data ingestion and transport pipeline system.
    The combination of Flume, Kafka, and Spark delivers unparalleled robustness, speed,
    and agility in an ever changing landscape. We closed the chapter with some remarks
    and observations on two streaming architectural paradigms, the Lambda and Kappa
    architectures.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们阐述了流式架构应用程序的基础，并描述了它们的挑战、约束和好处。我们深入探讨了Spark Streaming的内部工作方式，以及它如何与Spark
    Core对话，并与Spark SQL和Spark MLlib配合。我们通过TCP套接字、直播推文摄入以及直接从Twitter firehose处理的方式来阐述流式概念。我们讨论了使用Kafka将上游数据发布与下游数据订阅和消费解耦的概念，以最大程度地提高整体流式架构的弹性。我们还讨论了Flume——一个可靠、灵活和可扩展的数据摄入和传输管道系统。Flume、Kafka和Spark的结合在不断变化的环境中提供了无与伦比的稳健性、速度和灵活性。我们在本章中还对两种流式架构范式——Lambda和Kappa架构进行了一些评论和观察。
- en: The Lambda architecture combines batch and streaming data in a common query
    front-end. It was envisioned with Hadoop and Storm in mind initially. Spark has
    its own batch and streaming paradigms, and it offers a single environment with
    common code base to effectively bring this architecture paradigm to life.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: Lambda架构将批处理和流式数据结合在一个通用的查询前端。最初它是以Hadoop和Storm为目标构想的。Spark具有自己的批处理和流式范例，并提供了一个共同的代码库的单一环境，有效地将这种架构范式实现。
- en: The Kappa architecture promulgates the concept of the unified log, which creates
    an event-oriented architecture where all events in the enterprise are channeled
    in a centralized commit log that is available to all consuming systems in real
    time.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: Kappa架构宣扬了统一日志的概念，它创建了一个面向事件的架构，企业中的所有事件都被导入到一个中央提交日志中，并且实时提供给所有消费系统。
- en: We are now ready for the visualization of the data collected and processed so
    far.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们准备对迄今为止收集和处理的数据进行可视化。
