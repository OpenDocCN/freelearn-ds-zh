- en: Retaining Customers
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 客户留存
- en: As customers have more options for similar content to consume or similar products
    and services to shop for, it has become more difficult for many businesses to
    retain their customers and not lose them to other competitors. As the cost of
    acquiring new customers is typically higher than that of retaining and keeping
    existing customers, customer churn is becoming more and more of a concern than
    ever before. In order to retain existing customers and not lose them to competitors,
    businesses should not only try to understand their customers and their customers'
    needs and interests, but they should also be able to identify which customers
    are highly likely to churn and how to retain these customers at churn risk.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 由于客户有更多选择可以消费类似内容或购买类似产品和服务，许多企业发现留住客户变得越来越困难，且客户很容易被其他竞争对手吸引。因为获取新客户的成本通常高于留住现有客户的成本，所以客户流失问题比以往任何时候都更加令人担忧。为了保留现有客户并防止他们流失到竞争对手，企业不仅需要了解客户及其需求和兴趣，还应能够识别出哪些客户可能会流失，并采取措施留住这些面临流失风险的客户。
- en: In this chapter, we are going to dive deeper into customer churn and how it
    hurts businesses, as well as how to retain existing customers. We will discuss
    some of the common reasons for customers leaving businesses and look at how data
    science can help reduce the risk of losing customers. As a way of predicting customer
    churn, we will learn about what an artificial neural network model is and its
    applications in different areas, as well as how we can build one using Python
    and R.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将深入探讨客户流失及其对企业的影响，以及如何留住现有客户。我们将讨论一些客户离开企业的常见原因，并研究数据科学如何帮助减少客户流失的风险。作为预测客户流失的一种方法，我们将了解人工神经网络模型及其在不同领域的应用，并学习如何使用Python和R构建一个模型。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Customer churn and retention
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 客户流失与客户留存
- en: Artificial neural networks
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人工神经网络
- en: Predicting customer churn with Python
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Python预测客户流失
- en: Predicting customer churn with R
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用R预测客户流失
- en: Customer churn and retention
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 客户流失与客户留存
- en: '**Customer churn** is when a customer decides to stop using services, content,
    or products from a company. As we have briefly discussed in [Chapter 7](72e8f4ee-7f95-4acc-928d-d33c9fc31bd6.xhtml), *Exploratory
    Analysis for Customer Behavior*, when we discussed customer analytics, it is much
    less expensive to retain existing customers than to acquire new customers, and
    the revenue from repeat customers is typically higher than that form new customers.
    In competitive industries, where a business faces many competitors, the cost of
    new customer acquisition is even higher, and retaining existing customers becomes
    more important for such businesses.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '**客户流失**是指客户决定停止使用某公司提供的服务、内容或产品。正如我们在[第7章](72e8f4ee-7f95-4acc-928d-d33c9fc31bd6.xhtml)中简要讨论过的，*客户行为的探索性分析*，当我们讨论客户分析时，保留现有客户的成本远低于获取新客户的成本，且来自重复客户的收入通常高于新客户的收入。在竞争激烈的行业中，企业面临众多竞争者，新客户获取的成本更高，因此，对于这些企业来说，保留现有客户变得尤为重要。'
- en: There are many reasons behind customers leaving a business. Some of the common
    reasons why customers churn are poor customer service, not finding enough value
    in the products or services, lack of communications, and lack of customer loyalty.
    The first step to retaining these customers is to monitor customer churn rates
    over time. If the churn rate is generally high or is increasing over time, then
    it will be a good idea to dedicate some resources to improving customer retention.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 客户离开企业背后有很多原因。一些常见的客户流失原因包括服务质量差、产品或服务未能提供足够的价值、缺乏沟通和客户忠诚度低。留住这些客户的第一步是监控客户流失率的变化。如果流失率普遍较高或随着时间推移有所增加，那么分配一些资源来改善客户留存率将是一个好主意。
- en: In order to improve the customer retention rate, the top priority should be
    to understand the customer better. You can survey customers who have already churned
    to understand why they left. You can also survey existing customers to understand
    what their needs are and what their pain points are. A data science and data analytics
    approach would be to look into the data. For example, you can look at customers'
    web activity data and understand where they spend the most time, whether there
    were errors on the pages that they were looking at, or whether their search results
    did not return good content. You can also look into the customer service call
    logs to understand how long their wait time was, what their complaints were, and
    how their issues were handled. Conducting deep analyses on these data points can
    reveal the problems that a business is facing in retaining its existing customers.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高客户留存率，首要任务是更好地了解客户。你可以对已经流失的客户进行调查，了解他们离开的原因。你还可以对现有客户进行调查，了解他们的需求是什么，痛点在哪里。数据科学和数据分析方法是通过数据来寻找答案。例如，你可以查看客户的网页活动数据，了解他们花费最多时间的页面，是否在他们浏览的页面上出现了错误，或者他们的搜索结果是否没有返回好的内容。你还可以查看客户服务通话记录，了解他们的等待时间有多长，投诉了哪些问题，以及这些问题是如何被处理的。对这些数据点进行深入分析可以揭示企业在保持现有客户方面面临的挑战。
- en: When analyzing for customer churn, you can also utilize some of the topics we
    have discussed in this book. You can apply what we have learned from [Chapter
    5](73a716c6-6a84-4785-b04e-87651d0a29d1.xhtml), *Product Analytics*, and [Chapter 6](d3ba7047-2873-4b03-9a44-4c1d55b84178.xhtml),
    *Recommending the Right Products*, to understand which products serve the customer
    needs and interests the best, and recommend the right products so that you can
    deliver more personalized content. You can also use what we have learned from
    [Chapter 7](72e8f4ee-7f95-4acc-928d-d33c9fc31bd6.xhtml), *Exploratory Analysis
    for Customer Behavior*, and [Chapter 10](5955002d-2a75-4d5a-aa6a-86710a3bf00e.xhtml),*Data-Driven
    Customer Segmentation*, to understand the customer behavior better and the different
    segments of customers. Another way is to build a machine learning model that can
    predict which customers are likely to churn and target and retain these specific
    customers that are at higher risk of churn. In the following sections, we will
    discuss how to build a neural network model to identify those customers with higher
    risk of churn for customer retention.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在分析客户流失时，你还可以利用本书中讨论的一些主题。你可以运用我们在[第5章](73a716c6-6a84-4785-b04e-87651d0a29d1.xhtml)《*产品分析*》和[第6章](d3ba7047-2873-4b03-9a44-4c1d55b84178.xhtml)《*推荐合适的产品*》中学到的知识，了解哪些产品最能满足客户的需求和兴趣，并推荐合适的产品，从而提供更个性化的内容。你还可以运用我们在[第7章](72e8f4ee-7f95-4acc-928d-d33c9fc31bd6.xhtml)《*客户行为的探索性分析*》和[第10章](5955002d-2a75-4d5a-aa6a-86710a3bf00e.xhtml)《*基于数据的客户细分*》中学到的知识，更好地理解客户行为和不同的客户群体。另一种方法是构建一个机器学习模型，预测哪些客户可能流失，并针对这些流失风险较高的特定客户进行定向干预，争取留住他们。在接下来的章节中，我们将讨论如何构建一个神经网络模型，识别那些高流失风险的客户，以实现客户留存。
- en: Artificial neural networks
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人工神经网络
- en: 'The** artificial neural network** (**ANN**) model is a machine learning model
    that is inspired by how a human brain functions. Recent successful applications
    of ANN models in image recognition, voice recognition, and robotics have proven
    their predictive power and usefulness in various industries. You might have heard
    the term **deep learning**. This is a type of ANN model where the number of layers
    between the input and output layers is large. It is best explained with the following
    diagram:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**人工神经网络**（**ANN**）模型是一种受人脑运作启发的机器学习模型。近年来，ANN模型在图像识别、语音识别和机器人技术等领域的成功应用，证明了它们在各个行业中的预测能力和实用性。你可能听说过“**深度学习**”这个术语。它是ANN模型的一种，其中输入层和输出层之间的层数较多。下面的图示可以更好地解释这一概念：'
- en: '![](img/94952b7d-1e29-44d5-9886-ebc15f2b8781.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](img/94952b7d-1e29-44d5-9886-ebc15f2b8781.png)'
- en: This diagram shows a simple case of an ANN model with one hidden layer. The
    circles in this diagram represent artificial neurons or nodes, which model those
    neurons in human brains. The arrows represent how signals are transmitted from
    one neuron to another. As this diagram suggests, an ANN model learns by finding
    the patterns or the weights of signals from each input neuron to the neuron in
    the next layer, which best predicts the output.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 该图展示了一个具有单一隐藏层的人工神经网络（ANN）模型的简单示例。图中的圆圈代表人工神经元或节点，模拟的是人脑中的神经元。这些箭头表示信号如何从一个神经元传递到另一个神经元。正如该图所示，ANN
    模型通过寻找每个输入神经元到下一层神经元之间的信号模式或权重来学习，从而最佳地预测输出。
- en: The specific type of an ANN model that we will be experimenting with in the
    following programming exercises is a **multilayer perceptron** (**MLP**) model.
    Simply put, an MLP model is a neural network model that has at least one or more
    hidden layers of nodes. Including one layer for the input and another layer for
    the output, the MLP model consists of at least three or more layers of nodes.
    The diagram we just looked at is the simplest case of an MLP model, where there
    is only one hidden layer.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的编程练习中，我们将使用的具体 ANN 模型是**多层感知器**（**MLP**）模型。简单来说，MLP 模型是一种至少有一个或多个隐藏层节点的神经网络模型。包括一个输入层和一个输出层，MLP
    模型至少包含三个或更多层节点。我们刚才看到的图是 MLP 模型的最简单情况，其中只有一个隐藏层。
- en: ANN models can be utilized in many areas of marketing. Using neural network
    models by BrainMaker, Microsoft increased its direct mail response rate from 4.9%
    to 8.2%. This helped Microsoft to bring in the same amount of revenue for 35%
    less cost. Similarly, for the marketing engagement prediction problems we discussed
    in [Chapter 8](4f5163a1-c34a-495f-bc5f-e02f9b2a2052.xhtml), *Predicting the Likelihood
    of Marketing Engagement*, we could have used neural network models, instead of
    random forest models. We can also use neural network models for the customer segmentation
    problems that we discussed in [Chapter 10](5955002d-2a75-4d5a-aa6a-86710a3bf00e.xhtml),
    *Data-Driven Customer Segmentation*. In the following programming exercises, we
    will discuss how we can use ANN models to predict which customers are likely to
    churn.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: ANN 模型可以应用于许多营销领域。通过使用 BrainMaker 的神经网络模型，微软将其直邮响应率从 4.9% 提高到了 8.2%。这帮助微软在成本减少
    35% 的情况下实现了相同的收入。同样地，在我们在[第 8 章](4f5163a1-c34a-495f-bc5f-e02f9b2a2052.xhtml)《预测营销参与可能性》中讨论的营销参与预测问题中，我们本可以使用神经网络模型，而不是随机森林模型。我们也可以使用神经网络模型解决我们在[第
    10 章](5955002d-2a75-4d5a-aa6a-86710a3bf00e.xhtml)《数据驱动的客户细分》中讨论的客户细分问题。在接下来的编程练习中，我们将讨论如何使用
    ANN 模型预测哪些客户可能流失。
- en: Predicting customer churn with Python
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Python 预测客户流失
- en: In this section, we are going to discuss how to use an ANN model to predict
    the customers at the risk of leaving, or customers who are highly likely to churn.
    By the end of this section, we will have built a customer churn prediction model
    using an ANN model. We will be mainly using the `pandas`, `matplotlib`, and `keras` packages
    to analyze, visualize, and build machine learning models. For those readers who
    would like to use R, instead of Python, for this exercise, you can skip to the
    next section.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论如何使用 ANN 模型预测有离职风险的客户，或者是那些高度可能流失的客户。在本节结束时，我们将使用 ANN 模型构建一个客户流失预测模型。我们将主要使用`pandas`、`matplotlib`
    和 `keras` 包来进行分析、可视化以及构建机器学习模型。对于那些希望使用 R 而非 Python 进行此练习的读者，你可以跳到下一节。
- en: 'For this exercise, we will be using one of the publicly available datasets
    from the IBM Watson Analytics community, which can be found at this link: [https://www.ibm.com/communities/analytics/watson-analytics-blog/predictive-insights-in-the-telco-customer-churn-data-set/](https://www.ibm.com/communities/analytics/watson-analytics-blog/predictive-insights-in-the-telco-customer-churn-data-set/).
    You can follow this link and download the data, which is available in XLSX format,
    named `WA_Fn-UseC_-Telco-Customer-Churn.xlsx`. Once you have downloaded this data,
    you can load it into your Jupyter Notebook by running the following command:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本次练习，我们将使用来自 IBM Watson Analytics 社区的公开数据集之一，数据集链接如下：[https://www.ibm.com/communities/analytics/watson-analytics-blog/predictive-insights-in-the-telco-customer-churn-data-set/](https://www.ibm.com/communities/analytics/watson-analytics-blog/predictive-insights-in-the-telco-customer-churn-data-set/)。你可以点击该链接下载数据，数据以
    XLSX 格式提供，文件名为 `WA_Fn-UseC_-Telco-Customer-Churn.xlsx`。下载数据后，你可以通过运行以下命令将其加载到
    Jupyter Notebook 中：
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The DataFrame, `df`, is shown in the following screenshot:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '`df`数据框如下截图所示：'
- en: '![](img/82ebeb7f-fa1b-4fb8-9cb8-3c1e3f1f5048.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](img/82ebeb7f-fa1b-4fb8-9cb8-3c1e3f1f5048.png)'
- en: There are 21 variables in this dataset, where our goal is to predict the target
    variable, `Churn`.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集包含21个变量，其中我们的目标是预测目标变量`Churn`。
- en: Data analysis and preparation
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据分析与准备
- en: 'As you may notice by looking at the data, there are a few things we need to
    do before we can start building machine learning models. In this section, we are
    going to transform continuous variables that have monetary values and encode the
    target variable, `Churn`, as well as other categorical variables. To do so, perform
    the following steps:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，在查看数据后，我们需要做一些工作，才能开始构建机器学习模型。在本节中，我们将转换具有货币值的连续变量，并编码目标变量`Churn`以及其他分类变量。为此，请执行以下步骤：
- en: '**Target variable encoding**: As you may have noticed from the data, the target
    variable, `Churn`, has two values: `Yes` and `No`. We are going to encode these
    values as `1` for `Yes` and `0` for `No`. The code to encode the target variable
    looks like the following:'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**目标变量编码**：正如你从数据中看到的，目标变量`Churn`有两个值：`Yes`和`No`。我们将这些值编码为`1`代表`Yes`，`0`代表`No`。编码目标变量的代码如下所示：'
- en: '[PRE1]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'To get the overall churn rate, you can simply run the following code:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 要获得整体流失率，你可以简单地运行以下代码：
- en: '[PRE2]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The output of this code is around 0.27, which suggests that about 27% of customers
    have churned. A 27% churn rate is not a small number; rather, it is high enough
    for a business to worry about the overall customer churn and come up with a solution
    to retain these customers. In the following modeling section, we will discuss
    how to predict customers who are likely to churn with this data and use these
    predictions to retain customers.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 该代码的输出约为0.27，这意味着大约27%的客户流失。27%的流失率并不是一个小数字；相反，它足够高，足以让企业担心整体客户流失并采取措施留住这些客户。在接下来的建模部分，我们将讨论如何利用这些数据预测可能流失的客户，并利用这些预测来保留客户。
- en: '**Handling missing values in the TotalCharges column**: If you looked through
    the `TotalCharges` column in the dataset, you may have noticed that there are
    some records with no `TotalCharges` values. Since there are only `11` records
    with missing `TotalCharges` values, we are going to simply ignore and drop those
    records with missing values. Take a look at the following code:'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**处理TotalCharges列中的缺失值**：如果你查看数据集中的`TotalCharges`列，可能会注意到有些记录的`TotalCharges`值是缺失的。由于只有`11`条记录缺失`TotalCharges`值，我们将简单地忽略并删除这些缺失值的记录。请查看以下代码：'
- en: '[PRE3]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: As you may notice from this code, we are simply replacing the blank space values
    with `nan` values. Then, we are dropping all the records with `nan` values by
    using the `dropna` function.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 从这段代码可以看到，我们只是将空格值替换为`nan`值。然后，我们通过使用`dropna`函数删除所有包含`nan`值的记录。
- en: '**Transforming continuous variables**: The next step is to scale the continuous
    variables. Take a look at the following summary statistics for continuous variables:'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**转换连续变量**：下一步是对连续变量进行缩放。以下是连续变量的汇总统计信息：'
- en: '![](img/9b23f08b-ff28-4ecd-93d4-1605191cfbe0.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9b23f08b-ff28-4ecd-93d4-1605191cfbe0.png)'
- en: 'You can get these summary statistics using the following code:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用以下代码获取这些汇总统计信息：
- en: '[PRE4]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'As you can see from the summary statistics, the three `tenure`, `MonthlyCharges`,
    and `TotalCharges` continuous variables all have different scales. The `tenure` variable,
    ranges from `1` to `72`, while the `TotalCharges` variable , ranges from `18.8`
    to `8684.8`. ANN models typically perform better with scaled or normalized features.
    Take a look at the following code for normalizing these three features:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 从汇总统计中可以看到，三个`tenure`、`MonthlyCharges`和`TotalCharges`连续变量的尺度不同。`tenure`变量的范围是从`1`到`72`，而`TotalCharges`变量的范围是从`18.8`到`8684.8`。通常，ANN模型在使用缩放或归一化特征时表现更好。请查看以下代码，用于归一化这三个特征：
- en: '[PRE5]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'As you can see from this code, we apply log-transform first and then normalize
    the continuous variables by subtracting by the mean and dividing the values by
    standard deviations. The results look like the following:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 从这段代码可以看到，我们首先应用对数转换，然后通过减去均值并除以标准差来归一化连续变量。结果如下所示：
- en: '![](img/c3feef9a-26f3-4d7f-b6af-3c1fd1bbd9ce.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c3feef9a-26f3-4d7f-b6af-3c1fd1bbd9ce.png)'
- en: As you see from this output, all the variables now have a mean of `0` and a
    standard deviation of `1`. We are going to use these normalized variables for
    future model building.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，所有变量现在的均值为`0`，标准差为`1`。我们将使用这些标准化的变量来进行未来的模型构建。
- en: '**One-hot encoding categorical variables**: As you can see from the data, there
    are many categorical variables. Let''s first take a look at the number of unique
    values each column has. Take a look at the following code:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**独热编码分类变量**：从数据中可以看出，存在许多分类变量。我们首先来看一下每列有多少独特值。请查看以下代码：'
- en: '[PRE6]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'You can use the `nunique` function to count the number of unique values in
    each column. The output of this code looks like the following:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用`nunique`函数来计算每一列的独特值数量。这段代码的输出如下所示：
- en: '![](img/8607d3f9-078b-46c8-8795-36677f850605.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8607d3f9-078b-46c8-8795-36677f850605.png)'
- en: As this output suggests, there are `7032` unique customer IDs, `2` unique genders,
    `3` unique values for `MultipleLines`, and `6530` unique values for `TotalCharges`.
    We have handled the `tenure`, `MonthlyCharges`, and `TotalCharges` variables,
    in the previous step, so we are going to focus on those variables with `2` to
    `4` unique values.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 正如这个输出所示，存在`7032`个独特的客户ID，`2`个独特的性别，`3`个独特的`MultipleLines`值，以及`6530`个独特的`TotalCharges`值。我们已经在前一步处理了`tenure`、`MonthlyCharges`和`TotalCharges`变量，因此接下来我们将专注于那些具有`2`到`4`个独特值的变量。
- en: 'Let''s take a look at the distributions of some of these categorical variables.
    First, to view the distribution of the data between males and females, you can
    use the following code for visualization:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下这些分类变量的一些分布情况。首先，为了查看数据在男性和女性之间的分布情况，你可以使用以下代码进行可视化：
- en: '[PRE7]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The plot looks like the following:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 该图如下所示：
- en: '![](img/d45a82ef-8941-4a1e-b045-603f6a250358.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d45a82ef-8941-4a1e-b045-603f6a250358.png)'
- en: 'As you can see from this bar plot, the distribution of the data across different
    genders is roughly equally distributed. You can use the same code to view the
    distribution of the data across different values of `InternetService` and `PaymentMethod`.
    Take a look at the following plots:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 从这张条形图中可以看出，不同性别的数据分布大致均匀。你可以使用相同的代码来查看`InternetService`和`PaymentMethod`不同值之间的数据分布。请查看以下图表：
- en: '![](img/c9f241ba-b160-4d32-9ed5-6d5a3f4789cb.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c9f241ba-b160-4d32-9ed5-6d5a3f4789cb.png)'
- en: '![](img/02f7e148-eae1-433d-839d-846866528189.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](img/02f7e148-eae1-433d-839d-846866528189.png)'
- en: The first plot shows the distribution of the data across three different categories
    of the `InternetService` variable, and the second plot shows the distribution
    of the data across four different categories of the `PaymentMethod` variable.
    As you can see from these plots, we can easily visualize and understand what the
    distributions of categorical variables look like using bar plots. We recommend
    that you draw bar plots for other categorical variables to get a better understanding
    of the data distribution.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个图显示了数据在`InternetService`变量的三种不同类别之间的分布，第二个图显示了数据在`PaymentMethod`变量的四种不同类别之间的分布。从这些图中可以看出，我们可以通过条形图轻松地可视化和理解分类变量的分布情况。我们建议你为其他分类变量绘制条形图，以便更好地理解数据分布。
- en: 'Now, we are going to apply one-hot encoding for these categorical variables.
    Take a look at the following code:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将对这些分类变量应用独热编码。请查看以下代码：
- en: '[PRE8]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'As you can see from this code, we are using the `get_dummies` function in the
    `pandas` package to create dummy variables for each categorical variable. Then,
    we concatenate these newly created dummy variables back to the `sample_set` variable,
    which will be used for training models in the following section. The results are
    shown in the following output:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，我们在这段代码中使用了`pandas`包中的`get_dummies`函数为每个分类变量创建虚拟变量。然后，我们将这些新创建的虚拟变量与`sample_set`变量合并，这些数据将用于接下来建模阶段的训练。结果如下所示：
- en: '![](img/e0661e37-7736-4081-a012-d09060d67881.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e0661e37-7736-4081-a012-d09060d67881.png)'
- en: Once you have completed these four steps, it is time to start building ANN models
    for customer churn predictions. Move onto the next section for ANN modeling!
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦完成这四个步骤，就可以开始构建用于客户流失预测的人工神经网络（ANN）模型了。请进入下一部分进行ANN建模！
- en: ANN with Keras
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Keras 的人工神经网络（ANN）
- en: 'For building ANN models in Python, we are going to use `keras` package, which
    is a high-level neural networks library. For more details, we recommend you visit
    their official documentation at the following link: [https://keras.io/](https://keras.io/).
    Before we can use this package for building ANN models, we need to install two
    packages: `tensorflow` and `keras`. The `keras` package uses `tensorflow` as a
    backend for building neural network models, so we need to install `tensorflow`
    first. You can install these two packages using the following `pip` commands in
    your Terminal:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在Python中构建人工神经网络（ANN）模型，我们将使用`keras`包，这是一个高级的神经网络库。欲了解更多详细信息，我们建议您访问他们的官方文档：[https://keras.io/](https://keras.io/)。在我们使用这个包构建ANN模型之前，我们需要安装两个包：`tensorflow`和`keras`。`keras`包使用`tensorflow`作为构建神经网络模型的后台，因此我们需要先安装`tensorflow`。你可以通过以下`pip`命令在终端中安装这两个包：
- en: '[PRE9]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Once you have installed these two packages, we can finally start building our
    first neural network models. In this exercise, we are going to build a neural
    network model with one hidden layer. Take a look at the following code first:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你安装了这两个包，我们就可以开始构建我们的第一个神经网络模型了。在这个练习中，我们将构建一个具有一个隐藏层的神经网络模型。首先看看下面的代码：
- en: '[PRE10]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Let's take a closer look at this code. First, we are using a `Sequential` model
    here, which is the type of model where the layers are stacked linearly and looks
    similar to the diagram we saw in the earlier section about the MLP model. The
    first layer is an input layer, where `input_dim` is simply the number of features
    or columns in the sample set and the number of output units is `16`. We are using
    the `relu` activation function for this input layer. Then, in the hidden layer,
    the number of output units is `8` and the activation function to be used is `relu`.
    Lastly, the output layer has one output unit, which is the probability of customer
    churn, and we use the `sigmoid` activation function in this layer. You can experiment
    with different numbers of output units and activation functions for your exercise.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地看一下这段代码。首先，我们这里使用的是`Sequential`模型，这是层按线性顺序堆叠的模型类型，类似于我们在前面关于MLP模型部分中看到的图示。第一层是输入层，其中`input_dim`仅仅是样本集中的特征数或列数，而输出单元的数量是`16`。我们为这个输入层使用的是`relu`激活函数。接下来，在隐藏层中，输出单元的数量是`8`，并且使用的激活函数是`relu`。最后，输出层有一个输出单元，表示客户流失的概率，我们在这个层中使用的是`sigmoid`激活函数。你可以尝试不同数量的输出单元和激活函数进行实验。
- en: 'The final step to build a neural network model with the `keras` package is
    to compile this model. Take a look at the following code:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`keras`包构建神经网络模型的最后一步是编译这个模型。看看下面的代码：
- en: '[PRE11]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Here, we are using the `adam` optimizer, which is one of the most commonly and
    frequently used optimization algorithms. Since our target variable is binary,
    we are using `binary_crossentropy` as the loss function. Lastly, this model will
    use the `accuracy` metric to evaluate model performance during training.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用的是`adam`优化器，这是最常用和频繁使用的优化算法之一。由于我们的目标变量是二元的，因此我们使用`binary_crossentropy`作为损失函数。最后，这个模型将使用`accuracy`作为评估训练过程中模型性能的指标。
- en: 'Before we start training this neural network model, we will need to split our
    sample set into train and test sets. Take a look at the following code:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始训练这个神经网络模型之前，我们需要将我们的样本集分为训练集和测试集。请看一下下面的代码：
- en: '[PRE12]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'As you can see from this code, we are using the `train_test_split` function
    of the `scikit-learn` package. For our exercise, we will use 70% of the sample
    set for training and 30% for testing. Now we can train our neural network model
    using the following code:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 从这段代码中可以看出，我们正在使用`scikit-learn`包中的`train_test_split`函数。在我们的练习中，我们将使用70%的样本集进行训练，30%进行测试。现在，我们可以使用以下代码训练我们的神经网络模型：
- en: '[PRE13]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Here, we are using `100` samples as `batch_size`, from which the model is going
    to learn to predict each time, and `50` as the number of `epochs`, which is the
    number of complete passes through the entire training set. Once you run this code,
    you will see output that looks like the following:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用`100`个样本作为`batch_size`，即每次模型学习的样本数量，`50`作为`epochs`的数量，即通过整个训练集的完整遍历次数。运行这段代码后，你将看到类似如下的输出：
- en: '![](img/c3546491-4c7b-410c-80d6-47b584305a45.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c3546491-4c7b-410c-80d6-47b584305a45.png)'
- en: As you can see from this output, `loss` typically decreases and the accuracy
    (`acc`) improves in each epoch. However, the rate of model performance improvement
    decreases over time. As you can see from this output, there are big improvements
    in the loss and accuracy measures in the first few epochs and the amount of performance
    gain decreases over time. You can monitor this process and decide to stop when
    the amount of performance gain is minimal.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您从输出中看到的，`loss`通常会在每个周期减少，准确率（`acc`）会提高。然而，模型性能提升的速率随着时间的推移会逐渐减缓。正如您从输出中看到的，在前几个周期中，损失和准确率指标有显著改善，但随着时间的推移，性能提升的幅度逐渐变小。您可以监控这个过程，并决定在性能增益最小的时候停止训练。
- en: Model evaluations
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型评估
- en: 'Now that we have built our first neural network model, let''s evaluate its
    performance. We are going to look at the overall accuracy, precision, and recall,
    as well as the **receiver operating characteristic** (**ROC**) curve and area
    under the curve (AUC). First, take a look at the following code for computing
    accuracy, precision, and recall:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经建立了第一个神经网络模型，让我们来评估它的性能。我们将查看总体准确率、精确度和召回率，以及**接收者操作特征**（**ROC**）曲线和曲线下面积（AUC）。首先，来看一下计算准确率、精确度和召回率的代码：
- en: '[PRE14]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'You should be familiar with this code, as we used the same evaluation metrics
    in [Chapter 8](4f5163a1-c34a-495f-bc5f-e02f9b2a2052.xhtml), *Predicting the Likelihood
    of Marketing Engagement*. The output of this code in our case looks like the following:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该已经熟悉这段代码，因为我们在[第8章](4f5163a1-c34a-495f-bc5f-e02f9b2a2052.xhtml)《预测营销参与的可能性》中使用了相同的评估指标。对于我们这个案例，该代码的输出结果如下：
- en: '![](img/7494f39e-a14f-4eda-8c43-7f86d4fca089.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7494f39e-a14f-4eda-8c43-7f86d4fca089.png)'
- en: Due to some randomness in the model, your results might differ from these numbers.
    As you can see from this output, the accuracy of predicting whether a customer
    will churn or not in the test set is about `0.79`, suggesting the model is correct
    roughly about 80% of the time. The out-of-sample precision suggests that the model
    is correct about 66% of the time that it predicts that the customer is going to
    churn, and the out-of-sample recall suggests that the model captures roughly 52%
    of the churn cases.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 由于模型中存在一定的随机性，您的结果可能与这些数字有所不同。从这个输出中可以看到，测试集中预测客户是否流失的准确率约为`0.79`，这意味着模型大约有80%的时间是正确的。样本外的精确度表明，模型在预测客户流失时大约有66%的准确性，而样本外的召回率则表明，模型大约能捕捉到52%的流失案例。
- en: 'Next, we can compute the AUC numbers, using the following code:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们可以使用以下代码计算AUC值：
- en: '[PRE15]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The output of this code looks like this:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 该代码的输出结果如下：
- en: '![](img/0ec3005a-e8e1-48e0-a8ec-293c4ffff915.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0ec3005a-e8e1-48e0-a8ec-293c4ffff915.png)'
- en: 'To visualize this data in the ROC curve, you can use the following code:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在ROC曲线中可视化这些数据，您可以使用以下代码：
- en: '[PRE16]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'And the output looks like this:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![](img/99716b1c-5a70-4197-b28d-3a7297340dac.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](img/99716b1c-5a70-4197-b28d-3a7297340dac.png)'
- en: Along with the accuracy, precision, and recall measures that we looked at previously,
    the AUC and the ROC curve also suggest that the model captures and predicts those
    customers at churn risk pretty well. As you can see from these evaluation outputs,
    it is better to use the output of this model for identifying the customers who
    are likely to churn than simply guessing who they will be. By focusing on those
    customers with high churn probabilities from this model in your marketing strategies,
    you can try to retain those customers at churn risks in a more cost-effective
    way.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 除了之前查看的准确率、精确度和召回率指标外，AUC和ROC曲线也表明该模型能够很好地捕捉并预测流失风险较高的客户。正如你从这些评估输出中看到的，与简单地猜测哪些客户可能流失相比，使用该模型的输出来识别可能流失的客户更为有效。通过在市场营销策略中重点关注该模型预测的高流失概率客户，您可以以更具成本效益的方式留住这些有流失风险的客户。
- en: 'The full code for this exercise can be found in this repository: [https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.11/python/CustomerRetention.ipynb](https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.11/python/CustomerRetention.ipynb).'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 本练习的完整代码可以在此代码库中找到：[https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.11/python/CustomerRetention.ipynb](https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.11/python/CustomerRetention.ipynb)。
- en: Predicting customer churn with R
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用R预测客户流失
- en: In this section, we are going to discuss how to use an ANN model to predict
    the customers at risk of leaving or customers who are highly likely to churn.
    By the end of this section, we will have built a customer churn prediction model
    using the ANN model. We will be mainly using the `dplyr`, `ggplot2`, and `keras` libraries
    to analyze, visualize, and build machine learning models. For those readers who
    would like to use Python, instead of R, for this exercise, see the previous section.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论如何使用ANN模型预测有可能流失的客户或高度可能流失的客户。在本节结束时，我们将构建一个使用ANN模型的客户流失预测模型。我们将主要使用`dplyr`、`ggplot2`和`keras`库来分析、可视化和构建机器学习模型。对于那些希望使用Python而非R的读者，可以参阅前一节。
- en: 'For this exercise, we will be using one of the publicly available datasets
    from the IBM Watson Analytics community, which can be found at this link: [https://www.ibm.com/communities/analytics/watson-analytics-blog/predictive-insights-in-the-telco-customer-churn-data-set/](https://www.ibm.com/communities/analytics/watson-analytics-blog/predictive-insights-in-the-telco-customer-churn-data-set/).
    You can follow this link and download the data, which is available in XLSX format,
    named `WA_Fn-UseC_-Telco-Customer-Churn.xlsx`. Once you have downloaded this data,
    you can load it into your RStudio environment by running the following command:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将使用IBM Watson Analytics社区中公开的一个数据集，链接地址是：[https://www.ibm.com/communities/analytics/watson-analytics-blog/predictive-insights-in-the-telco-customer-churn-data-set/](https://www.ibm.com/communities/analytics/watson-analytics-blog/predictive-insights-in-the-telco-customer-churn-data-set/)。你可以通过这个链接下载数据，数据格式为XLSX，文件名为`WA_Fn-UseC_-Telco-Customer-Churn.xlsx`。下载数据后，你可以通过运行以下命令将其加载到你的RStudio环境中：
- en: '[PRE17]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The DataFrame, `df`, should look as in the following screenshot:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: DataFrame，`df`，应该像下面的截图一样：
- en: '![](img/d24ceede-a86b-41b1-bbd9-7666d58b0ced.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d24ceede-a86b-41b1-bbd9-7666d58b0ced.png)'
- en: There are 21 variables in this dataset, where our goal is to predict the target
    variable, `Churn`.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 这个数据集共有21个变量，我们的目标是预测目标变量`Churn`。
- en: Data analysis and preparation
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据分析与准备
- en: 'As you may have noticed by looking at the data, there are a few things we need
    to do before we start building machine learning models. In this section, we are
    going to transform continuous variables that have monetary values and encode the
    target variable, `Churn`, as well as other categorical variables. To do so, perform
    the following steps:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你可能从数据中看到的那样，在开始构建机器学习模型之前，我们需要做一些准备工作。在本节中，我们将转换具有货币值的连续变量，并编码目标变量`Churn`以及其他分类变量。为此，请执行以下步骤：
- en: '**Handling missing values in the data**: If you looked through the `TotalCharges` column
    in the dataset, you may have noticed that there are some records with no `TotalCharges` values.
    Since there are only `11` records with missing `TotalCharges` values, we are going
    to simply ignore and drop those records with missing values. Take a look at the
    following code:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**处理数据中的缺失值**：如果你查看了数据集中的`TotalCharges`列，你可能会注意到有些记录没有`TotalCharges`值。由于只有`11`条记录缺少`TotalCharges`值，我们将简单地忽略并删除这些缺失值的记录。请看下面的代码：'
- en: '[PRE18]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: As you may notice from this code, we are using the `drop_na` function in the `tidyr`
    package, which drops all records with `NA` values.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你从这段代码中可以看到的，我们使用了`tidyr`包中的`drop_na`函数，这个函数会删除所有含有`NA`值的记录。
- en: '**Categorical variables**: As you can see from the data, there are many categorical
    variables. Let''s first take a look at the number of unique values each column
    has. Take a look at the following code:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**分类变量**：如你从数据中看到的，有许多分类变量。我们首先来看一下每一列中有多少个唯一值。请看下面的代码：'
- en: '[PRE19]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'You can use the `unique` function to get the unique values in each column.
    By applying this function across all the columns in `df`, the output of this code
    looks like the following:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用`unique`函数获取每一列的唯一值。通过将这个函数应用于`df`中的所有列，代码输出结果如下：
- en: '![](img/1f273b2e-a384-444f-8f1f-7db9920dd7b9.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1f273b2e-a384-444f-8f1f-7db9920dd7b9.png)'
- en: As this output suggests, there are `7032` unique customer IDs, `2` unique genders,
    `3` unique values for `MultipleLines`, and `6530` unique values for `TotalCharges`.
    The `tenure`, `MonthlyCharges`, and `TotalCharges` variables, are continuous variables,
    where each variable can take any value and the rest are the categorical variables.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 从输出结果来看，数据集中有`7032`个唯一的客户ID，`2`个唯一的性别，`3`个唯一的`MultipleLines`值，和`6530`个唯一的`TotalCharges`值。`tenure`、`MonthlyCharges`和`TotalCharges`变量是连续变量，每个变量可以取任意值，其他则是分类变量。
- en: 'We are going to take a look at the distributions of some of these categorical
    variables. First, to view the distribution of the data between male and female,
    you can use the following code for visualization:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将查看一些分类变量的分布情况。首先，为了查看男性和女性之间的数据分布，你可以使用下面的代码进行可视化：
- en: '[PRE20]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The plot looks like this:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 绘图如下所示：
- en: '![](img/6260b535-4c47-4c74-80b2-af0ba8d0fafe.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6260b535-4c47-4c74-80b2-af0ba8d0fafe.png)'
- en: 'As you can see from this bar plot, the distribution of the data across the
    two genders is roughly equally distributed. You can use the same code to view
    the distribution of the data across different values of `InternetService` and `PaymentMethod`.
    Take a look at the following plots:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 从这张条形图中可以看出，两个性别的数据分布大致均衡。你可以使用相同的代码查看不同`InternetService`和`PaymentMethod`值下数据的分布。请查看下面的图：
- en: '![](img/680a8c86-bc81-438c-aef3-ba25bb90aee9.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![](img/680a8c86-bc81-438c-aef3-ba25bb90aee9.png)'
- en: '![](img/37b195d5-6b3d-4733-b792-c19443bf1187.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![](img/37b195d5-6b3d-4733-b792-c19443bf1187.png)'
- en: The first plot shows the distribution of the data across three different categories
    of the `InternetService` variable and the second plot shows the distribution of
    the data across four different categories of the `PaymentMethod` variable. As
    you can see from these plots, we can easily visualize and understand what the
    distributions of categorical variables look like using bar plots. We recommend
    that you draw bar plots for other categorical variables to get a better understanding
    of the data distribution.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个图展示了`InternetService`变量的三个不同类别下数据的分布，第二个图展示了`PaymentMethod`变量的四个不同类别下数据的分布。通过这些图，我们可以轻松地通过条形图可视化和理解分类变量的分布情况。我们建议你为其他分类变量绘制条形图，以便更好地了解数据分布。
- en: '**Transforming and encoding variables**: The next step is to transform the
    continuous variables and encode the binary-class categorical variables. Take a
    look at the following code:'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**变换和编码变量**：下一步是转化连续变量并编码二元分类变量。请看下面的代码：'
- en: '[PRE21]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'As you can see from this code, we are simply encoding those variables with
    only two categories, `gender`, `Partner`, `Dependents`, `PhoneService`, `PaperlessBilling`,
    and `Churn`, with `0`s and `1`s. Then, we apply log transformations to the two
    continuous variables that have monetary values, `MonthlyCharges` and `TotalCharges`.
    Also, we standardize all three continuous variables, `tenure`, `MonthlyCharges`,
    and `TotalCharges`, so that these variables center around `0` and have standard
    deviations of `1`. This is because ANN models typically perform better with scaled
    or normalized features. After transformations, the distributions of these three
    continuous variables look as in the following screenshot:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 从这段代码可以看出，我们仅对那些只有两个类别的变量进行编码，分别是`gender`、`Partner`、`Dependents`、`PhoneService`、`PaperlessBilling`和`Churn`，使用`0`和`1`。然后，我们对两个具有货币值的连续变量，`MonthlyCharges`和`TotalCharges`，应用对数变换。同时，我们标准化所有三个连续变量，`tenure`、`MonthlyCharges`和`TotalCharges`，使这些变量的均值为`0`，标准差为`1`。这是因为ANN模型通常在特征经过缩放或归一化后表现更好。经过变换后，这三个连续变量的分布如下图所示：
- en: '![](img/b8f430c2-8ecb-4a6b-91cf-6ab156c6950c.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b8f430c2-8ecb-4a6b-91cf-6ab156c6950c.png)'
- en: 'As you can see, the means of these three transformed variables are `0` and
    the standard deviations are `1`. Whereas, before this transformation, the distributions
    looked like the following:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，这三个变换后的变量的均值是`0`，标准差是`1`。而在此之前，这些分布看起来如下所示：
- en: '![](img/5e6d440f-d902-48a1-a6d9-1c66d4ede730.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5e6d440f-d902-48a1-a6d9-1c66d4ede730.png)'
- en: '**One-hot encoding categorical variables**: There is one last set of variables
    we need to transform: multi-class categorical variables that have three or more
    categories. We are going to apply one-hot encoding and create dummy variables
    for these variables. Take a look at the following code:'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**独热编码分类变量**：我们需要转化的最后一组变量是：具有三个或更多类别的多类别分类变量。我们将应用独热编码，为这些变量创建虚拟变量。请看下面的代码：'
- en: '[PRE22]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'As you can see from this code, we are using the `dummies` library to create
    dummy variables. Using the `dummy` function of this package, we can apply one-hot
    encoding and create dummy variables for each multi-class categorical variable.
    Since the `dummy` function prepends `sampleDF` to the names of the newly created
    dummy variables, we can replace it with corresponding variable name by using the `gsub`
    function. We are going to apply the same logic to the rest of the categorical
    variables, as shown in the following code:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，这段代码中我们使用了`dummies`库来创建虚拟变量。通过该包的`dummy`函数，我们可以应用独热编码并为每个多类别分类变量创建虚拟变量。由于`dummy`函数会将`sampleDF`前缀加到新创建的虚拟变量名称前，我们可以使用`gsub`函数将其替换为相应的变量名称。我们将对其余的分类变量应用相同的逻辑，如下所示：
- en: '[PRE23]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The results are shown in the following output:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 结果显示在以下输出中：
- en: '![](img/3f7333f7-b81f-4fae-8a53-06624b08ad67.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3f7333f7-b81f-4fae-8a53-06624b08ad67.png)'
- en: Once you have completed these four steps, it is time to start building ANN models
    for customer churn predictions. Move onto the next section for ANN modeling!
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 完成这四个步骤后，就可以开始构建用于客户流失预测的ANN模型了。继续下一节，进行ANN建模！
- en: ANN with Keras
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Keras构建ANN
- en: 'For building ANN models in R, we are going to use the `keras` package, which
    is a high-level neural networks library. For more details, we recommend you visit
    their official documentation at the following link: [https://keras.io/](https://keras.io/).
    Before we can use this package for building ANN models, we need to install two
    libraries:`tensorflow` and `keras`. The `keras` package uses `tensorflow` as a
    backend for building neural network models, so we need to install `tensorflow` first.
    You can install these two packages using the following commands in your RStudio:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在R中构建ANN模型时，我们将使用`keras`包，它是一个高级神经网络库。欲了解更多详细信息，建议访问其官方文档：[https://keras.io/](https://keras.io/)。在使用这个包构建ANN模型之前，我们需要安装两个库：`tensorflow`和`keras`。`keras`包使用`tensorflow`作为构建神经网络模型的后端，因此我们需要先安装`tensorflow`。你可以使用以下命令在RStudio中安装这两个包：
- en: '[PRE24]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Once you have installed these two libraries, we can finally start building
    our first neural network models. In this exercise, we are going to build a neural
    network model with one hidden layer. Take a look at the following code first:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 安装完这两个库后，我们终于可以开始构建我们的第一个神经网络模型了。在这个练习中，我们将构建一个具有一个隐藏层的神经网络模型。首先看一下下面的代码：
- en: '[PRE25]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Let's take a closer look at this code. First, we are building a `Sequential` model
    here, `keras_model_sequential`, which is the type of model where the layers are
    stacked linearly and looks similar to the diagram we saw in the earlier section
    about the MLP model. The first layer, `layer_dense`, is an input layer, where `input_shape` is
    simply the number of features or columns in the sample set and the number of output
    units is `16`. We are using the `relu` activation function for this input layer.
    Then, in the hidden layer, the number of output units is `8` and the activation
    function to be used is `relu`. Lastly, the output layer has one output unit, which
    is the probability of customer churn, and we use the `sigmoid` activation function
    in this layer. You can experiment with different numbers of output units and activation
    functions for your exercise. Lastly, we need to compile this model, using the `compile`
    function. Here, we are using the `adam` optimizer, which is one of the most frequently
    used optimization algorithms. Since our target variable is binary, we are using `binary_crossentropy` as
    the `loss` function. Lastly, this model will use the `accuracy` metric to evaluate
    model performance during training.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们仔细看看这段代码。首先，我们在这里构建了一个`Sequential`模型，`keras_model_sequential`，这是一种层次线性堆叠的模型，类似于我们在前面关于MLP模型部分看到的图示。第一层，`layer_dense`，是一个输入层，其中`input_shape`只是样本集中特征或列的数量，而输出单元的数量是`16`。我们在这个输入层使用的是`relu`激活函数。然后，在隐藏层中，输出单元的数量是`8`，并且使用的激活函数是`relu`。最后，输出层有一个输出单元，它表示客户流失的概率，我们在这一层使用`sigmoid`激活函数。你可以尝试不同数量的输出单元和激活函数进行练习。最后，我们需要编译这个模型，使用`compile`函数。在这里，我们使用`adam`优化器，它是最常用的优化算法之一。由于我们的目标变量是二元的，我们使用`binary_crossentropy`作为`loss`函数。最后，模型将使用`accuracy`指标来评估训练过程中的模型性能。
- en: 'Before we start training this neural network model, we will need to split our
    sample set into train and test sets. Take a look at the following code:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始训练这个神经网络模型之前，我们需要将样本集拆分成训练集和测试集。看一下下面的代码：
- en: '[PRE26]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'As you can see from this code, we are using the `sample.split` function of
    the `caTools` package. For our exercise, we will use 70% of the sample set for
    training and 30% for testing. Now we can train our neural network model using
    the following code:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 从这段代码中可以看到，我们正在使用 `caTools` 包的 `sample.split` 函数。在我们的练习中，我们将使用 70% 的样本集用于训练，30%
    用于测试。现在，我们可以使用以下代码训练神经网络模型：
- en: '[PRE27]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Here, we are using `100` samples as `batch_size`, from which the model is going
    to learn to predict every time, and `50` as the number of `epochs`, which is the
    number of complete passes through the entire training set. Once you run this code,
    you will see the following output:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用 `100` 个样本作为 `batch_size`，每次模型都将从中学习预测，并且使用 `50` 作为 `epochs` 的数量，即整个训练集的完整遍历次数。运行这段代码后，你将看到以下输出：
- en: '![](img/35a5fae0-f1a2-42df-903e-c27aba09ef92.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![](img/35a5fae0-f1a2-42df-903e-c27aba09ef92.png)'
- en: As you can see from this output, `loss` typically decreases and the accuracy
    (`acc`) improves in each epoch. However, the rate of model performance improvements
    decreases over time. As you can see from this output, there are big improvements
    in the loss and accuracy measures in the first few epochs and the amount of performance
    gain decreases over time. You can monitor this process and decide to stop when
    the amount of performance gain is minimal.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个输出中可以看到，`loss` 通常在每个 epoch 中减少，准确率（`acc`）提高。然而，模型性能改进的速度随着时间的推移而减慢。从输出中可以看出，在前几个
    epoch 中，损失和准确度指标有很大的改善，而随着时间推移，性能提升的幅度逐渐减少。你可以监控这个过程，并在性能提升最小时决定停止训练。
- en: Model evaluations
  id: totrans-146
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型评估
- en: 'Now that we have built our first neural network model, let''s evaluate its
    performance. We are going to look at the overall accuracy, precision, and recall,
    as well as the ROC curve and AUC. First, take a look at the following code for
    computing accuracy, precision, and recall:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经构建了第一个神经网络模型，让我们评估其性能。我们将查看整体准确率、精度和召回率，以及 ROC 曲线和 AUC。首先，查看以下计算准确率、精度和召回率的代码：
- en: '[PRE28]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'You should be familiar with this code, as we used the same evaluation metrics
    in [Chapter 8](4f5163a1-c34a-495f-bc5f-e02f9b2a2052.xhtml), *Predicting the Likelihood
    of Marketing Engagement*. The output of this code in our case looks like the following:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该熟悉这段代码，因为我们在[第 8 章](4f5163a1-c34a-495f-bc5f-e02f9b2a2052.xhtml)《预测营销互动的可能性》中使用了相同的评估指标。我们在本例中的代码输出如下：
- en: '![](img/d902f785-3d48-4cf3-a2cf-ea30f0ec423c.png)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d902f785-3d48-4cf3-a2cf-ea30f0ec423c.png)'
- en: Due to some randomness in the model, your results might differ from these numbers.
    As you can see from this output, the accuracy of predicting whether a customer
    will churn or not in the test set is about `0.83`, suggesting the model is correct
    roughly about 83% of the time. The out-of-sample precision suggests that the model
    is correct about 72% of the time it predicts that the customer is going to churn,
    and the out-of-sample recall suggests that the model captures roughly 58% of the
    churn cases.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 由于模型中的一些随机性，你的结果可能与这些数字有所不同。从这个输出中可以看到，预测客户是否会流失的准确率约为 `0.83`，表明该模型大约 83% 的时间是正确的。样本外精度表明，在预测客户会流失时，模型约有
    72% 的正确率，样本外召回率表明，模型捕捉到大约 58% 的流失案例。
- en: 'Next, we can compute the AUC and plot the ROC curve, using the following code:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们可以计算 AUC 并绘制 ROC 曲线，使用以下代码：
- en: '[PRE29]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'And the output looks like the following:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![](img/9f54bb8f-6c32-4411-86f8-36fb52b697b3.png)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9f54bb8f-6c32-4411-86f8-36fb52b697b3.png)'
- en: Along with the accuracy, precision, and recall measures that we looked at previously,
    the AUC and the ROC curve also suggest that the model captures and predicts those
    customers at churn risk pretty well. As you can see from these evaluation outputs,
    it is better to use the output of this model for identifying the customers who
    are likely to churn than simply guessing who they will be. By focusing on those
    customers with high churn probabilities from this model in your marketing strategies,
    you can try to retain those customers at churn risk in a more cost-effective way.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 除了我们之前查看的准确率、精度和召回率指标外，AUC 和 ROC 曲线还表明该模型很好地捕捉和预测了那些面临流失风险的客户。从这些评估结果中可以看出，使用该模型的输出来识别可能流失的客户，比单纯地猜测他们是谁要好得多。通过将营销策略集中在该模型预测的高流失概率客户身上，你可以更具成本效益地留住这些有流失风险的客户。
- en: The full code for this exercise can be found in this repository: [https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.11/R/CustomerRetention.R](https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.11/R/CustomerRetention.R).
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 本练习的完整代码可以在以下仓库找到：[https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.11/R/CustomerRetention.R](https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.11/R/CustomerRetention.R)。
- en: Summary
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we have learned about customer churn and retention. We have
    discussed the reasons why customer churn hurts businesses. More specifically,
    we have learned how retaining existing customers is much less expensive than acquiring
    new customers. We have shown some of the common reasons why customers leave a
    company, such as poor customer service, not finding enough value in products or
    services, lack of communications, and lack of customer loyalty. In order to understand
    why customers leave, we could conduct surveys or analyze customer data to understand
    their needs and pain points better. We have also discussed how we can train ANN models
    to identify those customers who are at risk of churning. Through programming exercises,
    we have learned how to use the `keras` library to build and train ANN models in
    Python and R.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们已经学习了客户流失和客户保持的相关内容。我们讨论了客户流失对企业的危害。更具体地说，我们了解了保持现有客户比获取新客户的成本要低得多。我们展示了客户离开公司的常见原因，例如：糟糕的客户服务、没有在产品或服务中找到足够的价值、沟通不畅和缺乏客户忠诚度。为了了解客户流失的原因，我们可以通过调查或分析客户数据来更好地了解他们的需求和痛点。我们还讨论了如何训练人工神经网络（ANN）模型来识别那些有流失风险的客户。通过编程练习，我们学习了如何使用`keras`库在Python和R中构建和训练ANN模型。
- en: In the following chapter, we are going to learn about A/B testing and how it
    can be used to determine the best marketing strategy among different options.
    We are going to discuss how to compute statistical significance in Python and
    R to help marketers decide which marketing strategy to choose among different
    ideas.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将学习A/B测试及其如何帮助确定在不同选项中最佳的营销策略。我们将讨论如何在Python和R中计算统计显著性，帮助营销人员决定在多个营销策略中选择哪一个。
