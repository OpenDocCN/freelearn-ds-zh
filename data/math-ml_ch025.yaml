- en: '15'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '15'
- en: Multivariable Functions
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: å¤šå˜é‡å‡½æ•°
- en: How different is multivariable calculus from its single-variable counterpart?
    When I was a student, I had a professor who used to say something like, â€œmultivariable
    and single-variable functions behave the same, you just have to write more.â€
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: å¤šå˜é‡å¾®ç§¯åˆ†ä¸å•å˜é‡å¾®ç§¯åˆ†æœ‰ä½•ä¸åŒï¼Ÿå½“æˆ‘è¿˜æ˜¯å­¦ç”Ÿæ—¶ï¼Œæˆ‘æœ‰ä¸€ä½æ•™æˆæ›¾ç»è¯´è¿‡ç±»ä¼¼çš„è¯ï¼šâ€œå¤šå˜é‡å’Œå•å˜é‡å‡½æ•°çš„è¡Œä¸ºæ˜¯ç›¸åŒçš„ï¼Œåªä¸è¿‡ä½ å¾—å†™æ›´å¤šçš„ä¸œè¥¿ã€‚â€
- en: 'Well, this couldnâ€™t be further from the truth. Just think about what we are
    doing in machine learning: training models with gradient descent; that is, finding
    a configuration of parameters that minimize a parametric function. In one variable
    (which is not a realistic assumption), we can do this with the derivative, as
    we saw in SectionÂ [13.2](ch021.xhtml#the-basics-of-gradient-descent). How can
    we extend the derivative to multiple dimensions?'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½å§ï¼Œè¿™ä¸ªè¯´æ³•è¿œç¦»äº‹å®ã€‚è¯•æƒ³ä¸€ä¸‹æˆ‘ä»¬åœ¨æœºå™¨å­¦ä¹ ä¸­åšçš„äº‹æƒ…ï¼šé€šè¿‡æ¢¯åº¦ä¸‹é™è®­ç»ƒæ¨¡å‹ï¼›ä¹Ÿå°±æ˜¯è¯´ï¼Œæ‰¾åˆ°ä¸€ä¸ªä½¿å‚æ•°å‡½æ•°æœ€å°åŒ–çš„å‚æ•°é…ç½®ã€‚åœ¨ä¸€ç»´ï¼ˆè™½ç„¶è¿™ä¸ªå‡è®¾å¹¶ä¸ç°å®ï¼‰ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡å¯¼æ•°æ¥å®ç°ï¼Œå°±åƒæˆ‘ä»¬åœ¨ç¬¬[13.2](ch021.xhtml#the-basics-of-gradient-descent)èŠ‚ä¸­çœ‹åˆ°çš„é‚£æ ·ã€‚é‚£ä¹ˆæˆ‘ä»¬å¦‚ä½•å°†å¯¼æ•°æ‰©å±•åˆ°å¤šç»´å‘¢ï¼Ÿ
- en: 'The inputs of multivariable functions are vectors. Thus, given a function f
    : â„^n â†’â„, we canâ€™t just define'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 'å¤šå˜é‡å‡½æ•°çš„è¾“å…¥æ˜¯å‘é‡ã€‚å› æ­¤ï¼Œç»™å®šä¸€ä¸ªå‡½æ•°f : â„^n â†’â„ï¼Œæˆ‘ä»¬ä¸èƒ½ä»…ä»…å®šä¹‰'
- en: '![df- f(x0)-âˆ’-f(x) n dx (x0 ) = xliâ†’mx0 x0 âˆ’ x , x0,x âˆˆ â„ ](img/file1428.png)'
  id: totrans-5
  prefs: []
  type: TYPE_IMG
  zh: '![df- f(x0)-âˆ’-f(x) n dx (x0 ) = xliâ†’mx0 x0 âˆ’ x , x0,x âˆˆ â„ ](img/file1428.png)'
- en: to the analogue of DefinitionÂ [54](ch020.xhtml#x1-198007r54). Why? Because the
    division with the vector x[0] âˆ’x is not defined.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹åº”äºå®šä¹‰[54](ch020.xhtml#x1-198007r54)çš„ç±»æ¯”ã€‚ä¸ºä»€ä¹ˆï¼Ÿå› ä¸ºä¸å‘é‡x[0] âˆ’xçš„é™¤æ³•æ˜¯æ²¡æœ‰å®šä¹‰çš„ã€‚
- en: 'As weâ€™ll see, differentiation in multiple dimensions is much more complicated.
    Think about it: in one dimension, there are only two directions, left and right.
    This is not true even for two dimensions, with an infinite number of directions
    at each point.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£å¦‚æˆ‘ä»¬å°†çœ‹åˆ°çš„ï¼Œå¤šç»´å¾®åˆ†è¦å¤æ‚å¾—å¤šã€‚æƒ³æƒ³çœ‹ï¼šåœ¨ä¸€ç»´ä¸­ï¼Œåªæœ‰ä¸¤ä¸ªæ–¹å‘ï¼Œå·¦å’Œå³ã€‚è€Œå³ä½¿æ˜¯åœ¨äºŒç»´ä¸­ï¼Œæ¯ä¸ªç‚¹çš„æ–¹å‘ä¹Ÿæ˜¯æ— é™å¤šçš„ã€‚
- en: So, what are multivariable functions anyway?
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ä¹ˆï¼Œç©¶ç«Ÿä»€ä¹ˆæ˜¯å¤šå˜é‡å‡½æ•°å‘¢ï¼Ÿ
- en: 15.1 What is a multivariable function?
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 15.1 ä»€ä¹ˆæ˜¯å¤šå˜é‡å‡½æ•°ï¼Ÿ
- en: We introduced functions in Chapter 9, as general mappings between two sets.
    However, weâ€™ve only discussed functions that map real numbers to real numbers.
    Simple scalar-scalar functions are great for conveying ideas, but the world around
    us is much more complex than what we could describe with them. At the other end
    of the spectrum, set-set functions are way too general to be useful.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åœ¨ç¬¬9ç« ä¸­ä»‹ç»äº†å‡½æ•°ï¼Œä½œä¸ºä¸¤ä¸ªé›†åˆä¹‹é—´çš„æ˜ å°„ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬åªè®¨è®ºäº†å°†å®æ•°æ˜ å°„åˆ°å®æ•°çš„å‡½æ•°ã€‚ç®€å•çš„æ ‡é‡-æ ‡é‡å‡½æ•°å¾ˆé€‚åˆä¼ è¾¾æ€æƒ³ï¼Œä½†æˆ‘ä»¬å‘¨å›´çš„ä¸–ç•Œæ¯”è¿™äº›å¯ä»¥æè¿°çš„è¦å¤æ‚å¾—å¤šã€‚åœ¨èŒƒå›´çš„å¦ä¸€ç«¯ï¼Œé›†åˆ-é›†åˆå‡½æ•°è¿‡äºä¸€èˆ¬åŒ–ï¼Œæ— æ³•å®é™…ä½¿ç”¨ã€‚
- en: 'In practice, three categories are special enough to be analyzed mathematically
    but general enough to describe the patterns in science and engineering: those
    that'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: å®é™…ä¸Šï¼Œä¸‰ä¸ªç±»åˆ«è¶³å¤Ÿç‰¹æ®Šï¼Œå¯ä»¥è¿›è¡Œæ•°å­¦åˆ†æï¼Œä½†åˆè¶³å¤Ÿé€šç”¨ï¼Œèƒ½å¤Ÿæè¿°ç§‘å­¦å’Œå·¥ç¨‹ä¸­çš„æ¨¡å¼ï¼šé‚£äº›
- en: 'map scalars to vectors, that is, f : â„ â†’â„^n,'
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'å°†æ ‡é‡æ˜ å°„åˆ°å‘é‡ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œf : â„ â†’â„^nï¼Œ'
- en: 'map vectors to scalars, that is, f : â„^n â†’â„,'
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'å°†å‘é‡æ˜ å°„åˆ°æ ‡é‡ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œf : â„^n â†’â„ï¼Œ'
- en: 'and those that map vectors to vectors, that is, f : â„^n â†’â„^m.'
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'ä»¥åŠé‚£äº›å°†å‘é‡æ˜ å°„åˆ°å‘é‡çš„å‡½æ•°ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œf : â„^n â†’â„^mã€‚'
- en: The scalar-vector variants are called curves, the vector-scalar ones are scalar
    fields, and the vector-vector functions are what we call vector fields. This nomenclature
    looks a bit abstract, so letâ€™s see some examples.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: æ ‡é‡-å‘é‡å˜ç§ç§°ä¸ºæ›²çº¿ï¼Œå‘é‡-æ ‡é‡å˜ç§ç§°ä¸ºæ ‡é‡åœºï¼Œè€Œå‘é‡-å‘é‡å‡½æ•°åˆ™æ˜¯æˆ‘ä»¬æ‰€è¯´çš„å‘é‡åœºã€‚è¿™ä¸ªå‘½åæœ‰ç‚¹æŠ½è±¡ï¼Œæ‰€ä»¥è®©æˆ‘ä»¬çœ‹çœ‹ä¸€äº›ä¾‹å­ã€‚
- en: Scalar-vector functions, or curves to use their more user-friendly name, are
    the mathematical representations of movement. A space station orbiting around
    Earth describes a curve. So does the trajectory of a stock in the market.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: æ ‡é‡-å‘é‡å‡½æ•°ï¼Œæˆ–è€…ç§°ä¸ºæ›²çº¿ï¼Œæ˜¯è¿åŠ¨çš„æ•°å­¦è¡¨ç¤ºã€‚ç¯ç»•åœ°çƒè¿è¡Œçš„ç©ºé—´ç«™æè¿°äº†ä¸€æ¡æ›²çº¿ã€‚è‚¡ç¥¨å¸‚åœºä¸­çš„è‚¡ç¥¨è½¨è¿¹ä¹Ÿæ˜¯å¦‚æ­¤ã€‚
- en: To give you a concrete example, the scalar-vector function
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: ç»™ä½ ä¸€ä¸ªå…·ä½“çš„ä¾‹å­ï¼Œæ ‡é‡-å‘é‡å‡½æ•°
- en: '![ âŒŠ âŒ‹ cos(t) f(t) = âŒˆ âŒ‰ sin(t) ](img/file1429.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![ âŒŠ âŒ‹ cos(t) f(t) = âŒˆ âŒ‰ sin(t) ](img/file1429.png)'
- en: describes the unit circle. This is illustrated by FigureÂ [15.1](#).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: æè¿°äº†å•ä½åœ†ã€‚è¿™åœ¨å›¾[15.1](#)ä¸­æœ‰æ‰€è¯´æ˜ã€‚
- en: '![PIC](img/file1430.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file1430.png)'
- en: 'FigureÂ 15.1: A scalar-vector function, that is, a curve'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾15.1ï¼šæ ‡é‡-å‘é‡å‡½æ•°ï¼Œå³æ›²çº¿
- en: Not all curves are closed. For example, the curve
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: å¹¶éæ‰€æœ‰æ›²çº¿éƒ½æ˜¯é—­åˆçš„ã€‚ä¾‹å¦‚ï¼Œæ›²çº¿
- en: '![ âŒŠ âŒ‹ | cos(t)| g(t) = | sin(t)| âŒˆ âŒ‰ t ](img/file1431.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![ âŒŠ âŒ‹ | cos(t)| g(t) = | sin(t)| âŒˆ âŒ‰ t ](img/file1431.png)'
- en: represents a motion that spirals upward, as illustrated by FigureÂ [15.2](#).
    These curves are called open.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: è¡¨ç¤ºä¸€ä¸ªèºæ—‹ä¸Šå‡çš„è¿åŠ¨ï¼Œå¦‚å›¾[15.2](#)æ‰€ç¤ºã€‚è¿™äº›æ›²çº¿ç§°ä¸ºå¼€å£æ›²çº¿ã€‚
- en: '![PIC](img/file1432.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file1432.png)'
- en: 'FigureÂ 15.2: An open curve'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾15.2ï¼šä¸€æ¡å¼€æ”¾æ›²çº¿
- en: Because of their inherent ability to describe trajectories, scalar-vector functions
    are essential in mathematics and science. Are you familiar with Newtonâ€™s second
    law of motion, stating that force equals mass times acceleration? This is described
    by the equation, F = ma, which is an instance of an ordinary differential equation.
    All of its solutions are curves.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºå®ƒä»¬å›ºæœ‰çš„æè¿°è½¨è¿¹çš„èƒ½åŠ›ï¼Œæ ‡é‡-çŸ¢é‡å‡½æ•°åœ¨æ•°å­¦å’Œç§‘å­¦ä¸­è‡³å…³é‡è¦ã€‚ä½ ç†Ÿæ‚‰ç‰›é¡¿ç¬¬äºŒå®šå¾‹å—ï¼Ÿå®ƒè¡¨æ˜åŠ›ç­‰äºè´¨é‡ä¹˜ä»¥åŠ é€Ÿåº¦ã€‚è¿™å¯ä»¥é€šè¿‡æ–¹ç¨‹ F = ma æ¥æè¿°ï¼Œè¿™æ˜¯ä¸€ä¸ªå¸¸å¾®åˆ†æ–¹ç¨‹çš„å®ä¾‹ã€‚å®ƒçš„æ‰€æœ‰è§£éƒ½æ˜¯æ›²çº¿ã€‚
- en: On the surface, scalar-vector functions have little to do with machine learning,
    but thatâ€™s not the case. Even though we wonâ€™t deal with them extensively, they
    have a serious presence behind the scenes. For instance, gradient descent is a
    discretized curve, as we saw in SectionÂ [13.3](ch021.xhtml#why-does-gradient-descent-work).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: è¡¨é¢ä¸Šçœ‹ï¼Œæ ‡é‡-çŸ¢é‡å‡½æ•°ä¸æœºå™¨å­¦ä¹ å‡ ä¹æ²¡æœ‰å…³ç³»ï¼Œä½†å®é™…ä¸Šå¹¶éå¦‚æ­¤ã€‚å°½ç®¡æˆ‘ä»¬ä¸ä¼šæ·±å…¥æ¢è®¨å®ƒä»¬ï¼Œä½†å®ƒä»¬åœ¨å¹•åæœ‰ç€é‡è¦çš„ä½œç”¨ã€‚ä¾‹å¦‚ï¼Œæ¢¯åº¦ä¸‹é™å°±æ˜¯ä¸€ä¸ªç¦»æ•£åŒ–çš„æ›²çº¿ï¼Œæ­£å¦‚æˆ‘ä»¬åœ¨ç¬¬[13.3](ch021.xhtml#why-does-gradient-descent-work)èŠ‚çœ‹åˆ°çš„é‚£æ ·ã€‚
- en: Vector-scalar functions will be our focus for the next few chapters. When I
    write â€œmultivariable function,â€ Iâ€™ll most often refer to a vector-scalar function.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: æ ‡é‡-çŸ¢é‡å‡½æ•°å°†æ˜¯æˆ‘ä»¬æ¥ä¸‹æ¥å‡ ç« çš„é‡ç‚¹ã€‚å½“æˆ‘è¯´â€œå¤šå˜é‡å‡½æ•°â€æ—¶ï¼Œæˆ‘é€šå¸¸æŒ‡çš„æ˜¯æ ‡é‡-çŸ¢é‡å‡½æ•°ã€‚
- en: 'Think about a map of a mountain landscape. This maps the height â€“ a scalar
    â€“ to each coordinate, thereby defining the surface. This is just a function f
    : â„Â² â†’â„ in mathematical terms.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 'æƒ³è±¡ä¸€ä¸‹å±±åœ°æ™¯è§‚çš„åœ°å›¾ã€‚å®ƒå°†é«˜åº¦â€”â€”ä¸€ä¸ªæ ‡é‡â€”â€”æ˜ å°„åˆ°æ¯ä¸ªåæ ‡ï¼Œä»è€Œå®šä¹‰äº†è¡¨é¢ã€‚ä»æ•°å­¦è§’åº¦æ¥çœ‹ï¼Œè¿™åªæ˜¯ä¸€ä¸ªå‡½æ•° f : â„Â² â†’ â„ã€‚'
- en: Thinking about scalar fields as surfaces is useful for building geometric intuition,
    giving us a way to visualize them as you can see in FigureÂ [15.3](#). (Note that
    the surface analog breaks down for dimensions larger than two.)
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: å°†æ ‡é‡åœºè§†ä¸ºè¡¨é¢æœ‰åŠ©äºæ„å»ºå‡ ä½•ç›´è§‰ï¼Œç»™æˆ‘ä»¬æä¾›äº†ä¸€ç§å¯è§†åŒ–å®ƒä»¬çš„æ–¹å¼ï¼Œæ­£å¦‚å›¾[15.3](#)æ‰€ç¤ºã€‚ï¼ˆæ³¨æ„ï¼Œå¯¹äºå¤§äºäºŒçš„ç»´åº¦ï¼Œè¡¨é¢ç±»æ¯”å°±ä¸æˆç«‹äº†ã€‚ï¼‰
- en: '![PIC](img/file1433.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file1433.png)'
- en: 'FigureÂ 15.3: A surface given by a vector-scalar function'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾15.3ï¼šç”±æ ‡é‡-çŸ¢é‡å‡½æ•°ç»™å‡ºçš„è¡¨é¢
- en: 'Letâ€™s clear up the notation first. If f : â„^n â†’â„ is a function of n variables,
    we might write f(x) for an x âˆˆâ„^n or f(x[1],â€¦,x[n]) for x[i] âˆˆâ„ if we want to
    emphasize the dependence on its variables. A function of n variables is the same
    as a function of a single vector variable. I know this seems confusing, but trust
    me, youâ€™ll get used to it in no time.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 'é¦–å…ˆè®©æˆ‘ä»¬æ¾„æ¸…ç¬¦å·ã€‚å¦‚æœ f : â„^n â†’ â„ æ˜¯ä¸€ä¸ª n å˜é‡çš„å‡½æ•°ï¼Œæˆ‘ä»¬å¯ä»¥å†™ä½œ f(x)ï¼Œå…¶ä¸­ x âˆˆ â„^nï¼Œæˆ–è€…å†™ä½œ f(x[1],â€¦,x[n])ï¼Œå…¶ä¸­
    x[i] âˆˆ â„ï¼Œå¦‚æœæˆ‘ä»¬æƒ³å¼ºè°ƒå®ƒå¯¹å˜é‡çš„ä¾èµ–å…³ç³»ã€‚n å˜é‡çš„å‡½æ•°ä¸å•ä¸€å‘é‡å˜é‡çš„å‡½æ•°æ˜¯ç›¸åŒçš„ã€‚æˆ‘çŸ¥é“è¿™çœ‹èµ·æ¥å¾ˆæ··ä¹±ï¼Œä½†ç›¸ä¿¡æˆ‘ï¼Œä½ å¾ˆå¿«å°±ä¼šä¹ æƒ¯çš„ã€‚'
- en: 'To give a concrete example for a vector-scalar function, letâ€™s consider pressure.
    Pressure is the ratio of the magnitude of the force and the area of the surface
    of contact:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†ç»™å‡ºä¸€ä¸ªæ ‡é‡-çŸ¢é‡å‡½æ•°çš„å…·ä½“ä¾‹å­ï¼Œæˆ‘ä»¬æ¥è€ƒè™‘å‹åŠ›ã€‚å‹åŠ›æ˜¯åŠ›çš„å¤§å°ä¸æ¥è§¦è¡¨é¢ç§¯ä¹‹æ¯”ï¼š
- en: '![p = F-. A ](img/file1434.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![p = F-. A ](img/file1434.png)'
- en: 'This can be thought of as a function of two variables: p(x,y) = xâˆ•y.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å¯ä»¥çœ‹ä½œæ˜¯ä¸€ä¸ªäºŒå˜é‡å‡½æ•°ï¼šp(x,y) = xâˆ•yã€‚
- en: To illustrate how problematic things can become in multiple dimensions, consider
    the pressure around (0,0). Although we havenâ€™t talked about the limits of multivariable
    functions yet, what do you think
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†è¯´æ˜åœ¨å¤šç»´ç©ºé—´ä¸­é—®é¢˜å¯èƒ½å˜å¾—å¤šä¹ˆå¤æ‚ï¼Œè€ƒè™‘ (0,0) å‘¨å›´çš„å‹åŠ›ã€‚å°½ç®¡æˆ‘ä»¬è¿˜æ²¡æœ‰è®¨è®ºå¤šå˜é‡å‡½æ•°çš„æé™ï¼Œä½†ä½ è§‰å¾—æ€ä¹ˆæ ·å‘¢ï¼Ÿ
- en: '![ x- (x,yli)â†’m(0,0)y ](img/file1435.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![ x- (x,yli)â†’m(0,0)y ](img/file1435.png)'
- en: should be?
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: åº”è¯¥æ˜¯ï¼Ÿ
- en: Based on how we defined limits for single-variable functions (see DefinitionÂ [51](ch019.xhtml#x1-190002r51)),
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: åŸºäºæˆ‘ä»¬ä¸ºå•å˜é‡å‡½æ•°å®šä¹‰æé™çš„æ–¹å¼ï¼ˆè§å®šä¹‰[51](ch019.xhtml#x1-190002r51)ï¼‰ï¼Œ
- en: '![ xn- nlâ†’imâˆ yn ](img/file1436.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![ xn- nlâ†’imâˆ yn ](img/file1436.png)'
- en: must match for all possible choices for x[n] and y[n]. This is not the case.
    Consider x[n] = Î±Â²âˆ•n and y[n] = Î±âˆ•n for any Î± real number. With this choice, we
    have
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: å¿…é¡»å¯¹æ‰€æœ‰å¯èƒ½çš„ x[n] å’Œ y[n] é€‰æ‹©åŒ¹é…ã€‚è¿™å¹¶éå¦‚æ­¤ã€‚è€ƒè™‘ x[n] = Î±Â²âˆ•n å’Œ y[n] = Î±âˆ•nï¼Œå…¶ä¸­ Î± æ˜¯ä»»æ„å®æ•°ã€‚é€šè¿‡è¿™ä¸ªé€‰æ‹©ï¼Œæˆ‘ä»¬å¾—åˆ°
- en: '![ 2 lim xn-= Î±-âˆ•n-= Î±. nâ†’ âˆ yn Î±âˆ•n ](img/file1437.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![ 2 lim xn-= Î±-âˆ•n-= Î±. nâ†’ âˆ yn Î±âˆ•n ](img/file1437.png)'
- en: Thus, the above limit is not defined. All we did here is approach zero along
    slightly different trajectories, yet the result is a total mess. In one variable,
    we have to flex our intellectual muscles to produce such examples; in multiple
    variables, a simple xâˆ•y will do the trick.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œä¸Šè¿°æé™æ˜¯æ²¡æœ‰å®šä¹‰çš„ã€‚æˆ‘ä»¬åœ¨è¿™é‡Œæ‰€åšçš„åªæ˜¯æ²¿ç€ç•¥å¾®ä¸åŒçš„è½¨è¿¹é€¼è¿‘é›¶ï¼Œç„¶è€Œç»“æœå´å®Œå…¨æ··ä¹±ã€‚åœ¨å•å˜é‡çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬éœ€è¦åŠ¨ç”¨æˆ‘ä»¬çš„æ™ºåŠ›æ‰èƒ½äº§ç”Ÿè¿™æ ·çš„ä¾‹å­ï¼›è€Œåœ¨å¤šå˜é‡çš„æƒ…å†µä¸‹ï¼Œç®€å•çš„
    xâˆ•y å°±è¶³å¤Ÿäº†ã€‚
- en: 'Vector-vector functions are called vector fields. For example, consider our
    solar system, modeled by â„Â³. Each point is affected by a gravitational force,
    which is a vector. Thus, the gravitational pull can be described by a f : â„Â³ â†’â„Â³
    function, hence the name vector field.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 'å‘é‡-å‘é‡å‡½æ•°ç§°ä¸ºå‘é‡åœºã€‚ä¾‹å¦‚ï¼Œè€ƒè™‘æˆ‘ä»¬çš„å¤ªé˜³ç³»ï¼Œç”¨ â„Â³ æ¥å»ºæ¨¡ã€‚æ¯ä¸ªç‚¹éƒ½å—åˆ°ä¸€ä¸ªå¼•åŠ›çš„å½±å“ï¼Œè¿™ä¸ªå¼•åŠ›æ˜¯ä¸€ä¸ªå‘é‡ã€‚å› æ­¤ï¼Œå¼•åŠ›å¯ä»¥é€šè¿‡ f : â„Â³
    â†’ â„Â³ å‡½æ•°æ¥æè¿°ï¼Œè¿™ä¹Ÿæ˜¯å‘é‡åœºè¿™ä¸ªåç§°çš„ç”±æ¥ã€‚'
- en: Although they are often hidden in the background, vector fields play an essential
    role in machine learning. Remember when we discussed why gradient descent works
    in SectionÂ [13.3](ch021.xhtml#why-does-gradient-descent-work)? (At least in one
    variable.) All the differential equations we have encountered there are equivalent
    to vector fields.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: å°½ç®¡å®ƒä»¬ç»å¸¸éšè—åœ¨èƒŒæ™¯ä¸­ï¼Œå‘é‡åœºåœ¨æœºå™¨å­¦ä¹ ä¸­æ‰®æ¼”ç€è‡³å…³é‡è¦çš„è§’è‰²ã€‚è¿˜è®°å¾—æˆ‘ä»¬åœ¨ç¬¬[13.3èŠ‚](ch021.xhtml#why-does-gradient-descent-work)ä¸­è®¨è®ºçš„ä¸ºä»€ä¹ˆæ¢¯åº¦ä¸‹é™æœ‰æ•ˆå—ï¼Ÿï¼ˆè‡³å°‘åœ¨ä¸€ä¸ªå˜é‡çš„æƒ…å†µä¸‹ã€‚ï¼‰æˆ‘ä»¬åœ¨é‚£å„¿é‡åˆ°çš„æ‰€æœ‰å¾®åˆ†æ–¹ç¨‹éƒ½ç­‰åŒäºå‘é‡åœºã€‚
- en: 'Why? Consider the differential equation x^â€² = f(x). If x(t) describes the trajectory
    of a moving object, then its derivative x^â€²(t) is its speed. Thus, we can interpret
    the equation x^â€²(t) = f(x(t)) as prescribing the speed of our object at every
    position. Itâ€™s not that spectacular when our object is moving in one dimension,
    but if the trajectory x : â„ â†’â„Â² describes a motion on the plane, the function
    f : â„Â² â†’â„Â² can be visualized neatly.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 'ä¸ºä»€ä¹ˆï¼Ÿè€ƒè™‘å¾®åˆ†æ–¹ç¨‹ x^â€² = f(x)ã€‚å¦‚æœ x(t) æè¿°äº†ä¸€ä¸ªç‰©ä½“çš„è¿åŠ¨è½¨è¿¹ï¼Œé‚£ä¹ˆå®ƒçš„å¯¼æ•° x^â€²(t) å°±æ˜¯å®ƒçš„é€Ÿåº¦ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥å°†æ–¹ç¨‹
    x^â€²(t) = f(x(t)) è§£é‡Šä¸ºåœ¨æ¯ä¸ªä½ç½®è§„å®šç‰©ä½“çš„é€Ÿåº¦ã€‚å½“ç‰©ä½“åœ¨ä¸€ç»´ç©ºé—´ä¸­è¿åŠ¨æ—¶ï¼Œè¿™å¹¶ä¸ç‰¹åˆ«æƒŠè‰³ï¼Œä½†å¦‚æœè½¨è¿¹ x : â„ â†’ â„Â² æè¿°äº†å¹³é¢ä¸Šçš„è¿åŠ¨ï¼Œé‚£ä¹ˆå‡½æ•°
    f : â„Â² â†’ â„Â² å¯ä»¥ç›´è§‚åœ°å‘ˆç°å‡ºæ¥ã€‚'
- en: For example, consider the population dynamics of a simple predator-prey system.
    Predators feed on the prey, thus, their numbers can grow in the abundance of food.
    In turn, over-consumption decreases the prey population, causing a famine among
    the predators and decreasing their numbers. This leads to a growth in the prey,
    and the cycle starts over again.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œè€ƒè™‘ä¸€ä¸ªç®€å•çš„æ•é£Ÿè€…-çŒç‰©ç³»ç»Ÿçš„äººå£åŠ¨æ€ã€‚æ•é£Ÿè€…ä»¥çŒç‰©ä¸ºé£Ÿï¼Œå› æ­¤åœ¨é£Ÿç‰©å……è¶³æ—¶ï¼Œå®ƒä»¬çš„æ•°é‡ä¼šå¢é•¿ã€‚åè¿‡æ¥ï¼Œè¿‡åº¦æ•é£Ÿä¼šå‡å°‘çŒç‰©ç§ç¾¤ï¼Œå¯¼è‡´æ•é£Ÿè€…çš„é¥¥è’å¹¶å‡å°‘å®ƒä»¬çš„æ•°é‡ã€‚è¿™å¯¼è‡´çŒç‰©ç§ç¾¤çš„å¢é•¿ï¼Œå¾ªç¯å†æ¬¡å¼€å§‹ã€‚
- en: 'If x[1](t) and x[2](t) are the size of the prey and predator populations, respectively,
    then their dynamics are described by the famous Lotka-Volterra equations:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœ x[1](t) å’Œ x[2](t) åˆ†åˆ«æ˜¯çŒç‰©å’Œæ•é£Ÿè€…ç§ç¾¤çš„å¤§å°ï¼Œé‚£ä¹ˆå®ƒä»¬çš„åŠ¨æ€ç”±è‘—åçš„ Lotka-Volterra æ–¹ç¨‹æè¿°ï¼š
- en: '![xâ€²1 = x1 âˆ’ x1x2 â€² x2 = x1x2 âˆ’ x2\. ](img/file1438.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![xâ€²1 = x1 âˆ’ x1x2 â€² x2 = x1x2 âˆ’ x2\. ](img/file1438.png)'
- en: If we represent the trajectory as the scalar-vector function
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬å°†è½¨è¿¹è¡¨ç¤ºä¸ºæ ‡é‡-å‘é‡å‡½æ•°
- en: '![ âŒŠ âŒ‹ x : â„ â†’ â„2, x (t) = âŒˆx1(t)âŒ‰, x2(t) ](img/file1439.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![ âŒŠ âŒ‹ x : â„ â†’ â„2, x (t) = âŒˆx1(t)âŒ‰, x2(t) ](img/file1439.png)'
- en: then the derivative
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åå¯¼æ•°ä¸º
- en: '![ âŒŠ âŒ‹ â€² âŒˆx â€²1(t)âŒ‰ x (t) = x â€²(t) 2 ](img/file1440.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![ âŒŠ âŒ‹ â€² âŒˆx â€²1(t)âŒ‰ x (t) = x â€²(t) 2 ](img/file1440.png)'
- en: is given by the vector-vector function
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±å‘é‡-å‘é‡å‡½æ•°ç»™å‡º
- en: '![ âŒŠ âŒ‹ 2 2 x1 âˆ’ x1x2 f : â„ â†’ â„ , f (x1,x2) = âŒˆ âŒ‰ . x1x2 âˆ’ x2 ](img/file1441.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![ âŒŠ âŒ‹ 2 2 x1 âˆ’ x1x2 f : â„ â†’ â„ , f (x1,x2) = âŒˆ âŒ‰ . x1x2 âˆ’ x2 ](img/file1441.png)'
- en: f can be visualized by drawing a vector onto each point of the plane, as illustrated
    by FigureÂ [13.4](#).
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: f å¯ä»¥é€šè¿‡åœ¨å¹³é¢ä¸Šçš„æ¯ä¸ªç‚¹ç»˜åˆ¶ä¸€ä¸ªå‘é‡æ¥å¯è§†åŒ–ï¼Œå¦‚å›¾[13.4](#)æ‰€ç¤ºã€‚
- en: '![PIC](img/file1442.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file1442.png)'
- en: 'FigureÂ 15.4: The vector field given by the Lotka-Volterra equations'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 15.4ï¼šç”± Lotka-Volterra æ–¹ç¨‹ç»™å‡ºçš„å‘é‡åœº
- en: Vector fields have serious applications in machine learning. As we shall see
    soon, the multivariable derivative (called gradient) defines a vector field.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: å‘é‡åœºåœ¨æœºå™¨å­¦ä¹ ä¸­æœ‰é‡è¦åº”ç”¨ã€‚æ­£å¦‚æˆ‘ä»¬å¾ˆå¿«ä¼šçœ‹åˆ°çš„ï¼Œå¤šå˜é‡å¯¼æ•°ï¼ˆç§°ä¸ºæ¢¯åº¦ï¼‰å®šä¹‰äº†ä¸€ä¸ªå‘é‡åœºã€‚
- en: Moreover, as indicated by the single-variable case (see SectionÂ [13.3](ch021.xhtml#why-does-gradient-descent-work)),
    the gradient descent algorithm will be the discretized trajectory determined by
    the vector field of the gradient.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼Œæ­£å¦‚å•å˜é‡æƒ…å†µæ‰€ç¤ºï¼ˆè§ç¬¬[13.3èŠ‚](ch021.xhtml#why-does-gradient-descent-work)ï¼‰ï¼Œæ¢¯åº¦ä¸‹é™ç®—æ³•å°†æ˜¯ç”±æ¢¯åº¦çš„å‘é‡åœºç¡®å®šçš„ç¦»æ•£åŒ–è½¨è¿¹ã€‚
- en: 'Now that we understand what multivariable functions are, letâ€™s see a special
    case. You know how we roll: examples are essential, and we always start with them
    whenever possible. This time, weâ€™ll put linear functions under the microscope.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬ç†è§£äº†å¤šå˜é‡å‡½æ•°çš„æ¦‚å¿µï¼Œè®©æˆ‘ä»¬æ¥çœ‹ä¸€ä¸ªç‰¹æ®Šæƒ…å†µã€‚ä½ çŸ¥é“æˆ‘ä»¬çš„æ–¹æ³•ï¼šä¸¾ä¾‹å­è‡³å…³é‡è¦ï¼Œæ¯å½“å¯èƒ½æ—¶æˆ‘ä»¬éƒ½ä¼šä»ä¸¾ä¾‹å¼€å§‹ã€‚è¿™æ¬¡ï¼Œæˆ‘ä»¬å°†çº¿æ€§å‡½æ•°æ”¾å¤§æ˜¾å¾®é•œä¸‹è§‚å¯Ÿã€‚
- en: 15.2 Linear functions in multiple variables
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 15.2 å¤šå˜é‡ä¸­çš„çº¿æ€§å‡½æ•°
- en: One of the most important functions in mathematics is the linear function. In
    one variable, it takes the form l(x) = ax + b, where a and b are arbitrary real
    numbers.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°å­¦ä¸­æœ€é‡è¦çš„å‡½æ•°ä¹‹ä¸€æ˜¯çº¿æ€§å‡½æ•°ã€‚åœ¨ä¸€ä¸ªå˜é‡çš„æƒ…å†µä¸‹ï¼Œå®ƒçš„å½¢å¼ä¸º l(x) = ax + bï¼Œå…¶ä¸­ a å’Œ b æ˜¯ä»»æ„å®æ•°ã€‚
- en: Weâ€™ve seen linear functions several times already. For instance, TheoremÂ [77](ch020.xhtml#x1-199002r77)
    gives that differentiation is equivalent to finding the best linear approximation.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å·²ç»å¤šæ¬¡è§è¿‡çº¿æ€§å‡½æ•°ã€‚ä¾‹å¦‚ï¼Œå®šç† [77](ch020.xhtml#x1-199002r77) è¯´æ˜ï¼Œå¾®åˆ†ç­‰åŒäºæ‰¾åˆ°æœ€å¥½çš„çº¿æ€§é€¼è¿‘ã€‚
- en: Linear functions, that is, functions of the form
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: çº¿æ€§å‡½æ•°ï¼Œä¹Ÿå°±æ˜¯å½¢å¦‚
- en: '![ âˆ‘n f (x1,...,xn) = b+ aixi, b,ai âˆˆ â„ i=1 ](img/file1443.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![ âˆ‘n f (x1,...,xn) = b+ aixi, b,ai âˆˆ â„ i=1 ](img/file1443.png)'
- en: are as important in multiple variables as in one.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å¤šå˜é‡ä¸­ï¼Œå®ƒä»¬å’Œåœ¨å•å˜é‡ä¸­ä¸€æ ·é‡è¦ã€‚
- en: 'To build up a deep understanding, weâ€™ll take a look at the simplest case: a
    line on the two-dimensional plane.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†å»ºç«‹æ·±åˆ»çš„ç†è§£ï¼Œæˆ‘ä»¬å°†çœ‹çœ‹æœ€ç®€å•çš„æƒ…å†µï¼šäºŒç»´å¹³é¢ä¸Šçš„ä¸€æ¡ç›´çº¿ã€‚
- en: '![PIC](img/file1444.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file1444.png)'
- en: 'FigureÂ 15.5: A line on the plane'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 15.5ï¼šå¹³é¢ä¸Šçš„ä¸€æ¡ç›´çº¿
- en: Given its normal vector m = (m[1],m[2]) and its arbitrary point v[0], the vector
    x is on the line if and only if m and x âˆ’v[0] is orthogonal, that is, if
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: ç»™å®šå…¶æ³•å‘é‡ m = (m[1],m[2]) å’Œä»»æ„ç‚¹ v[0]ï¼Œå¦‚æœä¸”ä»…å½“må’Œx âˆ’v[0]æ­£äº¤æ—¶ï¼Œå‘é‡xæ‰åœ¨ç›´çº¿ä¸Šï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œå¦‚æœ
- en: âŸ¨m, x âˆ’ v[0]âŸ© = 0 (15.1)
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: âŸ¨m, x âˆ’ v[0]âŸ© = 0 (15.1)
- en: holds. ([15.1](ch025.xhtml)) is called the normal vector equation of the line.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: ä¿æŒä¸å˜ã€‚([15.1](ch025.xhtml)) è¢«ç§°ä¸ºç›´çº¿çš„æ³•å‘é‡æ–¹ç¨‹ã€‚
- en: By using the bilinearity of the inner product and writing out âŸ¨m,xâŸ© in terms
    of their coordinates, we can simplify ([15.1](ch025.xhtml)). Assuming that m[2]â‰ 0,
    that is, the line is not parallel to the x[2] axis, a quick calculation yields
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡åˆ©ç”¨å†…ç§¯çš„åŒçº¿æ€§ç‰¹æ€§ï¼Œå¹¶ç”¨åæ ‡è¡¨ç¤ºâŸ¨m,xâŸ©ï¼Œæˆ‘ä»¬å¯ä»¥ç®€åŒ– ([15.1](ch025.xhtml))ã€‚å‡è®¾m[2]â‰ 0ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œç›´çº¿ä¸ä¸x[2]è½´å¹³è¡Œï¼Œå¿«é€Ÿè®¡ç®—å¾—åˆ°
- en: '![ m1- -1- x2 = âˆ’m2 x1 + m2 âŸ¨m, v0âŸ©. ](img/file1445.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![ m1- -1- x2 = âˆ’m2 x1 + m2 âŸ¨m, v0âŸ©. ](img/file1445.png)'
- en: This is a linear function of the single variable x[1] in its full glory. The
    coefficient âˆ’![m1- m2](img/file1446.png) describes the slope, while ![ 1 m2-](img/file1447.png)âŸ¨m,v[0]âŸ©
    describes the intercept.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯å•ä¸€å˜é‡x[1]çš„çº¿æ€§å‡½æ•°çš„å®Œæ•´å½¢å¼ã€‚ç³»æ•° âˆ’![m1- m2](img/file1446.png) æè¿°äº†æ–œç‡ï¼Œè€Œ ![ 1 m2-](img/file1447.png)âŸ¨m,v[0]âŸ©
    æè¿°äº†æˆªè·ã€‚
- en: In other words, linear functions are equivalent to vector equations of the form
    ([15.1](ch025.xhtml)), at least in one variable.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: æ¢å¥è¯è¯´ï¼Œçº¿æ€§å‡½æ•°ç­‰åŒäºå½¢å¦‚([15.1](ch025.xhtml))çš„å‘é‡æ–¹ç¨‹ï¼Œè‡³å°‘åœ¨ä¸€ä¸ªå˜é‡çš„æƒ…å†µä¸‹æ˜¯å¦‚æ­¤ã€‚
- en: What happens if we apply the same argument in higher dimensional spaces? In
    â„^(n+1), the normal vector equation
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬åœ¨æ›´é«˜ç»´ç©ºé—´ä¸­åº”ç”¨ç›¸åŒçš„è®ºè¯ï¼Œä¼šå‘ç”Ÿä»€ä¹ˆå‘¢ï¼Ÿåœ¨â„^(n+1)ä¸­ï¼Œæ³•å‘é‡æ–¹ç¨‹
- en: âŸ¨m, x âˆ’ v[0]âŸ© = 0, m, x, v[0] âˆˆ â„^(n+1) (15.2)
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: âŸ¨m, x âˆ’ v[0]âŸ© = 0, m, x, v[0] âˆˆ â„^(n+1) (15.2)
- en: defines a hyperplane, that is, an n-dimensional plane. (One dimension less than
    the embedding plane, which is â„^(n+1) in our case.) Unraveling ([15.2](ch025.xhtml)),
    we obtain
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: å®šä¹‰äº†ä¸€ä¸ªè¶…å¹³é¢ï¼Œä¹Ÿå°±æ˜¯ä¸€ä¸ªnç»´å¹³é¢ã€‚ï¼ˆæ¯”åµŒå…¥å¹³é¢å°‘ä¸€ä¸ªç»´åº¦ï¼Œåœ¨æˆ‘ä»¬çš„æƒ…å†µä¸‹æ˜¯â„^(n+1)ã€‚ï¼‰è§£å¼€ ([15.2](ch025.xhtml))ï¼Œæˆ‘ä»¬å¾—åˆ°
- en: '![ 1 âˆ‘n mi xn+1 = m----âŸ¨m, v0âŸ©âˆ’ m----xi. n+1 i=1 n+1 ](img/file1448.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![ 1 âˆ‘n mi xn+1 = m----âŸ¨m, v0âŸ©âˆ’ m----xi. n+1 i=1 n+1 ](img/file1448.png)'
- en: Thus, the general form of a linear function in n variables
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œnä¸ªå˜é‡çš„çº¿æ€§å‡½æ•°çš„é€šç”¨å½¢å¼
- en: '![ n f (x ,...,x ) = b+ âˆ‘ ax , b,a âˆˆ â„ 1 n i=1 i i i ](img/file1449.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![ n f (x ,...,x ) = b+ âˆ‘ ax , b,a âˆˆ â„ 1 n i=1 i i i ](img/file1449.png)'
- en: originates from the normal vector equation of the n-dimensional plane, embedded
    in the (n + 1)-dimensional space.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: èµ·æºäºåµŒå…¥åœ¨(n + 1)ç»´ç©ºé—´ä¸­çš„nç»´å¹³é¢çš„æ³•å‘é‡æ–¹ç¨‹ã€‚
- en: This can also be written in the vectorized form
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¹Ÿå¯ä»¥å†™æˆå‘é‡åŒ–å½¢å¼
- en: '![L(U,V ) = {f : U â†’ V | f is linear}](img/file1450.png)(15.3)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![L(U,V ) = {f : U â†’ V | f æ˜¯çº¿æ€§çš„}](img/file1450.png)(15.3)'
- en: which is how weâ€™ll mostly use it in the future. (Note that when looking at the
    matrix representation of a vector u âˆˆâ„^n, we always use the column form â„^(nÃ—1).
    Moreover, a is not the normal vector of the plane.)
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æˆ‘ä»¬ä»¥åå¤§å¤šæ•°æƒ…å†µä¸‹ä½¿ç”¨çš„æ–¹å¼ã€‚ï¼ˆæ³¨æ„ï¼Œåœ¨æŸ¥çœ‹å‘é‡u âˆˆ â„^nçš„çŸ©é˜µè¡¨ç¤ºæ—¶ï¼Œæˆ‘ä»¬æ€»æ˜¯ä½¿ç”¨åˆ—å‘é‡å½¢å¼â„^(nÃ—1)ã€‚æ­¤å¤–ï¼Œaå¹¶ä¸æ˜¯å¹³é¢çš„æ³•å‘é‡ã€‚ï¼‰
- en: Before we move on to study the inner workings of multivariable calculus, I want
    to emphasize how seriously multiple dimensions complicate things in machine learning.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä»¬ç»§ç»­ç ”ç©¶å¤šå˜é‡å¾®ç§¯åˆ†çš„å†…éƒ¨æœºåˆ¶ä¹‹å‰ï¼Œæˆ‘æƒ³å¼ºè°ƒä¸€ä¸‹ï¼Œåœ¨æœºå™¨å­¦ä¹ ä¸­ï¼Œå¤šç»´åº¦æ˜¯å¦‚ä½•è®©äº‹æƒ…å˜å¾—å¤æ‚çš„ã€‚
- en: 15.3 The curse of dimensionality
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 15.3 é«˜ç»´è¯…å’’
- en: 'First, letâ€™s talk about optimization. If all else fails, optimizing a single-variable
    function f : [a,b] â†’â„ can be as simple as partitioning [a,b] into a grid of n
    points, evaluating the function at each point, then finding the minima/maxima.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 'é¦–å…ˆï¼Œè®©æˆ‘ä»¬è°ˆè°ˆä¼˜åŒ–ã€‚å¦‚æœå…¶ä»–æ–¹æ³•éƒ½å¤±è´¥äº†ï¼Œä¼˜åŒ–ä¸€ä¸ªå•å˜é‡å‡½æ•° f : [a,b] â†’â„ å¯èƒ½å°±åƒå°† [a,b] åˆ’åˆ†ä¸ºnä¸ªç‚¹çš„ç½‘æ ¼ï¼Œè®¡ç®—æ¯ä¸ªç‚¹çš„å‡½æ•°å€¼ï¼Œç„¶åæ‰¾åˆ°æœ€å°å€¼/æœ€å¤§å€¼ä¸€æ ·ç®€å•ã€‚'
- en: We cannot do this in higher dimensions. To see why, consider ResNet18, the famous
    convolutional network architecture. It has precisely 11,689,512 parameters. Thus,
    training is equivalent to optimizing a function of a whopping 11,689,512-variable
    function. If we were to construct a grid with just two points along every dimension,
    we would have 2^(11689512) points to evaluate the function at. For comparison,
    the number of atoms in our observable universe is around 10^(82). A number that
    is dwarfed by the size of our grid. Thus, grid search is currently impossible
    on such an enormous grid. We are forced to devise clever algorithms that can tackle
    the size and complexity of large dimensional spaces.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ›´é«˜ç»´åº¦ä¸‹æˆ‘ä»¬æ— æ³•åšåˆ°è¿™ä¸€ç‚¹ã€‚ä¸ºäº†ç†è§£ä¸ºä»€ä¹ˆï¼Œè€ƒè™‘ ResNet18 è¿™ä¸€è‘—åçš„å·ç§¯ç¥ç»ç½‘ç»œæ¶æ„ã€‚å®ƒæœ‰ç²¾ç¡®çš„11,689,512ä¸ªå‚æ•°ã€‚å› æ­¤ï¼Œè®­ç»ƒç­‰åŒäºä¼˜åŒ–ä¸€ä¸ªæ‹¥æœ‰11,689,512ä¸ªå˜é‡çš„å‡½æ•°ã€‚å¦‚æœæˆ‘ä»¬åœ¨æ¯ä¸ªç»´åº¦ä¸Šæ„å»ºä¸€ä¸ªåŒ…å«ä¸¤ä¸ªç‚¹çš„ç½‘æ ¼ï¼Œæˆ‘ä»¬å°±ä¼šæœ‰
    2^(11689512) ä¸ªç‚¹éœ€è¦å¯¹å‡½æ•°è¿›è¡Œè¯„ä¼°ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œæˆ‘ä»¬å¯è§‚æµ‹åˆ°çš„å®‡å®™ä¸­çš„åŸå­æ•°å¤§çº¦ä¸º 10^(82)ã€‚è¿™ä¸ªæ•°å­—è¿œè¿œå°äºæˆ‘ä»¬ç½‘æ ¼çš„å¤§å°ã€‚å› æ­¤ï¼Œåœ¨å¦‚æ­¤å·¨å¤§çš„ç½‘æ ¼ä¸Šè¿›è¡Œç½‘æ ¼æœç´¢åœ¨å½“å‰æ˜¯ä¸å¯èƒ½çš„ã€‚æˆ‘ä»¬ä¸å¾—ä¸è®¾è®¡å·§å¦™çš„ç®—æ³•æ¥åº”å¯¹å¤§ç»´åº¦ç©ºé—´çš„è§„æ¨¡å’Œå¤æ‚æ€§ã€‚
- en: Another issue is that, in high dimensions, a strange thing starts to happen
    with balls. Recall that, by definition, the n-dimensional ball of radius r around
    the point x[0] âˆˆâ„^n is defined by
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: å¦ä¸€ä¸ªé—®é¢˜æ˜¯ï¼Œåœ¨é«˜ç»´ç©ºé—´ä¸­ï¼Œçƒä½“ä¼šå¼€å§‹å‡ºç°ä¸€ç§å¥‡æ€ªçš„ç°è±¡ã€‚å›æƒ³ä¸€ä¸‹ï¼Œæ ¹æ®å®šä¹‰ï¼Œnç»´ç©ºé—´ä¸­ä»¥ç‚¹ x[0] âˆˆâ„^n ä¸ºä¸­å¿ƒã€åŠå¾„ä¸º r çš„å•ä½çƒæ˜¯ç”±ä»¥ä¸‹æ–¹å¼å®šä¹‰çš„ï¼š
- en: '![Bn (r,x0) := {x âˆˆ â„n : âˆ¥x âˆ’ x0âˆ¥ <r}, ](img/file1451.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![Bn (r,x0) := {x âˆˆ â„n : âˆ¥x âˆ’ x0âˆ¥ <r}, ](img/file1451.png)'
- en: and we denote its volume by V [n](r). (The volume depends only on the radius
    and the dimension, not the center.)
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†å…¶ä½“ç§¯è®°ä½œ V [n](r)ã€‚ (ä½“ç§¯ä»…ä¾èµ–äºåŠå¾„å’Œç»´åº¦ï¼Œè€Œä¸ä¸­å¿ƒæ— å…³ã€‚)
- en: It turns out that
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: ç»“æœè¡¨æ˜ï¼Œ
- en: '![ Ï€ n2 n Vn(r) = Î“ (1+-n)r , 2 ](img/file1452.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![ Ï€ n2 n Vn(r) = Î“ (1+-n)r , 2 ](img/file1452.png)'
- en: where Î“(z) is the famous Gamma function ([https://en.wikipedia.org/wiki/Gamma_function](https://en.wikipedia.org/wiki/Gamma_function)),
    the generalization of the factorial.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ Î“(z) æ˜¯è‘—åçš„ä¼½é©¬å‡½æ•°ï¼ˆ[https://en.wikipedia.org/wiki/Gamma_function](https://en.wikipedia.org/wiki/Gamma_function)ï¼‰ï¼Œå®ƒæ˜¯é˜¶ä¹˜çš„æ¨å¹¿ã€‚
- en: The volume formula might seem complicated because of the Gamma function, the
    Ï€, and all the other terms, but letâ€™s focus on the core of the issue. What happens
    if we slice off an ğœ€-wide shell from the unit ball?
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: ä½“ç§¯å…¬å¼çœ‹èµ·æ¥å¯èƒ½å¾ˆå¤æ‚ï¼Œå› ä¸ºå®ƒæ¶‰åŠåˆ°ä¼½é©¬å‡½æ•°ã€Ï€ä»¥åŠå…¶ä»–æ‰€æœ‰é¡¹ï¼Œä½†æˆ‘ä»¬å¯ä»¥èšç„¦äºé—®é¢˜çš„æ ¸å¿ƒã€‚å¦‚æœæˆ‘ä»¬ä»å•ä½çƒä¸­åˆ‡å‰²å‡ºä¸€ä¸ªğœ€å®½çš„å¤–å£³ï¼Œä¼šå‘ç”Ÿä»€ä¹ˆå‘¢ï¼Ÿ
- en: 'It turns out that the volume of the unit ball is concentrated around its outer
    shell, as shown by the volume formula:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: ç»“æœè¡¨æ˜ï¼Œå•ä½çƒçš„ä½“ç§¯é›†ä¸­åœ¨å…¶å¤–å£³é™„è¿‘ï¼Œå¦‚ä½“ç§¯å…¬å¼æ‰€ç¤ºï¼š
- en: '![ lim Vn(1âˆ’--ğœ€)-= lim (1 âˆ’ ğœ€)n = 0\. nâ†’ âˆ Vn(1) nâ†’ âˆ ](img/file1453.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![ lim Vn(1âˆ’--ğœ€)-= lim (1 âˆ’ ğœ€)n = 0\. nâ†’ âˆ Vn(1) nâ†’ âˆ ](img/file1453.png)'
- en: Heuristically, this means that if you randomly select a point from the unit
    ball, its distance from the center will be close to 1 in high dimensions.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: ä»å¯å‘å¼è§’åº¦æ¥çœ‹ï¼Œè¿™æ„å‘³ç€å¦‚æœä½ ä»å•ä½çƒä¸­éšæœºé€‰æ‹©ä¸€ä¸ªç‚¹ï¼Œé‚£ä¹ˆåœ¨é«˜ç»´ç©ºé—´ä¸­ï¼Œå®ƒè·ç¦»ä¸­å¿ƒçš„è·ç¦»å°†æ¥è¿‘1ã€‚
- en: In other words, distance doesnâ€™t behave as you would intuitively expect. Another
    way of looking at the issue would be to study the effects of taking one step in
    each possible direction, starting from the origin and arriving at the point
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: æ¢å¥è¯è¯´ï¼Œè·ç¦»çš„å˜åŒ–å¹¶ä¸åƒä½ ç›´è§‰ä¸Šæ‰€æœŸæœ›çš„é‚£æ ·ã€‚å¦ä¸€ç§çœ‹å¾…è¿™ä¸ªé—®é¢˜çš„æ–¹æ³•æ˜¯ç ”ç©¶ä»åŸç‚¹å¼€å§‹ã€æœæ¯ä¸ªå¯èƒ½çš„æ–¹å‘è¿ˆä¸€æ­¥ååˆ°è¾¾æŸä¸€ç‚¹çš„å½±å“ã€‚
- en: '![1 = (1,1,...,1) âˆˆ â„n, ](img/file1454.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![1 = (1,1,...,1) âˆˆ â„n, ](img/file1454.png)'
- en: something like what FigureÂ [15.6](#) illustrates in the three-dimensional case.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚å›¾[15.6](#)æ‰€ç¤ºï¼Œè¿™ç§ç°è±¡åœ¨ä¸‰ç»´ç©ºé—´ä¸­ä¹Ÿæœ‰ç±»ä¼¼çš„è¡¨ç°ã€‚
- en: '![PIC](img/file1455.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file1455.png)'
- en: 'FigureÂ 15.6: Taking a step in each direction in three dimensions'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 15.6ï¼šåœ¨ä¸‰ç»´ç©ºé—´ä¸­æ¯ä¸ªæ–¹å‘ä¸Šè¿ˆå‡ºä¸€æ­¥
- en: The Euclidean distance we have traveled is
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬èµ°è¿‡çš„æ¬§å‡ é‡Œå¾—è·ç¦»æ˜¯ï¼š
- en: '![ â”Œ ----- â”‚â”‚ âˆ‘n âˆš -- âˆ¥1âˆ¥ = âˆ˜ 1 = n, i=1 ](img/file1456.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![ â”Œ ----- â”‚â”‚ âˆ‘n âˆš -- âˆ¥1âˆ¥ = âˆ˜ 1 = n, i=1 ](img/file1456.png)'
- en: which goes to infinity as the number of dimensions grows. That is, the diagonal
    of the unit cube is really big.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: éšç€ç»´åº¦çš„å¢åŠ ï¼Œå®ƒä¼šè¶‹å‘æ— ç©·å¤§ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œå•ä½ç«‹æ–¹ä½“çš„å¯¹è§’çº¿éå¸¸å¤§ã€‚
- en: These two phenomena can cause significant headaches in practice. More parameters
    result in more expressive models but also make training much more difficult. This
    is called the curse of dimensionality.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸¤ç§ç°è±¡åœ¨å®é™…åº”ç”¨ä¸­å¯èƒ½ä¼šå¸¦æ¥æ˜¾è‘—çš„å¤´ç—›ã€‚æ›´å¤šçš„å‚æ•°æ„å‘³ç€æ›´å…·è¡¨ç°åŠ›çš„æ¨¡å‹ï¼Œä½†ä¹Ÿä½¿å¾—è®­ç»ƒå˜å¾—æ›´åŠ å›°éš¾ã€‚è¿™å°±æ˜¯æ‰€è°“çš„â€œç»´åº¦çš„è¯…å’’â€ã€‚
- en: 15.4 Summary
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 15.4 å°ç»“
- en: In this chapter, we have dipped our toe into the ocean of multivariable functions.
    The very moment we add more dimensions, the complexity shoots up.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬åˆšåˆšè§¦åŠäº†å¤šå˜é‡å‡½æ•°çš„è¡¨é¢ã€‚åªè¦æˆ‘ä»¬å¢åŠ æ›´å¤šçš„ç»´åº¦ï¼Œå¤æ‚åº¦å°±ä¼šæ€¥å‰§ä¸Šå‡ã€‚
- en: 'For instance, we have three classes:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œæˆ‘ä»¬æœ‰ä¸‰ç±»ï¼š
- en: 'scalar-vector f : â„ â†’â„^n,'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'æ ‡é‡-å‘é‡å‡½æ•° f : â„ â†’â„^n,'
- en: 'vector-scalar f : â„^n â†’â„,'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'å‘é‡-æ ‡é‡å‡½æ•° f : â„^n â†’â„,'
- en: 'and vector-vector functions f : â„^n â†’â„^m.'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'å’Œå‘é‡-å‘é‡å‡½æ•° f : â„^n â†’â„^mã€‚'
- en: All of them are essential in machine learning. Feature transformations, like
    layers in neural networks, are vector-vector functions. Loss landscapes are given
    by vector-scalar functions, but training is done by following along a (discretized)
    scalar-vector function, also known as a curve.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒä»¬åœ¨æœºå™¨å­¦ä¹ ä¸­éƒ½æ˜¯è‡³å…³é‡è¦çš„ã€‚ç‰¹å¾è½¬æ¢ï¼Œå¦‚ç¥ç»ç½‘ç»œä¸­çš„å±‚ï¼Œæ˜¯å‘é‡-å‘é‡å‡½æ•°ã€‚æŸå¤±åœ°å½¢ç”±å‘é‡-æ ‡é‡å‡½æ•°ç»™å‡ºï¼Œä½†è®­ç»ƒæ˜¯é€šè¿‡æ²¿ç€ï¼ˆç¦»æ•£åŒ–çš„ï¼‰æ ‡é‡-å‘é‡å‡½æ•°è¿›è¡Œçš„ï¼Œä¹Ÿè¢«ç§°ä¸ºæ›²çº¿ã€‚
- en: 'Besides more complicated notations, we also have the curse of dimensionality
    to deal with. This is why optimizing functions of millions of variables is hard:
    not only does the parameter space get insanely large, but the concept of distance
    also begins to break down.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: é™¤äº†æ›´å¤æ‚çš„ç¬¦å·è¡¨ç¤ºå¤–ï¼Œæˆ‘ä»¬è¿˜å¿…é¡»åº”å¯¹ç»´åº¦çš„è¯…å’’ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆä¼˜åŒ–ç™¾ä¸‡å˜é‡çš„å‡½æ•°å¾ˆå›°éš¾ï¼šä¸ä»…å‚æ•°ç©ºé—´å˜å¾—å·¨å¤§ï¼Œè€Œä¸”è·ç¦»çš„æ¦‚å¿µä¹Ÿå¼€å§‹å¤±æ•ˆã€‚
- en: Now that weâ€™ve built some intuition about multivariable functions and familiarity
    with the notation, itâ€™s time to dive deep. How can we do calculus in higher dimensions?
    Letâ€™s see in the next chapter!
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å¯¹å¤šå˜é‡å‡½æ•°æœ‰äº†ä¸€äº›ç›´è§‰å¹¶ç†Ÿæ‚‰äº†ç¬¦å·è¡¨ç¤ºï¼Œæ¥ä¸‹æ¥è¯¥æ·±å…¥æ¢è®¨äº†ã€‚æˆ‘ä»¬å¦‚ä½•åœ¨æ›´é«˜ç»´åº¦ä¸­åšå¾®ç§¯åˆ†å‘¢ï¼Ÿè®©æˆ‘ä»¬åœ¨ä¸‹ä¸€ç« çœ‹çœ‹å§ï¼
- en: Join our community on Discord
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åŠ å…¥æˆ‘ä»¬çš„ Discord ç¤¾åŒº
- en: Read this book alongside other users, Machine Learning experts, and the author
    himself. Ask questions, provide solutions to other readers, chat with the author
    via Ask Me Anything sessions, and much more. Scan the QR code or visit the link
    to join the community. [https://packt.link/math](https://packt.link/math)
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸å…¶ä»–ç”¨æˆ·ã€æœºå™¨å­¦ä¹ ä¸“å®¶ä»¥åŠä½œè€…æœ¬äººä¸€èµ·é˜…è¯»è¿™æœ¬ä¹¦ã€‚æé—®ã€ä¸ºå…¶ä»–è¯»è€…æä¾›è§£å†³æ–¹æ¡ˆï¼Œé€šè¿‡â€œé—®æˆ‘ä»»ä½•é—®é¢˜â€ç¯èŠ‚ä¸ä½œè€…èŠå¤©ï¼Œè¿˜æœ‰æ›´å¤šå†…å®¹ã€‚æ‰«æäºŒç»´ç æˆ–è®¿é—®é“¾æ¥åŠ å…¥ç¤¾åŒºã€‚[https://packt.link/math](https://packt.link/math)
- en: '![PIC](img/file1.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](img/file1.png)'
