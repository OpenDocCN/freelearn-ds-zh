- en: '15'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '15'
- en: Multivariable Functions
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 多变量函数
- en: How different is multivariable calculus from its single-variable counterpart?
    When I was a student, I had a professor who used to say something like, “multivariable
    and single-variable functions behave the same, you just have to write more.”
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 多变量微积分与单变量微积分有何不同？当我还是学生时，我有一位教授曾经说过类似的话：“多变量和单变量函数的行为是相同的，只不过你得写更多的东西。”
- en: 'Well, this couldn’t be further from the truth. Just think about what we are
    doing in machine learning: training models with gradient descent; that is, finding
    a configuration of parameters that minimize a parametric function. In one variable
    (which is not a realistic assumption), we can do this with the derivative, as
    we saw in Section [13.2](ch021.xhtml#the-basics-of-gradient-descent). How can
    we extend the derivative to multiple dimensions?'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，这个说法远离事实。试想一下我们在机器学习中做的事情：通过梯度下降训练模型；也就是说，找到一个使参数函数最小化的参数配置。在一维（虽然这个假设并不现实）中，我们可以通过导数来实现，就像我们在第[13.2](ch021.xhtml#the-basics-of-gradient-descent)节中看到的那样。那么我们如何将导数扩展到多维呢？
- en: 'The inputs of multivariable functions are vectors. Thus, given a function f
    : ℝ^n →ℝ, we can’t just define'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '多变量函数的输入是向量。因此，给定一个函数f : ℝ^n →ℝ，我们不能仅仅定义'
- en: '![df- f(x0)-−-f(x) n dx (x0 ) = xli→mx0 x0 − x , x0,x ∈ ℝ ](img/file1428.png)'
  id: totrans-5
  prefs: []
  type: TYPE_IMG
  zh: '![df- f(x0)-−-f(x) n dx (x0 ) = xli→mx0 x0 − x , x0,x ∈ ℝ ](img/file1428.png)'
- en: to the analogue of Definition [54](ch020.xhtml#x1-198007r54). Why? Because the
    division with the vector x[0] −x is not defined.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 对应于定义[54](ch020.xhtml#x1-198007r54)的类比。为什么？因为与向量x[0] −x的除法是没有定义的。
- en: 'As we’ll see, differentiation in multiple dimensions is much more complicated.
    Think about it: in one dimension, there are only two directions, left and right.
    This is not true even for two dimensions, with an infinite number of directions
    at each point.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们将看到的，多维微分要复杂得多。想想看：在一维中，只有两个方向，左和右。而即使是在二维中，每个点的方向也是无限多的。
- en: So, what are multivariable functions anyway?
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，究竟什么是多变量函数呢？
- en: 15.1 What is a multivariable function?
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 15.1 什么是多变量函数？
- en: We introduced functions in Chapter 9, as general mappings between two sets.
    However, we’ve only discussed functions that map real numbers to real numbers.
    Simple scalar-scalar functions are great for conveying ideas, but the world around
    us is much more complex than what we could describe with them. At the other end
    of the spectrum, set-set functions are way too general to be useful.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在第9章中介绍了函数，作为两个集合之间的映射。然而，我们只讨论了将实数映射到实数的函数。简单的标量-标量函数很适合传达思想，但我们周围的世界比这些可以描述的要复杂得多。在范围的另一端，集合-集合函数过于一般化，无法实际使用。
- en: 'In practice, three categories are special enough to be analyzed mathematically
    but general enough to describe the patterns in science and engineering: those
    that'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，三个类别足够特殊，可以进行数学分析，但又足够通用，能够描述科学和工程中的模式：那些
- en: 'map scalars to vectors, that is, f : ℝ →ℝ^n,'
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '将标量映射到向量，也就是说，f : ℝ →ℝ^n，'
- en: 'map vectors to scalars, that is, f : ℝ^n →ℝ,'
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '将向量映射到标量，也就是说，f : ℝ^n →ℝ，'
- en: 'and those that map vectors to vectors, that is, f : ℝ^n →ℝ^m.'
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '以及那些将向量映射到向量的函数，也就是说，f : ℝ^n →ℝ^m。'
- en: The scalar-vector variants are called curves, the vector-scalar ones are scalar
    fields, and the vector-vector functions are what we call vector fields. This nomenclature
    looks a bit abstract, so let’s see some examples.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 标量-向量变种称为曲线，向量-标量变种称为标量场，而向量-向量函数则是我们所说的向量场。这个命名有点抽象，所以让我们看看一些例子。
- en: Scalar-vector functions, or curves to use their more user-friendly name, are
    the mathematical representations of movement. A space station orbiting around
    Earth describes a curve. So does the trajectory of a stock in the market.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 标量-向量函数，或者称为曲线，是运动的数学表示。环绕地球运行的空间站描述了一条曲线。股票市场中的股票轨迹也是如此。
- en: To give you a concrete example, the scalar-vector function
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 给你一个具体的例子，标量-向量函数
- en: '![ ⌊ ⌋ cos(t) f(t) = ⌈ ⌉ sin(t) ](img/file1429.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![ ⌊ ⌋ cos(t) f(t) = ⌈ ⌉ sin(t) ](img/file1429.png)'
- en: describes the unit circle. This is illustrated by Figure [15.1](#).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 描述了单位圆。这在图[15.1](#)中有所说明。
- en: '![PIC](img/file1430.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file1430.png)'
- en: 'Figure 15.1: A scalar-vector function, that is, a curve'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.1：标量-向量函数，即曲线
- en: Not all curves are closed. For example, the curve
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 并非所有曲线都是闭合的。例如，曲线
- en: '![ ⌊ ⌋ | cos(t)| g(t) = | sin(t)| ⌈ ⌉ t ](img/file1431.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![ ⌊ ⌋ | cos(t)| g(t) = | sin(t)| ⌈ ⌉ t ](img/file1431.png)'
- en: represents a motion that spirals upward, as illustrated by Figure [15.2](#).
    These curves are called open.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 表示一个螺旋上升的运动，如图[15.2](#)所示。这些曲线称为开口曲线。
- en: '![PIC](img/file1432.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file1432.png)'
- en: 'Figure 15.2: An open curve'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.2：一条开放曲线
- en: Because of their inherent ability to describe trajectories, scalar-vector functions
    are essential in mathematics and science. Are you familiar with Newton’s second
    law of motion, stating that force equals mass times acceleration? This is described
    by the equation, F = ma, which is an instance of an ordinary differential equation.
    All of its solutions are curves.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 由于它们固有的描述轨迹的能力，标量-矢量函数在数学和科学中至关重要。你熟悉牛顿第二定律吗？它表明力等于质量乘以加速度。这可以通过方程 F = ma 来描述，这是一个常微分方程的实例。它的所有解都是曲线。
- en: On the surface, scalar-vector functions have little to do with machine learning,
    but that’s not the case. Even though we won’t deal with them extensively, they
    have a serious presence behind the scenes. For instance, gradient descent is a
    discretized curve, as we saw in Section [13.3](ch021.xhtml#why-does-gradient-descent-work).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 表面上看，标量-矢量函数与机器学习几乎没有关系，但实际上并非如此。尽管我们不会深入探讨它们，但它们在幕后有着重要的作用。例如，梯度下降就是一个离散化的曲线，正如我们在第[13.3](ch021.xhtml#why-does-gradient-descent-work)节看到的那样。
- en: Vector-scalar functions will be our focus for the next few chapters. When I
    write “multivariable function,” I’ll most often refer to a vector-scalar function.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 标量-矢量函数将是我们接下来几章的重点。当我说“多变量函数”时，我通常指的是标量-矢量函数。
- en: 'Think about a map of a mountain landscape. This maps the height – a scalar
    – to each coordinate, thereby defining the surface. This is just a function f
    : ℝ² →ℝ in mathematical terms.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '想象一下山地景观的地图。它将高度——一个标量——映射到每个坐标，从而定义了表面。从数学角度来看，这只是一个函数 f : ℝ² → ℝ。'
- en: Thinking about scalar fields as surfaces is useful for building geometric intuition,
    giving us a way to visualize them as you can see in Figure [15.3](#). (Note that
    the surface analog breaks down for dimensions larger than two.)
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 将标量场视为表面有助于构建几何直觉，给我们提供了一种可视化它们的方式，正如图[15.3](#)所示。（注意，对于大于二的维度，表面类比就不成立了。）
- en: '![PIC](img/file1433.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file1433.png)'
- en: 'Figure 15.3: A surface given by a vector-scalar function'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.3：由标量-矢量函数给出的表面
- en: 'Let’s clear up the notation first. If f : ℝ^n →ℝ is a function of n variables,
    we might write f(x) for an x ∈ℝ^n or f(x[1],…,x[n]) for x[i] ∈ℝ if we want to
    emphasize the dependence on its variables. A function of n variables is the same
    as a function of a single vector variable. I know this seems confusing, but trust
    me, you’ll get used to it in no time.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '首先让我们澄清符号。如果 f : ℝ^n → ℝ 是一个 n 变量的函数，我们可以写作 f(x)，其中 x ∈ ℝ^n，或者写作 f(x[1],…,x[n])，其中
    x[i] ∈ ℝ，如果我们想强调它对变量的依赖关系。n 变量的函数与单一向量变量的函数是相同的。我知道这看起来很混乱，但相信我，你很快就会习惯的。'
- en: 'To give a concrete example for a vector-scalar function, let’s consider pressure.
    Pressure is the ratio of the magnitude of the force and the area of the surface
    of contact:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 为了给出一个标量-矢量函数的具体例子，我们来考虑压力。压力是力的大小与接触表面积之比：
- en: '![p = F-. A ](img/file1434.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![p = F-. A ](img/file1434.png)'
- en: 'This can be thought of as a function of two variables: p(x,y) = x∕y.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以看作是一个二变量函数：p(x,y) = x∕y。
- en: To illustrate how problematic things can become in multiple dimensions, consider
    the pressure around (0,0). Although we haven’t talked about the limits of multivariable
    functions yet, what do you think
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明在多维空间中问题可能变得多么复杂，考虑 (0,0) 周围的压力。尽管我们还没有讨论多变量函数的极限，但你觉得怎么样呢？
- en: '![ x- (x,yli)→m(0,0)y ](img/file1435.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![ x- (x,yli)→m(0,0)y ](img/file1435.png)'
- en: should be?
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 应该是？
- en: Based on how we defined limits for single-variable functions (see Definition [51](ch019.xhtml#x1-190002r51)),
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 基于我们为单变量函数定义极限的方式（见定义[51](ch019.xhtml#x1-190002r51)），
- en: '![ xn- nl→im∞ yn ](img/file1436.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![ xn- nl→im∞ yn ](img/file1436.png)'
- en: must match for all possible choices for x[n] and y[n]. This is not the case.
    Consider x[n] = α²∕n and y[n] = α∕n for any α real number. With this choice, we
    have
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 必须对所有可能的 x[n] 和 y[n] 选择匹配。这并非如此。考虑 x[n] = α²∕n 和 y[n] = α∕n，其中 α 是任意实数。通过这个选择，我们得到
- en: '![ 2 lim xn-= α-∕n-= α. n→ ∞ yn α∕n ](img/file1437.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![ 2 lim xn-= α-∕n-= α. n→ ∞ yn α∕n ](img/file1437.png)'
- en: Thus, the above limit is not defined. All we did here is approach zero along
    slightly different trajectories, yet the result is a total mess. In one variable,
    we have to flex our intellectual muscles to produce such examples; in multiple
    variables, a simple x∕y will do the trick.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，上述极限是没有定义的。我们在这里所做的只是沿着略微不同的轨迹逼近零，然而结果却完全混乱。在单变量的情况下，我们需要动用我们的智力才能产生这样的例子；而在多变量的情况下，简单的
    x∕y 就足够了。
- en: 'Vector-vector functions are called vector fields. For example, consider our
    solar system, modeled by ℝ³. Each point is affected by a gravitational force,
    which is a vector. Thus, the gravitational pull can be described by a f : ℝ³ →ℝ³
    function, hence the name vector field.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '向量-向量函数称为向量场。例如，考虑我们的太阳系，用 ℝ³ 来建模。每个点都受到一个引力的影响，这个引力是一个向量。因此，引力可以通过 f : ℝ³
    → ℝ³ 函数来描述，这也是向量场这个名称的由来。'
- en: Although they are often hidden in the background, vector fields play an essential
    role in machine learning. Remember when we discussed why gradient descent works
    in Section [13.3](ch021.xhtml#why-does-gradient-descent-work)? (At least in one
    variable.) All the differential equations we have encountered there are equivalent
    to vector fields.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管它们经常隐藏在背景中，向量场在机器学习中扮演着至关重要的角色。还记得我们在第[13.3节](ch021.xhtml#why-does-gradient-descent-work)中讨论的为什么梯度下降有效吗？（至少在一个变量的情况下。）我们在那儿遇到的所有微分方程都等同于向量场。
- en: 'Why? Consider the differential equation x^′ = f(x). If x(t) describes the trajectory
    of a moving object, then its derivative x^′(t) is its speed. Thus, we can interpret
    the equation x^′(t) = f(x(t)) as prescribing the speed of our object at every
    position. It’s not that spectacular when our object is moving in one dimension,
    but if the trajectory x : ℝ →ℝ² describes a motion on the plane, the function
    f : ℝ² →ℝ² can be visualized neatly.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '为什么？考虑微分方程 x^′ = f(x)。如果 x(t) 描述了一个物体的运动轨迹，那么它的导数 x^′(t) 就是它的速度。因此，我们可以将方程
    x^′(t) = f(x(t)) 解释为在每个位置规定物体的速度。当物体在一维空间中运动时，这并不特别惊艳，但如果轨迹 x : ℝ → ℝ² 描述了平面上的运动，那么函数
    f : ℝ² → ℝ² 可以直观地呈现出来。'
- en: For example, consider the population dynamics of a simple predator-prey system.
    Predators feed on the prey, thus, their numbers can grow in the abundance of food.
    In turn, over-consumption decreases the prey population, causing a famine among
    the predators and decreasing their numbers. This leads to a growth in the prey,
    and the cycle starts over again.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑一个简单的捕食者-猎物系统的人口动态。捕食者以猎物为食，因此在食物充足时，它们的数量会增长。反过来，过度捕食会减少猎物种群，导致捕食者的饥荒并减少它们的数量。这导致猎物种群的增长，循环再次开始。
- en: 'If x[1](t) and x[2](t) are the size of the prey and predator populations, respectively,
    then their dynamics are described by the famous Lotka-Volterra equations:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 x[1](t) 和 x[2](t) 分别是猎物和捕食者种群的大小，那么它们的动态由著名的 Lotka-Volterra 方程描述：
- en: '![x′1 = x1 − x1x2 ′ x2 = x1x2 − x2\. ](img/file1438.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![x′1 = x1 − x1x2 ′ x2 = x1x2 − x2\. ](img/file1438.png)'
- en: If we represent the trajectory as the scalar-vector function
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将轨迹表示为标量-向量函数
- en: '![ ⌊ ⌋ x : ℝ → ℝ2, x (t) = ⌈x1(t)⌉, x2(t) ](img/file1439.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![ ⌊ ⌋ x : ℝ → ℝ2, x (t) = ⌈x1(t)⌉, x2(t) ](img/file1439.png)'
- en: then the derivative
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 然后导数为
- en: '![ ⌊ ⌋ ′ ⌈x ′1(t)⌉ x (t) = x ′(t) 2 ](img/file1440.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![ ⌊ ⌋ ′ ⌈x ′1(t)⌉ x (t) = x ′(t) 2 ](img/file1440.png)'
- en: is given by the vector-vector function
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 由向量-向量函数给出
- en: '![ ⌊ ⌋ 2 2 x1 − x1x2 f : ℝ → ℝ , f (x1,x2) = ⌈ ⌉ . x1x2 − x2 ](img/file1441.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![ ⌊ ⌋ 2 2 x1 − x1x2 f : ℝ → ℝ , f (x1,x2) = ⌈ ⌉ . x1x2 − x2 ](img/file1441.png)'
- en: f can be visualized by drawing a vector onto each point of the plane, as illustrated
    by Figure [13.4](#).
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: f 可以通过在平面上的每个点绘制一个向量来可视化，如图[13.4](#)所示。
- en: '![PIC](img/file1442.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file1442.png)'
- en: 'Figure 15.4: The vector field given by the Lotka-Volterra equations'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15.4：由 Lotka-Volterra 方程给出的向量场
- en: Vector fields have serious applications in machine learning. As we shall see
    soon, the multivariable derivative (called gradient) defines a vector field.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 向量场在机器学习中有重要应用。正如我们很快会看到的，多变量导数（称为梯度）定义了一个向量场。
- en: Moreover, as indicated by the single-variable case (see Section [13.3](ch021.xhtml#why-does-gradient-descent-work)),
    the gradient descent algorithm will be the discretized trajectory determined by
    the vector field of the gradient.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，正如单变量情况所示（见第[13.3节](ch021.xhtml#why-does-gradient-descent-work)），梯度下降算法将是由梯度的向量场确定的离散化轨迹。
- en: 'Now that we understand what multivariable functions are, let’s see a special
    case. You know how we roll: examples are essential, and we always start with them
    whenever possible. This time, we’ll put linear functions under the microscope.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们理解了多变量函数的概念，让我们来看一个特殊情况。你知道我们的方法：举例子至关重要，每当可能时我们都会从举例开始。这次，我们将线性函数放大显微镜下观察。
- en: 15.2 Linear functions in multiple variables
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 15.2 多变量中的线性函数
- en: One of the most important functions in mathematics is the linear function. In
    one variable, it takes the form l(x) = ax + b, where a and b are arbitrary real
    numbers.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 数学中最重要的函数之一是线性函数。在一个变量的情况下，它的形式为 l(x) = ax + b，其中 a 和 b 是任意实数。
- en: We’ve seen linear functions several times already. For instance, Theorem [77](ch020.xhtml#x1-199002r77)
    gives that differentiation is equivalent to finding the best linear approximation.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经多次见过线性函数。例如，定理 [77](ch020.xhtml#x1-199002r77) 说明，微分等同于找到最好的线性逼近。
- en: Linear functions, that is, functions of the form
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 线性函数，也就是形如
- en: '![ ∑n f (x1,...,xn) = b+ aixi, b,ai ∈ ℝ i=1 ](img/file1443.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![ ∑n f (x1,...,xn) = b+ aixi, b,ai ∈ ℝ i=1 ](img/file1443.png)'
- en: are as important in multiple variables as in one.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在多变量中，它们和在单变量中一样重要。
- en: 'To build up a deep understanding, we’ll take a look at the simplest case: a
    line on the two-dimensional plane.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 为了建立深刻的理解，我们将看看最简单的情况：二维平面上的一条直线。
- en: '![PIC](img/file1444.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file1444.png)'
- en: 'Figure 15.5: A line on the plane'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15.5：平面上的一条直线
- en: Given its normal vector m = (m[1],m[2]) and its arbitrary point v[0], the vector
    x is on the line if and only if m and x −v[0] is orthogonal, that is, if
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 给定其法向量 m = (m[1],m[2]) 和任意点 v[0]，如果且仅当m和x −v[0]正交时，向量x才在直线上，也就是说，如果
- en: ⟨m, x − v[0]⟩ = 0 (15.1)
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: ⟨m, x − v[0]⟩ = 0 (15.1)
- en: holds. ([15.1](ch025.xhtml)) is called the normal vector equation of the line.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 保持不变。([15.1](ch025.xhtml)) 被称为直线的法向量方程。
- en: By using the bilinearity of the inner product and writing out ⟨m,x⟩ in terms
    of their coordinates, we can simplify ([15.1](ch025.xhtml)). Assuming that m[2]≠0,
    that is, the line is not parallel to the x[2] axis, a quick calculation yields
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 通过利用内积的双线性特性，并用坐标表示⟨m,x⟩，我们可以简化 ([15.1](ch025.xhtml))。假设m[2]≠0，也就是说，直线不与x[2]轴平行，快速计算得到
- en: '![ m1- -1- x2 = −m2 x1 + m2 ⟨m, v0⟩. ](img/file1445.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![ m1- -1- x2 = −m2 x1 + m2 ⟨m, v0⟩. ](img/file1445.png)'
- en: This is a linear function of the single variable x[1] in its full glory. The
    coefficient −![m1- m2](img/file1446.png) describes the slope, while ![ 1 m2-](img/file1447.png)⟨m,v[0]⟩
    describes the intercept.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这是单一变量x[1]的线性函数的完整形式。系数 −![m1- m2](img/file1446.png) 描述了斜率，而 ![ 1 m2-](img/file1447.png)⟨m,v[0]⟩
    描述了截距。
- en: In other words, linear functions are equivalent to vector equations of the form
    ([15.1](ch025.xhtml)), at least in one variable.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，线性函数等同于形如([15.1](ch025.xhtml))的向量方程，至少在一个变量的情况下是如此。
- en: What happens if we apply the same argument in higher dimensional spaces? In
    ℝ^(n+1), the normal vector equation
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们在更高维空间中应用相同的论证，会发生什么呢？在ℝ^(n+1)中，法向量方程
- en: ⟨m, x − v[0]⟩ = 0, m, x, v[0] ∈ ℝ^(n+1) (15.2)
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: ⟨m, x − v[0]⟩ = 0, m, x, v[0] ∈ ℝ^(n+1) (15.2)
- en: defines a hyperplane, that is, an n-dimensional plane. (One dimension less than
    the embedding plane, which is ℝ^(n+1) in our case.) Unraveling ([15.2](ch025.xhtml)),
    we obtain
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 定义了一个超平面，也就是一个n维平面。（比嵌入平面少一个维度，在我们的情况下是ℝ^(n+1)。）解开 ([15.2](ch025.xhtml))，我们得到
- en: '![ 1 ∑n mi xn+1 = m----⟨m, v0⟩− m----xi. n+1 i=1 n+1 ](img/file1448.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![ 1 ∑n mi xn+1 = m----⟨m, v0⟩− m----xi. n+1 i=1 n+1 ](img/file1448.png)'
- en: Thus, the general form of a linear function in n variables
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，n个变量的线性函数的通用形式
- en: '![ n f (x ,...,x ) = b+ ∑ ax , b,a ∈ ℝ 1 n i=1 i i i ](img/file1449.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![ n f (x ,...,x ) = b+ ∑ ax , b,a ∈ ℝ 1 n i=1 i i i ](img/file1449.png)'
- en: originates from the normal vector equation of the n-dimensional plane, embedded
    in the (n + 1)-dimensional space.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 起源于嵌入在(n + 1)维空间中的n维平面的法向量方程。
- en: This can also be written in the vectorized form
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 这也可以写成向量化形式
- en: '![L(U,V ) = {f : U → V | f is linear}](img/file1450.png)(15.3)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![L(U,V ) = {f : U → V | f 是线性的}](img/file1450.png)(15.3)'
- en: which is how we’ll mostly use it in the future. (Note that when looking at the
    matrix representation of a vector u ∈ℝ^n, we always use the column form ℝ^(n×1).
    Moreover, a is not the normal vector of the plane.)
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们以后大多数情况下使用的方式。（注意，在查看向量u ∈ ℝ^n的矩阵表示时，我们总是使用列向量形式ℝ^(n×1)。此外，a并不是平面的法向量。）
- en: Before we move on to study the inner workings of multivariable calculus, I want
    to emphasize how seriously multiple dimensions complicate things in machine learning.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续研究多变量微积分的内部机制之前，我想强调一下，在机器学习中，多维度是如何让事情变得复杂的。
- en: 15.3 The curse of dimensionality
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 15.3 高维诅咒
- en: 'First, let’s talk about optimization. If all else fails, optimizing a single-variable
    function f : [a,b] →ℝ can be as simple as partitioning [a,b] into a grid of n
    points, evaluating the function at each point, then finding the minima/maxima.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '首先，让我们谈谈优化。如果其他方法都失败了，优化一个单变量函数 f : [a,b] →ℝ 可能就像将 [a,b] 划分为n个点的网格，计算每个点的函数值，然后找到最小值/最大值一样简单。'
- en: We cannot do this in higher dimensions. To see why, consider ResNet18, the famous
    convolutional network architecture. It has precisely 11,689,512 parameters. Thus,
    training is equivalent to optimizing a function of a whopping 11,689,512-variable
    function. If we were to construct a grid with just two points along every dimension,
    we would have 2^(11689512) points to evaluate the function at. For comparison,
    the number of atoms in our observable universe is around 10^(82). A number that
    is dwarfed by the size of our grid. Thus, grid search is currently impossible
    on such an enormous grid. We are forced to devise clever algorithms that can tackle
    the size and complexity of large dimensional spaces.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在更高维度下我们无法做到这一点。为了理解为什么，考虑 ResNet18 这一著名的卷积神经网络架构。它有精确的11,689,512个参数。因此，训练等同于优化一个拥有11,689,512个变量的函数。如果我们在每个维度上构建一个包含两个点的网格，我们就会有
    2^(11689512) 个点需要对函数进行评估。相比之下，我们可观测到的宇宙中的原子数大约为 10^(82)。这个数字远远小于我们网格的大小。因此，在如此巨大的网格上进行网格搜索在当前是不可能的。我们不得不设计巧妙的算法来应对大维度空间的规模和复杂性。
- en: Another issue is that, in high dimensions, a strange thing starts to happen
    with balls. Recall that, by definition, the n-dimensional ball of radius r around
    the point x[0] ∈ℝ^n is defined by
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个问题是，在高维空间中，球体会开始出现一种奇怪的现象。回想一下，根据定义，n维空间中以点 x[0] ∈ℝ^n 为中心、半径为 r 的单位球是由以下方式定义的：
- en: '![Bn (r,x0) := {x ∈ ℝn : ∥x − x0∥ <r}, ](img/file1451.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![Bn (r,x0) := {x ∈ ℝn : ∥x − x0∥ <r}, ](img/file1451.png)'
- en: and we denote its volume by V [n](r). (The volume depends only on the radius
    and the dimension, not the center.)
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将其体积记作 V [n](r)。 (体积仅依赖于半径和维度，而与中心无关。)
- en: It turns out that
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 结果表明，
- en: '![ π n2 n Vn(r) = Γ (1+-n)r , 2 ](img/file1452.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![ π n2 n Vn(r) = Γ (1+-n)r , 2 ](img/file1452.png)'
- en: where Γ(z) is the famous Gamma function ([https://en.wikipedia.org/wiki/Gamma_function](https://en.wikipedia.org/wiki/Gamma_function)),
    the generalization of the factorial.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 Γ(z) 是著名的伽马函数（[https://en.wikipedia.org/wiki/Gamma_function](https://en.wikipedia.org/wiki/Gamma_function)），它是阶乘的推广。
- en: The volume formula might seem complicated because of the Gamma function, the
    π, and all the other terms, but let’s focus on the core of the issue. What happens
    if we slice off an 𝜀-wide shell from the unit ball?
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 体积公式看起来可能很复杂，因为它涉及到伽马函数、π以及其他所有项，但我们可以聚焦于问题的核心。如果我们从单位球中切割出一个𝜀宽的外壳，会发生什么呢？
- en: 'It turns out that the volume of the unit ball is concentrated around its outer
    shell, as shown by the volume formula:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 结果表明，单位球的体积集中在其外壳附近，如体积公式所示：
- en: '![ lim Vn(1−--𝜀)-= lim (1 − 𝜀)n = 0\. n→ ∞ Vn(1) n→ ∞ ](img/file1453.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![ lim Vn(1−--𝜀)-= lim (1 − 𝜀)n = 0\. n→ ∞ Vn(1) n→ ∞ ](img/file1453.png)'
- en: Heuristically, this means that if you randomly select a point from the unit
    ball, its distance from the center will be close to 1 in high dimensions.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 从启发式角度来看，这意味着如果你从单位球中随机选择一个点，那么在高维空间中，它距离中心的距离将接近1。
- en: In other words, distance doesn’t behave as you would intuitively expect. Another
    way of looking at the issue would be to study the effects of taking one step in
    each possible direction, starting from the origin and arriving at the point
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，距离的变化并不像你直觉上所期望的那样。另一种看待这个问题的方法是研究从原点开始、朝每个可能的方向迈一步后到达某一点的影响。
- en: '![1 = (1,1,...,1) ∈ ℝn, ](img/file1454.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![1 = (1,1,...,1) ∈ ℝn, ](img/file1454.png)'
- en: something like what Figure [15.6](#) illustrates in the three-dimensional case.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 如图[15.6](#)所示，这种现象在三维空间中也有类似的表现。
- en: '![PIC](img/file1455.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file1455.png)'
- en: 'Figure 15.6: Taking a step in each direction in three dimensions'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15.6：在三维空间中每个方向上迈出一步
- en: The Euclidean distance we have traveled is
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们走过的欧几里得距离是：
- en: '![ ┌ ----- ││ ∑n √ -- ∥1∥ = ∘ 1 = n, i=1 ](img/file1456.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![ ┌ ----- ││ ∑n √ -- ∥1∥ = ∘ 1 = n, i=1 ](img/file1456.png)'
- en: which goes to infinity as the number of dimensions grows. That is, the diagonal
    of the unit cube is really big.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 随着维度的增加，它会趋向无穷大。也就是说，单位立方体的对角线非常大。
- en: These two phenomena can cause significant headaches in practice. More parameters
    result in more expressive models but also make training much more difficult. This
    is called the curse of dimensionality.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 这两种现象在实际应用中可能会带来显著的头痛。更多的参数意味着更具表现力的模型，但也使得训练变得更加困难。这就是所谓的“维度的诅咒”。
- en: 15.4 Summary
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 15.4 小结
- en: In this chapter, we have dipped our toe into the ocean of multivariable functions.
    The very moment we add more dimensions, the complexity shoots up.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们刚刚触及了多变量函数的表面。只要我们增加更多的维度，复杂度就会急剧上升。
- en: 'For instance, we have three classes:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们有三类：
- en: 'scalar-vector f : ℝ →ℝ^n,'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '标量-向量函数 f : ℝ →ℝ^n,'
- en: 'vector-scalar f : ℝ^n →ℝ,'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '向量-标量函数 f : ℝ^n →ℝ,'
- en: 'and vector-vector functions f : ℝ^n →ℝ^m.'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '和向量-向量函数 f : ℝ^n →ℝ^m。'
- en: All of them are essential in machine learning. Feature transformations, like
    layers in neural networks, are vector-vector functions. Loss landscapes are given
    by vector-scalar functions, but training is done by following along a (discretized)
    scalar-vector function, also known as a curve.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 它们在机器学习中都是至关重要的。特征转换，如神经网络中的层，是向量-向量函数。损失地形由向量-标量函数给出，但训练是通过沿着（离散化的）标量-向量函数进行的，也被称为曲线。
- en: 'Besides more complicated notations, we also have the curse of dimensionality
    to deal with. This is why optimizing functions of millions of variables is hard:
    not only does the parameter space get insanely large, but the concept of distance
    also begins to break down.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 除了更复杂的符号表示外，我们还必须应对维度的诅咒。这就是为什么优化百万变量的函数很困难：不仅参数空间变得巨大，而且距离的概念也开始失效。
- en: Now that we’ve built some intuition about multivariable functions and familiarity
    with the notation, it’s time to dive deep. How can we do calculus in higher dimensions?
    Let’s see in the next chapter!
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们对多变量函数有了一些直觉并熟悉了符号表示，接下来该深入探讨了。我们如何在更高维度中做微积分呢？让我们在下一章看看吧！
- en: Join our community on Discord
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加入我们的 Discord 社区
- en: Read this book alongside other users, Machine Learning experts, and the author
    himself. Ask questions, provide solutions to other readers, chat with the author
    via Ask Me Anything sessions, and much more. Scan the QR code or visit the link
    to join the community. [https://packt.link/math](https://packt.link/math)
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他用户、机器学习专家以及作者本人一起阅读这本书。提问、为其他读者提供解决方案，通过“问我任何问题”环节与作者聊天，还有更多内容。扫描二维码或访问链接加入社区。[https://packt.link/math](https://packt.link/math)
- en: '![PIC](img/file1.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/file1.png)'
