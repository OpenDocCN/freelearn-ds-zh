- en: '3'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '3'
- en: Taking the Measure of Your Data
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测量你的数据
- en: Within a week of receiving a new dataset, at least one person is likely to ask
    us a familiar question – “so, how does it look?” This is not always asked relaxedly,
    and others are not usually excited to hear about all of the red flags we have
    already found. There might be a sense of urgency to declare the data ready for
    analysis. Of course, if we sign off on it too soon, this can create much larger
    problems; the presentation of invalid results, the misinterpretation of variable
    relationships, and having to redo major chunks of our analysis. The key is sorting
    out what we need to know about the data before we explore anything else in the
    data. The recipes in this chapter offer techniques for determining if the data
    is in good enough shape to begin the analysis, so that even if we cannot say,
    “it looks fine,” we can at least say, “I’m pretty sure I have identified the main
    issues, and here they are.”
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在收到新数据集的一周内，至少会有人问我们一个熟悉的问题——“那么，看起来怎么样？”这个问题并不总是以轻松的语气提出，别人通常也不太兴奋地听我们已经发现的所有警告信号。可能会有一种紧迫感，希望宣告数据已经准备好进行分析。当然，如果我们太快地签字确认，这可能会带来更大的问题；无效结果的展示、变量关系的误解，以及不得不重新做大部分分析。关键是要在探索数据的其他部分之前，理清我们需要了解的数据内容。本章中的技巧提供了判断数据是否足够清晰以开始分析的方法，即使我们不能说“看起来很好”，至少我们可以说“我很确定我已经识别出主要问题，问题在这里。”
- en: Often our domain knowledge is quite limited, or at least not nearly as good
    as those who created the data. We have to quickly get a sense of what we are looking
    at even when we have little substantive understanding of the individuals or events
    reflected in the data. Many times (for some of us, most of the time) there is
    not anything like a data dictionary or codebook accompanying the receipt of the
    data.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的领域知识通常非常有限，或者至少不如那些创建数据的人那么熟练。即使我们对数据中的个体或事件了解不多，我们也必须迅速了解我们所面对的数据内容。很多时候（对我们中的一些人来说，几乎是大多数时候）并没有类似数据字典或代码书这样的东西来帮助我们理解数据。
- en: 'Quick. Ask yourself what the first few things you try to find out in this situation
    are; that is, when you first get data about which you know little. It is probably
    something like this:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 快速地问问自己，在这种情况下你首先想弄清楚的事情是什么；也就是说，当你获得一些你知道很少的数据时，首先要弄清楚的可能是这样的事情：
- en: How are the rows of the dataset uniquely identified? (What is the unit of analysis?)
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据集的行是如何被唯一标识的？（分析单元是什么？）
- en: How many rows and columns are in the dataset?
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据集中有多少行和列？
- en: What are the key categorical variables and the frequencies of each value?
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关键的分类变量是什么？每个值的频率是多少？
- en: How are important continuous variables distributed?
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重要的连续变量是如何分布的？
- en: How might variables be related to each other – for example, how might the distribution
    of continuous variables vary according to categories in the data?
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 变量之间可能如何相关——例如，连续变量的分布如何根据数据中的类别而变化？
- en: What variable values are out of expected ranges, and how are missing values
    distributed?
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 哪些变量的值超出了预期范围，缺失值是如何分布的？
- en: We go over essential tools and strategies for answering the first four questions
    in this chapter. We look into the last two questions in the following chapter.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了回答前四个问题的基本工具和策略。接下来的章节我们将讨论最后两个问题。
- en: 'I should point out that this first take on our data is important even when
    the structure of the data is familiar; when, for example, we receive data for
    a new month or year with the same column names and data types as in previous periods.
    It is hard to guard against the sense that we can just rerun our old programs;
    it’s difficult to be as vigilant as we were the first few times we prepared the
    data for analysis. Most of us have probably been in situations where we receive
    new data with a familiar structure, but the answers to the preceding questions
    are meaningfully different: new valid values for key categorical variables; rare
    values that have always been permissible but that have not been seen for several
    periods; and unexpected changes in the status of clients/students/customers. It
    is important to build routines for understanding our data and follow them, regardless
    of our familiarity with it.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我必须指出，尽管数据结构已经很熟悉，但对数据的第一次处理仍然很重要。例如，当我们收到同一列名和数据类型的新月度或年度数据时，很容易产生一种错误的感觉，认为我们可以直接重新运行之前的程序；我们很难像第一次处理数据时那样保持警觉。大多数人可能都有过这种经历：我们收到结构相同的新数据，但之前问题的答案却有了实质性变化：关键类别变量的新有效值；一直允许但在几期内未曾出现的稀有值；以及客户/学生/顾客状态的意外变化。建立理解数据的例程并始终遵循它们是非常重要的，不论我们是否对数据熟悉。
- en: 'Specifically, we will cover the following topics in this chapter:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将重点介绍以下主题：
- en: Getting a first look at your data
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 初步了解你的数据
- en: Selecting and organizing columns
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择和组织列
- en: Selecting rows
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择行
- en: Generating frequencies for categorical variables
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为分类变量生成频率
- en: Generating summary statistics for continuous variables
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成连续变量的汇总统计
- en: Using generative AI to display descriptive statistics
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用生成性 AI 显示描述性统计数据
- en: Technical requirements
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: You will need pandas, Numpy, and Matplotlib to complete the recipes in this
    chapter. I used pandas 2.1.4, but the code will run on pandas 1.5.3 or later.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的食谱需要 pandas、Numpy 和 Matplotlib 库。我使用的是 pandas 2.1.4，但代码也可以在 pandas 1.5.3
    或更高版本上运行。
- en: The code in this chapter can be downloaded from the book’s github repository,
    [https://github.com/PacktPublishing/Python-Data-Cleaning-Cookbook-Second-Edition](https://github.com/PacktPublishing/Python-Data-Cleaning-Cookbook-Second-Edition).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的代码可以从本书的 GitHub 仓库下载，[https://github.com/PacktPublishing/Python-Data-Cleaning-Cookbook-Second-Edition](https://github.com/PacktPublishing/Python-Data-Cleaning-Cookbook-Second-Edition)。
- en: Getting a first look at your data
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 初步了解你的数据
- en: 'We will work with two datasets in this chapter: *The National Longitudinal
    Survey of Youth for 1997*, a survey conducted by the United States government
    that surveyed the same group of individuals from 1997 through 2023; and the counts
    of COVID-19 cases and deaths by country from *Our World in Data*.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们将处理两个数据集：*1997 年度国家纵向青少年调查*，这是美国政府进行的一项调查，跟踪了同一群体从 1997 年到 2023 年的情况；以及来自
    *Our World in Data* 的各国 COVID-19 案例和死亡人数数据。
- en: Getting ready…
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作…
- en: We will mainly be using the pandas library for this recipe. We will use pandas
    tools to take a closer look at the **National Longitudinal Survey** (**NLS**)
    and COVID-19 case data.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 本食谱主要使用 pandas 库。我们将使用 pandas 工具更深入地了解**国家纵向调查**（**NLS**）和 COVID-19 案例数据。
- en: '**Data note**'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据说明**'
- en: The NLS of Youth was conducted by the United States Bureau of Labor Statistics.
    This survey started with a cohort of individuals in 1997 who were born between
    1980 and 1985, with annual follow-ups each year through to 2023\. For this recipe,
    I pulled 89 variables on grades, employment, income, and attitudes toward government
    from the hundreds of data items in the survey. Separate files for SPSS, Stata,
    and SAS can be downloaded from the repository. The NLS data can be downloaded
    from [https://www.nlsinfo.org](https://www.nlsinfo.org). You must create an investigator
    account to download the data, but there is no charge.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 青少年 NLS 调查由美国劳工统计局进行。该调查从 1997 年开始，针对 1980 年至 1985 年之间出生的一群人，进行每年跟踪，直到 2023
    年。本食谱中，我从调查中的数百个数据项中提取了关于成绩、就业、收入和对政府态度的 89 个变量。SPSS、Stata 和 SAS 的独立文件可以从仓库下载。NLS
    数据可以从 [https://www.nlsinfo.org](https://www.nlsinfo.org) 下载。你需要创建一个研究者账户来下载数据，但无需收费。
- en: Our World in Data provides COVID-19 public use data at [https://ourworldindata.org/covid-cases](https://ourworldindata.org/covid-cases).
    The dataset includes total cases and deaths, tests administered, hospital beds,
    and demographic data such as median age, gross domestic product, and a human development
    index, which is a composite measure of standard of living, educational levels,
    and life expectancy. The dataset used in this recipe was downloaded on March 3,
    2024
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的《全球数据》提供了 COVID-19 的公共使用数据，网址是 [https://ourworldindata.org/covid-cases](https://ourworldindata.org/covid-cases)。该数据集包括总病例数、死亡病例数、已做的检测、医院床位数以及人口统计数据，如中位年龄、国内生产总值和人类发展指数，后者是衡量生活水平、教育水平和寿命的综合指标。本文所用的数据集于
    2024 年 3 月 3 日下载。
- en: How to do it…
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'We will get an initial look at the NLS and COVID-19 data, including the number
    of rows and columns, and the data types:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将初步查看 NLS 和 COVID-19 数据，包括行数、列数和数据类型：
- en: 'Import the required libraries and load the DataFrames:'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所需的库并加载数据框：
- en: '[PRE0]'
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Set and show the index and the size of the `nls97` data.
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置并显示 `nls97` 数据的索引和大小。
- en: 'Also, check to see whether the index values are unique:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，检查索引值是否唯一：
- en: '[PRE1]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Show the data types and `non-null` value counts:'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 显示数据类型和 `non-null` 值的计数：
- en: '[PRE7]'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Show the first 2 rows of the `nls97` data.
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 显示 `nls97` 数据的前两行。
- en: 'Use transpose to show a little more of the output:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 使用转置来显示更多输出：
- en: '[PRE9]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Set and show the index and size for the COVID-19 data.
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置并显示 COVID-19 数据的索引和大小。
- en: 'Also, check to see whether the index values are unique:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，检查索引值是否唯一：
- en: '[PRE11]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Show the data types and `non-null` value counts:'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 显示数据类型和 `non-null` 值的计数：
- en: '[PRE17]'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Show a sample of 2 rows of the COVID-19 data:'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 显示 COVID-19 数据的两行样本：
- en: '[PRE19]'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[PRE20]'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: This has given us a good foundation for understanding our DataFrames, including
    their sizes and column data types.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这为我们理解数据框提供了良好的基础，包括它们的大小和列数据类型。
- en: How it works…
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: We set and display the index of the `nls97` DataFrame, which is called `personid`,
    in *Step 2*. It is a more meaningful index than the default pandas `RangeIndex`,
    which is essentially the row numbers with zero base. Often there is a unique identifier
    when working with individuals as the unit of analysis. This is a good candidate
    for an index. It makes selecting a row by that identifier easier. Rather than
    using the `nls97.loc[personid==1000061]` statement to get the row for that person,
    we can use `nls97.loc[1000061]`. We will try this out in the next recipe.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤 2*中，我们为 `nls97` 数据框设置并显示了索引 `personid`。它是一个比默认的 pandas `RangeIndex` 更有意义的索引，后者本质上是从零开始的行号。通常在处理个体作为分析单元时，会有一个唯一标识符，这是一个很好的索引候选。它使得通过该标识符选择一行变得更加简单。我们不需要使用
    `nls97.loc[personid==1000061]` 语句来获取该人的数据行，而是可以使用 `nls97.loc[1000061]`。我们将在下一个示例中尝试这一方法。
- en: pandas makes it easy to view the number of rows and columns, the data type and
    numbers of non-missing values for each column, and the values of the columns for
    a few rows of your data. This can be accomplished by using the `shape` attribute
    and calling the `info` method, followed by either the `head` or `sample` methods.
    Using the `head(2)` method shows the first two rows, but sometimes it is helpful
    to grab a row from anywhere in the DataFrame, in which case we would use `sample`.
    (We set the seed when we call `sample` (`random_state=1`) to get the same results
    whenever we run the code.) We can chain our call to `head` or `sample` with a
    `T` to transpose it. This reverses the display of rows and columns. That is helpful
    when there are more columns than can be shown horizontally and you want to be
    able to see all of them. By transposing the rows and columns we are able to see
    all of the columns.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: pandas 使得查看每列的行数和列数、数据类型、非缺失值的数量，以及数据中前几行的列值变得容易。这可以通过使用 `shape` 属性和调用 `info`
    方法实现，接着使用 `head` 或 `sample` 方法。使用 `head(2)` 方法显示前两行，但有时从数据框中任意一行获取数据会更有帮助，这时我们可以使用
    `sample`。 （当我们调用 `sample` 时，我们设置了种子（`random_state=1`），这样每次运行代码时都会得到相同的结果。）我们可以将对
    `head` 或 `sample` 的调用链式调用 `T` 来转置数据框。这将反转行和列的显示顺序。当列的数量比水平方向上能显示的更多时，这个操作很有用，你可以通过转置查看所有列。通过转置行和列，我们能够看到所有的列。
- en: The `shape` attribute of the `nls97` DataFrame tells us that there are 8,984
    rows and 88 non-index columns. Since `personid` is the index, it is not included
    in the column count. The `info` method shows us that many of the columns have
    object data types and that some have a large number of missing values. `satverbal`
    and `satmath` have only about 1,400 valid values.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '`nls97` DataFrame的`shape`属性告诉我们该数据集有8,984行和88列非索引列。由于`personid`是索引，因此不包含在列数中。`info`方法显示，许多列的数据类型是对象型，且部分列有大量缺失值。`satverbal`和`satmath`只有大约1,400个有效值。'
- en: The `shape` attribute of the `covidtotals` DataFrame tells us that there are
    231 rows and 16 columns, which does not include the country `iso_code` column
    used for the index (`iso_code` is a unique three-digit identifier for each country).
    The key variables for most analyses we would do are `total_cases`, `total_deaths`,
    `total_cases_pm,` and `total_deaths_pm`. `total_cases` and `total_deaths` are
    present for each country, but `total_cases_pm` and `total_deaths_pm` are missing
    for one country.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '`covidtotals` DataFrame的`shape`属性告诉我们该数据集有231行和16列，其中不包括作为索引使用的国家`iso_code`列（`iso_code`是每个国家的唯一三位数标识符）。对于我们进行的大部分分析，关键变量是`total_cases`、`total_deaths`、`total_cases_pm`和`total_deaths_pm`。`total_cases`和`total_deaths`对每个国家都有数据，但`total_cases_pm`和`total_deaths_pm`在一个国家的数据缺失。'
- en: There’s more...
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: I find that thinking through the index when working with a data file can remind
    me of the unit of analysis. That is not obvious with the NLS data, as it is actually
    panel data disguised as person-level data. Panel, or longitudinal, datasets have
    data for the same individuals over some regular duration. In this case, data was
    collected for each person over a 26-year span, from 1997 till 2023\. The administrators
    of the survey have flattened it for analysis purposes by creating columns for
    certain responses over the years, such as college enrollment (`colenroct15` through
    `colenroct17`). This is a fairly standard practice, but it is likely that we will
    need to do some reshaping for some analyses.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我发现，在处理数据文件时，考虑索引能提醒我分析的单位。这在NLS数据中并不明显，因为它实际上是伪装成个人级数据的面板数据。面板数据，或称纵向数据，包含同一组个体在一段时间内的数据。在这种情况下，数据收集的时间跨度为26年，从1997年到2023年。调查管理员为了分析方便，通过创建某些年份响应的列（例如，大学入学情况(`colenroct15`至`colenroct17`)）将数据进行了平展。这是一个相对标准的做法，但我们可能需要对某些分析进行重新整形。
- en: One thing I pay careful attention to when receiving any panel data is any drop-off
    in responses to key variables over time. Notice the drop off in valid values from
    `colenroct15` to `colenroct17`. By October of 2017, only 75% of respondents provided
    a valid response (6,734/8,984). That is definitely worth keeping in mind during
    subsequent analysis, since the 6,734 remaining respondents may be different in
    important ways from the overall sample of 8,984.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我在接收任何面板数据时特别注意的是关键变量在时间上的响应下降。注意从`colenroct15`到`colenroct17`有效值的下降。到2017年10月，只有75%的受访者提供了有效回应（6,734/8,984）。在后续分析中，必须牢记这一点，因为剩余的6,734名受访者可能在重要方面与整体样本8,984人有所不同。
- en: See also
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: A recipe in *Chapter 1*, *Anticipating Data Cleaning Issues When Importing Tabular
    Data with pandas*, shows how to persist pandas DataFrames as feather or pickle
    files. In later recipes in this chapter, we will look at descriptives and frequencies
    for these two DataFrames.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '*第1章*中的一个食谱，*在导入表格数据时预测数据清理问题（使用pandas）*，展示了如何将pandas DataFrame保存为feather或pickle文件。在本章后续的食谱中，我们将查看这两个DataFrame的描述性统计和频率分析。'
- en: We reshape the NLS data in *Chapter 11*, *Tidying and Reshaping Data*, recovering
    some of its actual structure as panel data. This is necessary for statistical
    methods such as survival analysis, and is closer to tidy data ideals.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在*第11章*中对NLS数据进行了整形，*数据整理与重塑*，恢复了其作为面板数据的实际结构。这对于生存分析等统计方法是必要的，也更接近整洁数据的理想状态。
- en: Selecting and organizing columns
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 选择和组织列
- en: We explore several ways to select one or more columns from your DataFrame in
    this recipe. We can select columns by passing a list of column names to the `[]`
    bracket operator, or by using the pandas-specific `loc` and `iloc` data accessors.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在本食谱中，我们探索了几种从DataFrame中选择一个或多个列的方法。我们可以通过将列名列表传递给`[]`括号操作符，或者使用pandas特定的`loc`和`iloc`数据访问器来选择列。
- en: When cleaning data or doing exploratory or statistical analyses, it is helpful
    to focus on the variables that are relevant to the issue or analysis at hand.
    This makes it important to group columns according to their substantive or statistical
    relationships with each other, or to limit the columns we are investigating at
    any one time. How many times have we said to ourselves something like, *“Why does
    variable A have a value of x when variable B has a value of y?”* We can only do
    that when the amount of data we are viewing at a given moment does not exceed
    our perceptive abilities at that moment.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在清理数据或进行探索性分析或统计分析时，专注于与当前问题或分析相关的变量是非常有帮助的。这使得根据列之间的实质性或统计关系对列进行分组，或在任何时候限制我们正在研究的列变得非常重要。我们有多少次对自己说过类似
    *“为什么变量 A 在变量 B 为 y 时的值是 x？”* 的话呢？只有当我们查看的数据量在某一时刻不超过我们当时的感知能力时，我们才能做到这一点。
- en: Getting ready…
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作……
- en: We will continue working with the **National Longitudinal Survey** (**NLS**)
    data in this recipe.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在本食谱中，我们将继续使用**国家纵向调查**（**NLS**）数据。
- en: How to do it…
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到……
- en: 'We will explore several ways to select columns:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将探索几种选择列的方法：
- en: Import the `pandas` library and load the NLS data into pandas.
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入 `pandas` 库并将 NLS 数据加载到 pandas 中。
- en: 'Also, convert all columns in the NLS data of the object data type to the category
    data type. Do this by selecting object data type columns with `select_dtypes`
    and using `transform` plus a `lambda` function to change the data type to `category`:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，将 NLS 数据中所有对象数据类型的列转换为类别数据类型。通过使用 `select_dtypes` 选择对象数据类型的列，并利用 `transform`
    及 `lambda` 函数将数据类型转换为 `category` 来实现：
- en: '[PRE21]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Select a column using the pandas `[]` bracket operator and the `loc` and `iloc`
    accessors.
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 pandas 的 `[]` 括号操作符和 `loc` 以及 `iloc` 访问器选择列。
- en: 'We pass a string matching a column name to the bracket operator to return a
    pandas series. If we pass a list of one element with that column name (`nls97[[''gender'']]`),
    a DataFrame is returned. We can also use the `loc` and `iloc` accessors to select
    columns:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将一个与列名匹配的字符串传递给括号操作符，从而返回一个 pandas Series。如果我们传入一个包含该列名的单一元素的列表（`nls97[['gender']]`），则返回一个
    DataFrame。我们还可以使用 `loc` 和 `iloc` 访问器来选择列：
- en: '[PRE22]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[PRE23]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '[PRE24]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '[PRE25]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[PRE26]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[PRE27]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '[PRE28]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '[PRE29]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Select multiple columns from a pandas DataFrame.
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 pandas DataFrame 中选择多个列。
- en: 'Use the bracket operator and `loc` to select a few columns:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 使用括号操作符和 `loc` 选择几个列：
- en: '[PRE30]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '[PRE31]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '[PRE32]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '[PRE33]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '[PRE34]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '[PRE35]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '[PRE36]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '[PRE37]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Select multiple columns based on a list of columns.
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 基于列名列表选择多个列。
- en: 'If you are selecting more than a few columns, it is helpful to create a list
    of column names separately. Here, we create a `keyvars` list of key variables
    for analysis:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你选择的列超过几个，最好单独创建一个列名列表。在这里，我们创建了一个用于分析的关键变量 `keyvars` 列表：
- en: '[PRE38]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '[PRE39]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Select one or more columns by filtering by column name.
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过列名过滤选择一个或多个列。
- en: 'Select all of the `weeksworked##` columns using the `filter` operator:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `filter` 操作符选择所有的 `weeksworked##` 列：
- en: '[PRE40]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '[PRE41]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Select all columns of the category data type.
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择所有类别数据类型的列。
- en: 'Use the `select_dtypes` method to select columns by data type:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `select_dtypes` 方法按数据类型选择列：
- en: '[PRE42]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '[PRE43]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Organize columns using lists of column names.
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用列名列表组织列。
- en: 'Use lists to organize the columns in your DataFrame. You can easily change
    the order of columns or exclude some columns in this way. Here, we move the columns
    in the `demoadult` list to the front:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 使用列表组织 DataFrame 中的列。通过这种方式，你可以轻松地更改列的顺序或排除一些列。在这里，我们将 `demoadult` 列表中的列移到前面：
- en: '[PRE44]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Create the new reorganized DataFrame:'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建新的重新组织后的 DataFrame：
- en: '[PRE45]'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '[PRE46]'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: The preceding steps showed how to select columns and change the order of columns
    in a `pandas` DataFrame.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 上述步骤展示了如何在 `pandas` DataFrame 中选择列并更改列的顺序。
- en: How it works…
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: Both the `[]` bracket operator and the `loc` data accessor are very handy for
    selecting and organizing columns. Each returns a DataFrame when passed a list
    of names of columns. The columns will be ordered according to the passed list
    of column names.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '`[]` 括号操作符和 `loc` 数据访问器在选择和组织列时非常方便。当传入一个列名列表时，它们都会返回一个 DataFrame，列的顺序将按照传入的列名列表进行排列。'
- en: 'In *Step 1*, we use `nls97.select_dtypes([''object''])` to select columns with
    object data type and chain that with `transform` and a `lambda` function (`transform(lambda
    x: x.astype(''category''))`) to change those columns to category. We use the `loc`
    accessor to only update columns with the object data type (`nls97.loc[:, nls97.dtypes
    == ''object'']`). We go into much more detail on the use of `transform`, `apply`
    (which works similarly to `transform`), and `lambda` functions in *Chapter 6*,
    *Cleaning and Exploring Data with Series Operations*.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '在*步骤1*中，我们使用`nls97.select_dtypes([''object''])`来选择数据类型为对象的列，并将其与`transform`和`lambda`函数（`transform(lambda
    x: x.astype(''category''))`）链式调用，将这些列转换为类别类型。我们使用`loc`访问器只更新数据类型为对象的列（`nls97.loc[:,
    nls97.dtypes == ''object'']`）。我们将在*第六章*中详细讲解`transform`、`apply`（与`transform`类似）和`lambda`函数的使用，*清理和探索数据操作*。'
- en: We select columns by data type in *Step 6*. `select_dtypes` becomes quite useful
    when passing columns to methods such as `describe` or `value_counts`, when you
    want to limit the analysis to continuous or categorical variables.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在*步骤6*中通过数据类型选择列。`select_dtypes`在将列传递给如`describe`或`value_counts`等方法时非常有用，尤其是当你想将分析限制为连续变量或类别变量时。
- en: In *Step 8*, we concatenate six different lists when using the bracket operator.
    This moves the column names in `demoadult` to the front and organizes all of the
    columns by those six groups. There are now clear *high school record* and *weeks
    worked* sections in our DataFrame’s columns.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤8*中，当使用括号操作符时，我们将六个不同的列表连接起来。这将`demoadult`中的列名移到前面，并根据这六个组重新组织所有列。现在，我们的DataFrame列中有了清晰的*高中记录*和*工作周数*部分。
- en: There’s more…
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多…
- en: 'We can also use `select_dtypes` to exclude data types. Also, if we are just
    interested in the `info` results, we can chain the `select_dtypes` call with the
    `info` method:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用`select_dtypes`来排除数据类型。如果我们只对`info`结果感兴趣，我们可以将`select_dtypes`与`info`方法链式调用：
- en: '[PRE47]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: '[PRE48]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'The `filter` operator can also take a regular expression. For example, you
    can return the columns that have `income` in their names:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '`filter`操作符也可以接受正则表达式。例如，你可以返回列名中包含`income`的列：'
- en: '[PRE49]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: '[PRE50]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: See also
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: Many of these techniques can be used to create `pandas` Series as well as DataFrames.
    We demonstrate this in *Chapter 6*, *Cleaning and Exploring Data with Series Operations*.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 许多这些技巧也可以用于创建`pandas`的Series以及DataFrame。我们在*第六章*中演示了这一点，*清理和探索数据操作*。
- en: Selecting rows
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 选择行
- en: When we are taking the measure of our data and otherwise answering the question,
    *“How does it look?”*, we constantly zoom in and out and look at aggregated numbers
    and particular rows. But there are also important data issues that are only obvious
    at an intermediate-zoom level, issues that we only notice when looking at some
    subset of rows. This recipe demonstrates how to use pandas tools to detect data
    issues in subsets of our data.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在衡量数据并回答问题*“它看起来怎么样？”*时，我们不断地放大和缩小，查看汇总数据和特定行。但也有一些只有在中等缩放级别下才能明显看到的数据问题，只有当我们查看某些行的子集时，这些问题才会浮现。本篇食谱展示了如何使用`pandas`工具在数据的子集上检测数据问题。
- en: Getting ready...
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备就绪...
- en: We will continue working with the NLS data in this recipe.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在本篇食谱中，我们将继续使用NLS数据。
- en: How to do it...
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'We will go over several techniques for selecting rows in a `pandas` DataFrame:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将讨论几种选择`pandas` DataFrame中行的技巧：
- en: 'Import `pandas` and `numpy`, and load the `nls97` data:'
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`pandas`和`numpy`，并加载`nls97`数据：
- en: '[PRE51]'
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: Use slicing to start at the 1001^(st) row and go to the 1004^(th) row.
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用切片从第1001行开始，到第1004行结束。
- en: '`nls97[1000:1004]` selects every row starting from the row indicated by the
    integer to the left of the colon (`1000`, in this case) to, but not including,
    the row indicated by the integer to the right of the colon (`1004`). The row at
    `1000` is actually the 1001^(st) row because of zero-based indexing. Each row
    appears as a column in the output since we have transposed the resulting DataFrame:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '`nls97[1000:1004]`选择从左侧冒号指示的整数所在的行（此例中是`1000`）开始，到右侧冒号指示的整数所在的行（此例中是`1004`）之前的行。由于基于零索引，`1000`行实际上是第1001行。每一行都作为列出现在输出中，因为我们对结果DataFrame进行了转置：'
- en: '[PRE52]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: '[PRE53]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: Use slicing to start at the 1001^(st) row and go to the 1004^(th) row, skipping
    every other row.
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用切片从第1001行开始，到第1004行结束，跳过每隔一行。
- en: 'The integer after the second colon (`2` in this case) indicates the size of
    the step. When the step is excluded it is assumed to be 1\. Notice that by setting
    the value of the step to `2`, we are skipping every other row:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个冒号后的整数（在这里是`2`）表示步长。当步长被省略时，它默认是1。注意，设置步长为`2`时，我们跳过了每隔一行的行：
- en: '[PRE54]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: '[PRE55]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: Select the first three rows using `[]` operator slicing.
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`[]`操作符切片选择前三行。
- en: 'By not providing a value to the left of the colon in `[:3]`, we are telling
    the operator to get rows from the start of the DataFrame:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在`[:3]`中不提供冒号左侧的值，意味着我们告诉操作符从DataFrame的起始位置获取行：
- en: '[PRE56]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: '[PRE57]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: Note that `nls97[:3]` returns the same DataFrame as `nls97.head(3)` would have
    returned.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`nls97[:3]`返回的DataFrame与`nls97.head(3)`返回的是相同的。
- en: 'Select the last three rows using `[]` operator slicing:'
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`[]`操作符切片选择最后三行：
- en: '[PRE58]'
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: '[PRE59]'
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: Note that `nls97[-3:]` returns the same DataFrame as `nls97.tail(3)` would have
    returned.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`nls97[-3:]`返回的DataFrame与`nls97.tail(3)`返回的是相同的。
- en: Select a few rows using the `loc` data accessor.
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`loc`数据访问器选择几行。
- en: 'Use the `loc` accessor to select by `index` label. We can pass a list of index
    labels or we can specify a range of labels. (Recall that we have set `personid`
    as the index.) Note that `nls97.loc[[195884,195891,195970]]` and `nls97.loc[195884:195970]`
    return the same DataFrame, since those rows are contiguous:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`loc`访问器按`index`标签选择。我们可以传递一个索引标签的列表，或者指定一个标签范围。（回顾一下，我们已经将`personid`设置为索引。）请注意，`nls97.loc[[195884,195891,195970]]`和`nls97.loc[195884:195970]`返回的是相同的DataFrame，因为这些行是连续的。
- en: '[PRE60]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: '[PRE61]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: '[PRE62]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: '[PRE63]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: Select a row from the beginning of the DataFrame with the `iloc` data accessor.
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`iloc`数据访问器从DataFrame的开始位置选择一行。
- en: '`iloc` differs from `loc` in that it takes a list of row position integers,
    rather than index labels. For that reason, it works similarly to bracket operator
    slicing. In this step, we first pass a one-item list with the value of `0`. That
    returns a DataFrame with the first row:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '`iloc`与`loc`的不同之处在于，它接受一组行位置的整数，而不是索引标签。因此，它的工作方式类似于括号操作符切片。在这一步中，我们首先传递一个包含值`0`的单元素列表。这将返回一个包含第一行的DataFrame：'
- en: '[PRE64]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: '[PRE65]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: Select a few rows from the beginning of the DataFrame with the `iloc` data accessor.
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`iloc`数据访问器选择数据框的几行。
- en: 'We pass a three-item list, `[0,1,2]`, to return a DataFrame of the first three
    rows of `nls97`:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 我们传递一个包含三个元素的列表`[0,1,2]`，以返回`nls97`的前三行的DataFrame：
- en: '[PRE66]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: '[PRE67]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: We would get the same result if we passed `[0:3]` to the accessor.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将`[0:3]`传递给访问器，结果是一样的。
- en: Select a few rows from the end of the DataFrame with the `iloc` data accessor.
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`iloc`数据访问器从DataFrame的末尾选择几行。
- en: 'Use `nls97.iloc[[-3,-2,-1]]` to retrieve the last three rows of the DataFrame:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`nls97.iloc[[-3,-2,-1]]`来获取DataFrame的最后三行：
- en: '[PRE68]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: '[PRE69]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: We would have gotten the same result with `nls97.iloc[-3:]`. By not providing
    a value to the right of the colon in `[-3:]`, we are telling the accessor to get
    all rows from the third-to-last row to the end of the DataFrame.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`nls97.iloc[-3:]`也能得到相同的结果。通过不在`[-3:]`的冒号右侧提供值，我们告诉访问器获取从倒数第三行到DataFrame结尾的所有行。
- en: Select multiple rows conditionally using boolean indexing.
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用布尔索引按条件选择多行。
- en: 'Create a DataFrame of just individuals receiving very little sleep. About 5%
    of survey respondents got 4 or fewer hours of sleep per night, of the 6,706 individuals
    who responded to that question. Test who is getting 4 or fewer hours of sleep
    with `nls97.nightlyhrssleep<=4`, which generates a pandas Series of `True` and
    `False` values that we assign to `sleepcheckbool`. Pass that Series to the `loc`
    accessor to create a `lowsleep` DataFrame. `lowsleep` has approximately the number
    of rows we are expecting. We do not need to do the extra step of assigning the
    boolean Series to a variable. This is done here only for explanatory purposes:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个只包含睡眠时间极少的个体的DataFrame。约有5%的调查对象每晚睡眠时间为4小时或更少，调查共有6,706人回答了该问题。通过`nls97.nightlyhrssleep<=4`来测试哪些人每晚睡眠4小时或更少，这将生成一个`True`和`False`值的pandas系列，我们将其赋值给`sleepcheckbool`。将该系列传递给`loc`访问器以创建一个`lowsleep`
    DataFrame。`lowsleep`大约有我们预期的行数。我们不需要额外的步骤来将布尔系列赋值给变量。这里这样做仅仅是为了说明：
- en: '[PRE70]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: '[PRE71]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: '[PRE72]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: '[PRE73]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: '[PRE74]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: '[PRE75]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: '[PRE76]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: '[PRE77]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: Select rows based on multiple conditions.
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 基于多个条件选择行。
- en: 'It may be that folks who are not getting a lot of sleep also have a fair number
    of children who live with them. Use `describe` to get a sense of the distribution
    of the number of children for those who have `lowsleep`. About a quarter have
    three or more children. Create a new DataFrame with individuals who have `nightlyhrssleep`
    of 4 or less and number of children at home of 3 or more. The `&` is the logical
    *and* operator in pandas and indicates that both conditions have to be true for
    the row to be selected:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 可能有些没有得到充足睡眠的人，也有不少孩子和他们一起生活。使用`describe`来了解那些有`lowsleep`的人群中，孩子数量的分布情况。大约四分之一的人有三个或更多孩子。创建一个新的
    DataFrame，包含那些`nightlyhrssleep`为4小时或更少，且家中有3个或更多孩子的个体。`&`是pandas中的逻辑*与*运算符，表示只有当两个条件都满足时，行才会被选中：
- en: '[PRE78]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: '[PRE79]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: '[PRE80]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: '[PRE81]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: We would have gotten the same result if we worked from the `lowsleep` DataFrame
    – `lowsleep3pluschildren = lowsleep.loc[lowsleep.childathome>=3]` – but then we
    would not have been able to demonstrate testing multiple conditions.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们从`lowsleep` DataFrame开始，结果是一样的 – `lowsleep3pluschildren = lowsleep.loc[lowsleep.childathome>=3]`
    – 但那样我们就无法展示多个条件的测试。
- en: Select rows and columns based on multiple conditions.
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据多个条件选择行和列。
- en: 'Pass the condition to the `loc` accessor to select rows. Also, pass a list
    of column names to select:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 将条件传递给`loc`访问器以选择行。还可以传递一个列名的列表来选择列：
- en: '[PRE82]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: '[PRE83]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: The preceding steps demonstrated the key techniques for selecting rows in pandas.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 上述步骤展示了在pandas中选择行的关键技巧。
- en: How it works…
  id: totrans-205
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: We used the `[]` bracket operator in *Steps 2* through *5* to do standard Python-like
    slicing to select rows. That operator allows us to easily select rows based on
    a list or a range of values indicated with slice notation. This notation takes
    the form of `[start:end:step]`, where a value of `1` for `step` is assumed if
    no value is provided. When a negative number is used for `start`, it represents
    the number of rows from the end of the DataFrame.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤2*到*步骤5*中，我们使用了`[]`方括号运算符来做标准的类似Python的切片操作，选择行。这个运算符使得我们可以根据列出或范围的值，轻松选择行。切片表示法的形式为`[start:end:step]`，其中如果没有提供`step`值，则默认假定为`1`。当`start`使用负数时，它表示从DataFrame的末尾开始算起的行数。
- en: The `loc` accessor, used in *Step 6*, selects rows based on row index labels.
    Since `personid` is the index for the DataFrame, we can pass a list of one or
    more `personid` values to the `loc` accessor to get a DataFrame with rows for
    those index labels. We can also pass a range of index labels to the accessor,
    which will return a DataFrame with all rows having index labels between the label
    to the left of the colon and the label to the right (inclusive); so, `nls97.loc[195884:195970]`
    returns a DataFrame for rows with `personid` between `195884` and `195970`, including
    those two values.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '`loc`访问器，在*步骤6*中使用，根据行索引标签选择行。由于`personid`是DataFrame的索引，我们可以将一个或多个`personid`值的列表传递给`loc`访问器，以获得具有这些索引标签的行的DataFrame。我们也可以将一系列索引标签传递给访问器，这将返回一个包含所有行的DataFrame，这些行的索引标签介于冒号左边和右边的标签之间（包含这两个标签）；因此，`nls97.loc[195884:195970]`将返回`personid`在`195884`和`195970`之间的行的DataFrame，包括这两个值。'
- en: The `iloc` accessor works very much like the bracket operator. We see this in
    *Steps 7* through *9*. We can pass either a list of integers or a range using
    slicing notation.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '`iloc`访问器的工作方式与方括号运算符非常相似。这一点在*步骤7*到*步骤9*中有所体现。我们可以传递整数列表或使用切片表示法传递一个范围。'
- en: One of the most valuable pandas capabilities is boolean indexing. It makes it
    easy to select rows conditionally. We see this in *Step 10*. A test returns a
    boolean series. The `loc` accessor selects all rows for which the test is `True`.
    We actually didn’t need to assign the boolean data Series to the variable that
    we then passed to the `loc` operator. We could have just passed the test to the
    `loc` accessor with `nls97.loc[nls97.nightlyhrssleep<=4]`.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: pandas最有价值的功能之一是布尔索引。它使得条件选择行变得非常简单。我们在*步骤10*中看到了这一点。一个测试返回一个布尔序列。`loc`访问器选择所有测试为`True`的行。实际上，我们并不需要将布尔数据序列赋值给一个变量，再将该变量传递给`loc`运算符。我们本可以直接将测试条件传递给`loc`访问器，如`nls97.loc[nls97.nightlyhrssleep<=4]`。
- en: We should take a closer look at how we used the `loc` accessor to select rows
    in *Step 11*. Each condition in `nls97.loc[(nls97.nightlyhrssleep<=4) & (nls97.childathome>=3)]`
    is placed in parentheses. An error will be generated if the parentheses are excluded.
    The `&` operator is the equivalent of `and` in standard Python, meaning that *both*
    conditions have to be `True` for the given row to be selected. We would have used
    `|` for `or` if we had wanted to select the rows where *either* condition was
    `True`.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该仔细查看如何在 *步骤 11* 中使用 `loc` 访问器选择行。在 `nls97.loc[(nls97.nightlyhrssleep<=4)
    & (nls97.childathome>=3)]` 中，每个条件都被括号括起来。如果省略括号，将会产生错误。`&` 操作符在标准 Python 中等同于
    `and`，意味着 *两个* 条件都必须为 `True`，对应的行才会被选择。如果我们想选择 *任一* 条件为 `True` 的行，则会使用 `|` 来代替
    `&`。
- en: 'Finally, *Step 12* demonstrates how to select both rows and columns in one
    call to the `loc` accessor. The criteria for rows appear before the comma and
    the columns to select appear after the comma, as in the following statement:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，*步骤 12* 演示了如何在一次调用 `loc` 访问器时同时选择行和列。选择行的条件出现在逗号前，选择的列出现在逗号后，如以下语句所示：
- en: '[PRE84]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: This returns the `nightlyhrssleep` and `childathome` columns for all rows where
    the individual has `nightlyhrssleep` of less than or equal to 4, and `childathome`
    greater than or equal to 3.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 这将返回 `nightlyhrssleep` 和 `childathome` 列的所有行，其中每行的 `nightlyhrssleep` 小于或等于 4，且
    `childathome` 大于或等于 3。
- en: There’s more…
  id: totrans-214
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多…
- en: 'We used three different tools to select rows from a pandas DataFrame in this
    recipe: the `[]` bracket operator, and two pandas-specific accessors, `loc` and
    `iloc`. This is a little confusing if you are new to pandas, but it becomes clear
    which tool to use in which situation after just a few months. If you came to pandas
    with a fair bit of Python and NumPy experience, you likely find the `[]` operator
    most familiar. However, the pandas documentation recommends against using the
    `[]` operator for production code. I have settled on a routine of using that operator
    only for selecting columns from a DataFrame. I use the `loc` accessor when selecting
    rows by boolean indexing or by index label, and the `iloc` accessor for selecting
    rows by row number. Since my workflow has me using a fair bit of boolean indexing,
    I use `loc` much more than the other methods.'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 在本食谱中，我们使用了三种不同的工具从 pandas DataFrame 中选择行：`[]` 方括号操作符、以及两个 pandas 特有的访问器，`loc`
    和 `iloc`。如果你是 pandas 新手，这可能有点混淆，但只需几个月的使用，你就会明白在不同情况下该使用哪个工具。如果你是带着一定的 Python
    和 NumPy 经验来学习 pandas 的，你可能会发现 `[]` 操作符最为熟悉。然而，pandas 文档建议在生产代码中不要使用 `[]` 操作符。我已经习惯了仅在从
    DataFrame 中选择列时使用该操作符。选择行时，我使用 `loc` 访问器进行布尔索引或按索引标签选择，使用 `iloc` 访问器按行号选择行。由于我的工作流程中使用了大量布尔索引，我比其他方法使用
    `loc` 要多得多。
- en: See also
  id: totrans-216
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: The recipe immediately preceding this one, *Selecting and organizing columns*,
    has a more detailed discussion on selecting columns.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 紧接着前面的食谱，*选择和组织列*，对列选择有更详细的讨论。
- en: Generating frequencies for categorical variables
  id: totrans-218
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为分类变量生成频率
- en: Many years ago, a very seasoned researcher said to me, *“90% of what we’re going
    to find, we’ll see in the frequency distributions*.*”* That message has stayed
    with me. The more one-way and two-way frequency distributions (crosstabs) I do
    on a DataFrame, the better I understand it. We will do one-way distributions in
    this recipe, and crosstabs in subsequent recipes.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 多年前，一位经验丰富的研究人员对我说，*“我们要找到的90%的内容，都会在频率分布中看到。”* 这句话一直深深印在我心中。通过对 DataFrame 做更多的一维和二维频率分布（交叉表），我对其理解也越来越深刻。在本食谱中，我们将进行一维分布，之后的食谱将介绍交叉表。
- en: Getting ready…
  id: totrans-220
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备好…
- en: We continue our work with the NLS. We will also be doing a fair bit of column
    selection using filter methods. It is not necessary to review the recipe in this
    chapter on column selection, but it might be helpful.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将继续处理 NLS 数据集。我们还会使用过滤方法进行大量的列选择。虽然不必重新审视本章关于列选择的食谱，但它可能会有所帮助。
- en: How to do it…
  id: totrans-222
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'We use pandas tools to generate frequencies, particularly the very handy `value_counts`:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 pandas 工具生成频率，尤其是非常方便的 `value_counts`：
- en: Load the `pandas` library and the `nls97` file.
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载 `pandas` 库和 `nls97` 文件。
- en: 'Also, convert the columns of object data type to the category data type:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，将对象数据类型的列转换为类别数据类型：
- en: '[PRE85]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: Show the names of the columns of the category data type and check for the number
    of missing values.
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 显示类别数据类型列的名称，并检查缺失值的数量。
- en: 'Note that there are no missing values for `gender` and only a few for `highestdegree`,
    but many for `maritalstatus` and other columns:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`gender` 列没有缺失值，`highestdegree` 只有少数缺失值，但 `maritalstatus` 和其他列有许多缺失值：
- en: '[PRE86]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: '[PRE87]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: 'Show the frequencies for marital status:'
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 显示婚姻状况的频率：
- en: '[PRE88]'
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE88]'
- en: '[PRE89]'
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE89]'
- en: 'Turn off sorting by frequency:'
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 关闭按频率排序：
- en: '[PRE90]'
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE90]'
- en: '[PRE91]'
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE91]'
- en: 'Show percentages instead of counts:'
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 显示百分比而非计数：
- en: '[PRE92]'
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE92]'
- en: '[PRE93]'
  id: totrans-239
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE93]'
- en: Show the percentages for all government responsibility columns.
  id: totrans-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 显示所有政府责任列的百分比。
- en: 'Filter the DataFrame for just the government responsibility columns, then use
    `apply` to run `value_counts` on all columns in that DataFrame:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 仅筛选出政府责任列的 DataFrame，然后使用 `apply` 在该 DataFrame 的所有列上运行 `value_counts`：
- en: '[PRE94]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: '[PRE95]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: Find the percentages, for all government responsibility columns, of people who
    are married.
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 找出所有政府责任列中已婚人数的百分比。
- en: 'Do what we did in *Step 6*, but first select only rows with marital status
    equal to `Married`:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 做我们在 *第 6 步* 中所做的，但首先选择仅 `maritalstatus` 为 `Married` 的行：
- en: '[PRE96]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE96]'
- en: '[PRE97]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE97]'
- en: Find the frequencies and percentages for all category columns in the DataFrame.
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 找出所有类别列的频率和百分比。
- en: 'First, open a file to write out the frequencies:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，打开一个文件以写出频率：
- en: '[PRE98]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE98]'
- en: 'This generates a file, the beginning of which looks like this:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 这会生成一个文件，其开头如下所示：
- en: '[PRE99]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE99]'
- en: As these steps demonstrate, `value_counts` is quite useful when we need to generate
    frequencies for one or more columns of a DataFrame.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 正如这些步骤所展示的，`value_counts` 在我们需要为一个或多个 DataFrame 列生成频率时非常有用。
- en: How it works…
  id: totrans-254
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: Most of the columns in the `nls97` DataFrame (57 out of 88) have the object
    data type. If we are working with data that is logically categorical, but does
    not have a category data type in pandas, there are good reasons to convert it
    to the category type. Not only does this save memory; it also makes data cleaning
    a little easier, as we saw in this recipe.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: '`nls97` DataFrame 中大部分列（88列中的57列）具有对象数据类型。如果我们处理的数据在逻辑上是类别型的，但在 pandas 中没有类别数据类型，将其转换为类别类型是有充分理由的。这不仅节省内存，还使得数据清理变得更简单，就像我们在本教程中看到的那样。'
- en: The star of the show for this recipe is the `value_counts` method. It can generate
    frequencies for a Series, as we did with `nls97.maritalstatus.value_counts`. It
    can also be run on a whole DataFrame as we did with `nls97.filter(like="gov").apply(pd.Series.value_counts,
    normalize=True)`. We first create a DataFrame with just the government responsibility
    columns and then pass the resulting DataFrame to `value_counts` with `apply`.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程的重点是 `value_counts` 方法。它可以为 Series 生成频率，就像我们使用 `nls97.maritalstatus.value_counts`
    所做的那样。它也可以在整个 DataFrame 上运行，就像我们使用 `nls97.filter(like="gov").apply(pd.Series.value_counts,
    normalize=True)` 所做的那样。我们首先创建一个只包含政府责任列的 DataFrame，然后将生成的 DataFrame 传递给 `value_counts`
    与 `apply` 一起使用。
- en: You probably noticed that in *Step 7*, I split the chaining over several lines
    to make it easier to read. There is no rule about when it makes sense to do that.
    I generally try to do that whenever the chaining involves three or more operations.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能注意到在 *第 7 步* 中，我将链式操作拆分成了多行，以便更易于阅读。关于何时拆分并没有严格的规则。我通常会在链式操作涉及三次或更多操作时尝试这样做。
- en: 'In *Step 8*, we iterated over all of the columns with the category data type:
    `for col in nls97.select_dtypes(include=["category"])`. For each of those columns,
    we ran `value_counts` to get frequencies and `value_counts` again to get percentages.
    We used a `print` function to generate the carriage returns necessary to make
    the output readable. All of this is saved to the `frequencies.txt` file in the
    `views` subfolder. I find it handy to have a bunch of one-way frequencies around
    just to check before doing any work with categorical variables. *Step 8* accomplishes
    that.'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *第 8 步* 中，我们遍历了所有类别数据类型的列：`for col in nls97.select_dtypes(include=["category"])`。对于每一列，我们运行了
    `value_counts` 获取频率，再次运行 `value_counts` 获取百分比。我们使用 `print` 函数生成换行符，使输出更易读。所有这些都保存在
    `views` 子文件夹中的 `frequencies.txt` 文件中。我发现保留一组单向频率数据是非常方便的，便于在对类别变量进行任何工作之前进行检查。*第
    8 步* 就是实现这一目标的。
- en: There’s more…
  id: totrans-259
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多……
- en: Frequency distributions may be the most important statistical tool for discovering
    potential data issues with categorical data. The one-way frequencies we generated
    in this recipe are a good foundation for further insights.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 频率分布可能是发现类别数据潜在问题最重要的统计工具。我们在本教程中生成的单向频率是进一步洞察的良好基础。
- en: However, we often only detect problems once we examine the relationships between
    categorical variables and other variables, categorical or continuous. Although
    we stopped short of doing two-way frequencies in this recipe, we did start the
    process of splitting up the data for investigation in *Step 7*. In that step,
    we looked at government responsibility responses for married individuals and saw
    that those responses differed from those for the sample overall.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们通常只有在检查分类变量与其他变量（无论是分类的还是连续的）之间的关系时，才能发现问题。尽管在这个例子中我们没有进行双向频率分析，但我们确实在*第7步*中开始了拆分数据进行调查的过程。在那一步中，我们查看了已婚个体的政府责任回应，并发现这些回应与整体样本的回应有所不同。
- en: This raises several questions about our data that we need to explore. Are there
    important differences in response rates by marital status, and might this matter
    for the distribution of the government responsibility variables? We also want
    to be careful about drawing conclusions before considering potential confounding
    variables. Are married respondents likely to be older or to have more children,
    and are those more important factors in their government responsibility answers?
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 这引发了我们需要探索的几个关于数据的问题。婚姻状况是否会影响回应率，这是否会对政府责任变量的分布产生影响？在得出结论之前，我们还需要谨慎考虑潜在的混杂变量。已婚的受访者是否更可能年纪较大或拥有更多孩子，这些因素是否对他们的政府责任回答更为重要？
- en: I am using the marital status variable as an example of the kind of queries
    that producing one-way frequencies, like the ones in this recipe, are likely to
    generate. It is always good to have some bivariate analyses (a correlation matrix,
    some crosstabs, or a few scatter plots) at the ready should questions like these
    come up. We will generate those in the next two chapters.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 我使用婚姻状况变量作为示例，说明生成单向频率（如本例中的频率）可能会引发的查询问题。在遇到类似问题时，准备一些双变量分析（如相关矩阵、交叉表或一些散点图）总是明智的。我们将在接下来的两章中生成这些分析。
- en: Generating summary statistics for continuous variables
  id: totrans-264
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为连续变量生成总结统计数据
- en: pandas has a good number of tools we can use to get a sense of the distribution
    of continuous variables. We will focus on the splendid functionality of `describe`
    in this recipe and demonstrate the usefulness of histograms for visualizing variable
    distributions.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: pandas提供了大量工具，我们可以利用它们了解连续变量的分布。我们将在本例中重点展示`describe`的强大功能，并演示直方图在可视化变量分布中的作用。
- en: Before doing any analysis with a continuous variable, it is important to have
    a good understanding of how it is distributed – its central tendency, its spread,
    and its skewness. This understanding greatly informs our efforts to identify outliers
    and unexpected values. But it is also crucial information in and of itself. I
    do not think it overstates the case to say that we understand a particular variable
    well if we have a good understanding of how it is distributed, and any interpretation
    without that understanding will be incomplete or flawed in some way.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 在对连续变量进行任何分析之前，理解它的分布非常重要——它的集中趋势、分布范围以及偏态性。这些理解大大帮助我们识别离群值和异常值。然而，这本身也是至关重要的信息。我认为并不夸张地说，如果我们能够很好地理解某个变量的分布，我们就能很好地理解它，而没有这种理解的任何解释都会不完整或有缺陷。
- en: Getting ready…
  id: totrans-267
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备就绪……
- en: We will work with the COVID-19 totals data in this recipe. You will need **Matplotlib**
    to run this. If it is not installed on your machine already, you can install it
    in the terminal by entering `pip install matplotlib`.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将使用COVID-19总数数据。你需要**Matplotlib**来运行此代码。如果你的机器上尚未安装它，可以通过在终端输入`pip
    install matplotlib`来安装。
- en: How to do it…
  id: totrans-269
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做……
- en: 'Let’s take a look at the distribution of a few key continuous variables:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下几个关键连续变量的分布：
- en: 'Import `pandas`, `numpy`, and `matplotlib`, and load the COVID-19 case totals
    data:'
  id: totrans-271
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`pandas`、`numpy`和`matplotlib`，并加载COVID-19病例总数数据：
- en: '[PRE100]'
  id: totrans-272
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE100]'
- en: 'Let’s remind ourselves of the structure of the data:'
  id: totrans-273
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们回顾一下数据的结构：
- en: '[PRE101]'
  id: totrans-274
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE101]'
- en: '[PRE102]'
  id: totrans-275
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE102]'
- en: '[PRE103]'
  id: totrans-276
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE103]'
- en: '[PRE104]'
  id: totrans-277
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE104]'
- en: '[PRE105]'
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE105]'
- en: '[PRE106]'
  id: totrans-279
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE106]'
- en: 'Get the descriptive statistics on the COVID-19 totals columns:'
  id: totrans-280
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取COVID-19总数列的描述性统计：
- en: '[PRE107]'
  id: totrans-281
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE107]'
- en: '[PRE108]'
  id: totrans-282
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE108]'
- en: Take a closer look at the distribution of values for the cases and deaths columns.
  id: totrans-283
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更仔细地查看病例和死亡列的值分布。
- en: 'Use NumPy’s `arange` method to pass a list of floats from 0 to 1.0 to the `quantile`
    method of the DataFrame:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 使用NumPy的`arange`方法将从0到1.0的浮动数列表传递给DataFrame的`quantile`方法：
- en: '[PRE109]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE109]'
- en: '[PRE110]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE110]'
- en: 'View the distribution of total cases:'
  id: totrans-287
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看总病例的分布：
- en: '[PRE111]'
  id: totrans-288
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE111]'
- en: '![fig](img/B18596_03_01.png)'
  id: totrans-289
  prefs: []
  type: TYPE_IMG
  zh: '![fig](img/B18596_03_01.png)'
- en: 'Figure 3.1: A plot of total COVID-19 cases'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.1：COVID-19 总病例数的图表
- en: The preceding steps demonstrated the use of `describe` and Matplotlib’s `hist`
    method, which are essential tools when working with continuous variables.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的步骤展示了`describe`方法和Matplotlib的`hist`方法的使用，这些是处理连续变量时的基本工具。
- en: How it works…
  id: totrans-292
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: We used the `describe` method in *Step 3* to examine some summary statistics
    and the distribution of the key variables. It is often a red flag when the mean
    and median (the value at the 50^(th) percentile) have dramatically different values.
    Cases and deaths are heavily skewed to the right (reflected in the mean being
    much higher than the median). This alerts us to the presence of outliers at the
    upper end. This is true even with the adjustment for population size, as both
    `total_cases_pm` and `total_deaths_pm` show this same skew. We do more analysis
    of outliers in the next chapter.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在*步骤 3*中使用了`describe`方法来检查一些汇总统计数据和关键变量的分布。当均值和中位数（50^(th)百分位的值）差异巨大时，这通常是一个警示信号。病例和死亡数严重偏向右侧（这一点通过均值远高于中位数得以体现）。这提示我们在上端存在离群值。即使调整了人口规模，`total_cases_pm`和`total_deaths_pm`依然表现出相同的偏态。我们将在下一章进行更多关于离群值的分析。
- en: The more detailed percentile data in *Step 4* further supports this sense of
    skewness. For instance, the gap between the 90^(th)-percentile and 100^(th)-percentile
    values for cases and deaths is substantial. These are good first indicators that
    we are not dealing with normally distributed data here. Even if this is not due
    to errors, this matters for the statistical testing we will do down the road.
    On the list of things we want to note when asked, *“How does the data look?”*,
    this is one of the first things we want to say.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: '*步骤 4*中的更详细的百分位数据进一步支持了这种偏态感。例如，病例和死亡数在90^(th)-百分位和100^(th)-百分位之间的差距相当大。这些都是表明我们处理的数据不是正态分布的良好初步指标。即使这不是由于错误导致的，这对于我们未来进行的统计检验也是至关重要的。当被问到*“数据看起来怎么样？”*时，我们首先想说的就是这些内容。'
- en: The histogram of total cases confirms that much of the distribution is between
    0 and 100,000, with a few outliers and 1 extreme outlier. Visually, the distribution
    looks much more log-normal than normal. Log-normal distributions have fatter tails
    and do not have negative values.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 总病例数的直方图确认，大部分数据分布在0到100,000之间，且有一些离群值和1个极端离群值。从视觉效果来看，分布更接近对数正态分布，而非正态分布。对数正态分布具有更胖的尾部，并且没有负值。
- en: See also
  id: totrans-296
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: We take a closer look at outliers and unexpected values in the next chapter.
    We do much more with visualizations in *Chapter 5*, *Using Visualizations for
    the Identification of Unexpected Values*.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一章深入探讨离群值和意外值。在*第五章*中，我们将做更多关于可视化的工作，*使用可视化识别意外值*。
- en: Using generative AI to display descriptive statistics
  id: totrans-298
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用生成式AI显示描述性统计数据
- en: Generative AI tools provide data scientists with a great opportunity to streamline
    the data cleaning and exploration parts of our workflow. Large language models,
    in particular, have the potential to make this work much easier and more intuitive.
    Using these tools, we can select rows and columns by criteria, generate summary
    statistics, and plot variables.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI工具为数据科学家提供了一个极好的机会，以简化数据清洗和探索工作流程。尤其是大型语言模型，具有使这项工作变得更容易、更直观的潜力。通过使用这些工具，我们可以按条件选择行和列，生成汇总统计，并绘制变量图。
- en: A simple way to introduce generative AI tools into your data exploration is
    with PandasAI. PandasAI uses the OpenAI API to translate natural language queries
    into data selection and operations that pandas can understand. As of July 2023,
    OpenAI is the only large language model API that can be used with PandasAI, though
    the developers of the library anticipate adding other APIs.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 将生成式AI工具引入数据探索的一个简单方法是使用PandasAI。PandasAI利用OpenAI的API将自然语言查询转换为pandas能够理解的数据选择和操作。截至2023年7月，OpenAI是唯一可以与PandasAI配合使用的大型语言模型API，尽管该库的开发者预计将来会添加其他API。
- en: We can use PandasAI to substantially reduce the lines of code we need to write
    to produce some of the tabulations and visualizations we have created so far in
    this chapter. The steps in this recipe show how you can do that.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用PandasAI大幅减少编写代码的行数，以便生成我们在本章中创建的某些表格和可视化。此处的步骤展示了如何实现这一点。
- en: Getting ready…
  id: totrans-302
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作…
- en: You need to install PandasAI to run the code in this recipe. You can do that
    with `pip install pandasai`. We will work with the COVID-19 data again, which
    is available in the GitHub repository, as is the code.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行本食谱中的代码，你需要安装PandasAI。你可以使用`pip install pandasai`来安装。我们将再次使用COVID-19数据，该数据可在GitHub仓库中找到，代码也是如此。
- en: You will also need an API key from OpenAI. You can get one at [platform.openai.com](https://platform.openai.com).
    You will need to set up an account and then click on your profile in the upper-right
    corner, followed by **View API keys**.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 你还需要一个来自OpenAI的API密钥。你可以在[platform.openai.com](https://platform.openai.com)获取一个。你需要设置一个帐户，然后点击右上角的个人资料，再点击**查看API密钥**。
- en: How to do it…
  id: totrans-305
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'We create a PandasAI instance in the following steps and use it to take a look
    at the COVID-19 data:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在以下步骤中创建一个PandasAI实例，并使用它查看COVID-19数据：
- en: 'We start by importing `pandas` and the `PandasAI` library:'
  id: totrans-307
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们首先导入`pandas`和`PandasAI`库：
- en: '[PRE112]'
  id: totrans-308
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE112]'
- en: 'Next, we load the COVID-19 data and instantiate a `PandasAI SmartDataframe`
    object. The `SmartDataframe` object will allow us to work with our data using
    natural language:'
  id: totrans-309
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们加载COVID-19数据并实例化一个`PandasAI SmartDataframe`对象。`SmartDataframe`对象将允许我们使用自然语言处理数据：
- en: '[PRE113]'
  id: totrans-310
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE113]'
- en: 'Let’s look at the structure of the COVID-19 data. We can do this by passing
    natural language instructions to the SmartDataframe’s `chat` method:'
  id: totrans-311
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们看看COVID-19数据的结构。我们可以通过向SmartDataframe的`chat`方法传递自然语言指令来做到这一点：
- en: '[PRE114]'
  id: totrans-312
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE114]'
- en: '[PRE115]'
  id: totrans-313
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE115]'
- en: 'It is also straightforward to see the first few rows:'
  id: totrans-314
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 也可以轻松查看前几行数据：
- en: '[PRE116]'
  id: totrans-315
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE116]'
- en: '[PRE117]'
  id: totrans-316
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE117]'
- en: 'We can see which locations (countries) have the highest total cases:'
  id: totrans-317
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以查看哪些地点（国家）有最高的总病例数：
- en: '[PRE118]'
  id: totrans-318
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE118]'
- en: '[PRE119]'
  id: totrans-319
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE119]'
- en: We can show the highest total cases per million as well, and also show other
    columns.
  id: totrans-320
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还可以显示每百万最高总病例数，并且展示其他列数据。
- en: 'Notice that we do not need to add the underscores in `total_cases_pm` or `total_deaths_pm`.
    The chat method figures out that that is what we meant:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们不需要在`total_cases_pm`或`total_deaths_pm`中添加下划线。`chat`方法会自动识别我们指的就是这些内容：
- en: '[PRE120]'
  id: totrans-322
  prefs: []
  type: TYPE_PRE
  zh: '[PRE120]'
- en: '[PRE121]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE121]'
- en: 'We can also create a `SmartDataframe` with selected columns. When we use the
    `chat` method in this step, it figures out that a `SmartDataframe` should be returned:'
  id: totrans-324
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还可以创建一个包含选定列的`SmartDataframe`。当我们在这一步使用`chat`方法时，它会自动识别应该返回一个`SmartDataframe`：
- en: '[PRE122]'
  id: totrans-325
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE122]'
- en: '[PRE123]'
  id: totrans-326
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE123]'
- en: '[PRE124]'
  id: totrans-327
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE124]'
- en: '[PRE125]'
  id: totrans-328
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE125]'
- en: 'We do not need to be very precise in the language we pass to PandasAI. Instead
    of writing `Select`, we could have written `Get` or `Grab`:'
  id: totrans-329
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们不需要在传递给PandasAI的语言中非常精确。我们本可以写`Get`或`Grab`，而不是`Select`：
- en: '[PRE126]'
  id: totrans-330
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE126]'
- en: '[PRE127]'
  id: totrans-331
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE127]'
- en: 'We can select rows by summary statistic. For example, we can choose those rows
    where the total cases per million is greater than the 95^(th) percentile. Note
    that this might take a little while to run on your machine:'
  id: totrans-332
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以通过汇总统计选择行。例如，我们可以选择那些每百万总病例数高于第95百分位的行。请注意，这可能需要一些时间在你的机器上运行：
- en: '[PRE128]'
  id: totrans-333
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE128]'
- en: '[PRE129]'
  id: totrans-334
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE129]'
- en: 'We can see how continuous variables are distributed by asking for their distribution:'
  id: totrans-335
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以通过请求它们的分布来查看连续变量是如何分布的：
- en: '[PRE130]'
  id: totrans-336
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE130]'
- en: '[PRE131]'
  id: totrans-337
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE131]'
- en: 'We can also get group totals. Let’s get the total cases and deaths by region:'
  id: totrans-338
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还可以获取各组的总数。让我们按地区获取总病例数和死亡数：
- en: '[PRE132]'
  id: totrans-339
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE132]'
- en: '[PRE133]'
  id: totrans-340
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE133]'
- en: 'We can easily generate plots on the COVID-19 data:'
  id: totrans-341
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以轻松生成关于COVID-19数据的图表：
- en: '[PRE134]'
  id: totrans-342
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE134]'
- en: 'This code generates the following plot:'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码生成以下图表：
- en: '![temp_chart](img/B18596_03_02.png)'
  id: totrans-344
  prefs: []
  type: TYPE_IMG
  zh: '![temp_chart](img/B18596_03_02.png)'
- en: 'Figure 3.2: Distribution of total cases per million'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.2：每百万总病例数的分布
- en: 'We can also generate a scatterplot. Let’s look at total cases per million against
    total deaths per million:'
  id: totrans-346
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还可以生成散点图。让我们看看每百万总病例数与每百万总死亡数的关系：
- en: '[PRE135]'
  id: totrans-347
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE135]'
- en: 'This code produces the following plot:'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码生成以下图表：
- en: '![temp_chart](img/B18596_03_03.png)'
  id: totrans-349
  prefs: []
  type: TYPE_IMG
  zh: '![temp_chart](img/B18596_03_03.png)'
- en: 'Figure 3.3: Scatterplot of total cases per million against total deaths per
    million'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.3：每百万总病例数与每百万总死亡数的散点图
- en: 'We can indicate which plotting tool we want to use. Using `regplot` here might
    be helpful to give us a better sense of the relationship between cases and deaths:'
  id: totrans-351
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以指定要使用哪个绘图工具。这里使用`regplot`可能有助于更好地理解病例数与死亡数之间的关系：
- en: '[PRE136]'
  id: totrans-352
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE136]'
- en: 'This code produces the following plot:'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码生成以下图表：
- en: '![temp_chart](img/B18596_03_04.png)'
  id: totrans-354
  prefs: []
  type: TYPE_IMG
  zh: '![temp_chart](img/B18596_03_04.png)'
- en: 'Figure 3.4: Regression plot'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.4：回归图
- en: 'The extreme values for cases or deaths make it harder to visualize the relationship
    between the two for much of the range. Let’s also ask PandasAI to remove the extreme
    values:'
  id: totrans-356
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于病例或死亡的极端值，会使得在大部分范围内很难看到两者之间的关系。让我们也请求PandasAI去除这些极端值：
- en: '[PRE137]'
  id: totrans-357
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE137]'
- en: 'This produces the following plot:'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成以下图表：
- en: '![temp_chart](img/B18596_03_05.png)'
  id: totrans-359
  prefs: []
  type: TYPE_IMG
  zh: '![temp_chart](img/B18596_03_05.png)'
- en: 'Figure 3.5: Regression plot without the extreme values'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.5：去除极端值后的回归图
- en: This removed deaths per million above 350 and cases per million above 20,000\.
    It is easier to see the slope of the relationship over much of the data. We will
    work more with `regplot` and many other plotting tools in *Chapter 5*, *Using
    Visualizations for the Identification of Unexpected Values*.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 这次移除了每百万死亡超过350和每百万病例超过20,000的数据。这样可以更容易地看到数据大部分部分的关系趋势。我们将在*第五章*，*使用可视化方法识别意外值*中与`regplot`和许多其他绘图工具进行更多的操作。
- en: How it works…
  id: totrans-362
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: These examples demonstrate how intuitive it is to use PandasAI. Generative AI
    tools like PandasAI have the potential to improve our exploratory work by making
    it possible to interact with the data nearly as quickly as we can imagine new
    analyses. We only need to pass natural language queries to the PandasAI object
    to get the results we want.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 这些示例展示了使用PandasAI的直观性。像PandasAI这样的生成式AI工具有潜力通过使我们几乎能像想出新的分析一样快速与数据互动，从而提升我们的探索性工作。我们只需将自然语言查询传递给PandasAI对象，就能获得我们想要的结果。
- en: The queries we pass are not commands. We can use any language we want that conveys
    our intent. Recall, for example, that we were able to write `select`, `get`, or
    even `grab` to choose columns. OpenAI’s large language model is generally very
    good at understanding what we mean.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 我们传递的查询并不是命令。我们可以使用任何能表达我们意图的语言。例如，回想一下，我们能够使用`select`、`get`，甚至`grab`来选择列。OpenAI的大型语言模型通常非常擅长理解我们的意思。
- en: It is a good idea to check the PandasAI log file to see the code that is generated
    when you pass instructions to the SmartDataframe `chat` method. The pandasai.log
    file will be in the same folder as your Python code.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 查看PandasAI日志文件，以查看你传递给SmartDataframe `chat`方法时生成的代码是个好主意。pandasai.log文件将位于与你的Python代码同一文件夹中。
- en: A tool that helps us move more swiftly from question to answer can improve our
    thinking and analysis. It is definitely worth experimenting with if you have not
    done so already, even if you have well-established routines for looking at your
    data.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 一个帮助我们更快速从问题到答案过渡的工具可以提高我们的思维和分析能力。如果你还没有尝试过这个方法，值得进行尝试，即使你已经有了查看数据的成熟流程。
- en: See also
  id: totrans-367
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: 'The PandasAI GitHub repository is a great place to go for more information
    and to keep apprised of updates in the library. You can get to it here: [https://github.com/gventuri/pandas-ai](https://github.com/gventuri/pandas-ai).
    We will return to the PandasAI library in recipes throughout this book.'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: PandasAI的GitHub仓库是获取更多信息并了解库更新的好地方。你可以通过以下链接访问：[https://github.com/gventuri/pandas-ai](https://github.com/gventuri/pandas-ai)。我们将在本书的各个配方中继续使用PandasAI库。
- en: Summary
  id: totrans-369
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This chapter covered key steps we need to take the day after we convert our
    raw data into a pandas DataFrame. We explored techniques for examining the structure
    of our data, including the number of rows and columns, and data types. We also
    learned how to generate frequencies for categorical variables, and began to look
    at how values for one variable change with the values of another variable. Finally,
    we saw how to examine the distribution of continuous variables, including with
    sample statistics such as the mean, minimum, and max, and by plotting. This sets
    us up for the topics in the next chapter, where we will use techniques to identify
    outliers in our data.
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖了将原始数据转换为pandas DataFrame后的关键步骤。我们探讨了检查数据结构的技巧，包括行数、列数和数据类型。我们还学习了如何生成类别变量的频率，并开始研究一个变量的值如何随着另一个变量的值而变化。最后，我们了解了如何检查连续变量的分布，包括使用均值、最小值和最大值等样本统计量，并通过绘图展示。这为下一章的主题做了准备，在那一章中我们将使用技术来识别数据中的异常值。
- en: Join our community on Discord
  id: totrans-371
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们的Discord社区
- en: 'Join our community’s Discord space for discussions with the author and other
    readers:'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 加入我们社区的Discord空间，与作者和其他读者进行讨论：
- en: '[https://discord.gg/p8uSgEAETX](https://discord.gg/p8uSgEAETX )'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://discord.gg/p8uSgEAETX](https://discord.gg/p8uSgEAETX )'
- en: '![](img/QR_Code10336218961138498953.png)'
  id: totrans-374
  prefs: []
  type: TYPE_IMG
  zh: '![](img/QR_Code10336218961138498953.png)'
