- en: Linear Neural Networks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性神经网络
- en: In this chapter, we will go over some of the concepts in machine learning. It
    is expected that you have previously studied and have an understanding of machine
    learning. So this chapter will serve as a refresher for some of the concepts that
    will be needed throughout this book, rather than a comprehensive study of all
    the machine learning approaches.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论一些机器学习的概念。希望你已经学习过并理解机器学习的相关内容。因此，本章将作为对本书中需要的某些概念的复习，而不是全面学习所有机器学习方法。
- en: In this chapter, we will focus on linear neural networks, which are the simplest
    type of neural networks and are used for tasks such as linear regression, polynomial
    regression, logistic regression, and softmax regression, which are used most frequently
    in statistical learning.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将重点讲解线性神经网络，这是最简单的神经网络类型，常用于诸如线性回归、多项式回归、逻辑回归和softmax回归等任务，这些任务在统计学习中最为常见。
- en: We use regression to explain the relationship between one or more independent
    variables and a dependent variable. The concepts we will learn in this chapter
    are crucial for furthering our understanding of how machine learning works before
    we dive into deep neural networks in the next chapter.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用回归来解释一个或多个自变量与因变量之间的关系。本章中我们将学习的概念对于进一步理解机器学习的工作原理至关重要，尤其是在下章深入了解深度神经网络之前。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Linear regression
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线性回归
- en: Polynomial regression
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多项式回归
- en: Logistic regression
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逻辑回归
- en: Linear regression
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性回归
- en: The purpose of regression is to find the relationship that exists between data
    (denoted by *x*) and its corresponding output (denoted by *y*) and predict it.
    The output of all regression problems is a real number ([![](img/7efc43e8-d5e1-4eb3-87fe-f9ca8505fbb6.png)]).
    This can be applied to a range of problems, such as predicting the price of a
    house or what rating a movie will have.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 回归的目的是找出数据（用 *x* 表示）与其对应输出（用 *y* 表示）之间的关系，并进行预测。所有回归问题的输出都是一个实数（[![](img/7efc43e8-d5e1-4eb3-87fe-f9ca8505fbb6.png)]）。这可以应用于一系列问题，例如预测房价或预测电影评分。
- en: 'In order for us to make use of regression, we need to use the following:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 为了能够使用回归，我们需要以下内容：
- en: Input data, which could be either scalar values or vectors. This is sometimes
    referred to as **features**.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输入数据，可以是标量值或向量。它有时被称为**特征**。
- en: Training examples, which include a good number of (*x[i], y[i]*) pairs; that
    is, the output for each input.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练示例，包含大量的 (*x[i], y[i]*) 对；也就是每个输入的输出。
- en: A function that captures the relationship between the input and output—the model.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 捕捉输入与输出之间关系的函数——模型。
- en: A loss or an objective function, which tells us how accurate our model is.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 损失或目标函数，告诉我们模型的准确度。
- en: Optimization, to minimize the loss or the objective function.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优化，以最小化损失或目标函数。
- en: 'Before we go further, let''s look back to [Chapter 1](3ce71171-c5fc-46c8-8124-4cb71c9dd92e.xhtml),
    *Vector Calculus*, where we noted that the equation of a straight line is as follows:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在进一步讲解之前，让我们回顾一下[第1章](3ce71171-c5fc-46c8-8124-4cb71c9dd92e.xhtml)，*向量微积分*，在其中我们注意到直线的方程如下：
- en: '![](img/03e99142-929a-483a-a117-8c5bbf4cd01d.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](img/03e99142-929a-483a-a117-8c5bbf4cd01d.png)'
- en: 'Here, *m* is the gradient (or slope) and *b* is a correction term. We found
    the slope using two pairs of points on the line using the following equation:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*m* 是梯度（或斜率），*b* 是修正项。我们使用以下方程，通过直线上的两个点来找到斜率：
- en: '![](img/96e28355-1c7e-4e21-b50c-dfbb297181f0.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](img/96e28355-1c7e-4e21-b50c-dfbb297181f0.png)'
- en: 'As we know, this is easy to do. In linear regression, however, we are given
    many (*x[i], y[i]*) points, and our goal is to find the line of best fit that
    best captures the relationship. This line is what our model learns. We can represent
    this as follows:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所知，这很容易做到。然而，在**线性回归**中，我们给定了许多 (*x[i], y[i]*) 点，我们的目标是找到最能捕捉关系的最佳拟合线。这条线就是我们模型所学习的内容。我们可以如下表示：
- en: '![](img/ccc299b3-996f-466a-aa27-0d79e448d6c3.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ccc299b3-996f-466a-aa27-0d79e448d6c3.png)'
- en: Here, *ε* represents an error, which we assume to be Gaussian, *y* is the true
    label, and [![](img/9b75ef25-3a95-4910-adc3-9f65764a128f.png)] is the prediction
    that our model provides.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*ε* 代表误差，我们假设它是高斯分布，*y* 是真实标签，且 [![](img/9b75ef25-3a95-4910-adc3-9f65764a128f.png)]
    是我们的模型所提供的预测值。
- en: Let's now consider a case where we have multiple independent variables and we
    want to find the relationship between one dependent variable. This type of regression
    is known as **multiple regression**. In this case, each of the independent variables
    has an impact on the predicted output.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们考虑一个有多个自变量的案例，我们希望找到一个因变量之间的关系。这种回归方法称为**多元回归**。在这种情况下，每个自变量都会影响预测结果。
- en: 'Our inputs, in this case, will take the following form:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们的输入将采取如下形式：
- en: '![](img/c93c9b31-e539-48b7-aeee-0034b9e6e53f.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c93c9b31-e539-48b7-aeee-0034b9e6e53f.png)'
- en: Here, *n* is the number of independent variables.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*n* 是自变量的数量。
- en: To find [![](img/60f67eb9-ce2a-4ae4-97bc-3ca0cb11d226.png)], we could just average
    over all the dependent variables or sum them together, but this is not likely to give
    us the desired result. Suppose we want to predict the price of a house; our inputs
    could be the square footage of the lot, the number of bedrooms, the number of
    bathrooms, and whether or not it has a swimming pool.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 为了找到 [![](img/60f67eb9-ce2a-4ae4-97bc-3ca0cb11d226.png)]，我们可以对所有因变量求平均或将它们加起来，但这**不太可能**给我们期望的结果。假设我们想预测房子的价格；我们的输入可能是地块的平方英尺、卧室数量、浴室数量，以及是否有游泳池。
- en: 'Each of the inputs will have a corresponding weight, which the model will learn
    from the data points, that best describes the importance of each of the inputs.
    This then becomes the following:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 每个输入都会有一个对应的权重，模型会从数据点中学习这个权重，它最能描述每个输入的重要性。这就变成了如下形式：
- en: '![](img/fd5f2d12-81cb-4dc4-a89c-469792047467.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fd5f2d12-81cb-4dc4-a89c-469792047467.png)'
- en: 'Or, we have the following:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，我们可以得到如下形式：
- en: '![](img/4d84d7a6-3064-41ce-95a2-041b17f3b191.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4d84d7a6-3064-41ce-95a2-041b17f3b191.png)'
- en: 'We can also rewrite this in matrix form:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以将其重新写成矩阵形式：
- en: '![](img/8744799f-898d-41e7-9bdb-9e06e6f48bc0.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8744799f-898d-41e7-9bdb-9e06e6f48bc0.png)'
- en: But now, the obvious question arises—*how does our model learn these weights
    and this relationship?* This is easy for us to do because our brains instantly
    spot patterns and we can analytically spot relationships. However, if our machine
    is to learn this relationship, it needs a guide. This guide is the loss function,
    which tells the model how off its prediction is and which direction it needs to
    move in to improve.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 但现在，显然有一个问题——*我们的模型如何学习这些权重和这种关系？* 对我们来说，这很容易，因为我们的脑袋可以瞬间识别模式，我们能够从分析中发现关系。然而，如果我们的机器要学习这种关系，它需要一个指南。这个指南就是损失函数，它告诉模型预测偏差有多大，并指示它需要朝哪个方向移动才能改进。
- en: 'The loss is generally the distance between the prediction ([![](img/83b719ec-1803-448b-8545-dbefd29cbeb4.png)]) and
    the true value (*y[i]*), which we can write as follows:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 损失通常是预测值 ([![](img/83b719ec-1803-448b-8545-dbefd29cbeb4.png)]) 与真实值 (*y[i]*)
    之间的距离，我们可以如下表示：
- en: '![](img/a2e32feb-4a43-48c6-ba93-67919c751f52.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a2e32feb-4a43-48c6-ba93-67919c751f52.png)'
- en: 'But that still doesn''t give us the full picture. Our goal is to minimize the
    loss over all the data samples that the model is trained on, so we average the
    sum of the losses over all the data samples. This looks as follows:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 但这仍然没有给我们完整的视图。我们的目标是最小化模型在所有数据样本上的损失，因此我们将所有数据样本的损失求和并取平均。这看起来如下：
- en: '![](img/56c0c641-3f99-4185-9e46-f457657b0c31.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](img/56c0c641-3f99-4185-9e46-f457657b0c31.png)'
- en: 'The goal of training is to find the optimal parameters:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 训练的目标是找到最佳参数：
- en: '![](img/9a48ee26-6d2b-424e-b15f-75728bda8228.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9a48ee26-6d2b-424e-b15f-75728bda8228.png)'
- en: Having learned what linear regression is, let's now see what polynomial regression
    is all about in the following section.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在了解了线性回归之后，接下来让我们看看多项式回归的具体内容。
- en: Polynomial regression
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多项式回归
- en: 'Linear regression, as you might imagine, isn''t a one-size-fits-all solution
    that we can use for any problem. A lot of the relationships that exist between
    variables in the real world are not linear; that is, a straight line isn''t able
    to capture the relationship. For these problems, we use a variant of the preceding
    linear regression known as **polynomial regression**, which can capture more complexities,
    such as curves. This method makes use of applying different powers to the explanatory
    variable to discover non-linear problems. This looks as follows:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归，正如你所想，它并不是一个适用于所有问题的通用解决方案。现实中，变量之间的许多关系并不是线性的；也就是说，一条直线无法捕捉到这些关系。对于这些问题，我们使用前述线性回归的变体——**多项式回归**，它能够捕捉到更多的复杂性，例如曲线。这种方法利用将解释变量应用不同的幂次来发现非线性问题。其形式如下：
- en: '![](img/3421bf9d-521d-4462-8fc5-9da468a13ab3.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3421bf9d-521d-4462-8fc5-9da468a13ab3.png)'
- en: 'Or, we could have the following:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，我们可能会有以下情况：
- en: '![](img/adcf6e47-e525-4804-a39c-85748eb667ed.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](img/adcf6e47-e525-4804-a39c-85748eb667ed.png)'
- en: This is the case for [![](img/76d7c0d5-2e79-4a23-8894-87157a9444be.png)].
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这是 [![](img/76d7c0d5-2e79-4a23-8894-87157a9444be.png)] 的情况。
- en: As you can see from the preceding equation, a model such as this is not only
    able to capture a straight line (if needed) but can also generate a second-order,
    third-order, or *n^(th)-*order equation that fits the data points.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 如前面的方程所示，这样的模型不仅能够捕捉到一条直线（如果需要的话），还能够生成一个二阶、三阶或 *n^(th)-*阶方程来拟合数据点。
- en: 'Let''s suppose we have the following data points:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有以下数据点：
- en: '![](img/57eeebcf-d187-4f30-9f18-35ec13d15f45.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](img/57eeebcf-d187-4f30-9f18-35ec13d15f45.png)'
- en: 'We can immediately tell that a straight line will not do the job, but after
    we apply polynomial regression to it, we can see that our model learns to fit
    the curve, which resembles a sinusoidal wave. We can observe this in the following
    graph:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以立即判断，直线无法完成任务，但当我们应用多项式回归时，我们可以看到我们的模型学习拟合曲线，这个曲线类似于正弦波。我们可以在下图中观察到这一点：
- en: '![](img/84e5960a-bcf8-43c7-9fd5-2987fcbdd39e.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](img/84e5960a-bcf8-43c7-9fd5-2987fcbdd39e.png)'
- en: 'Let''s now take a look at a case where we are trying to learn a surface and
    we have two inputs, [![](img/84a44442-ce63-47b7-a866-8db81fae6ea6.png)], and one
    output, *y*. Again, as we can see in the following diagram, the surface is not
    flat; in fact, it is quite bumpy:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们来看一个案例，我们试图学习一个表面，并且有两个输入，[![](img/84a44442-ce63-47b7-a866-8db81fae6ea6.png)]，和一个输出， *y*。同样，如下图所示，表面并不平坦；实际上，它相当崎岖：
- en: '![](img/39c2e48d-16a4-4568-822c-e1c8f934b7c7.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](img/39c2e48d-16a4-4568-822c-e1c8f934b7c7.png)'
- en: 'We could approximate model this using the following third-order polynomial:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用以下三阶多项式来近似建模：
- en: '![](img/89bb7807-34c1-4707-9c30-ed689c514603.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](img/89bb7807-34c1-4707-9c30-ed689c514603.png)'
- en: If this gives us a satisfactory result, we can add another higher-degree polynomial
    (and so on) until there is one that models the surface.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这给出了令人满意的结果，我们可以添加另一个更高阶的多项式（以此类推），直到找到一个能够拟合表面的模型。
- en: Logistic regression
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 逻辑回归
- en: There is another kind of regression that we often use in practice—**logistic
    regression**. Suppose we want to determine whether or not an email is spam. In
    this case, our *x**(s)* value could be occurrences of *!(s)* or the total number
    of spelling errors in the email. Then, *y* can take on the value of 1 (for spam)
    and 0 (for not spam).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一种我们在实践中常用的回归方法——**逻辑回归**。假设我们想要判断一封电子邮件是否是垃圾邮件。在这种情况下，我们的 *x**(s)* 值可以是 *!(s)*
    出现的次数，或者是邮件中的拼写错误总数。然后， *y* 可以取值为 1（表示垃圾邮件）和 0（表示非垃圾邮件）。
- en: In this kind of case, linear regression will simply not work since we are not
    predicting a real value—we are trying to predict which class the email belongs
    to.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，线性回归将无法发挥作用，因为我们不是在预测一个实际值——我们是在预测电子邮件属于哪个类别。
- en: 'This will usually end up looking as follows:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这通常会呈现如下形式：
- en: '![](img/01bd01b2-49ee-42d4-866e-8d2f08bc04f4.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](img/01bd01b2-49ee-42d4-866e-8d2f08bc04f4.png)'
- en: As you can see, the data is grouped into two areas—one that represents non-spam
    and another that represents spam.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，数据被分成了两个区域——一个代表非垃圾邮件，另一个代表垃圾邮件。
- en: 'We can calculate this as follows:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以按以下方式计算：
- en: '![](img/ecd42f71-3b83-4fbb-ae7f-908e0f070183.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ecd42f71-3b83-4fbb-ae7f-908e0f070183.png)'
- en: Here, [![](img/998103ce-5957-4ba8-8240-06606f4d11f3.png)].
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 这里， [![](img/998103ce-5957-4ba8-8240-06606f4d11f3.png)]。
- en: 'However, this only works for binary classification. What if we want to classify
    multiple classes? Then, we can use softmax regression, which is an extension of
    logistic regression. This will look as follows:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这仅适用于二分类问题。如果我们想要分类多个类别怎么办？那我们可以使用 softmax 回归，它是逻辑回归的扩展。其形式如下：
- en: '![](img/a32f1773-9136-4f13-b444-72dd19877d15.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a32f1773-9136-4f13-b444-72dd19877d15.png)'
- en: This is the case for [![](img/b75a1fe0-065b-4db0-999f-2ffab4675152.png)] and [![](img/93f8591c-8ab0-4b16-b862-a352eca326e4.png)].
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这是 [![](img/b75a1fe0-065b-4db0-999f-2ffab4675152.png)] 和 [![](img/93f8591c-8ab0-4b16-b862-a352eca326e4.png)] 的情况。
- en: Summary
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we learned about various forms of regression, such as (multiple)
    linear regression, polynomial regression, logistic regression, and softmax regression.
    Each of these models has aided us in figuring out the relationship that exists
    between one or more independent variable(s) and a dependent variable. For some
    of you, these concepts may seem very rudimentary, but they will serve us well
    on our journey throughout this book and in gaining a deeper understanding of the
    concepts to come.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章，我们学习了各种回归形式，例如（多元）线性回归、二次回归、逻辑回归和softmax回归。每种模型都帮助我们找出了一个或多个自变量与因变量之间的关系。对一些人来说，这些概念可能显得非常基础，但它们将在我们本书的旅程中为我们提供很大帮助，并帮助我们更深入地理解接下来的概念。
- en: In the next chapter, we will learn about feedforward neural networks.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将学习前馈神经网络。
