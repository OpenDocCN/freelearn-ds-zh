- en: Preface
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 前言
- en: The purpose of data science is to transform the world using data, and this goal
    is mainly achieved through disrupting and changing real processes in real industries.
    To operate at that level we need to be able to build data science solutions of
    substance; ones that solve real problems, and which can run reliably enough for
    people to trust and act upon.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学的目的是利用数据改变世界，这个目标主要通过颠覆和改变真实行业中的真实流程来实现。要在这个层面上运作，我们需要能够构建实质性的数据科学解决方案；解决真正的问题，并且能够可靠地运行，以便人们信任并采取行动。
- en: 'This book explains how to use Spark to deliver production grade data science
    solutions that are innovative, disruptive, and reliable enough to be trusted.
    Whilst writing this book it was the authors’ intention to deliver a work that
    transcends the traditional cookbook style: providing not just examples of code,
    but developing the techniques and mind-set that are needed to explore content
    like a master; as they say, *Content is King*! Readers will notice that the book
    has a heavy emphasis on news analytics, and occasionally pulls in other datasets
    such as Tweets and financial data. This emphasis on news is not an accident; much
    effort has been spent on trying to focus on datasets that offer context at a global
    scale.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本书解释了如何使用Spark提供生产级的数据科学解决方案，这些解决方案创新、颠覆性，并且足够可靠，值得信赖。在撰写本书时，作者的意图是提供一本超越传统食谱风格的作品：不仅提供代码示例，还要培养探索内容的技巧和心态，就像一位大师；正如他们所说，“内容为王”！读者会注意到本书在新闻分析方面的重点，并偶尔引入其他数据集，如推文和金融数据。这种对新闻的重视并非偶然；我们花了很多精力试图专注于提供全球范围内提供背景的数据集。
- en: The implicit problem that this book is dedicated to is the lack of data offering
    proper context around how and why people make decisions. Often, directly accessible
    data sources are very focused on problem specifics and, as a consequence, can
    be very light on broader datasets offering the behavioral context needed to really
    understand what’s driving the decisions that people make.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本书致力于解决的隐含问题是缺乏提供人们如何以及为什么做出决策的适当背景的数据。通常，直接可访问的数据源非常专注于特定问题，因此在提供行为背景所需的更广泛数据集方面可能非常有限，这导致我们无法真正理解人们做出决策的驱动因素。
- en: Considering a simple example where website users’ key information such as age,
    gender, location, shopping behavior, purchases and so on are known, we might use
    this data to recommend products based on what others “like them” have been buying.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个简单的例子，网站用户的关键信息，如年龄、性别、位置、购物行为、购买等都是已知的，我们可以利用这些数据来推荐产品，基于其他“和他们相似”的人购买的产品。
- en: But to be exceptional, more context is required as to why people behave as they
    do. When news reports suggest a massive Atlantic hurricane is approaching the
    Florida coastline, and could reach the coast in say 36 hours, perhaps we should
    be recommending products people might need. Items such as USB enabled battery
    packs for keeping phones charged, candles, flashlights, water purifiers, and the
    like. By understanding the context in which decisions are being made, we can conduct
    better science.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 但要想成为杰出的人，需要更多的背景信息来解释人们为什么会表现出这样的行为。当新闻报道暗示一场大西洋飓风正在接近佛罗里达海岸线，并且可能在36小时内到达海岸时，也许我们应该推荐人们可能需要的产品。比如USB充电宝、蜡烛、手电筒、净水器等物品。通过了解决策背后的背景，我们可以进行更好的科学研究。
- en: Therefore, whilst this book certainly contains useful code and, in many cases,
    unique implementations, it further dives deep into the techniques and skills required
    to truly master data science; some of which are often overlooked or not considered
    at all. Drawing on many years of commercial experience, the authors have leveraged
    their extensive knowledge to bring the real, and exciting world of data science
    to life.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，尽管本书确实包含有用的代码，而且在许多情况下还包含独特的实现，但它进一步深入探讨了真正掌握数据科学所需的技术和技能；其中一些经常被忽视或根本没有被考虑。作者们凭借多年的商业经验，利用他们丰富的知识，将数据科学的真实而令人兴奋的世界呈现出来。
- en: What this book covers
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书涵盖的内容
- en: '[Chapter 1](ch01.xhtml "Chapter 1.  The Big Data Science Ecosystem"), *The
    Big Data Science Ecosystem*, this chapter is an introduction to an approach and
    accompanying ecosystem for achieving success with data at scale. It focuses on
    the data science tools and technologies that will be used in later chapters as
    well as introducing the environment and how to configure it appropriately. Additionally
    it explains some of the non-functional considerations relevant to the overall
    data architecture and long-term success.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[第1章](ch01.xhtml "第1章. 大数据科学生态系统"), *大数据科学生态系统*，本章介绍了一种在规模上实现数据成功的方法和相关生态系统。它侧重于数据科学工具和技术，这些工具和技术将在后面的章节中使用，并介绍了环境以及如何适当地配置它。此外，它解释了一些与整体数据架构和长期成功相关的非功能性考虑。'
- en: '[Chapter 2](ch02.xhtml "Chapter 2. Data Acquisition"), *Data Acquisition*,
    as a data scientist, one of the most important tasks is to accurately load data
    into a data science platform. Rather than having uncontrolled, ad hoc processes,
    this chapter explains how a general data ingestion pipeline in Spark can be constructed
    that serves as a reusable component across many feeds of input data.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '[第2章](ch02.xhtml "第2章. 数据获取"), *数据获取*，作为数据科学家，最重要的任务之一是将数据准确地加载到数据科学平台中。本章解释了如何构建Spark中的通用数据摄入管道，这个管道可以作为可重用的组件，服务于许多输入数据源。'
- en: '[Chapter 3](ch03.xhtml "Chapter 3. Input Formats and Schema"), *Input Formats
    and Schema*, this chapter demonstrates how to load data from its raw format onto
    different schemas, therefore enabling a variety of different kinds of downstream
    analytics to be run over the same data. With this in mind, we will look at the
    traditionally well-understood area of data schemas. We will cover key areas of
    traditional database modeling and explain how some of these cornerstone principles
    are still applicable to Spark today. In addition, whilst honing our Spark skills
    we will analyze the GDELT data model and show how to store this large dataset
    in an efficient and scalable manner.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 第3章，“输入格式和模式”，本章演示了如何从原始格式加载数据到不同的模式，从而使得可以对相同数据运行各种不同类型的下游分析。考虑到这一点，我们将研究传统上理解的数据模式领域。我们将涵盖传统数据库建模的关键领域，并解释其中一些基石原则如何今天仍然适用于Spark。此外，当我们磨练我们的Spark技能时，我们将分析GDELT数据模型，并展示如何以高效和可扩展的方式存储这个大型数据集。
- en: '[Chapter 4](ch04.xhtml "Chapter 4. Exploratory Data Analysis"), *Exploratory
    Data Analysis*, a common misconception is that an EDA is only for discovering
    the statistical properties of a dataset and providing insights about how it can
    be exploited. In practice, this isn’t the full story. A full EDA will extend that
    idea, and include a detailed assessment of the “feasibility of using this Data
    Feed in production.” It requires us to also understand how we would specify a
    production grade data loading routine for this dataset, one that might potentially
    run in a “lights out mode” for many years. This chapter offers a rapid method
    for doing Data Quality assessment using a “data profiling” technique to accelerate
    the process.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 第4章，“探索性数据分析”，一个常见的误解是，EDA仅用于发现数据集的统计属性，并提供关于如何利用它的见解。实际上，这并不是全部。完整的EDA将扩展这个想法，并包括对“在生产中使用这个数据源的可行性”的详细评估。这要求我们也要了解如何为这个数据集指定一个生产级的数据加载程序，这个程序可能会在很多年内以“无人值守模式”运行。本章提供了一种使用“数据概要分析”技术加速数据质量评估的快速方法。
- en: '[Chapter 5](ch05.xhtml "Chapter 5. Spark for Geographic Analysis"), *Spark
    for Geographic Analysis*, geographic processing is a powerful new use case for
    Spark, and this chapter demonstrates how to get started. The aim of this chapter
    is to explain how Data Scientists can process geographic data, using Spark, to
    produce powerful map based views of very large datasets. We demonstrate how to
    process spatio-temporal datasets easily via Spark integrations with Geomesa, which
    helps turn Spark into a sophisticated geographic processing engine. The chapter
    later leverages this spatio-temporal data to apply machine learning with a view
    to predicting oil prices.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 第5章，“地理分析的Spark”，地理处理是Spark的一个强大的新用例，本章演示了如何入门。本章的目的是解释数据科学家如何使用Spark处理地理数据，以生成基于地图的大型数据集的强大视图。我们演示了如何通过Spark与Geomesa集成轻松处理时空数据，从而帮助将Spark转变为一个复杂的地理处理引擎。本章后来利用这些时空数据应用机器学习，以预测石油价格。
- en: '[Chapter 6](ch06.xhtml "Chapter 6. Scraping Link-Based External Data"), *Scraping
    Link-Based External Data*, this chapter aims to explain a common pattern for enhancing
    local data with external content found at URLs or over APIs, such as GDELT and
    Twitter. We offer a tutorial using the GDELT news index service as a source of
    news URLS, demonstrating how to build a web scale News Scanner that scrapes global
    breaking news of interest from the internet. We further explain how to use the
    specialist web-scraping component in a way that overcomes the challenges of scale,
    followed by the summary of this chapter.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 第6章，“抓取基于链接的外部数据”，本章旨在解释一种增强本地数据的常见模式，即在URL或API上找到的外部内容，如GDELT和Twitter。我们提供了一个使用GDELT新闻索引服务作为新闻URL来源的教程，演示了如何构建一个从互联网上抓取感兴趣的全球突发新闻的Web规模新闻扫描器。我们进一步解释了如何使用专门的网络抓取组件来克服规模的挑战，随后总结了本章。
- en: '[Chapter 7](ch07.xhtml "Chapter 7. Building Communities"), *Building Communities*,
    this chapter aims to address a common use case in data science and big data. With
    more and more people interacting together, communicating, exchanging information,
    or simply sharing a common interest in different topics, the entire world can
    be represented as a Graph. A data scientist must be able to detect communities,
    find influencers / top contributors, and detect possible anomalies.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 第7章，“构建社区”，本章旨在解决数据科学和大数据中的一个常见用例。随着越来越多的人互动，交流信息，或者简单地分享不同主题的共同兴趣，整个世界可以被表示为一个图。数据科学家必须能够检测社区，找到影响者/顶级贡献者，并检测可能的异常。
- en: '[Chapter 8](ch08.xhtml "Chapter 8. Building a Recommendation System"), *Building
    a Recommendation System*, if one were to choose an algorithm to showcase data
    science to the public, a recommendation system would certainly be in the frame.
    Today, recommendation systems are everywhere; the reason for their popularity
    is down to their versatility, usefulness and broad applicability. In this chapter,
    we will demonstrate how to recommend music content using raw audio signals.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 第8章，“构建推荐系统”，如果要选择一个算法来向公众展示数据科学，推荐系统肯定会成为其中之一。今天，推荐系统随处可见；它们之所以如此受欢迎，是因为它们的多功能性、实用性和广泛适用性。在本章中，我们将演示如何使用原始音频信号推荐音乐内容。
- en: '[Chapter 9](ch09.xhtml "Chapter 9.  News Dictionary and Real-Time Tagging System"),
    *News Dictionary and Real-Time Tagging System*, while a hierarchical data warehouse
    stores data in files of folders, a typical Hadoop based system relies on a flat
    architecture to store your data. Without a proper data governance or a clear understanding
    of what your data is all about, there is an undeniable chance of turning data
    lakes into swamps, where an interesting dataset such as GDELT would be nothing
    more than a folder containing a vast amount of unstructured text files. In this
    chapter, we will be describing an innovative way of labeling incoming GDELT data
    in a non-supervised way and in near real time.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[第9章](ch09.xhtml "第9章. 新闻词典和实时标记系统")，“新闻词典和实时标记系统”，虽然分层数据仓库将数据存储在文件夹中，但典型的基于Hadoop的系统依赖于扁平架构来存储数据。如果没有适当的数据治理或对数据的清晰理解，就有不可否认的可能性将数据湖变成沼泽，其中一个有趣的数据集，如GDELT，将不过是一个包含大量非结构化文本文件的文件夹。在本章中，我们将描述一种创新的方式，以非监督的方式对即将到来的GDELT数据进行标记，并且几乎是实时的。'
- en: '[Chapter 10](ch10.xhtml "Chapter 10. Story De-duplication and Mutation"), *Story
    De-duplication and Mutation*, in this chapter, we de-duplicate and index the GDELT
    database into stories, before tracking stories over time and understanding the
    links between them, how they may mutate and if they could lead to any subsequent
    events in the near future. Core to this chapter is the concept of Simhash to detect
    near duplicates and building vectors to reduce dimensionality using Random Indexing.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '[第10章](ch10.xhtml "第10章. 故事去重和变异")，“故事去重和变异”，在本章中，我们对GDELT数据库进行去重和索引，然后跟踪故事的变化，了解它们之间的联系，它们如何变异，以及它们是否可能导致不久的将来发生的事件。本章的核心是使用Simhash检测近似重复项，并使用随机索引构建向量以降低维度。'
- en: '[Chapter 11](ch11.xhtml "Chapter 11. Anomaly Detection on Sentiment Analysis"),
    *Anomaly Detection and Sentiment Analysis*, perhaps the most notable occurrence
    of the year 2016 was the tense US presidential election and its eventual outcome:
    the election of President Donald Trump, a campaign that will long be remembered;
    not least for its unprecedented use of social media and the stirring up of passion
    among its users, most of whom made their feelings known through the use of hashtags.
    In this chapter, instead of trying to predict the outcome itself, we will aim
    to detect abnormal tweets during the US election using a real-time Twitter feed.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '[第11章](ch11.xhtml "第11章. 情感分析异常检测")，“异常检测和情感分析”，也许2016年最引人注目的事件是紧张的美国总统选举及其最终结果：唐纳德·特朗普当选总统，这场竞选将长久被人们铭记；尤其是因为其对社交媒体的空前利用以及激起用户激情的方式，其中大多数人通过使用标签表达了自己的情感。在本章中，我们将尝试使用实时Twitter信息流检测美国选举期间的异常推文，而不是试图预测选举结果本身。'
- en: '[Chapter 12](ch12.xhtml "Chapter 12. TrendCalculus"), *TrendCalculus*, long
    before the concept of “what’s trending” became a popular topic of study by data
    scientists, there was an older one that is still not well served by data science;
    it is that of Trends. Presently, the analysis of trends, if it can be called that,
    is primarily carried out by people “eyeballing” time series charts and offering
    interpretations. But what is it that people’s eyes are doing? This chapter describes
    an implementation in Apache Spark of a new algorithm for studying trends numerically:
    TrendCalculus.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '[第12章](ch12.xhtml "第12章. 趋势演算")，“趋势演算”，在“趋势”成为数据科学家研究的热门话题之前，早有一个更古老的概念，至今仍未得到数据科学的充分应用；那就是趋势。目前，对趋势的分析，如果可以这样称呼的话，主要是由人们“用眼睛看”时间序列图表并进行解释。但人们的眼睛究竟在做什么？本章描述了Apache
    Spark中用于数值研究趋势的新算法：趋势演算。'
- en: '[Chapter 13](ch13.xhtml "Chapter 13. Secure Data"), *Secure Data*, throughout
    this book we visit many areas of data science, often straying into those that
    are not traditionally associated with a data scientist’s core working knowledge.
    In this chapter we will visit another of those often overlooked fields, Secure
    Data; more specifically, how to protect your data and analytic results at all
    stages of the data life cycle. Core to this chapter is the construction of a commercial
    grade encryption codec for Spark.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '[第13章](ch13.xhtml "第13章. 安全数据")，“安全数据”，在本书中，我们涉及了许多数据科学领域，经常涉足那些传统上与数据科学家的核心工作知识不太相关的领域。在本章中，我们将讨论另一个经常被忽视的领域，安全数据；更具体地说，如何在数据生命周期的各个阶段保护您的数据和分析结果。本章的核心是构建一个用于Spark的商业级加密编解码器。'
- en: '[Chapter 14](ch14.xhtml "Chapter 14. Scalable Algorithms"), *Scalable Algorithms*,
    in this chapter we learn about why sometimes even basic algorithms, despite working
    at small scale, will often fail in “big data”. We’ll see how to avoid issues when
    writing Spark jobs that run over massive Datasets and will learn about the structure
    of algorithms and how to write custom data science analytics that scale over petabytes
    of data. The chapter features areas such as: parallelization strategies, caching,
    shuffle strategies, garbage collection optimization and probabilistic models;
    explaining how these can help you to get the most out of the Spark paradigm.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '[第14章](ch14.xhtml "第14章. 可扩展算法")，“可扩展算法”，在本章中，我们将了解为什么有时即使基本算法在小规模下运行良好，但在“大数据”中却经常失败。我们将看到如何避免在编写运行在大规模数据集上的Spark作业时出现问题，并了解算法的结构以及如何编写能够在数据量达到PB级别时扩展的自定义数据科学分析。本章涵盖了诸如：并行化策略、缓存、洗牌策略、垃圾回收优化和概率模型等领域；解释了这些如何帮助您充分利用Spark范式。'
- en: What you need for this book
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 阅读本书需要什么
- en: Spark 2.0 is used throughout the book along with Scala 2.11, Maven and Hadoop.
    This is the basic environment required, there are many other technologies used
    which are introduced in the relevant chapters.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中使用了Spark 2.0以及Scala 2.11、Maven和Hadoop。这是基本的环境要求，还有许多其他在相关章节中介绍的技术。
- en: Who this book is for
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 这本书是为谁准备的
- en: We presume that the data scientists reading this book are knowledgeable about
    data science, common machine learning methods, and popular data science tools,
    and have in the course of their work run proof of concept studies, and built prototypes.
    We offer a book that introduces advanced techniques and methods for building data
    science solutions to this audience, showing them how to construct commercial grade
    data products.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们假设阅读本书的数据科学家对数据科学、常见的机器学习方法和流行的数据科学工具有所了解，并且在工作中进行了概念验证研究并构建了原型。我们为这个受众提供了一本介绍高级技术和方法来构建数据科学解决方案的书籍，向他们展示如何构建商业级数据产品。
- en: Conventions
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 约定
- en: In this book, you will find a number of text styles that distinguish between
    different kinds of information. Here are some examples of these styles and an
    explanation of their meaning.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，您会发现一些文本样式，用于区分不同类型的信息。以下是一些这些样式的示例及其含义的解释。
- en: 'Code words in text, database table names, folder names, filenames, file extensions,
    pathnames, dummy URLs, user input, and Twitter handles are shown as follows: "The
    next lines of code read the link and assign it to the to the `BeautifulSoup` function."'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 文本中的代码单词、数据库表名、文件夹名、文件名、文件扩展名、路径名、虚拟URL、用户输入和Twitter句柄显示如下："下一行代码读取链接并将其分配给`BeautifulSoup`函数。"
- en: 'A block of code is set as follows:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 代码块设置如下：
- en: '[PRE0]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'When we wish to draw your attention to a particular part of a code block, the
    relevant lines or items are set in bold:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们希望引起您对代码块的特定部分的注意时，相关行或项目将以粗体显示：
- en: '[PRE1]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Any command-line input or output is written as follows:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 任何命令行输入或输出都以以下方式编写：
- en: '[PRE2]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**New terms** and **important words** are shown in bold. Words that you see
    on the screen, for example, in menus or dialog boxes, appear in the text like
    this: "In order to download new modules, we will go to **Files** | **Settings**
    | **Project Name** | **Project Interpreter**."'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**新术语**和**重要单词**以粗体显示。屏幕上看到的单词，例如菜单或对话框中的单词，会以这样的方式出现在文本中："为了下载新模块，我们将转到**文件**
    | **设置** | **项目名称** | **项目解释器**。"'
- en: Note
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Warnings or important notes appear in a box like this.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 警告或重要说明会出现在这样的框中。
- en: Tip
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: Tips and tricks appear like this.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 提示和技巧会出现在这样。
- en: Reader feedback
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 读者反馈
- en: Feedback from our readers is always welcome. Let us know what you think about
    this book-what you liked or disliked. Reader feedback is important for us as it
    helps us develop titles that you will really get the most out of. To send us general
    feedback, simply e-mail feedback@packtpub.com, and mention the book's title in
    the subject of your message. If there is a topic that you have expertise in and
    you are interested in either writing or contributing to a book, see our author
    guide at [www.packtpub.com/authors](http://www.packtpub.com/authors).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们始终欢迎读者的反馈。请告诉我们您对本书的看法-您喜欢或不喜欢的内容。读者的反馈对我们很重要，因为它可以帮助我们开发出您真正喜欢的标题。要发送一般反馈，只需发送电子邮件至feedback@packtpub.com，并在主题中提及书名。如果您在某个专题上有专业知识，并且有兴趣撰写或为书籍做出贡献，请参阅我们的作者指南[www.packtpub.com/authors](http://www.packtpub.com/authors)。
- en: Customer support
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 客户支持
- en: Now that you are the proud owner of a Packt book, we have a number of things
    to help you to get the most from your purchase.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您是Packt书籍的自豪所有者，我们有很多东西可以帮助您充分利用您的购买。
- en: Downloading the example code
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 下载示例代码
- en: You can download the example code files for this book from your account at [http://www.packtpub.com](http://www.packtpub.com).
    If you purchased this book elsewhere, you can visit  [http://www.packtpub.com/support](http://www.packtpub.com/support)
    and register to have the files e-mailed directly to you.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从[http://www.packtpub.com](http://www.packtpub.com)的帐户中下载本书的示例代码文件。如果您在其他地方购买了这本书，您可以访问[http://www.packtpub.com/support](http://www.packtpub.com/support)并注册，以便文件直接通过电子邮件发送给您。
- en: 'You can download the code files by following these steps:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以按照以下步骤下载代码文件：
- en: Log in or register to our website using your e-mail address and password.
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用您的电子邮件地址和密码登录或注册到我们的网站。
- en: Hover the mouse pointer on the **SUPPORT** tab at the top.
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将鼠标指针悬停在顶部的**支持**选项卡上。
- en: Click on **Code Downloads & Errata**.
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**代码下载和勘误**。
- en: Enter the name of the book in the **Search** box.
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**搜索**框中输入书名。
- en: Select the book for which you're looking to download the code files.
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择要下载代码文件的书籍。
- en: Choose from the drop-down menu where you purchased this book from.
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从下拉菜单中选择您购买本书的地点。
- en: Click on **Code Download**.
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**代码下载**。
- en: 'Once the file is downloaded, please make sure that you unzip or extract the
    folder using the latest version of:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 下载文件后，请确保使用最新版本的以下软件解压或提取文件夹：
- en: WinRAR / 7-Zip for Windows
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Windows上的WinRAR / 7-Zip
- en: Zipeg / iZip / UnRarX for Mac
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mac上的Zipeg / iZip / UnRarX
- en: 7-Zip / PeaZip for Linux
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Linux上的7-Zip / PeaZip
- en: The code bundle for the book is also hosted on GitHub at [https://github.com/PacktPublishing/Mastering-Spark-for-Data-Science](https://github.com/PacktPublishing/Mastering-Spark-for-Data-Science).
    We also have other code bundles from our rich catalog of books and videos available
    at [https://github.com/PacktPublishing/](https://github.com/PacktPublishing/).
    Check them out!
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 该书的代码包也托管在GitHub上，网址为[https://github.com/PacktPublishing/Mastering-Spark-for-Data-Science](https://github.com/PacktPublishing/Mastering-Spark-for-Data-Science)。我们还有其他代码包，来自我们丰富的书籍和视频目录，可在[https://github.com/PacktPublishing/](https://github.com/PacktPublishing/)上找到。快去看看吧！
- en: Downloading the color images of this book
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 下载本书的彩色图像
- en: We also provide you with a PDF file that has color images of the screenshots/diagrams
    used in this book. The color images will help you better understand the changes
    in the output. You can download this file from [https://www.packtpub.com/sites/default/files/downloads/MasteringSparkforDataScience_ColorImages.pdf](https://www.packtpub.com/sites/default/files/downloads/MasteringSparkforDataScience_ColorImages.pdf).
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还为您提供了一个PDF文件，其中包含本书中使用的屏幕截图/图表的彩色图像。彩色图像将帮助您更好地理解输出中的变化。您可以从[https://www.packtpub.com/sites/default/files/downloads/MasteringSparkforDataScience_ColorImages.pdf](https://www.packtpub.com/sites/default/files/downloads/MasteringSparkforDataScience_ColorImages.pdf)下载此文件。
- en: Errata
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 勘误
- en: Although we have taken every care to ensure the accuracy of our content, mistakes
    do happen. If you find a mistake in one of our books-maybe a mistake in the text
    or the code-we would be grateful if you could report this to us. By doing so,
    you can save other readers from frustration and help us improve subsequent versions
    of this book. If you find any errata, please report them by visiting [http://www.packtpub.com/submit-errata](http://www.packtpub.com/submit-errata),
    selecting your book, clicking on the **Errata Submission Form** link, and entering
    the details of your errata. Once your errata are verified, your submission will
    be accepted and the errata will be uploaded to our website or added to any list
    of existing errata under the Errata section of that title.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们已经尽一切努力确保内容的准确性，但错误还是会发生。如果您在我们的书籍中发现错误，也许是文本或代码中的错误，我们将不胜感激地希望您能向我们报告。通过这样做，您可以帮助其他读者避免挫折，并帮助我们改进本书的后续版本。如果您发现任何勘误，请访问[http://www.packtpub.com/submit-errata](http://www.packtpub.com/submit-errata)，选择您的书籍，点击**勘误提交表**链接，并输入您的勘误详情。一旦您的勘误经过验证，您的提交将被接受，并且勘误将被上传到我们的网站或添加到该书籍的勘误部分下的任何现有勘误列表中。
- en: To view the previously submitted errata, go to [https://www.packtpub.com/books/content/support](https://www.packtpub.com/books/content/support)
    and enter the name of the book in the search field. The required information will
    appear under the **Errata** section.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看先前提交的勘误，请访问[https://www.packtpub.com/books/content/support](https://www.packtpub.com/books/content/support)
    并在搜索框中输入书名。所需信息将出现在**勘误**部分下。
- en: Piracy
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 盗版
- en: Piracy of copyrighted material on the Internet is an ongoing problem across
    all media. At Packt, we take the protection of our copyright and licenses very
    seriously. If you come across any illegal copies of our works in any form on the
    Internet, please provide us with the location address or website name immediately
    so that we can pursue a remedy.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 互联网上侵犯版权材料的盗版是所有媒体的持续问题。在Packt，我们非常重视保护我们的版权和许可。如果您在互联网上以任何形式发现我们作品的非法副本，请立即向我们提供位置地址或网站名称，以便我们采取补救措施。
- en: Please contact us at copyright@packtpub.com with a link to the suspected pirated
    material.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 请通过copyright@packtpub.com与我们联系，并附上涉嫌盗版材料的链接。
- en: We appreciate your help in protecting our authors and our ability to bring you
    valuable content.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们感谢您帮助保护我们的作者和我们提供有价值内容的能力。
- en: Questions
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: If you have a problem with any aspect of this book, you can contact us at questions@packtpub.com,
    and we will do our best to address the problem.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您对本书的任何方面有问题，可以通过questions@packtpub.com与我们联系，我们将尽力解决问题。
