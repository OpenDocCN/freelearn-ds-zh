- en: '5'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '5'
- en: Matrices and Equations
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵与方程
- en: So, matrices are not just tables of numbers but linear transformations; we have
    spent a lengthy chapter discovering this relationship.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，矩阵不仅仅是数字的表格，而是线性变换；我们已经花费了长篇幅的章节来探索这一关系。
- en: Now, I want us to circle back to the good old tables of numbers once more, but
    representing systems of linear equations this time. Why? Simple. Because solving
    linear equations is the motivator behind key theoretical and technical innovations.
    In the previous chapter, we talked about inverse matrices but didn’t compute one
    in practice. With what we’re about to learn, we will be able to not only compute
    inverse matrices but do so blazing fast.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我希望我们再次回到那些老旧的数字表格，但这次是代表线性方程组。为什么？很简单。因为解线性方程是推动关键理论和技术创新的动力。在上一章中，我们谈到了逆矩阵，但没有实际计算它。通过我们即将学习的内容，我们不仅能够计算逆矩阵，还能迅速地完成这个过程。
- en: Let’s get to work!
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 开始工作吧！
- en: 5.1 Linear equations
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.1 线性方程
- en: In practice, we can translate several problems into linear equations. For example,
    a cash dispenser has $900 in $20 and $50 bills. We know that there are twice as
    many $20 bills than $50\. The question is, how many of each bill does the machine
    have?
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，我们可以将多个问题转化为线性方程。例如，一个现金分配机有$900，其中包含$20和$50钞票。我们知道，$20钞票的数量是$50钞票的两倍。问题是，这台机器分别有多少张$20和$50钞票？
- en: If we denote the number of $20 bills by x[1] and the number of $50 bills by
    x[2], we obtain the equations
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将$20钞票的数量记作x[1]，$50钞票的数量记作x[2]，那么我们得到以下方程：
- en: '![ x1 − 2x2 = 0 20x1 + 50x2 = 900\. ](img/file502.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![ x1 − 2x2 = 0 20x1 + 50x2 = 900\. ](img/file502.png)'
- en: For two variables, as we have now, these are easily solvable by expressing one
    in terms of the other. Here, the first equation would imply x[1] = 2x[2]. Plugging
    it back into the second equation, we obtain 90x[2] = 900, which gives x[2] = 10\.
    Coming full circle, we can substitute this into x[1] = 2x[2], yielding the solutions
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 对于现在我们所拥有的两个变量，这些方程可以通过将其中一个表示为另一个的形式轻松求解。在这里，第一个方程意味着x[1] = 2x[2]。将其代入第二个方程，我们得到90x[2]
    = 900，从而得出x[2] = 10。然后将其代入x[1] = 2x[2]，最终得到解：
- en: '![x = 20 1 x2 = 10\. ](img/file503.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![x = 20 1 x2 = 10\. ](img/file503.png)'
- en: However, for thousands of variables like in real applications, we need a bit
    more craft. This is where linear algebra comes in. By introducing the matrix and
    vectors
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，对于像实际应用中那样有成千上万的变量，我们需要更多的技巧。这就是线性代数的用武之地。通过引入矩阵和向量
- en: '![ ⌊ ⌋ ⌊ ⌋ ⌊ ⌋ A = ⌈ 1 − 2⌉ , x = ⌈x1 ⌉, b = ⌈ 0 ⌉ , 20 50 x2 900 ](img/file504.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![ ⌊ ⌋ ⌊ ⌋ ⌊ ⌋ A = ⌈ 1 − 2⌉ , x = ⌈x1 ⌉, b = ⌈ 0 ⌉ , 20 50 x2 900 ](img/file504.png)'
- en: 'the equation can be written in the form Ax = b. That is, in terms of linear
    transformations, we can reformulate the question: which vector x is mapped to
    b by the transformation A? This question is central in linear algebra, and we’ll
    dedicate this section to solving it.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这个方程可以写成Ax = b的形式。也就是说，从线性变换的角度来看，我们可以重新表述问题：哪个向量x通过变换A映射到b？这个问题在线性代数中非常重要，我们将专门用这一部分来解决它。
- en: 5.1.1 Gaussian elimination
  id: totrans-14
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1.1 高斯消元法
- en: 'Let’s revisit our earlier example:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下之前的例子：
- en: '![ x1 − 2x2 = 0 20x1 + 50x2 = 900\. ](img/file505.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![ x1 − 2x2 = 0 20x1 + 50x2 = 900\. ](img/file505.png)'
- en: We can use the first equation x[1] − 2x[2] = 0 to get rid of the term x[1] in
    the second equation 20x[1] + 50x[2] = 900\. We can do this by multiplying it by
    20 and subtracting it from the second row, obtaining 90x[2] = 900, from which
    x[2] = 10 is obtained. This can be substituted back into the first row, yielding
    x[1] = 20.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用第一个方程x[1] − 2x[2] = 0来消去第二个方程20x[1] + 50x[2] = 900中的x[1]项。我们可以通过将其乘以20并从第二行中减去来做到这一点，得到90x[2]
    = 900，从而得出x[2] = 10。然后可以将其代入第一行，得到x[1] = 20。
- en: 'What about the general case? Would this work for a general A ∈ℝ^(n×n) and x,b
    ∈ℝ^n? Absolutely. So far, we have used two rules for manipulating the equations
    in a linear system:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 那么一般情况呢？对于一般的A ∈ℝ^(n×n) 和 x,b ∈ℝ^n，这是否有效？绝对有效。到目前为止，我们已经使用了两条规则来操作线性系统中的方程：
- en: Multiplying an equation with a nonzero scalar won’t change the solutions.
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将方程乘以一个非零的标量不会改变解。
- en: Adding a scalar multiple of one row to another won’t change the solutions either.
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将一行的标量倍数加到另一行上也不会改变解。
- en: Earlier, we applied these repeatedly to eliminate variables progressively in
    our simple example. We can easily do the same for n variables! First, let’s see
    what we are talking about!
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 之前，我们反复应用这些方法来逐步消去变量。对于n个变量，我们也能轻松地做到！首先，让我们看看我们在谈论什么！
- en: Definition 21\. (System of linear equations)
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 定义21.（线性方程组）
- en: Let A ∈ ℝ^(n×n) be a matrix and b ∈ ℝ^n be a vector. The collection of equations
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 设 A ∈ ℝ^(n×n) 是一个矩阵，b ∈ ℝ^n 是一个向量。方程组的集合为
- en: '![Equation image](img/file506.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![Equation image](img/file506.png)'
- en: (5.1)
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: (5.1)
- en: are called the system of linear equations determined by A and b.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 称为由 A 和 b 决定的线性方程组。
- en: A system of linear equations is often written in the short form Ax = b, where
    A is called its coefficient matrix. If the vector x satisfies Ax = b, it is called
    a solution.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 线性方程组通常写成简短的形式 Ax = b，其中 A 称为系数矩阵。如果向量 x 满足 Ax = b，它就叫做解。
- en: Speaking of solutions, are there even any, and if so, how can we find them?
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 说到解，是否存在解，如果存在，我们如何找到它们呢？
- en: If a[11] is nonzero, we can multiply the first equation of ([5.1](ch011.xhtml#x1-88005r21))
    by ![aak111](img/file507.png) and subtract it from the k-th equation.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 a[11] 不为零，我们可以将 ([5.1](ch011.xhtml#x1-88005r21)) 中的第一个方程乘以 ![aak111](img/file507.png)，并从第
    k 个方程中减去它。
- en: This way, x[1] will be eliminated from all but the first row, obtaining
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，x[1] 将从除第一行以外的所有行中消去，得到
- en: '![Equation image](img/file508.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![Equation image](img/file508.png)'
- en: (5.2)
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: (5.2)
- en: To clear up this notation a bit, let’s denote the new coefficients with a[ij]^((1))
    and b[i]^((1)). So, we have
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更清楚地表示这个符号，我们将新的系数表示为 a[ij]^((1)) 和 b[i]^((1))。所以，我们得到
- en: '![L(U,V ) = {f : U → V | f is linear}](img/file509.png)(5.3)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![L(U,V ) = {f : U → V | f is linear}](img/file509.png)(5.3)'
- en: We can repeat the above process and use the second equation to get rid of the
    x[2] variable in the third equation, and so forth.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以重复上述过程，并使用第二个方程消去第三个方程中的 x[2] 变量，以此类推。
- en: 'This can be done n − 1 times in total, ultimately leading to an equation system
    A^((n−1))x = b^((n−1)) where all coefficients below the diagonal of A^((n−1))
    are 0:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 总共可以进行 n − 1 次这样的操作，最终得到一个方程系统 A^((n−1))x = b^((n−1))，其中 A^((n−1)) 的所有对角线以下的系数都是
    0：
- en: '![L(U,V ) = {f : U → V | f is linear}](img/equation_(8).png)(5.4)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![L(U,V ) = {f : U → V | f is linear}](img/equation_(8).png)(5.4)'
- en: 'Notice that the k-th elimination step only affects the coefficients from the
    (k + 1)-th row. Now we can work backward: the last equation a[nn]^((n−1))x[n]
    = b[n]^((n−1)) can be used to find x[n]. This can be substituted to the (n − 1)-th
    equation, yielding x[n−1]. Continuing like this, we can eventually find all x[1],…,x[n],
    obtaining a solution for our linear system.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，第 k 步的消元仅影响从第 (k + 1) 行开始的系数。现在我们可以倒退操作：最后一个方程 a[nn]^((n−1))x[n] = b[n]^((n−1))
    可用于求解 x[n]。将其代入 (n − 1) 阶方程中，得到 x[n−1]。以此类推，我们最终可以求出所有的 x[1],…,x[n]，从而获得线性方程组的解。
- en: This process is called Gaussian elimination, and it’s kind of a big deal. It
    is not only useful for solving linear equations, but it can also be used to calculate
    determinants, factor matrices into the product of simpler ones, and much more.
    We’ll talk about all of this in detail, but let’s focus on equations a little
    more.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程叫做高斯消元法，它非常重要。它不仅仅用于解线性方程，还可以用来计算行列式、将矩阵分解成简单矩阵的乘积等等。我们将详细讨论所有这些内容，但现在先多关注方程吧。
- en: Unfortunately, not all linear equations can be solved. For instance, consider
    the system
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，并非所有线性方程都能解。例如，考虑以下系统
- en: '![ x1 + x2 = 1 2x1 + 2x2 = − 1\. ](img/file511.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![ x1 + x2 = 1 2x1 + 2x2 = − 1\. ](img/file511.png)'
- en: Subtracting the first equation from the second one yields
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 从第二个方程中减去第一个方程得到
- en: '![x1 + x2 = 1 x1 + x2 = − 2 ](img/file512.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![x1 + x2 = 1 x1 + x2 = − 2 ](img/file512.png)'
- en: in the very first step, making it apparent that the equation has no solutions.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一步中，明确表明该方程无解。
- en: Before we turn to the technical details, let’s see a simple example of how Gaussian
    elimination is done in practice!
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们进入技术细节之前，让我们看看高斯消元法如何在实际中应用的一个简单例子！
- en: 5.1.2 Gaussian elimination by hand
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1.2 手动高斯消元法
- en: To build a deeper understanding of Gaussian elimination, let’s consider the
    simple equation system
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更深入地理解高斯消元法，让我们考虑这个简单的方程系统
- en: '![ x + 0x − 3x = 6 1 2 3 2x1 + 1x2 + 5x3 = 2 − 2x1 − 3x2 + 8x3 = 2\. ](img/file513.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![ x + 0x − 3x = 6 1 2 3 2x1 + 1x2 + 5x3 = 2 − 2x1 − 3x2 + 8x3 = 2\. ](img/file513.png)'
- en: To keep track of our progress (and, since we are lazy, to avoid writing too
    much), we record the intermediate results as
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 为了跟踪我们的进展（并且因为我们懒得写太多），我们记录下中间结果：
- en: '![ | 1 0 − 3|6 2 1 5 |2 | − 2 − 3 8 |2 ](img/file514.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![ | 1 0 − 3|6 2 1 5 |2 | − 2 − 3 8 |2 ](img/file514.png)'
- en: with the coefficient matrix A on the left side and b on the other. To get a
    good grip on the method, I encourage you to follow along and do the calculations
    yourself by hand.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 系数矩阵 A 在左边，b 在右边。为了更好地掌握该方法，我建议你亲自动手计算，跟着步骤做。
- en: After eliminating the first variable from the second and third equations, we
    have
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在从第二个和第三个方程中消去第一个变量之后，我们得到
- en: '![ | 1 0 − 3 | 6 0 1 11 |− 10 | , 0 − 3 2 | 14 ](img/file515.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![ | 1 0 − 3 | 6 0 1 11 |− 10 | , 0 − 3 2 | 14 ](img/file515.png)'
- en: while the final step yields
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 最终步骤的结果是
- en: '![ | 1 0 − 3| 6 0 1 11 |− 10 | . 0 0 35 |− 16 ](img/file516.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![ | 1 0 − 3| 6 0 1 11 |− 10 | . 0 0 35 |− 16 ](img/file516.png)'
- en: From this form, we can unravel the solutions one by one.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个形式中，我们可以逐个解开方程的解。
- en: In the 21st century, your chances of having to solve a linear equation by hand
    are close to 0\. (If you are reading this book during the 22nd century or later,
    I am incredibly honored and surprised at the same time. Or, at least, I would
    be if I were still alive.) Still, understanding the general principles behind
    solving linear equations can take you very far.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在21世纪，手动解线性方程的机会几乎为0。（如果你是在22世纪或更晚的时代阅读这本书，我同时感到无比荣幸和惊讶。或者，如果我还活着，我肯定会这么感受。）不过，理解解决线性方程背后的基本原理仍然能带你走得很远。
- en: 5.1.3 When can we perform Gaussian elimination?
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1.3 什么时候可以进行高斯消元？
- en: If you followed the description of Gaussian elimination carefully, you might
    have noticed that the process can break down. We might accidentally divide by
    0 during any elimination step!
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你仔细跟随高斯消元的描述，可能会注意到过程可能会出现问题。在任何消元步骤中，我们可能会不小心除以0！
- en: For instance, after the first step given by equation ([5.2](ch011.xhtml)), the
    new coefficients are of the form
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在方程([5.2](ch011.xhtml))给出的第一步之后，新的系数呈现如下形式
- en: '![(aij − a1j ai1), a11 ](img/file517.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![(aij − a1j ai1), a11 ](img/file517.png)'
- en: which is invalid if a[11] = 0\. In general, the k-th step involves division
    by a[kk]^((k−1)). Since a[kk]^((k−1)) is defined recursively, describing it in
    terms of A is not straightforward. For this, we introduce the concept of principal
    minors, the upper-left subdeterminants of a matrix.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 如果a[11] = 0，则此公式无效。一般来说，步骤k涉及到除以a[kk]^((k−1))。由于a[kk]^((k−1))是递归定义的，因此用A来描述它并不简单。为此，我们引入了主子式的概念，即矩阵的左上方子行列式。
- en: Definition 22\. (Principal minors)
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 定义22\。（主子式）
- en: Let ![ n n×n A = (aij)i,j=1 ∈ ℝ ](img/file518.png) be an arbitrary square matrix.
    Define the submatrix ![Ak ∈ ℝk×k ](img/file519.png) by omitting all rows and columns
    of ![A ](img/file520.png) with indices larger than ![k ](img/file521.png). For
    instance,
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 设 ![ n n×n A = (aij)i,j=1 ∈ ℝ ](img/file518.png) 为任意方阵。定义子矩阵 ![Ak ∈ ℝk×k ](img/file519.png)
    为去掉所有大于 ![k ](img/file521.png) 的A的行列。例如，
- en: '![ ⌊ ⌋ [ ] ⌈a11 a12⌉ A1 = a11 , A2 = a a , 21 22 ](img/file522.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![ ⌊ ⌋ [ ] ⌈a11 a12⌉ A1 = a11 , A2 = a a , 21 22 ](img/file522.png)'
- en: and so on. The k-th principal minor of A, denoted by M[k], is defined by
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 以此类推。A的第k个主子式，记作M[k]，定义为
- en: '![Mk := detAk. ](img/file523.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![Mk := detAk. ](img/file523.png)'
- en: The first and last principal minors are special, as M[1] = a[11] and M[n] =
    detA. With principal minors, we can describe when Gaussian elimination is possible.
    In fact, it turns out that
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个和最后一个主子式是特殊的，因为M[1] = a[11]且M[n] = detA。通过主子式，我们可以描述何时可以进行高斯消元。事实上，结果是
- en: '![ M M a11 = M1, a(21)2 = --2, ...,a(nnn−1)= ---n-- M1 Mn −1 ](img/file524.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![ M M a11 = M1, a(21)2 = --2, ...,a(nnn−1)= ---n-- M1 Mn −1 ](img/file524.png)'
- en: and, in general, a[kk]^((k−1)) = ![-Mk-- Mk−1](img/file525.png).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，a[kk]^((k−1)) = ![-Mk-- Mk−1](img/file525.png)。
- en: To summarize, we can state the following.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，我们可以得出以下结论。
- en: Theorem 30\.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 定理30\。
- en: Let ![ n×n A ∈ ℝ ](img/file526.png) be an arbitrary square matrix, and let ![Mk
    ](img/file527.png) be its ![k ](img/file528.png)-th principal minor. If ![Mk ⁄=
    0 ](img/file529.png) for all ![k = 1,2,...,n − 1 ](img/file530.png), then Gaussian
    elimination can be successfully performed.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 设 ![ n×n A ∈ ℝ ](img/file526.png) 为任意方阵，且 ![Mk ](img/file527.png) 为其第 ![k ](img/file528.png)
    主子式。如果对于所有 ![k = 1,2,...,n − 1 ](img/file530.png)，都有 ![Mk ⁄= 0 ](img/file529.png)，则可以成功进行高斯消元。
- en: As the proof is a bit involved, we are not going to do it here. (The difficult
    step is showing a[kk]^((k−1)) = M[k]∕M[k−1];’ the rest follows immediately.) The
    point is, if none of the principal minors are 0, the algorithm finishes.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 由于证明过程稍显复杂，我们这里不做详细讲解。（困难的步骤是证明a[kk]^((k−1)) = M[k]∕M[k−1]；其余部分立刻可以推导出。）关键是，如果没有主子式为0，算法就完成了。
- en: We can simplify this requirement a bit and describe the Gaussian elimination
    in terms of the determinant, not the principal minors.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以稍微简化这一要求，用行列式而不是主子式来描述高斯消元。
- en: Theorem 31\.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 定理31\。
- en: Let A ∈ℝ^(n×n) be an arbitrary square matrix. If detA≠0, then all principal
    minors are nonzero as well.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 设A ∈ℝ^(n×n) 为任意方阵。如果detA≠0，则所有主子式也都不为零。
- en: As a consequence, if the determinant is nonzero, the Gaussian elimination is
    successful. A simple and nice requirement.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是，如果行列式不为零，则高斯消元成功。一个简单而美妙的要求。
- en: 5.1.4 The time complexity of Gaussian elimination
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1.4 高斯消元的时间复杂度
- en: To get a handle on how fast the Gaussian elimination algorithm executes, let’s
    do a little complexity analysis. As described by ([5.2](ch011.xhtml)), the first
    elimination step involves an addition and a multiplication for each element, except
    for those in the first row. That is 2n(n − 1) operations in total.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 为了掌握高斯消元算法的执行速度，让我们做一点复杂度分析。如（[5.2](ch011.xhtml)）中所描述，第一次消元步骤涉及到每个元素的加法和乘法，除了第一行的元素。也就是说，总共有
    2n(n − 1) 次操作。
- en: The next step is essentially the first step, done on the (n − 1) × (n − 1) matrix
    obtained from A^((1)) by removing its first row and column. This time, we have
    2(n − 1)(n − 2) operations.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步本质上是第一次步骤，在从 A^((1)) 中去掉第一行和第一列后得到的 (n − 1) × (n − 1) 矩阵上执行。这时，我们有 2(n −
    1)(n − 2) 次操作。
- en: Following this train of thought, we quickly get that the total number of operations
    is
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 按照这个思路，我们很快得到总操作次数是
- en: '![∑n 2(n − i+ 1)(n− i), i=1 ](img/file531.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![∑n 2(n − i+ 1)(n− i), i=1 ](img/file531.png)'
- en: which doesn’t look that friendly. Since we are looking for the order of complexity
    instead of an exact number, we can be generous and suppose that at each elimination
    step, we are performing O(n²) operations. So, we have a time complexity of
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 这看起来并不那么友好。由于我们关注的是复杂度的阶数而不是精确的次数，我们可以宽松地假设在每次消元步骤中，我们执行的是 O(n²) 次操作。所以，我们的时间复杂度是
- en: '![∑n O(n2) = O (n3 ), i=1 ](img/file532.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![∑n O(n²) = O(n³), i=1 ](img/file532.png)'
- en: meaning that we need around cn³ operations for Gaussian elimination, where c
    is an arbitrary positive constant. This might seem a lot, but in the beautiful
    domain of algorithms, this is good. O(n³) is polynomial time, and we can have
    much, much worse.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着我们需要大约 cn³ 次操作来进行高斯消元，其中 c 是一个任意的正常数。乍看之下，这似乎很多，但在算法的美妙领域中，这是非常不错的。O(n³)
    是多项式时间，而且我们可以遇到更差的情况。
- en: 5.1.5 When can a system of linear equations be solved?
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1.5 何时可以解线性方程组？
- en: So, we have just seen that for any linear equation
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，我们刚刚看到，对于任何线性方程
- en: '![Ax = b, A ∈ ℝn×n, x, b ∈ ℝn, ](img/file533.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![Ax = b, A ∈ ℝn×n, x, b ∈ ℝn, ](img/file533.png)'
- en: 'Gaussian elimination can be successfully performed if the principal minors
    M[1],…,M[n−1] are nonzero. Notice one caveat about the result: M[n] = detA can
    be zero as well. Turns out, this is quite an important detail.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 如果主子式 M[1],…,M[n−1] 非零，则高斯消元可以成功执行。请注意结果的一个警告：M[n] = detA 也可以为零。事实证明，这是一个非常重要的细节。
- en: 'If you have closely followed the discussion leading up to this point, you will
    see that we missed a crucial point: are there any solutions at all for a given
    linear equation? There are three options:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你一直紧跟到现在的讨论，你会发现我们漏掉了一个关键点：对于给定的线性方程，是否存在解？有三种选择：
- en: There are no solutions.
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 没有解。
- en: There is exactly one solution.
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 只有一个解。
- en: There are multiple solutions.
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有多个解。
- en: 'All of these are relevant to us from a certain perspective, but let’s start
    with the most straightforward one: when do we have exactly one solution? The answer
    is simple: when A is invertible, the solution can be explicitly written as x =
    A^(−1)b. Speaking in terms of linear transformations, we can find a unique vector
    x that is mapped to b. We summarize this idea in the following theorem.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 从某种角度来看，这些都是相关的，但让我们从最直接的一个开始：何时我们有唯一解？答案很简单：当 A 可逆时，解可以明确写成 x = A^(−1)b。从线性变换的角度讲，我们可以找到一个唯一的向量
    x，它被映射到 b。我们在以下定理中总结了这一思想。
- en: Theorem 32\.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 定理 32\。
- en: Let ![A ∈ ℝn ×n ](img/file534.png) be an invertible matrix. Then, for any ![b
    ∈ ℝn ](img/file535.png), the equation ![Ax = b ](img/file536.png) has a unique
    solution that can be written as ![x = A− 1b ](img/file537.png).
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 设 ![A ∈ ℝn ×n ](img/file534.png) 是一个可逆矩阵。那么，对于任何 ![b ∈ ℝn ](img/file535.png)，方程
    ![Ax = b ](img/file536.png) 有一个唯一解，可以写成 ![x = A− 1b ](img/file537.png)。
- en: If A is invertible, then detA is nonzero. Thus, using what we have learned previously,
    Gaussian elimination can be performed, yielding the unique solution. Nice and
    simple.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 A 可逆，那么 detA 不为零。因此，利用我们之前学到的知识，可以执行高斯消元，从而得到唯一解。简单明了。
- en: 'If A is not invertible, the two remaining possibilities are in play: no vector
    is mapped to b, which means there are no solutions, or multiple vectors are mapped
    to b, giving infinite solutions.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 A 不可逆，则剩下的两种可能性是：没有向量被映射到 b，这意味着没有解，或者多个向量被映射到 b，导致无限多个解。
- en: Do you remember how we used the kernel of a linear transformation to describe
    its invertibility in Theorem [20](ch010.xhtml#x1-70003r20)? It turns out that
    kerA can also be used to find all solutions for a linear system.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 你还记得我们在定理 [20](ch010.xhtml#x1-70003r20) 中如何使用线性变换的核来描述其可逆性吗？事实证明，kerA 还可以用来求解线性系统的所有解。
- en: Theorem 33\.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 定理 33\。
- en: Let A ∈ℝ^(n×n) be an arbitrary matrix and let x[0] ∈ℝ^n be a solution to the
    linear equation Ax = b, where b ∈ℝ^n. Then, the set of all solutions can be written
    as
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 设 A ∈ℝ^(n×n) 为一个任意矩阵，且 x[0] ∈ℝ^n 为线性方程组 Ax = b 的一个解，其中 b ∈ℝ^n。则所有解的集合可以写为
- en: '![x0 + kerA := {x0 + y : y ∈ kerA}. ](img/file538.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![x0 + kerA := {x0 + y : y ∈ kerA}. ](img/file538.png)'
- en: 'Proof. We have to show two things: (a) if x ∈x[0] + kerA, then x is a solution;
    and (b) if x is a solution, then x ∈x[0] + kerA.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 证明。我们需要证明两件事：(a) 如果 x ∈ x[0] + kerA，则 x 是解；(b) 如果 x 是解，则 x ∈ x[0] + kerA。
- en: (a) Suppose that x ∈ x[0] + kerA, that is, x = x[0] + y for some y ∈ kerA. Then,
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 假设 x ∈ x[0] + kerA，即 x = x[0] + y，其中 y ∈ kerA。那么，
- en: '![Ax = A(x0 + y) = Ax0 + Ay = b, ◟=◝b◜◞ ◟◝=◜0◞ ](img/file539.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![Ax = A(x0 + y) = Ax0 + Ay = b, ◟=◝b◜◞ ◟◝=◜0◞ ](img/file539.png)'
- en: which shows that x is indeed a solution.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 这表明 x 确实是一个解。
- en: (b) Now let x be an arbitrary solution. We have to show that x −x[0] ∈ kerA.
    This is easy, since
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 现在设 x 为一个任意解。我们需要证明 x −x[0] ∈ kerA。这很容易，因为
- en: '![A (x− x0) = Ax − Ax0 = b − b = 0\. ](img/file540.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![A (x− x0) = Ax − Ax0 = b − b = 0\. ](img/file540.png)'
- en: Thus, (a) and (b) imply that x[0] + kerA is the set of all solutions.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，(a) 和 (b) 表明 x[0] + kerA 是所有解的集合。
- en: In theory, this theorem provides an excellent way of finding all solutions for
    linear equations, generalizing far beyond finite-dimensional vector spaces. (Note
    that the proof goes through verbatim for all vector spaces and linear transformations.)
    For instance, this exact result is used to describe all solutions of an inhomogeneous
    linear differential equation.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 从理论上讲，这一定理为求解线性方程组提供了一种极好的方法，广泛地推广到有限维向量空间以外。（请注意，这一证明对所有向量空间和线性变换适用。）例如，这一精确结果用于描述非齐次线性微分方程的所有解。
- en: 5.1.6 Inverting matrices
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1.6 矩阵求逆
- en: So far, we have seen that the invertibility of a matrix A ∈ℝ^(n×n) is key to
    solving linear equations. However, we haven’t found a way to compute the inverse
    of a matrix yet.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经看到矩阵 A ∈ℝ^(n×n) 的可逆性是解线性方程的关键。然而，我们还没有找到计算矩阵逆的办法。
- en: 'Let’s recap what the inverse is in terms of linear transformations. If the
    columns of A are denoted by the vectors a[1],…,a[n] ∈ℝ^n, then A is the linear
    transformation that maps the standard basis vectors to these vectors:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下逆矩阵在线性变换中的含义。如果 A 的列由向量 a[1],…,a[n] ∈ℝ^n 表示，那么 A 是将标准基向量映射到这些向量的线性变换：
- en: '![A : ei ↦→ ai, i = 1,...,n. ](img/file541.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![A : ei ↦→ ai, i = 1,...,n. ](img/file541.png)'
- en: If the direction of the arrows can be reversed, that is,
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 如果箭头的方向可以被反转，也就是说，
- en: '![A −1 : ai ↦→ ei, i = 1,...,n ](img/file542.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![A −1 : ai ↦→ ei, i = 1,...,n ](img/file542.png)'
- en: is a well-defined linear equation, then A^(−1) is called the inverse of A.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这是一个定义良好的线性方程，则 A^(−1) 称为 A 的逆矩阵。
- en: 'In light of all that we have seen in this chapter, the method for finding the
    inverse is simple: solve Ax = e[i] for each i where e[1],…,e[n] ∈ℝ^n is the standard
    basis.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 根据本章内容，求解逆矩阵的方法很简单：对于每个 i 求解 Ax = e[i]，其中 e[1],…,e[n] ∈ℝ^n 为标准基。
- en: 'Suppose that Ax[i] = e i . Then, if b can be written as b = ∑ [i=1]^nb[i]e
    i, the vector x = ∑ [i=1]^nb[i]x[i] is the solution of Ax = b:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 假设 Ax[i] = e i。如果 b 可以表示为 b = ∑ [i=1]^nb[i]e i，则向量 x = ∑ [i=1]^nb[i]x[i] 是方程
    Ax = b 的解：
- en: '![ ∑n ∑n A ( bixi) = biAxi i=1 i=1 ∑n = biei i=1 = b. ](img/file543.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![ ∑n ∑n A ( bixi) = biAxi i=1 i=1 ∑n = biei i=1 = b. ](img/file543.png)'
- en: Thus, the inverse is the matrix whose i-th column is x[i].
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，逆矩阵是其第 i 列为 x[i] 的矩阵。
- en: 'I know, this seems paradoxical: to find the solution of Ax = b, we need the
    inverse A^(−1). To find the inverse, we need to solve n equations. The answer
    is Gaussian elimination (Section [5.1.1](ch011.xhtml#gaussian-elimination)), which
    gives us an exact computational method to obtain A^(−1). In the next section,
    we are going to put this into practice and write our matrix-inverting algorithm
    from scratch. Pretty awesome.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我知道，这看起来很矛盾：为了找到 Ax = b 的解，我们需要逆矩阵 A^(−1)。为了求逆，我们需要解 n 个方程。答案是高斯消元法（第 [5.1.1](ch011.xhtml#gaussian-elimination)节），它为我们提供了一种精确的计算方法来获得
    A^(−1)。在下一节中，我们将把这一方法付诸实践，编写我们的矩阵求逆算法。从头开始，非常棒。
- en: 5.2 The LU decomposition
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.2 LU 分解
- en: In the previous chapter, I promised that you’d never have to solve a linear
    equation by hand. As it turns out, this task is perfectly suitable for computers.
    In this chapter, we will dive deep into the art of solving linear equations, developing
    the tools from scratch.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章，我承诺你永远不需要手动解线性方程。事实证明，这个任务非常适合计算机处理。在这一章中，我们将深入探讨解线性方程的艺术，从头开始开发工具。
- en: We start by describing the process of Gaussian elimination in terms of matrices.
    Why would we even do that? Because matrix multiplication can be performed extremely
    fast in modern computers. Expressing any algorithm in terms of matrices is a sure
    way to accelerate.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先通过矩阵来描述高斯消元法的过程。为什么我们要这样做呢？因为矩阵乘法在现代计算机中可以非常快速地执行。将任何算法表示为矩阵形式是加速的可靠方式。
- en: At the start, our linear equation Ax = b is given by the coefficient matrix
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始时，我们的线性方程 Ax = b 由系数矩阵给出
- en: '![ ⌊ ⌋ a11 a12 ... a1n || || | a21 a22 ... a2n| A = || ... ... ... ... || ∈
    ℝn×n, || || |⌈ an1 an2 ... ann|⌉ ](img/file544.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![ ⌊ ⌋ a11 a12 ... a1n || || | a21 a22 ... a2n| A = || ... ... ... ... || ∈
    ℝn×n, || || |⌈ an1 an2 ... ann|⌉ ](img/file544.png)'
- en: and at the end of the elimination process, A is transformed into the form
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在消元过程结束时，A 被转化为
- en: '![ ⌊ ⌋ | a11 a12 a13 ... a1n | || 0 a(1) a (1) ... a(1)|| (n−1) | 22 23(2)
    2(n2)| A = || 0 0 a 33 ... a3n || . || ... ... ... ... ... || ⌈ ⌉ 0 0 0 ... a(nnn−1)
    ](img/file545.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![ ⌊ ⌋ | a11 a12 a13 ... a1n | || 0 a(1) a (1) ... a(1)|| (n−1) | 22 23(2)
    2(n2)| A = || 0 0 a 33 ... a3n || . || ... ... ... ... ... || ⌈ ⌉ 0 0 0 ... a(nnn−1)
    ](img/file545.png)'
- en: A^((n−1)) is upper diagonal; that is, all elements below its diagonal are 0.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: A^((n−1)) 是上三角矩阵；也就是说，它的对角线以下的所有元素都是0。
- en: Gaussian elimination performs this task one step at a time, focusing on consecutive
    columns. After the first elimination step, this is turned into the equation ([5.1.1](ch011.xhtml)),
    described by the coefficient matrix
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 高斯消元法逐步执行这个任务，专注于连续的列。在第一次消元步骤后，这转化为方程式 ([5.1.1](ch011.xhtml))，由系数矩阵描述
- en: '![ ⌊ ⌋ | a11 a12 ... a1n| || 0 a(212) ... a(21)n|| (1) || . . . . || n×n A
    = | .. .. .. .. | ∈ ℝ . || 0 a(1) ... a(1)|| ⌈ n2 nn⌉ ](img/file546.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![ ⌊ ⌋ | a11 a12 ... a1n| || 0 a(212) ... a(21)n|| (1) || . . . . || n×n A
    = | .. .. .. .. | ∈ ℝ . || 0 a(1) ... a(1)|| ⌈ n2 nn⌉ ](img/file546.png)'
- en: Can we obtain A^((1)) from A via multiplication with some matrix; that is, can
    we find G[1] ∈ℝ^(n×n) such that A^((1)) = G[1]A holds?
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们能否通过与某个矩阵相乘从 A 获得 A^((1))；也就是说，我们能否找到 G[1] ∈ℝ^(n×n)，使得 A^((1)) = G[1]A 成立？
- en: Yes. By defining G[1] as
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 是的。通过定义 G[1] 为
- en: '![L(U,V ) = {f : U → V | f is linear}](img/equation_(9).png)(5.5)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![L(U,V ) = {f : U → V | f is linear}](img/equation_(9).png)(5.5)'
- en: we can see that A^((1)) = G[1]A is the same as performing the first step of
    Gaussian elimination. (Pick up a pen and paper and verify this by hand. It’s an
    excellent exercise.) G[1] is lower diagonal; that is, all elements above its diagonal
    are 0\. In fact, except for the first column, all elements below the diagonal
    are 0 as well. (Note that G[1] depends on A.)
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，A^((1)) = G[1]A 就是执行高斯消元法的第一步。（拿起笔和纸手动验证一下，这是一个很好的练习。）G[1]是下三角矩阵；也就是说，它的对角线以上的所有元素都是0。事实上，除了第一列外，所有对角线下方的元素也都是0。（请注意，G[1]依赖于A。）
- en: By analogously defining
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 通过类比定义
- en: '![L(U,V ) = {f : U → V | f is linear}](img/equation_(10).png)(5.6)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![L(U,V ) = {f : U → V | f is linear}](img/equation_(10).png)(5.6)'
- en: we obtain A^((2)) = G[2]A^((1)) = G[2]G[1]A, a matrix that is upper diagonal
    in the first two columns. (That is, all elements are 0 below the diagonal, but
    only in the first two columns.)
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到 A^((2)) = G[2]A^((1)) = G[2]G[1]A，这个矩阵在前两列上是上三角矩阵。（也就是说，所有元素在对角线以下为0，但仅限于前两列。）
- en: We can continue this process until we obtain the upper triangular matrix
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以继续这个过程，直到得到上三角矩阵。
- en: A^((n−1)) = G[n−1]…G[1]A.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: A^((n−1)) = G[n−1]…G[1]A。
- en: The algorithm is starting to shape up nicely. The G[i] matrices are invertible,
    with inverses
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 算法开始逐渐形成了良好的结构。G[i] 矩阵是可逆的，具有逆矩阵
- en: '![ ⌊ ⌋ ⌊ ⌋ 1 0 0 ... 0 |1 0 0 ... 0| ||a21 || ||0 1 0 ... 0|| ||a11 1 0 ...
    0|| || a(1) || |a31 0 1 ... 0| |0 3a(21) 1 ... 0| G −11= ||a1.1 . . . ||, G −21
    = || . 22\. . . || ,..., || .. .. .. .. || || .. .. .. .. || ||an1 0 0 ... 1||
    || a(n12) || ⌈a11 ⌉ |⌈0 a(212) 0 ... 1|⌉ ](img/file549.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![ ⌊ ⌋ ⌊ ⌋ 1 0 0 ... 0 |1 0 0 ... 0| ||a21 || ||0 1 0 ... 0|| ||a11 1 0 ...
    0|| || a(1) || |a31 0 1 ... 0| |0 3a(21) 1 ... 0| G −11= ||a1.1 . . . ||, G −21
    = || . 22\. . . || ,..., || .. .. .. .. || || .. .. .. .. || ||an1 0 0 ... 1||
    || a(n12) || ⌈a11 ⌉ |⌈0 a(212) 0 ... 1|⌉ ](img/file549.png)'
- en: and so on. Thus, by multiplying by their inverses one by one, we can express
    A as
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 依此类推。通过逐个乘以它们的逆矩阵，我们可以将 A 表示为
- en: '![ −1 −1 (n−1) A = G 1 ...G n−1A . ](img/file550.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![ −1 −1 (n−1) A = G 1 ...G n−1A . ](img/file550.png)'
- en: Fortunately, we can calculate L := G[1]^(−1)…G[n−1]^(−1) by hand. After a quick
    computation, we obtain
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，我们可以手动计算 L := G[1]^(−1)…G[n−1]^(−1)。经过快速计算，我们得到：
- en: '![L(U,V ) = {f : U → V | f is linear}](img/equation_(11).png)(5.8)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![L(U,V ) = {f : U → V | f is linear}](img/equation_(11).png)(5.8)'
- en: 'which is lower diagonal. (Again, don’t be shy about verifying ([5.8](ch011.xhtml#the-lu-decomposition))
    by hand.) By defining the upper diagonal matrix U := A^((n−1)), we obtain the
    famous LU decomposition, factoring A into a lower and upper diagonal matrix:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个下三角矩阵。（再次提醒，不要羞于手动验证（[5.8](ch011.xhtml#the-lu-decomposition)））。通过定义上三角矩阵
    U := A^((n−1))，我们得到了著名的 LU 分解，将 A 分解为下三角矩阵和上三角矩阵：
- en: '![A = LU. ](img/file552.png)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![A = LU.](img/file552.png)'
- en: 'Notice that with this algorithm, we perform two tasks for the price of one:
    factorizing A into the product of an upper diagonal and lower diagonal matrix,
    and performing Gaussian elimination.'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，使用这个算法，我们用一个代价完成了两个任务：将 A 分解为上三角矩阵和下三角矩阵的乘积，同时执行高斯消元。
- en: From a computational standpoint, the LU decomposition is an extremely important
    tool. Since it is just a refashioned Gaussian elimination, its complexity is O(n³),
    just as we saw this earlier (Section [5.1.4](ch011.xhtml#the-time-complexity-of-gaussian-elimination)).
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 从计算角度看，LU 分解是一个极其重要的工具。由于它本质上是高斯消元法的改进版，它的复杂度是 O(n³)，正如我们在之前（第[5.1.4](ch011.xhtml#the-time-complexity-of-gaussian-elimination)节）所看到的。
- en: 'Bad news: LU decomposition not always available. Since it is tied to Gaussian
    elimination, we can characterize its existence in similar terms. Recall that for
    the Gaussian elimination to successfully finish, the principal minors are required
    to be nonzero (Theorem [31](ch011.xhtml#x1-90004r31)). This is directly transferred
    to the LU decomposition.'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 坏消息：LU 分解并不总是可用的。由于它与高斯消元法相关联，我们可以用类似的方式描述其存在性。回顾一下，高斯消元法要成功完成，要求主小行列式非零（定理[31](ch011.xhtml#x1-90004r31)）。这一要求同样适用于
    LU 分解。
- en: Theorem 34\. (Existence of the LU decomposition)
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 定理 34.（LU 分解的存在性）
- en: Let A ∈ℝ^(n×n) be an arbitrary square matrix, and let M[k] be its k-th principal
    minor. If M[k]≠0 for all k = 1,2,…,n − 1, then A can be written as
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 设 A ∈ℝ^(n×n) 是一个任意的方阵，M[k] 是它的第 k 个主小行列式。如果对所有 k = 1, 2, …, n − 1，M[k] ≠ 0，则
    A 可以写作：
- en: '![A = LU, L, U ∈ ℝn×n, ](img/file553.png)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![A = LU, L, U ∈ ℝn×n,](img/file553.png)'
- en: where L is a lower diagonal and U is an upper diagonal matrix. Moreover, the
    elements along the diagonal of L are equal to 1.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 L 是下三角矩阵，U 是上三角矩阵。此外，L 的对角线元素均为 1。
- en: 'The gist is the same: everything is fine if we avoid division by 0 during the
    algorithm. Note that the LU algorithm doesn’t require a nonzero M[n] = detA, that
    is, an invertible matrix!'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 关键点是：如果在算法中避免除以 0，一切都没问题。请注意，LU 算法不要求非零 M[n] = detA，也就是说，不需要是一个可逆矩阵！
- en: After all this preparation, we are ready to put things into practice!
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 经过所有这些准备后，我们终于可以付诸实践了！
- en: 5.2.1 Implementing the LU decomposition
  id: totrans-160
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2.1 实现 LU 分解
- en: 'To summarize the LU decomposition, it’s essentially the iteration of two steps:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 总结 LU 分解，它本质上是两个步骤的迭代：
- en: Calculate the elimination matrices of the input.
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算输入的消元矩阵。
- en: Multiply the input by the elimination matrices, feeding the output back into
    the first step.
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将输入乘以消元矩阵，将输出反馈到第一步。
- en: 'The plan is clear: first, we write a function that computes the elimination
    matrices and their inverses; then, we iteratively perform the elimination steps
    using matrix multiplication.'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 计划很清晰：首先，我们写一个函数计算消元矩阵及其逆矩阵；然后，使用矩阵乘法迭代执行消元步骤。
- en: '[PRE0]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Now, we are ready to perform the elimination steps.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们准备执行消元步骤了。
- en: '[PRE1]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Let’s test our function on a small matrix.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在一个小矩阵上测试我们的函数。
- en: '[PRE2]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Is the result correct? Let’s test it by multiplying L and U together to see
    if it gives A back.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 结果正确吗？让我们通过将 L 和 U 相乘来测试，看看是否能还原回 A。
- en: '[PRE6]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Overall, the LU decomposition is a highly versatile tool, used as a stepping
    stone in the implementation of essential algorithms. One of them is computing
    the inverse matrix, as we shall see next.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，LU 分解是一种非常灵活的工具，在实现基本算法中作为一个重要的基础步骤。其中之一是计算逆矩阵，正如我们接下来将看到的。
- en: 5.2.2 Inverting a matrix, for real
  id: totrans-177
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2.2 逆矩阵的计算，真正的计算
- en: So far, we have talked a lot about the inverse matrix. We explored the question
    of invertibility from several angles, in terms of the kernel and the image, the
    determinant, and the solvability of linear equations.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经谈论了很多关于逆矩阵的内容。我们从多个角度探讨了可逆性的问题，包括核与像、行列式和线性方程的可解性。
- en: However, we haven’t yet talked about actually computing the inverse. With the
    LU decomposition, we obtain a tool that can be used for this purpose. How? By
    plugging in a lower triangular matrix into the Gaussian elimination process, we
    get its inverse as a side effect. So, we
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们还没有讨论实际计算逆矩阵的过程。通过LU分解，我们得到了一种可以用于此目的的工具。如何实现？通过将下三角矩阵代入高斯消元过程，我们可以将其逆矩阵作为副作用获得。因此，我们
- en: calculate the LU decomposition A = LU,
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算LU分解A = LU，
- en: invert the lower triangular matrices L and U^T ,
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 反转下三角矩阵L和U^T，
- en: use the identity (U[−1])T = (U[T] )−1 to get U^(−1),
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用恒等式(U[−1])T = (U[T])−1来得到U^(−1)，
- en: multiply L^(−1) and U^(−1) to finally obtain A^(−1) = U^(−1)L^(−1).
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将L^(−1)和U^(−1)相乘，最终得到A^(−1) = U^(−1)L^(−1)。
- en: That’s a plan! Let’s start with inverting lower triangular matrices.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是计划！让我们从反转下三角矩阵开始。
- en: Let L ∈ℝ^(n×n) be an arbitrary lower triangular matrix. Following the same process
    that led to ([5.7](ch011.xhtml#the-lu-decomposition)), we obtain
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 设L ∈ℝ^(n×n)是一个任意的下三角矩阵。按照与([5.7](ch011.xhtml#the-lu-decomposition))相同的过程，我们可以得到
- en: '![D = Gn −1...G1L, ](img/file554.png)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
  zh: '![D = Gn −1...G1L, ](img/file554.png)'
- en: where D, the final result of Gaussian elimination, is a diagonal matrix
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 其中D，经过高斯消元后的最终结果，是一个对角矩阵
- en: '![ ⌊ ⌋ |d1 0 ... 0 | | 0 d2 ... 0 | D = diag(d1,...,dn) = || . . . . ||, |⌈
    .. .. .. .. |⌉ 0 0 ... d n ](img/file555.png)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![ ⌊ ⌋ |d1 0 ... 0 | | 0 d2 ... 0 | D = diag(d1,...,dn) = || . . . . ||, |⌈
    .. .. .. .. |⌉ 0 0 ... d n ](img/file555.png)'
- en: and the G[i]-s are the elimination matrices defined by ([5.5](ch011.xhtml#the-lu-decomposition)),
    ([5.6](ch011.xhtml#the-lu-decomposition)), and so on.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: G[i]是由([5.5](ch011.xhtml#the-lu-decomposition))、([5.6](ch011.xhtml#the-lu-decomposition))等定义的消元矩阵。
- en: Since the inverse of ![D ](img/file556.png) is simply ![ − 1 −1 −1 D = diag(d1
    ,...,dn ) ](img/file557.png), we can express ![L −1 ](img/file558.png) as
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 由于![D ](img/file556.png)的逆矩阵就是![ − 1 −1 −1 D = diag(d1 ,...,dn ) ](img/file557.png)，我们可以将![L
    −1 ](img/file558.png)表示为
- en: '![L −1 = D −1Gn− 1...G1\. ](img/file559.png)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![L −1 = D −1Gn− 1...G1\. ](img/file559.png)'
- en: We can implement this very similarly to the LU decomposition; we can even reuse
    our elimination_matrix function.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以非常类似地实现这一点，LU分解的实现方法几乎相同；我们甚至可以重用我们的elimination_matrix函数。
- en: '[PRE8]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: With this done, we are ready to invert any matrix (that is actually invertible).
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 完成这些后，我们就准备好反转任何矩阵（前提是矩阵确实可逆）。
- en: We are almost at the finish line. Every component is ready; the only thing left
    to do is to put them together. We can do this with a few lines of code.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 我们几乎快到终点了。每个组件都已准备好，剩下的就是将它们组合起来。我们可以通过几行代码来完成这一切。
- en: '[PRE9]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Voilà! Witness the result with your own eyes.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: Voilà！亲眼见证这个结果。
- en: '[PRE10]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: To test the correctness of our invert function, we quickly check the results
    on a few randomly generated matrices.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试我们的反转函数的正确性，我们快速检查几种随机生成的矩阵结果。
- en: '[PRE12]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Since there is no error message above, the function is (probably) correct.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 由于上面没有错误消息，函数（可能）是正确的。
- en: What seemed complex and abstract a few chapters ago is now in our hands. We
    can invert any matrix, not with built-in functions, but with one that we wrote
    from scratch. I love these moments when the pieces are finally put together, and
    everything clicks. Sit back, relax, and appreciate the journey that got us here!
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 几章之前看似复杂抽象的内容，现在已掌握在我们手中。我们能够反转任何矩阵，不依赖内置函数，而是通过从零开始编写的函数来实现。我喜欢这种时刻，当所有的部分终于组合起来，一切都变得清晰明了。放松一下，欣赏一下带我们走到这里的过程吧！
- en: 5.2.3 How to actually invert matrices
  id: totrans-204
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2.3 如何实际反转矩阵
- en: Of course, our LU decomposition!matrices, invertingimplementation is far from
    optimal. When working with NumPy arrays, we can turn to the built-in functions.
    In NumPy, this is np.linalg.inv.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我们的LU分解！矩阵反转实现远非最优。当处理NumPy数组时，我们可以依赖内置函数。在NumPy中，这是np.linalg.inv。
- en: '[PRE13]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Let’s compare the runtime of our implementation and NumPy’s.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们比较一下我们实现的运行时间与NumPy的运行时间。
- en: '[PRE15]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'A massive improvement. Nice! (Don’t forget that the execution time isLU decomposition!matrices,
    inverting hardware-dependent.) Why is NumPy that much faster? There are two main
    reasons. First, it directly calls the SGETRI function from LAPACK, which is extremely
    fast. Second, according to its documentation ( [https://www.netlib.org/lapack/explore-html/da/d28/group__getri_gaa3bf1bb1432917f0e5fdf4c48bd6998c.html](https://www.netlib.org/lapack/explore-html/da/d28/group__getri_gaa3bf1bb1432917f0e5fdf4c48bd6998c.html)),
    SGETRI uses a faster algorithm:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 一次巨大的改进。不错！（别忘了执行时间是 LU 分解！矩阵的逆运算是硬件相关的。）为什么 NumPy 会更快呢？有两个主要原因。首先，它直接调用了 LAPACK
    中的 SGETRI 函数，这个函数极其快速。其次，根据它的文档（[https://www.netlib.org/lapack/explore-html/da/d28/group__getri_gaa3bf1bb1432917f0e5fdf4c48bd6998c.html](https://www.netlib.org/lapack/explore-html/da/d28/group__getri_gaa3bf1bb1432917f0e5fdf4c48bd6998c.html)），SGETRI
    使用了一个更快的算法：
- en: '[PRE17]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: So, NumPy calls the LAPACK function, which uses LU factorization in turn. (I
    am not particularly adept at digging through Fortran code that is older than I
    am, so let me know if I am wrong here. Nevertheless, the fact that state-of-the-art
    frameworks still make calls to this ancient library is a testament to its power.
    Never underestimate old technologies like LAPACK and Fortran.)
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，NumPy 调用了 LAPACK 函数，而该函数又使用了 LU 分解。（我并不是特别擅长深入研究比我还要古老的 Fortran 代码，所以如果我在这里错了，请告诉我。不过，现代框架仍然调用这个古老的库，足以证明它的强大。永远不要低估像
    LAPACK 和 Fortran 这样的老技术。）
- en: Are there any other applications of the powerful LU decomposition that we’ve
    just learned? Glad you asked! Of course there is; that’s the beauty of math. There’s
    always a new and unexpected application even for the oldest of tools. This time,
    we’ll finally see how to compute determinants fast! (And also slow.)
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚学到的强大 LU 分解，还有其他应用吗？很高兴你问了！当然有；这就是数学的美妙之处。即使是最古老的工具，总能找到新的和意想不到的应用。这一次，我们终于会看到如何快速计算行列式！（当然也会有慢的计算方法。）
- en: 5.3 Determinants in practice
  id: totrans-215
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.3 行列式的实际应用
- en: In the theory and practice of mathematics, the development of concepts usually
    has a simple flow. Definitions first arise from vague geometric or algebraic intuitions,
    eventually crystallizing in mathematical formalism.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 在数学的理论与实践中，概念的发展通常有一个简单的流程。定义首先源于模糊的几何或代数直觉，最终凝练为数学形式化。
- en: However, mathematical definitions often disregard practicalities. For a very
    good reason, mind you! Keeping practical considerations out of sight gives us
    the power to reason about structure effectively. This is the strength of abstraction.
    Eventually, if meaningful applications are found, the development flows toward
    computational questions, putting speed and efficiency onto the horizon.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，数学定义常常忽略实际情况。你可得理解，这背后有非常好的理由！把实际考虑抛在一边使得我们能够有效地推理结构，这就是抽象的力量。最终，如果能找到有意义的应用，发展方向就会朝向计算问题，速度和效率便成为焦点。
- en: The epitome of this is neural networks themselves. From theoretical constructs
    to state-of-the-art algorithms that run on your smartphone, machine learning research
    followed this same arc.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络本身就是这一点的典型。无论是从理论构想到如今可以在智能手机上运行的先进算法，机器学习研究遵循了这一同样的轨迹。
- en: This is also what we experience in this book on a microscopic level. Among many
    other examples, think about determinants. We introduced the determinant as the
    orientation of column vectors and the parallele-piped volume defined by them.
    Still, we haven’t really worked on computing them in practice. Sure, we gave a
    formula or two, but it is hard to decide which one is the most convoluted. All
    of them are.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 这也是我们在本书中从微观层面上所经历的事情。在许多其他例子中，想想行列式。我们将行列式定义为列向量的方向性以及由它们定义的平行六面体的体积。然而，我们实际上并没有真正进行过计算它们的实践。我们当然给出了一个或两个公式，但很难判断哪个公式最复杂，实际上它们都一样复杂。
- en: 'On the other hand, the mathematical study of determinants yielded a ton of
    useful results: invertibility of linear transformations, characterization of Gaussian
    elimination, and many more (and even more to come.).'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，行列式的数学研究产生了大量有用的结果：线性变换的可逆性、高斯消元的特征化等等（甚至更多的结果还在后面）。
- en: 'In this section, we are ready to pay off our debts and develop tools to actually
    compute determinants. As before, we will take a straightforward approach and use
    one of the previously derived determinant formulas. Spoiler alert: This is far
    from optimal, so we’ll find a way to compute the determinant with high speed.'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一节中，我们准备偿还我们的债务，并开发实际计算行列式的工具。像之前一样，我们将采用直接的方式，使用之前推导出的某个行列式公式。剧透一下：这远非最优方法，因此我们将找到一种更快速地计算行列式的方法。
- en: 5.3.1 The lesser of two evils
  id: totrans-222
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3.1 两害相权取其轻
- en: Let’s recall what we know about determinants (Definition [20](ch010.xhtml#x1-81006r20))
    so far. Given a matrix A ∈ℝ^(n×n), its determinant detA quantifies the volume
    distortion of the linear transformation x →Ax. That is, if e[1],…,e[n] is the
    standard orthonormal basis, then informally speaking,
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下迄今为止我们关于行列式的了解（定义 [20](ch010.xhtml#x1-81006r20)）。给定一个矩阵 A ∈ℝ^(n×n)，它的行列式
    detA 量化了线性变换 x → Ax 对体积的扭曲。也就是说，如果 e[1],…,e[n] 是标准的正交归一基，那么非正式地说，
- en: '![det A = (orientation of Ae1, Ae2,...,Aen ) × (area of the parallelepiped
    determined by Ae1, Ae2,...,Aen ). ](img/file560.png)'
  id: totrans-224
  prefs: []
  type: TYPE_IMG
  zh: '![det A = (orientation of Ae1, Ae2,...,Aen ) × (area of the parallelepiped
    determined by Ae1, Ae2,...,Aen ). ](img/file560.png)'
- en: 'We have derived two formulas to compute this quantity. Initially, we described
    the determinant in terms of summing over all permutations:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经推导出了两种计算这个量的公式。最初，我们通过对所有排列求和来描述行列式：
- en: '![det A = ∑ sign(σ)a ...a . σ(1),1 σ(n),n σ∈Sn ](img/file561.png)'
  id: totrans-226
  prefs: []
  type: TYPE_IMG
  zh: '![det A = ∑ sign(σ)a ...a . σ(1),1 σ(n),n σ∈Sn ](img/file561.png)'
- en: This is difficult to understand, let alone to programmatically compute. So,
    a recursive formula is derived, which we can also use. It states that
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 这很难理解，更不用说编程计算了。因此，推导出了一个递归公式，我们也可以使用。它指出：
- en: '![ ∑n detA = (− 1)j+1a1,j detA1,j, j=1 ](img/file562.png)'
  id: totrans-228
  prefs: []
  type: TYPE_IMG
  zh: '![ ∑n detA = (− 1)j+1a1,j detA1,j, j=1 ](img/file562.png)'
- en: where A[i,j] is the matrix obtained by deleting the i-th row and j-th column
    of A. Which one would you rather use? Take a few minutes to figure out your reasoning.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 A[i,j] 是通过删除 A 的第 i 行和第 j 列得到的矩阵。你更倾向于使用哪一种方法？花几分钟思考一下你的推理。
- en: Unfortunately, there are no right choices here. With the permutation formula,
    one has to find a way to generate all permutations first, then calculate their
    signs. Moreover, there are n! unique permutations in S[n], so this sum has a lot
    of terms. Using this formula seems extremely difficult, so we will go with the
    recursive version. Recursion has its issues (as we are about to see very soon),
    but it is easy to handle from a coding standpoint. Let’s get to work!
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，这里没有正确的选择。使用排列公式时，必须首先找到生成所有排列的方法，然后计算它们的符号。此外，S[n] 中有 n! 种唯一排列，因此这个和包含了很多项。使用这个公式似乎非常困难，因此我们将采用递归版本。递归也有它的问题（我们很快就会看到），但从编码的角度来看，它比较容易处理。让我们开始吧！
- en: 5.3.2 The recursive way
  id: totrans-231
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3.2 递归方式
- en: Let’s put the formula
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下这个公式：
- en: '![ ∑n detA = (− 1)j+1a1,j det A1,j j=1 ](img/file563.png)'
  id: totrans-233
  prefs: []
  type: TYPE_IMG
  zh: '![ ∑n detA = (− 1)j+1a1,j det A1,j j=1 ](img/file563.png)'
- en: under our magnifying glass. If A is an n×n matrix, then A[1,j] (obtained from
    A by deleting its first row and j-th column) is of size (n− 1) × (n− 1). This
    is a recursive step. For each n×n determinant, we have to calculate n pieces of
    (n− 1) × (n− 1) determinants, and so on.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的放大镜下。如果 A 是一个 n×n 矩阵，那么 A[1,j]（通过删除 A 的第一行和第 j 列得到的矩阵）是一个 (n−1) × (n−1)
    的矩阵。这是一个递归步骤。对于每个 n×n 的行列式，我们需要计算 n 个 (n−1) × (n−1) 的行列式，依此类推。
- en: By the end, we have a lots of 1 × 1 determinants, which are trivial to calculate.
    So, we have a boundary condition, and with that, we are ready to put these together.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 到最后，我们得到了大量的 1 × 1 行列式，这些可以很容易计算。因此，我们有了一个边界条件，有了它，我们准备将这些合并在一起。
- en: '[PRE18]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Let’s test the det function out on a small example. For 2 × 2 matrices, we can
    easily calculate the determinants using the rule
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在一个小例子中测试一下 det 函数。对于 2 × 2 矩阵，我们可以轻松使用以下规则计算行列式：
- en: '![ ⌊ ⌋ a b det⌈ ⌉ = ad − bc. c d ](img/file564.png)'
  id: totrans-238
  prefs: []
  type: TYPE_IMG
  zh: '![ ⌊ ⌋ a b det⌈ ⌉ = ad − bc. c d ](img/file564.png)'
- en: '[PRE19]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[PRE20]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: It seems to work. So far, so good. What is the issue? Recursion. Let’s calculate
    the determinant of a small 10 × 10 matrix, measuring the time it takes.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 结果似乎没问题。到目前为止，一切顺利。那问题出在哪里呢？递归。让我们计算一个小的 10 × 10 矩阵的行列式，并测量所需的时间。
- en: '[PRE21]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[PRE22]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: That was long and unbearable. For such a simple task, this feels like an eternity.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 那真是漫长且令人无法忍受。对于这么简单的任务，感觉像过了一个世纪。
- en: For n×n inputs, we call the det function recursively n times, on (n− 1) × (n−
    1) inputs. That is, if a[n] denotes the time complexity of our algorithm for an
    n ×n matrix, then, due to the recursive step, we have
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 n×n 的输入，我们递归地调用 det 函数 n 次，每次处理 (n−1) × (n−1) 的输入。也就是说，如果 a[n] 表示我们算法在 n×n
    矩阵上的时间复杂度，那么由于递归步骤，我们有：
- en: '![an = nan−1, ](img/file565.png)'
  id: totrans-246
  prefs: []
  type: TYPE_IMG
  zh: '![an = nan−1, ](img/file565.png)'
- en: 'which explodes really fast. In fact, a[n] = O(n!), which is the dreaded factorial
    complexity. Unlike some other recursive algorithms, [caching](https://docs.python.org/3/library/functools.html#functools.cache)
    doesn’t help either. There are two reasons for this: sub-matrices rarely match,
    and numpy.ndarray objects are mutable, thus not hashable.'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 它爆炸得非常快。实际上，a[n] = O(n!)，这就是令人害怕的阶乘复杂度。与其他一些递归算法不同，[缓存](https://docs.python.org/3/library/functools.html#functools.cache)也没有帮助。出现这种情况有两个原因：子矩阵很少匹配，而且numpy.ndarray对象是可变的，因此不能进行哈希处理。
- en: 'In practice, n can be in the millions, so this formula is utterly useless.
    What can we do? Simple: LU decomposition.'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，n可以达到数百万，所以这个公式完全没有用。我们该怎么办？很简单：LU分解。
- en: 5.3.3 How to actually compute determinants
  id: totrans-249
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3.3 如何实际计算行列式
- en: Besides the two formulas, we have seen lots of useful properties of matrices
    and determinants. Can we apply what we have learned so far to simplify the problem?
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这两个公式外，我们还看到了许多矩阵和行列式的有用性质。我们能否将目前学到的知识应用到简化问题上呢？
- en: Let’s consider the LU decomposition. According to this, if detA≠0, then A =
    LU, where L is lower triangular and U is upper triangular. Since the determinant
    behaves nicely with respect to matrix multiplication (see equation (4.11)), we
    have
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑LU分解。根据此分解，如果detA ≠ 0，则A = LU，其中L是下三角矩阵，U是上三角矩阵。由于行列式在矩阵乘法下表现良好（参见公式(4.11)），我们有
- en: '![detA = detL detU. ](img/file566.png)'
  id: totrans-252
  prefs: []
  type: TYPE_IMG
  zh: '![detA = detL detU. ](img/file566.png)'
- en: 'Seemingly, we made our situation worse: instead of one determinant, we have
    to deal with two. However, L and U are rather special, as they are triangular.
    It turns out that computing a triangular matrix’s determinant is extremely easy.
    We just have to multiply the elements on the diagonal together!'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 表面上看，我们把情况弄得更糟了：我们需要处理两个行列式，而不是一个。然而，L和U是非常特殊的，因为它们是三角矩阵。事实证明，计算三角矩阵的行列式是非常简单的。我们只需要把对角线上的元素相乘！
- en: Theorem 35\. (Determinant of a triangular matrix)
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 定理35（一个三角矩阵的行列式）
- en: Let A ∈ℝ^(n×n) be a triangular matrix. (That is, it is either lower or upper
    triangular.) Then,
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 让A ∈ ℝ^(n×n)是一个三角矩阵。（也就是说，它可以是下三角矩阵或上三角矩阵。）那么，
- en: '![ n ∏ det A = aii. i=1 ](img/file567.png)'
  id: totrans-256
  prefs: []
  type: TYPE_IMG
  zh: '![ n ∏ det A = aii. i=1 ](img/file567.png)'
- en: Proof.Suppose that A is lower triangular. (That is, all elements above its diagonal
    are 0.) According to the recursive formula for detA, we have
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 证明：假设A是下三角矩阵。（即，所有位于对角线上的元素都为0。）根据detA的递归公式，我们得到
- en: '![ ∑n detA = (− 1)j+1a1,j detA1,j. j=1 ](img/file568.png)'
  id: totrans-258
  prefs: []
  type: TYPE_IMG
  zh: '![ ∑n detA = (− 1)j+1a1,j detA1,j. j=1 ](img/file568.png)'
- en: Because A is lower triangular, a[1,j] = 0 if j >1\. Thus,
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 因为A是下三角矩阵，当j > 1时，a[1,j] = 0。所以，
- en: '![detA = a11 detA1,1\. ](img/file569.png)'
  id: totrans-260
  prefs: []
  type: TYPE_IMG
  zh: '![detA = a11 detA1,1\. ](img/file569.png)'
- en: A[1,1] = (a[ij])[i,j=2]^n is also lower triangular. By iterating the previous
    step, we obtain
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: A[1,1] = (a[ij])[i,j=2]^n也是下三角矩阵。通过迭代上一步，我们得到
- en: '![detA = a11a22 ...ann, ](img/file570.png)'
  id: totrans-262
  prefs: []
  type: TYPE_IMG
  zh: '![detA = a11a22 ...ann, ](img/file570.png)'
- en: which is what we had to show.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 这正是我们需要证明的。
- en: If A is upper triangular, its transpose A^T is lower triangular. Thus, we can
    apply the previous result, so
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 如果A是上三角矩阵，则其转置A^T是下三角矩阵。因此，我们可以应用之前的结果，所以
- en: '![detA = detAT = a11a22...ann ](img/file571.png)'
  id: totrans-265
  prefs: []
  type: TYPE_IMG
  zh: '![detA = detAT = a11a22...ann ](img/file571.png)'
- en: holds as well.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 这个式子同样成立。
- en: Back to our original problem. Since the diagonal L is constant 1 (see ([5.8](ch011.xhtml#the-lu-decomposition))),
    as guaranteed by the LU decomposition, we have
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 回到我们最初的问题。由于对角矩阵L的元素为常数1（见([5.8](ch011.xhtml#the-lu-decomposition))），这是LU分解所保证的，因此我们有
- en: '![ ∏n det A = detU = uii. i=1 ](img/file572.png)'
  id: totrans-268
  prefs: []
  type: TYPE_IMG
  zh: '![ ∏n det A = detU = uii. i=1 ](img/file572.png)'
- en: 'So, the algorithm to compute the determinant is quite simple: get the LU decomposition,
    then calculate the product of U’s diagonal. Let’s put this into practice!'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，计算行列式的算法非常简单：先获取LU分解，再计算U对角线元素的乘积。让我们实际操作一下！
- en: '[PRE23]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Yes, that simple. Let’s see how it performs!
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，就是这么简单。让我们看看它的效果吧！
- en: '[PRE24]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '[PRE25]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: It’s faster by a huge margin. How much faster?
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 它的速度提高了一个巨大的幅度。到底提高了多少呢？
- en: '[PRE26]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[PRE27]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: That’s quite an insane improvement! This can be even faster if we use a better
    implementation of the LU decomposition algorithm (for instance, scipy.linalg.lu,
    which relies on our old friend LAPACK).
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 这真是一个疯狂的改进！如果我们使用更好的LU分解算法（例如scipy.linalg.lu，它依赖于我们熟悉的LAPACK），速度甚至可以更快。
- en: I get emotional just by looking at this result. See how far we can go with a
    bit of linear algebra? This is why understanding the fundamentals such as Gaussian
    elimination is essential. Machine learning and deep learning are still very new
    fields, and even though an insane amount of research power is being put into it,
    moments like these happen all the time. Simple ideas often give birth to new paradigms.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 仅仅看到这个结果，我就感动得不行。看看我们能用一点点线性代数做到多远？这就是为什么理解高斯消元法等基础知识至关重要的原因。机器学习和深度学习仍然是非常新的领域，尽管已经投入了大量的研究力量，但这样的时刻却时常发生。简单的想法往往会催生新的范式。
- en: 5.4 Summary
  id: totrans-279
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.4 小结
- en: In this chapter, we have looked at matrices from the perspective of linear equation
    systems, i.e., equations of the form
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们从线性方程组的角度研究了矩阵，即形式为
- en: '![a11x1 + a12x2 + ⋅⋅⋅+ a1nxn = b1 a21x1 + a22x2 + ⋅⋅⋅+ a2nxn = b2 . .. an1x1
    + an2x2 + ⋅⋅⋅+ annxn = bn. ](img/file573.png)'
  id: totrans-281
  prefs: []
  type: TYPE_IMG
  zh: '![a11x1 + a12x2 + ⋅⋅⋅+ a1nxn = b1 a21x1 + a22x2 + ⋅⋅⋅+ a2nxn = b2 . .. an1x1
    + an2x2 + ⋅⋅⋅+ annxn = bn. ](img/file573.png)'
- en: Not surprisingly, these are described by matrices, and the above is equivalent
    to the expression Ax = b. Solving linear equations is an ancient art, so why are
    we talking about it in the age of AI?
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 不出所料，这些都可以用矩阵来描述，上述表达式等同于 Ax = b。解线性方程是一个古老的艺术，那么为什么我们在 AI 时代还要谈论它呢？
- en: 'Remember: It’s only AI if you are talking to investors. Deep down, it’s linear
    algebra, calculus, and probability theory.'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 记住：如果你在和投资者谈论，那才叫 AI。从根本上说，这只是线性代数、微积分和概率论。
- en: We wanted to solve linear equations, which led us to Gaussian elimination (well,
    led Gauss to Gaussian elimination). Which led us to the LU decomposition. Which
    led us to fast matrix inversion, and a bunch of other innovations on which our
    current technology is built on. Let me tell you, fast matrix multiplication and
    inversion are the bread and butter of computational linear algebra, and they all
    stem from that aforementioned ancient art of solving linear equations.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想要解线性方程，这将我们引向了高斯消元法（嗯，引导高斯到了高斯消元法）。这又引导我们到 LU 分解。然后引导我们到快速矩阵求逆，以及我们当前技术所建立的一系列其他创新。让我告诉你，快速的矩阵乘法和求逆是计算线性代数的基础，它们都源于那门古老的解线性方程的艺术。
- en: 'Let’s recap the feats that we’ve achieved in this chapter one by one:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们一一回顾一下在本章中取得的成就：
- en: solving linear equations by Gaussian elimination,
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过高斯消元法求解线性方程，
- en: characterizing the invertibility of matrices in terms of linear equations,
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过线性方程组来描述矩阵的可逆性，
- en: discovering a matrix factorization technique called LU decomposition,
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发现了一种矩阵分解技巧，称为 LU 分解，
- en: building a crazy-fast matrix-inverting algorithm using the LU decomposition,
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 LU 分解构建一个疯狂快速的矩阵求逆算法，
- en: and building a crazy-fast determinant-computing algorithm using – drumroll!
    – the LU decomposition.
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并且使用——鼓声！——LU 分解，构建一个疯狂快速的行列式计算算法。
- en: However, we are not done with matrices. Recall the relationship we established
    between them and linear transformations, viewing matrices as data transforms that
    distort the underlying feature space. As it turns out, if we are looking from
    the right perspective, this distortion is always a stretching. Well, almost always.
    Well, almost a stretching.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们与矩阵的关系还没有结束。回想一下我们之前建立的矩阵与线性变换之间的关系，将矩阵视为扭曲底层特征空间的数据变换。事实证明，如果从正确的角度来看，这种扭曲总是拉伸。嗯，几乎总是。嗯，几乎是拉伸。
- en: Well, that was too many wells, so let’s clear all of it up in the next chapter,
    diving into eigenvalues and eigenvectors. Let’s go!
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，那些“嗯”太多了，让我们在下一章中彻底清理这些内容，深入研究特征值和特征向量。出发吧！
- en: 5.5 Problems
  id: totrans-293
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.5 问题
- en: Problem 1\. Show that the product of upper triangular matrices is upper triangular.
    Similarly, show that the product of lower triangular matrices is lower triangular.
    (We have used these facts extensively in this section but didn’t give a proof.
    So, this is an excellent time to convince yourself about this if you haven’t already.)
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 问题 1\. 证明上三角矩阵的乘积是上三角矩阵。同理，证明下三角矩阵的乘积是下三角矩阵。（我们在本节中广泛使用了这些事实，但没有给出证明。所以，如果你还没有这么做，现在正是自己验证这些事实的好时机。）
- en: Problem 2\. Write a function that, given an invertible square matrix A ∈ℝ^(n×n)
    and a vector b ∈ℝ^n, finds the solution of the linear equation Ax = b. (This can
    be done with a one-liner if you use one of the tools we have built here.)
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 问题 2\. 编写一个函数，给定一个可逆的方阵 A ∈ℝ^(n×n) 和一个向量 b ∈ℝ^n，求解线性方程 Ax = b 的解。（如果你使用我们在这里构建的工具之一，可以通过一行代码完成。）
- en: 'Problem 3\. Before we wrap this chapter up, let’s go back to the definition
    of determinants. Even though there are lots of reasons against using the determinant
    formula, we have one for it: it is a good exercise, and implementing it will deepen
    your understanding. So, in this problem, you are going to build'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 问题3。 在我们结束本章之前，回到行列式的定义。尽管有很多理由反对使用行列式公式，但我们有一个支持它的理由：它是一个很好的练习，实现它会加深你的理解。因此，在这个问题中，你将构建
- en: '![ ∑ detA = sign(σ)aσ(1)1 ...a σ(n)n, σ∈Sn ](img/file574.png)'
  id: totrans-297
  prefs: []
  type: TYPE_IMG
  zh: '![ ∑ detA = sign(σ)aσ(1)1 ...a σ(n)n, σ∈Sn ](img/file574.png)'
- en: one step at a time.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 一步一步来。
- en: (i) Implement a function that, given an integer n, returns all permutations
    of the set {0,1,…,n − 1}. Represent each permutation σ as a list. For example,
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: (i) 实现一个函数，给定整数n，返回集合{0,1,…,n − 1}的所有排列。将每个排列σ表示为一个列表。例如，
- en: '[PRE28]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: would represent the permutation σ, where σ(0) = 2,σ(1) = 0, and σ(2) = 1.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 将表示排列σ，其中σ(0) = 2，σ(1) = 0，σ(2) = 1。
- en: (ii) Let σ ∈S[n] be a permutation of the set {0,1,…,n − 1}. Its inversion number
    is defined by
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: (ii) 让σ ∈S[n]是集合{0,1,…,n − 1}的一个排列。它的逆序数定义为
- en: '![inversion(σ) = |{(i,j) : i <j and σ(i) >σ (j)}|, ](img/file575.png)'
  id: totrans-303
  prefs: []
  type: TYPE_IMG
  zh: '![inversion(σ) = |{(i,j) : i <j and σ(i) >σ (j)}|, ](img/file575.png)'
- en: where j ⋅j denotes the number of elements in the set. Essentially, inversion
    describes the number of times a permutation reverses the order of a pair of numbers.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 其中j ⋅j表示集合中元素的数量。本质上，逆序描述了排列中反转一对数字顺序的次数。
- en: Turns out, the sign of σ can be written as
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 结果，σ的符号可以写成
- en: '![sign(σ) = (− 1)inversion(σ). ](img/file576.png)'
  id: totrans-306
  prefs: []
  type: TYPE_IMG
  zh: '![sign(σ) = (− 1)inversion(σ). ](img/file576.png)'
- en: Implement a function that first calculates the inversion number, then the sign
    of an arbitrary permutation. (Permutations are represented like in the previous
    problem.)
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 实现一个函数，首先计算逆序数，然后计算任意排列的符号。（排列如前一个问题中所示）
- en: (iii) Put the solutions for Problem 1\. and Problem 2\. together and calculate
    the determinant of a matrix using the permutation formula. What do you think the
    time complexity of this algorithm is?
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: (iii) 将问题1和问题2的解法结合在一起，并使用排列公式计算矩阵的行列式。你认为这个算法的时间复杂度是多少？
- en: Join our community on Discord
  id: totrans-309
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加入我们的社区，参与Discord讨论
- en: Read this book alongside other users, Machine Learning experts, and the author
    himself. Ask questions, provide solutions to other readers, chat with the author
    via Ask Me Anything sessions, and much more. Scan the QR code or visit the link
    to join the community. [https://packt.link/math](https://packt.link/math)
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他用户、机器学习专家以及作者本人一起阅读本书。提问、为其他读者提供解决方案、通过“问我任何问题”环节与作者交流，等等。扫描二维码或访问链接加入社区。[https://packt.link/math](https://packt.link/math)
- en: '![PIC](img/file1.png)'
  id: totrans-311
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file1.png)'
