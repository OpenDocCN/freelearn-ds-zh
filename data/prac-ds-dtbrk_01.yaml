- en: '1'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '1'
- en: The ML Process and Its Challenges
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习过程及其挑战
- en: Welcome to the world of simplifying your **machine learning** (**ML**) life
    cycle with the Databricks platform.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 欢迎来到使用Databricks平台简化你的**机器学习**（**ML**）生命周期的世界。
- en: As a senior specialist solutions architect at Databricks specializing in ML,
    over the years, I have had the opportunity to collaborate with enterprises to
    architect ML-capable platforms to solve their unique business use cases using
    the Databricks platform. Now, that experience will be at your service to learn
    from. The knowledge you will gain from this book will open new career opportunities
    for you and change how you approach architecting ML pipelines for your organization’s
    ML use cases.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 作为Databricks的高级解决方案架构师，专注于机器学习，多年来，我有机会与企业合作，架构能够解决其独特商业用例的机器学习平台，使用Databricks平台。现在，这段经验将为你提供学习资源。你从本书中获得的知识将为你开启新的职业机会，并改变你为组织的机器学习用例架构机器学习流水线的方式。
- en: This book does assume that you have a reasonable understanding of the Python
    language as the accompanying code samples will be in Python. This book is not
    about teaching you ML techniques from scratch; it is assumed that you are an experienced
    data science practitioner who wants to learn how to take your ML use cases from
    development to production and all the steps in the middle using the Databricks
    platform.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本书假定你已经对Python语言有一定了解，因为附带的代码示例将使用Python。 本书并不是从零开始教授机器学习技术；它假设你是一个经验丰富的数据科学从业者，想要学习如何利用Databricks平台将你的机器学习用例从开发到生产以及中间的所有步骤。
- en: For this book, some Python and pandas know-how is required. Being familiar with
    Apache Spark is a plus, and having a solid grasp of ML and data science is necessary.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本书需要一定的Python和pandas知识。熟悉Apache Spark是加分项，具备扎实的机器学习和数据科学基础是必要的。
- en: Note
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: This book focuses on the features that are currently generally available. The
    code examples provided utilize Databricks notebooks. While Databricks is actively
    developing features to support workflows using external **integrated development
    environments** (**IDEs**), these specific features are not covered in this book.
    Also, going through this book will give you a solid foundation to quickly pick
    up new features as they become GA.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 本书重点介绍当前一般可用的功能。提供的代码示例使用Databricks笔记本。尽管Databricks正在积极开发支持使用外部**集成开发环境**（**IDEs**）的工作流的功能，但本书未涵盖这些特定功能。此外，阅读本书将为你奠定坚实的基础，使你能够在新功能发布时快速掌握它们。
- en: 'In this chapter, we will cover the following:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下内容：
- en: Understanding the typical ML process
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解典型的机器学习过程
- en: Discovering the personas involved with the machine learning process in organizations
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发现参与组织中机器学习过程的各个角色
- en: Challenges with productionizing machine learning use cases in organizations
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在组织中将机器学习用例投入生产的挑战
- en: Understanding the requirements of an enterprise machine learning platform
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解企业机器学习平台的需求
- en: Exploring Databricks and the Lakehouse architecture
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索Databricks和Lakehouse架构
- en: By the end of this chapter, you should have a fundamental understanding of what
    a typical ML development life cycle looks like in an enterprise and the different
    personas involved in it. You will also know why most ML projects fail to deliver
    business value and how the Databricks Lakehouse Platform provides a solution.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 本章结束时，你应该对企业中典型的机器学习开发生命周期以及其中涉及的不同角色有基本的了解。你还将知道为什么大多数机器学习项目未能带来商业价值，并且了解Databricks
    Lakehouse平台如何提供解决方案。
- en: Understanding the typical machine learning process
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解典型的机器学习过程
- en: 'The following diagram summarizes the ML process in an organization:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 下图总结了组织中的机器学习过程：
- en: '![Figure 1.1 – The data science development life cycle consists of three main
    stages – data preparation, modeling, and deployment](img/B17875_01_001.jpg)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![图1.1 – 数据科学开发生命周期包括三个主要阶段——数据准备、建模和部署](img/B17875_01_001.jpg)'
- en: Figure 1.1 – The data science development life cycle consists of three main
    stages – data preparation, modeling, and deployment
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.1 – 数据科学开发生命周期包括三个主要阶段——数据准备、建模和部署
- en: Note
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'Source: [https://azure.microsoft.com/mediahandler/files/resourcefiles/standardizing-the-machine-learning-lifecycle/Standardizing%20ML%20eBook.pdf](https://azure.microsoft.com/mediahandler/files/resourcefiles/standardizing-the-machine-learning-lifecycle/Standardizing%20ML%20eBook.pdf).'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '来源: [https://azure.microsoft.com/mediahandler/files/resourcefiles/standardizing-the-machine-learning-lifecycle/Standardizing%20ML%20eBook.pdf](https://azure.microsoft.com/mediahandler/files/resourcefiles/standardizing-the-machine-learning-lifecycle/Standardizing%20ML%20eBook.pdf).'
- en: It is an iterative process. The raw structured and unstructured data first lands
    into a data lake from different sources. A data lake utilizes the scalable and
    cheap storage provided by cloud storage such as **Amazon Simple Storage Service**
    (**S3**) or **Azure Data Lake Storage** (**ADLS**), depending on which cloud provider
    an organization uses. Due to regulations, many organizations have a multi-cloud
    strategy, making it essential to choose cloud-agnostic technologies and frameworks
    to simplify infrastructure management and reduce operational overhead.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一种迭代过程。原始的结构化和非结构化数据首先从不同的来源进入数据湖。数据湖利用云存储提供的可扩展且低成本的存储服务，例如**Amazon 简单存储服务**（**S3**）或**Azure
    数据湖存储**（**ADLS**），具体取决于组织使用的云服务商。由于法规要求，许多组织采用多云策略，这使得选择云中立的技术和框架变得至关重要，从而简化基础设施管理并降低运营成本。
- en: 'Databricks defined a design pattern called the medallion architecture to organize
    data in a data lake. Before moving forward, let’s briefly understand what the
    medallion architecture is:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: Databricks 定义了一种名为勋章架构的数据湖组织设计模式。在继续之前，我们先简要了解一下什么是勋章架构：
- en: '![Figure 1.2 – Databricks medallion architecture](img/B17875_01_002.jpg)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.2 – Databricks 勋章架构](img/B17875_01_002.jpg)'
- en: Figure 1.2 – Databricks medallion architecture
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.2 – Databricks 勋章架构
- en: The medallion architecture is a data design pattern that’s used in a Lakehouse
    to organize data logically. It involves structuring data into layers (Bronze,
    Silver, and Gold) to progressively improve its quality and structure. The medallion
    architecture is also referred to as a “multi-hop” architecture.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 勋章架构是一种数据设计模式，用于在湖仓中逻辑地组织数据。它通过将数据结构化为多个层次（铜层、银层和金层）来逐步改善数据的质量和结构。勋章架构也被称为“多跳”架构。
- en: The Lakehouse architecture, which combines the best features of data lakes and
    data warehouses, offers several benefits, including a simple data model, ease
    of implementation, incremental **extract, transform, and load** (**ETL**), and
    the ability to recreate tables from raw data at any time. It also provides features
    such as ACID transactions and time travel for data versioning and historical analysis.
    We will expand more on the lakehouse in the *Exploring the Databricks Lakehouse*
    *architecture* section.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 湖仓架构结合了数据湖和数据仓库的最佳特性，提供了多个优点，包括简单的数据模型、易于实现、增量的**提取、转换和加载**（**ETL**）以及能够随时从原始数据重新创建表格的能力。它还提供了诸如
    ACID 事务和数据版本控制与历史分析的时间旅行等功能。我们将在*探索 Databricks 湖仓* *架构* 部分进一步展开湖仓的内容。
- en: In the medallion architecture, the Bronze layer holds raw data sourced from
    external systems, preserving its original structure along with additional metadata.
    The focus here is on quick **change data capture** (**CDC**) and maintaining a
    historical archive. The Silver layer, on the other hand, houses cleansed, conformed,
    and “just enough” transformed data. It provides an enterprise-wide view of key
    business entities and serves as a source for self-service analytics, ad hoc reporting,
    and advanced analytics.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在勋章架构中，铜层保存从外部系统获取的原始数据，保留其原始结构以及附加的元数据。这里的重点是快速的**变更数据捕获**（**CDC**）和维护历史档案。银层则存放经过清洗、符合标准的以及“恰好足够”转换后的数据。它提供了一个企业范围内的关键业务实体视图，并作为自助分析、临时报告和高级分析的来源。
- en: The Gold layer is where curated business-level tables reside that have been
    organized for consumption and reporting purposes. This layer utilizes denormalized,
    read-optimized data models with fewer joins. Complex transformations and data
    quality rules are applied here, facilitating the final presentation layer for
    various projects, such as customer analytics, product quality analytics, inventory
    analytics, and more. Traditional data marts and **enterprise data warehouses**
    (**EDWs**) can also be integrated into the lakehouse to enable comprehensive “pan-EDW”
    advanced analytics and ML.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 黄金层是精心策划的业务级表所在的位置，这些表已经为消费和报告目的进行了组织。该层使用去规范化、读优化的数据模型，减少了连接操作。这里应用了复杂的转换和数据质量规则，为各种项目提供了最终的展示层，如客户分析、产品质量分析、库存分析等。传统的数据集市和**企业数据仓库**（**EDWs**）也可以集成到湖仓中，以支持全面的“全企业数据仓库”高级分析和机器学习。
- en: The medallion architecture aligns well with the concept of a data mesh, where
    Bronze and Silver tables can be joined in a “one-to-many” fashion to generate
    multiple downstream tables, enhancing data scalability and autonomy.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 宝石架构与数据网格的概念非常契合，其中铜层和银层表可以以“一对多”的方式进行连接，生成多个下游表，从而提升数据的可扩展性和自主性。
- en: Apache Spark has taken over Hadoop as the *de facto* standard for processing
    data at scale in the last six years due to advancements in performance and large-scale
    developer community adoption and support. There are many excellent books on Apache
    Spark written by the creators of Apache Spark themselves; these have been listed
    in the *Further reading* section. They can give more insights into the other benefits
    of Apache Spark.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去六年里，Apache Spark因性能提升和大规模开发者社区的采纳与支持，已经取代了Hadoop，成为处理大规模数据的*事实上的*标准。关于Apache
    Spark，有许多由Apache Spark的创造者亲自撰写的优秀书籍；这些书籍已经列在了*进一步阅读*部分。它们能为你提供更多关于Apache Spark其他好处的见解。
- en: Once the clean data lands in the Gold standard tables, features are generated
    by combining gold datasets, which act as input for ML model training.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦清洗后的数据进入金标准表，特征便通过结合黄金数据集生成，这些数据集作为机器学习模型训练的输入。
- en: During the model development and training phase, various sets of **hyperparameters**
    and ML algorithms are tested to identify the optimal combination of the model
    and corresponding hyperparameters. This process relies on predetermined evaluation
    metrics such as accuracy, R2 score, and F1 score.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型开发和训练阶段，会测试不同的**超参数**和机器学习算法，以确定模型及其相应超参数的最佳组合。这个过程依赖于预先确定的评估指标，如准确率、R2分数和F1分数。
- en: In the context of ML, hyperparameters are parameters that govern the learning
    process of a model. They are not learned from the data itself but are set before
    training. Examples of hyperparameters include the learning rate, regularization
    strength, number of hidden layers in a neural network, or the choice of a kernel
    function in a support vector machine. Adjusting these hyperparameters can significantly
    impact the performance and behavior of the model.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习的背景下，超参数是控制模型学习过程的参数。它们不是从数据中学习到的，而是在训练之前设置的。超参数的例子包括学习率、正则化强度、神经网络中的隐藏层数，或支持向量机中核函数的选择。调整这些超参数会显著影响模型的表现和行为。
- en: On the other hand, training an ML model involves deriving values for other **model
    parameters**, such as node weights or model coefficients. These parameters are
    learned during the training process using the training data to minimize a chosen
    loss or error function. They are specific to the model being trained and are determined
    iteratively through optimization techniques such as gradient descent or closed-form
    solutions.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，训练一个机器学习模型涉及推导其他**模型参数**的值，如节点权重或模型系数。这些参数是在训练过程中使用训练数据学习的，通过最小化选择的损失或误差函数来优化。它们特定于所训练的模型，并通过梯度下降或闭式解等优化技术迭代确定。
- en: Expanding beyond node weights, model parameters can also include coefficients
    in regression models, intercept terms, feature importance scores in decision trees,
    or filter weights in convolutional neural networks. These parameters are directly
    learned from the data during the training process and contribute to the model’s
    ability to make predictions.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 超越节点权重，模型参数还可以包括回归模型中的系数、截距项、决策树中的特征重要性评分，或卷积神经网络中的滤波器权重。这些参数在训练过程中直接从数据中学习，并有助于模型进行预测。
- en: Parameters
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: You can learn more about parameters at [https://en.wikipedia.org/wiki/Parameter](https://en.wikipedia.org/wiki/Parameter).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[https://en.wikipedia.org/wiki/Parameter](https://en.wikipedia.org/wiki/Parameter)了解更多关于参数的信息。
- en: The finalized model is deployed either for batch, streaming, or real-time inference
    as a **Representational State Transfer** (**REST**) endpoint using containers.
    In this phase, we set up monitoring for drift and governance around the deployed
    models to manage the model life cycle and enforce access control around usage.
    Let’s take a look at the different personas involved in taking an ML use case
    from development to production.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 完成的模型将作为**表现状态转移**（**REST**）端点，通过容器进行批处理、流处理或实时推理部署。在此阶段，我们会设置监控机制以检测漂移并对已部署的模型进行治理，以便管理模型生命周期并强制执行使用控制。让我们看一下在将机器学习用例从开发阶段推向生产的过程中，涉及的不同角色。
- en: Discovering the roles associated with machine learning projects in organizations
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 发现组织中与机器学习项目相关的角色
- en: 'Typically, three different types of persona are involved in developing an ML
    solution in an organization:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，开发机器学习解决方案的过程中，涉及三种不同类型的角色：
- en: '**Data engineers**: The data engineers create data pipelines that take in structured,
    semi-structured, and unstructured data from source systems and ingest them in
    a data lake. Once the raw data lands in the data lake, the data engineers are
    also responsible for securely storing the data, ensuring that the data is reliable,
    clean, and easy to discover and utilize by the users in the organization.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据工程师**：数据工程师创建数据管道，将来自源系统的结构化、半结构化和非结构化数据导入数据湖。一旦原始数据进入数据湖，数据工程师还负责安全地存储数据，确保数据可靠、干净，并且易于组织中用户发现和使用。'
- en: '**Data scientists**: Data scientists collaborate with **subject matter experts**
    (**SMEs**) to understand and address business problems, ensuring a solid business
    justification for projects. They utilize clean data from data lakes and perform
    feature engineering, selecting and transforming relevant features. By developing
    and training multiple ML models with different sets of hyperparameters, data scientists
    can evaluate them on test sets to identify the best-performing model. Throughout
    this process, collaboration with SMEs validates the models against business requirements,
    ensuring their alignment with objectives and **key performance indicators** (**KPIs**).
    This iterative approach helps data scientists select a model that effectively
    solves the problem and meets the specified KPIs.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据科学家**：数据科学家与**主题专家**（**SME**）合作，理解和解决业务问题，确保项目有充分的业务理由。他们利用来自数据湖的清洗数据，进行特征工程，选择并转换相关特征。通过使用不同超参数集开发和训练多个机器学习模型，数据科学家可以在测试集上评估这些模型，以识别最佳表现的模型。在整个过程中，与主题专家的合作帮助验证模型是否符合业务需求，确保其与目标和**关键绩效指标**（**KPI**）的一致性。这种迭代的方法帮助数据科学家选择一个有效解决问题并满足指定KPI的模型。'
- en: '**Machine learning engineers**: The ML engineering teams deploy the ML models
    created by data scientists into production environments. It is crucial to establish
    procedures, governance, and access control early on, including defining data scientist
    access to specific environments and data. ML engineers also implement monitoring
    systems to track model performance and data drift. They enforce governance practices,
    track model lineage, and ensure access control for data security and compliance
    throughout the ML life cycle.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**机器学习工程师**：机器学习工程团队将数据科学家创建的机器学习模型部署到生产环境中。关键是尽早建立程序、治理和访问控制，包括定义数据科学家对特定环境和数据的访问权限。机器学习工程师还会实施监控系统来跟踪模型性能和数据漂移。他们执行治理实践，跟踪模型血统，并确保在整个机器学习生命周期中实施数据安全性和合规性访问控制。'
- en: A typical ML project life cycle consists of data engineering, then data science,
    and lastly, production deployment by the ML engineering team. This is an iterative
    process.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 一个典型的机器学习项目生命周期包括数据工程、数据科学，然后是机器学习工程团队的生产部署。这是一个迭代过程。
- en: Now, let’s take a look at the various challenges involved in productionizing
    ML models.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来看一下在将机器学习模型投入生产过程中所面临的各种挑战。
- en: Challenges with productionizing machine learning use cases in organizations
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 组织在将机器学习用例投入生产过程中面临的挑战
- en: At this point, we understand what a typical ML project life cycle looks like
    in an organization and the different personas involved in the ML process. It looks
    very intuitive, though we still see many enterprises struggling to deliver business
    value from their data science projects.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，我们已经了解了组织中典型的机器学习（ML）项目生命周期及参与其中的不同角色。虽然看起来很直观，但我们仍然看到许多企业在从数据科学项目中交付商业价值时遇到困难。
- en: In 2017, Gartner analyst Nick Heudecker admitted that 85% of data science projects
    fail. A report published by **Dimensional Research** ([https://dimensionalresearch.com/](https://dimensionalresearch.com/))
    also uncovered that only 4% of companies have been successful in deploying ML
    use cases to production. A recent study done by Rackspace Global Technologies
    in 2021 uncovered that only 20% of the 1,870 organizations in various industries
    have mature AI and ML practices.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 2017年，Gartner 分析师 Nick Heudecker 承认，85%的数据科学项目失败。**Dimensional Research**（[https://dimensionalresearch.com/](https://dimensionalresearch.com/)）发布的一份报告也揭示，仅有4%的公司成功将机器学习（ML）应用案例投入生产。Rackspace
    Global Technologies 在2021年进行的一项研究显示，来自各行各业的1,870家组织中，只有20%的组织在人工智能（AI）和机器学习（ML）方面有成熟的实践。
- en: Sources
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 来源
- en: See the *Further reading* section for more details on these statistics.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 有关这些统计数据的更多细节，请参见*进一步阅读*部分。
- en: 'Most enterprises face some common technical challenges in successfully delivering
    business value from data science projects:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数企业在成功交付数据科学项目的商业价值时面临一些共同的技术挑战：
- en: '**Unintended data silos and messy data**: Data silos can be considered as groups
    of data in an organization that are governed and accessible only by specific users
    or groups within the organization. Some valid reasons to have data silos include
    compliance with particular regulations around privacy laws such as **General Data
    Protection Regulation** (**GDPR**) in Europe or the **California Privacy Rights
    Act** (**CCPA**). These conditions are usually an exception to the norm. Gartner
    stated that almost 87% of organizations have low analytics and business intelligence
    maturity, meaning that data is not being fully utilized.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无意的数据孤岛和杂乱的数据**：数据孤岛可以被看作是组织中由特定用户或小组管理和访问的数据集合。存在数据孤岛的一些合理原因包括遵守特定的隐私法相关规定，如欧洲的**通用数据保护条例**(**GDPR**)或**加利福尼亚隐私权法案**(**CCPA**)等。这些情况通常是例外而非常规。Gartner
    曾表示，几乎87%的组织在分析和商业智能的成熟度上较低，这意味着数据并未得到充分利用。'
- en: Data silos generally arise as different departments within organizations. They
    have different technology stacks to manage and process the data.
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 数据孤岛通常出现在组织内部的不同部门，它们有不同的技术栈来管理和处理数据。
- en: 'The following figure highlights this challenge:'
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下图突出了这一挑战：
- en: '![Figure 1.3 – The tools used by the different teams in an organization and
    the different silos](img/Figure_01.3_B17875.jpg)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.3 – 组织中不同团队使用的工具和不同的数据孤岛](img/Figure_01.3_B17875.jpg)'
- en: Figure 1.3 – The tools used by the different teams in an organization and the
    different silos
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.3 – 组织中不同团队使用的工具和不同的数据孤岛
- en: The different personas work with different sets of tools and have different
    work environments. Data analysts, data engineers, data scientists, and ML engineers
    utilize different tools and development environments due to their distinct roles
    and objectives. Data analysts rely on SQL, spreadsheets, and visualization tools
    for insights and reporting. Data engineers work with programming languages and
    platforms such as Apache Spark to build and manage data infrastructure. Data scientists
    use statistical programming languages, ML frameworks, and data visualization libraries
    to develop predictive models. ML engineers combine ML expertise with software
    engineering skills to deploy models into production systems. These divergent toolsets
    can pose challenges in terms of data consistency, tool compatibility, and collaboration.
    Standardized processes and knowledge sharing can help mitigate these challenges
    and foster effective teamwork. Traditionally, there is little to no collaboration
    between these teams. As a result, a data science use case with a validated business
    value may not be developed at the required pace, negatively impacting the growth
    and effective management of the business.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 不同的角色使用不同的工具集，并且有不同的工作环境。数据分析师、数据工程师、数据科学家和 ML 工程师由于各自的角色和目标，使用不同的工具和开发环境。数据分析师依赖
    SQL、电子表格和可视化工具来获取洞察和报告。数据工程师使用编程语言和平台，如 Apache Spark，来构建和管理数据基础设施。数据科学家使用统计编程语言、ML
    框架和数据可视化库来开发预测模型。ML 工程师将 ML 专业知识与软件工程技能相结合，将模型部署到生产系统中。这些不同的工具集可能在数据一致性、工具兼容性和协作方面带来挑战。标准化的流程和知识共享可以帮助减轻这些挑战，促进有效的团队合作。传统上，这些团队之间几乎没有合作。因此，一个具有验证商业价值的数据科学用例可能无法以所需的速度开发，从而对业务的增长和有效管理产生负面影响。
- en: When the concept of data lakes came up in the past decade, they promised a scalable
    and cheap solution to support structured and unstructured data. The goal was to
    enable organization-wide effective usage and collaboration of data. In reality,
    most data lakes ended up becoming data swamps, with little to no governance regarding
    the quality of data.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 当过去十年提出数据湖的概念时，它们承诺提供一种可扩展且廉价的解决方案，支持结构化和非结构化数据。目标是使数据能够在整个组织中有效使用和协作。然而，实际上，大多数数据湖最终变成了数据沼泽，几乎没有关于数据质量的治理。
- en: This inherently made ML very difficult since an ML model is only as good as
    the data it’s trained on.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这本质上使得 ML 变得非常困难，因为一个 ML 模型的质量仅仅取决于它所训练的数据。
- en: '**Building and managing an effective ML production environment is challenging**:
    The ML teams at Google have done a lot of research on the technical challenges
    around setting up an ML development environment. A research paper published in
    NeurIPS on hidden technical debt in ML systems engineering from Google ([https://proceedings.neurips.cc/paper/2015/file/86df7dcfd896fcaf2674f757a2463eba-Paper.pdf](https://proceedings.neurips.cc/paper/2015/file/86df7dcfd896fcaf2674f757a2463eba-Paper.pdf))
    documented that writing ML code is just a tiny piece of the whole ML development
    life cycle. To develop an effective ML development practice in an organization,
    many tools, configurations, and monitoring aspects need to be integrated into
    the overall architecture. One of the critical components is monitoring drift in
    model performance and providing feedback and retraining:'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**构建和管理一个有效的 ML 生产环境是具有挑战性的**：Google 的 ML 团队在设置 ML 开发环境时，围绕技术挑战进行了大量研究。Google
    在 NeurIPS 上发布的一篇关于 ML 系统工程中隐性技术债务的研究论文（[https://proceedings.neurips.cc/paper/2015/file/86df7dcfd896fcaf2674f757a2463eba-Paper.pdf](https://proceedings.neurips.cc/paper/2015/file/86df7dcfd896fcaf2674f757a2463eba-Paper.pdf)）记录了编写
    ML 代码只是整个 ML 开发生命周期中的一小部分。为了在一个组织中发展有效的 ML 开发实践，需要将多个工具、配置和监控方面整合到整体架构中。一个关键的组成部分是监控模型性能的漂移并提供反馈和再训练：'
- en: '![Figure 1.4 – Hidden Technical Debt in Machine Learning Systems, NeurIPS 2015](img/Figure_01.4_B17875.jpg)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.4 – 机器学习系统中的隐性技术债务，NeurIPS 2015](img/Figure_01.4_B17875.jpg)'
- en: Figure 1.4 – Hidden Technical Debt in Machine Learning Systems, NeurIPS 2015
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.4 – 机器学习系统中的隐性技术债务，NeurIPS 2015
- en: Let’s understand the requirements of an enterprise-grade ML platform a bit more.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更深入地理解企业级 ML 平台的需求。
- en: Understanding the requirements of an enterprise-grade machine learning platform
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解企业级机器学习平台的需求
- en: In the fast-paced world of **artificial intelligence** (**AI**) and ML, an enterprise-grade
    ML platform takes center stage as a critical component. It is a comprehensive
    software platform that offers the infrastructure, tools, and processes required
    to construct, deploy, and manage ML models at a grand scale. However, a truly
    robust ML platform goes beyond these capabilities, extending to every stage of
    the ML life cycle, from data preparation, model training, and deployment to constant
    monitoring and improvements.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在快速发展的**人工智能**（**AI**）和机器学习（ML）领域，企业级机器学习平台作为关键组成部分，处于核心地位。它是一个综合软件平台，提供构建、部署和管理大规模机器学习模型所需的基础设施、工具和流程。然而，一个真正强大的机器学习平台超越了这些能力，涵盖了机器学习生命周期的每个阶段，从数据准备、模型训练和部署到持续监控和改进。
- en: When we speak of an enterprise-grade ML platform, several key attributes determine
    its effectiveness, each of which is considered a cornerstone of such platforms.
    Let’s delve deeper into each of these critical requirements and understand their
    significance in an enterprise setting.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们谈论企业级机器学习（ML）平台时，有几个关键特性决定了其有效性，这些特性每一个都是此类平台的基石。让我们深入探讨这些关键需求，并理解它们在企业环境中的重要性。
- en: Scalability – the growth catalyst
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可扩展性 – 增长催化剂
- en: Scalability is an essential attribute, enabling the platform to adapt to the
    expanding needs of a burgeoning organization. In the context of ML, this encompasses
    the capacity to handle voluminous datasets, manage multiple models simultaneously,
    and accommodate a growing number of concurrent users. As the organization’s data
    grows exponentially, the platform must have the capability to expand and efficiently
    process the increasing data without compromising performance.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 可扩展性是一个至关重要的特性，使平台能够适应快速发展的组织需求。在机器学习的背景下，这包括处理海量数据集的能力，管理多个模型的能力，以及容纳越来越多并发用户的能力。随着组织数据量的指数级增长，平台必须具备扩展能力，并高效处理不断增加的数据，同时不降低性能。
- en: Performance – ensuring efficiency and speed
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 性能 – 确保效率和速度
- en: In a real-world enterprise setting, the ML platform’s performance directly influences
    business operations. It should possess the capability to deliver high performance
    both in the training and inference stages. These stages are critical to ensure
    that models can be efficiently trained with minimum resources, and then deployed
    into production environments, ready to make timely and accurate predictions. A
    high-performance platform translates to faster decisions, and in today’s fast-paced
    business world, every second counts.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在现实世界的企业环境中，机器学习平台的性能直接影响业务运营。它应当具备在训练和推理阶段提供高性能的能力。这些阶段对确保模型能够用最少的资源高效训练，并且在生产环境中部署，做好及时且准确的预测至关重要。一个高性能的平台意味着更快的决策，而在当今快节奏的商业世界中，每一秒都至关重要。
- en: Security – safeguarding data and models
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安全性 – 保护数据和模型
- en: In an era where data breaches are common, an ML platform’s security becomes
    a paramount concern. A robust ML platform should prioritize security and comply
    with industry regulations. This involves an assortment of features such as stringent
    data encryption techniques, access control mechanisms to prevent unauthorized
    access, and auditing capabilities to track activities in the system, all of which
    contribute to securely handling sensitive data and ML models.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据泄露时有发生的时代，机器学习平台的安全性变得尤为重要。一个强大的机器学习平台应当优先考虑安全性，并遵守行业法规。这涉及多种功能，例如严格的数据加密技术、访问控制机制以防止未经授权的访问，以及审计功能以跟踪系统中的活动，所有这些功能共同作用，确保安全地处理敏感数据和机器学习模型。
- en: Governance – steering the machine learning life cycle
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 治理 – 驾驶机器学习生命周期
- en: Governance is an often overlooked yet vital attribute of an enterprise-grade
    ML platform. Effective governance tools can facilitate the management of the entire
    life cycle of ML models. They can control versioning, maintain lineage tracking
    to understand the evolution of models, and audit for regulatory compliance and
    transparency. As the complexity of ML projects increases, governance tools ensure
    smooth sailing by managing the models and maintaining a clean and understandable
    system.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 治理是一个经常被忽视但至关重要的企业级机器学习平台特性。有效的治理工具可以促进机器学习模型生命周期的管理。它们可以控制版本管理，维护模型的演变追踪，并进行审计以确保符合监管要求和透明度。随着机器学习项目复杂性的增加，治理工具通过管理模型和维护清晰可理解的系统，确保顺利运行。
- en: Reproducibility – ensuring trust and consistency
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可重复性 – 确保信任和一致性
- en: Reproducibility serves as a foundation for trust in any ML model. The ML platform
    should ensure the reproducibility of the results from ML experiments, thereby
    establishing credibility and confidence in the models. This means that given the
    same data and the same conditions, the model should produce the same outputs consistently.
    Reproducibility directly impacts the decision-making process, ensuring the decisions
    are consistent and reliable, and the models can be trusted.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 可重现性是任何机器学习（ML）模型可信度的基础。ML平台应确保实验结果的可重现性，从而建立模型的可信度和信任感。这意味着在相同的数据和条件下，模型应该始终如一地生成相同的输出。可重现性直接影响决策过程，确保决策的一致性和可靠性，同时使模型值得信赖。
- en: Ease of use – balancing complexity and usability
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 易用性——平衡复杂性与可用性
- en: Last, but by no means least, is the ease of use of the ML platform. Despite
    the inherent complexity of ML processes, the platform should be intuitive and
    user-friendly for a wide range of users, from data scientists to ML engineers.
    This extends to features such as a streamlined user interface, a well-documented
    API, and a user-centric design, making it easier for users to develop, deploy,
    and manage models. An easy-to-use platform reduces the barriers to entry, increases
    adoption, and empowers users to focus more on the ML tasks at hand rather than
    struggling with the platform.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 最后但同样重要的是，ML 平台的易用性。尽管 ML 过程本身具有内在复杂性，但该平台应当直观且用户友好，适合各种用户使用，从数据科学家到 ML 工程师。这包括流畅的用户界面、完善的
    API 文档和以用户为中心的设计，使用户在开发、部署和管理模型时更加轻松。易用的平台降低了入门门槛，提高了采用率，并使用户能够更多地专注于 ML 任务本身，而不是为平台而苦恼。
- en: In essence, an enterprise MLOps platform needs capabilities for model development,
    deployment, scalability, collaboration, monitoring, and automation. Databricks
    fits in by offering a unified environment for ML practitioners to develop and
    train models, deploy them at scale, and monitor their performance. It supports
    collaboration, integrates with popular deployment technologies, and provides automation
    and CI/CD capabilities.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 从本质上讲，企业级 MLOps 平台需要具备模型开发、部署、可扩展性、协作、监控和自动化的能力。Databricks 通过提供一个统一的环境，帮助 ML
    从业者开发和训练模型，按需大规模部署，并监控其性能。它支持协作，整合流行的部署技术，并提供自动化和 CI/CD 能力。
- en: Now, let’s delve deeper into the capabilities of the Databricks Lakehouse architecture
    and its unified AI/analytics platform, which establish it as an exceptional ML
    platform for enterprise readiness.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们深入了解 Databricks 湖仓架构及其统一的人工智能/分析平台，这使其成为一个卓越的企业级 ML 平台。
- en: Exploring Databricks and the Lakehouse architecture
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索 Databricks 和湖仓架构
- en: Databricks is a renowned cloud-native and enterprise-ready data analytics platform
    that integrates data engineering, data science, and ML to enable organizations
    to develop and deploy ML models at scale.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: Databricks 是一个著名的云原生、企业级数据分析平台，它将数据工程、数据科学和机器学习（ML）整合在一起，帮助组织大规模开发和部署 ML 模型。
- en: Cloud-native refers to an approach where software applications are designed,
    developed, and deployed specifically for cloud environments. It involves utilizing
    technologies such as containers, microservices, and orchestration platforms to
    achieve scalability, resilience, and agility. By leveraging the cloud’s capabilities,
    Databricks can scale dynamically, recover from failures, and adapt quickly to
    changing demands, enabling organizations to maximize the benefits of cloud computing.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 云原生指的是一种特定为云环境设计、开发和部署的软件应用程序方法。它涉及使用容器、微服务和编排平台等技术来实现可扩展性、韧性和敏捷性。通过利用云的能力，Databricks
    可以动态扩展，恢复故障，并快速适应变化的需求，帮助组织最大化云计算的优势。
- en: Databricks achieves the six cornerstones of an enterprise-grade ML platform.
    Let’s take a closer look.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: Databricks 实现了企业级 ML 平台的六大基石。让我们来更详细地看看。
- en: Scalability – the growth catalyst
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可扩展性——增长催化剂
- en: Databricks provides fully managed Apache Spark (an open source distributed computing
    system known for its ability to handle large volumes of data and perform computations
    in a distributed manner) clusters.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: Databricks 提供完全托管的 Apache Spark（一个开源的分布式计算系统，以其处理大量数据和分布式计算的能力而闻名）集群。
- en: Apache Spark consists of several components, including nodes and a driver program.
    **Nodes** refer to the individual machines or servers within the Spark cluster
    that contribute computational resources. The **driver** program is responsible
    for running the user’s application code and coordinating the overall execution
    of the Spark job. It communicates with the **cluster manager** to allocate resources
    and manages the **SparkContext**, which serves as the entry point to the Spark
    cluster. **RDDs** are the core data structure, enabling parallel processing, and
    Spark uses a **directed acyclic graph** (**DAG**) to optimize computations. **Transformations**
    and **actions** are performed on RDDs, while cluster managers handle resource
    allocation. Additionally, caching and shuffling enhance performance.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Spark 由多个组件组成，包括节点和驱动程序。**节点**指的是 Spark 集群中贡献计算资源的单独机器或服务器。**驱动程序**负责运行用户的应用程序代码，并协调
    Spark 作业的整体执行。它与 **集群管理器** 通信，以分配资源，并管理 **SparkContext**，它作为访问 Spark 集群的入口点。**RDDs**
    是核心数据结构，支持并行处理，Spark 使用 **有向无环图**（**DAG**）来优化计算。**转换**和 **操作** 在 RDD 上执行，而集群管理器处理资源分配。此外，缓存和洗牌操作提升了性能。
- en: The **DataFrames** API in Spark is a distributed collection of data that’s organized
    into named columns. It provides a higher-level abstraction compared to working
    directly with RDDs in Spark, making it easier to manipulate and analyze structured
    data. It supports a SQL-like syntax and provides a wide range of functions for
    data manipulation and transformation.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: Spark 中的 **DataFrames** API 是一个分布式数据集合，组织为命名的列。与直接操作 Spark 中的 RDD 相比，它提供了更高级的抽象，使得操作和分析结构化数据变得更容易。它支持类似
    SQL 的语法，并提供了丰富的数据操作和转换功能。
- en: Spark provides APIs in various languages, including Scala, Java, Python, and
    R, allowing users to leverage their existing skills and choose the language they
    are most comfortable with.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: Spark 提供了多种语言的 API，包括 Scala、Java、Python 和 R，允许用户利用现有技能并选择他们最熟悉的语言。
- en: Apache Spark processes large datasets across multiple nodes, making it highly
    scalable. It supports both streaming and batch processing. This means that you
    can use Spark to process real-time data streams as well as large-scale batch jobs.
    Spark Structured Streaming, a component of Spark, allows you to process live data
    streams in a scalable and fault-tolerant manner. It provides high-level abstractions
    that make it easy to write streaming applications using familiar batch processing
    concepts.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Spark 在多个节点上处理大规模数据集，使其具有高度可扩展性。它支持流处理和批处理。这意味着你可以使用 Spark 处理实时数据流以及大规模批处理作业。Spark
    结构化流处理（Spark Structured Streaming）是 Spark 的一个组件，允许你以可扩展和容错的方式处理实时数据流。它提供了高级抽象，使得使用熟悉的批处理概念编写流处理应用程序变得更加容易。
- en: Furthermore, Databricks allows for dynamic scaling and autoscaling of clusters,
    which adjusts resources based on the workload, ensuring the efficient use of resources
    while accommodating growing organizational needs.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，Databricks 允许集群动态扩展和自动扩展，根据工作负载调整资源，确保高效利用资源，同时满足组织日益增长的需求。
- en: While this book doesn’t delve into Apache Spark in detail, we have curated a
    *Further reading* section with excellent recommendations that will help you explore
    Apache Spark more comprehensively.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管本书没有详细讲解 Apache Spark，但我们整理了一个*进一步阅读*部分，提供了优秀的推荐书单，帮助你更全面地探索 Apache Spark。
- en: Performance – ensuring efficiency and speed
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 性能 – 确保效率和速度
- en: Databricks Runtime is optimized for the cloud and includes enhancements over
    open source Apache Spark that significantly increase performance. The Databricks
    Delta engine provides fast query execution for big data and AI workflows while
    reducing the time and resources needed for data preparation and iterative model
    training. Its optimized runtime improves both model training and inference speeds,
    resulting in more efficient operations.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: Databricks Runtime 针对云环境进行了优化，并且在开源 Apache Spark 的基础上进行了增强，显著提升了性能。Databricks
    Delta 引擎为大数据和 AI 工作流提供了快速查询执行，同时减少了数据准备和迭代模型训练所需的时间和资源。其优化的运行时提高了模型训练和推理的速度，从而提升了操作效率。
- en: Security – safeguarding data and models
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安全性 – 保护数据和模型
- en: Databricks ensures a high level of security through various means. It offers
    data encryption at rest and in transit, uses **role-based access control** (**RBAC**)
    to provide fine-grained user permissions, and integrates with identity providers
    for **single** **sign-on** (**SSO**).
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: Databricks 通过多种方式确保高级别安全性。它提供数据静态和传输加密，在用户权限方面使用**基于角色的访问控制**（**RBAC**），并与身份提供者集成实现**单点登录**（**SSO**）。
- en: Databricks also has a feature called Unity Catalog. Unity Catalog is a centralized
    metadata store for Databricks workspaces that offers data governance capabilities
    such as access control, auditing, lineage, and data discovery. Its key features
    include centralized governance, a universal security model, automated lineage
    tracking, and easy data discovery. Its benefits include improved governance, reduced
    operational overhead, and increased data agility. Unity Catalog is a powerful
    tool for enhancing data governance in Databricks. Unity Catalog is a complex topic
    that will not be covered extensively in this book. However, you can find more
    information on it in the *Further reading* section, where a link has been provided.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: Databricks 还有一个名为 Unity Catalog 的功能。Unity Catalog 是 Databricks 工作空间的集中式元数据存储，提供数据治理功能，如访问控制、审计、血统和数据发现。其主要特点包括集中式治理、统一安全模型、自动化血统追踪和简便的数据发现。其优点包括改善治理、降低运营开销和增强数据灵活性。Unity
    Catalog 是增强 Databricks 数据治理的强大工具。Unity Catalog 是本书中不会详细涵盖的复杂主题。但是，你可以在*进一步阅读*部分找到更多信息，提供了链接。
- en: The Databricks platform is compliant with several industry regulations, including
    GDPR, CCPA, HIPAA, SOC 2 Type II, and ISO/IEC 27017\. For a complete list of certifications,
    check out [https://www.databricks.com/trust/compliance](https://www.databricks.com/trust/compliance).
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: Databricks 平台符合多个行业法规，包括 GDPR、CCPA、HIPAA、SOC 2 Type II 和 ISO/IEC 27017\. 完整的认证列表，请查看
    [https://www.databricks.com/trust/compliance](https://www.databricks.com/trust/compliance)。
- en: Governance – steering the machine learning life cycle
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 治理 - 引导机器学习生命周期
- en: Databricks provides MLflow, an open source platform for managing the ML life
    cycle, including experimentation, reproducibility, and deployment. It supports
    model versioning and model registry for tracking model versions and their stages
    in the life cycle (staging, production, and others). Additionally, the platform
    provides audit logs for tracking user activity, helping meet regulatory requirements
    and promoting transparency. Databricks has its own hosted feature store as well,
    which we will cover in more detail in later chapters.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: Databricks 提供 MLflow，这是一个管理机器学习生命周期的开源平台，包括实验、可复现性和部署。它支持模型版本控制和模型注册，跟踪模型在生命周期中的阶段（暂存、生产等）。此外，该平台提供审计日志以跟踪用户活动，帮助满足监管要求并促进透明度。Databricks
    还拥有自己托管的特征存储，我们将在后面的章节中详细介绍。
- en: Reproducibility – ensuring trust and consistency
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可复现性 - 确保信任和一致性
- en: With MLflow, Databricks ensures the reproducibility of ML models. MLflow allows
    users to log parameters, metrics, and artifacts for each run of an experiment,
    providing a record of what was done and allowing for exact replication of the
    results. It also supports packaging code into reproducible runs and sharing it
    with others, further ensuring the repeatability of experiments.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 MLflow，Databricks 确保了 ML 模型的可复现性。MLflow 允许用户记录每次实验运行的参数、指标和工件，提供了完成的操作记录，允许精确复制结果。它还支持将代码打包到可复现的运行中，并与他人共享，进一步确保实验的可重复性。
- en: Ease of use – balancing complexity and usability
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用便捷性 - 平衡复杂性和可用性
- en: Databricks provides a collaborative workspace that enables data scientists and
    engineers to work together seamlessly. It offers interactive notebooks with support
    for multiple languages (Python, R, SQL, and Scala) in a single notebook, allowing
    users to use their preferred language. The platform’s intuitive interface, coupled
    with extensive documentation and a robust API, makes it user-friendly, enabling
    users to focus more on ML tasks rather than the complexities of platform management.
    In addition to its collaborative and analytical capabilities, Databricks integrates
    with various data sources, storage systems, and cloud platforms, making it flexible
    and adaptable to different data ecosystems. It supports seamless integration with
    popular data lakes, databases, and cloud storage services, enabling users to easily
    access and process data from multiple sources. Although this book specifically
    focuses on the ML and MLOps capabilities of Databricks, it makes sense to understand
    what the Databricks Lakehouse architecture is and how it simplifies scaling and
    managing ML project life cycles for organizations.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: Databricks 提供了一个协作工作空间，使数据科学家和工程师能够无缝协作。它提供了支持多种语言（Python、R、SQL 和 Scala）的交互式笔记本，允许用户使用他们偏好的语言。该平台直观的界面，加上丰富的文档和强大的
    API，使其易于使用，帮助用户更专注于机器学习任务，而不是平台管理的复杂性。除了协作和分析能力外，Databricks 还与各种数据源、存储系统和云平台集成，使其灵活且适应不同的数据生态系统。它支持与流行的数据湖、数据库和云存储服务的无缝集成，使用户能够轻松访问和处理来自多个来源的数据。尽管本书专注于
    Databricks 的机器学习和 MLOps 能力，但理解 Databricks Lakehouse 架构以及它如何简化组织中的机器学习项目生命周期管理和扩展，依然非常有意义。
- en: '**Lakehouse**, as a term, is a combination of two terms: **data lakes** and
    **data warehouses**. Data warehouses are great at handling structured data and
    SQL queries. They are extensively used for powering **business intelligence**
    (**BI**) applications but have limited support for ML. They store data in proprietary
    formats and can only be accessed using SQL queries.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '**Lakehouse** 作为一个术语，是两个词的结合：**数据湖** 和 **数据仓库**。数据仓库擅长处理结构化数据和 SQL 查询。它们广泛用于为
    **商业智能**（**BI**）应用程序提供支持，但在支持机器学习方面有所限制。它们以专有格式存储数据，并且只能通过 SQL 查询访问。'
- en: Data lakes, on the other hand, do a great job supporting ML use cases. A data
    lake allows organizations to store a large amount of their structured and unstructured
    data in a central scalable store. They are easy to scale and support open formats.
    However, data lakes have a significant drawback when it comes to running BI workloads.
    Their performance is not comparable to data warehouses. The lack of schema governance
    enforcement turned most data lakes in organizations into swamps.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，数据湖在支持机器学习（ML）应用场景方面表现出色。数据湖允许组织将大量的结构化和非结构化数据存储在一个可扩展的中央存储库中。它们容易扩展并支持开放格式。然而，数据湖在运行商业智能（BI）工作负载时有一个显著的缺点。它们的性能无法与数据仓库相比。缺乏架构治理的执行使得许多组织中的数据湖变成了“沼泽”。
- en: Typically, in modern enterprise architecture, there is a need for both. This
    is where Databricks defined the Lakehouse architecture. Databricks provides a
    unified analytics platform called the Databricks Lakehouse Platform. The Lakehouse
    Platform provides a persona-based single platform that caters to all the personas
    involved in data processing and gains insights. The personas include data engineers,
    BI analysts, data scientists, and MLOps. This can tremendously simplify the data
    processing and analytics architecture of any organization.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，在现代企业架构中，既需要数据仓库，也需要数据湖。这正是 Databricks 定义 Lakehouse 架构的背景。Databricks 提供了一个统一的分析平台，称为
    Databricks Lakehouse 平台。Lakehouse 平台提供了一个基于角色的单一平台，满足所有数据处理和洞察获取相关人员的需求。这些角色包括数据工程师、BI
    分析师、数据科学家和 MLOps。这个平台能够极大地简化任何组织的数据处理和分析架构。
- en: 'At the time of writing this book, the Lakehouse Platform is available on all
    three major clouds: **Amazon Web Services** (**AWS**), **Microsoft Azure**, and
    **Google Compute** **Platform** (**GCP**).'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本书时，Lakehouse 平台已在所有三大云服务平台上提供：**Amazon Web Services**（**AWS**）、**Microsoft
    Azure** 和 **Google Compute** **Platform**（**GCP**）。
- en: Lakehouse can be thought of as a technology that combines data warehouses’ performance
    and data governance aspects and makes them available at the scale of data lakes.
    Under the hood, Lakehouse uses an open protocol called **Delta** ([https://delta.io/](https://delta.io/)).
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: Lakehouse 可以被认为是一种将数据仓库的性能和数据治理功能相结合，并在数据湖的规模上提供这些功能的技术。从技术实现上看，Lakehouse 使用了一种名为
    **Delta** 的开放协议 ([https://delta.io/](https://delta.io/))。
- en: The Delta format adds reliability, performance, and governance to the data in
    data lakes. Delta also provides **Atomicity, Consistency, Isolation, and Durability**
    (**ACID**) transactions, making sure that all data operations either fully succeed
    or fail. In addition to ACID transaction support, under the hood, Delta uses the
    Parquet format. Unlike the regular Parquet format, the Delta format keeps track
    of transaction logs, offering enhanced capabilities. It also supports granular
    access controls to your data, along with versioning and the ability to roll back
    to previous versions. Delta format tables scale effortlessly with data and are
    underpinned by Apache Spark while utilizing advanced indexing and caching to improve
    performance at scale. There are many more benefits that the Delta format provides
    that you can read about on the official website.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: Delta 格式为数据湖中的数据添加了可靠性、性能和治理。Delta 还提供了**原子性、一致性、隔离性和持久性**（**ACID**）事务，确保所有数据操作要么完全成功，要么完全失败。除了支持
    ACID 事务外，Delta 在后台使用 Parquet 格式。与常规 Parquet 格式不同，Delta 格式会跟踪事务日志，提供增强的功能。它还支持对数据的细粒度访问控制，以及版本控制和回滚到先前版本的能力。Delta
    格式表格能与数据轻松扩展，并且在 Apache Spark 支持下，通过先进的索引和缓存技术提升大规模操作的性能。Delta 格式还提供了许多其他优势，您可以在官方网站上了解更多信息。
- en: When we say **Delta Lake**, we mean a data lake that uses the Delta format to
    provide the previously described benefits to the data lake.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们提到**Delta Lake**时，我们指的是使用 Delta 格式的数据湖，它为数据湖提供了前述的所有好处。
- en: 'The Databricks Lakehouse architecture is built on the foundation of Delta Lake:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: Databricks Lakehouse 架构是基于 Delta Lake 的基础构建的：
- en: '![Figure 1.5 – Databricks Lakehouse Platform](img/Figure_01.5_B17875.jpg)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.5 – Databricks Lakehouse 平台](img/Figure_01.5_B17875.jpg)'
- en: Figure 1.5 – Databricks Lakehouse Platform
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.5 – Databricks Lakehouse 平台
- en: Note
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 注
- en: 'Source: Courtesy of Databricks'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：感谢 Databricks 提供
- en: Next, let’s discuss how the Databricks Lakehouse architecture can simplify ML.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们讨论 Databricks Lakehouse 架构如何简化 ML。
- en: Simplifying machine learning development with the Lakehouse architecture
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 简化机器学习开发的 Lakehouse 架构
- en: As we saw in the previous section, the Databricks Lakehouse Platform provides
    a cloud-native enterprise-ready solution that simplifies the data processing needs
    of an organization. It provides a single platform that enables different teams
    across enterprises to collaborate and reduces time to market for new projects.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在上一节看到的，Databricks Lakehouse 平台提供了一个云原生的企业级解决方案，简化了组织的数据处理需求。它提供了一个单一平台，使得企业内不同团队能够协作，并减少新项目的上市时间。
- en: 'The Lakehouse Platform has many components specific to data scientists and
    ML practitioners; we will cover these in more detail later in this book. For instance,
    at the time of writing this book, the Lakehouse Platform released a drop-down
    button that allows users to switch between persona-based views. There are tabs
    to quickly access the fully integrated and managed feature store, model registry,
    and MLflow tracking server in the ML practitioner persona view:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: Lakehouse 平台有许多专门面向数据科学家和 ML 实践者的组件；我们将在本书后续章节中详细讲解这些组件。例如，在撰写本书时，Lakehouse
    平台推出了一个下拉按钮，允许用户在基于角色的视图之间切换。在 ML 实践者角色视图中，有快速访问完全集成和管理的特性存储、模型注册表和 MLflow 跟踪服务器的标签：
- en: '![Figure 1.6 – Databricks Lakehouse Platform persona selection dropdown](img/Figure_01.6_B17875.jpg)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.6 – Databricks Lakehouse 平台角色选择下拉菜单](img/Figure_01.6_B17875.jpg)'
- en: Figure 1.6 – Databricks Lakehouse Platform persona selection dropdown
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.6 – Databricks Lakehouse 平台角色选择下拉菜单
- en: With that, let’s summarize this chapter.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们总结一下本章内容。
- en: Summary
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we learned about ML, including the ML process, the personas
    involved, and the challenges organizations face in productionizing ML models.
    Then, we learned about the Lakehouse architecture and how the Databricks Lakehouse
    Platform can potentially simplify MLOps for organizations. These topics give us
    a solid foundation to develop a more profound understanding of how different Databricks
    ML-specific tools fit in the ML life cycle.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中，我们学习了机器学习（ML），包括 ML 流程、相关角色以及组织在生产化 ML 模型时面临的挑战。然后，我们了解了 Lakehouse 架构以及
    Databricks Lakehouse 平台如何简化组织中的 MLOps。这些内容为我们深入理解 Databricks 针对 ML 生命周期的不同专用工具提供了坚实的基础。
- en: For in-depth learning about the various features and staying up to date with
    announcements, the Databricks documentation is the ideal resource. You can access
    the documentation via the link provided in the *Further reading* section. Moreover,
    on the documentation page, you can easily switch to different cloud-specific documentation
    to explore platform-specific details and functionalities.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 若要深入学习各种功能并保持最新的公告，Databricks 文档是理想的资源。你可以通过*进一步阅读*部分提供的链接访问文档。此外，在文档页面上，你可以轻松切换到不同云平台的文档，探索平台特定的细节和功能。
- en: In the next chapter, we will dive deeper into the ML-specific features of the
    Databricks Lakehouse Platform.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将更深入地探讨 Databricks Lakehouse 平台中的机器学习专用功能。
- en: Further reading
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'To learn more about the topics that were covered in this chapter, take a look
    at the following resources:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解本章涉及的更多内容，请参考以下资源：
- en: Wikipedia, *Hyperparameter (machine* *learning)* ([https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning)](https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning))).
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 维基百科，*超参数（机器学习）* ([https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning)](https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning)))。
- en: Matt Asay, 2017, *85% of big data projects fail*, TechRepublic, November ([https://www.techrepublic.com/article/85-of-big-data-projects-fail-but-your-developers-can-help-yours-succeed/](https://www.techrepublic.com/article/85-of-big-data-projects-fail-but-your-developers-can-help-yours-succeed/)).
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Matt Asay，2017年，*85%的大数据项目失败*，TechRepublic，11月 ([https://www.techrepublic.com/article/85-of-big-data-projects-fail-but-your-developers-can-help-yours-succeed/](https://www.techrepublic.com/article/85-of-big-data-projects-fail-but-your-developers-can-help-yours-succeed/))。
- en: Rackspace Technologies, *New Global Rackspace Technology Study Uncovers Widespread
    Artificial Intelligence and Machine Learning Knowledge Gap*, January 2021 ([https://www.rackspace.com/newsroom/new-global-rackspace-technology-study-uncovers-widespread-artificial-intelligence-and](https://www.rackspace.com/newsroom/new-global-rackspace-technology-study-uncovers-widespread-artificial-intelligence-and)).
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rackspace Technologies，*全球新的 Rackspace 技术研究揭示广泛存在的人工智能与机器学习知识差距*，2021年1月 ([https://www.rackspace.com/newsroom/new-global-rackspace-technology-study-uncovers-widespread-artificial-intelligence-and](https://www.rackspace.com/newsroom/new-global-rackspace-technology-study-uncovers-widespread-artificial-intelligence-and))。
- en: Gartner, *Gartner Data Shows 87 Percent of Organizations Have Low BI and Analytics
    Maturity*, December 2018 ([https://www.gartner.com/en/newsroom/press-releases/2018-12-06-gartner-data-shows-87-percent-of-organizations-have-low-bi-and-analytics-maturity](https://www.gartner.com/en/newsroom/press-releases/2018-12-06-gartner-data-shows-87-percent-of-organizations-have-low-bi-and-analytics-maturity)).
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gartner，*Gartner 数据显示87%的组织在商业智能和分析方面的成熟度较低*，2018年12月 ([https://www.gartner.com/en/newsroom/press-releases/2018-12-06-gartner-data-shows-87-percent-of-organizations-have-low-bi-and-analytics-maturity](https://www.gartner.com/en/newsroom/press-releases/2018-12-06-gartner-data-shows-87-percent-of-organizations-have-low-bi-and-analytics-maturity))。
- en: '*Learning Spark: Lightning-Fast Data Analytics*, by Holden Karau, Andy Konwinski,
    Patrick Wendell, and Matei Zaharia: This comprehensive guide covers the fundamentals
    of Spark, including RDDs, the DataFrame API, Spark Streaming, MLlib, and GraphX.
    With practical examples and use cases, it will help you become proficient in using
    Spark for data analytics.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*《学习 Spark：极速数据分析》*，作者：Holden Karau、Andy Konwinski、Patrick Wendell 和 Matei
    Zaharia：这本全面的指南涵盖了 Spark 的基础知识，包括 RDD、DataFrame API、Spark Streaming、MLlib 和 GraphX。通过实际示例和使用案例，它将帮助你熟练掌握使用
    Spark 进行数据分析。'
- en: '*Spark: The Definitive Guide*, by Bill Chambers and Matei Zaharia: This acclaimed
    book provides a deep dive into Spark’s core concepts and advanced features. It
    covers Spark’s architecture, data processing techniques, ML, graph processing,
    and deployment considerations. Suitable for beginners and experienced users, it
    offers a comprehensive understanding of Spark.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*《Spark：权威指南》*，作者：Bill Chambers 和 Matei Zaharia：这本备受赞誉的书籍深入探讨了 Spark 的核心概念和高级功能，涵盖了
    Spark 的架构、数据处理技术、机器学习、图处理以及部署相关的注意事项。无论是初学者还是有经验的用户，都能全面理解 Spark。'
- en: '*High Performance Spark: Best Practices for Scaling and Optimizing Apache Spark*,
    by Holden Karau, Rachel Warren, and Matei Zaharia: This book explores strategies
    for optimizing Spark applications to achieve maximum performance and scalability.
    It offers insights into tuning Spark configurations, improving data locality,
    leveraging advanced features, and designing efficient data pipelines.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*高性能Spark：Apache Spark扩展与优化最佳实践*，作者：Holden Karau、Rachel Warren 和 Matei Zaharia：本书探讨了优化Spark应用程序的策略，以实现最大性能和可扩展性。书中提供了关于调整Spark配置、改善数据本地性、利用高级功能以及设计高效数据管道的见解。'
- en: '*Spark in Action*, by Jean-Georges Perrin: This practical guide takes you through
    the entire Spark ecosystem, covering data ingestion, transformation, ML, real-time
    processing, and integration with other technologies. With hands-on examples and
    real-world use cases, it enables you to apply Spark to your specific projects.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Spark实战*，作者：Jean-Georges Perrin：本实用指南带你了解整个Spark生态系统，涵盖数据摄取、转换、机器学习、实时处理以及与其他技术的集成。通过动手示例和实际用例，帮助你将Spark应用到具体项目中。'
- en: '*Get Started using Unity* *Catalog* ([https://docs.databricks.com/data-governance/unity-catalog/get-started.html](https://docs.databricks.com/data-governance/unity-catalog/get-started.html))'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*开始使用Unity* *目录* ([https://docs.databricks.com/data-governance/unity-catalog/get-started.html](https://docs.databricks.com/data-governance/unity-catalog/get-started.html))'
- en: '*Databricks* *documentation* ([https://docs.databricks.com/introduction/index.html](https://docs.databricks.com/introduction/index.html)).'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Databricks* *文档* ([https://docs.databricks.com/introduction/index.html](https://docs.databricks.com/introduction/index.html))。'
