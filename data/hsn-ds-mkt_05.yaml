- en: Drivers behind Marketing Engagement
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 驱动营销参与度的因素
- en: When you run marketing campaigns, one of the important measures that you will
    want to look at and analyze is customer engagement with your marketing efforts.
    For example, in email marketing, customer engagement can be measured by how many
    of your marketing emails were opened or ignored by your customers. Customer engagement
    can also be measured by the amount of website visits from individual customers.
    Successful marketing campaigns will draw a lot of engagement from your customers,
    while ineffective marketing campaigns will not only drive a lower amount of engagement
    from your customers, but will also negatively impact your business. Customers
    might mark emails from your business as spam or unsubscribe from your mailing
    list.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 当你进行营销活动时，你需要重点关注并分析的一个重要指标是客户对营销活动的参与度。例如，在电子邮件营销中，客户参与度可以通过客户打开或忽略你的营销邮件的数量来衡量。客户参与度还可以通过单个客户访问网站的次数来衡量。成功的营销活动会吸引大量客户参与，而无效的营销活动不仅会导致客户参与度较低，还会对你的业务产生负面影响。客户可能会将你的邮件标记为垃圾邮件或取消订阅你的邮件列表。
- en: In order to understand what affects customer engagement, in this chapter, we
    will discuss how we can use explanatory analysis (more specifically, regression
    analysis). We will briefly cover the definition of explanatory analysis, what
    regression analysis is, and how to use a logistic regression model for explanatory
    analysis. Then, we will cover how to build and interpret regression analysis results
    in Python, using the `statsmodels` package. For R programmers, we will discuss
    how we can build and interpret regression analysis results with `glm`.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解是什么影响了客户的参与度，本章我们将讨论如何使用解释性分析（更具体地说，是回归分析）。我们将简要介绍解释性分析的定义，回归分析是什么，以及如何使用逻辑回归模型进行解释性分析。接着，我们将讨论如何在Python中使用`statsmodels`包来构建和解释回归分析结果。对于R程序员，我们将讨论如何使用`glm`来构建和解释回归分析结果。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Using regression analysis for explanatory analysis
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用回归分析进行解释性分析
- en: Regression analysis with Python
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Python进行回归分析
- en: Regression analysis with R
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用R进行回归分析
- en: Using regression analysis for explanatory analysis
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用回归分析进行解释性分析
- en: In [Chapter 2](1fb7a852-d8fa-43f6-9807-6e3292dfa280.xhtml), *Key Performance
    Indicators and Visualizations*, we discussed what **descriptive analysis** is
    and how it is used to better understand a dataset. We experimented using various
    visualization techniques and building different types of plots in Python and R.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第二章](1fb7a852-d8fa-43f6-9807-6e3292dfa280.xhtml)中，*关键绩效指标与可视化*，我们讨论了**描述性分析**是什么，以及它如何帮助我们更好地理解数据集。我们通过使用各种可视化技术，并在Python和R中构建不同类型的图表进行了实验。
- en: In this chapter, we are going to expand our knowledge and start to discuss why,
    when, and how to use **explanatory analysis** for marketing.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将扩展我们的知识，开始讨论在营销中何时、如何以及为什么使用**解释性分析**。
- en: Explanatory analysis and regression analysis
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解释性分析与回归分析
- en: As we briefly discussed in [Chapter 1](c169428b-e0db-4624-896c-24316e9b29cc.xhtml),
    *Data Science and Marketing*, the purpose of explanatory analysis is to answer
    why we are using the data, whereas the purpose of descriptive analysis is to answer
    what we are using the data for, and how we are using it. When you run different
    marketing campaigns, often times, you will notice that some marketing campaigns
    perform much better than others; you might wonder why it is that some of your
    marketing campaigns work so well, while others do not. For example, you might
    want to understand what types and groups of customers typically open your marketing
    emails more often than others. As another example, you might want to analyze what
    attributes of the customer base are highly correlated with higher conversion rates
    and item purchases.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在[第一章](c169428b-e0db-4624-896c-24316e9b29cc.xhtml)中简要讨论的，*数据科学与营销*，解释性分析的目的是回答我们为何使用数据，而描述性分析的目的是回答我们用数据做什么，如何使用数据。当你进行不同的营销活动时，你通常会发现某些营销活动的表现比其他活动好得多；你可能会想知道，为什么有些营销活动效果如此之好，而有些却没有。例如，你可能想了解哪些类型和群体的客户比其他人更频繁地打开你的营销邮件。另一个例子是，你可能想分析客户群体的哪些属性与更高的转化率和商品购买率密切相关。
- en: 'With explanatory analysis, you can analyze and understand the key factors that
    are highly and significantly correlated with the outcomes that you want. **Regression
    analysis** and regression models are frequently used to model the relationships
    between the attributes and the outcomes. Simply put, regression analysis estimates
    the values of output variables by finding a function of the attributes or features
    that best approximates the output values. One of the frequently used forms of
    regression analysis is **linear regression**. As the name suggests, in linear
    regression, we try to estimate the output variables via linear combinations of
    the features. If we use *Y* for the output variable and *X[i]* for each of the
    features, where *i* is the *i*th feature, then the linear regression formula will
    look as follows:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 通过解释性分析，你可以分析并理解与所需结果高度相关的关键因素。**回归分析**和回归模型常用于建模属性与结果之间的关系。简而言之，回归分析通过找到最能近似输出值的属性或特征函数来估算输出变量的值。回归分析中一种常用的形式是**线性回归**。顾名思义，在线性回归中，我们尝试通过特征的线性组合来估计输出变量。如果我们用*Y*表示输出变量，用*X[i]*表示每个特征，其中*i*是第*i*个特征，那么线性回归公式如下：
- en: '![](img/4141c7bf-bbc5-4f2d-9b36-2c3877c5a77c.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4141c7bf-bbc5-4f2d-9b36-2c3877c5a77c.png)'
- en: 'As you can see from the preceding formula, the output variable *Y* is expressed
    as a linear combination of the features, *X[i]*. The purpose of the linear regression
    models is to find the intercept, *a*, and the coefficients, *b[i]*, that best
    estimate the output variable, using the given features. A fitted linear regression
    line will look something like the following (image from [https://towardsdatascience.com/linear-regression-using-python-b136c91bf0a2](https://towardsdatascience.com/linear-regression-using-python-b136c91bf0a2)):'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 从上述公式中可以看到，输出变量*Y*表示为特征*X[i]*的线性组合。线性回归模型的目的是找到最能估算输出变量的截距*a*和系数*b[i]*，并利用给定的特征进行拟合。拟合的线性回归线大致如下所示（图片来源于 [https://towardsdatascience.com/linear-regression-using-python-b136c91bf0a2](https://towardsdatascience.com/linear-regression-using-python-b136c91bf0a2)）：
- en: '![](img/d60fa219-a286-4b2c-a92e-209e6f4d3109.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d60fa219-a286-4b2c-a92e-209e6f4d3109.png)'
- en: The blue dots in this diagram are the data points, and the red line is the fitted,
    or trained, linear regression line. As you can see in the graph, linear regression
    tries to estimate the target variable through a linear combination of the features.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 该图中的蓝色点表示数据点，红色线是拟合的或训练过的线性回归线。正如图表所示，线性回归试图通过特征的线性组合来估计目标变量。
- en: In this chapter, we will discuss how we can use regression analysis, and, more
    specifically, **logistic regression** models, to understand what drives higher
    customer engagement.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论如何使用回归分析，尤其是**逻辑回归**模型，来理解是什么驱动了更高的客户参与度。
- en: Logistic regression
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 逻辑回归
- en: '**Logistic regression** is a type of regression analysis that is used when
    the output variable is binary (one for a positive outcome versus zero for a negative
    outcome). Like any other linear regression models, logistic regression models
    estimate the output from linear combinations of the feature variables. The only
    difference is what the model estimates. Unlike other linear regression models,
    logistic regression models estimate the log odds of an event, or, in other words,
    the log ratios between the probabilities of positive and negative events. The
    equation looks as follows:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**逻辑回归**是一种回归分析方法，通常用于输出变量是二元的情况（表示正面结果为1，负面结果为0）。与其他线性回归模型类似，逻辑回归模型通过特征变量的线性组合来估算输出。唯一的区别是模型估算的内容。与其他线性回归模型不同，逻辑回归模型估算的是事件的对数机会，或者换句话说，是正面事件和负面事件概率之间的对数比率。其公式如下：'
- en: '![](img/1946fce3-7d03-485d-a545-bd55a8d47e10.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1946fce3-7d03-485d-a545-bd55a8d47e10.png)'
- en: 'The ratio on the left is the odds of success, which represents the ratio between
    the probability of success and the probability of failure. The curve of the log
    odds, also called the **logit curve**, looks as follows:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 左边的比率是成功的机会，表示成功的概率与失败的概率之间的比率。对数机会的曲线，也称为**logit曲线**，如下所示：
- en: '![](img/ef7f8d76-83b1-4317-8df0-623cc1512349.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ef7f8d76-83b1-4317-8df0-623cc1512349.png)'
- en: 'The logistic regression model output is simply the inverse of logit, which
    ranges from zero to one. In this chapter, we are going to use regression analysis
    to understand what drives customer engagement, and the output variable will be
    whether a customer responded to marketing calls. Hence, logistic regression fits
    perfectly in this case, as the output is a binary variable that can take two values:
    responded versus did not respond. In the following sections, we will discuss how
    we can use and build logistic regression models in Python and R, and then we will
    cover how we can interpret regression analysis results in order to understand
    what attributes of customers are highly correlated with higher marketing engagement.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归模型的输出只是logit的逆，它的值范围从零到一。在本章中，我们将使用回归分析来理解是什么推动了客户参与度，输出变量将是客户是否对营销电话作出回应。因此，逻辑回归在这种情况下非常适用，因为输出是一个二元变量，可以取两个值：响应和未响应。在接下来的章节中，我们将讨论如何在Python和R中使用和构建逻辑回归模型，然后我们将讲解如何解读回归分析结果，以理解哪些客户属性与更高的营销参与度高度相关。
- en: Regression analysis with Python
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Python进行回归分析
- en: In this section, you will learn how to use the `statsmodels` package in Python
    to conduct regression analysis. For those readers that would like to use R instead
    of Python, for this exercise, you can skip to the next section. We will start
    this section by looking at the data more closely, using the `pandas` and `matplotlib`
    packages, and then we will discuss how to build regression models and interpret
    the results by using the `statsmodels` library.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将学习如何在Python中使用`statsmodels`包进行回归分析。对于那些希望使用R而非Python的读者，可以跳到下一节。在本节开始时，我们将通过使用`pandas`和`matplotlib`包更仔细地查看数据，然后我们将讨论如何使用`statsmodels`库构建回归模型并解读结果。
- en: 'For this exercise, we will be using one of the publicly available datasets
    from IBM Watson, which can be found at [https://www.ibm.com/communities/analytics/watson-analytics-blog/marketing-customer-value-analysis/](https://www.ibm.com/communities/analytics/watson-analytics-blog/marketing-customer-value-analysis/).
    You can follow the link and download the data file in a CSV format. In order to
    load this data into your Jupyter Notebook, you can run the following code:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们将使用IBM Watson提供的公开数据集之一，数据集可以在[https://www.ibm.com/communities/analytics/watson-analytics-blog/marketing-customer-value-analysis/](https://www.ibm.com/communities/analytics/watson-analytics-blog/marketing-customer-value-analysis/)找到。你可以点击链接下载CSV格式的数据文件。为了将该数据加载到你的Jupyter
    Notebook中，你可以运行以下代码：
- en: '[PRE0]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Similar to what we did in [Chapter 2](1fb7a852-d8fa-43f6-9807-6e3292dfa280.xhtml),
    *Key Performance Indicators and Visualizations*, we are importing the `matplotlib`
    and `pandas` packages first; using the `read_csv` function in `pandas`, we can
    read the data into a `pandas` DataFrame. We will use `matplotlib` later, for data
    analysis and visualizations.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 与我们在[第2章](1fb7a852-d8fa-43f6-9807-6e3292dfa280.xhtml)中做的类似，*关键绩效指标与可视化*，我们首先导入`matplotlib`和`pandas`包；使用`pandas`中的`read_csv`函数，我们可以将数据读取到`pandas`
    DataFrame中。稍后我们将使用`matplotlib`进行数据分析和可视化。
- en: 'The loaded DataFrame, `df`, looks as follows:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 加载后的DataFrame，`df`，如下所示：
- en: '![](img/333d7a69-95a2-4044-bcc1-5b6e92b72fc6.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](img/333d7a69-95a2-4044-bcc1-5b6e92b72fc6.png)'
- en: As we discussed in [Chapter 2](1fb7a852-d8fa-43f6-9807-6e3292dfa280.xhtml), *Key
    Performance Indicators and Visualizations*, a DataFrame `shape` attribute tells
    us the number of rows and columns in the DataFrame, and the `head` function will
    display the first five records of the dataset. Once you have successfully read
    the data into a `pandas` DataFrame, your data should look like it does in the
    screenshot.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们在[第2章](1fb7a852-d8fa-43f6-9807-6e3292dfa280.xhtml)中讨论的，*关键绩效指标与可视化*，DataFrame的`shape`属性告诉我们DataFrame中行和列的数量，而`head`函数会显示数据集的前五条记录。一旦成功将数据读取到`pandas`
    DataFrame中，数据应呈现如截图所示。
- en: Data analysis and visualizations
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据分析与可视化
- en: 'Before we dive into regression analysis, we will first take a more detailed
    look at the data, in order to have a better understanding of what data points
    we have and what patterns we can see in the data. If you look at the data, you
    will notice a column named `Response`. It contains information on whether a customer
    responded to marketing calls. We will use this field as a measure of customer
    engagement. For future computations, it will be better to encode this field with
    numerical values. Let''s take a look at the following code:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行回归分析之前，我们首先要更详细地查看数据，以便更好地理解我们拥有的数据点以及数据中可以看到的模式。如果你查看数据，你会注意到有一列名为`Response`，它包含客户是否响应营销呼叫的信息。我们将使用这个字段作为客户参与度的衡量标准。为了进行后续的计算，最好将这个字段编码为数值型。让我们看一下以下代码：
- en: '[PRE1]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: As you can see in this code, using the `apply` function of a `pandas` DataFrame,
    we are encoding those who did not respond to marketing calls (`No`) with a value
    of `0` and those who did respond (`Yes`) with a value of `1`. We are creating
    a new field named `Engaged` with these encoded values.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在这段代码中看到的，我们使用`pandas`数据框的`apply`函数，将未响应营销呼叫的客户（`No`）编码为`0`，而响应的客户（`Yes`）编码为`1`。我们创建了一个名为`Engaged`的新字段，存储这些编码值。
- en: Engagement rate
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参与率
- en: 'The first thing that we are going to look at is the aggregate engagement rate.
    This engagement rate is simply the percentage of customers that responded to the
    marketing calls. Take a look at the following code:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先要查看的是总体参与率。这个参与率简单来说就是响应营销呼叫的客户百分比。请看下面的代码：
- en: '[PRE2]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'As you can see from this code, we are grouping by the newly created field,
    `Engaged`, using the `groupby` function of a `pandas` DataFrame. Then, we are
    counting the number of records (or customers) in each `Engaged` group with the `count`
    function. By dividing by the total number of customers in the DataFrame and multiplying
    by `100.0`, we get the engagement rate. The results are as follows:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你从这段代码中看到的，我们使用`pandas`数据框的`groupby`函数按新创建的字段`Engaged`进行分组。接着，我们使用`count`函数统计每个`Engaged`组中的记录数（或客户数）。通过除以数据框中客户的总数并乘以`100.0`，我们得到参与率。结果如下所示：
- en: '![](img/97193318-df6f-461f-9404-86cb8ed4b87b.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](img/97193318-df6f-461f-9404-86cb8ed4b87b.png)'
- en: 'To make this easier to read, we can transpose the DataFrame, meaning that we
    can flip the rows and columns in the DataFrame. You can transpose a `pandas` DataFrame
    by using the `T` attribute of a DataFrame. It looks as follows:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更容易阅读，我们可以转置数据框（DataFrame），这意味着我们可以翻转数据框中的行和列。你可以通过使用数据框的`T`属性来转置`pandas`数据框。其效果如下所示：
- en: '![](img/04dd8f15-66c7-4bdd-a2c3-1e04839e1447.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](img/04dd8f15-66c7-4bdd-a2c3-1e04839e1447.png)'
- en: As you can see, about 14% of the customers have responded to marketing calls,
    and the remaining 86% of the customers have not responded.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，大约14%的客户响应了营销呼叫，其余86%的客户未做响应。
- en: Sales channels
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 销售渠道
- en: 'Now, let''s see whether we can find any noticeable patterns in the sales channel
    and engagement. We are going to analyze how the engaged and non-engaged customers
    are distributed among different sales channels. Let''s first look at the following
    code:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看是否能在销售渠道和客户参与度之间找到任何明显的模式。我们将分析参与和未参与的客户在不同销售渠道中的分布。首先看一下以下代码：
- en: '[PRE3]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'As you can see in this code snippet, we are using the `pivot_table` function
    in the `pandas` library to group by the `Sales Channel` and `Response` variables.
    Once you run this code, `engagement_by_sales_channel_df` will have the following
    data:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在这段代码中看到的，我们正在使用`pandas`库的`pivot_table`函数按`Sales Channel`和`Response`变量进行分组。运行这段代码后，`engagement_by_sales_channel_df`将包含如下数据：
- en: '![](img/0cd77263-2dc4-4680-b552-5a1d92ed0bcb.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0cd77263-2dc4-4680-b552-5a1d92ed0bcb.png)'
- en: 'As you will have noticed in the previous section, there are significantly more
    customers that are not engaged with the marketing efforts, so it is quite difficult
    to look at the differences in the sales channel distributions between the engaged
    and non-engaged customers from raw numbers. To make the differences more visually
    identifiable, we can build pie charts using the following code:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在上一节中已经注意到的，未参与营销活动的客户明显更多，因此在原始数据中很难直接看出参与客户与未参与客户在销售渠道分布上的差异。为了让这些差异更加直观地显现出来，我们可以使用以下代码构建饼图：
- en: '[PRE4]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Once you run this code, you will see the following pie charts, which show the
    distributions of engaged and non-engaged customers across different sales channels:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你运行这段代码，你将看到以下饼图，展示了已参与和未参与客户在不同销售渠道中的分布情况：
- en: '![](img/7e5402ab-645b-41ea-92ef-4e00ba53ac02.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7e5402ab-645b-41ea-92ef-4e00ba53ac02.png)'
- en: Compared to the previous table that shows raw counts of engaged and non-engaged
    customers in each sales channel, these pie charts help us to visually spot the
    differences in the distributions more easily. As you can see from these charts,
    more than half of the engaged customers were from agents, whereas non-engaged
    customers are more evenly distributed across all four different channels. As you
    can see from these charts, analyzing and visualizing data can help us to notice
    interesting patterns in the data, which will further help when we run regression
    analysis in the later parts of this chapter.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前显示每个销售渠道中已参与和未参与客户原始计数的表格相比，这些饼图帮助我们更轻松地可视化并发现分布差异。如你从这些图表中看到的，超过一半的已参与客户来自代理商，而未参与客户则更均匀地分布在所有四个不同的渠道中。正如你从这些图表中看到的，分析和可视化数据能够帮助我们发现数据中的有趣模式，这将在本章后续的回归分析中提供帮助。
- en: Total claim amounts
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总赔付金额
- en: 'The last thing that we are going to look at before we dive into the regression
    analysis are the differences in the distributions of `Total Claim Amount` between
    the engaged and non-engaged groups. We are going to visualize this by using box
    plots. Let''s first look at how we can build box plots in Python, as follows:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们进入回归分析之前，我们要先看一下`Total Claim Amount`在已参与和未参与组之间分布的差异。我们将通过箱形图来可视化这一点。首先，让我们看一下如何在Python中构建箱形图，如下所示：
- en: '[PRE5]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'As you can see in this code, it is quite straightforward to build box plots
    from a `pandas` DataFrame. You can simply call the `boxplot` function. Box plots
    are a great way to visualize the distributions of continuous variables. They show
    the min, max, first quartile, median, and third quartile, all in one view. The
    following box plots show the distributions of the `Total Claim Amount` between
    the engaged and non-engaged groups:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 如你在这段代码中看到的，从`pandas` DataFrame中构建箱形图非常简单。你只需调用`boxplot`函数。箱形图是可视化连续变量分布的一个极好的方式。它们展示了最小值、最大值、第一个四分位数、中位数和第三个四分位数，一目了然。以下箱形图展示了`Total
    Claim Amount`在已参与和未参与组之间的分布：
- en: '![](img/c38b00b9-e2ca-4edd-a34a-cf67ba11ea74.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c38b00b9-e2ca-4edd-a34a-cf67ba11ea74.png)'
- en: 'The central rectangle spans from the first quartile to the third quartile,
    and the green line shows the median. The lower and upper ends show the minimum
    and maximum of the distribution, respectively. One thing to note from the previous
    code is the `showfliers=False` argument. Let''s see what happens when we set that
    argument to `True`, using the following code:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 中央矩形从第一个四分位数到第三个四分位数，绿色线条显示中位数。下边和上边分别显示分布的最小值和最大值。需要注意的是，在之前的代码中使用了`showfliers=False`参数。让我们看看当我们将该参数设置为`True`时会发生什么，使用以下代码：
- en: '[PRE6]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Using this code and the `showfliers=True` flag, the resulting box plots now
    look as follows:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这段代码并设置`showfliers=True`标志，生成的箱形图如下所示：
- en: '![](img/5ff9f5b8-a67b-4e31-b2df-6f1c2661ac25.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5ff9f5b8-a67b-4e31-b2df-6f1c2661ac25.png)'
- en: As you notice in these box plots, they plot many dots above the upper boundary
    lines, which suggested maximum values in the previous box plots. The dots above
    the upper boundary line show the suspected outliers that are decided based on
    the **Interquartile range** (**IQR**). The IQR is simply the range between the
    first and third quartiles, and the points that fall `1.5*IQR` above the third
    quartile or `1.5*IQR` below the first quartile are suspected outliers and are
    shown with the dots.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在这些箱形图中所注意到的，它们在上边界线之上绘制了许多点，这些点代表了之前箱形图中的最大值。上边界线上的点显示了基于**四分位距**（**IQR**）判定的疑似异常值。IQR即第一个四分位数和第三个四分位数之间的范围，任何超过第三个四分位数`1.5*IQR`或低于第一个四分位数`1.5*IQR`的点都被认为是疑似异常值，并通过这些点显示出来。
- en: Regression analysis
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回归分析
- en: So far, we have analyzed the types of fields that we have in the data and how
    the patterns differ between the engaged group and the non-engaged group. Now,
    we are going to discuss how to conduct and interpret regression analysis in Python
    by using the `statsmodels` package. We will first build a logistic regression
    model with continuous variables, and you'll learn how to interpret the results.
    Then, we are going to discuss different ways to handle categorical variables when
    fitting regression models, and what impact those categorical variables have on
    the fitted logistic regression model.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经分析了数据中字段的类型以及参与组和非参与组之间的模式差异。现在，我们将讨论如何使用 `statsmodels` 包在 Python
    中进行回归分析及其解释。我们将首先用连续变量构建一个逻辑回归模型，并学习如何解释结果。接着，我们将讨论在拟合回归模型时如何处理分类变量，以及这些分类变量对拟合的逻辑回归模型的影响。
- en: Continuous variables
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 连续变量
- en: 'In linear regression, including logistic regression, it is straightforward
    to fit a regression model when the feature variables are continuous, as it just
    needs to find a linear combination of feature variables with numerical values
    for estimating the output variables. In order to fit a regression model with continuous
    variables, let''s first take a look at how to get the data types of the columns
    in a `pandas` DataFrame. Take a look at the following:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在线性回归中，包括逻辑回归，当特征变量是连续的时，拟合回归模型非常简单，因为它只需要找到特征变量的线性组合，利用数值特征来估计输出变量。为了用连续变量拟合回归模型，首先让我们看看如何获取
    `pandas` DataFrame 中列的数据类型。请看以下内容：
- en: '![](img/13cfa30a-b8b2-45db-8b1b-cc3b0b115cd3.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](img/13cfa30a-b8b2-45db-8b1b-cc3b0b115cd3.png)'
- en: 'As you can see from this Jupyter Notebook screenshot, the `dtype` attribute
    of a `pandas` `Series` object tells you what type of data it contains. As you
    can see from this snapshot, the `Income` variable has integers and the `Customer
    Lifetime Value` feature has floating point numbers. In order to take a quick look
    at the distributions of variables with numerical values, you can also do the following:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如你从这张 Jupyter Notebook 截图中看到的，`pandas` `Series` 对象的 `dtype` 属性告诉你它包含的数据类型。从这张截图可以看出，`Income`
    变量是整数，而 `Customer Lifetime Value` 特征是浮点数。为了快速查看具有数值的变量的分布，你也可以执行以下操作：
- en: '![](img/58348fa5-b7e6-49c3-b9de-5175614c4b24.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](img/58348fa5-b7e6-49c3-b9de-5175614c4b24.png)'
- en: As you can see in this Jupyter Notebook snapshot, the `describe` function of
    a `pandas` DataFrame shows the distributions of all of the columns with numerical
    values. For example, you can see that there are a total of `9134` records in the `Customer
    Lifetime Value` column, with a mean of `8004.94` and ranges from `1898.01` to
    `83325.38`.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 如你在这个 Jupyter Notebook 截图中看到的，`pandas` DataFrame 的 `describe` 函数显示了所有数值列的分布。例如，你可以看到
    `Customer Lifetime Value` 列中共有 `9134` 条记录，均值为 `8004.94`，范围从 `1898.01` 到 `83325.38`。
- en: 'We are going to store this list of the names of continuous variables in a separate
    variable, named `continuous_vars`. Take a look at the following code:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将把这些连续变量的名称存储在一个单独的变量中，命名为 `continuous_vars`。请看以下代码：
- en: '[PRE7]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Now that we know which columns are continuous variables, let''s start to fit
    a logistic regression model. In order to do that, we need to first import the `statsmodels`
    package, as shown in the following code:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经知道哪些列是连续变量，让我们开始拟合逻辑回归模型。为此，我们需要先导入 `statsmodels` 包，如下代码所示：
- en: '[PRE8]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'With the `statsmodels` package imported, the code to initiate a logistic regression
    model is quite simple, and looks as follows:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 导入 `statsmodels` 包后，启动一个逻辑回归模型的代码非常简单，如下所示：
- en: '[PRE9]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'As you can see from this code, we are using the `Logit` function within the
    `statsmodels` package. We are supplying the `Engaged` column as the output variable,
    which the model will learn to estimate, and the `continuous_vars` that contain
    all of the continuous variables as the input variables. Once a logistic regression
    object is created with the output and input variables defined, we can train or
    fit this model by using the following code:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 如你从这段代码中看到的，我们正在使用 `statsmodels` 包中的 `Logit` 函数。我们将 `Engaged` 列作为输出变量，模型将学习如何估计该输出，而
    `continuous_vars` 列包含所有的连续变量，作为输入变量。定义了输出和输入变量后，一旦创建了逻辑回归对象，我们可以使用以下代码来训练或拟合这个模型：
- en: '[PRE10]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'As you can see in this code, we are using the `fit` function of the logistic
    regression object, `logit`, to train a logistic regression model. Once this code
    is run, the trained model, `logit_fit`, will have learned the optimal solution
    that best estimates the output variable, `Engaged`, by using the input variables.
    In order to get a detailed description of the trained model, you can use the following
    code:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 如你在这段代码中看到的，我们正在使用逻辑回归对象`logit`的`fit`函数来训练逻辑回归模型。运行这段代码后，训练好的模型`logit_fit`将学习出最佳解决方案，通过使用输入变量来最佳估计输出变量`Engaged`。若要获得已训练模型的详细描述，可以使用以下代码：
- en: '[PRE11]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'When you run this code, the `summary` function will display the following output
    in the Jupyter Notebook:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 当你运行这段代码时，`summary`函数将在Jupyter Notebook中显示以下输出：
- en: '![](img/39146c4c-eacf-42ab-80f4-4801a8e3b76b.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](img/39146c4c-eacf-42ab-80f4-4801a8e3b76b.png)'
- en: Let's take a closer look at this model output. `coef` represents the coefficients
    for each of the input variables, and `z` represents the *z*-score, which is the
    number of standard deviations from the mean. The `P>|z|` column represents the
    *p*-value, which means how likely it is to observe the relationship between the
    feature and the output variable by chance. So, the lower the value of `P>|z|`
    is, the more likely it is that the relationship between the given feature and
    the output variable is strong and is not by chance. Typically, `0.05` is a good
    cut-off point for the *p*-value, and any value less than `0.05` signifies a strong
    relationship between the given feature and the output variable.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更仔细地看看这个模型输出。`coef`表示每个输入变量的系数，`z`表示*z*-分数，它是离均值的标准差个数。`P>|z|`列表示*p*-值，它表示通过偶然性观察到特征与输出变量之间关系的可能性。因此，`P>|z|`的值越低，给定特征与输出变量之间的关系越强，且不太可能是偶然的。通常，`0.05`是一个良好的*p*-值临界点，任何小于`0.05`的值都表示给定特征与输出变量之间存在强关系。
- en: Looking at this model output, we can see that `Income`, `Monthly Premium Auto`,
    `Months Since Last Claim`, `Months Since Policy Inception`, and `Number of Policies` variables
    have significant relationships with the output variable, `Engaged`. For example, `Number
    of Policies` variable is significant and is negatively correlated with `Engaged`.
    This suggests that the more policies that the customers have, the less likely
    they are to respond to marketing calls. As another example, the `Months Since
    Last Claim` variable is significant and is negatively correlated with the output
    variable, `Engaged`. This means that the longer it has been since the last claim,
    the less likely that the customer is going to respond to marketing calls.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个模型输出中，我们可以看到，`Income`、`Monthly Premium Auto`、`Months Since Last Claim`、`Months
    Since Policy Inception`和`Number of Policies`变量与输出变量`Engaged`有显著的关系。例如，`Number
    of Policies`变量是显著的，并且与`Engaged`呈负相关。这表明，客户拥有的保单越多，他们响应营销电话的可能性越小。另一个例子是，`Months
    Since Last Claim`变量也是显著的，并且与输出变量`Engaged`呈负相关。这意味着，自上次理赔以来的时间越长，客户回应营销电话的可能性就越低。
- en: As you can see from these examples, you can interpret the regression analysis
    results quite easily by looking at the *p*-values and coefficients of the features
    from the model output. This is a good way to understand which attributes of customers
    are significantly and highly correlated with your outcomes of interest.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 从这些例子中你可以看出，通过查看模型输出中特征的*p*-值和系数，你可以轻松地解释回归分析结果。这是理解哪些客户特征与我们关心的结果显著相关的好方法。
- en: Categorical variables
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分类变量
- en: 'As you saw in the case of continuous variables in the previous section, it
    is quite straightforward to understand the relationships between the input and
    output variables from the coefficients and *p*-values. However, it becomes not
    so straightforward when we introduce **categorical variables**. Categorical variables
    often do not have any natural order, or they are encoded with non-numerical values,
    but in linear regression, we need the input variables to have numerical values
    that signify the order or magnitudes of the variables. For example, we cannot
    easily encode the `State` variable in our dataset with certain orderings or values.
    That is why we need to handle categorical variables differently from continuous
    variables when conducting regression analysis. In Python, there are multiple ways
    to handle categorical variables when using the `pandas` package. Let''s first
    look at factorizing categorical variables, as shown in the following code:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在上一节中看到的连续变量的例子，理解输入和输出变量之间的关系是相当直接的，尤其是通过系数和*p*-值。然而，当我们引入**类别变量**时，情况就变得不那么直观了。类别变量通常没有任何自然顺序，或者它们被编码为非数值型的值，但在回归分析中，我们需要输入变量具有数值型的值，这些值能够表示变量的顺序或大小。例如，我们无法轻松地为数据集中的`State`变量编码出某种顺序或数值。这就是为什么在进行回归分析时，我们需要与连续变量不同地处理类别变量。在Python中，当使用`pandas`包时，有多种方式来处理类别变量。我们首先来看一下如何对类别变量进行因子化，如下面的代码所示：
- en: '[PRE12]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The `pandas` function, `factorize`, encodes categorical variables with numerical
    values by enumerating through the values. Let''s take a look at the following
    output first:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '`pandas`的`factorize`函数通过枚举值对类别变量进行数值编码。我们先来看一下下面的输出：'
- en: '![](img/6bd1e57a-4ea2-4d5d-b7a6-96c59a34773e.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6bd1e57a-4ea2-4d5d-b7a6-96c59a34773e.png)'
- en: As you can see from this output, the values of this `Gender` variable are encoded
    with zeros and ones, where `0` symbolizes female (`F`) and `1` symbolizes male
    (`M`). This is a quick way to encode categorical variables with numerical values.
    However, this function does not work when we want to embed natural orderings into
    the encoded values. For example, the `Education` variable in our dataset has five
    different categories: `High School or Below`, `Bachelor`, `College`, `Master`,
    and `Doctor`. We might want to embed the orderings when encoding different categories
    within this `Education` variable.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个输出中可以看出，`Gender`变量的值被用零和一编码，其中`0`表示女性（`F`），`1`表示男性（`M`）。这是一种快速地将类别变量编码为数值型值的方法。然而，当我们希望将自然顺序嵌入编码值时，这个函数就不起作用了。例如，我们数据集中的`Education`变量有五个不同的类别：`High
    School or Below`、`Bachelor`、`College`、`Master`和`Doctor`。我们可能希望在对`Education`变量内的不同类别进行编码时，能够嵌入顺序关系。
- en: 'The following code shows another way to encode categorical variables with orderings
    when using `pandas`:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码展示了另一种在使用`pandas`时对类别变量进行排序编码的方法：
- en: '[PRE13]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'As you can see in this code, we are using the `pd.Categorical` function to
    encode the values of `df[''Education'']`. We can define the orderings that we
    want with the argument, `categories`. In our example, we are giving values of
    `0`, `1`, `2`, `3`, and `4` for the `High School or Below`, `Bachelor`, `College`, `Master`,
    and `Doctor`, categories respectively. The output looks as follows:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 如你在这段代码中看到的，我们使用`pd.Categorical`函数对`df['Education']`的值进行编码。我们可以通过参数`categories`来定义我们希望的排序。在我们的例子中，我们为`High
    School or Below`、`Bachelor`、`College`、`Master`和`Doctor`这些类别分别赋予了`0`、`1`、`2`、`3`和`4`的值。输出如下所示：
- en: 'We will now add these encoded variables to the pandas DataFrame, `df`, as shown
    in the following code:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将这些编码后的变量添加到pandas DataFrame `df`中，如下面的代码所示：
- en: '[PRE14]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'With these encodings for the two categorical variables, `Gender` and `Education`,
    we can now fit a logistic regression model using the following code:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这两个类别变量，`Gender`和`Education`的编码后，我们可以使用以下代码来拟合逻辑回归模型：
- en: '[PRE15]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Similar to how we fit a logistic regression model with continuous variables
    previously, we can fit a logistic regression model with the encoded categorical
    variables, `GenderFactorized` and `EducationFactorized`, by using the `Logit`
    function in the `statsmodels` package. Using the `summary` function of the fitted
    logistic regression model object, we will get the following output:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于之前如何使用连续变量拟合逻辑回归模型，我们可以使用`statsmodels`包中的`Logit`函数，利用编码后的类别变量`GenderFactorized`和`EducationFactorized`来拟合逻辑回归模型。使用拟合后的逻辑回归模型对象的`summary`函数，我们将得到如下输出：
- en: '![](img/5ebbe76b-7881-455c-923a-8f3a1025b757.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5ebbe76b-7881-455c-923a-8f3a1025b757.png)'
- en: As you can see in this output and by looking at the *p*-values in the `P>|z|`
    column, both the `GenderFactorized` and `EducationFactorized` variables seem to
    have significant relationships with the output variable `Engaged`. If we look
    at the coefficients of these two variables, we can see that both are negatively
    correlated with the output. This suggests that male customers, encoded with `1`
    in the `GenderFactorized` variable, are less likely to be engaged with marketing
    calls, as compared to female customers, encoded with `0` in the `GenderFactorized` variable.
    Similarly, the higher the customers' education levels are, the less likely that
    they will be engaged with marketing calls.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，从输出结果中以及查看`P>|z|`列中的*p*-值，`GenderFactorized`和`EducationFactorized`这两个变量似乎与输出变量`Engaged`之间存在显著关系。如果我们查看这两个变量的系数，可以看到它们与输出变量呈负相关。这表明，与女性客户（在`GenderFactorized`变量中编码为`0`）相比，男性客户（在`GenderFactorized`变量中编码为`1`）更不可能参与营销电话。同样，客户的教育水平越高，他们参与营销电话的可能性就越低。
- en: We have discussed two ways of handling categorical variables in `pandas`, using
    the `factorize` and `Categorical` functions. With these techniques, we can understand
    how different categories of categorical variables are correlated with the output
    variable.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经讨论了在`pandas`中处理分类变量的两种方法，分别是使用`factorize`和`Categorical`函数。通过这些技术，我们可以了解不同类别的分类变量与输出变量之间的相关性。
- en: Combining continuous and categorical variables
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结合连续变量和分类变量
- en: 'The last Python exercise that we are going to do in this chapter involves combining
    continuous and categorical variables for our regression analysis. We can fit a
    logistic regression model by using both categorical and continuous variables,
    as shown in the following code:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们将进行的最后一个 Python 练习涉及将连续变量和分类变量结合起来进行回归分析。我们可以通过同时使用分类变量和连续变量来拟合逻辑回归模型，代码如下所示：
- en: '[PRE16]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The only difference from the previous codes is the features that we selected
    to fit a logistic regression model. As you can see in this code, we are now fitting
    a logistic regression model with the continuous variables, as well as the two
    encoded categorical variables, `GenderFactorized` and `EducationFactorized`, that
    we created in the previous section. The results look as follows:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前的代码唯一不同的是我们选择的特征，用于拟合逻辑回归模型。如你所见，在这段代码中，我们现在使用连续变量以及之前部分章节中创建的两个编码后的分类变量`GenderFactorized`和`EducationFactorized`来拟合逻辑回归模型。结果如下所示：
- en: '![](img/9d55b21f-2e47-4da4-a572-f517ad414c2a.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9d55b21f-2e47-4da4-a572-f517ad414c2a.png)'
- en: Let's take a closer look at this output. The `Income`, `Monthly Premium Auto`,
    `Months Since Last Claim,` `Months Since Policy Inception`, `Number of Open Complaints`,
    `Number of Policies`, and `GenderFactorized` variable are significant at a `0.05` significance
    level, and all of them have negative relationships with the output variable, `Engaged`.
    Hence, the higher the income is, the less likely that the customer will be engaged
    with marketing calls. Similarly, the more policies that the customer has, the
    less likely that he or she will be engaged with marketing calls.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们仔细看看这个输出。`Income`、`Monthly Premium Auto`、`Months Since Last Claim`、`Months
    Since Policy Inception`、`Number of Open Complaints`、`Number of Policies`和`GenderFactorized`这些变量在`0.05`的显著性水平下具有显著性，且它们与输出变量`Engaged`之间的关系都是负相关的。因此，收入越高，客户参与营销电话的可能性就越低。同样，客户拥有的保单越多，他们参与营销电话的可能性就越低。
- en: Lastly, male customers are less likely to engage with marketing calls than female
    customers, which we can see from looking at the coefficient of `GenderFactorized`. From
    looking at this regression analysis output, we can easily see the relationships
    between the input and output variables, and we can understand which attributes
    of customers are positively or negatively related to customer engagement with
    marketing calls.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，男性客户比女性客户更不可能参与营销电话，我们可以从`GenderFactorized`的系数中看到这一点。从这个回归分析的输出结果来看，我们可以轻松看到输入变量与输出变量之间的关系，并且可以理解哪些客户的属性与他们是否参与营销电话之间是正相关还是负相关。
- en: The full code for the Python exercise in this chapter can be found at [https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.3/python/RegressionAnalysis.ipynb](https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.3/python/RegressionAnalysis.ipynb).
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中 Python 练习的完整代码可以在 [https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.3/python/RegressionAnalysis.ipynb](https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.3/python/RegressionAnalysis.ipynb)
    找到。
- en: Regression analysis with R
  id: totrans-112
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 R 进行回归分析
- en: In this section, you are going to learn how to use the `glm` function in R to
    conduct regression analysis. For those readers that would like to use Python instead
    of R for this exercise, the step-by-step instructions for Python are in the previous
    section. We will start this section by analyzing the data more closely, using
    the `dplyr` package, and then we will discuss how to build regression models and
    interpret the results using the `glm` function.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将学习如何使用 R 中的 `glm` 函数进行回归分析。对于那些希望使用 Python 而非 R 进行此练习的读者，Python 的逐步操作说明可以在上一节找到。我们将从更仔细地分析数据开始，使用
    `dplyr` 包，然后讨论如何使用 `glm` 函数构建回归模型并解读结果。
- en: 'For this exercise, we will be using one of the publicly available datasets
    from IBM Watson, which can be found at [https://www.ibm.com/communities/analytics/watson-analytics-blog/marketing-customer-value-analysis/](https://www.ibm.com/communities/analytics/watson-analytics-blog/marketing-customer-value-analysis/).
    You can follow this link and download the data file in a CSV format. In order
    to load this data into your RStudio, you can run the following code:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在本次练习中，我们将使用来自 IBM Watson 的一个公开数据集，可以在 [https://www.ibm.com/communities/analytics/watson-analytics-blog/marketing-customer-value-analysis/](https://www.ibm.com/communities/analytics/watson-analytics-blog/marketing-customer-value-analysis/)
    找到。你可以点击此链接并下载 CSV 格式的数据文件。为了将数据加载到你的 RStudio 中，你可以运行以下代码：
- en: '[PRE17]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Similar to what we did in [Chapter 2](1fb7a852-d8fa-43f6-9807-6e3292dfa280.xhtml), *Key
    Performance Indicators and Visualizations*, we will first import the `dplyr` and `ggplot2` packages
    for data analysis and plotting in the following sections. Using the `read.csv` function
    in R, we can read the data into a DataFrame. Since this CSV file contains the
    header in the first row and the fields are separated by commas, we are using the `header=TRUE`
    and `sep=","` flags for the correct parsing.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于我们在 [第 2 章](1fb7a852-d8fa-43f6-9807-6e3292dfa280.xhtml) *关键绩效指标与可视化* 中所做的那样，我们将在接下来的章节中首先导入
    `dplyr` 和 `ggplot2` 包，以进行数据分析和绘图。通过在 R 中使用 `read.csv` 函数，我们可以将数据读取到 DataFrame
    中。由于此 CSV 文件的第一行包含标题，且字段由逗号分隔，我们使用 `header=TRUE` 和 `sep=","` 标志以确保正确解析数据。
- en: 'The following screenshot shows how the raw data looks in the DataFrame:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图展示了数据在 DataFrame 中的原始样子：
- en: '![](img/bfe00dbe-78f4-45a4-a4aa-2376f7431410.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bfe00dbe-78f4-45a4-a4aa-2376f7431410.png)'
- en: Now that we have loaded the data into a DataFrame, let's start to look at and
    analyze the data more closely, so that we can better understand the structure
    of the data.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经将数据加载到 DataFrame 中，让我们开始更仔细地查看和分析数据，以便更好地理解数据的结构。
- en: Data analysis and visualization
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据分析与可视化
- en: 'Before we dive into regression analysis, let''s first take a more detailed
    look at the data, in order to have a better understanding of what data points
    we have and what patterns we can see in the data. If you look at the data, you
    will notice a column named `Response`. It contains information on whether a customer
    responded to their marketing calls. We will use this field as a measure of customer
    engagement. For future computations, it will be better to encode this field with
    numerical values. Let''s take a look at the following code:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入回归分析之前，让我们先更详细地查看数据，以便更好地了解我们拥有的数据点以及可以在数据中看到的模式。如果你查看数据，会注意到一个名为 `Response`
    的列，它包含客户是否回应营销电话的信息。我们将使用这个字段作为客户参与度的衡量标准。为了进行未来的计算，最好将这个字段编码为数值类型。让我们来看一下以下代码：
- en: '[PRE18]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: As you can see in this code, using the `as.integer` function, we are encoding
    those who did not respond to marketing calls (`No`) with a value of `0` and those
    who did respond (`Yes`) with a value of `1`. Because `as.integer function` encodes
    values to `1` and `2` by default, we are subtracting the values by `1` to encode
    the response values with zeros and ones. Then, we are creating a new field named `Engaged` with
    these encoded values.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 如您在这段代码中所见，我们使用`as.integer`函数将未回应营销电话（`No`）的客户编码为`0`，将回应营销电话（`Yes`）的客户编码为`1`。由于`as.integer`函数默认将值编码为`1`和`2`，我们通过减去`1`来将回应值编码为零和一。然后，我们创建了一个名为`Engaged`的新字段，其中包含这些编码后的值。
- en: Engagement rate
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参与率
- en: 'The first thing that we are going to look at is the aggregate engagement rate.
    This engagement rate is simply the percentage of customers who responded to the
    marketing calls. Take a look at the following code:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先要看的内容是汇总的参与率。这个参与率简单来说就是回应了营销电话的客户所占的百分比。请看以下代码：
- en: '[PRE19]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'As you can see in this code, we are grouping by the newly created field, `Engaged`,
    using the `group_by` function. Then, we are counting the number of records or
    customers in each `Engaged` group with the `n()` function. By dividing by the
    total number of customers in the DataFrame, `df`, and multiplying by `100.0`,
    we get the engagement rate. The results look as follows:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 如您在这段代码中所见，我们通过使用`group_by`函数按新创建的`Engaged`字段进行分组。然后，我们使用`n()`函数统计每个`Engaged`组中的记录或客户数量。通过将其除以数据框`df`中的总客户数，并乘以`100.0`，我们得到了参与率。结果如下所示：
- en: '![](img/46c83142-7a95-4635-abf9-0bf6c55b1192.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![](img/46c83142-7a95-4635-abf9-0bf6c55b1192.png)'
- en: 'To make it easier to read, we can transpose the DataFrame, meaning that we
    can flip the rows and columns in the DataFrame. You can transpose a DataFrame by
    using the `t` function in R. The code looks as follows:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更方便地阅读，我们可以转置数据框，这意味着我们将数据框中的行和列进行交换。您可以使用R中的`t`函数来转置数据框。代码如下所示：
- en: '[PRE20]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The transposed DataFrame appears as follows:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 转置后的数据框如下所示：
- en: '![](img/61534cae-683e-4984-ae49-6a1f375555b3.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![](img/61534cae-683e-4984-ae49-6a1f375555b3.png)'
- en: As you can see, it is easier to see the total number and percentage of engaged
    and non-engaged customers by transposing the DataFrame. From this data, we can
    see that about 14% of the customers have responded to marketing calls, and the
    remaining 86% of the customers have not responded.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，通过转置数据框，我们可以更容易地查看参与和未参与客户的总数和百分比。从这些数据中，我们可以看到大约14%的客户回应了营销电话，剩余的86%的客户未回应。
- en: Sales channels
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 销售渠道
- en: 'Now, let''s see if we can find any noticeable patterns in sales channels and
    engagement. We are going to analyze how the engaged and non-engaged customers
    are distributed among different sales channels. Let''s first look at the following
    code:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看是否能发现销售渠道和参与之间的明显模式。我们将分析参与和未参与的客户在不同销售渠道中的分布。首先请看以下代码：
- en: '[PRE21]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'As you can see in this code snippet, we are using the `group_by` function in
    R to group by the `Sales Channel` and `Engaged` variables. Then, using the `n()`
    function, we will count the number of customers in each group. Once you have run
    this code, the `salesChannel` DataFrame will look as follows:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 如您在这段代码中所见，我们使用了R中的`group_by`函数对`Sales Channel`和`Engaged`变量进行分组。然后，使用`n()`函数，我们将统计每个组中的客户数量。运行这段代码后，`salesChannel`数据框将如下所示：
- en: '![](img/34a46f66-6a8f-4c2d-aa4c-b8ee50112ab4.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![](img/34a46f66-6a8f-4c2d-aa4c-b8ee50112ab4.png)'
- en: 'As you will have noticed from the previous section, there are significantly
    more customers that are not engaged with the marketing efforts, so it is quite
    difficult to compare and see the differences in the sales channel distributions
    between the engaged and non-engaged customers with the raw numbers. To make it
    easier to differentiate visually, we can build pie charts using the following
    code:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您在上一节中所注意到的，未参与营销活动的客户明显更多，因此，单凭原始数字很难比较并查看参与和未参与客户在销售渠道分布上的差异。为了更直观地区分这些差异，我们可以使用以下代码绘制饼图：
- en: '[PRE22]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Similar to what we did in [Chapter 2](1fb7a852-d8fa-43f6-9807-6e3292dfa280.xhtml), *Key
    Performance Indicators and Visualizations*, we are using `ggplot` to build a chart
    in R. If you remember that chapter, we can build pie charts by using `geom_bar`
    with `coord_polar("y")`. By using `face_wrap(~Engaged)`, we can split the pie
    charts in two: one for non-engaged customers and another for engaged customers.
    Once you have run this code, you will see the following pie charts, which show
    the distributions of engaged and non-engaged customers across different sales
    channels:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 与我们在[第2章](1fb7a852-d8fa-43f6-9807-6e3292dfa280.xhtml)《关键绩效指标和可视化》中所做的类似，我们使用`ggplot`来在R中构建图表。如果你还记得那一章，我们可以通过使用`geom_bar`和`coord_polar("y")`来构建饼图。通过使用`facet_wrap(~Engaged)`，我们可以将饼图分成两部分：一部分是未参与的客户，另一部分是已参与的客户。一旦你运行了这段代码，你会看到如下饼图，展示了已参与和未参与的客户在不同销售渠道中的分布：
- en: '![](img/8c162b53-d864-4865-93eb-13c38d1fc0a6.png)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8c162b53-d864-4865-93eb-13c38d1fc0a6.png)'
- en: Compared to the previous data table that shows raw counts of engaged and non-engaged
    customers in each sales channel, these pie charts can help us to visually see
    the differences in the distributions more easily. As you can see from these charts,
    more than half of the engaged customers were from agents, whereas non-engaged
    customers are more evenly distributed across all four different channels. As you
    can see from these charts, analyzing and visualizing data can help us to notice
    interesting patterns in the data, which will further help us when we run regression
    analysis in the later parts of this chapter.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前展示的每个销售渠道中已参与和未参与客户的原始计数数据表相比，这些饼图可以帮助我们更直观地看到分布差异。如你从这些图表中所看到的，超过一半的已参与客户来自代理商，而未参与的客户则在所有四个销售渠道中分布较为均匀。从这些图表中可以看出，数据分析和可视化帮助我们发现数据中的有趣模式，这将进一步帮助我们在本章后续进行回归分析时。
- en: Total claim amounts
  id: totrans-144
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总赔偿金额
- en: 'The last thing that we are going to look at before we dive into the regression
    analysis is are the differences in the distributions of `Total Claim Amount` between
    the engaged and non-engaged groups. We are going to visualize this by using box
    plots. Let''s first look at how we can build box plots in R:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入回归分析之前，最后要看的内容是`Total Claim Amount`在已参与和未参与组之间的分布差异。我们将通过箱线图来可视化这一点。首先，我们来看一下如何在R中构建箱线图：
- en: '[PRE23]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'As you can see in this code, it is quite straightforward to build box plots
    in R. You can simply call the `ggplot` function with `geom_boxplot`. A box plot
    is a great way to visualize the distributions of continuous variables. It shows
    the min, max, first quartile, median, and third quartile, all in one view. The
    following box plot shows the distributions of `Total Claim Amount` between the
    engaged and non-engaged groups:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在这段代码中所看到的，在R中构建箱线图非常简单。你只需调用`ggplot`函数，并使用`geom_boxplot`。箱线图是可视化连续变量分布的一个好方法。它显示了最小值、最大值、第一个四分位数、中位数和第三个四分位数，所有这些都能一目了然地呈现。以下箱线图展示了`Total
    Claim Amount`在已参与和未参与组之间的分布：
- en: '![](img/25b89a8f-f883-400c-812b-6866d25c84b7.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![](img/25b89a8f-f883-400c-812b-6866d25c84b7.png)'
- en: The central rectangle spans from the first quartile to the third quartile, and
    the line within the rectangle shows the median. The lower and upper ends of the
    lines from the rectangle show the minimum and maximum of the distribution, respectively.
    Another thing that you will notice from these box plots are the dots above the
    upper end of the line.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 中央矩形从第一个四分位数到第三个四分位数，矩形内的线表示中位数。矩形的上下端点分别表示分布的最小值和最大值。你还会注意到这些箱线图中，线的上方有一些点。
- en: The dots beyond the end of the upper line show the suspected outliers, which
    are decided based on the IQR. The IQR is simply the range between the first and
    third quartiles, which is the same as the height of the rectangle in the box plot
    that spans from the first quartile to the third quartile. The data points that
    fall `1.5*IQR` above the third quartile or `1.5*IQR` below the first quartile
    are suspected outliers, and are shown with the dots.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 超过上边线的点表示疑似异常值，这些值是基于IQR（四分位距）来判断的。IQR是指第一个四分位数和第三个四分位数之间的范围，也就是箱线图中从第一个四分位数到第三个四分位数的矩形高度。数据点如果高于第三个四分位数`1.5*IQR`或低于第一个四分位数`1.5*IQR`，就被认为是疑似异常值，并用点表示。
- en: 'Depending on your analysis goals, you might not care about (or you might not
    want to show) the outliers in box plots. Let''s take a look at the following code
    to see how we can remove those outliers from the box plots:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 根据你的分析目标，你可能不在乎（或者你可能不想显示）箱线图中的异常值。我们来看一下以下代码，看看如何从箱线图中去除这些异常值：
- en: '[PRE24]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'As you will notice in this code snippet, the only difference between this code
    and the previous one is `outlier.shape=NA` in the `geom_boxplot` function. Let''s
    take a look at how the box plots look now:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 如你在这段代码中所注意到的，这段代码与之前的唯一区别是`geom_boxplot`函数中的`outlier.shape=NA`。我们来看一下现在箱线图的样子：
- en: '![](img/427c69d6-87c2-4137-bd7d-f9d4d565c7c9.png)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![](img/427c69d6-87c2-4137-bd7d-f9d4d565c7c9.png)'
- en: In these plots, we can no longer see the dots beyond the end of the upper line.
    Depending on what you would like to show and analyze, having outliers in box plots
    may or may not help.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些图中，我们不再看到超出上限的点。根据你想要展示和分析的内容，箱线图中是否包含异常值可能会有所不同。
- en: Regression analysis
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回归分析
- en: So far, we have analyzed the types of fields that we have in the data and how
    the patterns differ between the engaged group and the non-engaged group. Now,
    we are going to discuss how to conduct and interpret regression analysis in R,
    using the `glm` function. We will first build a logistic regression model with
    continuous variables, and you will learn how to interpret the results. Then, we
    are going to discuss how to handle categorical variables when fitting regression
    models in R, and what impact those categorical variables have on the fitted logistic
    regression model.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经分析了数据中的字段类型以及参与组和非参与组之间的模式差异。接下来，我们将讨论如何使用`glm`函数进行回归分析并解释结果。我们将首先构建一个包含连续变量的逻辑回归模型，并学习如何解释其结果。然后，我们将讨论在`R`中拟合回归模型时如何处理分类变量，以及这些分类变量对拟合的逻辑回归模型的影响。
- en: Continuous variables
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 连续变量
- en: 'In linear regression, including logistic regression, it is straightforward
    to fit a regression model when the feature variables are continuous, as it just
    needs to find a linear combination of feature variables with numerical values
    for estimating the output variable. In order to fit a regression model with continuous
    variables, let''s first take a look at how to get the data types of the columns
    in an `R` DataFrame. Take a look at the following code:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在线性回归中，包括逻辑回归，当特征变量是连续变量时，拟合回归模型非常简单，因为它只需要找到特征变量的线性组合来估计输出变量。为了拟合一个包含连续变量的回归模型，我们首先来看一下如何获取`R`数据框中各列的数据类型。请看以下代码：
- en: '[PRE25]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Using the `sapply` function in `R`, we can apply the `class` function across
    the columns in a DataFrame, and the `class` function tells us the types of data
    in each column. The results of this code are as follows:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在`R`中使用`sapply`函数，我们可以将`class`函数应用于数据框的各列，`class`函数告诉我们每列的数据类型。此代码的输出如下所示：
- en: '![](img/99e6ea9c-822d-4e6b-8904-853a3b426c2b.png)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![](img/99e6ea9c-822d-4e6b-8904-853a3b426c2b.png)'
- en: 'Shown in the preceding screenshot, we can easily see which columns have numerical
    values and which do not. For example, the type of the `State` column is `"factor"`,
    which means that the variable is a categorical variable. On the other hand, the
    type of the `Customer.Lifetime.Value` column is `"numeric"`, and this means that
    this variable is a continuous variable with numeric values. Aside from this, we
    can also use an `R` function, `summary`, to get the summary statistics for each
    column of a DataFrame, so that we can see not only the types of each column, but
    can also take a look at a summary of what the distributions for each column look
    like. The code is as follows:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 如前面的截图所示，我们可以轻松看出哪些列包含数值，哪些列不包含数值。例如，`State`列的类型是`"factor"`，这意味着该变量是一个分类变量。另一方面，`Customer.Lifetime.Value`列的类型是`"numeric"`，这意味着该变量是一个具有数值的连续变量。除此之外，我们还可以使用`R`函数`summary`来获取数据框中每列的汇总统计信息，这样我们不仅可以查看每列的数据类型，还能看到每列的分布概况。代码如下：
- en: '[PRE26]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'When you run this code, you will get output that looks as follows:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 当你运行此代码时，输出将如下所示：
- en: '![](img/3fc841d4-179a-4089-b299-b0934b7fd763.png)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3fc841d4-179a-4089-b299-b0934b7fd763.png)'
- en: In this output, we can easily see a snapshot of the distributions of each column
    in an `R` DataFrame. For example, for the `State` variable, we can easily see
    that there are `1703` records or customers from `Arizona` and `3150` customers
    from `California`. On the other hand, we can easily see that the minimum value
    for the`Customer.Lifetime.Value` variable is `1898`, whereas, the mean is `8005`
    and the maximum value is `83325`.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个输出中，我们可以轻松地看到每列在`R`数据框中的分布情况。例如，对于`State`变量，我们可以看到来自`Arizona`的记录或客户有`1703`条，来自`California`的客户有`3150`条。另一方面，我们可以看到`Customer.Lifetime.Value`变量的最小值是`1898`，均值是`8005`，最大值是`83325`。
- en: 'Given this information from the previous code, we can easily select only the
    columns with numerical values, by using the following code:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 根据前面代码中的信息，我们可以轻松地通过以下代码只选择数值型列：
- en: '[PRE27]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'As you can see in this code snippet, we are using the `select_if` function,
    and the arguments for this function are the DataFrame, `df`, and a conditional
    statement, `is.numeric`, to define the type of column that we want to sub-select
    from the DataFrame. Using this function, only the numerical columns in the DataFrame,
    `df`, are selected and stored as a separate variable, named `continuousDF`. With
    the `colnames` function, we can see what columns are in the newly created DataFrame,
    `continuousDF`. You should see an output that looks like the following:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 如你在这段代码中所见，我们使用了`select_if`函数，传入的参数是数据框`df`和条件语句`is.numeric`，用于定义我们希望从数据框中子选的列类型。使用这个函数，数据框`df`中只有数值型的列会被选中，并作为一个名为`continuousDF`的单独变量存储。通过`colnames`函数，我们可以查看新创建的数据框`continuousDF`中有哪些列。你应该会看到类似以下的输出：
- en: '![](img/fa4c358f-ccd2-4da8-9e75-a743a319ce02.png)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fa4c358f-ccd2-4da8-9e75-a743a319ce02.png)'
- en: 'We are now ready to fit a logistic regression model with continuous variables.
    Let''s take a look at the following code first:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在准备使用连续变量拟合逻辑回归模型。首先让我们看看以下代码：
- en: '[PRE28]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: In R, you can fit regression models by using the `glm` function, which stands
    for **generalized linear models**. The R function `glm` can be used for various
    linear models. By default, the value of the family argument is `gaussian`, which
    tells the algorithm to fit a simple linear regression model. On the other hand,
    like in our case, if you use `binomial` for `family`, then it is going to fit
    a logistic regression model. For more detailed descriptions of the different values
    that you can use for the `family` argument, you can refer to [https://stat.ethz.ch/R-manual/R-devel/library/stats/html/family.html](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/family.html).
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在R中，你可以通过使用`glm`函数来拟合回归模型，`glm`代表**广义线性模型**。R的`glm`函数可以用于各种线性模型。默认情况下，`family`参数的值是`gaussian`，这会告诉算法拟合一个简单的线性回归模型。另一方面，如我们在此案例中所示，如果将`family`设置为`binomial`，则会拟合一个逻辑回归模型。有关`family`参数可以使用的不同值的详细描述，你可以参考[https://stat.ethz.ch/R-manual/R-devel/library/stats/html/family.html](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/family.html)。
- en: 'The other two arguments that we passed on to the `glm` function are `formula`
    and `data`. The first argument, `formula`, is where you define how you want the
    model to be fit. The variable on the left side of `~` is the output variable,
    and the one on the right side of `~` is the input variable. In our case, we are
    telling the model to learn how to estimate the output variable, `Engaged`, by
    using all of the other variables as the input variables. If you want to use only
    a subset of the variables as the input variables, then you can use something like
    the following for the formula:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 我们传递给`glm`函数的另外两个参数是`formula`和`data`。第一个参数`formula`是定义模型拟合方式的地方。`~`左侧的变量是输出变量，右侧的变量是输入变量。在我们的案例中，我们告诉模型通过使用其他所有变量作为输入变量来学习如何估计输出变量`Engaged`。如果你只想使用部分变量作为输入变量，则可以像下面这样编写公式：
- en: '[PRE29]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: In this formula, we are telling the model to learn how to estimate the output
    variable, `Engaged`, by only using `Income` and `Customer.Lifetime.Value` as the
    features. Lastly, the second argument in our `glm` function, `data`, defines which
    data to use to train a regression model.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个公式中，我们告诉模型通过仅使用`Income`和`Customer.Lifetime.Value`作为特征来学习如何估计输出变量`Engaged`。最后，`glm`函数中的第二个参数`data`定义了用于训练回归模型的数据。
- en: 'Now that we have a trained logistic regression model, let''s take a look at
    the following code, which shows how we can get the detailed regression analysis
    results from this model object:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经有了一个训练好的逻辑回归模型，让我们来看看以下的代码，它展示了我们如何从这个模型对象中获取详细的回归分析结果：
- en: '[PRE30]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The `summary` function in R provides a detailed description of the regression
    analysis results, which look as follows:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: R中的`summary`函数提供了回归分析结果的详细描述，结果如下所示：
- en: '![](img/6c37619a-21ef-4ffa-b36e-9fc327da669a.png)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6c37619a-21ef-4ffa-b36e-9fc327da669a.png)'
- en: Let's take a more detailed look at this output. The `Estimate` column in the `Coefficients`
    section gives us the computed value for each of the feature coefficients. For
    example, the coefficient for the `Income` variable is `0.000002042`, and the coefficient
    for `Number.of.Policies` is `-0.02443`. We can also see that the estimated `Intercept`
    value is `-1.787`. The column `z value` gives us the *z*-score, which is the number
    of standard deviations from the mean of the population, and the column `Pr(>|z|)` is
    the *p*-value, which means how likely it is to observe the relationship between
    the feature and the output variable by chance. So, the lower the value of `Pr(>|z|)` is,
    the more likely it is that the relationship between the given feature and the
    output variable is strong and is not by chance. Typically, `0.05` is a good cut-off
    point for the *p*-value, and any value less than `0.05` signifies a strong relationship
    between the given feature and the output variable.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地看看这个输出。`Coefficients`部分的`Estimate`列给出了每个特征系数的计算值。例如，`Income`变量的系数是`0.000002042`，`Number.of.Policies`的系数是`-0.02443`。我们还可以看到估计的`Intercept`值是`-1.787`。`z
    value`列给出了*z*-值，它是人口均值的标准差数，而`Pr(>|z|)`列是*p*-值，它表示通过偶然性观察到特征与输出变量之间关系的可能性。因此，`Pr(>|z|)`值越低，给定特征与输出变量之间的关系就越可能是强烈的，而不是偶然的。通常，`0.05`是*p*-值的一个良好的分界点，任何小于`0.05`的值都表示给定特征与输出变量之间存在强关系。
- en: As you can see from the `Signif. codes` section under the `Coefficients` section
    in the output, the `***` symbol, next to the *p*-value in the `Coefficients` section,
    indicates the strongest relationship with the *p*-value at `0`; `**` means that
    the *p*-value is less than 0.001; `*` means that the *p*-value is less than `0.05`,
    and so forth. If you look at the regression analysis output again, only three
    variables, `Income`, `Number.of.Policies`, and `Total.Claim.Amount`, have significant
    relationships with the output variable, `Engaged`, at a `0.1` significance level.
    Also, we can see that `Income` and `Total.Claim.Amount` are positively correlated
    with `Engaged`, meaning that the higher the income is or the higher the total
    claim amount is, the more likely that a customer will be engaged with marketing
    calls. On the other hand, the variable `Number.of.Policies` is negatively correlated
    with `Engaged`, which suggests that the higher the number of policies that a customer
    has, the less likely that the given customer will be engaged with marketing calls.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 从输出中`Coefficients`部分下的`Signif. codes`部分可以看出，`***`符号位于`Coefficients`部分的*p*-值旁边，表示*p*-值为`0`时的最强关系；`**`表示*p*-值小于`0.001`；`*`表示*p*-值小于`0.05`，以此类推。如果你再看一下回归分析输出，只有三个变量——`Income`、`Number.of.Policies`和`Total.Claim.Amount`——在`0.1`的显著性水平下与输出变量`Engaged`有显著的关系。此外，我们可以看到，`Income`和`Total.Claim.Amount`与`Engaged`呈正相关，意味着收入越高或总索赔金额越高，客户与营销电话互动的可能性就越大。另一方面，`Number.of.Policies`与`Engaged`呈负相关，这表明客户拥有的保单数量越多，客户参与营销电话的可能性就越小。
- en: As you can see in these examples, you can interpret the regression analysis
    results quite easily, by looking at the *p*-values and coefficients of the features
    from the model output. This is a good way to understand which attributes of customers
    are significantly and highly correlated with your outcomes of interest.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在这些示例中看到的，通过查看模型输出中各特征的*p*-值和系数，你可以很容易地解释回归分析结果。这是一种很好地理解哪些客户属性与感兴趣的结果有显著和高度相关性的方法。
- en: Categorical variables
  id: totrans-185
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 类别变量
- en: 'As you saw in the case with continuous variables in the previous section, it
    is quite straightforward to understand the relationships between the input and
    output variables from the coefficients and *p*-values. However, it becomes not
    so straightforward when we introduce categorical variables. Categorical variables
    often do not have any natural order but, in linear regression, we need the `input`
    variables to have numerical values that signify the orderings or magnitudes of
    the variables. For example, we cannot easily encode the `State` variable in our
    dataset with certain orders or values. That is why we need to handle categorical
    variables differently from continuous variables when conducting regression analysis.
    In R, the `factor` function helps you to handle these categorical variables easily
    when running regression analysis. Take a look at the following code:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 如您在上一节关于连续变量的案例中看到的那样，从系数和*p*-值中理解输入变量与输出变量之间的关系是非常直接的。然而，当我们引入分类变量时，这就变得不那么直观了。分类变量通常没有自然的顺序，但在进行线性回归时，我们需要输入变量具有数值，这些数值表示变量的顺序或大小。例如，我们不能轻易地给我们的数据集中的`State`变量编码特定的顺序或数值。这就是为什么在进行回归分析时，我们需要与连续变量不同地处理分类变量。在R语言中，`factor`函数帮助您轻松处理这些分类变量，以便进行回归分析。请看以下代码：
- en: '[PRE31]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'As you can see in this code, we are fitting a logistic regression model with
    `Engaged` as the output variable and the factorized `Education` as the input variable.
    Before we dive deeper into what this means, let''s first look at the following
    regression analysis results:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 如您在这段代码中所见，我们正在拟合一个以`Engaged`作为输出变量、以因子化的`Education`作为输入变量的逻辑回归模型。在我们深入了解这意味着什么之前，先让我们看看以下的回归分析结果：
- en: '![](img/31ab77a5-aeb4-4ed5-8288-144e0ea82443.png)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
  zh: '![](img/31ab77a5-aeb4-4ed5-8288-144e0ea82443.png)'
- en: 'As you can see in this output, the `factor` function created four additional
    variables: `factor(Education)College`, `factor(Education)Doctor`, `factor(Education)High
    School or Below`, and `factor(Education)Master`. These variables are encoded with
    `0` if the given customer does not belong to the given category, or `1` if the
    given customer belongs to the given category. This way, we can understand the
    positive or negative relationship between each of the `Education` category and
    the `output` variable, `Engaged`. For example, the factor variable, `factor(Education)Doctor`,
    has a positive coefficient, which suggests that if a customer has a doctoral degree,
    then it is more likely that the given customer will be engaged with marketing
    calls.'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 如您在此输出中所见，`factor`函数创建了四个额外的变量：`factor(Education)College`、`factor(Education)Doctor`、`factor(Education)High
    School or Below`和`factor(Education)Master`。如果给定的客户不属于某一类别，这些变量会被编码为`0`；如果客户属于某一类别，这些变量则会被编码为`1`。这样，我们就可以理解每个`Education`类别与`output`变量`Engaged`之间的正向或负向关系。例如，因子变量`factor(Education)Doctor`具有正系数，这表明如果一个客户拥有博士学位，那么该客户更可能参与营销电话。
- en: If you look closely, you will notice that this output does not have a separate
    factor variable for the `Bachelor` category in the `Education` variable. This
    is because `(Intercept)` contains the information for the `Bachelor` category.
    If a customer has a bachelor's degree, then all of the other factor variables
    would have been encoded with `0`s. Hence, all of the coefficient values are cancelled
    out, and only the `(Intercept)` value stays. Since the estimated `(Intercept)`
    value is negative, if a customer has a `Bachelor` degree, then it is less likely
    that the given customer will be engaged with marketing calls.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 如果仔细观察，您会发现这个输出中，`Education`变量的`Bachelor`类别没有单独的因子变量。这是因为`(Intercept)`包含了`Bachelor`类别的信息。如果一个客户拥有学士学位，那么所有其他的因子变量都会被编码为`0`。因此，所有系数值都会被抵消，只有`(Intercept)`的值保留。由于估计的`(Intercept)`值为负数，如果一个客户拥有学士学位，那么该客户参与营销电话的可能性较低。
- en: 'Let''s take a look at another example:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看另一个例子：
- en: '[PRE32]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'As you can see in this code, we are now fitting a regression model with the `Education`
    and `Gender` variables, and the output looks as follows:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 如您在这段代码中所见，我们现在正在拟合一个包含`Education`和`Gender`变量的回归模型，输出结果如下：
- en: '![](img/86d48265-182c-4c31-b7e1-755ea30c0488.png)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![](img/86d48265-182c-4c31-b7e1-755ea30c0488.png)'
- en: If you look closely at this output, you can only see one additional factor variable,
    `factor(Gender)M`, for male customers, where the data clearly has female customers.
    This is because the `Bachelor` category of the `Education` variable and the `F`
    (female) category of the `Gender` variable are lumped together as `(Intercept)`
    of this regression model. Thus, the base case, wherein the values of all of the
    factor variables are `0`, is for `female` customers with a `Bachelor` degree.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 如果仔细查看此输出，您只会看到一个额外的因子变量 `factor(Gender)M`，它表示男性客户，而数据中明显包含女性客户。这是因为 `Education`
    变量中的 `Bachelor` 类别和 `Gender` 变量中的 `F`（女性）类别被归为该回归模型的 `(Intercept)`。因此，当所有因子变量的值为
    `0` 时，基本情况是具有 `Bachelor` 学位的 `female` 客户。
- en: For male customers with a `Bachelor` degree, the factor variable `factor(Gender)M` will
    now have a value of `1`, and hence, the estimated value for the output variable,
    `Engaged`, will be the value of `(Intercept)` plus the coefficient value of `factor(Gender)M`.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 对于具有 `Bachelor` 学位的男性客户，因子变量 `factor(Gender)M` 将具有值 `1`，因此，输出变量 `Engaged` 的估计值将是
    `(Intercept)` 加上 `factor(Gender)M` 的系数值。
- en: As we have discussed so far, we can handle categorical variables by using the
    `factor` function in R. It is essentially the same as creating one separate input
    variable per category for each of the categorical variables. Using this technique,
    we can understand how different categories of categorical variables are correlated
    with the output variable.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们到目前为止所讨论的那样，我们可以通过在 R 中使用 `factor` 函数来处理分类变量。它本质上与为每个分类变量的每个类别创建一个单独的输入变量相同。使用这种技术，我们可以理解不同类别的分类变量如何与输出变量相关联。
- en: Combining continuous and categorical variables
  id: totrans-199
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结合连续变量和分类变量
- en: 'The last exercise that we are going to do in this chapter involves combining
    continuous and categorical variables for our regression analysis. Let''s first
    factorize the two categorical variables, `Gender` and `Education`, that we discussed
    in the previous section, and store them in a DataFrame by using the following
    code:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们要做的最后一个练习涉及将连续变量和分类变量结合起来进行回归分析。我们首先将前一节中讨论的两个分类变量 `Gender` 和 `Education`
    进行因子化，并通过以下代码将它们存储在一个数据框中：
- en: '[PRE33]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The DataFrame, `continuousDF`, now contains the following columns:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，数据框 `continuousDF` 包含以下列：
- en: '![](img/51c0514f-23f0-474c-ae49-53136c894319.png)'
  id: totrans-203
  prefs: []
  type: TYPE_IMG
  zh: '![](img/51c0514f-23f0-474c-ae49-53136c894319.png)'
- en: 'Now, we are going to fit a logistic regression model with both the categorical
    and continuous variables, using the following code:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将使用以下代码来拟合一个包含分类变量和连续变量的逻辑回归模型：
- en: '[PRE34]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'You should get an output that looks as follows:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该得到如下输出：
- en: '![](img/e3a76724-02ca-4dbb-b3db-9cbb77ee9554.png)'
  id: totrans-207
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e3a76724-02ca-4dbb-b3db-9cbb77ee9554.png)'
- en: Let's take a closer look at this output. The `Total.Claim.Amount` variables and
    `EducationDoctor` variables are significant at a `0.05` significance level, and
    both of them have positive relationships with the output variable, `Engaged`.
    Hence, the higher the total claim amount is, the more likely that the customer
    is going to engage with the marketing calls. Also, customers with doctoral degrees
    are more likely to engage with marketing calls than those with other educational
    backgrounds. At a `0.1` significance level, we can see that `Income`, `Number.of.Policies`,
    and `EducationMaster` now have significant relationships with the output variable,
    `Engaged`. From looking at this regression analysis output, we can easily see
    the relationships between the input and output variables, and we can understand
    which attributes of customers are positively or negatively related to customer
    engagement with marketing calls.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更仔细地查看此输出。`Total.Claim.Amount` 变量和 `EducationDoctor` 变量在 `0.05` 显著性水平下显著，并且它们与输出变量
    `Engaged` 存在正相关关系。因此，理赔总金额越高，客户与营销电话互动的可能性越大。此外，博士学位的客户比其他教育背景的客户更可能参与营销电话。在 `0.1`
    显著性水平下，我们可以看到 `Income`、`Number.of.Policies` 和 `EducationMaster` 现在与输出变量 `Engaged`
    存在显著关系。从这个回归分析输出中，我们可以轻松看到输入变量和输出变量之间的关系，并理解哪些客户属性与客户对营销电话的互动正相关或负相关。
- en: The full code for the R exercise can be found in the repository at [https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.3/R/RegressionAnalysis.R](https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.3/R/RegressionAnalysis.R).
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: R练习的完整代码可以在这个仓库中找到：[https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.3/R/RegressionAnalysis.R](https://github.com/yoonhwang/hands-on-data-science-for-marketing/blob/master/ch.3/R/RegressionAnalysis.R)。
- en: Summary
  id: totrans-210
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we discussed how to use explanatory analysis to draw insight
    on customer behavior. We discussed how regression analysis can be used to dive
    deeper into understanding customer behavior. More specifically, you learned how
    to use logistic regression to understand what attributes of customers drive higher
    engagement rates. In Python and R exercises, we employed the descriptive analysis
    that we covered in [Chapter 2](1fb7a852-d8fa-43f6-9807-6e3292dfa280.xhtml), *Key
    Performance Indicators and Visualizations*, as well as regression analysis for
    explanatory analysis. We started the exercises by analyzing the data in order
    to better understand and identify noticeable patterns in the data. While analyzing
    the data, you learned one additional way to visualize the data, through box plots,
    using the `matplotlib` and `pandas` packages in Python and the `ggplot2` library
    in R.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中，我们讨论了如何使用解释性分析来洞察客户行为。我们探讨了回归分析如何用于深入理解客户行为。更具体地，你学习了如何使用逻辑回归来理解哪些客户属性会推动更高的互动率。在Python和R的练习中，我们运用了在[第2章](1fb7a852-d8fa-43f6-9807-6e3292dfa280.xhtml)《*关键绩效指标与可视化*》中讨论的描述性分析方法，并结合回归分析进行解释性分析。我们从分析数据开始，以便更好地理解和识别数据中的明显模式。在分析数据时，你还学习了通过箱线图（box
    plot）来可视化数据，使用Python中的`matplotlib`和`pandas`包，以及R中的`ggplot2`库。
- en: 'While fitting regression models, we discussed the two different types of variables:
    continuous and categorical. You learned about the challenges in handling categorical
    variables when fitting logistic regression models, and how to handle such variables.
    For Python, we covered two ways of handling categorical variables: the `factorize`
    and `Categorical` functions from the `pandas` package. For R, we discussed how
    we can use the `factor` function to handle categorical variables when fitting
    a logistic regression model. With the regression analysis results, we showed how
    you can interpret the results and relationships between the input and output variables
    by looking at the coefficients and *p*-values. By looking at the regression analysis
    output, we can understand what attributes of customers show significant relationships
    with customer marketing engagement.'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 在拟合回归模型时，我们讨论了两种不同类型的变量：连续变量和分类变量。你学习了在拟合逻辑回归模型时，处理分类变量所面临的挑战，以及如何处理这些变量。对于Python，我们介绍了处理分类变量的两种方法：`factorize`和`Categorical`函数，均来自`pandas`包。对于R，我们讨论了如何在拟合逻辑回归模型时使用`factor`函数处理分类变量。通过回归分析结果，我们展示了如何通过查看系数和*p*-值来解释结果和输入输出变量之间的关系。通过查看回归分析输出，我们可以了解哪些客户属性与客户营销互动之间存在显著关系。
- en: In the next chapter, we are going to expand your knowledge of explanatory analysis.
    We will analyze what drives conversions after customer engagements. You will also
    learn about another machine learning algorithm, decision trees, and how to use
    them for explanatory analysis.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将扩展你对解释性分析的知识。我们将分析客户互动后，哪些因素推动了转化。你还将学习另一种机器学习算法——决策树，以及如何将其应用于解释性分析。
