- en: '10'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '10'
- en: How to Tell if Your Toaster is Learning – Machine Learning Essentials
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何判断你的烤面包机是否在学习——机器学习基础
- en: 'It seems as though every time we hear about the next great start-up or turn
    on the news, we hear something about a revolutionary piece of **machine learning**
    (**ML**) or **artificial intelligence** (**AI**) technology and how it will change
    the way we live. This chapter focuses on ML as a practical part of data science.
    We will cover the following topics in this chapter:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 每次我们听到关于下一个伟大创业公司或打开新闻时，都会听到关于革命性**机器学习**（**ML**）或**人工智能**（**AI**）技术的消息，以及它如何改变我们的生活方式。本章关注机器学习作为数据科学的实际应用部分。我们将在本章中讨论以下主题：
- en: Defining different types of ML, along with examples of each kind
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义不同类型的机器学习，并提供每种类型的示例
- en: Regression and classification
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回归与分类
- en: What is ML, and how is it used in data science?
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是机器学习，它如何在数据科学中应用？
- en: The differences between ML and statistical modeling and how ML is a broad category
    of the latter
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习与统计建模的区别，以及机器学习如何是后者的一个广泛类别
- en: An Introduction to Linear Regression
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线性回归简介
- en: Our aim in this chapter will be to utilize statistics, probability, and algorithmic
    thinking in order to understand and apply essential ML skills to practical industries,
    such as marketing. Examples will include predicting star ratings of restaurant
    reviews, predicting the presence of a disease, spam email detection, and much
    more. This chapter focuses on ML as a whole and as a single statistical model.
    The subsequent chapters will deal with many more models, some of which are much
    more complex.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的目标是利用统计学、概率论和算法思维，理解并应用机器学习的基本技能于实际行业中，如营销。示例包括预测餐厅评论的星级评分、预测疾病的存在、垃圾邮件检测等。
    本章关注机器学习作为一个整体以及作为单一统计模型。后续章节将涉及更多的模型，其中一些模型更为复杂。
- en: We will also turn our focus on metrics, which tell us how effective our models
    are. We will use metrics in order to conclude results and make predictions using
    ML.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将把焦点转向度量标准，这些标准告诉我们模型的有效性。我们将使用度量标准来得出结果并使用机器学习做出预测。
- en: Introducing ML
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍机器学习
- en: In [*Chapter 1*](B19488_01.xhtml#_idTextAnchor015), *Data Science Terminology*,
    we defined ML as giving computers the ability to learn from data without being
    given explicit rules by a programmer. This definition still holds true. ML is
    concerned with the ability to ascertain certain patterns (signals) out of data,
    even if the data has inherent errors in it (noise).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第1章*](B19488_01.xhtml#_idTextAnchor015)《数据科学术语》中，我们将机器学习（ML）定义为使计算机能够从数据中学习，而无需程序员提供明确的规则。这一定义仍然成立。机器学习关注的是从数据中识别出某些模式（信号）的能力，即使数据本身存在固有的错误（噪声）。
- en: ML models are able to learn from data without the explicit direction of a human.
    That is the main difference between ML models and classical non-ML algorithms.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型能够从数据中学习，而不需要人类的明确指导。这是机器学习模型与经典非机器学习算法之间的主要区别。
- en: Classical algorithms are told directly by a human how to find the best answer
    in a complex system, and the algorithm then achieves these best solutions, often
    working faster and more efficiently than a human. However, the bottleneck here
    is that the human has to first come up with the best solution in order to tell
    the algorithm what to do. In ML, the model is not told the best solution and,
    instead, is given several examples of the problem and told to figure out the best
    solution for itself.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 经典算法由人类直接告知如何在复杂系统中找到最佳答案，然后算法实现这些最佳解决方案，通常比人类更快、更高效。然而，这里的瓶颈是，人类首先需要提出最佳解决方案，然后告诉算法该如何操作。在机器学习中，模型并不直接告知最佳解决方案，而是提供多个问题实例，让其自行找出最佳解决方案。
- en: ML is just another tool in the belt of a data scientist. It is on the same level
    as statistical tests (chi-square or t-tests) or uses basic probability or statistics
    to estimate population parameters. ML is often regarded as the only thing data
    scientists know how to do, and this is simply untrue. A true data scientist is
    able to recognize when ML is applicable and, more importantly, when it is not.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习只是数据科学家工具箱中的另一个工具。它与统计检验（如卡方检验或t检验）处于同一水平，或使用基本的概率或统计方法来估算总体参数。机器学习常被视为数据科学家唯一会做的事情，但这并不正确。真正的数据科学家能够识别机器学习何时适用，更重要的是，何时不适用。
- en: ML is a game of correlations and relationships. Most ML algorithms in existence
    are concerned with finding and/or exploiting relationships between datasets (often
    represented as columns in a `pandas` DataFrame). Once ML algorithms can pinpoint
    certain correlations, the model can either use these relationships to predict
    future observations or generalize the data to reveal interesting patterns.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是一个关于相关性和关系的游戏。现存的大多数机器学习算法都关注寻找和/或利用数据集之间的关系（通常表示为`pandas` DataFrame中的列）。一旦机器学习算法能够确定某些相关性，模型就可以利用这些关系来预测未来的观察结果，或者将数据概括出来，揭示出有趣的模式。
- en: 'Perhaps a great way to explain ML is to offer an example of a problem coupled
    with two possible solutions: one using an ML algorithm and the other utilizing
    a non-ML algorithm.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 也许解释机器学习的一个好方法是提供一个问题的例子，并附带两个可能的解决方案：一个使用机器学习算法，另一个使用非机器学习算法。
- en: Example – facial recognition
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 例子——人脸识别
- en: 'This problem is, on its face (pun intended), quite simple: given a picture
    of a face, who does it belong to? However, let’s consider a slightly simpler task.
    Suppose you wish to implement a home security system that recognizes who is entering
    your house. Most likely, during the day, your house will be empty most of the
    time, and facial recognition will kick in only if there is a person in the shot.
    This is exactly the question I propose we try to solve – given a photo, is there
    a face in it to even recognize?'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这个问题，表面上看（双关语），非常简单：给定一张人脸照片，它属于谁？然而，让我们考虑一个稍微简单一点的任务。假设你希望实现一个家庭安全系统，能够识别谁正在进入你的家。很可能，在白天，你的家大部分时间是空的，只有当画面中有人的时候，人脸识别才会启动。这正是我提出的我们要解决的问题——给定一张照片，里面是否有可以识别的人脸？
- en: 'Given this task definition, I propose the following two solutions:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 给定这个任务定义，我提出以下两种解决方案：
- en: A non-ML algorithm that will define a face as having a roundish structure, two
    eyes, hair, nose, and so on. The algorithm then looks for these hardcoded features
    in the photo and returns whether or not it was able to find any of these features.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个非机器学习算法将定义人脸为具有圆形结构、两只眼睛、头发、鼻子等。该算法随后在照片中寻找这些硬编码的特征，并返回是否能够找到这些特征。
- en: An ML algorithm that will work a bit differently. The model will only be given
    several pictures of faces and non-faces that are labeled as such. From the examples
    (called training sets), it would figure out its own definition of a face.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个机器学习算法将以略微不同的方式工作。该模型将只给定一些标记为“人脸”和“非人脸”的图片。从这些例子（称为训练集）中，它将搞清楚“人脸”的定义。
- en: 'The ML version of the solution is never told what a face is; it is merely given
    several examples – some with faces, and some without. It is then up to the ML
    model to figure out the difference between the two. Once it figures this out,
    it uses this information to take in a picture and predict whether or not there
    is a face in the new picture. For example, to train the system, we might have
    the following images denoted in *Figure 10**.1*:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习版本的解决方案从未告诉它什么是“人脸”；它仅仅是给定了几个例子——一些是包含人脸的，一些是没有的。接下来，机器学习模型需要自己找出这两者之间的区别。一旦它搞清楚了这一点，它就会利用这些信息去分析一张新图片，预测其中是否有脸。例如，在训练系统时，我们可能会有如下图像，如*图
    10.1*所示：
- en: '![Figure 10.1 – Input images for training an ML model](img/B19488_10_01.jpg)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.1 – 训练机器学习模型的输入图像](img/B19488_10_01.jpg)'
- en: Figure 10.1 – Input images for training an ML model
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.1 – 训练机器学习模型的输入图像
- en: The model will then figure out the difference between the pictures labeled as
    *Face* and the pictures labeled as *No Face* and be able to use that difference
    to find faces in future photos. Because the promise of ML – learning simply from
    data and without explicit human intervention – is so alluring, many people might
    believe that ML is perfect, but it simply isn’t.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 模型将弄清楚标记为*人脸*的照片和标记为*非人脸*的照片之间的区别，并能够利用这种差异在未来的照片中找到人脸。由于机器学习的承诺——仅通过数据进行学习，无需明确的人类干预——非常有吸引力，很多人可能会认为机器学习是完美的，但事实并非如此。
- en: ML isn’t perfect
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习并不完美
- en: 'There are many caveats of ML. Many are specific to different models being implemented,
    but some assumptions are universal for any ML model:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习有许多警告和注意事项。很多是针对特定模型的实现的，但一些假设对任何机器学习模型来说都是普遍适用的：
- en: The data used, for the most part, is preprocessed and cleaned using the methods
    outlined in the earlier chapters. Almost no ML model will tolerate extremely dirty/incomplete
    data with missing values or categorical values.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所使用的数据，大多数已经通过前面章节中概述的方法进行预处理和清洗。几乎没有任何机器学习（ML）模型能够容忍极其脏乱或不完整的数据，尤其是带有缺失值或分类值的数据。
- en: Each row of a cleaned dataset represents a single observation of the environment
    we are trying to model.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每一行清理过的数据集代表了我们试图建模的环境中的单个观测值。
- en: The data as a whole should be representative of the task we are solving. This
    might sound obvious, but in so many cases, people use data to train an ML model
    that is close to but not exactly related to the task. This is often seen in criminal
    justice examples where people might use arrest data to train a model to predict
    criminality but, of course, arrests are not the same as convicting someone of
    a crime.
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 整体数据应该能够代表我们正在解决的任务。这听起来可能很明显，但在许多情况下，人们使用的数据来训练机器学习模型与任务有某种关系，但并不完全相关。这在刑事司法领域尤为常见，可能有人使用逮捕数据来训练模型预测犯罪行为，但当然，逮捕并不等同于判定某人有罪。
- en: If our goal is to find relationships between variables, then there is an assumption
    that there is some kind of relationship between these variables. Again, this seems
    obvious, but if a human putting the data together is biased and “believes” there
    is a relationship between the data, then they might incorrectly judge an ML model
    to be more powerful than it actually is.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果我们的目标是找到变量之间的关系，那么就有一个假设，即这些变量之间存在某种关系。再次强调，这似乎很明显，但如果整理数据的人有偏见，并且“相信”数据之间存在关系，那么他们可能错误地判断机器学习模型比实际更强大。
- en: This assumption is particularly important. Many ML models take this assumption
    very seriously. These models are not able to communicate that there might not
    be a relationship.
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个假设尤其重要。许多机器学习模型非常重视这一假设。这些模型无法传达可能不存在关系的情况。
- en: ML models are generally considered semi-automatic, which means that intelligent
    decisions by humans are still needed.
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习模型通常被认为是半自动化的，这意味着仍然需要人类做出智能决策。
- en: The machine is very smart but has a hard time putting things into context. The
    output of most models is a series of numbers and metrics attempting to quantify
    how well the model did. It is up to a human to put these metrics into perspective
    and communicate the results to an audience.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器非常聪明，但很难将事物置于上下文中。大多数模型的输出是一系列数字和指标，试图量化模型的表现如何。由人类来将这些指标放入上下文，并将结果传达给听众。
- en: Most ML models are sensitive to noisy data. This means that the models get confused
    when you include data that doesn’t make sense. For example, if you are attempting
    to find relationships between economic data around the world and one of your columns
    relates to puppy adoption rates in the capital city, that information is likely
    not relevant and will confuse the model.
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大多数机器学习模型对噪声数据非常敏感。这意味着当你包含不合理的数据时，模型会感到困惑。例如，如果你试图找到全球经济数据之间的关系，而你的一列数据与首都城市的幼犬收养率相关，这个信息可能不相关，并且会让模型感到困扰。
- en: These assumptions will come up again and again when dealing with ML. They are
    all too important and are often ignored by novice data scientists.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这些假设在处理机器学习时会一再出现。它们非常重要，但往往被初学者数据科学家忽视。
- en: How does ML work?
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习是如何工作的？
- en: Each flavor of ML and each individual model works in very different ways, exploiting
    different parts of mathematics and data science. However, in general, ML works
    by taking in data, finding relationships within the data, and giving as output
    what the model learned, as illustrated in *Figure 10**.2*.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 每种类型的机器学习和每个单独的模型工作方式都非常不同，利用了不同的数学和数据科学部分。然而，一般来说，机器学习通过接收数据、寻找数据中的关系，并输出模型所学到的内容来工作，如*图
    10.2*所示。
- en: '![Figure 10.2 – An overview of ML models taking in input data, learning signals,
    and identifying patterns in order to produce a meaningful and interpretable output](img/B19488_10_02.jpg)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.2 – 一个概述，展示了机器学习模型如何接收输入数据、学习信号，并识别模式，以便生成有意义且可解释的输出](img/B19488_10_02.jpg)'
- en: Figure 10.2 – An overview of ML models taking in input data, learning signals,
    and identifying patterns in order to produce a meaningful and interpretable output
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.2 – 一个概述，展示了机器学习模型如何接收输入数据、学习信号，并识别模式，以便生成有意义且可解释的输出
- en: As we explore different types of ML models, we will see how they manipulate
    data differently and come up with different outputs for different applications.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们探索不同类型的机器学习模型时，我们将看到它们如何以不同的方式操作数据，并为不同的应用得出不同的输出。
- en: Types of ML
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习的类型
- en: 'There are many ways to segment ML and dive deeper. In [*Chapter 1*](B19488_01.xhtml#_idTextAnchor015),
    *Data Science Terminology*, I mentioned statistical and probabilistic models.
    These models utilize statistics and probability, which we’ve seen in the previous
    chapters, in order to find relationships between data and make predictions. In
    this chapter, we will implement both types of models. In the following chapter,
    we will see ML outside the rigid mathematical world of statistics/probability.
    You can segment ML models by different characteristics, including the following:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多方法可以划分ML并深入研究。在[*第一章*](B19488_01.xhtml#_idTextAnchor015)，*数据科学术语*中，我提到了统计模型和概率模型。这些模型利用我们在前几章中学到的统计学和概率学，旨在找出数据之间的关系并进行预测。在本章中，我们将实现这两类模型。在下一章中，我们将看到统计/概率学这个严格数学世界之外的ML。你可以通过不同的特征划分ML模型，包括以下内容：
- en: The types of data organic structures they utilize (tree, graph, or **neural**
    **network** (**NN**))
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们使用的有机结构数据类型（树、图或**神经** **网络**（**NN**））
- en: The field of mathematics they are most related to (statistical or probabilistic)
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与其最相关的数学领域（统计学或概率论）
- en: The level of computation required to train (**deep** **learning** (**DL**))
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练所需的计算量（**深度** **学习**（**DL**））
- en: 'Branching off from the top level of ML, there are the following three subsets:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 从ML的顶层分支出以下三个子集：
- en: '**Supervised** **learning** (**SL**)'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监督** **学习**（**SL**）'
- en: '**Unsupervised** **learning** (**UL**)'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无监督** **学习**（**UL**）'
- en: '**Reinforcement** **learning** (**RL**)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**强化** **学习**（**RL**）'
- en: Let’s go into each one of these one by one. Our next chapter will include multiple
    examples of the first two, with the third one being slightly out of the scope
    of our introductory book. You can always find more resources in our code base!
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐一分析这些内容。我们的下一章将包含前两者的多个例子，第三个略超出我们这本入门书的范围。你可以在我们的代码库中找到更多的资源！
- en: SL
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SL
- en: Simply put, **SL** finds associations between features of a dataset (independent
    variables) and a target (dependent) variable. For example, SL models might try
    to find the association between a person’s health features (heart rate, weight,
    and so on) and that person’s risk of having a heart attack (the target variable).
    These associations allow supervised models to make predictions based on past examples.
    **Supervised ML** (**SML**) models are often called predictive analytics models,
    named for their ability to predict the future based on the past. This is often
    the first thing that comes to people’s minds when they hear the term *ML*, but
    it in no way encompasses the realm of ML.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 简单来说，**SL**通过找到数据集的特征（自变量）与目标（因变量）之间的关联。例如，SL模型可能会试图找出一个人的健康特征（心率、体重等）与该人心脏病发作风险（目标变量）之间的关联。这些关联使得监督学习模型能够基于过去的示例进行预测。**监督学习**（**SML**）模型通常被称为预测分析模型，因其能够基于过去预测未来。这通常是人们一听到*ML*这个术语时首先想到的内容，但它并不能涵盖ML的全部领域。
- en: SML requires a certain type of data called **labeled data** – data that acts
    as full, correct, and complete examples of the features and target variable. *Figure
    10**.1* shows a snippet of labeled data. The goal is to let our model learn by
    giving it historical examples that are labeled with the correct answer.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: SML需要一种特殊类型的数据，称为**标注数据**——数据作为特征和目标变量的完整、正确和完整的示例。*图10.1*展示了标注数据的一部分。目标是通过向模型提供带有正确答案的历史示例，让模型学习。
- en: Recall the facial recognition example. That is an SL model because we are training
    our model with the previous pictures labeled as either *face* or *not face*, and
    then asking the model to predict whether or not a new picture has a face in it.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下面部识别的例子。这是一个SL模型，因为我们正在用之前标注为“*人脸*”或“*非人脸*”的图片训练我们的模型，然后让模型预测新图片是否包含人脸。
- en: 'First, let us separate the data into two distinct parts, as follows:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们将数据分成以下两部分：
- en: The features, which are the columns that will be used to make our prediction.
    These are sometimes called predictors, input values, variables, and independent
    variables.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征，即用于进行预测的列。这些有时被称为预测因子、输入值、变量和自变量。
- en: The response, which is the column that we wish to predict. This is sometimes
    called outcome, label, target, and dependent variable.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 响应变量，即我们希望预测的列。这有时也被称为结果、标签、目标和因变量。
- en: 'SL attempts to find a relationship between features and responses in order
    to make a prediction. The idea is that, in the future, a data observation will
    present itself, and we will only know the predictors. The model will then have
    to use the features to make an accurate prediction of the response value. *Figure
    10**.3* shows a visualization of how we generally use supervised models: we train
    (fit) them using labeled training data and use the result to predict unseen cases
    (features without the response) to make final predictions:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: SL 尝试在特征和响应之间找到一种关系，以便进行预测。其思路是，在未来，某个数据观测值将出现，而我们只知道预测变量。模型将不得不使用这些特征来准确预测响应值。*图
    10**.3* 显示了我们通常如何使用有监督模型的可视化：我们通过使用带标签的训练数据进行训练（拟合），然后利用结果对未见过的案例（只有特征没有响应）进行预测，最终做出预测：
- en: "![Figure 10.3 – Supervised models are fit using labeled training data and are\
    \ then used to make predictions fro\uFEFFm unseen cases](img/B19488_10_03.jpg)"
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.3 – 有监督模型通过使用带标签的训练数据进行拟合，然后用来对未见过的案例进行预测](img/B19488_10_03.jpg)'
- en: Figure 10.3 – Supervised models are fit using labeled training data and are
    then used to make predictions from unseen cases
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.3 – 有监督模型通过使用带标签的训练数据进行拟合，然后用来对未见过的案例进行预测。
- en: Example – heart attack prediction
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 示例 – 心脏病预测
- en: Suppose we wish to predict whether someone will have a heart attack within a
    year. To predict this, we are given that person’s cholesterol level, blood pressure,
    height, smoking habits, and perhaps more. From this data, we must ascertain the
    likelihood of a heart attack. Suppose, to make this prediction, we look at previous
    patients and their medical history. As these are previous patients, we know not
    only their predictors (cholesterol, blood pressure, and so on) but also if they
    actually had a heart attack (because it already happened!).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们希望预测某人在一年内是否会发生心脏病发作。为了进行这个预测，我们会得到该人的胆固醇水平、血压、身高、吸烟习惯等信息。根据这些数据，我们需要评估心脏病发作的可能性。假设为了做出这个预测，我们查看了以前的患者及其病史。由于这些是以前的患者，我们不仅知道他们的预测变量（如胆固醇、血压等），还知道他们是否确实发生过心脏病发作（因为这已经发生了！）。
- en: 'This is an SML problem because we are doing the following:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个 SML 问题，因为我们正在做以下事情：
- en: We are making a prediction about someone
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们正在对某个人进行预测。
- en: We are using historical training data to find relationships between medical
    variables and heart attacks
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们正在使用历史训练数据来寻找医学变量与心脏病发作之间的关系。
- en: '*Figure 10**.4* shows a basic outline of how SML models use data:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 10**.4* 显示了 SML 模型如何使用数据的基本框架：'
- en: '![Figure 10.4 – An SML model uses predictors and a response from data in order
    to learn relationships between them, usually in order to make future predictions
    given predictors without the response](img/B19488_10_04.jpg)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.4 – SML 模型通过使用预测变量和响应变量的数据来学习它们之间的关系，通常是为了在给定预测变量而没有响应变量的情况下进行未来预测](img/B19488_10_04.jpg)'
- en: Figure 10.4 – An SML model uses predictors and a response from data in order
    to learn relationships between them, usually in order to make future predictions
    given predictors without the response
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.4 – SML 模型通过使用预测变量和响应变量的数据来学习它们之间的关系，通常是为了在给定预测变量而没有响应变量的情况下进行未来预测。
- en: The hope here is that a patient will walk in sometime in the future and our
    model will be able to identify whether or not the patient is at risk for a heart
    attack based on their conditions (just like a doctor would!).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的希望是，未来某个时刻会有一个患者走进来，我们的模型能够根据其状况判断该患者是否有心脏病发作的风险（就像医生一样！）。
- en: 'As the model sees more and more diverse and representative labeled data, it
    should adjust itself in order to match the correct labels outlined in the training
    data. We can then use different metrics (explained more in the next chapter) to
    pinpoint exactly how well our SML model is doing and how it can better adjust
    itself. One of the largest obstacles associated with SML is obtaining diverse
    and representative labeled data, which can be very difficult to get hold of. Suppose
    we wish to predict heart attacks; we might need thousands of patients along with
    all of their medical information and years’ worth of follow-up records for each
    person, which could be a nightmare to obtain. In short, supervised models use
    historical labeled data in order to make predictions about the future from predefined
    features. Some possible applications for SL include the following:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 随着模型看到越来越多的多样化和具有代表性的数据，模型应该进行自我调整，以匹配训练数据中定义的正确标签。然后，我们可以使用不同的度量标准（将在下一章中进一步解释）来准确评估我们的SML模型的表现，以及如何更好地调整它。与SML相关的最大障碍之一是获得多样化和具有代表性的数据集，这往往非常难以获取。假设我们想要预测心脏病发作，我们可能需要成千上万的患者数据以及每个患者的所有医疗信息和数年的跟踪记录，这可能是一个获取噩梦。简而言之，监督模型使用历史带标签的数据，通过预定义的特征来对未来进行预测。一些SL的可能应用包括以下几种：
- en: '**Stock price predictions**: Historical trading volume and movements could
    be features along with social media sentiment, while the future price could be
    a target'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**股票价格预测**：历史交易量和股价波动可以作为特征，同时社交媒体情绪也可以作为特征，未来价格则为目标变量'
- en: '**Weather predictions**: Using past meteorological data, such as temperature,
    humidity, and wind speed, to forecast future weather conditions'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**天气预测**：使用过去的气象数据，如温度、湿度和风速，来预测未来的天气状况'
- en: '**Disease diagnosis**: Medical imaging and patient history can be used to predict
    the presence or absence of a disease'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**疾病诊断**：通过医学影像和患者历史记录来预测疾病的有无'
- en: '**Facial recognition**: Features extracted from images of faces to identify
    individuals'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**人脸识别**：从人脸图像中提取的特征用于识别个人'
- en: '**Email filtering**: Using characteristics of emails to classify them as spam
    or not spam'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**邮件过滤**：通过邮件的特征将其分类为垃圾邮件或非垃圾邮件'
- en: '**Credit scoring**: Historical financial behavior data to predict creditworthiness'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**信用评分**：通过历史金融行为数据来预测信用worthiness'
- en: Each of these applications relies on a labeled dataset that includes historical
    data points and a target variable that the model is trying to predict. The quality
    and quantity of the labeled data are crucial in SL as they directly impact the
    model’s ability to learn and generalize to new, unseen data. When designing an
    SL model, it is important to consider the features that will be used. Features
    should be relevant, informative, and non-redundant to ensure the model performs
    effectively. Additionally, the choice of algorithm depends on the nature of the
    task (regression, classification), the size and dimensionality of the dataset,
    and the computational efficiency required.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这些应用程序依赖于一个带标签的数据集，其中包含历史数据点和模型试图预测的目标变量。数据标签的质量和数量在监督学习（SL）中至关重要，因为它们直接影响模型的学习能力以及模型对新数据的泛化能力。在设计SL模型时，考虑所使用的特征非常重要。特征应当是相关的、有信息量的，并且不可冗余，以确保模型的有效性。此外，算法的选择取决于任务的性质（回归、分类）、数据集的大小和维度以及所需的计算效率。
- en: By carefully preparing the dataset and selecting the right features and model,
    SL can provide powerful predictive insights across various fields, from finance
    to healthcare.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 通过精心准备数据集并选择合适的特征和模型，SL可以为各种领域提供强大的预测洞察，从金融到医疗保健。
- en: Types of SL models
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: SL模型类型
- en: 'There are, in general, two types of SL models: **regression** and **classification**
    models. The difference between the two is quite simple and lies in the nature
    of the response variable.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，SL模型分为两种类型：**回归**模型和**分类**模型。二者的区别非常简单，关键在于响应变量的性质。
- en: '**Regression** models attempt to predict a continuous response. This means
    that the response can take on a range of infinite values. Consider the following
    examples:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '**回归**模型试图预测一个连续的响应。这意味着响应可以取无限范围的值。考虑以下示例：'
- en: '**House pricing**: Where the value to be predicted is the cost of a house based
    on features such as square footage, number of bedrooms, and location'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**房价预测**：预测的值是基于房屋的特征（如建筑面积、卧室数量和地理位置）来预测房子的价格'
- en: '**Temperature forecasting**: Where the model predicts the temperature for future
    days or hours based on historical weather data'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**温度预测**：模型根据历史天气数据预测未来几天或几小时的温度。'
- en: '**Stock market price prediction**: Where the continuous response could be the
    future price of a stock based on its historical performance and other economic
    indicators'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**股市价格预测**：模型根据股票的历史表现和其他经济指标预测股票的未来价格，预测结果是连续性的。'
- en: '**Classification** models, on the other hand, predict categorical responses.
    These responses are discrete and have a finite number of values, often referred
    to as classes or categories. Here are some examples:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '**分类**模型则预测离散的响应。这些响应是离散的，且有有限个值，通常被称为类或类别。以下是一些示例：'
- en: '**Email spam detection**: The model classifies emails as either “spam” or “not
    spam” based on content, sender information, and other attributes'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**邮件垃圾邮件检测**：模型根据邮件内容、发件人信息和其他属性将邮件分类为“垃圾邮件”或“非垃圾邮件”。'
- en: '**Medical diagnosis**: A model might classify patient outcomes based on test
    results, predicting categories such as “disease” or “no disease”'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**医学诊断**：模型可能根据测试结果对患者的结局进行分类，预测如“患病”或“未患病”等类别。'
- en: '**Image recognition**: Classifying images into predefined categories such as
    “cat," “dog," “car," and so on, based on pixel data and patterns'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图像识别**：根据像素数据和模式将图像分类为预定义的类别，如“猫”，“狗”，“汽车”等。'
- en: 'Both regression and classification tasks use a similar process of learning
    from historical data, but their applications and evaluation metrics differ due
    to the nature of their output. Our earlier heart attack example is classification
    because the question was: Will this person have a heart attack within a year?
    This has only two possible answers: *Yes* or *No*. We will see a full example
    of regression later in this chapter and full examples of both classification and
    regression in the next chapter.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 回归和分类任务都使用类似的从历史数据中学习的过程，但由于它们的输出性质不同，应用和评估指标也有所不同。我们之前的心脏病发作示例属于分类，因为问题是：“此人在一年内是否会发生心脏病发作？”这个问题只有两个可能的答案：*是*
    或 *否*。我们将在本章后面看到回归的完整示例，并在下一章中看到分类和回归的完整示例。
- en: Deciding between classification and regression
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在分类和回归之间的选择
- en: Sometimes, it can be tricky to decide whether or not you should use classification
    or regression. Consider that we are interested in the weather outside. We could
    ask the question, *How hot is it outside?* In this case, your answer is on a continuous
    scale, and some possible answers are 60.7 degrees or 98 degrees. However, as an
    exercise, go and ask 10 people what the temperature is outside. I guarantee you
    that someone (if not most people) will not answer in some exact degrees but will
    bucket their answer and say something like *It’s in* *the 60s*.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，决定是否使用分类或回归算法可能会很棘手。假设我们关注的是外面的天气。我们可以问：“*外面有多热？*” 在这种情况下，答案是一个连续的数值，可能的答案有60.7度或98度。然而，作为练习，去问10个人外面温度是多少。我敢保证，其中一个人（如果不是大多数人）不会给出一个具体的度数，而是会将答案归类，比如说
    *“大约是60多度”*。
- en: We might wish to consider this problem as a classification problem, where the
    response variable is no longer in exact degrees but is in a bucket. There would
    only be a finite number of buckets in theory, making the model perhaps learn the
    differences between 60s and 70s a bit better.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能会将这个问题视为分类问题，其中响应变量不再是精确的温度，而是以桶的形式表示。理论上，桶的数量是有限的，这样可能会让模型更好地区分60度和70度之间的差异。
- en: What if we aren’t predicting anything, but instead we wanted to use ML to simply
    better understand and interpret our data? That’s where UL comes in very handy.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们不进行预测，而是希望利用机器学习更好地理解和解释我们的数据，**无监督学习（UL）**就非常有用。
- en: UL
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 无监督学习
- en: 'The second type of ML on our list does not deal with making predictions but
    has a much more open objective. **UL** takes in a set of predictors and utilizes
    relationships between the predictors in order to accomplish tasks such as the
    following:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们列表中的第二种机器学习方法并不是进行预测，而是具有更为开放的目标。**无监督学习（UL）**接收一组预测变量，并利用这些变量之间的关系来完成以下任务：
- en: It reduces the dimension of the data by condensing variables together. An example
    of this would be file compression. Compression works by utilizing patterns in
    the data and representing the data in a smaller format. This is referred to as
    **dimension reduction**.
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过将变量压缩在一起，它减少了数据的维度。一个例子就是文件压缩。压缩通过利用数据中的模式，将数据表示为更小的格式。这被称为**维度约简**。
- en: It finds groups of observations that behave similarly and groups them together.
    This is called **clustering**.
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它会找到行为相似的观察值并将它们聚集在一起，这就是**聚类**。
- en: Both of these are examples of UL because they do not attempt to find a relationship
    between predictors and a specific response and therefore are not used to make
    predictions of any kind. Unsupervised models, instead, are utilized to find organizations
    and representations of the data that were previously unknown.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 这两者都是无监督学习（UL）的例子，因为它们不试图寻找预测变量与特定响应之间的关系，因此不会用于任何形式的预测。无监督模型则用于寻找数据中先前未知的组织结构和表示。
- en: '*Figure 10**.5* gives a representation of a cluster analysis:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 10**.5* 展示了聚类分析的一个表示：'
- en: '![Figure 10.5 – Cluster analysis groups together similar data points to add
    a layer of interpretation on top of raw data](img/B19488_10_05.jpg)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.5 – 聚类分析将相似的数据点聚集在一起，为原始数据添加一层解释](img/B19488_10_05.jpg)'
- en: Figure 10.5 – Cluster analysis groups together similar data points to add a
    layer of interpretation on top of raw data
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.5 – 聚类分析将相似的数据点聚集在一起，为原始数据添加一层解释
- en: The model will recognize that each uniquely colored cluster of observations
    is similar to another but different from the other clusters.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 模型会识别出每个颜色不同的观察簇与另一个簇相似，但与其他簇不同。
- en: A big advantage of UL is that it does not require labeled data, which means
    that it is much easier to get data that complies with UL models. Of course, a
    drawback to this is that we lose all predictive power because the response variable
    holds the information to make predictions and, without it, our model will be hopeless
    in making any sort of predictions.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 无监督学习的一个大优势是它不需要标注数据，这意味着获取符合无监督学习模型的数据要容易得多。当然，这也有一个缺点，那就是我们失去了所有的预测能力，因为响应变量包含做出预测所需的信息，而没有它，我们的模型在做出任何预测时都将变得毫无希望。
- en: 'A big drawback is that it is difficult to see how well we are doing. In a regression
    or classification problem, we can easily tell how well our models are predicting
    by comparing our models’ answers to the actual answers. For example, if our supervised
    model predicts rain and it is sunny outside, the prediction is incorrect. If our
    supervised model predicts the price will go up by 1 dollar and it goes up by 99
    cents, our prediction is very close! In unsupervised modeling, this concept is
    foreign because we have no answer to compare our models to. Unsupervised models
    merely suggest differences and similarities that then require a human’s interpretation,
    as visualized in *Figure 10**.6*:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 一个大缺点是很难评估我们做得如何。在回归或分类问题中，我们可以通过将模型的预测结果与实际结果进行比较，轻松判断模型的预测效果。例如，如果我们的监督模型预测下雨，但外面却是晴天，那么预测就是错误的。如果我们的监督模型预测价格会上涨
    1 美元，但实际上只上涨了 99 美分，那么预测就非常接近！但在无监督建模中，这一概念是陌生的，因为我们没有答案可以与模型进行比较。无监督模型仅仅是提出差异和相似性，这些差异和相似性需要人类来解释，就像在*图
    10**.6*中所展示的那样：
- en: '![Figure 10.6 – Unsupervised models don’t have a notion of a “target” and instead
    focus on adding a layer of structure on top of raw data](img/B19488_10_06.jpg)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.6 – 无监督模型没有“目标”的概念，而是专注于在原始数据上添加一层结构](img/B19488_10_06.jpg)'
- en: Figure 10.6 – Unsupervised models don’t have a notion of a “target” and instead
    focus on adding a layer of structure on top of raw data
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.6 – 无监督模型没有“目标”的概念，而是专注于在原始数据上添加一层结构
- en: In short, the main goal of unsupervised models is to find similarities and differences
    between data observations and use these comparisons to add structure on top of
    otherwise raw and unstructured data.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，无监督模型的主要目标是找到数据观察值之间的相似性和差异，并利用这些比较为原始且未结构化的数据添加结构。
- en: Moving in a very different direction is our final type of ML. To be honest with
    you, we don’t have the time nor the pages in this book to cover our next topic
    with the respect it deserves, but it merits a place in our text regardless.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们最后要讨论的机器学习类型走向了一个非常不同的方向。老实说，我们没有足够的时间和篇幅来充分讲解接下来的话题，但无论如何，它仍然值得在本书中占有一席之地。
- en: RL
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 强化学习（RL）
- en: In **RL**, algorithms, referred to as agents, learn to make decisions by interacting
    with an environment. The agent selects an action to take based on its current
    state and then receives a reward or penalty based on the outcome of that action.
    The goal is to learn a policy—a mapping from states to actions—that maximizes
    the cumulative reward over time.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在**强化学习（RL）**中，算法被称为代理，代理通过与环境互动学习做出决策。代理根据当前状态选择一个动作，然后根据该动作的结果接收奖励或惩罚。目标是学习一个策略——即从状态到动作的映射——以最大化累积奖励。
- en: This type of ML is quite distinct from SL as it does not rely on labeled input/output
    pairs and does not require explicit correction of suboptimal actions. Instead,
    it focuses on finding a balance between exploration (trying new actions) and exploitation
    (using known information to maximize the reward).
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 这种类型的机器学习与SL有显著区别，因为它不依赖标注的输入/输出对，也不需要明确地纠正次优的行动。相反，它侧重于在探索（尝试新行动）和利用（使用已知信息最大化奖励）之间找到平衡。
- en: 'RL has been successfully applied in various domains, including the following:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习已成功应用于多个领域，包括以下内容：
- en: '**Game playing**: AI agents are trained to play and excel at complex games,
    such as Go, chess, and various video games, often surpassing human expert performance'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**游戏玩法**：AI代理被训练来玩并在复杂游戏中表现出色，如围棋、国际象棋和各种视频游戏，通常超越人类专家的表现。'
- en: '**Robotics**: Robots learn to perform tasks such as walking, picking up objects,
    or navigating through challenging terrain through trial and error'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**机器人技术**：机器人通过试错学习执行任务，如行走、拾取物体或在挑战性地形中导航。'
- en: '**Autonomous vehicles**: RL is used to develop systems that can make real-time
    driving decisions in dynamic and unpredictable environments'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自动驾驶车辆**：强化学习用于开发可以在动态和不可预测的环境中做出实时驾驶决策的系统。'
- en: OpenAI’s pioneering work in using **RL with human feedback** (**RLHF**) has
    been instrumental in developing AI models such as ChatGPT. By incorporating human
    preferences, these models are trained to generate responses that are not only
    relevant but also aligned with human values, enhancing their helpfulness and minimizing
    potential harm.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI在使用**强化学习与人类反馈**（**RLHF**）方面的开创性工作为开发像ChatGPT这样的AI模型发挥了重要作用。通过结合人类偏好，这些模型被训练生成不仅相关，而且符合人类价值观的回应，从而增强其有用性并减少潜在的伤害。
- en: 'A typical flow for an RL problem would look something like this:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 一个典型的强化学习（RL）问题流程大致如下：
- en: The agent receives state *S* from the environment.
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 代理从环境中接收状态*S*。
- en: The agent takes action *A* based on policy *π*.
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 代理根据策略*π*采取行动*A*。
- en: The environment presents a new state *S* and reward *R* to the agent.
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 环境向代理呈现一个新的状态*S*和奖励*R*。
- en: The reward informs the agent of the action’s effectiveness.
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 奖励通知代理该行动的有效性。
- en: The agent updates policy *π* to increase future rewards.
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 代理通过更新策略*π*来增加未来的奖励。
- en: Overview of the types of ML
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习类型概述
- en: 'Of the three types of ML – SL, UL, and RL – we can imagine the world of ML
    as something like the depiction in *Figure 10**.7*:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在三种机器学习类型——SL、UL和RL中，我们可以想象机器学习的世界就像*图10.7*中的描绘：
- en: '![Figure 10.7 – Our family tree of ML has three main branches: SL, UL, and
    RL](img/B19488_10_07.jpg)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![图10.7 – 我们的机器学习家谱有三个主要分支：SL、UL 和 RL](img/B19488_10_07.jpg)'
- en: 'Figure 10.7 – Our family tree of ML has three main branches: SL, UL, and RL'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.7 – 我们的机器学习家谱有三个主要分支：SL、UL 和 RL
- en: ML paradigms – pros and cons
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习范式——优缺点
- en: As we now know, ML can be broadly classified into three categories, each with
    its own set of advantages and disadvantages.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所知，机器学习可以大致分为三类，每类都有其各自的优缺点。
- en: SML
  id: totrans-130
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: SML
- en: This method leverages the relationships between input predictors and the output
    response variable to predict future data observations.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法利用输入预测因子与输出响应变量之间的关系来预测未来的数据观测。
- en: 'The advantages of it are as follows:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 它的优点如下：
- en: Enables predictive analysis for future events
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为未来事件提供预测分析。
- en: Quantifies the relationships and effects between variables
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 量化变量之间的关系和影响
- en: Provides insights into how variables interact and influence each other
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供对变量之间如何相互作用和影响彼此的洞察。
- en: 'Let’s see the disadvantage:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看其缺点：
- en: Dependent on the availability of labeled data, which can be scarce and expensive
    to procure
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 依赖标注数据的可用性，而标注数据通常稀缺且昂贵。
- en: Unsupervised ML (UML)
  id: totrans-138
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 无监督机器学习（UML）
- en: This approach discovers patterns by finding similarities and differences between
    data points without using labeled responses.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法通过寻找数据点之间的相似性和差异来发现模式，而无需使用标注的响应。
- en: 'The advantages of it are as follows:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 其优点如下：
- en: Identifies subtle correlations that may not be evident to human analysts
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别出人类分析师可能难以察觉的微妙相关性。
- en: Serves as a valuable preprocessing step for SL, transforming raw data into structured
    clusters
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作为有监督学习（SL）的宝贵预处理步骤，将原始数据转化为结构化的簇。
- en: Utilizes unlabeled data, which is generally more abundant and accessible
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用未标记的数据，这类数据通常更为丰富且易于获取。
- en: 'Here are the disadvantages:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是缺点：
- en: Lacks direct predictive capabilities
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缺乏直接的预测能力
- en: Validation of the model’s efficacy is challenging and highly reliant on human
    judgment
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 验证模型效果是具有挑战性的，并且高度依赖于人工判断。
- en: RL
  id: totrans-147
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 强化学习（RL）
- en: RL employs a system of rewards to train agents to take optimal actions within
    their environments.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: RL使用奖励系统训练智能体在其环境中采取最佳行动。
- en: 'The advantages of it are as follows:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 其优点如下：
- en: Capable of developing complex AI behaviors through intricate reward systems
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过复杂的奖励系统开发复杂的人工智能行为。
- en: Adaptable to a wide range of environments, including real-world scenarios
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可适应广泛的环境，包括现实世界的场景。
- en: 'The disadvantages are as follows:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 其缺点如下：
- en: Initial behavior can be unpredictable as the agent learns from its mistakes
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 初始行为可能不可预测，因为智能体需要从其错误中学习。
- en: Learning can be slow, as the agent may take time to discern beneficial actions
    from detrimental ones
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习可能较慢，因为智能体可能需要时间从有益和有害的行为中辨别出有价值的行动。
- en: There is a risk of the agent becoming overly cautious, limiting its actions
    to avoid negative outcomes
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 存在智能体变得过于谨慎的风险，可能限制其行动以避免负面结果。
- en: Enough talk – let’s look at our first ML code!
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 够多的讨论了——让我们来看一下我们的第一个机器学习代码！
- en: Predicting continuous variables with linear regression
  id: totrans-157
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用线性回归预测连续变量
- en: We will finally explore our first true ML model! Linear regression is a form
    of regression, which means that it is an ML model that attempts to find a relationship
    between predictors and a response variable, and that response variable is – you
    guessed it –continuous! This notion is synonymous with making a *line of best
    fit*. While linear regressions are no longer a state-of-the-art ML algorithm,
    the path behind it can be a bit tricky and it will serve as an excellent entry
    point for us.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将探索第一个真正的机器学习模型！线性回归是一种回归方法，意味着它是一种机器学习模型，试图找到预测变量和响应变量之间的关系，而这个响应变量——你猜对了——是连续的！这个概念与做出*最佳拟合线*是同义的。虽然线性回归不再是最先进的机器学习算法，但它背后的路径可能有些复杂，它将作为我们进入这一领域的绝佳起点。
- en: 'In the case of linear regression, we will attempt to find a linear relationship
    between our predictors and our response variable. Formally, we wish to solve a
    formula of the following format:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在线性回归的情况下，我们将尝试找到预测变量和响应变量之间的线性关系。形式上，我们希望解决以下格式的公式：
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi
    mathvariant="normal">β</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi
    mathvariant="normal">β</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mo>…</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi
    mathvariant="normal">β</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math>](img/158.png)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi
    mathvariant="normal">β</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi
    mathvariant="normal">β</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mo>…</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi
    mathvariant="normal">β</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math>](img/158.png)'
- en: 'Let’s look at the constituents of this formula:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下这个公式的组成部分：
- en: y is our response variable
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: y 是我们的响应变量
- en: xi is our ith variable (ith column or ith predictor)
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: xi 是我们的第 i 个变量（第 i 列或第 i 个预测变量）
- en: B0 is the intercept
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: B0 是截距项。
- en: Bi is the coefficient for the xi term
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bi 是 xi 项的系数
- en: 'Let’s take a look at some data before we go in depth. This dataset is publicly
    available and attempts to predict the number of bikes needed on a particular day
    for a bike-sharing program:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入研究之前，让我们先看一下数据。这份数据集是公开的，旨在预测某一天共享单车项目中所需的单车数量：
- en: '[PRE0]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Our data can be seen in *Figure 10**.8*:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的数据可以在 *图 10**.8* 中看到：
- en: '![Figure 10.8 – The first five rows (the head) of our bike-share data](img/B19488_10_08.jpg)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.8 – 我们共享单车数据的前五行（头部数据）](img/B19488_10_08.jpg)'
- en: Figure 10.8 – The first five rows (the head) of our bike-share data
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.8 – 我们共享单车数据的前五行（头部数据）
- en: We can see that every row represents a single hour of bike usage. In this case,
    we are interested in predicting the `count` value, which represents the total
    number of bikes rented in the period of that hour.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，每一行代表一个小时的单车使用情况。在这种情况下，我们关注的是预测`count`值，表示该小时内租出的单车总数。
- en: 'Let’s use the `seaborn` module to draw ourselves a line of best fit using only
    the `temp` feature, as follows:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用 `seaborn` 模块仅使用 `temp` 特征来绘制一条最佳拟合线，如下所示：
- en: '[PRE1]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The output of this code can be seen in *Figure 10**.9*:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码的输出可以在 *图 10**.9* 中看到：
- en: '![Figure 10.9 – Our first line of best fit showing us the relationship between
    the temperature and the number of bike shares](img/B19488_10_09.jpg)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.9 – 我们的第一条最佳拟合线，展示了温度与共享单车数量之间的关系](img/B19488_10_09.jpg)'
- en: Figure 10.9 – Our first line of best fit showing us the relationship between
    the temperature and the number of bike shares
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.9 – 我们的第一条最佳拟合线，展示了温度与共享单车数量之间的关系
- en: This line in the graph attempts to visualize and quantify the relationship between
    `temp` and `count`. To make a prediction, we simply find a given temperature and
    then see where the line would predict the count. For example, if the temperature
    is 20 degrees (Celsius, mind you), then our line would predict that about 200
    bikes will be rented. If the temperature is above 40°C, then more than 400 bikes
    will be needed!
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 图中的这条线试图可视化并量化 `temp` 和 `count` 之间的关系。为了进行预测，我们只需找出一个给定的温度，然后看看这条线会预测出多少单车数量。例如，如果温度为
    20°C（记得是摄氏度哦），那么我们的拟合线将预测大约会租出 200 辆单车。如果温度超过 40°C，那么将需要超过 400 辆单车！
- en: 'It appears that as `temp` goes up, our `count` value also goes up. Let’s see
    if our correlation value, which quantifies a linear relationship between variables,
    also matches this notion:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来，随着 `temp` 的上升，`count` 值也在上升。让我们看看我们的相关性值，它量化了变量之间的线性关系，是否也符合这一点：
- en: '[PRE2]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'There is a (weak) positive correlation between the two variables, which makes
    sense considering our line of best fit! Let’s now use `pandas` to create a variable
    for our features (`X`) and another one for our target (`y`):'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个变量之间存在一个（弱）正相关，考虑到我们的最佳拟合线，这是有意义的！现在，让我们使用 `pandas` 创建一个特征变量 (`X`) 和一个目标变量
    (`y`)：
- en: '[PRE3]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Our `X` and `y` variables represent our predictors and our response variable.
    Then, we will import our ML module, `scikit-learn`, as shown:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的 `X` 和 `y` 变量分别代表预测变量和响应变量。然后，我们将导入我们的机器学习模块 `scikit-learn`，如下面所示：
- en: '[PRE4]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Finally, we will fit our model to the predictors and the response variable,
    as follows:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将拟合模型到预测变量和响应变量，如下所示：
- en: '[PRE5]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Let’s attempt to interpret this:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试解释一下：
- en: '*B0 (6.04)* is the value of **y** when **X** = **0**'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*B0 (6.04)* 是当 **X** = **0** 时 **y** 的值'
- en: It is the estimation of bikes that will be rented when the temperature is 0°C
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这是预测在温度为 0°C 时租出单车的数量
- en: So, at 0°C, six bikes are predicted to be in use (it’s cold!)
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所以，在 0°C 时，预计将有六辆单车被使用（天气很冷！）
- en: Sometimes, it might not make sense to interpret the intercept at all because
    there might not be a concept of zero in some cases. Recall the levels of data.
    Not all levels have this notion of zero. Our target variable does have the inherent
    notion of no bikes; so, we are safe.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，解释截距可能没有意义，因为在某些情况下可能没有零的概念。回想一下数据的层次。并非所有层次都具有零的概念。我们的目标变量确实有“没有单车”的固有概念；因此，我们是安全的。
- en: Correlation versus causation
  id: totrans-191
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 相关性与因果关系
- en: In the context of linear regression, coefficients represent the strength and
    direction of the relationship between the predictor variables and the response
    variable. However, this statistical relationship should not be confused with causation.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 在线性回归的上下文中，系数表示预测变量与响应变量之间关系的强度和方向。然而，这种统计关系不应与因果关系混淆。
- en: 'The coefficient *B1*, with a value of 9.17 in our previous code snippet, indicates
    the average change in the dependent variable (number of bikes rented) for each
    one-unit change in the independent variable (temperature in °C). Concretely, this
    means the following:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 系数 *B1*，在我们之前的代码片段中值为9.17，表示自变量（温度，以°C为单位）每增加1单位时，因变量（租赁的自行车数量）的平均变化量。具体来说，这意味着以下内容：
- en: For every 1°C increase in temperature, there is an associated average increase
    of approximately 9 bikes in rentals
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每上升1°C，租赁的自行车数量平均增加约9辆
- en: 'The positive sign of this coefficient suggests a direct relationship: as temperature
    increases, so do bike rentals'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该系数的正号表明了直接关系：随着温度的升高，自行车租赁数量也随之增加
- en: 'Yet, despite the apparent association indicated by *B1*, we must be cautious.
    This is a correlation, which means it only indicates that two variables move together—it
    does not imply that one causes the other to change. A negative coefficient would
    have suggested an inverse relationship: as temperature rises, bike rentals would
    decrease. But again, this would not confirm that temperature changes cause changes
    in bike rentals.'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，尽管*B1*表明了显著的相关性，我们仍然需要保持谨慎。这只是一个相关性，意味着它仅仅表明两个变量是共同变化的——它并不意味着其中一个变量导致另一个变量的变化。若系数为负数，则表明两者之间存在反向关系：温度上升时，租赁的自行车数量下降。但同样，这也并不能确认温度变化会导致自行车租赁数量的变化。
- en: Causation
  id: totrans-197
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 因果关系
- en: To make a claim of causation, we would need a controlled experimental design
    or additional statistical techniques that account for confounding variables and
    establish a causal link. Without such evidence, our findings from regression analysis
    should be presented as correlational insights, which highlight patterns that may
    warrant further investigation but do not confirm causality.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 要证明因果关系，我们需要进行控制实验设计或使用额外的统计技术，考虑混杂变量并建立因果联系。没有这样的证据，我们从回归分析中得出的结果应当作为相关性洞察呈现，这些洞察展示了可能需要进一步调查的模式，但并不确认因果关系。
- en: Therefore, while our temperature coefficient *B1* suggests a correlation between
    warm weather and increased bike rentals, we cannot conclude that warm weather
    causes more people to rent bikes without a deeper causal analysis.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，尽管我们的温度系数 *B1* 表明温暖天气与增加的自行车租赁数量之间存在相关性，但在没有更深入的因果分析之前，我们不能得出温暖天气导致更多人租赁自行车的结论。
- en: 'Now that we are confident in our interpretations of our correlational findings,
    let’s use `scikit-learn` to make some predictions:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经对相关性分析结果的解释充满信心，让我们使用`scikit-learn`来进行一些预测：
- en: '[PRE6]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This means that roughly 189 bikes will likely be rented if the temperature is
    20°C.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着，如果温度为20°C，那么大约会租出189辆自行车。
- en: Adding more predictors
  id: totrans-203
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 添加更多的预测变量
- en: Of course, temperature is not the only thing that will help us predict the number
    of bikes. Adding more predictors to the model is as simple as telling the linear
    regression model in `scikit-learn` about them!
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，温度并不是唯一能够帮助我们预测自行车数量的因素。向模型中添加更多预测变量就像是告诉`scikit-learn`线性回归模型它们的存在一样简单！
- en: 'Before we do, we should look at the data dictionary provided to us to make
    more sense of some more features:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们进行下一步之前，应该查看数据字典，以便更好地理解一些特征：
- en: '**season**: **1** = **spring**, **2** = **summer**, **3** = **fall**, and **4**
    = **winter**'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**season**: **1** = **春季**，**2** = **夏季**，**3** = **秋季**，**4** = **冬季**'
- en: '**holiday**: Whether the day is considered a holiday'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**holiday**: 是否是节假日'
- en: '**workingday**: Whether the day is a weekend or holiday'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**workingday**: 是否是周末或节假日'
- en: '**weather**: **1** = **Clear, Few clouds, Partly cloudy**, **2** = **Mist +
    Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist**, **3** = **Light Snow,
    Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds**,
    and **4 = Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow +** **Fog**'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**weather**: **1** = **晴天，少云，局部多云**，**2** = **有雾+多云，有雾+破碎云层，有雾+少云，有雾**，**3**
    = **小雪，轻微雨+雷暴+散云，轻微雨+散云**，**4** = **大雨+冰雹+雷暴+雾，雪+雾**'
- en: '**temp**: The temperature in °C'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**temp**: 温度（单位：°C）'
- en: '**atemp**: The “feels like” temperature, taking wind speeds into consideration'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**atemp**: “体感温度”，考虑了风速的影响'
- en: '**humidity**: Relative humidity'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**humidity**: 相对湿度'
- en: 'Now, let’s create our linear regression model using more features. As before,
    we will first create a list holding the features we wish to look at, create our
    features and our response datasets (`X` and `y`), and then fit our linear regression.
    Once we fit our regression model, we will take a look at the model’s coefficients
    in order to see how our features are interacting with our response:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们使用更多特征创建线性回归模型。如之前一样，我们首先创建一个包含希望查看的特征的列表，创建我们的特征和响应数据集（`X`和`y`），然后进行线性回归拟合。一旦我们拟合了回归模型，我们将查看模型的系数，以了解我们的特征是如何与响应变量互动的：
- en: '[PRE7]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'And this is what that means:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着：
- en: Holding all other predictors constant, a 1-unit increase in temperature is associated
    with a rental increase of **7.86** bikes
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在保持其他预测因子不变的情况下，温度增加1个单位与租赁量增加**7.86**辆自行车相关。
- en: Holding all other predictors constant, a 1-unit increase in season is associated
    with a rental increase of **22.5** bikes
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在保持其他预测因子不变的情况下，季节增加1个单位与租赁量增加**22.5**辆自行车相关。
- en: Holding all other predictors constant, a 1-unit increase in weather is associated
    with a rental increase of **6.67** bikes
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在保持其他预测因子不变的情况下，天气增加1个单位与租赁量增加**6.67**辆自行车相关。
- en: Holding all other predictors constant, a 1-unit increase in humidity is associated
    with a rental decrease of **3.12** bikes
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在保持其他预测因子不变的情况下，湿度增加1个单位与租赁量减少**3.12**辆自行车相关。
- en: This is interesting.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 这很有趣。
- en: Important note
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 重要说明
- en: Note that, as **weather** goes up (meaning that the weather is getting closer
    to overcast), the bike demand goes up, as is the case when the season variables
    increase (meaning that we are approaching winter). This is not what I was expecting
    at all, frankly!
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，当**天气**升高时（意味着天气逐渐接近阴天），自行车需求增加，与季节变量增加（意味着我们接近冬季）时一样。这完全不是我预期的结果，老实说！
- en: While these individual correlations are helpful in many ways, it is crucial
    to identify metrics to judge our ML system as a whole. Usually, we think about
    metrics in terms of the task we are performing. Certain metrics are useful for
    classification, while other metrics are more useful for regression.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这些单独的相关性在很多方面都很有用，但至关重要的是要识别衡量整个机器学习系统的指标。通常，我们会根据正在执行的任务来考虑指标。某些指标对于分类任务很有用，而其他指标则更适用于回归任务。
- en: Regression metrics
  id: totrans-224
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 回归指标
- en: 'There are usually three main metrics when using regression ML models. They
    are as follows:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 使用回归机器学习模型时，通常有三个主要的指标。它们如下：
- en: '**Mean Absolute Error (MAE)**: This is the average of the absolute errors between
    the predicted values and the actual values. It’s calculated by taking the sum
    of the absolute values of the errors (the differences between the predicted values
    ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:mover
    accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math>](img/159.png)
    and the actual values ![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"
    xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>](img/160.png))
    and then dividing by the number of observations n:'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**平均绝对误差 (MAE)**：这是预测值与实际值之间绝对误差的平均值。它是通过将误差（预测值与实际值之间的差异）绝对值求和，再除以观察次数n来计算的：'
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:mtext>MAE</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:munderover><mml:mo
    stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mfenced
    open="|" close="|" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:mover
    accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math>](img/161.png)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:mtext>MAE</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:munderover><mml:mo
    stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mfenced
    open="|" close="|" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:mover
    accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math>](img/161.png)'
- en: '**Mean Squared Error (MSE)**: This is the average of the squares of the errors
    between the predicted values and the actual values. It’s computed by squaring
    each error, summing these squares, and then dividing by the number of observations:'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**均方误差 (MSE)**：这是预测值与实际值之间误差的平方的平均值。计算方法是将每个误差平方后求和，再除以观察值的数量：'
- en: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:mtext>MSE</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:munderover><mml:mo
    stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msup><mml:mrow><mml:mfenced
    separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:mover
    accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math>](img/162.png)'
  id: totrans-229
  prefs: []
  type: TYPE_IMG
  zh: '![<mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
    display="block"><mml:mtext>MSE</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:munderover><mml:mo
    stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msup><mml:mrow><mml:mfenced
    separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:mover
    accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math>](img/162.png)'
- en: '**Root MSE (RMSE)**: This is the square root of the MSE. It’s obtained by taking
    the square root of the average of the squared differences between the predicted
    values and the actual values. RMSE is useful because it scales the errors to the
    original units of the output variable and can be more interpretable than MSE:'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**均方根误差 (RMSE)**：这是 MSE 的平方根。通过对预测值与实际值之间的平方差的平均值开平方得到。RMSE 有用之处在于它将误差缩放到输出变量的原始单位，并且比
    MSE 更易于解释：'
- en: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mtext>RMSE</mtext><mo>=</mo><msqrt><mrow><mfrac><mn>1</mn><mi>n</mi></mfrac><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msup><mfenced
    open="(" close=")"><mrow><msub><mi>y</mi><mi>i</mi></msub><mo>−</mo><mover><msub><mi>y</mi><mi>i</mi></msub><mo
    stretchy="true">ˆ</mo></mover></mrow></mfenced><mn>2</mn></msup></mrow></mrow></msqrt></mrow></mrow></math>](img/163.png)'
  id: totrans-231
  prefs: []
  type: TYPE_IMG
  zh: '![<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mrow><mtext>RMSE</mtext><mo>=</mo><msqrt><mrow><mfrac><mn>1</mn><mi>n</mi></mfrac><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msup><mfenced
    open="(" close=")"><mrow><msub><mi>y</mi><mi>i</mi></msub><mo>−</mo><mover><msub><mi>y</mi><mi>i</mi></msub><mo
    stretchy="true">ˆ</mo></mover></mrow></mfenced><mn>2</mn></msup></mrow></mrow></msqrt></mrow></mrow></math>](img/163.png)'
- en: These metrics are crucial in evaluating the performance of regression models,
    with each having its own advantages. MAE provides a straightforward average-error
    magnitude, MSE penalizes larger errors more heavily, and RMSE is particularly
    sensitive to large errors due to the squaring of the errors.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 这些指标在评估回归模型性能时至关重要，每个指标都有其优势。MAE提供了一个简单的平均误差量，MSE对较大的误差进行了更严重的惩罚，而RMSE由于误差的平方而对大误差特别敏感。
- en: 'Let’s take a look at implementations in Python:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看Python中的实现：
- en: '[PRE8]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Here, the output would be as follows:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，输出将如下所示：
- en: '[PRE9]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Let’s use RMSE to ascertain which columns are helping and which are hindering.
    Let’s start with only using temperature. Note that our procedure will be as follows:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用RMSE来确定哪些列有助于哪些列有阻碍。让我们从只使用温度开始。请注意，我们的程序将按以下步骤进行：
- en: Create our **X** and our **y** variables.
  id: totrans-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建我们的**X**和我们的**y**变量。
- en: Fit a linear regression model.
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 拟合线性回归模型。
- en: Use the model to make a list of predictions based on **X**.
  id: totrans-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用模型基于**X**进行预测列表。
- en: Calculate the RMSE between the predictions and the actual values.
  id: totrans-241
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算预测值和实际值之间的RMSE。
- en: 'Let’s take a look at the code:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看代码：
- en: '[PRE10]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Now, let’s try it using temperature and humidity, as shown:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们尝试使用温度和湿度，如图所示：
- en: '[PRE11]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'It got better! Let’s try using even more predictors, as illustrated:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 它变得更好了！让我们尝试使用更多的预测变量，如图所示：
- en: '[PRE12]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Even better! At first, this seems like a major triumph, but there is actually
    a hidden danger here. Note that we are training the line to fit `X` and `y` and
    then asking it to predict `X` again! This is actually a huge mistake in ML because
    it can lead to overfitting, which means that our model is merely memorizing the
    data and regurgitating it back to us.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 更好！起初，这似乎是一个重大的胜利，但实际上这里存在着隐藏的危险。请注意，我们正在训练线来拟合`X`和`y`，然后要求它再次预测`X`！这实际上是机器学习中的一个巨大错误，因为它可能导致过度拟合，这意味着我们的模型只是记住数据并将其吐回给我们。
- en: Imagine that you are a student, and you walk into the first day of class and
    the teacher says that the final exam is very difficult in this class. In order
    to prepare you, she gives you practice test after practice test after practice
    test. The day of the final exam arrives, and you are shocked to find out that
    every question on the exam is exactly the same as in the practice test! Luckily,
    you did them so many times that you remember the answer and get 100% on the exam.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下你是一名学生，走进第一天的课堂，老师说这门课的期末考试非常困难。为了帮助你准备，她给了你一次又一次的练习测试。期末考试的那天到来了，你震惊地发现考试中的每一道题都与练习测试中的完全相同！幸运的是，你做了那么多次，记住了答案并在考试中得到了满分。
- en: The same thing applies here, more or less. By fitting and predicting on the
    same data, the model is memorizing the data and getting better at it. A great
    way to combat this **overfitting** problem is to use the train/test approach to
    fit ML models, which works as illustrated next.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 这里也大体上是一样的。通过在相同数据上拟合和预测，模型正在记忆数据并在其上变得更好。解决这个**过拟合**问题的一个很好的方法是使用训练/测试方法来拟合机器学习模型，下面将详细介绍。
- en: 'Essentially, we will take the following steps:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上，我们将采取以下步骤：
- en: 'Split up the dataset into two parts: a training and a test set.'
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据集分成两部分：训练集和测试集。
- en: Fit our model on the training set and then test it on the test set, just like
    in school, where the teacher would teach from one set of notes and then test us
    on different (but similar) questions.
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在训练集上拟合我们的模型，然后在测试集上进行测试，就像在学校里，老师会从一组笔记教学，然后用不同（但相似）的问题来测试我们。
- en: Once our model is good enough (based on our metrics), we turn our model’s attention
    toward the entire dataset.
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦我们的模型足够好（基于我们的指标），我们将模型的注意力转向整个数据集。
- en: Our model awaits new data previously unseen by anyone.
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们的模型等待先前任何人都未见的新数据。
- en: 'This can be visualized in *Figure 10**.10*:'
  id: totrans-256
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这可以在*图10**.10*中可视化：
- en: '![Figure 10.10 – Splitting our data up into a training and testing set helps
    us properly evaluate our model’s ability to predict unseen data](img/B19488_10_10.jpg)'
  id: totrans-257
  prefs: []
  type: TYPE_IMG
  zh: '![图10.10 – 将数据拆分成训练集和测试集有助于正确评估我们模型预测未见数据的能力](img/B19488_10_10.jpg)'
- en: Figure 10.10 – Splitting our data up into a training and testing set helps us
    properly evaluate our model’s ability to predict unseen data
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.10 – 将数据拆分成训练集和测试集有助于正确评估我们模型预测未见数据的能力
- en: The goal here is to minimize the out-of-sample errors of our model, which are
    errors our model has on data that it has never seen before. This is important
    because the main idea (usually) of a supervised model is to predict outcomes for
    new data. If our model is unable to generalize from our training data and use
    that to predict unseen cases, then our model isn’t very good.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的目标是最小化我们模型在未见过的数据上的错误，也就是模型对新数据的预测错误。这很重要，因为监督模型的主要目标（通常来说）是预测新数据的结果。如果我们的模型不能从训练数据中泛化并用于预测未见过的案例，那么我们的模型就不够好。
- en: The preceding diagram outlines a simple way of ensuring that our model can effectively
    ingest the training data and use it to predict data points that the model itself
    has never seen. Of course, as data scientists, we know that the test set also
    has answers attached to it, but the model doesn’t know that.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 上述图表概述了一种简单的方法，确保我们的模型能够有效地摄取训练数据，并利用这些数据预测模型从未见过的数据点。当然，作为数据科学家，我们知道测试集也附带答案，但模型并不知道这一点。
- en: 'All of this might sound complicated, but luckily, the `scikit-learn` package
    has a built-in method to do this, as shown:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 这一切可能听起来有点复杂，但幸运的是，`scikit-learn`包提供了一个内置方法来完成这一过程，如下所示：
- en: '[PRE13]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: In other words, our `train_test_split` function is ensuring that the metrics
    we are looking at are more honest estimates of our sample performance.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，我们的`train_test_split`函数确保我们所看的指标是对我们样本表现的更真实的估计。
- en: 'Now, let’s try again with more predictors, as follows:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们使用更多的预测变量，再做一次尝试，如下所示：
- en: '[PRE14]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Our model actually got worse with that addition! This implies that `workingday`
    might not be very predictive of our response, the bike rental count.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 加入这个特征后，我们的模型实际上变得更差了！这意味着`workingday`（工作日）可能对我们的预测变量——自行车租赁数量，并没有很强的预测能力。
- en: All of this is well and good, and we can keep adding and removing features to
    lower our RMSE, but how well is our model really doing at predicting rather than
    just guessing? We have an RMSE of around 167 bikes, but is that good? What do
    we compare it to? One way to discover this is to evaluate the null model.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 这一切都很好，我们可以继续添加和删除特征来降低我们的RMSE，但我们的模型在预测方面到底有多好，而不仅仅是猜测呢？我们有一个大约167辆自行车的RMSE，这好么？我们该拿什么来对比呢？发现这一点的一个方法是评估空模型。
- en: The **null model** in SML represents effectively guessing the expected outcome
    over and over, and seeing how you did. For example, in regression, if we always
    guess the average number of hourly bike rentals, then how well would that model
    do?
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: '**空模型**在监督机器学习中代表了反复猜测预期结果，并查看你做得如何。例如，在回归分析中，如果我们总是猜测每小时自行车租赁的平均值，那么这个模型会有多好？'
- en: 'First, let’s get the average hourly bike rental, as shown:'
  id: totrans-269
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，让我们计算平均每小时自行车租赁量，如下所示：
- en: '[PRE15]'
  id: totrans-270
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-271
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: This means that, overall, in this dataset, regardless of weather, time, day
    of the week, humidity, and everything else, the average number of bikes that go
    out every hour is about 192.
  id: totrans-272
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这意味着，在这个数据集中，无论天气、时间、星期几、湿度或其他因素如何，每小时平均外借的自行车数量大约是192辆。
- en: 'Let’s make a fake prediction list, wherein every single guess is 191.57\. Let’s
    make this guess for every single hour, as follows:'
  id: totrans-273
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们做一个假设的预测列表，其中每一个猜测值都是191.57。我们为每一个小时做这个猜测，如下所示：
- en: '[PRE17]'
  id: totrans-274
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-275
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[PRE19]'
  id: totrans-276
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The output is as follows:'
  id: totrans-277
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE20]'
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[PRE21]'
  id: totrans-279
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[PRE22]'
  id: totrans-280
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[PRE23]'
  id: totrans-281
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '[PRE24]'
  id: totrans-282
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '[PRE25]'
  id: totrans-283
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[PRE26]'
  id: totrans-284
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[PRE27]'
  id: totrans-285
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '[PRE28]'
  id: totrans-286
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'So, we have `10,886` values, all of which are the average hourly bike rental
    number. Let’s see what the RMSE would be if our model only ever guessed the expected
    value of the average hourly bike rental count:'
  id: totrans-287
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 因此，我们有`10,886`个值，所有值都是平均每小时的自行车租赁数量。让我们看看，如果我们的模型只猜测每小时的平均租赁数量，RMSE会是多少：
- en: '[PRE29]'
  id: totrans-288
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The output is as follows:'
  id: totrans-289
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE30]'
  id: totrans-290
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: This means that by simply guessing the average value over and over again, our
    RMSE would be 181 bikes. So, even with one or two features, we can beat it! Beating
    the null model is a kind of baseline in ML. If you think about it, why go through
    any effort at all if your ML is not even better than just guessing?
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着仅仅通过反复猜测平均值，我们的RMSE会是181辆自行车。因此，即使只有一两个特征，我们也能超过它！在机器学习中，打败空模型是一种基准。如果你想想看，如果你的机器学习模型甚至不如仅仅猜测的结果，为什么要费力去做呢？
- en: Summary
  id: totrans-292
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we looked at ML and its different subcategories. We explored
    SL, UL, and RL strategies and looked at situations where each one would come in
    handy.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们了解了机器学习及其不同的子类别。我们探索了监督学习（SL）、无监督学习（UL）和强化学习（RL）策略，并分析了每种策略在不同情况下的应用。
- en: Looking into linear regression, we were able to find relationships between predictors
    and a continuous response variable. Through the train/test split, we were able
    to help avoid overfitting our ML models and get a more generalized prediction.
    We were able to use metrics, such as RMSE, to evaluate our models as well.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 在研究线性回归时，我们能够找到预测变量与连续响应变量之间的关系。通过训练/测试集划分，我们能够帮助避免机器学习模型的过拟合，并获得更具泛化性的预测。我们还能够使用诸如RMSE等指标来评估我们的模型。
- en: In the next few chapters, we will be taking a much deeper dive into many more
    ML models and, along the way, we will learn new metrics, new validation techniques,
    and – more importantly – new ways of applying data science to the world.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的几章中，我们将深入探讨更多的机器学习模型，同时，我们将学习新的指标、新的验证技术，以及——更重要的是——将数据科学应用于世界的新方式。
