- en: Preface
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 前言
- en: 'The data processing framework named Spark was first built to prove that, by
    re-using the data sets across a number of iterations, it provided value where
    Hadoop MapReduce jobs performed poorly. The research paper *Mesos: A Platform
    for Fine-Grained Resource Sharing in the Data Center* talks about the philosophy
    behind the design of Spark. A very simplistic reference implementation built to
    test Mesos by the University of California Berkeley researchers has grown far
    and beyond to become a full blown data processing framework later became one of
    the most active Apache projects. It is designed from the ground up to do distributed
    data processing on clusters such as Hadoop, Mesos, and in standalone mode. Spark
    is a JVM-based data processing framework and hence it works on most operating
    systems that support JVM-based applications. Spark is widely installed on UNIX
    and Mac OS X, platforms and Windows adoption is increasing.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 数据处理框架Spark最初是为了证明，通过在多次迭代中重用数据集，它在Hadoop MapReduce作业表现不佳的地方提供了价值。研究论文《Mesos：数据中心细粒度资源共享平台》讨论了Spark设计背后的哲学。加州大学伯克利分校的研究人员为测试Mesos而构建的一个非常简单的参考实现，已经远远超越了最初的用途，发展成为一个完整的数据处理框架，后来成为最活跃的Apache项目之一。它从一开始就被设计用于在Hadoop、Mesos等集群上进行分布式数据处理，以及在独立模式下运行。Spark是一个基于JVM的数据处理框架，因此它可以在支持基于JVM的应用程序的大多数操作系统上运行。Spark广泛安装在UNIX和Mac
    OS X平台上，而Windows上的采用也在增加。
- en: Spark provides a unified programming model using the programming languages Scala,
    Java, Python and R. In other words, irrespective of the language used to program
    Spark applications, the API remains almost the same in all the languages. In this
    way, organizations can adopt Spark and develop applications in their programming
    language of choice. This also enables fast porting of Spark applications from
    one language to another without much effort, if there is a need. Most of Spark
    is developed using Scala and because of that the Spark programming model inherently
    supports functional programming principles. The most basic Spark data abstraction
    is the resilient distributed data set (RDD), based on which all the other libraries
    are built. The RDD-based Spark programming model is the lowest level where developers
    can build data processing applications.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: Spark通过编程语言Scala、Java、Python和R提供了一个统一的编程模型。换句话说，无论使用哪种语言编写Spark应用程序，API在所有语言中几乎都是相同的。这样，组织可以采用Spark并在他们选择的编程语言中开发应用程序。这也使得在需要时可以快速将Spark应用程序从一个语言移植到另一个语言，而无需太多努力。Spark大部分是用Scala开发的，因此Spark编程模型本质上支持函数式编程原则。最基本的Spark数据抽象是弹性分布式数据集（RDD），基于此构建了所有其他库。基于RDD的Spark编程模型是开发者可以构建数据处理应用程序的最低级别。
- en: Spark has grown fast, to cater to the needs of more data processing use cases.
    When such a forward-looking step is taken with respect to the product road map,
    the requirement emerged to make the programming more high level for business users. 
    The Spark SQL library on top of Spark Core, with its DataFrame abstraction, was
    built to cater to the needs of the huge population of developers who are very
    conversant with the ubiquitous SQL.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: Spark迅速发展，以满足更多数据处理用例的需求。当采取这种前瞻性的产品路线图步骤时，出现了对商业用户进行更高级别编程的需求。基于Spark核心的Spark
    SQL库，以其DataFrame抽象，被构建来满足大量非常熟悉无处不在的SQL的开发者的需求。
- en: Data scientists use R for their computation needs. The biggest limitation of
    R is that all the data that needs to be processed should *fit* into the main memory
    of the computer on which the R program is running. The R API for Spark introduced
    data scientists to the world of distributed data processing in their familiar
    data frame abstraction. In other words, using the R API for Spark, the processing
    of data can be done in parallel on Hadoop or Mesos, growing far beyond the limitation
    of the resident memory of the host computer.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家使用R语言进行计算需求。R语言最大的限制是所有需要处理的数据都应该*适合*运行R程序的计算机的主内存。Spark为R语言引入的API让数据科学家们熟悉了在熟悉的数据帧抽象中的分布式数据处理世界。换句话说，使用R语言的Spark
    API，数据处理可以在Hadoop或Mesos上并行进行，远远超出了主机内存的限制。
- en: In the present era of large-scale applications that collect data, the velocity
    of the data that is ingested is very high. Many application use cases mandate
    real-time processing of the data that is streamed. The Spark Streaming library,
    built on top of Spark Core, does exactly the same.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在当前大规模应用收集数据的时代，摄入数据的速率非常高。许多应用场景要求对流式数据进行实时处理。建立在Spark Core之上的Spark Streaming库正是为此而设计。
- en: The data at rest or the data that is streamed are fed to machine learning algorithms 
    to train data models and use them to provide answers to business questions. All
    the machine learning frameworks that were created before Spark had many limitations
    in terms of the memory of the processing computer, inability to do parallel processing,
    repeated read-write cycles, so on. Spark doesn't have any of these limitations
    and hence the Spark MLlib machine learning library, built on top of Spark Core
    and Spark DataFrames, turned out to be the best of breed machine learning library
    that glues together the data processing pipelines and machine learning activities.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 静态数据或流式数据被输入机器学习算法以训练数据模型，并使用这些模型来回答业务问题。在Spark之前创建的所有机器学习框架在处理计算机的内存、无法进行并行处理、重复的读写周期等方面存在许多限制。Spark没有这些限制，因此建立在Spark
    Core和Spark DataFrames之上的Spark MLlib机器学习库成为了最佳的机器学习库，它将数据处理管道和机器学习活动紧密结合。
- en: Graph is a very useful data structure used heavily in some special use cases.
    The algorithms used to process the data in a graph data structure are computationally
    intensive. Before Spark, many graph processing frameworks came along, and some
    of them were really fast at processing, but pre-processing the data needed to
    produce the graph data structure turned out to be a big bottleneck in most of
    these graph processing applications. The Spark GraphX library, built on top of
    Spark, filled this gap to make data processing and graph processing as chained
    activities.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图是一种非常有用的数据结构，在某些特殊用例中被大量使用。用于处理图数据结构的算法计算密集。在Spark之前，出现了许多图处理框架，其中一些处理速度非常快，但生成图数据结构所需的数据预处理在大多数图处理应用中成为了一个巨大的瓶颈。建立在Spark之上的Spark
    GraphX库填补了这一空白，使得数据处理和图处理成为链式活动。
- en: In the past, many data processing frameworks existed and many of them were proprietary
    forcing organizations to get into the trap of vendor lock-in. Spark provided a
    very viable alternative for a wide variety of data processing needs with no licensing
    cost; at the same time, it was backed by many leading companies, providing professional
    production support.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 过去，存在许多数据处理框架，其中许多是专有的，迫使组织陷入供应商锁定的陷阱。Spark为各种数据处理需求提供了一个非常可行的替代方案，且无需许可费用；同时，它得到了许多领先公司的支持，提供专业的生产支持。
- en: What this book covers
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书涵盖的内容
- en: '[Chapter 1](ch01.html "Chapter 1. Spark Fundamentals"), *Spark Fundamentals*,
    discusses the fundamentals of Spark as a framework with its APIs and the libraries
    that comes with it, along with the whole data processing ecosystem Spark is interacting
    with.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[第1章](ch01.html "第1章. Spark基础")，*Spark基础*，探讨了Spark作为一个框架的基本原理，包括其API和随附的库，以及Spark与之交互的整个数据处理生态系统。'
- en: '[Chapter 2](ch02.html "Chapter 2. Spark Programming Model"), *Spark Programming
    Model*, discusses the uniform programming model, based on the tenets of functional
    programming methodology, that is used in Spark, and covers the fundamentals of
    resilient distributed data sets (RDD), Spark transformations, and Spark actions.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[第2章](ch02.html "第2章. Spark编程模型")，*Spark编程模型*，讨论了基于函数式编程方法论的统一编程模型，该模型在Spark中使用，并涵盖了弹性分布式数据集（RDD）的基础、Spark转换和Spark操作。'
- en: '[Chapter 3](ch03.html "Chapter 3. Spark SQL"), *Spark SQL*, discusses Spark
    SQL, which is one of the most powerful Spark libraries used to manipulate data
    using the ubiquitous SQL constructs in conjunction with the Spark DataFrame API,
    and and how it works with Spark programs. This chapter also discusses how Spark
    SQL is used to access data from various data sources, enabling the unification
    of diverse data sources for data processing.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[第3章](ch03.html "第3章. Spark SQL")，*Spark SQL*，讨论了Spark SQL，这是最强大的Spark库之一，用于使用无处不在的SQL结构以及Spark
    DataFrame API来操作数据，并探讨了它如何与Spark程序协同工作。本章还讨论了如何使用Spark SQL从各种数据源访问数据，实现对多样数据源的数据处理统一。'
- en: '[Chapter 4](ch04.html "Chapter 4. Spark Programming with R"), *Spark Programming
    with R*, discusses SparkR or R on Spark, which is the R API for Spark; this enables
    R users to make use of the data processing capabilities of Spark using their familiar
    data frame abstraction. It gives a very good foundation for R users to get acquainted
    with the Spark data processing ecosystem.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[第4章](ch04.html "第4章 使用R进行Spark编程")，*使用R进行Spark编程*，讨论了SparkR或R on Spark，这是Spark的R
    API；这使得R用户能够利用Spark的数据处理能力，使用他们熟悉的数据帧抽象。它为R用户提供了一个很好的基础，以便熟悉Spark数据处理生态系统。'
- en: '[Chapter 5](ch05.html "Chapter 5. Spark Data Analysis with Python"), *Spark
    Data Analysis with Python*, discusses the use of Spark to do data processing and
    Python to do data analysis, using a wide variety of charting and plotting libraries
    available for Python. This chapter discusses combining these two related activities
    together as a Spark application with Python as the programming language of choice.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[第5章](ch05.html "第5章 使用Python进行Spark数据分析")，*使用Python进行Spark数据分析*，讨论了使用Spark进行数据处理和使用Python进行数据分析，利用了Python提供的各种图表和绘图库。本章讨论了将这两项相关活动结合在一起，作为使用Python作为首选编程语言的Spark应用程序。'
- en: '[Chapter 6](ch06.html "Chapter 6.  Spark Stream Processing"), *Spark Stream
    Processing*, discusses Spark Streaming, which is one of the most powerful Spark
    libraries to capture and process data that is ingested as a stream. Kafka as the
    distributed message broker and a Spark Streaming application as the consumer are
    also discussed.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[第6章](ch06.html "第6章 Spark流处理")，*Spark流处理*，讨论了Spark Streaming，这是用于捕获和处理以流形式输入的数据的最强大的Spark库之一。还讨论了作为分布式消息代理的Kafka和作为消费者的Spark
    Streaming应用程序。'
- en: '[Chapter 7](ch07.html "Chapter 7.  Spark Machine Learning"), *Spark Machine
    Learning*, discusses Spark MLlib, which is one of the most powerful Spark libraries
    used to develop machine learning applications at an introductory level.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[第7章](ch07.html "第7章 Spark机器学习")，*Spark机器学习*，探讨了Spark MLlib，这是用于开发入门级机器学习应用程序的最强大的Spark库之一。'
- en: '[Chapter 8](ch08.html "Chapter 8. Spark Graph Processing"), *Spark Graph Processing*,
    discusses Spark GraphX, which is one of the most powerful Spark libraries to process
    graph data structures, and comes with lots of algorithms to process data in graphs.
    This chapter covers the basics of GraphX and some use cases implemented using
    the algorithms provided by GraphX.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '[第8章](ch08.html "第8章 Spark图处理")，*Spark图处理*，讨论了Spark GraphX，这是处理图数据结构的最强大的Spark库之一，并附带了许多用于图数据处理的算法。本章涵盖了GraphX的基础知识以及使用GraphX提供的算法实现的一些用例。'
- en: '[Chapter 9](ch09.html "Chapter 9.  Designing Spark Applications"), *Designing
    Spark Applications*, discusses the design and development of a Spark data processing
    application, covering various features of Spark that were covered in the previous
    chapters of this book.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '[第9章](ch09.html "第9章 设计Spark应用程序")，*设计Spark应用程序*，讨论了Spark数据处理应用程序的设计和开发，涵盖了本书前几章中介绍的Spark的各种特性。'
- en: What you need for this book
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书所需条件
- en: Spark 2.0.0 or above is to be installed on at least a standalone machine to
    run the code samples and do further activities to learn more about the subject.
    For [Chapter 6](ch06.html "Chapter 6.  Spark Stream Processing"), Spark Stream
    Processing, Kafka needs to be installed and configured as a message broker with
    its command line producer producing messages and the application developed using
    Spark as a consumer of those messages.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: Spark 2.0.0或更高版本需要安装在至少一台独立机器上，以运行代码示例并进行进一步的活动，以更深入地了解该主题。对于[第6章](ch06.html
    "第6章 Spark流处理")，*Spark流处理*，需要安装并配置Kafka作为消息代理，其命令行生产者产生消息，而使用Spark开发的应用程序作为这些消息的消费者。
- en: Who this book is for
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书面向的读者
- en: If you are an application developer, data scientist, or big data solutions architect
    who is interested in combining the data processing power of Spark with R, and
    consolidating data processing, stream processing, machine learning, and graph
    processing into one unified and highly interoperable framework with a uniform
    API using Scala or Python, this book is for you.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你是应用程序开发者、数据科学家或大数据解决方案架构师，并对将Spark的数据处理能力与R结合，以及将数据处理、流处理、机器学习、图处理整合到一个统一且高度互操作的框架中，使用统一的API（Scala或Python）感兴趣，那么这本书适合你。
- en: Conventions
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 约定
- en: In this book, you will find a number of text styles that distinguish between
    different kinds of information. Here are some examples of these styles and an
    explanation of their meaning.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，您会发现多种文本样式用于区分不同类型的信息。以下是这些样式的一些示例及其含义的解释。
- en: 'Code words in text, database table names, folder names, filenames, file extensions,
    pathnames, dummy URLs, user input, and Twitter handles are shown as follows: "
    It is a good idea to customize this property `spark.driver.memory` to have a higher
    value."'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 文本中的代码词、数据库表名、文件夹名、文件名、文件扩展名、路径名、虚拟URL、用户输入和Twitter句柄如下所示："将此属性`spark.driver.memory`设置为更高值是个好主意。"
- en: 'A block of code is set as follows:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 代码块设置如下：
- en: '[PRE0]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Any command-line input or output is written as follows:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 任何命令行输入或输出书写如下：
- en: '[PRE1]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '**New terms** and **important words** are shown in bold. Words that you see
    on the screen, for example, in menus or dialog boxes, appear in the text like
    this: "The shortcuts in this book are based on the `Mac OS X 10.5+` scheme."'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**新术语**和**重要词汇**以粗体显示。屏幕上出现的词汇，例如在菜单或对话框中，在文本中这样呈现："本书中的快捷键基于`Mac OS X 10.5+`方案。"'
- en: Note
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Warnings or important notes appear in a box like this.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 警告或重要提示以这样的方框形式出现。
- en: Tip
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: Tips and tricks appear like this.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 提示和技巧这样呈现。
- en: Reader feedback
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 读者反馈
- en: Feedback from our readers is always welcome. Let us know what you think about
    this book-what you liked or disliked. Reader feedback is important for us as it
    helps us develop titles that you will really get the most out of. To send us general
    feedback, simply e-mail feedback@packtpub.com, and mention the book's title in
    the subject of your message. If there is a topic that you have expertise in and
    you are interested in either writing or contributing to a book, see our author
    guide at [www.packtpub.com/authors](http://www.packtpub.com/authors).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们始终欢迎读者的反馈。告诉我们您对本书的看法——您喜欢或不喜欢的部分。读者反馈对我们至关重要，因为它帮助我们开发您能真正从中受益的图书。若要向我们发送一般反馈，只需发送电子邮件至feedback@packtpub.com，并在邮件主题中提及书名。如果您在某个领域具有专业知识，并对撰写或参与撰写一本书感兴趣，请参阅我们的作者指南：[www.packtpub.com/authors](http://www.packtpub.com/authors)。
- en: Customer support
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 客户支持
- en: Now that you are the proud owner of a Packt book, we have a number of things
    to help you to get the most from your purchase.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 既然您已是Packt图书的自豪拥有者，我们有一系列服务帮助您从购买中获得最大收益。
- en: Downloading the example code
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 下载示例代码
- en: You can download the example code files for this book from your account at [http://www.packtpub.com](http://www.packtpub.com).
    If you purchased this book elsewhere, you can visit [http://www.packtpub.com/support](http://www.packtpub.com/support)
    and register to have the files e-mailed directly to you.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从您的[http://www.packtpub.com](http://www.packtpub.com)账户下载本书的示例代码文件。如果您在其他地方购买了本书，可以访问[http://www.packtpub.com/support](http://www.packtpub.com/support)并注册，以便将文件直接发送到您的邮箱。
- en: 'You can download the code files by following these steps:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过以下步骤下载代码文件：
- en: Log in or register to our website using your e-mail address and password.
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用您的电子邮件地址和密码登录或注册我们的网站。
- en: Hover the mouse pointer on the **SUPPORT** tab at the top.
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将鼠标悬停在页面顶部的**支持**选项卡上。
- en: Click on **Code Downloads & Errata**.
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**代码下载与勘误**。
- en: Enter the name of the book in the **Search** box.
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**搜索**框中输入书名。
- en: Select the book for which you're looking to download the code files.
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择您要下载代码文件的书籍。
- en: Choose from the drop-down menu where you purchased this book from.
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从下拉菜单中选择您购买本书的来源。
- en: Click on **Code Download**.
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**代码下载**。
- en: 'Once the file is downloaded, please make sure that you unzip or extract the
    folder using the latest version of:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 下载文件后，请确保使用最新版本的以下软件解压或提取文件夹：
- en: WinRAR / 7-Zip for Windows
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: WinRAR / 7-Zip（适用于Windows）
- en: Zipeg / iZip / UnRarX for Mac
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zipeg / iZip / UnRarX（适用于Mac）
- en: 7-Zip / PeaZip for Linux
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 7-Zip / PeaZip（适用于Linux）
- en: The code bundle for the book is also hosted on GitHub at [https://github.com/PacktPublishing/Apache-Spark-2-for-Beginners](https://github.com/PacktPublishing/Apache-Spark-2-for-Beginners).
    We also have other code bundles from our rich catalog of books and videos available
    at [https://github.com/PacktPublishing/](https://github.com/PacktPublishing/).
    Check them out!
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的代码包也托管在GitHub上，地址为[https://github.com/PacktPublishing/Apache-Spark-2-for-Beginners](https://github.com/PacktPublishing/Apache-Spark-2-for-Beginners)。我们还有来自丰富图书和视频目录的其他代码包，可在[https://github.com/PacktPublishing/](https://github.com/PacktPublishing/)查看。快去看看吧！
- en: Downloading the color images of this book
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 下载本书的彩色图像
- en: We also provide you with a PDF file that has color images of the screenshots/diagrams
    used in this book. The color images will help you better understand the changes
    in the output. You can download this file from [http://www.packtpub.com/sites/default/files/downloads/ApacheSpark2forBeginners_ColorImages.pdf](http://www.packtpub.com/sites/default/files/downloads/Bookname_ColorImages.pdf).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还为您提供了一个包含本书中使用的屏幕截图/图表彩色图像的PDF文件。彩色图像将帮助您更好地理解输出中的变化。您可以从[http://www.packtpub.com/sites/default/files/downloads/ApacheSpark2forBeginners_ColorImages.pdf](http://www.packtpub.com/sites/default/files/downloads/Bookname_ColorImages.pdf)下载此文件。
- en: Errata
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 勘误
- en: Although we have taken every care to ensure the accuracy of our content, mistakes
    do happen. If you find a mistake in one of our books-maybe a mistake in the text
    or the code-we would be grateful if you could report this to us. By doing so,
    you can save other readers from frustration and help us improve subsequent versions
    of this book. If you find any errata, please report them by visiting [http://www.packtpub.com/submit-errata](http://www.packtpub.com/submit-errata),
    selecting your book, clicking on the **Errata Submission Form** link, and entering
    the details of your errata. Once your errata are verified, your submission will
    be accepted and the errata will be uploaded to our website or added to any list
    of existing errata under the Errata section of that title.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们已经尽一切努力确保内容的准确性，但错误仍然会发生。如果您在我们的书中发现错误——可能是文本或代码中的错误——如果您能向我们报告，我们将非常感激。通过这样做，您可以节省其他读者的烦恼，并帮助我们改进本书的后续版本。如果您发现任何勘误，请通过访问[http://www.packtpub.com/submit-errata](http://www.packtpub.com/submit-errata)，选择您的书，点击**勘误提交表单**链接，并输入您的勘误详情来报告它们。一旦您的勘误得到验证，您的提交将被接受，勘误将被上传到我们的网站或添加到该标题的**勘误**部分下的任何现有勘误列表中。
- en: To view the previously submitted errata, go to [https://www.packtpub.com/books/content/support](https://www.packtpub.com/books/content/support)
    and enter the name of the book in the search field. The required information will
    appear under the **Errata** section.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看之前提交的勘误，请访问[https://www.packtpub.com/books/content/support](https://www.packtpub.com/books/content/support)并在搜索字段中输入书名。所需信息将显示在**勘误**部分下。
- en: Piracy
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 盗版
- en: Piracy of copyrighted material on the Internet is an ongoing problem across
    all media. At Packt, we take the protection of our copyright and licenses very
    seriously. If you come across any illegal copies of our works in any form on the
    Internet, please provide us with the location address or website name immediately
    so that we can pursue a remedy.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 互联网上版权材料的盗版是所有媒体持续存在的问题。在Packt，我们非常重视保护我们的版权和许可证。如果您在互联网上任何形式的非法复制我们的作品，请立即向我们提供位置地址或网站名称，以便我们采取补救措施。
- en: Please contact us at copyright@packtpub.com with a link to the suspected pirated
    material.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 请通过电子邮件copyright@packtpub.com与我们联系，并附上涉嫌盗版材料的链接。
- en: We appreciate your help in protecting our authors and our ability to bring you
    valuable content.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们感谢您在保护我们的作者和为我们带来有价值内容方面的帮助。
- en: Questions
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: If you have a problem with any aspect of this book, you can contact us at questions@packtpub.com,
    and we will do our best to address the problem.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在本书的任何方面遇到问题，可以通过questions@packtpub.com与我们联系，我们将尽最大努力解决问题。
