- en: '3'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '3'
- en: Data Types
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据类型
- en: The data type of a `pd.Series` allows you to dictate what kind of elements may
    or may not be stored. Data types are important for ensuring data quality, as well
    as enabling high-performance algorithms in your code. If you have a data background
    working with databases, you more than likely are already familiar with data types
    and their benefits; you will find types like `TEXT`, `INTEGER`, and `DOUBLE PRECISION`
    in pandas just like you do in a database, albeit under different names.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '`pd.Series`的数据类型允许你指定可以或不可以存储的元素类型。数据类型对于确保数据质量以及在代码中启用高性能算法至关重要。如果你有数据库工作背景，你很可能已经熟悉数据类型及其好处；你将在pandas中找到像`TEXT`、`INTEGER`和`DOUBLE
    PRECISION`这样的类型，就像在数据库中一样，尽管它们的名称不同。'
- en: Unlike a database, however, pandas offers multiple implementations of how a
    `TEXT`, `INTEGER`, and `DOUBLE PRECISION` type can work. Unfortunately, this means,
    as an end user, that you should at least have some understanding of how the different
    data types are implemented to make the best choice for your application.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，与数据库不同，pandas提供了多种实现方式，来处理`TEXT`、`INTEGER`和`DOUBLE PRECISION`类型。不幸的是，这意味着作为最终用户，你至少应该了解不同数据类型的实现方式，以便为你的应用选择最佳的选项。
- en: A quick history lesson on types in pandas can help explain this usability quirk.
    Originally, pandas was built on top of the NumPy type system. This worked for
    quite a while but had major shortcomings. For starters, the NumPy types pandas
    built on top of did not support missing values, so pandas created a Frankenstein’s
    monster of methods to support those. NumPy, being focused on *numerical* computations,
    also did not offer a first-class string data type, leading to very poor string
    handling in pandas.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 关于pandas中类型的简短历史可以帮助解释这一可用性上的怪癖。最初，pandas是建立在NumPy类型系统之上的。这种方法在一段时间内是有效的，但存在重大缺陷。首先，pandas构建的NumPy类型不支持缺失值，因此pandas创造了一种“弗兰肯斯坦的怪物”方法来支持这些值。由于NumPy专注于*数值*计算，它也没有提供一流的字符串数据类型，导致pandas中的字符串处理非常差。
- en: Work to move past the NumPy type system started with pandas version 0.23, which
    introduced new data types built directly into pandas that were still implemented
    using NumPy but could actually handle missing values. In version 1.0, pandas implemented
    its own string data type. At the time, these were called `numpy_nullable` data
    types, but over time, they have become referred to as pandas extension types.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 从pandas版本0.23开始，pandas努力超越了NumPy类型系统，该版本引入了直接内置在pandas中的新数据类型，这些类型虽然仍然使用NumPy实现，但实际上能够处理缺失值。在版本1.0中，pandas实现了自己的字符串数据类型。当时，这些类型被称为`numpy_nullable`数据类型，但随着时间的推移，它们被称为pandas扩展类型。
- en: While all of this was going on, Wes McKinney, the original creator of pandas,
    was working on the Apache Arrow project. Fully explaining the Arrow project is
    beyond the scope of this book, but one of the major things it helps with is to
    define a set of standardized data types that can be used from different tools
    and programming languages. Those data types also draw inspiration from databases;
    if using a database has already been a part of your analytics journey, then the
    Arrow types will likely be very familiar to you. Starting with version 2.0, pandas
    allows you to use Arrow for your data types.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一切发生的同时，pandas的原始创建者Wes McKinney正致力于Apache Arrow项目。完全解释Arrow项目超出了本书的范围，但它帮助的一个主要方面是定义一组可以在不同工具和编程语言之间使用的标准化数据类型。这些数据类型也受到数据库的启发；如果使用数据库已经是你分析旅程的一部分，那么Arrow类型对你来说可能非常熟悉。从版本2.0开始，pandas允许你使用Arrow作为数据类型。
- en: 'Despite support for pandas extension and Arrow data types, the default types
    from pandas were never changed, and in most cases still use NumPy. In the author’s
    opinion, this is very unfortunate; this chapter will introduce a rather opinionated
    take on how to best manage the type landscape, with the general guidance of the
    following:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管支持pandas扩展类型和Arrow数据类型，但pandas的默认类型从未改变，在大多数情况下仍然使用NumPy。作者认为这是非常遗憾的；本章将介绍一种较为主观的观点，如何最好地管理类型的领域，通常的指导原则如下：
- en: Use pandas extension types, when available
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在可用时，使用pandas扩展类型
- en: Use Arrow data types, when pandas extension types do not suffice
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当pandas扩展类型不足时，使用Arrow数据类型
- en: Use NumPy-backed data types
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用基于NumPy的数据类型
- en: This guidance may be controversial and can be scrutinized in extreme examples,
    but, for someone just starting with pandas, I believe this prioritization gives
    users the best balance of usability and performance, without requiring a deep
    understanding of how pandas works behind the scenes.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 这条指南可能会引发争议，并且在极端情况下可能会受到质疑，但对于刚接触pandas的人来说，我认为这种优先级设定为用户提供了最佳的可用性与性能平衡，无需深入了解pandas背后如何工作。
- en: The general layout of this chapter will introduce the pandas extension system
    for general use, before diving into the Arrow-type system for more advanced use
    cases. As we walk through these types, we will also highlight any special behavior
    that can be unlocked using *accessors*. Finally, we will talk about the historical
    NumPy-backed data types and take a deep dive into some of their fatal flaws, which
    I hope will convince you as to why you should limit your use of these types.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的总体结构将首先介绍pandas扩展系统的常规使用方法，然后再深入探讨Arrow类型系统以应对更复杂的使用案例。在我们介绍这些类型时，还将突出展示可以通过*访问器*解锁的特殊行为。最后，我们将讨论历史上的NumPy支持的数据类型，并深入探讨它们的一些致命缺陷，我希望这能说服你为什么应当限制使用这些类型。
- en: 'We are going to cover the following recipes in this chapter:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下几个实例：
- en: Integral types
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 整数类型
- en: Floating point types
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 浮点类型
- en: Boolean types
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 布尔类型
- en: String types
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 字符串类型
- en: Missing value handling
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缺失值处理
- en: Categorical types
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分类类型
- en: Temporal types – datetime
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 时间类型 – 日期时间
- en: Temporal types – timedelta
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 时间类型 – 时间差
- en: Temporal PyArrow types
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 时间类型 PyArrow
- en: PyArrow List types
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyArrow 列表类型
- en: PyArrow decimal types
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyArrow 十进制类型
- en: NumPy type system, the object type, and pitfalls
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NumPy 类型系统、对象类型及其陷阱
- en: Integral types
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 整数类型
- en: Integral types are the most basic type category. Much like the `int` type in
    Python or the `INTEGER` data type in a database, these can only represent whole
    numbers. Despite this limitation, integers are useful in a wide variety of applications,
    including but not limited to arithmetic, indexing, counting, and enumeration.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 整数类型是最基本的类型类别。类似于Python中的`int`类型或数据库中的`INTEGER`数据类型，这些类型仅能表示整数。尽管有这一限制，整数在各种应用中非常有用，包括但不限于算术运算、索引、计数和枚举。
- en: Integral types are heavily optimized for performance, tracing all the way from
    pandas down to the hardware on your computer. The integral types offered by pandas
    are significantly faster than the `int` type offered by the Python standard library,
    and proper usage of integral types is often a key enabler to high-performance,
    scalable reporting.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 整数类型经过高度优化，性能得到了极大的提升，从pandas一直追踪到你电脑上的硬件。pandas提供的整数类型比Python标准库中的`int`类型要快得多，正确使用整数类型通常是实现高性能、可扩展报告的关键。
- en: How to do it
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现
- en: 'Any valid sequence of integers can be passed as an argument to the `pd.Series`
    constructor. Paired with the `dtype=pd.Int64Dtype()` argument you will end up
    with a 64-bit integer data type:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 任何有效的整数序列都可以作为参数传递给`pd.Series`构造函数。搭配`dtype=pd.Int64Dtype()`参数，你将得到一个64位整数数据类型：
- en: '[PRE0]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'When storage and compute resources are not a concern, users often opt for 64-bit
    integers, but we could have also picked a smaller data type in our example:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 当存储和计算资源不成问题时，用户通常会选择64位整数，但在我们的示例中，我们也可以选择一个更小的数据类型：
- en: '[PRE2]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'With respect to missing values, pandas uses the `pd.NA` sentinel as its indicator,
    much like a database uses `NULL`:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 关于缺失值，pandas使用`pd.NA`作为指示符，类似于数据库使用`NULL`：
- en: '[PRE4]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'As a convenience, the `pd.Series` constructor will convert Python `None` values
    into `pd.NA` for you:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 为了方便，`pd.Series`构造函数会自动将Python中的`None`值转换为`pd.NA`：
- en: '[PRE6]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: There’s more…
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多……
- en: For users new to scientific computing, it is important to know that unlike Python’s
    `int`, which has no theoretical size limit, integers in pandas have lower and
    upper bounds. These limits are determined by the *width* and *signedness* of the
    integer.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 对于科学计算的新手用户来说，重要的是要知道，与Python的`int`类型不同，后者没有理论上的大小限制，pandas中的整数有上下限。这些限制由整数的*宽度*和*符号*决定。
- en: 'In most computing environments, users have integer widths of 8, 16, 32, and
    64\. Signedness can be either *signed* (i.e., the number can be positive or negative)
    or *unsigned* (i.e., the number must not be negative). Limits for each integral
    type are summarized in the following table:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数计算环境中，用户拥有的整数宽度为8、16、32和64。符号性可以是*有符号*（即，数字可以是正数或负数）或*无符号*（即，数字不得为负）。每种整数类型的限制总结在下表中：
- en: '| **Type** | **Lower Bound** | **Upper Bound** |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| **类型** | **下限** | **上限** |'
- en: '| --- | --- | --- |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| 8-bit width, signed | -128 | 127 |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| 8位宽度，有符号 | -128 | 127 |'
- en: '| 8-bit width, unsigned | 0 | 255 |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| 8位宽度，无符号 | 0 | 255 |'
- en: '| 16-bit width, signed | -32769 | 32767 |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| 16位宽度，有符号 | -32769 | 32767 |'
- en: '| 16-bit width, unsigned | 0 | 65535 |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| 16位宽度，无符号 | 0 | 65535 |'
- en: '| 32-bit width, signed | -2147483648 | 2147483647 |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| 32位宽度，有符号 | -2147483648 | 2147483647 |'
- en: '| 32-bit width, unsigned | 0 | 4294967295 |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| 32位宽度，无符号 | 0 | 4294967295 |'
- en: '| 64-bit width, signed | -(2**63) | 2**63-1 |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| 64位宽度，有符号 | -(2**63) | 2**63-1 |'
- en: '| 64-bit width, unsigned | 0 | 2**64-1 |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| 64位宽度，无符号 | 0 | 2**64-1 |'
- en: 'Table 3.1: Integral limits per signedness and width'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 表3.1：按符号性和宽度的整数极限
- en: The trade-off in these types is capacity versus memory usage – a 64-bit integral
    type requires 8x as much memory as an 8-bit integral type. Whether or not this
    is an issue depends entirely on the size of your dataset and the system on which
    you perform your analysis.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这些类型的权衡是容量与内存使用之间的平衡——64位整数类型需要的内存是8位整数类型的8倍。是否会成为问题完全取决于你的数据集的大小以及你执行分析的系统。
- en: 'Within the pandas extension type system, the `dtype=` argument for each of
    these follows the `pd.IntXXDtype()` form for signed integers and `pd.UIntXXDtype()`
    for unsigned integers, where `XX` refers to the bit width:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在 pandas 扩展类型系统中，每种类型的`dtype=`参数遵循`pd.IntXXDtype()`形式的有符号整数和`pd.UIntXXDtype()`形式的无符号整数，其中`XX`表示位宽：
- en: '[PRE8]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Floating point types
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 浮点类型
- en: Floating point types allow you to represent real numbers, not just integers.
    This allows you to work with a continuous and *theoretically* infinite set of
    values within your computations. It may come as no surprise that floating point
    calculations show up in almost every scientific computation, macro-financial analysis,
    machine learning algorithm, and so on.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 浮点类型允许你表示实数，而不仅仅是整数。这使得你可以在计算中处理一个连续的、*理论上*无限的值集。浮点计算几乎出现在每一个科学计算、宏观金融分析、机器学习算法等中，这一点并不令人惊讶。
- en: The emphasis on the word *theoretically*, however, is intentional and very important
    to understand. Floating point types still have boundaries, with real limitations
    being imposed by your computer hardware. In essence, the notion of being able
    to represent any number is an illusion. Floating point types are liable to lose
    precision and introduce rounding errors, especially as you work with more extreme
    values. As such, floating point types are not suitable when you need absolute
    precision (for that, you will want to reference the PyArrow decimal types introduced
    later in this chapter).
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，单词*理论上*的重点是故意强调的，并且对于理解非常重要。浮点类型仍然有边界，真实的限制是由你的计算机硬件所强加的。本质上，能够表示任何数字的概念是一种错觉。浮点类型容易失去精度并引入舍入误差，尤其是在处理极端值时。因此，当你需要绝对精度时，浮点类型并不适用（对于这种情况，你可以参考本章后面介绍的
    PyArrow 十进制类型）。
- en: Despite those limitations, it is rare that you actually would need absolute
    precision, so floating point types are the most commonly used data type to represent
    fractional numbers in general.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管存在这些限制，但实际上你很少需要绝对精度，因此浮点类型是最常用的数据类型，通常用于表示分数。
- en: How to do it
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作
- en: 'To construct floating point data, use `dtype=pd.Float64Dtype()`:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 要构建浮点数据，请使用`dtype=pd.Float64Dtype()`：
- en: '[PRE12]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Much like we saw with the integral types, the missing value indicator is `pd.NA`.
    The Python object `None` will be implicitly converted to this as a convenience:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 就像我们在整数类型中看到的那样，缺失值指示符是`pd.NA`。Python 对象`None`会被隐式地转换为此，以便于使用：
- en: '[PRE14]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: There’s more…
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多内容…
- en: By nature of their design, floating point values are *inexact*, and arithmetic
    with floating point values is slower than with integers. A deep dive into floating
    point arithmetic is beyond the scope of this book, but those interested can find
    much more information in the Python documentation.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 由于其设计的性质，浮点值是*不精确*的，且浮点值的算术运算比整数运算要慢。深入探讨浮点算术超出了本书的范围，但有兴趣的人可以在 Python 文档中找到更多信息。
- en: Python has a built-in `float` type that is somewhat of a misnomer because it
    is actually an IEEE 754 `double`. That standard and other languages like C/C++
    have distinct `float` and `double` types, with the former occupying 32 bits and
    the latter occupying 64 bits. To disambiguate these widths but stay consistent
    with Python terminology, pandas offers `pd.Float64Dtype()` (which some may consider
    a `double`) and `pd.Float32Dtype()` (which some may consider a `float`).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: Python 有一个内建的 `float` 类型，这个名字有些误导，因为它实际上是一个 IEEE 754 `double`。该标准和其他像 C/C++
    这样的语言有独立的 `float` 和 `double` 类型，前者占用 32 位，后者占用 64 位。为了澄清这些位宽的差异，同时保持与 Python 术语的一致性，pandas
    提供了 `pd.Float64Dtype()`（有些人认为它是 `double`）和 `pd.Float32Dtype()`（有些人认为它是 `float`）。
- en: 'Generally, unless your system is constrained on resources, users are recommended
    to use 64-bit floating point types. The odds of losing precision with 32-bit floating
    point types are much higher than with their respective 64-bit counterparts. In
    fact, 32-bit floats only offer between 6 and 9 decimal digits of precision, so
    the following expression will likely return `True` for equality comparison, even
    though we as humans can very clearly see the numbers are not the same:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，除非你的系统资源有限，否则建议用户使用 64 位浮动点类型。32 位浮动点类型丢失精度的概率远高于对应的 64 位类型。事实上，32 位浮动点数仅提供
    6 到 9 位小数的精度，因此，尽管我们可以很清楚地看到数字并不相同，下面的表达式仍然可能返回 `True` 作为相等比较的结果：
- en: '[PRE16]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: With a 64-bit floating point, you would at least get between 15 and 17 decimal
    digits of precision, so the values at which rounding errors occur are much more
    extreme.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 64 位浮动点数时，你至少能获得 15 到 17 位小数的精度，因此四舍五入误差发生的数值范围要远大于 32 位浮动点数。
- en: Boolean types
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 布尔类型
- en: A Boolean type represents a value that is either `True` or `False`. Boolean
    data types are useful to simply answer questions with a yes/no style of response
    and are also widely used in machine learning algorithms to convert categorical
    values into 1s and 0s (for `True` and `False`, respectively) that a computer can
    more easily digest (see also the *One-hot encoding with pd.get_dummies* recipe
    in *Chapter 5*, *Algorithms and How to Apply Them*).
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 布尔类型表示一个值，值只能是 `True` 或 `False`。布尔数据类型用于简单地回答是/否式的问题，也广泛用于机器学习算法中，将分类值转换为计算机可以更容易处理的
    1 和 0（分别代表 `True` 和 `False`）（参见《第 5 章，算法及其应用》中关于 *One-hot 编码与 pd.get_dummies*
    的部分）。
- en: How to do it
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现
- en: 'For Boolean, the appropriate `dtype=` argument is `pd.BooleanDtype`:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 对于布尔类型，适当的 `dtype=` 参数是 `pd.BooleanDtype`：
- en: '[PRE18]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[PRE19]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The pandas library will take care of implicitly converting values to their
    Boolean representation for you. Often, 0 and 1 are used in place of `False` and
    `True`, respectively:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: pandas 库会自动为你处理值到布尔值的隐式转换。通常，`False` 和 `True` 分别用 0 和 1 来代替：
- en: '[PRE20]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[PRE21]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Once again, `pd.NA` is the canonical missing indicator, although pandas will
    implicitly convert `None` to a missing value:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，`pd.NA` 是标准的缺失值指示符，尽管 pandas 会自动将 `None` 转换为缺失值：
- en: '[PRE22]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[PRE23]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: String types
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 字符串类型
- en: The string data type is the appropriate choice for any data that represents
    text. Unless you are working in a purely scientific domain, chances are that strings
    will be prevalent throughout the data that you use.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 字符串数据类型是表示文本数据的合适选择。除非你在纯粹的科学领域工作，否则字符串类型的值很可能会广泛存在于你使用的数据中。
- en: In this recipe, we will highlight some of the additional features pandas provides
    when working with string data, most notably through the `pd.Series.str` accessor.
    This accessor helps to change cases, extract substrings, match patterns, and more.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我们将重点介绍 pandas 在处理字符串数据时提供的一些附加功能，特别是通过 `pd.Series.str` 访问器。这个访问器有助于改变大小写、提取子字符串、匹配模式等等。
- en: As a technical note, before we jump into the recipe, strings starting in pandas
    3.0 will be significantly overhauled behind the scenes, enabling an implementation
    that is more type-correct, much faster, and requires far less memory than what
    was available in the pandas 2.x series. To make this possible in 3.0 and beyond,
    users are highly encouraged to install PyArrow alongside their pandas installation.
    For users looking for an authoritative reference on the why and how of strings
    in pandas 3.0, you may reference the PDEP-14 dedicated string data type.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个技术注解，在我们进入具体内容之前，从 pandas 3.0 开始，字符串类型将会在幕后进行重大改造，启用一种更符合类型的实现，速度更快，内存需求也比
    pandas 2.x 系列要低得多。为了在 3.0 及更高版本中实现这一点，强烈建议用户在安装 pandas 时同时安装 PyArrow。对于那些想了解 pandas
    3.0 中字符串处理的权威参考，可以查看 PDEP-14 专门针对字符串数据类型的文档。
- en: How to do it
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到这一点
- en: 'String data should be constructed with `dtype=pd.StringDtype()`:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 字符串数据应该使用 `dtype=pd.StringDtype()` 构造：
- en: '[PRE24]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '[PRE25]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'You have probably picked up by now that `pd.NA` is the missing indicator to
    use, but pandas will convert `None` implicitly for you:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经发现，`pd.NA` 是用于表示缺失值的标识符，但 pandas 会自动将 `None` 转换为 `pd.NA`：
- en: '[PRE26]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[PRE27]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'When working with a `pd.Series` containing string data, pandas will create
    what it refers to as the string *accessor* to help you unlock new methods that
    are tailored to strings. The string accessor is used via `pd.Series.str`, and
    helps you do things like report back the length of each string via `pd.Series.str.len`:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理包含字符串数据的 `pd.Series` 时，pandas 会创建一个称为字符串 *访问器* 的工具，帮助你解锁适用于字符串的新方法。字符串访问器通过
    `pd.Series.str` 使用，帮助你做诸如通过 `pd.Series.str.len` 获取每个字符串的长度等操作：
- en: '[PRE28]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '[PRE29]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'It may also be used to force everything to a particular case, like uppercase:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 它也可以用于强制将所有内容转换为特定的格式，例如大写：
- en: '[PRE30]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '[PRE31]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'It may also be used to force everything to lowercase:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 它也可以用于强制将所有内容转换为小写：
- en: '[PRE32]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '[PRE33]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'And even “title case” (i.e., the first letter only is capitalized, with everything
    else lower):'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 甚至可以是“标题大小写”（即只有第一个字母大写，其他字母小写）：
- en: '[PRE34]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '[PRE35]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '`pd.Series.str.contains` can be used to check for simple string containment:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '`pd.Series.str.contains` 可用于检查字符串是否包含特定内容：'
- en: '[PRE36]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '[PRE37]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'But it also has the flexibility to test for regular expressions with `regex=True`,
    akin to how `re.search` works in the standard library. The `case=False` argument
    will also turn the matching into a case-insensitive comparison:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 它还具有使用 `regex=True` 测试正则表达式的灵活性，类似于标准库中的 `re.search`。`case=False` 参数还会将匹配操作转换为不区分大小写的比较：
- en: '[PRE38]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '[PRE39]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Missing value handling
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 缺失值处理
- en: Before we continue with more data types, we must step back and talk about how
    pandas handles missing values. So far, things have been simple (we have only seen
    `pd.NA`), but as we explore more types we will see that the way pandas handles
    missing values is inconsistent, owing mostly to the history of how the library
    was developed. While it would be great to wave a magic wand and make any inconsistencies
    go away, in reality, they have existed and will continue to exist in production
    code bases for years to come. Having a high-level understanding of that evolution
    will help you write better pandas code, and hopefully convert the unaware to using
    the idioms we preach in this book.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续讨论更多数据类型之前，我们必须回过头来谈谈 pandas 如何处理缺失值。到目前为止，事情都很简单（我们只看到了 `pd.NA`），但随着我们探索更多类型，会发现
    pandas 处理缺失值的方式并不一致，这主要源于该库的开发历史。虽然能够挥动魔杖让任何不一致消失会很棒，但实际上，它们一直存在，并将在未来几年继续出现在生产代码库中。对这种发展过程有一个高层次的理解将帮助你编写更好的
    pandas 代码，并希望能将那些不了解的人引导到我们在本书中提倡的习惯用法中。
- en: How to do it
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到这一点
- en: The pandas library was originally built on top of NumPy, whose default data
    types do not support missing values. As such, pandas had to build its own missing
    value handling solution from scratch, and, for better or worse, decided that using
    the `np.nan` sentinel, which represents “not a number,” was useful enough to build
    off of.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: pandas 库最初是建立在 NumPy 之上的，而 NumPy 的默认数据类型不支持缺失值。因此，pandas 必须从零开始构建自己的缺失值处理解决方案，并且，无论好坏，它决定使用
    `np.nan` 哨兵值（代表“非数字”）作为其处理缺失值的工具。
- en: '`np.nan` itself is an implementation of the IEEE 754 standard’s “not a number”
    sentinel, a specification that only really had to do with floating point arithmetic.
    There is no such thing as “not a number” for integral data, which is why pandas
    implicitly converts a `pd.Series` like this:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '`np.nan` 本身是 IEEE 754 标准中的“非数字”哨兵值的实现，这一规范仅与浮点运算有关。对于整数数据来说并不存在“非数字”这一概念，这也是为什么
    pandas 会隐式地将像这样的 `pd.Series` 转换为：'
- en: '[PRE40]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '[PRE41]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'To a floating point data type after assigning a missing value:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在分配缺失值后，将数据转换为浮点数据类型：
- en: '[PRE42]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '[PRE43]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: As we discussed back in the *Floating point types* recipe, floating point values
    are slower than their integral counterparts. While integers can be expressed with
    8- and 16-bit widths, floating point types require 32 bits at a minimum. Even
    if you are using 32-bit width integers, using a 32-bit floating point value may
    not be viable without loss of precision, and with 64-bit integers, conversion
    simply may just have to lose precision. Generally, with a conversion from integral
    to floating point types, you have to sacrifice some combination of performance,
    memory usage, and/or precision, so such conversions are not ideal.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在 *浮动点类型* 配方中讨论的那样，浮动点值的计算速度比整型值要慢。虽然整数可以使用 8 位和 16 位宽度表示，但浮动点类型至少需要 32
    位。即使你使用的是 32 位宽度的整数，使用 32 位浮动点值可能会因为精度损失而不可行，而使用 64 位整数时，转换可能只能牺牲精度。一般来说，从整型到浮动点类型的转换，必须牺牲一定的性能、内存使用和/或精度，因此这类转换并不是理想的选择。
- en: Of course, pandas offers more than just integral and floating point types, so
    other types had to have custom missing value solutions attached to them. The default
    Boolean type gets converted to an `object` type, whose pitfalls will be explored
    in a recipe toward the end of this chapter. For datetime types, which we will
    discuss soon, pandas had to create a different `pd.NaT` sentinel altogether, as
    `np.nan` was technically not a feasible value to use for that data type. In essence,
    each data type in pandas could have its own indicator and implicit casting rules,
    which are hard to explain for beginners and seasoned pandas developers alike.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，pandas 不仅提供了整型和浮动点类型，因此其他类型也必须附加自定义的缺失值解决方案。默认的布尔类型会被转换为 `object` 类型，这一问题将在本章后面的一个配方中讨论。对于日期时间类型，我们很快会讨论，pandas
    必须创建一个完全不同的 `pd.NaT` 哨兵，因为 `np.nan` 在技术上并不适用于该数据类型。实质上，pandas 中的每个数据类型都有可能有自己的指示符和隐式类型转换规则，这对于初学者和有经验的
    pandas 开发者来说都很难解释清楚。
- en: The pandas library tried to solve these issues with the introduction of the
    *pandas extension types* back in the 0.24 release, and as we have seen with the
    recipes introduced so far, they do a good job of using just `pd.NA` without any
    implicit type conversion when missing values appear. However, the *pandas extension
    types* were introduced as opt-in types instead of being the default, so the custom
    solutions pandas developed to deal with missing values are still prevalent in
    code. Without having ever rectified these inconsistencies, it is unfortunately
    up to the user to understand the data types they choose and how different data
    types handle missing values.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: pandas 库通过引入 *pandas 扩展类型* 在 0.24 版本中尝试解决这些问题，正如我们迄今为止所看到的示例，它们在缺失值出现时仅使用 `pd.NA`
    并且没有进行隐式类型转换，做得相当出色。然而，*pandas 扩展类型* 被作为可选类型引入，而不是默认类型，因此 pandas 为处理缺失值所开发的自定义解决方案在代码中仍然占主导地位。遗憾的是，由于这些不一致性从未得到纠正，用户必须理解他们所选择的数据类型以及不同数据类型如何处理缺失值。
- en: 'Despite the inconsistencies, pandas fortunately offers a `pd.isna` function
    that can tell you whether an element in your array is missing or not. This works
    with the default data types:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管存在这些不一致之处，幸运的是 pandas 提供了一个 `pd.isna` 函数，可以告诉你数组中的某个元素是否缺失。它适用于默认数据类型：
- en: '[PRE44]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '[PRE45]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'It works just as well as it works with the *pandas extension types*:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 它与 *pandas 扩展类型* 同样有效：
- en: '[PRE46]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: '[PRE47]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: There’s more…
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多内容…
- en: Users should be aware that comparisons with `np.nan` and `pd.NA` do not behave
    in the same manner. For instance, `np.nan == np.nan` returns `False`, whereas
    `pd.NA == pd.NA` returns `pd.NA`. The former comparison is dictated by the terms
    of IEEE 757, whereas the `pd.NA` sentinel follows Kleene logic.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 用户应当注意，与 `np.nan` 和 `pd.NA` 进行比较时，它们的行为是不同的。例如，`np.nan == np.nan` 返回 `False`，而
    `pd.NA == pd.NA` 返回 `pd.NA`。前者的比较遵循 IEEE 757 标准，而 `pd.NA` 哨兵遵循 Kleene 逻辑。
- en: 'The way `pd.NA` works allows for much more expressive masking/selection in
    pandas. For instance, if you wanted to create a Boolean mask that also had missing
    values and use that to select values, `pd.BooleanDtype` allows you to do so, and
    naturally will only select records where the mask is `True`:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '`pd.NA` 的工作方式允许在 pandas 中进行更具表现力的掩码/选择。例如，如果你想创建一个也包含缺失值的布尔掩码并用它来选择值，`pd.BooleanDtype`
    使你能够做到这一点，并且自然地只会选择掩码为 `True` 的记录：'
- en: '[PRE48]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: '[PRE49]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'The equivalent operation without the Boolean extension type will raise an error:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有布尔扩展类型，相应的操作将引发错误：
- en: '[PRE50]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: '[PRE51]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'So, in code that does not use `pd.BooleanDtype`, you will likely see a lot
    of method calls that replace “missing” values with `False`, and use `pd.Series.astype`
    to try and cast back to a Boolean data type after the fill:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在不使用`pd.BooleanDtype`的代码中，你可能会看到许多方法调用，将“缺失”值替换为`False`，然后使用`pd.Series.astype`尝试在填充后将其转换回布尔数据类型：
- en: '[PRE52]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: '[PRE53]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: This is needlessly complex and inefficient. Using `pd.BooleanDtype` expresses
    the intent of your operations much more succinctly, letting you worry less about
    the nuances of pandas.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法不必要地复杂且低效。使用`pd.BooleanDtype`能更简洁地表达你的操作意图，让你更少担心pandas的细微差别。
- en: Categorical types
  id: totrans-152
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分类类型
- en: The main point of the categorical data type is to define an acceptable set of
    domain values that your `pd.Series` can contain. The *CSV - strategies for reading
    large files* recipe in *Chapter 4*, *The pandas I/O System*, will show you an
    example where this can result in significant memory savings, but generally, the
    use case here is to have pandas convert string values like `foo`, `bar`, and `baz`
    into codes `0`, `1`, and `2`, respectively, which can be much more efficiently
    stored.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 分类数据类型的主要目的是定义你的`pd.Series`可以包含的可接受域值集合。*第4章*中的*CSV - 读取大文件的策略*食谱将向你展示一个例子，其中这可能导致显著的内存节省，但通常这里的使用案例是让pandas将诸如`foo`、`bar`和`baz`等字符串值转换为代码`0`、`1`和`2`，这些代码可以更高效地存储。
- en: How to do it
  id: totrans-154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到
- en: So far, we have always opted for `pd.XXDtype()` as the `dtype=` argument, which
    still *could* work in the case of categorical data types, but unfortunately does
    not handle missing values consistently (see *There’s more…* for a deeper dive
    into this). Instead, we have to opt for one of two alternative approaches to creating
    a `pd.CategoricalDtype` with the `pd.NA` missing value indicator.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们总是选择`pd.XXDtype()`作为`dtype=`参数，这在分类数据类型的情况下仍然*可能*有效，但不幸的是，它没有一致地处理缺失值（详见*还有更多……*，深入探讨这个问题）。因此，我们必须选择两种替代方法中的一种，使用`pd.NA`缺失值指示符来创建`pd.CategoricalDtype`。
- en: 'With either approach, you will want to start with a `pd.Series` of data using
    `pd.StringDtype`:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 无论哪种方法，你都需要从一个使用`pd.StringDtype`的数据`pd.Series`开始：
- en: '[PRE54]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'From there, you may use `pd.DataFrame.astype` to cast this to categorical:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 从那里，你可以使用`pd.DataFrame.astype`将其转换为分类类型：
- en: '[PRE55]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: '[PRE56]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Or, if you need more control over the behavior of the categorical type, you
    may construct a `pd.CategoricalDtype` from your `pd.Series` of values and subsequently
    use that as the `dtype=` argument:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，如果你需要对分类类型的行为有更多控制，你可以从你的`pd.Series`值构造`pd.CategoricalDtype`，并随后将其用作`dtype=`参数：
- en: '[PRE57]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: '[PRE58]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: Both approaches get you to the same place, although the second approach trades
    some verbosity in constructing the `pd.CategoricalDtype` for finer-grained control
    over its behavior, as you will see throughout the remainder of this recipe.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 两种方法最终都能达到相同的目的，尽管第二种方法在构造`pd.CategoricalDtype`时牺牲了一些冗长性，以换取对其行为的更细致控制，正如你将在本食谱的其余部分看到的那样。
- en: 'Regardless of the approach you take, you should note that the values used at
    the time you construct your categorical `pd.Series` define the set of acceptable
    domain values that can be used. Given that we created our categorical type with
    values of `["foo", "bar", "baz"]`, subsequent assignment using any of these values
    is not a problem:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你采用何种方法，都应该注意，在构造分类类型`pd.Series`时所使用的值定义了可以使用的可接受域值的集合。鉴于我们用`["foo", "bar",
    "baz"]`创建了我们的分类类型，随后使用这些值进行赋值并没有问题：
- en: '[PRE59]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: '[PRE60]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'However, assigning a value outside of that domain will raise an error:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，赋值超出该域范围会引发错误：
- en: '[PRE61]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: '[PRE62]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: When explicitly constructing a `pd.CategoricalDtype`, you can assign a non-lexicographical
    order to your values via the `ordered=` argument. This is invaluable when working
    with *ordinal* data whose values are not naturally sorted the way you want by
    a computer algorithm.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 当显式构造`pd.CategoricalDtype`时，可以通过`ordered=`参数为值分配非字典序的顺序。这在处理*顺序*数据时非常宝贵，因为这些数据的值并不是按你想要的方式由计算机算法自然排序的。
- en: 'As a practical example, let’s consider the use case of clothing sizes. Naturally,
    small clothing is smaller than medium clothing, which is smaller than large clothing,
    and so on. By constructing `pd.CategoricalDtype` with the desired sizes in order
    and using `ordered=True`, pandas makes it very natural to compare sizes:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个实际例子，我们来考虑一下服装尺码的使用案例。自然，小号服装比中号服装小，中号服装比大号服装小，依此类推。通过按顺序构造`pd.CategoricalDtype`并使用`ordered=True`，pandas使得比较尺码变得非常自然：
- en: '[PRE63]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: '[PRE64]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'So, how does pandas make this so easy and efficient? The pandas library exposes
    a categorical accessor `pd.Series.cat`, which allows you to understand this more
    deeply. To dive further into this, let’s first create a `pd.Series` of categorical
    data where a given category is used more than once:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，pandas是如何做到这么简单高效的呢？pandas库暴露了一个类别访问器`pd.Series.cat`，它可以帮助你更深入地理解这一点。为了进一步探索，让我们首先创建一个`pd.Series`类别数据，其中某一类别被多次使用：
- en: '[PRE65]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: '[PRE66]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'If you inspect `pd.Series.cat.codes`, you will see a like-sized `pd.Series`,
    but the value `foo` is replaced with the number `0`, and the value `bar` is replaced
    with the value `1`:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你检查`pd.Series.cat.codes`，你会看到一个大小相同的`pd.Series`，但值`foo`被替换为数字`0`，值`bar`被替换为数字`1`：
- en: '[PRE67]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: '[PRE68]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'Separately, `pd.Series.cat.categories` will contain the values of each category,
    in order:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，`pd.Series.cat.categories`将包含每个类别的值，按顺序排列：
- en: '[PRE69]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: '[PRE70]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'Sparing some details around the internals, you can think of pandas as creating
    a dictionary of the form `{0: "foo", 1: "bar"}`. While it internally stores a
    `pd.Series` with values of `[0, 1, 0]`, when it comes time to display or access
    the values in any way, those values are used like keys in a dictionary to access
    the true value the end user would like to use. For this reason, you will often
    see the categorical data type described as a `dictionary` type (Apache Arrow,
    for one, uses the term dictionary).'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '除去一些内部细节，你可以将pandas视为创建了一个形式为`{0: "foo", 1: "bar"}`的字典。虽然它内部存储着一个值为`[0, 1,
    0]`的`pd.Series`，但当需要显示或以任何方式访问这些值时，这些值会像字典中的键一样被用来访问最终用户想要使用的真实值。因此，你会经常看到类别数据类型被描述为`字典`类型（例如，Apache
    Arrow就使用了“字典”这个术语）。'
- en: 'So, why bother? The process of *encoding* the labels into very small integer
    lookup values can have a significant impact on memory usage. Note the difference
    in memory usage between a normal string type:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，为什么要费心呢？将标签*编码*成非常小的整数查找值的过程，可能会对内存使用产生显著影响。请注意与普通字符串类型之间的内存使用差异：
- en: '[PRE71]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: '[PRE72]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'As compared to the equivalent categorical type, as follows:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 与等效的类别类型相比，如下所示：
- en: '[PRE73]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: '[PRE74]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: Your numbers may or may not exactly match the output of `.memory_usage()`, but
    you should at the very least see a rather drastic reduction when using the categorical
    data type.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 你的数字可能和`.memory_usage()`的输出完全不一致，但至少你应该会看到，在使用类别数据类型时，内存使用量有明显的减少。
- en: There’s more…
  id: totrans-192
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多…
- en: 'If using `dtype=pd.CategoricalDtype()` works directly, why would users not
    want to use that? Unfortunately, there is a rather large gap in the pandas API
    that prevents missing values from propagating with categorical types, which can
    unexpectedly introduce the `np.nan` missing value indicator we cautioned against
    using in the *Missing value handling* recipe. This can lead to very surprising
    behavior, even if you think you are properly using the `pd.NA` sentinel:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 如果直接使用`dtype=pd.CategoricalDtype()`有效，为什么用户不想使用它呢？不幸的是，pandas API中存在一个较大的空白，导致缺失值无法在类别类型之间传播，这可能会意外地引入我们在*缺失值处理*方法中警告过的`np.nan`缺失值指示符。这可能会导致非常令人惊讶的行为，即使你认为自己已经正确使用了`pd.NA`哨兵值：
- en: '[PRE75]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: '[PRE76]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'Notice in the preceding example that we tried to supply `pd.NA` but *still*
    got an `np.nan` in return? The explicit construction of a `pd.CategoricalDtype`
    from a `pd.Series` with `dtype=pd.StringDtype()` helps us avoid this very surprising
    behavior:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在前面的示例中，我们尝试提供`pd.NA`但*仍然*返回了`np.nan`？从`dtype=pd.StringDtype()`构造的`pd.Series`显式构建`pd.CategoricalDtype`帮助我们避免了这种令人惊讶的行为：
- en: '[PRE77]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: '[PRE78]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: If you find this behavior confusing or troublesome, trust that you are not alone.
    The light at the end of the tunnel may be PDEP-16, which aims to make `pd.NA`
    exclusively work as the missing value indicator. This would mean that you could
    safely use the `pd.CategoricalDtype()` constructor directly and follow all the
    same patterns you saw up until this point.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你发现这种行为令人困惑或麻烦，相信你并不孤单。隧道尽头的曙光可能是PDEP-16，它旨在让`pd.NA`仅作为缺失值指示符使用。这意味着你可以直接使用`pd.CategoricalDtype()`构造函数，并遵循直到此时为止所看到的所有相同模式。
- en: Unfortunately, this book was released around the time of the pandas 3.0 release
    and before PDEP-16 had been officially accepted, so it is hard to see into the
    future and advise when these inconsistencies in the API will go away. If you are
    reading this book a few years after publication, be sure to check back on the
    status of PDEP-16, as it may change the proper way to construct categorical data
    (alongside other data types).
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，这本书是在pandas 3.0发布的时候发布的，而且在PDEP-16被正式接受之前，因此很难预测这些API中的不一致何时会消失。如果你是在本书出版几年后阅读的，请务必查看PDEP-16的状态，因为它可能会改变构造分类数据的正确方式（以及其他数据类型）。
- en: Temporal types – datetime
  id: totrans-201
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 时间类型 – 日期时间
- en: The term *temporal* generally encompasses data types that concern themselves
    with dates and times, both in absolute terms as well as when measuring the duration
    between two different points in time. Temporal types are a key enabler for time-series-based
    analyses, which can be invaluable for trend detection and forecasting models.
    In fact, pandas was initially written at a capital management firm before being
    open sourced. Much of the time-series handling that was built into pandas has
    been influenced by real-world reporting needs from financial and economic industries.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: “时间”一词通常包含那些涉及日期和时间的数据类型，既包括绝对时间，也包括衡量两点之间持续时间的情况。时间类型是基于时间序列分析的关键支持，它对趋势检测和预测模型至关重要。事实上，pandas最初是在一家资本管理公司开发的，随后才开源。pandas内置的许多时间序列处理功能，受到金融和经济行业实际报告需求的影响。
- en: While the *Categorical types* section started to show some inconsistencies in
    the pandas type system API, temporal types take things a bit further. It would
    be reasonable to expect `pd.DatetimeDtype()` to exist as a constructor, but that
    is unfortunately not the case, at least as of writing. Additionally, and as mentioned
    in the *Missing value handling* recipe, temporal types, which were implemented
    before the pandas type extension system, use a different missing value indicator
    of `pd.NaT` (i.e., “not a time”).
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管*分类类型*部分开始展示了pandas类型系统API中的一些不一致，时间类型更是将这些问题推向了一个新的层次。合理的预期是，`pd.DatetimeDtype()`应该作为构造函数存在，但不幸的是，至少在写作时并非如此。此外，正如*缺失值处理*一节所提到的，时间类型是在pandas类型扩展系统之前实现的，使用了不同的缺失值指示符`pd.NaT`（即，“不是一个时间”）。
- en: Despite these issues, pandas offers a mind-boggling amount of advanced functionality
    for dealing with temporal data. *Chapter 9*, *Temporal Data Types and Algorithms*,
    will dive further into the applications of these data types; for now, we will
    just give a quick overview.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管存在这些问题，pandas仍然提供了令人惊讶的高级功能来处理时间数据。*第9章*，*时间数据类型与算法*，将深入探讨这些数据类型的应用；现在，我们只提供一个快速概述。
- en: How to do it
  id: totrans-205
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作
- en: Unlike many database systems that offer separate `DATE` and `DATETIME` or `TIMESTAMP`
    data types, pandas just has a single “datetime” type, which can be constructed
    via the `dtype=` argument of the `"datetime64[<unit>]"` form.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 与许多数据库系统提供单独的`DATE`和`DATETIME`或`TIMESTAMP`数据类型不同，pandas只有一种“日期时间”类型，可以通过`dtype=`参数的`"datetime64[<unit>]"`形式进行构造。
- en: 'Through much of the history of pandas, `ns` was the only accepted value for
    `<unit>`, so, let’s start with that for now (but check *There’s more…* for a more
    detailed explanation of the different values):'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 在pandas的历史大部分时间里，`ns`是唯一被接受的`<unit>`值，因此我们暂时从它开始（但请查看*还有更多……*，了解不同值的详细解释）：
- en: '[PRE79]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: '[PRE80]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: 'You can also construct a `pd.Series` of this data type using string arguments
    without time components:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以使用不包含时间组件的字符串参数构造一个`pd.Series`数据类型：
- en: '[PRE81]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: '[PRE82]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: 'The output of the preceding construction is slightly misleading; although the
    timestamps are not displayed, pandas still internally stores these values as datetimes,
    not dates. This might be problematic because there is no way to prevent subsequent
    timestamps from being stored in that `pd.Series`:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 上述构造的输出略显误导；虽然时间戳没有显示，pandas仍然将这些值内部存储为日期时间，而不是日期。这可能是一个问题，因为没有办法阻止后续的时间戳被存储在那个`pd.Series`中：
- en: '[PRE83]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: '[PRE84]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: If preserving dates is important, be sure to read the *Temporal PyArrow types*
    recipe later in this chapter.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 如果保留日期很重要，请务必稍后阅读本章中的*时间PyArrow类型*一节。
- en: Much like we saw back with string types, a `pd.Series` containing datetime data
    gets an *accessor*, which unlocks features to fluidly deal with dates and times.
    In this case, the accessor is `pd.Series.dt`.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 就像我们在字符串类型中看到的那样，包含日期时间数据的`pd.Series`会有一个*访问器*，它解锁了处理日期和时间的灵活功能。在这种情况下，访问器是`pd.Series.dt`。
- en: 'We can use this accessor to determine the year of each element in our `pd.Series`:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用这个访问器来确定`pd.Series`中每个元素的年份：
- en: '[PRE85]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: '[PRE86]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: '`pd.Series.dt.month` will yield the month:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '`pd.Series.dt.month`将返回月份：'
- en: '[PRE87]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: '[PRE88]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: '`pd.Series.dt.day` extracts the day of the month that the date falls on:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '`pd.Series.dt.day`提取日期所在的月日：'
- en: '[PRE89]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: '[PRE90]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: 'There is also a `pd.Series.dt.day_of_week` function, which will tell you the
    day of the week a date falls on. Monday starts at `0`, going up to `6`, meaning
    Sunday:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一个`pd.Series.dt.day_of_week`函数，它会告诉你一个日期是星期几。星期一为`0`，依此类推，直到`6`，表示星期日：
- en: '[PRE91]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: '[PRE92]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: If you’ve worked with timestamps before (especially in global organizations),
    another thing you may question is what time these values represent. 2024-01-03
    00:00:00 in New York City does not happen simultaneously with 2024-01-03 00:00:00
    in London, nor in Shanghai. So, how can we get a *true* representation of time?
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你曾经处理过时间戳（尤其是在全球化组织中），你可能会问这些值代表的是哪个时间。2024-01-03 00:00:00在纽约市发生的时间并不会与2024-01-03
    00:00:00在伦敦或上海同时发生。那么，我们如何获得*真正*的时间表示呢？
- en: The timestamps we have seen before are considered *timezone-naive*, (i.e., they
    do not clearly represent a single point in time anywhere on Earth). By contrast,
    you can make your timestamps *timezone-aware* by specifying a timezone as part
    of the `dtype=` argument.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前看到的时间戳被视为*无时区感知*的（即，它们并未清楚地表示地球上任何一个时刻）。相比之下，你可以通过在`dtype=`参数中指定时区，使你的时间戳变为*有时区感知*。
- en: 'Strangely enough, pandas does have a `pd.DatetimeTZDtype()`, so we can use
    that along with a `tz=` argument to specify the time zone in which our events
    are assumed to occur. For example, to make your timestamps represent UTC, you
    would do the following:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 奇怪的是，pandas 确实有一个`pd.DatetimeTZDtype()`，因此我们可以结合`tz=`参数来指定假定事件发生的时区。例如，要使你的时间戳表示为UTC，你可以执行以下操作：
- en: '[PRE93]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: '[PRE94]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: 'The string UTC represents an **Internet Assigned Numbers Authority** (**IANA**)
    timezone identifier. You can use any of those identifiers as the `tz=` argument,
    like `America/New_York`:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 字符串UTC表示的是**互联网号码分配局**（**IANA**）的时区标识符。你可以使用任何这些标识符作为`tz=`参数，如`America/New_York`：
- en: '[PRE95]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: '[PRE96]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE96]'
- en: 'In case you did not want to use a timezone identifier, you could alternatively
    specify a UTC offset:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你不想使用时区标识符，也可以选择指定一个UTC偏移量：
- en: '[PRE97]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE97]'
- en: '[PRE98]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE98]'
- en: 'The `pd.Series.dt` accessor we introduced in this recipe also has some nice
    features for working with timezones. For instance, if you are working with data
    that technically has no timezone associated with it, but you know in fact that
    the times represent US eastern time values, `pd.Series.dt.tz_localize` can help
    you express that:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本节中介绍的`pd.Series.dt`访问器也具有一些非常适用于时区操作的功能。例如，如果你正在处理的数据技术上没有时区信息，但你知道这些时间实际上代表的是美国东部时间，`pd.Series.dt.tz_localize`可以帮助你表达这一点：
- en: '[PRE99]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE99]'
- en: '[PRE100]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE100]'
- en: 'You can also use `pd.Series.dt.tz_convert` to translate times into another
    timezone:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以使用`pd.Series.dt.tz_convert`将时间转换为其他时区：
- en: '[PRE101]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE101]'
- en: '[PRE102]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE102]'
- en: 'You could even set all of your datetime data to midnight of whichever timezone
    it is in using `pd.Series.dt.normalize`. This can be useful if you don’t really
    care about the time component of your datetimes at all, and just want to treat
    them as dates, even though pandas does not offer a first-class `DATE` type:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 你甚至可以使用`pd.Series.dt.normalize`将所有的日期时间数据设定为所在时区的午夜。如果你根本不关心日期时间的时间部分，只想将其视为日期，这会很有用，尽管
    pandas 并没有提供一等的`DATE`类型：
- en: '[PRE103]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE103]'
- en: '[PRE104]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE104]'
- en: 'While we have so far pointed out many great features of pandas when working
    with datetime data, we should also take a look at one of the not-so-great aspects.
    Back in *Missing value handling*, we talked about how `np.nan` was historically
    used as a missing value indicator in pandas, even though more modern data types
    use `pd.NA`. With datetime data types, there is even yet another missing value
    indicator of `pd.NaT`:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们迄今为止提到的 pandas 在处理日期时间数据时有许多很棒的功能，但我们也应该看看其中一些并不那么出色的方面。在*缺失值处理*部分，我们讨论了如何使用`np.nan`作为
    pandas 中的缺失值指示符，尽管更现代的数据类型使用`pd.NA`。对于日期时间数据类型，还有一个额外的缺失值指示符`pd.NaT`：
- en: '[PRE105]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE105]'
- en: '[PRE106]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE106]'
- en: 'Again, this difference owes to the history that temporal types were offered
    before pandas introduced its extension types, and progress to move to one consistent
    missing value indicator has not fully occurred. Fortunately, functions like `pd.isna`
    will still correctly identify `pd.NaT` as a missing value:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，这个差异源于时间类型在 pandas 引入扩展类型之前就已经存在，而推动统一缺失值指示符的进展尚未完全实现。幸运的是，像`pd.isna`这样的函数仍然能够正确识别`pd.NaT`作为缺失值：
- en: '[PRE107]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE107]'
- en: '[PRE108]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE108]'
- en: There’s more…
  id: totrans-256
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多内容……
- en: 'The historical `ns` precision to pandas limited timestamps to a range that
    started slightly before 1677-09-21 and would go up to slightly after 2264-04-11\.
    Attempting to assign a datetime value outside of those bounds would raise an `OutOfBoundsDatetime`
    exception:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 历史上的`ns`精度限制了pandas中的时间戳范围，从稍早于1677-09-21开始，到稍晚于2264-04-11结束。尝试分配超出这些边界之外的日期时间值将引发`OutOfBoundsDatetime`异常：
- en: '[PRE109]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE109]'
- en: '[PRE110]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE110]'
- en: 'Starting with the 3.0 series of pandas, you could specify lower precisions
    like `s`, `ms`, or `us` to extend your range beyond those windows:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 从pandas的3.0系列开始，您可以指定低精度，如`s`、`ms`或`us`，以扩展您的时间范围超出这些窗口：
- en: '[PRE111]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE111]'
- en: '[PRE112]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE112]'
- en: Temporal types – timedelta
  id: totrans-263
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 时间类型 – timedelta
- en: Timedeltas are useful for measuring the *duration* between two points in time.
    This can be used to measure things like “on average, how much time passed between
    events X and Y,” which can be helpful to monitor and predict the turnaround time
    of certain processes and/or systems within your organization. Additionally, timedeltas
    can be used to manipulate your datetimes, making it easy to “add X number of days”
    or “subtract Y number of seconds” from your datetimes, all without having to dive
    into the minutiae of how your datetime objects are stored internally.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: Timedelta非常有用，用于测量两个时间点之间的*持续时间*。这可以用于测量诸如“平均来看，事件X和事件Y之间经过了多少时间”，这对于监控和预测组织内某些过程或系统的周转时间非常有帮助。此外，timedelta可以用于操作您的日期时间，轻松实现“添加X天”或“减去Y秒”，而无需深入了解日期时间对象在内部存储的细节。
- en: How to do it
  id: totrans-265
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作
- en: 'So far, we have introduced each data type by constructing it directly. However,
    the use cases where you would construct a timedelta `pd.Series` by hand are exceedingly
    rare. More commonly, you will come across this type as the result of an expression
    that subtracts two datetimes from one another:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经介绍了每种数据类型通过直接构建它。然而，手工构造timedelta `pd.Series`的用例非常罕见。更常见的情况是，您会遇到这种类型作为从一个日期时间减去另一个日期时间的表达式的结果：
- en: '[PRE113]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE113]'
- en: '[PRE114]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE114]'
- en: 'Within pandas, there is also the `pd.Timedelta` scalar, which can be used in
    expressions to add or subtract a duration to datetimes. For instance, the following
    code shows you how to add 3 days to every datetime in a `pd.Series`:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 在pandas中，还有`pd.Timedelta`标量，可以在表达式中用来添加或减去一个持续时间到日期时间。例如，以下代码展示了如何在`pd.Series`中的每个日期时间上添加3天：
- en: '[PRE115]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE115]'
- en: '[PRE116]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE116]'
- en: There’s more…
  id: totrans-272
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 更多信息…
- en: 'While not a common pattern, if you ever needed to manually construct a `pd.Series`
    of timedelta objects, you could do so using `dtype="timedelta[ns]"`:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然不是一个常见的模式，如果您曾经需要手动构建一个timedelta对象的`pd.Series`，您可以使用`dtype="timedelta[ns]"`来实现：
- en: '[PRE117]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE117]'
- en: '[PRE118]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE118]'
- en: 'What if we tried to create a timedelta of months? Let’s see:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们尝试创建一个以月为单位的timedelta呢？我们来看看：
- en: '[PRE119]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE119]'
- en: '[PRE120]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE120]'
- en: The reason pandas does not allow this is that timedelta represents a consistently
    measurable *duration*. While there are always 1,000 nanoseconds in a microsecond,
    1,000 microseconds in a millisecond, 1,000 milliseconds in a second, and so on,
    the number of days in a month is not consistent, ranging from 28-31\. Saying two
    events occurred *one month apart* does not appease the rather strict requirements
    of a timedelta to measure a finite duration of time passed between two points.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: pandas不允许这样做的原因是，timedelta表示一个一致可测量的*持续时间*。尽管微秒中始终有1,000纳秒，毫秒中始终有1,000微秒，秒中始终有1,000毫秒，等等，但一个月中的天数并不一致，从28到31不等。说两个事件*相隔一个月*并不能满足timedelta测量时间段的严格要求。
- en: If you need the ability to move dates by the calendar rather than by a finite
    duration, you can still use the `pd.DateOffset` object we will introduce in *Chapter
    9*, *Temporal Data Types and Algorithms*. While this does not have an associated
    data type to introduce in this chapter, the object itself can be a great complement
    or augmentation of the timedelta type, for analyses that don’t strictly think
    of time as a finite duration.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您需要按照日历而不是有限的持续时间来移动日期，您仍然可以使用我们在*第9章* *时间数据类型和算法*中将介绍的`pd.DateOffset`对象。虽然这本章节中没有相关的数据类型介绍，但该对象本身可以作为timedelta类型的一个很好的补充或增强，用于那些不严格将时间视为有限持续时间的分析。
- en: Temporal PyArrow types
  id: totrans-281
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: PyArrow的时间类型
- en: At this point, we have reviewed many of the “first-class” data types built into
    pandas, while highlighting some rough edges and inconsistencies that plague them.
    Despite those issues, the types baked into pandas can take you a long way in your
    data journey.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经回顾了内置到pandas中的许多“一流”数据类型，同时也突出了困扰它们的一些粗糙边缘和不一致性。尽管存在这些问题，内置到pandas中的这些类型可以在数据旅程中为您提供很长一段路。
- en: But there are still cases where the pandas types are not suitable, with a common
    case being interoperability with databases. Most databases have distinct `DATE`
    and `DATETIME` types, so the fact that pandas only offers a `DATETIME` type can
    be disappointing to users fluent in SQL.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 但仍然有一些情况下，pandas类型不适用，常见的情况是与数据库的互操作性。大多数数据库有独立的`DATE`和`DATETIME`类型，因此，pandas只提供`DATETIME`类型可能让熟悉SQL的用户感到失望。
- en: Fortunately, the Apache Arrow project defines a true `DATE` type. Starting in
    version 2.0, pandas users can start leveraging Arrow types exposed through the
    PyArrow library.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，Apache Arrow项目定义了一个真正的`DATE`类型。从2.0版本开始，pandas用户可以开始利用通过PyArrow库暴露的Arrow类型。
- en: How to do it
  id: totrans-285
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现
- en: 'To construct PyArrow types in pandas directly, you will always provide a `dtype=`
    argument of the `pd.ArrowDtype(XXX)` form, replacing `XXX` with the appropriate
    PyArrow type. The DATE type in PyArrow is called `pa.date32()`:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 要在pandas中直接构造PyArrow类型，你总是需要提供`dtype=`参数，格式为`pd.ArrowDtype(XXX)`，并用适当的PyArrow类型替换`XXX`。PyArrow中的DATE类型是`pa.date32()`：
- en: '[PRE121]'
  id: totrans-287
  prefs: []
  type: TYPE_PRE
  zh: '[PRE121]'
- en: '[PRE122]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE122]'
- en: 'The `pa.date32()` type can express a wider range of dates without having to
    toggle the precision:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: '`pa.date32()`类型可以表示更广泛的日期范围，而不需要切换精度：'
- en: '[PRE123]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE123]'
- en: '[PRE124]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE124]'
- en: The PyArrow library offers a timestamp type; however, the functionality is nearly
    identical to the datetime type you have already seen, so I would advise sticking
    with the datetime type built into pandas.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: PyArrow库提供了一个时间戳类型；然而，它的功能几乎与您已经看到的datetime类型完全相同，因此我建议使用pandas内置的datetime类型。
- en: PyArrow List types
  id: totrans-293
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: PyArrow列表类型
- en: 'Life would be so simple if every bit of data you came across fit nicely and
    squarely in a single location of `pd.DataFrame`, but inevitably you will run into
    issues where that is not the case. For a second, let’s imagine trying to analyze
    the employees that work at a company:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你遇到的每一项数据都恰好适合并整齐地放在`pd.DataFrame`的单个位置，生活将会变得如此简单，但不可避免地，你会遇到那些情况，数据并不总是这样。让我们先假设尝试分析一家公司中工作的员工：
- en: '[PRE125]'
  id: totrans-295
  prefs: []
  type: TYPE_PRE
  zh: '[PRE125]'
- en: '[PRE126]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE126]'
- en: This type of data is pretty easy to work with – you could easily add up or take
    the average number of years that each employee has of experience. But what if
    we also wanted to know that Bob and Michael reported to Alice while Janice reported
    to Jim?
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 这种类型的数据相对容易处理——你可以轻松地计算出每个员工的工作经验年数总和或平均值。但如果我们还想知道，Bob和Michael向Alice汇报，而Janice向Jim汇报怎么办？
- en: Our picturesque view of the world has suddenly come crashing down – how could
    we possibly express this in `pd.DataFrame`? If you are coming from a Microsoft
    Excel or SQL background, you may be tempted to think that you need to create a
    separate `pd.DataFrame` that holds the direct reports information. In pandas,
    we can express this more naturally using the PyArrow `pa.list_()` data type.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对世界的美好视角突然崩塌——我们怎么可能在`pd.DataFrame`中表达这个呢？如果你来自Microsoft Excel或SQL背景，你可能会想你需要创建一个单独的`pd.DataFrame`来存储直接汇报信息。但在pandas中，我们可以通过使用PyArrow的`pa.list_()`数据类型，更自然地表达这一点。
- en: How to do it
  id: totrans-299
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现
- en: 'When working with a `pa.list_()` type, you must *parametrize* it with the data
    type of elements it will contain. In our case, we want our list to contain values
    like `Bob` and `Janice`, so we will parametrize our `pa.list_()` type with the
    `pa.string()` type:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理`pa.list_()`类型时，您必须*参数化*它，指定它将包含的元素的数据类型。在我们的例子中，我们希望列表包含类似`Bob`和`Janice`这样的值，因此我们将使用`pa.string()`类型对`pa.list_()`类型进行参数化：
- en: '[PRE127]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE127]'
- en: '[PRE128]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE128]'
- en: There’s more…
  id: totrans-303
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多……
- en: 'When working with a `pd.Series` that has a PyArrow list type, you can unlock
    more features of the `pd.Series` by using the `.list` accessor. For instance,
    to see how many items a list contains, you can call `ser.list.len()`:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理具有PyArrow列表类型的`pd.Series`时，你可以通过使用`.list`访问器解锁更多`pd.Series`的功能。例如，要查看列表中包含多少项，可以调用`ser.list.len()`：
- en: '[PRE129]'
  id: totrans-305
  prefs: []
  type: TYPE_PRE
  zh: '[PRE129]'
- en: '[PRE130]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE130]'
- en: 'You can access the list item at a given position using the `.list[]` syntax:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用`.list[]`语法访问列表中给定位置的项：
- en: '[PRE131]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE131]'
- en: '[PRE132]'
  id: totrans-309
  prefs: []
  type: TYPE_PRE
  zh: '[PRE132]'
- en: 'There’s also a `.list.flatten` accessor, which could help you identify all
    of the employees who report to someone:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一个`.list.flatten`访问器，它可以帮助你识别所有向某人汇报的员工：
- en: '[PRE133]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE133]'
- en: '[PRE134]'
  id: totrans-312
  prefs: []
  type: TYPE_PRE
  zh: '[PRE134]'
- en: PyArrow decimal types
  id: totrans-313
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: PyArrow十进制类型
- en: When we looked at the *Floating point types* recipe earlier in this chapter,
    one of the important things we mentioned was that floating types are *inexact*.
    Most users of computer software can go their entire lives without knowing this
    fact, and in many cases, the lack of precision may be an acceptable trade-off
    to get the performance offered by floating point types. However, in some domains,
    it is **critical** to have extremely precise computations.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在本章早些时候查看 *浮点数类型* 示例时，我们提到的一个重要内容是浮点数类型是 *不精确的*。大多数计算机软件的用户可能一生都不会知道这个事实，在许多情况下，精度的缺失可能是为了获得浮点数类型所提供的性能而可接受的折衷。然而，在某些领域，**精确**的计算是至关重要的。
- en: As a simplistic example, let’s assume that a movie recommender system used floating
    point arithmetic to calculate the rating for a given movie as 4.3334 out of 5
    stars when it *really* should have been 4.33337\. Even if that rounding error
    was repeated a million times, it probably wouldn’t have a largely negative effect
    on civilization. On the flip side, a financial system that processes billions
    of transactions per day would find this rounding error to be unacceptable. Over
    time, that rounding error would accumulate into a rather large number in its own
    right.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 举一个简单的例子，假设一个电影推荐系统使用浮点算术计算某部电影的评分为 4.3334（满分 5 星），而实际应为 4.33337。即使这个四舍五入误差重复了一百万次，可能也不会对文明产生很大负面影响。相反，一个每天处理数十亿交易的金融系统会认为这种四舍五入误差是无法接受的。随着时间的推移，这个误差会积累成一个相当大的数值。
- en: Decimal data types are the solution to these problems. By giving up some performance
    that you would get with floating point calculations, decimal values allow you
    to achieve more precise calculations.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 十进制数据类型是解决这些问题的方案。通过放弃一些浮点计算带来的性能，十进制值允许你实现更精确的计算。
- en: How to do it
  id: totrans-317
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现
- en: The `pa.decimal128()` data type requires two arguments that define the *precision*
    and *scale* of the numbers you wish to represent. The precision dictates how many
    decimal digits can safely be stored, with the scale representing how many of those
    decimal digits may appear after a decimal point.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: '`pa.decimal128()` 数据类型需要两个参数，这两个参数定义了你希望表示的数字的 *精度* 和 *小数位*。精度决定了可以安全存储多少位小数，而小数位则表示这些小数位中有多少位出现在小数点后。'
- en: For example, with a *precision* of 5 and a *scale* of 2, you would be able to
    accurately represent numbers between -999.99 and 999.99, whereas a precision of
    5 with a scale of 0 gives you a range of -99999 to 99999\. In practice, the precision
    you choose will be much higher.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，当 *精度* 为 5 和 *小数位* 为 2 时，你可以准确表示 -999.99 到 999.99 之间的数字，而精度为 5 且小数位为 0 时，表示的范围是
    -99999 到 99999。实际上，你选择的精度通常会更高。
- en: 'Here’s an example of how to represent this in a `pd.Series`:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是如何在 `pd.Series` 中表示这一点的示例：
- en: '[PRE135]'
  id: totrans-321
  prefs: []
  type: TYPE_PRE
  zh: '[PRE135]'
- en: '[PRE136]'
  id: totrans-322
  prefs: []
  type: TYPE_PRE
  zh: '[PRE136]'
- en: 'Pay special attention to the fact that we provided our data as strings. If
    we had tried to provide that as floating point data to begin with, we would have
    immediately seen a loss in precision:'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 特别需要注意的是，我们将数据提供为字符串。如果我们一开始尝试提供浮点数数据，我们会立即看到精度丢失：
- en: '[PRE137]'
  id: totrans-324
  prefs: []
  type: TYPE_PRE
  zh: '[PRE137]'
- en: '[PRE138]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE138]'
- en: This happens because Python itself uses floating point storage for real numbers
    by default, so the rounding error happens the moment the language runtime tries
    to interpret the numbers you have provided. Depending on your platform, you may
    even find that `99999999.9999999999 == 100000000.0` returns `True`. To a human
    reader, that is obviously not true, but the limits of computer storage prevent
    the language from being able to discern that.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 这发生是因为 Python 默认使用浮点数存储实数，因此当语言运行时尝试解释你提供的数字时，四舍五入误差就会出现。根据你的平台，你甚至可能会发现 `99999999.9999999999
    == 100000000.0` 返回 `True`。对于人类读者来说，这显然不是真的，但计算机存储的限制使得语言无法辨别这一点。
- en: 'Python’s solution to this issue is the `decimal` module, which ensures rounding
    errors do not occur:'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: Python 解决这个问题的方法是使用 `decimal` 模块，确保不会发生四舍五入误差：
- en: '[PRE139]'
  id: totrans-328
  prefs: []
  type: TYPE_PRE
  zh: '[PRE139]'
- en: '[PRE140]'
  id: totrans-329
  prefs: []
  type: TYPE_PRE
  zh: '[PRE140]'
- en: 'While still giving you proper arithmetic, as follows:'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，你仍然可以进行正确的算术运算，如下所示：
- en: '[PRE141]'
  id: totrans-331
  prefs: []
  type: TYPE_PRE
  zh: '[PRE141]'
- en: '[PRE142]'
  id: totrans-332
  prefs: []
  type: TYPE_PRE
  zh: '[PRE142]'
- en: '`decimal.Decimal` objects are also valid arguments when constructing the PyArrow
    decimal type:'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: '`decimal.Decimal` 对象在构建 PyArrow 十进制类型时也是有效的参数：'
- en: '[PRE143]'
  id: totrans-334
  prefs: []
  type: TYPE_PRE
  zh: '[PRE143]'
- en: '[PRE144]'
  id: totrans-335
  prefs: []
  type: TYPE_PRE
  zh: '[PRE144]'
- en: There’s more…
  id: totrans-336
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多内容……
- en: 'The `pa.decimal128` data type can only support up to 38 significant decimal
    digits. If you need more than that, the Arrow ecosystem also provides a `pa.decimal256`
    data type:'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: '`pa.decimal128` 数据类型最多支持 38 位有效数字。如果你需要更高的精度，Arrow 生态系统还提供了 `pa.decimal256`
    数据类型：'
- en: '[PRE145]'
  id: totrans-338
  prefs: []
  type: TYPE_PRE
  zh: '[PRE145]'
- en: '[PRE146]'
  id: totrans-339
  prefs: []
  type: TYPE_PRE
  zh: '[PRE146]'
- en: Just be aware that this will consume twice as much memory as the `pa.decimal128`
    data type, with potentially even slower calculation times.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 只需注意，这将消耗是 `pa.decimal128` 数据类型两倍的内存，且可能会有更慢的计算时间。
- en: NumPy type system, the object type, and pitfalls
  id: totrans-341
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: NumPy 类型系统、对象类型和陷阱
- en: As mentioned back in the introduction to this chapter, at least in the 2.x and
    3.x series, pandas still defaults to types that are sub-optimal for general data
    analysis. You will undoubtedly come across them in code from peer or online snippets,
    however, so understanding how they work, their pitfalls, and how to avoid them
    will be important for years to come.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 如本章介绍所提到的，至少在 2.x 和 3.x 系列中，pandas 仍然默认使用对一般数据分析并不理想的数据类型。然而，你无疑会在同伴的代码或在线代码片段中遇到它们，因此理解它们的工作原理、潜在的陷阱以及如何避免它们，将在未来几年中变得非常重要。
- en: How to do it
  id: totrans-343
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到这一点
- en: 'Let’s look at the default construction of a `pd.Series` from a sequence of
    integers:'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下从整数序列构造 `pd.Series` 的默认方式：
- en: '[PRE147]'
  id: totrans-345
  prefs: []
  type: TYPE_PRE
  zh: '[PRE147]'
- en: '[PRE148]'
  id: totrans-346
  prefs: []
  type: TYPE_PRE
  zh: '[PRE148]'
- en: 'From this argument, pandas gave us back a `pd.Series` with an `int64` data
    type. That seems normal, so what is the big deal? Well, let’s go ahead and see
    what happens when you introduce missing values:'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个参数开始，pandas 给我们返回了一个 `pd.Series`，它的 `dtype` 是 `int64`。这看起来很正常，那到底有什么问题呢？好吧，让我们看看引入缺失值时会发生什么：
- en: '[PRE149]'
  id: totrans-348
  prefs: []
  type: TYPE_PRE
  zh: '[PRE149]'
- en: '[PRE150]'
  id: totrans-349
  prefs: []
  type: TYPE_PRE
  zh: '[PRE150]'
- en: 'Huh? We provided integer data but now we got back a floating point type. Surely
    specifying the `dtype=` argument will help us fix this:'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 嗯？我们提供了整数数据，但现在却得到了浮点类型。指定 `dtype=` 参数肯定能帮我们解决这个问题吧：
- en: '[PRE151]'
  id: totrans-351
  prefs: []
  type: TYPE_PRE
  zh: '[PRE151]'
- en: '[PRE152]'
  id: totrans-352
  prefs: []
  type: TYPE_PRE
  zh: '[PRE152]'
- en: 'Try as hard as you might, you simply *cannot* mix missing values with the NumPy
    integer data type, which pandas returns by default. A common solution to this
    pattern is to start filling missing values with another value like `0` before
    casting back to an actual integer data type with `pd.Series.astype`:'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你多么努力，你就是*不能*将缺失值与 pandas 默认返回的 NumPy 整数数据类型混合。解决这个模式的常见方法是，在使用 `pd.Series.astype`
    转回实际整数数据类型之前，先用另一个值（如 `0`）填充缺失值：
- en: '[PRE153]'
  id: totrans-354
  prefs: []
  type: TYPE_PRE
  zh: '[PRE153]'
- en: '[PRE154]'
  id: totrans-355
  prefs: []
  type: TYPE_PRE
  zh: '[PRE154]'
- en: That solves the problem of getting us to a proper integer type, but it had to
    change the data to get us there. Whether this matters is a context-dependent issue;
    some users may be OK with treating missing values as 0 if all they wanted to do
    was *sum* the column, but that same user might not be happy with the new *count*
    and *average* that gets produced by that data.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 这解决了让我们得到正确整数类型的问题，但它必须改变数据才能做到这一点。是否在意这个变化是一个依赖于上下文的问题；有些用户如果只是想对这一列进行*求和*，可能会接受将缺失值当作
    0 处理，但同样的用户可能不满意这种数据所产生的新*计数*和*平均值*。
- en: 'Note the difference between this `fillna` approach and using the pandas extension
    types introduced at the start of this chapter:'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意此`fillna`方法与本章开始时介绍的 pandas 扩展类型之间的区别：
- en: '[PRE155]'
  id: totrans-358
  prefs: []
  type: TYPE_PRE
  zh: '[PRE155]'
- en: '[PRE156]'
  id: totrans-359
  prefs: []
  type: TYPE_PRE
  zh: '[PRE156]'
- en: '[PRE157]'
  id: totrans-360
  prefs: []
  type: TYPE_PRE
  zh: '[PRE157]'
- en: '[PRE158]'
  id: totrans-361
  prefs: []
  type: TYPE_PRE
  zh: '[PRE158]'
- en: 'Not only do we get different results, but the approach where we do not use
    `dtype=pd.Int64Dtype()` takes longer to compute:'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 不仅得到了不同的结果，而且我们不使用 `dtype=pd.Int64Dtype()` 的方法需要更长时间来计算：
- en: '[PRE159]'
  id: totrans-363
  prefs: []
  type: TYPE_PRE
  zh: '[PRE159]'
- en: '[PRE160]'
  id: totrans-364
  prefs: []
  type: TYPE_PRE
  zh: '[PRE160]'
- en: '[PRE161]'
  id: totrans-365
  prefs: []
  type: TYPE_PRE
  zh: '[PRE161]'
- en: '[PRE162]'
  id: totrans-366
  prefs: []
  type: TYPE_PRE
  zh: '[PRE162]'
- en: This is perhaps not surprising when you consider the number of steps you had
    to go through to just get integers instead of floats.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 当你考虑到你必须经历的步骤，只为了获得整数而非浮点数时，这也许并不令人惊讶。
- en: 'When you look at the historical Boolean data type in pandas, things get even
    stranger. Let’s once again start with the seemingly sane base case:'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 当你查看 pandas 中历史上的布尔数据类型时，事情变得更加怪异。让我们再次从看似合理的基本案例开始：
- en: '[PRE163]'
  id: totrans-369
  prefs: []
  type: TYPE_PRE
  zh: '[PRE163]'
- en: '[PRE164]'
  id: totrans-370
  prefs: []
  type: TYPE_PRE
  zh: '[PRE164]'
- en: 'Let’s throw a wrench into things with a missing value:'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过引入缺失值来打乱一些事情：
- en: '[PRE165]'
  id: totrans-372
  prefs: []
  type: TYPE_PRE
  zh: '[PRE165]'
- en: '[PRE166]'
  id: totrans-373
  prefs: []
  type: TYPE_PRE
  zh: '[PRE166]'
- en: 'This is the first time we have seen the `object` data type. Sparing some technical
    details, you should trust that the `object` data type is one of the worst data
    types to use in pandas. Essentially *anything* goes with an `object` data type;
    it completely disallows the type system from enforcing anything about your data.
    Even though we just want to store `True=/=False` values where some may be missing,
    really any valid value can now be placed alongside those values:'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们第一次看到 `object` 数据类型。撇开一些技术细节，你应该相信 `object` 数据类型是 pandas 中最差的数据类型之一。基本上，`object`
    数据类型几乎可以存储任何内容；它完全禁止类型系统对你的数据进行任何强制要求。即使我们只是想存储 `True` 和 `False` 的值，其中一些可能是缺失的，实际上任何有效的值都可以与这些值一起存储：
- en: '[PRE167]'
  id: totrans-375
  prefs: []
  type: TYPE_PRE
  zh: '[PRE167]'
- en: '[PRE168]'
  id: totrans-376
  prefs: []
  type: TYPE_PRE
  zh: '[PRE168]'
- en: 'All of this nonsense can be avoided by using `pd.BooleanDtype`:'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些混乱都可以通过使用 `pd.BooleanDtype` 来避免：
- en: '[PRE169]'
  id: totrans-378
  prefs: []
  type: TYPE_PRE
  zh: '[PRE169]'
- en: '[PRE170]'
  id: totrans-379
  prefs: []
  type: TYPE_PRE
  zh: '[PRE170]'
- en: 'Another rather unfortunate fact of the default pandas implementation (at least
    in the 2.x series) is that the `object` data type is used for strings:'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个相当不幸的事实是，默认的 pandas 实现（至少在 2.x 系列中）将 `object` 数据类型用于字符串：
- en: '[PRE171]'
  id: totrans-381
  prefs: []
  type: TYPE_PRE
  zh: '[PRE171]'
- en: '[PRE172]'
  id: totrans-382
  prefs: []
  type: TYPE_PRE
  zh: '[PRE172]'
- en: 'Once again, there is nothing there that strictly enforces we have string data:'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，这里并没有严格强制要求我们必须拥有字符串数据：
- en: '[PRE173]'
  id: totrans-384
  prefs: []
  type: TYPE_PRE
  zh: '[PRE173]'
- en: '[PRE174]'
  id: totrans-385
  prefs: []
  type: TYPE_PRE
  zh: '[PRE174]'
- en: 'With `pd.StringDtype()`, that type of assignment would raise an error:'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`pd.StringDtype()`时，这种类型的赋值将会引发错误：
- en: '[PRE175]'
  id: totrans-387
  prefs: []
  type: TYPE_PRE
  zh: '[PRE175]'
- en: '[PRE176]'
  id: totrans-388
  prefs: []
  type: TYPE_PRE
  zh: '[PRE176]'
- en: There’s more…
  id: totrans-389
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多……
- en: 'We have talked at length in this recipe about how the lack of type enforcement
    with the `object` data type is a problem. On the flip side, there are some use
    cases where having that flexibility can be helpful, especially when interacting
    with Python objects where you cannot make assertions about the data up front:'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们详细讨论了`object`数据类型缺乏类型强制的问题。另一方面，在某些使用场景中，拥有这种灵活性可能是有帮助的，尤其是在与Python对象交互时，在这种情况下，您无法事先对数据做出断言：
- en: '[PRE177]'
  id: totrans-391
  prefs: []
  type: TYPE_PRE
  zh: '[PRE177]'
- en: '[PRE178]'
  id: totrans-392
  prefs: []
  type: TYPE_PRE
  zh: '[PRE178]'
- en: If you have worked with a tool like Microsoft Excel in the past, the idea that
    you can put any value anywhere in almost any format may not seem that novel. On
    the flip side, if your experience is more based on using SQL databases, the idea
    that you could just load *any* data may be a foreign concept.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您曾经使用过类似Microsoft Excel的工具，您可能会觉得将任何值以几乎任何格式放入任何地方的想法并不新奇。另一方面，如果您的经验更多来自于使用SQL数据库，您可能会觉得将*任何*数据加载进来是一个陌生的概念。
- en: 'In the realm of data processing, there are two major approaches: **extract,
    transform, load** (**ETL**) and **extract, load, transform** (**ELT**). ETL requires
    you to *transform* your data before you can load it into a data analysis tool,
    meaning all of the cleansing has to be done upfront in another tool.'
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据处理领域，主要有两种方法：**提取、转换、加载**（**ETL**）和**提取、加载、转换**（**ELT**）。ETL要求您在将数据加载到数据分析工具之前先进行*转换*，这意味着所有清理工作必须提前在其他工具中完成。
- en: The ELT approach allows you to just load the data first and deal with cleaning
    it up later; the `object` data type enables you to use the ELT approach in pandas,
    should you so choose.
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: ELT方法允许您先加载数据，稍后再处理清理工作；`object`数据类型使您能够在pandas中使用ELT方法，如果您选择这样做的话。
- en: With that said, I would generally advise that you strictly use the `object`
    data type as a `staging` data type before transforming it into a more concrete
    type. By avoiding the `object` data type, you will achieve much higher performance,
    have a better understanding of your data, and be able to write cleaner code.
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，我通常建议您将`object`数据类型严格用作`staging`数据类型，然后再将其转换为更具体的类型。通过避免使用`object`数据类型，您将获得更高的性能，更好地理解您的数据，并能够编写更简洁的代码。
- en: 'As a final note in this chapter, it is pretty easy to control data types when
    you work with a `pd.Series` constructor directly with the `dtype=` argument. While
    the `pd.DataFrame` also has a `dtype=` argument, it does not allow you to specify
    types per column, meaning you usually will end up with the historical NumPy data
    types when creating a `pd.DataFrame`:'
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的最后一点，当您直接使用`pd.Series`构造函数并指定`dtype=`参数时，控制数据类型是相当容易的。虽然`pd.DataFrame`也有`dtype=`参数，但它不允许您为每一列指定类型，这意味着您通常会在创建`pd.DataFrame`时使用历史的NumPy数据类型：
- en: '[PRE179]'
  id: totrans-398
  prefs: []
  type: TYPE_PRE
  zh: '[PRE179]'
- en: '[PRE180]'
  id: totrans-399
  prefs: []
  type: TYPE_PRE
  zh: '[PRE180]'
- en: 'Checking `pd.DataFrame.dtypes` will help us confirm this:'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 检查`pd.DataFrame.dtypes`将帮助我们确认这一点：
- en: '[PRE181]'
  id: totrans-401
  prefs: []
  type: TYPE_PRE
  zh: '[PRE181]'
- en: '[PRE182]'
  id: totrans-402
  prefs: []
  type: TYPE_PRE
  zh: '[PRE182]'
- en: 'To get us into using the more desirable pandas extension types, we could either
    explicitly use the `pd.DataFrame.astype` method:'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让我们开始使用更理想的pandas扩展类型，我们可以显式使用`pd.DataFrame.astype`方法：
- en: '[PRE183]'
  id: totrans-404
  prefs: []
  type: TYPE_PRE
  zh: '[PRE183]'
- en: '[PRE184]'
  id: totrans-405
  prefs: []
  type: TYPE_PRE
  zh: '[PRE184]'
- en: 'Or, we could use the `pd.DataFrame.convert_dtypes` method with `dtype_backend="numpy_nullable"`:'
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，我们可以使用`pd.DataFrame.convert_dtypes`方法并设置`dtype_backend="numpy_nullable"`：
- en: '[PRE185]'
  id: totrans-407
  prefs: []
  type: TYPE_PRE
  zh: '[PRE185]'
- en: '[PRE186]'
  id: totrans-408
  prefs: []
  type: TYPE_PRE
  zh: '[PRE186]'
- en: The term `numpy_nullable` is a bit of a misnomer at this point in the history
    of pandas, but, as we mentioned back in the introduction, it was the original
    name for what later became referred to as the pandas extension type system.
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: '`numpy_nullable`这个术语在pandas的历史上有些不准确，但正如我们在介绍中提到的，它是后来被称为pandas扩展类型系统的原始名称。'
- en: Join our community on Discord
  id: totrans-410
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们的Discord社区
- en: 'Join our community’s Discord space for discussions with the authors and other
    readers:'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 加入我们社区的Discord空间，与作者和其他读者进行讨论：
- en: '[https://packt.link/pandas](https://packt.link/pandas)'
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/pandas](https://packt.link/pandas)'
- en: '![](img/QR_Code5040900042138312.png)'
  id: totrans-413
  prefs: []
  type: TYPE_IMG
  zh: '![](img/QR_Code5040900042138312.png)'
- en: Leave a Review!
  id: totrans-414
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 留下评论！
- en: Thank you for purchasing this book from Packt Publishing—we hope you enjoy it!
    Your feedback is invaluable and helps us improve and grow. Once you’ve completed
    reading it, please take a moment to leave an Amazon review; it will only take
    a minute, but it makes a big difference for readers like you.
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢您从Packt出版购买本书——我们希望您喜欢它！您的反馈非常宝贵，能够帮助我们改进和成长。读完本书后，请花一点时间在亚马逊上留下评论；这只需要一分钟，但对像您这样的读者来说，意义重大。
- en: Scan the QR code below to receive a free ebook of your choice.
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 扫描下面的二维码，领取您选择的免费电子书。
- en: '[https://packt.link/NzOWQ](Chapter_3.xhtml)'
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/NzOWQ](Chapter_3.xhtml)'
- en: '![](img/QR_Code1474021820358918656.png)'
  id: totrans-418
  prefs: []
  type: TYPE_IMG
  zh: '![](img/QR_Code1474021820358918656.png)'
