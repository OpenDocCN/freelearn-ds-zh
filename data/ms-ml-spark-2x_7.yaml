- en: Graph Analytics with GraphX
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GraphX的图形分析
- en: In our interconnected world, graphs are omnipresent. The **World Wide Web**
    (**WWW**) is just one example of a complex structure that we can consider a graph,
    in which web pages represent entities that are connected by incoming and outgoing
    links between them. In Facebook’s social graph, many millions of users form a
    network, connecting friends around the globe. Many other important structures
    that we see and can collect data for today come equipped with a natural graph
    structure; that is, they can, at a very basic level, be understood as a collection
    of *vertices* that are connected to each other in a certain way by what we call *edges*.
    Stated in this generality, this observation reflects how ubiquitous graphs are.
    What makes it valuable is that the graphs are well-studied structures and that
    there are many algorithms available that allow us to gain important insights about
    what these graphs represent.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们相互连接的世界中，图形是无处不在的。**万维网**（**WWW**）只是一个我们可以考虑为图形的复杂结构的例子，其中网页代表着通过它们之间的传入和传出链接连接的实体。在Facebook的社交图中，成千上万的用户形成一个网络，连接着全球的朋友。我们今天看到并且可以收集数据的许多其他重要结构都具有自然的图形结构；也就是说，它们可以在非常基本的层面上被理解为一组通过我们称之为*边*的方式相互连接的*顶点*的集合。以这种一般性的方式陈述，这一观察反映了图形是多么普遍。它的价值在于图形是经过深入研究的结构，并且有许多可用的算法可以让我们获得关于这些图形代表的重要见解。
- en: 'Spark’s GraphX library is a natural entry point to study graphs at scale. Leveraging
    RDDs from the Spark core to encode vertices and edges, we can do graph analytics
    on vast amounts of data with GraphX. To give an overview, you will learn about
    the following topics in this chapter:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: Spark的GraphX库是研究大规模图形的自然入口点。利用Spark核心中的RDD来编码顶点和边，我们可以使用GraphX对大量数据进行图形分析。在本章中，您将学习以下主题：
- en: Basic graph properties and important graph operations
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基本图形属性和重要的图形操作
- en: How GraphX represents property graphs and how to work with them
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GraphX如何表示属性图形以及如何处理它们
- en: Loading graph data in various ways and generating synthetic graph data to experiment
    with
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以各种方式加载图形数据并生成合成图形数据以进行实验
- en: Essential graph properties by using GraphX’s core engine
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用GraphX的核心引擎来实现基本图形属性
- en: Visualizing graphs with an open source tool called Gephi
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用名为Gephi的开源工具可视化图形
- en: Implementing efficient graph-parallel algorithms using two of GraphX’s key APIs.
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用GraphX的两个关键API实现高效的图形并行算法。
- en: Using GraphFrames, an extension of DataFrames to graphs, and studying graphs
    using an elegant query language
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用GraphFrames，这是DataFrame到图形的扩展，并使用优雅的查询语言研究图形
- en: Running important graph algorithms available in GraphX on a social graph, consisting
    of retweets and a graph of actors appearing in movies together
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在社交图上运行GraphX中可用的重要图形算法，包括转发和一起出现在电影中的演员的图形
- en: Basic graph theory
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基本图形理论
- en: Before diving into Spark GraphX and its applications, we will first define graphs
    on a basic level and explain what properties they may come with and what structures
    are worth studying in our context. Along the way of introducing these properties,
    we will give more concrete examples of graphs that we consider in everyday life.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入研究Spark GraphX及其应用之前，我们将首先在基本层面上定义图形，并解释它们可能具有的属性以及在我们的上下文中值得研究的结构。在介绍这些属性的过程中，我们将给出更多我们在日常生活中考虑的图形的具体例子。
- en: Graphs
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图形
- en: 'To formalize the notion of a graph briefly sketched in the introduction, on
    a purely mathematical level, a graph *G = (V, E)* can be described as a pair of
    *vertices* V and *edges* E, as follows:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简要地形式化引言中简要概述的图形概念，在纯数学层面上，图形*G = (V, E)*可以描述为一对*顶点*V和*边*E，如下所示：
- en: '*V = {v[1], ..., v[n]}*'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '*V = {v[1], ..., v[n]}*'
- en: '*E = {e[1], ..., e[m]}*'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '*E = {e[1], ..., e[m]}*'
- en: 'We call the element *v[i]* in V a vertex and *e[i]* in E an edge, where each
    edge connecting two vertices *v[1] *and *v[2]* is, in fact, just a pair of vertices,
    that is, *e[i] = (v[1], v[2])*. Let''s construct a simple graph consisting of
    five vertices and six edges, as specified by the following graph data:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们称V中的元素*v[i]*为一个顶点，称E中的*e[i]*为一条边，其中连接两个顶点*v[1]*和*v[2]*的每条边实际上只是一对顶点，即*e[i]
    = (v[1], v[2])*。让我们构建一个由五个顶点和六条边组成的简单图形，如下图所示：
- en: '*V ={v[1], v[2], v[3], v[4], v[5]}*'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '*V ={v[1], v[2], v[3], v[4], v[5]}*'
- en: '*E = {e[1] = (v[1], v[2]), e[2] = (v[1], v[3]), e[3] = (v[2], v[3]),*'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '*E = {e[1] = (v[1], v[2]), e[2] = (v[1], v[3]), e[3] = (v[2], v[3]),*'
- en: '*       e[4] = (v[3], v[4]), e[5] = (v[4], v[1]), e[6] = (v[4], v[5])}*'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '*       e[4] = (v[3], v[4]), e[5] = (v[4], v[1]), e[6] = (v[4], v[5])}*'
- en: 'This is what the graph will look like:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是图形的样子：
- en: '![](img/00152.jpeg)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00152.jpeg)'
- en: 'Figure 1: A simple undirected graph with five vertices and six edges'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：一个由五个顶点和六条边组成的简单无向图
- en: Note that in the realization of the graph in *Figure 1*, the relative position
    of nodes to each other, the length of the edges, and other visual properties are
    inessential to the graph. In fact, we could have displayed the graph in any other
    way by means of deforming it. The graph definition entirely determines its *topology*.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在*图1*中实现的图形的实现中，节点相对位置、边的长度和其他视觉属性对于图形是不重要的。实际上，我们可以通过变形以任何其他方式显示图形。图形的定义完全决定了它的*拓扑*。
- en: Directed and undirected graphs
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 有向图和无向图
- en: In a pair of vertices that make up an edge *e*, by convention, we call the first
    vertex the *source* and the second one the *target*. The natural interpretation
    here is that the connection represented by edge *e* has a *direction;* it flows
    from the source to the target. Note that in *Figure 1*, the graph displayed is
    undirected; that is, we did not distinguish between the source and target.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在构成边*e*的一对顶点中，按照惯例，我们称第一个顶点为*源*，第二个顶点为*目标*。这里的自然解释是，边*e*所代表的连接具有*方向*；它从源流向目标。请注意，在*图1*中，显示的图形是无向的；也就是说，我们没有区分源和目标。
- en: 'Using the exact same definition, we can create a directed version of our graph,
    as shown in the following image. Note that the graph looks slightly different
    in the way it is presented, but the connections of vertices and edges remain unchanged:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 使用完全相同的定义，我们可以创建我们图的有向版本，如下图所示。请注意，图在呈现方式上略有不同，但顶点和边的连接保持不变：
- en: '![](img/00153.jpeg)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00153.jpeg)'
- en: 'Figure 2: A directed graph with the same topology as the previous one. In fact,
    forgetting edge directions would yield the same graph as in Figure 1'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：具有与前一个相同拓扑结构的有向图。事实上，忘记边的方向将产生与图1中相同的图形
- en: Each directed graph naturally has an associated undirected graph, realized by
    simply forgetting all the edge directions. From a practical perspective, most
    implementations of graphs inherently build on directed edges and suppress the
    additional information of direction whenever needed. To give an example, think
    of the preceding graph as a group of five people connected by the relationship,
    *friendship*. We may argue that friendship is a symmetric property in that if
    you are a friend of mine, I am also a friend of yours. With this interpretation,
    directionality is not a very useful concept in this example, so we are, in fact,
    better off to treat this as an undirected graph example. In contrast, if we were
    to run a social network that allows users to actively send friend requests to
    other users, a directed graph might be better to encode this information.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 每个有向图自然地有一个相关的无向图，通过简单地忘记所有边的方向来实现。从实际角度来看，大多数图的实现本质上都建立在有向边上，并在需要时抑制方向的附加信息。举个例子，将前面的图看作是由关系“友谊”连接的五个人组成的。我们可以认为友谊是一种对称属性，如果你是我的朋友，我也是你的朋友。根据这种解释，方向性在这个例子中并不是一个非常有用的概念，因此我们实际上最好将其视为一个无向图的例子。相比之下，如果我们要运行一个允许用户主动向其他用户发送好友请求的社交网络，有向图可能更适合编码这些信息。
- en: Order and degree
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 顺序和度
- en: For any graph, directed or not, we can read off some basic properties that are
    of interest later in the chapter. We call the number of vertices |V| the *order*
    of the graph and the number of edges |E| its *degree*, sometimes also referred
    to as its *valency*. The degree of a vertex is the number of edges that have this
    vertex as either source or target. In the case of directed graphs and a given
    vertex *v*, we can additionally distinguish between *in-degree**,* that is, the
    sum of all the edges pointing towards *v*, and *out-degree*, that is, the sum
    of all the edges starting at *v*. To give an example of this, the undirected graph
    in *Figure 1* has order 5 and degree 6, same as the directed graph shown in *Figure
    2*. In the latter, vertex v1 has out-degree 2 and in-degree 1, while v5 has out-degree
    0 and in-degree 1.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 对于任何图，无论是有向的还是不是，我们都可以得出一些基本的性质，这些性质在本章后面会讨论。我们称顶点的数量|V|为图的*顺序*，边的数量|E|为它的*度*，有时也称为*价度*。顶点的度是具有该顶点作为源或目标的边的数量。对于有向图和给定的顶点*v*，我们还可以区分*入度*，即指向*v*的所有边的总和，和*出度*，即从*v*开始的所有边的总和。举个例子，图1中的无向图的顺序为5，度为6，与图2中显示的有向图相同。在后者中，顶点v1的出度为2，入度为1，而v5的出度为0，入度为1。
- en: 'In the last two examples, we annotated the vertices and edges with their respective
    identifiers, as specified by the definition *G = (V, E)*. For most graph visualizations
    that follow, we will assume that the identity of vertices and edges is implicitly
    known and will instead represent them by labeling our graphs with additional information.
    The reason we make this explicit distinction between identifiers and labels is
    that GraphX identifiers can’t be strings, as we will see in the next section.
    An example of a labeled graph with relationships of a group of people is shown
    in the following diagram:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在最后两个例子中，我们用它们各自的标识符注释了顶点和边，如定义*G = (V, E)*所指定的那样。对于接下来的大多数图形可视化，我们将假设顶点和边的标识是隐含已知的，并将通过为我们的图形加上额外信息来代替它们。我们明确区分标识符和标签的原因是GraphX标识符不能是字符串，我们将在下一节中看到。下图显示了一个带有一组人的关系的标记图的示例：
- en: '![](img/00154.jpeg)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00154.jpeg)'
- en: 'Figure 3: A directed labelled graph showing a group of people and their relationships'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：显示了一组人及其关系的有向标记图
- en: Directed acyclic graphs
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 有向无环图
- en: The next notion we want to discuss is that of acyclicity. A *cyclic graph* is
    one in which there is at least one vertex for which there is a path through the
    graph, connecting this vertex to itself. We call such a path a *cycle*. In an
    undirected graph, any chain creating a cycle will do, while in a directed graph,
    we only speak of cycles if we can reach the starting vertex by means of following
    the directed edges. For example, consider some of the graphs we have seen before.
    In *Figure 2*, there is precisely one cycle formed by *{e2, e4, e5}*, while in
    its undirected version, shown in *Figure 1*, there are precisely two cycles, namely
    *{e2, e4, e5}* and *{e1, e2, e3}*.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接下来要讨论的概念是无环性。*循环图*是指至少有一个顶点，通过图中的路径连接到自身。我们称这样的路径为*循环*。在无向图中，任何形成循环的链都可以，而在有向图中，只有当我们可以通过遵循有向边到达起始顶点时，我们才谈论循环。例如，考虑我们之前看到的一些图。在图2中，由{e2,
    e4, e5}形成了一个循环，而在其无向版本中，即图1中，有两个循环，分别是{e2, e4, e5}和{e1, e2, e3}。
- en: 'There are a few special cases of cyclic graphs that are worth mentioning here.
    Firstly, if a vertex is connected to itself by a single edge, we will say the
    graph has a *loop*. Secondly, a directed graph that does not contain any two-loops,
    that is, without pairs of vertices joined by edges in both directions, is called
    an *oriented* *graph*. Thirdly, a graph with three-loops is said to contain *triangles*.
    The notion of triangles is an important one, as it is often used to assess the
    connectivity of a graph, which we will discuss later on. The following diagram
    shows an artificial example with different types of loops:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种值得在这里提到的循环图的特殊情况。首先，如果一个顶点通过一条边与自身相连，我们将说图中有一个*循环*。其次，一个不包含任何两个顶点之间双向边的有向图被称为*定向图*。第三，包含*三角形*的图被认为包含三角形。三角形的概念是重要的，因为它经常用于评估图的连通性，我们将在后面讨论。以下图显示了一个具有不同类型循环的人工示例：
- en: '![](img/00155.jpeg)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00155.jpeg)'
- en: 'Figure 4: A toy graph illustrating loops or self-edges, two-loops and triangles.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：一个玩具图，说明了循环或自环、双向边和三角形。
- en: In general, studying n-loops in a graph for any natural number *n* can tell
    you a lot about a graph, but triangles are the most common. As directed cycles
    are not only more expensive to compute but also rarer than their undirected versions,
    we will often look for undirected triangles only in a graph; that is, we'll forget
    its directed structure.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，研究图中任意自然数*n*的循环可以告诉你很多关于图的信息，但三角形是最常见的。由于有向循环不仅计算成本更高，而且比它们的无向版本更少见，我们通常只会在图中寻找无向三角形；也就是说，我们会忽略它的有向结构。
- en: An important class of graphs found repeatedly in many applications is that of **Directed
    Acyclic Graphs** (**DAGs**). We already know what a DAG is from the last paragraph,
    namely a directed graph without cycles, but since DAGs are so ubiquitous, we should
    spend a little more time on them.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多应用程序中反复出现的一类重要图是**有向无环图**（DAGs）。我们已经从上一段知道了DAG是什么，即一个没有循环的有向图，但由于DAG是如此普遍，我们应该花更多的时间来了解它们。
- en: 'One instance of a DAG that we have implicitly used throughout all the chapters
    leading up to this one is Spark’s job execution graph. Remember that any Spark
    job consists of stages executed in a certain order. Stages consist of tasks executed
    on each partition, some of which may be independent, while others depend on each
    other. We can thus interpret the execution of a Spark job as a directed graph
    consisting of stages (or tasks) as vertices, in which an edge represents the output
    of one computation being required for the next. The prototypical example might
    be that of a reduce stage that needs the output of a preceding map stage. Naturally,
    this execution graph does not contain any cycles, as this would mean we are to
    feed the output of some operators into the graph ad infinitum, preventing our
    program to eventually halt. Thus, this execution graph can be represented, and
    is in fact implemented in the Spark scheduler, as DAG:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在前面的所有章节中隐式使用的一个DAG实例是Spark的作业执行图。请记住，任何Spark作业都由按特定顺序执行的阶段组成。阶段由在每个分区上执行的任务组成，其中一些可能是独立的，而其他则彼此依赖。因此，我们可以将Spark作业的执行解释为由阶段（或任务）组成的有向图，其中边表示一个计算的输出被下一个计算所需。典型的例子可能是需要前一个映射阶段的输出的减少阶段。自然地，这个执行图不包含任何循环，因为这意味着我们要将一些运算符的输出无限地输入到图中，从而阻止我们的程序最终停止。因此，这个执行图可以被表示，并实际上在Spark调度器中实现为DAG：
- en: '![](img/00156.jpeg)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00156.jpeg)'
- en: 'Figure 5: Visualizing a chain of operations carried out on RDDs with Spark.
    The execution graph is by definition a DAG.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：用Spark在RDD上执行的一系列操作的可视化。执行图从定义上是一个DAG。
- en: Connected components
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 连通分量
- en: Another important property of graphs is that of *connectivity*. A graph is said
    to be *connected* if there is a path of edges connecting any two vertices we choose,
    regardless of the edge directions. So, for directed graphs, we completely neglect
    the directions for this definition. What can be a stricter definition of connectivity
    used for directed graphs? A graph is said to be *strongly connected* if any two
    vertices are connected by a directed chain of edges. Note that strong connectivity
    is a very strong assumption to impose on a directed graph. In particular, any
    strongly connected graph is cyclic. These definitions allow us to define the closely
    related concept of (strongly) connected components. Every graph can be decomposed
    into connected components. If it is connected, there is precisely one such component.
    If it is not, there are at least two. Formally defined, a connected component
    is the largest subgraph of a given graph that is still connected. The same rationale
    holds for strongly connected components. Connectivity is an important measure,
    as it allows us to cluster the vertices of a graph into groups that naturally
    belong together.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 图的另一个重要属性是*连通性*。如果我们选择的任意两个顶点之间存在一条边的路径，无论边的方向如何，我们就说图是*连通的*。因此，对于有向图，我们在这个定义中完全忽略方向。对于有向图，可以使用更严格的连通性定义吗？如果任意两个顶点都可以通过有向边连接，我们就说图是*强连通的*。请注意，强连通性是对有向图施加的一个非常严格的假设。特别地，任何强连通图都是循环的。这些定义使我们能够定义（强）连通分量的相关概念。每个图都可以分解为连通分量。如果它是连通的，那么恰好有一个这样的分量。如果不是，那么至少有两个。正式定义，连通分量是给定图的最大子图，仍然是连通的。强连通分量也是同样的道理。连通性是一个重要的度量，因为它使我们能够将图的顶点聚类成自然属于一起的组。
- en: For instance, one might be interested in the number of connected components
    in a social graph indicating friendship. In a small graph, there may be many separate
    components. However, the larger the graph, one might suspect that it is more likely
    to have just a single connected component, following the commonly accepted rationale
    that everyone is connected to each other by around six connections.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，一个人可能对社交图中表示友谊的连接组件数量感兴趣。在一个小图中，可能有许多独立的组件。然而，随着图的规模变大，人们可能会怀疑它更有可能只有一个连接的组件，遵循着普遍接受的理由，即每个人都通过大约六个连接与其他人相连。
- en: 'We will see how to compute connected components with GraphX in the next section;
    for now, let''s just inspect one simple example. In the following diagram*,* we
    see a directed graph with twelve vertices:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一节中看到如何使用GraphX计算连接组件；现在，让我们只检查一个简单的例子。在下面的图表中，我们看到一个有十二个顶点的有向图：
- en: '![](img/00157.jpeg)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00157.jpeg)'
- en: 'Figure 6: Connected and strongly connected components can easily be read off
    in small graphs, but this becomes increasingly difficult for larger graphs.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：在小图中，连接和强连接组件可以很容易地读取，但对于更大的图来说，这变得越来越困难。
- en: We can immediately see that it has three connected components, namely the three
    sets of vertices *{1, 2, 3}, {4, 5}*, and *{6, 7, 8, 9, 10, 11, 12}*. As for strongly
    connected components, that requires a little more effort than a quick visual inspection.
    We can see that *{4, 5}* forms a strongly connected component, and so does *{8,
    9, 10, 11}*. All the other six vertices form their own strongly connected components,
    that is, they are isolated. This example goes on to show that for a massive graph
    with millions of vertices, with the right visualization tool, we may be lucky
    to find roughly connected components, but strongly connected components are a
    little more complicated to compute, and this is just one use case where Spark
    GraphX comes in handy.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以立即看到它有三个连接的组件，即三组顶点*{1, 2, 3}, {4, 5}*, 和 *{6, 7, 8, 9, 10, 11, 12}*。至于强连接组件，这需要比快速的视觉检查更多的努力。我们可以看到*{4,
    5}*形成了一个强连接组件，*{8, 9, 10, 11}*也是如此。其他六个顶点形成了自己的强连接组件，也就是说，它们是孤立的。这个例子继续说明，对于一个有数百万个顶点的大图，通过正确的可视化工具，我们可能会幸运地找到大致连接的组件，但强连接组件的计算会更加复杂，这正是Spark
    GraphX派上用场的一个用例。
- en: Trees
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 树
- en: 'With the definition of connected components in our hands, we can turn to another
    interesting class of graphs, namely trees. A *tree* is a connected graph in which
    there is precisely one path connecting any given vertex to another. A graph consisting
    of a disjointed group of trees is called a forest. In the following diagram, we
    see a schematic *decision tree* ran on the well known Iris dataset. Note that
    this is for illustration purposes only, that is, to show how the output of this
    algorithm can be seen as a graph:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 有了我们手头的连接组件的定义，我们可以转向另一类有趣的图，即树。*树*是一个连接的图，在其中恰好有一条路径连接任何给定的顶点到另一个顶点。由一组树的不相交组成的图称为森林。在下面的图表中，我们看到了一个在众所周知的鸢尾花数据集上运行的示意*决策树*。请注意，这仅用于说明目的，即展示此算法的输出如何被视为一个图：
- en: '![](img/00158.jpeg)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00158.jpeg)'
- en: Figure 7: A simple decision tree ran on Iris, classifying into the three categories
    Setosa, Virginica and Versicolor by means of two features, namely petal length
    (PL) and petal width (PW)
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图7：在鸢尾花数据集上运行的简单决策树，通过两个特征，即花瓣长度（PL）和花瓣宽度（PW），将其分类为三个类别Setosa，Virginica和Versicolor
- en: Multigraphs
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多重图
- en: 'Generally, a graph without loops or multiple edges is called *simple*. Most
    graphs we will encounter in the applications of this chapter do not share this
    property. Very often, graphs constructed from real-world data will have multiple
    edges between vertices. In literature, graphs with multiple edges are referred
    to as multi-graphs or pseudo graphs. Throughout the chapter, we will stick with
    the multigraph notion and will follow the convention that such a multigraph can
    include loops as well. Since Spark supports multigraphs (including loops), this
    notion will be very useful in the applications. In the following diagram, we see
    a complex multigraph with multiple connected components:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，没有环或多重边的图被称为*简单*。在本章的应用中，我们将遇到的大多数图都不具备这个属性。通常，从现实世界数据构建的图会在顶点之间有多重边。在文献中，具有多重边的图被称为多重图或伪图。在整个章节中，我们将坚持多重图的概念，并遵循这样一个约定，即这样的多重图也可以包括环。由于Spark支持多重图（包括环），这个概念在应用中将非常有用。在下面的图表中，我们看到了一个复杂的多重图，其中有多个连接的组件：
- en: '![](img/00159.jpeg)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00159.jpeg)'
- en: 'Figure 8: A slightly more involved social multigraph with loops and multiple
    edges.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 图8：一个稍微复杂的社交多重图，带有环和多重边。
- en: Property graphs
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 属性图
- en: Before we move on to introduce GraphX as a graph processing engine, let's look
    at an extension of graphs as we have seen them before. We have already considered
    labeled graphs as a convenient way to name vertices and edges. In general, the
    graph data we will consider in the applications will have more information attached
    to both vertices and edges, and we need a way to model this additional information
    within our graph. To this end, we can utilize the notion of *property graphs*.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续介绍GraphX作为图处理引擎之前，让我们看一下我们之前所见过的图的扩展。我们已经考虑过标记的图作为一种方便的方式来命名顶点和边。一般来说，在应用中我们将考虑的图数据将附加更多信息到顶点和边上，我们需要一种方法在我们的图中对这些额外的信息进行建模。为此，我们可以利用*属性图*的概念。
- en: From the basic definition of a graph as a pair of vertices and edges, it is
    not directly possible to attach additional information to the two structures.
    Historically, one way to circumvent this is to blow up the graph and create more
    vertices corresponding to properties, connected to the original vertices by new
    edges that encode the relationship to the new vertices. For instance, in our previous
    examples of friend graphs, if we also want to encode the home addresses in our
    graph, each vertex representing a person must be connected to a vertex representing
    their address with the edge between them *lives at*. It does not take a lot of
    imagination to realize that this approach creates a lot of complexity, especially
    if the vertex properties interrelate. Representing properties in a graph by subject-predicate-object
    *triples* has been formalized in the so-called **Resource Description Framework** (**RDF**),
    and the result of this is called an RDF-model. RDFs are a subject on their own
    and allow for a little more flexibility than we presented. In any case, it is
    good to be familiar with the concept and understand its limitations.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 从图的基本定义作为顶点和边的一对开始，直接向这两个结构附加额外信息是不可能的。历史上，规避这一点的一种方法是扩展图并创建更多与属性对应的顶点，通过新的边与原始顶点连接，这些边编码与新顶点的关系。例如，在我们之前的朋友图示例中，如果我们还想在图中编码家庭地址，表示一个人的每个顶点必须与表示他们地址的顶点连接，它们之间的边是*lives
    at*。不难想象，这种方法会产生很多复杂性，特别是如果顶点属性相互关联。通过主语-谓语-宾语*三元组*在图中表示属性已经在所谓的**资源描述框架**（**RDF**）中得到了形式化，并且其结果被称为RDF模型。RDF是一个独立的主题，并且比我们所介绍的更灵活。无论如何，熟悉这个概念并了解其局限性是很好的。
- en: In a *property graph*, in contrast, we can augment both vertices and edges with
    essentially arbitrary additional structure. As with anything, gaining flexibility
    in this generality usually comes as a trade-off. In our case, basic graphs as
    implemented in many graph databases allow for the powerful optimization of queries,
    while with property graphs, we should be careful when it comes to performance.
    We will touch this topic in more detail in the next section, when we show how
    Spark GraphX implements property graphs.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，在*属性图*中，我们可以为顶点和边增加基本上任意的附加结构。与任何事物一样，获得这种一般性的灵活性通常是一种权衡。在我们的情况下，许多图数据库中实现的基本图允许对查询进行强大的优化，而在属性图中，当涉及性能时，我们应该小心。在下一节中，当我们展示Spark
    GraphX如何实现属性图时，我们将更详细地讨论这个话题。
- en: 'Throughout the rest of the chapter, we''ll use the following convention for
    property graphs. The additional data attached to vertices is called *vertex data *and
    the one for edges is called *edge data*. To give an example of a little more involved
    vertex and edge data, see the following diagram for an extension of our idea of
    extending a friend graph. This example also displays what we mean by a *triplet*,
    that is, an edge with its adjacent vertices and all their properties:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的其余部分，我们将使用以下约定来表示属性图。附加到顶点的额外数据称为*顶点数据*，附加到边的数据称为*边数据*。为了举例更复杂的顶点和边数据，请参见以下图表，扩展了我们扩展朋友图的想法。这个例子也展示了我们所说的*三元组*，即带有其相邻顶点及其所有属性的边：
- en: '![](img/00160.jpeg)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00160.jpeg)'
- en: 'Figure 9: A property graph showing friends augmented by address data, connected
    by more than one relation. Property data is encoded in JSON format.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 图9：显示通过地址数据增强的朋友属性图，通过多个关系连接。属性数据以JSON格式编码。
- en: Note that in the preceding example, we kept it simple on purpose, but in a more
    realistic scenario, we would have the need for nested data structures--for example,
    to answer how much money is owed and when it is due.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在前面的例子中，我们故意保持简单，但在更现实的情况下，我们需要嵌套数据结构--例如，回答欠款金额和到期时间。
- en: An interesting special case of a property graph in our context is that of a *weighted
    graph*, in which edges, vertices, or both have weights, for example, integers
    or floating point numbers attached to them. A prototypical example for this is
    a graph consisting of a set of cities as vertices ,with the edges connecting them
    carrying the distance between locations. A few classical questions arise in this
    scenario. One example would be to find the shortest path between two given cities.
    A related issue is the *traveling salesman problem*, in which a hypothetical salesman
    is asked to visit every city using the shortest route possible.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的上下文中，属性图的一个有趣的特殊情况是*加权图*，其中边、顶点或两者都具有权重，例如，附加到它们的整数或浮点数。这种情况的一个典型例子是一个由一组城市作为顶点组成的图，连接它们的边携带着位置之间的距离。在这种情况下会出现一些经典问题。一个例子是找到两个给定城市之间的最短路径。相关问题是*旅行推销员问题*，其中一个假设的推销员被要求使用可能的最短路线访问每个城市。
- en: As a closing remark for this section, it is important to know that in literature,
    there is a widely used synonymous notion for vertices, namely nodes. We will not
    use this term here, since in the context of Spark, it might easily be confused
    with compute nodes on which workers execute tasks. Instead, we will stick to vertices
    throughout the chapter. Also, whenever we speak of a graph, we generally assume
    that it is a *finite* *graph*, that is, the number of vertices and edges is finite,
    which, in practice, hardly counts as restriction.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 作为本节的结束语，重要的是要知道，在文献中，有一个广泛使用的与顶点同义的概念，即节点。我们在这里不使用这个术语，因为在Spark的上下文中，它很容易与执行任务的计算节点混淆。相反，我们将在整个章节中坚持使用顶点。此外，每当我们谈论图时，我们通常假设它是一个*有限*的*图*，也就是说，顶点和边的数量是有限的，在实践中，这几乎不算是限制。
- en: GraphX distributed graph processing engine
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GraphX分布式图处理引擎
- en: Along with Spark MLlib for machine learning, which we have already encountered
    a few times in this book, and others like Spark Streaming, which we will cover
    in Chapter 8, *Lending Club Loan Prediction*, Spark GraphX is one of the core
    components of the Spark ecosphere. GraphX is tailored for processing large graphs
    in an efficient way by building on top of RDDs.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 除了Spark MLlib用于机器学习，我们在本书中已经遇到了几次，以及其他组件，如我们将在第8章“Lending Club Loan Prediction”中介绍的Spark
    Streaming，Spark GraphX是Spark生态系统的核心组件之一。GraphX通过构建在RDD之上，专门用于以高效的方式处理大型图形。
- en: Using the nomenclature developed in the last section, a graph in GraphX is a
    finite multigraph with loops, where by *graph*, we actually mean the property
    graph extension discussed earlier. Next, we will see how graphs are built internally
    in GraphX.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 使用上一节开发的命名法，GraphX中的图形是一个带有环的有限多重图，其中*图形*实际上是指之前讨论的属性图扩展。接下来，我们将看到GraphX中图形是如何在内部构建的。
- en: 'For the examples used, we recommend firing up `spark-shell` locally, which
    will automatically provide dependencies for GraphX. To test whether this works
    properly in your setup, try importing the full GraphX core module using Scala''s
    wildcard operator, as follows:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 对于使用的示例，我们建议在本地启动`spark-shell`，这将自动为GraphX提供依赖项。要测试这在您的设置中是否正常工作，请尝试使用Scala的通配符运算符导入完整的GraphX核心模块，如下所示：
- en: '[PRE0]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'On your screen, you should see the following prompt:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在您的屏幕上，您应该看到以下提示：
- en: '![](img/00161.jpeg)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00161.jpeg)'
- en: 'If you would rather follow the examples by building a package using sbt, you
    should include the following `libraryDependencies` in your `build.sbt`:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您更愿意通过使用sbt构建一个包来跟随示例，您应该在您的`build.sbt`中包含以下`libraryDependencies`：
- en: '[PRE1]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Doing so should allow you to import GraphX, as shown previously, to create an
    app of your choice that you can call with spark-submit instead.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这样做应该允许你导入GraphX，就像之前展示的那样，创建一个你可以用spark-submit调用的应用程序。
- en: Graph representation in GraphX
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GraphX中的图形表示
- en: 'Recall that a property graph is, for us, a directed multigraph with loops that
    have custom data objects for both vertices and edges. The central entry point
    of GraphX is the `Graph` API, which has the following signature:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，对于我们来说，属性图是一个具有自定义数据对象的有向多重图。GraphX的中心入口点是`Graph` API，具有以下签名：
- en: '[PRE2]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: So, internally, a graph in GraphX is represented by one RDD encoding for vertices
    and one for edges. Here, `VD` is the vertex data type, and `ED` is the edge data
    type of our property graph. We will discuss both `VertexRDD` and `EdgeRDD` in
    more detail, as they are so essential for what follows.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在GraphX中，图形内部由一个编码顶点的RDD和一个编码边的RDD表示。在这里，`VD`是顶点数据类型，`ED`是我们属性图的边数据类型。我们将更详细地讨论`VertexRDD`和`EdgeRDD`，因为它们对接下来的内容非常重要。
- en: In Spark GraphX, vertices have unique identifiers of the `Long` type, which
    are called `VertexId`. A `VertexRDD[VD]` is, in fact, just an extension of `RDD[(VertexId,
    VD)]`, but optimized and with an extensive list of utility functionality that
    we will talk about at length. Thus, vertices in GraphX, simply put, are RDDs with
    identifiers and vertex data, which goes hand in hand with the intuition developed
    earlier.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在Spark GraphX中，顶点具有`Long`类型的唯一标识符，称为`VertexId`。`VertexRDD[VD]`实际上只是`RDD[(VertexId,
    VD)]`的扩展，但经过优化并具有大量的实用功能列表，我们将详细讨论。因此，简而言之，GraphX中的顶点是带有标识符和顶点数据的RDD，这与之前发展的直觉相一致。
- en: 'To explain the concept of `EdgeRDD`, let''s quickly explain what `Edge` is
    in GraphX. In a simplified form, `Edge` is defined by the following signature:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解释`EdgeRDD`的概念，让我们快速解释一下GraphX中的`Edge`是什么。简化形式上，`Edge`由以下签名定义：
- en: '[PRE3]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: So, an edge is completely determined by a source vertex ID, given by `srcId`,
    a target or destination vertex ID, provided as `dstId`, and an attribute object, `attr`,
    of the `ED` data type. Similar to the preceding vertex RDDs, we can understand
    `EdgeRDD[ED]` as an extension of `RDD[Edge[ED]]`. Thus, edges in GraphX are given
    by an RDD of edges of the `ED` type, which again lines up with what we discussed
    so far.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，边完全由源顶点ID（称为`srcId`）、目标或目的地顶点ID（称为`dstId`）和`ED`数据类型的属性对象`attr`确定。与前面的顶点RDD类似，我们可以将`EdgeRDD[ED]`理解为`RDD[Edge[ED]]`的扩展。因此，GraphX中的边由`ED`类型的边的RDD给出，这与我们迄今讨论的内容一致。
- en: We now know that as of Spark 2.1, graphs in GraphX are essentially pairs of
    vertex and edge RDDs. This is important information, as it allows us, in principle,
    to apply the full functionality and power of RDDs from Spark core to these graphs.
    As a word of warning, though, graphs come with a lot of functionality that is
    optimized for the purpose of graph processing. Whenever you find yourself using
    basic RDD functionality, see if you can find a specific graph equivalent, which
    will likely be more performant.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在知道，从Spark 2.1开始，GraphX中的图形本质上是顶点和边RDD的对。这是重要的信息，因为它原则上允许我们将Spark核心的RDD的全部功能和能力应用到这些图形中。然而，需要警告的是，图形带有许多针对图形处理目的进行优化的功能。每当你发现自己在使用基本的RDD功能时，看看是否可以找到特定的图形等效功能，这可能会更高效。
- en: 'To give a concrete example, let''s construct a graph from scratch, using what
    we just learned. We assume that you have a Spark context available as `sc`. We
    will create a graph with people connected to each other, namely the one from *Figure
    3* of the previous section, that is, a labelled graph. In the GraphX language
    we just acquired, to create such a graph, we need both vertex and edge data types
    to be of the `String` type. We do this by using `parallelize` to create vertices
    as follows:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 举个具体的例子，让我们使用刚刚学到的知识从头开始构建一个图。我们假设您有一个名为`sc`的Spark上下文可用。我们将创建一个人与彼此连接的图，即上一节中*图3*中的图，即一个带标签的图。在我们刚刚学到的GraphX语言中，要创建这样一个图，我们需要顶点和边数据类型都是`String`类型。我们通过使用`parallelize`来创建顶点，如下所示：
- en: '[PRE4]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'In the same way, we can create edges; note the use of `Edge` in the following
    definition:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，我们可以创建边；请注意以下定义中`Edge`的使用：
- en: '[PRE5]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Having these two RDDs ready is already sufficient to create `Graph`, which
    is as simple as the following line:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有这两个准备好的RDD已经足以创建`Graph`，就像以下一行一样简单：
- en: '[PRE6]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Note that we explicitly write out the types for all variables, which is just
    for clarity. We could just leave them out and rely on the Scala compiler to infer
    them for us. Furthermore, as indicated by the preceding signature, we can access
    vertices with `friendGraph.vertices` and edges with `friendGraph.edges`. Just
    to give a first glimpse of what is possible, we can now collect all the vertices
    and print them as follows:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们明确地为所有变量写出类型，这只是为了清晰。我们可以把它们留空，依赖Scala编译器为我们推断类型。此外，如前面的签名所示，我们可以通过`friendGraph.vertices`访问顶点，通过`friendGraph.edges`访问边。为了初步了解可能的操作，我们现在可以收集所有顶点并打印它们如下：
- en: '[PRE7]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The following is the output:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是输出：
- en: '![](img/00162.jpeg)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00162.jpeg)'
- en: 'Note that this does not use any GraphX-specific functionality, just what we
    already know from RDDs. As another example, let''s count all the edges for which
    the source ID is larger than the target ID. This could be done as follows:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这不使用任何GraphX特定的功能，只是使用我们已经从RDD中知道的知识。举个例子，让我们计算所有源ID大于目标ID的边的数量。可以这样做：
- en: '[PRE8]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'This gives back the expected answer, that is, `1`, but has a drawback. Once
    we call `.edges` on the graph, we completely lose all the graph structure that
    we previously had. Assuming that we want to further process a graph with transformed
    edges, this is not the way to go. In such a case, it is better to use the built-in
    `Graph` functionality instead, like the following `mapEdges` method:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 这给出了预期的答案，即`1`，但有一个缺点。一旦我们在图上调用`.edges`，我们就完全失去了之前拥有的所有图结构。假设我们想要进一步处理具有转换边的图，这不是正确的方法。在这种情况下，最好使用内置的`Graph`功能，比如以下的`mapEdges`方法：
- en: '[PRE9]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Note that the return value in this case is again a graph, but the edge data
    type is now `Boolean`, as expected. We will see many more examples of graph processing
    possibilities in just a bit. Having seen this example, let's take a step back
    and discuss why Spark GraphX implements graphs as it does. One reason is that
    we can effectively leverage both *data parallelism *and *graph parallelism.* In
    the previous chapters, we already encountered how RDDs and data frames in Spark
    exploit data parallelism by distributing data across partitions by keeping data
    in memory on each node. So, if we are only concerned about vertices or edges on
    their own and don't want to study their relationship, working with the vertex
    and edge RDDs will be very efficient.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这种情况下的返回值仍然是一个图，但是边的数据类型现在是`Boolean`，正如预期的那样。我们将在接下来看到更多关于图处理可能性的例子。看完这个例子后，让我们退一步，讨论为什么Spark
    GraphX实现图的方式。一个原因是我们可以有效地利用*数据并行性*和*图并行性*。在前几章中，我们已经了解到Spark中的RDD和数据框利用数据并行性，通过在每个节点上将数据分布到分区中并将数据保存在内存中。因此，如果我们只关心顶点或边本身，而不想研究它们的关系，那么使用顶点和边RDD将非常高效。
- en: In contrast, by graph parallelism we mean operations carried out in parallel
    *relative to notions of the graph*. For instance, a graph-parallel task will be
    to sum the weights of all the inbound edges for each vertex. To carry out this
    task, we need to work with both the vertex and edge data, which involves multiple
    RDDs. Doing this efficiently needs a suitable internal representation. GraphX
    tries to strike a balance between both the paradigms, which few other alternative
    programs offer.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，通过图并行性，我们指的是相对于图的概念进行并行操作。例如，图并行任务将是对每个顶点的所有入边的权重进行求和。要执行此任务，我们需要处理顶点和边数据，这涉及多个RDD。要高效地执行此操作，需要合适的内部表示。GraphX试图在这两种范式之间取得平衡，而其他一些替代程序则没有提供这种平衡。
- en: Graph properties and operations
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图属性和操作
- en: Having seen yet another artificial example, let's turn to a more interesting
    example next, which we will use to investigate some of the core properties that
    we have studied in the previous section. The data we will be considering in this
    chapter can be found at [http://networkrepository.com/](http://networkrepository.com/), an
    open network data repository with a vast amount of interesting data. First, we
    will load a relatively small data set retrieved from Twitter, which can be downloaded
    from [http://networkrepository.com/rt-occupywallstnyc.php](http://networkrepository.com/rt-occupywallstnyc.php).
    Download the zip file available on this page, that is, store rt_occupywallstnyc.zip
    and unpack it to access the file, rt_occupywallstnyc.edges. The file is in the
    CSV format with commas as separators. Each row represents a retweet of a tweet
    concerning the *occupy Wall Street* movement in New York City. The first two columns
    show Twitter user IDs and the third represents an ID for the retweet; that is,
    the user in the second column retweeted a tweet from the respective user in the
    first.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 看完另一个人工例子后，让我们转而看一个更有趣的例子，用它来研究我们在上一节中学习的一些核心属性。本章中我们将考虑的数据可以在[http://networkrepository.com/](http://networkrepository.com/)找到，这是一个拥有大量有趣数据的开放网络数据存储库。首先，我们将加载从Twitter获取的一个相对较小的数据集，可以从[http://networkrepository.com/rt-occupywallstnyc.php](http://networkrepository.com/rt-occupywallstnyc.php)下载。下载此页面上提供的zip文件，即存储rt_occupywallstnyc.zip并解压以访问文件rt_occupywallstnyc.edges。该文件以逗号分隔的CSV格式。每一行代表了有关纽约市占领华尔街运动的推文的转发。前两列显示了Twitter用户ID，第三列表示转发的ID；也就是说，第二列中的用户转发了第一列中相应用户的推文。
- en: 'The first ten items look as follows:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 前十个项目如下所示：
- en: '[PRE10]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: For instance, we can see that the tweets from user 3,212 have been retweeted
    at least six times, but since we don't know if the file is ordered in any way
    and that contains roughly 3.6k vertices, we should utilize GraphX to answer such
    questions for us.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们可以看到用户3,212的推文至少被转发了六次，但由于我们不知道文件是否以任何方式排序，并且其中包含大约3.6k个顶点，我们应该利用GraphX来为我们回答这样的问题。
- en: 'To build a graph, we will proceed by first creating an RDD of edges from this
    file, that is, `RDD[Edge[Long]]`, by using basic Spark functionality:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 要构建一个图，我们将首先从该文件创建一个边的RDD，即`RDD[Edge[Long]]`，使用基本的Spark功能：
- en: '[PRE11]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Recall that IDs in GraphX are of the `Long` type, which is why we cast all
    the values to `Long` after loading the text file and splitting each line by comma;
    that is, our edge data type in this case is `Long`. Here, we assume that the file
    in question resides in the same folder that we started `spark-shell` in; adapt
    it to your needs, if necessary. Having such an edge RDD, we can now use the `fromEdges`
    method of the `Graph` companion object as follows:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，GraphX中的ID是`Long`类型，这就是为什么在加载文本文件并通过逗号拆分每一行后，我们将所有值转换为`Long`的原因；也就是说，在这种情况下，我们的边数据类型是`Long`。在这里，我们假设所讨论的文件位于我们启动`spark-shell`的同一文件夹中；如果需要，可以根据自己的需求进行调整。有了这样的边RDD，我们现在可以使用`Graph`伴生对象的`fromEdges`方法，如下所示：
- en: '[PRE12]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: It may not come as a surprise that we need to supply `edges` to this method,
    but the `defaultValue` keyword deserves some explanation. Note that so far, we
    only have knowledge of edges, and while the vertex IDs are implicitly available
    as sources and targets of edges, we still have not settled on a vertex data type
    `VD` needed for any GraphX graph. The `defaultValue` allows you to create a default
    vertex data value, which comes with a type. In our case, we chose an empty string,
    which explains the signature of `rtGraph`.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 也许不足为奇的是，我们需要为这个方法提供`edges`，但`defaultValue`关键字值得一些解释。请注意，到目前为止，我们只知道边，虽然顶点ID隐式地作为边的源和目标可用，但我们仍然没有确定任何GraphX图所需的顶点数据类型`VD`。`defaultValue`允许您创建一个默认的顶点数据值，带有一个类型。在我们的情况下，我们选择了一个空字符串，这解释了`rtGraph`的签名。
- en: 'With this first real-world data graph loaded, let''s check for some basic properties.
    Using the notation from earlier, the *order* and *degree* of the graph can be
    computed as follows:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 加载了这个第一个真实世界的数据图后，让我们检查一些基本属性。使用之前的符号，图的*顺序*和*度*可以计算如下：
- en: '[PRE13]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The preceding code will yield 3,609 and 3,936, respectively. As for the degree
    of individual vertices, GraphX provides the `degrees` method on Graphs that returns
    a graph of integer vertex data type, which is used to store degrees. Let''s compute
    the average degree of our retweet graph:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码将分别产生3,609和3,936。至于各个顶点的度，GraphX提供了Graphs上的`degrees`方法，返回整数顶点数据类型的图，用于存储度数。让我们计算一下我们的转发图的平均度：
- en: '[PRE14]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The result of this operation should be roughly  `2.18`, which means that each
    vertex has about two edges connected to it on average. The notation used in this
    concise operation may seem a bit dense,  mostly due to the many wildcards used,
    so let''s dissect it a little. To explain this, we first call degrees, as discussed.
    Afterwards, we extract the degrees only by mapping to the second item of the pair;
    that is, we forget the vertex IDs. This leaves us with an RDD of integer values,
    which we can sum up by reducing by addition. The last step is casting `order.toDouble`
    to make sure we get floating division and then dividing by this total. The next
    code listing shows the same four steps expanded in more detail:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 这个操作的结果应该大约是`2.18`，这意味着每个顶点平均连接了大约两条边。这个简洁操作中使用的符号可能看起来有点密集，主要是因为使用了许多通配符，所以让我们来详细解释一下。为了解释这一点，我们首先调用degrees，如前所述。然后，我们通过映射到对中的第二个项目来提取度数；也就是说，我们忘记了顶点ID。这给我们留下了一个整数值的RDD，我们可以通过加法减少来总结。最后一步是将`order.toDouble`转换为确保我们得到浮点除法，然后除以这个总数。下一个代码清单显示了相同的四个步骤以更详细的方式展开：
- en: '[PRE15]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Next, we compute in-degree and out-degree of this directed graph by simply
    calling `inDegrees` and `outDegrees`, respectively. To make things more interesting,
    let''s compute the maximum in-degree, as well as the minimum out-degree, over
    all the vertices present in the graph and return its ID as well. We tackle the
    maximum in-degree first:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们通过简单地调用`inDegrees`和`outDegrees`来计算这个有向图的入度和出度。为了使事情更有趣，让我们计算图中所有顶点的最大入度，以及最小出度，并返回其ID。我们首先解决最大入度：
- en: '[PRE16]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Carrying out this computation, you should see that the vertex with ID `1783`
    has in-degree 401, meaning that the user with this ID retweeted 401 different
    tweets. So, an interesting follow-up question to ask is, "From how many different
    users has this user retweeted?" Again, we can answer this in a very quick manner
    by counting the distinct sources of this target in all the edges:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 进行这个计算，你会看到ID为`1783`的顶点的入度为401，这意味着具有这个ID的用户转发了401条不同的推文。因此，一个有趣的后续问题是，“这个用户转发了多少不同用户的推文？”同样，我们可以通过计算所有边中这个目标的不同来源来非常快速地回答这个问题：
- en: '[PRE17]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Executing this command should prompt 34, so on average, user `1783` retweeted
    about 12 tweets from any given user that he retweeted from at all in this data
    set. This in turn means that we found a meaningful example of a multigraph--there
    are pairs of vertices in this graph with many different connections between each
    other. Answering the question of minimum out-degree is now straightforward:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 执行这个命令应该会提示34，所以平均而言，用户`1783`从任何给定的用户那里转发了大约12条推文。这反过来意味着我们找到了一个有意义的多图的例子--在这个图中有许多不同连接的顶点对。现在回答最小出度的问题就很简单了：
- en: '[PRE18]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The answer is `1` in this case, which means that in this data set, each tweet
    has been retweeted at least once.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，答案是`1`，这意味着在这个数据集中，每条推文至少被转发了一次。
- en: 'Recall that a *triplet* of a property graph consists of an edge and its data,
    as well as both of the joining vertices and their respective data. In Spark GraphX,
    this concept is implemented in a class called `EdgeTriplet`, in which we can retrieve
    the edge data as `attr` and vertex data and IDs naturally through `srcAttr`, `dstAttr`,
    `srcId`, and `dstId`. To get triplets for our retweet graph, we can simply call
    the following:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，属性图的*三元组*由边及其数据以及连接顶点及其各自的数据组成。在Spark GraphX中，这个概念是在一个叫做`EdgeTriplet`的类中实现的，我们可以通过`attr`检索边数据，通过`srcAttr`、`dstAttr`、`srcId`和`dstId`自然地检索顶点数据和ID。为了获得我们的转发图的三元组，我们可以简单地调用以下内容：
- en: '[PRE19]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Triplets often prove practical, as we can directly retrieve the corresponding
    edge and vertex data, which would otherwise live in separate RDDs in the graph.
    For instance, we can quickly transform the generated triplets to give us somewhat
    readable data for each retweet by executing the following:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 三元组通常很实用，因为我们可以直接检索相应的边和顶点数据，否则这些数据将分别存在于图中的不同RDD中。例如，我们可以通过执行以下操作，快速将生成的三元组转换为每次转发的可读数据：
- en: '[PRE20]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The preceding code results in the following output:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码产生了以下输出：
- en: '![](img/00163.jpeg)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00163.jpeg)'
- en: 'When we discussed the `friendGraph` example earlier, we took note that `mapEdges`
    was, in certain regards, superior to first calling `edges` and then `map` them.
    The same holds true for vertices and triplets as well. Let''s say we want to change
    the vertex data of our graph to simply be the vertex IDs instead of the previously
    chosen default value. This can be most quickly and efficiently achieved by mapping
    the vertices as follows:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们之前讨论`friendGraph`示例时，我们注意到`mapEdges`在某些方面优于先调用`edges`然后再`map`它们。对于顶点和三元组也是如此。假设我们想要将图的顶点数据简单地更改为顶点ID而不是先前选择的默认值。这可以通过以下方式最快、最有效地实现：
- en: '[PRE21]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Similarly, instead of retrieving triplets first, we can start equally well from
    our initial graph and directly transform triplets using `mapTriplets`, returning
    a Graph object with modified edge data. To achieve the same effect as with the
    preceding `tweetStrings` but keeping the graph structure intact, we can run the
    following:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 同样地，我们可以直接从我们的初始图开始，而不是首先检索三元组，然后使用`mapTriplets`直接转换三元组，返回一个具有修改后的边数据的图形对象。为了实现与前面的`tweetStrings`相同的效果，但保持图形结构不变，我们可以运行以下操作：
- en: '[PRE22]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'As a last example of basic graph processing functionality, we will now look
    at the subgraphs of a given graph and how to join graphs with each other. Consider
    the task of extracting information of all the Twitter users in our graph that
    have been retweeted at least 10 times. We have already seen how to obtain out-degree
    from `rtGraph.outDegrees`. To make this information accessible in our original
    graph, we need to join this information to it. For this purpose, GraphX has the
    functionality provided by `outerJoinVertices` in place. To do so, we need to provide
    a `VertexRDD` of vertex data type, `U`, to join with and a function that determines
    how to aggregate the vertex data. If we call the RDD to join `other`, this looks
    as follows on paper:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 作为基本图处理功能的最后一个示例，我们现在将看一下给定图的子图以及如何将图形彼此连接。考虑提取我们的图中至少被转发10次的所有Twitter用户的信息的任务。我们已经看到如何从`rtGraph.outDegrees`中获取出度。为了使这些信息在我们的原始图中可访问，我们需要将这些信息连接到原始图中。为此，GraphX提供了`outerJoinVertices`的功能。为了这样做，我们需要提供一个顶点数据类型`U`的`VertexRDD`，以及一个确定如何聚合顶点数据的函数。如果我们称要加入的RDD为`other`，那么在纸上看起来如下：
- en: '[PRE23]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Note that since we carry out an outer join, not all IDs in the original graph
    may have a corresponding value in `other`, which is why we see the `Option` type
    in the respective map function. Doing this for our concrete example at hand works
    as follows:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，由于我们进行了外连接，原始图中的所有ID可能在`other`中没有相应的值，这就是为什么我们在相应的映射函数中看到`Option`类型的原因。对于我们手头的具体例子，这样做的工作方式如下：
- en: '[PRE24]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: We join with our original graph with the out-degree, `VertexRDD`, and as the
    map function, we simply discard the original vertex data and replace it with out-degree.
    If there is no out-degree available, we simply set it to `0` by using `getOrElse`
    to resolve the `Option`.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将我们的原始图与出度`VertexRDD`连接，并将映射函数简单地丢弃原始顶点数据并替换为出度。如果没有出度可用，我们可以使用`getOrElse`将其设置为`0`来解决`Option`。
- en: 'Next, we want to retrieve the subgraph of this graph, in which each vertex
    has at least 10 retweets. A subgraph of a graph consists of a subset of the original
    vertices and edges. Formally, we define a subgraph to be the result of a *predicate *on
    edges, vertices, or both. By this, we mean an expression evaluated on the vertices
    or edges that returns either true or false. The signature of the subgraph method
    on graphs is defined as follows:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们想要检索该图的子图，其中每个顶点至少有10次转发。图的子图由原始顶点和边的子集组成。形式上，我们定义子图为对边、顶点或两者的*谓词*的结果。我们指的是在顶点或边上评估的表达式，返回true或false。图上子图方法的签名定义如下：
- en: '[PRE25]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Note that since the default functions are provided, we can choose to provide
    only one of either `vpred` or `epred`. In our concrete example, we want to restrict
    to vertices with a degree of at least `10`, which can be done as follows:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，由于提供了默认函数，我们可以选择只提供`vpred`或`epred`中的一个。在我们具体的例子中，我们想要限制至少有`10`度的顶点，可以按照以下方式进行：
- en: '[PRE26]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: The resulting graph has a mere `10` vertices and `5` edges, but it's interesting
    to see that these influencers seem to connect to each other in about as much as
    the average.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的图仅有`10`个顶点和`5`条边，但有趣的是这些有影响力的人似乎彼此之间的连接大致与平均水平相当。
- en: 'To close this section, an interesting technique to know is that of *masking*.
    Assume that we now want to know the subgraph of vertices with less than 10 retweets,
    which is somewhat the opposite of the preceding `tenOrMoreRetweets`. Of course,
    this can be done by a subgraph definition, but we can also mask the original graph
    by `tenOrMoreRetweets`, as follows:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 为了结束这一部分，一个有趣的技术是*掩码*。假设我们现在想知道具有少于10次转发的顶点的子图，这与前面的`tenOrMoreRetweets`相反。当然，这可以通过子图定义来实现，但我们也可以通过以下方式掩盖原始图形`tenOrMoreRetweets`。
- en: '[PRE27]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: If we wanted, we could reconstruct `rtGraph` by joining `tenOrMoreRetweets`
    to `lessThanTenRetweets`.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们愿意，我们可以通过将`tenOrMoreRetweets`与`lessThanTenRetweets`连接来重建`rtGraph`。
- en: Building and loading graphs
  id: totrans-152
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建和加载图
- en: In the last section, we made a lot of leeway in graph analytics and discussed
    an interesting retweet graph. Before we dive into more complicated operations,
    let's take a step back and consider other options to construct graphs with GraphX.
    Having completed this interlude, we will have a quick look into visualization
    tools and then turn to the more involved applications.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们在图分析方面取得了很大进展，并讨论了一个有趣的转发图。在我们深入研究更复杂的操作之前，让我们退一步考虑使用GraphX构建图的其他选项。完成了这个插曲后，我们将快速查看可视化工具，然后转向更复杂的应用。
- en: 'In fact, we have already seen two ways to create GraphX graphs, one was to
    construct the vertex and edge RDDs explicitly, ourselves, to construct a graph
    from it; the other one was to use `Graph.fromEdges`. Another very handy possibility
    is to load a so-called *edge list file*. An example of this format is the following:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，我们已经看到了创建GraphX图的两种方法，一种是显式地构建顶点和边RDD，然后从中构建图；另一种是使用`Graph.fromEdges`。另一个非常方便的可能性是加载所谓的*边列表文件*。这种格式的一个例子如下：
- en: '[PRE28]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'So, an edge list file is a text file with pairs of IDs per row, separated by
    a space. Assuming that we store the preceding data as `edge_list.txt` in the current
    working directory, we can load a graph object in one line from it, using the `GraphLoader`
    interface:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，边列表文件是一个文本文件，每行有一对ID，用空格分隔。假设我们将前面的数据存储为`edge_list.txt`在当前工作目录中，我们可以使用`GraphLoader`接口从中一行加载一个图对象：
- en: '[PRE29]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'This represents a very convenient entry point, given that we have data provided
    in the right format. Additional vertex and edge data has to be joined to the resulting
    graph after loading the edge list file, though. Another similar approach to constructing
    a graph from the preceding data is to use the `fromEdgeTuples` method provided
    by the `Graph` object, which can be utilised as shown in the following code snippet:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 这代表了一个非常方便的入口点，因为我们有以正确格式提供的数据。加载边列表文件后，还必须将其他顶点和边数据连接到生成的图中。从前面的数据构建图的另一种类似方法是使用`Graph`对象提供的`fromEdgeTuples`方法，可以像下面的代码片段中所示那样使用：
- en: '[PRE30]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: The difference from the previous construction is that we create a raw-edge RDD,
    containing pairs of vertex IDs, which, together with a default value for vertex
    data, feeds into the construction of the graph.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前的构建不同之处在于，我们创建了一个原始边RDD，其中包含顶点ID对，连同顶点数据的默认值，一起输入到图的构建中。
- en: 'With this last example, we have essentially seen every single way currently
    supported in GraphX to load a graph from the given data. There is, however, also
    the possibility of *generating* random and deterministic graphs, which is very
    helpful for tests, quick sanity checks, and demonstrations. To this end, we import
    the following class:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 通过最后一个例子，我们基本上已经看到了GraphX目前支持的从给定数据加载图的每一种方式。然而，还有*生成*随机和确定性图的可能性，这对于测试、快速检查和演示非常有帮助。为此，我们导入以下类：
- en: '[PRE31]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'This class has a lot of functionality to offer. The two deterministic graph
    construction methods help build *star* and *grid* graphs. A star graph consists
    of a single central vertex and several vertices connecting only to the central
    one by means of one single edge. Here is how to create a star graph with ten vertices
    connecting to the central vertex:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类有很多功能可供使用。两种确定性图构建方法有助于构建*星形*和*网格*图。星形图由一个中心顶点和几个顶点组成，这些顶点只通过一条边连接到中心顶点。以下是如何创建一个有十个顶点连接到中心顶点的星形图：
- en: '[PRE32]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The following image is a graphical representation of a star graph:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图片是星形图的图形表示：
- en: '![](img/00164.jpeg)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00164.jpeg)'
- en: 'Figure 10: A star graph with ten vertices surrounding a central one.'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 图10：一个星形图，有十个顶点围绕着一个中心顶点。
- en: 'The other deterministic method for graph creation builds a grid, meaning that
    the vertices are organised in a matrix, and each vertex connects to its direct
    neighbours both vertically and horizontally. In a grid graph with *n* rows and
    *m* columns, there are precisely *n(m-1) + m(n-1)* edges--the first term is for
    all the vertical connections and the second one is for all the horizontal grid
    connections. This is how to build a `5` times `5` grid with 40 edges in GraphX:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 图的另一种确定性构建方法是构建网格，意味着顶点被组织成一个矩阵，每个顶点都与其直接邻居在垂直和水平方向上连接。在一个有*n*行和*m*列的网格图中，有精确地*n(m-1)
    + m(n-1)*条边--第一项是所有垂直连接，第二项是所有水平网格连接。以下是如何在GraphX中构建一个有40条边的`5`乘`5`网格：
- en: '[PRE33]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '![](img/00165.jpeg)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00165.jpeg)'
- en: 'Figure 11: A quadratic 3 by 3 grid graph with twelve vertices.'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 图11：一个由12个顶点组成的3x3的二次网格图。
- en: As far as random graphs are concerned, we will cover one creation method that
    approximately reflects many real-world graphs structurally, namely *log normal
    graphs*. Many structures found in real life follow a *power law*, in which the
    measure of an entity is given by the power of another. A concrete example for
    this would be the Pareto-principle, often called 80/20 principle, which implies
    that 80% of the wealth is possessed by 20% of the people, that is, most wealth
    is attributed to a few. A variant of this, called *Zipf's law,* applies to our
    scenario, namely a few vertices have very high degree, while most have very little
    connections. In the context of a social graph, very few people tend to have a
    lot of followers, while the majority have very little. This leads to a distribution
    of vertex degrees that follows a *log-normal distribution.* The star graph in
    *Figure 10* is an extreme variant of this behavior, in which all the edges are
    centered around one vertex.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 就随机图而言，我们将介绍一种创建方法，它在结构上大致反映了许多现实世界的图，即*对数正态图*。现实生活中许多结构都遵循*幂律*，其中一个实体的度量由另一个的幂给出。一个具体的例子是帕累托原则，通常称为80/20原则，它意味着80%的财富由20%的人拥有，也就是说，大部分财富归属于少数人。这个原则的一个变体，称为*齐夫定律*，适用于我们的情景，即少数顶点具有非常高的度，而大多数顶点连接很少。在社交图的背景下，很少有人倾向于拥有很多粉丝，而大多数人拥有很少的粉丝。这导致了顶点度数的分布遵循*对数正态分布*。*图10*中的星形图是这种行为的一个极端变体，其中所有的边都集中在一个顶点周围。
- en: 'Creating a log normal graph with 20 vertices in graphX is simply done as follows:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 在GraphX中创建一个具有20个顶点的对数正态图很简单，如下所示：
- en: '[PRE34]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'In the preceding code snippet, we also impose a mean of one out-degree per
    vertex and a standard deviation of three. Let''s see if we can confirm the log-normal
    distribution on vertex out-degree:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述代码片段中，我们还对每个顶点施加了一个平均出度和三个标准差。让我们看看是否可以确认顶点出度的对数正态分布：
- en: '[PRE35]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: This will produce a Scala array that should look as follows.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生一个Scala数组，应该如下所示。
- en: '![](img/00166.jpeg)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00166.jpeg)'
- en: Note that you might get different results, since the graph is randomly generated.
    Next, let's see how to visualize some of the graphs that we have constructed so
    far.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，由于图是随机生成的，您可能会得到不同的结果。接下来，让我们看看如何可视化我们迄今为止构建的一些图。
- en: Visualizing graphs with Gephi
  id: totrans-180
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Gephi可视化图形
- en: 'GraphX does not come with a built-in graph visualization tool, so for us to
    tackle visualizing massive graphs, we have to consider other options. There are
    many general-purpose visualization libraries out there, as well as a few specialized
    graph visualization tools. In this chapter, we choose *Gephi* for essentially
    two reasons:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: GraphX没有内置的图形可视化工具，因此为了处理可视化大规模图形，我们必须考虑其他选项。有许多通用的可视化库，以及一些专门的图形可视化工具。在本章中，我们选择*Gephi*基本上有两个原因：
- en: It is a free open source tool that is available for all the major platforms
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这是一个免费的开源工具，适用于所有主要平台
- en: We can utilise a simple exchange format, GEXF, to persist GraphX graphs, and
    can load them into the Gephi GUI to specify the visualization with it
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以利用一个简单的交换格式GEXF来保存GraphX图，并可以将它们加载到Gephi GUI中，以指定可视化。
- en: While the first point should be universally considered a plus, not everyone
    is a fan of the GUIs and it's certainly more in the spirit of most developers
    to define visualizations programatically. Note that this is in fact also possible
    with Gephi, but more on this later. The reason we chose the mentioned approach
    is to keep the book self-contained and the coding parts about Spark only, by still
    using powerful visualizations provided by Gephi.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然第一个观点应该被普遍认为是一个优点，但并不是每个人都喜欢GUI，对于大多数开发人员来说，以编程方式定义可视化更符合精神。请注意，事实上，使用Gephi也是可能的，但稍后再详细讨论。我们选择上述方法的原因是为了使本书内容自包含，而关于Spark的编码部分仅使用Gephi提供的强大可视化。
- en: Gephi
  id: totrans-185
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Gephi
- en: To get started, download Gephi from [https://gephi.org/](https://gephi.org/) and
    install it locally on your machine. At the time of writing this book, the stable
    version is 0.9.1, which we will use throughout. Upon opening the Gephi application,
    you will be prompted a welcome message and can choose from a few examples to explore.
    We will use `Les Miserables.gexf` to familiarize ourselves with the tool. We will
    discuss the GEXF file format in more detail later; for now, let's just focus on
    the application. The underlying graph data of this example consists of vertices representing
    characters of the piece, *Les Miserables*, and edges denoting the association
    of characters, *weighted* by an assessment of the importance of the connection.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始，请从[https://gephi.org/](https://gephi.org/)下载Gephi并在本地安装在您的机器上。在撰写本书时，稳定版本是0.9.1，我们将在整个过程中使用。打开Gephi应用程序时，您将收到欢迎消息，并可以选择一些示例来探索。我们将使用`Les
    Miserables.gexf`来熟悉工具。我们将在稍后更详细地讨论GEXF文件格式；现在，让我们专注于应用程序。这个例子的基础图数据包括代表作品《悲惨世界》中的角色的顶点，以及表示角色关联的边，*加权*表示连接的重要性评估。
- en: 'Gephi is a very rich tool and we can only discuss a few basics here. Once you
    open the preceding file you should already see a preview of the example graph.
    Gephi has three main views:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: Gephi是一个非常丰富的工具，我们只能在这里讨论一些基础知识。一旦您打开前面的文件，您应该已经看到示例图的预览。Gephi有三个主要视图：
- en: '**Overview**: This is the view in which we can manipulate all the visual attributes
    of the graph and get a preview. For our purposes, this is the most important view,
    and we will discuss it in more detail.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**概述**：这是我们可以操纵图的所有视觉属性并获得预览的视图。对于我们的目的，这是最重要的视图，我们将更详细地讨论它。'
- en: '**Data Laboratory**: This view shows raw graph data in a table format, split
    into *Nodes *and *Edges*, which can also be extended and modified as needed.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据实验室**：此视图以表格格式显示原始图形数据，分为*节点*和*边*，也可以根据需要进行扩展和修改。'
- en: '**Preview**: The preview view is used to see the result, that is, the graph
    visualization, as it can also be exported to various formats, such as SVG, PDF,
    and PNG.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预览**：预览视图用于查看结果，即图形可视化，它也可以导出为各种格式，如SVG、PDF和PNG。'
- en: 'If it is not already active, select Overview to proceed. In the main menu of
    the application, filed under *Window,* you can choose various tabs. Make sure
    to have Graph, Preview Settings, Appearance, Layout, and Statistics open, as indicated
    in the following image:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 如果尚未激活，请选择概述以继续。在应用程序的主菜单中，可以选择各种选项卡。确保打开图形、预览设置、外观、布局和统计，如下图所示：
- en: '![](img/00167.jpeg)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00167.jpeg)'
- en: Figure 12: Gephi's three main views and the essential tabs used in the Overview
    view
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 图12：Gephi的三个主要视图和概述视图中使用的基本选项卡
- en: The Graphtab, in which you should already see a visual representation of the
    sample *les miserables *graph, can be used for final touch-ups and visual inspection.
    For instance, the *Rectangle selection* on the left of the respective window allows
    you to select subgraphs by selecting vertices, whereas with *Drag*, you can move
    around vertices to your aesthetic needs.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: Graphtab可以用于最后的润色和视觉检查，您应该已经看到了样本*悲惨世界*图的视觉表示。例如，窗口左侧的*矩形选择*允许您通过选择顶点来选择子图，而使用*拖动*，您可以根据自己的审美需求移动顶点。
- en: 'In Preview settings, potentially the most interesting tab for us, we can configure
    most of the visual aspects of the graph. Presets allow you to change the general
    style of the graph, such as curved versus straight edges. We will keep the Defaultsetting
    as is. You may have noticed that the graph preview has no vertex or edge labels,
    so it''s impossible to see what each vertex stands for. We can change this by
    selecting *Show Labels *in the *Node Labels* category and then deselecting the *Proportional
    size *checkbox so that all the labels have the same size. If you now go to the Previewview,
    the graph you see should look as shown in the following image:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在*预览设置*中，可能是我们最感兴趣的选项卡，我们可以配置图形的大部分视觉方面。*预设*允许您更改图形的一般样式，例如曲线与直线边。我们将保持*默认*设置不变。您可能已经注意到，图形预览没有顶点或边的标签，因此无法看到每个顶点代表什么。我们可以通过在*节点标签*类别中选择*显示标签*，然后取消选择*比例大小*复选框来更改这一点，以便所有标签具有相同的大小。如果现在转到*预览*视图，您看到的图形应该如下图所示：
- en: '![](img/00168.jpeg)'
  id: totrans-196
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00168.jpeg)'
- en: 'Figure 13: Les miserables example graph, slightly modified with Gephi. Vertices
    are characters of the piece and edges represent importance of connection by means
    of edge thickness. Vertex size is determined by degree and vertices are additionally
    grouped by colour to indicate family membership, the latter of which can''t be
    seen in print.'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 图13：悲惨世界示例图，经过Gephi轻微修改。顶点是作品中的角色，边表示连接的重要性，通过边的粗细表示。顶点大小由度确定，顶点还根据颜色分组以表示家族成员资格，后者在打印中看不到。
- en: Note that the preceding graph comes with visual attributes that we did not specifically
    set. The vertex size is proportional to the vertex degree, the edge thickness
    is determined by the weight, and the graph is color-coded to show which family
    the individual characters belong to. To understand how this is done, we discuss
    the *Appearance *tab next, which also distinguishes between *Nodes *and *Edges*.
    In the top-right corner of this tab, there are four options to choose from, and
    we select *Size*, which is depicted by an icon showing several circles. Having
    done so, we can first select Nodes in the top-left corner and then *Ranking* right
    below it. In the drop-down menu, we can choose an attribute to determine the node
    size by, which, in the preceding example, is *degree. *Similarly, the other two
    attributes discussed previously can be configured.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，前面的图形具有我们没有专门设置的视觉属性。顶点大小与顶点度成比例，边的粗细由权重决定，图形的颜色编码显示了个体角色所属的家族。为了了解这是如何完成的，我们接下来讨论*外观*选项卡，它还区分了*节点*和*边*。在该选项卡的右上角，有四个选项可供选择，我们选择*大小*，它用一个显示几个圆圈的图标表示。这样做后，我们可以首先在左上角选择*节点*，然后在其下方选择*排名*。在下拉菜单中，我们可以选择一个属性来确定节点的大小，前面的例子中是*度*。同样，前面讨论过的另外两个属性也可以配置。
- en: Moving on, the next tab we discuss is *Layout*, in which we can select methods
    to automatically arrange the graph. Interesting layouts to play with are the two
    available *Force Atlas* schemes, which simulate vertices gravitating toward each
    other with configurable vertex attraction and repulsion properties. In *Figure
    13*, no layout was chosen, but it can be interesting to explore them a little.
    Whatever layout you choose, activate them by hitting the Runbutton.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 继续，我们讨论的下一个选项卡是*布局*，在这里我们可以选择自动排列图形的方法。有趣的布局包括两种可用的*力引导*方案，它们模拟顶点相互吸引和排斥的属性。在*图13*中，没有选择布局，但探索一下可能会很有趣。无论您选择哪种布局，都可以通过点击*运行*按钮来激活它们。
- en: Using the *Statistics* tab, we can explore graph properties from within Gephi,
    such as connected components and PageRank. Since we will discuss how to do this
    with GraphX, which is also much more performant, we will just leave it at that,
    although you are encouraged to experiment with the functionality in this tab,
    as it can help build intuition quickly.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 使用*统计*选项卡，我们可以在Gephi内探索图形属性，例如连通分量和PageRank。由于我们将讨论如何在GraphX中执行此操作，而且GraphX的性能也更高，因此我们将就此结束，尽管鼓励您在此选项卡中尝试功能，因为它可以帮助快速建立直觉。
- en: Having configured the attributes to our needs, we can now switch to the Previewview
    to see if the resulting graph is what we expect it to be. Assuming that everything
    worked out, the SVG/PDF/PNGbutton of the Preview settingstab can be used to export
    our final infographic to be used in your product, be it reports, further analyses,
    or other use cases.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们根据需要配置属性后，我们现在可以切换到*预览*视图，看看生成的图形是否符合我们的预期。假设一切顺利，*预览设置*选项卡的SVG/PDF/PNG按钮可以用来导出我们的最终信息图，以供在您的产品中使用，无论是报告、进一步分析还是其他用途。
- en: Creating GEXF files from GraphX graphs
  id: totrans-202
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建GEXF文件从GraphX图
- en: 'To connect the graph visualization capabilities of Gephi with Spark GraphX
    graphs, we need to address a way to communicate between the two. The canonical
    candidate for doing so is Gephi''s **Graph Exchange XML Format** (**GEXF**), a
    description of which can be found at [https://gephi.org/gexf/format/](https://gephi.org/gexf/format/).
    A very simple example of how graphs are described in this format is displayed
    in the following code listing:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 要将Gephi的图形可视化能力与Spark GraphX图形连接起来，我们需要解决两者之间的通信方式。这样做的标准候选者是Gephi的**图形交换XML格式**（**GEXF**），其描述可以在[https://gephi.org/gexf/format/](https://gephi.org/gexf/format/)找到。在以下代码清单中显示了如何以这种格式描述图形的一个非常简单的示例：
- en: '[PRE36]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Apart from the header and the meta data of the XML, the graph encoding itself
    is self-explanatory. It is useful to know that the preceding XML is just the bare
    minimum required for graph descriptions, and in fact, GEXF can be used to encode
    other properties, such as edge weights or even visual attributes that are automatically
    picked up by Gephi.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 除了XML的头部和元数据之外，图形编码本身是不言自明的。值得知道的是，前面的XML只是图形描述所需的最低限度，实际上，GEXF还可以用于编码其他属性，例如边的权重或甚至Gephi自动捕捉的视觉属性。
- en: 'To connect with GraphX, let''s write a little helper function that takes a
    `Graph` version and returns a `String` version of the preceding XML format:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 为了连接GraphX，让我们编写一个小的辅助函数，它接受一个`Graph`版本并返回前面XML格式的`String`版本：
- en: '[PRE37]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'While the code might seem a bit cryptic at first sight, very little is happening.
    We define the header and the footer for the XML. We need to map the edge and vertex
    properties to the `<nodes>` and `<edges>` XML tags. To this end, we use Scala''s
    convenient `${}` notation to ingest variables directly into strings. For a change,
    let''s use this `toGexf` function in a complete Scala app, which uses our simple
    friend graph from earlier. Note that for this to work, it is assumed that `toGexf`
    is available to `GephiApp`. So, either store it in the same object or in another
    file to import it from there. If you want to continue using spark-shell, just
    pasting the imports and the body of the main method, excluding the creation of
    `conf` and `sc`, should work without problems:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然代码乍一看可能有点神秘，但实际上发生的事情很少。我们定义了XML的头部和尾部。我们需要将边和顶点属性映射到`<nodes>`和`<edges>` XML标签。为此，我们使用Scala方便的`${}`符号直接将变量注入到字符串中。改变一下，让我们在一个完整的Scala应用程序中使用这个`toGexf`函数，该应用程序使用了我们之前的简单朋友图。请注意，为了使其工作，假设`toGexf`对`GephiApp`可用。因此，要么将其存储在相同的对象中，要么存储在另一个文件中以从那里导入。如果您想继续使用spark-shell，只需粘贴导入和主方法的主体，不包括创建`conf`和`sc`，应该可以正常工作：
- en: '[PRE38]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'This app stores our friend graph as `graph.gexf`, which we can use to import
    into Gephi. To do so, go to File, then click on *Open* to select this file and
    import the graph. The following diagram shows the result of this procedure by
    tweaking the visual attributes using the tabs and methods described earlier:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 这个应用程序将我们的朋友图存储为`graph.gexf`，我们可以将其导入到Gephi中使用。要这样做，转到“文件”，然后点击“打开”以选择此文件并导入图形。通过使用之前描述的选项卡和方法调整视觉属性，以下图表显示了此过程的结果：
- en: '![](img/00169.jpeg)'
  id: totrans-211
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00169.jpeg)'
- en: 'Figure 14: Our example friend graph displayed using Gephi'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 图14：使用Gephi显示的我们的示例朋友图
- en: As noted earlier, it is indeed possible to define visual attributes programmatically,
    using *Gephi Toolkit*, a Java library you can import into your project. There
    are other language wrappers available, but this is the supported library, available
    as a single JAR. It's far beyond the scope of this book to discuss the toolkit,
    but if you are interested, you can refer to [https://gephi.org/toolkit/](https://gephi.org/toolkit/),
    which serves as a good entry point.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 正如前面所述，确实可以使用*Gephi Toolkit*以编程方式定义视觉属性，这是一个可以导入到项目中的Java库。还有其他语言包装器可用，但这是支持的库，可作为单个JAR文件使用。讨论工具包远远超出了本书的范围，但如果您感兴趣，可以参考[https://gephi.org/toolkit/](https://gephi.org/toolkit/)，这是一个很好的入门点。
- en: Advanced graph processing
  id: totrans-214
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 高级图处理
- en: After a quick interlude into graph generation and visualization, let's turn
    towards more challenging applications and more advanced techniques for graph analytics.
    To recap, what we have done so far in terms of graph processing is just using
    the basic properties of the underlying edge and vertex RDDs of a GraphX graph,
    as well as a few transformations, including `mapVertices`, `mapEdges`, and `mapTriplets`.
    As we have seen, these techniques are already quite useful, but by themselves
    not powerful enough to implement graph-parallel algorithms with. For this purpose,
    GraphX graph has two strong candidates, which we will discuss next. Most of the
    built-in GraphX algorithms, including triangle counting, PageRank and so on, are
    implemented using either one or the other.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 在快速介绍了图生成和可视化之后，让我们转向更具挑战性的应用程序和更高级的图分析技术。总结一下，到目前为止，我们在图处理方面所做的只是使用GraphX图的基本属性，以及一些转换，包括`mapVertices`、`mapEdges`和`mapTriplets`。正如我们所见，这些技术已经非常有用，但单独使用还不足以实现图并行算法。为此，GraphX图有两个强大的候选者，我们将在下一节讨论。包括三角形计数、PageRank等大多数内置的GraphX算法都是使用其中一个或另一个实现的。
- en: Aggregating messages
  id: totrans-216
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 聚合消息
- en: 'First, we discuss the `aggregateMessages` method that GraphX graphs come with.
    The basic idea is to pass messages along edges in parallel across the whole graph,
    aggregate these messages suitably and store the result for further processing.
    Let''s have a closer look at how `aggregateMessages` is defined:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们讨论GraphX图带有的`aggregateMessages`方法。基本思想是在整个图中并行沿着边传递消息，合适地聚合这些消息并将结果存储以供进一步处理。让我们更仔细地看一下`aggregateMessages`是如何定义的：
- en: '[PRE39]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'As you can see, to implement an `aggregateMessages` algorithm we need to specify
    a message type `Msg` and provide three functions, which we will explain next.
    You may notice that there are two additional types that we haven''t encountered
    before, namely `EdgeContext` and `TripletFields`. Simply put, an edge context
    is an extension of `EdgeTriplets` that we have already seen, that is, an edge
    plus all information about adjacent vertices, with the only difference being that
    we can additionally send information to the source and target vertex defined as
    follows:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，要实现`aggregateMessages`算法，我们需要指定消息类型`Msg`并提供三个函数，我们将在下面解释。您可能会注意到我们之前没有遇到的两种额外类型，即`EdgeContext`和`TripletFields`。简而言之，边上下文是我们已经看到的`EdgeTriplets`的扩展，即边加上所有关于相邻顶点的信息，唯一的区别是我们还可以额外发送信息到源顶点和目标顶点，定义如下：
- en: '[PRE40]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '`TripletFields` allows one to restrict the `EdgeContext` fields used in the
    computation, which defaults to all available fields. In fact, in what follows
    we will simply use this default for `tripletFields` and focus on `sendMsg` and
    `mergeMsg` only. As indicated in the introduction to this topic, `sendMsg` is
    used to pass messages along edges, `mergeMsg` aggregates them and we store the
    result of this operation in a vertex RDD of `Msg` type. To make this more concrete,
    consider the following example, an alternative way to compute in-degree for all
    vertices for our little friend graph from earlier:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '`TripletFields`允许限制计算中使用的`EdgeContext`字段，默认为所有可用字段。实际上，在接下来的内容中，我们将简单地使用`tripletFields`的默认值，并专注于`sendMsg`和`mergeMsg`。如本主题的介绍所示，`sendMsg`用于沿着边传递消息，`mergeMsg`对它们进行聚合，并将此操作的结果存储在`Msg`类型的顶点RDD中。为了使这更具体化，考虑以下示例，这是一种计算先前的小伙伴图中所有顶点的入度的替代方法：'
- en: '[PRE41]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: In this example, sending a message is defined by taking an edge context and
    using its `sendToDst` method to send an integer message to each target vertex,
    namely the number one. What this means is that for each edge in parallel we send
    a one to each vertex this edge points to. This way vertices get send messages
    that we need to merge. The `mergeMsg` here should be understood the same way as
    `reduce` for RDDs in general, that is, we specify how two messages are merged
    and this recipe is used to collapse all messages into one. In the example at hand
    we just sum up all messages, which by definition yields the in-degree for each
    vertex. We confirm this by asserting equality of the arrays we get from collecting
    both `inDegVertexRdd` and `friendGraph.inDegrees` on master.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，发送消息是通过使用其`sendToDst`方法从边上下文中定义的，向每个目标顶点发送一个整数消息，即数字1。这意味着并行地，对于每条边，我们向该边指向的每个顶点发送一个1。这样，顶点就会收到我们需要合并的消息。这里的`mergeMsg`应该被理解为RDD中`reduce`的方式，也就是说，我们指定了如何合并两个消息，并且这个方法被用来将所有消息合并成一个。在这个例子中，我们只是将所有消息求和，这根据定义得到了每个顶点的入度。我们通过断言在主节点上收集到的`inDegVertexRdd`和`friendGraph.inDegrees`的数组的相等性来确认这一点。
- en: Note that the return value of `aggregateMessages` is a vertex RDD, not a graph.
    So, using this mechanism iteratively, we need to generate a new graph object in
    each iteration, which is not ideal. Since Spark is especially strong with iterative
    algorithms due to keeping partition data in memory and the fact that a lot of
    interesting graph algorithms are in fact iterative, we next discuss the slightly
    more complicated, but extremely powerful, Pregel API.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`aggregateMessages`的返回值是顶点RDD，而不是图。因此，使用这种机制进行迭代，我们需要在每次迭代中生成一个新的图对象，这并不理想。由于Spark在迭代算法方面特别强大，因为它可以将分区数据保存在内存中，而且许多有趣的图算法实际上都是迭代的，接下来我们将讨论略微复杂但非常强大的Pregel
    API。
- en: Pregel
  id: totrans-225
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Pregel
- en: Pregel is a system internally developed by Google, the companion paper of which
    is very accessible and available for download at [http://www.dcs.bbk.ac.uk/~dell/teaching/cc/paper/sigmod10/p135-malewicz.pdf](http://www.dcs.bbk.ac.uk/~dell/teaching/cc/paper/sigmod10/p135-malewicz.pdf).
    It represents an efficient, iterative graph-parallel compute model that allows
    one to implement a large class of graph algorithms. GraphX's implementation of
    Pregel differs slightly from the preceding paper, but we can't go into any details
    of this.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: Pregel是Google内部开发的系统，其伴随论文非常易于访问，并可在[http://www.dcs.bbk.ac.uk/~dell/teaching/cc/paper/sigmod10/p135-malewicz.pdf](http://www.dcs.bbk.ac.uk/~dell/teaching/cc/paper/sigmod10/p135-malewicz.pdf)上下载。它代表了一种高效的迭代图并行计算模型，允许实现大量的图算法。GraphX对Pregel的实现与前述论文略有不同，但我们无法详细讨论这一点。
- en: In flavor, GraphX's `Pregel` implementation is very close to `aggregateMessages`,
    but has a few key differences. Traits that are shared by both approaches are the
    send and merge message mechanics. On top of that, with Pregel we can define a
    so-called *vertex program* `vprog` that is executed before sending, to transform
    vertex data. Also, we start with a shared initial message on each vertex and can
    specify for how many iterations we want to execute the *vprog-send-merge* cycle,
    that is, iterations are part of the specification.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 在口味上，GraphX的`Pregel`实现与`aggregateMessages`非常接近，但有一些关键的区别。两种方法共享的特征是发送和合并消息机制。除此之外，使用Pregel，我们可以定义一个所谓的*顶点程序*`vprog`，在发送之前执行以转换顶点数据。此外，我们在每个顶点上都有一个共享的初始消息，并且可以指定要执行*vprog-send-merge*循环的迭代次数，也就是说，迭代是规范的一部分。
- en: 'The `apply` method of the Pregel implementation is sketched. Note that it takes
    two sets of inputs, namely a quadruple consisting of the graph itself, an initial
    message, the maximum iterations to be executed and a field called `activeDirection`.
    The last argument deserves some more attention. A detail of the Pregel specification
    we have not talked about yet is that *we only send new messages from vertices
    that have received messages in the previous iteration*. The active direction defaults
    to `Either`, but can also be both, `In` or `Out`. This behavior naturally lets
    algorithms converge in many cases and it also explains why the third argument
    is called `maxIterations` - we might stop earlier than specified:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: Pregel实现的`apply`方法是草图。请注意，它接受两组输入，即由图本身、初始消息、要执行的最大迭代次数和名为`activeDirection`的字段组成的四元组。最后一个参数值得更多关注。我们还没有讨论的Pregel规范的一个细节是，*我们只从在上一次迭代中收到消息的顶点发送新消息*。活动方向默认为`Either`，但也可以是`In`或`Out`。这种行为自然地让算法在许多情况下收敛，并且也解释了为什么第三个参数被称为`maxIterations`
    - 我们可能会比指定的迭代次数提前停止：
- en: '[PRE42]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: The second set of arguments to Pregel is the triple we already sketched, namely
    the vertex program, as well as sending and merging messages functions. The only
    noteworthy difference from before is the signature of `sendMsg`, which returns
    an *iterator over vertex ID and message pairs*. This does not change much for
    us, but interestingly, the signature of `sendMsg` in `aggregateMessage` has been
    such an iterator until Spark 1.6 and was changed to what we discussed previously
    in the update to Spark 2.0\. Very likely, the signature of Pregel will be changed
    accordingly as well, but as of 2.1.1 it remains as described.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: Pregel的第二组参数是我们已经草拟的三元组，即顶点程序，以及发送和合并消息函数。与以前的唯一值得注意的区别是`sendMsg`的签名，它返回一个*顶点ID和消息对的迭代器*。这对我们来说没有太大变化，但有趣的是，在Spark
    1.6之前，`aggregateMessage`中`sendMsg`的签名一直是这样的迭代器，并且在Spark 2.0的更新中已更改为我们之前讨论的内容。很可能，Pregel的签名也会相应地进行更改，但截至2.1.1，它仍然保持原样。
- en: 'To illustrate the possibilities of the Pregel API let''s sketch an implementation
    of an algorithm that computes connected components. This is a slight modification
    of the implementation currently available in GraphX. We define the `ConnectedComponents`
    object with a single following method, namely `run`, which takes any graph and
    a maximum number of iterations. The core idea of the algorithm is easy enough
    to explain. For each edge, whenever its source has a smaller ID than its target,
    send the source ID to the target and vice versa. To aggregate these messages,
    simply take the minimum of all broadcasted values and iterate this procedure long
    enough so that it runs out of updates. At this point, every vertex that is connected
    to another bears the same ID as vertex data, namely the smallest ID available
    in the original graph:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明Pregel API的可能性，让我们草拟一个计算连接组件的算法的实现。这是对GraphX中当前可用的实现的轻微修改。我们定义了`ConnectedComponents`对象，其中有一个名为`run`的方法，该方法接受任何图和最大迭代次数。算法的核心思想很容易解释。对于每条边，每当其源ID小于其目标ID时，将源ID发送到目标ID，反之亦然。为了聚合这些消息，只需取所有广播值的最小值，并迭代此过程足够长，以便它耗尽更新。在这一点上，与另一个顶点连接的每个顶点都具有相同的ID作为顶点数据，即原始图中可用的最小ID：
- en: '[PRE43]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Going step by step, the algorithm does as follows. We first forget all previously
    available vertex data by defining `idGraph`. Next, we define the vertex program
    to emit the minimum of the current vertex data attribute and the current message.
    This way we can store the minimum vertex ID as vertex data. The `sendMsg` method
    propagates the smaller ID for each edge to either source or target, as described
    before and `mergeMsg` again just takes the minimum over IDs. Having these three
    key methods defined, we can simply run `Pregel` on the `idGraph` with `maxIterations`
    as specified. Note that we do not care about which direction the messages flow,
    so we use `EdgeDirection.Either`. Also, we start with the maximum available Long
    value as our initial message, which works since we take the minimum over vertex
    IDs everywhere.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 逐步进行，算法的步骤如下。首先，我们通过定义`idGraph`来忘记所有先前可用的顶点数据。接下来，我们定义顶点程序以发出当前顶点数据属性和当前消息的最小值。这样我们就可以将最小顶点ID存储为顶点数据。`sendMsg`方法将较小的ID传播到源或目标的每条边上，如前所述，`mergeMsg`再次只是取ID的最小值。定义了这三个关键方法后，我们可以简单地在指定的`maxIterations`上运行`idGraph`上的`Pregel`。请注意，我们不关心消息流向的方向，因此我们使用`EdgeDirection.Either`。此外，我们从最大可用的Long值作为我们的初始消息开始，这是有效的，因为我们在顶点ID上取最小值。
- en: 'Having defined this allows us to find connected components on the retweet graph
    `rtGraph` from earlier as follows, choosing five iterations as maximum:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 定义了这一点使我们能够在先前的转发图`rtGraph`上找到连接的组件，如下所示，选择五次迭代作为最大值：
- en: '[PRE44]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Counting distinct vertex data items of the resulting graph gives us the number
    of connected components (in this case it is just one component), that is, all
    tweets in the data set are connected if we forget directionality. It is interesting
    to note that we do in fact need five iterations for the algorithm to converge.
    Running it with fewer iterations, that is, 1, 2, 3 or 4, yields 1771, 172, 56
    and 4 connected components. Since there has to be at least one connected component,
    we know that further increasing iterations would not change the outcome. However,
    in general we would rather not specify the number of iterations, unless time or
    computing power are an issue. By wrapping the preceding run method as follows,
    we can run this algorithm on graphs only, without explicitly providing iterations:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 对结果图的不同顶点数据项进行计数，可以得到连接组件的数量（在这种情况下只有一个组件），也就是说，如果忘记方向性，数据集中的所有推文都是连接的。有趣的是，我们实际上需要五次迭代才能使算法收敛。使用更少的迭代次数运行它，即1、2、3或4，会得到1771、172、56和4个连接组件。由于至少有一个连接组件，我们知道进一步增加迭代次数不会改变结果。然而，一般情况下，我们宁愿不指定迭代次数，除非时间或计算能力成为问题。通过将前面的run方法包装如下，我们可以在图上运行此算法，而无需显式提供迭代次数：
- en: '[PRE45]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Simply add this as an additional method to the `ConnectedComponents` object.
    For the retweet graph, we can now simply write instead. Having seen both `aggregateMessages`
    and Pregel, the reader should now be adequately equipped to develop their own
    graph algorithms:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 只需将此作为`ConnectedComponents`对象的附加方法。对于转发图，我们现在可以简单地编写。看过`aggregateMessages`和Pregel后，读者现在应该足够有能力开发自己的图算法：
- en: '[PRE46]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: GraphFrames
  id: totrans-240
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GraphFrames
- en: Note that so far, to compute any interesting indicators on a given graph, we
    had to use the compute model of the graph, an extension of what we know from RDDs.
    With Spark's DataFrame or Dataset concept in mind, the reader may wonder if there
    is any possibility to use an SQL-like language to do run queries against a graph
    for analytics. Query languages often provide a convenient way to get results quickly.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，为了计算给定图上的任何有趣的指标，我们必须使用图的计算模型，这是我们从RDDs所知的扩展。考虑到Spark的DataFrame或Dataset概念，读者可能会想知道是否有可能使用类似SQL的语言来对图进行分析运行查询。查询语言通常提供了一种快速获取结果的便捷方式。
- en: This is indeed possible with GraphFrames. The library was developed by Databricks
    and serves as natural extension of GraphX graphs to Spark DataFrames. Unfortunately,
    GraphFrames are not part of Spark GraphX, but instead available as Spark package.
    To load GraphFrames upon starting spark-submit, simply run
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: GraphFrames确实可以做到这一点。该库由Databricks开发，并作为GraphX图的自然扩展到Spark DataFrames。不幸的是，GraphFrames不是Spark
    GraphX的一部分，而是作为Spark软件包提供的。要在启动spark-submit时加载GraphFrames，只需运行
- en: '`spark-shell --packages graphframes:graphframes:0.5.0-spark2.1-s_2.11`'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '`spark-shell --packages graphframes:graphframes:0.5.0-spark2.1-s_2.11`'
- en: 'and suitably adapt preceding version numbers for both your preferred Spark
    and Scala versions. Converting a GraphX Graph to a `GraphFrame` and vice versa
    is as easy as it gets; in the following we convert our friend graph from earlier
    to a `GraphFrame` and then back:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 并适当调整您首选的Spark和Scala版本的先前版本号。将GraphX图转换为`GraphFrame`，反之亦然，就像变得那么容易；在接下来，我们将我们之前的朋友图转换为`GraphFrame`，然后再转换回来：
- en: '[PRE47]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: As indicated before, one added benefit of GraphFrames is that you can use Spark
    SQL with them, as they are built on top of DataFrames. This also means that GraphFrames
    are much faster than Graphs, since the Spark core team has brought a lot of speed
    gains to DataFrames through their catalyst and tungsten frameworks. Hopefully
    we see GraphFrames added to Spark GraphX in one of the next releases.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，GraphFrames的一个附加好处是您可以与它们一起使用Spark SQL，因为它们是建立在DataFrame之上的。这也意味着GraphFrames比图快得多，因为Spark核心团队通过他们的catalyst和tungsten框架为DataFrame带来了许多速度提升。希望我们在接下来的发布版本中看到GraphFrames添加到Spark
    GraphX中。
- en: 'Instead of looking at a Spark SQL example, which should be familiar enough
    from previous chapters, we consider another query language available for GraphFrames,
    that has a very intuitive compute model. GraphFrames has borrowed the *Cypher*
    SQL dialect from the graph database *neo4j*, which can be used for very expressive
    queries. Continuing with the `friendGraphFrame`, we can very easily find all length
    two paths for which either end in the vertex "Chris" or pass through the edge
    "trusts" first by using one concise command:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不再看Spark SQL示例，因为这应该已经在之前的章节中很熟悉了，我们考虑GraphFrames可用的另一种查询语言，它具有非常直观的计算模型。GraphFrames从图数据库*neo4j*中借用了*Cypher*
    SQL方言，可以用于非常表达式的查询。继续使用`friendGraphFrame`，我们可以非常容易地找到所有长度为2的路径，这些路径要么以顶点"Chris"结尾，要么首先通过边"trusts"，只需使用一个简洁的命令：
- en: '[PRE48]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Note how we can specify the graph structure in a manner that lets you think
    in terms of the actual graph, that is, we have two edges *e1* and *e2*, that are
    connected to each other by a common vertex *v2*. The result of this operation
    is listed in the following screenshot, which indeed gives back the three paths
    that suffice the preceding condition:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 注意我们可以以一种让您以实际图的方式思考的方式指定图结构，也就是说，我们有两条边*e1*和*e2*，它们通过一个共同的顶点*v2*连接在一起。此操作的结果列在以下屏幕截图中，确实给出了满足前述条件的三条路径：
- en: '![](img/00170.jpeg)'
  id: totrans-250
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00170.jpeg)'
- en: Unfortunately, we can not discuss GraphFrames here in more detail, but the interested
    reader is referred to the documentation available at [https://graphframes.github.io/](https://graphframes.github.io/) for
    more details. Instead, we will now turn to the algorithms available in GraphX
    and apply them to a massive graph of actor data.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，我们无法在这里更详细地讨论GraphFrames，但感兴趣的读者可以参考[https://graphframes.github.io/](https://graphframes.github.io/)上的文档获取更多详细信息。相反，我们现在将转向GraphX中可用的算法，并将它们应用于大规模的演员数据图。
- en: Graph algorithms and applications
  id: totrans-252
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图算法和应用
- en: For this application section, in which we will discuss triangle counting, (strongly)
    connected components, PageRank and other algorithms available in GraphX, we will
    load another interesting graph dataset from [http://networkrepository.com/](http://networkrepository.com/).
    This time please download data from [http://networkrepository.com/ca-hollywood-2009.php](http://networkrepository.com/ca-hollywood-2009.php),
    which consists of an undirected graph whose vertices represent actors occurring
    in movies. Each line of the file contains two vertex IDs representing an edge,
    meaning that these actors appeared together in a movie.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个应用程序部分中，我们将讨论三角形计数、（强）连通组件、PageRank和GraphX中可用的其他算法，我们将从[http://networkrepository.com/](http://networkrepository.com/)加载另一个有趣的图数据集。这次，请从[http://networkrepository.com/ca-hollywood-2009.php](http://networkrepository.com/ca-hollywood-2009.php)下载数据，该数据集包含一个无向图，其顶点表示出现在电影中的演员。文件的每一行包含两个顶点ID，表示这些演员在一部电影中一起出现。
- en: 'The dataset consists of about 1.1 million vertices and has 56.3 million edges.
    Although the file size, even after unzipping, is not particularly large, a graph
    of this size is a real challenge for a graph processing engine. Since we assume
    you work with Spark''s standalone mode locally, this graph will likely not fit
    into your computer''s memory and will crash the Spark application. To prevent
    this, let''s restrict the data a little, which also gives us the chance to clean
    up the file header. We assume you have unpacked `ca-hollywood-2009.mtx` and stored
    it in your current working directory. We use unix tools *tail* and *head* to delete
    the first two lines and then restrict to the first million edges:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集包括约110万个顶点和5630万条边。尽管文件大小即使解压后也不是特别大，但这样大小的图对于图处理引擎来说是一个真正的挑战。由于我们假设您在本地使用Spark的独立模式工作，这个图很可能不适合您计算机的内存，并且会导致Spark应用程序崩溃。为了防止这种情况发生，让我们稍微限制一下数据，这也给了我们清理文件头的机会。我们假设您已经解压了`ca-hollywood-2009.mtx`并将其存储在当前工作目录中。我们使用unix工具*tail*和*head*删除前两行，然后限制到前一百万条边：
- en: '`tail -n+3 ca-hollywood-2009.mtx | head -1000000 > ca-hollywood-2009.txt`'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: '`tail -n+3 ca-hollywood-2009.mtx | head -1000000 > ca-hollywood-2009.txt`'
- en: 'If these tools should not be available to you, any other will do, including
    manually modifying the file. From the structure described previously we can simply use
    `edgeListFile` functionality to load the graph into Spark and confirm that it indeed
    has a million edges:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这些工具对您不可用，任何其他工具都可以，包括手动修改文件。从前面描述的结构中，我们可以简单地使用`edgeListFile`功能将图加载到Spark中，并确认它确实有一百万条边：
- en: '[PRE49]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: Next, let's see what we can do with GraphX to analyze this graph.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们看看GraphX能够如何分析这个图。
- en: Clustering
  id: totrans-259
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 聚类
- en: 'Given a graph, a natural question to ask is if there are any subgraphs to it
    that naturally belong together, that is, that cluster the graph in some way. This
    question can be addressed in many ways, one of which we have already implemented
    ourselves, namely by studying connected components. Instead of using our own implementation,
    let''s use GraphX''s built-in version this time. To do so, we can simply call
    `connectedComponents` directly on the graph itself:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一个图，一个自然的问题是是否有任何子图与之自然地相连，也就是说，以某种方式对图进行聚类。这个问题可以用许多种方式来解决，其中我们已经自己实现了一种，即通过研究连接的组件。这次我们不使用我们自己的实现，而是使用GraphX的内置版本。为此，我们可以直接在图本身上调用`connectedComponents`：
- en: '[PRE50]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'As in our own implementation, the vertex data of the graph contains cluster
    IDs, which correspond to the minimum available vertex ID within the cluster. This
    allows us to directly count connected components, by collecting distinct cluster
    IDs. The answer for our restricted cluster graph is 173\. Computing components,
    we cache the graph so we can further use it for other computations. For instance,
    we might ask how large the connected components are, for example by computing
    the maximum and the minimum cluster size in terms of vertices. We can do this
    by using the cluster ID as key and reducing each group by counting its items:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 与我们自己的实现一样，图的顶点数据包含集群ID，这些ID对应于集群中可用的最小顶点ID。这使我们能够直接计算连接的组件，通过收集不同的集群ID。我们受限制的集群图的答案是173。计算组件后，我们缓存图，以便可以进一步用于其他计算。例如，我们可能会询问连接的组件有多大，例如通过计算顶点数量的最大值和最小值来计算。我们可以通过使用集群ID作为键，并通过计算每个组的项数来减少每个组来实现这一点：
- en: '[PRE51]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: It turns out the largest cluster spans a respectable group of 193,518 actors,
    while the smallest consists of a mere three actors. Next, let's ignore the fact
    that the graph in question does not actually have directionality, since appearing
    in a movie together is symmetric, and act as if the edge pairs were directed.
    We don't have to impose anything here, since an edge in Spark GraphX always has
    a source and a target. This allows us to study *strongly *connected components
    as well. We can call this algorithm similarly to that for connected components,
    but in this case we have to specify a number of iterations as well. The reason
    for this is that it's much more computationally demanding to "trace" directed
    edges in the same way we did for connected components and convergence is slower.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 结果表明，最大的集群包含了一个庞大的193,518名演员，而最小的集群只有三名演员。接下来，让我们忽略这样一个事实，即所讨论的图实际上没有方向性，因为一起出现在电影中是对称的，并且假装边对是有方向性的。我们不必在这里强加任何东西，因为在Spark
    GraphX中，边始终具有源和目标。这使我们也能够研究*强*连接的组件。我们可以像对连接的组件那样调用这个算法，但在这种情况下，我们还必须指定迭代次数。原因是在“追踪”有向边方面，与我们对连接的组件和收敛速度相比，计算要求更高，收敛速度更慢。
- en: 'Let''s settle for just one iteration to carry out the computation, since it
    is very expensive:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们只进行一次迭代来进行计算，因为这非常昂贵：
- en: '[PRE52]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: This computation might take a few minutes to complete. In case you have problems
    running even this example on your machine, consider further restricting `actorGraph`.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 这个计算可能需要几分钟才能完成。如果您在您的机器上运行甚至这个例子时遇到问题，请考虑进一步限制`actorGraph`。
- en: 'Next, let''s compute triangles for the actor graph, yet another way to cluster
    it. To do so, we need to slightly prepare the graph, namely we have to *canonicalize *the
    edges and specify a *graph partition strategy. *To canonicalize a graph means
    to get rid of loops and duplicate edges and make sure that the source ID is always
    smaller than the target ID for all the edges:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们为演员图计算三角形，这是另一种对其进行聚类的方法。为此，我们需要稍微准备一下图，也就是说，我们必须*规范化*边并指定*图分区策略*。规范化图意味着摆脱循环和重复边，并确保对于所有边，源ID始终小于目标ID：
- en: '[PRE53]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: Graph partition strategies, like RDD partitions we have already encountered,
    are concerned with the question of how to distribute a graph across the cluster
    efficiently. Of course, what efficiently means depends in large part on what we
    do with our graph. Roughly speaking, there are two basic partition strategies,
    namely *vertex cut* and *edge cut*. Vertex cut strategy means enforce split edges
    in a disjointed manner by cutting vertices, that is, vertices are repeated across
    partitions, if necessary. Edge cut strategy does the opposite in that vertices
    are unique throughout the cluster, but we may duplicate edges. GraphX has four
    partition strategies that are all based on vertex cut.  We will not discuss them
    here in detail, but rather just use `RandomVertexCut`, which hashes vertex IDs
    so that all same-direction edges between vertices are located on the same partition.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 图分区策略，就像我们已经遇到的RDD分区一样，关注的是如何有效地在集群中分发图。当然，有效意味着在很大程度上取决于我们对图的处理方式。粗略地说，有两种基本的分区策略，即*顶点切割*和*边切割*。顶点切割策略意味着通过切割顶点来强制以不相交的方式分割边，也就是说，如果需要，顶点会在分区之间重复。边切割策略则相反，其中顶点在整个集群中是唯一的，但我们可能会复制边。GraphX有四种基于顶点切割的分区策略。我们不会在这里详细讨论它们，而是只使用`RandomVertexCut`，它对顶点ID进行哈希处理，以便使顶点之间的所有同向边位于同一分区。
- en: Note that when creating a graph without specifying a partition strategy, the
    graph is distributed by simply adopting the structure of the underlying EdgeRDD
    that has been provided for construction. Depending on your use-case, this might
    not be ideal, for instance because edge partitions might be strongly imbalanced.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，当创建图时没有指定分区策略时，图会通过简单地采用已提供用于构建的底层EdgeRDD的结构来进行分发。根据您的用例，这可能不是理想的，例如因为边的分区可能非常不平衡。
- en: 'To partition `canonicalGraph` and continue with triangle counting, we now partition
    our graph using said strategy as follows:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 为了对`canonicalGraph`进行分区并继续进行三角形计数，我们现在使用上述策略对我们的图进行分区，如下所示：
- en: '[PRE54]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Computing triangles is conceptually simple. We first collect all neighboring
    vertices for each vertex and then compute the intersection of these sets for each
    edge. The logic is, if both source and target vertex sets contain the same third
    vertex, the three form a triangle. As a last step, we send the *count of the intersection
    set* to both source and target, thereby counting each triangle twice and we simply
    divide by two to get a triangle count per vertex. Doing the triangle count now
    boils down to running:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 计算三角形在概念上是很简单的。我们首先收集每个顶点的所有相邻顶点，然后计算每条边的这些集合的交集。逻辑是，如果源顶点和目标顶点集合都包含相同的第三个顶点，则这三个顶点形成一个三角形。作为最后一步，我们将*交集集合的计数*发送到源和目标，从而将每个三角形计数两次，然后我们简单地除以二得到每个顶点的三角形计数。现在进行三角形计数实际上就是运行：
- en: '[PRE55]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'In fact, instead of canonicalising `actorGraph` explicitly, we could simply
    have gotten away with just imposing `triangleCount` directly on the initial graph,
    that is, by computing the following:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，我们可以不需要显式地规范化`actorGraph`，而是可以直接在初始图上直接施加`triangleCount`，也就是通过计算以下内容：
- en: '[PRE56]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Equivalently, we can also import `TriangleCount` and call it on our actor graph
    as follows:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，我们也可以导入`TriangleCount`并在我们的actor图上调用它，如下所示：
- en: '[PRE57]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: Note, however, that these last two equivalent operations will in fact canonicalize
    the graph in question the same way we did, and canonicalisation is a computationally
    very expensive operation. So, whenever you see the chance to already load your
    graph in canonical form, the first approach shown will be more efficient.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，需要注意的是，这两个等价操作实际上将以相同的方式规范化所讨论的图，而规范化是一个计算上非常昂贵的操作。因此，每当你看到已经以规范形式加载图的机会时，第一种方法将更有效。
- en: Vertex importance
  id: totrans-281
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 顶点重要性
- en: In a graph of friends connected to each other, an interesting question to ask
    is who the most influential person in the group is. Is it the person with the
    most connections, that is, the vertex with the highest degree? For directed graphs,
    in-degree might be a good first guess. Or is it rather the person who knows a
    selected few people who themselves have a lot of connections? There are certainly
    many ways to describe how important or authoritative a vertex is and the concrete
    answer will depend on the problem domain a lot, as well as on what additional
    data we are given with the graph. Moreover, in the example we have given, for
    a specific person in the graph another person might be the most influential for
    their own, very subjective reasons.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个相互连接的朋友图中，一个有趣的问题是谁是群体中最有影响力的人。是拥有最多连接的人，也就是具有最高度的顶点吗？对于有向图，入度可能是一个很好的第一猜测。或者更确切地说，是那些认识一些人，而这些人本身又有很多连接的人？肯定有很多方法来描述一个顶点的重要性或权威性，具体的答案将在很大程度上取决于问题域，以及我们在图中附加的其他数据。此外，在我们给出的例子中，对于图中的特定人物，另一个人可能因为他们自己非常主观的原因而是最有影响力的。
- en: Still, seeking for vertex importance in a given graph is a challenging problem,
    and one historically important example of such an algorithm is *PageRank*, which
    was described back in 1998 in the seminal paper "The Anatomy of a Large-Scale
    Hypertextual Web Search Engine" available at  [http://ilpubs.stanford.edu:8090/361/1/1998-8.pdf](http://ilpubs.stanford.edu:8090/361/1/1998-8.pdf).
     In it, Sergey Brin and Larry Page laid the foundations of what ran their search
    engine Google when the company had just started out. While PageRank had a significant
    impact on finding relevant search results in the vast graph of web pages connected
    by links, the algorithm has since been replaced by other approaches within Google
    over the years. However, PageRank remains a prime example of how to rank web pages,
    or graphs in general, to gain a deeper understanding of it. GraphX provides an
    implementation of PageRank, which we will have a look at after describing the
    algorithm itself.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 寻找给定图中顶点的重要性是一个具有挑战性的问题，一个历史上重要的算法示例是*PageRank*，它在1998年的开创性论文"The Anatomy of
    a Large-Scale Hypertextual Web Search Engine"中被描述，可以在[http://ilpubs.stanford.edu:8090/361/1/1998-8.pdf](http://ilpubs.stanford.edu:8090/361/1/1998-8.pdf)上找到。在这篇论文中，Sergey
    Brin和Larry Page奠定了他们的搜索引擎Google在公司刚刚起步时运行的基础。虽然PageRank对于在由链接连接的庞大网页图中找到相关的搜索结果产生了重大影响，但这个算法在多年来已经被Google内部的其他方法所取代。然而，PageRank仍然是如何对网页或图进行排名的一个主要示例，以获得更深入的理解。GraphX提供了PageRank的实现，在描述算法本身之后我们将对其进行介绍。
- en: PageRank is an iterative algorithm for directed graphs that is initialized by
    setting the same value to each vertex, namely *1/N* where *N* denotes the order
    of the graph, that is, the number of vertices. It then repeats the same procedure
    of updating vertex values, that is, their PageRank, until we choose to stop or
    certain convergence criteria is fulfilled. More specifically, in each iteration
    a vertex sends its *current PageRank divided by its out-degree* to all vertices
    it has an outbound connection to, that is, it distributes its current PageRank
    evenly over all outbound edges. Vertices then sum up all the values they receive
    to set their new PageRank. If overall PageRanks did not change much in the last
    iteration, stop the procedure. This is the very basic formulation of the algorithm
    and we will further specify the stopping criterion when discussing the GraphX
    implementation.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: PageRank是一个针对有向图的迭代算法，通过将相同的值*1/N*初始化为每个顶点的值，其中*N*表示图的阶数，也就是顶点的数量。然后，它重复相同的更新顶点值的过程，也就是它们的PageRank，直到我们选择停止或满足某些收敛标准。更具体地说，在每次迭代中，一个顶点将其*当前PageRank除以其出度*发送到所有它有出站连接的顶点，也就是说，它将其当前PageRank均匀分布到所有出站边上。然后顶点们将接收到的所有值相加以设置它们的新PageRank。如果整体PageRank在上一次迭代中没有发生太大变化，则停止该过程。这是算法的非常基本的公式，我们将在讨论GraphX实现时进一步指定停止标准。
- en: However, we also need to slightly extend the baseline algorithm by introducing
    a *damping factor d*. The damping factor was invented to prevent so called *rank
    sinks*. Imagine a strongly connected component that has only incoming edges from
    the rest of the graph, then by preceding prescription this component will accumulate
    more and more PageRank through incoming edges in each iteration, but never "release"
    any of it through outbound connections. This scenario is called a rank sink and
    to get rid of it we need to introduce more *rank sources* through damping*.* What
    PageRank does is simulate the idealistic idea of a completely random user following
    links probabilistically with likelihood given by the link target's PageRank. The
    idea of damping changes this by introducing a chance of probability d the user
    follows their current path, and with likelihood (*1-d*), gets bored and continues
    reading a completely different page.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们还需要通过引入*阻尼因子d*稍微扩展基线算法。阻尼因子是为了防止所谓的*排名汇*。想象一个强连接组件，它只有来自图的其余部分的入边，那么按照前面的规定，这个组件将在每次迭代中通过入边积累越来越多的PageRank，但从不通过出边“释放”任何PageRank。这种情况被称为排名汇，为了摆脱它，我们需要通过阻尼引入更多的*排名源*。PageRank所做的是模拟一个完全随机的用户，以链接目标的PageRank给出的概率随机地跟随链接。阻尼的概念改变了这一点，引入了一个概率d的机会，用户按照他们当前的路径前进，并以概率(*1-d*)继续阅读一个完全不同的页面。
- en: 'In our rank sink example above the user would leave the strongly connected
    component and end up somewhere else in the graph, thereby increasing relevance,
    that is, PageRank, of other parts of the graph. To wrap up this explanation, the
    PageRank update rule with damping can be written as follows:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的排名示例中，用户将离开强连接组件，然后在图中的其他地方停留，从而增加了其他部分的相关性，也就是PageRank。为了总结这个解释，带有阻尼的PageRank更新规则可以写成如下形式：
- en: '![](img/00171.jpeg)'
  id: totrans-287
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00171.jpeg)'
- en: that is, to update PageRank *PR* for vertex *v*, we sum over the PageRank of
    all inbound vertices *w* divided by their respective out-degree *out(w)*.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 也就是说，为了更新顶点*v*的PageRank *PR*，我们对所有入边顶点*w*的PageRank除以它们各自的出度*out(w)*求和。
- en: 'Spark GraphX has two implementations for PageRank, one called static, the other
    dynamic. In the static version, we simply carry out the preceding update rule
    for a fixed amount of iterations `numIter` specified upfront. In the dynamic version,
    we specify a *tolerance* `tol` for convergence, namely that a vertex drops out
    of the computation if its PageRank did not change at least by `tol` in the last
    iteration, which means it will neither emit new PageRanks nor update its own anymore.
    Let''s compute PageRank in both static and dynamic versions for the tiny `friendGraph`.
    The static version with 10 iterations is called as follows:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: Spark GraphX有两种PageRank的实现，一种称为静态，另一种称为动态。在静态版本中，我们只需对预先指定的固定次数`numIter`执行前面的更新规则。在动态版本中，我们为收敛指定了一个*容差*`tol`，即如果顶点在上一次迭代中其PageRank至少没有变化`tol`，那么它将退出计算，这意味着它既不会发出新的PageRanks，也不会再更新自己。让我们为微小的`friendGraph`计算静态和动态版本的PageRank。使用10次迭代的静态版本如下调用：
- en: '[PRE58]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'After running the algorithm, we simply collect all vertices on master and print
    them, which yields the following:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 运行算法后，我们只需在主节点上收集所有顶点并打印它们，得到以下结果：
- en: '[PRE59]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'It''s interesting to see how PageRanks change with varying numbers of iterations;
    see the following table for details:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 看到PageRanks随着迭代次数的变化而变化是很有趣的；请参阅以下表格以获取详细信息：
- en: '| **numIter / vertex** | **Anne** | **Bernie** | **Chris** | **Don** | **Edgar**
    |'
  id: totrans-294
  prefs: []
  type: TYPE_TB
  zh: '| **numIter / vertex** | **Anne** | **Bernie** | **Chris** | **Don** | **Edgar**
    |'
- en: '| 1 | 0.213 | 0.213 | 0.341 | 0.277 | 0.213 |'
  id: totrans-295
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 0.213 | 0.213 | 0.341 | 0.277 | 0.213 |'
- en: '| 2 | 0.267 | 0.240 | 0.422 | 0.440 | 0.267 |'
  id: totrans-296
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 0.267 | 0.240 | 0.422 | 0.440 | 0.267 |'
- en: '| 3 | 0.337 | 0.263 | 0.468 | 0.509 | 0.337 |'
  id: totrans-297
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 0.337 | 0.263 | 0.468 | 0.509 | 0.337 |'
- en: '| 4 | 0.366 | 0.293 | 0.517 | 0.548 | 0.366 |'
  id: totrans-298
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 0.366 | 0.293 | 0.517 | 0.548 | 0.366 |'
- en: '| 5 | 0.383 | 0.305 | 0.554 | 0.589 | 0.383 |'
  id: totrans-299
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 0.383 | 0.305 | 0.554 | 0.589 | 0.383 |'
- en: '| 10 | 0.429 | 0.330 | 0.610 | 0.665 | 0.429 |'
  id: totrans-300
  prefs: []
  type: TYPE_TB
  zh: '| 10 | 0.429 | 0.330 | 0.610 | 0.665 | 0.429 |'
- en: '| 20 | 0.438 | 0.336 | 0.622 | 0.678 | 0.438 |'
  id: totrans-301
  prefs: []
  type: TYPE_TB
  zh: '| 20 | 0.438 | 0.336 | 0.622 | 0.678 | 0.438 |'
- en: '| 100 | 0.438 | 0.336 | 0.622 | 0.678 | 0.483 |'
  id: totrans-302
  prefs: []
  type: TYPE_TB
  zh: '| 100 | 0.438 | 0.336 | 0.622 | 0.678 | 0.483 |'
- en: 'While the general tendency of which vertex is more important than the other,
    that is, the relative ranking of the vertices is already established after only
    two iterations, note that it takes about 20 iterations for the PageRanks to stabilize
    even for this tiny graph. So, if you are only interested in ranking vertices roughly
    or it is simply too expensive to run the dynamic version, the static algorithm
    can come in handy. To compute the dynamic version, we specify the tolerance `tol`
    to be `0.0001` and the so called `resetProb` to `0.15`. The latter is nothing
    but *1-d*, that is, the probability to leave the current path and pop up at a
    random vertex in the graph. In fact, `0.15` is the default value for `resetProb`
    and reflects the suggestion of the original paper:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然在只有两次迭代后，哪个顶点比其他顶点更重要的一般趋势已经确定，但请注意，即使对于这个微小的图形，PageRanks稳定下来也需要大约20次迭代。因此，如果您只对粗略排名顶点感兴趣，或者运行动态版本太昂贵，静态算法可以派上用场。要计算动态版本，我们将容差`tol`指定为`0.0001`，将所谓的`resetProb`指定为`0.15`。后者不过是*1-d*，也就是说，离开当前路径并在图中的随机顶点出现的概率。实际上，`0.15`是`resetProb`的默认值，并反映了原始论文的建议：
- en: '[PRE60]'
  id: totrans-304
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Running this yields the following PageRank values, displayed in *Figure 15*.
    The numbers should look familiar, as they are the same as from the static version
    with 20 or more iterations:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 运行这个程序会产生以下的PageRank值，显示在*图15*中。这些数字应该看起来很熟悉，因为它们与具有20次或更多迭代的静态版本相同：
- en: '![](img/00172.jpeg)'
  id: totrans-306
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00172.jpeg)'
- en: 'Figure 15: PageRanks computed for our toy friend graph, using the dynamic GraphX
    implementation.'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 图15：使用动态GraphX实现计算的我们的玩具朋友图的PageRanks。
- en: 'For a more interesting example, let''s turn to the actor graph once more. With
    the same tolerance as in the preceding example, we can quickly find the vertex
    ID with the highest PageRank:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 对于一个更有趣的例子，让我们再次转向演员图。使用与前面示例中相同的容差，我们可以快速找到具有最高PageRank的顶点ID：
- en: '[PRE61]'
  id: totrans-309
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'This returns ID 33024 with a PageRank of 7.82\. To highlight how PageRank differs
    from the naive idea of simply taking in-degree as shot at vertex importance, consider
    the following analysis:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 这返回ID 33024，PageRank为7.82。为了突出PageRank与简单地将入度作为顶点重要性的想法有何不同，考虑以下分析：
- en: '[PRE62]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Restricting to the vertex ID in question and checking its in-degree results
    in 62 incoming edges. Let''s see what the top ten highest in-degrees in the graph
    are:'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 限制为所讨论的顶点ID并检查其入度结果为62个入边。让我们看看图中最高的十个入度是什么：
- en: '[PRE63]'
  id: totrans-313
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'This results in `Array(704, 733, 746, 756, 762, 793, 819, 842, 982, 1007)`,which
    means the vertex with the highest PageRank does not even come close to having
    among the highest in-degrees. In fact, there is a total of 2167 vertices that
    have at least `62` inbound edges, as can be seen by running:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 这导致`Array(704, 733, 746, 756, 762, 793, 819, 842, 982, 1007)`，这意味着具有最高PageRank的顶点甚至没有接近具有最高入度的顶点。事实上，总共有2167个顶点至少有62个入边，可以通过运行以下命令来查看：
- en: '[PRE64]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: So, while this still means the vertex is in the top 2% of all vertices in terms
    of in-degree, we see that PageRank yields a completely different answer from other
    approaches.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，虽然这仍然意味着该顶点在入度方面处于所有顶点的前2%，但我们看到PageRank得出了与其他方法完全不同的答案。
- en: GraphX in context
  id: totrans-317
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GraphX的上下文
- en: Having seen a lot of applications of graph analytics throughout the chapter,
    a natural question to follow up with is how GraphX fits into other parts of the
    Spark ecosphere and how we can use it for machine learning applications in conjunction
    with systems like MLlib, which we have seen earlier.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 在整个章节中看到了许多图分析的应用之后，一个自然的问题是GraphX如何适应Spark生态系统的其他部分，以及我们如何将其与之前看到的MLlib等系统一起用于机器学习应用。
- en: The quick answer is that while the concept of graphs is limited to Spark GraphX
    only, due to the underlying vertex and edge RDDs of a graph, we can seamlessly talk
    to any other module of Spark. In fact, we have used many core RDD operations throughout
    the chapter, but it does not stop there. MLlib does make use of GraphX functionality
    in a few selected places, like *Latent Dirichlet Analysis* or *Power Iteration
    Clustering*, which are unfortunately beyond the scope of this chapter to explain.
    Instead, we focused on explaining the basics of GraphX from first principles.
    However, the reader is encouraged to apply what we have learnt in this chapter,
    together with the ones before, and experiment with the preceding algorithms. For
    sake of completeness, there is one machine learning algorithm completely implemented
    in GraphX, namely *SVD++*, which you can read more about at [http://public.research.att.com/~volinsky/netflix/kdd08koren.pdf](http://public.research.att.com/~volinsky/netflix/kdd08koren.pdf),
    and which is a graph-based recommender algorithm.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，尽管图的概念仅限于Spark GraphX，但由于图的基础顶点和边RDD，我们可以无缝地与Spark的任何其他模块进行交流。事实上，我们在整个章节中使用了许多核心RDD操作，但并不止于此。MLlib确实在一些特定的地方使用了GraphX功能，比如*潜在狄利克雷分析*或*幂迭代聚类*，但这超出了本章的范围。相反，我们专注于从第一原理解释GraphX的基础知识。然而，鼓励读者将本章学到的知识与之前的知识结合起来，并尝试使用前面的算法进行实验。为了完整起见，GraphX中完全实现了一种机器学习算法，即*SVD++*，您可以在[http://public.research.att.com/~volinsky/netflix/kdd08koren.pdf](http://public.research.att.com/~volinsky/netflix/kdd08koren.pdf)上了解更多信息，这是一种基于图的推荐算法。
- en: Summary
  id: totrans-320
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we have seen how to put large-scale graph analytics in practice
    using Spark GraphX. Modeling entity relationships as graphs with vertices and
    edges is a powerful paradigm to assess many interesting problems.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们已经看到了如何使用Spark GraphX将大规模图分析付诸实践。将实体关系建模为具有顶点和边的图是一种强大的范例，可以评估许多有趣的问题。
- en: In GraphX, graphs are finite, directed property graphs, potentially with multiple
    edges and loops. GraphX does graph analytics on highly optimized versions of vertex
    and edge RDDs, which allows you to leverage both data and graph-parallel applications.
    We have seen how such graphs can be read by either loading them from `edgeListFile`
    or constructing them individually from other RDDs. On top of that, we have seen
    how easy it is to create both random and deterministic graph data for quick experiments.
    Using just the rich built-in functionality of the `Graph` model, we have shown
    how to investigate a graph for core properties. To visualize more complex graphs,
    we introduced *Gephi* and an interface to it, which allows one to gain intuition
    about the graph structure at hand.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 在GraphX中，图是有限的、有向的属性图，可能具有多个边和环。GraphX对顶点和边RDD的高度优化版本进行图分析，这使您可以利用数据和图并行应用。我们已经看到这样的图可以通过从`edgeListFile`加载或从其他RDD单独构建来读取。除此之外，我们还看到了如何轻松地创建随机和确定性图数据进行快速实验。仅使用`Graph`模型的丰富内置功能，我们已经展示了如何调查图的核心属性。为了可视化更复杂的图形，我们介绍了*Gephi*及其接口，这使得我们可以直观地了解手头的图结构。
- en: Among the many other possibilities that Spark GraphX has to offer, we introduced
    two powerful graph analytics tools, namely `aggregateMessages` and the `Pregel`
    API. Most of GraphX’s built-in algorithms are written using one of these options.
    We have seen how to write our own algorithms using each of these APIs. We also
    gave a brief overview of the GraphFrames package, which builds on top of DataFrames,
    comes equipped with an elegant query language that is not available in plain GraphX,
    and can come in handy for analytics purposes.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 在Spark GraphX提供的许多其他可能性中，我们介绍了两种强大的图分析工具，即`aggregateMessages`和`Pregel` API。大多数GraphX内置算法都是使用这两个选项之一编写的。我们已经看到如何使用这些API编写我们自己的算法。我们还简要介绍了GraphFrames包，它建立在DataFrames之上，配备了一种优雅的查询语言，这种语言在普通的GraphX中不可用，并且可以在分析目的上派上用场。
- en: In terms of practical applications, we have seen an interesting retweet graph,
    as well as a Hollywood movie actor graph in action. We carefully explained and
    applied Google’s PageRank algorithm, studied (strongly) connected components of
    graphs, and counted triangles thereof as a means of doing clustering. We finished
    by discussing the relationship between Spark MLlib and GraphX for advanced machine
    learning applications.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际应用方面，我们看到了一个有趣的转发图，以及好莱坞电影演员图的应用。我们仔细解释并应用了谷歌的PageRank算法，研究了图的（强）连通组件，并计算三角形作为聚类的手段。最后，我们讨论了Spark
    MLlib和GraphX在高级机器学习应用中的关系。
