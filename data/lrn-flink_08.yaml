- en: Chapter 8. Distributed Data Processing with Flink and Hadoop
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第8章。使用Flink和Hadoop进行分布式数据处理
- en: Apache Hadoop has become a core and essential part of data processing and analytics
    infrastructures over the last couple of years. With Hadoop 1.X, the community
    learnt the distributed data processing using the MapReduce framework, whereas
    the next version of Hadoop, 2.X taught us the efficient use of resources and scheduling
    using the YARN framework. The YARN framework is a core part of Hadoop data processing,
    where it handles complex tasks such as job executions, distribution, resource
    allocation, scheduling, and so on. It allows for multi-tenancy, scalability, and
    high availability.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去的几年中，Apache Hadoop已成为数据处理和分析基础设施的核心和必要部分。通过Hadoop 1.X，社区学习了使用MapReduce框架进行分布式数据处理，而Hadoop的下一个版本，2.X则教会了我们使用YARN框架进行资源的高效利用和调度。YARN框架是Hadoop数据处理的核心部分，它处理诸如作业执行、分发、资源分配、调度等复杂任务。它允许多租户、可伸缩性和高可用性。
- en: The best part about YARN is that it is not just a framework but more like a
    complete operating system where developers are free to develop and execute applications
    of their choice. It gives abstraction by letting developers only focus on application
    development and forget the pain of data and execution distribution in parallel.
    YARN sits on top of the Hadoop Distributed File System and can also read data
    from filesystems such as AWS S3.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: YARN最好的部分在于它不仅仅是一个框架，更像是一个完整的操作系统，开发人员可以自由开发和执行他们选择的应用程序。它通过让开发人员只专注于应用程序开发，忘记并行数据和执行分发的痛苦来提供抽象。YARN位于Hadoop分布式文件系统之上，还可以从AWS
    S3等文件系统中读取数据。
- en: The YARN application framework has been built so well that it can host any distributed
    processing engine. In recent times, there has been a significant rise in new distributed
    data processing engines such as Spark, Flink, and so on. As they are built to
    be executed on a YARN cluster, it becomes very easy for people to try new things
    in parallel on the same YARN cluster. This means we can run Spark as well as Flink
    jobs on the same cluster using YARN. In this chapter, we are going to see how
    we can make use of existing Hadoop/YARN clusters to execute our Flink job in parallel.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: YARN应用程序框架建得非常好，可以托管任何分布式处理引擎。最近，新的分布式数据处理引擎如Spark、Flink等出现了显著增长。由于它们是为在YARN集群上执行而构建的，因此人们可以很容易地在同一个YARN集群上并行尝试新的东西。这意味着我们可以在同一个集群上使用YARN运行Spark和Flink作业。在本章中，我们将看到如何利用现有的Hadoop/YARN集群并行执行我们的Flink作业。
- en: So let's get started.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 所以让我们开始吧。
- en: Quick overview of Hadoop
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Hadoop的快速概述
- en: Most of you will be already aware of Hadoop and what it does but for those who
    are new to the world of distributed computing, let me try to give a brief introduction
    to Hadoop.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 你们大多数人可能已经了解Hadoop及其功能，但对于那些对分布式计算世界还不熟悉的人，让我试着简要介绍一下Hadoop。
- en: 'Hadoop is a distributed, open source data processing framework. It consists
    of two important parts: one data storage unit, **Hadoop Distributed File System**
    (**HDFS**) and the resource management unit, **Yet Another Resource Negotiator**
    (**YARN**). The following diagram shows a high-level overview of the Hadoop ecosystem:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Hadoop是一个分布式的开源数据处理框架。它由两个重要部分组成：一个数据存储单元，Hadoop分布式文件系统（HDFS）和资源管理单元，另一个资源协商器（YARN）。以下图表显示了Hadoop生态系统的高级概述：
- en: '![Quick overview of Hadoop](img/image_08_001.jpg)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![Hadoop的快速概述](img/image_08_001.jpg)'
- en: HDFS
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: HDFS
- en: HDFS, as the name suggests, is a highly available, distributed filesystem used
    for data storage. These days, this is one of the core frameworks of most companies.
    HDFS consists of a master-slave architecture, with daemons such as NameNode, secondary
    NameNode, and DataNode.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: HDFS，顾名思义，是一个用于数据存储的高可用性分布式文件系统。如今，这是大多数公司的核心框架之一。HDFS由主从架构组成，具有NameNode、辅助NameNode和DataNode等守护程序。
- en: In HDFS, NameNode stores metadata about the files to be stored while DataNode
    stores the actual block comprising a file. Data blocks are by default three-fold
    replicated in order to achieve high availability. A secondary NameNode is used
    for backing up the filesystem metadata stored on NameNode.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在HDFS中，NameNode存储有关要存储的文件的元数据，而DataNode存储组成文件的实际块。数据块默认情况下是三倍复制的，以实现高可用性。辅助NameNode用于备份存储在NameNode上的文件系统元数据。
- en: Note
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Here is a link where you can read more about HDFS at [http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html](http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个链接，您可以在[http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html](http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html)上阅读有关HDFS的更多信息。
- en: YARN
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: YARN
- en: Prior to YARN, MapReduce was the data processing framework which ran on top
    of HDFS. But people started realizing its limitation of number of task trackers
    a job tracker can handle. This gave rise to YARN. The fundamental idea behind
    YARN is to separate the resource management and scheduling tasks. YARN has the
    global resource manager and per application--the application master. The resource
    manager works on master nodes whereas it has a per worker node agent--the node
    manager, which is responsible for managing containers, monitoring their usage
    (CPU, disk, memory) and reporting back to the resource manager.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在YARN之前，MapReduce是运行在HDFS之上的数据处理框架。但人们开始意识到它在处理作业跟踪器数量方面的限制。这催生了YARN。YARN背后的基本思想是分离资源管理和调度任务。YARN具有全局资源管理器和每个应用程序的应用程序主管。资源管理器在主节点上工作，而它有一个每个工作节点代理——节点管理器，负责管理容器，监视它们的使用情况（CPU、磁盘、内存）并向资源管理器报告。
- en: The resource manager has two important components--**scheduler** and **applications
    manager**. Scheduler is responsible for scheduling applications in the queue while
    applications manager takes care of accepting job submissions, negotiating first
    container to the application specific application master. It is also responsible
    for restarting the **application master** in case of failure.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 资源管理器有两个重要组件--**调度程序**和**应用程序管理器**。调度程序负责在队列中调度应用程序，而应用程序管理器负责接受作业提交，协商应用程序特定应用程序主节点的第一个容器。它还负责在应用程序主节点发生故障时重新启动**应用程序主节点**。
- en: Because of operating systems like nature, YARN provides API which can be extended
    to build applications. **Spark** and **Flink** are great examples of this.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 由于像YARN这样的操作系统提供了可以扩展构建应用程序的API。**Spark**和**Flink**就是很好的例子。
- en: Note
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Here is a link where you can read more about YARN at [http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html](http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在[http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html](http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html)阅读更多关于YARN的信息。
- en: Now let's look at how we can use Flink on YARN.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看如何在YARN上使用Flink。
- en: Flink on YARN
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Flink在YARN上
- en: 'Flink has been built-in supported to be execution-ready on YARN. Any application
    build using Flink APIs can be executed on YARN without much effort. Users don''t
    need to set up or install anything if they already have a YARN cluster. Flink
    expects the following requirements to be met:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: Flink已经内置支持在YARN上准备执行。使用Flink API构建的任何应用程序都可以在YARN上执行，而无需太多努力。如果用户已经有一个YARN集群，则无需设置或安装任何内容。Flink希望满足以下要求：
- en: Hadoop version should be 2.2 or above
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hadoop版本应该是2.2或更高
- en: HDFS should be up-and-running
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: HDFS应该已经启动
- en: Configurations
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 配置
- en: In order to run Flink on YARN, the following configurations needs to be done.
    First of all, we need to download the Hadoop compatible version of the Flink distribution.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在YARN上运行Flink，需要进行以下配置。首先，我们需要下载与Hadoop兼容的Flink发行版。
- en: Note
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The binaries are available for download at [http://flink.apache.org/downloads.html](http://flink.apache.org/downloads.html).
    You have to choose from the following options.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 二进制文件可在[http://flink.apache.org/downloads.html](http://flink.apache.org/downloads.html)下载。您必须从以下选项中进行选择。
- en: '![Configurations](img/image_08_002.jpg)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![配置](img/image_08_002.jpg)'
- en: Let's assume we are running Hadoop 2.7 and Scala 2.11\. We will download the
    specific binary and store it on a node where Hadoop is installed and running.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们正在运行Hadoop 2.7和Scala 2.11。我们将下载特定的二进制文件并将其存储在安装和运行Hadoop的节点上。
- en: 'Once downloaded, we need to extract the `tar` files as shown here:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 下载后，我们需要按照这里所示的方式提取`tar`文件：
- en: '[PRE0]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Starting a Flink YARN session
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 启动Flink YARN会话
- en: 'Once the binaries are extracted, we can start the Flink session. A Flink session
    is a session which starts all required Flink services (Job Manager and Task Managers)
    on respective nodes so that we can start executing Flink jobs. To start the Flink
    session, we have the following executable with the given options:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦二进制文件被提取，我们就可以启动Flink会话。Flink会话是一个会话，它在各自的节点上启动所有所需的Flink服务（作业管理器和任务管理器），以便我们可以开始执行Flink作业。要启动Flink会话，我们有以下可执行文件和给定选项：
- en: '[PRE1]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: We have to make sure that the `YARN_CONF_DIR` and `HADOOP_CONF_DIR` environment
    variables are set so that Flink can find the required configurations. Now let's
    start the Flink session by providing information.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须确保`YARN_CONF_DIR`和`HADOOP_CONF_DIR`环境变量已设置，以便Flink可以找到所需的配置。现在让我们通过提供信息来启动Flink会话。
- en: 'Here is how we start the Flink session by giving the details about the number
    of task managers, memory for each task manager, and slots to be used:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们如何通过提供有关任务管理器数量、每个任务管理器的内存和要使用的插槽的详细信息来启动Flink会话：
- en: '[PRE2]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: If the configuration directories are not set properly, you will get an error
    mentioning the same. In that case, first you can set the configuration directories
    and then start the Flink YARN session.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 如果配置目录未正确设置，您将收到错误消息。在这种情况下，首先可以设置配置目录，然后启动Flink YARN会话。
- en: 'The following command sets the configuration directories:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令设置了配置目录：
- en: '[PRE3]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Note
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'We can also check the Flink Web UI as by hitting the following URL: `http://host:8088/proxy/application_<id>/#/overview.`'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以通过访问以下URL来检查Flink Web UI：`http://host:8088/proxy/application_<id>/#/overview.`
- en: 'Here is the screenshot of the same:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这是同样的屏幕截图：
- en: '![Starting a Flink YARN session](img/image_08_003.jpg)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![启动Flink YARN会话](img/image_08_003.jpg)'
- en: Similarly, we can also check the YARN application UI at `http://myhost:8088/cluster/app/application_1478079131011_0107`.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，我们也可以在`http://myhost:8088/cluster/app/application_1478079131011_0107`上检查YARN应用程序UI。
- en: '![Starting a Flink YARN session](img/image_08_004.jpg)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![启动Flink YARN会话](img/image_08_004.jpg)'
- en: Submitting a job to Flink
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将作业提交到Flink
- en: Now that we have a Flink session connected to YARN, we are all set to submit
    a Flink job to YARN.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经连接到YARN的Flink会话，我们已经准备好将Flink作业提交到YARN。
- en: 'We can use the following command with options to submit the Flink job:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用以下命令和选项提交Flink作业：
- en: '[PRE4]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We can execute the Flink job using the run action. We have the following options
    in run:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用运行操作来执行Flink作业。在运行中，我们有以下选项：
- en: '| **Option** | **Description** |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| **选项** | **描述** |'
- en: '| `-c`, `--class <classname>` | Class with the program entry point (`main()`
    method or `getPlan()` method). Only needed if the JAR file does not specify the
    class in its manifest. |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| `-c`, `--class <classname>` | 具有程序入口点（`main()`方法或`getPlan()`方法）的类。只有在JAR文件没有在其清单中指定类时才需要。
    |'
- en: '| `-C`, `--classpath <url>` | Adds a URL to each user code classloader on all
    nodes in the cluster. The paths must specify a protocol (for example, `file://`)
    and be accessible on all nodes (for example, by means of an NFS share). You can
    use this option multiple times for specifying more than one URL. The protocol
    must be supported by `{@link java.net.URLClassLoader}`. This can be used in case
    you wish to use certain third-party libraries with Flink YARN session. |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: -C，--classpath <url> | 在集群中的所有节点的每个用户代码类加载器中添加URL。路径必须指定协议（例如`file://`）并且在所有节点上都可以访问（例如通过NFS共享）。您可以多次使用此选项来指定多个URL。协议必须受到{@link
    java.net.URLClassLoader}支持。如果您希望在Flink YARN会话中使用某些第三方库，可以使用此选项。
- en: '| `-d`, `--detached` | If present, runs the job in detached mode. Detached
    mode can be useful when you don''t want to keep running the Flink YARN session
    all the time. In this case, Flink client will only submit the job and will detach
    itself. We cannot stop detached Flink YARN session using Flink commands. To do
    so, we have to kill the application using YARN commands `yarn application -kill
    <appId>` |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: -d，--detached | 如果存在，以分离模式运行作业。分离模式在您不想一直运行Flink YARN会话时很有用。在这种情况下，Flink客户端只会提交作业并分离自己。我们无法使用Flink命令停止分离的Flink
    YARN会话。为此，我们必须使用YARN命令杀死应用程序 yarn application -kill <appId>
- en: '| `-m`, `--jobmanager <host:port>` | Address of the Job Manager (master) in
    which to connect. Use this flag to connect to a different Job Manager than the
    one specified in the configuration. |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: -m，--jobmanager <host:port> | 要连接的作业管理器（主节点）的地址。使用此标志连接到与配置中指定的不同作业管理器。 |
- en: '| `-p`, `--parallelism <parallelism>` | The parallelism with which to run the
    program. Optional flag to override the default value specified in the configuration.
    |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: -p，--parallelism <parallelism> | 运行程序的并行度。可选标志，用于覆盖配置中指定的默认值。
- en: '| `-q`, `--sysoutLogging` | If present, suppresses logging output to standard
    `OUT`. |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: -q，--sysoutLogging | 如果存在，抑制标准`OUT`的日志输出。
- en: '| `-s`, `--fromSavepoint <savepointPath>` | Path to a save point to reset the
    job back to, for example `file:///flink/savepoint-1537`. Savepoints are externally
    stored states of a Flink program. They are snapshots which are stored to a certain
    location. If Flink program fails, we can resume it from its last stored save point.
    More details on save points [https://ci.apache.org/projects/flink/flink-docs-release-1.2/setup/savepoints.html](https://ci.apache.org/projects/flink/flink-docs-release-1.2/setup/savepoints.html)
    |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: -s，--fromSavepoint <savepointPath> | 重置作业的保存点路径，例如 file:///flink/savepoint-1537。保存点是Flink程序的外部存储状态。它们是存储在某个位置的快照。如果Flink程序失败，我们可以从其上次存储的保存点恢复它。有关保存点的更多详细信息
    [https://ci.apache.org/projects/flink/flink-docs-release-1.2/setup/savepoints.html](https://ci.apache.org/projects/flink/flink-docs-release-1.2/setup/savepoints.html)
- en: '| `-z`, `--zookeeperNamespace <zookeeperNamespace>` | Namespace to create the
    Zookeeper sub-paths for high availability mode |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: -z，--zookeeperNamespace <zookeeperNamespace> | 用于创建高可用模式的Zookeeper子路径的命名空间
- en: 'The following options are available for the `yarn-cluster` mode:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '`yarn-cluster`模式提供以下选项：'
- en: '| **Option** | **Description** |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '**选项** | **描述**'
- en: '| `-yD <arg>` | Dynamic properties |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: -yD <arg> | 动态属性
- en: '| `yd`, `--yarndetached` | Start detached |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: yd，--yarndetached | 启动分离
- en: '| `-yid`, `--yarnapplicationId <arg>` | Attach to running YARN session |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: -yid，--yarnapplicationId <arg> | 连接到正在运行的YARN会话
- en: '| `-yj`, `--yarnjar <arg>` | Path to Flink jar file |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: -yj，--yarnjar <arg> | Flink jar文件的路径
- en: '| `-yjm`, `--yarnjobManagerMemory <arg>` | Memory for Job Manager container
    (in MB) |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: -yjm，--yarnjobManagerMemory <arg> | 作业管理器容器的内存（以MB为单位）
- en: '| `-yn`, `--yarncontainer <arg>` | Number of YARN containers to allocate (=
    number of task managers) |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: -yn，--yarncontainer <arg> | 分配的YARN容器数（=任务管理器数）
- en: '| `-ynm`, `--yarnname <arg>` | Sets a custom name for the application on YARN
    |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: -ynm，--yarnname <arg> | 为YARN上的应用设置自定义名称
- en: '| `-yq`, `--yarnquery` | Displays available YARN resources (memory, cores)
    |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: -yq，--yarnquery | 显示可用的YARN资源（内存，核心）
- en: '| `-yqu`, `--yarnqueue <arg>` | Specifies YARN queue |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: -yqu，--yarnqueue <arg> | 指定YARN队列
- en: '| `-ys`, `--yarnslots <arg>` | Number of slots per Task Manager |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: -ys，--yarnslots <arg> | 每个任务管理器的插槽数
- en: '| `-yst`, `--yarnstreaming` | Starts Flink in streaming mode |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: -yst，--yarnstreaming | 以流模式启动Flink
- en: '| `-yt`, `--yarnship <arg>` | Ships files in the specified director (t for
    transfer) |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: -yt，--yarnship <arg> | 在指定目录中传输文件（t表示传输）
- en: '| `-ytm`, `--yarntaskManagerMemory <arg>` | Memory per TaskManager ontainer
    (in MB) |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: -ytm，--yarntaskManagerMemory <arg> | 每个TaskManager容器的内存（以MB为单位）
- en: '| `-yz`, `--yarnzookeeperNamespace <arg>` | Namespace to create the Zookeeper
    sub-paths for high availability mode |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: -yz，--yarnzookeeperNamespace <arg> | 用于创建高可用模式的Zookeeper子路径的命名空间
- en: Now let's try to run a sample word count example on YARN. The following are
    the steps to do so.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们尝试在YARN上运行一个示例单词计数示例。以下是如何执行的步骤。
- en: 'First let''s have input file stored on HDFS as input to the word count program.
    Here we are going to run the word count on Apache License text. The following
    is the way we download and store it on HDFS:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们将输入文件存储在HDFS上，作为单词计数程序的输入。在这里，我们将在Apache许可证文本上运行单词计数。以下是我们下载并将其存储在HDFS上的方式：
- en: '[PRE5]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Now we will submit the example word count job:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将提交示例单词计数作业：
- en: '[PRE6]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'This will invoke the Flink job which would get executed on the YARN cluster.
    You should see the console as:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这将调用在YARN集群上执行的Flink作业。您应该在控制台上看到：
- en: '[PRE7]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The following are the screenshots of the job execution from the Flink application
    master UI. Here is the screenshot of the Flink execution plan:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是来自Flink应用程序主UI的作业执行的屏幕截图。这是Flink执行计划的屏幕截图：
- en: '![Submitting a job to Flink](img/image_08_005.jpg)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![提交作业到Flink](img/image_08_005.jpg)'
- en: 'Next we can see the screenshot of the steps getting executed for this job:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来我们可以看到执行此作业的步骤的屏幕截图：
- en: '![Submitting a job to Flink](img/image_08_006.jpg)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![提交作业到Flink](img/image_08_006.jpg)'
- en: 'And at last we have the screenshot of the timeline of the Flink job execution.
    The timeline shows all the steps that can be executed in parallel and what needs
    to be executed sequentially:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们有Flink作业执行时间轴的截图。时间轴显示了所有可以并行执行的步骤以及需要按顺序执行的步骤：
- en: '![Submitting a job to Flink](img/image_08_007.jpg)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![提交作业到Flink](img/image_08_007.jpg)'
- en: Stopping Flink YARN session
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 停止Flink YARN会话
- en: Once the processing is done, you can stop the Flink YARN session in two ways.
    First you can simple do a *Cltr*+*C* on the console where you started the YARN
    session. This will send the termination signal and stop the YARN session.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 处理完成后，您可以以两种方式停止Flink YARN会话。首先，您可以在启动YARN会话的控制台上简单地执行*Cltr*+*C*。这将发送终止信号并停止YARN会话。
- en: 'The second way is to execute the following command to stop the session:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 第二种方法是执行以下命令来停止会话：
- en: '[PRE8]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We can see immediately the Flink YARN application get killed:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以立即看到Flink YARN应用程序被终止：
- en: '[PRE9]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Running a single Flink job on YARN
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在YARN上运行单个Flink作业
- en: 'We can also run a single Flink job on YARN without blocking the resources for
    the YARN session. This is a good option if you only wish to run a single Flink
    job on YARN. In the earlier case, when we start the Flink session on YARN, it
    blocks the resources and cores until we stop the session whereas in this case
    the resources are blocked till the job is executing and they are freed up as soon
    as the job is complete. The following command shows how we execute a single Flink
    job on YARN without a session:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以在YARN上运行单个Flink作业，而不会阻塞YARN会话的资源。如果您只希望在YARN上运行单个Flink作业，这是一个很好的选择。在之前的情况下，当我们在YARN上启动Flink会话时，它会阻塞资源和核心，直到我们停止会话，而在这种情况下，资源会在作业执行时被阻塞，并且一旦作业完成，它们就会被释放。以下命令显示了如何在YARN上执行单个Flink作业而不需要会话：
- en: '[PRE10]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We can see similar results as we saw in the earlier case. We can also track
    its progress and debugging using the YARN application UI. The following is a sample
    screenshot of the same:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到与之前情况下相似的结果。我们还可以使用YARN应用程序UI跟踪其进度和调试。以下是同一样本的截图：
- en: '![Running a single Flink job on YARN](img/image_08_008.jpg)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![在YARN上运行单个Flink作业](img/image_08_008.jpg)'
- en: Recovery behavior for Flink on YARN
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Flink在YARN上的恢复行为
- en: 'Flink on YARN provides the following configuration parameters for tuning the
    recovery behavior:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: Flink在YARN上提供以下配置参数来调整恢复行为：
- en: '| **Parameter** | **Description** |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| **参数** | **描述** |'
- en: '| `yarn.reallocate-failed` | Sets whether Flink should reallocate failed task
    manager containers. The default is `true`. |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| `yarn.reallocate-failed` | 设置Flink是否应重新分配失败的任务管理器容器。默认值为`true`。'
- en: '| `yarn.maximum-failed-containers` | Sets the maximum number of failed containers
    the application master accepts before failing the YARN session. The default is
    number of task managers requested during initiation. |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| `yarn.maximum-failed-containers` | 设置应用程序主在YARN会话失败之前接受的最大失败容器数。默认值为启动时请求的任务管理器数量。'
- en: '| `yarn.application-attempts` | Sets the number of application master attempts.
    The default is `1`, which means if complete, the YARN session will fail if the
    application master fails. |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| `yarn.application-attempts` | 设置应用程序主尝试的次数。默认值为`1`，这意味着如果应用程序主失败，YARN会话将失败。'
- en: These configurations need to be in either `conf/flink-conf.yaml` or can be set
    during the session initiation using the `-D` parameter.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 这些配置需要在`conf/flink-conf.yaml`中，或者可以在会话启动时使用`-D`参数进行设置。
- en: Working details
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作细节
- en: 'In the previous sections, we looked at how we can use Flink on YARN. Now let''s
    try to understand how it works internally:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们看到了如何在YARN上使用Flink。现在让我们试着了解它的内部工作原理：
- en: '![Working details](img/image_08_009.jpg)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![工作细节](img/image_08_009.jpg)'
- en: 'The preceding diagram shows the internal workings of Flink on YARN. It goes
    through the following steps:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 上图显示了Flink在YARN上的内部工作原理。它经历了以下步骤：
- en: Checks if the Hadoop and YARN configuration directories are set.
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查Hadoop和YARN配置目录是否已设置。
- en: If yes, contacts HDFS and stores the JAR and configuration on HDFS.
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果是，则联系HDFS并将JAR和配置存储在HDFS上。
- en: Contacts the node manager for allocating the application master.
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 联系节点管理器以分配应用程序主。
- en: Once the application master is allocated, initiates the Flink Job Manager.
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦分配了应用程序主，就会启动Flink作业管理器。
- en: Later, initiates the Flink task managers based on the configuration parameters
    given.
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 稍后，根据给定的配置参数启动Flink任务管理器。
- en: Now we are all set to submit the Flink job on YARN.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好在YARN上提交Flink作业了。
- en: Summary
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we talked about how to use existing YARN clusters to execute
    Flink jobs in a distributed mode. We looked at the step-by-step details and understood
    some practical examples for the same.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了如何使用现有的YARN集群以分布式模式执行Flink作业。我们详细了解了一些实际示例。
- en: In the next chapter, we are going to see how to execute Flink jobs in the cloud
    environment.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将看到如何在云环境中执行Flink作业。
