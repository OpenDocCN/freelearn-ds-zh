- en: Setting Up Spark for Deep Learning Development
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为深度学习开发设置Spark
- en: 'In this chapter, the following recipes will be covered:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，将涵盖以下内容：
- en: Downloading an Ubuntu Desktop image
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 下载Ubuntu桌面镜像
- en: Installing and configuring Ubuntu with VMWare Fusion on macOS
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在macOS上使用VMWare Fusion安装和配置Ubuntu
- en: Installing and configuring Ubuntu with Oracle VirtualBox on Windows
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Windows上使用Oracle VirtualBox安装和配置Ubuntu
- en: Installing and configuring Ubuntu Desktop for Google Cloud Platform
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Google Cloud Platform上安装和配置Ubuntu桌面
- en: Installing and configuring Spark and prerequisites on Ubuntu Desktop
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Ubuntu桌面上安装和配置Spark和先决条件
- en: Integrating Jupyter notebooks with Spark
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将Jupyter笔记本与Spark集成
- en: Starting and configuring a Spark cluster
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 启动和配置Spark集群
- en: Stopping a Spark cluster
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 停止Spark集群
- en: Introduction
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: Deep learning is the focused study of machine learning algorithms that deploy
    neural networks as their main method of learning. Deep learning has exploded onto
    the scene just within the last couple of years. Microsoft, Google, Facebook, Amazon,
    Apple, Tesla and many other companies are all utilizing deep learning models in
    their apps, websites, and products. At the same exact time, Spark, an in-memory
    compute engine running on top of big data sources, has made it easy to process
    volumes of information at record speeds and ease. In fact, Spark has now become
    the leading big data development tool for data engineers, machine learning engineers,
    and data scientists.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习是机器学习算法的专注研究，其主要学习方法是使用神经网络。深度学习在过去几年内迅速发展。微软、谷歌、Facebook、亚马逊、苹果、特斯拉等许多公司都在其应用程序、网站和产品中使用深度学习模型。与此同时，作为运行在大数据源之上的内存计算引擎，Spark已经使处理大量信息变得更加容易和快速。事实上，Spark现在已成为数据工程师、机器学习工程师和数据科学家的主要大数据开发工具。
- en: Since deep learning models perform better with more data, the synergy between
    Spark and deep learning allowed for a perfect marriage. Almost as important as
    the code used to execute deep learning algorithms is the work environment that
    enables optimal development. Many talented minds are eager to develop neural networks
    to help answer important questions in their research. Unfortunately, one of the
    greatest barriers to the development of deep learning models is access to the
    necessary technical resources required to learn on big data. The purpose of this
    chapter is to create an ideal virtual development environment for deep learning
    on Spark.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 由于深度学习模型在处理更多数据时表现更好，Spark和深度学习之间的协同作用实现了完美的结合。几乎与用于执行深度学习算法的代码一样重要的是能够实现最佳开发的工作环境。许多才华横溢的人渴望开发神经网络，以帮助回答他们研究中的重要问题。不幸的是，深度学习模型开发的最大障碍之一是获得学习大数据所需的技术资源。本章的目的是为Spark上的深度学习创建一个理想的虚拟开发环境。
- en: Downloading an Ubuntu Desktop image
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下载Ubuntu桌面镜像
- en: Spark can be set up for all types of operating systems, whether they reside
    on-premise or in the cloud. For our purposes, Spark will be installed on a Linux-based
    virtual machine with Ubuntu as the operating system. There are several advantages
    to using Ubuntu as the go-to virtual machine, not least of which is cost. Since
    they are based on open source software, Ubuntu operating systems are free to use
    and do not require licensing. Cost is always a consideration and one of the main
    goals of this publication is to minimize the financial footprint required to get
    started with deep learning on top of a Spark framework.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: Spark可以为各种操作系统设置，无论是在本地还是在云中。对于我们的目的，Spark将安装在以Ubuntu为操作系统的基于Linux的虚拟机上。使用Ubuntu作为首选虚拟机有几个优势，其中最重要的是成本。由于它们基于开源软件，Ubuntu操作系统是免费使用的，不需要许可证。成本始终是一个考虑因素，本出版物的主要目标之一是尽量减少在Spark框架上开始深度学习所需的财务开支。
- en: Getting ready
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备就绪
- en: 'There are some minimum recommendations required for downloading the image file:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 下载镜像文件需要满足一些最低要求：
- en: Minimum of 2 GHz dual-core processor
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 至少2GHz双核处理器
- en: Minimum of 2 GB system memory
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 至少2GB的系统内存
- en: Minimum of 25 GB of free hard drive space
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 至少25GB的免费硬盘空间
- en: How to do it...
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 操作步骤...
- en: 'Follow the steps in the recipe to download an Ubuntu Desktop image:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 按照配方中的步骤下载Ubuntu桌面镜像：
- en: 'In order to create a virtual machine of Ubuntu Desktop, it is necessary to
    first download the file from the official website: [https://www.ubuntu.com/download/desktop.](https://www.ubuntu.com/download/desktop)'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要创建Ubuntu桌面的虚拟机，首先需要从官方网站下载文件：[https://www.ubuntu.com/download/desktop.](https://www.ubuntu.com/download/desktop)
- en: As of this writing, Ubuntu Desktop 16.04.3 is the most recent available version
    for download.
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 截至目前，Ubuntu桌面16.04.3是可供下载的最新版本。
- en: 'Access the following file in a `.iso` format once the download is complete:'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦下载完成，以.iso格式访问以下文件：
- en: '`ubuntu-16.04.3-desktop-amd64.iso`'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '`ubuntu-16.04.3-desktop-amd64.iso`'
- en: How it works...
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: Virtual environments provide an optimal development workspace by isolating the
    relationship to the physical or host machine. Developers may be using all types
    of machines for their host environments such as a MacBook running macOS, a Microsoft
    Surface running Windows or even a virtual machine on the cloud with Microsoft
    Azure or AWS; however, to ensure consistency within the output of the code executed,
    a virtual environment within Ubuntu Desktop will be deployed that can be used
    and shared among a wide variety of host platforms.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 虚拟环境通过隔离与物理或主机机器的关系，提供了一个最佳的开发工作空间。开发人员可能会使用各种类型的主机环境，如运行macOS的MacBook，运行Windows的Microsoft
    Surface，甚至在Microsoft Azure或AWS云上的虚拟机；然而，为了确保代码执行的一致性，将部署一个Ubuntu桌面内的虚拟环境，可以在各种主机平台上使用和共享。
- en: There's more...
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'There are several options for desktop virtualization software, depending on
    whether the host environment is on a Windows or a macOS. There are two common
    software applications for virtualization when using macOS:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 根据主机环境的不同，桌面虚拟化软件有几种选择。在使用macOS时，有两种常见的虚拟化软件应用：
- en: VMWare Fusion
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: VMWare Fusion
- en: Parallels
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Parallels
- en: See also
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: To learn more about Ubuntu Desktop, you can visit [https://www.ubuntu.com/desktop](https://www.ubuntu.com/desktop).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解有关Ubuntu桌面的更多信息，请访问[https://www.ubuntu.com/desktop](https://www.ubuntu.com/desktop)。
- en: Installing and configuring Ubuntu with VMWare Fusion on macOS
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在macOS上使用VMWare Fusion安装和配置Ubuntu
- en: This section will focus on building a virtual machine using an Ubuntu operating
    system with **VMWare Fusion**.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将重点介绍使用Ubuntu操作系统构建虚拟机的过程，使用**VMWare Fusion**。
- en: Getting ready
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备就绪
- en: 'A previous installation of VMWare Fusion is required on your system. If you
    do not currently have this, you can download a trial version from the following
    website:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 您的系统需要先安装VMWare Fusion。如果您目前没有安装，可以从以下网站下载试用版本：
- en: '[https://www.vmware.com/products/fusion/fusion-evaluation.html](https://www.vmware.com/products/fusion/fusion-evaluation.html)'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.vmware.com/products/fusion/fusion-evaluation.html](https://www.vmware.com/products/fusion/fusion-evaluation.html)'
- en: How to do it...
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Follow the steps in the recipe to configure Ubuntu with VMWare Fusion on macOS:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 按照本文步骤配置在macOS上使用VMWare Fusion的Ubuntu：
- en: 'Once VMWare Fusion is up and running, click on the *+* button on the upper-left-hand
    side to begin the configuration process and select New..., as seen in the following
    screenshot:'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦VMWare Fusion启动并运行，点击左上角的*+*按钮开始配置过程，并选择 New...，如下截图所示：
- en: '![](img/00005.jpeg)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00005.jpeg)'
- en: 'Once the selection has been made, select the option to Install from Disk or
    Image, as seen in the following screenshot:'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择后，选择从磁盘或镜像安装的选项，如下截图所示：
- en: '![](img/00006.jpeg)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00006.jpeg)'
- en: 'Select the operating system''s `iso` file that was downloaded from the Ubuntu
    Desktop website, as seen in the following screenshot:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择从Ubuntu桌面网站下载的操作系统的`iso`文件，如下截图所示：
- en: '![](img/00007.jpeg)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00007.jpeg)'
- en: 'The next step will ask whether you want to choose Linux Easy Install. It is
    recommended to do so, as well as to incorporate a Display Name/Password combination
    for the Ubuntu environment, as seen in the following screenshot:'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步将询问是否要选择Linux Easy Install。建议这样做，并为Ubuntu环境设置显示名称/密码组合，如下截图所示：
- en: '![](img/00008.jpeg)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00008.jpeg)'
- en: 'The configuration process is almost complete. A Virtual Machine Summary is
    displayed with the option to Customize Settings to increase the Memory and Hard
    Disk, as seen in the following screenshot:'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 配置过程几乎完成了。显示虚拟机摘要，可以选择自定义设置以增加内存和硬盘，如下截图所示：
- en: '![](img/00009.jpeg)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00009.jpeg)'
- en: 'Anywhere from 20 to 40 GB hard disk space is sufficient for the virtual machine;
    however, bumping up the memory to either 2 GB or even 4 GB will assist with the
    performance of the virtual machine when executing Spark code in later chapters.
    Update the memory by selecting Processors and Memory under the Settings of the
    virtual machine and increasing the Memory to the desired amount, as seen in the
    following screenshot:'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 虚拟机需要20到40 GB的硬盘空间就足够了；但是，将内存增加到2 GB甚至4 GB将有助于虚拟机在执行后续章节中的Spark代码时的性能。通过在虚拟机的设置下选择处理器和内存，并将内存增加到所需的数量来更新内存，如下截图所示：
- en: '![](img/00010.jpeg)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00010.jpeg)'
- en: How it works...
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: The setup allows for manual configuration of the settings necessary to get Ubuntu
    Desktop up and running successfully on VMWare Fusion. The memory and hard drive
    storage can be increased or decreased based on the needs and availability of the
    host machine.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 设置允许手动配置必要的设置，以便在VMWare Fusion上成功运行Ubuntu桌面。根据主机机器的需求和可用性，可以增加或减少内存和硬盘存储。
- en: There's more...
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'All that is remaining is to fire up the virtual machine for the first time,
    which initiates the installation process of the system onto the virtual machine.
    Once all the setup is complete and the user has logged in, the Ubuntu virtual
    machine should be available for development, as seen in the following screenshot:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 现在剩下的就是第一次启动虚拟机，这将启动系统安装到虚拟机的过程。一旦所有设置完成并且用户已登录，Ubuntu虚拟机应该可以用于开发，如下截图所示：
- en: '![](img/00011.jpeg)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00011.jpeg)'
- en: See also
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: 'Aside from VMWare Fusion, there is also another product that offers similar
    functionality on a Mac. It is called Parallels Desktop for Mac. To learn more
    about VMWare and Parallels, and decide which program is a better fit for your
    development, visit the following websites:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 除了VMWare Fusion外，在Mac上还有另一款提供类似功能的产品。它被称为Parallels Desktop for Mac。要了解有关VMWare和Parallels的更多信息，并决定哪个程序更适合您的开发，请访问以下网站：
- en: '[https://www.vmware.com/products/fusion.html](https://www.vmware.com/products/fusion.html)
    to download and install VMWare Fusion for Mac'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://www.vmware.com/products/fusion.html](https://www.vmware.com/products/fusion.html)
    下载并安装Mac上的VMWare Fusion'
- en: '[https://parallels.com](https://parallels.com) to download and install the
    Parallels Desktop for Mac'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://parallels.com](https://parallels.com) 下载并安装 Parallels Desktop for
    Mac'
- en: Installing and configuring Ubuntu with Oracle VirtualBox on Windows
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Windows上使用Oracle VirtualBox安装和配置Ubuntu
- en: Unlike with macOS, there are several options to virtualize systems within Windows.
    This mainly has to do with the fact that virtualization on Windows is very common
    as most developers are using Windows as their host environment and need virtual
    environments for testing purposes without affecting any of the dependencies that
    rely on Windows.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 与macOS不同，在Windows中有几种虚拟化系统的选项。这主要是因为在Windows上虚拟化非常常见，因为大多数开发人员都在使用Windows作为他们的主机环境，并且需要虚拟环境进行测试，而不会影响依赖于Windows的任何依赖项。
- en: Getting ready
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备就绪
- en: VirtualBox from Oracle is a common virtualization product and is free to use. Oracle
    VirtualBox provides a straightforward process to get an Ubuntu Desktop virtual
    machine up and running on top of a Windows environment.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: Oracle的VirtualBox是一款常见的虚拟化产品，可以免费使用。Oracle VirtualBox提供了一个简单的过程，在Windows环境中运行Ubuntu桌面虚拟机。
- en: How to do it...
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Follow the steps in this recipe to configure Ubuntu with **VirtualBox** on
    Windows:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 按照本配方中的步骤，在Windows上使用**VirtualBox**配置Ubuntu：
- en: 'Initiate an Oracle VM VirtualBox Manager. Next, create a new virtual machine
    by selecting the New icon and specify the Name, Type, and Version of the machine,
    as seen in the following screenshot:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动Oracle VM VirtualBox Manager。接下来，通过选择新建图标并指定机器的名称、类型和版本来创建一个新的虚拟机，如下截图所示：
- en: '![](img/00012.jpeg)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00012.jpeg)'
- en: 'Select Expert Mode as several of the configuration steps will get consolidated,
    as seen in the following screenshot:'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择“专家模式”，因为一些配置步骤将被合并，如下截图所示：
- en: '![](img/00013.jpeg)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00013.jpeg)'
- en: Ideal memory size should be set to at least `2048` MB, or preferably `4096`
    MB, depending on the resources available on the host machine.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 理想的内存大小应至少设置为`2048`MB，或者更好的是`4096`MB，具体取决于主机机器上的资源。
- en: 'Additionally, set an optimal hard disk size for an Ubuntu virtual machine performing
    deep learning algorithms to at least 20 GB, if not more, as seen in the following
    screenshot:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此外，为在Ubuntu虚拟机上执行深度学习算法设置一个最佳硬盘大小至少为20GB，如果可能的话更大，如下截图所示：
- en: '![](img/00014.jpeg)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00014.jpeg)'
- en: 'Point the virtual machine manager to the start-up disk location where the Ubuntu
    `iso` file was downloaded to and then Start the creation process, as seen in the
    following screenshot:'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将虚拟机管理器指向Ubuntu `iso`文件下载的启动磁盘位置，然后开始创建过程，如下截图所示：
- en: '![](img/00015.jpeg)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00015.jpeg)'
- en: 'After allotting some time for the installation, select the Start icon to complete
    the virtual machine and get it ready for development as seen in the following
    screenshot:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在安装一段时间后，选择启动图标以完成虚拟机，并准备好进行开发，如下截图所示：
- en: '![](img/00016.jpeg)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00016.jpeg)'
- en: How it works...
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: The setup allows for manual configuration of the settings necessary to get Ubuntu
    Desktop up and running successfully on Oracle VirtualBox. As was the case with
    VMWare Fusion, the memory and hard drive storage can be increased or decreased
    based on the needs and availability of the host machine.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 该设置允许手动配置必要的设置，以便在Oracle VirtualBox上成功运行Ubuntu桌面。与VMWare Fusion一样，内存和硬盘存储可以根据主机机器的需求和可用性进行增加或减少。
- en: There's more...
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: Please note that some machines that run Microsoft Windows are not set up by
    default for virtualization and users may receive an initial error indicating the
    VT-x is not enabled. This can be reversed and virtualization may be enabled in
    the BIOS during a reboot.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，一些运行Microsoft Windows的机器默认情况下未设置为虚拟化，并且用户可能会收到初始错误，指示VT-x未启用。这可以在重新启动时在BIOS中进行反转，并且可以启用虚拟化。
- en: See also
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: To learn more about Oracle VirtualBox and decide whether or not it is a good
    fit, visit the following website and select Windows hosts to begin the download
    process: [https://www.virtualbox.org/wiki/Downloads](https://www.virtualbox.org/wiki/Downloads).
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于Oracle VirtualBox并决定是否适合您，请访问以下网站并选择Windows主机开始下载过程：[https://www.virtualbox.org/wiki/Downloads](https://www.virtualbox.org/wiki/Downloads)。
- en: Installing and configuring Ubuntu Desktop for Google Cloud Platform
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装和配置Ubuntu桌面以在Google Cloud Platform上运行
- en: Previously, we saw how Ubuntu Desktop could be set up locally using VMWare Fusion.
    In this section, we will learn how to do the same on **Google Cloud Platform**.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 之前，我们看到了如何在VMWare Fusion上本地设置Ubuntu桌面。在本节中，我们将学习如何在**Google Cloud Platform**上进行相同的设置。
- en: Getting ready
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: The only requirement is a Google account username. Begin by logging in to your
    Google Cloud Platform using your Google account. Google provides a free 12-month
    subscription with $300 credited to your account. The setup will ask for your bank
    details; however, Google will not charge you for anything without explicitly letting
    you know first. Go ahead and verify your bank account and you are good to go.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 唯一的要求是一个Google账户用户名。首先使用您的Google账户登录到Google Cloud Platform。Google提供一个免费的12个月订阅，账户中有300美元的信用额度。设置将要求您的银行详细信息；但是，Google不会在未明确告知您的情况下向您收费。继续验证您的银行账户，然后您就可以开始了。
- en: How to do it...
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 操作方法...
- en: 'Follow the steps in the recipe to configure Ubuntu Desktop for Google Cloud
    Platform:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 按照配方中的步骤配置Ubuntu桌面以在Google Cloud Platform上运行：
- en: 'Once logged in to your Google Cloud Platform, access a dashboard that looks
    like the one in the following screenshot:'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦登录到您的Google Cloud Platform，访问一个看起来像下面截图的仪表板：
- en: '![](img/00017.jpeg)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00017.jpeg)'
- en: Google Cloud Platform Dashboard
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: Google Cloud Platform仪表板
- en: 'First, click on the product services button in the top-left-hand corner of
    your screen. In the drop-down menu, under Compute, click on VM instances, as shown
    in the following screenshot:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，点击屏幕左上角的产品服务按钮。在下拉菜单中，在计算下，点击VM实例，如下截图所示：
- en: '![](img/00018.jpeg)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00018.jpeg)'
- en: Create a new instance and name it. We are naming it `ubuntuvm1` in our case.
    Google Cloud automatically creates a project while launching an instance and the
    instance will be launched under a project ID. The project may be renamed if required.
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新实例并命名它。在我们的案例中，我们将其命名为`ubuntuvm1`。在启动实例时，Google Cloud会自动创建一个项目，并且实例将在项目ID下启动。如果需要，可以重命名项目。
- en: After clicking on **Create Instance**, select the zone/area you are located
    in.
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**创建实例**后，选择您所在的区域。
- en: Select **Ubuntu 16.04LTS** under the boot disk as this is the operating system
    that will be installed in the cloud. Please note that LTS stands for version,
    and will have long-term support from Ubuntu’s developers.
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在启动磁盘下选择**Ubuntu 16.04LTS**，因为这是将在云中安装的操作系统。请注意，LTS代表版本，并且将获得来自Ubuntu开发人员的长期支持。
- en: 'Next, under the boot disk options, select SSD persistent disk and increase
    the size to 50 GB for some added storage space for the instance, as shown in the
    following screenshot:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，在启动磁盘选项下，选择SSD持久磁盘，并将大小增加到50GB，以增加实例的存储空间，如下截图所示：
- en: '![](img/00019.jpeg)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00019.jpeg)'
- en: Next, set Access scopes to **Allow full access to all Cloud APIs**.
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，将访问范围设置为**允许对所有云API进行完全访问**。
- en: 'Under firewall, please check to **allow HTTP traffic** as well as **allow HTTPS
    traffic**, as shown in the following screenshot:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在防火墙下，请检查**允许HTTP流量**和**允许HTTPS流量**，如下图所示：
- en: '![](img/00020.jpeg)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00020.jpeg)'
- en: Selecting options  Allow HTTP traffic and HTTPS Traffic
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 选择选项允许HTTP流量和HTTPS流量
- en: Once the instance is configured as shown in this section, go ahead and create
    the instance by clicking on the Create button.
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦实例配置如本节所示，点击“创建”按钮创建实例。
- en: After clicking on the Create button, you will notice that the instance gets
    created with a unique internal as well as external IP address. We will require
    this at a later stage. SSH refers to secure shell tunnel, which is basically an
    encrypted way of communicating in client-server architectures. Think of it as
    data going to and from your laptop, as well as going to and from Google's cloud
    servers, through an encrypted tunnel.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 点击“创建”按钮后，您会注意到实例已经创建，并且具有唯一的内部和外部IP地址。我们将在后期需要这个。SSH是安全外壳隧道的缩写，基本上是在客户端-服务器架构中进行加密通信的一种方式。可以将其视为数据通过加密隧道从您的笔记本电脑到谷歌的云服务器，以及从谷歌的云服务器到您的笔记本电脑的方式。
- en: 'Click on the newly created instance. From the drop-down menu, click on **open
    in browser window**, as shown in the following screenshot:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击新创建的实例。从下拉菜单中，点击**在浏览器窗口中打开**，如下图所示：
- en: '![](img/00021.jpeg)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00021.jpeg)'
- en: 'You will see that Google opens up a shell/terminal in a new window, as shown
    in the following screenshot:'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您会看到谷歌在一个新窗口中打开了一个shell/终端，如下图所示：
- en: '![](img/00022.jpeg)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00022.jpeg)'
- en: 'Once the shell is open, you should have a window that looks like the following
    screenshot:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦shell打开，您应该看到一个如下图所示的窗口：
- en: '![](img/00023.jpeg)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00023.jpeg)'
- en: 'Type the following commands in the Google cloud shell:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Google云shell中输入以下命令：
- en: '[PRE0]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'When presented with a prompt to continue or not, type `y` and select ENTER, as
    shown in the following screenshot:'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当提示是否继续时，输入`y`并选择ENTER，如下图所示：
- en: '![](img/00024.jpeg)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00024.jpeg)'
- en: 'Once done with the preceding steps, type the following commands to set up the
    `vncserver` and allow connections to the local shell:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 完成上述步骤后，输入以下命令设置`vncserver`并允许连接到本地shell：
- en: '[PRE1]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Next, launch the server by typing the following command:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，通过输入以下命令启动服务器：
- en: '[PRE2]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'This will prompt you to enter a password, which will later be used to log in
    to the Ubuntu Desktop virtual machine. This password is limited to eight characters
    and needs to be set and verified, as shown in the following screenshot:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这将提示您输入密码，稍后将用于登录到Ubuntu桌面虚拟机。此密码限制为八个字符，需要设置和验证，如下图所示：
- en: '![](img/00025.jpeg)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00025.jpeg)'
- en: 'A startup script is automatically generated by the shell, as shown in the following
    screenshot. This startup script can be accessed and edited by copying and pasting
    its `PATH` in the following manner:'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 外壳自动生成了一个启动脚本，如下图所示。可以通过复制并粘贴其`PATH`来访问和编辑此启动脚本：
- en: '![](img/00026.jpeg)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00026.jpeg)'
- en: 'In our case, the command to view and edit the script is:'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在我们的情况下，查看和编辑脚本的命令是：
- en: '[PRE3]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This `PATH` may be different in each case. Ensure you set the right `PATH`.
    The `vim` command opens up the script in the text editor on a Mac.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 这个`PATH`在每种情况下可能会有所不同。确保设置正确的`PATH`。`vim`命令会在Mac上的文本编辑器中打开脚本。
- en: The local shell generated a startup script as well as a log file. The startup
    script needs to be opened and edited in a text editor, which will be discussed
    next.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 本地shell生成了一个启动脚本以及一个日志文件。启动脚本需要在文本编辑器中打开和编辑，接下来将讨论这一点。
- en: 'After typing the `vim` command, the screen with the startup script should look
    something like this screenshot:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入`vim`命令后，启动脚本的屏幕应该看起来像下图所示：
- en: '![](img/00027.jpeg)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00027.jpeg)'
- en: 'Type `i` to enter `INSERT` mode. Next, delete all the text in the startup script.
    It should then look like the following screenshot:'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入`i`进入`INSERT`模式。接下来，删除启动脚本中的所有文本。然后它应该看起来像下图所示：
- en: '![](img/00028.jpeg)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00028.jpeg)'
- en: 'Copy paste the following code into the startup script:'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将以下代码复制粘贴到启动脚本中：
- en: '[PRE4]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The script should appear in the editor, as seen in the following screenshot:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 脚本应该出现在编辑器中，如下截图所示：
- en: '![](img/00029.jpeg)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00029.jpeg)'
- en: Press Esc to exit out of `INSERT` mode and type `:wq` to write and quit the
    file.
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按Esc退出`INSERT`模式，然后输入`:wq`以写入并退出文件。
- en: 'Once the startup script has been configured, type the following command in
    the Google shell to kill the server and save the changes:'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动脚本配置完成后，在Google shell中输入以下命令关闭服务器并保存更改：
- en: '[PRE5]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'This command should produce a process ID that looks like the one in the following
    screenshot:'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此命令应该生成一个类似下图中的进程ID：
- en: '![](img/00030.jpeg)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00030.jpeg)'
- en: 'Start the server again by typing the following command:'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过输入以下命令重新启动服务器：
- en: '[PRE6]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The next series of steps will focus on securing the shell tunnel into the Google
    Cloud instance from the local host. Before typing anything on the local shell/terminal,
    ensure that Google Cloud is installed. If not already installed, do so by following
    the instructions in this quick-start guide located at the following website:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的一系列步骤将专注于从本地主机安全地进入Google Cloud实例的外壳隧道。在本地shell/终端上输入任何内容之前，请确保已安装Google
    Cloud。如果尚未安装，请按照位于以下网站的快速入门指南中的说明进行安装：
- en: '[https://cloud.google.com/sdk/docs/quickstart-mac-os-x](https://cloud.google.com/sdk/docs/quickstart-mac-os-x)'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://cloud.google.com/sdk/docs/quickstart-mac-os-x](https://cloud.google.com/sdk/docs/quickstart-mac-os-x)'
- en: 'Once Google Cloud is installed, open up the terminal on your machine and type
    the following commands to connect to the Google Cloud compute instance:'
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装完Google Cloud后，在您的机器上打开终端，并输入以下命令连接到Google Cloud计算实例：
- en: '[PRE7]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Ensure that the instance name, project ID, and zone are specified correctly
    in the preceding commands. On pressing ENTER, the output on the local shell changes
    to what is shown in the following screenshot:'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保在上述命令中正确指定实例名称、项目ID和区域。按下ENTER后，本地shell的输出会变成下图所示的样子：
- en: '![](img/00031.jpeg)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00031.jpeg)'
- en: Once you see the name of your instance followed by `":~$"`, it means that a
    connection has successfully been established between the local host/laptop and
    the Google Cloud instance. After successfully SSHing into the instance, we require
    software called **VNC Viewer** to view and interact with the Ubuntu Desktop that
    has now been successfully set up on the Google Cloud Compute engine. The following
    few steps will discuss how this is achieved.
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦您看到实例名称后跟着`":~$"`，这意味着本地主机/笔记本电脑和Google Cloud实例之间已成功建立了连接。成功通过SSH进入实例后，我们需要一个名为**VNC
    Viewer**的软件来查看和与已在Google Cloud Compute引擎上成功设置的Ubuntu桌面进行交互。接下来的几个步骤将讨论如何实现这一点。
- en: 'VNC Viewer may be downloaded using the following link:'
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可以使用以下链接下载VNC Viewer：
- en: '[https://www.realvnc.com/en/connect/download/viewer/](https://www.realvnc.com/en/connect/download/viewer/)'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.realvnc.com/en/connect/download/viewer/](https://www.realvnc.com/en/connect/download/viewer/)'
- en: 'Once installed, click to open VNC Viewer and in the search bar, type in `localhost::5901`,
    as shown in the following screenshot:'
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装完成后，点击打开VNC Viewer，并在搜索栏中输入`localhost::5901`，如下截图所示：
- en: '![](img/00032.jpeg)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00032.jpeg)'
- en: 'Next, click on **continue** when prompted with the following screen:'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，在提示以下屏幕时点击**continue**：
- en: '![](img/00033.jpeg)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00033.jpeg)'
- en: 'This will prompt you to enter your password for the virtual machine. Enter
    the password that you set earlier while launching the `tightvncserver` command
    for the first time, as shown in the following screenshot:'
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这将提示您输入虚拟机的密码。输入您在第一次启动`tightvncserver`命令时设置的密码，如下截图所示：
- en: '![](img/00034.jpeg)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00034.jpeg)'
- en: 'You will finally be taken into the desktop of your Ubuntu virtual machine on
    Google Cloud Compute. Your Ubuntu Desktop screen must now look something like
    the following screenshot when viewed on VNC Viewer:'
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您将最终被带入到您在Google Cloud Compute上的Ubuntu虚拟机的桌面。当在VNC Viewer上查看时，您的Ubuntu桌面屏幕现在应该看起来像以下截图：
- en: '![](img/00035.jpeg)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00035.jpeg)'
- en: How it works...
  id: totrans-161
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: You have now successfully set up VNC Viewer for interactions with the Ubuntu
    virtual machine/desktop. Anytime the Google Cloud instance is not in use, it is
    recommended to suspend or shut down the instance so that additional costs are
    not being incurred. The cloud approach is optimal for developers who may not have
    access to physical resources with high memory and storage.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 您现在已成功为与Ubuntu虚拟机/桌面交互设置了VNC Viewer。建议在Google Cloud实例不使用时暂停或关闭实例，以避免产生额外费用。云方法对于可能无法访问高内存和存储资源的开发人员来说是最佳的。
- en: There's more...
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'While we discussed Google Cloud as a cloud option for Spark,  it is possible
    to leverage Spark on the following cloud platforms as well:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们讨论了Google Cloud作为Spark的云选项，但也可以在以下云平台上利用Spark：
- en: Microsoft Azure
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Microsoft Azure
- en: Amazon Web Services
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Amazon Web Services
- en: See also
  id: totrans-167
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: 'In order to learn more about Google Cloud Platform and sign up for a free subscription,
    visit the following website:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于Google Cloud Platform并注册免费订阅，请访问以下网站：
- en: '[https://cloud.google.com/](https://cloud.google.com/)'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://cloud.google.com/](https://cloud.google.com/)'
- en: Installing and configuring Spark and prerequisites on Ubuntu Desktop
  id: totrans-170
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Ubuntu桌面上安装和配置Spark及其先决条件
- en: 'Before Spark can get up and running, there are some necessary prerequisites
    that need to be installed on a newly minted Ubuntu Desktop. This section will
    focus on installing and configuring the following on Ubuntu Desktop:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在Spark可以运行之前，需要在新创建的Ubuntu桌面上安装一些必要的先决条件。本节将重点介绍在Ubuntu桌面上安装和配置以下内容：
- en: Java 8 or higher
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Java 8或更高版本
- en: Anaconda
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Anaconda
- en: Spark
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Spark
- en: Getting ready
  id: totrans-175
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: The only requirement for this section is having administrative rights to install
    applications onto the Ubuntu Desktop.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 本节的唯一要求是具有在Ubuntu桌面上安装应用程序的管理权限。
- en: How to do it...
  id: totrans-177
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 操作步骤...
- en: 'This section walks through the steps in the recipe to install Python 3, Anaconda,
    and Spark on Ubuntu Desktop:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将逐步介绍在Ubuntu桌面上安装Python 3、Anaconda和Spark的步骤：
- en: 'Install Java on Ubuntu through the terminal application, which can be found
    by searching for the app and then locking it to the launcher on the left-hand
    side, as seen in the following screenshot:'
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过终端应用程序在Ubuntu上安装Java，可以通过搜索该应用程序并将其锁定到左侧的启动器上找到，如下截图所示：
- en: '![](img/00036.jpeg)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00036.jpeg)'
- en: 'Perform an initial test for Java on the virtual machine by executing the following
    command at the terminal:'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过在终端执行以下命令，在虚拟机上进行Java的初始测试：
- en: '[PRE8]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Execute the following four commands at the terminal to install Java:'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在终端执行以下四个命令来安装Java：
- en: '[PRE9]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'After accepting the necessary license agreements for Oracle, perform a secondary
    test of Java on the virtual machine by executing `java -version` once again in
    the terminal. A successful installation for Java will display the following outcome
    in the terminal:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接受Oracle的必要许可协议后，在终端再次执行`java -version`进行Java的二次测试。成功安装Java将在终端显示以下结果：
- en: '[PRE10]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Next, install the most recent version of Anaconda. Current versions of Ubuntu
    Desktop come preinstalled with Python. While it is convenient that Python comes
    preinstalled with Ubuntu, the installed version is for Python 2.7, as seen in
    the following output:'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，安装最新版本的Anaconda。当前版本的Ubuntu桌面预装了Python。虽然Ubuntu预装Python很方便，但安装的版本是Python
    2.7，如下输出所示：
- en: '[PRE11]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The current version of Anaconda is v4.4 and the current version of Python 3
    is v3.6\. Once downloaded, view the Anaconda installation file by accessing the
    `Downloads` folder using the following command:'
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当前版本的Anaconda是v4.4，Python 3的当前版本是v3.6。下载后，通过以下命令访问`Downloads`文件夹查看Anaconda安装文件：
- en: '[PRE12]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Once in the `Downloads` folder, initiate the installation for Anaconda by executing
    the following command:'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 进入`Downloads`文件夹后，通过执行以下命令启动Anaconda的安装：
- en: '[PRE13]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Please note that the version of Anaconda, as well as any other software installed,
    may differ as newer updates are released to the public. The version of Anaconda
    that we are using in this chapter and in this book can be downloaded from [https://repo.continuum.io/archive/Anaconda3-4.4.0-Linux-x86.sh](https://repo.continuum.io/archive/Anaconda3-4.4.0-Linux-x86.sh)
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，Anaconda的版本以及其他安装的软件的版本可能会有所不同，因为新的更新版本会发布给公众。本章和本书中使用的Anaconda版本可以从[https://repo.continuum.io/archive/Anaconda3-4.4.0-Linux-x86.sh](https://repo.continuum.io/archive/Anaconda3-4.4.0-Linux-x86.sh)下载
- en: 'Once the Anaconda installation is complete, restart the Terminal application
    to confirm that Python 3 is now the default Python environment through Anaconda
    by executing `python --version` in the terminal:'
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装完成Anaconda后，重新启动终端应用程序，通过在终端中执行`python --version`来确认Python 3现在是Anaconda的默认Python环境：
- en: '[PRE14]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The Python 2 version is still available under Linux, but will require an explicit
    call when executing a script, as seen in the following command:'
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Linux仍然提供Python 2版本，但在执行脚本时需要显式调用，如下命令所示：
- en: '[PRE15]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Visit the following website to begin the Spark download and installation process:'
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 访问以下网站开始Spark下载和安装过程：
- en: '[https://spark.apache.org/downloads.html](https://spark.apache.org/downloads.html)'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://spark.apache.org/downloads.html](https://spark.apache.org/downloads.html)'
- en: 'Select the download link. The following file will be downloaded to the `Downloads`
    folder in Ubuntu:'
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择下载链接。以下文件将下载到Ubuntu的**下载**文件夹中：
- en: '`spark-2.2.0-bin-hadoop2.7.tgz`'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '`spark-2.2.0-bin-hadoop2.7.tgz`'
- en: 'View the file at the terminal level by executing the following commands:'
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过执行以下命令在终端级别查看文件：
- en: '[PRE16]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Extract the `tgz` file by executing the following command:'
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过执行以下命令提取`tgz`文件：
- en: '[PRE17]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Another look at the Downloads directory using `ls` shows both the `tgz` file
    and the extracted folder:'
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`ls`查看**下载**目录，显示`tgz`文件和提取的文件夹：
- en: '[PRE18]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Move the extracted folder from the `Downloads` folder to the `Home` folder
    by executing the following command:'
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过执行以下命令，将提取的文件夹从**下载**文件夹移动到**主目录**文件夹：
- en: '[PRE19]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Now, the `spark-2.2.0-bin-hadoop2.7` folder has been moved to the **Home**
    folder, which can be viewed when selecting the **Files** icon on the left-hand
    side toolbar, as seen in the following screenshot:'
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，`spark-2.2.0-bin-hadoop2.7`文件夹已移动到**主目录**文件夹中，在左侧工具栏上选择**文件**图标时可以查看，如下截图所示：
- en: '![](img/00037.jpeg)'
  id: totrans-211
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00037.jpeg)'
- en: 'Spark is now installed. Initiate Spark from the terminal by executing the following
    script at the terminal level:'
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Spark现在已安装。通过在终端级别执行以下脚本来启动Spark：
- en: '[PRE20]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Perform a final test to ensure Spark is up and running at the terminal by executing
    the following command to ensure that the `SparkContext` is driving the cluster
    in the local environment:'
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行最终测试，以确保Spark在终端上运行，通过执行以下命令来确保`SparkContext`在本地环境中驱动集群：
- en: '[PRE21]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: How it works...
  id: totrans-216
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: This section explains the reasoning behind the installation process for Python,
    Anaconda, and Spark.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 本节解释了Python、Anaconda和Spark的安装过程背后的原因。
- en: Spark runs on the **Java virtual machine** (**JVM**), the Java **Software Development
    Kit** (**SDK**) is a prerequisite installation for Spark to run on an Ubuntu virtual
    machine.
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Spark在**Java虚拟机**（**JVM**）上运行，Java **软件开发工具包**（**SDK**）是Spark在Ubuntu虚拟机上运行的先决条件安装。
- en: In order for Spark to run on a local machine or in a cluster, a minimum version
    of Java 6 is required for installation.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使Spark在本地机器或集群上运行，安装需要最低版本的Java 6。
- en: Ubuntu recommends the `sudo apt install` method for Java as it ensures that
    packages downloaded are up to date.
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Ubuntu建议使用`sudo apt install`方法安装Java，因为这样可以确保下载的软件包是最新的。
- en: 'Please note that if Java is not currently installed, the output in the terminal
    will show the following message:'
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 请注意，如果尚未安装Java，则终端中的输出将显示以下消息：
- en: '[PRE22]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: While Python 2 is fine, it is considered legacy Python. Python 2 is facing an
    end of life date in 2020; therefore, it is recommended that all new Python development
    be performed with Python 3, as will be the case in this publication. Up until
    recently, Spark was only available with Python 2\. That is no longer the case.
    Spark works with both Python 2 and 3. A convenient way to install Python 3, as
    well as many dependencies and libraries, is through Anaconda. Anaconda is a free
    and open source distribution of Python, as well as R. Anaconda manages the installation
    and maintenance of many of the most common packages used in Python for data science-related
    tasks.
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 虽然Python 2也可以，但被视为传统Python。 Python 2将于2020年面临终止生命周期日期；因此，建议所有新的Python开发都使用Python
    3，就像本出版物中的情况一样。直到最近，Spark只能与Python 2一起使用。现在不再是这种情况。Spark可以与Python 2和3一起使用。通过Anaconda是安装Python
    3以及许多依赖项和库的便捷方式。Anaconda是Python和R的免费开源发行版。Anaconda管理Python中用于数据科学相关任务的许多常用软件包的安装和维护。
- en: 'During the installation process for Anaconda, it is important to confirm the
    following conditions:'
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在安装Anaconda过程中，重要的是确认以下条件：
- en: Anaconda is installed in the `/home/username/Anaconda3` location
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Anaconda安装在`/home/username/Anaconda3`位置
- en: The Anaconda installer prepends the Anaconda3 install location to a `PATH` in `/home/username/.bashrc`
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Anaconda安装程序将Anaconda3安装位置前置到`/home/username/.bashrc`中的`PATH`中
- en: After Anaconda has been installed, download Spark. Unlike Python, Spark does
    not come preinstalled on Ubuntu and therefore, will need to be downloaded and
    installed.
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装Anaconda后，下载Spark。与Python不同，Spark不会预先安装在Ubuntu上，因此需要下载和安装。
- en: 'For the purposes of development with deep learning, the following preferences
    will be selected for Spark:'
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了进行深度学习开发，将选择以下Spark的偏好设置：
- en: '**Spark release**: **2.2.0** (Jul 11 2017)'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Spark版本**：**2.2.0** (2017年7月11日)'
- en: '**Package type**: Prebuilt for Apache Hadoop 2.7 and later'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**软件包类型**：预构建的Apache Hadoop 2.7及更高版本'
- en: '**Download type**: Direct download'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**下载类型**：直接下载'
- en: Once Spark has been successfully installed, the output from executing Spark
    at the command line should look something similar to that shown in the following
    screenshot:![](img/00038.jpeg)
  id: totrans-232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦Spark安装成功，通过在命令行执行Spark的输出应该看起来类似于以下截图：![](img/00038.jpeg)
- en: Two important features to note when initializing Spark are that it is under
    the `Python 3.6.1` | `Anaconda 4.4.0 (64-bit)` | framework and that the Spark
    logo is version 2.2.0.
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化Spark时需要注意的两个重要特性是，它是在`Python 3.6.1` | `Anaconda 4.4.0 (64位)` | 框架下，并且Spark标志的版本是2.2.0。
- en: Congratulations! Spark is successfully installed on the local Ubuntu virtual
    machine. But, not everything is complete. Spark development is best when Spark
    code can be executed within a Jupyter notebook, especially for deep learning.
    Thankfully, Jupyter has been installed with the Anaconda distribution performed
    earlier in this section.
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 恭喜！Spark已成功安装在本地Ubuntu虚拟机上。但是，还没有完成所有工作。当Spark代码可以在Jupyter笔记本中执行时，Spark开发效果最佳，特别是用于深度学习。幸运的是，Jupyter已经在本节前面执行的Anaconda分发中安装了。
- en: There's more...
  id: totrans-235
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: You may be asking why we did not just use `pip install pyspark` to use Spark
    in Python. Previous versions of Spark required going through the installation
    process that we did in this section. Future versions of Spark, starting with 2.2.0
    will begin to allow installation directly through the `pip` approach. We used
    the full installation method in this section to ensure that you will be able to
    get Spark installed and fully-integrated, in case you are using an earlier version
    of Spark.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 也许你会问为什么我们不直接使用`pip install pyspark`在Python中使用Spark。之前的Spark版本需要按照我们在本节中所做的安装过程。从2.2.0开始的未来版本的Spark将开始允许通过`pip`方法直接安装。我们在本节中使用完整的安装方法，以确保您能够在使用早期版本的Spark时安装和完全集成Spark。
- en: See also
  id: totrans-237
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: 'To learn more about Jupyter notebooks and their integration with Python, visit
    the following website:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于Jupyter笔记本及其与Python的集成，请访问以下网站：
- en: '[http://jupyter.org](http://jupyter.org)'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://jupyter.org](http://jupyter.org)'
- en: 'To learn more about Anaconda and download a version for Linux, visit the following
    website:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解有关Anaconda的更多信息并下载Linux版本，请访问以下网站：
- en: '[https://www.anaconda.com/download/](https://www.anaconda.com/download/).'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.anaconda.com/download/](https://www.anaconda.com/download/)'
- en: Integrating Jupyter notebooks with Spark
  id: totrans-242
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将Jupyter笔记本与Spark集成
- en: When learning Python for the first time, it is useful to use Jupyter notebooks
    as an **interactive developing environment** (**IDE**). This is one of the main
    reasons why Anaconda is so powerful. It fully integrates all of the dependencies
    between Python and Jupyter notebooks. The same can be done with PySpark and Jupyter
    notebooks. While Spark is written in Scala, PySpark allows for the translation
    of code to occur within Python instead.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 初学Python时，使用Jupyter笔记本作为交互式开发环境（IDE）非常有用。这也是Anaconda如此强大的主要原因之一。它完全整合了Python和Jupyter笔记本之间的所有依赖关系。PySpark和Jupyter笔记本也可以做到同样的事情。虽然Spark是用Scala编写的，但PySpark允许在Python中进行代码转换。
- en: Getting ready
  id: totrans-244
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 做好准备
- en: Most of the work in this section will just require accessing the `.bashrc` script
    from the terminal.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 本节大部分工作只需要从终端访问`.bashrc`脚本。
- en: How to do it...
  id: totrans-246
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'PySpark is not configured to work within Jupyter notebooks by default, but
    a slight tweak of the `.bashrc` script can remedy this issue. We will walk through
    these steps in this section:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: PySpark默认情况下未配置为在Jupyter笔记本中工作，但稍微调整`.bashrc`脚本即可解决此问题。我们将在本节中逐步介绍这些步骤：
- en: 'Access the `.bashrc` script by executing the following command:'
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过执行以下命令访问`.bashrc`脚本：
- en: '[PRE23]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Scrolling all the way to the end of the script should reveal the last command
    modified, which should be the `PATH` set by Anaconda during the installation earlier
    in the previous section. The `PATH` should appear as seen in the following:'
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 滚动到脚本的最后应该会显示最后修改的命令，这应该是在上一节安装过程中由Anaconda设置的`PATH`。`PATH`应该如下所示：
- en: '[PRE24]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Underneath, the `PATH` added by the Anaconda installer can include a custom
    function that helps communicate the Spark installation with the Jupyter notebook
    installation from Anaconda3\. For the purposes of this chapter and remaining chapters,
    we will name that function `sparknotebook`. The configuration should appear as
    the following for `sparknotebook()`:'
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Anaconda安装程序添加的`PATH`下，可以包括一个自定义函数，帮助将Spark安装与Anaconda3中的Jupyter笔记本安装进行通信。在本章和后续章节中，我们将把该函数命名为`sparknotebook`。配置应该如下所示：`sparknotebook()`
- en: '[PRE25]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The updated `.bashrc` script should look like the following once saved:![](img/00039.jpeg)
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新后的`.bashrc`脚本应该保存后如下所示：![](img/00039.jpeg)
- en: 'Save and exit from the `.bashrc` file. It is recommended to communicate that
    the `.bashrc` file has been updated by executing the following command and restarting
    the terminal application:'
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保存并退出`.bashrc`文件。建议通过执行以下命令并重新启动终端应用程序来确认`.bashrc`文件已更新：
- en: '[PRE26]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: How it works...
  id: totrans-257
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: Our goal in this section is to integrate Spark directly into a Jupyter notebook
    so that we are not doing our development at the terminal and instead utilizing
    the benefits of developing within a notebook. This section explains how the Spark
    integration within a Jupyter notebook takes place.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 本节的目标是将Spark直接集成到Jupyter笔记本中，以便我们不是在终端上进行开发，而是利用在笔记本中开发的好处。本节解释了在Jupyter笔记本中进行Spark集成的过程。
- en: 'We will create a command function, `sparknotebook`, that we can call from the
    terminal to open up a Spark session through Jupyter notebooks from the Anaconda
    installation. This requires two settings to be set in the `.bashrc` file:'
  id: totrans-259
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将创建一个名为`sparknotebook`的命令函数，我们可以从终端调用它，通过Anaconda安装打开一个Spark会话的Jupyter笔记本。这需要在`.bashrc`文件中设置两个设置：
- en: PySpark Python be set to python 3
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: PySpark Python设置为python 3
- en: PySpark driver for python to be set to Jupyter
  id: totrans-261
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将PySpark驱动程序设置为Jupyter的Python
- en: 'The `sparknotebook` function can now be accessed directly from the terminal
    by executing the following command:'
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在可以直接从终端访问`sparknotebook`函数，方法是执行以下命令：
- en: '[PRE27]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: The function should then initiate a brand new Jupyter notebook session through
    the default web browser. A new Python script within Jupyter notebooks with a `.ipynb` extension
    can be created by clicking on the New button on the right-hand side and by selecting Python
    3 under Notebook: as seen in the following screenshot:![](img/00040.jpeg)
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，该函数应通过默认的Web浏览器启动全新的Jupyter笔记本会话。可以通过单击右侧的“新建”按钮并在“笔记本”下选择“Python 3”来创建Jupyter笔记本中的新Python脚本，其扩展名为`.ipynb`，如下截图所示:![](img/00040.jpeg)
- en: Once again, just as was done at the terminal level for Spark, a simple script
    of `sc` will be executed within the notebook to confirm that Spark is up and running
    through Jupyter:![](img/00041.jpeg)
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再次，就像在终端级别为Spark做的那样，将在笔记本中执行`sc`的简单脚本，以确认Spark是否通过Jupyter正常运行:![](img/00041.jpeg)
- en: Ideally, the Version, Master, and AppName should be identical to the earlier
    output when `sc` was executed at the terminal. If this is the case, then PySpark
    has been successfully installed and configured to work with Jupyter notebooks.
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 理想情况下，版本、主节点和应用名称应与在终端执行`sc`时的输出相同。如果是这种情况，那么PySpark已成功安装和配置为与Jupyter笔记本一起工作。
- en: There's more...
  id: totrans-267
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: It is important to note that if we were to call a Jupyter notebook through the
    terminal without specifying `sparknotebook`, our Spark session will never be initiated
    and we will receive an error when executing the `SparkContext` script.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要注意，如果我们通过终端调用Jupyter笔记本而没有指定`sparknotebook`，我们的Spark会话将永远不会启动，并且在执行`SparkContext`脚本时会收到错误。
- en: 'We can access a traditional Jupyter notebook by executing the following at
    the terminal:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过在终端执行以下内容来访问传统的Jupyter笔记本：
- en: '[PRE28]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Once we start the notebook, we can try and execute the same script for `sc.master`
    as we did previously, but this time we will receive the following error:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们启动笔记本，我们可以尝试执行与之前相同的`sc.master`脚本，但这次我们将收到以下错误：
- en: '![](img/00042.jpeg)'
  id: totrans-272
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00042.jpeg)'
- en: See also
  id: totrans-273
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: 'There are many managed offerings online of companies offering Spark through
    a notebook interface where the installation and configuration of Spark with a
    notebook have already been managed for you. These are the following:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 在线提供了许多公司提供Spark的托管服务，通过笔记本界面，Spark的安装和配置已经为您管理。以下是：
- en: Hortonworks ([https://hortonworks.com/](https://hortonworks.com/))
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hortonworks ([https://hortonworks.com/](https://hortonworks.com/))
- en: Cloudera ([https://www.cloudera.com/](https://www.cloudera.com/))
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cloudera ([https://www.cloudera.com/](https://www.cloudera.com/))
- en: MapR ([https://mapr.com/](https://mapr.com/))
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MapR ([https://mapr.com/](https://mapr.com/))
- en: DataBricks ([https://databricks.com/](https://mapr.com/))
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DataBricks ([https://databricks.com/](https://mapr.com/))
- en: Starting and configuring a Spark cluster
  id: totrans-279
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 启动和配置Spark集群
- en: For most chapters, one of the first things that we will do is to initialize
    and configure our Spark cluster.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大多数章节，我们将要做的第一件事是初始化和配置我们的Spark集群。
- en: Getting ready
  id: totrans-281
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备就绪
- en: Import the following before initializing cluster.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 在初始化集群之前导入以下内容。
- en: '`from pyspark.sql import SparkSession`'
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from pyspark.sql import SparkSession`'
- en: How to do it...
  id: totrans-284
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: This section walks through the steps to initialize and configure a Spark cluster.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 本节介绍了初始化和配置Spark集群的步骤。
- en: 'Import `SparkSession` using the following script:'
  id: totrans-286
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下脚本导入`SparkSession`：
- en: '[PRE29]'
  id: totrans-287
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Configure `SparkSession` with a variable named `spark` using the following
    script:'
  id: totrans-288
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下脚本配置名为`spark`的`SparkSession`：
- en: '[PRE30]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: How it works...
  id: totrans-290
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: This section explains how the `SparkSession` works as an entry point to develop
    within Spark.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 本节解释了`SparkSession`作为在Spark中开发的入口点的工作原理。
- en: Staring with Spark 2.0, it is no longer necessary to create a `SparkConf` and
    `SparkContext` to begin development in Spark. Those steps are no longer needed
    as importing `SparkSession` will handle initializing a cluster.  Additionally,
    it is important to note that `SparkSession` is part of the `sql` module from `pyspark`.
  id: totrans-292
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从Spark 2.0开始，不再需要创建`SparkConf`和`SparkContext`来开始在Spark中进行开发。导入`SparkSession`将处理初始化集群。此外，重要的是要注意，`SparkSession`是`pyspark`的`sql`模块的一部分。
- en: 'We can assign properties to our `SparkSession`:'
  id: totrans-293
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以为我们的`SparkSession`分配属性：
- en: '`master`: assigns the Spark master URL to run on our `local` machine with the
    maximum available number of cores.'
  id: totrans-294
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`master`：将Spark主URL分配给在我们的`local`机器上运行，并使用最大可用的核心数。'
- en: '`appName`: assign a name for the application'
  id: totrans-295
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`appName`：为应用程序分配一个名称'
- en: '`config`: assign `6gb` to the `spark.executor.memory`'
  id: totrans-296
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`config`：将`spark.executor.memory`分配为`6gb`'
- en: '`getOrCreate`: ensures that a `SparkSession` is created if one is not available
    and retrieves an existing one if it is available'
  id: totrans-297
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`getOrCreate`：确保如果没有可用的`SparkSession`，则创建一个，并在可用时检索现有的`SparkSession`'
- en: There's more...
  id: totrans-298
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: For development purposes, while we are building an application on smaller datasets,
    we can just use `master("local")`.  If we were to deploy on a production environment,
    we would want to specify `master("local[*]")` to ensure we are using the maximum
    cores available and get optimal performance.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 出于开发目的，当我们在较小的数据集上构建应用程序时，我们可以只使用`master("local")`。如果我们要在生产环境中部署，我们将希望指定`master("local[*]")`，以确保我们使用最大可用的核心并获得最佳性能。
- en: See also
  id: totrans-300
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: 'To learn more about `SparkSession.builder`, visit the following website:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解有关`SparkSession.builder`的更多信息，请访问以下网站：
- en: '[https://spark.apache.org/docs/2.2.0/api/java/org/apache/spark/sql/SparkSession.Builder.html](https://spark.apache.org/docs/2.2.0/api/java/org/apache/spark/sql/SparkSession.Builder.html)'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://spark.apache.org/docs/2.2.0/api/java/org/apache/spark/sql/SparkSession.Builder.html](https://spark.apache.org/docs/2.2.0/api/java/org/apache/spark/sql/SparkSession.Builder.html)'
- en: Stopping a Spark cluster
  id: totrans-303
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 停止Spark集群
- en: Once we are done developing on our cluster, it is ideal to shut it down and
    preserve resources.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们在集群上开发完成，最好关闭它并保留资源。
- en: How to do it...
  id: totrans-305
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: This section walks through the steps to stop the `SparkSession`.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 本节介绍了停止`SparkSession`的步骤。
- en: 'Execute the following script:'
  id: totrans-307
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下脚本：
- en: '`spark.stop()`'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: '`spark.stop()`'
- en: 'Confirm that the session has closed by executing the following script:'
  id: totrans-309
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过执行以下脚本来确认会话是否已关闭：
- en: '`sc.master`'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: '`sc.master`'
- en: How it works...
  id: totrans-311
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: This section explains how to confirm that a Spark cluster has been shut down.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将解释如何确认Spark集群已关闭。
- en: If the cluster has been shut down, you will receive the error message seen in
    the following screenshot when executing another Spark command in the notebook:![](img/00043.jpeg)
  id: totrans-313
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果集群已关闭，当在笔记本中执行另一个Spark命令时，将会收到以下截图中看到的错误消息：![](img/00043.jpeg)
- en: There's more...
  id: totrans-314
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: Shutting down Spark clusters may not be as critical when working in a local
    environment; however, it will prove costly when Spark is deployed in a cloud environment
    where you are charged for compute power.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 在本地环境中工作时，关闭Spark集群可能并不那么重要；然而，在Spark部署在计算成本需要付费的云环境中，关闭集群将会很昂贵。
