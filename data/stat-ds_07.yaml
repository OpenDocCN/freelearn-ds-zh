- en: Regularization for Database Improvement
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据库改进的正则化
- en: In this chapter, we will introduce the idea of statistical regularization to
    improve data models in an effort to help comprehend what statistical regularization
    is, why it is important as well as to feel comfortable with the various statistical
    regularization methods.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍统计正则化的概念，以改善数据模型，并帮助理解统计正则化是什么、为什么它很重要，并且让您对各种统计正则化方法感到熟悉。
- en: 'In this chapter, we''ve organized information into the following areas:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中，我们将信息组织成以下几个方面：
- en: Statistical regularization
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 统计正则化
- en: Using data to understand statistical regularization
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用数据理解统计正则化
- en: Improving data or a data model
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 改进数据或数据模型
- en: Using R for statistical regularization
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用R进行统计正则化
- en: Statistical regularization
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 统计正则化
- en: So, what is statistical regularization?
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，什么是统计正则化呢？
- en: With regularization, whether we are speaking about mathematics, statistics,
    or machine learning, we are essentially talking about a process of adding additional
    information in order to solve a problem.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在正则化中，无论我们讨论的是数学、统计学还是机器学习，本质上是在讨论通过添加额外信息来解决问题的过程。
- en: The term **regularization** has been described as an abstract concept of management of complex
    systems(according to a set of rules or accepted concepts). These rules will define
    how one can add or modify values in order to satisfy a requirement or solve a
    problem.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '**正则化**一词被描述为管理复杂系统的抽象概念（根据一套规则或公认的概念）。这些规则定义了如何添加或修改值，以满足要求或解决问题。'
- en: Does adding or modifying values mean changing data? (More about this will be
    studied later in this chapter.)
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 添加或修改值是否意味着改变数据？（本章稍后将深入研究这一问题。）
- en: Various statistical regularization methods
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 各种统计正则化方法
- en: 'Within the statistical community, the most popular statistical regularization
    methods may include the following:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在统计学界，最流行的统计正则化方法可能包括以下几种：
- en: Ridge
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 脊
- en: Lasso
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 套索
- en: Least angles
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最小角度
- en: Ridge
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 脊
- en: Ridge regression is a statistical technique that is used when analyzing regression
    data or models that suffer from a condition known as **multicollinearity**. When
    multicollinearity occurs, estimates may be unbiased but their variances are usually
    large and far from the true value. This technique adds a degree of bias to the
    regression estimates to reduce standard errors (to produce estimates that are
    more dependable).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 脊回归是一种统计技术，通常用于分析回归数据或模型，这些数据或模型存在一个被称为**多重共线性**的问题。当出现多重共线性时，估计值可能是无偏的，但其方差通常很大，且远离真实值。此技术通过向回归估计添加一定的偏差来减少标准误差（以产生更可靠的估计值）。
- en: Multicollinearity is a condition within statistics in which a predictor (variable)
    in multiple regression models can be linearly predicted from the others with a
    significant accuracy.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 多重共线性是统计学中的一种现象，在这种情况下，多元回归模型中的一个预测因子可以通过其他预测因子线性地预测，并且预测准确度较高。
- en: Lasso
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 套索
- en: '**Least absolute shrinkage and selection operator** (**Lasso**) is a statistical
    technique that performs both variable selection and regularization in an effort
    to enhance prediction accuracies within a model.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**最小绝对收缩和选择算子**（**Lasso**）是一种统计技术，既执行变量选择，又进行正则化，以提高模型中的预测准确性。'
- en: The process of choosing or selecting variables within a statistical model results,
    obviously, in reducing the number of variables, which is also referred to as variable
    shrinkage.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在统计模型中选择或挑选变量的过程显然会导致变量数量的减少，这也被称为变量收缩。
- en: Least angles
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最小角度
- en: '**Least Angle Regression** (**LARS**) is a statistical technique used by data
    scientists when dealing with high-dimensional data. If there is speculation that
    a response variable is determined by a particular subset of predictors, then the
    LARS technique can help with determining which variables to include in the regression
    process.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**最小角度回归**（**LARS**）是一种统计技术，数据科学家在处理高维数据时会使用此技术。如果怀疑某响应变量是由特定的预测因子子集决定的，那么LARS技术可以帮助确定应将哪些变量纳入回归过程。'
- en: Opportunities for regularization
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 正则化机会
- en: So, when would you, a data scientist, consider using any type of regularization
    method?
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，作为数据科学家，您何时会考虑使用任何类型的正则化方法？
- en: 'Well, the truth is that there is no absolute rule that dictates the use of
    regularization; however, there are certain indicators to observe that should cause
    you to consider regularization, for example:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，没有绝对的规则规定何时使用正则化；然而，有一些指标可以观察，当这些指标出现时，你应该考虑使用正则化。例如：
- en: If your data contains a high variable count
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果数据中包含较高的变量计数
- en: If there is a low ratio of the number of observations to the number of variables
    in your data
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果数据中观测值的数量与变量数量的比率很低
- en: In [Chapter 6](8a0b3272-dfa0-46ca-9e90-f6050f2007cd.xhtml), *Database Progression
    to Database Regression* (on statistical regression), we reviewed some sample data
    consisting of consulting project results. In that example, we explored the relationship
    between the total hours billed to the project, the total project management hours
    spent on the project, and the project's supposed profitability.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第6章](8a0b3272-dfa0-46ca-9e90-f6050f2007cd.xhtml)，*从数据库发展到数据库回归*（统计回归），我们回顾了一些包含咨询项目结果的示例数据。在该示例中，我们探讨了项目的总开票小时数、项目管理的总小时数和项目假定的盈利能力之间的关系。
- en: 'Looking closer at that same data, perhaps we may now see additional variables,
    such as the following:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 仔细观察相同的数据，也许我们现在会看到更多的变量，例如：
- en: Number of consultants assigned to the project full time
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分配到项目的全职顾问数量
- en: Number of consultants assigned to the project part-time
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分配到项目的兼职顾问数量
- en: Number of sub-contractors assigned to the project (full time or part time)
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分配到项目的分包商数量（全职或兼职）
- en: Number of customer resources assigned to the project full time
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分配到项目的全职客户资源数量
- en: Number of customer resources assigned to the project part-time
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分配到项目的兼职客户资源数量
- en: Number of local resources assigned to the project
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分配到项目的本地资源数量
- en: Years of experience with the projects core technology
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在项目核心技术方面的经验年数
- en: Total project management hours
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 总项目管理小时数
- en: Total development hours
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 总开发小时数
- en: Hourly bill rate
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每小时账单费率
- en: Total hours invoiced
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 总开票小时数
- en: Number of technologies used in the project
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 项目中使用的技术数量
- en: Project style (time and materials, not to exceed, or staff augment)
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 项目风格（时间和材料、不可超出预算或人员增补）
- en: Here, we can see more than twelve possible independent or predictor variables—certainly
    a manageable number—especially given that the number of observations (records)
    in the file is over 100 (the ratio of variables to observations is about 12%).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到超过十二个可能的自变量或预测变量——这显然是一个可管理的数量——特别是考虑到文件中的观测值（记录）数量超过100个（变量与观测值的比例约为12%）。
- en: An independent variable (or experimental or predictor variable) is a variable
    that is being manipulated in a model to observe the effect on a dependent variable,
    or an outcome variable.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 自变量（或实验变量或预测变量）是在模型中被操控的变量，目的是观察它对因变量或结果变量的影响。
- en: When a data scientist speaks of high variable counts, they are really referring
    to an excessive number or, if the number of variables is approaching the number
    of observations, (not so in this example) but suppose we had more than 50 possible
    predictor variables in our data of only 100 observations? This is what can be
    referred to as an overly complex model and warrants consideration of using a common
    regulation method.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据科学家谈到高变量计数时，实际上他们指的是过多的变量数，或者当变量数接近观测数时（在这个例子中不是如此），假设我们在只有100个观测值的数据中有超过50个可能的预测变量？这就是所谓的过于复杂的模型，并需要考虑使用常见的正则化方法。
- en: What constitutes as overly complex is often a subject for debate and often differs
    based on the data and objectives of the statistical model.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 什么构成过于复杂的模型通常是一个争议话题，且往往根据数据和统计模型的目标不同而有所不同。
- en: Experience shows us that when a model is excessively complex, a model may fit
    but have a poor predicting performance (which is ultimately the goal). When this
    occurs, a data scientist will recognize overfitting.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 经验证明，当模型过于复杂时，模型可能会拟合数据，但预测性能较差（最终目标是预测）。当这种情况发生时，数据科学家会认识到过拟合。
- en: Regularization is the statistical technique used by data scientists to avoid
    or address this overfitting problem. The idea behind regularization is that models
    that overfit the data are complex statistical models that have, for example, too
    many parameters.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 正则化是数据科学家用来避免或解决过拟合问题的统计技术。正则化的基本思想是，过拟合数据的模型是复杂的统计模型，这些模型例如具有过多的参数。
- en: 'Other known opportunities for the use of regulation include the following:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 正则化的其他已知应用包括以下内容：
- en: Instances involving high collinearity
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 涉及高共线性的实例
- en: When a project objective is a sparse solution
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当项目目标是稀疏解时
- en: Accounting for variables grouping in high-dimensional data
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 考虑高维数据中的变量分组
- en: Classification
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分类
- en: Collinearity
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 共线性
- en: The term **collinearity** describes a statistical situation when a selected
    predictor variable can be linearly predicted from the others with a considerable
    degree of accuracy.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '**共线性**一词描述了统计学中的一种情况，即选定的预测变量可以通过其他变量线性预测，且具有相当高的准确度。'
- en: Linear prediction is a procedure where future values of a variable are estimated
    based on a linear function of previous samples.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 线性预测是一种程序，其中根据先前样本的线性函数估算变量的未来值。
- en: This typically allows very small changes to the data to produce unreliable results
    regarding individual predictor variables. That is, multiple regression models
    with collinear predictors can indicate how well the entire bundle of predictors
    predicts the outcome variable, but it may not give valid results about any individual
    predictor, or about which predictors are redundant with respect to others.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这通常会导致数据的微小变化产生关于个别预测变量的不可靠结果。也就是说，具有共线性预测变量的多元回归模型可以指示整个预测变量组如何预测结果变量，但可能无法提供关于任何单个预测变量的有效结果，也无法指示哪些预测变量在与其他变量的关系中是冗余的。
- en: Sparse solutions
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 稀疏解
- en: A **sparse solution** or **approximation** is a sparse vector that approximately
    solves an arrangement of equations. Techniques to find sparse approximations have
    found a wide use in applications such as image processing and document analysis.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**稀疏解**或**近似解**是一个稀疏向量，它大致解决了一组方程。寻找稀疏近似解的技术在图像处理和文档分析等应用中得到广泛应用。'
- en: You should recall that a vector is a sequence of data points of the same basic
    type. Members of a vector are officially called **components**.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该记得，向量是由相同基本类型的数据点组成的序列。向量的成员正式称为**分量**。
- en: High-dimensional data
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 高维数据
- en: '**High-dimensional statistics** is the study of data where the number of dimensions
    is higher than the dimensions considered in the classical **multivariate analysis **(**MVA**).'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '**高维统计学**是研究数据维度大于经典**多元分析**（**MVA**）中考虑的维度的数据的学科。'
- en: In statistical studies, a **multivariate random variable** (or **random vector**)
    is a list of variables, each of whose value is unknown. MVA is defined as the
    study of this occasion.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在统计研究中，**多元随机变量**（或**随机向量**）是一个由变量组成的列表，每个变量的值都未知。多元分析（MVA）被定义为研究这一情况的学科。
- en: High-dimensional statistics relies on the theory of random vectors. In many
    applications, the dimension of the data vectors may be larger than the sample
    size.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 高维统计学依赖于随机向量理论。在许多应用中，数据向量的维度可能大于样本大小。
- en: Classification
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分类
- en: '**Classification** is the process of identifying to which of a set of categories
    or groups a new observation belongs, on the basis of a training set of data containing
    observations (or instances) whose category membership is known.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '**分类**是根据已知类别成员的数据训练集，识别新观察值属于哪些类别或组的过程。'
- en: Regularization is a common statistical technique used to address the mentioned
    (as well as other) scenarios. In the next section, we'll look at some simple examples
    of each of these.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 正则化是一种常见的统计技术，用于解决上述（以及其他）情境。在下一节中，我们将介绍每种情境的一些简单示例。
- en: Using data to understand statistical regularization
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用数据理解统计学正则化
- en: Variable selection is an imperative process within the field of statistics as
    it tries to make models simpler to understand, easier to train, and free of misassociations--by
    eliminating variables unrelated to the output.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 变量选择是统计学领域中的一个重要过程，因为它旨在通过消除与输出无关的变量，使模型更易理解、更易训练，并避免误关联。
- en: This (variable selection) is one possible approach to dealing with the problem
    of overfitting. In general, we don't expect a model to completely fit our data;
    in fact, the problem of overfitting often means that it may be disadvantageous
    to our predictive model's accuracy on unseen data if we fit our training or test
    data too well.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 这（变量选择）是解决过拟合问题的一个可能方法。通常，我们不期望模型完全拟合我们的数据；实际上，过拟合问题通常意味着如果我们过度拟合训练或测试数据，它可能会对我们预测模型在未见数据上的准确性造成不利影响。
- en: Rather than using variable selection, the process of regularization is an alternative
    approach to reducing the number of variables in the data in order to deal with
    the issue of overfitting and is essentially a process of introducing an intentional
    bias or constraint in a training of a model that (hopefully) prevents our coefficients
    from exhibiting very high variances.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 与其使用变量选择，不如说正则化过程是一种减少数据中变量数量的替代方法，用来解决过拟合问题，本质上是通过在模型训练过程中引入有意的偏差或约束（希望）防止我们的系数出现非常高的方差。
- en: When the number of parameters (in a population) is deemed very large—particularly
    compared to the number of available observations—linear regression tends to allow
    small changes in a few of the observations to cause the coefficients to change
    drastically (or, as we already put it, exhibit very high variances).
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 当参数的数量（在总体中）被认为非常大——尤其是与可用观察值的数量相比——线性回归往往允许少数观察值的微小变化导致系数发生剧烈变化（或者，如我们所说，表现出非常高的方差）。
- en: '**Ridge regression** is a statistical method that introduces a controlled bias
    (through or using a constraint) to the model''s regression estimates but is effective
    at reducing the model''s variance as well.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '**岭回归**是一种统计方法，通过对模型的回归估计引入受控偏差（通过或使用约束），但它在减少模型方差方面非常有效。'
- en: Ridge regression is sometimes referred to within the data scientist community
    as a penalized regression technique.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 岭回归有时在数据科学社区中被称为一种惩罚回归技术。
- en: There are a number of different R functions and packages that implement ridge
    regression, such as `lm.ridge()` from the `MASS` package and `ridge()` from the
    `genridge` package.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多不同的R函数和包实现了岭回归，例如来自`MASS`包的`lm.ridge()`函数和来自`genridge`包的`ridge()`函数。
- en: You might be familiar with the `MASS` R package but perhaps not `genridge`.
    The `genridge` package introduces generalizations of the standard univariate ridge
    trace plot used in ridge regression and related methods and is worthy of additional
    investigation.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能熟悉`MASS` R包，但可能不太了解`genridge`。`genridge`包引入了岭回归和相关方法中使用的标准单变量岭迹图的推广，并值得进一步研究。
- en: 'In [Chapter 6](8a0b3272-dfa0-46ca-9e90-f6050f2007cd.xhtml), *Database Progression
    to Database Regression* we proposed an example where we created a linear regression
    model on data from a consulting company''s project results in an effort to predict
    a project''s profitability. We used the R function: `lm()`, which takes in two
    main arguments: `formula` (an object of class formula) and `data` (typically a
    `data.frame`), as shown in the following R code:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第6章](8a0b3272-dfa0-46ca-9e90-f6050f2007cd.xhtml)《*从数据库进阶到数据库回归*》中，我们提出了一个例子，使用一个咨询公司项目结果的数据创建了一个线性回归模型，旨在预测项目的盈利能力。我们使用了R函数：`lm()`，该函数接受两个主要参数：`formula`（一个公式类的对象）和`data`（通常是一个`data.frame`），如下所示的R代码：
- en: '[PRE0]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: In this chapter, we are going to work with the `lm.ridge()` function in an attempt
    to acceptably fit the preceding linear model using ridge regression. The preceding
    code generated a linear model using our R object named `MyData`, using the `ProjectManagment`
    variable to predict `Profit`.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用`lm.ridge()`函数，尝试通过岭回归来合理地拟合前述线性模型。前面的代码使用我们的R对象`MyData`，并通过`ProjectManagment`变量来预测`Profit`，从而生成了一个线性模型。
- en: 'The `lm.ridge` function uses the following syntax:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '`lm.ridge`函数使用以下语法：'
- en: '[PRE1]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The arguments are included here for later reference:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 参数在此列出，供后续参考：
- en: '`formula`: This a formula expression as for regression models, of the form
    `response ~ predictors`'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`formula`：这是一个回归模型的公式表达式，形式为`response ~ predictors`'
- en: '`data`: This is an optional data frame in which to interpret the variables
    occurring in the formula'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data`：这是一个可选的数据框，用来解释公式中出现的变量'
- en: '`subset`: This is an expression saying which subset of the rows of the data
    should be used in the fit. All observations are included by default'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`subset`：这是一个表达式，用于指定在拟合过程中应使用数据的哪些行子集。默认情况下，所有观察值都会被包含在内。'
- en: '`na.action`: This a function to filter missing data'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`na.action`：这是一个函数，用于过滤缺失数据'
- en: '`lambda`: This is a scalar or vector of ridge constants'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lambda`：这是一个标量或向量，表示岭常数'
- en: '`model`: Should the model frame be returned?'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model`：是否返回模型框架？'
- en: '`x`: Should the design matrix be returned?'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`x`：是否返回设计矩阵？'
- en: '`y`: Should the response be returned?'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`y`：是否返回响应值？'
- en: '`contrasts`: A list of contrasts to be used for some or all of the factor terms
    in the formula'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`contrasts`：一组对比列表，用于公式中的某些或所有因子项'
- en: The term `lambda` (here, a parameter in the `lm.ridge` function) is typically
    defined as a comparison of a group means on a combination of dependent variables.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '`lambda` 这个术语（在此，指的是 `lm.ridge` 函数中的一个参数）通常定义为在一组依赖变量的组合上对组均值的比较。'
- en: To set up our next example, let's recall that our project data had a ratio of
    variables to observations of 12%. Suppose we've been provided with a new data
    file, one which has only 50 observations. Now our ratio of variables to observations
    goes up to 24%.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 为了设定我们下一个示例，让我们回顾一下，我们的项目数据的变量与观测值的比例为12%。假设我们已经获得了一个新的数据文件，这个文件只有50个观测值。现在，我们的变量与观测值的比例上升到24%。
- en: What about a file with only 12 observations? Further, suppose we are told that
    management believes that these 12 observations are based upon the key, high-visibility
    projects and therefore are unwilling to provide a bigger population to the data
    scientist (at least at this time)? Is it even worthwhile to model this data? Would
    the results be valuable in any way?
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，只有12个观测值的文件呢？再假设我们被告知，管理层认为这12个观测值基于关键的高可见性项目，因此不愿意提供更多的数据样本给数据科学家（至少目前是这样）？对这些数据建模是否还有意义？结果会有任何价值吗？
- en: In general terms, it is said that the more the variables present in a regression
    model, the more flexible a model is considered to be, or that it will become.
    It is very likely that a model of this type will be able to achieve a low error
    by fitting random fluctuations in the training data but the outcome or results
    won't represent the true, underlying distribution of the variables within the
    data and in other words, performance will, therefore, be poor when the model is
    run on future data drawn from the same distribution. (Management would not be
    happy if our predictions for project profitability were based upon flawed logic!)
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 通常来说，人们会说回归模型中变量越多，模型就越灵活，或者说它会变得更加灵活。很可能，这种类型的模型会通过拟合训练数据中的随机波动来获得较低的误差，但结果或结论并不能代表数据中变量的真实潜在分布，换句话说，当该模型在从相同分布中提取的未来数据上运行时，性能会较差。（如果我们关于项目盈利能力的预测是基于错误的逻辑，管理层可不会高兴！）
- en: Given the preceding scenario, how should a data scientist proceed? Well, it
    is certainly possible to fit good models when there are more variables than data
    points, but it must be done very carefully.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述情境下，数据科学家应该如何处理？好吧，尽管数据点少于变量时，确实有可能拟合出好的模型，但这必须非常小心地进行。
- en: As a rule, when the data contains more variables than observations, the results
    may seemingly yield acceptable performance, but as we already mentioned, the solution
    may achieve favorable results or even zero error on the training data. Such a
    model would certainly overfit on actual data because it's too flexible for the
    amount of training data. (This condition is called **ill-posed** or **underdetermined**.)
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，当数据中的变量数量超过观测值时，结果可能看起来会表现良好，但正如我们之前提到的，解决方案可能在训练数据上取得有利结果，甚至是零误差。这样的模型肯定会在实际数据上发生过拟合，因为它对于训练数据的数量来说过于灵活。（这种情况称为**病态**或**欠定**。）
- en: This problem is most often addressed by carefully setting limitations or imposing
    constraints on the parameters, either explicitly or via a logical process. The
    model then becomes a trade-off between fitting the data well and satisfying these
    set limits or constraints. Ridge regression constraints or penalizes data parameters
    and can yield better predictive performance by limiting the model's flexibility,
    thereby reducing the tendency to overfit.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这个问题通常通过仔细设定限制或施加约束来解决，可以通过显式的方式或逻辑过程来实现。模型成为了在很好地拟合数据和满足这些设定的限制或约束之间的权衡。岭回归约束或惩罚数据参数，并通过限制模型的灵活性来提高预测性能，从而减少过拟合的倾向。
- en: However, simply setting limits or imposing constraints doesn't imply that the
    resulting solution will be good or acceptable. Constraints will only produce good
    solutions when they're actually suited to the problem or objective at hand.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，简单地设定限制或施加约束并不意味着得到的解决方案会是好的或可接受的。只有当这些约束真正适合当前问题或目标时，它们才会产生好的解决方案。
- en: Let's get back to the `lm.ridge` function we mentioned earlier in the section.
    A little different from the use of the `lm` function, we can see the difference
    in the following use case examples.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 回到我们在本节前面提到的 `lm.ridge` 函数。与 `lm` 函数的使用稍有不同，我们可以通过以下的使用示例看到其中的差异。
- en: 'Typical to most examples you''ll find, we can utilize the `runif` and `rnom`
    R functions to generate some random number datasets (to be used for illustration),
    we can see the difference between executing `lm` and `lm.ridge`:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 和大多数示例一样，我们可以利用`runif`和`rnom`这两个R函数来生成一些随机数数据集（用于插图），我们可以看到执行`lm`和`lm.ridge`之间的区别：
- en: '[PRE2]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'As we know what we want to explore (for example, estimating the parameters
    in a linear regression model), we can take liberties with creating the testing
    data. The following is an example of R code that generates a linear regression
    model using our three made-up variables:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们知道了我们要探索的内容（例如，估计线性回归模型中的参数），我们就可以在创建测试数据时进行一些自由发挥。以下是一个使用我们三个人造变量生成线性回归模型的R代码示例：
- en: '[PRE3]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The following is the generated output from the preceding code:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是从前面的代码生成的输出：
- en: '![](img/14a32907-43d6-400a-b36a-e6a0ef9f84dd.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![](img/14a32907-43d6-400a-b36a-e6a0ef9f84dd.png)'
- en: Now, let's move on.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们继续。
- en: 'Using our same made-up example data and similar thinking, we can use the R
    function `lm.ridge` to attempt to fit our linear model using ridge regression:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 使用我们相同的虚拟示例数据和类似的思路，我们可以使用R函数`lm.ridge`来尝试通过岭回归拟合线性模型：
- en: '[PRE4]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The following is the output generated (note the difference in output generated
    by the `summary` function):'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是生成的输出（请注意`summary`函数生成的输出差异）：
- en: '![](img/b40c4f50-dc12-4ffe-acf7-87ea1a6da8f5.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b40c4f50-dc12-4ffe-acf7-87ea1a6da8f5.png)'
- en: You'll find that the `summary` function does not yield the same output on a
    linear regression model as it does on a model using the ridge regression method.
    However, there are a variety of packages available to produce sufficient output
    on ridge regression models.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 你会发现，`summary`函数在使用线性回归模型时与在使用岭回归方法的模型中生成的输出不同。然而，有多种包可以生成岭回归模型的充分输出。
- en: Improving data or a data model
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 改善数据或数据模型
- en: There are various parameters which are used for improving data or data model.
    In this section, we will be studying about a few of them.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 有多种参数可用于改善数据或数据模型。在本节中，我们将研究其中的一些。
- en: '![](img/161afca5-347a-4159-8d3b-8154f2c3cf63.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![](img/161afca5-347a-4159-8d3b-8154f2c3cf63.png)'
- en: 'There are much other acceptable or at least well-known methods or approaches
    that a data scientist may employ in an attempt to improve on a statistical model
    (other than regularization) and it''s worth spending some time mentioning a few
    of the most popular:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家可以采用许多其他可接受的或至少是广为人知的方法或策略，以期改进统计模型（除了正则化之外），值得花些时间提到其中一些最流行的方法：
- en: Simplification
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 简化
- en: Relevance
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相关性
- en: Speed
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 速度
- en: Transformation
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 转换
- en: Variation of coefficients
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 系数的变化
- en: Casual inference
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 因果推断
- en: Back to regularization
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回到正则化
- en: Reliability
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可靠性
- en: Simplification
  id: totrans-127
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简化
- en: The first may be just plain common sense. A simple model is just plain easier
    to interpret and understand. Algorithms run more efficiently on a simpler model,
    allowing the data scientist the luxury of higher iterations as well as more time
    to evaluate the outcomes.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个可能只是常识。一个简单的模型更容易解释和理解。算法在简单模型上运行得更高效，允许数据科学家有更多的迭代次数以及更多的时间来评估结果。
- en: Keep in mind, though, that a more complicated model is somewhat more believable,
    so beware of over-simplification. The approach to finding the right mix between
    complex and simple can be worked both ways; by starting simple and adding complexities
    or, more commonly, by starting complex and removing things out of the model, testing,
    and evaluating and then repeating, until successfully understanding the (fitting)
    process.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，请记住，更复杂的模型在某种程度上更具可信性，因此要小心过度简化。寻找复杂与简单之间正确平衡的方法可以双向进行；可以从简单开始并逐步增加复杂性，或者更常见的是，从复杂开始，然后逐步剔除模型中的内容，进行测试、评估并重复，直到成功理解（拟合）过程。
- en: Relevance
  id: totrans-130
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 相关性
- en: This one also seems obvious as well. In other words, don't waste time on statistical
    noise. Using common statistical regression packages, you will have visuals (such
    as quantile-quantile plots, influence diagrams, box plots, and so on) to pour
    over and understand. Spending time on removing irrelevancies from a model or data
    will pay dividends. The trick is to be able to identify what is relevant.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 这一点也似乎显而易见。换句话说，不要浪费时间在统计噪声上。使用常见的统计回归包，你将有可视化图（如分位数-分位数图、影响图、箱形图等）来研究并理解。花时间从模型或数据中剔除无关项将带来回报。关键是能够识别什么是相关的。
- en: Speed
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 速度
- en: The faster a data scientist can fit models, the more models (and data) can be
    evaluated and understood (the ultimate goal!). The ways and means of model optimization
    can be costly--either in time or expertise--and can focus on the model or the
    data, or both.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家能够更快地拟合模型，就能评估和理解更多的模型（和数据）（这就是最终目标！）。模型优化的方式和手段可能是昂贵的——无论是在时间上还是在专业技能上——并且可以集中在模型、数据或两者上。
- en: Transformation
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 变量变换
- en: This is something that can have a substantial effect on a model, but is not
    without risk. Transformation of variables can create models that could make sense
    (and can then be fit and compared to data) and that includes all relevant information,
    but if done irrationally, may introduce bias and imply incorrect outcomes.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一种可能对模型产生重大影响的方法，但并非没有风险。变量的转换可以创建看似合理的模型（然后可以拟合并与数据进行比较），并且包括所有相关信息，但如果做得不理性，可能会引入偏差并导致错误的结果。
- en: Variation of coefficients
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 系数的变异
- en: Testing coefficients to determine whether a coefficient should vary by group,
    and the estimated scale of variation, is a feasible approach to model improvement.
    Very small varying coefficients (across categories) have the propensity to be
    dropped out of consideration.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 测试系数，以确定某个系数是否应该随组别变化，以及变化的估计规模，是改善模型的可行方法。非常小的变动系数（在不同类别之间）有可能被排除在考虑之外。
- en: Casual inference
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 因果推断
- en: You may be tempted to set up a single large regression to answer several causal
    questions that exist in a model or data; however, in observational settings (including
    experiments in which certain conditions of interest are observational), this approach
    risks bias. The bottom line here is, don't assume anything about any perceived
    relationships (or coefficients), especially don't assume that a coefficient can
    be interpreted causally. However, a casual inference can be effective (where appropriate)
    as a method used to improve a statistical model.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会想设置一个大的回归模型来回答模型或数据中存在的多个因果问题；然而，在观察性设置中（包括在某些感兴趣的条件下的实验），这种方法可能存在偏差的风险。关键是，不要对任何感知到的关系（或系数）做出假设，尤其是不要假设一个系数可以因果解释。然而，因果推断可以在适当的情况下作为一种方法，用来改善统计模型。
- en: Back to regularization
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回到正则化
- en: Getting to the point--the theme of regularization is an attempt to improve an
    outcome or performance of a statistical model or method. In other words, to improve
    the process of learning (from data of course) through direct and indirect observation.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 直接切入主题——正则化的核心主题是试图改善统计模型或方法的结果或性能。换句话说，就是通过直接和间接的观察来改进学习过程（当然是通过数据）。
- en: The process of attempting to gain knowledge or learn from a finite dataset (also
    known as **empirical learning**) is said to be an **underdetermined problem**,
    because in general, it is an attempt to infer a function `x {\displaystyle x}`,
    given only some examples of data observations.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 试图从有限的数据集获取知识或学习（也称为**经验学习**）被认为是一个**欠定问题**，因为通常情况下，它是试图推断一个函数`x {\displaystyle
    x}`，仅给定一些数据观察的例子。
- en: Another possible method of improving a statistical model is to use **additive
    smoothing** (also known as **Laplacian smoothing**) during the training of a model.
    This is a form of regularization and it works by adding a fixed number to all
    the counts of feature and class combinations during model training.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 改进统计模型的另一种可能方法是，在模型训练过程中使用**加法平滑**（也称为**拉普拉斯平滑**）。这是一种正则化形式，通过在模型训练过程中将一个固定的数字添加到所有特征和类别组合的计数中来工作。
- en: It is a popular opinion that additive smoothing is more effective than other
    probability smoothing methods in several retrieval tasks such as language model-based
    applications.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 有一种普遍的观点认为，加法平滑在一些检索任务中（如基于语言模型的应用）比其他概率平滑方法更有效。
- en: Regularization fundamentally works to introduce additional information, or an
    intentional bias, or constraint in a training procedure—preventing coefficients
    from taking large values—in order to solve an ill-posed problem. This is a method
    that attempts to shrink coefficients, also known as a **shrinkage method**. The
    information introduced tends to be in the form of a penalty for complexity, such
    as restrictions for smoothness or bounds on the vector space norm. In other words,
    regularization A does what it implies, it regulates how or how much you can change
    a parameter within a statistical model or its data. Yes, that is right, you can
    change the actual data!
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 正则化从根本上来说是通过引入额外的信息、故意的偏差或约束来解决一个不适定的问题——防止系数取大值——这是一种试图收缩系数的方法，也称为**收缩方法**。引入的信息通常表现为对复杂度的惩罚，例如平滑性限制或向量空间范数的约束。换句话说，正则化A的作用正如其名称所示，它调节你可以在统计模型或其数据中如何以及多大程度上改变一个参数。没错，实际上，你可以改变数据本身！
- en: When is it justifiable to change the values of your data?
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 什么时候改变数据的值是合理的？
- en: The statistical community respects that the theoretical justification for regularization
    might be that it attempts to impose the belief that among competing hypotheses,
    the one with the fewest assumptions will be the most effective (and therefore
    should be the one selected and used). This belief is rigorously known as **Occam's
    razor** (or the law of parsimony).
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 统计学界认为，正则化的理论依据可能是它试图施加一种信念：在多个竞争假设中，假设最少的那一个将是最有效的（因此应当是被选中并使用的）。这种信念被严格称为**奥卡姆剃刀**（或称“简约法则”）。
- en: Reliability
  id: totrans-148
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可靠性
- en: Should one always (Of course, we are referring to those situations that are
    identified as we discussed in this chapter's section, *Opportunities for regulation*.)
    attempt to institute a regulation method on a statistical model? Will it always
    improve a model or data population?
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 是否应该总是在统计模型中尝试实施正则化方法呢？（当然，我们指的是本章“*正则化机会*”部分中所讨论的那些情况。）它是否总能改善模型或数据集？
- en: Before considering an answer to this question, remember that regularization
    does not improve the performance on the dataset that the algorithm initially used
    to learn the model parameters (feature weights). However, it can improve the generalization
    performance (the performance on new, unseen data, which is what you are looking
    for).
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在考虑如何回答这个问题之前，记住正则化不会改善算法最初用来学习模型参数（特征权重）的数据集上的表现。然而，它可以改善模型的泛化性能（即在新的、未见过的数据上的表现，这正是你所追求的）。
- en: Think of using regularization in a statistical model as the adding of bias as
    a countermeasure to overfitting; on the other hand, though, adding too much bias
    almost always results in underfitting and the model will perform badly.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 可以把在统计模型中使用正则化看作是对过拟合的反制措施，类似于加入偏差；但另一方面，加入过多的偏差几乎总是导致欠拟合，模型表现会很差。
- en: 'Answer: Regularization doesn''t always work and may cause a model to perform
    poorly (perhaps even worse than before!). S. Raschka, Author of Python Machine
    Learning, makes an interesting comment:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 答：正则化并不总是有效，可能导致模型表现不佳（甚至比之前更差！）。《Python机器学习》一书的作者S. Raschka提出了一个有趣的评论：
- en: In intuitive terms, you can think of regularization as a penalty against the
    complexity (of a model). Increasing the regularization strength penalizes large
    weight coefficients. Therefore, your goal is to prevent your model from picking
    up peculiarities or noise and to generalize well to new, unseen data.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 从直观角度来看，可以将正则化理解为对模型复杂度的惩罚。增加正则化强度会惩罚大权重系数。因此，你的目标是防止模型捕捉到异常或噪声，并确保模型能很好地泛化到新的、未见过的数据。
- en: Using R for statistical regularization
  id: totrans-154
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用R进行统计正则化
- en: There are a number of different functions and packages that implement ridge
    regression, such as `lm.ridge()` from the `MASS` package and `ridge()` from the
    `genridge` package. For the lasso, there is also the `lars` package. Here, in
    this chapter, we are going to use R's `glmnet()` function (from the `glmnet` package)
    due to it being well-documented and having a consistent and friendly interface.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多不同的函数和包实现了岭回归，例如来自`MASS`包的`lm.ridge()`和来自`genridge`包的`ridge()`。对于套索回归，还有`lars`包。在本章中，我们将使用R的`glmnet()`函数（来自`glmnet`包），因为它文档完善，接口一致且友好。
- en: The key to working with regularization is to determine an appropriate `lambda`
    value to use. The approach that the `glmnet()` function uses is to use a grid
    of different `lambda` values, training a regression model for each value. Then,
    one can either pick a value manually or use a technique to estimate the best `lambda`.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 使用正则化的关键是确定一个合适的`lambda`值。`glmnet()`函数使用的方法是使用不同的`lambda`值组成的网格，为每个值训练一个回归模型。然后，可以手动选择一个值，或者使用某种技术估计出最佳的`lambda`。
- en: You can specify the sequence of the values to try (via the `lambda` parameter);
    otherwise, a default sequence with 100 values will be used.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以指定尝试的值的序列（通过`lambda`参数）；否则，将使用包含100个值的默认序列。
- en: Parameter Setup
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参数设置
- en: 'The first parameter to the `glmnet()` function must be a matrix of features
    (which we can create using the R function, `model.matrix()`). The second parameter
    is a vector with the output variable. Finally, the `alpha` parameter is a switch
    between ridge regression (0) and lasso (1). The following code sets up for our
    example:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '`glmnet()`函数的第一个参数必须是特征矩阵（我们可以使用R函数`model.matrix()`创建该矩阵）。第二个参数是包含输出变量的向量。最后，`alpha`参数是用来在岭回归（0）和lasso（1）之间切换的。以下代码为我们的示例设置了环境：'
- en: '[PRE5]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The `model.matrix` R function creates a matrix by expanding factors to a set
    of summary variables (depending on the contrasts) and expanding interactions similarly.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '`model.matrix`是一个R函数，通过扩展因子为一组汇总变量（取决于对比）并类似地扩展交互作用来创建矩阵。'
- en: '[PRE6]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The preceding code that we used to set up the data to be used in this example
    (specifically, `length = 250`) provided a sequence of 250 values. This means that
    (in the preceding code) actually trained 250 ridge regression models and another
    250 lasso models!
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在此示例中用于设置数据的前述代码（具体为`length = 250`）提供了一个包含250个值的序列。这意味着（在前述代码中）实际上训练了250个岭回归模型和另外250个lasso模型！
- en: 'We can review the value of the `lambda` attribute (of the `cars_models_ridge`
    object) that is produced by `glmnet()` and then apply the `coef()` function to
    this object to retrieve the corresponding coefficients for the 100^(th) model,
    as follows:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以查看`glmnet()`生成的`cars_models_ridge`对象的`lambda`属性值，然后应用`coef()`函数来提取第100^(th)模型的相应系数，方法如下：
- en: '[PRE7]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Finally, we can use the R `plot()` function to obtain a plot showing how the
    values of the coefficients change as the logarithm values change.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以使用R的`plot()`函数生成一张图，显示随着对数值变化，系数值如何变化。
- en: 'As shown in the following code, it is very helpful to show the corresponding
    plot for ridge regression and lasso side by side:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 如以下代码所示，将岭回归和lasso的图表并排显示是非常有用的：
- en: '[PRE8]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The following is the plot graphic generated by the preceding R code:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是前述R代码生成的图形：
- en: '![](img/966624e3-2d01-46cd-a46d-bf473ac56cc6.png)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![](img/966624e3-2d01-46cd-a46d-bf473ac56cc6.png)'
- en: 'This is the R code to generate the `lasso` plot:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 这是生成`lasso`图的R代码：
- en: '[PRE9]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'This is the corresponding output:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 这是相应的输出：
- en: '![](img/ce26b845-7e47-48f0-839c-b26deda890ed.png)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ce26b845-7e47-48f0-839c-b26deda890ed.png)'
- en: The significant difference between the preceding two graphs is that `lasso`
    forces many coefficients to fall to zero exactly, whereas, in ridge regression,
    they tend to drop off smoothly and only become zero altogether at extreme values.
    Note the values on the top horizontal axis of both of the graphs, which show the
    number of non-zero coefficients as values vary.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 上述两个图的显著区别在于，`lasso`会强制许多系数精确地降到零，而在岭回归中，系数通常会平滑地下降，只有在极端值时才会完全降到零。请注意，两个图的上方水平轴上的数值，显示了随着值的变化，非零系数的数量。
- en: Along with applying regularization to minimize the issue of overfitting, the
    `lasso` function is often used to perform feature selection as a feature with
    a zero coefficient would not be included in the model.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 除了应用正则化以最小化过拟合问题外，`lasso`函数通常用于执行特征选择，因为具有零系数的特征将不会被包含在模型中。
- en: As a part of the `glmnet` package, the `predict()` function operates in a variety
    of contexts. We can, for example, determine the **coefficient variance** (**CV**)
    percentages (the strength and direction of a linear relationship between two variables)
    of a model for a `lambda` value that was not in our original list.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 作为`glmnet`包的一部分，`predict()`函数可以在多种情境中使用。例如，我们可以确定模型在一个原始列表中未包含的`lambda`值下的**系数方差**（**CV**）百分比（两个变量之间线性关系的强度和方向）。
- en: Predict is a generic function for predictions from the results of various model
    fitting functions.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '`Predict`是一个通用函数，用于从各种模型拟合函数的结果中进行预测。'
- en: Let's try using `predict` on our lasso model (created earlier).
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试在之前创建的`lasso`模型上使用`predict`。
- en: 'We can write the following R code on our previously created lasso model, `cars_models_lasso`:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在之前创建的`lasso`模型`cars_models_lasso`上编写以下R代码：
- en: '[PRE10]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: From the preceding output, you can see that `lasso` has not forced any coefficients
    to zero, in this case, suggesting that none should be removed (and therefore remain
    as features in the model) from the data.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的输出可以看出，`lasso`没有将任何系数强制为零，这表明在这种情况下，应该保留所有特征（即不应从数据中删除任何特征）。
- en: Summary
  id: totrans-183
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we provided an explanation of statistical regularization and
    then used sample data in an example to illustrate and better understand statistical
    regularization. Later, we had a discussion of various methods on how to improve
    (the performance of) data or a data model with regulation. Finally, we saw how
    well the R language supports the concepts and methods of regulation.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们提供了统计正则化的解释，并使用示例数据进行了演示，以便更好地理解统计正则化。之后，我们讨论了如何通过正则化来改进数据或数据模型的多种方法。最后，我们看到了R语言如何很好地支持正则化的概念和方法。
- en: In the next chapter, we're looking to cover the idea of data model assessment
    and using statistics for assessment. We'll compare the concepts of data assessment
    and data quality assurance, and finally, apply the idea of statistical assessment
    to data using R.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将介绍数据模型评估的概念，并使用统计学进行评估。我们将比较数据评估和数据质量保证的概念，最后，应用统计评估的思想，并通过R语言对数据进行评估。
