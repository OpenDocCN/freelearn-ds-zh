- en: '4'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '4'
- en: Understanding MLflow Components on Databricks
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解 Databricks 上的 MLflow 组件
- en: In the previous chapter, we learned about Feature Store, what problem it solves,
    and how Databricks provides the built-in Feature Store as part of the Databricks
    **machine learning** (**ML**) workspace, which we can use to register our feature
    tables.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们学习了特征存储，了解了它解决的问题，以及 Databricks 如何提供内建的特征存储作为 Databricks **机器学习** (**ML**)
    工作区的一部分，我们可以使用它来注册我们的特征表。
- en: In this chapter, we will look into managing our model training, tracking, and
    experimentation. In a software engineer’s world, code development and productionization
    have established best practices; however, such best practices are not generally
    adopted in the ML engineering/data science world. While working with many Databricks
    customers, I observed that each data science team has its own way of managing
    its projects. This is where MLflow comes in.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将深入探讨如何管理我们的模型训练、跟踪和实验。在软件工程师的世界里，代码开发和生产化有既定的最佳实践；然而，在 ML 工程/数据科学领域，这样的最佳实践并不普遍采用。在与许多
    Databricks 客户合作时，我观察到每个数据科学团队都有自己管理项目的方式。这正是 MLflow 进场的地方。
- en: MLflow is an umbrella project developed at Databricks, by Databricks engineers,
    to bring a standardized ML life cycle management tool to the Databricks platform.
    It is now an open source project with more than 500,000 daily downloads on average
    as of September 2023 and has broad industry and community support. MLflow provides
    features to manage the end-to-end ML project life cycle. Some of the features
    are only available on Databricks.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: MLflow 是一个由 Databricks 工程师开发的 umbrella 项目，旨在为 Databricks 平台提供一个标准化的 ML 生命周期管理工具。截至
    2023 年 9 月，它已成为一个开源项目，日均下载量超过 50 万次，并得到了广泛的行业和社区支持。MLflow 提供了管理端到端 ML 项目生命周期的功能，其中一些功能仅在
    Databricks 上可用。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论以下主题：
- en: Overview of MLflow
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MLflow 概述
- en: MLflow Tracking
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MLflow 跟踪
- en: MLflow Projects
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MLflow 项目
- en: MLflow Models
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MLflow 模型
- en: MLflow Model Registry
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MLflow 模型注册表
- en: Example code showing how to track ML model training in Databricks
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 示例代码展示了如何在 Databricks 中跟踪 ML 模型训练
- en: These components play an essential role in standardizing and streamlining your
    ML project’s life cycle. When we use MLflow with Databricks, some MLflow features
    are more helpful than others. We’ll point out the most useful ones as we go through
    this chapter.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这些组件在标准化和简化 ML 项目的生命周期中发挥着至关重要的作用。当我们在 Databricks 中使用 MLflow 时，某些 MLflow 功能比其他功能更有用。我们将在本章中指出最有用的功能。
- en: Technical requirements
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: All the code is available in this book’s GitHub repository [https://github.com/PacktPublishing/Practical-Machine-Learning-on-Databricks](https://github.com/PacktPublishing/Practical-Machine-Learning-on-Databricks)
    and is self-contained. To execute the notebooks, you can import the code repository
    directly into your Databricks workspace using repos. We discussed repos in our
    previous chapters.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的所有代码都可以在 GitHub 仓库中找到：[https://github.com/PacktPublishing/Practical-Machine-Learning-on-Databricks](https://github.com/PacktPublishing/Practical-Machine-Learning-on-Databricks)，并且是自包含的。要执行这些笔记本，你可以直接使用
    repos 将代码仓库导入到你的 Databricks 工作区。我们在之前的章节中讨论过 repos。
- en: 'This chapter also assumes that you have a preliminary understanding of what
    user-defined functions are in Apache Spark. You can read more about them here:
    [https://docs.databricks.com/en/udf/index.html](https://docs.databricks.com/en/udf/index.html).'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 本章还假设你对 Apache Spark 中的用户定义函数有初步的了解。你可以在这里阅读更多关于它们的信息：[https://docs.databricks.com/en/udf/index.html](https://docs.databricks.com/en/udf/index.html)。
- en: Overview of MLflow
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: MLflow 概述
- en: The ML life cycle is complex. It starts with ingesting raw data into the data/Delta
    lake in raw format from various batch and streaming sources. The data engineers
    create data pipelines using tools such as Apache Spark with Python, R, SQL, or
    Scala to process a large amount of data in a scalable, performant, and cost-effective
    manner.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: ML 生命周期很复杂。它从将原始数据以原始格式从各种批处理和流处理来源导入数据/Delta lake 开始。数据工程师使用 Apache Spark 等工具，结合
    Python、R、SQL 或 Scala 创建数据管道，以可扩展、高效和具成本效益的方式处理大量数据。
- en: The data scientists then utilize the various curated datasets in the data lake
    to generate feature tables to train their ML models. The data scientists prefer
    programming languages such as Python and R for feature engineering and libraries
    such as scikit-learn, pandas, NumPy, PyTorch, or any other popular ML or deep
    learning libraries for training and tuning ML models.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家随后利用数据湖中的各种精心策划的数据集生成特征表来训练他们的 ML 模型。数据科学家更喜欢使用 Python 和 R 等编程语言进行特征工程，使用
    scikit-learn、pandas、NumPy、PyTorch 或其他流行的 ML 或深度学习库进行模型训练和调优。
- en: Once the models have been trained, they need to be deployed in production either
    as a **re****presentational state transfer** (**REST**) **application programming
    interface** (**API**) for real-time inference, or a **user-defined function**
    (**UDF**) for batch and stream inference on Apache Spark. We also need to apply
    monitoring and governance around the deployed model. In case of drift in model
    performance or data, we may need to retrain and redeploy the model.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦模型训练完成，它们需要以**表述性状态转移**（**REST**）**应用程序编程接口**（**API**）的形式进行实时推理，或者以**用户定义函数**（**UDF**）的形式在
    Apache Spark 上进行批处理和流式推理。我们还需要对部署的模型应用监控和治理。如果模型性能或数据发生漂移，我们可能需要重新训练并重新部署模型。
- en: 'This process is iterative and brings a lot of development challenges to organizations
    looking to start working on ML projects:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程是迭代的，并给希望开始进行 ML 项目的组织带来了许多开发挑战：
- en: A zoo of software tools needs to be managed to provide a stable working environment
    for the data scientists. A large number of libraries need to be manually installed
    and configured.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为数据科学家提供稳定的工作环境需要管理大量的软件工具。许多库需要手动安装和配置。
- en: Tracking and reproducing the results of ML experiments is also a challenge.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 跟踪和重现 ML 实验的结果也是一大挑战。
- en: Managing the services and governance around productionizing models is difficult.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理服务和治理，尤其是将模型生产化，是一项困难的任务。
- en: Scaling the training of the models with the increase in the amount of data is
    a challenge.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随着数据量的增加，模型训练的规模化是一大挑战。
- en: 'MLflow, with its components, provides a solution to each of these challenges.
    In the Databricks environment, MLflow is integrated with workspace components
    such as notebooks, Feature Store, and AutoML. This integration provides a seamless
    experience for data scientists and ML engineers who are looking to get productive
    without getting into the operational overhead of managing the installation of
    MLflow on their own:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: MLflow 及其组件为每个挑战提供了解决方案。在 Databricks 环境中，MLflow 与工作区组件（如笔记本、特征存储和 AutoML）集成。这种集成为数据科学家和
    ML 工程师提供了无缝体验，使他们能够专注于生产力，而无需处理自己安装和管理 MLflow 的操作开销：
- en: '![Figure 4.1 – The various components of MLflow](img/B17875_04_1.jpg)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.1 – MLflow 的各个组件](img/B17875_04_1.jpg)'
- en: Figure 4.1 – The various components of MLflow
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.1 – MLflow 的各个组件
- en: 'Four software components make up MLflow:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: MLflow 由四个软件组件组成：
- en: '**MLflow Tracking**'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**MLflow 跟踪**'
- en: '**MLflow Projects**'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**MLflow 项目**'
- en: '**MLflow Models**'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**MLflow 模型**'
- en: '**MLflow** **Model Registry**'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**MLflow** **模型注册表**'
- en: In Databricks, all these components except MLflow Projects are integrated, fully
    managed, and provided as services as part of the Databricks workspace. As our
    primary focus is on MLflow features seamlessly integrated with Databricks, we
    won’t delve extensively into MLflow Projects. Rest assured, this won’t impact
    your ML project workflow when using Databricks. The Databricks ML workspace also
    offers high availability, automated updates, and access controls for all the integrated
    MLflow components.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Databricks 中，除了 MLflow 项目外，所有这些组件都已集成、完全管理并作为 Databricks 工作区的一部分提供服务。由于我们的主要关注点是与
    Databricks 无缝集成的 MLflow 特性，我们不会深入探讨 MLflow 项目。放心，使用 Databricks 时，这不会影响你的 ML 项目工作流程。Databricks
    ML 工作区还提供了高可用性、自动更新和对所有集成的 MLflow 组件的访问控制。
- en: Let’s take a look at each of these components in detail.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们详细了解一下这些组件。
- en: MLflow Tracking
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: MLflow 跟踪
- en: MLflow Tracking allows you to track the training of your ML models. It also
    improves the observability of the model-training process. The MLflow Tracking
    feature allows you to log the generated metrics, artifacts, and the model itself
    as part of the model training process. MLflow Tracking also keeps track of model
    lineage in the Databricks environment. In Databricks, we can see the exact version
    of the notebook responsible for generating the model listed as the source.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: MLflow 跟踪允许您跟踪机器学习模型的训练过程。它还提高了模型训练过程的可观察性。MLflow 跟踪功能使您能够记录生成的度量、工件和模型本身，作为模型训练过程的一部分。MLflow
    跟踪还在 Databricks 环境中跟踪模型的谱系。在 Databricks 中，我们可以看到负责生成模型的笔记本的确切版本，作为源代码进行列出。
- en: MLflow also provides **automatic logging** (**autolog**) capabilities that automatically
    log many metrics, parameters, and artifacts while performing model training. We
    can also add our own set of metrics and artifacts to the log.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: MLflow 还提供了 **自动日志记录**（**autolog**）功能，能够在执行模型训练时自动记录许多度量、参数和工件。我们还可以将自己的一组度量和工件添加到日志中。
- en: 'Using MLflow Tracking, we can chronologically track model training. Certain
    terms are specific to MLflow Tracking. Let’s take a look at them:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 MLflow 跟踪，我们可以按时间顺序跟踪模型训练。某些术语是 MLflow 跟踪特有的。我们来看看它们：
- en: '**Experiments**: Training and tuning the ML model for a business problem is
    an experiment. By default, each Python notebook in Databricks has an experiment
    with the same name. This is called a notebook-scoped experiment. You can easily
    change and set the experiment’s name using the MLflow API. Defining an experiment
    like this will create a workspace-scoped MLflow experiment that will now be visible
    in your workspace. Customizing the names of MLflow experiments offers valuable
    benefits in ML workflows – for example, it enhances organizational clarity by
    helping you categorize and differentiate experiments, acting as a form of documentation
    that aids communication and collaboration. Custom names facilitate version control
    and the tracking of experiment evolution, which is particularly useful for comparing
    performance or revisiting past configurations. Additionally, they simplify the
    process of accessing specific experiments through MLflow’s user interface or programmatic
    queries, ultimately contributing to more efficient and effective ML project management.
    We will be using a custom experiment name for our example code.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**实验**：为商业问题训练和调优机器学习模型是一个实验。默认情况下，Databricks 中的每个 Python 笔记本都有一个相同名称的实验，这被称为笔记本作用域实验。您可以通过
    MLflow API 轻松更改和设置实验名称。像这样定义实验将创建一个工作区作用域的 MLflow 实验，该实验现在可以在您的工作区中看到。自定义 MLflow
    实验名称在机器学习工作流程中提供了重要的优势——例如，通过帮助您对实验进行分类和区分，它提高了组织的清晰度，起到了文档作用，促进了沟通与协作。自定义名称有助于版本控制和跟踪实验的演变，这对于比较性能或回顾过去的配置特别有用。此外，它们简化了通过
    MLflow 用户界面或编程查询访问特定实验的过程，最终有助于更高效、更有效的机器学习项目管理。我们将在示例代码中使用自定义实验名称。'
- en: '**Runs**: We can have multiple models training with different hyperparameters
    logged under each experiment. Each of the unique combinations of ML model training
    logged under an experiment is called a run. The accompanying MLflow Tracking UI
    allows us to compare and contrast the different runs and get the best model.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**运行**：我们可以在每个实验下记录多个使用不同超参数训练的模型。每个在实验下记录的机器学习模型训练的独特组合称为一次运行。附带的 MLflow 跟踪用户界面允许我们对比不同的运行并找到最佳模型。'
- en: '**Metrics**: Each run will have critical offline metrics that we want to log
    while training our models. Unlike online metrics, which are calculated in real
    time as a model interacts with live data and users, offline metrics are computed
    retrospectively using a fixed dataset that was collected before the model’s deployment.
    These metrics are crucial during the model development and testing phases to gauge
    how well a model generalizes to unseen data and to guide model refinement. Common
    examples of offline metrics include accuracy, precision, recall, F1-score, **mean
    squared error** (**MSE**), and **area under the receiver operating characteristic
    curve** (**AUC-ROC**), among others. They provide insights into a model’s performance
    and can inform decisions regarding hyperparameter tuning, feature engineering,
    and model selection to improve overall predictive accuracy and effectiveness.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Metrics**: 每个运行将会有关键的离线指标，我们在训练模型时希望记录这些指标。与在线指标不同，后者是在模型与实时数据和用户交互时实时计算的，离线指标是使用在模型部署之前收集的固定数据集进行回顾性计算的。这些指标在模型开发和测试阶段至关重要，用于评估模型在未见数据上的泛化能力，并指导模型的优化。离线指标的常见示例包括准确率、精确度、召回率、F1
    分数、**均方误差**（**MSE**）和**接收者操作特征曲线下面积**（**AUC-ROC**），等等。它们为模型的性能提供见解，并可以指导超参数调整、特征工程和模型选择，以提高总体预测准确性和效果。'
- en: '**Artifacts**: MLflow artifacts play a pivotal role in MLflow’s experiment
    tracking system by facilitating the storage and versioning of supplementary files
    and data linked to ML experiments. These versatile artifacts can encompass a variety
    of resources, including ML model files, datasets, configuration files, data visualizations
    (for example, plots), documentation (for example, READMEs and Jupyter notebooks),
    custom scripts, and even reports summarizing experiment findings. Crucially, artifacts
    are versioned alongside experiment runs, ensuring precise tracking of changes
    over time. They support remote storage solutions and are programmatically accessible
    via MLflow’s API. This comprehensive approach enhances reproducibility, organization,
    and collaboration in ML projects, making it possible to recreate experiments accurately
    and access all relevant resources.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Artifacts**: MLflow 的 artifacts 在 MLflow 的实验跟踪系统中发挥着关键作用，通过便捷地存储和版本管理与 ML
    实验相关的附加文件和数据。这些多功能 artifacts 可以涵盖各种资源，包括 ML 模型文件、数据集、配置文件、数据可视化（例如绘图）、文档（例如 README
    和 Jupyter 笔记本）、自定义脚本，甚至是总结实验结果的报告。重要的是，artifacts 会随着实验运行进行版本控制，确保随时间的精确追踪变化。它们支持远程存储解决方案，并可通过
    MLflow 的 API 进行编程访问。这种全面的方法增强了 ML 项目中的可重现性、组织性和协作性，使得能够准确重现实验并访问所有相关资源成为可能。'
- en: '**Parameters**: Parameters are user-defined configuration settings or hyperparameters
    associated with ML experiment runs. They play a vital role in tracking, comparing,
    and reproducing experiments by recording the specific configuration settings used
    in each run. This allows for easy visualization and analysis of how parameter
    values impact experiment outcomes, making it simpler to identify optimal configurations
    and manage experiments effectively.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Parameters**: Parameters 是与 ML 实验运行相关联的用户定义的配置设置或超参数。它们通过记录每个运行中使用的具体配置设置，对实验进行跟踪、比较和重现起着至关重要的作用。这使得能够轻松可视化和分析参数值如何影响实验结果，从而更简单地识别最佳配置并有效管理实验。'
- en: '**Tags**: Tags are user-defined or automatically generated metadata labels
    that can be attached to ML experiment runs. They serve to provide context, categorization,
    and organization for runs, aiding in searching for, filtering, and analyzing experiments.
    Tags help document and distinguish different runs, making it easier to understand
    and manage ML projects, and they can be used for custom workflow integration or
    automation.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Tags**: Tags 是用户定义或自动生成的元数据标签，可以附加到 ML 实验运行中。它们用于为运行提供上下文、分类和组织，有助于搜索、过滤和分析实验。Tags
    有助于记录和区分不同的运行，从而更轻松地理解和管理 ML 项目，并可以用于自定义工作流集成或自动化。'
- en: Next, we will understand one of the key components of MLflow called MLflow Models.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将了解 MLflow 的关键组件之一，称为 MLflow Models。
- en: MLflow Models
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: MLflow Models
- en: MLflow Models is a standard packaging format for ML models. It provides a standardized
    abstraction on top of the ML model created by the data scientists. Each MLflow
    model is essentially a directory containing an `MLmodel` file in the directory’s
    root that can define multiple flavors that the model can be viewed in.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: MLflow Models 是一种标准的 ML 模型包装格式。它在数据科学家创建的 ML 模型之上提供了标准化的抽象。每个 MLflow 模型本质上是一个包含根目录中的
    `MLmodel` 文件的目录，该文件可以定义模型的多个 flavor。
- en: Flavors represent a fundamental concept that empowers MLflow Models by providing
    a standardized approach for deployment tools to comprehend and interact with ML
    models. This innovation eliminates the need for each deployment tool to integrate
    with every ML library individually. MLflow introduces several “standard” flavors,
    universally supported by its built-in deployment tools. For instance, the “Python
    function” flavor outlines how to execute the model as a Python function. However,
    the versatility of flavors extends beyond these standards. Libraries have the
    flexibility to define and employ their own flavors. As an example, MLflow’s `mlflow.sklearn`
    library allows you to load models as scikit-learn pipeline objects, suitable for
    use in scikit-learn-aware code, or as generic Python functions, catering to tools
    requiring a model application, such as the MLflow deployments tool with the `-t
    sagemaker` option for deploying models on Amazon SageMaker. So, flavors serve
    as a bridge between ML libraries and deployment tools, enhancing interoperability
    and ease of use.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: Flavor 代表了一个基本概念，它通过为部署工具提供标准化的方法来理解和与 ML 模型交互，从而增强了 MLflow 模型的能力。这一创新消除了每个部署工具需要与每个
    ML 库单独集成的需求。MLflow 引入了几个“标准”flavor，内置的部署工具普遍支持这些标准。例如，“Python 函数”flavor 描述了如何将模型作为
    Python 函数执行。然而，flavor 的多样性不仅限于这些标准。库有灵活性来定义并使用自己的 flavor。例如，MLflow 的 `mlflow.sklearn`
    库允许你将模型加载为 scikit-learn 管道对象，适用于在 scikit-learn 代码中使用，或者作为通用 Python 函数，满足需要应用模型的工具，比如使用
    `-t sagemaker` 选项将模型部署到 Amazon SageMaker 上的 MLflow 部署工具。因此，flavor 作为 ML 库和部署工具之间的桥梁，提升了互操作性和易用性。
- en: You can register an MLflow model from a run in an experiment using the `mlflow.<model-flavor>.log_mode``l`
    method. This method serializes the underlying ML model in a specific format and
    persists it in the underlying storage.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用 `mlflow.<model-flavor>.log_mode``l` 方法从实验中的一次运行注册一个 MLflow 模型。该方法将基础 ML
    模型序列化为特定格式，并将其持久化到底层存储中。
- en: 'Check out the official documentation for a complete list of ML libraries supported
    by MLflow Models: [https://www.mlflow.org/docs/latest/models.html#built-in-model-flavors](https://www.mlflow.org/docs/latest/models.html#built-in-model-flavors).
    If you have some existing models that were developed using any Python ML library,
    MLflow provides a method to create custom models via the `mlflow.pyfunc` module.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 查看官方文档，了解 MLflow Models 支持的完整 ML 库列表：[https://www.mlflow.org/docs/latest/models.html#built-in-model-flavors](https://www.mlflow.org/docs/latest/models.html#built-in-model-flavors)。如果你有一些已使用任何
    Python ML 库开发的现有模型，MLflow 提供了一种通过 `mlflow.pyfunc` 模块创建自定义模型的方法。
- en: Additional files are logged, such as `conda.yaml` and `requirements.txt`, that
    contain the library dependencies for recreating the runtime environment when needed.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 还会记录其他文件，如 `conda.yaml` 和 `requirements.txt`，这些文件包含库的依赖关系，用于在需要时重建运行时环境。
- en: 'The ML model YAML file contains the following attributes:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: ML 模型 YAML 文件包含以下属性：
- en: '`time_created`: The date and time in UTC ISO 8601 format describing when the
    model was created.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`time_created`：以 UTC ISO 8601 格式表示的日期和时间，描述模型创建的时间。'
- en: '`flavors`: This defines how downstream applications can use this model.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`flavors`：定义了下游应用程序如何使用该模型。'
- en: '`run_id`: This represents the unique identifier for the MLflow run; this model
    was logged under B.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`run_id`：表示 MLflow 运行的唯一标识符；该模型是通过 B 记录的。'
- en: '`signature`: The model signature in JSON format. This signature defines the
    expected format of input and output data for an ML model. It is automatically
    inferred from datasets representing valid input and output examples, such as the
    training dataset and model predictions.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`signature`：以 JSON 格式表示的模型签名。该签名定义了 ML 模型的输入和输出数据的预期格式。它是通过代表有效输入和输出示例的数据集自动推断出来的，例如训练数据集和模型预测。'
- en: '`input_example`: This is for if we provide sample records as input while training
    the model.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_example`：这是如果在训练模型时提供示例记录作为输入时使用的。'
- en: The MLflow Models API provides a method called `mlflow.evaluate()` that automatically
    evaluates our trained model on an evaluation dataset and logs the necessary metrics,
    such as accuracy, R2, and SHAP feature importance based on what kind of problem
    we are trying to solve. You can also create custom metrics and provide them as
    input to `mlflow.evaluate(custom_metrics=[<your custom metric>])` as a parameter.
    Links have been provided in the *Further reading* section if you want to learn
    more about it.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: MLflow 模型 API 提供了一种名为`mlflow.evaluate()`的方法，它可以自动在评估数据集上评估我们训练的模型，并记录必要的度量指标，例如准确率、R2
    和 SHAP 特征重要性，具体取决于我们试图解决的是什么问题。你还可以创建自定义度量并将它们作为参数传递给`mlflow.evaluate(custom_metrics=[<your
    custom metric>])`。如果你想了解更多，*进一步阅读* 部分已提供相关链接。
- en: 'MLflow Models also provide APIs to deploy the packaged ML models as a REST
    endpoint for real-time inference, as a Python function that can be used to perform
    batch and stream inference, or as a Docker container that can then be deployed
    to Kubernetes, Azure ML, or AWS SageMaker. The MLflow API provides convenient
    methods such as `mlflow.models.build_docker` to build and configure a Docker image.
    You can read more about the various methods that are available here: “[https://www.mlflow.org/docs/latest/python_api/mlflow.models.html?highlight=docker#mlflow.models.build_docker](https://www.mlflow.org/docs/latest/python_api/mlflow.models.html?highlight=docker#mlflow.models.build_docker)”.
    We will look into the various available deployment options as part of Databricks
    integrated with MLflow in [*Chapter 7*](B17875_07.xhtml#_idTextAnchor108), *Model*
    *Deployment Approaches*.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: MLflow 模型还提供 API，用于将打包的 ML 模型部署为 REST 端点进行实时推理，作为可以执行批量和流式推理的 Python 函数，或作为
    Docker 容器，随后可以部署到 Kubernetes、Azure ML 或 AWS SageMaker。MLflow API 提供了诸如`mlflow.models.build_docker`这样的便捷方法来构建和配置
    Docker 镜像。你可以在这里阅读有关各种可用方法的更多信息：[https://www.mlflow.org/docs/latest/python_api/mlflow.models.html?highlight=docker#mlflow.models.build_docker](https://www.mlflow.org/docs/latest/python_api/mlflow.models.html?highlight=docker#mlflow.models.build_docker)。我们将在[*第
    7 章*](B17875_07.xhtml#_idTextAnchor108)，*模型* *部署方法* 中探讨与 MLflow 集成的 Databricks
    的各种部署选项。
- en: 'Now, let’s look at the next feature on the list: MLflow Model Registry.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看列表中的下一个功能：MLflow 模型注册表。
- en: MLflow Model Registry
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: MLflow 模型注册表
- en: MLflow Model Registry is a tool that collaboratively manages the life cycle
    of all the MLflow Models in a centralized manner across an organization. In Databricks,
    the integrated Model Registry provides granular access control over who can transition
    models from one stage to another.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: MLflow 模型注册表是一个工具，用于以集中方式协作管理整个组织中所有 MLflow 模型的生命周期。在 Databricks 中，集成的模型注册表提供了对谁可以将模型从一个阶段转换到另一个阶段的精细访问控制。
- en: MLflow Model Registry allows multiple versions of the models in a particular
    stage. It enables the transition of the best-suited model between staging, prod,
    and archived states either programmatically or by a human-in-the-loop deployment
    model. Choosing one strategy over another for model deployment will depend on
    the use case and how comfortable teams are in automating the entire process of
    managing ML model promotion and testing process. We will take a deeper look into
    this in [*Chapter 6*](B17875_06.xhtml#_idTextAnchor100), *Model Versioning* *and
    Webhooks*.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: MLflow 模型注册表允许在特定阶段有多个版本的模型。它支持通过编程方式或人工干预部署模型，在各个阶段（如预生产、生产和归档状态）之间进行最佳模型的转换。选择哪种策略进行模型部署取决于使用案例以及团队在自动化整个
    ML 模型升级和测试过程方面的舒适度。我们将在[*第 6 章*](B17875_06.xhtml#_idTextAnchor100)，*模型版本管理* *和
    Webhooks* 中深入探讨这一点。
- en: Model Registry also logs model descriptions, lineage, and promotion activity
    from one stage to another, providing full traceability.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 模型注册表还会记录模型描述、血统信息以及从一个阶段到另一个阶段的推广活动，提供完整的可追溯性。
- en: We will look into the Model Registry feature more in detail in [*Chapter 6*](B17875_06.xhtml#_idTextAnchor100),
    *Model Versioning* *and Webhooks*.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[*第 6 章*](B17875_06.xhtml#_idTextAnchor100)，*模型版本管理* *和 Webhooks* 中更详细地探讨模型注册表功能。
- en: 'The following figure summarizes the interaction between various MLflow components:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 下图总结了各个 MLflow 组件之间的交互：
- en: '![Figure 4.2 – How the various MLflow components interact with each other](img/B17875_04_2.jpg)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.2 – 各个 MLflow 组件如何相互交互](img/B17875_04_2.jpg)'
- en: Figure 4.2 – How the various MLflow components interact with each other
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.2 – 各个 MLflow 组件如何相互交互
- en: You have the flexibility to choose your preferred Python ML libraries for model
    training within MLflow, while the MLflow Tracking server diligently logs metrics,
    tags, and artifacts, and then packages your model into the MLflow Models format.
    Once you’ve honed a candidate model ready for integration into Model Registry,
    it’s a straightforward process to register it there. Model Registry not only furnishes
    APIs but also offers governance mechanisms for smooth model transitioning between
    stages. Additionally, MLflow Model Registry introduces webhooks, which enable
    automated notifications to be triggered by specific user actions; we’ll delve
    into this further in[*Chapter 6*](B17875_06.xhtml#_idTextAnchor100), *Model Versioning
    and Webhooks*. In the end, downstream applications can harness APIs to fetch the
    latest models from the registry and deploy them in various flavors, including
    Python functions, Docker containers, or other supported deployment options that
    accommodate batch, streaming, and real-time use cases.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以灵活选择自己喜欢的Python ML库来进行模型训练，同时MLflow Tracking服务器会认真记录指标、标签和工件，并将你的模型打包成MLflow
    Models格式。一旦你完善了一个候选模型并准备好将其集成到模型注册表中，注册过程非常简单。模型注册表不仅提供API，还提供治理机制，确保模型在各阶段之间平稳过渡。此外，MLflow模型注册表引入了webhooks，能够在特定用户操作时触发自动通知；我们将在[*第6章*](B17875_06.xhtml#_idTextAnchor100)，*模型版本控制与Webhooks*
    中深入探讨这一点。最终，下游应用可以利用API从注册表中获取最新的模型，并将其以各种形式部署，包括Python函数、Docker容器或其他支持批处理、流处理和实时使用场景的部署选项。
- en: You have the freedom to independently manage your ML project life cycle by employing
    the features we’ve discussed thus far, even without utilizing Databricks Feature
    Store. However, utilizing Feature Store in ML projects offers numerous advantages,
    including centralized data management for streamlined access and consistency,
    feature reusability across projects, version control for reproducibility, data
    quality checks, collaborative teamwork, scalability to handle growing data complexity,
    real-time feature serving, model monitoring integration, regulatory compliance
    support, and significant time and cost savings. In essence, Feature Store enhances
    the efficiency and effectiveness of ML workflows by providing a structured and
    efficient approach to data management and feature handling.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过使用到目前为止讨论过的功能，独立管理你的ML项目生命周期，即使不使用Databricks Feature Store。然而，在ML项目中使用Feature
    Store提供了许多优势，包括集中化的数据管理，便于访问和一致性，跨项目的特征重用，版本控制以确保可重现性，数据质量检查，协作团队合作，扩展性以应对日益复杂的数据，实时特征服务，模型监控集成，合规性支持，以及显著的时间和成本节约。简而言之，Feature
    Store通过提供结构化和高效的数据管理和特征处理方法，提升了ML工作流的效率和效果。
- en: Let’s look at an end-to-end code example that goes through the entire flow of
    training an ML model in the Databricks environment and utilizes all the features
    of integrated MLflow.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一个端到端的代码示例，展示在Databricks环境中训练ML模型的整个流程，并利用集成的MLflow所有功能。
- en: Example code showing how to track ML model training in Databricks
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例代码展示了如何在Databricks中跟踪ML模型训练
- en: 'Before proceeding, it’s important to ensure that you’ve already cloned the
    code repository that accompanies this book, as outlined in [*Chapter 3*](B17875_03.xhtml#_idTextAnchor063).
    Additionally, please verify that you have executed the associated notebook for
    [*Chapter 3*](B17875_03.xhtml#_idTextAnchor063). These preparatory steps are essential
    to fully engage with the content and exercises presented here:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，确保你已经克隆了与本书配套的代码库，正如在[*第3章*](B17875_03.xhtml#_idTextAnchor063)中所述。此外，请验证你是否已经执行了与[*第3章*](B17875_03.xhtml#_idTextAnchor063)相关的笔记本。这些准备步骤对于全面参与此处提供的内容和练习至关重要：
- en: 'Go to `Chapter 04` and click on the `mlflow-without-featurestore` notebook:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 转到`第04章`，并点击`mlflow-without-featurestore`笔记本：
- en: '![Figure 4.3 – The code that accompanies this chapter](img/B17875_04_3.jpg)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![图4.3 – 本章配套的代码](img/B17875_04_3.jpg)'
- en: Figure 4.3 – The code that accompanies this chapter
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.3 – 本章配套的代码
- en: Make sure you have a cluster up and running and that the cluster is attached
    to this notebook, as you did with the notebook from [*Chapter 3*](B17875_03.xhtml#_idTextAnchor063),
    *Utilizing the* *Feature Store.*
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 确保你的集群已经启动并运行，并且集群已附加到此笔记本，正如你在[*第3章*](B17875_03.xhtml#_idTextAnchor063)中所做的，*使用Feature
    Store*。
- en: '`Cmd 3` demonstrates the use of notebook-scoped libraries. These can be installed
    using the `%pip` magic command. As best practice, keep the `%pip` command as one
    of the topmost cells in your notebook as it restarts the Python interpreter. We
    are just upgrading the version of the `scikit-learn` library here:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`Cmd 3`展示了如何使用笔记本范围的库。这些库可以通过`%pip`魔法命令进行安装。最佳实践是将`%pip`命令保留在笔记本的最顶部单元格中，因为它会重启
    Python 解释器。我们这里只是升级了`scikit-learn`库的版本：'
- en: '[PRE0]'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'In `Cmd 5` and `Cmd 6`, we are just defining some constant values we will be
    using to track our ML model training. Change the `USER_EMAIL` value to the email
    you’ve used to log into the Databricks workspace. In this notebook, we are not
    going to use the Feature Store API; however, every feature table is stored as
    a Delta table, which can be read as a regular hive table:'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`Cmd 5`和`Cmd 6`中，我们只是定义了一些常量值，用于跟踪我们的 ML 模型训练。将`USER_EMAIL`值更改为您用于登录 Databricks
    工作区的电子邮件。在此笔记本中，我们不会使用 Feature Store API；但是，每个特征表都存储为 Delta 表，可以像常规 Hive 表一样读取：
- en: '[PRE1]'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'To use Mlflow, we had to import the `mlflow` package. `mlflow.setExperiment(…)`
    creates a named experiment to track all the MLflow runs that we will execute in
    this notebook. After executing this code, you should be able to see a new type
    of entity listed in your workspace directory where `EXPERIMENT_NAME` points to.
    As mentioned earlier, this creates a workspace-scoped experiment:'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了使用 Mlflow，我们需要导入`mlflow`包。`mlflow.setExperiment(…)`创建一个命名实验，以跟踪我们将在此笔记本中执行的所有
    MLflow 运行。执行此代码后，您应该能够在您的工作区目录中看到一个新类型的实体，其中`EXPERIMENT_NAME`指向的内容。正如前面提到的，这会创建一个工作区范围的实验：
- en: '[PRE2]'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![Figure 4.4 – The new experiment that was created in the workspace](img/B17875_04_4.jpg)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.4 – 在工作区中创建的新实验](img/B17875_04_4.jpg)'
- en: Figure 4.4 – The new experiment that was created in the workspace
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.4 – 在工作区中创建的新实验
- en: 'Calling `mlflow.start_run()` starts a run under the listed experiment. The
    rest of the code simply trains a scikit learn model. With just a few lines of
    code, we are now using the features of MLflow Tracking:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调用`mlflow.start_run()`将在列出的实验下启动一个运行。其余代码只是训练一个 scikit-learn 模型。只需几行代码，我们便开始使用
    MLflow Tracking 的功能：
- en: '[PRE3]'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The following code utilizes the MLflow Tracking server to log artifacts and
    hyperparameter values while setting `tag` to the `sklearn` model that is being
    logged to the MLflow Tracking server:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下代码利用 MLflow Tracking 服务器记录工件和超参数值，同时将`tag`设置为正在记录到 MLflow Tracking 服务器的`sklearn`模型：
- en: '[PRE4]'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Once we’ve finished executing the code in this cell, we will be able to see
    the run and all its artifacts, parameters, and hyperparameters listed under the
    experiment:'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一旦我们完成执行此单元格中的代码，我们将能够在实验下看到该运行及其所有工件、参数和超参数：
- en: '![Figure 4.5 – The runs listed under the experiments](img/B17875_04_5.jpg)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.5 – 实验下列出的运行](img/B17875_04_5.jpg)'
- en: Figure 4.5 – The runs listed under the experiments
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.5 – 实验下列出的运行
- en: 'You can check the details of each run in the Tracking UI by clicking the shortcut
    icon:'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您可以通过点击快捷方式图标，查看 Tracking UI 中每次运行的详情：
- en: '![Figure 4.6 – The shortcut for accessing the integrated MLflow Tracking UI](img/B17875_04_6.jpg)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.6 – 访问集成 MLflow Tracking UI 的快捷方式](img/B17875_04_6.jpg)'
- en: Figure 4.6 – The shortcut for accessing the integrated MLflow Tracking UI
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.6 – 访问集成 MLflow Tracking UI 的快捷方式
- en: 'The Tracking UI displays information about each run in a lot more detail. Along
    with the serialized model, you can access logged artifacts, metrics, hyperparameters,
    the model signature, or the sample input that your model expects as input if you
    logged them during the run. At the top, you can see the path to the experiment
    under which this run is being tracked. Each run is uniquely identified with an
    ID that is also visible at the top. The tracking server provides lineage and links
    this model run back to the exact version of the notebook that was used to execute
    this run:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: Tracking UI 以更多细节展示每次运行的信息。除了序列化模型，您还可以访问记录的工件、指标、超参数、模型签名，或者如果您在运行时记录了它们，还可以查看模型期望的输入样本。在顶部，您可以看到此运行所跟踪的实验路径。每个运行都有一个唯一的
    ID，也会在顶部显示。跟踪服务器提供了溯源功能，并将此模型运行与执行该运行的笔记本的确切版本链接起来：
- en: '![Figure 4.7 – The details of the run in the Tracking UI](img/B17875_04_7.jpg)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.7 – 运行详情在 Tracking UI 中](img/B17875_04_7.jpg)'
- en: Figure 4.7 – The details of the run in the Tracking UI
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.7 – 运行详情在 Tracking UI 中
- en: 'Clicking on the experiment path at the top will take you to the experiment
    view where, if you have executed more than one run, you can select and compare
    various runs to get the best model or compare the best combinations of the hyperparameters:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击顶部的实验路径，将带你进入实验视图，在这里，如果你执行了多个运行，你可以选择并比较不同的运行结果，以便找到最佳模型或比较最佳的超参数组合：
- en: '![Figure 4.8 – All the runs associated with our experiment](img/B17875_04_8.jpg)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.8 – 与我们的实验相关的所有运行](img/B17875_04_8.jpg)'
- en: Figure 4.8 – All the runs associated with our experiment
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.8 – 与我们的实验相关的所有运行
- en: Now, let’s summarize this chapter.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们总结一下本章内容。
- en: Summary
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we covered the various components of MLflow and how they work
    together to make the end-to-end ML project life cycle easy to manage. We learned
    about MLflow Tracking, Projects, Models, and Model Registry.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们介绍了 MLflow 的各个组件以及它们如何协同工作，使得端到端的机器学习项目生命周期管理变得简单。我们学习了 MLflow Tracking、Projects、Models
    和 Model Registry。
- en: This chapter covered some key components of MLFlow and their purpose. Understanding
    these concepts is essential in effectively managing end-to-end ML projects in
    the Databricks environment.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了 MLFlow 的一些关键组件及其用途。理解这些概念对于在 Databricks 环境中有效管理端到端的机器学习项目至关重要。
- en: In the next chapter, we will look at the AutoML capabilities of Databricks in
    detail and how we can utilize them to create our baseline models for ML projects.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将详细介绍 Databricks 的 AutoML 功能，以及如何利用它们为机器学习项目创建基线模型。
