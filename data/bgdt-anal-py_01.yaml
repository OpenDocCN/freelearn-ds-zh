- en: '*Chapter 1*'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第1章*'
- en: The Python Data Science Stack
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Python 数据科学栈
- en: Learning Objectives
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 学习目标
- en: We will start our journey by understanding the power of Python to manipulate
    and visualize data, creating useful analysis.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过理解 Python 在数据操作和可视化中的强大能力，开启我们的学习之旅，进行有用的分析。
- en: 'By the end of this chapter, you will be able to:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将能够：
- en: Use all components of the Python data science stack
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Python 数据科学栈的所有组件
- en: Manipulate data using pandas DataFrames
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 pandas DataFrame 操作数据
- en: Create simple plots using pandas and Matplotlib
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 pandas 和 Matplotlib 创建简单的图表
- en: In this chapter, we will learn how to use NumPy, Pandas, Matplotlib, IPython,
    Jupyter notebook. Later in the chapter, we will explore how the deployment of
    `virtualenv`, `pyenv`, works, soon after that we will plot basic visualization
    using Matplotlib and Seaborn libraries.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习如何使用 NumPy、Pandas、Matplotlib、IPython、Jupyter notebook。稍后我们将探讨`virtualenv`、`pyenv`的部署方式，紧接着我们将使用
    Matplotlib 和 Seaborn 库绘制基本的可视化图表。
- en: Introduction
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 引言
- en: The Python data science stack is an informal name for a set of libraries used
    together to tackle data science problems. There is no consensus on which libraries
    are part of this list; it usually depends on the data scientist and the problem
    to be solved. We will present the libraries most commonly used together and explain
    how they can be used.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: Python 数据科学栈是一个非正式的名称，用来描述一组协同工作的库，用于解决数据科学问题。关于哪些库应当列入此名单，并没有统一的标准；通常这取决于数据科学家和待解决的问题。我们将介绍最常用的库，并解释如何使用它们。
- en: In this chapter, we will learn how to manipulate tabular data with the Python
    data science stack. The Python data science stack is the first stepping stone
    to manipulate large datasets, although these libraries are not commonly used for
    big data themselves. The ideas and the methods that are used here will be very
    helpful when we get to large datasets.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习如何使用 Python 数据科学栈来操作表格数据。Python 数据科学栈是处理大规模数据集的第一步，尽管这些库本身通常不用于大数据处理。这里使用的思想和方法将对我们后续处理大数据集时非常有帮助。
- en: Python Libraries and Packages
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Python 库和包
- en: One of the main reasons Python is a powerful programming language is the libraries
    and packages that come with it. There are more than 130,000 packages on the **Python
    Package Index** (**PyPI**) and counting! Let's explore some of the libraries and
    packages that are part of the data science stack.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: Python 之所以是一门强大的编程语言，其中一个重要原因就是它所附带的库和包。**Python 包索引**（**PyPI**）中有超过 130,000
    个包，且这个数字还在增长！让我们一起来探索一些数据科学栈中的库和包。
- en: 'The components of the data science stack are as follows:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学栈的组件如下：
- en: '**NumPy**: A numerical manipulation package'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**NumPy**：一个数值计算库'
- en: '**pandas**: A data manipulation and analysis library'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**pandas**：一个数据操作和分析库'
- en: '**SciPy library**: A collection of mathematical algorithms built on top of
    NumPy'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**SciPy 库**：建立在 NumPy 基础上的一组数学算法'
- en: '**Matplotlib**: A plotting and graph library'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Matplotlib**：一个绘图和图表库'
- en: '**IPython**: An interactive Python shell'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**IPython**：一个交互式 Python shell'
- en: '**Jupyter notebook**: A web document application for interactive computing'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Jupyter notebook**：用于交互式计算的 Web 文档应用'
- en: The combination of these libraries forms a powerful tool set for handling data
    manipulation and analysis. We will go through each of the libraries, explore their
    functionalities, and show how they work together. Let's start with the interpreters.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这些库的组合构成了一个强大的工具集，用于处理数据操作和分析。我们将逐一介绍每个库，探索它们的功能，并展示它们是如何协同工作的。让我们从解释器开始。
- en: 'IPython: A Powerful Interactive Shell'
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IPython：一个强大的交互式 shell
- en: 'The IPython shell ([https://ipython.org/](https://ipython.org/)) is an interactive
    Python command interpreter that can handle several languages. It allows us to
    test ideas quickly rather than going through creating files and running them.
    Most Python installations have a bundled command interpreter, usually called the
    **shell**, where you can execute commands iteratively. Although it''s handy, this
    standard Python shell is a bit cumbersome to use. IPython has more features:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: IPython shell（[https://ipython.org/](https://ipython.org/)）是一个交互式 Python 命令解释器，支持多种语言。它允许我们快速测试想法，而不需要创建文件并运行它们。大多数
    Python 安装包中都会包含一个命令解释器，通常被称为**shell**，你可以在其中逐行执行命令。尽管很方便，但标准的 Python shell 使用起来有些繁琐。IPython
    提供了更多的功能：
- en: Input history that is available between sessions, so when you restart your shell,
    the previous commands that you typed can be reused.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 会话之间的输入历史记录功能，确保你在重启 shell 后，之前输入的命令可以被重新使用。
- en: Using *Tab* completion for commands and variables, you can type the first letters
    of a Python command, function, or variable and IPython will autocomplete it.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用*Tab*自动补全命令和变量，你可以输入 Python 命令、函数或变量的首字母，IPython 会自动补全它。
- en: Magic commands that extend the functionality of the shell. Magic functions can
    enhance IPython functionality, such as adding a module that can reload imported
    modules after they are changed in the disk, without having to restart IPython.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 魔法命令扩展了 shell 的功能。魔法函数可以增强 IPython 的功能，例如添加一个模块，可以在模块在磁盘上被修改后重新加载，而不需要重启 IPython。
- en: Syntax highlighting.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语法高亮。
- en: 'Exercise 1: Interacting with the Python Shell Using the IPython Commands'
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 1：使用 IPython 命令与 Python Shell 交互
- en: 'Getting started with the Python shell is simple. Let''s follow these steps
    to interact with the IPython shell:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 启动 Python shell 很简单。让我们按照以下步骤与 IPython shell 互动：
- en: 'To start the Python shell, type the `ipython` command in the console:'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要启动 Python shell，请在控制台中输入`ipython`命令：
- en: '[PRE0]'
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The IPython shell is now ready and waiting for further commands. First, let's
    do a simple exercise to solve a sorting problem with one of the basic sorting
    methods, called **straight insertion**.
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: IPython shell 现在已准备好，等待进一步的命令。首先，让我们做一个简单的练习，解决一个排序问题，使用一种基本的排序方法，称为**直接插入法**。
- en: 'In the IPython shell, copy-paste the following code:'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 IPython shell 中，复制并粘贴以下代码：
- en: '[PRE1]'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Now, the output for the randomly generated numbers will be similar to the following:'
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，随机生成的数字的输出将类似于以下内容：
- en: '[PRE2]'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Use the following logic to print the elements of the `vec` array in ascending
    order:'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下逻辑按升序打印`vec`数组的元素：
- en: '[PRE3]'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Use the `print(vec)` command to print the output on the console:'
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用`print(vec)`命令在控制台打印输出：
- en: '[PRE4]'
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Now modify the code. Instead of creating an array of 5 elements, change its
    parameters so it creates an array with 20 elements, using the *up* arrow to edit
    the pasted code. After changing the relevant section, use the *down* arrow to
    move to the end of the code and press *Enter* to execute it.
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在修改代码。将参数从创建一个包含 5 个元素的数组更改为创建一个包含 20 个元素的数组，使用*上*箭头编辑粘贴的代码。修改相关部分后，使用*下*箭头移动到代码的末尾并按*Enter*键执行。
- en: Notice the number on the left, indicating the instruction number. This number
    always increases. We attributed the value to a variable and executed an operation
    on that variable, getting the result interactively. We will use IPython in the
    following sections.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 注意左侧的数字，表示指令编号。这个数字会一直增加。我们将值赋给一个变量并对该变量执行操作，得到交互式结果。我们将在接下来的章节中使用 IPython。
- en: The Jupyter Notebook
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Jupyter Notebook
- en: The Jupyter notebook ([https://jupyter.org/](https://jupyter.org/)) started
    as part of IPython but was separated in version 4 and extended, and lives now
    as a separate project. The notebook concept is based on the extension of the interactive
    shell model, creating documents that can run code, show documentation, and present
    results such as graphs and images.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: Jupyter notebook ([https://jupyter.org/](https://jupyter.org/)) 最初作为 IPython
    的一部分，但在版本 4 中被分离并扩展，现在作为一个独立的项目存在。Notebook 概念基于扩展交互式 shell 模型，创建可以运行代码、显示文档并展示结果（如图表和图像）的文档。
- en: Jupyter is a web application, so it runs in your web browser directly, without
    having to install separate software, and enabling it to be used across the internet.
    Jupyter can use IPython as a kernel for running Python, but it has support for
    more than 40 kernels that are contributed by the developer community.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: Jupyter 是一个 Web 应用程序，因此它直接在 Web 浏览器中运行，无需安装单独的软件，且可以在互联网上使用。Jupyter 可以使用 IPython
    作为运行 Python 的内核，但它支持超过 40 个由开发者社区贡献的内核。
- en: Note
  id: totrans-46
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: A kernel, in Jupyter parlance, is a computation engine that runs the code that
    is typed into a code cell in a notebook. For example, the IPython kernel executes
    Python code in a notebook. There are kernels for other languages, such as R and
    Julia.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Jupyter 的术语中，内核是执行代码单元中的代码的计算引擎。例如，IPython 内核执行 notebook 中的 Python 代码。也有其他语言的内核，如
    R 和 Julia。
- en: It has become a de facto platform for performing operations related to data
    science from beginners to power users, and from small to large enterprises, and
    even academia. Its popularity has increased tremendously in the last few years.
    A Jupyter notebook contains both the input and the output of the code you run
    on it. It allows text, images, mathematical formulas, and more, and is an excellent
    platform for developing code and communicating results. Because of its web format,
    notebooks can be shared over the internet. It also supports the Markdown markup
    language and renders Markdown text as rich text, with formatting and other features
    supported.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 它已经成为一个事实上的平台，从初学者到高级用户，从小型到大型企业，甚至是学术界，都可以用它来执行与数据科学相关的操作。在过去的几年里，它的受欢迎程度大幅度提高。一个
    Jupyter notebook 包含你在其上运行的代码的输入和输出。它支持文本、图像、数学公式等，是一个开发代码和交流结果的绝佳平台。由于它的 Web 格式，notebook
    可以通过互联网共享。它还支持 Markdown 标记语言，并将 Markdown 文本渲染为富文本，支持格式化及其他特性。
- en: 'As we''ve seen before, each notebook has a kernel. This kernel is the interpreter
    that will execute the code in the cells. The basic unit of a notebook is called
    a **cell**. A cell is a container for either code or text. We have two main types
    of cells:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前所见，每个 notebook 都有一个内核。这个内核是执行单元格中代码的解释器。一个 notebook 的基本单位叫做**单元格**。单元格是一个容器，可以容纳代码或文本。我们有两种主要类型的单元格：
- en: '**Code cell**'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**代码单元格**'
- en: '**Markdown cell**'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Markdown 单元格**'
- en: A code cell accepts code to be executed in the kernel, displaying the output
    just below it. A Markdown cell accepts Markdown and will parse the text in Markdown
    to formatted text when the cell is executed.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 代码单元格接受要在内核中执行的代码，并在其下方显示输出。Markdown 单元格接受 Markdown，当单元格执行时，会将文本解析为格式化文本。
- en: Let's run the following exercise to get hands-on experience in the Jupyter notebook.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们运行以下练习，获得在 Jupyter notebook 中的实际操作经验。
- en: The fundamental component of a notebook is a cell, which can accept code or
    text depending on the mode that is selected.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 notebook 的基本组件是单元格，单元格根据选择的模式可以接受代码或文本。
- en: 'Let''s start a notebook to demonstrate how to work with cells, which have two
    states:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们启动一个 notebook，演示如何使用单元格，单元格有两种状态：
- en: Edit mode
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编辑模式
- en: Run mode
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行模式
- en: When in edit mode, the contents of the cell can be edited, while in run mode,
    the cell is ready to be executed, either by the kernel or by being parsed to formatted
    text.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在编辑模式下，单元格的内容可以编辑，而在运行模式下，单元格准备好执行，可以由内核执行或被解析为格式化文本。
- en: You can add a new cell by using the **Insert** menu option or using a keyboard
    shortcut, *Ctrl* + *B*. Cells can be converted between Markdown mode and code
    mode again using the menu or the *Y* shortcut key for a code cell and *M* for
    a Markdown cell.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过使用**插入**菜单选项或使用键盘快捷键*Ctrl* + *B*来添加新单元格。单元格可以通过菜单或快捷键*Y*（代码单元格）和*M*（Markdown
    单元格）在 Markdown 模式和代码模式之间转换。
- en: To execute a cell, click on the **Run** option or use the *Ctrl* + *Enter* shortcut.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 要执行一个单元格，点击**运行**选项或使用*Ctrl* + *Enter*快捷键。
- en: 'Exercise 2: Getting Started with the Jupyter Notebook'
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 2：开始使用 Jupyter Notebook
- en: Let's execute the following steps to demonstrate how to start to execute simple
    programs in a Jupyter notebook.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们执行以下步骤，演示如何开始在 Jupyter notebook 中执行简单的程序。
- en: Working with a Jupyter notebook for the first time can be a little confusing,
    but let's try to explore its interface and functionality. The reference notebook
    for this exercise is provided on GitHub.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 第一次使用 Jupyter notebook 可能会有些困惑，但让我们尝试探索它的界面和功能。这个练习的参考 notebook 可以在 GitHub 上找到。
- en: 'Now, start a Jupyter notebook server and work on it by following these steps:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，启动一个 Jupyter notebook 服务器并按照以下步骤进行操作：
- en: 'To start the Jupyter notebook server, run the following command on the console:'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要启动 Jupyter notebook 服务器，在控制台运行以下命令：
- en: '[PRE5]'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: After successfully running or installing Jupyter, open a browser window and
    navigate to [http://localhost:8888](http://localhost:8888) to access the notebook.
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 成功运行或安装 Jupyter 后，打开浏览器窗口并访问[http://localhost:8888](http://localhost:8888)来访问
    notebook。
- en: 'You should see a notebook similar to the one shown in the following screenshot:![Figure
    1.1: Jupyter notebook](img/C12913_01_01.jpg)'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你应该能看到一个类似于以下截图的 notebook：[图 1.1：Jupyter notebook](img/C12913_01_01.jpg)
- en: 'Figure 1.1: Jupyter notebook'
  id: totrans-69
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.1：Jupyter notebook
- en: After that, from the top-right corner, click on **New** and select **Python
    3** from the list.
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，在右上角点击**新建**，从列表中选择**Python 3**。
- en: 'A new notebook should appear. The first input cell that appears is a **Code**
    cell. The default cell type is **Code**. You can change it via the **Cell Type**
    option located under the **Cell** menu:![Figure 1.2: Options in the cell menu
    of Jupyter](img/C12913_01_02.jpg)'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个新的 notebook 应该会出现。首先出现的输入单元格是 **代码** 单元格。默认单元格类型是 **代码**。你可以通过 **单元格** 菜单下的
    **单元格类型** 选项来更改它：![图 1.2：Jupyter 单元格菜单中的选项](img/C12913_01_02.jpg)
- en: 'Figure 1.2: Options in the cell menu of Jupyter'
  id: totrans-72
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.2：Jupyter 单元格菜单中的选项
- en: 'Now, in the newly generated **Code** cell, add the following arithmetic function
    in the first cell:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，在新生成的 **代码** 单元格中，在第一个单元格中添加以下算术函数：
- en: '[PRE6]'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Now, add a function that returns the arithmetic mean of two numbers, and then
    execute the cell:'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，添加一个返回两个数字算术平均值的函数，然后执行该单元格：
- en: '[PRE7]'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Let''s now use the `mean` function and call the function with two values, 10
    and 20\. Execute this cell. What happens? The function is called, and the answer
    is printed:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用 `mean` 函数，并用两个值 10 和 20 调用该函数。执行此单元格。会发生什么？函数被调用，答案会被打印出来：
- en: '[PRE8]'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We need to document this function. Now, create a new Markdown cell and edit
    the text in the Markdown cell, documenting what the function does:![Figure 1.3:
    Markdown in Jupyter](img/C12913_01_03.jpg)'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要记录这个函数。现在，创建一个新的 Markdown 单元格，并编辑单元格中的文本，记录该函数的功能：![图 1.3：Jupyter 中的 Markdown](img/C12913_01_03.jpg)
- en: 'Figure 1.3: Markdown in Jupyter'
  id: totrans-80
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.3：Jupyter 中的 Markdown
- en: Then, include an image from the web. The idea is that the notebook is a document
    that should register all parts of analysis, so sometimes we need to include a
    diagram or graph from other sources to explain a point.
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，插入一个来自网络的图片。其目的是 notebook 作为一个文档，应该记录分析的所有部分，因此有时我们需要从其他来源插入一个图表或图形来解释某个观点。
- en: 'Now, finally, include the mathematical expression in **LaTex** in the same
    Markdown cell:'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，最后在同一个 Markdown 单元格中插入 **LaTex** 数学表达式：
- en: '![Figure 1.4: LaTex expression in Jupyter Markdown](img/C12913_01_04.jpg)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.4：Jupyter Markdown 中的 LaTex 表达式](img/C12913_01_04.jpg)'
- en: 'Figure 1.4: LaTex expression in Jupyter Markdown'
  id: totrans-84
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.4：Jupyter Markdown 中的 LaTex 表达式
- en: As we will see in the rest of the book, the notebook is the cornerstone of our
    analysis process. The steps that we just followed illustrate the use of different
    kinds of cells and the different ways we can document our analysis.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们将在本书其余部分看到的，notebook 是我们分析过程的基石。我们刚才遵循的步骤展示了不同类型单元格的使用及我们记录分析过程的不同方式。
- en: IPython or Jupyter?
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IPython 或 Jupyter？
- en: Both IPython and Jupyter have a place in the analysis workflow. Usually, the
    IPython shell is used for quick interaction and more data-heavy work, such as
    debugging scripts or running asynchronous tasks. Jupyter notebooks, on the other
    hand, are great for presenting results and generating visual narratives with code,
    text, and figures. Most of the examples that we will show can be executed in both,
    except the graphical parts.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: IPython 和 Jupyter 在分析工作流中都有其作用。通常，IPython shell 用于快速交互和更为数据密集的工作，如调试脚本或运行异步任务。而
    Jupyter notebook 则非常适合用来展示结果，并通过代码、文本和图形生成可视化叙事。我们将展示的大多数示例都可以在这两者中执行，除了图形部分。
- en: IPython is capable of showing graphs, but usually, the inclusion of graphs is
    more natural in a notebook. We will usually use Jupyter notebooks in this book,
    but the instructions should also be applicable to IPython notebooks.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: IPython 能显示图形，但通常图形的加入在 notebook 中更为自然。在本书中，我们通常使用 Jupyter notebook，但这些指令同样适用于
    IPython notebook。
- en: 'Activity 1: IPython and Jupyter'
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动 1：IPython 和 Jupyter
- en: 'Let''s demonstrate common Python development in IPython and Jupyter. We will
    import NumPy, define a function, and iterate the results:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们展示在 IPython 和 Jupyter 中常见的 Python 开发。我们将导入 NumPy，定义一个函数，并迭代结果：
- en: Open the `python_script_student.py` file in a text editor, copy the contents
    to a notebook in IPython, and execute the operations.
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开 `python_script_student.py` 文件，在文本编辑器中复制其内容，粘贴到 IPython 的 notebook 中，并执行操作。
- en: Copy and paste the code from the Python script into a Jupyter notebook.
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 Python 脚本中的代码复制并粘贴到 Jupyter notebook 中。
- en: Now, update the values of the `x` and `c` constants. Then, change the definition
    of the function.
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，更新 `x` 和 `c` 常量的值。然后，修改函数的定义。
- en: Note
  id: totrans-94
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The solution for this activity can be found on page 200.
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该活动的解决方案可以在第 200 页找到。
- en: We now know how to handle functions and change function definitions on the fly
    in the notebook. This is very helpful when we are exploring and discovering the
    right approach for some code or an analysis. The iterative approach allowed by
    the notebook can be very productive in prototyping and faster than writing code
    to a script and executing that script, checking the results, and changing the
    script again.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经知道如何在 notebook 中处理函数并动态更改函数定义。当我们在探索和发现某段代码或分析的正确方法时，这非常有帮助。Notebook 支持的迭代方法在原型设计中非常高效，并且比写代码到脚本中再执行、检查结果并重新修改脚本要更快。
- en: NumPy
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: NumPy
- en: NumPy ([http://www.numpy.org](http://www.numpy.org)) is a package that came
    from the Python scientific computing community. NumPy is great for manipulating
    multidimensional arrays and applying linear algebra functions to those arrays.
    It also has tools to integrate C, C++, and Fortran code, increasing its performance
    capabilities even more. There are a large number of Python packages that use NumPy
    as their numerical engine, including pandas and scikit-learn. These packages are
    part of SciPy, an ecosystem for packages used in mathematics, science, and engineering.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy ([http://www.numpy.org](http://www.numpy.org)) 是一个来自 Python 科学计算社区的包。NumPy
    非常适合操作多维数组，并对这些数组应用线性代数函数。它还具备与 C、C++ 和 Fortran 代码集成的工具，进一步提高了性能。许多使用 NumPy 作为数值引擎的
    Python 包，包括 pandas 和 scikit-learn，都是 SciPy 生态系统的一部分，专门用于数学、科学和工程领域。
- en: 'To import the package, open the Jupyter notebook used in the previous activity
    and type the following command:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 要导入这个包，请打开之前活动中使用的 Jupyter notebook，并输入以下命令：
- en: '[PRE9]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The basic NumPy object is `ndarray`, a homogeneous multidimensional array, usually
    composed of numbers, but it can hold generic data. NumPy also includes several
    functions for array manipulation, linear algebra, matrix operations, statistics,
    and other areas. One of the ways that NumPy shines is in scientific computing,
    where matrix and linear algebra operations are common. Another strength of NumPy
    is its tools that integrate with C++ and FORTRAN code. NumPy is also heavily used
    by other Python libraries, such as pandas.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 基本的 NumPy 对象是 `ndarray`，它是一个同质的多维数组，通常由数字组成，但也可以存储通用数据。NumPy 还包含多个用于数组操作、线性代数、矩阵运算、统计学和其他领域的函数。NumPy
    的一个亮点是在科学计算中，矩阵和线性代数操作非常常见。NumPy 的另一个优势是它可以与 C++ 和 FORTRAN 代码集成。NumPy 也被其他 Python
    库广泛使用，如 pandas。
- en: SciPy
  id: totrans-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: SciPy
- en: '**SciPy** ([https://www.scipy.org](https://www.scipy.org)) is an ecosystem
    of libraries for mathematics, science, and engineering. NumPy, SciPy, scikit-learn,
    and others are part of this ecosystem. It is also the name of a library that includes
    the core functionality for lots of scientific areas.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '**SciPy** ([https://www.scipy.org](https://www.scipy.org)) 是一个数学、科学和工程学的库生态系统。NumPy、SciPy、scikit-learn
    等都是这个生态系统的一部分。它也是一个库的名称，包含了许多科学领域的核心功能。'
- en: Matplotlib
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Matplotlib
- en: '**Matplotlib** ([https://matplotlib.org](https://matplotlib.org)) is a plotting
    library for Python for 2D graphs. It''s capable of generating figures in a variety
    of hard-copy formats for interactive use. It can use native Python data types,
    NumPy arrays, and pandas DataFrames as data sources. Matplotlib supports several
    backend—the part that supports the output generation in interactive or file format.
    This allows Matplotlib to be multiplatform. This flexibility also allows Matplotlib
    to be extended with toolkits that generate other kinds of plots, such as geographical
    plots and 3D plots.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '**Matplotlib** ([https://matplotlib.org](https://matplotlib.org)) 是一个用于 Python
    的二维图形绘制库。它能够生成多种硬拷贝格式的图形，供互动使用。它可以使用原生 Python 数据类型、NumPy 数组和 pandas DataFrame
    作为数据源。Matplotlib 支持多个后端——支持互动或文件格式输出的部分。这使得 Matplotlib 可以跨平台运行。这种灵活性还允许 Matplotlib
    扩展工具包，用于生成其他类型的图形，例如地理图和 3D 图形。'
- en: The interactive interface for Matplotlib was inspired by the MATLAB plotting
    interface. It can be accessed via the `matplotlib.pyplot` module. The file output
    can write files directly to disk. Matplotlib can be used in scripts, in IPython
    or Jupyter environments, in web servers, and in other platforms. Matplotlib is
    sometimes considered low level because several lines of code are needed to generate
    a plot with more details. One of the tools that we will look at in this book that
    plots graphs, which are common in analysis, is the **Seaborn** library, one of
    the extensions that we mentioned before.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: Matplotlib 的交互式界面灵感来自 MATLAB 的绘图界面。可以通过 `matplotlib.pyplot` 模块访问。文件输出可以直接写入磁盘。Matplotlib
    可以在脚本、IPython 或 Jupyter 环境中使用，也可以在 Web 服务器和其他平台中使用。Matplotlib 有时被认为是低级的，因为生成包含更多细节的图表需要多行代码。在本书中，我们将介绍一个常用于分析中的绘图工具——**Seaborn**
    库，它是我们之前提到的扩展之一。
- en: 'To import the interactive interface, use the following command in the Jupyter
    notebook:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 要导入交互式界面，请在 Jupyter notebook 中使用以下命令：
- en: '[PRE10]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: To have access to the plotting capabilities. We will show how to use Matplotlib
    in more detail in the next chapter.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问绘图功能，我们将在下一章中更详细地展示如何使用 Matplotlib。
- en: Pandas
  id: totrans-110
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Pandas
- en: '**Pandas** ([https://pandas.pydata.org](https://pandas.pydata.org)) is a data
    manipulation and analysis library that''s widely used in the data science community.
    Pandas is designed to work with tabular or labeled data, similar to SQL tables
    and Excel files.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '**Pandas** ([https://pandas.pydata.org](https://pandas.pydata.org)) 是一个广泛用于数据科学社区的数据操作和分析库。Pandas
    旨在处理类似 SQL 表格和 Excel 文件的表格型或标签型数据。'
- en: 'We will explore the operations that are possible with pandas in more detail.
    For now, it''s important to learn about the two basic pandas data structures:
    the **series**, a unidimensional data structure; and the data science workhorse,
    the bi-dimensional **DataFrame**, a two-dimensional data structure that supports
    indexes.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将更详细地探讨 pandas 提供的各种操作。现在，了解两个基本的 pandas 数据结构非常重要：**series**，一种一维数据结构；以及数据科学的工作马——二维数据结构
    **DataFrame**，它支持索引。
- en: Data in DataFrames and series can be ordered or unordered, homogeneous, or heterogeneous.
    Other great pandas features are the ability to easily add or remove rows and columns,
    and operations that SQL users are more familiar with, such as GroupBy, joins,
    subsetting, and indexing columns. Pandas is also great at handling time series
    data, with easy and flexible datetime indexing and selection.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: DataFrame 和 series 中的数据可以是有序的或无序的，既可以是同质的，也可以是异质的。pandas 的其他优秀功能包括轻松添加或删除行和列，以及
    SQL 用户更熟悉的操作，如 GroupBy、连接、子集提取和索引列。Pandas 在处理时间序列数据方面也非常强大，具有易用且灵活的日期时间索引和选择功能。
- en: 'Let''s import pandas into the Jupyter notebook from the previous activity with
    the following command:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用以下命令在之前的 Jupyter notebook 中导入 pandas：
- en: '[PRE11]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Using Pandas
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Pandas
- en: We will demonstrate the main operations for data manipulation using pandas.
    This approach is used as a standard for other data manipulation tools, such as
    Spark, so it's helpful to learn how to manipulate data using pandas. It's common
    in a big data pipeline to convert part of the data or a data sample to a pandas
    DataFrame to apply a more complex transformation, to visualize the data, or to
    use more refined machine learning models with the `scikit-learn` library. Pandas
    is also fast for in-memory, single-machine operations. Although there is a memory
    overhead between the data size and the pandas DataFrame, it can be used to manipulate
    large volumes of data quickly.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将演示如何使用 pandas 进行数据操作。这个方法被作为其他数据操作工具（如 Spark）的标准，因此学习如何使用 pandas 操作数据是很有帮助的。在大数据管道中，常常将部分数据或数据样本转换为
    pandas DataFrame，以应用更复杂的转换、可视化数据，或使用更精细的机器学习模型（例如 `scikit-learn` 库）。Pandas 在内存中进行单机操作时也非常快速。尽管数据大小与
    pandas DataFrame 之间存在内存开销，但它仍然可以快速操作大量数据。
- en: 'We will learn how to apply the basic operations:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将学习如何应用基本操作：
- en: Read data into a DataFrame
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数据读取到 DataFrame 中
- en: Selection and filtering
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择和过滤
- en: Apply a function to data
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将函数应用于数据
- en: GroupBy and aggregation
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GroupBy 和聚合
- en: Visualize data from DataFrames
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可视化来自 DataFrame 的数据
- en: Let's start by reading data into a pandas DataFrame.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从将数据读取到 pandas DataFrame 开始。
- en: Reading Data
  id: totrans-125
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 读取数据
- en: Pandas accepts several data formats and ways to ingest data. Let's start with
    the more common way, reading a CSV file. Pandas has a function called `read_csv`,
    which can be used to read a CSV file, either locally or from a URL. Let's read
    some data from the Socrata Open Data initiative, a RadNet Laboratory Analysis
    from the U.S. Environmental Protection Agency (EPA), which lists the radioactive
    content collected by the EPA.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas 支持多种数据格式和数据导入方式。我们从更常见的方式开始，读取一个 CSV 文件。Pandas 有一个名为 `read_csv` 的函数，可以用来读取
    CSV 文件，无论是本地文件还是来自 URL 的文件。我们将从美国环保局（EPA）的 Socrata 开放数据计划中读取一些数据，这些数据列出了 EPA 收集的放射性物质含量。
- en: 'Exercise 3: Reading Data with Pandas'
  id: totrans-127
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 3：使用 Pandas 读取数据
- en: 'How can an analyst start data analysis without data? We need to learn how to
    get data from an internet source into our notebook so that we can start our analysis.
    Let''s demonstrate how pandas can read CSV data from an internet source so we
    can analyze it:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 一个分析师如何在没有数据的情况下开始数据分析？我们需要学习如何将数据从互联网源导入到我们的笔记本中，才能开始分析。让我们展示如何使用 pandas 从互联网源读取
    CSV 数据，以便我们进行分析：
- en: Import pandas library.
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入 pandas 库。
- en: '[PRE12]'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Read the **Automobile mileage dataset**, available at this URL: [https://github.com/TrainingByPackt/Big-Data-Analysis-with-Python/blob/master/Lesson01/imports-85.data](https://github.com/TrainingByPackt/Big-Data-Analysis-with-Python/blob/master/Lesson01/imports-85.data).
    Convert it to csv.'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 读取**汽车里程数据集**，可通过以下 URL 获取：[https://github.com/TrainingByPackt/Big-Data-Analysis-with-Python/blob/master/Lesson01/imports-85.data](https://github.com/TrainingByPackt/Big-Data-Analysis-with-Python/blob/master/Lesson01/imports-85.data)。将其转换为
    CSV 格式。
- en: Use the column names to name the data, with the parameter `names` on the `read_csv`
    function.
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用列名为数据命名，通过 `read_csv` 函数中的 `names` 参数。
- en: '[PRE13]'
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Use the function `read_csv` from pandas and show the first rows calling the
    method `head` on the DataFrame:'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 pandas 的 `read_csv` 函数并通过调用 DataFrame 的 `head` 方法显示前几行：
- en: '[PRE14]'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The output is as follows:'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 1.5: Entries of the Automobile mileage dataset](img/C12913_01_05.jpg)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.5：汽车里程数据集的条目](img/C12913_01_05.jpg)'
- en: 'Figure 1.5: Entries of the Automobile mileage dataset'
  id: totrans-138
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.5：汽车里程数据集的条目
- en: 'Pandas can read more formats:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas 可以读取更多格式：
- en: JSON
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: JSON
- en: Excel
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Excel
- en: HTML
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: HTML
- en: HDF5
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: HDF5
- en: Parquet (with PyArrow)
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Parquet（使用 PyArrow）
- en: SQL databases
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SQL 数据库
- en: Google Big Query
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Google Big Query
- en: Try to read other formats from pandas, such as Excel sheets.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试从 pandas 中读取其他格式，如 Excel 表格。
- en: Data Manipulation
  id: totrans-148
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据处理
- en: 'By data manipulation we mean any selection, transformation, or aggregation
    that is applied over the data. Data manipulation can be done for several reasons:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 数据处理是指对数据进行任何选择、转换或聚合操作。数据处理可以出于多种原因进行：
- en: To select a subset of data for analysis
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择一个数据子集进行分析
- en: To clean a dataset, removing invalid, erroneous, or missing values
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 清洗数据集，移除无效、错误或缺失的值
- en: To group data into meaningful sets and apply aggregation functions
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数据分组为有意义的集合并应用聚合函数
- en: Pandas was designed to let the analyst do these transformations in an efficient
    way.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas 的设计旨在让分析师以高效的方式进行这些转换。
- en: '**Selection and Filtering**'
  id: totrans-154
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**选择与过滤**'
- en: Pandas DataFrames can be sliced similarly to Python lists. For example, to select
    a subset of the first 10 rows of the DataFrame, we can use the `[0:10]` notation.
    We can see in the following screenshot that the selection of the interval `[1:3]`
    that in the NumPy representation selects the rows `1` and `2`.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas DataFrame 可以像 Python 列表一样进行切片。例如，要选择 DataFrame 的前 10 行子集，可以使用 `[0:10]`
    语法。在以下截图中，我们看到选择 `[1:3]` 区间，NumPy 表示法选择了行 `1` 和 `2`。
- en: '![](img/C12913_01_06.jpg)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![](img/C12913_01_06.jpg)'
- en: 'Figure 1.6: Selection in a pandas DataFrame'
  id: totrans-157
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.6：Pandas DataFrame 中的选择
- en: In the following section, we'll explore the selection and filtering operation
    in depth.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将深入探讨选择与过滤操作。
- en: '**Selecting Rows Using Slicing**'
  id: totrans-159
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**使用切片选择行**'
- en: When performing data analysis, we usually want to see how data behaves differently
    under certain conditions, such as comparing a few columns, selecting only a few
    columns to help read the data, or even plotting. We may want to check specific
    values, such as the behavior of the rest of the data when one column has a specific
    value.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行数据分析时，我们通常希望查看数据在特定条件下的不同表现，例如比较几列数据、选择仅有几列帮助阅读数据，或进行绘图。我们可能想查看特定值，例如当一列具有特定值时，其他数据的表现如何。
- en: After selecting with slicing, we can use other methods, such as the `head` method,
    to select only a few rows from the beginning of the DataFrame. But how can we
    select some columns in a DataFrame?
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用切片选择之后，我们可以使用其他方法，例如 `head` 方法，从数据框的开头只选择几行。但如何选择数据框中的某些列呢？
- en: 'To select a column, just use the name of the column. We will use the notebook.
    Let''s select the `cylinders` column in our DataFrame using the following command:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 要选择一列，只需使用列名。我们将使用 notebook。使用以下命令选择数据框中的 `cylinders` 列：
- en: '[PRE15]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The output is as follows:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 1.7: DataFrame showing the state](img/C12913_01_07.jpg)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.7：显示状态的数据显示框](img/C12913_01_07.jpg)'
- en: 'Figure 1.7: DataFrame showing the state'
  id: totrans-166
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.7：显示状态的数据显示框
- en: 'Another form of selection that can be done is filtering by a specific value
    in a column. For example, let''s say that we want to select all rows that have
    the `State` column with the `MN` value. How can we do that? Try to use the Python
    equality operator and the DataFrame selection operation:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种选择方式是通过列中的特定值进行筛选。例如，假设我们想选择所有`State`列中值为`MN`的行。我们该如何做呢？尝试使用 Python 的相等运算符和数据框选择操作：
- en: '[PRE16]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '![Figure 1.8: DataFrame showing the MN states ](img/C12913_01_08.jpg)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.8：显示 MN 状态的数据显示框](img/C12913_01_08.jpg)'
- en: 'Figure 1.8: DataFrame showing the MN states'
  id: totrans-170
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.8：显示 MN 状态的数据显示框
- en: 'More than one filter can be applied at the same time. The `OR`, `NOT`, and
    `AND` logic operations can be used when combining more than one filter. For example,
    to select all rows that have `State` equal to `AK` and a `Location` of `Nome`,
    use the `&` operator:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 可以同时应用多个筛选器。当组合多个筛选器时，可以使用 `OR`、`NOT` 和 `AND` 逻辑运算符。例如，要选择所有 `State` 等于 `AK`
    且 `Location` 为 `Nome` 的行，请使用 `&` 运算符：
- en: '[PRE17]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '![Figure 1.9: DataFrame showing State AK and Location Nome](img/C12913_01_09.jpg)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.9：显示状态为 AK 和位置为 Nome 的数据框](img/C12913_01_09.jpg)'
- en: 'Figure 1.9: DataFrame showing State AK and Location Nome'
  id: totrans-174
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.9：显示状态为 AK 和位置为 Nome 的数据框
- en: Another powerful method is `.loc`. This method has two arguments, the row selection
    and the column selection, enabling fine-grained selection. An important caveat
    at this point is that, depending on the applied operation, the return type can
    be either a DataFrame or a series. The `.loc` method returns a series, as selecting
    only a column. This is expected, because each DataFrame column is a series. This
    is also important when more than one column should be selected. To do that, use
    two brackets instead of one, and use as many columns as you want to select.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个强大的方法是 `.loc`。该方法有两个参数，一个是行选择，另一个是列选择，能够实现精细的选择。此时一个重要的注意事项是，根据所应用的操作，返回的类型可以是数据框或系列。当只选择一列时，`.loc`
    方法返回一个系列。这是预期的，因为每个数据框列本身就是一个系列。当需要选择多个列时，也需要特别注意。为此，可以使用两个括号而不是一个，选择你想要的多个列。
- en: 'Exercise 4: Data Selection and the .loc Method'
  id: totrans-176
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 4：数据选择和 .loc 方法
- en: 'As we saw before, selecting data, separating variables, and viewing columns
    and rows of interest is fundamental to the analysis process. Let''s say we want
    to analyze the radiation from `I-131` in the state of `Minnesota`:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前看到的，选择数据、分离变量并查看感兴趣的列和行是分析过程的基础。假设我们想分析`I-131`在`明尼苏达州`的辐射：
- en: 'Import the NumPy and pandas libraries using the following command in the Jupyter
    notebook:'
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Jupyter notebook 中使用以下命令导入 NumPy 和 pandas 库：
- en: '[PRE18]'
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Read the RadNet dataset from the EPA, available from the Socrata project at
    [https://github.com/TrainingByPackt/Big-Data-Analysis-with-Python/blob/master/Lesson01/RadNet_Laboratory_Analysis.csv](https://github.com/TrainingByPackt/Big-Data-Analysis-with-Python/blob/master/Lesson01/RadNet_Laboratory_Analysis.csv):'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 EPA 获取 RadNet 数据集，该数据集可以从 Socrata 项目的[https://github.com/TrainingByPackt/Big-Data-Analysis-with-Python/blob/master/Lesson01/RadNet_Laboratory_Analysis.csv](https://github.com/TrainingByPackt/Big-Data-Analysis-with-Python/blob/master/Lesson01/RadNet_Laboratory_Analysis.csv)下载：
- en: '[PRE19]'
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Start by selecting a column using the `[''<name of the column>'']` notation.
    Use the `State` column:'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，使用 `['<列名>']` 符号选择一列。选择 `State` 列：
- en: '[PRE20]'
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The output is as follows:'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 1.10: Data in the State column](img/C12913_01_10.jpg)'
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 1.10：状态列中的数据](img/C12913_01_10.jpg)'
- en: 'Figure 1.10: Data in the State column'
  id: totrans-186
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.10：状态列中的数据
- en: 'Now filter the selected values in a column using the `MN` column name:'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用 `MN` 列名筛选所选列中的值：
- en: '[PRE21]'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The output is as follows:'
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 1.11: DataFrame showing States with MN](img/C12913_01_11.jpg)'
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 1.11：显示包含 MN 状态的数据显示框](img/C12913_01_11.jpg)'
- en: 'Figure 1.11: DataFrame showing States with MN'
  id: totrans-191
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.11：显示包含 MN 状态的数据显示框
- en: 'Select more than one column per condition. Add the `Sample Type` column for
    filtering:'
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据条件选择多个列。为过滤添加`Sample Type`列：
- en: '[PRE22]'
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The output is as follows:'
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![](img/C12913_01_12.jpg)'
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](img/C12913_01_12.jpg)'
- en: 'Figure 1.12: DataFrame with State CA and Sample type as Drinking water'
  id: totrans-196
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.12：具有加利福尼亚州和样本类型为饮用水的DataFrame
- en: 'Next, select the `MN` state and the isotope `I-131`:'
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，选择`MN`州和同位素`I-131`：
- en: '[PRE23]'
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The output is as follows:'
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 1.13: Data showing the DataFrame with State Minnesota and Isotope
    I-131](img/C12913_01_13.jpg)'
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 1.13：显示具有明尼苏达州和同位素I-131的DataFrame数据](img/C12913_01_13.jpg)'
- en: 'Figure 1.13: Data showing the DataFrame with State Minnesota and Isotope I-131'
  id: totrans-201
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.13：显示具有明尼苏达州和同位素I-131的DataFrame数据
- en: The radiation in the state of Minnesota with ID `555` is the highest.
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 明尼苏达州（ID为`555`）的辐射值最高。
- en: 'We can do the same more easily with the `.loc` method, filtering by state and
    selecting a column on the same `.loc` call:'
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以更轻松地使用`.loc`方法，通过州进行过滤，并在同一`.loc`调用中选择一列：
- en: '[PRE24]'
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The output is as follows:'
  id: totrans-205
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 1.14: DataFrame with I-132](img/C12913_01_14.jpg)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.14：包含I-132的DataFrame](img/C12913_01_14.jpg)'
- en: 'Figure 1.14: DataFrame with I-132'
  id: totrans-207
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.14：包含I-132的DataFrame
- en: In this exercise, we learned how to filter and select values, either on columns
    or rows, using the NumPy slice notation or the `.loc` method. This can help when
    analyzing data, as we can check and manipulate only a subset of the data instead
    having to handle the entire dataset at the same time.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们学习了如何使用NumPy切片表示法或`.loc`方法来过滤和选择值，无论是在列还是行上。这可以帮助我们在分析数据时，仅检查和操作数据的一个子集，而不必一次性处理整个数据集。
- en: Note
  id: totrans-209
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: 'The result of the `.loc` filter is a `.loc`. Because the DataFrame can be understood
    as a 2D combination of series, the selection of one column will return a series.
    To make a selection and still return a DataFrame, use double brackets:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '`.loc`筛选的结果是一个`.loc`对象。因为DataFrame可以被理解为一个二维的系列组合，选择一列将返回一个系列。为了使选择仍然返回一个DataFrame，请使用双括号：'
- en: '`df[[''I-132'']].head()`'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '`df[[''I-132'']].head()`'
- en: '**Applying a Function to a Column**'
  id: totrans-212
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**对列应用函数**'
- en: Data is never clean. There are always cleaning tasks that have to be done before
    a dataset can be analyzed. One of the most common tasks in data cleaning is applying
    a function to a column, changing a value to a more adequate one. In our example
    dataset, when no concentration was measured, the `non-detect` value was inserted.
    As this column is a numerical one, analyzing it could become complicated. We can
    apply a transformation over a column, changing from `non-detect` to `numpy.NaN`,
    which makes manipulating numerical values more easy, filling with other values
    such as the mean, and so on.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 数据永远不会是干净的。在数据集可以被分析之前，总是需要做一些清理工作。数据清理中最常见的任务之一是对列应用一个函数，将值更改为更合适的值。在我们的示例数据集中，当没有测量浓度时，会插入`non-detect`值。由于这一列是数字型的，分析它可能会变得复杂。我们可以对该列应用转换，将`non-detect`更改为`numpy.NaN`，这使得操作数值更为简单，之后可以填充其他值，比如均值等。
- en: To apply a function to more than one column, use the `applymap` method, with
    the same logic as the `apply` method. For example, another common operation is
    removing spaces from strings. Again, we can use the `apply` and `applymap` functions
    to fix the data. We can also apply a function to rows instead of to columns, using
    the axis parameter (`0` for rows, `1` for columns).
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 要对多个列应用函数，请使用`applymap`方法，其逻辑与`apply`方法相同。例如，另一个常见的操作是去除字符串中的空格。我们可以使用`apply`和`applymap`函数来修复数据。我们还可以将函数应用于行而不是列，使用axis参数（`0`表示行，`1`表示列）。
- en: 'Activity 2: Working with Data Problems'
  id: totrans-215
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动 2：处理数据问题
- en: 'Before starting an analysis, we need to check for data problems, and when we
    find them (which is very common!), we have to correct the issues by transforming
    the DataFrame. One way to do that, for instance, is by applying a function to
    a column, or to the entire DataFrame. It''s common for some numbers in a DataFrame,
    when it''s read, to not be converted correctly to floating-point numbers. Let''s
    fix this issue by applying functions:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始分析之前，我们需要检查数据问题，当我们发现问题时（这非常常见！），我们必须通过转换DataFrame来纠正问题。例如，可以通过对某一列或整个DataFrame应用函数来解决问题。通常，DataFrame中的一些数字在读取时未能正确转换为浮点数。我们可以通过应用函数来修复这个问题：
- en: Import `pandas` and `numpy` library.
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`pandas`和`numpy`库。
- en: Read the RadNet dataset from the U.S. Environmental Protection Agency.
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从美国环保局读取RadNet数据集。
- en: Create a list with numeric columns for radionuclides in the RadNet dataset.
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个包含RadNet数据集中放射性核素的数字列的列表。
- en: Use the `apply` method on one column, with a lambda function that compares the
    `Non-detect` string.
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对单列使用`apply`方法，配合lambda函数比较`Non-detect`字符串。
- en: Replace the text values by `NaN` in one column with `np.nan`.
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将某一列中的文本值替换为`NaN`，使用`np.nan`。
- en: Use the same lambda comparison and use the `applymap` method on several columns
    at the same time, using the list created in the first step.
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用相同的lambda比较方法，并在多个列上同时使用`applymap`方法，使用第一步中创建的列表。
- en: Create a list of the remaining columns that are not numeric.
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个包含所有非数字列的列表。
- en: Remove any spaces from these columns.
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 删除这些列中的空格。
- en: Using the selection and filtering methods, verify that the names of the string
    columns don't have any more spaces.
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用选择和过滤方法，验证字符串列的列名中是否还存在空格。
- en: Note
  id: totrans-226
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The solution for this activity can be found on page 200.
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该活动的解决方案可以在第200页找到。
- en: The spaces in column names can be extraneous and can make selection and filtering
    more complicated. Fixing the numeric types helps when statistics must be computed
    using the data. If there is a value that is not valid for a numeric column, such
    as a string in a numeric column, the statistical operations will not work. This
    scenario happens, for example, when there is an error in the data input process,
    where the operator types the information by hand and makes mistakes, or the storage
    file was converted from one format to another, leaving incorrect values in the
    columns.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 列名中的空格可能是多余的，且会使选择和过滤变得更加复杂。修正数字类型对于需要使用数据计算统计值时非常有帮助。如果某个数字列中的值不合法，例如一个数字列中有字符串，统计操作将无法执行。例如，在数据输入过程中，操作员手动输入信息时可能会出错，或者存储文件从一种格式转换为另一种格式时，导致列中留下了不正确的值。
- en: Data Type Conversion
  id: totrans-229
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据类型转换
- en: 'Another common operation in data cleanup is getting the data types right. This
    helps with detecting invalid values and applying the right operations. The main
    types stored in pandas are as follows:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 数据清理中的另一个常见操作是确保数据类型正确。这有助于检测无效值并应用正确的操作。pandas中主要存储的类型如下：
- en: '`float` (`float64`, `float32`)'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`float`（`float64`、`float32`）'
- en: '`integer` (`int64`, `int32`)'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`integer`（`int64`、`int32`）'
- en: '`datetime` (`datetime64[ns, tz]`)'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`datetime`（`datetime64[ns, tz]`）'
- en: '`timedelta` (`timedelta[ns]`)'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`timedelta`（`timedelta[ns]`）'
- en: '`bool`'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bool`'
- en: '`object`'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`object`'
- en: '`category`'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`category`'
- en: Types can be set on, read, or inferred by pandas. Usually, if pandas cannot
    detect what data type the column is, it assumes that is object that stores the
    data as strings.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 数据类型可以通过pandas进行设置、读取或推断。通常，如果pandas无法检测到列的数据类型，它会假设该列是存储为字符串的对象类型。
- en: To transform the data into the right data types, we can use conversion functions
    such as `to_datetime`, `to_numeric`, or `astype`. Category types, columns that
    can only assume a limited number of options, are encoded as the `category` type.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将数据转换为正确的数据类型，我们可以使用转换函数，如`to_datetime`、`to_numeric`或`astype`。类别类型，即只能选择有限选项的列，会被编码为`category`类型。
- en: 'Exercise 5: Exploring Data Types'
  id: totrans-240
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习5：探索数据类型
- en: 'Transform the data types in our example DataFrame to the correct types with
    the pandas `astype` function. Let''s use the sample dataset from [https://opendata.socrata.com/](https://opendata.socrata.com/):'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 使用pandas的`astype`函数将我们示例数据框中的数据类型转换为正确的类型。我们将使用来自[https://opendata.socrata.com/](https://opendata.socrata.com/)的示例数据集：
- en: 'Import the required libraries, as illustrated here:'
  id: totrans-242
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照此处所示导入所需的库：
- en: '[PRE25]'
  id: totrans-243
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Read the data from the dataset as follows:'
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按如下方式读取数据集中的数据：
- en: '[PRE26]'
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Check the current data types using the `dtypes` function on the DataFrame:'
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`dtypes`函数检查DataFrame的当前数据类型：
- en: '[PRE27]'
  id: totrans-247
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Use the `to_datetime` method to convert the dates from string format to `datetime`
    format:'
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`to_datetime`方法将日期从字符串格式转换为`datetime`格式：
- en: '[PRE28]'
  id: totrans-249
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The output is as follows:'
  id: totrans-250
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '[PRE29]'
  id: totrans-251
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Use Lambda function:'
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用Lambda函数：
- en: '[PRE30]'
  id: totrans-253
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Apply the `to_numeric` method to the list of numeric columns created in the
    previous activity to convert the columns to the correct numeric types:'
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`to_numeric`方法对前一个活动中创建的数字列列表应用，转换列为正确的数字类型：
- en: '[PRE31]'
  id: totrans-255
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Check the types of the columns again. They should be `float64` for the numeric
    columns and `datetime64[ns]` for the date columns:'
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再次检查列的数据类型。数字列应该是`float64`类型，日期列应该是`datetime64[ns]`类型：
- en: '[PRE32]'
  id: totrans-257
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Use the `astype` method to transform the columns that are not numeric to the
    `category` type:'
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`astype`方法将非数字列转换为`category`类型：
- en: '[PRE33]'
  id: totrans-259
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Check the types with the `dtype` function for the last time:'
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后一次使用`dtype`函数检查数据类型：
- en: '[PRE34]'
  id: totrans-261
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The output is as follows:'
  id: totrans-262
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 1.15: DataFrame and its types](img/C12913_01_15.jpg)'
  id: totrans-263
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.15：DataFrame 及其类型](img/C12913_01_15.jpg)'
- en: 'Figure 1.15: DataFrame and its types'
  id: totrans-264
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.15：DataFrame 及其类型
- en: Now our dataset looks fine, with all values correctly cast to the right types.
    But correcting the data is only part of the story. We want, as analysts, to understand
    the data from different perspectives. For example, we may want to know which state
    has the most contamination, or the radionuclide that is the least prevalent across
    cities. We may ask about the number of valid measurements present in the dataset.
    All these questions have in common transformations that involve grouping data
    together and aggregating several values. With pandas, this is accomplished with
    `GroupBy`. Let's see how we can use it by key and aggregate the data.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们的数据集看起来不错，所有值都已正确转换为正确的数据类型。但数据修正只是其中的一部分。作为分析师，我们希望从不同的角度理解数据。例如，我们可能想知道哪个州的污染最严重，或者哪种放射性核素在各城市中最不常见。我们可能会问数据集中有效测量的数量。所有这些问题都有一个共同点，那就是涉及对数据进行分组并聚合多个值的转换。使用
    pandas，我们可以通过 `GroupBy` 来实现这一点。让我们看看如何按键进行分组并聚合数据。
- en: Aggregation and Grouping
  id: totrans-266
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 聚合与分组
- en: 'After getting the dataset, our analyst may have to answer a few questions.
    For example, we know the value of the radionuclide concentration per city, but
    an analyst may be asked to answer: which state, on average, has the highest radionuclide
    concentration?'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 在获得数据集后，分析师可能需要回答一些问题。例如，我们知道每个城市的放射性核素浓度，但分析师可能会被要求回答：平均而言，哪个州的放射性核素浓度最高？
- en: To answer the questions posed, we need to group the data somehow and calculate
    an aggregation on it. But before we go into grouping data, we have to prepare
    the dataset so that we can manipulate it in an efficient manner. Getting the right
    types in a pandas DataFrame can be a huge boost for performance and can be leveraged
    to enforce data consistency— it makes sure that numeric data really is numeric
    and allows us to execute operations that we want to use to get the answers.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 为了回答提出的问题，我们需要以某种方式对数据进行分组，并对其进行聚合计算。但在进入数据分组之前，我们需要准备数据集，以便能够以高效的方式进行操作。在 pandas
    的 DataFrame 中获得正确的数据类型可以极大地提高性能，并有助于执行数据一致性检查—它确保数值数据确实是数值数据，并允许我们执行所需的操作来获得答案。
- en: '`GroupBy` allows us to get a more general view of a feature, arranging data
    given a `GroupBy` key and an aggregation operation. In pandas, this operation
    is done with the `GroupBy` method, over a selected column, such as State. Note
    the aggregation operation after the `GroupBy` method. Some examples of the operations
    that can be applied are as follows:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: '`GroupBy` 允许我们从更一般的角度查看特征，通过给定 `GroupBy` 键和聚合操作来排列数据。在 pandas 中，这个操作是通过 `GroupBy`
    方法完成的，操作的列可以是例如 State。请注意 `GroupBy` 方法后的聚合操作。以下是一些可以应用的操作示例：'
- en: '`mean`'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mean`'
- en: '`median`'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`median`'
- en: '`std` (**standard deviation**)'
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`std` (**标准差**)'
- en: '`mad` (**mean absolute deviation**)'
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mad` (**均值绝对偏差**)'
- en: '`sum`'
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sum`'
- en: '`count`'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`count`'
- en: '`abs`'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`abs`'
- en: Note
  id: totrans-277
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注
- en: Several statistics, such as **mean** and **standard deviation**, only make sense
    with numeric data.
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一些统计量，例如 **均值** 和 **标准差**，只有在数值数据的情况下才有意义。
- en: After applying `GroupBy`, a specific column can be selected and the aggregation
    operation can be applied to it, or all the remaining columns can be aggregated
    by the same function. Like SQL, `GroupBy` can be applied to more than one column
    at a time, and more than one aggregation operation can be applied to selected
    columns, one operation per column.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 应用 `GroupBy` 后，可以选择特定的列并对其应用聚合操作，或者可以对所有剩余的列使用相同的聚合函数进行聚合。像 SQL 一样，`GroupBy`
    可以同时应用于多列，并且可以对选定的列应用多个聚合操作，每列一个操作。
- en: The `GroupBy` command in Pandas has some options, such as `as_index`, which
    can override the standard of transforming grouping key's columns to indexes and
    leaving them as normal columns. This is helpful when a new index will be created
    after the `GroupBy` operation, for example.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas 中的 `GroupBy` 命令有一些选项，例如 `as_index`，可以覆盖将分组键的列转换为索引并将其保留为普通列的标准。当在 `GroupBy`
    操作后将创建新索引时，这很有帮助，例如。
- en: Aggregation operations can be done over several columns and different statistical
    methods at the same time with the `agg` method, passing a dictionary with the
    name of the column as the **key** and a list of statistical operations as **values**.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 聚合操作可以在多个列上同时进行，并且使用 `agg` 方法可以同时应用不同的统计方法，通过传递一个字典，字典的键是列名，值是统计操作的列表。
- en: 'Exercise 6: Aggregation and Grouping Data'
  id: totrans-282
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 6：聚合和分组数据
- en: 'Remember that we have to answer the question of which state has, on average,
    the highest radionuclide concentration. As there are several cities per state,
    we have to combine the values of all cities in one state and calculate the average.
    This is one of the applications of `GroupBy`: calculating the average values of
    one variable as per a grouping. We can answer the question using `GroupBy`:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，我们需要回答哪个州的放射性核素浓度平均值最高。由于每个州有多个城市，我们需要将一个州内所有城市的值合并并计算平均值。这是 `GroupBy` 的一个应用：按分组计算一个变量的平均值。我们可以使用
    `GroupBy` 来回答这个问题：
- en: 'Import the required libraries:'
  id: totrans-284
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所需的库：
- en: '[PRE35]'
  id: totrans-285
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Load the datasets from the [https://opendata.socrata.com/](https://opendata.socrata.com/):'
  id: totrans-286
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 [https://opendata.socrata.com/](https://opendata.socrata.com/) 加载数据集：
- en: '[PRE36]'
  id: totrans-287
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Group the DataFrame using the `State` column.
  id: totrans-288
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `State` 列对 DataFrame 进行分组。
- en: '[PRE37]'
  id: totrans-289
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Select the radionuclide `Cs-134` and calculate the average value per group:'
  id: totrans-290
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择放射性核素 `Cs-134` 并计算每组的平均值：
- en: '[PRE38]'
  id: totrans-291
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Do the same for all columns, grouping per state and applying directly the `mean`
    function:'
  id: totrans-292
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对所有列执行相同的操作，按州分组并直接应用 `mean` 函数：
- en: '[PRE39]'
  id: totrans-293
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Now, group by more than one column, using a list of grouping columns.
  id: totrans-294
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，根据多个列进行分组，使用一个包含多个分组列的列表。
- en: 'Aggregate using several aggregation operations per column with the `agg` method.
    Use the `State` and `Location` columns:'
  id: totrans-295
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `agg` 方法对每一列执行多个聚合操作。使用 `State` 和 `Location` 列：
- en: '[PRE40]'
  id: totrans-296
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: NumPy on Pandas
  id: totrans-297
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: NumPy 与 Pandas
- en: NumPy functions can be applied to DataFrames directly or through the `apply`
    and `applymap` methods. Other NumPy functions, such as `np.where`, also work with
    DataFrames.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy 函数可以直接应用于 DataFrame，也可以通过 `apply` 和 `applymap` 方法应用。其他 NumPy 函数，如 `np.where`，也可以与
    DataFrame 一起使用。
- en: Exporting Data from Pandas
  id: totrans-299
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从 Pandas 导出数据
- en: After creating an intermediate or final dataset in pandas, we can export the
    values from the DataFrame to several other formats. The most common one is CSV,
    and the command to do so is `df.to_csv('filename.csv')`. Other formats, such as
    Parquet and JSON, are also supported.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 在 pandas 中创建了中间数据集或最终数据集之后，我们可以将 DataFrame 中的值导出到其他格式。最常用的格式是 CSV，执行此操作的命令是`df.to_csv('filename.csv')`。其他格式，如
    Parquet 和 JSON，也受到支持。
- en: Note
  id: totrans-301
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: Parquet is particularly interesting, and it is one of the big data formats that
    we will discuss later in the book.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: Parquet 格式特别有趣，它是我们将在本书后面讨论的一个大数据格式之一。
- en: 'Exercise 7: Exporting Data in Different Formats'
  id: totrans-303
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 7：导出不同格式的数据
- en: 'After finishing our analysis, we may want to save our transformed dataset with
    all the corrections, so if we want to share this dataset or redo our analysis,
    we don''t have to transform the dataset again. We can also include our analysis
    as part of a larger data pipeline or even use the prepared data in the analysis
    as input to a machine learning algorithm. We can accomplish data exporting our
    DataFrame to a file with the right format:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 完成分析后，我们可能想保存我们的转换数据集并包含所有的修正，这样如果我们想分享这个数据集或重新进行分析，就不必再次转换数据集。我们还可以将分析作为更大数据管道的一部分，甚至将准备好的数据用作机器学习算法的输入。我们可以通过将
    DataFrame 导出到正确格式的文件来实现数据导出：
- en: 'Import all the required libraries and read the data from the dataset using
    the following command:'
  id: totrans-305
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所有必要的库并使用以下命令从数据集中读取数据：
- en: '[PRE41]'
  id: totrans-306
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Redo all adjustments for the data types (date, numeric, and categorical) in
    the RadNet data. The type should be the same as in *Exercise 6: Aggregation and
    Grouping Data*.'
  id: totrans-307
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对 RadNet 数据中的数据类型（日期、数值、类别）重新进行所有调整。类型应与 *练习 6：聚合和分组数据* 中的相同。
- en: 'Select the numeric columns and the categorical columns, creating a list for
    each of them:'
  id: totrans-308
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择数值型列和类别型列，为每个列创建一个列表：
- en: '[PRE42]'
  id: totrans-309
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'The output is as follows:'
  id: totrans-310
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Figure 1.16: List of columns](img/C12913_01_16.jpg)'
  id: totrans-311
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 1.16：列列表](img/C12913_01_16.jpg)'
- en: 'Figure 1.16: List of columns'
  id: totrans-312
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1.16：列列表
- en: 'Apply the lambda function that replaces `Non-detect` with `np.nan`:'
  id: totrans-313
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 应用替换 `Non-detect` 为 `np.nan` 的 lambda 函数：
- en: '[PRE43]'
  id: totrans-314
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Remove the spaces from the categorical columns:'
  id: totrans-315
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 删除类别列中的空格：
- en: '[PRE44]'
  id: totrans-316
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Transform the date columns to the `datetime` format:'
  id: totrans-317
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将日期列转换为 `datetime` 格式：
- en: '[PRE45]'
  id: totrans-318
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Transform all numeric columns to the correct numeric format with the `to_numeric`
    method:'
  id: totrans-319
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `to_numeric` 方法将所有数值型列转换为正确的数值格式：
- en: '[PRE46]'
  id: totrans-320
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Transform all categorical variables to the `category` type:'
  id: totrans-321
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将所有类别变量转换为`category`类型：
- en: '[PRE47]'
  id: totrans-322
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Export our transformed DataFrame, with the right values and columns, to the
    CSV format with the `to_csv` function. Exclude the index using `index=False`,
    use a semicolon as the separator `sep=";"`, and encode the data as UTF-8 `encoding="utf-8"`:'
  id: totrans-323
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`to_csv`函数将我们转换后的DataFrame导出为CSV格式，确保包含正确的值和列。通过`index=False`排除索引，使用分号作为分隔符`sep=";"`，并将数据编码为UTF-8格式`encoding="utf-8"`：
- en: '[PRE48]'
  id: totrans-324
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Export the same DataFrame to the Parquet columnar and binary format with the
    `to_parquet` method:'
  id: totrans-325
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`to_parquet`方法将相同的DataFrame导出为Parquet列式和二进制格式：
- en: '[PRE49]'
  id: totrans-326
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: Note
  id: totrans-327
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: Be careful when converting a datetime to a string!
  id: totrans-328
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 转换datetime为字符串时要小心！
- en: Visualization with Pandas
  id: totrans-329
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Pandas进行可视化
- en: Pandas can be thought as a data Swiss Army knife, and one thing that a data
    scientist always needs when analyzing data is to visualize that data. We will
    go into detail on the kinds of plot that we can apply in an analysis. For now,
    the idea is to show how to do **quick and dirty** plots directly from pandas.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas可以被看作是一个数据的瑞士军刀，而数据科学家在分析数据时总是需要的一项技能就是可视化数据。我们将在后续详细介绍可应用于分析的各种图表类型。现在的目标是展示如何直接从pandas创建**快速且简单**的图表。
- en: The `plot` function can be called directly from the DataFrame selection, allowing
    fast visualizations. A scatter plot can be created by using Matplotlib and passing
    data from the DataFrame to the plotting function. Now that we know the tools,
    let's focus on the pandas interface for data manipulation. This interface is so
    powerful that it is replicated by other projects that we will see in this course,
    such as Spark. We will explain the plot components and methods in more detail
    in the next chapter.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: '`plot`函数可以直接从DataFrame选择调用，实现快速可视化。通过使用Matplotlib并将数据从DataFrame传递到绘图函数，可以创建散点图。现在我们了解了工具，接下来让我们专注于pandas的数据处理接口。这个接口非常强大，其他一些项目（如Spark）也复制了它。我们将在下一章更详细地解释图表的组成部分和方法。'
- en: You will see how to create graphs that are useful for statistical analysis in
    the next chapter. Focus here on the mechanics of creating plots from pandas for
    quick visualizations.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 你将在下一章看到如何创建对统计分析有用的图表。在这里，重点是了解如何从pandas创建图表以进行快速可视化。
- en: 'Activity 3: Plotting Data with Pandas'
  id: totrans-333
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动3：使用Pandas绘制数据
- en: 'To finish up our activity, let''s redo all the previous steps and plot graphs
    with the results, as we would do in a preliminary analysis:'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 为了完成我们的活动，让我们重新做一遍之前的所有步骤，并用结果绘制图表，就像在初步分析中所做的那样：
- en: Use the RadNet DataFrame that we have been working with.
  id: totrans-335
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用我们之前处理过的RadNet DataFrame。
- en: Fix all the data type problems, as we saw before.
  id: totrans-336
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 修复所有的数据类型问题，正如我们之前所看到的。
- en: 'Create a plot with a filter per `Location`, selecting the city of `San Bernardino`,
    and one radionuclide, with the *x*-axis as date and the *y*-axis as radionuclide
    `I-131`:![Figure 1.17: Plot of Location with I-131](img/C12913_01_17.jpg)'
  id: totrans-337
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个按`Location`过滤的图表，选择`San Bernardino`城市，并选择一个放射性核素，*x*-轴为日期，*y*-轴为放射性核素`I-131`：![图1.17：带I-131的地点图表](img/C12913_01_17.jpg)
- en: 'Figure 1.17: Plot of Location with I-131'
  id: totrans-338
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1.17：带I-131的地点图表
- en: 'Create a scatter plot with the concentration of two related radionuclides,
    `I-131` and `I-132`:'
  id: totrans-339
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个散点图，显示两个相关放射性核素`I-131`和`I-132`的浓度：
- en: '![Figure 1.18: Plot of I-131 and I-132](img/C12913_01_18.jpg)'
  id: totrans-340
  prefs: []
  type: TYPE_IMG
  zh: '![图1.18：I-131和I-132的图表](img/C12913_01_18.jpg)'
- en: 'Figure 1.18: Plot of I-131 and I-132'
  id: totrans-341
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1.18：I-131和I-132的图表
- en: Note
  id: totrans-342
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The solution for this activity can be found on page 203.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 本活动的解决方案可以在203页找到。
- en: We are getting a bit ahead of ourselves here with the plotting, so we don't
    need to worry about the details of the plot or how we attribute titles, labels,
    and so on. The important takeaway here is understanding that we can plot directly
    from the DataFrame for quick analysis and visualization.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里稍微有些超前了，因此不必担心图表的细节，或者如何设置标题、标签等。这里的关键是理解我们可以直接从DataFrame绘制图表进行快速分析和可视化。
- en: Summary
  id: totrans-345
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: We have learned about the most common Python libraries used in data analysis
    and data science, which make up the Python data science stack. We learned how
    to ingest data, select it, filter it, and aggregate it. We saw how to export the
    results of our analysis and generate some quick graphs.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经了解了数据分析和数据科学中最常用的Python库，它们组成了Python数据科学栈。我们学习了如何获取数据、选择数据、过滤数据并进行聚合。我们还学习了如何导出分析结果并生成一些快速图表。
- en: These are steps done in almost any data analysis. The ideas and operations demonstrated
    here can be applied to data manipulation with big data. Spark DataFrames were
    created with the pandas interface in mind, and several operations are performed
    in a very similar fashion in pandas and Spark, greatly simplifying the analysis
    process. Another great advantage of knowing your way around pandas is that Spark
    can convert its DataFrames to pandas DataFrames and back again, enabling analysts
    to work with the best tool for the job.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 这些步骤几乎适用于任何数据分析。这里展示的思路和操作可以应用于大数据的数据处理。Spark DataFrame 的创建考虑了 pandas 接口，许多操作在
    pandas 和 Spark 中以非常相似的方式执行，这大大简化了分析过程。掌握 pandas 的另一个巨大优势是，Spark 可以将其 DataFrame
    转换为 pandas DataFrame，然后再转换回来，使分析师能够使用最适合任务的工具。
- en: Before going into big data, we need to understand how to better visualize the
    results of our analysis. Our understanding of the data and its behavior can be
    greatly enhanced if we visualize it using the correct plots. We can draw inferences
    and see anomalies and patterns when we plot the data.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 在进入大数据之前，我们需要了解如何更好地可视化分析结果。如果我们使用正确的图表来可视化数据，我们对数据及其行为的理解可以大大增强。通过绘制数据，我们能够做出推断，并观察到异常和模式。
- en: In the next chapter, we will learn how to choose the right graph for each kind
    of data and analysis, and how to plot it using Matplotlib and Seaborn.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将学习如何为每种数据和分析选择合适的图表，并如何使用 Matplotlib 和 Seaborn 绘制它。
