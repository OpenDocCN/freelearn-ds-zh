- en: '4'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '4'
- en: Setting a Strong Baseline Forecast
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置强基线预测
- en: In the previous chapter, we saw some techniques we can use to understand **time
    series data**, do some **Exploratory Data Analysis** (**EDA**), and so on. But
    now, let’s get to the crux of the matter—**time series forecasting**. The point
    of understanding the dataset and looking at patterns, seasonality, and so on was
    to make the job of forecasting that series easier. And with any machine learning
    exercise, one of the first things we need to establish before going further is
    a **baseline**.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们介绍了一些可以用来理解**时间序列数据**、进行**探索性数据分析**（**EDA**）等技术。但现在，让我们进入重点——**时间序列预测**。理解数据集、观察模式、季节性等，目的是为了让预测这个序列的工作变得更容易。像任何机器学习任务一样，我们在进一步操作之前需要首先建立一个**基线**。
- en: A baseline is a simple model that provides reasonable results without requiring
    a lot of time to come up with them. Many people think of a baseline as something
    that is derived from common sense, such as an average or some rule of thumb. But
    as a best practice, a baseline can be as sophisticated as we want it to be, so
    long as it is quickly and easily implemented. Any further progress we want to
    make will be in terms of the performance of this baseline.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 基线是一个简单的模型，它能提供合理的结果，而且不需要花费大量时间来得出这些结果。许多人认为基线是由常识推导出来的，例如平均值或某些经验法则。但作为最佳实践，基线可以是我们想要的任何复杂度，只要它能够快速且容易地实现。我们想要取得的任何进一步进展，都会基于这个基线的性能。
- en: In this chapter, we will look at a few classical techniques that can be used
    as baselines, and strong baselines at that. Some may feel that the forecasting
    techniques we will be discussing in this chapter shouldn’t be baselines, but we
    are keeping them in here because these techniques have stood the test of time—and
    for good reason. They are also very mature and can be applied with very little
    effort, thanks to the awesome open source libraries that implement them. There
    can be many types of problems/datasets where it is difficult to beat the baseline
    techniques we will discuss in this chapter, and in those cases, there is no shame
    in just sticking to one of these baseline techniques.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中，我们将介绍一些可以作为基线使用的经典技术，并且这些基线非常强大。有人可能认为我们将在本章讨论的预测技术不应作为基线，但我们将它们保留在这里，因为这些技术经受住了时间的考验——这有充分的理由。它们也非常成熟，并且可以轻松应用，得益于实现这些技术的开源库。在许多类型的问题或数据集中，可能很难超越我们将在本章讨论的基线技术，而在这些情况下，依赖这些基线技术并不羞耻。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Setting up a test harness
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置测试框架
- en: Generating strong baseline forecasts
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成强基线预测
- en: Assessing the forecastability of a time series
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估时间序列的可预测性
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: You will need to set up the Anaconda environment following the instructions
    in the *Preface* of the book to get a working environment with all the libraries
    and datasets required for the code in this book. Any additional library will be
    installed while running the notebooks.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要按照本书*前言*中的说明，设置Anaconda环境，以便获得一个包含本书代码所需的所有库和数据集的工作环境。在运行笔记本时，任何额外的库将被安装。
- en: 'You will need to run the following notebook before using the code in this chapter:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用本章代码之前，你需要先运行以下笔记本：
- en: The `02-Preprocessing_London_Smart_Meter_Dataset.ipynb` preprocessing notebook
    from `Chapter02`
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Chapter02`中的`02-Preprocessing_London_Smart_Meter_Dataset.ipynb`预处理笔记本'
- en: The code for this chapter can be found at [https://github.com/PacktPublishing/Modern-Time-Series-Forecasting-with-Python-2E/tree/main/notebooks/Chapter04](https://github.com/PacktPublishing/Modern-Time-Series-Forecasting-with-Python-2E/tree/main/notebooks/Chapter04).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码可以在[https://github.com/PacktPublishing/Modern-Time-Series-Forecasting-with-Python-2E/tree/main/notebooks/Chapter04](https://github.com/PacktPublishing/Modern-Time-Series-Forecasting-with-Python-2E/tree/main/notebooks/Chapter04)找到。
- en: Setting up a test harness
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置测试框架
- en: Before we start forecasting and setting up baselines, we need to set up a **test
    harness**. In software testing, a test harness is a collection of code and inputs
    that have been configured to test a program under various situations. In terms
    of machine learning, a test harness is a set of code and data that can be used
    to evaluate algorithms. It is important to set up a test harness so that we can
    evaluate all future algorithms in a standard and quick way.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始进行预测和设置基准之前，我们需要设置一个**测试工具**。在软件测试中，测试工具是一个由代码和输入组成的集合，旨在在不同情况下测试程序。在机器学习中，测试工具是一组代码和数据，用于评估算法。设置测试工具非常重要，这样我们就可以以标准且快捷的方式评估未来的所有算法。
- en: The first thing we need is **holdout (test)** and **validation** datasets.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先需要的是**留出（测试）**和**验证**数据集。
- en: Creating holdout (test) and validation datasets
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建留出（测试）和验证数据集
- en: As a standard practice, in machine learning, we set aside two parts of the dataset,
    name them *validation data* and *test data*, and don’t use them at all to train
    the model. The validation data is used in the modeling process to assess the quality
    of the model. To select between different model classes, tune the hyperparameters,
    perform feature selection, and so on, we need a dataset. Test data is like the
    final test of your chosen model. It tells you how well your model is doing in
    unseen data. If validation data is like the mid-term exams, the test data is your
    final exam.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 作为机器学习中的标准做法，我们将数据集分为两个部分，命名为*验证数据*和*测试数据*，并且完全不用于训练模型。验证数据用于建模过程，用来评估模型的质量。为了选择不同的模型类、调优超参数、执行特征选择等，我们需要一个数据集。测试数据则是你所选择模型的最终测试，它告诉你模型在未见过的数据上表现如何。如果验证数据像期中考试，那么测试数据就像期末考试。
- en: In regular regression or classification, we usually sample a few records at
    random and set them aside. But while dealing with time series, we need to respect
    the temporal aspect of the dataset. Therefore, a best practice is to set aside
    the latest part of the dataset as the test data. Another rule of thumb is to set
    equal-sized validation and test datasets so that the key modeling decisions we
    make based on the validation data are as close as possible to the test data. The
    dataset that we introduced in *Chapter 2*, *Acquiring and Processing Time Series
    Data*, the London Smart Energy dataset, contains the energy consumption readings
    of households in London from November 2011 to February 2014\. So, we are going
    to put aside January 2014 as the validation data and February 2014 as the test
    data.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在常规的回归或分类中，我们通常会随机抽取一些记录并将其保留下来。但在处理时间序列时，我们需要尊重数据集的时间特性。因此，一个最佳实践是将数据集的最新部分作为测试数据。另一个经验法则是将验证数据集和测试数据集设置为相同大小，以便我们基于验证数据所做的关键建模决策尽可能接近测试数据。我们在*第2章*《获取和处理时间序列数据》中介绍的数据集——伦敦智能能源数据集，包含了2011年11月到2014年2月期间伦敦家庭的能源消耗读数。因此，我们将把2014年1月作为验证数据，2014年2月作为测试数据。
- en: 'Let’s open `01-Setting_up_Experiment_Harness.ipynb` from the `Chapter04` folder
    and run it. In the notebook, we must create the train-test split both before and
    after filling the missing values with `SeasonalInterpolation` and save them accordingly.
    Once the notebook finishes running, you will have created the following files
    in the pre-processed folder with the 2014 data saved separately:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们打开`01-Setting_up_Experiment_Harness.ipynb`文件（位于`Chapter04`文件夹中）并运行它。在笔记本中，我们必须在填补缺失值之前和之后，使用`SeasonalInterpolation`进行训练-测试拆分，并相应地保存它们。运行完成后，你将在预处理文件夹中创建以下文件，并将2014年的数据单独保存：
- en: '`selected_blocks_train.parquet`'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`selected_blocks_train.parquet`'
- en: '`selected_blocks_val.parquet`'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`selected_blocks_val.parquet`'
- en: '`selected_blocks_test.parquet`'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`selected_blocks_test.parquet`'
- en: '`selected_blocks_train_missing_imputed.parquet`'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`selected_blocks_train_missing_imputed.parquet`'
- en: '`selected_blocks_val_missing_imputed.parquet`'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`selected_blocks_val_missing_imputed.parquet`'
- en: '`selected_blocks_test_missing_imputed.parquet`'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`selected_blocks_test_missing_imputed.parquet`'
- en: Now that we have a fixed dataset that can be used to fairly evaluate multiple
    algorithms, we need a way to evaluate the different forecasts.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了一个固定的数据集，可以用来公平地评估多个算法，我们需要一种方法来评估不同的预测结果。
- en: Choosing an evaluation metric
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 选择评估指标
- en: 'In machine learning, we have a handful of metrics that can be used to measure
    continuous outputs, mainly **Mean Absolute Error** and **Mean Squared Error**.
    But in the time series forecasting realm, there are scores of metrics with no
    real consensus on which ones to use. One of the reasons for this overwhelming
    number of metrics is that no one metric measures every characteristic of a forecast.
    Therefore, we have a whole chapter devoted to this topic (*Chapter 19*, *Evaluating
    Forecast Errors—A Survey of Forecast Metrics*). For now, we will just review a
    few metrics, all of which we are going to use to measure the forecasts. We are
    just going to consider them at face value:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中，我们有一些可以用来衡量连续输出的指标，主要是**平均绝对误差**和**均方误差**。但在时间序列预测领域，有大量的指标，而且没有真正达成共识来决定应该使用哪些指标。造成这种众多指标的原因之一是没有一个指标可以衡量预测的所有特性。因此，我们专门为这个话题编写了整整一章（*第19章*，*评估预测误差——预测指标调查*）。现在，我们只是回顾几个我们将用于衡量预测的指标。我们将按字面意思进行考虑：
- en: '**Mean Absolute Error** (**MAE**): MAE is a very simple metric. It is the average
    of the unsigned (ignoring the sign) error between the forecast at timestep *t*(*f*[t])
    and the observed value at time *t*(*y*[t]). The formula is as follows:'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**平均绝对误差** (**MAE**)：MAE是一个非常简单的指标。它是预测值在时间步* t *（*f*[t]）与观察值在时间*t*（*y*[t]）之间无符号（忽略符号）的误差的平均值。公式如下：'
- en: '![](img/B22389_04_001.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22389_04_001.png)'
- en: Here, *N* is the number of time series, *L* is the length of time series (in
    this case, the length of the test period), and *f* and *y* are the forecast and
    observed values, respectively.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*N*是时间序列的数量，*L*是时间序列的长度（在本例中为测试期的长度），*f*和*y*分别是预测值和观察值。
- en: '**Mean Squared Error** (**MSE**): MSE is the average of the squared error between
    the forecast (*f*[t]) and observed (*y*[t]) values:'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**均方误差** (**MSE**)：MSE是预测值（*f*[t]）和观察值（*y*[t]）之间的平方误差的平均值：'
- en: '![](img/B22389_04_002.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22389_04_002.png)'
- en: '**Mean Absolute Scaled Error** (**MASE**): MASE is slightly more complicated
    than MSE and MAE but gives us a slightly better measure to overcome the scale-dependent
    nature of the previous two measures. If we have multiple time series with different
    average values, MAE and MSE will show higher errors for the high-value time series
    as opposed to the low-valued time series. MASE overcomes this by scaling the errors
    based on the in-sample MAE from the **naïve forecasting method** (which is one
    of the most basic forecasts possible; we will review it later in this chapter).
    Intuitively, MASE gives us the measure of how much better our forecast is as compared
    to the naïve forecast:'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**平均绝对缩放误差** (**MASE**)：MASE比MSE和MAE稍微复杂一些，但它能提供一个稍微更好的度量，克服前两者依赖规模的性质。如果我们有多个时间序列，其平均值不同，MAE和MSE会对高值时间序列显示较高的误差，而低值时间序列则相对较低。MASE通过基于**朴素预测方法**（这是最基础的一种预测方法，我们将在本章稍后进行回顾）中的样本内MAE来缩放误差，从而克服了这一点。直观地说，MASE给出了我们的预测比朴素预测更好的程度：'
- en: '![](img/B22389_04_003.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22389_04_003.png)'
- en: '**Forecast Bias** (**FB**): This is a metric with slightly different aspects
    from the other metrics we’ve seen. While the other metrics help assess the *correctness*
    of the forecast, irrespective of the direction of the error, forecast bias lets
    us understand the overall *bias* in the model. Forecast bias is a metric that
    helps us understand whether the forecast is continuously over- or under-forecasting.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预测偏差** (**FB**)：这是一个与我们看到的其他指标略有不同的度量。虽然其他指标有助于评估预测的*正确性*，不考虑误差的方向，预测偏差让我们了解模型的整体*偏差*。预测偏差有助于我们理解预测是否持续存在过度预测或不足预测的情况。'
- en: 'We calculate forecast bias as the difference between the sum of the forecast
    and the sum of the observed values, expressed as a percentage over the sum of
    all actuals:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过预测值总和与观察值总和之间的差异来计算预测偏差，并表示为所有实际值总和的百分比：
- en: '![](img/B22389_04_004.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22389_04_004.png)'
- en: Now, our test harness is ready. We also know how to evaluate and compare forecasts
    that have been generated from different models on a single, fixed holdout dataset
    with a set of predetermined metrics. Now, it’s time to start forecasting.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们的测试工具已经准备好了。我们也知道如何评估和比较在单一固定的保留数据集上，通过不同模型生成的预测结果，并使用一组预定的指标进行比较。现在，到了开始进行预测的时候了。
- en: Generating strong baseline forecasts
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成强基准预测
- en: '**Time series forecasting** has been around since the early 1920s, and through
    the years, many brilliant people have come up with different models, some statistical
    and some heuristic-based. I refer to them collectively as **classical statistical
    models** or **econometrics models**, although they are not strictly statistical/econometric.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**时间序列预测**自1920年代初期以来就已存在，并且多年来，许多杰出的人物提出了不同的模型，既有统计模型，也有启发式模型。我将它们统称为**经典统计模型**或**计量经济学模型**，尽管它们并不完全是统计/计量经济学模型。'
- en: In this section, we are going to review a few such models that can form really
    strong baselines when we want to try modern techniques in forecasting. As an exercise,
    we are going to use an excellent open source library for time series forecasting—NIXTLA
    ([https://github.com/Nixtla](https://github.com/Nixtla)). The `02-Baseline_Forecasts_using_NIXTLA.ipynb`
    notebook contains the code for this section so that you can follow along.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们将回顾一些模型，这些模型在我们尝试现代预测技术时可以作为强有力的基准。作为练习，我们将使用一个出色的开源时间序列预测库——NIXTLA（[https://github.com/Nixtla](https://github.com/Nixtla)）。`02-Baseline_Forecasts_using_NIXTLA.ipynb`
    笔记本包含了本部分的代码，方便你跟随学习。
- en: Before we start looking at forecasting techniques, let’s quickly understand
    how to use the NIXTLA library to generate forecasts. We are going to pick one
    consumer from the dataset and try out all the baseline techniques on the validation
    dataset one by one.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始了解预测技术之前，让我们快速了解如何使用 NIXTLA 库来生成预测。我们将从数据集中选择一个消费者，并在验证数据集上逐一尝试所有的基准技术。
- en: 'The first thing we need to do is select the consumer we want using the unique
    ID for each customer, the `LCLid` column (from the expanded form of data), and
    set the timestamp as the index of the DataFrame:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要做的第一件事是使用每个客户的唯一 ID（`LCLid` 列，来自扩展数据）选择我们想要的消费者，并将时间戳设置为 DataFrame 的索引：
- en: '[PRE0]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'NIXTLA has the flexibility to work directly with either pandas or Polars DataFrames.
    By default, NIXTLA looks for three columns:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: NIXTLA 具有灵活性，可以直接与 pandas 或 Polars DataFrame 一起使用。默认情况下，NIXTLA 查找三个列：
- en: '`id_col`: By default, it expects a column `unique_id`. This column uniquely
    identifies the time series. If you only have one time series, add a dummy column
    with the same unique identifier.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`id_col`：默认情况下，它期望一个名为 `unique_id` 的列。这个列唯一标识时间序列。如果你只有一个时间序列，请添加一个具有相同唯一标识符的虚拟列。'
- en: '`time_col`: By default, it expects a column `ds`. This is the column of your
    timestamp.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`time_col`：默认情况下，它期望一个名为 `ds` 的列。这是你的时间戳列。'
- en: '`target_col`: By default, it expects a column `y`. This column is what you
    want NIXTLA to forecast.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`target_col`：默认情况下，它期望一个名为 `y` 的列。这个列是你希望 NIXTLA 进行预测的目标。'
- en: 'This is very convenient as there is no need for further manipulation to go
    from data to modeling. NIXTLA follows the scikit-learn style with `.fit()` and
    `.predict()` and also adopts a `.forecast()` method, which is a memory-efficient
    method that doesn’t store the partial model outputs, whereas the scikit-learn
    interface stores the fitted models:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这非常方便，因为无需进一步操作即可从数据到建模。NIXTLA 遵循 scikit-learn 风格，使用 `.fit()` 和 `.predict()`，并且还采用了
    `.forecast()` 方法，这是一个内存高效的方法，不会存储部分模型输出，而 scikit-learn 接口会存储拟合的模型：
- en: '[PRE1]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'NIXTLA also has a `.forecast()` method, which is a memory-efficient method
    that doesn’t store the partial model outputs, whereas the scikit-learn interface
    stores the fitted models:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: NIXTLA 还提供了 `.forecast()` 方法，这是一个内存高效的方法，不会存储部分模型输出，而 scikit-learn 接口会存储拟合的模型：
- en: '[PRE2]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: When we call `.predict` **or** `.forecast`, we have to tell the model how long
    into the future we have to predict. This is called the horizon of the forecast.
    In our case, we need to predict our test period, which we can easily do by just
    taking the length of the `ts_test` array.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们调用 `.predict` **或** `.forecast` 时，我们必须告诉模型需要预测多久以后的数据。这被称为预测的时间范围（horizon）。在我们的案例中，我们需要预测测试期，我们可以通过获取
    `ts_test` 数组的长度轻松实现这一点。
- en: 'We can also calculate the metrics we discussed earlier in the test harness
    easily using NIXTLA’s classes. For added flexibility, we can loop through a list
    of metrics to get multiple measurements for each forecast:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用 NIXTLA 的类轻松计算之前讨论的测试指标。为了更大的灵活性，我们可以循环遍历一个指标列表，为每个预测获取多个测量值：
- en: '[PRE3]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Notice that, for MASE, the training set is also included.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，对于 MASE，训练集也包括在内。
- en: For ease of experimentation, we have encapsulated all of this into a handy function,
    `evaluate_performance`, in the notebook. This returns the predictions and the
    calculated metrics in a DataFrame.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 为了方便实验，我们将所有这些内容封装到笔记本中的一个便捷函数`evaluate_performance`中。该函数返回预测结果和计算的指标，格式为DataFrame。
- en: Now, let’s start looking at a few very simple methods of forecasting.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们开始看看一些非常简单的预测方法。
- en: Naïve forecast
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 简单预测
- en: 'A naïve forecast is as simple as you can get. The forecast is just the last/most
    recent observation in a time series. If the latest observation in a time series
    is 10, then the forecast for all future timesteps is 10\. This can be implemented
    as follows using the `Naive` class in NIXTLA:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 简单预测是最简单的预测方法。它的预测结果就是时间序列中最后一个/最新的观测值。如果时间序列中最新的观测值是10，那么未来所有时间点的预测值都是10。我们可以使用NIXTLA中的`Naive`类来实现这一点：
- en: '[PRE4]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Once we have initialized the model, we can call our helpful `evaluate_performance`
    function in the notebook to run and record the forecast and metrics.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们初始化了模型，就可以调用笔记本中的`evaluate_performance`函数，运行并记录预测结果和指标。
- en: 'Let’s visualize the forecast we just generated:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们可视化一下我们刚刚生成的预测结果：
- en: '![](img/B22389_04_01.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22389_04_01.png)'
- en: 'Figure 4.1: Naïve forecast'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.1：简单预测
- en: Here, we can see that the forecast is a straight line and completely ignores
    any pattern in the series. This is by far the simplest way to forecast, hence
    why it is naïve. Now, let’s look at another simple method.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到预测是一条直线，完全忽略了序列中的任何模式。这是迄今为止最简单的预测方法，因此它被称为简单预测。现在，让我们看另一种简单的方法。
- en: Moving average forecast
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 移动平均预测
- en: 'While a naïve forecast memorizes the most recent past, it also memorizes the
    noise at any timestep. **A moving average forecast** is another simple method
    that tries to overcome the pure memorization of the naïve method. Instead of taking
    the latest observation, it takes the mean of the latest *n* steps as the forecast.
    Moving average is not one of the models present in NIXTLA, but we have implemented
    a NIXTLA-compatible model in this book’s GitHub repository in the `Chapter04`
    folder:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然简单预测记住了最新的过去，但它也记住了每个时间步的噪音。**移动平均预测**是另一种简单的方法，它试图克服简单预测方法的纯粹记忆化。它不是采用最新的观测值，而是采用最近*n*步的均值作为预测结果。移动平均并不是NIXTLA中现有的模型之一，但我们在本书的GitHub仓库中的`Chapter04`文件夹实现了一个与NIXTLA兼容的模型：
- en: '[PRE5]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Let’s look at the forecast we generated:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们生成的预测结果：
- en: '![Figure 4.2 – Moving average forecast ](img/B22389_04_02.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.2 – 移动平均预测](img/B22389_04_02.png)'
- en: 'Figure 4.2: Moving average forecast'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.2：移动平均预测
- en: This forecast is also almost a straight line. Now, let’s look at another simple
    method, but one that considers seasonality as well.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这个预测几乎是一条直线。现在，让我们看另一种简单的方法，但它同时考虑了季节性因素。
- en: Seasonal naive forecast
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 季节性简单预测
- en: '**A seasonal naive forecast** is a twist on the simple naive method. In the
    naive method, we took the last observation (Y[t-1]), whereas in seasonal naïve,
    we take the Y[t-k] observation. So, we look back *k* steps for each forecast.
    This enables the algorithm to mimic the last seasonality cycle. For instance,
    if we set `k=48*7`, we will be able to mimic the latest seasonal weekly cycle.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '**季节性简单预测**是在简单的简单预测方法基础上的一种变体。在简单预测方法中，我们采用了最后一个观测值（Y[t-1]），而在季节性简单预测中，我们采用了Y[t-k]的观测值。所以，我们对于每个预测回顾了*k*步。这使得算法能够模拟上一季的季节性周期。例如，如果我们设置`k=48*7`，我们将能够模拟最新的季节性周周期。'
- en: 'This method is implemented in NIXTLA and we can use it like so:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法已在NIXTLA中实现，我们可以像这样使用它：
- en: '[PRE6]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Let’s see what this forecast looks like:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这个预测结果是什么样子的：
- en: '![](img/B22389_04_03.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22389_04_03.png)'
- en: 'Figure 4.3: Seasonal naïve forecast'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.3：季节性简单预测
- en: Here, we can see that the forecast is trying to mimic the seasonality pattern.
    However, it’s not very accurate because it is blindly following the last seasonal
    cycle.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到预测正在尝试模拟季节性模式。然而，由于它盲目地遵循了上一个季节性周期，它并不非常准确。
- en: Now that we’ve looked at a few simple methods, let’s look at a few statistical
    models.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了几种简单方法，让我们看看一些统计模型。
- en: Exponential smoothing
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 指数平滑
- en: '**Exponential smoothing** is one of the most popular methods for generating
    forecasts. It has been around since the late 1950s and has proved its mettle and
    stood the test of time. There are a few different variants of ETS—**single exponential
    smoothing**, **double exponential smoothing**, **Holt-Winters’ seasonal smoothing**,
    and so on. But all of them have one key idea that has been used in different ways.
    In the naïve method, we were just using the latest observation, which is like
    saying only the most recent data point in history matters and no data point before
    that matters. On the other hand, the moving average method considers the last
    n observations to be equally important and takes the mean of them.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '**指数平滑**是生成预测最流行的方法之一。自20世纪50年代末以来，它一直存在，并证明了其可靠性，经受住了时间的考验。ETS有几种不同的变体——**单一指数平滑**、**双重指数平滑**、**霍尔特-温特季节性平滑**等等。但它们都有一个关键的思想，这些思想以不同的方式被使用。在朴素方法中，我们只是使用了最新的观察数据，这就像是说只有最新的历史数据点才重要，之前的数据点不重要。另一方面，移动平均法认为最后n个观察值同样重要，并取它们的平均值。'
- en: 'ETS combines both these intuitions and says that all the history is important,
    but the recent history is more important. Therefore, the forecast is generated
    using a weighted average where the weights decrease exponentially as we move farther
    into the history:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: ETS结合了这两种思路，并表示所有历史数据都很重要，但最近的历史数据更为重要。因此，预测是通过加权平均值生成的，其中权重随着我们向历史的深入而指数递减：
- en: '![](img/B22389_04_005.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22389_04_005.png)'
- en: Here, ![](img/B22389_04_006.png) is the smoothing parameter that lets us decide
    how fast or slow the weights should decay, *y*[t] is the actuals at timestep *t*,
    and *f*[t] is the forecast at timestep *t*.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，![](img/B22389_04_006.png)是平滑参数，决定了权重衰减的速度，*y*[t]是时间步长*t*时的实际值，*f*[t]是时间步长*t*时的预测值。
- en: '**Simple exponential smoothing** (**SES**) is when you simply apply this smoothing
    procedure to the history. This is more suited for time series that have no trends
    or seasonality, and the forecast is going to be a flat line. The forecast is generated
    using the following formula:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '**简单指数平滑**（**SES**）是在历史数据上直接应用此平滑程序。这更适用于没有趋势或季节性的时间序列，且预测将是平坦的。预测是使用以下公式生成的：'
- en: '![](img/B22389_04_04.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22389_04_04.png)'
- en: '**Double exponential smoothing** (**DES**) extends the smoothing idea to model
    trends as well. It has two smoothing equations—one for the level and the other
    for the trend. Once you have the estimate of the level and trend, you can combine
    them. This forecast is not necessarily flat because the estimated trend is used
    to extrapolate it into the future. The forecast is generated according to the
    following formula:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '**双指数平滑**（**DES**）将平滑思想扩展到趋势建模。它有两个平滑方程——一个用于水平，另一个用于趋势。一旦你得到了水平和趋势的估计值，就可以将它们结合起来。这个预测不一定是平坦的，因为估计的趋势被用来将其外推到未来。预测是根据以下公式生成的：'
- en: '![](img/B22389_04_05.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22389_04_05.png)'
- en: First, we estimate the level (*l*[t]) using the *Level Equation* with the available
    observations. Then, we estimate the trend using the *Trend Equation*. Finally,
    to get the forecast, we combine *l*[t] and *b*[t] using the *Forecast Equation*.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们使用*水平方程*结合可用的观察数据来估计水平(*l*[t])。然后，我们使用*趋势方程*来估计趋势。最后，为了得到预测，我们将*l*[t]和*b*[t]结合在一起，使用*预测方程*。
- en: Researchers have found empirical evidence that this kind of constant extrapolation
    can result in over-forecasts over the long-term forecast. This is because, in
    the real world, time series data doesn’t increase at a constant rate forever.
    Motivated by this, an addition to this has also been introduced that dampens the
    trend by a factor of ![](img/B22389_04_007.png), such that when ![](img/B22389_04_008.png),
    there is no damping, and it is identical to DES.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 研究人员发现，经验证据表明，这种常数外推方法可能会导致长期预测中的过度预测。这是因为，在现实世界中，时间序列数据不会永远以恒定的速度增长。受到这一点的启发，已引入了一种附加方法，通过一个系数![](img/B22389_04_007.png)来减缓趋势，从而在![](img/B22389_04_008.png)时没有衰减，它与DES完全相同。
- en: '**Triple exponential smoothing** or **Holt-Winters’** (**HW**) takes this one
    step forward by including another smoothing term to model the seasonality. This
    has three parameters ( ![](img/B22389_04_009.png), ![](img/B22389_04_010.png),
    ![](img/B22389_04_011.png)) for the smoothing and uses a seasonality period (*m*)
    as input parameters. You can also choose between additive or multiplicative seasonality.
    The forecast equations for the additive model are as follows:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '**三重指数平滑**或**Holt-Winters**（**HW**）通过包括另一个平滑项来建模季节性，进一步发展了这一方法。该方法有三个平滑参数（
    ![](img/B22389_04_009.png)、 ![](img/B22389_04_010.png)、 ![](img/B22389_04_011.png)），并使用季节性周期（*m*）作为输入参数。你还可以选择加法季节性或乘法季节性。加法模型的预测方程如下：'
- en: '![](img/B22389_04_06.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22389_04_06.png)'
- en: These formulae are also used like in the double exponential case. Instead of
    estimating level and trend, we estimate level, trend, and seasonality separately.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 这些公式的使用与双指数平滑类似。不同的是，我们不仅估计水平和趋势，还会分别估计水平、趋势和季节性。
- en: 'The family of ETS methods is not limited to the three that we just discussed.
    A way to think about the different models is in terms of the trend and seasonal
    components of these models. The trend can either be no trend, additive, or additive
    damped. The seasonality can be no seasonality, additive, or multiplicative. Every
    combination of these parameters is a different technique in the family, as shown
    in the following table:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: ETS 方法家族不仅限于我们刚刚讨论的三种方法。思考这些不同模型的一种方式是通过这些模型的趋势和季节性组件来进行分析。趋势可以是无趋势、加法趋势或加法衰减趋势。季节性可以是无季节性、加法季节性或乘法季节性。这些参数的每种组合在该家族中都是一种不同的技术，如下表所示：
- en: '| **Trend component** | **Seasonal component** |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| **趋势组件** | **季节性组件** |'
- en: '|  | **N (None)** | **A (Additive)** | **M (Multiplicative)** |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '|  | **N（无）** | **A（加法）** | **M（乘法）** |'
- en: '| **N (None)** | Simple Exponential Smoothing | - | - |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| **N（无）** | 简单指数平滑 | - | - |'
- en: '| **A (Additive)** | Double Exponential Smoothing | Additive Holt-Winters |
    Multiplicative Holt-Winters |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| **A（加法）** | 双指数平滑 | 加法 Holt-Winters | 乘法 Holt-Winters |'
- en: '| **Ad (Additive damped)** | Damped Double Exponential Smoothing | - | Damped
    Holt-Winters |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| **Ad（加法衰减）** | 衰减双指数平滑 | - | 衰减 Holt-Winters |'
- en: 'Table 4.1: Exponential smoothing family'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4.1：指数平滑家族
- en: NIXTLA has an entire family of ETS methods.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: NIXTLA 拥有完整的 ETS 方法家族。
- en: 'Let’s see how we can initialize the ETS model in NIXTLA:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何在 NIXTLA 中初始化 ETS 模型：
- en: '[PRE7]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Here, `error_type = ''A''` refers to additive error. The user has the option
    for either additive error or multiplicative error, which could be called using
    `error_type = ''M''`. NIXTLA models have an option to use `AutoETS()`. This model
    will automatically choose which exponential smoothing model is the best option:
    simple exponential smoothing, double exponential smoothing (Holt’s method), or
    triple exponential smoothing (Holt-Winters method). It will also choose which
    parameters and error types are best for each individual time series. Refer to
    the GitHub notebooks for examples of how to use `AutoETS()`.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`error_type = 'A'` 表示加法误差。用户可以选择加法误差或乘法误差，后者可以通过 `error_type = 'M'` 来调用。NIXTLA
    模型提供了使用 `AutoETS()` 的选项。该模型会自动选择最合适的指数平滑模型：简单指数平滑、双指数平滑（Holt 方法）或三重指数平滑（Holt-Winters
    方法）。它还会为每个单独的时间序列选择最佳的参数和误差类型。有关如何使用 `AutoETS()` 的示例，请参考 GitHub 笔记本。
- en: 'Let’s see what the forecast using ETS looks like in *Figure 4.4*:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下使用 ETS 进行预测的结果，在*图 4.4*中：
- en: '![](img/B22389_04_07.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22389_04_07.png)'
- en: 'Figure 4.4: Exponential smoothing forecast'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.4：指数平滑预测
- en: The forecast has captured the seasonality but has failed to capture the peaks.
    But we can see the improvement in MAE already.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 该预测已捕捉到季节性，但未能捕捉到峰值。但我们已经可以看到 MAE 的改善。
- en: Now, let’s look at one of the most popular forecasting methods out there.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来看看目前最受欢迎的预测方法之一。
- en: AutoRegressive Integrated Moving Average (ARIMA)
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自回归积分滑动平均（ARIMA）
- en: '**ARIMA** models are the other class of methods that, like ETS, have stood
    the test of time and are one of the most popular classical methods of forecasting.
    The ETS family of methods is modeled around trend and seasonality, while ARIMA
    relies on **autocorrelation** (the correlation of *y*[t] with *y*[t][-1], *y*[t][-2],
    and so on).'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '**ARIMA** 模型是另一类方法，像 ETS 一样，它经受住了时间的考验，是最受欢迎的经典预测方法之一。ETS 方法家族以趋势和季节性为基础建模，而
    ARIMA 则依赖于 **自相关**（*y*[t] 与 *y*[t][-1]、*y*[t][-2] 等的相关性）。'
- en: 'The simplest in the family are the *AR* (*p*) models, which use **linear regression**
    with *p* previous timesteps or, in other words, *p* lags. Mathematically, it can
    be written as follows:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 家族中最简单的模型是*AR*（*p*）模型，它使用**线性回归**与*p*个过去的时间步长，或者换句话说，就是*p*个滞后期。数学上可以写作：
- en: '![](img/B22389_04_012.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22389_04_012.png)'
- en: Here, *c* is the intercept, and ![](img/B22389_04_013.png) is the noise or error
    at timestep *t*.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，*c*是截距，且 ![](img/B22389_04_013.png) 是时间步长 *t* 时的噪声或误差。
- en: 'The next in the family are *MA* (*q*) models, in which, instead of past observed
    values, we use the past *q* errors in the forecast (which is assumed to be pure
    white noise) to come up with a forecast:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 家族中的下一个模型是*MA*（*q*）模型，在这种模型中，我们使用过去的* q *个误差（假设为纯白噪声）而不是过去观察到的值来进行预测：
- en: '![](img/B22389_04_014.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22389_04_014.png)'
- en: Here, ![](img/B22389_04_015.png) is white noise and *c* is the intercept.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，![](img/B22389_04_015.png) 是白噪声，*c*是截距。
- en: This is not typically used on its own but in conjunction with *AR* (*p*) models,
    which makes the next one on our list *ARMA* (*p*, *q*) models. ARMA (AutoRegressive
    Moving Average) models are defined as *y*[t] = *AR* (*p*) + *MA* (*q*).
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 这种模型通常不会单独使用，而是与*AR*（*p*）模型结合使用，因此接下来我们要讨论的就是*ARMA*（*p*，*q*）模型。ARMA（自回归滑动平均）模型定义为
    *y*[t] = *AR*（*p*）+ *MA*（*q*）。
- en: In all the ARIMA models, there is one underlying assumption—the *time series
    is stationary* (we talked about stationarity in *Chapter 1*, *Introducing Time
    Series*, and will elaborate on this in *Chapter 6*, *Feature Engineering for Time
    Series Forecasting*). There are many ways to make the series stationary but taking
    the difference of successive values is one such technique. This is known as **differencing**.
    Sometimes, we need to do differencing once, while other times, we have to perform
    successive differencing before the time series becomes stationary. The number
    of times we do the differencing operation is called the *order of differencing*.
    The I in ARIMA, and the final piece of the puzzle, stands for *Integrated*. It
    defines the order of differencing we need to do before the series becomes stationary
    and is denoted by *d*.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有的ARIMA模型中，有一个基本假设——*时间序列是平稳的*（我们在*第1章*《时间序列简介》中讨论过平稳性，并将在*第6章*《时间序列预测特征工程》中进一步阐述）。有许多方法可以使序列变得平稳，而对连续值进行差分就是其中一种技术。这被称为**差分**。有时，我们只需要进行一次差分，而其他时候，则必须进行多次差分，直到时间序列变为平稳。我们执行差分操作的次数被称为*差分阶数*。ARIMA中的I，作为谜题的最后一部分，代表*集成*。它定义了在时间序列变为平稳之前需要做的差分阶数，记作*d*。
- en: So, the complete *ARIMA* (*p*, *d*, *q*) model says that we do the *d*^(th)
    order of differencing and then consider the last *p* terms in an autoregressive
    manner, and then include the last *q* moving average terms to come up with the
    forecast.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，完整的*ARIMA*（*p*，*d*，*q*）模型表示我们进行*d*阶差分后，考虑自回归方式的最后*p*项，再包括最后*q*个滑动平均项来做出预测。
- en: The ARIMA models we have discussed so far only handle non-seasonal time series.
    However, using the same concepts we discussed, but on a seasonal cycle, we get
    **seasonal ARIMA**. *p*, *d*, and *q* are slightly tweaked so that they work on
    the seasonal period, *m*. To differentiate them from the normal *p*, *d*, and
    *q*, we call the seasonal values *P*, *D*, and *Q*. For instance, if *p* means
    taking the last *p* lags, *P* means taking the last *P* seasonal lags. If *p*[1]
    is *y*[t][-1], *P*[1] would be *y*[t][-m]. Similarly, *D* means the order of seasonal
    differencing.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我们迄今讨论的ARIMA模型仅适用于非季节性时间序列。然而，使用我们讨论过的相同概念，只不过应用于季节性周期，我们就得到了**季节性ARIMA**。*p*，*d*和*q*会略微调整，以便它们适应季节周期
    *m*。为了与普通的*p*，*d*和*q*区分开来，我们将季节性的值称为*P*，*D*和*Q*。例如，如果*p*表示取最后*p*个滞后期，*P*则表示取最后*P*个季节性滞后期。如果*p*[1]是*y*[t][-1]，那么*P*[1]将是*y*[t][-m]。类似地，*D*表示季节性差分的阶数。
- en: Picking the right *p*, *d*, and *q* and *P*, *D*, and *Q* values is not very
    intuitive, and we will have to resort to statistical tests to find them. However,
    this becomes a bit impractical when you are forecasting many time series. An automatic
    way of iterating through the different parameters and finding the best *p*, *d*,
    and *q*, and *P*, *D*, and *Q* values for the data is called **AutoARIMA**. In
    Python, NIXTLA has implemented this method, `AutoARIMA()`. NIXTLA also has a normal
    ARIMA implementation as well, which is much faster but requires *p*, *d*, and
    *q* to be entered manually.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 选择合适的 *p*、*d* 和 *q* 以及 *P*、*D* 和 *Q* 值并不是很直观，我们需要借助统计测试来确定它们。然而，当你需要预测多个时间序列时，这种方法就显得不太实际了。一种自动化的方式是通过不同参数的迭代来找到最佳的
    *p*、*d* 和 *q*，以及 *P*、*D* 和 *Q* 值，这种方法被称为 **AutoARIMA**。在 Python 中，NIXTLA 实现了这个方法，即
    `AutoARIMA()`。NIXTLA 还提供了普通的 ARIMA 实现，虽然它速度更快，但需要手动输入 *p*、*d* 和 *q* 值。
- en: '**Practical considerations**:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '**实际考虑事项**：'
- en: Although ARIMA and AutoARIMA can give you good-performing models in many cases,
    they can be quite slow when you have long seasonal periods and a long time series.
    In our case, where we have almost 27K observations in the history, ARIMA becomes
    very slow and a memory hog. Even when subsetting the data, a single AutoARIMA
    fit takes around 60 minutes. Letting go of the seasonal parameters brings down
    the runtime drastically, but for a seasonal time series such as energy consumption,
    it doesn’t make sense. AutoARIMA includes many such fits to identify the best
    parameters and, therefore, becomes impractical for long time series datasets.
    Almost all the implementations in the Python ecosystem suffer from this drawback.
    NIXLTA claims to have the fastest and most accurate version of AutoARIMA, faster
    than the original R method as well.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 ARIMA 和 AutoARIMA 在许多情况下可以提供表现良好的模型，但当你面对较长的季节性周期和长时间序列时，它们的计算速度可能会非常慢。在我们的案例中，历史数据接近
    27K 个观测值，ARIMA 变得非常缓慢，并且占用大量内存。即使是对数据进行子集化处理，单次 AutoARIMA 拟合也需要大约 60 分钟。放弃季节性参数可以显著降低运行时间，但对于像能源消耗这样的季节性时间序列来说，这样做是没有意义的。AutoARIMA
    包括了许多此类拟合过程来识别最佳参数，因此对于长时间序列数据集，它变得不切实际。Python 生态系统中的几乎所有实现都存在这个缺陷。NIXTLA 声称拥有比原始
    R 方法更快、更准确的 AutoARIMA 版本。
- en: 'Let’s see how we can apply `ARIMA` and `AutoARIMA` using NIXTLA:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何使用 NIXTLA 应用 `ARIMA` 和 `AutoARIMA`：
- en: '[PRE8]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: For the entire list of parameters for `AutoARIMA`, head over to the NIXTLA documentation
    at [https://nixtlaverse.nixtla.io/statsforecast/docs/models/autoarima.html](https://nixtlaverse.nixtla.io/statsforecast/docs/models/autoarima.html).
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看 `AutoARIMA` 所有参数的完整列表，请访问 NIXTLA 文档 [https://nixtlaverse.nixtla.io/statsforecast/docs/models/autoarima.html](https://nixtlaverse.nixtla.io/statsforecast/docs/models/autoarima.html)。
- en: 'Let’s see what the ETS and ARIMA forecasts look like for the households we
    were experimenting with:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们实验的家庭在 ETS 和 ARIMA 预测下的结果：
- en: '![](img/B22389_04_08.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22389_04_08.png)'
- en: 'Figure 4.5: ETS and ARIMA forecasts'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.5：ETS 和 ARIMA 预测
- en: With NIXTLA, both ETS and ARIMA have done a good job of capturing both the seasonality
    and the peaks. The resulting MAE scores are also very similar, with 0.191 and
    0.203, respectively. Now, let’s look at another method—the Theta forecast.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 NIXTLA，ETS 和 ARIMA 都很好地捕捉了季节性和峰值。由此产生的 MAE 分数也非常相似，分别为 0.191 和 0.203。现在，让我们看一下另一种方法——Theta
    预测。
- en: Theta forecast
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Theta 预测
- en: The **Theta forecast** was the top-performing submission in the M3 forecasting
    competition that was held in 2002\. The method relies on a parameter, ![](img/B22389_04_016.png),
    that amplifies or smooths the local curvature of a time series, depending on the
    value chosen. Using ![](img/B22389_04_016.png), we smooth or amplify the original
    time series. These smoothed lines are called **Theta lines**. V. Assimakopoulos
    and K. Nikolopoulos proposed this method as a decomposition approach to forecasting.
    Although, in theory, any number of Theta lines can be used, the originally proposed
    method used two Theta lines, ![](img/B22389_04_018.png) and ![](img/B22389_04_019.png),
    and took an average of the forecast of the two Theta lines as the final forecast.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '**Theta 预测** 是 2002 年 M3 预测竞赛中表现最好的提交方法。该方法依赖于一个参数，![](img/B22389_04_016.png)，根据所选值的不同，它会放大或平滑时间序列的局部曲率。使用
    ![](img/B22389_04_016.png)，我们可以平滑或放大原始时间序列。这些平滑后的线条被称为 **Theta 线**。V. Assimakopoulos
    和 K. Nikolopoulos 提出了这种方法，作为一种分解方法来进行预测。尽管理论上可以使用任意数量的 Theta 线，最初提出的方法使用了两条 Theta
    线，![](img/B22389_04_018.png) 和 ![](img/B22389_04_019.png)，并取这两条 Theta 线的预测平均值作为最终预测值。'
- en: 'The M competitions are forecasting competitions organized by Spyros Makridakis,
    a leading forecasting researcher. They typically curate a dataset of time series,
    lay down the metrics with which the forecasts will be evaluated, and open these
    competitions to researchers all around the world to get the best forecast possible.
    These competitions are considered to be some of the biggest and most popular time
    series forecasting competitions in the world. At the time of writing, six such
    competitions have already been completed. To learn more about the latest competition,
    visit this website: [https://mofc.unic.ac.cy/the-m6-competition/](https://mofc.unic.ac.cy/the-m6-competition/).'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: M竞赛是由领先的预测研究人员Spyros Makridakis组织的预测竞赛。它们通常会策划一个时间序列数据集，设定用来评估预测结果的指标，并向全球的研究人员开放，目的是获得最好的预测结果。这些竞赛被认为是世界上最大和最受欢迎的时间序列预测竞赛。截至本文写作时，已经完成了六次此类竞赛。要了解最新竞赛的更多信息，请访问这个网站：[https://mofc.unic.ac.cy/the-m6-competition/](https://mofc.unic.ac.cy/the-m6-competition/)。
- en: 'In 2002, Rob Hyndman et al. simplified the Theta method and showed that we
    can use ETS with a drift term to get equivalent results to the original Theta
    method, which is what is adapted into most of the implementations of the method
    that exist today. The main steps that are involved in the Theta forecast (which
    is implemented in NIXTLA) are as follows:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 2002年，Rob Hyndman等人简化了Theta方法，并展示了我们可以使用带有漂移项的ETS来得到与原始Theta方法等效的结果，这也是今天大多数Theta方法实现所采用的方式。Theta预测的主要步骤（在NIXTLA中实现）如下：
- en: '**Deseasonalization**: Apply a classical multiplicative decomposition to remove
    the seasonal component from the time series (if it exists). This focuses the analysis
    on the underlying trend and cyclical components. Deseasonalization is done using
    `statsmodels.tsa.seasonal.seasonal_decompose`. This step creates a new deseasonalized
    time series.'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**去季节化**：对时间序列应用经典的乘法分解，以去除季节性成分（如果存在）。这将分析集中在潜在的趋势和周期性成分上。去季节化通过`statsmodels.tsa.seasonal.seasonal_decompose`来完成。此步骤创建了一个新的去季节化时间序列。'
- en: '**Theta Coefficients Application**: Decompose the deseasonalized series into
    two “Theta” lines using coefficients ![](img/B22389_04_020.png) and ![](img/B22389_04_021.png).
    These coefficients modify the second difference of the time series to either dampen
    (![](img/B22389_04_022.png) or accentuate ![](img/B22389_04_023.png) local fluctuations.'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Theta系数应用**：使用系数 ![](img/B22389_04_020.png) 和 ![](img/B22389_04_021.png)
    将去季节化的时间序列分解为两条“Theta”线。这些系数修改时间序列的第二差分，以减弱 (![](img/B22389_04_022.png)) 或强调 (![](img/B22389_04_023.png))
    局部波动。'
- en: '**Extrapolation of Theta Lines**: Treat each Theta line as a separate series
    and forecast them into the future. This is done using linear regression for the
    Theta line where ![](img/B22389_04_024.png), producing a straight line, and simple
    exponential smoothing for the Theta line where ![](img/B22389_04_025.png).'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Theta线的外推**：将每条Theta线视为一个独立的序列，并将其预测到未来。这是通过对Theta线应用线性回归（其中 ![](img/B22389_04_024.png)）得到一条直线，对Theta线应用简单指数平滑（其中
    ![](img/B22389_04_025.png)）完成的。'
- en: '**Recomposition**: Combine the forecasts from the two Theta lines. The original
    method uses equal weighting for both lines, which integrates the long-term trend
    and short-term movements effectively.'
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**重组**：将两个Theta线的预测结果结合起来。原始方法对这两条线采用相等的权重，有效地整合了长期趋势和短期波动。'
- en: '**Reseasonalize**: If the data was deseasonalized in the beginning.'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**重新季节化**：如果数据在开始时已经去季节化，则进行重新季节化。'
- en: 'NIXTLA has very different variations of the Theta method. More information
    on the specifics of the NIXTLA implementation can be found here: [https://nixtlaverse.nixtla.io/statsforecast/docs/models/autotheta.html](https://nixtlaverse.nixtla.io/statsforecast/docs/models/autotheta.html).'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: NIXTLA有许多不同的Theta方法变体。有关NIXTLA实现的详细信息，请访问：[https://nixtlaverse.nixtla.io/statsforecast/docs/models/autotheta.html](https://nixtlaverse.nixtla.io/statsforecast/docs/models/autotheta.html)。
- en: 'Let’s see how we can use it practically:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何在实际中使用它：
- en: '[PRE9]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The key parameters here are as follows: `season_length` and `decomposition_type`.
    These parameters are used for the initial seasonal decomposition. If left empty,
    the implementation automatically tests for seasonality and deseasonalizes the
    time series automatically using multiplicative decomposition. It is recommended
    to set these parameters with our domain knowledge if we know them. The decomposition
    type can be multiplicative (default) or additive.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的关键参数如下：`season_length`和`decomposition_type`。这些参数用于初步季节分解。如果留空，系统会自动测试季节性并使用乘法分解自动去除季节性。若我们知道这些参数的值，建议使用我们的领域知识进行设置。分解类型可以是乘法（默认）或加法。
- en: 'Let’s visualize the forecast we just generated using the Theta forecast:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用Theta预测法可视化我们刚刚生成的预测：
- en: '![](img/B22389_04_09.png)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22389_04_09.png)'
- en: 'Figure 4.6: The Theta forecast'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.6：Theta预测
- en: '**Reference check**:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '**参考检查**：'
- en: The research paper in which V. Assimakopoulos and K. Nikolopoulos proposed the
    Theta method is cited as reference *1* in the *References* section, while subsequent
    simplification by Rob Hyndman is cited as reference *2*.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: V. Assimakopoulos和K. Nikolopoulos提出Theta方法的研究论文在*参考文献*部分被引用为参考文献*1*，而Rob Hyndman的后续简化方法则被引用为参考文献*2*。
- en: The seasonality pattern is captured, but it’s not hitting the peaks. Let’s look
    at another very strong method, TBATS.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 季节性模式已被捕捉，但未能准确达到峰值。让我们看看另一种非常强大的方法——TBATS。
- en: TBATS
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TBATS
- en: Sometimes, a time series has more than one seasonality pattern or a non-integer
    seasonal period, commonly referred to as complex seasonality. An example would
    be an hourly forecast that could have a daily seasonality for the time of day,
    a weekly seasonality for the day of the week, and a yearly seasonality for the
    day of the year. Additionally, most time series models are designed for smaller
    integer seasonal periods, such as monthly (12) or quarterly (4) data, but yearly
    seasonality can pose a problem since a year is 364.25 days. TBATS was meant to
    combat these many challenges that pose problems for many forecasting models. However,
    with any automated approach, at times it is susceptible to poor forecasts.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，时间序列有多个季节性模式或非整数季节周期，通常称为复杂季节性。例如，一个小时预测可能具有每日季节性（与一天中的时间有关）、每周季节性（与一周中的某天有关）以及每年季节性（与年份中的某一天有关）。此外，大多数时间序列模型是为较小的整数季节周期设计的，如每月（12）或每季度（4）数据，但年度季节性可能会带来问题，因为一年有364.25天。TBATS旨在应对这些为许多预测模型带来问题的挑战。然而，任何自动化方法都有可能出现预测不准确的情况。
- en: '**TBATS** stands for:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '**TBATS**代表：'
- en: '**T**rigonometric seasonality'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**T**rigonometric季节性'
- en: '**B**ox-Cox transformation'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**B**ox-Cox变换'
- en: '**A**RMA errors'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**A**RMA误差'
- en: '**T**rend'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**T**rend'
- en: '**S**easonal components'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**S**easonal components'
- en: This model was first introduced by Rob J. Hyndman, Alysha M. De Livera, and
    Ralph D. Snyder in 2011\. There is also another variant of TBATS, referred to
    as BATS, which is without the trigonometric seasonality component. TBATS is from
    the state space model family. In state space forecasting models, the observed
    time series is assumed to be a combination of the underlying state variables and
    a measurement equation that relates the state variables to the observed data.
    The state variables capture the underlying patterns, trends, and relationships
    in the data.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型首次由Rob J. Hyndman、Alysha M. De Livera和Ralph D. Snyder在2011年提出。还有另一种TBATS的变体，称为BATS，去除了三角季节性成分。TBATS属于状态空间模型家族。在状态空间预测模型中，观测到的时间序列被假定为底层状态变量与一个将状态变量与观测数据联系起来的测量方程的组合。状态变量捕捉了数据中的底层模式、趋势和关系。
- en: 'BATS has parameters ![](img/B22389_04_026.png) indicating the Box-Cox parameter,
    damping parameter, ARMA parameters (*p*, *q*) and the seasonal periods (*m*[1],
    *m*[2], …, *m*[t]). Due to its flexibility, the BATS model can be considered a
    family of models encompassing many other models we have seen earlier. For instance:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: BATS有参数 ![](img/B22389_04_026.png)，表示Box-Cox参数、衰减参数、ARMA参数（*p*，*q*）和季节周期（*m*[1]，*m*[2]，…，*m*[t]）。由于其灵活性，BATS模型可以被视为一个模型家族，涵盖了我们之前看到的许多其他模型。例如：
- en: '*BATS*(1, 1, 0, 0, *m*[1]) = Holt-Winters Additive Seasonality'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*BATS*(1, 1, 0, 0, *m*[1]) = Holt-Winters加性季节性'
- en: '*BATS*(1, 1, 0, 0, *m*[2]) = Holt-Winters Additive Double Seasonality'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*BATS*(1, 1, 0, 0, *m*[2]) = Holt-Winters加性双重季节性'
- en: BATS has the flexibility for multiple seasonality; however, it is limited to
    only integer-based seasonal periods, and with multiple seasonalities, it can have
    a large number of states resulting in increasing model complexity. This is what
    TBATS was meant to address.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: BATS 具有多季节性的灵活性；然而，它仅限于基于整数的季节周期，并且在有多个季节性时，可能会有大量状态，导致模型复杂度增加。这正是 TBATS 要解决的问题。
- en: 'For reference, the TBATS parameter space is:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 参考，TBATS 参数空间为：
- en: '![](img/B22389_04_027.png)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22389_04_027.png)'
- en: 'The main advantages of TBATS are as follows:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: TBATS 的主要优点如下：
- en: Works with single, complex, and non-integer seasonality (trigonometric seasonality)
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 适用于单一、复杂和非整数季节性（三角季节性）
- en: Handles nonlinear patterns common in real-world time series (Box-Cox transformation)
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理真实世界时间序列中常见的非线性模式（Box-Cox 变换）
- en: Handles autocorrelation in the residuals (Autoregressive moving average errors)
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理残差中的自相关（自回归移动平均误差）
- en: To better understand the inner workings of TBATS, let’s break down each step.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解 TBATS 的内部工作原理，让我们分解每个步骤。
- en: 'The order in which operations are done (unlike the order in the acronym) using
    TBATS is:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 TBATS 时，操作执行的顺序（与缩写中的顺序不同）是：
- en: Box-Cox transformation
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Box-Cox 变换
- en: Exponentially smoothed trend
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指数平滑趋势
- en: Seasonal decomposition using Fourier series (trigonometric seasonality)
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用傅里叶级数进行季节性分解（三角季节性）
- en: AutoRegressive Moving Average (ARMA)
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 自回归移动平均 (ARMA)
- en: Parameter estimation through a likelihood-based approach
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过基于似然的方法进行参数估计
- en: Box-Cox transformation
  id: totrans-182
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Box-Cox 变换
- en: Box-Cox is a transformation in the family of power transformations.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: Box-Cox 是幂变换家族中的一种变换。
- en: In time series, making data stationary is an important step before forecasting
    (as discussed in *Chapter 1*). Stationarity ensures that our data does not statistically
    change over time, and thus more accurately resembles a probability distribution.
    There are several possible transformations that could be applied. More details
    on various target transformations, including Box-Cox, can be found in *Chapter
    7*.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在时间序列中，使数据平稳是预测前的重要步骤（如*第 1 章*中讨论）。平稳性确保我们的数据不会随时间发生统计变化，从而更准确地类似于概率分布。可以应用几种可能的变换。关于各种目标变换的更多细节，包括
    Box-Cox，可在*第 7 章*中找到。
- en: As a preview, here is a sample output from a Box-Cox transformation. After the
    transformation, our data more closely resembles that of a normal distribution.
    Box-Cox transformations can only be used with positive data, but in practice,
    this is often the case.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 作为预览，这是 Box-Cox 变换的一个输出示例。经过变换后，我们的数据更接近正态分布。Box-Cox 变换只能用于正数数据，但在实践中，这通常是可以的。
- en: '*Figure 4.7* shows an example of how a time series might look before and after
    a Box-Cox transformation.'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 4.7* 显示了时间序列在 Box-Cox 变换前后的示例。'
- en: '![](img/B22389_04_10.png)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22389_04_10.png)'
- en: 'Figure 4.7: Box-Cox transformation'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.7：Box-Cox 变换
- en: Exponentially smoothed trend
  id: totrans-189
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 指数平滑趋势
- en: 'Using **Locally Estimated Scatterplot Smoothing** (**LOESS**), a smoothed trend
    is extracted from the time series:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 **局部估计散点图平滑** (**LOESS**)，从时间序列中提取平滑趋势：
- en: '![](img/B22389_04_028.png)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22389_04_028.png)'
- en: '![](img/B22389_04_029.png)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22389_04_029.png)'
- en: LOESS works by applying a locally weighted, low-degree polynomial regression
    over the data points to create a smooth, flowing line through them. This technique
    is highly effective in capturing local trend variations without assuming a global
    form for the data, which makes it particularly useful for data with varying trends
    or seasonal variations. This is the same LOESS that we used to decompose a time
    series into a trend back in *Chapter 3*.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: LOESS 通过对数据点应用局部加权的低阶多项式回归，在数据点之间创建一条平滑的流线。这种技术在捕捉局部趋势变化方面非常有效，不假设数据的全局形式，这使得它对于具有变化趋势或季节性变化的数据特别有用。这就是我们在*第
    3 章*中用来分解时间序列趋势的 LOESS。
- en: Seasonal decomposition using Fourier series (trigonometric seasonality)
  id: totrans-194
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用傅里叶级数进行季节性分解（三角季节性）
- en: The remaining residuals are then modeled using Fourier terms (discussed in *Chapter
    3*) to decompose the seasonality component.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 然后使用傅里叶项（在*第 3 章*中讨论）对剩余的残差进行建模，以分解季节性成分。
- en: '![](img/B22389_04_030.png)'
  id: totrans-196
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22389_04_030.png)'
- en: '![](img/B22389_04_031.png)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22389_04_031.png)'
- en: '![](img/B22389_04_032.png)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22389_04_032.png)'
- en: '![](img/B22389_04_033.png)'
  id: totrans-199
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22389_04_033.png)'
- en: 'The main advantage of using Fourier to model seasonality is its ability to
    model multiple seasonalities, as well as non-integer seasonality, such as yearly
    seasonality with daily data since there are 364.25 days in a year. Most other
    decomposition methods cannot handle the non-integer period and have to resort
    to rounding to 365, which can fail to identify the true seasonality. An example
    of what a decomposed time series would like using Fourier is below. The observed
    time series in this example is hourly data. Therefore, our seasonal periods are:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 使用傅里叶方法建模季节性的主要优点是能够建模多个季节性，以及非整数季节性，例如使用日数据的年季节性，因为一年有364.25天。大多数其他分解方法无法处理非整数周期，只能将其四舍五入为365，这可能无法识别真实的季节性。以下是使用傅里叶方法分解的时间序列示例。此示例中的观察时间序列是按小时数据。因此，我们的季节性周期为：
- en: '*daily* = *24*'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '*每日* = *24*'
- en: '*weekly* = *24* *** *7* = *168*'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '*每周* = *24* *** *7* = *168*'
- en: Here, you can clearly see the defined seasonal patterns, the trend, and the
    remaining residuals. *Figure 4.8* shows the decomposition of the trend and seasonality,
    after which the residuals are modeled using an ARMA process.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，你可以清楚地看到定义的季节性模式、趋势和剩余残差。*图4.8*展示了趋势和季节性的分解，之后残差通过ARMA过程进行建模。
- en: '![](img/B22389_04_11.png)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22389_04_11.png)'
- en: 'Figure 4.8: Decomposed time series'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.8：分解后的时间序列
- en: ARMA
  id: totrans-206
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ARMA
- en: 'ARMA was discussed earlier as a subset of the ARIMA family:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: ARMA前面已经讨论过，作为ARIMA家族的一个子集：
- en: '![](img/B22389_04_034.png)'
  id: totrans-208
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22389_04_034.png)'
- en: The ARMA model in TBATS is used to model the remaining residuals to capture
    any autocorrelations of the lagged variables. The **autoregressive** (**AR**)
    component captures the correlation between an observation and several lagged observations.
    This deals with the momentum or continuation of the series. The **moving average**
    (**MA**) component models the error terms as a linear combination of errors at
    previous time periods, capturing information not explained by the AR part alone.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: TBATS中的ARMA模型用于建模剩余的残差，以捕捉滞后变量的自相关性。**自回归**（**AR**）组件捕捉观察值与若干滞后观察值之间的相关性。这涉及到序列的动量或延续性。**移动平均**（**MA**）组件将误差项建模为先前时间段的误差的线性组合，捕捉AR部分无法单独解释的信息。
- en: Parameter optimization
  id: totrans-210
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 参数优化
- en: 'To select the optimal parameter space, TBATS will fit several models and automatically
    select the best parameters. A few of the models TBATS fits internally are:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 为了选择最优的参数空间，TBATS会拟合多个模型并自动选择最佳参数。TBATS内部拟合的一些模型包括：
- en: With and without Box-Cox transformation
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有与无Box-Cox变换
- en: With and without trend
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有趋势与无趋势
- en: With and without trend damping
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有趋势与无趋势衰减
- en: Season and non-seasonal model
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 季节性与非季节性模型
- en: ARMA (*p*, *q*) parameters
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ARMA（*p*，*q*）参数
- en: The final model is chosen by which combination of parameters minimizes the **Akaike
    Information Criterion** (**AIC**), and AutoARIMA is used to determine the ARMA
    parameters.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 最终模型是通过选择使**赤池信息准则**（**AIC**）最小化的参数组合来确定的，AutoARIMA用于确定ARMA参数。
- en: As with all forecasting methods, there are benefits and trade-offs to different
    models. While TBATS offers some enhancements on many other models’ shortcomings,
    the trade-off is the need to build many models, which results in longer computation
    times. This can pose a problem if you have to model multiple time series. Additionally,
    TBATS does not allow for the inclusion of exogenous variables.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 与所有预测方法一样，不同的模型有其优点和权衡。虽然TBATS在许多其他模型的不足之处提供了一些改进，但其权衡是需要构建多个模型，这会导致更长的计算时间。如果你需要对多个时间序列进行建模，这可能会成为一个问题。此外，TBATS不允许包含外生变量。
- en: '**Practitioner’s note**:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '**实践者注意**：'
- en: TBATS cannot handle exogenous regression since it is related to ETS models,
    as per Hyndman himself, who suggests it is unlikely to include covariates (Hyndman,
    2014; Reference *7*). If external regressors are to be used, other methods such
    as ARIMAX or SARIMAX should be used. If the time series has complex seasonality,
    you can add Fourier features as covariates to your ARIMAX or SARIMAX model to
    help capture the seasonal patterns.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: TBATS无法处理外生回归，因为它与ETS模型相关，正如Hyndman本人所说，他建议不太可能包括协变量（Hyndman, 2014; 参考文献 *7*）。如果需要使用外部回归变量，应使用其他方法，如ARIMAX或SARIMAX。如果时间序列具有复杂的季节性，可以将傅里叶特征作为协变量添加到ARIMAX或SARIMAX模型中，以帮助捕捉季节性模式。
- en: 'This is implemented in `NIXLA`, and we can use the implementation shown here:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 这在`NIXLA`中实现，我们可以使用此处展示的实现方法：
- en: '[PRE10]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: In NIXTLA, you can also use AutoTBATS to let the system optimize how to handle
    the various parameters.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 在NIXTLA中，你还可以使用AutoTBATS让系统优化如何处理各种参数。
- en: 'Let’s see what the TBATS forecast looks like:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看TBATS预测的效果：
- en: '![](img/B22389_04_12.png)'
  id: totrans-225
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22389_04_12.png)'
- en: 'Figure 4.9: TBATS forecast'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.9：TBATS预测
- en: Again, the seasonality pattern has been replicated and is capturing most of
    the peaks in the forecast. Now let’s take a look at another method that is well
    suited for highly seasonal time series (even if it has multiple seasonalities
    like our case).
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，季节性模式已经被复制，并且捕捉到了大部分预测中的峰值。现在让我们看看另一种非常适合高度季节性时间序列的方法（即使它像我们这样有多重季节性）。
- en: Multiple Seasonal-Trend decomposition using LOESS (MSTL)
  id: totrans-228
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多重季节性-趋势分解使用LOESS（MSTL）
- en: 'Remember the time series decomposition we did back in *Chapter 3*? What if
    we can use the same techniques to forecast? That’s exactly what MSTL does. Let’s
    look at the components of a time series again:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 记得我们在*第3章*做的时间序列分解吗？如果我们能使用相同的技术来进行预测呢？这正是MSTL的作用。让我们再次看看时间序列的组成部分：
- en: Trend
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 趋势
- en: Cyclical
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 周期性
- en: Seasonality
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 季节性
- en: Irregular
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不规则
- en: Trend and cyclical components can be extracted using LOESS regression. If we
    fit a simple model on the trend values, we can use it to extrapolate to the future.
    And the seasonality component can easily be extrapolated because it is supposed
    to be a repeating pattern. Combining these, we get a forecasting model that works
    pretty well.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 趋势和周期成分可以使用LOESS回归提取。如果我们在趋势值上拟合一个简单模型，我们可以用它进行未来的外推。而季节性成分则可以轻松外推，因为它应该是一个重复的模式。将这些结合起来，我们得到了一个表现相当不错的预测模型。
- en: 'The MSTL method in NIXTLA applies the LOESS technique to decompose a time series
    into its various seasonal components. Following this decomposition, it employs
    a specialized non-seasonal model to forecast the trend, and a Seasonal Naive model
    to predict each of the seasonal components. This approach allows for the detailed
    analysis and forecasting of time series with complex seasonal patterns:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: NIXTLA中的MSTL方法应用LOESS技术将时间序列分解成其各种季节性成分。在此分解之后，它使用专门的非季节性模型来预测趋势，并使用季节性朴素模型来预测每个季节性成分。这种方法允许对具有复杂季节性模式的时间序列进行详细分析和预测：
- en: '[PRE11]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Let’s see what the MSTL forecast looks like:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看MSTL预测的效果：
- en: '![](img/B22389_04_13.png)'
  id: totrans-238
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22389_04_13.png)'
- en: 'Figure 4.10: MSTL forecast'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.10：MSTL预测
- en: 'Let’s also take a look at how the different metrics that we chose did for each
    of these forecasts for the household we were experimenting with (from the notebook):'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们也来看一下我们为每个预测选择的不同指标在家庭实验中的表现（来自笔记本）：
- en: '![A screenshot of a computer  Description automatically generated](img/B22389_04_14.png)'
  id: totrans-241
  prefs: []
  type: TYPE_IMG
  zh: '![A screenshot of a computer  Description automatically generated](img/B22389_04_14.png)'
- en: 'Figure 4.11: Summary of all the baseline algorithms'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.11：所有基线算法的汇总
- en: Out of all the baseline algorithms we tried, AutoETS is performing the best
    on MAE as well as MSE. ARIMA was the second-best model followed by TBATS. However,
    if you look at the **Time Elapsed** column, TBATS stands out taking just 7.4 seconds
    vs. 19 seconds for ARIMA. Since they had similar performance, we will choose TBATS
    over ARIMA, along with AutoETS as our baseline, and run them on all 399 households
    in the dataset (both validation and test) we’ve chosen (the code for this is available
    in the `02-Baseline_Forecasts_using_NIXTLA.ipynb` notebook).
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们尝试的所有基线算法中，AutoETS在MAE和MSE上表现最好。ARIMA是第二好的模型，随后是TBATS。然而，如果你看**时间消耗**这一列，TBATS脱颖而出，仅需7.4秒，而ARIMA则需要19秒。由于它们的表现相似，我们将选择TBATS而非ARIMA作为基线，并将AutoETS作为我们的基线，运行它们在我们选择的所有399个家庭（包括验证集和测试集）上（此代码可在`02-Baseline_Forecasts_using_NIXTLA.ipynb`笔记本中找到）。
- en: Evaluating the baseline forecasts
  id: totrans-244
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评估基线预测
- en: 'Since we have the baseline forecasts generated from ETS as well as TBATS, we
    should also evaluate these forecasts. The aggregate metrics for all the selected
    households for both these methods are as follows:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们已经有了从ETS和TBATS生成的基线预测，我们也应该评估这些预测。以下是这两种方法对所有选定家庭的汇总指标：
- en: '![A screenshot of a graph](img/B22389_04_15.png)'
  id: totrans-246
  prefs: []
  type: TYPE_IMG
  zh: '![A screenshot of a graph](img/B22389_04_15.png)'
- en: 'Figure 4.12: The aggregate metrics of all the selected households (both validation
    and test)'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.12：所有选定家庭（包括验证集和测试集）的汇总指标
- en: 'It looks like AutoETS is performing much better in all three metrics. We also
    have these metrics calculated at a household level. Let’s look at the distribution
    of these metrics in the validation dataset for all the selected households:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来AutoETS在所有三个指标上表现都要好得多。我们也在家庭层面计算了这些指标。让我们来看看这些指标在所有选定家庭的验证数据集中的分布：
- en: '![](img/B22389_04_16.png)![](img/B22389_04_17.png)'
  id: totrans-249
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22389_04_16.png)![](img/B22389_04_17.png)'
- en: 'Figure 4.13: The distribution of MASE and forecast bias of the baseline forecast
    in the validation dataset'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.13：验证数据集中的MASE分布和基准预测的预测偏差
- en: The MASE histogram of ETS seems to have a smaller spread than TBATS. ETS also
    has a lower median MASE than TBATS. We can see a similar pattern for forecast
    bias as well, with the forecast bias of ETS centered around zero and much less
    spread.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: ETS的MASE直方图似乎比TBATS的分布要窄。ETS的中位数MASE也低于TBATS。我们在预测偏差上也看到了类似的模式，ETS的预测偏差集中在零附近，且分布更小。
- en: Back in *Chapter 1*, *Introducing Time Series*, we saw why every time series
    is not equally predictable and saw three factors to help us think about the issue—understanding
    the **Data Generating Process** (**DGP**), the amount of data, and adequately
    repeating the pattern. In most cases, the first two are pretty easy to evaluate,
    but the third one requires some analysis. Although the performance of baseline
    methods gives us some idea about how predictable any time series is, they still
    are model-dependent. So, instead of measuring how well a time series is forecastable,
    we might be better measuring how well the chosen model can approximate the time
    series. This is where a few more fundamental techniques (relying on the statistical
    properties of a time series) come in.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 回到*第一章*，*介绍时间序列*，我们看到了为什么并非每个时间序列都是同样可预测的，并且探讨了三个有助于思考这个问题的因素——理解**数据生成过程**（**DGP**）、数据量以及模式的充分重复。在大多数情况下，前两者相对容易评估，但第三个因素需要一些分析。尽管基准方法的表现能给我们一些关于时间序列可预测性的想法，但它们仍然是依赖于模型的。因此，与其衡量时间序列的可预测性，不如衡量所选模型能够如何逼近时间序列。这时，依赖于时间序列统计特性的几种更基本的技术就显得尤为重要。
- en: Assessing the forecastability of a time series
  id: totrans-253
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估时间序列的可预测性
- en: Although there are many statistical measures that we can use to assess the predictability
    of a time series, we will just look at a few that are easier to understand and
    practical when dealing with large time series datasets. The associated notebook
    (`02-Forecastability.ipynb`) contains the code to follow along.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管有许多统计量可以用来评估时间序列的可预测性，但我们将只看一些更易于理解且在处理大规模时间序列数据集时更为实用的统计量。相关的笔记本（`02-Forecastability.ipynb`）包含了跟随的代码。
- en: Coefficient of variation
  id: totrans-255
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 变异系数
- en: The **Coefficient of Variation** (**CoV**) relies on the fact that the more
    variability that you find in a time series, the harder it is to predict it. And
    how do we measure variability in a random variable? **Standard deviation**.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: '**变异系数**（**CoV**）基于这样一个事实：你在时间序列中发现的变异性越大，预测它就越困难。那么，我们如何衡量一个随机变量的变异性呢？**标准差**。'
- en: 'In many real-world time series, the variation we see in the time series is
    dependent on the scale of the time series. Let’s imagine that there are two retail
    products, *A* and *B*. *A* has a mean monthly sale of 15, while *B* has 50\. If
    we look at a few real-world examples like this, we will see that if *A* and *B*
    have the same standard deviation, *B*, which has a higher mean, is much more forecastable
    than *A*. To accommodate this phenomenon and to make sure we bring all the time
    series in a dataset to a common scale, we can use the CoV:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多实际的时间序列中，我们看到的变异性是依赖于时间序列的规模的。假设有两个零售产品，*A*和*B*。*A*的月均销售量是15，而*B*是50。如果我们看一些这样的实际例子，我们会发现，如果*A*和*B*的标准差相同，那么具有较高均值的*B*比*A*更容易预测。为了适应这种现象，并确保我们将数据集中的所有时间序列带到一个共同的尺度上，我们可以使用CoV：
- en: '![](img/B22389_04_035.png)'
  id: totrans-258
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22389_04_035.png)'
- en: Here, ![](img/B22389_04_036.png)is the standard deviation, and ![](img/B22389_04_037.png)is
    the mean of the time series, *n*.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，![](img/B22389_04_036.png)是标准差，![](img/B22389_04_037.png)是时间序列的均值，*n*。
- en: The CoV is the relative dispersion of data points around the mean, which is
    much better than looking at the pure standard deviation.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: CoV是数据点围绕均值的相对离散度，它比单纯看标准差要好得多。
- en: The larger the value for the CoV, the worse the predictability of the time series.
    There is no hard cutoff, but a value of 0.49 is considered a rule of thumb to
    separate time series that are relatively easier to forecast from the hard ones.
    Depending on the general *hardness* of the dataset, we can tweak this cutoff.
    Something I have found useful is to plot a histogram of CoV values in a dataset
    and derive cutoffs based on that.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: CoV值越大，时间序列的可预测性越差。虽然没有硬性标准，但0.49被认为是一个经验值，用于将相对容易预测的时间序列与那些难以预测的区分开来。根据数据集的整体*难度*，我们可以调整这个临界值。我发现有用的一种方法是绘制数据集中CoV值的直方图，并根据此推导出切分点。
- en: 'Even though the CoV is widely used in the industry, it suffers from a few key
    issues:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管CoV在行业中广泛使用，但它存在一些关键问题：
- en: It doesn’t consider seasonality. A sine or cosine wave will have a higher CoV
    than a horizontal line, but we know both are equally predictable.
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它没有考虑季节性。正弦或余弦波会比水平线有更高的CoV，但我们知道两者同样是可预测的。
- en: It doesn’t consider the trend. A linear trend will make a series have a higher
    CoV, but we know it is equally predictable, like a horizontal line.
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它没有考虑趋势。线性趋势会使得一系列数据具有更高的变异系数（CoV），但我们知道它同样是可预测的，就像一条水平线。
- en: It doesn’t handle negative values in the time series. If you have negative values,
    it makes the mean smaller, thereby inflating the CoV.
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它没有处理时间序列中的负值。如果存在负值，会使均值减小，从而使CoV膨胀。
- en: To overcome these shortcomings, we propose another derived measure.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 为了克服这些缺点，我们提出了另一种衍生的度量方式。
- en: Residual variability
  id: totrans-267
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 残差变异性
- en: The thought behind **residual variability** (**RV**) is to try and measure the
    same kind of variability that we were trying to capture with the CoV but without
    the shortcomings. I was brainstorming on ways to avoid the problems of using the
    CoV, typically the seasonality issue, and was applying the CoV to the residuals
    after seasonal decomposition. It was then I realized that the residuals would
    have a few negative values and that the CoV wouldn’t work well. Stefan de Kok,
    who is a thought leader in demand forecasting and probabilistic forecasting, suggested
    using the mean of the original actuals, which worked.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: '**残差变异性**（**RV**）的思想是尽量测量与我们试图通过CoV捕捉的相同类型的变异性，但没有其缺点。我曾在思考如何避免使用CoV时遇到的问题，通常是季节性问题，并尝试将CoV应用于季节性分解后的残差。那时我意识到，残差会有一些负值，且CoV表现不好。斯特凡·德·科克（Stefan
    de Kok），一位需求预测和概率预测领域的思想领袖，建议使用原始实际值的均值，这种方法有效。'
- en: 'To calculate RV, you must perform the following steps:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 计算RV时，必须执行以下步骤：
- en: Perform seasonal decomposition.
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行季节性分解。
- en: Calculate the standard deviation of the residuals or the irregular component.
  id: totrans-271
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算残差或不规则成分的标准差。
- en: Divide the standard deviation by the mean of the original observed values (before
    decomposition).
  id: totrans-272
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将标准差除以原始观测值的均值（分解前）。
- en: 'Mathematically, it can be represented as:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 从数学角度来看，可以表示为：
- en: '![](img/B22389_04_038.png)'
  id: totrans-274
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22389_04_038.png)'
- en: where, ![](img/B22389_04_039.png) is the standard deviation of the residuals
    after decomposition and ![](img/B22389_04_040.png) is the mean of the original
    observed values.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，![](img/B22389_04_039.png)是分解后残差的标准差，![](img/B22389_04_040.png)是原始观测值的均值。
- en: The key assumption here is that seasonality and trend are components that can
    be predicted. Therefore, our assessment of the predictability of a time series
    should only look at the variability of the residuals. However, we cannot use CoV
    on the residuals because the residuals can have negative and positive values,
    so the mean of the residuals loses the interpretation of the level of the series
    and tends to zero. When residuals tend to zero, the CoV measure tends to infinity
    because of the division by mean. Therefore, we use the mean of the original series
    as the scaling factor.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的关键假设是季节性和趋势是可以预测的成分。因此，我们对时间序列可预测性的评估应该只看残差的变异性。然而，我们不能直接对残差使用CoV，因为残差可能有正负值，因此残差的均值失去了序列水平的解释，并趋向于零。当残差趋向零时，由于均值为分母，CoV度量会趋于无穷大。因此，我们使用原始序列的均值作为缩放因子。
- en: 'Let’s see how we can calculate RV for all the time series in our dataset (which
    are in a compact form):'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何为数据集中的所有时间序列计算RV（它们是紧凑形式的）：
- en: '[PRE12]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: In this section, we looked at two measures that are based on the standard deviation
    of the time series. Now, let’s look at assessing the forecastability of a time
    series.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们研究了基于时间序列标准差的两种度量方法。现在，让我们来看一下如何评估时间序列的可预测性。
- en: Entropy-based measures
  id: totrans-280
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于熵的度量
- en: '**Entropy** is a ubiquitous term in science. We see it popping up in physics,
    quantum mechanics, social sciences, and information theory. And everywhere, it
    is used to talk about a measure of chaos or lack of predictability in a system.
    The entropy we are most interested in now is the one from information theory.
    Information theory involves quantifying, storing, and communicating digital information.'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: '**熵**是科学中一个普遍使用的术语。我们看到它出现在物理学、量子力学、社会科学和信息理论中。在所有这些领域，它都用来表示系统中混乱或不可预测性的度量。我们现在最感兴趣的熵是来自信息理论的熵。信息理论涉及数字信息的量化、存储和传播。'
- en: Claude E. Shannon presented the qualitative and quantitative model of communication
    as a statistical process in his seminal paper *A Mathematical Theory of Communication*.
    While the paper introduced a lot of ideas, some of the concepts that are relevant
    to us are information entropy and the concept of a *bit*—a fundamental unit of
    measurement of information.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 克劳德·E·香农在他的开创性论文*《通信的数学理论》*中提出了通信的定性和定量模型，作为一种统计过程。尽管该论文介绍了许多思想，但对我们来说，相关的概念有信息熵和*比特*的概念——比特是信息的基本度量单位。
- en: '**Reference check**:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: '**参考文献检查**：'
- en: '*A Mathematical Theory of Communication* by Claude E. Shannon is cited as reference
    *3* in the *References* section.'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 克劳德·E·香农的*《通信的数学理论》*在*参考文献*部分被引用为参考文献*3*。
- en: 'The theory in itself is quite a lot to cover, but to summarize the key bits
    of information, take a look at the following short glossary:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 这个理论本身涵盖的内容相当多，但为了总结关键信息，可以参考以下简短的词汇表：
- en: Information is nothing but a sequence of *symbols*, which can be transmitted
    from the *receiver* to the *sender* through a medium, which is called a *channel*.
    For instance, when we are texting somebody, the sequence of symbols is the letters/words
    of the language in which we are texting; the channel is the electronic medium.
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 信息不过是一串*符号*，这些符号可以通过一个叫做*通道*的媒介从*接收者*传送到*发送者*。例如，当我们给某人发短信时，符号序列就是我们使用的语言中的字母/单词；而通道就是电子媒介。
- en: '*Entropy* can be thought of as the amount of *uncertainty* or *surprise* in
    a sequence of symbols given some distribution of the symbols.'
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*熵*可以被认为是给定某些符号分布的情况下，一串符号中*不确定性*或*惊讶*的量。'
- en: '*A bit*, as we mentioned earlier, is a unit of information and is a binary
    digit. It can either be 0 or 1.'
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如前所述，*比特*是信息的单位，是一个二进制数字。它可以是0或1。
- en: Now, if we were to transfer one bit of information, it would reduce the uncertainty
    of the receiver by two. To understand this better, let’s consider a coin toss.
    We toss the coin in the air, and as it is spinning through the air, we don’t know
    whether it is going to be heads or tails. But we do know it is going to be one
    of these two. When the coin hits the ground and finally comes to rest, we find
    that it is heads. We can represent whether the coin toss is heads or tails with
    one bit of information (0 for heads and 1 for tails). So, the information that
    was passed to us when the coin fell reduced the possible outcomes from two to
    one (heads). This transfer was possible with one bit of information.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果我们要传输一个比特的信息，它将把接收者的不确定性减少二倍。为了更好地理解这一点，我们可以考虑一次掷硬币的情境。我们把硬币扔到空中，在它旋转的过程中，我们无法知道它是正面还是反面。但我们知道它最终会是这两者之一。当硬币落地并最终静止时，我们发现它是正面。我们可以用一个比特的信息来表示硬币是正面还是反面（0表示正面，1表示反面）。因此，当硬币落下时传递给我们的信息，将可能的结果从两个减少到一个（正面）。这种信息传递只需要一个比特。
- en: In information theory, the entropy of a discrete random variable is the average
    level of *information*, *surprise*, or *uncertainty* inherent in the variable’s
    possible outcomes. In more technical parlance, it is the expected number of bits
    required for the best possible encoding scheme of the information present in the
    random variable.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 在信息理论中，离散随机变量的熵是该变量可能结果中固有的*信息*、*惊讶*或*不确定性*的平均水平。用更专业的术语来说，它是最佳编码方案所需的比特数，表示随机变量中信息的期望值。
- en: '**Additional reading**:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关阅读**：'
- en: If you want to intuitively understand entropy, cross-entropy, Kullback-Leibler
    divergence, and so on, head over to the *Further reading* section. There are a
    couple of links to blogs (one of which is my own) where we try to lay down the
    intuition behind these metrics.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想直观理解熵、交叉熵、Kullback-Leibler散度等内容，可以前往*进一步阅读*部分。那里有一些博客链接（其中一个是我自己的博客），我们尝试阐明这些度量背后的直觉。
- en: 'Entropy is formally defined as follows:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 熵的正式定义如下：
- en: '![](img/B22389_04_041.png)'
  id: totrans-294
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22389_04_041.png)'
- en: Here, *X* is the discrete random variable with possible outcomes, *x*[1], *x*[2],
    …, *x*[n]. Each of those outcomes has a probability of occurring, which is denoted
    by *P*(*x*[1]), *P*(*x*[2]), …, *P*(*x*[n]).
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*X*是一个离散随机变量，可能的结果是*x*[1]、*x*[2]、……、*x*[n]。每个结果都有一个发生的概率，分别用*P*(*x*[1])、*P*(*x*[2])、……、*P*(*x*[n])表示。
- en: 'To develop some intuition around this, we can think that the more spread out
    a probability distribution is, the more chaos is in the distribution, and thus
    more entropy. Let’s quickly check this with some code:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 为了建立一些直觉，我们可以认为，概率分布越分散，分布中的混乱就越多，从而熵也越大。让我们通过一些代码来快速验证这一点：
- en: '[PRE13]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Here, we can see that the probability distribution that spreads its mass has
    higher entropy.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到，质量分布较为分散的概率分布具有更高的熵。
- en: In the context of a time series, *n* is the total number of time series observations,
    and *P*(*x*[i]) is the probability for each symbol of the time series alphabet.
    A sharp distribution means that the time series values are concentrated on a small
    area and should be easier to predict. On the other hand, a wide or flat distribution
    means that the time series value can be equally likely across a wider range of
    values and hence is difficult to predict.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 在时间序列的背景下，*n*是时间序列观察值的总数，*P*(*x*[i])是时间序列字母表中每个符号的概率。一个尖锐的分布意味着时间序列的值集中在一个小范围内，因此应该更容易预测。另一方面，广泛或平坦的分布意味着时间序列的值可以在更广泛的范围内均等出现，因此更难预测。
- en: If we have two time series—one containing the result of a coin toss and the
    other containing the result of a dice throw—the dice throw would have any output
    between one and six, whereas the coin toss would be either zero or one. The coin
    toss time series would have lower entropy and be easier to predict than the dice
    throw time series.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们有两个时间序列，一个包含抛硬币的结果，另一个包含掷骰子的结果，掷骰子的结果会有一个介于1到6之间的输出，而硬币的结果则只能是0或1。硬币投掷的时间序列熵较低，比掷骰子的时间序列更容易预测。
- en: However, since time series is typically continuous, and entropy requires a discrete
    random variable, we can resort to a few strategies to convert the continuous time
    series into a discrete one. Many strategies, such as quantization or binning,
    can be applied, which leads to a myriad of complexity measures. Let’s review one
    such measure that is useful and practical.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，由于时间序列通常是连续的，而熵要求离散的随机变量，我们可以采用一些策略将连续时间序列转换为离散时间序列。许多策略，如量化或分箱，可以应用，从而引入各种复杂性度量。让我们回顾一种既有用又实际的度量。
- en: Spectral entropy
  id: totrans-305
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 谱熵
- en: To calculate the entropy of a time series, we need to discretize the time series.
    One way to do that is by using **Fast Fourier Transform** (**FFT**) and **power
    spectral density** (**PSD**). This discretization of the continuous time series
    is used to calculate spectral entropy.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 为了计算时间序列的熵，我们需要将时间序列离散化。一种方法是使用**快速傅里叶变换**（**FFT**）和**功率谱密度**（**PSD**）。这种连续时间序列的离散化被用于计算谱熵。
- en: We learned what Fourier Transform is earlier in this chapter and used it to
    generate a baseline forecast. But using FFT, we can also estimate a quantity called
    power spectral density. This answers the question, *How much of the signal is
    at a particular frequency?* There are many ways of estimating power spectral density
    from a time series, but one of the easiest ways is by using the **Welch method**,
    which is a non-parametric method based on Discrete Fourier Transform. This is
    also implemented as a handy function with the `periodogram(x)` signature in `scipy`.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前在本章中学习了傅里叶变换，并用它来生成基准预测。但通过使用FFT，我们还可以估计一个称为功率谱密度的量。这个问题的答案是，*信号在某个特定频率下有多少成分？*
    从时间序列中估计功率谱密度有许多方法，但其中最简单的方法之一是使用**Welch方法**，这是一种基于离散傅里叶变换的非参数方法。这个方法也可以通过`scipy`中的`periodogram(x)`函数方便地实现。
- en: 'The returned *PSD* will have a length equal to the number of frequencies estimated,
    but these are densities and not well-defined probabilities. So, we need to normalize
    *PSD* to be between zero and one:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 返回的*PSD*长度等于估计的频率数，但这些是密度而非定义良好的概率。因此，我们需要将*PSD*归一化到0和1之间：
- en: '![](img/B22389_04_042.png)'
  id: totrans-309
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22389_04_042.png)'
- en: Here, *F* is the number of frequencies that are part of the returned power spectrum
    density.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*F*是返回的功率谱密度中所包含的频率数。
- en: 'Now that we have the probabilities, we can just plug this into the entropy
    formula and arrive at the spectral entropy:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经得到了概率值，可以将其代入熵公式，从而得到谱熵：
- en: '![](img/B22389_04_043.png)'
  id: totrans-312
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22389_04_043.png)'
- en: When we introduced **entropy-based measures**, we saw that the more spread out
    the probability mass of a distribution is, the higher the entropy is. In this
    context, the more frequencies across which the spectral density is spread, the
    higher the spectral entropy. So, a higher spectral entropy means the time series
    is more complex and, therefore, more difficult to forecast.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们介绍**基于熵的度量**时，我们看到一个分布的概率质量越分散，熵值越高。在这种情况下，谱密度分布的频率越多，谱熵就越高。因此，较高的谱熵意味着时间序列更复杂，因此更难预测。
- en: 'Since FFT has an assumption of stationarity, it is recommended that we make
    the series stationary before using spectral entropy as a metric. We can even apply
    this metric to a detrended and deseasonalized time series, which we can refer
    to as **residual spectral entropy**. This book’s GitHub repository contains an
    implementation of spectral entropy under `src.forecastability.entropy.spectral_entropy`.
    This implementation also has a parameter, `transform_stationary`, which, if set
    to `True`, will detrend the series before we apply spectral entropy. Let’s see
    how we can calculate spectral entropy for our dataset:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 由于FFT假设序列是平稳的，建议在使用谱熵作为度量前先将时间序列转化为平稳序列。我们甚至可以将此度量应用于去趋势和去季节化的时间序列，这时我们可以称之为**残差谱熵**。本书的GitHub仓库中包含了`src.forecastability.entropy.spectral_entropy`下的谱熵实现。该实现还包含一个参数`transform_stationary`，如果设置为`True`，则在应用谱熵前会对序列进行去趋势处理。让我们来看一下如何为我们的数据集计算谱熵：
- en: '[PRE17]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: There are other entropy-based measures such as approximate entropy and sample
    entropy, but we will not cover them in this book. They are more computationally
    intensive and don’t tend to work for time series that contain fewer than 200 values.
    If you are interested in learning more about these measures, head over to the
    *Further reading* section.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 还有其他基于熵的度量方法，比如近似熵和样本熵，但我们在本书中不会涉及它们。它们的计算复杂度较高，而且通常不适用于包含少于200个值的时间序列。如果你对这些度量方法感兴趣，可以查看*进一步阅读*部分。
- en: Another metric that takes a slightly different path is the Kaboudan metric.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种稍有不同的度量是Kaboudan度量。
- en: Kaboudan metric
  id: totrans-318
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kaboudan度量
- en: 'In 1999, Kaboudan defined a metric for time series predictability, calling
    it the ![](img/B22389_04_044.png)-metric. The idea behind it is very simple. If
    we block-shuffle a time series, we are essentially destroying the information
    in the time series. **Block shuffling** is the process of dividing the time series
    into blocks and then shuffling those blocks. So, if we calculate the **sum of
    squared errors** (**SSE**) of a forecast that’s been trained on a time series
    and then contrast it with the SSE of a forecast trained on a shuffled time series,
    we can infer the predictability of the time series. The formula to calculate this
    is as follows:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 在1999年，Kaboudan定义了一种时间序列可预测性的度量，称之为![](img/B22389_04_044.png)-度量。其背后的理念非常简单。如果我们对时间序列进行块随机排列，本质上是破坏了时间序列中的信息。**块随机排列**是将时间序列分割成多个块，然后打乱这些块的顺序。因此，如果我们计算基于时间序列训练的预测的**平方误差和**（**SSE**），并将其与基于打乱后时间序列训练的预测的SSE进行对比，我们可以推测时间序列的可预测性。计算公式如下：
- en: '![](img/B22389_04_045.png)'
  id: totrans-320
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22389_04_045.png)'
- en: Here, *SSE*[Y] is the SSE of the forecast that was generated from the original
    time series, while *SSE*[S] is the SSE of the forecast that was generated from
    the block-shuffled series.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*SSE*[Y]是从原始时间序列生成的预测的SSE，而*SSE*[S]是从块随机排列后的时间序列生成的预测的SSE。
- en: If the time series contains some predictable signals, *SSE*[Y] would be lower
    than *SSE*[S] and ![](img/B22389_04_044.png) would approach one. This is because
    there was some information or patterns that were broken due to the block shuffling.
    On the other hand, if a series is just white noise (which is unpredictable by
    definition), there would be hardly any difference between *SSE*[Y] and *SSE*[S],
    and ![](img/B22389_04_044.png) would approach zero.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 如果时间序列包含某些可预测的信号，*SSE*[Y]会低于*SSE*[S]，而![](img/B22389_04_044.png)会接近1。这是因为某些信息或模式因块洗牌而被破坏。另一方面，如果一个序列只是白噪声（按定义是不可预测的），那么*SSE*[Y]和*SSE*[S]之间几乎没有差异，![](img/B22389_04_044.png)会接近零。
- en: 'In 2002, Duan investigated this metric and suggested some modifications in
    his thesis. One of the problems he identified, especially in long time series,
    is that the ![](img/B22389_04_044.png) values are found in a narrow band around
    1 and suggested a slight modification to the formula. We call this the **modified
    Kaboudan metric**. The measure on the lower side is also clipped to zero. Sometimes,
    the metric can go below zero because *SSE*[S] is lower than *SSE*[Y], which is
    because the series is unpredictable and, by pure chance, block shuffling made
    the SSE lower:'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 2002年，段某在他的论文中研究了这个度量并提出了一些修改建议。他所发现的一个问题，特别是在长期时间序列中， 是![](img/B22389_04_044.png)值集中在接近1的狭窄区间内，并且他对公式进行了轻微修改。我们称之为**修改后的Kaboudan度量**。下方的度量也被限制为零。有时，度量值可能会低于零，因为*SSE*[S]低于*SSE*[Y]，这意味着该序列是不可预测的，并且由于纯粹的偶然，块洗牌使得SSE值较低：
- en: '![](img/B22389_04_049.png)'
  id: totrans-324
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22389_04_049.png)'
- en: '**Reference check**:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: '**参考检查**：'
- en: The research paper that proposed the Kaboudan metric is cited as reference *4*
    in the *References* section. The subsequent modification that Duan suggested is
    cited as reference *5*.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 提出的Kaboudan度量的研究论文在*参考文献*部分被引用为参考文献*4*。段某建议的后续修改被引用为参考文献*5*。
- en: This modified version, as well as the original, has been implemented in this
    book’s GitHub repository.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 这个修改版以及原版都已经在本书的GitHub仓库中实现。
- en: There is no restriction on the forecasting model you use to generate the forecast,
    which makes it a bit more flexible. Ideally, we can choose one of the classical
    statistical methods that is fast enough to be applied to the whole dataset. But
    this also makes the Kaboudan metric dependent on the model, and the limitations
    of the model are inherent in the metric. The metric measures a combination of
    how difficult a series is to forecast and how difficult it is for the model to
    forecast the series.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 对于生成预测的预测模型没有限制，这使得它具有更多的灵活性。理想情况下，我们可以选择一种经典的统计方法，这种方法足够快速，能够应用于整个数据集。但这也使得Kaboudan度量依赖于模型，模型的局限性也在度量中体现。该度量衡量了一个序列预测的难度以及模型预测该序列的难度。
- en: 'Again, both metrics are implemented in this book’s GitHub repository. Let’s
    see how we can use them:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，这两个度量已经在本书的GitHub仓库中实现。让我们看看如何使用它们：
- en: '[PRE18]'
  id: totrans-330
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Although there are many more metrics we can use for this purpose, the metrics
    we just reviewed for assessing forecastability cover a lot of the popular use
    cases and should be more than enough to gauge any time series dataset in regards
    to the difficulty of forecasting it. We can use these metrics to compare one time
    series with another time series or to profile a whole set of related time series
    in a dataset with another dataset for benchmarking purposes.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们可以使用更多度量来实现这个目的，但我们刚刚回顾的用于评估可预测性的度量涵盖了很多流行的应用场景，并且足以用来衡量任何时间序列数据集在预测难度方面的情况。我们可以使用这些度量将一个时间序列与另一个时间序列进行比较，或者将一个数据集中的一组相关时间序列与另一个数据集进行对比，用于基准测试。
- en: '**Additional reading**:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: '**进一步阅读**：'
- en: If you want to delve a little deeper and analyze the behavior of these metrics,
    how similar they are to each other, and how effective they are in measuring forecastability,
    go to the end of the `03-Forecastability.ipynb` notebook. We compute rank correlations
    among these metrics to understand how similar these metrics are. We can also find
    rank correlations with the computed metrics from the best-performing baseline
    method to understand how well these metrics did in estimating the forecastability
    of a time series. I strongly encourage you to play around with the notebook and
    understand the differences between the different metrics. Pick a few time series
    and check how the different metrics give you slightly different interpretations.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想深入分析这些指标的行为，了解它们之间的相似性，以及它们在衡量可预测性方面的有效性，请前往`03-Forecastability.ipynb`笔记本的最后部分。我们计算了这些指标之间的排名相关性，以理解它们的相似度。我们还可以找到与最佳表现基准方法计算指标之间的排名相关性，以了解这些指标在估计时间序列的可预测性方面的效果。我强烈建议你玩转这个笔记本，理解不同指标之间的差异。挑选一些时间序列，检查不同指标如何给出略有不同的解释。
- en: 'Congratulations on generating your baseline forecasts—the first set of forecasts
    we have generated using this book! Feel free to head over to the notebooks, play
    around with the parameters of the methods, and see how forecasts change. It’ll
    help you develop an intuition around what the baseline methods are doing. If you
    are interested in learning more about how to make these baseline methods better,
    head over to the *Further reading* section, where we have provided a link to the
    paper *The Wisdom of the Data: Getting the Most Out of Univariate Time Series
    Forecasting*, by F. Petropoulos and E. Spiliotis.'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜你生成了基准预测——这是我们通过本书生成的第一组预测！你可以随意进入笔记本，调整方法的参数，看看预测结果如何变化。这将帮助你培养对基准方法的直觉。如果你有兴趣了解如何改进这些基准方法，可以查看*进一步阅读*部分，我们提供了关于F.
    Petropoulos 和 E. Spiliotis的论文*数据的智慧：如何最大化单变量时间序列预测*的链接。
- en: Summary
  id: totrans-335
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: And with this, we have come to the end of *Part 1*, *Getting Familiar with Time
    Series*. We have come a long way from just understanding what a time series is
    to generating competitive baseline forecasts. Along the way, we learned how to
    handle missing values and outliers and how to manipulate time series data using
    pandas. We used all those skills on a real-world dataset regarding energy consumption.
    We also looked at ways to visualize and decompose time series. In this chapter,
    we set up a test harness, learned how to use the NIXTLA library to generate a
    baseline forecast, and looked at a few metrics that can be used to understand
    the forecastability of a time series.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 至此，我们已经完成了*第一部分*，*了解时间序列*。我们从仅仅理解时间序列是什么，到生成具有竞争力的基准预测，走过了很长的路。在此过程中，我们学会了如何处理缺失值和异常值，如何使用pandas操作时间序列数据。我们把这些技能应用到了一个关于能源消费的实际数据集上。我们还探讨了如何可视化和分解时间序列。在这一章中，我们设置了一个测试框架，学习了如何使用NIXTLA库生成基准预测，并介绍了几种可用于理解时间序列可预测性的指标。
- en: For some of you, this may be a refresher, and we hope this chapter added some
    value in terms of some subtleties and practical considerations. For the rest of
    you, we hope you are in a good place foundationally to start venturing into modern
    techniques using machine learning in the next part of the book.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 对于你们中的一些人来说，这可能是一个复习，希望这一章能为你提供一些细节和实际考虑的价值。对于其余的读者，我们希望你们已经打下了坚实的基础，准备在本书的下一部分开始涉足现代机器学习技术。
- en: In the next chapter, we will discuss the basics of machine learning and delve
    into time series forecasting.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将讨论机器学习的基础，并深入探讨时间序列预测。
- en: References
  id: totrans-339
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'The following references were provided in this chapter:'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 本章提供了以下参考文献：
- en: 'Assimakopoulos, Vassilis and Nikolopoulos, K. (2000). *The theta model: A decomposition
    approach to forecasting*. International Journal of Forecasting. 16\. 521-530\.
    [https://www.researchgate.net/publication/223049702_The_theta_model_A_decomposition_approach_to_forecasting](https://www.researchgate.net/publication/223049702_The_theta_model_A_decomposition_approach_to_forecasting).'
  id: totrans-341
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'Assimakopoulos, Vassilis 和 Nikolopoulos, K. (2000). *The theta model: A decomposition
    approach to forecasting*. 国际预测学杂志。16. 521-530. [https://www.researchgate.net/publication/223049702_The_theta_model_A_decomposition_approach_to_forecasting](https://www.researchgate.net/publication/223049702_The_theta_model_A_decomposition_approach_to_forecasting)。'
- en: Rob J. Hyndman, Baki Billah. (2003). *Unmasking the Theta method*. International
    Journal of Forecasting. 19\. 287-290\. [https://robjhyndman.com/papers/Theta.pdf](https://robjhyndman.com/papers/Theta.pdf).
  id: totrans-342
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Rob J. Hyndman, Baki Billah. (2003). *揭示Theta方法的真相*. 国际预测学期刊. 19. 287-290. [https://robjhyndman.com/papers/Theta.pdf](https://robjhyndman.com/papers/Theta.pdf).
- en: 'Shannon, C.E. (1948), *A Mathematical Theory of Communication*. Bell System
    Technical Journal, 27: 379-423\. [https://people.math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf](https://people.math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf).'
  id: totrans-343
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'Shannon, C.E. (1948), *通信的数学理论*. 贝尔系统技术杂志, 27: 379-423. [https://people.math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf](https://people.math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf).'
- en: 'Kaboudan, M. (1999). *A measure of time series’ predictability using genetic
    programming applied to stock returns*. Journal of Forecasting, 18, 345-357: [http://www.aiecon.org/conference/efmaci2004/pdf/GP_Basics_paper.pdf](http://www.aiecon.org/conference/efmaci2004/pdf/GP_Basics_paper.pdf).'
  id: totrans-344
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'Kaboudan, M. (1999). *利用遗传编程应用于股票收益的时间序列可预测性度量*. 预测学杂志, 18, 345-357: [http://www.aiecon.org/conference/efmaci2004/pdf/GP_Basics_paper.pdf](http://www.aiecon.org/conference/efmaci2004/pdf/GP_Basics_paper.pdf).'
- en: 'Duan, M. (2002). *TIME SERIES PREDICTABILITY*: [https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.68.1898&rep=rep1&type=pdf](https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.68.1898&rep=rep1&type=pdf).'
  id: totrans-345
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'Duan, M. (2002). *时间序列可预测性*: [https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.68.1898&rep=rep1&type=pdf](https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.68.1898&rep=rep1&type=pdf).'
- en: De Livera, A. M., & Hyndman, R. J. (2009). Forecasting time series with complex
    seasonal patterns using exponential smoothing (Department of Econometrics and
    Business Statistics Working Paper Series 15/09)
  id: totrans-346
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: De Livera, A. M., & Hyndman, R. J. (2009). 使用指数平滑法预测具有复杂季节模式的时间序列（经济计量学与商业统计学工作论文系列
    15/09）
- en: Hyndman, Rob. “*Rob J Hyndman - TBATS with Regressors*.” Rob J Hyndman, 6 Oct.
    2014, [http://robjhyndman.com/hyndsight/tbats-with-regressors](http://robjhyndman.com/hyndsight/tbats-with-regressors)
  id: totrans-347
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Hyndman, Rob. “*Rob J Hyndman - 带有回归项的TBATS模型*.” Rob J Hyndman, 2014年10月6日,
    [http://robjhyndman.com/hyndsight/tbats-with-regressors](http://robjhyndman.com/hyndsight/tbats-with-regressors)
- en: Further reading
  id: totrans-348
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'To learn more about the topics that were covered in this chapter, take a look
    at the following resources:'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多本章所涉及的主题，请查看以下资源：
- en: '*Information Theory and Entropy*, by Manu Joseph: [https://deep-and-shallow.com/2020/01/09/deep-learning-and-information-theory/](https://deep-and-shallow.com/2020/01/09/deep-learning-and-information-theory/).'
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*信息理论与熵*, Manu Joseph著: [https://deep-and-shallow.com/2020/01/09/deep-learning-and-information-theory/](https://deep-and-shallow.com/2020/01/09/deep-learning-and-information-theory/).'
- en: '*Visual Information*, by Chris Olah: [https://colah.github.io/posts/2015-09-Visual-Information](https://colah.github.io/posts/2015-09-Visual-Information).'
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*视觉信息*, Chris Olah著: [https://colah.github.io/posts/2015-09-Visual-Information](https://colah.github.io/posts/2015-09-Visual-Information).'
- en: 'Fourier Transform: [https://betterexplained.com/articles/an-interactive-guide-to-the-fourier-transform/](https://betterexplained.com/articles/an-interactive-guide-to-the-fourier-transform/).'
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '傅里叶变换: [https://betterexplained.com/articles/an-interactive-guide-to-the-fourier-transform/](https://betterexplained.com/articles/an-interactive-guide-to-the-fourier-transform/).'
- en: '*Fourier Transform* by 3blue1brown—a visual introduction: [https://www.youtube.com/watch?v=spUNpyF58BY&vl=en](https://www.youtube.com/watch?v=spUNpyF58BY&vl=en).'
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*傅里叶变换* 由3blue1brown提供—一份视觉介绍: [https://www.youtube.com/watch?v=spUNpyF58BY&vl=en](https://www.youtube.com/watch?v=spUNpyF58BY&vl=en).'
- en: '*Understanding Fourier Transform by Example*, by Richie Vink: [https://www.ritchievink.com/blog/2017/04/23/understanding-the-fourier-transform-by-example/](https://www.ritchievink.com/blog/2017/04/23/understanding-the-fourier-transform-by-example/).'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*通过实例理解傅里叶变换*, Richie Vink著: [https://www.ritchievink.com/blog/2017/04/23/understanding-the-fourier-transform-by-example/](https://www.ritchievink.com/blog/2017/04/23/understanding-the-fourier-transform-by-example/).'
- en: 'Delgado-Bonal A, Marshak A. *Approximate Entropy and Sample Entropy: A Comprehensive
    Tutorial*. Entropy. 2019; 21(6):541: [https://www.mdpi.com/1099-4300/21/6/541](https://www.mdpi.com/1099-4300/21/6/541).'
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Delgado-Bonal A, Marshak A. *近似熵与样本熵: 一份全面教程*. 熵. 2019; 21(6):541: [https://www.mdpi.com/1099-4300/21/6/541](https://www.mdpi.com/1099-4300/21/6/541).'
- en: 'Yentes, J.M., Hunt, N., Schmid, K.K. et al. *The Appropriate Use of Approximate
    Entropy and Sample Entropy with Short Data Sets*. Ann Biomed Eng 41, 349–365 (2013):
    [https://doi.org/10.1007/s10439-012-0668-3](https://doi.org/10.1007/s10439-012-0668-3)'
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yentes, J.M., Hunt, N., Schmid, K.K. 等人. *近似熵与样本熵在短数据集中的适当使用*. 生物医学工程学报 41,
    349–365 (2013): [https://doi.org/10.1007/s10439-012-0668-3](https://doi.org/10.1007/s10439-012-0668-3)'
- en: Ponce-Flores M, Frausto-Solís J, Santamaría-Bonfil G, Pérez-Ortega J, González-Barbosa
    JJ. *Time Series Complexities and Their Relationship to Forecasting Performance*.
    Entropy. 2020; 22(1):89\. [https://www.mdpi.com/1099-4300/22/1/89](https://www.mdpi.com/1099-4300/22/1/89)
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ponce-Flores M, Frausto-Solís J, Santamaría-Bonfil G, Pérez-Ortega J, González-Barbosa
    JJ. *时间序列复杂性及其与预测性能的关系*。熵。2020; 22(1):89。 [https://www.mdpi.com/1099-4300/22/1/89](https://www.mdpi.com/1099-4300/22/1/89)
- en: 'Petropoulos F, Spiliotis E. *The Wisdom of the Data: Getting the Most Out of
    Univariate Time Series Forecasting*. Forecasting. 2021; 3(3):478-497\. [https://doi.org/10.3390/forecast3030029](https://doi.org/10.3390/forecast3030029)'
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Petropoulos F, Spiliotis E. *数据的智慧：如何充分利用单变量时间序列预测*。预测。2021; 3(3):478-497。 [https://doi.org/10.3390/forecast3030029](https://doi.org/10.3390/forecast3030029)
- en: Join our community on Discord
  id: totrans-359
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们的Discord社区
- en: 'Join our community’s Discord space for discussions with authors and other readers:'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 加入我们社区的Discord空间，与作者和其他读者进行讨论：
- en: '[https://packt.link/mts](https://packt.link/mts)'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/mts](https://packt.link/mts)'
- en: '![](img/QR_Code15080603222089750.png)'
  id: totrans-362
  prefs: []
  type: TYPE_IMG
  zh: '![](img/QR_Code15080603222089750.png)'
