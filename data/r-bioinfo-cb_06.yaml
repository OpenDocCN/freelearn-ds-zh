- en: Proteomics from Spectrum to Annotation
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从光谱到注释的蛋白质组学
- en: '**Mass spectrometry** (**MS**) data usually comprises spectra that must be
    bioinformatically processed to identify candidate peptides. These peptides include
    assignments, and counts can then be analyzed using a wide range of techniques
    and packages. The wide range of graphical user interface-driven tools for proteomics
    means that there is a proliferation of file formats that can be tough to deal
    with initially. These recipes will explore how to take advantage of the excellent
    parsers and reformatters available in the new `RforProteomics` project and associated
    tools for analysis and verification of spectra, and even show you how to view
    your peptides in genome browsers alongside other genomic information such as gene
    models.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '**质谱**（**MS**）数据通常包含必须经过生物信息学处理的光谱，以识别候选肽。这些肽包括分配，计数可以使用各种技术和包进行分析。用于蛋白质组学的各种图形用户界面驱动工具意味着出现了多种文件格式，最初可能很难处理。这些配方将探索如何利用`RforProteomics`项目中的优秀解析器和格式转换工具来分析和验证光谱，甚至向你展示如何在基因组浏览器中查看你的肽以及基因模型等其他基因组信息。'
- en: 'In this chapter, we will cover the following recipes:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下配方：
- en: Representing raw MS data visually
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以视觉方式表示原始MS数据
- en: Viewing proteomics data in a genome browser
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在基因组浏览器中查看蛋白质组学数据
- en: Visualizing distributions of peptide hit counts to find thresholds
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可视化肽命中次数的分布以寻找阈值
- en: Converting MS formats to move data between tools
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 转换MS格式以在工具之间传输数据
- en: Matching spectra to peptides for verification with protViz
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用protViz将光谱与肽匹配进行验证
- en: Applying quality control filters to spectra
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用质量控制滤波器到光谱
- en: Identifying genomic loci that match peptides
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别与肽匹配的基因组位置
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: The sample data you'll need is available from this book's GitHub repository
    at [https://github.com/danmaclean/R_Bioinformatics_Cookbook](https://github.com/danmaclean/R_Bioinformatics_Cookbook)[.](https://github.com/danmaclean/R_Bioinformatics_Cookbook) If
    you want to use the code examples as they are written, then you will need to make
    sure that this data is located in your working directory's subdirectory.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 你将需要的样本数据可以从本书的GitHub仓库中获取，地址是[https://github.com/danmaclean/R_Bioinformatics_Cookbook](https://github.com/danmaclean/R_Bioinformatics_Cookbook)[.]
    如果你想按原样使用代码示例，那么你需要确保该数据位于工作目录的子目录中。
- en: 'Here are the R packages that you''ll need. In general, you can install these
    with `install.packages("package_name")`. The packages listed under `Bioconductor`
    need to be installed with the dedicated installer, as described here. If you need
    to do anything else, the installation will be described in the recipes in which
    the packages are used:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是你将需要的R包。通常，你可以通过`install.packages("package_name")`来安装这些包。列在`Bioconductor`下的包需要通过专用的安装程序进行安装，如此处所述。如果你需要做其他事情，安装方法将在这些包所使用的配方中描述：
- en: '`Bioconductor`'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Bioconductor`'
- en: '`EnsDb.Hsapiens.v86`'
  id: totrans-14
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`EnsDb.Hsapiens.v86`'
- en: '`MSnID`'
  id: totrans-15
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MSnID`'
- en: '`MSnbase`'
  id: totrans-16
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MSnbase`'
- en: '`mzR`'
  id: totrans-17
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mzR`'
- en: '`proteoQC`'
  id: totrans-18
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proteoQC`'
- en: '`rtracklayer`'
  id: totrans-19
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rtracklayer`'
- en: '`data.table`'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data.table`'
- en: '`dplyr`'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dplyr`'
- en: '`ggplot2`'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ggplot2`'
- en: '`protViz`'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`protViz`'
- en: '`Bioconductor` is huge and has its own installation manager. You can install
    the manager with the following code:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '`Bioconductor`非常庞大，并且拥有自己的安装管理器。你可以通过以下代码安装该管理器：'
- en: '[PRE0]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Then, you can install the packages with this code:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，你可以使用此代码安装软件包：
- en: '[PRE1]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Further information is available at [https://www.bioconductor.org/install/](https://www.bioconductor.org/install/).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 更多信息可以在[https://www.bioconductor.org/install/](https://www.bioconductor.org/install/)找到。
- en: Normally in R, a user will load a library and use the functions directly by
    name. This is great in interactive sessions, but it can cause confusion when many
    packages are loaded. To clarify which package and function I'm using at a given
    moment, I will occasionally use the `packageName::functionName()` convention.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在R中，用户通常会加载一个库并直接通过名称使用其中的函数。这在交互式会话中非常方便，但在加载多个包时可能会造成困惑。为了明确在某一时刻我正在使用哪个包和函数，我偶尔会使用`packageName::functionName()`这种惯例。
- en: 'Occasionally, in the middle of a recipe, I''ll interrupt the code so you can
    see some intermediate output or the structure of an object that''s important for
    you to understand. Whenever that happens, you''ll see a code block, where each
    line begins with ##, that is, double hash symbols. Consider the following command:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，在配方中间，我会中断代码，以便你查看一些中间输出或对你理解非常重要的对象结构。每当发生这种情况时，你会看到一个代码块，其中每行以##（即双哈希符号）开头。考虑以下命令：
- en: '`letters[1:5]`'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '`letters[1:5]`'
- en: 'This will give us the following output:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '`## a b c d e`'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '`## a b c d e`'
- en: Note that the output lines are prefixed with `##`.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，输出行以`##`为前缀。
- en: Representing raw MS data visually
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 以可视化方式表示原始质谱数据
- en: The raw data of proteomics analysis is the spectra that's generated by the mass
    spectrometers. Each type of mass spectrometer has a different native file format
    in which the spectra are encoded. Examining and analyzing the spectra begins with
    loading in the files and coercing them into a common object type. In this recipe,
    we'll look at how to load the varied file types, look at the metadata, and plot
    the spectra themselves.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 蛋白质组学分析的原始数据就是由质谱仪生成的光谱。每种类型的质谱仪都有不同的本地文件格式来编码光谱。检查和分析光谱从加载文件并将其强制转换为通用的对象类型开始。在这个示例中，我们将学习如何加载不同类型的文件，查看元数据，并绘制光谱本身。
- en: Getting ready
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备就绪
- en: For this recipe, we'll need the `Bioconductor` package, `mzR`, and some files
    from this book's data repository, in the `datasets/ch6`folder. We'll use three
    different files, selected not so much for the data in them, but because they each
    represent one of the most common MS file types, `mzXML`, `mzdata`, and `mzML`.
    The example files all come from the `mzdata` package. Since they're extracted,
    you won't need to install this package, but if you'd like more example files,
    it's a good place to look.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个示例，我们需要使用`Bioconductor`包、`mzR`包以及本书数据仓库中的一些文件，这些文件位于`datasets/ch6`文件夹中。我们将使用三个不同的文件，它们的选择并不是基于文件中的数据，而是因为它们分别代表了最常见的三种质谱文件类型：`mzXML`、`mzdata`和`mzML`。这些示例文件都来自`mzdata`包。由于它们是提取出来的，你不需要安装该包，但如果你需要更多的示例文件，这个包是一个不错的选择。
- en: How to do it...
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到...
- en: 'Raw MS data can be represented visually using the following steps:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 原始质谱数据可以通过以下步骤以可视化方式表示：
- en: 'Load the libraries:'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载库：
- en: '[PRE2]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Load the files into objects:'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将文件加载到对象中：
- en: '[PRE3]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'View the metadata where available:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看可用的元数据：
- en: '[PRE4]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Plot the spectra:'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制光谱：
- en: '[PRE5]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: How it works...
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In *Step 1*, we load the libraries we'll need. The main one is `mzR`.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤 1*中，我们加载了所需的库。主要的库是`mzR`。
- en: In *Step 2*, we define the paths to the files we will load using the system-agnostic
    `file.path()` function, which returns a character vector with the filename in
    it. Then, we use that filename in the `openMSfile()` function from `mzR` to actually
    create an `mzR` object representing the data in the respective files. Note that
    we essentially run the same code three times, changing only the file and input
    file type each time. The `openMSfile()` function will automatically detect the
    format of the file.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤 2*中，我们使用系统无关的`file.path()`函数定义了我们将要加载的文件路径，该函数返回一个包含文件名的字符向量。然后，我们使用该文件名通过`mzR`中的`openMSfile()`函数来创建一个代表相应文件中数据的`mzR`对象。请注意，我们本质上运行了相同的代码三次，只是每次更改文件和输入文件类型。`openMSfile()`函数会自动检测文件的格式。
- en: In *Step 3*, we use the `mzR` package accessor functions, `runInfo()` and `sampleInfo()`,
    to extract some of the metadata in the input files. Note that `sampleInfo()` with
    `ms1` doesn't return anything—this is because that particular file didn't have
    that data in it. The metadata that can be returned is dependent on the file and
    file type.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤 3*中，我们使用`mzR`包的访问器函数`runInfo()`和`sampleInfo()`来提取输入文件中的一些元数据。请注意，`sampleInfo()`与`ms1`一起使用时没有返回任何内容——这是因为该特定文件中没有包含这些数据。可以返回的元数据取决于文件和文件类型。
- en: 'In *Step 4*, we use the `MSnbase` package to load in a file with its `readMSData()` function.
    This uses `mzR` on its backend, so it can do the same, but it returns a modified
    object of the `MSnbase` class. This means that some generic plot functions will
    work. We then use the `plot()` function to create an image of all the spectra
    in the file:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤 4*中，我们使用`MSnbase`包的`readMSData()`函数加载文件。该函数在后台使用`mzR`，因此可以执行相同的操作，但它返回一个修改后的`MSnbase`类对象。这意味着一些通用的绘图函数将会生效。接着，我们使用`plot()`函数创建文件中所有光谱的图像：
- en: '![](img/4d0b67ad-9667-473b-80ee-bba4bffa2395.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4d0b67ad-9667-473b-80ee-bba4bffa2395.png)'
- en: 'And then, by using indexing, we create an image of just the fifth spectrum
    in the file:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，通过使用索引，我们创建了仅包含文件中第五个光谱的图像：
- en: '![](img/9b263019-d698-464b-bba8-5db036393517.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9b263019-d698-464b-bba8-5db036393517.png)'
- en: Viewing proteomics data in a genome browser
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在基因组浏览器中查看蛋白质组学数据
- en: Once we have mass spectrometer data and have identified the peptides and proteins
    the spectra describe using search engine software such as Xtandem, MSGF+, or Mascot,
    we may want to look at those in their genomic context alongside other important
    data. In this recipe, we'll look at how to extract peptides and the Uniprot IDs
    from a search file, find the genes those Uniprot IDs map to, and then create a
    genome browser track showing those genes. These can be sent to the UCSC human
    genome browser, and the interactive web page, which will be loaded in your local
    browser automatically.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们获取了质谱数据，并使用如Xtandem、MSGF+或Mascot等搜索引擎软件识别了光谱描述的肽段和蛋白质，我们可能希望在其基因组上下文中查看这些数据，并与其他重要数据一起展示。在本食谱中，我们将展示如何从搜索文件中提取肽段和Uniprot
    ID，找到这些Uniprot ID映射的基因，并创建一个显示这些基因的基因组浏览器轨道。可以将这些发送到UCSC人类基因组浏览器，互动网页将会自动在本地浏览器中加载。
- en: Getting ready
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作：
- en: For this recipe, you'll need the Bioconductor packages `MSnID`, `EnsDB.Hsapiens.v86`,
    and `rtracklayer`, and the `HeLa_180123_m43_r2_CAM.mzid.gz` file from the `datasets/ch6`
    folder of this book's repository. For this recipe to work, you'll also need to
    be connected to the internet, and have a recent web browser that can run the UCSC
    genome browser located at [https://genome.ucsc.edu](https://genome.ucsc.edu).
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个食谱，您需要安装Bioconductor包`MSnID`、`EnsDB.Hsapiens.v86`和`rtracklayer`，以及本书仓库中`datasets/ch6`文件夹下的`HeLa_180123_m43_r2_CAM.mzid.gz`文件。为了使这个食谱生效，您还需要连接到互联网，并拥有一个能够运行UCSC基因组浏览器的现代浏览器，网址是[https://genome.ucsc.edu](https://genome.ucsc.edu)。
- en: How to do it...
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Proteomics data can be viewed in a genome browser using the following steps:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 通过以下步骤可以在基因组浏览器中查看蛋白质组学数据：
- en: 'Load the libraries:'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载库：
- en: '[PRE6]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Create and populate the search file object:'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建并填充搜索文件对象：
- en: '[PRE7]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Extract rows containing useful hits and columns containing useful information:'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提取包含有用命中的行和包含有用信息的列：
- en: '[PRE8]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Extract the Uniprot IDs from the `accession` column:'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`accession`列提取Uniprot ID：
- en: '[PRE9]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Create a database connection and obtain genes matching our Uniprot IDs:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建数据库连接并获取与我们的Uniprot ID匹配的基因：
- en: '[PRE10]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Set up the genome browser track:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置基因组浏览器轨道：
- en: '[PRE11]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Set up the browser session and view:'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置浏览器会话并查看：
- en: '[PRE12]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: How it works...
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: '*Step 1* is our standard library loading step.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '*步骤1*是我们的标准库加载步骤。'
- en: '*Step 2* is the data loading step. This is a little unusual. Instead of just
    calling a file-reading function, we must first create and empty the `MSnID` object
    and load the data into it. We create `msnid` with the `MSnID()` function and then
    pass it to the `read_mzid()` function to actually put data into it.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '*步骤2*是数据加载步骤。这一步有点特殊。我们不仅仅调用一个文件读取函数，而是首先创建并清空`MSnID`对象，并将数据加载到其中。我们使用`MSnID()`函数创建`msnid`，然后将其传递给`read_mzid()`函数，实际上将数据加载到其中。'
- en: '*Step 3* is concerned with extracting the information we are concerned about
    from the `msnid` object. We require rows that match actual hits, not decoys, so
    we access the `msnid@psms` slot directly, which contains the useful data and subset
    that retains a row if its value of `isDecoy` is `FALSE`. This gives us an object
    that we save in the `real_hits` variable. Next, we use `real_hits` to select a
    few useful columns from the many in the original object.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '*步骤3*关注于从`msnid`对象中提取我们关心的信息。我们需要的是匹配实际命中的行，而不是诱饵行，因此我们直接访问`msnid@psms`槽，该槽包含有用数据，并筛选出`isDecoy`值为`FALSE`的行。这将给我们一个对象，我们将其保存在`real_hits`变量中。接下来，我们使用`real_hits`从原始对象中的许多列中选择一些有用的列。'
- en: '*Step 4* helps us extract the Uniprot IDs embedded in the accession column
    field. It is important to note that these values come from the names that are
    used in the search engine''s database. Naturally, this step will vary according
    to the precise formatting of the database, but the general pattern applies. We
    have a fairly densely nested set of functions that breaks down like this: the
    inner, anonymous function, `function(x){x[2]}`, returns the second element of
    any vector it is passed. We use `lapply()` to apply that function to every element
    in the list returned from `strsplit()` on the accession column. Finally, as `lapply()`
    returns lists, we use `unlist()` to flatten it to the vector we require. Sometimes,
    this will generate NAs as there is no Uniprot ID, so we remove them from the vector
    with subsetting and `is.na()`.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '*步骤 4* 帮助我们提取嵌入在 accession 列字段中的 Uniprot ID。需要注意的是，这些值来自于搜索引擎数据库中使用的名称。自然地，这一步会根据数据库的精确格式有所不同，但一般的模式适用。我们有一组嵌套得相当密集的函数，其解析过程如下：内层的匿名函数`function(x){x[2]}`返回它所传入的任何向量的第二个元素。我们使用`lapply()`将这个函数应用于从
    `strsplit()` 函数返回的 accession 列中的每个元素。最后，由于`lapply()`返回的是列表，我们使用`unlist()`将其展开成我们所需的向量。有时，这会生成
    NAs，因为某些 Uniprot ID 可能不存在，所以我们通过子集和 `is.na()` 将其从向量中删除。'
- en: In *Step 5*, we connect to the Ensembl database package and use the `genes()` function
    to get Ensembl genes that match our Uniprot IDs. The vector of Uniprot IDs is
    passed in the `UniprotFilter()` function and, with the `columns` argument, we
    select the data we wish to get back from the database. This gives us a `GRanges` object
    that contains all the information we require in order to build a browser track.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *步骤 5* 中，我们连接到 Ensembl 数据库包，并使用 `genes()` 函数获取与我们的 Uniprot ID 匹配的 Ensembl
    基因。Uniprot ID 的向量被传递到 `UniprotFilter()` 函数中，并且通过 `columns` 参数，我们选择从数据库中返回的数据。这为我们提供了一个
    `GRanges` 对象，包含了构建浏览器轨道所需的所有信息。
- en: In *Step 6*, we use the helper function, `GRangesForUCSCGenome()`, passing it
    the version of the genome we wish to view—`hg38`, and then the basic chromosome
    name, coordinates, and strand information a `GRanges` object needs. We can use
    the `seqnames()`, `ranges()`, and `strand()` accessor functions to pull these
    out of the `genes_for_prots` object we created previously. The seqnames in UCSC
    are prefixed with `chr`, so we use paste to add that to our seqnames data. We
    also create columns for the gene name and gene ID, preserving that information
    in our eventual view. We save the resulting object in the `track` variable.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *步骤 6* 中，我们使用辅助函数`GRangesForUCSCGenome()`，并传入我们希望查看的基因组版本——`hg38`，然后是基本的染色体名称、坐标和链信息，这是创建
    `GRanges` 对象所需的数据。我们可以使用 `seqnames()`、`ranges()` 和 `strand()` 访问函数，从我们之前创建的 `genes_for_prots`
    对象中提取这些信息。UCSC 中的序列名称以 `chr` 为前缀，因此我们使用 `paste` 将其添加到我们的序列名称数据中。我们还为基因名称和基因 ID
    创建了列，以便在最终的视图中保留这些信息。我们将结果保存在 `track` 变量中。
- en: Finally, in *Step 7*, we can render the track we created. First, we create a
    session object that represents a session on UCSC and add the track to it with
    the `session()` and `track()` functions, respectively. We select which of the
    many peptides to focus on by passing the first peptide just to the `view()` function,
    which actually spawns a new web browser window with the data requested. The second
    argument to `view()` specifies a zoom level and, by formulating the argument as `first_peptide
    * -5`, we get a zoom that will fit five of the requested features.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在 *步骤 7* 中，我们可以渲染我们创建的轨道。首先，我们创建一个表示 UCSC 会话的会话对象，并分别使用 `session()` 和 `track()`
    函数将轨道添加到其中。我们通过将第一个肽传递给 `view()` 函数来选择关注的肽，`view()` 函数会实际打开一个新的网页浏览器窗口，显示请求的数据。`view()`
    的第二个参数指定缩放级别，通过将参数公式化为 `first_peptide * -5`，我们可以获得一个可以容纳五个请求特征的缩放视图。
- en: 'At the time of writing, this recipe generated the following view. Note that
    the very top track is our `my_peptides` track:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在写作时，这个配方生成了如下视图。请注意，最顶部的轨道是我们的 `my_peptides` 轨道：
- en: '![](img/349edda3-92f4-4d48-9e45-582d00e9480c.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](img/349edda3-92f4-4d48-9e45-582d00e9480c.png)'
- en: There's more...
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多内容……
- en: You may have noticed that this recipe actually plots whole genes, and not the
    peptide hits we started with. Plotting the genes is the simplest case, but going
    to the peptides requires only a small change. In *Step 5*, we create an object, `genes_for_prots`,
    which gives the start and end of the genes. The earlier `msnid@psms` object contains
    starts and ends of peptides within those genes, indexed from the start of the
    hit, so by adding one to the other, it is possible to create an object that represents
    the peptides and not the genes.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能注意到，这个示例实际上绘制的是整个基因，而不是我们最初开始时的肽段命中数据。绘制基因是最简单的情况，但要绘制肽段只需要稍作修改。在*步骤 5*中，我们创建了一个对象`genes_for_prots`，它给出了基因的起始和结束位置。早期的`msnid@psms`对象包含这些基因内肽段的起始和结束位置，这些位置是从命中开始处索引的，因此通过将两个数据合并在一起，就可以创建一个代表肽段而非基因的对象。
- en: For those of you not working with organisms in the UCSC browser, it is still
    possible to generate a GFF file of the hits to upload into another genome browser—many
    offer this functionality. Simply stop the recipe at the end of *Step 5* and use
    the `rtracklayer::export()` function to create a GFF file.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 对于那些没有使用UCSC浏览器中的生物体的用户，仍然可以生成命中的GFF文件，并上传到其他基因组浏览器——许多浏览器都提供这种功能。只需在*步骤 5*结束时停止该示例，并使用`rtracklayer::export()`函数创建一个GFF文件。
- en: Visualizing distributions of peptide hit counts to find thresholds
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可视化肽段命中数分布以找到阈值
- en: Every MS experiment will need some idea of the peptide hit counts that represent
    noise or unusual features, such as over-represented peptides in the proteome.
    In this recipe, we'll use some neat visualization tricks using `tidyverse` tools
    such as `dplyr` and `ggplot` to create graphics that will help you get an idea
    of the spread and limits of the peptide hits in your mass spectrometry experiment.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 每个质谱实验都需要了解哪些肽段命中数代表噪声或异常特征，例如在蛋白质组中出现过度表达的肽段。在这个示例中，我们将使用`tidyverse`工具，如`dplyr`和`ggplot`，结合一些巧妙的可视化技巧，创建图形，帮助你了解质谱实验中肽段命中的分布和限制。
- en: Getting ready
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: For this recipe, you'll require the `MSnId`, `data.table`, `dplyr`, and `ggplot` packages.We'll
    use the `mzid` file, `HeLa_180123_m43_r2_CAM.mzid.gz`, from the `datasets/ch6` folder
    of this book's repository.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个示例，你将需要`MSnId`、`data.table`、`dplyr`和`ggplot`包。我们将使用来自本书仓库`datasets/ch6`文件夹中的`mzid`文件`HeLa_180123_m43_r2_CAM.mzid.gz`。
- en: How to do it...
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何实现...
- en: 'Visualizing distributions of peptide hit counts to find thresholds can be done
    using the following steps:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化肽段命中数分布以找到阈值，可以使用以下步骤完成：
- en: 'Load the libraries and data:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载库和数据：
- en: '[PRE13]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Filter out decoy data rows and get a count of every time a peptide appears:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 过滤掉虚假数据行，并统计每个肽段出现的次数：
- en: '[PRE14]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Create a violin and jitter plot of the hit counts:'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个小提琴图和抖动图，显示命中计数：
- en: '[PRE15]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Create a plot of cumulative hit counts for peptides sorted by hit count:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个肽段命中数的累计图，并按命中数排序：
- en: '[PRE16]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Filter out very low and very high peptide hits and then replot them:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 过滤掉非常低和非常高的肽段命中数，然后重新绘制它们：
- en: '[PRE17]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: How it works...
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In *Step 1*, we do some library loading and add a data loading step. As we mentioned
    previously, with `MSnID`, this is a little unusual. Instead of just calling a
    file reading function, we must first create and empty the `MSnID` object and load
    the data into it. We create `msnid` with the `MSnID()` function and then pass
    it to the `read_mzid()` function to actually put data into it. Next, we use the
    `as()` function to convert `msnid` into a `data.table` object—a data frame-like
    object that is optimized for large datasets.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤 1*中，我们进行了一些库加载，并添加了数据加载步骤。如前所述，使用`MSnID`时，情况有些不同。我们不是直接调用文件读取函数，而是首先创建并清空`MSnID`对象，然后将数据加载到其中。我们通过`MSnID()`函数创建`msnid`，然后将其传递给`read_mzid()`函数，以实际将数据放入其中。接下来，我们使用`as()`函数将`msnid`转换为`data.table`对象——一个像数据框的对象，专门为大数据集优化。
- en: In *Step* *2*, we prepare a plot using the `tidyverse` packages, `dplyr` and
    `ggplot`. `tidyverse` packages all work really well in concert as they're centered
    on working with data frames. The usual way of working is to use the piping operator, `%>%`,
    to pass data from one function to another without having to save the interim object.
    By convention, the result of the upstream function is passed as the first argument
    of the downstream function, so we don't need to specify it. This results in the
    construction we have here. We take the `peptide_info` object and pass it through
    the `%>%` operator to the `dplyr filter()` function, which does its work and passes
    its result onto the `group_by()` function and so on. Each function does its work
    and passes the data on. So, in this pipeline, we use `filter()` to keep all the
    rows that are not decoys, and then use `group_by(pepSeq)` to group the long `data.table`
    into subtables according to the value of the `pepSeq` row – effectively getting
    one table per peptide sequence. The next step uses `summarise()`, which generates
    a summary table containing a column called `count` that contains the result of
    the `n()` function, which counts rows in a table, giving us a table with one row
    per peptide, telling us how many times the peptide appears in the table. It's
    a good idea to step through the code one function at a time if it isn't clear
    how these objects are building up. Finally, we use `mutate()` to add a new column
    called `sample` to the table, which simply creates a column of the same length
    as the current table, fills it with the word `peptide_counts`, and adds it to
    the table. The table is saved in a variable called `per_peptide_counts`.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤* *2*中，我们使用`tidyverse`包中的`dplyr`和`ggplot`准备图形。`tidyverse`包相互协作得非常好，因为它们专注于处理数据框。通常的工作方式是使用管道操作符`%>%`将数据从一个函数传递到另一个函数，而无需保存中间对象。按照惯例，上游函数的结果作为下游函数的第一个参数传递，因此我们不需要显式指定它。这就形成了我们所见的结构。我们将`peptide_info`对象通过`%>%`操作符传递给`dplyr
    filter()`函数，后者执行工作并将结果传递给`group_by()`函数，依此类推。每个函数执行完后将数据传递给下一个函数。因此，在这个管道中，我们使用`filter()`保留所有不是诱饵的行，然后使用`group_by(pepSeq)`将长`data.table`根据`pepSeq`行的值分组为子表——实际上就是按肽序列获取一个表格。接下来的步骤使用`summarise()`，它生成一个包含`count`列的汇总表，`count`列的内容是`n()`函数的结果，`n()`函数统计表格中的行数，得出的表格每行代表一个肽，告诉我们这个肽在表中出现的次数。如果不清楚这些对象是如何逐步构建起来的，逐个函数地调试代码是个好主意。最后，我们使用`mutate()`添加一个名为`sample`的新列到表中，这列的长度与当前表相同，并填充为`peptide_counts`，然后将其添加到表中。该表被保存在名为`per_peptide_counts`的变量中。
- en: 'In *Step 3*, we pipe the `per_peptide_counts` data to the `ggplot()` function,
    which sets up a `ggplot` object. These are built-in layers, so we use the `+`
    operator to add an aesthetic layer using the `aes()` function. This usually contains
    the variables to plot on the x and y axes – here, these are `sample` and `count`.
    Then, we use `+` again to add a `geom` – a layer that defines what a plot should
    look like. First, we add `geom_jitter()`, which plots the points, adding a bit
    of random x and y noise to spread them out a little. We then add another geom,
    `geom_violin()`, which gives a violin density plot. Finally, we add a scale layer,
    converting the scale into a log base 10 scale. The resulting plot looks like this:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤 3*中，我们将`per_peptide_counts`数据传递给`ggplot()`函数，该函数会设置一个`ggplot`对象。这些是内置层，因此我们使用`+`操作符通过`aes()`函数添加一个美学层。这个层通常包含要绘制在x轴和y轴上的变量——在这里，它们是`sample`和`count`。然后，我们再次使用`+`来添加一个`geom`——一个定义图形外观的层。首先，我们添加`geom_jitter()`，它绘制数据点，并在x轴和y轴上添加一些随机噪声，使点略微分散开。接着，我们添加另一个geom，`geom_violin()`，它生成一个小提琴密度图。最后，我们添加一个尺度层，将尺度转换为以10为底的对数尺度。最终的图形如下所示：
- en: '![](img/ca924fb6-0eb5-4b31-b30b-74551e87dad2.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ca924fb6-0eb5-4b31-b30b-74551e87dad2.png)'
- en: 'In *Step 4*, we create a cumulative hits plot by piping the `per_peptide_counts`
    data to the `arrange()` function, which sorts a data frame in ascending order
    by the variable specified (in this case, count). The result is piped to mutate
    to add a new column called `cumulative_hits`, which gets the result of the `cumsum()`
    function on the count column. We also add a column called `peptide`, which gets
    the row number of the table, but also gives us a convenient variable so that we
    can order the peptides in the plot. We can generate the plot by piping the sorted
    data directly to `ggplot()` and adding the `aes()` function so that `peptide`
    is on the x-axis and `cumulative_hits` is on the y-axis. Then by adding `geom_line()`,
    the resulting plot appears as follows:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第4步*中，我们通过将`per_peptide_counts`数据传递给`arrange()`函数，创建了一个累计命中图表。该函数按照指定的变量（在此案例中为计数）对数据框进行升序排序。结果被传递给`mutate()`，以添加一个新列`cumulative_hits`，它的值是`cumsum()`函数对计数列的计算结果。我们还添加了一个名为`peptide`的列，它获取表格的行号，同时也提供了一个方便的变量，使我们可以在图表中按顺序排列肽段。我们可以通过将排序后的数据直接传递给`ggplot()`并添加`aes()`函数来生成图表，使得`peptide`显示在x轴，`cumulative_hits`显示在y轴。然后，通过添加`geom_line()`，生成的图表如下所示：
- en: '![](img/bd630ef1-f6af-4ca3-8a35-f55ce24d8de0.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bd630ef1-f6af-4ca3-8a35-f55ce24d8de0.png)'
- en: From the two plots, we can see the spread of hits and assess which thresholds
    we wish to apply.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 从两个图表中，我们可以看到数据点的分布，并评估我们希望应用的阈值。
- en: 'With *Step 5*, we use the `filter()` function again to retain rows with a value
    of count over 5 and below 2500 and put that new data into the same plot recipe
    we made in *Step 3*. This gives us the following plot, showing the removal of
    points outside the thresholds:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第5步*中，我们再次使用`filter()`函数，保留计数值大于5且小于2500的行，并将这些新数据放入我们在*第3步*中创建的同一绘图配方中。这将生成如下图表，显示了阈值外的点被移除：
- en: '![](img/42a4fa9b-af31-4481-9e57-c5964eff9868.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![](img/42a4fa9b-af31-4481-9e57-c5964eff9868.png)'
- en: Converting MS formats to move data between tools
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 转换MS格式以在工具之间移动数据
- en: It's an unavoidable fact of bioinformatics life that we spend a lot of time
    converting between file formats. In this brief recipe, we'll look at some convenient
    methods in R, that allows us to convert between MS data formats.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在生物信息学中，我们花费大量时间在不同文件格式之间转换，这是不可避免的事实。在这个简短的配方中，我们将介绍一些R语言中的方便方法，帮助我们在MS数据格式之间进行转换。
- en: Getting ready
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: For this recipe, we require the `mzR` package and the `threonine_i2_e35_pH_tree.mzXML`
    file from the `datasets/ch6` folder of this book's repository. Some of the dependencies
    rely on encapsulated Java code, so you'll need to install a **Java Runtime Environment**
    (**JRE**) for your system; refer to [https://docs.oracle.com/goldengate/1212/gg-winux/GDRAD/java.htm](https://docs.oracle.com/goldengate/1212/gg-winux/GDRAD/java.htm) for
    instructions. Install the JRE before the R packages.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个配方，我们需要使用`mzR`包和来自本书仓库`datasets/ch6`文件夹中的`threonine_i2_e35_pH_tree.mzXML`文件。某些依赖项依赖于封装的Java代码，因此你需要为你的系统安装**Java运行时环境**（**JRE**）；有关安装说明，请参考[https://docs.oracle.com/goldengate/1212/gg-winux/GDRAD/java.htm](https://docs.oracle.com/goldengate/1212/gg-winux/GDRAD/java.htm)。请在安装R包之前安装JRE。
- en: How to do it...
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Converting MS formats to move data between tools can be done using the following
    steps:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下步骤可以在工具之间转换MS格式：
- en: 'Load the library and import the source data file:'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载库并导入源数据文件：
- en: '[PRE18]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Extract the header and peak data:'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提取标题和峰数据：
- en: '[PRE19]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Write the data into a new format file:'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据写入新格式的文件：
- en: '[PRE20]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: How it works...
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The first step is a straightforward data loading step that we've seen in previous
    recipes. We use the `openMSfile()` function, which autodetects the input file
    type.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是一个简单的数据加载步骤，我们在之前的配方中见过。我们使用`openMSfile()`函数，它会自动检测输入文件类型。
- en: '*Step 2* is the key step; to create output, we need to make a header object
    and a peak list. So, we use the `header()` and `spectra()` accessor functions
    to extract them from our `mzdata` object. The output function will require a list,
    so if you only have one spectrum in the file, use the `list()` function to wrap
    the `spectra()` function.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '*第2步*是关键步骤；为了创建输出，我们需要制作一个标题对象和一个峰值列表。因此，我们使用`header()`和`spectra()`访问器函数从我们的`mzdata`对象中提取它们。输出函数将需要一个列表，因此如果文件中只有一个光谱，使用`list()`函数将`spectra()`函数包装起来。'
- en: The final step is to write the file; here, the first argument is the peak list,
    the second is the name of the file to be created, and the third is the output
    format of your choice – you can choose from `mzml`, `mzxml`, and `mzdata`. The
    final argument states whether the retention times are coded in seconds; selecting
    `FALSE` sets the output to be written in minutes.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 最后的步骤是写入文件；在这里，第一个参数是峰值列表，第二个参数是要创建的文件名称，第三个参数是你选择的输出格式—可以选择`mzml`、`mzxml`和`mzdata`。最后一个参数表示保留时间是否以秒为单位编码；选择`FALSE`会将输出设置为以分钟为单位。
- en: Matching spectra to peptides for verification with protViz
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用protViz进行光谱与肽段的匹配验证
- en: Although most spectra/peptide matching is done in high throughput search engines,
    there are times when you'd like to check the quality of competing ambiguous matches
    against one another, or against a completely arbitrary sequence of interest. Running
    the whole search engine pipeline is probably overkill, so, in this recipe, we'll
    look at a convenient method to run a single spectrum against a single peptide
    sequence and get a plot of congruence between theoretical ion sizes and those
    present in the spectrum.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管大多数光谱/肽段匹配是在高通量搜索引擎中完成的，但有时你可能希望检查竞争的模糊匹配的质量，或者与一个完全任意的感兴趣序列进行比较。运行整个搜索引擎管道可能是过于复杂的操作，因此在本教程中，我们将介绍一种便捷的方法，用于将单个光谱与单个肽段序列匹配，并生成理论离子大小与光谱中存在的离子之间的吻合图。
- en: Getting ready
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: For this recipe, all we need is the `protViz` package, the `mzR` package, and
    the `MM8.mzml` file from the `datasets/ch6` folder of this book's repository.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本教程，我们只需要`protViz`包、`mzR`包以及本书仓库中`datasets/ch6`文件夹下的`MM8.mzml`文件。
- en: How to do it...
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何实现...
- en: 'Matching spectra to peptides with `protViz` can be done by using the following
    steps:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`protViz`将光谱与肽段匹配可以通过以下步骤完成：
- en: 'Load in the libraries and the MS data:'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载库和MS数据：
- en: '[PRE21]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Extract the peaks and retention time from the spectrum:'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从光谱中提取峰值和保留时间：
- en: '[PRE22]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Create a plot of theoretical versus observed ion masses:'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建理论与观测离子质量的图表：
- en: '[PRE23]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: How it works...
  id: totrans-144
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In *Step 1*, we load the libraries and use the `mzR` function, `openMSFile()`,
    to create the object representing the mass spectrometer data.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤1*中，我们加载所需的库，并使用`mzR`函数`openMSFile()`来创建代表质谱数据的对象。
- en: In *Step 2*, we use the `peaks()` function, which will extract the retention
    time and peak intensity as a matrix object. Note that the first column contains
    the retention time, while the second contains the intensity. The second argument
    to `peaks()` is the index of the spectrum we want, so we're getting the second
    spectrum in this file. If this argument is omitted, we get a list of all spectra.
    For the next step, we need to wrap the retention time and intensity data in a
    list, which we do by using the `list()` function, with members named `mZ` and
    `intensity`.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤2*中，我们使用`peaks()`函数，该函数会将保留时间和峰值强度提取为矩阵对象。注意，第一列包含保留时间，而第二列包含强度。`peaks()`的第二个参数是我们需要的光谱的索引，因此我们正在获取该文件中的第二个光谱。如果省略此参数，则会返回所有光谱的列表。接下来的步骤中，我们需要将保留时间和强度数据封装在一个列表中，我们使用`list()`函数完成此操作，列表的成员命名为`mZ`和`intensity`。
- en: 'Finally, we can make the plot using the `psm()` function. This function takes
    a sequence as its first argument (here, it''s a nonsense one to guarantee a poor
    match) and the spectrum data list we made previously as its second argument. By
    setting the plot argument to `TRUE`, we get the following resulting plot:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以使用`psm()`函数生成图表。该函数的第一个参数是一个序列（这里是一个无意义的序列，保证匹配不佳），第二个参数是我们之前创建的光谱数据列表。通过将图表参数设置为`TRUE`，我们可以得到如下结果图表：
- en: '![](img/3da98830-bbff-4fcc-9616-c7f61cf712f4.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3da98830-bbff-4fcc-9616-c7f61cf712f4.png)'
- en: In the plot, each point represents the difference between a predicted ion mass
    and the nearest mass observed in the spectra. Here, we can see that the ions b8,
    b7, and c1 are all around 1 Da, or more divergent in mass from any of the predicted
    masses, suggesting a poor fit to the spectrum for this peptide sequence.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在图表中，每个点表示预测离子质量与光谱中最接近的观测质量之间的差异。我们可以看到，离子b8、b7和c1的质量偏差约为1 Da，或者与任何预测质量相比更为分散，表明该肽段序列与光谱的拟合效果较差。
- en: Applying quality control filters to spectra
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对光谱应用质量控制过滤器
- en: Quality control of raw proteomics data is an essential step in ensuring that
    pipelines and analyses give believable and useful results. A large number of metrics
    and plots of data are needed to get a view of whether a particular experiment
    has been a success, and that means carrying out a lot of analysis before we start
    to actually derive any new knowledge from the data. In this recipe, we'll look
    at an integrated pipeline that carries out a wide range of relevant and useful
    QC steps and presents the result as a single helpful and readable report.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 原始蛋白质组学数据的质量控制是确保管道和分析能够给出可信和有用结果的关键步骤。需要大量的指标和数据图表来评估特定实验是否成功，这意味着在我们开始从数据中提取任何新知识之前，必须进行大量的分析。在这个配方中，我们将查看一个集成的管道，该管道执行一系列相关且有用的质量控制步骤，并将结果呈现为一个单一的、易于阅读的报告。
- en: Getting ready
  id: totrans-152
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: In this recipe, we'll be examining an Escherichia coli cell membrane proteomics
    experiment. This will require a large file that was too big to host in this book's
    repository, so we'll use code to download it directly. Due to this, you will need
    to be online for this recipe to work. We'll also need a file of the target organism
    peptides, that is, the `Escherichia_coli.pep.all.fa` file, which can be found
    in the `datasets/ch6` folder of this book's repository. Our main functions will
    come from the `proteoQC` library.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配方中，我们将研究大肠杆菌细胞膜的蛋白质组学实验。由于该文件太大，无法在本书的代码库中托管，因此我们将通过代码直接下载它。因此，在进行此实验时，您需要保持在线。我们还需要目标有机体的肽段文件，即`Escherichia_coli.pep.all.fa`文件，可以在本书代码库的`datasets/ch6`文件夹中找到。我们的主要功能将来自`proteoQC`库。
- en: How to do it...
  id: totrans-154
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Quality control filters can be applied to spectra using the following steps:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用以下步骤将质量控制过滤器应用于光谱：
- en: 'Load the library and download the source data:'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载库并下载源数据：
- en: '[PRE24]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Create a design file:'
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建设计文件：
- en: '[PRE25]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Set up the QC pipeline and run the following command:'
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置质量控制管道并运行以下命令：
- en: '[PRE26]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: How it works...
  id: totrans-162
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: After loading in the library in *Step 1*, we set up the URL to the file we want
    to pull over the internet from [http://www.proteomexchange.org/](http://www.proteomexchange.org/);
    we're after just one file in accession `PXD006247`, and we save the URL in the
    `online_file` variable. We also create an `mzmxl_file` variable that points to
    a non-existent file, `PXD006247_mz.xml.gzX`, on our local filesystem – this will
    be the saved name of the downloaded file. The `download.file()` function actually
    does the downloading; the first argument is the online source, while the second
    argument is the place to put the file on the local machine when it downloads.
    The final argument, `internal`, is the download method to use. The setting we've
    chosen should use a system-agnostic downloader that works anywhere, but you can
    change this to other faster or more system-specific settings if you like. The
    documentation will explain these options.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤 1*中加载库后，我们设置要从[http://www.proteomexchange.org/](http://www.proteomexchange.org/)获取的文件的URL；我们只需要获取`PXD006247`这个文件，并将URL保存在`online_file`变量中。我们还创建了一个指向本地文件系统中不存在的文件`PXD006247_mz.xml.gzX`的`mzmxl_file`变量——这将是下载文件保存的名称。`download.file()`函数实际上执行下载；第一个参数是在线源，第二个参数是文件下载到本地机器的存放位置。最后一个参数`internal`是下载方法。我们选择的设置应该使用一个系统无关的下载器，可以在任何地方使用，但如果你喜欢，也可以将其更改为其他更快或更符合系统的设置。文档将解释这些选项。
- en: 'In *Step 2*, we create a design file that describes the experiment. In our
    small demo, we only have one file, but you can specify many more here. In the
    first part, we create a dataframe with the columns **file**, **sample**, **bioRep**,
    **techRep**, and **fraction**. We only have one file, so the table only has one
    row. It looks like this:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤 2*中，我们创建一个设计文件，描述实验。在我们的小示例中，我们只有一个文件，但你可以在此处指定更多文件。在第一部分，我们创建一个数据框，包含**文件**、**样本**、**生物重复**、**技术重复**和**分级**列。我们只有一个文件，所以表格只有一行。它看起来是这样的：
- en: '| **file** | **sample** | **bioRep** | **techRep** | **fraction** |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| **文件** | **样本** | **生物重复** | **技术重复** | **分级** |'
- en: '| `PXD006247_mz.xml.gz` | 1 | 1 | 1 | 1 |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| `PXD006247_mz.xml.gz` | 1 | 1 | 1 | 1 |'
- en: If you had a more complicated experiment, you'd have many more rows describing
    the sample and bioRep, for example, for each file. We then save this file to disk
    for use in the next step using `write.table()` along with the appropriate options.
    Note that although, for the sake of demonstration, we've created this file programmatically,
    the file would be equally valid if we'd created it by hand in a spreadsheet program
    or text editor.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的实验更为复杂，那么每个文件会有更多的行来描述样本和生物重复（bioRep）。接下来，我们使用`write.table()`和适当的选项将这个文件保存到磁盘，以便在下一步中使用。需要注意的是，虽然为了演示目的，我们是通过编程方式创建了这个文件，但如果我们通过电子表格程序或文本编辑器手动创建它，这个文件同样有效。
- en: Finally, we set up and run the QC pipeline in *Step 3*. The main function, `msQCpipe()`,
    is the workhorse and needs a few option settings. The `spectralist` option needs
    the path to the design file we created so that it knows which files to open and
    how to treat them. The `fasta` option requires the file of the target organism
    protein sequences in `fasta` format. This allows the QC pipeline to carry out
    spectral peptide identification using `XTandem` from the `rtandem` package. The
    `outdir` argument gets the path to a new folder that will hold the numerous report
    files that will be created. Here, our folder will be called `qc_result`, and it
    will be a sub-directory of the current working directory. The arguments `enzyme`,
    `varmod`, and `fixmod` describe the enzyme used for digest (1 = trypsin), the
    variable modifications that may be present, and the fixed modifications that will
    be present on all residues. The arguments `tol` and `itol` specify tolerances
    on peptide mass values and error windows. The `cpu` argument specifies the compute
    cores to use on the source machine and `mode` specifies the sort of run to do.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们在*第3步*中设置并运行QC流程。主要函数`msQCpipe()`是核心部分，需要一些选项设置。`spectralist`选项需要指向我们创建的设计文件路径，以便知道打开哪些文件以及如何处理它们。`fasta`选项需要目标生物体蛋白质序列的`fasta`格式文件。这使得QC流程能够使用`rtandem`包中的`XTandem`进行谱肽识别。`outdir`参数指定了一个新文件夹的路径，用于保存将要创建的众多报告文件。在这里，我们的文件夹将被命名为`qc_result`，并且它将是当前工作目录的一个子目录。`enzyme`、`varmod`和`fixmod`参数分别描述了用于消化的酶（1
    = 胰蛋白酶）、可能存在的可变修饰以及所有残基上将存在的固定修饰。`tol`和`itol`参数指定了肽质量值的容差和误差窗口。`cpu`参数指定了源机器上要使用的计算核心数，而`mode`参数指定了运行的类型。
- en: When the QC pipeline completes, we get a series of reports in the `qc_result`
    folder. The `qc_report.html` file contains the browsable results of QC. The many
    pages describing the results should allow you to see the extent to which the experiment
    was a success.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 当QC流程完成后，我们会在`qc_result`文件夹中得到一系列报告。`qc_report.html`文件包含了可以浏览的QC结果。多个描述结果的页面应该能够让你了解实验的成功程度。
- en: There's more...
  id: totrans-170
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多…
- en: To find the proper values for the `enzyme`, `varmod`, and `fixmod` variables,
    you can use the `showMods()` and `showEnzymes()` functions to see a list and their
    key numbers.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 要找到合适的`enzyme`、`varmod`和`fixmod`变量值，你可以使用`showMods()`和`showEnzymes()`函数查看列表及其关键数字。
- en: Identifying genomic loci that match peptides
  id: totrans-172
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 确定与肽匹配的基因组位点
- en: Finding the exact places on a genome that a peptide matches to can be a challenging
    task, especially if the genome is one that is not represented by the original
    search file. In this recipe, we'll look at mixing in a classic command-line BLAST
    recipe to find short, nearly precise matches for peptides on a translated genome
    sequence to various R genomics pipelines by targeting a `GRanges` object of the
    BLAST hits.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 找到基因组中肽匹配的确切位置可能是一个具有挑战性的任务，尤其是当基因组没有出现在原始搜索文件中时。在这个方法中，我们将结合使用经典的命令行BLAST方法，在翻译后的基因组序列中寻找短的、几乎精确的肽匹配，并通过针对BLAST命中的`GRanges`对象，将其与各种R基因组学管道相结合。
- en: Getting ready
  id: totrans-174
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备就绪
- en: For this recipe, we'll use the `MSnID`, `dplyr`, `withR`, `GenomicRanges`, and
    `Biostrings` packages and a search engine output file of Escherichia coli-derived
    spectra, which can be found in the `PXD006247.mzXML.mzid` file in this book's
    `datasets/ch6` folder. You'll also need to have a locally installed version of
    BLAST+. You can install this using the conda package manager with `conda install
    -c bioconda blast` . You'll also need to know where the tblastn program from BLAST+
    was installed. You can find this on macOS and Linux systems with the Terminal
    command, `which tblastn`, and on Windows.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个食谱，我们将使用`MSnID`、`dplyr`、`withR`、`GenomicRanges`和`Biostrings`包，以及来自大肠杆菌谱图的搜索引擎输出文件，该文件可以在本书的`datasets/ch6`文件夹中的`PXD006247.mzXML.mzid`文件中找到。你还需要本地安装BLAST+版本。可以通过conda包管理器使用`conda
    install -c bioconda blast`命令安装。你还需要知道BLAST+中的tblastn程序安装的位置。可以在macOS和Linux系统上使用终端命令`which
    tblastn`找到，Windows系统亦然。
- en: How to do it...
  id: totrans-176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Genomic loci that match peptides can be identified using the following steps:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用以下步骤来识别与肽段匹配的基因组位点：
- en: 'Load in the libraries and the data:'
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载库和数据：
- en: '[PRE27]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Extract the peptide sequence and save it as a fasta file:'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提取肽段序列并将其保存为fasta文件：
- en: '[PRE28]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Prepare the filenames for the BLAST run:'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 准备BLAST运行的文件名：
- en: '[PRE29]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Prepare the `BLAST` command:'
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 准备`BLAST`命令：
- en: '[PRE30]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Run BLAST as a background process:'
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将BLAST作为后台进程运行：
- en: '[PRE31]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Convert BLAST into `GFF` and `GRanges`:'
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将BLAST转换为`GFF`和`GRanges`：
- en: '[PRE32]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: How it works...
  id: totrans-190
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: '*Step 1* loads the libraries and uses the `MSnID` package to load the data
    into an object that we then process using a `dplyr` pipeline, as described in
    *Step 2* of *Recipe 3* in this chapter. Look there for an in-depth explanation
    of this sort of syntax if you''re not familiar with it. Briefly, even though the
    pipeline removes rows that are decoys, it keeps only the `spectrumID` and `pepSeq`
    columns and adds a new column called `fasta_id`, which pastes the spectrum ID
    as a unique number. The resulting data frame is saved to the `peptide_info` variable.'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '*步骤 1*加载库，并使用`MSnID`包将数据加载到一个对象中，然后使用`dplyr`管道进行处理，正如本章中*食谱 3*的*步骤 2*所描述的。如果你不熟悉这种语法，可以查看那里进行深入解释。简而言之，虽然管道移除了假设行，但它仅保留`spectrumID`和`pepSeq`列，并添加了一个名为`fasta_id`的新列，该列将谱图ID粘贴为唯一编号。结果数据框被保存到`peptide_info`变量中。'
- en: '*Step 2* creates a `Biostrings` object from the `peptide_info$pepSeq` column
    using the `peptide_info$fasta_id` column for the names with the `names()` function.
    The resulting string_set `BioStrings` object is then written to disk in a fasta
    format file with the name `peptides.fa` using the `writeXStringSet()` function.
    Note the index `[1]` on the end of `string_set`; this is a small hack to make
    sure only the first peptide is written. We want this *only* because this is a
    demonstration and we want the code to complete in a short amount of time. For
    a genuine analysis, you can leave the index completely and write all the sequences
    to disk.'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '*步骤 2*使用`peptide_info$pepSeq`列和`peptide_info$fasta_id`列的名称，通过`names()`函数创建一个`Biostrings`对象。然后，使用`writeXStringSet()`函数将结果`BioStrings`字符串集对象以fasta格式写入名为`peptides.fa`的文件。请注意，`string_set`末尾的索引`[1]`；这是一个小技巧，确保只写入第一个肽段。我们之所以这样做，*仅仅是*因为这是一个演示，且我们希望代码在短时间内完成。对于真实分析，你可以完全去掉索引，写入所有的序列。'
- en: In *Step 3*, we just set up the filenames for the input and output files for
    the BLAST run. Note that the reference genome we map to `ecoli_genome.fasta` will
    be in the `datasets/ch6` folder of this book's repository .
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤 3*中，我们只是设置了BLAST运行的输入和输出文件名。请注意，我们映射到的参考基因组`ecoli_genome.fasta`将位于本书的`datasets/ch6`文件夹中的仓库内。
- en: In *Step 4*, we specify the `BLAST` command, while the code here is a simple
    pasting of variables and text to make one long character string that we save in
    the command. This is worth looking at in some detail. The first lines specify
    the BLAST+ program to run; here, `tblastn`, which uses protein inputs and a translated
    nucleotide database. The next three lines specify the input peptide sequences,
    the reference genome against which to BLAST, and the output file in which we save
    the results. The final long lines specify the BLAST+ options that allow for short,
    nearly precise matches. With these particular options set, BLAST runs can take
    a while, so it's a good idea to run just one sequence while you're developing.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤 4*中，我们指定了`BLAST`命令，这里的代码只是简单地将变量和文本粘贴在一起，形成一个长字符串并保存到命令中。值得详细查看的是，第一行指定了要运行的BLAST+程序；这里是`tblastn`，它使用蛋白质输入和翻译后的核苷酸数据库。接下来的三行指定了输入的肽序列、用于BLAST的参考基因组，以及保存结果的输出文件。最后的长行指定了BLAST+选项，以允许进行短小且几乎精确的匹配。设置了这些特定选项后，BLAST运行可能需要一些时间，因此在开发过程中建议只运行一个序列。
- en: In *Step 5*, with the `BLAST` command specified, we can run the actual BLAST.
    Our main function here is the base R function, `system()`, which will run a system
    command in the background. However, to help this function be portable across systems,
    we are using the `withR` library function `with_path()`, which temporarily adds
    a particular folder to the system's PATH – a list of folders that contain programs.
    This step is necessary because sometimes, R and RStudio don't pick up non-standard
    install locations like those used by the conda package manager. Hence, the first
    argument here is the path to the `tblastn` folder. Note that `/Users/macleand/miniconda2/bin` is
    the path on my machine; you'll need to get the value for your machine using something
    like `which tblastn` on the terminal or command line and substitute that. Once
    that path is added by `with_path()`, it will run its second argument, our `system()`
    function, which, in turn, runs BLAST. The actual running of the BLAST program
    will take some time.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤 5*中，指定了`BLAST`命令后，我们可以执行实际的BLAST。我们这里的主要函数是基本的R函数`system()`，它将在后台运行系统命令。然而，为了帮助这个函数在不同系统之间移植，我们使用了`withR`库中的`with_path()`函数，它暂时将一个特定文件夹添加到系统的PATH中——这个PATH是包含程序的文件夹列表。这个步骤是必要的，因为有时R和RStudio不会识别非标准的安装位置，比如conda包管理器使用的那些位置。因此，这里第一个参数是`tblastn`文件夹的路径。注意，`/Users/macleand/miniconda2/bin`是我机器上的路径；你需要使用类似`which
    tblastn`的命令在终端或命令行中获取你机器上的路径，并进行替换。添加路径后，`with_path()`将运行其第二个参数，我们的`system()`函数，进而运行BLAST。实际运行BLAST程序会花费一些时间。
- en: Once the command completes, in *Step 6*, we start by loading the output file
    made by BLAST into the results variable using the `read.table()` function. We
    then create a custom function to convert the rows of results to a GFF-compatible
    table. The `blast_to_gff()` function uses the `dplyr mutate()` function to add
    the relevant columns, and then it uses the `select()` function with the `-` option
    to select columns not beginning with the letter V, which all the original columns
    did. We can now use the `GenomicRanges` function, `makeGRangesFromDataFrame()`,
    to convert our GFF style dataframe into a `GRanges` object. This is the final
    part, and we now have an object of genomic loci that matches peptides that can
    be used in all the standard genomics pipelines in R and that are used in the genomics
    recipes in this book.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦命令完成，在*步骤 6*中，我们首先通过`read.table()`函数将BLAST生成的输出文件加载到结果变量中。然后，我们创建一个自定义函数，将结果的行转换为GFF兼容的表格。`blast_to_gff()`函数使用`dplyr
    mutate()`函数添加相关列，然后使用`select()`函数与`-`选项选择不以字母V开头的列，因为所有原始列的名称都是以V开头的。现在我们可以使用`GenomicRanges`函数`makeGRangesFromDataFrame()`，将我们的GFF风格数据框转换为`GRanges`对象。这是最后一步，我们现在拥有一个匹配肽的基因组位置对象，可以在R的所有标准基因组学管道中使用，并且可以在本书中的基因组学配方中使用。
